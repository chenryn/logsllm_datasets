某些元素具有id属性，可以用来在页面上唯一地确定该元素。你常常会告诉程
序，根据元素的id属性来寻找它。所以利用浏览器的开发者工具，弄清楚元素的id
属性，这是编写Web抓取程序常见的任务。
11.4.3 查看网页的HTML源代码
对于程序要处理的网页，你需要查看它的HTML源代码。要做到这一点，在浏
览器的任意网页上点击右键（或在OS X上Ctrl-点击），选择View Source或View page
source，查看该页的 HTML 文本（参见图 11-3）。这是浏览器实际接收到的文本。
浏览器知道如何通过这个HTML显示或渲染网页。
196 Python编程快速上手——让繁琐工作自动化
图11-3 查看网页的源代码
我强烈建议你查看一些自己喜欢的网站的HTML源代码。在查看源代码时，如果你
不能完全理解，也没有关系。你不需要完全掌握HTML，也能编写简单的Web抓取程序，
毕竟你不是要编写自己的网站。只需要足够的知识，就能从已有的网站中挑选数据。
11.4.4 打开浏览器的开发者工具
除了查看网页的源代码，你还可以利用浏览器的开发者工具，来检查页面的
HTML。在Windows版的Chrome和IE中，开发者工具已经安装了。可以按下F12，
让它们出现（参见图11-4）。再次按下F12，可以让开发者工具消失。在Chrome中，
也可以选择ViewDeveloperDeveloper Tools，调出开发者工具。在OS X中按下 -
Option-I，将打开Chrome的开发者工具。
对于Firefox，可以在Windows和Linux中需要按下Ctrl-Shift-C，或在OS X中按
下 -option-C，调出开发者工具查看器。它的布局几乎与Chrome的开发者工具一样。
第11章 从Web抓取信息 197
图11-4 Chrome浏览器中的开发者工具窗口
在Safari中，打开Preferences窗口，并在Advanced pane选中Show Develop menu
in the menu bar选项。在它启用后，你可以按下 -option-I，调出开发者工具。
在浏览器中启用或安装了开发者工具之后，可以在网页中任何部分点击右键，
在弹出菜单中选择Inspect Element，查看页面中这一部分对应的HTML。如果需要
在Web抓取程序中解析HTML，这很有帮助。
不要用正则表达式来解析HTML
在一个字符串中定位特定的一段HTML，这似乎很适合使用正则表达式。但
是，我建议你不要这么做。HTML 的格式可以有许多不同的方式，并且仍然被认
为是有效的HTML，但尝试用正则表达式来捕捉所有这些可能的变化，将非常繁
琐，并且容易出错。专门用于解析HTML的模块，诸如Beautiful Soup，将更不容
易导致缺陷。在 http://stackoverflow.com/a/1732454/1893164/，你会看到更充分的
讨论，了解为什么不应该用正则表达式来解析HTML。
11.4.5 使用开发者工具来寻找HTML元素
程序利用requests模块下载了一个网页之后，你会得到该页的HTML内容，作为一
个字符串值。现在你需要弄清楚，这段HTML的哪个部分对应于网页上你感兴趣的信息。
这就是可以利用浏览器的开发者工具的地方。假定你需要编写一个程序，从
http://weather.gov/获取天气预报数据。在写代码之前，先做一点调查。如果你访问该网
站，并查找邮政编码94105，该网站将打开一个页面，显示该地区的天气预报。
198 Python编程快速上手——让繁琐工作自动化
如果你想抓取那个邮政编码对应的气温信息，怎么办？右键点击它在页面的位
置（或在OS X上用Control-点击），在弹出的菜单中选择Inspect Element。这将打
开开发者工具窗口，其中显示产生这部分网页的HTML。图11-5展示了开发者工具
打开显示气温的HTML。
图11-5 用开发者工具查看包含温度文本的元素
通过开发者工具，可以看到网页中负责气温部分的 HTML 是57°F。这正是你要找的东西！看起来气温信息包含在一个元素
中，带有 myforecast-current-lrg 类。既然你知道了要找的是什么，BeautifulSoup 模
块就可以帮助你在这个字符串中找到它。
11.5 用 BeautifulSoup 模块解析 HTML
Beautiful Soup是一个模块，用于从HTML页面中提取信息（用于这个目的时，
它比正则表达式好很多）。BeautifulSoup 模块的名称是 bs4（表示 Beautiful Soup，
第4版）。要安装它，需要在命令行中运行pip install beautifulsoup4（关于安装第三
方模块的指导，请查看附录 A）。虽然安装时使用的名字是 beautifulsoup4，但要导
入它，就使用import bs4。
在本章中，Beautiful Soup的例子将解析（即分析并确定其中的一些部分）硬盘
上的一个HTML文件。在IDLE中打开一个新的文件编辑器窗口，输入以下代码，并
第11章 从Web抓取信息 199
保存为example.html。或者，从http://nostarch.com/automatestuff/下载它。
The Website Title
Download my Python book from my website.
Learn Python the easy way!
By Al Sweigart
你可以看到，既使一个简单的HTML文件，也包含许多不同的标签和属性。对
于复杂的网站，事情很快就变得令人困惑。好在，Beautiful Soup让处理HTML变
得容易很多。
11.5.1 从HTML创建一个BeautifulSoup 对象
bs4.BeautifulSoup()函数调用时需要一个字符串，其中包含将要解析的HTML。
bs4.BeautifulSoup()函数返回一个 BeautifulSoup 对象。在交互式环境中输入以下代
码，同时保持计算机与因特网的连接：
>>> import requests, bs4
>>> res = requests.get('http://nostarch.com')
>>> res.raise_for_status()
>>> noStarchSoup = bs4.BeautifulSoup(res.text)
>>> type(noStarchSoup)
这段代码利用requests.get()函数从No Starch Press网站下载主页，然后将响应
结果的 text 属性传递给 bs4.BeautifulSoup()。它返回的 BeautifulSoup 对象保存在变
量noStarchSoup中。
也可以向bs4.BeautifulSoup()传递一个File对象，从硬盘加载一个HTML文件。
在交互式环境中输入以下代码（确保example.html文件在工作目录中）：
>>> exampleFile = open('example.html')
>>> exampleSoup = bs4.BeautifulSoup(exampleFile)
>>> type(exampleSoup)
有了BeautifulSoup对象之后，就可以利用它的方法，定位HTML文档中的特定部分。
11.5.2 用select()方法寻找元素
针对你要寻找的元素，调用method()方法，传入一个字符串作为CSS“选择器”，
这样就可以取得Web页面元素。选择器就像正则表达式：它们指定了要寻找的模
式，在这个例子中，是在HTML页面中寻找，而不是普通的文本字符串。
完整地讨论 CSS 选择器的语法超出了本书的范围（在 http://nostarch.com/
automatestuff/的资源中，有很好的选择器指南），但这里有一份选择器的简单介绍。
200 Python编程快速上手——让繁琐工作自动化
表11-2举例展示了大多数常用CSS选择器的模式。
表11-2 CSS选择器的例子
传递给select()方法的选择器 将匹配…
soup.select('div') 所有名为的元素
soup.select('#author') 带有id属性为author的元素
soup.select('.notice') 所有使用CSS class属性名为notice的元素
soup.select('div span') 所有在元素之内的元素
soup.select('div > span') 所有直接在元素之内的元素，中间没有其他元素
soup.select('input[name]') 所有名为，并有一个name属性，其值无所谓的元素
soup.select('input[type="button"]') 所有名为，并有一个type属性，其值为button的元素
不同的选择器模式可以组合起来，形成复杂的匹配。例如，soup.select('p #author')
将匹配所有id属性为author的元素，只要它也在一个元素之内。
select()方法将返回一个Tag对象的列表，这是Beautiful Soup表示一个HTML
元素的方式。针对BeautifulSoup对象中的HTML的每次匹配，列表中都有一个Tag
对象。Tag值可以传递给str()函数，显示它们代表的HTML标签。Tag值也可以有
attrs属性，它将该Tag的所有HTML属性作为一个字典。利用前面的example.html
文件，在交互式环境中输入以下代码：
>>> import bs4
>>> exampleFile = open('example.html')
>>> exampleSoup = bs4.BeautifulSoup(exampleFile.read())
>>> elems = exampleSoup.select('#author')
>>> type(elems)
>>> len(elems)
1
>>> type(elems[0])
>>> elems[0].getText()
'Al Sweigart'
>>> str(elems[0])
'Al Sweigart'
>>> elems[0].attrs
{'id': 'author'}
这段代码将带有 id="author"的元素，从示例 HTML 中找出来。我们使用
select('#author')返回一个列表，其中包含所有带有 id="author"的元素。我们将这个
Tag对象的列表保存在变量中elems，len(elems)告诉我们列表中只有一个Tag对象，
只有一次匹配。在该元素上调用getText()方法，返回该元素的文本，或内部的HTML。
一个元素的文本是在开始和结束标签之间的内容：在这个例子中，就是'Al Sweigart'。
将该元素传递给 str()，这将返回一个字符串，其中包含开始和结束标签，以及该元
素的文本。最后，attrs给了我们一个字典，包含该元素的属性'id'，以及id属性的值'author'。
也可以从BeautifulSoup对象中找出元素。在交互式环境中输入以下代码：
第11章 从Web抓取信息 201
>>> pElems = exampleSoup.select('p')
>>> str(pElems[0])
'Download my Python book from my website.'
>>> pElems[0].getText()
'Download my Python book from my website.'
>>> str(pElems[1])
'Learn Python the easy way!'
>>> pElems[1].getText()
'Learn Python the easy way!'
>>> str(pElems[2])
'By Al Sweigart'
>>> pElems[2].getText()
'By Al Sweigart'
这一次，select()给我们一个列表，包含3次匹配，我们将它保存在pElems中。
在pElems[0]、pElems[1]和pElems[2]上使用str()，将每个元素显示为一个字符串，
并在每个元素上使用getText()，显示它的文本。
11.5.3 通过元素的属性获取数据
Tag对象的get()方法让我们很容易从元素中获取属性值。向该方法传入一个属性名
称的字符串，它将返回该属性的值。利用example.html，在交互式环境中输入以下代码：
>>> import bs4
>>> soup = bs4.BeautifulSoup(open('example.html'))
>>> spanElem = soup.select('span')[0]
>>> str(spanElem)
'Al Sweigart'
>>> spanElem.get('id')
'author'
>>> spanElem.get('some_nonexistent_addr') == None
True
>>> spanElem.attrs
{'id': 'author'}
这里，我们使用select()来寻找所有元素，然后将第一个匹配的元素保存
在spanElem中。将属性名'id'传递给get()，返回该属性的值'author'。
11.6 项目：“I’m Feeling Lucky”Google 查找
每次我在 Google 上搜索一个主题时，都不会一次只看一个搜索结果。通过鼠
标中键点击搜索结果链接，或在点击时按住CTRL键，我会在一些新的选项卡中打
开前几个链接，稍后再来查看。我经常搜索Google，所以这个工作流程（开浏览器，
查找一个主题，依次用中键点击几个链接）变得很乏味。如果我只要在命令行中输
入查找主题，就能让计算机自动打开浏览器，并在新的选项卡中显示前面几项查询
结果，那就太好了。让我们写一个脚本来完成这件事。
下面是程序要做的事：
202 Python编程快速上手——让繁琐工作自动化
• 从命令行参数中获取查询关键字。
• 取得查询结果页面。
• 为每个结果打开一个浏览器选项卡。
这意味着代码需要完成以下工作：
• 从sys.argv中读取命令行参数。
• 用requests模块取得查询结果页面。
• 找到每个查询结果的链接。
• 调用webbrowser.open()函数打开Web浏览器。
打开一个新的文件编辑器窗口，并保存为lucky.py。
第１步：获取命令行参数，并请求查找页面
开始编码之前，你首先要知道查找结果页面的URL。在进行Google查找后，你
看浏览器地址栏，就会发现结果页面的 URL 类似于 https://www.google.com/
search?q=SEARCH_TERM_HERE。requests 模块可以下载这个页面，然后可以用
Beautiful Soup，找到HTML中的查询结果的链接。最后，用webbrowser模块，在浏
览器选项卡中打开这些链接。
让你的代码看起来像这样：
#! python3
# lucky.py - Opens several Google search results.
import requests, sys, webbrowser, bs4
print('Googling...') # display text while downloading the Google page
res = requests.get('http://google.com/search?q=' + ' '.join(sys.argv[1:]))
res.raise_for_status()
# TODO: Retrieve top search result links.
# TODO: Open a browser tab for each result.
用户运行该程序时，将通过命令行参数指定查找的主题。这些参数将作为字符
串，保存在sys.argv列表中。
第２步：找到所有的结果