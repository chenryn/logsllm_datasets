input. We do not draw this replacement in Figure 3, as it would be
hardly readable.
Then, the state machine is converted to a Markov chain by forget-
ting the bit values and assigning probability 1/2 to each transition.
For 𝑤 = 2, the transition matrix is
(cid:169)(cid:173)(cid:173)(cid:173)(cid:171)
1
2
0 1 1 0 0 0 0 0
0 1 0 0 0 1 0 0
0 0 0 1 1 0 0 0
0 1 0 0 0 1 0 0
0 1 1 0 0 0 0 0
0 0 0 0 0 0 1 1
0 1 0 0 0 1 0 0
0 1 1 0 0 0 0 0
(cid:170)(cid:174)(cid:174)(cid:174)(cid:172) ,
(cid:0)0
which has stationary distribution
1/3
1/12
1/4
1/24
1/24
1/8
1/8(cid:1) .
1(cid:1) ,
𝐻2 =(cid:0)0
Standard theorems on Markov chains [11] let us interpret the sta-
tionary distribution as the probability that the finite state machine
is found in each state at any given time, as 𝑛 → ∞. To compute the
average entropy 𝐻𝑤(𝑥), it is thus sufficient to compute the inner
product of the stationary distribution and the vector 𝐻𝑤 of the
entropy values output by the state machine, in this example
0
0
0
1
0
1
leading to a “per bit” average entropy of 7/24, i.e., 𝐻2(𝑥) = 7𝑛/24
as 𝑛 → ∞, meaning that, given a uniformly sampled 𝑛 + 1-bits
exponent and its leakage 𝑐1, . . . , 𝑐𝐿+1, on average 7𝑛/24 bits remain
to be found.
We can get even more precise information on the distribution of
𝐻𝑤(𝑥) using the Markov chain central limit theorem, which states
that given a sequence of random variables 𝑋1, 𝑋2, . . . representing
the states of a Markov chain, assuming the distribution of 𝑋1, and
thus of any 𝑋𝑖, is the stationary distribution, and given a function
𝐻 assigning values to the states, the variable
ˆ𝐻𝑛 =
1
𝑛
𝐻(𝑋𝑖)
𝑛∑︁
𝑖=1
∞∑︁
𝑖=1
converges in distribution to a normal variate of mean 𝜇 = 𝐻(𝑋1)
and variance 𝜎2/𝑛, where
𝜎2 = var(𝐻(𝑋1)) + 2
cov(𝐻(𝑋1), 𝐻(𝑋1+𝑖)),
as 𝑛 → ∞. This theorem thus approximates the distribution of
𝐻(𝑥)/𝑛; put differently, it proves that as 𝑛 → ∞ the entropy 𝐻(𝑥)
tends to a normal variate of mean 𝑛𝜇 and variance 𝑛𝜎2.
The per bit variance cannot be computed exactly, but it is easily
estimated numerically: in the case 𝑤 = 2 we get 𝜎2 = 0.058449.
Table 1 lists the values of 𝜇 and 𝜎2 for all weights between 2 and
5. Of course, these asymptotic approximations only give a rough
estimate of the actual probability distribution of 𝐻𝑤(𝑥) for a given
bit length 𝑛; however they prove to be quite accurate in practice
even for small values of 𝑛 (as shown in the full version [15]). Us-
ing these approximations, we will give rather precise estimates
of the computational effort needed to recover random secret keys
generated by gcrypt and other libraries.
5.4.2 Key recovery. To assess the practical impact of the leakage
of sliding window exponentiation exposed so far we need to look
into the exact parameters used by the various libraries. Recall that
gcrypt uses short secret exponents, as detailed in Appendix A. The
window size used for exponentiation goes from 1 to 5, depending on
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2074|𝑝|
1024
2048
3072
4096
|𝑞|
166
226
270
306
|𝑥| 𝑤 𝐸(𝐻𝑤(𝑥))
108.94
250
180.62
340
215.79
406
460
244.56
3
4
4
4
Pollard
82.65
113.15
134.65
152.65
vOW
63.04
114.77
141.40
163.16
Table 2: Group (|𝑞|) and secret exponent (|𝑥|) bit sizes, and
window size (𝑤) used by gcrypt for each modulus size (|𝑝|).
𝐸(𝐻𝑤(𝑥)) is the mean leakage entropy estimated using Ta-
ble 1. “Pollard” indicates the (base 2 log of the) expected
running time of Pollard’s Rho algorithm in a group of size
𝑞, as a number of modular multiplications. “vOW” indicates
the expected running time of van Oorschot and Wiener’s
algorithm using a table of 260 entries.
the bit size of the exponent.16 Table 2 summarizes the parameters
adopted by gcrypt for some common modulus sizes.
Based on gcrypt’s parameters, Table 2 also reports on the mean
leakage entropy 𝐻𝑤(𝑥) as analyzed in Section 5.4.1. We can thus
compare the expected difficulty of recovering the secret exponent
via the leakage against the target difficulty of solving discrete loga-
rithms directly. gcrypt’s moduli are parameterized so that the best
algorithm for computing discrete logarithms is, indifferently, index
calculus in Z𝑝, or Pollard’s Rho in the subgroup of largest prime
order 𝑞. For simplicity, we use the cost of Pollard’s Rho, namely
√︁𝜋𝑞/2, as our reference difficulty.17
To exploit the leakage, we resort to vOW parallel collision search
(see Section 3), which costs 7 · 23𝐻𝑤 (𝑥)/4−𝑚/2−1𝐻𝑤(𝑥) modular
multiplications, where 2𝑚 is the amount of RAM available, counted
as a number of hash table entries (e.g., for |𝑝| = 2048 an entry
occupies slightly more than 256 bytes). Both Pollard’s Rho and vOW
can be parallelized with a linear speed-up [38, §5.1–3], justifying
the comparison.
The last two columns of Table 2 report the base 2 logarithm
of the expected efforts of Pollard’s Rho, and of vOW assuming
a hash table with at most 260 entries (note that even this “little”
memory is quite unrealistic). Comparing the columns, the leakage
of windowed exponentiation does not appear to be a serious threat
for the average gcrypt secret key. However this assessment is
deceiving on two accounts: (a) the standard deviation of 𝐻𝑤(𝑥)
is rather large, and thus some keys will be much easier to break
than others; and (b) gcrypt is assumed to be secure even when it
operates on secret keys generated by a different library, as long as
these are valid OpenPGP keys. Some libraries, such as Crypto++,
generate secret exponents with as few as |𝑞| bits, their keys are
thus easier targets.
Taking for reference the most commonly used modulus size
|𝑝| = 2048, Crypto++ exponents are between 1 and 226 bits long,
and the window size used by gcrypt is at most 𝑤 = 3, leading to an
average entropy of 98.0 bits. Worse still, more than one in 10, 000
keys is expected to have at most 80 bits of leakage entropy: for such
a small search space, vOW is expected to only require 250 modular
multiplications (roughly 235 Gcycles in software) for a hash table of
16See https://github.com/gpg/libgcrypt/blob/1a83df98/mpi/mpi-pow.c#L442-L451.
17Since in practice 𝑞 is unknown to an attacker, this ignores the cost of factoring 𝑝 − 1
first, but accounting for it would only make the side channel attack look better.
Figure 4: Running time of BSGS for increasing values of
the entropy 𝐻𝑤(𝑥), on our node equipped with 20 cores
and 64GiB of RAM. The dashed line indicates extrapolated
running times. Also represented the cumulative distribu-
tion functions of the normal distributions of parameters
(225·7/16, 225·0.098632) and (339·341/640, 339·0.126731), roughly
corresponding to the entropy distributions of Crypto++ and
gcrypt for a modulus of 2048 bits.
235 entries (roughly 4 TiB). We thus conclude that attacking a non-
negligible proportion of Crypto++-generated public keys within
gcrypt’s decryption routine is well within reach of a moderately
resourceful adversary.18
Proof of concept. To confirm the reality of the threat, without
going as far spending several thousands of dollars, we implement
a simple parallelized BSGS using GMP 6.1.2, and test it on a node
equipped with 20 Xeon E5-2640 cores clocked at 2.40GHz and 64GiB
of RAM. Due to memory contention the parallel speed-up is sublin-
ear, nevertheless we observe a speed-up slightly above 10× using
all 20 cores, thus justifying our preference for BSGS over the more
complex vOW algorithm which is marred by larger constants. Our
implementation uses hash table entries of 16 bytes, independently
of the modulus size; the node can thus accommodate for tables
with as many as 232 entries, ensuring the running time scales like
the square root of the entropy, up to 64 bits of entropy. Figure 4
plots the running time of BSGS for increasing values of 𝐻𝑤(𝑥),
and superimposes the cumulative distribution function of 𝐻𝑤(𝑥)
for Crypto++ and gcrypt, indicating what percentage of keys is
broken in a given time. Since BSGS is deterministic, we use for
the benchmarks the exponent that is tested by BSGS last, thus the
expected running time for an average exponent of given entropy is
half the time reported in the figure.
As a final confirmation, we instrument the Crypto++ code to
generate random secret exponents in a tight loop, and output them
along with their leakage entropy. Over 228 samples, we obtained
a 226 bits exponent with 62 bits of leakage entropy. Our probing
strategy described in Section 6.2 produces the expected leakage
pattern, from which our BSGS code recovers the exponent in about
30 minutes using 20 cores.
6 PRACTICAL EXPLOITATION
In this section we prototype the attacks described in Section 5 to
show that practical exploitation is possible. The attacks are mounted
18At the time of writing, 8 Amazon EC2 r6g.metal instances with 0.5 GiB of RAM
and 64 virtual CPUs each cost about 12,000$ per month.
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2075on a Core i7-8650U CPU with Ubuntu 18.04.5. We demonstrate how
FLUSH+RELOAD may be employed to extract leakage from the
sliding window modular exponentiation implementation of gcrypt
and use that to obtain full key recovery, as detailed in Section 5.4.
The exploitation of gcrypt presents interesting aspects for two
reasons: i) the library was patched to protect its modular exponenti-
ation routine against cache-based side channels attacks highlighted
by Yarom and Falkner [39] and by Liu et al. [22]; and ii) the attack
can be conducted on commodity hardware specifically owing to the
ElGamal interoperability issues highlighted in Section 2. We also
show how a PRIME+PROBE attack on data cache is able to reveal
the indices of the table accesses performed by the fixed window
modular exponentiation implementation of Go described in Sec-
tion 5.2. While the developers acknowledge that the implementation
is not safe, practical exploitation is still of interest as it reveals a few
caveats that we describe. Finally, we briefly discuss here the case of
comb-based exponentiation seen in Crypto++ (see Section 5.3). The
algorithm presents a combination of the weaknesses that we exploit
for gcrypt and Go: with reference to Figure 2, secret-dependent
control flow at line 22 and secret-dependent table access at line 23.
Exploitation relies on the same techniques that we describe below.
6.1 Threat Model
We consider a victim process that uses a private key to decrypt
ElGamal ciphertexts. We assume that the attacker has knowledge of
the victim program and of the specific decryption algorithm that is
used. We also assume that the attacker may cause the victim process
to execute, for example because the victim uses a PGP-enabled
mail client which automatically decrypts emails upon reception.
Consequently, we assume that the attacker is able to synchronise
side channel measurements with the victim execution. No physical
access is required to perform the attacks. Given that we target cache
side channels, the attacker may either be local, or it may be running
on a different, co-located, VM. The former may target any cache
level, the latter may only target LLC (unless the VM is hyperthread-
colocated). The attack in Section 6.3 targets a Go binary, where
ASLR is disabled by default. As to the attack in Section 6.2, we make
use of FLUSH+RELOAD on shared (physical) data pages and so
ASLR has no impact. Wlog we conduct the exploitation against the
L1 cache: as shown by Liu et al. [22], the same exploitation may be
achieved against higher cache levels.
6.2 Sliding window: the case of gcrypt