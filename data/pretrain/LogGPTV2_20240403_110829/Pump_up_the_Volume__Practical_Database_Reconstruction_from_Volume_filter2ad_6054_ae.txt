.
This is a useful result for several reasons. First, it implies convergence for volumes of range queries,
since the volume of every query [i, j] can be written R·( ˆF (j)− ˆF (i−1)). It is also a uniform convergence
bound, meaning its guarantees apply to all range queries simultaneously. Finally, its rate of convergence
is nearly as fast as a single Chernoﬀ bound, though it applies to many events at once.
5.1 The CDF Matching Attack
of R i.i.d. samples X1, . . . , XR from πDB. For any query q = [a, b], deﬁne VDB(q) =(cid:80)R
Pr [ q ] =(cid:80)
First deﬁne some notation. Let the number of records in the database be R. Let πDB = (p1, . . . , pN ) be a
distribution over [1, N ], and R the set of all range queries on [1, N ]. We model the database as a sequence
i=1 Ia≤Xi≤b and
Let our attack be represented by the adversary A. For any query q, A takes as input πDB, R, VDB(q),
and the conﬁdence parameter 0 
/2. An upper-bound
on the probability of this event can be obtained by directly applying DKW. This yields Pr [ Err ] ≤ δ,
as needed.
− (Pr [ 1, b ] − Pr [ 1, a − 1 ])
(cid:12)(cid:12)(cid:12)(cid:12) .
(cid:17)
− Pr [ 1, a − 1 ]
(cid:17)
(cid:16)(cid:113)
− Pr [ 1, b ]
(2 log 2
δ )/R
R
R
(cid:12)(cid:12)(cid:12)(cid:12)
R
R
(2 log 2
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(2 log 2
=
≤
R
R
+
This theorem implies that an adversary that chooses its candidate set in CDF matching via the
DKW inequality has perfect raw accuracy except with probability δ. Even with an inaccurate auxiliary
distribution, Theorem 2 and other results of this form are likely to hold as long as the KS distance
between the true distribution and the adversary’s auxiliary distribution is low.
Next we present a theorem on the uncertainty reduction of the CDF matching attack. Uncertainty
reduction measures the number of queries which could correspond to an observed volume. Intuitively,
uncertainty about the underlying query of an observed volume is related to the number of queries whose
probabilities are “close” to the real query.
Theorem 3. Let πDB = (p1, . . . , pN ) be a distribution on [1, N ], and let R be the set of all intervals of
[1, N ]. Let DB = X1, . . . , XR be R i.i.d. samples from πDB. For a range query q = [i, j] on [1, N ], deﬁne
δ )/R
deﬁne Cq = {q(cid:48) ∈ R : |Pr [ q ] − Pr [ q(cid:48) ]| ≤ 2} and CSq = {q(cid:48) ∈ R : | Pr [ q(cid:48) ]− (VDB(q)/R)| ≤ }. (Note
that Cq is ﬁxed by πDB, δ, R while CSq is a random variable.) Deﬁne CS to be the event, over the coins
(cid:96)=i p(cid:96) and VDB(q) = (cid:80)R
k=1 Ii≤Xk≤j. For any query q, 0  |Cq|). Then Pr [ CS ] ≤ δ.
(cid:113)
(2 log 2
Proof. If the event CS happens, then there exists a q ∈ R so that |CSq| > |Cq|. For query q, Cq is the
set of queries for which an  interval around their expected volume overlaps with the  interval around
the expected volume of q. Thus, |CSq| > |Cq| implies there exists q(cid:48) so that |(VDB(q(cid:48))/R)− Pr [ q(cid:48) ]| > .
Applying DKW lets us upper-bound the probability of this happening by δ.
This theorem is useful because it relates the size of the candidate set for a query to the number of
other queries whose expected volumes are close in probability. Further, for a given database distribution
we can quantify the rate at which the candidate sets for range queries get smaller as the number of
records increases.
21
Figure 6: Results of CDF matching experiments on HCUP attributes. The number appearing below each attribute
is the median across all hospitals of the KS distance between an individual hospital and the auxiliary distribution.
The percentage corresponding to each bar pattern is the proportion of queries in the set ˆQ for the correct
predictions; thus, smaller numbers are better.
5.2 Experimental Results
We performed two types of experiments to assess the risk of query reconstruction. The ﬁrst type assumes
the exact count of each element in the database is known, either because the database was stolen or
the attacker observed enough queries to run the clique-ﬁnding algorithm described above. For space
reasons, a description of the exact procedure and the results appear in Appendix E.
The second type of experiment evaluates the CDF matching algorithm using the attributes described
in Figure 7 of Appendix B. In each experiment, we took the individual hospital records for that attribute
for a particular year’s HCUP data to be the targets of the attack. We used the aggregate counts of a
diﬀerent year of HCUP data as the auxiliary data. We ran experiments with diﬀerent combinations of
auxiliary data and target hospitals for the HCUP years 2004, 2008, 2009 and 2013. Surprisingly, both
the performance of the experiments and the median KS distance between the auxiliary distribution and
the target hospitals varied only a small amount between diﬀerent experiments for an attribute, so for
simplicity of exposition we will only present one experiment for each.
An individual experiment performs the following steps: ﬁrst, we compute the number of records R
in the target hospital. Then we compute the epsilon given by the DKW inequality for R and δ = 0.05.
Then for each query in the target hospital, we compute the set of candidate queries ˆQ as described
above. Figure 6 shows the median raw recovery rate (i.e. the median fraction of times the correct query
is in ˆQ) broken down by the sizes of the sets ˆQ. The set sizes are relative to the total number of queries
for each attribute (given in Figure 7); to save space we omit converting the percentages to absolute sizes.
Roughly, the total height of each bar is the median fraction of correct predictions (of any size) and the
diﬀerent patterns on each bar report how much reduction in uncertainty each correct prediction gives
the adversary (where a smaller number means the size of ˆQ is smaller, and the adversary’s uncertainty
is reduced more). With precise knowledge of the database distribution and i.i.d. samples, the median
raw recovery rate would be 100% except with probability 0.05. With no knowledge at all, the “baseline
guessing” attack would simply set ˆQ to be all possible queries. On this graph, this would be a bar with
the 100% pattern going from 0.0 to 1.0.
Discussion. The raw recovery rate varied widely between diﬀerent attributes. For the two largest at-
tributes (AGEDAY and LOS) almost every set ˆQ contained the correct query. However, both attributes
have an extremely skewed distribution, so for almost all queries ˆQ contained almost every possible query.
22
AGEDAY0.06ZIPINC0.39AGE0.15MRISK0.1AMONTH0.02LOS0.1SEV0.1NDX0.2NPR0.17NCHRONIC0.160.00.10.20.30.40.50.60.70.80.91.0ProportionofallrangequeriesRawrecoveryrateanduncertaintyreductionforCDFmatchingexperiments1%5%10%20%50%100%Thus, the “reconstruction” achieved for most queries is not better than baseline guessing. The attack
performed well on AMONTH, and there the sets ˆQ were much smaller—over 30% of the recovered
queries had | ˆQ| ≤ 8. The auxiliary data was quite good for AMONTH: the median KS distance was
only 0.02.
The results for NDX, NPR, and NCHRONIC are more surprising. All three had relatively large
median KS distances, but a substantial fraction (around 15%) of all queries were correctly recovered
and had small | ˆQ|. For NDX and NPR, around 15% of queries were recovered and had | ˆQ| ≤ 14, and
for NCHRONIC around 10% of queries had | ˆQ| ≤ 35. The overall recovery rate was high as well. AGE
also had many correctly-recovered queries with small ˆQ, despite a high KS distance. In fact, in more
than 80% of hospitals there were correctly-recovered queries with | ˆQ| ≤ 15, which corresponds to only
0.4% of possible range queries! Despite having a poor auxiliary distribution, for all these attributes
the attack was able to recover ﬁne-grained information about many queries. Further, the analysis (in
particular Theorem 2), which formally only holds when the auxiliary distribution is nearly perfect, is
still partially predictive for accuracy in a noisy setting.
The conclusions we draw from these experiments are twofold: (1) simple query reconstruction attacks
can reveal ﬁne-grained information about queries and damage privacy even in practical settings and with
poor auxiliary data, and (2) idealized models of these attacks proven under seemingly strong assumptions
(such as perfect auxiliary data or i.i.d. samples) maintain much of their predictive power when these
assumptions are violated.
Database reconstruction.
If enough queries are reconstructed with high accuracy, it is possible to
reconstruct the database as well. If we write each query q = [a, b] as a 0-1 row vector where qi = 1
if a ≤ i ≤ b and zero otherwise, the database DB (a vector with N components whose sum is R) is
an (integer) solution to the system of linear equations Q · DB = (cid:126)v where Q is a matrix of row vectors
for each recovered query, and (cid:126)vi is the volume of the ith query. If the rank of the matrix Q is N , the
matrix-vector equation has a unique solution and the database can be recovered exactly.
of integer solutions to Q · DB = (cid:126)v (with(cid:80)
Pr [ DB ; πDB ] =(cid:0) R!
Even if only a few queries are recovered correctly and the rank of the matrix is less than N , the set
i DBi = R) is exactly the set of possible databases having
all the observed volumes. With knowledge of the database distribution, the “maximum-likelihood”
database for any set of recovered queries can be constructed using integer convex programming: observe
that for πDB = (p1, . . . , pN ) and a candidate solution DB = (x1, . . . , xN ), the log of the probability
N can be well-approximated by a convex function (using Stirling’s
approximation for log xi!). Using a standard relax-and-round approach to convert the integer problem to
one over RN , a convex programming solver can reconstruct the database with all the observed volumes
having the highest probability. Of course, one can use the attack from Section 3 to reconstruct the
database; the advantage of this approach is that it requires far fewer queries. We leave a more detailed
treatment to future work.
(cid:1)px1
x1!···xN !
1 ··· pxN
6 Countermeasures
In this section we brieﬂy discuss some possible countermeasures to our attacks. There are two basic
kinds of countermeasures: client processing and adding noise.
Volume information can be hidden if the client does some additional processing of queries and
results. If instead of issuing a single query, the client batches several queries together, the volume of
any individual query will not be revealed.
If queries are infrequent, this could incur a high latency
penalty. Another approach is putting a lower limit on the width of a range query. If the client wants
to query a small range, it queries a larger range and ﬁlters the unneeded results locally. This incurs
bandwidth overhead, but may be feasible in some settings. The database could be bucketed, meaning
23
records which are close in value are treated as one logical “value” for the purposes of retrieval [HMT04].
Bucketing would not generally prevent reconstruction, but would ensure the exact counts of individual
elements are not revealed.
Adding noise to the volumes can be done by adding dummy records to the database, incurring
server storage overhead. It seems inherent that the security beneﬁt is directly related to the storage
overhead: a small number of dummy records (yielding low storage overhead) will give little or no
security beneﬁt. One principled way of adding dummy records is using diﬀerential privacy (DP), as
suggested by KKNO in a follow-up work [KKNO17]. Rather than querying the database directly,
they query the output of a DP mechanism for range queries. Intuitively, the DP mechanism prevents
reconstruction of the exact count of every element in the database. Crucially, their guarantees do not
extend to query reconstruction: while query reconstruction should be less accurate, no formal guarantee
precludes accurate query reconstruction. Since a thorough examination of DP countermeasures would
be quite involved, we leave it to future work.
7 Related Work
Aside from KKNO, there are two recent works on reconstruction attacks which are related to ours. The
ﬁrst is by Cash et al. [CGPR15], who present an attack for revealing keyword search queries on natural-
language documents based on the number of results returned. Their sole attack in the volume-only
setting requires perfect knowledge of the documents in the database and simply matches an observed
volume with the query having that count. Our query reconstruction attack with exact counts (discussed
in Section 5) can be seen as a version of their count attack.
The other recent paper related to our attacks is by Lacharit´e et al. [LMP18]. Their auxiliary data
attack is similar in some ways to the CDF matching attack in Section 5. They target full reconstruction,
assuming both access pattern and rank leakage, but do not provide a formal analysis. In contrast, our
CDF matching attack targets query reconstruction with fewer assumptions. Moreover, it is accompanied
by an analysis which gives tight theoretical guarantees and maintains its predictive ability even if the
auxiliary data is inaccurate.
In the security community, communication volume and other traﬃc features like packet timings have
long been used to perform traﬃc analysis and website ﬁngerprinting attacks. For example, Wright et
al. [WBC+08] recovered spoken phrases from encrypted VoIP traﬃc by training a model on packet sizes
and timings. Both the settings and goals of these works are distinct from ours; in particular they rely
on information that is not available in our setting.
Some countermeasures for communication volume leakage exist. For example, IPSec has an optional
“Traﬃc Flow Conﬁdentiality” mode that adds padding. TLS 1.3 and SSH also allow packets to be
padded. These countermeasures are not widely used in practice, both because they are usually too
expensive to deploy in large systems and because prior work [DCRS12] has shown the overall usefulness
of these countermeasures is quite low.
In a recent follow-up [KKNO17] to their reconstruction attacks, KKNO combine ORAM and diﬀer-
ential privacy with the goal of preventing database reconstruction attacks based on either access pattern
or communication volume. We discuss this work in Section 6.
8 Conclusions and Future Directions
In this work we demonstrate practical reconstruction attacks which use only volume leakage. In the
context of encrypted databases, it is worth noting that while ORAM protects against attacks that require
access pattern leakage, it remains vulnerable to volume attacks. Given the rich volume information that