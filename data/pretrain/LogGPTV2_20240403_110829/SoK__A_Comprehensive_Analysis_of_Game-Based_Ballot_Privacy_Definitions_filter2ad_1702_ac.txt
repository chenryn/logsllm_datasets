More recently, a deﬁnition has been proposed, that aims
to deal with arbitrary result functions. It is inspired by cryp-
tographic security for encryption and roughly says that an
attacker should not be able to tell whether he is seeing the
real board or a fake board where all (honest) voters vote for
the same arbitrary dummy vote. Of course, the tally itself is
always performed on the real ballot box.
Deﬁnition 3 (BPRIV1): BB0, BB1, BB(cid:3)
are lists initialized
at empty. A distinguished vote value  ∈ V is chosen by
the challenger. The challenger starts by picking a random bit
β, and the adversary B = (B1,B2) is given access to list
BBβ. The challenger runs the setup algorithm to create keys
(pk, sk). Next, the adversary B1 can query oracles Ovote(·)
and Oballot(·) as follows:
• Ovote(v) : computes b0 := Vote(v) and b1 := Vote();
next runs BBβ ← BBβ(cid:10)bβ and BB(cid:3) ← BB(cid:3)(cid:10)b0.
• Oballot(b): runs bb ← bb(cid:10)b on inputs BBβ, BB(cid:3)
At some point, the adversary B2 asks to see the tallying output.
The challenger obtains (r, Π) ← Tally(BB(cid:3)
, sk) and returns r
to the adversary. Finally the BPRIV1 adversary B2 outputs β
(cid:3)
as its guess for β.
Formally, we say that a voting scheme V is BPRIV1 secure
if no PPT algorithm B can distinguish between the outputs in
the previous experiment for β = 0 and β = 1, i.e. for any
PPT adversary B,
.
(cid:2)
(cid:4)(cid:4)(cid:4) Pr
Expbpriv1,0
B
(λ) = 1
Expbpriv1,1
B
(λ) = 1
(cid:3)
(cid:2)
− Pr
(cid:3) (cid:4)(cid:4)(cid:4)
B
is the experiment deﬁned
is negligible, where Expbpriv1,β
above.
In the BPRIV1 deﬁnition, tally is executed either over the
faithful ballot box (namely, BB), or a fake box (namely, BB(cid:3)
),
containing fake votes  for honest voters. A limitation of
this deﬁnition is that the adversary is not allowed to see the
auxiliary data Π. Indeed in most cases, if the adversary can
see Π (e.g. a proof of correct tally of the ballot box), he would
be immediately able to tell whether he has seen the real or the
fake board. Therefore BPRIV1 does not fully model veriﬁable
voting protocols such as Helios or Civitas.
Recently, Cuvelier, Pereira and Peters [26] proposed a
variant of the BPRIV1 setting/deﬁnition to capture ballot
privacy even in the presence of computationally unbounded
adversaries, and which is named perfectly private audit trail
(PPAT). Similarly to BPRIV1, the deﬁnition PPAT is limited in
the sense that an adversary is not allowed to see the auxiliary
data Π.
D. Ballot privacy - ASIACRYPT 2012 [19], [20]
A variation of the BPRIV1 deﬁnition has been proposed,
that we name as BPRIV2 privacy. Its goal is to be able to
fully model veriﬁable voting protocols where the tally does not
produce just a result but also proofs of correct tally. Intuitively,
to avoid that the adversary immediately wins the game because
of the auxiliary data, this data needs to be simulated on the
504504
fake board. This deﬁnition makes therefore use of a simulator
SimProof that simulates the auxiliary data of the tally when
the adversary is not given the real board.
Deﬁnition 4 (BPRIV2): BB0, BB1, L are lists initialized
at empty. The challenger starts by picking a random bit
β, and the adversary B = (B1,B2) is given access to list
BBβ. The challenger runs the setup algorithm to create keys
(pk, sk). B1 is given access to oracles Ocorrupt,OvoteLR
and Oballot(·) as follows:
• OvoteLR(id, v0, v1) : if vγ /∈ V for γ = 0, 1, halts. Else,
runs BBγ ← BBγ(cid:10)Vote(id, vγ)) for γ = 0, 1 and sets
L ← L ∪ {id}, meaning that id has already voted.
• Ocast(id, b): if id ∈ L (a honest user already cast a
ballot), halts. Else runs BBβ ← BBβ(cid:10)b.
At some point, B2 asks to see the tallying output. The
the challenger
challenger proceeds as follows:
outputs (r, Π) ← Tally(BB0, sk). But if β = 1, the challenger
) ← Tally(BB0, sk) and Π ← SimProof(BB0, BB1,
†
sets (r, Π
pk, info), where info contains any information known to the
challenger. The challenger outputs (r, Π).
Finally the BPRIV2 adversary B2 outputs β
(cid:3) a the guess for
β.
We say that a voting scheme V is BPRIV2 secure if no
PPT algorithm B can distinguish between the outputs in the
experiment just described for β = 0 and β = 1, i.e. for any
PPT adversary B, there exists a simulator SimProof such that
if β = 0,
Expbpriv2,0
B
(λ) = 1
Expbpriv2,1
B
(λ) = 1
(cid:3)
(cid:2)
− Pr
(cid:3) (cid:4)(cid:4)(cid:4)
is negligible, where Expbpriv2,β
B
is the experiment deﬁned
(cid:2)
(cid:4)(cid:4)(cid:4) Pr
above.
Unfortunately, allowing the auxiliary data to be simulated
actually weakens too much the deﬁnition of ballot privacy. We
show next that BPRIV2 privacy declares as private, protocols
that reveal exactly how voters voted in the tabulation proof Π.
Such protocols should clearly not be declared private.
BPRIV2 fails to ensure ballot privacy: Let V(cid:3) be any
BPRIV2 secure scheme. We assume that ballots of V(cid:3) can
be extracted, that is, we assume a function Extract(sk, b) that
returns the vote v corresponding to ballot b. For example, if
b contains the encryption of v then Extract is simply the
decryption function. Let Leak(V(cid:3)
) be the scheme obtained
from V(cid:3) such that the tally now outputs the correspondence
between ballots and votes. Formally, Leak(V(cid:3)
) is obtained
from V(cid:3) by changing Tally(cid:3)
to Tally, Verify as follows:
• (r, Π) ← Tally(sk, BB), where (r, Π
(cid:3)
(sk, BB)
vb ←
and Π ← Π
Extract(sk, b);
• Verify(PBB, r, Π) parses Π as Π
outputs Verify(cid:3)
) ← Tally(cid:3)
b∈BB, where
(cid:3) ||{( b, vb )}
, Verify(cid:3)
(cid:3) ||{( b, vb )}
We write V := Leak(V(cid:3)
). Intuitively, it is easy to see that
V satisﬁes BPRIV2 although it is not private. Indeed, the
simulator SimProof knows all the OvoteLR(id, v0, v1) queries
(cid:3)
(PBB, r, Π
b∈BB and
).
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:30 UTC from IEEE Xplore.  Restrictions apply. 
made by the adversary. It may therefore pretend that any ballot
b corresponding to a query OvoteLR(id, v0, v1) corresponds
to v0 even when it corresponds to v1 (when β = 1). This
argument is worked out in detail in Appendix IX.
E. Ballot secrecy - ESORICS 2013 [22]
Another deﬁnition, called IND-SEC, has been recently been
proposed [22] to ﬁx the privacy breach of the deﬁnition
BPRIV2. This deﬁnition can be seen as a combination of
the BPRIV2 [19], [20] and the Benaloh’s [24] deﬁnitions.
Indeed, the IND-SEC game is intuitively deﬁned as follows.
The honest voters vote for an arbitrary sequence of votes V0
in the ﬁrst board and an other arbitrary sequence of votes
V1 in the second board. If the two sequences coincide when
viewed as multisets, then the real tally is disclosed (as in
Benaloh’s [24] deﬁnition). If the two multisets differ, the tally
is always performed on the ﬁrst ballot box (even when the
adversary has seen the second ballot box).
Deﬁnition 5 (IND-SEC): BB0, BB1, V0, V1 are lists initial-
ized at empty. The challenger starts by picking a random bit
β, and the adversary B = (B1,B2) is given access to list BBβ.
The challenger runs the setup algorithm and the keys (pk, sk)
are created. On input pk the adversary B1 can query oracles
OvoteLR(·,·) and Oballot(·) as follows:
• Ovote(v0, v1) : runs BBγ ← BBγ(cid:10){Vote(vγ)}, and
updates Vγ ← Vγ ∪ {vγ} for γ = 0, 1.
• Oballot(b): runs bb (cid:9)→ bb(cid:10)b on ballot boxes BB0, BB1.
At some point, B2 asks to see the tallying output. The
(cid:8)= V1
Tally(BB0, sk).
challenger proceeds as follows:
• If V0 = V1 (as multisets) the output is set to be that of
(r, Π) ← Tally(BBβ, sk).
(r, Π) ←
• If V0
the challenger outputs
Finally the IND-SEC adversary B2 outputs β
(cid:3) a the guess
for β.
Formally, we say that a voting scheme V has IND-SEC
secrecy if no PPT algorithm B can distinguish between the
outputs in the experiment just described for β = 0 and β = 1,
i.e. for any PPT adversary B,
(cid:3)
(cid:2)
(cid:2)
(cid:3) (cid:4)(cid:4)(cid:4)
(cid:4)(cid:4)(cid:4) Pr
Expindsec,0
B
(λ) = 1
Expindsec,1
B
(λ) = 1
− Pr
is negligible, where Expindsec,β
B
is the experiment deﬁned
above.
IND-SEC and Tally Uniqueness are Incompatible.: While
IND-SEC declares the Leak(V) voting scheme insecure, it
turns out that IND-SEC secrecy and veriﬁability are incom-
patible properties. In other words, any veriﬁable protocol will
be declared not private by IND-SEC.
Let V be a (correct) voting scheme with tally uniqueness
for a non-trivial result function ρ. We describe next a IND-
SEC adversary B that has advantage negligibly close to 1/2
against V in the IND-SEC game. More precisely, for any IND-
SEC adversary B there exists a tally uniqueness adversary B(cid:3)
such that Succbpriv1(B) ≥ 1 − Succuniq(B(cid:3)
). Therefore both
(cid:3)
(cid:3)
advantages can not be negligible at the same time, and thus
IND-SECl and tally uniqueness are incompatible properties.
The adversary B proceeds as follows. It chooses votes v, 
such that ρ(v) (cid:8)= ρ() and it makes a single query Ovote(v, ),
which causes b0 := Vote(v) and b1 := Vote() to be created.
:= 0 if Verify(BBβ, ρ(v), Π) = (cid:6),
Then B sets its guess β
where Π is computed by the IND-SEC challenger as (r, Π) ←
Tally({b0}, sk); otherwise sets β
:= 1. The claim follows
from the following facts:
• Verify({b0}, ρ(v), Π) = (cid:6), since V is correct;
• Verify({b1}, ρ(), Π1) = (cid:6), where Π1 is not explicitly
known but it is deﬁned by (r1, Π1) ← Tally({b1}, sk).
This holds since V is correct;
• Verify({b1}, ρ(v), Π) = ⊥ with overwhelming proba-
bility. Indeed, since V has tally uniqueness, and given
that Verify(Publish({b1}), ρ(), Π1) = (cid:6), the equation
Verify(Publish({b1}), ρ(v), Π) = (cid:6) for ρ(v) (cid:8)= ρ() is
satisﬁed only with negligible probability.
The latter implies in particular that Helios,
in any of
its known ﬂavours, cannot be both IND-SEC private and
veriﬁable.
F. Ballot privacy for restricted adversaries - PKC 2013 [21]
Another deﬁnition has been recently proposed by Chase et
al. [21]. As for the previous IND-SEC deﬁnition, the adversary
triggers honest voters, providing a left and right votes for each
voter. The tally is performed on the visible ballot box, that is,
the one the adversary sees (no simulation). However, if the
result announced differs depending on whether β = 0 and
β = 1, then the adversary loses the game.
Deﬁnition 6 (RPRIV): BB0, BB1, V0, V1 are lists initialized
at empty. The challenger starts by picking a random bit
β, and the adversary B = (B1,B2) is given access to list
BBβ. The challenger runs the setup algorithm and the keys
(pk, sk) are created. B1 on input pk is given access to oracles
Ovote(·),Oballot(·) as follows:
• Ovote(id, v0, v1) : runs BBδ ← BBδ(cid:10)Vote(id, vδ)),
Vδ ← Vδ ∪ {vδ} for δ = 0, 1.
• Oballot(id, b): runs bb (cid:9)→ bb(cid:10)b on ballot boxes BB0, BB1.
At some point, B2 asks to see the tallying output. The chal-
lenger computes (r0, Π0) ← Tally(BB0, sk) and (r1, Π1) ←
Tally(BB1, sk). If r0 (cid:8)= r1, the adversary loses. Otherwise, the
challenger replies (rβ, Πβ) to B2. Finally, B2 outputs β
(cid:3) a the
guess for β. Formally, we declare a voting scheme V RPRIV
private if for any adversary B the advantage
(cid:4)(cid:4)(cid:4) Pr
(cid:3) (cid:4)(cid:4)(cid:4) is neg-
Exprpriv,1
− Pr
Exprpriv,0
(λ) = 1
(λ) = 1
(cid:3)
(cid:2)
(cid:2)
B
B
ligible, where Exprpriv,β
B
is the experiment above.
This deﬁnition fails to capture replay attacks, whereby a
malicious voter replays a previously ballot cast by a honest
voter. It is known that replay attacks violate ballot secrecy.
Indeed, consider a referendum election with three voters,
namely, Alice, Bob, and Mallory: if Mallory replays Alice’s
ballot without being detected or rejected, then Mallory can
reveal Alice’s vote by observing the election outcome and