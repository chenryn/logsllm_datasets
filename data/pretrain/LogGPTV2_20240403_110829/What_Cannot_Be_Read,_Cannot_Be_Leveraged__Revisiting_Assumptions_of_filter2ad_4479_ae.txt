address into the absolute one, by adding it to the current
instruction pointer (rip). This can be done with a single
instruction in x64 (lea r10,[rip+0xc380ca]).
As this instruction will still emit the relative address as
the displacement, we split it in two instructions. First, we
add the current instruction pointer to the relative address
AND-ed with a random key (rip+0xc380ca&KEY). In the
second lea instruction, we add the sum to the relative
address AND-ed with the inverted (bitwise not) random
key, resulting in the desired offset (rip+0xc380ca). Note
that we use obfuscation by AND-ing the constant with a
random key instead of XOR-ing it, because (A+B⊕C)⊕
C does not equal to A + B, while (A + B∧C) + B∧¬C
does. Moreover, this obfuscation scheme allows us to
use lea instructions only, which has the advantage of not
modifying any ﬂags.
5.1.2 Direct Calls
We mitigate the implicit constants in direct calls by con-
verting the direct calls into indirect ones. To this end, we
150  25th USENIX Security Symposium 
USENIX Association
12
0x00: je 0xc380c4
0x06: 
....
0x00: je 0xc380cd
0x07: nop
0x08: ...
0x12: nop
0x13: 
....
0x00: jne 0x11
0x02: lea r10,[rip+0xc380ca&KEY]
0x09: lea r10,[r10+0xc380ca&~KEY]
0x10: jmp r10
0x13: 
....
0xc380ca: ....
0xc380d3: ....
0xc380d3: ....
(A) Original V8
(B) NOP Padding
(C) Modified V8
Figure 4: Steps of JIT hardening in V8
0x00:
0x07:
0x0e:
0x11:
lea r10, [rip+ADDRESS&KEY ]
lea r10, [r10+ADDRESS&~KEY]
call r10
....
; calls 0xc380d3
Figure 5: Hardening direct calls
distinguish whether the address of the callee is known
at compile time (e.g., when calling built-in functions).
If the callee’s address is known, we can move it to a
scratch register (r10) and then execute an indirect call
mov r10,ADDRESS;call r10. We thus emit the absolute
address of the callee as the immediate value of the mov
instruction, which is not under the control of the attacker
and is thus safe—in contrast to the relative address.
If the address is unknown at compile time, we use a
similar technique as we did for the conditional jumps,
i.e., we convert the relative address into an absolute
one (blinding the relative address during the conversion),
store it in the scratch register, and then execute an indi-
rect call, as shown in Figure 5.
5.2 Evaluation
To evaluate our defense technique we ran the V8 Bench-
mark Suite 7 on our modiﬁed V8. We performed each
benchmark 100 times on both the modiﬁed and original
V8s, and compared their corresponding averaged results.
Table 3 illustrates the average scores that were returned
by the benchmark suite, where a higher score indicates
better performance. The modiﬁed V8 has an average
overhead of less than 2%, and the worst overhead less
than 3%. The observation that the overhead is negative
for the NavierStokes benchmark can be explained by sta-
tistical variations across the different runs.
Additionally, we tested the modiﬁed V8 with mi-
crobenchmarks. To this end, we created two JavaScript
functions (ifs true and ifs false), both of them con-
taining 1,000,000 if statements. The condition of the if
statement in ifs true is always true (i.e., the if body
is executed), while the condition of ifs false is always
false. This way the JIT-compiled functions will contain
1,000,000 conditional jump instructions modiﬁed by us,
each of them testing separate execution paths. Further-
more, evaluation of the expression in the if statements
is done via a function call. Therefore, both of these
functions generate 1,000,000 modiﬁed call instructions
each and will thus incorporate the overhead caused by
the function calls. Each run of the microbenchmark calls
each of these functions 10 times. We ran the benchmark
1,000 times. We distinguish the ﬁrst execution of these
functions from the remaining nine, as the ﬁrst execution
is signiﬁcantly slower due to the JIT-compiler modifying
the generated intermediate functions to adjust them to the
type information. Because the overhead was dominated
mostly by the compiler, we did not see any overhead for
the ﬁrst function execution. For the remaining function
executions we had 14,25% overhead in ifs false and
9,81% for ifs true.
Besides computational performance, our defense tech-
nique also causes a memory overhead due to added code.
To measure this overhead, we compared the sizes of the
functions compiled by the original and the modiﬁed ver-
sions of V8. To get the needed output from V8, we ran it
with the --print-code ﬂag, which outputs the disassem-
bled code for each function after the compilation together
with additional information about the compiled function
including the size of the generated instructions. Run-
ning the benchmark suite with the aforementioned ﬂag
yielded that the total size of the instructions emitted by
the original V8 was 1,123 kB, while the modiﬁed V8
emitted 1,411 kB, giving 287 kB of additional code, i.e.,
≈26% code size overhead. Given the signiﬁcant size of
the benchmark suite, and given that memory of nowa-
days x86/x64 systems are typically in the range of giga-
bytes, we think that hundreds of kB of additional code
does not cause any bottlenecks on COTS systems.
6 Discussion
6.1 Defense Security Considerations
Our defense follows the general goal to remove unin-
tended gadgets from constants in JIT-compiled code. We
tailored our defense implementation towards protecting
jump and call offsets. Other offsets may be usable to en-
USENIX Association  
25th USENIX Security Symposium  151
13
Benchmark
Richards
DeltaBlue
Crypto
RayTrace
EarleyBoyer
RegExp
Splay
NavierStokes
Total
Original Modiﬁed Overhead(%)
1.95
2.51
1.92
2.21
2.67
1.71
2.92
-0.23
1.96
36,263
63,641
33,366
77,198
44,900
6,525
21,095
31,924
32,255
35,555
62,045
32,725
75,488
43,700
6,414
20,479
31,998
31,662
Table 3: Scores by the V8 benchmark (higher is faster)
code further gadgets. For example, relative addressing
is frequently used in combination with the base pointer,
such as when accessing parameters of a JavaScript func-
tion. As parameters are stored on the stack, they are
accessed relative to the frame pointer (ebp/rbp). Each
parameter access, after JIT-compilation, emits an assem-
bly instruction, which contains the offset of the param-
eter from the frame pointer in its displacement ﬁeld:
mov [ebp+0x0c],0x1. The number of possible gad-
gets, in this technique, is restricted by (i) limited stack
size (e.g., maximum 216 − 1 (0xffff) function parame-
ters in Chrome) and (ii) stack alignment (4 or 8 bytes). In
combination, this only allows generating gadgets whose
opcodes are multiples of 4 (or 8) and are in the range be-
tween 0xc and 0x40000, and thus gives the attacker only
limited capabilities. The stack size restrictions impose
the same limitations on implicit gadgets encoded in rela-
tive accesses to function’s local variables
While we think that the most important constants are
blinded, we cannot exclude the existence of further ways
to encode gadgets in assembly instructions. To eradicate
all potential gadgets, one could prevent the JIT compiler
from creating any potential gadgets (even in unaligned
instructions). Most notably, G-Free [24] is a gadget-
free compiler, which tries to generate gadget free bina-
ries. However, G-Free requires multiple recompilations
and code adjustments to reliably remove all possible gad-
gets. This will increase the runtime overhead for the JIT
compilers, as the compilation time is included in their
runtime.
6.2 Fine-Grained Code Randomization
An orthogonal approach to our defense would be to re-
move the attacker’s capability to ﬁnd the gadget’s loca-
tion (i.e., address). One way of doing so would be to
hide code pointers, e.g., via trampolines, as suggested
by Crane et al. [11].
If code pointers are not hidden,
the attacker can read the return instruction pointer on the
stack to get a pointer to the created gadget—which rep-
resents the current status in XnR implementations. This
results in (i) getting access to the gadget, (ii) a possibil-
ity to verify the gadget at runtime, and (iii) the ability to
retry in the case of a false result. By using similar tech-
niques as we used against NOP insertion, the attacker
can defeat ﬁne-grained code randomizations such as the
ones underlying Readactor [11]. Even though current
XnR implementations do not hide code pointers in JIT-
compiled code, XnR’s ideal implementation could also
expand fully to the JIT-compiled code, e.g., by introduc-
ing trampolines. This, together with the ﬁne-grained ran-
domization schemes such as NOP insertion, would suc-
cessfully protect against our attack. Note, however, that
NOP insertion does not remove gadgets, but tries to re-
duce the chances of the attacker to guess their locations.
In contrast, our proposed defense technique removes the
gadgets, hence also removing the risk of the attacker do-
ing a guesswork. Combining our technique with the ex-
tended XnR implementation would further improve the
security guarantees, removing the chances of both emit-
ting the gadgets and leaking the code layout information.
To guard against JIT-compiled gadgets, Wei et al. pro-
posed to do several code modiﬁcations such as (i) secur-
ing immediate values via constant blinding, (ii) modify-
ing internal ﬁelds of the instruction (e.g., registers being
used), and (iii) randomizing the order of the parameters
and local variables to randomize the offsets emitted by
them [34]. However, this is not effective against the at-
tacks proposed in Section 4, as the modiﬁcations do not
secure the displacement ﬁelds emitted by relative call-
s/jumps. Finally, the code randomization proposed by
Homescu et al. [17] that adds NOP instructions to ran-
domize the code output from the JIT compiler remains
ineffective if code pointers in JIT-compiled code are not
hidden.
6.3 Attack Generality
A natural question is how the proposed attack general-
izes, in particular to other operating systems or CPU
architectures. We have evaluated the attacks against
Chrome and Firefox running on Linux and IE on Win-
dows. As we exploit properties of the JIT compilers to
generate desired gadgets, the choice of the underlying
operating system is arbitrary. The proposed attacks rely
on the x86 system architecture (32- or 64-bit), though. In
RISC architectures, such as ARM and MIPS, instruction
lengths are ﬁxed, and execution of unaligned instructions
is forbidden by the hardware. However, the attacks may
still apply to ARM, as an attacker could emit arbitrary
two-byte values in the code if she can force the program
to switch to 16-bit THUMB mode. Although this lim-
its the attacker to using a single instruction, it still allows
setting the register contents and diverting the control ﬂow
152  25th USENIX Security Symposium 
USENIX Association
14
at the same time, e.g., by using a pop instruction.
We implemented our defense in the 64-bit version of
V8, taking advantage of the x64 architecture’s ability to
directly read the instruction pointer (rip). This simpli-
ﬁed the effort of converting relative addresses into ab-
solute ones. Even though one can read the instruction
pointer indirectly in 32-bit, e.g., by call 0x0;pop eax,
such additional memory read instructions would increase
the performance overhead. In addition, 32-bit features
only eight general-purpose registers. While in x64 we
could freely use a scratch register (r10 for Chrome), in
x86 we would likely need to save and restore the register.
Similar defenses in x86-32 are thus possible, but come at
an additional performance penalty. However, given that
64-bit systems are increasingly dominating the x86 mar-
ket, we think that 64-bit solutions are most relevant.
7 Related Work
In the following, we will summarize existing code-reuse
attacks and proposed defense mechanisms.
7.1 Code-Reuse Attacks: ROP / JIT-ROP
The most widespread defense against ROP is ASLR [32],
which randomizes the base addresses of memory seg-
ments. Although it raises the bar, ASLR suffers from
low entropy on 32-bit systems [30] and is not deployed
in many libraries [28]. In addition, ALSR does not ran-
domize within a memory segment, and thus leaves code
at ﬁxed offsets from the base address. Attackers can thus
undermine ASLR by leaking a code pointer [18].
thus
Researchers
suggested ﬁne-grained ASLR
schemes that randomize code within segments. Fine-
grained ASLR hides the exact code addresses from an
attacker, even if a base pointer was leaked. For example,
Pappas et al. [25] suggest diversifying code within basic
blocks, such as by renaming and swapping registers,
substituting instructions with semantically equivalent
ones, or changing the order of register saving instruc-
tions. ASLP, proposed by Kil et al. [20], randomizes
addresses of the functions as well as other data structures
by statically rewriting an ELF executable. To increase
the frequency of randomization, Wartell et al. propose
STIR [33], which increases randomness by permuting
basic blocks during program startup.
However, the invention of JIT-ROP undermined ﬁne-
grained ALSR schemes [31]. JIT-ROP assumes a mem-
ory disclosure vulnerability, which can be used by the
attacker repeatedly. The attacker then follows the point-
ers to ﬁnd executable memory, which she can read to ﬁnd
gadgets and build ROP chains on-the-ﬂy.
Recently, Athanasakis et al. [1] proposed to extend
JIT-ROP-like attacks by encoding gadgets in immediate
15
values of JIT-compiled code. Despite being limited to
two-byte constant emission by IE, the authors managed
to use aligned ret instructions, located at the end of each
function, as the part of their gadget. Note that, in their
attack, the authors were able to emit complete two-byte