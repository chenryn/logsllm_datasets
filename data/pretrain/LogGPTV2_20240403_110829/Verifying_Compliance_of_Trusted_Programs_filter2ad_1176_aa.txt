# Verifying Compliance of Trusted Programs

**Authors:**
- Sandra Julieta Rueda
- Dave King
- Trent Jaeger

**Affiliation:**
Systems and Internet Infrastructure Security Laboratory  
Department of Computer Science and Engineering  
The Pennsylvania State University  
{ruedarod, dhking, tjaeger}@cse.psu.edu

## Abstract

In this paper, we present an approach for verifying that trusted programs correctly enforce system security goals when deployed. Trusted programs are expected to perform only safe operations, despite having the authority to perform unsafe ones, such as initialization, administrative, and root network daemons. Currently, these programs are often trusted without concrete justification. The emergence of tools for building programs that guarantee policy enforcement, such as security-typed languages (STLs) and mandatory access control systems, provides a basis for justifying trust in such programs. We can determine whether these programs comply with the reference monitor concept. Since program and system policies are defined independently, often using different access control models, compliance for all program deployments may be challenging. We observe that the integrity of trusted programs must dominate the integrity of system data, and use this insight, which we call the Program Integrity Dominates System Integrity (PIDSI) approach, to infer the relationship between program and system policies, enabling automated compliance verification. Our findings show that the PIDSI approach is consistent with the SELinux reference policy for its trusted programs. Consequently, trusted program policies can be designed independently of their target systems while still ensuring the enforcement of system security goals.

## 1. Introduction

Every system contains a variety of trusted programs, which are expected to safely enforce the system's security goals despite being authorized to perform potentially unsafe operations. For example, the X Window server is a trusted program because it enables multiple user processes to share access to the system display, and the system trusts it to prevent one user’s data from being leaked to another. Other examples include initialization scripts, software installation and maintenance, windowing systems, and authentication services. The SELinux system includes over 30 programs specifically designated as trusted to enforce multilevel security (MLS) policies.

A critical question is whether these trusted programs actually enforce the system's security goals. Traditionally, trusted programs lack declarative access control policies governing their behavior. For instance, in SELinux, only the X server has an access control policy, and there is no effort to verify that this policy aligns with the system’s policy. Historically, formal assurance methods have been used to verify that a trusted program enforces system security goals, but these methods are time-consuming and manual. As a result, trusted programs are given additional privileges without any concrete justification.

Recently, the emergence of techniques for building programs with declarative access control policies motivates the development of an automated mechanism to verify that such programs correctly enforce security goals. Programs written in security-typed languages or integrated with user-level policy servers each include program-specific access control policies. In the case of security-typed languages, successful compilation proves policy enforcement. In the case of user-level policy servers, instrumentation ensures comprehensive enforcement of mandatory access control policies. We aim for such programs to enforce system security goals, which we refer to as compliance with the system’s security goals.

We use the classical reference monitor concept as the basis for the program’s compliance requirements:
1. The program policy must enforce a policy that represents the system security goals.
2. The system policy must ensure that the program cannot be tampered with.

Both of these problems can be cast as policy verification problems, but since program and system policies are written in different environments, they are not directly comparable. For example, the security-typed language Jif uses an information flow policy based on the Decentralized Label Model, while the SELinux system policy uses an extended Type Enforcement policy. Even where program policies are written for SELinux-compatible policy servers, the set of program labels is often distinct from the set of system labels. Prior work has involved manually joining a system policy with the program’s policy and providing a mapping between the two. To enable general programs to be compliant, our goal is to develop an approach by which compliant policy designs can be generated and verified automatically.

As a basis for an automated approach, we observe that trusted programs and the system data upon which they operate have distinct security requirements. For a trusted program, we must ensure that its components, such as executable files, libraries, and configurations, are protected from tampering by untrusted programs. For the system data, the system security policy should ensure that all operations on that data satisfy the system’s security goals. Since trusted programs should enforce the system’s security goals, their integrity must dominate the system data’s integrity. If the integrity of a trusted program is compromised, all system data is at risk. Using the insight that program integrity dominates system integrity, we propose the PIDSI approach to designing program policies, where we assign trusted program objects to a higher integrity label than system data objects. This results in a simplified program policy that enables automated compliance verification. Our experimental results show that this assumption is consistent with the SELinux reference policy for its trusted programs. Consequently, we are optimistic that trusted program policies can be designed independently of their target systems, yet still be deployed in a manner that ensures the enforcement of system security goals.

After providing background and motivation for the policy compliance problem in Section 2, we detail the following novel contributions:
1. In Section 3, we define a formal model for the policy compliance problem.
2. In Section 4, we propose the Program Integrity Dominates System Integrity (PIDSI) approach, where trusted programs are assigned to higher integrity labels than system data. We show that compliance program policies can be composed by relating the program policy labels to the system policy on the target system using the PIDSI approach.
3. In Section 5.1, we describe policy compliance tools that automate the proposed PIDSI approach, allowing a trusted program to be deployed on an existing SELinux system and verifying the enforcement of system security goals.
4. In Section 5.2, we show that the trusted programs for which there are Linux packages in SELinux are compatible with the PIDSI approach, with a few exceptions. We demonstrate how these can be resolved using simple policy modifications.

This work is the first, to our knowledge, that enables program and system security goals to be reconciled in a scalable (automated and system-independent) manner.

## 2. Background

The general problem is to develop an approach for building and deploying trusted programs, including their access control policies, in a manner that enables automated policy compliance verification. In this section, we specify the current mechanisms for three key steps: (1) trusted program policy construction; (2) trusted program deployment; and (3) trusted program enforcement. We will use the SELinux system as the platform for deploying trusted programs.

### 2.1 Program Policy Construction

There are two major approaches for constructing programs that enforce a declarative access control policy: (1) security-typed languages (STLs) and (2) application reference monitors. These two approaches are quite different, but we aim to verify policy compliance for programs implemented either way.

**Security-Typed Languages (STLs):**
Programs written in an STL will compile only if their information flows, determined by type inference, are authorized by the program’s access control policy. For example, in the Jif STL, a program consists of the code plus a policy file describing a Decentralized Label Model policy. The Jif compiler ensures that the policy is enforced by the generated program. We would use the policy file to determine whether the Jif program complies with the system security goals.

**Application Reference Monitors:**
For programs constructed with application reference monitors, the program includes a reference monitor interface that determines the authorization queries that must be satisfied to access program operations. The queries are submitted to a reference monitor component, which may be internal or external to the program. While the use of a reference monitor does not guarantee that the program policy is correctly enforced, a manual or semi-automated evaluation of the reference monitor interface is usually performed. For example, in the SELinux Policy Server, a program loads a policy package containing its policy into the SELinux Policy Server. The program is implemented with its own reference monitor interface, which submits authorization queries to the Policy Server. Programs that use an SELinux Policy Server may share labels, such as the labels of the system data, with other programs.

**Example: logrotate**
We previously reimplemented one of the trusted programs in an SELinux/MLS distribution, logrotate, using the Jif STL. logrotate manages logs by writing them to new files and is trusted in SELinux/MLS because it can read and write logs of multiple MLS secrecy levels. Our experience with logrotate showed that ensuring system security goals requires the trusted program to be aware of the system’s label for its data. For example, if logrotate accesses a log file, it should control access to the file data based on the SELinux label of that file. We manually designed the logrotate information flow policy to use the SELinux labels and the information flows they imply. Additionally, since logrotate variables may originate from program-specific data, such as configurations, the information flow policy had to ensure that the information flows among system data and program data were also correct. As a result, the information flow policy required a manual merge of program and system information flow requirements.

### 2.2 Program Deployment

We must also consider how trusted programs are deployed on systems to determine what it takes to verify compliance. In Linux, programs are delivered in packages, which include the executable, libraries, configuration files, etc. A package provides new files specific to a program, but a program may also depend on files already installed in the system, such as system shared libraries (e.g., libc). Some packages may also export files that other packages depend on (e.g., special libraries and infrastructure files used by multiple programs).

For a trusted program, such as logrotate, we expect that a Linux package would include two additional, noteworthy files:
1. The program policy, which contains the declarative access control policy to be enforced by the program’s reference monitor or STL implementation.
2. The SELinux policy module, which specifies the contribution of the package to the overall SELinux system policy.

In SELinux, the system policy is now composed from policy modules. SELinux policy modules specify the contribution of the package to the overall SELinux system policy. While SELinux policy modules are specific to programs, they are currently designed by expert system administrators. Our logrotate program policy is derived from the program’s SELinux policy module, and we envision that program policies and system policy modules will be designed in a coordinated way (e.g., by program developers rather than system administrators) in the future, although this is an open issue.

An SELinux policy module consists of three components:
1. A .te file defines a set of new SELinux types for the package and the policy rules that govern program accesses to its own resources and system resources.
2. A .fc file specifies the assignment of package files to SELinux types. Some files may use types local to the policy module, while others may be assigned types defined previously (e.g., system types like etc_t for files in /etc).
3. A .if file defines a set of interfaces that specify how other modules can access objects labeled with the types defined by this module.

When a package is installed, its files are downloaded onto the system and labeled based on the specification in the .fc file or the default system specification. Then, the trusted program’s module policy is integrated into the SELinux system policy, enabling the trusted program to access system objects and other programs to access the trusted program’s files. There are two ways that another program can access this package’s files:
1. Because a package file is labeled using an existing label.
2. Another module is loaded that uses this module’s interface or types.

For example, the logrotate package includes files for its executable, configuration file, documentation, man pages, execution status, etc. Some of these files are assigned new SELinux types defined by the logrotate policy module, such as the executable (logrotate_exec_t) and its status file (logrotate_var_lib_t), while others are assigned existing SELinux types, such as its configuration file (etc_t). The logrotate policy module uses system interfaces to obtain access to the system data (e.g., logs), but no other processes access logrotate interfaces. As a result, logrotate is only vulnerable to tampering because some of the system-labeled files it provides may be modified by untrusted processes.

We are also concerned that a logrotate process may be tampered with by the system data it uses (e.g., Biba read-down). For example, logrotate may read logs that contain malicious data. We believe that systems and programs should provide mechanisms to protect themselves from the system data they process. Some interesting approaches have been proposed to protect process integrity, so we consider this an orthogonal problem that we do not explore further here.

---

This revised version aims to improve the clarity, coherence, and professionalism of the original text.