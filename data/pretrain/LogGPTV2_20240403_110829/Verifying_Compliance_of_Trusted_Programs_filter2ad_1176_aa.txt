title:Verifying Compliance of Trusted Programs
author:Sandra Julieta Rueda and
Dave King and
Trent Jaeger
Verifying Compliance of Trusted Programs
Sandra Rueda, Dave King and Trent Jaeger
Systems and Internet Infrastructure Security Laboratory
Department of Computer Science and Engineering
The Pennsylvania State University
{ruedarod,dhking,tjaeger}@cse.psu.edu
Abstract
In this paper, we present an approach for verifying that
trusted programs correctly enforce system security goals
when deployed. A trusted program is trusted to only
perform safe operations despite have the authority to
perform unsafe operations; for example, initialization
programs, administrative programs, root network dae-
mons, etc. Currently, these programs are trusted without
concrete justiﬁcation. The emergence of tools for build-
ing programs that guarantee policy enforcement, such as
security-typed languages (STLs), and mandatory access
control systems, such as user-level policy servers, ﬁnally
offers a basis for justifying trust in such programs: we
can determine whether these programs can be deployed
in compliance with the reference monitor concept. Since
program and system policies are deﬁned independently,
often using different access control models, compliance
for all program deployments may be difﬁcult to achieve
in practice, however. We observe that the integrity of
trusted programs must dominate the integrity of system
data, and use this insight, which we call the PIDSI ap-
proach, to infer the relationship between program and
system policies, enabling automated compliance veriﬁ-
cation. We ﬁnd that the PIDSI approach is consistent
with the SELinux reference policy for its trusted pro-
grams. As a result, trusted program policies can be de-
signed independently of their target systems, yet still be
deployed in a manner that ensures enforcement of system
security goals.
1 Introduction
Every system contains a variety of trusted programs. A
trusted program is a program that is expected to safely
enforce the system’s security goals despite being autho-
rized to perform unsafe operations (i.e., operations that
can potentially violate those security goals). For exam-
ple, the X Window server [37] is a trusted program be-
cause enables multiple user processes to share access to
the system display, and the system trusts it to prevent
one user’s data from being leaked to another user. A sys-
tem has many such trusted processes, including those for
initialization (e.g., init scripts), administration (e.g.,
software installation and maintenance), system services
(e.g., windowing systems), authentication services (e.g.,
remote login), etc. The SELinux system [27] includes
over 30 programs speciﬁcally-designated as trusted to
enforce multilevel security (MLS) policies [14].
An important question is whether trusted programs ac-
tually enforce the system’s security goals. Trusted pro-
grams can be complex software, and they traditionally
lack any declarative access control policy governing their
behavior. Of the trusted programs in SELinux, only the
X server currently has an access control policy. Even in
this case, the system makes no effort to verify that the X
server policy corresponds to the system’s policy in any
way. Historically, only formal assurance has been used
to verify that a trusted program enforces system secu-
rity goals, but current assurance methodologies are time-
consuming and manual. As a result, trusted programs
are given their additional privileges without any concrete
justiﬁcation.
Recently, the emergence of techniques for building
programs with declarative access control policies moti-
vates us to develop an automated mechanism to verify
that such programs correctly enforce security goals. Pro-
grams written in security-typed languages [23, 26, 28] or
integrated with user-level policy servers [34] each in-
clude program-speciﬁc access control policies.
In the
former case, the successful compilation of the program
proves its enforcement of an associated policy. In the lat-
ter case, the instrumentation of the program with a pol-
icy enforcement aims to ensure comprehensive enforce-
ment of mandatory access control policies. In general,
we would want such programs to enforce system secu-
rity goals, in which case we say that the program com-
plies with the system’s security goals.
We use the classical reference monitor concept [1] as
the basis for the program’s compliance requirements1:
(1) the program policy must enforce a policy that rep-
resents the system security goals and (2) the system pol-
icy must ensure that the program cannot be tampered.
We will show that both of these problems can be cast as
policy veriﬁcation problems, but since program policies
and system policies are written in different environments,
often considering different security goals, they are not
USENIX Association  
17th USENIX Security Symposium 
321
directly comparable. For example, program policy lan-
guages can differ from the system policy language. For
example, the security-typed language Jif [26] uses an in-
formation ﬂow policy based on the Decentralized Label
Model [24], but the SELinux system policy uses an ex-
tended Type Enforcement policy [5] that includes multi-
level security labeling [2]. Even where program policies
are written for SELinux-compatible policy servers [34],
the set of program labels is often distinct from the set of
system labels. In prior work, veriﬁably-compliant pro-
grams were developed by manually joining a system pol-
icy with the program’s policy and providing a mapping
between the two [13]. To enable general programs to be
compliant, our goal is to develop an approach by which
compliant policy designs can be generated and veriﬁed
automatically.
As a basis for an automated approach, we observe that
trusted programs and the system data upon which it op-
erates have distinct security requirements. For a trusted
program, we must ensure that the program’s components,
such as its executable ﬁles, libraries, conﬁguration, etc.,
are protected from tampering by untrusted programs. For
the system data, the system security policy should ensure
that all operations on that data satisfy the system’s se-
curity goals. Since trusted programs should enforce the
system’s security goals, their integrity must dominate the
system data’s integrity. If the integrity of a trusted pro-
gram is compromised, then all system data is at risk. Us-
ing the insight that program integrity dominates system
integrity, we propose the PIDSI approach to designing
program policies, where we assign trusted program ob-
jects to a higher integrity label than system data objects,
resulting in a simpliﬁed program policy that enables au-
tomated compliance veriﬁcation. Our experimental re-
sults justify that this assumption is consistent with the
SELinux reference policy for its trusted programs. As
a result, we are optimistic that trusted program policies
can be designed independently of their target systems,
yet still be deployed in a manner that ensures enforce-
ment of system security goals.
After providing background and motivation for the
policy compliance problem in Section 2, we detail the
following novel contributions:
1. In Section 3, we deﬁne a formal model for policy
compliance problem.
2. In Section 4, we propose an approach called Pro-
gram Integrity Dominates System Integrity (PIDSI)
where trusted programs are assigned to higher in-
tegrity labels than system data. We show that com-
pliance program policies can be composed by relat-
ing the program policy labels to the system policy
on the target system using the PIDSI approach.
3. In Section 5.1, we describe policy compliance tools
that automate the proposed PIDSI approach such
that a trusted program can be deployed on an exist-
ing SELinux system and we can verify enforcement
of system security goals.
4. In Section 5.2, we show the trusted programs for
which there are Linux packages in SELinux are
compatible with the PIDSI approach with a few ex-
ceptions. We show how these can be resolved using
a few types of simple policy modiﬁcations.
This work is the ﬁrst that we are aware of that enables
program and system security goals to be reconciled in a
scalable (automated and system-independent) manner.
2 Background
The general problem is to develop an approach for build-
ing and deploying trusted programs, including their ac-
cess control policies, in a manner that enables automated
policy compliance veriﬁcation. In the section, we specify
the current mechanisms for these three steps: (1) trusted
program policy construction; (2) trusted program deploy-
ment; and (3) trusted program enforcement. We will use
the SELinux system as the platform for deploying trusted
programs.
2.1 Program Policy Construction
There are two major approaches for constructing pro-
grams that enforce a declarative access control policy:
(1) security-typed languages [26, 28, 33] (STLs) and (2)
application reference monitors [22, 34]. These two ap-
proaches are quite different, but we aim to verify policy
compliance for programs implemented either way.
Programs written in an STL will compile only if their
information ﬂows, determined by type inferencing, are
authorized by the program’s access control policy. As
a result, the STL compilation guarantees, modulo bugs
in the program interpreter, that the program enforces the
speciﬁed policy. As an example, we consider the Jif STL.
A Jif program consists of the program code plus a pro-
gram policy ﬁle [12] describing a Decentralized Label
Model [24] policy for the program. The Jif compiler en-
sures that the policy is enforced by the generated pro-
gram. We would use the policy ﬁle to determine whether
Jif program complies with the system security goals.
For programs constructed with application reference
monitors, the program includes a reference monitor in-
terface [1] which determines the authorization queries
that must be satisﬁed to access program operations. The
queries are submitted to a reference monitor component
that may be internal or external to the program. The use
of a reference monitor does not guarantee that the pro-
gram policy is correctly enforced, but a manual or semi-
automated evaluation of the reference monitor interface
is usually performed [17]. As an example, we consider
the SELinux Policy Server [34]. A program that uses the
322 
17th USENIX Security Symposium 
USENIX Association
SELinux Policy Server, loads a policy package contain-
ing its policy into the SELinux Policy Server. The pro-
gram is implemented with its own reference monitor in-
terface which submits authorization queries to the Policy
Server. We note that the programs that use an SELinux
Policy Server may share labels, such as the labels of the
system data, with other programs.
As an example, we previously reimplemented one of
the trusted programs in an SELinux/MLS distribution,
logrotate, using the Jif STL [13]. logrotate
ages logs by writing them to new ﬁles and is trusted
in SELinux/MLS because it can read and write logs
of multiple MLS secrecy levels. Our experience from
logrotate is that ensuring system security goals re-
quires the trusted program to be aware of the system’s
label for its data. For example, if logrotate accesses
a log ﬁle, it should control access to the ﬁle data based
on the system (e.g., SELinux) label of that ﬁle. We man-
ually designed the logrotate information ﬂow pol-
icy to use the SELinux labels and the information ﬂows
that they imply. Further, since logrotate variables
may also originate from program-speciﬁc data, such as
conﬁgurations, in addition to system ﬁles, the informa-
tion ﬂow policy had to ensure that the information ﬂows
among system data and program data was also correct.
As a result, the information ﬂow policy required a man-
ual merge of program and system information ﬂow re-
quirements.
2.2 Program Deployment
We must also consider how trusted programs are de-
ployed on systems to determine what it takes to verify
compliance. In Linux, programs are delivered in pack-
ages. A package is a set of ﬁles including the executable,
libraries, conﬁguration ﬁles, etc. A package provides
new ﬁles that are speciﬁc to a program, but a program
may also depend on ﬁles already installed in the sys-
tem (e.g., system shared libraries, such as libc). Some
packages may also export ﬁles that other packages de-
pend on (e.g., special libraries and infrastructure ﬁles
used by multiple programs).
For a trusted program, such as logrotate, we ex-
pect that a Linux package would include two additional,
noteworthy ﬁles:
(1) the program policy and (2) the
SELinux policy module2. The program policy is the ﬁle
that contains the declarative access control policy to be
enforced by the program’s reference monitor or STL im-
plementation, as described above.
In SELinux, the system policy is now composed from
the policy modules. SELinux policy modules specify the
contribution of the package to the overall SELinux sys-
tem policy [20]. While SELinux policy modules are spe-
ciﬁc to programs, they are currently designed by expert
system administrators. Our logrotate program pol-
icy is derived from the program’s SELinux policy mod-
ule, and we envision that program policies and system
policy modules will be designed in a coordinated way
(e.g., by program developers rather than system admin-
istrators) in the future, although this is an open issue.
An SELinux policy module consists of three compo-
nents that originate from three policy source ﬁles. First,
a .te ﬁle deﬁnes a set of new SELinux types3 for this
package. It also deﬁnes the policy rules that govern pro-
gram accesses to its own resources as well as system re-
sources. Second, a .fc ﬁle speciﬁes the assignment of
package ﬁles to SELinux types. Some ﬁles may use types
that are local to the policy module, but others may be as-
signed types deﬁned previously (e.g., system types like
etc t is used for ﬁles in /etc). A .if ﬁle deﬁnes a set
of interfaces that specify how other modules can access
objects labeled with the types deﬁned by this module.
When a package is installed, its ﬁles are downloaded
onto the system and labeled based on the speciﬁcation
in the .fc ﬁle or the default system speciﬁcation. Then,
the trusted program’s module policy is integrated into the
SELinux system policy4, enabling the trusted program to
access system objects and other programs to access the
trusted program’s ﬁles. There are two ways that another
program can access this package’s ﬁles: (1) because a
package ﬁle is labeled using an existing label or (2) an-
other module is loaded that uses this module’s interface
or types. As both are possible for trusted programs, we
must be concerned that the SELinux system policy may
permit an untrusted program to modify a trusted pro-
gram’s package ﬁle.
For example,
the logrotate package includes
ﬁles for its executable, conﬁguration ﬁle, documen-
tation, man pages, execution status, etc.
Some
of these ﬁles are assigned new SELinux types de-
ﬁned by the logrotate policy module, such as
the executable (logrotate exec t) and its status
ﬁle (logrotate var lib t), whereas others are as-
signed existing SELinux types, such as its conﬁguration
ﬁle (etc t). The logrotate policy module uses sys-
tem interfaces to obtain access to the system data (e.g.,
logs), but no other processes access logrotate inter-
faces. As a result, logrotate is only vulnerable to
tampering because some of the system-labeled ﬁles that
it provides may be modiﬁed by untrusted processes.
We are also concerned that a logrotate process
may be tampered by the system data that it uses (e.g.,
Biba read-down [4]). For example, logrotate may
read logs that contain malicious data. We believe that
systems and programs should provide mechanisms to
protect themselves from the system data that they pro-
cess. Some interesting approaches have been proposed to
protect process integrity [19, 30], so we consider this an
orthogonal problem that we do not explore further here.
USENIX Association  
17th USENIX Security Symposium 
323