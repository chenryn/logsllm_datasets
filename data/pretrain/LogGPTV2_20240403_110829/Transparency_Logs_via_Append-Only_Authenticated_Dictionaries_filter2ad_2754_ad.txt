(i.e., between the root BPT and BFT accumulators). The height of
the BPT is O (log n) and the height of the BFT is O (log (λn)) so the
Figure 4: A dynamic AAS with λ = 2 for set {B, C, D, E, F , H , J}.
Our AAS is a forest of BPTs with corresponding BFTs. Each
node stores a BPT accumulator (and subset proof), depicted
as a trie, in yellow. Root nodes store a BFT, depicted as the
missing red nodes.
size and verification time of a (non)membership proof is O (log n).
The digest is just the root accumulator of the BPT.
Handling appends efficiently. So far, we only discussed the case
of a static set S. However, our AAS should support appending new
elements to S. The main challenge here is efficiency since updating
the BPT and BFT as well as the disjointness proof after each update
is very expensive (at least linear). To address this we use a classic
“amortization” trick from Overmars [80] also used in [87].
to sets of elements S1, . . . , Sℓ. The final set is S =(cid:83)ℓ
Specifically, our AAS will consist not of one BPT for the entire set
S, but will be partitioned into a forest of BPTs and their correspond-
ing BFTs. Initially, we start with no elements in the AAS. When the
first element e1 is appended, we build its tree-pair: a BPT over the
set {e1}, its BFT and a disjointness proof. When the second element
e2 is appended, we “merge”: we build a size-2 tree-pair over {e1, e2}.
The rule is we always merge equal-sized tree-pairs. When e3 is
appended, we cannot merge it because there’s no other tree-pair
of size 1. Instead, we create a tree-pair over {e1}. In general, after
2ℓ − 1 appends, we end up with ℓ separate tree-pairs corresponding
j=1 Sj where
|Sj| = 2j. The evolution of such a forest is depicted in Figure 3 and
the final data structure can be seen in Figure 4.
Let us analyze the time to merge two size-n tree-pairs for S1 and
S2 into a size-2n tree-pair for S = S1 ∪ S2. To compute S’s BPT, we
need to (i) compute its root accumulator, (ii) set its children to the
“old” root accumulators of S1 and S2 and (iii) compute subset proofs
S1 ⊂ S and S2 ⊂ S. Since |S1| = |S2| = n, operations (i), (ii) and
(iii) take O (λn log2 n) time. Finally, we can compute S’s BFT from
scratch in O (λn log2 n) time.
To analyze the append time, consider the time T (n) to create an
AAS over a set S with n = 2ℓ elements (without loss of generality).
Then, T (n) is just the time to create a tree-pair over S and can be
broken into (i) the time to create a tree-pair over the children of S
of size n/2 (i.e., 2T (n/2)) (ii) the time to merge these two children
BPTs (including computing subset proofs) and (iii) the time to com-
pute the BFT of S. More formally, T (n) = 2T (n/2) + O (λn log2 n)
which simplifies to T (n) = O (λn log3 n) time for n appends. Thus,
the amortized time for one append is O (λ log3 n) and can be de-
amortized into worst-case time using generic techniques [80, 81].
The downside of our amortized approach is that proving non-
membership becomes slightly more expensive than in the static
AAS data structure from above. Specifically, now the server needs
Session 6C: Secure Computing VICCS ’19, November 11–15, 2019, London, United Kingdom1305to prove non-membership in each tree-pair separately, requiring an
O (log n) frontier proof in each of the O (log n) BFTs. This increases
the non-membership proof size to O (log2 n). On a good note, mem-
bership proofs remain unaffected: the server just sends a path to
a leaf in one of the BPTs where the element is found. Finally, the
AAS digest is set to the root accumulators of all BPTs and has size
O (log n). We analyze the complexity of our AAS in Appendix D.
Efficient append-only proofs. Our append-only proofs are sim-
ilar to the ones in history trees [29]. An append-only proof must
relate the root BPT accumulator(s) in the old AAS to the root BPT
accumulator(s) in the new AAS. We’ll refer to these as “old roots”
and “new roots” respectively. Specifically, it must show that every
old root either (i) became a new root or (ii) has a path to a new
root with valid subset proofs at every level. Such a path is verified
by checking the subset proofs between every child and its parent,
exactly as in a membership proof. At the same time, note that there
might be new roots that are neither old roots nor have paths to old
roots (e.g., root 111 in F5 from Figure 3). The proof simply ignores
such roots since they securely add new elements to the set. To
summarize, the append-only proof guarantees that each old root
(1) has a valid subset path to a new root or (2) became a new root.
Ensuring fork-consistency. For gossip protocols to work [28, 32],
our AAS must be fork-consistent. Interestingly, append-only proofs
do not imply fork-consistency. For example, consider a server who
computes an AAS for set {e1} and another one for the set {e2}. The
server gives the first set’s digest to user A and the second digest
to user B. Afterwards, he appends e2 to the first set and e1 to the
second one, which “joins” the two sets into a common set {e1, e2}.
The append-only property was not violated (as the two users can
deduce independently) but fork-consistency has been: the two users
had diverging views that were subsequently merged.
To avoid this, we will “Merkle-ize” each BPT using a CRHF H in
the standard manner (i.e., a node hashes its accumulator and its two
children’s hashes). Our AAS digest is now set to the Merkle roots
of all BPTs, which implicitly commit to all root accumulators in the
BPTs. As a result, after merging BPTs for elements e1 and e2, the
Merkle root of the merged BPT will differ based on how appends
were ordered: (e1, e2), or (e2, e1). Thus, violating fork-consistency
becomes as hard as finding a collision in H (see Appendix C).
5 FROM SETS TO DICTIONARIES
In this section, we turn our attention to constructing an append-
only authenticated dictionary (AAD). Recall that an AAS stores
elements and supports (non)membership queries of the form “Is
e ∈ S?” In contrast, an AAD stores key-value pairs and supports
lookups of the form “Is V the complete set of values for key k?” In
other words, an AAD maps a key k to a multiset of values V in
an append-only fashion. Specifically, once a value has been added
to a key, it cannot be removed nor changed. For example, if a key
is a domain name and its values are certificates for that domain,
then an AAD can be used as a Certificate Transparency (CT) log.
In general, keys and values can have any application-specific type,
as long as they can be hashed to a bit string.
Our construction has great similarities with the AAS of Section 4.
However, the different functionality calls for modifications. Indeed,
even the security notion for AADs is different (see Appendix E).
Specifically, in an AAS, no malicious server can simultaneously
produce accepting proofs of membership and non-membership for
the same element e with respect to the same digest. In contrast, in
an AAD, no malicious server can simultaneously produce accepting
proofs for two different sets of values V , V ′ for a key k with respect
to the same digest. This captures the related notion for an AAS
since one of the sets of values may be empty (indicating k has never
been registered in the dictionary) and the other non-empty. Next,
we describe how we modify our AAS from Section 4 to get an AAD.
Encoding key-value pairs. An AAS construction can trivially
support key-value pairs (k, v) by increasing the size of the domain
of the underlying AAS from 2λ bits to 4λ bits so as to account for
the value v. That is, (k, v) would be inserted in the AAS as k|v,
using the same algorithms from Appendix B. Thus AAD clients
)4λ+1
now have twice the number of public parameters: дτ , (дs i
i =0 .
Proving lookups. For simplicity, let us restrict ourselves to an
AAD of size 2i (i.e., with just one tree-pair). For a key k with no
values, a lookup proof is simply a frontier proof for a prefix of k
in the BFT, much like a non-membership proof in the AAS (see
Section 4). What if k has one or more values? First, the lookup proof
contains paths to BPT leaves with k’s values (i.e., with elements of
the form k|v), much like a membership proof in an AAS. But what
is to guarantee completeness of the response? What if a malicious
server leaves out one of the values of key k? (This is important in
transparency logs where users look up their own PKs and must
receive all of them to detect impersonation attacks.) We use the
same frontier technique as in the AAS to convince clients values are
not being left out. Specifically, the server proves specific prefixes
for the missing values of k are not in the BPTs (and thus are not
maliciously being left out). This is best illustrated with an example.
Suppose the server wants to prove k = 0000 has complete set
of values V = {v1 = 0001, v2 = 0011}. Consider a trie over k|v1
and k|v2 and note that F [k] = {(0000|1), (0000|01), (0000|0000),
(0000|0010)} is the set of all frontier prefixes for the missing values
of k. We call this set the lower frontier of k relative to V . The key
idea to prove completeness is to prove all lower frontier prefixes
are in the BFT via frontier proofs (as discussed in Section 4). Note
that |F [k]| = O (λ) and each frontier proof is O (log n)-sized, result-
ing in an O (λ log n)-sized proof. This idea generalizes to AADs of
arbitrary size: the server (i) proves non-membership of k in BPTs
with no values for k (via the BFT) and (ii) proves Vi is the com-
plete set of values of k in each remaining BPT i (via the BFT lower
frontier technique). In that case, a lookup proof for a key k with a
single value v consists of (1) an O (log n)-sized path in some BPT
with an O (λ log n)-sized frontier proof in its corresponding BFT (to
guarantee completeness) and (2) an O (log n)-sized frontier proof
for k in all other O (log n) BFTs, to prove k has no values there.
Smaller lookup proofs. When k has one value, it follows from
above that a lookup proof for k is O (λ log n)-sized. However, we can
easily decrease its size to O (log2 n). Note that the main overhead
comes from having to prove that all O (λ) lower frontier prefixes
of k are in a BFT. The key idea is to group all of k’s lower frontier
prefixes into a single BFT leaf, creating an accumulator over all of
them. As a result, instead of having to send O (λ) frontier proofs
(one for each lower frontier prefix), we send a single O (log n)-sized
frontier proof for a single BFT leaf which contains all lower frontier
Session 6C: Secure Computing VICCS ’19, November 11–15, 2019, London, United Kingdom1306)4λ+1
i =0
prefixes of k. We can generalize this idea: when k has |Vi| values
in the ith BFT in the forest, k’s lower frontier relative to Vi has
O (|Vi|λ) prefixes. Then, for each BFT i, we split the lower frontier
prefixes of k associated with Vi into separate BFT leaves each of size
at most 4λ +1. We remind the reader that clients have enough public
parameters (дs i
to reconstruct the accumulators in these BFT
leaves and verify the frontier proof.
Supporting large domains and multisets. To handle keys and
values longer than 2λ bits, we store H (k )|H (v) in the AAD (rather
than k|v), where H is a CRHF and we can retrieve the actual value
v from another repository. To support multisets (same v can be
inserted twice for a k), the server can insert H (H (v)|i) for the i-th
occurrence of (k, v).
Supporting inclusion proofs. Another useful proof for a trans-
parency log is an inclusion proof which only returns one of the
values of key k (while lookup proofs return all values of a key k).
For example, in Certificate Transparency (CT), browsers are sup-
posed to verify an inclusion proof of a website’s certificate before
using it. Our AAD supports inclusion proofs too. They consist of a
path to a BPT leaf with the desired key-value pair. Since they do not
require frontier proofs, inclusion proofs are only O (log n)-sized.
6 EVALUATION
In this section, we evaluate our AAD (not AAS) construction’s proof
sizes, append times and memory usage. We find that append times
and memory usage are too high for a practical deployment and dis-
cuss how they might be improved in future work (see Sections 6.1.1
and 6.1.4). If they are improved, we find AADs can save bandwidth
relative to CT and CONIKS and we describe exactly when and how
much in Section 6.2.1.
Codebase and testbed. We implemented our amortized AAD con-
struction from Section 5 in 5700 lines of C++. Its worst-case append
time is O (λn log2 n) while its amortized append time is O (λ log3 n).
We used Zcash’s libff [90] as our elliptic curve library with sup-
port for a 254-bit Barretto-Naehrig curve with a Type III pairing [7].
We used libfqfft [91] to multiply polynomials and libntl [92]
to divide polynomials and compute GCDs. Our code is available at:
https://github.com/alinush/libaad-ccs2019.
We ran our evaluation in the cloud on Amazon Web Services (AWS)
on a r4.16xlarge instance type with 488 GiB of RAM and 64 VCPUs,
running Ubuntu 16.04.4 (64-bit). This instance type is “memory-
optimized” which, according to AWS, means it is “designed to de-
liver fast performance for workloads that process large data sets in
memory.”
6.1 Microbenchmarks
6.1.1 Append times. Starting with an empty AAD, we append key-
value pairs to it and keep track of the cumulative average append-
time. Recall that appends are amortized in our construction (but can
be de-amortized using known techniques [80, 81]). As a result, in our
benchmark some appends are very fast (e.g., 25 milliseconds) while
others are painfully slow (e.g., 1.5 hours). To keep the running time
of our benchmark reasonable, we only benchmarked 213 = 8192
appends. We also investigate the effect of batching on append times.
Batching k = 2i appends together means we only compute one
BFT for the full tree of size k created after inserting the batch. In
contrast, without batching, we would compute k BFTs, one for each
new forest root created after an append. Figure 5c shows that the
average append time is 5.75 seconds with no batching and 0.76
seconds with batch size 8192. (For batch sizes 32, 64, . . . , 4096, the
average times per append in milliseconds are 3422, 3064, 2644, 2361,
1848, 1548, 1353 and 976 respectively.) These times should increase
by around 3.5 seconds if we benchmarked 220 appends.
Speeding up appends. The bottleneck for appends is comput-
ing the BFTs. Although we used libff’s multi-threaded multi-
exponentiation to compute accumulators faster, there are other
ways to speed up appends that we have not explored. First, we can
parallelize computing (1) the polynomials on the same level in a
BFT, (2) the smaller accumulators at lower levels of the BFT, where
multi-threaded multi-exponentiation does not help as much and (3)
the subset proofs in the forest. Second, we can reuse some of the
previously computed accumulators when computing a new BFT.
Third, our BPT and BFT constructions require “extractable” counter-
parts of the accumulators, which almost triple the time to commit
to a polynomial. We hope to remove this expensive requirement
by proving our construction secure in the generic group model,
similar to new SNARK constructions [48]. Finally, techniques for
distributed FFT could speed up polynomial operations [103].
Lookup proofs. We investigate three factors that affect lookup
6.1.2
proof size and verification time: (1) the dictionary size, (2) the num-