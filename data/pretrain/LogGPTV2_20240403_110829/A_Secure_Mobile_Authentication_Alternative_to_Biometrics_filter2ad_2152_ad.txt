0
0
0
4
4
0
0
5
5
4
4
0
0
0
0
5
5
)
%
(
e
r
o
c
s
R
R
F
)
%
(
e
r
o
c
s
R
R
F
60
50
40
30
20
10
0
60
50
40
30
20
10
0
5
5
0
0
0
0
0
0
1
1
0
0
5
5
1
1
0
0
0
0
2
2
0
0
0
0
0
0
5
5
2
2
3
λ
(a)
3
λ
(d)
0
0
5
5
3
3
0
0
0
0
4
4
0
0
5
5
4
4
0
0
0
0
5
5
0
0
0
0
1
1
0
0
5
5
1
1
0
0
0
0
2
2
0
0
0
0
0
0
5
5
2
2
3
λ
(c)
3
λ
(f)
0
0
5
5
3
3
0
0
0
0
4
4
0
0
5
5
4
4
0
0
0
0
5
5
Figure 5: (a-c) ai.lock cross validation performance, and (d-f) ai.lock holdout performance using diﬀerent ai.lock variants:
Single Layer Single Segment (SLSS), Multi Layer Single Segment (MLSS), Single Layer Multi Segment (SLMS), Multi Layer Multi
Segment (MLMS). Exploiting information from multiple Inception.v3 DNN layers (multi layer variants) lowers the FRR, while
splitting images into smaller segments (multi segment variants) lowers the FAR. ‡e MLMS variant of ai.lock consistently
achieves the lowest FAR, that can be as low as 0% for the holdout dataset.
λ
50
100
150
200
250
300
350
400
450
500
t (matching segment counts out of 5)
3
4
5
τ × 10
7.80
7.30
7.07
6.95
6.80
6.87
6.80
6.85
6.87
6.82
Table 3: Error tolerance threshold (τ ) values for the basic
ai.lock obtained through cross validation over the ai.lock
dataset, when using PCs with feature ranked 200-400.
test fold by the length of the imageprints. Œen, we apply more
than 4K diﬀerent real values, between 0 and 1, as a threshold on
the normalized Hamming distances of the authentication pairs to
classify them. At the end of the 5th cross validation experiment, we
select the threshold that has the maximum average performance,
in terms of F1 score, as the best separating threshold. We call this
the Error Tolerance Šreshold, which we denote by τ .
Table 3 reports the τ values for basic ai.lock with diﬀerent values
of λ, when using PCs with feature rank 200-400. We observe that
as λ increases, the value for τ decreases: we posit that larger λ
values preserve more information about the input vectors (PCs of
the embedding vectors) in the LSH output.
We translate τ to the error correcting capacity required for ECC.
Speciﬁcally, for an imageprint of length λ, we choose an ECC that
is able to correct up to c = ⌊λ × (1 − τ )⌋ bits.
ai.lock MLSS variant. Similar to the basic ai.lock, we have exper-
imented with multiple ranges of PCs and λ values to identify the
τ values for MLSS ai.lock, using the 5 fold cross validation experi-
ment on the ai.lock training dataset.
ai.lock: Multi segment variants. For this ai.lock variant, we
identify the τ values separately for each image segment, using the 5
cross validation experiment explained above. Œerefore, we end up
having 5 diﬀerent τ values corresponding to each image segment.
Œe τ corresponding to each segment can be used to identify if
8
F1 score (%) for SLMS
F1 score (%) for MLMS
93.13
95.53
90.95
94.64
85.84
92.42
Table 4: Cross validation performance (F1 score) for diﬀer-
ent values of t (number of segments that need to match out
of 5) when using PCs with feature rank 200-400 and λ = 500
for SLMS and MLMS variants of ai.lock. t = 3 consistently
achieves the best performance.
there is a match between the piece of the candidate image to the
corresponding piece in the reference image. We say that the whole
candidate and reference images match, when t of their segments
match. We have tested with t ranging from 3 to 5 and observed
that t=3 achieved the best F1 score (see Table 4).
Cross validation performance. We now report the cross valida-
tion performance of ai.lock with the parameters identiﬁed above,
for λ ranging from 50 to 500. Figures 5(a)-(c) compare the F1 score,
FAR and FRR values of the best version of the ai.lock variants (ba-
sic SLSS, SLMS, MLSS, and MLMS) over the 5-fold cross validation
experiments, using ai.lock training dataset. Œe performance of
all ai.lock variants improves with increasing the value of λ. Œe
MLMS ai.lock achieves the best performance, with an F1 score of
95.52% and FAR of 0.0009% when λ = 500. Œe MLSS ai.lock also
consistently improves over the basic ai.lock, with a smaller FRR
and a smaller or at most equal FAR. Its FRR (4.18% for λ = 500) is
slightly smaller than that of MLMS variants (5.36%), but it exhibits
a slight increase in FAR. For large values of λ, the FRR of SLMS and
SLSS are almost equivalent.
Œe average cross validation Equal Error Rate (EER, the rate at
which the FAR = FRR) of ai.lock for the SLSS and MLSS variants is
λ
50
150
250
350
500
FAR×10+6
33.87
4.34
3.29
0.69
0.20
ai.lock dataset
ai.lock + sy thetic image attack DS2 (Not PCA)
ai.lock + sy thetic image attack DS2
Table 5: SLSS ai.lock performance on synthetic attack DS1.
‡e FAR decreases signiﬁcantly as λ grows from 50 to 500.
‡e FAR when λ = 500 is only 0.2 × 10−6.
n
o
i
t
a
d
i
l
a
V
s
s
o
r
C
)
%
(
R
A
F
0.004
0.003
0.002
0.001
0.000
−0.001
0.004
0.003
0.002
0.001
0.000
%0.001
0
0
5
5
0
0
0
0
1
1
0
0
5
5