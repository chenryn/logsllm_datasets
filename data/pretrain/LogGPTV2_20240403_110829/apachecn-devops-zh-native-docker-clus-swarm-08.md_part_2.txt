*   该任务获得一个 IP 地址
*   其网络相关信息将提交到 Raft 日志存储中
*   在分配完成提交后，调度程序会将任务移动到另一个状态
*   调度程序将每个任务分派给一个工作节点
*   最后，与该任务相关联的容器将在 Docker 引擎上运行
如果一个任务不能分配其网络资源，它将停留在分配的状态，不会被调度。这与之前版本的 Docker 的重要区别在于，在 Swarm 模式的网络系统中，分配状态的概念很明显。这样就大大提高了系统的整体分配周期。当我们谈论分配时，我们不仅指 IP 地址的分配，还指相关的驱动程序工件。对于覆盖网络，它需要保留一个 VXLAN 标识符，这是每个 VXLAN 的一组全局标识符。这个标识符保留是由网络分配器完成的。
未来，一个插件做同样的分配机制，只实现一些接口，让状态由 Libnetwork 自动管理并存储到 Raft 日志中就足够了。有了这一点，资源分配是集中的，所以我们可以达到一致性和共识。有了共识，我们需要一个高效的共识协议。
# 网络控制平面
网络控制平面是 Libnetwork 的一个子系统，用于管理路由信息，我们需要一个快速收敛的协议来完成这项工作。例如，Libnet 不使用 BGP 作为协议(尽管 BGP 在支持非常多的端点的可伸缩性方面非常出色)，因为点 BGP 不会快速收敛到足以在高度动态的环境(如软件容器环境)中使用。
在一个以容器为中心的世界中，网络系统预计会发生非常迅速的变化，尤其是对于新的 Docker 服务模式，这需要大量且快速的 IP 分配。我们希望路由信息也能非常快速地收敛，尤其是在大规模的情况下，例如，超过 10，000 个容器。在 Swarm2k 和 Swarm3k 实验中，我们确实一次启动了 10，000 个容器。特别是在 Swarm3k 中，我们在 Ingress 负载平衡网络上启动了 4，000 个 NGINX 容器。如果没有一个良好的实现，这个数字的规模将无法正常工作。
为了解决这个问题，Libnetwork 团队选择在网络控制平面中包含八卦协议。协议的内部算法是这样工作的:它选择 3 个邻居，然后传播相同的信息；在 Libnetwork 的情况下，路由和其他网络相关信息。流言协议将重复这个过程，直到每个节点共享相同的信息。使用这种技术，整个集群将在几秒钟内非常快速地接收信息。
![Network Control Plane](img/image_08_003.jpg)
无论如何，整个集群并不总是需要相同的信息。集群中的每个节点不需要知道所有网络的信息。只有特定网络中的节点需要知道自己的网络信息。为了优化 Libnetwork，团队实现了两个范围，*集群范围的流言传播*和*网络范围的流言传播*。到目前为止，我们解释的是集群范围的流言传播，而网络范围的流言传播限制了特定网络中的网络信息。当一个网络扩展到覆盖更多的节点时，它的八卦范围的广播也将覆盖它们。
这项活动建立在多克的 CNM 之上，因此突出了网络抽象。从图中，我们在左侧网络中有节点 **w1** 、 **w2** 、 **w3** ，在右侧网络中还有 **w3** 、 **w4** 、 **w5** 。左侧网络执行流言蜚语，只有 **w1** 、 **w2** 、 **w3** 知道其路由信息。您可能会发现 w3 同时存在于两个网络中。因此，它将接收所有左右网络的路由信息。
# 立千伏
`libkv`是一个统一的库，用于与不同的键值存储后端进行交互。`libkv`最初是 Docker Swarm v1 的一部分，在开发的最初版本中。后来，所有与键值存储发现服务相关的代码都被重构并转移到了[www.github.com/docker/libkv](https://github.com/docker/libkv)。
`libkv`允许您执行 CRUD 操作，还可以从不同的后端观看键值条目，因此我们可以使用相同的代码来处理所有 HA 分布式键值存储，它们是**consult**、 **Etcd** 和 **ZooKeeper** ，如下图所示。在撰写本文时，libkv 还支持使用 **BoltDB** 实现的本地存储。
![Libkv](img/image_08_004.jpg)
## 如何使用 libkv
首先`libkv,`我们需要先了解如何调用它的 API。以下是 Go 中的`libkv Store`界面，适用于每个商店实现:
```
type Store interface {
 Put(key string, value []byte, options *WriteOptions) error
 Get(key string) (*KVPair, error)
 Delete(key string) error
 Exists(key string) (bool, error)
 Watch(key string, stopCh <-chan struct{}) (<-chan *KVPair, error)
 WatchTree(directory string, stopCh <-chan struct{}) (<-chan  
       []*KVPair, 
       error)
 NewLock(key string, options *LockOptions) (Locker, error)
 List(directory string) ([]*KVPair, error)
 DeleteTree(directory string) error
 AtomicPut(key string, value []byte, previous *KVPair, options 
       *WriteOptions) (bool, *KVPair, error)
 AtomicDelete(key string, previous *KVPair) (bool, error)
 Close()
}
```
我们需要知道如何`Put`、`Get`、`Delete`、`Watch`与一个店铺基本互动。
确保你的机器上也安装了 Go 和 Git，并且 Git 可执行文件在你的路径上。然后，我们需要为我们的程序安装一些 go get 依赖项:
```
$ go get github.com/docker/libkv
$ go get github.com/davecgh/go-spew/spew
$ go get github.com/hashicorp/consul/api
```
这里我们提供了一个骨架。在尝试运行以下程序之前，您需要启动单节点`Consul`:
```
# Delete all keys in Consul
$ curl -X DELETE http://localhost:8500/v1/kv/?recurse
# Compile the program
$ go build main.go
# Run it
$ ./main
# Spew is dumping the result for us in details
([]*store.KVPair) (len=1 cap=2) {
(*store.KVPair)(0x10e00de0)({
 Key: (string) (len=27) "docker/nodes/127.0.0.1:2375",
 Value: ([]uint8) (len=14 cap=15) {
 00000000  31 32 37 2e 30 2e 30 2e  31 3a 32 33 37 35        
      |127.0.0.1:2375|
 },
 LastIndex: (uint64) 736745
})
}
```
你也可以用 curl 测试你的价值。你投入的价值应该在那里。我们应该继续玩 libkv APIs，分别是`Get`和`Delete`。留给读者作为练习。
# 总结
本章介绍 Libnetwork，它是 Docker Swarm 最重要的部分之一。我们已经讨论了它的管理平面、控制平面和数据平面。本章还包括一些关于如何使用`libkv`，一个键值抽象来实现你自己的服务发现系统的技术。在下一章中，我们将重点讨论安全性。在下一章中，我们将学习如何保护集群。