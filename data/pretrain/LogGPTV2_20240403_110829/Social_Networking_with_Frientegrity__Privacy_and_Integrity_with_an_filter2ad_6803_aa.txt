title:Social Networking with Frientegrity: Privacy and Integrity with an
Untrusted Provider
author:Ariel J. Feldman and
Aaron Blankstein and
Michael J. Freedman and
Edward W. Felten
Social Networking with Frientegrity:
Privacy and Integrity with an Untrusted Provider
Ariel J. Feldman, Aaron Blankstein, Michael J. Freedman, and Edward W. Felten
Princeton University
Abstract
Today’s social networking services require users to trust
the service provider with the conﬁdentiality and integrity
of their data. But with their history of data leaks and
privacy controversies, these services are not always de-
serving of this trust. Indeed, a malicious provider could
not only violate users’ privacy, it could equivocate and
show diﬀerent users divergent views of the system’s state.
Such misbehavior can lead to numerous harms including
surreptitious censorship.
In light of these threats, this paper presents Frientegrity,
a framework for social networking applications that can be
realized with an untrusted service provider. In Frientegrity,
a provider observes only encrypted data and cannot devi-
ate from correct execution without being detected. Prior
secure social networking systems have either been decen-
tralized, sacriﬁcing the availability and convenience of a
centralized provider, or have focused almost entirely on
users’ privacy while ignoring the threat of equivocation.
On the other hand, existing systems that are robust to
equivocation do not scale to the needs social networking
applications in which users may have hundreds of friends,
and in which users are mainly interested the latest updates,
not in the thousands that may have come before.
To address these challenges, we present a novel method
for detecting provider equivocation in which clients col-
laborate to verify correctness. In addition, we introduce an
access control mechanism that oﬀers eﬃcient revocation
and scales logarithmically with the number of friends. We
present a prototype implementation demonstrating that
Frientegrity provides latency and throughput that meet the
needs of a realistic workload.
Introduction
1.
Popular social networking sites have hundreds of millions
of active users [20]. They have enabled new forms of
communication, organization, and information sharing; or,
as Facebook’s prospectus claims, they exist “to make the
world more open and connected” [60]. But by now, it is
widely understood that these beneﬁts come at the cost of
having to trust these centralized services with the privacy
of one’s social interactions. The history of these services
is rife with unplanned data disclosures (e.g., [22, 40]), and
1
these services’ centralization of information makes them
attractive targets for attack by malicious insiders and out-
siders. In addition, social networking sites face pressure
from government agencies world-wide to release infor-
mation on demand, often without search warrants [24].
Finally and perhaps worst of all, the behavior of service
providers themselves is a source of users’ privacy con-
cerns. Providers have repeatedly changed their privacy
policies and default privacy settings, and have made public
information that their users thought was private [46, 47].
Less recognized, however, is the extent to which users
trust social networking sites with the integrity of their data,
and the harm that a malicious or compromised provider
could do by violating it. Prior work on secure social
networking has focused primarily on privacy and largely
neglected integrity, or at most employed digital signatures
on users’ individual messages [5, 53, 54, 56]. But a ma-
licious provider could be more insidious. For example,
bloggers have claimed that Sina Weibo, a Chinese mi-
croblogging site, tried to disguise its censorship of a user’s
posts by hiding them from the user’s followers but still
showing them to the user [51]. This behavior is an exam-
ple of server equivocation [34, 39], in which a malicious
service presents diﬀerent clients with divergent views of
the system state. We argue that to truly protect users’ data,
a secure social networking service should defend against
this sort of attack.
To address the security concerns surrounding social net-
working, numerous prior works (e.g., [5, 17, 56]) have
proposed decentralized designs in which the social net-
working service is provided not by a centralized provider,
but by a collection of federated nodes. Each node could
either be a service provider of a user’s choice or the user’s
own machine or those of her friends. We believe that
decentralization is the wrong, or at least an insuﬃcient,
approach, however, because it leaves the user with an un-
enviable dilemma: either sacriﬁce availability, reliability,
and convenience by storing her data on her own machine,
or entrust her data to one of several providers that she
probably does not know or trust any more than she would
a centralized provider.
In light of these problems, we present Frientegrity, a
framework for building social networking services that
protects the privacy and integrity of users’ data from a
potentially malicious provider, while preserving the avail-
ability, reliability, and usability beneﬁts of centralization.
Frientegrity supports familiar social networking features
such as “walls,” “news feeds,” comment threads, and pho-
tos, as well as common access control mechanisms such
as “friends,” “friends-of-friends,” and “followers.” But
in Frientegrity, the provider’s servers only see encrypted
data, and clients can collaborate to detect server equivo-
cation and other forms of misbehavior such as failing to
properly enforce access control. In this way, Frientegrity
bases its conﬁdentiality and integrity guarantees on the
security of users’ cryptographic keys, rather than on the
service provider’s good intentions or the correctness of its
complex server code. Frientegrity remains highly scalable
while providing these properties by spreading system state
across many shared-nothing servers [52].
To defend against server equivocation, Frientegrity en-
forces a property called fork* consistency [33]. A fork*-
consistent system ensures that if the provider is honest,
clients see a strongly-consistent (linearizable [27]) order-
ing of updates to an object (e.g., a wall or comment thread).
But if a malicious provider presents a pair of clients with
divergent views of the object, then the provider must pre-
vent the clients from ever seeing each other’s subsequent
updates lest they identify the provider as faulty.
Prior systems have employed variants of fork* consis-
tency to implement network ﬁle systems [33, 34], key-
value stores [7, 38, 50], and group collaboration sys-
tems [21] with untrusted servers. But these systems as-
sumed that the number of users would be small or that
clients would be connected to the servers most of the time.
As a result, to enforce fork* consistency, they presumed
that it would be reasonable for clients to perform work
that is linear in either the number of users or the number
of updates ever submitted to the system. But these as-
sumptions do not hold in social networking applications
in which users have hundreds of friends, clients are Web
browsers or mobile devices that connect only intermit-
tently, and users typically are interested only in the most
recent updates, not in the thousands that may have come
before.
To accommodate these unique scalability challenges,
we present a novel method of enforcing fork* consistency
in which clients collaborate to detect server equivocation.
This mechanism allows each client to do only a small
portion of the work required to verify correctness, yet is
robust to collusion between a misbehaving provider and
as many as f malicious users, where f is a predetermined
security parameter per object.
Access control is another area where social network-
ing presents new scalability problems. A user may have
hundreds of friends and tens of thousands of friends-of-
friends (FoFs) [19]. Yet, among prior social networking
systems that employ encryption for access control (e.g.,
[5, 9, 37]), many require work that is linear in the number
of friends, if not FoFs, to revoke a friend’s access (i.e.,
to “un-friend”). Frientegrity, on the other hand, supports
fast revocation of friends and FoFs, and also gives clients
a means to eﬃciently verify that the provider has only
allowed writes from authorized users. It does so through a
novel combination of persistent authenticated dictionar-
ies [12] and key graphs [59].
To evaluate the scalability of Frientegrity, we imple-
mented a prototype that simulates a Facebook-like service.
We demonstrate that Frientegrity is capable of scaling with
reasonable performance by testing this prototype using
workloads with tens of thousands of updates per object
and access control lists containing hundreds of users.
Roadmap In §2, we introduce Frientegrity’s goals and
the threat model against which it operates. §3 presents an
overview of Frientegrity’s architecture using the task of
fetching a “news feed” as an example. §4 delves into the
details of Frientegrity’s data structures and protocols for
collaboratively enforcing fork* consistency on an object,
establishing dependencies between objects, and enforcing
access control. §5 discusses additional issues for untrusted
social networks such as friend discovery and group admin-
istration. We describe our prototype implementation in
§6 and then evaluate its performance and scalability in §7.
We discuss related work in §8 and then conclude.
2. System Model
In Frientegrity, the service provider runs a set of servers
that store objects, each of which corresponds to a famil-
iar social networking construct such as a Facebook-like
“wall”, a comment thread, or a photo or album. Clients
submit updates to these objects, called operations, on be-
half of their users. Each operation is encrypted under a
key known only to a set of authorized users, such as a
particular user’s friends, and not to the provider. Thus,
the role of the provider’s servers is limited to storing op-
erations, assigning them a canonical order, and returning
them to clients upon request, as well as ensuring that only
authorized clients can write to each object. To conﬁrm
that servers are fulﬁlling this role faithfully, clients collab-
orate to verify their output. Whenever a client performs a
read, it checks whether the response is consistent with the
responses that other clients received.
2.1 Goals
Frientegrity should satisfy the following properties:
Broadly applicable: If Frientegrity is to be adopted, it
must support the features of popular social networks such
as Facebook-like walls or Twitter-like feeds. It must also
support both the symmetric “friend” and “friend-of-friend”
relationships of services like Facebook and the asymmetric
“follower” relationships of services like Twitter.
2
Keeps data conﬁdential: Because the provider is un-
trusted, clients must encrypt their operations before sub-
mitting them to the provider’s servers. Frientegrity must
ensure that all and only the clients of authorized users can
obtain the necessary encryption keys.
Detects misbehavior: Even without access to objects’
plaintexts, a malicious provider could still try to forge
or alter clients’ operations. It could also equivocate and
show diﬀerent clients inconsistent views of the objects.
Moreover, malicious users could collude with the provider
to deceive other users or could attempt to falsely accuse
the provider of being malicious. Frientegrity must guar-
antee that as long as the number of malicious users with
permission to modify an object is below a predetermined
threshold, clients will be able to detect such misbehavior.
Eﬃcient: Frientegrity should be suﬃciently scalable to
be used in practice. In particular, a client that is only in-
terested in the most recent updates to an object should not
have to download and check the object in its entirety just
so that the it can perform the necessary veriﬁcation. Fur-
thermore, because social networking users routinely have
hundreds of friends and tens of thousands of friends-of-
friends [19], access control list changes must be performed
in time that is better than linear in the number of users.
2.2 Detecting Server Equivocation
To prevent a malicious provider from forging or modi-
fying clients’ operations without detection, Frientegrity
clients digitally sign all their operations with their users’
private keys. But as we have discussed, signatures are not
suﬃcient for correctness, as a misbehaving provider could
still equivocate about the history of operations.
To mitigate this threat, Frientegrity employs fork* con-
sistency [33].1 In fork*-consistent systems, clients share
information about their individual views of the history by
embedding it in every operation they send. As a result, if
clients to whom the provider has equivocated ever com-
municate, they will discover the provider’s misbehavior.
The provider can still fork the clients into disjoint groups
and only tell each client about operations by others in its
group, but then it can never again show operations from
one group to the members of another without risking de-
tection. Furthermore, if clients are occasionally able to
exchange views of the history out-of-band, even a provider
which forks the clients will not be able to cheat for long.
1Fork* consistency is a weaker variant of an earlier model
called fork consistency [39]. They diﬀer in that under fork con-
sistency, a pair of clients only needs to exchange one message
to detect server equivocation, whereas under fork* consistency,
they may need to exchange two. Frientegrity enforces fork*
consistency because it permits a one-round protocol to submit
operations, rather than two. It also ensures that a crashed client
cannot prevent the system from making progress.
Ideally, to mitigate the threat of provider equivocation,
Frientegrity would treat all of the operations performed on
all of the objects in the system as a single, uniﬁed history
and enforce fork* consistency on that history. Such a
design would require establishing a total order on all of the
operations in the system regardless of the objects to which
they belonged. In so doing, it would create unnecessary
dependencies between unrelated objects, such as between
the “walls” of two users on opposite sides of the social
graph. It would then be harder to store objects on diﬀerent
servers without resorting to either expensive agreement
protocols (e.g., Paxos [31]) or using a single serialization
point for all operations.
Instead, like many scale-out services, objects in Frien-
tegrity are spread out across many servers; these objects
may be indexed either through a directory service [1, 23]
or through hashing [15, 30]. The provider handles each
object independently and only orders operations with re-
spect to the other operations in the same object. Clients,
in turn, exchange their views of each object to which they
have access separately. Thus, for eﬃciency, Frientegrity
only enforces fork* consistency on a per-object basis.
There are situations, however, when it is necessary to
make an exception to this rule and specify that an opera-
tion in one object happened after an operation in another.
Frientegrity allows clients to detect provider equivocation
about the order of such a pair of operations by supply-
ing a mechanism for explicitly entangling the histories of
multiple objects (see §3.4).
2.3 Threat Model
Provider: We assume that the provider may be actively
malicious. It may not only attempt to violate the conﬁden-
tiality of users’ social interactions, but also may attempt to
compromise their integrity through either equivocation or
by directly tampering with objects, operations, or access
control lists (ACLs).
Although Frientegrity makes provider misbehavior de-
tectable, it does not prevent a malicious provider from
denying service, either by blocking all of a client’s updates
or by erasing the encrypted data it stores. To mitigate this
threat, clients could replicate their encrypted operations
on servers run by alternate providers. Furthermore, if
provider equivocation creates inconsistencies in the sys-
tem’s state, clients can resolve them using fork-recovery
techniques, such as those employed by SPORC [21]. We
argue, however, that because Frientegrity allows provider
misbehavior to be detected quickly, providers will have
an incentive to avoid misbehaving out of fear of legal
repercussions or damage to their reputations.
The provider does not have access to the contents of
objects or the contents of the individual operations that
clients upload, because they are encrypted under keys that
it does not know. In addition, because users’ names are
3
also encrypted, the provider can only identify users by
pseudonyms, such as the hash of the public keys they
use within the system. Nevertheless, we do not seek to
hide social relationships: we assume that the provider
can learn the entire pseudonymous social graph, including
who is friends with whom and who interacts with whom,
by analyzing the interconnections between objects and
by keeping track of which pseudonyms appear in which
objects, (e.g., by using social network deanonymization
techniques [4, 43]).
Preventing the provider from learning the social graph
is likely to be impossible in practice because even if
users used a new pseudonym for every new operation,
the provider would still be able to infer a great deal from
the size and timing of their operations. After all, in most
social networking applications, the ﬁrst thing a user does
when she signs in is check a “news feed” which is com-