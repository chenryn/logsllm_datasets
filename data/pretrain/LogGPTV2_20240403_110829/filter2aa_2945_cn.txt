Tasks, memory allocation, and efficiency
Just because a method is tagged as async, it does not mean that it will always
execute asynchronously. Consider the following method:
Click here to view code image
public async Task FindValueAsync(string key)
{
    bool foundLocally = GetCachedValue(key, out int result);
    if (foundLocally)
        return result;
    result = await RetrieveValue(key); // possibly takes a long time
    AddItemToLocalCache(key, result);
    return result;
}
The purpose of this method is to lookup an integer value associated with a
string key; for example, you might be looking up a customer ID given the
customer’s name, or you could be retrieving a piece of data based on a string
containing an encrypted key. The FindValueAsync method implements the
Cache-Aside pattern (see https://docs.microsoft.com/en-
us/azure/architecture/patterns/cache-aside for a detailed discussion of this
pattern), whereby the results of a potentially lengthy calculation or lookup
operation are cached locally when they are performed in case they are needed
again in the near future. If the same key value is passed to a subsequent call
of FindValueAsync, the cached data can be retrieved. The pattern uses the
following helper methods (the implementations of these methods is not
shown):
GetCachedValue. This method checks the cache for an item with the
specified key and passes the item back if it is available, in the out
parameter. The return value of the method is true if the data was found
in the cache, false otherwise.
RetrieveValue. This method runs if the item was not found in the
cache; it performs the calculation or lookups necessary to find the data
and returns it. This method could potentially take a significant time to
run, so it is performed asynchronously.
AddItemToLocalCache. This method adds the specified item to the
local cache in case it is requested again. This will save the application
from having to perform the expensive RetrieveValue operation again.
Download from finelybook PI:EMAIL
845
In an ideal world, the cache will account for the vast majority of the data
requested over the lifetime of the application, and the number of times it is
necessary to invoke RetrieveValue should become shrinkingly small.
Now consider what happens each time your code calls the
FindValueAsync method. In most cases, the work will be performed
synchronously (it finds the data in cache). The data is an integer, but it is
returned wrapped in a Task object. Creating and populating this object,
and then retrieving the data from this object when the method returns,
requires more effort in terms of processing power and memory allocation
than simply returning an int. C# caters to this situation by providing the
ValueTask generic type. You use it to specify the return type of an async
method, but the return value is marshaled as a value type on the stack rather
than a reference on the heap:
Click here to view code image
public async ValueTask FindValueAsync(string key)
{
    bool foundLocally = GetCachedValue(key, out int result);
    if (foundLocally)
        return result;
    result = await RetrieveValue(key); // possibly takes a long time
    AddItemToLocalCache(key, result);
    return result;
}
Note that this does not mean that you should always use ValueTask rather
than Task. If an asynchronous method actually performs the await operation,
then using ValueTask can decrease the efficiency of your code quite
significantly, for reasons that I don’t have time or space to go into here. So,
in general, consider returning a ValueTask object only if the vast majority of
the calls to an async method are likely to be performed synchronously,
otherwise stick to the Task type.
Note To use the ValueTask type, you must use the NuGet Package
Manager to add the System.Threading,Tasks,Extensions package to
your project.
Download from finelybook PI:EMAIL
846
The IAsyncResult design pattern in earlier versions
of the .NET Framework
Asynchronicity has long been recognized as a key element in building
responsive applications with the .NET Framework, and the concept
predates the introduction of the Task class in the .NET Framework
version 4.0. Microsoft introduced the IAsyncResult design pattern based
on the AsyncCallback delegate type to handle these situations. The
exact details of how this pattern works are not appropriate in this book,
but from a programmer’s perspective the implementation of this pattern
meant that many types in the .NET Framework class library exposed
long-running operations in two ways: in a synchronous form consisting
of a single method, and in an asynchronous form that used a pair of
methods, named BeginOperationName and EndOperationName, where
OperationName specified the operation being performed. For example,
the MemoryStream class in the System.IO namespace provides the Write
method to write data synchronously to a stream in memory, but it also
provides the BeginWrite and EndWrite methods to perform the same
operation asynchronously. The BeginWrite method initiates the write
operation that is performed on a new thread. The BeginWrite method
expects the programmer to provide a reference to a callback method that
runs when the write operation completes; this reference is in the form of
an AsyncCallback delegate. In this method, the programmer should
implement any appropriate tidying up and call the EndWrite method to
signify that the operation has completed. The following code example
shows this pattern in action:
Click here to view code image
...
Byte[] buffer = ...; // populated with data to write to the
MemoryStream
MemoryStream ms = new MemoryStream();
AsyncCallback callback = new
AsyncCallback(handleWriteCompleted);
ms.BeginWrite(buffer, 0, buffer.Length, callback, ms);
...
private void handleWriteCompleted(IAsyncResult ar)
Download from finelybook PI:EMAIL
847
{
    MemoryStream ms = ar.AsyncState as MemoryStream;
    ...// Perform any appropriate tidying up
    ms.EndWrite(ar);
}
The parameter to the callback method (handleWriteCompleted) is an
IAsyncResult object that contains information about the status of the
asynchronous operation and any other state information. You can pass
user-defined information to the callback in this parameter; the final
argument supplied to the BeginOperationName method is packaged into
this parameter. In this example, the callback is passed a reference to the
MemoryStream.
Although this sequence works, it is a messy paradigm that obscures
the operation you are performing. The code for the operation is split
into two methods, and it is easy to lose the mental connection between
these methods if you have to maintain this code. If you are using Task
objects, you can simplify this model by calling the static FromAsync
method of the TaskFactory class. This method takes the
BeginOperationName and EndOperationName methods and wraps them
into code that is performed by using a Task. There is no need to create
an AsyncCallback delegate because this is generated behind the scenes
by the FromAsync method. So you can perform the same operation
shown in the previous example like this:
Click here to view code image
...
Byte[] buffer = ...;
MemoryStream s = new MemoryStream(); Task t =
Task.Factory.FromAsync(s.Beginwrite, s.EndWrite, buffer, 0,
buffer.Length, null);
t.Start();
await t;
...
This technique is useful if you need to access asynchronous
functionality exposed by types developed in earlier versions of the
.NET Framework.
Download from finelybook PI:EMAIL
848
Using PLINQ to parallelize declarative data access
Data access is another area for which response time is important, especially if
you are building applications that have to search through lengthy data
structures. In earlier chapters, you saw how powerful LINQ is for retrieving
data from an enumerable data structure, but the examples shown were
inherently single-threaded. Parallel LINQ (PLINQ) provides a set of
extensions to LINQ that is based on Tasks, and that can help you boost
performance and parallelize some query operations.
PLINQ works by dividing a data set into partitions and then using tasks to
retrieve the data that matches the criteria specified by the query for each
partition in parallel. When the tasks have completed, the results retrieved for
each partition are combined into a single enumerable result set. PLINQ is
ideal for scenarios that involve data sets with large numbers of elements, or if
the criteria specified for matching data involve complex, computationally
expensive operations.
An important aim of PLINQ is to be as nonintrusive as possible. To
convert a LINQ query into a PLINQ query, you use the AsParallel extension
method. The AsParallel method returns a ParallelQuery object that acts
similarly to the original enumerable object, except that it provides parallel
implementations of many of the LINQ operators, such as join and where.
These implementations of the LINQ operators are based on tasks and use
various algorithms to try to run parts of your LINQ query in parallel
wherever possible. However, as ever in the world of parallel computing, the
AsParallel method is not magic. You cannot guarantee that your code will
speed up; it all depends on the nature of your LINQ queries and whether the
tasks they are performing lend themselves to parallelization.
To understand how PLINQ works and the situations in which it is useful,
it helps to see some examples. The exercises in the following sections
demonstrate a pair of simple scenarios.
Using PLINQ to improve performance while iterating
through a collection
The first scenario is simple. Consider a LINQ query that iterates through a
Download from finelybook PI:EMAIL
849
collection and retrieves elements from the collection based on a processor-
intensive calculation. This form of query can benefit from parallel execution
as long as the calculations are independent. The elements in the collection
can be divided into some partitions; the exact number depends on the current
load of the computer and the number of CPUs available. The elements in
each partition can be processed by a separate thread. When all the partitions
have been processed, the results can be merged. Any collection that supports
access to elements through an index, such as an array or a collection that
implements the IList interface, can be managed in this way.
Parallelize a LINQ query over a simple collection
1. Using Visual Studio 2017, open the PLINQ solution, which is located in
the \Microsoft Press\VCSBS\Chapter 24\PLINQ folder in your
Documents folder.
2. In Solution Explorer, double-click Program.cs in the PLINQ project to
display the file in the Code and Text Editor window.
This is a console application. The skeleton structure of the application
has been created for you. The Program class contains methods named
Test1 and Test2 that illustrate a pair of common scenarios. The Main
method calls each of these test methods in turn.
Both test methods have the same general structure: they create a LINQ
query (you will add the code to do this later in this set of exercises), run
it, and display the time taken. The code for each of these methods is
almost completely separate from the statements that actually create and
run the queries.
3. Examine the Test1 method.
This method creates a large array of integers and populates it with a set
of random numbers between 0 and 200. The random number generator
is seeded, so you should get the same results every time you run the
application.
4. Immediately after the first TO DO comment in this method, add the
LINQ query shown here in bold:
Click here to view code image
Download from finelybook PI:EMAIL
850
// TO DO: Create a LINQ query that retrieves all numbers that
are greater than 100
var over100 = from n in numbers
              where TestIfTrue(n > 100)
              select n;
This LINQ query retrieves all the items in the numbers array that have a
value greater than 100. The test n > 100 is not by itself computationally
intensive enough to show the benefits of parallelizing this query, so the
code calls a method named TestIfTrue, which slows it down a little by
performing a SpinWait operation. The SpinWait method causes the
processor to continually execute a loop of special “no operation”
instructions for a short period, keeping the processor busy but not
actually doing any work. (This is known as spinning.) The TestIfTrue
method looks like this:
Click here to view code image
public static bool TestIfTrue(bool expr)
{
    Thread.SpinWait(100);
    return expr;
}
5. After the second TO DO comment in the Test1 method, add the
following code shown in bold:
Click here to view code image
// TO DO: Run the LINQ query, and save the results in a
List object
List numbersOver100 = new List(over100);
Remember that LINQ queries use deferred execution, so they do not run
until you retrieve the results from them. This statement creates a
List object and populates it with the results of running the over100
query.
6. After the third TO DO comment in the Test1 method, add the following
statement shown in bold:
Click here to view code image
// TO DO: Display the results
Console.WriteLine($"There are {numbersOver100.Count} numbers
over 100");
Download from finelybook PI:EMAIL
851
7. On the Debug menu, click Start Without Debugging. Note the time that
running Test 1 takes and the number of items in the array that are greater
than 100.
8. Run the application several times, and take an average of the time.
Verify that the number of items greater than 100 is the same each time
(the application uses the same random number seed each time it runs to
ensure the repeatability of the tests). Return to Visual Studio when you
have finished.
9. The logic that selects each item returned by the LINQ query is
independent of the selection logic for all the other items, so this query is
an ideal candidate for partitioning. Modify the statement that defines the
LINQ query, and specify the AsParallel extension method to the
numbers array, as shown here in bold:
Click here to view code image
var over100 = from n in numbers.AsParallel()
              where TestIfTrue(n > 100)
              select n;
Note If the selection logic or calculations require access to shared
data, you must synchronize the tasks that run in parallel; otherwise,
the results might be unpredictable. However, synchronization can
impose an overhead and might negate the benefits of parallelizing
the query.
10. On the Debug menu, click Start Without Debugging. Verify that the
number of items reported by Test1 is the same as before but that the time
taken to perform the test has decreased significantly. Run the test several
times, and take an average of the duration required for the test.
If you are running on a dual-core processor (or a twin-processor
computer), you should see the time reduced by 40 to 45 percent. If you
have more processor cores, the decrease should be even more dramatic
(on my quad-core machine, the processing time dropped from 8.3
Download from finelybook PI:EMAIL
852
seconds to 2.4).
11. Close the application, and return to Visual Studio.
The preceding exercise shows the performance improvement you can
attain by making a small change to a LINQ query. However, keep in mind
that you will see results such as this only if the calculations performed by the
query take some time. I cheated a little by spinning the processor. Without
this overhead, the parallel version of the query is actually slower than the
serial version. In the next exercise, you will see a LINQ query that joins two
arrays in memory. This time, the exercise uses more realistic data volumes,
so there is no need to slow down the query artificially.
Parallelize a LINQ query that joins two collections
1. In Solution Explorer, open the Data.cs file in the Code and Text Editor
window and locate the CustomersInMemory class.
This class contains a public string array called Customers. Each string in
the Customers array holds the data for a single customer, with the fields
separated by commas; this format is typical of data that an application
might read in from a text file that uses comma-separated fields. The first
field contains the customer ID, the second field contains the name of the
company that the customer represents, and the remaining fields hold the
address, city, country or region, and postal code.
2. Find the OrdersInMemory class.
This class is similar to the CustomersInMemory class except that it
contains a string array called Orders. The first field in each string is the
order number, the second field is the customer ID, and the third field is
the date that the order was placed.
3. Find the OrderInfo class. This class contains four fields: the customer
ID, company name, order ID, and order date for an order. You will use a
LINQ query to populate a collection of OrderInfo objects from the data
in the Customers and Orders arrays.
4. Display the Program.cs file in the Code and Text Editor window and
locate the Test2 method in the Program class.
Download from finelybook PI:EMAIL
853
In this method, you will create a LINQ query that joins the Customers
and Orders arrays by using the customer ID to return a list of customers
and the orders that each customer has placed. The query will store each
row of the result in an OrderInfo object.
5. In the try block in this method, after the first TO DO comment, add the
code shown next in bold:
Click here to view code image
// TO DO: Create a LINQ query that retrieves customers and
orders from arrays
// Store each row returned in an OrderInfo object
var orderInfoQuery =
    from c in CustomersInMemory.Customers
    join o in OrdersInMemory.Orders
    on c.Split(',')[0] equals o.Split(',')[1]
    select new OrderInfo
    {
        CustomerID = c.Split(',')[0],
        CompanyName = c.Split(',')[1],
        OrderID = Convert.ToInt32(o.Split(',')[0]),
        OrderDate = Convert.ToDateTime(o.Split(',')[2],
            new CultureInfo("en-US"))
    };
This statement defines the LINQ query. Notice that it uses the Split
method of the String class to split each string into an array of strings.
The strings are split on the comma character. (The commas are stripped
out.) One complication is that the dates in the array are held in United
States English format, so the code that converts them into DateTime
objects in the OrderInfo object specifies the United States English
formatter. If you use the default formatter for your locale, the dates
might not parse correctly. All in all, this query performs a significant
amount of work to generate the data for each item.
6. In the Test2 method, after the second TO DO statement, add the
following code shown in bold:
Click here to view code image
// TO DO: Run the LINQ query, and save the results in a
List object
List orderInfo = new List(orderInfoQuery);
This statement runs the query and populates the orderInfo collection.
Download from finelybook PI:EMAIL
854
7. After the third TO DO statement, add the statement shown here in bold:
Click here to view code image
// TO DO: Display the results
Console.WriteLine($"There are {orderInfo.Count} orders");
8. In the Main method, comment out the statement that calls the Test1
method and uncomment the statement that calls the Test2 method, as
shown in the following code in bold:
Click here to view code image
static void Main(string[] args)
{
    // Test1();
    Test2();
}
9. On the Debug menu, click Start Without Debugging.
10. Verify that Test2 retrieves 830 orders, and note the duration of the test.
Run the application several times to obtain an average duration, and then
return to Visual Studio.
11. In the Test2 method, modify the LINQ query and add the AsParallel
extension method to the Customers and Orders arrays, as shown here in
bold:
Click here to view code image
var orderInfoQuery =
    from c in CustomersInMemory.Customers.AsParallel()
    join o in OrdersInMemory.Orders.AsParallel()
    on c.Split(',')[0] equals o.Split(',')[1]
    select new OrderInfo
    {
        CustomerID = c.Split(',')[0],
        CompanyName = c.Split(',')[1],
        OrderID = Convert.ToInt32(o.Split(',')[0]),
        OrderDate = Convert.ToDateTime(o.Split(',')[2],
            new CultureInfo("en-US"))
    };
Download from finelybook PI:EMAIL
855
Warning When you join two data sources in this way, they must
both be IEnumerable objects or ParallelQuery objects. This means
that if you specify the AsParallel method for one source, you
should also specify AsParallel for the other. If you fail to do this,
your code will not run—it will stop with an error.
12. Run the application several times. Notice that the time taken for Test2
should be significantly less than it was previously. PLINQ can make use
of multiple threads to optimize join operations by fetching the data for
each part of the join in parallel.
13. Close the application and return to Visual Studio.
These two simple exercises have shown you the power of the AsParallel
extension method and PLINQ. Note that PLINQ is an evolving technology,
and the internal implementation is very likely to change over time.
Additionally, the volumes of data and the amount of processing you perform
in a query also have a bearing on the effectiveness of using PLINQ.
Therefore, you should not regard these exercises as defining fixed rules that
you should always follow. Rather, they illustrate the point that you should
carefully measure and assess the likely performance or other benefits of using
PLINQ with your own data, in your own environment.
Canceling a PLINQ query
Unlike with ordinary LINQ queries, you can cancel a PLINQ query. To do
this, you specify a CancellationToken object from a
CancellationTokenSource and use the WithCancellation extension method of
the ParallelQuery.
Click here to view code image
CancellationToken tok = ...;
...
var orderInfoQuery =
from c in
    CustomersInMemory.Customers.AsParallel().WithCancellation(tok)
    join o in OrdersInMemory.Orders.AsParallel()
    on ...
Download from finelybook PI:EMAIL
856