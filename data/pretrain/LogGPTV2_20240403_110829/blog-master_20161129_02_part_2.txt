 9478851 cycles # 36.077 M/sec (scaled from 98.24%)   
 6771 instructions # 0.001 IPC (scaled from 98.99%)   
 111114049 branches # 422.908 M/sec (scaled from 99.37%)   
 8495 branch-misses # 0.008 % (scaled from 95.91%)   
 12152161 cache-references # 46.252 M/sec (scaled from 96.16%)   
 7245338 cache-misses # 27.576 M/sec (scaled from 95.49%)   
  0.265238069 seconds time elapsed   
```
上面告诉我们，程序 t1 是一个 CPU bound 型，因为 task-clock-msecs 接近 1。  
对 t1 进行调优应该要找到热点 ( 即最耗时的代码片段 )，再看看是否能够提高热点代码的效率。  
缺省情况下，除了 task-clock-msecs 之外，perf stat 还给出了其他几个最常用的统计信息：  
Task-clock-msecs：CPU 利用率，该值高，说明程序的多数时间花费在 CPU 计算上而非 IO。  
Context-switches：进程切换次数，记录了程序运行过程中发生了多少次进程切换，频繁的进程切换是应该避免的。  
Cache-misses：程序运行过程中总体的 cache 利用情况，如果该值过高，说明程序的 cache 利用不好  
CPU-migrations：表示进程 t1 运行过程中发生了多少次 CPU 迁移，即被调度器从一个 CPU 转移到另外一个 CPU 上运行。  
Cycles：处理器时钟，一条机器指令可能需要多个 cycles，  
Instructions: 机器指令数目。  
IPC：是 Instructions/Cycles 的比值，该值越大越好，说明程序充分利用了处理器的特性。  
Cache-references: cache 命中的次数  
Cache-misses: cache 失效的次数。  
通过指定 -e 选项，您可以改变 perf stat 的缺省事件 ( 关于事件，在上一小节已经说明，可以通过 perf list 来查看 )。假如您已经有很多的调优经验，可能会使用 -e 选项来查看您所感兴趣的特殊的事件。  
### perf Top  
使用 perf stat 的时候，往往您已经有一个调优的目标。比如我刚才写的那个无聊程序 t1。  
也有些时候，您只是发现系统性能无端下降，并不清楚究竟哪个进程成为了贪吃的 hog。  
此时需要一个类似 top 的命令，列出所有值得怀疑的进程，从中找到需要进一步审查的家伙。类似法制节目中办案民警常常做的那样，通过查看监控录像从茫茫人海中找到行为古怪的那些人，而不是到大街上抓住每一个人来审问。  
Perf top 用于实时显示当前系统的性能统计信息。该命令主要用来观察整个系统当前的状态，比如可以通过查看该命令的输出来查看当前系统最耗时的内核函数或某个用户进程。  
让我们再设计一个例子来演示吧。  
不知道您怎么想，反正我觉得做一件有益的事情很难，但做点儿坏事儿却非常容易。我很快就想到了如代码清单 2 所示的一个程序：  
#### 清单 2. 一个死循环  
```
 while (1) i++;  
```
我叫他 t2。启动 t2，然后用 perf top 来观察：  
下面是 perf top 的可能输出：  
```
 PerfTop: 705 irqs/sec kernel:60.4% [1000Hz cycles]   
 --------------------------------------------------   
 sampl pcnt function DSO   
 1503.00 49.2% t2   
 72.00 2.2% pthread_mutex_lock /lib/libpthread-2.12.so   
 68.00 2.1% delay_tsc [kernel.kallsyms]   
 55.00 1.7% aes_dec_blk [aes_i586]   
 55.00 1.7% drm_clflush_pages [drm]   
 52.00 1.6% system_call [kernel.kallsyms]   
 49.00 1.5% __memcpy_ssse3 /lib/libc-2.12.so   
 48.00 1.4% __strstr_ia32 /lib/libc-2.12.so   
 46.00 1.4% unix_poll [kernel.kallsyms]   
 42.00 1.3% __ieee754_pow /lib/libm-2.12.so   
 41.00 1.2% do_select [kernel.kallsyms]   
 40.00 1.2% pixman_rasterize_edges libpixman-1.so.0.18.0   
 37.00 1.1% _raw_spin_lock_irqsave [kernel.kallsyms]   
 36.00 1.1% _int_malloc /lib/libc-2.12.so   
 ^C  
```
很容易便发现 t2 是需要关注的可疑程序。不过其作案手法太简单：肆无忌惮地浪费着 CPU。所以我们不用再做什么其他的事情便可以找到问题所在。但现实生活中，影响性能的程序一般都不会如此愚蠢，所以我们往往还需要使用其他的 perf 工具进一步分析。  
通过添加 -e 选项，您可以列出造成其他事件的 TopN 个进程 / 函数。比如 -e cache-miss，用来看看谁造成的 cache miss 最多。  
### 使用 perf record, 解读 report  
使用 top 和 stat 之后，您可能已经大致有数了。要进一步分析，便需要一些粒度更细的信息。比如说您已经断定目标程序计算量较大，也许是因为有些代码写的不够精简。那么面对长长的代码文件，究竟哪几行代码需要进一步修改呢？这便需要使用 perf record 记录单个函数级别的统计信息，并使用 perf report 来显示统计结果。  
您的调优应该将注意力集中到百分比高的热点代码片段上，假如一段代码只占用整个程序运行时间的 0.1%，即使您将其优化到仅剩一条机器指令，恐怕也只能将整体的程序性能提高 0.1%。俗话说，好钢用在刀刃上，不必我多说了。  
仍以 t1 为例。  
```
 perf record – e cpu-clock ./t1   
 perf report  
```
结果如下图所示：  
#### 图 2. perf report 示例  
![pic](20161129_02_pic_002.jpg)    
不出所料，hot spot 是 longa( ) 函数。  
但，代码是非常复杂难说的，t1 程序中的 foo1() 也是一个潜在的调优对象，为什么要调用 100 次那个无聊的 longa() 函数呢？但我们在上图中无法发现 foo1 和 foo2，更无法了解他们的区别了。  
我曾发现自己写的一个程序居然有近一半的时间花费在 string 类的几个方法上，string 是 C++ 标准，我绝不可能写出比 STL 更好的代码了。因此我只有找到自己程序中过多使用 string 的地方。因此我很需要按照调用关系进行显示的统计信息。  
使用 perf 的 -g 选项便可以得到需要的信息：  
```
 perf record -e cpu-clock -g ./t1   
 perf report  
```
结果如下图所示：  
#### 图 3. perf – g report 示例  
![pic](20161129_02_pic_003.jpg)    
通过对 calling graph 的分析，能很方便地看到 91% 的时间都花费在 foo1() 函数中，因为它调用了 100 次 longa() 函数，因此假如 longa() 是个无法优化的函数，那么程序员就应该考虑优化 foo1，减少对 longa() 的调用次数。  
### 使用 PMU 的例子  
例子 t1 和 t2 都较简单。所谓魔高一尺，道才能高一丈。要想演示 perf 更加强大的能力，我也必须想出一个高明的影响性能的例子，我自己想不出，只好借助于他人。下面这个例子 t3 参考了文章“Branch and Loop Reorganization to Prevent Mispredicts”[6]  
该例子考察程序对奔腾处理器分支预测的利用率，如前所述，分支预测能够显著提高处理器的性能，而分支预测失败则显著降低处理器的性能。首先给出一个存在 BTB 失效的例子：  
#### 清单 3. 存在 BTB 失效的例子程序  
```
 //test.c   
 #include    
 #include    
 void foo()   
 {   
  int i,j;   
  for(i=0; i< 10; i++)   
  j+=2;   
 }   
 int main(void)   
 {   
  int i;   
  for(i = 0; i< 100000000; i++)   
  foo();   
  return 0;   
 }  
```
用 gcc 编译生成测试程序 t3:  
```
 gcc -o t3 -O0 test.c  
```
用 perf stat 考察分支预测的使用情况：  
```
 [lm@ovispoly perf]$ ./perf stat ./t3   
  Performance counter stats for './t3':   
 6240.758394 task-clock-msecs # 0.995 CPUs   
 126 context-switches # 0.000 M/sec   
 12 CPU-migrations # 0.000 M/sec   
 80 page-faults # 0.000 M/sec   
 17683221 cycles # 2.834 M/sec (scaled from 99.78%)   
 10218147 instructions # 0.578 IPC (scaled from 99.83%)   
 2491317951 branches # 399.201 M/sec (scaled from 99.88%)   
 636140932 branch-misses # 25.534 % (scaled from 99.63%)   
 126383570 cache-references # 20.251 M/sec (scaled from 99.68%)   
 942937348 cache-misses # 151.093 M/sec (scaled from 99.58%)   
  6.271917679 seconds time elapsed  
```
可以看到 branche-misses 的情况比较严重，25% 左右。我测试使用的机器的处理器为 Pentium4，其 BTB 的大小为 16。而 test.c 中的循环迭代为 20 次，BTB 溢出，所以处理器的分支预测将不准确。  
对于上面这句话我将简要说明一下，但关于 BTB 的细节，请阅读参考文献 [6]。  
for 循环编译成为 IA 汇编后如下：  
#### 清单 4. 循环的汇编  
```
 // C code   
 for ( i=0; i < 20; i++ )   
 { … }   
 //Assembly code;   
 mov    esi, data   
 mov    ecx, 0   
 ForLoop:   
 cmp    ecx, 20   
 jge      
 EndForLoop   
…  
 add    ecx, 1   
 jmp    ForLoop   