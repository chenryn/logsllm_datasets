title:Binary Control-Flow Trimming
author:Masoud Ghaffarinia and
Kevin W. Hamlen
Masoud Ghaffarinia and Kevin W. Hamlen. “Binary Control-Flow Trimming.” In Proceedings of the 26th
ACM SIGSAC Conference on Computer & Communications Security (CCS), 2019.
Binary Control-Flow Trimming
Masoud Ghaffarinia
The University of Texas at Dallas
PI:EMAIL
ABSTRACT
A new method of automatically reducing the attack surfaces of
binary software is introduced, affording code consumers the power
to remove features that are unwanted or unused in a particular
deployment context. The approach targets stripped binary native
code with no source-derived metadata or symbols, can remove
semantic features irrespective of whether they were intended and/or
known to code developers, and anticipates consumers who can
demonstrate desired features (e.g., via unit testing), but who may
not know the existence of specific unwanted features, and who lack
any formal specifications of the code’s semantics.
Through a combination of runtime tracing, machine learning,
in-lined reference monitoring, and contextual control-flow integrity
enforcement, it is demonstrated that automated code feature re-
moval is nevertheless feasible under these constraints, even for
complex programs such as compilers and servers. The approach
additionally accommodates consumers whose demonstration of de-
sired features is incomplete; a tunable entropy-based metric detects
coverage lapses and conservatively preserves unexercised but prob-
ably desired flows. A prototype implementation for Intel x86-64
exhibits low runtime overhead for trimmed binaries (about 1.87%),
and case studies show that consumer-side control-flow trimming
can successfully eliminate zero-day vulnerabilities.
CCS CONCEPTS
• Security and privacy → Software security engineering.
KEYWORDS
software debloating, control-flow integrity
ACM Reference Format:
Masoud Ghaffarinia and Kevin W. Hamlen. 2019. Binary Control-Flow Trim-
ming. In 2019 ACM SIGSAC Conference on Computer & Communications
Security (CCS’19), November 11–15, 2019, London, United Kingtom. ACM,
New York, NY, USA, 14 pages. https://doi.org/10.1145/3319535.3345665
1 INTRODUCTION
Security of software is widely believed to be inversely related to
its complexity (cf., [83, 93]). With more features, larger implemen-
tations, and more behavioral variety come more opportunities for
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3345665
Kevin W. Hamlen
The University of Texas at Dallas
PI:EMAIL
programmer error, malicious code introduction, and unforeseen
component interactions.
Unfortunately, economic forces have a history of driving com-
plexity increases in commercial software (sometimes dubbed Za-
winski’s law of software envelopment [65]). Software developers
understandably seek to create products that appeal to the widest
possible clientele. This “one-size-fits-all” business model has led to
commercial software products of increasing complexity, as develop-
ers pack more features into each product they release. As a result,
software becomes more multi-purpose and more complex, its attack
surface broadens, and more potential opportunities for malicious
compromise become available to adversaries. For security-sensitive
(e.g., critical infrastructure or military) consumers who leave many
product features unused but critically rely on others, these security
dangers are often unacceptable. Yet because of the market dom-
inance, low cost, and high availability of one-size-fits-all COTS
software, bloated software continues to pervade many mission-
critical software networks despite the security disadvantages.
As a high-profile example of such feature bloat, in 2014 the
bash command interpreter, which is a core component of nearly all
Posix-compliant operating systems, was found to contain a series of
obscure, undocumented features in its parser [81] that afforded at-
tackers near-arbitrary remote code execution capabilities. Though
sometimes referred to as the Shellshock “bug,” the vulnerabilities
were likely intended as features related to function inheritance
when bash was originally written in the 1980s [88]. Their inclusion
in a rarely analyzed part of the code caused them to elude detec-
tion for a quarter century, exposing millions of security-sensitive
systems to potential compromise. This demonstrates that high-
complexity software can contain obscure features that may have
been intended by software developers, but that are unknown to con-
sumers and pose security risks in certain deployment contexts.
Code-reuse attacks [11, 18, 70, 72, 74] are another example of the
inherent security risks that code-bloat can introduce. The potential
potency of these attacks depends on the variety of code fragments
(gadgets) in the victim program’s executable memory [32, 37], which
the attacks abuse to cause damage. Feature-bloated code offers
adversaries a larger code-reuse attack surface to exploit. Control-
flow integrity (CFI) protections [1, 2, 4, 49, 58, 60, 78, 79, 92] de-
fend against such attacks by constraining software to a policy of
control-flow graph (CFG) edges that is defined by the program-
mer [2, 79] (e.g., derived from the semantics of the programmer-
defined source code, or a recovery of those semantics from the
program binary). They therefore do not learn or enforce policies
that defend against undocumented feature vulnerabilities like Shell-
shock, whose control-flows are sanctioned by the source semantics
and are therefore admitted by CFI controls.
To demonstrate the openness of this problem, we tested the
ability of the 11 source-free CFI solutions listed in Table 1 to auto-
matically mitigate the vulnerabilities listed in Table 2, which each
Table 1: False negative rates of source-free CFI solutions when applied to perform code-debloating
false negatives
C-Flat PathArmor TypeArmor Lockdown BinCC O-CFI bin-CFI CCFIR MoCFI NaCl XFI
100%
100% 100% 100%
100% 100%
100%
100%
100%
100%
100%
CVE numbers
CVE-2014-6271, -6277, -6278, -7169
Table 2: CVEs of security-evaluated products
Program
Bash
ImageMagic CVE-2016-3714, -3715, -3716, -3717, -3718
Proftpd
Node.js
Exim
CVE-2015-3306
CVE-2017-5941
CVE-2016-1531
constitute an insecure (but possibly developer-intended) functional-
ity, such as Shellshock or ImageTragick (see §5 for details) that was
later patched once it became known to consumers. Each algorithm
was applied to secure all the binaries against control-flow abuse
attacks. All CFI-protected binaries nevertheless remain susceptible
to abuse of all the CVEs—a 100% false negative rate. These solu-
tions fail because they were designed to infer and enforce policies
that whitelist developer-intended control-flows, not automatically
de-bloat hidden features.
To address this unsolved problem, our research introduces bi-
nary control-flow trimming, a new technology for automatically
specializing binary software products to exclude semantic features
undesired by consumers, irrespective of whether the features are
intended or even known to developers, or whether they are part of a
product’s source-level design. Control-flow trimming is envisioned
as an extra layer of consumer-side defense (i.e., CFG policy tighten-
ing) that identifies and excises unwanted software functionalities
and gadgets that are beyond the reach of CFI alone.
Learning consumer-unwanted but developer-intended function-
alities cannot be achieved with purely non-probabilistic CFG re-
covery algorithms, such as those central to CFI, because such al-
gorithms approximate a ground truth policy that is is a strict su-
pergraph of the policy needed for feature removal. Tightening that
supergraph based on incomplete, consumer-supplied tests requires
coupling CFI with trace-based machine-learning. The resulting pol-
icy is a more complex, probabilistically constructed, contextual CFG
(CCFG), which considers fine-grained branch history to distinguish
consumer-wanted flows from a sea of developer-intended flows. No
prior CFI approach can enforce policies of this complexity because
their sensitivity is presently limited to only a few code features
(e.g., system API calls [61]), they rely on machine registers or OS
modifications unavailable to user code [20, 79], or they require
source code access [49] which is often unavailable to consumers.
To enforce these policies, we therefore introduce a new contextual
CFI enforcement strategy that efficiently encodes contexts as hash
codes safely maintainable in user-level machine registers.
In addition, our work assumes that consumers who lack source
code probably have no way of formally specifying semantic features
or control-flows that they wish to retain, and might not even be
aware of all features whose disuse make them candidates for trim-
ming. We therefore assume that consumers merely demonstrate
desired software features via unit tests (e.g., inputs or user inter-
actions that test behaviors for quality assurance purposes). Such
testing is inevitably incomplete and inexhaustive for programs
whose input spaces are large (often infinite); so in order to tolerate
this incompleteness, we introduce an entropy-based method of de-
tecting points of uncertainty in CCFGs derived from unit tests, and
a strategy for relaxing enforcement at such points. Consumers can
strengthen the enforcement by supplying additional unit tests that
exercise these points more thoroughly.
In summary, we contribute the following:
• We present a method to reduce the size and complexity of
binary software by removing functionalities unwanted by
code-consumers (but possibly intended by code-producers)
without any reliance on source code or debug metadata.
• We present a new binary-only context-sensitive control-flow
graph (CCFG) integrity policy formalism derivable from ex-
ecution traces.
• We propose a machine learning approach to construct CCFGs
from runtime trace sets, and demonstrate that it is accurate
enough to exhibit a 0% false positive rate for complicated
programs such as compilers and web servers.
• We showcase a fully functional prototype that automatically
instruments native code with an in-lined reference monitor
(IRM) [68] that enforces the CCFG policy.
• Experiments show that control-flow trimming can eliminate
zero-day vulnerabilities associated with removed functional-
ities, and that the approach exhibits low runtime overheads
of about 1.87%.
Section 2 first gives a high level overview of our system. Sec-
tions 3 and 4 next detail our technical approaches to feature iden-
tification and policy enforcement for Intel x86-64 native codes,
respectively. Section 5 evaluates the approach in terms of accuracy
and performance, followed by a discussion of limitations and future
work in Section 6. Finally, Section 7 compares our work with related
research, and Section 8 concludes.
2 APPROACH OVERVIEW
2.1 Contextual Control-flow Graph Policies
Our approach assumes that feature-trimming specifications are in-
formal, taking the form of unit tests that exercise only the consumer-
desired features of the software. Such testing is commonly practiced
by security-sensitive consumers. One obvious approach to trim-
ming unwanted features entails simply erasing all code bytes that
remain unexecuted by the tests. However, our early experimenta-
tion taught us that this blunt approach fails for at least two reasons:
(1) It requires an unrealistically comprehensive unit test set, lest
some code bytes associated with wanted features go unexercised
and get improperly erased. Such comprehensive testing is very dif-
ficult to achieve without source code. (2) It often retains unwanted
features due to the modular design of complex software, which
reuses each individual code block to implement multiple semantic
features—some wanted and some unwanted. When all code blocks
for an unwanted feature are each needed by some wanted feature,
the unwanted feature cannot be trimmed via code byte erasure
without corrupting the wanted features.
These experiences led us to adopt the more general approach
of control-flow trimming. Control-flow trimming removes seman-
tic features by making the control-flow paths that implement the
feature unreachable—e.g., by instrumenting all computed jump in-
structions in the program with logic that prohibits that flow. This
generalizes the code byte erasure approach because, in the special
case that the trimmed CFG contains no edges at all to a particular
code block, that block can be erased entirely.
We also discovered that control-flow policies that successfully
distinguish consumer-undesired (yet developer-intended) code fea-
tures from consumer-desired features tend to be significantly more
complex and powerful than any prior CFI solution can efficiently
enforce. In particular, policy decisions must be highly context-
sensitive, considering a detailed history of prior CFG edges tra-
versed by the program in addition to the next branch target when
deciding whether to permit an impending control transfer. Since
trace histories of real-world programs are large (e.g., unbounded),
these decisions must be implemented in a highly efficient manner
to avoid unreasonable performance penalties for the defense.
To illustrate, assume critical functionality F1 executes code blocks
c1; c2; c3; c4 in order, whereas undesired functionality F2 executes
c1; c3; c3; c4. A strict code byte erasure approach cannot safely re-
move any blocks in this case, since all are needed by F1. However,
control-flow trimming can potentially delete CFG edges (c1, c3) and
(c3, c3) to make functionality F2 unrealizable without affecting F1.
Extending the example to include context-sensitivity, consider
an additional critical functionality F3 implemented by sequence
c2; c3; c3; c1; c3; c4. This prevents removal of edges(c1, c3) and(c3, c3)
from the CFG, since doing so would break F3. But an enforcement
that permits edge (c3, c3) conditional on it being immediately pre-
ceded by edge (c2, c3) successfully removes F2 without harming F3.
In general, extending the context to consider the last n edges tra-
versed lends the technique greater precision as n increases, though
typically at the cost of higher space and time overheads. A balance
between precision and performance is therefore needed for best
results, which we explore in §5.
2.2 Automated, In-lined CCFG Enforcement
Figure 1 depicts our control-flow trimming architecture. The in-
put to our system consists of stripped x86-64 binaries along with
sample execution traces that exercise functionalities wanted by the
consumer. The rewriter automatically disassembles, analyzes, and
transforms them into a new binary whose control-flows are con-
strained to those exhibited by the traces, possibly along with some
additional flows that could not be safely trimmed due to uncertainty
in the trace set or due to performance limitations. We assume that
no source code, debug symbols, or other source-derived metadata
are provided. Prior work on reassemblable disassembly [86] has es-
tablished the feasibility of recovering (raw, unannotated) assembly
original binary
test suite
traces
conservative
disassembler
IRM rewriter
trimming
policy (CCFG)
policy learner
trimmed
binary
Figure 1: Binary control-flow trimming system architecture
files from binaries for easier code transformation, allowing us to
use assembly files as input to our prototype during evaluations (§5).
Discerning a consumer-desired CCFG policy based on traces
without access to sources is challenging. Our approach applies
machine learning to traces generated from the test suite to learn a
subgraph of the developer-intended flows. The output of this step
is a decision tree forest, with one tree for each control-flow transfer
point in the disassembled program. Each decision tree consults
the history of immediately previous branch destinations, along
with the impending branch target, to decide whether to permit the
impending branch. The forest therefore defines a CCFG policy.
Since decision trees tend to overfit the training, it is important
to detect overfitting and relax the policy to permit traces that were
not exhibited during training, but whose removal might break
consumer-desired functionalities. We therefore assign an entropy-
based confidence score to each node of the decision forest. Nodes
with unacceptable confidence receive relaxed enforcement by prun-
ing their children from the tree. In the extreme case, pruning all trees
to a height of 1 results in a non-contextual CFG that matches the
policy enforced by most non-contextual (backward- and forward-
edge) CFI. Trimming therefore always enforces a policy that is at
least as strict as non-contextual CFI, and usually stricter.
After deriving a suitable CCFG, the policy is enforced via in-lined
reference monitoring. Specifically, we surround each control-flow
transfer instruction in the program with guard code that maintains
and updates a truncated history of branch targets expressed as a
hash code. A read-only hash table determines whether the impend-
ing branch is permitted. Policy-violating branches yield a security
violation warning and premature termination of the program.
2.3 Threat Model
Like prior research on CFI and artificial diversity, success of our
approach can be measured in terms of two independent criteria: (1)
inference of an accurate policy to enforce, and (2) enforcement of
the inferred policy. For example, COOP attacks [69] exploit lapses
in the first criterion; they hijack software by traversing only edges
permitted by the policy, which is insufficiently precise. In con-
trast, coarse-grained CFI approaches are susceptible to lapses in
the second criterion; to achieve high performance, they enforce
a policy approximation, which sometimes allows attackers to ex-
ploit approximation errors to hijack the code (e.g., [17]). Artificial
diversity defenses can experience similar failures, as in the case of
implementation disclosure attacks [10, 24, 31, 71, 73].
With regard to the first criterion, our approach is probabilistic,
so success is evaluated empirically in §5 in terms of false negatives
and false positives. (The false classification rates measure accu-
racy against a policy that differs from CFI policies, however, since
control-flow trimming has a stricter model of ground truth than
CFI, as described in §1.) With regard to the second criterion, we
assume a relatively strong threat model in which attackers have
complete read-access to the program image as it executes, and even
have write-access to all writable data pages, but lack the power
to directly change page access permissions. Thus, attackers know
the policy being enforced but lack the ability to change it since
its runtime encoding resides in read-only memory. (We assume
that DEP or WX protections prevent writes to code and static
data sections.) Attackers also cannot directly corrupt CPU machine
registers, affording our defense a safe place to store security state.
Since our defense enforces a control-flow policy, non-control
data attacks are out of scope for this work. We defer mitigations of
such attacks to other defense layers.
3 DETAILED DESIGN
3.1 Learning CCFG Policies
Since it is usually easier for code-consumers to exhibit all features
they wish to preserve (e.g., through software quality testing), rather
than discovering those they wish to remove, we adopt a whitelisting
approach when learning consumer control-flow policies:
A trace e1, e2, e3, . . . is defined as the sequence of control-flow
edge traversals during one run of the program, where ei is the
ith edge taken. We include in the edge set all binary control-flow
transfers except for unconditional branches and fall-throughs of
non-branching instructions (whose destinations are fixed and there-