# Title: Binary Control-Flow Trimming
## Authors: Masoud Ghaffarinia and Kevin W. Hamlen

### Citation
Masoud Ghaffarinia and Kevin W. Hamlen. “Binary Control-Flow Trimming.” In Proceedings of the 26th ACM SIGSAC Conference on Computer & Communications Security (CCS), 2019.

## Abstract
This paper introduces a novel method for automatically reducing the attack surfaces of binary software, enabling code consumers to remove unwanted or unused features in specific deployment contexts. The approach targets stripped binary native code without source-derived metadata or symbols, and can eliminate semantic features regardless of whether they were intended or known by the developers. It is designed for consumers who can demonstrate desired features (e.g., via unit testing) but may be unaware of specific unwanted features and lack formal specifications of the code's semantics.

By combining runtime tracing, machine learning, in-lined reference monitoring, and contextual control-flow integrity enforcement, we show that automated feature removal is feasible even for complex programs such as compilers and servers. The method also accommodates incomplete demonstrations of desired features, using an entropy-based metric to detect coverage lapses and conservatively preserve unexercised but likely desired flows. A prototype implementation for Intel x86-64 demonstrates low runtime overhead for trimmed binaries (approximately 1.87%), and case studies show that consumer-side control-flow trimming can successfully eliminate zero-day vulnerabilities.

### CCS Concepts
- Security and privacy → Software security engineering

### Keywords
- Software debloating
- Control-flow integrity

### ACM Reference Format
Masoud Ghaffarinia and Kevin W. Hamlen. 2019. Binary Control-Flow Trimming. In 2019 ACM SIGSAC Conference on Computer & Communications Security (CCS’19), November 11–15, 2019, London, United Kingdom. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3319535.3345665

## 1 Introduction
The security of software is often inversely related to its complexity. As software grows in features, implementation size, and behavioral variety, it provides more opportunities for programmer errors, malicious code introduction, and unforeseen component interactions.

Economic forces have historically driven the increase in complexity in commercial software, often referred to as Zawinski’s law of software envelopment [65]. Developers aim to create products that appeal to the broadest possible audience, leading to increasingly complex and multi-purpose software. This expansion of the attack surface is particularly problematic for security-sensitive consumers, such as those in critical infrastructure or military contexts, who rely on specific features while leaving many others unused.

A high-profile example of this issue is the bash command interpreter, which was found in 2014 to contain undocumented features in its parser [81] that allowed attackers near-arbitrary remote code execution capabilities. These features, likely intended for function inheritance when bash was written in the 1980s [88], remained undetected for decades, exposing millions of security-sensitive systems to potential compromise.

Code-reuse attacks [11, 18, 70, 72, 74] are another example of the security risks introduced by code bloat. These attacks exploit the variety of code fragments (gadgets) in the victim program's executable memory [32, 37]. Control-flow integrity (CFI) protections [1, 2, 4, 49, 58, 60, 78, 79, 92] defend against such attacks by constraining the program to a policy of control-flow graph (CFG) edges defined by the programmer. However, CFI does not address undocumented feature vulnerabilities, as these control-flows are sanctioned by the source semantics and thus admitted by CFI controls.

To illustrate the problem, we tested the ability of 11 source-free CFI solutions listed in Table 1 to automatically mitigate the vulnerabilities listed in Table 2, which include CVE-2014-6271, -6277, -6278, -7169, and others. Each algorithm was applied to secure all the binaries against control-flow abuse attacks. All CFI-protected binaries remained susceptible to abuse of all the CVEs, resulting in a 100% false negative rate. These solutions fail because they are designed to infer and enforce policies that whitelist developer-intended control-flows, not to de-bloat hidden features.

### Contributions
- We present a method to reduce the size and complexity of binary software by removing functionalities unwanted by code-consumers (but possibly intended by code-producers) without relying on source code or debug metadata.
- We introduce a new binary-only context-sensitive control-flow graph (CCFG) integrity policy formalism derivable from execution traces.
- We propose a machine learning approach to construct CCFGs from runtime trace sets, demonstrating a 0% false positive rate for complex programs such as compilers and web servers.
- We showcase a fully functional prototype that automatically instruments native code with an in-lined reference monitor (IRM) [68] to enforce the CCFG policy.
- Experiments show that control-flow trimming can eliminate zero-day vulnerabilities associated with removed functionalities, with low runtime overheads of about 1.87%.

## 2 Approach Overview
### 2.1 Contextual Control-Flow Graph Policies
Our approach assumes that feature-trimming specifications are informal, taking the form of unit tests that exercise only the consumer-desired features of the software. Such testing is common among security-sensitive consumers. A simple approach to trimming unwanted features would be to erase all code bytes that remain unexecuted by the tests. However, this blunt approach fails for two reasons:
1. It requires an unrealistically comprehensive unit test set, which is difficult to achieve without source code.
2. It often retains unwanted features due to the modular design of complex software, where individual code blocks implement multiple semantic features—some wanted and some unwanted.

Instead, we adopt a more general approach of control-flow trimming. This method removes semantic features by making the control-flow paths that implement the feature unreachable, e.g., by instrumenting all computed jump instructions in the program with logic that prohibits that flow. This generalizes the code byte erasure approach, as in the special case where the trimmed CFG contains no edges to a particular code block, that block can be erased entirely.

We discovered that control-flow policies that distinguish consumer-undesired (yet developer-intended) code features from consumer-desired features tend to be significantly more complex than any prior CFI solution can efficiently enforce. Policy decisions must be highly context-sensitive, considering a detailed history of prior CFG edges traversed by the program in addition to the next branch target. Since trace histories of real-world programs are large, these decisions must be implemented efficiently to avoid performance penalties.

### 2.2 Automated, In-Lined CCFG Enforcement
Figure 1 depicts our control-flow trimming architecture. The input to our system consists of stripped x86-64 binaries along with sample execution traces that exercise functionalities wanted by the consumer. The rewriter automatically disassembles, analyzes, and transforms them into a new binary whose control-flows are constrained to those exhibited by the traces, possibly along with some additional flows that could not be safely trimmed due to uncertainty in the trace set or performance limitations. We assume no source code, debug symbols, or other source-derived metadata are provided.

Discerning a consumer-desired CCFG policy based on traces without access to sources is challenging. Our approach applies machine learning to traces generated from the test suite to learn a subgraph of the developer-intended flows. The output of this step is a decision tree forest, with one tree for each control-flow transfer point in the disassembled program. Each decision tree consults the history of immediately previous branch destinations, along with the impending branch target, to decide whether to permit the impending branch. The forest defines a CCFG policy.

Since decision trees tend to overfit the training, it is important to detect overfitting and relax the policy to permit traces not exhibited during training but whose removal might break consumer-desired functionalities. We assign an entropy-based confidence score to each node of the decision forest. Nodes with unacceptable confidence receive relaxed enforcement by pruning their children from the tree. In the extreme case, pruning all trees to a height of 1 results in a non-contextual CFG that matches the policy enforced by most non-contextual (backward- and forward-edge) CFI. Trimming always enforces a policy at least as strict as non-contextual CFI, and usually stricter.

After deriving a suitable CCFG, the policy is enforced via in-lined reference monitoring. Specifically, we surround each control-flow transfer instruction in the program with guard code that maintains and updates a truncated history of branch targets expressed as a hash code. A read-only hash table determines whether the impending branch is permitted. Policy-violating branches yield a security violation warning and premature termination of the program.

### 2.3 Threat Model
Success of our approach can be measured in terms of two independent criteria: (1) inference of an accurate policy to enforce, and (2) enforcement of the inferred policy. COOP attacks [69] exploit lapses in the first criterion, hijacking software by traversing only edges permitted by the policy, which is insufficiently precise. Coarse-grained CFI approaches are susceptible to lapses in the second criterion, enforcing a policy approximation that sometimes allows attackers to exploit approximation errors to hijack the code (e.g., [17]).

With regard to the first criterion, our approach is probabilistic, so success is evaluated empirically in terms of false negatives and false positives. With regard to the second criterion, we assume a strong threat model where attackers have complete read-access to the program image as it executes and write-access to all writable data pages, but lack the power to directly change page access permissions. Attackers know the policy being enforced but cannot change it since its runtime encoding resides in read-only memory. Non-control data attacks are out of scope for this work, and mitigations for such attacks are deferred to other defense layers.

## 3 Detailed Design
### 3.1 Learning CCFG Policies
Since it is usually easier for code-consumers to exhibit all features they wish to preserve (e.g., through software quality testing) rather than discovering those they wish to remove, we adopt a whitelisting approach when learning consumer control-flow policies:

A trace \( e_1, e_2, e_3, \ldots \) is defined as the sequence of control-flow edge traversals during one run of the program, where \( e_i \) is the \( i \)-th edge taken. We include in the edge set all binary control-flow transfers except for unconditional branches and fall-throughs of non-branching instructions, whose destinations are fixed.