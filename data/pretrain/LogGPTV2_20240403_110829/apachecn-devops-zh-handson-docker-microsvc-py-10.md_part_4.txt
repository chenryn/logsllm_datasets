Be pragmatic, though. Sometimes, errors can't be fixed straight away and time is best utilized in other tasks. However, teams should reserve time to reduce the number of errors that occur. Failing to do so will compromise the reliability of the system in the medium term.
`WARNING`日志表明，某些事情可能没有我们预期的那么顺利，但除非数字增长，否则没有必要恐慌。`INFO`只是在那里给我们上下文如果有问题，但否则应该被忽略。
Avoid the temptation to produce an `ERROR` log when there's a request returning a 400 BAD REQUEST status code. Some developers will argue that if the customer sent a malformed request, it is actually an error. But this isn't something that you should care about if the request has been properly detected and returned. This is business as usual. If this behavior can lead to indicate something else, such as repeated attempts to send incorrect passwords, you can set a `WARNING` log. There's no point in generating `ERROR` logs when your system is behaving as expected.
As a rule of thumb, if a request is not returning some sort of 500 error (500, 502, 504, and so on), it should not generate an `ERROR` log. Remember the categorization of 400 errors as *you (customer) have a problem* versus 500 errors, which are categorized as *I have a problem*.
This is not absolute, though. For example, a spike in authentication errors that are normally 4XX errors may indicate that users cannot create logs due to a real internal problem.
考虑到这些定义，您的开发和运营团队将有一个共同的理解，这将有助于他们采取有意义的行动。
随着系统的成熟，期望调整系统并更改一些日志级别。
# 开发时添加日志
正如我们已经看到的，正确配置`pytest`会使测试中的任何错误显示捕获的日志。
这是一个检查功能开发过程中是否生成了预期日志的机会。任何检查错误条件的测试都应该添加相应的日志，并检查它们是否是在特性开发期间生成的。
You can check the logs as part of testing with a tool such as `pytest-catchlog` ([https://pypi.org/project/pytest-catchlog/](https://pypi.org/project/pytest-catchlog/)) to enforce that the proper logs are being produced.
Typically, though, just taking a bit of care and checking during development that logs are produced is enough for most cases. However, be sure that developers understand why it's useful to have logs while they're developing.
在开发过程中，`DEBUG`日志可以用来显示额外的流量信息，这些信息对于生产来说太多了。这可能会填补`INFO`日志之间的空白，帮助我们养成添加日志的习惯。如果在测试过程中发现`DEBUG`日志有助于跟踪生产中的问题，则该日志可能会升级到`INFO`。
潜在地，`DEBUG`日志可以在受控情况下在生产中启用，以跟踪一些困难的问题，但是要注意拥有大量日志的影响。
Be sensible with the information that's presented in `INFO` logs. In terms of the information that's displayed, avoid sensible data such as passwords, secret keys, credit card numbers, or personal information. This is the same for the number of logs.
Keep an eye on any size limitations and how quickly logs are being generated. Growing systems may have a log explosion while new features are being added, more requests are flowing through the system, and new workers are being added.
此外，请仔细检查日志是否正确生成和捕获，以及它们是否在所有不同的级别和环境下工作。所有这些配置可能需要一点时间，但是您需要非常确定您可以捕获生产中的意外错误，并且所有管道都设置正确。
让我们来看看可观察性的另一个关键要素:度量。
# 设置指标
为了用普罗米修斯建立度量标准，我们需要了解这个过程是如何工作的。它的关键组成部分是，每个被测量的服务都有自己的 Prometheus 客户端来跟踪度量。普罗米修斯服务器中的数据将可用于 Grafana 服务，该服务将绘制指标。
下图显示了一般体系结构:
![](img/5b14900d-d4cd-4768-a10b-7a918425d553.png)
普罗米修斯服务器定期提取信息。这种操作方法非常轻量级，因为注册度量只会更新服务的本地内存，并且伸缩性很好。另一方面，它显示特定时间的采样数据，并且不记录每个单独的事件。这对存储和表示数据有一定的影响，并且对数据的分辨率有限制，特别是对于非常低的速率。
There are lots of available metrics exporters that will expose standard metrics in different systems, such as databases, hardware, HTTP servers, or storage. Check out the Prometheus documentation for more information: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/).
这意味着我们的每个服务都需要安装一个 Prometheus 客户端，并以某种方式公开其收集的指标。我们将使用 Flask 和 Django 的标准客户。
# 为思想后端定义度量标准
对于烧瓶应用，我们将使用`prometheus-flask-exporter`包([https://github.com/rycus86/prometheus_flask_exporter](https://github.com/rycus86/prometheus_flask_exporter)，该包已添加到`requirements.txt`。
在创建应用时，它会在`app.py`文件中被激活。
`metrics`对象在没有 app 的情况下设置，然后在`created_app`功能中实例化:
```
from prometheus_flask_exporter import PrometheusMetrics
metrics = PrometheusMetrics(app=None)
def create_app(script=False):
    ...
    # Initialise metrics
    metrics.init_app(application)
```
这会在`/metrics`服务端点中生成一个端点，即`http://thoughts.example.local/metrics`，该端点以普罗米修斯格式返回数据。普罗米修斯格式是纯文本，如下图所示:
![](img/81ba132d-890c-4b57-96db-46bbfca38f44.png)
由`prometheus-flask-exporter`捕获的默认度量是基于端点和方法(`flask_http_request_total`)的请求调用，以及它们花费的时间(`flask_http_request_duration_seconds`)。
# 添加自定义指标
当涉及到应用细节时，我们可能希望添加更具体的指标。我们还在请求的末尾添加了一些额外的代码，这样我们就可以存储类似于`prometheus-flask-exporter`允许我们存储的度量的信息。
特别是，我们使用较低级别的`prometheus_client`将这段代码添加到了`logging_after`函数([https://github . com/packt publishing/hand-On-Docker-for-microservice-with-Python/blob/master/chapter 10/microservice/thinks _ back/thinks _ back/app . py # L72](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py#L72))中。
该代码创建`Counter`和`Histogram`:
```
from prometheus_client import Histogram, Counter
METRIC_REQUESTS = Counter('requests', 'Requests',
                          ['endpoint', 'method', 'status_code'])
METRIC_REQ_TIME = Histogram('req_time', 'Req time in ms',
                            ['endpoint', 'method', 'status_code']) 
def logging_after(response):
    ...
    # Store metrics
    endpoint = request.endpoint
    method = request.method.lower()
    status_code = response.status_code
    METRIC_REQUESTS.labels(endpoint, method, status_code).inc()
    METRIC_REQ_TIME.labels(endpoint, method, status_code).observe(time_in_ms)
```
在这里，我们创建了两个度量:一个叫做`requests`的计数器和一个叫做`req_time`的直方图。直方图是具有特定值的度量和事件的普罗米修斯实现，例如请求时间(在我们的例子中)。
The histogram stores the values in buckets, thereby making it possible for us to calculate quantiles. Quantiles are very useful to determine metrics such as the 95% value for times, such as the aggregate time, where 95% comes lower than it. This is much more useful than averages since outliers won't pull from the average.
There's another similar metric called summary. The differences are subtle, but generally, the metric we should use is a histogram. Check out the Prometheus documentation for more details ([https://prometheus.io/docs/practices/histograms/](https://prometheus.io/docs/practices/histograms/)).
度量在`METRIC_REQUESTS`和`METRIC_REQ_TIME`中通过它们的名称、度量和它们定义的标签来定义。每个标签都是度量的一个额外维度，因此您可以根据它们进行筛选和聚合。在这里，我们定义了端点、HTTP 方法和产生的 HTTP 状态代码。
对于每个请求，都会更新度量。我们需要设置标签，计数器调用，即`.inc()`，直方图调用，即`.observe(time)`。
You can find the documentation for the Prometheus client at [https://github.com/prometheus/client_python](https://github.com/prometheus/client_python).
我们可以在度量页面上看到`request`和`req_time`度量。
**Setting up metrics for the Users Backend follows a similar pattern.** The Users Backend is a similar Flask application, so we install `prometheus-flask-exporter` as well, but no custom metrics. You can access these metrics at `http://users.example.local/metrics`.
下一个阶段是建立一个普罗米修斯服务器，这样我们就可以收集指标并适当地聚合它们。
# 收集指标
为此，我们需要使用 Kubernetes 部署度量。我们准备了一份 YAML 文件，所有内容都已经在`Chapter10/kubernetes/prometheus.yaml`文件中设置好了。
这个 YAML 文件包含一个部署，`ConfigMap`，它包含配置文件、服务和入口。服务和入口都很标准，所以我们在这里不做评论。
`ConfigMap`允许我们定义一个文件:
```
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: example
data:
  prometheus.yaml: |
    scrape_configs:
    - job_name: 'example'
      static_configs:
        - targets: ['thoughts-service', 'users-service', 
                    'frontend-service']
```
注意`|`符号后`prometheus.yaml`文件是如何生成的。这是从`thoughts-service`、`users-service`和`frontend-service`服务器上抓取的最小普罗米修斯配置。正如我们在前面章节中所知道的，这些名称访问服务并将连接到为应用服务的 pods。他们会自动搜索`/metrics`路径。
There is a small caveat here. From the point of view of Prometheus, everything behind the service is the same server. If you have more than one pod being served, the metrics that are being accessed by Prometheus will be load balanced and the metrics won't be correct.
This is fixable with a more complicated Prometheus setup whereby we install the Prometheus operator, but this is out of the scope of this book. However, this is highly recommended for a production system. In essence, it allows us to annotate each of the different deployments so that the Prometheus configuration is dynamically changed. This means we can access all the metrics endpoints exposed by the pods automatically once this has been set up. Prometheus Operator annotations make it very easy for us to add new elements to the metrics system.
Check out the following article if you want to learn how to do this: [https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3](https://sysdig.com/blog/kubernetes-monitoring-prometheus-operator-part3).
该部署从`prom/prometheus`中的公共普罗米修斯映像创建一个容器，如以下代码所示:
```
spec:
  containers:
  - name: prometheus
    image: prom/prometheus
    volumeMounts:
    - mountPath: /etc/prometheus/prometheus.yml
      subPath: prometheus.yaml
      name: volume-config
    ports:
    - containerPort: 9090
    volumes:
    - name: volume-config
      configMap:
        name: prometheus-config
```
它还将`ConfigMap`挂载为一个卷，然后在`/etc/prometheus/prometheus.yml`中挂载为一个文件。这将使用该配置启动普罗米修斯服务器。容器打开港口`9090`，这是普罗米修斯的默认港口。
At this point, note how we delegated for the Prometheus container. This is one of the advantages of using Kubernetes: we can use standard available containers to add features to our cluster with minimal configuration. We don't even have to worry about the operating system or the packaging of the Prometheus container. This simplifies operations and allows us to standardize the tools we use.
部署的普罗米修斯服务器可以在`http://prometheus.example.local/`访问，如入口和服务中所述。
这将显示一个可用于绘制图形的图形界面，如下图所示:
![](img/98c116d8-05e9-461b-b13b-d8a24a240609.png)
表达式搜索框还将自动完成指标，有助于发现过程。
该界面还显示普罗米修斯公司其他有趣的元素，例如目标的配置或状态:
![](img/4a164941-5d6b-4364-903e-5123751f6476.png)
这个界面中的图形是可用的，但是我们可以通过 Grafana 设置更复杂更有用的仪表盘。让我们看看这个设置是如何工作的。
# 绘制图表和仪表板
所需的 Kubernetes 配置`grafana.yaml`可在本书的 GitHub 存储库中的`Chapter10/kubernetes/metrics`目录中找到。就像我们使用普罗米修斯一样，我们使用一个文件来配置格拉夫纳。
出于我们之前解释的相同原因，我们不会显示入口和服务。部署很简单，但是我们安装了两个卷而不是一个卷，如以下代码所示:
```
spec:
  containers:
    - name: grafana
      image: grafana/grafana
      volumeMounts:
        - mountPath: /etc/grafana/provisioning
                     /datasources/prometheus.yaml
          subPath: prometheus.yaml
          name: volume-config
        - mountPath: /etc/grafana/provisioning/dashboards
          name: volume-dashboard
      ports:
        - containerPort: 3000
  volumes:
    - name: volume-config