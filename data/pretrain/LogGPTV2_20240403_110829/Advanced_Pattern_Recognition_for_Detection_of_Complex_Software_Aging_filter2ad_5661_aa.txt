title:Advanced Pattern Recognition for Detection of Complex Software Aging
Phenomena in Online Transaction Processing Servers
author:Karen J. Cassidy and
Kenny C. Gross and
Amir Malekpour
Advanced Pattern Recognition for Detection of Complex Software  
Aging Phenomena in Online Transaction Processing Servers 
Karen J. Cassidy1, Kenny C. Gross2 and Amir Malekpour3 
1SmartSignal Corporation, 2,3Sun Microsystems 
PI:EMAIL, PI:EMAIL, PI:EMAIL 
Abstract 
  Conventional  approaches 
Software aging phenomena have been recently studied; 
one  particularly  complex  type  is  shared  memory  pool 
latch contention in large OLTP servers.  Latch contention 
onset  leads  to  severe  performance  degradation  until  a 
manual rejuvenation of the DBMS shared memory pool is 
triggered. 
to  automated 
rejuvenation have failed for latch contention because no 
single  resource  metric  has  been  identified  that  can  be 
monitored to alert the onset of this complex mechanism.  
The  current  investigation  explores  the  feasibility  of 
applying an advanced pattern recognition method that is 
embodied 
in  a  commercially  available  equipment 
condition  monitoring  system  (SmartSignal  eCM(cid:153))  for 
proactive  annunciation  of  software-aging  faults.  One 
hundred data  signals  are  monitored  from  a  large  OLTP 
server,  collected  at  20-60  sec.  intervals  over  a  5-month 
period.    Results  show  13  variables  consistently  deviate 
from  normal  operation  prior  to  a  latch  event,  providing 
up to 2 hours early warning. 
1. Introduction 
As  business  becomes 
increasingly  dependent  on 
information  and  computing 
technology,  continuous 
availability is a universal concern.  Application downtime 
for enterprise servers at  eCommerce businesses can range 
from  $4,000  per  second  for  online  retailers 
like 
Amazon.com,  to  $108,000  per  second  for  Wall  Street 
brokerage firms [1].  Recent studies [2, 3, 4] have shown 
that one source of application and system unavailability is 
software aging.  Software aging is a phenomenon, usually 
caused by resource contention, that can cause eCommerce 
servers  to  hang,  panic,  or  crash. 
  Software  aging 
mechanisms  include  memory  bloating/leaks,  unreleased 
file locks, accumulation of unterminated threads, shared-
memory-pool latching, data corruption/round off accrual, 
file-space  fragmentation, 
thread  stack  bloating  and 
overruns. 
[2]. 
  For 
rejuvenation 
two  categories: 
rejuvenation,  dynamic 
Various  software  rejuvenation  schemes  have  been 
devised  to  proactively  mitigate  the  impacts  of  software 
aging.  Software rejuvenation may involve all or some of 
the  following:  garbage  collection,  preemptive  rollback, 
memory defragmentation, (cid:147)therapeutic(cid:148) reboots, flushing 
the  operating  system  kernel  tables,  purging  database 
shared  pool  latches,  and  reinitializing  internal  data 
structures [4, 5].  Rejuvenation strategies may be divided 
  Time-based  rejuvenation  and 
into 
prediction-based 
time-based 
rejuvenation  policies,  state  restoration 
is  performed 
regularly  and  at  deterministic  intervals.    For  prediction-
based 
resource  metrics  are 
continuously  monitored  and  rejuvenation  is  attempted 
only when the onset of aging is deemed highly probable.   
For non-cluster computers, it is generally the case that 
time-based  rejuvenation  is  simpler  to  implement,  but 
prediction-based rejuvenation has the potential to produce 
the highest overall gain in system availability.  The act of 
rejuvenation  carries  some  performance  cost.    If  one  can 
anticipate  the  incipience  or  onset  of  aging  and  trigger 
rejuvenations  only  at  such  times,  the  most  efficient 
overall system operation may be achieved. This approach, 
however,  requires  that  some  performance  metric  be 
identified  that  can  be  monitored  to  infer  the  onset  of 
aging. 
One  particularly  complex  form  of  software  aging  is 
known as shared-memory-pool latch contention in online 
transaction  processing  (OLTP)  database  (DB)  systems.  
This  problem  involves  an  accumulation  of  DB  shared 
memory pool latches during times of high DB throughput, 
and  can  trigger  a  sudden  denial-of-service  hang  for  the 
server.    When  latch  contention  occurs,  a  human  DB 
administrator  must  completely  flush  the  shared  memory 
pool,  creating  a  15-30  minute  disruption  in  service.  
Although latch contention usually occurs at times of high 
transaction  throughput,  it  cannot  be  predicted  by  system 
load alone.  Moreover, no resource metrics have yet been 
identified  that  may  be  monitored  with  a  threshold  to 
predict the onset of latch contention.  The phenomenon is 
a complex interaction of multiple, dynamic parameters.   
We investigate here applicability of advanced statistical 
real-time  monitoring  and 
recognition 
for 
pattern 
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:22:17 UTC from IEEE Xplore.  Restrictions apply. 
lengths,  and  I/O. 
annunciation  of  the  onset  of  latch  contention  in  OLTP 
servers.    Our  study  focuses  on  performance  parameters 
relating  to  throughput,  transaction  latency,  system  load, 
queue 
  Over  100  performance 
parameters  from  a  production  OLTP  server  at  a  large 
corporation  were  collected  at  20-second  to  one-minute 
  A  commercially 
intervals  over  a  5-month  period. 
available 
system 
(SmartSignal  eCM(cid:153))  is  tested  to  determine  whether 
abnormal  signal  behavior  can  be  detected  prior  to  the 
fault. This technology uses an empirical model based on 
normal operation and compares real-time signal values to 
predicted  estimates. 
  Subtle  but  significant  signal 
deviations are announced by (cid:145)alerts(cid:146) that give early indi-
cation of equipment degradation or process inefficiency.     
condition  monitoring 
equipment 
2.  Technology:  SmartSignal  eCM(cid:153)  pattern 
recognition 
The  basis  of  SmartSignal  eCM(cid:153)  technology  is  a 
proprietary  set  of  signal  processing  algorithms  designed 
to perform the following functions:  to create an empirical 
model  based  on  normal  system  behavior;  to  generate  a 
real-time  estimate  of  the  current  state  of  the  system  by 
comparing current system data values to the model; and to 
determine statistically whether the difference between the 
current  state  and  its  estimate  is  within  normal  variation. 
The  SmartSignal  technology  is  based  on  a  technology 
developed at Argonne National Laboratory (Argonne, IL, 
USA) called the Multivariate State Estimation Technique 
(MSET).  MSET  was  developed  to  provide  incipient 
detection  of  disturbances  in  equipment,  sensors,  and 
operational  parameters  for  nuclear  power  generating 
systems and other safety-critical applications [6, 7, 8].  In 
a  1996  U.S.  Department  of  Energy-sponsored  sensor 
calibration  case-study,  MSET  demonstrated  significant 
early  warning  prior  to  a  nuclear  power  plant  fault,  with 
advanced  results  over  competing  analytical  methods  [9]. 
In  recognition  of  its  wide  applicability  to  mechanical 
equipment  with  multiple  monitored  signals,  SmartSignal 
Corporation  was  created,  as  a  privately  held  technology 
company,  to  commercialize  the  technology  [10,  11].  
Currently  their  eCM(cid:153)  equipment  condition  monitoring 
system  is  used  for  on-site  and  remote  monitoring  of 
equipment  in  the  airline  (jet  engines),  power  generation 
(steam  and  coal),  and  transportation  (pipeline,  mining 
truck, locomotive) industries.  
Historical data are first collected from  multiple  sensor 
signals  for  a  full  range  of  normal  operation.  The 
sophisticated modeling engine quickly creates a compact 
empirical  model  of 
the  normal  system  behavior. 
Equipment  condition  is  evaluated  for  every  instance  or 
(cid:145)snapshot(cid:146) of recorded data by mathematically comparing 
it  to  the  empirical  model,  producing  an  estimate  of  that 
specific state (via the aggregate of signals), see Figure 1 
(top). If the system is operating normally, the current state 
should  approximate  the  estimate,  with  a  small  deviation 
due to normal process variation. The differences between 
the  estimated  value  and  the  current  signals,  i.e.  the 
residuals  (Fig.  1  center),  are  sent  to  a  decision-making 
engine. Generally, the magnitude of the residual is smaller 
than the actual signal value by a factor of 101 to 103. 
Figure  1.  Typical  Example  of  SmartSignal  Results.  Top: 
Actual  Signal  and  Estimates;  Center:  Residual  Signal; 
Bottom:  SSCADI  Index  Decisions  and  Alerts.  Here,  alerts 
begin at sample 132, fault occurs at sample 230.  
The  residuals  are  tested  to  determine  if  the  variation 
from  normal  operation  is  statistically  significant,  with 
very  high  reliability  and  sensitivity.  The  residual 
snapshots are processed sequentially using the SSCADI 
(SmartSignal  Corp.  Active  Decision  Index)  algorithm,  a 
sequential,  binary  hypothesis  testing  procedure  for  real-
time data (Fig. 1 bottom).  A SSCADI decision is made 
when  one  of  the  limits  is  crossed:  The  lower  index 
decision  that  the  value  is  normal  or  the  upper  index 
decision that the  value is abnormal. Since the upper and 
lower limits are specific to each signal in each state, the 
test  is  very  sensitive.  The  engine  continuously  renders  a 
highly  reliable  decision,  over  a  moving  window  of 
successive  observations,  determining  whether  or  not  the 
residuals reveal a statistically significant abnormality.  
3. Analytical methods: Application of eCMTM 
to detection of latch contention 
SmartSignal was initially provided with data sampled in 
real-time  over  a  5-month  period  from  the  OLTP  server.  
The variables monitored include performance parameters 
and statistics such as number of users, throughput, load on 
CPU, I/O traffic, transaction latency, shared-memory-pool 
variables,  queue  lengths,  and  Oracle  library  &  cache-
buffer  parameters.    The  study  was  conducted  as  a  blind 
empirical test, where only the three (cid:145)canary test(cid:146) variables 
were  identified  to  SmartSignal.    These  canary  tests  are 
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:22:17 UTC from IEEE Xplore.  Restrictions apply. 
the 
of 
duration 
comprises 
synthetic  user  transactions  sent  through  the  system  from 
one of three geographical locations; the  wait time of the 
transaction 
external 
transmission  plus  the  internal  transaction  latency  for  the 
server. Typical canary test wait times are 9 to 11 seconds 
during normal operation. During a latch contention event, 
all three canary test variables have significantly high wait 
times. Here, the onset of a latch event is defined as when 
all three variables reach 30 sec wait time. 
include  concurrent  manager, 
The raw data signals from 165 variables from 20 groups 
((cid:147)aa(cid:148) through (cid:147)at(cid:148)) were provided at one of four sampling 
rates, approximately 3 per min, 1 per min, 1 per 6 min, or 
1  per  24  min.  Here,  a  (cid:145)group(cid:146)  represents  several  signals 
monitored  with  a  similar  type  of  measured  parameter- 
these 
lock  waits,  free 
memory in share pool, disk reads, canary response times, 
latch  misses,  requests,  idle  users,  physical  read/write 
rates,  and  the  ratio  of  parse  time  elapsed  to  parse  time 
CPU.  Signals  with  information-poor  data  were  ignored, 
including  empty  sets,  low  precision  signals,  redundant 
signals, and those sampled less frequently (6-24 minutes 
apart).  The  remaining  were  resampled  at  1-minute 
intervals using linear interpolation.  Some signals appear 
to have periodic behavior related to daily usage patterns; 
others have cumulative signal patterns (steadily increasing 
totals), and others indicate sub-totals (such as wait times). 
Based on the qualitative patterns and quantitative results 
from  a  correlation  analysis,  another  15  virtual  variables 