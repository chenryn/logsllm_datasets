next one, with measured link capacities of 75 Mbps. The
controller is located outside of EC2 in the eastern US,
communicating with EC2 via the public Internet.
Methodology and traﬃc: To demonstrate the bene-
ﬁts of hybrid control, we compare VDN to two other de-
signs. Fully Distributed relies entirely on the distributed
control algorithm in §4 and Fully Centralized uses only
the centralized controller in §5. For each experiment we
generate 200 videos, each requested by one client to a
random edge cluster. Each channel has multiple bitrates:
200 Kbps, 600 Kbps, and 1.4 Mbps. We add a new chan-
nel to the system once a second. With 10 nodes and
75Mbps links, 100 videos can easily place great load on
the system. 100 videos * 1.4Mbps is ∼150 Mbps, ﬁlling
two of the four source/reﬂector links. 200 videos would
ﬁll all four links, overloading the system. The video
client is a simple HTTP chunk requester that always
fetches a new chunk 2 seconds (the chunk duration) after
the previous chunk was received.
7.2.1 Quality of experience
Figure 17a shows the average client bitrate as requests
are added. Similar to the trace-driven evaluation, in a
system with medium load, VDN gives up to a 2x per-
formance gain over Fully Distributed. As the system
becomes more loaded, Fully Distributed sharply drops
while VDN and Fully Centralized decay gradually. Even
when the system is under medium loaded, VDN stays
close to the controller’s original decision (Optimal). Once
the system reaches heavy load (∼150 videos), other prob-
lems emerge (e.g., connection establishment overhead,
request incast) causing performance to decay.
In Figure 17b, we see that VDN is highly responsive.
Although Fully Centralized provides good average bitrate
during load, its join time (time from request to ﬁrst
byte of video) suﬀers (∼7 seconds, compared to VDN’s
∼200 milliseconds). Fully Distributed also provides sub-
second join times, but as the system gets loaded, it sees
massive spikes in latency as the lack of coordination
overloads interior clusters.
Figure 17c shows buﬀering ratio. Despite having good
quality overall, Fully Centralized has a much worse buﬀer-
ing ratio due to its lack of responsiveness.
7.2.2 Coping with network events
Figure 18a shows the eﬀects of link ﬂuctuations. We
select 25% of links at random, degrade their capacity by
increasing amounts (using tc), and measure the perfor-
050100150200#ofchannels0200400600800100012001400AverageBitrate(Kbps)LightLoadMed.LoadHvy.LoadVDNFullyCentralizedFullyDistributedOptimal050100150200#ofchannels0510152025JoinTime(Seconds)LightLoadMed.LoadHvy.LoadVDNFullyCentralizedFullyDistributed050100150200#ofchannels01020304050607080BufferingRatio(%)LightLoadMed.LoadHvy.LoadVDNFullyCentralizedFullyDistributed322approaches [30] can potentially beneﬁt VDN, but may
cause additional issues with hybrid control (e.g., loops)
as they complicate the topology.
Traﬃc engineering: Recent work [13, 15, 23, 25]
shows the beneﬁts of centralized traﬃc engineering in
ensuring high utilization and fairness in both intra- and
inter-datacenter settings. Unlike VDN, they work on
ﬂow aggregates at coarse timescales, making it hard
for them to provide the ﬁne-grained dynamic control
required for live video.
Video optimization: There is much prior work on
understanding and improving video delivery, including
client-side bitrate adaptation [27], metrics [9, 10], cross-
CDN optimization (e.g., [32]), and CDN-selection strate-
gies (e.g., [19]). Our work focuses on end-to-end delivery
and provides a practical system design.
10 Conclusion
VDN is a platform for live video delivery that helps
balance the concerns of both users and CDN operators
by providing real-time control over individual streams
from the CDN side. VDN employs centralized quality
optimization and hybrid control for responsiveness. We
show that centralized optimization can greatly improve
video quality while minimizing cost. Our hybrid control
plane mitigates WAN challenges, providing quick join
times and responsiveness to failures. Using a live video
trace, we show that VDN provides a 1.7× improvement
in average bitrate and a 2× reduction in delivery cost in
diﬀerent scenarios. Using Amazon EC2, we show that
our design is responsive at a timescale of 200 ms.
Acknowledgments
The authors would like to thank Nicolas Feltman for
help with the ILP, Eric Anderson and Raja Sambasi-
van for help with distributed control, JungAh Hong for
help with the initial evaluation, Dave Oran for shepherd-
ing this paper, and the anonymous reviewers for their
feedback. This work is supported in part by the NSF
under award #CNS-1345305, NDSEG Fellowship 32
CFR 168a, the National Research Foundation of Korea
(NRF-2013R1A1A1076024), and the IITP under grant
No. B0126-15-1078 funded by the Korean Government
(MSIP).
11 References
[1] Ooyala global video index q3 2013.
http://go.ooyala.com/rs/OOYALA/images/
Ooyala-Global-Video-Index-Q3-2013.pdf.
[2] Private conversation with Bruce Maggs, vice president,
research at Akamai.
[3] Private conversation with Hui Zhang, chief executive oﬃcer,
at Conviva.
[4] Twitch. http://twitch.tv.
[5] Twitch is 4th in peak us internet traﬃc.
http://blog.twitch.tv/2014/02/
twitch-community-4th-in-peak-us-internet-traﬃc/.
[6] I. Sodagar. The MPEG-DASH Standard for Multimedia
Streaming Over the Internet. IEEE Multimedia (2011).
(a) Link ﬂuctuation.
(b) Updates dropped.
Figure 18: VDN handles network issues without
much degradation.
mance 10 seconds after adding 10 channels. We see that
all three systems perform similarly.
Figure 18b shows the eﬀects of loss. We drop updates
from the controller and measure the performance 10
seconds after adding 10 channels. As expected, Fully
Centralized performs much worse as updates are dropped.
VDN performs well even when it starts to lose all update
messages by falling back to distributed control.
8 Discussion
Complexity versus improvement: Despite the in-
herent complexity of hybrid control, VDN manages to
provide a signiﬁcant monetary beneﬁt (2×) to CDN op-
erators as well as increased ﬂexibility (see Figure 16a and
16b). Additionally, VDN provides a centralized point
of management to adjust link costs and video priorities.
Furthermore, as seen in §7, simple tweaks on current
CDNs, like shorter TTLs, don’t provide these beneﬁts.
Alternate topologies: We assume an (cid:110)-tiered topol-
ogy as we feel this is representative of modern CDNs [2,
29, 35, 40]. Additional work would be needed to ﬁt our
scheme to arbitrary topologies.
Client-side bitrate adaptation: Although not ex-
plicitly included in our system, we assume clients inde-
pendently do bitrate adaptation through some black-box
assessment of delivery quality. Distributed control al-
lows VDN to quickly respond to bitrate switching, but
we assume that the rate of switching is fairly low [9].
9 Related work
Content delivery networks: Large- (e.g., [29, 35])
and medium-scale (e.g., [18, 42]) CDN systems have ex-
plored various design choices, including peer-to-peer,
hybrid [22, 43], centralized, or hierarchical architec-
tures [24] as well as their tradeoﬀs [45]. None of these
papers provides the key combination of global coordi-
nation, video-speciﬁc optimization, cost-minimization,
attention to live-video speciﬁc issues, and practical end-
to-end system design.
Overlay multicast: Prior work on providing the
sustained high-throughput connections needed for live
video [12, 14, 26, 30] focuses on how to best organize
individual streams. However, they do not perform ex-
tensive coordination across video streams. P2P-based
020406080100%LinkCapacityChange200400600800100012001400AverageBitrate(Kbps)VDNFullyCentralizedFullyDistributed020406080100%ofUpdatesDropped0200400600800100012001400AverageBitrate(Kbps)VDNFullyCentralized323[7] Akamai. Akamai investor summit: 2013. http://www.
[27] Jiang, J., Sekar, V., and Zhang, H. Improving fairness,
akamai.com/dl/investors/2013 ir summit presentation.pdf.
[8] Amazon. Amazon Elastic Compute Cloude (Amazon EC2).
http://aws.amazon.com/ec2/.
[9] Balachandran, A., Sekar, V., Akella, A., Seshan, S.,
Stoica, I., and Zhang, H. A quest for an internet video
quality-of-experience metric. In Proceedings of the 11th
ACM Workshop on Hot Topics in Networks (New York,
NY, USA, 2012), HotNets-XI, ACM, pp. 97–102.
[10] Balachandran, A., Sekar, V., Akella, A., Seshan, S.,
Stoica, I., and Zhang, H. Developing a predictive model
of quality of experience for internet video. In Proc. ACM
SIGCOMM (2013), ACM, pp. 339–350.
[11] Bashore, A. Twitch stats. http://stats.twitchapps.com/.
[12] Castro, M., Druschel, P., Kermarrec, A.-M., Nandi,
A., Rowstron, A., and Singh, A. Splitstream:
high-bandwidth multicast in cooperative environments. In
ACM SIGOPS Operating Systems Review (2003), vol. 37,
ACM, pp. 298–313.
[13] Chowdhury, M., Zaharia, M., Ma, J., Jordan, M. I.,
and Stoica, I. Managing data transfers in computer
clusters with orchestra. SIGCOMM CCR 41, 4 (2011), 98.
[14] Chu, Y., Rao, S., Seshan, S., and Zhang, H. Enabling
conferencing applications on the internet using an overlay
muilticast architecture. ACM SIGCOMM computer
communication review 31, 4 (2001), 55–67.
[15] Fortz, B., Rexford, J., and Thorup, M. Traﬃc
engineering with traditional ip routing protocols.
Communications Magazine, IEEE 40, 10 (2002), 118–124.
[16] Foundation, A. Apache HTTP Server Project.
http://httpd.apache.org/.
[17] Frank, B., Poese, I., Lin, Y., Smaragdakis, G.,
Feldmann, A., Maggs, B., Rake, J., Uhlig, S., and
Weber, R. Pushing cdn-isp collaboration to the limit.
ACM SIGCOMM CCR 43, 3 (2013).
[18] Freedman, M. J. Experiences with coralcdn: A ﬁve-year
operational view. In Proc. USENIX NSDI (2010).
[19] Ganjam, A., Siddiqui, F., Zhan, J., Liu, X., Stoica, I.,
Jiang, J., Sekar, V., and Zhang, H. C3: Internet-scale
control plane for video quality optimization. In 12th
USENIX Symposium on Networked Systems Design and
Implementation (NSDI 15) (Oakland, CA, May 2015),
USENIX Association, pp. 131–144.
[20] Ghorbani, S., and Caesar, M. Walk the line: consistent
network updates with bandwidth guarantees. In Proc.
HotSDN (2012), ACM, pp. 67–72.
[21] Gurobi. Gurobi optimization. http://www.gurobi.com/.
[22] Han, D., Andersen, D., Kaminsky, M., Papagiannaki,
D., and Seshan, S. Hulu in the neighborhood. In Proc.
COMSNETS (Jan. 2011), pp. 1 –10.
[23] Hong, C.-Y., Kandula, S., Mahajan, R., Zhang, M.,
Gill, V., Nanduri, M., and Wattenhofer, R. Achieving
high utilization with software-driven wan. In Proc. ACM
SIGCOMM (2013).
[24] Huang, C., Wang, A., Li, J., and Ross, K. W. Measuring
and evaluating large-scale cdns. In Proc. ACM IMC (2008).
[25] Jain, S., Kumar, A., Mandal, S., Ong, J., Poutievski,
L., Singh, A., Venkata, S., Wanderer, J., Zhou, J., Zhu,
M., et al. B4: Experience with a globally-deployed
software deﬁned wan. In Proc. ACM SIGCOMM (2013).
[26] Jannotti, J., Gifford, D. K., Johnson, K. L.,
Kaashoek, M. F., et al. Overcast: reliable multicasting
with on overlay network. In Proc. 4th conference on
Symposium on Operating System Design & Implementation
(2000).
eﬃciency, and stability in http-based adaptive video
streaming with festive. In Proc. ACM CoNEXT (2012).
[28] Katta, N. P., Rexford, J., and Walker, D. Incremental
consistent updates. In Proc. HotSDN (2013), ACM.
[29] Kontothanassis, L., Sitaraman, R., Wein, J., Hong, D.,
Kleinberg, R., Mancuso, B., Shaw, D., and Stodolsky,
D. A transport layer for live streaming in a content delivery
network. Proceedings of the IEEE 92, 9 (2004), 1408–1419.
[30] Kosti´c, D., Rodriguez, A., Albrecht, J., and Vahdat,
A. Bullet: High bandwidth data dissemination using an
overlay mesh. In ACM SIGOPS Operating Systems Review
(2003), vol. 37, ACM, pp. 282–297.
[31] Lamport, L. The part-time parliament. ACM Trans.
Comput. Syst. 16, 2 (May 1998), 133–169.
[32] Liu, X., Dobrian, F., Milner, H., Jiang, J., Sekar, V.,
Stoica, I., and Zhang, H. A case for a coordinated
internet video control plane. In Proc. ACM SIGCOMM
(2012), pp. 359–370.
[33] Liu, Y., Zhang, H., Gong, W., and Towsley, D. On the
interaction between overlay routing and underlay routing.
In INFOCOM 2005. 24th Annual Joint Conference of the
IEEE Computer and Communications Societies.
Proceedings IEEE (2005), vol. 4, IEEE, pp. 2543–2553.
[34] McGeer, R. A safe, eﬃcient update protocol for openﬂow
networks. In Proc. HotSDN (2012), ACM, pp. 61–66.
[35] Nygren, E., Sitaraman, R. K., and Sun, J. The akamai
network: a platform for high-performance internet
applications. ACM SIGOPS Operating Systems Review 44,
3 (2010), 2–19.
[36] Prasad, R., Dovrolis, C., Murray, M., and Claffy, K.
Bandwidth estimation: metrics, measurement techniques,
and tools. Network, IEEE 17, 6 (2003), 27–35.
[37] Sandvine. Global internet phenomena report: 1h 2014.
https://www.sandvine.com/downloads/general/
global-internet-phenomena/2014/
1h-2014-global-internet-phenomena-report.pdf.
[38] Spangler, T. World cup sets new internet-video streaming
records for espn, univision, and akamai.
http://variety.com/2014/digital/news/
world-cup-sets-new-internet-video-streaming-record-1201221997/.
[39] Strauss, J., Katabi, D., and Kaashoek, F. A
measurement study of available bandwidth estimation tools.
In Proceedings of the 3rd ACM SIGCOMM Conference on
Internet Measurement (New York, NY, USA, 2003), IMC
’03, ACM, pp. 39–44.
[40] Su, A.-J., and Kuzmanovic, A. Thinning akamai. In Proc.
ACM IMC (2008).
[41] Team, T. How twitch ﬁts in amazon’s strategy.
http://www.forbes.com/sites/greatspeculations/2014/08/
28/how-twitch-ﬁts-in-amazons-strategy/.
[42] Wang, L., Park, K., Pang, R., Pai, V. S., and Peterson,
L. L. Reliability and security in the codeen content
distribution network. In Proc. USENIX ATC, General
Track (2004).
[43] Xu, D., Kulkarni, S. S., Rosenberg, C., and keung
Chai, H. A cdn-p2p hybrid architecture for cost-eﬀective
streaming media distribution. Computer Networks 44
(2004), 353–382.
[44] YouTube. Live encoder settings, bitrates and resolutions.
https:
//support.google.com/youtube/answer/2853702?hl=en.
[45] Yu, M., Jiang, W., Li, H., and Stoica, I. Tradeoﬀs in
cdn designs for throughput oriented traﬃc. In Proc. ACM
CoNEXT (2012), ACM, pp. 145–156.
324