Fuzzyfox
16
14
12
)
s
m
(
10
i
e
m
T
d
e
t
r
o
p
e
R
8
6
4
2
0
 2
 4
 6
Size (MB)
 8
 10
Figure 2: Script Parsing Attack with Asynchronous Clock
(Except for JSKERNEL, the reported parsing time measured
by the callback of setTimeout increases for all other defenses
when the size of the ﬁle increases.)
social network Friends, by appending them to the Document
Object Tree (DOM) tree and measuring the loading time.
Hence, the secret, which the adversary tries to steal, is
the loading time of DOM operations, such as appending
children. There are different types of DOM elements that
the adversary may want to steal—speciﬁcally, van Goethem
et al. propose two types of attacks, i.e., script parsing and
image decoding. The former loads a cross-origin resource as
a script and the latter as an image. Both attacks, as shown in
Table I, are still possible in all the existing defenses except
for JSKERNEL and DeterFox, which adopt determinism to
defeat timing attacks.
The evaluation results in Figure 2 show that existing de-
fenses other than JSKERNEL are vulnerable to script parsing
attacks. Speciﬁcally, when the ﬁle size increases, the loading
time also does so. That is, an adversary can infer the ﬁle size
based on the loading time. Firefox, Chrome and Edge show
a linear line, i.e., it is easy to differentiate ﬁne-grained ﬁle
size in both browsers. Tor Browser, Fuzzyfox and Chrome
Zero raise the bar, making it harder to differentiate ﬁles with
small size difference, but it is still possible to infer two ﬁles
with larger than 1MB difference.
2) Animation-related timing attack using requestAnim-
ationFrame or CSS Animation as an implicit clock:
An animation-related timing attack, such as history sniff-
ing [9], SVG ﬁltering [14], ﬂoating point [10], relies on the
requestAnimationF rame API or CSS Animation [12] to
measure the time to launch a repainting related operation, i.e.,
a secret. The time may be used to further infer cross-origin
contents, such as pixels in a cross-origin image. For example,
the history snifﬁng attack can be used to differentiate the
color of a visited and unvisited link, thus determining whether
the link is visited by the browser user. The SVG ﬁltering
attack mentioned in the DeterFox paper [14] can be used to
differentiate two images with drastically different resolutions.
The ﬂoating-point attack [10] is designed to steal pixels from
a cross-origin image. The original attacks have been ﬁxed by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:51 UTC from IEEE Xplore.  Restrictions apply. 
70
Chrome and Firefox, and the version that we used here is a
combination of the original attack and pixel stealing one [9].
We take a closer look at the SVG ﬁltering attack in Table II
(SVG Filtering column). We run each test for 25 times against
each defense and take the average duration as the measurement
results. The evaluation results show that this side channel still
exists in all other defenses except for JSKERNEL. Speciﬁcally,
the adversary can easily differentiate two images in Chrome,
Firefox, Edge, Chrome Zero, and Tor browser with a few runs.
Fuzzyfox does increase the bar, because it adds much noise to
the execution time; however, an adversary can still average the
results of 25 runs and differentiate two images with different
resolutions.
3) Loopscan Attack: Loopscan [11] is a novel attack that
monitors the event loop usage pattern to infer the domain
name of cross-origin websites visited by the user. For example,
the usage pattern of google.com is different from the one
of youtube.com, and therefore an adversary can infer what
websites are visited by the victim user. We adopt the original
implementation of Loopscan to evaluate existing defenses.
For simplicity, we only record the maximum event interval
and evaluate existing defenses’ capability to differentiate two
websites. Table II (Loopscan Attack column) shows the eval-
uation results: except for JSKERNEL, all other defenses are
vulnerable to the Loopscan attack. That is, the maximum event
intervals of these defenses are different for youtube.com and
google.com, and thus an adversary can infer the website name
based on the interval.
4) Clock edge attack: Clock edge attack [6] measures the
duration of a cheap operation, such as i + +, by using a
coarse-grained clock. Speciﬁcally, an adversary can count the
number of a cheap operation between two edges of one tick in
the coarse-grained clock—and the calculate the weight of the
cheap operation by dividing the number by the tick value of
the coarse-grained clock. Then, the cheap operation can serve
as a ﬁne-grained clock to measure a secret.
The evaluation results in Table I show that JSKERNEL can
defend against the clock edge attack. The reason is that the
time interval between two coarse-grained clock API calls is
determined by the number of API calls but not the number
of the cheap operations. By contrast, the clock edge attack
provides a more accurate timer in Chrome, Firefox and Tor
Browser. Fuzzyfox does defend against the clock edge attack
as claimed in the paper.
B. Other Web Concurrency Attacks
We herewith evaluate the capability of JSKERNEL to defend
against other web concurrency attacks. The methodology of
ﬁnding and evaluating web concurrency attacks is as follow.
First, we search the keyword “worker” and a browser name,
such as Firefox and Chrome, on the National Vulnerability
Database (NVD) and then manually go through all the vul-
nerabilities to conﬁrm their relationship to web concurrency
attack. Note that
this may not be a complete list of all
the web concurrency attacks but it is the best we can do
to ﬁnd web concurrency attacks. Second, we download the
vulnerable version of the browser together, ﬁnd the available
attacks online, e.g., on Bugzilla, and then evaluate the corres-
ponding defenses. Since some older browsers do not support
new features, we replace these new features with old ones
correspondingly. Note that some vulnerabilities are platform
speciﬁc—for example, CVE-2018-5092 can only be triggered
on Windows 10.
A high-level overview of the results is shown in Table I. The
native defenses are not robust as none of them are equipped to
consider web concurrency attacks except for simpler cases of
timing with implicit clocks. Chrome Zero can defend against
some vulnerabilities at the price of reduced functionalities
as Chrome Zero only adopts a polyﬁll implementation of a
web worker. We now present some examples to illustrate why
JSKERNEL can defend against these vulnerabilities.
• CVE-2013-1714 [18] is a vulnerability that violates same-
origin policy, i.e., a worker thread can send an XMLHt-
tpRequest to web servers with any origin. The condition to
trigger the vulnerability is that the request needs to come
from a worker thread. Therefore, JSKERNEL enforces a
policy to check the origins for all the requests coming from
a web worker.
• CVE-2013-5602 [19] is a vulnerability that refers to a
null pointer when an adversary assigns an onmessage
callback function to a Web Worker object. JSKERNEL
enforces a policy to avoid assigning an onmessage callback
by hooking both the setter function of onmessage and
setEventListener.
• CVE-2014-1488 [20] is a use-after-free vulnerability, in
which the worker thread passes a transferable ArrayBuffer
to the main thread but will free the ArrayBuffer once it is
terminated. The condition to trigger the vulnerability is that
the worker thread needs to ﬁrst pass a transferable to the
main thread and then be terminated. Therefore, the policy
enforced by JSKERNEL is that if the worker thread passes
a transferable object, the worker will only be terminated at
the user level, but the kernel level will still maintain the
worker to avoid the triggering condition.
• CVE-2014-1487 [21] and CVE-2015-7215 [22] are two
information disclosure vulnerabilities that show
similar
cross-origin information in the error message of a worker
thread creation and the importScripts() function of a
worker thread. JSKERNEL enforces a policy that sanit-
izes the error message of onerror callback function and
importScripts() by throwing a new message without the
cross-origin information and ensuring security.
• CVE-2017-7843 [23] is a vulnerability in which the access
to indexedDB in private browsing mode is not deleted after
existing. Therefore, the policy enforced by JSKERNEL is to
avoid access to indexedDB during private browsing mode
to obey the mode’s speciﬁcation.
V. SYSTEM EVALUATION
In this section, we evaluate JSKERNEL based on two
metrics: performance overhead and compatibility.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:51 UTC from IEEE Xplore.  Restrictions apply. 
71
 100
)
%
(
e
g
a
t
n
e
c
r
e
P
 80
 60
 40
 20
 0
 0
 10
 20
Time (ms)
Chrome
Chrome with JSKernel
Chrome with ChromeZero
Firefox
Firefox with JSKernel
Deterfox
Tor Browser
Fuzzyfox
 30
 40
 50
Figure 3: Cumulative Distribution Function (CDF) of Loading
Time of Top 500 Alexa Websites (Browsers with JSKERNEL
and DeterFox incur the least overhead; Tor Browser and
Fuzzyfox are the slowest; Chrome Zero incurs more overhead
than JSKERNEL.)
A. Performance Overhead
We evaluate the performance overhead using both micro-
and macro-benchmarks. The micro-benchmark evaluates the
performance overhead of speciﬁc APIs, especially those re-
lated to web concurrency attacks; the macro-benchmark eval-
uates top Alexa websites using both loading times and check-
points speciﬁed in the Raptor test. Note that all the experiments
are performed on a Linux machine with an Intel(R) 2.30GHz
Core(TM) i5-6300HQ CPU, 8 GB memory, and an ADSL
network with 9.5 Mbit/s bandwidth.
1) Micro-benchmark: Dromaeo and Worker Test: We ﬁrst
evaluate JSKERNEL extensions with Google Chrome us-
ing Dromaeo [15], a comprehensive JavaScript performance
benchmark with many micro-level test cases, such as math-
ematical calculations, data structure manipulations, and DOM
operations. Overall, the performance drops 1.99% on average
after installing JSKERNEL on Google Chrome and the median
performance reduction is 0.30%. The DOM Attribute Test
incurs the largest overhead,
i.e., 21.15% decrease in the
performance, because this test needs to traverse through the
kernel and the website JavaScript for many times, which brings
overhead.
any web worker
As Dromaeo does not have
in-
volved, we also tested JSKERNEL extension with Google
Chrome under a Worker benchmark (http://pmav.eu/stuff/
javascript-webworkers/). Speciﬁcally, we created 16 workers
and measured the time to create these workers with 5 repeat
experiments—the average overhead is 0.9% with and without
JSKERNEL extension.
2) Macro-benchmark: Alexa Top 500 Websites: We eval-
uated the performance of JSKERNEL using Alexa Top 500
websites. Speciﬁcally, we used Selenium [24], a browser auto-
mation tool, to visit Alexa websites and record the timestamp
before the visit and the timestamp when onload event is ﬁred.
We then calculated the interval, i.e., the loading time of the
website, on our experiment machine. Each experiment is per-
Table III: Average Website Loading Time in Raptor-tp6-1 (C:
Chrome and F: Firefox). All numbers in the table are in
milliseconds (ms).
Subtest
Amazon
Facebook
Google
Youtube
Chrome (C)
107.2±12.8
178.8±9.5
48.3±3.2
298.9±110.6
JSKERNEL (C)
109.3±11.4
172.1±15.7
51.3±3.5
308.9±100.3
Firefox (F)
809.1±50.6
1,018.9±109.1
400.7±107.9
1,249.8±158.4
JSKERNEL (F)
831.9±57.9
1,005±238.3
425.4±105.4
1,136.8±135.1
formed three times to obtain an average result. Figure 3 shows
the cumulative distribution function (CDF) of the loading time
of Alexa websites with seven different browsers, i.e., Chrome,
Chrome with JSKERNEL, Chrome with Chrome Zero, Firefox,
Firefox with JSKERNEL, DeterFox [14], Tor Browser [17],
and Fuzzyfox [6].
There are four things worth noting. First, JSKERNEL adds
minimal, non-observable overhead to the web browsers. Spe-
ciﬁcally, the curve of JSKERNEL with Chrome and Firefox
is very close to the original browser with no observable,
statistically-signiﬁcant overhead. Second, although the per-
formance of DeterFox is also similar to Firefox, DeterFox
only works as a Firefox variance. That is, it remains unclear
how to integrate DeterFox with Google Chrome, which may
require signiﬁcant engineering work. Third, both Tor Browser
and Fuzzyfox, which are based on and modiﬁed from Firefox,
incur non-negligible overhead, because they add noises to the
browser. In addition, similar to DeterFox, it is unclear how
to integrate these two approaches with Google Chrome either.
Lastly, both JSKERNEL and Chrome Zero can be deployed
as a Chrome extension, but JSKERNEL incurs much less
overhead compared with Chrome Zero.
3) Macro-benchmark: Raptor Loading Tests: In addition to
the aforementioned experiment on Alexa Top 500 Websites,
we also run Raptor loading tests [25], i.e., raptor-tp6-(1–7), to
evaluate the performance of JSKERNEL. The reason that we
use this test is that some modern websites continue loading
after the onload event via JavaScript—Raptor loading tests,
which adopt a hero element to indicate the loading time, can
capture such loading tasks performed by websites. Speciﬁcally,
we load each subtest 25 times and skip the ﬁrst result due
to the involvement of opening a tab. The average loading
overhead for JSKERNEL on Chrome (as indicated by the
loading of the hero element) is 2.75% and on Firefox 3.85%.
We also listed the detailed numbers for raptor-tp6-1 in the
Table III. There are two things worth noting. First, the loading
time with JSKERNEL could be smaller than the one without
JSKERNEL, such as in the case of Facebook and Youtube
(Firefox), because elements loaded in JSKERNEL may follow
a speciﬁc sequence in which the hero element is loaded early.
Second, the time differences with and without JSKERNEL are
smaller than the standard deviation, i.e., the overhead is small
enough.
B. Compatibility
In this subsection, we evaluate the compatibility of JSKER-
NEL with legacy websites and JavaScript applications.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:24:51 UTC from IEEE Xplore.  Restrictions apply. 
72
1) API Speciﬁc Test:
In order to ﬁnd legacy JavaScript
applications with certain APIs, we rely on CodePen [26], a so-
cial development environment for front-end designers and de-
velopers. Speciﬁcally, CodePen provides a search interface, in
which we can type an API name, such as perf ormance.now,
and then CodePen will return a list of applications using
that searched API. In this experiment, we obtain the top ﬁve
applications returned by CodePen as our test dataset when
searching a corresponding API in CodePen.
Our evaluation methodology works as follows. We ask a
student to ﬁrst run the application in four different browsers:
Firefox, Fuzzyfox, DeterFox, and a Firefox with JSKERNEL
installed. The student needs to interact with the application