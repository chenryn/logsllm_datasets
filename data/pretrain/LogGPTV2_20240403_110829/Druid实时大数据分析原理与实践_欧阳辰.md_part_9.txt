时需要从磁盘加载数据的次数就少，查询速度就快；反之，查询时需要从磁盘加载数据的次
50
硬件分配给冷数据，使其能够满足较大的存储空间要求。基于上述的理论考虑，在实践中往
更多性能中等的硬件分配给温数据，使其能够满足较快的响应速度；而将最多的性能普通的
程度来综合考虑：将少量性能较好的硬件分配给热数据，使其能够满足最快的响应速度；将
对于分布式系统来说，在规划存储时需要同时考虑硬件的异构性与数据温度，并在它们
数据温度与成本的平衡示意图如图3-15所示。
·冷数据：偶尔被访问。特点是总的数据量占比最大，但响应速度不用很快。
·热数据：经常被访问。特点是总的数据量不算大，
不难看出，历史节点的查询效率受内存空间富余程度的影响很大：内存空间富余，查询
在规划存储的时候，为了达到尽量好的性价比，可以结合数据温度的特点与硬件的优劣
·温数据：
层的分组功能
：不经常被访问。特点是总的数据量一般，且要求响应速度尽量快。
冷数据
温数据
热数据
图3-15数据温度与成本的平衡示意图
不经常被访问
偶尔被访问
经常被访问
数据量
，但要求响应速度最快。
一越频繁温度越高。根据数据温
Druid实时大数据分析原理与实践
访问性能要求
---
## Page 75
询中枢点，如图3-16所示。
实时节点与历史节点查询到的数据合并后返回给客户端。因此，查询节点便是整个集群的查
3.6.1
据
3.6
他处于工作状态的历史节点。
集群后，同样会被协调节点发现，然后协调节点会将原本分配给它的Segment重新分配给其
被协调节点发现，然后协调节点将会自动分配相关的Segment给它；原有的历史节点被移出
3.5.3
Segment数据文件，以达到效率与成本相对平衡的状态。
根据性能容量等指标分为不同的层，并且可以让不同性质的DataSource使用不同的层来存储
第3章架构详解
在常规情况下，Druid集群直接对外提供查询的节点只有查询节点，而查询节点会将从
合并后返回给调用方。
历史节点拥有极佳的可扩展性与高可用性。新的历史节点被添加后，会通过Zookeeper
Druid也考虑到了这个问题，因此提出了层（Tier）的概念：将集群中所有的历史节点
查询节点
查询节点
查询中枢点
高可用性与可扩展性
江
（BrokerNode）对外提供数据查询服务，并同时从实时节点与历史节点查询数
(Realtime Node)
实时节点
图3-16
(Broker Node)
查询节点查询数据
查询节点
Segments
(Client)
客户端
(Historical Node)
历史节点
---
## Page 76
3-18所示。
客户端查询的gateway来完成对多个查询节点的负载均衡，
无论访问哪个查询节点都能得到同样的查询结果。因此，在实践中也常常会通过Nginx作为
询节点可用的情况，通常会多加一个查询节点到集群中。在集群中有多个查询节点的时候，
3.6.3
时候才会去访问历史节点与实时节点以查询数据。
供选择。
的提高
次访问库中的相关数据一
询再次发生时，可以直接利用之前存储在Cache中的数据作为部分或全部的结果，而不用再
3.6.2
52
如果用查询节点的内存作为Cache，查询的时候会首先访问其Cache，只有当不命中的
Druid也使用了Cache机制来提高自己的查询效率。Druid提供了两类介质作为Cache以
很多数据库都会利用缓存（Cache）来存储之前的查询结果，如图3-17所示。
。本地Cache，比如查询节点或历史节点的内存作为Cache。
·外部Cache，比如Memcached。
一般Druid集群中只需要一个查询节点即可。但是为了防止出现单个节点失败导致无查
高可用性
缓存的使用
results for segment2013-01-07/2013-01-08
resultsforsegment2013-01-02/2013-01-03
resultsforsegment2013-01-01/201301-02
Cache(onbrokernodes)
一这样，在Cache中数据的命中率较高时，查询效率也会得到明显
图3-17使用查询节点的缓存
，并达到集群高可用的效果，如图
segment for data2013-01-06/2013-01-07
segmentfordata2013-01-05/2013-01-06
segment fordata2013-01-04/2013-01-05
segment for data2013-01-03/2013-01-04
Historicalandreal-timenodes
Druid实时大数据分析原理与实践
当相似查
---
## Page 77
个 Segment数据文件来说，协调节点会逐条检查规则，当碰到当前 Segment数据文件符合某
体的数据文件，以管理数据生命周期。可以对一个DataSource按顺序添加多条规则，对于一
3.7.2
历史节点虽然还能向外提供查询服务，但已经不再接收新的Segment数据了。
会给历史节点分配数据，完成数据分布在历史节点间的负载均衡。当协调节点不可访问时，
何其他节点；但是，对于历史节点来说，协调节点便是它们的Master节点，因为协调节点将
其实并没有真正意义上的Master节点，因为实时节点与查询节点能自行管理并不听命于任
失效的问题，以及集群的扩展性有时受限于Master节点的能力。对于整个Druid集群来说
构的优势在于集群比较容易通过Master节点进行管理，但缺点是Master节点容易出现单点
3.7.1
的生命周期。
3.7
第3章
Druid利用针对每个DataSource设置的规则（Rule）来加载（Load）或丢弃（Drop）具
很多分布式项目往往采用主从（Master-Slave）节点的架构，比如 HDFS、Yarn等。该架
协调节点（Coordinator Node）负责历史节点的数据负载均衡，以及通过规则管理数据
协调节点
架构详解
利用规则管理数据生命周期
集群数据负载均衡的主宰
(Realtime Node)
(Broker Node)
实时节点
查询节点
图3-18通过Nginx访问查询节点
Segments
Nginx
(Client)
客户端
(Historical Node)
(Broker Node)
查询节点
历史节点
3
---
## Page 78
结构作为其架构方式，其中统治节点（OverlordNode）为主节点，
3.8.1
数据文件相关的所有操作，如合并、删除Segment数据文件等。
灵活地管理与使用系统资源；可以完成Segment副本数量的控制；能够灵活完成跟Segment
手工编写数据消费配置文件的方式，可以通过API的编程方式来灵活定义任务配置；可以更
件的方式，索引服务的优点是除了对数据能够用pull的方式外，还支持push的方式；不同于
dexing Service）的组件同样能够制造Segment数据文件。相比实时节点生产Segment数据文
3.8
关工作。
调节点即可。当某个协调节点退出服务时，集群中的其他协调节点依然能够自动完成相
3.7.4
节点的突发下线情况，在需要做集群升级的时候也能保证集群查询服务在此过程中不间断。
查询到相关数据—Segment数据文件的单点问题便迎刃而解。这个特性不仅能够应对历史
中，当某个历史节点不可访问时还能从其他同样拥有该Segment数据文件副本的历史节点中
果用户设置了更多的副本数量，则意味着某Segment数据文件在集群中存在于多个历史节点
副本数量默认为1，即仅有一个历史节点提供某Segment数据文件的查询，存在单点问题。
单点失效的问题。Druid通过Segment数据文件的副本（Replication）解决了这个问题。
载均衡到其他历史节点前的这一段时间内无法查询，因此从这个意义上说Segment 数据存在
负载均衡，但是当某个历史节点突然退出集群的时候，它本身所包含的Segment数据在被负
3.7.3
载或丢弃，并停止检查余下的规则，否则继续检查下一条设置好的规则。
条规则的情况时，协调节点会立即命令历史节点对该Segment数据文件执行这条规则一
54
对于协调节点来说，高可用性的问题十分容易解决一
Druid允许用户对某个DataSource定义其Segment数据文件在历史节点中的副本数量
虽然协调节点能够根据历史节点数目的变化，动态地完成Segment数据文件在集群中的
不同于实时节点的单节点模式，索引服务实际包含一组组件，并以主从（Master-Slave）
除了通过实时节点生产出Segment数据文件外，Druid还提供了一组名为索引服务（In-
索引服务
主从结构的架构
高可用性
副本实现Segment的高可用性
一只需要在集群中添加若干个协
Druid实时大数据分析原理与实践
，而中间管理者（Middle
---
## Page 79
http://:/druid/indexer/v1/task/{taskId}/shutdown
http://:/druid/indexer/v1/task
到从节点即中间管理者上。统治节点有以下两种运行模式。
3.8.2
Manager）为从节点。索引服务架构示意图如图3-19所示。
第3章架构详解
统治节点作为索引服务的主节点，对外负责接收任务请求，对内负责将任务分解并下发
客户端也可以发出杀掉某个任务的命令。
·远程模式（RemoteMode）：在该模式下，统治节点与中间管理者分别运行在不同的节
·本地模式（LocalMode）：默认模式。在该模式下，统治节点不仅负责集群的任务协调
分配工作，
命令格式如下。
供RESTful的访问方法，因此客户端可以通过HTTPPOST请求向统治节点提交任务。
点上，它仅负责集群的任务协调分配工作，不负责完成任何具体的任务。统治节点提
统治节点
，也能够负责启动一些苦工（Peon）来完成一部分具体的任务。
/tasks
peon
图3-19
Middle Manager
mm3
/mm2
peon
索引服务架构示意图
ZooKeepe
new_task
ew_task
Overlord
new_task
/status/new_task
peon
ewtaskstatus
new_task_status
5
---
## Page 80
3.8.4
工即独立的IVM来完成具体的任务。这样的架构实际与 Hadoop Yarn 很像。
3.8.3
http: //:/console.html
制台（Console），因此用户可以通过浏览器轻松地了解任务与工作节点的状态。
混杂型
销毁Segment 型
合并Segment型
合并Segment 型
创建Segment型
创建Segment型
父类
个简单介绍。
索引服务能执行的任务（Task)都基本与索引数据即 Segment数据相关，下面通过表格做
·苦工相当于Yarn的Container，启动在具体节点上负责具体任务的执行。
·统治节点相当于Yarn 的 ResourceManager，
中间管理者就是索引服务的工作节点，负责接收统治节点分配的任务，然后启动相关苦
客户端可以发出查看任务状态、接收Segment等的任务。同时统治节点也提供了一个控
。中间管理者相当于Yarn的NodeManager，负责管理独立节点的资源并接受任务。
任务
中间管理者与苦工
kill
merge
append
index
segment
convert
hadoop
hadoop
index
Type
版
销
合
任务
普
引任务
Hadoop索
务
本转换
务
毁索引
务
并索引
务
加索引
通
称
索引
换，适合体量比较大的Segment数据文件的版本转换
MapReduce任务以完成 Segment 数据文件的版本转
素。Hadoop 版本转换任务会利用 Hadoop 集群执行
通常用来重定义Segment 数据文件的压缩方法等要
DeepStorage
彻底将指定的Segment数据文件从Druid集群包括
并为一个Segment数据文件
将若干个Segment娄
Segment数据文件
将若干个Segment数据文件首尾相连，最终合成一个
创建任务
文件的创建，适合体量比较小的 Segment数据文件的
利用Druid集群本身的系统资源来完成Segment数据
数据文件的创建任务
ment数据文件的创建，
利用Hadoop集群执行MapReduce任务以完成Seg-
描述
，负责集群资源管理与任务分配。
上删除
数据文件按照指定的聚合方法合
Druid实时大数据分析原理与实践
，适合体量比较大的Segment
---
## Page 81
管理。
时，Druid也通过其索引服务使得用户可以比较容易地与Druid集群进行交互，完成任务的
用户可以比较简单地对集群进行部署、分别优化以及运维，大大降低了集群的使用成本。同
据消费与探索的平台。Druid集群在构成上通过不同数据服务的明确分工及协同合作，使得
ment实现的精妙数据文件结构与组织方式，最终提供一个能够在大数据集上做高效实时数
3.9
第3章
混杂型
混杂型
父类
Druid在架构上借鉴了LSM-tree及读写分离的思想，并且通过其基于DataSource与 Seg-
小结
架构详解
noop
segment
convert
Type
务
无
中
版
名
操作任
务
本转换
称
作。通常用来做测试用途
将任务启动并沉睡一段时间，并不完成具体的任何工
件的版本转换
文件的版本转换，适合体量比较小的Segment数据文
会利用Druid集群本身的系统资源完成Segment数据
描述
续表
5
---
## Page 82
4.1.1安装包简介
4.1
Zookeeper、MySQL和HDFS。本章将从如下几部分重点介绍Druid的安装部署和配置。
节点组成，同时为了实现节点间的信息同步和服务高可用性，其还依赖一些外部组件如
安装与配置
第
·源代码编译：github.com/druid-io/druid/releases，这种方式更多的是出于定制化需求的
获取Druid安装包有以下几种方式。
·如何搭建一个Druid集群以及关键配置说明。
·通过一个简单例子快速上手Druid的数据导人和查询。
·Druid服务的安装部署（单机版用于测试学习，集群版用于生产环境）。
服务的搭建与运行是认识Druid的第一步，采取分布式设计的Druid由不同职责的