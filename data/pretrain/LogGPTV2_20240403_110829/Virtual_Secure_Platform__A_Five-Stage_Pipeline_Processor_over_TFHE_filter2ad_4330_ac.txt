our custom ISA in such a way that the circuit of the processor
can be minimized, while retaining C compatibility.
(iii) Maximizing Parallelism
Figure 4: The VSP architecture and the main procedural ﬂow.
As mentioned, the amount of parallelism in VSP (and gen-
erally in lattice-based cryptography) exceeds the parallel pro-
cessing capability of conventional desktop computers. How-
ever, we point out that cloud vendors may have much more
computational resources available than a home computer. To
fully leverage the computational resources available in data
centers, we designed the processor architecture in VSP to have
a pipelined structure, where the processor circuit is divided
into different pipeline stages that can be evaluated simulta-
neously. We assert that the pipeline technique does affect
the execution time when the physical machine does not have
much parallel processing capability. However, the runtime of
VSP can be signiﬁcantly reduced by the pipeline technique
when there are enough physical processor cores.
6.2 The Architecture of VSP
Notation: In this paper, physical machine is the actual pro-
cessing unit that runs VSP. CPU and GPU refers the physical
CPU or GPU in the physical machine. In contrast, we use
processor to refer to the virtual processor constructed over
TFHE in VSP.
The visual overview of the implemented protocol ﬂow of
the proposed VSP framework is given in Figure 4, which
details the abstract protocol ﬂow in Figure 3. Table 1 shows
USENIX Association
30th USENIX Security Symposium    4013
(a)TFHEppC code(c) CAHPv3executable(plaintext)Result(plaintext)(b) llvm-cahpEncryptedresult(d)IyokanProcessorCircuit(netlist)(e)CAHP-RubyorCAHP-Pearl(Chisel)Secret key(f)sbt & Yosys(a)cuFHEABCConvert A to B by CABImplement B with A3. Compilation(kvsp-cc)6. Decryption(kvsp-dec)4. Encrypt(kvsp-enc)5. Evaluation(kvsp-run)AliceBob(a)TFHEpp(kvsp-genkey)1. Key GenerationBootstraping key2. Registration(kvsp-genbkey)7. Resumption(kvsp-resume)(a)TFHEppRAMROM(a)TFHEpp?TerminationFlagSnapshotInputTable 1: The Phases of VSP and the Associated Subcommands of the Command-Line Interface kvsp
Phase
Key Generation
Subcommand
Modules
kvsp-gen
(a)
Registration
kvsp-genbkey
(a)
kvsp-cc
(b), (c)
Compilation Encryption Evaluation Decryption
kvsp-dec
kvsp-enc
(c)
kvsp-run
(a), (d)
Resumption
kvsp-resume
(a), (d)
(a)
which phase each subcommand of kvsp [31] (a command-line
user interface for VSP) corresponds to and by which module
is called. Each subcommand of kvsp takes its inputs as a ﬁle,
and outputs its results to a ﬁle. Therefore, the communication
between the parties can be done via ﬁles transferring through
public channels.
We ﬁrst describe how the modules (a)-(f) are used here.
Then, we explain each module. In this work, we name our
proposed processor circuits as (e) CAHP-Ruby and CAHP-
Pearl, and the details on the circuits are explained in Section 7.
It is assumed that Alice and Bob agree on which processor ar-
chitecture will be used in advance. (f) sbt [33] and Yosys [34]
are used to convert the Chisel code for the processor into a
JSON netlist. Here, the netlist is a graph of nodes, where each
node corresponds to a logic gate. The netlist is provided to
Bob before the start of the protocol. In Key Generation phase,
Alice uses (a) TFHEpp, a C++ implementation of TFHE on
CPU, to generate a secret key. In Registration phase, Alice
uses (a) TFHEpp one more times to generate the Bootstrap-
ping Key from the secret key and sends the Bootstrapping
Key to Bob. In Compilation phase, Alice uses (b) llvm-cahp,
our C compiler for our custom ISA called (c) CAHPv3, to
generate executable binaries. In Encryption phase, Alice uses
(a) TFHEpp to encrypt the executable binaries and the input
into encrypted ROM and RAM. Then, Alice sends the ROM
and RAM to Bob. In Evaluation phase, Bob uses (d) Iyokan to
evaluate the processor circuit netlist over TFHE with the given
encrypted ROM and RAM data. (a) TFHEpp and cuFHE,
the CUDA implementation of TFHE on GPU, are used in
(d) Iyokan to perform homomorphic computations. Then,
Bob sends back the encrypted result to Alice. In Decryption
phase, (a) TFHEpp is used to decrypt the encrypted result. In
Resumption phase, Alice checks the termination ﬂag in the
result. If it is 1, she terminates the protocol. Otherwise, Alice
tells Bob to resume evaluation. Bob again runs (d) Iyokan for
the new round of homomorphic evaluation.
(a) TFHEpp and cuFHE: The TFHE libraries
TFHEpp is our fully-scratch C++17 implementation of TFHE
on the CPU, while cuFHE is a TFHE library on the GPU (we
optimized the original TFHE library from [35, 36]).
In general, cuFHE is faster than TFHEpp, especially when
multiple logic gates are run in parallel, as the throughput of
GPU is higher than that of CPU. We describe how we use
these libraries in (d) Iyokan.
While TFHEpp supports Circuit Bootstrapping, which is a
necessary component of CMUX Memory, cuFHE does not.
cuFHE uses Number Theoretic Transform (NTT) to perform
fast polynomial multiplication, where the ciphertext modulus
is kept to be 264 − 232 + 1. This bit width constraint is to en-
sure that the operands involved in NTT ﬁt into the multiply
instructions on the GPUs. Unfortunately, due to this bit width
constraint, cuFHE cannot directly perform Circuit Bootstrap-
ping, as the moduli required by Circuit Bootstrapping needs
to be larger than 64-bit. While we can simply increase the
size of modulus to be compatible with Circuit Boostrapping,
the performance of cuFHE in practice will be signiﬁcantly re-
duced as more multiplication instructions (on the GPUs) and
memory accesses are required to perform a single polynomial
multiplication operation. The efﬁcient implementation of Cir-
cuit Bootstrapping on GPUs currently remain as an open ﬁeld
of study.
(b) llvm-cahp: The C Compiler
We implemented a new C compiler llvm-cahp for our ISA,
CAHPv3, using LLVM9.
The LLVM compiler infrastructure project is an assemblage
of compiler and toolchain technologies [32], which serves as
a good foundation for our custom processor architecture and
ISA. LLVM is widely used in both open and closed projects as
well as used in academia [37]. In particular, LLVM surpasses
GCC to win the ACM Software System Award in 2012 [38].
LLVM includes four parts. First, we have language-dependent
frontends that compile the program source code into the in-
termediate representation named LLVM IR. Second, LLVM
has a target-independent optimizer that operates on LLVM IR.
Third, the LLVM target-speciﬁc backends are used to gener-
ate the object code of each target from LLVM IR. Finally, the
LLVM linker turns multiple object codes into one executable.
Since we deﬁned a custom ISA, we implemented a new back-
end for CAHPv3. We also added support for CAHPv3 to the
frontend of the C language (i.e., Clang), and to the LLVM
linker (i.e., LLD). By putting them together, we can directly
compile C program into a CAHPv3 executable binary ﬁle.
Our compiler supports almost all features of C such as
basic arithmetic operations, control expressions, function calls
including recursion, structures, and so on. Furthermore, since
LLVM has the target-independent optimizer as mentioned
above, llvm-cahp can output fast and small executables by
using the -O3 or -Oz compiler options.
Since the proposed processor is a virtual one, our modiﬁed
compiler does not provide functions in standard libraries that
4014    30th USENIX Security Symposium
USENIX Association
require physical processor components (e.g., the print func-
tion). There are also some minor limitations (e.g., jump over
1kiB) in our compiler.
(c) CAHPv3: Instruction Set Architecture
CAHPv31 is our RISC ISA based on RISC-V 32-bit integer
and 16-bit compressed instructions (RV32IC). CAHPv3 has
16-bit datapath and sixteen 16-bit registers. However, the in-
struction bit width is a mixture of 24 bits and 16 bits, since
we want to minimize the size of the machine code.
CAHPv3 has two important features from the perspectives
of our design goals. First, it is relatively easy to implement the
LLVM backend for CAHPv3, due to its similarities to main-
stream ISAs such as x86 and RISC-V. We note that this is one
of the main reasons why the OISC used in FURISC is consid-
ered impractical. Second, CAHPv3 reduces the complexity
of the processor circuitry because it is a RISC ISA, and the
datapath is only of 16-bit wide. Unlike RV32IC, CAHPv3
does not include instructions that are not necessary in VSP,
such as privileged instructions and synchronization instruc-
tions, further reducing the total gate count. The speciﬁcation
is here [39].
(d) Iyokan: The Gate Evaluation Engine
Iyokan is our main software written in C++17 to run the pro-
cessor over TFHE. The fundamental features of Iyokan are to
receive an arbitrary Boolean circuit along with the encrypted
input data, evaluate the circuits according to the inputs over
TFHE, and return encrypted results of the evaluation. There-
fore, we can execute encrypted programs without decryption
by feeding Iyokan with the processor as a logical circuit and
the associated inputs.
Iyokan works in the following way:
edges in the DAG. Almost all the tasks are executed on
GPUs via cuFHE, and the rest of the tasks which can-
not be run on GPUs, such as Circuit Bootstrapping, are
executed on CPUs via TFHEpp.
This step gives us the output of the combinational circuit
in the current cycle, which is used as the inputs to the
ﬂip-ﬂops.
4. Save the inputs the previous step provides to the ﬂip-
ﬂops (physical memories).
5. Output the stored values in the ﬂip-ﬂops.
6. Exit if the number of clock cycles exceeds the threshold
which is speciﬁed by the user through command-line
option. Otherwise, go to step 3.
Each evaluation from step 3 to 6 corresponds to one clock
cycle. As mentioned in Section 4.1, Alice has to decide a
threshold, that is, how many times the steps between step 3
and 6 should be repeated.
There are two important features of Iyokan. First, Iyokan
can handle not only normal logic gates but also CMUX Mem-
ory. CMUX Memory can be represented as a scheduled graph,
so it can also be embedded in the DAG. Second, Iyokan can
run more than one worker on CPUs and GPUs in parallel.
(e) CAHP-Ruby, CAHP-Pearl: Processor
We developed two processors, CAHP-Ruby and CAHP-Pearl,
for VSP:
CAHP-Ruby CAHP-Ruby is a 5-stage pipeline processor
that implements CAHPv3 ISA. We will explain its de-
tails in Section 7.
1. Split the input sequential logical circuit into two parts:
combinational circuits and ﬂip-ﬂops to represent general
Boolean circuits.
CAHP-Pearl CAHP-Pearl is a single cycle processor that
also implements CAHPv3 ISA. We made it by just re-
moving pipeline registers from CHAP-Ruby.
2. Convert the combinational circuits into a directed acyclic
graph (DAG), where the logical gates are represented
as graph nodes, and wires as directed edges. Figure 1b
shows an example graph representation of the half adder
circuit in Figure 1a.
3. Evaluate the DAG by using the converted circuit along
with its inputs and the outputs of the ﬂip-ﬂops. Since ev-
ery node in the DAG has to be evaluated, Iyokan uses the
list scheduling algorithm to assign the tasks to workers
which are physical CPU and GPU processing units. Note
here that the scheduling algorithm also needs to resolve
the dependency relations between nodes represented as
1CAHP is short for “CAHP Ain’t for Hardware Processors,” and v3 means
this is our third version ISA for VSP (the former two did not work well).
(f) sbt and Yosys: Logic Synthesis
We chose Chisel [40], a particular Hardware Description Lan-
guage (HDL), to instantiate our processors for VSP, as Chisel
is widely adopted in the industry [41]. The sbt program com-
piles Chisel to the Verilog HDL. Then, Yosys [34] is utilized
to compile Verilog codes into JSON netlists.
7 The Proposed Processor Architecture
Figure 5 conceptually illustrates CAHP-Ruby, the proposed
custom processor architecture. CAHP-Ruby has a ﬁve-stage
pipeline structure consisting of an Instruction Fetch, an In-
struction Decode, an Execution, a Memory Access, and a Write
USENIX Association
30th USENIX Security Symposium    4015
Figure 5: The architecture of the ﬁve-stage pipelined CAHP-
Ruby processor.
Back stage. We chose a ﬁve-stage construction, as this struc-
ture is widely used in physical processor designs [42–45]. De-
termining the optimal number of pipeline is actually platform-
dependent, i.e., it depends on the physical resources available
to VSP. A framework that automatically optimizes the number
of pipeline stage is one of our main future works.
CAHP-Ruby has two different memory areas: ROM and
RAM, as shown in Figure 5. This structure greatly simpliﬁes
the processor circuitry and enables each memory area to have
different and optimized implementations, further discussed in
Section 8. Here, ROM is a read-only memory area, designated
for the compiled instructions. RAM permits both read and
write operations, and is mainly for program data handling.
We note that CAHP-Ruby does not support any peripheral
devices nor interruption because they are not needed in a
virtual processor. Through such design decisions, we are able
to reduce the complexity of the CAHP-Ruby circuitry.
In what follows, we detail the operational behavior of each
of our custom processor stages.
Instruction Fetch (IF): IF is responsible for producing
an instruction. First, IF fetches a 32-bit block from ROM.
However, the block may not contain any complete instructions
due to the fact that our custom ISA contains both 16-bit and
24-bit instructions. Therefore, IF includes a 32-bit instruction
cache to resolve this 24/16-bit boundary alignment problem.
The cache contains ROM output value of the previous clock
cycle. If the currently fetched 32-bit ROM block does not
contain a complete instruction, data from the instruction cache
can be read, and it is guaranteed that there will always be a
complete instruction in a 64-bit ROM block. Therefore, IF
constructs a complete instruction with the assistance of the
instruction cache and the current ROM output value.
Instruction Decode (ID): ID decodes the instruction to
provide operands for the execution stage. This stage also
reads the data from the registers speciﬁed by the instruction
in the main register ﬁle. ID is also responsible for generating
the termination ﬂag. In this work, we indicate a program
termination by inserting a jump instruction which jumps to
the same its own memory address, creating an inﬁnite loop.
Once the ID stage detects such loop, the termination ﬂag is
set, and can be read from the dedicated port.
Execution (Ex): This stage consists of an arithmetic and
logical unit (ALU) and a branch controller. ALU performs
(homomorphic) arithmetic operations such as addition and
subtraction, and logical operations such as logical summation,
and shift. In the case of a jump instruction or a branch instruc-
tion, the branch controller generates a ﬂag indicating whether
to jump or not according to the result of the ALU operation.
We assert that all the computations and branches are over FHE
ciphertexts, guaranteeing that the processor circuit evaluator
does not observe any private information.
Memory Access (Mem): This stage consists of two parts:
memory controller and RAM. We defer a detailed presentation
of the RAM in Section 8. The memory controller takes write
data from the execution stage as its input. When the write
data is 8-bit wide, the controller converts the write data to be
of 16-bit wide, for the RAM only accepts 16-bit data. The
memory controller also reads the data from the read port of
RAM and format when the output value to be of 8-bit wide.
Finally, the memory controller passes the read data from the
RAM to the write back stage.
Write Back (WB): This stage simply writes data into the
main register ﬁles.
8 CMUX Memory
In this section, we present CMUX Memory, a new construc-
tion of memory unit over HE that leverages the LHE mode of
TFHE for optimization. As mentioned, there are two types of
memories: RAM and ROM.
8.1 Theoretical Speed Predictions