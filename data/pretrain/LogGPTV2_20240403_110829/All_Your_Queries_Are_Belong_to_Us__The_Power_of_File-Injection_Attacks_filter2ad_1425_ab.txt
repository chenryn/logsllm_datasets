with roughly 5,000 keywords (see Section 5 for further
details), the average number of keywords per email is 90;
only 3% of the emails contain more than 200 keywords.
Using the threshold countermeasure with T = 200 would
thus affect only 3% of the honest client’s files, but would
require the server to inject many more files in order to
carry out a naive variant of the binary-search attack.
Specifically, the server could replace each file Fi (that
contains |K|/2 keywords) in the basic attack with a se-
quence of |K|/2T files Fi,1, . . . ,Fi,|K|/2T each containing
T keywords, such that ∪ jFi, j = Fi. If any of these files is
returned, this is equivalent to the original file Fi being re-
turned in the basic attack. Note, however, that the server
must now inject |K|/2T · log|K| files. Unfortunately, as
we explore in detail in the following section, the thresh-
old countermeasure can be defeated using fewer injected
files via more-sophisticated attacks.
Note also that the threshold countermeasure does not
affect the binary-search attack with small keyword uni-
verse K(cid:31) ⊂ K, as long as |K(cid:31)| ≤ 2T .
4 Advanced Attacks
In this section, we present more-sophisticated attacks
for when the threshold countermeasure introduced in the
previous section is used. In Section 4.1 we show an at-
tack that uses fewer injected files than a naive modifica-
tion of the binary-search attack, still without any knowl-
edge of the client’s files. Then, in the following section,
we show attacks that reduce the number of injected files
even further, but based on the assumption that the server
has information about some fraction of the client’s files.
4.1 Hierarchical-Search Attack
We noted earlier that the threshold countermeasure does
not affect the binary-search attack with small keyword
universe K(cid:31) ⊂ K if |K(cid:31)| ≤ 2T . We can leverage this to
learn keywords in the entire universe using what we call
a hierarchical search attack. This attack works by first
partitioning the keyword universe into (cid:24)|K|/T(cid:23) subsets
containing T keywords each. The server injects files con-
taining the keywords in each subset to learn which subset
the client’s keyword lies in. In addition, it uses the small-
universe, binary-search attack on adjacent pairs of these
subsets to determine the keyword exactly. The algorithm
is presented in Figure 3.
sets K1, . . . ,Kw of T keywords each.
Algorithm F ← Inject Files hierarchical(K)
1: Partition the universe into w = (cid:24)|K|/T(cid:23) sub-
2: for i = 1,2, . . . ,w do
3:
4: for i = 1,2, . . . ,w/2 do
5:
6: Output F = {F1, . . . ,Fw,F1, . . . ,F w/2}.
Algorithm k ← Recover hierarchical(R,K)
1: Parse the search result R as
Generate Fi containing every keyword k ∈ Ki.
Fi ← Inject Files(K2i−1 ∪ K2i).
R = {r1, . . . ,r w,R1, . . . ,R w/2} ,
corresponding to the results on the files in F
described above.
2: Using the {ri}, identify the subset K2x−1 ∪ K2x
the unknown keyword lies in.
3: k ← Recover(Rx,K2x−1 ∪ K2x).
Figure 3: The hierarchical-search attack. T is the thresh-
old determining the maximum number of keywords in a
file. R denotes the search results on the injected files.
Inject Files and Recover are from Figure 2.
We now calculate the number of injected files required
In Step 3 of Inject Files hierarchical,
by this attack.
the server injects (cid:24)|K|/T(cid:23) files, and in Step 5 it injects
(cid:24)|K|/2T(cid:23) · (cid:24)log2T(cid:23) files. The total number of injected
files is therefore at most
(cid:24)|K|/2T(cid:23)· ((cid:24)log2T(cid:23) + 2) .
In fact, for each i the first file in the set Fi generated
by Inject ﬁles(K2i−1 ∪ K2i) is the same as F2i−1 and the
server does not need to inject it again. Also, the server
does not need to generate Fw in Step 3 because if the
keyword is not in F1, . . . ,Fw−1 then the server knows it
must be in Fw. So the total number of injected files can
710  25th USENIX Security Symposium 
USENIX Association
4
be improved to
(cid:31)|K|/2T(cid:29)· ((cid:31)log2T(cid:29) + 1)− 1 .
When the size of the keyword universe is |K| = 5,000
and the threshold is T = 200, the server needs to inject
only 131 files, and the number of injected files grows lin-
early with the size of the keyword universe. We highlight
again that the same injected files can be used to recover
the keywords corresponding to any number of tokens;
i.e., once these files are injected, the server can recover
the keywords of any future searches made by the client.
We remark that an adaptive version of the above at-
tack is also possible. Here, the attacker would first in-
ject (cid:31)|K|/T(cid:29)−1 files to learn what subset the unknown
keyword lies in, and then carry out the small-universe,
binary-search attack on a subset of size T . This requires
only (cid:31)|K|/T(cid:29) + logT − 1 injected files, but has the dis-
advantage of being adaptive and hence requires the SE
scheme to not satisfy forward privacy. This version of
the attack also has the disadvantage of targeting one par-
ticular search query of the client; additional files may
need to be injected to learn the keyword used in some
subsequent search query.
4.2 Attacks Using Partial Knowledge
With the goal of further decreasing the number of in-
jected files required to recover a token in presence of the
threshold countermeasure, we now explore additional at-
tacks that leverage prior information that the server might
have about some of the client’s files; we refer to the
files known to the server as leaked ﬁles.2 A similar as-
sumption is used in prior work showing attacks on SE
schemes [10, 4]; previous attacks, however, require the
server to know about 90% of the client’s files to be effec-
tive (see Section 5), whereas our attacks work well even
when the server knows a much smaller fraction of the
client’s files.
Our attacks utilize the frequency of occurrence of the
tokens and keywords in the client’s files. We define the
frequency of a token (resp., keyword) as the fraction of
the client’s files containing this token (resp., keyword).
Similarly, we define the joint frequency of two tokens
(resp., keywords) as the fraction of files containing both
tokens (resp., keywords). The server learns the exact fre-
quency (resp., joint frequency) of a token (resp., pair of
tokens) based on the observed search results. The server
obtains an estimate of the frequencies (resp., joint fre-
quencies) of all the keywords based on the client’s files
that it knows. We let f (t) denote the exact (observed) fre-
quency of token t, and let f (t1,t2) be the joint frequency
2We stress that our attacks only rely on the content of these leaked
files; we do not assume the server can identify the file identifiers corre-
sponding to the leaked files after they have been uploaded to the server.
Algorithm k ← Inject Files Single(t,K)
1: Let K(cid:25) be the set of 2T keywords with esti-
mated frequencies closest to f (t).
2: F ← Inject Files(K(cid:25)).
Algorithm k ← Recover Single(R,K(cid:25))
1: If R contains all 0s, output ⊥.
2: Else k ← Recover(R,K(cid:25)).
Figure 4: Recovering a single keyword using partial file
knowledge. T is the threshold determining the maximum
number of keywords in a file. R denotes the search results
on the injected files. Inject Files and Recover are from
Figure 2.
of tokens t1,t2. We use f ∗(k) to denote the estimated fre-
quency of keyword k, and define f ∗(k1,k2) analogously.
Our attacks use the observation that if the leaked files are
representative of all the client’s files, then f (t) and f ∗(k)
are close when t is the token corresponding to keyword k.
4.2.1 Recovering One Keyword
Say the server obtains a token t sent by the client, hav-
ing observed frequency f (t). The server first constructs
a candidate universe K(cid:25) for the keyword corresponding
to t consisting of the 2T keywords whose estimated fre-
quencies are closest to f (t). The server then uses the
small-universe, binary-search attack to recover the key-
word exactly. In this way, the number of injected files is
only (cid:31)log2T(cid:29). The attack is presented in detail in Fig-
ure 4.
Differences from attacks in previous sections. The at-
tack just described is adaptive, in that it targets a par-
ticular token t and injects files whose contents depend
on the results of a search using t. This means the attack
only applies to SE schemes that do not satisfy forward
privacy. It also means that the attack needs to be carried
out again in order to learn the keyword corresponding to
some other token.
Another difference from our previous attacks is that
this attack does not work with certainty.
In particular,
if the observed and estimated frequencies are far apart,
or the number of keywords whose estimated frequencies
are close to the observed frequency is larger than 2T , the
server may fail to recover the keyword corresponding to
the token. On the other hand, the server can tell whether
the attack succeeds or not, so will never associate an in-
correct keyword with a token. This also means that if
the attack fails, the attacker can re-run the attack with
a different candidate universe, or switch to using one of
our earlier attacks, in order to learn the correct keyword.
USENIX Association  
25th USENIX Security Symposium  711
5
(We rely on this feature to design an attack for multiple
tokens in the following section.) This is in contrast to
earlier attacks [10, 4], where the attacker cannot always
tell whether the keyword was recovered correctly.
4.2.2 Recovering Multiple Keywords
To learn the keywords corresponding to m tokens, the
server can repeat the attack above for each token, but
then the number of injected files will be (in the worst
case) m · (cid:30)log2T(cid:29). A natural way to attempt to reduce
the number of injected files is for the server to determine
a candidate universe of size 2T for each token and then
use the union of those candidate universes when injecting
the files. In that case, however, the union would almost
surely contain more than 2T keywords, in which case the
number of keywords in the files produce by the binary-
search attack will exceed the threshold T .
A second approach would be for the server to make the
size of the candidate universe for each token 2T /m, so
the size of their union cannot exceed 2T keywords. Here,
however, if m is large then the candidate universe for
each token is very small and so the probability of the cor-
responding keyword not lying in its candidate universe
increases substantially. Therefore, the recovery rate of
this attack would be low.
Instead, we propose a more-complex attack that recov-
ers multiple tokens by taking into account the joint fre-
quencies for tokens and keywords. Our attack has two
main steps (see Figure 5):
1. First, we recover the keywords corresponding to
a subset of the tokens, namely the n (cid:28) m tokens
with the highest observed frequencies. We recover
the keywords using the second approach sketched
above, which works (with few injected files) be-
cause n is small. This gives us as a set of tokens
and their associated keywords as “ground truth.”
2. Given the ground truth, we recover the keyword as-
sociated with some other token t(cid:27) using the follow-
if k(cid:27) is the keyword correspond-
ing observation:
ing to t(cid:27), then the observed joint frequency f (t,t(cid:27))
should be “close” to the estimated joint frequency
f ∗(k,k(cid:27)) for all pairs (t,k) in our ground-truth set,
where “closeness” is determined by a parameter δ .
By discarding candidate keywords that do not sat-
isfy this property, we are left with a small set K(cid:27)
of candidate keywords for t(cid:27). If the candidate uni-
verse of keywords for each token is small enough,
then even their union will be small. We then use a
small-universe, binary-search attack to recover the
corresponding keywords exactly.
Note that in the above attack the ability to tell whether a
token is recovered correctly when building the ground
truth is crucial—otherwise the ground-truth set could
contain many incorrect associations.
Parameter selection. Our attack has two parameters: n
and δ . A larger value of n means that the ground-truth
set can potentially be larger, but if n is too large then
there is a risk that the candidate universe Kt (comprising
the 2T /n keywords with estimated frequencies closest
to f (t)) will not contain the true keyword corresponding
to t. In our experiments, we set n heuristically to a value
that achieves good performance.
The value of δ is chosen based on statistical-
estimation theory. The estimated joint frequency is an
empirical average computed from a collection of leaked
files assumed to be sampled uniformly from the set of
all files. Thus, we set δ such that if keywords k,k(cid:27) cor-
respond to tokens t,t(cid:27), respectively, then the estimated
joint frequency f ∗(k,k(cid:27)) is within ±δ · f ∗(k,k(cid:27)) of the
true value f (t,t(cid:27)) at least 99% of the time.
Ground-truth set selection. When building the ground-
truth set, we recover the keywords associated with those
tokens having the highest observed frequencies. We do
so because those keywords can be recovered correctly
with higher probability, as we explain next.
If the leaked files are chosen uniformly from the set of
all files, then using statistical-estimation theory as above
the attacker can compute a value δ such that at least 99%
of the time it holds that | f ∗(k)− f (t)| ≤ε · f ∗(k), where
k denotes the (unknown) keyword corresponding to t.
Thus, if the attacker sets the candidate universe Kt to be
the set of all keywords whose estimated frequencies are
within distance ε · f ∗(k) of f (t), the candidate universe
will include the keyword corresponding to t at least 99%
of the time. The problem with taking this approach is
that the set Kt constructed this way may be too large.
If we assume a Zipfian distribution [3] for the keyword
frequencies, however, then the size of Kt as constructed
above is smallest when f (t) is largest. (This is a con-
sequence of the fact that the Zipfian distribution places
high probability on a few items and low probability on
many items.)
In particular, then, the set of 2T /n key-
words with estimated frequencies closest to f (t) (as cho-
sen by our algorithm), will “cover” all keywords within
distance ε · f ∗(k) of f (t) from f (t) – or, equivalently, the
candidate universe will contain the true keyword k – with
high probability.
5 Experiments
We simulate the attacks from Section 4. (We do not run
any simulations for the binary-search attack described in
Section 3, since this attack succeeds with probability 1,
injecting a fixed number of emails.) We compare our
attacks to our own implementation of the attacks by Cash
712  25th USENIX Security Symposium 
USENIX Association
6
t = {t1, . . . ,tm} is the set of m tokens whose keywords we wish to recover.
Algorithm k ← Attack Multiple Tokens(t,K)
Build ground truth set G.
1: Sort tokens in t according to their exact frequencies f (t). Let t1 denote the n tokens with highest observed
frequencies.
Set its candidate universe Kt as the set of 2T
n keywords with estimated frequencies f ∗(k) nearest to f (t).
Set its candidate universe Kt(cid:27) as the set of 2T keywords with estimated frequencies f ∗(k) nearest to f (t(cid:27)).
for each keyword k(cid:27) ∈ Kt(cid:27) do
for each token/keyword pair (t,k) ∈ G do
If | f (t,t(cid:27))− f ∗(k,k(cid:27))| > δ · f ∗(k,k(cid:27)), remove k(cid:27) from candidate universe Kt(cid:27).
kt ← Recover(Rt ,K(cid:27)).
Add (t,kt ) to G.
Let Rt be the search result of token t on files F1.
if Rt is not all 0s then
2: for each token t in t1 do
3:
4: Define K(cid:27) = ∪t∈t1Kt and inject files generated by F1 ← Inject Files(K(cid:27)).
5: for each token t in t1 do
6:
7:
8:
9:
Recover the remaining tokens, let t2 be the set of unrecovered tokens.
10: for each token t(cid:27) ∈ t2 do
11:
12:
13:
14:
15: Set K(cid:27)(cid:27) = ∪t(cid:27)∈t2Kt(cid:27).
16: if |K(cid:27)(cid:27)| ≤ 2T then
17:
18:
19:
20:
21: else
22:
23:
24:
25:
26: Output k that includes all recovered keywords.
F2 ← Inject Files(K(cid:27)(cid:27)).
for each token t(cid:27) ∈ t2 do