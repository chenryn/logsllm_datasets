如果你不需要担心如何查询与访问资料，那么储存资料通常是非常简单的。模式设计、索引和储存引擎的许多复杂性，都是希望支援某些特定查询和访问模式的结果（请参阅 [第三章](ch3.md)）。出于这个原因，透过将资料写入的形式与读取形式相分离，并允许几个不同的读取检视，你能获得很大的灵活性。这个想法有时被称为 **命令查询责任分离（command query responsibility segregation, CQRS）**【42,58,59】。
资料库和模式设计的传统方法是基于这样一种谬论，资料必须以与查询相同的形式写入。如果可以将资料从针对写入最佳化的事件日志转换为针对读取最佳化的应用状态，那么有关规范化和非规范化的争论就变得无关紧要了（请参阅 “[多对一和多对多的关系](ch2.md#多对一和多对多的关系)”）：在针对读取最佳化的检视中对资料进行非规范化是完全合理的，因为翻译过程提供了使其与事件日志保持一致的机制。
在 “[描述负载](ch1.md#描述负载)” 中，我们讨论了推特主页时间线，它是特定使用者关注的人群所发推特的快取（类似邮箱）。这是 **针对读取最佳化的状态** 的又一个例子：主页时间线是高度非规范化的，因为你的推文与你所有粉丝的时间线都构成了重复。然而，扇出服务保持了这种重复状态与新推特以及新关注关系的同步，从而保证了重复的可管理性。
#### 并发控制
事件溯源和变更资料捕获的最大缺点是，事件日志的消费者通常是非同步的，所以可能会出现这样的情况：使用者会写入日志，然后从日志衍生检视中读取，结果发现他的写入还没有反映在读取检视中。我们之前在 “[读己之写](ch5.md#读己之写)” 中讨论了这个问题以及可能的解决方案。
一种解决方案是将事件追加到日志时同步执行读取检视的更新。而将这些写入操作合并为一个原子单元需要 **事务**，所以要么将事件日志和读取检视储存在同一个储存系统中，要么就需要跨不同系统进行分散式事务。或者，你也可以使用在 “[使用全序广播实现线性一致的储存](ch9.md#使用全序广播实现线性一致的储存)” 中讨论的方法。
另一方面，从事件日志汇出当前状态也简化了并发控制的某些部分。许多对于多物件事务的需求（请参阅 “[单物件和多物件操作](ch7.md#单物件和多物件操作)”）源于单个使用者操作需要在多个不同的位置更改资料。透过事件溯源，你可以设计一个自包含的事件以表示一个使用者操作。然后使用者操作就只需要在一个地方进行单次写入操作 —— 即将事件附加到日志中 —— 这个还是很容易使原子化的。
如果事件日志与应用状态以相同的方式分割槽（例如，处理分割槽 3 中的客户事件只需要更新分割槽 3 中的应用状态），那么直接使用单执行绪日志消费者就不需要写入并发控制了。它从设计上一次只处理一个事件（请参阅 “[真的序列执行](ch7.md#真的序列执行)”）。日志透过在分割槽中定义事件的序列顺序，消除了并发性的不确定性【24】。如果一个事件触及多个状态分割槽，那么需要做更多的工作，我们将在 [第十二章](ch12.md) 讨论。
#### 不变性的局限性
许多不使用事件溯源模型的系统也还是依赖不可变性：各种资料库在内部使用不可变的资料结构或多版本资料来支援时间点快照（请参阅 “[索引和快照隔离](ch7.md#索引和快照隔离)” ）。Git、Mercurial 和 Fossil 等版本控制系统也依靠不可变的资料来储存档案的版本历史记录。
永远保持所有变更的不变历史，在多大程度上是可行的？答案取决于资料集的流失率。一些工作负载主要是新增资料，很少更新或删除；它们很容易保持不变。其他工作负载在相对较小的资料集上有较高的更新 / 删除率；在这些情况下，不可变的历史可能增至难以接受的巨大，碎片化可能成为一个问题，压缩与垃圾收集的表现对于运维的稳健性变得至关重要【60,61】。
除了效能方面的原因外，也可能有出于管理方面的原因需要删除资料的情况，尽管这些资料都是不可变的。例如，隐私条例可能要求在使用者关闭帐户后删除他们的个人资讯，资料保护立法可能要求删除错误的资讯，或者可能需要阻止敏感资讯的意外泄露。
在这种情况下，仅仅在日志中新增另一个事件来指明先前的资料应该被视为删除是不够的 —— 你实际上是想改写历史，并假装资料从一开始就没有写入。例如，Datomic 管这个特性叫 **切除（excision）** 【62】，而 Fossil 版本控制系统有一个类似的概念叫 **避免（shunning）** 【63】。
真正删除资料是非常非常困难的【64】，因为副本可能存在于很多地方：例如，储存引擎，档案系统和 SSD 通常会向一个新位置写入，而不是原地覆盖旧资料【52】，而备份通常是特意做成不可变的，防止意外删除或损坏。删除操作更多的是指 “使取回资料更困难”，而不是指 “使取回资料不可能”。无论如何，有时你必须得尝试，正如我们在 “[立法与自律](ch12.md#立法与自律)” 中所看到的。
## 流处理
到目前为止，本章中我们已经讨论了流的来源（使用者活动事件，感测器和写入资料库），我们讨论了流如何传输（直接透过讯息传送，透过讯息代理，透过事件日志）。
剩下的就是讨论一下你可以用流做什么 —— 也就是说，你可以处理它。一般来说，有三种选项：
1. 你可以将事件中的资料写入资料库、快取、搜寻索引或类似的储存系统，然后能被其他客户端查询。如 [图 11-5](../img/fig11-5.png) 所示，这是资料库与系统其他部分所发生的变更保持同步的好方法 —— 特别是当流消费者是写入资料库的唯一客户端时。如 “[批处理工作流的输出](ch10.md#批处理工作流的输出)” 中所讨论的，它是写入储存系统的流等价物。
2. 你能以某种方式将事件推送给使用者，例如传送报警邮件或推送通知，或将事件流式传输到可实时显示的仪表板上。在这种情况下，人是流的最终消费者。
3. 你可以处理一个或多个输入流，并产生一个或多个输出流。流可能会经过由几个这样的处理阶段组成的流水线，最后再输出（选项 1 或 2）。
在本章的剩余部分中，我们将讨论选项 3：处理流以产生其他衍生流。处理这样的流的程式码片段，被称为 **运算元（operator）** 或 **作业（job）**。它与我们在 [第十章](ch10.md) 中讨论过的 Unix 程序和 MapReduce 作业密切相关，资料流的模式是相似的：一个流处理器以只读的方式使用输入流，并将其输出以仅追加的方式写入一个不同的位置。
流处理中的分割槽和并行化模式也非常类似于 [第十章](ch10.md) 中介绍的 MapReduce 和资料流引擎，因此我们不再重复这些主题。基本的 Map 操作（如转换和过滤记录）也是一样的。
与批次作业相比的一个关键区别是，流不会结束。这种差异会带来很多隐含的结果。正如本章开始部分所讨论的，排序对无界资料集没有意义，因此无法使用 **排序合并连线**（请参阅 “[Reduce 侧连线与分组](ch10.md#Reduce侧连线与分组)”）。容错机制也必须改变：对于已经运行了几分钟的批处理作业，可以简单地从头开始重启失败任务，但是对于已经执行数年的流作业，重启后从头开始跑可能并不是一个可行的选项。
### 流处理的应用
长期以来，流处理一直用于监控目的，如果某个事件发生，组织希望能得到警报。例如：
* 欺诈检测系统需要确定信用卡的使用模式是否有意外地变化，如果信用卡可能已被盗刷，则锁卡。
* 交易系统需要检查金融市场的价格变化，并根据指定的规则进行交易。
* 制造系统需要监控工厂中机器的状态，如果出现故障，可以快速定位问题。
* 军事和情报系统需要跟踪潜在侵略者的活动，并在出现袭击征兆时发出警报。
这些型别的应用需要非常精密复杂的模式匹配与相关检测。然而随著时代的进步，流处理的其他用途也开始出现。在本节中，我们将简要比较一下这些应用。
#### 复合事件处理
**复合事件处理（complex event processing, CEP）** 是 20 世纪 90 年代为分析事件流而开发出的一种方法，尤其适用于需要搜寻某些事件模式的应用【65,66】。与正则表示式允许你在字串中搜索特定字元模式的方式类似，CEP 允许你指定规则以在流中搜索某些事件模式。
CEP 系统通常使用高层次的宣告式查询语言，比如 SQL，或者图形使用者介面，来描述应该检测到的事件模式。这些查询被提交给处理引擎，该引擎消费输入流，并在内部维护一个执行所需匹配的状态机。当发现匹配时，引擎发出一个 **复合事件**（即 complex event，CEP 因此得名），并附有检测到的事件模式详情【67】。
在这些系统中，查询和资料之间的关系与普通资料库相比是颠倒的。通常情况下，资料库会持久储存资料，并将查询视为临时的：当查询进入时，资料库搜寻与查询匹配的资料，然后在查询完成时丢掉查询。CEP 引擎反转了角色：查询是长期储存的，来自输入流的事件不断流过它们，搜寻匹配事件模式的查询【68】。