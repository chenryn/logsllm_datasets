# Title: Vulnerability Discovery with Function Representation Learning from Unlabeled Projects

## Authors:
- Guanjun Lin
- Jun Zhang
- Wei Luo
- Lei Pan
- Yang Xiang

## Affiliations:
- **Guanjun Lin, Jun Zhang, Wei Luo, Lei Pan**
  - School of Information Technology, Deakin University, Geelong, VIC, Australia
  - Email: {lingu, jun.zhang, wei.luo, l.pan}@deakin.edu.au
- **Yang Xiang**
  - Digital Research & Innovation Capability Platform, Swinburne University of Technology, Melbourne, VIC, Australia
  - Email: [PI:EMAIL]

## Abstract
In cybersecurity, the discovery of vulnerabilities in source code is a fundamental problem. Machine learning (ML) techniques have gained significant attention for automating this process. However, existing ML-based methods often focus on component or file-level detection, requiring substantial human effort to pinpoint vulnerable code fragments. Additionally, using source code files limits the generalizability of ML models across different projects. This paper addresses these challenges by targeting function-level vulnerability discovery in a cross-project scenario. We propose a function representation learning method that leverages abstract syntax trees (ASTs) to obtain high-level and generalizable function representations. First, serialized ASTs are used to learn project-independent features. Then, a customized bi-directional LSTM neural network is employed to learn sequential AST representations from a large number of raw features. Our approach demonstrates promising performance gains, validated using a unique dataset where we manually labeled over 6000 functions from three open-source projects. The results confirm the potential of our AST-based function representation learning.

## Keywords
vulnerability detection, cross-project, AST, representation learning

## 1. Introduction
Vulnerability detection is crucial for mitigating security risks in software. Early and accurate detection is essential, making machine learning (ML) based automatic vulnerability detection techniques increasingly preferred as manual inspection becomes infeasible with the exponential growth of program source codes. Scandariato et al. [5] applied ML techniques to detect vulnerable components in Android applications, while Shin et al. [6] used models trained on early versions of Firefox and Linux kernel to detect vulnerable files in subsequent versions. These approaches primarily focus on component- or file-level vulnerability detection. Yamaguchi et al. [7] proposed a finer-grained approach for extrapolating vulnerable functions, but their method is limited to within-project domains.

In this paper, we propose an approach for function-level vulnerability detection in a cross-project scenario. We overcome the challenge of obtaining manual labels by leveraging well-understood complexity metrics, which can be automatically generated at scale. These metrics are used to bootstrap the generation of rich AST representations. Our approach assumes that vulnerable programming patterns are associated with many potential vulnerabilities and can be discovered by analyzing the program's ASTs. We use bi-directional Long Short-Term Memory (LSTM) networks to capture local and relational features in functions. Our empirical studies show that the obtained representations reveal important signals that distinguish between neutral and vulnerable functions.

Our contributions are as follows:
- We propose a learning framework for function-level vulnerability detection.
- We develop an approach to extract sequential features from ASTs, representing the structural information of functions for vulnerability detection.
- We implement a stacked LSTM network and use a proxy as a substitute for data labels to acquire high-level AST representations, which can be used as indicators for vulnerability detection.

## 2. Function Representation Learning
### 2.1 Data Collection and Processing
Figure 1 illustrates the workflow of our proposed framework, which consists of four stages:
1. **Data Collection**: We use three open-source projects: LibTIFF, LibPNG, and FFmpeg, whose source code is available on GitHub.
2. **Feature Extraction**: We extract raw features from the ASTs of functions.
3. **Model Training**: We design a stacked LSTM network and introduce a proxy for learning AST representations of functions.
4. **Evaluation**: We examine the prediction capability of the learned representations in detecting vulnerable functions in real-world cases.

#### 2.1.1 AST Sequential Processing
We use "CodeSensor1," a robust parser based on island grammars, to extract ASTs from source code without a working build environment. An AST represents programming patterns by depicting the structural information of the code. To preserve this structure, we use depth-first traversal to map AST nodes to vector elements. The sequence of elements in a vector partially reflects the hierarchical position of the nodes in the AST. For example, the vector might look like: [foo, int, params, int, x, stmnts, decl, int, y, op, =, call, bar,...]. The first element, "foo," is the function name, and the second element, "int," denotes the return type. To handle distinct naming conventions across projects, we normalize project-specific names by replacing them with "proj-specific" terms.

#### 2.2 Deep AST Representation
The similarity between ASTs and natural language sentences motivates us to apply LSTM for learning high-level representations. The vectors mapped from ASTs contain sequential context, preserving the tree structure. Altering the sequence changes the semantic meaning. LSTM is well-suited for handling such data, as it can capture long-term dependencies. We assume that vulnerable functions will display certain "linguistic" oddities discoverable by LSTM.

Our LSTM-based network has five layers:
1. **Embedding Layer**: Maps each element of the sequence to a fixed-dimensional vector.
2. **Stacked LSTM Layers**: Two bi-directional LSTM layers, each with 64 units (total 128 units per layer).
3. **Dense Layers**: Two dense layers with ReLU and Linear activation functions, converging a 128-dimensional output to a single dimension.
4. **Loss Function**: Mean Squared Error (MSE).

We feed the network with extracted ASTs from the three open-source projects and use a code metric as a proxy for obtaining the representations.

## 3. Empirical Study
We evaluate the effectiveness of the learned AST representations using the random forest algorithm. Among the functions used for obtaining AST representations, we manually label them as vulnerable or neutral to assess the performance of the learned representations in vulnerability detection.

## 4. Discussion
This work, although in its early stage, demonstrates the feasibility and potential of learning deep representations from ASTs and proxy metrics. Project-independent AST representations provide new angles for discovering vulnerable functions. Future research could explore alternative proxies, such as lines of code or cyclomatic complexity, and consider multi-task deep learning to avoid overfitting. A more flexible architecture, such as a sequence-to-sequence network, could further improve the generalizability of the representations. More labeled data will provide deeper insights into how deep learning can help reveal program vulnerabilities.

## 5. Conclusions
We propose an approach for automatically learning high-level representations of functions based on their ASTs. Using an AST parser, we extract functions' ASTs and convert them to vectors. To handle cross-project detection, we blur project-specific contents while preserving structural information, leveraging a stacked LSTM network to capture intrinsic patterns of vulnerable functions. Our experiments demonstrate that the learned representations are effective for cross-project vulnerability detection at the function level.

## Acknowledgements
Guanjun Lin is supported by the Australian Government Research Training Program Scholarship. This work was also supported by the National Natural Science Foundation of China (No. 61401371).

## References
[1] Istehad Chowdhury and Mohammad Zulkernine. 2011. Using complexity, coupling, and cohesion metrics as early indicators of vulnerabilities. Journal of Systems Architecture 57, 3 (2011), 294–313.

[2] Emanuel Giger, Marco D’Ambros, Martin Pinzger, and Harald C Gall. 2012. Method-level bug prediction. In Proceedings of the ACM-IEEE international symposium on Empirical software engineering and measurement. ACM, 171–180.

[3] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735–1780.

[4] Leon Moonen. 2001. Generating robust parsers using island grammars. In Reverse Engineering, 2001. Proceedings. Eighth Working Conference on. IEEE, 13–22.

[5] Riccardo Scandariato, James Walden, Aram Hovsepyan, and Wouter Joosen. 2014. Predicting vulnerable software components via text mining. IEEE Transactions on Software Engineering 40, 10 (2014), 993–1006.

[6] Yonghee Shin, Andrew Meneely, Laurie Williams, and Jason A Osborne. 2011. Evaluating complexity, code churn, and developer activity metrics as indicators of software vulnerabilities. IEEE Transactions on Software Engineering 37, 6 (2011), 772–787.

[7] Fabian Yamaguchi, Felix Lindner, and Konrad Rieck. 2011. Vulnerability extrapolation: assisted discovery of vulnerabilities using machine learning. In Proceedings of the 5th USENIX conference on Offensive technologies. USENIX Association, 13–13.

[8] Fabian Yamaguchi, Markus Lottmann, and Konrad Rieck. 2012. Generalized vulnerability extrapolation using abstract syntax trees. In Proceedings of the 28th Annual Computer Security Applications Conference. ACM, 359–368.

## Figure 2: R@K Comparison
The R@K (top-k recall) comparison between our method and random selection on a cross-project scenario. Our method identifies 20 vulnerable functions by checking the top 200 returned functions, while random selection only covers 27% of vulnerable functions when examining 200 randomly selected functions.