title:Towards Automatic Software Lineage Inference
author:Jiyong Jang and
Maverick Woo and
David Brumley
Towards Automatic Software Lineage Inference
Jiyong Jang, Maverick Woo, and David Brumley, Carnegie Mellon University
Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4Towards Automatic Software Lineage Inference
Jiyong Jang, Maverick Woo, and David Brumley
{jiyongj, pooh, dbrumley}@cmu.edu
Carnegie Mellon University
Abstract
Software lineage refers to the evolutionary relationship
among a collection of software. The goal of software
lineage inference is to recover the lineage given a set of
program binaries. Software lineage can provide extremely
useful information in many security scenarios such as
malware triage and software vulnerability tracking.
In this paper, we systematically study software lineage
inference by exploring four fundamental questions not
addressed by prior work. First, how do we automatically
infer software lineage from program binaries? Second,
how do we measure the quality of lineage inference al-
gorithms? Third, how useful are existing approaches to
binary similarity analysis for inferring lineage in reality,
and how about in an idealized setting? Fourth, what are
the limitations that any software lineage inference algo-
rithm must cope with?
Towards these goals we build ILINE, a system for auto-
matic software lineage inference of program binaries, and
also IEVAL, a system for scientiﬁc assessment of lineage
quality. We evaluated ILINE on two types of lineage—
straight line and directed acyclic graph—with large-scale
real-world programs: 1,777 goodware spanning over a
combined 110 years of development history and 114 mal-
ware with known lineage collected by the DARPA Cyber
Genome program. We used IEVAL to study seven metrics
to assess the diverse properties of lineage. Our results
reveal that partial order mismatches and graph arc edit
distance often yield the most meaningful comparisons in
our experiments. Even without assuming any prior infor-
mation about the data sets, ILINE proved to be effective
in lineage inference—it achieves a mean accuracy of over
84% for goodware and over 72% for malware in our data
sets.
1
Software evolves to adapt to changing needs, bug ﬁxes,
and feature additions [28]. As such, software lineage—the
evolutionary relationship among a set of software—can
be a rich source of information for a number of security
questions. Indeed, the literature is replete with analyses
of known or manually recovered software lineages. For
example, software engineering researchers have analyzed
Introduction
the histories of open source projects and the Linux kernel
to understand software evolution [14, 45] as well as its
effect on vulnerabilities in Firefox [33]. The security com-
munity has also studied malware evolution based upon the
observation that the majority of newly detected malware
are tweaked variants of well-known malware [2, 18, 20].
With over 1.1 million malware appearing daily [43], re-
searchers have exploited such evolutionary relationships
to identify new malware families [23, 31], create models
of provenance and lineage [9], and generate phylogeny
models based upon the notion of code similarity [22].
The wealth of existing research demonstrating the util-
ity of software lineage immediately raises the question—
“Can we infer software lineage automatically?” We fore-
see a large number of security-related applications once
this becomes feasible. In forensics, lineage can help de-
termine software provenance. For example, if we know
that a closed-source program pA is written by author X
and another program pB is derived from pA, then we may
deduce that the author of pB is likely to be related to X.
In malware triage [2, 18, 20], lineage can help malware
analysts understand trends over time and make informed
decisions about which malware to analyze ﬁrst. This is
particularly important since the order in which the vari-
ants of a malware are captured does not necessarily mirror
its evolution. In software security, lineage can help track
vulnerabilities in software of which we do not have source
code. For example, if we know a vulnerability exists in
an earlier version of an application, then it may also exist
in applications that are derived from it. Such logic has
been fruitfully applied at the source level in our previous
work [19]. Indeed, these and related applications are im-
portant enough that the US Defense Advanced Research
Projects Agency (DARPA) is funding a $43-million Cyber
Genome program [6] to study them.
Having established that automatically and accurately
infer software lineage is an important open problem, let
us look at how to formalize it. Software lineage inference
is the task of inferring a temporal ordering and ances-
tor/descendant relationships among programs. We model
software lineage by a lineage graph:
Deﬁnition 1.1. A lineage graph G = (N,A) is a directed
acyclic graph (DAG) comprising a set of nodes N and a
set of arcs A. A node n ∈ N represents a program, and
USENIX Association  
22nd USENIX Security Symposium  81
Straight(Line(Lineage
Set Distances
DAG(Lineage
5
Features 2
4
Datasets
Contiguous Revisions
Released Versions
Released Binaries
Malware
Symmetric Distance
Weighted Symmetric Distance
Dice Coefficient
Jaccard Distance
Jaccard Containment
Features 12
Section Size
File Size
Cyclomatic Complexity
n-grams
S/D Instructions
S/D Mnemonics
S/D Normalized Mnemonics
S/D Multi-resolution
Root Revision
2
Inferred Root
Real Root
Metrics
2
Inversions
Edit Distance to Monotonicity
S/D Multi-resolution
Root Revision
Inferred Root
Real Root
2
Timestamp
3
No Timestamp
Pseudo Timestamp
Real Timestamp
Datasets
2
DAG Revisions
Malware
Metrics
5
LCA Mismatches
Avg Distance to True LCA
Partial Order
Graph Arc Edit Distance
k-Cone
Figure 1: Design space in software lineage inference (S/D represents static/dynamic analysis-based features.)
an arc (x,y) ∈ A denotes that program y is a derivative of
program x. We say that x is a parent of y and y is a child
of x.
A root is a node that has no incoming arc and a leaf is
a node that has no outgoing arc. The set of ancestors of a
node n is the set of nodes that can reach n. Note that n is
an ancestor of itself. The set of common ancestors of x
and y is the intersection of the two sets of ancestors. The
set of lowest common ancestors (LCAs) of x and y is the
set of common ancestors of x and y that are not ancestors
of other common ancestors of x and y [4]. Notice that in
a tree each pair of nodes must have a unique LCA, but in
a DAG some pair of nodes can have multiple LCAs.
In this paper, we ask four basic research questions:
1. Can we automatically infer software lineage? Exist-
ing research focused on studying known software history
and lineage [14, 33, 45], not creating lineage. Creating
lineage is different from building a dendrogram based
upon similarity [22, 23, 31]. A dendrogram can be used
to identify families; however it does not provide any infor-
mation about a temporal ordering, e.g., root identiﬁcation.
In order to infer a temporal ordering and evolution-
ary relationships among programs, we develop new algo-
rithms to automatically infer lineage of programs for two
types of lineage: straight line lineage (§4.1) and directed
acyclic graph (DAG) lineage (§4.2). In addition, we ex-
tend our approach for straight line lineage to k-straight
line lineage (§4.1.4). We build ILINE to systematically
evaluate the effectiveness of our lineage inference algo-
rithms using twelve software feature sets (§2), ﬁve dis-
tance measures between feature sets (§3), two policies on
the root identiﬁcation (§4.1.1), and three policies on the
use of timestamps (§4.2.2).
Without any prior information about data sets, for
straight line linage, the mean accuracies of ILINE are
95.8% for goodware and 97.8% for malware. For DAG
lineage, the mean accuracies are 84.0% for goodware and
72.0% for malware.
2. What are good metrics? Existing research focused on
building a phylogenetic tree of malware [22, 23], but did
not provide quantitative metrics to scientiﬁcally measure
the quality of their output. Good metrics are necessary
to quantify how good our approach is with respect to the
ground truth. Good metrics also allow us to compare
different approaches. To this end, we build IEVAL to
assess our lineage inference algorithms using multiple
metrics, each of which represents a different perspective
of lineage.
IEVAL uses two metrics for straight line lineage (§5.1).
Given an inferred lineage graph G and the ground truth
G∗, the number of inversions measures how often we
make a mistake when answering the question “which one
of programs pi and p j comes ﬁrst”. The edit distance
to monotonicity asks “how many nodes do we need to
remove in G so that the remaining nodes are in the sorted
order (and thus respect G∗)”.
IEVAL also utilizes ﬁve metrics to measure the accuracy
of DAG lineage (§5.2). An LCA mismatch is a generalized
version of an inversion because the LCA of two nodes
in a straight line is the earlier node. We also measure
the average pairwise distance between true LCA(s) and
derived LCA(s) in G∗. The partial order mismatches in
a DAG asks the same question as inversions in a straight
line. The graph arc edit distance for (labeled) graphs mea-
sures “what is the minimum number of arcs we need to
delete from G and G∗ to make both graphs equivalent”. A
k-Cone mismatch asks “how many nodes have the correct
set of descendants counting up to depth k”.
Among the above seven metrics, we recommend two
metrics—partial order mismatches and graph arc edit dis-
tance. In §5.3, we discuss how the metrics are related,
which metric is useful to measure which aspect of a lin-
eage graph, which metric is efﬁcient to compute, and
which metric is deducible from other metrics.
3. How well are we doing now? We would like to un-
derstand the limits of our techniques even in ideal cases,
meaning we have (i) control over variables affecting the
compilation of programs, (ii) reliable feature extraction
techniques to abstract program binaries accurately and
precisely, and (iii) the ground truth with which we can
compare our results to measure accuracy and to spot error
cases. We discuss the effectiveness of different feature
82  22nd USENIX Security Symposium 
USENIX Association
sets and distance measures on lineage inference in §8.
We argue that it is necessary to also systematically val-
idate a lineage inference technique with “goodware”, e.g.,
open source projects. Since malware is often surrepti-
tiously developed by adversaries, it is typically hard or
even impossible to obtain the ground truth. More funda-
mentally, we simply cannot hope to understand the evo-
lution of adversarial programs unless we ﬁrst understand
the limits of our approach in our idealized setting.
We systematically evaluated ILINE with both good-
ware and malware that we have the ground truth on: 1,777
goodware spanning over a combined 110 years of devel-
opment history and 114 malware collected by the DARPA
Cyber Genome program.
4. What are the limitations? We investigate error cases
in G constructed by ILINE and highlight some of the
difﬁcult cases where ILINE failed to recover the correct
evolutionary relationships. Since some of our experiments
are conducted on goodware with access to source code,
we are able to pinpoint challenging issues that must be ad-
dressed before we can improve the accuracy in software
lineage inference. We discuss such challenging issues
including reverting/refactoring, root identiﬁcation, clus-
tering, and feature extraction in §9. This is important
because we may not be able to understand malware evo-
lution without understanding limits of our approach with
goodware.
2 Software Features for Lineage
In this study, we use three program analysis methods:
syntax-based analysis, static analysis, and dynamic analy-
sis. Given a set of program binaries P, various features
fi are extracted from each pi ∈ P to evaluate different
abstractions of program binaries. Source code or meta-
data such as comments, commit messages or debugging
information is not used as we are interested in results in
security scenarios where source code is typically not avail-
able, e.g., forensics, proprietary software, and malware.
2.1 Using Previous Observations
Previous work analyzed software release histories to un-
derstand a software evolution process. It has been often
observed that program size and complexity tend to in-
crease as new revisions are released [14, 28, 45]. This
observation also carries over to security scenarios, e.g.,
the complexity of malware is likely to grow as new vari-
ants appear [8]. We measured code section size, ﬁle size,
and code complexity to assess how useful these features
are in inferring lineage of program binaries.
• Section size: ILINE ﬁrst identiﬁes executable sections
in binary code, e.g., .text section, which contain exe-
cutable program code, and calculates the size.
• File size: Besides the section size, ILINE also calcu-
lates the ﬁle size, including code and data.
d485db75
83c42c5b
5dc383c4
e9adf8ff
db750783
2c5b5e5d
5b5e5de9
5dd485db
0783c42c
5e5dc383
5de9adf8
85db7507
c42c5b5e
c383c42c
adf8ffff
8b5dd485db750783c42c5b5e5dc383c42c5b5e5de9adf8ffff
(a) Byte sequence of program code
8b5dd485
750783c4
5b5e5dc3
5e5de91d
(b) 4-grams
mov -0x2c(%ebp),%ebx;test %ebx,%ebx;jne 805e198
add $0x2c,%esp;pop %ebx;pop %esi;pop %ebp;ret
add $0x2c,%esp;pop %ebx;pop %esi;pop %ebp;jmp 805da50
(c) Disassembled instructions
mov mem,reg;test reg,reg;jne imm
add imm,reg;pop reg;pop reg;pop reg;ret
add imm,reg;pop reg;pop reg;pop reg;jmp imm
(d) Instructions mnemonics with operands type
mov mem,reg;test reg,reg;jcc imm
add imm,reg;pop reg;pop reg;pop reg;ret
add imm,reg;pop reg;pop reg;pop reg;jmp imm
(e) Normalized mnemonics with operands type
Figure 2: Example of feature extraction
• Cyclomatic complexity: Cyclomatic complexity [34]
is a common metric that indicates code complexity by
measuring the number of linearly independent paths.
From the control ﬂow graph (CFG) of a program, the
complexity M is deﬁned as M = E − N + 2P where E is
the number of edges, N is the number of nodes, and P is
the number of connected components of the CFG.
2.2 Using Syntax-Based Feature
While syntax-based analysis may lack semantic under-
standing of a program, previous work has shown its ef-
fectiveness on classifying unpacked programs. Indeed,
n-gram analysis is widely adopted in software similarity
detection, e.g., [20, 22, 26, 40]. The beneﬁt of syntax-
based analysis is that it is fast because it does not require
disassembling.
• n-grams: An n-gram is a consecutive subsequence of
length n in a sequence. From the identiﬁed executable
sections, ILINE extracts program code into a hexadeci-
mal sequence. Then, n-grams are obtained by sliding a
window of n bytes over it. For example, Figure 2b shows
4-grams extracted from Figure 2a.
2.3 Using Static Features
Existing work utilized semantically richer features by
ﬁrst disassembling a binary. After reconstructing a con-
trol ﬂow graph for each function, each basic block can
be considered as a feature [12]. In order to maximize
the probability of identifying similar programs, previous
work also normalized disassembly outputs by considering
instruction mnemonics without operands [23, 46] or in-
struction mnemonics with only the types of each operand
(such as memory, a register or an immediate value) [39].
In our experiments, we introduce an additional nor-
malization step of normalizing the instruction mnemonics
themselves. This was motivated by our observations when
USENIX Association  
22nd USENIX Security Symposium  83
we analyzed the error cases in the lineages constructed
using the above techniques. Our results indicate that this
normalization notably improves lineage inference quality.
We also evaluate binary abstraction methods in an ide-
alized setting in which we can deploy reliable feature
extraction techniques. The limitation with static analysis
comes from the difﬁculty of getting precise disassem-
bly outputs from program binaries [27, 30]. In order to
exclude the errors introduced at the feature extraction
step and focus on evaluating the performance of software
lineage inference algorithms, we also leverage assembly
generated using gcc -S (not source code itself) to ob-
tain basic blocks more accurately. Note that we use this