POI’s signiﬁcance based on its part of the user’s total amount
of time spent in all POIs.
POI detection rate. A total of 1,053 POIs (across all users)
were identiﬁed using the Incremental-agent method. For each
trafﬁc-based method we calculated: (1) the total number of
POIs identiﬁed; (2) the true positive measure (number of POIs
that were also detected by the Incremental-agent method); (3)
the precision (the true positive value divided by the total num-
ber of POIs identiﬁed); and (4) the recall (the true positive
value divided by the number of POIs identiﬁed by the bench-
mark method, i.e., Incremental-agent).
In addition, previous work on location data analysis showed
that previously obtained semantic information (e.g., land-
marks, shopping centers, roads, etc.) can be used in order
to determine if a location trace is a user’s POI or a transit loca-
tion [33]. Thus, in order to further improve the POI inference
process, we used previously obtained semantic information
in order to better determine the real POIs. Speciﬁcally, we
used Google’s reverse geo-coding API in order to remove geo-
location clusters (i.e., POIs) that are located on highways.
The results are presented in Table 5. As can be seen, the
recall, which represents the POI discovery rate, is approxi-
mately 20% for all methods; the Incremental-trafﬁc method
yields the best results, compared to the other methods, with
slightly lower recall but much higher precision. The values
within the parentheses represents the results of detected POIs
(true positive, precision, and recall) when using this semantic
information. As can be seen, using semantic information to
eliminate irrelevant location clusters can improve the preci-
sion with no effect on the recall. This can be explained by the
fact that due to the lower and inconsistent location leakage
within the network trafﬁc, the irrelevant location clusters (e.g.,
highways) are poorly reﬂected within the network trafﬁc but
better captured by the agent.
In a real-life scenario, the adversary will not be able to label
the extracted geolocations as ’true,’ ’false,’ or ’unknown’ (as
described in Section 5). Therefore, in Table 5 we applied the
clustering algorithm on all of the geolocations.
Nevertheless, in order to evaluate the best results that an ad-
versary could achieve, we applied the POI identiﬁcation pro-
cess only on the users’ ’true’ geolocations. In this case, the
Incremental-trafﬁc clustering method achieved a similar re-
call, however the precision improved dramatically to 95%.
The importance of the 25% identiﬁed POIs. The num-
ber of identiﬁed POIs alone does not necessarily provide a
good estimation of the exposure rate of users’ whereabouts.
For example, let’s assume a user with ten different signiﬁcant
locations (POIs). If a user spends 50% of his/her time at home
and is at work 35% of the time, by determining the user’s
home and work locations, we are able to identify the locations
at which the user spends 85% of his/her time (although we
identiﬁed only 20% of the user’s POIs).
Thus, in order to estimate the signiﬁcance of the identiﬁed
locations (POIs), we computed a weighted measure for the
POI detection rate as follows. For each POI detected we com-
puted the relative time spent by the user at that location (i.e.,
the total time that the user was at the POI divided by the total
time the user spent at all POIs). The weighted measure of
the POIs was computed from the baseline Incremental-agent
method. Then, the POI discovery rate measure was computed
by using the weights computed for each POI identiﬁed. The
results presented in Table 6 show a high weighted POI discov-
ery ratio for the medium and high leakage rates, and a total
of 61% weighted POI’s exposure rate.
The attack. To conclude, an adversary that can eavesdrop
on the user’s network trafﬁc can apply the following step-by-
step attack in order to infer the user’s POIs (and consequently
reveal his or her identity). First, the attacker identiﬁes geo-
graphic coordinates within the outgoing network trafﬁc (us-
ing regex or pre-trained machine learning models). Next, the
attacker applies the latitude/longitude pair and geo-fencing
ﬁlters on the identiﬁed coordinates. Finally, the attacker ap-
plies our proposed incremental-trafﬁc clustering algorithm
on the remaining geo-locations (after applying the ﬁlters) in
order to identify the user’s POIs.
In a real-life scenario an attacker would not have a benchmark
to relate to, and inferring a user’s POI exposure rate would be
based on captured data alone. By deriving a regression model
(Table 7), we can see that the user weighted POI exposure
ratio parameter has a high correlation with the leakage and
coverage rate measures and no signiﬁcant correlation with
the relative standard deviation. Therefore, the attacker can
compute the leakage rate and coverage measures from the
analyzed trafﬁc and estimate the potential exposure rate of
the user’s POIs.
Total
True positive
Precision
Recall
Incremental
282 (263)
205 (193)
0.73 (0.73)
0.20 (0.2)
DBSCAN
470 (374)
213 (201)
0.45 (0.54)
0.20 (0.2)
STDBSCAN
339 (264)
148 (141)
0.43 (0.53)
0.14 (0.14)
Table 5: Recall and precision measures of the three methods
(Incremental-trafﬁc, DBSCAN-trafﬁc, STDBSCAN-trafﬁc),
when considering the Incremental-agent as the ground truth of
the users’ POIs. The values within the parentheses represents
the results of detected POIs when using semantic information.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 253Leakage rate
High
Medium
Low
POI discovery ratio
Weighted POI discovery ratio
48%
26%
8%
81%
67%
37%
Table 6: The POI and weighted POI discovery ratios of the
Incremental-trafﬁc method. The POI discovery rate is the
number of places found in the network data divided by the
number of places found by the Incremental-agent method.
The weighted POI discovery rate is the amount of time spent
at the identiﬁed POIs out of the total user time.
Dependent variable:
Weighted POI’s exposure rate
Coverage
Leak rate
Relative standard deviation
Constant
R2
Adjusted R2
Residual Std. Error
F Statistic
Note:
0.559∗∗∗
(0.172)
−0.0000013∗∗
(0.00000)
−0.048
(0.078)
0.597∗∗∗
(0.106)
0.315
0.283
0.331 (df = 65)
9.955∗∗∗ (df = 3; 65)
∗p<0.1; ∗∗p<0.05; ∗∗∗p<0.01
Table 7: The linear regression model for estimating POIs’
exposure rate from network trafﬁc measures.
7
Identifying leaking applications
The goal of the analysis presented in this section is to de-
termine which applications are responsible for leaking the
location data and whether the leakage occurs as a result of
intentional misuse or a benign application sending location
data in plaintext.
One approach for obtaining such information is real-time
on device monitoring of the installed applications’ outgoing
trafﬁc [17, 41]. However, starting from Android version no’
8.0, such operations require super-user privileges (which ne-
cessitate rooting the user’s device). In our experiment, we
analyzed the network trafﬁc of the user’s personal device,
therefore such an approach was not an option.
Deriving information about the leaking applications from
the network trafﬁc captured is also challenging for three main
reasons: (1) the network trafﬁc captured does not provide
an explicit indication of the sending application/service, (2)
because of the growing use of cloud services and content
delivery networks, many destination IPs are hosted by services
such as AWS, Akamai or Google, and (3) location data can
be sent to advertisement and intelligence service domains by
components embedded in many Android applications.
Given this, we opted to analyze the destination host names
observed within the HTTP trafﬁc. We focused speciﬁcally on
outgoing trafﬁc containing location leaks. By extracting the
host names from the HTTP requests that contained the leaked
location data, we identiﬁed 112 different services. Then, we
analyzed the host names using a public security service (such
as VirusTotal), search engines (Google and Whois), and se-
curity reports. Based on the results of this analysis, we were
able to classify each host name by its reported usage (e.g.,
weather forecast, navigation, location analytics) and whether
it appears to be a legitimate or unwanted/suspicious service.
Services with clear/reasonable location usage and no reported
security issues were classiﬁed as ’benign’; the rest of the
services were classiﬁed as ’suspicious.’
Figure 12 presents the top 12 host names classiﬁed by
their category (color) and level of suspiciousness (size of
circle). Each host name is placed on the graph according to
the average number of detected leakage events (x-axis) and
the number of participants sending location data to that host
name (y-axis).
Some of the suspicious domain names include samsung-
buiasr.vlingo.com which was previously published as a Sam-
sung pre-installed speech recognition application called
Vlingo. This application was found to be leaking sen-
sitive information. Other example includes the domains,
n129.epom.com and mediation.adnxs.com, which are re-
ported to provide personalized advertisements. An additional
signiﬁcant suspicious domain is app.woorlds.com, which was
reported to be a location analytics service. Interestingly, our
analysis concludes that the Google Maps JavaScript API
(maps.googleapis.com), which lets Android application devel-
opers customize maps with user locations, is also responsible
for sending location data in plaintext. This is particularly
noteworthy since Google recommends that application devel-
opers use the secured Maps JavaScript API (which operates
over HTTPS) whenever possible.5 Nonetheless, our analysis
shows that in practice, developers also use the unsecured Map
JavaScript API. Overall, based on the analyzed data, we found
that the set of unwanted services is responsible for more than
60% of location leakage events.
Another observation is that although the number of location
data leakage events (x-axis in Figure 12) for each individual
host name is not high, based on the analysis presented in
Section 6 we were still able identify the users’ signiﬁcant POIs
from the data. We attribute that ﬁnding to the fact that there are
multiple applications installed on each individual smartphone,
which together leak a sufﬁcient amount of information that
can be analyzed in order to infer the POIs.
Although the identity of the leaking application is not ex-
plicitly indicated in the network trafﬁc, we performed further
analysis in an attempt to link the identiﬁed host names with
the applications installed on the users’ mobile devices. In or-
der to do so, we ﬁrst extracted (using our Android agent) the
set of all applications installed on the mobile devices of the
users which require both location and network permissions.
Next, we computed a modiﬁed tf-idf measure for each pair
5https://developers.google.com/maps/documentation/javascript/tutorial
254          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX AssociationT FIDFh(a) = T Fh(a)∗ max(cid:0)1,IDF(a)(cid:1)
The reason for limiting the inverse document frequency (IDF)
value to one is to prevent rare applications from achieving a
very high tf-idf score and consequently be erroneously linked
with the host name. In addition, we applied min-max normal-
ization to the tf-idf scores of applications in order to keep
them within the range of zero to one. A high t f value for
an application a with respect to a host h indicates that a was
frequently observed in devices that transmit location data in
plaintext to h.
On the other hand, a high id f value for a indicates that a
was not observed frequently on the devices in general. Thus,
a high tf-idf score for application a with respect to host h may
indicate that a is related to the location leakage to h.
The raw results of this analysis are presented in Fig-
ure 13, where the tf-idf values are shown for each host
name (x-axis) and application (y-axis). Based on these re-
sults, we classiﬁed the applications into two categories. The
ﬁrst category includes applications that send the location
data to their own hosting service. In this category we can
ﬁnd multiple HTC, LG, and Samsung pre-installed appli-
cations found to be related to their own hosting services
(htc2.accu-weather.com, lgemobilewidget.accu-weather.com,
and samsungbuiasr.vlingo.com), as well as the GetTaxi
(com.gettaxi.android) and Easy (easy.co.il.easy3) applications
which were found to be related to their hosting services (loca-
tion.gtforge.com and easy.co.il respectively).
The second category includes applications that send (via in-
tegrated "software plug-ins") location data to third party ser-
vices such as advertisement APIs (n129.epom.com) or analyt-
ical services (app.woorlds). In this category we identiﬁed a
popular student application named com.mobixon.istudent. We
also identiﬁed applications that send location data to Google
Maps services, some of which potentially use the Google
Maps JavaScript API in an unsecured manner (the HTTP
protocol instead of the HTTPS protocol).
8 Mitigation strategies
In order to reduce the privacy risk associated with location
leakage and POI inference presented in our paper, the fol-
lowing countermeasures are suggested and could be further
investigated and developed in future work.
Awareness. The most basic approach is increasing the
awareness of mobile device users to such risks and providing
them with the tools and means to reduce the risk [43]. For
example, reducing the risk can be achieved by installing only
trusted applications (from trusted sources), monitoring and
limiting sensitive permissions such as location and Internet
access, and disabling location service on the device while
not in use and turning it on only on demand. Tools such as
Recon [8] and LP-Doctor [10] can also be used to increase
Figure 12: Presenting the top 12 host names classiﬁed by their
category (color) and level of suspiciousness (size of circle).
The x-axis represents the average number of detected leakage
events, and the y-axis represents the number of participants
sending location data to that host name.
consisting of an application and host name. A well-known
measure in the ﬁeld of text categorization, tf-idf is often used
as a weighting factor in information retrieval and text min-
ing [42]. The tf-idf is a numerical statistic intended to reﬂect
how important a term (i.e., word) is to a document in a col-
lection or corpus. The tf-idf value increases proportionally to
the number of times a term appears in the document, but it is
offset by the frequency of the term in the corpus, which helps
to adjust for the fact that some terms appear more frequently
in general. In our case, a document is a host name, and a term
is an application. The term frequency (denoted by T F) of an
application (denoted by a) with respect to a given host name
(denoted by h) is calculated as follows:
h|
|U a
|Uh|
T Fh(a) =
where Uh represents the set of users for which we identify a
location leakage (from their devices to h), and U a
h represents
the subset of users from Uh that have application a installed
on their devices.
The inverse document frequency (denoted by IDF) of an
application is calculated as follows:
(cid:18)|U a|
(cid:19)
|U|
IDF(a) = −log10
where U a represents the set of users for which application a
was installed on the devices; and U represents the set of all
users.
Given the above, the tf-idf of an application with respect
to a given host name is calculated as follows:
050010001500200025003000Avarage Leakage Volume (packets)5101520253035Leakage Volume (users)mediation.adnxs.comn129.epom.comapp.woorlds.comsamsungbuiasr.vlingo.comupload.wikimedia.orglocation.gtforge.commaps.googleapis.comvenues.waze.co.illgemobilewidget.accu-weather.comeasy.co.ilhtc2.accu-weather.comapi.openweathermap.orgCategoryAdvertisementAnalyticsSpeech RecognitionOtherLocation ServiceWeatherLabelSuspiciousBenignUSENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 255Monitoring. Monitoring network trafﬁc by third party se-
curity providers in order to detect PII leaks was proposed
by [8] and is a useful approach for identifying applications
that misuse users’ private information. The proposed Recon
application [8] also allows the user to replace the transmitted
data with another value selected by the user.
Anonymization and PII obfuscation. Various techniques
and algorithms were presented to ensure k-anonymity in
LBSs [47–53]. Most of the methods rely on a proxy that
ﬁlters, manipulates, or generalizes the user’s location data
before sending it to the LBS. Such an approach is difﬁcult to
apply when the LBS requires accurate or frequent location
samples in order to provide the service. In addition, these
techniques do not consider the unique threat model of an ad-
versary that has access to the location data of multiple LBSs.
Puttaswamy et al. [54] suggested that LBSs should move
the application functionality to the client devices in order to
preserve their privacy. This is however, impractical because
in most cases (particularly for free applications or third-party
SDK) collecting personal data (e.g., location) is the LBS’s
main business model.
An alternative approach can be in the form of an applica-
tion installed on the mobile device that monitors the location
sampling or location leakage over the network trafﬁc and in-
telligently inject spoofed locations that can make it difﬁcult
for a threat actor to infer the true POIs of the user.
Due to the inherent trade-off between providing the re-
quired location data to location-based applications (or ser-
vices) on the one hand, and protecting user privacy on the
other hand, we believe that a privacy preserving solution
should be: (1) implemented at the OS level and thus have