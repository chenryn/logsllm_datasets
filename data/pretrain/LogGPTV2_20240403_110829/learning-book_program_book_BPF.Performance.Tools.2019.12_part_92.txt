### Latency Range Visualization

It is possible to use a scatter plot for visualizing time and latency; however, with thousands or millions of I/O operations, the points overlap, and details are lost. Heat maps address this issue by scaling their color range as needed.

In Vector, heat maps are generally available for relevant BCC tools. At the time of writing, these include:
- `biolatency(8)` for block I/O latency,
- `runqlat(8)` for CPU run queue latency, and
- `ext4dist(8)`, `xfsdist(8)`, and `zfsdist(8)` for monitoring file system latency.

By configuring the BCC PMDA (explained in Section 17.1.5) and launching an appropriate BCC chart in Vector, you can visualize the outputs over time. Figure 17-3 shows block I/O latency collected on a host with two-second samples running simple `fio(1)` jobs.

**Figure 17-3: Vector Latency Heat Map Showing BCC/BPF biolatency(8)**

From the heat map, it is evident that the most common block latencies fall within the 256- to 511-microsecond range. The tooltip at the cursor point indicates there were 505 samples in that bucket.

For comparison, the following is the result from the command-line `biolatency(8)` capturing a similar time period:

```
+biolatency
Tracing block device I/O... Hit Ctrl-C to end.
...
256 -> 511 : 12989
512 -> 1023 : 11425
1024 -> 2047 : 2406
2048 -> 4095 : 1034
4096 -> 8191 : 374
8192 -> 16383 : 189
16384 -> 32767 : 0
131072 -> 262143 : 42
```

The same latencies are visible in the aggregate; however, the heat map makes it much easier to see the variation over time. It also clearly shows that the I/O in the 128- to 256-millisecond range is consistent over time and not the result of a short burst.

### Visualization: Tabular Data

In addition to visualizing data, it can be helpful to see the raw data in a table. This is especially useful for some BCC tools, as tables can provide additional context or help to make sense of a list of values.

For example, you can monitor `execsnoop(8)` output to show a list of recently started processes. Figure 17-4 shows a Tomcat (catalina) process starting on the monitored host.

**Figure 17-4: Vector Displaying Per-Event Output from BCC/BPF execsnoop(8)**

Another example is monitoring TCP sockets with `tcplife(8)`, which shows host address and port details, transferred bytes, and session duration. This is shown in Figure 17-5.

**Figure 17-5: Vector Listing TCP Sessions via BCC/BPF tcplife(8)**

In this case, you can see that `amazon-ssm-agent` appears to be long-polling for 20 seconds, and a `wget(1)` command was executed that received two Gbytes of data in 41.595 seconds.

### BCC Provided Metrics

Most tools available in the `bcc-tools` package are currently available with the PCP PMDA. Vector has pre-configured charts for the following BCC tools:
- `biolatency(8)` and `biotop(8)`
- `ext4dist(8)`, `xfsdist(8)`, and `zfsdist(8)`
- `tcplife(8)`, `tcptop(8)`, and `tcpretrans(8)`
- `runqlat(8)`
- `execsnoop(8)`

Many of these tools support configuration options that can be provided on the host. Additional BCC tools can also be added to Vector, with custom charts, tables, or heat maps to visualize the data.

Vector also supports adding custom event metrics for tracepoints, uprobe, and USDT events.

### Internals

Vector is a web application that runs entirely within the user’s browser. It is built with React and uses D3.js for charting. The metrics are collected and made available from the Performance Co-Pilot (PCP), a toolkit for collecting, archiving, and processing performance metrics from multiple operating systems. A typical Linux PCP installation offers more than 1000 metrics by default and is extensible with its own plugins, or PMDAs.

To understand how Vector visualizes BPF metrics, it is important to understand how PCP collects these metrics (see Figure 17-6).

**Figure 17-6: Vector Metric Source Internals**

- **PMCD (Performance Metrics Collector Daemon)**: The central component of PCP, typically runs on the target host and coordinates the collection of metrics from numerous agents.
- **PMDA (Performance Metrics Domain Agent)**: An agent hosted by PCP. Many PMDAs are available, each exposing different metrics. For example, there are agents for kernel data, different filesystems, NVIDIA GPUs, and more. To use BCC metrics with PCP, the BCC PMDA must be installed.
- **Vector**: A single-page web app that can be deployed to a server or executed locally, allowing connection to a target `pmwebd` instance.
- **pmwebd**: Acts as a REST gateway to the `pmcd` instance on the target host. Vector connects to the exposed REST port and uses this to interact with `pmcd`.

PCP's stateless model makes it lightweight and robust, with negligible overhead on hosts. Metrics are not aggregated across hosts or persisted outside of the user’s browser session, keeping the framework light.

### Installing PCP and Vector

To try out PCP and Vector, you can run them both on a single host for local monitoring. In a real production deployment, you would likely run Vector on a different host than the PCP agent and PMDAs. Refer to the latest project documentation for details.

The steps to install Vector are documented and updated online [176][177]. They currently involve installing `pcp` and `pcp-webapi` packages and running the Vector UI from a Docker container. Follow these additional instructions to ensure that the BCC PMDA is enabled:

```sh
$ cd /var/lib/pcp/pmdas/bcc/
$ ./Install
```

When Vector and PCP are running on the system with a configured BCC PMDA, you can connect and view system metrics.

### Connecting and Viewing Data

Browse to `http://localhost/` (if testing on your local machine) or the appropriate address where Vector is installed. Enter the hostname of the target system in the dialog shown in Figure 17-7.

**Figure 17-7: Vector Target System Selection**

The connection area will show a new connection. As shown in Figure 17-8, the icon should indicate a specific chart instead of a prepared dashboard. Flip to the Custom tab and choose `runqlat`. Any modules not available on the server will be dimmed and not available. Click on the enabled module and click the Dashboard arrow to close the dashboard.

**Figure 17-8: Vector Selection of BCC/BPF Tool**

In the connection dialog, by switching to the Custom tab and looking at the BCC/BPF options, you can see the available BCC/BPF metrics. In this case, many of these BPF programs appear grayed out as they are not enabled in the PMDA. When you select `runqlat` and close the Dashboard panel, a run queue latency heat map is shown, updated live each second, as shown in Figure 17-9.

**Figure 17-9: Vector Run Queue Latency Heat Map**

Be sure to explore the configuration widget for other available BCC metrics.

### Configuring the BCC PMDA

Much of the BCC PMDA functionality is not available unless it is specifically configured. The BCC PMDA man page (`pmdabcc(1)`) describes the configuration file format in detail. The following steps configure the `tcpretrans` BCC module to make it available in Vector, so you can see TCP session statistics.

```sh
$ cd /var/lib/pcp/pmdas/bcc
$ sudo vi bcc.conf
```

In the full file, you will see additional configuration options for the `tcplife` module and many others. This file is important for configuring the BCC PMDA.

```ini
[tcpretrans]
module = tcpretrans
cluster = 3
process = java
lport = 8443
+dport = 80,443
```

Any time the PMDA configuration changes, you should recompile and restart the PMDA:

```sh
$ cd /var/lib/pcp/pmdas/bcc
$ ./Rebuild
```

You can now refresh your browser and select the `tcpretrans` chart.

### Future Work

More work is still required between Vector and PCP to improve integration with the full suite of BCC tools. Vector has served Netflix well for many years as a detailed on-host metrics solution. Netflix is currently investigating whether Grafana can also provide this capability, which would allow more development focus to be on the host and metrics. Grafana is covered in Section 17.2.

### Further Reading

For more information on Vector and PCP, see:
- [https://getvector.io/](https://getvector.io/)
- [https://github.com/performancecopilot/pcp](https://github.com/performancecopilot/pcp)

### Grafana and Performance Co-Pilot (PCP)

Grafana is a popular open-source charting and visualization tool that supports connecting to and displaying data stored in many back-end data sources. By using Performance Co-Pilot (PCP) as a data source, you can visualize any of the metrics exposed in PCP. PCP is covered in more detail in Section 17.1.

There are two approaches for configuring PCP to support the presentation of metrics in Grafana:
- **Grafana PCP Live Data Source**: Use the `grafana-pcp-live` plugin. This plugin polls a PCP instance for the latest metric data and keeps a short history (a few minutes worth) of results in the browser. There is no long-term persistence of the data. The advantage is that there is no load on the system being monitored while you are not viewing the data.
- **Grafana PCP Archived Data Source**: Use the `grafana-pcp-redis` plugin. This plugin fetches data from the source using the PCP `pmseries` data storage and collates the data into a Redis instance. This relies on a configured `pmseries` instance and means PCP will poll and store the data. This makes it more suitable for collecting larger time series data that will be looked at across multiple hosts.

It is assumed that you have performed the PCP configuration steps previously described in Section 17.1. For both options, the projects are undergoing changes, so the best approach for installation is to see the links in Section 17.2.4 and look at the installation instructions for each plugin.

### Connecting and Viewing Data

The `grafana-pcp-live` plugin is under heavy development. At the time of writing, the approach to connecting to a back end relies on the setup of variables required for the PCP client. Since it does not have any storage, this allows the dashboard to be dynamically reconfigured to connect to multiple different hosts. These variables are `_proto`, `_host`, and `_port`.

Create a new dashboard, enter the dashboard settings, create variables for the dashboard, and set them up with the required configuration settings. You can see the result in Figure 17-10 (where you fill in the host field with an appropriate host):

**Figure 17-10: Setting Up Dashboard Variables in grafana-pcp-live**