sents the result (provided by the execution environment).
In order to address functions that change the memory state,
we have introduced a new event whose arguments are byte-
arrays containing data read-from/written-to speciﬁed mem-
ory regions. For that, we have implemented a simple mech-
anism to specify the memory footprint of an external func-
tion. We allow the arguments of each function to be either
a primitive C type or a pointer to a memory region that is
either read or written. The size of regions is declared by an
expression that is allowed to refer to other (int) arguments.
As an example, consider the declaration of the sample octets
and random oracle functions that instantiate the Rand and
RO oracles in our PKCS implementation:
#pragma libspec sample_octets: OutPtr #1,Int->Void
extern void sample_octets(unsigned char *,size_t);
#pragma libspec random_oracle: OutPtr #1, Int,
InPtr #3,Int->Void
extern void random_oracle(unsigned char *, size_t,
unsigned char *, size_t);
In the ﬁrst line, the pragma directive informs CompCert that
the ﬁrst argument is a pointer to a memory region written
1224by the function. The size of the region is given by the integer
passed as second argument. This mechanism is implemented
in a general way that allows specifying arbitrary functions
that feed output memory regions to the environment and ﬁll
input memory regions with data collected from the environ-
ment. More precisely, the semantics of a function declared
using this mechanism is deﬁned to:
1. read the memory regions and other input arguments;
2. ask the environment for a byte-array with size equal
to the sum of the output sizes;
3. split the obtained array in the required pieces, and
write them in the corresponding memory regions;
4. produce an event with arguments as described above.
By extending the correctness result of CompCert to cover
these external functions, it follows that the observable be-
haviour of a source program will be preserved in the assem-
bly code, for any instantiation of these functions. However,
in the context of security-aware compilation, one must re-
call that these functions are actually idealised constructions
that are used in the security proofs. It is critical to the se-
curity of the ﬁnal implementation that the instantiation of
these functions complies as much as possible with the as-
sumptions that are made explicit in the EasyCrypt proof. In
other words, these functions must be trustworthy in order
to obtain assembly-level security, and this is why we named
this mechanism TrustedLib.
In the particular case of the RSA-OAEP implementation
the above discussion implies that, in line with standard cryp-
tographic practice, it is up to the end-user to instantiate
sample octets with a function that provides good quality ran-
domness, and to follow the recommentations in the PKCS
standard for the instantiation of the mask generation func-
tion that we model as a random oracle. Furthermore, the as-
sumptions regarding the leakage of these external functions
that are axiomatized in EasyCrypt should also be satisﬁed
by the instantiation.
Correctness of the cryptographic API. There is a mis-
match between what it means for a compiled program to be
correct under the CompCert formalization and our notion of
correctness. In CompCert, the meaning of a C program is
the behaviour of executing a speciﬁc entry-point: the main
function. Our notion of correctness imposes instead the cor-
rectness (in terms of input/output behaviour) of all the func-
tions acting as entry points of the functionality formalized in
EasyCrypt: we call this the correctness of the cryptographic
API. To bridge the gap between these two notions, we have
anchored our correctness result on a C entry-point with the
following shape:
Function main( )
id ← read( )
(cid:126)p ← read( )
o ← id((cid:126)p)
write(o)
This generic entry point reads the identiﬁer of the func-
tion to evaluate (in the case of a PKE implementation this
means either Enc or Dec). It then uses external functions
read and write to obtain input values for the function from
the environment, and to externalise the corresponding out-
puts.4 This pattern registers every possible input/output
behaviour of each function as an admissible behaviour of
the program. Hence, the correctness result of CompCert en-
sures preservation of this behaviour along the compilation
process.
The main function is added to the cryptographic imple-
mentation to ensure that the translation to assembly is ex-
plicitly captured by the correctness theorem of CompCert.
This function can be discarded from the assembly code, since
the implementation is itself intended to be used as a library
by some higher level application.
Adding support for a big-number library. The imple-
mentation of public-key cryptography code often requires
the use of big-number libraries to carry out complex alge-
braic computations such as modular exponentiation. For
example, a typical implementation of RSA-OAEP will dele-
gate the big-number computations to a (often pre-compiled)
library such as GMP.5 From the developers’ point of view,
this can be seen as extending C with a new data type and
native operations that provide support for big integers.
One possible approach to handle such external libraries
would be to use the TrustedLib mechanism to equip our
framework with external functions, which would leave it
to the environment to provide the big-integer operators.6
However, this would not match the setting we have cap-
tured in the EasyCrypt formalization, in which we consider
a well-deﬁned intended semantics for these operations. Fur-
thermore, the correctness and security of the C implemen-
tation depend crucially on the correct implementation of
these functions (otherwise, the axioms assumed in the Easy-
Crypt theory might not be validated). For this reason, we
have opted to include the necessary big-integer operations
as new built-in operations in CompCert, with a fully deﬁned
semantics, which we see as a contract on the library that
we will use for linking with our program. Once again we
must trust the library that instantiates these operations to
correctly implement those contracts, which would ideally be
addressed through formal veriﬁcation. Unfortunately, the
complexity of state-of-art libraries such as GMP make such
an enterprise an enormous eﬀort (although results obtained
on smaller libraries [31] and in speciﬁc algorithms [12] pro-
vide conﬁdence on feasibility in a near future).
Technically, the formalization of the semantics of the big-
number builtin operations is a reﬁnement of that presented
for the TrustedLib functions, in which the transformations
on the state are fully speciﬁed, and where the events sig-
nalling communication with the environment are ommit-
ted. The transformations on the state are described in three
steps: i. reading the big-integer word representations of all
the inputs and converting them into (Coq) integers; ii. per-
forming the operations over the integers; and iii. converting
back into the memory representation and storing the results.
A consequence of our approach is that we needed to com-
mit to a concrete representation of big-integers. We use a
230 radix representation, stored as an array of 32-bit ma-
4In the case of our example, the inputs and outputs are
simply octet strings of various lengths, which means that
the read and write functions can be also implemented using
the external function mechanism described above.
5http://gmplib.org
6In fact, we have used that mechanism to specify all the
GMP low-level integer API.
1225chine integers. This means that we use 30-bits in each ma-
chine word for storage, where the remaining two bits should
always be kept at zero at the function boundaries (func-
tions may internally and temporarily cause these bits to be
non-zero). Our formalization is ﬂexible enough to enable
straightforward adaptation to other representations. The
formalization of the big-number library as built-in opera-
tions in CompCert has the additional advantage of automat-
ically extending the CompCert interpreter to support these
operations, which may be useful for debugging.
Our framework includes an instantiation of the big-number
library that was developed for illustrative purposes, adapted
from the Long Integer Package (LIP) library by A. Lenstra.7
One of our concerns was to ensure that all the big-integer
operations comply with the leakage requirements imposed
by the EasyCrypt proof: the leakage should be constant and
independent of the concrete inputs passed to the functions.
To this end, we have incorporated a standard countermea-
sure against side-channel attacks, and simpliﬁed the library
to consider only unsigned integers and use static memory al-
location. All the routines have been modiﬁed so that there
is no data-dependent branching and memory indexing as ex-
plained, for example, in [11]. This means that all functions
in the library execute in constant time and access the same
memory addresses, regardless of the input data.
Integers
are stored in statically declared arrays of pre-deﬁned size,
which means that the maximum range of the integers that
will be manipulated by the program must be known in ad-
vance, and must be provided at the time of compilation. For
our example, we have aimed at 4096-bit RSA keys, repre-
sented using 137 words. We note that ﬁxing the maximum
length of integers is consistent with our assumption that the
security parameter is known at compile time, and the formal
semantics that we have added in CompCert captures exactly
the behaviour of our library. Although the functionality of
our library is not formally veriﬁed, we have used a Frama-C
plug-in [8] to check that the side-channel countermeasures
are correctly deployed.
Dealing with side-channel leakage. The last extension
to CompCert concerns the need to satisfy the part of Deﬁni-
tion 4 imposing that traces generated by the assembly code
in the PC model can be simulated from the leakage model
we adopted for C programs.
The annotation mechanism of CompCert allows us to ex-
tend standard C code with dummy statements that, when
evaluated, give rise to events that externalize arbitrary con-
stant identiﬁers making them visible in the observable be-
haviour of the program. This means that a direct transla-
tion of the EasyCrypt code into CompCert taking advantage
of these annotations gives rise to a C program whose observ-
able behaviour includes (among the other events that may
be signalled) a trace of all the conditional jumps taken by the
program. Furthermore, CompCert guarantees that the same
exact traces will be observable in the assembly program.
It is obvious that, by inspecting the sequence of events
that reports which conditional jumps were taken, one can
reconstruct the entire control ﬂow of the C program. How-
ever, the same cannot be said for the control ﬂow of the
assembly program: indeed, CompCert is only guaranteed to
preserve the observable behaviour of the C program, and
7http://www.win.tue.nl/~klenstra/
many possible assembly programs can achieve this. In par-
ticular, there may be assembly programs which are insecure
in the PC model (i.e. that leak sensitive information via the
control ﬂow) and still have an observable behaviour that
matches that of the original C program.
In other words,
it may not be possible to fully determine the sequence of
program counter values taken by an assembly implementa-
tion solely from the observable conditional jumps taken by
the C program. However, in order to achieve security-aware
compilation, this is precisely what we require.
Instead of proving that each of the compiler passes does
not introduce spurious branching, we have implemented a
simple static analysis on the generated assembly program
that establishes the desired property. Our analysis is for-
malized in Coq as a translation validation that checks, for
every conditional branch instruction in the assembly code,
that i. all execution paths arising from that instruction go
through an annotation; and ii. that these annotations give
rise to events that externalize (pairwise) distinct constant
identiﬁers. This is suﬃcient to ensure that the observable
behaviour of the program fully reﬂects the choice of the ex-
ecution path, and we have formalized and proved in Coq
the following theorem that establishes the soundness of the
translation validation.
(PC trace simulatability). Let S be an
assembly program that passes the translation validation de-
scribed above. Let also s1 and s2 be memory states s.t.
s1 ≡PC s2; and, let B1 and B2 be behaviours s.t. B1 ∼ann B2,
(cid:104)S; s1(cid:105) ⇓ B1, and (cid:104)S; s2(cid:105) ⇓ B2. Then, for any states s(cid:48)
1, s(cid:48)
and traces t1, t2 we have that
t2−→ s
2 =⇒ s
(cid:48)
1 ∧ s2
(cid:48)
1 ≡PC s
(cid:48)
(cid:48)
2 .
2
Theorem 4
t1−→ s
s1
Here, states s1, s2 are PC-equivalent (s1 ≡PC s2) when
they agree on the value stored in the PC register and have
the same call stack, and behaviours B1, B2 are annotation-
equivalent (B1 ∼ann B2) when they exhibit the same (possi-
bly inﬁnite) sequence of annotation events. The above theo-
rem shows that the sequence of PC values in the evaluation of
an assembly program that passes the translation validation
is fully determined by the sequence of constant identiﬁers
revealed via annotations in the observable behaviour. More
precisely, the theorem expresses this result in the style of
a non-interference result:
if a program is validated by the
test, then any two instances of it that exhibit the same an-
notations on their behaviour, are guaranteed to proceed in
lockstep, i.e., the next PC value can always be determined
from the observable trace.
The above theorem treats the execution of external calls
and other compiler builtins as atomic steps. The sound-
ness of the validation depends on the assumption that these
external functions have precisely the same property (a com-
piler warning collects the identiﬁers of all these functions to
remind the user of this fact). From the perspective of the
end-user, the test is triggered by a new command-line op-
tion -max-annot. When the validation fails, no executable is
produced and an error is emitted pointing to the branch of
the (bad) assembly program that fails the check.
The following corollary relates the theorem above to the
notion of semantic preservation in Deﬁnition 4.
Corollary 5
(Informal). Consider a PKE implemen-
tation that, when it is compiled with CompCert, gives rise to
1226an assembly program that passes the translation validation
check. Then, the compilation performed by CompCert en-
forces Deﬁnition 4.
The proof of this corollary follows directly from the fact
that the correctness theorem for CompCert guarantees that
Deﬁnition 4 is satisﬁed, provided that simulator S can be
constructed. The theorem above guarantees the correctness
of the trivial simulator that looks ahead to the potential
executions of the assembly program, until it ﬁnds the anno-
tation that reveals the correct execution paths.
Using CompCert for security-aware compilation. To sum-
marize the above discussions, we have extended CompCert
with a number of features and adapted the correctness re-
sult of the compiler to accommodate these extensions. This
means that CompCert will preserve the observable behaviours
of source C programs that rely on an arbitrary TrustedLib.
We have also shown that the translation validation step
that we have added to the compiler guarantees that sim-
ulation of PC traces is possible for accepted assembly pro-
grams. Putting these two results together, we conclude that
our version of CompCert provides security-aware compilation
by guaranteeing semantic preservation according to Deﬁni-
tion 4. This means that, by the Theorems proved in Sec-
tion 4, compiling a cryptographic implementation from C
code to assembly, one obtains the following guarantees:
1. Assuming that the C implementation is secure in a
side-channel aware security model such as the one de-
scribed in Section 2;
2. Compiling the C implementation with the generic main
entry point using CompCert and activating the trans-
lation validation stage;
3. Assuming that the TrustedLib functions are instanti-
ated with a secure and correct library that satisﬁes the
requirements speciﬁed in the security proof;
4. Then, if compilation does not fail, the assembly im-
plementation is correct and secure against real-world
adversaries that attack the scheme in the PC model.
i.
Experimental results. We have performed an evaluation