  ----------------------------------------------- -------------------------------------- ----------------------------------------------------------------------------------------------------------
  **type**                                        \--                                    组件类型，这个是： `jdbc`
  db.type                                         DERBY                                  使用的数据库类型，目前只支持 DERBY.
  driver.class                                    org.apache.derby.jdbc.EmbeddedDriver   所使用数据库的 JDBC 驱动类
  driver.url                                      (constructed from other properties)    JDBC 连接的 URL
  db.username                                     \"sa\"                                 连接数据库使用的用户名
  db.password                                     \--                                    连接数据库使用的密码
  connection.properties.file                      \--                                    JDBC连接属性的配置文件
  create.schema                                   true                                   如果设置为 `true` ，没有数据表的时候会自动创建
  create.index                                    true                                   是否创建索引来加快查询速度
  create.foreignkey                               true                                   是否创建外键
  transaction.isolation                           \"READ_COMMITTED\"                     面向连接的隔离级别，可选值： `READ_UNCOMMITTED` ， `READ_COMMITTED`， `SERIALIZABLE`， `REPEATABLE_READ`
  maximum.connections                             10                                     数据库的最大连接数
  maximum.capacity sysprop.\* sysprop.user.home   0 (unlimited)                          channel 中存储 Event 的最大数 针对不同DB的特定属性 Derby 的存储主路径
配置范例：
``` properties
a1.channels = c1
a1.channels.c1.type = jdbc
```
#### Kafka Channel
将 Event
存储到Kafka集群（必须单独安装）。Kafka提供了高可用性和复制机制，因此如果Flume实例或者
Kafka 的实例挂掉，能保证Event数据随时可用。 Kafka
channel可以用于多种场景：
1.  与source和sink一起：给所有Event提供一个可靠、高可用的channel。
2.  与source、interceptor一起，但是没有sink：可以把所有Event写入到Kafka的topic中，来给其他的应用使用。
3.  与sink一起，但是没有source：提供了一种低延迟、容错高的方式将Event发送的各种Sink上，比如：HDFS、HBase、Solr。
目前支持Kafka 0.10.1.0以上版本，最高已经在Kafka
2.0.1版本上完成了测试，这已经是Flume 1.9发行时候的最高的Kafka版本了。
配置参数组织如下：
1.  通常与channel相关的配置值应用于channel配置级别，比如：a1.channel.k1.type
    =
2.  与Kafka相关的配置值或Channel运行的以"kafka."为前缀（这与CommonClient
    Configs类似），例如：\*a1.channels.k1.kafka.topic\* 和
    *a1.channels.k1.kafka.bootstrap.servers*。 这与hdfs
    sink的运行方式没有什么不同
3.  特定于生产者/消费者的属性以kafka.producer或kafka.consumer为前缀
4.  可能的话，使用Kafka的参数名称，例如：bootstrap.servers 和 acks
当前Flume版本是向下兼容的，但是第二个表中列出了一些不推荐使用的属性，并且当它们出现在配置文件中时，会在启动时打印警告日志。
必需的参数已用 **粗体** 标明。
  属性                                                                       默认值          解释
  -------------------------------------------------------------------------- --------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  **type**                                                                   \--             组件类型，这个是： `org.apache.flume.channel.kafka.KafkaChannel`
  **kafka.bootstrap.servers**                                                \--             channel使用的Kafka集群的实例列表，可以是实例的部分列表。但是更建议至少两个用于高可用支持。格式为hostname:port，多个用逗号分隔
  kafka.topic                                                                flume-channel   channel使用的Kafka topic
  kafka.consumer.group.id                                                    flume           channel 用于向 Kafka 注册的消费者群组ID。 多个 channel 必须使用相同的 topic 和 group，以确保当一个Flume实例发生故障时，另一个实例可以获取数据。请注意，使用相同组ID的非channel消费者可能会导致数据丢失。
  parseAsFlumeEvent                                                          true            是否以avro基准的 Flume Event 格式在channel中存储Event。 如果是Flume的Source向channel的topic写入Event则应设置为true； 如果其他生产者也在向channel的topic写入Event则应设置为false。 通过使用 flume-ng-sdk 中的 *org.apache.flume.source.avro.AvroFlumeEvent* 可以在Kafka之外解析出Flume source的信息。
  pollTimeout                                                                500             消费者调用poll()方法时的超时时间（毫秒） 
  defaultPartitionId                                                         \--             指定channel中所有Event将要存储的分区ID，除非被 *partitionIdHeader* 参数的配置覆盖。 默认情况下，如果没有设置此参数，Event 会被Kafka生产者的分发程序分发，包括key（如果指定了的话），或者被 *kafka.partitioner.class* 指定的分发程序来分发。
  partitionIdHeader                                                          \--             从Event header中读取要存储Event到目标Kafka的分区的属性名。 如果设置了，生产者会从Event header中获取次属性的值，并将消息发送到topic的指定分区。 如果该值表示的分区无效，则Event不会存入channel。如果该值有效，则会覆盖 *defaultPartitionId* 配置的分区ID。
  kafka.consumer.auto.offset.reset                                           latest          当Kafka中没有初始偏移量或者当前偏移量已经不在当前服务器上时（比如数据已经被删除）该怎么办。 earliest：自动重置偏移量到最早的位置； latest：自动重置偏移量到最新的位置； none：如果没有为消费者的组找到任何先前的偏移量，则向消费者抛出异常； else：向消费者抛出异常。
  kafka.producer.security.protocol                                           PLAINTEXT       设置使用哪种安全协议写入Kafka。可选值： `SASL_PLAINTEXT` 、 `SASL_SSL` 和 `SSL` 有关安全设置的其他信息，请参见下文。
  kafka.consumer.security.protocol *more producer/consumer security props*   PLAINTEXT       与上面的相同，只不过是用于消费者。 如果使用了 `SASL_PLAINTEXT` 、 `SASL_SSL` 或 `SSL` 等安全协议，参考 [Kafka security](http://kafka.apache.org/documentation.html#security) 来为生产者、消费者增加安全相关的参数配置
下表是弃用的一些参数
+-------------------------+---------------+-------------------------+
| 属性                    | 默认值        | 解释                    |
+=========================+===============+=========================+
| brokerList              | \--           | 改用                    |
|                         |               | kafka.bootstrap.servers |
+-------------------------+---------------+-------------------------+
| topic                   | flume-channel | 改用 kafka.topic        |
+-------------------------+---------------+-------------------------+
| groupId                 | flume         | 改用                    |
|                         |               | kafka.consumer.group.id |
+-------------------------+---------------+-------------------------+
| readSmallestOffset      | false         | 改用                    |
|                         |               | kafka.con               |
|                         |               | sumer.auto.offset.reset |
+-------------------------+---------------+-------------------------+
| migrateZookeeperOffsets | > true        | > 如果找不到Kafka存储的 |
|                         |               | 偏移量，去Zookeeper中查 |
|                         |               | 找偏移量并将它们提交给  |
|                         |               | > Kafka 。              |
|                         |               | > 它应该设置为          |
|                         |               | true以支持从旧版本的Flu |
|                         |               | meKafka客户端无缝迁移。 |
|                         |               | > 迁移                  |
|                         |               | 后，可以将其设置为fals  |
|                         |               | e，但通常不需要这样做。 |
|                         |               | > 如果在Zookeepe        |
|                         |               | r未找到偏移量，则可通过 |
|                         |               | > *kafka.cons           |
|                         |               | umer.auto.offset.reset* |
|                         |               | > 配置如何处理偏移量。  |
+-------------------------+---------------+-------------------------+
::: note
::: title
Note
:::
由于channel是负载均衡的，第一次启动时可能会有重复的Event出现。
:::
配置范例：
``` properties
a1.channels.channel1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.channel1.kafka.bootstrap.servers = kafka-1:9092,kafka-2:9092,kafka-3:9092
a1.channels.channel1.kafka.topic = channel1
a1.channels.channel1.kafka.consumer.group.id = flume-consumer
```
**安全与加密：**
Flume 和 Kafka
之间通信渠道是支持安全认证和数据加密的。对于身份安全验证，可以使用 Kafka
0.9.0版本中的 SASL、GSSAPI （Kerberos V5） 或 SSL
（虽然名字是SSL，实际是TLS实现）。
截至目前，数据加密仅由SSL / TLS提供。
当你把 *kafka.producer（consumer）.security.protocol*
设置下面任何一个值的时候意味着：
-   **SASL_PLAINTEXT** - 无数据加密的 Kerberos 或明文认证
-   **SASL_SSL** - 有数据加密的 Kerberos 或明文认证
-   **SSL** - 基于TLS的加密，可选的身份验证。
::: warning
::: title
Warning
:::
启用 SSL 时性能会下降，影响大小取决于 CPU 和 JVM 实现。参考 [Kafka
security
overview](http://kafka.apache.org/documentation#security_overview) 和
[KAFKA-2561](https://issues.apache.org/jira/browse/KAFKA-2561) 。
:::
**使用TLS：**
请阅读 [Configuring Kafka Clients
SSL](http://kafka.apache.org/documentation#security_configclients)
中描述的步骤来了解用于微调的其他配置设置，例如下面的几个例子：启用安全策略、密码套件、启用协议、truststore或秘钥库类型。
服务端认证和数据加密的一个配置实例：
``` properties
a1.channels.channel1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.channel1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.channels.channel1.kafka.topic = channel1
a1.channels.channel1.kafka.consumer.group.id = flume-consumer
a1.channels.channel1.kafka.producer.security.protocol = SSL
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.channels.channel1.kafka.producer.ssl.truststore.location = /path/to/truststore.jks
a1.channels.channel1.kafka.producer.ssl.truststore.password = 
a1.channels.channel1.kafka.consumer.security.protocol = SSL
a1.channels.channel1.kafka.consumer.ssl.truststore.location = /path/to/truststore.jks
a1.channels.channel1.kafka.consumer.ssl.truststore.password = 
```
如果配置了全局ssl，上面关于ssl的配置就可以省略了，想了解更多可以参考
[SSL/TLS 支持](#ssltls-支持) 。 注意，默认情况下
ssl.endpoint.identification.algorithm
这个参数没有被定义，因此不会执行主机名验证。如果要启用主机名验证，请加入以下配置：
``` properties
a1.channels.channel1.kafka.producer.ssl.endpoint.identification.algorithm = HTTPS
a1.channels.channel1.kafka.consumer.ssl.endpoint.identification.algorithm = HTTPS
```
开启后，客户端将根据以下两个字段之一验证服务器的完全限定域名（FQDN）：
1)  Common Name (CN) 
2)  Subject Alternative Name (SAN)
如果还需要客户端身份验证，则还应在 Flume
配置中添加以下内容，当然如果配置了全局ssl就不必另外配置了，想了解更多可以参考
[SSL/TLS 支持](#ssltls-支持) 。 每个Flume
实例都必须拥有其客户证书，来被Kafka 实例单独或通过其签名链来信任。
常见示例是由 Kafka 信任的单个根CA签署每个客户端证书。
``` properties
# 如果在全局配置了SSL下面几个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.channels.channel1.kafka.producer.ssl.keystore.location = /path/to/client.keystore.jks
a1.channels.channel1.kafka.producer.ssl.keystore.password = 
a1.channels.channel1.kafka.consumer.ssl.keystore.location = /path/to/client.keystore.jks
a1.channels.channel1.kafka.consumer.ssl.keystore.password = 
```
如果密钥库和密钥使用不同的密码保护，则ssl.key.password
属性将为消费者和生产者密钥库提供所需的额外密码：
``` properties
a1.channels.channel1.kafka.producer.ssl.key.password = 
a1.channels.channel1.kafka.consumer.ssl.key.password = 
```
**Kerberos安全配置：**
要将Kafka channel
与使用Kerberos保护的Kafka群集一起使用，请为生产者或消费者设置上面提到的producer（consumer）.security.protocol属性。
与Kafka实例一起使用的Kerberos
keytab和主体在JAAS文件的"KafkaClient"部分中指定。
"客户端"部分描述了Zookeeper连接信息（如果需要）。
有关JAAS文件内容的信息，请参阅 [Kafka
doc](http://kafka.apache.org/documentation.html#security_sasl_clientconfig)。
可以通过flume-env.sh中的JAVA_OPTS指定此JAAS文件的位置以及系统范围的
kerberos 配置：
``` properties
JAVA_OPTS="$JAVA_OPTS -Djava.security.krb5.conf=/path/to/krb5.conf"
JAVA_OPTS="$JAVA_OPTS -Djava.security.auth.login.config=/path/to/flume_jaas.conf"
```
使用 SASL_PLAINTEXT 的示例安全配置：
``` properties
a1.channels.channel1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.channel1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.channels.channel1.kafka.topic = channel1
a1.channels.channel1.kafka.consumer.group.id = flume-consumer
a1.channels.channel1.kafka.producer.security.protocol = SASL_PLAINTEXT
a1.channels.channel1.kafka.producer.sasl.mechanism = GSSAPI
a1.channels.channel1.kafka.producer.sasl.kerberos.service.name = kafka
a1.channels.channel1.kafka.consumer.security.protocol = SASL_PLAINTEXT
a1.channels.channel1.kafka.consumer.sasl.mechanism = GSSAPI
a1.channels.channel1.kafka.consumer.sasl.kerberos.service.name = kafka
```
使用 SASL_SSL 的安全配置范例：
``` properties
a1.channels.channel1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.channel1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.channels.channel1.kafka.topic = channel1
a1.channels.channel1.kafka.consumer.group.id = flume-consumer
a1.channels.channel1.kafka.producer.security.protocol = SASL_SSL
a1.channels.channel1.kafka.producer.sasl.mechanism = GSSAPI
a1.channels.channel1.kafka.producer.sasl.kerberos.service.name = kafka
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.channels.channel1.kafka.producer.ssl.truststore.location = /path/to/truststore.jks
a1.channels.channel1.kafka.producer.ssl.truststore.password = 
a1.channels.channel1.kafka.consumer.security.protocol = SASL_SSL
a1.channels.channel1.kafka.consumer.sasl.mechanism = GSSAPI
a1.channels.channel1.kafka.consumer.sasl.kerberos.service.name = kafka
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.channels.channel1.kafka.consumer.ssl.truststore.location = /path/to/truststore.jks
a1.channels.channel1.kafka.consumer.ssl.truststore.password = 
```
JAAS 文件配置示例。有关其内容的参考，请参阅Kafka文档 [SASL