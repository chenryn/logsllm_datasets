[7] Toon Calders and Sicco Verwer. 2010. Three naive Bayes approaches for
discrimination-free classification. Data Mining and Knowledge Discovery 21,
2 (2010), 277‚Äì292.
[8] Kamalika Chaudhuri, Claire Monteleoni, and Anand D. Sarwate. 2011. Differen-
tially Private Empirical Risk Minimization. Journal of Machine Learning Research
12 (2011), 1069‚Äì1109.
[9] David Maxwell Chickering and David Heckerman. 2000. A Decision Theoretic
Approach to Targeted Advertising. In Proceedings of the Sixteenth Conference on
Uncertainty in Artificial Intelligence (UAI‚Äô00). Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA, 82‚Äì88.
[10] Corinna Cortes and Vladimir Vapnik. 1995. Support-Vector Networks. Mach.
Learn. 20, 3 (Sept. 1995), 273‚Äì297.
[11] Paulo Cortez and Alice Maria Goncalves Silva. 2008. Using data mining to
predict secondary school student performance. Technical Report, Department of
Computer Science, University of Camerino. (2008).
[12] Thomas M Cover and Joy A Thomas. 2012. Elements of information theory. John
Wiley & Sons.
[13] Anupam Datta, Matthew Fredrikson, Gihyuk Ko, Piotr Mardziel, and Shayak
Sen. 2017. Use Privacy in Data-Driven Systems: Theory and Experiments with
Machine Learnt Programs. arXiv preprint arXiv:1705.07807 (2017).
[14] Anupam Datta, Shayak Sen, and Yair Zick. 2016. Algorithmic Transparency via
Quantitative Input Influence: Theory and Experiments with Learning Systems.
In Proceedings of IEEE Symposium on Security & Privacy 2016.
[15] A. Datta, M.C. Tschantz, and A. Datta. 2015. Automated Experiments on Ad
Privacy Settings: A Tale of Opacity, Choice, and Discrimination. In Proceedings
on Privacy Enhancing Technologies (PoPETs 2015). 92‚Äì112.
[16] Amit Datta, Michael Carl Tschantz, and Anupam Datta. 2015. Automated Experi-
ments on Ad Privacy Settings: A Tale of Opacity, Choice, and Discrimination. In
Proceedings on Privacy Enhancing Technologies (PoPETs). De Gruyter Open.
[18] Pam Dixon and Robert Gellman. 2014.
[17] Wendy Davis. 2016. FTC‚Äôs Julie Brill Tells Ad Tech Companies To Improve
Privacy Protections. (2016). http://www.mediapost.com/publications/article/
259210/ftcs-julie-brill-tells-ad-tech-companies-to-impro.html Accessed Nov 11,
2016.
The Scoring of America:
How Secret Consumer Scores Threaten Your Privacy and Your Future.
(2014). http://www.worldprivacyforum.org/wp-content/uploads/2014/04/WPF-
Scoring-of-America-April2014-fs.pdf Accessed: 2016-11-05.
(2012). http://
www.nytimes.com/2012/02/19/magazine/shopping-habits.html (Accessed Aug
13, 2016).
[20] Olive Jean Dunn. 1959. Estimation of the Medians for Dependent Variables. The
[19] Charles Duhigg. 2012. How Companies Learn Your Secrets.
Annals of Mathematical Statistics 30, 1 (03 1959), 192‚Äì197.
[21] Cynthia Dwork. 2006. Differential Privacy. In Automata, Languages and Program-
ming, 33rd International Colloquium, ICALP 2006, Venice, Italy, July 10-14, 2006,
Proceedings, P (Lecture Notes in Computer Science), Vol. 4052. Springer, 1‚Äì12.
[22] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard
Zemel. 2012. Fairness Through Awareness. In Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference (ITCS ‚Äô12). ACM, New York, NY, USA,
214‚Äì226.
[23] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. 2012. Fairness Through
Awareness. In Proceedings of the 3rd Innovations in Theoretical Computer Science
Conference (ITCS 2012). 214‚Äì226.
[24] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard S.
Zemel. 2011. Fairness Through Awareness. Computing Research Repository (CoRR)
(2011).
[25] Cynthia Dwork, Frank Mcsherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
brating Noise to Sensitivity in Private Data Analysis. In Theory of Cryptography
Conference. Springer, 265‚Äì284.
[26] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Calibrat-
ing Noise to Sensitivity in Private Data Analysis. In TCC. 265‚Äì284.
[27] Steven Englehardt, Christian Eubank, Peter Zimmerman, Dillon Reisman,
and Arvind Narayanan. 2014. Web Privacy Measurement: Scientific prin-
ciples, engineering platform, and new results. Manuscript posted at http:
//randomwalker.info/publications/WebPrivacyMeasurement.pdf. (June 2014).
Accessed Nov. 22, 2014.
[28] European Commission. 2016. General Data Protection Regulation (GDPR). Regu-
lation (EU) 2016/679, L119. (May 2016).
[29] Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and
Suresh Venkatasubramanian. 2015. Certifying and Removing Disparate Impact.
In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD ‚Äô15). ACM, New York, NY, USA, 259‚Äì268.
[30] Michael Feldman, Sorelle A. Friedler, John Moeller, Carlos Scheidegger, and
Suresh Venkatasubramanian. 2015. Certifying and Removing Disparate Impact. In
Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining (KDD).
[31] Nicole Freeling. 2016. How Big Data is helping students graduate on time.
(2016). https://www.universityofcalifornia.edu/news/how-big-data-helping-
students-graduate-time (Accessed Nov 11, 2016).
[32] Edward W. Frees, Richard A. Derrig, and Glenn Meyers. 2014. Predictive Modeling
Applications in Actuarial Science. Cambridge University Press.
[33] Deepak Garg, Limin Jia, and Anupam Datta. 2011. Policy auditing over incom-
plete logs: theory, implementation and applications. In Proceedings of the ACM
Conference on Computer and Communications Security (CCS).
[34] Adrian Gepp, J. Holton Wilson, Kuldeep Kumar, and Sukanto Bhattacharya. 2012.
A Comparative Analysis of Decision Trees Vis-a-vis Other Computational Data
Mining Techniques in Automotive Insurance Fraud Detection. Journal of Data
Science 10, 3 (2012), 537‚Äì561.
[35] Saikat Guha, Bin Cheng, and Paul Francis. 2010. Challenges in Measuring Online
Advertising Systems. In Proceedings of the 10th ACM SIGCOMM Conference on
Internet Measurement (IMC ‚Äô10). ACM, New York, NY, USA, 81‚Äì87.
[36] Aniko Hannak, Piotr Sapiezynski, Arash Molavi Kakhki, Balachander Krish-
namurthy, David Lazer, Alan Mislove, and Christo Wilson. 2013. Measuring
Personalization of Web Search. In Proceedings of the 22nd International Conference
on World Wide Web (WWW ‚Äô13). ACM, New York, NY, USA, 527‚Äì538.
[37] Aniko Hannak, Gary Soeller, David Lazer, Alan Mislove, and Christo Wilson.
2014. Measuring Price Discrimination and Steering on E-commerce Web Sites.
In Proceedings of the 2014 Conference on Internet Measurement Conference (IMC
‚Äô14). ACM, New York, NY, USA, 305‚Äì318.
[38] Robert Hare. 2003. Manual For the Revised Psychopathy Checklist. Multi-Health
Systems.
(1 2016).
[39] Benjamin Harold. 2016. The Future of Big Data and Analytics in K-12 Education.
[40] Andrew Hilts, Christopher Parsons, and Jeffrey Knockel. 2016. Every Step You
Fake: A Comparative Analysis of Fitness Tracker Privacy and Security. (2016).
https://openeffect.ca/fitness-tracker-privacy-and-security/ Accessed Nov 11,
2016.
[41] Wassily Hoeffding. 1963. Probability Inequalities for Sums of Bounded Random
Variables. J. Amer. Statist. Assoc. 58, 301 (March 1963), 13‚Äì30.
[42] Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma. 2011. Fairness-aware
learning through regularization approach. In Proceedings of the Workshop on
Privacy Aspects of Data Mining.
[43] Mathias L√©cuyer, Guillaume Ducoffe, Francis Lan, Andrei Papancea, Theofilos
Petsios, Riley Spahn, Augustin Chaintreau, and Roxana Geambasu. 2014. XRay:
Enhancing the Web‚Äôs Transparency with Differential Correlation. In Proceed-
ings of the 23rd USENIX Conference on Security Symposium (SEC‚Äô14). USENIX
Association, Berkeley, CA, USA, 49‚Äì64.
[44] Mathias Lecuyer, Riley Spahn, Yannis Spiliopolous, Augustin Chaintreau, Roxana
Geambasu, and Daniel Hsu. 2015. Sunlight: Fine-grained Targeting Detection
at Scale with Statistical Confidence. In Proceedings of the 22Nd ACM SIGSAC
Conference on Computer and Communications Security (CCS ‚Äô15). ACM, New York,
NY, USA, 554‚Äì566.
[45] Benjamin Letham, Cynthia Rudin, Tyler H. McCormick, and David Madigan.
2015. Interpretable classifiers using rules and Bayesian analysis: Building a better
stroke prediction model. Ann. Appl. Stat. 9, 3 (09 2015), 1350‚Äì1371.
[46] Richard J. Lipton and Kenneth W. Regan. 2016. Making Public Information Secret.
(2016). https://rjlipton.wordpress.com/2016/05/20/making-public-information-
secret/ Accessed Aug 13, 2016.
[47] Changchang Liu, Supriyo Chakraborty, and Prateek Mittal. 2016. Dependence
Makes You Vulnerable: Differential Privacy Under Dependent Tuples. In Network
and Distributed System Security Symposium (NDSS). The Internet Society.
[48] Binh Thanh Luong, Salvatore Ruggieri, and Franco Turini. 2011. k-NN As an
Implementation of Situation Testing for Discrimination Discovery and Preven-
tion. In Proceedings of the ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD).
[49] Teena Maddox. 2016.
The Dark Side of Wearables.
//www.techrepublic.com/article/the-dark-side-of-wearables-how-theyre-
secretly-jeopardizing-your-security-and-privacy/ Accessed Nov 11, 2016.
[50] Sumaria Mohan-Neill, Indira Neill Hoch, and Meng li. 2014. An Analysis of Us
Household Socioeconomic Profiles Based on Marital Status and Gender. Journal
of Economics and Economic Education Research 3 (9 2014).
[51] Helen Nissenbaum. 2009. Privacy in Context: Technology, Policy, and the Integrity
(2016).
http:
of Social Life. Stanford University Press.
In Quantified: Biosensing Technologies in Everyday Life. MIT Press, 80‚Äì100.
[52] Helen Nissenbaum and Heather Patterson. 2016. A Value for n-Person Games.
[53] The President‚Äôs Council of Advisors on Science and Technology. 2014. Big Data
and Privacy: A Technological Perspective. Technical Report. Executive Office of
the President.
[54] Office of the Privacy Commissioner of Canada. 2015. PIPEDA legislation and
regulations. (2015). https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-
canada/the-personal-information-protection-and-electronic-documents-act-
pipeda/ Accessed May 15, 2017.
[55] Office for Civil Rights. 2003. Summary of the HIPAA Privacy Rule. OCR Privacy
Brief, U.S. Department of Health and Human Services. (2003).
[56] John Paparrizos, Ryen W. White, and Eric Horvitz. 2016. Screening for Pancreatic
Adenocarcinoma Using Signals From Web Search Logs: Feasibility Study and
Results. Journal of Oncology Practice 12, 8 (2016), 737‚Äì744. https://doi.org/
10.1200/JOP.2015.010504 PMID: 27271506.
[57] Frank Pasquale. 2015. The Black Box Society: The Secret Algorithms That Control
Money and Information. Harvard University Press, Cambridge, MA, USA. http:
//www.hup.harvard.edu/catalog.php?isbn=9780674368279
[58] Shayak Sen, Saikat Guha, Anupam Datta, Sriram K. Rajamani, Janice Tsai, and
Jeannette M. Wing. 2014. Bootstrapping Privacy Compliance in Big Data Systems.
In Proceedings of the 2014 IEEE Symposium on Security and Privacy (SP ‚Äô14). IEEE
Computer Society, Washington, DC, USA, 327‚Äì342.
[59] Geoffrey Smith. 2015. Recent Developments in Quantitative Information Flow
(Invited Tutorial). In Proceedings of the 2015 30th Annual ACM/IEEE Symposium on
Logic in Computer Science (LICS) (LICS ‚Äô15). IEEE Computer Society, Washington,
DC, USA, 23‚Äì31.
[60] S.E. Smith. 2015. How do search engines respond when you Google ‚Äòsuicide‚Äô?
(2015). https://www.dailydot.com/via/germanwings-suicide-hotline/ Accessed
May 15, 2017.
[61] Daniel J. Solove. 2006. A Taxonomy of Privacy. University of Pennsylvania Law
Review 154, 3 (Jan. 2006), 477‚Äì560.
[62] Hugo Teufel III. 2008. Privacy Policy Guidance Memorandum: The Fair In-
formation Practice Principles: Framework for Privacy Policy at the Depart-
ment of Homeland Security. Memorandum Number: 2008-01. (Dec. 2008).
https://www.dhs.gov/xlibrary/assets/privacy/privacypolicyguide2008-01.pdf
[63] Florian Tram√®r, Vaggelis Atlidakis, Roxana Geambasu, Daniel J. Hsu, Jean-Pierre
Hubaux, Mathias Humbert, Ari Juels, and Huang Lin. 2015. Discovering Un-
warranted Associations in Data-Driven Applications with the FairTest Testing
Toolkit. CoRR abs/1510.02377 (2015).
[64] Michael Carl Tschantz, Anupam Datta, and Jeannette M. Wing. 2012. Formalizing
and Enforcing Purpose Restrictions in Privacy Policies. In Proceedings of the 2012
IEEE Symposium on Security and Privacy. Washington, DC, USA, 176‚Äì190.
[65] Michael Carl Tschantz, Anupam Datta, and Jeannette M. Wing. 2012. Formalizing
and Enforcing Purpose Restrictions in Privacy Policies. In IEEE Symposium on
Security and Privacy, SP 2012, 21-23 May 2012, San Francisco, California, USA.
176‚Äì190.
[66] Joseph Turow. 2011. The Daily You: How the New Advertising Industry Is Defining
Your Identity and Your Worth. Yale University Press.
[67] J. Turow. 2017. The Aisles Have Eyes: How Retailers Track Your Shopping, Strip
Your Privacy, and Define Your Power. Yale University Press.
the Personal
(PIPEDA). 2014.
[68] Findings under
Documents Act
tion for
https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/
investigations-into-businesses/2014/pipeda-2014-001/
2017).
Information Protection and Electronic
Use of sensitive health informa-
(2014).
targeting of Google ads raises privacy concerns.
(Accessed May 15,
[69] Thomas Vissers, Nick Nikiforakis, Nataliia Bielova, and Wouter Joosen. 2014.
Crying wolf? On the price discrimination of online airline tickets. In 7th Work-
shop on Hot Topics in Privacy Enhancing Technologies (HotPETs 2014). https:
//lirias.kuleuven.be/handle/123456789/454872"
[70] Siva Viswanathan. 2010. Business Intelligence and Predictive Analytics for
Financial Services: The Untapped Potential of Soft Information. In Digits: Center
for Digital Innovation, Technology, and Strategy ‚ÄúResearch in Practice‚Äù Paper Series.
Robert H. Smith School of Business, University of Maryland.
[71] Craig E. Wills and Can Tatar. 2012. Understanding what they do with what they
know. In Proceedings of the 2012 ACM Workshop on Privacy in the Electronic Society.
New York, NY, USA, 13‚Äì18. http://doi.acm.org/10.1145/2381966.2381969
[72] Rich Zemel, Yu Wu, Kevin Swersky, Toni Pitassi, and Cynthia Dwork. 2013.
Learning Fair Representations. In Proceedings of the Internetional Conference on
Machine Learning.
A PROOF OF THEOREM 1
Theorem 1. No definition of proxy use can satisfy Properties 1-4
simultaneously.
Proof. Proof by contradiction. Assume that a definition of proxy
use satisfies all four properties. Let X, Y, and Z be uniform binary
random variables, such that Pr(Y = X ‚äï Z) = 1, but X, Y and Z
are pairwise independent. By (explicit use of proxy), the model
ùíú(Y , Z) = Y ‚äï Z has proxy use of Z. By (dummy), the model
ùíú‚Ä≤(Y , Z , X) = Y ‚äï Z has proxy use of Z. Choose f (x, z) = x ‚äï z. By
our assumption earlier, Pr(Y = f (X , Z)) = 1. Therefore, by (prepro-
cessing), the model ùíú‚Ä≤‚Ä≤(Z , X) = ùíú‚Ä≤(f (X , Z), Z , X) has proxy use of
Z. Note that ùíú‚Ä≤‚Ä≤(Z , X) = X ‚äï Z ‚äï Z = X. Therefore, by (dummy),
ùíú‚Ä≤‚Ä≤‚Ä≤(X) = X has proxy use of Z. But, by (independence), ùíú‚Ä≤‚Ä≤‚Ä≤ does
not have proxy use of Z. Therefore, we have a contradiction.
‚ñ°
The key intuition behind this result is that Property 2 requires
proxy use to be preserved when an input is replaced with a function
that predicts that input via composition. However, with a purely
semantic view of function composition, the causal effect of the
proxy can disappear. The particular example of this observation we
use in the proof is Y ‚äï Z, where Z is the protected information type.
This function has proxy use of Z. However, if X ‚äï Z is a perfect
predictor for Y, then the example can be reduced to X ‚äï Z ‚äï Z = X,
which has no proxy use of Z. To overcome this impossibility result,
we choose a more syntactic notion of function composition, which
is tied to how the function is represented as a program, and looks
for evidence of proxy use within the representation.
B ALGORITHM FOR DETECTION
In this section we provide technical details about the detection
algorithm skipped from the main body of the paper. In particular, we
formally define the decomposition used in the implementation, how
machine learning models are translated to the term language, and
how associational tests mitigate spurious results due to sampling.
B.1 Decomposition
Before we present the formal algorithm for detection, we need to
develop notation for precisely denoting decompositions. Decompo-
sition follows naturally from the subterm relation on expressions.
However, as identical subterms can occur multiple times in an ex-
pression, care must be taken during substitution to distinguish
between occurrences. For this reason we define substitution po-
sitionally, where the subterm of expression e = op(e1, . . . , en) at
Algorithm 4 Detection for expression programs.
Require: association (d), influence(Œπ) measures
procedure ProxyDetect(p, X, Z , œµ, Œ¥)
P ‚Üê ‚àÖ
for each term e appearing in p do
p1 ‚Üê Œªx1, . . . , xn .e
Q ‚Üê {q | p|q = e}
for each k ‚àà [1, . . . , |Q|],(q1, . . . , qk) ‚àà Q do
p2 ‚Üê Œªx1, . . . , xn, u.p[u]q1, ...,qk
if Œπ(p1, p2) ‚â• Œ¥ ‚àß d((cid:74)p1(cid:75)(X), Z) ‚â• œµ then
P ‚Üê P ‚à™ {(p1, p2)}
end if
end for
end for
return P
position q, written e|q, is defined inductively:
op(e1, . . . , en)|q =
op(e1, . . . , en)
ei|q‚Ä≤
op(ei1 , . . . , eik )
‚ä•
if q = œµ
if q = iq‚Ä≤ ‚àß 1 ‚â§ i ‚â§ n
if q = {i1, . . . , ik}