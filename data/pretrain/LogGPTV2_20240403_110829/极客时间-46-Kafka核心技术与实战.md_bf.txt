# 设置环境变量BASE_DIR=/Users/huxi/testenv 
# 你需要修改此处CERT_OUTPUT_PATH="$BASE_DIR/certificates"PASSWORD=test1234KEY_STORE="$CERT_OUTPUT_PATH/server.keystore.jks"TRUST_STORE="$CERT_OUTPUT_PATH/server.truststore.jks"CLIENT_KEY_STORE="$CERT_OUTPUT_PATH/client.keystore.jks"CLIENT_TRUST_STORE="$CERT_OUTPUT_PATH/client.truststore.jks"KEY_PASSWORD=$PASSWORDSTORE_PASSWORD=$PASSWORDTRUST_KEY_PASSWORD=$PASSWORDTRUST_STORE_PASSWORD=$PASSWORDCERT_AUTH_FILE="$CERT_OUTPUT_PATH/ca-cert"DAYS_VALID=365DNAME="CN=Xi Hu, OU=YourDept, O=YourCompany, L=Beijing, ST=Beijing, C=CN"  mkdir -p $CERT_OUTPUT_PATH echo "1. 产生 key 和证书......"keytool -keystore $KEY_STORE -alias kafka-server -validity $DAYS_VALID -genkey -keyalg RSA \-storepass $STORE_PASSWORD -keypass $KEY_PASSWORD -dname "$DNAME" keytool -keystore $CLIENT_KEY_STORE -alias kafka-client -validity $DAYS_VALID -genkey -keyalg RSA \-storepass $STORE_PASSWORD -keypass $KEY_PASSWORD -dname "$DNAME" echo "2. 创建 CA......"openssl req -new -x509 -keyout $CERT_OUTPUT_PATH/ca-key -out "$CERT_AUTH_FILE" -days "$DAYS_VALID" \-passin pass:"$PASSWORD" -passout pass:"$PASSWORD" \-subj "/C=CN/ST=Beijing/L=Beijing/O=YourCompany/OU=YourDept,CN=Xi Hu" echo "3. 添加 CA 文件到 broker truststore......"keytool -keystore "$TRUST_STORE" -alias CARoot \-importcert -file "$CERT_AUTH_FILE" -storepass "$TRUST_STORE_PASSWORD" -keypass "$TRUST_KEY_PASS" -noprompt echo "4. 添加 CA 文件到 client truststore......"keytool -keystore "$CLIENT_TRUST_STORE" -alias CARoot \-importcert -file "$CERT_AUTH_FILE" -storepass "$TRUST_STORE_PASSWORD" -keypass "$TRUST_KEY_PASS" -noprompt echo "5. 从 keystore 中导出集群证书......"keytool -keystore "$KEY_STORE" -alias kafka-server -certreq -file "$CERT_OUTPUT_PATH/server-cert-file" \-storepass "$STORE_PASSWORD" -keypass "$KEY_PASSWORD" -noprompt keytool -keystore "$CLIENT_KEY_STORE" -alias kafka-client -certreq -file "$CERT_OUTPUT_PATH/client-cert-file" \-storepass "$STORE_PASSWORD" -keypass "$KEY_PASSWORD" -noprompt echo "6. 使用 CA 签发证书......"openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca-key -in "$CERT_OUTPUT_PATH/server-cert-file" \-out "$CERT_OUTPUT_PATH/server-cert-signed" -days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD" openssl x509 -req -CA "$CERT_AUTH_FILE" -CAkey $CERT_OUTPUT_PATH/ca-key -in "$CERT_OUTPUT_PATH/client-cert-file" \-out "$CERT_OUTPUT_PATH/client-cert-signed" -days "$DAYS_VALID" -CAcreateserial -passin pass:"$PASSWORD" echo "7. 导入 CA 文件到 keystore......"keytool -keystore "$KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$STORE_PASSWORD" \ -keypass "$KEY_PASSWORD" -noprompt keytool -keystore "$CLIENT_KEY_STORE" -alias CARoot -import -file "$CERT_AUTH_FILE" -storepass "$STORE_PASSWORD" \ -keypass "$KEY_PASSWORD" -noprompt echo "8. 导入已签发证书到 keystore......"keytool -keystore "$KEY_STORE" -alias kafka-server -import -file "$CERT_OUTPUT_PATH/server-cert-signed" \ -storepass "$STORE_PASSWORD" -keypass "$KEY_PASSWORD" -noprompt keytool -keystore "$CLIENT_KEY_STORE" -alias kafka-client -import -file "$CERT_OUTPUT_PATH/client-cert-signed" \ -storepass "$STORE_PASSWORD" -keypass "$KEY_PASSWORD" -noprompt echo "9. 删除临时文件......"rm "$CERT_OUTPUT_PATH/ca-cert.srl"rm "$CERT_OUTPUT_PATH/server-cert-signed"rm "$CERT_OUTPUT_PATH/client-cert-signed"rm "$CERT_OUTPUT_PATH/server-cert-file"rm "$CERT_OUTPUT_PATH/client-cert-file"你可以把上面的代码保存成一个 SHELL 脚本，然后在一台 Broker上运行。该脚本主要的产出是 4个文件，分别是：server.keystore.jks、server.truststore.jks、client.keystore.jks和 client.truststore.jks。你需要把以 server 开头的两个文件，拷贝到集群中的所有 Broker 机器上，把以client 开头的两个文件，拷贝到所有要连接 Kafka集群的客户端应用程序机器上。接着，你要配置每个 Broker 的 server.properties 文件，增加以下内容：    listeners=SSL://localhost:9093ssl.truststore.location=/Users/huxi/testenv/certificates/server.truststore.jksssl.truststore.password=test1234ssl.keystore.location=/Users/huxi/testenv/certificates/server.keystore.jksssl.keystore.password=test1234security.inter.broker.protocol=SSLssl.client.auth=requiredssl.key.password=test1234现在我们启动 Broker进程。倘若你发现无法启动或启动失败，那么你需要检查一下报错信息，看看和上面的哪些配置有关，然后有针对性地进行调整。接下来，我们来配置客户端的SSL。首先，我们要创建一个名为 client-ssl.config 的文件，内容如下：    security.protocol=SSLssl.truststore.location=/Users/huxi/testenv/certificates/client.truststore.jksssl.truststore.password=test1234ssl.keystore.location=/Users/huxi/testenv/certificates/server.keystore.jksssl.keystore.password=test1234ssl.key.password=test1234ssl.endpoint.identification.algorithm=注意，一定要加上最后一行。因为自 Kafka 2.0版本开始，它默认会验证服务器端的主机名是否匹配 Broker端证书里的主机名。如果你要禁掉此功能的话，一定要将该参数设置为空字符串。配置好这些，你可以使用 ConsoleConsumer 和 ConsoleProducer 来测试一下Producer 和 Consumer 是否能够正常工作。比如，下列命令指定producer-config 指向刚才我们创建的 client-ssl 配置文件。    $ bin/kafka-console-producer.sh --broker-list localhost:9093 --topic test --producer.config client-ssl.config好了，现在我们来说说 ACL 的配置。如果你在运营一个云上的 Kafka集群，那么势必会面临多租户的问题。**除了设置合理的认证机制外，为每个连接Kafka集群的客户端授予恰当的权限，也是非常关键的**。现在我来给出一些最佳实践。第一，就像前面说的，要开启 ACL，你需要设置authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer。第二，我建议你采用白名单机制，这样的话，没有显式设置权限的用户就无权访问任何资源。也就是说，在Kafka 的 server.properties 文件中，不要设置allow.everyone.if.no.acl.found=true。第三，你可以使用 kafka-acls 脚本为 SSL用户授予集群的权限。我们以前面的例子来进行一下说明。在配置 SSL 时，我们指定用户的 Distinguished Name 为"CN=Xi Hu,OU=YourDept, O=YourCompany, L=Beijing, ST=Beijing, C=CN"。之前在设置Broker 端参数时，我们指定了security.inter.broker.protocol=SSL，即强制指定 Broker 间的通讯也采用 SSL加密。如果不为指定的 Distinguished Name 授予集群操作的权限，你是无法成功启动Broker 的。因此，你需要在启动 Broker 之前执行下面的命令：    $ bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:"CN=Xi Hu,OU=YourDept,O=YourCompany,L=Beijing,ST=Beijing,C=CN" --operation All --cluster第四，你要为客户端程序授予相应的权限，比如为生产者授予 producer权限，为消费者授予 consumer 权限。假设客户端要访问的主题名字是test，那么命令如下：    $ bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:"CN=Xi Hu,OU=YourDept,O=YourCompany,L=Beijing,ST=Beijing,C=CN" --producer --topic 'test'    $ bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 --add --allow-principal User:"CN=Xi Hu,OU=YourDept,O=YourCompany,L=Beijing,ST=Beijing,C=CN" --consumer --topic 'test' --group '*'注意这两条命令中的 \--producer 和\--consumer，它们类似于一个快捷方式，直接将 Producer 和 Consumer常用的权限进行了一次性的授予。作为云环境 PaaS管理员，除了以上这些必要的权限，你最好不要把其他权限授予客户端，比如创建主题的权限。总之，你授予的权限越少，你的Kafka 集群就越安全。
## 小结讲到这里，我们就完整地把 Kafka 授权机制梳理了一遍。除此之外，我还附赠了SSL端配置方法。希望你能将这两讲关于安全配置的内容结合起来学习，打造一个超级安全的Kafka 集群。![](Images/7559288e77a0a532519353cfdebc6b18.png){savepage-src="https://static001.geekbang.org/resource/image/39/66/39431082a84db9a3ed0dacd085f60f66.jpg"}
## 开放讨论Kafka提供的权限有很多种，我们今天讨论的内容只覆盖了其中最重要的几个权限。如果要让一个客户端能够查询消费者组的提交位移数据，你觉得应该授予它什么权限？欢迎写下你的思考和答案，我们一起讨论。如果你觉得有所收获，也欢迎把文章分享给你的朋友。![](Images/a7d15815f9efb5693db5b2d278244658.png){savepage-src="https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg"}
# 35 \| 跨集群备份解决方案MirrorMaker你好，我是胡夕。今天我要和你分享的主题是：Kafka 的跨集群数据镜像工具MirrorMaker。一般情况下，我们会使用一套 Kafka集群来完成业务，但有些场景确实会需要多套 Kafka集群同时工作，比如为了便于实现灾难恢复，你可以在两个机房分别部署单独的Kafka集群。如果其中一个机房出现故障，你就能很容易地把流量打到另一个正常运转的机房下。再比如，你想为地理相近的客户提供低延时的消息服务，而你的主机房又离客户很远，这时你就可以在靠近客户的地方部署一套Kafka 集群，让这套集群服务你的客户，从而提供低延时的服务。如果要实现这些需求，除了部署多套 Kafka集群之外，你还需要某种工具或框架，来帮助你实现数据在集群间的拷贝或镜像。值得注意的是，**通常我们把数据在单个集群下不同节点之间的拷贝称为备份，而把数据在集群间的拷贝称为镜像**（Mirroring）。今天，我来重点介绍一下 Apache Kafka 社区提供的 MirrorMaker工具，它可以帮我们实现消息或数据从一个集群到另一个集群的拷贝。
## 什么是 MirrorMaker？从本质上说，MirrorMaker 就是一个消费者 +生产者的程序。消费者负责从源集群（SourceCluster）消费数据，生产者负责向目标集群（TargetCluster）发送消息。整个镜像流程如下图所示：``{=html}![](Images/2b81fa12ef66a877b5835b4540e1b13b.png){savepage-src="https://static001.geekbang.org/resource/image/fe/8c/fe4e9c756bf30933ec3dba10bad30e8c.png"}MirrorMaker连接的源集群和目标集群，会实时同步消息。当然，你不要认为你只能使用一套MirrorMaker来连接上下游集群。事实上，很多用户会部署多套集群，用于实现不同的目的。我们来看看下面这张图。图中部署了三套集群：左边的源集群负责主要的业务处理；右上角的目标集群可以用于执行数据分析；而右下角的目标集群则充当源集群的热备份。![](Images/d5dba9760010df19904ca2826e7eb7e8.png){savepage-src="https://static001.geekbang.org/resource/image/63/78/63fb620532337fcfdfd1ca2df351a378.png"}
## 运行 MirrorMakerKafka 默认提供了 MirrorMaker 命令行工具 kafka-mirror-maker脚本，它的常见用法是指定生产者配置文件、消费者配置文件、线程数以及要执行数据镜像的主题正则表达式。比如下面的这个命令，就是一个典型的MirrorMaker 执行命令。    $ bin/kafka-mirror-maker.sh --consumer.config ./config/consumer.properties --producer.config ./config/producer.properties --num.streams 8 --whitelist ".*"现在我来解释一下这条命令中各个参数的含义。-   consumer.config 参数。它指定了 MirrorMaker    中消费者的配置文件地址，最主要的配置项是**bootstrap.servers**，也就是该    MirrorMaker 从哪个 Kafka 集群读取消息。因为 MirrorMaker    有可能在内部创建多个消费者实例并使用消费者组机制，因此你还需要设置    group.id 参数。另外，我建议你额外配置    auto.offset.reset=earliest，否则的话，MirrorMaker    只会拷贝那些在它启动之后到达源集群的消息。-   producer.config 参数。它指定了 MirrorMaker    内部生产者组件的配置文件地址。通常来说，Kafka Java Producer    很友好，你不需要配置太多参数。唯一的例外依然是**bootstrap.servers**，你必须显式地指定这个参数，配置拷贝的消息要发送到的目标集群。-   num.streams    参数。我个人觉得，这个参数的名字很容易给人造成误解。第一次看到这个参数名的时候，我一度以为    MirrorMaker 是用 Kafka Streams    组件实现的呢。其实并不是。这个参数就是告诉 MirrorMaker 要创建多少个    KafkaConsumer    实例。当然，它使用的是多线程的方案，即在后台创建并启动多个线程，每个线程维护专属的消费者实例。在实际使用时，你可以根据你的机器性能酌情设置多个线程。-   whitelist    参数。如命令所示，这个参数接收一个正则表达式。所有匹配该正则表达式的主题都会被自动地执行镜像。在这个命令中，我指定了".\*"，这表明我要同步源集群上的所有主题。