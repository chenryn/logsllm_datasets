### Table 12: Average Accuracy Over 5 Runs of the Fine-Pruning Defense, VGG-LL UTKFace, for Three Subpopulations Impacted by the Attack

| Original Model Target | Pruned Test | Pruned Target | FT Test | FT Target | FT Target Ïƒ |
|-----------------------|-------------|---------------|---------|-----------|-------------|
| 0.890                 | 0.798       | 0.508         | 0.577   | 0.508     | 0.356       |
| 0.839                 | 0.797       | 0.503         | 0.595   | 0.578     | 0.286       |
| 0.838                 | 0.796       | 0.497         | 0.563   | 0.665     | 0.376       |
| 0.838                 | 0.797       | 0.497         | 0.736   | 0.789     | 0.161       |
| 0.838                 | 0.782       | 0.524         | 0.542   | 0.452     | 0.106       |
| 0.839                 | 0.782       | 0.524         | 0.532   | 0.448     | 0.083       |
| 0.839                 | 0.782       | 0.524         | 0.634   | 0.510     | 0.115       |
| 0.839                 | 0.782       | 0.524         | 0.685   | 0.657     | 0.205       |
| 0.840                 | 0.782       | 0.419         | 0.464   | 0.161     | 0.000       |
| 0.842                 | 0.782       | 0.419         | 0.622   | 0.832     | 0.035       |
| 0.842                 | 0.781       | 0.419         | 0.690   | 0.684     | 0.299       |
| 0.841                 | 0.782       | 0.419         | 0.704   | 0.690     | 0.219       |

**Note:** The columns represent the original model target subpopulation accuracy, and the test and target accuracy after the attack, after the pruning phase, and after the fine-tuning phase of the defense. We also report the standard deviation for Target accuracy after fine-tuning.

### Algorithm 4: TRIM Defense Against Availability Attacks
Iteratively identifies poisoning by high loss values and trains without those points.

**Input:**
- Training data \( D \) of \( n \) examples
- Loss function \( \ell \)
- Attack count \( m \)
- Training algorithm \( A \)
- Maximum iteration count \( T \)

**Procedure:**
1. Initialize \( IND = [n] \), \( IND\_PREV = [] \), and \( Iterations = 0 \).
2. While \( IND \neq IND\_PREV \) and \( Iterations < T \):
   - Set \( IND\_PREV = IND \)
   - Increment \( Iterations \)
   - Train model \( f = A(D[IND]) \)
   - Compute all losses: \( Losses = [\ell(x_i, y_i) | (x_i, y_i) \in D] \)
   - Update \( IND \) to the indices of the lowest \( n - m \) losses
3. Return the trained model \( f \).

### Discussion on TRIM and SEVER Defenses
The TRIM defense can exacerbate the poisoning attack if the subpopulation attack causes a bias towards the poisoned class. This bias leads TRIM to misidentify real data as the attack, further intensifying the poisoning. Similar results are observed with the SEVER defense. These findings highlight a failure mode of existing availability defenses in protecting against subpopulation attacks.

### Results of Fine Pruning Defense
Table 12 presents the results of the fine-pruning defense. A large, clean holdout set is required for fine pruning, which makes it challenging to apply in our threat model. Tables 13 and 14 show that the certified defense still allows high target damages for many subpopulations.

### Subpopulation Transferability
Table 15 shows the results of attacking CIFAR-10 + VGG-FT with ClusterMatch using subpopulations generated with ResNet-50 embeddings. The attack is less successful with transferred embeddings but remains effective, with most subpopulations exhibiting 15-16% target damage and no more than 2% collateral damage. Knowledge of the learner's model architecture is helpful but not necessary for generating ClusterMatch subpopulations.

### Example ClusterMatch Subpopulations
Figure 3 illustrates six example subpopulations generated with ClusterMatch on UTKFace. While not perfectly human-interpretable, these subpopulations exhibit consistent trends. For instance:
- Figure 3a: Primarily older white men.
- Figure 3b: Mostly older white women.
- Figure 3c: Bearded men or men with darker skin color (potentially including some white men in darker environments).

### Influence Functions Results
Influence functions were proposed for targeted poisoning attacks with a single target point. However, they can also attack multiple test points simultaneously. To compare with the experiment in [30], we use ClusterMatch to generate target sets and show that it makes the attack easier than manual selection. The results in Table 16 indicate that ClusterMatch targets are easier to attack and require fewer iterations to compromise when vulnerable.

### Table 16: Effectiveness of ClusterMatch in Aid of Influence-Based Poisoning Attack Generation

| Selection Method | Worst-1 Success Rate | Worst-5 Success Rate | Iterations (Successful) |
|------------------|----------------------|----------------------|-------------------------|
| Random           | 0.24                 | 0.6                  | 380                     |
| ClusterMatch     | 1.0                  | 1.0                  | 250                     |

**Note:** The test points drawn from the Kaggle Cats and Dogs dataset were easier to attack than those used in [30], likely due to distribution differences between ImageNet and the Kaggle dataset.