These choices are motivated by the following considerations: while simple cryptographic
constructions like key exchange and digital signatures reveal only a few samples (per fresh
secret) to the adversary, other constructions like homomorphic encryption, identity/attribute-
based encryption, and pseudorandom functions can reveal a much larger (possibly even
adversary-determined) number of samples.
Clearly, revealing more samples cannot increase the hardness of an instantiation, be-
cause the attacker can just ignore some of them. There is also evidence that in certain
parameter regimes, such as small bounded errors, increasing the number of samples can
signiï¬cantly reduce concrete hardness [AG11; Alb+14]. At the same time, the main worst-
case hardness theorems for Ring-LWE place mild or no conditions at all on the number
of samples [LPR13b, Theorem 3.6], and the same goes for plain LWE [Reg09; Pei09;
Bra+13]. (Worst-case hardness theorems for less-standard LWE instantiations [MP13],
and for (Ring-)LWR [BPR12; Alw+13; Bog+16; AA16], do have a strong dependence on
the number of samples, however.) There are also standard techniques to generate fresh
(Ring-)LWE samples from a ï¬xed number of given ones, though at a cost in the error rate of
the new samples [Lyu05; GPV08; App+09].
In summary, the practical effect of the number of samples on concrete hardness is
unclear, and seems to depend heavily on the other parameters of the instantiation. Therefore,
we separately consider both the small- and moderate-sample regime for our challenge
instantiations.
7.1.2 Other Related Work
In a recent concurrent and independent work, Buchmann et al. [Buc+16] describe a method
and implementation for creating challenges for LWE (but not Ring-LWE). Both their work
and ours encounter a common issueâ€”that naÃ¯ve methods of generating challenges require
knowing the solutionsâ€”but their main goal is quite different from ours: to prevent the
solutions from existing in any one place, so that nobody is excluded from participating in
210
the subsequent cryptanalysis. They accomplish this by generating the challenges using a
multi-party computation protocol, so that the solutions never reside with any single party.
(Their implementation uses three parties, although this is not inherent to the approach.)
The protocol of [Buc+16] also allows for retroactively auditing that the parties honestly
executed the protocol as implemented, but only after a challenge has been solved. This is a
substantially weaker veriï¬ability property than we obtain, for at least three reasons:
1. First, just half of the parties can undetectably create harder-than-expected or even
unsolvable instances, which would never have the chance to be audited at all. To
achieve the same end in our system, the challenger and the randomness beacon (e.g.,
NIST) would have to collude.
2. Second, auditing the MPC protocol requires the parties to retain their secret input
seeds in perpetuity, and to reveal them when challenge solutions are found. If any
of the seeds are lost, then so is veriï¬ability. In our system, once the cut-and-choose
protocol completes, the challenges are self-contained and veriï¬able with no external
help.
3. Third, even if the parties do run the MPC protocol of [Buc+16] as implemented, one
still needs to carefully audit the code to conclude that the resulting challenges actually
have solutions. In fact, due to an bug, the ï¬rst set of published challenges had no
solutions! In our system, one does not need to trust or audit code, but only check that
the â€œspoiledâ€ instances have proper-looking errors.
Over the years there have been many analyses of various LWE parameterizations, in both
the asymptotic and concrete settings, against various kinds of attacks, e.g., [MR09; LP11;
AFG13; Alb+14; Alb+15; APS15; HKM15]. All of these apply equally well to Ring-LWE,
which can be viewed as a specialized form of LWE, although they do not attempt to exploit
the ring structure.
211
Cryptanalytic challenges have been provided for many other kinds of problems and
cryptosystems, including integer factorization [91], discrete logarithm on elliptic curve
groups [97], short-vector problems on ad-hoc distributions of ideal lattices [PS13a], the
NTRU cryptosystem [15], and multivariate cryptosystems [Yas+15].
7.1.3 Organization
The remainder of the paper uses the background material from chapter 2 and is organized as
follows:
Section 7.2 describes our non-interactive, publicly veriï¬able â€œcut-and-chooseâ€ protocol for
giving evidence that the challenge instances are properly distributed.
Section 7.3 gives further details on how we choose our instantiationsâ€™ parameters, speciï¬-
cally their Gaussian widths and moduli.
Section 7.4 describes how we obtain approximate hardness estimates for our challenge
instantiations.
Section 7.5 gives some lower-level technical details about our implementation and the
operational security measures we used while creating the challenges.
Acknowledgments. We thank Oded Regev for helpful discussions, and for initially sug-
gesting the idea of publishing Ring-LWE challenges.
7.2 Cut-and-Choose Protocol
A central issue in the creation of challenges for LWE-like problems is that a dishonest
challenger could publish improperly generated instances that are much harder than honestly
generated ones, or even impossible to solve, because they have larger error than claimed
or are even uniformly random. Because both the proper and improper distributions are
conjectured to be pseudorandom, such misbehavior would be very difï¬cult to detect. This
212
stands in contrast to other types of cryptographic challenges for, e.g., the factoring or discrete
logarithm problems, where improper distributions like unbalanced factors or non-uniform
exponents seem like they can only make the instances easier to solve (or at least no harder),
so the challenger has no incentive to use them.
To deal with this issue, we use a simple, non-interactive, publicly veriï¬able â€œcut-and-
chooseâ€ protocol to give reasonably convincing evidence that the challenge instances are
properly distributed, or at least not much harder than claimed. The protocol uses a timestamp
service and a randomness beacon. The former allows anyone to verify that a given piece of
data was generated and submitted to the service before a certain point in time. The latter is a
source of public, timestamped, truly random bits. Concretely, for timestamps we use the
Bitcoin blockchain via the OriginStamp service [GB14], and for randomness we use the
NIST beacon [11].
The use of a centralized beacon means that a veriï¬er must trust that the challenger cannot
predict or inï¬‚uence the beacon values, e.g., by collusion. This is obviously not entirely ideal
from a security standpoint. Unfortunately, at the time we released our challenges we knew
of no decentralized and practically usable alternatives that met our needs. For example,
while the Bitcoin blockchain has been proposed and analyzed as a source of randomness,
it turns out to be relatively easy and inexpensive to introduce signiï¬cant bias [BCG15;
PW16]. Similarly, the â€œunicornâ€ protocol [LW15] is trivial to bias completely, unless the
time window for public contribution is smaller than the (fastest possible) computation time
for a â€œslowâ€ hash function, which is impractical for our purposes: we would need a large
time window to ensure sufï¬cient participation. Lastly, a proposal based on multi-national
lotteries [Bai+15] does not come with a practically usable implementation, and requires the
veriï¬er to manually obtain past lottery numbers from many different countries.
7.2.1 Protocol Description and Properties
At a high level, our protocol proceeds as follows:
213
1. For each challenge instantiation (i.e., type of problem and concrete parameter set), the
challenger commits by generating and publishing a moderately large number ğ‘ (e.g.,
ğ‘ = 32) of independent instances, along with a distinct beacon address indicating
a time in the near future, e.g., a few days later. The challenger also timestamps the
commitment.8
2. At the announced time, the challenger obtains from the beacon a random value
ğ‘– âˆˆ {0, . . . , ğ‘ âˆ’ 1}.
3. The challenger then publicly reveals the secrets (which also implicitly reveals the
errors) underlying all the instances except for the ğ‘–th one. The one unrevealed instance
is then considered the â€œofï¬cialâ€ challenge instance for its instantiation, and the others
are considered â€œspoiled.â€
4. Anyone who wishes to verify the challenge checks that:
(a) the original commitment was timestamped sufï¬ciently in advance of the beacon
address (and all beacon addresses across multiple challenges are distinct);
(b) secrets for the appropriate instances were revealed, as indicated by the beacon
value; and
(c) the revealed secrets appear â€œproper.â€ For Ring-LWE, one checks that the errors
are short enough, potentially along with other statistical tests, e.g., on the errorsâ€™
covariance. For Ring-LWR one recomputes the rounded products with the
revealed secret and compares them to the challenge instance.
Importantly, a veriï¬er does not need to witness the challengerâ€™s initial commitment ï¬rsthand,
because it can just check the timestamp. In addition, the beaconâ€™s random outputs are
cryptographically signed, and can be downloaded and veriï¬ed at any time, or even provided
by the challenger in the reveal step (which is what our implementation does).
8All the challengerâ€™s public messages are cryptographically signed under a known public key. This is for
the challengerâ€™s protection, so that other parties cannot publish bogus data in its name.
214
Under the reasonable assumptions that the challenger cannot backdate timestamps, nor
predict or inï¬‚uence the output of the randomness beacon, the above protocol provides the
following guarantee: if one or more of the instances in a particular challenge are â€œimproper,â€
i.e., they lack a secret that would convince the veriï¬er, then the challenger has probability
at most 1/ğ‘ of convincing the veriï¬er. (Moreover, if two or more of the instances are
improper, then the challenger can never succeed.)
Potential cheats and countermeasures.
It is important to notice that as described, the
protocol does not prove that the instances were correctly sampled according to the claimed
Ring-LWE distribution, only that the revealed errors satisfy the statistical tests (i.e., they are
short enough, etc.). Below in subsection 7.2.2 we describe a supplementary (but platform-
and implementation-speciï¬c) test, which we also include in our implementation, that gives a
stronger assurance of correct sampling. However, the above protocol already seems adequate
for practical purposes, because there does not appear to be any signiï¬cant advantage to the
challenger in choosing non-uniform ğ‘ğ‘– âˆˆ ğ‘…ğ‘ or ğ‘  âˆˆ ğ‘…âˆ¨
ğ‘ , nor in deviating from spherical
Gaussian errors within the required error bound. In particular, spherical Gaussians are
rotationally invariant, and have maximal entropy over all distributions bounded by a given
covariance.
Another way the challenger might try to cheat is a variant of the â€œperfect predictionâ€
stock market scam: the challenger could prepare and timestamp a large number of different
initial commitments (step 1) containing various invalid instances. The challengerâ€™s goal is
for at least one of these commitments to be successfully revealable once the beacon values
become available; the challenger would then publish only that (timestamped) commitment
as the â€œofï¬cialâ€ one, and discard the rest. The more commitments it prepares in advance,
the more invalid (but unrevealed) instances it can hope to sneak past the veriï¬er. However,
the number of commitments it must prepare grows exponentially with the number of invalid
instances.
215
In order to rule out this kind of misbehavior, we prove that there is a single commitment
by widely announcing it (or its hash value under a conjectured collision-resistant hash
function) before the beacon values become available, in several venues where it would be
hard or impossible to make multiple announcements or suppress them at a later time. For
example, on the IACR ePrint archive we have created one dated submission for this paper,
every version of which contains the same hash value of the commitment (in section 3). Also,
we announced the hash value at the IACR Crypto 2016 Rump Session, which was streamed
live on the Internet and is available for replay on YouTube.9
7.2.2 Alternative Protocols
Here we describe some potential alternative approaches for validating Ring-LWE challenges,
and analyze their strengths and drawbacks.
Publishing PRG seeds. As noted above, revealing the secrets and errors does not actually
prove that the instances were sampled from the claimed Ring-LWE distribution. To address
this concern, the challenger could generate each instance deterministically, making its
random choices using the output of a cryptographically secure pseudorandom generator
(PRG) on a short truly random seed. Then to reveal an instance, the challenger would simply
reveal the corresponding seed, which the veriï¬er would use to regenerate the instance and
check that it matches the original one. We caution that this method still does not guarantee
that the instances are properly sampled, because the challenger could still introduce some
bias by generating many instances and suppressing ones it does not like, or even choosing
seeds maliciously. However, publishing PRG seeds seems to signiï¬cantly constrain a
dishonest challengerâ€™s options for misbehavior. (Using a public randomness beacon is not
an option, because some of the PRG seeds must remain secret.)
There are a few signiï¬cant practical drawbacks to this approach. First, establishing any
reasonable level of assurance requires the veriï¬er to understand and run the challenger-
9The announcement can be viewed at https://youtu.be/FpdoPcThsU0?t=24m37s.
216
provided code of the instance generator, rather than just checking that its outputs appear
â€œproper,â€ as the above protocol does. This also makes it difï¬cult to write an alternative
veriï¬cation program (e.g., in a different programming language) without specifying exactly
how the PRG output bits are consumed by the instance generator, which is cumbersome for
continuous distributions like Gaussians. Second, even the provided veriï¬cation code might
be platform-speciï¬c: using different compiler versions or CPUs could result in different
outputs on the same seed, due to differences in how the PRG output bits are consumed.10
Despite the above drawbacks, however, using and revealing PRG seeds does not need
to replace the above protocol, but can instead supplement it to provide an extra layer of
assurance. Therefore, our challenger and veriï¬er also implement this method (and allow for
very small â‰¤ 2âˆ’20 differences in ï¬‚oating-point values, to account for compiler differences).
A failed match does not necessarily indicate misbehavior on the challengerâ€™s part, but is
output as a warning by the veriï¬er.
Zero-knowledge proofs. Another possibility is to view a Ring-LWE instance as a Bounded
Distance Decoding (BDD) problem on a lattice, and have the challenger give a non-
interactive zero-knowledge proof that it knows a solution within a given error bound. This
can be done reasonably efï¬ciently via, e.g., the public-coin protocol of [MV03] or Stern-
style protocols for LWE-like problems [Lin+13], using a randomness beacon to provide the
public coins. While at ï¬rst glance this appears to provide exactly what we need, it turns out
not to give any useful guarantee, due to the approximation gap between the completeness
and soundness properties.
In more detail, for a BDD error bound ğµ, an honest prover can always succeed in
convincing the veriï¬er that the error is at most ğµ. However, the soundness guarantees
only prevent a dishonest prover from succeeding when the BDD error is signiï¬cantly larger
10We actually witnessed this phenomenon during development: different compilers yielded very small
differences in the ï¬‚oating-point values of our continuous Ring-LWE instances, but not our discrete ones. We at-
tribute this to the compilers producing different orders of instructions, and the non-associativity/commutativity
of ï¬‚oating-point arithmetic.
217
than ğµ. Speciï¬cally, the protocol from [MV03] has a bound of â‰ˆ ğµ
lattice dimension, and the protocol from [Lin+13] only proves that the largest coefï¬cient (in
ğ‘‘ where ğ‘‘ is the
âˆš
some basis) of the error is bounded. For our Gaussian error distributions, this bound would
need to be about 2â€“3 times larger than the size of a typical coefï¬cient. In summary, these
protocols can only guarantee that the error is bounded by (say) 2ğµ, which can correspond to
a much harder Ring-LWE instance than one with error bound ğµ. By contrast, our protocol
has a gap of only 10-15%, as shown next.
7.2.3 Veriï¬er and Error Bounds
Here we describe our veriï¬er in more detail, including some relevant aspects of its im-
plementation, and describe how we compute rather sharp error bounds for our Ring-LWE
instantiations.
Recall that each of our Ring-LWE instantiations is parameterized by a cyclotomic
index ğ‘š deï¬ning the ğ‘šth cyclotomic number ï¬eld ğ¾ and cyclotomic ring ğ‘…, which have
degree ğ‘› = ğœ™(ğ‘š); a positive integer modulus ğ‘ deï¬ning ğ‘…ğ‘ := ğ‘…/ğ‘ğ‘… and ğ‘…âˆ¨
ğ‘ := ğ‘…âˆ¨/ğ‘ğ‘…âˆ¨;
and a Gaussian error parameter ğ‘Ÿ > 0. (The number of samples is also a parameter, but it
plays no role in the bounds.)
Veriï¬cation. To verify a (continuous) Ring-LWE instance consisting of samples (ğ‘ âˆˆ
ğ‘…ğ‘, ğ‘ âˆˆ ğ¾/ğ‘ğ‘…âˆ¨) for a purported secret ğ‘  âˆˆ ğ‘…âˆ¨
ğ‘ and given error bound ğµ, one does the
following for each sample:
1. compute Â¯ğ‘’ := ğ‘ âˆ’ ğ‘  Â· ğ‘ âˆˆ ğ¾/ğ‘ğ‘…âˆ¨,
2. express Â¯ğ‘’ with respect to the decoding basis âƒ—ğ‘‘ = (ğ‘‘ğ‘—) of ğ‘…âˆ¨, as Â¯ğ‘’ =âˆ‘ï¸€
3. â€œliftâ€ Â¯ğ‘’ âˆˆ ğ¾/ğ‘ğ‘…âˆ¨ to a representative ğ‘’ âˆˆ ğ¾, deï¬ned as ğ‘’ =âˆ‘ï¸€
each Â¯ğ‘’ğ‘— âˆˆ Q/ğ‘Z.