abdTRG constructioncefghijkacbfabcbbdecghfjcikf41Time
PID
DestAddr
Request (Q)
Host
Referrer (R)
Q Type
R Type
ParentID
22.723
22.733
22.973
2724
2724
2724
64.30.224.103:80
198.82.164.40:80
198.82.164.40:80
/
.../combined.js
.../matrix.css
www.cnet.com N/A
i.i.com.com
i.i.com.com
www.cnet.com/
www.cnet.com/
website
javascript
css
NULL
website
website
25.307
2724
198.82.164.40:80
.../bgBody.gif
i.i.com.com
.../matrix.css multimedia
css
0
4
4
6
ID
...
4
5
6
...
14
...
Table 1: Original network events observed. Time, Q Type, R Type, and ParentID stands for timestamp, request
type, referrer type, and the ID of its parent event. The source IP of network events in this example is the
same, while the source ports may diﬀer (not shown).
(ID1,ID2)
TimeDiﬀ
PIDDiﬀ
AddrDiﬀ
RequestSim HostSim ReferrerSim
Q1
R2
Relation
(4,5)
(4,6)
(4,14)
(5,6)
(5,14)
(6,14)
0.00
0.25
2.584
0.24
2.574
2.334
1
1
1
1
1
1
1111000001
1111000001
1111000001
1111111111
1111111111
1111111111
1
1
0.1667
0.1356
0.5593
1
0.5
0.5
0.5
1
1
1
0
0
0
1
0.5
0.5
website
website
website
website
website
css
javascript website
javascript
css
css
css
1
1
0
0
0
1
Table 2: Examples of pairwise attributes as outputs of the Pairing operation. Q1 and R2 stand for the ﬁrst
event’s request type and the second event’s referrer type, respectively.
events. The comparison function fi() (e.g., isEqual,
isGreaterThan, isWithinThreshold, isSubstring, etc.) is
chosen based on the type of attribute. The feature con-
struction can be extended to comparing diﬀerent traﬃc
types. Pairing is performed on every two events that
may have the parent-child triggering relation. More-
over, we demonstrate an eﬃcient pairing algorithm to
reduce the cost of pairing without compromising the
analysis accuracy in Section 3.3. The pairwise fea-
tures are used as inputs to the subsequent learning
algorithms.
• Data Labeling is the operation that produces the
correct triggering relations for the event pairs in a
(small) training dataset. A binary label (1 or 0) indi-
cates the existence or non-existence of any triggering
relation in an event pair, e.g.,  represents
that event e triggers e(cid:48). Data labeling is based on
pairwise attributes (e.g., B1, . . . , Bm) and may require
manual eﬀorts.
• Training is the operation that produces a machine
• Classification is the operation to use the trained
machine learning model to predict triggering relations
on new event pairs P = {(ei, ej)}. E.g., the out-
puts of binary prediction results are in the form of
{}, where the binary classiﬁcation re-
sult lij ∈ {0, 1} represents whether event ei triggers ej
in P.
• TRG Construction is the operation to construct the
complete triggering relation graph based on pairwise
classiﬁcation results. If event ei triggers ej in the event
pairs P, then ei is the parent of ej in the TRG.
• Report is the operation to apply security deﬁnitions
to the triggering relation graph and report anomalous
events. A user-intention based security deﬁnition for
TRG analysis is presented in Section 3.5.
learning model with labeled training data.
We describe details of our new Pairing operation in the
next two sections. This feature extraction operation is
unique in that the features enable the use of binary clas-
siﬁcation for pairwise directional relation discovery.
3.2 Pairing Operation
1, . . . , A(cid:48)
The Pairing operation extracts features of event pairs.
Pairwise attributes (B1, . . . , Bm) are computed by compar-
ing the attribute values (A1, . . . , Am) and (A(cid:48)
m) of
two individual events e and e(cid:48). A comparison function
i) for i ∈ [1, m] is selected based on the type of
fi(Ai, A(cid:48)
attributes Ai and A(cid:48)
i. An event attribute is of the numeric,
nominal, string/text, or composite type. After the pairwise
feature extraction, binary classiﬁcation algorithms is used
for classiﬁcation. The classiﬁcation requires labeled pairs
for training, where triggering relations among events (i.e.,
labels) are known. For test data, triggering relations are
unknown and need to be predicted.
Without loss of generality, we illustrate a basic pairing
procedure with outbound HTTP network events as an exam-
ple. The approach can be generalized to other event types.
In Table 1 we show examples of some HTTP events. The
triggering relations, if known, are shown in the last column
(under ParentID). The features in Table 1 are derived from
the header of HTTP requests. As the header contains op-
erating parameters of an application layer transaction, the
casual/semantic relation can be measured by the features
of the requests. These features are previously used to un-
derstand the behavioral model of web traﬃc [10], while our
work further leverages them to build the trigger relations
of network traﬃc for security purpose. The pairwise at-
tributes are formed by aligning the same event features and
comparing the relevant ones (e.g., the request type and the
referrer type). Six event pairs are generated and their new
pairwise attributes are shown in Table 2. For example, the
HostSim, ReferrerSim and RequestSim give the similarity of
two events in Host, Referrer and Request attributes, respec-
tively, according to certain similarity measures. Each pair
has a binary representation of the existence of a triggering
relation (under Relation in Table 2). The pairing details are
illustrated as follows.
• Numeric attributes (e.g., timestamps) are compared by
computing their diﬀerence, e.g., the interval TimeDiﬀ
between the timestamps of two network events. That
is, Bi = Ai − A(cid:48)
i.
42• A nominal attribute (e.g., ﬁle type, protocol type) cat-
egorizes the property of an event. Comparing nominal
attributes usually involves string comparison, e.g., sub-
string or equality tests.
• For the string type of attributes, we compute the sim-
ilarity of the attribute values as the pairing attribute
value. That is, Bi = fs(Ai, A(cid:48)
i), where function fs
is a similarity measure, e.g., normalized edit distance.
Take HTTP request as an example, we compute pair
attributes HostSim and ReferrerSim by measuring the
string similarities between two host ﬁelds and two re-
ferrer ﬁelds, respectively.
• A composite attribute is converted to primitive types,
e.g., a destination address containing four octets for
the IP address and an integer for the port. The com-
parison of two composite attribute values is made by
comparing the sub-attribute values separately.
Given a list of n network events, the total number of event-
pair candidates is bounded by O(n2). To reduce the compu-
tational cost, one may pair up the events that occur within
a certain time frame τ , assuming that events occurring far
apart are unlikely to have triggering relations. We design a
more sophisticated pairing heuristic in the next section.
3.3 Efﬁcient Pairing Algorithm
Our pairing algorithm pre-screens attributes to quickly
eliminate unqualiﬁed pair candidates. The pseudocode of
our algorithm is shown below. It takes a list of chronologi-
cally sorted network requests as the input and outputs a set
of pairs of events.
d ← the domain of ej’s Host
if ej’s Referrer is not NULL then
dom ← the domain of ej’s Referrer
dom ← d
Algorithm 1 Eﬃcient Pairing Algorithm (EPA)
Input: a list of chronological sorted events, L = {ei}
Output: a set of event pairs, P = {(ei, ej)}, 1 ≤ i < j
1: deﬁne a set P to store the compared pairs {(ei, ej)}
2: deﬁne a dictionary D = (d,{e}), where d is the domain
of event and {e} is a set of events whose domain is d.
3: for each event ej ∈ L do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
end if
20:
21: end for
22: return P
end if
end for
calculate the expire time and update D[d]
add ej in D[d]
add new entry (d,{ej}) in D
end if
if dom in D’s keyset then
P ← P ∪ P airing(ei, ej)
if pass the Screening(ei, ej) then
for each event ei in D[dom] do
else
else
Algorithm 1 uses a dictionary D = {(key, value)} to store
the current network events. These events may be the parent
triggers of future events. The key of the dictionary is the
domain attribute of an event. The value is a set of requests,
whose domain attribute is same as the key. Events with
unmatched key values are ﬁltered out (in Screening function
of Algorithm 1), and not stored or paired, reducing both
storage and computation overheads. As a result, a much
longer time can be used to retire a domain, providing a more
comprehensive coverage on pairs.
3.4 Feature Selection and Classiﬁcation
Feature selection is to ﬁnd an optimal set of representative
features can greatly improve the eﬀectiveness of machine
learning classiﬁers. In our experiments, we use two diﬀerent
feature selection algorithms, namely Information Gain and
Gain Ratio. Once a set of features is chosen, we train and
classify the data using three common supervised machine-
learning classiﬁers – Naive Bayes, a Bayesian network [20],
and a support vector machine (SVM) [12].
Cost Sensitive Classiﬁers Because of the sparsity of trig-
gering relations, we deﬁne customized cost matrices [15] to
penalize missed relations during the training. The cost ma-
trix can be deﬁned to weigh the false positive (FP) and false
negative (FN) diﬀerently. A false negative refers to the fail-
ure to discover a triggering relation. A false positive means
ﬁnding triggering relation in a non-related pair.
Shown in Table 3, our cost matrix for classifying trigger-
ing relations is labeled by two categories: with triggering
relation and without triggering relation. The values in the
matrix are the weights for penalizing classiﬁcation mistakes.
We set positive values in the cells for FN and FP. The cost
sensitive classiﬁcation takes a cost matrix as an input. The
trained model aims at minimizing the total penalty in imbal-
ance data sets. For simplicity, we show the values and omit
is a cost
the labels of the cost matrix. For example,
1, 0
penalizes the
matrix that has no bias on FPs and FNs;
FNs 10 times more than FPs for a classiﬁer. In Section 4, we
thoroughly evaluate how cost matrices improve our analysis
accuracy.
(cid:104)0, 1
(cid:105)
(cid:104) 0, 1
10, 0
(cid:105)
Classiﬁed As
W/O TR
With TR
d
n
u
o