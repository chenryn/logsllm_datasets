block of memory space, statistically multiplexing their memory
demand. Therefore, we may encounter high memory load when
many dierent queries simultaneously collect coupons for many
keys. We discuss BeauCoup’s memory size requirement under real-
world trac settings in Section 5.2.3.
4.3 Query Compiler and Code Generation
Figure 3 presents the high-level architecture of the BeauCoup
system. Given a set of queries Q, we rst run a query compiler
(using the algorithm in Section 3.2) to compute a conguration
{<@,? @,= @} for each query @, and produce the hash functions for
attributes. The query compiler generates an intermediate represen-
tation with the mapping from each hash function’s output values to
all of the coupons. Subsequently, the rules generator uses these map-
pings to generate the TCAM matching rules and the corresponding
action parameters, representing the query set Q.
Meanwhile, BeauCoup generates the P4 code for the switch us-
ing a python-based code generator. The generator uses an algorithm
template (approximately 750 lines), written under the Jinja [28]
templating language, that implements BeauCoup’s data-plane algo-
rithm. Jinja enables auto-generating repeated P4 elements, such as
dening multiple hash functions and variables, as demonstrated in
Appendix A. Given the queries’ key elds and attribute tuples as
input, the code generator prepares the denition for hash functions,
then expands the template into a P4 [9] program (approximately
1500 lines), which is subsequently compiled and installed into the
PISA switch. When the TCAM matching rules are installed in the
tables specied by the P4 program, the switch executes the query
BeauCoup: Answering Many Network Traic eries
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
set Q. We have open-sourced the complete template program, the
code generator, as well as the query compiler on GitHub1.
Although the packet parser (header eld denitions), hash func-
tions, and query key extraction rules are part of the P4 data-plane
program, the TCAM matching rules can be updated on the y. The
user may frequently change the query set Q, by rst running the
query compiler and the rules generator, then installing the new
matching rules, as long as all queries are using existing key elds
and attribute tuples already dened in the data-plane program. This
also avoids the potential network downtime caused by re-installing
a new data-plane program, which would temporarily interrupt the
switch’s normal operation. The green shaded box on the left half
of Figure 3 represents the heavy-weight update of the data-plane
program, which is largely static, while the yellow shaded box on the
right represents light-weight update of query matching rules, which
can be installed swiftly without causing downtime. Still, using a
new header eld in a query’s key or attribute denition requires
re-generating P4 code and re-compiling the data-plane program.
5 EVALUATION
In this section, we demonstrate that BeauCoup can accurately and
eciently execute multiple queries. We rst show that the query
compiler produces good parameters for coupon collection. Then, we
investigate BeauCoup’s performance when answering queries over
a real-world trac trace, under limited memory access constraint,
and show it achieves the same accuracy using 4x fewer memory
accesses than alternatives. Finally, we show BeauCoup ’s data-plane
program only uses a modest fraction of the available hardware
resources on a commodity switch.
Recall that the query compiler outputs the conguration {<@,? @,= @}
5.1 Evaluating the Query Compiler
We now investigate the coupon-collector congurations generated
by the query compiler under dierent thresholds)@ and average per-
packet coupon limit W@. The compiler’s running time is negligible
(< 1ms) given its time complexity $(F2|Q|).
with the lowest Mean Relative Error given that its expected num-
ber of draws ⇠⇠(<@,? @,= @) is close to the query threshold )@. In
Figure 5 we plot the minimum possible Mean Relative Error of
various congurations, when the expected number of draws ex-
actly matches the threshold ()@ = ⇠⇠(<@,? @,= @)). We note that
adjusting ?@ does not noticeably change the error, and only plotted
the relationship between Mean Relative Error and (<@,= @) for all
congurations in 2  =@  <@  64.
As we can see from Figure 5, in general, using more coupons
leads to lower error. We can further observe that for any given
<@ (total coupons), the conguration with minimal Mean Relative
Error corresponds to a choice of =@ around 0.75<@. That is, the
coupon-collector conguration should stop when around three-
fourths of coupons are collected, as this leads to the least variance
in the number of random draws required. We also veried that
the =@ ⇡ 0.75<@ heuristic still holds with thousands of coupons,
although we defer a rigorous analysis to future work. However,
when memory access is extremely constrained, the compiler often
1https://github.com/Princeton-Cabernet/BeauCoup
232
Figure 5: When using various coupon collector congura-
tions, we nd that collecting approximately = = 0.75< out of
< coupons produce the lowest error.
Figure 6: Using more coupons lead to lower Mean Relative
Error. A coupon collector can achieve 13.7% minimum error
when using < = 32 coupons.
selects =@ = <@ = 1, as the congurations using more coupons
consume many more memory accesses per packet.
We now look at the relationship between the minimum Mean
Relative Error and the total number of coupons (<@), as shown in
Figure 6. In our current prototype implementation, we restrict the
query compiler to use at most <@ = 32 coupons, as one memory
read on the PISA hardware reads a 32-bit memory word. Using
<@ = 32 coupons achieves 13.7% minimum error, which means
BeauCoup may send a super-spreader alert upon seeing 860⇠1140
distinct IP addresses, given the threshold 1000. We note that Beau-
Coup can maintain more coupons in a collector by using multi-
ple memory words, if a higher accuracy is desired. Using <@ = 64
coupons achieves 9.8% minimum error, while using 128, 256, or
1024 coupons achieves 6.9%, 5.0%, or 3.1% error respectively. These
errors are comparable with the HyperLogLog distinct counting
algorithm using the same memory space.
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Xiaoqi Chen, Shir Landau-Feibish, Mark Braverman, Jennifer Rexford
5.2 Query Accuracy
Now we evaluate the accuracy of BeauCoup queries over real-world
network trac, by rst running a single query and comparing Beau-
Coup with related works, then run many queries simultaneously.
Our experiments mostly focus on BeauCoup’s accuracy under the
limited memory access constraint by providing abundant memory
for all algorithms. We also present some results regarding limited
memory space.
5.2.1 One ery and One Key. We rst demonstrate BeauCoup’s
coupon collectors are an ecient way to perform distinct count
queries, by comparing them against other approximate distinct
counting algorithms. Here we only focus on counting distinct at-
tributes for one particular query and one particular key, as other
distinct counting algorithms are designed for only one key and
cannot support multiple keys.
In this experiment, we use dierent algorithms to count the num-
ber of distinct source-destination IP pairs in the trac, and stop
when the estimate exceeds ) = 1000 distinct IP pairs. All algorithms
are implemented in Python. We use the CAIDA Anonymized Inter-
net Traces Dataset 2018 [5] (CAIDA trace), and repeat all runs 100
times with dierent random seeds.
HyperLogLog [13] is a widely-used approximate distinct count-
ing algorithm, that counts distinct items by counting the maximum
number of leading zeros seen from a random hash function. The
algorithm splits its input and feeds them to multiple independent
estimators, and outputs the harmonic mean across all estimators.
We use a HyperLogLog instance with 64 estimators.
UnivMon [22] is the state-of-the-art multi-purpose measure-
ment sketch that runs on PISA programmable switches, and can
compute various functions over a set of attributes, including dis-
tinct counting. NitroSketch [21] performs sampling over sketch
memory updates to reduce a sketching algorithm’s memory access
while preserving its accuracy. The authors of NitroSketch had pro-
posed applying the NitroSketch technique to UnivMon to reduce
UnivMon’s average memory access per packet. We hereby refer to
the new algorithm as NitroSketch-UnivMon. NitroSketch-UnivMon
supports all the queries supported by UnivMon, including distinct
counting. NitroSketch-UnivMon is the only sketch we are aware
of that achieves fewer than one memory access per packet on av-
erage and supports distinct counting. We use 16 layers of 4x1024
CountSketch for UnivMon, and change NitroSketch’s sampling
parameters to let NitroSketch-UnivMon achieve dierent average
memory access per packet.
We also include a packet sampling approach in the comparison.
As analyzed by Spang and McKeown [30], it is possible to estimate
the distinct number of ows (attributes) given a sampled subset of
all packets, using a statistical estimator [6]. We sample each packet
with a small probability ?, and record each sampled packet’s IP pair.
Subsequently, we feed the sampled subset to the estimator.
We rst note that the memory size used by BeauCoup is mini-
mal: a coupon collector uses one word of memory, at most F = 32
bits. Including auxiliary data (timestamp and checksum), each key
uses three words, or 96 bits. Meanwhile, one HyperLogLog in-
stance with 64 estimators uses 320 bits of memory. As we dis-
cussed in Section 5.1, when using the same number of bits of
Figure 7: BeauCoup’s coupon collector approach uses 4x
fewer memory access than NitroSketch-UnivMon or sam-
pling to achieve the same accuracy.
memory space, coupon collectors can achieve comparable accu-
racy as HyperLogLog.
On the other hand, NitroSketch-UnivMon uses 256 kilobytes
of memory space and is not directly comparable, as it is a multi-
purpose sketch supporting more than distinct counting. It is possible
to t a handful of instances of NitroSketch-UnivMon into a switch’s
data-plane memory space, but it is unfeasible to run multiple queries
with multiple keys, which requires thousands of instances. Packet
sampling uses $(? · !) memory space, proportional to the sampling
probability and stream length.
Since we need to simultaneously answer multiple queries under
a total per-packet memory access constraint, each BeauCoup query
can only make a very small number of memory accesses per packet.
We now compare the accuracy of each distinct counting algorithm
under the same average memory access constraint of W  1 words
per packet:
• When using packet sampling, for each sampled packet, we need
to access two words of memory to save its IP pair. Thus, we can
satisfy the per-packet memory access constraint by setting the
sampling probability to ? = W/2.
• For NitroSketch-UnivMon, we tune each layer’s NitroSketch sam-
pling probability individually to achieve W/16 average memory
access, thus making total memory access across all layers to
t within W words per packet. Since not all layers use their ac-
cess budgets fully, we record the actual number of total memory
accesses in experiments.
• For BeauCoup coupon collectors, recall that collecting each coupon
requires accessing 2 = 3 words (for coupon vector, timestamp,
and checksum). We specify an average per-packet coupon limit
W@ = W/2, and use the BeauCoup query compiler to nd the
coupon collector conguration that satises the constraint. Here
we also record the actual number of memory accesses.
• Finally, although HyperLogLog is very accurate, it always ac-
cesses exactly one word of memory per packet, regardless of
the number of estimators. We nevertheless included its accuracy
for reference.
233
BeauCoup: Answering Many Network Traic eries
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
After obtaining the coupon-collector congurations, we run
BeauCoup in a python-based simulator, which is behaviorally equiv-
alent to the data-plane P4 program, but allows us to freely tune
all parameters and concurrently run many simulations with dif-
ferent random seeds. We once again use the CAIDA trace in the
following experiments.
Average accuracy across queries. Figure 8 shows the overall
accuracy of all queries, measured by Mean Relative Error, given
dierent total memory access limits  . We can observe that when
the memory access limit becomes lower, the error becomes higher,
and the accuracy of dierent queries gradually converges. This is
because when we have abundant memory accesses, the queries with
higher thresholds do not need to use all of their fair share of mem-
ory accesses, and can achieve better accuracy than those actually
constrained by memory access; when all queries are constrained,
the fair allocation policy leads to similar accuracy for all queries.
Per-query accuracy. Now we scrutinize the accuracy of each
query. We rst compare the eect of increasing memory access
limit   on each query’s average relative error. In Figure 9, we choose
four dierent queries with various )@ from 100, 500, 5000, to 10000
and analyze their accuracy. Naturally, the query with the lowest
threshold is the hardest to execute, as it requires coupons with
larger probability ?@ and easily exhausts its memory access budget.
Increasing   allows the query to increase accuracy signicantly.
For queries with larger )@, the improvement is not as signicant.
Notably, the query with )@ = 10000 reaches its optimal accuracy
when   = 0.2, and its accuracy slightly deteriorates when we allow
more memory accesses. This is due to having collisions with other
queries when the system draws more than one coupon and enters
tie-breaking more often, which slightly skews the probability of
drawing each coupon.
We also compare dierent queries with the same )@ = 1000 yet
with dierent :4~@ and 0CCA@ denitions. Here we use four queries
as an example, the rst one being super-spreader. As we can see
from Figure 10, their average relative error has almost the same
relationship regarding the total memory access constraint  . The
third plot in Figure 10 has a slightly higher variance, and is because
this particular query outputs fewer alarms in our experiment trace,
hence has more outliers for the average relative error statistics.
5.2.3 Memory Size. So far, we have focused on limited mem-
ory access and assumed unlimited memory size and an innite
time window. However, practical systems have a limited amount of
memory (() and can run out of space for large window size , .
We rst observe that the number of unique query keys present
in the trac usually follows power law. For a stream of ! pack-
ets, we can observe !U@ unique keys, with U@ being specic to
the trac and dierent key denitions. For the CAIDA trace, U@
ranges between 0.7 to 0.85. Therefore, given the average per-packet
coupon limit W@, we can give an upper bound (W@!)U@ for the num-
ber of coupon collectors needed for query @, and therefore the
maximum total memory needed by all queries is upper-bounded
Figure 11 shows the actual memory space requirement of Beau-
Coup with regards to dierent time window sizes , , when process-
ing the same query set Q under the CAIDA trace, under a log-log