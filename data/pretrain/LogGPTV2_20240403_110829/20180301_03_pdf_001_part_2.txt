### Heavy Hitters and Sketches

**Definition:**
A heavy hitter in a sequence of items is an item whose multiplicity exceeds a fraction \(\alpha\) of the total cardinality, i.e., \(a_i > \alpha |a|\). In any given sequence, there can be between 0 and 1 heavy hitters.

**Approximation:**
An approximation algorithm accepts any \(i\) such that \(a_i \geq (\alpha + \epsilon) |a|\) for some specified \(\epsilon\). The probability that the count of any item \(j\) exceeds \((\alpha + \epsilon) |a|\) is given by:
\[ \Pr[\forall j: \text{count}[j, h(i)] > (\alpha + \epsilon) |a|] = \Pr[\forall j: a_i + X_{i,j} > (\alpha + \epsilon) |a|] = \Pr[\forall j: X_{i,j} > e \mathbb{E}(X_{i,j})] \]

To achieve the same accuracy, we set \(b = e\), which minimizes the space used. This results in a cost of \((2 + e) \ln \frac{1}{\delta}\) words. For practical implementations, other (integer) values of \(b\) may be preferable for simpler computations or faster updates.

For large values of \(a_i\) relative to \(|a|\), the bound in terms of \(\epsilon |a|\) can be translated into a relative error in terms of \(a_i\). This has implications for applications that rely on retrieving large values, such as large wavelet or Fourier coefficients.

**Previous Results:**
The best-known previous result using sketches was in [5], where sketches were used to approximate point queries. The space used was \(O\left(\frac{1}{\epsilon^2} \log \frac{1}{\delta}\right)\), and the dependency on \(\epsilon\) was \(\frac{1}{\epsilon^2}\) in every case considered.

**Comparison with CM Sketches:**
- **Variance Analysis:** Prior analyses of sketch structures compute the variance of their estimators to apply the Chebyshev inequality, resulting in a dependency on \(\epsilon^2\). Directly applying the Markov inequality yields a more direct analysis that depends only on \(\epsilon\).
- **Space Efficiency:** Practitioners may have observed that less than \(O(1/\epsilon^2)\) space is needed in practice. Here, we provide a proof for this observation and a tighter bound.
- **Error Bound:** The error bound here is one-sided, unlike previous constructions which gave two-sided errors. This benefits many applications that use sketches.

**Estimation Procedure:**
- **Median Estimation:** The query \(Q(i)\) is answered with \(\hat{a}_i = \text{median} \{\text{count}[j, h(i)]\}\).
- **Theorem 2:** With probability \(1 - \delta\),
  \[ a_i - 3\epsilon |a| \leq \hat{a}_i \leq a_i + 3\epsilon |a| \]
- **Proof:** Observe that \(\mathbb{E}(|\text{count}[j, h(i)] - a_i|) \leq \epsilon |a|\). Applying Chernoff bounds, the probability that any count is off by more than \(3\epsilon |a|\) is less than \(\delta\). The time to produce the estimate is \(O(\ln \frac{1}{\delta})\) and the space used is \((2 + e) \ln \frac{1}{\delta}\) words. The best prior result for this problem was the method of [5]. The dependence on \(\epsilon\) is improved from \(\frac{1}{\epsilon^2}\) to \(\frac{1}{\epsilon}\).

### Inner Product Query

**Estimation Procedure:**
- **Inner Product Estimation:** Set \((a \cdot b)_j = \sum_{k=1}^w \text{count}_a[j, k] \text{count}_b[j, k]\). Our estimation of \(Q(a, b)\) for non-negative vectors \(a\) and \(b\) is \(\hat{a \cdot b} = \min_j (a \cdot b)_j\).

**Theorem 3:**
- **Bound:** \(\hat{a \cdot b} \leq a \cdot b\) and, with probability \(1 - \delta\), \(\hat{a \cdot b} \geq a \cdot b - \epsilon |a| |b|\).
- **Proof:**
  \[ (a \cdot b)_j = \sum_{i=1}^n a_i b_i + \sum_{p \neq q, h_j(p) = h_j(q)} a_p b_q \]
  Clearly, \((a \cdot b)_j \leq a \cdot b\) for non-negative vectors. By pairwise independence of \(h\),
  \[ \mathbb{E}((a \cdot b)_j - a \cdot b) = \sum_{p \neq q} \Pr[h_j(p) = h_j(q)] a_p b_q \leq \frac{\epsilon |a| |b|}{e} \]
  So, by the Markov inequality,
  \[ \Pr[(a \cdot b)_j - a \cdot b > \epsilon |a| |b|] \leq \delta \]

The space and time to produce the estimate is \(O\left(\frac{1}{\epsilon} \log \frac{1}{\delta}\right)\). Updates are performed in time \(O\left(\log \frac{1}{\delta}\right)\).

**Special Case:**
- If \(b_i = 1\) and \(b\) is zero at all other locations, the procedure is identical to the point estimation procedure and gives the same error guarantee (since \(|b| = 1\)). A similar result holds in the general case, where vectors may have negative entries.

**Join Size Estimation:**
- **Importance:** Join size estimation is crucial in database query planners to determine the optimal order of query evaluation.
- **Definition:** The join size of two database relations on a particular attribute is the number of items in the Cartesian product of the two relations that agree on the value of that attribute.
- **Representation:** Assume without loss of generality that attribute values in the relation are integers in the range \(1, \ldots, n\). Represent the relations being joined as vectors \(a\) and \(b\) such that \(a_i\) represents the number of tuples with value \(i\) in the first relation, and \(b_i\) similarly for the second relation. Then, \(a \cdot b\) is the join size of the two relations.

**Corollary 1:**
- **Approximation:** The join size of two relations on a particular attribute can be approximated up to \(\epsilon |a| |b|\) with probability \(1 - \delta\) by keeping space \(O\left(\frac{1}{\epsilon} \log \frac{1}{\delta}\right)\).