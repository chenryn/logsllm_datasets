100
0
('t)
L()
N
Z3
0
C
::::I N
0
0
L()
Q)
C) ~
C'G
II)
II)
Q) ~
:E
0
L()
0
130
-
c1395
c1408
c1424
c1490
c1496
-- c1818
c2411
c2465
c4514
c4515
c4516
c4597
c4616
c5132
-
-
140
170
Time in minutes (One minute intervals)
160
150
0
0
('t)
0
0
N
II)
C
::::I
0
0
Q)
OJ
C'G
II)
II)
Q)
0
:E ~
0
L()
0
0
0
"""'"
0
0
('t)
Z3
C
::::I
0
0
0
Q)
OJ 0
C'G N
II)
II)
Q)
:E 0
0
~
0
Fig. 4.
Window-Max Filter
in the pre-failure window and not before. This is evidence
that there is information, other than the failure code itself,
in the log files describing the .failure. By using the filters,
we can identify these codes to help categorize the failure.
For example, Figures 4(a),(b) show a set of codes obtained
after applying the window-max filter on a log file from a
system which had periodic failures over a course of time. Each
failure of the system was found to have a signature similar to
Figure 4(a). Figure 4(b) shows only the pre-failure window
from Figure 4(a). Looking at the corresponding messages in
the log file revealed that the set of messages were caused by a
number of phones repeatedly trying to register themselves with
the CM (an anomaly condition). In another case, there was a
set of 48 logs that displayed highly similar codes related to
scheduled maintenance just before failure. The failure turned
out to be maintenance triggering a crash. The two examples
given above show how filters can be used to extract failure
signatures from the log files.
D. Application Specific Clustering
The results in Section V-C prompted us to look deeper into
codes 4514 and 4597 that show an increasing trend towards
failure. Recall that during the log preprocessing stage, we had
de-parameterized and clustered the original log messages. We
inevitably lost some information from the logs but this was a
necessary step to reduce the total number of messages.
Now, we introduce the concept of application-specffic clus(cid:173)
tering, where we allow the de-parameterization and clustering
to be tuned to the specific application logs. As an example, for
code 4514 below, we tune the clustering to not de-parameterize
i.e. we reinstate some of
the first and second NUM fields,
the parameters in the 4514 messages to recover some of this
information.
Original Clustered Message for code 4514:
hrnrn:CM_proc_err: pro=(NUM),err=(NUM) ,seq=(NUM) ,da= ...
Application Specifi c Clustering:
hrnrn: CM_proc_err: pro=7171, err=200, seq= (NUM) , da=
hrnrn: CM_proc_err: pro=7172, err=603, seq= (NUM) , da=
.
.
This led to a breakdown of about 400 different sub-codes
of the original code 4514. Extracting just these messages from
the logs, we employed the techniques shown in Section V-C
on this message set. The results showed that, while the codes
may differ between releases, only a few codes in each release
were responsible for the increasing trend found earlier. This
1-4244-2398-9/08/$20.00 ©2008 IEEE
402
DSN 2008: Lim et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:35 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
allowed us to isolate the exact error numbers and processes
that were associated with the pre-failure increasing trend.
Figure 5 shows the same log file as Figure 3 with slope-based
filter applied on the sub-codes of code 4514. The graph shows
only 2 of the 400 sub-codes were responsible for the increasing
trend.
Message Counts for 4514 codes
0
L()
IIc
::s
0
0
0
0
CD
en ~
ca
f/J
f/J
CD
:E L()
0
0
0
-
c112
c130
50
150
Time in minutes (One minute Intervals)
100
Fig. 5.
Figure 3(a) with application-specific clustering of dominating code
VI. ANALYSIS IN THE ABSENCE OF FAILURE MARKERS
In the above analysis, we have assumed that we know when
the failures occur and are able to mark out the failure times.
Note that without this information, none of the automated
filters described in Section V-C make much sense. However,
even in the absence of these failure markers, our techniques
can still yield useful results. As an example, our second data
set was a series of log files spanning a 108 days period,
obtained from one CM deployment. Within this period, there
were intervals when the network was very slow and impacted
the quality of service provided by the CM. However, these
times were not exactly marked in the logs through some known
failure codes.
MeSS$ge Counts for duration of 108 days
Anomalies.
I
o
500
1000
1500
2000
2500
Interval
(One hour intervals)
tenfold from normal, indicating possible problems. We zoomed
into those areas and identifying them as "failure" areas, used
techniques discussed earlier to get to the interesting codes.
By plotting these interesting codes across the whole 108 days
period, we see that they indeed corresponded to the dates when
the network experienced difficulties. Figure 6 shows the plot
of the message frequency per hour for the anomalous codes.
Large sections of log file (e.g. first 450 hours ~ 18 days)
show normal behavior with sudden spikes in the codes where
the network anomalies occur. Most of the anomalous codes
were associated with large number of phones re-registering
and slowing down the CM.
VII. CONCLUSIONS
Despite the many innate difficulties in dealing with the CM
log files, we were able to extract meaningful results. The key
to our approach is to transform the chaotic log files into a stan(cid:173)
dard form for visualization. Together with user feedback and
simple analysis tools, visualization allowed expert knowledge
to be efficiently applied to anomaly prediction, detection and
categorization. Our analysis techniques led to the detection
and categorization of several failure types and in some cases
predicted trends which lead towards failures.
The techniques and analysis presented in the paper need not
be restricted to CM log files or even general log files. Any
indexed (time or otherwise) set of text files can be visualized
the same way.
REFERENCES
[1] F. M. Facca and P. L. Lanzi, "Mining interesting knowledge from
weblogs: a survey," Data Know/. Eng., vol. 53, no. 3, pp. 225-241,
2005.
[2] R. K. Saboo, A. J. Oliner, I. Rish, M. Gupta, J. E. Moreira, S. Ma,
R. Vilalta, and A. Sivasubramaniam, "Critical event prediction for
proactive management in large-scale computer clusters," in Proc. ACM
Int. Con! on Knowledge Discovery and Data Mining, pp. 426-435,
2003.
I. Lee, R. Iyer, and D. Tang, "Error/failure analysis using event logs
from fault tolerant systems," in Fault-Tolerant Computing Symposium,
FTCS-21, pp. 10-17, June 1991.
[3]
[4] T.-T. Lin and D. Siewiorek, "Error log analysis: statistical modeling and
heuristic trend analysis," IEEE Trans. on Reliability, vol. 39, pp. 419(cid:173)
432, October 1990.
[5] S. G. Eick, "Visualizing online activity," Commun. ACM, vol. 44, no. 8,
pp. 45-50, 2001.
[6] D. Tang and R. Iyer, "Analysis and modeling of correlated failures
in multicomputer systems," IEEE Transactions on Computers, vol. 41,
no. 5, pp. 567-577, 1992.
[7] F. Nassar and D. Andrews, "A methodology for analysis of failure
prediction data," in Proc. Real TIme Systems Symposium, pp. 160-166,
Dec. 1985.
[8] S. Ma and J. Hellerstein, "Mining partially periodic event patterns
with unknown periods," in Proc. of International Conference on Data
Engineering, pp. 409-416, 2001.
[9] S. Ma, J. L. Hellerstein, and C.-S. Perng, "Eventminer: An integrated
mining tool for scalable analysis of event data," in Knowledge and Data
Discovery Workshop on Visual Data Mining, 2001.
[10] R. Vaarandi, "A breadth-first algorithm for mining frequent patterns from
Fig. 6.
108 days of log without any explicit failure markers
event logs," pp. 293-308, 2004.
In the absence of failure markers, we first plotted the overall
message frequency and then used our knowledge gained from
the previous analysis to track the usual suspect codes (e.g.
4514 and 4597). Both of these plots indicated anomalous
regions. The overall message frequency plot showed intervals
of time (about 1 hour) where the message frequency increased
[11] A. Oliner and J. Stearley, "What supercomputers say: A study of five
system logs," in Proc. Conf. on Dependable Systems and Networks, June
2007.
[12] Levenshtein Distance, ''http://en.wikipedia.orgjwikillevenshtein_distance."
[13] R. Vasireddy, S. Garg, N. Singh, and S. Yajnik, "Log transformation
technique for failure analysis of large communication systems," in Fast
abstract, Proc. Conf. on Dependable Systems and Networks, June 2007.
1-4244-2398-9/08/$20.00 ©2008 IEEE
403
DSN 2008: Lim et at
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:35 UTC from IEEE Xplore.  Restrictions apply.