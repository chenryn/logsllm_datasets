tions to read or modify the contents of any physical memory
address within the non-secure world. These BOOMERANG
ﬂaws are speciﬁc instantiations of the confused deputy prob-
lem [6], [8], [9], [17], [40]. Nevertheless, BOOMERANG
presents a particularly dangerous manifestation of this problem
as it exploits a fundamental design choice in the security
architecture of TEEs that currently affects hundreds of millions
of devices.
III. THE BOOMERANG VULNERABILITY
BOOMERANG exploits the semantic gap inherent to the
design of all the current TEE implementations, where the
secure world and its associated TAs have the ability to read
and write to non-secure world memory. However, most TAs
have a legitimate need to interact with the non-secure world’s
memory, and this functionality is routinely offered as a feature
of the architecture. While the untrusted OS is able to protect
itself and its applications within the non-secure world, all
of these security mechanisms can be trivially bypassed from
within the secure world. The trusted OS has no inherent ability
to determine the provenance or security properties of any
non-secure memory regions that are passed from untrusted
applications, due to the separation provided by the TrustZone
mechanism. More precisely, while the trusted OS can analyze
secure world pointer values to protect itself and other secure-
world applications, it has no insight into the memory permis-
sions of the non-secure world. Thus, when a TA receives a non-
secure world memory address as a parameter to a command,
it has no choice but to blindly act on that memory.
The untrusted OS is the most obvious place to implement
a defense, as it is already enforcing the non-secure world
security mechanisms, and, in fact, all current implementations
do employ some form of pointer sanitization (PTRSAN)
functions when handling pointers. However, the trusted OSes
and their applications frequently deﬁne their own structures
for the exchange of commands and data, making it impractical
for the untrusted OS to determine which values in the data are
pointers and need to be sanitized. This semantic gap forces the
untrusted OS to obliviously pass unknown data structures to
the secure world and similarly forces the secure world to act on
non-secure memory without any veriﬁcation of whether or not
the untrusted OS has authorized those actions. Thus, in these
scenarios, an untrusted application is able to issue requests to
the secure world for memory that it does not own, which the
secure world will manipulate, permitting unauthorized reading
and writing of another application’s memory, including the
untrusted OS’s kernel. Even when such pointer sanitizations
occur in the untrusted kernel, most of the PTRSAN functions
are implemented incorrectly, making them easy to bypass,
resulting in BOOMERANG vulnerabilities.
We demonstrate this interaction graphically at a high level
in Figure 1 and brieﬂy walk through a speciﬁc example in
TrustZone; however, this general data ﬂow holds for all TEE
implementations. Note that there are three distinct security and
semantic boundaries that must be properly handled: user mode
to supervisor mode in the non-secure world 1 , supervisor
mode in the non-secure world to supervisor mode in the
secure world 2 , and supervisor mode to user mode in the
secure world 3 . Since the SMC instruction, which is used
to change between the two worlds, is a protected call, the
untrusted OS must either implement a long-running service
that user applications can use as an arbiter to interact with the
secure world 1a or expose an API to applications and permit
interaction with the TEE driver directly 1b
(most vendors
provide a library in this case for convenience, shown as 1c ).
All TEE implementations rely on an agreed-upon standard
between the untrusted OS and the trusted OS for passing
information 2 . However, as mentioned previously, there are
various trusted OSes in circulation and there is no global
3
standard, as of yet, that has been agreed upon by these trusted
OS vendors. Thus, each trusted OS is accompanied by a spe-
cialized untrusted kernel driver for interacting with the secure
world, each driver using its own unique calling convention.
What is worse, while the protocol for exchanging information
between the trusted OS and the trusted application 3
is well-
deﬁned, the structure of this information is not standardized.
Therefore, most TA vendors are required to devise their own
unique data structures for sharing data between the untrusted
application and the trusted-world application 4 . Note that
while the untrusted OS can sanitize the memory address of the
structure, it has no insight into its contents unless the untrusted
application explicitly provides it. Similarly, TAs currently have
no way of conferring with the untrusted OS to validate the
authenticity of memory pointers and they have no choice but
to assume that all pointers have been sanitized.
Because of the isolation between secure and non-secure
worlds, the virtual memory addresses that applications use are
incomparable as the worlds utilize separate page tables within
the memory management unit (MMU). Thus, any reference to
memory must be converted to a common entity before being
shared with the other world. While it is possible for both
worlds to simply use a common memory map, this has been
shown to be a major security risk, as it allows the non-secure
world to control the execution of secure world by using page
faults [5]. Therefore, in practice, this commonly agreed-upon
representation is typically either a physical memory address or
a shared identiﬁer (e.g., a virtual address in the secure world),
which permits each world to access the particular memory
region without any insight into the other world’s memory
mapping. We refer to this translation of memory addresses,
and any associated security checks, as PTRSAN and depict its
various implementations in Figure 2.
By virtue of the implementation, any data being passed
2 must go through a PTRSAN
between the two worlds
function, which will convert pointers to this common entity.
This PTRSAN step is typically implemented within a hardened
application 1a or within the kernel ( 1b and 1c ) for two
reasons: 1) the speciﬁc pointer translation procedure should
be transparent to the user application, which increases the
modularity of the code; and 2) the PTRSAN function can
perform the appropriate security checks to verify that
the
pointer indeed belongs to the corresponding application and is
safe for applications in the secure world to access. PTRSAN
is intended to protect both the untrusted kernel and other
untrusted applications from a malicious application. However,
amongst the data being handled by PTRSAN, there is TA-
speciﬁc data, which the PTRSAN application has no insight
into. Any pointers within these TA-speciﬁc data structures
must be explicitly annotated so that the PTRSAN can translate
them appropriately. Herein lies the problem, and the core ﬂaw
being exploited by BOOMERANG. Speciﬁcally, the PTRSAN
function has no insight into the protocol agreed upon between
user application and the trusted application 4 , and thus it is
possible for the user application to pass pointers directly, which
evade the PTRSAN security checks. This critical semantic
gap is fundamentally what makes it so difﬁcult to prevent
BOOMERANG attacks in practice.
To demonstrate how memory addresses can evade sani-
tization in practice, we will brieﬂy walk through an example
Non-secure World
TEE Daemon
PTRSAN
User Application
Secure World
Trusted Application
R
T
P
R
T
P
R
T
P
R
T
P
R
T
P
Data
R
T
P
Data
R
T
P
4
R
T
P
R
T
P
Data
R
T
P
Data
R
T
P
1a
1b
1c
User Mode
3
User Mode
Rich OS
PTRSAN
Trusted OS
R
T
P
R
T
P
R
T
P
R
T
P
R
T
P
R
T
P
R
T
P
R
T
P
2
2
R
T
P
Supervisor Mode
Supervisor Mode
R Normal Pointer P
R Malicious Pointer P
T
P
T
R Sanitized Pointer
T
Unkown Data
Fig. 2: An example of BOOMERANG, where a malicious
memory pointer is hidden from pointer sanitization, ultimately
tricking a TA to act on that memory address.
from Figure 2. Note that 4 is the boundary that the data must
ultimately cross; however, the architecture does not permit this
particular interaction directly. So, the application prepares a
data packet destined for the TA in memory, using a data struc-
ture that was speciﬁed by corresponding TA. When the user
application needs to share a large amount of variable length
data with the trusted application (e.g., encrypted content), it is
desirable to permit the TA to act on this data in place (versus
copying it into a separate memory region). The pointer to the
data to be manipulated is annotated using the speciﬁc API
for the TEE, and the PTRSAN function handles the pointer
appropriately. However, in most cases, this annotation can be
trivially omitted, permitting the user application to control
the pointer value that the trusted application will receive. For
example, when physical memory is used as the common entity
between the two worlds, the user application could pass a phys-
ical address in the TA-speciﬁc data structure without reporting
this information to PTRSAN (i.e., a malicious pointer). The
TA has no way of validating these pointers, due to the semantic
gap, and thus has no choice but to perform the requested action
resulting in a BOOMERANG vulnerability.
To the best of our knowledge, BOOMERANG was previ-
ously completely unknown. In fact, the most related security
issue that was mentioned in the documentation [12] was a
time-of-check vs. time-of-use bug that exists in TEEs, wherein
the contents of non-secure memory may be changed while
the TEE is operating on the buffer. This limitation could lead
to situations where the data could be changed in malicious
ways to exhibit unintended behavior or permit untrusted world
applications to access each other’s data if the shared memory
region is globally readable. As we show in Section VII-C, our
proposed defense, CSR, can be trivially augmented to address
this security concern as well.
It is worth noting that there is already a mechanism in
place for querying the non-secure world from TAs. In an effort
to decrease the TCB within the secure world, any high-level
operations (e.g., ﬁle operations, networking) that the secure
world needs to exercise are typically handled by the non-
secure world on behalf of the secure world. In practice, each
trusted OS is accompanied by a user space service (i.e., a
4
TEE daemon) that is capable of handling these requests. In
some cases, this same daemon is also utilized as the arbiter
between untrusted applications and the untrusted kernel driver
( 1c in Figure 1). We show in Section VII-C, how we were able
to leverage this mechanism (i.e., the trusted world requesting
information from the untrusted world) to reconstruct the non-
secure world semantics and prevent BOOMERANG.
IV. BOOMERANG: THREAT MODEL
This work focuses primarily on TrustZone-enabled mo-
bile devices running Android, and thus our threat model
is described in terms of the Android ecosystem for clarity;
however, the same concepts are generally applicable. Android
was chosen because of the variety of TEE implementations
that exist on Android devices, and the sheer number of
devices that could potentially be implicated. Nevertheless, we
note that BOOMERANG bugs are likely to exist in any TEE
implementation where the secure world can access non-secure
world memory.
In the case of Android and TrustZone, we assume that an
attacker can convince a user to install an app on her phone.
We also assume that this app has the ability to interact, using
proper system calls, with TEE applications. Depending on the
implementation, this requires either no permissions or a single
permission to interact with a speciﬁc TEE application (e.g.,
the ACCESS_DRM permission to access the DRM application
in the trusted world). No root or system permissions are
required for the attacker application in the untrusted world.
The presented attacks do not leverage arbitrary code exe-
cution bugs in any secure world application nor in the trusted
kernel. For this reason, in the context of this paper, we assume
that
the attacker cannot execute arbitrary code inside the
TEE. In fact, the attacker’s goal is not to compromise TEE
computation, but it is to convince the code running within
the TEE to read and write non-secure world memory at the
attacker’s will. In this way, the attacker is able to thwart
security mechanisms of the untrusted OS, and, for instance,
raise the privileges of the controlled malicious app to root.
V. BOOMERANG ON REAL WORLD DEVICES
While BOOMERANG, in general, is applicable across all
TEE implementations, it is useful to examine various ﬂavors
that appear in real-world implementations. To this end, we have
examined the most popular TEE implementations to verify
the existence of BOOMERANG. In this section, we describe
the architecture of each of the examined implementations,
highlighting how their speciﬁc design choices affect
their
susceptibility to BOOMERANG.
A. Qualcomm Secure Execution Environment (QSEE)
Recent studies indicate that around 60% of all Android
phones in production are running Qualcomm’s QSEE [24],