sequential consistency”.
As basis for the study we assume a low level program
(e.g. a hypervisor, a separation kernel, a security monitor, or a
TrustZone crypto-service) running on a commodity CPU such
as the ARMv7 Cortex A7 of Raspberry Pi 2. We refer to the
trusted program as “the kernel”. The kernel shares the system
with an untrusted application, henceforth “the application”.
We assume that the kernel has been subject to a pervasive
formal veriﬁcation that established its functional correctness
and isolation properties using a model that reﬂects the ARMv7
ISA speciﬁcation to some level of granularity. For instance for
both seL4 and the Prosper kernel the processor model is based
on Anthony Fox’s cacheless L3 model of ARMv7 2.
We identify two special classes of system resources (read:
Memory locations):
• Critical resources: These are the resources whose integrity
must be protected, but which the application needs access
to for its correct operation.
• Conﬁdential
resources: These are the resources that
should be read protected against the application.
There may in addition be resources that are both critical and
conﬁdential. We call those internal resources. Examples of
critical resources are the page tables of a hypervisor, the exe-
cutable code of the untrusted software in a run-time monitor,
and in general the resources used by the invariants needed
for the veriﬁcation of functional correctness. Conﬁdential
(internal) resources can be cryptographic keys, internal kernel
data structures, or the memory of a guest colocated with the
application.
The goal is to repair the formal analysis of the kernel,
reusing as much as possible of the prior analysis. In particular,
our goals are:
1) To demonstrate that critical and internal resources cannot
be directly affected by the application and that for these
resources the actual system behaves according to the
formal speciﬁcation (i.e. that sequential consistency is
2In case of Prosper, augmented with a detailed model of the MMU [33].
5050
preserved and the integrity attacks described in Sec-
tion III-B cannot succeed).
2) To guarantee that no side channel is present due to caches,
i.e. that the real system exposes all and only the channels
that are present in the formal functional speciﬁcation that
have been used to verify the kernel using the formal
model.
A. Repairing the Integrity Veriﬁcation
For simplicity, we assume that the kernel accesses all re-
sources using cacheable virtual addresses. To preserve integrity
we must ensure two properties:
• That an address belonging to a critical resource cannot
be directly or indirectly modiﬁed by the application.
• Sequential consistency of the kernel.
The latter property is equivalent to guaranteeing that what is
observed in presence of caches is exactly what is predicted by
the ISA speciﬁcation.
The veriﬁcation depends on a system invariant that must be
preserved by all executions: For every address that belongs to
the critical and internal resources, if there is a cache hit and the
corresponding cache line differs from the main memory then
the cache line must be dirty. The mechanism used to establish
this invariant depends on the speciﬁc countermeasure used.
It is obvious that if the caches are disabled (Section V-A)
the invariant holds, since the caches are always empty. In
the case of “Always Cacheable Memory” (Section V-B) the
invariant is preserved because no non-cacheable alias is used
to access these resources: the content of the cache can differ
from the content of the memory only due to a memory update
that changed the cache, thus the corresponding cache line is
dirty. Similar arguments apply to the C ⊕ U Policy, taking
into account that the cache is cleaned whenever a resource
type switch from cacheable (C) to uncacheable (U) and vice
versa.
More complex reasoning is necessary for other counter-
measures, where the attacker can build uncacheable aliases
in its own memory. In this case we know that the system
is conﬁgured so that the application cannot write the critical
resources, since otherwise the integrity property cannot be
established for the formal model in the ﬁrst place. Thus, if
the cache contains critical or internal data different from main
memory it must have been written there by the kernel that
only uses cacheable memory only, hence the line is dirty as
well.
To show that a physical address pa belonging to a critical
resource cannot not be directly or indirectly modiﬁed by the
application we proceed as follows. By the assumed formal
veriﬁcation, the application has no direct writable access to
pa, otherwise the integrity property would not have been
established at the ISA level. Then, the untrusted application
can not directly update pa neither in the cache nor in the
memory. The mechanism that can be used to indirectly update
the view of the kernel of the address pa consists in evicting
a cache line that has a value for pa different from the one
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
stored in the memory and that is not dirty. However, this case
is prevented by the new invariant.
Proving that sequential consistency of the kernel is pre-
served is trivial: The kernel always uses cacheable addresses
so it is unable to break the new invariant: a memory write
always updates the cache line if there is a cache hit.
B. Repairing the Conﬁdentiality Veriﬁcation
Section III demonstrates the capabilities of the attacker:
Additionally to the resources that can be accessed in the
formal model (registers, memory locations access to which
is granted by the MMU conﬁguration, etc) the attacker is able
to measure which cache lines are evicted. Then the attacker
can (indirectly) observe all the resources that can affect the
eviction. Identifying this set of resources is critical to identify
the constraints that must be satisﬁed by the trusted kernel.
For this reason, approximating this set (e.g. by making the
entire cache observable) can strongly reduce the freedom of
the trusted code. A more reﬁned (still conservative) analysis
considers observable by the attacker the cache line tag3 and
whether a cache line is empty (cache line emptiness). Then to
guarantee conﬁdentiality it is necessary to ensure that, while
the application is executing, the cache line tag and emptiness
never depend on the conﬁdential resources. We stress that
this is a sufﬁcient condition to guarantee that no additional
information is leaked due to presence of caches with respect
to the formal model
Showing that
the condition is met by execution of the
application is trivial. By the assumed formal veriﬁcation we
already know that the application has no direct read access
(e.g. through a virtual memory mapping) to conﬁdential re-
sources. On the other hand, the kernel is able to access these
resources, for example to perform encryption. The goal is to
show that the caches do not introduce any channel that has not
been taken into account at the level of the formal model. Due
to the overapproximation described above, this task is reduced
to a “cache-state non-interference property”, i.e. showing that
if an arbitrary functionality of the kernel is executed then the
cache line emptiness and the line tags in the ﬁnal state do not
depend on conﬁdential data.
The analysis of this last veriﬁcation condition depends on
the countermeasure used by the kernel. If the kernel always
terminates with caches empty, then the non-interference prop-
erty trivially holds, since a constant value can not carry any
sensible information. This is the case if the kernel always
ﬂushes the caches before exiting, never use cacheable aliases
(for both program counter and memory accesses) or the caches
are completely disabled.
In other cases (e.g. “Secret-Independent Memory Accesses”
and “Selective Eviction”) the veriﬁcation condition is further
decomposed to two tasks:
3On direct mapped caches, we can disregard the line tag, because they
contain only one way for each line. In order to observe the tags of addresses
accessed by the kernel, the attacker requires at least two ways per cache line:
one that contains an address accessible by the kernel and one that the attacker
can prime in order to measure whether the ﬁrst line has been accessed.
1) Showing that starting from two states that have the same
cache states, if two programs access at the same time
the same memory locations then the ﬁnal states have the
same cache states.
2) Showing that
the sequence of memory accesses per-
formed by the kernel only depends on values that are
not conﬁdential.
1, s2, s(cid:3)
The ﬁrst property is purely architectural and thus independent
of the kernel. Hereafter we summarise the reasoning for a
system with a single level of caches, with separated instruction
and data caches and whose caches are physically indexed and
physically tagged (e.g. the L1 memory subsystem of ARMv7
CPUs). We use s1, s(cid:3)
2 to range over machine states and
s1 → s(cid:3)
1 to represent the execution of a single instruction.
From an execution s1 → s2 ··· → sn we deﬁne two
projections: πI (s1 → s2 ··· → sn) is the list of encountered
program counters and πD(s1 → s2 ··· → sn) is the list of
executed memory operations (type of operation and physical
address). We deﬁne P as the biggest relation such that if
s1 P s2 then for both data and instruction cache
• a line in the cache of s1 is empty if and only if the same
line is empty in s2, and
• the caches of s1 and s2 have the same tags for every line.
The predicate P is preserved by executions s1 → . . . and
s2 → . . .
if the corresponding projections are cache safe:
(i) the instruction tag and index of πI (s1 → . . . )[i] is equal
to the instruction tag and index of πI (s2 → . . . )[i] (ii) if
πD(s1 → . . . )[i] is a read (write) then πD(s2 → . . . )[i] is a
read (write) (iii) the cache line tag and index of the address
in πD(s1 → . . . )[i] is equal to the cache line tag and index
of the address in πD(s2 → . . . )[i]
Consider the example in Figure 1, where va3 and va4 are
different addresses. In our current setting this is secure only if
va3 and va4 share the same data cache index and tag (but they
could point to different positions within a line). Similarly, the
example in Figure 4 is secure only if the addresses of both
targets of the conditional branch have the same instruction
cache index and tag. Notice that these conditions are less
restrictive than the ones imposed by the program counter
security model. Moreover, these restrictions dot not forbid
completely data-dependent look-up tables. For example, the
scrambled implementation of AES presented In Section V-C
satisﬁes the rules that we identiﬁed even if it uses data-
dependent look-up tables.
In practice, to show that the trusted code satisﬁes the cache
safety policy, we rely on a relational observation equivalence
and we use existing tools for relational veriﬁcation that support
trace based observations. In our experiments we adapted the
tool presented in [6]. The tool executes two analyses of the
code. The ﬁrst analysis handles the instruction cache: we make
every instruction observable and we require that the matched
instructions have the same set index and tag for the program
counter. The second analysis handles the data cache: we make
every memory access an observation and we require that the
matched memory accesses use the same set index and tag
5151
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
(originally the tool considered observable only memory writes
and required that the matched memory writes access the same
address and store the same value). Note that the computation of
set index and tag are platform-dependent, thus when porting
the same veriﬁed code to a processor, whose caches use a
different method for indexing lines, the code might not be
cache safe anymore. To demonstrate the feasibility of our
approach we applied the tool
to one functionality of the
hypervisor described in Section IV-B, which is implemented
by 60 lines of assembly and whose analysis required 183
seconds.
VII. RELATED WORK
Kocher [31] and Kelsey et al. [27] were the ﬁrst to demon-
strate cache-based side-channels. They showed that
these
channels contain enough information to enable an attacker
to extract the secret key of cryptographic algorithms. Later,
Page formally studied cache side-channels and showed how
one can use them to attack na¨ıve implementations of the
DES cryptosystem [36]. Among the existing cache attacks,
the trace-driven and access-driven attacks are the most closely
related to this paper since they can be reproduced using the
vectors presented in Section III.
In trace-driven attacks [36] an adversary proﬁles the cache
activities while the victim is executed. Acıic¸mez showed a
trace-driven cache attack on the ﬁrst two rounds of AES [2],
which has been later improved and extended by X. Zhao [56]
to compromise a CLEFIA block cipher. A similar result is
reported in [9]. In an access-driven, or Prime+Probe, attack the
adversary can determine the cache sets modiﬁed by the victim.
In several papers this technique is used to compromise real
cryptographic algorithms like RSA [37], [25] and AES [22],
[34], [47].
Due to the security concerns related to cache channels,
research on the security implications of shared caches has
so far been focusing on padding [54] and mitigation [3]
techniques to address timing channels. Notably, Godfrey and
Zulkernine have proposed efﬁcient host-based solutions to
close timing channels through selective ﬂushing and cache
partitioning [20]. In the STEALTHMEM approach [28] each
guest is given exclusive access to a small portion of the shared
cache for its security critical computations. By ensuring that
this stealth memory is always allocated in the cache, no timing
differences are observable to an attacker.
In literature, few works investigated cache based storage
channels. In fact, all implementations of the above attacks use
timing channels as the attack vector. Brumley [11] recently
conjectured the existence of a storage channel that can be
implemented using cache debug functionality on some ARM
embedded microprocessors. However,
the ARM technical
speciﬁcation [15] explicitly states that such debug instructions
can be executed only by privileged software in TrustZone,
making practically impossible for an attacker to access them
with the exception of a faulty hardware implementation.
The attack based on mismatched cacheability attributes
opens up for TOCTTOU like vulnerabilities. Watson [50]
demonstrated this vulnerability for Linux system call wrap-
pers. A similar approach is used in [10] to invalidate security
guarantees, attestation of a platform’s software, provided by
a Trusted Platform Module (TPM). TPM takes integrity mea-
surements only before software is loaded into the memory,
and it assumes that once the software is loaded it remains
unchanged. However, this assumption is not met if the attacker
can indirectly change the software before is used.
Cache-related architectural problems have been exploited
before to bypass memory protection. In [52], [19] the authors
use a weakness of some Intel x86 implementations to bypass
SMRAM protection and execute malicious code in System
Management Mode (SMM). The attack relies on the fact
that the SMRAM protection is implemented by the memory
controller, which is external to the CPU cache. A malicious
operating system ﬁrst marks the SMRAM memory region
as cacheable and write-back, then it writes to the physical
addresses of the SMRAM. Since the cache is unaware of the
SMRAM conﬁguration, the writes are cached and do not raise
exceptions. When the execution is transferred to SMM, the
CPU fetches the instructions from the poisoned cache. While
this work shows similarities to the integrity threat posed by
cache storage channels, the above attack is speciﬁc to certain
Intel implementations and targets only the highest security
level of x86. On ARM, the cache keeps track which lines have
been ﬁlled due to accesses performed by TrustZone SW. The
TrustZone SW can conﬁgure via its page tables the memory
regions that are considered “secure” (e.g. where its code and
internal data structure are stored). A TrustZone access to a
secure memory location can hit a cache line only if it belongs
to TrustZone.
The attack vectors for data caches presented in this paper
abuse undeﬁned behaviour in the ISA speciﬁcation (i.e., ac-
cessing the same memory address with different cacheability
types) and deterministic behaviour of the underlying hardware
(i.e., that non-cacheable accesses completely bypass the data
caches and unexpected cache hits are ignored). While we
focused on an ARMv7 processor here,
there is a strong
suspicion that other architectures exhibit similar behaviour. In
fact, in experiments we succeeded to replicate the behaviour
of the memory subsystem on an ARMv8 processor (Cortex-
A53), i.e., uncacheable accesses do not hit valid entries in
the data cache. For Intel x64, the reference manual states that
memory type aliases using the page tables and page attribute
table (PAT) “may lead to undeﬁned operations that can result
in a system failure” ([26], Vol. 3, 11.12.4). It is also explicitly
stated that the accesses using the (non-cacheable) WC memory
type may not check the caches. Hence, a similar behaviour as
on ARM processors should be expected. On the other hand,
some Intel processors provide a self-snooping mechanism
to support changing the cacheability type of pages without
requiring cache ﬂushes. It seems to be similar in effect as the
hardware countermeasure suggested in Section V-D. In the
Power ISA manual ([38], 5.8.2), memory types are assumed
to be unique for all aliases of a given address. Nevertheless this
is a software condition that is not enforced by the architecture.