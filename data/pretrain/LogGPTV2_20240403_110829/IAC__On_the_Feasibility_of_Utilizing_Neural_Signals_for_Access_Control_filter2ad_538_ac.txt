approved by the Oce of Research Integrity (ORI) at the University
of California, Riverside under UCR IRB-HS 16-210. All participants
were given the option to withdraw from the study at any point of
the time. Devices involved in the study were sanitized after each
session to avoid skin problems (e.g., irritation). The standard best
practices were followed to protect the condentiality and privacy
of the participants data. Compensation of $30 was provided to the
participants whether they withdrew or not.
Participants Recruitment. After obtaining the IRB approval, we
recruited a total of 41 healthy participants for our experiments.
Among the 41 participants, 33 participants were for single app
experiment and 8 participants were for multiple app experiment.
Participants were recruited by word of mouth, yers, and social
media (Facebook) advertising. Informed consent and some non-
personally-identiable data (gender, age, and major) were obtained
from all participants. Twenty-seven (65.85%) of the participants
were male, and Fourteen (34.15%) were female. The details on the
participants’ demographics are provided in Table 2.
Experiment Setup. The experiment consists a consumer-grade
EEG headset (Emotiv EPOC+), an Android phone (Google Nexus
5X), an experiment app (§4.1), a laptop, and the Emotiv software
package [21]. Participants are asked to use the app on the Android
phone while wearing the lightweight EEG headset. The EEG headset
connects to laptop and sends EEG data via a Bluetooth dongle. The
Android phone connects to the laptop via USB. To construct the
ERPs, the Android app records the timestamp of the task. Clocks of
the phone and the laptop are synchronized with network time to
precisely align the event time stamps and the EEG data. EEG data
is recorded using the Emotiv Pure.EEG software.
Testbed. Our testbed is based on Android. To ease the creation of
ERP, in the experiments, we use touch events as the anchor to distin-
guish dierent ERPs. In particular, we developed a standalone moni-
toring app which uses the accessibility service in Android to capture
all the touch events (using the flagRetrieveInteractiveWindows
ag) [26] and log the timestamps of the events and the target GUI
element. The logged timestamps are then used to synchronize with
the neural signals captured by the BCI device and generate ERPs
corresponding to the touch events. To label ERPs, we manually
label GUI controls with corresponding intents (similar to access
control gadget). If a monitored touch event triggers a labeled GUI
control, we tag the ERP with the corresponding intent.
Figure 5: Experiment setup user is playing android apps
while wearing the Emotiv Epoc+ BCI headset. The sensors
of headset captured neural signals, converted to digital form
and transmitted encrypted data to the neural data collection
computer via USB dongle receiver.
Preparation Phase. The rst step of the preparation is to inform
participants that their brain signals would be collected while play-
ing our app on our test Android device and will be used to improve
the access control model. Next, we sanitize the electrodes of the
EEG headset and apply gel on them to improve their connectivity
with the skin. Then we set-up the EEG headset by putting it on the
head of the participant. Because the signal-to-noise ratio is lower in
raw EEG data, additional preparation steps are followed to ensure
the quality of the data. First, all experiments were conducted in a
quiet meeting room reserved for one participant only (Figure 5).
Table 2: Participants Demographic Distribution Summary
Gender (%)
Male
Female
Age (%)
18-21 years
22-25 years
26-29 years
≥ 30 years
Background (%)
Computer Science
Bioengineering
Biology
Psychology
Linguistic
Business
Political Science
Mechanical Engineering
Economics
Public Policy
Anthropology
Gender and Sexuality
Toxicology
Medical Science
Undeclared
65.85
34.15
39.03
24.39
29.26
7.32
31.70
9.74
4.87
7.32
2.44
7.32
7.32
2.44
7.32
2.44
2.44
2.44
2.44
2.44
7.32
IAC: On the Feasibility of Utilizing Neural Signals for
Access Control
Second, a preprocessing step is carried out on the raw EEG data
to increase their signal-to-noise ratio. During preprocessing, noise
reduction is applied to each of the raw EEG channels. To ensure
all the signals from the electrodes were properly channeled, we
checked the Pure.EEG control panel [21]. With the help of this tool,
we can validate the signal strength of each channel (electrodes).
The color green against the channel in the control panel meant
good strength while black meant no signal.
Task Execution Phase. Before starting the data collection, the
operator verbally instructed to the participants about the proce-
dure of experiments. For the single app experiment, all participants
performed the same set of tasks for 5 sessions, where each session
includes performing all 10 sets of tasks (Figure 4a); so a total num-
ber of 200 actions (trials) were performed by each participant if
without doing any mistake. All sessions were performed on the
same day and in the same room. A break of 2-4 minutes was given
to participant between each session. Users were instructed to stay
calm and relax in the entire session of the experiment. In real life,
participants may not face close to 40 actions within a short time (∼
5 min). However, multiple trials are the fundamental requirement
of most ERP-related study [40, 58]. We conducted this single app
for proving the ground truth of IAC. For multiple app experiments,
participants interacted with 8 popular apps for the entire time of
the experiments. They were instructed to play those apps for ap-
proximately 25 minutes. The operator notied the participants to
stop the browsing after 25 minutes. However, the participants were
allowed to stop the session if they were feeling uneasy or bored.
On average, the session duration for this experiment was 21 min-
utes. After nished the experiment, if the participant is interested
about our study, we explained the details of our experiment to those
curious participants.
5 DATA PROCESS AND ANALYSIS
Figure 2 depicts the work ow of our system. First, we acquire
the neural data using the EEG device. Then the raw EEG data is
preprocessed to make it usable for the classiers. Next, we apply
Independent Component Analysis (ICA) to recover original signals
from unknown mixtures of sources and extract features using au-
toregressive coecients. Finally, we utilize machine learning (ML)
techniques to get the intent.
Raw Data Acquisition. We collected raw EEG data using the
Emotiv Pure.EEG software [21]. We synchronize the EEG data with
actions (i.e., click events received by the app) using calibrated clocks
on the phone and the laptop. Based on the study of Martinovic et
al. [40] and Neupane et al. [44], we epochize the signals with 938 ms
window which starts at 469 ms before a touch event and 469 ms after
the event. We chose this window size as it provides the best results
during our analyses. Similar to the previous works [40, 44], we also
consider the window before the touch event because participants
know beforehand which action they will perform; so the stimuli
session actually starts before the event is recorded.
Data Preprocessing. Neural activities of human involve a huge
number of neuronal-membrane potentials. EEG records the voltage
change of cerebral tissues and the state of brain function. However,
these signals are weak, non-stationary and nonlinear in nature [6].
ACSAC’18, December 3–7,2018, San Juan, PR, USA
For this reason, EEG signals can easily be contaminated by ex-
ternal noises like the frequency of the power supply and noise
generated by the human body, such as eye movements, eye blinks,
cardiac signals, muscles noise, etc. The most signicant and com-
mon artifact produced by eye movements and blinks is known as
electrooculogram (EOG). Electromyography (EMG) is another type
of contaminating artifact, which is a measurement of the electrical
activity in muscles as a byproduct of contraction. EMG artifacts
are much more complex than EOG artifacts due to the movement
of muscles, particularly those of the neck, face, and scalp. Both
EMG and EOG seriously degrade the extraction of the EEG sig-
nals and lead to incorrect analyses. Hence they must be removed
from the raw data. Similar to previous work [3, 53], we used the
AAR (Automatic Artifact Removal) toolbox [27], which utilizes the
Blind Source Separation (BSS) algorithm to remove both EOG and
EMG [35]. After removing the EOG and EMG artifacts, we applied
an 8th order Butterworth band pass lter with a cuto frequency
of 3-60 Hz to remove all other useless signals. The band pass lter
keeps signals within the specied frequency range and rejects the
rest. The selected frequency range covers all ve major frequency
bands in EEG signal, namely delta (0.1 to 4 Hz), theta (4.5 to 8 Hz),
alpha (8.5 to 12 Hz), beta (12.5 to 36 Hz), and gamma (36.5 Hz and
higher) [19]. This preprocessing step extracts quality signals with
good SNR (signal-to-noise-ratio).
ICA. Independent Component Analysis (ICA) is standard method
to recover original signals from known observations where each
observation is an unknown mixture of the original signals. EEG de-
vice has 14 electrodes for receiving the brain signals from dierent
regions of the brain. Typically, each sensor will receive signals from
a mixture of regions. ICA can be applied to separate independent
sources from a set of simultaneously received signals from dierent
regions of human brain [31, 32, 64]. In this study, we used ICA to
separate multi-channel EEG data into independent sources.
Feature Extraction. The features from neural signals are ex-
tracted using autoregressive (AR) model. This model is a popular
feature extraction method for biological signals, especially for time
series data [15]. It can estimate the current values x(t) of a time
series from the previous x(t − 1) observations of the same time
series. The current term x(t) of the series can be estimated by a
linear weighted sum of previous term x(t − 1). A generic formula
for representing the time series data (e.g., EEG) is
n
i =1
x(t) =
αi x(t − i) + e(t)
(1)
Where αi, is weight which also known as the autoregressive
coecients, x(t) is the EEG signal, and n is the order of the model,
indicating the number of previous data points used for estimation.
e(t) is called noise or residual term which is assumed to be Gaussian
white noise. x(t) measured in time period t.
The selection of order in AR is the crucial step for getting a
successful application. We chose AR order six like previous stud-
ies [5, 44, 50]. All these studies used the 128Hz Emotiv EPOC device.
We calculated AR coecients using the Yule-Walker method [22].
We consider all 14 channels data for our analysis. Therefore, six AR
coecients were obtained for each electrode channel, resulting in
ACSAC’18, December 3–7,2018, San Juan, PR, USA
M. Rahman et al.
84 (14x6) features for each action of data. The total process of ex-
tracting feature applied all the actions for both of the experiments.
Classication Models and Evaluation Metrics. In this study,
we used random forest (RF) [12] because our extracted features
(autoregressive coecients) are suitable for RF algorithms [8, 24].
For implementation, we used the Weka classication software pack-
age [29].
We evaluate IAC using the weighted average of Precision, Recall
and F − Measure. A higher weighted average Precision value indi-
cates less false positives (i.e.incorrectly authorize access to sensitive
data and sensors). A higher weighted average Recall value indicate
less false negatives (i.e.unnecessarily prompt users for authoriza-
tion). The weighted average F −Measure is the weighted average of
Precision and Recall which takes both false positives and false neg-
atives into account and gives the balance of our machine learning
model. Finally, we used k-fold cross validation to validate our re-
sults, where k = 10. This is a broadly used technique for calculating
test accuracy in the classication problem for small sample which
can prevent overtting. The goal of our study is to train a classier
which can be used to predict user’s intent based on features that
extracted using earlier step.
6 FEASIBILITY TEST
In this section, we aim to answer the research questions through
analyzing the data we collected from the two dierent experiments
described in §4. We start from Q1—is it possible to distinguish the
three high-level intent based on neural signals using machine learning
algorithm.
6.1 Single App Analysis
Recall that our single app experiment includes 5 sessions for each
participant, where each session includes 10 sets of tasks and each
task set includes 4 actions. Therefore, each participant has 50 in-