!
5
9
.
2
!
7
8
.
1
!
6
7
.
1
!
2
6
.
1
95th Percentile!
!
4
8
.
3
!
6
1
.
3
!
0
7
.
1
!
5
7
.
1
!
5
8
.
1
!
4
7
.
1
5!
4!
3!
2!
1!
0!
5!
4!
3!
2!
1!
0!
!
t
n
e
m
e
v
o
r
p
m
I
f
o
r
o
t
c
a
F
!
t
n
e
m
e
v
o
r
p
m
I
f
o
r
o
t
c
a
F
=75%!
All Jobs!
Perc. of Job Duration Spent in Communication!
(b) Improvements in time spent in communication
Figure 6: [EC2] Average and 95th percentile improvements in job and com-
munication completion times over per-ﬂow fairness using Varys.
to-output ratios of tasks, locality constraints, and inter-arrival times
between jobs. It runs at 10s decision intervals for faster completion.
Metrics Our primary metric for comparison is the improvement
in average completion times of coﬂows and jobs (when its last task
ﬁnished) in the workload, where
Factor of Improvement =
Current Duration
Modiﬁed Duration
For deadline-sensitive coﬂows, the primary metric is the percent-
age of coﬂows that meet their deadlines.
The baseline for our deployment is TCP fair-sharing. We com-
pare the trace-driven simulator against per-ﬂow fairness as well.
Due to the lack of implementations of per-ﬂow prioritization mech-
anisms [8, 25], we compare against them only in simulation.
7.2 Varys’s Performance in Minimizing CCT
Figure 6a shows that inter-coﬂow scheduling reduced the average
and 95th percentile completion times of communication-dominated
jobs by up to 2.5× and 2.94×, respectively, in EC2 experiments.
Corresponding average and 95th percentile improvements in the
average CCT (CommTime) were up to 3.16× and 3.84× (Fig-
ure 6b). Note that varying improvements in the average CCT in dif-
ferent bins are not correlated, because it depends more on coﬂow
characteristics than that of jobs. However, as expected, jobs be-
come increasingly faster as the communication represent a higher
fraction of their completion times. Across all bins, the average end-
to-end completion times improved by 1.25× and the average CCT
improved by 1.85×; corresponding 95th percentile improvements
were 1.15× and 1.74×.
Figure 7 shows that Varys improves CCT for diverse coﬂow char-
acteristics. Because bottlenecks are not directly correlated with a
coﬂow’s length or width, pairwise comparisons across bins – spe-
cially those involving bin-2 and bin-3 – are harder. We do observe
more improvements for coﬂows in bin-1 than bin-4 in terms of av-
erage CCT, even though their 95th percentile improvements con-
tradict. This is due to coordination overheads in Varys – recall that
Varys does not handle small coﬂows to avoid ﬁxed overheads.
Figure 8a presents comparative CDFs of CCTs for all coﬂows.
Per-ﬂow fairness performs better – 1.08× on average and 1.25× at
the 95th percentile – only for some of the tiny, sub-second (<500
milliseconds) coﬂows, which still use TCP fair sharing. As coﬂows
5!
4!
3!
2!
1!
0!
!
t
n
e
m
e
v
o
r
p
m
I
f
o
r
o
t
c
a
F
Average!
!
9
7
.
2
!
1
9
.
2
!
4
9
.
1
!
2
8
.
1
95th Percentile!
!
6
4
.
1
!
9
5
.
1
!
3
2
.
2
!
3
8
.
1
!
5
8
.
1
!
4
7
.
1
Bin 1!
Bin 2!
Bin 3!
Coﬂow Types!
Bin 4!
ALL!
Figure 7: [EC2] Improvements in the average and 95th percentile CCTs
using coﬂows w.r.t. the default per-ﬂow fairness mechanism.
!
s
w
o
ﬂ
o
C
f
o
n
o
i
t
c
a
r
F
1!
0.5!
0!
!
s
w
o
ﬂ
o
C
f
o
n
o
i
t
c
a
r
F
1!
0!
Inter-Coﬂow Scheduling!
Per-Flow Fairness!
Inter-Coﬂow Scheduling!
Per-Flow Prioritization!
Per-Flow Fairness!
0.01!
1!
100!
10000!
0.01!
Coﬂow Completion Time (Seconds)!
1!
100!
10000!
Coﬂow Completion Time (Seconds)!
(a) EC2
(b) Simulation
Figure 8: CCT distributions for Varys, per-ﬂow fairness, and per-ﬂow pri-
oritization schemes (a) in EC2 deployment and (b) in simulation. Note that
the X-axes are in logarithmic scale.
!
t
n
e
m
e
v
o
r
p
m
I
f
o
r
o
t
c
a
F
30!
20!
10!
0!
!
4
2
.
0
3
!
8
5
.
7
2
!
1
3
.
9
!
8
4
.
6
W.r.t. Per-Flow Prioritization (Average)!
W.r.t. Per-Flow Prioritization (95th Percentile)!
W.r.t. Per-Flow Fairness (Average)!
W.r.t. Per-Flow Fairness (95th Percentile)!
!
!
!
4
9
8
0
.
.
4
5
!
!
5
2
3
2
.
.
4
4
8
0
!
9
0
.
9
8
.
!
!
7
5
2
5
.
.
3
3
!
!
4
2
8
2
.
.
5
6
!
!
2
5
9
4
.
.
3
3
!
!
3
5
0
8
.
.
5
5
!
6
6
!
7
7
.
3
.
2
Bin 1!
Bin 2!
Bin 3!
Coﬂow Types!
Bin 4!
ALL!
Figure 9: [Simulation] Improvements in the average and 95th percentile
CCTs using inter-coﬂow scheduling.
become larger, the advantages of coﬂow scheduling becomes more
prominent. We elaborate on Varys’s overheads next; later, we show
simulation results that shed more light on the performance of small
coﬂows in the absence of coordination overheads.
Overheads Control plane messages to and from the Varys master
are the primary sources of overheads. Multiple messages from the
same endpoint are batched whenever possible. At peak load, we ob-
served a throughput of 4000+ messages/second at the master. The
scheduling algorithm took 17 milliseconds on average to calculate
new schedules on coﬂow arrival or departure. The average time to
distribute new schedules across the cluster was 30 milliseconds.
An additional source of overhead is the synchronization time be-
fore a coﬂow becomes READY for scheduling. Recall that a coﬂow
waits for numFlows get() calls; hence, a single belated get() can
block the entire coﬂow. In our experiments, the average duration to