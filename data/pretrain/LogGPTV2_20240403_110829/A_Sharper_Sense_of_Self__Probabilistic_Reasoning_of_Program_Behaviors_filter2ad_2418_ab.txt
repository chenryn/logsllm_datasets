states. Because of the many context-sensitive calls, we design a
many-to-one mapping. That is, a hidden state in HMM may be
initialized to represent multiple similar system or library calls.
The reduced size of the constructed hidden Markov model
helps accelerate the training process. Time complexity of each
training iteration is O(T S2), where T is the length of trace
and S is the number of hidden states in the model.
For the purposes of state reduction through clustering, we
deﬁne a new call-transition vector below. We show examples
of call-transition vectors in Figure 1 (d).
Deﬁnition 6: For a call-transition matrix of dimension n, a
call-transition vector (cid:3)x of call c is of size 2n, consisting of
both the transition-from (i.e., column) probabilities of c and
the transition-to (i.e., row) probabilities of c.
A straightforward clustering algorithm is to directly com-
pute distances of calls based on their call-transition vectors
from Def. 6. The problem of this straightforward clustering
algorithm is the overhead of the training process. Training
with high-dimension vectors can be expensive, since data
points are relatively sparse in the vector space and difﬁcult
to model statistically. In our analysis, we use PCA (Principle
Component Analysis) to obtain a low-dimension input matrix
for clustering. PCA maps data points from a high-dimension
space to a low-dimension space, while still preserving distance
information in the original data. The input of the PCA is our
original matrix with call-transition vectors. The output of the
PCA is a reduced-dimension matrix, which is denoted as the
post-PCA matrix. For each system or library call ci, intuitively
the i-th row of the post-PCA matrix can be viewed as its call
transition probabilities in the compact dimension.
We use the K-means clustering algorithm for hidden state
reduction. The post-PCA matrix is fed as the input for K-
means clustering. We chose the K-means clustering algorithm
470
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 1 Pseudocode for Clustering Similar Calls of a
Program Based on Call Transitions.
Input: The aggregated call transition matrix of a program.
Output: The clustered call transition matrix of the program.
function CLUSTER(matrix m)
/* Each call is represented with its call-transition vector, which
is the concatenation of its row of outgoing probabilities and its
column of incoming probabilities. */
vectors[i] = (m[i], mT[i])
for (i = 1 → m.size()) do
end for
/* PCA to reduce dimensions of call-transition vectors*/
vectors = P CA.transf orm(vectors)
/* Cluster vectors. */
clusters = cluster vectors(vectors)
/* Reconstruct clustered call transition matrix*/
for (j = 1 → clusters.size()) do
n = clusters[j].size()
for index in clusters[j] do
m new[j][∗]+ = m[index][∗]/n
m new[∗][j]+ = m[∗][index]/n
end for
end for
return m new
end function
for its simplicity and efﬁciency. It is conceivable that advanced
clustering algorithms can be used by CMarkov to improve
its ability of identifying nodes with similar transitions. The
similarity measure used for merging similar call-transition
i (xi − yi)2
vectors is Euclidean distance computed as
for call-transition vectors (cid:3)x and (cid:3)y of size m. Intuitively, the
similarity of two call vectors is measured by comparing the
following: 1) the sets of incoming and outgoing calls; 2)
the distribution of probabilities from incoming calls and to
outgoing calls.
(cid:2)(cid:3)m
Our initialization of hidden Markov model is based on the
clustering results. Speciﬁcally, for the similar call-transition
vectors appearing in one cluster, we associate the correspond-
ing calls with the same hidden state. Thus, the hidden state
has the (averaged) emission probability vector. The transition
probability vector associated with that state is also adjusted
accordingly. Pseudocode of the state-reduction operation is
described in Algorithm 1. This clustering-based transforma-
tion is the key to making the context-sensitive probabilistic
behavioral modeling become practical.
IV. PROBABILITY FORECAST WITH
CONTEXT-SENSITIVITY
Context information is maintained and utilized during CFG-
based control-ﬂow probability forecast. Key operations in the
probability forecast in this context-sensitive model, complexity
analyses, and proofs of probability properties extend those of
the context-insensitive STILO model.
Computing reachability probability inside each function’s
control-ﬂow graph is the basis of our probability forecast. To
compute reachability probability (Deﬁnition 3), our algorithm
traverses a CFG and estimates the probability to reach a CFG
node from the function entry. We assume that the execution
r
P
c
ik
(1)
starts from the function entry with the probability of 1.0.
The calculation of reachability probabilities starts from the
function entry of a CFG, and is performed top down. Formally,
for a node nk in the CFG, the reachability probability P r
k
is computed as in Equation 1, where P r
is the reachability
i
probability of one of nk’s parents and P c
ik is the conditional
probability (Deﬁnition 2) for node pair (ni, nk).
i ∗ P
P
r
k =
(cid:4)
Speciﬁcally, P c
∀ ni ∈ parent set of nk
ij for node pair (ni, nj) is based on the
in the control-ﬂow
branching factor at the parent node ni
graph. If node ni has only one child node nj, then P [nj|ni] =
1. If ni has two or more child nodes, P c
ij follows a probability
distribution function, e.g., an equal or biased distribution.
Advanced branch prediction and path frequency approximation
techniques can be utilized, such as branch prediction [10,
11, 12], path frequency [13]. Our prototype uses the uniform
distribution. Branch heuristics can be added to further improve
our probability-estimation operation [10, 11, 12]. The com-
plexity for computing reachability probabilities for a control-
ﬂow graph G(V, E) with nodes V and edges E is O(|V |+|E|).
The number of outgoing edges for each node is usually small
(e.g., 2 or 3). Thus, the complexity is O(|V |) in practice.
Computing likelihood of occurrence for call pairs in a
function, i.e., transition probability (Deﬁnition 4) is as follows.
We identify all the nodes {L} such that a node nl ∈ L satisﬁes
the following three properties. Let nk be a node in the CFG
of f () that makes a call ca. i) Node nl makes a call (e.g.,
libcall or syscall) cb. ii) There exists a directed path (denoted
by nk, nk+1, ... , nl−1, nl) from nk to nl. iii) No other nodes
on the path between nk and nl make any calls. For each node
nl ∈ L, we compute the transition probability P
tf
akbl of call
pair (ca, cb) in f () as Equation (2). With caching, the worst-
case complexity of this computation is O(|E|).
tf
akbl
P
= P
k ∗ (cid:5)l−1
r
i=k
c
i(i+1)
P
(2)
A program may contain multiple functions. Thus, obtain-
ing the call-transition matrix corresponding to the program
requires the aggregation of transition probabilities from indi-
vidual CFG call-transition matrices, which is described next.
Aggregation of call transitions generates a large matrix
representation for the entire program. The resulting matrix is
compatible with the mathematical representation of a hidden
Markov model, and used for initializing the HMM. The inputs
for this operation include: i) the call graph of the program and
ii) call-transition matrix for each function. As we aggregate
callee functions’ matrices representation into caller functions’,
the call graph is needed for the calling relations among
functions. We inline the call
transition matrices of callee
functions into the matrices of caller functions, so that: i) The
ﬁnal call transition matrix captures the execution pattern of
the entire program rather than single functions. ii) The ﬁnal
transition matrix consists of only system calls or library calls.
(Internal function calls are reduced and removed.)
471
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
During the aggregation operation, the context information of
each call is unchanged. For example, the call write@f in the
callee function f continued to be represented as write@f,
after the call is aggregated into the call transition matrix of f’s
caller function g. Our model records the most immediate caller
of each system call and library call as its context information
(i.e., 1-level calling-context sensitivity), and this information
is maintained throughout the static analysis including the ag-
gregation of call transition matrices. Providing or Maintaining
context information at such granularity effectively enforces
where a call can actually be made, thus limits the ﬂexibility
an attacker may have during exploitation. The worst-case time
complexity of this operation is O(|E|).
Our data structure is compact and has low space complexity.
The dimension of the aggregated matrix is the number of
distinct calls. We do not record the entire call sequences. In
addition, all occurrences of the same call pair are added up
to one matrix cell. Our design is more efﬁcient than inlining
control ﬂow graphs [14].
Summary In CMarkov, the analysis takes control ﬂows
that can be statically inferred as inputs, and transforms them
into a rigorous probability representation for all
the call
transitions in the program. Context information, together with
each system and library calls are preserved in the output.
Program behaviors that are not covered by our static program
analysis (e.g., function pointer, recursions and loops) will be
learned from program traces by our CMarkov HMM model.
V. EXPERIMENTAL EVALUATION
Our prototype for the static program analysis is imple-
mented in C/C++ using the Dyninst library [15]. We use
the system tools strace and ltrace to intercept system calls
and library calls of running application processes as well as
the instruction pointer at the time of each call. The instruction
pointers are later translated to the caller function with the
binary utility tool addr2line. The translation operation is
efﬁcient as results can be cached.
For performance consideration, alternative monitoring tools
(e.g., auditd [16]) can be used by our implementation in
production systems. An acceptable 10% overhead was reported
on a hybrid benchmark with realistic workload for auditd [17].
The HMM training and evaluation code is written in Java using
the Jahmm library [18]. The evaluation or classiﬁcation of call
sequence is relatively efﬁcient. For example, the computation
for a 15-call segment takes 0.038 milliseconds (CMarkov for
gzip), also this operation can be done ofﬂine, and paralleled
for accelerated processing.
For identifying system calls, we compile a program with
static linking. The library calls of interest are the glibc
library calls, which are a collection of C standard libraries.
A. Experiment Setup
The programs and test cases used in our experiments
include utility applications (flex, grep, gzip, sed, bash,
vim) from the Software-artifact Infrastructure Repository
(SIR) [19], as well as an FTP server proftpd and an HTTP
server nginx. These programs average over 52, 586 lines
of code, and 1, 139KB in size. The programs we tested
include both utility applications and server programs, which
are all potential victims of attacks such as memory corruption,
back-door, or binary instrumentation/replacement by attackers.
The coverages of the test cases for programs in SIR are
summarized in Table I.
STATISTICS OF PROGRAMS AND TEST CASES USED IN EXPERIMENT. THE
COLLECTED TRACES ARE BROKEN INTO 15-GRAMS (SEGMENTS) FOR
TABLE I
CLASSIFICATION.
Program # of test cases
Branch coverage
Line coverage
ﬂex
grep
gzip
sed
bash
vim
Average
525
809
214
370
1061
976
659
81.3%
58.7%
68.5%
72.3%
66.3%
55.0%
67.0%
76.0%
63.3%
66.9%
65.6%
59.4%
51.9%
63.9%
We also tested server programs proftpd and nginx to
get normal traces. For proftpd, we test it by connecting to
the running server from a client, navigating around the server
directories, creating new directories and ﬁles, downloading,
uploading, and deleting ﬁles and folders. For nginx, our test
cases include both static webpages and dynamic php webpages
which interact with an SQL database we set up. Our test cases
cover different media types including text, images, scripts and
video ﬁles with Flash and Mp4 formats. Normal http and
encrypted https accesses are also tested.
We compare performance of following models:
• CMarkov: CMarkov builds its model with statically ex-
tracted context-sensitive call transition probabilities, and
also goes through dynamic training with context-sensitive
call traces.
• Regular-basic: This model is the widely accepted HMM-
based classiﬁcation, which is the state-of-the-art proba-
bilistic anomaly detection model (e.g., [2, 3]).
• Regular-context: Different from the Regular-basic model
where each observation is a system or library call, the
Regular-context model uses context-sensitive observa-
tions where each call is associated with its caller.
• STILO: The HMM is initialized with static analysis
operations, but without context information, i.e., only call
name is recorded for each system or library call.
The accuracy of a regular HMM relies heavily on com-
pleteness of training data. Thus, high coverage of test cases in
SIR gives the regular HMM a fair chance in the comparison
with our model. For the regular HMM, the set of observation
symbols consists of distinct calls from execution traces. The
number of hidden states is the size of the call set (i.e., the
total number of distinct calls in the traces). The regular model
randomly chooses the initial HMM parameters, including the
initial transition probabilities, initial emission probabilities,
and the initial distribution of hidden states.
Our experiments answer the following questions.
472
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
STATISTICS ABOUT THE CLUSTERING OF CALLS IN THE INITIAL HMM MODELS FOR SELECTED PROGRAMS AND MODELS AND THE ESTIMATED SPEEDUP.
TABLE II
Program
bash
vim
proftpd
Model
# distinct calls
# states after clustering
Estimated training time reduction
CMarkov-libcall
CMarkov-libcall
CMarkov-libcall
1366
829
1115
455
415
372
88.91%
74.94%
88.87%
1) How much speedup in HMM training is provided by
clustering-based state reduction? (In Section V-B)
2) How much improvement in classiﬁcation accuracy do
CMarkov models provide compared to the regular HMM
models? (In Section V-C)
3) What are the reasons for CMarkov HMM improvement,
and which type of models give more accurate classiﬁca-
tion, library calls or system calls? (In Section V-C)
4) How does context-sensitive detection limit ROP gadgets?
5) Can CMarkov detect real-world attack traces? (In Sec-
(In Section V-D)
tion V-E)
Standard HMM procedures are followed for model training
and testing. All comparable HMM models are subject to the
same convergence criteria during training. To help avoid model
overﬁtting, for both CMarkov and regular HMM models, 20%
of the normal data is kept aside to determine the termination
of training. After each round of training, the intermediate
model is tested on the termination data set, and the training is
stopped with a converged model when there’s no signiﬁcant
improvement on the termination data set. We perform 10-fold
cross validation on the rest of the normal data.
Given a threshold T for a program, false negative (FN) and
false positive (FP) rates in HMM are deﬁned in Equations (3)
and (4), where {SA} and {SN} denote the set of abnormal
segments and the set of normal segments of the program,
respectively, and PSA and PSN represent the probability of
an abnormal segment and a normal segment, respectively.
F N =
F P =
|{SA : PSA > T}|
|{SN : PSN < T}|
|{SA}|
|{SN}|
(3)
(4)
Training and classiﬁcation are on n-grams of program
traces, where n =15 in our experiments (i.e., all segments
consist of 15 calls). Researchers found that classiﬁcation with
segments of length 15 produces more precise results than
shorter segments [3]. Therefore, we use 15 as the segment
length for our experiments. Duplicate segments are removed
in our training datasets in order to avoid bias. 1
• Normal segments are obtained by running the target
executable and recording the library call or system call
segments as the result of the execution. A total of
130,940,213 such segments from around 4,000 test cases
of eight programs are evaluated. A HMM classiﬁcation
1Experiments were conducted on a Linux machine with Intel Core i7-3770
CPU (@3.40GHz) and 16G memory.
473
model needs to give high probabilities to these normal se-
quences. The training of hidden Markov models requires
normal sequences, not abnormal sequences. We test the
trained models with two types of abnormal call segments.
Those segments should be given 0 or low probabilities.
• Abnormal-A segments (or attack segments) are obtained
by reproducing several real-world attack exploits and
payloads.
• Abnormal-S segments (or synthetic abnormal segments)
are generated by replacing the last 4 normal calls in a
segment with randomly selected calls from the legitimate
call set. The legitimate call set consists of the distinct
calls in a program’s traces. A total of 160,000 Abnormal-S
segments are evaluated. Our use of Abnormal-S segments
enables a rigorous accuracy assessment.
B. Clustering for State Reduction
We applied the clustering to programs bash, vim, and
proftpd for libcalls. For our evaluation, we choose K as 1
2 or 1
3
of the original number of states. Table II shows the reduction
of model sizes and estimated training speedup. A substantial
75% to 89% reduction in training time is observed. Despite
the reduction in model sizes, our CMarkov models still out-
perform others as show in the next section.
In another experiment, we trained and tested the libcall
HMM for proftpd with unclustered model. The clustered
model only needs 10% of the training time, in order to achieve
the same false positive rates as its unclustered counterpart.
C. Classiﬁcation Accuracy
For each program, we compare four different models in-
cluding CMarkov, STILO, Regular-basic and Regular-context
models in their abilities to recognize new segments. New
segments include Normal segments (through 10-fold cross
validation) and Abnormal-S segments.
For the Linux utility programs, Figure 2 and Figure 3
give the accuracy comparison among the models. The results
show that CMarkov models signiﬁcantly outperform regular
or context-insensitive HMMs in most cases. In addition,
CMarkov models work better than STILO models with lower
false negative rates.
For the two server programs proftpd and nginx, we
show the library call and system call results in Figure 4 and
Figure 5, respectively. Overall, CMarkov models outperform
all other regular or context-insensitive models being compared.
Context-sensitive models (including CMarkov and Regular-
context) outperform STILO and Regular-basic HMM models
by a signiﬁcant margin, as shown in Figure 4. This phe-
nomenon is partly due to the great diversity of libc calls.
Library (libc) calls are usually directly used in user code by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:20:29 UTC from IEEE Xplore.  Restrictions apply. 
Regular-basic
Regular-context
STILO
CMarkov
libcall:flex
Regular-basic
Regular-context
STILO
CMarkov
libcall:grep
Regular-basic
Regular-context
STILO
CMarkov
libcall:gzip
Regular-basic
Regular-context
STILO
CMarkov
libcall:sed
Regular-basic
Regular-context
STILO
CMarkov
libcall:bash
Regular-basic
Regular-context
STILO
CMarkov
libcall:vim
 0.1
 0.01
 0.001
 0.01
 0.001
 0.1
 0.01
 0.001
 1
 0.1
 0.01
 0.001
 1
 0.1
 0.01
 0.001
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0
 0.0