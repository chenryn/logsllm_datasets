online probabilistic attack detection (e.g., when an overﬂow
it), while HEAPTHER-
occurs,
APY+ performs ofﬂine deterministic attack analysis and patch
generation. How to apply patches generated by heavyweight
ofﬂine analysis to lightweight online defense generation is
non-trivial and solved by our work. (2) Exterminator does not
handle overread or uninitialized-read, while HEAPTHERAPY+
handles all the frequently exploited heap vulnerability types
including overwrite, overread, use after free, and uninitialized
read. (3) Exterminator relies on a custom heap allocator that
incurs large overheads, while HEAPTHERAPY+ does not; the
defense of HEAPTHERAPY+ is transparent to the underlying
allocator. (4) Exterminator uses the expensive stack walking
to retrieve calling contexts, while targeted calling context
encoding is proposed and used in HEAPTHERAPY+. But the
two works share the insight in calling context-sensitive heap
patches, which we do not claim as our contribution.
D. Shadow Memory
Our ofﬂine heavyweight analysis makes use of shadow
memory [54], which tags every byte of memory used by a
program with some information. For example, by tagging a
memory region as inaccessible, a read zone is created. Despite
its powerful capabilities in dynamic analysis, it incurs very
high overheads. The implementation in Memcheck, which is
built in Valgrind, incurs 22.2x slowdown [54]. AddressSani-
tizer improved it signiﬁcantly with many functionalities cut,
but still incurs 73% speed slowdown [8]. Our system extends
shadow memory by associating every heap buffer with its
calling context ID.
HEAPTHERAPY+ does not propose new techniques ex-
cept targeted calling context encoding, but properly combines
heavyweight ofﬂine analysis (based on shadow memory) and
lightweight online defenses (based on allocation/deallocation
interception and calling context encoding). It resolves the chal-
lenge of applying ofﬂine analysis results to online defenses.
III. PROBLEM STATEMENT AND ARCHITECTURE
A. Problem Statement
Similar to conventional patch generation, our system uses
collected inputs that reproduce the bug for vulnerability inves-
tigation and patch generation. Given a program P that contains
a heap vulnerability V and an attack input I that exploits
V,2 our system outputs a patch P, which, once installed, can
2Actually, an attack input is not required. “Steps to reproduce”, which is a
regular part of a bug report [55], sufﬁces.
532
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:53:42 UTC from IEEE Xplore.  Restrictions apply. 
One-time program 
instrumentation
Program
Program 
Instrumentation Tool
Instrumented 
program 
Patch generation
Attack inputs
Offline Patch 
Generator
Patches
 Patched program execution                   
Online Defense 
Generator
Configuration file
Fig. 1. System architecture.
defeat attacks that exploit V. We consider the three frequently
exploited heap vulnerability types described in Section I.
But our system differs from conventional patch generation
in the following aspects. (1) Instead of relying on lengthy man-
ual investigation, patches can be generated instantly without
human intervention. (2) Rather than updating the program P
to ﬁx vulnerabilities, patches are written into a conﬁguration
ﬁle C to take effect, without introducing new bugs.
B. System Architecture
As shown in Figure 1,
the system consists of the fol-
lowing components: (1) A Program Instrumentation Tool:
it builds the calling context encoding capability into the
program (Section IV). Program instrumentation is an one-time
effort. Because of the simplicity of the instrumentation, its
correctness can be veriﬁed automatically. The instrumented
program is then used for both ofﬂine patch generation and the
online system. (2) An Ofﬂine Patch Generator: it automatically
generates the patch by replaying the attack (Section V). (3) An
Online Defense Generator: it is ashared library that (a) loads
the patches from the conﬁguration ﬁle C, and (b) intercepts
buffer allocation operations for recognizing vulnerable buffers
and generate defenses online (Section VI).
C. Calling-Context Sensitive Patches
In order to generate a patch P based on attack analysis, it
is critical to extract some invariant among attack instances.
Such invariant then can be used to design protection against
future attacks that also exploit V.
Our observation is that attacks that exploit V usually share
some attack-time calling context (e.g., the sequence of active
function calls that lead to a buffer overﬂow due to a memcpy
call). If we trace the program execution backward,
these
vulnerable buffers should share the allocation-time calling
context, which we call a vulnerable calling context and can
be used as an invariant to generate the patch P.
IV. TARGETED CALLING CONTEXT ENCODING
Simple call stack walking for retrieving calling contexts
would incur a large overhead, especially for programs with
intensive heap allocations [30]. There exist several efﬁcient
calling context encoding techniques, such as [30]–[32]. We
propose targeted calling context encoding, which is a suite
of algorithms that can be used to optimize these encoding
techniques. The insight
functions,
whose calling contexts are of interest, are known, many call
sites do not need to be instrumented and thus the overhead
can be signiﬁcantly reduced. Speciﬁcally, if some functions
never appear in the calling contexts that lead to the target
functions, they do not need to be instrumented (Section IV-A);
moreover, if one function has only one call site that can reach
the target function, then its instrumentation can also be pruned
(Sections IV-B and IV-C).
is that when the target
While we believe the optimization algorithms can beneﬁt
other encoding techniques [31], [32], to make the discussion
concrete (and based on our choice of the encoding technique
for heap patching), we use Probabilistic Calling Context
(PCC) [30] to demonstrate the application of the proposed
optimizations. According to PCC, at the prologue of each
function, the current calling context ID (CCID), which is
stored in a thread-local integer variable V , is read into a
local variable t; right before each call site, V is updated as
V = 3 ∗ t + c, where c is a constant integer unique for each
call site.3 This way, V continuously stores the current CCID.
Hence, the current CCID can be obtained conveniently by
reading V . With PCC, however, it may happen that multiple
calling contexts obtain the same encoding due to hash colli-
sions. It is shown practically and theoretically that the chance
of hash collision is very low [30]. It is worth noting that a hash
collision in our system means that a non-vulnerable buffer may
be recognized as a vulnerable buffer and get enhanced. Any
of our enhancements do not change the program logic, so a
hash collision can cause unnecessary overhead, but does not
affect the correctness of our system.
We call the original encoding algorithm that take all the
call sites into consideration as Full-Call-Site (FCS) instru-
mentation. The three famous encoding algorithms, PCC [30],
PCCE [31] and DeltaPath [32] all enforce FCS. Figure 2(a)
shows that all the call sites in those red nodes are instrumented,
and T1 and T2 are the target functions. The less call sites are
instrumented, the smaller overhead is incurred.
A. Targeted-Call-Site (TCS) Optimization
FCS blindly instruments all the call sites in a program. In
practice, very often users are only interested in the calling
contexts that end at one of a speciﬁc set of target functions,
such as security-sensitive system calls and critical transaction
calls. In our case, we are only interested in calling con-
texts when the allocation APIs (such as malloc, calloc,
calloc, memalign, aligned_alloc) are invoked. It is
3The encoding in PCCE [31] and DeltaPath [32] basically adopts V = t+c,
where c is calculated according to their encoding algorithms.
533
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:53:42 UTC from IEEE Xplore.  Restrictions apply. 
GFull
A
C
E
T1
T2
(a) FCS
B
D
H
I
GTargeted
A
GSlimmed
A
GIncremental
A
F
G
B
D
H
I
C
E
T1
F
G
T2
(b) TCS
B
D
H
I
C
E
T1
T2
F
G
B
D
H
I
C
E
T1
T2
F
G
(c) Slim
(d) Incremental
Fig. 2. Comparison of different encoding optimization algorithms using an
example call graph. The gray nodes, T1 and T2, are target functions; red
nodes indicate functions whose call sites are instrumented; and white nodes
indicate functions whose call sites are not instrumented. For the simplicity of
presentation, the example does not include back edges. Our algorithms can
handle back edges without problems as shown in Algorithm 1.
unnecessary to instrument functions that may never appear in
the call stacks when these target functions are invoked.
We thus propose the ﬁrst optimization, Targeted-Call-Site
(TCS), where only the call sites that may appear in the calling
contexts of target functions are instrumented. To conduct the
TCS optimization, reachability analysis on the call graph of the
program is performed. Given a call graph G = (cid:2)V, E(cid:3), where
V is the set of nodes representing functions of the program
and E the set of function calls, and a set of functions F, we
perform reachability analysis to ﬁnd edges that can reach any
of the functions in F, and only call sites corresponding to
these edges are instrumented.
Figure 2(b) shows the instrumentation result of TCS. As the
edges DH and HI cannot reach any of the target functions
T1 and T2, they are pruned from the instrumentation, reducing
the set of call sites that need to be instrumented.
B. Slim Optimization
On the basis of TCS, there is still potential to further prune
the set of call sites to be instrumented. In a call graph, a node
can be classiﬁed as either a branching or non-branching one:
a branching node is one that has multiple outgoing edges that
can reach (one of) the target functions. Our insight is that the
purpose of call site instrumentation is to make sure different
calling contexts can obtain different encoding values; given a
non-branching node, whether or how its contained call sites
are instrumented does not affect the distinguishability of the
encoding results. Thus, we propose to avoid instrumenting the
call sites in those non-branching nodes.
For example, as shown in Figure 2(c), according to the Slim
optimization, all call sites in the non-branching nodes, B and
E, are excluded from the instrumentation set.
C. Incremental Optimization
The two optimization algorithms treat all target functions as
a whole. Our another insight is that when the call to a target
function is intercepted for analysis or logging purpose, the
analyzer or logger usually knows the target function. In our
case, when malloc and memalign are intercepted, different
interception functions will be invoked.
Therefore, we can use the pair of (cid:2) Target_fun, CCID
(cid:3) (rather than CCID alone) to distinguish different calling
contexts. Based on this insight, we propose another opti-
mization algorithm that can further reduce the number of
instrumented call sites. A node is a true branching node if
it has two or more outgoing edges that reach the same target
function. That is, if a node has multiple outgoing edges, each
of which reaches a different target function, it is called a false
branching node. The idea of the Incremental encoding is to
avoid instrumentation the call sites in a false branching node.
In Figure 2, node A is a true branching node, as its two
outgoing edges can reach the same node T1 (and T2 as well).
So is node C, as its two outgoing edges can reach T1. Thus,
only the call sites that correspond to AB, AC, CE, CF need
to be instrumented. Take the calling contexts of T2 as an
example, the instrumentation at AB and AC is sufﬁcient to
distinguish the two calling contexts that reach T2.
InstrumentationSet ← {}
for t ∈ T do
T ⊆ N, where N is the set of functions and E edges.
V isitedN odes ← {}
Queue.push(t)
for n ← Queue.pop() do
V isitedN odes.push(n)
for each e = (cid:2)m, n(cid:3) of the incoming edges of n do
Algorithm 1 Incremental Optimization.
Input: A call graph CG = (cid:2)N, E(cid:3), and the set of target functions
Output: The edges in E to be instrumented.
1: function FILTER(T, CG = (cid:2)N, E(cid:3)):