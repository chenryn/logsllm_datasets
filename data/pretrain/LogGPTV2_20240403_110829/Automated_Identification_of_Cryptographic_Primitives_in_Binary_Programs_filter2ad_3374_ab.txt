State
Debug Info
Fig. 2. Schematic overview of implementation for stage 2
3.2 Fine-Grained Dynamic Binary Instrumentation
Execution tracing, or simply tracing, is the process of analyzing a binary exe-
cutable during runtime to generate a protocol that describes the instructions
executed and the data accessed by the executable. Dynamic instrumentation is
a technique that performs code transformations to insert analysis code into an
arbitrary program.
As mentioned before, the software sample is traced using the Pin dynamic
binary instrumentation framework [11]. Since Pin uses dynamic instrumenta-
tion, there is no need to recompile or relink the program. Pin discovers code at
runtime, including dynamically-generated code, and instruments it as speciﬁed
by the user-supplied Pintool. Using the Pin API, a Pintool has access to con-
text information such as register contents or debug symbols. The Pin framework
deals with the dynamic code injection, code integrity, and restoring of registers
which were modiﬁed by the Pintool. Pin diﬀerentiates between two modiﬁcations
to program code: instrumentation routines and analysis routines. Instrumenta-
tion routines detect where instrumentation should be inserted, e.g., before each
instruction, and then modify the code accordingly. Thus, the instrumentation
routines are only executed the ﬁrst time a new instruction is executed. On the
other hand, analysis routines deﬁne what actions are performed when the in-
strumentation is activated, e.g., writing to the trace ﬁle. They occur every time
an instrumented instruction is executed.
Data Reduction. In order to minimize the size of the trace ﬁle, we utilize
two ﬁlter methods. On the one hand, we exclude instructions from libraries of
which we have a priori knowledge that they do not contain cryptographic code.
Using a DLL whitelist, we are able to circumvent large code portions. This is
especially useful to reduce the trace time and ﬁle size. On the other hand, we
can ﬁlter by thread ID and are also able to start the trace after a certain number
of instructions already occurred, for example to skip an unpacker (if we have a
priori knowledge that a speciﬁc packer is used by the given sample).
Automated Identiﬁcation of Cryptographic Primitives in Binary Programs
47
Collected Data. For the analysis we need to record the following information
on an instruction-level granularity:
– Current thread ID
– Current instruction pointer together with involved registers and their data
– Instruction disassembly
– Accessed memory values, before and after the instruction, including mode
(read or write), size, and address
– (Optional:) Debug information of the current instruction location, e.g., DLL
module, function symbol, oﬀset to function symbol
Using this information, we are able to conduct the next step: the analysis of the
trace. The analysis, which is performed after or in parallel to the trace, is divided
into two kinds of procedures. First, high-level information, e.g., the control ﬂow
graph, is generated from the trace. Next, the cryptographic code identiﬁcation
methods are executed upon the high-level representation.
Basic Block Detection. A basic block is deﬁned as a sequence of instructions
which are always executed in the given order. Each basic block has a single entry
and single exit point. Since the basic blocks are generated dynamically from a
trace, the result of the basic block detection algorithm may diﬀer from a static
detection algorithm [19]. The basic blocks are generated from the dynamic trace,
thus non-executed code will not be considered by the detection algorithm, be-
cause it is not incorporated in the trace. Nevertheless, an advantage of dynamic
tracing is the ability to monitor indirect branches and thus we are able to incor-
porate their result into the basic block detection algorithm. If a basic block is
changed by self-modifying code, the change is noticed when the new code is ﬁrst
executed. A modiﬁed basic block is therefore registered as a new basic block,
because the new block’s instructions are diﬀerent from the old ones.
Loop Detection and Control Flow Graph Generation. Loops are deﬁned
as the repeated execution of the same instructions, commonly with diﬀerent
data. To perform the detection of loops, we follow the approach from Tubella
and Gonz´alez [18]. We could use the dominator relationship in the ﬂow graphs
(e.g., via the Lengauer and Tarjan algorithm [8]), but this would not recover the
same amount of information: these algorithms operate on a control ﬂow graph,
and therefore do not convey in which order control edges are taken during ex-
ecution. However, using the Tubella and Gonz´alez algorithm, we are able to
determine the hierarchy of loops and the exact amount of executions and iter-
ations of each loop body. The algorithm detects a loop by multiple executions
of the same code addresses. A loop execution is completed if there is no jump
back to the beginning of the loop body, a jump outside of the loop body, or a
return instruction executed inside the loop body. Loop detection, with the ﬁne
granularity presented here, is a clear advantage of dynamic analysis. For exam-
ple, with static analysis, the number of iterations or executions of a particular
loop cannot always be easily determined.
48
F. Gr¨obert, C. Willems, and T. Holz
A common optimization technique for cryptographic code is the unrolling of
loops to save the instructions needed for the loop control, e.g., counters, com-
pare, and jump instructions, and to mitigate the risk of clearing the instruction
pipeline by a falsely-predicted jump. While many implementations discussed
here partially unroll loops, no implementation unrolls every loop. Therefore, we
ﬁnd a lot of looped cryptographic code and can still rely on this heuristic.
We also build a control ﬂow graph based upon the basic block detection
algorithm. Given the list of executed basic blocks, we detect the control ﬂow
changes, i.e., which basic block jumps to which block, and use this information
to reconstruct the control ﬂow graph.
Memory Reconstruction. To further analyze the data incorporated in a trace,
we need to reconstruct the memory contents, i.e., generate memory dumps from
the trace at diﬀerent points in time. This is especially important because crypto-
graphic keys are larger (e.g., 128 or 256 bit) than the word size of the architecture
(e.g., 32 bit). Thus, a cryptographic primitive can extend over several words in
memory and has to be accessed by multiple operations. To reconstruct such a
primitive, we need to consider and combine multiple operations. As we do not
conduct ﬁne-grained taint analysis [1,6,14], we need to reassemble the memory
based on its addresses, which can serve as a rough approximation.
If an instruction involves a memory access, we record the following information
in the trace:
– Memory address and size of access (8, 16, or 32 bit)
– Actual data read or written
– Mode of operation (read or write)
From this information we reconstruct the memory content. Since data at an
address can change during the trace, we may have several values for the same
address. Thus, instead of dumping the memory for a particular point in time,
we instead reconstruct blocks of memory that have a semantic relationship. For
example, a read of 128 bit cryptographic key material may occur in four con-
secutive 32 bit reads. Then, later a 8 bit write operations to the same memory
region may destroy the key in a memory reconstruction. Therefore, we try to
separate the 8 bit writes from the read 128 bit key block.
For this method, we rely on a few characteristics of the memory block, i.e., the
interconnected memory composed of several words. First, we distinguish between
read or write blocks and thus separate the traced memory accesses based on the
access mode. Second, we assume that a block is accessed in an ascending or
descending sequential order. Thus, we save the last n memory accesses, which
occurred before the current memory access. In our experiments n = 6 turned
out to be a reliable threshold. As a third characteristic, we use the size of the
access to distinguish between multiple accesses at the same address.
3.3 Heuristics for Detecting Cryptographic Primitives
In this section, we discuss the diﬀerent properties of cryptographic code and
elaborate on the implemented methods to detect the cryptographic code and its
Automated Identiﬁcation of Cryptographic Primitives in Binary Programs
49
primitives. First, we provide an overview of the identiﬁcation methodology and
then, based on code observations we make, we explain the developed identiﬁca-
tion methods. In order to successfully identify the cryptographic primitives we
have to algorithmically solve the following questions: which cryptographic prim-
itives are used, where are they implemented in code, what are their parameters,
and when are they used?
We distinguish between two classes of identiﬁcation algorithms: signature-
based and generic. The main diﬀerentiation is the knowledge needed for the
identiﬁcation algorithm. For signature-based identiﬁcation, we need a priori
knowledge about the speciﬁc cryptographic algorithm or implementation. On
the other hand, for generic identiﬁcation we use characteristics common to all
cryptographic algorithms and therefore do not need any speciﬁc knowledge.
Observations. We now point out three important features of cryptographic
code, which we found and conﬁrmed during the course of this work.
1) Cryptographic code makes excessive use of bitwise arithmetic instructions.
Due to the computations inherent in cryptographic algorithms many arithmetic
instructions occur. Especially for substitutions and permutations, the compiled
implementations make extensive use of bitwise arithmetic instructions. Also,
many cryptographic algorithms are optimized for modern computing architec-
tures: for example, contemporary algorithms like AES are speed-optimized for
the Intel 32 bit architecture and use the available bitwise instructions.
2) Cryptographic code contains loops. While substitutions and permutations
modify the internal data representation, they are applied multiple times com-
monly with modiﬁcations to the data, e.g., the round key. We can recognize,
even in unrolled code, that the basic blocks of cryptographic code are executed
multiple times.
Solely for an identiﬁcation method the presence of loops is insuﬃcient. The
observation rather has to be combined with other methods to provide a sound
identiﬁcation, because loops are inherent in all modern software. Although the
number of encryption rounds is unique to each algorithm and may be used for
an identiﬁcation, this is not the case for unrolled algorithms, where the original
number of rounds cannot be found in the majority of unrolled testing applications
which we investigated.
3) Input and output to cryptographic code have a predeﬁned, veriﬁable relation.
The cryptographic algorithms which we consider in this paper are deterministic.
Therefore, for any input the corresponding output will be constant over multi-
ple executions. Given a cryptographic primitive was executed during the trace,
the input and output parameters contained in the trace will conform to the
deterministic relation of the cryptographic algorithm. Thus, if we can extract
possible input and output candidates for a cryptographic algorithm, we can ver-
ify whether a reference algorithm generates the same output for the given input.
Thereby, we cannot only verify which cryptographic algorithm has been traced,
50
F. Gr¨obert, C. Willems, and T. Holz
but we can also determine what cryptographic parameters have been used. Of
course, this observation can only be utilized with a reference implementation: if
the software program contains a proprietary algorithm, we cannot verify it.
Identiﬁcation Methods. Based on our observations detailed before, we devel-
oped and implemented several identiﬁcation methods.
Chains Heuristic. The ﬁrst heuristic is based on the sequence of instructions, i.e.,
the ordered concatenation of all mnemonics in a basic block. For identiﬁcation,
an unknown sample’s sequence is created and compared to the set of existing,
known sequences in the pattern database. If the sequence can be found, a cryp-
tographic implementation has been detected. We prepared the pattern database
with diﬀerent open-source cryptographic implementations. To diﬀerentiate be-
tween sequences deﬁning an algorithm and sequences deﬁning an implementa-
tion, we generated multiple datasets for each algorithm and each implementation.
Thereby, we can identify implementations and algorithms in diﬀerent levels of
granularity and compare the eﬀectiveness of the diﬀerent patterns. Then, we
form diﬀerent datasets using union, intersection, and subtraction as follows:
– For each implementation of an algorithm
– For each algorithm, based on the intersection of all implementations of the
– An unique dataset for each algorithm, based on the subtraction with other
particular algorithm
algorithms
Mnemonic-Const Heuristic. The second identiﬁcation method extends the ﬁrst
one and is based on the combination of instructions and constants. The intu-
ition is that each implementation of a cryptographic algorithm contains unique
(mnemonic, constant)-tuples that are characteristic for this algorithm, e.g., every
MD5 implementation we studied contains ROL 0x7 and ROL 0xC instructions. We
also studied whether constants alone are characteristic enough (e.g., 0xc66363a5
is the ﬁrst value of the unrolled lookup table for AES implementations), but
found that such an approach leads to many false positives in practice. However,
a combination of instructions and constants leads to a more robust approach,
and thus we developed an identiﬁcation method which employs a dataset based
on (mnemonic, constant)-tuples. For every implementation we generate a set of
instructions and their corresponding constants, e.g., ROL 0x7. Then, we again
form the diﬀerent data sets as described in the ﬁrst heuristic.
An example for the datasets is given in Figure 3. For a given set of (mnemonic,
constant)-tuples from a trace, we can measure to which percentage the tuples
from a signature dataset are included in the trace. We observed that the unique
and intersection datasets have a stronger relation to the algorithm. Implemen-
tation datasets have a looser connection to the traced implementation and pose
a higher risk of generating false-positives. The number of tuples per testing ap-
plication varies between 40 and 454 and the mean value is 165 tuples.
The comparison is implemented as follows: First, we generate the set of
(mnemonic, constant)-tuples found during the tracing. Using this trace-set, we
Automated Identiﬁcation of Cryptographic Primitives in Binary Programs
51
cryptopp aes
beecrypt md5
(cmp, 56)
openssl md5
(shr, 2)
(rol, 20)
unique md5
(rol, 4)
(rol, 6)
(add, 16404)
(dec, 4)
(cmp, 24)
intersection md5
(and, 4)
(xor, 4)
(and, 255)
(or, 1)
cryptopp md5
openssl rc4
Fig. 3. Composition of (mnemonic, constant)-tuple datasets
check for each of the known pattern datasets to which percentage the trace-set
intersects the signature-set. If the percentage is above the threshold of 70%, we
report a positive identiﬁcation. The threshold was empirically determined during
the development process and in preliminary tests of our tool.
Veriﬁer Heuristic. The third identiﬁcation method is focused on memory data.
We use veriﬁers to conﬁrm a relationship between the input and output of a
permutation box. Using the memory reconstruction method described in Sec-
tion 3.2, we are able to verify complete instances of a cryptographic algorithm
using plaintext, key, and ciphertext residing in memory.
As the memory reconstruction method reassembles cryptographic data of any
length, we are able to reconstruct a set of possible key, plaintext, and ciphertext
candidates. These candidates are then passed to a reference implementation of
the particular algorithm, the veriﬁer. If the output of the algorithm matches the
output in memory, we have successfully identiﬁed an instance of the algorithm
including its parameters. The main limitation of this approach is the premise
that the algorithm is public and our system contains a reference implementation
to verify the input-output relation.
We do not speciﬁcally have to consider and distinguish between encryption
or decryption, because the encryption and decryption are commonly the same
algorithms for stream and block ciphers. The eﬃciency of this approach is bound
to the amount of candidates: if we can identify speciﬁc cryptographic code using
other identiﬁcation methods before, the eﬃciency is highly increased, since less
candidates need to be checked. Optionally, we can reduce the set of candidates
using previous identiﬁcation results (e.g., if a signature has detected AES code,
52
F. Gr¨obert, C. Willems, and T. Holz
we can reduce the memory reconstruction to this code section, instead of the
complete trace). Further, we only need to check for 128, 192, and 256 bit keys
and 128 bit input/output blocks, based on the previous identiﬁcation of AES.
Interestingly, this method isolates the cryptographic values from further mod-
iﬁcations. Since we only verify and test using the reference implementation, fur-
ther modiﬁcations, i.e., padding, encoding, or compression, can be separated and
we detect the exact parameters to the cryptographic algorithm. Because of this
soundness of the method, we already can note that we do not encounter false-
positives using this method, as shown in the evaluation. In our proof-of-concept
implementation, we only focussed on symmetric cryptographic algorithms.
Other Approaches. For comparison, we also implemented the approaches by Ca-
ballero et al. [2] and Wang et al. [20] to evaluate their method. A simple, yet
eﬀective, generic identiﬁcation method is built upon the ﬁrst observation: we
evaluate basic blocks and determine whether the percentage of bitwise instruc-
tions is above a certain threshold. If the percentage is above the empirically-
determined threshold of 55%, then we have identiﬁed cryptographic code. To
eradicate false-positives, we use a minimum instructions per basic block thresh-
old of 20: this threshold was determined by Caballero et al. and proved to be
successful in our experiments, too.
Following the work from Wang et al. [20], we also implemented a cumulative
measurement of the bitwise arithmetic instructions. Instead of measuring the
bitwise percentage for basic blocks or function names, we update the percentage
of bitwise instructions as we traverse the trace.
4 Experimental Evaluation
We have implemented the heuristics introduced in the previous section and now
evaluate our approach and compare it to related work in this area. First, we
provide an overview of the testing environment and then describe the system’s
performance for the testing applications, an oﬀ-the-shelf application, a packed
testing application, and a real-world malware sample.
4.1 Evaluation Environment
The tracing is performed in a Sun VirtualBox 3.1.2 running Windows XP SP3
which is hosted on Mac OS X 10.6.2. The Pin version is 2.7-31933. The virtual
machine is conﬁgured to have 1024 MB of RAM and operates with a single core
of the host computer. The trace is written to the disk of the host computer
through a VirtualBox shared folder. The host computer, on which the analysis
VM is running, is equipped with a 2.4 GHz Intel Core 2 Duo with 4 GB of RAM.
The FIFO queue size of the analysis is by default 500,000 instructions. With a
fully loaded queue, the analysis process uses about 1.9 GB of RAM.
For the evaluation, we developed 13 testing applications and Table 2 provides
an overview. The applications take input (e.g., two ﬁles holding plaintext and
Automated Identiﬁcation of Cryptographic Primitives in Binary Programs
53
Table 2. Overview of testing applications
Implementation Algorithm Version
Mode
Beecrypt AES
Brian Gladman AES
Cryptopp AES
OpenSSL AES
Cryptopp DES
OpenSSL DES
Cryptopp RC4
OpenSSL RC4
Beecrypt MD5
Cryptopp MD5
OpenSSL MD5
Cryptopp RSA
OpenSSL RSA
Compiler
VC dynamic ECB encryption