pointer at the start of every 128-byte chunk with the rest of
the chunk zero-padded. We ensured that the pointers chosen
Fig. 4: Execution times for the single-level pointer-chasing DMP (“Array
of Pointers”), single-level indirection-based DMP (“Indirections”; c.f. Sec-
tion V-F3), and Baseline/pointers computed on the fly (“Computed”) patterns,
using the setup in Algorithm 1. We measure access time using on-chip timers
according to Algorithm 1 (stop time - start time). Times are obtained
using mach_absolute_time and converted to nanoseconds as described in
Section V-D. For the indirection-based access pattern, the AoP dereference is
replaced with an indirection. Each point represents average pointer dereference
time (averaged across 2560 runs and the number of accesses in the train loop)
with error bars representing standard deviation.
We attribute this to the DRAM frequency scaling discussed
in Section II-E. From the core’s perspective, an increase in
DRAM frequency will appear as a decrease in access times.
These results provide evidence that the speedups are not the
result of speculative execution. First, speculation would not
cause such a large and consistent speedup for the AoP while
leaving the baseline–which executes the same (serialized)
instruction sequence in the same loop–unaffected.2 Second,
these speedups vanish when we run the same experiment
on the M1’s Icestorm cores, which still feature speculative
execution but (presumably) lack other high-performance mi-
croarchitectural features such as the DMP.
The results are consistent with the behavior of a DMP
(Section II-A). When iterating through smaller AoPs (regimes
(1) and (2) in Figure 4),
the DMP is less confident and
dereferences fewer pointers. When iterating through larger
AoPs (regime (2)), the DMP is more confident and aggres-
sively dereferences more pointers resulting in larger speed
ups [17, 50].
1) Testing for prefetches+dereferences of unaccessed
AoP entries: We also tested the existence of the DMP with a
second methodology. Shown in Figure 3, the idea is to have the
test program stop iterating through the AoP without accessing
all of the pointers and to then test whether the next unaccessed
AoP entries have been prefetched and dereferenced. If the AoP
stores M pointers, we have the test program access N pointers
for N < M. We then perform what we call a test access, and
measure the time to load the cache line at the address given
by aop[M].3 Critically, we avoid interaction with the DMP
by not accessing the aop during the test access. That is, by
computing and accessing the address pointed to by aop[M] in
the same manner as in the baseline case.
2Subsequent results in Section VI are also inconsistent with speculative
execution but consistent with prefetchers.
3This assumes M ≤ N +△ where △ is the prefetcher depth (Section II-A).
In this experiment, we assume that this holds and that △ is known. Analyzing
what is the depth △ in different situations is a subject in Section II-A.
(3)(2)(1)Memory	Access	PatternComputedIndirectionsArray	of	PointersMean	Access	Time	(NS)02004006008001000Number	of	Accesses	in	Train	Loop	(NUM_PTRS)124816326412825651210242048409681920255075100125150175Trial number101102103Access time (PMC cycles)L1 access timeL2 access timeFastest main memory timesDMP prefetched ptr access timeBaseline pattern ptr access timefor the outer AoP would not cause the DMP to activate for the
inner AoP and data buffer, which would create false positives.
The access pattern and training loop is then the same as the
AoP DMP (Algorithm 1), but this time we double dereference
the pointer at the current index of the AoP.
3) Testing for single-level
indirection-based DMPs:
Next, we tested for the existence of a single-level indirection-
based prefetcher such as the indirect memory prefetcher (i.e.,
B[A[i]] [50]). Such prefetchers also have interesting (and dif-
ferent) security implications due to their ease of leaking non-
pointer data (Section IV-C). For this experiment, we changed
the single-level AoP-style code in Algorithm 1 so that the AoP
would store offsets into a second array, as opposed to direct
pointers into memory.
4) Results: Both of the above experiments did not indicate
the presence of other styles of DMP. Figure 4 “Indirections”
shows the performance of the indirection-based experiment
relative to the pointer-chasing variants. We did not try to
equalize the instruction sequences between this variant and the
pointer-chasing variants. Yet, the Indirections variant results in
performance that is very similar to the pointer-chasing variant.
This is expected assuming no such indirection-based DMP
exists: both codes are memory bound (hence, performance is
largely a function of the average memory access time) and
exhibit the same memory system performance.
Since the single-level indirection-based prefetcher experi-
ment returned a negative result, we did not directly test the
existence of a multi-level indirection-based prefetcher.
5) Other microarchitectures: We also ran existence tests
for indirection-based DMPs (Section V-F3) and the single-
level, pointer-chasing DMP (Algorithm 1) on more than 5 Intel
and 3 AMD processor families, more than 50 machines in
total. In none of these systems did we observe test pointers
being prefetched.
VI. REVERSE ENGINEERING THE M1 DMP
After confirming that there is a DMP on the M1, we now
turn to reverse engineering the parameters of the M1 DMP so
that we can exploit it. Recall from Section IV that we need to
answer the following questions to understand how to exploit
or mitigate a DMP:
• What are the preconditions for DMP activation?
• What memory regions can a DMP access?
• What function of memory values is transmitted?
• How can the adversary receive the transmitted values?
These questions are discussed below and summarized in
Table II.
A. What are the preconditions for activating the M1 DMP?
We identified four conditions necessary to activate the M1’s
DMP.
1) Fire vs. Icestorm cores: Any thread interacting with
the DMP must be running on a Firestorm core (Section II-E).
Developers and MacOS users can specify whether a program
should run on an Icestorm or Firestorm core by modifying a
process’s quality of service (QoS) bits. For example, setting a
process’s QoS to ‘user interactive’ will cause the process to
be scheduled only on Firestorm cores [12, 26].
9
2) DMP “noise” tolerance: There are restrictions on oper-
ations between sequential accesses of the AoP. We examined
four types of noise: serialization, system calls, other spurious
operations, and time. We found that system calls and serial-
ization such as instruction and data synchronization barriers4
placed between accesses to pointers in the AoP prevents the
DMP from activating. On the other hand, we found that
the DMP is generally tolerant of time-based delays between
memory accesses and the insertion of unrelated arithmetic
(e.g., incrementing a counter variable from 1 to 1000) or
memory operations between accesses.
3) DMP minimum confidence threshold: For the DMP to
activate, the program needs to dereference at least 3 pointers
in the AoP. That is, the DMP has a minimum confidence
threshold of 3 accesses to activate at all (Section II-A).
We determined this threshold by running the Section V-E1
experiment with various lengths of training loop (N). We
then find the smallest N at which we observe cache hits on
dereferencing the (un-touched) test pointers. On the M1, this
occurs after 3 AoP pattern accesses. This is consistent with
Figure 4, which shows the AoP and baseline patterns diverging
for train lengths between 2 and 4.
4) AoP alignment requirements: The M1 DMP will not
build confidence if the addresses of the pointers in the AoP are
not aligned to eight-byte boundaries. This is easily observed
by offsetting the start of the AoP by any amount that is not
a multiple of 8, and running any of the previous experiments.
This is slightly disappointing for attackers, as it precludes a
sliding-window style attack where the attacker learns a secret
byte-by-byte through repeated experiments with differently-
aligned AoPs.5
We also make several observations that weaken assumptions
needed to activate the DMP.
5) The DMP is not IP indexed: We observed that the M1
DMP is not IP indexed. That is, the instructions that cause
the memory accesses matching the AoP pattern need not be
related in any way. We tested this by unrolling the training
loop from Algorithm 1 into straight-line memory accesses
without branches and observing that both of the experiments
from Section V still show the DMP activating.
6) The DMP can be activated using only speculative
accesses: We found that the DMP can be activated using only
speculative memory accesses that are eventually squashed. We
demonstrate this by adapting a Spectre attack example [5] to
run on the M1, and using it to activate the DMP on branch
mispredictions (Algorithm 6). Instead of tricking the branch
predictor into reading out of bounds, the experiment will read
the first three elements in the DMP AoP pattern when it
mispredicts and speculatively executes. Since DMP activation
is slightly noisy for an AoP with 3 pointers (Figure 2),
the experiment performs this branch-predictor training and
misprediction loop many times (lines 7-16) to raise confidence
in whether target ptr was dereferenced or not. If the DMP
4https://developer.arm.com/documentation/100941/0100/Barriers.
5Recall from Section IV-C, the attacker may be able to learn high-order bits
of a secret (even if it is not a virtual address) by monitoring TLB and related
MMU state. A sliding-window attack can amplify this leakage by tricking the
DMP into interpreting different secret bytes as high-order address bits.
can be triggered via speculation only, then the target pointer
should be dereferenced and it will be a cache hit which is
tested for on line 17.
1 aop[0∗ 128] = p1
2 aop[1∗ 128] = p2
3 aop[2∗ 128] = p3
4 aop[3∗ 128] = target ptr
5 aop[4∗ 128] = target ptr
6 FLUSH CACHE
7 for train iter in 1...30 do
8
idx1 = 0
/* Branchless if-then-elses */
idx2 = if (train iter%6) then 0 else 1
idx3 = if (train iter%6) then 0 else 2
if idx3 == access evicted memory containing(0) then
9
10
11
12
13
14
15
16 end
17 result = was l2 timing(target ptr)
∗aop[idx1∗ 128]
∗aop[idx2∗ 128]
∗aop[idx3∗ 128]
end
Algorithm 2:
Pseudocode of experiment for determining whether
the DMP will activate when all memory accesses are speculative and
eventually squashed. This code will also be used in our ASLR break
(Section VII-D). p1, p2, p3 are unique random pointers to a data buffer.
The cache line storing the value 0 used in the conditional check is evicted
on each iteration.
Fig. 6: Speculative accesses in an AoP pattern causes the DMP to activate.
Figure 6 shows the dereference times of the target ptr
(line 17) across 1530 experiment runs. The baseline shows
dereference times for the target pointer without
the three
speculative accesses on each 6th train loop iteration–i.e., it
never mispredicts.
B. What memory regions can the M1 DMP access?
There are two main considerations for whether or not the
M1 DMP can leak a secret at a given address: 1) how far the
secret is located from an adversary-interactable AoP and 2)
whether the DMP is willing to prefetch memory located at
any reachable address.
Recall from Section IV-B that
thest pointer past
level DMP can dereference is
the location of the fur-
the end of an AoP that a single-
(max stride × depth) +
10
end o f
training address where the maximum prefetch dis-
tance is max stride× depth in bytes. In the case of the M1,
we found that the DMP will also activate when traversing an
AoP backwards.
1) Determining maximum prefetch distance (as a func-
tion of confidence, stride and depth): We found there to be a
non-trivial relationship between DMP confidence (the number
of training accesses touching the AoP) and stride (distance
between pointers) in determining the M1 DMP’s maximum
prefetch depth. This is shown in Figure 7 and Table I. The
high-order bit is that a stride of 64 cache lines (8 KiB) enables
the DMP to reach (access and dereference) a pointer 64 KiB
(i.e., 8 pointers deep) away from either end of the AoP.
To start, Figure 7 shows that the number of entries the
DMP is willing to prefetch and dereference (depth) is clearly
proportional to the number of accesses the program makes
that match the DMP’s target pattern (confidence). This is
consistent with expected DMP behavior (Section V-E). Note,
consistent with Section VI-A3, the AoP DMP plot only shows
low latency test accesses for train sizes 4 and larger. We
note two other features in the data. First, when more than
2048 accesses are performed, either the first eight or sixteen
accesses are not prefetched. This behavior is caused by a 16
KiB page boundary, and is further studied in Section VI-B2.
Second, for both the AoP and baseline patterns, as the number
of accesses increases, the access time for misses decreases. We
propose an explanation for this in Section V-E.
Table I reports the maximum distance in bytes we can
prefetch/dereference a pointer. We run this experiment with
a training loop that is large enough to maximize confidence
(and therefore depth, see previous paragraph). Our experiments
show that the maximum distance is not monotonically increas-
ing with stride, but larger strides do tend to enable larger
maximum prefetch distances, as expected. To summarize, up
to a stride of 8 KiB, the maximum distance increases (up to
a maximum distance of 64 KiB). We did not see the DMP
activate for strides larger than 8 KiB (1024 pointers).
Finally, we observed that the DMP does not activate when
the stride, at cache line granularity, is not a power of two.
This is shown in Figure 8. We confirmed that low measure-
ments on the y-axis (faster times) occur iff test accesses are
dereferenced, i.e., indicate that the DMP activated.
Stride (B) Maximum Distance
Stride (B) Maximum Distance
from AoP (B)
384
384
256
1536
1024
2048
8
16
32
64
128
256
from AoP (B)
4096
8192
16384
32768
65536
512
1024
2048