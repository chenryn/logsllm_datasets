84.1 ± 1.7
76.8 ± 2.5
82.6 ± 5.6
VNG++
93.9 ± 0.3
91.6 ± 0.3
93.5 ± 0.3
94.3 ± 0.3
94.8 ± 0.3
91.7 ± 0.4
88.2 ± 0.4
87.6 ± 0.3
80.2 ± 0.5
85.6 ± 0.7
Figure 10. Accuracies (%) of P, P-NB, and VNG++ classiﬁers at k =
128.
when we consider countermeasures, VNG++ matches P in
performance. This holds despite the use of fewer features
and the simpler machine learning algorithm used by the
former. As it turns out, in the face of countermeasures,
the coarse features are the damaging ones and ﬁne-grained
features are not particularly helpful.
A ﬁnal question lingers: does using an SVM provide any
advantage over a na¨ıve Bayes classiﬁer? We implemented a
na¨ıve Bayes version of the P classiﬁer. This P-NB classiﬁer
uses a 1-1 mapping of the features used by P to analogues
suitable for use with a na¨ıve Bayes classiﬁer. A comparison
of performance at k = 128 for P, P-NB, and VNG++ are
given in Figure 10. Overall, we see that the results are
consistent across all three classiﬁers. A single exception
is the accuracy of P-NB for Session Random 255, which
results in a surprisingly low classiﬁer accuracy.
E. Discussion
The nine countermeasures considered so far attempt to
obfuscate leaked features of the trafﬁc via padding and
insertion of dummy packets. As we’ve seen, however,
these fail
to protect signiﬁcant amounts of identifying
information from being leaked from coarse features of
the encrypted trafﬁc, rather than the ﬁne-grained, per-
packet features typically targeted by TA countermeasures.
Unfortunately, these kinds of features are precisely the
ones that are most difﬁcult to efﬁciently hide.
Obfuscating total bandwidth is an obvious case in point.
To prevent this feature from leaking information, a coun-
termeasure must ensure a similar amount of bandwidth
use across all websites in any given privacy set. Since we
do not want to forego functionality (e.g., shutting down
connections prematurely), this translates into a counter-
measure that inserts dummy trafﬁc until we achieve a total
bandwidth close to that of the maximum bandwidth usage
of any website in the privacy set.
Hiding burst bandwidth is also problematic. As seen
in Figure 8, different websites can have quite different
patterns of bursts. A countermeasure must smooth out
these patterns. In theory, a trafﬁc morphing-like coun-
termeasure can attempt to imitate a target trace’s burst
patterns, however this will require buffering packets for
potentially long periods of time. Thus, countermeasures
for preventing website trafﬁc analysis must incur both
bandwidth and latency overheads.
In all, our analyses leaves little wiggle room for coun-
termeasures to operate within. Providing robust protection
against ﬁngerprinting attacks for arbitrary websites in a
closed-world setting, such as the one presented here, is
going to have to be inefﬁcient.
VII. BuFLO: BUFFERED FIXED-LENGTH OBFUSCATOR
Our analysis thus far leaves us with the conclusion that,
despite the long line of work on TA attacks and counter-
measures, we have no packet-oriented countermeasure that
prevents website ﬁngerprinting attacks. We therefore want
to know whether any measure can work, even prohibitively
inefﬁcient ones.
Following the analysis of the last section, we know
that any effective countermeasure must hide the total time,
bandwidth use, and burst patterns. To that end, we consider
a new countermeasure Buffered Fixed-Length Obfuscator,
or BuFLO. It is a realization of the “fool-proof” folk-
lore countermeasure that, intuitively, should defeat any
TA classiﬁer by removing all side-channel information.
BuFLO operate by sending ﬁxed-length packets at a ﬁxed
341
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Figure 11. Accuracy of P (left) and VNG++ (right) classiﬁers against the best-performing countermeasures from Section III.
interval for at least a ﬁxed amount of time. If a ﬂow goes
longer than the ﬁxed time out, BuFLO lets it conclude
while still using ﬁxed-length packets at a ﬁxed interval.
In an ideal implementation, BuFLO will not leak packet
lengths or packet timings, and so BuFLO should do a good
job at closing side-channels that enable TA classiﬁers.
This type of countermeasure has been investigated in the
context of other TA attacks, such as those on anonymity
networks [17, 23]
Our simulation-based analysis of BuFLO provides some
positive evidence for packet-level countermeasures, but in
fact our results here are mostly negative, thereby reinforc-
ing the lessons learned in prior sections. BuFLO is, as one
might expect, incredibly inefﬁcient. Moreover, we will see
that even mild attempts to claw back some efﬁciency can
fail: setting the minimum session too aggressively short
opens up vulnerability to our coarse-feature classiﬁers.
A. BuFLO Description
A BuFLO implementation is governed by three integer
parameters d, ρ and τ:
• Parameter d determines the size of our ﬁxed-length
packets.
• Parameter ρ determines the rate or frequency (in
milliseconds) at which we send packets.
• Parameter τ determines the minimum amount of time
(in milliseconds) for which we must send packets.
A BuFLO implementation at the start of communications
will send a packet of length d every ρ milliseconds until
communications cease and at least τ milliseconds of time
have elapsed. Speciﬁcally, data is buffered into discrete
chunks, and these chunks are sent as quickly as possible
via the steady ﬂow of the ﬁxed-length packets. When
no data is in the buffer, dummy data is sent
instead.
This assumes that the application-layer signals the start
and end of communication. Alternatively, we could have
chosen τ as an upper bound on the duration of our
communications session and forcibly close the connection
even if communications are still in progress. This would
disable any websites that take longer to load, making it
unlikely to be a pragmatic choice.
B. Experiments
the very least difﬁcult
In this section, we examine BuFLO for various pa-
rameters using the Hermann dataset and provide detailed
results in Figure 12. Since we are using a simulation-based
experiment, these results reﬂect an ideal implementation
that assumes the feasibility of implementing ﬁxed packet
timing intervals. This is at
in
practice [7] and clearly impossible for some values of
ρ. Simulation also ignores the complexities of cross-layer
communication in the network stack, and the ability for
the BuFLO implementation to recognize the beginning
and end of a data ﬂow. If BuFLO cannot work in this
setting, then it is unlikely to work elsewhere, aiding us in
our exploration of the goal of understanding the limits of
packet-level countermeasures.
We evaluated BuFLO empirically with parameters in
the ranges of τ ∈ {0, 10000}, ρ ∈ {20, 40} and d ∈
{1000, 1500}. The least bandwidth-intensive conﬁgura-
tion, at τ = 0, ρ = 40 and d = 1000 would require at
least 0.2 Mbps of continuous synchronous client-server
bandwidth to operate8. Surprisingly, with this BuFLO
conﬁguration and a privacy set size of k = 128, the P
classiﬁer still identiﬁes sites with an average accuracy of
27.3%. This is compared to 97.5% average accuracy with
no countermeasure applied. At the other extreme of our
experiments with τ = 10000, ρ = 20 and d = 1500 it
would require at least 0.6 Mbps of synchronous client-
server bandwidth to operate. Here, the P classiﬁer can still
identify sites with a privacy set size of k = 128 with an
average 5.1% accuracy.
C. Observations about BuFLO
leak packet
BuFLO cannot
lengths, nor can it
leak
packet timings. Yet, our experiments indicate that an ag-
gressively conﬁgured BuFLO implementation can still leak
information about transmitted contents. This is possible
because BuFLO can leak total bytes transmitted and the
time required to transmit a trace in two circumstances:
(cid:2)
1000
ρ
(cid:3)
(cid:2)
·
(cid:3)
.
8d
106
8Calculated by
342
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:50:30 UTC from IEEE Xplore.  Restrictions apply. 
Parameters
BuFLO (τ=0, ρ=40, d=1000)
BuFLO (τ=0, ρ=40, d=1500)
BuFLO (τ=0, ρ=20, d=1000)
BuFLO (τ=0, ρ=20, d=1500)
BuFLO (τ=10000, ρ=40, d=1000)
BuFLO (τ=10000, ρ=40, d=1500)
BuFLO (τ=10000, ρ=20, d=1000)
BuFLO (τ=10000, ρ=20, d=1500)
Overhead
Bandwidth (%)
Latency (s)
93.5
120.0
140.5
201.3
129.2
197.5
364.5
418.8
6.0
3.6
2.4
1.2
6.0
3.6
2.4
1.2
Classiﬁer Accuracy (%)
LL
18.4 ± 2.9
16.2 ± 1.6
16.3 ± 1.2
13.0 ± 0.8
12.7 ± 0.9
8.9 ± 1.0
5.4 ± 0.8
4.4 ± 0.2
H
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
P
27.3 ± 1.8
23.3 ± 3.3
20.9 ± 1.6
24.1 ± 1.8
14.1 ± 0.9
9.4 ± 1.3
7.3 ± 1.0
5.1 ± 0.7
VNG++
22.0 ± 2.1
18.3 ± 1.0
15.6 ± 1.2
18.4 ± 0.9
12.5 ± 0.8
8.2 ± 0.8
5.9 ± 1.0
4.1 ± 0.8
P-NB
21.4 ± 1.0
18.8 ± 1.4
17.9 ± 1.7
18.7 ± 1.0
13.2 ± 0.7
9.3 ± 1.3
6.8 ± 0.9
5.3 ± 0.5
Figure 12. Overhead and accuracy results for the BuFLO countermeasure at k = 128.
• The data source continued to produce data beyond the
threshold τ.
• The data source ceases to produce data by the thresh-
old τ, but there is still data in the buffer at time τ.
The ﬁrst situation can occur if our our threshold τ is not
sufﬁciently large to accommodate for all web pages that we
may visit. The latter situation occurs when values ρ and d
are not sufﬁciently conﬁgured to handle our application’s
data throughput, such that we transmit all data by time τ.
What is more, in some circumstances an inappropriately
conﬁgured BuFLO implementation can can actually beneﬁt
an adversary. At k = 128 with τ = 0, ρ = 40
and d = 1000 (see Figure 12) the BuFLO countermeasure
can increase the accuracy of the Time classiﬁer from 9.9%
to 27.3%! In retrospect this is not surprising. If we throttle
the bandwidth of the web page transfer, we will amplify
its timing ﬁngerprint.
These results reinforce the observations of prior sec-
tions. Namely, that TA countermeasures must, in the con-
text of website identiﬁcation, prevent coarse features from
being leaked. As soon as these features leak, adversaries
will gain some advantage in picking out web pages.
VIII. RELATED WORK
Trafﬁc analysis of encrypted data has been studied ex-
tensively. Our focus is on identiﬁcation (or ﬁngerprinting)
of web pages within encrypted tunnels, and we do not
discuss other contexts, such as analysis of encrypted VoIP
trafﬁc [18–21] or revelation of web page contents [2, 3].
Even so, there is a signiﬁcant amount of literature focused
on website identiﬁcation, including a wide diversity of
evaluation methodologies, attacks, and countermeasures.
To the best of our knowledge, the ﬁrst academic dis-
cussion of TA attacks in this context was by Wagner and
Schneier [16]. They relayed an observation of Yee that
SSL might leak the URL of an HTTP get request because
ciphertexts leak plaintext
length. Wagner and Schneier
suggested that per-ciphertext random padding should be
included for all cipher modes of SSL.
Cheng and Avnur [4] provided some of the ﬁrst ex-
perimental evidence of web page ﬁngerprinting attacks
by analyzing pages hosted within one of three websites.
Their attack assumes perfect knowledge of HTML and web
343
page object sizes, which is not always precisely inferred
from ciphertexts. They also suggested countermeasures
including padding of HTML documents, Pad to MTU, and
introduction of spurious HTTP requests. They evaluated
the ﬁrst two in the context of their attack, and claim some
efﬁcacy for the considered websites.
Sun et al. [15] investigated a similar setting, in which
the adversary can precisely uncover the size of individual
HTTP objects in a non-pipelined, encrypted HTTP connec-
tion. They provided a thorough evaluation utilizing a cor-
pus of 100,000 websites. They described a classiﬁer based
on the Jaccard coefﬁcient similarity metric and a simple
thresholding scheme. It was successful against raw trafﬁc,
and while we did not implement their attack, several of the
classiﬁers we consider are likely to outperform it. They
also explored numerous countermeasures, including per-
packet padding, byte-range requests, client-based prefetch-
ing, server-based pushing of content, content negotiation,
web ad blockers, pipelining, and using multiple browsers