for each patient p.
If p has HIV (which is private information),
she prints out p’s address for her records. The resulting transaction
takes one of two forms. Both begin with the event Patsy start. If p
is HIV negative, the transaction ends with Read HIV. Otherwise, it
includes the blue events with dashed outlines. Meanwhile, Mallory
updates the p’s (less secret) address (3b), resulting in the transac-
tion with red, solid-bordered events. This conﬂicts with Patsy’s
transaction, requiring the system to order the update and the read,
exactly when p has HIV (“?” in 3c).
Patsy reads every patient’s address. This illustrates a core goal of
our work: identifying which programs can be scheduled securely.
In Fig. 4a, lines 3 and 4 of Patsy’s code have been switched. As
Fig. 4c shows, both possible transactions read the patient’s address.
Since Mallory cannot distinguish which of Patsy’s transactions has
run, she cannot learn which patients have HIV.
2.3 Attack Demonstration
Using code resembling Fig. 3, we implemented the attack de-
scribed in our hospital example (§2.2) using the Fabric distributed
system [3, 24]. We ran nodes representing Patsy and Mallory, and
a storage node for the patient records.
To improve the likelihood of Mallory conﬂicting with Patsy (and
thereby receiving an abort), we had Patsy loop roughly once a sec-
ond, continually reading the address of a single patient after veri-
fying their HIV-positive status. Meanwhile, Mallory attempted to
update the patient’s address with approximately the same frequency
as Patsy’s transaction.
Like many other distributed transaction systems, Fabric uses two-
phase commit. Mallory’s window of opportunity for receiving an
abort exists between the two phases of Patsy’s commit, which ordi-
narily involves a network round trip. However, both nodes were run
on a single computer. To model a cloud-based server, we simulated
a 100 ms network delay between Patsy and the storage node.
We ran this experiment for 90 minutes. During this time, Mal-
lory received an abort roughly once for every 20 transactions Patsy
attempted. As a result, approximately every 20 seconds, Mallory
learned that a patient had HIV. In principle, many such attacks
could be run in parallel, so this should be seen as a minimal, rather
than a maximal, rate of information leakage for this setup.
As described later, our modiﬁed Fabric compiler (§ 7) correctly
rejects Patsy’s code. We amended Patsy’s code to reﬂect Fig. 4, and
our implementation of the staged commit protocol (§ 6) was able
to schedule the transactions without leaking information. Mallory
was no more or less likely to receive aborts regardless of whether
the patient had HIV.
3. SYSTEM MODEL
We introduce a formal, abstract system model that serves as our
framework for developing protocols and proving their security prop-
erties. Despite its simplicity, the model captures the necessary fea-
High Security (H)
Low Security (L)
Update address
?
Read address
Patsy start
(a) Patsy’s code
1 atomic {
2 p.address+="␣";
3 }
(b) Mallory’s code
Figure 4: Secure hospital scenario. A secure version of Fig. 3,
in which lines 3 and 4 of Patsy’s code (3a) are switched, and the
resulting lines 2 and 3 can be run in parallel ((cid:104) (cid:107) (cid:105)). Thus the trans-
action reads p’s address regardless of whether p has HIV, and so
Mallory cannot distinguish which form Patsy’s transaction takes.
(c) Resulting transactions
Mallory start
tures of distributed transaction systems and protocols. As part of
this model, we deﬁne what it means for transactions to be serializ-
able and what it means for a protocol to serialize transactions both
correctly and securely.
3.1 State and Events
Similarly to Lamport [23], we deﬁne a system state to include
a ﬁnite set of events, representing a history of the system up to a
moment in time. An event (denoted e) is an atomic native action
that takes place at a location, which can be thought of as a physical
computer on the network. Some events may represent read oper-
ations (“the variable x had the value 3”), or write operations (“2
was written into the variable y”). In Figures 3 and 4, for example,
events are represented as ovals, and correspond to lines of code.
Also part of the system state is a causal ordering on events. Like
Lamport’s causality [23], the ordering describes when one event e1
causes another event e2. In this case, we say e1 happens before e2,
written as e1(cid:95)e2. This relationship would hold if, for example,
((cid:95)) is a strict partial order: irreﬂexive, asymmetric, and transitive.
Therefore, e1(cid:95)e2 and e2(cid:95)e3 together imply e1(cid:95)e3.
e1 is the sending of a message, and e2 its receipt. The ordering
The arrows in Figures 2 to 4 show happens-before relationships
for the transactions involved.
3.2
Information Flow Lattice
We extend Lamport’s model by assigning to each event e a se-
curity label, written (cid:96)(e), which deﬁnes the conﬁdentiality and in-
tegrity requirements of the event. Events are the most ﬁne-grained
unit of information in our model, so there is no distinction between
the conﬁdentiality of an event’s occurrence and that of its contents.
Labels in our model are similar to high and low event sets [30,
10]. In Figures 3 and 4, two security labels, High and Low (H and
L for short), are represented by the events’ positions relative to the
dashed line.
For generality, we assume that labels are drawn from a lattice [12],
depicted in Fig. 5. Information is only permitted to ﬂow upward in
the lattice. We write “(cid:96)(e1) is below (cid:96)(e2)” as (cid:96)(e1)(cid:118)(cid:96)(e2), mean-
ing it is secure for the information in e1 to ﬂow to e2.
For instance, in Fig. 3, information should not ﬂow from any
events labeled H to any labeled L. Intuitively, we don’t want secret
information to determine any non-secret events, because unautho-
rized parties might learn something secret. However, information
can ﬂow in the reverse direction: reading the patient’s address (la-
beled L) can affect Patsy’s printout (labeled H): L (cid:118) H.
Like events, each location has a label, representing a limit on
events with which that location can be trusted. No event should
secret
untrusted
public
untrusted
C
A
B
inte
grity
(cid:118)
secret
trusted
confidentiality
public
trusted
Figure 5: Security lattice: The dot represents a label in the lattice,
and the dashed lines divide the lattice into four quadrants relative
to this label. If the label represents an event, then only events with
labels in quadrant B may inﬂuence this event, and this event may
only inﬂuence events with labels in quadrant A. If the label rep-
resents a location, then only events with labels in quadrant C may
occur at that location.
have more integrity than its location. Similarly, no event should
be too secret for its location to know. Thus, in Fig. 5, only events
to the left of a location’s label (i.e., region C in the ﬁgure) may take
place at that location.
For example, consider Gloria’s payment event at CountriBank in
the Rainforest example Fig. 1. This event (r5 in Fig. 2) represents
money moving from Gloria’s account to Outel’s. The label (cid:96) of r5
should not have any more integrity than CountriBank itself, since
the bank controls r5. Likewise, the bank knows about r5, so (cid:96)
cannot be more conﬁdential than the CountriBank’s label. This
would put (cid:96) to the left of the label representing CountriBank in the
lattice of Fig. 5.
Our prototype implementation of secure transactions is built us-
ing the Fabric system [24], so the lattice used in the implementation
is based on the Decentralized Label Model (DLM) [27]. However,
the results of this paper are independent of the lattice used.
3.3 Conﬂicts
Two events in different transactions may conﬂict. This is a prop-
erty inherent to some pairs of events. Intuitively, conﬂicting events
are events that must be ordered for data to be consistent. For exam-
ple, if e1 represents reading variable x, and e2 represents writing
x, then they conﬂict, and furthermore, the value read and the value
written establish an ordering between the events. Likewise, if two
events both write variable x, they conﬂict, and the system must
decide their ordering because it affects future reads of x.
In our hospital example (Figures 3 and 4), the events Read ad-
dress and Update address conﬂict. Speciﬁcally, the value read will
change depending on whether it is read before or after the update.
Thus for any such pair of events, there is a happens-before ((cid:95))
ordering between them, in one direction or the other.
We assume that conﬂicting events have the same label. This as-
sumption is intuitive in the case of events that are reads and writes
to the same variable (that is, storage location). Read and write op-
erations in separate transactions could have occurred in either or-
der, so the happens-before relationship between the read and write
events cannot be predicted in advance.
Our notion of conﬂict is meant to describe direct interaction be-
tween transactions. Hence, we also assume any conﬂicting events
happen at the same location.
r2
r0
b1
p
r1
b2
b0
Figure 6: An example system state. The events r0, r1, and r2 form
transaction R, and the events b0, b1, and b2 form transaction B.
Event p is not part of either transaction. It may be an input, such
as a network delay event, or part of a protocol used to schedule
the transactions. In this state, r1(cid:95)p(cid:95)b1, which means that r1
happens before b1, and so the transactions are ordered: R(cid:95)B.
3.4 Serializability and Secure Information Flow
Traditionally a transaction is modeled as a set of reads and writes
to different objects [28]. We take a more abstract view, and model a
transaction as a set of events that arise from running a piece of code.
Each transaction features a start event, representing the decision to
execute the transaction’s code. Start events, by deﬁnition, happen
before all others in the transaction. Multiple possible transactions
can feature the same start event: the complete behavior of the trans-
action’s code is not always determined when it starts executing, and
may depend on past system events.
Fig. 4c shows two possible transactions, in blue, that can result
from running the secure version of Patsy’s code. They share the
three events in solid blue, including the start event (Patsy start);
one transaction contains a fourth event, Print address. The ﬁgure
also shows in red the transaction resulting from Mallory’s code.
Fig. 6 is a more abstract example, in which r0 is the start event of
transaction R, and b0 is the start event of transaction B.
In order to discuss what it means to serialize transactions, we
need a notion of the order in which transactions happen. We obtain
this ordering by lifting the happens-before relation on events to a
tion T2 directly depends on T1, written T1 ≺ T2, if an event in T1
happens before an event in T2:
happens-before ((cid:95)) relation for transactions. We say that transac-
T1 ≺ T2 ≡ T1 (cid:54)= T2 ∧ ∃e1 ∈ T1, e2 ∈ T2 . e1(cid:95)e2
closure of this direct dependence relation ≺. Thus, in Fig. 6, the
The happens-before relation on transactions ((cid:95)) is the transitive
ordering R(cid:95)B holds. Likewise, Fig. 7 is a system state featur-
Patsy(cid:95)Mallory holds.
ing the transactions from our hospital example (Fig. 4), in which
DEF. 1
(SERIALIZABILITY). Transactions are serializable ex-
actly when happens-before is a strict partial order on transactions.
ordering would represent a serial order of transactions.
Any total order consistent with this strict partial order would then
respect the happens-before ordering ((cid:95)) of events. Such a total
formation-ﬂow secure if happens-before ((cid:95)) relationships between
(SECURE INFORMATION FLOW). A transaction is in-
transaction events—and therefore causality—are consistent with
permitted information ﬂow:
DEF. 2
e1(cid:95)e2 =⇒ (cid:96)(e1)(cid:118)(cid:96)(e2)
This deﬁnition represents traditional information ﬂow control
within each transaction.
Intuitively, each transaction itself can-
not cause a security breach (although this deﬁnition says noth-
ing about the protocol scheduling them). In our hospital example,
Read HIV
Print address
High Security
Low Security
Mallory releases lock
Update address
Mallory acquires lock
Patsy releases lock
Read address
Patsy acquires lock
Patsy start
Mallory start
Figure 7: A possible system state after running transactions from
Fig. 4c, assuming the patient has HIV, and an exclusive lock is used
to order the transactions. (Events prior to everything in both trans-
actions are not shown.) Because Patsy acquires the lock ﬁrst, the
transactions are ordered Patsy(cid:95)Mallory. While each transaction
is information-ﬂow secure (a property of events within a transac-
tion), when Patsy releases the lock after her transaction, a high se-
curity event happens before a low security one. We discuss secure
scheduling protocols in §6.
Patsy’s transaction in Fig. 3c is not information-ﬂow secure, since
Read HIV happens before Read address, and yet the label of Read
HIV, H, does not ﬂow to the label of Read address, L. However, in
the modiﬁed, secure version (Fig. 4c), there are no such insecure
happens-before relationships, so Patsy’s transaction is secure.
3.5 Network and Timing
Although this model abstracts over networks and messaging, we
consider a message to comprise both a send event and a receive
event. We assume asynchronous messaging: no guarantees can be
made about network delay. Perhaps because this popular assump-
tion is so daunting, many security researchers ignore timing-based
attacks. There are methods for mitigating leakage via timing chan-
nels [22, 4, 7] but in this work we too ignore timing.
To model nondeterministic message delay, we introduce a net-
work delay event for each message receipt event, with the same
label and location. The network delay event may occur at any time
after the message send event. It must happen before ((cid:95)) the cor-
responding receipt event. In Fig. 6, event r1 could represent send-
ing a message, event p could be the corresponding network delay
event, which is not part of any transaction, and event b1 could be
the message receipt event. Fig. 6 does not require p to be a network
delay event. It could be any event that is not part of either transac-
tion. For example, it might be part of some scheduling protocol.
3.6 Executions, Protocols, and Inputs
An execution is a start state paired with a totally ordered se-
quence of events that occur after the start state. This sequence must