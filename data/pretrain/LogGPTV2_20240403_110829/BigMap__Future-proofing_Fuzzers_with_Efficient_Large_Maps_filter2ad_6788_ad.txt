13.98
25.64
101
140
122
174
345
1,046
64,317
65,781
76,065
82,105
108,231
131,677
licm
gvn
strength-reduce
indvars
loop-vectorize
instcombine
1 Maximum edge coverage among all fuzzing conﬁgurations.
2 With a 64kB map.
3 Derived using SanitizerCoverage [18].
36.29
36.89
40.83
42.98
51.06
56.90
instrumentation code. This mode is faster than the gcc-based
or coverage-sanitizer based alternatives [13]. Optimizations
mentioned in Section IV-E applied to both AFL and BigMap.
2) Benchmarks: We used 19 benchmarks in our experi-
ments. The characteristics of these benchmarks are given in
Table II. The ﬁrst 13 benchmarks are taken from FuzzBench
[10]. These benchmarks are relatively small and have low
collision rates. The remaining six benchmarks are LLVM
optimization passes collected from OSSFuzz [5]. These
benchmarks share the same LLVM-opt binary [20], and
different fuzzing harnesses are selected via command-line
arguments. The LLVM-opt binary itself has a high number
of static edges. Collectively, the benchmarks span a wide
range of discoverable edges (∼1k - 131k) and collision rates.
3) Performance Metrics: The following metrics are used
to evaluate the performance of our approach:
• Test case generation throughput or execution rate:
Denotes the number of test cases evaluated by the
fuzzer per unit time. Everything else being equal (e.g.,
seed selection and mutation strategy), a fuzzer with a
higher throughput is expected to give better coverage.
• Unique crashes: AFL has a built-in deduplication
mechanism for ﬁnding unique crashes. AFL considers
a crash unique if it covers an edge unseen by the
previous crashes or does not cover an edge common
in all the previous crashes. This mechanism requires
maintaining a local and global crash-coverage bitmap,
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
537
)
c
e
s
/
s
d
n
a
s
u
o
h
t
(
t
u
p
h
g
u
o
r
h
T
18
16
14
12
10
8
6
4
2
0
AFL
BigMap
64k
64k
256k
256k
2M
2M
8M
8M
Average speedups
64k map : 0.98x
256k map : 1.4x
2M map : 4.5x
8M map : 33.1x
Figure 6: Test case generation throughput of AFL and BigMap with different map sizes. AFL’s throughput drops signiﬁcantly
as the map size is increased. Map size variation has considerably less impact on BigMap.
making it inherently biased towards larger maps. To
avoid this bias, we resorted to Crashwalk [21], which
takes the hash of the call stack and the faulting address
for deduplicating crashes.
• Edge Coverage: While crash coverage is the proper
way of quantifying a fuzzer’s performance, crashes in
a program are typically sparse. Therefore, in addition
to crash coverage, we also report edge coverage. Intu-
itively, a fuzzer that covers more edges are also likely
to discover more bugs. To get the edge coverage, we
collected the output corpus of the fuzzers and subjected
them to a bias-free independent coverage build.
B. Evaluating the Impact of Map Size Variation
We claimed that BigMap performs efﬁciently regardless of
the size of the coverage bitmap. This section validates the
claim by comparing BigMap’s performance with AFL for
four different map sizes: 64kB, 256kB, 2MB, and 8MB. In
this experiment, we used an average of three runs to reduce
the variations introduced by random mutation steps.
1) Impact on Test Case Generation Throughput: The
test case generation throughput of AFL and BigMap is
shown in Figure 6. As expected, AFL’s throughput dropped
dramatically as the map size is increased. On average, AFL’s
throughput went from 4,400/sec for a 64kB map to only
125/sec for an 8MB map. BigMap handled large maps
gracefully without any signiﬁcant drop, and the average
throughput remained consistently above 4,100/sec irrespec-
tive of the map size.
For the 64kB map, BigMap usually outperformed AFL
for smaller benchmarks (e.g., zlib, libpng, proj4), while AFL
performed better on larger benchmarks (e.g., sqlite3, indvars,
instcombine). This outcome is because only a tiny portion
of the 64kB map is used for the small benchmarks. In such
cases, BigMap gained the advantage by traversing the used
region of the map. On the other hand, larger benchmarks
almost completely ﬁlled the 64kB map. As a result, BigMap
and AFL performed nearly the same during the classify,
compare, and reset stages, but BigMap is ultimately slightly
slower due to the extra indirection overhead during the
update stage. One thing to note here is that the nearly full
map also implies very high collision rates, suggesting the use
of maps bigger than 64kB would be beneﬁcial. Other factors
impacting the throughput include the working-set size and
access-pattern of the benchmark itself.
For larger maps, BigMap universally provided higher
throughput than AFL. The 8MB map, in particular, incurred
an extremely high performance hit for AFL. This perfor-
mance hit is because, with an 8MB map, the combined
size of the local and global coverage maps exceeded the
last-level cache capacity of our experimental setup. Note
that for a few benchmarks (e.g., libpng, proj4, libjpeg etc.),
BigMap attained higher throughput at
larger map sizes.
We attribute this behavior to the various non-deterministic
steps applied throughout the fuzzing process. As mentioned
before, we have aggregated multiple runs to reduce the
impact of randomness. Still, a fuzzing run can produce test
cases that exercise longer (or shorter) execution paths more
frequently relative to other runs.
On average, BigMap attains 0.98x, 1.4x, 4.5x, and 33.1x
higher throughput for 64kB, 256kB, 2MB, and 8MB maps,
respectively. We conclude that BigMap might not be an
attractive choice for small map size of 64kB. However, if
larger map is required (e.g., for reducing hash collisions or
to support complex coverage metrics), then BigMap clearly
provides superior test generation throughput.
2) Impact on Edge Coverage and Unique Crashes:
Figure 7 shows the edge coverage with map size increase.
During a fuzzing campaign, the rate of discovering new
edges is initially high and then ﬂattens out as time pro-
gresses. Our results indicate that BigMap reached the plateau
for all of the benchmarks within the 24 hour time budget.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
538
otherwise (e.g., longer runs or multiple instances with co-
operative fuzzing). Finding the optimal map size is less of
an issue for BigMap as we can choose an arbitrarily large
map size with little runtime penalty. This adaptive nature of
BigMap makes it an attractive choice.
C. Evaluating Coverage Metric Composition
Previously we mentioned how BigMap’s efﬁciency with
large maps enables an aggressive composition of multiple
coverage metrics. In this section, we investigate one such
scenario by stacking laf-intel [11] and N-gram [12]. Because
the original AFL does not have in-built support for laf-intel
and N-gram, we implemented BigMap on a community-
maintained version of AFL called AFLPlusPlus [23]. We
used all the LLVM fuzzing harnesses available on OSS-
Fuzz as benchmarks. The laf-intel transforms each multi-
byte comparison into a series of single-byte comparisons.
The switch statements and strcmp/memcmp functions are
also deconstructed into multiple if-else statements. With laf-
intel applied, the resulting LLVM-opt has around 5.5 million
static edges. N-gram does not increase the number of static
edges but provides a more thorough coverage metric. Unlike
AFL’s default edge coverage with (src block, dst block)
tuple, N-gram gets partial path coverage by hashing the
last N blocks. We choose N = 3 (i.e., the hash of the
last three blocks) for this experiment. With stacked laf-intel
and N-gram applied, the covered edges vary between 212k
- 603k (∼87% collision rate). While laf-intel and N-gram
independently showed improvement in terms of edge/crash
coverage in small benchmarks, they were not applied to
such large benchmarks previously due to excessive hash
collisions. To our knowledge, this is the ﬁrst time the com-
bination of laf-intel and N-gram is applied to benchmarks
of this scale. Also, note that the purpose of this experiment
is not to scrutinize the effectiveness of the N-gram or laf-
intel themselves, rather show that BigMap can effortlessly
Table III: Code Coverage with laf-Intel and N-gram
Collision rate
Edge coverage
Unique crash
64kB
2MB
64kB
2MB
64kB 2MB
Benchmark
(with n-gram
& laf-intel)
loop-unswitch
sccp
earlycase
loop-prediction
loop-rotate
irce
licm
gvn
simplifycfg
strength-reduce
indvars
loop-vectorize
instcombine
70.6
71.1
75.3
75.8
76.2
77.0
78.5
79.0
79.1
83.1
84.0
87.2
86.9
4.9
5.2
5.8
6.2
6.2
6.0
7.1
7.3
7.4
8.4
9.3
11.2
13.1
214,437
218,473
260,008
265,740
271,383
281,479
301,490
309,262
311,143
387,462
409,555
512,991
588,397
211,697
226,084
255,295
270,806
269,534
262,675
312,943
324,302
325,526
373,813
414,217
510,469
602,669
276
261
279
202
276
226
284
295
285
250
271
233
295
264
325
324
382
265
384
245
433
367
412
307
342
362
434
352
Map sizes: 64k – 256k – 2M – 8M
Figure 7: Edge coverage with varying map sizes. AFL’s edge
coverage suffers due to throughput loss with bigger maps.
Not all benchmarks are shown to improve clarity.
Map sizes: 64k - 256k - 2M - 8M
Figure 8: Unique crashes found with varying map sizes.
Going from 64kB to 256kB map shows improvement as a
result of reduced collisions. AFL suffers for bigger map sizes
due to throughput loss.
AFL performed identically for small benchmarks. However,
AFL’s low throughput on bigger maps prevented it from
reaching the plateau for benchmarks with a higher num-
ber of discoverable edges. Note that mitigating the hash
collision was not particularly beneﬁcial at improving the
edge coverage. A public report available on FuzzBench
indicates that the metric edge coverage has a relatively small
variance across a wide range of fuzzers [22]. Furthermore,
AFL authors noted that edge count bucketing provides some
protection against collisions [13]. We hypothesize that the
inherent small variance and the binning process made the
edge coverage relatively insensitive to collisions.
Crashes, on the other hand, are extremely sparse and do
not follow any simple pattern. We were able to ﬁnd crashes
on the bloaty and the LLVM benchmarks. For bloaty, we
found one unique crash on all conﬁgurations except for AFL
8MB. The number of unique crashes found on the LLVM
benchmarks is given in Figure 8. From this ﬁgure, it is
evident that AFL performed its best with a 256kB map.
The smaller 64kB map prevented ﬁnding more crashes due
to collisions, while larger maps of 2MB and 8MB caused
excessive runtime overhead, leading to low crash coverage.
Interestingly, the optimal map size is unknown beforehand
and may vary with the target application. Therefore, to ﬁnd
the most crashes, AFL has to run the target application
with different map sizes (or have access to an oracle).
However,
testing with multiple map sizes will consume
valuable compute time that may have been better utilized
AVERAGE
78.8% 7.5% 333,217
335,387
539
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
support such combinations with high map pressure. Similar
to the setup of Section V-B, we took an average of three runs
to reduce the variation caused by random mutation steps.
The results of the experiment are shown in Table III.
Here, both the 64kB and 2MB version employs BigMap.
By mitigating collision with a bigger map,
the unique
crashes found improved by 33% on average. However, the
edge coverage remained unaffected, similar to what we
observed in our previous experiment. We conclude that for
large applications and/or when applying extensive coverage
metrics, crash coverage can beneﬁt from collision mitigation.
D. Evaluating the Scalability with Parallel Fuzzing
Every fuzzing instance uses one CPU core. As a result,
a system with n physical cores can run n concurrent
fuzzing instances with virtually little performance penalty
(assuming there is minimal contention for other system
resources) while gaining about n times more throughput.
This linear scaling property is achievable by programs with