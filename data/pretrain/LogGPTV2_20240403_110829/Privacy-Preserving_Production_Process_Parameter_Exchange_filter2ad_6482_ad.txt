the bandwidth asynchronously (labels correspond to server-client
speed). The client-server link is restricted to 1/10 to mimic common
broadband connections. Both latency and reduced bandwidth add a
factor to the overhead of additional OTs. However, even for a large
latency of 300 ms, 100 OT extensions are executed in ‚âà6 minutes.
Similarly, a severely constrained bandwidth (6 MBit/s) adds only
30 min overhead. While the data provision is not time-critical, sev-
eral days for client requests are acceptable (cf. injection molding).
Thus, we can tolerate slow Internet links with significant latency.
OT protocols balance the trade-off between computation and
communication overhead differently [2]. Hence, the underlying OT
protocol can be selected based on use case-specific needs.
Similarity Metrics. The matching phase of BPE is driven by
7.2.3
the number of elements that the similarity metric ùë†(ùëû) returns as
each element must be tested for membership in the Bloom filter.
Even today, membership tests are time-consuming if the candidate
set ùëÜ grows very large. A usable metric for transfer learning in
injection molding is able to evaluate the similarity of two processes,
hence, how data from a different process can substitute missing
training data of the process, which must be modeled. Today, sensible
real-world metrics are still being actively researched [38, 82].
The number of elements further depends on the exact representa-
tion of parameters. For example, a fine-granular rounding results in
more values for the same interval of potentially interesting records.
An increase of the granularity of one parameter (ùë•‚Ä≤
ùëñ ) yields a linear
increase of candidates while a granularity increase for all input
parameters (ùë•‚Ä≤
ùëõ) results in an exponential blow-up of the can-
didate set ùëÜ. The number of input parameters ùëõ is further influential
because ùëÜ grows exponential in the number of varied parameters.
Given that the similarity metric ùë†(ùëû) is solely computed at the
client, its performance does not impact the other parts of our design.
to ùë•‚Ä≤
1
7.3 Combined Performance of BPE
We now combine the individual building blocks and look at the
overall performance of each phase. We treat the data providers (data
provision) and clients (matching and record retrieval) separately.
Data Provision. Figure 7 details the runtime when offloading
up to 1000 records and shows that the provision scales linearly with
Figure 8: The local computation of complex similarity met-
rics by the client dominates the retrieval of data records.
the number of records. Here, we used records with 100 parameters,
each representing a float chosen uniform at random. Accordingly,
all records have unique identifiers and require a unique key for en-
cryption. The key retrieval dominates this phase. The length of the
records only marginally influences the runtime (cf. Appendix B.3).
Matching and Record Retrieval. In contrast to the data pro-
vision, client requests can be time-critical and are use case-specific.
We offloaded records with 100 parameters and use 10 parameters
as input for the indexing (ùëõ = 10, ùëö = 90). Each input parameter is
discretized to three digits. As similarity metric ùë†(ùëû), we computed
an offset of 0.5 % for each input record ùëû. We ensured that sufficient
records are matched and available that the storage server. While
OTs mainly impact the provision, Figure 8 shows that the matching
dominates the client queries. Despite the good performance of
Bloom filters (cf. Section 7.2.1), the matching is expensive as it
results in a large candidate set ùëÜ of >29 Mio. elements. While we
observe a runtime below 5 min, real-world metrics might produce
sets that are magnitudes larger, further increasing the runtime.
Given that several days for client requests are feasible (cf. injection
molding), metrics with excessive candidate sets are possible as well.
Besides, testing for membership is embarrassingly parallelizable and
does not depend on external entities. Accordingly, clients can scale their
metrics to their constraints, i.e., time and computational resources.
7.4 Real-World Performance Measurements
To test the real-world applicability of our scenario (cf. Section 2),
we now operate on a total of 4620 genuine records, consisting of
28 parameters each. They describe the production of toy bricks.
For the optimization of the IM-machine settings during process
setup, each toy brick is defined by ùëö = 21 geometry parameters,
while the remaining ùëõ = 7 parameters describe 6 essential machine
settings (injection volume flow, melt temperature, mold tempera-
ture, packing pressure, packing pressure time, cooling time) and
one quality indicator (part weight). For other use cases than the
optimization of IM-machine settings during the process setup, the
data and its representation may differ. Here, sensitive information
is represented by the machine settings and the corresponding part
quality: Only combined with the identifying parameters, i.e., geom-
etry information, the data can be used for transfer learning. With
this indexing, we have a total of 60 indices, where each index points
to 77 unique records that contain varied machine parameters.
Data Provision. The entire provision takes less than 12 s (cf.
Appendix B.3) and is comparable to our previous experiment (cf.
Figure 7). Thus, even orders of magnitude more records are feasible.
Matching and Record Retrieval. We evaluated two poten-
tially used metrics to look into client queries. For metric IM-2%, we
11002003004005006007008009001000Uploads [#]0102030405060Time [s]Hash Key Retrieval (R.)Key R. (OT)OT TLSEncryptionSending01002003004005006007008009001000Results [#]0100200300400Time [s]|S|29 Mio.Hash Key R.Bloom R.MatchingKey R. (OT)OT TLSRecord R.DecryptionPrivacy-Preserving Production Process Parameter Exchange
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Figure 9: The larger candidate set produced by IM-2.5% leads
to a dominating matching phase for the full client request.
used a relative offset for all (21) input parameters of 2 % and for
IM-2.5%, a relative offset of 2.5 %. The rounding is set to two digits
for each input parameter. In our example, both metrics resulted in
a single match, i.e., the client retrieves the records corresponding
to a single index. As visualized in Figure 9, the matching quickly
dominates client queries, rendering the remaining steps negligible.
We again underline that the locally conducted membership tests
are the crucial factor. Keeping the use case-induced time constraints
(of several days) in mind, even metrics with significantly larger can-
didate sets can be supported. In conjunction with the virtually
irrelevant performance of offloading records, we thus conclude
that the performance of BPE is well-suited for a privacy-preserving
exchange of parameters in the domain of injection molding. There-
fore, it could greatly support the application and implementation
of transfer learning for the highly complex task of process setups.
To conclude, we showcased that BPE can handle client requests with
a large candidate set in a real-world setting. The one-time required
provision is negligible for the performance of BPE. Our client-sided
computation easily enables complex similarity metrics in the future.
7.5 Universally Applied Parameter Exchange
To showcase the applicability of our proposed exchange platform,
we now look into a second real-world use case, i.e., machine tools.
7.5.1 A Parameter Exchange for Machine Tools. For subtractive
manufacturing (turning and milling), major factors that affect the
workpiece quality and productivity are the machine tools and the
choice of the cutting parameters, such as cutting speed, feed rate,
and cutting depths. Traditionally, cutting parameters are deter-
mined based on experience or manufacturer-specific recommen-
dations. In a lengthy process, the machine operator starts with a
conservative value and then tunes the parameter through real tests.
While this approach yields acceptable results, it is time-consuming.
Thus, optimization methods are actively being researched [12,
26, 46]. Particle swarm optimization promises to obtain optimal
cutting parameters for certain requirements, such as roughness
and tool lifetime [46]. A model-based approach integrating real-
time process data actively combines quality measurement data [12].
Thereby, the potential for optimization of the cutting process can be
estimated, resulting in improved productivity. Similarly, Denkena
et al. [26] apply machine learning to determine the optimal cutting
parameters under consideration of the process outcome.
However, all optimization methods require detailed modeling of
the machining process and the machine tool, which is difficult and
not always feasible. Meanwhile, other companies may already have
optimized cutting parameters, ready for a parameter exchange.
Figure 10: Both metrics produce negligible overhead for the
matching. For these sizes, both BPE and PPE are feasible.
7.5.2 Evaluation. Here, we rely on a dataset with 600 records with
19 parameters each (ùëõ = 17, ùëö = 2). Each record has a unique index.
Data Provision. Offloading all records is completed within 30 s
and, therefore, uncritical for any real setting and its providers.
Matching and Record Retrieval. For this second use case, we
evaluate two different client queries. First, for MT-Material, we only
vary the production material of a workpiece, i.e., the client wants to
produce an identical workpiece with another material. Second, for
MT-Diameter, we request parameters where the same workpiece
should be produced with a different milling cutter. To this end, we
iterate over the input defining the milling cutter‚Äôs diameter.
We detail the processing times for both metrics in Figure 10 (incl.
times of our PPE design variant, which we specifically elaborate on
in Section 8.2). Even though this use case does not impose any hard
time constraints, concluding the client query after less than 1 min
is a fitting result. Given that we only vary a single input parameter
for each metric, the resulting candidate set is tiny compared to the
evaluated injection molding metrics. Thus, the (large) Bloom filter
and the key retrieval dominate the runtime of these client requests.
Here, we showed the further applicability of BPE on a second real-
world use-case, i.e., BPE also handles simple metrics efficiently.
8 PRACTICAL PRIVACY IMPROVEMENTS
In this section, we discuss the privacy provided by our BPE design.
Based on our findings in Section 8.1, we then propose two variants
that further improve provider and client privacy (G1 and G2).
8.1 Security Discussion
Given that we only operate with well-known and authenticated
entities, i.e., registered companies under known jurisdictions (cf.
Section 6.1), we focus on a semi-honest setting, i.e., we assume that
all entities follow the specified protocol as deviations are prosecuted.
Consequentially, we do not have to rely on more complex building
blocks, such as secret sharing [74], for our parameter exchange as
suitable (semi-trusted) operators are available in industrial settings.
The security goals of the design are twofold. First, provider
privacy (G1), i.e., protecting uploaded data records, and second,
client privacy (G2), i.e., hiding all queries, need to be considered.
Key Server. As all sensitive key retrievals are handled via OT,
the key server cannot harm provider and client privacy. While
colluding with data providers does not harm the client privacy,
colluding with the client could harm the provider privacy if cipher-
texts are retrieved illegitimately. A collusion of the operators of
key and storage servers is the main threat in our design as it can
result in plaintext access, violating both provider and client privacy.
However, we envision a storage server operator with a significant
60006500Time [s]IM-2%IM-2.5%TLSHash Key R.Bloom R.MatchingKey R. (OT)Record R.DecryptionPhase0102030|S|1 Mio.|S|143 Mio.Hash Key R.Bloom R.MatchingPSI Prep.PSI Exec.Key R. (OT)Record R.DecryptionPhase051015202530Time [s]|S|=11|S|=11|S|=701|S|=701Standard BPEPSI-based PPE(Section 8.2)MT-MaterialMT-DiameterTLSACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Pennekamp et al.
Figure 11: In settings where our more secure PSI variant PPE
is applicable, it achieves comparable performance to BPE.
reputation (cf. Section 6.1) not willing to risk legal punishment.
Thus, we expect that this kind of misbehavior is unlikely.
Storage Server. As discussed in Section 5.3, BPE does not hide
the indices of client-requested records. Thus, it allows the storage
server to partially reconstruct the client‚Äôs candidate set, slightly
violating G2. However, inferring the similarity metric is infeasible
as neither the metric‚Äôs input nor the unmatched indices are known
to the server. Moreover, handing out the Bloom filter is a prob-
lematic step for provider privacy as the client obtains an encoded
representation of the available records. While Bloom filters do not
allow the retrieval of all stored items directly, brute-force attacks
could provide rough estimates, especially with a low FP rate. We
tolerate this slight violation of G1 to enable the local computation
of client metrics even in huge settings (up to billions of elements).
By using a hash key for indices computation, which is unknown
to the storage server, we increase both provider and client privacy
as the storage server cannot compute any index itself even if it is
aware of suitable input parameters. We achieve provider privacy as
requested records are only shared without their origins against a
payment. Similarly, providers are unaware of who paid for a record,
satisfying client privacy. In the case of unintended data leaks, we
protect records by utilizing different encryption keys to render
brute-force attacks infeasible. Other misbehavior can by retraced
through access logs at both key and storage servers. We leave an
analysis of the implications of joining these logs for future work.
To summarize, the security foundations of BPE build on the sepa-
ration of key material and ciphertexts. To ensure client privacy, the
storage server may not collude with data providers either. To fur-
ther improve provider and client privacy at the expense of additional
overhead, we take a look at possible design variants in the following.
8.2 Design Variants
To achieve adaptability (G5), we propose two variants to improve
the privacy for settings where BPE is currently insufficient. We
evaluate a variant with PSIs, which improves provider privacy. We
further design a fully OT-based concept for enhanced client privacy.
8.2.1 PPE: A PSI-based Approach. To prevent potential informa-
tion leaks through the Bloom filter, i.e., a list indicating all available
indicies shared with every client, we also propose a design variant
that replaces the Bloom filter-based matching with a PSI (cf. Appen-
dix C.1). By using PSIs, clients only learn the matching elements
and cannot brute force the complete set of all available records.
However, due to the limited supported size of the candidate
set ùëÜ in PPE, we favor BPE over PPE despite its weaker provider
privacy. In settings, with specific privacy needs and comparable
small candidate sets, PPE can be a suitable, more secure alternative.
PPE Performance. We repeated the setting from Section 7.3
with a PPE-feasible sized candidate set ùëÜ through a relative offset of
0.3 % with only 0.3 Mio. elements (compared to 29 Mio. elements).
Figure 11 visualizes the performance results and compares them
to BPE. By design, only the matching phases differ and in this
setting, the PSI introduces slight overhead when compared to BPE.
In Appendix C.2, we detail the linear influences of set size, latency,
and bandwidth on the PSI performance in a building block analysis.
We also evaluate IM-2% in Appendix C.3 showing a larger PSI
overhead. Moreover, we measured our second use case (cf. Sec-
tion 7.5.1) with PPE as its small candidate sets are well-suited.
Figure 10 shows a comparison of BPE and PPE for both metrics. In
this use case, the download of the large Bloom filter even outweighs
the PSI execution time, such that PPE results in a shorter runtime.