regarding their types
Fig. 5. Cumulative ratio of domains regard-
ing their score
answered with a NOERROR status DNS response containing always the same IP ad-
dress. This technique is useful to tolerate Internet users typing mistakes, or mis-
spelling of subdomain without any consequence. For instance, DNS requests for
domain such as wwe.yahoo.com, snt.yahoo.com or anyotherlabel.yahoo.com
will return the same IP address. However some TLDs such as .ws, .tk, .us.com,
etc. apply also wildcarding. As a result these TLDs have been identiﬁed in order
to discard all generated two-level-domains that contain one of them. We can see
that these domains represent between 75% and 85% (from 60,000 to 90,000) of
the domains discovered.
The remaining part is composed of two other categories. First some do-
mains are registered but lead to websites of domain name resellers such as Go-
Daddy or Future Media Architect. A lot of meaningful domain names belong
to this category, around 4,000 per campaign. Some examples of such domains
are freecolours.com or westeurope.com. Regarding a probing campaign, the
IP addresses obtained through DNS responses are stored and sorted by their
number of occurrences. The IP addresses having more than ﬁfty occurrences
are manually checked to see if they are either related to real hosting or domain
selling. Around ﬁfty IP addresses and ranges have been identiﬁed as leading to
domain name resellers. These domains are also discarded in our study, as they
are not likely to be malicious domains. Finally the black part represents the
domains that are unknown and have to be checked to conﬁrm if they are related
to phishing or not. As highlighted in Figure 4, the remaining potential malicious
domains represent only between 15,000 and 20,000 domains out from one million
of generated ones. This reduction is automated and allows discarding a lot of
domain names, which will reduce the overhead of the checking process.
14
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
For domains of the unknown part that are known to be really legitimate or
phishing, a score, M Cscore, is calculated. This latter measures the similitude
with the underlying training dataset, which have been used for building the
model. Assuming a two-level-domain w1w2 . . . wn.tld where wi is the ith word
composing the name, wi may have been generated using DISCO from an original
word observed w′
i. M Cscore is computed as follows:
n
M Cscore = distf irstword2,w′
1
×simw1,w′
1
×
distbiwords2,wi,w′
i+1
×simwi+1,w′
i+1
Yi=1
(10)
The ﬁrst word probability is multiplied by each probability of crossed tran-
sition in the Markov chain. If some parts are found using DISCO, the similarity
score given in equation (7) is used (simwi,wi = 1 else).
Figure 5 represents the cumulative sums of the ratio of domains (in %) that
have a score lower than x for each kind of label. These curves show that globally
phishing related domain names have a higher M Cscore than legitimate ones,
around ten times higher. Even if a high number of domains are labeled as un-
known and some of them are legitimate, it is easy to discard a lot of them in
order to keep a set containing a main part of malicious domains. If we consider
as malicious only the generated domains having a M Cscore higher than 0.001,
then 93% of the legitimate domains will be discarded while 57% of the malicious
domains will be kept. This technique can be used to avoid the use of a domain
checking technique, as introduced in 2.1, or to reduce its workload.
4.3 Eﬃciency and steadiness of generation
This section assesses the variation of the eﬃciency of the malicious domain
discovery regarding the ratio of domains in the testing set and in the training
set. Five probing campaigns are performed with a ratio that varies from 10%
training/90% testing (10/90) to 90% training/10% testing (90/10), the subsets
are randomly made up. Figure 6(a) shows the number of malicious domains
generated regarding the total number of probed names.
On one hand the best result is given by 30% training/70% testing with a total
number of 508 phishing domains discovered. When the testing set size decreases,
there are less domain names candidates that can be found, which implies that
more domains are discovered with 30/70 than 90/10. On the other hand, the
curve representing 10% training/90% testing grows faster, and after only 100,000
probes more than the half (217 domains) of the total number of phishing domains
generated are found. Following the curve’s trend, if more probes are performed, a
reasonable assumption is that more malicious domain names can be discovered.
Figure 6(b) depicts the steadiness of the discovery results. Five probing cam-
paigns are performed for the ratio that yields the best result: 30% training/70%
testing. The training and testing sets are randomly made up and are diﬀerent for
each campaign. Observations are similar for every tests which lead to discover
around 500 phishing domains. Moreover, half of the discovered phishing domains
Proactive Discovery of Phishing Related Domain Names
15
s
e
m
a
n
n
i
a
m
o
d
s
u
o
i
c
i
l
a
m
f
o
#
700
600
500
400
300
200
100
0
0
10/90
30/70
50/50
70/30
90/10
2
0
4
0
6
0
0
0
0
0
0
0
0
0
0
0
0
0
8
0
0
0
0
0
1
e
+
0
6
s
e
m
a
n
n
i
a
m
o
d
s
u
o
i
c
i
l
a
m
f
o
#
600
500
400
300
200
100
0
0
test1
test2
test3
test4
test5
2
0
0
0
4
0
0
0
6
0
0
0
8
0
0
0
0
0
0
0
0
0
0
0
1
e
+
0
6
# of generated domain names
# of generated domain names
(a) Variation of testing/training set ratio
(b) 5 probing campaigns with 30% train-
ing & 70% testing
Fig. 6. Number of domains discovered regarding the number of probes
are generated during the ﬁrst 200,000 generations, highlighting the ability of our
system to generate the most likely malicious domains in priority before being
discarded for next probes.
4.4 Predictability
This experiment evaluates the time between the date when a malicious domain
name can be generated using the generator and the date it is actually blacklisted.
The training set is composed of the 10% oldest blacklisted domains and the
remaining 90% belong to the testing set. The testing set represent 34 months of
blacklisted domains and the training set 4 months. Figure 7 depicts the number
of malicious domain names generated regarding the number of months they are
actually blacklisted after their generation (m+x). A large quantity of generated
malicious domains appears in ﬁrst four months after their generation, 14 in
the two following months and 23 more in the next two months. This shows
that domain name composition follows fashion schemes because more malicious
domains that are discovered appear just after the ones that are used to train the
model. However, it is worth noting that such domains continue to be discovered
in the present showing that even old datasets can be useful to generate relevant
malicious domains
4.5 Strategy evaluation
We have described in section 2 the two core building blocks for generating do-
main names: the Markov chain model and the semantic exploration module. The
impact of each module is assessed with respect to four strategies:
• MC: the Markov chain model alone.
• MC + 5 DISCO: the Markov chain model and for each selected state of the
Markov chain the ﬁve most related words, regarding DISCO, are tested.
16
Samuel Marchal, J´erˆome Fran¸cois, Radu State, and Thomas Engel
s
e
m
a
n
n
i
a
m
o
d
s
u
o
i
c
i
l
a
m
f
o
#
25
20
15
10
5
0
s
e
m
a
n
n
i
a
m
o
d
s
u
o
i
c
i
l
a
m
f
o
#
400
350
300
250
200
150
100
50
0
0
MC
MC + 5 Disco
MC + 5/20 Disco
MC + 5/50 Disco
2
0
0