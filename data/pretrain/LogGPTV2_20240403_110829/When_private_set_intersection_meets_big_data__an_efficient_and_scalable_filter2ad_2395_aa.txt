title:When private set intersection meets big data: an efficient and scalable
protocol
author:Changyu Dong and
Liqun Chen and
Zikai Wen
When Private Set Intersection Meets Big Data:
An Efﬁcient and Scalable Protocol
Changyu Dong
Dept. of Computer and
Information Sciences
University of Strathclyde
Glasgow, UK
PI:EMAIL
Liqun Chen
Hewlett-Packard Laboratories
Bristol, UK
PI:EMAIL
Zikai Wen
Dept. of Computer and
Information Sciences
University of Strathclyde
Glasgow, UK
PI:EMAIL
ABSTRACT
Large scale data processing brings new challenges to the design of
privacy-preserving protocols: how to meet the increasing require-
ments of speed and throughput of modern applications, and how to
scale up smoothly when data being protected is big. Efﬁciency and
scalability become critical criteria for privacy preserving protocols
in the age of Big Data. In this paper, we present a new Private Set
Intersection (PSI) protocol that is extremely efﬁcient and highly
scalable compared with existing protocols. The protocol is based
on a novel approach that we call oblivious Bloom intersection. It
has linear complexity and relies mostly on efﬁcient symmetric key
operations. It has high scalability due to the fact that most opera-
tions can be parallelized easily. The protocol has two versions: a
basic protocol and an enhanced protocol, the security of the two
variants is analyzed and proved in the semi-honest model and the
malicious model respectively. A prototype of the basic protocol
has been built. We report the result of performance evaluation and
compare it against the two previously fastest PSI protocols. Our
protocol is orders of magnitude faster than these two protocols. To
compute the intersection of two million-element sets, our protocol
needs only 41 seconds (80-bit security) and 339 seconds (256-bit
security) on moderate hardware in parallel mode.
Categories and Subject Descriptors
D.4.6 [OPERATING SYSTEMS]: Security and Protection—Cryp-
tographic controls
Keywords
Private Set Intersection; Bloom Filters
1.
INTRODUCTION
In many countries, protecting data privacy is no longer optional
but a legal obligation. Legislation includes various US privacy laws
(HIPAA, COPPA, GLB, FRC, etc.), European Union Data Protec-
tion Directive, and more speciﬁc national privacy regulations. It
is a challenging task for organizations because they have to pro-
tect data in use and transmission. To this end, many security so-
lutions have been proposed to enable privacy-preserving data pro-
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516701.
cessing. The amount of data to be processed and protected becomes
increasingly large. For example, geneticists need to search 3 bil-
lion base pairs in personal genome to ﬁnd genetic disorders that
might cause diabetes or cancers, epidemiologists need to link mul-
tiple medical databases that contain millions of patients’ records to
identify risk factors for diseases, and online retailers want to cor-
relate petabytes of their transaction records with customers’ social
network activities, hoping to increase customer satisfaction. Any
privacy-preserving data processing service is not cost free and this
has brought us new challenges: how to meet the increasing require-
ments of speed and throughput of modern applications, and how
to scale up smoothly when data being protected is big? With the
prevalence of large scale data processing, efﬁciency and scalability
become critical criteria for designing a privacy-preserving protocol
in the age of “Big Data”.
The subject of study in this paper is the Private Set Intersection
(PSI) problem. Namely, two parties, a client and a server, want to
jointly compute the intersection of their private input sets in a man-
ner that at the end the client learns the intersection and the server
learns nothing. The PSI problem has been extensively studied for
two reasons, ﬁrstly set intersection is a foundational primitive and
secondly it has many practical applications. For example, PSI has
been proposed as a building block in applications such as privacy
preserving data mining [4], human genome research [6], homeland
security [16], Botnet detection [33], social networks [32], location
sharing [35] and cheater detection in online games [11]. Many PSI
protocols have been proposed, e.g. [21, 30, 23, 13, 24, 27, 12, 16,
15, 28, 5, 25]. PSI protocols are often criticized as being impracti-
cal because the performance becomes unacceptable when the input
size or the security parameter becomes large, and it is difﬁcult to
improve the performance by just adding hardware proportionally.
The criticism is not unfounded. Currently two protocols claim to
be the fastest PSI protocol: the RSA-OPRF-based protocol by De
Cristofaro et al [16, 17] and the garbled circuit protocol by Huang
et al [25]. Both protocols have a highly optimized implementation.
We obtained the source code from the authors of these two proto-
cols and tested the performance. To compute the intersection of
two 1,048,576-element (220) sets, De Cristofaro’s protocol needs
10.6 minutes at 80-bit security, but requires a much longer time
at 256-bit security. We estimate the time to be approximately 131
hours from tests with smaller sets. The tests with million-element
sets on Huang’s protocol were unsuccessful because the Java Vir-
tual Machine ran out of memory on the client computer that has 16
GB RAM. From tests with smaller sets, we estimate that Huang’s
protocol requires 27 hours and 51 hours respectively to compute
the intersection at 80-bit and 256-bit security. Clearly to use PSI in
real world applications, we need more practical protocols.
Contributions We present a new PSI protocol that is much more
789efﬁcient than all the already existing PSI protocols. The protocol is
designed based on a novel two-party computation approach, which
makes use of a new variant of Bloom ﬁlters that we call garbled
Bloom ﬁlters, and we refer the new approach as oblivious Bloom in-
tersection. The ideas of garbled Bloom ﬁlters and oblivious Bloom
intersection are general and have their own interests.
Our PSI protocol has two versions: a basic protocol, security of
which can be proved in the semi-honest model, and an enhanced
protocol, security of which can be proved in the malicious model.
The basic protocol has linear complexity (with a small constant fac-
tor) and relies mostly on symmetric key operations. It is fast even
with large input sets, and when the security parameter increases,
the performance degrades gracefully. Test results show it is orders
of magnitude faster than the previous best protocols. The enhanced
protocol is an extension of the basic protocol, that only increases
the cost by a factor proportional to the security parameter.
Apart from efﬁciency, another big advantage of the protocol is
scalability: the computational, memory and communication com-
plexities are all linear in the size of the input sets. More attractively,
most operations in the protocol can be performed in the SPMD
(single program, multiple data) fashion, which means little effort
is required to separate the computation into a number of parallel
tasks. Therefore it can fully take the advantage of parallel pro-
cessing capacity provided by current multi-core CPUs, GPGPUs
(General-purpose graphics processing unit) and cloud computing.
As a result, the protocol is particularly suitable for Big Data ori-
ented applications that have to process data in a parallelized and/or
distributed way.
We have implemented a proof of concept prototype of the basic
protocol. To compute the intersection of two million-element sets,
it needs only 41 seconds (80-bit) and 5.65 minutes (256-bit) on two
moderate computers in parallel mode.
Organization The paper is organized as follows: in section 2, we
review the related work, in section 3 we introduce the notation and
building blocks; in section 4, we present the garbled Bloom ﬁlter
data structure, the semi-honest protocol, analyze the security and
provide a simulation-based proof; in section 5 we show how to
extend the basic protocol to achieve security against malicious ad-
versaries; in section 6 we show a prototype of the basic protocol
and the performance evaluation result; in section 7, we conclude
the paper.
2. RELATED WORK
The concept and ﬁrst protocol of Private Set Intersection were
introduced by Freedman et al in [21]. Their protocol is based on
oblivious polynomial evaluation. Along this line, Kissner and Song
[30] proposed protocols in multiparty settings, Dachman-Soled et
al [13], and Hazay and Nissim [24] proposed protocols which are
more efﬁcient in the presence of malicious adversaries. Hazey and
Lindell [23] proposed another approach for PSI which is based
on oblivious pseudorandom function (OPRF) evaluation. This ap-
proach is further improved by Jarecki and Liu [27, 28] and De
Cristofaro et al [16, 15]. There are also a number of variants of
PSI protocols, which aim to achieve more features than the original
PSI concept. Camenisch and Zaverucha [12] proposed a PSI pro-
tocol which requires the input sets to be signed and certiﬁed by a
trusted party, Ateniese et al [5] proposed a PSI protocol that also
hides the size of the client’s input set. Among the above protocols,
the most efﬁcient protocol is the protocol by De Cristofaro et al
It has linear complexity and requires O(n) public key
[16, 15].
operations, where n is the size of the set. The performance of this
protocol is affected signiﬁcantly by n and the security parameter.
Recently, Huang et al [25] presented a semi-honest PSI protocol
based on garble circuits. This protocol requires O(nlogn) sym-
metric key operations and a small number of public key operations.
The authors demonstrated that in certain cases this protocol is sig-
niﬁcantly more efﬁcient than the previous PSI protocols. At low
security settings, De Cristofaro’s protocol [16] is the fastest but at
high security settings, Huang’s protocol [25] is more efﬁcient.
Recently a few PSI protocols based on Bloom ﬁlters were pro-
posed. In [31], the parties AND their Bloom ﬁlters by a secure mul-
tiplication protocol and each party obtains an intersection Bloom
ﬁlter. They then query the resulting Bloom ﬁlter to obtain the inter-
section. However the protocol is not secure because the intersec-
tion Bloom ﬁlter leaks information about other party’s sets. In [29],
Bloom ﬁlters are used in conjunction with the Goldwasser Micali
homomorphic encryption.The semi-honest version of the protocol
requires kn hash operations and (k log2 e + kl + k + 2l)n modu-
lar multiplications, where k and l are parameters controlling false
positive and e is the base of natural logarithms. Our basic protocol
requires 2(k +k log2 e)n hash operations and a few hundred public
key operations (independent to n). The total number of operations
in our basic protocol is much less than the protocol in [29]. Given
that a modular multiplication is faster than a public key operation
but slower than a hash operation, for large input sets (i.e. a large
value of n), the PSI scheme in [29] would be slower than our basic
protocol. The protocol also has a higher communication overhead
than ours, as each bit in the Bloom ﬁlter and the encrypted elements
has to be expanded to a group element. The version secure in the
malicious model requires a trusted party to certify the client’s set,
thus is hard to compare fairly with our enhanced protocol.
3. PRELIMINARIES
3.1 Notation
A function µ(·) is negligible in n, or just negligible, if for ev-
ery positive polynomial p(·) and any sufﬁciently large n it holds
that µ(n) ≤ 1/p(n). A probability ensemble indexed by I is a
sequence of random variables indexed by a countable index set I.
Namely, X = {Xi}i∈I where each Xi is a random variable. Two
distribution ensembles X = {Xn}n∈N and Y = {Yn}n∈N are
c
≡ Y if for ev-
computationally indistinguishable, denoted by X
ery probabilistic polynomial-time (PPT) algorithm D, there exists
a negligible function µ(·) such that for every n ∈ N,
|P r[D(Xn, 1n) = 1] − P r[D(Yn, 1n) = 1]| ≤ µ(n)
For a set X, we denote by x r← X the process of choosing an
element x of X uniformly at random.
3.2 Bloom Filters
A Bloom ﬁlter [9] is a compact data structure for probabilis-
tic set membership testing. A Bloom ﬁlter is an array of m bits
that can represent a set S of at most n elements. A Bloom ﬁlter
comes with a set of k independent uniform hash functions H =
{h0, ..., hk−1} such that each hi maps elements to index numbers
over the range [0, m − 1] uniformly. In the rest of the paper, we use
(m, n, k, H)-Bloom ﬁlter to denote a Bloom ﬁlter parameterized
by (m, n, k, H), use BFS to denote a Bloom ﬁlter that encodes
the set S, and use BFS[i] to denote the bit at index i in BFS .
Initially, all bits in the array are set to 0. To insert an element x ∈
S into the ﬁlter, the element is hashed using the k hash functions to
get k index numbers. The bits at all these indexes in the bit array
are set to 1, i.e. set BFS[hi(x)] = 1 for 0 ≤ i ≤ k − 1. To check
if an item y is in S, y is hashed by the k hash functions, and all
790locations y hashes to are checked. If any of the bits at the locations
is 0 , y is not in S, otherwise y is probably in S.
Because the hash functions are deterministic, if y is encoded in
the ﬁlter then in the query phase every BFS[hi(y)] must be 1, so
a Bloom ﬁlter never yields a false negative. However, a false pos-
itive is possible, i.e. it is possible that y is not in the set S, but all
BFS[hi(y)] are set to 1. The probability that a particular bit in the
Bloom ﬁlter is set to 1 is p = 1 − (1 − 1/m)kn, and according to
[10], the upper bound of the false positive probability is:
ǫ = pk × (1 + O(
k
pr ln m − k ln p
m
))
(1)
which is negligible in k.
In practice we often need to build a Bloom ﬁlter with a capped
false positive probability, i.e. it represents any set of at most n ele-
ments from a universe in a manner that allows false positive proba-
bility to be at most ε. The efﬁciency of such a Bloom ﬁlter depends
on the parameters m and k. It turns out the lower bound of m in this
case is m ≥ n log2 e · log2 1/ε, where e is the base of natural loga-
rithms. The optimal number of hash functions is k = (m/n) · ln 2
and if m is also optimal then the optimal k is log2 1/ε. In the rest
of the paper, we always assume optimal k and m unless otherwise
stated.
A standard Bloom ﬁlter trick is that if we have two (m, n, k, H)-
Bloom ﬁlters that each encodes a set S1 and S2, we can obtain an-
other (m, n, k, H)-Bloom ﬁlter BFS1∩S2 by bit-wisely ANDing
BFS1 and BFS2 . The resulting Bloom ﬁlter has no false nega-
tive, which means the query result of any element y ∈ S1 ∩ S2
against BFS1∩S2 is always true. The false positive probability of
the resulting Bloom ﬁlter is no higher than either of the constituent
Bloom ﬁlter [37]. Note that due to collisions, it is possible that the
jth bit is set in BFS1 by an element in S1 − S1 ∩ S2 and jth bit is
set in BFS2 by an element in S2 − S1 ∩ S2. Therefore the resulting
Bloom ﬁlter usually contains more 1 bits than the Bloom ﬁlter built
from scratch using S1 ∩ S2.
3.3 Secret Sharing
Secret sharing is a fundamental cryptographic primitive. It al-
lows a dealer to split a secret s into n shares such that the secret
s can be recovered efﬁciently with any subset of t or more shares.
With any subset of less than t shares, the secret is unrecoverable
and the shares give no information about the secret. Such a sys-
tem is called a (t, n)-secret sharing scheme. An example of such a
scheme is Shamir’s secret sharing scheme [40].
When t = n, an efﬁcient and widely used secret sharing scheme
can be obtained by simple ⊕ (XOR) operations [39]. The scheme
works by generating n − 1 random bit strings r1, ..., rn−1 of the
same length as the secret s, and computing rn = r1⊕, ..., ⊕rn−1⊕
s. Each ri is a share of the secret. It is easy to see that s can be
recovered by computing r1⊕, ..., ⊕rn and any subset of less than
n shares reveals no information about the secret.
3.4 Oblivious Transfer
Oblivious transfer [38, 20] allows a sender to send part of its
input to a receiver in a manner that protects both parties. Namely,
the sender does not know which part the receiver receives and the
receiver does not learn any information about the other part of the