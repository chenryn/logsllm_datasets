0 .00
0 , 00
1. 00
1pidstat
[..-]
pidstat(1) shows CPU usage per process. top(1) is a popular tool for this purpose; however,
pidstat(1) provides rolling output by default so that variation over time can be seen. This output
shows that a Java process is consuming a variable amount of CPU each second; these percentages
are summed across all CPUs, so 500% is equivalent to five CPUs at 100%.
3.3.6
iostat -xz 1
iostat -xz 1
Linux 4,.13,019-genexlc
1.. -1
08/04/2018
_x85_64_
(16 CPU)
[...]
avg-cpu:
Musex
Snlce Ssysten lloxalt
1stea1
51d1e
22 . 90
0 ,00
0.82
0, 63
0.06
75 .59
Device:
rrqn/s
2/uB3A
r/ B
/s
ckB/s
xkB/s avgrq=5z avgqu=sz
axait r_avalt v_avait
svctn
Mut11
nvne0n1
0.00
1167,00
0.00 1220.00
0.00 151293,00
248.02
2 .10
1 , T2
0 . 00
1, 72
0 .21
26.00
nvme1n1
0.001164.00
0.00 1219.00
0.00 151384,00
248.37
0 . 90
0 , 74
0 . 00
0 .74
0 .19
23.60
md0
0.00
0.00
0,00 4770.00
0.00 303113,00
127,09
0 . 00
0.00
0 .00
0.00
0 .00
0 .00
[. .-]
This tool shows storage device I/O metrics. The output columns for each disk device have
line-wrapped here, making it difficult to read.
Columns to check:
•r/s, w/s, rkB/s, and wkB/s: These are the delivered reads, writes, read Kbytes, and write
Kbytes per second to the device. Use these for workload characterization. A performance
problem may simply be dlue to an excessive load having been applied.
await: The average time for the I/O in milliseconds. This is the time that the application
suffers, as it includes both time queued and time being serviced. Larger-than-expected
average times can be an indicator of device saturation or device problems.
multithreaded applications exceeding 10o%, The change was everntually reverted, but be aware in case you encounter
Jo, pgexul sem je sndpno 01 po) sN1 [9e] %oot oq sofequaaiad paddes (Tltelspd os a@ueup yuasas e jeg aon T
the changed version of pidstat(1)
---
## Page 114
3.3 Linux 60-Second Analysis
77
• avgqu-sz: The average number of requests issued to the device. Values greater than one can
be evidence of saturation (although devices, especially virtual devices that front multiple
back-end disks, typically operate on requests in parallel.)
 %util: Device utilization. This is really a busy percentage, showing the time each second
that the device was doing work. It does not show utilization in a capacity planning sense,
as devices can operate on requests in parallel. Values greater than 60% typically lead to
poor performance (which should be seen in the await column), although it depends on the
device. Values close to 100% usually indicate saturation.
The output shows a write workload of ~300 Mbytes/sec to the md0 virtual device, which looks like
it is backed by both of the nvme0 devices.
3.3.7
free -m
$ free
tota1
used
free
shared buff/cache
ava11ab1e
Men:
122872
39158
3107
1166
80607
81214
Sxap:
0
0
This shows available memory in Mbytes. Check that the available value is not near zero; it shows
how much real memory is available in the system, including in the buffer and page caches.
Having some memory in the cache improves file system performance.
3.3.8
sar -n DEV 1
5 sar -n DEV 1
Linux 4.13,019generic
1..-1
08/04/2018
_x86_64_
(16 CPU)
03:38:28 A
IFACE
rxpek/s
txpck/s
rxkB/s
t.xkB/s
rxcnp/s
txcnp/s
rxncst/s
s1futi1
03 :38 :29 A
eth0
7770.00
4444,00
10720,12
5574, 74
0.00
0.00
0 . 00
0,00
03:38:29 
1.0
24.00
24,00
19, 63
19 , 63
0 .00
0. 00
0.00
0.00
on age aq feu (tseso Ag poods se oeen s00T e aoep e aqm uoenys 9usnuo au os spe S1 Z
accept a higher workoad. It is just reporting that someting was busy 00% of the time, but it was nt 10% utilied: it
could have accepted more work, The %util reported by iostat(1) is especially misleading for volumes backed by a pool of
multiple disks, which have an increased ability to run work in parallel.
3 The output of freel(1) has changed recently It used to show bufers and cache as separate columns, and it left the
available column as an exercise for the end user to calculate. I like the newer version bettec. The separate buffers and
cached columns can be shown by using v for wide mode.
---
## Page 115
78
Chapter 3 Performance Analysis
03:38:29 M
IFACE
rxpck/s
txpck/s
rxkB/s
t.xkB/s
rxcnp/s
txcnp/s
rxncst/s
1futi1
03:38:30 A
eth0
5579.00
2175,00
7829,20
2626, 93
0.00
0.00
0. 00
0,00
03:3:30 
10
33.00
33,00
1. 79
1. 79
0.00
0.00
0.00
0,00
[...]
The sar(1) tool has many modes for different groups of metrics. Here I'm using it to look at
network device metrics. Check interface throughput rxkB/s and txkB/s to see if any limit may
have been reached.
3.3.9
sar -n TCP,ETCP 1
+ sar -n TCP,ETCP 1
Linux 4.13,019-genex1c
| - . - ]
08/04/2019
_x86_64_
(16 CPO)
03:41:01 AX
active/s passive/s
1seg/s
oseg/s
03:41:02 
1.00
1.00
348,.00
1626,00
03:41:01 A
atnptf/s
estres/s
cetre
ans/s isegert/s
5/2510
03:41:02 AK
0 .00
0.00
1 , 00
0 .00
0 , 00
03:41:02 AX
active/s passive/s
1seg/s
oseg/s
03:41:03 M
0 .00
0.00
521.00
2660,00
03:41: 02 A
atngtf/s
estres/s1
retrans/s isegerr/s
2/24510
03:41:03 AX
0.00
0. 00
0 .00
0,00
0.00
[. ..]
Now we're using sar(1) to look at TCP metrics and TCP errors. Columns to check:
 active/s: Number of locally initiated TCP connections per second (e-g., via connect0)
 passive/s: Number of remotely initiated TCP connections per second (e.g., via accept()
•retrans/s: Number of TCP retransmits per second
Active and passive connection counts are useful for workload characterization. Retransmits are a
sign of a network or remote host issue.
3.3.10
top
top - 03:44:14 up 17 days, 4:46, 1 user,  1oad average: 2.32, 2.20, 2.21
Tasks: 474 tota1,
1 running, 473 sleeping,
*paddo2 0
0 zonbie
5Cpu(s) : 29.T us, 0.4 sy, 0.0 n1, 69.7 id, 0.1 va, 0.0 hi,  0.0 si, 0.0 st
---
## Page 116
3.4 BCC Tool Checklist
79
KiB Men: 12582137+total,
3159704 free, 40109716 used, B2551960 buff/cache
K1B Svap:
0 total,
0 fxee,
0 used. 83151728 aval1 He
PID USER
PRBI
12569 xm
VIRT
02.495t 0,051t 0.018t 5 484,7 43.313276:02 java
RES
SRR S  ICPO MMEX
TIHE+ COMNAND
20
12178w
20
0 12.214g 3.107g 16540 S  4.9 2.6
553:41 Java
125312 coot
 0
0 s1.00.00:13.20 kvorker/u256:0
128697root
200
 0
0 S  0.3 0.00:02.10 kxorker/10:2
[ - - · ]
At this point you’ll have already seen many of these metrics with prior tools, but it can be
useful to double-check by finishing with the top(1) utility and browsing the system and process
summaries.
With luck, this 60-second analysis will have helped you unearth a clue or two about the perfor-
mance of your system. You can use these clues to jump to some related BPF tools for further
analysis.
3.4BCC Tool Checklist
This checklist is part of the BCC repository under docs/tutorial.md and was written by me [30]. It
provides a generic checklist of BCC tools to work through:
1. execsnoop
2. opensnoop
3. ext4slovex (or btrfs*, xfs*, zfs*)
4. b1olatency
5. biosnoop
6. cachestat
7. tcpconnect
8. tcpaccept
9. tcpretrans
10. runqlat
11. profile
These tools expose more information for new processes, opened files, file system latency, disk I/O
latency, file system cache performance, TCP connections and retransmits, scheduler latency, and
sadeqo sape[ u eap anou tu pa1aoo are AauL aesn (d
---
## Page 117
80
Chapter 3 Performance Analysis
3.4.1
execsnoop
 execsnoop
FCOMM
PID
RET ARGS
supervise
9660
 0 /xun
asT.3adn.s
9661
0/run
nkd1
9662
vreu/- d- xrpxu/va,/ 0
run
9663
0/run
[..-]
execsnoop(8) shows new process execution by printing one line of output for every execve(2)
syscall. Check for short-lived processes, as these can consume CPU resources, but may not show
up in most monitoring tools that periodically take snapshots of which processes are running.
execsnoop(8) is covered in detail in Chapter 6.
3.4.2
opensnoop
+ opensnoop
PID
COMX
FD ERR PATH
1565
redis-server
0 /groc/1565/stat
1603
snnpd
9
0 /pzoc/net/dev
1603
snnpd
1.1
0/proc/net/if_inet6
1603
snnpd
-1
2 /sys/class/net/e th0/devIce /vendor
1603
snnpd
11
0/proc/sys/net/ipv4/neigh/eth0/ret.rans_t.ime_m&
1603
snnpd
11
0/pzoc/sys/net/ipv6/ne1gh/eth0/zet.rans_t.ime_ms
1603
snnpd
1.1
0/prec/ays/net/ipv6/conf /eth0/forvarding
[..-]
opensnoop(8) prints one line of output for each open(2) syscall (and its variants), including details
of the path that was opened and whether it was successful (the *ERR* error column). Opened files
can tell you a lot about how applications work: identifying their data files, config files, and log files.
Sometimes applications can misbehave and perform poorly when they are constantly attempting to
read files that do not exist. opensnoop(8) is covered in more detail in Chapter 8.
3.4.3
ext4slower
 ext4slower
Tracing ext4 operations slover than 10 ns
06:35:01 eren
TIME
COMH
PID
T BYTES
0FF_KB
LAT (ms) FILENAME
16464R 1249
0