message set through some form of clustering.
A. Message Clustering
Note that the payload part of the message and hence the
effective message comes from debug/trace messages written by
the system developers. Such messages are usually composed
of a text string with some parameters. The parameters could
be IP addresses, memory locations in the code, or any other
generic alphanumeric strings.
Each invocation of a given message in the code may print
out in the log file as a different message, depending on the
values of the parameters in the message. One approach that
could be taken to reduce the number of unique messages in
the data set is to de-parameterize the messages and cluster
similar messages together. The simplest and most coarse(cid:173)
grained de-parameterization technique that we used in the first
round of analysis was to replace the following with generic
tokens: (a) IPlEthernet addresses, (b) memory locations, (c)
all hexadecimal digits. Once this was done, we then clustered
the messages based on Levenshtein distance [12]. This sim(cid:173)
ple combination of de-parametrization/clustering reduced the
number of unique messages to nearly 13,000 which was about
0.5% of the original message set. This is a more manageable
set of information and the ratio of the unique messages to the
total number of messages is small enough to detect possible
patterns in the logs.
Note that there is a trade-off between the granularity of
de-parameterization/clustering and the amount of information
retained. A general purpose clustering technique like the one
we used leads to a higher loss of information. However, the
size of the unique message set is reduced significantly and
becomes easier to analyze. After the first round of analysis,
custom clustering/de-parameterization techniques (determined
through domain-specific knowledge) can be applied to impor(cid:173)
tant subsets of messages to retain more information during the
analysis.
B. Message Normalization
Storing textual messages in memory during analysis is very
resource intensive and can slow down the analysis signifi(cid:173)
cantly. To avoid this problem, we normalized our message
set by assigning unique numerical identifiers to each message
in the set of all 13,000 unique messages. The techniques for
assigning identifiers to messages has been discussed in our
earlier work [13]. Henceforth, we will refer to these numerical
identifiers as message codes or just codes. We pre-processed
each of our 714 log files, such that each line of log was
converted to a timestamp and a numeric code.
Next, we discuss the analysis of these pre-processed logs
files.
V. ANALYSIS FOR LOGS WITH KNOWN FAILURES
Our study was targeted towards two types of data sets. In
the first data set of 714 logs, each log was retrieved from a
system after a crash failure and had a distinct failure marker.
These logs contained three hours of data before failure and one
hour after failure. There were different types of crash failures
in the logs and each was identified with the presence of its
corresponding message code in the log. Our analysis for these
logs was aimed towards finding a common signature across
all failures of the same type and determining if the failure can
be predicted through a build-up of messages. Note that even
though we applied our techniques to all 714 log files, results
1-4244-2398-9/08/$20.00 ©2008 IEEE
400
DSN 2008: Lim et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:35 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
from a sample set of log files presented here are enough to
showcase the validity of our techniques.
A. Frequent Itemset Mining
interval. The graph shows a steady increase in the message
frequency before the failure at the 180 minute mark. In many
cases simple visualization of the overall message frequency
graphs helped in identifying common failures across log files.
C. Individual Message Frequency Analysis
The first effort at analyzing the pre-processed logs was to
detect common pattern across log files with similar types of
failures. We wanted to find item sets that were commonly
associated with each failure code. The hope was that the pres-
ence of these item sets would predict or at least characterize
the failure. We grouped the logs based on their corresponding
failure codes and mined for frequent
group. The high support frequent
to
be codes associated with the failure and recovery process.
Our results show that frequent itemset mining was a useful
approach for categorizing failures as it indicated the set of
common messages that occurred during the failure ofa certain
type. However, it did not help in predicting failures.
item sets turned out
Taking the next step, we looked at the message frequencies
of individual codes in a log file. We wanted to find codes that
showed peculiar trends before failure. As explained before, we
focus our attention on the part of the log just before failure.
item sets within the We computed message frequencies for 1 minute intervals for
each code and plotted these for visualization. A sample graph
is shown in Figure 3(a). This is a graph of individual message
frequencies for the same log file shown in Figure 2. There
are 29 differen! message codes and except for a few dominant
codes, it is difficult to visually determine any pattern in the
other codes. We encountered similar difficulties across other
log files where the number of codes was too large to explore.
Therefore, we needed a mechanism to filter out only the
"interesting" codes.
As one may expect,
the failure and recovery messages
mostly occur just before and immediately after the failure. To
eliminate them from our prediction analysis, we cut the logs
just before failure, and perform frequent item set mining on
the shortened log. We found that codes 4514 (related to pro-
cess errors) and code 4597 (generated from the maintenance
system) were the most common codes before failure.
4514 hmm: CM_proc_err: pro= (NUM) I err= (NUM) I seq= (NUM) I da= (NUM) I • • • Slope Filter: The slope-filter was the most natural. We are
interested in identifying codes that steadily builds up towards
4597 hmm: MTCEVT ERR type= (NUM)
the failure. We simply ran a linear regression on the individual
indicators of upcoming failure as they were fairly prevalent message code frequencies and plotted only the interesting
codes across all log files. However, the results here did prompt
us to look deeper into these codes in subsequent analysis. This
is discussed further in Section V-D.
We implemented 3 types of automated filters to pick out
the codes to plot: slope, window-max, and window-rate filters.
These filters were targeted to bring out the codes that show
some form of trend or anomaly before the failure.
codes with slope higher than a specified threshold.
Unfortunately,
their presence alone did not make good
Iname= (NUM) pn=...
(a) Slow buildup of Overall Message Density
oo
~
50
100
150
Time in minutes (One minute Intervals)
Fig. 2. Overall Message Frequency Analysis
B. Overall Message Frequency Analysis
In our earlier work [13],
total message frequency (Le.
total number of message across all codes per unit
time)
was analyzed, showing some promise of information. This
technique relied on the fact that processes become more chatty
as the failure approaches, especially in the cases where there
is a slow build up of failure in the system. As an example,
Figure 2 shows the overall message frequency plotted against
time. Message frequency was obtained for each 1 minute
The slope filter captured codes 4514 and 4597. Figure 3(b)
shows the slope-filtered graph for the same log shown in
Figure 3(a). As can be seen from the graph, the number of
"interesting" codes go from 29 down to 2. The graph shows
that these two codes were largely responsible for the increased
message frequencies detected in Figure 2. This behavior of
codes 4514 and 4597 was observed in log files spanning across
a number of systems. Hence, for such systems, to do failure
prediction based on a steady build-up of log messages, we
only had to look at codes 4514 and 4597.
Window-Max and Window-Rate Filters: The other two
filters are based on the idea that there is a period of time just
before failure during which the log behaves anomalously. Here
we designate a specified window before failure as the window
of interest and call it the pre-failure window. We would like
to detect codes that had increased activity in this window.
In our analysis, we used a pre-failure window of one hour.
The window-max filter plots only the codes whose maximum
frequency in the pre-failure window is a threshold-fold higher
than the maximum frequency before the window. The rate filter
plots only the codes whose average frequency is a threshold(cid:173)
fold higher than the average frequency before the pre-failure
window.
The window-max and window-rate filters found more codes
of interest
than the slope based filters. It is worth noting
that the two window based filters had similar results. This
is due to the fact that a large number of codes only appear
1-4244-2398-9/08/$20.00 ©2008 IEEE
401
DSN 2008: Lim et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:35 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
(a) All Codes
(b) Slope-based Filter
-
-
-
-
-
-
-
c1391
c1406
c2464
c2465
c2466
c2467
c4510
c4514
c4515
c4516
c4517
c4597
c4918
c5132
c5133
c5887
c5960
c6175
c6187
c6196
c6490
c6698
c6785
c6911
c7261
c7842
c9689
c12599
c12628
0
50
100
150
Time in minutes (One minute Intervals)
0
0
('t)
0
0
N
II)
C
::::I
0
0
Q)
OJ
C'G
II)
II)
Q)
0
:E ~
0
L()
0
0
50
150
Time in minutes (One minute intervals)
100
Fig. 3. Use of Slope-based Filters reduces codes
(a) Window-Max Filter applied to whole log
(b) One hour pre-failure window
-
c1395
c1408
c1424
c1490
c1496
c1818
c2411
c2465
c4514
c4515
c4516
c4597
c4616
c5132
c5133
- - c6187
c6547
c6867
-
-
--..1-'___~_~__~~__ ~_~I'\__~~"___~',_,~_~_
0
50
150
Time in minutes (One minute intervals)