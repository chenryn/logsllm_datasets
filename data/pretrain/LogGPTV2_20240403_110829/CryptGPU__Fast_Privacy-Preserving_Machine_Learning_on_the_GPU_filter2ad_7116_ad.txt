### Evaluation and Performance Comparisons

#### End-to-End Protocol Execution Time and Communication
For each pair considered in our evaluation, we measure the end-to-end protocol execution time and the total amount of communication. 

#### Comparison with Prior Work
We compare the performance of CRYPTGPU against FALCON [6] and CRYPTFLOW [5]. To our knowledge, these are the only privacy-preserving machine learning frameworks that have demonstrated the ability to handle neural networks at the scale of AlexNet on large datasets.

Given our primary focus on the scalability of our approach, rather than on the performance of shallow networks (where GPUs may not significantly outperform optimized CPU protocols), we concentrate our comparisons with FALCON and CRYPTFLOW.

- **CRYPTFLOW**: This framework supports private inference for ResNet. We use the performance numbers reported in their paper, which also operates in a LAN environment.
- **FALCON**: This framework supports private inference and private training for LeNet, AlexNet, and VGG-16. We collect benchmarks using their provided reference implementation [43]. The FALCON system is run on three compute-optimized AWS instances (c4.8xlarge) in the Northern Virginia region. Each instance runs Ubuntu 18.04 and has 36 Xeon E5-2666 v3 (2.9 GHz) CPUs and 60 GB of RAM. The measured network bandwidth between machines is 1.16 GB/s with an average latency of 0.2 ms.

For the main benchmarks, we also measure the computational cost using PyTorch on plaintext data (with GPU acceleration).

#### Private Inference
Table I summarizes the performance of CRYPTGPU’s private inference protocol on various models and datasets described in Section IV-A. For shallow networks and small datasets (e.g., LeNet on MNIST or AlexNet on CIFAR), FALCON outperforms CRYPTGPU. However, as we scale to progressively larger datasets and deeper models (e.g., VGG-16 on Tiny ImageNet), CRYPTGPU is faster (3.7× on VGG-16). The performance on small datasets is expected; if the computation is simple, the extra parallelism provided by the GPU is unlikely to benefit. Additionally, more efficient cryptographic building blocks (which may not be "GPU-friendly") can allow a CPU-based approach to perform better.

The setting where the GPU-based approach excels is with large datasets and deeper models. For example, at the scale of ImageNet, CRYPTGPU can perform private inference over the ResNet-152 network (containing over 150 layers and over 60 million parameters) in just over 25 seconds, which is about 2.2× faster than CRYPTFLOW. For the ResNet family of networks, the running time of CRYPTGPU scales linearly with the depth of the network.

Compared to plaintext inference on the GPU, there remains a significant 1000× gap in performance, highlighting the importance of designing more GPU-friendly cryptographic primitives to bridge this gap.

#### Batch Private Inference
We can leverage GPU parallelism to process a batch of images, thereby amortizing the cost of private inference. Table II shows the time and communication needed for private inference over a batch of 64 images on the CIFAR-10 dataset. Here, the amortized cost of private inference on a single image using AlexNet drops from 0.91s to 0.017s (a 53× reduction). With VGG-16, batch processing reduces the per-image cost from 2.14s to 0.18s (a 12× reduction).

Table III shows the time and communication needed for private inference on ImageNet using the ResNet networks with a batch of 8 images. Here, we see a 1.9× reduction in the amortized per-image private inference cost for each of ResNet-50, ResNet-101, and ResNet-152. The cost reduction compared to those on the CIFAR-10 dataset (Table II) is smaller, likely due to the smaller batch sizes (8 vs. 64). Supporting larger batch sizes is possible by either using multiple GPUs or using GPUs with more available memory. Regardless of the model/input size, batch private inference allows us to amortize the cost of the private inference protocol. Communication in all cases scales linearly with the batch size.

#### Private Training
We expect GPUs to have a larger advantage in the setting of private training, similar to modern deep learning, where training is more challenging and thus more reliant on hardware acceleration. We measure the time needed for a single iteration of private backpropagation (Appendix A) on a batch size of 128 images for several dataset/model configurations and summarize our results in Table IV (together with measurements for the equivalent plaintext protocol). We only compare with FALCON because CRYPTFLOW does not support private training.

The public implementation of the FALCON system [43] does not include support for computing the cross-entropy loss function for backpropagation. However, given the gradients for the output layer, the provided implementation supports gradient computation for intermediate layers. Thus, our measurements for the FALCON system only include the cost of computing the gradients for intermediate layers, providing a lower bound on the running time of using FALCON for private training. Our system supports the full backpropagation training algorithm.

Our system achieves a considerable speedup over FALCON in multiple settings, especially with larger models and datasets. For instance, to train AlexNet on Tiny ImageNet, a single iteration of (private) backpropagation completes in 11.30s with CRYPTGPU and 6.9 minutes using FALCON. Privately training AlexNet on Tiny ImageNet (100,000 examples) would take just over a week (≈ 10 days) using CRYPTGPU, while it would take over a year (≈ 375 days) using FALCON (assuming 100 epochs over the training set).

On the larger VGG-16 network, our system is constrained by GPU memory limitations, requiring adjustments in batch size. Despite this, CRYPTGPU still outperforms FALCON, demonstrating the effectiveness of GPU acceleration in private training.