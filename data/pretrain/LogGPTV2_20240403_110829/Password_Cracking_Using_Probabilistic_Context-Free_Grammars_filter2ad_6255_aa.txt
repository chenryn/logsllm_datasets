title:Password Cracking Using Probabilistic Context-Free Grammars
author:Matt Weir and
Sudhir Aggarwal and
Breno de Medeiros and
Bill Glodek
2009 30th IEEE Symposium on Security and Privacy
Password Cracking Using Probabilistic Context-Free Grammars 
Matt Weir, Sudhir Aggarwal, Breno de Medeiros, Bill Glodek 
Department of Computer Science,  
Florida State University, Tallahassee, Florida 32306, USA 
PI:EMAIL, PI:EMAIL, PI:EMAIL, PI:EMAIL 
that  generates  password  structures 
  Abstract  —  Choosing  the  most effective word-mangling rules 
to use when performing a dictionary-based password cracking 
attack  can  be  a  difficult  task.  In  this  paper  we  discuss  a  new 
method 
in  highest 
probability order. We first automatically create a probabilistic 
context-free  grammar  based  upon  a  training  set  of  previously 
disclosed passwords. This grammar then allows us to generate 
word-mangling  rules,  and  from  them,  password  guesses  to  be 
used  in  password  cracking.  We  will  also  show  that  this 
approach  seems  to  provide  a  more  effective  way  to  crack 
passwords  as  compared  to  traditional  methods  by  testing  our 
tools  and  techniques  on  real  password  sets.    In  one  series  of 
experiments,  training  on  a  set  of  disclosed  passwords,  our 
approach was able to crack 28% to 129% more passwords than 
John  the  Ripper,  a  publicly  available  standard  password 
cracking program. 
  Index  Terms  —  Computer  security,  Data  security,  Computer 
crime 
1.  INTRODUCTION 
    Human-memorable passwords remain a common form of 
access control to data and computational resources. This is 
largely driven by the fact that human memorable passwords 
do  not  require  additional  hardware,  be  it  smartcards,  key 
fobs, or storage to hold private/public key pairs. 
   Trends  that  increase  password  resilience,  in  particular 
against  off-line  attacks, 
include  current  or  proposed 
password  hashes  that  involve  salting  or  similar  techniques 
[1].  Additionally,  users  are  often  made  to  comply  with 
stringent  password  creation  policies.  While  user  education 
efforts can improve the chances that users will choose safer 
and  more  memorable  passwords  [2],  systems  that  allow 
users to choose their own passwords are typically vulnerable 
to  space-reduction  attacks 
that  can  break  passwords 
considerably  more  easily  than  through  a  brute-force  attack 
(for a survey, see [3]).  
Manuscript received November 10, 2008.  
This work was supported in part by the U.S. National Institute of Justice 
under Grant 2006-DN-BX-K007. 
M. Weir is a PhD student in the Computer Science Department at Florida 
State University; weir@cs.fsu.edu. 
S. Aggarwal is Professor of Computer Science at Florida State University; 
sudhir@cs.fsu.edu. 
B. de Medeiros works for Google and is a courtesy professor of Computer 
Science at Florida State University; breno.demedeiros@gmail.com. 
B. Glodek graduated with an M.S. degree in Computer Science from 
Florida State University; wjglodek@gmail.com. 
   To  estimate  the  risk  of  password-guessing  attacks,  it  has 
been  proposed  that  administrators  pro-actively  attempt  to 
crack  passwords  in their systems [4]. Clearly, the accuracy 
of such estimates depends on being able to approximate the 
most efficient tools available to adversaries. Therefore, it is 
an  established  practice  among  security  researchers  to 
investigate  and  communicate  advances 
in  password-
breaking:  If  the  most  efficient  attack  is  indeed  publicly 
known,  then  at  least  legitimate  system  operators  will  not 
underestimate the risk of password compromise. Moreover, 
password  breaking  mechanisms  may  also  be  used  for  data 
recovery  purposes.  This  often  becomes  necessary  when 
important data is stored in encrypted form under a password-
wrapped  key  and  the  password  is  forgotten  or  otherwise 
unavailable.  In  this  paper  we  describe  novel  advancements 
in password-breaking attacks. 
    Some improvements in password retrieval are achieved by 
increasing  the  speed  with  which  the  attacker  can  make 
guesses, often by utilizing specialty hardware or distributed 
computing [5, 6]. While increasing the speed at which you 
can make guesses is important, our focus is to try and reduce 
the  number  of  guesses  required  to  crack  a  password,  and 
thus to optimize the time to find a password given whatever  
resources are available.  
   Our  approach  is  probabilistic,  and  incorporates  available 
information  about  the  probability  distribution  of  user 
passwords.  This  information  is  used  to  generate  password 
patterns  (which  we  call  structures)  in  order  of  decreasing 
probability. These structures can be either password guesses 
themselves or, effectively, word-mangling templates that can 
later  be  filled  in  using dictionary words.  As far as we are 
aware, our work is the first that utilizes large lists of actual 
passwords  as  training  data  to  automatically  derive  these 
structures. 
   We  use  probabilistic  context-free grammars to model the 
derivation  of  these  structures  from  a  training  set  of 
passwords.  In one series of experiments, we first trained our 
password  cracker  on  a  training  set  of  disclosed  passwords.  
We  then  tested  our  approach  on  a  different  test  set  of 
disclosed passwords and compared our results with John the 
Ripper  [11],  a  publicly  available  password  cracking 
program.  Using  several  different  dictionaries,  and  allowing 
the same number of guesses, our approach was able to crack 
28% to 129% more passwords than John the Ripper.  Other 
experiments also showed similar results. 
1081-6011/09 $25.00 © 2009 IEEE
DOI 10.1109/SP.2009.8
391
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:16:33 UTC from IEEE Xplore.  Restrictions apply. 
   By training our attacks on known passwords, this approach 
also  provides  us  a  great  deal  of  flexibility  in  tailoring  our 
attacks  since  we  automatically  generate  probability-valued 
structures from training data. For instance, we can train our 
password cracker on known Finnish passwords if our target 
is a native Finnish speaker. 
2.  BACKGROUND AND PREVIOUS WORK 
    In  off-line  password  recovery,  the  attacker  typically 
possesses only a hash of the original password. To crack it, 
the  attacker  makes  a  guess  as  to  the  value  of  the  original 
password.  The  attacker  then  hashes  that  guess  using  the 
appropriate  password-hashing  algorithm  and  compares  the 
two  hashes.  If  the  two  hashes  match,  the  attacker  has 
discovered  the  original  password,  or  in  the  case  of  a  poor 
password  hashing  algorithm,  they  at  least  have  a  password 
that will grant them access.  
    The  two  most  commonly  used  methods  to  make  these 
guesses  are  brute-force  and  dictionary  attacks.  With  brute-
force,  the  attacker  attempts  to  try  all  possible  password 
combinations. While this attack is guaranteed to recover the 
password  if  the  attacker  manages  to  brute-force  the  entire 
password  space,  it  often  is  not  feasible  due  to  time  and 
equipment  constraints.  If  no  salting  is  used,  brute-force 
attacks can be dramatically improved through the use of pre-
computation and powerful time-memory trade-off techniques 
[7, 8]. 
    The  second  main  technique  is  a  dictionary  attack.  The 
dictionary  itself  may  be  a  collection  of  word  lists  that  are 
believed  to  be  common  sources  for  users  to  choose 
mnemonic  passwords  [9].  However,  users  rarely  use 
unmodified  elements  from  such  lists  (for  instance,  because 
password  creation  policies  prevent  it),  and  instead  modify 
the words in such a way that they can still recall them easily. 
In  a  dictionary  attack,  the  attacker  tries  to  reproduce  this 
frequent  approach  to  password  choice,  processing  words 
from  an  input  dictionary  and  systematically  producing 
variants  through  the  application  of  pre-selected  mangling 
rules.  For  example,  a  word-mangling  rule  that  adds  the 
number “9” at the end of a dictionary word would create the 
guess,  “password9”,  from  the  dictionary  word  “password”. 
For  a  dictionary  attack  to  be  successful,  it  requires  the 
original word to be in the attacker’s input dictionary, and for 
the attacker to use the correct word-mangling rule. While a 
dictionary  based  attack  is  often  faster  than  brute-force  on 
average,  attackers  are  still  limited  by  the  amount  of  word-
mangling  rules  they  can  take  advantage  of  due  to  time 
constraints. Such constraints become more acute as the sizes 
of  the  input  dictionaries  grow.  In  this  case,  it  becomes 
important  to  select  rules  that  provide  a  high  degree  of 
is  especially 
true  when 
the  rules  are  used 
success  while  limiting  the  number  of  guesses  required  per 
dictionary word. 
    Choosing  the  right  word-mangling rules is crucial as the 
application of each rule results in a large number of guesses. 
This 
in 
combination. For example, adding a two-digit number to the 
end  of  a  dictionary  word  for  a  dictionary  size  of  800,000 
words [9] would result in 80,000,000 guesses. Changing the 
first letter to be both uppercase and lowercase would double 
this  figure.  Furthermore,  in  a  typical  password  retrieval 
attempt it is necessary to try many different mangling rules. 
The  crucial  question  then  becomes,  which  word-mangling 
rules should one try and in which order? 
    Narayanan and Shmatikov use Markov models to generate 
probable  passwords  that  are  phonetically  similar  to  words 
and  that  thus  may  be  candidates  for  guesses  [10].  They 
further  couple  the  Markov  model  with  a  finite  state 
automaton  to  reduce  the  search  space  and  eliminate  low 
probability  strings.    The goal of their work, however, is to 
support  rainbow-based  pre-computation  (and,  subsequently 
very fast hash inversion) by quickly finding passwords from 
dictionaries that only include linguistically likely passwords. 
They thus do not consider standard dictionary attacks.  
    Our  approach  can  be  viewed  as  an  improvement  to  the 
standard dictionary-based attack by using existing corpuses 
of leaked passwords to automatically derive word-mangling 
rules  and  then  using  these  rules  and  the  corpus  to  further 
derive  password  guesses  in  probability  order.  We  are  also 
able  to  derive  more  complex  word-mangling  rules  without 
being  overwhelmed  by 
the 
assignments of probabilities to the structures. 
large  dictionaries  due 
to 
3.  PROBABILISTIC PASSWORD CRACKING 
    Our  starting  assumption  is  that  not  all  guesses  have  the 
same  probability  of  cracking a password. For example, the 
guess  “password12”  may  be  more  probable  than  the  guess 
“P@$$W0rd!23” depending on the password creation policy 
and  user creativity. Our goal is thus to generate guesses in 
decreasing  order  of  probability  to  maximize  the  likelihood 
of cracking the target passwords within a limited number of 
guesses. 
    The  question  then  becomes,  “How  should  we  calculate 
these  probabilities?”  To  this  end,  we  have  been  analyzing 
disclosed  password  lists.  These  lists  contain  real  user 
passwords  that  were  accidentally  disclosed  to  the  public. 
Even  though  these  passwords  are  publicly  available,  we 
realize they contain personal information and thus treat them 
as confidential.  
    For  our  experiments  we  needed  to  divide  the  password 
lists up into two parts, a training corpus and a test corpus. If 
a password appears in our training corpus, we will not use it 
392
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:16:33 UTC from IEEE Xplore.  Restrictions apply. 
in  the  test  corpus.  In  the  case  of  password  lists  that  were 
disclosed in plain-text format, (i.e. prior to any hashing), we 
can choose to use the passwords in either the training or the 
test  corpuses.  If  a  list  of  password  hashes  was  instead 
disclosed, we used the entire list in the test corpus. This is 
because we have to crack the password hashes before we can 
know what the plain text words were that created them. By 
separating  the  training  and  test  corpuses  we  can  then 
compare  the  effectiveness  of  our  probabilistic  password 
cracking  with  other  publicly  available  password  cracking 
attacks,  notably  John  the  Ripper  [11],  by  comparing  their 
results on the test sets. 
3.1  PREPROCESSING 
    In the preprocessing phase, we measure the frequencies of 
certain patterns associated to the password strings. First we 
define some terminology that is used in the rest of the paper. 
    Let  an  alpha  string  be  a  sequence  of  alphabet  symbols. 
Also let a digit string be a sequence of digits, and a special 
string  be  a  sequence  of  non-alpha  and  non-digit  symbols. 
When parsing the training set, we denote alpha strings as L, 
digit strings as D, and special strings as S. For example the 
password “$password123” would define the simple structure 
SLD.  The  base  structure  is  defined  similarly  but  also 
captures  the  length  of  the  observed  substrings.  In  the 
example  this  would  be  S1L8D3.  See  Table  3.1.1  and  Table 
3.1.2.    Note  that  the  character  set  for  alpha  strings  can  be 
language  dependent  and  that  we  currently  do  not  make  a 
distinction between upper case and lower case. 
    The first preprocessing step is to automatically derive all 
the  observed  base  structures  of  all  the  passwords  in  the 
training set and their associated probabilities of occurrence. 
TABLE 3.1.1 
Listing of different string types 
Symbols 
abcdefghijklmnopqrstuvwxyzäö 
0123456789 
!@#$%^&*()-_=+[]{};’:”,./<>? 
Examples 
cat 
432 
!! 
Data Type 