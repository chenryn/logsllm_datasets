reducing this ﬁltering, more precise abuse-based ﬁltering, and
minimizing the impact of this growing threat to people that
use anonymity networks such as Tor.
A. Anonymous Blacklisting Systems
Anonymity networks, such as Tor, make it more difﬁcult
for ASNs and website operators to discern abusive users from
benign visitors based on IP address, since they cloak the user’s
true IP address. This causes many automated and list-driven
abuse-detection systems to blacklist some or all of the exit
nodes’ IP addresses.
Anonymous blacklisting systems [10], [26] have been
proposed as a method to enable website operators to more
precisely allow benign visitors to access their sites and hold
abusive users accountable for their actions. The goal of anony-
mous blacklisting systems is to allow a website, such as
Wikipedia, to block access to an individual anonymous abusive
user without requiring a trusted third-party that can revoke
a user’s anonymity. This capability would allow websites to
defend themselves against anonymous abusive users using
similar methods as against identiﬁable users. Most anonymous
blacklisting systems require users to anonymously register
and authenticate with the anonymity network using blind
signatures or zero-knowledge proof techniques, and create
whitelists of permitted users. The registration process must
require anonymous payment or otherwise bind users to scarce
resources, such as IP addresses, to mitigate Sybil attacks.
Adoption of anonymous blacklisting systems has been
negligible due to issues of degraded user privacy—anonymous
blacklisting systems either offer pseudonymity instead of full
anonymity or require a semi-trusted third-party to provide
anonymity—and additional computational overhead [9]. If
these issues could be addressed, anonymity blacklisting sys-
tems might be more widely deployed by anonymity net-
works and website operators, reducing the amount of explicit
anonymity network blocking and fate-sharing experienced by
users of these systems.
B. Contextual Awareness
It is conceivable that anonymity networks could reduce
instances of abuse-based ﬁltering by learning which websites
were blocking certain exit nodes and reroute requests for these
sites to another exit node that was not blocked. This would
likely require application-layer analysis on the exit node that
might be overly invasive from a privacy context.
A less privacy-invasive technique could involve the Tor
Browser displaying a message when ﬁltering is suspected. This
could be done by including block page detection similar to that
used in our study. The browser could also offer to retry the
request using a different exit node. Both of these techniques
could marginally reduce the impact of abuse-based blocking.
However, neither of these approaches directly addresses fate-
sharing issues caused by abuse-based blocking of Tor exit IP
addresses. They also have the potential to trigger an “arms-
race” as abusers could beneﬁt from Tor spreading out abusive
trafﬁc causing more aggressive ﬁltering of Tor trafﬁc by
impacted services.
C. Redesigning Anonymity Networks
Tor and other anonymity networks could attempt to recruit
a larger pool of exit nodes that enables each exit to deliver a
smaller amount of trafﬁc. Our results ﬁnd a (weak) correlation
between the amount of trafﬁc a node exits and the probability
of a node’s IP address being blocked due to automated abuse-
based ﬁltering. Thus, reducing the amount of trafﬁc each
node exits might reduce their probability of being blocked
by automated abuse-based ﬁltering. The risk of this and other
techniques to fan out trafﬁc to more IP addresses is that it
might cause more websites to preemptively block all Tor exit
trafﬁc. This also does not deter abusive usage of Tor.
We could also consider disincentivizing large-scale abuse
by charging Tor users for trafﬁc usage. The BRAIDS [11]
system proposed an anonymous payment scheme for improved
quality-of-service originally with the goal of disincentivizing
users from performing bulk downloads using Tor. BRAIDS
could also be used to charge Tor users for trafﬁc usage. This
might reduce the amount of abuse, but at the cost of Tor
becoming unusable by people that are not willing or cannot
pay for usage or improved quality-of-service.
D. Redesigning Automated Abuse Blocking
Basing automated abuse blocking on ratios of abusive
to benign requests instead of absolute values might reduce
the instances of higher-bandwidth exit nodes being blocked
by abuse-based ﬁltering. However, this would allow abusive
users to insert benign chaff requests to evade automated abuse
ﬁltering based on ratios instead of ﬁxed limits.
Another idea is to never completely block requests and
instead display CAPTCHAs to low-reputation IP addresses
associated with Tor exit nodes. The risk of websites not
blocking Tor exit node IP addresses is that CAPTCHAs are
an economic deterrent
to large-scale abuse that might be
insufﬁcient in cases of proﬁt-driven abuse, such as spam [15].
This highlights the challenges of websites that block Tor exit
node IP addresses in self-defense based on automated abuse
ﬁltering systems.
VII. CONCLUSION AND FUTURE WORK
Anonymous communication on the Internet is a critical
resource for people whose access to the Internet is restricted
by governments. However, the utility of anonymity networks
is threatened by services on the Internet that block or degrade
requests from anonymous users. In this paper, we measured
that at least 1.3 million addresses in the IPv4 address space,
and ≈ 3.67% of the Alexa top 1,000 websites, either block or
offer degraded service to Tor users. Our study provides a ﬁrst
step in illuminating the scale of the problem and identifying
centralized mechanisms that impact the usability of many sites
for users of anonymity networks. While many websites block
Tor to reduce abuse, doing so inadvertently impacts users from
censored countries who do not have other ways to access
censored Internet content. In the future, we plan to perform
14
[9] R. Henry and I. Goldberg.
Formalizing Anonymous Blacklisting
In IEEE Symposium on Security and Privacy, pages 81–
Systems.
95, May 2011. http://www.ieee-security.org/TC/SP2011/PAPERS/2011/
paper006.pdf.
[10] R. Henry, K. Henry, and I. Goldberg. Making a nymbler Nymble using
VERBS. In Privacy Enhancing Technologies, volume 6205, pages 111–
129. July 2010.
http://www.cacr.math.uwaterloo.ca/techreports/2010/
cacr2010-05.pdf.
[11] R. Jansen, N. Hopper, and Y. Kim. Recruiting new Tor relays with
In ACM Conference on Computer and Communications
BRAIDS.
Security, pages 319–328, 2010. http://www-users.cs.umn.edu/∼hopper/
braids ccs.pdf.
[12] D. Johnson. Stem. https://stem.torproject.org/.
[13] B. Jones, T.-W. Lee, N. Feamster, and P. Gill. Automated detection
and ﬁngerprinting of censorship block pages. In Internet Measurement
Conference. ACM, 2014. http://conferences2.sigcomm.org/imc/2014/
papers/p299.pdf.
[14] N. Mathewson. #1751: Project: Make it harder to use exits as one-hop
proxies, July 2010. https://bugs.torproject.org/1751.
[15] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G. M. Voelker,
and S. Savage. Re: CAPTCHAs: Understanding CAPTCHA-solving
In USENIX Security Symposium,
services in an economic context.
pages 28–28, 2010. https://www.usenix.org/legacy/events/sec10/tech/
full papers/Motoyama.pdf.
[16] OONI.
HTTP Requests Test,
July 2013.
https://github.
com/TheTorProject/ooni-spec/blob/6a3c38f2dc/test-specs/
ts-003-http-requests.md.
[17] Open Observatory of Network Interference (OONI).
torproject.org/.
https://ooni.
[18] R. Padmanabhan, P. Owen, A. Schulman, and N. Spring. Timeouts:
Beware surprisingly high delay. In Internet Measurement Conference,
pages 303–316. ACM, 2015.
http://conferences2.sigcomm.org/imc/
2015/papers/p303.pdf.
sectoor GmbH. TOR DNSBL - blacklist for Tor servers. http://www.
sectoor.de/tor.php.
[19]
[20] The Tor Project. Onionoo—a Tor network status protocol. https://
onionoo.torproject.org/.
[21] The Tor Project. The public TorDNSEL service. https://www.torproject.
org/projects/tordnsel.
[22] The Tor Project.
https://metrics.torproject.org/userstats-relay-country.html?graph=
userstats-relay-country&end=2015-09-01.
Direct
users
by
country, Aug.
2015.
[23] The Tor Project. Tor directory protocol, version 3, Aug. 2015. https:
//spec.torproject.org/dir-spec.
[24] The Tor Project. Tor pluggable transport speciﬁcation, 2015. https:
//spec.torproject.org/pt-spec.
[25] Tor: ‘The king of high-secure, low-latency anonymity’. Media leak,
Oct. 2013. http://www.theguardian.com/world/interactive/2013/oct/04/
tor-high-secure-internet-anonymity.
[26] P. Tsang, A. Kapadia, C. Cornelius, and S. Smith. Nymble: Blocking
IEEE Transactions on
misbehaving users in anonymizing networks.
Dependable and Secure Computing, 8(2):256–269, Mar. 2011.
[27] Various authors. List of services blocking Tor. https://trac.torproject.
org/projects/tor/wiki/org/doc/ListOfServicesBlockingTor.
[28] Wikipedia. Advice to users using Tor, Aug. 2015. https://en.wikipedia.
org/w/index.php?title=WP:TOR&oldid=670864289.
[29] P. Winter. exitmap, 2014. https://github.com/NullHypothesis/exitmap.
[30] P. Winter, R. K¨ower, M. Mulazzani, M. Huber, S. Schrittwieser,
Spoiled onions: Exposing malicious
In Privacy Enhancing Technologies. Springer, 2014.
S. Lindskog, and E. Weippl.
Tor exit relays.
http://www.cs.kau.se/philwint/spoiled onions/pets2014.pdf.
large-scale studies of the HTTP layer to discover ﬁner-grained
discrimination, such as websites offering restricted services
to anonymous users. We will also investigate more effective
technical and policy-level solutions to mitigate the second-
class treatment of anonymous users. Data availability: All
relevant data, code, and auxiliary information are available
from the University College London database, under the DOI:
http://dx.doi.org/10.5522/00/5
ACKNOWLEDGEMENTS
We thank the sysadmins at the University of California,
Berkeley, University of Cambridge and University of Michigan
for their help and support throughout this project; and the
operators of the Tor exit nodes used in this study, Moritz
Bartl and Juris Vetra from project Torservers.net, for their
assistance with data collection. We thank Philipp Winter for
help in running Exitmap, Arturo Filast`o for advice in working
with OONI measurements, and George Danezis for advice
on Bayesian analysis method to ﬁnd conﬁdence intervals for
our results to mitigate the effect of network loss. We thank
Michael Tschantz, Zakir Durumeric, Georg Koppen and Bjoern
A. Zeeb for comments and help on various aspects of this
work. Likewise, we also appreciate the valuable feedback we
received from our shepherd, Lujo Bauer, and the anonymous
reviewers.
This work was supported by the Engineering and Physical
Sciences Research Council [grant number EP/L003406/1]; the
US National Science Foundation (grants CNS-1223717, CNS-
1237265, CNS-1619620, and CNS-1518918); Intel through
the ISTC for Secure Computing and the Open Technology
Fund through the Freedom2Connect Foundation and from
the US Department of State, Bureau of Democracy, Human
Rights and Labor. Any opinions, ﬁndings, conclusions or
recommendations expressed in this material are those of the
authors and do not necessarily reﬂect the views of the sponsors.
REFERENCES
[1] D. Austin. TOR Node List. https://www.dan.me.uk/tornodes.
[2] Citizen Lab. URL testing lists, July 2015. https://github.com/citizenlab/
test-lists.
[3] CloudFlare. Does CloudFlare block Tor?, May 2015. https://support.
cloudﬂare.com/hc/en-us/articles/203306930.
[4] R. Dingledine.
cept anonymous users, Aug. 2014.
call-arms-helping-internet-services-accept-anonymous-users.
to arms: Helping Internet services ac-
https://blog.torproject.org/blog/
A call
[5] R. Dingledine and J. Appelbaum. How governments have tried to block
Tor. Chaos Communication Congress, Dec. 2012. https://svn.torproject.
org/svn/projects/presentations/slides-28c3.pdf.
[6] R. Dingledine and N. Mathewson.
resistant anonymity system.
Tor Project, Nov. 2006.
blocking-2006-11.pdf.
Design of a blocking-
Technical Report 2006-11-001, The
https://research.torproject.org/techreports/
[7] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-
generation onion router. In USENIX Security Symposium, Aug. 2004.
https://svn.torproject.org/svn/projects/design-paper/tor-design.pdf.
[8] Z. Durumeric, E. Wustrow, and J. A. Halderman. ZMap: Fast Internet-
In USENIX Security
wide scanning and its security applications.
Symposium, pages 605–620, 2013. https://www.usenix.org/conference/
usenixsecurity13/technical-sessions/paper/durumeric.
15