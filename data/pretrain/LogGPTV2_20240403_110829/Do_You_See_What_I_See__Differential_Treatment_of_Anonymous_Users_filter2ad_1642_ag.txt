### Reducing Filtering, Enhancing Precision, and Mitigating Threats in Anonymity Networks

#### A. Anonymous Blacklisting Systems

Anonymity networks, such as Tor, complicate the process of distinguishing between abusive users and benign visitors based on IP addresses, as they mask the user's true IP. This often leads to automated and list-driven abuse-detection systems blacklisting some or all exit nodes' IP addresses.

**Anonymous blacklisting systems** [10], [26] have been proposed to allow website operators to more accurately block individual anonymous abusive users without compromising their anonymity. The goal is to enable websites like Wikipedia to block specific abusive users without needing a trusted third party to revoke their anonymity. This would allow websites to defend themselves against anonymous abusers using similar methods as for identifiable users.

Most anonymous blacklisting systems require users to anonymously register and authenticate with the anonymity network using techniques like blind signatures or zero-knowledge proofs, and create whitelists of permitted users. The registration process must also include mechanisms to prevent Sybil attacks, such as requiring anonymous payments or binding users to scarce resources like IP addresses.

However, the adoption of these systems has been limited due to concerns about degraded user privacy and additional computational overhead [9]. If these issues could be addressed, anonymous blacklisting systems might be more widely deployed, reducing the need for explicit blocking of anonymity networks and the associated fate-sharing experienced by users.

#### B. Contextual Awareness

Anonymity networks could potentially reduce abuse-based filtering by learning which websites are blocking certain exit nodes and rerouting requests to unblocked nodes. This would likely require application-layer analysis on the exit node, which may be overly invasive from a privacy perspective.

A less invasive approach could involve the Tor Browser displaying a message when filtering is suspected, similar to the block page detection used in our study. The browser could also offer to retry the request using a different exit node. While these techniques could marginally reduce the impact of abuse-based blocking, they do not directly address the fate-sharing issues caused by the blocking of Tor exit IP addresses. Additionally, they could trigger an "arms race" where abusers benefit from the spreading of abusive traffic, leading to more aggressive filtering by affected services.

#### C. Redesigning Anonymity Networks

Tor and other anonymity networks could attempt to recruit a larger pool of exit nodes, allowing each node to handle a smaller amount of traffic. Our findings suggest a weak correlation between the amount of traffic a node exits and the likelihood of its IP address being blocked due to automated abuse-based filtering. Thus, reducing the traffic per node might lower the probability of being blocked. However, this approach risks causing more websites to preemptively block all Tor exit traffic, and it does not deter abusive usage of Tor.

Another strategy is to charge Tor users for traffic usage, as proposed by the BRAIDS system [11]. Originally designed to improve quality-of-service and discourage bulk downloads, BRAIDS could also be used to charge for traffic. This might reduce abuse but at the cost of making Tor unusable for those who cannot or are unwilling to pay.

#### D. Redesigning Automated Abuse Blocking

Automated abuse blocking could be improved by basing decisions on the ratio of abusive to benign requests rather than absolute values. This might reduce the instances of higher-bandwidth exit nodes being blocked. However, it could also allow abusers to evade detection by inserting benign chaff requests.

Alternatively, instead of completely blocking requests, websites could display CAPTCHAs to low-reputation IP addresses associated with Tor exit nodes. While CAPTCHAs can act as an economic deterrent, they may be insufficient in cases of profit-driven abuse, such as spam [15]. This highlights the challenges faced by websites that block Tor exit node IP addresses for self-defense.

### Conclusion and Future Work

Anonymous communication on the Internet is crucial for individuals whose access is restricted by governments. However, the utility of anonymity networks is threatened by services that block or degrade requests from anonymous users. Our study found that at least 1.3 million IPv4 addresses and approximately 3.67% of the Alexa top 1,000 websites either block or offer degraded service to Tor users. This research provides a first step in understanding the scale of the problem and identifying centralized mechanisms that impact the usability of many sites for anonymity network users.

While many websites block Tor to reduce abuse, this inadvertently affects users from censored countries who have no other means to access censored content. Future work will involve conducting large-scale studies of the HTTP layer to discover finer-grained discrimination, such as websites offering restricted services to anonymous users. We will also explore more effective technical and policy-level solutions to mitigate the second-class treatment of anonymous users.

### Acknowledgements

We thank the sysadmins at the University of California, Berkeley, University of Cambridge, and University of Michigan for their support. We also acknowledge the operators of the Tor exit nodes used in this study, Moritz Bartl and Juris Vetra from Torservers.net, for their assistance with data collection. Special thanks to Philipp Winter for help in running Exitmap, Arturo Filast√≤ for advice on OONI measurements, and George Danezis for guidance on Bayesian analysis. We also appreciate the feedback from Michael Tschantz, Zakir Durumeric, Georg Koppen, Bjoern A. Zeeb, Lujo Bauer, and the anonymous reviewers.

This work was supported by the Engineering and Physical Sciences Research Council, the US National Science Foundation, Intel through the ISTC for Secure Computing, the Open Technology Fund through the Freedom2Connect Foundation, and the US Department of State, Bureau of Democracy, Human Rights, and Labor. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.