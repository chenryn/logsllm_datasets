bors. Therefore, there is no correlation between se-
lected peers. Alternately, we may start many walks in
parallel. In either cases, after r steps, the selection is
independent of the origin.
• While the stationary distribution, π(x), is biased to-
wards peers with high degree, the bias is precisely
known, allowing us to correct it.
• Random walks may visit the same peer twice, which
lends itself better to a dynamic setting as described in
Section 3.
In practice, r need not be exceptionally large. For graphs
where the edges have a strong random component (such as
in peer-to-peer networks), it is suﬃcient that the number
of steps exceed the log of the population size, i.e., r ≥
O(log |V |).
Adjusting for degree bias: To correct for the bias to-
wards high degree peers, we make use of the Metropolis–
Hastings method [8, 14, 28] for Markov Chains. Random
walks on a graph are a special case of Markov Chains. In
a regular random walk, the transition matrix P (x, y) leads
to the stationary distribution π(x), as described above. The
Metropolis–Hastings method provides us with a way to build
a modiﬁed transition matrix, Q(x, y), leading to a target
stationary distribution μ(x), as follows:
Q(x, y) =
1 −P
P (x, y) min
μ(y)P (y,x)
μ(x)P (x,y)
, 1
x(cid:5)=y Q(x, y)
if x (cid:3)= y,
if x = y
”
(
“
“
”
«
Equivalently, to take a step from peer x, select a neighbor
y of x as normal (i.e., with probability P (x, y)). Then, with
probability min
, accept the move. Otherwise,
return to x. For a proof this deﬁnition of Q(x, y) leads to
sampling peer x with probability μ(x), see [8].
μ(y)
μ(x) = 1, so the
To collect uniform samples, we have
μ(y)P (y,x)
μ(x)P (x,y)
, 1
move-acceptance probability becomes:
„
«
„
min
μ(y)P (y, x)
μ(x)P (x, y)
, 1
= min
degree(x)
degree(y)
, 1
Therefore, our algorithm for selecting the next step from
some peer x is as follows:
degree.
• Select a neighbor y of x uniformly at random.
• Query y for a list of its neighbors, to determine its
• Generate a random number, p, uniformly between 0
• If p ≤ degree(x)
• Otherwise, remain at x as the next step.
degree(y) , y is the next step.
and 1.
We call this the Metropolized Random Walk (MRW). Qual-
itatively, the eﬀect is to suppress the rate of transition to
peers of higher degree, resulting in selecting each peer with
equal probability.
Evaluation: Although [8] provides a proof of correctness
for the Metropolis–Hastings method, to ensure the correct-
ness of our implementation we conduct evaluations through
simulation over static graphs. This additionally provides the
opportunity to compare MRW with conventional techniques
such as Breadth-First Search (BFS) or naive random walks
(RW) with no adjustments for degree bias.
To evaluate a technique, we use it to collect a large number
of sample vertices from a graph, then perform a goodness-of-
ﬁt test against the uniform distribution. For Breadth-First
Search, we simulate typical usage by running it to gather a
batch of 1,000 peers. When one batch of samples is collected,
the process is reset and begins anew at a diﬀerent starting
point. To ensure robustness with respect to diﬀerent kinds
of connectivity structures, we examine each technique over
several types of graphs as follows:
Erd¨os–R´enyi: The simplest variety of random graphs
Watts–Strogatz: “Small world” graphs with high cluster-
ing and low path lengths
Barab´asi–Albert: Graphs with extreme degree distribu-
tions, also known as power-law or scale-free graphs
Gnutella: Snapshots of the Gnutella ultrapeer topology,
captured in our earlier work [41]
To make the results more comparable, the number of ver-
tices (|V | = 161, 680) and edges (|E| = 1, 946, 596) in each
graph are approximately the same.1 Table 1 presents the
results of the goodness-of-ﬁt tests after collecting 1000 · |V |
samples, showing that Metropolis–Hastings appears to gen-
erate uniform samples over each type of graph, while the
other techniques fail to do so by a wide margin.
Figure 1 explores the results visually, by plotting the num-
ber of times each peer is selected. If we select k·|V | samples,
1Erd¨os–R´enyi graphs are generated based on some proba-
bility p that any edge may exist. We set p =
|V |·(|V |−1)
so that there will be close to |E| edges, though the exact
value may vary slightly. The Watts–Strogatz model require
that |E| be evenly divisible by |V |, so in that model we use
|E| = 1, 940, 160.
2|E|
)
s
r
e
e
p
f
o
#
(
m
a
r
g
o
t
s
i
H
2500
2000
1500
1000
500
0
0
RW, BFS
Oracle, MRW
RW
Oracle, MRW
BFS
RW
BFS
RW
BFS
1000
1500
500
Number of times sampled
(a) Erd¨os–R´enyi
0
500
1500
Number of times sampled
1000
0
(b) Gnutella
500
1000
1500
Number of times sampled
(c) Watts–Strogatz
(small world)
0
500
1500
Number of times sampled
1000
(d) Barab´asi–Albert
(power-law)
Figure 1: Bias of different sampling techniques; after collecting k · |V | samples. The ﬁgures show how many peers (y-axis) were selected x times.
the typical node should be selected k times, with other nodes
being selected close to k times approximately following a
normal distribution with variance k.2 We used k = 1, 000
samples. We also include an “Oracle” technique, which se-
lects peers uniformly at random using global information.
The Metropolis–Hastings results are virtually identical to
the Oracle, while the other techniques select many peers
much more and much less than k times. In the Gnutella,
Watts–Strogatz, and Barab´asi–Albert graphs, Breadth-First
Search exhibits a few vertices that are selected a large num-
ber of times (> 10, 000). The (not-adjusted) Random Walk
(RW) method has similarly selected a few vertices an excep-
tionally large number of times in the Gnutella and Barab´asi–
Albert models. The Oracle and MRW, by contrast, did not
select any vertex more than around 1,300 times.
In summary, the Metropolis–Hastings method selects peers
uniformly at random from a static graph. The next section
examines the additional complexities when selecting from a
dynamic graph, introduces appropriate modiﬁcations, and
evaluates the algorithm’s performance.
5 Sampling from Dynamic Graphs
Section 3 set aside topological issues and examined the dy-
namic aspects of sampling. Section 4 set aside temporal is-
sues and examined the topological aspects of sampling. This
section examines the unique problems that arise when both
temporal and topological diﬃculties are present.
Our hypothesis is that a Metropolis–Hastings random walk
will yield approximately unbiased samples even in a dynamic
environment. The fundamental assumption of Metropolis–
Hastings is that the frequency of visiting a peer is propor-
tional to the peer’s degree. We argue that this assumption
will be approximately correct if peer relationships change
only slightly during the walk. On one extreme, if the en-
tire walk completes before any graph changes occur, then
the problem reduces to the static case. If a single edge is
removed mid-walk, the probability of selecting the two af-
fected peers is not signiﬁcantly aﬀected, unless those peers
have very few edges. If many edges are added and removed
during a random walk, but the degree of each peer does not
change signiﬁcantly, we would also expect that the proba-
bility of selecting each peer will not change signiﬁcantly. In
peer-to-peer systems, each peer actively tries to maintain a
number of connections within a certain range, so we have
2Based on the normal approximation of a binomial distri-
bution with p = 1|V | and n = k|V |.
reason to believe that the degree of each peer will be rela-
tively stable in practice. On the other hand, it is quite possi-
ble that in a highly dynamic environment, or for certain de-
gree distributions, the assumptions of Metropolis–Hastings
are grossly violated and it fails to gather approximately un-
biased samples.
The fundamental question we attempt to answer in this
section is: Under what conditions does the Metropolis–Hastings
random walk fail to gather approximately unbiased samples?
Intuitively, if there is any bias in the samples, the bias will
be tied to some property that interacts with the walk. We
identify the following three fundamental properties that in-
teract with the walk:
Degree: The Metropolis–Hastings method is a modiﬁcation
of a regular random walk in order to correct for degree-
bias as described in Section 4. It assumes a ﬁxed rela-
tionship between degree and the probability of visiting
a peer. If the Metropolis–Hastings assumptions are in-
valid, the degree-correction may not operate correctly,
introducing a bias correlated with degree.
Session lengths: Section 3 showed how sampling may re-
sult in a bias based on session length.
If the walk
is more likely to select either short-lived or long-lived
peers, there will be a bias correlated with session length.
Query latency: In a static environment the only notion of
time is the number of steps taken by the walk. In a
dynamic environment, each step requires querying a
peer, and some peers will respond more quickly than
others. This could lead to a bias correlated with the
query latency. In our simulations, we model the query
latency as twice the round-trip time between the sam-
pling node and the peer being queried.3
For other peer properties, sampling bias can only arise if the
desired property is correlated with a fundamental properties
and that fundamental property exhibits bias. For example,
when sampling the number of ﬁles shared by each peer, there
may be sampling bias if the number of ﬁles is correlated with
session length and sampling is biased with respect to session
length. One could also imagine the number of ﬁles being
correlated with query latency (which is very loosely related
to the peer bandwidth). However, sampling the number of
shared ﬁles cannot be biased independently, as it does not
interact with the walk. To show that sampling is unbiased
2 RTT for the SYN, 1
the ACK and the request, and 1
2 RTT for the SYN-ACK, 1
2 RTT for
2 RTT for the reply.
3 1
for any property, it is suﬃcient to show that it is unbiased for
the fundamental properties that interact with the sampling
technique.
5.1 Adapting random walks for a dynamic environ-
ment
Departing peers introduce an additional practical consider-
ation. The walk may try to query a peer that is no longer
present–a case where the behavior of the ordinary random
walk algorithm is undeﬁned. We make an adaptation by
maintaining a stack of visited peers. When the walk chooses
a new peer to query, we push the peer’s address on the stack.
If the query times out, we pop the address oﬀ the stack, and
choose a new neighbor of the peer that is now on top of the
stack. If all of a peer’s neighbors time out, we re-query that
peer to get a fresh list of its neighbors. If the re-query also
times out, we pop that peer from the stack as well, and so
on. If the stack underﬂows, we consider the walk a failure.
We do not count timed-out peers as a hop for the purposes
of measuring the length of the walk. We call this adaptation
of the MRW sampling technique the Metropolized Random
Walk with Backtracking (MRWB) method for sampling from
dynamic graphs. Note that when applied in a static envi-
ronment, this method reduces to MRW.
5.2 Evaluation methodology
In the static case, we can rely on graph theory to prove the
accuracy of the MRW technique. Unfortunately, graph the-
ory is not well-suited to the problem of dynamically chang-
ing graphs. Therefore, we rely on simulation rather than
analysis. We have developed a session-level dynamic overlay
simulator that models peer arrivals, departures, latencies,
and neighbor connections. We now describe our simulation
environment.
The latencies between peers are modeled using values from
the King data set [13]. Peers learn about one another using
one of several peer discovery mechanisms described below.
Peers have a target minimum number of connections (i.e.,
degree) that they attempt to maintain at all times. When-
ever they have fewer connections, they open additional con-
nections. We assume connections are TCP and require a
3-way handshake before the connection is fully established,
and that peers will time out an attempted connection to a
departed peer after 10 seconds. A new peer generates its
session length from one of several diﬀerent session length
distributions described below and departs when the session
length expires. New peers arrive according to a Poisson
process, where we select the mean peer arrival rate based on
the session length distribution to achieve a target population
size of 100,000 peers.
To query a peer for a list of neighbors, the sampling node
must set up a TCP connection, submit its query, and receive
a response. The query times out if no response is received
after 10 seconds.4 We run the simulator for a warm-up pe-
riod to reach steady-state conditions before performing any
random walks.
Our goal is to discover if random walks started under
identical conditions will select a peer uniformly at random.
To evaluate this, we start 100,000 concurrent random walks
from a single location. Although started at the same time,
)
%
(
F
D
C
C
100
80
60
40
20
0
0
10
20
Time since start of sampling (s)
30
40
Figure 2: Distribution of time needed to complete a random walk (simu-
lated)
the walks will not all complete at the same time.5 We chose
to use 100,000 walks as we believe this is a much larger num-
ber of samples than most researchers will use in practice. If
there is no discernible bias with 100,000 samples, we can
conclude that the tool is unbiased for the purposes of gath-
ering fewer samples (i.e., we cannot get more accuracy by
using less precision). Figure 2 shows the distribution of how
long walks take to complete in one simulation using 50 hops
per walk, illustrating that most walks take 10–20 seconds
to complete. In the simulator the walks do not interact or
interfere with one another in any way. Each walk ends and
collects an independent sample.
As an expected distribution, we capture a perfect snap-
shot (i.e., using an oracle) at the median walk-completion
time, i.e., when 50% of the walks have completed.
5.3 Evaluation of a base case
Because the potential number of simulation parameters is
unbounded, we need a systematic method to intelligently
explore the most interesting portion of this parameter space.
Towards this end, we begin with a base case of parameters as
a starting point and examine the behavior of MRWB under
those conditions. In the following subsections, we vary the
parameters and explore how the amount of bias varies as a
function of each of the parameters. As a base case, we use
the following conﬁguration:
Session length distribution: Weibull(k = 0.59, λ = 40)
Target degree:
Maximum degree:
Peer discovery mechanism:
15
30
FIFO
Table 2: Base Case Conﬁguration
Figure 3 presents the sampled and expected distributions
for the three fundamental properties: degree, session length,
and query latency. The fact that the sampled and expected
distributions are visually indistinguishable demonstrates that
the samples are not signiﬁcantly biased in the base case.
To eﬃciently examine other cases, we introduce a sum-
mary statistic to quickly capture the diﬀerence between the
sampled and expected distributions, and to provide more
rigor than a purely visual inspection. For this purpose, we
use the Kolmogorov-Smirnov (KS) statistic, D, formally de-
ﬁned as follows. Where S(x) is the sampled cumulative dis-
tribution function and E(x) is the expected cumulative dis-
4The value of 10 seconds was selected based on our ex-
periments in developing a crawler for the Gnutella network
in [37].
5Each walk ends after the same number of hops, but not
every hop takes the same amount of time due to diﬀerences
in latencies and due to the occasional timeout.
)
%
(
F
D
C
C
100
80
60
40
20