#### Mechanical Sympathy for Elephants: Reducing I/O and Memory Stalls    
 30:28  2  Munro, Thomas    
This talk looks at the mechanics of memory and storage, and discusses a selection of opportunities for PostgreSQL to reduce stalls and improve performance. These include experimental and committed work done in the PostgreSQL and OS communities, along with some relevant ideas and observations found in academic papers. The following topics will be covered: * avoiding I/O stalls in recovery, index scans and joins * limiting I/O streams for parallel queries and concurrent queries * avoiding memory stalls for hash joins, sequential scans, index searches * avoiding branches through inlining and specialisation * reducing TLB misses for data and code    
#### pgagroal: High-performance connection pool for PostgreSQL.    
 25:53  4  Pedersen, Jesper    
pgagroal is a high performance protocol-native connection pool for PostgreSQL. pgagroal is built upon libev, a high performance network library, and uses a shared-memory process model together with atomic operations for tracking state to achieve its high performance. In this session we will explore the * Architecture * Features * Deployment * Performance * Roadmap of pgagroal.    
#### PostgreSQL HA Cluster with Query Load Balancing on Kubernetes    
 40:59  8  Peng, Bo    
Kubernetes is an open source container orchestration platform for automating deployment, scaling and management of application containers. Nowadays, more and more applications are being deployed in containers on Kubernetes. However, managing database on Kubernetes is difficult because the data redundancy can have very specific requirements. There are several solutions that can help us to run a PostgreSQL HA cluster on Kubernetes. However, these solutions don't provide query load balancing functionality. Therefore, users need to modify the application to distribute read queries among multiple PostgreSQL containers. In this talk, I would like to give you an overview of Kubernetes and explain how to deploy a PostgreSQL HA cluster with query load balancing using Pgpool-II on Kubernetes. Although Kubernetes provides a way to monitor the basic cluster status, this is not sufficient for practical cluster management. In this talk, I will introduce the way to implement custom Prometheus metrics to monitor PostgreSQL cluster status and performance for extensive cluster monitoring.    
#### PostgreSQL on K8s at Zalando: Two years in production    
 46:52  5  Kukushkin, Alexander    
Many DBAs avoid any kind of cloud offering and prefer to run their databases on dedicated hardware. At the same time companies demand to run Postgres at scale, efficiently, automated and well integrated into the infrastructure landscape. The arrival of Kubernetes provided good building blocks and an API to interact with and with it solve many problems at the infrastructure level. The database team at Zalando started running highly-available PostgreSQL clusters on Kubernetes more than two years ago. In this talk I am going to share how we automate all routine operations, providing developers with easy-to-use tools to create, manage and monitor their databases, avoiding commercial solutions lock-in and saving costs, show open-source tools we have built to deploy and manage PostgreSQL cluster on Kubernetes by writing short manifests describing a few essential properties of the result. Operating a few hundred PostgreSQL clusters in a containerized environment has also generated observations and learnings which we want to share: infrastructure problems (AWS), how engineers use our Postgres setup and what happens when the load becomes critical. * [Zalando Postres-Operator] * [Zalando Patroni]    
#### Progress adding SQL:2011 valid time to Postgres    
 51:43  2  Jungwirth, Paul A.    
I have a patch in progress to add SQL:2011 valid time support to Postgres, so that you can more easily record a history of things that change over time. It lets you define temporal primary and foreign keys and issue temporal UPDATE and DELETE commands. Although the SQL:2011 standard introduces a new concept called PERIODs, I've based the Postgres features on our own built-in ranges---and plan to support PERIODs too (hopefully before I get to PGCon).    
#### Protect Your PostgreSQL Passwords: How SCRAM Works & Why You Need It    
 58:27  3  Katz, Jonathan S.    
Passwords: they just seem to work. You connect to your PostgreSQL database and you are prompted for your password. You type in the correct character combination, and presto! you're in, safe and sound. But what if I told you that all was not as it seemed. What if I told you there was a better, safer way to use passwords with PostgreSQL? What if I told you it was imperative that you upgraded, too?    
#### Ptrack 2.0: yet another block-level incremental backup engine    
 42:41  3  Kondratov, Alexey    
Ptrack has been developed a few years ago and provided a way to track page-level changes of the PostgreSQL database data. This information was used for implementation of block-level incremental backups, which was bundled with pg probackup. However, that implementation of in-core Ptrack engine had a number of major drawbacks: * Requirement to keep a lot of additional files (one extra fork per relation); * Extremely invasive in-core changes; * Tricky workarounds to avoid races, when taking a backup. In this talk I am going to discuss block-level incremental backups and present a new incarnation of Ptrack — Ptrack 2.0. Being rewritten from the scratch it now uses a single shared hash table, which is mmap'ed in memory from the file on disk. All operations are made using atomics, so the map is completely lockless during the normal PostgreSQL operation. Ptrack map is written on disk at the end of checkpoint atomically block by block involving the CRC32 checksum calculation that is checked on the next whole map re-read after crash or restart. Due to the fixed size of the map there may be false positives (when some block is marked as changed without being actually modified), but not false negative results. This approach helps us to build simple, but yet durable and fast block-level incremental backups solution.    
#### Seamless SQL optimization    
 2:15:26  3  Samokhvalov, Nikolay    
There are two types of analysis and optimization. The first, macro-analysis, is analyzing the workload as a whole. Usually, it is done using pg stat statements or pgBadger The second one is micro-analysis and the central tool here is the EXPLAIN command. And there is a huge gap between them, partially covered by auto explain and pg qualstats extensions. In this tutorial, we learn how to establish a smooth and seamless SQL optimization process in your organization? Topics we'll cover: What are the pros and cons of using pg stat statements compared to log analysis performed by pgBadger? What are the key metrics in macro-analysis and how to choose the most applicable in each case (is it total time consumed by an SQL query group? or average timing, or maybe shared buffers hit and read by the query group per second?); Closing the gap: how to switch from macro-analysis to micro-analysis (you identified a "bad" SQL group, how to start optimizing it and what is needed to make this process faster / more automated?). How to simplify the process of adaption of using EXPLAIN command by a wide range of backend developers, what metrics matter and how (timing vs buffers involved). EXPLAIN visualization technics and their pros and cons (PEV, and FlameGraphs for EXPLAIN). How to accumulate knowledge about SQL optimization, share it with teammates and improve collaboration.    
#### The "default" postgresql.conf, step by step    
 59:44  2  Kosmodemiansky, Ilya    
If you ever wanted to find out what can be configured in postgresql.conf, you can easily find it in the official Postgres documentation. So, all you need to do is read it, yes, all of it, and you will have a perfectly configured database. Sounds easy, right? The reality, however, tends to differ from the laboratory conditions that documentation describes, in addition, there is never enough time to go through the documentation, especially, considering that not every parameter would make sense for your database. There are also settled differences that one should be aware of and the new releases that require constant adaptation of your config settings. In this tutorial, I will take you through all the settings that, in my experience, as a consultant working with a variety of databases, should be adjusted. I will look into reasoning for it, and review the chain reaction that each change in each of these settings, will trigger. We will review some typical workloads and I will also be sharing some recommended configurations which our DBAs follow when setting up for our clients and which have been proven over and over with different databases and under variety of our client’s requirements. Following this tutorial you will have the knowledge required to understand major postgresql.conf parameters, know what role they play in the overall database performance and will be able to set up your own version that will work for your database. If you are a DBA who is just starting to work with Postgres and would like to make sure that you have a reliable base to build your work on, this tutorial is for you.    
#### The Way for Updating Materialized Views Rapidly    
 39:18  2  Nagata, Yugo et al.    
Materialized views is a feature to store the results of view definition queries in DB in order to achieve faster query response. However, after base relations are modified, view maintenance is needed to keep the contents up to date. REFRESH MATERIALIZED VIEW command is prepared for the purpose, but this has to recompute the contents from a scratch, so this is not efficient in cases where only a small part of a base table is modified. Incremental View Maintenance (IVM) is a technique to maintain materialized views efficiently, which computes and applies only the incremental changes to the materialized views rather than recomputing. This feature is not implemented on PostgreSQL yet. We have proposed a patch to implement IVM on PostgreSQL and this is now under discussion. Since the first submission of the last year, we have made a great progress on this patch. For example, some aggregates, subqueries, self-join, and outer joins are supported now. These operations are important since they are commonly used in real applications. In this talk, we will explain the current status of our IVM implementation. The talk includes what problems are under the implementation, its solutions, what the current implementation can do, and what limitations and problems are left.    
#### Time Series Databases: A Deeper Look    
 59:39  3  Eisentraut, Peter    
The term "time series" is popular (again) in database circles. What is it and what's the point? Clearly, a traditional relational database like PostgreSQL can deal with time and with series. So why is time series a special use case? In this presentation, I want to look beyond the marketing a bit and analyze what the true technical characteristics of a time series database are and what use cases drive it. Then we can analyze how PostgreSQL handles these requirements, which workarounds are handy, and where improvements would be necessary. In PGCon tradition, this presentation is both guidance for users and a call to action for developers.    
#### Toward full ACID distributed transaction support with Foreign Data Wrapper    
 34:02  1  Sawada, Masahiko    
PostgreSQL has Foreign Data Wrapper feature and it is the powerful feature to access the distributed data across heterogenous data stores. FDW became writable at PostgreSQL 9.3 therefore PostgreSQL with FDW has potential to become distributed database supporting reads and writes. However one of the biggest missing piece is transaction management for distributed transactions. Currently atomicity and consistency of ACID properties are missing but are essential to achieve full ACID supported distributed transaction. Some proposals have been proposed but these are under discussion. This talks about the current status of FDW and problem regarding atomicity and isolation and introduce to the proposed solutions and other solutions employed by other distributed databases. Also I'll also explain the use cases like database sharding and federation.    
#### What's Missing For Postgres Monitoring    
 38:26  4  Fittl, Lukas    
Monitoring your Postgres database is important. But its actually not as easy as it sounds. Postgres itself does not expose enough information, or sometimes data is exposed that can be misinterpreted. In this session we'll spend time looking at specific cases that are blank spots on the map right now, where one either doesn't know what Postgres is up to, or where you have to use system-level tools and other creative methods to get information. Some examples of what we'll take a look at: The deceptive value of buffer hit counters, the multiple efforts to bring planning data to pg stat statements, and why you often have to resort to "perf" to identify performance bottlenecks. You'll leave this session with more ideas on how to work around these short-comings, as well as an understanding of where development effort is going to fix some of the issues.    
#### work mem warriors    
 41:19  1  Davis, Jeff et al.    
Recent work on the Postgres executor has made improvements to memory management -- from accounting for the memory used to responding to memory pressure. It is important to bind the memory usage of the database with the appropriate execution mechanisms and to choose those during planning based on cost in order to meet users' expectations and ensure predictable performance. This talk will cover three such improvements: the addition of memory accounting information to MemoryContexts, the memory-bounding of HashAgg (spilling HashAgg to disk), and the adaptive hashjoin fallback to nested hashloop join. The talk will also include an interactive session to solicit feedback from users on their expectations and experiences with work mem and the memory behavior of Postgres.    
#### Zedstore: In-core Column Store for Postgres    
 42:52  3  Wang, Alexandra et al.    
Zedstore is a column store for PostgreSQL that targets to reduce I/Os for queries that only need access to a few columns out of a wide table, to improve performance for analytics workloads, and to enable better compressions. It is under development and it uses the table AM APIs that were introduced in PostgreSQL V12. This talk will cover the use cases for column store in Postgres, the architecture and design decisions of Zedstore, performance and size comparisons between Zedstore and Heap tables for both OLTP and OLAP queries, changes required in the table AM APIs to accommodate table AMs other than heap, and the latest development status of Zedstore.    
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")