the number of diﬀerent processed inputs under the respective
secret. This is exploited in DPA attacks, which use the
observation of several diﬀerent processings of a secret value
in a device to learn its value, e.g., the adversary tries to
learn the secret key from power traces observed during the
en-/decryption of multiple (public) input values.
One important property of DPA attacks is their order.
The order d of a DPA [25, 31] is deﬁned as the number of d
diﬀerent internal values in the executed algorithm that are
used in the attack. The attack complexity of DPA grows
exponentially with its order [8].
3.3 Proﬁled Attacks
Independently of whether SPA or DPA is performed, side-
channel attacks can make use of proﬁling. Proﬁling of a side-
channel, e.g., the power consumption, means to construct
templates [9] that classify the side-channel information of
a target device with respect to a certain value processed
inside the device. In the actual attack, the templates are
matched with the side-channel trace to gain some information
on the value processed inside the device. The information
learned from template matching can then be exploited in
either SPA or DPA manner. Note however that conducting
proﬁled attacks requires much more eﬀort than performing
non-proﬁled attacks. Further note that in many applications
it is impossible to perform the required proﬁling step at all.
3.4 DPA Countermeasures
The eﬀectiveness of DPA attacks has caused a lot of eﬀort
to be put into the development of countermeasures to prevent
DPA. Two basic approaches to counteract DPA have evolved,
namely, (1) to protect the cryptographic implementation
using mechanisms like masking, and (2) the frequent re-
keying of unprotected cryptographic primitives.
3.4.1 Masking
Masking [8, 16], also called secret sharing, is a technique
that can hinder DPA attacks up to certain orders. The idea
behind masking is to prevent DPA by making the side-channel
leakage independent from the processed data.
In a masked cryptographic implementation, every secret
value v is split into d + 1 shares v0, ..., vd in order to protect
against d-th order DPA attacks. Thereby, d shares are chosen
uniformly at random and the (d + 1)-th share is chosen such
that the combination of all d+1 shares gives the actual secret
value v. As a result, an adversary is required to combine the
692side-channel leakage of all d + 1 shares to be able to exploit
the side channel, i.e., to perform a (d + 1)-th order DPA.
While the masking operation itself is usually cheap, e.g.,
XOR, cryptographic primitives typically contain several op-
erations that become more complex in the masked represen-
tation. This eventually results in massive implementation
overheads. For example, the 1st-order DPA secure threshold
implementations of AES in [7, 33] add an area-time overhead
of a factor of four.
3.4.2 Frequent Re-Keying
The success rate of key recovery with DPA rises with the
number of diﬀerent processed inputs. Therefore, frequent re-
keying [24,29] tries to limit the number of diﬀerent processed
inputs per key, i.e., the data complexity.
The countermeasure constrains a cryptographic scheme
to use a certain key k only for q diﬀerent public inputs (q-
limiting [41]). When the limit of q diﬀerent inputs is reached,
another key k(cid:48) is chosen. Thus, for a certain key k, an
adversary can only obtain side-channel leakage for q diﬀerent
inputs, which limits the feasibility of DPA to recover k.
Therefore, designing schemes and protocols with small
data complexity q is one measure to prohibit DPA against
unprotected cryptographic implementations. In more detail,
it is widely accepted that very small data complexities, i.e.,
q = 1 and q = 2, have suﬃciently small side-channel leak-
age and do not allow for successful key recovery from DPA
attacks [5, 36, 41, 44].
Leakage-Resilient Cryptography. Frequent re-keying
can be applied to any cryptographic scheme, e.g., an encryp-
tion scheme EN C or an authenticated encryption scheme AE,
by choosing a new key whenever a new message has to be
encrypted and authenticated, respectively. However, in such
a re-keying approach, side-channel resistance is also aﬀected
by the concrete instance of the cryptographic scheme. In
practice, the cryptographic scheme must be able to process
arbitrarily long messages using a standard primitive, e.g.,
AES with 128-bit block size. This situation facilitates DPA
in certain modes, such as CBC. Therefore, the cryptographic
scheme must be designed with special care.
A generic construction for an encryption scheme EN C
that can process arbitrarily long messages without DPA
vulnerability is given in Figure 1. For DPA security, it
requires a new key k0 to be chosen for every new message. To
securely process an arbitrary number of message blocks, the
depicted scheme chains a primitive f that encapsulates the
block encryption ci = E(ki; pi) and a key update mechanism
ki+1 = u(ki). Hereby, the included key update mechanism
ki → ki+1 ensures the unique use of each key ki. The
construction can be considered secure against side-channel
attacks if the key update mechanism is chosen such that
the side-channel leakages of all invocations to f cannot be
usefully combined. However, note that given that the key
is iteratively derived using f , random access to individual
blocks is typically quite expensive.
Exemplary constructions following the principle of Figure 1
to design DPA secure schemes from unprotected primitives
are the leakage-resilient encryption schemes in [36, 41, 44]
and the leakage-resilient MAC in [35]. Block-cipher based
instantiations of these schemes have a data complexity of
q = 2 in order to prohibit successful key recovery via DPA
attacks.
Figure 1: Generic encryption scheme EN C.
4. RE-KEYING FOR
MEMORY ENCRYPTION
Frequent re-keying is a mechanism to protect against DPA
without requiring that the implementation of the crypto-
graphic primitive uses costly DPA countermeasures such as
masking. Simultaneously, there are more and more practical
systems being deployed with unprotected cryptographic ac-
celerators by vendors not being aware of side-channel attacks.
As a result, re-keying based schemes are an interesting option
for protecting memory encryption and authentication against
DPA.
In this section, we perform the ﬁrst investigation of the
security of re-keying in the context of memory encryption
and authentication. It shows that contrary to other use cases,
the re-keying operation itself can be realized without DPA
countermeasures when protecting memory. However, we also
show that the application of re-keying to memory encryption
allows for proﬁled, higher-order DPA that leaks conﬁdential
constants in memory due to read-modify-write operations
inevitably occuring in encrypted memory.
4.1 The Re-Keying Operation
Up until now, the principle of re-keying was applied only to
communicating parties aiming for conﬁdential transmission.
Hereby, constructions following Figure 1 prevent DPA, but
require the initialization with a fresh key and thus secure key
synchronization between the communicating parties. This
synchronization is typically achieved by deriving a fresh key
from a shared master secret k and a public, random nonce
n [14,29,41]. However, this approach shifts the DPA problem
to the key derivation, which thus needs DPA protection
through mechanisms like masking.
The encryption and authentication of data stored in mem-
ory gives diﬀerent conditions for the instantiation of re-keying
based schemes. In particular, encrypting data in memory
means that en- and decryption is performed by the same
party, i.e., a single device encrypts data, writes it to the mem-
ory, and later reads and decrypts the data. Therefore, key
synchronization becomes unnecessary and the cryptographic
scheme can be re-keyed using random numbers without the
need for any cryptographic primitive or function being im-
plemented with DPA countermeasures.
4.2 Re-Keying and Plaintext Conﬁdentiality
The typical target of DPA attacks is the key being used as
key recovery fully breaks a cryptographic scheme. Re-keying
based schemes thus thwart such attacks and make DPA on
the key infeasible. However, the actual goal of encryption is
to ensure data conﬁdentiality. Therefore, protecting the key
against DPA is a useful measure, but as our analysis shows,
k0ffp0c0k1ffp1c1k2…693the application of re-keying to memory encryption can yet
result in a loss of memory conﬁdentiality.
The main observation that leads to this conclusion are
read-modify-write operations that inevitably occur in any
encrypted memory. These take place whenever the write
granularity is smaller than the encryption granularity. For
example, when a single byte is written to a memory that
is encrypted using an 128-bit block cipher, the respective
128-bit encryption block has to be loaded from memory,
decrypted and modiﬁed according to the byte-wise write
access, and then be encrypted again and written back to the
memory. In this case, 120 bits of the respective block remain
the same. The same phenomenon is observed in encryption
schemes that cover multiple encryption blocks p0, p1, p2, ... .
Here as well, one plaintext block, e.g., p0, might be changing,
while others, e.g., p1, remain constant.
If now re-keying is applied to memory encryption, the
constant plaintext parts within read-modify-write operations
will be encrypted several times using diﬀerent keys. This
causes constant, secret plaintext parts to be mixed with
varying keys. This situation is quite similar to the original
DPA setting, where a constant, secret key is mixed with
varying plaintexts. For stream ciphers, attackers can easily
exploit this mixing operation—the XOR of varying pad and
constant plaintexts—in a ﬁrst-order DPA. Namely, attackers
can model the power consumption of the varying pad for each
plaintext hypothesis using the observed ciphertexts. Match-
ing the power model with the side-channel observations then
eventually reveals the constant plaintext. For block ciphers,
a ﬁrst-order DPA does not work, but a proﬁled, second-
order DPA that is similar to unknown plaintext template
attacks [19] can be applied to learn constant plaintexts.
Unknown Plaintext Template Attacks. In [19], the
constant key k of a block cipher E is attacked by observing
the encryption of several unknown plaintexts with the help
of power templates. Hereby, the power templates are used
to learn information on the unknown plaintexts p0, p1, ...
and intermediate values v0, v1, ... in the respective encryp-
tion processes E(k; p0), E(k; p1), ... . Exploiting the relation
between the information learned on p0, p1, ... and v0, v1, ...,
the key k is recovered. As the attack combines side-channel
information from both the unknown plaintexts p0, p1, ... and
the intermediate values v0, v1, ..., the order of this attack is
two.
The described attack can be easily applied to a re-keyed
encryption scheme (cf. Figure 1). Namely, read-modify-write
operations cause a constant plaintext block pi to be encrypted
several times using diﬀerent keys ki, k(cid:48)
i, ... . Changing the
roles of plaintext and key in the attack from [19], re-keying
allows to learn the constant plaintext block pi from side-
channel information on the varying key ki, k(cid:48)
i, ... and some
intermediate value vi, v(cid:48)
i, ..., both extracted using power tem-
plates. As a result, one plaintext may only be encrypted with
one single key for re-keying to completely thwart DPA. This
also seems reasonable in the view of leaking more information
on a plaintext, the more often it is encrypted under diﬀerent
conditions, i.e., using diﬀerent keys.
Summarizing, memory encryption inevitably causes read-
modify-write operations. These cause re-keyed stream ci-
phers to become vulnerable to ﬁrst-order DPA and re-keyed
block ciphers to become vulnerable to proﬁled, second-order
DPA. These attacks do not target the actual keys, but the
conﬁdential memory content. While these attacks cannot
be prevented in the memory scenario, note that the eﬀort
and complexity of proﬁled, second-order DPA attacks is very
high in practice. Hence, re-keyed block encryption provides a
suitable basis to construct a memory encryption scheme with
ﬁrst-order DPA security. We further pursue this approach
in Section 5. To obtain higher-order security, we extend
our design in Section 6 and propose masking of the stored
plaintext values. This eﬀectively increases the number of
values to be recoverd via templates without the need for
masking being implemented in the cipher.
5. DPA-SECURE MEMORY ENCRYPTION
AND AUTHENTICATION
The analysis in Section 4 showed that frequent re-keying
of a block cipher based mode is a suitable approach to con-
struct a memory encryption and authentication scheme with
ﬁrst-order DPA security from unprotected cryptographic
primitives. However, one major requirement in Section 2
is to provide fast random access in memory, which is not
provided by present re-keying based encryption schemes.
A common way to provide fast random access to large
memory is to split the memory into blocks that can be directly
accessed. However, encrypting each of these memory blocks
by the means of fresh re-keying would render the number of
keys to be kept available in secure on-chip storage too high.
This problem is quite similar to memory authentication with
replay protection, which also requires block-wise authenticity
information to be stored in a trusted manner. To tackle this
issue, state-of-the-art authenticity techniques (cf. Section 2
and Appendix A) employ tree constructions to gain scalability
and to minimize the required amount of expensive on-chip
storage.
In this section, we therefore use the synergies between
frequent re-keying and memory authentication to present
Meas—a Memory Encryption and Authentication Scheme
with ﬁrst-order DPA security built upon unprotected crypto-
graphic primitives and suitable for all kinds of large memory,
e.g., RAM and NVM. Similar to existing memory authentica-
tion techniques, Meas uses a tree structure to minimize the
amount of secure on-chip storage. However, instead of hashes
or nonces, keys are encapsulated within the tree. In more
detail, the leaf nodes of the tree, which store the actual data,
are encrypted and authenticated using an authenticated en-
cryption scheme that is provided with fresh keys on every
write access. Similarly, the inner nodes of the tree, which
store the encryption keys for their respective child nodes, are
encrypted with an encryption scheme that uses a fresh key
on every write. Meas is shown secure in the leaking chip
model, and in particular, its DPA security is substantiated
by limiting the number of diﬀerent processed inputs per key
to q = 2 such as in [5, 36, 41, 44].
In the following, we ﬁrst present the construction of Meas,
followed by a security analysis considering authenticity, and
side-channel attacks.
5.1 Construction
The construction of Meas is designed to be secure ac-
cording to the leaking chip model. Therefore, Meas re-
quires an SPA-secure block encryption scheme EN C and
an SPA-secure authenticated encryption scheme AE. Both
EN C and AE have to fulﬁll the common security proper-
ties for (authenticated) encryption schemes. Such schemes
694can, e.g., be instantiated from unprotected cryptographic
implementations using leakage-resilient block encryption [44],
a leakage-resilient MAC [35], and the generic composition
encrypt-then-MAC [6]. Besides, a random number generator
is required for generating the keys.
An example of the tree construction proposed for Meas is
depicted in Figure 2. For the sake of simplicity, this example
as well as the following description assumes the use of a
binary tree, i.e., arity a = 2. However, instantiating the tree
with higher arity is easily possible.
The structure of Meas is as follows. The data in memory is
split into m plaintext blocks pi. Each of these pi is encrypted
and authenticated to a ciphertext-tag pair (ci, ti) using the
authenticated encryption scheme AE with data encryption
key deki:
(ci, ti) = AE(deki; pi)
0 ≤ i ≤ m − 1.
The encryption scheme EN C then encrypts the data encryp-
tion keys deki to the ciphertexts cl−1,i using key encryption
keys kekl−1,i. The operator || denotes concatenation.
cl−1,i = EN C(kekl−1,i; dek2i||dek2i+1)
0 ≤ i ≤ m
2
− 1.
Recursively applying EN C in a similar way to the key
encryption keys ﬁnally leads to the desired tree.
cj,i = EN C(kekj,i; kekj+1,2i||kekj+1,2i+1)