from GPS (left) and accelerometer (right) datasets
7.2.4 Turning
Turning data from the accelerometer produces the results
shown in Figure 8. Intuitively, drivers handle cornering ac-
cording to their force tolerance and perceived safety, as men-
tioned before. In practice, this data is not very eﬀective. At
best, only 3 of 31 self-identiﬁcation tests resulted in false
alarms, but about half of the possible 930 impersonations
were allowed. The infrequency of turning events in compar-
ison with positive or negative acceleration events likely re-
duces the usefulness of this data, and more data could result
in better performance. If we had enough data to properly
train the system on turning events, it would still however
require too much data-gathering time in testing the identity
of new users to eﬃciently render a decision, which is the
overarching concern.
Figure 9: Trial statistics not using (left) and using
(right) velocity range partitioning of driving data
The velocity ranges used here are chosen such that the
following concerns are satisﬁed:
• The divisions should be numerous enough to allow
for all the behavioral diﬀerences a person could make
based on speed.
• The divisions should be small enough such that the
lower bound does not “feel” signiﬁcantly diﬀerent than
the upper bound.
• The divisions should be few enough and suﬃciently
large to accumulate adequate data for comparison in
a timely manner, so decisions can be made eﬃciently.
433Empirical testing evinced a set of ranges most appropriate
for our experiment comprised of 0-20, 20-40, 40-60, and 60+
mph.
7.2.6 Feature Selection Summary
We found that both sources of acceleration data were use-
ful as they both had strengths and weaknesses. The data
from the accelerometer was very ﬁne-grained, being mea-
sured ﬁfty times per second, and was able to be parsed into
acceleration events quite well. However the magnitudes of
the forces upon the accelerometer did not show enough vari-
ation to identify unique users with high accuracy by itself.
This may be due to the device’s placement on the cushioned
passenger seat, which likely dulled the force somewhat. The
acceleration as calculated from position data, in contrast,
had more accurate magnitudes due to its direct calculation
from the location trace. GPS is accurate to within 3-7 me-
ters with 95% conﬁdence [22], so apart from some local in-
accuracies the overall traces were highly accurate. Never-
theless those local inaccuracies were large, so the GPS data
was also insuﬃcient for identiﬁcation on its own. Finally,
previously stated as a beneﬁt to the negative acceleration
feature, GPS data contributes its ability to often ignore re-
active (non-preferential) actions that are too brief for the
frequency of data collection.
Taking from the useful events, we have features includ-
ing (1) positive acceleration measured by the accelerometer
and (2) combined positive and negative acceleration calcu-
lated from the GPS position measurement. Both features
are ﬁnally subdivided into four velocity ranges, for a total of
eight features, ultimately resulting in 97% self-identiﬁcation
and 91% diﬀerentiation rates. Our Predictor component’s
set of thresholds is set to accommodate the total number of
feature tests in its classiﬁcation of drivers.
7.3 Threshold Size
The number of features required to pass authentication
has an eﬀect on the rate at which a car owner is authorized
as well as the rate at which illegitimate users are autho-
rized. We have eight features and two tests performed on
each feature. With the data split into ten blocks, there are
thus a total of 160 feature tests, 80 for each test type. To
use both test types, we combine them according to several
rules and thresholds as discussed in Section 5.2. For the K-S
test, we have thresholds specifying the maximum number of
tests which may be failed while still resulting in authoriza-
tion. For the total variation distance, we specify the maxi-
mum variation distance to which the tests may be summed.
Lower thresholds will prevent more users from being erro-
neously authorized, but will reduce the number of rightful
owners being authorized as well. Likewise, high thresholds
can ensure all legitimate users are authorized, but several
“thieves” will also be accepted.
For this portion of the experiment, full training and test-
ing datasets are used, for the broadest applicable view of the
data. These datasets are tested sequentially block by block.
To ﬁnd the optimal set of thresholds, we ﬁnd the point where
the false alarm and mis-detection curves intersect in Figure
10. In this ﬁgure, we search the possible thresholds to ﬁnd
the mis-detection rate associated with a speciﬁc false alarm
rate. We ﬁnd an intersection with lowest total error nearest
3 false alarms, identifying all but roughly a tenth of illegiti-
mate users.
1
0.8
0.6
0.4
0.2
e
t
a
R
r
o
r
r
E
0
0
2
False Alarm
Mis−Detection
4
False Alarms allowed
6
8
10
Figure 10: Finding an optimized threshold
We also note that with a diﬀerent threshold selection, we
can reduce illegitimate access to the neighborhood of 6%
with 16% false alarm rate. This boost to the false alarm
rate might be worth the added security depending on the
individual. Because alarms only notify the car owner (de-
pending on the setup), users may ﬁnd this false alarm rate
unobtrusive enough to choose the very stringent and con-
sequently secure threshold set. In practice, users could be
given the option to specify their own mis-detection threshold
based on perceived risk and comfort level.
7.4 Training Data Size
The training process for a classiﬁer beneﬁts from an abun-
dance of data (though sometimes too much data can make a
classiﬁer too speciﬁc and not applicable to new data). If the
application of the classiﬁer is to prevent irretrievable vehicle
theft, the user would prefer to have this protection as soon
as possible. We examine the impact of diﬀerent training
sizes here, to ﬁnd out how much data collection is necessary
before a user can begin protecting the car.
As our volunteers collected diﬀering amounts of data, we
base our training data size on the small datasets, those sup-
plied by our volunteers who drove for smaller amounts of
time. This size is broken into ten blocks to see the eﬀects of
increasing the data size on our false alarm and mis-detection
rates for all drivers. The maximum training data allowed
here is roughly 450 seconds (450 points) worth of positive
and negative acceleration from the GPS data, and 180 sec-
onds (9000 points) of positive acceleration measured by the
accelerometer. For reference, our users accomplished this
amount in 25-45 minutes depending on how much time was
spent cruising or at stop lights. All available testing data is
used, and the threshold set used for authentication is that
arrived at in the previous section on Threshold Size. The
results are shown in Figure 11.
As expected, the best accuracy is attained with all avail-
able blocks of data included. These error rates are higher
than those we measure in other tests, because we are re-
stricted to the small dataset size. Additionally, because the
threshold set is constant, optimized for the full available
training size, the false alarms are slightly erratic before set-
tling to lower values in later blocks. Of largest impact here is
the fall of the mis-detection rate showing better theft detec-
tion with larger training data. We recommend 1.5-2 hours of
training time, because in perusing the results, we ﬁnd those
4341
0.8
0.6
0.4
0.2
e
t
a
R
r
o
r
r
E
0
0
2
False Alarm
Mis−Detection
4
6
8
10
Training Data Size(blocks)
Figure 11: Eﬀects of training dataset size on error
rates
users who provided that amount of data almost universally
were identiﬁed as themselves with the least number of failed
feature tests, and were rarely confused with other drivers
(mis-detected).
7.5 Testing Data Size
The amount of data available for testing unsurprisingly
has eﬀects on accuracy similar to the training data. The
desire is again to require only a small amount of data, this
time in order to perform accurate authentication in time to
quickly identify a theft. We therefore analyze the eﬀect of
diﬀering testing sizes to ascertain the appropriate length of
testing data collection.
As with the training size experiment, we restrict the max-
imum amount of data allowed to be 450 seconds of GPS
sourced positive and negative acceleration alongside 180 sec-
onds of accelerometer sourced positive acceleration. Again,
this equates to 25-45 minutes of driving to ensure the larger
datasets do not skew the results to a higher accuracy and
a uniform amount of data is used. We allow full training
datasets, however, as users in the real world will have full
control of their training phase. The threshold set is again
held constant, using the results of the Threshold Size study.
Results appear below in Figure 12:
It is important to note again that the thresholds used for
this examination of testing dtaa size were optimized for all
data available. This threshold set works quite well for the
proper test size, and this emphasizes the importance of the
minimum length of time used for gathering testing data. It
also displays the eﬀect of increasing test data on the testing
stringency. To begin, all users are permitted access, result-
ing in no false alarms but 100% mis-detection, and by the
time all 10 blocks of data are used, most unauthorized users
are detected and some legitimate users begin to generate
false alarms. It is therefore important also to prevent test-
ing data size to grow too large and too speciﬁc.
As further evidence of the eﬀect of additional data, con-
sider Figure 13. As discussed, the K-S test returns a decision
on whether or not two datasets are from the same distribu-
tion, and it does so by estimating the probability that the
two datasets’ empirical distributions would be the measured
distance apart while still being part of the same overall dis-
tribution. This probability is referred to as the p-value, and
points on this ﬁgure are the average p-values for all feature
tests between users as additional data is included. The line
labeled “Self” refers to the average of self-identiﬁcation tests,
and by the criteria above, the p-values for these tests should
be large. The line labeled “Others” refers to the average of
those tests between distinct users, and these p-values should
be small. The ﬁgure shows self-identiﬁcation tests remain-
ing at a ﬂat rate, indicating that it takes very little time to
match one’s testing data with one’s own training data. As
desired, the p-values for the Others line are below those for
the Self line. Furthermore, while it takes longer to rule out
other users than it does to self-identify, our results show that
the p-values diverge quickly after a few ﬁnal data blocks are
added to the testing data.
100
10−1
l
e
u
a
V
−
P
t
s
e
T
S
−
K
Self
Others
False Alarm
Mis−Detection
10−2
0
2
4
6
8
10
Testing Data Size (blocks)
Figure 13: Eﬀects of testing dataset size on K-S test
p-values
7.6 Evaluation Summary
To conclude this evaluation, we present the following suc-
cesses:
• We found eﬀective features including positive accelera-
tion measured by the accelerometer as well as positive
and negative acceleration measured by the GPS.
• We found further eﬀective features in partitioning the
above according to speciﬁc velocity ranges.
1
0.8
0.6
0.4
0.2
e
t
a
R
r
o
r
r
E
0
5
6
7
8
9
10
Testing Data Size(blocks)
Figure 12: Eﬀects of testing dataset size on error
rates
435• We showed this collection of features capable of at-
taining 97% self-identiﬁcation and 91% diﬀerentiation
accuracies.
• We illustrated the eﬀects of varying our testing thresh-
olds and the ability to attain very low mis-detection
(around 7%) by allowing slightly higher false alarm
rates.
• We analyzed the size of training and testing data to
determine the requirements for robust accuracy.
8. CONCLUSION
In this paper, we proposed a fast automatic driver recogni-
tion system that continuously authenticates the driver as the
vehicle is operated. Our basic idea is to extract unique fea-
tures from the driving behavior, which cannot be exactly re-
produced by a thief driving away in the stolen car. Through
an in-depth investigation of the typical driving events, we
identiﬁed eﬀective driving features (i.e., positive and nega-
tive accelerations, at multiple speed ranges) to distinguish
between the car owner and any unauthorized users. We per-
formed extensive experimental evaluation using the driving
data collected from 31 volunteers. Our experiment results
show that the proposed system can successfully distinguish
that the current driver is the car owner, with 97% accuracy,
while also preventing impersonation 91% of the time.
Acknowledgments
This work is supported by the National Science Foundation
under grants 1527144 and 1553304, and the Army Research
Oﬃce under grant W911NF-14-1-0324.
9. REFERENCES
[1] Federal Bureau of Investigation, “Motor vehicle theft,”
http://www.fbi.gov/about-us/cjis/ucr/crime-in-the-
u.s/2012/crime-in-the-u.s.-2012/property-
crime/motor-vehicle-theft,
2012.
[2] Fox News, “Owner of stolen car sued in deadly
Hit-and-Run,”
http://www.foxnews.com/story/2009/05/15/owner-
stolen-car-sued-in-deadly-hit-and-run/,
2009.
[3] “Onstar,”
https://www.onstar.com/web/portal/home?g=1,
2014.
[4] “Lojack,” http://www.lojack.com/Home, 2014.
[5] N. H. T. S. Administration, “Vehicle theft prevention:
What consumers should know,”
http://www.safercar.gov/Vehicle+Owners/Resources/
Theft+Prevention.
[6] M. Shahzad, A. X. Liu, and A. Samuel, “Secure
unlocking of mobile touch screen devices by simple
gestures: You can see it but you can not do it,” in
Proc. of the Annual International Conference on
Mobile Computing and Networking (Mobicom), 2013.
[7] M. Qi, Y. Lu, J. Li, X. Li, and J. Kong, “User-speciﬁc
iris authentication based on feature selection,” in Proc.
of International Conference on Computer Science and
Software Engineering, vol. 1, 2008, pp. 1040–1043.
[8] R. Bowe, “Red ﬂag on biometrics: Iris scanners can be
tricked,” https://www.eﬀ.org/deeplinks/2012/07/red-
ﬂag-biometrics-iris-scanner-vulnerability-revealed,
2012.
[9] T. C. Clancy, N. Kiyavash, and D. J. Lin, “Secure
smartcard-based ﬁngerprint authentication,” in Proc.
of the 2003 ACM SIGMM Workshop on Biometrics
Methods and Applications, 2003, pp. 45–52.
[10] A. W.
Kosner, “iphone 5s touch id ﬁngerprint scanner is a fail,”
http://www.forbes.com/sites/anthonykosner/2013/10/
15/iphone-5s-touch-id-ﬁngerprint-scanner-is-a-fail-for-
20-of-users-heres-what-to-do/,
2013.
[11] L. Li, X. Zhao, and G. Xue, “Unobservable
re-authentication for smartphones,” in Proc. of the
Network and Distributed System Security (NDSS)
Symposium, 2013.
[12] C. Nickel, T. Wirtl, and C. Busch, “Authentication of
smartphone users based on the way they walk using
k-NN algorithm,” in Proc. of International Conference
on Intelligent Information Hiding and Multimedia
Signal Processing, July 2012.
[13] N. Clarke and S. Furnell, “Authenticating mobile
phone users using keystroke analysis,” International
Journal of Information Security, vol. 6, no. 1, pp.
1–14, 2007.
[14] X. Zou and D. M. Levinson, “Modeling pipeline
driving behaviors: Hidden markov model approach,”
Journal of the Transportation Research Board, vol.
1980, no. 1, pp. 16–23, 2006.
[15] N. Oza, “Probabilistic models of driver behavior,” in
Proc. of Spatial Cognition Conference, 1999.
[16] A. Sathyanarayana, P. Boyraz, and J. Hansen, “Driver
behavior analysis and route recognition by hidden
markov models,” in Proc. of International Conference
on Vehicular Electronics and Safety, Sept 2008.
[17] C. Miyajima, Y. Nishiwaki, K. Ozawa, T. Wakita,
K. Itou, K. Takeda, and F. Itakura, “Driver modeling
based on driving behavior and its evaluation in driver
identiﬁcation,” Proceedings of the IEEE, vol. 95, no. 2,
pp. 427–437, Feb 2007.
[18] P. Olofsson, Probability, Statistics, and Stochastic
Processes 2nd edition. John Wiley, 2012.
[19] J. A. Adell and P. Jodr´a, “Exact kolmogorov and total
variation distances between some familiar discrete
distributions,” Journal of Inequalities and
Applications, vol. 2006, no. 1, p. 64307, 2006.
[20] “How to make a smart car surveillance system using a
mobile phone,”
http://www.wikihow.com/Discussion:Make-a-Smart-
Car-Surveillance-System-Using-a-Mobile-Phone,
2005.
[21] “Open automotive alliance,”
http://www.openautoalliance.net/, 2014.
[22] National Coordination Oﬃce for Space-Based
Positioning, Navigation, and Timing, “GPS accuracy,”
http://www.gps.gov/systems/gps/performance/accuracy/,
2014.
436