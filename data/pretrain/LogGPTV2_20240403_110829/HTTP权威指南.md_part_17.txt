见图4-6，C6），并对响应数据进行处理（参见图4-6，C7）。
4.2 对TCP性能的考虑
HTTP紧挨着TCP，位于其上层，所以HTTP事务的性能在很大程度上取决于底层
TCP通道的性能。本节重点介绍了一些很重要的、对这些TCP连接的性能考虑。理
解了TCP的某些基本性能特点之后，就可以更好地理解HTTP的连接优化特性，这
样就能设计实现一些更高性能的HTTP应用程序了。
连接管理 ｜ 85
本节要求大家对TCP协议的内部细节有一定的了解。如果对TCP性能考虑的细节
不感兴趣（或者很熟悉这些细节），可以直接跳到4.3节。TCP是个很复杂的话题，
所以这里我们只能提供对TCP性能的简要概述。本章末尾的4.8节列出了一些很好
的TCP参考书，以供参考。
4.2.1 HTTP事务的时延
我们来回顾一下，在HTTP请求的过程中会出现哪些网络时延，并以此开始我们的
TCP性能之旅。图4-7描绘了HTTP事务主要的连接、传输以及处理时延。
服务器
时间
DNS查询 连接 请求 处理 响应 关闭
客户端
80 图4-7 串行HTTP事务的时间线
注意，与建立TCP连接，以及传输请求和响应报文的时间相比，事务处理时间可能
是很短的。除非客户端或服务器超载，或正在处理复杂的动态资源，否则HTTP时
延就是由TCP网络时延构成的。
HTTP事务的时延有以下几种主要原因。
(1) 客户端首先需要根据URI确定Web服务器的IP地址和端口号。如果最近没有对
URI中的主机名进行访问，通过DNS解析系统将URI中的主机名转换成一个IP
地址可能要花费数十秒的时间3。
(2) 接下来，客户端会向服务器发送一条TCP连接请求，并等待服务器回送一个请
求接受应答。每条新的TCP连接都会有连接建立时延。这个值通常最多只有一
两秒钟，但如果有数百个HTTP事务的话，这个值会快速地叠加上去。
(3) 一旦连接建立起来了，客户端就会通过新建立的TCP管道来发送HTTP请求。
数据到达时，Web服务器会从TCP连接中读取请求报文，并对请求进行处理。
注3： 幸运的是，大多数HTTP客户端都有一个小的DNS缓存，用来保存近期所访问站点的IP地址。如果
已经在本地“缓存”（记录）了IP地址，查询就可以立即完成。因为大多数Web浏览器浏览的都是
少数常用站点，所以通常都可以很快地将主机名解析出来。
86 ｜ 第4章
因特网传输请求报文，以及服务器处理请求报文都需要时间。
(4) 然后，Web服务器会回送HTTP响应，这也需要花费时间。
这些TCP网络时延的大小取决于硬件速度、网络和服务器的负载，请求和响应报文
的尺寸，以及客户端和服务器之间的距离。TCP协议的技术复杂性也会对时延产生
巨大的影响。
4.2.2 性能聚焦区域
本节其余部分列出了一些会对HTTP程序员产生影响的、最常见的TCP相关时延，
其中包括：
• TCP连接建立握手；
• TCP慢启动拥塞控制；
• 数据聚集的Nagle算法；
• 用于捎带确认的TCP延迟确认算法；
• TIME_WAIT时延和端口耗尽。
如果要编写高性能的HTTP软件，就应该理解上面的每一个因素。如果不需要进行
这个级别的性能优化，可以跳过这部分内容。 81
4.2.3 TCP连接的握手时延
建立一条新的TCP连接时，甚至是在发送任意数据之前，TCP软件之间会交换一系
列的IP分组，对连接的有关参数进行沟通（参见图4-8）。如果连接只用来传送少量
数据，这些交换过程就会严重降低HTTP的性能。
(a) SYN (c) ACK
服务器 GET / HTTP. . .
(d) HTTP/1.1 304 Not modified
(b) SYN+ACK . . .
连接
时间
连接握手时延 数据传输
客户端
图4-8 在发送数据之前，TCP要传送两个分组来建立连接
连接管理 ｜ 87
TCP连接握手需要经过以下几个步骤。
(1) 请求新的TCP连接时，客户端要向服务器发送一个小的TCP分组（通常是40～
60个字节）。这个分组中设置了一个特殊的SYN标记，说明这是一个连接请求。
（参见图4-8a）。
(2) 如果服务器接受了连接，就会对一些连接参数进行计算，并向客户端回送一个
TCP分组，这个分组中的SYN和ACK标记都被置位，说明连接请求已被接受
（参见图4-8b）。
(3) 最后，客户端向服务器回送一条确认信息，通知它连接已成功建立（参见图4-8c）。
现代的TCP栈都允许客户端在这个确认分组中发送数据。
HTTP程序员永远不会看到这些分组——这些分组都由TCP/IP软件管理，对其是不
可见的。HTTP程序员看到的只是创建TCP连接时存在的时延。
通常HTTP事务都不会交换太多数据，此时，SYN/SYN+ACK握手（参见图4-8a
和图4-8b）会产生一个可测量的时延。TCP连接的ACK分组（参见图4-8c）通常
都足够大，可以承载整个HTTP请求报文4，而且很多HTTP服务器响应报文都可
以放入一个IP分组中去（比如，响应是包含了装饰性图片的小型HTML文件，或
82 者是对浏览器高速缓存请求产生的304 Not Modified响应）。
最后的结果是，小的HTTP事务可能会在TCP建立上花费50%，或更多的时间。后
面的小节会讨论HTTP是如何通过重用现存连接，来减小这种TCP建立时延所造成
的影响的。
4.2.4 延迟确认
由于因特网自身无法确保可靠的分组传输（因特网路由器超负荷的话，可以随意丢
弃分组），所以TCP实现了自己的确认机制来确保数据的成功传输。
每个TCP段都有一个序列号和数据完整性校验和。每个段的接收者收到完好的段
时，都会向发送者回送小的确认分组。如果发送者没有在指定的窗口时间内收到确
认信息，发送者就认为分组已被破坏或损毁，并重发数据。
由于确认报文很小，所以TCP允许在发往相同方向的输出数据分组中对其进行“捎
带”。TCP将返回的确认信息与输出的数据分组结合在一起，可以更有效地利用网
络。为了增加确认报文找到同向传输数据分组的可能性，很多TCP栈都实现了一种
注4： 因特网流量中的IP分组通常是几百字节，本地流量中的IP分组为1500字节左右。
88 ｜ 第4章
“延迟确认”算法。延迟确认算法会在一个特定的窗口时间（通常是100～200毫
秒）内将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那
个时间段内没有输出数据分组，就将确认信息放在单独的分组中传送。
但是，HTTP具有双峰特征的请求-应答行为降低了捎带信息的可能。当希望有相
反方向回传分组的时候，偏偏没有那么多。通常，延迟确认算法会引入相当大的时
延。根据所使用操作系统的不同，可以调整或禁止延迟确认算法。
在对TCP栈的任何参数进行修改之前，一定要对自己在做什么有清醒的认识。TCP
中引入这些算法的目的是防止设计欠佳的应用程序对因特网造成破坏。对TCP配置
进行的任意修改，都要绝对确保应用程序不会引发这些算法所要避免的问题。
4.2.5 TCP慢启动
TCP数据传输的性能还取决于TCP连接的使用期（age）。TCP连接会随着时间进行
自我“调谐”，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移
提高传输的速度。这种调谐被称为TCP慢启动（slow start），用于防止因特网的突
然过载和拥塞。 83
TCP慢启动限制了一个TCP端点在任意时刻可以传输的分组数。简单来说，每成功
接收一个分组，发送端就有了发送另外两个分组的权限。如果某个HTTP事务有大
量数据要发送，是不能一次将所有分组都发送出去的。必须发送一个分组，等待确
认；然后可以发送两个分组，每个分组都必须被确认，这样就可以发送四个分组了，
以此类推。这种方式被称为“打开拥塞窗口”。
由于存在这种拥塞控制特性，所以新连接的传输速度会比已经交换过一定量数据的、
“已调谐”连接慢一些。由于已调谐连接要更快一些，所以HTTP中有一些可以重用
现存连接的工具。本章稍后会介绍这些HTTP“持久连接”。
4.2.6 Nagle算法与TCP_NODELAY
TCP有一个数据流接口，应用程序可以通过它将任意尺寸的数据放入TCP栈中——
即使一次只放一个字节也可以！但是，每个TCP段中都至少装载了40个字节的标
记和首部，所以如果TCP发送了大量包含少量数据的分组，网络的性能就会严重
下降。5
注5： 发送大量单字节分组的行为称为“发送端傻窗口综合症”。这种行为效率很低、违反社会道德，而且
可能会影响其他的因特网流量。
连接管理 ｜ 89
Nagle算法（根据其发明者John Nagle命名）试图在发送一个分组之前，将大量
TCP数据绑定在一起，以提高网络效率。RFC 896“IP/TCP互连网络中的拥塞控
制”对此算法进行了描述。
Nagle算法鼓励发送全尺寸（LAN上最大尺寸的分组大约是1500字节，在因特网
上是几百字节）的段。只有当所有其他分组都被确认之后，Nagle算法才允许发送
非全尺寸的分组。如果其他分组仍然在传输过程中，就将那部分数据缓存起来。只
有当挂起分组被确认，或者缓存中积累了足够发送一个全尺寸分组的数据时，才会
将缓存的数据发送出去。6
Nagle算法会引发几种HTTP性能问题。首先，小的HTTP报文可能无法填满一个
分组，可能会因为等待那些永远不会到来的额外数据而产生时延。其次，Nagle算
法与延迟确认之间的交互存在问题——Nagle算法会阻止数据的发送，直到有确认
分组抵达为止，但确认分组自身会被延迟确认算法延迟100～200毫秒。7
HTTP应用程序常常会在自己的栈中设置参数TCP_NODELAY，禁用Nagle算法，
提高性能。如果要这么做的话，一定要确保会向TCP写入大块的数据，这样就不会
84 产生一堆小分组了。
4.2.7 TIME_WAIT累积与端口耗尽
TIME_WAIT端口耗尽是很严重的性能问题，会影响到性能基准，但在现实中相对
较少出现。大多数遇到性能基准问题的人最终都会碰到这个问题，而且性能都会变
得出乎意料地差，所以这个问题值得特别关注。
当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最
近所关闭连接的IP地址和端口号。这类信息只会维持一小段时间，通常是所估计的
最大分段使用期的两倍（称为2MSL，通常为2分钟8）左右，以确保在这段时间内
不会创建具有相同地址和端口号的新连接。实际上，这个算法可以防止在两分钟内
创建、关闭并重新创建两个具有相同IP地址和端口号的连接。
现在高速路由器的使用，使得重复分组几乎不可能在连接关闭的几分钟之后，出现
在服务器上。有些操作系统会将2MSL设置为一个较小的值，但修改此值时要特别
注6： 这个算法有几种变体，包括对超时和确认逻辑的修改，但基本算法会使数据的缓存比一个TCP段小一些。
注7： 使用管道化连接（本章稍后介绍）时这些问题可能会更加严重，因为客户端可能会有多条报文要发送
给同一个服务器，而且不希望有时延存在。
注8： 将2MSL的值取为2分钟是有历史原因的。很早以前，路由器的速度还很慢，人们估计，在将一个分
组的复制副本丢弃之前，它可以在因特网队列中保留最多一分钟的时间。现在，最大分段生存期要小
得多了。
90 ｜ 第4章
小心。分组确实会被复制，如果来自之前连接的复制分组插入了具有相同连接值的
新TCP流，会破坏TCP数据。
2MSL的连接关闭延迟通常不是什么问题，但在性能基准环境下就可能会成为一个
问题。进行性能基准测试时，通常只有一台或几台用来产生流量的计算机连接到某
系统中去，这样就限制了连接到服务器的客户端IP地址数。而且，服务器通常会在
HTTP的默认TCP端口80上进行监听。用TIME_WAIT防止端口号重用时，这些
情况也限制了可用的连接值组合。
在只有一个客户端和一台Web服务器的异常情况下，构建一条TCP连接的4个值：
其中的3个都是固定的——只有源端口号可以随意改变：
客户端每次连接到服务器上去时，都会获得一个新的源端口，以实现连接的唯一性。
但由于可用源端口的数量有限（比如，60 000个），而且在2MSL秒（比如，120
秒）内连接是无法重用的，连接率就被限制在了60 000/120=500次/秒。如果再不
85
断进行优化，并且服务器的连接率不高于500次/秒，就可确保不会遇到TIME_
WAIT端口耗尽问题。要修正这个问题，可以增加客户端负载生成机器的数量，或
者确保客户端和服务器在循环使用几个虚拟IP地址以增加更多的连接组合。
即使没有遇到端口耗尽问题，也要特别小心有大量连接处于打开状态的情况，或为
处于等待状态的连接分配了大量控制块的情况。在有大量打开连接或控制块的情况
下，有些操作系统的速度会严重减缓。
4.3 HTTP连接的处理
本章的前两节对TCP连接及其性能含义进行了精要的介绍。要想学习更多与TCP
联网有关的知识，请参见本章末尾的资源列表。
现在我们切回到HTTP上来。本章其余部分将解释操作和优化连接的HTTP技术。
我们从HTTP的Connection首部开始介绍，这是HTTP连接管理中一个很容易被
误解，但又很重要的部分。然后会介绍一些HTTP连接优化技术。
4.3.1 常被误解的Connection首部
HTTP允许在客户端和最终的源端服务器之间存在一串HTTP中间实体（代理、高
速缓存等）。可以从客户端开始，逐跳地将HTTP报文经过这些中间设备，转发到源
连接管理 ｜ 91
端服务器上去（或者进行反向传输）。
在某些情况下，两个相邻的HTTP应用程序会为它们共享的连接应用一组选项。
HTTP的Connection首部字段中有一个由逗号分隔的连接标签列表，这些标签为
此连接指定了一些不会传播到其他连接中去的选项。比如，可以用Connection:
close来说明发送完下一条报文之后必须关闭的连接。
Connection首部可以承载3种不同类型的标签，因此有时会很令人费解：
• HTTP首部字段名，列出了只与此连接有关的首部；
• 任意标签值，用于描述此连接的非标准选项；
• 值close，说明操作完成之后需关闭这条持久连接。
如果连接标签中包含了一个HTTP首部字段的名称，那么这个首部字段就包含了
与一些连接有关的信息，不能将其转发出去。在将报文转发出去之前，必须删除
86 Connection首部列出的所有首部字段。由于Connection首部可以防止无意中对
本地首部的转发，因此将逐跳首部名放入Connection首部被称为“对首部的保
护”。图4-9显示了一个这样的例子。
首部说明：不应该转发Meter首部，要应
HTTP/1.1 200 OK