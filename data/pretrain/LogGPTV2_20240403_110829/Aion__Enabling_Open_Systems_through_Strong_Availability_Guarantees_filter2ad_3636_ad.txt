semantics is similar to how Intel SGX handles long-latency crypto-
graphic operations, such as einit [18, §40.3]. Specifically, whenever
an interrupt request arrives during a cryptographic operation, the
CPU resets the cryptographic core (without committing or leaking
any internal state), sets the zero flag, and updates the program
counter before state saving proceeds as usual via the exception
engine. This behavior ensures that interrupt response times cannot
be delayed by long-standing cryptographic operations (cf. require-
ments in Section 3.1). Interrupted cryptographic instructions can
be simply restarted later when they are followed by a conditional
jump that tests the zero flag.
4.3 Modifications to RIOT
In Aion, we need to protect the scheduler and its associated data
structures from outside interferences. At the same time, it is de-
sirable to provide a similar functionality as the unmodified RIOT.
Thus, we map the scheduler enclave over the RIOT scheduler and
incorporate core features of the RIOT timer. Since the scheduler
is executed on every interrupt already, we also grant it exclusive
access to the timer peripheral which we map into the protected
memory region of the scheduler. This allows scheduling decisions
not only based on expiring timers such as sleeping jobs, but it also
allows other applications to use the scheduler as a source for trusted
system timings. It, furthermore, enables the scheduler to be the only
instance that monopolizes the shared resource of CPU time. In our
prototype, the scheduler disables interrupts during its execution
and will never interrupt itself. This increases the interrupt latency
of our prototype and is not strictly necessary to uphold the defined
guarantees. With more engineering effort, the scheduler could also
be implemented to allow interrupts at carefully selected parts of its
execution paths.
As discussed above, a fair scheduling can only exist if the default
state of the system is schedulable. Any platform owner that accepts
new application to be deployed to the open system must check
that the requirements of the new application do not exceed the
capabilities of the available shared resources. If the shared resources
are schedulable, however, the Aion scheduler can enforce a fair
share for each deployed application. For the prototype, we limit the
number of maximum running or sleeping applications but allow
the attacker to register additional applications up to this limit.
5 EXPERIMENTAL EVALUATION
We evaluate Aion in two steps. First, we present a case study imple-
menting the running example from Section 2.2. Then, we provide a
cycle-accurate performance evaluation for all operations impacting
the real-time performance of the hardware and the scheduler.
CLIX 
return read_sensor ()
1 def sync_input :
2
3
4
5 def async_output ( payload ):
CLIX 
6
try :
7
8
9
10
11
12
13 def async_io_task :
14
15
16
output_buf [i] = payload
except : fail
while True :
for i in output_buf
output_buffer (i)
i = buf_free ( get_caller_id () )
if i != 0:
Listing 1: Pseudo-code of the I/O enclave I of our case study.
5.1 Case Study
We demonstrate the security and availability features of Aion by
implementing the running example from Fig. 1. Our case study fea-
tures three enclaved RIOT jobs that all run with the highest priority.
These jobs implement the application enclaves A and B, and an I/O
enclave I. The latter provides an interface to synchronously read
the sensor and to asynchronously dispatch messages to a serial line.
The enclaves make use of Sancus’s TEE features [30], including
isolation guarantees and secure linking between A and I, and B
and I; they can further be remotely attested. All three enclaves
schedule timer interrupts to be woken up at regular intervals.
In Listings 1 and 2 we illustrate interesting aspects of our im-
plementation. Aion’s development toolchain is based on that of
Sancus and currently supports programming in C and assembly.
We decided to present only the enclave entry functions (as opposed
to internal functions that can only be called from within the same
enclave) in Python-like pseudo code to reduce the complexity and
focus on important security and software engineering aspects that
are enabled by Aion. The C implementation of our case study is
given in Appendix B and as part of the open-source artifact.
I/O job and API. Following Listing 1, I provides three entry
points: sync_input returns a sensor reading; the code to operate
the MMIO resource – a few assembly instructions – reside in the
internal function read_sensor. The function first executes clix to
ensure atomic execution of this operation. Following our semantics
of clix, it is up to the developer to guarantee that sync_input
completes with the end of the requested clix period. The execution
of the clix itself is protected by the atomic entry period. Similar
to sync_input, async_output is also an atomic function. But in-
stead of performing the I/O operation immediately, the payload is
buffered. The function may throw an exception if no free buffer is
available for the specific calling context and we anticipate that I
would provide guaranteed buffers for a number of protected jobs
such as A and B, while other jobs would have to share buffers. In
our example, this decision is based on the Sancus get_caller_id
primitive, which allows I to identify the calling enclave. We have
hard-coded this for reasons of simplicity and discuss a more general
implementation in Section 6. Finally, async_io_task is an inter-
ruptible function to output buffered payloads from async_output.
The implementation of output_buffer would again be atomic to
ensure non-interference during the I/O operation. Indeed, I is free
Session 5A: Control System Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1366while True :
1 def worker :
2
3
4
5
6
sleep (1 s)
t = sync_input ()
if (t > threshold ):
async_output (" WARNING ")
Listing 2: Pseudo-code of the application enclaves A and B
to implement a wide range of policies for accepting and executing
I/O operations. A and B can attest I to be ensured that they use
an I/O implementation suitable to implement their requirements.
Application jobs. The application enclaves A and B can be im-
plemented as illustrated in Listing 2. A single function worker will
use the functionality provided by I to acquire sensor readings, eval-
uate these readings, and, if necessary, queue a warning message
with I. We assume that I is programmed such that our A and B
are guaranteed a free I/O buffer once per second, thus we do not
handle the exception. Other applications, in particular code that is
not enclaved, may not enjoy these guarantees and therefore need
to handle the exception. The application then schedules a sleep of
1 s and is guaranteed to be woken up by the scheduler when this
time period is elapsed, plus the scheduling margins summarized in
Table 3. Note that our application does not make use of clix and is
therefore interruptible. Making the execution of A and B entirely
atomic is neither feasible (nested clix with I are not allowed) nor
intended, as this would reduce the responsiveness of the overall
system. However, even if B would deviate from the behavior in
listing Listing 2 by performing a clix or causing a violation, this
would not impact the security or availability of A, which we discuss
more comprehensively in Section 6.
Our case study shows that applications and drivers can be im-
plemented such that, even in the presence of an uncooperative or
malicious application that monopolizes system resources and maxi-
mizes delays, well-behaving protected applications make progress
with deterministic latencies.
5.2 Performance Evaluation
One core performance metric of Aion implementations is the acti-
vation latency of applications. This activation latency is the time
from when an application should be scheduled up to the time when
control is actually passed over to it and it can start executing. In the
following we consider the best and worst-case activation latencies
for our prototype. An important characteristic of our prototype
implementation is that any operation that the scheduler performs
itself is atomic, i.e., interrupts are disabled during scheduler exe-
cution so that the scheduler will not interrupt itself. In addition to
regular scheduling, the scheduler also offers multiple operations
to applications that return back to the caller or switch to another
application. This means that activation latencies of application may
be delayed by currently running scheduler operations. We first eval-
uate the performance of each scheduler operation in the best and
worst-cases and use the results from this evaluation to perform an
in-depth analysis of the activation latency of pending applications.
All timing overheads below are measured in CPU cycles and
were retrieved through repeated measurements with the proto-
type implementation in a cycle-accurate simulation of Aion with
Verilator [37]. Note that all performance numbers depend on the
Table 2: Detailed overhead in observed cycles for the opera-
tions provided by the scheduler.
Scheduler operation
Create job
Exit job
Sleep
Yield
Get time
Best case (cycles)
worst-case (cycles)
688
512
1124
424
860
736
1320
628
212
implementation of the trusted scheduler and show observed cycles
only. Our prototype can only be seen as a baseline for real-world
performance, that could be improved substantially with additional
development effort.
Table 2 shows an overview over the timing overhead of all opera-
tions that applications can request from the scheduler. All scheduler
operations are carefully designed to have a constant worst-case exe-
cution time. The remaining differences between best and worst-case
execution time mostly depend on the amount of already scheduled
or pending applications in the system. Since the prototype imple-
mentation places a sensible upper bound on the number of maxi-
mum running or sleeping applications, the worst-case execution
times are strictly bounded and cannot be extended by adversaries.
The longest operation that an adversary can attempt is to sleep
while the maximum amount of other applications are already sleep-
ing, which means that the scheduler needs to insert a new timer into
a list of the maximum length. We observe a deterministic overhead
of 1320 cycles for this operation.
Building on these first evaluation numbers, we craft an attacker
that (i) enters an adversary-controlled enclave right before the
victim deadline, (ii) executes a clix of the maximum length, and
finally (iii) enters the scheduler with the worst-case sleep opera-
tion before the clix expires. At the end of the triggered scheduler
operation, the scheduler will then detect the pending interrupt and
process that interrupt instead of returning back to the adversary
or another application. This represents the longest chain of events
that an attacker can craft before a periodic enclave is executed.
Table 3 shows the best and worst-case latencies that are possible
for such an application deadline. In the absence of an attacker (i.e.,
in the best case), interrupts are already enabled (i.e., GIE=1) when
the application is to be woken up, and the exception engine can
process the interrupt immediately. In the presence of an attacker,
however, the attacker would perform the sequence of steps as de-
scribed above in order to delay the handling of the deadline. Since
in our implementation, interrupts are disabled during scheduler
operations, this prolongs the time until an interrupt is triggered
by the time of the running operation. This bounds the worst-case
latency between an issued interrupt and its actual processing in
the scheduler by a maximum of 2330 cycles (10 cycles of atomic
entry, 1000 of clix operation, followed by the 1320 cycles of the
worst-case sleep operation). Note, that the adversary does not ben-
efit from creating a violation during the last cycles of the clix
instruction as a violation is also handled by the scheduler which
can check whether other interrupts are currently pending before
resuming execution of a job.
Processing the interrupt in hardware takes 7 cycles if an unpro-
tected job is being interrupted, while interrupting enclaved jobs
Session 5A: Control System Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1367Table 3: Detailed overhead for an event that preempts a run-
ning job. Shown are measurements with default Aion pa-
rameters and the overheads in the best and worst-case. Val-
ues in parentheses show the worst-case in the absence of an
attacker and are zero for the crafted attacker scenario.
Task/Stage
1. Interrupt arrival
2. Interrupt processing
3. Scheduler entry
4.1 Timer
4.2 Scheduler run
5 Scheduler resume
Activation latency
Best case (cycles)
0
7
157
1356
443
72
2035
worst-case (cycles)
10 + clix + 1320
(35)
(115)
4075
443
72
5920 + clix
takes 35 cycles. The overhead stems from the additional work to
store the CPU context in the enclave versus only storing the pro-
gram counter and status register on the unprotected job’s stack.
This overhead is reversed on entering the scheduler for unprotected
code (157 cycles) versus entering the scheduler after interrupting an
enclave (115 cycles). In the crafted attacker scenario, the scheduler
can detect the pending interrupt at the end of the running operation
and before it would resume execution to the next application. Thus,
in the worst-case, steps 2 and 3 are skipped by the scheduler as it
can start processing the interrupt without needing to reenter itself.
In our prototype, processing a timer tick requires the processing
of all software timers to evaluate whether a software timer is ready
to be fired. This means that in the best case, no timer has to be
processed, leading to a latency of 1356 cycles while in the worst-case,
all 15 jobs currently have set a timer which leads to a latency of 4075
cycles. Identifying the next job to schedule takes a static duration
of 443 cycles as periodic enclaves are always scheduled with the
highest priority on the system. Resuming from the scheduler then
takes 72 cycles.
Overall, our prototype can guarantee an activation latency of
2035 cycles in the best and 6920 cycles in the worst-case. This means
that in the presence of an active adversary that controls all 14 other
threads besides the victim thread and performs the sequence of steps
as described above, our best-effort Aion prototype can guarantee
that the first guaranteed application to be scheduled is served at the
latest 6920 cycles after its trigger occurred. We discuss below what
activation latency can be given to any application other than the
first to be scheduled if multiple applications received guarantees
simultaneously.
6 DISCUSSION AND SECURITY ANALYSIS
Confidentiality and integrity. Firstly, our reliance on TEEs and
enclaved execution protects A and dependent code from a range of
attacks on confidentiality and integrity. TEEs and their limitations
are well understood in general [24] and for Sancus in particular [30].
For example, it is clear that enclaved applications must be developed
such that they are free of vulnerabilities that allow an attacker to
hijack the enclave’s control flow or to extract secrets. The TCB
reduction provided by TEEs helps to implement secure enclaves,
relying on extensive code reviews, testing, and formal verification,
which are orthogonal lines of research.
An important consideration to nuance the architectural confiden-
tiality guarantees offered by TEEs is information leakage through