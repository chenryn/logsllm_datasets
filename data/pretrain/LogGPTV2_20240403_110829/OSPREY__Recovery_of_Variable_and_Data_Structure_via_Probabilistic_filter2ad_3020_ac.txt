correctness of memory partition can be guaranteed. Although
these are very challenging tasks, addressing them is beyond
the scope of this paper. As discussed in Section VIII, there
are existing techniques [29], [6], [30], [31], [32], [33] that
particularly focus on these problems. A stack region for a
function f, denoted as Sf , models the stack frame that holds
local variables/structures for f. A heap region allocated at an
instruction i is denoted as Hi. A memory region r could be
any of the three kinds. A memory address a is represented
as (cid:104)r, o(cid:105), in which r stands for the region a belongs to and
o for a’s offset relative to the base of the region. A memory
chunk, which is a term we inherit from VSA [13], denotes
a variable-like smallest memory unit that is ever visited by
some instruction. It is represented as (cid:104)a, s(cid:105) where a models
the starting address of the unit and s its size. It may correspond
to a scalar variable, a data structure ﬁeld, or an array element
of some primitive type.
Consider the assemble code at instruction [11], “movups
in Figure 1b. As register rax acquires
[rax], xmm0”,
its value a = (cid:104)r = H08, o = 0(cid:105) from instruction [08], the
movups instruction accesses a 16-byte variable-like memory
chunk v = (cid:104)a = (cid:104)H08, 0(cid:105) , s = 16(cid:105).
Primitive Analysis Facts Collected by BDA. As the ﬁrst
step, we extend BDA to collect a set of basic facts. Recall
that BDA is a per-path abstract interpretation technique driven
by path sampling. It uses precise symbolic values (i.e., without
approximation) and interprets individual paths separately. One
can consider that BDA is analogous to executing the subject
binary on an abstract domain. It does not need to merges
values across paths like other abstract interpretation techniques
(e.g., VSA), so the abstract domain is precise instead of
approximate. We collect six types of facts such as memory
access behaviors and points-to relations, as presented in the
top of Figure 5. Speciﬁcally, Access(i, v, k) [F01] states that
instruction i accessed a memory chunk v for k times during
the sample runs. By precisely tracking data-ﬂow through both
registers and memory, BDA can determine the base address
of all offsetting operations. In particular, it looks for data-
ﬂow paths that starts by loading an address to a register,
Fig. 3: System design.
address), each denoted by a random variable. Here a memory
chunk is a smallest memory unit accessed by some instruc-
tion. A set of inference rules are introduced to describe
the correlations across these random variables. As such, a
random variable is constrained in multiple ways (by various
hints). In step 4(cid:13), these constraints/rules are transformed to a
probabilistic graph model. A customized inference algorithm
(developed from scratch) is then used to resolve these proba-
bilistic constraints to produce the posterior probabilities. Dif-
ferent from most existing probabilistic inference algorithms,
our algorithm is iterative to deal with on-the-ﬂy changes of
the constraints, which are inevitable due to the nature of
our problem. For example, ﬁnding a new likely array leads
to introduction of new predicates denoting its properties and
requires re-inference. Our algorithm is also optimized as most
existing inference engines cannot deal with the large number
of random variables in our context. Our optimization leverages
the modular characteristics commonly seen in programs and
program analysis. Finally, the most probable type and struc-
tural predicates are reported and further processed to generate
the ﬁnal variable, type, and structure declarations.
Background: BDA – Path Sampling Driven Per-path Ab-
stract Interpretation. The ﬁrst step of our technique is to
collect basic facts of the subject binary’s behaviors. Traditional
static analysis such as VSA [13] is not accurate (for larger
programs) [15]. Although dynamic analysis are accurate, they
need to have good quality input to achieve good coverage.
BDA is an advanced static analysis technique that aims to
achieve the beneﬁts of both. It uses a sophisticated path
sampling algorithm so that the different paths of a program
can be sampled uniformly. Note that simply tossing a fair coin
at each predicate leads to a distribution that is substantially
biased towards short paths. Uniform sampling allows exploring
a lot more long paths. For each sampled path, it performs
accurate abstract interpretation. As shown in [15], it produces
binary points-to results that are substantially better than VSA,
leading to much higher accuracy in downstream analysis.
IV. DETERMINISTIC REASONING
Before probabilistic inference, our technique performs de-
terministic reasoning, through which analysis facts are col-
lected and processed to derive a set of relations and hints. Such
information provides the needed abstraction so that the later
probabilistic inference, which is sensitive to problem scale,
does not have to be performed on the low-level facts.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
817
FFactsBinaryBDADeterministicReasoningProb. Constraint ConstructionRAbstract Relations/HintsProb. Constraint SolvingCConstraints/RulesSData Structures1234Primitive Analysis Facts
F01
F02
F03
F04
F05
F06
Access(i, v, k)
BaseAddr(i, v, a)
MemCopy(vs, vd)
PointsTo(v, a)
MallocedSize(i, s)
MayArrray(a, k, s)
: Memory chunk v was accessed by instruction i for k > 0 times during sampling.
:
Instruction i has accessed memory chunk v with base address a during sampling.
:
The value loaded from vs was stored to vd directly, or indirectly via register copying in the middle during sampling.
: Memory chunk v stored an address a during sampling.
:
:
The malloc function call at instruction i requested s bytes.
There may be an array with k elements, each s bytes, starting from address a.
SameRegion(a1, a2) : Bool
H01
H02 Offset(a1, a2) : Size ∪ {∞}
AdjacentChunk(v1, v2)∗ : Bool
H03
H04 OverlappingChunk(v1, v2)∗ : Bool
H05
Helper Functions
::= a1.r = a2.r
::= SameRegion(a1, a2) ? a1.o − a2.o : ∞ e.g., Offset((cid:104)S, 8(cid:105) , (cid:104)S, 0(cid:105)) = 8
::= Offset(v2.a, v1.a) = v1.s
::= Offset(v2.a, v1.a)  1
ah = max(AccessAddrsInRegion(i, r))
al = min(AccessedAddrsInRegion(i, r))
k = max({kt|Access(i, v, kt)}) ∧ Access(i, v, k) ∧ v.a = af
(|MallocedSizes(i)| = 1) ∧ (s ∈ MallocedSizes(i))
(|MallocedSizes(i)| > 1) ∧ (SizeDifferenceGCD(MallocedSizes(i)) = s)
as = vs.a ∧ ad = vd.a ∧ (Offset(v(cid:48)
d.a, ad) = s) ∧
SameRegion(as,v(cid:48)
as = vs.a ∧ ad = vd.a ∧ (Offset(v(cid:48)
SameRegion(as,v(cid:48)
s) ∧ Accessed(i2, v(cid:48)
Accessed(i2, v(cid:48)
d)
as = vs.a ∧ ad = vd.a ∧ (Offset(v(cid:48)
s.a, as) = Offset(v(cid:48)
SameRegion(as,v(cid:48)
PointsTo(vx, as) ∧ PointsTo(vx, ad)
s.a) ∧ SameRegion(ad,v(cid:48)
s.a) ∧ SameRegion(ad,v(cid:48)
s.a) ∧ SameRegion(ad,v(cid:48)
s.a, as) = Offset(v(cid:48)
s.a, as) = Offset(v(cid:48)
d.a, ad) = s) ∧
d.a, ad) = s) ∧
d.a) ∧ MemCopy(vs, vd) ∧ MemCopy(v(cid:48)
s, v(cid:48)
d)
d.a) ∧ Accessed(i1, vs) ∧ Accessed(i1, vd)∧
d.a) ∧ BaseAddr(−, v(cid:48)
s, as) ∧ BaseAddr(−, v(cid:48)
d, ad)
+Assuming ∀k ∈ [0, n), Offset(ak+1, ak) ≥ 0 and sk+1 − s ≥ 0 without losing generality.
∗Assuming Offset(v2.a, v1.a) ≥ 0 without losing generality
Fig. 5: Deterministic Reasoning Rules.
which is further copied to other registers or memory chunks,
incremented by constant offsets, and eventually dereferenced.
BaseAddr(i, v, a) [F02] denotes that i accessed a memory
chunk v whose base address is a. MemCopy(vs, vd) [F03]
states that chunk vs was copied to vd. It is abstracted from a
data-ﬂow path from a memory read to a memory write, with
possible register copies in the middle. PointsTo(v, a) [F04]
states that an address value a was ever stored to v. Intuitively,
one can consider v a pointer pointing to a. MallocedSize(i, s)
[F05] records that a memory allocation function invocation i
ever requested size s. MayArray(a, k, s)[F06] denotes that a
may start an array of k elements, each with size s. Similar
to Ghidra and IDA, these array-related hints are collected
via heuristics, e.g., by looking at the arguments of calloc
library call. We will show later that we have more advanced
inference rules for arrays. MayArray only denotes the direct
hints. Examples can be found in Appendix B.
Helper Functions. In the middle of Figure 5, we deﬁne a
number of helper functions that are derived from the six
kinds of basic analysis facts. These helper functions essentially
derive aggregated information across a set of primitive analysis
facts. They will be used in the inference rules discussed later.
Speciﬁcally, SameRegion(a1, a2) [H01] determines whether
two memory addresses belong to the same memory region.
Note that in Figure 5, the explanation and example for each
helper function are to its right. Offset(a1, a2)[H02] returns the
offset between two memory addresses, which equals to the
difference between their offset values if the two addresses be-
long to the same region, ∞ otherwise. AdjacentChunk(v1, v2)
[H03] determines if two memory chunks are next to each other.
AddrDifferenceGCD (a1, ..., an) [H05] returns the greatest
common divisor (GCD) of the differences of a list of sorted
addresses. SizeDifferenceGCD (s1, ..., sn) [H05] returns the
GCD of the differences between a list of sorted sizes. Mal-
locedSizes(i) [H06] returns the list of requested sizes from a
malloc-site i. AccessedAddrsInRegion(i, r) [H07] returns all
the addresses accessed by i in region r.
Deterministic Inference Rules. The goal of deterministic
inference is to derive additional relations that were not explicit.
In the lower half of Figure 5, we present the inference rules
in the following format.
T :− P1 ∧ P2 ∧ ··· ∧ Pn
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:33:02 UTC from IEEE Xplore.  Restrictions apply. 
818
T is the target relation and Pi
is a predicate. It means
that the satisfaction of predicates P1, P2, . . . , Pn leads to the
introduction of T . Observe that no probabilities are involved.
Speciﬁcally, Accessed(i, v) [R01] denotes if instruction i has
accessed memory chunk v and Accessed(v) [R02] denotes if v
has been accessed. They are derived from the primitive fact Ac-
cess(...) [F01]. The next two relations model the access pattern
of instruction i in memory region r. AccessSingleChunk(i, r)
[R03] denotes that
instruction i is always accessing only
one memory chunk in region r. A typical example is an
instruction writing to a constant address, e.g.,
instruction
“mov [0xdeadbeef],0”. AccessMultiChunks(i, r) [R04],
in contrast, denotes i accessed multiple chunks in r, such
as an instruction in some for-loop that accesses individual
elements in a memory buffer. HiAddrAccessed(i, r, ah)[R05]
dictates that ah is the highest address in r accessed by
i. LoAddrAccessed(i, r, al)[R06] is the inverse. MostFreqAd-
drAccessed(i, r, af , k) [R07] denotes af is the most frequently
accessed address in r by i.
The next two rules describe the allocation patterns. Con-