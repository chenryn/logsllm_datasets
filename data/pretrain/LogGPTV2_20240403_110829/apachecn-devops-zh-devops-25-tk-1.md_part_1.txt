# 一、根据资源使用情况自动缩放部署和状态集
Change is the essential process of all existence.
- *史巴克*
到目前为止，您可能已经理解了基于 Kubernetes 的系统的一个关键方面是高水平的动态性。几乎没有什么是静止的。我们定义部署或状态集，Kubernetes 将 Pods 分布在集群中。在大多数情况下，这些豆荚很少长时间坐在一个地方。滚动更新会导致重新创建 Pods，并可能将其移动到其他节点。任何类型的失败都会引发对受影响资源的重新安排。许多其他事件导致豆荚四处移动。Kubernetes 星团就像一个蜂巢。它充满了生命，而且总是在运动。
Kubernetes 集群的动态特性不仅仅是由于我们(人类)的行为或者由失败引起的重新调度。自动缩放也应该受到指责。我们应该完全接受 Kubernetes 的动态特性，并朝着能够在没有(太多)人工参与的情况下满足应用需求的自治和自给自足的集群发展。为此，我们需要提供足够的信息，让 Kubernetes 能够扩展应用以及构成集群的节点。在本章中，我们将重点讨论前一种情况。我们将探索基于内存和 CPU 消耗自动扩展 Pods 的常用和基本方法。我们将使用 HorizontalPodAutoscaler 来实现这一点。
HorizontalPodAutoscaler's only function is to automatically scale the number of Pods in a Deployment, a StatefulSet, or a few other types of resources. It accomplishes that by observing CPU and memory consumption of the Pods and acting when they reach pre-defined thresholds.
HorizontalPodAutoscaler 实现为 Kubernetes API 资源和控制器。资源决定控制器的行为。控制器定期调整状态集或部署中的副本数量，以使观察到的平均 CPU 利用率与用户指定的目标相匹配。
我们将很快看到 HorizontalPodAutoscaler 投入使用，并通过实际例子来评论它的具体特性。但是，在我们到达那里之前，我们需要一个 Kubernetes 集群以及一个度量源。
# 创建集群
在我们创建一个集群(或者开始使用一个你已经有的集群)之前，我们将克隆`vfarcic/k8s-specs`([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))存储库，它包含了我们将在本书中使用的大多数定义。
A note to Windows users
Please execute all the commands from this book from Git Bash. That way, you'll be able to run them as they are instead of modifying their syntax to adapt them to Windows terminal or PowerShell. All the commands from this chapter are available in the `01-hpa.sh` ([https://gist.github.com/vfarcic/b46ca2eababb98d967e3e25748740d0d](https://gist.github.com/vfarcic/b46ca2eababb98d967e3e25748740d0d)) Gist.
```
 1  git clone https://github.com/vfarcic/k8s-specs.git
 2
 3  cd k8s-specs
```
如果您之前克隆了存储库，请通过执行`git pull`确保您拥有最新版本。
下面的 gists 和规范用于测试本章中的命令。请在创建您自己的测试集群时使用它们作为灵感，或者验证您计划用于练习的集群是否满足最低要求。
*   `docker-scale.sh` : **Docker for Desktop** 带 2 个 CPU，2 GB RAM，带**tiller**([https://gist . github . com/vfarcic/ca 52 ff 97 fc 80565 af 0c 46 c 37449 babac](https://gist.github.com/vfarcic/ca52ff97fc80565af0c46c37449babac))。
*   `minikube-scale.sh` : **minikube** 带 2 个 CPU，2 GB RAM，带**tiller**([https://gist . github . com/vfarcic/5bc 07d 822 f 8825263245829715261 a68](https://gist.github.com/vfarcic/5bc07d822f8825263245829715261a68))。
*   `gke-scale.sh` : **带 3 个 n1-standard-1 工作节点的 GKE** 和带**分蘖**([https://gist . github . com/vfarcic/9c 777487 F7 ebee 6c 09027 d3a 1 df 8663 c](https://gist.github.com/vfarcic/9c777487f7ebee6c09027d3a1df8663c))。
*   `eks-scale.sh` : **EKS** 带 3 个 T2 .小工人节点和**分蘖**([https://gist . github . com/vfarcic/a94 dffef 7 d6dc 60 f 79570d 351 c 92408d](https://gist.github.com/vfarcic/a94dffef7d6dc60f79570d351c92408d))。
*   `aks-scale.sh` : **带有 3 个 Standard_B2s 工作节点的 AKS** 和带有**分蘖**([https://gist . github . com/vfarcic/f1b 05d 33 cc 8 a 98 e 4c eab 3d 3770 C2 feb](https://gist.github.com/vfarcic/f1b05d33cc8a98e4ceab3d3770c2fe0b))。
请注意，我们将使用 Helm 来安装必要的应用，但是我们将切换到“纯”Kubernetes YAML 来尝试本章中使用的(可能是新的)资源和部署演示应用。换句话说，我们将使用 Helm 进行一次性安装(例如，Metrics Server)，使用 YAML 进行我们将更详细探讨的事情(例如，HorizontalPodAutoscaler)。
现在，让我们谈谈度量服务器。
# 观察指标服务器数据
扩展 Pods 的关键元素是 Kubernetes 度量服务器。你可能认为自己是一个 Kubernetes 忍者，但从未听说过度量服务器。如果是这样，不要感到羞耻。你不是唯一一个。
如果您开始观察 Kubernetes 指标，您可能会使用 Heapster。它已经存在很长时间了，即使您不知道它是什么，您也可能会让它在您的集群中运行。两者都有相同的目的，其中一个暂时被否决了，所以让我们澄清一下。
早些时候，Kubernetes 引入了 Heapster 作为工具，为 Kubernetes 启用容器集群监控和性能分析。从 Kubernetes 1 . 0 . 6 版本开始就有了。你可以说 Heapster 从蹒跚学步的时候就已经是 Kubernetes 生活的一部分了。它收集并解释各种指标，如资源使用情况、事件等。Heapster 已经成为 Kubernetes 不可或缺的一部分，并使其能够适当地安排 Pods。没有它，Kubernetes 斯就会失明。它不知道哪个节点有可用内存，哪个 Pod 使用了过多的 CPU，等等。但是，就像大多数其他早期可用的工具一样，它的设计是一个“失败的实验”。
随着 Kubernetes 的不断发展，我们(Kubernetes 周围的社区)开始意识到需要一个新的、更好的，更重要的是，一个更可扩展的设计。因此，度量服务器诞生了。现在，即使 Heapster 仍在使用，它也被认为是不推荐使用的，即使今天(2018 年 9 月)度量服务器仍处于测试状态。
那么，什么是度量服务器？一个简单的解释是，它收集关于节点和 Pods 的已用资源(内存和 CPU)的信息。它不存储指标，所以不要认为你可以用它来检索历史值和预测趋势。还有其他工具可以实现这一点，我们将在后面探讨。相反，度量服务器的目标是提供一个可用于检索当前资源使用情况的应用编程接口。我们可以通过`kubectl`或者通过发送直接请求来使用该应用编程接口，比如说`curl`。换句话说，度量服务器收集集群范围的度量，并允许我们通过其应用编程接口检索它们。这本身非常有力，但只是故事的一部分。
我已经提到了扩展性。我们可以扩展度量服务器，从其他来源收集度量。我们会在适当的时候到达那里。目前，我们将探索它开箱即用地提供了什么，以及它如何与其他一些 Kubernetes 资源交互，这些资源将帮助我们使我们的 Pods 更具可扩展性和弹性。
如果你读了我的其他书，你会知道我不太喜欢理论，相反，我更喜欢通过实际例子来展示特征和原理。这本书也不例外，我们将直接进入度量服务器实践练习。第一步是安装它。
如果有图表的话，Helm 可以让几乎所有公开软件的安装变得非常容易。如果没有，您可能需要考虑一个替代方案，因为这清楚地表明供应商或其背后的社区不相信 Kubernetes。或者，也许他们没有开发图表所需的技能。无论哪种方式，最好的行动方案都是逃避它，采用替代方案。如果这不是一个选择，自己开发一个掌舵图。在我们的情况下，没有必要采取这样的措施。度量服务器确实有一个掌舵图，我们需要做的就是安装它。
A note to GKE and AKS users
Google and Microsoft already ship Metrics Server as part of their managed Kubernetes clusters (GKE and AKS). There is no need to install it, so please skip the commands that follow. A note to minikube users
Metrics Server is available as one of the plugins. Please execute   commands instead of those following. A note to Docker for Desktop users
Recent updates to the Metrics Server do not work with self-signed certificates by default. Since Docker for Desktop uses such certificates, you'll need to allow insecure TLS. Please add `--set args={"--kubelet-insecure-tls=true"}` argument to the `helm install` command that follows.
```
 1  helm install stable/metrics-server \
 2      --name metrics-server \
 3      --version 2.0.2 \
 4      --namespace metrics
 5
 6  kubectl -n metrics \
 7      rollout status \
 8      deployment metrics-server
```
我们用 Helm 安装了 Metrics Server，我们一直等到它推出。
度量服务器将定期从运行在节点上的库布雷获取度量。目前，这些指标包含 Pods 和节点的内存和 CPU 利用率。其他实体可以通过具有主度量应用编程接口的应用编程接口服务器向度量服务器请求数据。这些实体的一个例子是调度程序，一旦安装了度量服务器，它就使用其数据来做出决策。
正如您将很快看到的，度量服务器的使用超出了调度器的范围，但是目前，解释应该提供基本数据流的映像。
![](img/b3d2c07d-2505-4373-ae4c-181a83afb8c0.png)
Figure 1-1: The basic flow of the data to and from the Metrics Server (arrows show directions of data flow)
现在我们可以探索一种检索指标的方法。我们将从那些与节点相关的开始。
```
 1  kubectl top nodes
```
如果你很快，输出应该是`metrics are not available yet`。这很正常。执行度量检索的第一次迭代需要几分钟。唯一的例外是 GKE 和 AKS，它们已经加入了度量服务器。
在我们重复命令之前去拿些咖啡来。
```
 1  kubectl top nodes
```
这一次，输出不同。
In this chapter, I'll show the outputs from Docker for Desktop. Depending on the Kubernetes flavor you're using, your outputs will be different. Still, the logic is the same and you should not have a problem to follow along.
我的输出如下。
```
NAME               CPU(cores) CPU% MEMORY(bytes) MEMORY%
docker-for-desktop 248m       12%  1208Mi        63%
```
我们可以看到我有一个节点叫做`docker-for-desktop`。它使用 248 毫秒的中央处理器。由于节点有两个内核，这是总可用 CPU 的 12%。同样，使用 1.2 GB 的 RAM，这是 2 GB 总可用内存的 63%。
节点的资源使用是有用的，但不是我们要找的。在本章中，我们将重点介绍自动缩放 Pods。但是，在我们到达那里之前，我们应该观察我们的每个 Pods 使用了多少内存。我们将从那些在`kube-system`命名空间中运行的程序开始。
```
 1  kubectl -n kube-system top pod
```
输出(在桌面的 Docker 上)如下。
```
NAME                                       CPU(cores) MEMORY(bytes)
etcd-docker-for-desktop                    16m        74Mi
kube-apiserver-docker-for-desktop          33m        427Mi
kube-controller-manager-docker-for-desktop 44m        63Mi
kube-dns-86f4d74b45-c47nh                  1m         39Mi
kube-proxy-r56kd                           2m         22Mi
kube-scheduler-docker-for-desktop          13m        23Mi
tiller-deploy-5c688d5f9b-2pspz             0m         21Mi
```
我们可以看到当前在`kube-system`中运行的每个 Pods 的资源使用情况(CPU 和内存)。如果我们找不到更好的工具，我们可以利用这些信息来调整那些 Pods 的`requests`使其更加准确。然而，有更好的方法来获得这些信息，所以我们现在将跳过调整。相反，让我们尝试获取所有 Pods 的当前资源使用情况，无论名称空间如何。
```
 1  kubectl top pods --all-namespaces
```
输出(在桌面的 Docker 上)如下。
```
NAMESPACE   NAME                                       CPU(cores) MEMORY(bytes) 
docker      compose-7447646cf5-wqbwz                   0m         11Mi 
docker      compose-api-6fbc44c575-gwhxt               0m         14Mi 
kube-system etcd-docker-for-desktop                    16m        74Mi 
kube-system kube-apiserver-docker-for-desktop          33m        427Mi 
kube-system kube-controller-manager-docker-for-desktop 46m        63Mi 
kube-system kube-dns-86f4d74b45-c47nh                  1m         38Mi 
kube-system kube-proxy-r56kd                           3m         22Mi 
kube-system kube-scheduler-docker-for-desktop          14m        23Mi 
kube-system tiller-deploy-5c688d5f9b-2pspz             0m         21Mi 
metrics     metrics-server-5d78586d76-pbqj8            0m         10Mi 
```
该输出显示了与前一个相同的信息，只是扩展到了所有名称空间。应该没必要评论。
通常，Pod 的度量标准不够精细，我们需要观察构成 Pod 的每个容器的资源。我们需要做的就是添加`--containers`参数来获得容器度量。
```
 1  kubectl top pods \
 2    --all-namespaces \
 3    --containers
```
输出(在桌面的 Docker 上)如下。
```
NAMESPACE   POD                                        NAME                 CPU(cores) MEMORY(bytes) 
docker      compose-7447646cf5-wqbwz                   compose                 0m         11Mi 
docker      compose-api-6fbc44c575-gwhxt               compose                 0m         14Mi 
kube-system etcd-docker-for-desktop                    etcd                    16m        74Mi 
kube-system kube-apiserver-docker-for-desktop          kube-apiserver          33m        427Mi 
kube-system kube-controller-manager-docker-for-desktop kube-controller-manager 46m        63Mi 
kube-system kube-dns-86f4d74b45-c47nh                  kubedns                 0m         13Mi 
kube-system kube-dns-86f4d74b45-c47nh                  dnsmasq                 0m         10Mi 
kube-system kube-dns-86f4d74b45-c47nh                  sidecar                 1m         14Mi 
kube-system kube-proxy-r56kd                           kube-proxy              3m         22Mi 
kube-system kube-scheduler-docker-for-desktop          kube-scheduler          14m        23Mi 
kube-system tiller-deploy-5c688d5f9b-2pspz             tiller                  0m         21Mi 
metrics     metrics-server-5d78586d76-pbqj8            metrics-server          0m         10Mi 
```
我们可以看到，这一次，输出分别显示了每个容器。例如，我们可以观察分成三个容器(`kubedns`、`dnsmasq`、`sidecar`)的`kube-dns-*`吊舱的度量。
当我们通过`kubectl top`请求度量时，数据流几乎和调度器发出请求时一样。请求被发送到应用编程接口服务器(主度量应用编程接口)，它从度量服务器获取数据，而度量服务器又从运行在集群节点上的库布雷收集信息。
![](img/e5faabe0-8a82-4b4a-b2b3-7e8298f6dc0a.png)
Figure 1-2: The flow of the data to and from the Metrics Server (arrows show directions of data flow)
虽然`kubectl top`命令对于观察当前的指标很有用，但是如果我们想从其他工具访问它们，它就非常无用了。毕竟目标不是让我们坐在一个有`watch "kubectl top pods"`命令的终端前。那将是对我们(人类)天赋的浪费。相反，我们的目标应该是从其他工具中获取这些指标，并基于实时和历史数据创建警报和(也许)仪表板。为此，我们需要 JSON 或其他机器可解析格式的输出。幸运的是，`kubectl`允许我们以原始格式直接调用它的 API，并检索相同的结果，就像工具会查询它一样。
```
 1  kubectl get \
 2      --raw "/apis/metrics.k8s.io/v1beta1" \
 3      | jq '.'
```
输出如下。
```
{
  "kind": "APIResourceList",
  "apiVersion": "v1",
  "groupVersion": "metrics.k8s.io/v1beta1",
  "resources": [
    {
      "name": "nodes",
      "singularName": "",
      "namespaced": false,
      "kind": "NodeMetrics",
      "verbs": [
        "get",
        "list"
      ]
    },
    {
      "name": "pods",
      "singularName": "",
      "namespaced": true,
      "kind": "PodMetrics",
      "verbs": [
        "get",
        "list"
      ]
    }
  ]
}
```
我们可以看到`/apis/metrics.k8s.io/v1beta1`端点是一个索引 API，有两个资源(`nodes`和`pods`)。
让我们仔细看看度量 API 的`pods`资源。
```
 1  kubectl get \
 2      --raw "/apis/metrics.k8s.io/v1beta1/pods" \
 3      | jq '.'
```
输出太大，无法在书中呈现，所以我将让您自行探索。您会注意到，输出相当于我们通过`kubectl top pods --all-namespaces --containers`命令观察到的 JSON。
这是对度量服务器的快速概述。有两件重要的事情需要注意。首先，它提供集群内运行的容器的当前(或短期)内存和 CPU 利用率。第二点也是更重要的一点是，我们不会直接使用它。度量服务器不是为人类设计的，而是为机器设计的。我们稍后会到达那里。现在，请记住有一个叫做度量服务器的东西，您不应该直接使用它(一旦您采用了一个工具，将刮擦它的度量)。
现在我们已经探索了度量服务器，我们将尝试很好地使用它，并学习如何根据资源利用率自动扩展我们的 Pods。
# 基于资源利用率的自动扩展 Pods
我们的目标是部署一个应用，该应用将根据其资源使用情况自动缩放(或缩小)。我们将首先部署一个应用，然后讨论如何实现自动扩展。
I already warned you that I assume that you are familiar with Kubernetes and that in this book we'll explore a particular topic of monitoring, alerting, scaling, and a few other things. We will not discuss Pods, StatefulSets, Deployments, Services, Ingress, and other "basic" Kubernetes resources. This is your last chance to admit that you do NOT understand Kubernetes' fundamentals, to take a step back, and to read *The DevOps 2.3 Toolkit: Kubernetes* ([https://www.devopstoolkitseries.com/posts/devops-23/](https://www.devopstoolkitseries.com/posts/devops-23/)) and *The DevOps 2.4 Toolkit: Continuous Deployment To Kubernetes* ([https://www.devopstoolkitseries.com/posts/devops-24/](https://www.devopstoolkitseries.com/posts/devops-24/)*)*.
让我们看一下我们将在示例中使用的应用的定义。
```
 1  cat scaling/go-demo-5-no-sidecar-mem.yml
```
如果你熟悉 Kubernetes，YAML 的定义应该是不言自明的。我们将只评论与自动缩放相关的部分。
输出限于相关部分，如下所示。
```
...
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: db