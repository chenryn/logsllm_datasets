impact of both networks on our results.
Some users in each neighborhood only have a single connection
to other users. These isolated users later result in some communities
with a size of one and two. We applied a standard technique called
k-core [72] to extract the maximal connected subgraph of each of
the networks, where all nodes have a degree of at least k, here
k = 2.
After obtaining the k-core of all 300 networks, the mean neigh-
borhood size is 271, while some neighborhoods include more than
1000 users.
Figure 3(a) shows the histogram of the number of users (neigh-
borhood size) in 300 neighborhoods. After obtaining the k-core of
all 300 networks, the median for neighborhood size is 178 and the
mean is 271. Seven neighborhoods include more than 1000 users.
Figure 3(b) shows the histogram of timelines’ length in our dataset,
with an average value of 332 and a median of 177. Examining our
hypotheses on both small and large neighborhoods demonstrates
that our findings are not dependent on the size of a dataset or a
specific neighborhood.
In summary, the dataset for testing the first hypothesis includes
15,751,198 English tweets posted by a total of 82,275 users in 300
neighborhoods.
4.3 Community Detection
To find structural communities, we employed one of the most
widely accepted disjoint community detection algorithms, called
Infomap [69]. This algorithm has shown good performance in tests
using benchmark networks [43, 44].1 In Infomap, a community
is a partition that minimizes the average number of bits per step
required to describe trajectories of random walkers.
Infomap detects a total of 2,283 communities in our 300 neighbor-
hoods. While on average neighborhoods contain 8 communities, a
handful of them contain more than 30 communities. Figure 4 shows
the histograms for number of communities and their size resulting
from the Infomap community detection algorithm. The median for
number of communities in each neighborhood is 4 and the mean
1Among the variety of community detection methods, we evaluated the impact of a set
of them on our results, including Infomap [69], Spinglass [26], Walktrap [64], Leading
eigenvector [60], Fastgreedy [18] and Multilevel [7]. Interestingly, we obtained very
similar results while Infomap slightly outperforms the other algorithms.
Documents. As explained in Section 3.3, POISED divides the
timeline into several documents.Since on Twitter, some accounts are
older and some users post more often, the lengths of timelines can
differ substantially. Figure 3(b) shows the histogram of timelines’
length in our dataset, with an average value of 332 and a median of
177. On average, the users’ timeline include 332 posts. As explained
earlier, for each user we only consider at most 300 of the most
recent tweets for our analysis.
Each document contains a fixed l number of tweets. The number
of documents for a user depends on the number of tweets in the
user’s timeline. In our experiments, we investigated the impact of l
on the list of detected topics and found that there is not a significant
difference with a variation of l. Nonetheless, LDA detects topics
slightly more accurately with 20 tweets per document.
Topics. We cleaned the documents by removing URLs, and non-
printable characters. We removed stop words, a list of common
words found in the English language, to improve topic detection
and obtain detailed topics.
We employed the LDA implementation provided by Machine
Learning for Language Toolkit (MALLET) [53]. The output includes
documents labeled with a series of topics. We chose to label each
document with the topic having the highest weight value. Having
several documents for a user results in possibly several topics for
the user. If all the documents of a user are labeled with a particular
topic, then it shows that the user is interested in that specific topic.
MALLET requires a few parameters to apply LDA, such as the
amount of topics to be found in the given documents. We exper-
imented with various amounts of topics. Later, we show that the
best results are obtained with 500 topics. Moreover, we tested dif-
ferent amounts of tweets per document, and later show that the
best results are obtained with 20 tweets per document. In MALLET,
we also set the iteration count to 200, which provides more precise
topics at the expanse of a longer processing time.
050010001500020406080100Histogram050015002500350002000040000600008000010500001020304050Histogram0501001700200400600800100005001000150020005 EVALUATION: COMMUNITIES OF
INTEREST
In this section, we examine our first hypothesis that members of a
networked community have similar topics of interest.
5.1 Metrics and Null Model
We validate Hypothesis H1 on our dataset by computing three
entropy-based metrics: completeness, homogeneity, and V-measure of
topics detected in communities. These metrics were first proposed
by Rosenberg and Hirschberg [68], and have been commonly used
for evaluating many natural language processing tasks [19, 68].
All these three criteria produce a score in the interval of [0, 1],
with 1 being ‘good’ and 0 ‘bad.’ Completeness measures if all doc-
uments of a community are assigned to the same topic, e.g., they
are only about football. Symmetrically, homogeneity measures if
each topic is only observed in a single community, e.g., if all mes-
sages about a local art competition are posted by members of one
community. V-measure is the harmonic mean of completeness and
homogeneity and measures how successfully the two criteria are
met. The computation of these measures is independent of the num-
ber of documents and topics in the communities and the network.
By computing these three metrics, we are able to measure if the
members of a detected community are interested in the same topic.
To further validate that communities provide additional infor-
mation about members’ common interests, we propose comparing
their scores with those of a null model. Statisticians use null models
as baseline points of comparison for assessing goodness of fit [63].
Recently, null models have been used for studying network struc-
tures [16, 61, 63, 77] and community structures [56]. We generate a
null model that randomly partitions documents into groups.
To have a fair comparison between the documents in the actual
communities and those of the random clusters of the null model,
the documents are shuffled so that the distribution of size of groups
in the null model remains the same as in the detected communities
in the network, and the number of communities remains the same.
As a result, if the actual communities have higher scores, then our
hypothesis is validated that users in communities are grouped over
some specific topics of interest, and random clustering of documents
does not provide similar or better scores.
5.2 Communities Discuss Different Matters
While Community Members Talk About
Similar Topics
We examine Hypothesis H1 by comparing the communities of in-
terest that are detected in our neighborhoods with the random
communities of the null model.
Figure 5 compares the scores for these two models. To examine
the effect of the number of communities on the scores, Figure 5
presents them according to the number of communities in the
neighborhoods. The normal results denote the scores obtained from
the model created from actual communities, while the random
results show the results for the null model created from random
communities.
Figure 5: Both metrics highly decrease for the null model.
Figure 6: The metrics’ score slightly increase for 500 topics.
Overall, the tests with random communities show a substantial
drop in results. For communities of interest, on average, complete-
ness and homogeneity scores are about 0.16 and 0.90 respectively
while those scores are about 0.063 and 0.49 for random commu-
nities. We also ran a Z-test to compare the homogeneity and the
completeness values for actual and random communities. For both
metrics, the p-values are lower than 0.0001.
The completeness and homogeneity scores indicate that people in
the communities talk about certain topics that are mainly different
from those talked in other communities in their neighborhood. The
homogeneity results also confirm that communities of interest are
effectively distinguishable.
Some parameters can affect our evaluation of the first hypothesis.
For example, the total amount of possible topics is a fixed value
given as a parameter to MALLET. Also, we used a fixed amount of
tweets written into each document. Figure 6 shows the impact of
the amount of topics varying from 100 to 1000. As can be seen, the
amount of topics do not significantly change the scores.
Only the homogeneity score slightly varied, being 0.87 at its
maximum, when the topic count is 500. Similarly, we tested the
impact of document size varying from 5 to 300 tweets per document.
In summary, this parameter only affects the scores slightly (at most
0.17 in the range of [0,1]) and the best scores are provided when
the document contains 20 tweets.
To measure the impact of different community detection algo-
rithms, we also re-run the experiments for communities detected by
several of these algorithms. The topic detection by LDA is indepen-
dent of the community detection algorithm, and each community
includes topics detected for its members.
Figure 7: The communities and their topics of interest show
high homogeneity but relatively low completeness.
Figure 8: Size of groups of similar messages in the whole
dataset and labeled dataset.
(a) Global dataset
(b) Labeled dataset
Figure 7 shows the scores for various community detection algo-
rithms. These scores were calculated for each neighborhood, and
then averaged. It illustrates that no matter what community detec-
tion algorithm is used, the communities and their topics of interest
demonstrate high homogeneity, [0.8, 0.89]. Higher homogeneity
confirms that communities do have little topics in common and,
hence, are distinguishable. Considering its high homogeneity score,
Infomap was chosen to be applied by POISED. Similarly, no matter
what community detection algorithm is used, the completeness
between communities and their topics is about 0.25. The Walktrap
community detection algorithm provides communities with the
highest completeness, with a score of 0.31. These values show that,
for communities, not one but multiple topics are detectable.
Since the scores for the directed networks are slightly higher,
we used the directed networks for our analysis.
6 EVALUATION: TWITTER SPAM
DETECTION
Here, we examine our second hypothesis that benign and malicious
content diffuse through distinguishable parties of interest, which
can be used to detect Twitter spam messages.
6.1 Clustering Similar Messages
First, POISED needs to observe the diffusion of messages through
communities of interest to learn about their parties of interest. For
this, it applies four-gram analysis to detect similar messages in
every neighborhood. We cleaned tweets by removing stop words
and punctuation. Also, each URL is considered as a word.
In total, in our dataset, we found 1,219,991 groups of similar mes-
sages with the size range being between 2 and 94,382. Figure 8(a)
shows the CCDF of the size of groups of similar messages in our
dataset, which follows a power law distribution, with a small num-
ber of big groups and many small ones.
6.2 Create a Labeled Dataset
To evaluate the probabilistic models for spam detection, we need
to have a ground-truth dataset including both spam and benign
messages. Since it is not possible to manually label over 1 million
clusters of similar messages, we picked the top 5000 groups after
ordering them by their size, and labeled these groups. The group
size picked for labeling ranges from 68 to 94,382. We may find more
malicious campaigns by looking at larger clusters compared to all
data. However, many large clusters also contain benign messages
such as simple “happy birthday” wishes, as well as memes and
trending topics.
The tweets in this dataset were manually checked by a group of
14 security researchers who labeled them independently, following
a similar methodology to the one applied by previous work [14].
The researchers were advised on the risks of clicking on suspicious
links and took precautions not to get infected (e.g., by using virtual
machines to lookup URLs). Each group of similar tweets is evaluated
and labeled by three researchers, and then the majority vote is
considered as the final label. We provided some guidelines for the
researchers and defined some categories so that they can label each
tweet with one of those categories. These categories are defined as:
Spam: A message that is encouraging users to do something, such
as buying an item, voting for someone, visiting a URL, etc. Encour-
aging users is not by itself a malicious activity, however, if a tweet
is doing it, then a more careful assessment is needed. For example,
coders had to visit the websites these URLs refer to. If the URL is
suspicious, then the message is spam. Note that memes also may
include URLs. If in some cases, the URLs are not functional, then
the coders were advised to label the groups based on their subject,
and their tone.
App-generated: A message that is automatically posted by an ap-
plication on the user timeline. Some examples are weather alerts
posted by IFTTT2 and health-related reports posted by fitness track-
ers such as Fitbit.3 In the process, we also found that some of the
bigger clusters are the result of some apps such as Twittascope,
which regularly post tweets on behalf of the users. These tweets
usually contain links to some articles.
Quote: A message that is a popular quote. In the first round of
labeling, we found that many tweets consisted of quotes, so we
created a separate category for them, and asked the researchers to
fix their labels accordingly.
2https://ifttt.com
3https://www.fitbit.com
CCDF10110210310410510−310−210−1100CCDF10210310410510−310−210−1100Table 1: Examples of messages in each category
Spam
App-generated
Quote
Normal
“Fellas need a mix 2 get ur lady in the mood heres a mix to help u succeed. [_URL]”
“@X Listen To My Lul Song XXX Hot! Download And Share [_URL]”
“Wow! another great item; available on eBay [_URL]”
“WOW! No Cost Traffic For Your Website Home Based Business Blog Click Here Now Please #retweet [_URL]”
“4 tweeps unfollowed (goodbye!) me in the past week. Thank you [_URL].”
“New week; new tweets; new stats. 2 followers; 3 unfollowers. Via good old [_URL].”
“August 28; 201X #Fitbit activity: 11XXX steps taken; 5.XX miles walked/ran; and 2XXX calories burned.”
“Your key planet Venus is now moving through your 12th House of... More for Libra [_URL]”
“Either you run the day or the day runs you. - Jim Rohn”
“You’re only as good as the people you hire. - Ray Kroc”
“Do you want to know who you are? Don’t ask. Act! Action will delineate and define you. - Thomas Jefferson”
“Problems are only opportunities in work clothes. - Henry J. Kaiser”
“If you could ask a business consultant any question; what would you ask?”
“Brendan Rodgers: Liverpool boss has no plans to leave club [_URL]”
“RT @X: Thank you XX for last night. Hope you all enjoyed the show; you’ve always been lovely to us.”
“RT @X: Puppy caught eating paper decides killing the witness is the only way out [_URL]
Normal: A message that seems normal and has become popular
(trending) because of its content. Examples are memes about current
news and links to interesting reads, videos, photos, etc.
Unknown: If the coders were unsure about the category of a mes-
sage, they could choose ’Unknown.’ However, researchers were
advised to try not to choose this option.
Table 1 provides some examples of manually labeled messages.
Table 2 shows the size of each category after labeling all 5,000 clus-
ters of similar messages. It also shows the number of tweets in each
category. In total, by labeling these 5,000 groups, we obtained labels
for 1,277,833 tweets. As you can see, clusters of similar messages
are almost evenly labeled as normal (44%) and spam (42%). Most
tweets though are labeled as normal (38%) because groups labeled
as normal include more tweets. While only about 8% of groups are
labeled as app, they include about 33% of tweets.
Labeling the tweets also can be utilized to classify users into two
groups of spam and benign users. Table 2 shows the amount of
unique users identified in each category. The total amount of unique
users in all the groups is 66,788. However, some users appear in
multiple categories. For users who appear in both spam and normal
categories, three possible explanations are: First, spam accounts
may try to emulate normal users to avoid suspension by Twitter;
second, accounts may have been compromised, and, therefore, some
posts on their timeline are benign while others are spam; and, third,
their tweets are mislabeled.
Another interesting observation is that the amount of tweets in
the normal category is only about 5% and 10% more than that in the
spam and app categories, respectively, while the number of unique
users in the normal category is almost 4 and 6 times more than
that in the spam and app categories. These considerable differences
indicate that spam accounts or campaigns are responsible for larger
clusters that repeatedly post similar spam messages.
6.3 Identifying Parties of Interest
The probabilistic table representing the parties of interest is gen-