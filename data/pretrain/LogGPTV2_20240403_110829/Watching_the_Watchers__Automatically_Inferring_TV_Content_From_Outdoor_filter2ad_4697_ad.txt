50% reduced screen brightness level with room light off, 3) normal
screen brightness with the room light on. The obtained retrieval
results are shown in Table 2 and Figure 7.
Figure 7: Ratio to second-best under different illumination conditions.
The results indicate that higher screen brightness levels make
the retrieval slightly more successful as it takes shorter segment
lengths for successful retrieval and the similarity ratio is higher.
However, the inﬂuence of the screen brightness seems marginal. It
can also be seen from Table 2 and Figure 7 that even with the room
light on, our attack is successful with moderate segment length,
which we attribute that to our robust similarity metric. The only
effect that both the lower screen brightness and the active room
light have is that it mandates that longer segments are necessary for
successful retrieval in the worst case. This is expected, as in both
cases, smaller, less signiﬁcant brightness changes are not detectable
anymore. Accordingly, there are fewer distinguishing elements we
can use. In the case of the active room light, we only failed once
when retrieving a video based on a segment that was 270 seconds,
but succeeded with a 300 second segment. It is worth noting that
in the case of an active room light, a human observer is not able to
perceive the resulting subtle intensity changes on the wall.
7.2 Impact of Screen Size
The amount of light captured by a camera not only depends on
the screen’s illumination setting but also on the actual screen size as
it inﬂuences the amount of light emitted into the environment. Gen-
erally, bigger screens emanate more light, which leads to higher
quality video capture. To evaluate the impact of screen size, we
performed an experiment in which we used differently sized LCD
displays. In particular, we used displays with 24 inch, 30 inch, and
50 inch screen sizes. We again use a Canon Rebel T4i DSLR to
capture the video of the back wall, which is 3 m away from the
screen. For each screen size we capture ﬁve videos. The result-
ing required worst case segment lengths for successful retrieval are
shown in Table 3 while Figure 8 shows their distribution. The SNR
Figure 5: The median ratio within the dataset of 54,000 references.
Figure 6: Rank of correct video in the best case (blue) and worst case (red).
especially useful since it provides a measurement for an attacker of
how much video is needed to reliably achieve a successful attack.
To measure these boundaries we evaluate the retrieval success rates
for all possible sub-sequences longer than 10 seconds and all possi-
ble starting points for our 62 test sequences. For each of these tests
we then rank the retrieved videos by their similarity scores and re-
port the rank of the ground-truth video. If the corresponding video
is ranked ﬁrst the retrieval was successful, otherwise it was not.
Figure 6 shows the rank of the corresponding video with respect
to the captured video’s length for one of our test videos. The re-
sults for the other videos are comparable.
In the best case, the
corresponding reference video is always ranked ﬁrst, which means
if the attacker is lucky enough, she will be able to retrieve the cor-
rect video even if she only captures 10 seconds of video. The re-
sults also shows that any captured segment longer than 120 seconds
within this particular video can always be successfully retrieved.
Next, we summarize the results on a per-video basis by assign-
ing a video its worst segment’s similarity ranking, i.e., its worst
possible ranking obtained by any of the corresponding video for
any of its segments. This captures the lower bound of the attacks
performance for each of our 62 test videos. The results are shown
in Figure 10. Expectedly, the variation is the largest for the short-
est segments of less than 100 seconds and converges to one with
capture length longer than 240 seconds.
7.1 Lights On
The illumination of a scene (e.g., both room and natural light)
contribute signiﬁcantly to the amount of light entering the camera,
which in turn inﬂuences the brightness level of the captured video.
Obviously, screens with lower brightness naturally reduce the light
emanation. Therefore, we evaluate the inﬂuence of the illumination
425The results are shown in Figure 9. As expected, it can be seen
that the larger the database, the longer the segments have to be to
guarantee a successful retrieval. However, the increase in segment
length with respect to the increase in database size is moderate.
For example, for an increase in database size from 4,000 to 54,000
videos (13.5x), the segment length only increases by 20% (from
approximately 200 seconds to 240 seconds). We predict that this
increase will decline even more for larger databases as the proba-
bility of two identical video segments appearing in different videos
exponentially decreases with the length of the segment.
Figure 10: Rank of correct video (among 54,000 videos).
7.4 As Seen From Outdoors
Figure 8: Boxplot of the second-best ratio w.r.t. different screen sizes.
is lower because the experiment was performed in a different room
with a lot of light-absorbing materials.
Screen Size
SNR Worst Case Length
24 inch
30 inch
50 inch
5
48
109
270s
180s
180s
Table 3: Worst case capture length with different screen size.
Expectedly, the larger screen size supports better retrieval for
shorter segments. The shorter segments that fail on the 24 inch
screen can often be successfully retrieved with the 30 and the 50
inch screens. The similarity ratio is higher on larger screens leading
to more robust identiﬁcation.
7.3 Impact of Reference Library Size
Figure 9: Rank of correct video among libraries of size 1,000 and 4,000.
The retrieval results are inﬂuenced by the distribution of the videos
within the database and the size of the database. To characterize the
change in behavior we compute the worst case ranking for two ref-
erence libraries consisting of 1000 and 4000 videos respectively.
Figure 11: TV reﬂection in the room is captured from a distance of 13.5
meters (left). The worst case results (right) are illustrated for different types
of videos: TV shows, music and ﬁlm from top to bottom. All segments
longer than 180s were successfully retrieved.
To further demonstrate the practicality of our proposed attack,
we tested its effectiveness from outdoors. We captured the ema-
nations seem on an outside window of a room with a TV showing
60 of our test sequences. In this scenario, the attacker was posi-
tioned on the sidewalk observing the third ﬂoor ofﬁce window of
426the room with the TV (see Figure 11). The TV emanations re-
ﬂected off the beige ceiling of the room and towards the window
which was situated orthogonal to the TV. The TV is 13.5 meters
away from the adversary. For completeness, we evaluated our ap-
proach using videos from varying categories of media that include
TV shows, music videos and ﬁlms. 20 samples of each video type
were captured. Figure 11 (right) shows the worst case result with
respect to different subsequences. The results indicate similar suc-
cess across all videos tested, and in all cases, we were able to per-
form the conﬁrmation attack.
To guage the robustness of our approach, we further experimented
with recordings captured at much further distances. In this case,
the attacker was positioned on the sidewalk 70.9 meters from the
building; the TV was playing in the same third-ﬂoor room as in
the previous experiment. TV emanations were captured from the
ceiling reﬂection with the same Canon Camrecorder. 20 sequences
randomly selected from different categories are tested. The pro-
posed approach successfully retrieved 18 sequences out of them
within 5 minutes. The experimental setting and results are depicted
in Figure 12. The results are compared with that of direct view and
13.5 meter reﬂection (Figure 12 bottom). In the worst case, the se-
quence can usually be retrieved within 100 seconds at 13.5 meters
away, compared to 190 seconds, on average, from 70 meters away.
Figure 12: TV reﬂection in the room is captured from a distance of 70.9
meters(top). The camera and the window are labelled in red(top right). The
required capture length is compared with direct view and 13.5 meter reﬂec-
tion (bottom). It takes longer for successful retrieval with longer distance.
8. MITIGATIONS
The simplest mitigation is to cover the windows of the room with
blackout curtains to effectively avoid the leakage of the light to the
outside. To guage the effectiveness of such a defense we performed
a rudimentary experiment with vinyl blinds and curtains (see Figure
13)3. The setup was the same as for the attack carried out at 13.5
meters outdoors, except for the use of shades. In this experiment,
only two samples were tested in each case. For the case of vinyl
blinds and a standard beige curtain with brown stripes, we were still
able to determine 3 of the 4 videos being watched after capturing
3The brighter pattern in the middle picture is caused by a reﬂection
on the vinyl blinds from an outside street lamp.
270s worth of footage. The other video failed to be recovered even
after 5 mins. We were unable to conﬁrm any of the watched content
when thicker, room darkening, (black) curtains were used.
Figure 13: Captured image directly from window (left), through vinyl
blinds (middle) and through a curtain (right).
If the use of curtains is not desired the screen brightness could
be lowered to increase the SNR of any captured video. Our experi-
mental evaluation demonstrated though that this has only a limited
effect on twarting the attack. Our experiments show that retrieval
will still be possible as long as the brightness change is perceptible.
Although this strategy would not prevent the attack altogether, low-
ering the screen brightness will increase the burden on the attacker
as longer observations would be required to successfully carry out
the attack. Similarly, the burden on the attacker can be increased if
a bright room light is used as that would increase the noise level in
the captured signal.
Another defensive strategy may be to install a ﬂood light next
to any window of the room so as to effectively blind a camera that
tries to observe the diffusions through the window. Doing so would
prevent the camera from capturing the subtle brightness changes
required to successfully execute the attack. That said, a motivated
attacker could overcome this defense by using sophisticated high
dynamic range image cameras, which can capture a large dynamic
range of light intensities. Alternatively, our attack could be mit-
igated by installing an adaptive lighting system, which measures
the emitted light and counters any brightness change of the emit-
ted light. Doing so would help maintain a constant amount of light
emission and would not reveal the brightness change information to
an outside observer. Obviously, these defenses would not be popu-
lar in densely populated areas as the outdoor light emissions would
likely not be appreciated by neighbors.
9. CONCLUSIONS
We propose a novel method to identify the video content shown
on a victim’s screen using recordings collected in a number of
practical scenarios (e.g., observations of light effusions through
the windows or off the walls) and at great distances (e.g., 70m
away). Our attack shows reliable identiﬁcation of the content being
watched in a wide range of evaluated scenarios. The robustness of
the attack is due to a novel application of unique feature sets, a well
suited similarity metric, and the development of efﬁcient index-
ing structures for performing rapid matches in near real-time. Our
empirical results show that we can successfully conﬁrm hypothe-
ses while capturing short recordings (typically less than 4 minutes
long) of the changes in brightness from the victim’s display.
10. ACKNOWLEDGEMENTS
We are thankful to Michael Bailey, Kevin Snow, and the anony-
mous reviewers for their insightful comments and suggestions. This
work is supported in part by a grant from the National Science
Foundation, under award number 1148895.
427References
[1] M. Backes, M. Durmuth, and D. Unruh. Compromising
reﬂections-or-how to read LCD monitors around the corner.
In Proceedings of the IEEE Symposium on Security and
Privacy, 2008.
[2] J. L. Bentley. Multidimensional binary search trees used for
associative searching. Communications of the ACM, 18(9):
509–517, 1975.
[3] A. Buades, B. Coll, and J.-M. Morel. A review of image
denoising algorithms, with a new one. Multiscale Modeling
& Simulation, 4(2):490–530, 2005.
[4] M. Enev, S. Gupta, T. Kohno, and S. N. Patel. Televisions,
video privacy, and powerline electromagnetic interference.
In Proceedings of the 18th ACM conference on Computer
and communications security, pages 537–550. ACM, 2011.
[5] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast
subsequence matching in time-series databases. ACM
International Conference on Management of Data
(SIGMOD), 23(2), 1994.
[6] D. Gomery. As the dial turns. The Wilson Quarterly, pages
41–46, 1993.
[7] U. Greveler, B. Justus, and D. Loehr. Multimedia content
identiﬁcation through smart meter power usage proﬁles.
Computers, Privacy and Data Protection, 2012.
[8] G. E. Healey and R. Kondepudy. Radiometric ccd camera
calibration and noise estimation. Pattern Analysis and
Machine Intelligence, IEEE Transactions on, 16(3):267–276,
1994.
[9] M. G. Kuhn. Compromising emanations of lcd tv sets.
Electromagnetic Compatibility, IEEE Transactions on, 55(3):
564–570, 2013.
[10] B. Langmead, C. Trapnell, M. Pop, S. L. Salzberg, et al.
Ultrafast and memory-efﬁcient alignment of short dna
sequences to the human genome. Genome Biol, 10(3):R25,
2009.
[11] J. Liu, Z. Huang, H. Cai, H. T. Shen, C. W. Ngo, and
W. Wang. Near-duplicate video retrieval: Current research
and future trends. ACM Computing Surveys (CSUR), 45(4):
44, 2013.
[12] Y.-S. Moon, K.-Y. Whang, and W.-S. Han. General match: a
subsequence matching method in time-series databases based
on generalized windows. In Proceedings of the 2002 ACM
SIGMOD international conference on Management of data,
pages 382–393. ACM, 2002.
[13] R. Raguram, A. M. White, Y. Xu, J.-M. Frahm, P. Georgel,
and F. Monrose. On the privacy risks of virtual keyboards:
automatic reconstruction of typed input from compromising
reﬂections. Dependable and Secure Computing, IEEE
Transactions on, 10(3):154–167, 2013.
[14] A. Torralba and W. T. Freeman. Accidental pinhole and
pinspeck cameras: revealing the scene outside the picture. In
Computer Vision and Pattern Recognition (CVPR), 2012
IEEE Conference on, pages 374–381. IEEE, 2012.
[15] Y. Tsin, V. Ramesh, and T. Kanade. Statistical calibration of
ccd imaging process. In Computer Vision, 2001. ICCV 2001.
Proceedings. Eighth IEEE International Conference on,
volume 1, pages 480–487. IEEE, 2001.
[16] B. Widrow and I. Kollár. Quantization noise: roundoff error
in digital computation, signal processing, control, and
communications. Cambridge University Press, 2008.
[17] Y. Xu, J. Heinly, A. M. White, F. Monrose, and J.-M. Frahm.
Seeing double: reconstructing obscured typed input from
repeated compromising reﬂections. In Proceedings of the
2013 ACM SIGSAC conference on Computer &
communications security, pages 1063–1074. ACM, 2013.
[18] L. Zhang and Y. Rui. Image search–from thousands to
billions in 20 years. ACM Transactions on Multimedia
Computing, Communications, and Applications
(TOMCCAP), 9(1s):36, 2013.
428