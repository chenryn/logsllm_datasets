### 5.3 Impact of Screen Brightness and Room Lighting

To evaluate the impact of screen brightness and room lighting on the retrieval performance, we conducted experiments under three conditions:
1. 50% reduced screen brightness with room light off.
2. Normal screen brightness with room light off.
3. Normal screen brightness with room light on.

The results are presented in Table 2 and Figure 7.

**Figure 7: Ratio to Second-Best Under Different Illumination Conditions**

Our findings indicate that higher screen brightness levels slightly improve the retrieval success rate. This is evidenced by shorter required segment lengths for successful retrieval and higher similarity ratios. However, the influence of screen brightness appears to be marginal. As shown in Table 2 and Figure 7, even with the room light on, our attack remains successful with moderate segment lengths, which we attribute to our robust similarity metric.

The primary effect of both lower screen brightness and active room lighting is that they necessitate longer segments for successful retrieval in the worst-case scenarios. This is expected, as in both conditions, smaller, less significant brightness changes become undetectable. Consequently, there are fewer distinguishing elements available for retrieval. In the case of active room lighting, we failed once when attempting to retrieve a video based on a 270-second segment but succeeded with a 300-second segment. It is worth noting that, in the presence of active room lighting, a human observer cannot perceive the subtle intensity changes on the wall.

### 5.4 Impact of Screen Size

The amount of light captured by a camera depends not only on the screen's illumination setting but also on the actual screen size, as it influences the amount of light emitted into the environment. Generally, larger screens emit more light, leading to higher quality video capture. To evaluate the impact of screen size, we performed an experiment using differently sized LCD displays: 24 inches, 30 inches, and 50 inches. We used a Canon Rebel T4i DSLR to capture the video of the back wall, which was 3 meters away from the screen. For each screen size, we captured five videos.

**Table 3: Worst Case Capture Length with Different Screen Sizes**

| Screen Size | SNR | Worst Case Length (s) |
|-------------|-----|-----------------------|
| 24 inch     | 5   | 270                   |
| 30 inch     | 48  | 180                   |
| 50 inch     | 109 | 180                   |

**Figure 8: Boxplot of the Second-Best Ratio w.r.t. Different Screen Sizes**

As expected, larger screen sizes support better retrieval for shorter segments. Segments that fail on the 24-inch screen can often be successfully retrieved with the 30-inch and 50-inch screens. The similarity ratio is higher on larger screens, leading to more robust identification.

### 5.5 Impact of Reference Library Size

The retrieval results are influenced by the distribution of videos within the database and the size of the database. To characterize this behavior, we computed the worst-case ranking for two reference libraries consisting of 1,000 and 4,000 videos, respectively.

**Figure 9: Rank of Correct Video Among Libraries of Size 1,000 and 4,000**

The results show that, as expected, the larger the database, the longer the segments must be to guarantee a successful retrieval. However, the increase in segment length with respect to the increase in database size is moderate. For example, increasing the database size from 4,000 to 54,000 videos (a 13.5x increase) only requires a 20% increase in segment length (from approximately 200 seconds to 240 seconds). We predict that this increase will decline further for even larger databases, as the probability of two identical video segments appearing in different videos exponentially decreases with the length of the segment.

**Figure 10: Rank of Correct Video (Among 54,000 Videos)**

### 5.6 As Seen From Outdoors

To further demonstrate the practicality of our proposed attack, we tested its effectiveness from outdoors. We captured the emanations seen through an outside window of a room with a TV showing 60 of our test sequences. The attacker was positioned on the sidewalk, observing the third-floor office window of the room with the TV (see Figure 11). The TV emanations reflected off the beige ceiling of the room and towards the window, which was situated orthogonal to the TV. The TV was 13.5 meters away from the adversary.

**Figure 11: TV Reflection in the Room Captured from a Distance of 13.5 Meters (Left). The Worst Case Results (Right) for Different Types of Videos: TV Shows, Music, and Film from Top to Bottom. All Segments Longer than 180s Were Successfully Retrieved.**

We evaluated our approach using videos from varying categories, including TV shows, music videos, and films. Twenty samples of each video type were captured. The results indicate similar success across all videos tested, and in all cases, we were able to perform the confirmation attack.

To gauge the robustness of our approach, we further experimented with recordings captured at much greater distances. In this case, the attacker was positioned on the sidewalk 70.9 meters from the building, and the TV was playing in the same third-floor room as in the previous experiment. TV emanations were captured from the ceiling reflection using the same Canon Camcorder. Twenty randomly selected sequences from different categories were tested. Our approach successfully retrieved 18 out of 20 sequences within 5 minutes.

**Figure 12: TV Reflection in the Room Captured from a Distance of 70.9 Meters (Top). The Camera and the Window Are Labeled in Red (Top Right). The Required Capture Length Is Compared with Direct View and 13.5 Meter Reflection (Bottom). It Takes Longer for Successful Retrieval with Longer Distance.**

In the worst case, the sequence can usually be retrieved within 100 seconds at 13.5 meters away, compared to 190 seconds, on average, from 70 meters away.

### 6. Mitigations

The simplest mitigation is to cover the windows of the room with blackout curtains to effectively prevent the leakage of light to the outside. To gauge the effectiveness of such a defense, we performed a rudimentary experiment with vinyl blinds and curtains (see Figure 13).

**Figure 13: Captured Image Directly from Window (Left), Through Vinyl Blinds (Middle), and Through a Curtain (Right)**

The setup was the same as for the attack carried out at 13.5 meters outdoors, except for the use of shades. In this experiment, only two samples were tested in each case. For the case of vinyl blinds and a standard beige curtain with brown stripes, we were still able to determine 3 of the 4 videos being watched after capturing 270 seconds of footage. The other video failed to be recovered even after 5 minutes. We were unable to confirm any of the watched content when thicker, room-darkening (black) curtains were used.

If the use of curtains is not desired, the screen brightness could be lowered to increase the signal-to-noise ratio (SNR) of any captured video. Our experimental evaluation demonstrated that this has only a limited effect on thwarting the attack. Retrieval will still be possible as long as the brightness change is perceptible. Although this strategy would not prevent the attack altogether, lowering the screen brightness will increase the burden on the attacker, as longer observations would be required to successfully carry out the attack. Similarly, the burden on the attacker can be increased if a bright room light is used, as this would increase the noise level in the captured signal.

Another defensive strategy may be to install a floodlight next to any window of the room to effectively blind a camera that tries to observe the diffusions through the window. Doing so would prevent the camera from capturing the subtle brightness changes required to successfully execute the attack. However, a motivated attacker could overcome this defense by using sophisticated high-dynamic-range (HDR) cameras, which can capture a large dynamic range of light intensities. Alternatively, our attack could be mitigated by installing an adaptive lighting system, which measures the emitted light and counters any brightness change of the emitted light. This would help maintain a constant amount of light emission and would not reveal the brightness change information to an outside observer. Obviously, these defenses would not be popular in densely populated areas, as the outdoor light emissions would likely not be appreciated by neighbors.

### 7. Conclusions

We propose a novel method to identify the video content shown on a victim’s screen using recordings collected in a number of practical scenarios (e.g., observations of light effusions through windows or off walls) and at great distances (e.g., 70 meters away). Our attack shows reliable identification of the content being watched in a wide range of evaluated scenarios. The robustness of the attack is due to a novel application of unique feature sets, a well-suited similarity metric, and the development of efficient indexing structures for performing rapid matches in near real-time. Our empirical results show that we can successfully confirm hypotheses while capturing short recordings (typically less than 4 minutes long) of the changes in brightness from the victim’s display.

### 8. Acknowledgements

We are thankful to Michael Bailey, Kevin Snow, and the anonymous reviewers for their insightful comments and suggestions. This work is supported in part by a grant from the National Science Foundation, under award number 1148895.

### References

[1] M. Backes, M. Durmuth, and D. Unruh. Compromising reflections—or how to read LCD monitors around the corner. In Proceedings of the IEEE Symposium on Security and Privacy, 2008.

[2] J. L. Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9): 509–517, 1975.

[3] A. Buades, B. Coll, and J.-M. Morel. A review of image denoising algorithms, with a new one. Multiscale Modeling & Simulation, 4(2): 490–530, 2005.

[4] M. Enev, S. Gupta, T. Kohno, and S. N. Patel. Televisions, video privacy, and powerline electromagnetic interference. In Proceedings of the 18th ACM conference on Computer and communications security, pages 537–550. ACM, 2011.

[5] C. Faloutsos, M. Ranganathan, and Y. Manolopoulos. Fast subsequence matching in time-series databases. ACM International Conference on Management of Data (SIGMOD), 23(2), 1994.

[6] D. Gomery. As the dial turns. The Wilson Quarterly, pages 41–46, 1993.

[7] U. Greveler, B. Justus, and D. Loehr. Multimedia content identification through smart meter power usage profiles. Computers, Privacy and Data Protection, 2012.

[8] G. E. Healey and R. Kondepudy. Radiometric CCD camera calibration and noise estimation. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 16(3): 267–276, 1994.

[9] M. G. Kuhn. Compromising emanations of LCD TV sets. Electromagnetic Compatibility, IEEE Transactions on, 55(3): 564–570, 2013.

[10] B. Langmead, C. Trapnell, M. Pop, S. L. Salzberg, et al. Ultrafast and memory-efficient alignment of short DNA sequences to the human genome. Genome Biol, 10(3): R25, 2009.

[11] J. Liu, Z. Huang, H. Cai, H. T. Shen, C. W. Ngo, and W. Wang. Near-duplicate video retrieval: Current research and future trends. ACM Computing Surveys (CSUR), 45(4): 44, 2013.

[12] Y.-S. Moon, K.-Y. Whang, and W.-S. Han. General match: a subsequence matching method in time-series databases based on generalized windows. In Proceedings of the 2002 ACM SIGMOD international conference on Management of data, pages 382–393. ACM, 2002.

[13] R. Raguram, A. M. White, Y. Xu, J.-M. Frahm, P. Georgel, and F. Monrose. On the privacy risks of virtual keyboards: automatic reconstruction of typed input from compromising reflections. Dependable and Secure Computing, IEEE Transactions on, 10(3): 154–167, 2013.

[14] A. Torralba and W. T. Freeman. Accidental pinhole and pinspeck cameras: revealing the scene outside the picture. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 374–381. IEEE, 2012.

[15] Y. Tsin, V. Ramesh, and T. Kanade. Statistical calibration of CCD imaging process. In Computer Vision, 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on, volume 1, pages 480–487. IEEE, 2001.

[16] B. Widrow and I. Kollár. Quantization noise: roundoff error in digital computation, signal processing, control, and communications. Cambridge University Press, 2008.

[17] Y. Xu, J. Heinly, A. M. White, F. Monrose, and J.-M. Frahm. Seeing double: reconstructing obscured typed input from repeated compromising reflections. In Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security, pages 1063–1074. ACM, 2013.

[18] L. Zhang and Y. Rui. Image search–from thousands to billions in 20 years. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP), 9(1s): 36, 2013.