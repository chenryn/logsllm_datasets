DITL collection (April 2019).
Not all of the source IP addresses extracted from the DITL data
were acceptable targets for our experiment. We excluded about
4 million addresses designated as “special purpose” addresses by
IANA [9]; for these addresses, there would be no legitimate en-
tries in public routing table. We excluded another 36,027 source
IP addresses for which there was no announced route from which
we could derive other-prex addresses from the same AS (see Sec-
tion 3.2). Ultimately, our set of target IP addresses consisted of
11,204,889 IPv4 addresses and 784,777 IPv6 addresses, from 53,922
and 7,904 ASes, respectively.
3.2 Spoofed Sources
The set of source addresses for each target was selected with the
intent of maximizing the chances that the target would accept a
query. If the server rejected a query, we could not systematically
know if that query had penetrated a network border. For any given
target IP address, we issued as many as 101 DNS queries using
spoofed sources from the following categories:
• Other prex: up to 97 other-prex addresses (explained here-
after).
• Same prex: an IP address from the same /24 (IPv4) or /64
(IPv6) prex.
• Private or unique local: 192.168.0.10 or fc00::10.
• Destination-as-source: the target IP address itself.
• Loopback: 127.0.0.1 or ::1.
The other-prex addresses were generated as follows. We rst
looked up the AS number (ASN) for every target IP address. For
each ASN in the resulting set, we looked up all the IP prexes
originating from that AS. The next steps depended on whether the
IP address and ASN were associated with IPv4 or IPv6.
For IPv4, we divided all the IP address space originating from
an AS into 24-bit prexes. Every /24 prex containing a target
IP address was set aside for random selection of a same-prex IP
address. From each of the remaining /24 prexes, we selected, at
random, a single IP address. In both cases, the rst and the last IP
addresses were excluded from selection because of their reserved
status in a /24 subnet. The resulting IP addresses formed the set
of other-prex addresses for any target IP address announced by
that AS. Because some ASes had a prohibitively large number of
/24 prexes, we limited our selection to 97 prexes2.
For IPv6, we similarly divided each AS’s aggregate IP address
space, but we used a 64-bit prex, which is the typical prex length
for IPv6 subnets. As with IPv4, we selected an IP address from within
each /64 prex announced by the AS—for both the same-prex and
other-prex addresses. However, we used a more targeted method-
ology to identify more realistic client addresses, rather than blindly
probing the sparsely-populated IPv6 address space. First, for IPv6
prex selection, we gave preference to /64 prexes that contained
IPv6 addresses from an IPv6 “hit list” [21]—a sign of observed activ-
ity within that prex. Second, address selection within a /64 prex
was limited to the rst 100 addresses in the /64 prex (minus the
rst two addresses, often used for the router address).
3.3 Query Names
We encoded the query names used in our experiment according to
the following template: ts.src.dst.asn.kw.dns-lab.org, where ts
is the timestamp the query was sent, src is the spoofed-source IP
address, dst is the target IP address, asn is the ASN of the target IP
address, and kw is a keyword associated with the current experi-
ment. With this template, we could associate any query arriving at
the dns-lab.org authoritative servers (under our control) with the
experimental query that induced it. The use of a timestamp in the
query name ensured the uniqueness of a given query such that it
would never be in the cache of a recursive resolver.
Our primary interest was whether a query with one of the ex-
perimental query names reached our authoritative DNS servers.
We did not see any particular benet to making the experimental
query names actually resolve. Therefore, to simplify our setup, our
authoritative servers returned an NXDOMAIN (name does not exist)
response code in response to any experimental queries. When an-
alyzing our data, however, we learned that there were some side
eects associated with this approach that caused some gaps in our
2The number 97 was chosen when we had three other spoofed-source categories in
mind, such that the maximum number of source IP addresses we would use for a given
target would be an even 100. However, we ended up adding another source IP address
to our experiment, such that at most 101 sources would be used to query a given target.
67
IMC ’20, October 27–29, 2020, Virtual Event, USA
Casey Deccio, Alden Hilton, Michael Briggs, Trevin Avery, and Robert Richardson
experiment visibility. We discuss these side eects and quantify
their impact on our analysis in Section 3.6.4.
3.4 Query Execution
The queries were scheduled such that the entire experiment would
be carried out in about four weeks time. Considering the number of
target IP addresses and the sources for each, the rate of DNS queries
leaving our client maintained a rate of roughly 700 queries per
second—which was an administrative constraint we were required
to work with. We spaced the queries for a given target IP address
such that they were evenly spread over the entire duration of the
experiment.
The queries associated with our experiment were issued between
November 6 and December 27, 2019, from a network that lacked
OSAV (BCP 38 [20]). The absence of OSAV in our client’s network
was a requirement for eectively testing DSAV. The time frame for
our experiment was longer than the four weeks we had planned
because of several unexpected interruptions, including a power
outage. Despite the gaps in our experimental activity, we were able
to successfully issue all of the prepared queries associated with the
experiment, albeit behind schedule.
3.5 Follow-Up Queries
We monitored authoritative DNS server logs to detect incoming
queries that had been generated as a result of our activity, in real
time. Whenever we rst observed a DNS query associated with a
given target IP address, a series of follow-up queries were issued to
that target IP address. The follow-up queries were sent using the
same spoofed-source address as that which induced the query rst
observed at our authoritative servers. Subsequent queries associated
with the target IP address (i.e., beyond the rst) were logged but
not further acted on; thus, a given target IP address only received
one set of follow-up queries. The follow-up queries included:
• IPv4- and IPv6-only: two sets of 10 queries that elicited queries
exclusively over IPv4 and IPv6, respectively, to our authori-
tative servers.
• Open resolver: non-spoofed-source query.
• TCP: a query that elicited a DNS-over-TCP query to our
authoritative servers.
The IPv4- and IPv6-only queries were elicited by using query names
in DNS domains that were only delegated to IPv4 addresses or IPv6
addresses, respectively. The TCP query was elicited by issuing a
query for which the authoritative server would always respond
with the truncation (TC) bit set. A truncated response causes the
recursive resolver to issue its query again over TCP [13].
3.6 Methodology Considerations
Several issues merit our discussion, including the eect of middle-
boxes or human intervention on our experiment, data freshness,
and QNAME minimization.
3.6.1 Middleboxes. It is possible for a DNS request to be transpar-
ently intercepted and handled by a middlebox between our client
and the target DNS resolver [6]. In this case it would be unclear
if the DNS resolver itself—or, more importantly, its network—was
reachable. We observed that for 86% of IPv4 ASes and 95% of IPv6
68
ASes, at least one recursive-to-authoritative query was received
directly from an address in the target AS. In these cases, even
if our spoofed-source query did not reach its destination IP ad-
dress, we know that reached its destination AS, which conrmed
lack of DSAV. As for the remaining ASes, at least one recursive-to-
authoritative query was received from major public DNS services
(Cloudare [23], Google [22], CenturyLink [7], OpenDNS [8], or
Quad9 [39]) for 89% of IPv4 ASes and 86% of IPv6 ASes. Forwarding
to such DNS services is not characteristic of middleboxes. These
numbers explain all but 2% (IPv4) and 1% (IPv6) for our per-AS
DSAV measurements.
3.6.2 Data Freshness. We consider the reasonableness of using
DITL as a set of target recursive IP addresses. Certainly not all of
the approximately 12 million target IP addresses from the DITL data
were functioning as recursive servers at the time of our experiment.
It is possible that some IP addresses that did represent recursive
DNS servers at the time of DITL collection, no longer did when we
ran our experiment six months later. Previous research has shown
that there is churn in IP addresses of DNS resolvers—specically,
open resolvers—over time [31]. It is also possible that some of the
IP addresses might never have been used used as recursive DNS
servers. For example, perhaps they represent software used only
to monitor Internet connectivity or health. We argue that we are
working with an incomplete but suciently representative data set.
This is validated in part by the fact our results are consistent with
those from previous work (see Section 2). Additionally, we do not
expect our data to include the IP addresses of all recursive servers.
This is in part because the DITL data is not comprehensive (i.e., not
all root servers participate in the collection) and in part because
an active resolver might not need to query the root server during
that period, depending on its query patterns and caching behaviors.
Finally, the source IP address of some of the queries captured in the
DITL data might in fact be spoofed and thus not associated with
an actual DNS resolver.
There is also the question of whether or not IP churn occurring
during the experiment itself aected the results, causing addresses
that were at one point responsive to be unresponsive later on. While
this situation is certainly possible, it could really only aect the
results of one aspect of our study, that of spoofed-source eec-
tiveness (Section 4.1); for the rest of our evaluation of DSAV, an
AS was considered to be lacking DSAV if at least one query was
handled by a target IP address. We might have chosen to send all
queries to a given target IP address in rapid succession, rather than
spreading them out over the entire experiment period; this would
have mitigated the question of churn. However, we opted to min-
imize possible impact and attention, e.g., from IDS, by spreading
the queries out.
3.6.3 Human Intervention. We expect that some of our spoofed-
source queries might be dropped and/or logged by IDS or servers
as suspicious. Curious human analysts might resolve the domain
name to learn more about the activity, resulting in a query to our
authoritative servers. However, such a query does not provide
reliable DSAV information.
To overcome this ambiguity, we calculated query lifetime (i.e.,
how long it was “alive” in the system) by subtracting the timestamp
embedded in the query name from the time at which the query was
Behind Closed Doors
IMC ’20, October 27–29, 2020, Virtual Event, USA
received at our authoritative servers. We considered a query with
a lifetime of 10 seconds or less as unlikely made by a human, in
response to logs. While a query passing through the most reliable
systems might consistently have a lifetime of less than a single
second, we selected this higher threshold because query retrans-
missions (i.e., by recursive resolvers) can happen after timeouts of
one or more seconds. The results we present only include queries
whose lifetime was under our 10-second threshold. Queries for an
additional 3,444 IPv4 addresses and 70 IPv6 addresses had a life-
time that exceeded our threshold, representing less than 0.1% of
addresses, for both protocols. These corresponded to 421 IPv4 ASes
and 32 IPv6 ASes. For all but 19 and 2 of these ASes, we were able to
infer lack of DSAV through the presence of other resolvers which
did query our servers within the 10 second window.
3.6.4 QNAME Minimization. In an eort to preserve privacy, some
modern DNS resolvers avoid sending authoritative servers the
full query name (QNAME) and instead only ask for the next un-
known label. This is known as QNAME Minimization [3]. In the
case of our experiment, before asking for the full QNAME (i.e.,
ts.src.dst.asn.kw.dns-lab.org), a resolver using QNAME mini-
mization would ask for kw.dns-lab.org, then asn.kw.dns-lab.org,
etc. As we mentioned in Section 3.3, our authoritative servers re-
turned an NXDOMAIN response code in response to any queries re-
lated to our experiment. For at least some resolver implementations
that implement QNAME minimization, an NXDOMAIN response halts
further queries associated with the QNAME. This is because an
NXDOMAIN for a given domain name implies that no subdomains
(i.e., with additional labels on the left) exist [4].
We observed QNAME-minimized queries from 17,981 (0.16%)
of the IP addresses that we targeted with our initial reachability
query. For 9,898 (55%) of these IP addresses, we never received a
query with the full QNAME. Most notably, they did not include
the label with the encoded source address. With no way to identify
the source IP address that we used to reach these 9,898 targets, we
exluded them from the total number of reachable targets. Nonethe-
less, we still learned something about the networks from which
the QNAME-minimized queries originated. We observed that DNS
clients from 2,081 ASNs queried for kw.dns-lab.org (the product
of QNAME minimization). Of those, 2,041 (98%) were identied as
lacking DSAV, in that we observed queries from these same QNAME-
minimizing resolvers or from other (i.e., non-QNAME-minimizing)
resolvers. Thus, QNAME minimization did not diminish our DSAV
measurement results. Nonetheless, a future version of our experi-
ment would produce more inclusive results by returning answers
synthesized from wildcard entries, rather than returning NXDOMAIN.
3.7 Ethical Considerations
The measurement of network and systems vulnerabilities requires
care, both in the activity itself and in the disclosure of the ndings.
Because of the nature of our research, we consulted various re-
sources for ethical guidance. While our organization has no ethics
board, we consulted with individuals from the legal department,
the oce of research and creative activities, and our own computer
science department with respect to the ethics of our research. We
likewise reviewed the Menlo Report [14], which holds some of the
key guidelines for ethical research in this area. Of the ethics prin-
ciples outlined in the Menlo Report, those most applicable to our
current research are 1) justice, 2) respect for law and public interest,
and 3) benecence.
Regarding justice, our measurements considered all target IP
addresses (i.e., from the DITL data) equally; no particular industry,
geography, nation state, address space, or protocol was deliberately
targeted more than another.
Perhaps the biggest ethical question associated with our research
was the legality of measuring another’s network using our method-
ology. Our measurements crossed interstate boundaries world-wide,
each potentially with their own laws regarding unauthorized net-
work access. For example, the United States (U.S.) outlaws any
intentional access of non-public, government-owned computer sys-
tems, without authorization [24]. We cannot denitively determine
whether or not the systems that we measured are non-public nor
whether our benign packets even constitute a violation of this
statute. In any case, we believe that our methodology is justied
because of the benet it brings in the public interest. Indeed the
Menlo Report’s principle of benecence suggests that the benets
of an experiment should be maximized and the harms minimized.
Bringing to light the severity and pervasiveness of the lack of DSAV
and the potential for network penetration is extremely valuable to
the Internet community. We expect that responsibly publishing our
ndings will be a catalyst in spreading awareness and taking the
necessary action to ll the security gaps identied herein.
The potential harms associated with our experiment might in-
clude degradation of service due to our trac, time spent following
up on alerts from Intrusion Detection Systems (IDS), or careless
vulnerability disclosure. We took several measures to minimize any
negative impact, and even the appearance of abuse. First, we limited
both the number and the rate of queries directed towards any given
destination, as described in Section 3.4. Considering query rates