### Probability Definitions and Estimations

Given the conditional probabilities:
- \( \Pr[X_n = 0 | K_1] = \theta_1 \)
- \( \Pr[X_n = 1 | K_1] = 1 - \theta_1 \)

In this context, \( 1 - \theta_0 \) represents the measurable probability of observing IP ID acceleration during the injection, while \( \theta_1 \) is the prior probability of no IP ID acceleration during the SAR (Sequential Analysis of Reﬂectors) window across all reﬂector measurements. These values provide conservative estimations of the prior probabilities. The measurable IP ID acceleration during the SAR window is further discussed in Section V-D.

Figure 2 illustrates how this construction is used to label \( S_i \) and \( R_j \) as either outbound-blocked or not blocked. If the thresholds are not met and there are no more trials, we conclude that \( S_i \) is not inbound-blocked, but the outbound-block status remains unknown.

### Expected Number of Trials

The Sequential Hypothesis Testing (SHT) framework from Jung et al. also provides a method for calculating the expected number of trials needed to make a decision between hypotheses \( H_0 \) and \( H_1 \). The expected values are defined as:

\[
E[N|H_0] = \frac{\alpha \ln \beta + (1 - \alpha) \ln \left(\frac{1-\beta}{1-\alpha}\right) + (1 - \theta_0) \ln \left(\frac{1-\theta_1}{1-\theta_0}\right)}{\theta_0 \ln \left(\frac{\theta_1}{\theta_0}\right)}
\]

\[
E[N|H_1] = \frac{\beta \ln \beta + (1 - \beta) \ln \left(\frac{1-\beta}{1-\alpha}\right) + (1 - \theta_1) \ln \left(\frac{1-\theta_1}{1-\theta_0}\right)}{\theta_1 \ln \left(\frac{\theta_1}{\theta_0}\right)}
\]

Here, \( \alpha \) and \( \beta \) are parameters bounded by the tolerable false positive and false negative rates, which are discussed in detail later.

### False Positives and Negatives

Following the construction from Jung et al., \( \alpha \) and \( \beta \) are tunable parameters constrained by our tolerance to false positives and false negatives. \( P_F \) is the false positive probability, and \( P_D \) is the detection probability. The complement of \( P_D \), \( 1 - P_D \), is the probability of false negatives. These values represent the probability of a false result for a single SHT experiment. However, since we perform numerous SHT experiments across multiple sites and reﬂectors, we set both \( P_F \) and \( 1 - P_D \) to \( 10^{-5} \).

As \( P_F \) and \( 1 - P_D \) decrease, the expected number of trials to reach a decision increases. This effect is somewhat mitigated by the separation between experimentally observed priors, as explored in Section V-D and Figure 4.

### Augur Implementation and Experiment Data

#### A. Selecting Reﬂectors and Sites

**Reﬂector Selection:**
To identify reﬂectors that meet the criteria from Section IV, we developed a new ZMap [20] probe module that sends SYN-ACK packets and looks for well-formed RST responses. This module is now part of the open-source ZMap distribution. We scan the entire IPv4 address space on port 80 to identify potential reﬂectors.

We then perform a second set of probes against these candidate reﬂectors to identify those that conform to the desired IP ID behavior. Our tool runs from the measurement machine, sending ten SYN-ACK packets to port 80 of each host precisely one second apart, recording the IP ID of each RST response. We select reﬂectors that exhibit no IP ID wrapping, variable accelerations (indicating induced perturbations in IP ID dynamics), and respond to all probes. The measurement machine ensures a constant packet generation rate, so any additional IP ID acceleration must be due to traffic from other connections. We ensure the reﬂector responds to each probe packet, ensuring stability and reliability.

**Site Selection:**
We start with a list of sites, some of which are expected to be disrupted by network filtering or censorship from various vantage points. We seed our candidate sites with the Citizen Lab list of potentially censored URLs [15], known as the CLBL. This list contains potentially blocked URLs, categorized by type. To further identify sensitive URLs, we use Khattak et al.’s dataset [32], which probed these URLs using the OONI [40] measurement platform for active censorship. After filtering, we distill the URLs down to domain names and resolve them to corresponding IP addresses using a local recursive DNS resolver on a U.S. network. If a domain resolves to multiple IPs, we randomly select one A record. We augment this list with randomly selected domains from the Alexa top 10,000 [2]. Section V-B provides a breakdown of the site population, and Section V-E explains how we dynamically enforce site requirements.

#### B. Measurement Dataset

**Reﬂector Dataset:**
The geographic distribution of reﬂectors highlights our ability to investigate censorship or connectivity disruption within each country. Table I summarizes the geographic diversity of our reﬂector datasets. An Internet-wide ZMap scan found 140 million reachable hosts, with approximately 22.7 million demonstrating a shared, monotonically increasing IP ID. These reﬂectors are distributed across 234 countries, with a median of 1,667 reﬂectors per country.

Merging with the Ark dataset to ensure only network infrastructure reﬂectors reduces the 22.7 million potential reﬂectors to about 53,000, distributed across 179 countries with a median of 15 reﬂectors per country. Table II provides a breakdown of reﬂector coverage by continent.

We select a subset of these reﬂectors for our final experiment dataset, randomly choosing up to 16 reﬂectors in all 179 countries, yielding 1,947 reﬂectors. We add 103 high-reliability reﬂectors primarily from China and the US, resulting in 2,050 reﬂectors representing 31,188 ASes. Using the Ark dataset, we reduce this set to 4,214 ASes, with our final experiment sample comprising 817 ASes.

**Site Dataset:**
Merging the CLBL with Khattak et al.’s dataset [32] yields 1,210 distinct IP addresses. We add 1,000 randomly selected sites from the Alexa top 10,000, along with several known Tor bridges. The final site list contains 2,134 unique sites, with a CLBL composition of 56.7%.

#### C. Experiment Setup

Our selection process leaves us able to measure connectivity between 2,134 sites and 2,050 reﬂectors. Over 17 days, we collected 207.6 million runs across 47 total trials, testing each reﬂector-site pair 47 times.

Each run consists of one-second time intervals. For each interval, we measure the IP ID state of the reﬂector independently. We start each run by sending a non-spoofed SYN to the site from the measurement machine to ensure the site is up and responding. We also measure if the site sends SYN-ACK retries and characterize their timing. After four seconds, we inject 10 spoofed SYN packets towards the site. The reﬂector measurements during this window serve as control measurements.

At the end of the run, we send corresponding RST packets for all generated SYNs to induce tear-down of all host state. We then cool down for 1 second before starting a new run. We randomize the order of sites and reﬂectors for each trial, ensuring no reﬂector and site are involved in two independent simultaneous measurements.

After each run, we verify that the reﬂector’s IP ID remains monotonically increasing, no packet loss occurred, and the site is up and responding. We discard measurements if any condition fails. After validity checks, our dataset contains 182.5 million runs across 1,960 reﬂectors and 2,089 sites. We then apply SHT (Section IV) to analyze the reachability between these site-reﬂector pairs.

#### D. Measured Priors and Expectations

A critical component of our SHT framework is formulating the prior probabilities for each hypothesis. Figure 3 shows CDFs of the measured prior probabilities of IP ID acceleration for three different scenarios.

The IP ID acceleration of reﬂectors matches our intuition, where the acceleration decreases as frequently as it increases across the dataset. The "No Injection" CDF shows nearly all reﬂectors have a probability of IP ID acceleration without injection of less than 0.5. Many reﬂectors have a much lower probability, corresponding to low or stable traffic patterns. We use this per-reﬂector prior for \( \theta_1 \) in our SHT construction for detecting inbound blocking.

Figure 3 also shows the probability of IP ID acceleration under injection, which approaches 1 for many reﬂectors and is above 0.8 for more than 90% of reﬂectors. Some reﬂectors, however, have very low or even zero probabilities, indicating degenerate or broken reﬂectors. We remove these from our experiment. We use this experimentally measured prior as \( 1 - \theta_0 \) in both sequential hypothesis tests. This distribution provides a robust basis for our analysis.