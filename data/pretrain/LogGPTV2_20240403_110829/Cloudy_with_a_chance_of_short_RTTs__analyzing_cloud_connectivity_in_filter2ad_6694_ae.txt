### Enhancing the Understanding of Cloud Peering Relationships

To gain a more comprehensive understanding of cloud peering relationships, it is essential to simultaneously measure from both client-side (as done in this study) and within cloud networks (as in [8, 74]). Additionally, different ISPs globally may have unique peering relationships with cloud providers. Grouping these ISPs together could obscure regional-specific routing trends. While we provide some insights into country-specific peering case studies in §6.2 and Appendix A.4, a thorough examination of the routing relationships between ISPs and cloud providers, similar to [9], is necessary. This is an area we plan to explore in future work.

Figure 10 illustrates the percentage distribution of paths across the three interconnection categories for all cloud providers in our target list. Our results confirm the advertised backbone network types of cloud providers as shown in Table 1. The majority of connections are direct, aligning with the advertised network types.

### Global Connectivity and Interconnection Strategies

Cloud providers prefer direct peering when possible. When direct peering is not feasible, they often use private interconnects via Tier-1 ISPs like Telia Carrier. Smaller providers, such as Linode, Vultr, and Oracle, primarily rely on the public Internet for routing their tenant traffic.

### Impact of ISP Peering on Latency

We now focus on the impact of direct ISP-cloud peering interconnections on user cloud access latency. For a detailed analysis, we examine measurements from Europe (VPs in Germany to DCs in the UK) and Asia (VPs in Japan to DCs in India). Cloud providers have historically invested in infrastructure within Europe and North America to maximize profits from existing user bases [67, 92]. These continents already have a reliable Internet backbone and have been at the forefront of networking innovation for decades [19, 42, 88].

Previous studies have shown that the benefits of private cloud WANs decrease with shorter geographical distances between users and datacenters [8]. As indicated in Table 1, users in both EU and NA have multiple options for accessing the nearest DC. In contrast, datacenter deployment in regions like Asia, South America, and Africa is more scattered, favoring only a few select countries. Consequently, the impact of using privately managed WANs operated by cloud providers should be more noticeable in these regions.

To maintain a comparative analysis across these two continents, we selected Germany and Japan as originating countries due to their dense availability of Speedchecker VPs (see Figure 1b). Similarly, the UK and India were chosen as endpoints because they have datacenter deployments from almost all providers in our target list. This analysis aims to understand the continent-specific routing policies set up by cloud providers to transport tenant traffic. Additional case studies, such as Bahrain VPs to India DCs (for Asia) and Ukraine VPs to UK DCs (for Europe), are provided in Appendix A.4 to support our findings.

Figures 12 and 13 highlight the impact of different cloud-ISP interconnections in Europe and Asia, respectively. In Europe, Figure 12a shows the peering types used by German ISPs while transporting traffic bound to cloud providers. The color denotes the percentage of paths belonging to the majority interconnection type between the ISP and the cloud provider. Our results validate the findings in Figure 10. The three hypergiants—Amazon, Google, and Microsoft—exclusively peer directly with almost all serving ISPs in Germany. This results in the majority of traffic from Germany to these providers' DCs traversing a very "flat" Internet, avoiding even transit Tier-1 ISPs [9].

For other cloud operators, except for traffic from Telefonica (AS 6805) to Alibaba and Vodafone (AS 3209) to DigitalOcean, almost all German ISPs route their traffic via private interconnection facilities that support the PoP of that provider. IBM, as a medium-sized operator, uses a combination of direct and private interconnects, but also exchanges traffic at public IXPs more than its contemporaries.

### Pervasiveness of Cloud Providers

Figure 11 shows the degree of pervasiveness of different cloud providers globally. High pervasiveness in Google, Microsoft, and Amazon routes indicates that the majority of routers on end-users' paths to the nearest DC are within ASes owned and operated by the providers themselves.

For client ISPs without direct peering, cloud providers increasingly employ carrier peering via private Tier-1 ISPs (e.g., Telia Carrier - AS1299, GTT Comm. - AS3257, etc.). Private peering interconnections are used by almost all cloud providers as the peering providers host edge PoPs for multiple operators [2]. Medium-sized cloud providers, such as IBM and DigitalOcean, benefit greatly from private peering as their private WANs are still localized, allowing them to divert investments into expanding their infrastructure by deploying more datacenters [27].

IBM follows a hybrid interconnection approach, relying on private peering for shorter paths (mainly within Europe and North America) and public transit for longer paths (mostly in Asia). Paths destined to small-sized cloud providers, such as Linode, Vultr, and Oracle, often include two or more on-path ASes, likely indicating routing via the public Internet. Interestingly, despite its massive datacenter and private WAN deployment [4], Alibaba also uses public Internet paths to interconnect users to its cloud regions. This behavior is attributed to the low availability of Speedchecker probes in China (see Fig. 1b), which does not provide visibility into Alibaba’s primary operational region. Outside of China, Alibaba operates its datacenters as independent "islands," only allowing ingress into their WAN via public transit providers.

### Router-Level Traceroute Analysis

We analyze router-level traceroute data and calculate pervasiveness in Figure 11. Pervasiveness is defined as the ratio of the number of routers owned by the cloud providers to the overall path length to the cloud. A high pervasiveness degree indicates that most of the end-user route to the cloud is owned, controlled, and operated by the provider, highlighting the reach of their private WAN. We find that the pervasiveness of cloud providers follows a similar trend to the AS-level hop distribution; Google, Microsoft, and Amazon own more than 60% of the path in almost every continent. Providers with two or more ASes only own approximately 20% of routers on a path, further validating our methodology for identifying types of ISP-cloud interconnections.

### Key Takeaways

- **Hypergiant Cloud Providers (Amazon, Google, Microsoft)**: These typically have direct peering with clients’ ISPs (> 50%) in most regions.
- **Direct Peering in Europe**: Direct peering between ISPs and cloud operators has minimal effect on cloud access latency between Germany and the UK, indicating that geographical distances (§4.3) have a greater impact on latency than routing.
- **Direct Peering in Asia**: Direct peering significantly reduces latency variations in connections from Japanese VPs to Indian DCs, showcasing the benefits of undersea cable investments [58, 79].
- **In-Land Interconnections in Asia**: Direct peering improves median latency by a significant margin, especially for in-land interconnections within the continent.

### Discussion

While our experiments cover a wide range of scenarios, they are inherently limited by the measurement platforms and the nature of network connections. Traceroute-based analyses are susceptible to inconsistencies from asymmetric forwarding and reverse paths [26, 32]. Additionally, traceroutes only provide base network latency, and actual user-observed delays can be higher due to processing and internal queuing. Thus, our reported latencies represent the best-case scenario and can be considered lower bounds on achievable performance.

Our final limitation comes from the Speedchecker platform. Our experiments do not include the last-mile access type (WiFi/cellular) throughout the duration of the measurement, leading to potential false positives in inferring the type of wireless access through traceroutes.

### Utility of Edge Computing

Given the factors affecting global cloud access latencies, we discuss the utility of deploying compute edge servers outside the cloud domain:

- **Networks Without the Edge**: Regions with dense datacenter deployments, such as developed areas, show stable latencies regardless of wired or wireless last-mile connectivity. Developing regions, with poorer connections to cloud datacenters, would benefit more from bringing services closer to users via edge computing [23]. Even sparser edge deployments, such as regional edges or small datacenters [59, 62], could significantly improve connectivity in these regions.
- **Applications Without the Edge**: Cloud can satisfy HRT in almost all measured cases and easily achieve HPL in regions with denser datacenter deployments. However, MTP-constrained applications remain infeasible, particularly with wireless last-mile latencies. While wireless last-mile latencies may decrease with advancements like 5G, the reduction may not be substantial enough to enable widespread edge deployments, especially in developed regions where transit latency overhead is minimal.

Peering agreements between operators help ensure lower latency variations, but they do not markedly reduce base latencies, especially in regions with well-provisioned public backhauls. More consistent latencies aid applications by making the network more predictable [61]. For example, video streaming services can make more accurate estimates about buffering needs and optimize video quality better when the network is stable. Deploying edge servers would further enhance this predictability and performance.