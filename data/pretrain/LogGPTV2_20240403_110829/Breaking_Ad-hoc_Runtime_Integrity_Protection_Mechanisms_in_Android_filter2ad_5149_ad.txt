text.getApplicationInfo().publicSourceDir.
The native code then reads the APK ﬁle and checks for app
tampering, similar to I_Group_APK_Path.
How to bypass. For such cases, we implement FakeContext, which
is exactly same as Context except that it contains the path to the
unmodiﬁed APK ﬁle generated by getUnmodifiedPackage-
CodePath() (Figure 4f).
4.3 Third-party Security Libraries
On close examination, we found that 60 (out of 76) apps inte-
grated one or more security libraries that implement self-defense
mechanisms. We used the Java package names and the ﬁle name of
the libraries to infer the security company that produced the library.
Table 5 shows those libraries and the additional security features
that the libraries support. All libraries except Lib8 are written in
native code. From the library code and the security companies’
web pages, we discovered that the libraries provide various secu-
rity functions other than self-defense mechanisms. The most com-
mon function provided by the libraries is malware detection. The
libraries scan malicious apps and processes directly by getting the
lists of installed apps and running processes from the system, or
they scan by transacting with security apps developed by the same
vendor. Also, the libraries support various features, such as code
obfuscation, anti-decompiling, and emulator detection, to prevent
the reverse engineering of apps.
We found that some libraries communicate with an external
server while running self-defense mechanisms. As described in
Section 2, the libraries send data or the examination result to the
server to be validated, which results in a complex call graph.
Risk of using security libraries. If many apps share the same li-
braries, these apps are vulnerable to the same bypass attacks. For
example, as shown in Table 5, 30 apps use Lib0 to perform de-
vice rooting checks, and our single bypass attack defeated 17 out
of these 30 apps. The rest needed more than one type of bypass
attacks.
4.3.1 Case Studies
Given the popularity of security libraries, we did an in-depth
analysis of the self-defense mechanisms implemented in those li-
braries. Speciﬁcally, we chose the top ﬁve libraries, Lib0, Lib1,
Lib2, Lib3, and Lib4. Although the libraries use various methods
to check device rooting and app integrity via the system calls de-
scribed in Tables 1 and 2, we bypassed all checks with the app
rewriting techniques described above.
How the libraries check device rooting.
The libraries use various system calls to check device rooting.
Normally, they concentrate on ﬁnding executable binary ﬁles and
app package ﬁles related to device rooting. However, some libraries
use other methods to examine device rooting, such as checking the
user ID of a system process and investigating system properties.
Lib0. We found two ways that Lib0 checks device rooting. First,
the library checks predictable ﬁle paths in the su binary (e.g., /sys-
tem/xbin/su, /system/bin/su) using the stat() [13] system call.
The system call takes the ﬁle path as an argument and returns the
existence of the ﬁle. The library checks the existence of the su
binary by calling stat() for each predictable ﬁle path.
Second, the library checks the user ID of the adbd process.
The library ﬁnds adbd’s process ID by scanning the /proc/ direc-
tory, which contains numerous subdirectories for running processes
named by the process IDs [13]. The library then gets the user ID
of the adbd process by reading the /proc/[pid]/status ﬁle via the
read() system call. If the device is not rooted, the user ID of
adbd is 2,000, which is the shell user’s ID. Otherwise, the user ID
of adbd is zero, which is the root user’s ID. Therefore, the library
can check device rooting using adbd’s user ID.
Lib1. To check device rooting, Lib1 tries to open or access
ﬁles or directories related to device rooting. First, it calls the
access() system call to check whether private directories for
the apps related to device rooting (e.g., com.marutian.quckunroot,
com.noshufou.android.su) are accessible.
Second, the library tries to open the su binary and root-related
apps’ APK ﬁles using the open() system call.
If the ﬁle
can be opened as read-only, open() returns its ﬁle descrip-
186tor number. Otherwise, if the ﬁle does not exist, open() re-
turns -1. Using the system call,
the library checks whether
an su binary exists in the predictable path and whether root-
related apps’ APK ﬁles are stored (e.g., /system/app/superuser.apk,
/data/app/com.noshufou.android.su-2.apk).
Lib2, Lib3. Similar to Lib1, Lib2 and Lib3 try to open the su
binary and root apps’ APK ﬁles using the open() system call.
Lib4. Lib4 employs various methods to examine the platform’s
integrity in addition to checking root-related apps and binaries,
such as other libraries. First, the library ﬁnds the system property
ro.kernel.qemu’s value. If the value is one, the method considers
that the app runs in an emulator. Second, the library searches every
ﬁle under the root directory recursively except for some unimpor-
tant directories, such as /sdcard/ and /mnt/. To evaluate every ﬁle,
the library calls opendir(), readdir(), and chdir(). If the
library ﬁnds a ﬁle whose name is “su” or that contains a string like
“noshufou” or “supersu,” it concludes that the platform has been
tampered with.
How the libraries check app integrity.
The libraries use a methodology similar to that described in Sec-
tion 4.2 to check an app’s integrity; they take the app’s APK ﬁle
path, read the ﬁle, calculate the hash value, and compare the value
with the one stored in an external server. Even if the libraries are
written in native code, they always obtain the APK ﬁle path using
Android APIs because the path varies by device.
Lib2. To check app integrity, Lib2 reads the app’s APK ﬁle and
library ﬁle. The library takes the ﬁles’ paths as string-type argu-
ments. The library ﬁrst checks whether the APK ﬁle’s path is valid,
i.e., the ﬁle is stored in either /data/app/, /data/app-private/, or /m-
nt/asec, and the ﬁle’s name starts with the app’s package name.
The library then reads the ﬁles, calculates the hash values, and
sends them to the app developer’s server for the validation of app
integrity.
Lib3. Similar to Lib2, Lib3 examines the app’s integrity by reading
the app’s APK ﬁle and computing its hash value. The library then
sends the data to the app developer’s private server.
Lib4.
The
library then gains
the app’s APK ﬁle path from Con-
text.getApplicationInfo().sourceDir and computes
the hash value of the ﬁle. The library sends the hash value to the
app developer’s private server to check the app’s integrity.
Lib4 takes a Context object as an argument.
How an app ﬁnds out whether the self-defense mecha-
nism had been called.
Although the libraries use various methods to check device root-
ing and app integrity, almost none of the apps or libraries verify af-
ter the checks that the checks were performed. We ﬁnd that AppL,
which has integrated Lib2, uses an external server to probe whether
the self-defense mechanism has been called. So, if we skip the
checks, then the app can get the signal from the server. Therefore,
simply rewriting the native method’s declaration to a Java method
does not work for AppL, and we used a different bypass attack in
this case.
How the libraries terminate an app running in an un-
safe environment.
If a self-defense mechanism ﬁnds that the device is rooted or the
app has been tampered with, the security library stops the app’s
execution. The security libraries, except Lib3, return the checking
result to a Java method instead of directly showing an alert dialog.
Lib3. Lib3 has characteristics different from the other libraries in
terms of how it terminates the app when the checks fail. If the li-
brary judges that the app is running under unsafe conditions, unlike
other libraries, it does not return and terminates the app using the
exit() system call. To store the method call records before termi-
nation, we had to register a wrap-up function using the atexit()
function, which registers a function that should be called in normal
process termination [13].
How the libraries return the result and how we by-
passed.
The libraries use diverse techniques to check device rooting and
app integrity, and to prevent apps from executing in unsafe envi-
ronments. However, the techniques do not deviate from those de-
scribed in Section 4.2, so they cannot prevent attackers from by-
passing checks.
Lib0. If the device is not rooted, Lib0’s native method returns zero.
Otherwise, the method returns -1. We bypass the check by chang-
ing the native method’s declaration to a Java method that returns
zero.
Lib1. Lib1’s native method for a device rooting check returns a
string “0” when the device is not rooted. Otherwise, the method
returns “1.” We bypass the check by changing the native method’s
declaration to a Java method that returns “0.”
Lib2. If the device is not rooted and the app has not been tampered
with, Lib2’s native method returns zero. Otherwise, the method re-
turns an error number as an integer. Normally, we can bypass the
checks by editing the native method’s declaration to a Java method,
which returns zero. Exceptionally, we modify the library ﬁle and
the APK ﬁle path instead of changing the native method’s declara-
tion for AppL.
Lib3. When a device rooting check and an app tempering check
pass, Lib3’s native method returns a string “0000.” If they do not,
the library terminates the app immediately or returns a four-digit
number as a string, such as “9002” when the device is rooted, or
“9001” when the app has been tampered with. In both cases, we
bypass the checks by editing the native method’s declaration to a
Java method, which returns “0000.”
Lib4. Because Lib4’s native method returns a byte array, it is hard
to predict the return value when an app runs in an untampered en-
vironment. Therefore, we cannot rewrite the method’s declaration
to a Java method. Instead, we modify the native library ﬁle to by-
pass the device rooting check and use FakeContext, as described in
Section 4.2.2, to bypass the app integrity check.
4.4 Summary
We have shown that the apps and libraries use diverse Android
APIs and system calls to detect evidence of tampering, but they
mainly focus on only a few characteristics of tampered systems
and apps. For example, to check device rooting, apps and libraries
try to ﬁnd binaries and apps related to device rooting using known
ﬁle paths and app names. To check app integrity, they compute
the app package ﬁle’s hash value and compare it with the correct
value. These checks are done in the app itself, which makes it easy
to bypass the self-defense mechanisms. We have shown that the
strategies we put together for bypass attacks are effective against
these apps and libraries. Additionally, we found that some libraries
leverage characteristics that other apps or libraries do not consider.
For example, Lib0 checks a system process’s user ID and Lib4 in-
vestigate all ﬁles and directories in the system to check device root-
ing. We also found that one app checks whether the self-defense
mechanism has been bypassed, during runtime. However, these at-
187tempts are still made in the app, so they cannot completely prevent
the bypass attacks. From the ﬁndings, we conclude that the cur-
rently implemented self-defense mechanisms are ineffective, and
thus platform-level veriﬁcation is required to ensure the integrity
of the platform and the apps.
5. MERCIDroid EFFECTIVENESS AND
LIMITATIONS
This section describes the effectiveness and limitations of MER-
CIDroid.
5.1 Effectiveness of MERCIDroid
We investigate the effectiveness of MERCIDroid in two aspects.
We ﬁrst evaluate the number of apps for which MERCIDroid can
generate SDMGraphs. SDMGraphs are generated when an SDM-
Graph contains both an environment information provider(s) and
an execution terminator. MERCIDroid constructs SDMGraphs for
67 out of 73 apps that check device rooting and 39 out of 44 apps
that check app integrity. Overall, MERCIDroid constructs SDM-
Graphs for 130 out of 140 self-defense mechanisms, which means
that at least 130 self-defense mechanisms follow the self-defense
mechanism structure described in Section 2.
We also evaluate the effectiveness of our tool in narrowing the
scope of the methods we should analyze. For each self-defense
mechanism for which we can generate an SDMGraph, we count
the number of the methods in the SDMGraph. We compare this
number with the total number of methods in the execution trace of
each self-defense mechanism. On average, the number of meth-
ods in each app is approximately 30,894. The number of methods
that are called at least once in the execution trace of running a self-
defense mechanism for analysis is approximately 1,079, except An-
droid APIs. Finally, the number of methods in the SDMGraph for
self-defense mechanisms is around 40. This means that we need
to consider only 3.7% of the methods in each execution trace and
0.13% of the methods in each app to analyze the robustness of the
self-defense mechanisms. The SDMGraphs for 130 self-defense
mechanisms show that the control ﬂows of 88 of them contain indi-
rect relationships among threads and Android components. With-
out identifying the indirect relationships, we may only be able to
analyze 32% of the self-defense mechanisms.
5.2 Limitations of MERCIDroid
MERCIDroid identiﬁed more than 92% of self-defense mecha-
nisms in our target apps, but it has a few limitations. As described
in Section 2, MERCIDroid relies on some assumptions regarding
the typical structure of a self-defense mechanism. For example, we
assume that an alert message in an execution termination contains
some keywords such as “root” or “forged.” We also assume that
there is a common ancestor between environment investigation and
execution termination. Most self-defense mechanisms can be spot-
ted with such assumptions, but there are some self-defense mecha-
nisms that do not follow the assumptions and thus are not identiﬁed
by MERCIDroid (Limit_Cases 1, 2). Also, MERCIDroid has some
implementation limitations (Limit_Cases 1, 3, 4). Table 4 shows
the number of apps included in Limit_Cases 1 to 3.
Limit_Case_1. An environment investigation and an execu-
tion termination are called from different entry points. MER-
CIDroid cannot ﬁnd a relationship between an environment inves-
tigation and an execution termination when they are called from
different entry points. In Android, every app component (e.g., Ac-
tivity, Service, ContentProvider, BroadcastReceiver) can be an en-
try point to be used in the Android system [4]. Therefore, an en-
vironment investigation and an execution termination can be called
from different entry points and exchange checking results through
a class’ member variable. Then, MERCIDroid cannot ﬁnd their
common ancestor because it is located in the Android system pro-
cess, where MERCIDroid is unable to trace the control ﬂow. We
found three apps where this case holds. To overcome this limita-
tion, MERCIDroid should trace the control ﬂow between an app
and the Android system.
Limit_Case_2. An app uses WebView. MERCIDroid cannot ana-
lyze three apps that use WebView to provide the apps’ services. The
apps display an execution termination using a website instead of
the Android APIs mentioned in Table 3. Therefore, MERCIDroid
cannot trace the execution termination part.
Limit_Case_3. A native method uses multi-threads. MER-
CIDroid can trace multi-threads at the Java level but not at the na-
tive level. If we want to trace a new thread executed by the target
thread, we should use strace with the -f option. However, in MER-
CIDroid, the option makes strace sleep. Therefore, MERCIDroid
cannot trace system calls from the new thread. Five apps belong to
this category. We can solve this limitation by making MERCIDroid
trace the native level inside a process instead of using an external
process such as strace.
6. DISCUSSION
It is security critical to ensure that ﬁnancial Android apps only
run on a non-rooted platform. With the lack of a platform-level
support, we ﬁnd that many ﬁnancial apps employ various checks
themselves, which are ineffective as shown by our analysis. We
ﬁrst discuss a few existing platform-level approaches that can ben-
eﬁt apps which need to ensure platform integrity before execut-
ing security critical functions. We then discuss the limitations that
make these approaches impractical.
It is not uncommon for users to root their device. They may de-
cide to install benign apps that require rooting without fully un-
derstanding security risks. They may get tricked into installing
a root-kit that results in a compromised platform. To help those
users avoid further harm, it is desirable for ﬁnancial apps to have
the capability to abort security sensitive functions if the platform
is deemed compromised. However, since an app runs under the
control of the platform, an app alone is fundamentally insufﬁcient
to determine the integrity of the platform. One option is to lever-
age a hardware capability called remote attestation introduced by
Trusted Computing Group [17]. Nauman et al. [43] discuss ways
that an Android platform can integrate remote attestation.
If a
trusted third-party service validates the attestation value, the ser-
vice end involved with an app can determine whether to continue
the transaction from a particular device. This approach, however,
requires hardware changes, new services for validating attestation,
and new protocols to orchestrate a somewhat complicated ﬂow be-
tween a device, a ﬁnancial app, a service, and the server end of the
ﬁnancial app.
Another approach is adding a barrier to prevent tampering of
the boot chain and critical system components. Veriﬁed boot, also
known as trusted boot or secure boot, is a technique that ensures
that only authorized boot loaders and kernel modules are loaded
into a device [18, 19]. Android 4.4 and later support veriﬁed boot
for device manufacturers [20]. However, veriﬁed boot is an op-
tional solution for device manufacturers, thus there is no guarantee
that a ﬁnancial app runs on a device that uses veriﬁed boot. Google
provides SafetyNet API [6] as part of Google Play services for apps
to query whether the device running the app has passed the Android
compatibility testing. Although SafetyNet seems to collect vari-
188ous information, fundamentally, it shares the same limitation with
other cases shown in this paper as long as a compromised platform
ﬁnds ways to present fake data that make it appear unchanged when
probed by SafetyNet.
7. RELATED WORK
Financial security.
There are several studies related to the security-level of ﬁnan-
cial services on various platforms such as mobile apps and web
browsers. Recent studies investigated the security of branchless
banking apps, an emerging ﬁnancial service [36, 47]. Joel et al.
showed that security images, which prevent phishing attacks on on-
line banking systems, are ineffective due to user negligence [39].
To improve the security of ﬁnancial services, many studies have
proposed more practical solutions. Several works propose a multi-