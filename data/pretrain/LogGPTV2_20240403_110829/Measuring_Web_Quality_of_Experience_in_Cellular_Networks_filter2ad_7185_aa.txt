title:Measuring Web Quality of Experience in Cellular Networks
author:Alemnew Sheferaw Asrese and
Ermias Andargie Walelgne and
Vaibhav Bajpai and
Andra Lutu and
&quot;Ozg&quot;u Alay and
J&quot;org Ott
Measuring Web Quality of Experience
in Cellular Networks
Alemnew Sheferaw Asrese1(B), Ermias Andargie Walelgne1, Vaibhav Bajpai2,
Andra Lutu4, ¨Ozg¨u Alay3, and J¨org Ott2
1 Aalto University, Espoo, Finland
PI:EMAIL
2 Technische Universit¨at M¨unchen, Munich, Germany
3 Simula Metropolitan, Oslo, Norway
4 Telefonica Research, Barcelona, Spain
Abstract. Measuring and understanding the end-user browsing Qual-
ity of Experience (QoE) is crucial to Mobile Network Operators (MNOs)
to retain their customers and increase revenue. MNOs often use traﬃc
traces to detect the bottlenecks and study their end-users experience.
Recent studies show that Above The Fold (ATF) time better approxi-
mates the user browsing QoE compared to traditional metrics such as
Page Load Time (PLT). This work focuses on developing a methodol-
ogy to measure the web browsing QoE over operational Mobile Broad-
band (MBB) networks. We implemented a web performance measure-
ment tool WebLAR (it stands for Web Latency And Rendering) that
measures web Quality of Service (QoS) such as TCP connect time, and
Time To First Byte (TTFB) and web QoE metrics including PLT and
ATF time. We deployed WebLAR on 128 MONROE (a European-wide
mobile measurement platform) nodes, and conducted two weeks long
(May and July 2018) web measurement campaign towards eight web-
sites from six operational MBB networks. The result shows that, in the
median case, the TCP connect time and TTFB in Long Term Evolution
(LTE) networks are, respectively, 160% and 30% longer than ﬁxed-line
networks. The DNS lookup time and TCP connect time of the websites
varies signiﬁcantly across MNOs. Most of the websites do not show a
signiﬁcant diﬀerence in PLT and ATF time across operators. However,
Yahoo shows longer ATF time in Norwegian operators than that of the
Swedish operators. Moreover, user mobility has a small impact on the
ATF time of the websites. Furthermore, the website design should be
taken into consideration when approximating the ATF time.
1 Introduction
Recent studies show that mobile data traﬃc is increasing exponentially, and
web browsing is amongst the dominant applications on MBB networks [13]. The
dependency on MBB networks and the widespread availability of LTE is boosting
user expectations towards fast, reliable, and pervasive connectivity. The users
make the MNOs responsible for the shortcomings in the mobile experience [5].
c(cid:2) Springer Nature Switzerland AG 2019
D. Choﬀnes and M. Barcellos (Eds.): PAM 2019, LNCS 11419, pp. 18–33, 2019.
https://doi.org/10.1007/978-3-030-15986-3_2
Measuring Web Quality of Experience in Cellular Networks
19
This demand pushes the MNOs to further enhance the capabilities of the mobile
networks for emerging applications. One of the challenging use cases for MBB
networks is the mobility scenario [28], for example, browsing the web while com-
muting in a high-speed train. Thus, for MNOs, it is paramount to understand the
end-user browsing experience while using their network [16]. Users are mostly
concerned with the fulﬁllment of the quality expectation rather than the level
of the QoS metrics like throughput.
There have been a number of previous eﬀorts (Sect. 4) to measure and under-
stand the performance of MBB networks. NetRadar [34,37], SamKnows broad-
band measurement [12], Meteor [32] are some of the tools that have been devel-
oped to measure the QoS metrics from MBB network. These tools either aim
at measuring the metrics related to QoS or do not indicate how the metrics are
used to measure the QoE. Moreover, web performance and QoE have been well
studied [3,9,13,14,19,25–27,33]. Nonetheless, most of the studies that investi-
gated mobile web QoE are either from lab experiments or do not cover a wide
range of metrics to approximate the end-user browsing experience. As a result,
our understanding of web QoE on operational MNOs is limited. Mainly, this is
because of two reasons: (1) the lack of large-scale measurements that investigate
the application level metrics in operational MBB networks, and (2) the map-
ping of the network QoS to objective application QoS metrics and then to the
subjective QoE, has not been well validated for mobile networks.
Our ﬁrst contribution in this work (Sect. 2) is the design and development of
WebLAR [7], a lightweight tool for measuring the end-user web experience over
operational MNOs. The measurement tool can be deployed at scale and cap-
tures web latency and QoE metrics at diﬀerent layers such as the DNS lookup
time, TCP connect time, PLT, and the ATF time. The ATF time is the time
required to show the content in the browsers’ current viewport [15]. The authors
in [9,25] used two diﬀerent approaches to approximate the ATF time in ﬁxed-
line networks. Asrese et al. [9] used a pixel-wise comparison of the changes in
the browser’s viewport to approximate the ATF time. They capture a series
of screenshots of the webpage loading process and compare the pixel diﬀerence
between consecutive screenshots with a three seconds threshold. When there is
no change observed for three seconds, the webpage is considered as rendered com-
pletely. The ATF time is the diﬀerence between the starting time of the webpage
loading process and the time where the last pixel change is observed. Hora et
al. [25] used the browsers timing information to approximate the ATF time. They
consider that the ATF time is the integral of the downloading time of the main
HTML ﬁle, scripts, stylesheets and the images located in the above-the-fold area.
By adopting the methods from the existing work [9,25], we designed WebLAR
to approximate the ATF time in operational MNOs. In addition, WebLAR cap-
tures network and device level metadata information such as the radio access
technology, the GPS locations, CPU and memory usage in the device. Diﬀerent
confounding factors such as the device aﬀect the QoE. In this work, we build a
baseline view by using MONROE, a platform that can be used for performing
measurements in a more controlled setting.
20
A. S. Asrese et al.
The second contribution of this work (Sect. 3) are the insights derived from
the dataset collected using WebLAR. We deployed WebLAR on MONROE [6],
a Europe-wide experimental platform for MBB network measurement. We mea-
sured the performance of eight popular websites from 128 stationary and mobile
MONROE nodes distributed across Norway and Sweden. In our measurement
campaign, measuring a larger set of websites was not possible because of data
quota limitation. So, we picked eight websites (Appendix A) that are popular in
Norway and Sweden. The result from our analysis shows that there is a diﬀer-
ence in DNS lookup time, and TCP connect time of the websites across diﬀerent
MNOs. For most of the websites, there is no signiﬁcant diﬀerence in PLT and
ATF time across the operators. However, we also observed a big variation in
ATF time of Yahoo between MNOs across diﬀerent countries. That is, Yahoo
has longer ATF time in the Norwegian MNOs. Moreover, we observed that user
mobility does not have a signiﬁcant eﬀect on the web QoE.
The applicability of the aforementioned approaches [9,25] to approximate
the ATF time have not been validated for webpages that have diﬀerent design
style. That is, one approach may work better for certain types of webpages but
may not work well for others. Using the dataset collected using WebLAR, we
showed that the website design should be taken into consideration while using
the browser timing information and the pixel-wise comparison approaches to
approximate the ATF time (Sect. 3.3). We also showed that for the pixel-wise
comparison approach three seconds threshold is suﬃcient to determine when
the content in the above-the-fold area of the webpage is stabilized. To encourage
reproducibility [11], we open source the tool [7], and release the collected dataset
along with the Jupyter notebooks [10] that were used for parsing and analysing
the results.
2 Experiment Design
We begin by presenting our methodology (Sect. 2.1) to approximate the ATF
time of websites. We provide details on the design, the experimental workﬂow
(Sect. 2.2), and the implementation aspects (Sect. 2.3) of WebLAR required for
its deployment on the MONROE platform.
2.1 Methodology
The contents in the above-the-fold area of the webpage (that is, the content
within the current viewport of the browser) are the key parts of the webpage
for the user to judge whether or not the page has downloaded and rendered.
As such, the time at which the contents in the above-the-fold area stop chang-
ing and reach the ﬁnal state is one objective metric to approximate the user
QoE [15]. We refer to this as ATF time. One way to approximate the ATF
time is by monitoring the pixel changes in the visible part of the webpage and
detecting when it stabilizes [9]. Another method is approximating by using the
performance timing information that the browsers provide [25]. Browsers provide
Measuring Web Quality of Experience in Cellular Networks
21
APIs to retrieve performance and navigation time information of the websites.
The two approaches have their limitations. The webpage may not stabilize due
to diﬀerent reasons; for example, it may contain animating contents. As such, it
might be diﬃcult to detect when the webpage stabilizes. This makes it harder to
approximate the ATF time using the pixel-wise approach. Conversely, in some
cases it is diﬃcult to identify the exact location of some types of objects. This is
one of the challenges in approximating the ATF time using the browser’s timing
API. Thus, one approach could better approximate ATF time for certain types
of websites, while the other approach may underestimate or overestimate it.
Recent studies [9,25] have developed tools to estimate the ATF time in ﬁxed-
line networks. We take this forward by designing and developing WebLAR that
measures the web QoE in cellular networks by combining both approaches.
WebLAR can approximate the ATF time using both the pixel-wise compari-
son [9] and using the browser performance timing information [25]. Unlike [9],
where the measurement system approximates the ATF time by downloading
all the web objects at the measurement nodes and pushing them to a cen-
tralized server location for processing, we approximate the ATF time at the
MONROE nodes themselves. For simplicity of notations, we refer the ATF time
approximated using this method as ATFp time. Hora et al. [25] developed a
Google Chrome extension to approximate the ATF time, which requires user
interaction. Since the mobile version of Google Chrome does not support exten-
sions (at least without using additional tools), it is not possible to use the browser
timing information to approximate the ATF time in mobile devices. To close this
gap, WebLAR approximates the ATF time in measurement probes that mimic
mobile devices. We refer the ATF time approximated using this approach as
ATFb time. Moreover, using the browsers timing API, WebLAR also records
metrics such as the DNS lookup time, TCP connect time, TTFB, and PLT. The
browser API also enables us to get the web complexity metrics [22] including the
number and the size of objects of the webpages. WebLAR also captures meta-
data information about the network conditions at the measurement nodes (e.g.,
MBB coverage proﬁles, signal strength) and other information that describe the
user’s mobility (e.g., GPS coordinates) and other events like CPU and memory
usage.
2.2 Experiment Workﬂow
Figure 1 shows the sequence of operations of WebLAR experiment in MON-
ROE measurement platform. The MONROE measurement platform provides
a web interface where the users can submit their custom experiment (#1 in
Figure). The MONROE back-end service then schedules (#2) the submitted
user experiments to the selected nodes. It also starts the execution of the test
according to the parameters that the user provided through the web interface.
Once a node receives the commands for executing an experiment, it checks
whether the docker container that contains the test is available locally. Oth-
erwise, it fetches the docker container from a remote repository. Then the node
starts the container with the parameters given in the MONROE web interface.
22
A. S. Asrese et al.
MONROE  
FRONT END 
MONROE
BACKEND
MONROE
NODES
WEB
SERVERS
1. Submit Experiment 
2. Schedule Experiment 
3. Change default interface 
4. Record Metadata     
5.  Get Webpage 
HTTP[s] GET
s
e
t
i
s
b
e
W
r
e
h
t
o
r
o
f
t
a
e
p
e
R
6. Capture Web QoS,
Complexity and ATF 
7. Calculate Rendering
Time 
8. Stop Metadata Recording 
t
s
r
o