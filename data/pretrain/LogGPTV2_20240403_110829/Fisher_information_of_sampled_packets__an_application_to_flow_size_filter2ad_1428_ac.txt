i /(θi − 1).
p = 0.01. From equation (10), we have (G)i = θ2
−1 be the inverse of function β. Equation (9) yields
Let β
2 /d2, where (cid:2)ej = (b1,j, b2,j)·
−1(θ1)) = −(cid:2)e1 (cid:2)e T
J(β
((cid:2)θ2/((cid:2)θ − 1)). Let j denote the number of sampled packets
in a SYN sampled ﬂow. Then b1,1 = 1, b1,2 = 0, b2,1 = 0.99
and b2,2 = 0.01. The inverse of the Fisher information I−1
(equation (11)) of one sampled ﬂow is
1 /d1 −(cid:2)e2 (cid:2)e T
» −1078
I−1
=
1078
1078 −1078
–
Now assume n ﬂows are sampled. Thus the lower bound
on the mean squared error of estimates ˜γ1 and ˜γ2 obtained
using the Cram´er-Rao bound will be E[(γ1− ˜γ1)2] ≥ 1078/n
and E[(γ2 − ˜γ2)2] ≥ 1078/n. The Cram´er-Rao bound of
parameters (cid:2)θ comes from the delta method as seen in Sec-
tion 3.2. Matrix H is
»
–
H =
0.105
0
0 0.105
.
3.3.2 Essential information from TCP sequence num-
bers
Consider the problem of estimating ﬂow size distribution
using packet counts, and SYN and sequence number in-
formation as deﬁned in Section 2.2. The data processing
inequality [17] states that adding information can only in-
crease the Fisher information. Thus, we expect that an eﬃ-
cient estimator using extra information performs better, or
at least no worse, than an eﬃcient estimator that does not
use the extra information. This clearly holds as one can al-
ways throw the extra information away inside the estimator.
For our next example, assume a maximum ﬂow size W = 4
and (cid:2)θ = (0.56, 0.08, 0.18, 0.18). The elements of B are bi,1 =
(1 − p)i−1 and bi,j = p(1 − p)i−j for j > 1. We compute the
Cram´er-Rao bound for a sampling rate of p = 1/100. Also
consider the estimation using packet counts over SYN ﬂows
(SYN-pktct) as deﬁned in Section 2.2. Figure 1 shows the
Cram´er-Rao bound obtained with 108 sampled ﬂows under
this scenario. Clearly the addition of TCP sequence num-
bers drastically increases the Fisher information of the sam-
ples. This increase in the Fisher information is translated
into a much smaller lower bound on estimation error. The
graph also shows that the SYN-pktct estimator is able to
gather very little information about the original ﬂow sizes.
Next we look at an example where the Fisher information
is used to obtain the number of samples needed by a given
estimate error using diﬀerent types of protocol information.
3.4 Minimum number of samples required
for high quality estimates
The Fisher information is also a powerful tool to adjust
measurement parameters. Through the Cram´er-Rao bound,
one can assess the minimum number of samples needed to
achieve a given error.
In the following example we use
W = 20 and p = 1/200 and calculate how many samples
are needed until the best unbiased estimator can achieve a
mean standard deviation error of 0.1 for ﬂows of size one.
In the following experiment we renormalized the ﬂow size
distribution obtained from the Sprint backbone network.
The ﬂow size distribution renormalization creates a distri-
bution (cid:2)θ that is a re-scaled true Internet ﬂow size distri-
bution but with maximum ﬂow size W . The original dis-
tribution comes from the trace BB-East-1, summarized in
Table 3 at the beginning of Section 5. The results show
that without any protocol information, only using packet
counts (ALL-pktct), the best unbiased estimator needs at
least 2.25 × 1016 sampled ﬂows. Using SYN sampled ﬂows
and packet counts (SYN-pktct) the best unbiased estimator
needs at least 3.4×1016 sampled ﬂows (from where 7.5×1015
are SYN sampled ﬂows). On the other hand, the best unbi-
ased estimator using SYN ﬂags and TCP sequence numbers,
ALL-seq-sﬂag, needs a dramatically lower number: 4 × 104
sampled ﬂows. These ﬁndings are summarized in Table 2.
Next we shortly present MLEs for the ALL-pktct, SYN-
pktct, SYN-seq and ALL-seq-sﬂag estimators. Experimen-
tally we will ﬁnd that the ALL-seq-sﬂag MLE is eﬃcient in
that it approaches the Cram´er-Rao bound even for a small
sample size, n = 260, 000.
Thus from (13), the mean squared error of any unbiased
estimates ˜θ1 and ˜θ2 of θ1 and θ2 respectively are: E[(θ1 −
˜θ1)2] ≥ 1092/n and E[(θ2 − ˜θ2)2] ≥ 1092/n for n sampled
ﬂows, given n suﬃciently large.
4. FINDING AN OPTIMAL UNBIASED
ESTIMATOR
The Maximum log-Likelihood Estimator (MLE), ﬁnds a
Lower bound on the flow size distribution estimator error
from 100 million SYN sampled flows
is α(n)(
ˆ(cid:2)d (n);
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
e
t
a
m
i
t
s
e
i
i
e
z
s
w
o
l
f
e
h
t
f
o
r
o
r
r
e
n
o
i
t
i
a
v
e
d
d
r
a
d
n
a
S
t
 1
 2
Flow size i
 3
 4
Estimator using packet counts
Estimator using TCP sequence numbers
Figure 1: Cram´er-Rao bounds of the examples on
Section 3.3.2. This graph compares the estimation
of SYN-pktct to the SYN-seq. Notice that adding
TCP sequence numbers to the estimation greatly
improves its quality.
˜(cid:2)θ that maximize the log-likelihood of the
set of parameters
sampled data. Under the same regularity conditions as re-
quired for the Cram´er-Rao bound, the MLE is an asymptot-
ically eﬃcient unbiased estimator of (cid:2)γ, i.e., its error achieves
the Cram´er-Rao lower bound as the number of samples tends
to inﬁnity. As in practice we do not have a very large num-
ber of samples, we would like it to be eﬃcient using the
number of samples typically collected at Tier-1 backbone
routers. This section presents MLEs for the models in Sec-
tion 2. In particular we show that the ALL-seq-sﬂag MLE
does not require a large number of samples to be unbiased
and achieve the Cram´er-Rao error lower bound. In addition,
we present a conjugate gradients algorithm for the MLE, a
faster convergence algorithm than the commonly used Ex-
pectation Maximization algorithm.
We estimate the MLE over function α(n) through the
use of penalty functions for the constraints in (6) and (7).
Whenever a value of (cid:2)θ violates one of the constraints, the
likelihood function receives a penalty, which in the end forces
the search to remain within the constrained region. To sim-
plify analysis, we generate synthetic sampled ﬂows for the
traﬃc in an idealized fashion. In the ﬁrst part of this section
we estimate the ﬂow size distribution using only SYN sam-
pled ﬂows. This, of course, does not account for the “noise”
introduced by ﬂow-splitting, which splits one long original
ﬂow into two or more shorter ones. We will not account for
ﬂow splitting, although [11] shows that is possible to do so.
We will evaluate the complete model with “noise” in Sec-
tion 5 on an actual trace. Next we introduce the MLE for
our model.
˜(cid:2)θ). The MLE can be written as
˜(cid:2)θ = arg max
˜(cid:2)θ)j
˜(cid:2)θ
X
ln(B
ˆd
j
(n)
n
∀j∈L
(15)
P
i
subject to
˜θi = 1 and 0 < ˜θi < 1, ∀i ∈ {1, . . . , W}.
First we consider the SYN-pktct MLE as proposed in [3].
We analyze the Expectation Maximization (EM) algorithm,
used in [3] to ﬁnd a solution of the log-likelihood equation
(n)
(15). Let ˆD
(S,r) denote the number of SYN sampled ﬂows
(n)
with label r sampled packets. Let ˆd
(S,r) be the fraction of
SYN sampled ﬂows with r sampled packets, as deﬁned by
(4).
We detail the approach in [3] for the sake of completeness.
ˆ(cid:2)θ (n) by the successive
The EM algorithm ﬁnds the MLE
reﬁnement of previous estimates:
(k+1)
˜θ
i
(k)
= ˜θ
i
X
∀j∈L
PW
(n)
bi,j ˆd
(S,j)
(k)
˜θ
r br,j
r=1
,
where
˜(cid:2)θ(0) is an initial guess of (cid:2)θ.
Although the EM algorithm is sound, needs no ﬁne tuning,
and is guaranteed to always improve the estimate at each
step, in practice it can suﬀer from slow convergence [14].
More speciﬁcally, Theorem 5.2 in [14] shows that if the pa-
rameters (cid:2)θ are “poorly separable” then EM exhibits a slow
convergence rate. The term “poorly separable” can be quan-
tiﬁed as the diﬃculty of distinguishing whether a sample j
, i.e., if bi,jθi ≈ bi(cid:2),jθi(cid:2) .
(cid:2)
came from ﬂow sizes i or i
Unfortunately, ﬂow size estimation suﬀers from this vileness.
Although one expects that other maximum likelihood algo-
rithms will also suﬀer with these “poorly separable” param-
eters, it is believed that in practice the eﬀect is felt more
by EM [14] (conjecture strengthened by our practical expe-
rience with our EM and conjugate gradients method imple-
mentations when applied to the ﬂow size estimation prob-
lem).
with i (cid:7)= i
(cid:2)
We instead use the method of conjugate gradients [13] to
compute a solution to (15). Our conjugate gradients MLE
algorithm was implemented with the help of the wnlib li-
brary1.
trix B and the gradient ∇ ˜(cid:2)θ ln α(n)(
PW
X
For the above algorithm to work, need to provide the ma-
˜(cid:2)θ) conditioned on
ˆ(cid:2)d (n);
i=1 θi = 1. The i th component of our gradient is
− 1.
jPW
˜(cid:2)θ) =
bi,j ˆd
ln α
ˆ(cid:2)d
(n)
(n)
(n)
(
;
∂
∂θi
∀j∈L
˜θr br,j
r=1
The remaining constraints 0 < ˜θi < 1, ∀i ∈ {1, . . . , W} are
introduced as penalty functions. Like EM, the conjugate
˜(cid:2)θ (0). The
gradient algorithm also requires an initial guess
only requirement for any initial guess is that no ﬂow size
can have zero probability.
4.2 The use of TCP sequence numbers on SYN
sampled ﬂows
4.1 MLE with conjugate gradients
Let n be the number of sampled ﬂows and n ˆd
the num-
ber of sampled ﬂows with label j ∈ L. The likelihood func-
j
tion with respect to parameters (cid:2)θ, as deﬁned in Section 3.1,
(n)
The following two experiments, with results shown in Fig-
ures 2 and 3, were designed to compare the use of various
types of information on the MLE accuracy. Let W = 50 be
1http://www.willnaylor.com/wnlib.html
the maximum ﬂow size and p = 1/200 be the packet sam-
pling rate. We use samples from a renormalized ﬂow size dis-
tribution obtained from the Sprint backbone network. The
renormalized ﬂow size distribution is based on the distribu-
tion of the BB-East-1 trace, summarized at the beginning of
Section 5 in Table 3. These experiments use 1012 synthet-
ically generated ﬂows that, in average, produce 1.8 × 1010
sampled ﬂows after packet sampling (from where 5× 109 are
SYN sampled ﬂows). The initial value for the MLE opti-
mization is ˜θ
(0)
i = 1/W .
which amounts to 80% of the sampled ﬂows in the BB-East-1
trace. The estimator accuracy could be increased by adding
the remaining 80% of the sampled ﬂows to the estimator.
In [3] the authors argue that there are not enough SYN
ﬂows to ﬁnd good estimates using the SYN-pktct MLE. In
what follows we consider all sampled ﬂows and show that
the best estimator in [3], “ALL-pktct MLE” according to
our nomenclature, also suﬀers from the same problems as
the SYN-pktct MLE. We further show that adding ﬂows
without a SYN sampled packet drastically increases the ac-
curacy of the estimator that uses TCP sequence numbers.
4.3 MLEs using all sampled ﬂows
Incorporating SYN ﬂag information for all sampled ﬂows
can be done seamlessly in the SYN-seq estimator and even in
the SYN-pktct estimator. This extension can potentially in-
crease the accuracy of the ALL-pktct MLE presented in [3].
However we will restrict this modiﬁcation to the estimator
with TCP sequence numbers further referred as “ALL-seq-
sﬂag estimator”. In this section we compare the ALL-seq-
sﬂag MLE to the ALL-pktct MLE.
Figure 2: Flow size distribution estimate obtained
with SYN-pktct and SYN-seq MLEs. Obtained us-
ing 120 runs with 5 × 109 SYN sampled ﬂows each