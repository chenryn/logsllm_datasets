ity to monitor their internet connection, but cannot easily
inﬁltrate Tor nodes and web servers outside the country.
Fingerprinting attacks on encrypting tunnels. Sev-
eral researchers have developed web page ﬁngerprinting at-
tacks on encrypted web traﬃc, as occurs when the victim
uses HTTPS, link-level encryption, such as WPA, or an en-
crypting tunnel such as SSH, a VPN, or IPSec [2, 4, 9, 10,
11, 13, 14, 20, 27, 28, 6]. Most attacks against these systems
focus on packet sizes, and many throw away all information
about packet ordering. Packet sizes do carry a lot of in-
formation in these scenarios, where data packets are simply
padded to a multiple of the block size (typically 16 bytes),
but Tor pads all data packets to a multiple of 512 bytes,
providing much less information. Most recently, Dyer et
al. performed a thorough survey of past attacks and past
network-level defenses and found that no network-level de-
fense was secure [6]. They did not evaluate application-level
defenses, such as HTTPOS or randomized pipelining.
The unpublished work of Danezis [4] is also worth pointing
out, since it uses HMMs to model entire web sites in much
the same way that we do. Lu, et al., propose a ﬁngerprint
based on edit distance [14], but their ﬁngerprints depend
heavily on packet size information, which is not available
when attacking Tor users. Yu, et al. [27] also proposed to use
HMMs to model web sites, but their observations consisted
only of the amount of time a victim spent viewing each page,
and hence their success rate was not very high.
Fingerprinting attacks on Tor. There is relatively lit-
tle research on ﬁngerprinting attacks on Tor. Herrmann, et
al., used a Multinomial Naive Bayes classiﬁer on features
that captured no information about packet ordering – only
packet sizes [10]. They applied this classiﬁer to several en-
crypting tunnels, such as SSH, and achieved over 94% suc-
cess in recognizing packet traces from a set of 775 possible
web pages. When they applied this classiﬁer to Tor, how-
ever, they had less than a 3% success rate on the same set
of web pages. In the same year, Shi, et al., proposed to use
cosine similarity on feature vectors that represented some
ordering information about packets, but they achieved only
a 50% success rate on a set of 20 web pages [19]. Panchenko,
et al., used ad hoc, HTTP-speciﬁc features with support vec-
tor machines to achieve a 54.61% success rate on the same
data set [17]. We re-implemented their attack and obtained
a 65.4% success rate on our data set of 100 web pages.
Proposed traﬃc analysis defenses.
IP- and TCP-
level defense mechanisms involve padding packets, splitting
packets into multiple packets, and inserting dummy pack-
ets. Fu, et al., performed an early theoretical analysis of
constant-rate transmission of ﬁxed-size packets as a defense
mechanism [8]. Surprisingly, they found that variations in
load at the sender caused detectable variations in transmis-
sion time, implying that transmitting at random intervals
provides better defense against analysis. Wright, et al., pro-
posed a technique for morphing one traﬃc pattern to look
like another pattern [26]. Their morphing algorithm only
mapped one packet size distribution onto another – it did
not change the sequencing of packets or handle correlations
between the sizes of successive packets. They also proposed
a variant of their defense that would only enlarge packets – it
never split or re-ordered packets. Since our attack works well
even without packet size information, it can defeat this ver-
sion of traﬃc morphing (our experiments achieved an 81%
success rate, described later). Lu, et al., later analyzed traf-
ﬁc morphing, including an extension to morphing on the
distribution of packet size n-grams [14].
At NDSS 2011, Luo, et al., described HTTPOS, a col-
lection of HTTP- and TCP-level tricks for fooling traﬃc
analysis attacks previously described in the literature [15].
At the TCP level, they manipulate MSS options and and
window sizes to perturb the size and ordering of packets in
the TCP stream. At the HTTP level, they split single re-
quests into multiple possibly overlapping requests using the
HTTP Range feature, re-order some requests via pipelining,
generate some extra, unnecessary requests, and insert some
extra data into HTTP GET headers. Our attack is able to
defeat their prototype implementation of HTTPOS.
The Tor project recently proposed a traﬃc analysis de-
fense based on “randomized pipelining”, in which the browser
loads images and other embedded content in a random or-
der [18]. It also pipelines random subsets of these requests.
Even with this defense in place, our attack is able to identify
the target web page over 87% of the time in our experiments.
Other related work. A few previous papers are notable
for using similar techniques on similar problems. Wright,
et al., used HMMs for protocol classiﬁcation of encrypted
TCP streams [25], i.e. to determine whether an encrypted
connection was an HTTP, SMTP, POP, IMAP, etc. session.
More recently, White, et al., used HMMs to recover partial
plaintext of encrypted VoIP conversations [24].
3. RECOGNIZING WEB PAGES
Web pages can consist of multiple objects, such as HTML
ﬁles, images, and ﬂash objects, and browsers send separate
requests for each object. Browsers may use a combination
of multiple TCP connections and pipelining in order to load
pages more quickly [12]. Furthermore, browsers may begin
issuing requests for objects referenced in a web page before
they have ﬁnished loading that page.
Note, however, that there is some inherent stability in the
ordering of requests: browsers cannot request an object until
they have received the portion of a page that references it.
The sequence of requests and responses may vary each time
the browser loads the page: some requests may be delayed
due to CPU load or packet re-ordering, and some requests
(or responses) may be omitted if the browser has a copy of
the object in its cache. Dynamic web pages may also vary
slightly in the size and number of objects they contain, and
hence in the number of requests sent by the browser and the
total number of packets returned by the server.
Web privacy proxies, such as Tor and SSH, multiplex these
data transfers over a single, encrypted channel, so an at-
tacker can only see the size, direction, and timing of packets
in the multiplexed stream. Tor furthermore sends all data
in 512-byte cells, so packet sizes carry limited information.
These facts suggest a simple representation for the at-
tacker’s traﬃc observations, and a similarity metric the at-
tacker can use to compare traces. Our attack represents
a trace of (cid:96) packets as a vector t = (d1, . . . , d(cid:96)), where
di = ±si, where si is the size of the ith packet and the
sign indicates the direction of the packet. Our attack com-
pares traces t and t(cid:48) using the Damerau-Levenshtein edit
distance [16], which is the length of the shortest sequence
of character insertions, deletions, substitutions, and trans-
positions required to transform t into t(cid:48). In the context of
607our packet traces, these edits correspond to packet and re-
quest re-ordering, request omissions (e.g. due to caching),
and slight variations in the sizes of requests and responses.
Thus, this model and distance metric are a good match for
real network and HTTP-level behavior.
The Damerau-Levenshtein algorithm supports diﬀerent costs
for each operation. Ideally, these costs would be tuned to
match the probability of packet drops, retransmissions, etc.
in the real network. We experimented with several cost
schemes; the impact was mild, but the attack yielded best
results when transpositions were 20 times cheaper than in-
sertions, deletions, and substitutions. We did not explore
this parameter thoroughly – a better approach would be to
learn optimal costs from the training data using the recently-
proposed method of Bellet, et al. [1].
We found that TCP ACK packets reduce the performance
of our classiﬁer. This seems natural: inserting an ACK after
every packet essentially makes all traces look more similar –
they’re all half ACKs. Our Tor classiﬁer deletes all 40 and
52 byte packets from the traces. Our SSH classiﬁer deletes
all packets of size 84 or less.
Since Tor transmits data in 512-byte cells, our attack also
rounds all packet sizes up to a multiple of 600 (we use 600
instead of 512 in order to account for other inter-cell headers
and overhead).
In some of the experiments described in
Section 6, we deleted all packet size information, i.e. traces
were reduced to sequences of ±1s.
Our attack normalizes the edit distance to compensate for
the large variation in the lengths of packet traces. If d(t, t(cid:48))
is the Damerau-Levenshtein edit distance, the attack uses
L(t, t
(cid:48)
) =
d(t, t(cid:48))
min(|t|,|t(cid:48)|)
where |t| is the number of packets in trace t. The classi-
ﬁer normalizes by the minimum of the two lengths because,
if t and t(cid:48) are very diﬀerent in length, then they are prob-
ably from diﬀerent web pages.
In this case, dividing by
min(|t|,|t(cid:48)|) will result in a relatively large normalized dis-
tance, which is desirable. Other normalization factors, such
as |t| + |t(cid:48)| and max(|t|,|t(cid:48)|), yielded worse results.
To build a classiﬁer for recognizing encrypted, anonymized
page loads of 1 of n web pages, an attacker collects k traces
of each page, using the same privacy system, e.g. Tor or an
SSH proxy, in use by the victim. He then trains a support
vector machine [22] using a kernel based on edit distance:
K(t, t
(cid:48)
) = exp(−γL(t, t
(cid:48)
)2)
The γ parameter is used to normalize L so that it’s outputs
fall into a useful range. In our experiments, we found γ = 1
works well. We also adjusted the SVM cost of misclassiﬁca-
tions to be 4, based on early experimental results.
Intuitively, an SVM kernel function acts as an inner prod-
uct on a vector space, allowing the SVM to measure the
angle between two vectors. Vectors with a small angle are
considered more similar by the SVM and likely to be placed
in the same class. The above kernel will assign traces with
a small distance an “inner product” close to 1, indicating a
small angle between them and hence high similarity. Traces
with a large distance will have kernel value close to 0, cor-
responding to a large angle and hence low similarity.
This basic approach can be customized in several ways,
depending on the application. For example, instead of view-
ing the observed network traﬃc as a sequence of packets, as
above, an attacker could view it as a sequence of 512-byte
Tor cells, or even as a sequence of bytes, if appropriate. He
would then generate a trace vector of ±1s for each cell or
byte of traﬃc. Finally, the attacker could encode timing in-
formation by inserting additional “pause” symbols into the
trace whenever there is a long gap between packets.
We brieﬂy explored several of the above variations in our
attack on Tor. We tried representing traces as a sequence
of Tor cells instead of as a sequence of packets. Classiﬁer
performance degraded slightly, suggesting that the Tor cells
are often grouped into packets in the same way each time a
page is loaded. We tried adding pause symbols to our traces,
but this made no contribution to classiﬁer performance. An
early version of our attack classiﬁed traces using a nearest
neighbor algorithm: to classify trace t, the attacker com-
puted t∗ = argmint(cid:48) L(t, t(cid:48)) over every trace in his database,
and guessed that t was from the same web page as t∗. This
attack correctly guessed a victim’s web page (out of 100
possibilities) over 60% of the time. Finally, we tried us-
ing a metric embedding to convert our variable-length trace
vectors into ﬁxed-length vectors in a space using the (cid:96)2-
norm, and then used an SVM to classify these vectors. This
performed substantially worse than the SVM classiﬁer with
distance-based kernel described above.
4. RECOGNIZING WEB SITES
As the evaluation results in Section 6 will show, the classi-
ﬁer described above is quite good at determining which of n
web pages a user is visiting, assuming the user is visiting one
of those n pages. However, attackers often want to answer
a slightly diﬀerent question: “Is the user visiting one of a
small list of banned web sites?” There are three diﬀerences
between the previous scenario and this one: (1) there is no
prior assumption about which sites the user may be visiting;
(2) the attacker wants to know if the user is visiting any of
the pages on a banned web site; and (3) the attacker will
want a high degree of conﬁdence in the answer.
To answer this type of question, an attacker can construct
a Hidden Markov Model for each target web site, and use
the forward algorithm to compute the log-likelihood that
a given packet trace would be generated by a user visiting
the target web site. If the log-likelihood is below a certain
threshold, then he can conclude that the user is visiting the
web site, otherwise she is not.
In our web site model, each web page corresponds to an
HMM state, and state transition probabilities represent the
probability that a user would navigate from one page to an-
other. These transition probabilities, along with the initial
state probabilities, can be derived from the link structure of
the web site and observations of real user behavior.
To complete the HMM, the attacker must deﬁne the set,
O, of observations and, for each observation o ∈ O and HMM
state s, the probability, Pr[o|s], that the HMM generates
observation o upon transitioning to state s. Our attack uses
the classiﬁer from the previous section for this purpose. The