I have installed Nginx, uWSGI, and Django on a VDS with 3 CPU cores. uWSGI is configured to use 6 processes, each with 5 threads. My goal is to configure uWSGI to utilize processes for load balancing until all processes are busy, and then to use threads if needed. However, it seems that uWSGI prefers using threads, and I haven't found a configuration option to change this behavior. Currently, the first process consumes 100% of the CPU time, the second one about 20%, and the remaining processes are mostly idle.

Our site receives around 40 requests per second (r/s). Typically, 3 processes without threads are sufficient to handle all requests. However, request processing occasionally hangs due to issues like locked shared resources, resulting in a situation where we effectively have -1 available process. Users, frustrated by the delay, repeatedly click the link, leading to all processes becoming hung and causing further delays for all users.

I considered adding more threads to improve server robustness, but the Python Global Interpreter Lock (GIL) limits the effectiveness of threads in utilizing all CPU cores. Multiple processes generally work better for load balancing, but threads can be helpful in cases of locked shared resources or I/O wait delays. A process can continue doing other work while one of its threads is locked.

I do not want to decrease time limits unless absolutely necessary, as I prefer to avoid showing error messages to users or making them wait for every request. In theory, the problem could be solved with threads, and I would like to explore this option before resorting to other measures.

**Questions:**
1. Is there a way to configure uWSGI to prioritize processes over threads for load balancing?
2. How can I ensure that multiple threads per process are used effectively without degrading performance?
3. Are there any uWSGI features or configurations that can help dynamically spawn more processes when the server is overloaded?

**Additional Information:**
- The current uWSGI version is 2.0.19.
- I am considering using uWSGI's cheaper modes to dynamically manage processes based on load.

---

**Response:**

Thank you for providing detailed information about your setup and the challenges you are facing. Here are some suggestions and clarifications to help you optimize your uWSGI configuration:

### 1. Prioritizing Processes Over Threads
uWSGI does not have a direct configuration option to prioritize processes over threads. However, you can achieve a similar effect by carefully configuring the number of processes and threads. 

To ensure that processes are fully utilized before threads, you can:
- **Reduce the number of threads per process**: Start with fewer threads per process (e.g., 2-3) and increase the number of processes. This will make uWSGI more likely to use processes first.
- **Use `lazy-apps` and `lazy` options**: These options can help in managing the startup and shutdown of processes and threads more efficiently.

### 2. Effective Use of Threads
To ensure that multiple threads per process are used effectively:
- **Ensure stable uWSGI release**: Make sure you are using a stable version of uWSGI with solid threading support, such as 2.0.19 or later.
- **Check for lock contention**: Investigate if there is significant lock contention or other resource bottlenecks. Tools like `gprof` or `py-spy` can help identify these issues.
- **Optimize application code**: Ensure that your Django application is optimized for multi-threading. Avoid global locks and use thread-safe data structures.

### 3. Dynamic Process Management
uWSGI provides several features to dynamically manage processes based on load:
- **Cheaper modes**: Use the `cheaper` mode to dynamically spawn more processes when the server is overloaded. For example:
  ```ini
  [uwsgi]
  cheaper = 1
  cheaper-algo = busyness
  cheaper-overload = 20
  ```
  This configuration will start additional processes when the average load exceeds 20%.

- **Harakiri and Harakiri-verbose**: Set a reasonable timeout for requests to prevent them from hanging indefinitely. For example:
  ```ini
  harakiri = 30
  harakiri-verbose = true
  ```

- **Max-worker-lifetime**: Set a maximum lifetime for worker processes to ensure they are periodically recycled, which can help in case of memory leaks or other issues.
  ```ini
  max-worker-lifetime = 3600
  ```

### Example Configuration
Here is an example uWSGI configuration that incorporates the above suggestions:
```ini
[uwsgi]
http = :8000
chdir = /path/to/your/project
module = your_project.wsgi:application

# Number of processes and threads
processes = 6
threads = 2

# Lazy loading of applications
lazy-apps = true
lazy = true

# Cheaper mode for dynamic process management
cheaper = 1
cheaper-algo = busyness
cheaper-overload = 20

# Timeout and verbose logging for long-running requests
harakiri = 30
harakiri-verbose = true

# Recycle workers after 1 hour
max-worker-lifetime = 3600
```

By following these steps, you should be able to better balance the load between processes and threads, and dynamically manage the number of processes based on the server load. If you continue to experience issues, further profiling and optimization of your application may be necessary.