ignores their dependence. Therefore, our advanced inference
attack is still effective even for realistic adversaries with partial
auxiliary information.
Violating DP Guarantees: We ﬁrst prove that the max-
imum information leakage due to a DP-adversary, quantiﬁed
by the metric in Eq. 11, is bounded by . This is the upper
bound on the information leakage from a differentially private
query output due to a DP-adversary.
Theorem 2. The Leaked Inf ormation (in Eq. 11) for an
-differentially private mechanism is bounded by .
Detailed proof for Theorem 2 is deferred to the appendix.
As illustrated in Fig. 5(b), the information leakage due to
a DDP-adversary, that exploits dependence relationships be-
tween tuples, exceeds the upper bound computed on a DP-
adversary. This proves our claim that a DDP-adversary can
violate the security guarantees provided by DP mechanisms.
From our analysis, we can see that a differential privacy
technique performed on a dependent data set will disclose
more information than expected, and this is a serious privacy
violation which hinders its applications to real-world data
that may be inherently dependent. Note that we used the
location data just as an example, and our attack observations
are broadly applicable to any dataset that exhibits probabilistic
dependence between user records. Therefore, we have to take
the dependent relationships into consideration when applying
differential privacy to real-world dependent tuples.
V. DEPENDENT DIFFERENTIAL PRIVACY
As demonstrated in Section IV, DP underestimates the
privacy risk in the presence of dependent tuples, resulting in
degradation of expected privacy for existing DP mechanisms.
Hence, for databases with dependent tuples, a stronger privacy
notion is required.
Recent work has made attempts to capture and model
this notion of tuple dependence and correlation in databases.
The Pufferﬁsh framework [25], proposed as a generalization
of DP, incorporates adversarial belief about a database and
its generation as a distribution over all possible database
instances. The Blowﬁsh framework [21], which is a subclass of
the Pufferﬁsh framework, allows a user to specify adversarial
knowledge about the database in the form of deterministic
policy constraints.
Motivated by the above frameworks, we formalize the
notion of dependent differential privacy, as a subclass of
the general Pufferﬁsh framework, incorporating probabilistic
dependence between the tuples in a statistical database. In
addition, we also propose an effective perturbation mechanism
(Section VI) that can provide rigorous privacy guarantees. In
contrast, there are no general algorithms known for achieving
Pufferﬁsh privacy.
For any database D = [D1, D2,··· , Dn], we deﬁne its
6
0100020003000400000.20.40.60.81Inference Error (Km)Cumulative Distribution Function  ε=0.1, w/o social relationshipsε=0.1, with social relationshipsε=1, w/o social relationshipsε=1, with social relationships00.511.522.53012345678Privacy Budget εLeaked Information  with social relationships, Nprior=6968w/o social relationships, Nprior=6968with social relationships, Nprior=3500security guarantee by DPdependence size to be L if any tuple in D is dependent on
at most L − 1 other tuples. We denote by R the probabilistic
dependence relationship among the L dependent tuples. Re-
lationship R could be due to the data generating process as
speciﬁed in [24] or could be due to other social, behavioral
and genetic relationships arising in real-world scenarios. We
provide an instance of R in Section IV, where dependence in
the Gowalla location dataset was introduced via the Gowalla
social network dataset and such dependence is probabilistic
instead of deterministic as in Blowﬁsh framework [21]. The
DDP framework is equivalent to the DP framework when R
represents independence between data tuples. We begin by
deﬁning the dependent neighboring databases as follows:
Deﬁnition 3. Two databases D(L,R), D(cid:48)(L,R) are depen-
dent neighboring databases, if the modiﬁcation of a tuple value
in database D(L,R) (e.g., the change from Di in D(L,R)
i) causes change in atmost L − 1 other tuple values in
to D(cid:48)
D(cid:48)(L,R) due to the probabilistic dependence relationship R
between the data tuples.
Based on the above dependent neighboring databases, we
deﬁne our dependent differential privacy as follows.
Deﬁnition 4. (-Dependent Differential Privacy) A randomized
algorithm A provides -dependent differential privacy, if for
any pair of dependent neighboring databases D(L,R) and
D(cid:48)(L,R) and any possible output S, we have
P (A(D(L,R)) = S)
P (A(D(cid:48)(L,R)) = S)
max
D(L,R),D(cid:48)(L,R)
(12)
where L denotes the dependence size and R is the probabilistic
dependence relationship between the data tuples.
≤ exp()
From Deﬁnition 4, we see that dependent differential
privacy restricts an adversary’s ability to infer the sensitive
information of an individual tuple, even if the adversary has
complete knowledge of the probabilistic dependence relation-
ship R between the tuples.
A. Security Analysis
Dinur et al. [11] proved that unless a particular amount
of noise is added to the query responses, an adversary can
use a polynomial number of queries to completely reconstruct
the database. Therefore, any privacy framework must provide
privacy guarantees for multiple queries, in order to defend
against such composition attacks [11], [18]. In the following,
we show that DDP is secure against these composition attacks.
Here, ‘secure’ means that the algorithms that provide strict
DDP also provide meaningful privacy in the presence of aux-
iliary information. To this end, we propose both the sequential
composition theorem and the parallel composition theorem for
DDP by extending the previous results on composition for DP
in [30]. Our analysis show that the composition properties for
DDP provide privacy guarantees in a well-controlled manner,
rather than collapsing rapidly as other approaches in [18]. The
proofs for Theorems 3 and 4 follow directly from the ones
presented in [30] for differential privacy and are deferred to
the appendix to improve readability.
Sequential Composition Theorem Multiple queries that each
provides dependent differential privacy in isolation provide
dependent differential privacy in sequence.
7
Fig. 6. Separation for different queries under dependent tuples.
Theorem 3. Let randomized algorithm At each provide t-
dependent differential privacy under the dependence size L
and probabilistic dependence relationship R over the same
input data D. The sequence of these algorithms At provides
(cid:80)
t t-dependent differential privacy under the same L,R.
Parallel Composition Theorem When the queries are applied
to disjoint subsets of the data, we have the parallel composition
theorem as
Theorem 4. Let randomized algorithms At provide t-
dependent differential privacy under the dependence size L
and probabilistic dependence relationship R. We denote by
Dt the arbitrary disjoint subsets of the input domain D. The
sequence of these randomized algorithm At provides max
t-
dependent differential privacy under the same L,R.
B. Privacy Axioms
t
Kifer et al. in [23] suggested two privacy axioms: trans-
formation invariance and convexity that should be satisﬁed by
any consistent privacy deﬁnition. The following theorems show
that our DDP satisﬁes both the axioms.
Theorem 5. Transformation Invariance Property: For a ran-
domization algorithm A that satisﬁes -dependent differential
privacy under the dependence size L and probabilistic depen-
dence relationship R and any other randomization algorithm
B, BA(·) = B(A(·)) also satisﬁes -dependent differential
privacy under the same L,R.
Theorem 6. Convexity Property: For two randomization algo-
rithms A1,A2 that both satisfy -dependent differential privacy
under the dependence size L and probabilistic dependence
relationship R, let Ap represent an algorithm that runs A1
with probability p and runs A2 with probability 1 − p, then
Ap also satisﬁes -dependent differential privacy under the
same L,R.
Proofs for the above two theorems are also deferred to
appendix to improve readability.
VI. MECHANISM DESIGN FOR DDP
In this section, we design an effective mechanism to
achieve -dependent differential privacy and support private
query results over dependent tuples. We also describe exten-
sions to the existing LPM-based differential privacy scheme
that allows it to be used in the DDP setting.
To provide more insights into our privacy mechanism de-
sign, we take a further look at Example 1 in Section III. Recall
that the probabilistic dependence relationship R was speciﬁed
(cid:11)(cid:12),ijijQDDDD(cid:170)(cid:186)(cid:32)(cid:14)(cid:172)(cid:188)(cid:11)(cid:12),ijijQDDDD(cid:170)(cid:186)(cid:32)(cid:16)(cid:172)(cid:188)0.5(cid:72)(cid:72)(cid:11)(cid:12),ijijQDDDD(cid:170)(cid:186)(cid:32)(cid:172)(cid:188)(cid:60)(cid:11)(cid:12)(cid:11)(cid:12)1,ijPDdDS(cid:170)(cid:186)(cid:32)(cid:32)(cid:172)(cid:188)(cid:25)(cid:11)(cid:12)(cid:11)(cid:12)2,ijPDdDS(cid:170)(cid:186)(cid:32)(cid:32)(cid:172)(cid:188)(cid:25)1.5(cid:72)(cid:72)(cid:72)(cid:72)P
P
(cid:17)
(cid:16)
A([Di = di1, Dj]) = [(cid:101)di,(cid:101)dj]
(cid:16)
(cid:17)
A(Di = [di2, Dj]) = [(cid:101)di,(cid:101)dj]
P ((cid:101)Di =(cid:101)di|Di = di1)(cid:80)
P (Dj = dj|Di = di1)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
P ((cid:101)Di =(cid:101)di|Di = di2)(cid:80)
P (Dj = dj|Di = di2)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
(cid:80)
P ((cid:101)Di =(cid:101)di|Di = di1)
(cid:80)
P ((cid:101)Di =(cid:101)di|Di = di2)
P (Dj = dj|Di = di1)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
P (Dj = dj|Di = di2)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
max
di1 ,di2
dj
dj
dj
dj
max
di1 ,di2
= max
di1 ,di2
≤ max
di1 ,di2
(12)
as Dj = 0.5Di + 0.5X where Di, X are independently and
uniformly distributed within [0, 1].
Quantifying the performance of LPM: We use separa-
tion as a metric to analyze the performance of the LPM-based
differential privacy scheme under dependent tuples. Separa-
tion measures the maximum difference between two Laplace
distributions of P (A([Di = d1, Dj]) = S) and P (A([Di =
d2, Dj]) = S). Smaller separation implies better privacy
performance. We further consider three query functions sum,
subtraction, multiplication over the same dependent database.
To achieve DP, an Laplace noise with parameter 1/ is added
to each of the three query results. Assuming independent
tuples, the separation for each noisy query output is the same
 as guaranteed by DP (shown in Fig. 6). In comparison,
under the probabilistic dependence between tuples, we have
the following interesting observations: 1) the separation may
become larger for the dependent tuples than that under the
independent assumption (see the sum query in Fig. 6); and
2) the change of separation caused by the same dependent
database may vary for different queries. In this section, we aim
to develop a principled perturbation mechanism for supporting
arbitrary query functions, by introducing an extra parameter
dependence coefﬁcient to measure the ﬁne-grained dependence
relationship between tuples.
A. Baseline Approach
A database D(L,R) with dependence size L would result
in a quicker exhaustion of the privacy budget  in DP by a
factor of L. This observation provides the baseline approach
for achieving the -dependent differential privacy as stated in
the theorem below:
Theorem 7. An /L-differentially private mechanism A(D) =
Q(D)+Lap(L∆Q/) over a database D with the dependence
size L achieves -dependent differential privacy, for a query
function Q with global sensitivity ∆Q.
While the above theorem follows directly from the def-
inition of DDP, the baseline approach is not optimal as it
implicitly assumes that all the dependent tuples in the database
are completely dependent on each other. By completely depen-
dent, we mean that the change in one tuple would cause a
dependent tuple to change by the maximum domain value, thus
making the sensitivity of the query over the two tuples twice
the sensitivity under the independent assumption. As we can
see from Fig. 6, the sensitivity for the sum query ∆Q, under
the independent tuple assumption, is 1 as Di ∈ [0, 1]. Under
the dependent tuples, the maximum change in Dj caused by
the change of Di is 0.5, which is only half of the maximum
domain value for Dj. Therefore, the sensitivity of the sum
query over the two dependent tuples is 1.5, which is smaller
than 2 × ∆Q = 2 as considered in the baseline approach.
This conservative assumption of completely dependent
tuples results in the addition of a lot of unnecessary noise to
the query output rendering it unusable. In real-world datasets,
although the tuples are related, only a few of them are
completely dependent on each other. This insight motivates
us to explore mechanisms that can use less amount of noise
but still satisfy all the guarantees provided by -dependent
differential privacy.
B. Our Dependent Perturbation Mechanism
To minimize the amount of added noise we want to iden-
tify the ﬁne-grained dependence relationship between tuples
and use it to design the mechanism. We begin with a simple
query function (e.g., an identity query) over a dataset with only
two tuples D = [Di, Dj]. The privacy objective is to publish
a sanitized version of the dataset i.e., (cid:101)D = [(cid:101)Di,(cid:101)Dj] as query
output. We later generalize our analysis to scenarios involving
arbitrary query functions over databases with more than two
tuples, i.e., D = [Di, Dj, Dk,··· ]. According to Deﬁnition 4,
to satisfy -dependent differentially privacy requires
(cid:16)A([Di = di1, Dj]) = [(cid:101)di,(cid:101)dj]
(cid:16)A([Di = di2, Dj]) = [(cid:101)di,(cid:101)dj]
(cid:17)
(cid:17) ≤ exp()
P
max
di1 ,di2
(11)
where the output distributions of A, due to the change in Di
from di1 to di2, would be bounded.
Motivated by the LPM in Section II-B, we continue to use
Laplace noise for perturbing the true query output to satisfy
-dependent differential privacy. Our objective thus reduces to
ﬁnding a proper scaling factor σ() for the required Laplace
distribution. According to the law of total probability4, we
further transform the left-handside (LHS) of Eq. 11 to Eq. 12.
For the ﬁrst term of the right-handside (RHS) of Eq. 12, we
have
P
P ((cid:101)Di =(cid:101)di|Di = di1)
P ((cid:101)Di =(cid:101)di|Di = di2)
max
di1 ,di2
σ()
(cid:19)
(cid:18)(cid:107)(cid:101)di−di1(cid:107)1
(cid:19)
(cid:18)
−(cid:107)(cid:101)di−di2(cid:107)1
(cid:18)(cid:107)di1 − di2(cid:107)1
(cid:19)
(cid:19)
σ()
σ()
exp
= max
di1 ,di2
exp
≤ max
di1 ,di2
exp
(cid:18) ∆Di
≤ exp
σ()
(13)
4We restrict ourselves to discrete variables for simplicity, but all the results
will also apply to the continuous case as in [1].
8
where ∆Di is the maximal difference due to the change in
Di. If we ignore the second term in the RHS of Eq. 12 and
combine the remaining terms with Eq. 11 and Eq. 13, we
obtain the scaling factor of the Laplace noise as σ() = ∆Di
,

which is exactly the same form as in traditional DP [12].
Therefore, the LPM that satisﬁes DP is only a special case
for our mechanism. The second term in the RHS of Eq. 12
incorporates the dependence relationship between Di, Dj and
we will focus our study on this term.
To evaluate the extent of dependence induced in Dj by
the modiﬁcation of Di, we deﬁne the dependence coefﬁcient
ρij as
Next, we aim to prove that 0 ≤ ρij ≤ 1. We ﬁrst have,
exp
=
dj
dj
σ()
(cid:19)
(cid:18) ρij∆Dj
(cid:80)
P (Dj = dj|Di = di1)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
(cid:80)
P (Dj = dj|Di = di2)P ((cid:101)Dj =(cid:101)dj|Dj = dj)
(cid:80)
P (Dj = dj|Di = di1 )P ((cid:101)Dj =(cid:101)dj|Dj = dj)
(cid:80)