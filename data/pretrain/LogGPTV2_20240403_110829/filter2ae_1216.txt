# 前言
在上文《[基于AST的Webshell检测》](https://xz.aliyun.com/t/5848
"基于AST的Webshell检测》")中，笔者已经提出了基于抽象语法树是可以用来检测Webshell的，那么如何将这种思想应用在jsp/jspx的webshell检测便是本文讨论的重点。  
简单回顾下抽象语法树的检测原来，由于webshell和正常文件在语法结构上会有比较明显的出入，比如说一句话木马普遍流程就是传参然后执行命令，转化为语法结构上其实是比较单一的，正常文件的语法结构会比这复杂的多得多，因此从语法结构上来分辨是否为webshell也是一种不错的选择。但是语法结构的缺点就是难以对具体参数进行分析，所以当出现“eval('1111');”和“eval(file_put_contents('shell.php','
            com.github.javaparser
            javaparser-core
            3.14.8
这里在参照了网上的大部分教程后，决定使用文件流的方式来静态编译。
    public static void main(String[] args) throws Exception {
        String filename = args[0];
        //File file = new File("src/classes/org/apache/jsp/s03_jsp.java");
        File file = new File(filename);
        FileInputStream in = new FileInputStream(file);
        CompilationUnit cu = StaticJavaParser.parse(in);
        cu.accept(new MethodVistor(),null);
    }
这里的MethodVistor类其实就是语法结构类型的检测方法，比如说函数调用可能就叫MethodCall，如果是注释就叫Comment，所以说经过这个类我们就能够生成全局的语法结构节点序列。这中间并不是取了所有的语法结构特征，并且针对部分语法结构特征做了深一步处理，如函数调用可能需要进一步获取函数名等。  
# 机器学习
得到这个序列后，需要使用相关模型来将其转化为矩阵，以便后面的训练和学习，针对这种序列流模型，我采用的是tfidf模型，主要思想就是如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。这个模型其实是由词频和逆向文件频率组成的，最后表示其实就是两个参数的乘积，这个不多说，，没什么意义。。
    CV = CountVectorizer(ngram_range=(1,3), decode_error="ignore",max_features=max_features,
                                           token_pattern = r'\b\w+\b',min_df=0,max_df=0.9)
        x=CV.fit_transform(x_all).toarray()
        transformer = TfidfTransformer(smooth_idf=False)
        x_tfidf = transformer.fit_transform(x)
        x = x_tfidf.toarray()
那么通过这个模型，我们就能将每个文件的ast语法结构序列给转化为一个统一的矩阵，并分别给黑白样本打上标记，进行有监督式的训练。这里黑样本来源于github上的开源仓库，白样本的获取其实有点难度，这里也是搜寻了大量的开源cms，不过白样本依然很少，原因比较简单，一个cms的jsp文件毕竟有限，所以这里唯一比较遗憾的就是数据量的问题。其中黑样本数量为632，白样本数量为470。  
最后选取算法，这里参照前文的检测经验，初步选定了xgboost、随机森林、mlp等三种算法，最后经过漫长的调参和比较后，裁定各个算法的最优参数。
# 实验结果
采用随机算法的检测结果  
采用xgboost算发的检测结果  
采用mlp算法的检测结果  
# 后记
回头看来，觉得整个实现思路上还是比较简单的，就是可能有几个坑点的确比较烦一点，不过感觉本文只能作为检测jsp/jspx
webshell的基本思路，复杂点的还是会被绕过，如果真的想要提高检测精度，自我感觉对参数语义的检测还是非常有必要的！  
上述如有不当之处，敬请指出~