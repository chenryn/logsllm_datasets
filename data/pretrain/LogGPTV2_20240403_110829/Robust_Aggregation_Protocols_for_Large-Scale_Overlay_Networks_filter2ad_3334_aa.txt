title:Robust Aggregation Protocols for Large-Scale Overlay Networks
author:Alberto Montresor and
M&apos;ark Jelasity and
&quot;Ozalp Babaoglu
Robust Aggregation Protocols for Large-Scale Overlay Networks∗
Alberto Montresor
Dept. of Computer Science
University of Bologna, Italy
PI:EMAIL
M´ark Jelasity
†
Ozalp Babaoglu
Dept. of Computer Science
University of Bologna, Italy
PI:EMAIL
Dept. of Computer Science
University of Bologna, Italy
PI:EMAIL
Abstract
Aggregation refers to a set of functions that provide
global information about a distributed system. These func-
tions operate on numeric values distributed over the system
and can be used to count network size, determine extremal
values and compute averages, products or sums. Aggrega-
tion allows important basic functionality to be achieved in
fully distributed and peer-to-peer networks. For example, in
a monitoring application, some aggregate reaching a spe-
ciﬁc value may trigger the execution of certain operations;
distributed storage systems may need to know the total free
space available; load-balancing protocols may beneﬁt from
knowing the target average load so as to minimize the trans-
fered load. Building on the simple but efﬁcient idea of anti-
entropy aggregation (a scheme based on the anti-entropy
epidemic communication model), in this paper we intro-
duce practically applicable robust and adaptive protocols
for proactive aggregation, including the calculation of aver-
age, product and extremal values. We show how the averag-
ing protocol can be applied to compute further aggregates
like sum, variance and the network size. We present theoret-
ical and empirical evidence supporting the robustness of the
averaging protocol under different scenarios.
1. Introduction
The latest generation of peer-to-peer (P2P) networks are
typically self-organizing, large-scale distributed systems.
Unlike many traditional distributed systems, however, nei-
ther a central authority nor a ﬁxed communication topology
are employed to control the various components. Instead,
a dynamically changing overlay network is maintained and
control is completely decentralized with “cooperation” links
among nodes being created and deleted based on the re-
quirements of the particular application. Such systems are
attractive for several reasons, including the lack of single
points of failure, the potential to scale to millions of nodes,
∗
†
This work was partially supported by the FET unit of the European
Commission through Project BISON (IST-2001-38923).
also with MTA RGAI, SZTE, Szeged, Hungary
and the fact that they allow the creation of relatively inex-
pensive distributed computing platforms.
The decentralized nature of
such systems, how-
ever, presents certain drawbacks. P2P systems tend to be
highly dynamic, with a continuous ﬂow of nodes join-
ing and leaving the network. Control and monitoring in
such systems are difﬁcult tasks: performing global compu-
tations requires orchestrating a huge number of nodes.
A useful building block for monitoring and control in
P2P systems is aggregation, which is the collective name
given to a set of functions that provide statistical informa-
tion about the system [10]. These functions include ﬁnd-
ing extremal values of some property, computing averages
and sums, etc. Aggregation can provide participants in a P2P
network with important global information such as the size
of the network or the average load in a network. Further-
more, aggregation can be used as a building block for ob-
taining more complex protocols. For example, the knowl-
edge of the average load in a network can be exploited to
implement near-optimal load-balancing schemes [6].
Aggregation protocols can be divided into two cate-
gories: reactive and proactive. Reactive protocols respond
to speciﬁc queries issued by nodes in the network. The an-
swers are returned directly to the issuer of the query [3].
Proactive protocols, on the other hand, continuously pro-
vide the value of some aggregate to all nodes in the sys-
tem in an adaptive fashion. By adaptive we mean that if the
aggregate changes due to network dynamism or because of
variations in the values being aggregated, the output of the
aggregation protocol should follow this change reasonably
quickly. Proactive protocols are often useful when aggrega-
tion is used as a building block for completely decentralized
protocols. For example, in the load-balancing scheme cited
above, the knowledge of the average load is used by each
node to decide when it can stop transferring load [6].
In this paper we introduce a robust and adaptive proto-
col for calculating aggregates in a proactive manner. The
core of the protocol is a simple scheme [5] in which ag-
gregation is performed in the style of an anti-entropy epi-
demic protocol, typically used for propagating updates in
distributed databases [2]. Periodically, each node selects a
random peer and communicates with it to bring the two
states up-to-date. In our case, instead of resolving differ-
ences between databases, the elementary step consists of
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:01 UTC from IEEE Xplore.  Restrictions apply. 
some aggregation-speciﬁc computation based on the values
maintained by the two communicating peers.
Our contribution is threefold. First, we present a full-
ﬂedged practical solution for proactive aggregation in dy-
namic environments, complete with mechanisms for adap-
tivity, robustness and topology management. Second, we
show how our approach can be extended to compute addi-
tional aggregates such as variances and products. Third, we
present both theoretical and experimental evidence on the
robustness of our protocol.
2. System Model
We consider a P2P network consisting of a large collec-
tion of nodes that are assigned unique identiﬁers and that
communicate through message exchanges. The network is
highly dynamic; new nodes may join at any time, and exist-
ing nodes may leave, either voluntarily or by crashing. Our
protocol does not need any mechanism speciﬁc to leaves so
crashes and voluntary leaves can be treated uniformly. Thus,
in the following, we limit our discussion to node crashes.
Byzantine failures, with nodes behaving arbitrarily, are ex-
cluded from the present discussion (but see [7]).
We assume that nodes are connected through an exist-
ing routed network, such as the Internet, where every node
can potentially communicate with every other node. To actu-
ally communicate, a node has to know the identiﬁers of a set
of other nodes, called its neighbors. This neighborhood re-
lation over the nodes deﬁnes the topology of the overlay net-
work. Given the large scale and the dynamicity of our envi-
sioned system, neighborhoods are typically limited to small
subsets of the entire network. Communication incurs unpre-
dictable delays and is subject to failures. Single messages
may be lost, links between pairs of nodes may break. Occa-
sional performance failures of nodes (e.g., delay in receiv-
ing or sending a message in time) can be seen as communi-
cation failures, and are treated as such. Nodes have access to
local clocks that can measure the passage of real time with
reasonable accuracy, that is, with small short-term drift.
In this paper we focus on node and link failure and mes-
sage loss. Some other aspects of the model that are outside
of the focus of our present analysis—like clock drift and
message delay—are discussed only informally in Section 4.
3. Aggregation: the Basic Idea
Each node in the network holds a numeric value. In a
practical setting, this value can characterize any (dynamic)
aspect of the node or its environment (e.g., the load at the
node, temperature monitored by a sensor network). The task
of a proactive protocol is to continously provide all nodes
with an up-to-date estimate of an aggregate function, com-
puted over the values held by the current set of nodes.
Our basic aggregation protocol is based on the epidemic-
style push-pull scheme illustrated in Figure 1. Each node
p executes two different threads. The active thread period-
ically initiates an information exchange with a peer node q
do forever
wait(δ time units)
q ← GETNEIGHBOR()
send sp to q
sq ← receive(q)
sp ← UPDATE(sp, sq)
do forever
sq ← receive(*)
send sp to sender(sq)
sp ← UPDATE(sp, sq)
(a) active thread
Figure 1. Protocol executed by node p.
(b) passive thread
selected randomly among its neighbors, by sending q a mes-
sage containing the local state sp and waiting for a response
with the remote state sq. The passive thread waits for mes-
sages sent by an initiator and replies with the local state.
The term push-pull refers to the fact that each information
exchange is performed in a symmetric manner: both peers
send and receive their states.
Even though the system is not synchronous, we ﬁnd it
convenient to describe the protocol execution in terms of
consecutive real time intervals of length δ called cycles that
are enumerated starting from some convenient point.
Method UPDATE builds a new local state based on the pre-
vious one and the remote state received during the informa-
tion exchange. The output of UPDATE depends on the spe-
ciﬁc function being implemented by the protocol. Here, we
limit the discussion to AVERAGE, which computes the global
average. Additional functions are described in Section 4.
To implement AVERAGE, each node stores a single nu-
meric value representing the current estimate of the aggre-
gation output. Each node initializes the estimate with the lo-
cal value it holds. Method UPDATE(sp, sq), where sp and sq
are the estimates exchanged by p and q, returns (sp + sq)/2.
After one exchange, the sum of the two local estimates re-
mains unchanged since method UPDATE simply distributes
the initial sum equally among the two peers. So, the oper-
ation does not change the global average either; it only de-
creases the variance over all the estimates.
It is easy to see that the value at each node will converge
to the true global average, as long as the underlying over-
lay network remains connected. In our previous work [5],
we presented analytical results for the convergence speed of
the averaging protocol. Let µi be the empirical mean and σ2
i
be the empirical variance of the local estimates at cycle i:
µi =
N(cid:1)
k=1
1
N
ai,k,
σ2
i =
1
N − 1
N(cid:1)
k=1
(ai,k − µi)2
(1)
where ai,k is the estimate maintained at node k = 1, . . . N
during cycle i and N is the number of nodes.
The convergence factor ρi, with i ≥ 1, characterizes the
speed of convergence for the aggregation protocol and is
i )/E(σ2
deﬁned as ρi = E(σ2
i−1). If the (connected) over-
√
lay network topology is sufﬁciently random, it is possible to
show that for i ≥ 1, ρi ≈ 1/(2
e). In other words, each cy-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:52:01 UTC from IEEE Xplore.  Restrictions apply. 
100000
10000
1000
100
10
1
0.1
0.01
0.001
e
g
a
r
e
v
A
d
e
t
a
m
i
t
s
E
0.0001
0
5
10
1.025
1.02
1.015
1.01
1.005
1
0.995
0.99
22
24
26
28
30
Experiments
Maximum
Minimum
15
Cycles
20
25
30
Figure 2. Behavior of protocol AVERAGE.
√
cle of the protocol reduces the expected variance of the lo-
cal estimates by a factor 2
e. From this result, it is clear
that the protocol converges exponentially and very high pre-
cision estimates of the true average can be achieved in only
a few cycles, irrespective of the network size, conﬁrming the
extreme scalability of our protocol.
Figure 2 illustrates the behavior of the protocol. The AV-
ERAGE protocol was run on a simulated network composed
of 105 nodes connected through a regular random overlay
network, where each node knows exactly 20 neighbors. Ini-
tially, a single node has the value 105, while all others have
zero as their local value (so that the global average is 1). We
are interested in this peak distribution for two reasons: ﬁrst,
it will be the basis of our COUNT protocol presented in Sec-
tion 4; and second, it is the most demanding scenario for
testing robustness, since the single node holding the initial
peak value constitutes a single point of failure.
In the Figure, results for the ﬁrst 30 cycles of the proto-
col are shown. The two curves represent the minimum and
the maximum estimates of the average over all the nodes at
the completion of each cycle. The curves correspond to av-
erages over 50 independent experiments, whose results are
shown as individual points in the ﬁgure.
4. Aggregation: A Practical Protocol
4.1. Automatic Restarting
The generic protocol described so far is not adaptive, as
the aggregation takes into account neither the dynamicity of
the network nor the variability of values. To provide up-to-
date estimates, the protocol must be periodically restarted:
at each node, the protocol is terminated and the current esti-
mate is returned as aggregation output; then, the current val-
ues are used to re-initialize the estimates and aggregation
starts again with these fresh initial values.
To implement termination, we adopt a very simple mech-
anism: each node executes the protocol for a predeﬁned
number of cycles, denoted as γ, depending on the required
accuracy of the output and the convergence factor that can
be achieved in the particular overlay topology adopted.
To implement restarting, we divide the protocol execu-
tion in consecutive epochs of length ∆ and start a new in-
stance of the protocol in each epoch. Depending on the ra-
tio between ∆ and γδ, it is possible that different epochs of
the protocol may be executing concurrently in the network.
Thus, messages exchanged for a particular epoch have to be
tagged with unique epoch identiﬁers.
4.2. Dynamic Membership
When a new node joins the network, it contacts a node
that is already participating in the protocol. Here, we as-
sume the existence of an out-of-band mechanism to discover
such a node, and the problem of initializing the neighbor set
of the new node is discussed in Section 4.4.
The existing node provides the new node with the next
epoch identiﬁer and the time until the start of the next epoch.
Joining nodes are not allowed to participate in the current
epoch; this is necessary to make sure that each epoch con-
verges to the average that existed at the start of the epoch.
As for crashes, when a node initiates a exchange, it sets
a timeout period to detect the failure of the contacted node.
If the timeout expires before the message is received, the
exchange step is skipped. The effect of these missing ex-
changes due to real (or presumed) failures on the ﬁnal aver-
age will be discussed in Section 7.
4.3. Synchronization