datasets, totaling 86,163 apps:
High-proﬁle app dataset: We crawled the top free high-
proﬁle apps in May 2020 from the Google Play store based on
the AppBrain statistic [5]. For each country and 33 categories,
AppBrain lists the top 500 apps. However, for some cate-
gories, AppBrain does not provide a full list of 500 apps (e.g.,
Events with only 271 apps). Therefore, as a result, our crawler
obtained 16,163 high-proﬁle apps from 33 app categories.
Long-tail app dataset: Between May and September
2020, we crawled all free Android apps available in the store
from Germany and successfully obtained more than 1 million
apps. Rather than running the analysis of the entire dataset,
we decided to ﬁlter the list of apps through two steps to reach
a more manageable dataset: we ﬁrst rely on Exodus-Privacy
[22] to identify apps that have integrated tracking or adver-
tising libraries. As a result, we obtained more than 700,000
apps with embedded tracking or advertising libraries (304 of
which are detected by Exodus-Privacy) in their code. Of these
apps, we randomly sampled approx. 10% of apps with at least
10,000 downloads and excluded those in the high-proﬁle set
already, yielding 70,000 distinct apps for testing.
We note that this pre-selection strategy of ﬁltering out apps
which Exodus-Privacy did not ﬂag as containing advertising
or tracking libraries results in a sampling bias compared to
the high-proﬁle apps. To account for that, when comparing
the statistics later, we only compare our data against those
high-proﬁle apps that Exodus-Privacy also ﬂagged.
4.2 Network Trafﬁc Analysis
As mentioned in Section 3.3, our approach suffers from cer-
tain limitations which keep us from analyzing all apps in the
dataset. We were able to successfully analyze 72,274 (83.9%)
apps, i.e., 14,975 high-proﬁle apps and 57,299 long-tail apps.
The remaining 13,889 either crashed or detected the analysis
environment, making all of them potential false negatives.
Out of the 72,274 successfully analyzed apps, we iden-
tiﬁed 41,900 apps that contacted the Internet in either of
the launches in R1. Speciﬁcally, we identiﬁed 10,290 unique
fully-qualiﬁed domain names being contacted. However, we
found that a single registerable domain uses many subdomains
(e.g., rt.applovin.com, d.applovin.com). To normalize
these hosts to their registerable domain (applovin.com in
the above cases), we rely on the public sufﬁx list [51]. We
refer to these resolved domains as domain names in the fol-
lowing. As a result, we identiﬁed 7,384 domain names that
were contacted by 41,900 apps.
Among the 7,384 domain names, we found 1,744 (23,6%)
domain names that received one or more of the types of PD
listed in Table 1. Each time any of the relevant data is sent
by an app to a domain, we count this as a case of PD being
sent out. Speciﬁcally, we identiﬁed 28,665 apps (see the ﬁrst
column of Table 3) that sent PD to these 1,744 domain names.
We now rely on the assumption that a third party would serve
multiple apps and hence ﬂag those domains as third-party
domains that are contacted by at least ten different apps. This
leads us to detect 337 distinct third-party domains. We found
that 28,065 (97.9% of 28,665; second column in Table 3)
apps sent PD to 209 third-party domains. Notably, third-party
domains, representing only 12.0% of domains which received
PD, are responsible for a disproportionate fraction (94,7%)
of cases of receiving PD without prior consent.
This result suggests that only a negligible number of ﬁrst
parties collect PD. In contrast, the majority of PD was sent to
third parties, which developers heavily rely on for a variety of
purposes such as monetization (e.g., personalized ads), error
logging, analytic services, user engagement, or social network
integration. We note that GDPR mandates explicit consent in
case such a third party acts as a data controller (rather than
a data processor, that does not itself beneﬁt from processing
the data). Hence, in the following, we speciﬁcally focus on
domains for which we can unequivocally determine that they
control data for their own purposes, namely advertisement.
USENIX Association
30th USENIX Security Symposium    3673
Any Domains
(N=28,665)
Third-Party Domains
(N=28,065)
Advertisement Domains
(N=24,838)
High-Proﬁle Apps
5,177 (34.6 %)
86 (0.6 %)
48 (0.3 %)
459 (3.1 %)
4 (0.0 %)
107 (0.7 %)
22 (0.1 %)
68 (0.5 %)
1 (0.0 %)
49 (0.3 %)
9 (0.1 %)
73 (0.5 %)
Long-Tail Apps High-Proﬁle Apps
5,072 (33.9 %)
22,152 (38.7 %)
71 (0.5 %)
107 (0.2 %)
113 (0.2 %)
42 (0.3 %)
363 (2.4 %)
1,151 (2.0 %)
3 (0.0 %)
3 (0.0 %)
51 (0.3 %)
611 (1.1 %)
26 (0.0 %)
8 (0.1 %)
30 (0.2 %)
126 (0.2 %)
4 (0.0 %)
1 (0.0 %)
17 (0.1 %)
158 (0.3 %)
29 (0.1 %)
5 (0.0 %)
67 (0.4 %)
108 (0.2 %)
Long-Tail Apps High-Proﬁle Apps
4,366 (29.2 %)
21,957 (38.3 %)
16 (0.1 %)
88 (0.2 %)
108 (0.2 %)
—
136 (0.9 %)
946 (1.7 %)
1 (0.0 %)
—
36 (0.2 %)
444 (0.8 %)
6 (0.0 %)
—
27 (0.2 %)
41 (0.1 %)
—
—
3 (0.0 %)
91 (0.2 %)
19 (0.0 %)
—
17 (0.1 %)
78 (0.1 %)
Long-Tail Apps
19,904 (34.7 %)
12 (0.0 %)
—
244 (0.4 %)
—
356 (0.6 %)
—
17 (0.0 %)
—
3 (0.0 %)
—
15 (0.0 %)
1,044 (7.0 %)
4,471 (7.8 %)
938 (6.3 %)
4,236 (7.4 %)
679 (4.5 %)
3,533 (6.2 %)
5,455 (36.4%)
23,210 (40.5%)
5,276 (35.2%)
22,789 (39.8%)
4,415 (29.5%)
20,423 (35.6%)
AAID
BSSID
EMAIL
GPS
GSF
IMEI
IMSI
MAC
PHONE
SERIAL
SIM_SERIAL
SSID
UID
Any
Table 3: Types of data and number of apps sending this to any, third-party, and ad domains (percentages relative to dataset sizes).
4.3
Identifying Advertisement Domains
Under the GDPR, all personal data processing has to have a
legal justiﬁcation. The ﬁrst party acting as a data controller
may rely on several potential legal justiﬁcations for their data
processing: fulﬁllment of a contract, legitimate interest, or
consent. This legal justiﬁcation extends to any third party
acting as a data processor for the app developer. Since the
third party acts completely under the app developer’s control
they are viewed as in the same legal domain as the ﬁrst party.
Meanwhile, a third party acting as a data controller would
need its own legal justiﬁcation to receive and process the
user’s PD. As such, they cannot rely on the original controller
(app developer) to be the only responsible party to obtain a
valid legal basis for their processing operations, or to ensure
compliance with other obligations under the GDPR, particu-
larly regarding the exercise of data subjects’ rights. [29].
As the most prominent business case of third parties receiv-
ing and processing user data for their own business purposes,
we chose (targeted) advertising to have a conservative lower
bound for the cases of GDPR violations in the wild. An app
which relies on external data controllers for targeted adver-
tising needs to explicitly ask for the user’s consent to share
her PD with the third party. We found that third-party do-
mains received 94,7% of all PD being sent out to the Internet.
In order to analyze whether this data transfer would most
likely require the user’s prior consent, we ﬁrst need to identify
whether a third party is an advertising company, and second
need to differentiate between those third parties that act as
data processors and those that act as data controllers.
To determine whether a party is a potential advertisement
company, we ﬁrst rely on Webshrinker’s categorization to
identify the main topic of a domain [68] for all 209 third-
party domains that received PD in our analysis. For all do-
mains not ﬂagged as ad-related, we manually review the Web
pages of the domains to assess if the domain is related to a
company offering in-app advertising services. For example,
while Facebook is categorized by Webshrinker as a social net-
work, they are also an advertising company, which relies on
graph.facebook.com for advertising and tracking [52]. In
this fashion, we identiﬁed 69 domains which are operated by
ad-related companies. However, not all these domains actually
act as data controllers under the GDPR. To distinguish be-
tween data controllers and processors, we analyzed the legal
documents provided by the third parties.
Particularly, we manually analyzed the terms of service,
privacy policies, developer guidelines and contracts, if avail-
able. The GDPR requires companies processing personal data
to transparently provide their processing purposes and justi-
ﬁcation. We relied on the third party’s legal self-assessment
whether they describe themselves and their data use as a data
controller or data processor. If they described their data use
as mainly for their own company’s gain, e.g., assembling and
selling user proﬁles across several different apps, we would
classify them as data controllers. If they limit their described
data use as purely on behalf of and instructed by the app de-
veloper and if they would provide the additional necessary
data processor agreement documents, we classify them as data
processors. If a company’s legal statements were too vague
or they offered services as both data controller and processor,
we classiﬁed them as data processors in order to conserva-
tive estimate the number of potential GDPR violations and to
not unjustly notify app developers that commissioned these
companies as data processors.
Out of 69 third-party domains which are operated by ad-
related companies, we identiﬁed 45 domains of data con-
trollers (full list in Appendix, Table 5), which would require
explicit consent to receive data. In the next section, based on
these 45 ad-related domains, we present our analysis on the
GDPR compliance of apps regarding consent requirements.
3674    30th USENIX Security Symposium
USENIX Association
In-Depth Analysis of Violations
4.4
We now focus on the set of apps which contacted any of the
aforementioned 45 domains which we determined to be ad-
related data controllers. Based on these domains, we ﬁnd that
the vast majority of apps that contact third parties with PD in
fact send this to ad-related domains (24,838/28,065 or 88.5%,
as shown in the third column of Table 3). Moreover, 86.6%
(24,838/28,665) of apps which sent out any data do so towards
advertisement domains. Relative to the number of apps we
could successfully analyze, this means that 34.4% of them
sent out PD to third-party data controllers, thereby violating
GDPR’s mandated consent to such collection. We note that
this is in light of a mere 45/1,774 (2.5%) contacted domains
being ﬂagged as advertisement domains, which shows the
signiﬁcant skew towards apps sending out PD to advertise-
ment companies without user’s explicit prior consent. No-
tably, there is a signiﬁcant skew towards the AAID as being
the most frequently transferred piece of PD. However, accord-
ing to both the advertising industry [35] and Google’s own
brand [33], the AAID is considered PD and regularly requires
consent before being collected by third-party data controllers.
Identifying Major Players We now turn to analyze which
are the most frequent parties that receive PD. Figure 3 shows
the top 10 ad-related domains that received PD in our dataset,
counting the number of apps that sent data towards them. We
ﬁnd that more than half of the apps which sent data without
consent sent data to (at least) Facebook. It is noteworthy that
Facebook makes GDPR compliance particularly tough for
developers to implement. According to their own documenta-
tion [23], their SDK defaults to assuming user consent. That
is, a developer must actively disable the automated transmis-
sion of PD and implement their own consent dialogue. In the
case of Facebook, they operate in multiple capacities (e.g.,
social media integration and advertisement), yet their terms
allow data sharing between the different services in their pri-
vacy policies. Speciﬁcally, the Facebook Graph API can share
its data with Facebook Ads [4], which in turn can again be
used to optimize advertisement.
The current version of the SDK of the second most-
prevalent recipient of data, namely Unity, supports two vari-
ants of consent [63]: either, the developer provides consent
through an API call (naturally after having acquired explicit
consent) or the app developer can rely on Unity’s solution
which asks the user when the ﬁrst ad is shown. However, as
per their legal documentation, this is an opt-out mechanism
rather than opt-in [64]. We believe this to be the major driving
force behind the large number of requests towards Unity, as
their ads ﬁrst transmit data and then ask users to opt-out.
As for the third-largest recipient, we note that Flurry also
supports a consent API, but the documentation is unclear
about the default behavior and lacks important details about
the proper implementation [26]. More notably, Flurry dele-
Figure 3: Top 10 ad domains that frequently received PD from
24,838 apps that sent PD to all ad-related domains.
gates the responsibility to acquire consent to the app developer.
Moreover, they explicitly state that they assume any data is
only sent after the developer has received consent. Overall,
this implies that library providers make it very cumbersome
for developers to be compliant with GDPR.
Combining Multiple Identiﬁers As our data indicates, the
vast majority of apps send out the AAID. While this in itself is
already problematic with respect to the GDPR, apps sending
out any other information alongside the AAID also violate
the Google policy for AAID usage. In particular, according
to said policy [3, 50], the AAID must only be used for ad-
vertising and user analytics. For both purposes, the AAID
may not be connected to persistent device identiﬁers (e.g.,
SSID, IMEI). The AAID may only be connected to other
personally-identiﬁable information with the user’s explicit
consent. In our dataset, we found that a total of 3,840 apps
combined the AAID with some other type of personal infor-
mation. Hence, all these apps not only infringe on the explicit
consent required by GDPR, but also violate Google’s policy,
which means they could be removed from the app store.
For each app, we investigated to which ad-related domain
they sent out the combination of the AAID and other PD.
The results of this analysis are shown in Table 4. Note that,
on purpose, we do not include the UID here, as we cannot
identify whether a particular unique ID is just the AAID (e.g.,
hashed with an unknown algorithm). The results indicate that
there are numerous domains that receive the combination of
AAID and some other identiﬁers. Speciﬁcally, for cases such
as the 190 apps that sent out the AAID with the IMEI to Flurry,
Google can remove the apps without prior notice from the app
store. To further understand this violation of Google’s policy
(combined with the fact that only relatively few apps conduct
this practice), we analyzed the versions of SDKs used in apps
which sent out the data to these top 5 ad-related domains. To
that end, we rely on a two-step approach. First, based on the
collected trafﬁc, we identify SDK version numbers from the
requests, such as GET or POST parameters (see Appendix B
for details). For apps which lack such version information in
the HTTP trafﬁc, we instead rely on a more involved analysis
USENIX Association
30th USENIX Security Symposium    3675
02,0004,0006,0008,00010,00012,00014,00016,000Number of appsfacebook.comunity3d.comflurry.comsupersonicads.comchartboost.comappsflyer.comadcolony.comstartappservice.comvungle.combranch.ioDomain names12,451 (50.13%)8,845 (35.61%)2,866 (11.54%)1,802 (7.26%)1,721 (6.93%)1,664 (6.7%)1,066 (4.29%)1,048 (4.22%)881 (3.55%)870 (3.5%)Data Types
IMEI
GPS
SERIAL
SSID
MAC
No. Apps
190
156
4
2
1
BSSID;GPS;MAC;SSID
MAC
GPS;MAC
BSSID;GPS;IMEI;MAC;SSID
22
17
2
1