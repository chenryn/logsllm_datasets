# Flume 1.9用户手册中文版
## 译者注
-   本文档在线查阅：
    [https://flume.liyifeng.org](https://flume.liyifeng.org?flag=fromDoc)
    ，离线下载：[https://flume.liyifeng.org/down](https://flume.liyifeng.org/down?flag=docDown)
    ，英文原版文档： [Flume 1.9 User
    Guide](http://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html)
-   Flume 1.9新版更新内容请看 [Flume v1.9.0
    发行日志](http://flume.apache.org/releases/1.9.0.html)
-   查阅文档前请先阅读 [翻译版格式约定](translateAgreement.html)
## 简介
### 概览
Apache Flume
是一个分布式、高可靠、高可用的用来收集、聚合、转移不同来源的大量日志数据到中央数据仓库的工具
Apache Flume是Apache软件基金会（ASF）的顶级项目
::: hint
::: title
Hint
:::
一句话总结：我，Flume，牛B
:::
### 系统要求
1.  Java运行环境 - Java 1.8或更高版本
2.  内存 - 足够的内存 用来配置Souuces、Channels和Sinks
3.  硬盘空间 - 足够的硬盘用来配置Channels 和 Sinks
4.  目录权限 - Agent用来读写目录的权限
::: hint
::: title
Hint
:::
唯一有用的就是第一行，其余都是废话。我找出了最近几个Flume版本对JRE的依赖，如下表：
:::
+----------------------------------+-------------------------------------+
| Flume版本                        | 依赖的JRE版本                       |
+==================================+=====================================+
| Flume 1.9.0                      | Java1.8 或更高版本                  |
+----------------------------------+-------------------------------------+
| Flume 1.8.0                      | Java1.8 或更高版本                  |
+----------------------------------+-------------------------------------+
| Flume 1.7.0                      | Java1.7 或更高版本                  |
+----------------------------------+-------------------------------------+
| Flume 1.4.0、1.5.0、1.5.2、1.6.0 | > Java1.6 或更高版本（建议使用1.7） |
+----------------------------------+-------------------------------------+
### 体系结构
#### 数据流模型
Event是Flume定义的一个数据流传输的最小单元。Agent就是一个Flume的实例，本质是一个JVM进程，该JVM进程控制Event数据流从外部日志生产者那里传输到目的地（或者是下一个Agent）。
::: hint
::: title
Hint
:::
学习Flume必须明白这几个概念，Event英文直译是事件，但是在Flume里表示数据传输的一个最小单位（被Flume收集的一条条日志又或者一个个的二进制文件，不管你在外面叫什么，进入Flume之后它就叫event）。参照下图可以看得出Agent就是Flume的一个部署实例，
一个完整的Agent中包含了必须的三个组件Source、Channel和Sink，Source是指数据的来源和方式，Channel是一个数据的缓冲池，Sink定义了数据输出的方式和目的地（这三个组件是必须有的，另外还有很多可选的组件interceptor、channel
selector、sink processor等后面会介绍）。
:::
![](images/UserGuide_image00.png){.align-center}
Source消耗由外部（如Web服务器）传递给它的Event。外部以Flume
Source识别的格式向Flume发送Event。例如，[Avro Source](#avro-source)
可接收从Avro客户端（或其他FlumeSink）接收Avro Event。用 [Thrift
Source](#thrift-source)
也可以实现类似的流程，接收的Event数据可以是任何语言编写的只要符合Thrift协议即可。
当Source接收Event时，它将其存储到一个或多个channel。该channel是一个被动存储器（或者说叫存储池），可以存储Event直到它被Sink消耗。‘文件channel’就是一个例子 -
它由本地文件系统支持。sink从channel中移除Event并将其放入外部存储库（如HDFS，通过
Flume的 [HDFS Sink](#hdfs-sink) 实现）或将其转发到流中下一个Flume
Agent（下一跳）的Flume Source。
Agent中的source和sink与channel存取Event是异步的。
Flume的Source负责消费外部传递给它的数据（比如web服务器的日志）。外部的数据生产方以Flume
Source识别的格式向Flume发送Event。
::: hint
::: title
Hint
:::
\"Source消耗由外部传递给它的Event\"，这句话听起来好像Flume只能被动接收Event，实际上Flume也有Source是主动收集Event的，比如：[Spooling
Directory Source](#spooling-directory-source) 、[Taildir
Source](#taildir-source) 。
:::
#### 复杂流
Flume可以设置多级Agent连接的方式传输Event数据。也支持扇入和扇出的部署方式，类似于负载均衡方式或多点同时备份的方式。
::: hint
::: title
Hint
:::
这里必须解释一下，第一句的意思是可以部署多个Agent组成一个数据流的传输链。第二句要知道扇入（多对一）和扇出（一对多）的概念，就是说Agent可以将数据流发到多个下级Agent，也可以从多个Agent发到一个Agent中。
其实他们就是想告诉你，你可以根据自己的业务需求来任意组合传输日志的Agent流，引用一张后面章节的图，这就是一个扇入方式的Flume部署方式，前三个Agent的数据都汇总到一个Agent4上，最后由Agent4统一存储到HDFS。
:::
![](images/UserGuide_image02.png){.align-center}
::: hint
::: title
Hint
:::
官方这个图的Agent4的Sink画错了，不应该是 [Avro Sink](#avro-sink)
，应该是 [HDFS Sink](#hdfs-sink) 。
:::
#### 可靠性
Event会在每个Agent的Channel上进行缓存，随后Event将会传递到流中的下一个Agent或目的地（比如HDFS）。只有成功地发送到下一个Agent或目的地后Event才会从Channel中删除。这一步保证了Event数据流在Flume
Agent中传输时端到端的可靠性。
::: hint
::: title
Hint
:::
同学们这里是知识点啊（敲黑板）！Flume的这个channel最重要的功能是用来保证数据的可靠传输的。其实另外一个重要的功能也不可忽视，就是实现了数据流入和流出的异步执行。
:::
Flume使用事务来保证Event的
**可靠传输**。Source和Sink对Channel提供的每个Event数据分别封装一个事务用于存储和恢复，这样就保证了数据流的集合在点对点之间的可靠传输。在多层架构的情况下，来自前一层的sink和来自下一层的Source
都会有事务在运行以确保数据安全地传输到下一层的Channel中。
#### 可恢复性
Event数据会缓存在Channel中用来在失败的时候恢复出来。Flume支持保存在本地文件系统中的‘文件channel’，也支持保存在内存中的‘内存Channel’，‘内存Channel’显然速度会更快，缺点是万一Agent挂掉‘内存Channel’中缓存的数据也就丢失了。
## 安装
### 开始安装第一个Agent
Flume Agent的配置是在一个本地的配置文件中。这是一个遵循Java
properties文件格式的文本文件。一个或多个Agent配置可放在同一个配置文件里。配置文件包含Agent的source，sink和channel的各个属性以及他们的数据流连接。
#### 第一步：配置各个组件
每个组件（source，sink或者channel）都有一个name，type和一系列的基于其type或实例的属性。例如，一个avro
source需要有个hostname（或者ip地址）一个端口号来接收数据。一个内存channel有最大队列长度的属性（capacity），
一个HDFS
sink需要知晓文件系统的URI地址创建文件，文件访问频率（`hdfs.rollInterval`）等等。所有的这些组件属性都需要在Flume配置文件中设置。
#### 第二步：连接各个组件
Agent需要知道加载什么组件，以及这些组件在流中的连接顺序。通过列出在Agent中的source，sink和channel名称，定义每个sink和source的channel来完成。
::: hint
::: title
Hint
:::
本来上面这段原文中描述了一个例子，可是并不直观，不如直接看下面hello
world里面的配置例子。
:::
#### 第三步：启动Agent
bin目录下的flume-ng是Flume的启动脚本，启动时需要指定Agent的名字、配置文件的目录和配置文件的名称。
比如这样:
    $ bin/flume-ng agent -n $agent_name -c conf -f conf/flume-conf.properties.template
到此，Agent就会运行flume-conf.properties.template里面配置的source和sink了。
#### 一个简单的Hello World
这里给出了一个配置文件的例子，部署一个单节点的Flume，这个配置是让你自己生成Event数据然后Flume会把它们输出到控制台上。
::: hint
::: title
Hint
:::
下面的配置文件中，source使用的是 [NetCat TCP
Source](#netcat-tcp-source)，这个Source在后面会有专门的一节来介绍，简单说就是监听本机上某个端口上接收到的TCP协议的消息，收到的每行内容都会解析封装成一个Event，然后发送到channel，
sink使用的是 [Logger
Sink](#logger-sink)，这个sink可以把Event输出到控制台，channel使用的是
[Memory Channel](#memory-channel) ，是一个用内存作为Event缓冲的channel。
Flume内置了多种多样的source、sink和channel，后面 [配置](#配置)
章节会逐一介绍。
:::
``` properties
# example.conf: 一个单节点的 Flume 实例配置
# 配置Agent a1各个组件的名称
a1.sources = r1    #Agent a1 的source有一个，叫做r1
a1.sinks = k1      #Agent a1 的sink也有一个，叫做k1
a1.channels = c1   #Agent a1 的channel有一个，叫做c1
# 配置Agent a1的source r1的属性
a1.sources.r1.type = netcat       #使用的是NetCat TCP Source，这里配的是别名，Flume内置的一些组件都是有别名的，没有别名填全限定类名
a1.sources.r1.bind = localhost    #NetCat TCP Source监听的hostname，这个是本机
a1.sources.r1.port = 44444        #监听的端口
# 配置Agent a1的sink k1的属性
a1.sinks.k1.type = logger         # sink使用的是Logger Sink，这个配的也是别名
# 配置Agent a1的channel c1的属性，channel是用来缓冲Event数据的
a1.channels.c1.type = memory                #channel的类型是内存channel，顾名思义这个channel是使用内存来缓冲数据
a1.channels.c1.capacity = 1000              #内存channel的容量大小是1000，注意这个容量不是越大越好，配置越大一旦Flume挂掉丢失的event也就越多
a1.channels.c1.transactionCapacity = 100    #source和sink从内存channel每次事务传输的event数量
# 把source和sink绑定到channel上
a1.sources.r1.channels = c1       #与source r1绑定的channel有一个，叫做c1
a1.sinks.k1.channel = c1          #与sink k1绑定的channel有一个，叫做c1
```
配置文件里面的注释已经写的很明白了，这个配置文件定义了一个Agent叫做a1，a1有一个source监听本机44444端口上接收到的数据、一个缓冲数据的channel还有一个把Event数据输出到控制台的sink。这个配置文件给各个组件命名，并且设置了它们的类型和其他属性。通常一个配置文件里面可能有多个Agent，当启动Flume时候通常会传一个Agent名字来做为程序运行的标记。
::: hint
::: title
Hint
:::
同一个配置文件中如果配置了多个agent流，启动Flume的命令中 `--name`
这个参数的作用就体现出来了，用它来告诉Flume将要启动该配置文件中的哪一个agent实例。
:::
用下面的命令加载这个配置文件启动Flume：
``` none
$ bin/flume-ng agent --conf conf --conf-file example.conf --name a1 -Dflume.root.logger=INFO,console
```
请注意，在完整的部署中通常会包含
\--conf=\这个参数，\目录里面包含了flume-env.sh和一个log4j
properties文件，在这个例子里面，我们强制Flume把日志输出到了控制台，运行的时候没有任何自定义的环境脚本。
测试一下我们的这个例子吧，打开一个新的终端窗口，用telnet命令连接本机的44444端口，然后输入Hello
world！后按回车，这时收到服务器的响应\[OK\]（这是 [NetCat TCP
Source](#netcat-tcp-source) 默认给返回的），说明一行数据已经成功发送。
``` none
$ telnet localhost 44444