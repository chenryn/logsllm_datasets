root server to the Palo Alto f-root server9 would be counted as
one ﬂap. Using our measurement data, we determined the av-
erage time between ﬂaps to a given root server for each prob-
ing node. Figure 5 plots various percentiles for the average
time between ﬂaps when probing various anycasted servers.
The ﬁgure shows that the anycasted services are very stable
as viewed from almost all locations. For example, more than
95% of the nodes observed less than a ﬂap per day for all the
anycasted destinations. Similarly, ∼48% of the nodes never
observed a ﬂap when probing the f-root during the entire 30
day period.
Also, the few nodes that observed frequent ﬂaps (i.e. an
average inter-ﬂap duration of less than a day) had their av-
erage skewed by tiny bursts of instability in between large
periods of stability. For example, the Planetlab node that
experienced most ﬂaps (208) over the month when probing
j-root was in Leixip, Ireland. Of these, 180 ﬂaps occurred in
a 3-hour period. We conjecture that such phenomena can be
attributed to ephemeral issues speciﬁc to the sites to which
these nodes belong. While a more rigorous analysis of the col-
lected data and correlation with BGP-updates for the preﬁxes
representing these anycasted destinations would be needed
for determining the causes and patterns amongst these ﬂaps,
the overall ﬁgures do paint an encouraging picture. These
measurements reveal that the probability that a two minute
connection breaks due to a ﬂap is about 1 in 4500 and the
probability that an hour long connection breaks is about 1 in
150. Note that it is the short connections that, in order to
avoid the overhead of anycast to unicast redirect, need to rely
on anycast aﬃnity. Long connections can incur the overhead
of a redirect and hence, could use anycast for discovery and
unicast for the actual communication.
We admit that the limited number(129) and variety of van-
tage points and the number of locations of the anycast des-
9San Jose and Palo Alto are two locations of the f-root server
Figure 7: Average system wide messages (per sec-
ond) versus the percentage of inaccuracy with vary-
ing number of proxies and varying maximum group
size.
tinations makes our study preliminary. Also, the operators
of j-root, based on their observations, have come to the op-
posite conclusion regarding the ability of native IP anycast
to support stateful connections[26]. While their results are
being debated by many in the operational community[27], we
are trying to acquire the relevant data-sets so as to ﬁnd the
reason for the ﬂapping observed by them (something that the
authors of the j-root study have not analyzed).
4.2 Scalability by group size and dynamics
In this experiment, we evaluate PIAS’s ability to handle
large and dynamic groups (as described in 3.3). We simulate
the load imposed by a large group with high churn on the
proxy infrastructure. The dynamics of the simulated group
- the arrival rate of group members and the session duration
cumulative distribution function - resemble the dynamics of
the largest event observed in a study of large-scale streaming
applications[28]. Simulation of just one such group is suﬃ-
cient as the load imposed varies linearly with the number of
such groups supported.
The PIAS infrastructure in the simulation has varying num-
ber of proxies and maximum group size. We simulate four
RAPs per group. We want to measure the number of mes-
sages required to keep the 2-tier membership hierarchy up-
dated in face of the group dynamics. This is the number of
messages from the JAPs of the group to the 4 RAPs and is
referred to as ’system wide messages’.
Figure 6 plots the system wide messages produced with a
proxy deployment of size 1000 and the group size bounded by
90000. The topmost curve in the ﬁgure shows how the group
size varies with the time. A ﬂash crowd, at a rate of ∼100
members/second, leads to a sudden rise in the group size in
the ﬁrst 10 minutes. The other curves plot the number of
messages produced in the corresponding minute (as plotted
along the X-axis) for varying degrees of inaccuracy. The de-
gree of inaccuracy, as explained in section 3.3, implies that a
JAP only informs a RAP of a change in the number of mem-
bers associated with it if the change is more than a certain
percentage of the last value sent.
The inaccuracy of information oﬀers only a small beneﬁt in
the nascent stages of the group (the ﬁrst minute). This is be-
cause no matter what inaccuracy percentage we use, the JAP
must inform the RAP of the ﬁrst group member that contacts
it. In the next couple of minutes, as the group increases in
size and more members join their corresponding JAPs, the
inaccuracy causes the traﬃc towards the 4 RAPs to drop
rapidly (see the embedded graph in ﬁgure 6). Overall, the
average number of messages over the duration of the entire
event reduces from 2300 per min. with the naive approach to
117 per min. with 50% inaccuracy.
Figure 7 plots the average system wide messages (per sec-
ond) versus the percentage of inaccuracy for varying number
of proxies and varying maximum group size. Each plotted
point is obtained by averaging across 20 runs. All curves
tend to knee around an inaccuracy mark of 50%−60%. The
closeness of the curves for diﬀerent sized groups (given a ﬁxed
number of proxies) points to the scalability of the system by
the group size even in the face of high churn.
More interesting is the variation of the load on the RAPs
with the number of proxies. As the number of proxies in-
crease, the number of JAPs increase; an oﬀshoot of the as-
sumption that the group members are evenly distributed across
the proxy infrastructure. For a given group size, each JAP
is associated with lesser number of group members. Hence,
there is lesser beneﬁt due to the inaccuracy approach. This
shows up as the increase in the average number of messages
directed towards the RAPs with the number of proxies.
The ﬁgure shows that such an extreme group in a 100 proxy
deployment with 100% inaccuracy would require an average
of ∼0.18 messages/second. As a contrast the same setup in
a 10000 proxy deployment would necessitate an average of
∼7.25 messages/second. The low message overhead substan-
tiates the PIAS scalability claim. Note that a larger number
of proxies implies that each proxy is a RAP for a smaller num-
ber of groups. The number of targets associated with each
proxy (as a JAP) reduces too. Thus, increasing the num-
ber of proxies would indeed reduce the overall load on the
individual proxies.
4.3 Stretch
PIAS causes packets to follow a longer path (client ⇒ IAP
⇒ JAP ⇒ target). We have argued that the combination of
native IP anycast and proxy-to-proxy latency measurements
minimizes the eﬀect of this longer path. This section sim-
ulates the stretch introduced by PIAS along the end-to-end
path.
For the simulation, we use a subset of the actual tier-1
topology of the Internet, as mapped out in the Rocketfuel
project [16]. This subset consists of 22 ISPs, 687 POPs, and
2825 inter-POP links (details in [29]). The use of only the
tier-1 topology can be justiﬁed on two grounds. First, a large
proportion of traﬃc between a randomly chosen client-target
pair on the Internet would pass through a tier-1 ISP. Second,
such a simulation gives us an approximate idea about the
overhead that a PIAS deployment restricted to tier-1 ISPs
would entail.
The topology was annotated with the actual distance be-
tween POPs (in Kms) based on their geographical locations.
We then used SSFNET[30] to simulate BGP route conver-
gence. This allowed us to construct forwarding tables at each
of the POPs and hence, determine the forwarding path be-
tween any two POPs.
The simulated PIAS deployment involves placing a variable
number of proxies at random POPs, one proxy per POP.
These POPs are referred to as the proxy POPs. For every
client-target pair to be simulated, we choose a POP through
client
which the client’s packets enter the topology (the
t
t
h
h
g
g
n
n
e
e
l
l
h
h
t
t
a
a
p
p
t
t
c
c
e
e
r
r
i
i
D
D
o
o
t
t
N
N
R
R
N
N
I
I
f
f
o
o
o
o
i
i
t
t
a
a
R
R
 3.5
 3.5
 3
 3
 2.5
 2.5
 2
 2
 1.5
 1.5
 1
 1
 0.5
 0.5
 0
 0
 0
 0
10 - 25 - 50 - 75 - 90 percentile
10 - 25 - 50 - 75 - 90 percentile
 100
 100
 200
 200
 300
 300
 400
 400
 500
 500
 600
 600
 700
 700
# of Proxies
# of Proxies
Figure 8: Percentiles for the stretch with varying
number of proxies
POP ) and a POP through which the target’s packets enter
the topology (the target POP ). The forwarding paths between
the client and the target through these POPs represents the
direct path. The IAP is assumed to be in the proxy POP
closest to the client POP—this is the IAP POP. Similarly,
the JAP is in the proxy POP closest to the target POP—this
is the JAP POP. The PIAS path comprises of the following
three segments: from the client POP to the IAP POP, from
the IAP POP to the JAP POP and from the JAP POP to
the target POP.
Figure 8 plots the percentiles for the stretch with varying
number of proxies. For a given number of proxies, we simu-
lated 100000 runs. Each run comprised of simulating a client-
target pair and ﬁnding the direct and the PIAS path length
(in kms). Note that the well-documented non-optimal nature
of inter-domain routing[14] is reﬂected in the cases where the
PIAS path turns out to be shorter than the direct path. The
ﬁgure shows that with a deployment of just 100 proxies (a
mature deployment might encompass 50 times more POPs),
the median stretch is 1.01 with the 90th percentile being 2.2.
Hence, even with a small size deployment, PIAS performs
well with regards to the direct path.
4.4 Implementation
We have implemented the PIAS system and are in the pro-
cess of deploying it. The current implementation of PIAS
proxies comprises of a user-space component responsible for
the overlay management tasks, such as handling proxy fail-
ures, target join/leaves, health monitoring etc. and a kernel-
space component responsible for the actual forwarding of
packets through the use of Netﬁlter hooks[31]. This involves
tunnelling of the packets when sending them between 2 proxy
nodes, and using a NAT when handling packets to/from a
target.
5. RELATED WORK
Partridge et. al.
Table 2 summarizes the pros and cons of PIAS, application
level anycast, and other related approaches described below.
[1] originally proposed the IPv4 anycast
service. It involves assigning an otherwise unicast IP address
IPA to multiple hosts, and advertising it into the routing in-
frastructure from all the hosts. Packets addressed to IPA
will be forwarded to the host nearest to the packet source in
terms of metrics used by the routing protocol. Later, IPv6
incorporated anycast into its addressing architecture[8].
It
allowed for scoped anycast addresses for groups conﬁned to a
topological region, which does not burden the global routing
system. However, a globally spread group still poses scalabil-
ity problems. Besides, IPv6 anycast also inherits all the other
Criterion (related to goal number)
Router Modiﬁcation(1)
Client Modiﬁcation(1)
Scalability by group size(2)
Stretch(3)
Robustness(4)
Failover(5)
Target Deployment(6)
Scalability by no. of groups(7)
Scalability by group dynamics(8)
Cost of Proximity(9)
Low-level access
IPv4
No
No
IPv6
No
No
IP + GIA
App. Level
No
No
Poor
No
Mixed
Fast
Easy
Yes
Poor
Large
No
i3
No
Yes
Poor/Good
Little
Mixed
Fast
Easy
Yes
Poor/Good
Large
Yes
10
10
PIAS
No
No
11
Good
Little
Mixed
Fast
Easy
Yes
Good
Small
Yes
Yes
No
12
Fast
Very Good Very Good Very Good
Little/No
No Issue
No Issues
No Issues
No
No
12
Fast
12
Fast
Diﬃcult
Diﬃcult
Diﬃcult
No
Poor
None
Yes
No
Poor
None
Yes
Yes
Poor
Small
Yes
Table 2: The Anycast Design Space
limitations of IPv4 anycast. Despite the shortcomings, there
has been work detailing the relevance of anycast as a tool for