title:Differential Slicing: Identifying Causal Execution Differences for
Security Applications
author:Noah M. Johnson and
Juan Caballero and
Kevin Zhijie Chen and
Stephen McCamant and
Pongsin Poosankam and
Daniel Reynaud and
Dawn Song
2011 IEEE Symposium on Security and Privacy
Differential Slicing: Identifying Causal Execution Differences for
Security Applications
Noah M. Johnson†, Juan Caballero‡, Kevin Zhijie Chen†, Stephen McCamant†,
Pongsin Poosankam§†, Daniel Reynaud†, and Dawn Song†
†University of California, Berkeley
‡IMDEA Software Institute
§Carnegie Mellon University
Abstract—A security analyst often needs to understand
two runs of the same program that exhibit a difference in
program state or output. This is important, for example, for
vulnerability analysis, as well as for analyzing a malware
program that features different behaviors when run in different
environments. In this paper we propose a differential slicing
approach that automates the analysis of such execution dif-
ferences. Differential slicing outputs a causal difference graph
that captures the input differences that triggered the observed
difference and the causal path of differences that led from those
input differences to the observed difference. The analyst uses
the graph to quickly understand the observed difference. We
implement differential slicing and evaluate it on the analysis
of 11 real-world vulnerabilities and 2 malware samples with
environment-dependent behaviors. We also evaluate it in an
informal user study with two vulnerability analysts. Our results
show that differential slicing successfully identiﬁes the input
differences that caused the observed difference and that the
causal difference graph signiﬁcantly reduces the amount of time
and effort required for an analyst to understand the observed
difference.
I. INTRODUCTION
Often, a security analyst needs to understand two runs of
the same program that contain an execution difference of
interest. For example, the security analyst may have a trace
of an execution that led to a program crash and another trace
of an execution of the same program with a similar input
that did not produce a crash. Here, the analyst wants to
understand the crash and why one program input triggered
it but the other one did not, and use this knowledge to
determine whether the bug causing the crash is exploitable,
how to exploit it, and how to patch it.
For another example, a security analyst may use manual
testing or previously proposed techniques to ﬁnd trigger-
based behaviors in malware [4], [7], [8], [16]. The analyst
may obtain an execution trace of a piece of malware (e.g.,
a spam bot) in environment A, which does not exhibit
malicious behavior (e.g., does not spam), and another trace
of an execution of the same piece of malware in environment
B, which does exhibit malicious behavior (e.g., does spam).
However, knowing how to trigger the hidden behavior is not
enough for many security applications. It is often important
to know exactly why and how the trigger occurred, for ex-
ample, in order to write a rule that bypasses the trigger [13].
Suppose there are many differences between environments
A and B. The analyst needs to understand which subset of
environment differences are truly relevant to the trigger, as
well as locate the checks that the malware performs on those
environment differences.
The two scenarios are similar in that one execution trace
contains some unexpected behavior (e.g., the crash for the
benign program and the non-malicious behavior for the
malware) and the other trace contains some expected behav-
ior. In both scenarios the analyst would like to understand
why that execution difference, which we term the target
difference, exists. This is a pre-requisite for the analyst to
act, i.e., to write a patch or exploit for the vulnerability and
to write a rule to bypass the trigger. In addition, the analyst
needs to perform this analysis directly on binary programs
because source code is often not available.
To automate this analysis we propose a novel differential
slicing approach. Given traces of two program runs and the
target difference, our approach provides succinct information
to the analyst about 1) the parts of the program input or
environment that caused the target difference, and 2) the
sequence of events that led to the target difference.
Automating these two tasks is important for the analyst
because manually comparing and sieving through traces
of two executions of the same program to answer these
questions is a challenging, time-consuming task. This is
because, in addition to the target difference, there are often
many other execution differences due to loops that iterate
a different number of times in each run, and differences in
program input that are not relevant to the target difference
(e.g., to the crash) but still introduce differences between the
executions.
We implement our differential slicing approach and evalu-
ate it for two different applications. First, we use it to analyze
11 real-world vulnerabilities. Our results show that
the
output graph often reduces the number of instructions that an
analyst needs to examine for understanding the vulnerability
from hundreds of thousands to a few dozen. We conﬁrm this
in a user study with two vulnerability analysts, which shows
that our graphs signiﬁcantly reduce the amount of time
and effort required for understanding two vulnerabilities in
Adobe Reader. Second, we evaluate differential slicing on 2
malware samples that check environment conditions before
deciding whether to perform malicious actions. Our results
1081-6011/11 $26.00 © 2011 IEEE
DOI 10.1109/SP.2011.41
347
show that differential slicing identiﬁes the speciﬁc parts of
the environment that the malware uses and that the output
graphs succinctly capture the checks the malware performs
on them.
This paper makes the following contributions:
• We propose differential slicing, a novel
technique
which, given traces of two executions of the same
program containing a target difference, automatically
ﬁnds the input and environment differences that caused
the target difference, and outputs a causal difference
graph that succinctly captures the sequence of events
leading to the target difference.
• We propose an address normalization technique that
enables identifying equivalent memory addresses across
program executions. Such normalization enables prun-
ing equivalent addresses from the causal difference
graph and is important for scalability.
• We design an efﬁcient ofﬂine trace alignment algorithm
based on Execution Indexing [29] that aligns the execu-
tion traces for two runs of the same program in a single
pass over both traces. It outputs the alignment regions
that represent the similarities and differences between
both executions.
• We implement differential slicing in a tool that works
directly on binary programs. We evaluate it on 11
different vulnerabilities and 2 malware samples. Our
evaluation includes an informal user study with 2
vulnerability analysts and demonstrates that the output
of our tool can signiﬁcantly reduce the amount of time
and effort required for understanding a vulnerability.
II. PROBLEM DEFINITION AND OVERVIEW
In this section, we describe the problem setting, give the
problem deﬁnition, and present an overview of our approach.
A. Problem Setting
We consider the following problem setting. We are given
execution traces of two runs of the same program that
contain some target execution difference to be analyzed. The
two execution traces may be generated from two different
program inputs or from the same program running in two
different system environments.
For example, in crash analysis, a security analyst may
have two execution traces obtained by running a program
with two similar inputs where one input causes a crash and
the other one does not. Here, the analyst’s goal is ﬁrst to
understand the crash (informally, what caused it and how it
came to happen), so that she can patch or exploit it.
In a different application, a security analyst is given exe-
cution traces of a malware program running in two system
environments, where the malware behaves differently in both
environments, e.g., launches a denial-of-service attack in one
environment but not in the other. Here, the analyst has access
to two environments that trigger the different behaviors, but
still needs to understand which parts of the environment
(e.g., the system date) as well as which checks (e.g., it was
Feb. 24th, 2004) caused the different behavior, so that she
can write a rule that bypasses the trigger.
We can unify both cases by considering the system
environment as a program input. The analyst’s goal
is
then to understand the target difference, which comprises:
1) identifying the input differences that caused the target
difference, and 2) understanding the sequence of events that
led from the input differences to the target difference.
To refer to both execution traces easily, we term the trace
that contains the unexpected behavior (e.g., the crash of a
benign program or the absence of malicious behavior) from
a malware program, the failing trace and the other one the
passing trace. The corresponding inputs (or environments)
are the passing input and the failing input.
Note that how to obtain the different
inputs and en-
vironments that cause the target difference is application
dependent and out of scope of this paper. In many security
applications such as the two scenarios described above, ana-
lysts routinely obtain such different inputs and environments.
Motivating example. A motivating crash analysis example
for demonstrating our approach is shown in Figure 1. For
ease of understanding we present the example as C code
even though our approach works at the binary level. This
simple program ﬁrst copies its two arguments and then
compares them. It contains a bug because the length of the
input strings is checked before allocation, but not before
copying, which causes the program to crash if it copies
a value into an unallocated buffer. In this example, the
failing trace is obtained by running vuln_cmp "" foo,
which produces a crash, while the passing trace is obtained
by running vuln_cmp bar bazaar, which successfully
prints that the strings are not equal and exits. Figure 2 shows
the execution traces for both runs. The target difference is
the crashing statement in the failing trace.
In this example the analyst would like to understand that
the ﬁrst argument of the program caused the crash while the
second argument was not involved. She would also like to
understand the causal path that led from the difference in
the ﬁrst argument to the crash and, in particular, that the
crash happens because the allocation at statement #8 was
not executed in the failing run. A commonly used technique
for establishing a causal path in one execution is dynamic
slicing [14]. However, dynamic slicing on the failing trace
does not help to identify the cause of this crash since the
cause is a statement that should have executed, but did not,
and thus is not present in the failing trace.
B. Problem Deﬁnition
Our problem is how to build the causal difference graph,
which captures the sequences of execution differences that
led from the input differences to the target difference.
Intuitively, execution differences are values that differ across
348
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
c h a r ∗ s 1 =NULL, ∗ s 2 =NULL ;
i n t main ( i n t a r g c , c h a r ∗∗ a r g v ) {
i f ( a r g c < 3 )
r e t u r n 1 ;
i n t
i n t
i f
l e n 1 = s t r l e n ( a r g v [ 1 ] ) ;
l e n 2 = s t r l e n ( a r g v [ 2 ] ) ;
( l e n 1 )
s 1 = ( c h a r ∗ ) m a l l o c ( l e n 1 ) ;
i f
( l e n 2 )
s 2 = ( c h a r ∗ ) m a l l o c ( l e n 2 ) ;
s t r n c p y ( s1 ,
s t r n c p y ( s2 ,
i f
a r g v [ 1 ] ,
a r g v [ 2 ] ,
l e n 1 ) ;
l e n 2 ) ;
( s t r c m p ( s1 , s 2 )
p r i n t f ( ” S t r i n g s
! = 0 )
a r e n o t e q u a l \n ” ) ;
r e t u r n 0 ;
}
Figure 1: Motivating example program, vuln cmp.c.
runs, or statements that executed in only one run. However,
determining that a value differs, or that a statement appears
only in one trace, requires ﬁrst establishing correspondence
between statements in both traces. This is difﬁcult because
the same statement may appear multiple times in an ex-
ecution due to loops, recursive functions, or invocations
of the same function in different contexts. The process of
establishing such correspondence is called trace alignment
and is a pre-requisite for identifying execution differences.
Trace alignment. Given passing (p) and failing (f ) traces
of size n and m instructions, respectively, we say that a
pair of statements from these traces (px, fy) s.t. x ∈ [1, n],
y ∈ [1, m] are aligned if they correspond to each other. We
say that a statement in one trace is disaligned if it has no
corresponding statement in the other trace, which we rep-
resent with a pair (px,⊥) or (⊥,fy). Trace alignment marks
each statement in both traces as either aligned or disaligned.
Since execution traces can contain many statements, we
group them together into regions based on their alignment.
An aligned region is a maximal sequence of consecutive
aligned statements: (px, fy), (px+1, fy+1), . . . , (px+k, fy+k)
s.t. ∀i ∈ [0, k] px+i, fy+i 6=⊥. Similarly, a disaligned region
is a maximal sequence of consecutive disaligned statements:
(px, ⊥), . . . , (px+k, ⊥) or (⊥, fx), . . . , (⊥, fx+k).
A disaligned region is always immediately preceded by
an aligned region. We term the last statement in an aligned
region a divergence point because it creates a disaligned
region by transferring control to different statements in both
traces. Given a disaligned region, we call the divergence
point of the immediately preceding aligned region,
the
immediate divergence point.
Figure 2 shows the alignment for our motivating exam-
ple and illustrates these deﬁnitions. The ﬁgure shows that
the two executions are aligned until branch statement #7
executes. Here, statements #3–#7 in each trace form an
aligned region. Branch statement #7 is a divergence point;
it evaluates to true in the passing run and to false in the
349
Passing run
Failing run
/* argc = 3 */
3: if(argc<3) 
/* argv[1] = "bar" */
5: int len1 = strlen(argv[1]) 
/* argv[2] = "bazaar" */
6: int len2 = strlen(argv[2]) 
/* len1 = 3 */
7: if (len1)  
/* argc = 3 */
3: if(argc<3)
/* argv[1] = "" */
5: int len1 = strlen(argv[1])
/* argv[2] = "foo" */
6: int len2 = strlen(argv[2])
/* len1 = 0 */
7: if (len1)
/* len1 = 3 */
8: s1 = (char *)malloc(len1)
/* len2 = 6 */
9: if (len2)
/* len2 = 6 */ 
10: s2 = (char *)malloc(len2)
/* s1 = (ptr to 3-byte buﬀer),
    argv[1] = "bar", 
    len1 = 3 */
11: strncpy(s1, argv[1], len1)
/* len2 = 3 */
9: if (len2)
/* len2 = 3 */
10: s2 = (char *)malloc(len2)
/* s1 = NULL,
    argv[1] = "",
    len1 = 0 */
11: strncpy(s1, argv[1], len1)
/* s1 = (ptr to 6-byte buﬀer),
    argv[2] = "bazaar",
    len2 = 6 */
12: strncpy(s2, argv[2], len2)
...
15: return 0
crash
_
V
V
V
F
V
V
V
F
F
Figure 2: Traces and alignment for motivating example.
V and F refer to value and ﬂow differences, respectively
(Section II-B).
failing run, creating a disaligned region because statement
#8 executes in the passing run but not in the failing run (an
execution omission). The two executions realign at statement
#9 and remain aligned until statement #11 produces the crash
in the failing trace. Thus, statements #9–#11 form another
aligned region.
Execution differences. Given two aligned executions, we
deﬁne two types of execution differences: ﬂow differences
and value differences. A ﬂow difference is simply a dis-
aligned statement. For example, statement #8 in Figure 2 is
a ﬂow difference.
A value difference is a variable used in an aligned
statement that has a different value in both executions. For
example, the len2 variable in statement #10 in Figure 2
is a value difference because it has value 6 in the passing
run and value 3 in the failing run. We say that a statement
has a value difference when it uses one or more variables
that are value differences. For example, statement #11 in
Figure 2 has 3 value differences: s1, argv[1], and s1.
Each statement in Figure 2 is marked on the left with a V to
indicate that it contains a value difference, an F to indicate
that it is a ﬂow difference, or - otherwise.
Causal difference graph. The causal difference graph con-
tains the sequences of execution differences leading from
the input differences to the target difference. The causal
difference graph is rooted at the input (or environment)
differences because those are the root cause of all execution
differences. The graph captures the sequence of events that
Figure 3: Source code level causal difference graph for the motivating example.
cause the target difference but it is more succinct than a full
causal path because it only contains ﬂow differences and
statements that have value differences. The intuition here is
that any execution difference (including the target difference)
can only be caused by previous execution differences, never
by statements that have no value differences or are not
ﬂow differences. The causal difference graph is also more
succinct than the full list of execution differences between
both runs, since not all execution differences may be relevant
to the target difference. For example, in Figure 1, statement
#6 contains a value difference because the value of len2
differs in both runs. However, statement #6 is not relevant
to the crash and is therefore not included in the causal
difference graph.
Figure 3 presents the graph for our motivating example.
Starting from the bottom, it begins with the target difference,
which is statement #11 because it crashes in the failing run,
continues with the ﬂow difference at #8, the len1 value
difference at #7, the argv[1] value difference at #5, and
ends at argv[1], the sole input difference that is relevant
to the crash.
C. Approach Overview
To compute the causal difference graph, we propose a