datasets is a constraint for the use of statistical methods In this context, we developed a new tool to detect analytical correlation into datasets 
The algorithm principle is to group features from the same analyte and to propose one single representative per group The user can define 
grouping criteria with various options including correlation coefficient, retention time, mass defect information The representative feature can be 
determined following four methods according to the analytical technology The present tool was compared to one of the most commonly used 
free package proposing a grouping method: ‘CAMERA’, using its Galaxy version ‘CAMERAannotate’ available in Workflow4Metabolomics (W4M; 
http://workflow4metabolomicsorg) To illustrate its functionalities, a published dataset available on W4M (Thevenot et al, 2015) was used as an 
example Within the 3,120 ions of the dataset, the tool allowed creating 2,651 groups, meaning that 15% of ions are proposed to be filtered because 
of analytical redundancies The proposed tool subdivided more than 20 groups of more than 10 ions into smaller ones corresponding to individual 
annotated metabolites, thus demonstrating the efficiency and relevance of the present approach As a key element in metabolomics data analysis, 
the tool will be available via the web-based galaxy platform W4M with different output files for network vizualisation and for further data analysis 
within workflows
P-502
Comets-Analytics: a centralized computational framework for consortia level meta-analyses
PRESENTING AUTHOR: Ewy Mathe, Ohio State University, United States
CO-AUTHORS: Moore, Krista Zanetti, Kai-Ling Chen, Dave Ruggieri, Ella Temprosa
Metabolomics is increasingly applied in large-scale epidemiological studies to uncover metabolites associated with physiological states (eg age, 
disease) The National Cancer Institute-led “Consortium of Metabolomics Studies” (COMETS) includes > 45 international prospective cohorts 
with serum metabolomics profiles and detailed phenotypic data To support meta-analysis of these studies at a consortia level, we created a 
centralized computational infrastructure, Comets-Analytics Comets-Analytics was built with the following guiding principles in mind: 1) minimal 
burden on analyst time, 2) reproducibility, 3) data privacy, 4) adherence with FAIR guidelines, 5) usability The software supports harmonization of 
metabolite names across different platforms used in COMETS and implements partial correlation modeling Notably, Comets-Analytics includes 
“smart analytics”, which internally performs extensive data and model checks to ensure that models are valid, and that the model building process 
is reproducible Meaningful warnings (eg adjustment variable is dropped because it only has one unique value) and errors (eg adjustment and 
stratification variables are the same) are returned to precisely inform users about how to fix their input data and about what models are run Further, 
the web application includes interactive tables and plots to empower users to promptly and globally assess results With Comets-Analytics, cohorts 
analyze their own data using a common data format and standardized results are sent centrally for meta-analysis This streamlined approach greatly 
facilitates large consortia studies and helps ensure integrity, and reproducibility of results Comets-Analytics, including detailed documentation, is 
available as an R package at https://githubcom/CBIIT/R-cometsAnalytics, and can be run directly from our servers at http://comets-analyticsorg/
Page 235
POSTER SESSIONS 1 AND 2 – Monday and Tuesday – all odd number posters will be on display.POSTER SESSIONS 3 AND 4 – Wednesday and Thursday – all even number posters will be on display.TECHNOLOGY15th Annual Conference of the Metabolomics Society*AWARD WINNERSTECHNOLOGY
P-503
Composite Score: A Multivariate Correlation for Comparison of Metabolomics-Based Studies of Complex Mixtures
PRESENTING AUTHOR: Joshua Kellogg, University of North Carolina at Greensboro, United States
CO-AUTHORS: Olav M. Kvalheim, Nadja B. Cech
Untargeted metabolomics analyses, where an entire measurable metabolome is analyzed without defined biomarker compounds to guide analysis, 
is useful when the study has no a priori chemical or mechanistic hypotheses However, successful untargeted metabolomics studies rely on effective 
statistical analysis of the metabolomic dataset to guide interpretation and inform conclusions A primary statistical tool, principal component analysis 
(PCA), results in the selection of maximum three components from a larger model to visually represent similarity within the entire dataset This limits 
the comprehensiveness of the model and can yield poor discrimination between samples Other metrics of similarity also have limitations when 
considering untargeted metabolomics studies Here we have developed a new statistical metric, the composite score (CS), as a univariate statistic 
that incorporates multiple principal components to enable quantitative comparisons among metabolomics datasets By integrating the scores and 
loadings components of the significant components from the original PCA model, the CS provides an advantageous measure of similarity, enabling 
more quantitative comparisons than are possible with visual inspection of a PCA scores plot or hierarchical cluster analysis (HCA) Several case 
studies focusing on complex natural product mixtures – green tea (Camellia sinensis) and goldenseal (Hydrastis canadensis) dietary supplements – 
highlight the utility of composite scores to evaluate similarity and identify outliers within a sample set
P-504
Integrating 4D peak picking of LC-TIMS-MS/MS data into GNPS feature based molecular networking for metabolomics and 
lipidomics analysis
PRESENTING AUTHOR: Florian Zubeil, Bruker Daltonik GmbH, Germany
CO-AUTHORS: Nikolas Kessler, Heiko Neuweger, Sven Meyer, Ulrike Schweiger-Hufnagel, Aiko Barsch
As throughput of metabolomic and lipidomic analyses continuously expands, effective workflows for analyzing the resulting datasets are of 
increasing importance Molecular networking in recent years has become a vital tool in the metabolomics community as it quickly allows the 
identification of compounds with similar fragmentation patterns which are often structurally related This also allows propagation of annotations 
from known compounds to related derivatives While this approach mainly focusses on the fragment spectra, important information can be 
deduced from the precursor spectra, ie intensity, accurate mass and isotopic pattern of the analytes Herein, we present a workflow to integrate 
analyte information for untargeted profiling from the software MetaboScape into GNPS feature based molecular networking The nodes in the 
resulting molecular network are enriched by useful information about the precursor ions like the intensity in individual samples, molecular formula, 
annotation, CCS values, group mean and maximum intensity The latter information are important indicators to assess distribution of a specific 
analyte between sample groups (by group mean) Likewise, interpretation of the resulting molecular network is greatly simplified by displaying 
generated molecular formulas instead of precursor masses as node labels Additionally, this workflow enables the integration of 4D peak picking 
results from PASEF-MS/MS data into GNPS molecular networking which is demonstrated on a lipid sample This enables a straight forward 
processing of TIMS-MS data including the benefit of cleaner MS/MS spectra of co-eluting analytes for molecular networking which are generated by 
ion mobility separation
P-505
Hierarchical Bayesian models for Stable Isotope Resolved Metabolomics: a unified framework for testing hypotheses about 
total abundance and isotopologue distribution
PRESENTING AUTHOR: Patrick J. Trainor, University of Louisville, United States
CO-AUTHORS: Pawel K. Lorkiewicz, Joshua K. Salabei, Bradford G. Hill
The analysis of data from Stable Isotope Resolved Metabolomics (SIRM) experiments presents a unique statistical challenge First, experimental 
manipulations (eg gene knockout or treatment with an enzymatic inhibitor) may change between phenotypes: the concentration or pool of 
a metabolite present, the fractional distribution of the metabolite pool within isotopologues, or both Second, multiplicity concerns arise from 
conducting univariate statistical tests at the isotopologue level between phenotypes We propose a hierarchical Bayesian model for testing 
hypotheses in SIRM experiments that is well-suited for addressing these challenges This model assumes Gaussian prior distributions for the total 
abundance of a metabolite, Dirichlet prior distributions for the fractional distribution of abundances within isotopologues, and Gaussian priors to 
account for within-phenotype variability as well as measurement error Gibbs sampling, a Markov chain Monte Carlo technique, is utilized to simulate 
the joint posterior distribution of model parameters given observed experimental data From the joint posterior distribution hypotheses regarding 
both total metabolite abundance and isotopologue distribution can be tested We demonstrate an application of the methodology to a 15N2, 
13C5-glutamine labeling experiment conducted in order to evaluate the effect of aminoooxyacetic acid (an inhibitor of aminotransferases including 
aspartate aminotransferase) treatment (AOA) in murine cardiac mesenchymal cells isolated on the basis of c-kit positivity Metabolites extracted 
from AOA+ and AOA- treated cells were detected by FTICR-MS and relative abundances were quantified We report differences in isotopologue 
distributions between AOA+ and AOA- cells in malate and glutamate; and differences in total abundances of malate, aspartate, and glutamate
Page 236
POSTER SESSIONS 1 AND 2 – Monday and Tuesday – all odd number posters will be on display.POSTER SESSIONS 3 AND 4 – Wednesday and Thursday – all even number posters will be on display.TECHNOLOGY15th Annual Conference of the Metabolomics Society*AWARD WINNERSTECHNOLOGY
P-506
Metabolomic profiling identifies a systemic suppression of steroid metabolism among prevalent asthma cases; are inhaled 
steroids the cause?
PRESENTING AUTHOR: Priyadarshini Kachroo, Brigham & Women’s Hospital, United States
CO-AUTHORS: Priyadarshini Kachroo, Rachel S. Kelly, Mengna Huang, Isobel Stewart, Claudia Langenberg, Scott T. Weiss, Jessica A. Lasky-Su
Asthma is a complex disease, often effectively treated with the use of inhaled corticosteroids (ICSs) We aimed to identify metabolomic signatures 
of asthma and evaluate the impact that ICSs may have on the overall plasma metabolomic profile The current study included 10,754 participants 
from the population-based EPIC-Norfolk cohort with data available for prevalent physician-diagnosed asthma Metabolomic profiling of plasma was 
conducted using ultrahigh-performance liquid chromatography and tandem mass spectrometry We assessed individual metabolite associations 
with asthma using multivariable logistic regression models and evaluated the impact of ICS use on those findings We replicated these findings 
using data from 613 individuals in the Partners Biobank (PB) After quality control, we identified 858 known metabolites, of which 27 (31%) were 
associated with prevalent asthma after Bonferroni multiple-comparison correction (P<58e-5) The top two associations: dehydroisoandrosterone 
sulfate (DHEA-S) and cortisone were decreased in asthmatics (OR=065,P=14e-27; OR=072,P=78e-20 respectively) 15/27 metabolites replicated in 
Partners Biobank (P<005), including strong associations between the top two EPIC findings and asthma: DHEA-S and cortisone (OR=036,P=27e-4; 
OR=030,P=30e-5 respectively) Notably, all 15 metabolites were in the corticosteroid, pregnenolone, and androgenic steroid pathways and were 
markedly reduced in asthmatics (ORs=065-081) Further investigation demonstrated that these metabolites had consistent negative associations 
with ICS use These findings suggest that significant suppression of multiple steroid pathways in asthmatics could be modulated by ICSs, which 
merits from further investigation The consistent negative relationship between ICS use and steroid metabolites further suggests that ICSs may have 
stronger systemic effects on circulating plasma steroid levels than is currently recognized
P-507
Hierarchical preprocessing for LC/MS metabolomics data generated in multiple batches
PRESENTING AUTHOR: Tianwei Yu, Emory University, United States
CO-AUTHORS: Qin Liu, Douglas Walker, Karan Uppal, Shuzhao Li, ViLinh Tran, Dean P. Jones
With the growth of metabolomics research, more and more studies are conducted on large numbers of samples Due to technical limitations of the 
Liquid Chromatography – Mass Spectrometry (LC/MS) platform, the samples need to be processed in multiple batches Across different batches, 
we often observe differences in data characteristics In this work, we specifically focus on data generated in multiple batches on the same LC/MS 
machinery Traditional preprocessing methods treat all samples as a single group, which makes it necessary to use larger m/z and retention time 
tolerance levels in order to allow for between-batch differences Such an approach is sub-optimal, as it can result in errors in the alignment of peaks, 
which cannot be corrected by batch effect correction methods applied after preprocessing To address this issue, we developed a new approach 
that process the data in a hierarchical manner – first within batch and then between batch Different parameter settings can be adaptively found 
for within-batch and between-batch quantification and alignments The method is implemented in the existing workflow of the apLCMS platform 
Analyzing data with multiple batches, both generated from standardized plasma samples and from real biological studies, the new method resulted 
in feature matrices with higher consistency The method can be useful for large studies involving multiple batches
P-508
Integrated workflow with quality control for large cohort and clinical metabolomics research using robust hardware and  
signal correction
PRESENTING AUTHOR: Nikolas Kessler, Bruker, Germany
CO-AUTHORS: Sebastian Goetz, Ulrike Schweiger-Hufnagel, Matthias Szesny, Aiko Barsch, Sven W. Meyer, Matthew R. Lewis, Nikolas Kessler
Metabolomics research relies on precision measurement of statistically powered sets of hundreds or thousands of samples First, this requires 
robust analytical hardware with long term stability, capable of generating high precision data Second, processing of large datasets may require 
additional mathematical correction to compensate for systematic changes in observed signals as samples interact with the analytical system 
affecting its performance We investigated the long-term stability of an LC-HR-QTOF system by measuring a batch of more than 1000 urine samples 
and monitoring the effect of data acquisition on MS ion source contamination and detector aging To address the remaining within-batch intensity 
drifts we present new software: First, a fully automated software workflow allows for the automated correction of intensity drifts, improving data 
precision and statistical reliability Second, an interactive and intuitive visualization provides rapid feature-wise review of intensity drifts (and their 
corrections) as well as detection of statistical outliers Run-order signal drift correction effectively reduced the relative standard deviation (RSD) 
of feature intensities within sample groups measured across replicate quality control sample measurements This also increased the number of 
analytes which meet the requirements of an RSD below 20%, a typical cut-off Visually this improvement was also observed in PCA, with more 
closely clustering of sample groups In summary, we present a workflow for population and clinical metabolomics research enabled by robust LC-
HRMS hardware and software allowing filtering and correction for signal drift effects
Page 237
POSTER SESSIONS 1 AND 2 – Monday and Tuesday – all odd number posters will be on display.POSTER SESSIONS 3 AND 4 – Wednesday and Thursday – all even number posters will be on display.TECHNOLOGY15th Annual Conference of the Metabolomics Society*AWARD WINNERSTECHNOLOGY
P-509
Detect and Quantify Sources of Variability in Metabolite Measurement in a Japanese population
PRESENTING AUTHOR: Ayano Takeuchi, Keio University, Japan
CO-AUTHORS: Sei Harada, Taichi Shimazu, Taiki Yamaji, Norie Sawada, Junko Ishihara, Ribeka Takachi, Kazutoshi Nakamura, Junta Tanaka, 
Manami Inoue, Motoki Iwasaki, Hiroyasu Iso, Masahiro Sugimoto, Akiyoshi Hirayama, Tomoyoshi Soga, Masaru Tomita, Shoichiro Tsugane, 
Toru Takebayashi
Our study purpose is to quantify sources of variability in urine and plasma metabolite concentrations measured using capillary electrophoresis-mass 
spectrometry and detect sources of variability in metabolite measurements We measured metabolite concentrations of using the samples from 
Japan Public Health Center-Based Prospective Study for the Next Generation (JPHC-NEXT) validation study in Japan (J Epidemiol 2016;26:420-
32) We used twenty-four-hour urine collections and plasma specimens of 253 men and women aged 40–74 years from five areas in the study, 
collected at 2 time points, baseline (2012) and same period of next year (2013)  We randomly selected 43 samples from study subjects and dispense 
specimens into 3 We measured some 3 dispensing specimens sequentially to detect the sum of the squared deviations of ‘pure measurement 
error’ We layout and measured some 3 dispensing specimens in different position of the same batch to detect ‘within batch variation of 
measurement’ We layout and measured remained 3 dispensing specimens in same positon of different batch to detect ‘between batch variation of 
measurement’ We will show the proportion of these 3 types of variation (pure measurement error, within batch variation, between batch variations) 
and variation between times (2012 to 2013) for all metabolite (123 metabolites for urine, 102 metabolites for plasma) we measured on our poster
P-510
Virtual Metabolomics Mass Spectrometer (ViMMS): A Mass Spectrometry Simulator for Comparing Different Fragmentation 
Strategies in Metabolomics
PRESENTING AUTHOR: Joe Wandy, Glasgow Polyomics, United Kingdom
CO-AUTHORS: Vinny Davies, Justin J.J. van der Hooft, Ronan Daly, Simon Rogers
Liquid-Chromatography (LC) coupled to Tandem mass spectrometry (MS/MS) is widely used in identifying small molecules in untargeted 
metabolomics However, the development of new MS/MS acquisition strategies is hampered by the lack of simulators that let researchers prototype 
and compare different fragmentation strategies before validations on real machines Although some simulators exist, they are typically focused on 
proteomics and do not include simulation of MS2 acquisition within a chromatographic run We introduce Virtual Metabolomics Mass Spectrometer 
(ViMMS), a modular metabolomics LC-MS/MS simulator framework that allows for real-time scan-level control of the MS2 acquisition process in-
silico ViMMS can generate new data based on kernel density estimates trained on empirical data, or generate data that resembles real data from a 
list of user-defined chemical formulas Alternatively, pre-existing data can be re-run in-silico with different fragmentation strategies Samples can be 
exported as mzML files, and different fragmentation controllers compared ViMMS is also extendable with additional spectra generation processes 
and noise models We will show results from experiments that compare different fragmentation strategies First ViMMS will be used to take the 
output of a real LC/MS analysis and examine the effect of varying N in Top-N Data Dependent Acquisition protocol We will also demonstrate how 
ViMMS can be used to compare published acquisition strategies, eg Data-set-Dependent Acquisition (DsDA) and Nested Data-Independent 
Acquisition (DIA) We expect that ViMMS will save development time by allowing for offline evaluation of novel fragmentation strategies and 
optimisation of fragmentation strategy for a particular sample
P-511
Open source software platform for mass spectrometry based non-target screening in the environment
PRESENTING AUTHOR: Rick Helmus, Institute for Biodiversity and Ecosystem Dynamics, Netherlands
CO-AUTHORS: Vittorio Albergamo, Olaf Brock, John Parsons, Pim de Voogt
Chemical analysis has been widely applied over the past decades to characterize both natural and anthropogenic compounds within our 
environment A ‘non-target’ approach becomes increasingly adopted where hundreds to thousands of unknown chemicals are screened 
simultaneously At this scale, tools are crucial to automatize extraction, prioritization and identification of chemicals of potential interest The various 
software tools now available typically solve only part of the workflow and may lack functionality specifically required for environmental sciences 
As a consequence, the need to combine tools may require familiarizing with various software environments, tedious transformation of in-between 
datasets and complicating reproducible non-target research We are developing an R based open source software platform which provides a 
common interface for non-target analysis tailored for environmental sciences Existing software solutions (eg XCMS, OpenMS, CAMERA, and 
MetFrag) are utilized to provide a typical non-target workflow such as extraction of features, calculation of chemical formulae and tentative 
compound identification A common interface to these tools allows easy incorporation of tested algorithms and comparison of their output Other 
functionalities include filtering and prioritization of data, interactive and static reporting and interoperability with vendor software Our software is 
currently being applied in various non-target studies conducted in our institute Examples include the chemical characterization of dissolved organic 
matter to study its stabilization in podzols, the identification of small and polar emerging polar contaminants to study their removal by reverse 
osmosis during water treatment and elucidation of transformation products of biocides released in constructed wetlands
Page 238
POSTER SESSIONS 1 AND 2 – Monday and Tuesday – all odd number posters will be on display.POSTER SESSIONS 3 AND 4 – Wednesday and Thursday – all even number posters will be on display.TECHNOLOGY15th Annual Conference of the Metabolomics Society*AWARD WINNERSTECHNOLOGY
P-512
A new method for enhancing gap filling accuracy and specificity in high resolution mass spectrometry data processing
PRESENTING AUTHOR: Erik Mueller, Helmholtz Centre for Environmental Research - UFZ, Germany
CO-AUTHORS: Werner Brack, Martin Krauss, Tobias Schulze
Liquid chromatography high resolution mass spectrometry is a key analytical technology in the identification of targets, suspects and unknowns 
for profiling in environmental screening and metabolomics By default, peak picking uses heuristic algorithms for the extraction of individual ion 
chromatograms (EICs) from chromatographic raw data and identification of peaks in these EICs But heuristic methods cannot account for all types 
and shapes of noise occurring in the data While some algorithms exist to mitigate this problem, most gap filling approaches result in many false 
positives and negatives We present here a novel gap filling method that utilizes the similarity between the extracted ion chromatograms of a peak 
in different samples to deduce where previously undetected peaks can be found while also keeping the number of inaccurately categorized peaks 
at a minimum With our new approach, the accuracy of categorized peaks was increased by 51% compared to the peak finder in MZmine
P-513
A full workflow for machine learning techniques in integrative multiomics studies as part of the COVAIN toolbox
PRESENTING AUTHOR: Xiaoliang Sun, University of Vienna, Austria
CO-AUTHORS: Wolfram Weckwerth
The Vienna Metabolomics Center has established open-source and cross-platform workflows for computational mass spectrometry, integrative 
multi-omics analysis and predictive modelling for clinical, biochemical, agricultural and ecological studies All algorithms are implemented in the 
toolbox COVAIN (1) High resolution mass spectral raw data are processed with an algorithm called mzFun which identifies and aligns thousands of 
compounds over hundreds of samples from MS/MSn fragmentations, molecular formula, isotopomer pattern and internal and external MS libraries 
From this initial annotation biochemical pathways are assigned to unknown m/z features with an algorithm called mzGoupAnalyzer (2) Processed 
metabolomics, proteomics, transcriptomics, phenotypical and physiological data are imported into COVAIN, which provides rigorous statistical 
tools for data mining from data cleaning, imputation, uni- and multi-variate statistics including ANOVA, PCA, ICA, PLS, correlation, clustering, 
Granger causality, multiple regression up to advanced machine learning procedures These algorithms include multivariate best subset selection 
by genetic algorithm, classifiers like SVM, DA, KNN and ensemble methods as well as ROC/AUC diagnostics Further, statistical network inference, 
visualization, modularity analysis, KEGG pathway enrichment analysis are implemented COVAIN is also featured with an experimentally validated 
inverse Jacobian calculation that infers biochemical regulation Jacobian matrix directly from genome-scale metabolomics covariance data (1,3) 
During this processes high quality editable figures are provided All these computational mass spectrometry and data mining tools are organized 
in an All-In-One tool with graphical user interface 1 Sun X & Weckwerth W (2012) Metabolomics 8(1):81-93 2 Doerfler et al (2014) Plos One 
9(5):e96188 3 Doerfler et al (2013) Metabolomics 9(3): 564-574
P-514
UMetDIA: Advancing SWATH-MS Based Untargeted Metabolomics
PRESENTING AUTHOR: Ruohong Wang, Shanghai Institute of Organic Chemistry, Chinese Academy of Sciences, China
CO-AUTHORS: Yandong Yin, Zheng-Jiang Zhu
Advancing SWATH-MS Based Untargeted Metabolomics through High-Coverage Spectral Library Building and Quantitative Ion Selection Data-
independent acquisition (DIA) has been emerged as a powerful technology for untargeted metabolomics due to its capability to acquire all MS2 
spectra and high quantitative accuracy However, in DIA, the direct link between MS1 and MS2 ions in multiplexed MS2 spectra is missing, and 
there is no universal evaluation approach to decide whether MS1 or MS2 ion should be selected as the quantification ion for one metabolite To 
address these current limitations in DIA data analysis, we developed a new strategy integrating DIA spectral library construction,quantitative 
ion selection with large-scale targeted re-extraction in DIA data itself First, we proposed a new methodology that enabled us to construct a 
comprehensive spectral library directly from DIA data (referred as DIA-Lib, usually from pooled samples) The constructed DIA-Lib possessed the 
strengths including broad spectrum coverage, high quality and high reproducibility Then, for every feature in DIA-Lib, the suitable quantitative 
ion was selected by Qscore method we proposed We demonstrated the advantage of Qscore quantification method such as accuracy, linearity, 
and reproducibility Furthermore, the high-coverage DIA-lib was used to re-extract ions in biological samples Combining with the ion information 
selected by Qscore method above, large-scale metabolites extraction and accurate quantification in biological sample can be realized Finally, the 
strategy was applied on colorectal cancer clinical sample set Compared with conventional MS1 quantification method, our method performed better 
on separating cancer and adjacent tissues
Page 239