### Datasets as a Constraint for the Use of Statistical Methods

In the context of limited datasets, we have developed a new tool to detect analytical correlations. The algorithm's principle is to group features from the same analyte and propose a single representative per group. Users can define grouping criteria using various options, including correlation coefficients, retention times, and mass defect information. The representative feature can be determined using four methods, depending on the analytical technology.

To evaluate its performance, we compared our tool with one of the most commonly used free packages that offer a grouping method: ‘CAMERA’. Specifically, we used the Galaxy version ‘CAMERA.annotate’ available in Workflow4Metabolomics (W4M; http://workflow4metabolomics.org). We illustrated the tool's functionalities using a published dataset available on W4M (Thevenot et al., 2015). In this dataset, which contains 3,120 ions, our tool created 2,651 groups, indicating that 15% of the ions are proposed to be filtered due to analytical redundancies. Additionally, the tool subdivided more than 20 groups of over 10 ions into smaller ones, corresponding to individual annotated metabolites, thereby demonstrating the efficiency and relevance of our approach.

As a key element in metabolomics data analysis, this tool will be available via the web-based Galaxy platform W4M, providing different output files for network visualization and further data analysis within workflows.

---

### Comets-Analytics: A Centralized Computational Framework for Consortia-Level Meta-Analyses

**Presenting Author:** Ewy Mathe, Ohio State University, United States  
**Co-Authors:** Krista Zanetti Moore, Kai-Ling Chen, Dave Ruggieri, Ella Temprosa

**Abstract:**

Metabolomics is increasingly being applied in large-scale epidemiological studies to uncover metabolites associated with physiological states such as age and disease. The National Cancer Institute-led “Consortium of Metabolomics Studies” (COMETS) includes over 45 international prospective cohorts with serum metabolomics profiles and detailed phenotypic data. To support meta-analysis at the consortia level, we have created a centralized computational infrastructure called Comets-Analytics. This framework was built with the following guiding principles: minimal analyst burden, reproducibility, data privacy, adherence to FAIR guidelines, and usability.

Comets-Analytics supports the harmonization of metabolite names across different platforms used in COMETS and implements partial correlation modeling. It includes "smart analytics" that perform extensive data and model checks to ensure validity and reproducibility. Meaningful warnings and errors are returned to inform users about how to fix their input data and what models are run. The web application also includes interactive tables and plots to empower users to promptly and globally assess results.

With Comets-Analytics, cohorts can analyze their own data using a common data format, and standardized results are sent centrally for meta-analysis. This streamlined approach greatly facilitates large consortia studies and ensures the integrity and reproducibility of results. Comets-Analytics, including detailed documentation, is available as an R package at https://github.com/CBIIT/R-cometsAnalytics and can be run directly from our servers at http://comets-analytics.org/.

---

### Composite Score: A Multivariate Correlation for Comparison of Metabolomics-Based Studies of Complex Mixtures

**Presenting Author:** Joshua Kellogg, University of North Carolina at Greensboro, United States  
**Co-Authors:** Olav M. Kvalheim, Nadja B. Cech

**Abstract:**

Untargeted metabolomics analyses, where the entire measurable metabolome is analyzed without predefined biomarker compounds, are useful when there are no a priori chemical or mechanistic hypotheses. However, successful untargeted metabolomics studies rely on effective statistical analysis to guide interpretation and inform conclusions. Principal Component Analysis (PCA), a primary statistical tool, often limits the comprehensiveness of the model by selecting a maximum of three components, which can yield poor discrimination between samples.

We have developed a new statistical metric, the composite score (CS), as a univariate statistic that incorporates multiple principal components to enable quantitative comparisons among metabolomics datasets. By integrating the scores and loadings of significant components from the original PCA model, the CS provides a more advantageous measure of similarity, enabling more quantitative comparisons than visual inspection of a PCA scores plot or hierarchical cluster analysis (HCA).

Several case studies focusing on complex natural product mixtures, such as green tea (Camellia sinensis) and goldenseal (Hydrastis canadensis) dietary supplements, highlight the utility of composite scores in evaluating similarity and identifying outliers within a sample set.

---

### Integrating 4D Peak Picking of LC-TIMS-MS/MS Data into GNPS Feature-Based Molecular Networking for Metabolomics and Lipidomics Analysis

**Presenting Author:** Florian Zubeil, Bruker Daltonik GmbH, Germany  
**Co-Authors:** Nikolas Kessler, Heiko Neuweger, Sven Meyer, Ulrike Schweiger-Hufnagel, Aiko Barsch

**Abstract:**

As the throughput of metabolomic and lipidomic analyses continues to expand, effective workflows for analyzing the resulting datasets are becoming increasingly important. Molecular networking has become a vital tool in the metabolomics community, allowing the identification of compounds with similar fragmentation patterns, which are often structurally related. This approach primarily focuses on fragment spectra, but important information can also be deduced from precursor spectra, such as intensity, accurate mass, and isotopic patterns.

We present a workflow to integrate analyte information for untargeted profiling from the software MetaboScape into GNPS feature-based molecular networking. The nodes in the resulting molecular network are enriched with useful information about the precursor ions, such as intensity in individual samples, molecular formula, annotation, CCS values, group mean, and maximum intensity. This information is crucial for assessing the distribution of specific analytes between sample groups. Additionally, this workflow enables the integration of 4D peak picking results from PASEF-MS/MS data into GNPS molecular networking, as demonstrated on a lipid sample. This approach simplifies the interpretation of the resulting molecular network by displaying generated molecular formulas instead of precursor masses as node labels and benefits from cleaner MS/MS spectra of co-eluting analytes generated by ion mobility separation.

---

### Hierarchical Bayesian Models for Stable Isotope Resolved Metabolomics: A Unified Framework for Testing Hypotheses about Total Abundance and Isotopologue Distribution

**Presenting Author:** Patrick J. Trainor, University of Louisville, United States  
**Co-Authors:** Pawel K. Lorkiewicz, Joshua K. Salabei, Bradford G. Hill

**Abstract:**

The analysis of data from Stable Isotope Resolved Metabolomics (SIRM) experiments presents unique statistical challenges. Experimental manipulations, such as gene knockout or treatment with an enzymatic inhibitor, may change the concentration or pool of a metabolite, the fractional distribution of the metabolite pool within isotopologues, or both. Additionally, conducting univariate statistical tests at the isotopologue level raises multiplicity concerns.

We propose a hierarchical Bayesian model for testing hypotheses in SIRM experiments that addresses these challenges. The model assumes Gaussian prior distributions for the total abundance of a metabolite, Dirichlet prior distributions for the fractional distribution of abundances within isotopologues, and Gaussian priors to account for within-phenotype variability and measurement error. Gibbs sampling, a Markov chain Monte Carlo technique, is used to simulate the joint posterior distribution of model parameters given observed experimental data. From the joint posterior distribution, hypotheses regarding both total metabolite abundance and isotopologue distribution can be tested.

We demonstrate the application of this methodology to a 15N2, 13C5-glutamine labeling experiment conducted to evaluate the effect of aminooxyacetic acid (an inhibitor of aminotransferases including aspartate aminotransferase) treatment in murine cardiac mesenchymal cells isolated based on c-kit positivity. Metabolites extracted from treated and untreated cells were detected by FTICR-MS, and relative abundances were quantified. We report differences in isotopologue distributions between treated and untreated cells in malate and glutamate, and differences in total abundances of malate, aspartate, and glutamate.

---

### Metabolomic Profiling Identifies a Systemic Suppression of Steroid Metabolism Among Prevalent Asthma Cases: Are Inhaled Steroids the Cause?

**Presenting Author:** Priyadarshini Kachroo, Brigham & Women’s Hospital, United States  
**Co-Authors:** Rachel S. Kelly, Mengna Huang, Isobel Stewart, Claudia Langenberg, Scott T. Weiss, Jessica A. Lasky-Su

**Abstract:**

Asthma is a complex disease, often effectively treated with inhaled corticosteroids (ICSs). We aimed to identify metabolomic signatures of asthma and evaluate the impact of ICSs on the overall plasma metabolomic profile. Our study included 10,754 participants from the population-based EPIC-Norfolk cohort with data available for prevalent physician-diagnosed asthma. Metabolomic profiling of plasma was conducted using ultrahigh-performance liquid chromatography and tandem mass spectrometry.

We assessed individual metabolite associations with asthma using multivariable logistic regression models and evaluated the impact of ICS use on those findings. These results were replicated using data from 613 individuals in the Partners Biobank (PB). After quality control, we identified 858 known metabolites, of which 27 (3.1%) were associated with prevalent asthma after Bonferroni multiple-comparison correction (P<5.8e-5). The top two associations, dehydroisoandrosterone sulfate (DHEA-S) and cortisone, were decreased in asthmatics (OR=0.65, P=1.4e-27; OR=0.72, P=7.8e-20, respectively). Fifteen out of 27 metabolites replicated in the Partners Biobank (P<0.05), including strong associations between the top two EPIC findings and asthma: DHEA-S and cortisone (OR=0.36, P=2.7e-4; OR=0.30, P=3.0e-5, respectively).

Notably, all 15 metabolites were in the corticosteroid, pregnenolone, and androgenic steroid pathways and were markedly reduced in asthmatics (ORs=0.65-0.81). Further investigation demonstrated consistent negative associations between ICS use and these metabolites. These findings suggest that significant suppression of multiple steroid pathways in asthmatics could be modulated by ICSs, which merits further investigation. The consistent negative relationship between ICS use and steroid metabolites suggests that ICSs may have stronger systemic effects on circulating plasma steroid levels than currently recognized.

---

### Hierarchical Preprocessing for LC/MS Metabolomics Data Generated in Multiple Batches

**Presenting Author:** Tianwei Yu, Emory University, United States  
**Co-Authors:** Qin Liu, Douglas Walker, Karan Uppal, Shuzhao Li, ViLinh Tran, Dean P. Jones

**Abstract:**

With the growth of metabolomics research, more studies are being conducted on large numbers of samples. Due to technical limitations of the Liquid Chromatography – Mass Spectrometry (LC/MS) platform, samples need to be processed in multiple batches. Across different batches, differences in data characteristics are often observed. Traditional preprocessing methods treat all samples as a single group, necessitating larger m/z and retention time tolerance levels to account for between-batch differences. This approach is sub-optimal, as it can result in errors in peak alignment that cannot be corrected by batch effect correction methods applied after preprocessing.

To address this issue, we developed a new approach that processes the data hierarchically—first within each batch and then between batches. Different parameter settings can be adaptively found for within-batch and between-batch quantification and alignments. The method is implemented in the existing workflow of the apLCMS platform. Analyzing data with multiple batches, both from standardized plasma samples and real biological studies, the new method resulted in feature matrices with higher consistency. This method is useful for large studies involving multiple batches.

---

### Integrated Workflow with Quality Control for Large Cohort and Clinical Metabolomics Research Using Robust Hardware and Signal Correction

**Presenting Author:** Nikolas Kessler, Bruker, Germany  
**Co-Authors:** Sebastian Goetz, Ulrike Schweiger-Hufnagel, Matthias Szesny, Aiko Barsch, Sven W. Meyer, Matthew R. Lewis

**Abstract:**

Metabolomics research relies on the precise measurement of statistically powered sets of hundreds or thousands of samples. First, this requires robust analytical hardware with long-term stability capable of generating high-precision data. Second, processing large datasets may require additional mathematical correction to compensate for systematic changes in observed signals as samples interact with the analytical system, affecting its performance.

We investigated the long-term stability of an LC-HR-QTOF system by measuring a batch of more than 1,000 urine samples and monitoring the effect of data acquisition on MS ion source contamination and detector aging. To address the remaining within-batch intensity drifts, we present new software: a fully automated workflow that allows for the automated correction of intensity drifts, improving data precision and statistical reliability. An interactive and intuitive visualization provides rapid feature-wise review of intensity drifts and their corrections, as well as detection of statistical outliers.

Run-order signal drift correction effectively reduced the relative standard deviation (RSD) of feature intensities within sample groups measured across replicate quality control sample measurements. This also increased the number of analytes meeting the requirement of an RSD below 20%, a typical cut-off. Visually, this improvement was observed in PCA, with more closely clustering of sample groups. In summary, we present a workflow for population and clinical metabolomics research enabled by robust LC-HRMS hardware and software, allowing filtering and correction for signal drift effects.

---

### Detect and Quantify Sources of Variability in Metabolite Measurement in a Japanese Population

**Presenting Author:** Ayano Takeuchi, Keio University, Japan  
**Co-Authors:** Sei Harada, Taichi Shimazu, Taiki Yamaji, Norie Sawada, Junko Ishihara, Ribeka Takachi, Kazutoshi Nakamura, Junta Tanaka, Manami Inoue, Motoki Iwasaki, Hiroyasu Iso, Masahiro Sugimoto, Akiyoshi Hirayama, Tomoyoshi Soga, Masaru Tomita, Shoichiro Tsugane, Toru Takebayashi

**Abstract:**

Our study aims to quantify sources of variability in urine and plasma metabolite concentrations measured using capillary electrophoresis-mass spectrometry. We used samples from the Japan Public Health Center-Based Prospective Study for the Next Generation (JPHC-NEXT) validation study in Japan. We collected 24-hour urine and plasma specimens from 253 men and women aged 40–74 years from five areas, collected at two time points: baseline (2012) and the same period the following year (2013).

We randomly selected 43 samples and dispensed them into three replicates. We measured the replicates sequentially to detect the sum of the squared deviations of 'pure measurement error'. We also measured some replicates in different positions within the same batch to detect 'within-batch variation of measurement' and in the same position in different batches to detect 'between-batch variation of measurement'.

We will show the proportion of these three types of variation (pure measurement error, within-batch variation, and between-batch variation) and variation between times (2012 to 2013) for all 123 metabolites in urine and 102 metabolites in plasma that we measured.

---

### Virtual Metabolomics Mass Spectrometer (ViMMS): A Mass Spectrometry Simulator for Comparing Different Fragmentation Strategies in Metabolomics

**Presenting Author:** Joe Wandy, Glasgow Polyomics, United Kingdom  
**Co-Authors:** Vinny Davies, Justin J.J. van der Hooft, Ronan Daly, Simon Rogers

**Abstract:**

Liquid-Chromatography (LC) coupled with Tandem mass spectrometry (MS/MS) is widely used in identifying small molecules in untargeted metabolomics. However, the development of new MS/MS acquisition strategies is hampered by the lack of simulators that allow researchers to prototype and compare different fragmentation strategies before validation on real machines. Although some simulators exist, they are typically focused on proteomics and do not include simulation of MS2 acquisition within a chromatographic run.

We introduce Virtual Metabolomics Mass Spectrometer (ViMMS), a modular metabolomics LC-MS/MS simulator framework that allows for real-time scan-level control of the MS2 acquisition process in-silico. ViMMS can generate new data based on kernel density estimates trained on empirical data or generate data that resembles real data from a list of user-defined chemical formulas. Alternatively, pre-existing data can be re-run in-silico with different fragmentation strategies. Samples can be exported as .mzML files, and different fragmentation controllers can be compared. ViMMS is also extendable with additional spectra generation processes and noise models.

We will show results from experiments comparing different fragmentation strategies. First, ViMMS will be used to take the output of a real LC/MS analysis and examine the effect of varying N in Top-N Data Dependent Acquisition protocol. We will also demonstrate how ViMMS can be used to compare published acquisition strategies, such as Data-set-Dependent Acquisition (DsDA) and Nested Data-Independent Acquisition (DIA). We expect that ViMMS will save development time by allowing for offline evaluation of novel fragmentation strategies and optimization of fragmentation strategy for a particular sample.

---

### Open Source Software Platform for Mass Spectrometry-Based Non-Target Screening in the Environment

**Presenting Author:** Rick Helmus, Institute for Biodiversity and Ecosystem Dynamics, Netherlands  
**Co-Authors:** Vittorio Albergamo, Olaf Brock, John Parsons, Pim de Voogt

**Abstract:**

Chemical analysis has been widely applied over the past decades to characterize both natural and anthropogenic compounds in the environment. A 'non-target' approach, which screens hundreds to thousands of unknown chemicals simultaneously, is becoming increasingly adopted. At this scale, tools are crucial for automating extraction, prioritization, and identification of chemicals of potential interest. Existing software tools typically solve only part of the workflow and may lack functionality specifically required for environmental sciences. Combining these tools can require familiarizing with various software environments, tedious transformation of in-between datasets, and complicating reproducible non-target research.

We are developing an R-based open-source software platform that provides a common interface for non-target analysis tailored for environmental sciences. Existing software solutions (e.g., XCMS, OpenMS, CAMERA, and MetFrag) are utilized to provide a typical non-target workflow, such as extraction of features, calculation of chemical formulae, and tentative compound identification. A common interface to these tools allows easy incorporation of tested algorithms and comparison of their output. Other functionalities include filtering and prioritization of data, interactive and static reporting, and interoperability with vendor software.

Our software is currently being applied in various non-target studies conducted in our institute. Examples include the chemical characterization of dissolved organic matter to study its stabilization in podzols, the identification of small and polar emerging contaminants to study their removal by reverse osmosis during water treatment, and elucidation of transformation products of biocides released in constructed wetlands.

---

### A New Method for Enhancing Gap Filling Accuracy and Specificity in High-Resolution Mass Spectrometry Data Processing

**Presenting Author:** Erik Mueller, Helmholtz Centre for Environmental Research - UFZ, Germany  
**Co-Authors:** Werner Brack, Martin Krauss, Tobias Schulze

**Abstract:**

Liquid chromatography high-resolution mass spectrometry (LC-HRMS) is a key analytical technology for identifying targets, suspects, and unknowns in environmental screening and metabolomics. By default, peak picking uses heuristic algorithms for the extraction of individual ion chromatograms (EICs) from chromatographic raw data and identification of peaks in these EICs. However, heuristic methods cannot account for all types and shapes of noise occurring in the data. While some algorithms exist to mitigate this problem, most gap-filling approaches result in many false positives and negatives.

We present a novel gap-filling method that utilizes the similarity between the extracted ion chromatograms of a peak in different samples to deduce where previously undetected peaks can be found while keeping the number of inaccurately categorized peaks at a minimum. With our new approach, the accuracy of categorized peaks was increased by 51% compared to the peak finder in MZmine.

---

### A Full Workflow for Machine Learning Techniques in Integrative Multi-Omics Studies as Part of the COVAIN Toolbox

**Presenting Author:** Xiaoliang Sun, University of Vienna, Austria  
**Co-Author:** Wolfram Weckwerth

**Abstract:**

The Vienna Metabolomics Center has established open-source and cross-platform workflows for computational mass spectrometry, integrative multi-omics analysis, and predictive modeling for clinical, biochemical, agricultural, and ecological studies. All algorithms are implemented in the COVAIN toolbox. High-resolution mass spectral raw data are processed with an algorithm called mzFun, which identifies and aligns thousands of compounds over hundreds of samples from MS/MSn fragmentations, molecular formula, isotopomer pattern, and internal and external MS libraries. From this initial annotation, biochemical pathways are assigned to unknown m/z features with an algorithm called mzGroupAnalyzer.

Processed metabolomics, proteomics, transcriptomics, phenotypical, and physiological data are imported into COVAIN, which provides rigorous statistical tools for data mining, including data cleaning, imputation, uni- and multivariate statistics (ANOVA, PCA, ICA, PLS, correlation, clustering, Granger causality, multiple regression), and advanced machine learning procedures. These algorithms include multivariate best subset selection by genetic algorithm, classifiers like SVM, DA, KNN, and ensemble methods, as well as ROC/AUC diagnostics. Further, statistical network inference, visualization, modularity analysis, and KEGG pathway enrichment analysis are implemented.

COVAIN also features an experimentally validated inverse Jacobian calculation that infers biochemical regulation Jacobian matrix directly from genome-scale metabolomics covariance data. During this process, high-quality editable figures are provided. All these computational mass spectrometry and data mining tools are organized in an All-In-One tool with a graphical user interface.

References:
1. Sun X & Weckwerth W (2012) Metabolomics 8(1):81-93.
2. Doerfler et al. (2014) Plos One 9(5):e96188.
3. Doerfler et al. (2013) Metabolomics 9(3): 564-574.

---

### UMetDIA: Advancing SWATH-MS Based Untargeted Metabolomics

**Presenting Author:** Ruohong Wang, Shanghai Institute of Organic Chemistry, Chinese Academy of Sciences, China  
**Co-Authors:** Yandong Yin, Zheng-Jiang Zhu

**Abstract:**

Data-independent acquisition (DIA) has emerged as a powerful technology for untargeted metabolomics due to its capability to acquire all MS2 spectra and high quantitative accuracy. However, in DIA, the direct link between MS1 and MS2 ions in multiplexed MS2 spectra is missing, and there is no universal evaluation approach to decide whether MS1 or MS2 ion should be selected as the quantification ion for one metabolite.

To address these limitations, we developed a new strategy integrating DIA spectral library construction, quantitative ion selection, and large-scale targeted re-extraction in DIA data itself. First, we proposed a new methodology that enables the construction of a comprehensive spectral library directly from DIA data (referred to as DIA-Lib, usually from pooled samples). The constructed DIA-Lib possesses broad spectrum coverage, high quality, and high reproducibility. For every feature in DIA-Lib, the suitable quantitative ion was selected using the Qscore method we proposed. We demonstrated the advantages of the Qscore quantification method, such as accuracy, linearity, and reproducibility.

Furthermore, the high-coverage DIA-Lib was used to re-extract ions in biological samples. Combining the ion information selected by the Qscore method, large-scale metabolite extraction and accurate quantification in biological samples can be realized. Finally, the strategy was applied to a colorectal cancer clinical sample set. Compared with conventional MS1 quantification methods, our method performed better in separating cancer and adjacent tissues.