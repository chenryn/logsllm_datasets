4个单值：案例数、活动数、参与组织去重数、参与资源去重数。4个单值：案例数、活动数、参与组织去重数、参与资源去重数。
1个表格：组织负荷统计。每行一个组织，分别展示列：组织名称、参与案例数、负荷集中度(Group relative focus)、负荷分配均衡度(Group relative stake)、组织覆盖率(Group coverage)。表格默认按覆盖率高到低排序。可点击表头换成负荷集中度或分配均衡度排序。统计数值均为当前时间范围内的总统计值。
1个时间趋势图：展示指定组织的上述 3 个百分比值的时间趋势。时间分桶按固定桶数自动计算。默认为分析上面组织负荷表上集中度最高的组织。支持在表格上点击切换“组织”展示。点击时应滚动页面使趋势图在屏幕可见。
1 个表格：组内成员贡献率(Group member contribution)。每行一个资源，分别展示列：资源名称、参与案例数和贡献率的每日数据。支持切换“组织”，和上一个复用。1 个时间趋势图：展示指定成员的贡献率的时间趋势。默认为分析上面组内成员贡献率表上贡献率最高的成员。支持在表格上点击切换“成员”展示。
钻取行为：在组织负荷时间趋势图上，钻取为组织这个属性和时间段的过滤；在组内成员贡献时间趋势图上钻取为资源这个属性和时间段的过滤。
这几个值可能需要 info 解释：
负荷集中度：这个组织完成指定活动的次数，占该组织所有活动次数的比例。
负荷分配均衡度：这个组织完成指定活动的次数，占该活动的总次数的比例。
组织覆盖率：这个组织中完成过指定活动的成员人数，占该组织成员总数的比例。
组内成员贡献率：这个组织中不同成员各自完成指定活动次数的占比，全员总和为 100%。
这个图来自原始论文中的设计。对应值的计算逻辑可以参考。
社交图谱标签页
本标签页存在于组织分析标签页后面，仅在日志数据包含资源属性时可见。
画布内容为资源之间社交相关性，节点是资源名称，连线是社交强度，有粗细区别。画布内容为资源之间社交相关性，节点是资源名称，连线是社交强度，有粗细区别。
支持类型的切换：工作交接、分包、合作。
支持关系展示比例的调节。默认为 30%。
画布支持放大缩小。
三个分析类型可能需要 info 解释：
Handover of Work，工作交接指标，即一个资源跟在另一个资源后面的次数多少。
Subcontracting，分包指标，即一个资源跟在一个资源后面一起干活，后续流程又返回原始资源的情况。
Working Together，合作指标，即两个资源一起并发干活。——存疑：如果需要有 start_time，就先不做。
注意：组织分析、图谱分析，所用数据也受顶部过滤条件控制。
保存为 BPMN 模型
在流程发现页，右上角“更多”菜单中提供“保存为BPMN 模型”选项。点击后填写模型名称、描述。
和 BPMN 模型进行流程对比
和“变体对比”功能类似，把“选中对比”按钮改成一个下拉按钮，另一个选项叫“模型审查”。点击“模型审查”后，选择加载一个已存 BPMN 模型；流程画布上，展现选中BPMN 模型所转换成的 DFG 图做为基准图，原本在展示中的变体部分为对比图。画布展现二者差异。
导入导出 BPMN 模型
在流程发现页，右上角“更多”菜单中提供“BPMN 模型管理”选项，打开 BPMN 模型列表。
在流程列表页，右侧操作栏“更多”菜单中提供“BPMN 模型管理”选项，打开 BPMN模型列表。
模型列表右侧提供“导出”按钮，点击下载文件到本地。
模型列表右上角提供“导入”按钮，点击选择本地文件上传。
BPMN 模型应该都不太大，导入导出操作应该不用异步处理，转圈等待即可。
案例回放
流程发现页，画布左上角操作区域新增“回放”按钮，支持按天聚合、按小时聚合、逐一回放。
点击开始回放后，流程图上，以圆圈动画走实际流程。
如果是聚合，按案例数大小范围来展示圆圈大小。注意大小范围控制。如果是聚合，按案例数大小范围来展示圆圈大小。注意大小范围控制。
不同连线有时间，圆圈在线上速度应有对应区别。
播放器上支持速度调整，支持时间轴快进。
注意：
当实际案例行为要经过被百分比隐藏的活动或路径时，回放也自动隐藏，别在空白画布上跑~
时间轴长度为当前过滤方案下所有日志的总时间跨度，向上取整。比如实际 19d23h，展示 20d。
播放速度默认为 5min 播放完毕，UI 层面点击加倍则同比缩减。实际播放倍速由程序根据总时间跨度和播放时长计算。比如总跨度 1month，默认倍速播放，则实际倍速为8640x。
合规性检测
底部新增“合规性检查”标签页。进入标签页时，首先要从BPMN 模型列表中选择一个BPMN 模型。点击开始检查，然后得到结果页面。
页面内容包括：
合规性概览统计：合规案例占比及时间趋势图、不合规行为总数、合规 vs 不合规对比值（数量、案例耗时、平均步骤数）不合规行为清单：每行一个行为。内容包括行为名称、涉及案例数及占比、案例耗时影响、步骤数影响、查看日志。点击“查看日志”操作时，跳转到“流程日志”标签页进行对应案例的日志查看。
支持的不合规行为类型包括：
不应经过活动、应经过活动、不应经过路径、不应作为开始节点、不应作为结束节点。
根因分析
不合规行为清单上，点击具体单行，进入针对该行为的根因分析页面。
页面内容包括：
当前行为概览统计：当前行为涉及的案例数、占比、时间趋势图、当前行为 vs 合规对比值（案例耗时、平均步骤数）
根因分析清单：每行一个属性。内容包括：属性名称、根因属性值、相关性分值、涉及案例数。支持切换分值和数量排序。如果强相关的属性值有多个，则一并列出。目前界面不支持“OR”过滤条件，所以属性值暂时不支持点击过滤。根因分析算法，拟参考 elasticsearch 的 significant terms aggregation 实现，并从其中 4 个选项中挑选了 GND，因为这个输出是在 0-1 区间：elasticsearch/GND.java at main · elastic/elasticsearch (github.com)
es 官网文档中还有更常见的 p-value，但是这个是 xpack-ml 里的，es 真坑，一个函数里不同参数都拆分不同协议发布。
注1：相关性计算是针对一个属性的所有取值都要逐一计算，得出该属性中哪个值最相关。计算量较大，可以做一些限定。比如：一个属性如果去重值 > 100 或去重值/总数>0.7，就不参与根因分析计算。
注 2：以上计算方法仅针对文本属性有效。对于数值类型，需要先进行 bins=10的分桶，转换为[start,end)区间范围，然后再计算区间范围内案例的相关性评分。注 3：es 的 GND 和标准的谷歌 NGD 有所区别，标准 NGD 是0 到正无穷，越接近 0 相似度越大，超过 1 的就不太相关了。es 的 GND =exp(-1 * NGD)，所以是 0-1 区间，exp(-1)=0.368。所以在清单上，对相关性分值大于 0.8 的，采用高优先级颜色标记，0.4 到 0.8 的，采用中优先级颜色标记，0.4 以下的，采用低优先级颜色标记，高、中分界阈值需提供后台参数项可配，我们需要项目上积累一些经验值。
BPMN 编辑器
https://www.ibm.com/docs/en/process-mining/1.13.2?topic=analysis-model-editor
在 BPMN 模型列表上新增“编辑”入口，点击打开编辑画布如上所示。
在 BPMN 模型列表上新增“新建/上传”入口，点击可上传本地 bpmn 文件。
工作时段配置工作时段配置
配置页包括时段配置和日历配置。
时段配置支持设定工作时段，(start - end)，可设范围是时分秒。
日历配置支持设定节假日和倒休日。可设内容为年月日。
暂不考虑多份日历的定义。可以考虑复用日志易系统内的日历定义。
自定义指标
https://learn.microsoft.com/en-us/power-automate/minit/calculation-context
https://learn.microsoft.com/en-us/power-automate/minit/statistical-operations
https://learn.microsoft.com/en-us/power-automate/minit/requirements-for-applicationhttps://www.ibm.com/docs/en/process-mining/1.13.2?topic=SSWR2IP_1.13.2/process-mining-documentation/references/case-object-methods.htm
从上述文档中明显可以看到 minit 的设计比 ibm 复杂的多，但又没有celonis 那样直接上个 code editor那么复杂。作为初期设计概念正好合适。介绍 minit 的设计大概思路：
自定义指标根据最后可用的地方归入 1- 4 类：map 类、stat 类、filter 类、RCA 类。
map 类比较特殊。就是针对活动和步骤的总统计值，可以理解为作用域为 ALL。
stat 类，根据作用域来区分是 event 还是 case 还是 edge。还有额外的overview 和duration influence 两类。filter 类和 stat 类基本差不多。但是缺了 duration influence 类。
rca 类，只能用stat 的 overview 类。
自定义指标的agg计算函数（包括count、pct、avg、sum、min、max、first、last等）要各自申明作用域，分为：view（应该是当前可见的部分）、process（应该是所有变体）、rule（应该是所有变体但又被过滤条件了的部分）、caseperattr（符合条件的一个案例算一次，每个属性值都groupby输出）、eventperattr（符合条件的一个案例里多次活动算 N 次）、edgeperattr。
自定义指标可用的stat 数据包括：eventcount、duration、start、end、casecount、reworkcount、loopcount、occurrence等。 如果是 edge 作用域的，还有 target、source 什么的。其他做计算的通用函数。加减乘除、if、case、数值、文本、时间运算等。
工作时段函数。isworkinghour, isworkingday, ispublicholiday, durationcalendar（最主要的，根据日历计算两个时间之间的有效耗时）, addworkingdays, addworkinghours, addworkingminutes（后面这三个完全想不明白用来干嘛）。
以项目需求示例：“判断某个活动是否超时，是个别现象还是普遍较高，耗时PCT90，PCT50是不是也有些作用，或者这个活动耗时在总耗时里占比，这样可以判断活动是否严重影响了总体流程时间”
可以自定义指标如下：
Pct90_duration：计算语句为 pct(eventperattr, duration(), 90)Proport_duration：计算语句为sum(eventperattr, duration()) / sum(caseperattr, duration())
流程图top统计分析
在活动或路径上点击时，右侧可以出统计分析区域，包括这个活动或节点的事件统计（案例数、活动数、重做数）、耗时分布（平均值及占比、总耗时及占比、标准差、最大值、最小值）、自定义指标、属性分布等。如下图的 minit 所示：
https://www.youtube.com/watch?v=wYmMCTPIiPQ
社交图谱top 统计分析
可以在社交图谱上查看具体 resource 的统计情况，包括：包含该员工的案例数量、案例平均耗时，该员工执行的活动（可选择）的数量、平均耗时、自定义指标等。
图谱应支持给资源按角色分组染色（给出图例）。图谱应支持给资源按角色分组染色（给出图例）。
https://www.ibm.com/docs/en/process-mining/1.13.2?topic=mapping-social-net
活动地图分析
在社交图谱之外，新增一种和弦图分析方法：
中间是流程的活动清单，可以按执行顺序或活动数量排序。
外圈是所有资源，按角色分组颜色。
鼠标停在资源上，高亮展示该资源执行过的活动们。
鼠标停在活动数，高亮展示执行过该活动的资源们。
点击选中资源或活动，查看 top 统计。内容和上一节类似。
https://www.ibm.com/docs/en/process-mining/1.13.2?topic=mapping-activity-map
整合需求
应用部署和 license 控制
新增“可使用流程挖掘应用”功能权限。
非功能性需求
安全性需求
可用性需求新增“可使用流程挖掘应用”功能权限。
非功能性需求
安全性需求
可用性需求
流程挖掘场景预期的每个场景数据量规模为：原始日志数百万条，transaction 后的案例为十万条。
上述所有统计、过滤操作，都基于相同的数据源。即 SPL 语句的 | transaction  maxspan=30d mvlist=,,...部分，在完成属性映射后，就可以确定。
transaction 指令只能 SPLserver 单机运行，流程发现页上每次操作会发起 5 次以上 transaction，资源消耗过大和响应速度超时等问题可能导致页面实际不可用。
需要考虑对每次流程模型进行中间结果的缓存。而流程发现页所有 SPL 改为基于中间结果的分析和过滤。目前可选方案有：通过 collect 指令写入一个特定 beaver 索引——问题有两个。一是多值存入 beaver 可能有排序问题，而分析中排序很重要；二是数据的 OOR 和 TTL 问题。
通过 outputlookup 指令写入一个特定 kvstore——问题是预期数据量下性能和稳定性未知。
实现一对 inputjson/outputjson 自定义指令，直接缓存为本地文件——问题是非单机情况如何同步。
不依赖 SPL，由Django 后端服务自行完成查询结果的缓存、流程图的缓存和即时性的每次过滤、统计分析。
从开发工期考虑，最终选择方案 4，由 Django 服务完成后端实现。