shared path, denoted by SP .
Discover divergence: In the second step, we ﬁrst ﬁnd
all symbolic addresses which are different in the ﬁnal cache
states. That is, we use M1 and M2 to ﬁnd addresses such
that they make a difference between ce 1 and ce 2. Intuitively,
these are the problematic memory addresses that we need to
localize the error cause for each of them.
For each problematic memory address l, the localization
algorithm reports the ﬁrst point in SP , say an instruction c,
so that the abstract cache states of l are different for the next
point in SP , but are identical for the previous point in SP .
Such an instruction is reported as the root cause of the side
channel at l. Note that when multiple addresses may cause
side channels, our algorithm reports multiple instructions in
a program, following the same procedure for each l that
causes a difference between ce 1 and ce 2.
Example: Fig. 1 shows a simple example with two side
channels. For the ﬁnal cache state, an SMT solver reports
a model where RK[3] = 256, key[0] = 255 in value set
M1 and RK[3] = 0, key[0] = 0 in value set M2. Based on
the model and tracked path conditions in the control ﬂow
graph, the localization algorithm constructs a shared path
consisting of the blocks in grey, shown in Fig. 5.
In this example, the ﬁnal cache state differs for several
symbolic addresses, including Sbox[0], base and so on.
For the address Sbox[0], the ﬁrst point in the shared
path that ce differs between the two execution paths is
after the assignment RK[4]=RK[0]ˆSbox[(RK[3] >>
8) & 0xFF, which is the correct location to blame for
the cache difference of address Sbox[0]. For the address
base, the ﬁrst point in the shared path that ce differs
between the two execution paths is after the branch con-
dition bit_set_at_i(key[0],i). This is the correct
location to blame as well, since the secret dependent branch
caused cache difference. For other problematic addresses,
the localization algorithm points to those two problematic
instructions as well in this example.
B. Fixing side channels
The localized causes of side channels enable a program-
mer or a compiler to ﬁx the identiﬁed side channels. We
explore two commonly used techniques for cache-based
side channel mitigation in this section and show how the
localized error causes facilitate error ﬁxing.
(cid:22)(cid:18)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:15 UTC from IEEE Xplore.  Restrictions apply. 
RK[4]=RK[0] …;
res = res * res
res = res % mod
bit_set_at_i
False
True
res = base * res;
res = res % mod
exit
Figure 5: Shared path computed from the model generated
by the SMT solver for the code in Fig. 1.
1) Preloading: Preloading eliminates cache-based side
channels by loading certain memory addresses before the
vulnerable instructions [2], [45]. It is typically used in AES
implementations, where all SBox tables ﬁt
in cache. In
AES, those tables only contain public data, but indexes
used to access the tables are key-dependent, which enables
an attacker to infer the key based on the footprints of the
AES implementation on cache [14], [2], [15]. This is similar
to the code in Example 1. To mitigate such attacks, AES
implementations preload the entire lookup tables into the
data cache before the actual encryption/decryption. That is,
they insert code that accesses every table entry to ensure
all table data are in the cache before encryption/decryption
starts. Hence, even if there are key-dependent table look-
ups, they will not affect the cache state as long as all table
entries are already in the cache initially and they are not
evicted during encryption/decryption.
2) Pinning: Pinning prevents cache misses on the data
that is explicitly “pinned” in a program. For instance, this
feature can be implemented in a customized cache, where
a cache entry with the “pin” bit set is never evicted [32];
it can also be implemented on some commodity hardware
with Hardware Transactional Memory (HTM) [46]. Com-
pared with preloading, pinning provides extra assurance
that pinned data will not be evicted until it is explicitly
“unpinned” in the program. Previous work has shown that
pinning can be use to defend against cache-based side
channels [32], [46].
3) Fixing side channels: To support preloading and pin-
ning, CaSym introduces special instructions in the form of
PRELOAD l and PIN l, which semantically preload/pin the
corresponding symbolic addresses into cache (when l is an
array, the instruction preloads/pins all elements in the array).
The localized root causes of side channels makes it
straightforward to insert needed preloading/pinning instruc-
tions to remove side channels: if the vulnerable point for
memory address l is an instruction c, then preload/pin l
before c will remove the counterexample found by the SMT
solver. For example, preloading/pinning the entire SBox
table right before its vulnerable point at line 3 in Fig. 1
as well as preloading base, res, mod right before their
shared vulnerable point at line 6 in Fig. 1 (found by the
localization algorithm in Section VII-A) will remove the side
channels in this program.
Although ﬁxing side channels seems easy with the help
of CaSym, we emphasize that ﬁnding where and what to
preload/pin is nontrivial without CaSym, since identifying
what data to preload can be difﬁcult. For example, the crucial
data in AES is the lookup table, which only stores public
information. Moreover, for preloading, fetching the data too
early may cause the data to be evicted before the vulnerable
instructions, which undermines the effect of preloading.
VIII. IMPLEMENTATION
CaSym is implemented inside LLVM [47] as a compiler
pass that performs cache analysis and error localization. It
analyzes LLVM IR code and performs symbolic execution
to build a cache formula. We use the Z3 SMT solver [48] to
check the satisﬁability of the cache formula, but any SMT
solver with theories for bit-vectors and arrays could sufﬁce.
The compiler pass of CaSym sends to the Z3 solver (in
the same process as the compiler pass) the cache formula as
an in-memory object. If the formula is satisﬁable (meaning
there is a side channel),
the solver generates a model
containing the assignments for the formula’s variables. Us-
ing this model, CaSym localizes the vulnerable LLVM IR
instructions. CaSym then uses the debugging information to
report the corresponding line numbers in the source program
to the user.
IX. EVALUATION
We evaluated CaSym on a set of crypto and database
benchmarks. All experiments were run on Ubuntu 14.04
in a virtual machine with 16 GB of RAM and an Intel
i7-5820K CPU at 3.30 GHZ. During evaluation, we were
mostly interested in answering the following questions:
1) how effective is CaSym in identifying cache-based side
channels and how accurate are the results?
2) how efﬁcient is CaSym and whether it can generate
useful results within a reasonable amount of time?
3) how do different cache models compare when identi-
fying side channels?
4) how well does CaSym’s error localization perform?
5) whether CaSym can validate the result after applying
prefetching or pinning to ﬁx a side channel?
For benchmarks, we collected realistic crypto implemen-
tations from popular libraries, including Libgcrypt 1.8.1,
mbed TLS 2.6.0, and glibc 2.26. These benchmarks can be
(cid:22)(cid:18)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:41:15 UTC from IEEE Xplore.  Restrictions apply. 
Access
(cid:3)(cid:4)
(cid:2)
(cid:5)
(cid:2)
Trace
(cid:3)(cid:4)
(cid:5)
Access
(cid:3)(cid:4)
(cid:2)
(cid:5)
(cid:2)
Trace
(cid:3)(cid:4)
(cid:5)
Benchmarks
Inﬁnite Age
Inﬁnite
Age
0.20
0.25
0.61
0.30
0.14
0.06
0.12
0.08
8.9 64 0
5.9 17 0
62.5 128 0
27.0 48 0
0.92 2
0
0
0.24 0
0
18.9 4
0
8.2 4
84.8 3
0
LOC
TP FP t(s) TP FP t(s)
AES gcry
182
16.7
64 0
0.60
AES mbed
220
17.0
0.34
17 0
triple-DES gcry
127
189
28.70 128 0
triple-DES mbed
111
22.9
73.2
48 0
DES glibc
114
122.9 2
0
2.65
41 (cid:3) 0.01 (cid:3) 0.02
UFC glibc
1.27
0
0
sqr-alwys-mul gcry 131
184
0
3
0.66
130
sqr-mul gcry
125
0
4
0.44
LR-mod-expo gcry
208
2618
6.39
3
0
Table I: Evaluation results for access and trace-based at-
tackers for crypto benchmarks. For access-based results,
means a side channel identiﬁed and (cid:3)means no side channel
identiﬁed; it also reports the amount of time in seconds for
CaSym to perform side-channel checking. For trace-based
results, the TP column identiﬁes the number of true positives
found. Similarly FP is the number of false positives. The
third column for each models depicts the amount of time
(in seconds) for each test.
roughly divided into two categories: encryption using sym-
metric ciphers and modular exponentiation using asymmetric
ciphers. In order to evaluate CaSym on other less scrutinized
codebases, we also analyzed functions from the PostgreSQL
10.2, which is a popular database back end.
Symmetric cipher benchmarks: We include six bench-
marks: AES gcry, AES mbed (the 128-bit-key AES en-
cryption in Libgcrypt and mbed TLS respectively), triple-
DES gcry, triple-DES mbed (the triple-DES encryption in
Libgcrypt and mbed TLS respectively), DES glibc (the DES
encryption in the glibc library) and UFC glibc (the ultra fast
encryption algorithm in glibc).
Asymmetric cipher benchmarks: Given a base b, an
exponent e, and a modulus m, modular exponentiation com-
putes “be mod m”. The majority of asymmetric encryption
such as RSA and ElGamal performs modular exponentiation.
Computing modular exponentiation directly would be
rather costly in both time and space. Libgcrypt implemented
three versions of efﬁcient modular exponentiation, which
we call sqr-alwys-mul gcry, sqr-mul gcry, and LR-mod-
expo gcry. The ﬁrst two versions implement the square-and-
multiply method; the main difference between the two is
that the square and multiply algorithm only performs the
multiplication when the bit being processed is set, while
the square-and-always-multiply algorithm performs the mul-
tiplication regardless of whether the current bit is set. The
ﬁnal version implements the left-to-right k-ary method [49].
Following previous analysis on crypto implementations [13],
we did not analyze the code of library implementing multi-
precision integers (MPI).
Database benchmarks: The crypto benchmarks are typ-
ically well scrutinized for side channels. To see how CaSym
(cid:22)(cid:18)(cid:23)
Benchmarks
Inﬁnite Age
Inﬁnite
Age
LOC
advance array keys
99
0.26
126 (cid:3) 0.06
binsrch
compare
174
1.24
ﬁnd xtreme element 117 (cid:3) 0.38
heap key test
0.07
is equal
0.12
mark array keys
sort array elements
start array keys
Table II: Evaluation results for access and trace based
attackers for the PostgreSQL database.
TP FP t(s) TP FP
0
5
0
0
0
7
0
0
3
0
0
1
0
0
1
2
2
0
253
115
5.84
2.52
3.47
118
89
3.80
34 (cid:3) 0.01 (cid:3) 0.13
5.44
144
42
2.43
0 1.33 5
0 0.46 1
0 0.31 8
0 0.62 1
0 0.33 3
0 1.68 1
0 0.08 0
1 4.17 4