## üêõ Bug
I believe the vector strides are being incorrectly passed to the `gemv` function on the GPU. This issue does not occur on the CPU.

## Steps to Reproduce
```python
import torch

# Define a 2x2 matrix and a 2-element vector, both on the GPU
mat = torch.randn(2, 2).cuda()
vec = torch.randn(2).cuda().requires_grad_(True)

# Perform a matrix-vector multiplication and sum the result
result = (mat @ vec).sum()

# Compute the gradient of the result with respect to the vector
result.backward()
```

### Error Message
```
RuntimeError: at::cuda::blas::gemv argument incx must be positive and less than 2147483647 but got 0
```

### Additional Context
I initially discovered this bug while investigating an issue in the DGER operation during the gradient computation of `mat @ vec` in the generated function `MvBackward::apply` in `torch/csrc/autograd/generated/Functions.cpp`. The error message is the same as the one reported in [cornellius-gp/gpytorch#834](https://github.com/cornellius-gp/gpytorch/issues/834). However, while trying to create a minimal example to reproduce that issue, I encountered this different bug instead.

## Expected Behavior
The gradient for `vec` should be computed without any errors, and the program should not crash.

## Environment
This bug has been reproduced in the `master` branch and PyTorch 1.4.0.

### Master Branch
- **PyTorch Version:** 1.6.0a0+cf82011
- **Debug Build:** No
- **CUDA Version Used to Build PyTorch:** 10.0
- **OS:** Ubuntu 16.04.6 LTS
- **GCC Version:** 7.1.0
- **CMake Version:** 3.14.0
- **Python Version:** 3.7
- **CUDA Available:** Yes
- **CUDA Runtime Version:** 10.0.130
- **GPU Models and Configuration:**
  - GPU 0: GeForce GTX 1080
  - GPU 1: GeForce GT 710
- **NVIDIA Driver Version:** 418.87.01
- **cuDNN Version:** /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5
- **Relevant Libraries:**
  - [pip3] numpy==1.11.0
  - [conda] blas 1.0 mkl
  - [conda] gpytorch 1.0.1 dev_0
  - [conda] magma-cuda100 2.5.2 1 pytorch
  - [conda] mkl 2020.0 166
  - [conda] mkl-include 2020.1 217
  - [conda] mkl-service 2.3.0 py37he904b0f_0
  - [conda] mkl_fft 1.0.15 py37ha843d7b_0
  - [conda] mkl_random 1.1.0 py37hd6b4f25_0
  - [conda] numpy 1.18.1 py37h4f9e942_0
  - [conda] numpy-base 1.18.1 py37hde5b4d6_1
  - [conda] numpydoc 0.9.2 py_0
  - [conda] torch 1.6.0a0+cf82011 pypi_0 pypi
  - [conda] torchvision 0.6.0 pypi_0 pypi

### PyTorch 1.4.0
- **PyTorch Version:** 1.4.0
- **Debug Build:** No
- **CUDA Version Used to Build PyTorch:** 10.1
- **OS:** Ubuntu 16.04.6 LTS
- **GCC Version:** 7.1.0
- **CMake Version:** 3.16.0-rc3
- **Python Version:** 3.7
- **CUDA Available:** Yes
- **CUDA Runtime Version:** 10.1.243
- **GPU Models and Configuration:**
  - GPU 0: GeForce GTX 1080
  - GPU 1: GeForce GT 710
- **NVIDIA Driver Version:** 418.87.01
- **cuDNN Version:** /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5
- **Relevant Libraries:**
  - [pip3] gpytorch==1.0.1
  - [pip3] numpy==1.18.2
  - [pip3] torch==1.4.0
  - [pip3] torchvision==0.5.0
  - [conda] Could not collect

## Additional Context
I would have attempted to fix this myself, but the C++ call stack is too deep, and I get lost. Additionally, I am unsure about the origin of the `generated/` functions. Therefore, I am passing this issue to you and will use a workaround in the meantime.

## Workaround
To avoid this issue, you can use `vec.unsqueeze(-1)` to turn the vector into a matrix, perform the `gemm` operation, and then squeeze the result back to a vector.
```python
vec = vec.unsqueeze(-1)
result = (mat @ vec).squeeze().sum()
result.backward()
```

cc @ezyang @ssnl @albanD @zou3519 @gqchen