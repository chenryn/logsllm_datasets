## ðŸ› Bug
I think the vector strides are passed incorrectly to `gemv` on GPU. It works
well on CPU.
## To Reproduce
    import torch
    mat = torch.randn(2, 2).cuda()
    vec = torch.randn(2).cuda().requires_grad_(True)
    (mat @ vec).sum().backward()
Here I get:
> RuntimeError: at::cuda::blas::gemv argument incx must be positive and less
> than 2147483647 but got 0
Originally I found the bug as an issue during DGER in the gradient of `mat @
vec`, in the generated function `MvBackward::apply` in
`torch/csrc/autograd/generated/Functions.cpp`. The error message is the same
as cornellius-gp/gpytorch#834 . But, attempting to write minimal code to
reproduce that, I hit this other bug instead.
## Expected behavior
The gradient for `vec` should be calculated, and the program should not crash.
## Environment
I have reproduced this bug in `master`, and Pytorch 1.4.
Details of master version
> PyTorch version: 1.6.0a0+cf82011  
>  Is debug build: No  
>  CUDA used to build PyTorch: 10.0
>
> OS: Ubuntu 16.04.6 LTS  
>  GCC version: (Ubuntu 7.1.0-10ubuntu1~16.04.york0) 7.1.0  
>  CMake version: version 3.14.0
>
> Python version: 3.7  
>  Is CUDA available: Yes  
>  CUDA runtime version: 10.0.130  
>  GPU models and configuration:  
>  GPU 0: GeForce GTX 1080  
>  GPU 1: GeForce GT 710
>
> Nvidia driver version: 418.87.01  
>  cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5
>
> Versions of relevant libraries:  
>  [pip3] numpy==1.11.0  
>  [conda] blas 1.0 mkl  
>  [conda] gpytorch 1.0.1 dev_0  
>  [conda] magma-cuda100 2.5.2 1 pytorch  
>  [conda] mkl 2020.0 166  
>  [conda] mkl-include 2020.1 217  
>  [conda] mkl-service 2.3.0 py37he904b0f_0  
>  [conda] mkl_fft 1.0.15 py37ha843d7b_0  
>  [conda] mkl_random 1.1.0 py37hd6b4f25_0  
>  [conda] numpy 1.18.1 py37h4f9e942_0  
>  [conda] numpy-base 1.18.1 py37hde5b4d6_1  
>  [conda] numpydoc 0.9.2 py_0  
>  [conda] torch 1.6.0a0+cf82011 pypi_0 pypi  
>  [conda] torchvision 0.6.0 pypi_0 pypi
Details of 1.4.0 version
> PyTorch version: 1.4.0  
>  Is debug build: No  
>  CUDA used to build PyTorch: 10.1
>
> OS: Ubuntu 16.04.6 LTS  
>  GCC version: (Ubuntu 7.1.0-10ubuntu1~16.04.york0) 7.1.0  
>  CMake version: version 3.16.0-rc3
>
> Python version: 3.7  
>  Is CUDA available: Yes  
>  CUDA runtime version: 10.1.243  
>  GPU models and configuration:  
>  GPU 0: GeForce GTX 1080  
>  GPU 1: GeForce GT 710
>
> Nvidia driver version: 418.87.01  
>  cuDNN version: /usr/lib/x86_64-linux-gnu/libcudnn.so.7.6.5
>
> Versions of relevant libraries:  
>  [pip3] gpytorch==1.0.1  
>  [pip3] numpy==1.18.2  
>  [pip3] torch==1.4.0  
>  [pip3] torchvision==0.5.0  
>  [conda] Could not collect
## Additional context
I would fix this myself but the C++ call stack is too deep and I get lost. I
also don't know where the `generated/` functions come from. Thus I pass the
baton to you, and will use a workaround.
## Workaround
Use `vec.unsqueeze(-1)` to turn it into a `gemm`. Squeeze the result.
cc @ezyang @ssnl @albanD @zou3519 @gqchen