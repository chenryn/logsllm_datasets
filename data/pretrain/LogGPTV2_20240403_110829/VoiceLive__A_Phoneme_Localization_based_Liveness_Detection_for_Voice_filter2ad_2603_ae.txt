both horizontal and vertical placements.
5. DISCUSSION AND FUTURE WORK
Achievable TDoA Range. The achievable TDoA range
is determined by the distance between two microphones and
is aﬀected by the relative position between the phone and
user’s mouth. Figure 27 shows the achievable TDoA range
with Samsung Galaxy Note3 by using the sound origin model
we built in Figure 5. The distance between two microphones
is 15.1cm. Figure 27 plots the sectional view on Y-Z plane
and the coordinate (0,0) is the location of the mouth. Each
(y, z) point in vertical placement indicates the center of the
phone when place the phone vertically, whereas it represents
the bottom microphone of the phone when place phone hor-
izontally. The color at each position represents the achiev-
able TDoA range at that position. As we can see from Fig-
ure 28, the maximum achievable TDoA range is around 6cm
for vertical placement, whereas it is about 4cm for horizontal
placement if we place the phone very close to user’s mouth.
The reason we cannot achieve maximum TDoA range as the
distance between two microphones is that the origin of the
)
%
(
y
c
a
r
u
c
c
A
100
80
60
40
20
0
Correlation
Probability
Combined Method
Horizontal
Vertical
Figure 25: Accuracy of horizontal and vertical place-
ments.
)
%
(
R
E
E
4
3
2
1
0
Correlation
Probability
Combined Method
Horizontal
Vertical
Figure 26: EER of horizontal and vertical place-
ments.
phoneme sound is crowded in user’s mouth and nasal cavities
(i.e., all are at similar directions to the two microphones).
Such maximum achievable TDoA ranges (i.e., 6cm and 4cm)
could ideally distinguish 33 and 23 diﬀerent phoneme sounds
under 192kHz sampling rate, respectively. We also ﬁnd that
the achievable TDoA range decreases rapidly when increas-
ing the distance between the phone and the mouth. For
example, with the phone placed at 30cm away from user’s
mouth, the achievable TDoA range decreases to less than
1cm, which makes it hard to capture any TDoA dynamic
of a passphrase. This is why our system is robust to the
replace attack, where an adversary attempts to record the
TDoA dynamic under diﬀerent social distances.
Potential Active Attacks. In our experiments, we only
evaluate our system under the scenarios that an adversary
uses similar recording hardware as the one used by the le-
gitimate users. However, it is possible for an attacker to use
advanced hardware to record the voice samples and further
deduce the TDoA dynamic that can match the victim’s pro-
ﬁle. In particular, an attacker can leverage a microphone ar-
ray to locate each phoneme within the victim’s vocal system.
As the maximum achievable TDoA range decreases rapidly
with the increased distance between the recorder and the
user’s mouth, it requires the microphone array to support
an ultra-high sampling rate so as to have suﬃcient ranging
resolution to uniquely locate each phoneme. For example,
with the microphone array placed 30cm away from the user,
the maximum achievable TDoA range is less than 1cm. To
uniquely locate each phoneme, the ranging resolution should
be at least 0.2mm, which is ten times of that supported by
192kHz. Current professional digital recorders (e.g., Direct-
Stream Digital (DSD) recorders that worth thousands of
dollars and have the sizes similar to a desktop mainframe)
that support 2.8224MHz and 5.6448MHz sampling rates can
be leveraged to locate each phoneme without placing the
recorder very close to victim’s mouth.
After locating each phoneme, the attacker can deduce the
TDoA dynamic of the victim based on the relative position
between the phone and the victim’s mouth. This does re-
quire the attacker to observe how the phone is placed to
the victim’s mouth. Given the obtained TDoA dynamic,
108910
1
10
1
10
1
10
D
C
B
A
1
1
A
10 1
10 1
B
C
10 1
D
10
1
0.8
0.6
0.4
0.2
0
-0.2
-0.4
-0.6
-0.8
Figure 28: Similarity of TDoA dynamics between
diﬀerent users.
ual way of pronouncing. It also shows that it is promising
to use the TDoA dynamic or the location of phoneme as a
new biometric trait for user authentication. In our future
work, we will study the possibility of verifying or identify-
ing the speaker by making a model using the location of the
phoneme sound.
6. RELATED WORK
In recent years, more and more mobile devices and apps
are embracing voice biometric for mobile authentication.
However, voice authentication is subject to spooﬁng attacks,
as indicated in recent studies [16, 33, 14, 26]. Voice spoof-
ing attacks can be divided into four categories, which are
described below together with countermeasures.
Replay Attack. An adversary can spoof a voice authen-
tication system by using a pre-recorded voice sample of the
victim [24]. To defend against such attacks, Shang et al.
propose to compare a new access voice sample with stored
instances of past access attempts [31]. If this results in an
extremely high similarity score, a replay attack is identiﬁed.
As an alternative, Villalba et al. utilize the increased noise
and reverberation of replaying far-ﬁeld recordings for attack
detection [32], whereas Wang et al. use the additional chan-
nel noise of the recording and loudspeaker for attack detec-
tion [33]. However, the eﬀectiveness of these approaches is
very limited in practice (e.g., the FAR rate could be as high
as 17%.). Chetty and Wagner utilize video camera to detect
lip movements for liveness detection [13], whereas Poss et
al. aim to improve authentication accuracy by combining
the techniques of a neural tree network and Hidden Markov
Models [28]. Aley-Raz et al. develop a liveness detection
system, which requires a user to repeat one or more random
sentences prompted by the system for attack detection [10].
Impersonation Attack. It refers to attacks where an
adversary tries to mimic the victim’s voice without utilizing
any computer or professional devices. Recent work shows
that impersonation attack could be defended very eﬃciently
by using advanced speaker models, such as GMM-UBM [11]
and i-vector models [16]. Existing voice authentication sys-
tems with such advanced speaker models thus are resistant
to impersonation attacks.
Speech Synthesize Attack. This type of attack indi-
cates an attacker has the ability to synthesize the victim’s
voice by utilizing speech synthesize technologies. Earlier
work done by Lindberg and Blomberg [24] shows that the
FAR can be increased to as high as 38.9% with less sophisti-
cated speaker models. Recent work done by De Leon et al.
shows that by adopting both GMM-UBM and SVM tech-
(a) Vertical placement (b) Horizontal place-
ment
Figure 27: The achievable TDoA range under both
vertical and horizontal placements.
the attacker is further required to reproduce the voice sam-
ples that satisfy the TDoA constraints. It could be done by
creating a synthetic two-channel audio stream. With such
an audio stream, the attacker can either conduct a replace
attack or a playback attack to bypass the VoiceLive.
In our future work, we will study the feasibility of con-
ducting such active attacks. Particularly, we will evaluate
whether or not current acoustic localization systems could
achieve the level of localization accuracy required in the ac-
tive attacks. The potential countermeasure is to detect the
synthetic two-channel audio stream. VoiceLive could inte-
grate with existing speaker veriﬁcation techniques, such as
the higher order Mel-cepstral coeﬃcients [14, 12], which are
able to detect speech synthesize attacks. We will evaluate
the eﬀectiveness of detecting the synthetic two-channel au-
dio stream with these techniques in our future work.
Extension to Text-Independent System. As a text-
independent system operates on arbitrary utterances, we
cannot rely on the TDoA dynamic of a passphrase for live-
ness detection. However, a text-independent system requires
collecting a large number of utterances from the user to train
its speaker models. We therefore can extract the TDoA
value of each phoneme sound to build a model similar to
that of the Figure 5 by re-using the training data when the
system trains the speaker models. During the online authen-
tication phase, we extract the TDoA value of each phoneme
from the incoming utterances and then could build another
model. Such a model (could be a sub-model of the trained
model) can then be matched with the one trained during
the training phase. It is thus still possible to use the loca-
tion of each phoneme sound for liveness detection in text-
independent systems.
Diversity in Human Vocal System. An individual’s
vocal system diﬀers in the shape and size of the larynx,
nasal passages and vocal tract.
In addition, diﬀerent in-
dividuals have their own habitual ways of pronouncing the
same word, which results in diﬀerent cadences, accents and
pronunciations. We thus investigate how similar are the ex-
tracted TDoA dynamics for diﬀerent users with the same
passphrase. Figure 28 depicts the similarity of the extracted
TDoA dynamics for the same passphrase between four users:
A, B, C, and D. Each user speaks the same passphrase 10
times, and we measure the similarity within each user and
between users using Pearson correlation coeﬃcients. We ob-
serve that the correlation coeﬃcients for the same user under
diﬀerent trials are very high, at around 0.9, whereas they are
generally below 0.6 between diﬀerent users. This indicates
that the diversity in TDoA dynamic does exist, which is
similar to that of individual vocal system and user’s habit-
1090nologies, voice authentication systems are able to lower the
FAR of the system to 2.5% [14]. Also, Chen et al. [12] show
that by employing higher order Mel-cepstral coeﬃcients, the
EER can be lowered to 1.58%.
Voice Conversion Attack.
It aims at manipulating
or converting existing voice samples from other users so
that they would resemble the target’s voice.
In the early
work, researchers demonstrate such attacks can signiﬁcantly
aﬀect the authentication system [19]. Recent studies by
Mukhopadhyay et al.
show that current speaker veriﬁca-
tion systems based on UBM-GMM and ISV speaker models
are vulnerable to voice conversion attacks [26]. To defend
against voice conversion attacks, Wu et al. [34] developed
an authentication system with PLDA component that could
achieve 1.71% FAR, whereas Alegre et al. utilize PLDA and
FA technologies, which result in the FAR rate of 1.6% [9].
7. CONCLUSION
In this work, we developed a liveness detection system
for voice authentication that requires only stereo recording
on smartphones. Our system VoiceLive is practical as no
additional hardware is required during the authentication
process. VoiceLive performs liveness detection by measur-
ing TDoA changes of a sequence of phoneme sounds from
the two microphones of a smartphone. It distinguishes a live
user from a replay attack by comparing the TDoA changes
of the input utterance to the one stored in the system. Our
experimental evaluation demonstrates the viability of dis-
tinguishing between a live user and a replay attack under
various experimental settings. Our experimental results also
show the generality of our system, as we experiment with dif-
ferent phone types, placements and sampling rates. Overall,
VoiceLive can achieve over 99% accuracy, with an EER as
low as 1%.
8. ACKNOWLEDGEMENTS
We thank our shepherd, Dr. Nitesh Saxena, and the
anonymous reviewers for their insightful feedbacks. This
work was partially supported by the National Science Foun-
dation Grants CNS-1514436, SES-1450091, CNS-1505175,
CNS-1652447 and CNS-1514238.
9. REFERENCES
[1] Android voice recognition. http:
//www.popsci.com/new-android-can-recognize-your-voice.
[2] Google smart lock. https://get.google.com/smartlock/.
[3] Hsbc oﬀers voice biometric.
http://www.bbc.com/news/business-35609833.
[4] Mobile voice biometric security. http://voicevault.com/
hsbc-embraces-mobile-voice-biometric-security-technology/.
[5] Saypay technologies. http://saypaytechnologies.com/.
[6] Vocalpassword.
http://www.nuance.com/ucmprod/groups/enterprise/
@web-enus/documents/collateral/nc 015226.pdf.
[7] Voicekey mobile applications. http://speechpro-usa.com/
product/voice authentication/voicekey#tab2.
[8] Wechat voiceprint. http://blog.wechat.com/2015/05/21/
voiceprint-the-new-wechat-password/.
[9] F. Alegre, A. Amehraye, and N. Evans. A one-class
classiﬁcation approach to generalised speaker veriﬁcation
spooﬁng countermeasures using local binary patterns. In
IEEE BTAS, 2013.
[10] A. Aley-Raz, N. M. Krause, M. I. Salmon, and R. Y. Gazit.
Device, system, and method of liveness detection utilizing
voice biometrics, May 14 2013. US Patent 8,442,824.
[11] T. B. Amin, J. S. German, and P. Marziliano. Detecting
voice disguise from speech variability: Analysis of three
glottal and vocal tract measures. The Journal of the
Acoustical Society of America, 2013.
[12] L.-W. Chen, W. Guo, and L.-R. Dai. Speaker veriﬁcation
against synthetic speech. In 2010 IEEE Chinese Spoken
Language Processing (ISCSLP), 2010.
[13] G. Chetty and M. Wagner. Automated lip feature
extraction for liveness veriﬁcation in audio-video
authentication. Proc. Image and Vision Computing, 2004.
[14] P. L. De Leon, M. Pucher, J. Yamagishi, I. Hernaez, and
I. Saratxaga. Evaluation of speaker veriﬁcation security and
detection of hmm-based synthetic speech. IEEE Processing
of Audio, Speech, and Language, 2012.
[15] E. Hall. Handbook for proxemic research. Anthropology
News, 1995.
[16] R. G. Hautam¨aki, T. Kinnunen, V. Hautam¨aki, T. Leino,
and A.-M. Laukkanen. I-vectors meet imitators: on
vulnerability of speaker veriﬁcation systems against voice
mimicry. In INTERSPEECH, 2013.
[17] A. Jain, R. Bolle, and S. Pankanti. Biometrics: personal
identiﬁcation in networked society. Springer Science &
Business Media, 2006.
[18] T. Kevenaar. Protection of biometric information. In
Security with Noisy Data. 2007.
[19] T. Kinnunen et al. Vulnerability of speaker veriﬁcation
systems against voice conversion spooﬁng attacks: The case
of telephone speech. In IEEE ICASSP, 2012.
[20] A. Kipp, M.-B. Wesenick, and F. Schiel. Automatic
detection and segmentation of pronunciation variants in
german speech corpora. In IEEE ICSLP, 1996.
[21] T. Kisler, F. Schiel, and H. Sloetjes. Signal processing via
web services: the use case webmaus. In Digital Humanities
Conference, 2012.
[22] C. H. Knapp and G. C. Carter. The generalized correlation
method for estimation of time delay. IEEE Processing of
Acoustics, Speech and Signal, 1976.
[23] P. Ladefoged. A course in phonetics. Hardcourt Brace
Jovanovich Inc. NY, 2014.
[24] J. Lindberg, M. Blomberg, et al. Vulnerability in speaker
veriﬁcation-a study of technical impostor techniques. In
Eurospeech, 1999.
[25] J. Liu, Y. Wang, G. Kar, Y. Chen, J. Yang, and
M. Gruteser. Snooping keystrokes with mm-level audio
ranging on a single phone. In ACM MobiCom, 2015.
[26] D. Mukhopadhyay, M. Shirvanian, and N. Saxena. All your
voices are belong to us: Stealing voices to fool humans and
machines. In European Symposium on Research in
Computer Security, 2015.
[27] J. P. Olive, A. Greenwood, and J. Coleman. Acoustics of
American English speech: a dynamic approach. Springer
Science & Business Media, 1993.
[28] J. C. Poss, D. Boye, and M. W. Mobley. Biometric voice
authentication, June 10 2008. US Patent 7,386,448.
[29] M. K. Ravishankar. Eﬃcient algorithms for speech
recognition. Technical report, DTIC Document, 1996.
[30] M. A. Redford. The handbook of speech production. John
Wiley & Sons, 2015.
[31] W. Shang and M. Stevenson. Score normalization in
playback attack detection. In IEEE ICASSP, 2010.
[32] J. Villalba and E. Lleida. Detecting replay attacks from
far-ﬁeld recordings on speaker veriﬁcation systems. In
Biometrics and ID Management. 2011.
[33] Z.-F. Wang, G. Wei, and Q.-H. He. Channel pattern noise
based playback attack detection algorithm for speaker
recognition. In IEEE ICMLC, 2011.
[34] Z. Wu, T. Kinnunen, E. Chng, and H. Li. A study on
spooﬁng attack in state-of-the-art speaker veriﬁcation: the
telephone speech case. In IEEE APSIPA ASC, 2012.
[35] J. Yang, Y. Chen, and W. Trappe. Detecting spooﬁng
attacks in mobile wireless environments. In SECON, 2009.
1091