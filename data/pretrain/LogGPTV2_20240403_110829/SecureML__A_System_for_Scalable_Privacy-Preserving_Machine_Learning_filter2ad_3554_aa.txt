title:SecureML: A System for Scalable Privacy-Preserving Machine Learning
author:Payman Mohassel and
Yupeng Zhang
2017 IEEE Symposium on Security and Privacy
SecureML: A System for Scalable
Privacy-Preserving Machine Learning
Payman Mohassel∗ and Yupeng Zhang†
∗Visa Research,
†University of Maryland
Abstract—Machine learning is widely used in practice to pro-
duce predictive models for applications such as image processing,
speech and text recognition. These models are more accurate
when trained on large amount of data collected from different
sources. However, the massive data collection raises privacy
concerns.
In this paper, we present new and efﬁcient protocols for
privacy preserving machine learning for linear regression, logistic
regression and neural network training using the stochastic
gradient descent method. Our protocols fall in the two-server
model where data owners distribute their private data among
two non-colluding servers who train various models on the joint
data using secure two-party computation (2PC). We develop new
techniques to support secure arithmetic operations on shared
decimal numbers, and propose MPC-friendly alternatives to non-
linear functions such as sigmoid and softmax that are superior
to prior work.
We implement our system in C++. Our experiments validate
that our protocols are several orders of magnitude faster than
the state of the art implementations for privacy preserving linear
and logistic regressions, and scale to millions of data samples
with thousands of features. We also implement the ﬁrst privacy
preserving system for training neural networks.
I. INTRODUCTION
Machine learning techniques are widely used in practice
to produce predictive models for use in medicine, banking,
recommendation services, threat analysis, and authentication
technologies. Large amount of data collected over time have
enabled new solutions to old problems, and advances in deep
learning have led to breakthroughs in speech, image and text
recognition.
Large internet companies collect users’ online activities to
train recommender systems that predict their future interest.
Health data from different hospitals, and government organi-
zation can be used to produce new diagnostic models, while
ﬁnancial companies and payment networks can combine trans-
action history, merchant data, and account holder information
to train more accurate fraud-detection engines.
While the recent technological advances enable more efﬁ-
cient storage, processing and computation on big data, combin-
ing data from different sources remains an important challenge.
Competitive advantage, privacy concerns and regulations, and
issues surrounding data sovereignty and jurisdiction prevent
many organizations from openly sharing their data. Privacy-
preserving machine learning via secure multiparty computation
(MPC) provides a promising solution by allowing different
†This work was partially done when the author was interning at Visa
Research.
© 2017, Payman Mohassel. Under license to IEEE.
DOI 10.1109/SP.2017.12
19
entities to train various models on their joint data without
revealing any information beyond the outcome.1
We focus on machine learning algorithms for training
linear regression,
logistic regression and neural networks
models, and adopt the two-server model (see section III for
more details), commonly used by previous work on privacy-
preserving machine learning via MPC [37], [36], [21]. In this
model, in a setup phase, the data owners (clients) process,
encrypt and/or secret-share their data among two non-colluding
servers. In the computation phase, the two servers can train
various models on the clients’ joint data without learning any
information beyond the trained model.
The state of the art solutions for privacy preserving linear
regression [37], [21] are many orders of magnitude slower
than plaintext training. The main source of inefﬁciency in prior
implementations is that the bulk of computation for training
takes place inside a secure 2PC for boolean circuits (e.g Yao’s
garbled circuit) that performs arithmetic operation on decimal
numbers represented as integers. It is well-known that boolean
circuits are not suitable for performing arithmetic operations,
but they seem unavoidable given that existing techniques for
ﬁxed-point or ﬂoating-point multiplication require bit-level
manipulations that are most efﬁcient using boolean circuits.
In case of logistic regression and neural networks, the
problem is even more challenging as the training procedure
computes many instances of non-linear activation functions
such as sigmoid and softmax that are expensive to compute
inside a 2PC. Indeed, we are not aware of any privacy
preserving implementations for these two training algorithms.
A. Our Contributions
We design new and efﬁcient protocols for privacy preserving
linear regression,
logistic regression and neural networks
training in the two-server model discussed above assuming an
arbitrary partitioning of the dataset across the clients.
Our privacy preserving linear regression protocol is several
orders of magnitude more efﬁcient than the state of the art
solutions for the same problem. For example, for a dataset
with 100, 000 samples and 500 features and in a comparable
setup and experimental environment, our protocol is 1100-
1300× faster than the protocols implemented in [37], [21].
Moreover, as our experiments show, we signiﬁcantly reduce
the gap between privacy-preserving and plaintext training.
1In the more general variant of our protocols, even the model can remain
private (secret shared).
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:22:48 UTC from IEEE Xplore.  Restrictions apply. 
We also implement the ﬁrst privacy preserving protocols
for logistic regression and neural networks training with high
efﬁciency. For example, on a dataset of size 60,000 with 784
features, our privacy preserving logistic regression has a total
running time of 29s while our privacy-preserving protocol for
training a neural network with 3 layers and 266 neurons runs
in 21,000s.
Our protocols are naturally divided into a data-independent
ofﬂine phase and a much faster online phase. When excluding
the ofﬂine phase, the protocols are even more competitive
with plaintext training. For instance, for a dataset with 60,000
samples and 784 features, and in the LAN setting, the linear
regression protocol runs in 1.4s, the logistic regression in 8.9s,
and the neural network training in 653.0s.
Arithmetic on shared decimal numbers. As mentioned
earlier, a major bottleneck in prior work is the computation
of ﬁxed-point arithmetic inside a secure 2PC such as garbled
circuits. This is prohibitively expensive, given the large number
of multiplications needed for training.
Fixed-point addition is fairly straightforward. For multipli-
cation, we show that the following strategy is very effective:
represent the two shared decimal numbers as shared integers
in a ﬁnite ﬁeld; perform a multiplication on shared integers
using ofﬂine-generated multiplication triplets; have each party
truncate its share of the product so that a ﬁxed number
of bits represent the fractional part. We prove that, with
high probability, the product when reconstructed from these
truncated shares, is at most 1 bit off in the least signiﬁcant
position of the fractional part compared to ﬁxed-point arith-
metic. Our experiments on two different datasets, MNIST and
Arcene [6], [1], conﬁrm that the small truncation error has
no effect on accuracy of the trained model (in fact accuracies
match those of standard training) when the number of bits
representing the fractional part is sufﬁciently large. As a result,
the online phase for privacy preserving linear regression does
not involve any cryptographic operations and only consists of
integer multiplications and bit shifting, while the ofﬂine phase
consists of generating the necessary multiplication triplets. Our
microbenchmarking shows that even when considering total
time (online and ofﬂine combined) our approach yields a factor
of 4-8× improvement compared to ﬁxed-point multiplication
using garbled circuits.
MPC-friendly activation functions. As discussed earlier, lo-
gistic regression and neural network training require computing
the logistic (
e−xi ) functions which
are expensive to compute on shared values. We experimentally
show that the use of low-degree polynomials to approximate
the logistic function is ineffective. In particular, one needs
polynomials of degree at least 10 to approach the accuracy of
training using the logistic function. We propose a new activation
function that can be seen as the sum of two RELU functions
(see Figure 5), and computed efﬁciently using a small garbled
circuit. Similarly, we replace the softmax function with a
combination of RELU functions, additions and a single division.
Our experiments using the MNIST, and Arcene datasets conﬁrm
that accuracy of the models produced using these new functions
either match or are very close to those trained using the original
functions.
1+e−x ), and the softmax ( e−xi(cid:2)
1
We then propose a customized solution for switching between
arithmetic sharing and Yao sharing, and back, for our particular
computation, that signiﬁcantly reduces the cost by minimizing
rounds of interaction and number of invoked oblivious transfers
(OT). Our microbenchmarking in Section G shows that the time
to evaluate our new function is much faster than to approximate
the logistic function with a high degree polynomial.
We use the same ideas to securely evaluate the RELU
functions used in neural networks training.
Vectorizing the protocols. Vectorization, i.e. operating on
matrices and vectors, is critical in efﬁciency of plaintext training.
We show how to beneﬁt from the same vectorization techniques
in the shared setting. For instance, in the ofﬂine phase of our
protocols which consists of generating many multiplication
triplets, we propose and implement two solutions based on
linearly homomorphic encryption (LHE) and oblivious transfer.
The techniques are inspired by prior work (e.g., [18]) but
are optimized for our vectorized scenario where we need to
compute multiplication of shared matrices and vectors. As a
result the complexity of our ofﬂine protocols is much better than
the naive approach of generating independent multiplication
triplets for each multiplication. In particular, the performance
of the OT-based multiplication triplets generation is improved
by a factor of 4×, and the LHE-based generation is improved
by 41-66×.
In a different security model similar to [21], we also
propose a much faster ofﬂine phase where clients help generate
the multiplication triplets. This provides a weaker security
gauarantee than our standard setting. In particular, it requires
the additional assumption that servers and clients do not collude,
i.e. an attacker either corrupts a server or a subset of clients but
not both. We discuss pros/cons of this approach and compare
its performance with the standard approach in Section V and
Appendix F.
B. Related Work
Earlier work on privacy preserving machine learning has
focused on decision trees [31], k-means clustering [28], [14],
SVM classiﬁcation [48], [44], linear regression [19], [20], [40]
and logistic regression [42]. These papers propose solutions
based on secure multiparty computation, but appear to incur
high efﬁciency overheads and lack implementation/evaluation.
Nikolaenko et. al. [37] present a privacy preserving linear
regression protocol on horizontally partitioned data using a
combination of LHE and garbled circuits, and evaluate it on
datasets with millions of samples. Gascon et. al. [21] extend
the results to vertically partitioned data and show improved
performance. However, both papers reduce the problem to
solving a linear system using Yao’s garbled circuit protocol,
which introduces a high overhead on the training time and
cannot be generalized to non-linear models. In contrast, we
use the stochastic gradient descent method which enables
training non-linear models such as logistic regression and
neural networks. Recently, Gilad-Bachrach et. al. [23] propose
a framework for secure data exchange, and support privacy
preserving linear regression as an application. However, only
small datasets are tested and the protocol is implemented purely
using garbled circuit, which does not scale for larger datasets.
20
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:22:48 UTC from IEEE Xplore.  Restrictions apply. 
Privacy preserving logistic regression is considered by Wu
et. al. [46]. They propose to approximate the logistic function
using polynomials, and train the model using LHE. However,
the complexity is exponential in the degree of the approximation
polynomial, and as we will show in experiments, the accuracy
of the model is degraded compared to using the logistic function.
Aono et. al. [10] consider a different security model where an
untrusted server collects and combines the encrypted data from
multiple clients, and transfers it to a trusted client to train the
model on the plaintext. By carefully approximating the cost
function of logistic regression with a degree 2 polynomial, the
optimal model can be calculated by solving a linear system.
However, in this setting, the plaintext of the aggregated data is
leaked to the client who trains the model. We are not aware of
any prior work with a practical system for privacy preserving
logistic regression in the two-server model.
Privacy preserving machine learning with neural networks
is more challenging. Shokri and Shmatikov [41] propose a
solution where instead of sharing the data, the two servers
share the changes on a portion of the coefﬁcients during the
training. Although the system is very efﬁcient (no cryptographic
operation is needed at all), the leakage of these coefﬁcient
changes is not well-understood and no formal security guaran-
tees are obtained. In addition, their approach only works for
horizentally partitioned data since each server needs to be able
to perform the training individually on its portion in order to
obtain the coefﬁcient changes. Privacy preserving predictions
using neural networks were also studied recently by Gilad-
Bachrach et. al. [22]. Using fully homomorphic encryption, the
neural network model can make predictions on encrypted data.
In this case, it is assumed that the neural network is trained
on plaintext data and the model is known to one party who
evaluates it on private data of another.
An orthogonal line of work considers the differential privacy
of machine learning algorithms [16], [43], [9]. In this setting,
the server has full access to the data in plaintext, but wants
to guarantee that the released model cannot be used to infer
the data used during the training. A common technique used
in differentially private machine learning is to introduce an
additive noise to the data or the update function (e.g., [9]).
The parameters of the noise are usually predetermined by
the dimensions of the data, the parameters of the machine
learning algorithm and the security requirement, and hence
are data-independent. Our system can be composed with such
constructions given that the servers can always generate the
noise according to the public parameters and add it directly
onto the shared values in the training. In this way, the trained
model will be differentially private once reconstructed, while
all the data still remains private during the training.
II. PRELIMINARIES
A. Machine Learning
In this section, we brieﬂy review the machine learning
algorithms considered in this paper: linear regression, logistic
regression and neural networks. All algorithms we present
are classic and can be found in standard machine learning
textbooks (e.g., [26]).
a) Linear regression: Given n training data samples xi
each containing d features and the corresponding output labels
yi, regression is a statistical process to learn a function g
such that g(xi) ≈ yi. Regression has many applications in real
life. For example, in medical science, it is used to learn the
relationship between a disease and representative features, such
as age, weight, diet habits and use it for diagnosing purposes.
In linear regression, the function g is assumed to be linear
(cid:2)d
and can be represented as the inner product of xi with the
j=1 xijwj = xi · w, where xij
coefﬁcient vector w: g(xi) =
(resp. wj) is the jth value in vector xi (resp. w), and · denotes
the inner product of two vectors.2
To learn the coefﬁcient vector w, a cost function C(w) is
deﬁned and w is calculated by the optimization argminw C(w).
(cid:2)
In linear regression, a commonly used cost function is C(w) =
1
n
2 (xi · w − yi)2. 3