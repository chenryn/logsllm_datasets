ﬂushed, and any outstanding micro-op results are discarded
from the reorder buffer. This rollback ensures that the results of
unintended transient instructions, which were wrongly executed
ahead of time, are never visible at the architectural level.
Address translation: Modern CPUs use virtual addresses
to isolate concurrently running tasks. A multi-level page-table
hierarchy is set up by the operating system (OS) or hypervisor
to translate virtual to physical addresses. The lower 12 address
bits are the index into a 4 KB page, while higher address
bits index a series of page-table entries (PTEs) that ultimately
yield the corresponding physical page number (PPN). Figure 1
overviews the layout of an Intel x86 PTE [13, 32]. Apart from
the physical page number, PTEs also specify permission bits to
indicate whether the page is present, accessible to user space,
writable, or executable.
The translation lookaside buffer (TLB) caches recent address
translations. Upon a TLB miss, the CPU’s page-miss handler
performs a page-table walk and updates the TLB. The CPU’s
TLB miss handler circuitry is optimized for the fast path, and
delegates more complex operations, e.g., setting of “accessed”
and “dirty” PTE bits, using microcode assists [17]. Depending
on the permission bits, a page fault (#PF) may be raised to
abort the memory operation and redirect control to the OS.
CPU Integer
Registers
(180)
FPU Vector
Registers
(168)
Fig. 2. Overview of the memory hierarchy in modern x86 microarchitectures.
Memory hierarchy: Superscalar CPUs consist of multiple
physical cores connected through a bus interconnect to the
memory controller. As the main memory is relatively slow,
the CPU uses a complex memory subsystem (cf. Figure 2),
including various caches and buffers. On Intel CPUs, the L1
cache is the fastest and smallest, closest to the CPU, and split
into a separate unit for data (L1D) and instructions (L1I). L1D
is usually a 32 KB 8-way set-associative cache. It is virtually-
indexed and physically-tagged, such that lookups can proceed
in parallel to address translation. A cache line is 64 bytes, which
also deﬁnes the granularity of memory transactions (load and
store) through the cache hierarchy. To handle various sized
memory operations, L1D is connected to a memory-order buffer
(MOB), which is interfaced with the CPU’s register ﬁles and
execution units through dedicated load ports (LPs).
The MOB includes a store buffer (SB) and load buffer (LB),
plus various dependency prediction and resolution circuits to
safeguard correct ordering of memory operations. The SB keeps
track of outstanding store data and addresses to commit stores
in order, without stalling the pipeline. When a load entry in LB
is predicted to not depend on any prior store, it is executed out
of order. If a store-to-load (STL) dependency is detected, the
SB forwards the stored data to the dependent load. However, if
the dependency of a load and preceding stores is not predicted
correctly, these optimizations may lead to situations where
the load consumes either stale data from the cache or wrong
data from the SB while the CPU reissues the load to obtain
the correct data. These optimizations within the MOB can
undermine security [9, 23, 35].
Upon on L1D cache miss, data is fetched from higher levels
in the memory hierarchy via the line-ﬁll buffer (LFB), which
keeps track of outstanding load and store requests without
blocking the L1D cache. The LFB retrieves data from the
next cache levels or main memory and afterward updates the
corresponding cache line in L1D. An “LFB hit” occurs if the
CPU has a cache miss for data in a cache line that is in the
LFB. Furthermore, uncacheable memory and non-temporal
stores bypass the cache hierarchy using the LFB.
B. Intel SGX
Intel Software Guard Extensions (SGX) [13] provides
processor-level isolation and attestation for secure “enclaves”
in the presence of an untrusted OS. Enclaves are contained in
the virtual address space of a conventional user-space process,
and virtual-to-physical address mappings are left under explicit
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
56
control of untrusted system software. To protect against active
address remapping attackers [13], SGX maintains a shadow
entry for every valid enclave page in the enclave page-cache
map (EPCM) containing amongst others the expected virtual
address. Valid address mappings are cached in the TLB, which
is ﬂushed upon enclave entry, and a special EPCM page fault
is generated when encountering an illegal virtual-to-physical
mapping (cf. Appendix A).
However, previous work showed that Intel SGX root attackers
can mount high-resolution, low-noise side-channel attacks
through the cache [7, 46, 52], branch predictors [15, 24, 40],
page-table accesses [63, 65, 71], or interrupt timing [64]. In
response to recent transient-execution attacks [11, 53, 61, 67],
which can extract enclave secrets from side-channel resistant
software, Intel released microcode updates which ﬂush microar-
chitectural buffers on every enclave entry and exit [25, 29].
C. Transient-Execution Attacks
Modern processors safeguard architectural consistency by
discarding the results of any outstanding transient instructions
when ﬂushing the pipeline. However, recent research on
transient-execution attacks [38, 42, 61] revealed that these
unintended transient computations may leave secret-dependent
traces in the CPU’s microarchitectural state, which can be
subsequently recovered through side-channel analysis. Follow-
ing a recent classiﬁcation [10], we refer to attacks exploiting
misprediction [23, 37, 38, 39, 44] as Spectre-type, and attacks
exploiting transient execution after a fault or microcode
assist [9, 42, 53, 57, 61, 67] as Meltdown-type.
Meltdown-type attacks extract unauthorized program data
across architectural isolation boundaries. Over the past years,
faulting loads with different exception types and microcode
assists have been demonstrated to leak secrets from intermediate
microarchitectural buffers in the memory hierarchy: the L1 data
cache [42, 61, 70], the line-ﬁll buffer and load ports [53, 67],
the FPU register ﬁle [57], and the store buffer [9, 51].
A perpendicular line of Spectre-type attacks, on the other
hand, aims to steer transient execution in the victim domain
by poisoning various microarchitectural predictors. Spectre
attacks are limited by the depth of the transient-execution
window, which is ultimately bounded by the size of the reorder
buffer [68]. Most Spectre variants [38, 39, 44] hijack the
victim’s transient control ﬂow by mistraining shared branch
prediction history buffers prior to entering the victim domain.
Yet, not all Spectre attacks depend on branch history, e.g.,
in Spectre-STL [23] the processor’s memory disambiguation
predictor incorrectly speculates that a load does not depend on
a prior store, allowing the load to transiently execute with a
stale outdated value. Spectre-STL has for instance been abused
to hijack the victim’s transient control ﬂow in case the stale
value is a function pointer or indirect branch target controlled
by a previous attacker input [68].
III. LOAD VALUE INJECTION
Table I summarizes the existing transient-execution attack
landscape. The Spectre family of attacks (upper right) con-
m
a
r
g
o
r
P
A
S
I
h
c
r
A
-
μ
2
Faulting load &B
4
Fixup
load value injection
1
Fill &A
3
Transient gadget
array[B] or CALL *B
illegal microarchitectural serve
A
μ-Arch buffer
A
B
Mem
Fig. 3. Phases in a Load Value Injection (LVI) attack: (1) a microarchitectural
buffer is ﬁlled with value A; (2) the victim executes a faulting or assisted load
to retrieve value B which is incorrectly served from the microarchitectural
buffer; (3) the injected value A is forwarded to transient instructions following
the faulting or assisted load, which may now perform unintended operations
depending on the available gadgets; (4) the CPU ﬂushes the faulting or assisted
load together with all other transient instructions.
tributed an injection-based methodology to invert prior predic-
tion history side-channels (upper left) by abusing confused-
deputy code gadgets within the victim domain. At the same
time, Meltdown-type attacks (lower left) demonstrated cross-
domain data leakage. The LVI attack plane (lower right)
remains unexplored until now. In this paper, we adopt an
injection-based methodology known from Spectre attacks
to reversely exploit Meltdown-type microarchitectural data
leakage. LVI brings a signiﬁcant change in the threat model,
similar to switching from branch history side-channels to
Spectre-type attacks. Crucially, LVI has the potential to replace
the outcome of any victim load, including implicit load micro-
ops like in the x86 ret instruction, with attacker-controlled
data. This is in sharp contrast to Spectre-type attacks, which
can only replace the outcomes of branches and store-to-load
dependencies by poisoning execution metadata accumulated in
various microarchitectural predictors.
A. Attack Overview
We now outline how LVI can hijack the result of a trusted
memory load operation, under the assumption that attackers
can provoke page faults or microcode assists for (arbitrary)
load operations in the victim domain. The attacker’s goal is
to force a victim to transiently compute on unintended data,
other than the expected value in trusted memory. Injecting such
unexpected load values forces a victim to transiently execute
gadget code immediately following the faulting or assisted load
instruction with unintended operands.
Figure 3 overviews how LVI exploitation can be abstractly
broken down into four phases.
1) In the ﬁrst phase,
the microarchitecture is optionally
prepared in the desired state by ﬁlling a hidden buffer
with an (attacker-controlled) value A.
2) The victim then executes a load micro-op to fetch a trusted
value B. However, in case this instruction suffers a page
fault or microcode assist, the CPU may erroneously serve
the load request from the microarchitectural buffer. This
results in incorrect forwarding of value A to dependent
transient micro-ops following the faulting or assisted load.
At this point, the attacker has succeeded in tricking the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
57
victim into transiently computing on the injected value A
instead of the trusted value B.
3) These unintended transient computations may subsequently
expose victim secrets through microarchitectural state
changes. Depending on the speciﬁc “gadget” code sur-
rounding the original load operation, LVI may either encode
secrets directly or serve as a transient control or data ﬂow
redirection primitive to facilitate second-stage gadget abuse,
e.g., when B is a trusted code or data pointer.
4) The architectural results of gadget computations are even-
tually discarded at the retirement of the faulting or assisted
load instruction. However, secret-dependent traces may have
been left in the CPU’s microarchitectural state, which can
be subsequently recovered through side-channel analysis.
B. A Toy Example
Listing 1 provides a toy LVI gadget to illustrate how faulting
loads in a victim domain may trigger incorrect transient
forwarding. Our example gadget bears a high resemblance
to known Spectre gadgets but notably does not rely on branch
misprediction or memory disambiguation. Furthermore, our
gadget executes entirely within the victim domain and is hence
not affected by widely deployed microcode mitigations that
ﬂush microarchitectural buffers on context switch. Regardless
of the prevalence of this speciﬁc toy gadget, it serves as an
initial example which is easy to understand and illustrates the
power of LVI as a generic attack primitive.
Following the general outline of Figure 3, the gadget code
in Listing 1 ﬁrst copies a 64-bit value untrusted_arg
provided by the attacker into trusted memory (e.g., onto the
stack) at line 2. In the example, the argument copy is further
not used, and this store operation merely serves to bring some
attacker-controlled value into some microarchitectural buffer.
Subsequently, in the second phase of the attack, a pointer-
to-pointer trusted_ptr (e.g., a pointer in a dynamically
allocated struct) is dereferenced at line 3. We assume that, upon
the ﬁrst-level pointer dereference, the victim suffers a page fault
or microcode assist. The faulting load causes the processor to
incorrectly forward the attacker’s value untrusted_arg that
was previously brought into the store buffer by the completely
unrelated store at line 2, like in a Meltdown-type attack [9].
At this point, the attacker has succeeded in replacing the
architecturally intended value at address *trusted_ptr with
her own chosen value. In the third phase of the attack, the
gadget code transiently uses untrusted_arg as the base
address for a second-level pointer dereference and uses the
result as an index in a lookup table. Similar to a Spectre
gadget [38], the lookup in array serves as the sending end
of a cache-based side-channel, allowing to encode arbitrary
memory locations within the victim’s address space.
Figure 4 illustrates how in the ﬁnal phase of the attack,
after the fault has been handled and the load has been re-
issued allowing the victim to complete, adversaries can abuse
access timings to the probing array to reconstruct secrets
from the victim’s transient execution. Notably, the timing
diagram showcases two clear drops: one dip corresponds to
58
e
m
i
t
]
s
e
l
c
y
c
[
s
s
e
c
c
A
600
400
200
0
0
50
100
150
200
250
Page
Fig. 4. Access times to the probing array after the execution of Listing 1.
The dip at 68 (‘D’) is the transmission speciﬁed by the victim’s architectural
program semantics. The dip at 83 (‘S’) is the victim secret at the address
untrusted_arg injected by the attacker.
1 void call_victim(size_t untrusted_arg) {
2
3
4 }
*arg_copy = untrusted_arg;
array[**trusted_ptr * 4096];
Listing 1: An LVI toy gadget for leaking arbitrary data from a victim domain.
the architecturally intended value that was processed after the
faulting load got successfully re-issued, while the second dip
corresponds to the victim secret at the address chosen by the
attacker. This toy example hence serves as a clear illustration
of the danger of incorrect transient forwarding following a
faulting load in a victim domain. We elaborate further on
attacker assumptions and gadget requirements for different LVI
variants in Sections IV and VI respectively.
C. Difference with Spectre-type Attacks
While LVI adopts a gadget-based exploitation methodology
known from Spectre-type attacks, both attack families exploit
fundamentally different microarchitectural behaviors (i.e., incor-
rect transient forwarding vs. misprediction). We explain below
how LVI is different from and requires orthogonal mitigations
to known Spectre variants.
a) LVI vs. branch prediction: Most Spectre variants [10,
38, 39, 44] transiently hijack branch outcomes in a victim pro-
cess by poisoning various microarchitectural branch prediction
history buffers. On recent and updated systems, these buffers
are typically not simultaneously shared anymore and ﬂushed
on context switch. Furthermore, to foil mistraining strategies
within a victim domain, hardened compilers insert explicit
lfence barriers after potentially mispredicted branches.
In contrast, LVI allows to hijack the result of any victim load
micro-op, not just branch targets. By directly injecting incorrect
values from the memory hierarchy, LVI allows data-only attacks
as well as control-ﬂow redirection in the transient domain.
Essentially, LVI and Spectre exploit different subsequent phases
of the victim’s transient execution: while Spectre hijacks control
ﬂow before the architectural branch outcome is known, LVI-
based control-ﬂow redirection manifests only after the victim
attempts to fetch the branch-target address from application
memory. LVI does not rely on mistraining of any (branch)
predictor, and hence, applies even to CPUs without exploitable
prediction elements, and to systems protected with up-to-date
microcode and compiler mitigations.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:02:52 UTC from IEEE Xplore.  Restrictions apply. 
b) LVI vs. speculative store bypass: Spectre-STL [23]
exploits the memory disambiguation predictor, which may
speculatively issue a load even before all prior store addresses
are known. That is, in case a load is mispredicted to not depend
on a prior store, the store is incorrectly not forwarded and the
load transiently executes with a stale outdated value.
Crucially, while Spectre-STL is strictly limited to injecting
stale values for loads that closely follow a store to the exact
same address, LVI has the potential to replace the result of
any victim load with unrelated and possibly attacker-controlled
data. LVI therefore drastically widens the spectrum of incorrect
transient paths. As an example, the code in Listing 1 is
not in any way exposed to Spectre-STL since the store and
load operations are to different addresses, but this gadget
can still be exploited with LVI in case the load suffers a
page fault or microcode assist. Consequently, LVI is also not
affected by Spectre-STL mitigations, which disable the memory
disambiguation predictor in microcode or hardware.
c) LVI vs. value prediction: While value prediction has
already been proposed more than two decades ago [41, 69],
commercial CPUs do not implement it yet due to complexity
concerns [49]. As long as no commercial CPU supports value
speculation, Spectre-type value misprediction attacks are purely
theoretical. In LVI, there is no mistraining of any (value)
predictor, and hence, it applies to today’s CPUs already.
IV. ATTACKER MODEL AND ASSUMPTIONS
We focus on software adversaries who want to disclose
secrets from an isolated victim domain, e.g., the OS kernel,
another process, or an SGX enclave. For SGX, we assume
an attacker with root privileges, i.e., the OS is under control
of the attacker [13]. Successful LVI attacks require carefully
crafted adversarial conditions. In particular, we identify the
following three requirements for LVI exploitability:
a) Incorrect transient forwarding: As with any fault
injection attack, LVI requires some form of exploitable incorrect