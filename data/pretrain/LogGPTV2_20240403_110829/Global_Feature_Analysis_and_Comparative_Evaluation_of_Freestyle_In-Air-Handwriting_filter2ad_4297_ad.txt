Zero
EER
FAR
37.2
5.10
3.64
37.2
29.5
3.08
34.8
2.16
15.4
1.83
17.0
2.61
2.61
16.6
23.2
2.74
2.40
18.3
FAR
1K
27.6
19.9
13.3
15.2
7.4
10.9
10.7
10.6
8.91
without collision (in %)
Zero
FAR
FAR
1K
49.46
3.80
2.97
48.84
43.80
1.33
35.50
0.85
36.12
0.93
2.95
0.16
3.10
0.16
2.79
0.16
0.16
2.02
FAR
10K
10.52
7.30
5.26
2.86
2.06
0.39
0.39
0.42
0.39
Zero
FRR
98.18
50.97
8.56
11.23
16.21
6.57
4.25
0.50
2.29
EER
1.24
1.12
0.75
0.68
0.39
0.16
0.16
0.16
0.16
with collision (in %)
Zero
EER
FAR
38.9
5.04
4.17
38.9
19.6
2.95
23.6
2.39
30.9
1.98
6.2
1.51
1.51
5.6
12.2
1.86
1.38
5.1
FAR
1K
24.0
23.0
12.0
13.6
15.6
4.7
4.4
6.5
3.5
to interpret the numbers in Table 1 and Table 2 because they may
have some level of uncertainty due to the limited number of false
rejects in the experiments. Meanwhile, different signal preprocess-
ing implementations can also have small influences in these results.
Moreover, we intentionally allow each user to have two strings
in our datasets to reveal more “hard cases” for analysis since we
believe there are always users with similar writing styles. The goal
of this research is not trying to design an authentication algorithm
with the best performance, but discussing the feasibility and design
space of authentication algorithms as well as obtaining insights
through global feature analysis of the signals.
It is interesting to see that both the camera device and the
glove device share a lot in common in the characteristics of the
features and the authentication performances, even though these
476ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Duo Lu, Yuli Deng, and Dijiang Huang
Table 2: Comparison to existing works.
Ref.
Ours (camera)
Ours (glove)
Liu et al.[17]
Bailador et al.[2]
Bashir et al.[3]
Chan et al.[6]
Tian et al.[31]
number
of users
180
180
20 ∼ 25
96
40
16
18
EER
(w/o collision)
0.10% ∼ 1.24%
0.16% ∼ 1.24%
1.8% ∼ 2.1%
∼ 3%
∼1.8%
0.8%
∼2%
EER
(w/ collision)
1.83% ∼ 5.10%
1.38% ∼ 5.04%
∼10%
∼ 5%
N/A
N/A
N/A
Device
Algorithm
Leap Motion
custom data glove
SVM, TTV, DTW
SVM, TTV, DTW
Wii remote
smartphone
custom digital pen
Leap Motion
Kinect
DTW, Bayes, HMM
DTW
DTW
random forest
DTW
Figure 9: Matching score distribution of each account with the Feature Fusion method.
Figure 10: Examples of hard cases. The templates are in blue, and the testing signals are in orange.
two types of sensors use fundamentally different motion tracking
methods. Our signal model and preprocessing steps remove the
sensor-dependent information. As a result, we believe our feature
analysis and authentication framework can also apply to a broad
range of devices. Still, there are small differences between the re-
sults of different devices. For example, the signal quality is slightly
better with the glove device, and the user behavior is slightly more
consistent. This may be the result of the lack of field-of-view re-
striction with the glove device. Also, the glove device tracks the tip
of the index finger, which moves more significantly than the center
of the palm tracked by the camera device. The hand movement
is more stable if a user writes it more naturally with the “muscle
memory” rather than attention.
6.1 Analysis of Hard Cases
Besides collective performance results, in Figure 9, we also show
the ranges of distance scores δ of the signals in different classes
using the Feature Fusion method. On the top half of this figure, we
show the ranges of distance scores for signals with c = same and
signals with c = diff. Here, the two lines for “diff-min” and “diff-
avg” are the minimum and average of the distance scores for those
login request signals with class label c = diff for each account. The
colored area “diff-range” shows the range of these distance scores.
Similarly, “same-max” is the maximum of the distance scores for
those login request signals with class label c = same for each account,
and the range of these scores is shown by the colored area “same-
range”. The intersection between the “diff-range” and “same-range”
477Global Feature Analysis and Comparative Evaluation of Freestyle In-Air-Handwriting Passcode for User Authentication
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
is shown in darker colors and denoted as “overlap”. On the bottom
half of this figure, we show the ranges of distance scores for signals
with c = same and signals with c = collision in a similar way. The
accounts are sorted by the “same-max” to show a trend from the
“easy cases” on the left to the “hard cases” on the right.
There are a few testing signals with c = diff which have smaller
matching scores below a “reasonable threshold” (around 0.4, where
FAR is ≈ 0.001% and FRR is ≈ 1% without considering collision).
They are the first type of “hard cases,” which significantly influence
the security strength of the authentication system and further de-
termine the threshold that should be used in practice. Even if these
passcode strings are different in content, they may have similar
stroke patterns when writing in the air because of the transitioning
strokes. For example, there are two strings “feng” and “yang”, and
these signals are very similar because of the similarity in content
and writing style, as shown in Figure 10 (a). This pair of signals and
template has a matching distance score of 0.294. Another example
is shown in Figure 10 (b), where the two strings are “Kaicheng”
and “Kirkland”. This pair of signals and template has a matching
distance score of 0.373.
On the rightmost of the figure, there are signals with c = same
with large matching distance scores above the reasonable threshold.
They are the second type of hard cases which influence usability.
Two examples of the hard cases are shown here. For Figure 10
(c), the signal and the template are generated by the same user
writing the same passcode content “Victor”, but the user changes
the writing behavior, and the resulting δ is 0.524. For Figure 10
(d) the signal and the template are generated by the same user
writing the same passcode content “harrison67”, and the resulting δ
is 0.566. In this example, at the end of the signal, many meaningless
hand movements cause interference in the the alignment and the
hand pose normalization in the signal preprocessing step 2. As
a result, the scores of these hard cases are even larger than the
typical distance score between a template and a signal with c =
collision. Such a collision example is shown in Figure 10 (e), where
both the user and the imposter wrote “Simon” and the resulting
distance score δ is 0.555. On the contrary, in Figure 10 (f), we show
a template and a signal obtained by the same user writing “123456”,
and the distance score δ is only 0.187.
6.2 Spoofing Attack Analysis
We collected a dataset with active spoofing attacks with both leak-
age of passcode content and visual leakage of passcode writing
behavior. The dataset is similar the dataset 2, and we asked 10 im-
postors to write the passcode of 180 accounts created by 90 users
in the first dataset for five times. The impostors were informed of
the content of the passcode, and they were allowed to see a video
recording of the original account owner writing the passcode from
the frontal side with unlimited times at any speed. We also briefly
trained the imposters and paid them with more incentive money so
as to ask them to put more effort in imitating the in-air-handwriting
of the original users. There were 90 users in this spoofing attack
experiment because only these 90 users granted permissions to us
for recording the videos.
The results are shown in Table 3. Compared with the results
with collision in Table 1, the performance of our framework under
Table 3: Evaluation results with active spoofing.
method
DTW (camera)
T-Fusion (camera)
DTW (glove)
T-Fusion (glove)
EER
4.7
2.9
3.5
1.9
FAR1K FAR10K ZeroFAR
59.3
26.2
19.6
9.8
78.3
33.1
52.7
37.1
78.3
33.1
52.7
37.1
FRR100
24.5
12.1
17.2
10.5
active spoofing attacks does not collapse completely. The impostors
reported that when the user writes the passcode fast like a signature,
it was difficult to mimic the behavior. However, there were still a
significant number of accounts that can be successfully cracked by
the impostors if the distance score threshold is set to a practical
value such that the FRR is close to 1%, as shown in the column
“FRR100” (at this threshold, the FAR is approximately between 10−4
to 10−5 without considering collision). As a result, we believe our
framework is more like a password-based authentication system
where the content of the passcode should be kept as a secret, rather
than a signature-based authentication system. On the other hand,
a password-based authentication system will not be able to defend