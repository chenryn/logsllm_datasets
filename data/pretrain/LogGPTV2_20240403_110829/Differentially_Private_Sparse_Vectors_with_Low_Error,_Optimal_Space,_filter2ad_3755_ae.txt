2 log(cid:16)
(cid:17)
ğœ“
,
(cid:170)(cid:174)(cid:174)(cid:172) Â· ğ›¼ .
Proof. It is easy to see that |ğ‘¥ğ‘– âˆ’ ğ‘¥â€²
ğ‘– |  0, and ğ‘  âˆˆ N.
Input
:ğ‘˜-sparse vector ğ‘¥ âˆˆ Rğ‘‘+, where ğ‘  > 2ğ‘˜.
Sequence of hash functions from domain [ğ‘‘]
to [ğ‘ ], â„ = (â„1, . . . , â„ğ‘š), where ğ‘š =
:ğœ€-differentially private representation of ğ‘¥.
ğ›¼
(cid:108) ğ›½ğœ€
(cid:109).
Output
(1) Scale the entries of ğ‘¥ such that Ë†ğ‘¥ğ‘– = ğ‘¥ğ‘– Â· ğœ€.
(2) Let â„, Ëœğ‘§ = ALP1-projectionğ›¼,ğ›½Â·ğœ€,ğ‘ ( Ë†ğ‘¥, â„).
(3) Release â„ and Ëœğ‘§.
Algorithm 5: ALP-estimator
Parameters:ğ›¼, ğœ€ > 0.
Input
Output
(1) Let Ëœğ‘¥ğ‘– = ALP1-estimatorğ›¼ ( Ëœğ‘§, â„, ğ‘–).
(2) Return Ëœğ‘¥ğ‘–
ğœ€ .
:Embedding Ëœğ‘§ âˆˆ {0, 1}ğ‘ Ã—ğ‘š. Sequence of hash
functions â„ = (â„1, . . . , â„ğ‘š). Index ğ‘– âˆˆ [ğ‘‘].
:Estimate of ğ‘¥ğ‘–.
4.3 Generalization to ğœ€-differential privacy
We now generalize the ALP mechanism from 1-differential privacy
to satisfying ğœ€-differential privacy. A natural approach is to use a
function of ğœ€ as the parameter for randomized response in Algo-
rithm 2. The projection algorithm is ğœ€-differentially private if we
1
ğœ€+2. However, the expected
remove the scaling step and set ğ‘ =
per-entry error would be bounded by 8ğœ€+8
ğœ€2 by Equation 1 (with-
out considering hash collisions), which is as large as ğ‘‚(cid:16) 1
(cid:17) for
ğœ€2
small values of ğœ€. Other approaches modifying the value of ğ‘ have
a similar expectation.
In the following, we use a simple pre-processing and post-processing
step to achieve optimal error. The idea is to scale the input vector as
well as the parameter ğ›½ by ğœ€ before running Algorithm 2. We scale
back the estimates from Algorithm 3 by 1/ğœ€. These generalizations
are given as Algorithm 4 and Algorithm 5, respectively.
Lemma 4.12. Algorithm 4 satisfies ğœ€-differential privacy.
Proof. It follows from the proof of Lemma 4.1 that for any
Pr[ALP1-projection( Ë†ğ‘¥)âˆˆğ‘†] â‰¤ ğ‘’ âˆ¥ Ë†ğ‘¥âˆ’ Ë†ğ‘¥â€²âˆ¥1.
subset of outputs ğ‘† we have Pr[ALP1-projection( Ë†ğ‘¥â€²)âˆˆğ‘†]
As such for any pair of neighboring vectors ğ‘¥ and ğ‘¥â€² we have:
Pr[ALP1-projection( Ë†ğ‘¥â€²) âˆˆ ğ‘†]
Pr[ALP1-projection( Ë†ğ‘¥) âˆˆ ğ‘†]
â‰¤ ğ‘’ âˆ¥ Ë†ğ‘¥âˆ’ Ë†ğ‘¥â€²âˆ¥1 = ğ‘’ğœ€Â·âˆ¥ğ‘¥âˆ’ğ‘¥â€²âˆ¥1 â‰¤ ğ‘’ğœ€ .
Pr[ALP-projection(ğ‘¥â€²) âˆˆ ğ‘†]
Pr[ALP-projection(ğ‘¥) âˆˆ ğ‘†] =
â–¡
Lemma 4.13. Let ğ›¼ = Î˜(1) and ğ‘  = Î˜(ğ‘˜). The output of Algo-
rithm 4 can be stored using ğ‘‚(ğ‘˜ğ›½ğœ€) bits.
Proof. It follows from Lemma 4.2 that the output can be stored
(cid:17) bits. Recall that we assume ğ‘˜ = Î©(log(ğ‘‘)),
using ğ‘‚(cid:16) (ğ‘ +log(ğ‘‘))ğ›½ğœ€
i.e., ğ‘‚(cid:16) (ğ‘ +log(ğ‘‘))ğ›½ğœ€
(cid:17)
ğ›¼
ğ›¼
= ğ‘‚(ğ‘˜ğ›½ğœ€).
â–¡
9
Lemma 4.14. Let ğ›¼ = Î˜(1) and ğ‘  = Î˜(ğ‘˜). Then the expected per-
entry error of Algorithm 5 is E[|ğ‘¥ğ‘– âˆ’ Ëœğ‘¥ğ‘–|] â‰¤ max(0, ğ‘¥ğ‘– âˆ’ ğ›½) + ğ‘‚(1/ğœ€)
and the evaluation time is ğ‘‚(ğ›½ğœ€).
Proof. It is clear that the error of Algorithm 5 is 1
ğœ€ times the
error of Algorithm 3 for entries at most ğ›½. As such the expected per-
entry error follows from Lemma 4.8. The evaluation time follows
directly from Lemma 4.3.
â–¡
ğ›¾+2 , ğ‘ = 1 âˆ’ ğ‘, ğ‘¥ğ‘– â‰¤ ğ›½, and
1
2 Â· (4ğ‘ğ‘)(ğœğœ€/2ğ›¼)âˆ’1/2
ğ‘ 
ğœ â‰¥ ğ›¼
Pr[|ğ‘¥ğ‘– âˆ’ Ëœğ‘¥ğ‘–| â‰¥ ğœ]  0.
Input
Output
:ğ‘˜-sparse vector ğ‘¥ âˆˆ Rğ‘‘+.
:ğœ€-differentially private representation of ğ‘¥.
(1) Let ğ‘£ğ‘– = ğ‘¥ğ‘– + ğœ‚ğ‘– for all ğ‘– âˆˆ [ğ‘‘], where ğœ‚ğ‘– âˆ¼ Lap(1/ğœ€).
(2) Truncate entries below ğ‘¡:
(cid:40)ğ‘£ğ‘–,
0,
if ğ‘¦ğ‘– â‰¥ ğ‘¡
otherwise
Ëœğ‘£ğ‘– =
(3) Return Ëœğ‘£.
Algorithm 7: Threshold ALP-projection
Parameters:ğ›¼, ğœ€1, ğœ€2 > 0, and ğ‘  âˆˆ N.
Input
:ğ‘˜-sparse vector ğ‘¥ âˆˆ Rğ‘‘+, where ğ‘  > 2ğ‘˜.
Sequence of hash functions from domain [ğ‘‘]
to [ğ‘ ], â„ = (â„1, . . . , â„ğ‘š), where ğ‘š =
:(ğœ€1 + ğœ€2)-differentially private representation
of ğ‘¥.
.
ğ›¼
(cid:108) ğ›½ğœ€2
(cid:109).
Output
ln(ğ‘‘/2)
ğœ€1
(1) Let ğ‘¡ =
(2) Let Ëœğ‘£ = Thresholdğœ€1,ğ‘¡ (ğ‘¥).
(3) Let â„, Ëœğ‘§ = ALP-projectionğ›¼,ğœ€2,ğ‘¡,ğ‘ (ğ‘¥, â„)
(4) Return Ëœğ‘£, â„ and Ëœğ‘§.
Lemma 5.2. Let ğ‘¡ =
ğ‘‚(ğ‘˜)-sparse with high probability.
ğœ€
ln(ğ‘‘/2)
. Then the output of Algorithm 6 is
Proof. Using Definition 2.5 we find that the probability of stor-
ing a zero entry is:
Pr[Lap(1/ğœ€) â‰¥ ğ‘¡] = Pr[Lap(1/ğœ€) â‰¤ âˆ’ğ‘¡] =
1
2ğ‘’âˆ’ğ‘¡ğœ€ =
1
ğ‘‘
.
By linearity of expectation, the expected number of stored true zero
entries is at most one, and as such the vector is ğ‘‚(ğ‘˜)-sparse with
high probability.
â–¡
gorithm 6 is ğ‘‚(cid:16) log(ğ‘‘)
(cid:17) for worst-case input. We combine the al-
As discussed in Section 3, the expected per-entry error of Al-
gorithm with the ALP mechanism from the previous section to
achieve ğ‘‚(1/ğœ€) expected per-entry error for any input. We use the
threshold parameter ğ‘¡ as value for parameter ğ›½ in Algorithm 4. The
algorithm is presented in Algorithm 7.
ğœ€
Lemma 5.3. Algorithm 7 satisfies (ğœ€1 + ğœ€2)-differential privacy.
Proof. The two parts of the algorithm are independent as there
is no shared randomness. The first part of the algorithm satisfies
ğœ€1-differential privacy by Lemma 5.1 and the second part satisfies
ğœ€2-differential privacy by Lemma 4.12. As such it follows directly
from composition (Lemma 2.3) that Algorithm 7 satisfies (ğœ€1 + ğœ€2)-
differential privacy.
â–¡
Lemma 5.4. Let ğ›¼ = Î˜(1), ğ‘  = Î˜(ğ‘˜), ğœ€1 = Î˜(ğœ€2). Then the out-
put of Algorithm 7 is stored using ğ‘‚(ğ‘˜ log(ğ‘‘ + ğ‘¢)) bits with high
probability.
10
Algorithm 8: Threshold ALP-estimator
Parameters:ğ›¼, ğœ€2 > 0.
Input
:Vector Ëœğ‘£ âˆˆ Rğ‘‘+. Embedding Ëœğ‘§ âˆˆ {0, 1}ğ‘ Ã—ğ‘š.
Sequence of hash functions â„ = (â„1, . . . , â„ğ‘š).
Index ğ‘– âˆˆ [ğ‘‘].
:Estimate of ğ‘¥ğ‘–.
(1) Estimate the entry using either the vector or the embedding
ALP-estimatorğœ€2,ğ›¼ ( Ëœğ‘§, â„, ğ‘–),
if Ëœğ‘£ğ‘– â‰  0
otherwise
(cid:40) Ëœğ‘£ğ‘–,
Output
such that:
Ëœğ‘¥ğ‘– =
(2) Return Ëœğ‘¥ğ‘–.
Proof. It follows from Lemma 5.2 that we can store Ëœğ‘£ using
ğ‘‚(ğ‘˜ log(ğ‘‘+ğ‘¢)) bits with high probability. Since ğ›½ = ğ‘¡ it follows from
Lemma 4.13 that we can store â„ and Ëœğ‘§ using ğ‘‚(ğ‘˜ğ‘¡ğœ€2) = ğ‘‚(ğ‘˜ log(ğ‘‘))
bits.
â–¡
To estimate an entry, we access Ëœğ‘£ when a value is stored for
the entry and the ALP embedding otherwise. This algorithm is
presented in Algorithm 8.
Lemma 5.5. Let ğ›¼ = Î˜(1), ğ‘  = Î˜(ğ‘˜), and ğœ€1 = Î˜(ğœ€2). Let Ëœğ‘£, â„,
and Ëœğ‘§ be the output of Algorithm 7 given these parameters. Then the
evaluation time of Algorithm 8 is ğ‘‚(log(ğ‘‘)). The expected per-entry
error is ğ‘‚(1/ğœ€) and the expected maximum error is ğ‘‚(cid:16) log(ğ‘‘)
(cid:17)
.
ğœ€
Proof. The evaluation time follows from Lemma 4.14. That is,
the evaluation time is ğ‘‚(ğ›½ğœ€) = ğ‘‚(ğ‘¡ğœ€) = ğ‘‚(log(ğ‘‘)).
The error depends on both parts of the algorithm. The expected
per-entry error for the ğ‘–th entry is max(0, ğ‘¥ğ‘–âˆ’ğ›½)+ğ‘‚(1/ğœ€2) when Ëœğ‘£ğ‘– =
0 by Lemma 4.14. That is, when ğœ‚ğ‘– is less than ğ›½ âˆ’ ğ‘¥ğ‘– in Algorithm 6.
When Ëœğ‘£ğ‘– â‰  0 the error is the absolute value of ğœ‚ğ‘–. That is, we can
analyze it using conditional probability and the probability density
function of the Laplace distribution from Definition 2.4.
E[|ğ‘¥ğ‘– âˆ’ Ëœğ‘¥ğ‘–|] = E[|ğ‘¥ğ‘– âˆ’ Ëœğ‘¥ğ‘–| | Ëœğ‘£ğ‘– = 0] Â· Pr[ Ëœğ‘£ğ‘– = 0]
+ E[|ğ‘¥ğ‘– âˆ’ Ëœğ‘¥ğ‘–| | Ëœğ‘£ğ‘– â‰  0] Â· Pr[ Ëœğ‘£ğ‘– â‰  0]
â‰¤ (max(0, ğ‘¥ğ‘– âˆ’ ğ›½) + ğ‘‚(1/ğœ€2)) Â· Pr[Lap(1/ğœ€1) < ğ›½ âˆ’ ğ‘¥ğ‘–]
ğ›½âˆ’ğ‘¥ğ‘–
+
âˆ« âˆ
âˆ« ğ›½âˆ’ğ‘¥ğ‘–