e
t
s
u
C
l
f
o
%
106
107
 0
 0
Spam Clusters
Legitimate Clusters
105
103
104
102
Average Time Interval (sec)
Spam Clusters
Legitimate Clusters
 100
 200
 300
 400
 500
Number of Unique URLs
Figure 9: Cumulative distribution of average time interval
of spam and legitimate clusters, respectively.
Figure 11: Cumulative distribution of number of unique
URLs contained in spam and legitimate clusters, respec-
tively.
)
F
D
C
(
s
r
e
t
s
u
C
l
f
o
%
 100
 80
 60
 40
 20
 0
 0
Spam Clusters
Legitimate Clusters
 0.5
 1
 1.5
 2
Average Number of URL
Figure 10: Cumulative distribution of average number of
URLs per message of spam and legitimate clusters, respec-
tively.
sorted. Alternatively, we quantify this property using the
average time interval, which is much more “lightweight”,
since only the starting time, ending time and the total num-
ber of messages in the cluster are needed to calculate its
value. Figure 9 plots the CDFs of average time interval of
spam and legitimate clusters, respectively. The x axis is
in log scale so that the ﬁgure is readable. It shows that the
average time interval of legitimate clusters is orders of mag-
nitude larger than that of spam clusters.
Average URL Number per Message
Spammers always
solicit some action from the recipients, e.g. , to click a link,
in order for economic beneﬁt ultimately. As the most com-
monly adopted practice, spam messages are embedded with
URLs that the spammers want to advertise. In contrast, le-
gitimate messages do not contain URLs in most of the case.
Hence, we use the average number of URLs per message
in each cluster as one feature. Figure 10 plots the CDFs of
this feature for spam and legitimate clusters, respectively. It
shows that more than 80% of benign clusters do not contain
any URL. Only about 2% benign clusters contain more than
one URL in each message on average. In comparison, about
80% of malicious clusters contain at least one URL in each
message on average.
Unique URL Number URL blacklist has been exten-
sively used nowadays. As an attempt to evade blacklist
based detection, spammers have evolved to embed differ-
ent URLs in messages from the same campaign, with each
URL being used less frequently, so that some, if not all, of
the spam URLs will not be blacklisted. This type of spam
campaigns will inevitably contain large number of unique
URLs. On the other hand, legitimate clusters are not likely
to exhibit the same behavior. Figure 11 plots the CDFs
of the number of unique URLs contained in spam and le-
gitimate clusters, respectively. The curve representing le-
gitimate clusters embraces the y axis, which is consistent
with the fact that many legitimate messages do not contain
URL. On the contrary, about a half of the spam clusters have
multiple URLs. The most diverse cluster uses 486 different
URLs.
4 System Design
In this section, we present the detailed design of the on-
line spam ﬁltering system. Section 4.1 ﬁrst introduces the
system overview. After that, Section 4.2 and Section 4.3
present the incremental clustering module and the super-
vised machine learning module, respectively. Finally, Sec-
tion 4.4 illustrates an extension on the basic design that ex-
ploits parallelism to boost the system throughput.
4.1 Overview
Figure 12 shows the system design overview. The intu-
ition is that spam campaigns are generated using templates
and that messages in the same campaign shall retain certain
similarity among them. After a clustering process, spam
Time
Past Messages
Current Message
msg
msg
msg
...
msg msg
msg
Incremental Clustering
Clusters
Trained 
Classifier
Computed 
Features
Detection 
Results
Decay over Time
Figure 12: The system design overview.
messages in the same campaign will reside in the same clus-
ter or only a small number of clusters. Note that we do not
depend on the system to agglomerate an entire campaign
into one single cluster, which is impractical due to the vari-
ation brought by the spam template. However, because the
total number of messages in a spam campaign is very large,
each spam cluster will still contain signiﬁcant number of
messages. In addition, the clusters formed by the spam mes-
sages will exhibit different characteristics comparing to the
legitimate clusters as Section 3 shows. Hence, they can be
differentiated using supervised machine learning.
Accordingly, the two major components in the system
are the incremental clustering module and the supervised
machine learning module. The ﬁrst module maintains a col-
lection of disjoint clusters such that each message that has
been processed in the past is present. The second module is
essentially a trained classiﬁer that makes binary decisions.
When the system receives a new message, it ﬁrst incremen-
tally updates the clustering result with minimal computa-
tional overhead. The new message may form a new clus-
ter by itself, be incorporated into one existing cluster or
even trigger the merge of multiple existing clusters. In the
ﬁrst case, the system directly marks the message as “legit-
imate” without invoking the classiﬁer, because the average
time interval feature cannot be calculated with only 1 mes-
sage. This implicit limitation will cause a false negative
only when the new message is the ﬁrst one in a spam cluster,
which happens very rarely. In any other case, the values of
the six features of the cluster that the new message resides
in are (re-)calculated. The other clusters are intact. After
that, the trained classiﬁer accepts these values and decides
whether these values represent a spam cluster. Note that
if the classiﬁer outputs “spam”, it will only trigger a spam
alarm on the current message, rather than all the messages
in the cluster. Since it is an online system, the decision on
the previous messages in the same cluster has already been
made and is not changed.
A practical concern is that the hardware resource is al-
ways limited. It is not affordable to keep track of all the
messages observed in the past. In addition, recent messages
should be given heavier weight that inﬂuences the clusters’
feature values. To address these two concerns, the clusters
that the system maintains decays exponentially over time.
More speciﬁcally, once after the system has processed w
messages, it shrinks the six feature values associated with
each cluster by a factor of a, where w and a are two impor-
tant system parameters to determine the decaying speed. If
a cluster’s size is shrunk to a value below a threshold t, it
is permanently removed and all the resources it takes up are
freed.
4.2
Incremental Clustering
The ability to do incremental clustering is the key to
the system. The ﬁrst design choice we must make is to
deﬁne the distance between two messages. Naturally, us-
ing semantic similarity will result in more accurate clus-
tering result as messages in the same campaign are more
likely to have small distance. However, semantic analysis
involves heavier computational overhead that is not accept-
able for a real-time system. Alternatively, we choose text
shingling [7] as the basic tool to calculate the distance be-
tween messages. Text shingling is initially proposed to ana-
lyze web page similarity in huge volume and is sufﬁciently
lightweight. In the shingling process, the original message
is disassembled into ﬁxed-length substrings, each of which
is called a “shingle”. We sort the hashed shingle and use the
ﬁrst 20 of them to represent each message. For the messages
with less than 20 shingles, the system does not cluster them
and directly marks them as legitimate if they do not contain
any URL, since they are too short to carry out attacks. The
similarity between a message pair is estimated by its resem-
blance score, deﬁned as the ratio of shared shingles to all
unique shingles. Two messages are deemed as “similar” if
their resemblance score surpasses a predeﬁned threshold.
We augment the original text shingling with URL com-
parison as an adaptation to the speciﬁc application of spam
detection. URLs embedded in the spam messages represent
the spammers’ goal. Hence two spam messages sharing the
same embedded URL shall come from the same campaign,
although their textual description might be quite different
judged by text shingling due to the usage of templates. To
sum up, two messages are considered as “similar” if their
resemblance score is sufﬁciently large or their embedded
URLs are identical. They will reside in the same cluster if
either condition is satisﬁed. A similar method was also used
by Zhuang et al. [35] to analyze email spam traces ofﬂine.
We use a hash table to store the text shingling result, in-
dexed by the shingles. It keeps track of all the messages
that contain the corresponding shingle. Meanwhile, we use
another hash table to store the result of URL comparison.
It is indexed by the URLs and each element is a list of
messages that contain the corresponding URL. When a new
message arrives, it is disassembled into shingles and all the
previously observed messages with identical shingles can
be conveniently identiﬁed. The same holds for the URL
comparison. In this way, the system does not need to com-
pare the new message with all observed messages sequen-
tially.
Instead, it directly looks up the hash tables at the
location of matching shingles and URLs, thus minimizing
the overhead.
For the purpose of incremental clustering, our system
maintains a set of disjoint clusters. Upon the arrival of a
new message, it ﬁrst creates a cluster containing a single
element, the new message itself. Next, all clusters that con-
tain a message that is “similar” to the new message must
be found and merged with the new cluster, while the other
clusters stay intact. We build a Union-Find data structure to
accommodate this need. A Union-Find data structure sup-
ports three operations very efﬁciently, which are i) creating
a new set, ii) ﬁnding the set containing a given element
and iii) merging two sets.
In addition, the system needs
to eliminate clusters from time to time because of the ex-
ponential decaying. This operation is not supported by the
standard Union-Find data structure. As a result, we enhance
it to provide the functionality to return all the elements of a
given cluster.
4.3 Supervised Machine Learning
While clustering provides a division of the observed
messages, our system needs to make decision on each in-
coming message that ﬂags it as either a spam or a legitimate
message. The supervised machine learning module is es-
sentially a trained classiﬁer that makes this binary decision.
Two classiﬁer candidates,
support vector machine
(SVM) [8] and decision tree [21], are widely used in
the literature. Decision tree has the advantage that the
trained classiﬁer is simple to understand and fast. The
time complexity to make a prediction on a new test point
is O(log(N )), where N is the number of nodes in the
trained tree. Such efﬁciency is a desirable property for
an online system. On the other hand, SVM is reported to
achieve good accuracy on a wide variety of problems such
as handwriting recognition, face detection, text categoriza-
tion, etc. However, the classiﬁcation process of new data
points gets slower if the training set is large. We test both
classiﬁers on our dataset and decision tree yields better ac-
curacy, i.e. , higher true positive rate and lower false positive
rate. Consequently, we pick decision tree as the classifying
module in the system.
4.4 Parallelization
Our system needs to achieve high throughput as an on-
line spam ﬁltering tool. The basic design shown in Fig-
ure 12 spends the majority of running time on incremental
clustering. Consequently, accelerating the clustering pro-
cess can greatly enhance the throughput.
Parallelization is a natural choice to achieve such a goal,
but it seems to be counterintuitive in our speciﬁc case at the
ﬁrst glance, since incremental clustering is a sequential pro-
cess, in the sense that the clustering process of the n + 1th
message is based on the clustering result of the ﬁrst nth
messages. Our solution is to compute the incremental clus-
tering result for the next k messages, instead of the next one
message, simultaneously. For each one of the next k mes-
sages, we compare its similarity to the observed messages
and decide which existing clusters it should be merged into.
The computation for one message is independent from oth-
ers. Accordingly, k threads are executed at the same time
with each thread handling one message. Note that only the
message similarity comparison is parallelized. All other op-
erations, such as cluster merging, remain sequential to avoid
conﬂict among threads.
The parallel design might slightly alter the clustering re-
sult comparing to the sequential case, but it will not notice-
ably affect the detection result. Without loss of generality,
we analyze the potential alteration under the scenario of two
threads, t1 and t2, processing two messages, m1 and m2, in
parallel. The only situation when the clustering result dif-
fers must satisfy two conditions: i) m1 and m2 are simi-
lar, ii) there does not exist a previously observed message
m0, such that m0 is similar to both m1 and m2.
In this
situation, a sequential execution will cluster m1 and m2 to-
gether immediately, but a parallel execution will not do so.
The reason is that t1 is unaware of m2 and cannot ﬁnd any
previously observed message that is similar to m1. Hence
m1 is left in a separate cluster containing only itself. The
same applies to m2. However, their corresponding clusters
will be merged once a third message, m3, which is simi-
lar to both m1 and m2, has been processed. In the context
of spam message detection, the above scenario maps to the
case that the ﬁrst two spam messages from the same cam-
paign are handled by the system in parallel. Given the lim-
ited number of spam campaigns, this scenario shall happen
very rarely. For legitimate messages, such inconsistency in
the clustering process will not affect the detection result at
all since any clusters with size of 1 will be assumed to be
legitimate.
5 Experiment
5.1 Methodology
We evaluate the system on a server machine that has
eight cores (Xeon E5520 2.2Ghz) with Hyper-Threading
and 16GB memory. We sort all the messages according to
their timestamps and divide them into the training set and
the testing set. The training set includes the ﬁrst 25% of
spam messages and all the legitimate messages in the same
time period. The testing set contains the remaining mes-
sages.
The system has multiple tunable parameters (Sec-
tion 4.1). W and a control the speed of cluster decay.
The choice of their value is mainly constrained by the hard-
ware resource, as lower decaying speed results in more re-
source consumption and slower processing speed. We pick
100,000 and 0.2 as the value of w and a in the experiments,
respectively, according to our hardware resource limit. We
also tested faster decaying speed by setting a as 0.5, but
only found very slight change in the detection result. We
pick 3 as the value of t, the size threshold to eliminate a
cluster, since a small value reduces the risk of removing a
live spam cluster from the system.
In the training phase, we ﬁrst feed the incremental clus-
tering module with the training set, and record the feature
values for all spam and legitimate clusters. We use all 6 fea-
tures for the Facebook dataset. We use the 5 features other
than interaction history score for the Twitter dataset, since
interaction history score is not applicable for the broadcast
interaction in Twitter. Next, We use the extracted feature
values to train the classiﬁer. We only use the clusters whose
size is at least 5 for training. After that, the system is fed
with the testing set. We conduct all the experiments obey-
ing the time order, so that the experimental results can re-
semble the system performance in real-world deployment
accurately.
5.2 Clustering Resemblance Threshold
The detection is based on the clustering of spam mes-
sages. Hence, the resemblance threshold used in the clus-
tering process could potentially affect the detection result.
Recall that the resemblance of a message pair is the ratio
of shared shingles to the total number of distinct shingles,
which represents the “similarity” between the message pair.
In order to understand how to pick the best threshold, we
study the resemblance value among spam and legitimate
message pairs, respectively.
We ﬁrst divide the Facebook dataset into the spam set
and the legitimate message set. The division is trivial us-
ing the label of each message. After that, we compute
the resemblance value of all the spam message pairs and
)
F
D
C