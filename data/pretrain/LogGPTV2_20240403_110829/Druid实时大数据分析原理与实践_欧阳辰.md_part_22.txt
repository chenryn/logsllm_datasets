Any ISO 8601 duration
任意字符串
任意字符串
任意字符串
高
级，排序靠前的优先级
JSONMap，Broker服务
名
Broker 服务名的有序
Key为tier，Value为
任意字符串
可能的值
名的顺序代表其优先
务
自定义的路由策略列表
轮询周期，人
获取规则的接口
所有DataSource
的Broker服务
查询具体tier的数据路由到合适
Coordinator
Coordinator
接到默认的服务名
名中所有的Broker不可用时，
路由规则不满足或者选取的服务
解释
用于发现新的规则
节点
的服务名、用于获取
口
的默认规则
连
:"priority"}]
Boundary"),("type"
[l"type":"time-
PT1M
nator/vl/rules"
["_default": ""}
druid/broker
"/druid/coordi-
默认值
"_default"
175
---
## Page 200
个参数，返回tier所需要的Broker服务，如果没有则返回Null，表示使用默认的Broker服务。
3.
0，则会跳过该策略。
地，将minPriority设置为0，maxPriority为1，如果查询的优先级为0，查询的默认优先级是
176
JavaScript
通过JavaScript 函数的方式可以实现任意的路由规则，该函数需要传入confg和query两
priority
"type":"timeBoundary"
timeBoundary
//为了便于演示，JavaScript代码添加换行和缩进，使用时需要符合JSON规范
"type":"javascript",
如下示例是如果查询中含有三个以上Aggregator，则会被路由到最低优先级的服务名。
}else
如果查询的优先级小于minPriority，则会被路由到最低优先级的Broker服务名。默认
"maxPriority":1
"minPriority":0,
"type":"priority"
添加该策略，意味着timeBoundary类型的查询总是路由到最高优化级的Broker服务名。
return null
}else{
return config.getTierToBrokerMap().values().toArray()[size-1]
return config.getDefaultBrokerServiceName(）}
//获取tierToBrokerMap的最后一个元素，排序越靠后，优先级越低
if（size>0）{
var size=config.getTierToBrokerMap().values().size();
Druid实时大数据分析原理与实践
---
## Page 201
层面的查询没有迫切需求时，不推荐使用Router。
查询性能造成影响。所以就像开始提到的那样，当数量没有达到TB级别，或者对隔离Broker
认配置的“priority”路由策略，同时将查询的优先级设置为2，2>maxPriority(1)，则会使用
broker-cold"，我们想让时间跨度为最近一个月的查询落在“druid:broker-hot”"，可以使用默
数据分层的例子中，tierToBrokerMap配置是{hot"："druid:broker-hot"，”_default_tier"："druid：
的优先级是由其在tierToBrokerMap中的排序来决定的，排序靠前则说明优先级高。回到冷热
例如JavaScript例子中的Aggregator数量，来选择合适优先级的Broker服务名，Broker服务名
第7章高级功能和特性
出以及查询性能，所以需要在延迟移交和丢弃数据之间进行权衡，选择合适的时间窗口。
就解决问题了吗？时间窗口调大的负面影响是延迟移交，它会影响索引服务的任务的完成退
找到一个合适的windowPeriod来保障不丢弃数据。你可能想，把时间窗口调整为足够大不
中。分布式日志收集以及实时计算过程中都会导致延迟，而且延迟是不可预测的，所以很难
度以后延迟时间窗口的时间再进行移交，这样可以保障延迟的数据依然能被添加到Segment
据的延迟以及乱序问题，它允许数据存在时间窗口内的延迟，超出以后被丢弃。
7.5.1
7.5
的优先级，除了timeBoundary查询以外，只能通过tier匹配的方式路由。
最高优先级的服务名“druid:broker-hot”。由此可见，使用默认的路由策略，并且不调整查询
Router相当于根据策略规则把查询路由到Broker的反向代理，加人这一层以后势必会对
通过对上述路由策略的学习，知道其实现机制是根据查询的优先级、类型或者其他特性
windowPeriod会影响Segment移交（Hand of）的时间点，达到 Segment设定的时间粒
影响数据丢弃的主要因素是时间窗口（windowPeriod），时间窗口的设定是为了解决数
实现ExactlyOnce语义，必须要保障不重复摄入数据，以及不丢弃数据。
Kafka索引服务为增强数据实时摄人而生。其核心特性如下。
·操作的易用性，自适应性强，可以根据Kafka分区的增加或者减少调整任务的数量。
不再受windowPeriod的约束，可以摄入任意时间戳的数据，而不仅仅是当前的数据。
·保障数据摄入的Exactly Once（有且只有一次）。实现Exactly Once，需要保障既不能
重复摄入，同时也不能丢弃任何一条数据。
设计背景
Kafka索引服务
177
---
## Page 202
改replicas的值来调整任务副本的数量。
分配给TaskGroup的所有Kafka分区的数据，而且都是从相同的起始Ofset 处读取。通过修
要数据结构，用来保障任务多副本执行。TaskGroup中的所有任务总是做相同的事情，读取
达到completionTimeout的时间）。
持发布状态，直到生成Segment，并推送到深度存储中，以及等待历史节点加载以后（或者
读取和发布。任务会保持读取状态，直到达到taskDuartion以后进人发布状态。接下来会保
KafkaSupervisor通过修改endOffset的值来结束任务的执行。运行中的任务一般有两种状态
中，startPartition中的Offset 不会改变，endPartition的Ofset初始设置为Long.MAX_VALUE，
取数据，一直到endPartition的结束Ofset处以后结束读取，发布移交Segment。在执行过程
结构。
分区以后的可扩展性，以及任务多副本执行。
期，它会监管Kafka索引任务的状态来完成协调移交、管理失败，同时保障添加/删除Kafka
Overlord上。我们来看一下其实现的关键类。
层API实现对Ofset的事务管理。Kafka索引服务采用 Supervisor（监督者）的方式运行在
7.5.2实现
（组）的方式，同一Group内的消息只能被一个消费者消费一次。但它也会带来一些问题。
的Leader选择、Ofset的维护、管理分区和消费者之间的均衡以及重平衡等功能。采用Group
KafkaFireChief实现中采用HighLevel（高层）的Consumer（消费者），它会帮助完成Broker
178
TaskGroup是KafkaSupervisor管理Kafka的分区、分区的Ofset以及Kafka索引任务的重
KafkalndexTask（Kafka索引任务）从KafkaIOConfig的startPartition中的Ofset处开始读
KafkaPartitions用来记录Kafka的Topic（主题）以及Partition->Offset的映射关系的数据
KafkaSupervisor类似于一个大管家，负责Kafka索引任务的创建以及管理其整个生命周
Kafka索引服务为了实现Exactly Once语义，去掉了windowPeriod 以及采用Kafka的底
·同一Group内的消息只能被消费一次，所以很难实现数据摄入阶段的多副本来保障高
影响数据仅摄人一次、不重复摄人的主要因素是Kafka的Ofset（偏移）管理。在最初的
·HighLevel的Consumer采用Zookeeper保存Ofset，内存增量索引持久化和Ofset的
取导致数据重复摄入。虽然这种情况发生的概率很低，但还是有可能发生的。
Offset，节点失败，然后重启，加载持久化的索引以后，继续从上一次提交的Ofset读
提供是分开进行的，不能在同一事务中处理。假设持久化成功但还没有来得及提交
可用性和查询一致性。
Druid实时大数据分析原理与实践
---
## Page 203
1 小时。如果达到了，则发送信号提示其停止读取数据，进入Segment 发布阶段。其执行流
taskGroupId=partition %ioConfig.getTaskCount(）;
则如下：
情，包括使用SegmentAllocator将数据分配到指定的 Segment，以及监控移交等工作。
界流式数据，在索引结束以后执行移交操作。在这个类中完成Appenderator不能做的那些事
度存储中，它并不负责Segment的分配，而只是将 Segment 信息发布到元数据存储中。
索引组成，并负责这两部分的查询。这个模块负责索引和查询数据，并将 Segment推送到深
第7章高级功能和特性
程如图7-7所示。
检查是否达到任务的持续时间，任务的持续时间由参数“taskDuration”来决定，默认为
从Kafka中更新Partition信息，用于发现新的Partition，并为其分配TaskGroup。分配规
SegmentAllocator根据给定的时间戳，分配一个Segment。
FiniteAppenderatorDriver驱动Appenderator完成有限流式数据的索引，它不能处理无边
Appenderator用来索引数据，采用类似于LSM-Tree的架构。它由内存增量索引和持久化
KafkaSupervisor有三个重要的数据结构。
·调用KafkalndexTask的“/offsets/end”接口，设置endOfsets为上一步得到的值，并恢
·暂停TaskGroup中的所有任务，KafkalndexTask提供了“/pause”接口，调用该接口可
下面重点介绍信号通知的实现机制。
partitionGroups，保存taskGroupID 和Kafka分区起始偏移的 Map 结构。其结构为
·pendingCompletionTaskGroups，使用信号通知TaskGroup结束读取，进人Segment发布
·taskGroups，保存读取状态的 TaskGroup的Map结构。Key为 groupld，Value为相应的
发布状态。
复其执行。当任务的读取选代过程发现达到endOffsets时，会跳出选代进入Segment
出每个Partition对应的最高Offset，构建成Map结构。这里把它叫作endOfsets。
有Partition->Ofset的映射关系。比较TaskGroup中每个任务返回的currentOffsets，找
以暂停从Kafka中读取数据，并返回该任务的currentOffsets，currentOfsets包含了所
Map>。
状态以后，将该Task Group从 taskGroups 移除放人 pendingCompletionTaskGroups 中。
TaskGroup
179
---
## Page 204
for(Integer groupId :partitionGroups.keySet(）)
180
if (!taskGroups.containsKey(groupId)）{
taskGroups.put(groupId,new TaskGroup(generateStartingoffsetsforPartitionGroup(
查找有哪些groupId还没有创建TaskGroup，
创建TaskGroup及其任务副本，
将endOfsets 作为下一个TaskGroup的起始Offset放人partitionGroups中，用于创建
等任务完成以后就可以执行下一个任务。
新的TaskGroup继续从前一个任务的结束Offset处读取数据。
图7-7
将Group从taskGroups中移
pendingCompletionTaskGro
给Group中的所有Task发
StartTime+Duraton:/druid/indexer/vl/supervisor。
兼容之前版本的Kafka Broker，所以最好将KafkaBroker升级到0.9版本。
Manager（中间管理者）中。
7.5.3
据的问题。
储中，元数据存储一般采用MySQL等关系型数据库，使用事务处理的方式解决重复摄人数
set，只有在发布阶段，将endOfset写入元数据存储中，Segment信息也写入同一个元数据存
交需要在同一事务中处理。FiniteAppenderatorDriver在索引的构建过程中不会修改startOf-
的问题。实现不重复摄人数据的关键因素是Segment信息发布到元数据存储中和Ofset的提
182
编写Supervisor规范，通过HTTPPOST方式提交给Overlord的URL:http://<OVERLORD_
"dataSchema":{
如何编写Supervisor规范，我们来看一个简单的样例。
Kafka索引服务使用Kafka0.9版本的ConsumerAPI，由于在0.9版本中协议改变了，不
去掉时间窗口，解决了数据丢失的问题，实现ExactlyOnce，还需要解决不重复摄人数据
如何使用
"metricsSpec":[
"granularitySpec":{
"dataSource":"metrics-kafka"
"parser":{
、
"queryGranularity":"NONE",
"parseSpec":[
"type":"uniform"
"segmentGranularity":"HOUR"
"dimensionsSpec":
"type":"count"
"name":"count"
"dimensionExclusions":[
Druid实时大数据分析原理与实践
---
## Page 207
第7章
ioConfig
tuningConfig
dataSchema
type
属
性
类似其他的摄人规范，Supervisor规范由type、dataSchema、tuningConfg和ioConfng组成。
"type":“kafka"
"tuningConfig":{
"ioConfig":{
"type":"kafka"
"maxRowsPerSegment":5000000,
"topic":"metrics"
"taskCount";
"consumerProperties":
高级功能和特性
"taskDuration":"PT1H"
'replicas":
"bootstrap.servers": "localhost:9092"
"type": "string"
KafkaTuningConfig，用于给KafkaIndexTask 调优
用于KafkaIndexTask摄入数据，配置和其他摄入规范相同
Supervisor的类型，对于Kafka索引服务而言，必须是“kafka
解释