title:F-BLEAU: Fast Black-Box Leakage Estimation
author:Giovanni Cherubin and
Konstantinos Chatzikokolakis and
Catuscia Palamidessi
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
F-BLEAU: Fast Black-box Leakage Estimation
Giovanni Cherubin
Konstantinos Chatzikokolakis
EPFL
giovanni.cherubin@epﬂ.ch
University of Athens
PI:EMAIL
Catuscia Palamidessi
INRIA, École Polytechnique
PI:EMAIL
Abstract—We consider the problem of measuring how much a
system reveals about its secret inputs. We work in the black-box
setting: we assume no prior knowledge of the system’s internals,
and we run the system for choices of secrets and measure its
leakage from the respective outputs. Our goal is to estimate the
Bayes risk, from which one can derive some of the most popular
leakage measures (e.g., min-entropy leakage).
The state-of-the-art method for estimating these leakage
measures is the frequentist paradigm, which approximates the
system’s internals by looking at the frequencies of its inputs and
outputs. Unfortunately, this does not scale for systems with large
output spaces, where it would require too many input-output
examples. Consequently, it also cannot be applied to systems with
continuous outputs (e.g., time side channels, network trafﬁc).
In this paper, we exploit an analogy between Machine Learning
(ML) and black-box leakage estimation to show that the Bayes
risk of a system can be estimated by using a class of ML methods:
the universally consistent learning rules; these rules can exploit
patterns in the input-output examples to improve the estimates’
convergence, while retaining formal optimality guarantees. We
focus on a set of them, the nearest neighbor rules; we show
that they signiﬁcantly reduce the number of black-box queries
required for a precise estimation whenever nearby outputs tend
to be produced by the same secret; furthermore, some of them
can tackle systems with continuous outputs. We illustrate the
applicability of these techniques on both synthetic and real-
world data, and we compare them with the state-of-the-art tool,
leakiEst, which is based on the frequentist approach.
I. INTRODUCTION
Measuring the information leakage of a system is one
of the founding pillars of security. From side-channels to
biases in random number generators, quantifying how much
information a system leaks about its secret inputs is crucial
for preventing adversaries from exploiting it; this has been the
focus of intensive research efforts in the areas of privacy and
of quantitative information ﬂow (QIF). Most approaches in the
literature are based on the white-box approach, which consists
in calculating analytically the channel matrix of the system,
constituted by the conditional probabilities of the outputs given
the secrets, and then computing the desired leakage measures
(for instance, mutual information [1], min-entropy leakage [2],
or g-leakage [3]). However, while one typically has white-
box access to the system they want to secure, determining
a system’s leakage analytically is often impractical, due to
the size or complexity of its internals, or to the presence of
unknown factors. These obstacles led to investigate methods
for measuring a system’s leakage in a black-box manner.
Until a decade ago, the most popular measure of leakage
was Shannon mutual information (MI). However, in his semi-
nal paper [2] Smith showed that MI is not appropriate to repre-
sent a realistic attacker, and proposed a notion of leakage based
on Rényi min-entropy (ME) instead. Consequently, in this
paper we consider the general problem of estimating the Bayes
risk of a system, which is the smallest error achievable by
an adversary at predicting its secret inputs given the outputs.
From the Bayes risk one can derive several leakage measures,
including ME and the additive and multiplicative leakage [4].
These measures are considered by the QIF community among
the most fundamental notions of leakage.
To the best of our knowledge, the only existing approach
for the black-box estimation of the Bayes risk comes from a
classical statistical technique, which refer to as the frequentist
paradigm. The idea is to run the system repeatedly on chosen
secret inputs, and then count the relative frequencies of the
secrets and respective outputs so to estimate their joint prob-
ability distribution; from this distribution, it is then possible
to compute estimates of the desired leakage measure. Leak-
Watch [5] and leakiEst [6], two well-known tools for black-box
leakage estimation, are applications of this principle.
Unfortunately,
the frequentist approach does not always
scale for real-world problems: as the number of possible input
and output values of the channel matrix increases, the number
of examples required for this method to converge becomes too
large to gather. For example, LeakWatch requires a number
of examples that is much larger than the product of the size
of input and output space. For the same reason, this method
cannot be used for systems with continuous outputs; indeed,
it cannot even be formally constructed in such a case.
Our contribution
In this paper, we show that machine learning (ML) methods
can provide the necessary scalability to black-box measure-
ments, and yet maintain formal guarantees on their estimates.
By observing a fundamental equivalence between ML and
black-box leakage estimation, we show that any ML rule
from a certain class (the universally consistent rules) can
be used to estimate with arbitrary precision the leakage of
a system. In particular, we study rules based on the nearest
neighbor principle – namely, Nearest Neighbor (NN) and kn-
NN, which exploit a metric on the output space to achieve a
considerably faster convergence than frequentist approaches.
In Table I we summarize the number of examples necessary for
the estimators to converge, for the various systems considered
in the paper. We focus on nearest neighbor methods, among
the existing universally consistent rules, because: i) they are
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:40)(cid:74)(cid:80)(cid:87)(cid:66)(cid:79)(cid:79)(cid:74)(cid:1)(cid:36)(cid:73)(cid:70)(cid:83)(cid:86)(cid:67)(cid:74)(cid:79)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:24)(cid:20)
(cid:25)(cid:20)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:33 UTC from IEEE Xplore.  Restrictions apply. 
NUMBER OF EXAMPLES REQUIRED FOR CONVERGENCE OF THE ESTIMATES. “X” MEANS AN ESTIMATE DID NOT CONVERGE.
TABLE I
System
Random
Geometric (ν = 0.1)
Geometric (ν = 0.02)
Geometric (ν = 2)
Multimodal Geometric (ν = 0.1)
Spiky (contrived example)
Planar Geometric ν = 2
Laplacian ν = 2
Blahut-Arimoto ν = 2
Dataset
frequentist
100 secrets, 100 obs.
100 secrets, 10K obs.
100 secrets, 10K obs.
10K secrets, 1K obs.
100 secrets, 10K obs.
2 secrets, 10K obs.
Gowalla checkins in San Francisco area
"
"
10 070
35 016
152 904
95 500
44 715
22 908
X
N/A
1 285
NN
10 070
333
152 698
94 204
568
29 863
X
X
1 170
kn-NN
10 070
458
68 058
107 707
754
62 325
19 948
19 961
1 343
The proposed tool, F-BLEAU, is the combination of frequentist, NN, and kn-NN estimates, as an alternative to the frequentist paradigm.
simple to reason about, and ii) we can identify the class of
systems for which they will excel, which happens whenever
the distribution is somehow regular with respect to a metric
on the output (e.g., time side channels, trafﬁc analysis, and
most mechanisms used for privacy). Moreover, some of these
methods can tackle directly systems with continuous output.
We evaluate these estimators on synthetic data, where we
know the true distributions and we can determine exactly
when the estimates converge. Furthermore, we use them for
measuring the leakage in a real dataset of users’ locations,
defended with three state-of-the-art mechanisms: two geo-
indistinguishability mechanisms (planar geometric and planar
Laplacian) [7], and the method by Oya et al. [8], which we
refer to as the Blahut-Arimoto mechanism. Crucially, the pla-
nar Laplacian is real-valued, which kn-NN methods can tackle
out-of-the box, but the frequentist method cannot. Results in
both synthetic and real-world data show our methods give a
strong advantage whenever there is a notion of metric in the
output that can be exploited. Finally, we compare our methods
with leakiEst on the problem of estimating the leakage of
European passports [6], [9], and on the location privacy data.
As a further evidence of their practicality, we use them in
Appendix G to measure the leakage of a time side channel in
a hardware implementation of ﬁnite ﬁeld exponentiation.
No Free Lunch
A central
takeaway of our work is that, while all
the
estimators we study (including the frequentist approach) are
asymptotically optimal in the number of examples, none of
them can guarantee on its ﬁnite sample performance; indeed,
no estimator can. This is a consequence of the No Free Lunch
theorem in ML [10], which informally states that all learning
rules are equivalent among the possible distributions of data.
This rules out the existence of an optimal estimator.
In practice,
this means that we should always evaluate
several estimators, and select the one that converged faster.
Fortunately, our main ﬁnding (i.e., any universally consistent
ML rule is a leakage estimator) adds a whole new class of
estimators, which one can use in practical applications.
We therefore propose a tool, F-BLEAU (Fast Black-box
Leakage Estimation AUtomated), which computes nearest
neighbor and frequentist estimates, and selects the one con-
verging faster. We release it as Open Source software1, and
we hope in the future to extend it to support several more
estimators based on UC ML rules.
Nearest Neighbor rules
Nearest neighbor rules excel whenever there is a notion of
metric on the output space, and the output distributions is
“regular” (in the sense that it does not change too abruptly
between two neighboring points). We expect this to be the
case for several real-world systems, such as: side channels
whose output is time, an electromagnetic signal, or power
consumption; for trafﬁc analysis on network packets; and for
geographic location data. Moreover, most mechanisms used
in privacy and QIF use smooth noise distributions. Suitable
applications may also come from recent attacks to ML models,
such as model inversion [11] and membership inference [12].
Furthermore, we observe that even when there is no metric,
or when the output distribution is irregular, (e.g., a system
whose internal distribution has been randomly sampled), these
rules are equivalent to the frequentist approach. Indeed, the
only case we observe when they are misled is when the system
is crafted so that the metric contributes against classiﬁcation
(e.g., see “Spiky” example in Table I).
II. RELATED WORK
Chatzikokolakis et al. [13] introduced methods for mea-
suring the leakage of a deterministic program in a black-box
manner; these methods worked by collecting a large number of
inputs and respective outputs, and by estimating the underlying
probability distribution accordingly; this is what we refer to as
the frequentist paradigm. A fundamental development of their
work by Boreale and Paolini [14] showed that, in the absence
of signiﬁcant a priori information about the output distribution,
no estimator does better than the exhaustive enumeration of
the input domain. In line with this work, section IV will show
that, as a consequence of the No Free Lunch theorem in ML,
1https://github.com/gchers/fbleau.
(cid:25)(cid:20)(cid:23)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:33 UTC from IEEE Xplore.  Restrictions apply. 
TABLE II
SYMBOLS TABLE.
(s, o) ∈ S × O An example
Symbol
s ∈ S
o ∈ O
(π, Cs,o)
f : S (cid:3)→ O
μ
(cid:4)
Rf
R∗
Description
A secret
An object/black-box output
A system, given a set of priors π and channel matrix C
Distribution induced by a system on S × O
A classiﬁer
Loss function w.r.t. which we evaluate a classiﬁer
The expected misclassiﬁcation error of a classiﬁer f
Bayes risk
no leakage estimator can claim to converge faster than any
other estimator for all distributions.
The best known tools for black-box estimation of leakage
measures based on the Bayes risk (e.g., min-entropy) are
leakiEst [6], [15] and LeakWatch [5], [16], both based on the
frequentist paradigm. The former also allows a zero-leakage
test for systems with continuous outputs. In section VIII we
provide a comparison of leakiEst with our proposal.
Cherubin [17] used the guarantees of nearest neighbor
learning rules for estimating the information leakage (in terms
of the Bayes risk) of defenses against website ﬁngerprinting
attacks in a black-box manner.
Shannon mutual information (MI) is the main alternative to
the Bayes risk-based notions of leakage in the QIF literature.
Although there is a relation between MI and Bayes risk [18],
the corresponding models of attackers are very different: the
ﬁrst corresponds to an attacker who can try inﬁnitely many
times to guess the secret, while the second has only one try at
his disposal [2]. Consequently, MI and Bayes-risk measures,
such as ME, can give very different results: Smith [2] shows
two programs that have almost the same MI, but one has an
ME several orders of magnitude larger than the other one;
conversely, there are examples of two programs such that ME
is 0 for both, while the MI is 0 in one case and strictly positive
(several bits) in the other one.
In the black-box literature, MI is usually computed by using
Kernel Density Estimation, which although only guarantees
asymptotic optimality under smoothness assumptions on the
distributions. On the other hand, the ML literature offered
developments in this area: Belghazi et al. [19] proposed an
MI lower bound estimator based on deep neural networks,
and proved its consistency (i.e., it converges to the true MI
value asymptotically). Similarly, other works constructed MI
variational lower bounds [20], [21].
III. PRELIMINARIES
We deﬁne a system, and show that
its leakage can be
expressed in terms of the Bayes risk. We then introduce ML
notions, which we will later use to estimate the Bayes risk.
A. Notation
We consider a system (π,Cs,o), that associates a secret input
s to an observation (or object) o in a possibly randomized way.
The system is deﬁned by a set of prior probabilities π(s) :=
P (s), s ∈ S, and a channel matrix C of size |S| × |O|, for
which Cs,o := P (o|s) for s ∈ S and o ∈ O. We call S× O the
example space. We assume the system does not change over
time; for us, S is ﬁnite, and O is ﬁnite unless otherwise stated.
B. Leakage Measures
The state-of-the-art in QIF is represented by the leakage
measures based on g-vulnerability, a family whose most rep-
resentative member is min-vulnerability [2], the complement
of the Bayes risk. This paper is concerned with ﬁnding tight
estimates of the Bayes risk, which can then be used to estimate
the appropriate leakage measure.
a) Bayes risk: The Bayes risk, R
, is the error of the
optimal (idealized) classiﬁer for the task of predicting a secret
s given an observation o output by a system. It is deﬁned with
respect to a loss function (cid:3) : S × S (cid:3)→ R≥0, where (cid:3)(s, s
) is
the risk of an adversary predicting s
for an observation o,
when its actual secret is s. We focus on the 0-1 loss function,
, 0 otherwise.
(cid:3)(s, s
The Bayes risk of a system (π,Cs,o) is deﬁned as:
), taking value 1 if s (cid:5)= s
) := I(s (cid:5)= s
(cid:4)
(cid:4)
(cid:4)
(cid:4)
(cid:4)
∗
∗
R
:= 1 −
Cs,oπ(s) .
(1)
(cid:2)
max
s∈S
o∈O
b) Random guessing: A baseline for evaluating a system
is the error committed by an idealized adversary who knows
priors but has no access to the channel, and who’s best strategy
is to always output the secret with the highest prior. We call
the error of this adversary random guessing error:
Rπ := 1 − max
s∈S
∗
π(s) .
(2)
C. Black-box estimation of R
This paper is concerned with estimating the Bayes risk given
n examples sampled from the joint distribution μ on S × O
generated by (π,Cs,o). By running the system n times on
secrets s1, . . . , sn ∈ S, chosen according to π, we generate
a sequence of corresponding outputs o1, . . . , on, thus forming
a training set2 of examples {(o1, s1), ..., (on, sn)}. From these
data, we aim to make an estimate close to the real Bayes risk.
D. Learning Rules
We introduce ML rules (or, simply, learning rules), which
are algorithms for selecting a classiﬁer given a set of training
examples. In this paper, we will use the error of some ML
rules as an estimator of the Bayes risk.
Let F := {f | f : O (cid:3)→ S} be a set of classiﬁers. A learning
rule is a possibly randomized algorithm that, given a training
set {(o1, s1), ..., (on, sn)}, returns a classiﬁer f ∈ F, with the
goal of minimizing the expected loss E (cid:3)(f (o), s) for a new
example (o, s) sampled from μ [22]. In the case of the 0-1
loss function, the expected loss coincides with the expected
probability of error (expected error for short), and if μ is
2In line with the ML literature, we call the training or test “set” what is
technically a multiset; also, we loosely use the set notation “{}” for both sets
and multisets when the nature of the object is clear from the context.
(cid:25)(cid:20)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:49:33 UTC from IEEE Xplore.  Restrictions apply. 
generated by a system (π,Cs,o), then the expected error of a
classiﬁer f : O (cid:3)→ S is:
Rf = 1 −
Cf (o),oπ(f (o))
(3)
(cid:2)
o∈O
where f (o) is the secret predicted for object o. If O is inﬁnite
(and μ is continuous) the summation is replaced by an integral.
E. Frequentist estimate of R
The frequentist paradigm [13] for measuring the leakage of