 l_linestatus    |           2 |           1
 l_shipdate      |        2491 |           1
 l_commitdate    |        2457 |    0.998449
 l_receiptdate   |        2515 |    0.999927
 l_shipinstruct  |           4 |    0.249326
 l_shipmode      |           7 |    0.141158
 l_comment       | 1.03348e+06 | -0.00203378
(16 rows)
postgres=# select attname,n_distinct,correlation from pg_stats where tablename='orders';
     attname     | n_distinct  | correlation  
-----------------+-------------+--------------
 o_orderkey      |          -1 |   0.00226882
 o_shippriority  |           1 |            1
 o_comment       | 4.36756e+07 |  0.000669195
 o_custkey       | 6.16305e+07 | -0.000200988
 o_orderstatus   |           3 |     0.962756
 o_totalprice    | 3.65714e+07 |   -0.0022367
 o_orderdate     |        2403 |            1
 o_orderpriority |           5 |     0.186165
 o_clerk         |      998950 |  -0.00599872
(9 rows)
```
1、PostgreSQL 10 1TB TPC-H在单机的一组测试数据(SF=1000，即1TB的量)。  
这组测试非常具有代表意义，例如用户每天新增1TB的数据增量，对增量进行统计，生成报表。  
![pic](20170703_01_pic_003.jpg)  
PG 10 分区表的并行度目前不支持alter设置，需要UPDATE PG_CLASS, 例如   
```
update pg_class set reloptions =array['parallel_workers=32'] where relname ~ 'lineitem' and relkind='r';
update pg_class set reloptions =array['parallel_workers=32'] where relname ~ 'orders' and relkind='r';
```
从这组数据来看，日增量1TB的场景中，仅仅使用现有特性，PG已可以应付其OLAP需求。  
如果数据的线性相关性好(pg_stats.correlation接近1或-1)，可以不使用分区表。   
2、另外，在同一主机上，测了一组deepgreen的性能，1TB TPC-H跑完约1小时。（deepgreen是一个完全兼容Greenplum的MPP数据库，在列存储、SQL优化器、JIT、向量计算方面有大幅增强）。  
![pic](20170703_01_pic_001.jpg)  
[deepgreen tpch explain result](20170703_01_explain.tar.bz2)  
为什么要测deepgreen？前面说了在OLAP性能方面，Greenplum已经远超Oracle。而Deepgreen的性能已在Greenplum之上。我们可以将deepgreen作为一个标杆（DP实际上也是基于PG开发的MPP版本），PostgreSQL将来在经过增强后OLAP方面有可能达到甚至超过DP的性能。  
如果PostgreSQL能达到DP的水平，超过Oracle自然没问题（没有对比就没有伤害，读者可以试试同样数据量的Oracle性能）。  
![pic](20170703_01_pic_004.jpeg)  
（PostgreSQL 10目前仅使用了JIT、多核并行、OP复用、分区表、哈希聚合、哈希分组 等若干对OLAP场景有较大性能提升的技术手段，还有列存储、向量计算、appendscan并行等手段可以使用，预计至少还有10倍左右的性能提升空间。）  
### 100TB+, 日增量超过1TB后 - PostgreSQL 黑科技  
除了PG 10已经具备的 JIT，多核并行、OP复用、分区表、哈希聚合、哈希分组，等OLAP场景黑科技，PostgreSQL还有哪些黑科技可用来大幅提升单机OLAP场景的性能？  
#### 1、JIT  
LLVM增强，目前PG 10已整合了JIT框架，但是要支持更多的算子。  
#### 2、向量化  
目前有一个PG插件，可以实现PG的向量计算。  
已支持的向量计算类型如下  
![pic](20170703_01_pic_005.jpg)  
下面是一组使用向量化技术后的性能提升数据。  
```  
postgres=#   \d customer  
                                      Unlogged table "public.customer"  
    Column    |          Type          | Collation | Nullable |                   Default                     
--------------+------------------------+-----------+----------+---------------------------------------------  
 c_custkey    | bigint                 |           | not null | nextval('customer_c_custkey_seq'::regclass)  
 c_name       | character varying(25)  |           |          |   
 c_address    | character varying(40)  |           |          |   
 c_nationkey  | bigint                 |           | not null |   
 c_phone      | character(15)          |           |          |   
 c_acctbal    | double precision       |           |          |   
 c_mktsegment | character(10)          |           |          |   
 c_comment    | character varying(117) |           |          |   
postgres=# create unlogged table vops_customer (c_custkey vops_int8, c_nationkey vops_int8, c_acctbal vops_float8);  
CREATE TABLE  
postgres=# select populate(destination := 'vops_customer', source := 'customer');  
 populate    
-----------  
 150000000  
(1 row)  
postgres=# create unlogged table c as select c_custkey,c_nationkey,c_acctbal from customer;  
SELECT 150000000  
```  
测试时确保数据均在shared buffer中.  
使用向量化前，56秒。    
```  
postgres=# select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),count(*) from c;  
        sum        |          avg          | min |    max    |    sum     |         avg         | min | max |       sum       |   min   |   max   |       avg        |   count     
-------------------+-----------------------+-----+-----------+------------+---------------------+-----+-----+-----------------+---------+---------+------------------+-----------  
 11250000075000000 | 75000000.500000000000 |   1 | 150000000 | 1800117761 | 12.0007850733333333 |   0 |  24 | 675048124067.72 | -999.99 | 9999.99 | 4500.32082711813 | 150000000  
(1 row)  
Time: 55972.494 ms (00:55.972)  
postgres=# explain (analyze,verbose,timing,costs,buffers) select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),count(*) from c;  
                                                                                                         QUERY PLAN                                                                                                           
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=7330421.81..7330421.82 rows=1 width=200) (actual time=57319.855..57319.855 rows=1 loops=1)  
   Output: sum(c_custkey), avg(c_custkey), min(c_custkey), max(c_custkey), sum(c_nationkey), avg(c_nationkey), min(c_nationkey), max(c_nationkey), sum(c_acctbal), min(c_acctbal), max(c_acctbal), avg(c_acctbal), count(*)  
   Buffers: shared hit=955415  
   ->  Seq Scan on public.c  (cost=0.00..2455416.60 rows=150000160 width=24) (actual time=0.012..14185.622 rows=150000000 loops=1)  
         Output: c_custkey, c_nationkey, c_acctbal  
         Buffers: shared hit=955415  
 Planning time: 0.068 ms  
 Execution time: 57319.926 ms  
(8 rows)  
Time: 57320.443 ms (00:57.320)  
```  
使用向量化后，10秒。     
```  
postgres=# select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),countall(*) from vops_customer;   
        sum        |       avg        | min |    max    |    sum     |       avg        | min | max |       sum       |   min   |   max   |       avg        | countall    
-------------------+------------------+-----+-----------+------------+------------------+-----+-----+-----------------+---------+---------+------------------+-----------  
 11250000075000000 | 75000000.4473924 |   1 | 150000000 | 1800117761 | 12.0007850733333 |   0 |  24 | 675048124067.72 | -999.99 | 9999.99 | 4500.32082711813 | 150000000  
(1 row)  
Time: 9785.634 ms (00:09.786)  
postgres=# explain (analyze,verbose,timing,costs,buffers) select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),countall(*) from vops_customer;  
                                                                                                          QUERY PLAN                                                                                                             
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
 Aggregate  (cost=568359.38..568359.39 rows=1 width=104) (actual time=9707.393..9707.393 rows=1 loops=1)  
   Output: sum(c_custkey), avg(c_custkey), min(c_custkey), max(c_custkey), sum(c_nationkey), avg(c_nationkey), min(c_nationkey), max(c_nationkey), sum(c_acctbal), min(c_acctbal), max(c_acctbal), avg(c_acctbal), countall(*)  
   Buffers: shared hit=468750  
   ->  Seq Scan on public.vops_customer  (cost=0.00..492187.50 rows=2343750 width=1584) (actual time=0.008..842.816 rows=2343750 loops=1)  
         Output: c_custkey, c_nationkey, c_acctbal  
         Buffers: shared hit=468750  
 Planning time: 0.073 ms  
 Execution time: 9707.461 ms  
(8 rows)  
Time: 9709.400 ms (00:09.709)  
```  
PG 10采样向量化插件提升了N倍性能，叠加并行化，甚至可以超过DP的性能。  
使用向量化除了性能本身的提升，还可以更好的压缩数据。  
```  
非向量化存储  
postgres=# \dt+ c  
                    List of relations  
 Schema | Name | Type  |  Owner   |  Size   | Description   
--------+------+-------+----------+---------+-------------  
 public | c    | table | postgres | 7464 MB |   
(1 row)  
向量化存储  
postgres=# \dt+ vops_customer   
                         List of relations  
 Schema |     Name      | Type  |  Owner   |  Size   | Description   
--------+---------------+-------+----------+---------+-------------  
 public | vops_customer | table | postgres | 3663 MB |   
(1 row)  
```  
并行叠加向量计算的效果测试。  
PG 10: 439毫秒。   
```
postgres=# set max_parallel_workers_per_gather =48;
SET
postgres=# alter table vops_customer set (parallel_workers =48);
ALTER TABLE
postgres=# explain (analyze,verbose,timing,costs,buffers) select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),countall(*) from vops_customer;  
 Finalize Aggregate  (cost=470827.14..470827.15 rows=1 width=104) (actual time=315.794..315.794 rows=1 loops=1)
   Output: sum(c_custkey), avg(c_custkey), min(c_custkey), max(c_custkey), sum(c_nationkey), avg(c_nationkey), min(c_nationkey), max(c_nationkey), sum(c_acctbal), min(c_acctbal), max(c_acctbal), avg(c_acctbal), countall(*)
   Buffers: shared hit=476862
   ->  Gather  (cost=470825.20..470825.21 rows=48 width=176) (actual time=315.483..315.770 rows=49 loops=1)
         Output: (PARTIAL sum(c_custkey)), (PARTIAL avg(c_custkey)), (PARTIAL min(c_custkey)), (PARTIAL max(c_custkey)), (PARTIAL sum(c_nationkey)), (PARTIAL avg(c_nationkey)), (PARTIAL min(c_nationkey)), (PARTIAL max(c_nationkey)), (PAR
TIAL sum(c_acctbal)), (PARTIAL min(c_acctbal)), (PARTIAL max(c_acctbal)), (PARTIAL avg(c_acctbal)), (PARTIAL countall(*))
         Workers Planned: 48
         Workers Launched: 48
         Buffers: shared hit=476862
         ->  Partial Aggregate  (cost=470825.20..470825.21 rows=1 width=176) (actual time=300.421..300.421 rows=1 loops=49)
               Output: PARTIAL sum(c_custkey), PARTIAL avg(c_custkey), PARTIAL min(c_custkey), PARTIAL max(c_custkey), PARTIAL sum(c_nationkey), PARTIAL avg(c_nationkey), PARTIAL min(c_nationkey), PARTIAL max(c_nationkey), PARTIAL sum(c_
acctbal), PARTIAL min(c_acctbal), PARTIAL max(c_acctbal), PARTIAL avg(c_acctbal), PARTIAL countall(*)
               Buffers: shared hit=468750
               Worker 0: actual time=286.534..286.534 rows=1 loops=1
                 Buffers: shared hit=8616
......
               Worker 46: actual time=310.345..310.345 rows=1 loops=1
                 Buffers: shared hit=9389
               Worker 47: actual time=310.727..310.727 rows=1 loops=1
                 Buffers: shared hit=9280
......
               ->  Parallel Seq Scan on public.vops_customer  (cost=0.00..469238.28 rows=48828 width=1584) (actual time=0.017..114.654 rows=47832 loops=49)
                     Output: c_custkey, c_nationkey, c_acctbal
                     Buffers: shared hit=468750
                     Worker 0: actual time=0.021..107.447 rows=43080 loops=1
                       Buffers: shared hit=8616
                     Worker 1: actual time=0.019..109.747 rows=42325 loops=1
......
                     Worker 47: actual time=0.018..119.142 rows=46400 loops=1
                       Buffers: shared hit=9280
 Planning time: 0.135 ms
 Execution time: 439.027 ms
(208 rows)
```
相对应的deepgreen测试如下: 532毫秒.      
```
postgres=# select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),count(*) from customer;   
        sum        |    avg     | min |    max    |    sum     |       avg        | min | max |       sum        |   min   |   max   |       avg        |   count   
-------------------+------------+-----+-----------+------------+------------------+-----+-----+------------------+---------+---------+------------------+-----------
 11250000075000000 | 75000000.5 |   1 | 150000000 | 1800117761 | 12.0007850733333 |   0 |  24 | 675048124068.057 | -999.99 | 9999.99 | 4500.32082712038 | 150000000
(1 row)
Time: 531.973 ms
postgres=# explain analyze select sum(c_custkey),avg(c_custkey),min(c_custkey),max(c_custkey),sum(c_nationkey),avg(c_nationkey),min(c_nationkey),max(c_nationkey),sum(c_acctbal),min(c_acctbal),max(c_acctbal),avg(c_acctbal),count(*) from customer;   
                                                                 QUERY PLAN                                                                  
---------------------------------------------------------------------------------------------------------------------------------------------
 Aggregate  (cost=7151025.61..7151025.62 rows=1 width=200)
   Rows out:  1 rows with 0.001 ms to first row, 330 ms to end, start offset by 1.624 ms.
   ->  Gather Motion 48:1  (slice1; segments: 48)  (cost=7151025.03..7151025.53 rows=1 width=224)
         Rows out:  48 rows at destination with 458 ms to end, start offset by 1.625 ms.
         ->  Aggregate  (cost=7151025.03..7151025.04 rows=1 width=224)
               Rows out:  Avg 1.0 rows x 48 workers.  Max 1 rows (seg0) with 0.002 ms to first row, 471 ms to end, start offset by 4.299 ms.
               ->  Append-only Columnar Scan on customer  (cost=0.00..2276025.00 rows=3125000 width=24)
                     Rows out:  0 rows (seg0) with 57 ms to end, start offset by 71 ms.
 Slice statistics:
   (slice0)    Executor memory: 443K bytes.
   (slice1)    Executor memory: 18722K bytes avg x 48 workers, 18722K bytes max (seg0).
 Statement statistics:
   Memory used: 128000K bytes
 Settings:  optimizer=off
 Optimizer status: legacy query optimizer
 Total runtime: 789.744 ms
(16 rows)
Time: 791.114 ms
```
![pic](20170703_01_pic_007.jpg)  
PG 10 多核+向量计算组合后，已和Deepgreen的分析性能持平甚至略好。（要知道测试中，PG10 还没有使用正儿八经的列式存储呢，还有提升的潜力。）       
[PostgreSQL VOPS guide](20170703_01_vops.html)  
[PostgreSQL VOPS 向量计算中文guide](../201702/20170225_01.md)  
#### 3、多核并行  