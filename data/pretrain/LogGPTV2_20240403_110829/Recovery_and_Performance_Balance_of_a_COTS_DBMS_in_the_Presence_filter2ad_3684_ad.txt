Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:58 UTC from IEEE Xplore.  Restrictions apply. 
For the faults that require the processing of the archive
log files the recovery time is not influenced by the check-
points frequency, because the recovery starts from a
checkpoint that is not stored in the online redo log files
anymore. In practice, the recovery always starts from the
reposition of database files from a backup. In this case,
the recovery time depends on the size of the archive log
files. Small files tend to increase the recovery time be-
cause a large amount of files have to be processed. In this
case, the best recovery time is obtained for larger files.
Fault Configuration
Recovery time (seconds)
Injection
150 Sec
Injection
300 Sec
Injection
600 Sec
t
r
o
b
a
n
w
o
d
t
u
h
S
e
l
i
f
a
t
a
d
e
t
e
l
e
D
e
n
i
l
f
f
o
e
l
i
f
a
t
a
d
t
e
S
F40G3T10
F40G3T5
F40G3T1
F10G3T5
F10G3T1
F1G6T1
F1G3T1
F1G2T1
F40G3T10
F40G3T5
F40G3T1
F10G3T5
F10G3T1
F1G6T1
F1G3T1
F1G2T1
F40G3T10
F40G3T5
F40G3T1
F10G3T5
F10G3T1
F1G6T1
F1G3T1
F1G2T1
31
28
24
21
19
14
17
18
33
39
32
36
35
59
55
48
10
9
11
6
6
3
4
6
34
31
24
21
22
13
13
17
42
40
43
51
55
109
98
70
11
11
10
4
6
1
1
2
35
34
28
22
22
13
18
16
57
64
64
76
77
191
139
115
17
18
11
7
5
5
4
3
Always close to 1 second
Set tablespace offline
Table 5.Recovery time for faults with complete recov.
A relevant result for the faults that caused incomplete
recovery is that some commited transactions have been
lost. However, the number of lost commited transactions
was constantly very small because the recovery was
always started immediately after the fault occurrence. This
doesn’t happen in the field, because the detection time
may be dependent on the database administrator actions.
In our experiments we assumed a constant (and small)
detection time, as the goal of our work is to assess the
effectiveness of the recovery mechanisms and not the
database administrator
reaction time and capabilities.
Another very important conclusion is that none of the
operator faults caused data integrity violations.
5.3. Results with Stand-by Database
The main goal of the stand-by database is to reduce the
recovery time and, consequently, minimize downtime. The
stand-by database is kept in a permanent recovery state in
which it processes the redo entries in archive logs of the
primary database. For this reason, different configurations
of the archive logs and online redo logs cause different
behaviors on the stand-by database. Furthermore, in addi-
tion to the performance degradation caused by the activa-
tion of the archive logs mechanism, stand-by database also
requires some mean to share archive log files between
both machines, which may also cause some overhead.
Lines in Figure 6 show the performance results for both
the stand-by database and the archive log mechanisms. As
we can see, both the archive logs and the stand-by
database cause a moderate performance impact, which
suggests that performance penalty is not an excuse for not
using these more elaborate Oracle recovery mechanisms.
200
160
120
80
40
0
)
.
c
e
S
(
i
e
m
T
y
r
e
v
o
c
e
R
Archive Logs
Standby DB
Archive Logs
Standby DB
)
C
m
p
t
(
3000
2500
2000
1500
1000
500
0
e
c
n
a
m
r
o
f
r
e
P
0
1
T
3
G
0
4
F
5
T
3
G
0
4
F
1
T
3
G
0
4
F
5
T
3
G
0
1
F
1
T
3
G
0
1
F
1
T
6
G
1
F
1
T
3
G
1
F
1
T
2
G
1
F
Figure 6. Performance and recovery time with archive
logs and stand-by database.
The recovery time in a stand-by database is the same
for all the faults. This is due to the fact that the stand-by
database activation time is independent of the primary
database. Figure 6 shows the recovery times for operator
faults injected 600 seconds after the workload starting. In
order to allow results comparison, Figure 6 also presents
the recovery times obtained in the experiments with the
archive log mechanism for the Delete Datafile fault, injec-
ted 600 seconds after the workload start. As can be seen, a
considerable reduction of the recovery time is achieved.
However, in the stand-by database configuration, if the
primary database current
redo log group cannot be
archived due to the crash of the system, the transactions
associated to the log entries saved on that group are lost,
and the corresponding commited transactions cannot be
recovered. To reduce the number of lost redo log entries,
the size of the redo log files must be the as small as
possible. Figure 7 shows the results concerning the lost
transactions using different
redo log files sizes and
different number of redo log groups.
5000
4000
3000
2000
1000
0
s
n
o
i
t
c
a
s
n
a
r
T
t
s
o
L
#
0
1
T
3
G
0
4
F
5
T
3
G
0
4
F
1
T
3
G
0
4
F
5
T
3
G
0
1
F
1
T
3
G
0
1
F
1
T
6
G
1
F
1
T
3
G
1
F
1
T
2
G
1
F
Figure 7. Lost transactions in the stand-by database.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:58 UTC from IEEE Xplore.  Restrictions apply. 
6. Conclusion
This paper proposes an experimental approach to
characterize both the performance and the recoverability
in DBMS by extending the standard TPC-C benchmark to
include two new elements: a faultload based on operator
faults and measures related to recoverability. Given the
rather artificial performance results achieved by typical
performance benchmarks (because normally do not take
into account
the balance between performance and
recoverability) we think that this kind of benchmarks is
very useful to characterize DBMS in realistic scenarios.
the same environment can be used to
Additionally,
characterize
recovery mechanisms
in
DBMS, including measures such as recovery time, data
integrity violations, and lost transactions.
configurations
The paper also proposes a classification of operator
faults for DBMS, and defines a comprehensive set of
types of operator faults. A set of tools have been designed
and built to reproduce operator faults in Oracle DBMS,
which is, to the best of our knowledge, the first proposal
of an environment to inject operator faults in DBMS.
The experimental results obtained by extending the
TPC-C benchmark with our approach were analyzed and
discussed in detail. These results clearly show that
recovery mechanisms do affect peak performance but, at
the same time, show that it is possible to configure the
Oracle DBMS to get good recovery features with
moderate or even minimal performance impact. In our
opinion, it would be difficult to characterize these well-
balanced configurations without an experimental approach
such as the one proposed in this paper.
7. References
[1] Transaction Processing Performance Consortium, “TPC
Benchmark C, Standard Specification, Version 5.0,” 2001,
available at: http://www.tpc.org/tpcc/.
[2] S. Bagchi, Y. Liu, K. Whisnant, Z. Kalbarczyk, R. Iyer, Y.
Levendel, “A Framework for Database Audit and Control Flow
Checking for a Wireless Telephone Network Controller”, Proc.
of the 2001 Intl. Conference on Dependable Systems and
Networks, Gotheburg, Sweden, 1-4 July, 2001, pp.225-234.
[3] W. T. Ng and P. M. Chen, “Integrating Reliable Memory in
Databases”, In Proceedings of the 1997 Intl. Conf. on Very
Large Databases (VLDB), pages 76-85, August 1997.
[4] S.Chandra and Peter M.Chen, "How Fail-Stop are Faulty
Programs?", 28th International Symposium on Fault-Tolerant
Computing, Munich, Germany,1998, pp. 240-249.
[5] M. Sabaratnam, Ø. Torbjørsen
and S.Hvasshovd,
“Evaluating the Effectiveness of Fault Tolerance in Replicated
Database Management
29th
International Symposium on Fault-Tolerant Computing, June
15-18, Madison, Wisconsin, 1999, pp. 306-313.
Proceedings
Systems”,
of
a
case
study of
and
P. Koopman,
for Database
(Addison-Wesley Publishing Company, 1990),
[6] D. Costa, T. Rilho, and H. Madeira, “Joint Evaluation of
Performance and Robustness of a COTS DBMS Through Fault-
Injection”,
IEEE/IFIP Dependable Systems and Networks
Conference – DSN (FTCS-30 e DCCA-8), New York, USA, 25-
28 June, 2000, pp. 251-260.
[7] Aaron Brown and David Patterson, "Towards availability
benchmark:
software RAID systems",
Proceedings of 2000 USENIX Annual Technical Conference,
San Diego, California, USA, June 18-23, 2000, pp 263-276.
“Dependability
[8] H. Madeira
Benchmarking: making choices in an n-dimensional problem
space”, First Workshop on Evaluating and Architecting System
Dependability (EASY), DSN-2001, Göteborg, Sweden, July 1,
2001.
[9] K. Kanoun, J. Arlat, D. Costa, M. Dal Cin, P. Gil, J-C.
Laprie, H. Madeira, and N. Suri, “DBench: Dependability
Benchmarking”, in Suppl. of the Int. Conference on Dependable
Systems and Networks, DSN-2001, Chalmers University of
Technology, Göteborg, Sweden, 2001, pp. D.12-D.15.
[10] R. Ramakrishnan, “Database Management Systems” second
edition, McGraw Hill, ISBN 0-07-232206-3.
[11] E. F. Codd, "A Relational Model of Data for Large Shared
Data Banks ", Communications of the ACM (1970).
[12] E. F. Codd, The Relational Model
Management
ISBN 0-201-14192-2.
[13] C. J. Date and Hugh Darwen, “The SQL Standard”, Third
Edition (Addison-Wesley Publishing Company, 1993), 414
pages; paperbound; ISBN 0-201-55822-X.
[14] J. Gray and A. Reuter, “Transaction Processing: Concepts
and Techniques”, The Morgan Kaufmann Series in Data
Management Systems, Jim Gray, Series Editor 1993, ISBN 1-
55860-190-2.
[15] Oracle Corp., "Oracle 8i Server Concepts Manual", 1999.
[16] J. Gray, “A Census of Tandem Systems Availability
Between 1985 and 1990”, IEEE Transactions on Reliability,
Vol. 39, No. 4, pp. 409-418, October 1990.
[17] M. Sullivan and R. Chillarege, “Comparison of Software
Defects in Database Management Systems and Operating
Systems”, Proceedings of
the 22nd IEEE Fault Tolerant
Computing Symp., FTCS-22, pp. 475-484, July 1992.
[18] I. Lee and R. K. Iyer, “Software Dependability in the
Tandem GUARDIAN System”, IEEE Transactions on Software
Engineering, Vol. 21, No. 5, pp. 455-467, May 1995.
[19] M. Kalyanakrishnam, Z. Kalbarczyk, R. Iyer, ”Failure Data
Analysis of a LAN of Windows NT Based Computers”,
Symposium on Reliable Distributed Database Systems,
SRDS18, October, Switzerland, pp. 178-187, 1999.
[20]
Survey Results”,
http://www.sunbelt-software.com/ntrelres3.htm, March,23, 1999
[21] J. Christmansson and R. Chillarege, “Generation of an
Error Set that Emulates Software Faults”, Proceedings of the
26th IEEE Fault Tolerant Computing Symposium, FTCS-26,
Sendai, Japan, pp. 304-313, June 1996.
[22] H. Madeira, M. Vieira and D. Costa, “On the Emulation of
Software Faults by Software Fault Injection”, Int. Conf. on
Dependable Systems and Networks, New York, USA, June,
2000, pp. 417-426.
“NT Reliability
Sunbelt
Int.,
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:58 UTC from IEEE Xplore.  Restrictions apply.