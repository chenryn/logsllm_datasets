title:DDoS defense by offense
author:Michael Walfish and
Mythili Vutukuru and
Hari Balakrishnan and
David R. Karger and
Scott Shenker
DDoS Defense by Offense
Michael Walﬁsh∗, Mythili Vutukuru∗, Hari Balakrishnan∗, David Karger∗, and Scott Shenker†
MIT, {mwalﬁsh,mythili,hari,karger}@csail.mit.edu
†
∗
UC Berkeley and ICSI, PI:EMAIL
ABSTRACT
This paper presents the design, implementation, analysis, and ex-
perimental evaluation of speak-up, a defense against application-
level distributed denial-of-service (DDoS), in which attackers crip-
ple a server by sending legitimate-looking requests that consume
computational resources (e.g., CPU cycles, disk). With speak-up,
a victimized server encourages all clients, resources permitting, to
automatically send higher volumes of trafﬁc. We suppose that at-
tackers are already using most of their upload bandwidth so cannot
react to the encouragement. Good clients, however, have spare up-
load bandwidth and will react to the encouragement with drastically
higher volumes of trafﬁc. The intended outcome of this trafﬁc inﬂa-
tion is that the good clients crowd out the bad ones, thereby captur-
ing a much larger fraction of the server’s resources than before. We
experiment under various conditions and ﬁnd that speak-up causes
the server to spend resources on a group of clients in rough pro-
portion to their aggregate upload bandwidth. This result makes the
defense viable and effective for a class of real attacks.
[Computer-
INTRODUCTION
Categories
and Subject Descriptors: C.2.0
Communication Networks]: Security and protection
General Terms: Design, Experimentation, Security
Keywords: DoS attack, bandwidth, currency
1
Our goal is to defend servers against application-level Distributed
Denial of Service (DDoS), a particularly noxious attack in which
computer criminals mimic legitimate client behavior by send-
ing proper-looking requests via compromised and commandeered
hosts [10, 18, 36, 37]. By exploiting the fact that many Internet
servers have “open clientele” (i.e., they cannot tell a good client
from the request alone), the attacker forces the victim server to
spend much of its resources on spurious requests. For the savvy
attacker, the appeal of this attack over a classic ICMP link ﬂood
is two-fold. First, it requires far less bandwidth: the victim’s com-
putational resources—disks, CPUs, memory, application server li-
censes, etc.—can often be depleted by proper-looking requests long
before its access link is saturated. Second, because the attack trafﬁc
is “in-band”, it is harder to identify and thus more potent. Examples
of such (often extortionist [30,44]) attacks include using bots to at-
tack Web sites by: requesting large ﬁles [36, 37], making queries
of search engines [10], and issuing computationally expensive re-
quests (e.g., database queries or transactions) [21].
Current DDoS defenses try to slow down the bad clients. Though
we stand in solidarity with these defenses in the goal of limiting
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM ’06, September 11–15, 2006, Pisa, Italy.
Copyright 2006 ACM 1-59593-308-5/06/0009 . . . $5.00.
the service that attackers get, our approach is different. We rely
on encouragement (a term made precise in §3), whereby the server
causes a client, resources permitting, to automatically send a higher
volume of trafﬁc. Our approach is to encourage all clients to speak
up, rather than sit idly by while attackers drown them out. For if,
as we suppose, bad clients are already using most of their upload
bandwidth, then encouragement will not change their trafﬁc vol-
ume. However, the good clients typically use only a small fraction
of their available bandwidth to send requests, so they will react to
encouragement by drastically increasing their trafﬁc volume. As
good clients send more trafﬁc, the trafﬁc into the server inﬂates,
but the good clients will be much better represented in the mix and
thereby capture a much larger portion of the server than before.
Of course, this caricature of our approach leaves many mech-
anisms unmentioned and myriad issues unaddressed. The purpose
of this paper is to bring the preceding high-level description to life
with a viable and effective system. To that end, we describe the
design, prototype implementation, and evaluation of speak-up, a
defense against application-level DDoS attacks in which clients are
encouraged to send more trafﬁc to an attacked server.
We put our approach in context with the following taxonomy of
defenses:
Over-provision massively.
In theory, one could purchase
enough computational resources to serve attackers and good
clients. However, anecdotal evidence suggests that while sites pro-
vision additional link capacity during attacks [33], even the largest
Web sites try to conserve computation by detecting and denying
access to bots [30, 42] using the methods in the next category.
Detect and block. These approaches try to distinguish between
good and bad clients. Examples are proﬁling by IP address [5,9,27]
(a box in front of the server or the server itself admits requests ac-
cording to a learned demand proﬁle); rate-limiting alone (a special
case of proﬁling in which the acceptable request rate is the same for
all clients); CAPTCHA-based defenses [16,21,29,42,47] that pref-
erentially admit humans; and capabilities [4, 50, 51] (the network
allows only trafﬁc that the recipient has authorized). These tech-
niques are powerful because they seek to block or explicitly limit
unauthorized users, but their discriminations can err (see §8.1).
Moreover, they cannot easily handle heterogeneous requests (i.e.,
those that cause the server to do different amounts of work). The
next category addresses these limitations.
Charge all clients in a currency. Here, an attacked server gives
a client service only after it pays in some currency. Examples are
CPU or memory cycles (evidence of payment is the solution to a
computational puzzle) [1, 6, 7, 11, 12, 20, 25, 49] and money [25].
With these defenses, there is no need to discriminate between good
and bad clients, and the server can require a client to pay more
for “hard” requests. However, for the legitimate users to capture
the bulk of the service, they must in aggregate have more of the
currency than the attackers.
In this taxonomy, speak-up is a currency approach with bandwidth
as the currency. We believe that this work is the ﬁrst to investigate
this idea (though it was proposed in a workshop paper by us [48]
and [17, 39] share the same high-level motivation; see §8.1).
The central mechanism in speak-up is a server front-end, the
thinner, that protects the server from overload and performs encour-
agement (§3). Encouragement can take several forms (§3.2, §3.3).
The one that we implement and evaluate is a virtual auction: when
the server is overloaded, the thinner causes each new client to auto-
matically send a congestion-controlled stream of dummy bytes on
a separate payment channel, and when the server is ready to pro-
cess a request, the thinner selects the client that has sent the most
bytes (§3.3). We show that the ability to “game” this scheme is lim-
ited (§3.4). We also design an extension of the thinner to handle
heterogeneous requests (§5).
As a concrete instantiation of speak-up, we implemented the
thinner as a Web front-end (§6). The thinner performs encourage-
ment by giving JavaScript to unmodiﬁed Web clients that makes
them send large HTTP POSTs. These POSTs are the “bandwidth
payment”. We ﬁnd that this implementation meets our goal of al-
locating the protected server’s resources in rough proportion to
clients’ upload bandwidth (§7). Despite being unoptimized, the im-
plementation sinks 1.5 Gbits/s on a high-end PC.
Practical DDoS mitigation requires multiple techniques, and
speak-up is not intended to stand alone. In §8, we compare speak-
up to other defenses and discuss when it should work with them.
2 APPLICABILITY OF SPEAK-UP
Before describing speak-up’s design, we discuss under what condi-
tions and to what extent speak-up is useful. We start by informally
addressing four commonly asked questions and then characterize
our threat model and speak-up’s range of applicability.
2.1 Four Questions
How much aggregate bandwidth does the legitimate clientele need
for speak-up to be effective? Speak-up helps good clients, no matter
how much bandwidth they have. Speak-up either ensures that the
good clients get all the service they need or increases the service
they get (compared to an attack without speak-up) by the ratio of
their available bandwidth to their current usage, which we expect to
be very high. Moreover, as with many security measures, speak-up
“raises the bar” for attackers: to inﬂict the same level of service-
denial on a speak-up defended site, a much larger botnet—perhaps
several orders of magnitude larger—will be required. Similarly, the
amount of over-provisioning needed at a site defended by speak-up
is much less than what a non-defended site would need.
Thanks for the sales pitch, but what we meant was: how much ag-
gregate bandwidth does the legitimate clientele need for speak-up
to leave them unharmed by an attack? The answer depends on
the server’s spare capacity (i.e., 1−utilization) when unattacked.
Speak-up’s goal is to allocate resources in proportion to the band-
widths of requesting clients. If this goal is met, then for a server
with spare capacity 50%, the legitimate clients can retain full ser-
vice if they have the same aggregate bandwidth as the attacking
clients (see §3.1). For a server with spare capacity 90%, the legiti-
mate clientele needs only 1/9th of the aggregate bandwidth of the
attacking clients.
We now put these results in the context of today’s botnets by
ﬁrst noting that most botnets today are less than 100,000 hosts, and
even 10,000 hosts is a large botnet [18, 19]. (Supporting evidence
for these sizes is as follows. One study found that the average bot
has roughly 100 Kbits/s of bandwidth [40]. If each bot uses half
its bandwidth during an attack, then a 10,000-node botnet gener-
ates 500 Mbits/s of trafﬁc, and a 100,000-node botnet generates 5
Gbits/s of trafﬁc. These numbers are above, respectively, the 80th
percentile and 99th percentile of attack sizes observed in [38].) Sec-
ond, assume that the average good client also has 100 Kbits/s of
bandwidth. Then for a service whose spare capacity is 90%, speak-
up can fully defend it (i.e., leave its good clients unharmed) against
a 10,000-host (resp., 100,000-host) botnet if the good clients num-
ber ∼1,000 (resp., ∼10,000).
We believe that these orders of magnitude are not larger than
the clientele of the Web’s largest sites: these numbers refer to the
good clients currently interested in the service, many of which may
be quiescent. For example, consider search engines. Humans paus-
ing between queries count in the “current clientele”, and there are
almost certainly thousands of such users at any time for the large
search engines.
Then couldn’t small Web sites, even if defended by speak-up, still be
harmed? Yes. For botnets of the sizes just mentioned (and for the
small number of even larger ones [18, 19, 43]), speak-up-defended
sites need a large clientele or vast over-provisioning to fully with-
stand attack. However, we think that future botnets will be smaller.
Our rationale is as follows. Today, sites can recognize primitive
bots. Such bots launch attacks too quickly, and sites block them by
proﬁling IP addresses. To evade these defenses, bots will eventually
become more sophisticated, for example by building up an activity
proﬁle at a given Web site and then ﬂying under the proﬁling radar
during an attack. At this point, it will be hard for sites to identify
and block the bots. However, ISPs, which can observe their hosts
over long periods of time, will still be able to identify bots. Indeed,
we speculate that once sites no longer have effective defenses, so-
ciety (governments, public and industry pressure, etc.) will force
ISPs to act, thereby reducing the number of bots (but not elim-
inating them—bot identiﬁcation is not a precise science). When
attackers adapt to having fewer but smarter bots, application-level
attacks—which require smart bots but conserve resources—will be
more common, making speak-up more broadly applicable.
Because bandwidth is in part a communal resource, doesn’t the
encouragement to send more trafﬁc damage the network? We ﬁrst
observe that speak-up inﬂates trafﬁc only to servers currently un-
der attack—a very small fraction of all servers—so the increase in
total trafﬁc will be minimal. Moreover, the “core” appears to be
heavily over-provisioned (see, e.g., [15]), so it could absorb such
an increase. Finally, speak-up’s additional trafﬁc is congestion-
controlled and will share fairly with other trafﬁc. We address this
question more fully in §4 and other issues raised by speak-up in §9.
2.2 Threat Model and Applicability Conditions
The preceding informal discussion gave a general picture of speak-
up’s applicability. We now give a more precise description, begin-
ning with the threat model. Speak-up aims to protect a server, de-
ﬁned as any network-accessible service with scarce computational
resources (disks, CPUs, RAM, application licenses, ﬁle descriptors,
etc.), from an attacker, deﬁned as an entity (human or organization)
that is trying to deplete those resources with legitimate-looking re-
quests (database queries, HTTP requests, etc.). Such an assault is
called an application-level attack [18].
Each attacker sends trafﬁc from many compromised hosts, and
this trafﬁc obeys all protocols, so the server has no easy way to tell
from a single request that it was issued with ill intent. Most services
handle requests of varying difﬁculty (e.g., database queries with
very different completion times). While servers may not be able to
determine a request’s difﬁculty a priori, our threat model presumes
that the attacker can send difﬁcult requests intentionally.
One reason that application-level attacks are challenging to
thwart is that the Internet has no robust notion of host iden-
tity. For datagram protocols without three-way handshakes (e.g.,
DNS-over-UDP), spooﬁng is trivial, and even for protocols
with three-way handshakes, spooﬁng is possible. (Such spurious
handshakes—observed before [41] and correlated with spam trans-
missions [34]—work because many ISPs accept spurious BGP
routes and propagate them to other ISPs [14].) Since a determined
attacker can repeatedly request service from a site while pretending
to have different IP addresses, we assume that an abusively heavy
client of a site will not always be identiﬁable as such.
We are not considering link attacks. We assume that the server’s
access links (and, more generally, the network infrastructure) are
not ﬂooded; see condition C1 below.
There are many types of Internet services, with varying defen-
sive requirements; speak-up is not appropriate for all of them. For
speak-up to defend against the threat modeled above, the following
two conditions must hold:
C1 Adequate link bandwidth. The protected service needs
enough link bandwidth to handle the incoming request stream
(and this stream will be inﬂated by speak-up). A server can
satisfy this condition via a high-bandwidth access link or co-
location at a data center. However, we expect the more com-
mon deployment to be ISPs—which of course have signiﬁ-
cant bandwidth—offering speak-up as a service (just as they
do with other DDoS defenses today), perhaps amortizing the
expense over many defended sites, as suggested in [2].
C2 Adequate client bandwidth. To be unharmed during an at-
tack, the good clients must have in total roughly the same
order of magnitude (or more) bandwidth than the attacking
clients. As argued in §2.1, this property holds for some sites
today, and we expect it to hold for many more in the future.
Furthermore, speak-up offers advantages over alternate defenses
when all of the following also hold:
C3 No pre-deﬁned clientele. Otherwise, the server can install
ﬁlters or use capabilities [4,50,51] to permit only trafﬁc from
known clients.
C4 Non-human clientele. If the clientele is exclusively human,
one may be able to use proof-of-humanity tests (e.g., [16, 21,