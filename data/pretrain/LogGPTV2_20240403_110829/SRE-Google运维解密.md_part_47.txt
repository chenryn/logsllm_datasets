我们使用一种称为自适应节流的技术来实现客户端节流。具体地说，每个客户端记录过
已生成请求的数量。超过这个请求数量限制的请求直接在本地回复失败，而不会真正发
大部分都是由于“配额不足”错误导致时，该客户端开始自行限制请求速度，限制它自
客户端侧的节流机制可以解决这个问题1。当某个客户端检测到最近的请求错误中的一
有可能该后端在忙着不停地发送拒绝回复时一样会进入过载状态。
就算在某些情况下，拒绝请求可以节省大量资源，发送这些拒绝回复仍然会消耗一定数
耗内存差不多（因为这里主要的消耗是在应用层协议解析中，结果的产生部分很简单）。
不适用于所有请求。例如，拒绝一个执行简单内存查询的请求可能跟实际执行该请求消
类型的错误，该回复应该比真正处理该请求所消耗的资源少得多。然而，这种逻辑其实
客户端侧的节流机制
个请求的不同阶段。
线程”模式设计的软件服务器尤其困难，这种软件用非阻塞API和线程池模式来处理每
时计算每个请求所消耗的资源（尤其是CPU）。这种计算对某些不是按“每个请求一个
我们在后端任务中写了相当多的代码来做到这一点。这里比较有趣的一个技术难点是实
送给每个后端任务。该系统的实现细节，已经超出了本书讨论的范围，但是可以说的是，
我们随后从所有的后端任务中实时获取用量信息，并且使用这些数据将配额调整信息推
这是因为所有用户都同时将他们的资源配额用满是一种非常罕见的情况。
这里要注意的是，上述这些数字的总和会超过该后端服务总共分配的10000CPU容量，
它们的每用户限额可能与下面的类似：
例如，如果一个后端服务在全世界范围内分配了10.000个CPU（分布在多个数据中心中），
个合理的使用约定，同时使用这个约定来配置用户配额，并且配置相应的资源。
到网络层。
量的资源。如果拒绝回复的数量也很多，这些资源消耗可能也十分可观。在这种情况下，
当某个用户超过资源配额时，后端任务应该迅速拒绝该请求，返回一个“用户配额不足”
●邮件服务（Gmail）允许使用4.000CPU（每秒使用4,000个CPU）。
其他用户允许使用500CPU
Google+允许使用2.000CPU
安卓服务（Android）允许使用3.000CPU
日历服务（Calendar）允许使用4,000CPU
第21章
应对过载
---
## Page 257
户端的请求之后，所有客户端检测到这个变化的耗时就会减小。
后端资源，但是却加快了后端状态到客户端的传递速度。举例来说，后端停止拒绝该客
*accepts，那么就意味着每10个后端请求之中只有1个会被拒绝。
算法的accepts的倍值K（例如，2）就可解决
来发送拒绝请求可能是不合理的。在这种情况下，解决方案很简单：通过修改客户端中
对那些处理请求消耗的资源和拒绝请求的资源相差无几的系统来说，允许用50%的资源
赖，也不会影响延迟。
优势是客户端完全依靠本地信息来做出决定，同时实现算法相对简单：不增加额外的依
即使在超大型的过载情况下，后端服务基本上可以保持50%的处理率。这个方式的一大
我们发现自适应节流算法在实际中效果良好，可以整体上保持一个非常稳定的请求速率
本地丢弃请求的概率。
点。随着客户端发送请求的速度加快（相对后端接受请求的速度来说），我们希望提高
看起来有点反直觉，因为本地拒绝的请求实际没有到达后端，但这恰恰是这个算法的重
当客户端开始自己拒绝请求时，requests会持续上升，而继续超过accepts。这里虽然
概率使用公式21-1进行计算：
限制，客户端开始自行节流，新的请求会在本地直接以一定概率被拒绝（在客户端内部），
在常规情况下，这两个值是相等的。随着后端任务开始拒绝请求，请求接受数量开始比
请求接受数量（accepts）
请求数量（requests）
去两分钟内的以下信息：
一般来说推荐采用K=2，通过允许后端接收到比期望值更多的请求，浪费了一定数量的
举例来说，
公式21-1：客户端请求拒绝概率
后端任务接受的请求数量。
应用层代码发出的所有请求的数量总计(指运行于自适应节流系统之上的应用代码)。
降低该倍值会使自适应节流算法更加激进。
增加该倍值会使该算法变得不再那么激进。
，假设将客户端请求的上限从request=2*accepts调整为request=1.1
requests+1
客户端侧的节流机制
215
251
---
## Page 258
252
216
我们同时增强了RPC系统，可以自动传递重要性信息。如果后端接收到请求A，在处理
些搜索请求的可丢弃性非常强（如果系统处于过载状态，这些结果也可以不显示），但
我们将重要性属性当成RPC系统的一级属性，花费了很多工夫将它集成进我们的很多控
可丢弃的SHEDDABLE
可丢弃的SHEDDABLE_PLUS
重要CRITICAL
最重要CRITICAL_PLUS
端的请求都会被标记为以下4类中的一种，这说明了请求的重要性。
重要性（criticality）是另外一个在全局配额和限制机制中比较有用的信息。某个发往后
重要性
客户端对后端状态的记录非常有限，任何想提高状态可见度的手段相对来说成本都较高。
是这些请求的延迟性仍然要求很高。
关的。例如，当系统在用户输入搜索请求词语过程中实时显示搜索结果或者建议时，这
请求的优先级和该请求的延时性要求，也就是底层的网络服务质量（QoS）信息是不相
制手段中，以便这些系统在处理过载情况下可以使用该信息。例如：
类，以便更细粒度地描述请求。但是增加额外的值需要增加处理这些信息的系统所需资源。
我们发现以上4种分类可以描述大部分服务。我们曾经数次讨论过在中间增加更多的分
另外一个考量是，客户端节流可能不适用于那些请求频率很低的客户端。在这种情况下，
这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用。
PLUS流量配置相应的资源。
生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题，但是可能
为最重要的请求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。
·自适应节流系统也会根据每个优先级分别计数。
请求通常可以过几分钟，或者几小时之后重试。
这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些
没有CRITICAL_PLUS那么严重。我们要求服务必须为所有的CRITICAL和CRTICAL
当某个任务开始进入过载状态时，低优先级的请求会先被拒绝。
际上，全局配额系统是可以按重要性分别设置的）。
当某个客户全局配额不够时，后端任务将会按请求优先级顺序分级拒绝请求（实
第21章
应对过载
---
## Page 259
信息时应该如何应对。在过载错误中，我们区分下列两种可能的情况：
在服务器端妥善处理过载请求之外，我们还仔细思考了在客户端接收到过载相关的错误
处理过载错误
阈值的时候开始拒绝请求。
该系统还可以配置为同时使用多个信号，并且在超过综合（或者某个独立）目标利用率
端任务的内存使用率是否已经超出了正常运行范围—作为另一个可能的利用率信号。
人后端自己定义的任意资源利用率信号。例如，我们可能会使用内存压力一表明了后
虽然将执行器负载均值用在实践中被证实是一个非常有用的信号，但我们的系统可以接
的水平），这些任务会开始拒绝请求。
上会将这个突发情况处理掉。但是如果这些请求不是短时的（负载值长时间保持在较高
求被展开成突发性的大批短时请求），会导致负载值急剧上升，但是这个平滑过程基本
数量时开始拒绝请求。这意味着，当某个请求展开成非常大量的请求时（例如，某个请
衰变算法（exponential decay）来平滑这个值，当活跃线程数量超过该任务分配的CPU
正在运行，
要计算执行器负载均值，我们要统计整个进程中的活跃线程数。在这里，“活跃”指那些
载”，这是通过一个所谓的执行器负载均值（executorload average）决定的。
保护任务自身），针对不同的信号有具体的实现。
我们使用的资源利用率信号是完全基于本地信息计算的（因为这个信号的作用就是为了
的重要性来拒绝一些请求（高重要性的请求对应高阈值）。
某些情况下，同时也会考虑内存的使用率。随着资源利用率的上升，我们开始根据请求
率仅仅是指目前CPU的消耗程度（目前CPU使用量除以全部预留CPU数量）。但是在
我们的任务过载保护是基于资源利用率（utilization）实现的。在多数情况下，资源利用
资源利用率信号
以在特殊情况下在处理栈的某处覆盖优先级设置。
览器或者客户端最近的地方设置优先级——通常在HTTP前端服务器上。同时，我们可
确的优先级来拒绝请求，不论它们处于整个处理栈中多深的位置。于是我们一般在离浏
定节点处统一设置重要性属性。这意味着，我们相信依赖的服务在过载情况下可以按正
是通常不能跨服务兼容。通过标准化和在RPC系统中自动传递，我们现在可以在某些特
在过去一段时间内，Google内部的许多系统都逐渐产生了一种与重要性类似的属性，
过程中发出了请求B和C给其他后端，请求B和C会使用与A相同的重要性属性。
，或者已经准备好运行，但是正在等待空闲CPU的线程。我们同时利用指数性
一个比较有用的信号是基于进程的“负
处理过载错误
217
253
---
## Page 260
255
218
个请求在这个比例低于10%的时候才会重试。这里的逻辑是，如果仅仅只有一小部分任
第二，我们实现了一个每客户端的重试限制。每个客户端都跟踪重试与请求的比例。
数据中心中的一小部分后端任务处于过载状态
务处于过载状态，那么重试数量应该是相对较小的。
任务，再重试也很可能无济于事，这时整个数据中心可能都处于过载状态。
我们会将该错误回应给调用者。这里的逻辑是指，如果一个请求已经三次选择了过载的
第一，我们增加了每次请求重试次数限制，限制重试3次。某个请求如果已经失败3次，
量后端任务过载的情况有几个方法来避免进行重试。
决定何时重试
移给其他的任务。
待重试请求和新请求事实上形成了一种天然的负载均衡机制：可以将多余的负载自动转
然是最好的选择。这些请求可以立刻在另外一个可能有空余资源的任务上重试。同等对
就算某个后端任务只是轻微过载，如果后端请求将重试和新请求同等对待，快速拒绝仍
从负载均衡策略的角度看，重试请求和新请求是无法区分的。也就是说，我们并不会使
况下，重试某个请求造成的延时一
用的后端在另外一个大陆上），但是我们往往可以用其他手段解决这个问题。在这种情
请求发往最近的数据中心。在特殊情况下，最近的数据中心仍然很远（如某个客户端可
们更倾向于立即重试该请求。一般来说，我们的跨数据中心负载均衡系统试图将客户端
者（例如，向最终用户发送一个错误信息）。在更常见的、小部分任务过载的情况下，我
如果大部分后端任务都处于过载状态，请求应该不再重试，而应该一直向上传递给请求
数据中心中的大量后端任务都处于过载状态
的API复杂度无谓地提高。
的情况下，这个“概率”本身就很大。增加新的逻辑确保请求发往不同的后端会将我们
用任何特殊的逻辑来保证某个重试请求真的会发往另外一个后端任务。在后端数量较多
这种情况一般是由负载均衡系统的不完美造成的。例如，某个任务可能最近接收到
如果跨数据中心负载均衡系统正在正常运行（意味着它可以传递状态，并且实时调
可以处理该请求。
了一个处理成本巨大的请求。在这种情况下，很有可能该数据中心仍然有其他容量
度流量），这种情况应该不会出现。
第21章应对过载
一般是几个网络RTT一
一基本上是可以忽略的。
---
## Page 261
个大型的重试爆炸。
无法被处理，同时不应该被重试时，返回一个“过载；无须重试”错误，以避免触发一
这种架构下，请求只应该在被拒绝的层面上面的那一层进行重试。当我们决定某个请求
Google的大型服务通常是由一个层次很深的系统栈组成的，这些系统可能互相依赖。在
图21-1：不同情况下的请求直方图
能会影响这些数据。
试限制被忽略了（这些数据假设唯一的限制是每个请求重试3次），同时后端子集也可
据一个滑动窗口计算的（1000个初始请求，不计算重试）。为了更简单，这里客户端重