Consider
the mechanism that outputs
from the Laplace
t1, t2, · · · , tk in the dataset by adding to it
drawn
Pr[Lap(β) = x] = 1
UDP. Now consider the event S = k, we have Pr[S|t1]
Therefore, Pr[S|t1]
This satisﬁes ǫ-positive
ekǫ .
, which can get arbitrarily close
ǫ(cid:1), where
Pr[S|¬t1] = 1
Lap(cid:0) 1
2β e−|x|/β.
distribution
1
Pr[t1] =
p+(1−p) 1
ekǫ
to ekǫ by choosing very small p. Thus, for any γ  γ, violating γ-PMP.
Similar to Theorem 4.5, we can show that ǫ-negative UDP is
equivalent to (DI , eǫ)-NMP. We omit the proof here.
4.2 Bounded Differential Privacy
We now consider how BDP relates to membership privacy. We
ﬁrst note that unlike the unbounded version of differential privacy,
BDP has a symmetry to it and cannot be decomposed into a positive
condition and a negative condition.
Because BDP only requires closeness in output distributions a-
mong datasets of the same size, we must limit to distributions where
all datasets that have non-zero probabilities have the same number
of entities. We introduce the following two families.
DISTRIBUTION FAMILY 4.6. DB: Bounded Mutually Inde-
pendent (BMI) Distributions. We say a distribution is a BMI distri-
bution if it is the conditional distribution of a mutually independent
distribution given that all datasets with non-zero probability has
the same size. DB includes all such BMI distributions.
DISTRIBUTION FAMILY 4.7. D2
B: 1-out-of-2 BMI Distribu-
tions. We say a BMI distribution is a 1-out-of-2 BMI distribution
if each distribution has exactly two datasets with nonzero proba-
bility. That is, all except for two entities have probability of either
1 or 0, and it is required that the size of the sampled dataset is
1 + |{t| Pr[t] = 1}|.
By Deﬁnition, ǫ-BDP is equivalent to satisfying Pr[S|t]
B. Thus, ǫ-BDP is equivalent to (D2
Pr[S|¬t] ≤ eǫ
for distributions in D2
B, eǫ)-
PMP (from Theorem 3.6). The following theorem shows that ǫ-
BDP achieves PMP for all distributions in DB.
THEOREM 4.8. A mechanism A satisﬁes ǫ-BDP if and only if it
provides (DB, eǫ)-PMP.
PROOF. The “if” direction follows straightforwardly from the
fact that ǫ-BDP is equivalent to D2
B and that D2
B ⊂ DB.
For the “only if” direction, similar to the proof of the unbounded
Pr[S|¬t] ≤ eǫ assum-
case, we would show that for any t, we have Pr[S|t]
ing that we have (DB, eǫ)-PMP.
Let T2 range over all datasets such that |T2| = k − 1 ∧ t 6∈ T2,
and T1 ranges over all datasets such that |T1| = k ∧ t 6∈ T1. We
have
Pr[S|t]
Pr[S|¬t] =
=
(cid:16)PT2
(cid:16)PT2
Pr[T2∪{t}] Pr[S|T2∪{t}](cid:17)/ Pr[t]
(cid:16)PT1
Pr[T1] Pr[S|T1](cid:17)/ Pr[¬ t]
Pr[T2∪{t}| t] Pr[S|T2∪{t}](cid:17)
(cid:16)PT1
Pr[T1|¬ t] Pr[S|T1](cid:17)
The main idea of the remaining proof is to construct a joint distribu-
tion Pk,k−1 deﬁned on all pairs of (T1, T2) such that T2 ⊆ T1 (so
that T2 ∪ {t} is a neighbor of T1) while the margin distribution of
Pk,k−1 on T1, T2 is Pr(T1|¬t) and Pr(T2 ∪ {t}|t). The existence
of such a joint distribution when we do not have size constraints
on T1, T2 is trivial as we can simply take T1 = T2 and this is al-
so essentially how we prove the unbounded case. The proof for
the existence of such a distribution for the bounded privacy case is
technically more challenging as we need to show the existence of
a such distribution when T1 is sampled from all sets of size k − 1
that does not contain t and T2 is sampled from all sets of size k that
does not contains t. Formally, we prove the following lemma:
LEMMA 4.9. For any k-bouneded mutually independent distri-
bution Pk deﬁned on n entities, there exists a distribution Pk,k−1
deﬁned on pair (T1, T2) satisfying that |T1| = k, |T2| = k −
1, T2 ⊂ T1 ⊆ [n], t /∈ T1. The margin probability of Pk,k−1
on T1 is Pr(T1|¬t) and on T2 is Pr(T2 ∪ {t}|t).
Assuming the correctness of Lemma 4.9 and by the margin prop-
erty of Pk,k−1 , we know that
(11)
Pr[S|t]
Pr[S|¬t]
Notice that T2 ∪ {t} and T1 are adjacent to each other accord-
ing to the deﬁnition of bounded differential privacy, and therefore
Pr[S|T2∪{t}]
= P(T1,T2) PrPk,k−1 [T1, T2] · Pr[S|T2 ∪ {t}]
P(T1,T2) PrPk,k−1 [T1, T2] · Pr[S|T1]
Pr[S|T1] ≤ eǫ. This directly implies that (11) ≤ eǫ.
The complete proof of Lemma 4.9 is quite involved. We ﬁrst
show that the existence of the distribution Pk,k−1 is equivalent to
the existence of a perfect solution in certain network ﬂow problem;
then we use a generalization of Hall’s marriage theorem (see [14])
to show the existence of such a perfect solution in the network. The
full proof appears in Appendix A.3.
5. OTHER INSTANTIATIONS
The membership privacy framework enables one to design and
choose privacy notions suitable for particular situations by choos-
ing appropriate families of distributions. We have shown that
choosing DU , the family that includes all possible distributions,
results in a privacy notion that is likely too strong. We have al-
so shown that UDP corresponds to choosing DI, the family that
includes all mutually independent distributions, and that BDP cor-
responds to choosing DB
I , that family that includes all bounded mu-
tually independent distributions.
In this section, we explore membership privacy under three oth-
er families of distributions. The ﬁrst one is DN , the family that
includes the single uniform distribution over all possible subsets of
U. The second one corresponds to differential identiﬁability [20],
and the third one corresponds to differential privacy under sam-
pling [22].
5.1 PMP Under the Uniform Distribution
The ﬂexibility offered by PMP enables data publishers to have
more choices in trading off privacy versus utility. Here we show
that it is possible to satisfy PMP under a more restrictive family of
distributions while providing a much better utility than it is known
to be possible under differential privacy. We consider PMP under
the following family.
DISTRIBUTION FAMILY 5.1. DN : Non-informative Distribu-
tion DN includes a single distribution DN , the uniform distribution
such that each subset of U has the same probability
1
2|U| .
Note that DN , which contains a single distribution, should not
be confused with DU , which contains an inﬁnite number of distri-
butions. Under DN , we have Pr[t] = 1
2 for every entity t. PMP
under DN means that one assumes an uninformed adversary that
has no prior knowledge about the possible dataset, which may be
reasonable for some data publishing scenarios. We note that mech-
anisms that satisfy syntactic privacy notions such as k-anonymity
generally does not satisfy (DN , γ)-PMP, because from anonymized
dataset one can tell membership with high conﬁdence even assum-
ing the uninformed prior. We now show that it is possible to satisfy
DN while providing signiﬁcantly more utility than satisfying dif-
ferential privacy. As an example, we consider the universe U to
be one where each entity has a single numerical attribute, e.g., in-
come. And our goal is to publish the maximum income value in
T ⊂ U. Naturally the global range of the income attribute is very
large, while the max value of most datasets is likely to be much
smaller than the global max.
It is very difﬁcult to compute max while satisfying differential
privacy. The global sensitivity of the max function is very high. By
changing one entity, the max may change all the way from the low-
est possible value to the highest possible value. Therefore, whether
one applies the Laplacian mechanism or the exponential mechanis-
m, the amount of noise one has to add would dominate the result.
When one aims at satisfying (DN , γ)-PMP, however, it is pos-
sible to output the max of a set with very high accuracy. For sim-
plicity of explnanation, let us sort all entities in U based on their
income value, and use the index to refer to these entities. That is, 1
denote the entity with smallest income value, and n = |U| denotes
the entity with the largest income value, and we use ci to denote
the income of element i.
DEFINITION 5.2
(k-MAX MECHANISM). The k-Max mech-
anism, parameterized by an integer k ≥ 2, works as follows. Given
a dataset T , let j be the largest element in T , the mechanism gives
a value picked at uniform random from the following set:
C =(cid:26) {cj , cj+1, · · · , cj+k−1}
{cn−k+1, cn−k+2, · · · , cn} otherwise
when j + k − 1 ≤ n,
We note that this mechanism is highly accurate when k is not
large. It outputs the value of an element whose rank in the universe
is within distance k of the true max of the dataset. For example,
suppose that the elements in the universe have values that are the
ﬁrst 10000 prime numbers (up to 104729), on a dataset that has
four entities with values {2, 5, 113, 9851}, the mechanism 3-Max
outputs one of 9851, 9857, 9859 each with probability 1
3 , which is
remarkably close to the true max. The intuition that this satisﬁes
PMP is that no matter which of the three value is outputted, the
posterior probability that the entity with value 9851 (or any other
entity) is in the input is not signiﬁcantly higher than the prior prob-
ability of 1
12 according to the following proposition.
2 ; it is at most 7
PROPOSITION 5.3. The k-Max mechanism satisﬁes (DN , γ)-
PMP for γ = 2k −1
2k −2
.
PROOF. Because for any i, we have Pr[i] = 1
2 , we need to show
that for each i, j, Pr[i|cj ] ≤ min( γ
2 , γ−0.5
γ
).
Consider Pr[i|cj ], when cj is the output, we know that the
true max element in the input must be with distance k of j. Let
Mj denote the set of entities that are possible true max when
cj is output, and sj = |Mj| denote the number of elements in
Mj, and mj denote the max in Mj. When j ≤ n − k, then
Mj = {j − k + 1, · · · , j} includes exactly k elements. When
j > n − k, then all elements in {j − k + 1, · · · , j} are still in Mj,
but Mj may include elements with rank > j. (For example, when
k = 2 and cn−1 is output, both n and n − 2 may be the true max.)
In any case, we always have sj ≥ k.
When cj is output, we know that at least one element in Mj
must appear, and no element with index > mj can appear. The
event under which that cj is output can be divided into 2sj − 1
equal-probability events, each corresponding to the selection of one
subset of Mj to be included in T (∅ is not allowed). For each
event, the probability that cj is output is exactly 1
k . Each i in Mj is
included in 2sj −1 of the events, and not included in 2sj −1 − 1 of
them.
We have Pr[i|cj ] = 0 when i > mj, and Pr[i|cj ] = 1
2 when i ≤
j − k. When j − k < i ≤ mj, we have Pr[i|cj ] = 2sj −1
because
2sj −1
when cj is output, there are 2sj − 1 equally likely possibilities, and
i appears in 2sj −1 of these possibilities.
2sj −1 ≤ min( γ
2k −1 ≤ min( γ
). Because sj ≥
), solving which
k, the above holds when 2(k−1)
2 , γ−0.5
2 , γ−0.5
Therefore, we want 2
(sj −1)
γ
γ
gets γ ≥ max(cid:16) 2k
2k −1 , 2k −1
2k −2(cid:17) = 2k −1
2k −2
This means that one obtains (DN , 3
PMP for k = 3, and (DN , 15
.
14 )-PMP for k = 4.
2 )-PMP for k = 2, (DN , 7
6 )-
This example demonstrates that when one is willing to accept a
privacy notion weaker than differential privacy, then one can obtain
dramatic improvement in utility for some queries. k-Max is just a
preliminary example. Many other data analysis tasks may become
signiﬁcantly more accurate under this weaker privacy notion. We
also note that the accuracy of k-Max is also due in part to satisfying
only PMP and not NMP. k-Max does not satisfy (DN , γ)-NMP for
any γ, as observing output cj can reduce the posterior probability
of some large entities to 0.
We emphasize that we are not arguing that (DN , γ)-PMP is a
suitable privacy notion for all situations. Indeed even differential
privacy is not; as it is unsuitable when one cannot make the inde-
pendence assumption. We believe that a range of privacy notions
is needed in practice. We also stress than (DN , γ)-PMP is by no
means the only meaningful relaxation of differential privacy in the
membership privacy framework; and it is interesting future work
to explore other family of distributions which would induce useful
privacy notions.
5.2 Differential Identiﬁability
In [20], Lee and Clifton argued that there are no clear guide-
lines on how to set ǫ for ǫ-differential privacy, because ǫ limits how
much one individual can affect the resulting output, not how much
information is revealed about an individual; and this does not match
legal deﬁnitions of privacy, which require protection of individual-
ly identiﬁable data [1, 2]. From analysis of US HIPAA safe harbor
rule [2], it is concluded that the goal of the privacy policy is met
if one limits the estimate of the probability that an individual is in
the data to approximately 1.5%. Lee and Clifton thus propose the
following notion.
DEFINITION 5.4. (ρ-differential
identiﬁability (DI) [20]) A
mechanism A is said to satisfy ρ-DI if for any dataset T , any entity