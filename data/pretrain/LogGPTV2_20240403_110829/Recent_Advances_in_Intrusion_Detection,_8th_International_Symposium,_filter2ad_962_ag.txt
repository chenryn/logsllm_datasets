### 3. Trace Data

The study presented in this paper is based on traffic traces collected from the border of an academic department's network. The network consists of 1200 externally routable hosts and serves approximately 1500 users. These hosts are used for various purposes, including research, administration, and general computing activities such as web browsing and email. The network hosts a diverse range of operating systems.

Since May 2003, we have recorded, in an anonymized form, all IP and common second-layer headers (e.g., TCP or UDP) of packets entering and leaving the network. Additionally, we captured DNS traffic payloads for use in the experiments described in Section 8.

During the tracing period, we recorded two worm attacks: Blaster and Welchia [16, 17]. Both are scanning worms that exploit the Windows DCOM RPC vulnerability. For each attack, we conducted a post-mortem analysis to identify the set of infected hosts within the network. We classified outbound worm traffic as those originating from infected hosts and targeting a specific destination port (e.g., port 135 for Blaster). Whenever possible, we used payload sizes similar to those documented in Symantec’s worm advisories to further confirm the identification of worm traffic.

It is important to note that the infected hosts in our network were exclusively Windows clients, which, under normal circumstances, rarely (if ever) made any outbound connections to port 135. Once infected, these hosts initiated tens of thousands of outbound connections to port 135, making the task of identifying worm traffic relatively straightforward.

For this analysis, we use a 24-day outbound trace from August 6th to August 30th, 2003. This period includes the first documented infection of Blaster in our network, which occurred on August 11th, and the Welchia attack, which hit the network on August 18th. Collectively, Blaster and Welchia infected 100 hosts in the network. Since the traffic patterns of hosts infected by Blaster and Welchia were similar during the overlapping time period, we do not attempt to separate the two attacks. Our data suggests that the residual effects of the worms persisted for months, but the most significant impact was observed during the first two weeks of the attack.

### 4. Analysis Methodology

As previously mentioned, we use a 24-day outbound trace collected at the border of a 1200-host network with documented Blaster and Welchia activities. Our goal is to evaluate the performance of various proposed rate limiting schemes. The performance criteria for our analysis include error rates, specifically false positives and false negatives. We define the false positive rate as the percentage of normal traffic misidentified as worm traffic and subsequently rate-limited. The false negative rate is the percentage of worm traffic that is not affected by the rate limiting mechanism and allowed through without delay. Rate-limited traffic can be either blocked or delayed. In the following analysis, we differentiate between these two cases and present error rates accordingly. Note that the false negative rate is only meaningful during the infection period, while false positives are considered throughout the entire trace period. Where appropriate, we present Receiver Operating Characteristic (ROC) curves to contrast false negatives with false positives.

For each scheme analyzed, there is a set of parameters that impact the performance of the mechanism. We identify these parameters and evaluate the sensitivity of the error rates with respect to each parameter. In some cases, the impact of these parameters has not been studied previously. A key contribution of our study is to provide a precise understanding of how these parameters might be implemented in practice.

One factor that we were unable to fully evaluate in our work was the placement of rate limiting mechanisms within the network. Our trace does not include internal traffic, and due to the anonymized nature of our trace data, we were unable to reconstruct the internal network topology.

### 5. Williamson’s IP Throttling

Williamson’s IP throttling scheme operates on the assumption that normal applications typically exhibit a stable contact rate to a limited number of external hosts (e.g., web servers, file servers) [23]. Restricting host-level contact rates to unique IPs can limit rapid connections to random addresses, such as those initiated by worm traffic. Williamson achieves this by maintaining a working set of addresses for each host, which models the normal contact behavior of the host. The throttling mechanism permits outgoing connections for addresses in the working set but delays other packets by placing them in a delay queue. If the delay queue is full, further packets are simply dropped. The packets in the delay queue are dequeued and processed at a constant rate (one per second, as suggested by [23]). At the same rate, the least recently used address in the working set is evicted to make room for the new connection. As a result, connections to frequently contacted addresses are allowed through with a high probability, while connections to random addresses (as those initiated by scanning worms) are likely delayed and possibly dropped.

For this scheme, the size of the working set and the delay queue are crucial. A larger working set permits a higher contact rate, while the delay queue length determines how liberal or restrictive the scheme is. Williamson recommends a five-address working set and a delay queue length of 100 for host-based implementations. Our analysis reports on the impact of these parameter settings. We also analyze a version of Williamson’s throttling on the edge router.

#### End Host Throttling

To analyze Williamson’s end host IP throttling, we reconstructed end-host traffic from our trace and simulated Williamson’s rate limiting scheme using these traces.

Figure 2(a) shows the daily false positive rate for infected hosts with the size of the working set ranging from 4 to 10. False positive rates are calculated as the percentage of benign traffic subjected to rate limiting. The data points in Figure 2(a) show daily false positive statistics as averages across infected hosts while they remained infected. For comparison, we tested Williamson’s scheme on normal hosts, the results of which are shown in Figure 2(b).

A few key insights are important here: First, Figure 2 suggests that false positives are low during normal operation (about 15%). However, once infection occurs, Williamson’s scheme yields false positive rates nearly 90%. This is undesirable because, during the worm outbreak, essentially all benign traffic is subjected to delay incurred by the throttling scheme. Figure 2(d) shows the average queue length for infected hosts. As shown, when infection hit on day 6, the average queue length quickly reached the maximum (100 in this case) and remained at that level.