of our analysis is diﬀerent and therefore oﬀers diﬀerent insights and conclusions.
3 Trace Data
The study in this paper is conducted using traﬃc traces collected from the border
of an academic department. The network has 1200 externally routable hosts and
serves approximately 1500 users. Hosts are used for research, administration, and
general computing (web browsing, mail, etc). There is a diverse mix of operating
systems on the network. Since May 2003 we recorded in an anonymized form
all IP and common second layer headers of packets (e.g., TCP or UDP) leaving
and entering the network. We also recorded DNS traﬃc payloads for use in the
experiment in Section 8.
During the course of tracing, we recorded two worm attacks: Blaster and
Welchia [16, 17]. Both are scanning worms that exploited the Windows DCOM
RPC vulnerability. For each attack recorded, we conducted post-mortem analysis
to identify the set of infected hosts within the network. We further identiﬁed
outbound worm traﬃc as those from infected hosts with a particular destination
port (e.g., port 135 for Blaster). Whenever possible, a payload size identical or
similar to those publicized in Symantec’s worm advisories is used as additional
evidence to identify worm traﬃc. It is important to note that infected hosts in
our network were exclusively Windows clients that, under normal circumstances,
rarely (if ever) made any outbound port 135 connections to external addresses.
Once infected, these hosts initiated tens of thousands of outbound connections
to port 135. As such, the task of identifying worm traﬃc is made relatively easy.
For the purpose of this analysis, we use a period of 24-day outbound trace,
from August 6th to August 30th 2003. This period contains the ﬁrst documented
infection of Blaster in our network, which occurred on August 11th. Welchia hit
the network on the 18th. Collectively, Blaster and Welchia infected 100 hosts in
the network. Since hosts infected by Blaster and Welchia exhibited similar traﬃc
patterns during the overlapping time period, we do not attempt to separate the
two attacks. Our data suggests that residual eﬀects of the worms lingered on for
months but the eﬀects of the infection are most prominent during the ﬁrst two
weeks of the attack.
l
s
w
o
F
P
C
T
f
o
r
e
b
m
u
N
Empirical Analysis of Rate Limiting Mechanisms
25
 1.2e+07
 1e+07
 8e+06
 6e+06
 4e+06
 2e+06
 0
 0
Number of TCP Flows at the Edge Router per day
Total Flows
Total Worm Flows
Total Nonworm Flows
Blaster hits
Welchia hits
 5
 10
 15
 20
Days
 9e+06
 8e+06
 7e+06
 6e+06
 5e+06
 4e+06
 3e+06
 2e+06
 1e+06
s
e
s
s
e
r
d
d
A
P
I
n
o
i
t
a
n
i
t
s
e
D
t
c
n
i
t
s
D
i
 0
 0
Distinct Destination IP Addresses Per Day
Distinct IP Addresses
 5
 10
 15
 20
Days
(a) Daily outgoing ﬂows
(b) Daily volume of distinct IPs
Fig. 1. Traﬃc Statistics for the Blaster/Welchia Trace
Figure 1(a) shows the daily volume of outgoing traﬃc as seen by the edge
router for the trace period. Figure 1(b) shows the number of distinct IP ad-
dresses daily. As shown, the aggregate outgoing traﬃc experienced a large spike
as Blaster hits the network on day 6. At its peak, the edge router saw 11 million
outbound ﬂows in a day. This is in contrast to the normal 500,000 ﬂows/day.
The increase in traﬃc is predominantly due to worm activities.
Unless otherwise noted, the trace data refers to aggregate traﬃc as seen by
the edge router. In some of the later analysis (e.g., Williamson’s host-based
throttling), we use host-level traﬃc from the aggregate trace. In those cases we
will diﬀerentiate between infected host traﬃc and normal host traﬃc.
4 Analysis Methodology
As previously mentioned, we use a period of 24-day outbound traces collected at
the border of a 1200-host network with documented Blaster and Welchia activ-
ities. Our goal is to evaluate the performance of various proposed rate limiting
schemes. The performance criteria we use in the analysis is error rates (e.g., false
positives and false negatives) of the diﬀerent schemes. We deﬁne the false pos-
itive rate as the percentage of normal traﬃc misidentiﬁed as worm traﬃc and
subsequently rate limited. False negative rate is the percentage of worm traf-
ﬁc that is not aﬀected by the rate limiting mechanism and permitted through
without delay. Rate limited traﬃc can be either blocked or delayed. In the analy-
sis that follow, we diﬀerentiate between these two cases and present error rates
accordingly. Note the false negative rate is only meaningful during infection,
while false positives are considered throughout the entire trace period. When-
ever appropriate, we present Receiver Operator Curves (ROC) to contrast false
negatives with false positives.
For each scheme analyzed, there exists a set of parameters that impact the per-
formance of the mechanism. We identify these parameters and evaluate the sensi-
tivity of the error rates with respect to each parameter. In some cases, the impact
of the parameters has not been studied previously. A contribution of our study is
to understand precisely how these parameters might be implemented in practice.
26
C. Wong et al.
One factor that we were unable to evaluate fully in our work was the place-
ment of RL mechanisms within the network. Our trace does not include internal
traﬃc and due to the anonymized nature of our trace data, we were unable to
reconstruct the internal network topology.
5 Williamson’s IP Throttling
Williamson’s IP throttling scheme operates on the assumption that normal ap-
plications typically exhibit a stable contact rate to a limited number of external
hosts (e.g., web servers, ﬁle servers) [23]. Restricting host-level contact rates to
unique IPs can limit rapid connections to random addresses (e.g., worm traﬃc).
Williamson accomplishes this by keeping a working set of addresses for each host,
which models the normal contact behavior of the host. The throttling mecha-
nism permits outgoing connections for addresses in the working set, but delays
other packets by placing them in a delay queue. If the delay queue is full, fur-
ther packets are simply dropped. The packets in the delay queue are dequeued
and processed at a constant rate (one per second, as suggested by [23]). At the
same rate, the least recently used address in the working set is evicted to make
room for the new connection. As a result, connections to frequently contacted
addresses are allowed through with a high probability while connections to ran-
dom addresses (as those initiated by scanning worms) are likely delayed and
possibly dropped.
For this scheme, the size of the working set and the delay queue are important.
A larger working set permits a higher contact rate while the delay queue length
determines how liberal (or restrictive) the scheme is. Williamson recommends a
ﬁve-address working set and a delay queue length of 100 for host-based imple-
mentations. Our analysis reports on the impact of these parameter settings. We
also analyze a version of Williamson’s throttling on the edge router.
End Host Throttling. To analyze Williamson’s end host IP throttling, we
reconstructed end-host traﬃc from our trace and simulated Williamson’s rate
limiting scheme using these traces.
Figure 2(a) shows the daily false positive rate for infected hosts with the size
of the working set ranging from 4 to 10. Again, false positive rates are calculated
as the percentage of benign traﬃc subjected to rate limiting. The data points in
Figure 2(a) show daily false positive statistics as averages across infected hosts
while the host stayed infected. For comparison reasons, we tested Williamson’s
scheme on normal hosts, the result of which are shown in Figure 2(b).
A few high-level insights are important here: First, Figure 2 suggests that false
positives are low during normal operation (about 15%). Once infection occurs,
however, Williamson’s scheme yields false positive rates nearly 90%. This is un-
desirable as during the worm outbreak, essentially all benign traﬃc is subjected
to delay incurred by the throttling scheme. Figure 2(d) shows the average queue
length for infected hosts. As shown, when infection hit on day 6, the average
queue length quickly reached the maximum (100 in this case) and remained in
Empirical Analysis of Rate Limiting Mechanisms
27
FP for End Host MW RL w/ varying Working Set len. Infected Host
FP for End Host MW RL w/ varying Working Set len. Normal Host
 100
 80
 60
 40
 20
 0
 0
 5
Aset len. 4
Aset len. 5
Aset len. 6
Aset len. 7
Aset len. 8
Aset len. 9
Aset len. 10
 10
Days
 15
 20
)
%
(
e
v
i
t
i
s
o
P
e
s
a
F
l
Aset len 4
Aset len 5
Aset len 6
Aset len 7
Aset len 8
Aset len 9
Aset len 10
 100
 80
 60
 40
 20
 0
 0
 5
 10
Days
 15
 20
)
%
(
e
v
i
t
i
s
o
P
e
s
a
F
l
(a) FP per day for Infected Hosts
(b) FP per day for Normal Hosts
FN for End Host MW RL w/ varying Working Set len. Infected Host
Average Delay Queue Length for MW End Host RL Infected Hosts
 5
 4
 3
 2
 1
)
%
(
e
v
i
t
a
g
e
N
e
s
a
F
l
Aset len. 4
Aset len. 5
Aset len. 6
Aset len. 7
Aset len. 8
Aset len. 9
Aset len. 10
 100
 80
 60
 40
 20
h
t
g
n
e