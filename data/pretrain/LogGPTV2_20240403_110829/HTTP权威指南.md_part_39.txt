### 9.2.1 支持Host首部的重要性

为了支持虚拟主机（参见第5章），HTTP请求中必须包含Host首部。如果请求中不包含Host首部，可能会导致机器人将错误的内容与特定的URL关联起来。因此，HTTP/1.1协议要求使用Host首部。

大多数服务器默认配置为提供一个特定的站点。例如，假设一台服务器同时托管了`www.joes-hardware.com`和`www.foo.com`两个站点，并且默认情况下配置为提供`www.joes-hardware.com`。如果爬虫请求`www.foo.com`上的某个页面但未包含Host首部，那么爬虫实际上会获取到`www.joes-hardware.com`的内容，并误认为这些内容来自`www.foo.com`。这种混淆可能导致更严重的问题，尤其是在两个站点具有相反的政治立场或其他敏感观点时。

#### 示例
**Web机器人客户端**
```http
GET /index.html HTTP/1.0
User-Agent: ShopBot 1.0
```
**响应报文**
```http
HTTP/1.0 200 OK
[...]
Welcome to Joe's Hardware!
[...]
```
如图9-5所示，当请求没有携带Host首部时，虚拟文档根目录会导致问题。

### 9.2.3 条件请求

减少机器人获取内容的数量通常是明智之举。对于互联网搜索引擎机器人来说，需要下载的潜在页面数量巨大，因此只在内容发生变化时才重新获取内容是合理的。

一些机器人实现了条件HTTP请求，通过比较时间戳或实体标签来检查最近获取的版本是否已更新。这种方法类似于HTTP缓存验证本地副本有效性的机制。更多关于缓存验证的信息请参见第7章。

### 9.2.4 响应处理

许多机器人的主要任务是通过简单的GET方法获取内容，因此通常不会在处理响应的方式上花费太多时间。然而，使用某些HTTP特性（如条件请求）的机器人，以及那些希望更好地探索和交互的机器人，则需要能够处理各种类型的HTTP响应。

#### 状态码
所有机器人至少应该能够处理常见的状态码，如200 OK和404 Not Found。它们还应该能够根据响应的一般类别处理不太理解的状态码。第3章的表3-2列出了不同状态码的分类及其含义。

需要注意的是，有些服务器可能不会返回适当的错误代码，甚至可能在HTTP状态码200 OK的情况下返回描述错误状态的主体文本。实现者应对此有所了解。

#### 实体
除了HTTP首部信息外，机器人还会在实体中查找信息。HTML元标签（如meta http-equiv）允许内容编写者嵌入附加信息。例如：
```html
<meta http-equiv="Refresh" content="1; URL=index.html">
```
这个标签指示接收者处理文档时，将其视为包含了一个值为1, URL=index.html的Refresh HTTP首部。有些服务器会在发送HTML页面前解析这些指令并将其作为首部包含进去；而有些服务器则不会。机器人实现者可能会扫描HTML文档的HEAD部分以查找这些信息。

### 9.2.5 User-Agent导向

网站管理员应意识到会有许多机器人访问他们的站点，并做好相应的准备。许多站点会为不同的用户代理优化内容，并尝试检测浏览器类型以确保支持各种站点特性。然而，当实际的HTTP客户端是机器人而非浏览器时，站点可能会返回错误页面而不是预期的内容。例如，在搜索引擎中搜索短语“your browser does not support frames”（你的浏览器不支持框架），会生成包含该短语的错误页面列表。

站点管理员应设计处理机器人请求的策略。例如，他们可以为其他功能较少的浏览器和机器人开发一些页面，而不是将内容限定在特定浏览器支持的范围内。至少，管理员应知道机器人会访问其站点，并不应感到措手不及。

### 9.3 行为不当的机器人

行为不当的机器人可能会造成严重问题。以下是一些常见错误及其后果：

- **失控机器人**：编程逻辑错误或陷入循环的机器人可能会向Web服务器发出大量请求，导致服务器过载。
- **失效的URL**：如果Web站点对其内容进行了大量修改，机器人可能会请求大量不存在的URL，这会激怒站点管理员。
- **很长的错误URL**：由于环路和编程错误，机器人可能会请求非常长的、无意义的URL，降低服务器性能。
- **爱打听的机器人**：机器人可能会获取指向私有数据的URL，从而侵犯隐私。一旦发现这种情况，应立即删除这些数据。
- **动态网关访问**：机器人可能会访问计算开销高的网关应用程序，导致站点管理员不满。

### 9.4 拒绝机器人访问

为了管理机器人访问Web站点时可能引发的问题，1994年提出了一项自愿约束技术，称为“拒绝机器人访问标准”。该标准通过在Web服务器的文档根目录中放置一个名为`robots.txt`的文件来实现。这个文件说明了机器人可以访问服务器的哪些部分。

#### 示例
**Web机器人客户端**
```http
GET /robots.txt
```
**响应报文**
```http
HTTP/1.0 200 OK
[...]
```
**继续发送请求**
```http
GET /specials/acetylene-torches.html
```

#### 拒绝机器人访问标准
目前大多数机器人采用的标准是v0.0或v1.0。版本v2.0虽然提供了正则表达式和定时信息的支持，但并未得到广泛应用。这里我们重点介绍v1.0标准，因为它应用广泛且与v0.0完全兼容。

#### 获取robots.txt
机器人使用HTTP GET方法获取`robots.txt`资源。如果有`robots.txt`文件，服务器会将其放在text/plain主体中返回。如果服务器以404 Not Found状态码响应，机器人可以认为该服务器没有机器人访问限制，可以请求任意文件。

机器人应在From首部和User-Agent首部中传输标识信息，以帮助站点管理者跟踪机器人的访问并提供联系信息。例如：
```http
GET /robots.txt HTTP/1.0
Host: www.joes-hardware.com
User-Agent: Slurp/2.0
Date: Wed Oct 3 20:22:48 EST 2001
```

#### 响应码
- 如果服务器以成功状态（HTTP状态码2XX）响应，机器人必须解析内容并使用排斥规则从该站点获取内容。
- 如果服务器响应说明资源不存在（HTTP状态码404），机器人可以认为服务器没有激活任何排斥规则，对该站点的访问不受`robots.txt`限制。