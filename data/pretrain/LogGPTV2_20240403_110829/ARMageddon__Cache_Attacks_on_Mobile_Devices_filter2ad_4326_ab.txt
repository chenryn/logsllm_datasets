e
S
s
t
e
S
(
1
)
L2 Unified Cache
(
2
)
(3)
s
e
s
s
e
c
c
a
f
o
r
e
b
m
u
N
3
2
1
0
Hit (same core)
Miss (same core)
Hit (cross-core)
Miss (cross-core)
·104
0
200
400
600
800
1,000
Measured access time in CPU cycles
Figure 1: Cross-core instruction cache eviction through
data accesses.
When it comes to caches, ARM CPUs are very hetero-
geneous compared to Intel CPUs. For example, whether
or not a CPU has a second-level cache can be decided by
the manufacturer. Nevertheless, the last-level cache on
ARM devices is usually shared among all cores and it can
have different inclusiveness properties for instructions
and data. Due to cache coherence, shared memory is
kept in a coherent state across cores and CPUs. This is of
importance when measuring timing differences between
cache accesses and memory accesses (cache misses), as
fast remote-cache accesses are performed instead of slow
memory accesses [6]. In case of a non-coherent cache, a
cross-core attack is not possible but an attacker can run
the spy process on all cores simultaneously and thus fall
back to a same-core attack. However, we observed that
caches are coherent on all our test devices.
To perform a cross-core attack we load enough data
into the cache to fully evict the corresponding last-level
cache set. Thereby, we exploit that we can fill the last-
level cache directly or indirectly depending on the cache
organization. On the Alcatel One Touch Pop 2, the last-
level cache is instruction-inclusive and thus we can evict
instructions from the local caches of the other core. Fig-
ure 1 illustrates such an eviction. In step 1, an instruc-
tion is allocated to the last-level cache and the instruc-
tion cache of one core. In step 2, a process fills its core’s
data cache, thereby evicting cache lines into the last-level
cache. In step 3, the process has filled the last-level cache
set using only data accesses and thereby evicts the in-
structions from instruction caches of other cores as well.
We access cache lines multiple times to perform trans-
fers between L1 and L2 cache. Thus, more and more
addresses used for eviction are cached in either L1 or L2.
As ARM CPUs typically have L1 caches with a very low
associativity, the probability of eviction to L2 through
other system activity is high. Using an eviction strategy
that performs frequent transfers between L1 and L2 in-
creases this probability further. Thus, this approach also
works for other cache organizations to perform cross-
core and cross-CPU cache attacks. Due to the cache co-
herence protocol between the CPU cores [6,33], remote-
core fetches are faster than memory accesses and thus
can be distinguished from cache misses. For instance,
Figure 2: Histograms of cache hits and cache misses
measured same-core and cross-core on the OnePlus One.
Figure 2 shows the cache hit and miss histogram on the
OnePlus One. The cross-core access introduces a latency
of 40 CPU cycles on average. However, cache misses
take more than 500 CPU cycles on average. Thus, cache
hits and misses are clearly distinguishable based on a sin-
gle threshold value.
3.2 Fast Cache Eviction
In this section, we tackle the aforementioned challenges
3 and 4, i.e., not all ARM processors support a flush in-
struction, and the replacement policy is pseudo-random.
There are two options to evict cache lines: (1) the
flush instruction or (2) evict data with memory accesses
to congruent addresses, i.e., addresses that map to the
same cache set. As the flush instruction is only available
on the Samsung Galaxy S6, we need to rely on eviction
strategies for the other devices and, therefore, to defeat
the replacement policy. The L1 cache in Cortex-A53 and
Cortex-A57 has a very small number of ways and em-
ploys a least-recently used (LRU) replacement policy [5].
However, for a full cache eviction, we also have to evict
cache lines from the L2 cache, which uses a pseudo-
random replacement policy.
Eviction strategies. Previous approaches to evict data
on Intel x86 platforms either have too much over-
head [23] or are only applicable to caches implement-
ing an LRU replacement policy [35, 37, 42]. Spreitzer
and Plos [51] proposed an eviction strategy for ARMv7-
A CPUs that requires to access more addresses than
there are cache lines per cache set, due to the pseudo-
random replacement policy. Recently, Gruss et al. [17]
demonstrated how to automatically find fast eviction
strategies on Intel x86 architectures. We show that
their algorithm is applicable to ARM CPUs as well.
Thereby, we establish eviction strategies in an automated
way and significantly reduce the overhead compared to
[51]. We evaluated more than 4 200 access patterns on
our smartphones and identified the best eviction strate-
gies. Even though the cache employs a random replace-
USENIX Association  
25th USENIX Security Symposium  553
5
Table 2: Different eviction strategies on the Krait 400.
Table 3: Different eviction strategies on the Cortex-A53.
N
-
11
12
13
16
24
13
11
11
10
A D
-
-
2
2
3
1
5
1
1
1
1
1
2
1
1
3
1
4
2
2
Cycles
549
1 578
2 094
2 213
3 026
4 371
2 372
1 608
1 948
1 275
Eviction rate
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
99.58%
80.94%
58.93%
51.12%
ment policy, average eviction rate and average execu-
tion time are reproducible. Eviction sets are computed
based on physical addresses, which can be retrieved via
/proc/self/pagemap as current Android versions al-
low access to these mappings to any unprivileged app
without any permissions. Thus, eviction patterns and
eviction sets can be efficiently computed.
We applied the algorithm of Gruss et al. [17] to a set
of physically congruent addresses. Table 2 summarizes
different eviction strategies, i.e., loop parameters, for the
Krait 400. N denotes the total eviction set size (length of
the loop), A denotes the shift offset (loop increment) to
be applied after each round, and D denotes the number of
memory accesses in each iteration (loop body). The col-
umn cycles states the average execution time in CPU cy-
cles over 1 million evictions and the last column denotes
the average eviction rate. The first line in Table 2 shows
the average execution time and the average eviction rate
for the privileged flush instruction, which gives the best
result in terms of average execution time (549 CPU cy-
cles). We evaluated 1863 different strategies and our best
identified eviction strategy (N = 11, A = 2, D = 2) also
achieves an average eviction rate of 100% but takes 1578
CPU cycles. Although a strategy accessing every address
in the eviction set only once (A = 1, D = 1, also called
LRU eviction) performs significantly fewer memory ac-
cesses, it consumes more CPU cycles. For an average
eviction rate of 100%, LRU eviction requires an eviction
set size of at least 16. The average execution time then
is 3026 CPU cycles. Considering the eviction strategy
used in [51] that takes 4371 CPU cycles, clearly demon-
strates the advantage of our optimized eviction strategy
that takes only 1578 CPU cycles.
We performed the same evaluation with 2295 different
strategies on the ARM Cortex-A53 in our Alcatel One
Touch Pop 2 test system and summarize them in Table 3.
For the best strategy we found (N = 21, A = 1, D = 6), we
measured an average eviction rate of 99.93% and an av-
erage execution time of 4275 CPU cycles. We observed
that LRU eviction (A = 1, D = 1) on the ARM Cortex-
N
-
23
23
22
21
20
800
200
100
48
A D
-
-
2
5
6
4
6
1
6
1
6
4
1
1
1
1
1
1
1
1
Cycles
767
6 209
16 912
5 101
4 275
13 265
142 876
33 110
15 493
6 517
Eviction rate
100.00%
100.00%
100.00%
99.99%
99.93%
99.44%
99.10%
96.04%
89.77%
70.78%
Flush (address cached)
Flush (address not cached)
100
200
300
400
500
600
Measured execution time in CPU cycles
s
e
s
a
c
f
o
r
e
b
m
u
N
3 ·104
2
1
0
0
Figure 3: Histograms of the execution time of the flush
operation on cached and not cached addresses measured
on the Samsung Galaxy S6.
A53 would take 28 times more CPU cycles to achieve an
average eviction rate of only 99.10%, thus it is not suit-
able for attacks on the last-level cache as used in previous
work [51]. The reason for this is that data can only be al-
located to L2 cache by evicting it from the L1 cache on
the ARM Cortex-A53. Therefore, it is better to reaccess
the data that is already in the L2 cache and gradually add
new addresses to the set of cached addresses instead of
accessing more different addresses.
On the ARM Cortex-A57 the userspace flush in-
struction was significantly faster in any case. Thus,
for Flush+Reload we use the flush instruction and for
Prime+Probe the eviction strategy.
Falling back to
Evict+Reload is not necessary on the Cortex-A57. Sim-
ilarly to recent Intel x86 CPUs, the execution time of the
flush instruction on ARM depends on whether or not the
value is cached, as shown in Figure 3. The execution
time is higher if the address is cached and lower if the
address is not cached. This observation allows us to dis-
tinguish between cache hits and cache misses depending
on the timing behavior of the flush instruction, and there-
fore to perform a Flush+Flush attack. Thus, in case of
shared memory between the victim and the attacker, it is
not even required to evict and reload an address in order
to exploit the cache side channel.
554  25th USENIX Security Symposium 
USENIX Association
6
A note on Prime+Probe. Finding a fast eviction strat-
egy for Prime+Probe on architectures with a random
replacement policy is not as straightforward as on In-
tel x86. Even in case of x86 platforms, the problem of
cache trashing has been discussed by Tromer et al. [54].
Cache trashing occurs when reloading (probing) an ad-
dress evicts one of the addresses that are to be accessed
next. While Tromer et al. were able to overcome this
problem by using a doubly-linked list that is accessed
forward during the prime step and backwards during the
probe step, the random replacement policy on ARM also
contributes to the negative effect of cache trashing.
We analyzed the behavior of the cache and designed
a prime step and a probe step that work with a smaller
set size to avoid set thrashing. Thus, we set the evic-
tion set size to 15 on the Alcatel One Touch Pop 2. As
we run the Prime+Probe attack in a loop, exactly 1 way
in the L2 cache will not be occupied after a few attack
rounds. We might miss a victim access in 1
16 of the cases,
which however is necessary as otherwise we would not
be able to get reproducible measurements at all due to set
thrashing. If the victim replaces one of the 15 ways occu-
pied by the attacker, there is still one free way to reload
the address that was evicted. This reduces the chance of
set thrashing significantly and allows us to successfully
perform Prime+Probe on caches with a random replace-
ment policy.
3.3 Accurate Unprivileged Timing
In this section, we tackle the aforementioned challenge 5,
i.e., cycle-accurate timings require root access on ARM.
In order to distinguish cache hits and cache misses,
timing sources or dedicated performance counters can be
used. We focus on timing sources, as cache misses have
a significantly higher access latency and timing sources
are well studied on Intel x86 CPUs. Cache attacks on
x86 CPUs employ the unprivileged rdtsc instruction
to obtain a sub-nanosecond resolution timestamp. The
ARMv7-A architecture does not provide an instruction
for this purpose.
Instead, the ARMv7-A architecture
has a performance monitoring unit that allows to mon-
itor CPU activity. One of these performance counters—
denoted as cycle count register (PMCCNTR)—can be
used to distinguish cache hits and cache misses by re-
lying on the number of CPU cycles that passed during
a memory access. However, these performance counters
are not accessible from userspace by default and an at-
tacker would need root privileges.
We broaden the attack surface by exploiting timing
sources that are accessible without any privileges or per-
missions. We identified three possible alternatives for
timing measurements.
Hit (PMCCNTR)
Miss (PMCCNTR)
Hit (syscall×.25)
Miss (syscall×.25)
Hit (clock gettime×.15)
Miss (clock gettime×.15)
Hit (counter thread×.05)
Miss (counter thread×.05)
·104
0
20
40
80
140
60
Measured access time (scaled)
100
120
160
180
200
s
e
s
s
e
c
c
a
f
o
r
e
b
m
u
N
4
2
0
Figure 4: Histogram of cross-core cache hits/misses on
the Alcatel One Touch Pop 2 using different methods.
X-values are scaled for visual representation.
layer
Unprivileged syscall. The
is an abstract
perf_event_open
to access perfor-
syscall
indepen-
mance information through the kernel
dently of the underlying hardware.
For instance,
PERF_COUNT_HW_CPU_CYCLES returns an accurate
cycle count including a minor overhead due to the
syscall. The availability of this feature depends on the