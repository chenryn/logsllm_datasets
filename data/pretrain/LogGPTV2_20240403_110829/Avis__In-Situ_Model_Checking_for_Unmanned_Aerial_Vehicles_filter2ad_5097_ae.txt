(cid:88)
(cid:88)
(cid:88)
(cid:88)
37
32
1
2
10
21
5
4
18
TABLE IV: Number of unsafe scenarios identiﬁed by each
approach in each mode.
Avis
Simulations
Found
Strat. BFI
Found
Simulations

(cid:88)

(cid:88)

N/A
N/A
3
5
N/A
TABLE V: Existing bugs triggered by Avis.
injection scenarios that were effectively redundant. The 3D
Iris sampled sensors 103 to 104 times per second. In our ex-
periments, BFI’s model took ∼ 10 seconds to label an injection
scenario. BFI was unable to explore even a single second of
data within its 2 hour budget. Stratiﬁed BFI addresses this
problem by using SABRE, Avis’s injection schedule. However,
Stratiﬁed BFI failed to correctly predict the behavior of sensor
failures during modes that were not executed long in the
workload. Table IV shows a breakdown of unsafe scenarios
found in each mode by each approach.
C. Detecting Existing Bugs
In order to approximate Avis’ false negative rate, we
evaluated Avis using bugs that were previously reported on
Github. We used 5 sensor bugs that (1) did not require special
environmental conditions, e.g., heavy winds, (2) applied to the
Iris quadcopter and (3) had serious symptoms. We reinserted
these bugs into the code base and used Avis to ﬁnd unsafe
conditions. As shown in Table V, Avis found unsafe conditions
triggered by all 5 bugs. Stratiﬁed BFI found 2. BFI and random
found none. Further, Avis triggered the bugs quickly, using at
most 21 simulations. Stratiﬁed BFI, using the SABRE search
algorithm, also discovered bugs quickly when it was effective.
Table V shows that Stratiﬁed BFI does not identify bugs that
require multiple failures, like PX4-13291. PX4-13291 reports
that a ﬂy-away occurs when the UAV’s battery drops to an
unsafe level without local position. Avis triggers this bug by
injecting a GPS fault. This causes the UAV to lose its local
position estimate. Then, Avis injects a battery sensor failure.
This causes the ﬁrmware to trigger the battery fail-safe. At
this point, Avis has triggered the bug. Stratiﬁed BFI does not
uncover this scenario because the UAV handles the GPS or
battery failure, but not both together. Having not seen the
effects of joint failures in the training data, the model is unable
to predict this outcome.
VII. RELATED WORK
Our work is related to in-situ model checking, cyber-
physical attacks and mitigation, sensor fault detection, and
empirical UAV bug studies.
a) In-Situ Model Checking: In-situ model checkers have
been successfully used to check many real systems such
as network protocol implementations [25] and ﬁle systems
[41], [42]. More recently, this technique has been applied to
distributed computing [13], [18], [40], [38], [12]. However,
existing in-situ model checkers are not effective in triggering
sensor bugs in UAVs because they do not consider the behavior
of the vehicle. As the ﬁrst in-situ model checker designed for
UAVs, Avis injects sensor faults at mode boundaries to be both
effective and efﬁcient at triggering sensor bugs.
b) Cyber-Physical Attacks and Mitigation: UAVs have
become a hot topic of security research in recent years. Sensors
have been shown to be a major attack vector for UAVs [34],
[37], [39]. These attacks work by disturbing the UAV’s sensors
to cause their models to diverge from their physical state
and actuate according to the attacker’s desires. RVFuzzer [16]
shows a method to measure the similarity between mission
executions by using state deviation, an idea that we reﬁned in
our own ﬂy-away detector. A large body of work demonstrates
how to use control semantics to detect or mitigate attacks
against vehicle [10], [8], [14]. We rely on similar principles
to design our pruning policies.
c) Detecting Sensor Faults: Prior research shows how
to detect byzantine sensor faults. Control semantics are used
for this in [14]. [31] and [17] leverage neural networks to
detect or mitigate sensor faults. Recently, [19] shows how to
use physical measurements to detect sensor faults. Prior work
shows how vehicles can survive our fault model [9]. Our work
demonstrates how to detect when a UAV fails to correctly
handle sensor failures.
d) Empirical RV Bug Studies: Both [11] and [36] look at
bug reproducibility. They ﬁnd that UAV bugs are reproducible.
We provide similar data for sensor bugs speciﬁcally and show
they are reproducible. [35] shows that sensor bugs afﬂict
participants in the robotic soccer league.
VIII. CONCLUSION
Unmanned aerial vehicles rely on sensors to model their
physical states and must contend with sensor failures. Our
empirical bug study on ArduPilot and PX4, two popular open-
source UAV control ﬁrmware, showed severe consequences for
mishandling sensor failures, a.k.a, sensor bugs. We presented
AVIS: an in-situ model checking approach for UAVs. Even
though UAVs access sensors frequently and many sensor bugs
manifest only if failures occur within narrow timing windows,
we used AVIS to ﬁnd 10 previously unknown sensor bugs of
which 2 have been reproduced by ﬁrmware developers. Avis
used modern ﬁrmware support for operating modes to inject
sensor failures at critical points during ﬂight execution. Avis
provides a missing tool for software developers, enabling a
preemptive approach to diagnose sensor bugs and analyze their
root causes. We hope our work improves reliability for this
emerging technology and unlocks new UAV applications. In
addition, we hope our work can draw more attention to UAV
reliability in the community.
11
REFERENCES
[1] ArduPilot fork with libhinj integrations.
ArdupilotLibhinj, 2021. Accessed: 2021-03-22.
[2] PX4 fork with libhinj
integrations.
PX4Libhinj, 2021. Accessed: 2021-03-22.
https://github.com/obicons/
https://github.com/obicons/
[3] Vincent G Ambrosia, Steven S Wegener, Donald V Sullivan, Sally W
Buechel, Stephen E Dunagan, James A Brass, Jay Stoneburner, and
Susan M Schoenung. Demonstrating uav-acquired real-time thermal data
over ﬁres. Photogrammetric engineering & remote sensing, 69(4):391–
402, 2003.
[4] APMCopter. Iris. http://www.arducopter.co.uk/iris-manual.html, 2020.
[5] ArduPilot. ArduPilot: Versatile, Trusted, Open. https://ardupilot.org,
Accessed: 2020-05-23.
2020. Accessed: 2020-05-23.
[6] ArduPilot Dev Team. Autotest Framework. https://ardupilot.org/dev/
docs/the-ardupilot-autotest-framework.html, 2020. Accessed: 2020-05-
25.
[7] Canberra UAV. The UAV Challenge. http://canberrauav.org.au/the-uav-
challenge/, 2020. Accessed: 2020-05-25.
[8] Hongjun Choi, Wen-Chuan Lee, Yousra Aafer, Fan Fei, Zhan Tu,
Xiangyu Zhang, Dongyan Xu, and Xinyan Deng. Detecting attacks
against robotic vehicles: A control invariant approach. In Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communica-
tions Security, CCS ’18, page 801–816, New York, NY, USA, 2018.
Association for Computing Machinery.
[9] G. R. Drozeski, B. Saha, and G. J. Vachtsevanos. A fault detection
and reconﬁgurable control architecture for unmanned aerial vehicles. In
2005 IEEE Aerospace Conference, pages 1–9, 2005.
[10] F. Fei, Z. Tu, R. Yu, T. Kim, X. Zhang, D. Xu, and X. Deng. Cross-
layer retroﬁtting of uavs against cyber-physical attacks. In 2018 IEEE
International Conference on Robotics and Automation (ICRA), pages
550–557, 2018.
[11] M. Grottke, A. P. Nikora, and K. S. Trivedi. An empirical investigation
In 2010 IEEE/IFIP
of fault types in space mission system software.
International Conference on Dependable Systems Networks (DSN),
pages 447–456, 2010.
[12] Haryadi S. Gunawi, Thanh Do, Pallavi Joshi, Peter Alvaro, Joseph M.
Hellerstein, Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau,
Koushik Sen, and Dhruba Borthakur. Fate and destini: A framework for
cloud recovery testing. In Proceedings of the 8th USENIX Conference
on Networked Systems Design and Implementation, NSDI’11, page
238–252, USA, 2011. USENIX Association.
[13] Huayang Guo, Ming Wu, Lidong Zhou, Gang Hu, Junfeng Yang, and
Lintao Zhang. Practical software model checking via dynamic interface
In Proceedings of the Twenty-Third ACM Symposium on
reduction.
Operating Systems Principles, SOSP ’11, page 265–278, New York,
NY, USA, 2011. Association for Computing Machinery.
[14] Guillermo Heredia, Anibal Ollero, Manuel Bejar, and R. Mahtani.
Sensor and actuator fault detection in small autonomous helicopters.
Mechatronics, 18:90–99, 03 2008.
[15] S. Jha, S. Banerjee, T. Tsai, S. K. S. Hari, M. B. Sullivan, Z. T.
Kalbarczyk, S. W. Keckler, and R. K. Iyer. Ml-based fault injection for
autonomous vehicles: A case for bayesian fault injection. In 2019 49th
Annual IEEE/IFIP International Conference on Dependable Systems and
Networks (DSN), pages 112–124, 2019.
[16] Taegyu Kim, Chung Hwan Kim, Junghwan Rhee, Fan Fei, Zhan Tu,
Gregory Walkup, Xiangyu Zhang, Xinyan Deng, and Dongyan Xu.
Rvfuzzer: Finding input validation bugs in robotic vehicles through
control-guided testing. In Proceedings of the 28th USENIX Conference
on Security Symposium, SEC’19, page 425–442, USA, 2019. USENIX
Association.
[17] Emre Kiyak. A fault tolerant ﬂight control system for sensor and actuator
faults. In International Conference on Dynamical Systems and Control,
01 2010.
[18] Tanakorn Leesatapornwongsa, Mingzhe Hao, Pallavi Joshi, Jeffrey F.
Lukman, and Haryadi S. Gunawi. Samc: Semantic-aware model check-
ing for fast discovery of deep bugs in cloud systems. In Proceedings of
the 11th USENIX Conference on Operating Systems Design and Imple-
mentation, OSDI’14, page 399–414, USA, 2014. USENIX Association.
[19] Sumukh Marathe, Akshay Nambi, Manohar Swaminathan, and Ronak
Sutaria. CurrentSense: A novel approach for fault and drift detection
in environmental IoT sensors. In 2021 IEEE/ACM Sixth International
Conference on Internet-of-Things Design and Implementation (IoTDI),
2021.
[20] M Anwar Ma’Sum, M Kholid Arroﬁ, Graﬁka Jati, Futuhal Ariﬁn,
M Nanda Kurniawan, Petrus Mursanto, and Wisnu Jatmiko. Simulation
of intelligent unmanned aerial vehicle (uav) for military surveillance.
In 2013 International Conference on Advanced Computer Science and
Information Systems (ICACSIS), pages 161–166. IEEE, 2013.
[21] MAVLink. MAVLink Developer Guide. https://mavlink.io/en/, 2020.
Accessed: 2020-05-23.
[22] Max Taylor. Avis: The aerial vehicle in situ model checker. https:
//github.com/obicons/avis, 2021. Accessed: 2021-03-22.
[23] Max Taylor. libhinj: The Hardware Fault INJector library. https://github.
com/obicons/libhinj, 2021. Accessed: 2021-03-22.
[24] L. Meier. PX4 Issue Tracker. https://github.com/PX4/PX4-Autopilot/
issues/13291, 2020. Accessed: 2020-12-07.
[25] Madanlal Musuvathi, David Y. W. Park, Andy Chou, Dawson R. Engler,
and David L. Dill. Cmc: A pragmatic approach to model checking real
code. SIGOPS Oper. Syst. Rev., 36(SI):75–88, December 2003.
[26] Nicholas Nethercote and Julian Seward. Valgrind: A framework for
heavyweight dynamic binary instrumentation. In ACM Conference on
Programming Language Design and Implementation, pages 89–100,
2007.
[27] V. Poon. How Drone Technologies Are Used In The Current COVID-19
https://px4.io/how-drone-technologies-
2020.
Medical Response Operation.
are-used-in-the-current-covid-19-medical-response-operation/,
Accessed: 2020-05-25.
[28] PX4. PX4 Autopilot: Open Souce Autopilot for Drones. https://px4.io,
2020. Accessed: 2020-05-23.
[29] PX4 Dev Team. Simulation Debugging. https://dev.px4.io/v1.9.0/en/
debug/simulation debugging.html, 2020. Accessed: 2020-05-25.
[30] PyMAVLink. PyMAVLink. https://github.com/ArduPilot/pymavlink/,
2020. Accessed: 2020-05-23.
[31] I. Samy, I. Postlethwaite, and D. Gu. Neural network based sensor
validation scheme demonstrated on an unmanned air vehicle (uav)
model. In 2008 47th IEEE Conference on Decision and Control, pages
1237–1242, 2008.
[32] L. Schroth, H. Bodecker, and M. Radovic. The drone market report.
[33] D. Selwod. What happens when yourgps fails. https://www.eejournal.
https://droneii.com, 2020.
com/article/20111109-gps/, 2020.
[34] Yunmok Son, Hocheol Shin, Dongkwan Kim, Youngseok Park, Juhwan
Noh, Kibum Choi, Jungwoo Choi, and Yongdae Kim. Rocking drones
In 24th USENIX
with intentional sound noise on gyroscopic sensors.
Security Symposium (USENIX Security 15), pages 881–896, Washington,
D.C., August 2015. USENIX Association.
[35] Gerald Steinbauer. A survey about faults of robots used in robocup. In
Xiaoping Chen, Peter Stone, Luis Enrique Sucar, and Tijn van der Zant,
editors, RoboCup 2012: Robot Soccer World Cup XVI, pages 344–355,
Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.
[36] C. S. Timperley, A. Afzal, D. S. Katz, J. M. Hernandez, and C. Le Goues.
Crashing simulated planes is cheap: Can simulation detect robotics bugs
early? In 2018 IEEE 11th International Conference on Software Testing,
Veriﬁcation and Validation (ICST), pages 331–342, 2018.
[37] T. Trippel, O. Weisse, W. Xu, P. Honeyman, and K. Fu. Walnut: Waging
doubt on the integrity of mems accelerometers with acoustic injection
attacks. In 2017 IEEE European Symposium on Security and Privacy
(EuroS P), pages 3–18, 2017.
[38] Maysam Yabandeh, Nikola Kneˇzevi´c, Dejan Kosti´c, and Viktor Kun-
cak. Predicting and preventing inconsistencies in deployed distributed
systems. ACM Trans. Comput. Syst., 28(1), August 2010.
[39] Chen Yan, Wenyuan Xu, and Jianhao Liu. Can you trust autonomous
vehicles: Contactless attacks against sensors of self-driving vehicle. DEF
CON, 24(8):109, 2016.
[40] Junfeng Yang, Tisheng Chen, Ming Wu, Zhilei Xu, Xuezheng Liu,
Haoxiang Lin, Mao Yang, Fan Long, Lintao Zhang, and Lidong Zhou.
Modist: Transparent model checking of unmodiﬁed distributed systems.
In Proceedings of the 6th USENIX Symposium on Networked Systems
Design and Implementation, NSDI’09, page 213–228, USA, 2009.
USENIX Association.
[41] Junfeng Yang, Can Sar, and Dawson Engler. Explode: A lightweight,
general system for ﬁnding serious storage system errors. In Proceedings
of
the 7th USENIX Symposium on Operating Systems Design and
Implementation - Volume 7, OSDI ’06, page 10, USA, 2006. USENIX
Association.
12
[42] Junfeng Yang, Paul Twohey, Dawson Engler, and Madanlal Musuvathi.
Using model checking to ﬁnd serious ﬁle system errors. ACM Trans.
Comput. Syst., 24(4):393–423, November 2006.
[43] Ming-Der Yang, Jayson G Boubin, Hui Ping Tsai, Hsin-Hung Tseng,
Yu-Chun Hsu, and Christopher C Stewart. Adaptive autonomous uav
scouting for rice lodging assessment using edge computing with deep
learning edanet. Computers and Electronics in Agriculture, 179:105817,
2020.
[44] Zichen Zhang, Jayson Boubin, Christopher Stewart, and Sami Khanal.
Whole-ﬁeld reinforcement learning: A fully autonomous aerial scouting
method for precision agriculture. Sensors, 20(22):6585, 2020.
13