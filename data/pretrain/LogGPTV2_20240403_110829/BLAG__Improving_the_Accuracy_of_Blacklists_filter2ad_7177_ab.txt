entire network (e.g., one or a set of IP preﬁxes) could improve
coverage of malicious sources. Figure 1(c) shows the number
of blacklisted IP addresses in the same /24 preﬁx, for all /24
preﬁxes that are present in the blacklist dataset observed during
the entire monitoring period. About 57.5% of /24 preﬁxes have
at least two blacklisted IP addresses in the same /24 preﬁxes.
For about 1.7% of /24 preﬁxes, nearly half the /24 preﬁx (128
IP addresses) are blacklisted. Only a few /24 preﬁxes have
(0.007%) all their IP addresses in a /24 preﬁx blacklisted.
Identifying preﬁxes that harbor more malicious sources can
increase the blacklist’s coverage of malicious sources.
D. Careful Aggregation and Expansion
Not all IP addresses that appear on blacklists are necessar-
ily malicious. Some may have been malicious and got cleaned,
which means that the blacklist has stale information. Others
may have been misclassiﬁed by the blacklisting algorithm.
Since blacklists are built using proprietary algorithms, it is
impossible to evaluate their accuracy and/or bias.
If we were to naïvely aggregate and expand blacklisted
addresses, this would amplify bias and misclassiﬁcation of
legitimate sources. For example, Figure 2(c) illustrates, on
the y-axis, the percentage of legitimate addresses in our three
Scenario datasets (see Section IV for details on datasets) that
appears on a blacklist. These address sets are mostly disjoint
and are collected from regular inbound trafﬁc in three different
networks. The x-axis shows different blacklists in our Blacklist
dataset. The order of blacklists is always the same on the x-
axis. For this Figure, we used naïvely aggregated historical
data of each blacklist, i.e, for a given blacklist we produced the
list of all addresses that were listed on it up to the time of our
Scenario (shown in blue). We make several observations. First,
for each Scenario, all misclassiﬁcations are concentrated on a
few blacklists. On average, about 0.14%, 0.17% and 0.016%
of legitimate IP addresses are misclassiﬁed. Blacklists such as
Cruzit [16] and Chaos Reigns [4] have high misclassiﬁcations
of 3.3% and 9.8% respectively. Figure 2(c) also shows that
3
050100150020406080100(#) of blacklists(%) of reported addresses that re­offend  in the same blacklist050100150200020406080100Days between reoffense(%) of reoffenses0102002040600501001500369Naïve aggregationNaïve aggregation expansion(#) of blacklist(%) of misclassificationsScenario 1Scenario 2Scenario 3Figure 3: BLAG implementation consists of assigning relevance scores to IP addresses from different blacklists and creating a
new misclassiﬁcation blacklist (MB). The MB contains all possible IP addresses, but a score is only assigned to those that are
misclassiﬁcations from the known-legitimate sources dataset (Ltr). Then, a recommendation system generates missing scores
for IP addresses in the MB. IP addresses that have a score higher than α threshold (red blocks in MB) are pruned out and
the remaining ones are used for aggregation. These IP addresses will be put on a new blacklist known as “Master blacklist
candidates”. Finally, we selectively expand some candidates into /24 preﬁxes, if we estimate that this expansion will not severely
increase misclassiﬁcation.
there is no single blacklist that has misclassiﬁcations across
all three scenarios, thus removing certain blacklists will not
solve the problem. Instead, we must tailor each blacklist to
the customer that is going to use it, to identify and remove
portions that may lead to misclassiﬁcations of the sources of
customer’s inbound trafﬁc.
Naïve expansion of blacklisted addresses into preﬁxes can
also lead to misclassiﬁcations. We take the naïvely aggregated
historical data described earlier, expand every address to its
/24 preﬁx and show the percentage of misclassiﬁcation in
Figure 2(c) (yellow dotted lines). We see that the percentage of
misclassiﬁcations further increases with naïve expansion. On
average, about 0.66%, 6.6% and 1.03% of legitimate addresses
are misclassiﬁed. Blacklists such as Cleantalk [14] and Chaos
Reigns [4] have high misclassiﬁcation of 67.2% and 22.6%
respectively. Although blacklisted addresses are collocated,
naïvely expanding them into /24 preﬁxes can increase mis-
classiﬁcations.
III. BLAG DESIGN
We present BLAG’s design in this section and illustrate
the system in Figure 3. BLAG collects historical data from
multiple blacklists (B) and updates this dataset whenever a
blacklist is updated by its maintainers. When a customer wants
to use BLAG, our system uses its historical dataset (B) and a
sample of the legitimate sources that send inbound trafﬁc to
the customer network (Ltr) to curate a master blacklist tailored
to that customer.
BLAG’s goal when producing the master blacklist is to
include as much information about malicious sources from (B)
as possible while ensuring that very few current (Ltr) or future
(Lte) legitimate sources of the customer get blacklisted. To
achieve this, we need a relatively accurate list of legitimate
sources that communicate with the customer. One way a
customer could build this list would be to leverage its existing,
more sophisticated defenses. Many networks today run an
intrusion detection system, a ﬁrewall, and a spam ﬁlter. These
defenses will drop or quarantine some trafﬁc during regular
operation. Let us denote the sources of dropped or quarantined
trafﬁc as (D) and let (A) represent all sources that have recently
sent inbound trafﬁc to the customer. The customer can create
(Ltr) by starting with a set (A) and removing sources that
appear in (D).
BLAG’s operation proceeds in the following steps:
(1) Evaluate the relevance of every address on every
blacklist in (B) (Section III-A), taking into account the listing’s
age (similar to [78]) and re-offense history. The relevance
score is the function of the address’s history on a particular
blacklist.
(2) Aggregate IP addresses and run the recommendation
system using IP addresses in the (Ltr) set. The system predicts
relevance scores of IP addresses that are not in (Ltr) but may
be among legitimate sources for the customer network in the
future (F ⊂ Lte). This step ends with a set of addresses that are
likely legitimate and likely to communicate with the customer
network in the future (F). BLAG then uses a threshold-based
approach to prune out current and likely misclassiﬁcations (all
addresses from (Ltr) and most addresses from (F)) and the
remaining IP addresses form the master blacklist candidates.
(3) Selectively expand some candidate IP addresses into
preﬁxes to increase malicious source identiﬁcation. During this
expansion we use (Ltr) and (F) sets to estimate the likely
increase in misclassiﬁcation for each candidate if it were to be
expanded into an IP preﬁx. Our expansion method is selective
because it balances the gain in malicious source identiﬁcation
against potential future misclassiﬁcations (Section III-C).
A. Relevance Scores: Evaluating Quality
Historical blacklist data can be a valuable source to detect
potential re-offenders. Earlier, we have seen that about 29% of
blacklisted IP addresses re-offend and 91% of these reoffenses
4
Relevance ScoreCalculation169.231.140.68193.1.64.8216.59.16.171Blacklist 1Blacklist 2Blacklist mBlacklist 3 ..169.231.140.68193.1.64.5193.1.64.8216.59.0.8243.13.0.23MB169.231.140.10243.13.222.203193.1.64.5216.59.0.8169.231.140.68193.1.64.8216.59.16.171Blacklist 1Blacklist 2Blacklist m-1Blacklist 3 ..243.13.0.23MB169.231.140.10243.13.222.203193.1.64.5216.59.0.8RecommendationsystemEvaluateAggregateExpandKnown Legitimatesources (Ltr)Currently andhistorically listedIP addresses (B)Likely to be a misclassiﬁcationUnlikely to be a misclassiﬁcationPrune 193.1.64.0/24216.59.0.0/24169.231.140.68SelectiveexpansionBL 1BL m....0.280.11......0.46....0.720.23........0.32....0.58....0.15..0.250.950.87............0.790.87..0.810.220.40.120.910.60.920.99....0.78....0.750.30.1......0.5....0.70.5........0.04....0.7....0.1..0.10.90.9............0.71..0.9???1?11....0.8....?Master blacklistcandidatesBLAG masterblacklist occur within 30 days. We have also seen that blacklists of
different attack types overlap. Existing work also agrees with
our ﬁndings. PRESTA [78], a study on three paid-for blacklists
shows that recent offenders are more likely to re-offend. BLAG
starts its aggregation by generating a relevance score for each
address a listed in blacklist b ∈ B based on the formulation
used by PRESTA. BLAG deﬁnes relevance score ra,b as:
ra,b = 2
l
t−tout
(1)
where l is a constant, which we set empirically (discussed
in Section VII), tout is the most recent de-listing (removal)
time of a at blacklist b and t is the time in days when the
score is calculated. The exponential factor ensures that the
score decays exponentially over time, giving higher weight to
recently blacklisted IP addresses. The relevance score ranges
from 0 to 1, and a higher score indicates a higher chance of
reoffense. If the address a is currently listed in b, we set its
relevance score to 1.
B. Recommendation System: Estimating Future Misclassiﬁca-
tions
Ideally,
if we knew all
legitimate IP addresses in the
Internet at any given time, or if we knew which currently
blacklisted addresses are no longer malicious, we could prune
out misclassiﬁcations during aggregation. However, it is im-
possible to know this information. At best, a customer network
has limited visibility into some set of its known-legitimate
sources (Ltr), which have recently communicated with the
customer. We leverage this set
to predict IP addresses (F
⊂ Lte) that may be future legitimate trafﬁc sources for the
customer network, and that would be misclassiﬁed in BLAG’s
aggregation and expansion steps.
When all the relevance scores are calculated, BLAG places
them into a score matrix where blacklists from (B) are at
the columns and all listed IP addresses (in any blacklist) are
at the rows as shown in Figure 4 (see Evaluate step). Each
cell in the score matrix holds the relevance score ra,b for
the given row (address a) and given column (blacklist b).
BLAG adds a new, artiﬁcial blacklist to this matrix, called
the “misclassiﬁcation blacklist” (MB column in Figure 4).
MB contains all known-legitimate sources from the set (Ltr).
BLAG assigns a relevance score ra,M B of 1 to all IP addresses
a listed in the misclassiﬁcation blacklist. This high score will
help us identify likely future misclassiﬁcations (F).
The misclassiﬁcation blacklist column is sparse because
many addresses that exist in (B) do not appear in (Ltr) and
we cannot know if they are legitimate or malicious. BLAG
ﬁlls the empty cells of the misclassiﬁcation blacklist column
by using a recommendation system.
Recommendation systems are usually used to predict future
product ratings by some users, given a set of past ratings of
same or related products, by target users and other similar
users. A well-known example is the Netﬂix recommendation
system [59], which may recommend a new movie M to user U
by relying on the U’s past ratings of movies similar to M, and
on ratings that users similar to U have given to M or movies
similar to M. In our context, IP addresses are analogous to
movies that are being evaluated, and blacklists are analogous
5
to users assigning the rating. We view the relevance score as
the rating.
Two most commonly used types of recommendation sys-
tems are content-based recommendation system [69] and
collaborative ﬁltering [72]. A content-based recommendation
system would require an explicit deﬁnition of features that a
blacklist uses to determine if an IP address should be listed.
Such features are hard to obtain since each blacklist maintainer
has its private criteria for listing an address. Collaborative
ﬁltering infers information about
the relationship between
a blacklist and an address being listed in a blacklist, by
using only the existing relevance scores. That is, it infers
the relationship between blacklists and IP addresses, based on
when the IP addresses were listed in blacklists and based on
similarity in listing dynamics of different blacklists. It then
uses the inferred relationships to predict relevance scores for
missing cells in the score matrix. We use collaborative ﬁltering
in BLAG.
Figure 4 illustrates the recommendation system’s operation
for a customer network. Let M and N represent the set of
IP addresses and blacklists, respectively. Let R be a score
matrix of size |M xN| which consists of relevance scores
quantifying the relevance of an address being listed by a
given blacklist. For example, in Figure 4, score matrix R
consists of four blacklists (M = 4), and ﬁve IP addresses
(N = 5). Misclassiﬁcation blacklist, curated from known-
legitimate sources (Ltr) for the customer network, is added as
the last column in the matrix, and in this example, 128.0.0.5
(highlighted in red) is present in (Ltr). Blacklisted IP addresses
have been present at various times in different blacklists, which
is reﬂected by the relevance score’s value. Address 128.0.0.1
listed in nixspam blacklist has a high score of 0.7 since it
was the most recently listed address. Address 128.0.0.2, on
the other hand, has a low score of 0.1 in openbl blacklist,
since it was listed long ago. Finally, address 128.0.0.5, has a
score of zero in nixspam blacklist, where it has never been
listed and has a score of 1 in MB since it is known to send
legitimate trafﬁc (Ltr) to the customer network. There are
latent (unknown) features of blacklists and IP addresses that
lead to an address being listed in a blacklist. Let the number of
latent features that inﬂuence relevance scores of IP addresses in
blacklists be K (see Section VII for how we choose the value
of K). In this example, we set K = 2. Our goal is to estimate
the relevance scores of IP addresses that are not present in
MB, by estimating two matrices P (|M xK|) and Q(|N xK|),
which are factors of the original matrix R, such that their
cross product is approximately equal to known values in R. In
other words, matrix factorization is used on R to obtain factor
matrices P and Q such that:
R ≈ P × QT = R(cid:48)
(2)
We obtain the values of latent matrices P and Q using gradient
descent [62], which randomly assigns values to P and Q
and estimates how different the product of P and Q is from
the original score matrix R. We use root mean squared error
(RMSE) to estimate the difference. Gradient descent tries to
minimize RMSE iteratively. We discuss in Section VII the
number of iterations required to have a small RMSE. After
obtaining matrices P and Q, each row in P represents the
association strength between IP addresses and latent features
K, and each row in Q represents the association strength
Figure 4: Latent factorization of the score matrix R, a M × N matrix, where M is the number of IP addresses and N is the
number of blacklists. The cells indicate relevance scores. IP addresses not listed in a blacklist are assigned a zero score and IP
addresses listed in misclassiﬁcation blacklist (MB) are given a score of 1. Score matrix is factorized into two matrices of M × K
and K × N, and the cross product results in a new matrix R(cid:48), which updates the missing scores in MB.
between blacklists and latent features K. To obtain a relevance
score for an address a in misclassiﬁcation blacklist MB, the
dot product of two latent vectors corresponding to address a
and MB is calculated as follows:
ra,b = pT
a qM B
(3)
Where pa deﬁnes the association strength of address a with
features K and qM B deﬁnes the association strength of MB
with features K.
Consider IP addresses 128.0.0.1 and 128.0.0.5 in Figure 4,
where one of them is listed in the MB and the other is not. Both
IP addresses have similar relevance scores in other blacklists
(with bambenek_c2’s scores of 0.6 and 0.7, and openbl’s scores