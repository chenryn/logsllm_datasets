The trampoline code is placed in a page of memory al-
located from the nonpaged memory pool by calling the ker-
nel function ExAllocatePoolWithTag. This ensures
that the trampoline is always available, and will never be
swapped to disk. The trampoline code section is copied
from within the driver’s code base to the newly allocated
memory region. In order to modify the SSDT, we ﬁrst iden-
tify the index of the NtCreateSection service. Then
we identify the base of the SSDT using the kernel sym-
bol KeServiceDescriptorTable. We then create the
hook by placing the address of the trampoline in the appro-
priate entry after storing the old service routine’s address
(i.e., the location of the actual NtCreateSection func-
tion) in a pointer. This pointer is placed in the newly al-
located memory region along with the trampoline code, so
that it is protected from malicious modiﬁcations.
Once the hook is placed to point to the trampoline code,
the driver initiates a notiﬁcation call using a VMCALL to
the hypervisor to inform the installation of the hook and the
address range of the newly allocated memory region. This
information is used to secure the indicated regions using
the prot range hypercall described in Section 4.4. This
entire process is completed during the secure initialization
of the guest OS.
4.2
Inter-VM Communication
When the trampoline code from the guest OS makes a
VMCALL into Xen, it is sending a signal asking Xen to
assist with inter-VM communication. In our architecture,
inter-VM communication is facilitated by Xen with signal-
ing from the domains performed through hypercalls. We
added a new hypercall to Xen, lares op, that is callable
from both the guest VM (via a VMCALL instruction) and the
security VM (via a direct hypercall). This hypercall takes
two arguments. The ﬁrst argument is a command. If the
command requires a parameter, it is sent as the second ar-
gument. We provide details on each command below.
The
LARESOP security register
command
saves a memory address of the buffer used to exchange
information between Xen and the security driver. The other
two commands are slightly more complex.
The LARESOP guest hook command builds
a
struct to send as a request to the security driver. This
struct contains a unique identiﬁer for the request and
information about
the hook event (e.g., hook number,
associated Windows handle, or process id). This struct
is copied to the security driver’s shared memory region
and then a virtual interrupt is sent to the security VM.
This virtual interrupt, which is implemented using Xen
event channels, is a signal to the security driver to process
the hook information in its shared memory region. At
this point, the command waits at a barrier until a reply is
provided by the security driver. After the reply is provided,
it is returned causing the VMCALL instruction to return,
which allows the guest VM to continue normal operation.
The reply from the security driver is signaled with the
LARESOP security response command. Upon re-
ceiving this command, Xen gets the reply value by copying
a struct from the security driver’s shared memory region.
Next, the command makes this reply available to the hook
command and breaks its barrier.
These three commands, implemented as a single hyper-
call, are all that is needed to support the inter-VM commu-
nication for the Lares architecture. They were implemented
by adding 127 SLOC to Xen.
4.3 Security Driver and Application
The security driver and application are designed to ex-
ecute within the same VM. For our implementation, this
VM is the privileged para-virtualized VM called “domain
0” because it already has the necessary privileges to view
memory from other VMs, thus simplifying memory intro-
spection. However, it would be possible to implement this
functionality in a fully-virtualized VM, or a different para-
virtualized VM, if desired. Regardless of the location of
these components, their function remains the same.
The security driver is designed to pass information up
from Xen to the security application, and down from the
239
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:19 UTC from IEEE Xplore.  Restrictions apply. 
Security VM (domain 0)
Security
Application
signal
ioctl
Security
Driver
virtual IRQ via
event channel
hypercall
Xen Hypervisor
PsInitialSystemProcess
...
EPROCESS
EPROCESS
EPROCESS
EPROCESS
EPROCESS
ObjectCode
HandleTable
TableCode
Body
Object
Object
Header
Object
Handle 
Tables 
L1,L2,L3
Figure 3: (Left) The information ﬂow path from Xen, through the security driver, to the security application
and back are all event driven to provide good performance when processing hook events from the guest
VM. (Right) An overview of the data structures in the guest OS kernel traversed using introspection. The
TableCode pointer is resolved at initialization time so that handles can be resolved efﬁciently for each hook.
security application to Xen as shown in Figure 3. No in-
formation processing or decision making occurs within this
driver. This is an intentional design choice because it is
harder to implement and change kernel-level code. As new
features are added to this system, changes will typically
only be made to the security application.
Since the security driver is designed to run in the Linux
kernel, it is implemented as a Linux kernel module (LKM).
The LKM is installed automatically when the security ap-
plication is started. During initialization, the LKM sets up a
shared memory region, a proc entry and its handler, and a
virtual interrupt handler. The shared memory region is used
to pass data between the security driver and Xen, as de-
scribed in Section 4.2. The proc entry receives data from
the security application and the virtual interrupt handler re-
ceives signals from Xen.
When
a
by
virtual
interrupt
triggered
the
is
LARESOP guest hook command,
as described in
Section 4.2, the security driver sends a signal to the security
application. This signal tells the application that there is a
new hook event to process. The LKM knows which process
identiﬁer (PID) to send the signal to because the application
provides its PID as a module parameter to the LKM.
The security application is responsible for sending both
the LARESOP security register command and the
LARESOP security response command to Xen. Af-
ter installing the LKM, the application sends a registra-
tion command to the driver by issuing an ioctl request
through its proc interface. This command is forwarded to
Xen using the lares op hypercall. Likewise, after receiv-
ing a signal from the LKM, the application issues an ioctl
request to receive the hook information and another ioctl
request to send the response back to Xen.
After receiving the hook information, and before send-
ing the response back to Xen, the security application must
make a decision about how to handle this hook event. The
decision is based on contextual information related to this
240
hook event that is obtained using memory introspection.
To access memory from the guest VM based on the guest
OS’s virtual addresses, we use the XenAccess library [22].
The hook that we implemented provides the security ap-
plication with a Windows ﬁle handle that was passed to
NtCreateSection. We lookup this handle in the ker-
nel memory of the guest OS, and then extract the ﬁlename
associated with the handle. Our implementation then allows
execution of this ﬁle if it is contained within a white list of
allowed executable ﬁles. More complex policies could also
be implemented such as inspecting the ﬁle for a virus sig-
nature or to validate its checksum. The sophistication of
these policies is only limited by the information available in
memory, or on disk, in the guest VM.
Looking up the Windows ﬁle handle using introspec-
tion requires bridging a semantic gap. The memory struc-
tures we traverse are shown in Figure 3. We ﬁrst iden-
tify the PsInitialSystemProcess which is a Win-
dows EPROCESS struct representing the system pro-
cess. Next, we traverse ActiveProcessLinks, which
is a circular doubly linked list of all processes on the sys-
tem. We identify the process associated with our hook, and
then follow a series of pointers to the level 1 (L1) han-
dle table. From this point, we walk the handle tables that
are structured similarly to multi-level page tables. Next,
we get the address of the handle’s object header. The
ObjectHeader struct contains a pointer to the object
type. If the object is a ﬁle object, then we resolve the object,
which contains the full path and ﬁle name. Finally, this ﬁle
name is used to verify if the hook should be allowed.
The security driver and application are both written in C.
The driver is 182 SLOC and should not require any changes
when new hooks are added to the system. The applica-
tion is 298 SLOC for our proof of concept implementation.
More complex policies and the handling of additional hooks
would be added to this code base, making such changes rel-
atively simple to implement and debug.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:19 UTC from IEEE Xplore.  Restrictions apply. 
Guest page table
Virtual                 Physical
PTE propagation
Shadow page table
Virtual                Machine
Is the PF listed as 
protected?
NO
YES
Page fault due to
failed write
YES
Is the write targeted at 
a protected region?
NO
Mark as read-only
Propagate exception 
to guest
Emulate the 
write
Figure 4: The page protection scheme leverages the propagation of page table entries (PTEs) from guest
space to hypervisor space (left) to protect memory pages, as well as Xen’s page fault handler to make sure it
can be done with a byte-sized granularity by emulating the memory write (right).
4.4 Memory Protection
We leveraged Xen’s memory management subsystem
when building the memory protection mechanism. The
primary goal of memory management in Xen is to virtu-
alize each guest OS’s view of memory and enforce isola-
tion between the OSes. In fully-virtualized VMs, Xen does
this using a technique called shadow paging. This tech-
nique maintains two versions of page tables for each VM:
guest page tables (GPTs), which are controlled by the guest;
and shadow page tables (SPTs), which are controlled by
the hypervisor. The guest OS handles its GPTs the same
as it would in a non-virtualized setting. The main differ-
ence is that the GPT’s mappings translate virtual addresses
to an intermediate layer of addresses, called physical ad-
dresses. Physical addresses virtualize the memory view of
a guest OS, similar to the way virtual addresses work for
processes. SPTs provide direct mappings from virtual to
machine addresses, which are the addresses used by the
hardware. Therefore, the SPTs are used by the hardware
to translate addresses for the guest OS while Xen maintains
consistency between the GPT and SPT. When an entry is
added or changed in a GPT, Xen translates the physical ad-
dress into its corresponding machine address, performs any
necessary adjustments, and then updates the corresponding
SPT. This process is called page table entry (PTE) propa-
gation. Under this model, Xen controls the actual machine
frames used by each VM, while also providing each guest
OS with the illusion that it has full control of the memory.
Our memory protection mechanism protects arbitrary
memory regions with a byte-sized granularity. It is com-
posed of two main parts. The ﬁrst is implemented in the
sh progatate function, which controls the propagation
of entries from GPTs to SPTs. The second is implemented
in the sh page fault function, Xen’s page fault handler.
Our mechanism adds 78 SLOC to Xen, satisfying our re-
quirements of making only minimal additions to it.
The ﬁrst part, illustrated on the left of Figure 4, imple-
ments the core technique behind our protection mechanism.
At this location we intercept the propagation of entries be-
tween the GPTs and SPTs, and then write-protect desig-
nated frames of the guest OS’s physical memory. This can
happen whenever an entry is modiﬁed in a GPT, either le-
gitimately or by an attacker. Since Xen has full mediation
over propagation and is isolated from the the guest OS, such
protection cannot be circumvented. We store a list of the
memory regions that require protection, which we call the
protection list. Each time an entry is propagated from a GPT
to an SPT, this list is searched for the entry’s physical frame.
If it is found, its corresponding shadow copy is marked as
read-only. This prevents the guest OS from performing any
further modiﬁcations to this page frame.
By itself, this technique only provides page-level pro-
tection, which is problematic if a page contains protected
and writable regions. The second part of our mechanism
extends this technique to provide byte-level protection. Its
operation is illustrated on the right of Figure 4. Each time a
page fault occurs due to a failed write, we check the target’s
virtual address, which is stored in the cr2 CPU register.
Next, we check the protection list to see if the target ad-
dress requires protection. If it does, a page fault exception is
propagated to the guest OS, preventing the write attempt. If
not, then the guest is attempting to write to a non-protected
region of a frame that contains a protected region. In this
case, we emulate the write operation for the guest OS.
We added a new hypercall, prot range, that can be
called from the security application running in domain 0 to
initialize the protection list. This is done from domain 0
during the architecture’s initialization, as soon as the hook
and the trampoline are placed inside the guest OS. Addi-
tional memory ranges can also be added to the list at run-
time, if desired. Each time an update is made to the list,
the shadow page cache is erased to eliminate outdated map-
pings and force the re-propagation of new mappings. Since
most applications, including our prototype, only add items
to this list during initialization, there is no runtime perfor-
mance impact on the system.
241
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:19 UTC from IEEE Xplore.  Restrictions apply. 
This combination of page-sized memory protection and
write emulation allows us to efﬁciently implement the pro-
tection of arbitrary memory regions of the guest OS, with
the granularity of a single byte. In our prototype, we used
this mechanism to protect several memory regions in the
guest OS. The ﬁrst was the NtCreateSection hook
placed in the SSDT, a 4-byte long function pointer. The
second was the trampoline, a segment of code consisting of
89 bytes in a memory page allocated when the architecture
is initialized. Additional components that require protection
to prevent hook circumvention are discussed in Section 6.
5 Evaluation
We tested both the security and performance of our pro-
totype implementation. Security was tested by verifying
that the memory protection techniques worked as expected.
In addition, we provide an extensive analysis of our archi-
tecture’s security in Section 6. Performance was tested by
measuring the time required to process a hook using our ar-