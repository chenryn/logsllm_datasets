being intersections of cases, as discussed before for IPA and IPB.
Hence, we have to conduct experiments (results shown in Section
5.2) to better understand the behaviour of incorrect recognitions
(FAR and IPR).
4.4 Leveraging non boolean output—can we
do it better, for free?
By combining the basic methods in a boolean way, as presented
in Section 4.3, we considered only the binary output (1, accepted,
or 0, rejected) of each single basic method involved in the combi-
nation. Instead, we argue that each single basic method has poten-
tially more information, rather than just the binary output (accep-
t/reject). In fact, each of the two algorithms (DTW-D and DTW-S)
considered in the basic methods gives its output based on a sim-
ilarity measure. The similarity measure is a value that expresses
how close (or how far) is the new test pattern compared to the T
patterns in the training set. While a single method can only out-
put a binary value with respect to a threshold, combining meth-
ods together, as described below, can convey more information. In
particular, the intuition is the following. Assume for example that
Method A suggests that the new pattern is very close to the one
of the correct user, while Method B suggests that the pattern does
not belong to the correct user just because the similarity goes be-
yond the threshold for a small value. We expect that in this case,
the likelihood that Method B is making a mistake is signiﬁcantly
higher than the probability that Method A is making a mistake. We
describe combinations that can be applied to both DTW-D (Section
3.2.1) and DTW-S (Section 3.2.2) to leverage additional informa-
tion from the similarity measure, rather than only binary outputs.
We expect that this combination is able to signiﬁcantly reduce, at
the same time, both FAR and IPR (not just one of them as we expect
for the boolean combination).
4.4.1 DTW-D Normalized
In DTW-D, a test pattern is compared with the threshold maxDist
+ (cid:28)D (cfr. Section 3.2.2). We modify DTW-D to have an output that
is normalized, in the range of possible distances from maxDist
+ (cid:28)D. In presenting the proposed normalization, we refer to Fig-
ure 2, where: the line represents an axis where the possible output
similarity values lie (lower bounded by 0—for identical patterns);
above the line we indicate the range of values that are accepted,
[0, maxDist + (cid:28)D), and the range of values that are rejected,
[maxDist + (cid:28)D, ∞); av and rv indicate the values assigned to
an example of accepted and an example of a rejected pattern, re-
spectively (their computation are explained below); the dotted in-
terval indicates the distance between the value av and maxDist
+ (cid:28)D; similarly, the dashed interval indicates the distance between
the example of a rejected value rv and maxDist + (cid:28)D.
That is, we want to make the obtained value normalized to a ref-
erence interval. We consider as reference interval the one from 0
to maxDist + (cid:28)D, that is the interval of all possible accepted val-
ues. This normalization will apply to both av and rv. The result r
outputted by the normalized DTW-D will be:
i=1 di=T )  0, if (
∑
• r  (maxDist + (cid:28)D);
r =
(maxDist + (cid:28)D)
T
i=1 di=T
:
(7)
4.4.2 DTW-S Normalized
We give a normalized version of DTW-S in a way that is similar
to the one used for DTW-D (Section 4.4.1). The main difference
is the way users get accepted. In this case, a test pattern is consid-
ered to correspond to the authorized user if the result is greater (not
smaller, as for the DTW-D) than a given threshold. We refer to Fig-
ure 3 to describe the normalized version of DTW-S. The notation
used in the ﬁgure is consistent with the one described in Section
4.4.1 for Figure 2. However, we underline that the accepted val-
ues are now on the right of the threshold (that here is (cid:28)S), and the
rejected values are on the left of the same threshold.
Figure 3: Normalized output for DTW-S.
The result r, for the normalized version of DTW-S, is computed
according to the following equation (where si is the similarity value
that the non normalized version of DTW-S outputs):
∑
r =
T
i=1 si=T − (cid:28)S
(cid:28)S
(8)
Figure 2: Normalized output for DTW-D.
We remind that DTW-D, in its intermediate steps (cfr. Section
3.2.2), computes for the test pattern a distance di from each pat-
tern in the training set (i = 1 : : : T ). Then, these di are evaluated
to decide whether to accept or reject the test pattern (cfr. Section
3.2.2). Here, we propose a different usage of these di. First, we
compute the average of this values (
i=1 di=T ). In case this av-
erage is ≤ maxDist + (cid:28)D we denote this result as av; otherwise,
we denote the result as rv (examples of av and rv are reported in
Figure 2). However, we are now looking for a normalized value.
∑
T
4.4.3 Combining Normalized Results
Now that we have the normalized version of both DTW-D and
DTW-S, we need to design the combination mechanism. First, we
observe that the result r of the normalized algorithms is no more
just binary (1, accept, or 0, reject). The mechanism to combine
the results is simple as just computing the sum of the normalized
results for each method, and compare it to a new threshold, ^(cid:28).
Let us ﬁrst consider the case of two methods, say Method A and
Method B, that use the normalized versions DTW-D and DTW-S.
Let us also denote their results are mA (for Method A) and mB
(for Method B). In the combined method, the user is accepted if
the following equation holds (where (cid:11) and (cid:12) are parameters of the
combination mechanism):
((cid:11)mA + (cid:12)mC ) ≥ ^(cid:28) ;
(9)
255
Parameters (cid:11) and (cid:12) are used to regulate the inﬂuence of the two
building block methods on the overall result. If Equation 9 does
not hold, the user is rejected.
More generally, combining all four methods, we propose a simi-
lar procedure, except that we compute the sum of all the four meth-
ods (mA, mB, mC and mD), and compare them again with the
threshold ^(cid:28). Finally, the user is accepted if the following equation
holds:
((cid:11)mA + (cid:12)mB + (cid:13)mC + (cid:14)mD) ≥ ^(cid:28) ;
(10)
where (cid:11), (cid:12), (cid:13), and (cid:14) are used to control the importance given to
each method. If Equation 10 does not hold, the user is rejected.
5. EVALUATION
To evaluate our proposal, we performed a wide range of exper-
iments. In particular, we investigated the performances of all the
presented basic methods (cfr. Section 4.2), and the possible com-
binations (cfr. Section 4.4 and Section 4.4). We wrote an Android
application, named FANTASY-app to get movement patterns, that
is the corresponding values over time of the accelerometer and ori-
entation sensors. We installed FANTASY-app on the Android Dev
Phone 1 [1], equipped with Android platform version 1.6. More in-
formation on our proposal, the FANTASY-app, and its source code
can be found on the project website [2]. We involved in our exper-
iments 10 test users (User 1, : : : , User 10), each of them providing
us with 50 movement patterns (for answering or placing a call). In
particular, we asked the users to answer the phone in the way we
depicted before, put the phone in front of them, press the “start”
button to imitate the call, then bring the phone to the ear. We did
not consider different ways of starting a call, like using hand-free
devices or using voice-recognition to ﬁnd a name in the contact list
and automatically initiate the call.
As for performance metrics, we used the ones commonly used
for evaluation of biometric authentication systems [8, 10, 9], that
are: the percentage of times the correct user is not granted access—
FAR (False Alarm Rate)—, and the percentage of times an impos-
tor is granted access—IPR (Impostor Pass Rate). For computing
FAR, for each user we trained the system with her ﬁrst T out of all
(50) patterns. Then, we gave as input to the authentication method
the remaining T − 50 patterns, hence considered test patterns. We
counted the percentage of times the system were not accepting this
patterns—hence not granting access to the correct user. Similarly,
we computed IPR by using the ﬁrst T patterns of User 1 as training
patterns, and the patterns of the the other users as test patterns.
Given the described setting, in the following we show and dis-
cuss the results of our experiments. In particular, Section 5.1 dis-
cusses the experimental results for the basic methods, Section 5.2
the ones for the boolean combinations, while Section 5.3 present
the ones for the combinations considering the normalized version
of both DTW-D and DTW-S algorithms. When combining the ba-
sic methods, we considered, for each of them, the choice of param-
eters T and (cid:28) as summarized in Table 3.
5.1 The basic methods
In this section we show the results obtained for the four basic
methods: DTW-D-Sa, DTW-S-Sa, DTW-D-So, and DTW-S-So.
For each of this methods, we varied the number of training patterns,
T , from 2 to 20, and we tested 10 different values for the threshold
((cid:28)). In particular, since the two considered algorithm DTW-D and
DTW-S work in different ways, we also considered for the two of
them different set of threshold values. That is, we considered the
following values for the threshold (cid:28)D: 0, 1000, 3000, 5000, 7500,
256
10000, 12500, 15000, 17500, and 20000. Similarly, for (cid:28)S (thresh-
old of DTW-S), we considered the following values: 7%, 8%, 9%,
10%, 11%, 12%, 13%, 14%, 15%, and 16%. We run experiments
with all the combination of these parameters and for each combi-
nation, we computed FAR and IPR.
Figures 4 and 5 show how the variation of T and (cid:28)D inﬂuences
FAR and IPR, in the DTW-D-So method. Figure 4 reports the re-
sults for different values of (cid:28)D, when varying T on the x-axis. In
particular, Figure 4(a) shows (on y-axis) the corresponding FAR,
and Figure 4(b) the corresponding IPR. Similarly, Figure 5 gives a
different view on the same data. It reports the results for the vari-
ation of (cid:28)S (on the x-axis) for different values of T . In particular,
Figure 5(a) shows the FAR, while Figure 5(b) shows the IPR.
(a) FAR
(b) IPR
Figure 4: DTW-D-So, Varying T .
We observe from Figure 4 that an increase in the number of train-
ing patterns decreases the FAR by 30% (from 45%, for T = 0, to
15% for T = 20), and increases the number of IPR by only 10%
(from 0%, for T = 0, to less then 10% for T = 20). Also, we
observe that the results for the several considered (cid:28)S are close to
each other. Hence, within the considered range, the variation of
the threshold does not signiﬁcantly inﬂuence the results. This ob-
servation can also be drawn from the other view we have on the
same data (Figure 5)—the curves for different threshold values are
almost parallel to the x-axis.
Due to space limitation, we do not report here the same detailed
results for the other methods: DTW-D-Sa, DTW-S-Sa, and DTW-
 0 10 20 30 40 50 2 4 6 8 10 12 14 16 18 20Rate(%)T010003000500075001000012500150001750020000 0 1 2 3 4 5 6 7 2 4 6 8 10 12 14 16 18 20Rate(%)T010003000500075001000012500150001750020000(a) FAR
Figure 6: Selection of basic methods with best performances.
Method
DTW-D-Sa
DTW-S-Sa
DTW-D-So
DTW-S-So
(cid:28)
0
58
0
14
T
6
20
20
20
IPR
13.1111
12.8888
4.4444
32.0000
FAR
23.6666
20.6666
9.3333
19.6666
Table 3: Parameters for methods comparison.
nition are similar to the ones of our system. However, while being
transparent, walking pattern recognition takes a long time before
the system can detect that the person using the phone is not the cor-
rect one. Keystroke dynamic, while obtaining an EER close to zero
when performed on computers, it gave for mobile devices an EER