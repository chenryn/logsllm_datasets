




  

  
	
	




	

	




























	
	







  

  
	
	




	

	




























	
	







  

  
	
	




	

	





(b)
(c) 
(d)
Fig. 9. Throughput scalability measured for a small topology (# switches = 10, #hosts = 100).
C. Impact of Topology on The Control Plane Capacity
In this test, shown in Figure 11, we emulate a larger
topology with 30 switches and 300 hosts and we measure the
performance of ONOS when serving requests from 1,000 to
7,000 requests/s. Results show a dramatic loss of performance
(compared to 10 switches topology used in Figures 9.(a)-(d).
With larger topology, scaling out SDN control plane by adding
more controller instances does not provide the expected bene-
Ô¨Åts, and none of the performed analysis passed the acceptance
test (i.e., 99% of the requests executed 95% of the times).
During this set of experiments, the controller instances ex-
perienced high memory and CPU utilization which eventually
led to a crash of the instances. Through the data collected
by SCP-CLUB, we identiÔ¨Åed that the increase in the number
of switches and of the hosts beyond a threshold reduces the
overall throughput because: i) the overhead caused by the I/O
handling of the connections towards the SDN switches through
the SBI increases, and ii) contention on the task queue and
other shared resources increases inside the ONOS core. The
biggest limitation identiÔ¨Åed by the SCP-CLUB analysis is that
the larger number of switches and hosts increase the internal
overhead of ONOS intent non-linearly. The compilation of
a batch of intents takes a longer time to complete over a
larger topology. Being a single-threaded operation, it causes
a longer queue of intent requests to accumulate in the system
that eventually may lead one of the instances to instability (see
example in Figure 8). In addition, larger topologies require
larger number of Ô¨Çows to install to provision an intent. Recall
that in ONOS Ô¨Çow rules and intent-related data are shared
with eventual consistency across nodes. Whenever an intent is
compiled and the Ô¨Çow rules are created, Ô¨Çows are copied into
the distributed data store shared across the instances by the node
that compiled the intent. Eventually, each node synchronizes,
TABLE V
Improvement
# vCores
Scaling Point
Scaling Point
for Œ∑ ‚â• 0, 8
SCALING POINTS FOR THE IMPROVED VERSION OF ONOS.
Overhead
‚Üë 60%
‚Üë 36%
‚Üì 4%
‚Üì 60%
‚Üë 60%
‚Üë 50%
‚Üì 41%
‚Üì 98%
‚Üë 54%
‚Üë 47%
‚Üì 31%
‚Üì 36%
‚Üë 50%
‚Üë 38%
‚Üì 25%
‚Üì 27%
ONOS
Deploy Size
ONOS‚Äì1VM‚ÄìS
ONOS‚Äì1VM‚ÄìM
ONOS‚Äì1VM‚ÄìL
ONOS‚Äì1VM‚ÄìXL
ONOS‚Äì3VMs‚ÄìS
ONOS‚Äì3VMs‚ÄìM
ONOS‚Äì3VMs‚ÄìL
ONOS‚Äì3VMs‚ÄìXL
ONOS‚Äì5VMs‚ÄìS
ONOS‚Äì5VMs‚ÄìM
ONOS‚Äì5VMs‚ÄìL
ONOS‚Äì5VMs‚ÄìXL
ONOS‚Äì7VMs‚ÄìS
ONOS‚Äì7VMs‚ÄìM
ONOS‚Äì7VMs‚ÄìL
ONOS‚Äì7VMs‚ÄìXL
160
800
2,500
4,800
220
600
2,600
4,000
300
800
4,000
4,800
400
1,400
5,000
5,600
80
200
312.5
300
36.7
50
108.3
83.3
30
40
100
60
28.6
50
89.3
50
(a)  

	
/
]
s
q
e
r
K
[
t
u
p
h
g
u
o
r
h
T
/
]
s
q
e
r
K
[
t
u
p
h
g
u
o
r
h
T
7
6
5
4
3
2
1
0
7
6
5
4
3
2
1
0

VM

ExtraLarge

Large
Medium

Small
  
0
1

VM

ExtraLarge
Large

Medium

Small
  
0
1
3
2
Input Request Rate [Kreq/s]
4
5
(a)
	
	
3
2
Input Request Rate [Kreq/s]
4
5
(c) 
/
]
s
q
e
r
K
[
t
u
p
h
g
u
o
r
h
T
/
]
s
q
e
r
K
[
t
u
p
h
g
u
o
r
h
T
7
6
5
4
3
2
1
0
7
6
5
4
3
2
1
0

VM

ExtraLarge

Large
Medium

Small
  
0
1

VM

ExtraLarge
Large

Medium

Small
  
0
1
6
7
6
7
	
	
3
2
Input Request Rate [Kreq/s]
5
4
(b)
	
	
3
2
Input Request Rate [Kreq/s]
5
4
(d)
6
7
6
7
Fig. 10. Throughput of ONOS with the implemented asynchronous interface.
every intent, and to ii) free the I/O thread, which can accept
new incoming requests.
Figure 10 shows the throughput analysis repeated after the
changes in the NBI of ONOS. Scaling points and overhead
Ô¨Ågures are shown in Table V. The overhead improvement
to the overhead in Table III. It
is computed with respect
is worth noticing that
the throughput of the LARGE and
EXTRA-LARGE deployments is substantially improved, as
compared with the original results in Figure 9. The use of an
asynchronous request protocol allowed to reduce the bottleneck
in the NBI and enabled a more efÔ¨Åcient use of the large
number of cores and large memory footprint of the LARGE and
EXTRA-LARGE VMs. Differently from the original version,
the modiÔ¨Åed NBI is able to serve the maximum request rate of
7,000 requests/s (5- and 7-nodes cluster with EXTRA-LARGE
deploys - Figure 6.(c) and (d)). In total, we measured an
improvement in the overhead from 4% (with respect to ONOS-
1-VM-XL in Table V) to 98% (for ONOS-3-VMs-XL).
Discussion. In the performed enhancement, SMALL and
MEDIUM deployments showed a decrease in the throughput
due to the additional memory footprint and CPU overhead
caused by the pool of threads. In order to overcome this
limitation, we implemented a simple REST controller module
in the NBI of ONOS that can switch between the synchronous
and asynchronous approach dynamically, depending on the rate
of incoming requests and rate of failed intent installation. The
REST controller accepts switching thresholds externally, for
instance, from the results of the SCP-CLUB in-production tests.
651
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:48:08 UTC from IEEE Xplore.  Restrictions apply. 
























	







  

  