启用 SSL 时性能会下降，影响大小取决于 CPU 和 JVM 实现。参考 [Kafka
security
overview](http://kafka.apache.org/documentation#security_overview) 和
[KAFKA-2561](https://issues.apache.org/jira/browse/KAFKA-2561) 。
:::
**使用TLS**
请阅读 [Configuring Kafka Clients
SSL](http://kafka.apache.org/documentation#security_configclients)
中描述的步骤来了解用于微调的其他配置设置，例如下面的几个例子：启用安全策略、密码套件、启用协议、truststore或秘钥库类型。
服务端认证和数据加密的一个配置实例：
``` properties
a1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.sink1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.sinks.sink1.kafka.topic = mytopic
a1.sinks.sink1.kafka.producer.security.protocol = SSL
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.sinks.sink1.kafka.producer.ssl.truststore.location = /path/to/truststore.jks
a1.sinks.sink1.kafka.producer.ssl.truststore.password = 
```
如果配置了全局ssl，上面关于ssl的配置就可以省略了，想了解更多可以参考
[SSL/TLS 支持](#ssltls-支持) 。 注意，默认情况下
ssl.endpoint.identification.algorithm
这个参数没有被定义，因此不会执行主机名验证。如果要启用主机名验证，请加入以下配置：
``` properties
a1.sinks.sink1.kafka.producer.ssl.endpoint.identification.algorithm = HTTPS
```
开启后，客户端将根据以下两个字段之一验证服务器的完全限定域名（FQDN）：
1)  Common Name (CN) 
2)  Subject Alternative Name (SAN)
如果还需要客户端身份验证，则还应在 Flume
配置中添加以下内容，当然如果配置了全局ssl就不必另外配置了，想了解更多可以参考
[SSL/TLS 支持](#ssltls-支持) 。
每个Flume实例都必须拥有其客户证书，来被Kafka
实例单独或通过其签名链来信任。 常见示例是由 Kafka
信任的单个根CA签署每个客户端证书。
``` properties
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.sinks.sink1.kafka.producer.ssl.keystore.location = /path/to/client.keystore.jks
a1.sinks.sink1.kafka.producer.ssl.keystore.password = 
```
如果密钥库和密钥使用不同的密码保护，则 *ssl.key.password*
属性将为生产者密钥库提供所需的额外密码：
``` properties
a1.sinks.sink1.kafka.producer.ssl.key.password = 
```
**Kerberos安全配置：**
要将Kafka Sink 与使用 Kerberos 保护的Kafka群集一起使用，请为生产者设置上面提到的 *producer.security.protocol* 属性。 与 Kafka 实例一起使用的 Kerberos keytab 和主体在 JAAS 文件的"KafkaClient"部分中指定。
:   "客户端"部分描述了 Zookeeper 连接信息（如果需要）。 有关 JAAS
    文件内容的信息，请参阅 [Kafka
    doc](http://kafka.apache.org/documentation.html#security_sasl_clientconfig)。
    可以通过 flume-env.sh 中的 JAVA_OPTS 指定此 JAAS
    文件的位置以及系统范围的 kerberos 配置：
``` properties
JAVA_OPTS="$JAVA_OPTS -Djava.security.krb5.conf=/path/to/krb5.conf"
JAVA_OPTS="$JAVA_OPTS -Djava.security.auth.login.config=/path/to/flume_jaas.conf"
```
使用 SASL_PLAINTEXT 的示例安全配置：
``` properties
a1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.sink1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.sinks.sink1.kafka.topic = mytopic
a1.sinks.sink1.kafka.producer.security.protocol = SASL_PLAINTEXT
a1.sinks.sink1.kafka.producer.sasl.mechanism = GSSAPI
a1.sinks.sink1.kafka.producer.sasl.kerberos.service.name = kafka
```
使用 SASL_SSL 的安全配置范例：
``` properties
a1.sinks.sink1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.sink1.kafka.bootstrap.servers = kafka-1:9093,kafka-2:9093,kafka-3:9093
a1.sinks.sink1.kafka.topic = mytopic
a1.sinks.sink1.kafka.producer.security.protocol = SASL_SSL
a1.sinks.sink1.kafka.producer.sasl.mechanism = GSSAPI
a1.sinks.sink1.kafka.producer.sasl.kerberos.service.name = kafka
# 如果在全局配置了SSL下面两个参数可省略，但是如果想使用自己独立的truststore，就可以把这两个参数加上。
a1.sinks.sink1.kafka.producer.ssl.truststore.location = /path/to/truststore.jks
a1.sinks.sink1.kafka.producer.ssl.truststore.password = 
```
JAAS 文件配置示例。有关其内容的参考，请参阅Kafka文档 [SASL
configuration](http://kafka.apache.org/documentation#security_sasl_clientconfig)
中关于所需认证机制（GSSAPI/PLAIN）的客户端配置部分。 与 Kafka Source 和
Kafka Channel
不同，"Client"部分并不是必须的，除非其他组件需要它，否则不必要这样做。
另外，请确保 Flume 进程的操作系统用户对 JAAS 和 keytab 文件具有读权限。
``` javascript
KafkaClient {
  com.sun.security.auth.module.Krb5LoginModule required
  useKeyTab=true
  storeKey=true
  keyTab="/path/to/keytabs/flume.keytab"
  principal="flume/flumehost1.example.com@YOURKERBEROSREALM";
};
```
#### HTTP Sink
HTTP Sink 从 channel 中获取 Event，然后再向远程 HTTP 接口 POST
发送请求，Event 内容作为 POST 的正文发送。
错误处理取决于目标服务器返回的HTTP响应代码。 Sink的 *退避* 和 *就绪*
状态是可配置的，事务提交/回滚结果以及Event是否发送成功在内部指标计数器中也是可配置的。
状态代码不可读的服务器返回的任何格式错误的 HTTP 响应都将产生 *退避*
信号，并且不会从 channel 中消耗该Event。
必需的参数已用 **粗体** 标明。
  属性                      默认值       解释
  ------------------------- ------------ -----------------------------------------------------------------------------------------------------------------------------
  **channel**               \--          与 Sink 绑定的 channel
  **type**                  \--          组件类型，这个是： `http`.
  **endpoint**              \--          将要 POST 提交数据接口的绝对地址
  connectTimeout            5000         连接超时（毫秒）
  requestTimeout            5000         一次请求操作的最大超时时间（毫秒）
  contentTypeHeader         text/plain   HTTP请求的Content-Type请求头
  acceptHeader              text/plain   HTTP请求的Accept 请求头
  defaultBackoff            true         是否默认启用退避机制，如果配置的 *backoff.CODE* 没有匹配到某个 http 状态码，默认就会使用这个参数值来决定是否退避
  defaultRollback           true         是否默认启用回滚机制，如果配置的 *rollback.CODE* 没有匹配到某个 http 状态码，默认会使用这个参数值来决定是否回滚
  defaultIncrementMetrics   false        是否默认进行统计计数，如果配置的 *incrementMetrics.CODE* 没有匹配到某个 http 状态码，默认会使用这个参数值来决定是否参与计数
  backoff.CODE              \--          配置某个 http 状态码是否启用退避机制（支持200这种精确匹配和2XX一组状态码匹配模式）
  rollback.CODE             \--          配置某个 http 状态码是否启用回滚机制（支持200这种精确匹配和2XX一组状态码匹配模式）
  incrementMetrics.CODE     \--          配置某个 http 状态码是否参与计数（支持200这种精确匹配和2XX一组状态码匹配模式）
注意 backoff， rollback 和 incrementMetrics 的 code
配置通常都是用具体的HTTP状态码，如果2xx和200这两种配置同时存在，则200的状态码会被精确匹配，其余200\~299（除了200以外）之间的状态码会被2xx匹配。
::: hint
::: title
Hint
:::
Flume里面好多组件都有这个退避机制，其实就是下一级目标没有按照预期执行的时候，会执行一个延迟操作。比如向HTTP接口提交数据发生了错误触发了退避机制生效，系统等待30秒再执行后续的提交操作，
如果再次发生错误则等待的时间会翻倍，直到达到系统设置的最大等待上限。通常在重试成功后退避就会被重置，下次遇到错误重新开始计算等待的时间。
:::
任何空的或者为 null 的 Event 不会被提交到HTTP接口上。
配置范例：
``` properties
a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = http
a1.sinks.k1.channel = c1
a1.sinks.k1.endpoint = http://localhost:8080/someuri
a1.sinks.k1.connectTimeout = 2000
a1.sinks.k1.requestTimeout = 2000
a1.sinks.k1.acceptHeader = application/json
a1.sinks.k1.contentTypeHeader = application/json
a1.sinks.k1.defaultBackoff = true
a1.sinks.k1.defaultRollback = true
a1.sinks.k1.defaultIncrementMetrics = false
a1.sinks.k1.backoff.4XX = false
a1.sinks.k1.rollback.4XX = false
a1.sinks.k1.incrementMetrics.4XX = true
a1.sinks.k1.backoff.200 = false
a1.sinks.k1.rollback.200 = false
a1.sinks.k1.incrementMetrics.200 = true
```
#### Custom Sink
你可以自己写一个 Sink 接口的实现类。启动 Flume 时候必须把你自定义 Sink
所依赖的其他类配置进 classpath 内。custom source 在写配置文件的 type
时候填你的全限定类名。 必需的参数已用 **粗体** 标明。
  属性          默认值   解释
  ------------- -------- -------------------------------------------
  **channel**   \--      与 Sink 绑定的 channe
  **type**      \--      组件类型，这个填你自定义class的全限定类名
配置范例：
``` properties
a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = org.example.MySink
a1.sinks.k1.channel = c1
```
### Flume Channels
channel 是在 Agent 上暂存 Event 的缓冲池。
Event由source添加，由sink消费后删除。
#### Memory Channel
内存 channel 是把 Event 队列存储到内存上，队列的最大数量就是 *capacity*
的设定值。它非常适合对吞吐量有较高要求的场景，但也是有代价的，当发生故障的时候会丢失当时内存中的所有
Event。 必需的参数已用 **粗体** 标明。
  属性                                        默认值   解释
  ------------------------------------------- -------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  **type**                                    \--      组件类型，这个是： `memory`
  capacity                                    100      内存中存储 Event 的最大数
  transactionCapacity                         100      source 或者 sink 每个事务中存取 Event 的操作数量（不能比 *capacity* 大）
  keep-alive                                  3        添加或删除一个 Event 的超时时间（秒）
  byteCapacityBufferPercentage byteCapacity   20       指定 Event header 所占空间大小与 channel 中所有 Event 的总大小之间的百分比 Channel 中最大允许存储所有 Event 的总字节数（bytes）。默认情况下会使用JVM可用内存的80%作为最大可用内存（就是JVM启动参数里面配置的-Xmx的值）。 计算总字节时只计算 Event 的主体，这也是提供 *byteCapacityBufferPercentage* 配置参数的原因。注意，当你在一个 Agent 里面有多个内存 channel 的时候， 而且碰巧这些 channel 存储相同的物理 Event（例如：这些 channel 通过复制机制（ [复制选择器](#复制选择器) ）接收同一个 source 中的 Event）， 这时候这些 Event 占用的空间是累加的，并不会只计算一次。如果这个值设置为0（不限制），就会达到200G左右的内部硬件限制。
::: hint
::: title
Hint
:::
举2个例子来帮助理解最后两个参数吧：
两个例子都有共同的前提，假设JVM最大的可用内存是100M（或者说JVM启动时指定了-Xmx=100m）。
例子1： *byteCapacityBufferPercentage* 设置为20， *byteCapacity*
设置为52428800（就是50M），此时内存中所有 Event body
的总大小就被限制为50M \*（1-20%）=40M，内存channel可用内存是50M。
例子2： *byteCapacityBufferPercentage* 设置为10， *byteCapacity*
不设置，此时内存中所有 Event body 的总大小就被限制为100M \* 80%
\*（1-10%）=72M，内存channel可用内存是80M。
:::
配置范例：
``` properties
a1.channels = c1
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 10000
a1.channels.c1.byteCapacityBufferPercentage = 20
a1.channels.c1.byteCapacity = 800000
```
#### JDBC Channel
JDBC
Channel会通过一个数据库把Event持久化存储。目前只支持Derby。这是一个可靠的channel，非常适合那些注重可恢复性的流使用。
必需的参数已用 **粗体** 标明。
  属性                                            默认值                                 解释