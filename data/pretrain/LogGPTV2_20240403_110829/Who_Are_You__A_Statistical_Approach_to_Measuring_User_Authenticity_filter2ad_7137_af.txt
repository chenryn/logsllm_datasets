overview over current challenges for password-based authenti-
cation, and mention a machine-learning approach as the most
likely solution to the problems that user authentication faces to-
day. Potential privacy implications of reinforced authentication
have been also recently discussed in a position statement [9].
It is worth mentioning that, as advocated by the adversarial
machine learning ﬁeld, protection systems based on statistical
knowledge extracted from data are prone to be attacked by
skilled adversaries who can purposely modify data to mislead
the outcome of the automatic analysis [6], [4], [31], [3],
[12]. We have performed a preliminary investigation of the
vulnerabilities of our system against evasion attacks, in which
attackers aim to impersonate legitimate users during opera-
tion. Another interesting scenario may be that of poisoning
attacks [3], [48], [31], [7], [57], in which the attacker may
tamper with the training data to mislead learning; e.g., she may
try to increase the reputation of IPs from which she is going to
launch a future attack, by legitimately logging in several times
from them, to accounts that are not necessarily associated to
real users, but created on purpose. A crowdturﬁng campaign
may be also staged to this end [53].
Besides considering more challenging attack settings, we
may exploit some countermeasures proposed in the area of
adversarial machine learning to improve system security in
13
more practical cases. Most of the work in that area has
been devoted to countering attacks in a proactive manner,
by explicitly modeling the interactions between classiﬁcation
algorithms and attackers, or considering attacks as outlying
samples with respect to the expected, normal behavior [16],
[12], [29], [45], [48], [15], [31], [3]. While investigating these
countermeasures may be of interest for future work, it is well
known that, in practice, system security can also be signif-
icantly improved in a reactive manner, by timely detecting
novel attacks and retraining the system, and verifying the
consistency of classiﬁer decisions with the (labeled) training
data [5], [31].
VIII. CONCLUSIONS AND FUTURE WORK
In this work we have evaluated an approach to strength-
ening password-based authentication by classifying login at-
tempts into normal and suspicious activity based on parameters
available during login. This approach is particularly useful for
Internet-wide services with a large and diverse user base, as it
can be deployed without changing the user experience. Similar
schemes are in use by large websites, and our work is the
ﬁrst public analysis and benchmark of such approaches. We
make no claim that our system is more sophisticated or more
accurate than any given non-public scheme, and we welcome
contributions to the literature that offer contrasting approaches.
In Sects. II–VI we have described a statistical framework,
provided a systematic study of possible attackers, developed a
fully functional prototype implementation, and validated the
system on a sample of real-life login data from LinkedIn,
showing a recall of up to 89% for a false-positive rate of
10%, using the user’s IP history as well as the useragent-string
history.
Several directions seem promising for future work. The
classiﬁers we considere do not take into account temporal
correlation among login attempts. This may carry useful
information, as attacks are often launched in campaigns and
in a short time span. Hence, if a login attempt is marked as an
attack, then other login attempts that are close in time to this
particular one and have a substantial overlap of feature values
are likely to be account-takeover attempts as well.
Manually labeling account-takeover events is a time-
consuming task. Techniques like active learning can be used
to reduce this effort, by smartly choosing login events that
require manual labeling to maximally improve the classiﬁer.
For our prototype evaluation of the model, the feature
set computation is performed on historical data instead of in
real-time. By updating frequency features in real time, we
can potentially avoid cases which were wrongly marked as
account-takeover attempts due to lack of updated user login
history in our dataset.
ACKNOWLEDGMENTS
This work has been partly supported by the project “Ad-
vanced and secure sharing of multimedia data over social
networks in the future Internet” funded by the Regional
Administration of Sardinia, Italy (CUP F71J11000690002).
REFERENCES
[1] D. V. Bailey, M. D¨urmuth, and C. Paar, “Statistics on password re-
use and adaptive strength for ﬁnancial accounts,” in Security and
Cryptography for Networks, ser. Lecture Notes in Computer Science,
vol. 8642. Springer, 2014, pp. 218–235.
[2] M. Barreno, B. Nelson, A. Joseph, and J. Tygar, “The security of
machine learning,” Machine Learning, vol. 81, pp. 121–148, 2010.
[3] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar,
“Can machine learning be secure?” in Proc. ACM Symp. Information,
Computer and Comm. Sec., ser. ASIACCS ’06. New York, NY, USA:
ACM, 2006, pp. 16–25.
test
[4] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ˇSrndi´c, P. Laskov,
G. Giacinto, and F. Roli, “Evasion attacks against machine learning
time,” in European Conference on Machine Learning and
at
Principles and Practice of Knowledge Discovery in Databases (ECML
PKDD), Part III, ser. Lecture Notes in Computer Science, H. Blockeel,
K. Kersting, S. Nijssen, and F. ˇZelezn´y, Eds., vol. 8190.
Springer
Berlin Heidelberg, 2013, pp. 387–402.
[5] B. Biggio, G. Fumera, and F. Roli, “Pattern recognition systems under
attack: Design issues and research challenges,” Int’l J. Patt. Recogn.
Artif. Intell., vol. 28, no. 7, p. 1460002, 2014.
[6] ——, “Security evaluation of pattern classiﬁers under attack,” IEEE
Transactions on Knowledge and Data Engineering, vol. 26, no. 4, pp.
984–996, April 2014.
[7] B. Biggio, B. Nelson, and P. Laskov, “Poisoning attacks against support
vector machines,” in 29th Int’l Conf. on Machine Learning, J. Langford
and J. Pineau, Eds. Omnipress, 2012, pp. 1807–1814.
[9]
[8] M. Bishop and D. V. Klein, “Improving system security via proactive
password checking,” Computers & Security, vol. 14, no. 3, pp. 233–249,
1995.
J. Bonneau, E. Felten, P. Mittal, and A. Narayanan, “Privacy concerns
of implicit secondary factors for web authentication,” in WAY 2014:
Who are you?! Adventures in Authentication Workshop, July 2014.
J. Bonneau, C. Herley, P. C. van Oorschot, and F. Stajano, “The past,
present, and future of password-based authentication on the Web,”
Communications of the ACM, March 2015.
J. Bonneau and S. E. Schechter, “Towards reliable storage of 56-bit
secrets in human memory,” in Proc. 23rd USENIX Security Symposium,
2014, pp. 607–623.
[10]
[11]
[12] M. Br¨uckner, C. Kanzow, and T. Scheffer, “Static prediction games
for adversarial learning problems,” J. Mach. Learn. Res., vol. 13, pp.
2617–2654, September 2012.
[13] C. Castelluccia, M. D¨urmuth, and D. Perito, “Adaptive password-
strength meters from Markov models,” in Proc. Network and Distributed
System Security Symposium (NDSS). The Internet Society, 2012.
[14] S. F. Chen and J. Goodman, “An empirical study of smoothing tech-
niques for language modeling,” Computer Speech & Language, vol. 13,
no. 4, pp. 359–393, 1999.
[15] G. F. Cretu, A. Stavrou, M. E. Locasto, S. J. Stolfo, and A. D.
Keromytis, “Casting out demons: Sanitizing training data for anomaly
sensors,” in IEEE Symposium on Security and Privacy. Los Alamitos,
CA, USA: IEEE Computer Society, 2008, pp. 81–95.
[16] N. Dalvi, P. Domingos, Mausam, S. Sanghai, and D. Verma, “Adver-
sarial classiﬁcation,” in Tenth ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining (KDD), Seattle, 2004, pp.
99–108.
[17] A. Das, J. Bonneau, M. Caesar, N. Borisov, and X. Wang, “The tangled
web of password reuse,” in Proc. Network and Distributed System
Security Symposium (NDSS), 2014.
[18] X. de Carnavalet and M. Mannan, “From very weak to very strong:
Analyzing password-strength meters,” in Proc. Network and Distributed
System Security Symposium (NDSS), 2014.
[19] A. De Luca, A. Hang, F. Brudy, C. Lindner, and H. Hussmann, “Touch
me once and I know it’s you!: Implicit authentication based on touch
screen patterns,” in Proc. SIGCHI Conference on Human Factors in
Computing Systems, ser. CHI ’12. ACM, 2012, pp. 987–996.
[20] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern Classiﬁcation. Wiley-
Interscience Publication, 2000.
14
[21] M. D¨urmuth, F. Angelstorf, C. Castelluccia, D. Perito, and A. Chaabane,
“Omen: Faster password guessing using an ordered markov enumera-
tor,” in Proc. International Symposium on Engineering Secure Software
and Systems (ESSoS), 2015, to appear.
[22] S. Egelman, A. Sotirakopoulos, I. Muslukhov, K. Beznosov, and C. Her-
ley, “Does my password go up to eleven?: The impact of password
meters on password selection,” in Proc. SIGCHI Conference on Human
Factors in Computing Systems, ser. CHI ’13. ACM, 2013, pp. 2379–
2388.
[23] EMC Corp., “RSA adaptive authentication,” http://www.emc.com/
collateral/data-sheet/11637-h9077-aaecom-ds.pdf.
[24] ——, “RSA risk-based authentication,” http://www.emc.com/collateral/
data-sheet/h11506-rsa-rba-ds.pdf.
[25] D. Florencio and C. Herley, “A large-scale study of web password
habits,” in WWW ’07: Proc. 16th International Conference on the World
Wide Web. ACM, 2007, pp. 657–666.
[26] ——, “Is everything we know about password stealing wrong?” Security
Privacy, IEEE, vol. 10, no. 6, pp. 63–69, Nov 2012.
[27] D. Florencio, C. Herley, and P. C. van Oorschot, “Password portfolios
and the ﬁnite-effort user: Sustainably managing large numbers of
accounts,” in Proc. 23rd USENIX Security Symposium, 2014, pp. 575–
590.
[28] R. S. Gaines, W. Lisowski, S. J. Press, and N. Shapiro, “Authentication
by keystroke timing: Some preliminary results,” DTIC Document, Tech.
Rep., 1980.
[29] A. Globerson and S. T. Roweis, “Nightmare at test time: robust learning
by feature deletion,” in Proc. 23rd International Conference on Machine
Learning, W. W. Cohen and A. Moore, Eds., vol. 148. ACM, 2006,
pp. 353–360.
“Google authenticator,” Online at https://code.google.com/p/google-
authenticator/.
[30]
[31] L. Huang, A. D. Joseph, B. Nelson, B. Rubinstein, and J. D. Tygar,
“Adversarial machine learning,” in 4th ACM Workshop on Artiﬁcial
Intelligence and Security (AISec 2011), Chicago, IL, USA, 2011, pp.
43–57.
[32] M. Karnan, M. Akila, and N. Krishnaraj, “Biometric personal authen-
tication using keystroke dynamics: A review,” Applied Soft Computing,
vol. 11, no. 2, pp. 1565–1573, 2011.
[33] S. Komanduri, R. Shay, L. F. Cranor, C. Herley, and S. E. Schechter,
“Telepathwords: Preventing weak passwords by reading users’ minds,”
in Proc. 23rd USENIX Security Symposium, 2014, pp. 591–606.
[34] S. Z. Li and A. Jain, Eds., Handbook of Face Recognition, 2nd ed.
Springer, 2011.
[35] Z. Li, W. He, D. Akhawe, and D. Song, “The emperor’s new password
manager: Security analysis of web-based password managers,” in Proc.
23rd USENIX Security Symposium, 2014, pp. 465–479.
[36] D. Lowd and C. Meek, “Adversarial learning,” in Proc. 11th ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining (KDD). Chicago, IL, USA: ACM Press, 2005, pp. 641–647.
J. Ma, W. Yang, M. Luo, and N. Li, “A study of probabilistic password
models,” in Proc. IEEE Symposium on Security and Privacy.
IEEE,
2014, pp. 689–704.
[37]
[44] A. Narayanan and V. Shmatikov, “Fast dictionary attacks on passwords
using time-space tradeoff,” in Proc. 12th ACM conference on Computer
and communications security. New York, NY, USA: ACM, 2005, pp.
364–372.
[45] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P. Rubinstein,
U. Saini, C. Sutton, J. D. Tygar, and K. Xia, “Exploiting machine
learning to subvert your spam ﬁlter,” in LEET’08: Proc. 1st Usenix
Workshop on Large-Scale Exploits and Emergent Threats. Berkeley,
CA, USA: USENIX Association, 2008, pp. 1–9.
[46] C. Palow, “After watching this talk, you’ll never look at passwords the
same again,” Presentation at the Hacker News Meetup, London. Record-
ing available online http://vimeo.com/80460475, November 2013.
[47] R Core Team, R: A Language and Environment
for Statistical
Computing, R Foundation for Statistical Computing, Vienna, Austria,
2014. [Online]. Available: http://www.R-project.org/
[48] B. I. Rubinstein, B. Nelson, L. Huang, A. D. Joseph, S.-h. Lau, S. Rao,
N. Taft, and J. D. Tygar, “Antidote: understanding and defending against
poisoning of anomaly detectors,” in Proc. 9th ACM SIGCOMM Internet
Measurement Conference, ser. IMC ’09. New York, NY, USA: ACM,
2009, pp. 1–14.
[49] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz, “A Bayesian
approach to ﬁltering junk e-mail,” AAAI Technical Report WS-98-05,
Madison, Wisconsin, 1998.
[50] S. Schechter, C. Herley, and M. Mitzenmacher, “Popularity is every-
thing: a new approach to protecting passwords from statistical-guessing
attacks,” in Proc. 5th USENIX Conference on Hot Topics in Security.
USENIX Association, 2010, pp. 1–8.
[51] Solar Designer, “John the Ripper,” Online at www.openwall.com/john.
[52]
J. Steube, “OclHashcat performance comparison,” Online at http://
hashcat.net/oclhashcat/.
[53] G. Wang, T. Wang, H. Zheng, and B. Y. Zhao, “Man vs. machine:
Practical adversarial detection of malicious crowdsourcing workers,” in
23rd USENIX Security Symposium (USENIX Security 14). San Diego,
CA: USENIX Association, 2014.
[54] WatchGuard Technologies, Inc., “Watchguard reputation authority,”
Available at http://www.borderware.com, February 2015.
[55] M. Weir, S. Aggarwal, B. de Medeiros, and B. Glodek, “Password
cracking using probabilistic context-free grammars,” in IEEE Sympo-
sium on Security and Privacy.
IEEE Computer Society, 2009, pp.
391–405.
[56] T. Wu, “A real-world analysis of kerberos password security,” in Proc.
Network and Distributed System Security Symposium (NDSS), 1999.
[57] H. Xiao, B. Biggio, G. Brown, G. Fumera, C. Eckert, and F. Roli,
“Is feature selection secure against training data poisoning?” in JMLR
W&CP - Proc. 32nd Int’l Conf. Mach. Learning (ICML), F. Bach and
D. Blei, Eds., vol. 37, 2015, pp. 1689–1698.
[38] E. Maler, A. Cser, S. Balaouras,
J. McKee”,
Forrester
Online
http://www.arrowecs.be/?event=tools.ehgetﬁle.FileHandler&ting&f
string=/FMS/19644.the forrester wave risk based authentication.pdf,
2012.
authentication,”
wave:
Risk-based
and
“The
at
[39] D. Maltoni, D. Maio, A. Jain, and S. Prabhakar, Handbook of Finger-
print Recognition, 2nd ed. Springer, 2009.
[40] S. Marechal, “Advances in password cracking,” Journal in Computer
Virology, vol. 4, no. 1, pp. 73–81, 2008.
[41] F. Monrose and A. D. Rubin, “Keystroke dynamics as a biometric for
authentication,” Future Generation computer systems, vol. 16, no. 4,
pp. 351–359, 2000.
[42] R. Morris and K. Thompson, “Password Security: A Case History,”
Commun. ACM, vol. 22, no. 11, pp. 594–597, Nov. 1979.
[43] K. Nandakumar, Y. Chen, S. C. Dass, and A. Jain, “Likelihood ratio-
based biometric score fusion,” IEEE Transactions on Pattern Analysis
and Machine Intelligence, vol. 30, pp. 342–347, February 2008.
15