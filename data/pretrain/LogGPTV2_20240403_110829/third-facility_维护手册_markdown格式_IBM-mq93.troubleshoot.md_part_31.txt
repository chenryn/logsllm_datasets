“Making initial checks on IBM i” on page 20
Before you start problem determination in detail on IBM i, consider whether there is an obvious cause of
the problem, or an area of investigation that is likely to give useful results. This approach to diagnosis can
often save a lot of work by highlighting a simple error, or by narrowing down the range of possibilities.
Related reference
Messages and reason codes
Application balancing troubleshooting
Use this section to help you troubleshoot problems with application balancing
Applications not balancing correctly
Many symptoms relating to application balancing can be diagnosed using the DISPLAY APSTATUS
command in various ways.
DIS APSTATUS(X) TYPE(APPL)
196 Troubleshooting and Support for IBM MQ
Symptom
The expected application is not listed.
Solution
• Verify the APPLTAG field is set correctly, either in code, or when the application is started.
• Investigate other listed applications in DIS APSTATUS(*) output to see if any are unexpected due to the
name being formed incorrectly, or defaulting.
• Try running the command DIS APSTATUS(X) TYPE(LOCAL) where(MOVABLE eq NO) on each
queue manager in the uniform cluster, to look for application instances which can not be distributed
around the uniform cluster.
Symptom
The expected total number of applications are not listed.
Solution
• Verify you are actually launching the expected number of instances to connect to the uniform cluster
• Verify that the uniform cluster is communicating correctly and all queue managers are reporting
application counts in DIS APSTATUS(X) TYPE(QMGR).
Symptom
The expected total number of applications are listed but some applications are flagged as not movable.
Solution
On each queue manager in the uniform cluster, use DIS APSTATUS(X) TYPE(LOCAL) where (MOVABLE
equals NO) and investigate the IMMREASN field.
Symptom
The balanced state is UNKNOWN
Solution
This is a temporary state, and will resolve itself shortly. Retry the command in a while.
Symptom
The balanced state is NOTAPPLIC.
Solution
• If this queue manager is not in a uniform cluster, the balance state is always NOTAPPLIC as nothing can
be rebalanced.
• In a uniform cluster, this means there has never been an application with this name connecting as
movable. Information on this application is not distributed around the cluster.
Use DIS APSTATUS(X) TYPE(LOCAL) where(MOVABLE eq NO) and investigate the IMMREASN field.
Symptom
The balanced state is NO
Solution
• Monitor this output across a period of time. If applications constantly connect and disconnect this might
be the appropriate answer as the instances are not given chance to rebalance.
IBM MQ troubleshooting and support 197
• Use DIS APSTATUS(X) TYPE(QMGR) to investigate the numbers on each queue manager, which indicates
queue managers with a surplus, or deficit, number of instances and continue the investigation on those
queue managers.
DIS APSTATUS(X) TYPE(QMGR)
Symptom
Not all queue managers in the uniform cluster are listed.
Solution
• Verify the BALSTATE is not NOTAPPLIC as that prevents information being flown around the uniform
cluster.
Use DIS APSTATUS(X) TYPE(LOCAL) to look at the IMMREASN field.
• Verify any missing queue managers are running.
• Verify the state of clustering, and that channels are running between this queue manager and the
missing queue manager.
Symptom
A queue manager is listed as ACTIVE(NO)
Solution
• Verify any missing queue managers are running
• Verify the state of clustering and that channels are running between this queue manager and the
inactive queue manager
Symptom
A queue manager has some immovable instances of an application.
Solution
On that queue manager in the uniform cluster, Use DIS APSTATUS(X) TYPE(LOCAL) where(MOVABLE eq
NO) and investigate the IMMREASN field.
Symptom
The BALSTATE is unexpected.
Solution
• Monitor this over time, as the BALSTATE is the state when the queue manager last attempted to
rebalance applications, which only happens periodically
• Are applications continually connecting and disconnecting? If so, this might prevent the application ever
being rebalanced into a stable state.
• If BALSTATE stays unbalanced, look at the error logs on the queue managers that are BALSTATE(HIGH)
and BALSTATE(LOW), which should indicate whether they are requesting application instances, and how
many were permitted to be moved.
• Verify DIS APSTATUS(X) TYPE(LOCAL) where(IMMCOUNT gt 1) to see if there are instances which are
failing to move when requested.
198 Troubleshooting and Support for IBM MQ
DIS APSTATUS(X) TYPE(LOCAL)
This display command can be used to diagnose many issues which might cause an application not to
rebalance as expected. Firstly, check the IMMDATE and IMMTIME fields to see if the application is only
temporarily marked as immovable.
Other reasons for applications failing to rebalance are indicated by the IMMREASN. The following table
shows the various causes (IMMREASN) and actions needed. Note, that in most cases, these causes need
to be reviewed with the application developer or owner concerned
IMMREASN ACTION
NOTCLIENT The application is using server bindings and therefore cannot be moved to
another queue manager. In most cases applications can be modified to use
a client connection. This might require rebuilding the application however
depending on the language and library versions in use.
NOTRECONN The application connection is not marked as 'reconnectable'. This might be a
deliberate decision in the application code, because its design requires that
all messages flow to and from a single queue manager, or might indicate a
configuration error or oversight (for example very old client libraries do not
support reconnection).
Note that for application balancing to work RECONNECT_QMGR is not
sufficient, as this indicates reconnection is only permitted to the
'same' Queue Manager instance. To see the connection options in use
from an application instance you can issue DIS CONN(*) TYPE(CONN)
WHERE(CONNTAG eq 'xxx') CONNOPTS, where xxx is the CONNTAG from
the DIS APSTATUS output.
APPNAMECHG The application is making multiple connections on the same TCP connection,
but with differing application names. This means that application instances
cannot be reliably separated so rebalancing is prevented. If this issue occurs
the application code is probably explicitly overriding the application name in
the MQCONNX call.
MOVING This should be a temporary status only as it indicates that the application
instance has already been identified for rebalancing.
The application is currently in a transaction so rebalancing is avoiding
INTRANS
interruption (rollback). If the application developer or deployer is not
concerned about excessive rollbacks for this application, and would prefer
to prioritize maintaining a consistent balance of application connections, this
constraint can be ignored both in application code or configuration settings;
see BalanceOptions for more information.
Alternatively, how long the queue manager permits transactions to continue
before considering interruption anyway can be modified using the Timeout
field.
This application has been marked as type 'request reply' and is waiting for a
REPLY
response to a previously dispatched request message. If you do not want to
wait for responses, marking as type 'SIMPLE' prevents this wait.
Alternatively, you can configure the extent of the waiting period using either
the message expiry of the application request messages, or the Timeout.
Note that it is often best to configure both appropriately, so that Timeout
does not unexpectedly truncate wait times for responses.
Related reference
DISPLAYAPSTATUS
IBM MQ troubleshooting and support 199
Applications continually connect or disconnect
A symptom and solution associated with applications continually connecting or disconnecting, or fail to
reach the expected balance.
First, rule out common causes using the DIS APSTATUS command described in “Applications not
balancing correctly” on page 196
Symptom
All application instances appear movable, but instances are continually re-balancing and failing to reach
equilibrium, and/or some queue managers do not have any instances of the application.
A likely cause is an incorrectly configured client channel definition table (CCDT). Uniform clusters require
that clients connect using a CCDT which includes connection information for every individual queue
manager in the cluster. When an application instance is asked to reconnect to another queue manager
(to rebalance connections), the IBM MQ client code consults the CCDT to establish the route to the new
destination.
If some queue managers are not included in the CCDT, or there is an error in their configuration
information, when an application instance attempts to reconnect it fails part way through the move
(usually reconnecting back to its previous queue manager). At some later point, it will likely be asked to
attempt to reconnect again, with the same result. This results in connections frequently 'bouncing', and
the application as a whole never achieving an even spread across the uniform cluster.
Solution
Ensure that all members of a uniform cluster are always represented in the CCDT provided to client
applications. This should include temporarily inactive members as applications are not requested to
rebalance to queue managers that are not currently running. If you identify errors in the CCDT, after
making any corrections redeploy the file to all clients using your existing mechanism. There is no need to
restart client applications, which locate the modified entries the next time a reconnect is attempted.
If the CCDT entries appear correct, there might be a problem with the listener or SRVCONN channel
definition on some members of the cluster, which causes similar behavior for the same reasons.
Application issues seen when running REFRESH CLUSTER
Issuing REFRESH CLUSTER is disruptive to the cluster. It might make cluster objects invisible for a short
time until the REFRESH CLUSTER processing completes. This can affect running applications. These
notes describe some of the application issues you might see.
Reason codes that you might see from MQOPEN, MQPUT, or MQPUT1 calls
During REFRESH CLUSTER the following reason codes might be seen. The reason why each of these
codes appears is described in a later section of this topic.
• 2189 MQRC_CLUSTER_RESOLUTION_ERROR
• 2085 MQRC_UNKNOWN_OBJECT_NAME
• 2041 MQRC_OBJECT_CHANGED
• 2082 MQRC_UNKNOWN_ALIAS_BASE_Q
• 2270 MQRC_NO_DESTINATIONS_AVAILABLE
All these reason codes indicate name lookup failures at one level or another in the IBM MQ code, which is
to be expected if apps are running throughout the time of the REFRESH CLUSTER operation.
The REFRESH CLUSTER operation might be happening locally, or remotely, or both, to cause these
outcomes. The likelihood of them appearing is especially high if full repositories are very busy. This
happens if REFRESH CLUSTER activities are running locally on the full repository, or remotely on other
queue managers in the cluster or clusters that the full repository is responsible for.
200 Troubleshooting and Support for IBM MQ
In respect of cluster queues that are absent temporarily, and will shortly be reinstated, then all of these
reason codes are temporary retry-able conditions (although for 2041 MQRC_OBJECT_CHANGED it can
be a little complicated to decide whether the condition is retry-able). If consistent with application rules
(for example maximum service times) you should probably retry for about a minute, to give time for the
REFRESH CLUSTER activities to complete. For a modest sized cluster, completion is likely to be much
quicker than that.
If any of these reason codes is returned from MQOPEN, then no object handle is created, but a later retry
should be successful in creating one.
If any of these reason codes is returned from MQPUT, then the object handle is not automatically closed,
and retrying should eventually succeed without a need first to close the object handle. However, if the
application opened the handle using bind-on-open options, and so requires all messages to go to the
same channel, then (contrary to the application's expectations) it is not guaranteed that the retried put
would go to the same channel or queue manager as before. It is therefore wise to close the object handle
and open a new one, in that case, to regain the bind-on-open semantics.
If any of these reason codes is returned from MQPUT1, then it is unknown whether the problem happened
during the open or the put part of the operation. Whichever it is, the operation can be retried. There are no
bind-on-open semantics to worry about in this case, because the MQPUT1 operation is an open-put-close
sequence that is performed in one continuous action.
Multi-hop scenarios
If the message flow incorporates a multi-hop, such as that shown in the following example, then a name
lookup failure caused by REFRESH CLUSTER can occur on a queue manager that is remote from the
application. In that case, the application receives a success (zero) return code, but the name lookup
failure, if it occurs, prevents a CLUSRCVR channel program from routing the message to any proper
destination queue. Instead, the CLUSRCVR channel program follows normal rules to write the message
to a dead letter queue, based on the persistence of the message. The reason code associated with that
operation is this:
• 2001 MQRC_ALIAS_BASE_Q_TYPE_ERROR
If there are persistent messages, and no dead letter queues have been defined to receive them, you will
see channels ending.
Here is an example multi-hop scenario:
• MQOPEN on queue manager QM1 specifies Q2.
• Q2 is defined in the cluster on a remote queue manager QM2, as an alias.
• A message reaches QM2, and finds that Q2 is an alias for Q3.
• Q3 is defined in the cluster on a remote queue manager QM3, as a qlocal.
• The message reaches QM3, and is put to Q3.
When you test the multi-hop, you might see the following queue manager error log entries:
• On the sending and receiving sides, when dead letter queues are in place, and there are persistent
messages:
AMQ9544: Messages not put to destination queue
During the processing of channel 'CHLNAME' one or more messages could not be put to the
destination queue and attempts were made to put them to a dead letter queue. The location of
the queue is $, where 1 is the local dead letter queue and 2 is the remote dead letter queue.
• On the receiving side, when a dead letter queue is not in place, and there are persistent messages:
AMQ9565: No dead letter queue defined
AMQ9599: Program could not open a queue manager object
AMQ9999: Channel program ended abnormally
• On the sending side, when a dead letter queue is not in place, and there are persistent messages:
IBM MQ troubleshooting and support 201
AMQ9506: Message receipt confirmation failed
AMQ9780: Channel to remote machine 'a.b.c.d(1415)' is ending because of an error
AMQ9999: Channel program ended abnormally
More details about why each of these reason codes might be displayed when
running REFRESH CLUSTER
2189 (088D) (RC2189): MQRC_CLUSTER_RESOLUTION_ERROR
The local queue manager asked its full repositories about the existence of a queue name. There was
no response from the full repositories within a hard-coded timeout of 10 seconds. This is because the
request message or the response message is on a queue for processing, and this condition will be
cleared in due course. At the app, the condition is retry-able, and will succeed when those internal
mechanisms have completed.
2085 (0825) (RC2085): MQRC_UNKNOWN_OBJECT_NAME
The local queue manager asked (or has previously asked) its full repositories about the existence of
a queue name. The full repositories have responded, saying that they did not know about the queue
name. In the context of REFRESH CLUSTER taking place on full and partial repositories, the owner
of the queue might not yet have told the full repositories about the queue. Or it might have done so,
but the internal messages carrying this information are on a queue for processing, in which case this
condition will be cleared in due course. At the app, the condition is retry-able, and will succeed when
those internal mechanisms have completed.
2041 (07F9) (RC2041): MQRC_OBJECT_CHANGED
Most likely to be seen from bind-on-open MQPUT. The local queue manager knows about the existence
of a queue name, and about the remote queue manager where it resides. In the context of REFRESH
CLUSTER taking place on full and partial repositories, the record of the queue manager has been
deleted and is in the process of being queried from the full repositories. At the app, it is a little
complicated to decide whether the condition is retry-able. In fact, if the MQPUT is retried, it will
succeed when those internal mechanisms have completed the job of learning about the remote queue
manager. However there is no guarantee that the same queue manager will be used. It is safer to
follow the approach usually recommended when MQRC_OBJECT_CHANGED is received, which is to
close the object handle and re-open a new one.
2082 (0822) (RC2082): MQRC_UNKNOWN_ALIAS_BASE_Q
Similar in origin to the 2085 MQRC_UNKNOWN_OBJECT_NAME condition, this reason code is seen
when a local alias is used, and its TARGET is a cluster queue that is inaccessible for the reasons
previously described for reason code 2085.
A2001 (07D1) (RC2001): MQRC_ALIAS_BASE_Q_TYPE_ERROR
This reason code is not usually seen at applications. It is only likely to be seen in the queue manager
error logs, in relation to attempts to send a message to a dead letter queue. A CLUSRCVR channel
program has received a message from its partner CLUSSDR and is deciding where to put it. This
scenario is just a variation of the same condition previously described for reason codes 2082 and
2085. In this case, the reason code is seen when an alias is being processed at a different point in the
MQ product, compared to where it is processed during an application MQPUT or MQOPEN.
2270 (08DE) (RC2270): MQRC_NO_DESTINATIONS_AVAILABLE
Seen when an application is using a queue that it opened with MQOO_BIND_NOT_FIXED, and
the destination objects are unavailable for a short time until the REFRESH CLUSTER processing
completes.
Further remarks
If there is any clustered publish/subscribe activity in this environment, then REFRESH CLUSTER can have
additional unwanted effects. For example temporarily losing subscriptions for subscribers, that then find
they missed a message. See REFRESH CLUSTER considerations for publish/subscribe clusters.
Related concepts
REFRESH CLUSTER considerations for publish/subscribe clusters
202 Troubleshooting and Support for IBM MQ
Clustering: Using REFRESH CLUSTER best practices
Related reference
MQSC Commands reference: REFRESH CLUSTER
A cluster-sender channel is continually trying to start
Check the queue manager and listener are running, and the cluster-sender and cluster-receiver channel
definitions are correct.
Symptom