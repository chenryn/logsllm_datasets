l
Mζ = Cγ/2ν (γη − τ γη − 1, ζ)
(7)
ν =10, γ =5, η =1000
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
10−15
80 82 84 86 88 90 92 94 96 98 100
ζ/(νη) (%)
Figure 7: False miss (value modiﬁcation) as function of ζ
ζ
i
M
s
s
m
e
s
a
F
l
100
10−5
10−10
10−15
1
ν =10, η =1000, ζ/(νη) =90%
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
2
3
4
5
γ
6
7
8
9
10
Figure 8: False miss (value modiﬁcation) as function of γ
ν =10, γ =5, ζ/(νη) =90%
ζ
i
M
s
s
m
e
s
a
F
l
100
10−5
10−10
10−15
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
2000
4000
6000
η
8000
10000
Figure 9: False miss (value modiﬁcation) as function of η
Figures 7, 8, and 9 show the false miss in the case of random
value modiﬁcation. The default parameters in these ﬁgures are
ζ/(γη) = 90% (i.e., 90% of the values are modiﬁed randomly),
ν = 10, γ = 5, and η = 1000. The general trend shown in these

Figure 5: False miss (tuple insertion) as function of γ
γ =5, ξ /η =90%
ξ
i
M
s
s
m
e
s
a
F
l
100
10−5
10−10
10−15
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
2000
4000
6000
η
8000
10000
Figure 6: False miss (tuple insertion) as function of η
90% of the new tuples are inserted into the data to replace the wa-
termarked tuples), γ = 5, and η = 1000. A general trend shown
in these ﬁgures is that the false miss is monotonic increasing with
watermark detection parameter τ . This trend is opposite to that of
the false hit, which is monotonic decreasing with τ as indicated in
Figures 2 and 3. Therefore, there is a tradeoff between false hit and
false miss with respect to τ .
Figure 4 shows that even if 80% of watermarked tuples are re-
placed with new tuples, the false miss is as low as 10−15 for all τ
values greater than or equal to 51%. The false miss is close to one
only if more than 90% of watermarked tuples are replaced in this
ﬁgure.
Figures 5 and 6 illustrate that the false miss is monotonic de-
creasing with γ and η, which is similar to the trend of false hit as
indicated in Figures 2 and 3. With reasonably large γ and/or η, the
false miss can be made extremely low.
For value modiﬁcation, we assume that the modiﬁed values are
randomly chosen. We leave the selective modiﬁcation targeted on
watermarked values to the next subsection. Recall that there are ν
attributes in the original data in which γ attributes are watermarked
for each tuple. When a random modiﬁcation happens, it has prob-
ability γ/ν that a watermarked value is chosen. When a water-
marked value is modiﬁed, its MSB has probability 1/2 to change
(i.e., the value is modiﬁed randomly). In watermark detection, a de-
tected MSB has probability γ/(2ν) not to match its counterpart in
the public watermark. The false miss Mζ for randomly modifying
ﬁgures for value modiﬁcation is similar to that shown in previous
Figures 4, 5, and 6 for tuple insertion. The difference in calculation
is due to the use of probability γ/2ν in Equation 7 instead of proba-
bility 1/2 in Equation 6. Figure 7 shows that even if 80% of values
are modiﬁed randomly, which would make the data less useful, the
false miss rate in detection is less than 10−10 in our computation.
4.3.2
Selective Value Modiﬁcation and Suppression
Since both the watermark key and the watermark are public in
our scheme, an attacker can pinpoint the MSBs of watermarked
values. A simple attack would be to ﬂip some of those MSBs so
that the watermark detection will detect no match. Assuming that ς
watermarked MSBs are ﬂipped in selective value modiﬁcation, the
false miss Mς can be written as
Mς = 1 if ς ≥ γη − τ γη
0 otherwise
(8)
If no less than γη −τ γη watermarked MSBs are ﬂipped, the wa-
termarked data will no longer be detected. The robustness of our
scheme can then be measured in terms of the error introduced by
this attack. The larger the error introduced for defeating the water-
mark detection (i.e., achieving Mς = 1), the better the robustness.
Recall that any change to an MSB would introduce intolerable
error to the related data value. To defeat the watermark detection,
no less than γη−τ γη MSBs have to be ﬂipped; this would intro-
duce intolerable errors to no less than γη − τ γη data values. We
thus measure the robustness in terms of failure error rate, which is
the least fraction F of total data values that need to be intolerably
modiﬁed for defeating the watermark detection. This failure error
rate can be written as
F =
γη − τ γη
ην
≈ (1 − τ )
γ
ν
(9)
A larger failure error rate (or better robustness) can be achieved
by increasing γ (watermark generation parameter) or decreasing
τ (watermark detection parameter). There is a tradeoff between
the robustness of our scheme and the size of the public watermark
(which has γ binary attributes). To achieve the best robustness
in terms of thwarting the selective modiﬁcation attacks, one may
choose γ = ν and τ ≈ 0.5. (However, this would increase the
false hit as indicated in Section 4.2.) In this extreme case, approxi-
mately 50% of data values have to be intolerably modiﬁed so as to
defeat the watermark detection.
To avoid the intolerable error, an attacker may choose to suppress
some watermarked values rather than ﬂipping their MSBs. Since
this attack causes no mismatch in watermark detection, the false
miss is zero. However, it will increase the false hit because those
MSBs will be missed in watermark detection. It is easy to know that
the effect of suppressing ς MSBs to the false hit is the equivalent
of decreasing the total number of MSBs by ς in the computation
of false hit. Thus, the false hit formula (see section 4.2) changes
from C1/2(τ γη, γη) to C1/2(τ (γη − ς), γη − ς) for selective
suppression of ς watermarked values.
Figure 10 shows the inﬂuence of selective value suppression to
the false hit for ﬁxed γ = 5, η = 1000, and various τ from 0.51 to
0.55. In the ﬁgure, we change the rate ς/(γη) (the percentage of
watermarked bits are suppressed) from 0% to 99%. Even if the rate
ς/(γη) increases up to 50%, the false hit is still below 15.4% for
τ = 0.51, below 2.2% for τ = 0.52, below 0.13% for τ = 0.53,
below 3 ∗ 10−5 for τ = 0.54, and below 2.6 ∗ 10−7 for τ = 0.55.
4.4 Overhead
We now analyze the time and space overhead for both watermark
γ =5, η =1000
100
10−5
H
t
i
h
e
s
a
F
l
10−10
10−15
0
τ =0.51
τ =0.52
τ =0.53
τ =0.54
τ =0.55
10 20 30 40 50 60 70 80 90 100
ς/(γη) (%)
Figure 10: False hit (value suppression) as function
of ς
generation and watermark detection. Throughout the analysis, we
ignore the IO cost (i.e., reading and writing tuples). Table 2 de-
scribes the symbols that will be used in this section.
Consider watermark generation. For each of η tuples to be pro-
cessed, a random sequence generator G is ﬁrst seeded, then γ MSBs
are determined based on γ random numbers generated by G. The
MSBs are assigned to the corresponding attributes in the public
watermark. For each MSB to be determined, one mod operation is
involved and one attribute is deleted from the copy of related tuple.
The memory requirement for the process of a tuple is to keep the
copy of the tuple, γ MSBs, and the watermark key in concatenation
with the tuple’s primary key. Therefore, the time overhead tgenW
and space overhead mgenW for watermark generation are
tgenW = ηtseed + ηγ(tgenS + tmod + tbit + tdelA)
= O(ηγ)
mgenW = mtuple + γ + mwkey = O(γ)
(10)
(11)
In watermark detection, the time and space overheads are the
same as in watermark generation except for the cost of processing
the count information. Let tif denote the cost of the last operation
“if match count/total count > τ .” The time overhead tdetW
and space overhead mdetW for watermark detection can be written
as
tdetW = 2tcount + ηtseed + ηγ(tgenS + tmod + tbit +
tdelA + 2tcount) + tif = O(ηγ)
mdetW = 2mcount + mtuple + γ + mwkey = O(γ)
(12)
(13)
The generated watermark W will be stored on disk. The disk
storage requirement mdisk is thus
mdisk = |W| = ηmpkey + ηγ = O(ηγ)
4.5 Tradeoffs
(14)
In our watermark scheme, we have two parameters: watermark
generation parameter γ and watermark detection parameter τ . The
two parameters can be used to balance between the robustness and
the overhead of our scheme. Table 3 summarizes the tradeoffs that
can be made when choosing the two parameters.
The watermark generation parameter γ is used to balance be-
tween robustness and overhead. The larger the γ, the better the
robustness of our scheme and the worse the time and space over-
head. While the watermark detection parameter τ has no effect on

Table 2: Symbols used in the analysis of overhead
tseed
tgenS
tmod
tdelA
tbit
tcount
mcount
mtuple
mwkey
mpkey
cost of seeding random sequence generator S with public key and a tuple’s primary key
cost of generating a random number from S
cost of mod operation
cost of deleting an attribute from a copy of a tuple
cost of assigning/comparing a bit value to/with the public watermark
cost of assigning/updating a count in watermark detection
number of bits required to store a count in watermark detection
number of bits required to store a copy of a tuple
number of bits to store a watermark key
number of bits to store a primary key value
Table 3: Tradeoffs
para-
meter
γ ↑
τ ↑
false
false
hit
miss
H ↓ M ↓
H ↓ M ↑
failure
error rate
F ↑
F ↓
robustness
(summary)
↑
↑ in terms of H
↓ in terms of M, F
overhead