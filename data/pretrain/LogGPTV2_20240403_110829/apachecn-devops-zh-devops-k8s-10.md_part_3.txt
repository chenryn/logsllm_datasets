![](img/00144.jpeg)
# 节点池
启动 Kubernetes 集群时，可以使用`--num-nodes`选项指定节点数量。GKE 将 Kubernetes 节点作为节点池进行管理。这意味着您可以管理一个或多个连接到 Kubernetes 集群的节点池。
如果需要添加更多节点或者删除一些节点怎么办？GKE 提供了一个调整节点池大小的功能，方法是按照命令将 Kubernetes 节点从 3 更改为 5:
```
//run resize command to change number of nodes to 5
$ gcloud container clusters resize my-k8s-cluster --size 5 --zone asia-northeast1-a
//after a few minutes later, you may see additional nodes
$ kubectl get nodes
NAME                                            STATUS    AGE       VERSION
gke-my-k8s-cluster-default-pool-ae180f53-47h5   Ready     5m        v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-6prb   Ready     5m        v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-f8ps   Ready     30s       v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-qzxz   Ready     30s       v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-z6l1   Ready     5m        v1.6.7  
```
如果您需要横向扩展节点容量，增加节点数量会有所帮助。但是，在这个场景中，它仍然使用最小的实例类型(`f1-micro`，它只有 0.6 GB 的内存)。如果单个容器需要超过 0.6 GB 的内存，这可能没有帮助。在这种情况下，您需要扩大规模，这意味着您需要添加更大规模的虚拟机实例类型。
在这种情况下，您必须向集群中添加另一组节点池。因为在同一个节点池中，所有虚拟机实例都配置相同。因此，您不能在同一个节点池中更改实例类型。
因此，向集群添加一个新的节点池，该节点池具有两组新的`g1-small` (1.7 GB 内存)虚拟机实例类型。然后可以用不同的硬件配置扩展 Kubernetes 节点。
By default, there are some quotas that you can create a number limit of VM instances within one region (for example, up to eight cpu cores on `us-west1`). If you wish to increase this quota, you must change your account to be a paid account. Then request quota change to GCP. For more details, please read online documentation from [https://cloud.google.com/compute/quotas](https://cloud.google.com/compute/quotas) and [https://cloud.google.com/free/docs/frequently-asked-questions#how-to-upgrade](https://cloud.google.com/free/docs/frequently-asked-questions#how-to-upgrade).
运行以下命令，添加具有两个`g1-small`实例的附加节点池:
```
//create and add node pool which is named "large-mem-pool"
$ gcloud container node-pools create large-mem-pool --cluster my-k8s-cluster --machine-type g1-small --num-nodes 2 --tags private --zone asia-northeast1-a
//after a few minustes, large-mem-pool instances has been added
$ kubectl get nodes
NAME                                              STATUS    AGE       VERSION
gke-my-k8s-cluster-default-pool-ae180f53-47h5     Ready     13m       v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-6prb     Ready     13m       v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-f8ps     Ready     8m        v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-qzxz     Ready     8m        v1.6.7
gke-my-k8s-cluster-default-pool-ae180f53-z6l1     Ready     13m       v1.6.7
gke-my-k8s-cluster-large-mem-pool-f87dd00d-9v5t   Ready     5m        v1.6.7
gke-my-k8s-cluster-large-mem-pool-f87dd00d-fhpn   Ready     5m        v1.6.7  
```
现在，集群中总共有七个 CPU 内核和 6.4 GB 内存，容量更大。但是由于硬件类型较大，Kubernetes 调度器可能会先分配部署 pod 到`large-mem-pool`，因为它有足够的内存容量。
但是，您可能希望保留`large-mem-pool`节点，以防大应用需要大堆内存大小(例如，Java 应用)。因此，您可能需要区分`default-pool`和`large-mem-pool`。
在这种情况下，Kubernetes 标签`beta.kubernetes.io/instance-type`有助于区分节点的实例类型。因此，使用`nodeSelector`为 pod 指定所需的节点。例如，以下`nodeSelector`参数将强制使用`f1-micro`节点进行 nginx 应用:
```
//nodeSelector specifies f1-micro
$ cat nginx-pod-selector.yml 
apiVersion: v1
kind: Pod
metadata:
 name: nginx
spec:
 containers:
 - name: nginx
 image: nginx
 nodeSelector:
 beta.kubernetes.io/instance-type: f1-micro
//deploy pod
$ kubectl create -f nginx-pod-selector.yml 
pod "nginx" created
//it uses default pool
$ kubectl get pods nginx -o wide
NAME      READY     STATUS    RESTARTS   AGE       IP           NODE
nginx     1/1       Running   0          7s        10.56.1.13   gke-my-k8s-cluster-default-pool-ae180f53-6prb
```
If you want to specify a particular label instead of `beta.kubernetes.io/instance-type`, use `--node-labels` option to create a node pool. That assigns your desired label for the node pool.
For more details, please read the following online document:
[https://cloud.google.com/sdk/gcloud/reference/container/node-pools/create](https://cloud.google.com/sdk/gcloud/reference/container/node-pools/create).
当然，如果不再需要，您可以随意删除节点池。为此，运行以下命令删除`default-pool` ( `f1-micro` x 5 个实例)。如果`default-pool`有一些 Pod 在运行，该操作将涉及 Pod 迁移(在`default-pool`上终止 Pod ，在`large-mem-pool`上重新启动)；
```
//list Node Pool
$ gcloud container node-pools list --cluster my-k8s-cluster --zone asia-northeast1-a
NAME            MACHINE_TYPE  DISK_SIZE_GB  NODE_VERSION
default-pool    f1-micro      100           1.6.7
large-mem-pool  g1-small      100           1.6.7
//delete default-pool
$ gcloud container node-pools delete default-pool --cluster my-k8s-cluster --zone asia-northeast1-a
//after a few minutes, default-pool nodes x 5 has been deleted
$ kubectl get nodes
NAME                                              STATUS    AGE       VERSION
gke-my-k8s-cluster-large-mem-pool-f87dd00d-9v5t   Ready     16m       v1.6.7
gke-my-k8s-cluster-large-mem-pool-f87dd00d-fhpn   Ready     16m       v1.6.7  
```
您可能已经注意到，前面的所有操作都发生在一个区域(`asia-northeast1-a`)中。因此，如果`asia-northeast1-a`区域中断，您的集群将会关闭。为了避免区域故障，您可以考虑设置一个多区域集群。
# 多区域集群
GKE 支持多区域集群，允许您在多个区域启动 Kubernetes 节点，但仅限于同一区域。在前面的示例中，它仅在`asia-northeast1-a`进行了资源调配，因此让我们重新调配一个总共有三个分区的`asia-northeast1-a`、`asia-northeast1-b`和`asia-northeast1-c`的集群。
很简单；创建新集群时，只需追加一个`--additional-zones`参数。
As of August, 2017, there is a beta feature that supports to update existing clusters from single zones to multi zones. Use a beta command as follows:
`$ gcloud beta container clusters update my-k8s-cluster --additional-zones=asia-northeast1-b,asia-northeast1-c`.
To change an existing cluster to multi zone, it may need an additional SDK tool installation, but out of SLA.
让我们删除之前的集群，并创建一个带有`--additional-zones`选项的新集群:
```
//delete cluster first
$ gcloud container clusters delete my-k8s-cluster --zone asia-northeast1-a
//create a new cluster with --additional-zones option but 2 nodes only
$ gcloud container clusters create my-k8s-cluster --cluster-version 1.6.7 --machine-type f1-micro --num-nodes 2 --network my-custom-network --subnetwork subnet-c --zone asia-northeast1-a --tags private --additional-zones asia-northeast1-b,asia-northeast1-c  
```
在本例中，它将为每个区域创建两个节点(`asia-northeast1-a`、`b`和`c`)；因此，总共将添加六个节点:
```
$ kubectl get nodes
NAME                                            STATUS    AGE       VERSION
gke-my-k8s-cluster-default-pool-0c4fcdf3-3n6d   Ready     44s       v1.6.7
gke-my-k8s-cluster-default-pool-0c4fcdf3-dtjj   Ready     48s       v1.6.7
gke-my-k8s-cluster-default-pool-2407af06-5d28   Ready     41s       v1.6.7
gke-my-k8s-cluster-default-pool-2407af06-tnpj   Ready     45s       v1.6.7
gke-my-k8s-cluster-default-pool-4c20ec6b-395h   Ready     49s       v1.6.7
gke-my-k8s-cluster-default-pool-4c20ec6b-rrvz   Ready     49s       v1.6.7  
```
You may also distinguish node zone by Kubernetes label `failure-domain.beta.kubernetes.io/zone` so that you can specify desired zones to deploy a pod.
# 集群升级
一旦开始管理 Kubernetes，在升级 Kubernetes 集群时可能会遇到一些困难。因为 Kubernetes 项目非常激进，大约每三个月就会有一个新的发布，比如 1 . 6 . 0(2017 年 3 月 28 日 th 发布)到 1 . 7 . 0(2017 年 6 月 29 日 th 发布)。
GKE 还不断及时增加新版本支持。它允许我们通过`gcloud`命令升级主机和节点。您可以运行以下命令来查看 GKE 支持哪个 Kubernetes 版本:
```
$ gcloud container get-server-config
Fetching server config for us-east4-b
defaultClusterVersion: 1.6.7
defaultImageType: COS
validImageTypes:
- CONTAINER_VM
- COS
- UBUNTU
validMasterVersions:
- 1.7.3
- 1.6.8
- 1.6.7
validNodeVersions:
- 1.7.3
- 1.7.2
- 1.7.1
- 1.6.8
- 1.6.7
- 1.6.6
- 1.6.4
- 1.5.7
- 1.4.9  
```
因此，您可能会看到目前在主节点和节点上都支持的最新版本是 1.7.3。由于前面安装的示例是版本 1.6.7，让我们更新到 1.7.3。首先，你需要先升级主控:
```
//upgrade master using --master option
$ gcloud container clusters upgrade my-k8s-cluster --zone asia-northeast1-a --cluster-version 1.7.3 --master
Master of cluster [my-k8s-cluster] will be upgraded from version 
[1.6.7] to version [1.7.3]. This operation is long-running and will 
block other operations on the cluster (including delete) until it has 
run to completion.
Do you want to continue (Y/n)?  y
Upgrading my-k8s-cluster...done. 
Updated [https://container.googleapis.com/v1/projects/devops-with-kubernetes/zones/asia-northeast1-a/clusters/my-k8s-cluster].  
```
根据环境，大约需要 10 分钟，之后您可以通过以下命令进行验证:
```
//master upgrade has been successfully to done
$ gcloud container clusters list --zone asia-northeast1-a
NAME            ZONE               MASTER_VERSION  MASTER_IP       MACHINE_TYPE  NODE_VERSION  NUM_NODES  STATUS
my-k8s-cluster  asia-northeast1-a  1.7.3           35.189.141.251  f1-micro      1.6.7 *       6          RUNNING  
```
现在，您可以将所有节点升级到版本 1.7.3。由于 GKE 尝试执行滚动升级，它将对每个节点逐一执行以下步骤:
1.  从集群中注销目标节点。
2.  删除旧的虚拟机实例。
3.  调配新的虚拟机实例。
4.  使用 1.7.3 版本设置节点。
5.  向主人登记。
因此，它需要比主升级长得多的时间:
```
//node upgrade (not specify --master)
$ gcloud container clusters upgrade my-k8s-cluster --zone asia-northeast1-a --cluster-version 1.7.3 
All nodes (6 nodes) of cluster [my-k8s-cluster] will be upgraded from 
version [1.6.7] to version [1.7.3]. This operation is long-running and will block other operations on the cluster (including delete) until it has run to completion.
Do you want to continue (Y/n)?  y  
```
在滚动升级过程中，您可以看到节点状态如下，它显示了滚动更新的中间过程(两个节点已升级到 1.7.3，一个节点正在升级，三个节点待定):
```
NAME                                            STATUS                        AGE       VERSION
gke-my-k8s-cluster-default-pool-0c4fcdf3-3n6d   Ready                         37m       v1.6.7
gke-my-k8s-cluster-default-pool-0c4fcdf3-dtjj   Ready                         37m       v1.6.7
gke-my-k8s-cluster-default-pool-2407af06-5d28   NotReady,SchedulingDisabled   37m       v1.6.7
gke-my-k8s-cluster-default-pool-2407af06-tnpj   Ready                         37m       v1.6.7
gke-my-k8s-cluster-default-pool-4c20ec6b-395h   Ready                         5m        v1.7.3