cases in a more focused way. Consider, for example, a sig-
nature that detects a certain attack by searching for a partic-
ular string in the URL ﬁeld of every HTTP request. All at-
tack instances that are different only in their HTTP header
values (but not in the URL) can be considered equivalent
for this test, as these differences do not inﬂuence the IDS
detection process. Unfortunately, without any knowledge
of the signature, the test generation process can only try
to blindly generate all the possible variations, leading to a
very large number of equivalent test cases. However, by
using the set of constraints extracted by our dynamic data
ﬂow analysis, it is possible to drive the test case genera-
tion process in order to generate only the “interesting” test
cases. In fact, the knowledge of how a signature is matched
allows the test case generator to focus only on those attack
variations that, while remaining inside the space of valid at-
tacks, lie outside the signature constraints of the IDS. The
result is a more focused approach that takes into account
the actual signature constraints that are relevant for detec-
tion.
We implemented this technique as an extension to
Sploit [29]. Sploit is a mutant exploit generation tool that
takes an attack template and a set of transformations as in-
put, and generates a set of different, semantically equiv-
alent versions of the attack. These variations, called mu-
tants, can then be executed against a target system in order
to test a NIDS’s ability to detect different variations of the
same attack. For this project, Sploit was modiﬁed to incor-
porate the constraint information generated by iTrace into
its mutant generation engine, as described in the following
sections.
4.1. Mapping Constraints to Exploit Fea-
tures
To be able to process the information provided by our
dynamic data ﬂow analysis of the execution of an attack,
Sploit must ﬁrst map the constraints generated by iTrace
into the corresponding features of the attack. All the dy-
namic information discussed in the previous sections is
based on the absolute positions (or labels) of bytes in the
5858
packets that comprise the attack stream. However, Sploit
does not reason in terms of bytes, but rather in terms of pro-
tocols, commands, and command ﬁelds. Thus, a mapping
between the two representations is needed. This mapping
leverages an execution table, which stores the associations
between the positions of the bytes in the network stream
and the object that was responsible for their generation.
In Sploit, whenever an exploit sends data using a cer-
tain protocol, the corresponding protocol manager (i.e., the
object in charge of managing the protocol communication
and the list of mutant operators working at that layer) adds
to the execution table a new row with the details of the data
that is added and its location in the network stream. As
a result, by knowing the location of a byte in the network
stream, Sploit can identify the appropriate set of mutant
operators that can operate on that byte.
Note that a given byte position can be associated with
more than one mutant operator. For example, consider the
case of an attack that injects shellcode inside one of the
header ﬁelds of an HTTP request. When the HTTP request
is sent, each byte of the shellcode will be associated with
both the ShellCode and the HTTPRequest sets of mu-
tant operators.
4.2. Focusing the Test Case Generation
During signature analysis, Sploit ﬁrst executes the base
exploit (i.e., the attack with no transformations applied),
and collects the constraints generated by iTrace. Then, it
relies on two subsequent reﬁnement phases in order to de-
termine which mutant operators should be applied to gen-
erate the relevant test cases.
The ﬁrst phase consists of taking into account only the
positions of the bytes that the IDS used to detect the at-
tack. As mentioned previously, based on the execution ta-
ble, Sploit maps each byte back to the corresponding por-
tion of the attack that was executed. Once all the byte po-
sitions identiﬁed as relevant for the detection process are
translated into commands and ﬁeld locations within the at-
tack, Sploit can use this information to reﬁne the mutant
generation process. In particular, Sploit disables every mu-
tant operator that does not affect any relevant part of the
attack. More general transformations that do not apply to
particular parts of the attack (e.g., IP fragmentation) are
temporarily deactivated as well, even though they can be
reconsidered again when the tool is not able to evade de-
tection using other techniques.
At the end of the ﬁrst phase, all transformations that can-
not affect the parts of the attack checked by the IDS have
been removed. Even though this can considerably improve
the relevance of the test cases that are generated, a better
result can be obtained analyzing the type of constraints ex-
tracted by iTrace. In order to take them into account, Sploit
implements a second reﬁnement phase, based on a local
simulation of the effects of each mutant operator.
In Sploit, a mutant operator can have a set of parameters
that describe in which way the transformation is applied to
the original exploit. For example, an operator that obfus-
cates the shellcode’s NOP sled can have a parameter that
contains the list of bytes that can be used to compose the
sled. This means that a single mutant operator can generate
multiple (but ﬁnite) different attack mutations. Consider
an example in which Sploit is able to pinpoint that the IDS
only checks the part of the network stream where the ex-
ploit shellcode is stored. By analyzing the dynamic con-
straints, Sploit can now incorporate information on the ex-
act checks that were performed by the IDS on the shellcode
section. For example, suppose that the IDS was searching
for a particular string, such as a sequence of 0x90 bytes,
which is often used as a NOP sled. Then, the simulation
routine cycles through the set of mutant operators selected
by the ﬁrst phase and uses each of them to mutate the shell-
code for every possible value of the operator parameters.
The result of each iteration is checked against the signa-
ture constraints (in this example, represented by the string
automaton that encodes a series of 0x90 bytes). If the con-
straint is not violated, Sploit removes the parameter value
from the list of possible alternatives. Furthermore, if all
possible parameters values have been eliminated for a mu-
tant operator, the operator itself is deactivate, because its
transformation cannot evade the detection process.
It is important to note that this simulation phase does not
require generating all the possible mutants locally. For ex-
ample, suppose that for a certain attack, ten mutant opera-
tors are available, each with ten possible parameter values.
Combining them, the total number of possible test cases
that can be generated is 1010. However, the number of in-
stances that must be locally simulated is only 100: one for
each parameter value of each operator.
By applying the previous reﬁning phases, Sploit can fo-
cus the test case generation process to produce only those
test cases that can evade at least one of the derived con-
straints. If the resulting test suite is empty, it might be the
case that some constraints could not be evaded by the avail-
able mutant operators, and more general mutation tech-
niques can be applied to try to evade the IDS.
5. Evaluation
To demonstrate the effectiveness of our technique, an
evaluation was conducted using prototype implementations
of Sploit and iTrace. In particular, we developed two dy-
namic analysis components: one for the extraction of basic
constraints and one for the extraction of string automata.
As we previously explained in Section 3.2, the string ex-
traction algorithm requires a trafﬁc generator that can be
controlled to inject different payloads. We implemented
two different modules to create both UDP packets and TCP
sessions. Finally, we extended the Sploit tool to process the
5959
constraints’ feedback and use them to focus the test case
generation.
A limit of the current implementation is that complex
signatures cannot be analyzed in a fully-automated fash-
ion. In fact, most IDS engines are optimized to check the
string constraints only after all the other simple constraints
contained in the signature have matched the trafﬁc. This
implies that the IDS string analysis routine is not invoked
when simpler constraints do not match. As a result, in order
to reverse-engineer a complex signature, the user must ﬁrst
set up iTrace to extract the basic constraints, then modify
the trafﬁc generator to match these constraints, and ﬁnally
run the string extraction tool. Once the constraints have
been retrieved, the mutant generation process is completely
automatic and does not require any human intervention.
We tested our technique against two intrusion detec-
tion systems: Snort and Symantec’s NIDS. The evaluation
testbed was composed of a RedHat Linux 9 system running
several vulnerable services, a RedHat Linux 9 machine run-
ning the Sploit prototype, a Gentoo Linux 2005.0 machine
running iTrace and Snort 2.4.3, and the Symantec Network
Security 7120 appliance (also running iTrace, and patched
to version 4.0.0.11).
5.1. Dynamic Analysis of Snort Signatures
One may naturally question the use of Snort in this eval-
uation, as its standard signatures set is freely available for
analysis. This would seem to negate the motivation be-
hind our approach, since it would be easier to manually
analyze the signatures rather than infer the signature con-
straints from the execution of the IDS. However, we felt it
necessary to demonstrate our technique against known sig-
natures, in effect establishing a “ground truth” with respect
to its effectiveness.
For the ﬁrst experiment, we tested the ability of our ap-
proach to generate and process basic constraints derived
from direct numeric comparisons observed by iTrace. The
signature we examined was the Snort signature for the
Samba trans2open buffer overﬂow [27], the relevant por-
tions of which are shown in Figure 2.
This signature contains four basic constraints, based
both on single bytes (speciﬁed through the content key-
word) and on a 16-bit short comparison (speciﬁed through
the byte test keyword). Our tool was able to extract
a set of constraints that correctly reﬂects all these checks.
When Sploit analyzed these constraints, it determined that
the tests for 0x00, 0xff and SMB2 were performed on
the SMB header of the packet; because Sploit possesses no
available mutant operators that operate on the SMB header,
the mutation engine could not violate these constraints. The
checks for 0x00 and 0x14, however, were performed on
a portion of the exploit that was equivalent to padding, and,
therefore, Sploit’s shellcode generator was able to gener-
ate a semantically-equivalent padding byte to replace the
0x00 byte. As a result, the attack based on this transforma-
tion was able to evade Snort, while successfully exploiting
the target application.
In order to test the ability of our approach to infer string-
In
matching automata, we run two sets of experiments.
the ﬁrst set, we run our component to analyze a simpli-
ﬁed version of the complete Snort’s FTP-based signature
set (with 76 signatures). Each rule was modiﬁed in order
to eliminate any constraint that would prevent the string
matching mechanism to be executed, by including only the
content rules that were used to deﬁne the strings. In this
case, our tool was able to correctly extract all the 76 corre-
sponding automata.
For the second set of experiments, we examined the sig-
nature shown in Figure 3, associated with a remote com-
mand execution vulnerability in the Avenger’s News Sys-
tem [25].
that requires that
The automaton extracted with our tool matched ex-
actly the string constraint speciﬁed by the signature (i.e.,
the constraint
the URI contains the
string “/ans.pl?p=../../”). The automaton was then
loaded in Sploit and used to verify if any of the applied mu-
tant operators would affect the string. The result was a test
suite containing only the mutants with a modiﬁed URL.
Also in this case, the ﬁrst test case executed, which had a
“/./” inserted into the path passed to the argument p, was
able to successfully evade Snort, while being successful at
compromising the target application.
5.2. Dynamic Analysis of Closed-source
Signatures
Having validated our approach against an open-source
IDS with known signatures, we wanted to demonstrate its
effectiveness against a closed-source intrusion detection
system. This required two different experiments. The ﬁrst
experiment aimed at demonstrating that the constraints de-
rived in the case of a closed-source system correspond to
those speciﬁed by the signatures. Unfortunately, the details
of the signatures are not known for the Symantec IDS, and,
therefore, we had to use a user-deﬁned signature to test the
precision of our constraint-derivation process with respect
to the closed-source detection engine. The goal of the sec-
ond experiment was, instead, to prove that our technique
could be used to automatically evade a signature whose im-
plementation was not known a priori.
For the ﬁrst experiment, we loaded into the Symantec
NIDS a signature to detect the IIS chunked encoding at-
tack [26]. The signature contained some basic constraints
that tested for the presence of a series of constant bytes in
an HTTP chunk (PADP\r\n), used in a particular version
of the chunked encoding exploit. Then, we executed the
attack, which was correctly detected, and we collected the
sensor’s execution traces using iTrace. The analysis of the
traces allowed for the derivation of basic constraints that
6060
netbios.rules:alert tcp $EXTERNAL_NET any -> $HOME_NET 139 (
msg:"NETBIOS SMB trans2open buffer overflow attempt";
content:"|00|"; depth:1;
content:"|FF|SMB2"; depth:5; offset:4;
content:"|00 14|"; depth:2; offset:60;
byte_test:2,>,256,0,relative,little;
reference:bugtraq,7294; reference:cve,2003-0201;
reference:url,www.digitaldefense.net/labs/advisories/DDI-1013.txt;
classtype:attempted-admin; sid:2103; rev:9;)
Figure 2. Snort SMB trans2open overﬂow signature.
web-misc.rules:alert tcp $EXTERNAL_NET any -> $HTTP_SERVERS $HTTP_PORTS (
msg:"WEB-MISC ans.pl attempt"; flow:to_server,established;
uricontent:"/ans.pl?p=../../";
reference:bugtraq,4147; reference:bugtraq,4149; reference:cve,2002-0306;
reference:cve,2002-0307; reference:nessus,10875;
classtype:web-application-attack; sid:1522; rev:10;)
Figure 3. Snort Avenger’s News System remote command execution signature.
were identical to the ones contained in our signature. The
constraints were then passed to the Sploit engine, which
generated a variation of the exploit that successfully evaded
detection.
For the following experiments, we loaded a user-deﬁned
signature into the Symantec IDS that employed a string
match to detect an attack. More precisely, we used the same
string-based signature that we used in the analysis of Snort
(see Figure 3). Our string-derivation technique was able to
correctly identify that the string “/ans.pl?p=../../”
was used as part of the detection process. This information
was used to drive the Sploit tool, which, as in the Snort