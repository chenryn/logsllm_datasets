this function with two different arguments (cache->rbtree
and cf->cycle->conf->rbtree). Figure 11 shows how
the use of Steensgaard’s analysis in this case leads to impre-
cision. Because Steensgaard’s algorithm uses uniﬁcation to
resolve constraints, it uniﬁes all pointer targets for the pointer
root, and concludes that the cf pointer “may” point to both
the cache_rbtree and the cycle_cf_rbtree objects.
However, because Andersen’s analysis is inclusion-based, it
correctly infers that the cycle ﬁeld of the cf pointer can
point only to the cycle_cf_rbtree object.
B. Constraints and Constraint Resolution Rules
In this section we discuss the various types of constraints
and constraint resolution rules that are relevant to pointer
analysis. Instructions that deal with pointer operations generate
constraints of the four types shown below. The constraint
associated with an instruction remains the same, irrespectively
of whether an inclusion-style (Andersen’s) pointer analysis
URRW
6
FDFKH
UEWUHH
FI
F\FOH
FRQIB
UEWUHH
6
&DFKH
UEWUHH
REMHFW
&RQI
F\FOH
UEWUHH
REMHFW
6
Fig. 11: Imprecision introduced by Steensgaard’s Analysis.
Solid arrows indicate actual points-to relationships. Dashed
arrows indicate ﬁelds-of relationships. Circles indicate pointers
and rectangles indicate memory objects. Steensgaard’s pointer
analysis forms three sets (S1, S2, S3), and derives that S1
→ S2, and S2 → S3. Therefore, according to Steensgaard’s
pointer analysis, cf->cycle->conf_tree may point to
both objects in set S3, and cache->rbtree also may point
to both objects in set S3.
algorithm, or a uniﬁcation-style (Steensgaard’s) algorithm is
used to solve them.
The constraints that are relevant to pointer analysis are:
1) p := &x (Address-of )
2) p := q (Copy)
3) p := ∗q (Dereference)
4) ∗p := q (Assign)
Note that p and q in these examples can be single-indirection
(int *p) or multi-indirection (int **p) pointers.
We assume that the relationship pts(p) represents the points-
to set for the pointer p. Then, the constraint resolution rules
for Andersen’s inclusion-style analysis are as follows:
1) p := &x ⇒ x ∈ pts(p)
2) p := q ⇒ pts(p) ⊇ pts(q)
3) p := ∗q ⇒ pts(p) ⊇ pts(pts(q))
4) ∗p := q ⇒ pts(pts(p)) ⊇ pts(q)
Steensgaard’s analysis is a uniﬁcation-based pointer analysis
algorithm. Every pointer and memory object belongs to a
single “set.” We assume that the operation set can be used to
ﬁnd the set membership of a pointer (i.e., which set a pointer
belongs to). Constraints in Steensgaard’s analysis are resolved
by unifying these sets and we assume that the operation join
ﬁnds the union of two sets. The constraint resolution rules for
Steensgaard’s uniﬁcation-style analysis are as follows:
1) p := &x ⇒ join(pts(set(p)), set(x))
2) p := q ⇒ join(pts(set(p)), pts(set(q)))
3) p := ∗q ⇒ join(pts(set(p)), pts(pts(set(q))))
4) ∗p := q ⇒ join(pts(pts(set(p))), pts(set(q)))
C. Steensgaard Constraint Graph Representation Details
As discussed in Appendix B, different instructions generate
constraints of different types. For example, LLVM instructions
of type AllocaInst, which create and return the address
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:29 UTC from IEEE Xplore.  Restrictions apply. 
1934
of an object, generate Addr-of constraints. Type casting in-
structions, such as BitCastInst and TruncInst, generate
Copy constraints. LoadInst instructions, which dereference
an IR pointer and return the value stored at the target location,
generate Deref constraints, and StoreInst instructions
generate Assign constraints.
SVF ﬁrst models these instructions and their constraints as
nodes on a graph, called the pointer assignment graph (PAG).
Instruction operands that are pointers or objects are modeled
as nodes in the PAG, and the IR instructions that represent the
constraints are modeled as edges. SVF then clones the PAG into
a constraint graph and begins solving the constraints. During
solving, the nodes and edges of the graph are modiﬁed to reﬂect
the constraint resolutions. While we reuse the functionality
provided by SVF to build the PAG and to model calls to external
functions, we use our own constraint graph implementation,
which we call the PTSGraph.
In Steensgaard’s analysis, pointers are members of points-
to sets. Therefore, we need a quick way to perform set
membership tests. Moreover, when the constraint solving
process encounters a copy constraint, representing a statement
of the form p := q, where p and q are pointers, we need a way
to quickly unify the two points-to sets of p and q.
In PTSGraph, we represent each points-to set with a unique
identiﬁer. A points-to set can contain multiple objects and other
pointers (in case of double pointers, such as int **p). To
ensure fast set membership tests and set uniﬁcation operations,
we represent set membership as a BitVector, a data structure
provided by LLVM that is optimized for set operations. The set
operations take time proportional to the size of the bit vector,
and operations are performed one word at a time, instead of
one bit at a time, improving performance further.
Second, points-to relationships are represented by a one-
to-one, directed relationship between two sets. To im-
prove efﬁciency, we represent
these relationships as a
std::unordered_multi_map. After processing each con-
straint in the PTSGraph, this map contains a unique map-
ping from one set identiﬁer to another. However, because
the intermediate processing of these constraints can occa-
sionally result in having to store a 1:M mapping, we use
an unordered_multi_map, to store this mapping. Be-
cause unordered_multi_map uses a hash table internally,
lookup has an average complexity of O(k), where k is the
number of set identiﬁers returned by the lookup operation.
Because after processing of each constraint k is always 1, the
lookup operation has an average complexity of O(1).
D. DFT Loop Optimizations for Array Accesses
Sensitive label lookups are signiﬁcantly less expensive than
cryptographic operations (our experiments in Section VI-B
show that AES encryption is 430% more expensive than a label
lookup), and reduce the imprecision of Steensgaard’s analysis,
as shown in Figure 1. However, label lookups still involve
a memory read and have a non-negligible runtime overhead,
especially when they are repeatedly invoked in a loop. We
observed that most label lookups that occur within loops are
due to byte-by-byte array traversals (either on the stack or the
heap) through partially sensitive pointers—as the pointer is
partially sensitive, a lookup is needed before accessing each
element. Our static analysis does not distinguish between the
individual elements of an array, and thus even if one element
is sensitive, then all elements of the array become sensitive.
Given that these in-loop lookups incur considerable runtime
overhead, we optimize them as follows. First, we use LLVM’s
Loop Analysis pass to retrieve all loops in the bitcode of the
program. For each loop, we inspect each instruction to check
if it performs a memory load or store indexed by an offset
from a base pointer, of the form v = *(ptr+i) or v =
ptr[i], where i is the loop counter. For every such loop,
we clone it and specialize the clone to unconditionally perform
the required AES transformation on the identiﬁed memory
operations, while the original loop body remains unchanged.
The sensitive label lookup is then hoisted outside the loop,
and checks only the ﬁrst element of the array. A conditional
branch then transfers control to either the specialized or the
unmodiﬁed loop, depending on the presence or absence of
a sensitive label. This allows us to perform a single label
lookup to ascertain the sensitivity of the entire array, instead
of performing multiple byte-by-byte lookups, thus reducing
the performance overhead.
E. Spectre Exploit Details
1) Spectre-PHT (Bounds Check Bypass): The Spectre-PHT
PoC [40] contains a bounds check which is bypassed to leak
a secret string. Listing 2 shows the bounds check in the
function victim_function, that is speculatively bypassed
to overﬂow array2 and load the secret string from memory
into the cache. We mark this string as sensitive and use
DynPTA to harden the program. This encrypts the in-memory
representation of the secret. When the secret is speculatively
accessed, by overﬂowing array2, only the encrypted contents
are loaded into the caches. Therefore, only the encrypted
contents can be leaked and the conﬁdentiality of the secret is
preserved.
1 void victim_function(size_t x) {
2
3
4
5
6
7 }
8
9 int main(void) {
10
11
12
13 }
Listing 2: Code snippet for Spectre Variant-1 vulnerability
char* secret = "This is a secret";
mark_sensitive(secret);
...
}
...
...
if (x < array1_size) {
temp &= array2[array1[x] * 512];
2) Spectre-BTB (Indirect Branch Poisoning): The Spectre-
BTB PoC [41] contains a secret string that is leaked by
redirecting the speculative execution to an appropriate gadget.
Listing 3 shows the relevant snippet of code from the PoC. The
function victim_function contains the indirect branch
that can be poisoned to redirect (speculative) execution to
the gadget that leaks the in-memory secret. Similarly to the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:29 UTC from IEEE Xplore.  Restrictions apply. 
1935
Fig. 12: Runtime overhead of Nginx for protecting passwords
along with SSL private key when HTTP password authentica-
tion is enabled.
return channel[*addr * 1024];
Spectre-PHT exploit, we mark this secret as sensitive and use
DynPTA to harden the program. This encrypts the in-memory
representation of the secret, ensuring that only the encrypted
contents are loaded into (and potentially leaked from) the cache,
while the plaintext secret remains conﬁdential.
1 int gadget(char *addr) {
2
3 }
4
5 int safe_target() {
6
7 }
8
9 int victim_function( *addr, int input) {
10
11
12
13 }
14
15 int main(void) {
16
17
18
19
20 }
Listing 3: Code snippet for Spectre Variant-2 vulnerability
char* secret = "This is a secret";
mark_sensitive(secret);
...
victim(...);
return 42;
...
(*addr)();
...
F. Nginx with Password Authentication
In addition to protecting the SSL private key, we enabled
HTTP password authentication for Nginx and also protect the
in-memory passwords. Although this is a rarely encountered
use case in real-world deployments, marking these two different
types of data as sensitive results in additional instrumentation at
different parts of the code. During authentication, the provided
user password is checked against a list of credentials loaded in
memory from a ﬁle, which we mark as sensitive. Using the same
set of experiments described in Section VI-C1, we observed
only a minor increase of 1% in the overall performance
overhead, as shown in Figure 12. This is in line with our
experience with protecting the HTTP password for Httpd and
Lighttpd (Figure 9(b)–(c)).
During startup, the SSL private key is read from a ﬁle, and
thus its plaintext form is brieﬂy exposed on the stack, before
being encrypted by DynPTA. In practice, these stack frames
are destroyed (overwritten) right after the server’s initialization
Fig. 13: Microbenchmark results of DynPTA’s run-time over-
head with and without scoped-DFT, for an increasing ratio
of sensitive vs. non-sensitive data in the program. As the
percentage of sensitive data exceeds 70–80%, the scoped DFT
and label lookups become more costly than simply encrypting
all objects identiﬁed by the points-to analysis.
completes (and the called function returns). For our work, we
assume that the system starts from a clean state, and because
the server has not started handling requests yet, this window of
opportunity does not represent a vulnerability. Still, to illustrate
that sensitive data can be protected right upon their initial
introduction in memory from external sources, we marked as
sensitive the stack objects in which the SSL private key is
loaded temporarily during program initialization (speciﬁcally,
buf, data, and dataB in function PEM_read_bio). The
data in these objects is read via the fread Glibc call. Marking
these objects as sensitive, using the mark_sensitive
primitive, encrypts them in memory. Because PEM_read_bio
is invoked only during program startup and these objects are
never referenced again, we did not observe any performance
impact due to these additional sensitive objects.
G. Microbenchmarks
To further study the performance characteristics of DynPTA
as an increasing amount of application data is marked as
sensitive, we implemented two microbenchmark programs and
hardened them using DynPTA. The data in both programs
comprise a list of 100 arrays, with each array initialized with
100,000 random integers. In each round, we can vary the
percentage of arrays that are marked as sensitive. The ﬁrst
microbenchmark computes the largest number of all items in
the list of arrays, and the second microbenchmark sorts all
integers in the list of arrays using the merge sort algorithm.
For our experiments, we varied the ratio of sensitive to
non-sensitive arrays in each microbenchmark and measured
the run-time overhead at each point. As shown in Figure 13,
as the ratio of sensitive to non-sensitive arrays increases, the
overhead increases linearly as well (from 5.4% to 401% for
largest number, and from 6% to 393% for merge sort).
To study the performance beneﬁts of scoped DFT, we
repeated the above experiments by disabling scoped DFT and
label lookups, i.e., using the results of Steensgaard’s analysis
directly to encrypt all objects identiﬁed by the points-to analysis.
As shown in Figure 13, without scoped DFT the overhead is
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:29 UTC from IEEE Xplore.  Restrictions apply. 
1936
signiﬁcantly higher and overall remains constant, irrespectively
of how many arrays are actually marked as sensitive. Both
microbenchmarks consist of a tight loop that reads the items
from each array in the list and performs an operation on
them. Because the same pointer is used to perform the indirect
memory read access from each arrays, pointer analysis infers
that this is a sensitive pointer, and thus applies the AES
transformations to it. This results in all arrays being treated
as sensitive (and requiring to be encrypted in memory), even
though the programmer explicitly annotated only a fraction of
them as sensitive. This results in high performance impact even
though only a fraction of the arrays are marked as sensitive.
Although DynPTA performs better than this “naive” approach
as long as the amount of sensitive data remains below 70–80%,
scoped DFT actually becomes more costly once the amount of
sensitive data exceeds this threshold. The main reason is that the
cost of the excessive number of DFT label lookups at that point
becomes higher than the beneﬁt of eliding AES operations, as
only a fraction of data at that point is non-sensitive.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:29 UTC from IEEE Xplore.  Restrictions apply. 
1937