title:Differentially Private Histograms in the Shuffle Model from Fake Users
author:Albert Cheu and
Maxim Zhilyaev
4
1
6
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
Â©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
Differentially Private Histograms
in the Shufï¬‚e Model from Fake Users
Albert Cheu
Department of Computer Science
Georgetown University
Email: PI:EMAIL
Maxim Zhilyaev
Meta Privacy
Email: PI:EMAIL
Abstractâ€”There has been much recent work in the shufï¬‚e
model of differential privacy, particularly for approximate d-bin
histograms. While these protocols achieve low error, the number
of messages sent by each userâ€”the message complexityâ€”has
so far scaled with d or the privacy parameters. The message
complexity is an informative predictor of a shufï¬‚e protocolâ€™s
resource consumption. We present a protocol whose message
complexity is two when there are sufï¬ciently many users. The
protocol essentially pairs each row in the dataset with a fake
row and performs a simple randomization on all rows. We show
that the error introduced by the protocol is small, using rigorous
analysis as well as experiments on real-world data. We also prove
that corrupt users have a relatively low impact on our protocolâ€™s
estimates.
I. INTRODUCTION
Given that statistical computations often involve data sourced
from human users, an analyst could execute differentially
private algorithms in the central model (also called centrally
private algorithms). Originally deï¬ned by Dwork, McSherry,
Nissim, and Smith [12], these algorithms provide quantiï¬able
protection to data contributors at a small price in terms of
accuracy. As an example, there exists an (Îµ, Î´)-centrally private
algorithm that computes d-bin histograms from n users up to
maximum ((cid:96)âˆ) error O( 1
Îµn log 1
Î´ ) [6].
We focus on computing accurate histograms since they allow
approximate top-t selection, the set of t data values that occur
most frequently in a population. One application is smart-
phone autocomplete. Because devices are resource constrained,
a keyboard offers word corrections from a smaller pool than
the entire vocabulary. To obtain a list of the most common
words, user devices could participate in a differentially private
computation that estimates word frequencies.
Users contributing to a centrally private algorithm need to
trust that the analyst correctly executes the algorithm and does
not leak their data. To collect data from less trusting users,
analysts can instead implement locally private protocols: each
user applies a differentially private algorithm on their data and
sends a message containing the algorithmâ€™s output to the analyst.
This weaker trust assumption comes at a price: there are lower
bounds that show locally private protocols have signiï¬cantly
more error than the centrally private counterparts. Returning to
the histogram example, Bassily & Smith show (Îµ, o(1/n))-local
privacy incurs a maximum error of â„¦( 1
Îµ
(cid:113) log d
n ) [4].
Figure 1: Diagram of the shufï¬‚e model. Like the local model,
users individually randomize their data to protect against an
untrusted analyzer. But unlike the local model, there is a shufï¬‚er
which anonymizes messages.
Originating with work by Bittau et al. and Cheu et al.
[5, 10], shufï¬‚e privacy has emerged as an appealing middle-
ground. Here, we assume that there is a service called the
shufï¬‚er that uniformly permutes user messages. The output of
the shufï¬‚er must satisfy (Îµ, Î´)-differential privacy. Intuitively,
if each user generates a locally private message, then the
anonymity provided by the shufï¬‚er should â€œamplifyâ€ the
privacy guarantee. Put another way, o( 1
n ) histogram
Îµ
error may be possible for the same privacy parameters as in
the local model.
(cid:113) log d
As shown in Figure 1, a user can send multiple messages
to the shufï¬‚er. And a user does not need to produce these
messages in a differentially private manner, since we only
require that the output of the shufï¬‚er is differentially private.
This ï¬‚exibility is leveraged by the histogram protocol of Balcer
& Cheu [2], where each user sends d + 1 messages and the
maximum error is O( 1
Î´ ) for Î´ = O(1/n). This is within
a 1/Îµ factor of the central model result. Alternative histogram
protocols in the shufï¬‚e model have been introduced by Ghazi,
Golowich, Kumar, Pagh, and Velingker [16] and by Ghazi,
Kumar, Manurangsi, and Pagh [17]. As shown in Table I,
these protocols demand fewer messages from each user (in
expectation) than the protocol from [2].
Îµ2n log 1
We will use message complexity to refer to the number of
messages sent by each user and communication complexity to
refer to total number of bits consumed by those messages. The
message complexity is necessary to have a complete picture
of a protocolâ€™s resource consumption. For starters, the amount
of randomness needed to perform the shufï¬‚e is a function of
Â© 2022, Albert Cheu. Under license to IEEE.
DOI 10.1109/SP46214.2022.00055
440
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
User ğ‘›User 2User 1ğ‘¦1,1Shufflerğ‘†ğ‘…(ğ‘¥1)ğ‘¥1Analyzerğ´ğ‘¦2,1ğ‘…(ğ‘¥2)ğ‘¥2ğ‘¦ğ‘›,1ğ‘…(ğ‘¥ğ‘›)ğ‘¥ğ‘›Raw dataRandomizerMessagesğ‘¦81,1ğ‘¦27,2ğ‘¦4,1â€¦ â€¦ â€¦ â€¦ ğ‘¦1,2ğ‘¦2,2ğ‘¦ğ‘›,2the message complexity but not the length of each message.
Furthermore, two protocols P,P(cid:48) with the same communication
complexity can incur different costs, since the physical delivery
of a message over a network in a secure fashion requires
overhead. If P sends more messages than P(cid:48), the computing
cost of transmitting messages is larger for P, since it needs to
perform cryptographic operations on each message. Also, the
bandwidth overhead is larger for P, due to both encryption
and physical network protocols such as TCP/IP.
In light of the above, one can ask the following question:
Are there shufï¬‚e private protocols for histograms
that have low message complexity but still provide
estimates that are competitive with prior work?
Given the distributed nature of local and shufï¬‚e protocols,
they are impacted by users who deviate from the intended
behavior. In the local privacy literature, there is research
on manipulation attacks where corrupted users aim to skew
estimates and tests by sending carefully crafted messages. One
baseline attack is to simply feed wrong inputs into the protocol,
but the prior work has shown that there are attacks against
locally private protocols that introduce signiï¬cantly worse error
(see e.g. Cao, Jia, and Gong [7] and Cheu, Smith, and Ullman
[11] and citations within). Here, we investigate manipulation
against shufï¬‚e private protocols. Speciï¬cally,
Are there shufï¬‚e private protocols for histograms
that are robust to manipulation by users?
A. Our Contributions
Our primary contribution is a shufï¬‚e private protocol for
histograms that answers both questions in the afï¬rmative. For
a large range of n, the message complexity can be as small as
two. We also show that one consequence of the low message
complexity is robustness to manipulation.
any positive integer. Each message is d bits.
Section III contains the full speciï¬cation and analysis of our
protocol, but we give an overview of the core features in the
theorem below.
Theorem I.1 (Informal). For any privacy parameters Îµ = O(1),
Î´ < 1/100, and number of users n = â„¦(log d + 1
Î´ ),
Îµ2 log 1
there is an (Îµ, Î´)-differentially private shufï¬‚e protocol that
approximates d-bin histograms with the following properties
i. The message complexity is k + 1, where k can be set to
ii. The maxmimum error of any bin estimate is f (k) Â·
Î´ ) with probability 9/10,1 where
n Â·
iii. m corrupted users can skew an estimate by at most m
O( log d
f (k) monotonically approaches 1 from above.
(k + 1) Â· f (k).
We unpack this theorem. Parts i and ii show that the protocol
allows for a tradeoff between message complexity and the
measurement accuracy, since increasing k reduces a scaling
factor f (k). This may not be signiï¬cant for large n, but it could
log d log 1
(cid:113)
n + 1
Îµn
1We use 9/10 as a target success probability throughout this work, but it
can be changed to any other constant without affecting the asymptotic analysis.
be useful for smaller n (e.g. the target population of a health
survey can consist of much fewer subjects than the dictionary-
building example). Re-scaling k by a factor of c will naturally
increase the transmission cost by c but the trafï¬c remains
feasible since n is small. Thus, we can improve accuracy
without altering the privacy guarantee.
Meanwhile, Part iii bounds the impact of any manipulation
attack. Each corrupt user in our protocol can introduce O( 1
n )
bias whenever kÂ· f (k) = O(1). For comparison, we also prove
that a protocol by Ghazi et al. [16] suffers â„¦( 1
Î´ ) bias
per corrupt user.
Îµ2 log 1
n Â· 1
In Section IV, we describe experiments on text sampled
from Twitter to evaluate our protocolâ€™s accuracy (absent an
attack). The error introduced by our protocol to the histogram
is consistent with our theoretical bounds. We also show that
the top-t items in the output of the protocol are consistent
with those in the raw dataset, for several choices of t. The
experimental results of our protocol compare favorably to that
of [2]. We also show that the protocol in [17] produces more
accurate estimates than ours but at high cost.
We also study variants of our main protocol. In Section
V, we describe how to exponentially reduce the protocolâ€™s
communication complexity. The price is an increased message
complexity and a mildly increased error. Appendix C analyzes
the special case where k = 0 so that each user transmits only
one message. We combine steps taken by Ghazi et al. [16] with
the state-of-the art ampliï¬cation lemma by Feldman, McMillan,
and Talwar [15]. This alternative protocolâ€™s maximum error is
proportional to 1/n3/4 instead of 1/n.
Techniques: Each user in our protocol ï¬rst encodes their data
âˆˆ [d] as a binary string âˆˆ {0, 1}d with a single set bit. They
then ï¬‚ip each bit independently with probability q. Next, they
repeat this bit ï¬‚ipping on k all-zero strings, which corresponds
to introducing k fake users with null data. The user sends all
k + 1 randomized strings to the shufï¬‚er. The analyzer receives
the shufï¬‚ed set of messages and then computes a simple linear
function on the binary sums. Much of our work is devoted
to choosing q so that the nk messages from the fake users
provide differential privacy for the actual users.
Our technique to reduce communication complexity proceeds
in two stages. We ï¬rst make the simple observation that a binary
string with known length is equivalent to a list of the indices
of set bits. By construction, a message generated by our local
randomizer is a binary string where the number of such indices
has expectation O(dq). Our choice of q is proportional to
1/n, so this alternative representation is very effective when n
approaches or exceeds d.
The small n regime motivates the second round of compres-
sion, which adapts the count-min sketching technique. Given
a random hash function, we can reduce the size of the domain
d to some Ë†d, so we run our histogram protocol on the hashed
data. Collisions with user data are possible, but if we sample
enough hash functions, it is likely that there is a hash for each
domain element that free of such collisions. We remark that
Ghazi et al. [16] build a speciï¬c histogram protocol out of
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:25:20 UTC from IEEE Xplore.  Restrictions apply. 
441
count-min, while our approach is general enough to work with
arbitrary histogram protocols.
B. Related Work
We brieï¬‚y recap prior work on private histograms in the
shufï¬‚e model. Cheu, Smith, Ullman, Zeber, and Zhilyaev
[10] rigorously deï¬ne the shufï¬‚e model and give a histogram
protocol that requires d messages per user. Balcer & Cheu [2]
give a different protocol with the same asymptotic message
complexity but with maximum error independent of d. These
two results are presented in the ï¬rst row of Table I.
We note that Cheu et al. [10] and Balcer & Cheu [2] use the
same design pattern: equate a histogram with a composition
of d counts and then privatize those counts using binomial
noise. This technique is not used by our core protocol or
the protocol based on Hadamard response by Ghazi et al.
[16]. In these works, users generate exactly one message
from their data and then sample messages from a data-
independent distribution. Privacy proofs for these protocols rely
on bespoke multinomial distributions, instead of composition of
the binomial mechanism. Our work differs from [16] because
we explore what is possible with low message complexity
while they optimize communication complexity.
[16] also give a protocol based on the ampliï¬cation lemma
from Balle, Bell, GascÃ³n, and Nissim [3]. Our analysis in
Appendix C uses a more recent ampliï¬cation lemma.
In follow-up work, Ghazi et al. [17] give a protocol where
the message complexity shrinks as n increases. Our protocol
has the same property but at a faster rate. Speciï¬cally, our
message complexity is two when n is logarithmic in d while
the prior work requires n to be linear in d.
Manipulation attacks have previously been studied in the
context of local privacy. Ambainis, Jakobsson, and Lipmaa
[1] as well as Moran and Naor [19] study the vulnerability
of randomized response to these attacks. Work by Cao, Jia,
and Gong [7] also consider attacks against histogram and
heavy hitter protocols. Cheu, Smith, and Ullman [11] show
that powerful attacks are inevitable for any locally private
protocol. In particular, these attacks are stronger when the
privacy guarantee is stronger or the data dimension is larger.
may not hold for every (cid:126)x âˆ¼ (cid:126)x (cid:48) âˆˆ X n. In these cases, we
will disambiguate by saying it satisï¬es differential privacy for
inputs from X .
Because this deï¬nition assumes that the algorithm M has
â€œcentralâ€ access to compute on the entire raw dataset, we
sometimes call this central differential privacy. Two properties
about differentially private algorithms will be useful. First,
privacy is preserved under post-processing.
Fact II.2. For (Îµ, Î´)-differentially private algorithm M :
X n â†’ Z and randomized algorithm f : Z â†’ Z(cid:48), f â—¦ M
is (Îµ, Î´)-differentially private.
This means that any computation based solely on the output
of a differentially private function does not affect the privacy
guarantee. Refer to Prop. 2.1 in the text by Dwork and Roth [13]
for a proof. The second property is closure under composition.
Fact II.3. For (Îµ1, Î´1)-differentially private M1 and (Îµ2, Î´2)-
differentially private M2, M3 deï¬ned by M3((cid:126)x) =
(M1((cid:126)x),M2((cid:126)x)) is (Îµ1 + Îµ2, Î´1 + Î´2)-differentially private.
Fact