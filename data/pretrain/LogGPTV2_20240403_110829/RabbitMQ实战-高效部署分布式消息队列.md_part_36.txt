做你就可以降低未消费消息总数上的误报次数，同时能够在未确认消息总数高企时
快速收到通知。
与到目前为止所有的健康检测一样，首先你需要获取RabbitMQ连接和从命令
行传入的认证信息。除此之外，还需要获取监控的队列名称，以及未消费（等待）
和未确认消息计数这两者的critical和warning国值：
server, port = sys.argv[l].split(":")
vhost = sys.argv[2]
username =-sys.argv[3]
password = sys.argv[4]
queue_name= sys.argv[5]
max_unack_critical = int(sys.argv[6])
max_unack_warn = int(sys.argv[7])
max_ready_critical = int(sys.argv[8]
max_ready_warn = int(sys.argv[9])
在设置了健康检测之后，你准备好连接到API服务器。与之前基于API的健
康检测一样，你会使用相同的连接代码。不过这次你将连接到/api/queues/
/:
conn = httplib.HTTPConnection(server, port)
path = "/api/queues/%s/%s" % (urllib.quote(vhost， safe=""),
queue_name)
method="GET"
credentials =base64.b64encode("%s:%s" % (username, password))
try:
conn.request (method, path, "",
{"Content-Type":"application/json",
"Authorization":"Basic "+ credentials})
except socket.error:
exit(EXIT_UNKNOWN)
response = conn.getresponse()
if response.status > 299:
exit (EXIT_UNKNOWN)
假设API连接成功并且请求没有导致任何HTTP错误，你现在可以分析响应来
确定队列当前的消息计数级别。在对响应进行JSON解码后，你就可以从响应字典
中获取 messages_unacknowledged 和 messages_ready :
resp_payload = json.loads(response.read())
msg_cnt_unack = resp_payload["messages_unacknowledged"]
---
## Page 236
214
第10章监控
msg_cnt_ready = resp_payload["messages_ready"]
msg_cnt_total = resp_payload["messages"]
最后，在获得未消费（等待）和未确认消息计数之后，你可以将它们与提供的
国值进行比较，如下列清单所示。
清单10.9api_queue_count_check.py：检查消息计数
if msg_cnt_unack >= max_unack_critical:
print "CRITICAL:%s - %d unack'd messages."%(queue_name,
1未确认的消
msg_cnt_unack)
息计数超过
exit(EXIT_CRITICAL)
了阈值
elif msg_cnt_unack>= max_unack_warn:
等待消费2
print"wARN:s-%d unack'd messages."%(queue_name,
的消息计
msg_cnt_unack)
数超过了
exit(EXIT_WARNING)
阈值
> if msg_cnt_ready >= max_ready_critical:
msg_cnt_ready
exit(EXIT_CRITICAL)
elif msg_cnt_ready >= max_ready_warn:
print "wARN:%s -%d unconsumed messages."%(queue_name,
msg_cnt_ready)
exit(EXIT_WARNING)
print"oK:$s-&d in-flight messages.%dB used memory."\
(queue_name,msg_cnt_total,resp_payload["memory"])
消息计数低
exit (EXIT_OK)
于阈值，返
③回OK
首先要检测的是未确认消息计数是否超过了critical或者warning级别O。如果
是的话，则将退出代码设置为EXIT_CRITICAL或EXIT_WARNING（取决于超过了
哪个国值），并输出队列中当前未确认消息的总数。假设未确认消息计数未超过任何
国值，下一步将分析未消费（等待）消息计数2。同样地，如果未消费消息计数超
过了critical或者warning阈值的话，将退出代码设置为EXIT_CRITICAL或EXIT_
WARNING，然后输出未消费消息的总数。最后，如果未消费消息和未确认消息计数
均未超过对应的critical或者warning阈值的话，那么将状态退出码设置为EXIT_
OK，以便让Nagios知道一切正常3，同时输出队列中的消息总数（未消费+未确认）
和队列当前消耗的内存量。
虽然测试未确认消息阈值较为复杂，但是你应该可以使用队列mY_queue中的
消息（之前测试基于AMQP的消息总数检测时创建）来验证这个新的基于API的
检测程序。如果你分别将未确认的critical/warning国值设置为两条和一条消息的话，
---
## Page 237
10.2确保消费者正常工作
215
API消息计数检测应该能正确地检测到未消费（等待）消息超过了国值：
$ python api_queue_count_check.py localhost:55672 / guest \
guest my_queue 2 1 2 1
CRITICAL: my_queue - 2 unconsumed messages.
$echo$?
2
如果你分别将critical/warning未消费国值提升到四条和三条消息的话，检测程
序应该认为队列中的未消费消息计数是正常的：
$.python api_queue_count_check.py localhost:55672 / guest \
guestmy_queue4343
OK: my_queue - 2 in-flight messages. 9800B used memory.
$echo $?
0
检测程序报告了队列中共有两条消息，同时该队列消耗了9800字节的内存（实
际内存使用不尽相同）。现在你手里的健康检测程序能够区分到底是队列中的未确
认消息还是未消费消息超过了国值。这能帮助你更快地确认消息总数表明的是由负
载增加导致的，还是由应用程序中的缺陷导致的。剩下的问题是：如何为队列确定
消息总数的基准线，以便为健康检测程序设置critical和warning阈值？
10.2.3建立队列的消息计数基准经验法则
有许多方法来确认队列消息总数的critical和warning国值。如果你正将现存的
应用转换为使用消息通信架构的话，其中的日志文件可以提供合理而又准确的信息
来源。举例来说，如果应用程序处理信用卡订单的话，你可能已经将每笔订单的时
间戳记录到了数据库当中。通过使用这些日志观测10秒时间间隔内能够处理多少
笔订单，就是很好的经验法则。该数值通常来讲可以作为你的warming国值，这是
常代表的是1秒甚至是更短的时间段。如果队列中的消息总数在任何给定的时间上
超过了10秒内消息/订单处理总数的话，那么就有问题了。同理，将critical阀值
设置为20秒内处理的订单/消息总数。记住，该方法是一种估算，你需要监控真实
的队列级别来确认这些国值对你的环境来说是否正确。
确定warning和critical消息总数国值的最好方法是使用Cacti或Graphite这样
的图形监控系统来监控队列。通过对消息总数检测程序进行修改来与这些系统一同
---
## Page 238
216
第10章监控
工作，它们能够通过定期采样数据来图形化真实的队列消息总数。由此产生的图形
结果将向你展示近乎精确的真实平均未消费和未确认消息总数。在掌握了这些数据
之后，增加20%就可以得到warning阈值，而增加100%就可以得到critical国值。
通常来讲，任何高于正常情况20%~90%的情况都属于正常波动。但是高于正常情
况100%或者更高的话，那绝对值得你去探个究竟，因为肯定已经出了差错。
10.3总结
或者确保它真正可靠。现在你已经构建了健康检测程序，它不仅可以查询RabbitMQ
服务器以确保其可以处理AMQP命令；又能监控实际的消息总数级别，用来确定从
队列上消费的消费者的健康情况。此外，你也能对队列的配置进行监控，以确保人
为错误不会将你的队列从持久化更改为非持久化，从而避免下次服务器发生故障时
演变为灾难。监控RabbitMQ是确保服务器正常运行并为应用程序高效地提供动力
的至关重要的组成部分。一旦开始监控RabbitMQ，这些健康检测程序就能够让你
观测到低效和问题，你可以通过调整Rabbit来进行纠正。记住这些，现在该来看看
分析RabbitMQ性能和行为的方法，这样你就能在应用程序中将两者最大化。
---
## Page 239
提升性能，保障安全
本章要点
■交换器、队列和绑定的内存占用
■消息持久化和磁盘I/O
■RabbitMQ的SSL连接
■设置私钥架构
在之前的几个章节中，你已经知道如何设计消息通信系统架构了。你见识过了
使用不同种类的AMQP构造块，诸如交换器、队列和绑定来实现多种消息通信模式。
根据你手头遇到的问题，你选择这些构造块的特定组合来实现解决方案。如果你需
要在多台机器上分发日志的话，则可以遵循pub-sub模式，使用topic或者fanout交
换器；如果你需要点对点通信，那么就使用direct交换器，等等。在本章中，我们
会回顾这些设计决策的性能。你将会看到使用direct交换器和topic交换器的利对
比；交换器、队列或者绑定规则的最小内存占用；与fanout交换器相比，当你拥有
数以百计的绑定规则附加在topic交换器上的话，会如何呢？同时你可能也会有这
样的疑问，消息何时写人磁盘？服务器如何处理众多的内存队列？我们的目标是提
供足够的信息，以便在涉及容量规划时帮助决策。我们通过分析消息从生产者路由
到消费者的路径，基于多个AMQP选项，来完成实现。
---
## Page 240
218
第1章提升性能，保障安全
在我们讨论性能之后，你将看到如何保障RabbitMQ安装的安全性；更具体地说，
如何使用SSL来建立到代理服务器的可信赖的连接。我们会讲到在RabbitMQ中后
用SSL监听器的配置方面，如何生成SSL证书，以及如何使用SSL来连接代理服务器。
让我们先看看11.1节，在这里你会明白，从AMQP的角度来看，是什么影响
了消息通信的投递速度。
11.1对速度的需求
有很多因素可以影响RabbitMQ投递消息的速度，这依赖于硬件和软件的配置。
在硬件配置方面，这些因素有网络配置、磁盘管理、处理器核心数等。在软件级别，
你可以配置多个AMQP参数，例如消息持久化、路由算法、绑定数目，以及消息确
认策略。由于前者完全取决于装机情况，因此在本章中我们就不展开了。我们会专
门讨论AMQP细节以及RabbitMQ如何对它们进行设置。
让我们从回顾消息的持久化和消息确认机制是如何影响消息投递的开始。
11.1.1消息持久化
当讨论软件性能时，所有事情都应该谨慎对待。为什么呢？因为你做的任何决
定都应该顾及到整个应用场景。你做的任何决定都有利有弊。举个例子，你能加快
系统日志的消息投递速度，这些消息甚至都不用持久化到磁盘上，但是对那些购物
车的订单处理来说，你最好确保处理过程方无一失。因此，虽然你可以把日志信息
作为非持久化消息发送出去，然后消费它们而无须确认，但是你可承担不起以这种
方式来同样处理与客户的金钱交易。所以每当处理这种类型的性能调优时，你都应
该再三思考所做的取舍。
当发布消息时，你需要决定去失其中的任何消息对你来说是否可以接受。如果
丢失了几千条消息当中的几条（不管什么原因）对你来说可以接受的话，那么可以
将delivery-mode设置为1（即非持久化的），然后发布它们。通常情况下，你会
通过将delivery-mode设置为2来将消息设置成持久化的，然后再发送。但是这
是有代价的，服务器需要把消息写到磁盘上。举例来说，在一台Mac上，RabbitMQ
可以轻轻松松以最多每秒12000条的速度投递消息。如果启用消息持久化的话，那
么速度会一下子掉到每秒4000条左右的样子。虽然这样的速率仍然很高，但是相
---
## Page 241
11.1对速度的需求
219
比之前已经大大地降低了。
你如何管理这个设定呢？你需要为每一条发往服务器的消息指定该属性。下列
代码片段展示了如何用PHP库来创建非持久化消息：
另一个影响消息通信速度的设定是消息确认。让我们看看吧。
11.1.2消息确认
前面我们介绍了消息发布的设定；现在该来看看在消息消费过程中你该如何配
置了。其中一个可以加快消息投递的设定是no-ack标记，你可以在队列订阅时指明。
如果设置为trule，服务器就会在消息发送给客户端后自动将其出队。如果由于某些
原因连接中断了，或者你的客户端应用程序发生故障了，那么该消息就永远去失了。
如果在订阅队列时将no-ack设置为true的话，那么你处理完消息之后就无须
再发送确认消息回服务器。这样就能极大地加快消费者消费的速度。在服务器端，
由于RabbitMQ在消息投递之后就无须再关注了，因此消息处理的过程得到了简化。
以下是Python代码片段，它向你展示了如何从队列消费消息，并将no-ack设置为
true:
channel.basic_consume(critical_notify,
queue="critical",
no_ack=True,
consumer_tag="critical")
你将从critical队列消费消息，并且也用critical作为消费者标记。对于
收到的每一条消息，回调函数critical_notify都会被调用。现在该看看消息路
由期间发生了什么。在下一节里，我们将分别介绍RabbitMQ使用的几种主要路由
算法。
11.1.3路由算法和绑定规则
在本书中，我们已经讨论过了三种不同类型的交换器：direct、fanout和topic。
每种交换器类型代表了服务器实现的特定路由算法。当需要交换器来路由一条消息
时，它会根据消息的路由键以及队列与交换器之间的绑定来选择队列。由于每种交
---
## Page 242
220
第11章提升性能，保障安全
换器类型都会区别对待消息路由键，因此队列的选择过程会因为交换器类型的不同
而不同。
在服务器端，交换器和绑定作为记录条目存储在Mnesia中。这意味着当
RabbitMQ匹配消息路由键时，它会尝试查找对应该路由键的绑定。Mnesia是一个
高性能数据库，它的存储是基于Erlang的ETS 和 DETS 表的'。ETS 指的是Erlang
TermStorage（Erlang数据存储），它将数据存储在内存中；而相应地，DETS是一个
基于磁盘的存储方案。使用基于普通ETS函数调用的Mnesia的好处是，Mnesia可
以协调在整个集群中对表的访问。举个例子，当你在一个集群节点上创建了交换器
的时候，Mnesia会负责将该信息复制到集群中的所有其他节点上；而对于添加绑定、
声明队列等来说，Mnesia也会这样做。虽然Mnesia在保持一致性方面工作得很好，
但是当你需要执行某种类似路由键匹配的查询时会减慢速度。不过，其中的部分过
程已经针对direct和fanout类型的交换器进行了优化，所以你不用承受Mnesia为
了协调工作而付出的代价了。对于该交换器类型来说，绑定存储在ordered_set
类型的rabbit_route表中。根据ETS表的介绍文档，针对这种类型表格的访问
时间与数据库中的条目总数成对数关系。同时，由于orderedset表格类型的特
性，RabbitMQ开发人员在从表格中选取数据时，可以执行一些有趣的优化来绕过
Mnesia。这意味看RabbitMQ路由表由Mnesia来提供对一致性的保证，而由普通
ETS表来提供数据查询速度的保证。
direct和fanout交换器
direct交换器和fanout交换器之间的差别在于后者在查询rabbitroute表时
忽略了路由键。因此，虽然你可以在队列绑定时为fanout交换器提供一个路由键，
但是在路由消息的时候，该路由键会被忽略。当发布带有路由键的消息给fanout交
换器时，该路由键同样会被忽略。