的结构，另一方面是大刀阔斧地提升SM的数量。
伏特微架构基本沿用了麦斯威尔微架构开创的SM结构，但是加入
了一些增强。在GV100的每个SM中（见图9-8），仍是按4个片区来配
置处理器。在每个片区中，除了有16个32位的CUDA核心外，还有16个
整数处理器（图中标为INT），8个双精度浮点处理器（图中标为
FP64）。此外，还针对深度学习用途增加了两个支持混合精度数据类型
的张量核心（Tensor Core）。引入张量核心应该也有与谷歌公司的
TPU（Tensor Processing Unit）竞争的目的。
图9-8 GV100（伏特微架构）SM结构框图
GV100发布在正值人工智能（AI）技术如火如荼的时候，其主要设
计目标也是面向AI的。在这一目标的指导下，可以看到SM中的硬件资
源分配也是朝着AI方向倾斜的。有一方重，就有另一方轻，在GV100
中，针对3D图形应用的资源明显减少。纹理处理单元的数量从帕斯卡
微架构时的8个减少为4个，专门应用于3D图形的PolyGraph引擎也不见
了。
在芯片层面，GV100空前地把SM个数提高到84，每14个SM组成一
个GPC，一共有6个GPC（见图9-9）。不过，因为生产过程中部分芯片
的个别SM可能存在瑕疵，所以在实际产品中SM的数量可能是低于84个
的。在GV100的产品描述中，SM的个数为80，于是32位CUDA核心的
总个数达到空前的5120。
图9-9 GV100（伏特微架构）结构框图
在图9-9中，左右两侧标有HBM2的方框代表第二代高带宽内存接口
（High Bandwidth Memory 2，HBM2）。HBM技术最先是由AMD研发
的，2013年成为工业标准。为了保证内部的5000多个CUDA核心可以顺
畅地访问显存，GV100配备了 8 个内存控制器（memory controller），
每两个内存控制器控制共用一个HBM2高速接口，以避免内存访问成为
瓶颈。
图9-9下方的NVLink代表的是高速互联接口，主要用于多个GPU之
间的高速通信。NVLink技术是帕斯卡微架构引入的。
9.2.8 持续改进
上文花较大篇幅介绍了Nvidia GPU的微架构，从特斯拉微架构开
始，一直到较新的伏特微架构。为了更容易观察各个微架构之间的共性
和差异，针对特斯拉产品线中的4款产品，表9-2列出了它们的关键特征
[5]。
表9-2 不同微架构关键特征比较
关 键 特 性
特斯拉K40
特斯拉M40
特斯拉P100
特斯拉V100
GPU
GK180（开普勒
架构）
GM200（麦斯威
尔架构）
GP100（帕斯卡
架构）
GV100（伏特
架构）
SM个数
15
24
56
80
TPC个数
15
24
28
40
FP32核心/ SM
192
128
64
64
FP32核心/
GPU
2880
3072
3584
5120
FP64核心/ SM
64
4
32
32
FP64核心/
GPU
960
96
1792
2560
张量核心
NA
NA
NA
640
GPU跳频时钟
810/875MHz
1114MHz
1480MHz
1530MHz
FP32
TFLOP/s①
5.04
6.8
10.6
15.7
FP64
TFLOP/s①
1.68
0.21
5.3
7.8
张量核心
TFLOP/s①
NA
NA
NA
125
纹理单元
240
192
224
320
显存接口
384位 GDDR5
384位GDDR5
4096位HBM2
4096位 HBM2
内存大小
最大12GB
最大24GB
16GB
16GB
L2缓存大小
1536KB
3072KB
4096KB
6144KB
共享内
存/SM（KB）
16、32和48
96
64
最高可配置为
96
寄存器文
件/SM
256KB
256KB
256KB
256KB
寄存器文
件/GPU
3840KB
6144KB
14336KB
20480KB
TDP
235W
250W
300W
300W
晶体管数量
7.1×109
8×109
1.53×1010
2.11×1010
芯片面积
551mm²
601mm²
610mm²
815mm²
生产工艺
28nm
28nm
16nm FinFET+
12nm FFN
① 这里都是GPU跳频（boost）后的峰值数据。
与CPU相比，GPU的关键优势是多核和并行能力。如何不断增加并
行能力，保持领先呢？开普勒微架构大胆尝试了在一个SM中增加
CUDA核心的个数，但是这样做功耗高、难以保证所有核的利用率而且
影响产品的良率。于是从麦斯威尔微架构开始，每个SM中CUDA核心
的数量又减少了，从192个减少到128个，并且分成4个片区，每个片区
有调度器，精细化管理，目的是提高效率。帕斯卡微架构进一步把每个
SM中CUDA核心的数量减少到64个，伏特微架构沿用了这个数量，看
来每个SM中配置64个CUDA核心是经过几番波动后得出的最佳值。降
低了每个SM中CUDA核心的数量后，要提高并行度就要增加SM的个
数。从表9-2中可以看到，SM的数量在不断上升。保持SM的紧凑和高
效，通过SM的个数来实现伸缩性，看起来这是Nvidia目前的策略。
除了SM方面的规律外，从表9-2中，还可以看到如下一些明显的趋
势：生产工艺不断精细化，晶体管密度越来越高；晶体管的总数单调上
升，GV100达到惊人的2.11×1010亿个；总的CUDA核心数和并行能力不
断上升。
9.3 硬件指令集
对于使用通用处理器思想设计的GPU来说，它的指令集代表着软硬
件之间最根本的接口，其重要性不言而喻。但遗憾的是，Nvidia并没有
公开详细的指令集文档。我们只能通过非常有限的资料介绍指令集的部
分信息。
9.3.1 SASS
Nvidia把GPU硬件指令对应的汇编语言称为SASS。关于SASS的全
称，官方文档不见其踪影。有人说它是Streaming ASSembler（流式汇编
器）的缩写[10]，也有人说它是Shader Assembler的缩写，作者觉得前者
可能更接近。
可以使用CUDA开发包中的cuobjdump来查看SASS汇编，比如执行
如下命令可以把嵌在vectorAdd.exe中的GPU代码进行反汇编，然后以文
本的形式输出出来。
cuobjdump --dump-sass win64\debug\vectorAdd.exe
在使用CUDA GDB调试时，可以直接使用GDB的反汇编命令来查