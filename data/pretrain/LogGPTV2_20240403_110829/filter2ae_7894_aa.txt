## 前言
前段时间打的SUCTF2019中有一个题目叫Pythongin思路大概来源于黑帽大会
不怎么明白漏洞的原理，就准备复现一下，在复现的过程中出现了很多坑，来记录一下。
## 踩坑过程
整个SUCTF2019的源码都已经开源了，地址如下
具体题目的分析过程就不再赘述了，感觉师傅们分析的一个比一个详细,我在文末也放了几个师傅的分析的writeup
搭建好docker的环境，直接按照文档中的命令可以直接复现成功
    docker build -t dockerflask .
    docker run -p 3000:80 dockerflask
    open http://localhost:3000
然后按照题目的payload可以直接复现成功
然而问题来了，我比较懒，我是直接把文件放到了我的sublime 然后，使用一个官方的payload
居然没有打成功怀疑是我的环境和编辑器的编码出现了问题，然后放到我的WSL系统里面运行（这里说一句题外话，最近刚刚给自己的电脑安装了WSL
win下的ubuntu，感觉很好用 ，想用linux的时候不必再去开虚拟机了）大家可以去尝试一下，同时也顺便美化一下自己的终端。
再win下的环境是
在linux下的环境是
    /mnt/d/CTF/SUCTF  python3
    Python 3.6.8 (default, Jan 14 2019, 11:02:34)
    [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
    Type "help", "copyright", "credits" or "license" for more information.
    >>>
在win下的环境是
    C:\Users\11466>python3
    Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 22:22:05) [MSC v.1916 64 bit (AMD64)] on win32
    Type "help", "copyright", "credits" or "license" for more information.
    >>>
可以看版本不一样，同时python最后更新的时间也不一样问题就出现在这里了。
对源码做出的简单的修改，用来测试payload
    def getUrl2(url):
        host = parse.urlparse(url).hostname
        if host == 'suctf.cc':
            return "我扌 your problem? 111"
        parts = list(urlsplit(url))
        host = parts[1]
        if host == 'suctf.cc':
            return "我扌 your problem? 222 " + host
        newhost = []
        for h in host.split('.'):
            newhost.append(h.encode('idna').decode('utf-8'))
        parts[1] = '.'.join(newhost)
        #去掉 url 中的空格
        finalUrl = urlunsplit(parts).split(' ')[0]
        host = parse.urlparse(finalUrl).hostname
        if host == 'suctf.cc':
            return "success"
        else:
            return "我扌 your problem? 333"
    if __name__=="__main__":
        # get_unicode()
        # try:
        #     print_unicode()
        # except:
        #     print("something_error")
        url = "file://suctf.c℆sr%2ffffffflag @111"
        print(url)
        print(getUrl2(url))
        # print(getUrl(url))
        # get_unicode()
可以出运行不同的结果：
在win下
    file://suctf.c℆sr%2ffffffflag @111
    Traceback (most recent call last):
      File "1.py", line 72, in 
        print(getUrl2(url))
      File "1.py", line 45, in getUrl2
        host = parse.urlparse(url).hostname
      File "E:\python3\lib\urllib\parse.py", line 368, in urlparse
        splitresult = urlsplit(url, scheme, allow_fragments)
      File "E:\python3\lib\urllib\parse.py", line 461, in urlsplit
        _checknetloc(netloc)
      File "E:\python3\lib\urllib\parse.py", line 407, in _checknetloc
        "characters under NFKC normalization")
    ValueError: netloc 'suctf.cc/usr%2ffffffflag @111' contains invalid characters under NFKC normalization
在WSL下
    /mnt/d/CTF/NUCA  python3 1.py
    file://suctf.c℆sr%2ffffffflag @111
    success
原来没怎么分析过python的源码
但是从报错信息上可以找到，问题就出现在`python3\lib\urllib\parse.py`
于是就来简单分析了下parse.py的源码
## 源码对比
在win下是比较新的一个python，很明显对于这类漏洞已经修补
在WSL下的是一个比较就得python
使用在win下找到`E:\python3\lib\urllib\parse.py`
在WSL下找到 `/usr/lib/python3.6/urllib/parse.py`
    /mnt/d/CTF/SUCTF  python3
    Python 3.6.8 (default, Jan 14 2019, 11:02:34)
    [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
    Type "help", "copyright", "credits" or "license" for more information.
    >>> import sys
    >>> sys.path
    ['', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/fangzhang/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages']
    >>>
     /mnt/d/CTF/SUCTF cd /usr/lib/python3.6/urllib/
     /usr/lib/python3.6/urllib
使用文本对比工具
得到一下结果：
    --- E:\python3\Lib\urllib\parse.py
    +++ /usr/lib/python3.6/urllib 
    @@ -390,21 +390,6 @@
             if wdelim >= 0:                    # if found
                 delim = min(delim, wdelim)     # use earliest delim position
         return url[start:delim], url[delim:]   # return (domain, rest)
    -    -def _checknetloc(netloc):
    -    if not netloc or netloc.isascii():
    -        return
    -    # looking for characters like \u2100 that expand to 'a/c'
    -    # IDNA uses NFKC equivalence, so normalize for this check
    -    import unicodedata
    -    netloc2 = unicodedata.normalize('NFKC', netloc)
    -    if netloc == netloc2:
    -        return
    -    _, _, netloc = netloc.rpartition('@') # anything to the left of '@' is okay
    -    for c in '/?#@:':
    -        if c in netloc2:
    -            raise ValueError("netloc '" + netloc2 + "' contains invalid " +
    -                             "characters under NFKC normalization")
     def urlsplit(url, scheme='', allow_fragments=True):
         """Parse a URL into 5 components:
    @@ -424,6 +409,7 @@
         i = url.find(':')
         if i > 0:
             if url[:i] == 'http': # optimize the common case
    +            scheme = url[:i].lower()
                 url = url[i+1:]
                 if url[:2] == '//':
                     netloc, url = _splitnetloc(url, 2)
    @@ -434,8 +420,7 @@
                     url, fragment = url.split('#', 1)
                 if '?' in url:
                     url, query = url.split('?', 1)
    -            _checknetloc(netloc)
    -            v = SplitResult('http', netloc, url, query, fragment)
    +            v = SplitResult(scheme, netloc, url, query, fragment)
                 _parse_cache[key] = v
                 return _coerce_result(v)
             for c in url[:i]:
    @@ -458,7 +443,6 @@
             url, fragment = url.split('#', 1)
         if '?' in url:
             url, query = url.split('?', 1)
    -    _checknetloc(netloc)
         v = SplitResult(scheme, netloc, url, query, fragment)
         _parse_cache[key] = v
         return _coerce_result(v)
    @@ -600,7 +584,7 @@
         # if the function is never called
         global _hextobyte
         if _hextobyte is None:
    -        _hextobyte = {(a + b).encode(): bytes.fromhex(a + b)
    +        _hextobyte = {(a + b).encode(): bytes([int(a + b, 16)])
                           for a in _hexdig for b in _hexdig}
         for item in bits[1:]:
             try:
    @@ -750,7 +734,7 @@
     _ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
                              b'abcdefghijklmnopqrstuvwxyz'
                              b'0123456789'
    -                         b'_.-~')
    +                         b'_.-')