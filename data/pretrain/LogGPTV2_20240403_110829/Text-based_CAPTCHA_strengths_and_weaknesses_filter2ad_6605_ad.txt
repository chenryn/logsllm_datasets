% success0%10%20%30%40%50%60%70%80%90%Trainning set size102050100200500Authorize Baidu BlizzardCaptcha.net CNN Digg eBay Megaupload NIH Reddit Skyrock Slashdot Wikipedia 134Figure 15: Decaptcha pipeline
Overall, although we tried to use existing libraries as much as pos-
sible we ended up writing roughly 80% of Decaptcha code, which
took us at least a year of development. For example, we rewrote a
KNN algorithm [12] because we needed a conﬁdence metric and
we rewrote various distance algorithms to maximize the speed on
binary vectors. Note that Decaptcha in its current version is able to
work on audio and image captchas.
7.1 Decaptcha pipeline
Decaptcha uses the ﬁve stage pipeline illustrated in ﬁgure 15.
These stages are:
1. Preprocessing: In this ﬁrst stage, the captcha’s background is
removed using several algorithms and the captcha is binarized
(represented in black and white) and stored in a matrix of
binary values. Transforming the captcha into a binary matrix
makes the rest of the pipeline easier to implement, as the
remaining algorithm works on a well-deﬁned abstract object.
The downside of using a binary representation is that we lose
the pixel intensity. However in practice this was never an
issue.
2. Segmentation: In this stage Decaptcha attempts to segment
the captchas using various segmentation techniques, the most
common being CFS [32] (Color Filling Segmentation) which
uses a paint bucket ﬂood ﬁlling algorithm [28]. This is the de-
fault segmentation technique because it allows us to segment
the captcha letters even if they are tilted, as long as they are
not contiguous.
3. Post-Segmentation: At this stage the segments are processed
individually to make the recognition easier. During this phase
the segments’ sizes are always normalized.
4. Recognition: In training mode, this stage is used to teach the
classiﬁer what each letter looks like after the captcha has been
segmented. In testing mode, the classiﬁer is used in predictive
mode to recognize each character.
5. Post-processing: During this stage the classiﬁer’s output is
improved when possible. For example, spell checking is
performed on the classiﬁer’s output for Slashdot because we
know that this captcha scheme uses dictionary words. Using
spellchecking allows us to increase our precision on Slashdot
from 24% to 35% .
7.2 Design principles to write a captcha solver
Before writing the full blown version of Decaptcha in C#, we
wrote a prototype in Ruby two years ago. Building this prototype
allowed us to learn a couple of key principles that need to be applied
to create a sucessful evaluation framework.
Here is the list of the four main design principles speciﬁc to
captcha breaking that made the current Decaptcha implementation
(Figure 16) an effective attack framework:
1. Aiming for generality: Decaptcha development was focused
on algorithm generality and simplicity rather than accuracy
optimization. We made this choice very early as we believed
that on the long run it will yield better results. The fact that
we were able to break the last three schemes evaluated in this
paper, namely CNN, Megaupload and Reddit, in less than 3
hours without writing a new algorithm support this hypothesis.
Overall we believe that this focus on generality and simplicity
is what makes Decaptcha truly different from the previous
add-hoc designed to break a single scheme.
2. Immediate visual feedback: When trying to break a captcha
scheme most of the time is spend on trying and tweaking
various algorithms, so it is essential to have quick feedback
on how the change affected the attack’s performance. We
discovered that it is far more effective to provide this feedback
in a pie chart form with a deﬁned color code than use a table
with raw numbers. As visible in ﬁgure 16 in Decaptcha the
pie chart is in the center of the interface, which allows us
to immediately see how efﬁcient the current pipeline is. For
example, in the screenshot it is very easy to see that in this
tryout we have an overall success of 66% (green) on Blizzard
captchas, that 5% of the failures occur at the recognition
stage (yellow), 18% - at the segmentation stage (orange) and
11% - at the pre-processing stage (red).
3. Visual debugging: Similarly, we discovered that the only
way to understand quickly how an algorithm is behaving is to
look at how it affects and interacts with the captchas. That is
why the ability to view the visual pipeline for a given captcha
sample with a simple click is essential. In Decaptcha we
implemented this principle by allowing the user to display a
given captcha pipeline stage on the right side of the interface
by clicking on a captcha from the list located in the middle
of the interface. For example, in the example of ﬁgure 16,
we selected a captcha that failed the segmentation stage and
the fact that the failure occurs at the segmentation is clear by
looking at the pipeline states. It also makes it very easy to
understand that this segmentation failure is due to an error
of our anti-pattern algorithm, which removed most of the
background pattern except a few pixels at the bottom right,
due to the similarity of their color to the text color.
Pre-processingSegmentationPost-segmentationRecognitionPost-processingImage MatrixSegments matricesSegments matricesPotential answerFinal answerCaptchak356fsk356fsPipelineExample135Figure 16: Decaptcha interface
4. Algorithm independence: Finding the optimal set of al-
gorithms to break a given scheme is not trivial and often
we ended up swapping one algorithm for another either be-
cause we found a better-performing algorithm or because we
changed the approach. For example, for de-noising a captcha
we moved from using an anti-pattern algorithm to a Markov
Random Field algorithm [14]. Being able to combine algo-
rithms as “lego bricks” without worrying about side effects
is one of the keys to Decaptcha ’s success. Having a ﬂexible
pipeline is achieved by abstracting the image representation
as a matrix and ensuring that every algorithm has no side
effects. This design also allows us to parallelize pipeline ex-
ecutions which is important because image processing and
machine learning algorithms are usually slow. The algorithm
independence principle is also what allows Decaptcha to work
on image and audio captchas indistinctly.
5. Exposing algorithm attributes: Being able to change al-
gorithm parameters such as a threshold without editing and
recompiling the code makes a huge difference. Oftentimes,
by tweaking parameters we were able to gain up to 40%
in accuracy or segmentation efﬁciency. We tried to ﬁnd a
way to automatically optimize parameters but it turned out
that modifying the parameters in one algorithm in isolation
is not effective, as changing the behavior of one algorithm
often requires re-adjusting parameters of algorithms used later
in the pipeline. For example, being more aggressive when
de-noising will force us to be more aggressive when recon-
structing the captcha’s characters afterward.
8. FURTHER RELEVANT WORK
In this section we summarize the related work cited in the paper
and discuss further relevant work.
Captcha. In [10] the authors propose using machine learning classi-
ﬁers to attacks captchas. In [7] the same authors study how efﬁcient
statistical classiﬁer are at recognizing captcha letters. In [5] the
authors study how good humans are at solving well-known captchas
using Mechanical Turk.
In [15] the authors were able to break the Microsoft ASIRRA
captcha using SVM. In [32] the authors were able to break the old
Microsoft captcha using the two phase approach. In [30] the author
proposes using the erode and dilate ﬁlter to segment captchas. [31]
is one of the ﬁrst papers to propose the use of histogram-based
segmentation against captchas.
Recognition algorithm. The perceptron, the simplest neural net-
work, has been used as a linear classiﬁer since 1957 [27]. The
convolutive neural networks which are considered to be the most
efﬁcient neural network to recognize letters were introduced in [20].
The space displacement neural network that attempts to recognize
digits without segmentation was introduced in [24]. The support
vector machines were introduced in [11]. The KNN algorithm is
described in detail in [12]. The use of a bag of features to recognize
objects in images is a very active ﬁeld. The closest work to ours in
this area is by [22], where the authors try to segment and categorize
objects using this approach.
Machine vision algorithms. Detecting and removing lines is a well
studied ﬁeld in computer vision since the ’70s. Two well-known and
efﬁcient algorithms that can be used against captchas with lines are
the Canny detection [6] and the Hough Transform [13]. Removing
noise using a Markov Random Field (Gibbs) was introduced in [14].
Many image descriptors have been proposed over the last decades:
one of the ﬁrst and most used descriptors is the the Harris Corner
detector [16] introduced in 1988. However, recently it has been
replaced by more complex descriptors that are insensitive to scale
and rotation (to a certain extent). Of these, the two most notable and
promising for dealing with captchas are SIFT [23] and SURF [1].
9. CONCLUSION
As a contribution toward improving the systematic evaluation and
design of visual captchas, we evaluated various automated methods
on real world captchas and synthetic one generated by varying
signiﬁcant features in ranges potentially acceptable to human users.
We evaluated state-of-the-art anti-segmentation techniques, state-of-
the-art anti-recognition techniques, and captchas used by the most
popular websites.
136We tested the efﬁciency of our tool Decaptcha against real captchas
from Authorize, Baidu, Blizzard, Captcha.net, CNN, Digg, eBay,
Google, Megaupload, NIH, Recaptcha, Reddit, Skyrock, Slashdot,
and Wikipedia. On these 15 captchas, we had 1%-10% success rate
on two (Baidu, Skyrock), 10-24% on two (CNN, Digg), 25-49%
on four (eBay, Reddit, Slashdot, Wikipedia), and 50% or greater
on ﬁve (Authorize, Blizzard, Captcha.net, Megaupload, NIH). To
achieve such a high success rate we developed the ﬁrst successful
attacks on captchas that use collapsed characters (eBay and Baidu).
Only Google and Recaptcha resisted to our attack attempts, and we
reached some informative understanding of why we couldn’t break
them. Because of Decaptcha genericity we were able to break 7 of
these 15 schemes without writing a new algorithm. Overall, our
analysis led to a series of recommendations for captcha designers,
including recommendations to use some anti-segmentation tech-
niques, and recommendations not to use features that are ineffective
against automated attacks but counterproductive for humans.
Acknowledgment
We thank Markus Jakobsson, Dave Jackson, Aleksandra Korolova
and our anonymous reviewers for their comments and suggestions.
This work was partially supported by the National Science Founda-
tion, the Air Force Ofﬁce of Scientiﬁc Research, and the Ofﬁce of
Naval Research.
10. REFERENCES
[1] H. Bay, T. Tuytelaars, and L. Van Gool. Surf: Speeded up
robust features. Computer Vision–ECCV 2006, pages
404–417, 2006.
[2] E. Bursztein and S. Bethard. Decaptcha: breaking 75% of
eBay audio CAPTCHAs. In Proceedings of the 3rd USENIX
conference on Offensive technologies, page 8. USENIX
Association, 2009.
[3] E. Bursztein, S. Bethard, Fabry C., Dan Jurafsky, and John C.
Mitchell. Design parameters and human-solvability of
text-based captchas. To appears.
[4] Elie Bursztein, Romain Bauxis, Hristo Paskov, Daniele Perito,
Celine Fabry, and John C. Mitchell. The failure of noise-based
non-continuous audio captchas. In Security and Privacy, 2011.
[5] Elie Bursztein, Steven Bethard, John C. Mitchell, Dan
Jurafsky, and Celine Fabry. How good are humans at solving
captchas? a large scale evaluation. In Security and Privacy,
2010.
[6] J. Canny. A computational approach to edge detection.
Readings in computer vision: issues, problems, principles,
and paradigms, 184:87–116, 1987.
[7] K. Chellapilla, K. Larson, P.Y. Simard, and M. Czerwinski.
Computers beat humans at single character recognition in
reading based human interaction proofs (hips). In CEAS, 2005.
[8] K Chellapilla and P Simard. Using machine learning to break
visual human interaction proofs. In MIT Press, editor, Neural
Information Processing Systems (NIPS), 2004.
[9] K. Chellapilla and P. Simard. Using machine learning to break
visual human interaction proofs (HIPs). Advances in Neural
Information Processing Systems, 17, 2004.
[10] K. Chellapilla and P.Y. Simard. Using machine learning to
break visual hips. In Conf. on Neural Information Processing
Systems, NIPS 2004, 2004.
[11] C. Cortes and V. Vapnik. Support-vector networks. Machine
learning, 20(3):273–297, 1995.
[12] B.V. Dasarathy. Nearest Neighbor ({NN}) Norms:{NN}
Pattern Classiﬁcation Techniques. 1991.
[13] R.O. Duda and P.E. Hart. Use of the Hough transformation to
detect lines and curves in pictures. Communications of the
ACM, 15(1):11–15, 1972.
[14] S. Geman and D. Geman. Stochastic relaxation, Gibbs
distributions and the Bayesian restoration of images*. Journal
of Applied Statistics, 20(5):25–62, 1993.
[15] P. Golle. Machine learning attacks against the asirra captcha.
In ACM CCS 2008, 2008.
[16] C. Harris and M. Stephens. A combined corner and edge
detector. In Alvey vision conference, volume 15, page 50.
Manchester, UK, 1988.
[17] S.Y. Huang, Y.K. Lee, G. Bell, and Z. Ou. A projection-based
segmentation algorithm for breaking MSN and YAHOO
CAPTCHAs. In Proceedings of the World Congress on
Engineering, volume 1. Citeseer, 2008.
[18] P Simard K Chellapilla, K Larson and M Czerwinski.
Building segmentation based human- friendly human
interaction proofs. In Springer-Verlag, editor, 2nd Int’l
Workshop on Human Interaction Proofs, 2005.
[19] Andrew Kirillov. aforge framework.
http://www.aforgenet.com/framework/.
[20] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner.
Gradient-based learning applied to document recognition.
Proceedings of the IEEE, 86(11):2278–2324, 1998.
[21] Yann Lecun. The mnist database of handwritten digits
algorithm results.
http://yann.lecun.com/exdb/mnist/.
[22] B. Leibe, A. Leonardis, and B. Schiele. Robust object
detection with interleaved categorization and segmentation.
International Journal of Computer Vision, 77(1):259–289,
2008.
[23] D.G. Lowe. Object recognition from local scale-invariant
features. In iccv, page 1150. Published by the IEEE Computer
Society, 1999.
[24] O. Matan, C.J.C. Burges, and J.S. Denker. Multi-digit
recognition using a space displacement neural network.
Advances in Neural Information Processing Systems, pages
488–488, 1993.
[25] Moni Naor. Veriﬁcation of a human in the loop or
identiﬁcation via the turing test. Available electronically:
http://www.wisdom.weizmann.ac.il/~naor/
PAPERS/human.ps, 1997.
[26] R. Quinlan. Machine Learning. Morgan Kaufmann Pub.
[27] F. Rosenblatt. The perceptron: a perceiving and recognizing
automation (projet PARA), Cornell Aeronautical Laboratory
Report. 1957.
[28] Wikipedia. Flood ﬁll algorithm.
http://en.wikipedia.org/wiki/Flood_fill.
[29] Wikipedia. Hsl and hsv color representaiton.
http://en.wikipedia.org/wiki/HSL_and_HSV.
[30] J. Wilkins. Strong captcha guidelines v1. 2. Retrieved Nov,
10:2010, 2009.
[31] J. Yan and A.S.E. Ahmad. Breaking visual captchas with
naive pattern recognition algorithms. In ACSAC 2007, 2007.
[32] J. Yan and A.S. El Ahmad. A Low-cost Attack on a Microsoft
CAPTCHA. In Proceedings of the 15th ACM conference on
Computer and communications security, pages 543–554.
ACM, 2008.
137