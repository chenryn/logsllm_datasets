100
1
10
100
no rollback
protection
3.85 (± 0.06)
4.65 (± 0.05)
6.49 (± 0.04)
0.06 (± 0.00)
0.19 (± 0.00)
1.76 (± 0.05)
SGX counter
protection
160.7 (± 0.7)
162.7 (± 1.6)
169.1 (± 2.1)
61.04 (± 3.1)
61.17 (± 3.1)
62.74 (± 3.2)
Table 1: Example application throughput without roll-
back protection, using ROTE and using SGX counters.
5.17 (± 0.03)
6.03 (± 0.03)
7.83 (± 0.05)
1.41 (± 0.02)
1.53 (± 0.01)
3.1 (± 0.02)
delay, due to the dependency on network connections
between various geographic locations in the protection
group. The update time between two locations takes 654
ms while between ﬁve the update time is 1.37 seconds.
The read delay is respectively 342 ms and 810 ms.
We draw two conclusions from these experiments.
First, the performance overhead imposed by ROTE is
deﬁned largely by the network connections between the
nodes. Second, if the nodes are connected over a low-
delay network, ROTE supports applications requiring
very fast state updates (1-2 ms). For applications toler-
ating larger delays (e.g., more than 600 ms per state up-
date), ROTE can be run on geographically distant groups.
6.2 Example Application Throughput
Additionally, we measured the throughput of an ex-
ample ﬁnancial enclave that processes incoming transac-
tions repeatedly (the transaction buffer is never empty).
We tested the enclave using (a) no rollback protection,
(b) the ROTE implementation, and (c) SGX counter
based rollback protection. The experimental setup was
a protection group of four nodes. For every update trans-
action, the enclave updates its state, creates a new seal,
and writes it to the disk, while the read transaction in-
cludes reading from the disk, unsealing and retrieving
the counter for comparison. In case of ROTE and SGX
counter variants, the enclave also performs a counter in-
crement. We tested three different enclave state sizes (1
KB, 10 KB, 100 KB) since the state size for transactions
can differ based on the exact use case.
USENIX Association
26th USENIX Security Symposium    1301
234Numberofnodesinthegroup1.01.21.41.61.82.02.22.42.6Time(ms)ResponseTimeUpdateResponseTimeRead2468101214161820Numberofnodesinthegroup0.60.81.01.21.41.61.82.02.22.42.62.83.03.2Time(ms)ResponseTimeUpdateResponseTimeRead23456Numberofnodesinthegroup200400600800100012001400Time(ms)ResponseTimeUpdateResponseTimeReadResults. Table 1 shows our results. In all three cases
the ROTE system provides signiﬁcantly better state up-
date performance than using SGX counters (e.g., 190
over 6 tx/s for 1KB) while suffering a 20-25% perfor-
mance drop in comparison to systems which have no
rollback protection (e.g., 260 over 190 tx/s for 1KB).
We conclude that our system provides signiﬁcantly faster
rollback protection than methods based on local non-
volatile memory. Compared to systems with no rollback
protection, our solution imposes a moderate overhead.
7 Discussion
Data migration. Although sealing binds encrypted
enclave data to a speciﬁc processor, our solution enables
data migration within the protection group. Migration is
especially useful before planned hardware replacements
and group updates (e.g., node removal).
In a migra-
tion operation, an ASE ﬁrst unseals its persistent data
and passes it to the RE. The RE sends the enclave data
to another Rollback Enclave within the same protection
group together with the measurement of the ASE. The
communication channel between the REs is encrypted
and authenticated. On the receiving processor, the RE
passes the enclave data to an instance of the same ASE
(based on attestation using the received measurement)
which can seal it. Note that the RE is agnostic to the in-
ternal state of ASEs and just re-encrypts data it receives
from an ASE without the need to understand its seman-
tics. Combined with group updates (Section 4.7), such
enclave data migration enables ﬂexible management of
available computing resources. Similar data migration is
discussed in [25].
Information leakage. Our model excludes execution
side-channels. Here we brieﬂy discuss additional infor-
mation leakage that our solution may add. Each enclave
state update and read causes network communication.
An adversary that can observe the network, but does not
have access to the local persistent storage, can use the in-
formation leakage to determine the timing of sealing and
unsealing events. Also the reboot of the target platform
causes an observable network pattern. We consider such
information leakage a practical concern but developing
countermeasures is outside the scope of this paper.
Performance. The main performance characteristic
of our solution, the state update delay, is dominated by
the networking and the asymmetric signature operation
required for the ﬁrst message of the state update proto-
col. In case of a local, 1Gpbs, network and an average
laptop, the networking takes approximately 1 ms and the
signature operation 0.5 ms. A possible optimization is to
pre-compute the asymmetric signatures. Since the signed
data is predictable MC values, we can pre-compute and
store them. This pre-computation may be done at times
when the expected load is low or at system initialization
depending on the speciﬁc scenario.
For communication between the enclaves we use sym-
metric keys derived from the key agreement protocol for
performance reasons, since it is computationally much
less expensive. However, depending on the application
scenario we could use asymmetric keys which would en-
able, for example, post-incident forensics. This design
choice is dependent on the use case and performance re-
quirements. ROTE can accommodate both approaches.
Consensus applications. In the speciﬁc case where
all participating enclaves implement a distributed appli-
cation with the purpose to maintain a consensus (e.g.,
permissioned blockchain), our rollback protection can be
optimized further. In such an application, all participat-
ing enclaves have a shared, global state and the state up-
date protocol can be replaced with a suitable Byzantine
agreement protocol. When an enclave is restarted (or de-
termines its latest state), it queries its latest state from the
participating enclaves similar to our RE restart protocol.
We leave a detailed design as future work.
Forking prevention. The current SGX architecture
does not provide the ability for one enclave instance to
check if another instance of the same enclave is already
running. The implementation of this feature would sim-
plify rollback protection signiﬁcantly.
Forking prevention could be implemented using a
TPM. After system boot, the RE instance could extend
a PCR that has a known value at boot. If a second RE
instance is started, it can check if the PCR value differs
from its known initial value [2]. The drawback of this
approach is the increase of the system security perimeter
outside of the processor.
Periodic check-pointing. For increased robustness,
our rollback protection can be complemented with peri-
odic check-pointing. An example approach would be to
increment a counter on local NVRAM on selected up-
dates (e.g., mod 100). If all nodes crash at the same time,
the administrator has an option to recover from the latest
saved checkpoint with the risk of possible rollback.
8 Related work
SGX-counter and TPM solutions. Ariadne [2] uses
TPM NVRAM or SGX counters for enclave rollback
protection. The counter is incremented using store-then-
inc that provides crash resilience, but allows two execu-
tions of the latest input. Ariadne minimizes the TPM
NVRAM wear using counter increments that ﬂip only a
single bit. Compared to our solution, SGX counters are
an optional feature, increments are slow and make the
non-volatile memory unusable after few days of contin-
uous use. Similar performance limitations apply to TPM
NVRAM. SGX counters are also likely vulnerable to bus
tapping and ﬂash mirroring attacks [22], while in our so-
lution the trust perimeter is the processor package.
1302    26th USENIX Security Symposium
USENIX Association
Memoir [4] also leverages TPM NVRAM for rollback
protection, and therefore has similar performance limi-
tations. An optimized variant of Memoir assumes the
availability of an Uninterrupted Power Supply (UPS).
This variant stores the state updates to volatile Platform
Conﬁguration Registers (PCRs) and at system shutdown
writes the recorded update history to the NVRAM. ICE
[3] enhances the CPU with protected volatile memory, a
power supply and a capacitor that at system shutdown the
ﬂushes the latest state to non-volatile memory. Both the
optimized Memoir and ICE require hardware changes.
Additionally, reliably ﬂushing data upon a crash or power
outage can be challenging in practice.
Client-side detection. Brandenburger [26] proposes
client-side rollback detection for SGX in the context of
cloud computing. The main difference to our work is
that this approach does not prevent a rollback directly on
the server. Instead, it allows mutually trusting clients to
remain synchronized, and given that certain connectivity
requirements are met, detect consistency and integrity vi-
olations (including rollback) after the incident.
Integrity servers. Verena [6] maintains authenti-
cated data structures for web applications and stores in-
tegrity information on a separate, trusted server. Another
use case is to prevent the usage of disabled credentials
on mobile devices by storing counters on an integrity-
protected server [8]. In such solutions the integrity server
becomes a single point of failure.
Byzantine broadcast and agreement. Our state up-
date protocol follows the approach of Echo broadcast
[15] with an additional conﬁrmation message in the
end. Like other byzantine broadcast primitives, our
state update protocol requires O(n) messages. Byzantine
agreement typically require O(n2) messages. Byzantine
broadcast and agreement protocol operate on arbitrary
values and assume a potentially malicious sender. Thus,
such protocols require 3 f + 1 replicas.
In our system
the target enclave is trusted and the distributed data is a
signed counter value. Thus, f + 1 replicas are sufﬁcient.
Secure audit logs. Secure audit log systems [27, 28,
29, 30] provide accountability and in particular prevent
manipulation of previous log entries after the target plat-
form becomes compromised. Most such audit log sys-
tems assume a trusted but infrequently accessible stor-
age. Our goal is to design a system that has no single
point of failure, and therefore in ROTE the trusted stor-
age is realized as a distributed system amongst a set of
assisting nodes (some of which can be compromised).
Accountability for distributed systems. PeerReview
[31] provides accountability for distributed systems and
in particular detect nodes that violate from expected be-
haviour. Instead of fault detection, our goal is to realize
distributed secure storage, customized for rollback pro-
tection, in the presence of faulty nodes.
Adversary models. Agreement has been considered
under models where the faulty nodes have some trusted
functionality (e.g., an unmodiﬁable hardware primitive).
Such approaches reduce the number of required replicas
to 2 f + 1 [32, 33, 34, 35] or f + 1 [36]. We have no
trust assumptions on the compromised nodes. Byzan-
tine agreement has also been considered with dual failure
models [37, 38, 39] where the adversary can fully con-
trol the faulty processes and can read the secrets of other
processes. In our case, the adversary cannot read secrets
from trusted enclaves, but it can extract keys from f com-
promised nodes, and additionally schedule enclaves’ ex-
ecution on all nodes.
Several recently proposed SGX systems [40, 41, 42,
13, 43, 44, 45, 46] consider an adversary model with an
untrusted OS. To the best of our knowledge, our work is
the ﬁrst to deﬁne a model with explicit adversarial capa-
bilities that cover enclave restarts and multiple instances.
These capabilities are critical for the security of our sys-
tem and also other SGX systems (see the extended ver-
sion of this paper for details [20]).
9 Conclusion
In this paper we have proposed a new approach for
rollback protection on Intel SGX. Our main idea is to
implement integrity protection as a distributed system
across collaborative enclaves running on separate pro-
cessors. We consider a powerful adversary that controls
the OS on all participating platforms and has even com-
promised a subset of the assisting processors. We show
that our system provides a strong security guarantee that
we call all-or-nothing rollback. Our experiments demon-
strate that distributed rollback protection provides signif-
icantly better performance compared to solutions based
on local non-volatile memory.
Acknowledgements
This work was partly supported by the TREDISEC
project (G.A. no 644412), funded by the European Union
(EU) under the Information and Communication Tech-
nologies (ICT) theme of the Horizon 2020 (H2020) re-
search and innovation programme. We would like to
thank Jonathan McCune for his insightful comments.
References
[1] V. Costan et al., “Intel SGX explained,” in Cryptology ePrint
Archive, 2016.
[2] R. Strackx et al., “Ariadne: A minimal approach to state continu-
ity,” in USENIX Security, 2016.
[3] ——, “ICE: A passive, high-speed, state-continuity scheme,” in
ACSAC, 2014.
[4] B. Parno et al., “Memoir: Practical state continuity for protected
modules,” in IEEE S&P, 2011.
[5] Intel, “SGX documentation:
2016, https://software.intel.com/en-us/node/696638.
sgx create monotonic counter,”
USENIX Association
26th USENIX Security Symposium    1303
[6] N. Karapanos et al., “Verena: End-to-End Integrity Protection for
Web Applications,” in IEEE S&P, 2016.
[7] M. van Dijk et al., “Ofﬂine Untrusted Storage with Immediate
Detection of Forking and Replay Attacks,” in ACM STC, 2007.
[8] K. Kostiainen et al., “Credential Disabling from Trusted Execu-
tion Environments,” in Nordsec, 2010.
[9] M. Castro et al., “Practical Byzantine fault tolerance,” in OSDI,
1999.
[10] D. Dolev et al., “On the security of public key protocols,” IEEE
Transactions on information theory, 1983.
[11] M. Pease et al., “Reaching agreement in the presence of faults,”
Journal of the ACM, 1980.
[12] L. Lamport et al., “The Byzantine Generals Problem,” ACM
TOPLAS, 1982.
[13] M.-W. Shih et al., “S-NFV: Securing NFV states by using SGX,”
in ACM SDN-NFV, 2016.
[14] F. Schuster et al., “VC3: trustworthy Data Analytics in the Cloud
Using SGX,” in IEEE S&P, 2015.
[15] M. K. Reiter, “Secure agreement protocols: Reliable and atomic
group multicast in Rampart,” in ACM CCS, 1994.
[16] C. Cachin et al., Introduction to reliable and secure distributed
programming. Springer, 2011.
[17] Y. Xu et al., “Controlled-Channel Attacks: Deterministic Side
Channels for Untrusted Operating Systems,” in IEEE S&P, 2015.
[18] F. Brasser et al., “Software Grand Exposure: SGX Cache Attacks
are Practical,” 2017, http://arxiv.org/abs/1702.07521.
[19] M. Schwarz et al., “Malware Guard Extension: Using SGX to
Conceal Cache Attacks,” 2017, http://arxiv.org/abs/1702.08719.
[20] S. Matetic et al., “Rote: Rollback protection for trusted execu-
tion,” 2017, https://eprint.iacr.org/2017/048.
[21] Intel Support Forum,
of Enclave,”
intel-software-guard-extensions-intel-sgx/topic/709552.
2017,
“Ensuring only a single instance
https://software.intel.com/en-us/forums/
[22] S. Skorobogatov, “The bumpy road towards iPhone 5c NAND
mirroring,” 2016, http://arxiv.org/abs/1609.04327.
[23] Trusted Computing Group, “Trusted Platform Module Library,
Part 1: Architecture, Family 2.0,” 2014.
[24] Intel, “SGX documentation: sgx get trusted time,” 2016, https: