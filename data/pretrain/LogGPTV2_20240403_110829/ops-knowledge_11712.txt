User: I'm working on a project that uses Django and mongoengine. When a user presses a button, a trigger to a call_command (django.core.management - just calls a script it seems to me) is made which sshs to multiple servers in parallel, copies some files, parses them and stores them in the database.
The problem is that when the button is pressed and the above process is running, if any other user tries to use the website, it doesn't load.
Is this because of mongo's lock? This happens as soon as the button is pressed (so when the connections to other servers are still made, not yet writing to the DB) so I was thinking that it's not a mongo issue.
So is it a Django issue calling the command synchronously? Do I need to use Celery for this task?
Assistant: When you make the synchronous calls to external systems it will tie up a thread in the application server, so depending on application server you choose and how many concurrent threads/users you have will determine whether doing it that way will work for you.
Usually when you have long running requests like that it is a good idea to use a background processing system such as celery, like you suggest.