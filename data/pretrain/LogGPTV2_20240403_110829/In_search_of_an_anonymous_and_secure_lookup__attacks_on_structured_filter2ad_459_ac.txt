attempts to trace back from Y to X. Recall that we have
presented a passive attack on the NISAN lookup in Section
3.2 that allows the attacker to learn lower and upper bounds
of the target ID. Let L denote the lower bound related to
the lookup performed by X for Y . Since L is contacted by
X in the lookup, the attacker could infer X as long as she
can associate L with Y . Assuming there are α concurrent
lookups being performed in the network, then there could be
up to α concurrent lower bounds. The attacker’s task is to
guess the correct lower bound L associated with Y among all
the concurrent lower bounds. More precisely, the attacker
will assign probability to all the concurrent lower bounds:
312the lower bounds that are more likely to be L will receive
high probability, while the lower bounds that are less likely
to be L will receive small probability.
Since L is the contacted malicious node laying closest to
the lookup target and the Chord ring is directed, intuitively
L would be very likely to lay close to Y . As we analyzed in
Section 3.2, L would belong to the ﬁnal TopList as long as
there is a malicious node in the TopList. This happens with
very high probability (98.85% when f = 0.2, m = 20). In
this case, both L and Y are in the TopList, and hence there
are at most m − 1 nodes between L and Y on the ring. Note
that, there could be very few lower bound nodes that are
within m hops from Y . This is because to be a lower bound,
a node must be malicious, queried in a concurrent lookup,
and closest to the lookup target. Therefore, the attacker
can make a good guess on L by assigning high probability
on the lower bound nodes that are within m hops from Y ,
and consequently the entropy of X could be very low. The
attacker can apply the hop-by-hop tracing attack multiple
times until reaching the initiator I.
4.2.2 Analysis
We formally analyze the hop-by-hop tracing attack, and
use the entropy of I as the metric to evaluate the anonymity.
We show that with the hop-by-hop tracing attack, the en-
tropy of I is much lower than the expected value.
The average entropy of I is calculated as follows (note
that the exit relay C must be compromised):
H(I) = P r(MC ∧ MB ∧ MA) · H(I|MC ∧ MB ∧ MA)
+ P r(MC ∧ MB ∧ ¬MA) · H(I|MC ∧ MB ∧ ¬MA)
+ P r(MC ∧ ¬MB ∧ MA) · H(I|MC ∧ ¬MB ∧ MA)
+ P r(MC ∧ ¬MB ∧ ¬MA) · H(I|MC ∧ ¬MB ∧ ¬MA)
+ P r(¬MC) · log2(1 − f ) · n
Since the attacker can break the tunnel when both A and
C are compromised, the entropy of I in this case is 0. Hence,
H(I|MC ∧ MB ∧ MA) = 0, and H(I|MC ∧ ¬MB ∧ MA) = 0.
Now we calculate H(I|MC ∧ MB ∧ ¬MA) and H(I|MC ∧
¬MB ∧ ¬MA), respectively.
(1) Calculation of H(I|MC ∧MB ∧¬MA). In this scenario,
the ID of A is known to the attacker, and she needs to link
A to I. To compute this entropy, we consider two cases:
either L belongs to the TopList, or L is outside the TopList.
We let H1 and H2 denote the entropies for the two cases,
respectively. Then, H(I|MC ∧ MB ∧ ¬MA) can be written
as:
P r(L ∈ T opList) · H1 + P r(L /∈ T opList) · H2
As we mentioned before, P r(L ∈ T opList) ≫ P r(L /∈
T opList). Hence, for the case L /∈ T opList, we use an upper
bound log2(1 − f )n to compute H2 for simplicity.
As for the case L ∈ T opList, we use the following nota-
tions when computing H1. We let Lp(1), · · · , Lp(u) denote
the sequence of concurrent lower bounds that precede A in
the TopList (if any), and let Ls(1), · · · , Ls(v) denote the list
of concurrent lower bounds that succeed A in the TopList
(if any).
It is possible that a lower bound node could be
the lower bound in multiple concurrent lookups. Hence, we
let Ip(t), 1 ≤ t ≤ u (or Is(r), 1 ≤ r ≤ v) denote the set of
concurrent lookup queriers related with Lp(t) (or Ls(r)).
We let θ(g) denote the probability that L is a lower bound
in g concurrent lookups (excluding the one performed by I
for A), g = 0, 1, · · · . Since among the α concurrent lookups,
(1 − f )2α of them are performed by a honest node and ﬁnish
f n(cid:17),
with a honest relay, we have θ(g) = bino(cid:16)g, (1 − f )2α, 1
where bino(x, y, z) ≡ zx(1 − z)y−x. Then, we have:
H1 = −Xt Xg XIp(t),g ∈Ip(t)
θ(g) · P r(I = Ip(t),g)
· log2(cid:0)θ(g) · P r(I = Ip(t),g)(cid:1)
−Xr Xh XIs(r),h ∈Is(r)
· log2(cid:0)θ(h) · P r(I = Is(r),h)(cid:1)
θ(h) · P r(I = Is(r),h)
, where Ip(t),g denotes an element in Ip(t) when Ip(t) contains
g + 1 elements (including the correct initiator I). Similar
deﬁnition applies to Is(r),h.
Based on the attacker’s observation, she cannot distin-
guish the initiators related with a same lower bound, and
thus she will make an even guess on these initiator candi-
dates. Therefore,
P r(I = Ip(t),g) =
P r(I = Is(r),h) =
1
g + 1
1
h + 1
· P r(L = Lp(t))
· P r(L = Ls(r))
Now we do some preparation calculations before comput-
ing P r(L = Lp(t)) and P r(L = Ls(r)). We deﬁne SL and
SA as the positions of L and A in the TopList (clockwise),
respectively. Since L is the queried malicious node closest
to the target, all ﬁngers succeeding L in the TopList must
be honest. Therefore, we have:
P r(SL = i) = f (1 − f )m−i
1 ≤ i ≤ m
Since A is selected randomly from the TopList and can not
be L (since L is malicious and A is honest), we have:
P r(SA = j) =
1
m − 1
1 ≤ j ≤ m
We deﬁne β as the probability that a node is a lower bound.
Then β is calculated as:
β = f 1 −(cid:18)1 −
1
f n(cid:19)(1−f )α!
There are r − 1 lower bounds laying between Ls(r) and A,
and thus P r(L = Ls(r)) is:
P r(SA = j) ·
m−r
Xj=1
m
Xi=j+r
P r(SL = i) · bino(r − 1, i − j − 1, β)
Since all ﬁngers succeeding L in the TopList are honest
and are impossible to be lower bounds, only Lp(u) (the clos-
est lower bound that precedes B) is likely to be L. So,
P r(L = Lp(t)) = 0,
1 ≤ t ≤ u − 1
P r(L = Lp(u)) =
P r(SA = j) ·
m
Xj=2
P r(SL = i)
j−1
Xi=1
(2) Calculation of H(I|MC ∧ ¬MB ∧ ¬MA). In this sce-
nario, the ID of B is learned by the attacker, and she needs
to trace back two hops: B to A, and A to I. Using the same
strategy, the attacker ﬁrst ﬁnds a number of candidates for
A and assigns them with probabilities. The calculation of
31313.5
13
12.5
12
11.5
11
10.5
)
I
(
H
Our attack (analysis), alpha=n/50
Our attack (analysis), alpha=n/100
Our attack (analysis), alpha=n/200
Our attack (simulation), alpha=n/50
Our attack (simulation), alpha=n/100
Our attack (simulation), alpha=n/200
No attack (expected entropy)
Ideal passive attack
10
0
0.02
0.04
0.06
0.08
0.1
0.12
Fraction of malicious nodes (f)
14
13.5
13
12.5
)
I
(
H
12
11.5
11
10.5
10
4
0.14
0.16
0.18
0.2
Our attack, f=0.10
Our attack, f=0.20
No attack (expected entropy), f=0.10
No attack (expected entropy), f=0.20
Ideal passive attack, f=0.10
Ideal passive attack, f=0.20
6
8
10
12
14
Length of the construction path (l)
16
18
20
Figure 6: Entropy of I to the attacker. n = 10 000.
these probabilities for A is the same as the above scenario.
Then for each candidate of A, the attacker further ﬁnds a
number of candidates for I. The entropy is averaged over
all candidates of I. Since the calculation is similar in spirit
with scenario (1), we omit the details for simplicity.
4.2.3 Results
We calculate H(I) using the above analysis, and the re-
sults are given in Figure 6. We also simulate the hop-by-
hop tracing attack using the simulator we developed for
the NISAN lookup. We adopt the same conﬁguration as
the simulation of the NISAN lookup (Section 3.2). We use
n = 10 000 nodes, and 100 random Chord rings. The sim-
ulation results are averaged over 10 000 independent runs.
Figure 6 shows that our analysis results are upper bounds
of the actual values. This is because we use an upper bound
value for H2 when computing H(I|MC ∧ MB ∧ ¬MA).
We compare our attack against the ideal passive attack, in
which the attacker can obtain full knowledge of I as long as
the exit relay is compromised3, i.e., H(I) = (1 − f ) log2(1 −
f )n. We can see that the entropy of I achieved by our attack
is very close to the optimal value of the ideal attack, showing
that the hop-by-hop tracing attack is a very powerful attack.
4.3 Construction III: Further Enhancements
to Construction II
One way to mitigate the attacker’s knowledge of I is to use
a longer path. To reduce the expense of relaying traﬃc over
a long path and mitigate selective DoS attack, we adopt the
idea of ShadowWalker proposed by Mittal and Borisov [19]
to construct the circuit: I ﬁrst follows Construction II to
ﬁnd a sequence of l relays, and then use the last two relays
to build the circuit.
However, this approach can only mitigate attackers’ knowl-
edge of I to some extent, since timing analysis (on lookup
traﬃc) allows the attacker to associate the ﬁrst malicious
relay and the last non-exit malicious relay on the path, and
thus skip linking the relays in the middle. Figure 7 shows
that the attacker can still reduce the entropy of I by 1.2
bits when l = 20 and f = 0.2. Furthermore, this construc-
tion substantially increases bootstrapping latency and ren-
ders the system vulnerable to DoS attack (i.e., preventing
3Note that when the exit relay is honest, it is impossible
for the attacker to learn both I and the destination, so the
entropy in this case is the maximum value log2(1 − f )n.
Figure 7: H(I) with a long construction path. n =
10 000, m = 20, and α = n/100.
4567%8 95('
$% &' (%%'")
 !"#
*+,-./
*+,-*/
1
2
0
3
Figure 8: Torsk circuit construction.
clients from conducting anonymous communication by drop-
ping lookup traﬃc).
5. TORSK
From the discussion of the NISAN circuit constructions,
we can see that letting the initiator I or the end relay of a
partial circuit to look up the next hop allows an attacker to
launch hop-by-hop tracing attack to associate the destina-
tion with I. The authors of Torsk [16] proposed an alter-
native design for circuit construction by using secret buddy
nodes. We show that although Torsk is immune to passive
hop-by-hop tracing attack, introducing secret buddies ren-
ders the system seriously vulnerable to active attacks.
5.1 Secret Buddy
One important notion in Torsk is secret buddy. Torsk
requires each node to privately select a number of random
buddies from the global pool of nodes in the network; a
lookup querier will request one of its buddies to perform the
lookup on its behalf, so that an attacker cannot associate the
lookup target with the querier. Then, hop-by-hop tracing
attack cannot be applied, as long as the relationship between
nodes and their buddies is kept secret from the attacker and
the buddies are not compromised.
Torsk proposes four mechanisms to ensure secrecy of re-
lationship between nodes and their buddies as well as the
security of the buddy selection process. First, Torsk pro-
poses to use anonymous random walks to select buddies,
leaking little information about the relationship between the
random walk initiator and the ﬁnally picked node. Second,
the buddy selection process is performed oﬀ-line (before a
lookup is performed), so that timing analysis attack cannot
be applied. Third, Torsk requires that buddies must be one-
time use. Otherwise, an attacker can associate a node U
with its buddy, by requesting U to perform a lookup for x∗
(for circuit extension), and the node that looks up x∗ subse-
314quently is learned as U ’s buddy node. Finally, Torsk applies
certiﬁcate veriﬁcation at each hop of the random walk, pre-
venting attackers from biasing the random walk to increase
the chance of malicious nodes being selected as buddies.
5.2 Buddy Exhaustion Attack on Torsk
Although using secret buddies to extend circuits breaks oﬀ
the “clue” of tracing the path backwards, the one-time use
of buddies makes the system vulnerable to buddy exhaustion
attack : an attacker can prevent the circuits having honest
entry nodes from being extended, by exhausting buddies
of the end relays of these partial circuits. Consequently, a
large fraction of constructed circuits would have malicious
entry nodes. Among these circuits, the attacker can further
apply selective DoS attack [3] by letting the malicious entry
nodes tear down the circuits that have honest exit relays.
As a result, the majority of built circuits would have both
compromised entry and exit nodes, and hence the attacker
can launch timing analysis attack to break the tunnel.
Now we describe buddy exhaustion attack in details. First,
we let all malicious nodes choose colluding nodes as their
buddies. Hence, when the attacker observes a lookup per-
formed by a honest buddy, she is sure that this lookup is re-
quested by a honest node. In particular, we consider the case
when the entry relay A is honest (if A is malicious, then se-
lective DoS attack can be applied directly). As shown in Sec-
tion 3.1, due to information leaks, the attacker can observe
nearly all lookups (over 99.5% when f = 0.2). Hence, when
Bud(A) looks up B, the attacker can observe the lookup and
infer that A is honest4. Then, the attacker ﬂoods B with
suﬃciently many lookup requests, so that all cached bud-
dies of B would be exhausted. Consequently, B will have no
buddy to perform any lookup for A to extend the circuit.
The buddy exhaustion attack can successfully defeat the
second mechanism of Torsk (oﬀ-line buddy selection), since
the victim node B under the buddy exhaustion attack has
to ﬁnd new buddies during the circuit construction.
Now we show that the attacker can further prevent B from
recovering from the buddy exhaustion attack, by blocking B
from ﬁnding new buddies. We ﬁrst brieﬂy review the ran-
dom walk process for buddy selection. First, the querier
randomly picks a ﬁnger F1 out of its FT as the ﬁrst hop of
the random walk, and then asks F1 for its FT, from which
the second hop F2 is selected at random. This process is
iteratively performed for l hops, and is followed by a geo-
metrically distributed “tail” with expected length l. To pre-
vent the attacker from biasing the random walk, the querier
requests and veriﬁes the certiﬁcates related to the incoming
and outgoing links of Fi. If an invalid certiﬁcate is found, the
random walk is restarted. Therefore, to prevent the querier
from ﬁnding new buddies, the attacker can let malicious
nodes involved in a random walk return invalid certiﬁcates
to force the random walk to restart. Since the random walks
are typically long (with 2l hops, l = 14 5), the attacker could
have a very good chance to interrupt the buddy selection
process.