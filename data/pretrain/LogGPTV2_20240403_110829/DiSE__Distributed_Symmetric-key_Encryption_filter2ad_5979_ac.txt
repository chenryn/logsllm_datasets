proof of security for these constructions under a strong pseudo-randomness requirement.
These constructions, however, do not satisfy the correctness deﬁnition (against malicious
adversaries).
Interestingly, we note that the recommended approach of obtaining correctness
by applying a NIZK to each message of the protocol runs into a subtle technical issue, and
show how to circumvent it by modifying the construction such that the public parameters
provide a trapdoor commitment to the secret keys of the parties.
Attempt-0: A four-round protocol. As discussed earlier, our goal is to obtain a two-
round protocol where one party sends a message to others and receives a response. But
it is helpful to review a ﬁrst attempt that requires four rounds of interaction and meets
all our security requirements. We assume a DPRF scheme is already setup. To encrypt a
message m, parties evaluate the DPRF on a random message r generated by the encryptor
to obtain the output w. The encryptor then encrypts the message m using a CPA-secure
symmetric-key encryption with w as the secret-key to obtain a ciphertext c. Parties then
run the DPRF protocol one more time on H(c) for a collision-resistance hash function H,
such that the encryptor obtains the tag t. Encryptor outputs (r, c, t) as the output of the
encryption protocol. The decryption protocol works as expected by ﬁrst recomputing and
checking t and then recovering w to decrypt c.
It is worth noting that this construction is reminiscent of the standard encrypt-then-MAC
approach for obtaining an authenticated encryption scheme, where in one invocation the
DPRF is used to generate a fresh random key for encryption and in the second invocation it
is used to compute a MAC on the ciphertext. Note that the encryption protocol requires two
sequential calls to the DPRF protocol, hence yielding four rounds of interaction. Interestingly,
to obtain a two-round protocol, we need to deviate from this and design a protocol that
roughly follows the MAC-then-encrypt paradigm but nevertheless meets our strong notions
of security. Next we review two 2-round proposals that fail to achieve our notions.
Failed Attempt-1 [NPR99]. The ﬁrst (to the best of our knowledge) proposal for a
distributed encryption is due to Naor et al. [NPR99] (NPR in short). They propose to (i)
ﬁrst encrypt the message m locally to produce a ciphertext e = SEw(m) by a “standard”
symmetric-key encryption scheme SE where the key w is chosen freshly at random; (ii) then
invoke the DPRF on the input (j(cid:107)e) for the encryptor to obtain y, where j is the encryptor’s
identity; (iii) ﬁnally mask the key w with y. The ﬁnal ciphertext is of the form (j, y ⊕ w, e).
Although this achieves message privacy, it fails to achieve authenticity since the adversary,
after obtaining a valid ciphertext as above, can change the key by mauling w to w(cid:48) (and hence
maul the ciphertext) and decrypt e with w(cid:48) to produce a valid message m(cid:48). The crux of the
problem is in giving the adversary the ﬂexibility to choose the encryption key w without any
checks or restrictions.
Failed Attempt-2. Another natural approach to construct distributed threshold encryp-
tion is to (i) choose a random nonce r, (ii) compute a DPRF value w on (j, r) and (iii) use
w as a key for a standard authenticated encryption scheme AE to compute e = AEw(m).
The ﬁnal ciphertext is (j, r, e). One can easily observe that, although message private, this
approach does not suﬃce for authenticity since an attacker can make a single encryption
query to obtain w and use it to encrypt more valid messages without violating the security
11
of the AE scheme.
Note that both attacks discussed above work even in the semi-honest setting since the
corrupt parties behave honestly in all distributed protocols. In fact, the above attempts fail
to achieve even a much weaker notion of authenticity which does not allow decryption queries.
See Appendix B for more details.
Our Construction. At a high level, we use a DPRF scheme to generate a pseudorandom
key w that is used to encrypt the message m. But to avoid the recurring problem in the failed
attempts above, we need to ensure that an adversary cannot use the same w to generate any
other valid ciphertext. To do so, we bind w to the message m (and the identity of party
j). One way to achieve that is to use (j(cid:107)m) as an input to the DPRF. First, note that it
is necessary to put j inside the DPRF, otherwise a malicious attacker can easily obtain w
by replaying the input of the DPRF in a new encryption query and thereby recovering any
message encrypted by an honest encryptor. In the protocol we make sure each party checks
if a message of the form (j,∗) is indeed coming from party j. Second, this does not suﬃce as
it reveals m to all other parties during the encryption protocols originated by honest parties
and as a result fails to achieve even message privacy. To overcome this, we instead input
a commitment to m to the DPRF. The hiding property of the commitment ensures that
m remains secret, and the binding property of the commitment binds w to this particular
message. To enable the veriﬁcation of the decommitment during the decryption, we need to
also encrypt the commitment randomness along with m.
This almost works4 except that the attacker can still generate valid new ciphertexts by
keeping m, j and w the same and using new randomness to encrypt m. We prevent this by
making the ciphertext deterministic given m and w: we input w to a pseudorandom number
generator to produce a pseudorandom string serving as a “one-time pad” that is used to
encrypt m just by XOR’ing (this can be thought of as applying a standard stream-cipher
using w as the “random” nonce).
To summarize, our ﬁnal construction can be informally described as follows: (i) the
encryptor with identity j chooses a random ρ to compute α := Com(m; ρ) where Com is a
commitment and sends (j, α) to the participating parties, (ii) the participating parties then
ﬁrst check if the message (j, α) is indeed sent by j (otherwise they abort) and then evaluate
the DPRF on (j(cid:107)α) for the encryptor to obtain the output w, (iii) ﬁnally, the encryptor
computes e = PRG(w) ⊕ (m(cid:107)ρ) and outputs the ciphertext (j, α, e).
In Section 7 we show that the above construction achieves consistency, message privacy
and authenticity (ciphertext integrity) against a malicious adversary who corrupts up to t− 1
parties if the underlying DPRF is consistent and pseudorandom. Moreover, if the underlying
DPRF satisﬁes our correctness deﬁnition, then our TSE achieves strong authenticity. Note
that given a DPRF, the only assumption required for the transformation is one-way functions.
3 Related Work
We brieﬂy discuss several related research directions with similar motivations.
Secret-sharing. Secret-sharing schemes can be used to share the key for symmetric-key
encryption among multiple parties, say n. They guarantee that even if up to n− 1 parties are
4In fact this already satisﬁes a weaker notion of plaintext integrity (see Remark 6.10) since the adversary
cannot forge a ciphertext for a new message.
12
compromised, no information about the key is leaked. A popular key management tool called
Vault [vaub] takes this approach. It uses Shamir’s secret sharing [Sha79] to split the master
secret key into shards. According to the documentation [vauc], “This allows each shard of the
master key to be on a distinct machine for better security.” In practice, however, the master
secret key is reconstructed from the shards when the Vault server is started, and remains
in the memory of several—potentially, very weakly protected—parties for extended periods
of time5. Certainly, Vault makes it easy for multiple applications or services to share the
same key material but, at the same time, does not reduce key exposure in a signiﬁcant way.
Eﬀectively, instead of being stored in a permanent way on multiple parties, the key material
lives in memory.
Threshold PKE. Threshold public-key encryption is a well-studied problem in cryptog-
raphy [Fra90, DF90, DDFY94, SG98, CG99, NPR99, DP08]. Here, the decryption key is
shared among a set of parties such that at least a threshold of them are needed to decrypt
any ciphertext. In some sense, threshold PKE is an analog of the problem we study here. But
as discussed earlier, being a public-key notion, neither the security notions nor the eﬃciency
requirements meet those of symmetric-key applications.
Threshold Pseudorandom Functions. To the best of our knowledge, the only thresh-
old constructions designed for symmetric-key primitives are for pseudorandom functions
[MS95, NPR99, Nie02, Dod03, DY05, DYY06, BLMR13, ECS+15]. This line of work is
primarily focused on distributed PRFs (DPRF) with security in the standard model or ad-
ditional properties such as veriﬁability or key-rotation, but does not provide deﬁnitions or
constructions for the more general case of symmetric-key encryption. The only exception is
the work of Naor et al. [NPR99], which also proposes a mechanism for encrypting messages
using their DPRF construction. But as we have discussed (c.f. Sec 2.1, Appendix B), their
proposal fails to meet our deﬁnition of threshold authenticated encryption. Nevertheless, we
use Naor et al.’s DPRF constructions as the main building block in our constructions and
implementations.
General-purpose MPC. Secure multi-party computation (MPC) allows multiple parties
to evaluate a function over their private inputs without revealing anything about their inputs
beyond the function’s output. Since its introduction in early 80s, MPC has grown into a
rich area with a number of diﬀerent solutions of various ﬂavors. In the last decade or so,
the performance of general-purpose MPC protocols (which allow arbitrary functions to be
computed) has improved substantially in both the two-party and multi-party setting [mpca,
mpcb, mpcc].
However, all general-purpose MPC protocols work with a circuit representation of the
function which seems to be an overkill to solve our speciﬁc problem. Furthermore, the
communication complexity of these protocols typically scales linearly with the size of the
circuit and the number of parties. Finally, the number of rounds of interactions is often
more than two6 for all practical MPC instantiations; and the protocols require all pairs of
5If not the master secret key itself, then at least the encryption key remains in memory. The encryption
key encrypts the actual data and the master key encrypts the encryption key. We refer to the documentation
for details.
6A recent surge of results [GGHR14, MW16, GMPP16, GS18, GS17, BL18] construct two round MPC
protocols. However, these constructions focus mainly on generic feasibility and minimizing assumptions and
are far from being practical.
13
parties to interact. Thus, a general-purpose MPC protocol for evaluating symmetric ciphers
such as AES in any encryption mode [DK10, GRR+16, RSS17, dya] is too expensive of a
solution for many applications of distributed symmetric-key encryption. On the other hand,
MPC-based solutions are advantageous in scenarios where the desired encryption scheme is
ﬁxed and cannot be changed by the application (due to compatibility with other components
or a compliance requirement to use standardized schemes such as AES) since MPC can be
used to securely compute arbitrary cryptographic functions.
4 Preliminaries
In this paper, unless mentioned otherwise, we focus on challenge-response style two-round
protocols: a party sends messages to some other parties and gets a response from each one
of them. In particular, the parties contacted need not communicate with each other.
Common notation. Let N denote the set of positive integers. We use [n] for n ∈ N to
denote the set {1, 2, . . . , n}. A function f : N → N is negligible, denoted by negl, if for every
polynomial p, f (n) < 1/p(n) for all large enough values of n. We use D(x) =: y or y := D(x)
to denote that y is the output of the deterministic algorithm D on input x. Also, R(x) → y
or y ← R(x) denotes that y is the output of the randomized algorithm R on input x. R can
be derandomized as R(x; r) =: y, where r is the explicit random tape used by the algorithm.
Finally, we write X ∼ DS to denote a random variables X that follows a distribution D
over a set S. For two random variables X and Y we write X ≈comp Y to denote that they
are computationally indistinguishable and X ≈stat Y to denote that they are statistically
close. Concatenation of two strings a and b is either denoted by (a(cid:107)b) or (a, b). Throughout
the paper, we use n to denote the total number of parties, t to denote the threshold, and κ
to denote the security parameter. We make the natural identiﬁcation between players and
elements of {1, . . . , n}.
We will use Lagrange interpolation for evaluating a polynomial. For any polynomial P ,
the i-th Lagrange coeﬃcient for a set S to compute P (j) is denoted by λj,i,S. Matching the
threshold, we will mostly consider (t − 1)-degree polynomials, unless otherwise mentioned.
In this case, at least t points on P are needed to compute any P (j).
Inputs and outputs. We write [j : x] to denote that the value x is private to party j. For
a protocol π, we write [j : z(cid:48)] ← π([i : (x, y)], [j : z], c) to denote that party i has two private
inputs x and y; party j has one private input z; all the other parties have no private input;
c is a common public input; and, after the execution, only j receives an output z(cid:48). We write
[i : xi]∀i∈S or more compactly(cid:74)x(cid:75)S to denote that each party i ∈ S has a private value xi.
Network model. We assume that all the parties are connected by point-to-point secure
and authenticated channels. We also assume that there is a known upper-bound on the time
it takes to deliver a message over these channels.
Adversary model. We allow an adversary to take control of up to t − 1 parties and make
them behave in an arbitrary manner (active/malicious corruption). The set of corrupt parties
is not known in advance, but we assume that it does not change during protocol execution
(static corruption). We use C to denote the set of parties under the control of an adversary
A.
14
Cryptographic primitives. We need some standard cryptographic primitives to design
our protocols like commitments, secret-sharing, non-interactive zero-knowledge proofs, etc.
For completeness we deﬁne them formally in Appendix A.
5 Distributed Pseudo-random Functions: Deﬁnitions
Micali and Sydney introduced the notion of distributed pseudo-random functions in the mid
90s [MS95]. A DPRF distributes between n parties the evaluation of a function f which is
an approximation of a random function, such that only authorized subsets of parties are able
to compute f . A party who wants to compute f (x) sends x to the parties in an authorized
subset and receives information which enables her to ﬁnd f (x). A DPRF must be consistent
in the sense that for all inputs x, all authorized subsets should lead to the same value f (x).
A number of constructions and variants have been proposed over the course of more than
two decades but they either involve multiple rounds of communication [Dod03], extensive
interaction [Nie02, DY05], consider only passive corruption [NPR99, BLMR13], or achieve
stronger properties which makes them more expensive [DYY06]. Several pseudo-randomness
deﬁnitions have also been put forward in the literature, but they are not very formal or general
in most cases. There are several attacks that are not explicitly captured by these deﬁnitions
(though the proposed constructions may be secure against them). First, the adversary is
not allowed to choose the set of parties to corrupt based on the public parameters (the
only exception we know of is the deﬁnition proposed by Boneh et al. [BLMR13]). Second, it
cannot obtain DPRF partial evaluations from honest parties on the challenge input (up to the
threshold). Third, it is not allowed to participate in computing the DPRF on the challenge
input, which may help it in distinguishing the true DPRF value from random. (Note that
this last attack makes sense only under an active corruption.)
We allow the adversary to do all of the above in the pseudo-randomness game, thus ob-
taining a much stronger security guarantee. Apart from consistency and pseudo-randomness,
we also propose a correctness property which ensures that even if corrupt parties are in-
volved in a DPRF computation, they cannot make an honest party output a wrong value.7
We build on the constructions of Naor et al. [NPR99] to obtain these properties from our
DPRF instantiations.
Naor et al. [NPR99], however, were mainly concerned with DPRF security against semi-
honest adversaries. They provide a security deﬁnition and two diﬀerent constructions for such
adversaries. They mention brieﬂy that using non-interactive zero-knowledge (NIZK) proofs,
one could make their DPRF constructions actively secure. However, they do not give a formal
security deﬁnition for active security. It turns out that a naive application of NIZK proofs is
in fact not suﬃcient to obtain security against malicious participants. We additionally need
trapdoor commitments to satisfy the stronger pseudo-randomness requirement proposed here.
Further, the fact that adversaries can obtain DPRF partial outputs on the challenge input
and participate in computing the challenge DPRF value makes the proof more intricate.
We now present a formal treatment of DPRF. Similar to NPR [NPR99], we use a threshold
t to capture the authorized subsets, i.e., any set of at least t parties can compute the function
f . Security is provided against any set of up to t − 1 corrupt parties.
7This is a weaker requirement than robustness for DPRFs which guarantees that an honest party will receive
the correct DPRF value. However, Dodis [Dod03], for instance, assumes that the set of parties contacted by
the honest party includes at least t honest parties to achieve robustness (and the proposed protocol involves
several rounds of communication). We do not make any such assumption. In fact, when the threshold is close
to the total number of parties, there may not be enough honest parties to fulﬁll the condition.
15
Deﬁnition 5.1 (Distributed Pseudo-random Function) A distributed pseudo-random
function (DPRF) DP is a tuple of three algorithms (Setup, Eval, Combine) who satisfy a con-
sistency property.
– Setup(1κ, n, t) → ((sk1, . . . , skn), pp). The setup algorithm generates n secret keys (sk1,
sk2, . . ., skn) and public parameters pp. The i-th secret key ski is given to party i.
– Eval(ski, x, pp) → zi. The Eval algorithm generates pseudo-random shares for a given
value. Party i computes the i-th share zi for a value x by running Eval with ski, x and
pp.
– Combine({(i, zi)}i∈S, pp) =: z/⊥. The Combine algorithm combines the partial shares
{zi}i∈S from parties in the set S to generate a value z. If the algorithm fails, its output
is denoted by ⊥.
Consistency. For any n, t ∈ N such that t ≤ n, all ((sk1, . . . , skn), pp) generated by
Setup(1κ, n, t), any input x, any two sets S, S(cid:48) ⊂ [n] of size at least t, there exists a negligible
function negl such that
Pr[Combine({(i, zi)}i∈S, pp) = Combine({(j, z(cid:48)
j)}j∈S(cid:48), pp) (cid:54)= ⊥] ≥ 1 − negl(κ),
where zi ← Eval(ski, x, pp) for i ∈ S, z(cid:48)
over the randomness used by Eval.
j ← Eval(skj, x, pp) for j ∈ S(cid:48), and the probability is
Deﬁnition 5.2 (Security of DPRF) Let DP be a distributed pseudo-random function. We
say that DP is secure against malicious adversaries if it satisﬁes the pseudorandomness re-
quirement (Def. 5.3). Also, we say that DP is strongly-secure against malicious adversaries