也许是CPU以某种方式存储访问是否在上次访问时被拒绝，并在这种情况下阻止了攻击？
> “幸运的是，当不允许访问时，我没有得到一个缓慢的read suggesting的英特尔的null.”
（从内核地址读取返回全零）似乎发生的内存不足够缓存，但对于哪些可跳转表项存在，至少在重复读取尝试后。 对于未映射的内存，内核地址读取根本不返回结果。
# 进一步研究的想法
我们相信，我们的研究提供了许多尚未研究的剩余研究课题，我们鼓励其他公共研究人员研究这些课题。  
本节包含的博客数量比本博客的其余部分还要高 - 它包含未经测试的想法，这可能毫无用处。
## 没有数据高速缓存时序的泄露
除了测量数据高速缓存时序之外，研究是否存在微架构攻击会很有趣，这些数据高速缓存时序可用于从推测执行中泄露数据。
## 其他微架构
到目前为止，我们的研究相对以Haswell为中心。查看细节，例如其他现代处理器的分支预测如何工作，以及如何攻击可能会很有趣。
## 其他JIT引擎
我们针对Linux内核中内置的JIT引擎开发了成功的变体1攻击。看看对系统控制较少的更先进的JIT引擎的攻击是否也是实用的 -尤其是JavaScript引擎是很有意义的。
## 更高效地扫描主机虚拟地址和缓存集
在变体2中，在扫描客户拥有的页面的主机虚拟地址的同时，尝试首先确定其L3缓存集合可能是有意义的。这可以通过使用通过physmap的逐出模式执行L3逐出，然后测试逐出是否影响客户拥有的页面来完成。
对于缓存集合也可能有效 - 使用L1D +
L2驱逐集合来驱逐主机内核上下文中的函数指针，使用内核中的小配件使用物理地址驱逐L3集合，然后使用它来确定哪些缓存集合是来宾直到宾客拥有的驱逐集已经构建完成为止。
## 倾倒完整的BTB状态
考虑到通用BTB似乎只能区分2个31-8个或更少的源地址，似乎可行的是在约几个小时的时间范围内转储由例如超级调用产生的完整BTB状态。（扫描跳转源，然后对于每个发现的跳转源，将跳转目标等分）。即使主机内核是定制的，也可能用于识别主机内核中函数的位置。
源地址别名会在某种程度上降低实用性，但由于目标地址不会受到这种影响，因此可能会将来自具有不同KASLR偏移量的机器的（源，目标）对关联起来，并且可能会基于KASLR而减少候选地址的数量加法，而混叠是按位。
然后，这可能允许攻击者根据跳转偏移或函数之间的距离来猜测主机内核版本或用于构建它的编译器。
## 变体2：泄露更有效的gadget
如果对变体2使用足够高效的gadget，那么可能根本不需要从L3缓存驱逐主机内核函数指针，只用L1D和L2驱逐它们就足够了。
## 各种加速
特别是变体2 PoC仍然有点慢。这可能是因为：
  * 它一次只泄漏一点点; 一次泄漏更多点应该是可行的。
  * 它大量使用IRETQ来隐藏处理器的控制流。
使用变体2可以实现哪些数据泄漏率会很有趣。
## 使用return预测器泄露或注入
如果返回预测器在特权级别更改时也不会丢失状态，它可能对于从VM内部定位主机内核（在这种情况下，可以使用二分法来快速发现主机内核的完整地址）或注入返回目标（特别是如果返回地址存储在高速缓存行中，可以被攻击者清除并且在返回指令之前不重新加载）。
然而，我们还没有对迄今为止取得确凿结果的返回预测因子进行任何实验。
## 从间接调用预测器泄露数据
我们试图从间接调用预测器泄露目标信息，但尚未使其工作。
# 供应商声明
Project Zero向其透露此漏洞的供应商向我们提供了有关此问题的以下声明：
## 英特尔
英特尔致力于提高计算机系统的整体安全性。这里描述的方法依赖于现代微处理器的共同特性。因此，对这些方法的敏感度不仅限于英特尔处理器，也不意味着处理器超出其预期的功能规格。英特尔正在与我们的生态系统合作伙伴以及其他处理器受到影响的芯片供应商密切合作，为这些方法设计和分发软件和硬件缓解措施。
有关更多信息和有用资源的链接，请访问：  
[https://security-center.intel.com/advisory.aspx?intelid=INTEL-SA-00088&languageid=en-fr](https://security-center.intel.com/advisory.aspx?intelid=INTEL-SA-00088&languageid=en-fr)  
## AMD
AMD提供了以下链接： 
## ARM
Arm认识到，尽管按预期工作，许多现代高性能处理器的推测功能可以与缓存操作的时间结合使用，以泄漏本博客中描述的一些信息。相应地，Arm开发了我们推荐部署的软件缓解措施。
有关受影响的处理器和缓解的具体细节可以在此网站上找到：
Arm包含详细的技术白皮书以及来自Arm架构合作伙伴关于其特定实施和缓解措施的信息的链接。
# 文献
请注意，其中一些文档 - 特别是英特尔的文档 - 会随着时间而改变，所以引用和引用它们可能不会反映英特尔文档的最新版本。
  *  ：英特尔的优化手册有许多有趣的优化建议暗示相关微架构行为; 例如：  
“在间接分支之后立即放置数据可能会导致性能问题，如果数据由全零组成，它看起来像是一长串ADD到内存目标，这可能会导致资源冲突并减缓分支恢复的速度。间接分支可能会作为分支出现在分支预测[sic]硬件上，它可以分支执行其他数据页面，这可能导致后续自修改代码问题。“  
“负载可以：[...]在前面的分支解决之前进行推测。”  
“软件应避免写入正在执行的同一个1 KB子页面中的代码页，或者避免写入正在写入的相同2
KB子页面中的代码。此外，共享包含直接或推测性执行代码的页面处理器作为一个数据页面可以触发一个SMC条件，导致机器的整个流水线和跟踪缓存被清除，这是由于自修改代码的条件。“  
“如果映射为WB或WT，则可能导致推测性处理器读取将数据带入缓存”  
“如果未能将该地区映射为WC，则可能会使该行被推测性地读入处理器缓存中（通过错误预测分支的错误路径）。”
  * 
  *  Fog关于逆向工程处理器行为和相关理论的文档对这项研究非常有帮助。
  *  Evtyushkin，Dmitry Ponomarev和Nael Abu-Ghazaleh关于滥用分支目标缓冲区行为的先前研究泄漏地址，我们用它作为分析Haswell处理器分支预测的起点。Felix Wilhelm基于此的研究提供了变体2的基本思想。
  *  Gruss，ClémentineMaurice和Stefan Mangard的rowhammer.js研究包含关于L3缓存逐出模式的信息，我们在KVM PoC中重用它以驱逐函数指针。
  *  Godbolt发表了关于对英特尔处理器上分支预测器结构进行逆向工程的博客。
  *  D'Antoine撰写了一篇论文，表明操作码调度理论上可用于在超线程之间传输数据。
  *  Gruss，Moritz Lipp，Michael Schwarz，Richard Fellner，ClémentineMaurice和Stefan Mangard撰写了一篇关于缓解由用户空间和内核之间的可分页共享引起的微体系结构问题的论文。
  * 
  *  Wong的这篇博文探讨了英特尔Ivy Bridge架构使用的L3高速缓存替换策略。
# 参考
[1]
这个最初的报告没有包含关于变体3的任何信息。我们曾经讨论过直接读取内核内存是否可行，但认为这不太可能。在 Fogh的工作之前，我们后来测试并报告了变体3
。  
[2]
“测试处理器”部分列出了精确的型号名称。用于重现此操作的代码位于bugtracker的writeup_files.tar归档中，位于文件夹userland_test_x86和userland_test_aarch64中。  
[3] 攻击者控制的偏移量用于通过此PoC对阵列执行超出边界的访问，是一个32位值，将可访问地址限制为内核堆区域中的4GiB窗口。  
[4] 此PoC不支持SMAP支持的CPU; 然而，这不是一个基本的限制。  
[5] linux-image-4.9.0-3-amd64，版本为4.9.30-2 +
deb9u2（
linux-image-4.9.0-3-amd64_4.9.30-2％2Bdeb9u2_amd64.deb，sha256
5f950b26aa7746d75ecb8508cc7dab19b3381c9451ee044cd2edfd6f5efff1f8，通过Release.gpg，Release，Packages.xz签名）;
那是我安装机器时的当前发行版内核版本。PoC不太可能与其他内核版本无变化地协作; 它包含许多硬编码地址/偏移量。  
[6] 手机从2017年5月开始运行Android版本。  
[7]   
[8]  ”  
[9] 超过2 15种映射效率更高，但内核对流程可以拥有的VMA数量设置了2 16 的硬限制。  
[10]
英特尔的优化手册指出：“在HT技术的第一个实现中，物理执行资源是共享的，并且每个逻辑处理器的体系结构状态都是重复的”，因此预测状态可以共享。虽然预测器状态可能由逻辑核心标记，但这可能会降低多线程进程的性能，因此似乎不太可能。  
[11] 如果历史缓冲区比我们测量的大一点，我们增加了一些余量 -特别是因为我们在不同的实验中看到了稍微不同的历史缓冲区长度，并且因为26不是一个非常整数。  
[12]
基本思想来自