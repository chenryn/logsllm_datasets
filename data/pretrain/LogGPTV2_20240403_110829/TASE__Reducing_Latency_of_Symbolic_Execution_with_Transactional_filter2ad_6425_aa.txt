title:TASE: Reducing Latency of Symbolic Execution with Transactional
Memory
author:Adam Humphries and
Kartik Cating-Subramanian and
Michael K. Reiter
TASE: Reducing Latency of Symbolic Execution
with Transactional Memory
Adam Humphries
University of North Carolina
PI:EMAIL
Kartik Cating-Subramanian
University of Colorado
PI:EMAIL
Michael K. Reiter
Duke University
PI:EMAIL
Abstract—We present the design and implementation of a tool
called TASE that uses transactional memory to reduce the latency
of symbolic-execution applications with small amounts of sym-
bolic state. Execution paths are executed natively while operating
on concrete values, and only when execution encounters symbolic
values (or modeled functions) is native execution suspended and
interpretation begun. Execution then returns to its native mode
when symbolic values are no longer encountered. The key innova-
tions in the design of TASE are a technique for amortizing the cost
of checking whether values are symbolic over few instructions,
and the use of hardware-supported transactional memory (TSX)
to implement native execution that rolls back with no effect
when use of a symbolic value is detected (perhaps belatedly).
We show that TASE has the potential to dramatically improve
some latency-sensitive applications of symbolic execution, such
as methods to verify the behavior of a client in a client-server
application.
I.
INTRODUCTION
Since its introduction [7], [29], symbolic execution has
found myriad applications for security analysis and defense
(e.g., [31], [9], [11], [52], [20], [51], [35], [46], [41], [57]),
software testing (e.g., [50], [25], [43], [49], [2], [40], [26],
[12]), and debugging (e.g., [56], [54]). Whereas regular, “con-
crete” execution of a program maintains a speciﬁc value for
each variable, symbolic execution allows some “symbolic”
variables to be undetermined but possibly constrained (e.g.,
to be in some range). Upon reaching a branch condition
involving a symbolic variable, each branch is executed under
the constraint on the symbolic variable implied by having taken
that branch. Any execution path thus explored yields a set of
constraints on the symbolic variables implied by having taken
that path. In an example use case, these constraints could
be provided to an SMT solver [36] to compute a concrete
assignment to the symbolic inputs that would cause that path
to be executed.
When applied to testing, the speed of symbolic execution
is typically a secondary concern. However, several security
applications place symbolic execution on the critical path of
defensive response in time-critical circumstances. For example,
some works (e.g., [9], [20]) leverage symbolic execution to
generate vulnerability signatures upon detecting an exploit
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24327
www.ndss-symposium.org
attempt, and so the speed of symbolic execution is a limiting
factor in the speed with which vulnerability signatures can
be created and deployed to other sites. Other examples are
intrusion-detection systems in which a server-side veriﬁer
symbolically executes a client program to ﬁnd an execution
path that is consistent with messages received from the client,
without knowing all inputs driving the client (e.g., [19], [16]).
If each message could be veriﬁed before delivering it to the
server, then the server would be protected from exploit trafﬁc
that a legitimate client would not send (e.g., Heartbleed packets
to an OpenSSL server [16]). However, such tools are not yet
fast enough to perform this checking on the critical path of
delivering messages to the server, reducing them to detecting
exploits alongside server processing.
Conventional wisdom holds that SMT solving and state
explosion are the primary latency bottlenecks in symbolic
execution. However, the speed of straightline, concrete ex-
ecution has been found to be the primary culprit in some
contexts (e.g., [19], [55]). Most symbolic execution tools incur
a substantial performance penalty to straightline execution
because they interpret the program under analysis, even when it
is performing operations on concrete data. For example, Yun
et al. [55] report straightline-execution overheads of 3000×
and 321,000× native execution speed for KLEE [10] and
angr [46], due to interpretation. The need to interpret the
program in these tools arises from the need to track symbolic
variables, to accumulate constraints on those variables along
each execution path, and to explore multiple execution paths.
Even attempts to optimize symbolic execution when processing
only instructions with concrete arguments must typically incur
overheads due to lightweight interpretation; e.g., S2E [18]
encounters an overhead of roughly 6× vanilla QEMU [4]
execution speed on purely concrete data due its use of memory
sharing between QEMU and KLEE. In our microbenchmark
evaluations (see Sec. VI-A), these overheads in S2E resulted
in concrete execution costs of up to ≈ 72× native execution.
In this paper, we provide a solution that supports fast
native execution of instructions with concrete values—while
still using interpretation to do the “symbolic parts” of sym-
bolic execution—on modern x86 platforms. Our design and
associated tool, called TASE1, accomplish this through two key
innovations. Though TASE instruments the executable to test
whether variables are concrete or symbolic (like EXE [11]),
our ﬁrst innovation amortizes the costs of these tests by batch-
ing many into a few instructions. To maximize the beneﬁts
of this amortization, TASE defers these checks to ensure
1TASE stands for “Transactional Acceleration for Symbolic Execution”.
that only variables actually used are checked; this deferment,
together with the amortization, means that instructions may be
concretely executed on symbolic variables. Therefore, a critical
second innovation in TASE is a way of rolling back such
erroneous computations so they have no effect. TASE uses
hardware transactions as supported by Intel TSX extensions
for this purpose, though as we will see, accomplishing with
low overhead is nontrivial.
This paper outlines the design of TASE, and evaluates
its potential to accelerate symbolic execution of applications
with small amounts of symbolic state. We ﬁrst show where
TASE improves over modern alternatives such as KLEE,
S2E, and QSYM [55], through a microbenchmark comparison.
This comparison shows that while TASE can perform poorly
relative to some of these alternatives for applications with large
amounts of symbolic data, it can perform much better than
them when the amount of symbolic data is small.
Second, we show how TASE qualitatively improves the
deployment options for a speciﬁc defensive technique, namely
behavioral veriﬁcation of a client program [19], [16] as in-
troduced above. Though Chi et al. were able to show the
veriﬁcation of OpenSSL client messages in TLS 1.2 sessions
induced by a Gmail workload at a speed that coarsely keeps
pace with these sessions [16], their veriﬁcation was not fast
enough to perform on the critical path of message delivery.
We show that replacing the symbolic execution component
of their tool with TASE substantially improves the prospects
for performing veriﬁcation as a condition of message delivery.
More speciﬁcally, we show that TASE’s optimizations reduce
the average, median, and maximum lag suffered by any client-
to-server message by over 90%, 94%, and 79%, where lag is
deﬁned as the delay between arrival of a message to the veriﬁer
and its delivery to the server after veriﬁcation completes. In
doing so, TASE brings these lags into ranges that are practical
for performing inline veriﬁcation of TLS sessions driven by
applications, like Gmail, that are paced by human activity.
Third, we demonstrate the ﬂexibility of the techniques in
TASE by using it to prototype memory protections (stack
canaries and buffer under- or over-run detection, while either
reading or writing) for program execution. This demonstration
is of interest primarily due to its minimality, requiring changes
to TASE and associated components of fewer than 140 source
lines of code. The resulting protections add less than 15% to
our microbenchmarks’ execution times with TASE, as well.
To summarize, our contributions are as follows:
• We introduce a method to limit tests for determining
whether variables are symbolic to only those variables
that are actually used, and to batch many such tests into
few instructions. Since this deferred testing can result in
our erroneously executing instructions on symbolic data,
we show how transactional memory can be leveraged to
undo the effects of these erroneous computations.
• We detail the numerous optimizations necessary to realize
the promise of this approach, in terms of achieving com-
pelling performance improvements for some applications
of symbolic execution. We show through microbench-
mark tests where TASE outperforms modern alternatives,
KLEE, S2E, and QSYM. We also compare to contempora-
neously developed symbolic execution tool SymCC [39].
• We show that TASE improves a speciﬁc defense using
symbolic execution, namely behavioral veriﬁcation [19],
[16], to an extent that qualitatively improves how such a
defense can be deployed on TLS trafﬁc. Speciﬁcally, we
show that TASE reduces the costs of this defense to permit
its application inline for all but very latency-sensitive
applications. In doing so, TASE enables preemptively
protecting the server from exploits using this approach,
versus its current ability to only detect malformed client
messages alongside their processing by the server. We
also demonstrate the ﬂexibility of TASE by developing
memory protections as an application of its techniques.
The rest of this paper is structured as follows. We discuss
related work in Sec. II. We provide background and describe
challenges that we must overcome to realize TASE in Sec. III,
and present the design of TASE in Sec. IV. We discuss ad-
ditional aspects of TASE’s implementation in Sec. V. Sec. VI
contains an evaluation of TASE for a symbolic execution-based
application, and microbenchmarks. We discuss limitations of
TASE in Sec. VII and conclude in Sec. VIII.
II. RELATED WORK
We now outline prior work on symbolic execution systems
and work using Intel’s Transactional Synchronization Instruc-
tions.
A. Symbolic Execution Engines
Symbolic execution engines DART [25] and CUTE [43]
represent some of the earliest modern attempts to mix concrete
and symbolic execution [12]. Their approach, called concolic
testing, analyzes a program by choosing an initial set of
concrete input values V to a given program. The program
is then executed with instrumentation to determine when
control ﬂow instructions are encountered, and constraints are
accumulated at these branch locations in terms of their relation
to the concrete inputs. After execution with input V terminates
or is suspended, the constraints gathered from execution on V
are analyzed to determine a new set of concrete inputs V (cid:48) to
guide execution down a different path. The process can be
run repeatedly until all paths are explored, or until the tester
wishes to cease path exploration. Although we prioritize native
execution in TASE and mix concrete and symbolic execution,
our approach differs from concolic execution in that we do not
require entirely concrete inputs to drive symbolic execution.
We also do not require re-execution of a program from a new
set of concrete values to reach different execution paths, as
we employ native forking (see Sec. IV-E) to explore different
branches of program execution when control ﬂow depends on
the value of a symbolic variable. QSYM is another example of
a concolic execution tool that requires re-execution to explore
new execution paths [55]. Like TASE, QSYM incorporates
optimizations to reduce the cost of interpretation. However,
unlike TASE, QSYM sacriﬁces soundness to optimize its
performance for fuzzing. Another recent tool, SymCC [39],
implements concolic execution using compile-time instrumen-
tation inserted into the LLVM IR of a program before machine
code is generated.
Rather than using a program’s native execution state as
its primary representation, the KLEE symbolic execution en-
gine [10] instead analyzes a program by interpreting its source
2
code translated to LLVM IR. KLEE is deeply optimized to
minimize the cost of constraint solving by caching previous
query results, applying normalization to constraints and queries
to facilitate comparisons between expressions, and analyzing
queries to determine subexpressions which may have already
been solved. KLEE is also structured to explore multiple
program paths within a single process. By doing so, KLEE is
able to closely guide state exploration with heuristics chosen
to prioritize code coverage or search for speciﬁc bugs or
problematic behavior. KLEE also implements software based
copy-on-write to more efﬁciently manage the symbolic states
associated with different program paths.
EXE [11], Mayhem [13], and S2E [18] are symbolic
execution engines that use a program’s native state as its
principal representation. EXE analyzes a program by executing
it natively and checking each use of a variable against a
map that
indicates if the variable is symbolic. Similarly,
Mayhem uses dynamic taint analysis [38] to detect instruction
blocks that touch symbolic data, while otherwise executing
the program natively. EXE and Mayhem also use forking to
explore multiple execution paths, i.e., forking the symbolic-