execution model, which is the case for most the applications
we studied. As discussed earlier, writing parsers is largely
one-time efforts. However, it is possible that our execution
model study do not cover some execution models, leading to
incompleteness of the fusion rules. We plan to address this
issue in the future work.
C. Demand-driven Datalog Inference, Graph Construction
ALchemist relies on the underlying Datalog inference
engine to perform log fusion. However, according to our
experiment in Section V, on average three million audit events
and thirty thousand application log events can be generated
everyday with a regular workload. Complex attacks may span
over days, weeks and even months. It is infeasible for a Datalog
engine to operate on the logs of such a long period. We
leverage the observation that although attack span may be long,
the attack behaviors may only be a very small portion of overall
logged behaviors. Given that ALchemist is capable of avoiding
bogus dependencies, we propose a demand-driven Datalog
inference algorithm. Particularly, for a backward forensic task
that tries to identify the root cause of an attack, we start with
the raw logs (of a long period of time) and the symptom event.
We separate the log entries by processes. We then perform
log fusion on the process of the symptom to construct its
causal graph, e.g., through rules (R12)-(R15) in Fig. 9. With
the dependence relations, the provenance graph is constructed
as follows.
Provenance Graph Construction. A unit node is created
for each unit. It contains all the application log events and
audit log events in the unit based on the sameU nitH and
sameU nitL relations (in Fig. 9). An event node is created for
each event such that each unit node contains a set of event
nodes. Dependence edges are introduced between event nodes
according to the depH and depL relations. Projection edges
are introduced between an application event node and an audit
event node according to the projection relation. Examples can
be found in Section VI.
After the dependence graph is constructed, it is traversed
backward from the symptom event. Through the traversal,
ALchemist identiﬁes the other processes that are causally re-
lated to the symptom through direct or transitive dependencies.
Then, only the logs of those processes are fused and further
TABLE IV: Attack overview
No.
Platform Duration Attack Surface
Scenario Name
Attack Reference
0d8h TightVNC-1.3.9
1 Ubuntu 14.04
2 Ubuntu 14.04
0d3h
3 Ubuntu 14.04 0d20h
4 Ubuntu 14.04 0d10h
5 Ubuntu 14.04 1d23h
Case3.5(Engagement 4)
Nginx-1.2.9
Case3.8(Engagement 3)
Firefox54.0 Phishing Email Link Case4.5(Engagement 3)
Firefox54.0
Case4.9(Engagement 3)
Firefox54.0 Phishing Email Exec Case4.8(Engagement 3)
Ransomware
Exﬁltration
Backdoor
6 Mint 17.1
7 Mint 17.1
8 Mint 17.1
9 Mint 17.1
10 Mint 17.1
Metasploit
0d7h OpenSSH-6.6
Case3.6(Engagement 4)
0d5h OpenSSH-6.6 Azazel Injection Case3.2(Engagement 4)
SSHD Injection Case3.14(Engagement 3)
1d0h
Case3.1(Engagemnet 3)
0d3h
0d10h
Case4.4(Engagement 3)
Nginx-1.2.9
Nginx-1.2.9
Firefox54.0
RAT Malware
Web-Shell
ShellShock
11 Ubuntu 14.04 0d19h Apache-2.4.7
12 Ubuntu 14.04 1d20h OpenSSH-6.6
13 Ubuntu 14.044 1d18h Apache-2.4.7
14 Ubuntu 14.04 0d23h OpenSSH-6.6
traversed. Section V shows that such a demand-driven strategy
substantially reduces the workload for the Datalog engine.
passwd-gzip-scp
Cheating Student
ProTracer[54]
PrioTracker[49]
High Fidelity[71]
NoDoze[31]
Data Theft
V. EVALUATION
ALchemist supports both Linux 64 bits and 32 bits sys-
tems. Its code base includes approximately 600 lines of parser
speciﬁcation, 11500 lines of Python code, and 1900 lines of
Datalog rules. We focus on the following research questions.
is the runtime and space overhead of AL-
RQ1 What
chemist(Section V-B)?
RQ2 What is the performance of Datalog module when
analyzing real world attacks (Section V-C)?
RQ3 How effective is our execution partitioning scheme
based on log fusion (Section V-D)?
RQ4 How effective is ALchemist when analyzing real
world attacks? How does it compare to the state-of-the-art
techniques that do not require instrumentation: NoDoze [31]
and OmegaLog [33] (Section V-E)?
A. Experiment Setup
To evaluate the efﬁciency of ALchemist (RQ1), we use 12
popular applications collected from the literature [53], [45].
To answer RQ3, we construct a few most commonly seen use
cases for each application, which involve intensive background
behaviors, and demonstrate that ALchemist can correctly
partition these executions and attribute the background activ-
ities. Also, to show the effectiveness of ALchemist (RQ4)
and study the performance of Datalog inference (RQ2), we
emulate 10 advanced attacks collected from various public
resources including the DARPA TC engagements [6] and the
4 real world attacks in NoDoze [31]. We are not able to
acquire the implementation of NoDoze or OmegaLog. We
hence reimplement them based on the papers and validate the
correctness of reimplementation by comparing the results of
our implementation with their published results.
Our evaluation environments include the Ubuntu 14.04
64-bit operating system (as a few attacks require exploiting
vulnerabilities on 64-bit applications) and the Mint 17.1 32-bit
operating system. These systems have the audit logging mod-
ule running, with the conﬁguration of collecting 48 security
related syscalls. The built-in application logging components
are all activated. Several attacker machines with different IPs
launch remote attacks and generate benign workload. NoDoze
11
Fig. 12: Space overhead
Fig. 14: Runtime overhead
authors and compare ALchemist with them. To measure space
overhead, we use the logs from the one-week experiments
on the 8 systems. We have turned on ALchemist, MPI and
BEEP. The results are shown in Fig. 12. For ALchemist, the
space overhead denotes the ratio of aggregated application log
size over the audit log size. For MPI and BEEP, the space
overhead denotes the size of the additional events emitted
by instrumentation over the audit log size. Observe that for
complex applications such as ﬁrefox, our system introduces
much less overhead compared to MPI and BEEP. For ﬁrefox,
our system introduces 7.11% overhead while MPI introduces
18.20% overhead and BEEP introduces 42.16% overhead. This
is because the instrumentation is quite low level such that a
high level event (i.e., one entry in the application log) may give
rise to a large number of instrumented events. We also evaluate
the whole system overhead in real world scenario. With one
week of normal workload, our system on average generates
15.8GB logs with 1.7GB application logs. Fig. 13 shows the
space consumption over time for one of the machines.
Runtime Overhead. To measure runtime overhead, we cre-
ated a set of normal workloads for individual applications,
representing typical use cases, such as browsing websites
and downloading ﬁles in ﬁrefox. We use ab [3] to simulate
apache workload and a UI input simulation tool xdotool [9]
to scriptize keyboard and mouse activities. The results are
shown in Fig. 14. Here the original applications with audit
logging turned on serve as the baseline. Observe that for
most applications ALchemist has the lowest overhead as its
runtime overhead comes only from application logging. For 4
applications such as ﬁrefox and transimission, MPI has lower
overhead as it only instruments places that are critical for
causality, whereas the application logs record additional infor-
mation such as application performance statistics. The more
important message here is that all these methods, including
ALchemist, have very small overhead.
C. Datalog Inference Overhead (RQ2)
The analysis overhead of ALchemist
is dominated by
the Datalog engine. Recall that ALchemist is demand-driven
and only performs inference on log entries related to attacks.
Table V shows the important statistics for Datalog inference
for the 14 attacks. The ﬁrst column shows the attacks. The
second column shows that how many raw log entries, including
both audit log entries and application log entries, are con-
sumed, with and without demand-driven analysis. For instance,
6.6M/291K (1st row) means that without demand-driven, 6.6M
tuples have to be processed and with demand-driven, they
Fig. 13: Space consumption over a week
requires collecting event frequency in normal workload in
order to determine outlier events during deployment. To collect
such proﬁle, we collect audit logs of 4 weeks from 10 work-
stations in our institute (running typical end-user workloads)
and calculate the frequency of each dependence edge. These
work-stations are used exclusively by the authors of this
paper and they all agree to use the collected data for their
own research. Besides, we anonymized the identity related
information including account names, private ﬁle names, and
private domain names.
To answer the research questions, we run 8 systems for
seven days. Most of the time, the systems are dealing with
normal workloads, e.g., as the primary machine for daily usage.
The fourteen attacks are conducted during the seven-day period
on various machines (some machines having more than one
attacks conducted). We assume that we know the symptom
events and we conduct backward analysis to understand the
root cause. The details of fourteen attacks (nine on the 64-bits
platform and the other ﬁve on 32-bits) are shown in Table IV.
They are reproduced based on reports at [6] and description in
[31]. Observe in column 3, each attack procedure is distributed
in a long duration of time (within the 7-day period), in order
to simulate real attacks and test how well ALchemist can
identify attack provenance from benign workload. The Datalog
inference module and visualization module are deployed on a
separate server with Intel i7-9700 CPU 4.7GHz and 64 GB
memory running Ubuntu 14.04 OS.
B. System Overhead (RQ1)
Space Overhead. In the overhead experiments, we acquire
the implementations of MPI [53] and BEEP [45] from their
12
0.0%2.0%4.0%6.0%8.0%10.0%AlchemistMPIBEEP0246810121416DAY1DAY2DAY3DAY4DAY5DAY6DAY7Log Size(GB)Time(day)AppAudit0.0%0.2%0.4%0.6%0.8%1.0%1.2%1.4%AlchemistMPIBEEPTABLE V: Datalog inference details of attacks
Attack
Rules(#) Relations(#)
-/347.26M
-/59.48M
-/221.85M
1
2
3
4
5
6
7
8
9
10
11
12
13
14
-/3.45M
-/6.87M
-/9.33M
-/4.25M
-/5.72M
-/46.57M
-/281.62M
-/223.71M
-/151.9M
-/161.6M
Tuple(#)
73.8M/3.2M 16.4M/1.2M 40.0 / 1.1
6.6M/291K
0.6 / 0.5
1.74M/1.16M 554K/429K
313K/95K
-/11.96M
- /88.5
83M/1.76M
- /23.2
-/3.74M
39M/800K
-/22.2M
- /70.6
149M/3.06M
494M/9.18M 11.7M/1.89M 106.0 / 2.7
3.6M/181.8K
106M/6.61M 1.50M/854K 42.3 / 2.3
2.58M/155.36K
10.8M/697.82K
544M/15.48M 79.4M/2.49M 136.0 / 3.3
5.37M/154.83K 184.7M/31.65M 14.2M/12.2M 46.4 /12.5
- /12.1
17.5M/730.82K
- /97.3
7.37M/2.12M
- /99.0
5.07M/1.25M
- /84.5
4.30M/1.05M
4.02M/521K
- /95.4
Time(s) Memory(MB)
262 / 40
23 / 17
- /217
- / 95
- /384
178 / 46
38 / 28
1180 / 53
191 /154
- / 79
- /409
- /370
- /267
- /145
are reduced to 291K. The third column reports the number
of applications of inference rules (with and without demand-
driven). Symbol ‘-’ means timeout (10 hours) or out of mem-
ory. The fourth column shows the number of derived relations;
the ﬁfth column time consumed and the last column memory
consumed. The results indicate the necessity of the demand-
driven strategy. Observe that in a complex attack 5 (involving
complex ﬁrefox behaviors), the inference engine applies over
220 million rules, deriving 22.2 million new relations. The
corresponding runtime overhead is only 70 seconds while the
space overhead is only 384MB, demonstrating the practicality
of ALchemist in attack forensics.
D. Effectiveness in Execution Partitioning (RQ3)
We conduct an experiment to evaluate the effectiveness of
log fusion for execution partitioning. For each application, we
craft a special workload that represents the most commonly
seen background activities of the application. Each workload
represents multiple independent tasks (i.e., units), each task
having substantial background activities. We ﬁrst run the tasks
one by one with complete separation to acquire the ground-
truth (i.e., which unit an event belongs to). Then we execute
these tasks again in parallel, inducing maximum interleaving,
and then evaluate the precision and recall of ALchemist. Here,
precision means that how many unit attributions identiﬁed
by ALchemist are correct and recall means that how many
correct unit attributions are reported by ALchemist. In order to