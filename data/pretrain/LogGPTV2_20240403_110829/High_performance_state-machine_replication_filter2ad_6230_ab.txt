III. HIGH PERFORMANCE SMR
Our approach to improving the performance of state-
machine replication addresses its two fundamental limita-
tions: we show how to reduce the response time and how
to increase the throughput of a replicated system. This work
has been conducted in the context of Ring Paxos, a high
throughput total order broadcast protocol. In the following,
we ﬁrst recall Ring Paxos (Section III-A), and then introduce
each one of our contributions (Sections III-B and III-C).
A. Ring Paxos outline
Ring Paxos is a variation of Paxos [9], optimized for clus-
tered systems. Paxos distinguishes three roles: proposers,
acceptors, and learners. A node can execute one or more
roles simultaneously. In a client-server setup, clients act as
proposers and servers as learners. A value is a command
proposed by a client to be executed by the servers; the
decided value is the next command to be executed. Each
instance of Paxos proceeds in two phases: During Phase
1, the coordinator selects a unique round number c-rnd
and asks a quorum Qa (i.e., any majority) of acceptors
to promise for it. By promising, an acceptor declares that,
for that instance, it will reject any request (Phase 1 or 2)
with round number less than c-rnd. Phase 1 is completed
when Qa conﬁrms the promise to the coordinator. Notice
that Phase 1 is independent of the value, therefore it can
be pre-executed by the coordinator. If any acceptor already
accepted a value for the current instance, it will return this
value to the coordinator, together with the round number
received when the value was accepted (v-rnd).
Once a coordinator completes Phase 1 successfully, it can
proceed to Phase 2. Phase 2 messages contain a value and
the coordinator must select it with the following rule: if
no acceptor in Qa accepted a value, the coordinator can
select any value (i.e., the next client-submitted value). If
however any of the acceptors returned a value in Phase 1,
the coordinator is forced to execute Phase 2 with the value
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:31:45 UTC from IEEE Xplore.  Restrictions apply. 
 0 1 2 3 4 5 6 0 5 10 15 20 25 30 35 40Response time (msec)Number of clientsSMRCS02K4K6K8K10KCS1248Throughput (cmd/sec)Number of replicas456that has the highest round number v-rnd associated to it.
In Phase 2 the coordinator sends a message containing a
round number (the same used in Phase 1). When receiving
such a request, the acceptors acknowledge it, unless they
have already acknowledged another message (Phase 1 or 2)
with a higher round number. Acceptors update their c-rnd
and v-rnd variables with the round number in the message.
When a quorum of acceptors accepts the same round number
(Phase 2 acknowledgement), consensus terminates: the value
is permanently bound to the instance, and nothing will
change this decision. Thus, it is safe for learners to deliver
the value. Learners learn this decision either by monitoring
the acceptors or by receiving a decision message from the
coordinator.
As long as a nonfaulty coordinator is eventually selected,
there is a majority quorum of nonfaulty acceptors, and
at least one nonfaulty proposer, every consensus instance
will eventually decide on a value. A failed coordinator is
detected by the other nodes, which select a new coordinator.
If the coordinator does not receive a response to its Phase
1 message it can re-send it, possibly with a bigger round
number. The same is true for Phase 2, as long as the same
round number is used. If the coordinator wants to execute
Phase 2 with a higher round number, it has to complete
Phase 1 with that round number beforehand. Eventually the
coordinator will receive a response or will suspect the failure
of an acceptor.
Ring Paxos [11] differs from Paxos in a few aspects that
make it more throughput efﬁcient (see Figure 3):
• Acceptors are organized in a logical ring. The coordi-
nator is one of the acceptors. Phase 1 and 2 messages
are forwarded along the ring, each acceptor appends its
decision so that the coordinator, at the end of the ring,
can know the outcome (Step 3 in Figure 3).
• Ring Paxos executes consensus on value IDs: for each
client value, a unique identiﬁcation number is selected
by the coordinator. Consensus is executed on IDs which
are usually signiﬁcantly smaller than the real values.
• The coordinator makes use of ip-multicast. It triggers
Phase 2 by multicasting a packet containing the client
value, the associated ID, the round number and the
instance number to all acceptors and learners (Step 2
in Figure 3).
• The ﬁrst acceptor in the ring creates a small message
the ID and its own
containing the round number,
decision and forwards it along the logical ring.
• An additional acceptor check is required to guarantee
safety. To accept a Phase 2 message, the acceptor must
know the client value associated with the ID contained
in the packet.
• Once consensus is reached, the coordinator can inform
all the learners by just conﬁrming that some value ID
has been chosen. The learner will deliver the corre-
sponding client value in the appropriate instance (Step
4 in Figure 3). This information can be piggybacked to
the next ip-multicast message.
Message losses may cause learners to receive the value
proposed without the notiﬁcation that it was accepted, the
notiﬁcation without the value, or none of them. Learners
recover lost messages by inquiring other nodes. Ring Paxos
assigns each learner to a preferential acceptor in the ring, to
which the learner can ask lost messages. Lost Phase 1 and
2 messages are handled like in Paxos. The failure of a node
(acceptor or coordinator) requires a new ring to be laid out.
Figure 3. Ring Paxos in a client-server setup (n acceptors, up to f of
which can fail, and m learners/servers)
B. Speculative execution
The response time experienced by a client of a replicated
service is the result of three activities: (a) proposing and
ordering a command, (b) executing the command at the
servers, and (c) transmitting the response to the client. A
reduction in the duration of any of these activities will
likely decrease response time. However, in the context of
Ring Paxos this is not easy to do since the protocol is
already highly optimized and it seems unlikely that it can
be signiﬁcantly improved to accommodate high throughput
and lower response time. Moreover, the delay incurred by the
execution of a command and the transmission of its response
is mostly service speciﬁc.
We resort to a speculative (or optimistic) strategy which
consists in overlapping part of the ordering protocol (i.e.,
Ring Paxos) with the execution of commands. In Ring
Paxos, a command reaches the servers before its ordering
information (Steps 2 and 4 in Figure 3, respectively). When
a command arrives, it is buffered by the server and only
executed once its order is known. We propose to execute
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:31:45 UTC from IEEE Xplore.  Restrictions apply. 
ClientProposerCoordinatorAcceptor 1Acceptor 2  Acceptor n-f  Learner 1Server 1Phase 2APhase 2BDecisionPhase 2Bip-multicast➁➂➃. . .execCmdexecCmdRingPaxos➅Learner mServer m. . .Cmd( )Reply( )➀➄➀ Client sends command to coordinator➁ Coordinator ip-multicasts Phase 2A message➂ Acceptors exchange Phase 2B messages➃ Coordinator ip-multicasts Decision message➄ Servers execute command➅ Servers send command result to client457Some services, however, may not allow perfect partition-
ing. This is the case when a service’s state is partitioned
into sub-states such that some of the commands access
more than one partition. We illustrate this case with an
example. Consider a B-tree service with insert and query
commands—Section IV contains a detailed description of
this service. We can partition the B-tree into sub-trees by
assigning to each sub-tree a non-overlapping key interval
and replicate each sub-tree using state-machine replication.
An insert command is directed to a single replicated sub-
tree. A query command that requests a set of keys within
a certain range may be addressed to a single sub-tree or
to multiple sub-trees, depending on the range and the key
intervals assigned to each sub-tree. If the query command
addresses multiple sub-trees, then it is divided into “sub-
commands”, one for each sub-tree; the client builds the ﬁnal
response from the results received from each sub-tree. Such
a service, however, cannot be implemented by independent
instances of Ring Paxos, as we now explain.
To understand why, consider the execution on the left
of Figure 4. Under linearizability,
this execution cannot
happen since client C3 sees C1’s insert before C2’s, and
C4 sees ﬁrst C2’s insert before C1’s.
If we partition
the B-tree into two independent sub-trees, however, as
in the execution on the right of Figure 4,
then clients
may observe a non-linearizable behavior. In this execu-
tion, C3’s and C4’s Query(0, 100) command is composed
of two sub-commands, Query(0, 50) and Query(51, 100).
The problem is that while C3’s Query(0, 50) succeeds
C4’s Query(0, 50) in one partition, C3’s Query(51, 100)
precedes C4’s Query(51, 100) in the other partition, and
thus, C3’s Query(0, 100) neither precedes nor succeeds C4’s
Query(0, 100). To ensure linearizability we must establish a
total order on commands, not on sub-commands that access
a common partition.
We now deﬁne state partitioning ordering, a guarantee
needed to ensure that an execution with commands involving
multiple service partitions is linearizable. Let a service state
be decomposed into partitions P1, ..., Pk, each one replicated
and implemented as a series of consensus executions—the
i-th consensus instance decides on the i-th sub-command
of partition Pk. Let command Cx be composed of sub-
commands {cx,i | cx,i is a subcommand of Cx in Pi}. We
deﬁne directed graph G = (V, E) such that V contains all
commands Cx in the execution and E contains directed
edges Cx → Cy such that cx,i precedes cy,i in Pi. State
partitioning ordering requires that G be acyclic, that is,
for any two commands Cx and Cy, if cx,i precedes cy,i
in partition Pi, then in no partition Pj, cy,j precedes cx,j,
where cx,i, cx,j ∈ Cx and cy,i, cy,j ∈ Cy. A consequence of
G being acyclic is that it can be topologically ordered.
the command immediately after it
is received, avoiding
any buffering. In doing so, servers can start processing the
command before its order is conﬁrmed, saving some time.
A server can only respond to a client after it has executed
the command and its order is conﬁrmed. The mechanism is
speculative because it works as long as the order in which
commands arrive at the servers (and thus the order in which
they are executed) is conﬁrmed. In rare occasions (discussed
below) commands may be executed out-of-order. If the order
in which one or more commands were executed is not
conﬁrmed, the server must rollback them and re-execute the
commands in the proper order. Rolling back a command is
service-speciﬁc and can be done physically (e.g., by using
an undo log) or logically (e.g., by executing an action that
reverses the effects of the out-of-order command) [12]. We
illustrate logical rollback in Section IV.
Fortunately,
in Ring Paxos the order assigned by the
coordinator when a command is ip-multicast
is always
conﬁrmed by the acceptors. The only situation in which
the execution order of a command may change is when the
coordinator is replaced by another process (e.g., due to a
crash), a rare event. Lost messages do not cause commands
to be executed out-of-order since each command (or batch
of commands) contains a consensus instance number, which
allows a server to detect missing commands.
We can estimate the improvements expected from specu-
lative execution. Let δ be the time it takes for a client to send
a command to the coordinator and for a server to respond to
the client with its results (Steps 1 and 6 in Figure 3). Assume
further that ∆o is the time needed to order the command
(i.e., the time difference between the ﬁrst and the second ip-
multicast related to the command) and ∆e is the time needed
to execute the command. Without speculative execution,
the response time expected by a client in the absence of
contention is 2δ + ∆o + ∆e. With speculative execution,
it depends on the values of ∆o and ∆e: if ∆o < ∆e
then response time is 2δ + ∆e; otherwise response time is
2δ + ∆o. Thus, we can expect an improvement of the order
of min(∆o, ∆e).
C. State partitioning
As discussed in Section II-B, a service implemented
by means of state-machine replication has limited or no
scalability at all, as a consequence of server replicas storing
the full service state, and receiving and handling all client
commands. To make the system scalable, we must partition
the service’s state into “sub-states”. If the partitioning is
perfect, that is, all commands access one sub-state or an-
other, but no command accesses two or more sub-states,
then the technique can be trivially implemented: It sufﬁces
to replicate each partition individually, using different and
independent
instances of Ring Paxos, and submit client
commands to the appropriate partition.