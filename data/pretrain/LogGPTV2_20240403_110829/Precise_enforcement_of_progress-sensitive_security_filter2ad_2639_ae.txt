establishes that techniques for reasoning about program termina-
tion can be adapted to reasoning about progress channels. Second,
we extended the Jif compiler [35] to track information ﬂow via
progress channels, and analyzed a Jif application. We ﬁnd it is fea-
sible to enforce progress-sensitive security conditions for security-
critical applications. We report the details of our evaluation below.
7.1 Prototype implementation
Our prototype termination oracle is based on work by Chawd-
hary et al. [14], which is a form of logical abstract interpretation
over a specialized abstract domain for termination. A particular
advantage of this analysis is its performance, compared to analy-
ses that are based on binary reachability (e.g., Terminator [19]).
The analysis is parameterized over an algorithm for discovering ter-
mination arguments. Following the instantiation given by Chawd-
hary et al., we use the linear rank synthesis algorithm of Podelski
and Rybalchenko [38]. Our termination analysis uses the z3 SMT
solver [1] for linear rank synthesis and for eliminating spurious pro-
gram paths.
Our prototype is furthermore extended with a simple constant
propagation analysis that is applied to low variables when casts are
encountered at run time. This allows us to ﬁnd termination argu-
ments that rely on the current run-time values of low variables.
We use our implementation to validate the security of the all ex-
amples in this paper. Analyzing a program like the one in Listing 4
results in 31 calls to z3, with an overall time of under 0.8 seconds
on a machine with a 2.4 GHz CPU. For more complex programs,
this overhead will certainly be larger. Of course, for subprograms
that always terminate, like Listing 4, the analysis can be done stat-
ically ahead of time. We discuss related work that could improve
performance in Section 8.
Because we currently do not take into account the output his-
tory of the program, we cannot achieve the tight bound on budget
consumption for the example in the beginning of Section 5. An
implementation of more precise oracle that would take the output
history into account is deferred to future work.
# Loops
# Casts
Jif std-lib
Civitas
75
310
66
89
Termination
arith
28
88
heap
35
1
errors
3
-
Figure 8: Audit of casts required to rule out intra-procedural
progress channels in the Jif standard library and the Civitas secure
voting system. Casts are categorized by the termination argument
required to prove them safe: linear arithmetic or heap shape. Loops
that are intended to always terminate but may not are reported as
errors.
We use our experience with this prototype as a guideline for eval-
uating the feasibility of enforcing progress-sensitive guarantees in
real-world applications, which we discuss next.
7.2 Audit of progress channels in Civitas
Civitas [18] is a remote voting system that provides veriﬁable re-
sults while protecting voter conﬁdentiality. The security of Civitas
relies on two factors: strong properties of the underlying crypto-
graphic protocols for voting and information ﬂow guarantees of the
implementation. To address the latter, Civitas is implemented in
Jif [35], a security-typed language which is believed to enforce a
progress-insensitive security condition.
Our premise for this evaluation is that, despite Jif providing only
progress-insensitive guarantees, Civitas (and most other security
typed programs) satisfy a stronger, progress-sensitive security con-
dition. To evaluate this claim, we extended Jif with our multi-level
security type system to track progress channels within methods.
We focus only on intra-procedural progress channels, and ignore
any inter-procedural progress channels. We identiﬁed 66 loops in
the Jif standard library and 89 loops in Civitas that require casts
to secure possible progress channels. The loops that did not re-
quire casts were either dependent on public information or had no
low side-effects following them within the containing method. We
manually categorized each cast by the termination analysis neces-
sary to demonstrate that it is secure. Figure 8 reports our ﬁndings.
Termination analysis Notably, we discovered three simple termi-
nation bugs in the Jif standard library. The containsAll method of
the AbstractCollection class uses a loop to iterate over elements of
the given collection but the loop is missing an increment statement.
As a result, the method will terminate when called with an empty
collection as an argument, but diverge otherwise. In both linked list
implementations provided by the library, the hash code of the list is
intended to be computed by iterating over this list’s elements and
combining the hash codes of each, but the current element is not
advanced between iterations. Similar to the ﬁrst bug, these imple-
mentations will terminate for empty lists but diverge otherwise. Jif
programs using these methods may inadvertently leak information.
All of the remaining loops always terminate, regardless of input.
This matches our initial intuition: most programs are intended to
terminate and are thus likely to satisfy a stronger, progress-sensitive
security condition. Encouragingly, in practice the analysis neces-
sary to prove the absence of progress channels is minimal. We
found that all but one of the loops we needed to secure in Civitas
were simple loops where the loop counter was a low-security vari-
able, the loop bounds were not changed in the loop body, and the
stride was constant. Such loops are easily proven to terminate with
existing termination tools, for example by the analysis we use in
our prototype implementation. The remaining loop uses a collec-
tion iterator from the standard library. Its termination could either
be proved directly with a more powerful tool for heap-based termi-
nation analysis or by appeal to a model of the standard library.
889In the standard library, we found that a heap-based termination
analysis, e.g., [8], would be necessary for 35 of the 66 casts. While
this type of analysis is more complex, it can be applied once for the
library, and subsequent uses of the library can rely on models that
express the termination-relevant properties of collections as arith-
metic operations [19].
We conclude from this audit that strengthening the guarantees
provided by security typed languages is feasible; non-malicious
programs are likely to require minimal modiﬁcation. Thus, it is not
unreasonable to require progress-sensitive guarantees from real-
world security-critical applications.
8. DISCUSSION AND RELATED WORK
Declassiﬁcation The budgeted semantics and type system allow
the attacker to learn a limited amount of secret information, a form
of declassiﬁcation. Much recent work on language-based infor-
mation ﬂow has considered weakening noninterference using de-
classiﬁcation policies to specify what information may be released,
when, where and by whom (see Sabelfeld and Sands [46] for a sur-
vey). Casts for which the oracle is unable to determine whether the
command terminates or diverges can be considered a form of what
information release: the system reveals the termination behavior
of the cast. (The information theoretic bound on this information
provides a form of quantitative information release, another kind of
what information release.)
There are several existing security-type systems that enforce de-
classiﬁcation policies (e.g., [45, 16]), but the semantic security con-
dition enforced is progress insensitive. We note that even if these
type systems were strengthened to enforce a progress-sensitive se-
curity condition by rejecting high-security loops (as in, e.g., [32])
it is not clear how declassiﬁcation annotations may enforce a re-
quirement that secret information is leaked only via the progress
channel.
Assume our commands are extended with declassiﬁcation of ex-
pressions, as in e.g., [3], and consider the following program in
which the loop guard is explicitly declassiﬁed at each iteration.
guard := declassify(h > 0)
while guard do {
h := h − 1;
guard := declassify(h > 0);
}
This program is accepted by the type system of [3]. However, be-
cause after the declassiﬁcation, the loop guard is low, the type sys-
tem also accepts a program that contains a low output in the body
of the loop:
guard := declassify(h > 0)
1
2 while guard do {
h := h − 1;
3
guard := declassify(h > 0);
4
outputL(1);
5
6
}
This program reveals more information than just the fact that the
loop terminates:
it reveals the initial value of h if h is positive,
similar to the example in Listing 1.
Type systems that are designed to prevent information launder-
ing [44, 2, 7, 33] reject the program above, because of the update to
variable h on Line 3, and thus these type systems appear unsuitable
for straightforward adaptation to progress sensitivity.
Progress (in)sensitivity Much recent work on language-based
information ﬂow relies on progress-insensitive noninterference [4]
as the underlying target security condition. Demange and Sands
observe [24] that security guarantees of progress-insensitive non-
interference may be too weak for small secrets. They distinguish
between small and big secrets in programs, and propose a coarse-
grained type system that guarantees progress-sensitive security for
the small secrets and progress-insensitive security for the big se-
crets. This approach can easily beneﬁt from the results of our work.
Secure multi-execution [25, 29] addresses the problem of termi-
nation channels by enforcing strict isolation between outputs on
different security levels. The price is high performance overhead,
and non-trivial modiﬁcation of the semantics of the program.
It
is moreover unclear whether secure multi-execution may be ap-
plied to policies beyond noninterference. Compared to that, our
approach is minimally-invasive and does not change the intended
semantics of the program. This enables straightforward composi-
tion with other work on language-based information ﬂow.
Progress-sensitive enforcement appears in literature on concur-
rent information ﬂow. The enforcement mechanism of Boudol [10],
is, similarly to our approach, parametrized over a class of terminat-
ing programs, but unlike our work, it does not take runtime infor-
mation into account; moreover, nonterminating programs are ruled
out. Type systems of [48, 11, 41] enforce progress-sensitivity by
permitting high loops but disallowing public side effects after that;
this is similar to what one achieves in our language without cast
command.
Recent work by Stefan et al. addresses the problem of termi-
nation channels by spawning background threads for high compu-
tations [53]. A thread may wait upon a spawned computation to
inspect its result; doing so reveals whether the computation ter-
minated, and raises the security level of the waiting thread. This
technique is largely complimentary to ours, and relies on light-
weight concurrency for efﬁciency. It may be an adequate alterna-
tive to halting program execution when the termination oracle fails
or when the progress leakage budget is exhausted.
Integrity While the technical development of this paper focuses
on conﬁdentiality, our results apply to integrity as well. Clarkson
and Schneider [17] introduce two characterizations of integrity:
contamination and suppression. Contamination occurs when un-
trusted input propagates to trusted output; suppression occurs when
the program’s output omits correct output. We believe progress in-
tegrity attacks can be viewed as a form of suppression.
Termination analysis This work is inspired by recent progress
on static analyses for proving termination of realistic imperative
programs [19, 31, 52].
As outlined in Section 7, our current prototype implementation
uses the logical abstract interpretation for termination analysis of
Chawdhary et al. [14]; we currently support programs with linear
termination arguments. Because our language semantics are pa-
rameterized on an oracle for termination analysis, improvements
in automated termination analysis will increase the precision of
our enforcement mechanism. In particular, results on proving ter-
mination for recursive programs [21] and programs with polyno-
mial [23], bit-vector [22], and heap-based [8] termination argu-
ments offer possibilities for further improving precision of the ter-
mination oracle.
Recent work on conditional termination [20] statically computes
preconditions under which a program terminates.
Incorporating
these results may lead to more efﬁcient ways to incorporate low-
security information at runtime.
Quantitative bounds Our budgeted semantics enforces a simple
quantitative bound on the amount of information that may be leaked
via a progress channel. Here, our information-theoretic bound of
log2(B + 1) bits of progress leakage is similar in spirit to the
890bounds presented by Zhang, Askarov, and Myers [5, 57]. A log-
arithmic bound is also given by Rafnsson and Sabelfeld [40]; they
buffer outputs and give the bound in the number of the buffered
output batches.
Much recent work on quantitative information ﬂow focuses on
what the attacker may learn about the secrets based on a single
observation [49, 30]. Incorporating these results provides an inter-
esting avenue for future work.
Smith and Alpizar study non-termination of probabilistic pro-
grams [50]. They demonstrate that when probability of nontermi-
nation in well-typed programs is small, nontermination does not
skew the probability distribution of low outputs. A key technical
element of their proof machinery is a program transformation that
eliminates all high computations in a program. These results ap-
pear particularly relevant for understanding computational security
guarantees of programs that use cryptographic primitives (which
would otherwise be formulated “modulo termination”).
Timing channels Timing channels are known to be a dangerous
covert channel in computer systems. Exploiting timing channels
requires a strong adversary who has access to an external clock in
order to measure timing of the individual outputs. Compared to
that attacker model, we assume a weaker but more widespread at-
tacker who is limited to counting the number of low outputs. This
attacker model is fairly common in both traditional systems as well
as cloud-based batch services, e.g., map/reduce. Because our at-
tacker model considers only a speciﬁc aspect of low observations,
a more precise characterization of security is possible. Indeed, the
information-theoretic bound on the progress channel that we ob-
tain in this work is tighter than the one used in general mitigation
of timing channels [5, 57].
Auditing for information ﬂow Work on auditing systems for
information ﬂow violations pivots around explicit ﬂow violations
(e.g., [36]) or audit of authority decisions for declassiﬁcation [39,
9, 15]. Our work provides means for auditing progress channel vio-
lations. The semantics for low outputs can be augmented to record