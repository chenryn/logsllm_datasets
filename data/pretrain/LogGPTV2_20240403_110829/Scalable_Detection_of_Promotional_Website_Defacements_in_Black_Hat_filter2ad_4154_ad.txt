### DMOS and DMOS_V2: Jargon Normalization and Performance

DMOS and its updated version, DMOS_V2, enhance the performance of the THAN/BERT models by normalizing jargon before classification. By identifying and learning the semantics of jargon, both versions achieve superior results, as demonstrated in Table 2. The introduction of Jargon Normalization (JNA) increases the precision of THAN from 91.29% to 94.89%, reducing manual efforts for verifying false alarms by over 41%. Similarly, JNA improves the precision of T-BERT from 95.66% to 97.53%, cutting false positives by over 43%.

### Online Experiments

#### Business Model and Performance Analysis

In this section, we introduce the business model of the DMOS service and analyze its performance based on Figure 6, which illustrates the features learned by THAN. The figure shows tags and corresponding sentences in Chinese on the left, with their English translations highlighted in the same color on the right.

#### Offline Testing Dataset

The offline testing dataset consists of 20,958 defaced pages and 40,426 legitimate ones. This dataset is used to evaluate the performance of DMOS and other detection schemes.

### Comparison with Other Detection Schemes

We compare DMOS with several state-of-the-art solutions in malicious web content detection:

- **WAF**: Most WAF vendors use a keyword-searching approach. We tested a WAF device from a major Chinese vendor without further training.
- **Saxe et al. [39]**: This method divides documents into sub-regions and uses deep learning to aggregate and classify them. We re-implemented their detection scheme.
- **BoW Model**: We used TF-IDF to extract important words and XGBoost for classification.
- **HAN [46]**: We reproduced the HAN network for defaced web page classification.
- **FastText [31]**: A simple and efficient neural network text classification model, using its open-source library.
- **BERT [24]**: A multi-layer bidirectional Transformer, fine-tuned for various NLP tasks. The training process is detailed in Section 3.3.4.

All baseline models (except the black-box WAF) were trained on the same dataset and fine-tuned for optimal performance. As shown in Table 2, DMOS outperforms all baselines across multiple metrics.

### Online Testing Results

Table 3 summarizes the online testing results over five months. DMOS classified 38,526,989 web pages (after deduplication) across 7,298 websites, identifying 532,021 defaced pages among 824 websites. DMOS outperforms the widely-used WAF in recall, F1 score, and overall detection accuracy, though it has slightly lower precision. Over 90% of false positives occur in just 67 websites, suggesting that a whitelist-based approach can mitigate these issues.

### Deployment and Usage

#### Scheduler and Defacement Detection

To handle the large volume of web pages, we use Kafka to distribute incoming pages to available DMOS instances. Each instance consumes 1.2GB of memory, and the classification of each web page takes an average of 0.3 seconds. This efficiency allows DMOS to analyze millions of web pages daily.

#### Manual Verification

For accurate ground truth, we manually checked every page reported by DMOS and WAF. We estimated false negatives by filtering out innocent pages and performing sampled manual checks. This process was conducted daily by specialized data annotators during our five-month experiment.

#### Longitudinal Study

To measure the impact of concept drift, we performed a five-month longitudinal study. DMOS maintained stable performance, with recall consistently above 99% and precision stabilizing around 88% after a slight initial decrease. Periodic fine-tuning with new data can maintain or even enhance DMOS's performance.

### Comparison with Online URL Checkers

We compared DMOS with popular online URL safety-checking tools from Baidu, Tencent, and VirusTotal. Due to API query limits, we checked hundreds of URLs. Table 4 shows that DMOS significantly outperforms these tools in various metrics.

### Adaptation for Other Languages

While our focus has been on Chinese web pages, DMOS can be adapted for other languages with the following steps:

- Collect datasets for training.
- Replace the jargon normalization algorithm with language-specific de-obfuscation techniques if necessary.
- Use language-specific word embeddings and train the THAN model as usual.

We demonstrate the adaptation of DMOS for detecting defacements in English web pages, showing its generalizability and effectiveness across different languages.