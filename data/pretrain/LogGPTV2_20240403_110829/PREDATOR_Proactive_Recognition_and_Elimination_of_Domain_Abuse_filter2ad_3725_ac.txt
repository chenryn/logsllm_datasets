and we assign a default value (0 in our experiment).
Previous registrar (categorical). The previous registrar offers some
insight from where and how spammers gather the expired domain
information. We map previous registrars to a group of binary features.
Only the feature corresponding to the previous registrar is set to 1,
and the others have values 0. We handle brand-new domains whose
previous registrar ﬁeld is not applicable by simply adding a dummy
registrar feature.
Re-registration from the same registrar (categorical). We add
features to explicitly indicate whether the registrar of a re-registration
domain is the same registrar of the previous registration. We observe
that in the .com zone2 18% of non-spammer retread domains use the
same previous registrar, while only 4% of spammer retread domains
do so, presumably because miscreants choose particular registrars
(Section 5.1), which are unlikely to be those used by prior legitimate
registrants. We use a dummy value to deal with brand-new domains.
5.3 Batch Correlation Features
Batch correlation features examine domains within the same tuple
(cid:104)registrar, ﬁve-minute epoch(cid:105), which we deﬁne as a batch. The batch
information is initially known by registrars or registries.
Probability of batch size (continuous). Miscreants often register
domains in large batches, presumably due to cheaper price of bulk
registration or management ease. We identify the qualitatively differ-
ent registration behavior by using the model of compound Poisson
process, deﬁned as in Hao et al. [20]. A low-probability batch size
from the model indicates an abnormally large registration spike. We
use the probability as a feature in our system.
Life-cycle proportion (continuous). As mentioned before, the regis-
tration history can characterize a domain as brand-new, drop-catch,
or retread. Miscreants tend to register domains in a particular part
of the domain life-cycle in a single batch due to how they select the
names. We generate three features, each measuring the proportion
of different life cycles for domains in the same batch. These three
features sum to 1 by construction.
Name cohesiveness (continuous). Spammer domains registered in
the same batch will sometimes have names lexically similar to one
another, as miscreants use the same strategy or generation algorithm
to produce a list of domains. To quantify the cohesiveness of the given
domain name with respect to all other domain names in the same
batch, we compute the edit distances of the domain to every other
domain in the batch. We normalize these edit distances by dividing
the length of the domain name to provide a similarity score. We
2Our data has no previous registrar information on .net, per Sec-
tion 7.1.
then compute ten features as the numbers of domains with similarity
between [0, 0.1], [0, 0.2], . . . , [0, 1.0]. We use the logarithmic scale
to account for the large variability of the batch sizes.
6. CLASSIFIER DESIGN
This section introduces the Convex Polytope Machine (CPM), a
supervised learning algorithm that we use (including our rationale
for selecting this algorithm); the process of building the detection
models; and the derivation of feature importance based on the models.
6.1 Supervised Learning: CPM
We want a classiﬁer that can quickly train over large sets of data
and achieve high accuracy. While linear Support Vector Machines
(SVM) [12, 47] or comparable linear methods are often used in such
high performance settings, nonlinearities in our data raise difﬁcul-
ties for SVM-style approaches. Instead, we employ a state-of-the-
art supervised learning algorithm, the Convex Polytope Machine
(CPM) [30]. CPM maintains an ensemble of linear sub-classiﬁers,
and makes its ﬁnal decision for incoming instances based on the
maximum of all of their scores. More formally, suppose x ∈ Rd is an
instance of d features, and w1, . . . , wK ∈ Rd represent the weights
of the K sub-classiﬁers. We derive the score of x as:
f (x) = max
1≤k≤K
(cid:104)x, wk(cid:105)
The prediction score of f (x) reﬂects how likely a domain is registered
for spam-related activity. Geometrically, a CPM deﬁnes a convex
polytope as the decision boundary to separate the two instance classes.
In our application, it appears that this richer, non-linear decision
boundary gives us high classiﬁcation accuracy. Training of a CPM can
be efﬁciently achieved by using the gradient descent technique [47].
To assess our design choice, we tested SVM [12] using libsvm
with parameters tuned to our application. We found that in the
low-false-positive region of operation, CPM produced a 10% higher
true-positive rate, and trained faster than an SVM.
6.2 Building Detection Models
The ﬁrst step of building the model is to normalize the continu-
ous and ordinal features. We transform real values into the [0, 1]
interval to ensure that they do not overly dominate categorical fea-
tures. We compute the ranges for each of the continuous and ordi-
nal features to obtain max/min values, and normalize feature v to
(v − vmin)/(vmax − vmin). Since the categorical features are in
binary, we do not need additional normalization process.
We adapt a sliding window mechanism for re-training models
and evaluating the detection accuracy close to the real-deployment
training (cid:52)Ttrain, cooling
scenario. We deﬁne three windows:
(cid:52)Tcool, and testing (cid:52)Ttest. As shown in Figure 3, suppose at
round N the training window starts at time TN . The model will
Zone updateRound NTrainingCoolingTestingZone updateTrainingCoolingTestingRound N+1Ground truth for trainingGround truth for testingGround truth for trainingGround truth for testingBlacklist feedsBlacklist feedsTNTN!TN!TN△Tcool△Tcool△Ttrain△Ttrain△Ttest△TtestTimedomains registered during [TN , TN +(cid:52)Ttrain]. Since this approach
requires time to corroborate that a domain is indeed involved with
spam-related activity, especially based on observations from blacklists,
be constructed at time (cid:98)TN = TN + (cid:52)Ttrain + (cid:52)Tcool, with the
we use the ground truth collected during the period [TN ,(cid:98)TN ] to label
real-time prediction on those domains registered during [(cid:98)TN ,(cid:98)TN +
blacklists from time (cid:98)TN up to our last collection date of the blacklists.
(cid:52)Ttest, which makes the new model build at time (cid:98)TN + (cid:52)Ttest.
domains to build the model (in the training mode). In the testing
period (corresponding to the operation mode), PREDATOR makes
(cid:52)Ttest]. The ground truth that we use in the testing period to evaluate
the detection accuracy is composed of the domains showing on
In the next round, N + 1, we move the time window forward by
The period (cid:52)Ttest indicates how frequently we re-train the model.
Operators can customize the three window lengths according to
different requirements and settings (see Section 7.4).
6.3 Assessing Feature Importance
Given a subset S ⊂ {1, . . . , d} of features, a derived CPM model
{w1, . . . , wK}, and a dataset of points {x1, . . . , xn}, we derive
a measure to evaluate the importance of the set of features in our
classiﬁer. If the model weights have large magnitudes while at the
same time the associated features have low variance, i.e., they are
essentially constant, these dimensions are not particularly informative
and should receive a low importance score. We design a scoring
method to measure the total amount of variation on the score f (x)
over the dataset induced by the features S. In the case of a single
linear classiﬁer (K = 1), we measure this quantity as:
(cid:118)(cid:117)(cid:117)(cid:116)Var
x
(cid:34)(cid:88)
i∈S
I 1
S =
w1
i xi
(cid:35)
To generalize this measure to the case K ≥ 2, for each sub-classiﬁer
k, we compute the score I k
S based on its subset of assigned instances
Ak, and combine the scores.
(cid:114)|A1|
(cid:118)(cid:117)(cid:117)(cid:116) 1
K(cid:88)
n
n
k=1
IS =
=
I 1
S + . . . +
|Ak| Var
x∈Ak
|AK|
n
(cid:34)(cid:88)
i∈S
(cid:35)
I K
S
wk
i xi
where Ak is composed of x, satisfying k = arg maxk(cid:48)(cid:104)wk(cid:48)
, x(cid:105).
Higher values of IS indicate that the feature group S contributes
more on the decision-making. We demonstrate the feature importance
in Section 7.4.
7. EVALUATION
In this section, we report our evaluation results, compare the
performance of PREDATOR to existing blacklists, and analyze the
evasion scenarios.
7.1 Data Set and Labeling
Our primary dataset consists of changes made to the .com zone,
the largest TLD [60], for a ﬁve-month period, March–July 2012.
We obtain the DNZA ﬁles from Verisign (which have ﬁve-minute
granularity), ﬁnd the registrations of new domains, and extract the
updates of authoritative nameservers and IP addresses. During March–
July 2012, we have 12,824,401 newly registered second-level .com
domains. To label the registered domains as legitimate or malicious,
we collected public blacklisting information from March–October
2012 (eight months), including Spamhaus [49] (updated every 30
Figure 4: ROC of PREDATOR on .com domains. The inlay
ﬁgure shows the ROC curve under the range of 0–5% false pos-
itives.
Page content of domain
Advertisement links
Lottery, survey, and coupon
Adult content
Merchandise
Pharmaceutical
Download of Software and ﬁles
Online gambling
No obvious spam-related content
Percentage
38%
7%
7%
7%
6%
5%
4%
26%
Table 4: Breakdown of manually checking 100 random samples
of unlabeled domains that PREDATOR classiﬁes as malicious.
(Note that pages with no obvious spam-related content might
still host other malicious activities such as drive-by downloads.)
minutes), URIBL [56] (updated every 60 minutes), and a spam trap
that we operate (real time). If a domain appeared on blacklists after
registration, we label the domain as being involved in spam-related
activities and registered by miscreants. To obtain benign labels, we
queried McAfee SiteAdvisor [48] in June 2013 to ﬁnd the domains
that are reported as deﬁnitely benign. Eventually we have about 2%
of .com domains with malicious labels and 4% with benign domain
labels. We discuss the prediction results on labeled and unlabeled
domains respectively in Section 7.2.
We also obtain the DNZA data of .net zone for ﬁve months, from
October 2014 to February 2015, which contain 1,284,664 new do-
mains. We used similar blacklists (URIBL and our spam trap) from
October 2014 to May 2015 (eight months) to label malicious domains
and queried McAfee in November 2015 to ﬁnd benign labels. How-
ever, the information for .net domains is not complete, which just
allows limited analysis on .net domains. We only have Spamhaus
snapshot on December 7th 2015 (instead of a continuous feed), and
the previous registrar information is not available.
7.2 Detection Accuracy
We demonstrate the accuracy of PREDATOR in terms of false
positive rate, which is the ratio of benign domains misclassiﬁed as
malicious to all benign instances; and detection rate, which accounts
for the ratio of correctly predicted spammer domains to all spammer
domain samples. By setting different thresholds, we make tradeoffs
between false positive rates and detection rates.
For .com domains, we use data from March 2012 to extract the
known-bad domain set and derive probability models for registration
batches, and take April–July 2012 for our experiments. We used the
sliding window method (introduced in Section 6.2) and tested different
window lengths, where better results resulted from longer training
windows (i.e., more domains for training) and shorter testing windows
False positive (%)0102030405060708090100True positive (%)010203040506070809010000.511.522.533.544.55020406080100Figure 5: Distribution of days between domain registration and
appearance in either our spam trap, URIBL, or Spamhaus,
which indicates how early PREDATOR can make detections
compared to the existing blacklists (no Spamhaus timing infor-
mation on .net).
(i.e., more frequent re-training). We demonstrate the performance
results of PREDATOR with the setting of the training window to 35
days, the cooling window to 1 day, and the testing window to 7 days,
which produces good detection accuracy and allows realistic operation
(see Section 7.4 for detailed discussion on window selection).
Figure 4 shows the ROC curve of PREDATOR. The x-axis shows
the false positive rate, and the y-axis shows the detection rate. The
inlay ﬁgure shows the ROC curve for the range of 0–5% false positives.
PREDATOR achieves good detection rates under low false positives.
For example, with a 70% detection rate, the false positive is 0.35%.
We emphasize that these results only rely on features constructed
from the limited information available at registration time. Thus,
as an early-warning mechanism, PREDATOR can effectively detect
many domains registered for malicious activities.
Results on the entire .com zone. We project the 0.35% false pos-
itive to the entire .com zone. Since there are around 80,000 new
domains everyday, the daily false positives are about 280 domains
(as an upper estimate, assuming all domains are benign). Given that
even the known spammer domains totalled more than 1,700 every
day, PREDATOR can greatly help to narrow down the set of suspect
domains. We ran additional tests to examine how many unlabeled
domains are classiﬁed as spam-related by using the constructed de-
tection model on the entire zone dataset, about seven million .com
new domains registered over three months. With a threshold under
a 0.35% false positive rate (in Figure 4, obtaining a 70% detection
rate), PREDATOR reports about 1,000 unlabeled domains per day as
spam-related, the same magnitude as the labeled spammer domains
(1,700 per day). Overall, PREDATOR predicts 3% of all newly regis-
tered .com domains as malicious, which capture 70% of the malicious
domains showing up later on blacklists. As a ﬁrst line of defense,
PREDATOR can effectively reduce and prioritize suspect domains
for further inspection (e.g., URL crawling or manual investigation)
and ﬁnd more malicious pages given a ﬁxed amount of resources. In
Section 7.3, we investigate to what extent the unlabeled domains that
PREDATOR classiﬁes as malicious indeed connect to illicit online
activities while missed by current blacklists.
Detection accuracy on .net domains. We performed a similar
experiment to report the detection accuracy on .net zone (ﬁve months
in 2014–2015). Due to data limitation, two features, the previous
registrar and re-registration from the same registrar, are unavailable,
and in the blacklists Spamhaus only has a single snapshot. With
the same sliding window setting, the detection rate on .net domains
is 61% (close to the 70% on .com domains) under a 0.35% false
Figure 6: ROC of PREDATOR using domains that Spamhaus
blacklisted within the ﬁrst 2 hours of registration and after the
ﬁrst 2 hours of registration for labels.
Testing
window
Training
window
35 days
21 days
14 days
7 days
35 days 56 days
70.00% 68.29% 66.81%
67.10% 64.96% 60.56%
64.13% 60.51% 58.22%
Table 5: Detection rates (under a 0.35% false positive rate) with
different window settings. With shorter training windows and
longer testing windows (i.e., less frequent re-training), the pre-
diction will become more inaccurate. Our experiments show
that the performance is not overly sensitive to the window set-
tings.
positive rate. The result shows that PREDATOR can successfully
make prediction at different zones. In the rest experiments, we focus
on .com domains (.net domains either yield similar results or cannot
conduct the analysis due to data defect).
7.3 Comparison to Existing Blacklists
We investigate and compare different blacklists and ﬁnd that
PREDATOR can help to mitigate the shortcomings of current black-
listing methods and detect malicious domains earlier.
Detection of more spammer domains. The ﬁrst property we exam-
ine is completeness, which explores how many spammer domains
PREDATOR detects compared to other blacklists. We ﬁnd that during
May–July 2012, the exclusive blacklisted .com domains (i.e., not
reported by other feeds) on Spamhaus, URIBL, and our spam trap
number 24,015, 4,524, and 442 respectively. Each blacklist has many
domains not identiﬁed by other sources, which indicates the existing
blacklists are not perfect to detect all malicious domains. Having
incomplete blacklists makes it quite challenging to develop more
accurate registration-time detection, and also shows how PREDATOR