### Describe your issue.
One way to speed up scipy.optimize.minimize is to compute the gradient when
computing the function value. Because most of the computation are shared, this
nearly half the amount of time required.
Although shgo document this under the "options" parameter, it actually doesn't
work: _shgo_lib/triangulation.py tries to compare the results when calling the
function twice. But because the result is a numpy array, it fails with a
ValueError: "The truth value of an array with more than one element is
ambiguous. Use a.any() or a.all()".
### Reproducing Code Example
    import numpy as np
    from scipy.optimize import minimize, shgo
    def f(x):
        return np.sum(x * x), 2 * x
    # This succeeds
    print(minimize(f, [0.5, 0.5], jac=True))
    # This fails
    print(shgo(f, [(-1., 1.), (-1., 1.)], options={'jac': True}))
### Error message
    File .../scipy/optimize/_shgo_lib/triangulation.py:597, in (.0)
        595 """Check whether this vertex is strictly less than all its neighbors"""
        596 if self.check_min:
    --> 597     self._min = all(self.f < v.f for v in self.nn)
        598     self.check_min = False
        600 return self._min
    ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
### SciPy/NumPy/Python version information
1.7.3 1.21.6 sys.version_info(major=3, minor=9, micro=5, releaselevel='final',
serial=0)