tical ones with a mark including the distance between these
two and the length of the repeated contents. After obtaining
the preprocessed ﬁle, Gzip then uses Huffman algorithm [30]
to encode characters. The more frequently occurring charac-
ters in the ﬁle are encoded with fewer bits, thus compressing
the ﬁle further. The mapping between a single character and
its encoding will be recorded into a table, which is usually
referred as the reference table.
ML based lossless compression. DeepZip [19] is state-of-
the-art ML based lossless compression method. It uses a
DNN and arithmetic encoding to better locate the statistical
redundancy in inputs and improve compression effectiveness.
DeepZip ﬁrst determines a ﬁxed-window size n, and uses a
sequence of n characters in the input as an input to the DNN.
Based on the given input, the DNN is trained to predict the
distribution of the next character with a standard backward
propagation method. Then, the arithmetic encoder encodes
the character using the obtained predicted possibility distribu-
tion. If the character is predicted accurately, i.e., the character
has the highest predicted value, it will be encoded with the
fewest number of bits using arithmetic encoding.
Arithmetic encoding works differently from Huffman en-
coding, and is also used by many existing compression meth-
ods [9, 61]. It uses a probabilistic model that constantly up-
dates the occurrence probability of each character at the cur-
rent location based on the prediction of a certain predictor, and
encodes them so that a character with a higher predicted prob-
ability will get fewer bits. As a result, better prediction results
will lead to lower compression ratios, and it can guarantee
that the compression is lossless.
2.2 Log Compression
Traditionally, Gzip is the most widely used method for log
compression [12,52]. However, its compression ratio is higher
than ML based methods. Existing work observed that DNN
based lossless data compression methods can achieve far bet-
ter results than Gzip because of the capability of identifying
statistical redundancy in data. Our evaluation results (see Sec-
tion 4) also conﬁrm such ﬁndings. For example, on Linux
system log, DeepZip and Gzip achieve 1.60% and 3.57%
compression ratio, respectively. Namely, ﬁles compressed by
DeepZip take less than half space compared with Gzip. Con-
sidering the log size in large enterprises can be in PB or even
larger, such a lower compression ratio can lead to signiﬁcant
savings in storage maintenance.
Despite the amazing effect in compressing textual data,
DNN based compression methods have not been widely used
in log compression. This is mainly because of its low efﬁ-
ciency. As shown in Section 4.3, DeepZip takes several hours
to compress a small log ﬁle, e.g., 12.7 hours for a 0.8 GB ﬁle,
which is unacceptable. The decompression process also takes
longer time compared with methods like Gzip. Besides, ex-
isting compression methods are designed for general textual
data, and do not leverage the domain knowledge of log ﬁles,
which leads to non-optimal compression ratios.
USENIX Association
30th USENIX Security Symposium    3025
2.3 Motivating Example
Motivated by the fact that all existing log collection systems
are not storage efﬁcient, we propose ELISE to solve this prob-
lem. Figure 1 illustrates how different methods work on a
simpliﬁed log entry from the Linux Auditd system. It logs a
system call event with syscall number 20 (syscall and type)
and related context including pid, timestamp (ts), sequence
number of this log entry in this logging session (counter),
ﬁle paths (path) and so on.
The compression process can be roughly divided into three
steps. The ﬁrst step is to preprocess the original log from its
original format to a compression friendly format. The second
step is to produce an encoder that knows the representation of
the log. The last step is to encode the log with the encoder and
compress it. Gzip uses a deterministic encoding algorithm
(i.e., Huffman encoding), so it does nothing in step 2. DeepZip
does not perform any analysis on the original log ﬁle, and it
has no preprocessing logic. ELISE has its own preprocessing
step and an improved training procedure in step 2.
Gzip. The workﬂow of Gzip is shown in Box A of Figure 1.
In the preprocessing step, Gzip leverages the LZ77 algorithm
to replace repeated strings. LZ77 algorithm uses a buffer to
store recently scanned data and looks for new common sub-
strings that are longer than a threshold (typically 3). When
such a substring is found, LZ77 will replace it with a mark
which is shorter than the substring (i.e., the substring length
threshold has to be larger than the length of the mark). For the
given example in Figure 1, LZ77 can ﬁnd that syscall is a
repeated string in 1 , and then replaces it with the new mark
(16,7). The ﬁrst number in this mark denotes the distance to
the last appearance of this string (i.e., the second syscall
is 16 characters away from its last appearance), and the sec-
ond number represents the length of this repeated string (i.e.,
syscall is a 7-char long string).
In the log compression step (step 3), Gzip applies Huffman
encoding to compress the log ﬁle. Huffman encoding counts
the frequency of all characters in the ﬁle and encodes more
frequent characters with shorter binary codes to ensure that
the number of bits needed to encode the entire ﬁle is the
minimal. For example, digit 6 has higher frequency than 1,
and as a result, encoding of 6 (i.e.,“10”) is shorter than that
of 1 (i.e., “110”). Moreover, such binary formats are shorter
than the original encoding where all characters have the same
length of binary bits.
DeepZip. In Figure 1, Box B presents the overview of
DeepZip. It does not perform any preprocessing for the tar-
get ﬁle 3 . It trains a DNN based classiﬁer as encoder on
the given log ﬁle. The DNN takes a string in the log ﬁle as
input and tries to predict the next character. For example, it
uses the sequence counter:13,syscall:20,type:syscal
to predict the next character. The output of the model will
give a probability pair (low,high) for all possible characters.
In this case, it assigns (0.1,0.7) to letter “l”. The ﬁrst value
denotes the sum of probabilities for all characters before “l”
(e.g., letters a to k), and the second value adds the probability
of letter “l”. In this case, the probability of the next letter
being letters before “l” is 0.1 and letter “l” itself is 0.6, thus
the second value is 0.7.
DeepZip uses arithmetic encoding to compress logs in step
3. A detailed example of arithmetic encoding is described
in Section 3. Compared with Gzip, DNNs have better dis-
tribution estimations for characters than Huffman encoding,
enabling lower compression ratios.
ELISE. Because of DNN based encoder, DeepZip is more
effective in compressing ﬁles compared with Gzip. However,
we observe that DeepZip is still not optimal. Firstly, DeepZip
works on non-optimal log formats. Logs are highly redundant,
and DeepZip ignores such redundancy. Secondly, training a
good DNN model in DeepZip is very difﬁcult and resource
consuming. This is because it directly trains on all possible
characters, and the input space is huge.
Log ﬁle is a special type of inputs for compression tasks.
It has a few unique characters. Firstly, all log ﬁles can be or
have already been well formatted. Entries in a log are usually
generated by printf-family functions or similar libraries
in other programming languages. These functions require a
format string, which essentially provides a template to parse
the log entry [65]. Existing projects like LogStash [1] can
help format log ﬁles from various sources. Secondly, log ﬁles
have a limited vocabulary. Besides words in log statement
templates, variables in each log entry are mostly either well
formatted (e.g., IP addresses) or consistently appear in the log
(i.e., process names).
Based on the analysis of existing methods and log ﬁles,
we propose ELISE (BOX C in Figure 1). It features a prepro-
cessing step that reduces all structural redundancy from log
entries, which effectively reduces the ﬁle to compress; and
converts all strings/characters to a numerical representation,
which reduces the input/output space for DNN based encoder
and numerical values make it easier to train. For the example
in Figure 1, ELISE applies four different preprocessing rules
to convert the entry to a much shorter one, and also converts
them into numerical formats making it easier to train the en-
coder. The DNN training and encoding steps are very similar
to that of DeepZip. But with modiﬁed log Entries, it can com-
press the log with shorter bit strings and a faster speed. Based
on our evaluation in Section 4, ELISE is around 5.63 times
faster than DeepZip.
Compared with Gzip, DNN based encoding has a stronger
capability of capturing information redundancy and provides
better encodings, and hence has lower compression ratios [19].
That is why both DeepZip and ELISE have lower compres-
sion ratios than Gzip. ELISE further improves DeepZip by
applying preprocessing rules to capture different levels of
redundancy and converting all data into numerical formats to
improve the training speed.
3026    30th USENIX Security Symposium
USENIX Association
Figure 1: Example of Gzip, DeepZip and ELISE.
3 Design of ELISE
In this section, we ﬁrst give an overview of ELISE design
and a deﬁnition of our threat model, and then introduce each
component including preprocessing, DNN based encoder and
data compression and decompression.
3.1 Overview of ELISE
The overall workﬂow of ELISE is shown in Figure 2. After re-
ceiving logs from various sources, ELISE ﬁrst converts them
into a united format, and then splits large ﬁles into small ones
for concurrent processing (component A in Figure 2). Then,
the log ﬁles are preprocessed to remove the redundancy (com-
ponent B). For each of them, we train a small DNN as its
encoder (component C). When compressing the log, we lever-
age the trained encoder and arithmetic encoding to produce
the ﬁnal output. The dashed box includes all the artifacts (in-
cluding a DNN model, a reference table and the compressed
data ﬁle) that are required to reproduce the raw log. In the fol-
lowing sections, we will introduce each component and how
ELISE can be deployed in real world scenarios (e.g., avoiding
retraining for all ﬁles and improving prediction accuracy to
improve compression performance).
Scope of the paper. ELISE is designed to be part of an en-
terprise security infrastructure. It provides the capability of
storing large size logs with the minimal space without infor-
mation loss. ELISE is suitable for enterprise level systems
which generate a large amount of log data and store them for
various analysis, and hence the storage overhead is high. Also,
ELISE is designed for centralized log storage. Namely, instead
of storing logs on individual end user computers or servers,
logs from different sources are stored in a well protected
server. This is a common practice for modern enterprises. A
centralized server can provide better data integrity protection
and storage optimization. ELISE guarantees the integrity of
logs during its processing, and assumes the integrity of logs
from sources (both in compression and decompression).
3.2 Log Formatting
ELISE accepts logs from different sources, and the ﬁrst job it
does is to normalize them into the same format. To do this,
ELISE leverages LogStash [1] to convert all ﬁles to JSON
format. Yuan et al. [65] demonstrated that most logs are gen-
erated by the printf-family functions or their variants in
other languages. Such logs use the format string as their
ﬁrst parameter. As a result, log entries can be organized in
a (key:value) pattern with constant strings in the format
string as keys and runtime variable values as values. Thus,
JSON is commonly used to store logs. LogStash is a log nor-
malization tool which can parse log and convert their formats
based on given rules. It has built-in support for many popular
applications and systems already. After formatting all logs,
ELISE also splits the large ﬁles into smaller ones to enable
parallel data compression and achieve high efﬁciency.
USENIX Association
30th USENIX Security Symposium    3027
0.002021875…00000000070.004751168...000000002'0': (0, 0.1)...',': (0.1, 0.9)...Final ResultModel Prediction A.  GzipStep1: PreprocessingStep2: Obtaining EncoderStep3: Log Compressionpid,ts,...,pathpid:50, ts:159.2, counter:13, syscall:20, type:syscall, path:/usr/local/A, path:/usr/local/B...LZ77Repeated StringsDNN Model...1.0, 2...1.0② ..., counter:13,syscall:20, type:(16, 7)...② ..., counter:13,syscall:20, type:(16, 7)...DATA. Simplified LogB.  DeepZipC. ELISEA. 1A. 2A. 3C. 1C. 2C. 3's': (0.1, 0.9)...'l': (0.1, 0.7)...Model Prediction Final ResultDNN Model...syscal l...syscal③ ..., counter:13, syscall:20, type:syscallB. 1B. 2B. 3① ..., counter:13, syscall:20, type:syscall...'1':'110', '6': '10','7': '01'......1101001...Final ResultHuffman EncodingCounting Frequency0A,0Bpid:50ts:159.2Counter:13[0]1.0, 20/usr/local/A/usr/local/BRule 1Rule 2Rule 4Rule 30A,0Bpid:50ts:159.2Counter:13[0]1.0, 20/usr/local/A/usr/local/BRule 1Rule 2Rule 4Rule 3Figure 2: Workﬂow of ELISE.
3.3 Log Preprocessing
Before obtaining the encoder and compressing the log ﬁle,
ELISE ﬁrst applies a set of rules to remove the redundancy
and prepare them for DNN based encoder training.
Preprocessing 1: Key patterns. Different from other rules,
preprocessing rule 1 focuses on reducing keys belonging to
the same type of log entries (e.g., the keyword “pid”, “ts” and
“path” in system logs) with short numerical codes. Other pre-
processing rules reduce redundant values (e.g., the pid number
“50”). Recall that each log entry consists of a constant tem-
plate part and some runtime variable values (Section 3.2).
There are a limited number of templates in a program, but
they can generate countless log entries. Even though the log
formatting step in ELISE can remove some redundant items
(e.g., by shrinking a natural language sentence to a single
word), the JSON log ﬁle still has a lot of redundancy, espe-
cially the repeated keywords and their orders. For example,
in Linux Auditd logs, there are only four different types of
logs despite millions of entries.
ELISE automatically converts all ﬁxed keywords into a nu-
merical sequence with the minimal number of digits. For ex-
ample, the log entry (pid:50, ts:159.2, counter:13,
syscall:20, type:syscall, rs:success) will be
converted to a new string (0: {50, 159.2, 13, 20,
syscall, success}) with a reference code r. Then, we
create a reference table containing the rule to convert the nu-
merical value back to its original format. In this case, we mark
the rule corresponds to the reference code r as (0) r(cid:55)−→ (pid,
ts, counter, syscall, type, rs). During decompression, ELISE
will query the reference table to ﬁnd the translation rules and
then apply them. To automatically discover such keys, we
leverage LogStash rules. When LogStash parses the log, it
also detects the constants and variables in these entries, and
ELISE directly uses the constants keys in the converted log as