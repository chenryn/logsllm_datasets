retained invalid pages to new free blocks. For those valid pages,
their corresponding mapping entries in 1 are updated and pointed
to the new PPAs. The retained invalid pages will be kept in the
Figure 4: The structure of the out-of-band (OOB) metadata in
each physical page. It includes the LPA mapped to this physi-
cal page, the previous physical page address (P-PPA) mapped
to the current LPA, the timestamp when the page is written,
the retained invalid page (RIP) bit indicating whether this
page should be retained if it becomes invalid.
The RTT organizes entries in the way of the PVT 4 , except
that each entry in the RTT is a read bitmap3 indexed by a block
address. With the same optimization used in PVT, RTT enables
RFTL to access and update the bitmap in an efficient manner. We
use a buffer (4 KB in RFTL) to cache the frequently accessed RTT
entries, which introduces only a small storage overhead in SRAM.
5.2 Read and Write Operations in RFTL
In this section, we describe how RFTL performs I/O requests in
cooperation with the data structures discussed in § 5.1.
Read operation: When a read request to page X is received, RFTL
first looks up the LPA in the cached address mapping table 1 . If
it is a cache miss, it searches the corresponding translation page in
the GMD 2 to locate the mapping entry for X in the translation
page. During this process, the RFTL also places the mapping entry
in the LRU cache for the address mapping 1 . If it is a cache hit
when accessing the cached address mapping table 1 , the read
operation will be issued directly. After locating the PPA of page X
for serving the read operation, the RFTL updates the read bitmap
in RTT 5 and sets the corresponding bit to 1 to indicate that the
corresponding physical page has been read.
Write operation: When receiving a write request, RFTL performs
the same address lookup procedure as for read in the cached ad-
dress mapping table 1 . If the mapping entry exists in the LRU
cache, the data is written to a new free page, the address mapping
entry is updated with the new PPA. Otherwise, a new mapping
entry is created. The updated or newly created mapping entries are
propagated to the translation pages and GMD 2 when they are
evicted from the cached address mapping table 1 .
To enable the reverse mapping from the physical page in SSDs
to logical page in file systems for data recovery, RFTL stores the
metadata information of a page in its out-of-band (OOB) metadata.
The commodity SSDs typically reserve 16-64 bytes OOB metadata
for each physical page. FlashGuard leverages this space to store the
metadata information about a page as shown in Figure 4.
The OOB metadata includes (1) the LPA mapped to this physical
page, (2) the previous PPA (P-PPA) mapped to the current LPA (it
is used when a page is overwritten and it enables FlashGuard to
3In FlashGuard, we use a bitmap carries 64 bits because each block contains 64 pages.
DataOOBPhysical Block Physical Page LPARIPTimestampP-PPA4Bytes1Bit4Bytes4BytesAlgorithm 1 Garbage Collection in RFTL
Input: ReserveT ime = the time threshold for retaining invalid pages
Reserved = the bit flag indicating a page is invalid but retained
1: Select the candidate block for GC
the candidate block has the least number of valid pages and
retained invalid pages.
▷
Check page’s RIP bit
if RIP == Reserved then
Copy page to a new free page
Update address mapping entry
Check read tracker table (RTT)
if page has been read then
Check page’s OOB metadata
Verify page’s validity
if page is valid then
2: Check PVT to find valid pages in candidate block
3: for each valid page do
4:
5:
6:
7:
8:
9: for each invalid page do
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
Discard and reclaim this page
else
else
else
page_timestamp← timestamp in page’s OOB metadata
if current_time - page_timestamp < ReserveTime then
Clear this page’s read bit in the bitmap of RTT
Copy page and its OOB metadata to a new free page
Set the new page’s read bit in RTT to 1 (Read)
Discard and reclaim this page
Clear this page’s read bit in the bitmaps of RTT
Set metadata (timestamp←current_time, RIP←Reserved)
Clear this page’s read bit in the bitmaps of RTT
Copy page and its OOB metadata to a new free page
Set the new page’s read bit in RTT to 1 (Read)
However, these blocks will not be frequently garbage collected
because of the throttling and swapping mechanisms in the existing
GC design: cold data (i.e., not frequently accessed data) is migrated
to old blocks (i.e., blocks that experience more wear). The blocks
which have many retained invalid pages will be accessed less fre-
quently, and the chance that they will be collected shortly is small.
In addition, if all the pages in a GC candidate block are invalid and
will be retained, RFTL does not garbage collect them.
Impact on SSD lifetime: The SSD lifetime is determined by the
wear-leveling and write traffic to the device. The GC in existing
FTLs uses a greedy policy for candidate block selection, which
always selects the block having the least number of valid pages.
Such a GC policy provides maximal GC efficiency (i.e., the least
page migration), and the throttling and swapping mechanisms are
used to balance the wear between blocks. RFTL employs these
techniques. Moreover, recent research [14, 50] on SSDs discloses
that a relaxed wear-leveling can provide guaranteed SSD lifetime.
Experiments with a variety of real-world workloads demonstrate
that RFTL has minimal impact on SSD lifetime in § 6.
5.4 Data Recovery
To restore the invalid pages retained in an SSD when victims are
aware of the ransomware infection, users can remove the SSD
Figure 5: An example of candidate block selection in state-of-
the-art GC vs. RFTL’s GC. Traditionally, block C is selected,
as the number of the valid pages is the least. In RFTL, block
A is selected, since RFTL counts the retained invalid pages
(RIP) as valid pages.
flash device for a certain time (a configurable threshold, 20 days in
FlashGuard by default).
RFTL uses the timestamp stored in the page’s OOB metadata to
calculate how long this page has been retained. Once the interval
between the timestamp in the OOB metadata and the current time
is larger than the configured threshold, the page will be erased
and reclaimed. Otherwise, both the page and its OOB metadata are
copied to a free page, so that RFTL will keep retaining this invalid
page in the SSD until it is expired when it is selected by GC next
time (see line 13-21 in Algorithm 1).
For an invalid page X whose RIP bit is not set and has been read
as indicated in RTT 5 , it is treated as a page to be retained and
will be copied to a free page Y. RFTL runs the GC procedure for
this type of invalid pages as follows:
First, RFTL prepares the OOB metadata for the new page Y: the
RIP bit is set to be Reserved, the timestamp is set to the current time
(so that the content of this page will be conservatively retained for
a certain period of time), the LPA and P-PPA are kept the same as
in page X’s OOB metadata. Second, RFTL copies the page X and its
OOB metadata into the free page Y in a new free block. Third, page
X’s read bit in RTT is cleared and page Y’s read bit in RTT is set to 1
(indicating the content of this page has been read). Finally, the page
X is garbage collected (see line 23-26 in Algorithm 1). After this
procedure, RFTL moves the retained invalid page to a new location
and keeps holding it in the flash device.
For an invalid page which has never been read, RFTL will discard
and garbage collect it (see line 28 in Algorithm 1), which is handled
in the same way as in traditional SSDs.
Impact on SSD performance: The GC scheme in RFTL keeps the
basic and essential procedures in the state-of-the-art FTLs, including
candidate block selection and valid page movement. In our design,
the overhead is introduced by copying retained invalid pages. The
RFTL takes retained invalid pages as valid pages and the GC on the
blocks carrying these pages will be delayed (see Figure 5). Meantime,
RFTL also needs to ensure all the blocks age at the same rate (i.e.,
wear leveling) to extend the lifetime of the SSD. The blocks that
have retained invalid pages, would still be selected as candidate
blocks for GC, thus additional overhead would be introduced.
Block B#Valid Pages = 2#RIP Pages = 2Block C#Valid Pages = 1#RIP Pages = 4Block A#Valid Pages = 3#RIP Pages = 0Valid PageInvalid PageRIP PageFigure 6: FlashGuard can restore all the overwritten pages by
travelling back to their previous versions with the previous
physical page address stored in each page’s OOB metadata.
device and plug it into another clean and isolated computer for
data recovery in case ransomware would attack the data recovery
procedure. FlashGuard first checks the RTT 5 to locate all the
pages that have been read recently. These pages are the candidate
pages that may contain the user’s stale data. As the RTT is cached in
firmware RAM, this checking procedure is fast. To read the retained
invalid page, FlashGuard checks the RIP bit in OOB metadata of
each candidate page. If the RIP bit flag is set, the page is read from
flash. Otherwise, RFTL will check the address mapping table 1 to
figure out whether this page is valid or not. If it is invalid, the page
is read from flash as well, since it is possible that this page is also a
victim page.
We leverage the internal parallelism in an SSD to accelerate
the procedure of reading the reatined invalid pages. Specifically,
FlashGuard can simultaneously read the pages from multiple chips
of an SSD to the host machine, therefore the recovery procedure
will not take too much time (see the evaluation in § 6).
Once these retained invalid pages are read from a flash drive,
the LPAs, P-PPAs, and timestamps stored in these pages’ OOB
metadata will be used to reconstruct the user files. FlashGuard can
use the previous physical page address (P-PPA) stored in each page’s
OOB metadata to reverse an invalid page to its previous versions as
shown in Figure 6. In order to maintain data locality for performance
reasons, modern file systems usually manage the logical address
space in a contiguous manner, and also flash controllers buffer
storage operations to exploit temporal and spatial locality [22]. With
these insights, the recovery tool in FlashGuard sorts the retained
invalid pages with their LBAs and timestamps to reconstruct the
original file. As a page could have been overwritten several times by
either ransomware or trusted users, the recovery tool can reverse
it to any older version and allow users to verify the content.
Since FlashGuard retains all the versions of the invalid pages
in flash device, many other existing data recovery tools can also
be leveraged to reconstruct user files (if there is no information
available for data locality). For example, some recovery tools can
read the first few bytes in each page to figure out the file type (e.g.,
.ppt or .doc file), and then use the defined layout for the file type
to recover the data [7].
5.5 Metadata Recovery
As all the data structures (see Figure 3) are cached in firmware RAM,
the cached data could be lost if a power failure happens. FlashGuard
maintains their durability by leveraging the metadata recovery and
check-pointing techniques that have been adopted in the state-of-
the-art FTLs [8, 16]. RFTL identifies the recent written flash block
by checking its OOB metadata (which includes timestamp as shown
in Figure 4) and use the metadata information to recover the cached
entries such as the address mapping table 1 . For the data structure
RTT 5 that tracks the recent reads, RFTL recovers it to the latest
checkpointed states. For the blocks that have been written after
the checkpoint, RFTL identifies their older versions (with P-PPA in
OOB metadata) and conservatively marks them as ‘read’ in RTT.
An alternative solution is to use a battery or large capacitor to
preserve the cached entries and persist them before power turns
off, which simplifies the metadata recovery procedure significantly.
We wish to take this solution as the future work.
5.6 FlashGuard Implementation
We implement FlashGuard on a programmable SSD with a state-of-
the-art page-level FTL. The size of the SSD is 1 TB. Each block in
the SSD has 64 pages and each page is 4 KB with 16 bytes of OOB
metdata. The programmable SSD provides basic I/O control com-
mands to issue read, write and erase operations against the physical
flash device. The RFTL for FlashGuard is implemented based on
the page-level FTL. FlashGuard is implemented with 5,718 lines
of C code on top of the flash device. The SSD is over-provisioned
with 15% of its full capacity by default, and the garbage collection
is running in background. As we develop FlashGuard as a firmware
solution, once the firmware is flushed into the device controller,
commodity SSDs no longer allow firmware modifications. This
characteristic ensures the integrity of FlashGuard.
We also implement a recovery tool that can read all the retained
invalid pages from flash device and organize them in the manner
as discussed in 5.4. The recovered data will be written back to SSD
after having verified by users.
6 EVALUATION
Our evaluation demonstrates the efficiency of FlashGuard in two
major aspects. First, we measure the effectiveness of deploying
FlashGuard against encryption ransomware. We verify that Flash-
Guard can efficiently recover data locked by various types of en-
cryption ransomware. Second, we evaluate the extra cost that would
be introduced by FlashGuard. Specifically, we show that: (1) Flash-
Guard introduces negligible overhead to the storage operations
from a variety of popular application workloads; (2) FlashGuard
has minimal impact on the SSD lifetime.
6.1 Experimental Setup
To evaluate the capability of FlashGuard to recover data encrypted
by ransomware, we use the 1,477 ransomware samples from 13
families as shown in Table 1. These samples are executed with the
same experimental setup as described in§ 2.1. Once a ransom screen
appears, we start to run the recovery tool to recover encrypted data.
To evaluate the impact of FlashGuard on storage performance
and SSD lifetime, we reply five sets of I/O traces collected from a va-
riety of real-world applications (see Table 3): (1) the storage traces
collected from enterprise servers running different applications
(e.g., media server, research project management systems, and print
server) in Microsoft Research at Cambridge for six days [28]; (2) the
storage traces collected from machines running in a department at
Block ABlock BBlock CP-PPAdataP-PPAdataP-PPAdataTable 3: A variety of real-world application workloads used
for evaluating FlashGuard. R: Read, W: Write.
Workload
online-
course
webmail
home
mailserver
web-
research
web-users
hm
mds
prn
prxy
rsrch
src
stg
ts
usr
wdev
web
postmark
IOZone
TPC-C
TPC-E
e
c
a
r
T
O
I
U
I
F
s
r
e
v
r
e
S
t
f
o
s
o
r
c
i
M
c
s
i
M
Description
course management system of a
department using Moodle
web interface to the mail server
research group activities: devel-
oping, testing, experiments, etc.
department mail server traces
research projects management
using Apache web server
web server hosting faculty, staff
and graduate student web sites
hardware monitoring
media server
print server
firewall/web proxy
research projects
source control
web staging
terminal server
user home directories
test web server
web/SQL server
mail servers
filesystem benchmark