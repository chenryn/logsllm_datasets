in the database. The server also runs the preprocessing phase
of the OT.
Client execution phase. After the client captures an image
and computes its representative vector, it sends a correction
vector which is the exclusive-or between this vector and
the random vector chosen by the client in the preprocessing
phase. This is a string of 900 bits. Afterwards the client
decrypts the result that the server sends it, and both parties
invoke the OT protocol where the client is the sender.
Server execution phase. After receiving the correction
vector, the server computes the encryption of the Hamming
distance between every image in the database and the client
image. (The server can parallize this step.) It then sends to
the client an encryption of the sum of the Hamming distance
and a random value. Afterwards it runs the OT protocol with
the client and learns the ﬁnal result.
Results: We ran multiple experiments where the server
stored a list of 100 face representations. Following are the
average timing measurements results of the experiments.
Preprocessing. Ofﬂine preprocessing at the client took
about 213 sec. Of this time, 38 seconds were spent on
preparing 900 homomorphic encryptions, 71 seconds were
used to send these encryption to the server, and 92 seconds
were spent on running the preprocessing phase of the 1-out-
of-180 OT (which is used since we set dmax = 180). As
can be seen, almost half of the preprocessing time is spent
on preparing and sending the Homomorphic encryptions. As
for the server, the ofﬂine preprocessing time of the server
includes receiving the encryptions (this time was already
counted by us at the client side); summing every possible
combination of each pair of consecutive bits, a step which
takes about 57 sec; and running the preprocessing of the OT
(this step was also already counted by us at the client side).
Online performance. The previous preprocessing steps
optimize the performance tremendously, and the resulting
online execution time is minor for each image. The online
execution time of the server for an image after receiving the
correction binary vector is only about 0.31 second. This time
is divided to (1) Computing the Hamming distance for the
image, adding to it a random value and sending the result
to the client; these steps require .28 sec. (2) Running the
online step of the OT protocol, where the server learns the
result, this step takes about .012 sec.
The run time is obviously linear in the size of the server’s
database. The total online time for comparing the client’s
input to 100 database images in only about 100 · 0.31 = 31
seconds. The bulk of the server’s computation can be fully
Figure 6: Identiﬁcation test on the frontal sub-set of CMU-
PIE.
Figure 7: Identiﬁcation test on the fc probe set of FERET.
the server’s database. It is also clear that an implementation
in the C language, with a faster cryptographic library, would
have a considerably better performance.
The experiments were performed on two Linux machines.
The machines were located in two different buildings and
communicated using sockets through TCP/IP over the local
network. We turned off Nagle algorithm in order to prevent
the ”ACK delay” (turning off Nagle algorithm indeed greatly
improved the performance of the communication layer). The
server machine was an 8 core machine of 2.6 GHz AMD
Opteron processors and 1GB RAM. The client machine had
a 2.8 GHz dual core Pentium D processor and 2GB RAM.
The protocol used in the SCiFI implementation is the
Fthreshold protocol where the server learns the output. As we
described earlier in the text, the computation is composed
of two phases, a preprocessing phase which is run before
the client’s input is known, and an online execution phase.
Our goal was to optimize the performance of online phase.
Next, we detail the steps of each party.
Client preprocessing phase. In the preprocessing phase
the client (1) chooses a random vector of 900 bits and
sends the encryption of these bits to the server, and (2)
runs the preprocessing phase of the OT, as is described in
252
Occluded
Part
Left eye
Mouth
Nose
Recognition rate
for 15% false positives
89%
91.5%
92.8%
Num. of occluded
parts
10/30
4/30
3/30
Table II: Partial occlusion results on a subset of CMU-PIE.
parallelized, and therefore using, e.g., six processors, reduces
the recognition time in this example to about 5 seconds.
Figure 8: Examples of tested occlusions.
REFERENCES
[1] M. Osadchy, Y. LeCun, and M. Miller, “Synergistic face
detection and pose estimation with energy-based models,”
Journal of Machine Learning Research, vol. 8, pp. 1197–
1215, May 2007.
[2] P. Viola and M. Jones, “Rapid object detection using a boosted
cascade of simple features,” in Proc. IEEE Conf. on Computer
Vision and Pattern Recognition, 2001, pp. 511–518.
[3] C. Chen, R. Veldhuis, T. Kevenaar, and A. Akkermans, “Bio-
metric binary string generation with detection rate optimized
bit allocation,” in CVPR Workshop on Biometrics, 2008, pp.
1–7.
[4] P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss,
“The FERET evaluation methodology for face-recognition
algorithms,” PAMI, vol. 22, no. 10, pp. 1090–1104, 2000.
[5] T. Sim, S. Baker, and M. Bsat, “The CMU pose, illumination,
and expression database,” PAMI, vol. 25, pp. 1615–1618,
2003.
[6] A. Juels and M. Sudan, “A fuzzy vault scheme,” in Symposium
on Information Theory, 2002.
[7] P. Tuyls and J. Goseling, “Capacity and examples of template-
protecting biometric authentication systems,” in ECCV Work-
shop BioAW, 2004.
[8] Y. Dodis, R. Ostrovsky, L. Reyzin, and A. Smith, “Fuzzy
extractors: How to generate strong keys from biometrics and
other noisy data,” SIAM J. Comput., vol. 38, no. 1, pp. 97–
139, 2008.
[9] Y. Adini, Y. Moses, and S. Ullman, “Face recognition: the
problem of compensating for changes in illumination direc-
tion,” PAMI, vol. 19, no. 7, pp. 721–732, 1997.
[10] M. Turk and A. Pentland, “Eigenfaces for recognition,” Jour-
nal of Cognitive Neuroscience, vol. 3, no. 1, pp. 71–86, 1991.
253
[11] N. K. Ratha, S. Chikkerur, J. H. Connell, and R. M. Bolle,
“Generating cancelable ﬁngerprint templates,” PAMI, vol. 29,
no. 4, pp. 561–572, 2007.
[12] T. Boult, “Robust distance measures for face-recognition
supporting revocable biometric tokens,” in IEEE, 7th Intl.
Conf. on Automatic Face and Gesture Recognition, 2006, pp.
560–566.
[13] S. Avidan and M. Butman, “Blind vision,” in ECCV (3).
Springer, 2006, pp. 1–13.
[14] A. Senior, S. Pankanti, A. Hampapur, L. Brown, Y.-L. Tian,
A. Ekin, J. Connell, C. F. Shu, and M. Lu, “Enabling video
privacy through computer vision,” IEEE Security and Privacy,
vol. 3, no. 3, pp. 50–57, 2005.
[15] F. Dufaux and T. Ebrahimi, “Scrambling for Video Surveil-
lance with Privacy,” in IEEE Workshop on Privacy Research
in Vision.
IEEE, 2006.
[16] E. M. Newton, L. Sweeney, and B. Malin, “Preserving privacy
by de-identifying face images,” IEEE Trans. on Knowl. and
Data Eng., vol. 17, no. 2, pp. 232–243, 2005.
[17] T. Boult, “Pico: Privacy through invertible cryptographic
obscuration,” Computer Vision for Interactive and Intelligent
Environment, 2005, pp. 27–38, 2005.
[18] J. Schiff, M. Meingast, D. Mulligan, S. Sastry, and K. Gold-
berg, “Respectful cameras: Detecting visual markers in real-
time to address privacy concerns,” in Int. Conf. on Intelligent
Robots and Systems (IROS), 2007, pp. 971–978.
[19] A. Yao, “How to generate and exchange secrets,” in FOCS,
1986, pp. 162–167.
[20] O. Goldreich, Foundations of Cryptography: Volume 2, Basic
Applications. Cambridge University Press, 2004.
[21] Z. Erkin, M. Franz, J. Guajardo, S. Katzenbeisser, I. La-
gendijk, and T. Toft, “Privacy-preserving face recognition,”
in Proc, of
the 9th International Symposium on Privacy
Enhancing Technologies (PET). Springer, 2009, p. 253.
[22] A. Sadeghi, T. Schneider, and I. Wehrenberg, “Efﬁcient
Privacy-Preserving Face Recognition,” in 12th Interna-
tional Conference on Information Security and Cryptology
(ICISC09), LNCS. Springer, 2009.
[23] D. G. Lowe, “Distinctive image features from scale-invariant
keypoints,” IJCV, vol. 60, no. 2, pp. 91–110, 2004.
[24] C. T. Yuen, M. Rizon, W. S. San, and M. Sugisaka, “Au-
tomatic detection of face and facial features,” in ISPRA’08,
2008, pp. 230–234.
[25] N. Gourier, D. Hall, and J. L. Crowley, “Facial features
detection robust to pose, illumination and identity,” in Int’l
Conf. on Systems Man and Cybernetics, 2004.
[26] P. Paillier, “Public-key cryptosystems based on composite
degree residuosity classes,” in EUROCRYPT, 1999, pp. 223–
238.
[27] M. Naor and B. Pinkas, “Computationally secure oblivious
transfer,” J. Cryptology, vol. 18, no. 1, pp. 1–35, 2005.
[28] A. Jarrous and B. Pinkas, “Secure hamming distance based
computation and its applications,” in Applied Cryptography
and Network Security conf. (ACNS), 2009, pp. 107–124.
[29] V. Arlazarov, E. Dinic, M. Kronrod, and I. Faradzev, “On eco-
nomical construction of the transitive closure of an oriented
graph,” in Soviet Math. Dokl, vol. 11, no. 1209-1210.
[30] Y. Aumann and Y. Lindell, “Security against covert adver-
saries: Efﬁcient protocols for realistic adversaries,” in TCC,
ser. Lecture Notes in Computer Science, S. P. Vadhan, Ed.,
vol. 4392. Springer, 2007, pp. 137–156.
[31] S. Romdhani, V. Blanz, and T. Vetter, “Face identiﬁcation by
ﬁtting a 3d morphable model using linear shape and texture
error functions,” in ECCV, 2002, pp. 3–19.
[32] Y. Wang, Z. Liu, G. Hua, Z. Wen, Z. Zhang, and D. Samaras,
“Face re-lighting from a single image under harsh lighting
conditions,” in CVPR, vol. 1, 2007, pp. 1–8.
[33] T. Ahonen, A. Hadid, and M. Pietikainen, “Face description
with local binary patterns: Application to face recognition,”
PAMI, vol. 28, no. 12, pp. 2037–2041, 2006.
APPENDIX
The min functionality: The basic building block used
for computing the Fmin+t functionality is a protocol for
outputting the minimum of two numbers (which will be
used for comparing Hamming distances). More speciﬁcally,
in this protocol, denoted min, the client has two inputs
y0, y1, where yi = di + ri, 0 ≤ d0, d1 ≤ (cid:2), and addition is
performed in the ﬁeld or ring over which the homomorphic
encryption is deﬁned. The server has inputs r0, r1. The
server’s output is a random number r(cid:2). The client’s output
is b ∈ {0, 1}, which is the index of the smaller element
among d0, d1, and the value min(d0, d1)+r(cid:2), where the min
operation is computed over the integers. (This basic protocol
will later be used for computing the minimum among N
numbers, by running a tournament between these N values.)
The basic observation behind the protocol is that the value
d0 − d1 is in the range [−dmax, dmax] and is negative iff
d0 < d1. Therefore a OT2dmax+1
protocol, adapted to the
use of the keys r0, r1, can compute the functionality.
The min protocol is described in Figure 9. Correctness
follows from setting the server’s inputs in the OT protocol
such that the client retrieves r(cid:2) − r0 if d0 < d1, and r(cid:2) − r1
otherwise. Security is implied by the security of the OT
protocol. The overhead is that of running a single OT2dmax+1
protocol, namely of executing log(2dmax +1) invocations of
OT2
1, and encrypting and sending 2dmax + 1 values.
The Fmin+t functionality.: Running the basic Fthreshold
protocol until Step 4 results in the client learning DH + ri
and the server learning ri. This is exactly the input to the
min protocol, and therefore the parties can run a tournament
1
1
min(y0, y1; r0, r1)
The protocol uses a ring or a ﬁeld F over which a homomorphic
encryption scheme is deﬁned. The inputs d0, d1 are integers in
the range [0, dmax]. We note that the value of dmax is negligible
compared to |F|.
INPUT: The client’s input is y0, y1, where y0 = d0 + r0, y1 =
r1 + d1 and addition is done in F. The server’s input is r0, r1.
, where b ∈ {0, 1} is such
OUTPUT: The client receives b, db+r(cid:2)
that db < d1−b, where comparison is done over the integers.
The server obtains r(cid:2)
1. The client computes (over F) the value α = y0 − y1 =
(d0 − d1) + (r0 − r1). The client then computes (over
the integers) β = α mod 2dmax + 1.
if dmax < r0 − r1 < |F| − dmax − 1,
Note that
an event which happens with overwhelming probability
since dmax (cid:5) F, then 0 ≤ (d0−d1)+(r0−r1) ≤ |F|−1
and therefore β is equal
to the result of computing
y0 − y1 = (d0 − d1) + (r0 − r1) mod 2dmax + 1 over
the integers.
, which is chosen randomly in F.
1
2. The parties run a OT2dmax+1
protocol where the client
is the receiver and the server is the sender. The input of
the client is β.
The server chooses a random r(cid:2) ∈ F, and sets its inputs
in the OT such that the client learns the value 0|(r(cid:2) −
r0) if y0 < y1, and 1|(r(cid:2) − r1) otherwise. This is done
by setting the inputs X0, . . . , X2dmax such that Xi =
0|(r(cid:2) − r0) if i − (r0 − r1) mod 2dmax + 1 is in the
range [dmax + 1, 2dmax] and Xi = 1|(r(cid:2)− r1) otherwise.
3. Denote the value learned by the client in the OT as b|γ.
Then the client sets its output to be yb + γ = db + rb +
(rb − r(cid:2)) = db + r(cid:2)
. The server’s output is r(cid:2)
.
Figure 9: The min protocol.
in which the minimal DH value is computed: The ﬁrst stage
of the tournament compares adjacent values received from
the Fthreshold protocol. The next stage compares the results
of the previous stage. After log N stages the tournament
ﬁnds a winner which is the minimal value. Note that the
min protocol reveals which of the two items it compares is
smaller, whereas the Fmin+t functionality must not reveal
any such intermediate result. Therefore the server must
permute the order of its inputs each time Fmin+t is run.
The protocol described above ﬁnds the minimal Hamming
distance. More accurately, the server and client learn outputs
outs, outc, respectively, such that the sum of these values
is the minimal Hamming distance. However, the Fmin+t
functionality outputs the minimal Hamming distance only
if it is smaller than the threshold. Therefore an additional
step of the protocol must check if outs+outc is smaller than
the threshold, and outputs outc+outs and the corresponding
index if this is indeed the case. This step can be implemented
using a solution to the millionaires problem [19]. (Some
additional care must be taken if a different threshold is used
for every face in the server’s list. The details will be given
in the full version of the paper.)
254