tion will discourage building up queues (bloating buffers will de-
crease a ﬂow’s score). Moreover, avoiding packet loss as a conges-
tion signal allows the protocol to robustly handle stochastic (non-
congestive) packet losses without adversely reducing performance.
We avoid giving the sender access to the RTT (as opposed to the
RTT ratio), because we do not want it to learn different behaviors
for different RTTs.
Figure 2: Dumbbell network with uncertainty.
At the start of each ﬂow, before any ACKs have been received,
the memory starts in a well-known all-zeroes initial state. Remy-
CCs do not keep state from one “on” period to the next, mimicking
TCP’s behavior in beginning with slow start every time a new con-
nection is established (it is possible that caching congestion state
is a good idea on some paths, but we don’t consider this here). Al-
though RemyCCs do not depend on loss as a congestion signal, they
do inherit the loss-recovery behavior of whatever TCP sender they
are added to.
4.2 RemyCC: Mapping the memory to an action
A RemyCC is deﬁned by how it maps values of the memory to
output actions. Operationally, a RemyCC runs as a sequence of
lookups triggered by incoming ACKs. (The triggering by ACKs
is inspired by TCP’s ACK clocking.) Each time a RemyCC sender
receives an ACK, it updates its memory and then looks up the corre-
sponding action. It is Remy’s job to pre-compute this lookup table
during the design phase, by ﬁnding the mapping that maximizes the
expected value of the objective function, with the expectation taken
over the network model.
Currently, a Remy action has three components:
1. A multiple m ≥ 0 to the current congestion window (cwnd).
2. An increment b to the congestion window (b could be nega-
tive).
3. A lower bound r > 0 milliseconds on the time between suc-
cessive sends.
If the number of outstanding packets is greater than cwnd, the
sender will transmit segments to close the window, but no faster
than one segment every r milliseconds.
A RemyCC is deﬁned by a set of piecewise-constant rules, each
one mapping a three-dimensional rectangular region of the three-
dimensional memory space to a three-dimensional action:
(cid:104)ack_ewma, send_ewma, rtt_ratio(cid:105) → (cid:104)m,b,r(cid:105).
4.3 Remy’s automated design procedure
The design phase of Remy is an optimization procedure to efﬁ-
ciently construct this state-to-action mapping, or rule table. Remy
uses simulation of the senders on various sample networks drawn
from the network model, with parameters drawn within the ranges
of the supplied prior assumptions. These parameters include the
link rates, delays, the number of sources, and the on-off distri-
butions of the sources. Ofﬂine, Remy evaluates candidate algo-
rithms on millions of randomly generated network conﬁgurations.
Because of the high speed of current computers and the “embar-
rassingly parallel” nature of the task, Remy is able to generate
congestion-control algorithms within a few hours.
A single evaluation step, the innermost loop of Remy’s design
process, consists of drawing 16 or more network specimens from
...TCP 1TCP 2TCP n(n uncertain)QueueLink(speed uncertain)...TCP ReceiverTCP ReceiverTCP ReceiverRound-trip time (uncertain)Switching process(state uncertain)ONOFFON127the network model, then simulating the RemyCC algorithm at each
sender for 100 seconds on each network specimen. At the end of the
simulation, the objective function for each sender, given by Equa-
tion 1, is totaled to produce an overall ﬁgure of merit for the Re-
myCC. We explore two cases, α = β = 1 and α = 2,δ = 0. The
ﬁrst case corresponds to proportional throughput and delay fairness,
maximizing
U = log(throughput)− δ · log(delay),
with δ specifying the importance placed on delay vs. throughput.
The second case corresponds to minimizing the potential delay of a
ﬁxed-length transfer, by maximizing
1
U = −
throughput
.
Remy initializes a RemyCC with only a single rule. Any values
of the three state variables (between 0 and 16,384) are mapped to a
default action where m = 1, b = 1, r = 0.01.
Each entry in the rule table has an “epoch.” Remy maintains a
global epoch number, initialized to 0. Remy’s search for the “best”
RemyCC given a network model is a series of greedy steps to build
and improve the rule table:
1. Set all rules to the current epoch.
2. Find the most-used rule in this epoch. Simulate the current
RemyCC and see which rule in the current epoch receives the
most use. If no such rules were used, go to step 4.
3. Improve that action until we can’t anymore. Focus on this
rule and ﬁnd the best action for it. Draw at least 16 network
specimens from the model, and then evaluate roughly 100
candidate increments to the current action, increasing geo-
metrically in granularity as they get further from the current
value. For example, evaluate r± 0.01, r± 0.08, r± 0.64, . . . ,
taking the Cartesian product with the alternatives for m and
b.
The modiﬁed action is evaluated by substituting it into all
senders and repeating the simulation in parallel. We use the
same random seed and the same set of specimen networks in
the simulation of each candidate action to reduce the effects
of random variation.
If any of the candidates is an improvement, replace the ac-
tion with the best new action and repeat the search, still with
the same specimen networks and random seed. Otherwise,
increment the epoch number of the current rule and go back
to step 2.
4. If we run out of rules in this epoch. Increment the global
epoch. If the new epoch is a multiple of a parameter, K, con-
tinue to step 5. Otherwise go back to step 1. We use K = 4
to balance structural improvements vs. honing the existing
structure.
5. Subdivide the most-used rule. Recall that each rule repre-
sents a mapping from a three-dimensional rectangular region
of memory space to a single action.
In this step, ﬁnd the
most-used rule, and the median memory value that triggers
it. Split the rule at this point, producing eight new rules (one
per dimension of the memory-space), each with the same ac-
tion as before. Then return to step 1.
yield a more granular function relating memory to action. Which
rules are more often triggered depends on every endpoint’s behav-
ior as well as the network’s parameters, so the task of ﬁnding the
right structure for the rule table is best run alongside the process of
optimizing existing rules.
To the best of our knowledge, this dynamic partitioning approach
is novel in the context of multi-agent optimization. The “greedy”
approach in step 2 is key to the computational tractability and efﬁ-
ciency of the search because it allows us to prune the search space.
Dividing the memory space into cells of different size proportional
to their activity produces a rule table whose granularity is ﬁner in
regions of higher use. An improvement to consider in the future is
to divide a cell only if the actions at its boundaries markedly dis-
agree.2
5. EVALUATION
We used ns-2 to evaluate the algorithms generated by Remy and
compare them with several other congestion-control methods, in-
cluding both end-to-end schemes and schemes with router assis-
tance. This section describes the network and workload scenarios
and our ﬁndings.
5.1 Simulation setup and metrics
Congestion-control protocols. The end-to-end schemes we com-
pared with are NewReno, Vegas, Cubic, and Compound. In addi-
tion, we compared against two schemes that depend on router assis-
tance: XCP, and Cubic over stochastic fair queueing [31] with each
queue running CoDel [33]. We use Nichols’s published sfqCoDel
implementation (version released in March 2013) for ns-2.3 The
Cubic, Compound, and Vegas codes are from the Linux implemen-
tations ported to ns-2 and available in ns-2.35. For the datacenter
simulation, we also compare with the DCTCP ns-2.35 patch.4
RemyCCs. We used Remy to construct three general-purpose
RemyCCs. Each one was designed for an uncertain network model
with the dumbbell topology of Figure 2, but with three different
values of δ (the relative importance of delay): 0.1, 1, and 10. The
parameters of the network and trafﬁc model used at design time
were:
Quantity
n max senders
“on” process
“off” process
link speed
round-trip time
queue capacity
Design range Distribution
1–16
mean 5 s
mean 5 s
10–20 Mbps
100–200 ms
unlimited
uniform
exponential
exponential
uniform
uniform
The model captures a 64-fold range of bandwidth-delay product
per user. Each RemyCC took about 3–5 CPU-days to optimize.
Calculations were run on Amazon EC2 and on an 80-core and 48-
core server at MIT. In wall-clock time, each RemyCC took a few
hours to be constructed. The RemyCCs contain between 162 and
204 rules each.
We also used Remy to assess how performance varies based on
the speciﬁcity of the assumptions used at design time, by building
one RemyCC for a link speed known exactly a priori, and one that
assumes only that the link speed will lie within a tenfold range:
By repeating this procedure, the structure of a RemyCC’s rule ta-
ble becomes an octree [32] of memory regions. Areas of the mem-
ory space more likely to occur receive correspondingly more atten-
tion from the optimizer, and are subdivided into smaller bins that
2We thank Leslie Kaelbling for this suggestion.
3http://www.pollere.net/Txtdocs/sfqcodel.cc
4http://www.stanford.edu/~alizade/Site/DCTCP.html
128Quantity
link speed
round-trip time
queue capacity
Range
15 Mbps
150 ms
1000 pkts (tail drop)
Distribution
exact
exact
2. Cellular wireless: We measured the downlink capacity of
the Verizon and AT&T LTE cellular services while mobile,
by carefully saturating the downlink (without causing buffer
overﬂow) and recording when packets made it to the user de-
vice. We recreate this link within ns-2, queueing packets
until they are released to the receiver at the same time they
were released in the trace. This setup probes the RemyCC’s
resilience to “model mismatch” — in both the Verizon and
AT&T traces, throughput and round-trip time were outside
the limits of the RemyCC design range.
Quantity
link speed
round-trip time
queue capacity
Range
varied 0–50 Mbps
50 ms
1000 pkts (tail drop)
Distribution
empirical
exact
3. Differing RTTs: Cases where different RemyCCs, contend-
ing for the same link, had different RTTs to their correspond-
ing receiver. We analyzed these cases for throughput and de-
lay fairness and compared with existing congestion-control
schemes.
Quantity
n max senders
“on” process
“off” process
link speed
queue capacity
Range
4
16× 103–3.3× 109 bytes
mean 0.2 sec
10 Mbps
1000 pkts (tail drop)
Fig. 3
exponential
exact
Distribution
4. Datacenter: We compared a RemyCC against DCTCP in a
simulated datacenter topology.
Quantity
n max senders
“on” process
“off” process
link speed
round-trip time
queue capacity
queue capacity modiﬁed RED
Range
64
mean 20 megabytes
mean 0.1 sec
10 Gbps
4 ms
1000 pkts (tail drop)
Distribution
exact
exponential
exponential
exact
exact
(for RemyCC)
(for DCTCP)
In addition, we investigate:
5. Competing protocols: We assessed how a RemyCC “played
with” existing congestion-control schemes (Cubic and Com-
pound) when contending for the same bottleneck link.
6. Sensitivity of design range: We investigated how helpful
prior knowledge of the network is to the performance of
Remy’s generated algorithms.
Metrics. We measure the throughput and average queueing delay
observed for each source-destination pair. With an on-off source,