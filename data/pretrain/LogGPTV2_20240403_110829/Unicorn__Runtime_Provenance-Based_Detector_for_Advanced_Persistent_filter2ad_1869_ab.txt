tree graph kernel algorithm based on one dimensional WL
test of isomorphism [126]. The WL test of isomorphism
and its subtree kernel variation [110] are known for their
discriminative power for a broad class of graphs, beyond many
state-of-the-art graph learning algorithms (e.g., graph neural
networks [52, 129]).
Our use of the WL subtree graph kernel hinges on our
ability to construct a histogram of vertices that captures
the graph structure surrounding each vertex. We bin vertices
according to augmented vertex labels that describe fully the R-
hop neighborhood of the vertex. We construct these augmented
vertex labels by iterative label propagation; we provide an
intuitive description here and a more formal one below. For
simplicity of exposition, assume we have an entire static graph.
A single relabeling step takes as input a vertex label, the
labels of all its incoming edges, and the labels of the source
vertices of all those edges. It then outputs a new label for the
vertex representing the aggregation of all the input labels. We
repeat this process for every vertex, and then repeat the entire
procedure R times to construct labels describing an R-hop
neighborhood. Once we have constructed augmented vertex
labels for every vertex in the graph, we create a histogram
whose buckets correspond to these labels. The WL test of
isomorphism compares two graphs based on these augmented
vertex labels;
two graphs are similar if they have similar
distributions across similar sets of labels.
Algorithm 1: Graph Histogram Generation
: G = (V, E, F v, F e, C), R
Input
Output: Histogram H
for i ← 1 to R do
foreach v ∈ V do
M ← {}
if i == 1 then
else if i == 2 then
l0(v) ← F v(v)
T S ← {}
foreach e ∈ In(v) do
w ← Source(e)
M ← M + {F e(e) :: l1(w)}
T (w) ← C(e)
T S ← T S + {T (w)}
T (v) ← Min(TS)
T S ← {}
foreach w ∈ N (v) do
M ← M + {li−1(w)}
T S ← T S + {T (w)}
T (w) ← Min(TS)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
else
foreach v ∈ V do
Sort(M ) based on timestamps T (w), ∀w whose label is
included in M
sv ← li−1(v) + Concat(M)
li(v) ← Hash(sv)
if li(v) /∈ H then H[li(v)] ← 1
else H[li(v)] ← H[li(v)] + 1
Alg. 1 presents the algorithm more formally. We deﬁne
a static graph G as a 5-tuple (V, E,F v,F e,C), where V
is the set of vertices, E is the set of directed edges, i.e.,
e = (u, v) ∈ E and (u, v) (cid:54)= (v, u) ∀ u, v ∈ V . F v : V → Σ is
a function that assigns labels from an alphabet Σ to each vertex
in the graph, and similarly, F e : E → Ψ assigns labels from
an alphabet Ψ to each edge. C is a function that records the
timestamp of each edge. In line 1, R is the number of neigh-
borhood hops that each vertex explores to generate histogram
elements. UNICORN creates a histogram representation of an
entire graph by examining rooted subtrees around every vertex
in the graph. By considering such non-linear substructures,
in addition to the attributes of each vertex/edge, UNICORN
preserves structural equivalence of provenance graphs, which
has been demonstrated to outperform linear approaches such
as random walk [94]. M is a list of neighboring vertex and/or
edge labels of a vertex v and li(v) is the label (i.e., histogram
element) of the vertex v in the ith iteration (or the (i − 1)-
hop neighborhood, where the 0-hop neighborhood is the vertex
itself). T S is a list of timestamps of the neighboring vertices.
In line 8, the function In(v) returns all the incoming edges of
the vertex v and the function Source(e) in line 9 returns the
source vertex of the edge e. T records the timestamp of each
4
scenarios, the long duration of a potential attack suggests that
a good model must include the system’s long-term behavior.
However, system behavior often changes over time, which
results in changes in the underlying statistical properties of
the streaming provenance graph. This phenomenon is referred
to as concept drift [120].
UNICORN accounts for such changes in system behavior
through the use of exponential weight decay [70] on histogram
element counts to gradually forget outdated data. It assigns
weights that are inversely proportional
to the age of the
data [73]. For each element h in the histogram H, as a new
data item xt (i.e., a hashed label li(v) from Alg. 1 line 23)
streams in at time t, instead of counting Hh as:
(cid:88)
t
Hh =
1xt=h
UNICORN discounts the inﬂuence of existing data accord-
ing to their age:
(cid:88)
t
Lh =
wt 1xt=h
where 1cond is an indicator function that returns 1 when
cond is true and 0 otherwise, and wt = e−λ∆t. UNICORN
increments t monotonically with the number of edges added
to the graph. We use L instead of H to denote weighted
histograms (Table X).
Applicability in Intrusion Detection Scenarios. The gradu-
ally forgetting approach helps UNICORN focus on the current
dynamics of system execution (i.e., the most recent part of
the provenance graph), as well as any parts of the graph that
are causally related to the current execution (based on the
path length), while maintaining fading “memory” of the past,
the rate of which is controlled by the weight decay factor λ.
Notably, regardless of how temporally distant an event has
occurred from the current state of system execution, if it is
causally related to a current object/activity, that event and
its surrounding neighborhood will contribute to the histogram
without discount. Therefore, provenance graphs ensure that
relevant contextual information remains in the analysis regard-
less of time. In § IV-D, we discuss how UNICORN models a
system’s evolutionary behavior.
C. Generating Graph Sketches
The graph histogram is a simple vector space graph statistic
that describes system execution. However, unlike traditional
histogram-based similarity analysis [13, 24, 133], UNICORN
constantly updates the histogram as new edges arrive. Measur-
ing the similarity between streaming histograms is challenging,
because the number of histogram elements is not known a
priori and changes continuously. Moreover, we should measure
the similarity based on the underlying distribution of graph
features, instead of absolute counts. However, most existing
machine learning [31, 57] and data mining [34, 54] techniques
applicable to modeling system behavior from graph histograms
require ﬁxed-length numerical vectors.
Fig. 2: A simple, abstracted provenance graph where dotted edges arrive after
all solid edges have been processed and dotted vertices are newly-arrived. If
the provenance graph observes partial ordering, edge 1 must arrive before
edge 2 and only the local structures of vertex E and F need to be computed.
However, in a provenance graph where partial ordering is not observed, we
can encounter edge 3 and 4 and the newly-arrived vertex G (in dotted red)
after the solid edges. In such a case, with R = 2, we need to update both
vertex C and E (descendants of D) for edge 3 and vertex C, D, and E
(descendants of G) for edge 4.
vertex v. In line 16, N (v) = {w | (w, v) ∈ E} is the set of
vertices to which v is connected by an in-coming edge.
Our goal is to construct histograms where each element
of the histogram corresponds to a unique vertex label, which
captures the vertex’s R-step in-coming neighborhood. Labels
capture information about the edges in the neighborhood and
the identities of the vertices in that neighborhood, including
complex contextual information that reveals causal relation-
ships among objects, subjects, and activities [94]. We bootstrap
the labels as follows: each vertex begins with its own initial
label. We then incorporate 1-hop neighbors by adding the
labels of the incoming edges and the initial vertex labels of the
sources of those edges. After this bootstrapping process, every
vertex label now represents both vertex and edge labels so that
as we expand to increasingly large neighborhoods, we need
only add labels for the sources of all the incoming edges (since
those labels already incorporate edge labels from their incom-
ing edges). We sort all the labels by the timestamp of their
corresponding edge, respecting the sequence of events in the
system, and then hash the label list to facilitate fast lookup and
bookkeeping. Some vertices/edges may have multiple labels,
but the same hashing trick permits multi-label computation at
negligible cost.
Streaming Variant and Complexity. In a streaming envi-
ronment, we run Alg. 1 only on newly-arriving vertices and
on vertices whose in-coming neighborhood is affected by
new edges. In provenance graphs that use multiple vertices
per provenance entity or activity to represent different ver-
sions or states of the corresponding object
[90], we need
to compute/update only the neighborhood of the destination
vertex for each new edge, because all incoming edges to a
vertex arrive before any outgoing ones [101]. UNICORN takes
advantage of this partial ordering to minimize computation
(Fig. 2), which is particularly important during exploration
of large neighborhoods. Our implementation (§ VI) further
reduces computation using batch processing. Consequently,
the practical runtime complexity of the streaming variant of
Alg. 1 is approximately equivalent to that of the original 1-
dimensional Weisfeiler-Lehman algorithm [110]: using R-hop
neighborhoods, the complexity is O(R|E|).
Discounting Histogram Elements for Concept Drift. In APT
5
One naive solution is to enumerate all possible histogram
elements beforehand, e.g., through combinatorial enumeration
and manual feature engineering. However, given a potentially
large number of vertex and edge labels, exacerbated by the
multi-label nature of the graph and a possibly large number of
neighborhood iterations, the resulting histogram will be sparse
and thus problematic in terms of space and time complexity.
Alternatively, manual feature engineering might reduce the
size of the histogram, but it is time-consuming and inevitably
requires arbitrary handling of unseen histogram elements.
We instead use locality sensitive hashing [59], also called
similarity-preserving data sketching [124], which is commonly
used in classifying [5] and ﬁltering [12] high-cardinality data
streams. UNICORN employs HistoSketch [132], an approach
based on consistent weighted sampling [82], that efﬁciently
maintains compact and ﬁxed-size sketches for streaming his-
tograms. HistoSketch is a constant time algorithm, so it is
fast enough to support real-time streaming analysis on rapidly
growing provenance graphs. It also unbiasedly approximates
histograms based on their normalized, generalized min-max
(Jaccard) similarity [128]. Jaccard similarity [27] has been
successfully applied in a variety of machine-learning-based
real-world problems, such as document analysis [111] and
malware classiﬁcation [107] and detection [32]. We review
HistoSketch in Appendix § B. For proof of correctness of the
algorithm, we refer interested readers to the original work by
Yang et al. [132].
D. Learning Evolutionary Models
Given graph sketches and a similarity metric, clustering is
a common data mining approach to identify outliers. However,
conventional clustering approaches fail to capture a system’s
evolutionary behavior [8]. APT scenarios are sufﬁciently long
term that failing to capture this behavior leads to too many false
positives [83]. UNICORN leverages its streaming capability
to create evolutionary models that capture normal changes
in system behavior. Crucially,
it builds these evolutionary
models during training, not during deployment. Systems that
dynamically evolve models during deployment risk poisoning
their models during an APT’s drawn out attack phase [83].
UNICORN creates a series of temporally-ordered sketches
during training. It then clusters this sketch sequence from a
single server using the well-known K-medoids algorithm [65],
using the silhouette coefﬁcient to determine the optimal value
of K [108]. The clusters represent “meta-states” of system
execution, e.g., startup, initialization, steady state behavior.
UNICORN then uses both the temporal ordering of the sketches
in all clusters and the statistics of each cluster (e.g., diame-
ter, medoid) to produce a model of the system’s evolution.
Alg. 2 describes the construction of the evolutionary model.
Each sketch S(t) belongs to a single cluster indexed k. The
evolution E is an ordered list of cluster indices, whose order
is determined by the temporally-ordered sketches S(t).
For each training instance, UNICORN creates a model that
captures the changes of system execution states during its
runtime. Intuitively, this is similar to an automaton [62, 109]
that tracks the state of system execution. The ﬁnal model
consists of many sub-models from all the provenance graphs
in the training data. With evolutionary modeling, UNICORN
Algorithm 2: Generating an Evolution Trace
Input
: Sketches S(t), t = 0, · · · , T of a streaming provenance graph,
ordered by time t
Output: Evolution List E
for t ← 0 to T do
1 E = {}
2
3
4
5
k = BelongsTo(S(t))
if Empty(E) || Tail(E) != k then E = E :: k
/* k ∈ {1, · · · , K} */
learns system behavior at many points in time; with the
gradually forgetting scheme (§ IV-B), at any point in time,
UNICORN is able to focus on the most relevant activities.
E. Detecting Anomalies
During deployment, anomaly detection follows the same
streaming paradigm described in previous sections. UNICORN
periodically creates graph sketches as the histogram evolves
from the streaming provenance graph. Given a graph sketch,
UNICORN compares the sketch to all the sub-models learned
during modeling, ﬁtting it to a cluster in each sub-model.
UNICORN assumes that monitoring starts from system boot
and tracks system state transitions within each sub-model. To
be considered valid in any sub-model, a sketch must either
ﬁt into the current state or (one of) the next state(s) (i.e., in
the cases where the sketch captures state transition in system
execution); otherwise, it is considered anomalous. Thus, we
detect two forms of anomalous behavior: sketches that do
not ﬁt into existing clusters and invalid transitions between
clusters.
V.
IMPLEMENTATION
We use the vertex-centric graph processing framework,
GraphChi [75] to implement UNICORN’s graph processing al-
gorithms in C++; we implement its data parsing and modeling
components in Python.
GraphChi [75] is a disk-based system that efﬁciently com-
putes on large graphs with billions of edges on a single com-
puter. Using GraphChi, UNICORN achieves efﬁcient analysis
performance without needing to store the entire provenance
graph in memory. UNICORN relies on two important features
of GraphChi:
1) GraphChi uses a Parallel Sliding Windows (PSW) algorithm
to split the graph into shards, with approximately the same
number of edges in each shard; it computes on each shard in
parallel. The algorithm allows fast vertex and edge updates to
disk with only a small number of non-sequential disk accesses.
This allows UNICORN to analyze the whole provenance graph
independent of memory constraints.
2) UNICORN leverages GraphChi’s efﬁcient computation on
streaming graphs. Per edge updates are efﬁcient in their use of
I/O, and selective scheduling reduces computation. UNICORN’s
guaranteed partial ordering (§ IV-B) minimizes the number of
vertices it visits even when the neighborhood hop parameter,
R, is large. Batching edge additions, rather than processing
one edge at a time, makes processing even faster.
Appendix § A provides details on obtaining and testing our
open-source implementation.
6
VI. EVALUATION
We analyzed approximately 1.5 TB of system monitoring
data containing approximately 2 billion OS-level provenance
records from various tracing systems, demonstrating the ap-
plicability of our approach. Our evaluation addresses the
following research questions:
Q1. Can UNICORN accurately detect anomalies in long-
running systems under APT attacks? (§ VI-A, § VI-B, § VI-C)
Q2. How important are the design decisions we made that are
tailored to the characteristics of APTs? (§ VI-C)
Q3. Does UNICORN’s gradually forgetting scheme improve
understanding of system behavior? (§ VI-C)
Q4. How effective are UNICORN’s evolutionary models com-
pared to existing clustering-based approaches that use static
snapshots? (§ VI-A)
Q5. Is UNICORN fast enough to perform realtime monitoring
and detection without falling behind? (§ VI-E)
Q6. What are UNICORN’s memory and CPU utilization during
system execution? (§ VI-F)
We compare UNICORN to StreamSpot, a state-of-the-art
anomaly detector that has shown promising results for APT
attacks. We show that multiple factors lead to UNICORN’s
higher detection accuracy; both its multi-hop graph exploration
(Q2) and the evolutionary modeling scheme (Q4) are better
suited for provenance-based APT detection.
We then explore the efﬁcacy of UNICORN with three real-
life APT attack datasets, all of which were captured during
a red-team vs. blue-team adversarial engagement organized
by U.S. DARPA and are publicly available [66]. We separate
DARPA’s datasets based on the underlying provenance capture
systems (i.e., Cadets, ClearScope, and THEIA). We show
that UNICORN can detect system anomalies during real APT
campaigns (Q1).
Lastly, we create our own simulated APT supply-chain
attack datasets (SC-1 and SC-2) using CamFlow in a controlled
lab environment to demonstrate that UNICORN is performant
in terms of processing speed (Q5) and CPU and memory efﬁ-