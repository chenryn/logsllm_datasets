### 优化后的文本

#### 表1：64位和128位Arbiter PUFs的LR结果
| 参数 | 64位 | 128位 |
| --- | --- | --- |
| Rate | 95% | 99% | 99.9% | 95% | 99% | 99.9% |
| CRPs数量 | 640 | 2,555 | 18,050 | 1,350 | 5,570 | 39,200 |
| 时间 | 0.01秒 | 0.13秒 | 0.60秒 | 0.06秒 | 0.51秒 | 2.10秒 |

表1展示了64位和128位Arbiter PUFs（或具有64位和128位长度）的LR结果。我们使用了线性加性延迟模型[13]，其中两个电信号路径的延迟被简单地相加并比较。

在本文中，我们使用以下定义：
- **预测误差** \(\epsilon\) 是训练好的机器学习算法在测试集上错误响应的比例。
- 对于所有LR应用，测试集每次由10,000个随机选择的CRPs组成。
- 对于所有ES应用（即Feed-Forward Arbiter PUF），测试集每次由8,000个随机选择的CRPs组成。
- **预测率** 为 \(1 - \epsilon\)。

**NCRP**（或简称“CRPs”）表示攻击者在其攻击中使用的CRPs数量，例如为了达到某个预测率。这一术语贯穿全文。然而，需要注意的是，在所有LR应用中（即第3到第5节），NCRP等于机器学习算法的训练集大小。而在ES应用中（即第6节），情况更为复杂。攻击者需要一个测试集来确定其多次随机运行中的最佳结果。因此，第6节表格和公式中的NCRP值反映了攻击者使用的训练集和测试集大小的总和。

### 3. Arbiter PUFs

#### 3.1 机器学习结果
为了确定分离超平面 \(\mathbf{w}^T \Phi = 0\)，我们应用了SVMs、LR和ES。LR取得了最佳结果，如表1所示。我们选择了三个不同的预测率作为目标：95%大约是64位Arbiter PUF在温度变化45°C和电压变化±2%时的环境稳定性[17]。99%和99.9%分别代表优化后的ML结果基准。表1中的所有数据都是通过对5个不同训练集进行平均得到的。准确性通过10,000个CRPs的测试集进行估计。

#### 3.2 可扩展性
我们还进行了LR的可扩展性实验，结果显示在图1和图2中。这些图表表明，相关参数——训练集中所需的CRPs数量和计算复杂度（即基本操作的数量）——随误分类率\(\epsilon\)和Arbiter PUF的长度\(k\)呈线性或低次多项式增长。理论分析（特征空间维度、Vapnik-Chervonenkis维度）表明，建模一个具有误分类率\(\epsilon\)的\(k\)级仲裁器所需的最小CRPs数量 \(N_{CRP}\) 应满足关系：

\[ N_{CRP} = O \left( \frac{k}{\epsilon} \right) \]

这得到了我们的实验结果的验证。

在实际PUF应用中，了解在PUF安全性崩溃之前可能已知的具体CRPs数量至关重要。假设双对数图中的近似线性函数依赖关系 \(y = ax + c\)，斜率为 \(a = -1\)，我们得到了以下经验公式（10）：

\[ N_{CRP} \approx 0.5 \cdot k + \frac{1}{\epsilon} \]

该公式给出了学习具有误分类率\(\epsilon\)的\(k\)级仲裁器所需的近似CRPs数量。

我们的实验还表明，ML算法的训练时间（以基本操作次数\(NBOP\)衡量）增长缓慢。它由以下两个因素决定：(i) 当前模型似然性的评估（公式1）及其梯度（公式2），(ii) 优化过程收敛前的迭代次数（见第2.1.1节）。前者是对所有\(N_{CRP}\)特征向量\(\Phi\)的函数求和，因此复杂度为 \(O(k \cdot N_{CRP})\)。基于图2中的数据，我们可以进一步估计迭代次数与CRPs数量\(N_{CRP}\)的对数成正比。综合起来，整体复杂度为：

\[ NBOP = O \left( \frac{k^2}{\epsilon} \cdot \log \frac{k}{\epsilon} \right) \]

### 4. XOR Arbiter PUFs

#### 4.1 机器学习结果
在将SVMs和ES应用于XOR Arb-PUFs时，我们能够破解小型实例，例如2或3个XOR和64级的XOR Arb-PUFs。LR显著优于其他两种方法。关键观察是，除了确定线性决策边界（公式7），还可以指定非线性边界（公式6）。这是通过设置LR决策边界 \(f = \sum_{i=1}^{l} \mathbf{w}_i^T \Phi_i\) 来实现的。结果如表2所示。

#### 4.2 含有错误的CRPs上的性能
第4.1节中使用的CRPs是通过PUF的加性线性延迟模型伪随机生成的。这与实际情况有两个方面的偏差：首先，从真实PUF获得的CRPs受到噪声和随机错误的影响；其次，线性模型非常接近实际电路的现象[17]，但并不完美。这导致任何真实系统在一小部分CRPs上偏离线性模型。

为了模拟这种情况，我们研究了当少量错误人为注入训练集时的ML性能。一定比例的训练集响应被随机选择，并将其比特值翻转。然后，在未改变的、无错误的测试集上评估ML性能。结果如表3和表4所示。它们显示，如果使用大约3到4倍更多的CRPs，LR可以很好地应对错误。含有错误的训练集所需的收敛时间与相同大小的无错误训练集相比没有显著变化。

#### 4.3 可扩展性
图4和图5展示了我们的LR扩展实验结果。同样，为了达到误分类率\(\epsilon\)所需训练集中最小的CRPs数量 \(N_{CRP}\) 与问题参数（阶段数\(k\)和XORed Arb-PUFs的数量\(l\)的乘积）呈线性关系：

\[ N_{CRP} \sim \frac{(k + 1) \cdot l}{\epsilon} \]

但是，与标准Arb-PUFs不同，现在在训练集上优化非线性决策边界（公式6）是一个非凸问题，因此LR算法不能保证在第一次试验中找到全局最优解（或其吸引子）。它需要迭代重启\(N_{trial}\)次。\(\ N_{trial}\)不仅取决于\(k\)和\(l\)，还取决于所用训练集的大小\(N_{CRP}\)。

正如[20]中详细讨论的那样，找到全局最优解（或其吸引子）的成功率（\(= 1/N_{trial}\)）似乎由梯度信息的维度（\(\propto N_{CRP}\)，因为梯度是特征向量的线性组合）和问题在线性可分的维度\(d_{\Phi}\)之间的比率决定。维度\(d_{\Phi}\)是\(\Phi_{XOR} = \bigotimes_{i=1}^{l} \Phi_i\)的独立维度。张量积由多个向量的所有可能的乘积组成，独立维度由不同分量的数量给出。更正式地，\(d_{\Phi}\)表示为：

\[ d_{\Phi} = \binom{k+1}{l} + \binom{k+1}{l-2} + \binom{k+1}{l-4} + \ldots \approx \frac{(k+1)^l}{l!} \]

图5展示了LR算法成功率达到依赖于\(d_{\Phi}\)与\(N_{CRP}\)比率的平均成功率。