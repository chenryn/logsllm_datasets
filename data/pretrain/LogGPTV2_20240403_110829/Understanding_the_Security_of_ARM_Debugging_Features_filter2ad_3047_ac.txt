Galaxy Note 2
Mate 7
E4 Plus
Redmi 6
Samsung
Huawei
MediaTek
MediaTek
Exynos 4412
Kirin 925
MT 6737
MT 6762
SoC
Debug Authentication Signals
Name
Juno
i.MX53
BCM2837
Kirin 620
ThunderX
Armada 370/XP
DBGEN
NIDEN
SPIDEN
SPNIDEN












































authentication signals. For the target devices, we build a
Loadable Kernel Module (LKM) to read the status of the
debug authentication signals via this register. However, some
stock ROMs in the mobile devices forbid the load of LKM.
In that case, we obtain the kernel source code of the stock
ROM and recompile a kernel image with LKM enabled option.
The recompiled image is then ﬂashed back to the device to
conduct the investigation. Note that we make no change to
other functionalities in the kernel, and the kernel replacement
does not affect the status of the authentication signals.
Table I summarizes the default status of the debug au-
thentication signals in the tested devices. On the Juno board,
which is designed only for development purpose, the debug
authentication signals are all enabled by default. However,
we are surprised to ﬁnd that all
the debug authentication
signals are enabled by default on the commercial devices
like Raspberry PI 3 Model B+, Huawei Mate 7, Motorola
E4 Plus, and Xiaomi Redmi. Moreover, all the investigated
cloud platforms also enable all these signals. The results on
other platforms show that the debug authentication signals are
partially enabled by default in the tested mobile devices.
For the mobile phones that enable SPNIDEN and SPIDEN,
we also investigate the usage of the TrustZone on these
devices. According to [2], [24], [62], the Huawei Mate 7,
Motorola E4 Plus and Xiaomi Redmi 6 leverage TrustZone to
enforce a hardware-level protection on the collected ﬁngerprint
image. By manually introspect the binary image of the TEE
in Huawei Mate 7, we also ﬁnd that there exists an encryption
engine inside the TEE. The TEE image of Motorola E4
Plus and Xiaomi Redmi 6 indicate that both of them use
ARM Trusted Firmware (ATF) [11] as the TEE OS. The ATF
provides support for both trusted boot and trusted apps, and we
also ﬁnd a potential secure patching module in these binaries.
In the TEE image of Xiaomi Redmi 6, we identify a large
array with pairs of ﬁle names and 128-bit checksums, which
may be used to verify the integrity of the system ﬁles.
C. Management of the Authentication Signals
To understand the deployed signal management mechanism,
we collect
information from the publicly available TRMs
and the source code released by the hardware vendors. The
signal management mechanism on Juno board and i.MX53
QSB is partially documented in the TRMs, and we have also
identiﬁed some potential-related code in the kernel source code
of Motorola Nexus 6 and Huawei Mate 7. In regard to the
other platforms, the signal management mechanism cannot
be identiﬁed from the publicly available TRMs and released
source code.
1) What we learned from the TRMs:
NXP i.MX53 Quick Start Board (QSB). According to
the publicly available TRM of i.MX53 SoC [51], the DBGEN
signal is controlled by the DBGEN bit of the ARM_GPC register
located at memory address 0x63FA0004, and no privilege
requirement is speciﬁed for the access to this register. The
management of other debug authentication signals is not doc-
umented. In the further experiment, we ﬁnd that the SPIDEN
and SPNIDEN signals can be controlled via the JTAG port.
Once we use the JTAG to connect to the board via additional
debugging software (ARM DS-5 [7] or OpenOCD [53]), the
SPIDEN and SPNIDEN signals are directly enabled. Note that
this mechanism actually breaks ARM’s design purpose since
it allows a debugger to enable the debug authentication signals
which are design to restrict the usage of the debugger.
ARM Juno r1 Board. As an ofﬁcial development platform
released by ARM, the management mechanism of the debug
authentication signals is well-documented in the TRM of Juno
Board [10]. Developers can control the signal via the debug
authentication register in the System Conﬁguration Controller
(SCC) or the System Security Control (SSC) registers. The
SCC is actually managed by a text ﬁle in a conﬁguration Mir-
coSD card and the conﬁgurations on the card are loaded by the
motherboard micro-controller ﬁrmware during the early board
setup; modiﬁcation to the text ﬁle becomes effective after a
reboot. This conﬁguration MircoSD card is not available to
(cid:23)(cid:17)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:28 UTC from IEEE Xplore.  Restrictions apply. 
the on-chip OS and can be mounted to a remote PC via a
dedicated USB cable. In contrast, the SSC registers can be
modiﬁed at runtime, and they can only be accessed when the
processor is running in the secure state. In our experiment,
we ﬁnd that the debug authentication register in the SCC can
only be used to manage the SPIDEN and SPNIDEN signals.
Clearing the bit 0 of the register, which is documented as
“Global External Debug Enable” bit, does not disable any of
the debug authentication signals. Similarly, the SSC registers
can control the status of the SPIDEN and SPNIDEN signals,
but the modiﬁcation to the DBGEN and NIDEN signals does
not work. Unlike the aforementioned i.MX53 QSB, connecting
to the external debugging software via JTAG will not enable
the SPIDEN and SPNIDEN signals.
2) What we learned from the source code:
Motorola Nexus 6. We check the kernel source code for
Motorola Nexus 6 provided by Android Open Source Project
(AOSP) and ﬁnd that the debug authentication signals are
controlled by a CoreSight fuse [64] at address 0xFC4BE024.
Since the fuse is considered as a One-Time Programmable
(OTP) device, directly writing to the corresponding memory
fails without providing any error messages.
Huawei Mate 7. The kernel source code for Huawei Mate 7
is released at Huawei Open Source Release Center [30]. From
the source code, we ﬁnd that the DBGEN signal is controlled
by the register located at address 0xFFF0A82C. However,
directly read/write this register leads to a critical fault that
makes the phone to reboot. We consider that Huawei has
adopted additional protection to prevent the access to this
register for security concerns.
D. Summary
Our investigation shows that the debug authentication sig-
nals are fully or partially enabled on all the tested devices by
default, which makes them vulnerable to the aforementioned
isolation violation and privilege escalation. Moreover, there is
no publicly available management mechanism for these signals
on all tested devices except for development boards, and the
documented management mechanism of development boards
is either incomplete (i.MX53 QSB) or not fully functional
(Juno Board). On the one hand, the unavailable management
mechanism may help to prevent malicious access to the debug
authentication signals. On the other hand, it also stops the user
to disable the debug authentication signals for defense purpose.
V. NAILGUN ATTACK
To verify the security implications concluded in Section III
and the ﬁndings about the debug authentication signals de-
scribed in Section IV, we craft an attack named NAILGUN and
implement it in several different platforms. NAILGUN misuses
the non-invasive and invasive debugging features in the ARM
architecture, and gains the access to the high-privilege resource
from a low-privilege mode. To further understand the attack,
we design two attacking scenarios for non-invasive and inva-
sive debugging, respectively. With the non-invasive debugging
feature, NAILGUN is able to infer the AES encryption key,
which is isolated in EL3, via executing an application in
non-secure EL1. In regard to the invasive debugging feature,
NAILGUN demonstrates that an application running in non-
secure EL1 can execute arbitrarily payloads in EL3. To learn
the impact of NAILGUN on real-world devices, we show
that NAILGUN can be used to extract the ﬁngerprint image
protected by TEE in Huawei Mate 7. Similar attacks can be
launched to attack EL2 from EL1. Since there are three major
ARM architectures (i.e., ARMv7, 32-bit ARMv8, and 64-bit
ARMv8), we also implement NAILGUN on these different
architectures and discuss the differences in implementations.
A. Threat Model and Assumptions
In our attack, we make no assumption about the version
or type of the operation system, and do not rely on software
vulnerabilities. In regard to the hardware, NAILGUN is not
restricted to any particular processor or SoC, and is able to
work on various ARM-based platforms. Moreover, physical
access to the platform is not required.
In the non-invasive debugging attack, we assume the
SPNIDEN or NIDEN signal is enabled to attack the secure
state or the non-secure state, respectively. We also make
similar assumptions to the SPIDEN and DBGEN signals in
the invasive debugging attack. We further assume the target
platform is a multi-processor platform in the invasive de-
bugging attack. Moreover, our attack requires access to the
CoreSight components and debug registers, which are typically
mapped to some physical memory regions in the system. Note
that it normally requires non-secure EL1 privilege to map
the CoreSight components and debug registers to the virtual
memory address space.
B. Attack Scenarios
1) Inferring Encryption Key with Non-Invasive Debugging
The AES algorithm has been proved to be vulnerable to
various attacks [35], [36], [41], [42], [43], [69]. The key
vulnerability is the table-lookup based implementation, which
is designed to improve the performance of AES, leaks the
information about the encryption key. With the addresses of
the accessed table entries, the attacker can efﬁciently rebuild
the encryption key. In this attack, we assume there is a
secure application running in TrustZone that holds the AES
encryption key, and the secure application also provides an
interface to the non-secure OS to encrypt a given plaintext. The
non-secure OS cannot directly read the encryption key since
TrustZone enforces the isolation between the secure and non-
secure states. Our goal is to reveal the encryption key stored
in the secure memory by calling the encryption interface from
the non-secure OS.
The violation of privilege isolation described in Figure 4
enables a non-secure application to learn the information about
the secure execution. Speciﬁcally, the ETM instruction trace
aids to rebuild the addresses of the executed instructions while
the ETM data-address trace records the addresses of the data
involved in data processing instructions (e.g., ldr, str, mov,
and etc.). According to the access pattern of the AES, it
(cid:23)(cid:17)(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:28 UTC from IEEE Xplore.  Restrictions apply. 
invasive debugging since we can halt the target processor and
access the restricted resources via the debugging architecture.
Figure 5 shows a brief concept about the privilege escalation
with invasive debugging, and we further expand the idea to
achieve arbitrary payload execution.
The EDITR register offers an attacker the ability to execute
instructions on the TARGET from the HOST. However, not all
of the instructions can be executed via the EDITR register. For
example, the execution of branch instructions (e.g., b, bl, and
blr instructions) in EDITR leads to an unpredictable result.
Meantime, a malicious payload in real world normally contains
branch instructions. To bypass the restriction, NAILGUN crafts
a robust approach to executing arbitrary payload in the high-
privilege modes.
In general, we consider the execution of the malicious
payload should satisfy three basic requirements: 1) Com-
pleteness. The payload should be executed in the non-debug
state to overcome the instruction restriction of the EDITR
register. 2) High Privilege. The payload should be executed
with a privilege higher than the attacker owns. 3) Robust. The
execution of the payload should not affect the execution of
other programs.
To satisfy the ﬁrst requirement, NAILGUN has to manipulate
the control ﬂows of the non-debug state in the TARGET. For
a processor in the debug state, the DLR_EL0 register holds
the address of the ﬁrst instruction to execute after exiting the
debug state. Thus, an overwrite to this register can efﬁciently
hijack the instruction control ﬂow of the TARGET in the non-
debug state.
The second requirement
is tricky to satisfy. Note that
the execution of the dcps instructions does not change the
exception level of the non-debug state, which means that
we need another privilege escalation in the non-debug state
although the HOST can promote the privilege of the TARGET
in the debug state. The smc instruction in the non-debug state
asserts a Secure Monitor Call (SMC) exception which takes
the processor to EL3, and we can leverage this instruction to
enter EL3. However, we still need to redirect the execution
to the payload after entering EL3. In each exception level,
the incoming exceptions are handled by the handler speciﬁed
in the corresponding exception vectors. In light of this, we
manipulate the exception vector and redirect the corresponding
exception handlers to the payload.
The third requirement is also critical since NAILGUN ac-
tually modiﬁes the instruction pointed by DLR_EL0 and the
exception vectors indicated by the VBAR_EL3 registers. To
avoid the side-effect introduced by the manipulation, NAIL-
GUN needs to rollback these changes in the TARGET after the
execution of the payload. Moreover, NAILGUN needs to store
the value of stack pointers and general purpose registers at the
very beginning of the payload and reverts them at the end of
the payload.
We implement NAILGUN on 64-bit ARMv8 Juno r1
board [10] to show that the Implications 2-4 lead to arbitrary
payload execution in EL3. The board includes two Cortex-
A57 processors and four Cortex-A53 processors, and we use
Figure 6: Retrieving the AES Encryption Key.
is trivial to learn the instruction-address range that performs
the table lookup and identify the memory addresses of the
tables from the trace output, which further helps to retrieve the
encryption key with the recorded data addresses. Note that the
only information we require is the indices of the table entries
accessed by the AES algorithm. Thus, to simplify the analysis
and reduce the noise, we can use the address range ﬁlter in the
ETM to trace only the address range that performs the table
lookup.
To demonstrate the attack, we ﬁrst build a bare-metal
environment on an NXP i.MX53 Quick Start Board [52]. The
board is integrated with a single Cortex-A8 processor that
enables the data-address trace, and we build our environment
based on an open-source project [75] that enables the switch-
ing and communication between the secure and non-secure
states. Next, we transplant the AES encryption algorithm of
the OpenSSL 1.0.2n [54] to the environment and make it run
in the secure state with a predeﬁned 128-bit key stored in the
secure memory. A non-secure application can request a secure
encryption with an smc instruction and a plaintext pointer in
register r0.
Figure 6 demonstrates our attack process. We use a random
128-bit input as the plaintext of the encryption in  and the
corresponding ciphertext is recorded in . From the ETM trace
stream, we decode the addresses of the accessed table entries
in each encryption round and convert them into the indices of
the entries by the base addresses of the tables, as shown in .
With the indices and the ciphertext, it is trivial to reverse the
AES encryption algorithm and calculate the round keys in .
Finally, with the encryption key and accessed table entries in
round 1, NAILGUN decodes the original encryption key in .
The critical part of the source code is included in Appendix A.
Note that previous side-channel attacks to the AES algo-
rithm require hundreds of or even thousands of runs with
different plaintexts to exhaust different possibilities. NAILGUN
is able to reveal the AES encryption key with a single run of
an arbitrary plaintext.
2) Arbitrary Payload Execution with Invasive Debugging
The invasive debugging is more powerful than the non-
(cid:23)(cid:18)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:28 UTC from IEEE Xplore.  Restrictions apply. 
Normal Memory
Secure Memory
Normal Memory
Secure Memory
Normal Memory
Secure Memory
DLR_EL0
mov x0, #1
DLR_EL0
smc #0
VBAR_EL3
+ 0x400
msr daifclr, #4
...
payload:
VBAR_EL3
+ 0x400
...
...
eret
b payload
...
pc
smc #0
payload:
VBAR_EL3
+ 0x400