### Figure 13: Size of Pruned Sets for ACLs with 500 Rules
- **X-axis**: Number of matches completed during a multi-match classification.
- **Y-axis**: Size of the largest pruned set after the i-th match has been found.
- **i**: Number of Matches Found

### Table 9: Comparison of Key Metrics for Multi-Match Schemes
| Metric                       | Geometric Intersection-based | MUD                             |
|------------------------------|------------------------------|---------------------------------|
| Multi-threading Support      | Yes                          | Yes                             |
| Worst-case TCAM Entries for N Rules | O(NF)                        | N                               |
| Update Cost                  | O(NF)                        | O(N)                            |
| Cycles for k Multi-matches   | 1                            | 1 + d + (d-1)(k-2) with DIRPE: 1 + d(k-1) |
| Extra Bits                   | 0                            | r without DIRPE: d              |
| Overhead on Packet Processor | None                         | with DIRPE: log2(d/r) + (d-r) + (2r-1) |
| Entry Invalidation            | No                           | Small state machine logic; can be implemented using a few hundred gates or a few microcode instructions |

- **N**: Number of rules in the database
- **F**: Number of fields in a rule
- **d**: log2(number of unique discriminator values)
- **r**: Chunk width, where \( r \geq 2 \)

### Performance and Practical Considerations
The geometric intersection-based scheme can require several minutes of recomputation each time a new rule is added. In contrast, MUD supports high density, fast updates, and multi-threading at the cost of extra searches through the TCAM.

#### Worst-Case Analysis for Finding k Matches
- After the first match, the subsequent searches correspond to the discriminator prefixes needed to represent > i, which is at most d prefixes.
- After the second match, the worst-case number of prefixes is at most \( d - 1 \).
- For finding k matching rules, when \( d \geq (k - 1) \), the worst-case number of total searches is \( 1 + d + (k - 2)(d - 1) \).
- Using DIRPE with \( d' = 1 + (d/r)(k - 1) \), the search throughput is further increased.
- The additional searches do not adversely affect the multi-match performance: MUD can support multi-match classification at multi-gigabit link speeds, as shown in Table 8.

### Practical Considerations in Using MUD
Both DIRPE and MUD use extra unused bits from the TCAM array. When used simultaneously, the available extra bits must be shared based on desired performance and density. Typical TCAMs today have about 36 extra bits when used with IP ACLs. If MUD uses 12 bits, DIRPE would have 24 bits. A possible way to split the bits is to assign 16 DIRPE bits to the first range field and 8 bits to the second range field, resulting in an expansion of 1.31, comparable to the expansion obtained when all the bits were used for DIRPE.

### Future Directions
While the deterministic search throughput of TCAMs makes them attractive, the cost factor makes it difficult to scale to millions of rules. We plan to investigate how a combination of TCAM and RAM can scale both single and multi-match classification to millions of rules with high search performance in real-life databases.

#### Heuristic Implementation
We implemented a simple variation of a heuristic that recursively splits the rules based on whether the bit in the rule is 0, 1, or x. Figure 14 shows the variation of the number of TCAM entries and the number of RAM entries that need to be accessed per classification as a function of the bucket size, T. The desired search rate dictates the number of RAM accesses allowed per search. The number of TCAM entries needed reduces as the number of RAM accesses increases. Depending on system requirements—available RAM bandwidth, desired search throughput, and cost—we can choose the appropriate value of the bucket size.

### Conclusions
Ternary CAMs (TCAMs) have been widely used in the industry for packet classification for databases with up to hundreds of thousands of rules. This paper presents two algorithms that advance the state-of-the-art in solving important problems in TCAM usage:
1. **Database Independent Range Pre-Encoding (DIRPE)**: Addresses efficient representation of range rules in TCAMs, reducing worst-case expansion, scaling to a large number of ranges, and having good incremental update properties.
2. **Multi-match Using Discriminators (MUD)**: Solves the problem of finding multiple matches for a search key. MUD does not store per-search state, making it suitable for multi-threaded environments. It does not increase the number of TCAM entries and scales to large databases, supporting multi-match classification at multi-gigabit link speeds.

Our schemes do not require any change to TCAMs and rely on extra bits in the TCAM entry. They can be used in conjunction by using disjoint sets of extra bits. We evaluated the algorithms using a large real-life router ACL database, a randomly generated database, and worst-case analysis.

### References
[1] F. Baboescu, S. Singh, and G. Varghese. "Packet Classification for Core Routers: Is there an Alternative to CAMs?" In Proc. of IEEE INFOCOM, 2003.
...
[25] F. Yu and R. H. Katz. "Efficient Multi-Match Packet Classification with TCAM." In Proc. of HotI, 2004.