ring.
NF
Median Deviation (ns)
LB / Hash table
LB / Hash ring
LB / Red-Black Tree
LB / Unbalanced Tree
LPM / Patricia Trie
LPM / Lookup Table
LPM / DPDK LPM
NAT / Hash Table
NAT / Hash ring
NAT / Red-Black Tree
NAT / Unbalanced Tree
Zipfian Manual
-
-
-
256
112
-
-
-
-
-
359
131
103
179
109
87
115
141
160
148
404
237
CASTAN
141
161
141
240
100
346
141
182
384
176
397
Table 5: List of NFs and tested workloads, indicating
the median latency deviation from NOP.
automatically. When the structure of the NF makes it more
difficult to manually reason in such a way, CASTAN proves to
be invaluable, generating workloads up to 201% slower than
typical Zipfian traffic.
Due to limitations in our experimental setup, our evalua-
tion only explored scenarios with 100% adversarial traffic. A
more realistic adversary can only inject a fraction of the over-
all traffic as a part of a DDoS campaign. We expect that due
to the effects of head of line blocking, even a limited adver-
sary could potentially cause more damage than their limited
capabilities would suggest. Furthermore, whereas a typical
DDoS overwhelms the NF through sheer volume, adversarial
workloads can increase the efficiency of such an attack by
consuming disproportionately more resources for the same
amount of attack traffic. Studying such effects would require
a detailed cost-benefit analysis from the attacker’s point of
view, which we leave to future work.
CASTAN also has several limitations. For simpler network
functions with a more direct mapping between the input
packet and its processing performance, CASTAN has an easier
time reverse engineering adversarial workloads. However,
there are several ways in which this performance envelope
can be obfuscated, making it more difficult for us to derive
such workloads. The use of one-way functions, such as hash
functions poses one such challenge. We use rainbow tables
383
to help reverse these but this can fail or only partially suc-
ceed when additional constraints on the hashed packet come
into play. For now, analyzing the hash function directly in
symbolic execution is intractable but these functions are
not typically cryptographically secure and can hence be rea-
soned about with sufficiently powerful solvers or appropriate
constraint algebra. We leave exploring such possibilities to
future work.
Another challenge arises when the constraints on sym-
bolic pointers that arise during the CASTAN analysis prove
to be incompatible with the limited contention sets that our
cache model was able to capture empirically. To handle this
more robustly, it would be more appropriate to have a more
complete model of the cache behavior, based on the actual
cache slicing and eviction algorithms implemented in the
CPU. Reverse engineering the internal structure of CPU
caches to this effect is still in many cases an open problem
in active research [4]. We tried incorporating some prior art
from this field in our own models but failed to achieve suffi-
cient predictive power for our purposes, hence our reliance
on empirical models. If it ever becomes possible to further
encapsulate the cache behavior in a more powerful algebraic
model that can be integrated into CASTAN, we anticipate that
it will be much easier to generate adversarial workloads with
even more precision (i.e. even fewer packets).
6 RELATED WORK
Performance evaluation and diagnosis:
Software performance attacks are a well studied problem.
[13] describes adversarial complexity-based attacks on data-
structures and network applications and how to mitigate
them. [3, 36] have studied specific IDS NFs while considering
both algorithmic complexity and the cache. These works
manually study specific systems; whereas CASTAN offers an
automated approach to discovering such issues.
[30, 32, 39] use fuzzing-like approaches to automatically
expose performance bottlenecks at the level of individual
methods and data-structures. Such approaches may not scale
well when the input space is larger and less structured as
is the case in NFs. [28] automatically detects and exploits
 0 0.2 0.4 0.6 0.8 1 4200 4400 4600 4800 5000 5200 5400 5600 5800CDFLatency (ns)NOP1 PacketZipﬁanUniRandUniRand CASTANCASTAN 0 0.2 0.4 0.6 0.8 1 4200 4400 4600 4800 5000 5200 5400 5600 5800CDFLatency (ns)NOP1 PacketZipﬁanUniRandUniRand CASTANCASTAN 0 0.2 0.4 0.6 0.8 1 4200 4400 4600 4800 5000 5200 5400 5600 5800CDFLatency (ns)NOP1 PacketZipﬁanUniRandUniRand CASTANCASTANAutomated Synthesis of Adversarial Workloads
for Network Functions
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
second order denial-of-service attacks in web services. Such
attacks result from the implicit complexity of processing
database queries in web service architectures and don’t di-
rectly apply in NF environments. Like CASTAN, [7] also uses
symbex to attack algorithmic complexity. This work uses
exhaustive symbex for small inputs to find worst-case inputs
and then generalizes to discover likely worst-case candidates
for larger inputs. CASTAN could benefit from this technique
for more complex NFs where the analysis may otherwise not
scale.
Quantifying worst-case performance can follow one of
two approaches. The first approach, of which CASTAN is an
example, under-approximates the worst case performance.
By constructing adversarial workloads this approach pro-
vides a lower bound on the worst-case performance. The
other approach, commonly known as Worst-Case Execution
Time (WCET) Analysis [40] typically over-approximates the
WCET and provides conservative but safe upper bounds on
the execution time. While such an approach may provide
formal performance guarantees, it does not provide an ad-
versarial workload which is of prime importance during the
debugging phase.
With the adoption of software NFs, there exist several pro-
posals for online performance diagnosis systems. NFVPerf [26]
leverages passive traffic monitoring to identify both hard-
ware and software bottlenecks in Virtualized NFs. PerfSight [41]
leverages low-level packet processing performance metrics
to detect and diagnose performance problems. These systems
help diagnose performance issues at run time given a spe-
cific NF workload. CASTAN complements these approaches
by generating adversarial workloads that they can then use
to diagnose and debug the underlying performance issue.
Program Analysis Applied to NFs: Several prior works
have proposed using static analysis to help understand, de-
bug, and verify software NFs. StateAlyzr [20] does this to
identify per-flow and global state in NFs to facilitate the
implementation of state migration and redistribution. Many
other approaches, like CASTAN, use symbolic execution to find
bugs or formally verify correctness. [9, 10, 22, 44] leverage
this technique to automate bug finding and test-case gener-
ation. [14, 43], on the other hand, use exhaustive symbolic
execution to formally verify functional correctness. Others
have extended symbolic execution to explore multiple sys-
tems at once: [23] finds discrepancies between different SDN
agents, while [29] identifies interoperability issues between
a client and a server. [37] symbolically executes NF models to
reason about network properties like reachability and loops.
Right now there is no guarantee that NF models and imple-
mentations agree, but emerging techniques automatically
synthesize the models [42].
384
7 CONCLUSIONS
In this paper, we present CASTAN, a tool that automates the
generation of adversarial workloads for NFs that lead to poor
performance. We statically analyze the NF code using sym-
bolic execution to find code paths that perform poorly. Dur-
ing analysis, we attack NF performance on three fronts: algo-
rithmic complexity, adversarial memory access patterns, and
reversing hash functions. Algorithmic complexity attacks
are caused by code paths which execute more instructions.
We find these paths by using a directed symbolic execution
heuristic which estimates the number of CPU cycles needed
to process each packet. We then prioritize the exploration of
code paths that maximize this metric. We also build a CPU
cache model that allows us to determine specific memory
access patterns that induce persistent L3 cache misses and
evictions. Finally, we incorporate the use of rainbow tables
during analysis to reverse one-way functions such as those
used in hash tables. These three techniques combined allow
CASTAN to successfully generate adversarial workloads for
11 different NFs that we evaluate in a detailed measurement
campaign in §5. The results show that under ideal circum-
stances, a CASTAN workload is able to increase NF latency
by 201% and decrease throughput by 19% when compared
to typical test network traffic. When the NF structure is
simple enough that human intuition can create adversarial
workloads manually, we show that a corresponding CASTAN
workload behaves similarly, while being generated in an au-
tomated fashion. We also show that CASTAN completes in a
reasonable amount of time, typically less than an hour.
ACKNOWLEDGEMENTS
We would like to thank the anonymous reviewers and our
shepherd Sujata Banerjee for helping us improve our work.
We were funded by Starting Grant #BSSGI0_155834 from the
Swiss National Science Foundation and Intel Corporation.
REFERENCES
[1] 2012.
Intel Data Direct I/O Technology Overview.
https:
//www.intel.com/content/dam/www/public/us/en/documents/
white-papers/data-direct-i-o-technology-overview-paper.pdf.
Accessed: 2018-06-25.
[2] 2018. The LLVM Compiler Infrastructure. https://llvm.org/. Accessed:
2018-06-14.
[3] Yehuda Afek, Anat Bremler-Barr, Yotam Harchol, David Hay, and Yaron
Koral. 2016. Making DPI Engines Resilient to Algorithmic Complexity
Attacks. IEEE/ACM Trans. on Networking 24, 6 (2016).
[4] Gorka Irazoqui Apecechea, Thomas Eisenbarth, and Berk Sunar. 2015.
Systematic Reverse Engineering of Cache Slice Selection in Intel Pro-
cessors. IACR Cryptology ePrint Archive 2015 (2015).
[5] Mike Barnett, Bor-Yuh Evan Chang, Robert DeLine, Bart Jacobs, and
K Rustan M Leino. 2005. Boogie: A Modular Reusable Verifier for
Object-Oriented Programs. In Formal Methods for Components and
Objects.
[6] Theophilus Benson, Aditya Akella, and David A Maltz. 2010. Network
traffic characteristics of data centers in the wild. In Internet Measure-
ment Conf.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
L. Pedrosa et al.
[7] Jacob Burnim, Sudeep Juvekar, and Koushik Sen. 2009. WISE: Au-
tomated test generation for worst-case complexity. In Intl. Conf. on
Software Engineering.
[8] Cristian Cadar, Daniel Dunbar, Dawson R Engler, et al. 2008. KLEE:
Unassisted and Automatic Generation of High-Coverage Tests for
Complex Systems Programs. In Symp. on Operating Sys. Design and
Implem.
[9] Marco Canini, Dejan Kostic, Jennifer Rexford, and Daniele Venzano.
2011. Automating the testing of OpenFlow applications. Intl. Workshop
on Rigorous Protocol Engineering (2011).
[10] Marco Canini, Daniele Venzano, Peter Perešíni, Dejan Kostić, and
Jennifer Rexford. 2012. A NICE Way to Test OpenFlow Applications.
In Symp. on Networked Systems Design and Implem.
[11] CASTAN 2018. CASTAN code repository. https://github.com/nal-epfl/
castan.
[12] Sophie Cluet and Claude Delobel. 1992. A general framework for the
optimization of object-oriented queries. ACM SIGMOD Record 21, 2
(1992).
[13] Scott A Crosby and Dan S Wallach. 2003. Denial of Service via Algo-
rithmic Complexity Attacks. In USENIX Security Symp.
[14] Mihai Dobrescu and Katerina Argyraki. 2014. Software Dataplane
Verification. In Symp. on Networked Systems Design and Implem.
[15] Mihai Dobrescu, Katerina Argyraki, and Sylvia Ratnasamy. 2012. To-
ward Predictable Performance in Software Packet-Processing Plat-
forms. In Symp. on Networked Systems Design and Implem.
[16] Paul Emmerich, Sebastian Gallenmüller, Daniel Raumer, Florian Wohl-
fart, and Georg Carle. 2015. MoonGen: A Scriptable High-Speed Packet
Generator. In Internet Measurement Conf. https://doi.org/10.1145/
2815675.2815692
[17] Patrice Godefroid. 2012. Test Generation Using Symbolic Execution.
In IARCS Annual Conf. on Foundations of Software Technology and
Theoretical Computer Science, Vol. 18. https://doi.org/10.4230/LIPIcs.
FSTTCS.2012.24
[18] B. Han, V. Gopalakrishnan, L. Ji, and S. Lee. 2015. Network function
virtualization: Challenges and opportunities for innovations.
IEEE
Communications Magazine 53, 2 (Feb 2015). https://doi.org/10.1109/
MCOM.2015.7045396
[19] P. E. Hart, N. J. Nilsson, and B. Raphael. 1968. A Formal Basis for
the Heuristic Determination of Minimum Cost Paths. IEEE Trans. on
Systems Science and Cybernetics 4, 2 (July 1968). https://doi.org/10.
1109/TSSC.1968.300136
[20] Junaid Khalid, Aaron Gember-Jacobson, Roney Michael, Anubhavnidhi
Abhashkumar, and Aditya Akella. 2016. Paving the Way for NFV:
Simplifying Middlebox Modifications Using StateAlyzr. In Symp. on
Networked Systems Design and Implem.
[21] J. C. King. 1976. Symbolic Execution and Program Testing. J. ACM 19,
7 (1976).
[22] Nupur Kothari, Ratul Mahajan, Todd Millstein, Ramesh Govindan, and
Madanlal Musuvathi. 2011. Finding protocol manipulation attacks.
SIGCOMM Computer Communication Review 41, 4 (2011).
[23] Maciej Kuzniar, Peter Peresini, Marco Canini, Daniele Venzano, and
Dejan Kostic. 2012. A SOFT Way for OpenFlow Switch Interoperabil-
ity Testing. In Intl. Conf. on Emerging Networking Experiments and
Technologies.
[24] Kin-Keung Ma, Khoo Yit Phang, Jeffrey S Foster, and Michael Hicks.
2011. Directed symbolic execution. In Intl. Static Analysis Symp.
[25] Philip J Mucci, Shirley Browne, Christine Deane, and George Ho. 1999.
PAPI: A portable interface to hardware performance counters. In Pro-
ceedings of the department of defense HPCMP users group conference,
Vol. 710.
[26] Priyanka Naik, Dilip Kumar Shaw, and Mythili Vutukuru. 2016.
NFVPerf: Online performance monitoring and bottleneck detection
for NFV. In IEEE Conf. on Network Function Virtualization and Software
Defined Networks. https://doi.org/10.1109/NFV-SDN.2016.7919491
[27] Philippe Oechslin. 2003. Making a faster cryptanalytic time-memory
trade-off. In Annual Intl. Cryptology Conf.
[28] Oswaldo Olivo, Isil Dillig, and Calvin Lin. 2015. Detecting and Ex-
ploiting Second Order Denial-of-Service Vulnerabilities in Web Ap-
plications. In Conf. on Computer and Communication Security. https:
//doi.org/10.1145/2810103.2813680
[29] Luis Pedrosa, Ari Fogel, Nupur Kothari, Ramesh Govindan, Ratul Ma-
hajan, and Todd Millstein. 2015. Analyzing Protocol Implementa-
tions for Interoperability . https://www.usenix.org/conference/nsdi15/
technical-sessions/presentation/pedrosa. In Symp. on Networked Sys-
tems Design and Implem.
[30] Theofilos Petsios, Jason Zhao, Angelos D Keromytis, and Suman Jana.
2017. Slowfuzz: Automated domain-independent detection of algorith-
mic complexity vulnerabilities. In Conf. on Computer and Communica-
tion Security.
[31] Mia Primorac, Katerina Argyraki, and Edouard Bugnion. 2017. How
to Measure the Killer Microsecond. In ACM SIGCOMM Workshop on
Kernel-Bypass Networks.
[32] P. Puschner and R. Nossal. 1998. Testing the Results of Static Worst-
Case Execution-Time Analysis. In Real-Time Systems Symp.
[33] C.V. Ramamoorthy, S.-B.F. Ho, and W.T. Chen. 1976. On the Automated
Generation of Program Test Data. IEEE Trans. on Software Engineering
2, 4 (1976).
[34] Vyas Sekar, Norbert Egi, Sylvia Ratnasamy, Michael K. Reiter, and
Guangyu Shi. 2012. Design and Implementation of a Consolidated
Middlebox Architecture. In Symp. on Networked Systems Design and
Implem.
[35] Vyas Sekar and Petros Maniatis. 2011. Verifiable Resource Accounting
for Cloud Computing Services. In Cloud Computing Security Workshop.
https://doi.org/10.1145/2046660.2046666
[36] Randy Smith, Cristian Estan, and Somesh Jha. 2006. Backtracking
algorithmic complexity attacks against a NIDS. In Annual Computer
Security Applications Conf.
[37] Radu Stoenescu, Matei Popovici, Lorina Negreanu, and Costin Raiciu.
2016. SymNet: scalable symbolic execution for modern networks. In
ACM SIGCOMM Conf.
[38] Wojciech Szpankowski. 1990. Patricia Tries Again Revisited. J. ACM
37, 4 (Oct. 1990). https://doi.org/10.1145/96559.214080
[39] Luca Della Toffola, Michael Pradel, and Thomas R. Gross. 2018. Synthe-
sizing Programs That Expose Performance Bottlenecks. In Intl. Symp.
on Code Generation and Optimization. https://doi.org/10.1145/3168830
[40] Reinhard Wilhelm, Jakob Engblom, Andreas Ermedahl, Niklas Holsti,
Stephan Thesing, David Whalley, Guillem Bernat, Christian Ferdinand,
Reinhold Heckmann, Tulika Mitra, Frank Mueller, Isabelle Puaut, Peter
Puschner, Jan Staschulat, and Per Stenström. 2008. The Worst-case
Execution-time Problem — Overview of Methods and Survey of Tools.
ACM Trans. Embed. Comput. Syst. 7, 3, Article 36 (May 2008). https:
//doi.org/10.1145/1347375.1347389
[41] Wenfei Wu, Keqiang He, and Aditya Akella. 2015. PerfSight: Perfor-
mance Diagnosis for Software Dataplanes. In Internet Measurement
Conf. https://doi.org/10.1145/2815675.2815698
[42] Wenfei Wu, Ying Zhang, and Sujata Banerjee. 2016. Automatic Syn-
thesis of NF Models by Program Analysis. In ACM Workshop on Hot
Topics in Networks. https://doi.org/10.1145/3005745.3005754
[43] Arseniy Zaostrovnykh, Solal Pirelli, Luis Pedrosa, Katerina Argyraki,
and George Candea. 2017. A Formally Verified NAT. In ACM SIGCOMM
Conf.
[44] Hongyi Zeng, Peyman Kazemian, George Varghese, and Nick McKe-
own. 2012. Automatic test packet generation. In Intl. Conf. on Emerging
Networking Experiments and Technologies.
385