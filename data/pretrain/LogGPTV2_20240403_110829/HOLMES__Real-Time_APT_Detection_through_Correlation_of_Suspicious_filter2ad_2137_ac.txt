


	





	
	
	
	
	

	



























	
	





	






	

Fig. 5. High-Level Scenario Graph for the Running Example.
of TTPs in the HSG at any time, making it possible to
carry out sophisticated analyses without impacting real-time
performance.
D. Avoiding Spurious Dependencies
By spurious dependencies, we refer to uninteresting and/or
irrelevant dependencies on the attacker‚Äôs activities. For in-
stance, in Fig. 2, the process nginx (P2) writes to the Ô¨Åle
/usr/log/nginx-error.log, and the cat process later reads
that Ô¨Åle. However, even though there is a dependency between
cat and the log Ô¨Åle, cat is unrelated to the attack and is
invoked independently through ssh. More generally, consider
any process that consumes secondary artifacts produced by
the attack activity, e.g., a log rotation system that copies a
log Ô¨Åle containing some fraction of entries produced by an
attacker‚Äôs process. Such processes, although they represent
benign background activity, will be Ô¨Çagged in the provenance
graph as having a dependence on the attacker‚Äôs processes. If
these spurious dependencies aren‚Äôt promptly pruned, there can
be a dependence explosion that can enormously increase the
size of HSGs. As a result, the Ô¨Ånal result presented to the
analyst may be full of benign activities, which can cause the
analyst to miss key attack steps embedded in a large graph. For
this reason, we prioritize stronger dependencies over weaker
ones, pruning away the latter as much as possible.
Intuitively, we can say that a process Pd has a strong
dependency on a process Pa if Pd is a descendant process
of Pa. Similarly, a Ô¨Åle or a socket has a strong dependency
on a process Pa if Pa or its descendant processes write to
this Ô¨Åle/socket. More generally, consider two entities and a
path between them in the provenance graph that indicates an
information between them. Determining if this Ô¨Çow represents
a strong or weak information Ô¨Çow is equivalent to determining
if the entities in the Ô¨Çow share compromised ancestors. If they
share compromised ancestors, they are part of the attacker‚Äôs
activities, and there is a strong dependency among them, which
must be prioritized. Otherwise, we consider the dependency to
be weak and deemphasize it in our analysis.
To generalize the above discussion to a case where there
may be multiple compromised processes, we introduce the
following notion of an ancestral cover AC(f ) of all processes
on an information Ô¨Çow path f:
‚àÄp ‚àà f ‚àÉa ‚àà AC(f ) a = p or a is an ancestor of p
Note that non-process nodes in f don‚Äôt affect the above deÔ¨Å-
nition. A minimum ancestral cover, ACmin(f ) is an ancestral
cover of minimum size. Intuitively, ACmin(f ) represents the
minimum number of ancestors that an attacker must compro-
mise (i.e., the number of exploits) to have full control of the
information Ô¨Çow path f. For instance, consider again the Ô¨Çow
from the nginx process, which is under the control of the
attacker, to the cat process. Since these two processes share
no common ancestors, the minimum ancestral cover for the
path among them has a size that is equal to 2. Therefore, to
control the cat process, an attacker would have to develop
an additional exploit for cat. This requires the attacker to Ô¨Årst
Ô¨Ånd a vulnerability in cat, then create a corresponding exploit,
and Ô¨Ånally, write this exploit into the log Ô¨Åle. By preferring
an ancestral cover of size 1, we capture the fact that such an
attack involving cat is a lot less likely than one where the
attack activities are executed by nginx and its descendants.
We can now deÔ¨Åne the notion of path f actor(N1, N2)
mentioned earlier in the discussion of TTPs. Intuitively, it
captures the extent of the attacker‚Äôs control over the Ô¨Çow from
N1 to N2. Based on the above discussion of using minimum
ancestral covers as a measure of dependency strength, we
deÔ¨Åne path f actor as follows. Consider all of the information
Ô¨Çow paths f1, ..., fn from N1 to N2, and let mi be the mini-
mum ancestral cover size for fi. Then, path f actor(N1, N2)
is simply the minimum value among m1, . . . , mn.
if process N2 is a child of N1,
then there
is a path with just a single edge between N1 to N2. The
size of minimum ancestral cover for this path is 1 since
N1 is an ancestor of N2. In contrast, the (sole) path from
nginx to cat has a minimum ancestral cover of size 2, so
path f actor(nginx, cat) = 2.
Note that
We describe an efÔ¨Åcient computation of path f actor in
Section V. In our experience, the use of path f actor greatly
mitigated dependency explosions by prioritizing attacker-
inÔ¨Çuenced Ô¨Çows.
E. Noise Reduction
One of the challenges in the analysis of audit logs for attack
detection and forensics is the presence of noise, i.e., benign
events matching TTP rules. Long-living processes such as
browsers, web servers, and SSH daemons trigger TTP matches
from time to time. To cut down these false positives, we
incorporate noise reduction rules based on training data. We
leverage two notions: (1) benign prerequisite matches and (2)
benign data Ô¨Çow quantity.
Noise reduction based on benign prerequisites. For each
process, our system learns prerequisites that Ô¨Åred frequently
when the system is run in a benign context. At runtime, when
the prerequisites of a triggered TTP match the prerequisites
that were encountered during training, we ignore the match.
(cid:18)(cid:18)(cid:21)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:10 UTC from IEEE Xplore.  Restrictions apply. 
"!!
"!
!
!  
" !$

"!!
#	
#	
$
%! 
$
!



 
!

! 
 
!!


Fig. 6. HOLMES Architecture.
Noise reduction based on data Ô¨Çow quantity. Filtering
based on benign prerequisites may lead to false negatives: a
malicious event may go unnoticed because it matches behavior
observed during the learning phase. For instance, even with-
out any attack, nginx reads /etc/passwd during its startup
phase. However, if we were to whitelist all nginx access
to /etc/passwd, then a subsequent read by a compromised
nginx server will go unnoticed.
To tackle this problem, we enhance our learning to in-
corporate quantities of information Ô¨Çow, measured in bytes
transferred. For instance, the amount of information that can
Ô¨Çow from the Ô¨Åle /etc/passwd to nginx is equal to the size of
that Ô¨Åle, since nginx reads that Ô¨Åle only once. Therefore, if sig-
niÔ¨Åcantly more bytes are observed Ô¨Çowing from /etc/passwd
to nginx, then this Ô¨Çow may be part of an attack. To determine
the cut-off points for information quantity, we observe process-
Ô¨Åle and process-socket pairs over a period in a benign setting.
F. Signal Correlation and Detection
Given a set of HSGs, how do we distinguish the ones that
constitute an attack with a high conÔ¨Ådence? We address this
challenge by assigning a severity score to each HSG. This
assignment proceeds in two steps further described below.
Threat Tuples. First, we represent the attacker‚Äôs progress in a
campaign by an abstract threat tuple associated with the cor-
responding HSG. In particular, for every HSG, a threat tuple
is a 7-tuple (cid:5)S1, S2, S3, ..., S7(cid:6) where each Si corresponds to
the severity level of the APT stage at index i of the HSG. We
chose 7-tuples based on an extensive survey of APTs in the
wild [3], but other choices are possible as well.
Since different TTPs belonging to a certain APT stage may
have different severity levels, there are usually multiple candi-
dates to pick from. It is natural to choose the highest severity
level among these candidates. For instance, the threat tuple
associated with the HSG of Fig. 5 is (cid:5)M, L, H, H,‚àí, H, M(cid:6).
This tuple contains 6 entries because its matched TTPs belong
to 6 different APT stages. The entries are ordered according
to the order of the APT stages in the kill-chain. For instance,
the Ô¨Årst entry of the tuple is M since the most severe TTP be-
longing to Initial Reconnaissance in the graph has severity M.
HSG Ranking and Prioritization. To rank HSGs, we Ô¨Årst
transform a threat tuple to a numeric value. In particular,
we Ô¨Årst map each element of a threat tuple to a numerical
value based on the conversion table (Table 7) included in
the Common Vulnerability Scoring System (CVSS), a vendor-
neutral
industry standard created through the collaboration
of security professionals across commercial, non-commercial,
and academic sectors [5]. Alternative scoring choices may be
made by an enterprise, taking into context its perceived threats
and past threat history.
Qualitative level
Quantitative Range
Low
Medium
High
Critical
TABLE 7.
Rounded up
Average Value
0.1 - 3.9
4.0 - 6.9
7.0 - 8.9
9.0 - 10.0
NIST severity rating scale
2.0
6.0
8.0
10.0
Next, we combine the numeric scores for the 7 APT stages
into a single overall score. The formula that we use to compute
this score was designed with two main criteria in mind: (1)
Ô¨Çexibility and customization, and (2) the correlation of APT
steps is reÔ¨Çected in the magniÔ¨Åcation of the score as the
steps unfold. To address these criteria, we associate a weight
with each entry in the converted threat tuple and calculate a
weighted product of the threat tuple as the score. These weights
are conÔ¨Ågurable by a system administrator, and they can be
used to prioritize detection of speciÔ¨Åc stages over other stages.
Using a training set, we performed several experiments and
compared results using other schemes, such as weighted sum,
exponential sum, and geometric sum. For each equation, we
measured the average margin between the benign subgraph
scores and the attack subgraph scores after normalization and
found that the weighted product had the best results. Hence
we use the following criteria to Ô¨Çag an APT attack:
n(cid:2)
i=1
(Si)wi ‚â• œÑ
(1)
Here, n is the number of APT stages, wi and Si denote
respectively the weight and severity of stage i, and œÑ is the
detection threshold. If no TTP occurs in stage i, we set Si = 1.
V.
IMPLEMENTATION
Stream Consumption for Provenance Graph Construction.
Fig. 6 shows the architecture of HOLMES. To achieve platform
independence, audit records from different OSs are normal-
ized to a common data representation (CDR) with shared
abstractions for various system entities. For streamlined audit
data processing, CDR-based audit records are published to a
stream processing server (Kafka) and real-time analysis and
detection proceeds by consuming from the streaming server.
We use our SLEUTH system [22] for stream consumption,
causality tracking, and provenance graph construction, so we
don‚Äôt describe those steps in detail here.
Policy Matching Engine and HSG Construction. The Policy
Matching Engine takes the TTP rule speciÔ¨Åcations as input
and operates on the provenance graph. A representative set of
the TTP rule speciÔ¨Åcations used in the current implementation
(cid:18)(cid:18)(cid:21)(cid:20)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:43:10 UTC from IEEE Xplore.  Restrictions apply. 
APT Stage
Initial
Compromise(P )
TTP
U ntrusted Read(S, P )
Event
Family
READ
M ake M em Exec(P, M )
MPROTECT
M ake F ile Exec(P, F )
CHMOD
Establish
F oothold(P )
P rivilege
Escalation(P )
Internal
Recon(P )
M ove
Laterally(P )
Complete
M ission(P )
Cleanup
T racks(P )
U ntrusted F ile Exec(F, P )
Shell Exec(F, P )
CnC(P, S)
Sudo Exec(F, P )
EXEC
EXEC
SEND
EXEC
Switch SU (U, P )
SETUID
Sensitive Read(F, P )
Sensitive Command(P, P
(cid:2))
Send Internal(P, S)
Sensitive Leak(P, S)
Destroy System(F, P )
Clear Logs(P, F )
READ
FORK
SEND
SEND
WRITE/
UNLINK
UNLINK
Sensitive T emp RM (P, F )
UNLINK
U ntrusted F ile RM (P, F )
UNLINK
Severity
L
M
H
C
M
L
H
H
M
H
M
H
C
H
M
M
(cid:2)
, F ) <= path thres
, P ) <= path thres
, P ) <= path thres
, P ) <= path thres
, P ) <= path thres
(cid:2)) : path f actor(P
(cid:2)
(cid:2)) : path f actor(P
, F ) <= path thres
(cid:2)(cid:2)
, P ) <= path thres
(cid:2)) : path f actor(P