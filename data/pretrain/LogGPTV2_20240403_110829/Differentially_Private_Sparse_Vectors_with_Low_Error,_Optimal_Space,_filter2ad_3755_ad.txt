(𝑝𝑞)𝑖(𝑞 − 𝑝)
(cid:18)2𝑖
𝑖
(cid:19)
∞∑︁
𝑛
(cid:18)2𝑖
(cid:19)
𝑖
𝑖
(𝑝𝑞)𝑖
= 2(𝑞 − 𝑝)
𝑖=0
4𝑝𝑞
(𝑞 − 𝑝)2 .
=
We are now ready to find the expected last non-negative step of
an infinite simple random walk as:
𝑖=0 𝑖(cid:0)2𝑖
The last equality follows from the identity∞
2𝑝𝑞
(𝑞−𝑝)3 . See Appendix A for a proof of this identity.
𝑖
(cid:1)(𝑝𝑞)𝑖 =
□
We are now ready to bound E[|𝑦𝑖 − ˜𝑦𝑖|]. We consider entries
with value at most 𝛽, i.e., 𝑦𝑖 ≤ 𝑚.
Lemma 4.7. Let 𝑦𝑖 ≤ 𝑚 and 𝛾 = 𝛼+2
1+ 𝛼𝑘
value of |𝑦𝑖 − ˜𝑦𝑖| is bounded such that
E[|𝑦𝑖 − ˜𝑦𝑖|] ≤ 4𝛼 + 4
𝛼2
𝑠
+ 4𝛾 + 4
𝛾2
.
− 2. Then the expected
from the definition of ¯𝑦𝑖 as a maximum that𝑦𝑖
Proof. Recall the definition of 𝑃 from Algorithm 3. Let ¯𝑦𝑖 ∈ 𝑃
denote an element furthest from 𝑦𝑖 that is |𝑦𝑖 − 𝑎| ≤ |𝑦𝑖 − ¯𝑦𝑖| for
all 𝑎 ∈ 𝑃. It it clearly sufficient to consider ¯𝑦𝑖 for the proof since
|𝑦𝑖 − ˜𝑦𝑖| ≤ |𝑦𝑖 − ¯𝑦𝑖|. We first consider the case of ¯𝑦𝑖 ≤ 𝑦𝑖. It follows
𝑗= ¯𝑦𝑖+1 ˜𝑧ℎ 𝑗 (𝑖),𝑗 ≤ 0.
As such at least half the bits ( ˜𝑧ℎ ¯𝑦𝑖+1(𝑖), ¯𝑦𝑖+1, . . . , ˜𝑧ℎ𝑦𝑖 (𝑖),𝑦𝑖) must be
zero, that is they were flipped by randomized response in Step (3)
of Algorithm 2. As such the length of the longest interval ending
at bit ˜𝑧ℎ𝑦𝑖 (𝑖),𝑦𝑖
where at least half the bits were flipped is an upper
bound on the value of 𝑦𝑖 − ¯𝑦𝑖. The expected size of said interval is
bounded by the expected last non-negative step of a simple random
walk with 𝑝 =
1
𝛼+2. It follows from Lemma 4.6 that:
E[𝑦𝑖 − ¯𝑦𝑖 | ¯𝑦𝑖 ≤ 𝑦𝑖] ≤
4𝑝𝑞
(𝑞 − 𝑝)2 =
4𝛼+4
(𝛼+2)2
𝛼2
(𝛼+2)2
4𝛼 + 4
𝛼2
=
.
We can use a similar argument when 𝑦𝑖 ≥ ¯𝑦𝑖 to show that at
least half the bits in ( ˜𝑧ℎ𝑦𝑖+1(𝑖),𝑦𝑖+1, . . . , ˜𝑧ℎ ¯𝑦𝑖 (𝑖), ¯𝑦𝑖) must be 1 since
¯𝑦𝑖 is a maximum. In this case we have to consider the possibility
of hash collisions. Each hash function maps to [𝑠] and at most 𝑘
entries result in a hash collision. The probability of a hash collision
is at most 𝑘
𝑠 using a union bound. As such for 𝑗 > 𝑦𝑖 we have
𝛼+2 . We let 1+ 𝛼𝑘
1+ 𝛼𝑘
Pr[ ˜𝑧ℎ 𝑗 (𝑖),𝑗 = 1] ≤ (1 − 𝑘
1
𝛾+2
such that E[ ¯𝑦𝑖 − 𝑦𝑖
𝛾2 by Lemma 4.6 and the
𝑠 · 𝑞 =
𝑠 ) · 𝑝 + 𝑘
| ¯𝑦𝑖 ≥ 𝑦𝑖] ≤ 4𝛾+4
𝛼+2 =
𝑠
𝑠
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1229calculation above. We isolate 𝛾 to find:
1
𝛾 + 2 =
𝛾 + 2 =
𝛾 =
(⇔)
(⇔)
𝑠
1 + 𝛼𝑘
𝛼 + 2
𝛼 + 2
1 + 𝛼𝑘
𝛼 + 2
1 + 𝛼𝑘
𝑠
𝑠
− 2 .
Note that 𝛾 > 0 holds due to the requirement 𝑠 > 2𝑘 of Algo-
rithm 2. By conditional expectation, we may upper bound the total
expected error by
E[|𝑦𝑖 − ˜𝑦𝑖|] ≤ E[|𝑦𝑖 − ¯𝑦𝑖|]
≤ E[𝑦𝑖 − ¯𝑦𝑖 | ¯𝑦𝑖 ≤ 𝑦𝑖] + E[ ¯𝑦𝑖 − 𝑦𝑖 | ¯𝑦𝑖 ≥ 𝑦𝑖]
≤ 4𝛼 + 4
𝛼2
+ 4𝛾 + 4
𝛾2
.
(1)
□
As such we can bound the expected per-entry error for entries
with a true value of at most 𝛽 by a function of the parameters 𝛼
and 𝑠. In Section 6 we discuss the choice of these parameters based
on the upper bond and experiments. For any fixed values of 𝛼 and
𝑠 we have:
𝑘
Lemma 4.8. Let 𝛼 = Θ(1) and 𝑠 = Θ(𝑘). Then the expected per-
entry error of Algorithm 3 is E[|𝑥𝑖 − ˜𝑥𝑖|] ≤ max(0, 𝑥𝑖 − 𝛽) + 𝑂(1).
Proof. It follows from Lemmas 4.4 and 4.7 that the expected
error for any entry bounded by 𝛽 is:
(cid:18) 1
2 + 4𝛼 + 4
𝛼2
(cid:19)
+ 4𝛾 + 4
𝛾2
· 𝛼 ,
E[|𝑥𝑖 − ˜𝑥𝑖| | 𝑥𝑖 ≤ 𝛽] ≤
where 𝛾 = 𝛼+2
1+ 𝛼𝑘
− 2. Entries above 𝛽 have an additional error of
up to 𝑥𝑖 − 𝛽, since 𝑦𝑖 = 𝑚 and 𝑦𝑖 > 𝑚 are represented identically
in the embedding by Algorithm 2. Since 𝛼 and 𝑘
𝑠 are constants we
have:
𝑠
E[|𝑥𝑖 − ˜𝑥𝑖|] ≤ max(0, 𝑥𝑖 − 𝛽) + 𝑂(1) .
□
Next, we bound the tail probabilities for the per-entry error of the
mechanism. We bound the error of the estimate ˜𝑦𝑖, which implies
bounds on the error of the mechanism.
Lemma 4.9. Let 𝛾 = 𝛼+2
1+ 𝛼𝑘
𝑠
Then for Algorithm 3 we have:
−2 and 𝜏 > 0. Let 𝑝 =
𝛾+2 and 𝑞 = 1−𝑝.
1
Pr[|𝑦𝑖 − ˜𝑦𝑖| ≥ 𝜏] ≤ 2 · (4𝑝𝑞)𝜏/2
√
𝜋(𝑞 − 𝑝)
,
Proof. Let 𝑆 be a simple random walk. We find an upper bound
on the probability that the position of the last non-negative step in
8
𝑗
𝑛
(cid:19)
(cid:18)2𝑗
∞∑︁
Pr[(max
𝑆 is at least 𝜏:
: 𝑆𝑛 ≥ 0) ≥ 𝜏] =
∞∑︁
𝑗=⌈𝜏/2⌉
≤ 𝑞 − 𝑝√
𝑞 − 𝑝√
≤ (4𝑝𝑞)𝜏/2
(cid:1) ≤ 4𝑗√
where the first inequality follows from(cid:0)2𝑗
√
𝜋(𝑞 − 𝑝) ,
𝑗=⌈𝜏/2⌉
(4𝑝𝑞) ⌈𝜏/2⌉
1 − 4𝑝𝑞
=
𝜋
𝜋
(𝑝𝑞) 𝑗 (𝑞 − 𝑝)
(4𝑝𝑞) 𝑗
𝑗
when 𝑗 ≥ 1 [9].
The last inequality follows from 1− 4𝑝𝑞 = (𝑞 − 𝑝)2. As discussed in
the proof of Lemma 4.7, the expectation of |𝑦𝑖 − ˜𝑦𝑖| can be bounded
1
𝛾+2.
by two random walks each with 𝑝 at most
□
𝛾+2 and 𝑞 = 1 − 𝑝. With
1
Lemma 4.10. Let 𝛾 = 𝛼+2
1+ 𝛼𝑘
− 2, 𝑝 =
probability at least 1 − 𝜓 for Algorithm 3 we have:
𝜋 𝑗
𝑠
2 log(cid:16)
(cid:17)
|𝑦𝑖 − ˜𝑦𝑖| ≤
2
√
𝜋 (𝑞−𝑝)
log(1/(4𝑝𝑞))
𝜓
.
Proof. We set 𝜓 =
2·(4𝑝𝑞)𝜏/2
√
𝜋 (𝑞−𝑝) and isolate 𝜏 as follows:
=
𝜓 =
(4𝑝𝑞)−𝜏/2
2 · (4𝑝𝑞)𝜏/2
√
𝜋(𝑞 − 𝑝)
2
√
𝜋(𝑞 − 𝑝)
2
√
𝜋(𝑞 − 𝑝)
2
√
𝜋 (𝑞−𝑝)
log(1/(4𝑝𝑞))
By Lemma 4.9 we have: Pr[|𝑦𝑖 − ˜𝑦𝑖| ≤ 𝜏] ≥ 1 − 𝜓.
(cid:18)
2 log(cid:16)
log(1/(4𝑝𝑞)) · 𝜏
2 = log
𝜏 =
𝜓
𝜓
𝜓
(cid:19)
(cid:17)
.
□
Up to constant factors, the tail probabilities of our mechanism
are similar to the properties of the Laplace mechanism summarized
in Proposition 2.7. The probabilities depend on the parameters of
the mechanism. In Section 6 we fix the parameters and evaluate the
error in practice. We summarize the tail probabilities for |𝑥𝑖 − ˜𝑥𝑖|
in Lemma 4.11.
Lemma 4.11. Let 𝛾 = 𝛼+2
1+ 𝛼𝑘
− 2, 𝑝 =
𝜏 ≥ 𝛼. Then for Algorithm 3 we have:
𝑠
𝛾+2 , 𝑞 = 1 − 𝑝, 𝑥𝑖 ≤ 𝛽, and
1
2 · (4𝑝𝑞)(𝜏/2𝛼)−1/2
Pr[|𝑥𝑖 − ˜𝑥𝑖| ≥ 𝜏] <
√
𝜋(𝑞 − 𝑝)
With probability at least 1 − 𝜓 we have:
2
√
𝜋 (𝑞−𝑝)
log(1/(4𝑝𝑞))
|𝑥𝑖 − ˜𝑥𝑖| <(cid:169)(cid:173)(cid:173)(cid:171)1 +