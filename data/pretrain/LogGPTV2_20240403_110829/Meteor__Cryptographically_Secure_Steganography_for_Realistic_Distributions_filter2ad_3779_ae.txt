of possible next tokens and P is the probability associated
with each of these tokens.
To illustrate Meteor‚Äôs support for different model types, we im-
plemented the algorithm with the weakened version of the GPT-2
language model released by OpenAI and two character-level recur-
rent neural networks (RNN) that we train. The GPT-2 model [51]
is a generative model of the English language. It parses language
into a vocabulary of words and generates words when given previ-
ous context. Meteor encodes stegotext into these generated words.
The character-level models generate ASCII characters in each it-
eration. These models output lower-quality English text, but are
more generalizable. Character-level models work with any data that
can be represented as text, including other languages and non-text
protocols, whereas word-level models are specific to the English
language models.
Our GPT-2 codebase builds upon that of [44]. We note that the
next-generation GPT language model, GPT-3, has been published
by OpenAI [52]; however, at the time of this writing, the codebase
for the GPT-3 has not been released. The GPT-3 interface is the same
as the GPT-2, meaning integration will be automatic, increasing
stegotext quality while maintaining security guarantees. Example
stegotext generated with the GPT-2 model can be found in Appendix
C.
Figure 5 shows how to instantiate the SampleùõΩM and RecoverùõΩM
algorithms from Section 3 with the distribution represented as a gen-
erative model M (in discussion of classical steganography, we used
D). Both algorithms use NextM(H), which generates an array of
possible next tokens T and an array of probabilities associated with
each token P using the model‚Äôs internal structure. The SampleùõΩM
Session 5C: Messaging and Privacy CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea1538Table 2: Performance measurements for Meteor on the GPT-
2 by device for a shorter context. Times are provided in sec-
onds.
Device
GPU
CPU
Mobile
Load
5.867
5.234
1.830
Encode Decode Overhead (time)
6.899
41.221
473.58
1√ó
4.6√ó
49.5√ó
6.095
40.334
457.57
for generative networks accumulates the probabilities and selects
the first token for which the cumulative probability exceeds the
randomness supplied. This is equivalent to multinomial sampling,
and is the unmodified method of sampling normally from the GPT-2
model. In the unmodified (i.e., non-Meteor) case, the GPT-2 chooses
a true random value ùëü instead of a PRG as in Meteor. RecoverùõΩM
inverts the process, returning the entire set of random values that
would yield the target sample ùë†.
In addition to the GPT-2 variant, we trained two character-level
RNN models to test with Meteor, using the code of [103] with lo-
cally trained models. Each model uses long short term memory
(LSTM) cells to store state [89]. The first model, named ‚ÄúWikipedia‚Äù,
was trained on the Hutter Prize dataset [104], which consists of
a subset of English Wikipedia articles. The data from this model
contains English text structured with Wiki markup. The output
of this model is good, but its character-level nature makes its out-
puts less convincing human text than GPT-2 output. The second
model, named ‚ÄúHTTP Headers‚Äù, consist of the headers for 530,128
HTTP GET requests from a 2014 ZMap scan of the internet IPv4
space [105, 106]. This highly structured dataset would facilitate
hiding messages amongst other HTTP requests. We note that the
flexibility of character-level models allows us to generalize both
text-like channels and protocol-esque channels [55]. Both mod-
els have three hidden layers. The Wikipedia model has a hidden
layer size 795 and was trained for 25,000 epochs. The HTTP head-
ers model has size 512 and was for 5,000 epochs, due to its more
structured nature. The two models were trained at a batch size of
100 characters and learning rate 0.001. Example output from the
Wikipedia character-level model can be found in Appendix C.
Evaluation hardware. To measure performance across different
hardware types, we evaluate Meteor on 3 systems: (1) Desktop/GPU,
a Linux workstation with an Intel Core i7-6700 CPU, NVIDIA TI-
TAN X GPU, and 8 GiB of RAM, (2) Laptop/CPU, a Linux laptop
with an Intel Core i7-4700MQ CPU, no discrete GPU, and 8 GiB of
RAM, and (3) Mobile, an iPhone X running iOS 13. The Desktop
ran benchmarks on the GPU, while the Laptop machine ran on the
CPU; as such, the Laptop is more representative of consumer hard-
ware. We evaluate Meteor on both the Desktop and Laptop using
each of the three models discussed above. Additionally, we evaluate
reordering and native compression optimizations (see below). The
results are summarized in Table 3. We discuss mobile benchmarks
separately at the end of this section.
Model performance. The capacity, or number of bits encoded
per token, is much higher for the GPT-2 model examples than for
the Wikipedia and HTTP Headers models. Intuitively, the word-
level nature of GPT-2 means there is usually more entropy in each
Figure 6: Comparison of plaintext length versus time to run
encoding and decoding for different Meteor models. ùëÖ =
0.9745 (GPT-2), 0.9709 (Wikipedia), 0.9502 (HTTP Headers)
distribution, whereas the character-level models have, at most, 100
printable ASCII characters from which to sample; this pushes the
capacity of a single token to be much higher as a result. The stark
difference in capacity between the capacities of Wikipedia and
HTTP Headers can be attributed to the difference in structure of
the training data. The Wikipedia dataset, although structured, is
mostly English text. On the other hand, the HTTP Headers dataset is
based on the HTTP protocol, which is rigid in structure ‚Äî variation
only exists in fields that can change, such as dates and URLs.
Encoding statistics. Our next suite of benchmarks measures the
relationship between the length of message and the time it takes
to produce a stegotext. We generated plaintexts randomly and
encoded them, incrementing the length of the message by one in
each run. The results are plotted in Figure 6, which shows a clear
linear relationship between the two variables. It is also apparent
from the plot that the variance in encoding time increases as the
length increases. This is because as tokens are selected, the model
state can diverge; in some of these branches, the entropy may be
very low, causing longer encoding times. This is amplified in the
HTTP Headers model, as the baseline entropy is already very low.
Heuristic optimizations. In addition to implementing Meteor, we
also evaluated two heuristic optimizations that could yield shorter
stegotext. The first optimization is deterministically reordering
the model‚Äôs output distribution intervals to maximize expected
throughput. Because this deterministic process does not change the
relative sizes of the interval, it does not impact the distribution of
the stegotext. However, because the placement of the intervals is
usually arbitrary, it is possible to move large intervals that would
normally have no shared prefix to a starting location where there is
a shared prefix, potentially increasing throughput. A more thorough
discussion of this technique can be found in Appendix B.
We evaluate this optimization for all three of our models (see
Table 3). For the GPT-2 model, we see a marked (24.8%) increase in
capacity as well as a proportional reduction in stegotext length as a
result of reordering the model outputs. The reordering does induce
computational overhead, as the distribution over which the heuris-
tic is performed is large (max 50,256 tokens). Reordering induces
050100150200250300PlaintextLength020406080100TimetoEncodeandDecodeGPT-2WikipediaHTMLHeadersSession 5C: Messaging and Privacy CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea1539a 0.5% overhead in the Laptop/CPU, where updating the model is
slow, and 69.0% overhead in the Desktop/GPU, where updating the
model is fast. For the lower entropy models, the reordering algo-
rithm we use is significantly faster, but yields mixed results. We
believe these mixed results are an artifact of our choice of greedy
reordering algorithms, which may perform poorly with heavily
biased distributions.
The second optimization is to use the model itself as a compres-
sion function when encoding with an English language model, as
in [44]. This technique leverages the fact that all known words in
the model‚Äôs vocabulary are internally represented by a unique num-
ber, taking fewer bits than its normal ASCII representation. Before
encoding, the secret message can be tokenized and each token can
be replaced by its unique identifier. These identifiers are then parsed
as bits and encoded as normal. When implemented with GPT-2,
we see a 47.77% decrease in time spent on CPU, and an associated
52.5% decrease in stegotext size. While powerful, this technique
can only be used to encode English language messages into Eng-
lish language models. Compressing the plaintext message using
traditional compression (e.g., GZip) would yield similar results.
Mobile benchmarks. Because Meteor is intended for censorship
resistance, it is natural to benchmark it on mobile devices, where
most sensitive communication happens. We implement Meteor on
iOS using the CoreML framework, utilizing an existing GPT-2 iOS
implementation as a base [107]. To our knowledge, our work repre-
sents the first evaluation of a neural network-based steganographic
system on a mobile device. Our implementation, in Swift, employs
an even smaller version of the GPT-2 model which fits on mobile
devices as it uses smaller size context. An example of the output
from this experiment can be found in Appendix C.
Our results are summarized in Table 2. The Mobile benchmark in
the table was performed on the iPhone X Simulator, as we wished to
instrument and profile our tests. We separately confirmed that sim-
ulator runtimes were similar to those of actual iPhone X hardware.
While Laptop/CPU is 4.6√ó slower than Desktop/GPU, the Mobile
runtime is a massive 49.5√ó slower than the baseline case. While
deep learning is supported on mobile platforms like iOS, the inten-
sive, iterative computations required by Meteor and other neural
stegosystems are not performant on mobile systems. Nonetheless,
our proof-of-concept demonstrates that Meteor could be used in
a mobile context, and hardware improvements [108] would allow
for secure communication between users even when available com-
munication platforms do not offer end-to-end encryption, such as
WeChat.
7 COMPARISON TO NLP-BASED
STEGANOGRAPHY
Noting the appeal of hiding sensitive messages in natural text, re-
searchers in the field of natural language processing (NLP) have
recently initiated an independent study of steganography. Unfor-
tunately, this work does not carefully address the security impli-
cations of developing steganographic systems from NLP models.
Instead, the results employ a variety of ad-hoc techniques for em-
bedding secret messages into the output of sophisticated models.
The resulting papers, often published in top NLP conferences, lack
rigorous security analyses; indeed, existing work cannot be proven
secure under the definitions common in the cryptographic liter-
ature. Highlighting this weakness, there is a concurrent line of
work in the same conferences showing concrete attacks on these
schemes, e.g., [45‚Äì50].
The first wave of steganographic techniques in the NLP com-
munity leverages synonyms and grammatical reorganization for
encoding, e.g., [32‚Äì36, 42]. The key observation in this work is
that natural variation in linguistic patterns can be used to hide
information. For instance, if one of two synonyms can be used in
a sentence, each with probability .5, then the selection conveys
a bit of information. Similarly, comma usage or word order can
be used to encode small amounts of information. Because not all
possible linguistic variations occur with equal likelihood, some of
these works adapt a Huffman encoding scheme to facilitate variable
length encoding, e.g., [32, 36]. These approaches rely on linguistic
idiosyncrasies and are therefore not generalizable.
More recently, researchers found ways to use the structure of
these models to steganographically encode information, including
LSTMs [37], Generative Adversarial Networks [38], Markov Mod-
els [39], and other forms of Deep Neural Networks [40, 41, 43, 44].
Rather than give an exhaustive description of the encoding tech-
niques used in these works, we give a brief description of the most
important techniques.
Early constructions directly modified the distributions. One such
construction [37] organized the distribution into ‚Äúbins,‚Äù each rep-
resenting a short bitstring, and randomly selected an output from
the bins corresponding to the message.2 Building on this intuition,
other research [41, 43] uses Huffman coding to encode variable
numbers of bit in each iteration. More recent work has attempted
to use the message itself as the sampling method, a method known
as ‚Äúarithmetic coding‚Äù [44]. This method attempts to convert a
plaintext message into a deterministic stegotext based on its con-
tents, iteratively using bits from the message to sample into the
distribution. The first two constructions heavily modify the output
distribution, rendering stegotext easily detectable. The arithmetic
construction is also insecure, since it reuses randomness in multi-
ple sampling events, a problem similar to the one that Meteor is
designed to overcome.
The relaxed adversarial models considered in the NLP commu-
nity lead to significantly less robust constructions. For instance,
the adversaries in the NLP literature do not have access to the
model [37, 41, 43, 44], significantly limiting the attacks they can
mount. Without this assumption, an adversary can clearly differen-
tiate between a stegotext and covertext by identifying biases in the
output distribution. The adversary compares the candidate output
to random samples from the model, easily distinguishing when a
stegosystem is being run and defeating the purpose entirely.
The NLP threat model folds in the face of an advanced, persis-
tent adversary who can always exfiltrate the model through other
means. Moreover, recent advanced in adversarial machine learning
have demonstrated how even the ‚Äúsecret‚Äù parameters of a black-
box model can be extracted by seeing enough output [109‚Äì111],
unlike that of encryption keys or pseudorandom functions. This
pervasive requirement that the model remains private informa-
tion is therefore unreasonable. Unable to achieve cryptographic
2A similar, but secure, partition based approach is investigated in [27]
Session 5C: Messaging and Privacy CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea1540Table 3: Model statistics for encoding a 160-byte plaintext. Timing results reflect model load, encoding, and decoding combined.
Mode
GPT-2
GPT-2 (Reorder)
GPT-2 (Compress)
Wikipedia
Wikipedia (Reorder)
HTTP Headers
HTTP Headers (Reorder)