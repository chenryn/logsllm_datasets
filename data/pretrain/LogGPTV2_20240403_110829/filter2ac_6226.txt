**Title: Black Hat EU-20: Light Commands - Hacking Voice Assistants with Lasers**

In the near future, our homes will likely be equipped with numerous Internet of Things (IoT) devices. These devices often use advanced microphones to listen for and respond to voice commands. Our research, known as "Light Commands," demonstrates a novel laser-based injection attack that can exploit these microphones. By modulating the amplitude of a laser light, we can inject inaudible and invisible commands into the microphones of smart speakers, phones, and tablets, even from a distance and through glass windows.

In this presentation, we will cover:

1. **The Mechanism of Light Commands:** We will explain how this attack exploits a physical vulnerability in MEMS (Micro-Electro-Mechanical Systems) microphones, causing them to interpret light as sound.
   
2. **Remote Command Injection:** We will demonstrate how it is possible to remotely inject and execute unauthorized commands on popular voice assistants such as Alexa, Portal, Google Assistant, and Siri.

3. **Security Vulnerabilities in Connected Ecosystems:** We will discuss how the devices connected to these voice assistants, including smart locks, home switches, and even cars, are susceptible to common security vulnerabilities (e.g., PIN brute-forcing). This makes the Light Commands attack even more dangerous by enabling broader access and control over a user's environment.

This talk aims to highlight the potential risks associated with the widespread adoption of voice-activated technology and to encourage the development of more robust security measures to protect against such attacks.