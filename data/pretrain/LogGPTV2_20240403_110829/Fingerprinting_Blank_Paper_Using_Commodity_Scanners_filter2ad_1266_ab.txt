(cid:107)(x,oy,oz)(cid:62)(cid:107)3
(cid:107)(x,oy,oz)(cid:62)(cid:107)3 dx
2oy
= ny ρs .
(2)
That is, the difference dy directly yields the y component ny
of the surface normal n, multiplied by the albedo ρ and a
ﬁxed constant s that is dependent on the scanner geometry
only. Analogously, dx = I270◦ − I90◦ = nx ρs. With four scans
we can determine each surface normal’s projection into to
xy-plane, n2 = (nx,ny), up to a scale. The factor s is assumed
to be fairly constant across the page, and the remaining scale
is given by the local surface reﬂectance ρ of the paper at
any given location.
Application of equation (2) requires precise alignment of
each surface point across all scans. To reduce the effect
of alignment imprecision and to isolate frequencies of the
document that are stable across scans and different scanners,
we apply a low-pass ﬁlter to the document and down-sample
it. In our experiments we scanned each document at 1200
SPI (samples per inch) and down-sampled it by a factor of
eight, resulting in an effective resolution of 150 SPI.
After processing the four scans of a document, we recover
the surface texture as a two-dimensional vector ﬁeld with d =
(dx,dy)(cid:62) = ρsn2 deﬁned at each location of the document.
3.2. Computing the feature vector
From this vector ﬁeld d we determine the feature vector
of the document. A good feature vector captures unique
characteristics of a document, while at the same time being
concise. We model the feature vector V as an N-bit vector
of independent bits fi whose values are derived from the
surface normals of the document.
In contrast to previous approaches, we do not extract a
feature vector from a single region of the document, but we
compute the feature vector from a collection of representative
subsections, patches, of the document. For documents down-
sampled to 150 SPI, we choose square patches of 8×8
samples, centered at a series of random locations pi. For even
spacing we draw these locations from a Voronoi distribution
[7]: we use the random seed stored in the ﬁngerprint to
initialize P pseudorandom start locations on the page and
use Lloyd’s Voronoi relaxation to obtain a set of locations
distributed evenly across the document, as shown in Figure 4.
In principle one could now directly compare the patches
of a document A to corresponding patches in a document
B in order to verify two documents as being the same. The
disadvantages are that this requires access to the patches of B
when verifying A, which would require an amount of storage
prohibitive for ofﬂine applications, and, more importantly,
that it would reveal the original document’s structure to a
forger. Hence, we derive a compressed feature vector and
store its hash along with a secure sketch to hide the feature
vector from an adversary.
Each patch contains 64 2-D samples di, i = 1, . . . ,64,
which we stack to create a patch vector p ∈ IR128. Each
patch contributes T bits to the feature vector. We compute
these feature bits fi, i = 1, . . . ,T , by subsequently comparing
the patch vector to T template vectors ti. The template
vectors are a set of pseudorandomly chosen orthonormal
vectors in IR128 generated using the same seed that is used
to determine patch locations: the ti are initialized with vector
components drawn from a N(0,1) distribution, followed by
Gram-Schmidt orthonormalization. Each template vector can
be interpreted as a template patch of 8×8 2-vectors denoting
surface orientation.
The comparison is performed by correlating the patch
vector p and each template vector ti; i.e., by computing
the dot product (cid:104)p,ti(cid:105). Positive correlation means that
surface orientations in the patch and the template patch
Figure 4. Sample Voronoi distribution of 100 points in the
unit square. Voronoi distributions give relatively uniform
coverage of a region, while simultaneously ensuring no
overlap of patches.
4
00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91100 Locations Drawn from Voronoi Distribution X-Axis of Unit SquareY-Axis of Unit Squareagree; negative correlation denotes mostly opposing surface
orientations. The respective feature bit is determined by the
sign of the correlation:
1 + sign((cid:104)p,ti(cid:105))
fi =
.
(3)
2
See Algorithm 1 for further illustration.
V = bool[PT ]
Retrieve surface orientation vectors of document
Extract P patches based on Voronoi distribution
for p = 1 to P do
template = generate new set of T pseudo-
random orthonormal template vectors
for i = 1 to T do
c = (cid:104) patch[p], template[i] (cid:105)
f(p−1)P+i = TRUE if c > 0
end for
end for
Algorithm 1: Feature vector generation.
The number of independent bits that can be extracted
from a patch in this way is limited and depends on the
amount of information contained in a patch. A standard
tool to characterize this amount of information is principal
component analysis (PCA) [8]. We performed PCA on a large
set of randomly chosen patches from different documents.
The results show that for 8×8-patches 75% of the information
can be expressed with only 32 principal components; that
is, within a 32-dimensional subspace. We hence decided to
restrict ourselves to T = 32 of 128 possible orthonormal
template vectors, as additional template vectors are likely
to produce increasingly correlated feature bits. We further
choose 100 patches, P = 100, leading to a feature vector of
3,200 bits for each document.
3.3. Creating the document ﬁngerprint
From the feature vector we can create a document
ﬁngerprint that can be used to authenticate the document
without revealing information about the document. The
ﬁngerprinting method should be both concise and robust to
errors. This situation is similar to that of biometrics, where a
user provides a value (cid:101)V which is close to, but not identical
to the registered value V (e.g., the Hamming distance is
relatively small). Additionally, providing an adversary with
the full feature vector may not be desirable, as it provides a
blueprint for potential forgery.
A document ﬁngerprint consists of a hash of the feature
vector H(V), where H is a collision-resistant cryptographic
hash function, along with a secure sketch ss(V) following
the ideas of Dodis et al. [9] and Juels and Wattenberg [10].
The secure sketch allows the system to correct any errors that
may occur in the candidate (cid:101)V, assuming (cid:101)V is close enough
to V, without revealing V to an adversary who does not have
any information about V.
Suppose the registered value for a document is an N-bit
distance δ N of V. The secure sketch proposed by Juels and
Wattenberg chooses a random codeword x from an error-
correcting code of length N that can correct δ N errors, and
value V, and we wish to accept any (cid:101)V within Hamming
stores ss(V) = V⊕ x. To recover V from a candidate (cid:101)V, the
system calculates ˆx = ss(V)⊕(cid:101)V, corrects ˆx to the nearest
(cid:101)V have Hamming distance less than δ N, the system correctly
codeword, and veriﬁes that H(V) = H(x⊕ ss(V)). If V and
outputs V.
Dodis et al. [9] show that the number of bits of information
about the ﬁngerprint revealed by the secure sketch is N − k,
where k = logK is the dimension of the error-correcting code
used in the secure sketch when it has K codewords. Thus, in
order to maximize the security of the system for a ﬁxed N,
the error-correcting code should have as high a dimension k
as possible.
Low-Density Parity Check (LDPC) codes, along with turbo
codes, are among the strongest error-correcting codes in use,
thanks to efﬁcient decoding algorithms developed in the last
two decades. In our implementation, we used the LDPC
library written by Neal [11]. LDPC codes are well-suited
to this application because they work well on large block
sizes and in practice can often correctly decode beyond
the minimum distance of the code [12]. In addition, the
LDPC decoding algorithm can take into account a conﬁdence
level speciﬁed for each individual bit to further improve the
performance of the code. In our case, this conﬁdence level
can be calculated from the magnitude of the dot product of
Figure 5. Principal component analysis of a large num-
ber of 8×8-patches shows that 75% of the information
has been extracted after 32 components.
5
02040608010012000.10.20.30.40.50.60.70.80.91Cumulative Energy of Eigenvalues of Template Basis FunctionsNumber of Templete Vectors% Information Accounted ForFigure 6. Fraction of ﬁngerprints successfully decoded
for varying ﬁngerprint error rates using LDPC codes of
different dimensions k.
Figure 7. Correspondence between dot product magni-
tude and error probability during validation. (Fit to normal
distribution with µ=0 and σ=0.1314.)
the template vector with the patch vector. The correspondence
between the two is graphed in Figure 7.
The length of our feature vector is N = 3200 bits. We
experimented with codes of suitable dimension to correct bit
error rates between δ = 10%, allowing correct identiﬁcation
of all types of paper we experimented with under ideal
conditions (see Figure 8), and δ = 30%, suitable to identify
documents under less-ideal conditions such as soaking and
scribbling (see Figure 9). For the case of decoding under
ideal conditions, a code of dimension k = 1000 and N = 3200
is sufﬁcient to correctly verify all test documents, with no
false positives. For the case of decoding under less ideal
conditions, a code of dimension k = 300 and N = 3200
sufﬁced to correctly verify 95% of all test documents, with
no false positives. See Figure 6 for a summary of these
results.
The feature vector length can be adjusted to suit the needs
of the application (and the expected document treatment
conditions) by increasing or reducing the number of patches.
Longer feature vectors provide a higher level of accuracy
when distinguishing two documents, especially under harsh
treatment, but require increased storage. We chose N = 3200
bits as our feature vector length to ensure that it would ﬁt
in a 2-D barcode.
4. Robustness
the fragility of a document ﬁngerprint under various treatment
conditions. Our goal is to test whether our technique typically
validates different observations of the same document (true
positives) and rejects pairs of observations of different
documents (true negatives), while rarely validating pairs
of observations of different documents (false positives) or
rejecting different observations of the same document (false
negatives).
Our experiments show that a ﬁngerprint can be found for
a variety of different types of paper. Unless otherwise noted,
each experiment began with a document scanned at 1200
DPI on an Epson Perfection v700 scanner. Each test focused
on a 3×3 inch square in the center of the page.1
For each test, we captured ﬁve observations of a set of ﬁve
documents, for a total of 25 observations. Each observation
consisted of four scans taken at 0◦, 90◦, 180◦, and 270◦
that we used to estimate surface normals. We expect no two
scans of the same document to be exactly alike due to slight
variations in placement on the scanner, random noise, and
other uncontrollable variables in the process.
The amount of error tolerated in a matching ﬁngerprint can
be adjusted by choosing an appropriate error-correcting code
during the ﬁngerprinting process described in Section 3. The
number of bits that can be corrected by the code should be
determined by the needs of the application, as it establishes
Section 3 describes a process for registration and validation
of a document ﬁngerprint. In this section we evaluate docu-
ment ﬁngerprints across different types of paper, including
normal copy paper (Boise Aspen 50), university letterhead
with a visible watermark, and index cards. We also evaluate
1. In our robustness experiments, we used a printed box on the test pages
to identify the region to be ﬁngerprinted and to align the different scans.
However, alignment could be accomplished by other means, such as by
relying on the boundaries of the page or other printed material, or by simply
recording a few patches at high resolution [13]. Different sets of patches
should be used for alignment and veriﬁcation, because using the same
patches could increase the false positive rate.
6
1015202530350102030405060708090100% Error in Fingerprint% Successful Decoding of Fingerprint% Error in Fingerprint vs. % Successful Decoding1000800500400300200−5−4−3−2−10123450Dot Product Magnitude vs. Error Probability of Bit Dot Product MagnitudeBit Error Probabilitya tradeoff between the security of the system and the relative
likelihood (or harm) of a false positive or false negative.
4.1. Ideal handling conditions
As a baseline test, we measured the frequency of correct
and incorrect validation and rejection under ideal handling
conditions, when we expect no document degradation.
We began with 25 observations (5 from each of 5 docu-
ments). We chose 40 random seeds and sampled a ﬁngerprint
from each observation for each seed, following the process
described in Section 3. We made (cid:0)25
(cid:1) = 300 comparisons
for each seed, yielding a total of 12,000 comparisons.
2
For each comparison, we computed the Hamming distance
between the two ﬁngerprints. These distances are summarized
for the 12,000 comparisons by the histogram shown in the
top graph in Figure 8. Under non-adversarial conditions,
document ﬁngerprints of normal copy paper differ, on average,
in only 99 (3.1%) of the 3200 bits. In contrast, as one would
expect, the average Hamming distance for ﬁngerprints made
from observations of different documents is 50% of the
bits. These distributions are well-separated; the maximum
Hamming distance between feature vectors from the same
document is 177, while the minimum distance between
feature vectors of different documents is 1490. An error
tolerance anywhere in this range should give no false positives
and no false negatives for these tests. We found similar results
for index cards and university letterhead; see Figure 8.
The distributions for the “same” ﬁngerprint comparison
tests and “different” ﬁngerprint comparison tests seem to be
reasonably approximated by a normal distribution. Fitting
Gaussian curves to this data, we can ﬁnd a summary statistic,
Egan’s sensitivity index for Gaussian distributions of signal
and noise with unequal variances, given by:
ds = 2(µ2 − µ1)/(σ1 + σ2)
(4)
where µ1, µ2, σ1 and σ2 are the means and standard
deviations of the distributions [14]. For this experiment,
ds = 52.0. To give some intuition about the signiﬁcance
of this statistic, the two Gaussians intersect at a Hamming
distance of 731 bits; the heights of the curves are such that
the chance of a single comparison resulting in either a false
positive or false negative is 1 in 10148. If we reduce the
feature vector length from N = 3200 bits to 1600, 800, or
400 bits, the probability of such errors is 1 in 1096, 1 in 1057,
or 1 in 1035, respectively.
We repeated these experiments on different scanner models
and found similar results. When comparing a document
ﬁngerprinted on one model and veriﬁed on another, results
are slightly worse.2
2. We chose several of the parameters of our algorithm (e.g.,
the
downsample factor and size of the patches) based on preliminary experiments
using the Epson v700 scanner. The optimal settings for veriﬁcation of
documents using other scanner models may vary.
7
4.2. Non-ideal handling conditions
The previous experiments were performed under ideal han-