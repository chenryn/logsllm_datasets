### Humio Scalability Benchmark: 100TB Daily Ingestion & Real-Time Observability

On May 20, 2019, Humio announced the results of a scalability benchmark test that confirmed its ability to provide real-time visibility of data at ingestion rates of 100TB per day. This paper details the benchmark testing and its key findings.

#### Objectives of the Scalability Benchmark

The primary goal of this benchmark was to publicly demonstrate the capabilities that Humio already delivers to its customers. Specifically, the objectives were to:

1. **Ingest Log Data at Scale**: Show that Humio can ingest log data at a rate of at least 100TB/day with ease.
2. **Real-Time Search Performance**: Demonstrate that accelerated and highly accurate searches can be performed in real-time at scale.
3. **Linear Scalability**: Prove that the Humio architecture and approach scale linearly.
4. **Reference Architecture**: Provide benchmark results that can assist customers in defining a log management reference architecture for both cloud and on-premise deployments without constraints.

#### Test Bed Overview

Humio designed a test environment that is easy to deploy, flexible, and uses widely available and understood elements. The environment was created to replicate the conditions of current and potential Humio customers—enterprises with large volumes of log data. Importantly, the test bed was not custom-tuned to artificially produce optimized performance results. Humio's goal is to help enterprises maximize their use of log data while minimizing the cost and complexity of ingestion, query, and analysis.

For this round of benchmarking, Humio aimed to see if its approach could scale linearly to 25 nodes, starting with 10 Humio nodes. The test bed consisted of Humio pods and testing framework pods deployed on Kubernetes. Google Kubernetes Engine (GKE) was chosen due to the test developer's familiarity with this environment, but the infrastructure could also be run on AWS, Azure, or other cloud platforms.

The test bed included two main elements, code-named Nebulosa and Strix:

| Element | Configuration |
|---|---|
| **Nebulosa** | 40 n-standard instances: 25 for Humio, 13 for Kafka, and 5 for Zookeeper, each with 1TB of SSD. |
| **Strix** | 24 n-standard instances, similar to Nebulosa, ensuring only Humio activity was measured. |

Separating these elements ensured that only Humio activity was being measured and not mixed with testing processes. Both Nebulosa and Strix are GitHub projects. Terraform and Helm were used for infrastructure provisioning and configuration, selected for their widespread use in Kubernetes environments.

#### Test Methodology

A log generator produced a stream of data similar to a syslog environment. The ingest rate was measured using Humio’s Scala-based load-testing framework. The cumulative measurement of ingested data was made by observing devices where the data was stored. Notably, no indexing was used. Instead, the test bed employed Humio’s unique approach to ingesting, compressing (up to 10:1), searching, and analyzing log data. Humio parses the data as it is ingested, sends it through a Kafka queue, and makes it available for analysis in an average of 20ms.

#### Key Results

Over a six-day period in early May 2019, between 100TB and 110TB of log data was ingested daily. Ingest rates consistently reached over 100TB/day, peaking at 150TB/day. Depending on the size of the event, over 2.5 million events/second were recorded consistently.

To demonstrate real-time search capabilities, the term “Hello World” was embedded numerous times in the data stream but was not identified as a field. Even without indexing, the term was successfully found throughout an ingest process running at up to 119GB/s.

#### Key Takeaways

1. **High Ingest Rates and Query Performance**: Log data can be ingested at a rate of at least 100TB/day and queried with sub-second latency, even at hundreds of gigabytes per second.
2. **Linear Scalability**: The linear scalability of the Humio approach means even higher ingest/query rates can be achieved without costly IT infrastructure upgrades and/or customization.

#### Market Implications and Use Cases

One of the biggest obstacles to widespread enterprise adoption of observability tools is scalability. Humio is purpose-built to help customers achieve the benefits of large-scale logging and analysis. By demonstrating that its service can scale to 100TB/day and beyond, Humio has shown that it is now both feasible and cost-effective to "log everything and miss nothing."

Most enterprises do not log everything due to cost avoidance. Even in cases where logging is conducted on a large scale, the time to meaningful insight—especially for time-sensitive use cases—can be so long (minutes, even hours) that teams responsible for managing logs are often compromised in their ability to avoid or mitigate potentially damaging events or operational issues.

**Customer Testimonials:**

- **Rob McCurdy, CIO at MSU**: "Humio’s unlimited ingest pricing now enables us to scale our data without worry."
- **Alex Tasioulis, Platform Engineering Lead at On the dot**: "Humio not only manages all our log data but also allows us to do real-time, complex queries on our log stream that wasn’t possible before."
- **Rob McCurdy, CIO at MSU**: "The query language and speed of Humio compared to searching logs in Kibana is crazy! Much better experience in my opinion, and makes investigating and caring about logs so much easier."

#### Summary of the Benchmark

While most organizations currently utilizing log data rarely produce more than 10-20TB of data per day, all expectations are that the use of log data will increase exponentially in the years ahead. This benchmark confirms that Humio can support high-volume log management environments today—using readily available tools and modern infrastructure technologies without the need for custom tuning. As a result, log data can be ingested and queried in real-time at the rate of at least 100TB/day. This performance breakthrough opens vast possibilities for enterprises to expand their use of log data.

For more information, visit [https://info.humio.com/100tb-benchmark](https://info.humio.com/100tb-benchmark).

**Schedule a Demo:**
To learn more about how this benchmark can help your organization or to schedule a private demonstration, visit [humio.com/request-demo](https://humio.com/request-demo).

#### About Humio

Humio is a real-time observability solution for DevOps, ITOps, and Security Professionals, focused on changing the way users view all data across entire complex, distributed systems. The platform empowers teams to log all their data to gain instant visibility into their entire system and instantly identify and address concerns or vulnerabilities in a complex computing environment.