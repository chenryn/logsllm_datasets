study. For instance, we can observe that S[STATE_PX] is used to
define tmpSPX in Line 7, and tmpSPX is used to futhur define an-
other variable dS[STATE_PY] in Line 12. That means the value of
dS[STATE_PY] indrectly depends on S[STATE_PX], and tmpSPX is
an intermediate temporary variable. In Line 11, the variable acc->x
is used to define ds[STATE_PX] and there is no further updates for
them. Therefore, acc->x is considered as input and ds[STATE_PX]
is considered as output in this code segment. After summarizing
all the variable changes and their mutual dependencies for each
instruction, we obtain the Input set for the basic block, which is
used to calculate those variables in Output set. As shown in Figure
5, the final Input set will be the input nodes for neural network
models and Output set will be the output nodes.
(b) Sequence-to-sequence training dataset with sliding window
Figure 4: Mini-Me converts the collected time-series dataset
into windowed sequential dataset
For the collected dataset, we normalize all the training input and
output data into floating-point values by using scaling functions
based on their respective dimensions. For instance, if we observe
that the computation results of the integration sub-module in the
PID velocity controller usually range between -30 to 30, the veloc-
ity error (between current and target velocity states) could range
5
1  #define GRAVITY_MAGNITUDE (9.81f) 2 staticfloat R[3][3]; /* rotation matrix */ 3 staticfloat S[STATE_DIM];/* the quad's state, stored as a column vector */ 4 staticfloat dS[STATE_DIM]; 5while(quadIsFlying){6     /* keep previous time step's state for the update */ 7 tmpSPX=S[STATE_PX]; 8tmpSPY=S[STATE_PY];9   tmpSPZ=S[STATE_PZ]; 10/* body-velocity update: accelerometer -gyroscope cross velocity -gravity in body frame */ 11    dS[STATE_PX] =dt *(acc->x +gyro->z *tmpSPY-gyro->y *tmpSPZ-GRAVITY_MAGNITUDE *R[2][0]);12    dS[STATE_PY] =dt *(acc->y -gyro->z *tmpSPX+gyro->x *tmpSPZ-GRAVITY_MAGNITUDE *R[2][1]);13    dS[STATE_PZ] =dt *(acc->z +gyro->y *tmpSPX-gyro->x *tmpSPY-GRAVITY_MAGNITUDE *R[2][2]);14    } Original controller codeFuntionstatePredictBasicBlockwhile.body: Input:{ acc->x, acc->y, acc->z, gyro->x, gyro->y, gyro->z, S[STATE_PX], S[STATE_PY], S[STATE_PZ], dt, GRAVITY_MAGNITUDE, R[2][0], R[2][1], R[2][2] } Output:{ dS[STATE_PX], dS[STATE_PY], dS[STATE_PZ] } Input and output setFuntionstatePredictBasic Blockwhile.body: %7: use:{ S[STATE_PX] } define:{ tmpSPX} %8: use:{ S[STATE_PY] } define:{ tmpSPY} %9: use:{ S[STATE_PZ] } define:{ tmpSPZ}    use-after-define%11: use:{ dt, acc->x, gyro->z, tmpSPY, gyro->y, tmpSPZ, GRAVITY_MAGNITUDE, R[2][0]} define:{ dS[STATE_PX] } %12: use:{ dt, acc->y, gyro->z, tmpSPX, gyro->x, tmpSPZ, GRAVITY_MAGNITUDE, R[2][1]} define:{ dS[STATE_PY] } %13: use:{ dt, acc->z, gyro->y, tmpSPX, gyro->x, tmpSPY, GRAVITY_MAGNITUDE, R[2][2]} define:{ dS[STATE_PZ] } Dataflow analysisTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_targetTime Stampsroll_anglepitch_angleyaw_angle…Time Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_targetTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_targetTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_targetTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_targetTime Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Input vectorOutput vectorNetworkTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_target…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Time Stampsroll_anglepitch_angleyaw_angle…Windowed input sequence Output sequenceNetworkTime Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_target…Time Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_target…Time Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_target…Time Stampsacc.xacc.yacc.z...vel_error.xvel_error.yvel_xy_pvel_xy_ivel_xy_d…roll_targetpitch_targetyaw_target…432between -500 to 500. Therefore, this preprocessing step aims to
mitigate the aggressive disturbance caused by those some input fea-
tures with a large scalability sequence during the gradient descent
calculation of the back-propagation process. Given the condition
that the RAV’s logging data are in time-series, we define a sliding
window with fixed size to covert the training samples from vector-
to-vector into sequence-to-sequence as shown in Figure 4. In other
words, we use a sequence of inputs (e.g., target attitude) in a past
period of time to predict the next outputs (e.g., updated attitude),
which improves the accuracy and robustness of our learning model.
Neural Network Topology and Construction. To construct a
semantically similar approximation of the targeted code segment,
Mini-Me can use multiple kinds of neural network topology based
on applications. In particular, we use the long short-term memory
(LSTM) neural network [39], a variant of recurrent neural net-
work (RNN), to learn the numerical mapping between the input
and output sequences of the target controller segments in RAVs.
The size and concrete elements of these sequences depend on the
aforementioned dataflow analysis, which includes the vehicle dy-
namics (e.g., attitude, velocity of the RAV’s body frame), sensor
measurements and intermediate control state variables (e.g., PID
sub-module parameters). Therefore, we construct the transparent
inputs and outputs with explainable intermediate concepts [42, 52]
for the neural network model.
As shown in Figure 5, Mini-Me’s LSTM model is designed to
be lightweight, consisting of the LSTM layer(s) and dense layer(s).
The stacked LSTM layers aim to learn the temporal representation
of non-linear relations between input and output sequences. In
contrast to a typical classifier, our LSTM network does not comprise
a softmax layer. Instead, we add fully connected dense layers at the
end of the model to convey those linear relations between input and
output sequences. We define the activation functions accordingly
to achieve the empirically best performance on multivariate time-
series forecasting.
The advantages of LSTM topology in Mini-Me over the general
machine learning methodologies (e.g., SVM, decision tree, logistic
regression with a ridge or lasso estimator) lie on the characteristics
of training data samples. These traditional learning models are usu-
ally used for classification purposes with limited number of target
labels. However, our training datasets are the time-series sequential
samples for the forecasting purpose (e.g., predict updated vehicle
dynamics), which contain numerous control states and are difficult
to be labeled. In addition, LSTM is the most mentioned model used
in time-series data training and forecasting because (1) it uses a
sequence of samples (Figure 4b) as opposed to single input sample
(Figure 4a) at each time. (2) it overcomes the vanishing gradient
problem [20], which commonly exists on training processes (e.g.,
back-propagation) of gradient-based learning methods (e.g., CNN,
simple RNN [33]).
Offline Training. Mini-Me trains the LSTM model in an itera-
tive manner using classic feed-forward calculation then backpropa-
gation. We initialize the network with random weights and hidden
states with zeros. The training samples are shuffled and put into
the model by batch. Each dense layer are activated by relu function
and each LSTM layer are activated by sigmoid function. The whole
network is trained end-to-end and the weights are updated by mea-
suring the mean-square-error (MSE) between the predicted and the
Figure 5: Mini-Me approximate computing model example
based on LSTM neural network topology
target output sequence. We employ the Adam [50] optimizer and
the total training epoch is set between 200 to 500.
In fact, given the multi-dimensional inputs and outputs, it is not a
trivial challenge to determine the neural network topology and find
its best hyperparameters since the training may not converge or
even diverge (e.g., the training losses fail to move towards global or
local minimums with a decreasing trend). Therefore, loss function
MSE is not the only measure we use to evaluate the overall training
quality. We employ the hyperparameter optimization framework
to tune the hyperparameter settings (e.g., learning rate) and partial
network structure choices (e.g., number of LSTM layers) in exten-
sive trials, and our design optimization objective is to minimize the
cross-validation loss when testing the NN model on new mission
data sets, which guarantees the convergence and precision of our
model. For instance, we suggest a new floating-point value from
the log domain between 1e-1 to 1e-7 in every trial to search for the
best learning rate. After all the tuning trials finish, we freeze the
best available model and store it for further inference.
Neural Network Model Compression. In this step, Mini-Me
significantly increases the execution speed (especially for infer-
ence) of the LSTM-based approximate model by utilizing neural
network compression, which makes it easier to get deployed on
a resource-constrained RAV system (e.g., low memory usage). As
shown in Fig 6, Mini-Me performs the post-training quantization
to quantize the weights and activations of each layer in the model.
By converting the weights and inputs into integer types (e.g., 32-bit
floating-point to 8-bit integer), Mini-Me consumes less memory
bandwidth and achieves faster inference computation. Meanwhile,
the trader-off with quantization is that Mini-Me degrades the model
accuracy due to the reduced-precision arithmetic calculations in
the network. In Mini-Me, the decrease of accuracy results in the
enlargement of the error between the estimated state outputs (from
the approximate model) and the perceived outputs (from the run-
ning control logic). Mini-Me mitigates this by applying confidence
interval in runtime detection.
4.4 Runtime Monitoring
Binary Rewriting. To insert the Mini-Me detection function into
the main control loop of the ARM binary in a RAV, We employ the
trampoline binary rewriting technique [63] that is similar with [27].
The execution of the inserted monitoring function needs the func-
tion arguments and declarations. We reuse the identified input and
output state variables as the arguments to construct the monitoring
6
……Input sequenceOutput sequenceLSTM layer(s)Dense layer(s)acc->xacc->yacc->zR[2][2]ds[STATE_PX]ds[STATE_PY]ds[STATE_PZ]433Figure 6: Mini-Me neural network model compression us-
ing static quantization
function. To ensure the reformed program declares the external
function call and supports related neural network libraries, we pre-
compile the source code of neural network inference as well as the
supplementary functions, and then link all the object files to the
ARM binary during its compiling and executing as a runtime library
to get the final binary executable. we insert an external function
call of the monitoring function and set the insert point after the
target controller segment. Therefore, we successfully calculate the
estimated control state outputs from the neural network model
inference at runtime.
Attack Detection via Confidence Interval. To monitor the
controller integrity in realtime, we calculate the Euclidean distance
between the perceived outputs Y and estimated outputs ˆY as the
estimation error E in equation 1 for all the benign data samples
(e.g., independent testing data).
(cid:114)(cid:16)
(cid:17)2
(cid:118)(cid:117)(cid:116) n
∫ e
k =1
E =
Y − ˆY
=
(yk − ˆyk)2
(1)
1
√
2π
σ
exp− (t−µ)2
2σ 2 dt
F(e) = P(E ⩽ e) =
−∞
(2)
All the benign estimation errors for the neural network approx-
imate model form a closely normal distribution with a mean µ
and standard deviation σ as shown in Figure 7. The cumulative
distribution function F(e) in equation 2 describes the probability
that the estimation error E is less than or equal to a user-defined
error threshold e, which determines the confidence of its estimation.
If we define e as the safe interval between µ − 3σ to µ + 3σ, the
estimation error has the probability of 99.7% to fall in this interval
in all benign experiments as shown in Figure 7a. In contrast, the
probability that the estimation error falls out of this interval is less
than 0.03%, which very likely happens only when attacks occur.
Thus, it could be an indication that the monitored controller logic
is compromised as shown in Figure 7b. In very few corner cases
of benign samples, their estimation errors might also fall out of
the safe interval and are marked as attacks, that is, false positive
alarms.
In fact, the real-time estimation error of every new sample (i.e.,
control state updates) for online monitoring should obey the same
statistical distribution generated from benign experiments if the
integrity of monitored control logic holds. Therefore, the attacks are
detected if we observed the real-time estimation error significantly
violates the confidence interval of the benign error distribution.
It is important for Mini-Me to notify the system when a mali-
cious execution is detected. Upon receiving the alert, we assume
there are some secure operations that can be utilized to handle
(a) Benign Runs
(b) Attack Runs
Figure 7: Runtime estimation error probability in benign
and attack experiments
the responsive countermeasure if the control logic is compromised.
Mini-Me does not recover the correct sensor data or original control
logic. Instead, Mini-Me can boot the actuators into a failsafe mode
which is defined by the user (e.g., safely land at a pre-determined
location in a RAV use case) and prevent the RAV from a crash.
5 EVALUATION
In this section, we conduct and test Mini-Me in one real-world nano-
quadcopter Crazyflie 2.0 [12] and widely-adopted open-source
RAV virtual models, ArduPilot [11] and PX4 [9]. We evaluate the
Mini-Me’s real-time detection capability against five kinds of data-
oriented attacks in terms of its effectiveness and performance. Our
experiments answer the three main questions:
• Q1: How accurate is Mini-Me at learning linear and nonlin-
• Q2: How effective is Mini-Me at detecting the data-oriented
• Q3: What is the runtime performance overhead of Mini-Me?
ear controller functions?
attacks?
5.1 Implementation and Experimental Setup
We use llvm-mctoll [78] to lift the RAV’s controller executable (ARM
architecture) and use RetDec [4] as the decompiler to annotate the
binary instructions with addresses. We implement two individual
LLVM passes to identify the critical controller functions and per-
form the dataflow analysis to pinpoint the state variables in the
LLVM IR. The neural network models are implemented in Python
3.7.4 based on Keras 2.4.3 with tensor flow 2.2.0 as the back-end. We
implement the LSTM neural network models (e.g., stacked LSTM
layers and fully connected layer) on the basis of Keras sequential
model for both linear and nonlinear target controller functions. The
training data used in LSTM model training are generated from real
flight operations via autonomous scripts of mission generation and
running.
Figure 8: RAVs in evaluation: Crazyflie 2.0, ArduCopter-
based 3DR IRIS+, PX4-based 3DR Solo
7
……fp32fp32fp32……int8int8int8EstimationError!"2"3"−"−2"−3"Probability99.72%EstimationError!"2"3"−"−2"−3"Probability0.1%0.1%434For the experimental platform, we implement the prototype of
Mini-Me on five different RAV systems including one real vehi-
cle crazyflie 2.0 (quadcopter) and another four ArduCopter-based
and PX4-based virtual vehicles since they are widely adapted and
open-sourced, providing ground truth experiments for our study.
All these RAVs are equipped with sensors, communication protocol,
configuration and an ARM controller. Specifically, crazyflie 2.0 is
designed as a double-MCU architecture to enrich its functionality.
The main chip STM32F405 contains a 168MHz ARM Cortex-M4
processor, a 196KB static RAM and a 1MB flash ROM, which reads
data from the inertial measurement unit (IMU) sensor, a combina-
tion of a 3-axis gyroscope, 3-axis accelerator, 3-axis magnetometer
and a digital motion processor (DMP), to operate motors and per-
form flight control. For the virtual RAVs, we use the ArduCopter
flight controller with its default APM SITL [5] simulator and PX4
controller with Gazebo [1] simulator. The simulation runs on 64-bit
Ubuntu virtual machine of VMware and 4 processor cores @2.6GHz
with 8 GB RAM.
5.2 Effectiveness of Attack Detection
Model Convergence and Error Distribution. After offline model
construction, these data flow results constitute the training inputs
and outputs for our neural network, which includes the rotation
matrix, quadcopter state matrix, the position vector in both the
global frame and its body frame, the attitude quaternion vector and
attitude errors for prediction. We launch 30 different missions for
each RAV and collect running data by mission, and each of them