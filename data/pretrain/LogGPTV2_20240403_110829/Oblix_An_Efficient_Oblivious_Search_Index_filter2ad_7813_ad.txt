In the rest of this section, we denote the number of buckets at
the server by N, the capacity of each bucket (in blocks) by C,
and the block size (in bits) by B. We use a linear-time function
OblSwap(b, x, y) that obviously swaps x and y if b = 1. Our
algorithms also invoke Batcher’s oblivious odd-even merge
sort, which has time complexity O(n log2 n) to sort n items.
Naive approach. A straightforward approach to achieve
double-obliviousness is to replace suitable sub-routines (e.g., a
binary search) with linear scans. Namely, ReadBlock fetches
the required path, inserts all blocks on that path into its stash,
and returns the requested block by linearly scanning the stash;
Evict constructs buckets for the path of a leaf lf as follows.
Initialize mut inserted = 0. Then for each block bl in the stash Stash:
For each bucket bu on the path of lf (ordered from leaf upwards):
1) Let is_ancestor = 1 if bu is on the path to bl’s leaf.
2) For each i ∈ {1, . . . , C}:
a) Let cond = bu[i].is_dummy ∧ is_ancestor ∧ ¬ inserted.
b) OblSwap(cond, bl, bu[i]).
c) Set inserted := cond ∨ inserted.
Namely, for each block bl in Stash, Evict scans the list of
buckets to be written back, checks if bl can go in one of these,
and obliviously writes it to that bucket if so. When evicting
n paths after n ReadBlock calls, the stash contains roughly
S = nC log(N ) blocks, and so this naive Evict procedure has
time complexity O(B · S · nC log N ) = O(n2BC 2 log2 N ).
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:06 UTC from IEEE Xplore.  Restrictions apply. 
Scheme
Algorithm
Client type
Standard
Doubly-oblivious
Path
ORAM
ODS
OSM
=
=
=
Ti1
Init
ReadBlock Tr
Te
Evict
Ti2
Ts
Ta
=
Tf (n) =
Init
Start
Finalize
Access
=
=
(cid:2)
(cid:8)∈ cache
∈ cache
Init
Find(m)
Size
Insert
O(CN log CN )
O(C log N log S)
O(BS log N log(ibu)) O(ebl2
O(CN log
O(C log N + ebl)
log N + BS log
2 BS)
2
(CN ) log N )
O(log(ca)) + Tr
O(log(ca))
O(ca) + Tr
O(ca)
O(CN log(CN )) + Ti1
O(1)
O(ca) + Te (with ebl = n)
O(CN log(CN )) + Ti2
(2h + m) · Ta + Tf (2h + m)
h · Ta + Tf (h)
(h + 1) · Ta + Tf (h + 1)
B block size (in bits)
N server size (in buckets)
C bucket size (in blocks)
ebl size of ExplicitBlocks (in blocks)
ibu size of ImplicitBuckets (in buckets)
S = ebl + C · ibu, stash size (in blocks)
ca size of ODS cache (≤ ebl)
h = 1.44 log(CN ), worst-case height of
AVL tree with CN nodes
time
bucketed correctly: they are already in buckets on the path to
their leaves. Hence, we can skip re-bucketing these blocks, and
can focus on re-bucketing only the blocks in ExplicitBlocks.
Concretely, Evictf, like Evicts, proceeds in two phases:
• Block assignment. We use ImplicitBuckets to compute a
pre-populated bucket fullness map BuFu. Then, for every
block in ExplicitBlocks, we update BuFu as in Evicts and
assign each block to a bucket. This step has time complexity
O(|ExplicitBlocks| · n log N ).
• Bucket construction. We proceed as in Evicts.1
Evictf
The
thus
O(nC log N (n/C + B log2(nBC log N ))), which saves
a factor of log N
C
compared to Evicts.
overall
complexity
Table I: Comparison of standard and doubly-oblivious client algorithms for Path ORAM, ODS, and OSM. Whenever a client algorithm invokes a subroutine,
the running time of the subroutine is for the corresponding client type. For example, DODS invokes Path DORAM algorithms.
Saving a multiplicative factor of C. We improve upon
naive eviction by splitting eviction into two steps, saving a
multiplicative factor of C. In the ﬁrst step, we assign blocks
to buckets; in the second step, we write blocks to buckets.
• Block assignment. We initialize a linear-scan “bucket fullness”
map BuFu from bucket nodes (i.e., identiﬁers of the bucket’s
location in the ORAM tree, not the full bucket) to the number
of blocks in those buckets (i.e., the fullness of the bucket) so
that entries in BuFu are sorted by their nodes from leaf to root.
Then, for each block bl in Stash, we scan the list of buckets
to be written back (in order from leaf to root), and update
BuFu as follows. If bl should be written to a bucket bu, then
we increment BuFu[bu.node], and set bl.node := bu.node.
Otherwise, we perform dummy operations. This step has
time complexity O(S · n log N ) ≈ O(n2C log2 N ).
• Bucket construction. We obliviously sort Stash to group
together blocks with the same node, and construct buckets
out of these. To hide how many blocks are assigned to
buckets, we pad Stash with dummy blocks. Any unassigned
blocks are re-added to Stash. This step has time complexity
O(B · S log2(S)) ≈ O((nBC log N ) log2(nBC log N )).
The overall complexity of this eviction procedure, which we call
Evicts, is O(n2C log2 N + nBC log N log2(nBC log N )) ≈
O(nC log N (n log N + B log2(nBC log N ))).
Processing only requested blocks. We further improve on the
above via the following insight. Even though a user invokes
ReadBlock to request only one block, O(log N ) additional
blocks are implicitly fetched and added to the stash, which
means that Evict has to process these additional blocks when
constructing buckets. Our new eviction procedure Evictf gains
in time complexity by separately processing explicitly requested
blocks (henceforth explicit blocks) and implicitly fetched blocks
(henceforth implicit blocks), as follows.
However, this efﬁciency gain comes at the expense of a lower
eviction rate; Evictf evicts fewer blocks than Evicts. This is
because Evictf only re-assigns explicit blocks, and does not
shufﬂe implicit blocks. Furthermore, each such explicit block
can only be assigned to a slot vacated by a previously fetched
explicit block. Together, these constraints reduce the rate of
stash eviction. As a countermeasure, our ﬁnal construction of
DORAM.Evict invokes Evictf in the common case (for speed),
but invokes Evicts at ﬁxed intervals (to empty out the stash).
Empirical evidence from our experiments, suggests that this
interval can be a ﬁxed constant as small as 3.
Initialization. There is a naive doubly-oblivious initialization
strategy: given the initial list of n blocks [bli]n
1 , individually
insert every block into the stash, and then use DORAM.Evict to
evict each block from the stash. However this method requires
time O(nCN ). When the server is at capacity (CN ≈ n), this
grows quadratically with n, and is too large for the database
sizes that we consider. We address this problem by designing
a new doubly-oblivious initialization strategy that has time
complexity O(CN log3 N ), which enables us to efﬁciently
handle databases with tens of millions of records.
of
is
In more detail, we modify ReadBlock to scan the list of
fetched buckets, (obliviously) remove the block of interest
(say bl), and replace bl with a dummy block. It then adds
bl to a list ExplicitBlocks of previously requested explicit
blocks, and adds the updated list of fetched buckets to a list
of previously requested buckets ImplicitBuckets. For eviction,
note that blocks in (buckets in) ImplicitBuckets are already
Our algorithm proceeds layer by layer in the tree. Within each
layer, it proceeds similarly to Evict: it ﬁrst assigns blocks to
buckets, and then obliviously sorts these blocks to group them
1In our implementation, instead of sorting, we write blocks to buckets via
linear scans (as in the naive approach). While this is asymptotically worse,
for our use cases this method is concretely faster.
286
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:06 UTC from IEEE Xplore.  Restrictions apply. 
(m, [bli]n
• Read a block: DORAM.ReadBlockS
into buckets. In more detail, for a given tree layer, DORAM.Init
ﬁrst obliviously sorts [bli]n
1 by the blocks’ tree nodes (initially,
just each block’s assigned leaf). Next, it scans the list to
compute the fullness of each bucket, and assigns each block to
a bucket according to this fullness. Finally, it constructs buckets
by obliviously sorting [bli]n
1 so that blocks with the same tree
nodes are together (as before, we pad with enough dummy
blocks before to hide the number of bucketed blocks). To
proceed to the next layer, it sets the nodes of unassigned blocks
to be the parent of their current nodes. Since there are log(N )
layers, and each layer requires two oblivious sorts and a linear
scan, this algorithm has time complexity O(CN log3(N )).
Final construction. We now summarize our ﬁnal construction
of Path DORAM; for detailed pseudocode see Appendix D.
1 ) → st. Proceed layer-
• Initialization: ORAM.InitS
by-layer in the ORAM tree. In each layer, ﬁrst assign blocks
to buckets, and then obliviously sort these blocks to group
them into buckets.
(mut st, bid, lf) → bl.
Fetch buckets on the path to lf. Scan this list to obliviously
replace the block bl having identiﬁer bid with a dummy
block. Insert the modiﬁed buckets into ImplicitBuckets, and
insert bl into ExplicitBlocks. Finally, output bl.
• Eviction: DORAM.EvictS
1 ). Given a integer t
ﬁxed at setup, store in st a counter c ∈ Zt. If c = 0 mod t,
invoke Evicts; else, invoke Evictf. Increment c.
Note that we have not speciﬁed how to obliviously access the
client’s position map because this can be achieved by standard
recursion techniques [64] or by using the ODS framework [74].
Stashless ORAM. The primary obstacle we faced in designing
Path DORAM was creating a doubly-oblivious stash eviction
procedure. To avoid this trouble, one might instead think to use
a stateless ORAM scheme [28]. However, this idea does not
help because all such schemes still require working space to
store blocks between reads and eviction; the adjective “stateless”
only describes permanent client storage. Obliviously accessing
this working space is expensive when it is large, but Path
ORAM only requires polylog(N ) working space, compared
to space nc for 0 < c < 1 for other schemes.
(mut st, [lfi]n
B. Doubly-oblivious data structures
We describe a framework for doubly-oblivious data struc-
tures (DODS). We modify the existing framework for singly-
oblivious data structures (ODS, see Section III-B) to: (i) use
Path DORAM (see prior sub-section), instead of merely Path
ORAM, as a building block; and (ii) leverage other ideas for
efﬁciency. Details follow.
The ODS client. We brieﬂy recall the construction of the
singly-oblivious data structure framework of [74]. The client
realizes a data structure operation by running ODS.Start once,
ODS.Access some number of times, and ODS.Finalize once;
throughout, the client maintains a cache with fetched nodes.
Whenever the client is queried on a node (via ODS.Access),
it looks for the node in the cache and returns it if there;
287
otherwise, the client performs an ORAM.ReadBlock oper-
ation to fetch the node from the server, adds it
to the
cache, and returns it. Since the number of ORAM.ReadBlock
operations may be data dependent, ODS.Finalize pads this
number to a data-independent (worst-case) number with dummy
ORAM.ReadBlock operations, thereby ensuring that accesses
to the (external) memory at the server are oblivious.
Naive approach. A naive approach to make the ODS client
doubly-oblivious is to simply replace the underlying ORAM
scheme with a DORAM scheme and replace the cache with
an oblivious one. However, this does not sufﬁce: whether the
returned node is fetched from the cache or the server depends
on the queried node, and an adversary observing accesses to
internal memory can distinguish between the two cases, even if
accesses to external memory are oblivious and their number is
data independent. A straightforward ﬁx is to always perform
a (possibly dummy) DORAM.ReadBlock operation whenever
DODS.Access is invoked, regardless of whether the queried
node is cached or not. However, while doubly-oblivious, this
approach harms efﬁciency since the ODS client now may
perform unnecessary DORAM.ReadBlock operations.
Our approach. We avoid unnecessary dummy ReadBlock
operations via the observation that,
the
in certain cases,
adversary can predict if a node is fetched from the cache.
For example, in an AVL tree insertion, the rebalancing phase
only visits nodes that have been previously visited, and so are
in the cache. In our doubly-oblivious sorted multimap (see
Section V-C), we design insertion so that rebalancing begins
only after a ﬁxed number of nodes have been accessed in the
previous phase, so the adversary can predict when rebalancing
begins, and thus also that the nodes accessed then are cached.
In such cases, we can forgo the dummy DORAM.ReadBlock
operation and gain efﬁciency. When we are not in such a case
(the information of whether a node is in the cache is not public),
we fall back to the aforementioned simple approach (of always
performing a dummy DORAM.ReadBlock).