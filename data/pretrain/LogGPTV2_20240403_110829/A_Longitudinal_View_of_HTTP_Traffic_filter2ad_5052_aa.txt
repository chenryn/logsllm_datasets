title:A Longitudinal View of HTTP Traffic
author:Tom Callahan and
Mark Allman and
Vern Paxson
A Longitudinal View of HTTP Trafﬁc(cid:2)
Tom Callahan1, Mark Allman2, and Vern Paxson2,3
1 Case Western Reserve University
2 International Computer Science Institute
3 University of California, Berkeley
Abstract. In this paper we analyze three and a half years of HTTP trafﬁc ob-
served at a small research institute to characterize the evolution of various facets
of web operation. While our dataset is modest in terms of user population, it is
unique in its temporal breadth. We leverage the longitudinal data to study var-
ious characteristics of the trafﬁc, from client and server behavior to object and
connection characteristics. In addition, we assess how the delivery of content is
structured across our datasets, including the use of browser caches, the efﬁcacy
of network-based proxy caches, and the use of content delivery networks. While
each of the aspects we study has been investigated to some extent in prior work,
our contribution is a unique long-term characterization.
1 Introduction
In this paper we study logs of web trafﬁc collected at the border of a small research
institute over a three and a half year period (2006–mid-2009). There are an average of
160 active users per month in our dataset. While this is a relatively small population,
we gain insight into the evolution of web trafﬁc by taking a longitudinal view of the
trafﬁc. This investigation serves to re-appraise and update previous results. We believe
our contribution has utility in informing the community’s mental models about myriad
aspects of how the modern web works—including things like transaction types and
sizes, as well as how web content delivery is accomplished through content delivery
networks, browser caches and the like. In addition, a multi-faceted view of web content
delivery is useful in setting up realistic testbeds and simulations to accurately reﬂect the
make-up and structure of today’s web.
Our methodology employs web trafﬁc logs from our intrusion detection system col-
lected over three and a half years to study various aspects of the web. We describe
our data collection and analysis methodology in § 2. We then characterize a number of
facets of the trafﬁc at the transaction-level in § 3. We next consider various aspects of
user-driven behavior, such as object popularity and the impact of caching in § 4. Finally,
we consider the structure of the web page delivery process, including the use of CDNs
in § 5. We brieﬂy touch on related work in § 6 and summarize in § 7.
2 Data and Methodology
For this work we use logs of web trafﬁc taken at the border connecting the Inter-
national Computer Science Institute (ICSI) with its ISP. We use the Bro intrusion
(cid:2) This work is supported in part by NSF grants CNS-0831535 and CNS-0831780.
A. Krishnamurthy and B. Plattner (Eds.): PAM 2010, LNCS 6032, pp. 222–231, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
A Longitudinal View of HTTP Trafﬁc
223
10M
1M
100K
10K
1K
100
2006
10M
1M
100K
10K
s
n
o
i
t
c
a
s
n
a
r
T
HTTPS connections
Requests
Connections
Unique Server Hostnames
Unique Server IPs
2007
2008
Year
2009
1K
2006
2007
2008
Year
GET
POST
Other
2009
Fig. 1. Dataset Summary
Fig. 2. HTTP Transaction Types
detection system [12] to reconstruct HTTP [7] sessions from the observed packet
stream. These sessions are then logged using Bro’s standard HTTP logging policy
(found in http.bro in the Bro package). The logs include timestamps, involved IP
addresses, URLs, HTTP transaction types and sizes, hostnames and HTTP response
codes. The dataset used in this paper runs from January 2006 through July 2009. Due
to the size of the dataset we analyze only the ﬁrst seven days of each month for lo-
gistical reasons. We do not believe this biases our results. The original logs include
all incoming and outgoing HTTP trafﬁc. However, we winnowed to only the outgoing
connections (i.e., ICSI clients) as we do not wish to bias our results by the particular
characteristics of the few server instances at ICSI. Of the 28.8 million total connections
from the ﬁrst seven days of each month in our dataset we retain 16.9 million as initiated
by ICSI clients. In ﬁgure 1 we show the high-order characteristics of the dataset. The
overall number of web object requests, HTTP connections, HTTPS connections, server
hostnames and server IP addresses show general stability over time.1 Since the HTTPS
connections are encrypted we cannot further analyze them in this work. We identify
“web servers” in two different ways: by IP address and by hostname. Due to the use of
content delivery networks (CDNs) a particular IP address may host content for multi-
ple distinct hostnames. In fact, in the ﬁgure we see this effect as there are more server
hostnames than server IP addresses (this is studied in more detail in § 5). However, note
that the opposite is also true: that a given hostname could have multiple IP addresses
(e.g., to serve content from a close source or for load balancing). Finally, we note that
the number of users is modest—an average of 160 per month with a standard deviation
of 13—our contribution is the longitudinal tracking of this user population.
Finally, we note that there are two versions of Bro HTTP policy scripts used in
gathering the data we employ in this study with one crucial difference. For the ﬁrst ten
months of 2006 the scripts gathered logical web sessions together as one logical entity
under one identiﬁer regardless of the number of underlying TCP connections used to
obtain the components of the web pages. In these log ﬁles this process obscures the
number of TCP connections used to transfer the data. Due to the onerous amount of
state required to stitch together a web session from disparate TCP connections, starting
1 The number of connections has a dramatic increase in December 2007. We delve into this in
detail in § 5.
224
T. Callahan, M. Allman, and V. Paxson
in mid-October 2006 the scripts were changed to simply gather together all activity on
a per-TCP connection basis. For most of our analysis the difference in logging is not
important, but for analysis that requires an understanding of the number of underlying
TCP connections we start our analysis in November 2006 instead of January 2006. In
ﬁgure 1 the reported number of connections for the ﬁrst 10 months of the dataset is
actually the number of web sessions (which is reported to give the reader context even
though the precise number of connections is unknown).
3 HTTP Transaction Characterization
We ﬁrst focus on characterizing client HTTP transactions. First, ﬁgure 2 shows the
transaction type breakdown over time. Over the course of our dataset the majority of
observed transactions—approaching 90% in most months—are requests for data (GET
transactions). Most of the remainder of the transactions—around 10%—involve the user
uploading data to the web server (POST transactions). A small number of additional
transaction types are also observed (HEAD, PROPFIND, etc.). Together these additional
types account for less than 1% of the transactions in most months. We note that in
absolute terms the number of GETs and POSTs have a slight increasing trend over our
observation period (note, the ﬁgure is plotted on a log scale and therefore the increase is
less readily apparent). Further, the number of POSTs observed increases quickly at the
beginning of our dataset. This is caused by a dramatic uptick in the use of GMail during
early 2006. Non-GMail POST requests are more steady and only slowly increasing
during this period.
Figures 3 and 4 show the average and median size of GET and POST transactions
over time. Both transaction types show a generally increasing average transaction size
over time which is likely explained by users both increasingly downloading richer con-
tent and participating in so-called web 2.0 sites that host user-provided content. The
median results for POST transactions are interesting as they remain small and fairly
constant over the study period. This indicates that simple form input that only results in
the transmission of a small amount of data is prevalent throughout. For the GET requests
we ﬁnd the medians are generally an order of magnitude less than the averages. This is
expected due to many previous studies that show most responses are short and a few re-
sponses carry most of the bytes—i.e., web trafﬁc is heavy-tailed [5]. Figure 5 shows the
distribution of GET response sizes for July 2 2007 as a typical example of the per-day
distribution (this date was chosen arbitrarily as a weekday roughly in the middle of the
study period). Finally, we note that the average GET response size in December 2006 is
four times the size of the surrounding months. This anomaly is caused by a single client
fetching a large series of big ﬁles. We removed this client from our analysis and plot
a point on the graph to show the average size of GET responses without this particular
client. Without the energetic client the average is similar to the surrounding months.
Figure 6 shows the median duration of HTTP connections, as well as the median
time between establishing a connection and the client issuing an HTTP request. We
note that the median connection duration is reduced between November and December
2007 which is explained by a reduction in the use of persistent HTTP connections
e
z
i
S
n
o
i
t
c
a
s
n
a
r
T
n
a
e
M
F
D
C
C
A Longitudinal View of HTTP Trafﬁc
225
100K
90K
80K
70K
60K
50K
40K
30K
20K
10K
0
2006
GET Response sizes
POST Request sizes
s
e
z
i
S
n
o
i
t
c
a
s
n
a
r
T
n
a
i
d
e
M
2007
2008
Year
2009
 1600
 1400
 1200
 1000
 800
 600
 400
 200
 0
2006
GET Response sizes
POST Request sizes
2007
2008
2009
Year
Fig. 3. Average transaction sizes
Fig. 4. Median transaction sizes
 1
 0.1
 0.01
 0.001
 0.0001
 1e-05
Median Connection Duration
Median Time to First Request
 10
 1
 0.1
s
d
n
o
c
e
S
10
1KB
100KB
10MB
1GB
Object Size (Bytes)
 0.01
2007
2008
Year
2009
Fig. 5. CCDF of GET sizes for July 2 2007
Fig. 6. Connection duration and request time
(see § 5). As connections are used for fewer objects their duration drops. Before De-
cember 2007 the median connection duration was around 1 second and after this point
the median duration falls to 100–200 msec. The short duration of connections suggests
that seemingly small changes to the delivery process that save modest amounts of wall-
clock time may ultimately beneﬁt the user experience more than one might think at ﬁrst
blush—e.g., Early Retransmit [2] and reducing TCP’s traditional exponential backoff
between retransmissions [10].
Figure 6 also illustrates the time between establishing a connection and sending an
HTTP request. In related work [1] we study claim-and-hold attacks on web servers
whereby a malicious client opens a connection and does not send an HTTP request to
force the server to allocate resources that can then not be used for legitimate trafﬁc.
In ﬁgure 6 we show that the median time before an HTTP request is issued is roughly
constant—at just under 100 msec—in our dataset, which agrees with the results in [1].
However, we also note that we ﬁnd successful transactions whereby the time between
connection establishment and transmission of the HTTP request is quite a bit longer. In
particular, we ﬁnd this with GMail. The 99th percentile interval is roughly 246 seconds
for GMail in each year, while the interval ranges from 14 seconds in 2006 to 55 seconds
in 2009 for non-GMail trafﬁc. This indicates that expecting short intervals may not be
the right model for newer web application-driven web pages.
226
T. Callahan, M. Allman, and V. Paxson
F
D
C
C
 1
 0.1
 0.01
 0.001
 0.0001
 1e-05
2006
2007
2008
2009
1
10
100
10K 100K
1K
Requests
1M
F
D
C
C
 1
 0.1
 0.01
 0.001
 0.0001
 1e-05
 1e-06
1
2006
2007
2008
2009
10
100
1K
10K
Requests
Fig. 7. Requests per hostname
Fig. 8. Requests per object
4 User Behavior