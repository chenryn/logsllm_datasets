ance, and a transaction count (which prevents replaying past
transactions). The constraints that verify a transaction in C
thus require two Merkle tree updates, one each for payer and
payee. (Each update comprises two Merkle paths; §2.1).
We observe that a single MultiSwap (§3) can replace all of
the Merkle tree updates for a batch of transactions. In particu-
lar, MultiSwap’s semantics guarantee sequential consistency
of the transactions with respect to Γ and Γ(cid:48). And whereas
the per-swap cost of Merkle swaps increase logarithmically
with the number of accounts stored in Γ, the per-swap cost
of MultiSwap is essentially independent of the number of
users. This means that for large batches of transactions and/or
large numbers of users, a MultiSwap-based Rollup requires
far fewer constraints than a Merkle-based one.
Costs. The middle two rows of Figure 3 show costs for
Rollup using Merkle and MultiSwap. Both cases pay to ver-
10Anecdotally, recent Ethereum prices [54] result in storage costs of more
than $1 per kilobyte. Similarly, per-transaction costs are frequently in the
$0.25 to $1 range even when executing minimal computation.
11Rollup is distinct from Optimistic Rollup [58], which does not use cryp-
tographic proofs and is not discussed in this paper.
USENIX Association
29th USENIX Security Symposium    2083
Number of constraints
System
Merkle swap
MultiSwap (§3, §4)
Payments (Merkle swap)
Payments (MultiSwap)
RAM (Merkle-based [32])
RAM (MultiSwap)
Per-Operation Costs
2(cHe + m· cH )
2(cHe + cHin + csplit + c+(cid:96)( f ) + c×(cid:96))
Merkle swap ×2 + csig + ctx
MultiSwap×2 + csig + ctx
(1 + w)(cHe + m· cH )
MultiSwap +cmem-check
Per-Proof Costs
4ceG(|(cid:96)|) + 2c×G + cHp + cmod(cid:96)(bH∆ )
MultiSwap
MultiSwap
ﬁeld width (log2|F|) (255)
group element bits (log2|G|) (2048)
cost of F2 → F hash (varies)
prime challenge bits (352)
operation cost in G (7563)
write fraction (RAM) (varies)
cost of multiplication, mod (cid:96) (479)
per-operation cost of full-input hash (varies)
(< 125)
λ
bH∆
cHe
cHp
csplit
csig
ctx
m
cmem-check
c+(cid:96) (b)
cmod(cid:96) (b)
ceG (b)
security parameter (128)
bits in division-intractable hash output (2048)
cost of multiset item hash to F (varies)
cost of prime generation (217703)
cost of strict bitsplit in F (388)
cost of signature check (12000)
cost of tx validity check (255)
log2 of accumulator capacity (varies)
cost of memory checks, 21 + log2 k + 2· m for k operations [116, Fig. 5; 79, Appx. B.A]
cost of addition with two inputs of maximum width b, mod (cid:96) (16 + b)
cost of reduction mod (cid:96), with a b-bit input (16 + b)
cost of exponentiation with a b-bit exponent, in G (7044b)
f
bG
cH
|(cid:96)|
c×G
w
c×(cid:96)
cHin
Figure 3: Constraint count models for Merkle swaps (§2.1), MultiSwap (§3, §4), Payments (§5.1), and Persistent RAM (§5.2).
The approximate value of each parameter in our implementation (§6, §7) is given in parentheses. See Section 5 for discussion.
ify the payer’s signature and ensure that the payer’s balance is
sufﬁcient. The difference is in the swap costs, which are dis-
cussed above (§5); Rollup requires two swaps per transaction,
one each to update the payer’s and payee’s accounts.
5.2 Efﬁcient persistent RAM
Recall from Section 2.2 that Pantry-style RAM, while expen-
sive, offers unique functionality: the ability to pass the full
state of RAM from one proof to another. This enables compu-
tations over persistent state [32], recursively veriﬁable state
machine execution [15, 89], and other useful applications.
Unfortunately, the high cost (in constraints) of hash func-
tions (§6) limits the number of Pantry-style RAM opera-
tions that can be used in a computation—especially for large
RAMs [32, 79, 116]. In this section, we show how to use the
batched RSA accumulator construction of Section 4 to address
this issue. Our design yields a persistent RAM abstraction
whose per-access constraint cost is lower than Pantry’s even
at modest RAM sizes, and is nearly insensitive to RAM size.
To begin, notice that Pantry’s RAM abstraction essentially
stores memory values in a ﬁxed-size Merkle tree, executing
a membership proof for each LOAD and a swap for each
STORE. Moreover, since our goal is efﬁciency, our design will
ideally check all memory operations using a small number of
batched accumulator operations (§4).
This seems to suggest the following (incorrect) approach.
First, replace the Merkle tree with an RSA accumulator,
representing memory locations as (cid:104)addr,data(cid:105) tuples. Then,
verify all LOAD and STORE operations in a batch using
MultiSwap (§3) as follows. For each LOAD from address
δ, P supplies as advice the value ν purportedly stored at δ,
and the constraints encode a swap that replaces the tuple (cid:104)δ,ν(cid:105)
with itself. For each STORE of the value ν(cid:48) to address δ, P
supplies as advice the value ν purportedly being overwritten,
and the constraints encode the swap ((cid:104)δ,ν(cid:105),(cid:104)δ,ν(cid:48)(cid:105)).
The reason this approach is incorrect is that it does not en-
force the consistency of LOAD operations with program exe-
cution. In particular, recall (§3) that MultiSwap(S,σ,S(cid:48)) only
guarantees that S(cid:48) is produced by a sequentially-consistent
cycle-free subsequence σ(cid:48) ⊆ σ. Since LOAD operations
are self-cycles, they are not included in σ(cid:48). This use of
MultiSwap thus only guarantees that σ correctly encodes
STORE operations—LOADs can return any value.
We might attempt to ﬁx this issue by checking LOAD oper-
ations using membership proofs. But this is inefﬁcient: check-
ing such a proof requires the constraints to materialize an
accumulator that contains the value being loaded; meanwhile,
the LOAD might correspond to a prior STORE, in which case
the accumulator against which the proof must be checked
would ﬁrst have to be computed. In other words, this strategy
makes batching accumulator operations impossible.
Our key insight is that a hybrid of the Pantry and BCGT ap-
proaches solves this issue. At a high level, our design enforces
2084    29th USENIX Security Symposium
USENIX Association
the correctness of LOAD and STORE operations using an
address-ordered transcript (§2.2) while ensuring that this tran-
script is consistent with the initial and ﬁnal state of RAM us-
ing batched accumulator operations. As above, each memory
location is stored in the accumulator as an (cid:104)addr,data(cid:105) tuple.
As in BCGT-style RAM, the constraints build an execution-
ordered transcript, P supplies an address-ordered transcript
T , and the constraints ensure that T is correctly ordered, co-
herent, and a permutation of the execution-ordered transcript.
For the initial state of RAM, the constraints enforce consis-
tency by ensuring that the ﬁrst time an address δ is accessed
in T , the tuple (cid:104)δ,ν(cid:105) is removed from the accumulator. If the
ﬁrst access is a LOAD, ν is the corresponding DATA value
from T . Otherwise, P supplies as advice a claimed ν value
such that (cid:104)δ,ν(cid:105) is in the accumulator. (For now, we assume
that memory location δ has some corresponding tuple in the
accumulator; we discuss uninitialized memory below.) Ob-
serve that this ensures consistency, because a removal is only
possible if (cid:104)δ,ν(cid:105) is indeed in the accumulator.
For the ﬁnal state of RAM, the constraints enforce consis-
tency by ensuring that the last time an address δ is accessed
in T , the tuple (cid:104)δ,ν(cid:48)(cid:105) is inserted into the accumulator. The
value ν(cid:48) is the corresponding DATA value from T . Together
with the above, this ensures that all of the accesses to address
δ collectively result in the swap ((cid:104)δ,ν(cid:105),(cid:104)δ,ν(cid:48)(cid:105)).
Constraints for the above checks work as follows. First, for
entry i in T , the constraints compute hi,del = H∆((cid:104)ADDRi,ν(cid:105))
and hi,ins = H∆((cid:104)ADDRi,ν(cid:48)(cid:105)) (§4.2). Then, for each sequen-
tial pair of entries i, i + 1 in T , if ADDRi (cid:54)= ADDRi+1, then
entry i must be the last access to ADDRi and entry i + 1 must
be the ﬁrst access to ADDRi+1. Finally, the constraints com-
pute ∏i∈F hi,del mod (cid:96) and ∏i∈L hi,ins mod (cid:96) (§4), the values
inserted into and removed from the accumulator, respectively,
for F the ﬁrst-accessor set and L the last-accessor set.
Handling uninitialized memory. A remaining issue is
how to handle the case where memory is uninitialized. Re-
call that in the BCGT approach, a LOAD not preceded by a
STORE to the same address is serviced with a default value,
say, 0. That does not work here, because this approach re-
lies crucially on swapping old values for new ones, to ensure
consistency with both the initial and ﬁnal accumulators.
A straightforward solution is to ensure that every mem-
ory location is initialized, by executing a setup phase that
constructs an accumulator containing the tuple (cid:104)δ,0(cid:105) for ev-
ery address δ. The cost of constructing this accumulator is
high when the address space is large, since it amounts to one
exponentiation per entry in RAM. Note, however, that this
computation can be parallelized using the pre-computed val-
ues described in Section 4.4, and admits the same time-space
tradeoff described in that section.12
12An alternative solution is to implement, in essence, a shadow mem-
ory [92] indicating which addresses are valid. This is effected by storing a
canary value valid[δ] in the accumulator for each address δ for which some
tuple (cid:104)δ,·(cid:105) exists. If Ψ attempts to LOAD or STORE from a memory location
Costs. The constraint costs of memory accesses are shown
in the bottom two rows of Figure 3. The Merkle-based RAM
requires two proofs of membership for each STORE, but only
only one for each LOAD [32], so it is slightly cheaper than a
Merkle swap—but logarithmic in RAM size.
The RSA accumulator–based RAM uses one MultiSwap
for all LOADs and STOREs, with attendant per-operation
costs (which are independent of RAM size; §5). It also incurs
extra per-operation costs to check T as described above; these
are logarithmic in the number of accesses but concretely very
inexpensive (§2.2, [116, Fig. 5; 79, Appx. B-A]).
6
Implementation
We implement a library comprising multiprecision arith-
metic, Pocklington prime certiﬁcation, RSA accumulators,
and Merkle trees. This library extends Bellman [9], a library
for building constraint systems and generating proofs using
the pairing-based argument due to Groth [70]. Based on this
library, we implement two end-to-end applications: one that
veriﬁes a sequence of swaps, and one that veriﬁes a batch of
transactions for a distributed payment system (§5.1).
We also implement or adapt four hash functions: MiMC [1],
which costs 731 constraints (91 rounds of the x7 permutation);
Poseidon [69], which costs 316 constraints; Pedersen [72, 97],
which costs 2753 constraints (based on the JubJub elliptic
curve [28]), and SHA-256 [57], which costs 45567 constraints.
We adapt the latter three hashes from Sapling [104].13
Finally, we implement custom Bellman constraint synthe-
sizers (ConstraintSystems, in the jargon of Bellman) that
allow us to quickly measure a constraint system’s size and
P ’s cost computing a corresponding witness.
We use a 2048-bit RSA quotient group (§2) modulo the
RSA-2048 challenge number [76, 102], and choose a random
2048-bit ∆ to deﬁne the division-intractable hash function
H∆ (§4.2); we give concrete values in Appendix B. We syn-
thesize all constraints over the BLS12-381 [27] curve.
In total, our implementation comprises ≈11,300 lines of
Rust. We have released it under an open-source license [10].
7 Evaluation
We evaluate our MultiSwap implementation, comparing it to
Merkle trees by answering the following questions:
δ for which no value exists, P supplies a proof of non-membership (§2.1)
for valid[δ], plus a default value. This obviates the setup phase, but requires
additional constraints to (1) compute H∆(valid[ADDRi]) for each entry in T ,
(2) check a batched non-membership proof, (3) check a batched insertion of
valid[·] values (which can be combined with the swap check), and (4) enforce
correctness of the default value. Further exploration is future work.