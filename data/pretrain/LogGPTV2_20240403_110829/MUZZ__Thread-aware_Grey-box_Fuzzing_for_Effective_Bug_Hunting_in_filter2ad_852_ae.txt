0
0
0
0
1
24
1
19
2
176
0
0
43
1
Nc
6
0
49
27
495
88
52
MAFL
Nm
c
0(+6)
0(+15)
23(+40)
0(0)
279(+68)
88(+15)
0(0)
Nm
v
1(0)
0(+1)
2(+2)
0(0)
1(+1)
1(0)
0(0)
AFL
MOPT
c Ns
Ns
v
0
0
0
0
1
26
1
27
2
216
0
0
52
1
Nc
0
0
29
14
393
78
62
Nm
c
0(+6)
0(+15)
6(+57)
0(0)
205(+142)
78(+25)
0(0)
Nm
v
0(+1)
0(+1)
2(+2)
0(0)
1(+1)
1(0)
0(0)
c Ns
Ns
v
0
0
0
0
1
23
1
14
2
188
0
0
62
1
Nc
0
0
32
15
501
66
59
Nm
c
0(+6)
0(+15)
6(+57)
0(0)
301(+46)
66(+37)
0(0)
Nm
v
0(+1)
0(+1)
2(+2)
0(0)
1(+1)
1(0)
0(0)
c Ns
Ns
v
0
0
0
0
1
26
1
15
2
200
0
0
59
1
respectively), while MAFL, AFL and MOPT failed to detect
it in 15 days (360 hours) in all their six fuzzing runs. The
newly detected vulnerability has been assigned with another
CVE ID. The vulnerability details are available in Table 5.
Given the fact that there are extremely few CVE records
caused by concurrency-vulnerabilities (e.g., 202 among
70438, based on records from CVE-2014-* to CVE-2018-
*) [48], MUZZ demonstrates the high capability in detecting
concurrency-vulnerabilities.
Answer to RQ2: MUZZ demonstrates superiority in
exercising more multithreading-relevant crashing states
and detecting concurrency-vulnerabilities.
6.4 Concurrency-bug Revealing (RQ3)
The fuzzing phase only detects the vulnerabilities caused by
crashes, but the seemingly normal seed ﬁles generated dur-
ing fuzzing may still execute paths that trigger concurrency-
violation conditions like data-races, deadlocks, etc. We detect
concurrency-bugs in concurrency-bug revealing component
( D , right-top in Figure 3). It is worth noting that our goal is
not to improve the capabilities of concurrency-bug detection
over existing techniques such as TSan [42], Helgrind [49],
or UFO [21]. Instead, we aim to reveal as many bugs as
possible within a time budget, by replaying against fuzzer-
generated seeds with the help of these techniques. In practice,
this component feeds the target program with the seeds that
were generated during fuzzing as its inputs, and facilitate de-
tectors such as TSan to reveal concurrency-bugs. During this
evaluation, we compiled the target programs with TSan and
replayed them against the fuzzer-generated multithreading-
relevant seeds (corresponding to Nmt in Table 2). We did not
replay with all the generated seeds (corresponding to Nall in
Table 2) since seeds not exercising multithreading context
will not reveal concurrency-bugs.
We limit our replay time budget to two hours; in §6.5.4 we
discuss the rationale of this conﬁguration. The next is to deter-
mine the replay pattern per seed to reveal more concurrency-
bugs within this budget. This is necessary since TSan may
fail to detect concurrency-bugs in a few runs when it does
not observe concurrency violation conditions [12, 42, 49].
Meanwhile, as the time budget is limited, we cannot exhaus-
tively replay against a given seed to see whether it may trigger
concurrency-violations — in the worst case, we may waste
time in executing against a seed that never violates the condi-
tions. We provide two replay patterns.
P1 It executes against each seed in the queue once per turn
in a round-robin way, until reaching the time budget.
P2 It relies on Nc in repeated execution (c.f., §5.2): each seed
is executed Nc
times per turn continuously in a round-
N0
robin way. According to Equation 4, we replay 5 times
per turn (40/8) for AFL generated multithreading-relevant
seeds; for MUZZ and MAFL, it is determined by Equa-
tion (5), with candidate values 2, 3, 4, 5.
It is fair to compare replay results w.r.t. P1 and P2 in that
the time budget is ﬁxed. The difference between the two
patterns is that seeds’ execution orders and accumulated exe-
cution time spent on them can be rather different.
Table 4 depicts the results for concurrency-bug revealing
with P1 and P2. Nm
e is the number of observed concurrency-
violation executions and Nm
B is the number of concurrency-
bugs (Bm) according to their root causes. For example, it only
counts one concurrency-bug (Nm
B =1) even when the replay-
ing process observes 10 data-race pairs across executions
(Nm
e =10), as long as the root cause of the races is unique. We
analyze this table from two perspectives.
First, MUZZ demonstrates superiority in concurrency-bug
detection regardless of replay patterns. This is observed based
on the “best results” for each metric in each pattern. MUZZ
achieves the best results for most projects. For example, when
x264 is replayed with Nm
e , 1) MUZZ’s found the most viola-
tions — the values of Nm
e are, MUZZ: 68, MAFL: 46, AFL:
28, MOPT: 30; 2) the best result of Nm
B also comes from
MUZZ, MUZZ: 8, MAFL: 6, AFL: 4, MOPT: 5. Similar re-
sults can also be observed with P2 for x264, where MUZZ
has the biggest Nm
B (9). The only project
where MAFL achieves the best is pigz-c, where it is slightly
e (91) and biggest Nm
2336    29th USENIX Security Symposium
USENIX Association
Table 4: Comparisons of replay patterns P1 and P2 on MUZZ, MAFL, AFL and MOPT, in terms of concurrency violations (Nm
e )
and concurrency-bugs (Nm
B are underlined / bold for P1 / P2 respectively.
B ). The best results of Nm
e and Nm
ID
lbzip2-c
pigz-c
gm-cnvt
im-cnvt
vpxdec
x264
MUZZ
Nm
e
469
793
93
92
31
68
Nm
B
1
1
5
3
3
8
MAFL
Nm
Nm
e
B
1
447
1
803
4
79
84
3
1
17
46
6
P1
AFL
Nm
e
386
764
45
58
23
28
Nm
B
1
1
2
2
1
4
MOPT
Nm
B
1
1
3
2
1
5
Nm
e
435
789
55
56
18
30
MUZZ
Nm
e
493
856
133
118
42
91
Nm
B
1
1
5
3
3
9
MAFL
Nm
Nm
e
B
1
483
1
862
4
83
3
117
1
22
52
6
P2
AFL
Nm
e
421
727
54
65
25
25
Nm
B
1
1
3
2
1
4
MOPT
Nm
B