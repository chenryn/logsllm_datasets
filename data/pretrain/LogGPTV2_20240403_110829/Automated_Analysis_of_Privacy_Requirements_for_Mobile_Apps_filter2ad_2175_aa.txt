# Automated Analysis of Privacy Requirements for Mobile Apps

**Authors:**
- Sebastian Zimmeck
- Ziqi Wang
- Lieyong Zou
- Roger Iyengar
- Bin Liu
- Florian Schaub
- Shomir Wilson
- Norman M. Sadeh
- Steven M. Bellovin
- Joel R. Reidenberg

## Abstract
Mobile applications must meet various privacy requirements, including the provision of a privacy policy and notification of users about their data practices. However, it can be challenging for users to verify if an app adheres to its stated policies. This study introduces a scalable system to analyze and predict Android apps' compliance with privacy requirements. We collaborated with the California Office of the Attorney General to customize our system, which is intended to assist regulators, activists, app publishers, and app store owners in assessing privacy requirement compliance.

Our analysis of 17,991 free Android apps demonstrates the effectiveness of combining machine learning-based privacy policy analysis with static code analysis. The results indicate that 71% of apps without a privacy policy should have one. For the 9,050 apps with a policy, we found many potential inconsistencies between the policy and the app's actual behavior. Specifically, 41% of these apps may collect location information and 17% may share such data with third parties without disclosing this in their policies. On average, each app exhibits 1.83 potential privacy requirement inconsistencies.

## 1. Introduction
Snapchat’s privacy policy stated, "We do not ask for, track, or access any location-specific information [...]." However, its Android app transmitted Wi-Fi and cell-based location data to analytics service providers, a discrepancy that was only discovered when a researcher examined the app. This case highlights the frequent non-compliance of mobile apps with privacy requirements, which can lead to enforcement actions by regulatory bodies like the Federal Trade Commission (FTC). Such discrepancies can persist for years, as seen with Yelp’s collection of children's information.

The FTC has repeatedly expressed dissatisfaction with the current state of app privacy compliance. In surveys of children's and shopping apps, the FTC found that many publishers fail to disclose their data collection, use, and sharing practices. Given the limited scope of these investigations, a large number of discrepancies likely remain undetected.

In this study, we present a privacy analysis system for Android that checks apps’ data practices against privacy requirements derived from their policies and selected laws. Our system helps app publishers identify potentially privacy-invasive practices before publication and aids regulators in enforcing privacy laws on a large scale. Our main contribution is the novel combination of machine learning and static analysis techniques to detect potential non-compliance with privacy requirements.

### Key Contributions:
1. **Privacy Policy Analysis**: For 17,991 Android apps, we check whether they have a privacy policy. For the 9,295 apps with a policy, we use machine learning classifiers to analyze the content based on a human-annotated corpus of 115 policies. Only 46% of the analyzed policies describe a notification process for policy changes.
2. **Static Code Analysis**: Using static analysis, we investigate the actual data practices in the apps' code. Our approach has a failure rate of 0.4%, a mean F-1 score of 0.96, and a mean analysis time of 6.2 seconds per app, making large-scale app analyses feasible and reliable.
3. **Inconsistency Detection**: We map the policy to the app analysis results to identify and analyze potential privacy requirement inconsistencies. We also construct a statistical model to predict such inconsistencies based on app metadata. For instance, apps with a Top Developer badge have significantly lower odds of having potential inconsistencies.
4. **Collaboration with Regulators**: In collaboration with the California Office of the Attorney General, we performed a preliminary evaluation of our system for use in privacy enforcement activities. Results suggest that our system can help lawyers and other users efficiently analyze salient privacy requirements, allowing them to prioritize critical areas.

## 2. Related Work
### 2.1 Privacy Policy Analysis
Privacy policies are essential for disclosing an organization's data practices. Despite efforts to make them machine-readable, natural language policies remain the standard. These policies are often long and difficult to read, leading to few lay users reading them and regulators lacking the resources for systematic review. Previous studies have aimed to make policies more comprehensible, but there is a need for an automated system to accurately analyze policy content.

Our work automates and scales the analysis of natural language privacy policies, focusing on legal questions and not just readability. We use machine learning classifiers and introduce a new approach for privacy policy feature selection. Our analysis is informed by previous studies but goes beyond them in terms of breadth and depth, analyzing a larger policy corpus and focusing on legal questions not yet automatically analyzed.

### 2.2 Mobile App Analysis
Our analysis of Android apps distinguishes between first and third-party data practices, which must be analyzed independently due to their separate legal relationships with users. Ad and analytics libraries are particularly important, as they are responsible for a significant portion of data sharing. We extend various app analysis techniques to achieve a meaningful analysis of potential non-compliance with privacy requirements derived from policies and laws.

Our app analyzer is built on Androguard, a static analysis tool, and uses PScout to check required permissions for API calls. We also draw on FlowDroid and DroidSafe for sensitive data sharing and the ded decompiler for APKs. However, our work is unique in its focus on large-scale privacy requirement analysis.

### 2.3 Potential Privacy Requirement Inconsistencies
While mobile app analysis has received attention, the results are often not placed in a legal context. We address this by inquiring whether apps' practices are consistent with their privacy policies and selected legal requirements. This legal dimension gives meaning to the app analysis results. We combine the analyses of apps, privacy policies, and laws to identify potential privacy requirement inconsistencies.

Previous studies have focused on creating privacy documentation from code or comparing program behavior with non-legal texts. Our approach is inspired by TaintDroid and similar studies but goes beyond them by addressing new privacy questions, distinguishing between first and third-party practices, and achieving higher accuracy and lower failure rates.

## 3. Privacy Policy Analysis
[This section will be expanded with detailed methods and results of the privacy policy analysis, including the use of machine learning classifiers, feature selection, and the specific privacy questions addressed.]

---

This revised version provides a clearer, more structured, and professional presentation of the research, highlighting the key contributions and methods used.