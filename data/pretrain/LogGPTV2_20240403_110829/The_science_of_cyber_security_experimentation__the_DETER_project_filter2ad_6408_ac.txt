• 
• 
• 
• 
some  parts  of  an  apparatus  require  high-resolution 
nodes with high fidelity; 
some  other  parts  require  a  lower  degree  of  resolution 
and can represent real computing at a larger scale; 
there is a “scale of scaling” with points that range from 
high fidelity and linear scaling, to low fidelity and high 
scalability; 
different points on the scale will be enabled by different 
mechanisms for emulation and simulation. 
As  a  result  of  this  observation,  we  began  to  explore  methods  to 
incorporate  a  number  of  representation  methods  that  together 
provide a full spectrum of scale-fidelity tradeoffs for experimental 
system components. The following is a partial list of examples: 
• 
• 
• 
• 
• 
a  single  hardware  node  running  a  single  experiment 
node,  either  natively,  or  via  a  conventional  Virtual 
Machine  Manager  (VMM)  supporting  a  single  guest 
OS; 
a  single  hardware  node  running  several  virtualized 
experiment  nodes,  each  a  full-blown  conventional 
Virtual Machine (VM) on a conventional VMM; 
a  single  node  running  a  large  number  of  lightweight 
VMs  on  a  VMM  designed  for  scaling  the  number  of 
experiment-nodes with limited functionality; 
representation of individual experiment nodes as threads 
of  execution 
thread  management 
environment; 
large-scale software-based network simulation [22].  
large-scale 
in  a 
Further, we recognized that these methods would be more useful 
to experimenters if all methods were part of a unified framework 
for  the  construction  of  composable  experiment  apparatus,  using 
both some common building blocks and methods of composition 
with abstraction and re-use.  Our approach to such a framework is 
to base on it on an abstract fundamental building block  called a 
“container”  which  represents  experimental  elements  at  the  same 
level  of  abstraction,  and  is  the  basic  unit  of  composition  for 
constructing  an  experimental  apparatus.  The  container-based 
methodology is a key part of pursuing some important goals: 
• 
• 
• 
leverage DeterLab’s physical resources more flexibly to 
create larger scale experiments; 
enable  experimenters  to  model  complex  systems  with 
high  resolution  and  fidelity  for  the  things  that  matter 
most  to  them,  and  abstract  out  the  less  important 
elements; 
reduce  the  experimenter’s  workload  of  experiment 
apparatus  construction,  enabling  larger  scale  apparatus 
with lower levels of effort. 
3.5  Lesson Learned: From Experimental 
Apparatus to Experimental Data to 
Experimental Results 
The previous four lessons learned were largely related to the static 
aspects of setting up an experimental apparatus: basic construction 
of an apparatus; use of fixtures for federation; use of fixtures to 
enable  limited  communication  outside  the  testbed;  and  use  of 
fixtures  that  support  orders-of-magnitude  experiment  scale-up 
it 
that  experimenters  could  use 
over  that  obtainable  with  more  simplistic  use  of  physical 
resources.  
Other lessons learned were about the dynamic aspect of running 
an experiment. Early in the 2nd phase, we recognized the need for 
a  workbench 
to  operate  an 
experimental  apparatus,  feeding 
input  data  and  events, 
observing  its  operation,  and  adjusting  the  fixtures  for  collecting 
experimental  data.  The  first-phase  workbench,  SEER  [10],  met 
that  need  to  some  extent.  However,  adoption  of  SEER  also 
brought into focus a growing need for DeterLab experimenters: an 
approach to the “big data” problem. As DeterLab facilities have 
matured with scale and power and data capture capability, and as 
observation  of  the  behavior  of  a  running  experiment  drove 
improvements  in  data  collection,  the  result  was,  for  many 
experiments, a much larger set of output data to be analyzed from 
each experiment run. 
Further, not only the size of data grew, but also the structure and 
complexity  of  the  datasets  increased.  In  addition  to  log  analysis 
tools to help deal with raw data size, there was a need for other 
methods  –  and  automated  support  for  them  –  to  analyze  data  in 
terms  of  the  intended  semantics  of  the  experiment  run,  and 
ultimately  to  proceed  from  data  analysis  to  actual  experimental 
results: proving or disproving a hypothesis, or stating knowledge 
of  malware  behavior,  or  use  of  metrics  for  effectiveness  of 
countermeasures.  
In other words, experimenters need both tools and methodologies 
for mining experimental data to discover experiment results. This 
lesson  learned  served  to  underscore  the  importance  of  our 
research work on narrowing this large “semantic gap” as part of 
our research efforts on Experiment Lifecycle Management. 
4.  CURRENT DETER RESEARCH 
PROGRAM 
Our  current  research  program  includes,  but  is  not  limited  to, 
activities related to the above lessons learned. Current research is 
in  some  cases  an  outgrowth  of  work  performed  as  part  of  our 
agenda to enrich the testbed with progressive enhancements that 
resulted  in  what  we  now  call  DeterLab.  During  the  2nd  phase  in 
which  we  were 
learning  from  DeterLab  users,  our  own 
enhancement efforts included: 
First generation of federation capabilities [9]; 
• 
•  Risky  experiment  management  and  abilities  to  include 
outside communication [16];  
The  first-generation  “experimenter  workbench”  for 
managing an experiment in process, viewing its activity 
and results data [10]. 
• 
In  some  cases,  there  was  real  synchronicity  between  our 
objectives and the needs of DeterLab experimenters. As described 
above, the first generation of federation capability arose from our 
desire to reach greater scale by using resources in other testbeds 
that we could link to; in addition, we learned that experimenters 
wished  to  link  into  their  experiments  some  outside  resources  of 
their own, and/or specialized resources that they had access to. As 
a result, our research agenda (for federation with access control) 
was enriched with new use cases and additional requirements. 
4.1  Experiment Lifecycle Management 
Experiment lifecycle management is an outgrowth of work on our 
first  generation  workbench,  SEER.  Indeed,  many  of  SEER’s 
capabilities,  including  experiment  monitoring  and  visualization, 
are  carried  over  into  the  next  generation  workbench,  the 
Experiment  Lifecycle  Manager  (ELM),  albeit  in  a  new  usage 
paradigm. 
One  critical  aspect  of  ELM  focuses  on  the  general  concept  of 
objects that an experimenter uses. DeterLab has grown to include 
a  large  number  and  variety  of  objects  available  to  experiments. 
With that growth has come the challenges of giving experimenters 
the  tools  need  to  effectively  manage  their  working  set,  and 
(critically)  to  effectively  share  with  other  experimenters.  The 
objects  used  by  an  experimenter  include  scientific,  physical, 
communication,  and  computational 
in  an 
experiment.  Also  included  are  models,  designs,  procedures, 
programs, and data. Storage, presentation, archival, browsing, and 
searching are basic ELM functions for managing an experiment’s 
components – and allowing other researchers to access them – far 
beyond the original testbed approach of shell login and filesystem 
access. We are building this basic management framework on the 
Eclipse  [23]  platform,  in  order  to  leverage  and  build  upon  the 
many  integrated  development  environment  (IDE)  capabilities  of 
Eclipse. 
resources  used 
Figure 1: Screenshot of an experimenter using ELM to view a 
catalog of experiment components, and select and view a 
network topology displayed visually 
New levels of abstraction in experiment definition are also a key 
component  of  ELM. 
testbed  approach, 
experimenters had to specify in detail a number of different types 
of resources: 
the  original 
In 
the 
and 
complete 
•  Computational  elements  such  as  physical  or  virtual 
“network  plumbing” 
hosts, 
configuration of each. 
Elements of a network operating environment, including 
network  topology,  router  and  switch  nodes  and  their 
configurations. 
• 
•  Network nodes that perform traffic shaping to simulate 
real  world  network  conditions,  delays,  throughput 
limits, etc. 
software 
elements 
typical  of 
the  network 
running  within 
In  addition,  experimenters  had  to  specify  in  detail  a  number 
experiment 
and 
computational resources: host operating systems, guest operating 
systems  for  VMs,  application  software,  and  logging  and  other 
infrastructure 
systems.  Further, 
experimenters  had  to  deploy  on  these  systems  a  number  of 
experimental fixtures such as traffic generators, tools for running 
experimental  procedures  and  collecting  result  data,  and  often 
malware to be observed and cyber-defenses to be tested. 
Perhaps most significantly, each experimenter tended to do their 
own  apparatus  construction  largely  from  the  ground  up,  with 
limited  leverage  of  others’  work  in  defining  experimental 
real 
components 
abstractly,  with 
apparatus.  In  ELM,  all  these  types  of  experiment  resources, 
elements, fixtures, and artifacts do of course need to be managed 
as  individual  objects,  as  building  blocks  for  components  of  an 
experiment.  More  importantly,  we’re  working  on  construction 
methods  that  include  both  the  basic  building  blocks,  and  also 
structures  of  them  that  prior  experimenters  have  contributed.  In 
other words, with ELM, experiments can be highly modular, and 
explicitly structured for re-use as shown in Figure 1.   
Although  the  detail-oriented  “expert  mode”  is  still  available,  we 
expect most researchers to use the newer facilities for defining an 
experiment’s 
requirements, 
constraints,  and  invariants,  rather  than  specify  directly  and  in 
every detail. For example, an earlier experiment may already have 
defined an apparatus that simulates a handful of large enterprise 
networks  connected  over  the  public  network,  a  number  of  ISP 
networks, and home computers. This apparatus, though conceived 
for use in worm spread, may nevertheless be described with meta-
data  that  enables  a  later  researcher  to  identify  it  as  a  suitable 
starting point for their work. The later researcher should be able to 
use  the  archived  design,  and  state  some  new  requirements  and 
constraints  relevant  to  their  work,  or  specify  some  properties  of 
specific  experiment  fixtures  for  input  generation  or  monitoring. 
Without  having  to  know  other  detail  beyond  their  requirements, 
experimenters  can  describe  an  experiment  apparatus  entirely 
independent  of 
its  realization  on  computing  and  network 
resources. 
Thus  far,  the  description  of  ELM  is  analogous  to  an  IDE  with 
source  code 
for 
combining  them,  with  shared  storage,  versioning,  and  change 
control  –  all  valuable  advances  from  the  early  DETER  testbed. 
However, ELM also provides other critical facilities analogous to 
an IDE: 
repositories,  modules, 
libraries, 
facilities 
•  Mechanisms  for  “realizing”  an  abstract,  modular 
experiment definition by allocating and configuring real 
network and computing elements. 
Tools  for 
to  yield 
information that expresses experimental results in terms 
of  the  experiment’s  model  and  the  abstractions  that 
helped define the apparatus. 
interpreting  experimental  data 
• 
Following  sections  describe  some  of  our  work  on  advances  in 
realizing  and  running  experiments  at  scale,  and  on  model-based 
experimentation  that  enables  semantic  analysis  of  results.  That 
work is directly reflected into the ELM methodologies and tools 
mentioned above. 
4.2  Containers: Scale-up and Flexible Fidelity 
Our  continuing  work  on  scalability  is  based  on  the  observations 
(summarized in Section 3.4) about trade-offs between the fidelity 
or realism of a computational element in DeterLab, and the scale 
of  network  and  computing  resources  required  to  realize  a 
computational element. However, re-usability is also an important 
goal  for  the  ease  of  use  of  DeterLab  tools  for  constructing  an 
experimental  apparatus.  By  adding  new  types  of  computational 
element (conventional VMs, QEMU lightweight VMs, processes 
on  conventional  OSs,  QEMU  processes,  individual  threads  of 
execution),  each  of  which  can  be  used  to  model  a  node  in  a 
simulated  network,  we  added  both  flexibility  and  complexity  to 