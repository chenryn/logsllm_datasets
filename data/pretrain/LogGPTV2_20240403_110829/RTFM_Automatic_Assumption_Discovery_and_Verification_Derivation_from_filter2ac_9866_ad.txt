0.67
0.67
0.4
0.8
0.78
0.66
5.2 Effectiveness
Here we report the findings made by our evaluation of Advance,
first about its overall effectiveness in identifying API misuse from
the applications integrating the APIs of libpcap, libdbus and libxml2,
and then about the effectiveness of its individual components (i.e.,
IA discovery, IA dereference and VC generation).
End-to-end effectiveness. Since OpenSSL was used for S-HAN
training and later for CD mining along with SQLite, they were
excluded in our experiment for fairly evaluating the end-to-end
effectiveness of Advance. In the experiment, we ran Advance on 20
applications integrating APIs of libpcap, libdbus and libxml2, which
reported 92 API misuses. To validate the results, three researchers
took 2 days to cross-check 𝐷𝑎𝑝𝑖 for known API misuses, and man-
ually verify the results for unknown ones. 83 of the reported API
misuses were confirmed (52 undisclosed and 31 disclosed misuses),
which yields a precision of 90%. Table 4 in Appendix includes these
manually-validated API misuses, along with their security impacts.
Note that we also ran Advance on all five library documents as
detailed in Section 5.4.
Looking into the 9 false positives, we found that all of them were
introduced by CodeQL, which cannot effectively performs a data-
flow analysis. Although our verification code were all correctly
generated in these cases, CodeQL were found to be less effective in
implementing the check, causing the false positives. For example,
consider the code snippet in Listing 3 in Appendix: its IA requires
the pointer assigned through xmlGetProp to be freed, which has
been done after the pointer assigned to a list; however, even though
the code Advance generates for CodeQL indeed correctly invokes
the CodeQL API TaintTracking to track this dataflow, the API
itself fails to discover the connection between the pointer and the
list, thereby falsely claiming discovery of a misuse.
Note that compared with code analysis-based API misuse de-
tectors [30, 52], Advance reports a lower false positive rate (Sec-
tion 5.3). This is because our approach extracts IAs from API docu-
mentation to guide misuse detection in applications, whereas code
analysis-based approaches infer putative IAs through identifying
code invariants, which tend to be less accurate and heavily rely on
the quality of 𝐷𝑎𝑝𝑝. Further, Advance is unique in its capability
to suppress the false positives incurred by IA discovery and IA
dereference, which could be removed by the strict VC generation
templates (Section 3.4). As a result, wrongly identified IAs may not
be translated into VCs.
To understand false negatives introduced by Advance, we utilized
the ground-truth set 𝐷𝑎𝑝𝑖 to find out whether it captures known
API misuses (related to libxml2, libpcap and libdbus). The study
shows that our approach reports 31 out of 38 cases in 𝐷𝑎𝑝𝑖 (82%).
Among the 7 cases missed, one is introduced by the error in IA
dereference, another by the mis-classification of S-HAN, and the all
remaining by the failure in CD-to-VCS translation, due to missing
CDs (which are rare and therefore are not translated).
Effectiveness of IA discovery. In our study, we first evaluated the
effectiveness of IA discovery on 1,305 IAs and 3,881 non-IAs from
OpenSSL in 𝐷𝑖𝑎𝑑 using a five-fold cross-validation. Our prototype
achieved a false positive rate of 8% and a false negative rate of 9%
in finding IA, as shown in Table 2.
Further, using the S-HAN model trained on OpenSSL, we ran IA
discovery over the documents of the four other libraries (i.e., SQLite,
libpcap, libdbus, libxml2). Altogether, our prototype identified 542,
249, 799 and 1,671 IAs for SQLite, libpcap, libdbus, libxml2, respec-
tively, which yields an average false positive rate of 10% and a false
negative rate of 15% on 𝐷𝑖𝑎𝑑 (over the four libraries as shown in
Table 1). Table 2 details the experiment results.
When looking into the false positives observed from the model’s
output, interestingly, we found that most sentences falsely labeled
as IAs turn out to indeed contain sentiment terms and state some
constraints, which however are supposed to be followed not by
the developers who integrate the APIs but by those developing,
maintaining or extending the library. For example, the sentence
“Additionally it indicates that the session ticket is in a renewal period
and should be replaced” is falsely labeled as an IA, since it includes
the sentiment word “should” and describes the required operations
to be performed by the OpenSSL library. On the other hand, false
negatives apparently were introduced by the sentiment analysis
performed by S-HAN, which misses some sentiment terms like “not
safe”, “is broken”, etc., due to the incompleteness of our training set.
Effectiveness of IA dereference. The effectiveness of the IA
dereference was evaluated on 𝐷𝑣𝑐. The results are shown in Table 2,
where the columns “API” and “Parameter” present the results for
API dereference and parameter dereference respectively. Each kind
of dereference was evaluated based upon four metrics ACC, F1, FRP
and FNR. The API dereference analysis achieves an accuracy of 94%,
a F1 of 66%, a false positive rate of 4% and a false negative rate of
27% respectively, which are 89%, 51%, 12% and 9% for the parameter
dereference analysis.
For the IA dereference, both FNs and FPs were caused by the
incorrect tags generated by the shadow parsing. For example, in the
noun phrase (NP) “file descriptor BIOs”, “file” should be labeled as a
noun, but the tool we use (StandfordCoreNLP [38]) marks it as a
verb, causing the NP to be incorrectly dereferenced. False negatives
also occur when the similarity between a VP and the description of
its related API is low, due to the limitations of word embedding.
Also, Advance utilized the first sentence of an API’s description
as the functionality sentence (Section 3.3). To evaluate the effective-
ness of this design choice, we sampled 178 API descriptions and
found that the first sentences of 157 (88%) are indeed functionality
sentences. Also, we manually checked the 21 sentences wrongly
labeled. None of them leads to incorrect IA dereference.
Effectiveness of VC generation. The last internal component
we evaluated is verification code generation. To evaluate its effec-
tiveness, we checked whether the 420 IA-CD pairs in 𝐷𝑣𝑐 were
generated by our VC generation process, which yields an average
recall of 69% and false negative rate of 31% as shown in Table 2.
We further looked into such false negatives in our study, with
the following discoveries. Some FNs were introduced by rarely used
CDs whose VCSes do not exist in our system. In the other cases, we
found that some VCSes could not be handled by CodeQL. For exam-
ple, consider the statement “sqlite3_deserialize is only available if
SQLite is compiled with the SQLITE_ENABLE_DESERIALIZE option.”;
the CD “be compiled with” can be detected by our approach, but
cannot be converted to the VCS, since CodeQL cannot check how
the application is compiled. As another example, in the IA “A server
application must also call the SSL_CTX_set_tlsext_status_cb function
if it wants to be able to provide clients with OCSP Certificate Status
responses”, we have no idea whether indeed the developer intends
to do so and therefore cannot run CodeQL to check a program’s
compliance with the IA. Note that VC generation templates used in
our study are not narrow, as evidenced by the high coverage of our
approach (75% of all the CDs of IAs; see “CD-Cov” in Table 2).
Runtime performance. Running Advance on 39 applications as-
sociated with 5 libraries (1.47MB files), it took Advance 32.5 hours
to finish all the tasks including IA discovery, IA dereference and
VC generation. Among the three components, VC generation was
the most time-consuming one (31 hours/95%). IA discovery took
1.5 hours (3%) to preprocess data and training S-HAN. It only took
170 seconds to find IAs of 5 libraries. The rest 2% time is used for
IA dereference.
5.3 Comparison with the State-of-the-Art
In our research, we firstly compared the end-to-end performance of
Advance with that of static API misuse analyzers (e.g., APEx [30]
and APISAN [52]) and a dynamic fuzzer (e.g., AFL [2]). Then we
further compared the effectiveness of Advance’s individual com-
ponents against their counterparts in the state-of-the-art of other
document-based approaches. Note that to the best of our knowl-
edge, there is no end-to-end tool available for detecting API misuse
from unstructured library documents.
Comparison with other API misuse detectors. We ran two
state-of-the-art static API misuse detection tools (APISAN [52]
and APEx [30]) on 𝐷𝑎𝑝𝑝, which reported 150,788 and 1,100 API
misuses, respectively. Given the huge number of cases, known high
false positive rates of these approaches [30, 52] and the difficulty
in validating even a sampled subset (due to the lack of ground
truth for the IA semantics inferred), we only cross-checked the
results against our ground-truth set 𝐷𝑎𝑝𝑖 and the 139 undisclosed
but manually-validated API misuses found by Advance. The results
are presented under “APISAN” and “APEx” of Table 4 in Appendix.
From the table, we can see that only 15% and 2% API misuses that
Advance reports can also be found by APISAN and APEx, respec-
tively. Also, among the 66 misuse cases in 𝐷𝑎𝑝𝑖, APISAN and APEx
only find 4 and 2, respectively, whereas Advance detects 54.
Also, when compared with the precision of APISAN and APEx,
as reported by the prior work [30, 52] (12% and 21.6%), Advance
achieves a much higher precision (90%, see Section 5.2). The reason
is that APISAN and APEx rely on program analysis to infer possible
IAs (invariants in API uses) for detecting API misuses, which is less
reliable and tends to miss legitimate IAs or introduce false ones.
Further, we compared Advance with the most popular dynamic
bug detector AFL [2]. In our research, we ran AFL on each applica-
tion in our dataset (except 1 vulnerable version of ntop, which is too
old (16 years ago) to compile). Following Klees et al [33], we set the
timeout to 24 hours, and also utilized the default settings to choose
initial seeds, i.e., choosing from AFL testcases4, or the test cases
provided by application themselves. From the result shown under
“AFL” of Table 4, we can see that AFL detects no API misuses. This
is because without the guidance of IAs, coverage-based fuzzers like
AFL can be hard to trigger the anomalous program behaviors caused
by API misuses and in some cases, they fundamentally cannot: for
example, those unrelated to memory errors, such as authentication
bypass, cannot be found by AFL.
Comparison with other IA discovery approaches. We com-
pared Advance’s IA discovery component with two state-of-the-
art document-based approaches, one using keywords [47] and the
other leveraging grammatical templates based upon shallow pars-
ing (called ALICS) [44] for detecting IAs. In our experiment, we
evaluated the approaches on 𝐷𝑖𝑎𝑑 under the settings described in
their papers [44, 47]. Figure 5 shows the experiment results in terms
of accuracy, F1, FPR and FNR. Our study shows that Advance sig-
nificantly outperforms both approaches, particularly in terms of
accuracy (e.g. 88% vs 44% for ALICS [44]) and F1 score. Also, the
false negative rate of Advance is lower.
We also compared our S-HAN with two most popular off-the-
shelf classifiers: Text-CNN [32] and RCNN [34]. We trained these
models on the training data in 𝐷𝑖𝑎𝑑. Figure 6 (a) shows the accuracy
of the three models (RCNN, Text-CNN, and S-HAN) on 𝐷𝑖𝑎𝑑. We
can see that S-HAN has a much better accuracy, especially when
applied to different libraries. This is mainly because the attention
mechanism captures the sentiment words used by various develop-
ers in different documents.
Comparison with other VC generation approaches. For veri-
fication code generation, we compared our approach with three
popular tools tComment [48], Toradocu [27], and Jdoctor [22]. Since
these tools cannot automatically discover IAs from documents, we
utilized the annotated IAs in 𝐷𝑣𝑐 as their inputs, and evaluated
their effectiveness on 𝐷𝑣𝑐. Figure 6 (b) illustrates the experiment
results, showing that Advance significantly outperforms all these
three tools. We observe that Advance incurs a much lower false
negative rate than others: these approaches can only handle the IAs
4All kinds of file types that are provided by AFL.
Figure 5: Comparison with other IA discovery approaches (Keywords and ALICS). (a) to (d) represent 4 comparison metrics
on 5 evaluated libraries.
Figure 6: (a) Comparing S-HAN accuracy with RCNN and
TextCNN models. (b) Comparing VC generation FNR of Ad-
vance with tComment, Teradocu and Jdoctor
with simple arithmetic operations and logic operations, whereas
Advance can address more complicated constraints with data flow,
control flow and complex context conditions.
5.4 Findings
Running Advance on the documentation of 5 popular libraries (i.e.,
OpenSSL, SQLite, libpcap, libdbus and libxml2) and 39 applications
integrating these libraries, our study uncovered 139 undisclosed
and 54 known API misuses (shown in Table 4 in Appendix). Among
them, 16 of the undisclosed API misuses have been confirmed by the
application developers [5–11]. Also 6 of the known API misuses has
been assigned with CVEs. When classifying them using the CWE
standard5, we observe a wide range of vulnerability types: memory
corruptions or misuse (e.g., double free (CWE-415), use after free
(CWE-416), improper resource shutdown or release (CWE-404)),
authentication errors (e.g., improper certificate validation (CWE-
295)), incorrect check of return value (CWE-253) and use of obsolete
function (CWE-477). Table 4 lists the security impact of 193 API
misuses reported by Advance. We can observe serious security
implications of these API misuses including information leakage,
code execution, system crash, etc. Interestingly, we observed misuse
associated with deprecated API, e.g., using the deprecated API
RAND_pseudo_bytes of OpenSSL will allow remote attackers to
defeat the system [12].
Taking a close look at the discovered IAs and the instances of
API misuses, we found that around 60% of the violated IAs are
post-conditions, such as “Ownership of the passed parameter tm is
not transferred by these functions, so it must be freed up after the call.”
and “if an error occurs, PKCS7_sign_add_signers returns NULL”.
A hypothesis is that the developer tends to be less careful about
the post-conditions once an API has been invoked. Also we found
that the IAs of post-conditions or context conditions usually carry
5CWE defines a list of common software and hardware security weaknesses.
more than one CD, due to their relatively complicated grammar
structures, while IAs of pre-conditions are usually simple and often
used to constrain the input-value range.
5.5 Case study
Atril [3] is a multi-page document viewer for EPS, DVI, DJVU, XPS,
PDF file format. When running Atril 1.24.0 (the latest release), Ad-
vance reported an API misuse associated with a NULL dereference
bug, which can cause a DOS attack. The bug information from
AddressSanitiezer is shown in Appendix Listing 5. The vulnerable
function epub_document_check_hits is presented in Listing 2.
1 guint epub_document_check_hits (... , EvPage * page ,...) {
2
gchar * filepath = g_filename_from_uri (( gchar *) page ->
htmlDocPtr htmldoc =
backend_page , NULL , NULL );
3
4 + if (! htmldoc ) error_handle () ;
5
6 + if (! htmltag ) error_handle () ;
7
8
xmlParseFile ( filepath );
htmlNodePtr htmltag = xmlDocGetRootElement ( htmldoc );
htmlNodePtr bodytag = htmltag -> xmlChildrenNode ;
...
Listing 2: An libxml2 API misuse in Atril.
Specifically, epub_document_check_hits is a function used to
count the number of target strings on a page when searching on
the epub format documents. On the line 3, htmldoc is assigned
with the return value of xmlParseFile(filepath). According to
the documentation, xmlParseFile returns NULL in some con-
dition (e.g., when filepath is non-existent) and thus htmldoc
needs to be checked in default which, however, has not been fol-
lowed by Atril. Note that no matter what arguments are passed
to g_filename_from_uri, filepath is NULL, if the file associated
with filepath does not exist, Further, Atril passes htmldoc to
xmlDocGetRootElement to obtain the root element of the html file.
Similar to xmlParseFile, xmlDocGetRootElement returns NULL
when there is no root element (e.g., when htmldoc is NULL). Hence,
htmltag also needs to be checked in default. The violation of
these two IAs in the document results in a NULL dereference
bug when dereferencing htmltag at line 7. To trigger this bug,
we set the filepath to be an non-existent path. After manually
analyzing the source code, we found that filepath is a file cre-
ated by Atril and it does not check whether the file related to
filepath exists when using. Thus, deleting the file related to
filepath after being created will trigger the bug. In summary,
this bug is caused by the unchecked return value of xmlParseFile
and xmlDocGetRootElement, which is required in the documents
in default. It can be triggered through deleting the file filepath
by another attack process.
OpenSSLSQLitelibpcaplibdbuslibxml2Average0.00.20.40.60.8Accuracy(a)OpenSSLSQLitelibpcaplibdbuslibxml2Average0.00.20.40.60.8F1(b)OpenSSLSQLitelibpcaplibdbuslibxml2Average0.00.10.20.30.40.50.60.70.8FPR(c)OpenSSLSQLitelibpcaplibdbuslibxml2Average0.00.20.40.60.8FNR(d)S-HANKeywordsALICSOpenSSLSQLitelibpcaplibdbuslibxml2Average0.600.650.700.750.800.850.900.951.00Accuracy(a)S-HANRCNNText-CNNOpenSSLSQLitelibpcaplibdbuslibxml2Average0.00.20.40.60.81.0FNR(b)AdvancetCommentToradocuJdoctorUsing Advance, we first discovered the IAs “xmlParseFile returns
the resulting document tree if the file was wellformed, NULL otherwise”
and “xmlDocGetRootElement returns the #xmlNodePtr for the root or
NULL” through S-HAN. Both of them only match the CD “return”,
whose VCS is shown in Listing 46 in Appendix. With only one
matched CD, that VCS becomes the corresponding VC as the input
of CodeQL to discover API misuse. In Listing 4, Line 1 imports
the CodeQL modules like Python. The grammars of Line 2-5 are
similar to database query language (e.g., MySQL). They query the
function invocation xmlDocGetRootElement that has not checked
the returned NULL value and then print the invocation location (i.e.,
API misuse location).
6 Discussion
With its higher precision than all existing approaches, still Advance
introduces false positives and misses some API misuses. These
problems mostly come from the limitations of the tools underlying
our implementation and unusual IA descriptions present in library
documentation. Specifically, CodeQL and the NLP tools (such as
StanfordNLP [38]) used in our prototype are imperfect, and their
accuracy affects the outcome of our analysis. For example, Cod-
eQL cannot effectively handle complicated data-flow analysis like
tracking tainted data across a structure, which leads to a report
of false API misuses (Section 5.2). Also, even state-of-the-art NLP
techniques cannot effectively handle grammatical errors and am-
biguous descriptions, which are widely present in real-world library
documentations.
In addition, our approach required an off-line, one-time effort to
translate popular CDs to VCS (Section 3.4). We acknowledge that
our current template-based approach fails to capture the CDs with
low frequency, such as “must be inside an array-typed value”, which