similar assumptions on the ability to distinguish abnormality
from normalcy using provenance graphs.
StreamSpot. StreamSpot [48] detects host-system intrusions
based on information ﬂow graphs. Similar to Frappuccino,
it leverages a clustering-based approach using a similarity
function that compares two graphs based on their statistics. It
represents each graph as a vector of local substructure frequen-
cies and further approximates the vector using a similarity-
preserving hashing scheme. The hashing scheme reduces the
dimensionality of the vector while preserving discriminatory,
principal features that better generalize the learned model.
2352    30th USENIX Security Symposium
USENIX Association
Since StreamSpot claims to detect any anomalies on the host
system, we expect it to identify abnormal installation activity.
Experimental Results. Table 5 shows the overall results for
all the baseline systems. For StreamSpot and Frappuccino, we
use the same experimental setups as described in their respec-
tive papers or as implemented in their publicly available code
repositories. We notice that StreamSpot’s original implemen-
tation analyzes only small local substructures in the graph.
Such a constrained graph exploration tends to make graphs
look overly similar to each other, thus resulting in high FNs
and low true positives (TPs). We reimplement StreamSpot to
analyze larger graph neighborhoods. We show the reimple-
mentation results (i.e., better performance) in Table 5.
We see from Table 5 that SIGL signiﬁcantly outperforms
all baseline systems in terms of recall, accuracy, and F-score.
It reported only 42 FPs among over 1,000 software installa-
tions in three months. On the contrary, the commercial TDS
produces an overwhelmingly large number of FPs (9,240
events are considered potential threats during the experiment),
resulting in exceedingly low precision 2. The commercial
TDS results are consistent with a recent study that shows that
many enterprises receive at least 300 alerts per day with more
than 50% being FPs [21]. StreamSpot marginally outperforms
SIGL in precision by only 3%, at the expense of a much lower
recall (by 47%). A low recall is typically a product of low TPs
and high FNs. Both StreamSpot and Frappuccino suffer from
low recall because they have limited graph analytical capabil-
ity. They use a vertex-centric approach to explore local graph
neighborhoods, but such exploration ignores temporal rela-
tionships among those substructures and provides only limited
views of graph evolution. As a result, they are unable to dis-
tinguish malicious installers from benign ones, producing few
FPs (i.e., higher precision) but many FNs (i.e., lower recall).
Although SIGL reports slightly more FPs, we show in § 5.5
that it provides auxiliary information that allows rapid inspec-
tion and dismissal of FPs, which is absent in both StreamSpot
and Frappuccino. Reducing FPs from the hundreds per day
of a typical commercial TDS [21] to fewer than one per day
is a signiﬁcant step at mitigating “alert fatigue” [31]. Exist-
ing techniques, such as whitelisting trusted processes during
backtracking, can further reduce these FPs. The performance
of our StreamSpot reimplementation demonstrates the impor-
tance of incorporating structural information in the analysis.
StreamSpot outperformed Frappuccino, because Frappuccino
is unable to retain just the relevant information; it overgener-
alizes its model with “noise” in the dataset.
SIGL beneﬁts from three important features of graph
neural networks. First, they effectively ﬁlter noise. SIGL
learns to capture relevant information during training, a data-
2The commercial TDS’s performance values are computed on a per-event
basis, rather than a per-graph basis, because it has no notion of causality.
To understand an alarm, however, system administrators typically resort to
causal analysis, which requires them to inspect benign events in addition to
the alarm-triggering event.
s
r
e
l
l
a
t
s
n
i
s
u
o
i
c
i
l
a
m
f
o
%
1
0.8
0.6
0.4
0.2
0
FileZilla
FireFox
P W Safe
M P3Gain
ShotCut
Team Viewer
Foobar
7Zip
TurboV NC
WinMerge
Launchy
DropBox
WinRAR
Skype
Slack
OneDrive
AV Remover
NotePad++
ICBC
Flash
Basic Guidance
Targeted Guidance
Figure 3: Prioritization of anomalous processes.
Improved Guidance
oriented approach different from the hashing technique used
in StreamSpot. Second, they preserve long-term memory.
SIGL memorizes the sequential procedure of a software in-
stallation and uses this long-term memory to determine the
legitimacy of a process during different stages of the instal-
lation. StreamSpot and Frappuccino consider only “bag-of-
subgraphs” when analyzing provenance graphs. Third, they
consider non-linear encoding of graph structures. Graph struc-
tures are contexts that help distinguish normal and abnormal
process nodes. SIGL learns graph structure via its unique neu-
ral network architecture, while the commercial TDS isolates
each event from its broader execution context.
5.5 Prioritizing Anomalous Processes
Many existing provenance-based detection systems [28,
48, 61] lack support for postmortem attack investigation, be-
cause their contextual analysis typically requires a holistic
understanding of a large provenance (sub)graph. It is there-
fore difﬁcult to pinpoint the exact nodes/edges responsible
when a decision is made based on the entire (sub)graph. Oth-
ers [31, 33, 56] instead focus on using data provenance to
correlate alerts from simple edge-based detection systems
(e.g., commercial TDS) to reduce false alarms and provide
attack attribution. However, they depend on the underlying
threat detection system to reliably report all possible threats,
assuming a 100% detection rate [31]. SIGL conducts con-
textual graph analysis to maintain high detection accuracy.
We show in Fig. 3 that it also assists attack attribution by
accurately identifying anomalous processes within the graph.
We consider three levels of attribution that provide cyber-
analysts with increasing degrees of guidance. We call the
malware process (and its associated ﬁle) the target and the
ranked list generated by SIGL based on processes’ anomaly
scores the list. Note that SIGL assigns every process and
its versions (§ 4.2) an anomaly score. If SIGL identiﬁes a
process among the top 10 in the list that is fewer than 3
hops away from the target (Fig. 3, checks), we consider SIGL
successfully having provided basic guidance. If the process
USENIX Association
30th USENIX Security Symposium    2353
is ranked among the top 5 and is less than or equal to 3 hops
away (Fig. 3, stripes), SIGL has provided improved guidance.
Finally, if SIGL identiﬁes the target among the top 5 in the
list or the target is only 1 hop away from a top-5 process
(Fig. 3, solid), we say that SIGL offered targeted guidance.
These three levels of guidance are based on typical behavior
of system administrators, trying to understand the sequence
of steps that produced an attack [43], and the value (e.g., time
savings) that SIGL brings to the human analysts.
Fig. 3 shows that SIGL is able to provide at least basic guid-
ance to identify almost all malicious processes or ﬁles for
all software installers in the experiment. In fact, it provides
targeted guidance for at least 10% of malicious installers in
all cases and more than 50% of them in the majority (75%) of
the cases. We investigate two speciﬁc examples, Foobar and
OneDrive, as they have distinctive results. SIGL has difﬁculty
providing effective guidance for about half of the malicious
Foobar installers. We inspected the SIGs of those installers
manually and discovered that SIGL identiﬁes many versions
of a process that originally connects to the malware ﬁle as
the most anomalous. It is likely that anomaly scores “accu-
mulate” as later versions of the process are being analyzed.
Concrete investigation of how provenance graph versioning
affects graph analysis is left for future work.
SIGL is not able to provide targeted guidance for OneDrive,
because OneDrive frequently identiﬁes the update processes
in the SIG as among the most anomalous. As mentioned
in § 5.3, a small number of OneDrive training SIGs include
both installation and update processes. SIGL cannot accu-
rately learn update behavior from only a small number of
samples and therefore incurs high reconstruction losses for
those processes. The same situation is less severe in Fire-
Fox, because the update process occurs more frequently in its
training data. However, it does result in lower recall (Table 6)
as the FireFox model attempts to generalize both behaviors
using a small number of training samples.
Overall, SIGL can effectively guide cyber-analysts to
quickly identify abnormal processes and potential malware.
Neither StreamSpot nor Frappuccino provides any guidance.
5.6 Using SIGL in an Enterprise
In an enterprise environment, system administrators con-
ﬁgure workstations to include a standard set of installations.
When there is a new software release, the installed software
needs to be updated. This can lead to a supply-chain-attack
scenario, where the attacker exploits a vulnerability in the
new release by compromising the software distribution chan-
nel, so no legitimate version of the new release is available.
Therefore, we investigate how well SIGL models generalize
across versions, given that administrators’ only defense is the
model from the previous version of the software installation.
Experimental Setup. We installed an adjacent version of
the software listed in Table 2. In some cases, our modeled
software was already the latest release (at the time of writing);
False Alarm
True Alarm
Guidance
Software Installer
FireFox
FileZilla
PWSafe
MP3Gain
ShotCut
TeamViewer
Foobar
7Zip
TurboVNC
WinMerge
Launchy
Skype
WinRAR
DropBox
Slack
Flash
OneDrive
NotePad++
ICBC Anti-Phishing
ESET AV Remover
Modeled Version
18.1.0
3.35.1
3.48.0
1.2.5
18.12.23
14.4.2669
1.4.6
18.5.0
2.1.2
2.14.0
2.5
8.50.0
5.71.0
79.4.143
4.0.1
32.0.0.223
19.103.527
7.7.1
1.0.8
1.4.1
Test Version
19.0.1
3.34.0
3.49.0
1.2.4
18.12.25
14.5.1691
1.5
19.0.0
2.2.2
2.13.22
2.6
8.51.0
5.61.0
69.4.102
4.0.2
32.0.0.238
19.086.502
7.7.0
N/A
1.3.2


















N/A

: Improved Guidance


















N/A

N/A
: Targeted Guidance
: Basic Guidance
Table 7: Results when testing an adjacent software version on a model.
in those cases, we installed its previous version instead. To
create malicious installers, we bundle each software installer
with a random malware in Table 4. Table 7 lists the versions
of the software we use in this experiment. Note that ICBC
Anti-Phishing has only one version.
Experimental Results. Table 7 shows the results for each
installer modeled in § 5.3. We run only one benign and one
malicious instance against each model. If SIGL considers a
benign installer abnormal, we put a check mark () in the
False Alarm column in Table 7; we check the True Alarm
column if SIGL correctly detects a malicious installer. We
see in Table 7 that SIGL continues to maintain high precision
and recall across versions. Among the 19 benign installers,
SIGL correctly classiﬁes 16 of them (84%) without raising
a false positive alarm. False alerts in our experiments are
caused by signiﬁcant changes in graph structures (correspond-
ing to changes in installation behavior) and node identities
(corresponding to changes in ﬁles installed) between two ver-
sions. For example, Dropbox’s installation behavior changed
across the two versions. We observe that the older version
of the Dropbox installer frequently reads from and executes
a temporary ﬁle during the installation process. This behav-
ior creates a large subgraph in the SIG between the ﬁle and
the process that is absent in the training dataset. We quickly
identify this difference following the guidance provided by
SIGL. In § 7, we further discuss this issue regarding software
evolution. In terms of true alerts, SIGL detects all malicious
installers with the majority (74%) having targeted guidance.
5.7 Sensitivity Analysis
Anomaly-based detection systems [11] typically require
setting threshold values representing how much of a deviation
from normality constitutes an anomaly. Thresholds determine
the tradeoffs between precision and recall. Detection systems
that are overly sensitive to threshold settings are difﬁcult to
use in practice, even if there exists an optimal threshold that
performs perfect detection.
SIGL quantiﬁes a normality threshold from the validation
dataset based on the anomaly scores of individual nodes in
the graph (§ 4.5). We demonstrate in Fig. 4 that the anomaly
scores of benign and malicious graphs are well-separated with
2354    30th USENIX Security Symposium
USENIX Association
AVRemover
ICBC
NotePad++
OneDrive
Flash
Slack
DropBox
WinRAR
Skype
Launchy
WinMerge
TurboVNC
7Zip
Foobar
TeamViewer
ShotCut
MP3Gain
PWSafe
FileZilla
FireFox
10−7
10−6
10−5
: Benign Installer
10−4
10−3