title:Evaluating the Contextual Integrity of Privacy Regulation: Parents'
IoT Toy Privacy Norms Versus COPPA
author:Noah J. Apthorpe and
Sarah Varghese and
Nick Feamster
Evaluating the Contextual Integrity of 
Privacy Regulation: Parents’ IoT Toy Privacy 
Norms Versus COPPA
Noah Apthorpe, Sarah Varghese, and Nick Feamster, Princeton University
https://www.usenix.org/conference/usenixsecurity19/presentation/apthorpe
This paper is included in the Proceedings of the 28th USENIX Security Symposium.August 14–16, 2019 • Santa Clara, CA, USA978-1-939133-06-9Open access to the Proceedings of the 28th USENIX Security Symposium is sponsored by USENIX.Evaluating the Contextual Integrity of Privacy Regulation:
Parents’ IoT Toy Privacy Norms Versus COPPA
Noah Apthorpe
Princeton University
Sarah Varghese
Princeton University
Nick Feamster
Princeton University
Abstract
Increased concern about data privacy has prompted new and
updated data protection regulations worldwide. However,
there has been no rigorous way to test whether the practices
mandated by these regulations actually align with the privacy
norms of affected populations. Here, we demonstrate that
surveys based on the theory of contextual integrity provide
a quantiﬁable and scalable method for measuring the con-
formity of speciﬁc regulatory provisions to privacy norms.
We apply this method to the U.S. Children’s Online Privacy
Protection Act (COPPA), surveying 195 parents and provid-
ing the ﬁrst data that COPPA’s mandates generally align with
parents’ privacy expectations for Internet-connected “smart”
children’s toys. Nevertheless, variations in the acceptabil-
ity of data collection across speciﬁc smart toys, informa-
tion types, parent ages, and other conditions emphasize the
importance of detailed contextual factors to privacy norms,
which may not be adequately captured by COPPA.
1 Introduction
Data privacy protections in the United States are enforced
through a combination of state and federal legislation and
regulatory action.
In Europe, the General Data Protection
Regulation (GDPR) is currently the best example of strong,
centralized privacy legislation. The GDPR has inspired sim-
ilar laws in other countries, such as the Brazilian General
Data Privacy Law. According to the United Nations Confer-
ence on Trade and Development [51], 57% of countries have
data protection and privacy legislation as of 2018.
Although data privacy protections vary across countries
in terms of details and implementation, many share a com-
mon provenance: public pressure to protect sensitive per-
sonal data from unauthorized use or release. Surveys report
that consumers worldwide were more concerned about on-
line privacy in 2016 than 2014 [7] and that over 60% of U.S.
survey respondents in 2018 are concerned about data privacy
in general [34]. However, there has been no rigorous, quan-
tiﬁable, and scalable way to measure whether existing legal
privacy protections actually match the privacy expectations
of affected individuals. Without such data, it is difﬁcult to
know which aspects of privacy regulation effectively align
company behaviors with social and cultural privacy norms
and which necessitate further revision.
In this paper, we demonstrate that an existing survey tech-
nique [3] based on the formal privacy theory of contextual
integrity (CI) [32] can be directly adapted to test the confor-
mity of speciﬁc regulatory requirements to privacy norms,
providing much-needed data to policymakers and the pri-
vacy research community. The survey technique can be ap-
plied to any privacy regulation that deﬁnes guidelines for
data collection and transfer practices. Importantly, the sur-
vey technique involves questions describing privacy scenar-
ios that are concrete and understandable to respondents from
all backgrounds. It also allows straightforward longitudinal
and cross-sector measurements to track the effectiveness of
regulatory updates over time.
We present a rigorous case study of this technique eval-
uating the U.S. Children’s Online Privacy Protection Act
(COPPA), which provides a federal legal framework to pro-
tect the online privacy of children under the age of 13.
Speciﬁcally, we investigate whether parents’ opinions about
the acceptability of data collection practices by Internet-
connected “smart” children’s toys match COPPA mandates.
Since the Federal Trade Commission (FTC) only updated its
guidance on COPPA to explicitly include “connected toys or
other Internet of Things devices” in June 2017 [16], our re-
sults provide the ﬁrst indication as to whether COPPA aligns
with parents’ privacy expectations.
This question is particularly relevant given the recent high-
proﬁle security breaches of smart toys, ranging from the theft
of personal information of over 6 million children from toy
manufacturer VTech to vulnerabilities in Mattel’s Hello Bar-
bie [13]. More recently, Germany banned children’s smart
watches and Genesis Toys’ My Friend Cayla doll, citing se-
curity risks and “spying concerns” [17, 31].
We survey a panel of 195 U.S. parents of children from
USENIX Association
28th USENIX Security Symposium    123
ages 3 to 13, the largest sample size for a study of parent
opinions of smart toy data collection in the literature to date.
We ﬁnd that parents generally view information collection
predicated on requirements speciﬁed by COPPA (e.g., “if the
information is used to protect a child’s safety”) as accept-
able, while viewing equivalent information collection with-
out COPPA-speciﬁed conditions as unacceptable. This indi-
cates that the existing conditions COPPA places on informa-
tion collection by smart toys are generally in line with par-
ents’ privacy norms, although there may be additional data
collection requirements which could be added to regulation
that were not tested in our study.
Additionally, we ﬁnd that COPPA requirements for notiﬁ-
cation and consent result in more acceptable data collection
practices than requirements related to conﬁdentiality and se-
curity. This corroborates previous work indicating the pri-
mary importance of consent to user privacy norms [3]. We
also ﬁnd variations in the acceptability of COPPA-permitted
data collection practices across speciﬁc smart toys, types of
information, certain information use cases, parent ages, par-
ent familiarity with COPPA, and whether parents own smart
devices. These variations emphasize the importance of de-
tailed contextual factors to parents’ privacy norms and mo-
tivate additional studies of populations with privacy norms
that may be poorly represented by COPPA.
We conclude by noting that COPPA’s information collec-
tion criteria are broad enough to allow smart toy implementa-
tions that compromise children’s privacy while still adhering
to the letter of the law. Continuing reports of smart toys vio-
lating COPPA [6] also suggest that many non-compliant toys
remain available for purchase. Further improvements to both
data privacy regulation and enforcement are still needed to
keep pace with corporate practices, technological advance-
ments, and privacy norms.
In summary, this paper makes the following contributions:
• Demonstrates that an existing survey method [3] based
on contextual
integrity [32] can be applied to test
whether privacy regulations effectively match the norms
of affected populations.
• Provides the ﬁrst quantitative evidence that COPPA’s re-
strictions on smart toy data collection generally align
with parents’ privacy expectations.
• Serves as a template for future work using contextual
integrity surveys to analyze current or proposed privacy
regulation for policy or systems design insights.
2 Background & Related Work
In this section, we place our work in the context of related
research on contextual integrity, COPPA, and smart toys.
2.1 Contextual Integrity
The theory of contextual integrity (CI) provides a well-
established framework for studying privacy norms and ex-
pectations [32]. Contextual integrity deﬁnes privacy as the
appropriateness of information ﬂows based on social or cul-
tural norms in speciﬁc contexts. CI describes information
ﬂows using ﬁve parameters: (1) the subject of the informa-
tion being transferred, (2) the sender of this information,
(3) the attribute or type of information, (4) the recipient of
the information, and (5) the transmission principle or condi-
tion imposed on the transfer of information from the sender
to the recipient. For example, one might be comfortable
with a search engine (recipient) collecting their (subject &
sender) Internet browsing history (attribute) in order to im-
prove search results (transmission principle), but not in or-
der to improve advertisement targeting, which is a different
transmission principle that places the information in a dif-
ferent context governed by different norms. Privacy norms
can therefore be inferred from the reported appropriateness
and acceptability of information ﬂows with varying combi-
nations of these ﬁve parameters.
Previous research has used CI to discover and analyze pri-
vacy norms in various contexts.
In 2012, Winter used CI
to design an interview study investigating Internet of things
(IoT) device practices that could be viewed as privacy viola-
tions [54].
In 2016, Martin and Nissenbaum conducted a survey with
vignette questions based on CI to understand discrepancies
between people’s stated privacy values and their actions in
online spaces [27]. Rather than straightforward contradic-
tions, they ﬁnd that these discrepancies are due to nuanced
effects of contextual information informing real-world ac-
tions. This result motivates the use of CI in our study and
others to investigate privacy norms in realistic situations.
In 2016, Shvartzshnaider et al. used the language of CI to
survey crowdworkers’ privacy expectations regarding infor-
mation ﬂow in the education domain [46]. Survey respon-
dents indicated whether information ﬂows situated in clearly
deﬁned contexts violated acceptability norms. The results
were converted into a logic speciﬁcation language which
could be used to verify privacy norm consistency and iden-
tify additional acceptable information ﬂows.
In 2018, we designed a scalable survey method for discov-
ering privacy norms using questions based on CI [3]. We ap-
plied the survey method to measure the acceptability of 3,840
information ﬂows involving common connected devices for
consumer homes. Results from 1,731 Amazon Mechanical
Turk respondents informed recommendations for IoT device
manufacturers, policymakers, and regulators.
This paper adapts the survey method from our previous
work [3] for a speciﬁc application: comparing privacy norms
to privacy regulation. Our use of language from regula-
tion in CI survey questions, direct comparison of discov-
124    28th USENIX Security Symposium
USENIX Association
ered privacy norms to policy compliance plans, and survey
panel of special interest individuals (parents of children un-
der age 13) distinguishes our work from previous uses of the
survey method and previous CI studies in general.
2.2 COPPA & Smart Toys
Previous research has investigated Internet-connected toys
and COPPA from various perspectives. Several studies have
focused on identifying privacy and/or security vulnerabili-
ties of speciﬁc smart toys [45, 48, 53], some of which are
expressly noted as COPPA violations [6]. Our work uses
these examples to inform the information ﬂow descriptions
included on our survey.
Researchers have also developed methods to automate the
detection of COPPA violations. In 2017, Zimmeck et al. au-
tomatically analyzed 9,050 mobile application privacy poli-
cies and found that only 36% contained statements on user
access, editing, and deletion rights required by COPPA [59].
In 2018, Reyes et al. automatically analyzed 5,855 Android
applications designed for children and found that a majority
potentially violated COPPA [43]. Most violations were due
to collection of personally identiﬁable information or other
identiﬁers via third-party software development kits (SDKs)
used by the applications, often in violation of SDK terms of
service. These widespread violations indicate that COPPA
remains insufﬁciently enforced. Nevertheless, COPPA re-
mains the primary legal foundation for state [30] and fed-
eral [12] action against IoT toy manufacturers and other tech-
nology companies for children’s privacy breaches.
Additional work has investigated parents’ and chil-
dren’s relationships with Internet-connected toys. In 2015,
Manches et al. conducted observational ﬁeldwork of children
playing with Internet-connect toys and held in-school work-
shops to investigate parents’ and children’s cognizance of
how IoT toys work [26]. They found that most children and
caregivers were unaware of IoT toys’ data collection poten-
tial, but quickly learned fundamental concepts of connected
toy design when instructed.
In 2017, McReynolds et al. conducted interviews with par-
ents and children to understand their mental models of and
experience with Internet-connected toys [28]. Parents in this
study were more aware of and concerned about IoT toy pri-
vacy than in [26], likely due to the intervening two years of
negative publicity about connected toy privacy issues. The
parents interviewed by McReynolds et al. provided feedback
about desired privacy properties for connected toys, such as
improved parental controls and recording indicators. The re-
searchers urge ongoing enforcement of COPPA, but do not
evaluate the parents’ responses in light of the law.
Our work builds on past research by obtaining opinions
about smart toy information collection and transfer practices
from a much larger pool of parents (195 subjects). We use
these data to evaluate whether privacy protections mandated
by COPPA align with parents’ privacy norms.
3 CI Survey Method
This study adapts a CI-based survey method ﬁrst presented
in our previous work [3] to evaluate whether speciﬁc require-
ments in privacy regulations align with user privacy norms.
We chose this particular survey method because it is previ-
ously tested, scalable to large respondent populations, and
easily adaptable to speciﬁc domains. The survey method
works as follows, with our modiﬁcations for regulation anal-
ysis marked in italics:
1. Information transfers (“ﬂows”) are deﬁned according to
CI as sets of ﬁve parameters: subject, sender, attribute,
recipient, and transmission principle (described in Sec-
tion 2.1).
2. We select lists of values for each of these parameters
drawn from or directly relevant to a particular piece of
privacy regulation. Using these values, we generate a
combinatorial number of information ﬂow descriptions
allowed or disallowed by the regulation.
3. Survey respondents rate the acceptability of these infor-
mation ﬂows, each of which describe a concrete data
collection scenario in an understandable context.
4. Comparing the average acceptability of ﬂows allowed
or disallowed by the regulation indicates how well they
align with respondents’ privacy norms.
5. Variations in acceptability contingent upon speciﬁc in-
formation ﬂow parameters or respondent demographics
can reveal nuances in privacy norms that may or may
not be well served by the regulation.
The following sections provide detailed descriptions of our
survey design (Sections 3.1–3.2), deployment (Section 3.3),
and results analysis (Section 3.4) for comparing parents’ pri-
vacy norms about smart toy data collection against COPPA
regulation. Many of these steps mirror those in our previous
work [3], but we include them here with speciﬁc details from
this study for the sake of replicability.
3.1 Generating Smart Toy Information Flows
We ﬁrst selected CI information ﬂow parameters (Table 1)
involving smart toys and speciﬁc data collection require-
ments from COPPA. We then programmatically generated
information ﬂow descriptions from all possible combinations
of the selected CI parameters.
We next discarded certain information ﬂow descriptions
with unrealistic sender/attribute pairs, such as a toy speaker
(sender) recording a child’s heart rate (attribute). Unrealis-
tic sender/attribute pairs were identiﬁed at the authors’ dis-
cretion based on whether each toy could reasonably be ex-
pected to have access to each type of data during normal use.
This decision was informed by smart toy products currently
available on the market. The use of exclusions to remove
USENIX Association
28th USENIX Security Symposium    125