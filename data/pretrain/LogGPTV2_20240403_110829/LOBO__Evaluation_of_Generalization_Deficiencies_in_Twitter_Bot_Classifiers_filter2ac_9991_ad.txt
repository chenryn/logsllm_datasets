results. In the second step, again, we randomly choose X Bursty
bots from the test data, and move them to the training data. And
so on. The test nishes at the 9th step when both the test data and
the training data contain about 250 Bursty bots. The step sizes are
xed at 0,2,4,8,16,32,64,128 and 256 (basically it is a 2x scale but we
traded the rst step for zero bots which matches LOBO test II).Note
that, this being a single C500 dataset, the dierence in accuracy
between the 0 bot case and LOBO test II is expected. We also use the
full 500 instances of each of the classes except the target, instead of
limiting to 70%.
144
Figure 3: Mean (Blue) and error range (blue shade 95% con-
dence) for the classier accuracy on target classes according
to the number of samples seen from the target class
Figure 4: Error range for mean (blue shade) and classier ac-
curacy against number of samples seen (for specic classes)
We repeat the above process 50 iterations, and then calculate
the average prediction accuracy at each step for the target class.
Repetition is needed because each of the times dierent bots from
the target class are being sent into the training set, and it aects
the overall accuracy dierently. Finally, we run the learning rate
test for each bot class in Table 6 as a target class. Detailed results
are shown in Table 7.
Figure 3 shows the average accuracy after X samples for all bot
classes that have been tested, with the shaded area representing the
95% condence interval. The overall trend would suggest that the
classier has learned to identify most target classes of bots after a
few examples. In contrast, Figure 4 shows that the performance for
dierent classes varies signicantly. It contains the same shaded
area as Figure 3 to show the stark dierences between the average
and the widely varying performance of each target class.
We can further notice bot class V (caught by honeypots) making
no reasonable improvement regardless of how many instances of it
has been shown to the classier. Finally, we can see some classes
that increase dramatically from 50 to 99% accuracy (bot class A) and
from 0-95% accuracy (bot class F), after only 16 and 32 instances,
respectively. This implies learning to identify the whole class while
training only on 6% of it.
LOBO – Evaluation of Generalization Deficiencies
in Twier Bot Classifiers
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Tgt.
Class
8
96.4
97.4
87.3
86.8
79.8
72.0
10.5
85.3
67.3
89.6
36.9
79.9
91.1
16
98.8
98.1
87.5
87.0
84.9
86.8
25.7
95.2
70.1
89.5
38.5
80.0
91.2
32
99.9
98.6
88.0
87.6
89.4
94.9
49.4
96.6
74.2
89.7
43.2
80.7
91.5
Number (X) of samples of target class in training data
256
0
100
59.4
A
99.8
97.4
B
86.7
92.9
C
90.6
86.7
D
95.9
64.9
E
98.3
0.8
F
1.7
81.6
H
99.5
4.0
K
95.3
64.2
M
91.0
89.9
T
69.6
33.7
U
80.0
84.3
V
93.0
W 90.9
Table 7: Classier accuracy (%) - trained C500 excluding all
but X samples of target class.
64
100
99.0
88.6
87.8
92.8
96.9
66.9
98.5
80.8
90.1
50.0
81.0
91.7
128
100
99.6
90.9
89.0
94.7
97.6
76.3
99.2
87.5
90.2
59.1
82.2
92.2
4
89.4
97.7
86.9
86.7
72.2
21.3
4.3
51.9
66.3
89.6
34.6
79.7
90.9
2
71.7
97.4
86.5
86.8
68.6
1.7
2.3
17.8
64.8
89.9
34.0
79.7
91.0
Notably, this section has shown the learning speeds for some
target classes is much higher than others. Improvements of over 20
accuracy percent points for the addition of 2 single instances are
seen in more than one class. Finally, dierent bot classes show vari-
ous degrees of improvement. Some of the target classes, worryingly,
show almost no improvement at all.
(a) Star Wars Bots and Bursty Bots
7.3 TSNE plot
In an eort to further understand why some of these bot classes
seem easier to predict than others, we’ve created a t-distributed
stochastic neighbor embedding (TSNE) plot [38] with the dataset
with class size  30k. This is a dimensionality reduction algorithm
that is also helpful to visualize high dimension datasets in two
dimension plots. In Figure 5a it is clearly shown that there are
clusters readily formed by dierent bot classes, where each one is
plotted in a dierent colour, and users are always in black.
Figure 5a emphasizes the Star Wars bots and the Bursty bots,
which show clear cut groups and clusters that are rarely mixed
with the real users.
In contrast, Figure 5b tells a dierent tale. We can see the honey-
pot bots (dataset B) mostly sharing the same "strands" with the real
users. These bots are the ones the LOBO test showed to be dicult
to classify, so it is no surprise that they look similar to our user
dataset.
8 DISCUSSION
8.1 Accuracy and Generalization
The average accuracy on target classes was very similar in LOBO
tests I and II. Even after accounting for the fact that the LOBO test
I accuracies on target classes might be aected by chance (since it
was not repeated 100 times) it is interesting to see that both tests
have almost the exact same accuracy on target bot classes.
8.2 Improvements with small data additions
There is a silver lining that is clearly noticeable in this evaluation.
Apparently, it does not matter how much data of a bot class is added
145
(b) HoneyPot Bots
Figure 5: T-SNE plot of all the bot classes against real users
with emphasis on Star Wars bots and Bursty users (a) and
Bad performing bots (b).
in proportion to the dataset size, improvement in performance
follows.
However, there is one more important fact. In the LOBO test
II, we are testing the classier on the complete target class. This
means, potentially, that adding 500 bots to a simple classier allows
us to further detect the full botnet (in this case, 357,000 instances) at
over 99% accuracy up from 62%. If we further delve into the details,
we can see from the learning speed test that adding 16 samples gets
us to 99% accuracy on the Star Wars bots.
8.3 Scalability
While re-training a classier several times can be computationally
expensive, we have empirically shown that using a few examples
on a dataset with balanced bot classes yields similar and stable
results. Reducing the size of each bot class from several thousands
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Juan Echeverrï£¡a et al.
[13] G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes using social networks.
[14] V. Dave, S. Guha, and Y. Zhang. Measuring and Fingerprinting Click-Spam in Ad
WWW, 2017.
In NDSS. San Diego, CA, 2009.
Networks. In SIGCOMM, 2012.
to 500 decreases the needed resources signicantly. Resource-wise,
this specic implementation of the classiers used a relatively large
amount of storage capacity, mostly because we are analysing all
the tweets for each of the users. This ends up being several ter-
abytes of data. However, most, if not all, of the methodology can
be implemented in parallel. Collecting, parsing, sampling, training
(each) classier, and testing can easily be done in parallel.
The importance of this method goes beyond this, as it can readily
allow multiple bot classes to be plugged in as needed, provided there
are more than a few samples of them.
9 CONCLUSION
In this paper, we investigated the resilience of bot detection systems
on Twitter. We showed that these systems perform very well when
trained on homogeneous data, but that their performance drops
dramatically when they are tested on classes of bots that they have
not observed before. We also proposed a methodology to evaluate
how well we can expect any given classier to generalize on unseen
bot data. It uses dierent bot datasets or classes as a proxy for the
new and unseen classes. These unseen classes may be developed
in the future, but may also be already present but undetected. This
nding has important implications for our research eld, since it
shows that detection systems might not generalize very well, a
problem that becomes particularly important in the fast paced and
inherently adversarial world of social network abuse.
Acknowledgments. This project has received funding from the
European Union’s Horizon 2020 Research and Innovation program
under the Marie Skłodowska-Curie ENCASE project (Grant Agree-
ment No. 691025).
REFERENCES
[1] M. Abu Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multifaceted approach to
understanding the botnet phenomenon. In ACM IMC, 2006.
[2] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida. Detecting spammers on
twitter. In CEAS, volume 6, page 12, 2010.
[3] C. Besel, J. Echeverria, and S. Zhou. Full cycle analysis of a large-scale botnet
attack on twitter. In ASONAM, 2018.
[4] A. Bessi and E. Ferrara. Social bots distort the 2016 U.S. Presidential election
online discussion. First Monday, 21(11), 2016.
[5] Y. Boshmaf, D. Logothetis, G. Siganos, J. Lería, J. Lorenzo, M. Ripeanu, and
Integro: Leveraging victim prediction for robust fake account
K. Beznosov.
detection in osns. In NDSS, volume 15, 2015.
[6] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu. The socialbot network:
In Proceedings of the 27th Annual
when bots socialize for fame and money.
Computer Security Applications Conference, pages 93–102. ACM, 2011.
[7] Z. Cai and C. Jermaine. The latent community model for detecting sybil attacks
in social networks. In NDSS, 2012.
[8] Q. Cao, X. Yang, J. Yu, and C. Palow. Uncovering large groups of active malicious
accounts in online social networks. In CCS, 2014.
[9] N. Chavoshi, H. Hamooni, and A. Mueen. DeBot: Twitter Bot Detection via
Warped Correlation. In IEEE ICDM, pages 817–822, 2016.
[10] N. Chavoshi, H. Hamooni, and A. Mueen. Identifying Correlated Bots in Twitter.
In Social Informatics, Lecture Notes in Computer Science. Springer, Cham, 2016.
[11] S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, and M. Tesconi. Fame for sale:
Ecient detection of fake Twitter followers. Decision Support Systems, 2015.
[12] S. Cresci, R. Di Pietro, M. Petrocchi, A. Spognardi, and M. Tesconi. The Paradigm-
Shift of Social Spambots: Evidence, Theories, and Tools for the Arms Race. In
146
[15] C. A. Davis, O. Varol, E. Ferrara, A. Flammini, and F. Menczer. BotOrNot: A
System to Evaluate Social Bots. In WWW Companion, 2016.
[16] E. De Cristofaro, A. Friedman, G. Jourjon, M. A. Kaafar, and M. Z. Shaq. Paying
for likes?: Understanding facebook like fraud using honeypots. In ACM IMC,
2014.
[17] J. Echeverria, C. Besel, and S. Zhou. Discovery of the twitter bursty botnet. Data
[18] J. Echeverria and S. Zhou. Discovery, retrieval, and analysis of ’star wars’ botnet
Science for Cyber-Security, 2017.
in twitter. In ASONAM, 2017.
[19] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna. Compa: Detecting compromised
accounts on social networks. In NDSS, 2013.
[20] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y. Zhao. Detecting and character-
izing social spam campaigns. In ACM IMC, 2010.
[21] Z. Gilani, R. Farahbakhsh, G. Tyson, L. Wang, and J. Crowcroft. Of Bots and
Humans (on Twitter). In ASONAM, 2017.
[22] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @ spam: the underground on 140
characters or less. In ACM CCS, 2010.
[23] B. Hooi, H. A. Song, A. Beutel, N. Shah, K. Shin, and C. Faloutsos. Fraudar:
Bounding graph fraud in the face of camouage. In ACM KDD, 2016.
[24] M. Ikram, L. Onwuzurike, S. Farooqi, E. D. Cristofaro, A. Friedman, G. Jour-
jon, M. A. Kaafar, and M. Z. Shaq. Measuring, Characterizing, and Detecting
Facebook Like Farms. ACM TOPS, 20(4):13, 2017.
[25] K. Lee, B. D. Eo, and J. Caverlee. Seven Months with the Devils: A Long-Term
Study of Content Polluters on Twitter. In ICWSM, 2011.
[26] S. Lee and J. Kim. Warningbird: Detecting suspicious urls in twitter stream. In
[27] C. Liu, P. Gao, M. Wright, and P. Mittal. Exploiting temporal dynamics in sybil
NDSS, 2012.
defenses. In ACM CCS, 2015.
In ACSAC, 2010.
[28] S. Narang. Green Coee and Spam: Elaborate spam operation on Twitter uses
nearly 750,000 accounts. https://symc.ly/2Cp7CJ5, 2017.
[29] S. Nilizadeh, F. Labrèche, A. Sedighian, A. Zand, J. Fernandez, C. Kruegel,
G. Stringhini, and G. Vigna. Poised: Spotting twitter spam o the beaten paths.
In CCS, 2017.
[30] G. Stringhini, M. Egele, C. Kruegel, and G. Vigna. Poultry Markets: On the
Underground Economy of Twitter Followers. In WOSN, 2012.
[31] G. Stringhini, C. Kruegel, and G. Vigna. Detecting spammers on social networks.
[32] G. Stringhini, P. Mourlanne, G. Jacob, M. Egele, C. Kruegel, and G. Vigna. Evilco-
hort: detecting communities of malicious accounts on online services. In USENIX
Security Symposium, 2015.
[33] G. Stringhini, G. Wang, M. Egele, C. Kruegel, G. Vigna, H. Zheng, and B. Y. Zhao.
Follow the Green: Growth and Dynamics in Twitter Follower Markets. In ACM
IMC, 2013.
[34] V. S. Subrahmanian, A. Azaria, S. Durst, V. Kagan, A. Galstyan, K. Lerman, L. Zhu,
E. Ferrara, A. Flammini, and F. Menczer. The DARPA twitter bot challenge. IEEE
Computer, 49, 2016.
[35] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design and evaluation of a
real-time url spam ltering service. In IEEE S&P, 2011.
[36] K. Thomas, C. Grier, D. Song, and V. Paxson. Suspended accounts in retrospect:
an analysis of twitter spam. In ACM IMC, pages 243–258. ACM, 2011.
[37] K. Thomas, D. McCoy, C. Grier, A. Kolcz, and V. Paxson. Tracking Fraudulent
Accounts: The Role of the Underground Market in Twitter Spam and Abuse. In
Usenix Security, 2013.
[38] L. van der Maaten and G. Hinton. Visualizing data using t-SNE. Journal of
Machine Learning Research, 2008.
[39] G. Wang, T. Konolige, C. Wilson, X. Wang, H. Zheng, and B. Y. Zhao. You are how
you click: Clickstream analysis for sybil detection. In Usenix Security, volume 14,
2013.
[40] C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers’ Social
Networks for Fun and Prot. In WWW, 2012.
[41] C. Yang, R. C. Harkreader, and G. Gu. Die free or live hard? empirical evaluation
and new design for ghting evolving twitter spammers. In RAID, 2011.