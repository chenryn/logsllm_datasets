title:Throughput Prediction on 60 GHz Mobile Devices for High-Bandwidth,
Latency-Sensitive Applications
author:Shivang Aggarwal and
Zhaoning Kong and
Moinak Ghoshal and
Y. Charlie Hu and
Dimitrios Koutsonikolas
Throughput Prediction on 60 GHz
Mobile Devices for High-Bandwidth,
Latency-Sensitive Applications
Shivang Aggarwal1(B), Zhaoning Kong2, Moinak Ghoshal1, Y. Charlie Hu2,
and Dimitrios Koutsonikolas1
1 Northeastern University, Boston, USA
PI:EMAIL
2 Purdue University, West Lafayette, USA
Abstract. In the near future, high quality VR and video streaming at
4K/8K resolutions will require Gigabit throughput to maintain a high
user quality of experience (QoE). IEEE 802.11ad, which standardizes
the 14 GHz of unlicensed spectrum around 60 GHz, is a prime candidate
to fulﬁl these demands wirelessly. To maintain QoE, applications need
to adapt to the ever changing network conditions by performing quality
adaptation. A key component of quality adaptation is throughput pre-
diction. At 60 GHz, due to the much higher frequency, the throughput
can vary sharply due to blockage and mobility. Hence, the problem of
predicting throughput becomes quite challenging.
In this paper, we perform an extensive measurement study of the pre-
dictability of the network throughput of an 802.11ad WLAN in down-
loading data to an 802.11ad-enabled mobile device under varying mobil-
ity patterns and orientations of the mobile device. We show that, with
carefully designed neural networks, we can predict the throughput of the
60 GHz link with good accuracy at varying timescales, from 10 ms (suit-
able for VR) up to 2 s (suitable for ABR streaming). We further identify
the most important features that aﬀect the neural network prediction
accuracy to be past throughput and MCS.
1 Introduction
The past few years have witnessed the rise of a number of high-bandwidth,
latency-sensitive applications including virtual reality (VR), high-resolution
video streaming, live video streaming, and connected autonomous vehicles. Such
applications are characterized by stringent user-perceived quality of experience
(QoE) requirements, which in turn dictate high demand for the network perfor-
mance in terms of ultra high throughput and low latency. Further, such applica-
tions typically run on mobile devices, which require high network performance to
be supported wirelessly. For example, 8K resolution VR demands 1.2 Gbps [28] in
order to satisfy the 20 ms photon-to-motion latency, while live 4K video stream-
ing at 30 FPS demands 1.8 Gbps [16] for good user QoE.
c(cid:2) Springer Nature Switzerland AG 2021
O. Hohlfeld et al. (Eds.): PAM 2021, LNCS 12671, pp. 513–528, 2021.
https://doi.org/10.1007/978-3-030-72582-2_30
514
S. Aggarwal et al.
Such stringent demand for network performance could not be supported in
the past decade. However, the advent of mmWave technologies in recent years
has made such network performance within reach and holds the promise to
enable these demanding applications. For example, the IEEE 802.11ad WLAN
standard [20] governs the use of the unlicensed spectrum around 60 GHz and
supports 2 GHz wide channel to provide PHY data rates of up to 6.7 Gbps.
However, 60 GHz networks also come with higher dynamics due to their vastly
diﬀerent propagation characteristics compared to sub-6 GHz networks. In par-
ticular, due to the high attenuation loss at 60 GHz, directional communication is
needed, making the wireless link highly susceptible to human blockage and mobil-
ity [42,43]. Due to these challenges, a user watching a 360◦ video or playing a VR
game over a 60 GHz network may experience long periods of rebuﬀering/stalls
due to intervals of low to no connectivity [16,44,48]. For example, the user may
be moving around in such a way so as to face completely away from the AP and
thus self-block the link. For this reason, a 60 GHz WLAN often cannot be used
as a standalone technology to enable these high resolution applications, and the
legacy sub-6 GHz WiFi, which does not suﬀer from blockage and mobility, may
be required as a backup [16,42].
Fortunately, most of the network-demanding applications already have some
type of quality adaptation built-in, to deal with the network dynamics. For
example, adaptive bitrate (ABR) streaming has become a de facto mechanism
implemented in modern video streaming systems such as YouTube, backed by a
number of adaptive streaming standards introduced over the years [3,11,33,40].
In a nutshell, ABR streaming continuously monitors the network conditions and
adapts the content quality to optimize the QoE, which typically is a function of
the frame resolution, frame continuity, and rebuﬀering time. ABR streaming has
been applied in all the recent proposals for high-resolution 360◦ video stream-
ing [18,34,37] as well as live video streaming [16]. Similar adaptation techniques
have also been proposed for state-of-the-art mobile VR systems [26].
The very ﬁrst task of network adaptation in such network-demanding appli-
cations is the estimation of network conditions for the next time interval. For
example, in video streaming, most ABR systems estimate the throughput in the
next time interval and choose a video quality level based on the throughput esti-
mate and playback buﬀer occupancy [39,41], as both can aﬀect the QoE. More
recently, the use of deep learning (DL) to select the most appropriate quality
level has gained popularity [29,46] and ML-based ABR algorithms have been
shown to outperform traditional algorithms.
The unique characteristics of the 60 GHz links, however, make throughput
prediction in 60 GHz WLANs a much more challenging problem than in legacy
WLANs. Although throughput estimation/prediction has been studied in the
past in the context of sub-6 GHz WLANs [22,23,38] and cellular networks [27],
no previous work, to our best knowledge, has studied throughput prediction at
60 GHz networks. In this work, we carry out the ﬁrst measurement study of the
throughput predictability in 60 GHz WLANs using ML.
Throughput Prediction on 60 GHz Mobile Devices
515
There are two main challenges to conduct this measurement study. First,
in order to reliably train and test any ML model, we need to collect a sig-
niﬁcant amount of data. Since 60 GHz WLANs are not widely deployed (the
ﬁrst 802.11ad-enabled smartphone model was only launched in 2019), we cannot
collect data from real networks, as in previous ABR studies [29,46]. Further,
the only two phones that support 802.11ad, the ASUS ROG Phone [5] and the
ASUS ROG Phone II [6], are not VR Ready; hence, we cannot perform real
VR experiments with volunteers, as in previous VR studies [26,45]. Thus, we
need to develop a methodology to collect traces in a controlled environment
eﬃciently and in an automated way, in order to obtain a large amount of data
while covering a wide variety of realistic mobility patterns. To meet these con-
ﬂicting requirements, we mounted the 802.11ad phone on a programmable 3-axis
motion controller typically used by professional photographers. Using this setup,
we collected more than 100 h of traces while running diﬀerent applications under
random mobility patterns. Second, unlike in previous works, which make pre-
dictions only on coarse-grained timescales, e.g., in the order of a few seconds for
ABR video streaming [46,47], we study throughput prediction at timescales as
ﬁne as 10 ms, which are needed by some of the demanding applications such as
VR. To support throughput prediction at such ﬁne timescales, we need ML mod-
els that strike a good balance between being accurate as well as being lightweight
enough to run on mobile devices within such short timescales. To overcome this
challenge, we started with a neural network model previously shown to work well
at the 2-s timescale [46], and performed multiple iterations of grid search on the
two conﬁguration dimensions (number of layers and number of nodes) to ﬁnd
the smallest conﬁguration, beyond which the performance increase is marginal,
to derive a model conﬁguration that balances accuracy and inference latency.
We also considered a recurrent neural network (RNN) model, Long Short Term
Memory (LSTM), which is suitable for processing time series data, as is the
case with throughput prediction. We again went through conﬁguration search to
arrive at a cost-eﬀective LSTM model for our throughput prediction problem.
We then experimentally compared both models throughout our measurement
study.
In summary, our work makes the following contributions.
– We conducted the ﬁrst measurement study of the throughput predictability
of a 60 GHz WLAN to a mobile device. The dataset is publicly available [1].
– We tuned the parameters of state-of-the-art throughput-prediction DNNs to
strike a balance between prediction accuracy and lightweightness usable for
online throughput prediction. Our two models run in 0.41 ms and 4.02 ms on
the ASUS ROG Phone II and require less than 4 MB of memory.
– We found that TCP throughput prediction in static scenarios is highly accu-
rate for 40 to 2000 ms, with 95th percentile error ranging between 10.6% for
40 ms and 5.7% for 2 s. For 10–20 ms, the accuracy drops but still remains at
satisfactory levels.
516
S. Aggarwal et al.
– However, the accuracy drops in random mobility scenarios, typical of real
applications. The 95th percentile error increases to 38.1% for 10 ms and 19.4%
for 2 s timescales.
– We performed a feature selection study and found that only a few features
are important to make accurate throughput predictions. At timescales smaller
than 100 ms, past throughput is the most important, but for larger timescales,
MCS becomes more useful.
– Our study suggests that VR apps should be conservative in the use of through-
put prediction. In particular, at the 10 ms timescale the prediction error is
above 10% for 40% of the time, and the 95th percentile prediction error is
38%.
2 Experimental Methodology
Devices. We used a Netgear Nighthawk X10 Smart WiFi router [12] and an
ASUS ROG Phone II [6] for our measurements. The Netgear router has a 10-
Gigabit SFP+ Ethernet port, which we use to connect to a powerful desktop act-
ing as the server in our experiments. The ASUS ROG Phone II has an octa-core
Snapdragon 855 Plus processor with a maximum CPU frequency of 2.96 GHz,
a 6000 mAh battery, and an 8 GB RAM, and runs the Android OS 10. Both
devices support all 12 802.11ad single carrier MCSs, yielding theoretical data
rates up from 385 Mbps to 4.6 Gbps. However, similar to previous studies using
laptops as 802.11ad clients [16,35,36], the maximum TCP throughput is limited
to 1.65 Gbps in practical scenarios.
In
Experimental Setup and Trace Collection.
all our experiments, except for those with real appli-
cations in Sect. 3.4, we used nuttcp [13] with the
default CUBIC congestion control to generate back-
logged TCP traﬃc from the server to the phone
and logged throughput every 10 ms. We devel-
oped an Android app that
runs on the phone
and logs sensor and link state information. This
information is used as input in the ML models,
described in Sect. 2. Speciﬁcally, the app uses the
Android Sensor API [4] to log information from the
TYPE ROTATION VECTOR/TYPE GAME ROTATION VECTOR sensors, which report the
phone’s rotation angle in the azimuth and pitch dimensions (Fig. 1), and from
the accelerometer (TYPE ACCELEROMETER) sensor, which gives the acceleration of
the phone (in m/s2) on the x-, y-, and z-axis. Sensor data are logged every 10
ms. The app also logs 60 GHz link information reported by the wil6210 driver
on the phone every 20 ms. This includes the MCS used by the AP for data trans-
mission, link quality estimators (SQI, RSSI), the link status (OK, RETRYING,
FAILED), and the selected beamforming sectors.
Fig. 1. Mobility experi-
ments setup
Throughput Prediction on 60 GHz Mobile Devices
517
Since 60 GHz WLANs are not widely deployed, we cannot collect data from
real networks, as in previous ABR studies over the Internet [29,46]. In addi-
tion, our phone is not VR Ready and we cannot perform real VR experiments
with volunteers, as in previous VR studies [26,45]. Hence, we used the following
methodology to collect a large amount of data, while covering a wide variety
of realistic mobility patterns in a controlled environment eﬃciently and in an
automated way. For all our experiments, we kept the phone in a Google Card-
board [9] headset at a distance of 4 m from the AP, to emulate a realistic signal
propagation environment. For the experiments involving mobility, we mounted
the headset on a Cinetics Lynx 3-Axis Slider [7], used by professional photogra-
phers (Fig. 1). This setup enabled us to perform full 360◦ rotation in the azimuth
and pitch dimensions at a speed of up to 48◦/s and translational motion of up to
1 m. We used the Dragonframe software [8] to program custom mobility patterns
(e.g., emulating a user playing a VR game or watching a 360◦ video). Using this
methodology, we collected over 100 h of traces.
Trace Processing. Applications have diverse requirements on the timescale
of throughput prediction. For example, VR applications need to predict the
throughput in the window of the next tens of milliseconds. On the other end of
the spectrum, video streaming applications usually fetch video chunks of several
seconds in length and therefore need to predict the average throughput in the
window of the next few seconds. As such, we study the throughput predictability
over 802.11ad covering the full range of practical timescales, including timescales
of 10 ms, 20 ms, 40 ms, 100 ms, 400 ms, 1000 ms, and 2000 ms.
To support the above study of multiple timescales, we always log through-
put samples at the ﬁnest timescale, i.e., every 10 ms, and then oﬄine convert
the logged throughput into multiple coarser timescales, by combining consecu-
tive samples using their mean value. For example, to obtain 20 ms traces, every
2 adjacent data points are combined. For all other features, which consist of
categorical values, and are not meaningful when averaged, we consider the last
data point in each window. In addition, the last value in the window can more
accurately reﬂect the up-to-date state of the feature. To make a consistent com-
parison of throughput predictability across diﬀerent timescales, we always use
the ﬁrst 15,000 data points for training, and the following 3,000 for testing.
Machine Learning-Based Prediction. Recent work has shown that simple
DNN can predict throughput well at the 2-s timescale [46]. We therefore focus
on a number of DNNs for making throughput predictions. In addition to pre-
diction accuracy, we also need the DNN to be lightweight so that it can be
used in even the most-latency sensitive applications, such as VR, when running
on mobile devices. We experimented with three neural networks. For each net-
work, we performed multiple iterations of grid search on the two conﬁguration
dimensions (number of layers and number of nodes) to ﬁnd the smallest conﬁg-
uration, beyond which the performance increase is marginal, to derive a model
conﬁguration that balances accuracy and inference latency.
518
S. Aggarwal et al.
Fig. 2. Throughput at diﬀerent azimuth
angles.
Fig. 3. Throughput timeline within the
◦
FoV (0
) at diﬀerent timescales.
BP8 : a fully-connected neural network with 3 hidden layers, each of 40 neurons.
It takes as input the actual throughput in the past 8 windows, pose information
(azimuth and pitch) in the past 1 window, and link layer information (MCS,
transmit beamforming sector, link status, SQI, and RSSI) in the past 1 window.
RNN8 : a recurrent neural network with 3 hidden layers, each with 20 neurons.
It takes as input the actual throughput, pose information, and link layer infor-
mation in the past 8 windows.
RNN20 : same as RNN8, but takes information in the past 20 windows as input.
We also experimented with the BP8 model to take as input all information
in the past 8 windows like RNN8, but the results were very similar.
The neural network outputs the probability distribution (PD) of the through-
put in the current window Tt. The PD P1, ..., P21 is over 21 bins of throughput in
Mbps: B1 = [0, 50), ..., B21 = [1950, 2000]. We calculate the expected throughput
based on the PD as the prediction output:
T hroughput = 0 × P1 +
20(cid:2)
i=2
median(Bi) × Pi + 2000 × P21
(1)
Accuracy Metrics. We evaluate the performance of the throughput prediction
models in terms of 3 metrics: (i) RMSE: The root mean squared error between
the prediction and the actual throughput; (ii) ARE95 : The absolute relative
error of the prediction at the 95% percentile; and (iii) PARE10 : The percentage
of predictions with absolute relative error below 10%. To gain insight into which