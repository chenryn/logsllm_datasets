throughput by using the time between the start message and
the acknowledgment of the last message. We ensure that
the acknowledgment latency is negligible compared to the
overall experience time. We also perform the same experi-
ment but with only one sender and one message. Repeating
this experiment several times gives us the average latency
in the contention-free case.
)
s
m
(
y
c
n
e
t
a
L
600
500
400
300
200
100
0
0
10
20
30
40
50
60
70
80
90
Throughput (Mb/s)
Figure 7. Latency as a function of
throughput.
the
)
s
/
b
M
(
t
u
p
h
g
u
o
r
h
T
100
90
80
70
60
50
40
1
2
3
4
5
6
7
8
9
10
Number of processes
Figure 8. Throughput as a function of the
number of processes.
til the maximum throughput is reached. Then, unprocessed
messages are stored in local queues at each process, which
explains the important increase of the observed latency.
5.2 Latency Evaluation
5.3 Throughput Evaluation
Figure 6 plots the latency without contention as a func-
tion of the number of processes. The experiments consisted
in n-to-n TO-broadcasts of 100KB messages. The repre-
sented latency is the average of the latencies observed at
each sender. The graph shows that the latency is linear with
respect to the number of processes, which con(cid:2)rms the the-
oretical analysis.
Figure 7 plots the latency as a function of the through-
put. The experiments consisted in n-to-n TO-broadcasts of
100KB messages between 5 processes. The results were ob-
tained by throttling the senders to a given sending rate and
reporting the corresponding average latency and through-
put. This graph shows that the latency is almost constant un-
Figure 8 plots the maximum throughput as a function of
the number of processes. The experiments consisted in n-
to-n TO-broadcasts of 100KB messages. The graph shows
that FSR achieves a throughput of 79 Mbit/s on a 100 Mbit/s
switched Ethernet network. Moreover, it shows that the
achieved throughput is independent of the number of pro-
cesses in the ring, which con(cid:2)rms our analysis.
The last experiment consisted in varying the number of
senders in the ring. The experiment consisted in k-to-5 TO-
broadcasts (k ranging from 1 to 5) of 100KB messages. The
graph shows that the performance of FSR does not depend
on k. This means that FSR reaches the maximal throughput,
whichever the number of sender is.
/
)
s
b
M
(
t
u
p
h
g
u
o
r
h
T
100
90
80
70
60
50
40
1
2
3
4
5
Number of senders
Figure 9. Throughput as a function of the
number of senders.
6 Summary
This paper presents FSR, a uniform total order broad-
cast protocol that can be used at the main communication
block of a replication scheme to achieve software-based
fault-tolerance.
FSR is the (cid:2)rst uniform total order broadcast protocol
that consistently provides high throughput whether one or
several processes continuously TO-broadcast messages. In
short, high throughput captures the ability to deliver the
largest possible number of messages broadcast, regardless
of message broadcast patterns. This notion is precisely de-
(cid:2)ned in a round-based model of computation which cap-
tures message passing interaction patterns over clusters of
homogeneous machines interconnected by fully switched
LANs. We believe that the model is interesting in its own
right and can be used to evaluate the performance of other
protocols.
FSR is based on a ring topology, only relies on point-to-
point inter-process communication, and has linear latency
with respect to the number of processes. FSR is also fair
in the sense that each process has an equal opportunity of
having its messages delivered by all processes.
References
[1] Y. Amir, L. E. Moser, P. M. Melliar-Smith, D. A. Agarwal,
and P. Ciarfella. The Totem single-ring ordering and mem-
bership protocol. ACM Transactions on Computer Systems,
13(4):311(cid:150)342, 1995.
[2] E. Anceaume. A lightweight solution to uniform atomic
broadcast for asynchronous systems. In Proceedings of the
27th International Symposium on Fault-Tolerant Computing
(FTCS ’97), Washington, DC, USA, 1997. IEEE Computer
Society.
[3] S. Armstrong, A. Freier, and K. Marzullo. Multicast trans-
port protocol. RFC 1301, IETF, 1992.
[4] R. Baldoni, S. Cimmino, and C. Marchetti. A Classi(cid:2)cation
of Total Order Speci(cid:2)cations and its Application to Fixed
Sequencer-based Implementations. to appear in Journal of
Parallel and Distributed Computing, June 2006.
[5] A. Bar-Noy and S. Kipnis. Designing broadcasting algo-
rithms in the postal model for message-passing systems.
Mathematical Systems Theory, 27(5):431(cid:150)452, 1994.
[6] K. Birman and T. Joseph. Exploiting virtual synchrony in
distributed systems.
In Proceedings of the eleventh ACM
Symposium on Operating systems principles (SOSP’87),
pages 123(cid:150)138, New York, NY, USA, 1987. ACM Press.
[7] K. Birman and T. Joseph. Reliable communication in the
presence of failures. ACM Trans. Comput. Syst., 5(1):47(cid:150)
76, 1987.
[8] K. Birman and R. van Renesse. Reliable Distributed Com-
puting with the Isis Toolkit. IEEE Computer Society Press,
1993.
[9] R. Carr. The tandem global update protocol. Tandem Syst.
Rev. 1, pages 74(cid:150)85, jun 1985.
[10] T. Chandra and S. Toueg. Unreliable failure detectors for
reliable distributed systems. J. ACM, 43(2):225(cid:150)267, 1996.
[11] T. Chandra and S. Toueg. Unreliable failure detectors for
reliable distributed systems. Journal of the ACM, 43(2):225(cid:150)
267, 1996.
[12] J.-M. Chang and N. Maxemchuk. Reliable broadcast proto-
cols. ACM Trans. Comput. Syst., 2(3):251(cid:150)273, 1984.
[13] F. Cristian. Asynchronous atomic broadcast. IBM Technical
Disclosure Bulletin, 33(9):115(cid:150)116, 1991.
[14] F. Cristian, S. Mishra, and G. Alvarez. High-performance
asynchronous atomic broadcast. Distrib. Syst. Eng. J.,
4(2):109(cid:150)128, jun 1997.
[15] D. Culler, R. Karp, D. Patterson, A. Sahay, K. Schauser,
E. Santos, R. Subramonian, and T. von Eicken. LogP: To-
wards a realistic model of parallel computation. In Princi-
ples Practice of Parallel Programming, pages 1(cid:150)12, 1993.
[16] X. D·efago, A. Schiper, and P. Urb·an. Comparative perfor-
mance analysis of ordering strategies in atomic broadcast
algorithms. IEICE Trans. on Information and Systems, E86-
D(12):2698(cid:150)2709, 2003.
[17] X. D·efago, A. Schiper, and P. Urb·an. Total order broad-
cast and multicast algorithms: Taxonomy and survey. ACM
Comput. Surv., 36(4):372(cid:150)421, 2004.
[18] R. Ekwall, A. Schiper, and P. Urban. Token-based atomic
broadcast using unreliable failure detectors. In Proceedings
of the 23rd IEEE International Symposium on Reliable Dis-
tributed Systems (SRDS’04), pages 52(cid:150)65, Washington, DC,
USA, 2004. IEEE Computer Society.
[19] P. Ezhilchelvan, R. Macedo, and S. Shrivastava. Newtop: a
fault-tolerant group communication protocol.
In Proceed-
ings of the 15th International Conference on Distributed
Computing Systems (ICDCS’95), Washington, DC, USA,
1995. IEEE Computer Society.
[20] T. Friedman and R. V. Renesse. Packing messages as a tool
for boosting the performance of total ordering protocls. In
Proceedings of the 6th International Symposium on High
Performance Distributed Computing (HPDC ’97), Washing-
ton, DC, USA, 1997. IEEE Computer Society.
[21] U. Fritzke, P. Ingels, A. Mostefaoui, and M. Raynal.
Consensus-based fault-tolerant total order multicast. IEEE
Trans. Parallel Distrib. Syst., 12(2):147(cid:150)156, 2001.
(SRDS’02), Washington, DC, USA, 2002. IEEE Computer
Society.
[40] B. Whetten, T. Montgomery, and S. Kaplan. A high perfor-
mance totally ordered multicast protocol. In Selected Papers
from the International Workshop on Theory and Practice
in Distributed Systems, pages 33(cid:150)57, London, UK, 1994.
Springer-Verlag.
[41] U. Wilhelm and A. Schiper. A hierarchy of totally ordered
multicasts. In Proceedings of the 14TH Symposium on Re-
liable Distributed Systems, Washington, DC, USA, 1995.
IEEE Computer Society.
[22] H. Garcia-Molina and A. Spauster. Ordered and reli-
able multicast communication. ACM Trans. Comput. Syst.,
9(3):242(cid:150)271, 1991.
[23] A. Gopal and S. Toueg. Reliable broadcast in synchronous
and asynchronous environments (preliminary version).
In
Proceedings of the 3rd International Workshop on Dis-
tributed Algorithms, pages 110(cid:150)123, London, UK, 1989.
Springer-Verlag.
[24] R. Guerraoui and A. Schiper. Software-based replication for
fault tolerance. Computer, 30(4):68(cid:150)74, 1997.
[25] V. Hadzilacos and S. Toueg. Fault-tolerant broadcasts and
related problems. Distributed systems (2nd Ed.), pages 97(cid:150)
145, 1993.
[26] F. Kaashoek and A. Tanenbaum. An evaluation of the
In Proceedings of
amoeba group communication system.
the 16th International Conference on Distributed Comput-
ing Systems (ICDCS ’96), Washington, DC, USA, 1996.
IEEE Computer Society.
[27] J. Kim and C. Kim. A total ordering protocol using a dy-
namic token-passing scheme. Distrib. Syst. Eng. J., 4(2):87(cid:150)
95, jun 1997.
[28] M. Leclercq, V. Qu·ema, and J.-B. Stefani. DREAM: a Com-
ponent Framework for the Construction of Resource-Aware,
Con(cid:2)gurable MOMs.
IEEE Distributed Systems Online,
6(9), September 2005.
[29] S. Luan and V. Gligor. A fault-tolerant protocol for atomic
IEEE Trans. Parallel Distrib. Syst., 1(3):271(cid:150)
broadcast.
285, 1990.
[30] N. A. Lynch. Distributed Algorithms. Morgan-Kaufmann,
1996.
[31] L. Malhis, W. Sanders, and R. Schlichting. Numerical per-
formability evaluation of a group multicast protocol. Distrib.
Syst. Eng. J., 3(1):39(cid:150)52, march 1996.
[32] L. Moser, P. Melliar-Smith, and V. Agrawala. Asynchronous
fault-tolerant total ordering algorithms. SIAM J. Comput.,
22(4):727(cid:150)750, 1993.
[33] Netperf. http://www.netperf.org/.
[34] T. Ng. Ordered broadcasts for large applications. In Pro-
ceedings of the 10th IEEE International Symposium on Re-
liable Distributed Systems (SRDS’91), pages 188(cid:150)197, Pisa,
Italy, 1991. IEEE Computer Society.
[35] L. Peterson, N. Buchholz, and R. Schlichting. Preserving
and using context information in interprocess communica-
tion. ACM Trans. Comput. Syst., 7(3):217(cid:150)246, 1989.
[36] L. Rodrigues, H. Fonseca, and P. Verissimo. Totally or-
dered multicast in large-scale systems.
In Proceedings of
the 16th International Conference on Distributed Comput-
ing Systems (ICDCS ’96), Washington, DC, USA, 1996.
IEEE Computer Society.
[37] Sun.
Java 2 Platform, Enterprise Edition (J2EE).
http://java.sun.com/j2ee/.
[38] P. Urb·an, X. D·efago, and A. Schiper. Contention-aware
metrics for distributed algorithms: Comparison of atomic
broadcast algorithms. In Proceedings of 9th IEEE Interna-
tional Conference on Computer Communications and Net-
works (IC3N 2000), pages 582(cid:150)589, 2000.
[39] P. Vicente and L. Rodrigues. An indulgent uniform total
order algorithm with optimistic delivery. In Proceedings of
the 21st IEEE Symposium on Reliable Distributed Systems