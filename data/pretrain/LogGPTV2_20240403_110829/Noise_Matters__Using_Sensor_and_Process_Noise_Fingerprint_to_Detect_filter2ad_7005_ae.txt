### Data and Performance Metrics

The following tables present the performance metrics and data points collected from various experiments. The first set of numbers (e.g., 27, 37, 35, etc.) represents different attack sequences, while the second set (e.g., 99.65%, 97.88%, etc.) represents the corresponding detection accuracy rates.

**Attack Sequences:**
- 27
- 27
- 37
- 37
- 35
- 12
- 5
- 24
- 22
- 29
- 22
- 20
- 8

**Detection Accuracy Rates:**
- 99.65%
- 97.88%
- 99.49%
- 91.41%
- 91.55%
- 92.09%
- 99.86%
- 62.5%
- 88.88%
- 81.48%
- 78.37%
- 59.45%
- 57.14%
- 66.66%
- 86.3%
- 89.4%
- 94.2%
- 88.7%
- 88.85%
- 89.5%
- 91.6%
- 88.88%
- 93.54%
- 80.64%
- 80.95%
- 78.57%
- 77.5%
- 73.3%

### Methodology

In our approach, each sensor is checked only against its own profile and not against all other sensors. Since we do not have an attacker's spoofed data beforehand, it is not possible to train a classifier for the illegitimate class. Therefore, data from all other sensors is considered as an "other class." We also used one-class SVM to train only for the "legitimate class" for each sensor and then tested the performance under various attacks. These observations indicate that the proposed technique will scale well even if the number of sensors is large, as it is not necessary to compare a sensor’s fingerprint with the whole population.

The experiments were conducted on a water treatment testbed, which includes different types and models of sensors. Additionally, there are six stages in the process plant with different process dynamics, highlighting the generality of the proposed technique.

### Limitation (False Alarm Rate)

For any intrusion detection system, false alarms are a limiting factor. In Table 5, it can be seen that using one-class SVM helps to detect attacks with higher accuracy (TPR) but at the cost of slightly lower TNR (i.e., misclassifying normal operation as under attack). Since the lowest TNR is 86%, we can set a heuristic threshold of 85% to raise an alarm for an attack. This would significantly lower the false alarm rate. We are also experimenting with a moving average window filter to further reduce the false alarm rate by tuning the detector parameters on a live water treatment testbed.

### Performance Comparison with Reference Techniques

The attacks studied in this article are a set of benchmark attacks used by others [1, 10]. The list in Table 6 shows executed attacks performed on sensors or on a sensor-actuator pair. Accuracy results in Table 6 can be directly compared (for each exact attack sequence) with results in [10]. Our proposed technique performs better, but a fair comparison must account for the downside of false alarms. The authors in [10] do not provide false alarm rates for attacked datasets, meaning that even for attack datasets, attacks were executed intermittently, and most readings are normal. Therefore, they should also provide accuracy for normal data classification.

In [1], the detection metrics are not attack detection accuracy but an alarm for the case of an attack. From Table 6, it can be seen that the proposed technique performs similarly by successfully detecting attacks on sensors and does not require design information (which is required by the method in [1]) to come up with physical invariants.

### Implementation and Practical Considerations

#### Sensor Replacement/Retraining

Since fingerprints are specific to each sensor, a question arises about what happens to a fingerprint if a sensor is replaced? When a sensor is replaced for any reason, the proposed technique does not need to create a new system model because the system dynamics remain the same. We only need to determine the noise component contributed by the new sensor's hardware. To achieve this, we simply run the system, collect data, and update the profile only for the newly added sensor. This does not require generating a new system model but only training data for machine learning methods.

#### Training Phase (Capturing System Dynamics)

To create a representative system model, one must capture the entire process dynamics. For example, in the case of a water treatment testbed, a complete cycle of the process is involved, starting from raw water to filtration stages until clean drinking water is obtained.

### Related Work

Device fingerprinting is not a new concept, but creating new fingerprints for devices in a Cyber-Physical System (CPS) is less explored. Device fingerprinting for CPS devices poses unique challenges due to different technologies compared to IT infrastructures and encounters different threat models. Previous research efforts focused on threats including privacy compromise or tracking of a certain device. In this work, it is proposed to authenticate the sensors and also to detect attacks in a CPS setting. This work is a continuation of our earlier proposal [5] to create unique fingerprints for sensing devices in a CPS and demonstrate their effectiveness against a range of strong attack scenarios.

A summary of the related work is as follows:

- **Device Fingerprinting:** Camera identification based on a CMOS sensor [25] inspired our work. In [25], a reference noise pattern for each camera is extracted and used for camera attribution. Remote device identification based on microscopic deviations in the device’s clock [21, 29, 34] and network traffic analysis [37] are also presented.
- **CPS Device Fingerprinting and Attack Detection:** Among attack detection techniques in the context of CPS, a few related works have used the same testbed (SWaT) for experiments. We have used the same testbed and dataset as presented in [1, 10]. Both of those techniques use physical invariants to detect attacks. Our proposed technique is different as it only considers device/sensor characteristics and does not necessarily care about the whole system state. It does not need source code or the control system design of a process plant and does not need to come up with invariants, which is a tedious procedure on its own.

### Conclusions

A technique to fingerprint the sensor and process noise is presented. It is shown that such a fingerprint can uniquely identify the sensor by looking at the sensor measurements passively. The upper bounds for state deviation under a stealthy attack are derived. Results have shown that sensors can be identified with as high an accuracy of 98% by using the noise fingerprint. A multitude of attacks on sensor measurements are detected with a high true positive and true negative rate. A security argument against stealthy attacks is provided, showing that the proposed technique can detect a strong adversary.

**Future Work:** The goal is to achieve higher accuracy for attack detection and a very low false alarm rate. An idea is to implement heuristics such as a voting system among physically coupled sensors and to improve the system model by using a bank of observers scheme.

### Acknowledgments

This work was supported by the National Research Foundation (NRF), Prime Minister’s Office, Singapore, under its National Cyber Security R&D Programme (Award No. NRF2014NCR-NCR001-40) and administered by the National Cybersecurity R&D Directorate.

### References

[References listed here as per the original text.]

---

This revised version aims to make the text more coherent, clear, and professional, while retaining all the essential details and findings.