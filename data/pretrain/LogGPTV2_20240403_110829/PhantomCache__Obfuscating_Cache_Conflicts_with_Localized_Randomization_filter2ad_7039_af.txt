[3]. Speciﬁcally, we use all the 20 benchmarks from the
SPECspeed 2017 Integer and SPECspeed 2017 Floating Point
suites. For each benchmark, a representative slice is selected
for fast simulation with performance estimates comparative to
full-execution simulation [17]. Such a representative slice can
be obtained using SimPoint [17] and Pin [27]. The workloads
corresponding to the representative slices of all 20 adopted
benchmarks are readily available in ChampSim. When running
a workload only consisting of a single benchmark on a multi-
core CPU, every core is running the same benchmark. We
6This is because ChampSim features a 3-level cache. The L2 cache is exactly
from which the LLC receives an access request.
Fig. 9. Comparison of resistance to eviction set minimization.
also evaluate the performance using mixed workloads that are
generated by randomly selecting n out of the 20 benchmarks on
an n-core CPU. Each selected benchmark is then pinned to a
different core [34], [46]. We run at least 2 billion instructions per
workload. The ﬁrst 1 billion instructions are used for warming
up the cache while the other 1 billion or more instructions are
used for collecting performance statistics.
Metrics. We evaluate PhantomCache using three performance
metrics—instructions per cycle (IPC), misses per 1,000 in-
structions (MPKI) of LLC, and miss rate of LLC. To evaluate
how PhantomCache impacts cache performance, we normalize
all these metrics using the ratio of PhantomCache’s metrics
to that of the baseline cache without modiﬁcation. A higher
normalized IPC indicates a better performance, exceeding 100%
if PhantomCache outperforms baseline. Moreover, a lower
normalized MPKI or normalized miss rate demonstrates a better
performance. To measure aggregate performance, we further
report the geometric mean of normalized IPC and the average
of normalized MPKI and normalized miss rate.
Results. Based on the conﬁguration in Table III, the results
show that, to secure an 8-bank 16 MB 16-way LLC against
the powerful O(|E|) attack, PhantomCache introduces a 1.20%
slowdown on average among all 20 SPEC CPU 2017 bench-
marks (Figure 10). When taking into account the same set
of 17 benchmarks as the state-of-the-art ScatterCache [45],
PhantomCache introduces an only 1.06% slowdown on average,
being 2x more efﬁcient than ScatterCache. In terms of mixed
workloads, PhantomCache brings a much smaller slowdown of
0.50% on average.
A. Resistance to Eviction Set Minimization
We ﬁrst evaluate the effectiveness of PhantomCache against
eviction set minimization. Following recent related work [34],
[35], [45], we run the sate-of-the-art O(|E|) eviction set mini-
mization algorithm on a traditional cache and PhantomCache,
respectively. The security metric we use is the number of
cache sets accessed during each iteration of the algorithm. (The
term “accessed” means that among all the memory accesses in
this iteration, at least one address maps to that cache set.). If
the eviction set minimization process succeeds, we expect to
observe a noticeable decrease in the number of accessed cache
sets as the iteration proceeds.
We conﬁgure a 16 MB 16-way LLC with 16,384 cache
sets. The initial eviction set consists of 16,384 × 16 randomly
picked addresses. The size of the initial set guarantees a high
possibility that there are sufﬁcient addresses to form an eviction
set for the target cache line.
12
Iteration Index01020304050Set Count×10400.511.52(a) Baseline CacheIteration Index0200040006000800010000Set Count×10400.511.52(b) PhantomCacheFig. 11.
Impact of calculation latency on PhantomCache performance.
Fig. 12.
Impact of randomization degree on PhantomCache performance.
lead to performance degradation for all workloads. For example,
the lbm workload and the leela workload in Figure 10(c)
improves the performance by 0.73% and 0.34%, respectively. To
evaluate how salt choice affects performance, we run multiple
trials of small workloads (each with 0.1-billion instructions)
with different salts per run. The results show little effect on
performance by different salts. This mainly attributes to strong
randomness of the mapping function (Section IV-C). Moreover,
a single trial of a workload with 1-billion or more instructions
may sufﬁce to quantify the average over multi-trial of the same
workload [34], [46].
We understand the slight impact of PhantomCache on
processor performance as follows. First, it takes extra access
latency because of newly introduced components such as the
hash function. Since all the introduced operations complete
in only one clock cycle (Section IV-D), the extra latency
cannot ﬂuctuate overall performance in comparison with a
20 clock-cycle LLC hit and a 100+ clock-cycle memory access.
Second, since PhantomCache changes the mapping pattern of
LLC, conﬂict misses are affected. Addresses that map to the
same set in the baseline cache can map to different sets in
PhantomCache. While lessening cache conﬂicts in this set, the
remapped addresses may increase cache conﬂicts in other sets.
This feature has an unpredictable inﬂuence on MPKI and miss
rate. Some workloads may happen to enjoy fewer cache misses
while others may suffer more. As shown in Figure 10, the
overall impact on performance is as minimal as 1.20%. Note
that the state-of-the-art ScatterCache does not test the three
benchmarks of gcc, wrf, and cam4 due to compilation failure
[45]. They happen to be the major contribution to performance
degradation in our test as shown especially in Figure 10(b) and
Figure 10(c). Toward an objective comparison, we recalculate
the overall performance degradation of PhantomCache without
considering gcc, wrf, and cam4. The result is decreased to
1.06%, which is 2x more efﬁcient than ScatterCache with 2%
performance degradation [45].
Fig. 10. PhantomCache performance with metrics normalized over baseline.
As shown in Figure 9, the O(|E|) algorithm completes the
eviction set minimization process in a traditional cache after
only 48 iterations. However, in PhantomCache, the number of
accessed cache sets of each iteration remains the same even
after 10,000 rounds. The result shows that the most powerful
eviction set minimization algorithm so far does not work in
PhantomCache. An attacker gains no progress of minimization
in PhantomCache as in a traditional cache.
B. Processor Capacity
To evaluate how PhantomCache affects cache performance,
we start with experiments under various processor capacity
settings. Processor capacity differs mainly in the number
of cores,
the size of LLC, and the number of channels
connecting to memory. We consider both single-core and
multi-core processors. Each core is usually assigned with a
2 MB cache [18]. For randomization degree, we use r = 8
by default as it guarantees a strong security level. Figure 10
reports the normalized performance metrics on three different
processors. PhantomCache imposes only an average normalized-
IPC degradation of 0.05%, 1.02%, 1.20% on the 1-core, 4-core,
and 8-core processors, respectively. The corresponding increase
of normalized MPKI is 0.08%, 0.14%, and 0.41%. Normalized
miss rate shows a much smaller growth up to 1.40%. The
performance of PhantomCache, however, does not necessarily
13
bwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103104105106Normalized Metrics (%)(a) 1-core CPU, 2 MB LLC, 1-channel DRAMIPCMPKIMiss RatebwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103104105106Normalized Metrics (%)(b) 4-core CPU, 8 MB LLC, 2-channel DRAMIPCMPKIMiss RatebwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103104105106Normalized Metrics (%)(c) 8-core CPU, 16 MB LLC, 2-channel DRAMIPCMPKIMiss RatebwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103Normalized IPC (%)0 cycle1 cycle2 cycles3 cycles4 cyclesbwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103Normalized IPC (%)2 degrees4 degrees6 degrees8 degreesFig. 13.
Impact of LLC capacity on PhantomCache performance.
C. Calculation Latency
PhantomCache simply uses XOR and a hash function to
efﬁciently calculate the candidate sets of a requested data
block. Since the calculation process is necessary for each
LLC access, its latency is performance critical. We evaluate
the impact of calculation latency using an 8-core CPU, a
16 MB LLC, and a 2-channel DRAM. Figure 11 shows the
performance of PhantomCache with the calculation latency
ranging from 0 cycles to 4 cycles. A 4-cycle latency decreases
normalized IPC by 1.53%. As expected, a lower latency
yields a better performance. Based on our current design,
PhantomCache promises only one clock cycle latency. This
decreases normalized IPC by only 1.20%.
D. Randomization Degree
So far, we report all performance statistics using a number
of r = 8 candidate sets for an address. We choose it because
of its strong security guarantee. As shown in Table II, 8-degree
PhantomCache costs an attacker more than 500 years to ﬁnd
a minimal eviction set. A smaller r = 6, however, can also
impede the eviction set minimization process for as long as 7.8
years. This should be sufﬁcient for securing most computers.
One may thus become curious about how PhantcomCache
performs using fewer candidate sets. We evaluate the impact
of randomization degree using an 8-core CPU, a 16 MB LLC,
and a 2-channel DRAM. Figure 12 shows the normalized
performance of PhantomCache with a randomization degree of
2, 4, 6, and 8. We observe that the performance is relatively
insensitive to randomization degree. This encourages adopters
of PhantomCache to strive for an even stronger security
than 8 candidate sets provide, as long as they consider the
corresponding hardware cost affordable.
E. LLC Capacity
As the original goal of PhantomCache is LLC friendliness,
we further evaluate the scalability of PhantomCache as LLC
capacity increases. We evaluate the impact of LLC capacity
using an 8-core CPU, a 2-channel DRAM, and an LLC with
varying capacity. Figure 13 shows the normalized IPC of
PhantomCache in an 8 MB, 16 MB, 32 MB, and 64 MB
LLC. As expected, a workload performs better upon a larger
LLC. This is because of the intrinsic cache property that a
larger cache guarantees fewer memory accesses, which is much
slower than cache accesses. Furthermore, in comparison with
the baseline cache, the average performance degradation by
PhantomCache using an 8 MB, 16 MB, 32 MB, and 64 MB
LLC is at most 1.20%. This demonstrates that PhantomCache
Fig. 14.
Impact of bank numer on PhantomCache performance.
can efﬁciently secure large LLCs against conﬂict-based cache
timing attacks.
F. Bank Number
We evaluate how PhantomCache affects cache performance
when we realize it using multi-banked LLCs with different
number of banks. Speciﬁcally, we use a 16 MB 16-way LLC and
divide it to different numbers of banks. “No Bank” corresponds
to when the cache is not divided. In this case, PhantomCache
has no parallelism to enjoy and has to sequentialize all cache
accesses. Figure 14 reports the performance results. Generally,
the performance degradation decreases as the number of
banks increases. For the no-bank PhantomCache, the average
performance degradation is within 2.27%. For the 8-bank
PhantomCache, the average performance degradation is only
1.20%.
G. Sliced LLC
Beyond the multi-banked structure, we further adapt Phan-
tomCache to recent sliced LLCs and evaluate its performance.
Modern Intel CPUs use sliced LLCs where the LLC is split
into different slices. A physical address maps to a slice through
some special hash function [29]. The hash function is designed
to guarantee that consecutive memory lines can be distributed
across different slices and thus can be read by different cores
in parallel to improve efﬁciency. However, the slice mapping
function of existing sliced LLCs is deterministic [29]. It does
not apply to PhantomCache that requires randomized mapping.
For adapting PhantomCache to an s-slice LLC, we choose to
use the log s most signiﬁcant bits of the computed set index
by PhantomCache as the slice ID. Since the set index is a
hash result of the physical address and a random salt, it has
intrinsic randomness. Taking its s most signiﬁcant bits can also
guarantee randomness. This further ensures that consecutive
addresses be distributed across different slices.
We compare the performance of the preceding adapted
PhantomCache with that of the baseline sliced LLC that
uses the reverse-engineered hash function [29] of an Intel
sliced LLC. We run both approaches on an 8-core CPU with
16 MB 8-slice LLC with 8 candidate sets for PhantomCache
and report the results in Figure 15. In terms of normalized
IPC, PhantomCache introduces a performance degradation of
1.52% (and 1.38% without including gcc, wrf, and cam4)
to the baseline sliced LLC. The performance degradation is
slightly larger than previous 1.20% on the multi-banked LLC.
It implies that the slice mapping function of PhantomCache
does impact on the effect of memory access parallelism across
different slices. Since currently we simply use the 3 most
14
bwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103Normalized IPC (%)8 MB16 MB32 MB64 MBbwavescactuBSSNcam4deepsjengexchange2fotonik3dgccimagicklbmleelamcfnabomnetppperlbenchpop2romswrfx264xalancbmkxzAverage90919293949596979899100101102103Normalized IPC (%)No Bank2 Banks4 Banks8 BanksFig. 15. PhantomCache performance with metrics normalized over the baseline
sliced LLC.
signiﬁcant bits of the computed set index for slice mapping,
it is challenging to reserve the property of evenly mapping
consecutive addresses to different slices as the baseline sliced
LLC. Improving the slice mapping of PhantomCache toward
such a property certainly improves PhantomCache performance.
However, such an improvement may or may not bring much
intricacy to hardware and is left for future work.
H. Mixed Benchmark
As with some related work [34], [35], [46], we also evaluate
PhantomCache performance using mixed workloads. On an n-
core CPU, a mixed workload is generated by randomly selecting
n out of the 20 benchmarks. During experiment execution,
each of the n selected benchmarks is pinned to a different
core. This resembles the environment of a real system where
different applications run on different cores in parallel. We
run 10 mixed workloads for both 4-core CPU and 8-core CPU.
PhantomCache is conﬁgured as default with r = 8 and mapping
latency of 1 clock cycle on an 8-bank LLC. Figure 16 reports
the performance comparison with the baseline 8-bank LLC. We
observe that PhantomCache performs better on mixed workloads
than on individual benchmarks. For example, it introduces an
only 0.50% average performance degradation to an 8-core CPU
with an 8-bank 16 MB 16-way LLC (Figure 16(b)).
We analyze the slight performance overhead of Phantom-
Cache as follows.
Limited miss rates on L1 and L2 caches. By design, the
higher-level L1 and L2 caches, can satisfy most of the proces-
sor’s memory accesses. In contrast, the LLC has much less
visibility to the memory activity [26]. Therefore, slower LLC
handling may not contribute too much to overall slowdown.
Pipelined cache optimization. Modern caches are optimized
with pipelined cache-requests handling. That is, n consecutive
requests do not necessarily cause n times latency as that of a
single request.
Parallelism over multiple banks. Multiple banks mitigate
the contention caused by the 8 inﬂated requests for every
original requests. The more the banks, the more requests can
be processed in parallel.
Bank assignment unevenness. Most workloads may not fully
utilize the multi-banked LLC. We observe that it is uncommon
that multiple cores access the LLC at the same time. Some
banks that stay idle in the baseline cache will be made full use
of in PhantomCache. This further reduces contention and thus
increase PhantomCache performance.
Fig. 16. PhantomCache performance with metrics normalized over baseline
using mixed workloads.
I. Hardware Overhead
The hardware complexity of PhantomCache design depends