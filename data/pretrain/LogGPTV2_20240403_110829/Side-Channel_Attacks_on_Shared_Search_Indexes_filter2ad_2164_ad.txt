sharded with some d ∈ M without spending extra time to
determine which document it was.
The ﬁnal detail is ﬁxing δ, which must be set so that
we distinguish larger changes in the score from random
variation. We experimented with each service by repeating
several queries over a period of time, and setting δ to more
than the maximum observed variation (see Figure 2 for an
example of observed random variation).
Co-shard testing on stable services. On some services
we noticed that searching for two terms with DF exactly
1 would return results with exactly the same score. On
such stable services we can save time when co-shard testing
many documents via the following strategy: create many
documents, all containing the same random term r. Then
request a search for r, which returns all of the created
documents, and partition the documents returned by their
scores. If the service is stable, the documents on the same
shard will have the same scores, and otherwise their scores
will likely differ. Thus our test can immediately ﬁlter to
a subset of documents that are likely co-sharded, and then
perform the co-shard test to verify correctness.
E. Tool: Shard Mapping
Our multi-shard attacks will start with a pre-computation
phase that we call shard mapping, which aims to place
680
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:39 UTC from IEEE Xplore.  Restrictions apply. 
exactly one adversary-owned document on each shard in the
system. We call a set M of documents with this property
a shard map, and the goal of this subsection is to compute
a shard map efﬁciently. Recall that this is non-trivial since
the mapping of documents to shards is hidden by the
interface. After this somewhat slower pre-computation set
the adversary will be able to build attacks efﬁciently as we
describe below.
Our method for computing a shard map M is as follows:
Initialize a set M consisting of a single document d1 (on
some shard). Then create another document d2, and use the
co-shard test to check if d1 and d2 are on the same shard.
If they are, then the attack discards d2. If d1 and d2 are on
different shards, then it adds d2 to the map M. The attack
continues creating further documents, except this time it tests
for co-sharding with its documents in M before deciding that
it has found a new shard and adding the new document to S.
After some large number of runs that do not ﬁnd a new shard,
the adversary concludes that the set S consists of exactly one
document on each shard of the system.
We denote our method by MAPSHARDS and it is given in
detail in Algorithm 2. We repeatedly create a new document
and test if it has landed in an “unmapped” shard using
COSHARDTEST. If not, we discard the document. If, on the
other hand, the document is on a new shard, then we add it
to the map M.
Run-time analysis.
In Algorithm 2 we assume a service-
speciﬁc constant nMAX has been ﬁxed. We want to pick an
nMAX large enough to ensure that we eventually ﬁnd every
shard without wasting too much time in the attack, since each
co-shard test requires a costly sleep to propagate writes.
To analyze the run-time we assume that each newly created
document is assigned a uniformly random shard out of nSHRDS
possibilities. (Note that the actual shard assignment strategy
being used by a target service could be more complex, so
nSHRDS estimated by MAPSHARDS would only be a lower
bound.) Then the expected number of iterations before we
have a document on every shard is given by the well-
known coupon collector problem with nSHRDS coupons (see
for example [5]). A classic analysis tell us that the expected
number of tries is close to nSHRDS · (ln(nSHRDS) + 1.6), with
tight tail bounds on deviations from the expectation.
Thus one can set nMAX to be slightly larger
than
the coupon-collector prediction when one knows nSHRDS,
say, from technical information the service has released.
Alternatively, one can simply guess nSHRDS and run the attack
until many iterations fail to ﬁnd a shard. Let nFIND be the
number of shards found after k iterations, and nFAIL be the
number of consecutive iterations fail to ﬁnd a shard after
the kth iteration. The probability of seeing nFAIL iterations
of failing can be calculated as (nFIND/nSHRDS)nFAIL. Then, one
can stop if the probability is smaller than a certain threshold.
We took the latter approach in our attacks.
: Shard map M
Algorithm 2: MAPSHARDS
Parameter: Integer nmax > 0
Output
1 Create an empty document d1;
2 M ← {d1};
3 for j = 2, . . . , nMAX do
4
5
6
7
8
9
10 end
11 return M
M ← M ∪ {dj};
Discard dj;
end
else
Create new empty document dj;
if COSHARDTEST(dj , M ) = False then
j
, d(2)
Optimizations and multi-mapping. We also implemented
a slightly more complicated, but faster, variant of shard
mapping. In each iteration of the main loop on line 3, we
changed the algorithm to create two new empty documents
d(1)
instead of one. We then execute a version of
j
COSHARDTEST to test if either d(1)
(or both) landed on
new shards. If neither did, we discard them both. If exactly
one did, then we keep it and discard the other. If both landed
on new shards, then we must test if they landed on the same
new shard via another co-shard test. In principle this could
be run with more than two new documents in each iteration
but we found that mapping was fast enough with two.
, d(2)
j
j
A second optimization is to apply the faster co-shard test
when the service returns stable scores. On some services this
will increase the speed of the mapping attack substantially.
Later we show that some attacks can be sped up using
multiple shard maps M1, . . . , Mm, where the ﬁrst documents
of all shard maps lie on the same shard, and second lie on the
same shard, etc. On some services like GitHub this will be
easy to construct due to their sharding policy, which places
all ﬁles from a repository on the same shard. On others we
can run shard mapping multiple times, and then use co-shard
testing again to ﬁnd one document from each map that is on
each shard.
F. Attack 1: Brute-Force Term Extraction
We now build our brute-force term extraction attack using
a pre-computed shard map M. Our attack will use M to
quickly determine the DF of given terms on every shard of
the system. More precisely, let B be a (potentially large) set
of terms that we are interested in testing for, in a system with
nSHRDS shards. Our attack will return a tuple (B1, . . . , BnSHRDS )
of sets of terms, where Bi ⊆ B consists of the terms from B
that are in the i-th shard of the system.
Our attack is given in Algorithm 3. It starts by initializing
the sets Bi to be empty, and then iterates over each document
in the shard map, writing a random term and all of the
terms in B to the document. After waiting for the writes to
propagate, it then tests for the presence of each t ∈ B on
the shards using score-dipping again with some threshold δ.
681
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:39 UTC from IEEE Xplore.  Restrictions apply. 
: Shard map M = {d1, . . . , dnSHRDS
)
Algorithm 3: TERMEXTRACT
Input
Output: (B1, . . . , BnSHRDS
Param : δ > 0
1 Initialize all Bi ← ∅;
2 for i = 1, . . . , nSHRDS do
ri ← RNDTERM;
3
WRITE(di, {ri} ∪ B)
4
5 end
6 SLEEP;
7 foreach t ∈ B do
for i = 1, . . . , nSHRDS do
si ← score(ri, di);
i ← score(t, di);
s(cid:2)
i − si) > δ then
if (s(cid:2)
Bi ← Bi ∪ {t}
8
9
10
11
12
13
14
15 end
16 return (B1, . . . , BnSHRDS
end
end
)
}, term set B
: Documents d1, . . . , dnDFE on same shard
Algorithm 4: DFPRED
Input
Output : Score-to-DF model f
Params: nDFE, training algorithm TRAIN
1 Lscrs ← φ;
2 for i = 1 . . . nDFE do
r ← RNDTERM;
3
for j = 1 . . . i do WRITE(dj , r);
4
SLEEP;
5
si ← (cid:2)i
j=1 score(r, dj )/i;
6
Append {(cid:8)i, si(cid:9)} to Lscrs
7
8 end
9 f ← TRAIN(Lscrs);
10 return f
target shard and then search and record the score as s. Finally,
we produce an estimated DF by computing
[f−1
(s)] − 1
This approach minimizes the number of costly sleep times
by writing many terms to each ﬁle.
This technique crucially depends on the shard map to avoid
incorrectly dipping the score for a term t with the attacker’s
own write operations. Also we note that if we have multiple
shard maps then we can partition B and run independent
instances of TERMEXTRACT in parallel.
G. Attack 2: DF Prediction via Score Extrapolation
Natural extensions of our ﬁrst attack to estimate DFs
appeared to work correctly but were slow, as they had
if the DF was 0, 1, 2, 3, . . . before
to measure and test
ﬁnding the correct value. Our second attack estimates how
many documents contain a given term on each shard of a
search service (that is, we estimate df(t, Dj) for each shard
document set Dj). We call this DF prediction which is
denoted as DFPRED.
At a high level, DF prediction works by collecting data on
the behavior of the score function when the DF of a term
is known, and then training a model that predicts DF from
relevance scores alone. In our attacks we can speculatively
guess the class of scoring functions based on knowledge of
common implementations, but we still assume that constants
and custom modiﬁcations to the function are hidden.
The algorithm DFPRED is described in Algorithm 4. It
assumes it is given input several documents on the same shard
of the service (either from several shard maps or from some
other method). Then it performs a data collection step in the
loop that estimates the score of a search when a term has
DF equal to 1, . . . , nDFE, where nDFE is a parameter of the
system (see Figure 3 for example data). After this step it uses
a training algorithm to ﬁt a curve f (from some class) that
maps integers to reals. This f intuitively is a guess for the
mapping from DFs to relevance scores induced by the system.
After computing f we can apply it in attacks. Given a term
t of interest, an attack can write t to the document on the
where [x] denotes the closest integer to x. We subtract 1 to
account for the document added by the attack that contains t.
Comparison to Brute-Force Term Extraction. Once we
have computed the model f we can also use it for brute-force
term extraction to get an attack with essentially the same
complexity by using f to predict when terms have DF equal
to zero. We opted for the ﬁrst attack above because it does not
require the training phase. Note that DF prediction actually
recovers more, as it guesses the DF of a term rather than only
detecting if the DF is non-zero. As mentioned above, using
TERMEXTRACT to decide the DF of a term would be slow.
H. Attack 3: Rank-only Attacks
Our attacks above assumed that the search interface returns
relevance scores. Some services however only return the list
of ranked results without scores, and here we sketch how to
adapt our techniques to this case.
We assume that the service supports multi-term search
queries, and that
the relevance scoring function assigns
weights to terms that decrease with their DF. For now, we
also assume there is no noise in the scores on a shard.
When there is no noise in scores, scores will often result
in ties, and we start by reverse-engineering how the service
breaks ties. In our experience this was done by sorting on the
document name, creation time, or some other easily-noticed
property of the documents.
Rank-only term extraction. Our rank-only term extraction
attack is given in Algorithm 5. It
two
documents d1 and d2 on the same shard, and a target term
set B. Without loss of generality we assume that d1 is ranked
higher than d2 in the case of a tie.
The algorithm will compute the subset B(cid:2) ⊆ B of terms
present on the shard with d1 and d2. The algorithm iterates
over each t ∈ B. It writes t into the document d1, and it
writes fresh random terms ri into the document d2.
takes as input
682
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:18:39 UTC from IEEE Xplore.  Restrictions apply. 
Algorithm 5: ROTERMEXTRACT
Input
: Documents d1, d2, term set B
: Terms B(cid:2) ⊆ B present on the shard.
Output
1 foreach t ∈ B do
r ← RNDTERM
WRITE(d1, t)
WRITE(d2, r)
SLEEP
R ← ROSEARCH({t, ri})
if d1 is ranked below d2 in R then
B(cid:2) ← B(cid:2) ∪ {t}
2
3
4
5
6