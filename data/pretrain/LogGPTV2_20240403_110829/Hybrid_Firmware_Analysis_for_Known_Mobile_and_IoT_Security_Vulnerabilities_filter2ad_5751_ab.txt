whether the report by the static analysis is indeed correct.
If so, the target function within the ﬁrmware is reported to be
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:28:40 UTC from IEEE Xplore.  Restrictions apply. 
375
vulnerable along with the corresponding CVE number. It is
noteworthy that PATCHECKO’s analysis is performed without
any source code access and hence its deployment does not rely
on the cooperation of the ﬁrmware vendors.
Since we don’t really know whether the reported function is
patched, PATCHECKO will ﬁrst compare the difference based
on their static features and restart the whole process based on
the patched version of the vulnerable function. PATCHECKO
then uses the differential engine to analyze the static/dynamic
features as well as the similarity score to decide whether the
function has been patched.
III. DESIGN
In this section we present the design of the PATCHECKO
framework that explores any given mobile/IoT ﬁrmware binary
executable and discovers and reports vulnerable points in the
binary code/data segments of the ﬁrmware without access
to its source code. Beyond similarity-based vulnerable code
discovery, PATCHECKO can also accurately verify the pres-
ence/absence of a security patch for a target ﬁrmware binary.
A. Deep Learning-Based Firmware Assessment
Vulnerabilities
for Known
Comparing with the previous bipartite graph matching [44]
and dynamic similarity testing [15], deep learning approaches
[41] can achieve signiﬁcantly better accuracy and efﬁciency for
known vulnerability discovery. This is due to the fact that deep
learning approaches can evaluate graphical representations of
binaries as a whole and can also automatically learn relation-
ships without manually deﬁned rules. PATCHECKO uses a deep
learning approach as a ﬁrst step to generate a list of vulnerable
candidate functions on the order of seconds. However, in order
to accommodate our prior assumptions, we ﬁrst need to build
a training dataset that extracts static function features to train
a deep learning model.
Feature extractor. In order to extract static function fea-
tures, PATCHECKO ﬁrst analyzes functions in assembly format.
Marking the correct boundary, scope, and range of each
assembly routine is usually the ﬁrst problem to solve. Fur-
thermore, distinguishing between code and data is equally
important. The input for PATCHECKO’s neural network model
is the function feature vector that
is extracted from the
disassembled binary code of the target function. To obtain
this feature vector, we ﬁrst identify the function boundaries.
Function boundary identiﬁcation with minimal reliance of
instruction set semantics is an independent problem of interest.
Previous approaches range from traditional machine learning
techniques [4] to neural networks [38] to applying function
interface veriﬁcation [35]. In this work, we assume that these
steps are handled by the disassembler using a robust heuristic
technique. A disassembler can provide the control ﬂow graph
(CFG) of a binary–a common feature used in vulnerability
detection.
Figure 2 shows the procedure for PATCHECKO’s function
feature extraction. PATCHECKO utilizes the CFG with differ-
ent basic block-level attributes as the features to model the
function in our problem. For each function, PATCHECKO can
extract function-level, basic block-level and inter-block-level
information. Table I shows the completed extracted interesting
48 features from each function for generating a feature vector.
(cid:3)(cid:10)(cid:16)(cid:12)(cid:21)(cid:4)(cid:16)(cid:6)(cid:1)(cid:10)(cid:12)(cid:4)(cid:8)(cid:6)
(cid:3)(cid:14)(cid:1)(cid:4)(cid:6) (cid:4)(cid:7)
(cid:2)
(cid:2)
(cid:3)(cid:19)(cid:13)(cid:5)(cid:18)(cid:10)(cid:14)(cid:13)(cid:1)(cid:5)(cid:14)(cid:13)(cid:18)(cid:16)(cid:14)(cid:11)(cid:1)(cid:7)(cid:11)(cid:14)(cid:21)(cid:1)(cid:8)(cid:16)(cid:4)(cid:15)(cid:9)(cid:17)
(cid:2) (cid:4)(cid:8)(cid:12) (cid:4)(cid:8)(cid:13) (cid:4)(cid:9)(cid:5)
(cid:2)
(cid:2)
(cid:3)(cid:10)(cid:11)(cid:13)
(cid:1)(cid:1)(cid:1)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)
(cid:3)(cid:10)(cid:12)(cid:1)(cid:13)
(cid:4)(cid:5)(cid:4)(cid:6)(cid:4)(cid:7)
(cid:4)(cid:5)(cid:4)(cid:6)(cid:4)(cid:7)
(cid:4)(cid:8)(cid:9)
(cid:4)(cid:8)(cid:9)
(cid:2) (cid:4)(cid:13)(cid:10) (cid:4)(cid:13)(cid:11)
(cid:3)(cid:6)(cid:4)(cid:18)(cid:19)(cid:16)(cid:6)(cid:1)(cid:20)(cid:6)(cid:5)(cid:18)(cid:14)(cid:16)(cid:17)
Fig. 2: PATCHECKO’s static analysis of mobile/IoT ﬁrmware.
(cid:6)(cid:17)(cid:12)(cid:8)(cid:16)(cid:11)(cid:13)(cid:12)(cid:2)(cid:4)(cid:1)(cid:10)(cid:9)(cid:7)(cid:16)(cid:17)(cid:14)(cid:9)(cid:15)
(cid:6)(cid:17)(cid:12)(cid:8)(cid:16)(cid:11)(cid:13)(cid:12)(cid:2)(cid:5)(cid:1)(cid:10)(cid:9)(cid:7)(cid:16)(cid:17)(cid:14)(cid:9)(cid:15)
(cid:3)(cid:18)(cid:4)
Fig. 3: Sample feature vector for deep learning model.
PATCHECKO keeps the feature extraction rich (48 features),
efﬁcient (automated feature extraction) and scalable (multi-
architecture support).
Training the deep learning model. For PATCHECKO’s deep
learning, we adapt a sequential model that is composed of a
linear stack of layers. All hyperparameters were determined
empirically. Figure 3 shows a sample vector for training the
deep learning model. The sample vector is composed of the
function vector pairs and a bit indicating whether the two
functions are similar. Two similar feature vectors correspond
to the two subroutine (function) binaries that come from the
same source codes. Figure 4 depicts an actual example process
of training the model with a 6-layer network. We ﬁrst specify
the input for each layer. The ﬁrst layer in our sequential model
needs to receive information about its input shape. The model
is trained using the extracted function features in our dataset
built from 2,108 binaries with different architectures.
B. Pruning Candidate Functions (False Positives) via In-
Depth Dynamic Analysis
We use dynamic analysis to further prune the candidates
returned by the deep learning stage. This step determines
whether the reported pair of matching functions from the
previous stage are indeed a match (i.e. either a patched or
vulnerable function). This dynamic analysis step executes
candidate functions of the two binaries with the same inputs
and compares the observed behaviors and several features for
similarity.
Two functions may be compiled with different ﬂags. In
that case, the instruction execution traces of these functions
may differ drastically for the same input. Hence, our analysis
will consider the semantic similarity of the execution traces
in terms of the ultimate effect on the memory after the two
functions ﬁnish their execution on the identical input values.
To do so, we extract features from the execution traces
(dynamic features). Our approach compares the feature vectors
of the two traces that result from two function executions on
the same input values. If the observed features are similar
across different generated inputs, we assume that they are
semantically similar.
Figure 5 illustrates the workﬂow of PATCHECKO’s dynamic
analysis. There are a few challenges to apply the dynamic
analysis for actual execution. At ﬁrst, one resides in preparing
the execution environment. The second one simultaneously
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:28:40 UTC from IEEE Xplore.  Restrictions apply. 
376
(cid:3)(cid:5)(cid:12)
(cid:4)(cid:5)(cid:4)(cid:6)(cid:4)(cid:7)(cid:10)(cid:4)(cid:7)(cid:11)(cid:4)(cid:11)(cid:8)(cid:4)(cid:11)(cid:9)
(cid:3)(cid:6)(cid:12)
(cid:4)(cid:5)(cid:4)(cid:6)(cid:4)(cid:7)(cid:10)(cid:4)(cid:7)(cid:11)(cid:4)(cid:11)(cid:8)(cid:4)(cid:11)(cid:9)
(cid:1)(cid:1)(cid:1)(cid:2)
(cid:5)(cid:2)(cid:13)(cid:10)(cid:5)
(cid:5)(cid:2)(cid:13)(cid:9)(cid:10)
(cid:5)(cid:2)(cid:13)(cid:9)(cid:7)
(cid:14)
(cid:7)
(cid:6)
(cid:12)
(cid:13)
(cid:7)
(cid:7)
(cid:4)
(cid:5)(cid:2)(cid:13)(cid:8)(cid:12)
(cid:14)
(cid:5)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:7)(cid:2)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:11)(cid:2)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:6)(cid:5)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:6)(cid:7)(cid:2)(cid:9)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:6)(cid:9)
(cid:5)(cid:10)(cid:11)(cid:8)(cid:1)(cid:2)(cid:9)(cid:3)
(cid:5)(cid:2)(cid:13)(cid:8)(cid:8)
(cid:3)(cid:2)(cid:4)(cid:7)(cid:8)
(cid:3)(cid:2)(cid:4)(cid:6)(cid:8)
(cid:11)
(cid:11)
(cid:10)
(cid:4)
(cid:3)(cid:2)(cid:4)(cid:5)(cid:8)
(cid:11)
(cid:2)(cid:5)(cid:3)(cid:1)(cid:10)(cid:22)(cid:17)(cid:7)(cid:21)(cid:13)(cid:18)(cid:17)(cid:1)(cid:26)(cid:10)(cid:27)
(cid:3)(cid:24)(cid:9)(cid:7)(cid:22)(cid:21)(cid:13)(cid:18)(cid:17)(cid:1)(cid:9)(cid:17)(cid:23)(cid:13)(cid:19)(cid:18)(cid:17)(cid:16)(cid:9)(cid:17)(cid:21)
(cid:2)(cid:6)(cid:17)(cid:8)(cid:13)(cid:8)(cid:6)(cid:21)(cid:9)(cid:1)(cid:10)(cid:22)(cid:17)(cid:7)(cid:21)(cid:13)(cid:18)(cid:17)(cid:20)(cid:1)
(cid:26)(cid:11)(cid:27)
(cid:2)(cid:18)(cid:15)(cid:15)(cid:9)(cid:7)(cid:21)(cid:1)(cid:21)(cid:12)(cid:9)(cid:1)(cid:8)(cid:25)(cid:17)(cid:6)(cid:16)(cid:13)(cid:7)(cid:1)
(cid:21)(cid:19)(cid:6)(cid:7)(cid:13)(cid:17)(cid:11)(cid:1)(cid:13)(cid:17)(cid:10)(cid:18)(cid:19)(cid:16)(cid:6)(cid:21)(cid:13)(cid:18)(cid:17)(cid:1) (cid:6)(cid:17)(cid:8)(cid:1)
(cid:9)(cid:24)(cid:21)(cid:19)(cid:6)(cid:7)(cid:21)(cid:1)(cid:8)(cid:25)(cid:17)(cid:6)(cid:16)(cid:13)(cid:7)(cid:1)
(cid:10)(cid:9)(cid:6)(cid:21)(cid:22)(cid:19)(cid:9)(cid:20)
(cid:12)(cid:19)
(cid:21)(cid:22)(cid:14)(cid:15)(cid:1)(cid:3)(cid:1)(cid:14)(cid:16)(cid:15)(cid:23)
(cid:12)(cid:20)
(cid:21)(cid:22)(cid:14)(cid:15)(cid:1)(cid:3)(cid:1)(cid:14)(cid:16)(cid:15)(cid:23)
(cid:4)(cid:13)(cid:16)(cid:13)(cid:15)(cid:6)(cid:19)(cid:13)(cid:21)(cid:25)(cid:1)(cid:6)(cid:17)(cid:6)(cid:15)(cid:25)(cid:20)(cid:13)(cid:20)(cid:1)
(cid:6)(cid:17)(cid:8)(cid:1)(cid:19)(cid:6)(cid:17)(cid:14)(cid:13)(cid:17)(cid:11)
(cid:13)(cid:16)(cid:18)(cid:1)(cid:6)(cid:7)(cid:2)(cid:9)
(cid:13)(cid:16)(cid:17)(cid:1)(cid:8)(cid:10)(cid:2)(cid:4)
(cid:13)(cid:15)(cid:16)(cid:1)(cid:11)(cid:4)(cid:2)(cid:7)
(cid:13)(cid:16)(cid:16)(cid:1)(cid:11)(cid:5)(cid:2)(cid:6)
(cid:2)(cid:2)(cid:2)
(cid:13)(cid:9)(cid:5)(cid:7)(cid:7)(cid:7)(cid:5)(cid:7)(cid:7)(cid:7)(cid:1)(cid:27)(cid:15)(cid:22)(cid:25)(cid:21)(cid:17)(cid:1)(cid:30)(cid:17)(cid:16)(cid:28)(cid:24)(cid:26)(cid:27)
(cid:14)(cid:26)(cid:15)(cid:20)(cid:23)(cid:20)(cid:23)(cid:18)(cid:1)(cid:3)(cid:15)(cid:25)(cid:25)(cid:26)(cid:24)(cid:31)(cid:6)(cid:1)(cid:8)(cid:10)(cid:1)(cid:19)(cid:24)(cid:29)(cid:26)(cid:27)(cid:4)
(cid:3)(cid:2)(cid:4)(cid:4)(cid:8)
(cid:3)(cid:2)(cid:4)(cid:3)(cid:8)
(cid:3)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:5)(cid:2)(cid:8)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:8)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:9)(cid:2)(cid:8)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:4)(cid:3)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:4)(cid:5)(cid:2)(cid:8)(cid:1)(cid:1)(cid:1)(cid:1)(cid:4)(cid:8)
(cid:5)(cid:8)(cid:9)(cid:6)(cid:1)(cid:2)(cid:7)(cid:3)
(cid:12)(cid:11)(cid:2)(cid:1)(cid:15)(cid:16)(cid:16)(cid:29)(cid:26)(cid:15)(cid:16)(cid:32)
Fig. 4: Training the neural networks for automated ﬁrmware
vulnerability assessment of mobile/IoT ﬁrmware.
Fig. 5: PATCHECKO’s dynamic analysis. Given CVE function f
and a set of candidate functions g, collect the dynamic features
on given execution environments and compute the similarity
between CVE function and candidate functions based on
dynamic features vector.
TABLE I: Function features used in PATCHECKO.
Feature Name
num constant
num string
num inst
size local
fun ﬂag
num import
num ox
num cx
size fun
min i b
max i b
avg i b
std i b
min s b
max s b
avg s b
std s b
num bb
num edge
cyclomatic complexity
fcb normal
fcb indjump
fcb ret
fcb cndret
fcb noret
fcb enoret
fcb extern
fcb error
min call b
max call b
avg call b
std call b
sum call b
min arith b
max arith b
avg arith b
std arith b
sum arith b
min arith fp b
max arith fp b
avg arith fp b
std arith fp b
sum arith fp b
min betweeness cent
max betweeness cent
avg betweeness cent
std betweeness cent
betweeness cent zero
Feature Description
the number of constants value in the function
the number of strings in the function
the number of instruction in the function
the size of local variables in bytes
various ﬂags associated with a function, e.g., FUNC NORET, FUNC FAR.
the number of import functions
the number of code references from this function
the number of function calls from this function
the size of the function
the minimal number of instruction for basic block
the maximal number of instruction for basic block
the average number of instruction for basic block
the standard deviation of number of instruction for basic block
the minimal size of basic block
the maximal size of basic block
the average size of basic block
the standard deviation of size of basic block
the number of basic block for each function
the number of edge of among basic blocks for each function
function cyclomatic complexity = Edges - Nodes + 2
normal block type of function basic block
block ends with indirect jump
return block type of function basic block
conditional return block type of function basic block
noreturn block type of function basic block
external noreturn block (does not belong to the function)
external normal block type of function basic block
block passes execution past the function end
the minimal number of call instruction of each basic block
the maximal number of call instruction of each basic block
the average number of call instruction of each basic block
the standard deviation of call instruction of basic block
the total number of call instruction of the function
the minimal number of arithmetic instruction of each basic block
the maximal number of arithmetic instruction of each basic block
the average number of arithmetic instruction of each basic block
the standard deviation of arithmetic instruction of each basic block
the total number of arithmetic instruction of the function
the minimal number of arithmetic FP instruction of each basic block
the maximal number of arithmetic FP instruction of each basic block
the average number of arithmetic FP instruction of each basic block
the standard deviation number of arithmetic FP instruction of each basic block
the total number of arithmetic FP instruction of the function
the minimal number of betweeness centrality
the maximal number of betweeness centrality
the average number of betweeness centrality
the standard deviation number of betweeness centrality
how many node the betweeness centrality is zero
monitors the execution of multiple candidate functions. Fur-
thermore, because we are working in a heterogeneous mo-
bile/IoT ecosystem, concretely running binary code to obtain
execution traces is not trivial, especially since “valid” values
are required for correct function execution. We ﬁrst discuss the
preparation of the inputs that feed into the dynamic analysis
engine.
Inputs to the dynamic analysis engine. A key challenge in
implementing PATCHECKO’s dynamic analysis engine consists
of preparing the associated inputs. The dynamic analysis
the program binary, F, and the
engine takes two inputs:
execution environment of F. The program binary contains
the target function, f. One difﬁculty consists in isolating the
binary execution to the target function. One approach consists
of providing concrete and valid input values. This usually
requires loading and executing the entire program binary since
it is not possible to instruct the operating system to start
execution at a particular address. PATCHECKO solves this
problem by providing an execution environment that contains
the required execution state.
PATCHECKO uses fuzzing to generate different inputs for
functions
target functions to boost coverage of the associated CFG. For
each execution of a target function, PATCHECKO exports a
compact representation of a function-level executable, i.e., a
compact binary representation of the ﬁle that can be executed
dynamically using runtime DLL binary injection, as well
as the associated inputs that triggered that execution. This
allows the dynamic analysis execution engine to efﬁciently
execute the target function. This implies that PATCHECKO
will use multiple ﬁxed execution environments associated with
different inputs for target functions.
validation. Before
execution
Candidate
function
the
PATCHECKO begins
target
to instrument
execution, PATCHECKO uses multiple ﬁxed
execution
environments to perform execution on a large number of
candidate functions. There are several possible outcomes
after we start to run a target function, f. For example, the
candidate f may terminate, the candidate f may trigger a
system exception, or the candidate f may go into an inﬁnite
loop. If the candidate f triggers a system exception, we
will remove the candidate function from a candidate set.
After validating candidate functions execution with multiple
execution environments, the reserved candidate functions will
be instrumented.
Target function instrumentation. The output of the dy-
namic analysis engine for a function f in a ﬁxed execution
environment is a feature vector v(f, env) of length N. In
order to generate the feature vector, PATCHECKO traces the
function execution. For the actual dynamic analysis, a wealth
of systems are available such as debuggers, emulators, and
virtual machines. However, because of the heterogeneity of
mobile/IoT ﬁrmware architectures and platforms, PATCHECKO
utilizes an instrumentation tool
that supports a variety of
architectures and platforms accordingly.
PATCHECKO extracts particular features that capture a vari-
ety of instruction information (e.g., number of instructions),
system level
information (e.g., memory accesses), as well
as higher level attributes such as function and system calls.
Table II shows the initial set of features we initially considered
and eventually proved to be useful for establishing function bi-
nary similarity. However, this feature list is not comprehensive
and can easily be extended.
For each execution, the dynamic engine will generate a
set of observations for each feature, e.g., in the above case
there will be 21 sets of observations. Once all instructions for
a function f have been covered, PATCHECKO combines the
observations into a single vector, e.g., (finput_1). The same
process is repeated for different inputs for the same function
to produce (finput_2),(finput_3),...,(finput_N).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:28:40 UTC from IEEE Xplore.  Restrictions apply. 
377
Index
1
2