**信息中心日志运维的探索和实践**
关键字: 日志 大数据 运维
1.  **背景介绍**
随着海关信息化建设，业务正常运行对IT系统的依赖度逐步加大，海关信息系统及承载的物理环境日趋复杂并呈现多样化趋势，与此同时，信息系统中的主机、服务器、网络设备、安全设备、数据库以及各种应用服务系统在运行过程中会产生大量的运行日志、安全日志和行为日志，这些体量巨大的日志蕴含着丰富的信息。但目前信息中心日志缺乏统一管理，数据分散在各自管理部门，运维人员对于日志现状无直观总体了解。同时，了解现有日志现状，也是对日志高效分析、有效挖掘日志信息的前提。
2.  **发展现状**
海关信息中心经历了几十年的发展，已经形成了一整套覆盖海关业务的信息化系统，这些信息化系统为推动海关业务发展起到了至关重要的作用，除涉密系统外，海关信息化系统部署运行在运行网、管理网及对外接入局域网。目前海关信息化系统主要分为应用层、系统层和网络层三部分，并且信息安全贯穿三部分。
![](media/image1.emf)图1 海关网络拓扑图
## 日志情况
目前海关信息中心运行服务器573台，虚拟机1712台，小型机23台，对外接入局域网30台，运行网100台。海关日志主要分为应用日志、系统日志、网络日志及信息安全日志。每日数据量：业务日志800G、操作系统日志600G、网络设备日志500G、安全日志1000G，云平台、数据库、各省海关等其余日志数据2000G，数据中心日志量合计5T/天。
### 2.1.1 应用日志
海关基本通关业务系统分为贸易通关系统、个人间快件系统、跨境电子商务系统、旅客通关系统等，业务系统日志目前分散在各海关数据库中，日志存储时间半年至一年左右。
以贸易通关系统为例：核心系统通关审核、基础审单平均每天30万笔交易日志，整个交易经过30多个（申报、审单、缴税、放行等）业务系统，通关系统采用B/S
架构，利用人机交互方式实现，部分表单有唯一标识，因为历史原因有三个系统没有日志，有些系统日志记录不全，仅有告警信息，还有系统报错仅在客户端以弹出框方式告警，给整个运维造成很大困扰。
### 2.1.2 系统日志
系统日志包括各服务器操作系统日志、IBM小机操作系统日志、交换机、云平台、存储系统日志及中间件日志。目前未全部集中收集，仅有部分为系统部门工作人员用于查看系统情况，具体系统设备信息见附件1所示。
### 2.1.3 网络日志
网络日志包括相关网络设备日志，内容涉及主机信息、安全信息，目前已部分接入金关工程二期日志分析系统中，能实现基本的故障定位、链路监控。具体网络设备信息见附件1所示。
### 2.1.4 信息安全日志
安全运管中心的安全日志以事件形式存储，已在安全运管中心及金关工程二期日志分析系统集中采集，包括26类设备日志、操作日志；涵盖30家厂家的1000多台设备的日志，主要用于统计运行状态、登陆登出、攻击类型等；数据量每天800G，每七天归档一次。具体安全设备信息见附件2所示。
## 日志系统现状
目前海关日志主要分为应用日志、系统日志、网络日志及信息安全日志，已规划建立日志系统金关工程二期应用支撑平台日志管理系统和金关工程二期日志分析系统（B0507）。
### 金关工程二期应用支撑平台日志管理系统
规划中主要负责应用项目日志收集、存储、分析和展示，目前已经完成对各系统的对接，但目前并未开展收集工作，其中分析程度主要为错误信息聚合和展示。
### 金关工程二期日志分析系统
规划中主要负责基础平台的日志（包括系统日志和网络日志）及安全日志的汇总、存储、分析和展示，其中数据将在信息中心和上海大数据云各存储一份。目前已经完成网络及信息安全的接入工作，仅能根据网络监控数据结合阀值进行报警，缺乏实时检索、关联分析的能力。
### 安全运管中心
规划中用于海关安全大数据分析，安全日志以事件形式存储在数据库中，包括26类设备日志、操作日志；涵盖30家厂家的1000多台设备的日志，主要用于统计运行状态、登陆登出、攻击类型等；数据量每天800G，存储时间180天，每七天归档一次。
目前信息中心没有对日志进行整体管控，而按照日志大类由各部门独立进行管理，缺少对整体日志的使用场景规划，并直接造成日志存储分散------日志分散存储在金关工程二期应用支撑平台日志管理系统、金关工程二期日志分析系统，系统服务器日志没有纳入到金关工程二期日志分析系统。同时存储规范不统一，日志数据被应用项目割裂，各日志之间缺乏关联，无法形成对上层应用系统运行情况的分析及支撑，缺乏相关大数据分析工具，无法形成大数据分析及关联分析。
3.  **业界经验**
当前国内对日志系统的认识已经从最早的数据库存储发展到统一的日志管理平台，目前通过建立日志管理平台进行智能运维的案例已经成功运用于能源、金融、运营商等行业。日志管理中心不仅可以完成对主机、网络安全设备、数据库等基本设备的日志收集，而且对信息系统日志、安全审计日志等进行全面收集，对数据信息进行全面整合，从而方便利用大数据技术进行准实时数据检索、异常行为检测、日志关联分析、场景建模及综合研判等工作。
![](media/image2.png){width="5.773611111111111in"
height="5.560416666666667in"}
图2 功能架构图
建立集中制的日志管理平台，将分散的各类日志统一采集、统一处理，可以通过统一界面进行日志关联分析及复杂逻辑的实时监控告警服务，一旦发生故障技术人员无需登陆各台服务器进行人工排查，通过准实时检索快速定位，大幅度提升运维效率。当下主流的日志中心采用如下结构：
![](media/image3.png){width="6.273611111111111in"
height="2.553472222222222in"}
图3 日志中心IT架构图
整个系统可由多个模块构成，并支持资源横向拓展及功能模块重新分布，用户可以根据自身服务器资源、数据量、系统稳定性等因素自定义各个模块的节点组成，同时支持物理机和虚拟机混合部署，保证数据安全性。在数据量每日达到十几TB时，通过集群部署方式，借助云计算能力和存储的弹性扩展能力为日志管理中心提供可靠的运行环境，满足日志审查要求。
## 主要技术
上述功能架构图中所涉及技术如下：
### 数据摄取技术①
**Flume**：Flume可以从其他应用程序收集日志数据，然后将这些数据送入到**Hadoop**：官方网站声称："它功能强大、具有容错性，还拥有可以调整优化的可靠性机制和许多故障切换及恢复机制。"
**Sqoop**：企业经常需要在关系数据库与Hadoop之间传输数据，而Sqoop就是能完成这项任务的一款工具。它可以将数据导入到Hive或HBase，并从Hadoop导出到关系数据库管理系统（RDBMS）。
**Kafka**
：Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。
### ETL（萃取、转换）技术②
**Crunsh**：Crunch 是一个用 Go 语言开发的基于 Hadoop 的 ETL
和特性抽取工具，特点是速度快。
**Apache Falcon**：Apache
Falcon是一个面向Hadoop的、新的数据处理和管理平台，设计用于数据移动、数据管道协调、生命周期管理和数据发现。它使终端用户可以快速地将他们的数据及其相关的处理和管理任务"上载（onboard）"到Hadoop集群。
### 分析类库③
**SparkR**：SparkR是一个R语言包,它提供了轻量级的方式使得可以在R语言中使用Apache
Spark。
**Mathout**：Mahout 是 Apache Software Foundation（ASF）
旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用
Apache Hadoop 库，Mahout 可以有效地扩展到云中。
### 流式技术④
**Storm**：Storm现在是一个Apache项目，它提供了实时处理大数据的功能（不像Hadoop只提供批任务处理）。其用户包括推特、美国天气频道、WebMD、阿里巴巴、Yelp、雅虎日本、Spotify、Group、Flipboard及其他许多公司。
**Spark Streaming**：Spark
Streaming是一种构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。
### 批处理技术⑤
**MapReduce**：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念\"Map（映射）\"和\"Reduce（归约）\"，是它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。
当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。
### 引擎技术⑥
**Spark**：Spark是一种数据处理引擎。它声称，用在内存中时，其速度比MapReduce最多快100倍；用在磁盘上时，其速度比MapReduce最多快10倍。它可以与Hadoop和Apache
Mesos一起使用，也可以独立使用。
**Flink**：Apache
Flink是一个可伸缩的开源批处理和流处理平台。其核心模块是一个数据流引擎，该引擎在分布式的流数据处理的基础上提供数据分发、交流、以及容错的功能
4.  **统一的日志管理平台**
当前信息中心日志资源丰富，每日数据量达到TB级别，已经具备建立统一日志中心的条件，对全网设备、应用以及网络中的各类操作进行全面的日志采集，符合当下海关的日志管理需求；通过实时监控系统事件，并根据设定条件对日志数据进行过滤，同时将无序杂乱的非结构化的日志转换成结构化数据，提供统一管理方式，实现日志的日志持久化、标准化存储，从而符合标准政策规定内控需求；从IT
系统的行为、状态、配置、故障等事件中，自动产生趋势预判，提供准实时运维可用性监控及应用性能监控，帮助海关技术人员进行安全信息与实践管理、事件关联分析、在线业务统计分析等工作，提升工作效率，符合提升运维工作需求。
## 日志管理平台架构设计
对海关整体IT架构及业务流程做全面分析,针对海关业务特点，设计日志平台架构，实现日志集中采集、统一管理。
1.  消息队列技术 ②集群资源同步与管理技术
图4 日志中心总体架构图
-   物理支撑层：采用分布式集群方式搭建日志中心环境，借助云计算机能力和存储的弹性扩展能力为日志中心提供可靠的运行环境。
-   日志采集层：日志中心依据日志采集规范通过Agent、Syslog、ODBC、SNMP
    Trap、Socket、File等多种接口，采集各设备、系统和应用的本地型日志等；通过镜像等方式采集网络型日志，通过两种采集方式的合理配置，实现全部设备和资源的日志采集。
-   日志存储、加工层：实现日志的持久化、结构化存储，统一日志格式，并根据规则、策略库，对日志进行加工处理，结合资产信息实现日志信息的关联。
-   应用与展现层：实现系统管理、策略制定、规则制定、关键业务参数配置等基本业务功能，提供常用的告警分析场景，实现海量日志的快速查询，数据分析统计及可视化，并提供对外接口服务，方便系统进行二次开发。
## 模型的实现
### 日志采集技术
一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，支持在日志系统中定制各类数据发送方，用于收集数据；同时提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。
\(1\) 可靠性
当节点出现故障时，日志能够被传送到其他节点上而不会丢失。集群提供了end-to-end模式来保障可靠性：收到数据agent首先将event发送到后端消息队列集群，如果数据发送失败，将event写到磁盘上，可以重新发送。
\(2\) 可扩展性
模块完全是多主平行结构，不存在单点故障问题。
\(3\) 可管理性
每个节点均提供metric
api接口，以json格式数据展现服务状态，方便提供服务指标和运维监控。
### 消息队列技术
用于消息的持久化和缓存。该系统使用磁盘文件做持久化，顺序进行读写，以append方式写入文件。为减少内存copy，集群使用sendfile发送数据，通过合并message提升性能。集群本身不储存每个消息的状态，而使用（consumer/topic/partition）保存每个客户端状态，大大减小了维护每个消息状态的麻烦。在消息推拉的选择上，集群使用拉的方式，避免推的方式下存在的各个客户端的处理能力、流量等不同产生不确定性。以多机形式形成集群，建议3台或3台以上奇数台服务器组建，并且支持分区副本。
采用高吞吐量的分布式发布订阅消息系统有如下特性：