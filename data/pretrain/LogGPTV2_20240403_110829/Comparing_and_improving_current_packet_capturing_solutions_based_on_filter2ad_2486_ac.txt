### 4.2 Comparing Packet Capture Setups under Low Application Load

Applications that capture network traffic typically use libpcap [12], as discussed in Section 2.1. FreeBSD includes libpcap version 1.0.0 in its base system, and most Linux distributions also use this version. Our experiments reveal that the size of the memory-mapped area has minimal influence on performance. We conducted similar experiments with Berkeley Packet Filter (BPF) buffer sizes on FreeBSD and other buffer sizes on Linux. All these experiments showed that increasing the buffer size beyond a certain limit does not significantly boost capturing performance. Instead, we found that excessively large buffers can negatively impact capturing performance. These findings contradict those of Schneider et al. [4], who reported that larger buffers improve capturing performance.

The primary factor affecting performance is the capturing application itself. Our hardware, particularly the AMD platform, can transfer all packets from the network card to memory. If the software can process incoming packets faster than the wire-speed, the in-kernel buffers will never fill up, and there will be no packet loss. However, if the application cannot process packets as quickly as they arrive, increasing the buffer size will only reduce packet loss by the number of elements that can be stored in the buffer until it is filled.

Schneider et al. sent 1,000,000 packets per measurement run, while our tests involved generating packets at 1 GE speed (i.e., more than 100 Megabytes per second), resulting in over 1,000,000 packets per second over a 100-second interval. Increasing kernel buffer sizes to 20 megabytes, as recommended by Schneider et al., allows them to buffer a significant portion of their total packets but does not help much in the long term. In our experiments, increasing the buffers to the recommended size did not yield any significant improvements.

Buffer size can be crucial when the monitoring system cannot process packets at wire-speed. For example, if the system can consume up to N packets per second (pps) and bursty internet traffic is captured, having a sufficiently sized buffer to store burst packets is important. If the average traffic rate is less than or equal to N pps but has bursts with a higher pps rate, a well-dimensioned buffer is essential.

Another important parameter is the `transparent_mode` configuration option, which determines how PF_RING handles packets:
- **Transparent mode 0**: Captured packets are inserted into the ring via the standard Linux socket API.
- **Transparent mode 1**: The network card driver inserts packets directly into the ring (requiring an adapted network driver). Packets are also inserted into the standard Linux network stack.
- **Transparent mode 2**: Same as mode 1, but received packets are not copied into the standard Linux network stack (for PF_RING capturing only).

Transparent mode 2 performs best because it is optimized for capturing. We conducted comparisons using different packet sizes and rates and found that PF_RING performs best in this mode.

We expected PF_RING to outperform standard Linux capturing, especially with small packet sizes (64 bytes) and high packet rates, as seen in previous evaluations [8, 6]. According to Deri’s evaluation, capturing small packets should benefit from PF_RING. Figure 6 compares different libpcap versions on Linux and FreeBSD. Most Linux distributions now use libpcap-1.0.0, which includes shared-memory support. Our results show that libpcap-0.9.8 performs slightly better on Xeon, while libpcap-1.0.0 performs better on AMD. However, the differences are minor, so we used libpcap-1.0.0 for our experiments.

Figure 6 also reveals that the Xeon platform generally performs better than the AMD platform, which is surprising given the superior hardware performance of the AMD system. This discrepancy points to unknown performance issues on the AMD platform.

### 4.3 Comparing Packet Capture Setups under High Application Load

In the previous section, we analyzed capturing performance with low application load by writing captured packets to `/dev/null`. We now increase the application load by performing more computational work for each packet using the tool packzip, which compresses captured packets using libz [19]. The application load can be configured by changing the compression level of libz. Higher compression levels result in higher application load, though the load does not increase linearly. This is evident in the packet drop rates shown in Figure 10.

Figure 10 presents the results of capturing streams consisting of 512 and 256-byte packets at maximum wire-speed on the AMD platform. It clearly shows that higher application load leads to higher packet loss on both operating systems and with all capturing solutions presented in Section 2.1. Packet loss occurs when the available CPU processing power is insufficient to process all packets. We note that FreeBSD performs worse on the AMD platform compared to Linux with PF_PACKET under higher application loads.

However, when capturing a stream of 64-byte packets, we observe an unexpected effect, as shown in Figure 11. Initially, the overall capturing performance is worse with no application load (compression level 0) compared to capturing 256 and 512-byte packets. This is expected because capturing a large number of small packets is more challenging. Surprisingly, as the application load increases, the capturing performance also improves. This paradoxical effect is observed with PF_PACKET and PF_RING but is limited to Linux. FreeBSD is not affected by this phenomenon; instead, its capturing performance remains nearly constant with increasing application load but is almost always below Linux's performance.

To understand this perplexing phenomenon, we need to examine the packet capturing process in Linux. A key task in the capturing chain is passing a captured packet from the kernel to the application via a shared memory area (SHM) between the kernel and the application within libpcap. The SHM is associated with a socket to allow signaling between the kernel and the application if desired.

The packet transmission algorithm involves the following steps:
- The user application is ready to fetch a new packet.
- It checks SHM for new packets. If a new packet is found, it is processed.
- If no new packet is found, the `poll()` system call is issued to wait for new packets.
- The kernel receives a packet and copies it into SHM.
- The kernel informs the socket about the available packet, and `poll()` returns, allowing the user application to process the packet.

This algorithm is problematic because it involves many system calls if the application consumes packets very quickly, as noted in Deri’s prior work [8]. System calls are expensive operations, leading to context switches, cache invalidations, and new process scheduling. When the compression level increases, the time spent consuming packets also increases, reducing the number of system calls. Reducing the number of system calls is beneficial for the packet capture system.

There are several ways to reduce the number of system calls. One solution is to skip the `poll()` call and perform an active wait instead. However, this can cause problems: if capturing and analysis are scheduled on the same processor, polling in a user space process consumes valuable CPU time needed by the kernel. Even if they run on different cores, there are penalties due to memory access synchronization and cache invalidations. We patched libpcap to perform an active wait and found some, but only minor, improvements.

Another approach, proposed by Deri [8], is to perform a sleep operation for several nanoseconds if SHM is found to be empty. Although the sleep operation still involves a system call, it is better than multiple `poll()` calls, as it gives the kernel time to copy several packets into SHM. Deri suggested an adaptive sleep interval that adjusts based on the incoming packet rate.