mobile users tend to have less patience for videos to startup
as they tend to be busy and are “on the go”, resulting in
greater abandonment. Further assume that mobile users
tend to have larger startup delays due to poor wireless con-
nectivity.
In this situation, a correlation between startup
delay and abandonment may not imply causality unless we
can account for the confounding variable of how the viewer
is connected to the Internet. In our causal analyses, we sys-
tematically identify and account for all or a subset of the
following three categories of confounding variables as rele-
vant (see Figure 8).
Content. The video4 being watched could itself inﬂuence
both quality and viewer behavior. For instance, some
videos are more captivating than others leading view-
ers to watch more of it. Or, some videos may have
higher perceived value than others, leading viewers to
tolerate more startup delay. The manner in which the
video is encoded and the player heuristic used by the
4Note that our notion of video content is url-based and thus
also incorporates the content provider. If the same movie is
available from two content providers, they would constitute
two diﬀerent pieces of content for our analysis.
media player could also impact stream quality. For
instance, the player heuristics that could diﬀer from
one content provider to another speciﬁes how much of
the video needs to be buﬀered before the stream can
startup or resume play after rebuﬀering.
Connection Type. The manner in which a viewer con-
nects to the Internet, both the device used and typical
connectivity characteristics can inﬂuence both stream
quality and viewer behavior. We use the connection
type of the viewer as a confounding variable, where
the connection type can take discrete values such as
mobile, DSL, cable, and ﬁber (such as AT&T’s Uverse
and Verizon’s FiOS).
Geography. Geography of viewer captures several social,
economic, religious, and cultural aspects that can in-
ﬂuence viewer behavior. For instance, it has been ob-
served by social scientists that the level of patience
that consumers exhibit towards a delay in receiving
a product varies based on geography of the consumer
[5]. Such a phenomena might well be of signiﬁcance
in the extent to which the viewer’s behavior is altered
by stream quality. In our work, we analyze viewer’s
geography at the granularity of a country.
4.2.1 The Quasi Experimental Design (QED) Method
A primary technique for showing that an independent
variable X (called the treatment variable) has a causal im-
pact on a dependent variable Y (called the outcome vari-
able) is to design a controlled experiment. To design a true
experiment in our context, one would have to randomly as-
sign viewers to diﬀering levels of stream quality (i.e., values
of X) and observe the resultant viewer behaviors (values of
Y ). The random assignment in such an experiment removes
any systematic bias due to the confounding variables that
are threats to a causal conclusion. However, the level of
control needed to perform such an experiment at scale for
our problem is either prohibitively hard, expensive, or even
impossible.
In fact, there are legal, ethical, and other is-
sues with intentionally degrading the stream quality of a set
of viewers to do a controlled experiment. However, there
are other domains were a controlled experiment can and are
performed, example, A|B testing of web page layouts [11].
Given the inability to perform true experiments, we adapt
a technique called QED to discover causal relationships from
observational data that already exists. QEDs were devel-
oped by social and medical scientists as a similar inability
to perform controlled experiments is very common in those
domains [23]. In particular, we use a speciﬁc type of QED
called the matched design [18] where a treated individual
(in our case, a view or viewer) is randomly matched with
an untreated individual, where both individuals have identi-
cal values for the confounding variables. Consequently, any
diﬀerence in the outcome for this pair can be attributed to
the treatment. Our population typically consists of views or
viewers and treatment variable is typically is binary. For in-
stance, in Section 7, viewers who experienced “bad” stream
quality in the form a failed visit are deemed to be treated
and viewers who had normal experience are untreated. We
form comparison sets by randomly matching each treated
viewer with an untreated viewer such that both viewers are
as identical as possible on the confounding variables. Need-
less to say, the more identical the viewers are in each pair
216the more eﬀective the matching is in neutralizing the con-
founding variables. Note that matching ensures that the
distributions of the confounding variables in the treated and
untreated set of viewers are identical, much as if viewers were
randomly assigned to treated and untreated sets in a con-
trolled experiment. Now, by studying the behavioral out-
comes of matched pairs one can deduce whether or not the
treatment variable X has a causal eﬀect on variable Y , with
the inﬂuence of the confounding variables neutralized. Note
that treatment variable need not always be stream quality.
Depending on the causal conclusion, we could choose the
treatment variable to content length or connection type, if
we would like to study their impact on viewer behavior.
Statistical Signiﬁcance of the QED Analysis.
As with any statistical analysis, it is important to evalu-
ate whether the results are statistically signiﬁcant or if they
could have occurred by random chance. As is customary in
hypothesis testing [14], we state a null hypothesis Ho that
contradicts the assertion that we want establish. That is,
Ho contradicts the assertion that X impacts Y and states
that the treatment variable X has no impact on the outcome
variable Y . We then compute the “p-value” deﬁned to be the
probability that the null hypothesis Ho is consistent with the
observed results. A “low” p-value lets us reject the null hy-
pothesis, bolstering our conclusions from the QED analysis
as being statistically signiﬁcant. However, a “high” p-value
would not allow us to reject the null hypothesis. That is, the
QED results could have happened through random chance
with a “suﬃciently” high probability that we cannot reject
Ho. In this case, we conclude that the results from the QED
analysis are not statistically signiﬁcant.
The deﬁnition of what constitutes a “low” p-value for a
result to be considered statistically signiﬁcant is somewhat
arbitrary.
It is customary in the medical sciences to con-
clude that a treatment is eﬀective if the p-value is at most
0.05. The choice of 0.05 as the signiﬁcance level is largely
cultural and can be traced back to the classical work of R.A.
Fisher about 90 years ago. Many have recently argued that
the signiﬁcance level must be much smaller. We concur and
choose the much more stringent 0.001 as our signiﬁcance
level, a level achievable in our ﬁeld given the large amount of
experimental subjects (tens of thousands treated-untreated
pairs) but is rarely achievable in medicine with human sub-
jects (usually in the order of hundreds of treated-untreated
pairs). However, our results are unambiguously signiﬁcant
and not very sensitive to the choice of signiﬁcance level. All
our results turned out to be highly signiﬁcant with p-values
of 4×10−5 or smaller, except for one conclusion with a larger
p-value that we deemed statistically insigniﬁcant.
The primary technique that we employ for evaluating sta-
tistical signiﬁcance is the sign test that is a non-parametric
test that makes no distributional assumptions and is par-
ticularly well-suited for evaluating matched pairs in a QED
setting [26]. We sketch the intuition of the technique here,
while deferring the speciﬁcs to the technical sections. For
each matched pair (u, v), where u received treatment and
v did not receive treatment, we deﬁne the diﬀerential out-
come denoted by outcome(u, v) as the numerical diﬀerence
If Ho holds,
in the outcome of u and the outcome of v.
then the outcomes of the treated and untreated individuals
are identically distributed, since the treatment is assumed
to have no impact on the outcome. Thus, the diﬀerential
outcome is equally likely to be a positive number as a neg-
ative number. Thus, for n independently selected matched
pairs, the number of positive values of the diﬀerential out-
come (call it X) follows the binomial distribution with n
trials and probability 1/2. In a measured sample consisting
of a total of n non-zero values of the diﬀerential outcome,
suppose that x have positive values. Given that Ho holds,
the probability (i.e., p-value) of such an occurrence is at
most P rob (|X − n/2|≥| x − n/2|) , which is sum of both
tails of the binomial distribution. Evaluating the above tail
probability provides us the required bound on the p-value.
As an aside, note that a diﬀerent but distribution-speciﬁc
signiﬁcance test called the paired T-test may be applicable in
other QED situations. A paired T-test uses the Student’s T
distribution and requires that the diﬀerential outcome has a
normal distribution. Since our diﬀerential outcome does not
have a normal distribution, we rely on the distribution-free
non-parametric sign test that is more generally applicable.
Some Caveats.
It is important to understand the limitations of our QED
tools, or for that matter any experimental technique of infer-
ence. Care should be taken in designing the quasi-experiment
to ensure that the major confounding variables are explicitly
or implicitly captured in the analysis. If there exists con-
founding variables that are not easily measurable (example,
the gender of the viewer) and/or are not identiﬁed and con-
trolled, these unaccounted dimensions could pose a risk to a
causal conclusion, if indeed they turn out to be signiﬁcant.
Our work on deriving a causal relationship by systematically
accounting for the confounding variables must not be viewed
as a deﬁnitive proof of causality, as indeed there can be no
deﬁnitive proof of causality. But, rather, our work increases
the conﬁdence in a causal conclusion by accounting for po-
tential major sources of confounding. This is of course a
general caveat that holds for all domains across the sciences
that attempt to infer causality from observational data.
5. VIEWER ABANDONMENT
We address the question of how long a viewer will wait
for the stream to start up, a question of great importance
that has not been studied systematically to our knowledge.
However, the analogous problem of how long a user will wait
for web content to download has received much attention.
In 2006, Jupiter Research published a study based on inter-
viewing 1,058 online shoppers and postulated what is known
in the industry as the “4-second rule” that states that an av-
erage online shopper is likely to abandon a web site if a
web page does not download in 4 seconds [21]. But, a recent
study [16] implied that the users have become impatient over
time and that even a 400 ms delay can make users search
less. Our motivation is to derive analogous rules for stream-
ing where startup delay for video is roughly analogous to
download time for web pages.
Assertion 5.1. An increase in startup delay causes more
abandonment of viewers.
To investigate if our assertion holds, we classify each view
into 1-second buckets based on their startup delay. We then
compute for each bucket the percentage of views assigned
to that bucket that were abandoned. From Figure 9, we see
that the percent of abandoned views and startup delay are
positively correlated with a Kendall correlation of 0.72.
217Figure 9: Percentage of abandoned views and
startup delay are positively correlated.
Suppose now that we build a media delivery service that
provides a startup delay of exactly x seconds for every view.
What percent of views delivered by this system will be aban-
doned? To estimate this metric, we deﬁne a function called
AbandonmentRate(x) that equals
100 × Impatient(x)/(Impatient(x) + Patient(x)),
where Impatient(x) is all views that were abandoned af-
ter experiencing less than x seconds of startup delay and
Patient(x) are views where the viewer waited at least x time
without abandoning. That is, Impatient(x) (resp., Patient(x))
corresponds to views where the viewer did not (resp., did)
demonstrate the patience to hold on for x seconds with-
out abandoning. Note that a view in Patient(x) could still
have been abandoned at some time greater than x. Also,
note that a view where the video started to play before x
seconds does not provide any information on whether the
viewer would have waited until x seconds or not, and so
is considered neither patient or impatient. Figure 10 shows
the abandonment rate computed from our data which is near
zero for the ﬁrst 2 seconds, but starts to rise rapidly as the
startup delay increases. Fitting a simple regression to initial
part of the curve shows that abandonment rate increases by
5.8% for each 1-second increase in startup delay.
Assertion 5.2. Viewers are less tolerant of startup delay
for short videos in comparison to longer videos.
Researchers who study the psychology of queuing [13] have
shown that people have more patience for waiting in longer
queues if the perceived value of the service that they are
waiting for is greater. Duration of the service often inﬂu-
ences its perceived value with longer durations often per-
ceived as having greater value. People often tolerate the 30
minute delay for the checkin process for a 4-hour plane ride
but would ﬁnd the same wait excessive for a 10-minute bus
ride. On the same principle, is it true that viewers would
Figure 10: Viewers start to abandon the video if the
startup delay exceeds about 2 seconds. Beyond that
point, a 1-second increase in delay results in roughly
a 5.8% increase in abandonment rate.
be more patient for the video to startup if they expect to be
watching the video for longer period of time?
To investigate our assertion, we ﬁrst classify the views
based on whether the content is short with duration smaller
than 30 minutes (e.g., news clip), or long with duration
longer than 30 minutes (e.g., movies). The Kendall cor-
relation between the two variables, percent of abandoned
videos and startup delay, were 0.68 and 0.90 for short and
long videos respectively, indicating a strong correlation for
each category. Further, Figure 11 shows abandonment rate
for each type of content as a function of the startup delay.
One can see that viewers typically abandon at a larger rate
for short videos than for long videos.
Assertion 5.3. Viewers watching videos on a better con-
nected computer or device have less patience for startup de-
lay and so abandon sooner.
The above assertion is plausible because there is some ev-
idence that users who expect faster service are more likely
to be disappointed when that service is slow. In fact, this
is often touted as a reason for why users are becoming less
and less able to tolerate web pages that download slowly. To
study whether or not this is true in a scientiﬁc manner, we
segment our views into four categories based on their con-
nection type that indicates how the corresponding viewer
is connected to the Internet. The categories in roughly the
increasing order of connectivity are mobile, DSL, cable mo-
dem, and ﬁber (such as Verizon FIOS or AT&T Uverse).
In all four categories, we see a strong correlation between
the two variables, percent of abandoned views and startup
delay. The Kendall correlations for mobile, DSL, cable, and
ﬁber are 0.68, 0.74, 0.71, and 0.75 respectively. Further, in
Figure 12, we show the abandonment rate for each connec-
tion type. We can see that viewers abandon signiﬁcantly
less on mobile in comparison with the other categories, for
218Figure 11: Viewers abandon at a higher rate for
short videos than for long videos.
Figure 12: Viewers who are better connected aban-
don sooner.
a given startup delay. Some diﬀerence in abandonment is
discernible between the other categories in the rough order
of cable, DSL, and ﬁber though they are much smaller.
5.1 QED for Assertion 5.2
First, we devise a QED to study the impact of content
length on abandonment (Assertion 5.2). Therefore, we make
the content length (long or short) the treatment variable and
the outcome measures patience of the viewer to startup de-
lay. The viewer’s patience to startup delay can be inﬂuenced
by both the viewer’s geography and connection type which
we use as the confounding variables. Speciﬁcally, we form
matched pairs (u, v) such that view u is a short video that
was abandoned and view v is a long video that was aban-
doned and u and v are watched by viewers from the same
geography, and the viewers have the same connection type.