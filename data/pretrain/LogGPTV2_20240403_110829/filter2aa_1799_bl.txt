pushlocks require only the size of a pointer in storage (4 bytes on 32-bit systems, and 8 bytes on 64-bit 
systems). When a thread acquires a normal pushlock, the pushlock code marks the pushlock as owned 
if it is not currently owned. If the pushlock is owned exclusively or the thread wants to acquire the 
thread exclusively and the pushlock is owned on a shared basis, the thread allocates a wait block on 
associated with the pushlock. When a thread releases a pushlock, the thread wakes a waiter, if any are 
Because a pushlock is only pointer-sized, it actually contains a variety of bits to describe its state. 
The meaning of those bits changes as the pushlock changes from being contended to noncontended. 
In its initial state, the pushlock contains the following structure:
I 
One lock bit, set to 1 if the lock is acquired
I 
One waiting bit, set to 1 if the lock is contended and someone is waiting on it
I 
optimized
I 
One multiple shared bit, set to 1 if the pushlock is shared and currently acquired by more than
one thread
I 
28 (on 32-bit Windows) or 60 (on 64-bit Windows) share count bits, containing the number of
threads that have acquired the pushlock
As discussed previously, when a thread acquires a pushlock exclusively while the pushlock is already 
acquired by either multiple readers or a writer, the kernel allocates a pushlock wait block. The structure 
of the pushlock value itself changes. The share count bits now become the pointer to the wait block. 
-
tive to force it to be 16-byte aligned, the bottom 4 bits of any pushlock wait-block structure will be all 
zeros. Therefore, those bits are ignored for the purposes of pointer dereferencing; instead, the 4 bits 
shown earlier are combined with the pointer value. Because this alignment removes the share count 
bits, the share count is now stored in the wait block instead.
A cache-aware pushlock adds layers to the normal (basic) pushlock by allocating a pushlock for each 
processor in the system and associating it with the cache-aware pushlock. When a thread wants to 
CHAPTER 8 System mechanisms
201
acquire a cache-aware pushlock for shared access, it simply acquires the pushlock allocated for its cur-
rent processor in shared mode; to acquire a cache-aware pushlock exclusively, the thread acquires the 
pushlock for each processor in exclusive mode.
As you can imagine, however, with Windows now supporting systems of up to 2560 processors, the 
number of potential cache-padded slots in the cache-aware pushlock would require immense fixed al-
locations, even on systems with few processors. Support for dynamic hot-add of processors makes the 
problem even harder because it would technically require the preallocation of all 2560 slots ahead of 
time, creating multi-KB lock structures. To solve this, modern versions of Windows also implement the 
auto-expand push lock. As the name suggests, this type of cache-aware pushlock can dynamically grow 
the number of cache slots as needed, both based on contention and processor count, while guarantee-
ing forward progress, leveraging the executive’s slot allocator, which pre-reserves paged or nonpaged 
pool (depending on flags that were passed in when allocating the auto-expand pushlock).
Unfortunately for third-party developers, cache-aware (and their newer cousins, auto-expand) 
pushlocks are not officially documented for use, although certain data structures, such as FCB Headers in 
Windows 10 21H1 and later, do opaquely use them (more information about the FCB structure is available 
in Chapter 11.) Internal parts of the kernel in which auto-expand pushlocks are used include the memory 
manager, where they are used to protect Address Windowing Extension (AWE) data structures. 
Finally, another kind of nondocumented, but exported, push-lock is the address-based pushlock, 
which rounds out the implementation with a mechanism similar to the address-based wait we’ll shortly 
see in user mode. Other than being a different “kind” of pushlock, the address-based pushlock refers 
more to the interface behind its usage. On one end, a caller uses ExBlockOnAddressPushLock, passing 
in a pushlock, the virtual address of some variable of interest, the size of the variable (up to 8 bytes), 
and a comparison address containing the expected, or desired, value of the variable. If the variable 
does not currently have the expected value, a wait is initialized with ExTimedWaitForUnblockPushLock. 
This behaves similarly to contended pushlock acquisition, with the difference that a timeout value can 
be specified. On the other end, a caller uses ExUnblockOnAddressPushLockEx after making a change 
to an address that is being monitored to signal a waiter that the value has changed. This technique 
is especially useful when dealing with changes to data protected by a lock or interlocked operation, 
so that racing readers can wait for the writer’s notification that their change is complete, outside of a 
lock. Other than a much smaller memory footprint, one of the large advantages that pushlocks have 
over executive resources is that in the noncontended case they do not require lengthy accounting and 
integer operations to perform acquisition or release. By being as small as a pointer, the kernel can use 
atomic CPU instructions to perform these tasks. (For example, on x86 and x64 processors, lock cmpxchg 
is used, which atomically compares and exchanges the old lock with a new lock.) If the atomic compare 
and exchange fails, the lock contains values the caller did not expect (callers usually expect the lock to 
be unused or acquired as shared), and a call is then made to the more complex contended version. 
To improve performance even further, the kernel exposes the pushlock functionality as inline 
functions, meaning that no function calls are ever generated during noncontended acquisition—the 
assembly code is directly inserted in each function. This increases code size slightly, but it avoids the 
slowness of a function call. Finally, pushlocks use several algorithmic tricks to avoid lock convoys (a 
situation that can occur when multiple threads of the same priority are all waiting on a lock and little 
202 
CHAPTER 8 System mechanisms
actual work gets done), and they are also self-optimizing: the list of threads waiting on a pushlock will 
be periodically rearranged to provide fairer behavior when the pushlock is released.
One more performance optimization that is applicable to pushlock acquisition (including for address-
based pushlocks) is the opportunistic spinlock-like behavior during contention, before performing the 
dispatcher object wait on the pushlock wait block’s event. If the system has at least one other unparked 
processor (see Chapter 4 of Part 1 for more information on core parking), the kernel enters a tight spin-
based loop for ExpSpinCycleCount cycles just like a spinlock would, but without raising the IRQL, issuing 
a yield instruction (such as a pause on x86/x64) for each iteration. If during any of the iterations, the push-
lock now appears to be released, an interlocked operation to acquire the pushlock is performed.
If the spin cycle times out, or the interlocked operation failed (due to a race), or if the system does 
not have at least one additional unparked processor, then KeWaitForSingleObject is used on the event 
object in the pushlock wait block. ExpSpinCycleCount is set to 10240 cycles on any machine with more 
than one logical processor and is not configurable. For systems with an AMD processor that imple-
ments the MWAITT (MWAIT Timer) specification, the monitorx and mwaitx instructions are used 
instead of a spin loop. This hardware-based feature enables waiting, at the CPU level, for the value at an 
address to change without having to enter a loop, but they allow providing a timeout value so that the 
wait is not indefinite (which the kernel supplies based on ExpSpinCycleCount).
On a final note, with the introduction of the AutoBoost feature (explained in Chapter 4 of Part 1), 
pushlocks also leverage its capabilities by default, unless callers use the newer ExXxxPushLockXxxEx, 
functions, which allow passing in the EX_PUSH_LOCK_FLAG_DISABLE_AUTOBOOST flag that disables 
the functionality (which is not officially documented). By default, the non-Ex functions now call the 
newer Ex functions, but without supplying the flag.
Address-based waits
Based on the lessons learned with keyed events, the key synchronization primitive that the Windows 
kernel now exposes to user mode is the alert-by-ID system call (and its counterpart to wait-on-alert-by-
ID). With these two simple system calls, which require no memory allocations or handles, any number 
of process-local synchronizations can be built, which will include the addressed-based waiting mecha-
nism we’re about to see, on top of which other primitives, such as critical sections and SRW locks, are 
based upon.
Address-based waiting is based on three documented Win32 API calls: WaitOnAddress, WakeBy 
AddressSingle, and WakeByAddressAll. These functions in KernelBase.dll are nothing more than for-
warders into Ntdll.dll, where the real implementations are present under similar names beginning with 
Rtl, standing for Run Time Library. The Wait API takes in an address pointing to a value of interest, the 
size of the value (up to 8 bytes), and the address of the undesired value, plus a timeout. The Wake APIs 
take in the address only.
First, RtlWaitOnAddress builds a local address wait block tracking the thread ID and address and 
inserts it into a per-process hash table located in the Process Environment Block (PEB). This mir-
rors the work done by ExBlockOnAddressPushLock as we saw earlier, except that a hash table wasn’t 
needed because the caller had to store a push lock pointer somewhere. Next, just like the kernel API, 
RtlWaitOnAddress checks whether the target address already has a value different than the undesirable 
CHAPTER 8 System mechanisms
203
one and, if so, removes the address wait block, returning FALSE. Otherwise, it will call an internal func-
tion to block.
If there is more than one unparked processor available, the blocking function will first attempt to 
avoid entering the kernel by spinning in user mode on the value of the address wait block bit indicating 
availability, based on the value of RtlpWaitOnAddressSpinCount, which is hardcoded to 1024 as long as 
the system has more than one processor. If the wait block still indicates contention, a system call is now 
made to the kernel using NtWaitForAlertByThreadId, passing in the address as the hint parameter, as 
well as the timeout.
If the function returns due to a timeout, a flag is set in the address wait block to indicate this, and 
the block is removed, with the function returning STATUS_TIMEOUT. However, there is a subtle race 
condition where the caller may have called the Wake function just a few cycles after the wait has timed 
out. Because the wait block flag is modified with a compare-exchange instruction, the code can detect 
this and actually calls NtWaitForAlertByThreadId a second time, this time without a timeout. This is 
guaranteed to return because the code knows that a wake is in progress. Note that in nontimeout 
cases, there’s no need to remove the wait block, because the waker has already done so.
On the writer’s side, both RtlWakeOnAddressSingle and RtlWakeOnAddressAll leverage the same 
helper function, which hashes the input address and looks it up in the PEB’s hash table introduced 
earlier in this section. Carefully synchronizing with compare-exchange instructions, it removes the 
address wait block from the hash table, and, if committed to wake up any waiters, it iterates over all 
matching wait blocks for the same address, calling NtAlertThreadByThreadId for each of them, in the 
All usage of the API, or only the first one, in the Single version of the API.
With this implementation, we essentially now have a user-mode implementation of keyed events 
that does not rely on any kernel object or handle, not even a single global one, completely removing 
any failures in low-resource conditions. The only thing the kernel is responsible for is putting the thread 
in a wait state or waking up the thread from that wait state.
The next few sections cover various primitives that leverage this functionality to provide synchroni-
zation during contention.
Critical sections
Critical sections are one of the main synchronization primitives that Windows provides to user-mode 
application developers on top of the kernel-based synchronization primitives. Critical sections and the 
other user-mode primitives you’ll see later have one major advantage over their kernel counterparts, 
which is saving a round trip to kernel mode in cases in which the lock is noncontended (which is typi-
cally 99 percent of the time or more). Contended cases still require calling the kernel, however, because 
it is the only piece of the system that can perform the complex waking and dispatching logic required 
to make these objects work. 
Critical sections can  remain in user mode by using a local bit to provide the main exclusive locking 
logic, much like a pushlock. If the bit is 0, the critical section can be acquired, and the owner sets the bit 
to 1. This operation doesn’t require calling the kernel but uses the interlocked CPU operations dis-
cussed earlier. Releasing the critical section behaves similarly, with bit state changing from 1 to 0 with 
204 
CHAPTER 8 System mechanisms
an interlocked operation. On the other hand, as you can probably guess, when the bit is already 1 and 
another caller attempts to acquire the critical section, the kernel must be called to put the thread in a 
wait state. 
Akin to pushlocks and address-based waits, critical sections implement a further optimiza-
tion to avoid entering the kernel: spinning, much like a spinlock (albeit at IRQL 0—Passive Level) 
on the lock bit, hoping it clears up quickly enough to avoid the blocking wait. By default, this 
is set to 2000 cycles, but it can be configured differently by using the InitializeCriticalSectionEx 
or InitializeCriticalSectionAndSpinCount API at creation time, or later, by calling 
SetCriticalSectionSpinCount. 
Note As we discussed, because WaitForAddressSingle already implements a busy spin wait 
as an optimization, with a default 1024 cycles, technically there are 3024 cycles spent spin-
ning by default—first on the critical sections’ lock bit and then on the wait address block’s 
lock bit, before actually entering the kernel.
When they do need to enter the true contention path, critical sections will, the first time they’re 
called, attempt to initialize their LockSemaphore field. On modern versions of Windows, this is only done 
if RtlpForceCSToUseEvents is set, which is the case if the KACF_ALLOCDEBUGINFOFORCRITSECTIONS 
(0x400000) flag is set through the Application Compatibility Database on the current process. If the flag 
is set, however, the underlying dispatcher event object will be created (even if the field refers to sema-
phore, the object is an event). Then, assuming that the event was created, a call to WaitForSingleObject is 
performed to block on the critical section (typically with a per-process configurable timeout value, to aid 
in the debugging of deadlocks, after which the wait is reattempted).
In cases where the application compatibility shim was not requested, or in extreme low-memory 
conditions where the shim was requested but the event could not be created, critical sections no 
longer use the event (nor any of the keyed event functionality described earlier). Instead, they directly 
leverage the address-based wait mechanism described earlier (also with the same deadlock detection 
timeout mechanism from the previous paragraph). The address of the local bit is supplied to the call 
to WaitOnAddress, and as soon as the critical section is released by LeaveCriticalSection, it either calls 
SetEvent on the event object or WakeAddressSingle on the local bit.
Note Even though we’ve been referring to APIs by their Win32 name, in reality, critical 
sections are implemented by Ntdll.dll, and KernelBase.dll merely forwards the functions 
to identical functions starting with Rtl instead, as they are part of the Run Time Library. 
Therefore, RtlLeaveCriticalSection calls NtSetEvent. RtlWakeAddressSingle, and so on.
Finally, because critical sections are not kernel objects, they have certain limitations. The primary 
one is that you cannot obtain a kernel handle to a critical section; as such, no security, naming, or other 
Object Manager functionality can be applied to a critical section. Two processes cannot use the same 
critical section to coordinate their operations, nor can duplication or inheritance be used.
CHAPTER 8 System mechanisms
205
User-mode resources
User-mode resources also provide more fine-grained locking mechanisms than kernel primitives. A 
resource can be acquired for shared mode or for exclusive mode, allowing it to function as a multiple-
reader (shared), single-writer (exclusive) lock for data structures such as databases. When a resource is 
acquired in shared mode and other threads attempt to acquire the same resource, no trip to the kernel 
is required because none of the threads will be waiting. Only when a thread attempts to acquire the 
resource for exclusive access, or the resource is already locked by an exclusive owner, is this required.
To make use of the same dispatching and synchronization mechanism you saw in the kernel, resources 
make use of existing kernel primitives. A resource data structure (RTL_RESOURCE) contains handles 
to two kernel semaphore objects. When the resource is acquired exclusively by more than one thread, 
the resource releases the exclusive semaphore with a single release count because it permits only one 
owner. When the resource is acquired in shared mode by more than one thread, the resource releases 
the shared semaphore with as many release counts as the number of shared owners. This level of detail 
is typically hidden from the programmer, and these internal objects should never be used directly.
Resources were originally implemented to support the SAM (or Security Account Manager, which is 
discussed in Chapter 7 of Part 1) and not exposed through the Windows API for standard applications. 
Slim Reader-Writer Locks (SRW Locks), described shortly, were later implemented to expose a similar 
but highly optimized locking primitive through a documented API, although some system components 
still use the resource mechanism.
Condition variables
Condition variables provide a Windows native implementation for synchronizing a set of threads that 
are waiting on a specific result to a conditional test. Although this operation was possible with other 
user-mode synchronization methods, there was no atomic mechanism to check the result of the condi-
tional test and to begin waiting on a change in the result. This required that additional synchronization 
be used around such pieces of code.
A user-mode thread initializes a condition variable by calling InitializeConditionVariable to set up the 
initial state. When it wants to initiate a wait on the variable, it can call SleepConditionVariableCS, which 
uses a critical section (that the thread must have initialized) to wait for changes to the variable, or, even 
better, SleepConditionVariableSRW, which instead uses a Slim Reader/Writer (SRW) lock, which we de-
scribe next, giving the caller the advantage to do a shared (reader) of exclusive (writer) acquisition.
Meanwhile, the setting thread must use WakeConditionVariable (or WakeAllConditionVariable) after 
it has modified the variable. This call releases the critical section or SRW lock of either one or all waiting 
threads, depending on which function was used. If this sounds like address-based waiting, it’s because 
it is—with the additional guarantee of the atomic compare-and-wait operation. Additionally, condition 
variables were implemented before address-based waiting (and thus, before alert-by-ID) and had to 
rely on keyed events instead, which were only a close approximation of the desired behavior.
Before condition variables, it was common to use either a notification event or a synchronization 
event (recall that these are referred to as auto-reset or manual-reset in the Windows API) to signal the 
206 
CHAPTER 8 System mechanisms
change to a variable, such as the state of a worker queue. Waiting for a change required a critical section 
to be acquired and then released, followed by a wait on an event. After the wait, the critical section 
had to be reacquired. During this series of acquisitions and releases, the thread might have switched 
contexts, causing problems if one of the threads called PulseEvent (a similar problem to the one that 
keyed events solve by forcing a wait for the signaling thread if there is no waiter). With condition 
variables, acquisition of the critical section or SRW lock can be maintained by the application while 
SleepConditionVariableCS/SRW is called and can be released only after the actual work is done. This 
makes writing work-queue code (and similar implementations) much simpler and predictable. 
With both SRW locks and critical sections moving to the address-based wait primitives, however, 
conditional variables can now directly leverage NtWaitForAlertByThreadId and directly signal the 
thread, while building a conditional variable wait block that’s structurally similar to the address wait 
block we described earlier. The need for keyed events is thus completely elided, and they remain only 
for backward compatibility.
Slim Reader/Writer (SRW) locks
Although condition variables are a synchronization mechanism, they are not fully primitive locks 
because they do implicit value comparisons around their locking behavior and rely on higher-
level abstractions to be provided (namely, a lock!). Meanwhile, address-based waiting is a primitive 
operation, but it provides only the basic synchronization primitive, not true locking. In between these 
two worlds, Windows has a true locking primitive, which is nearly identical to a pushlock: the Slim 
Reader/Writer lock (SRW lock). 
Like their kernel counterparts, SRW locks are also pointer sized, use atomic operations for acquisition 
and release, rearrange their waiter lists, protect against lock convoys, and can be acquired both in 
shared and exclusive mode. Just like pushlocks, SRW locks can be upgraded, or converted, from shared 
to exclusive and vice versa, and they have the same restrictions around recursive acquisition. The only 
real difference is that SRW locks are exclusive to user-mode code, whereas pushlocks are exclusive to 
kernel-mode code, and the two cannot be shared or exposed from one layer to the other. Because 
SRW locks also use the NtWaitForAlertByThreadId primitive, they require no memory allocation and are 
guaranteed never to fail (other than through incorrect usage).
Not only can SRW locks entirely replace critical sections in application code, which reduces the need to 
allocate the large CRITICAL_SECTION structure (and which previously required the creation of an event 
object), but they also offer multiple-reader, single-writer functionality. SRW locks must first be initialized 
with InitializeSRWLock or can be statically initialized with a sentinel value, after which they can be ac-
quired or released in either exclusive or shared mode with the appropriate APIs: AcquireSRWLockExclusive, 
ReleaseSRWLockExclusive, AcquireSRWLockShared, and ReleaseSRWLockShared. APIs also exist for op-
portunistically trying to acquire the lock, guaranteeing that no blocking operation will occur, as well as 
converting the lock from one mode to another.
CHAPTER 8 System mechanisms
207
Note Unlike most other Windows APIs, the SRW locking functions do not return with a 
value—instead, they generate exceptions if the lock could not be acquired. This makes 
it obvious that an acquisition has failed so that code that assumes success will terminate 
instead of potentially proceeding to corrupt user data. Since SRW locks do not fail due to 
resource exhaustion, the only such exception possible is STATUS_RESOURCE_NOT_OWNED 
in the case that a nonshared SRW lock is incorrectly being released in shared mode.
The Windows SRW locks do not prefer readers or writers, meaning that the performance for either 
case should be the same. This makes them great replacements for critical sections, which are writer-
only or exclusive synchronization mechanisms, and they provide an optimized alternative to resources. 
If SRW locks were optimized for readers, they would be poor exclusive-only locks, but this isn’t the 
case. This is why we earlier mentioned that conditional variables can also use SRW locks through the 
SleepConditionVariableSRW API. That being said, since keyed events are no longer used in one mecha-
nism (SRW) but are still used in the other (CS), address-based waiting has muted most benefits other 
than code size—and the ability to have shared versus exclusive locking. Nevertheless, code targeting 
older versions of Windows should use SRW locks to guarantee the increased benefits are there on 
kernels that still used keyed events.
Run once initialization
The ability to guarantee the atomic execution of a piece of code responsible for performing some sort 
of initialization task—such as allocating memory, initializing certain variables, or even creating objects 
on demand—is a typical problem in multithreaded programming. In a piece of code that can be called 
simultaneously by multiple threads (a good example is the DllMain routine, which initializes a DLL), there 
are several ways of attempting to ensure the correct, atomic, and unique execution of initialization tasks.
For this scenario, Windows implements init once, or one-time initialization (also called run once ini-