Figure 15: Google (AS15169) resolvers on 2020-02-06, dur-
ing .nz TsuNAME event: time in between queries for AAAA
queries
txt
[46] RIPE NCC. 2021. RIPE Atlas Measurement IDS. https://atlas.ripe.net/measu
rements/ID.
, where ID is the experiment ID: New Domain:25666966, Recur-
rent:25683316 , One-off-AfterGoogle: 29078085, RecurrentAfterGoogle: 29099244,
probe52196:29491104, TripeDep:29559226, CNAME: 29560025.
[47] RIPE NCC Staff. 2015. RIPE Atlas: A Global Internet Measurement Network.
Internet Protocol Journal (IPJ) 18, 3 (Sep 2015), 2ś26.
[48] RIPE Network Coordination Centre. 2020. RIPE Atlas. https://atlas.ripe.net.
[49] RIPE Network Coordination Centre. 2020. RIPE Atlas - Raw data structure
documentations,https://atlas.ripe.net/docs/data_struct/.
[50] Root Server Operators. 2015. Events of 2015-11-30. http://root-servers.org/ne
ws/events-of-20151130.txt.
[51] Root Server Operators. 2020. Root DNS. http://root-servers.org/.
[52] Root Zone file. 2020. Root. http://www.internic.net/domain/root.zone.
[53] Kyle Schomp, Tom Callahan, Michael Rabinovich, and Mark Allman. 2013. On
measuring the client-side DNS infrastructure. In Proceedings of the 2015 ACM
Conference on Internet Measurement Conference. ACM, 77ś90.
[54] SIDN Labs. 2020. ENTRADA - DNS Big Data Analytics. https://entrada.sidnlabs.
nl/.
[55] Raffaele Sommese, Leandro Bertholdo, Gautam Akiwate, Mattijs Jonker, van
Rijswijk-Deij, Roland, Alberto Dainotti, KC Claffy, and Anna Sperotto. 2020.
MAnycast2ÐUsing Anycast to Measure Anycast. In Proceedings of the ACM
Internet Measurement Conference. ACM, Pittsburgh, PA, USA. https://doi.org/10.
1145/3419394.3423646
[56] Suzanne Goldlust. 2018. Using the Response Rate Limiting Feature. https:
//kb.isc.org/docs/aa-00994.
[57] S. Thomson, C. Huitema, V. Ksinant, and M. Souissi. 2003. DNS Extensions to
Support IP Version 6. RFC 3596. IETF. http://tools.ietf.org/rfc/rfc3596.txt
[58] Sipat Triukose, Zakaria Al-Qudah, and Michael Rabinovich. 2009. Content De-
livery Networks: Protection or Threat?. In Computer Security ś ESORICS 2009,
Michael Backes and Peng Ning (Eds.). Springer Berlin Heidelberg, Berlin, Heidel-
berg, 371ś389.
[59] Roland van Rijswijk-Deij, Anna Sperotto, and Aiko Pras. 2014. DNSSEC and Its
Potential for DDoS Attacks: a comprehensive measurement study. In Proceedings
of the 2014 ACM Conference on Internet Measurement Conference (IMC). ACM,
449ś460.
[60] Duane Wessels and Marina Fomenkov. 2003. Wow, That’s a Lot of Packets. In
Proceedings of the Passive and Active Measurement Workshop. https://www.caida.
org/publications/papers/2003/dnspackets/wessels-pam2003.pdf
[61] Chris Williams. 2019. Bezos DDoS’d: Amazon Web Services’ DNS systems
knackered by hours-long cyber-attack. https://www.theregister.co.uk/2019/10/
22/aws_dns_ddos/.
[62] D. Wing and A. Yourtchenko. 2012. Happy Eyeballs: Success with Dual-Stack Hosts.
RFC 6555. IETF. http://tools.ietf.org/rfc/rfc6555.txt
[63] S. Woolf and D. Conrad. 2007. Requirements for a Mechanism Identifying a Name
Server Instance. RFC 4892. IETF. http://tools.ietf.org/rfc/rfc4892.txt
[64] Maarten Wullink, Giovane CM Moura, Moritz Müller, and Cristian Hesselman.
2016. ENTRADA: A high-performance network traffic data streaming warehouse.
In Network Operations and Management Symposium (NOMS), 2016 IEEE/IFIP. IEEE,
913ś918.
A EXTRA TABLE AND FIGURES
Figure 15 shows the AAAA queries for Google during the .nz event.
Figure 16 show a timeseries of daily queries per AS during the
.nz event.
411
 1 10 100 1000 10000 100000 1x106 1x107 1x108 0 200 400 600 800 1000 1200 1400 0 50000 100000 150000 200000ms (log)QueriesResolver (sorted by queries)TsuNAME
IMC ’21, November 2–4, 2021, Virtual Event, USA
B INFLUENCE OF RECURRENT QUERIES
In the ğ4.1 we establish the New domain for problematic resolvers
using a one-off configuration: we saw the volume of queries is time
dependent, and that roughly 574 resolvers (out of 11k, thus 5.1%)
are problematic.
To determine the influence of recurrent queries ś similar to
what happened with TsuNAMEś we now set up an experiment in
which we configure VPs to repeat queries every 10mins, as shown
in Table 3 (recurrent column). To avoid warming up caches, we
configure Atlas probes to query unique query names, with random
values (R in qname).
On the client side, we see 13k VPs in Table 3, which issued ∼727k
queries for this measurement. Most of them were answered as
SERVFAIL, similar to the one-off measurement.
On the authoritative server side (ns1 and ns2 in Table 3), we see a
different story: altogether, the authoritative servers received ∼70M
queries over the period ś an amplification factor of 99x compared
to the queries sent by Atlas VPs.
Influence of recurrent queries: Figure 18 shows the timeseries
of both queries and unique resolvers reaching our authoritative
servers. We see a large oscillation during the period in which At-
las is active ś anywhere from 1k to 8k are active at any moment
(Figure 18b). The reasons for that are twofold: some resolvers are
indeed in loop here, but also our is configure to send new queries
every 30min (Table 3). Similarly to ğ4.1, once Atlas stops sending
queries, we still see a portion of resolvers staying in loop. In fact, for
this measurement, we find 1423 resolvers from 192 ASes (Table 4)
that are in the loop mode.
Figure 19 shows the top 10 ASes sending queries our authori-
tative servers when atlas stopped, i.e., they should not have sent
any queries. We see that Google did roughly 60% of the queries
again, but similarly to the one-off measurement, other ASes have
the same issue.
Time in-between queries: Figure 20 shows the IQR and queries for
the top 50 resolvers in terms of query volume, that send A records
queries for a server for a qname in cyclic dependency. Compared
with the one-off case (Figure 7), we see a very similar pattern,
except for the volume of queries, which is larger, given that the
measurement was kept running for longer than the one-off.
The conclusion we can draw from this experiment is that more
client incoming queries will amplify even further the number of
queries experienced by authoritative servers.
C STOPPING THE SINKHOLE EXPERIMENT
We stop the sinkhole experiment in two steps: We do this in two
steps: first, we return these domains to their original, sinkholed
NS records ś as in the Pre phase. We do that by changing the NS
records in the parent DNS zone (.nl). In theory, this should redirect
all clients to the newly configured NS records. We see that most
of the resolvers do that, but we still keep on receiving queries on
the łoldž server (AWS route 53) ś the latter are referred to as child-
centric resolvers [55], as they trust the information of the child
zone delegation over the parent. We fully stop the experiment at
20:18 UTC, by removing the zones from AWS Route 53 (Delegation
removed phase). After that point, all clients of this domain query
the NS records of the Pre phase, which we do not monitor.
Figure 16: .nz event: queries per AS
Figure 17: Resolvers with at least 100x traffic growth (AAAA
queries)
AS Number
15169
23969
10013
36692
39289
3561
3452
16509
11233
45142
200050
30844
15267
AS name
Google
Country
US
TOT Public Company Limited
Thailand
FreeBit
Cisco OpenDNS
MediaSeti
CENTURYLINK
University of Alabama
Amazon, Inc
Gorge Networks
Loxley Wireless
ITSVision
Liquid Telecom
702 communications
Japan
US
Russia
US
US
US
US
Thailand
France
UK
US
Table 11: List of top ASes per volume of queries during ex-
periments and .nz event.
Figure 17 shows the resolvers with at least 100x traffic growth,
for AAAA queries, in the sinkhole experiment.
Table 11 shows the list of top ASes during the .nz event.
412
 100 10000 1x106 1x10830/0106/0213/0220/0227/02 Cyclic DependencyQueries (log)Day (2020)Google (AS15169)TOT (AS23969)FreeBit (AS10013)Amazon (AS16509)Vodafone (AS9500) 0 10000 20000 30000 40000 50000 1 2 4 8 16 32 64Queries Cy1hQueries NormalGoogleRestIMC ’21, November 2–4, 2021, Virtual Event, USA
G. C. M. Moura et al.
(a) Queries
(a) Queries
(b) Resolvers
(b) Resolvers
Figure 21: TripleDep measurement: Queries and unique re-
solvers querying authoritative servers (5min bins)
Figure 18: Recurrent: queries and unique resolvers time-
series (5min bins)
Figure 19: Recurrent experiment: queries per AS with prob-
lematic resolvers
Figure 20: Recurrent: IQR and queries for A records of
ns.vuur.cachetest.net
413
D LONGER AND CNAME CYCLES
In this section we investigate other types of loops, namely longer
cycles and CNAME-based loops.
D.1 Triple cyclic dependency
First, in measurement TripleDep (Table 3), we configure a triple
cyclic dependency (Table 12) to determine if resolvers would also
be vulnerable it, and what would be the impact compared to regular
cyclic dependencies.
Similarly to the New Domain experiment, we only configure the
probes to send 1 query per vantage point. We see in in Figure 21
the timeseries of queries and resolvers we see. Compared with the
New domain experiment (Figure 5), we see that the query rates
reduce very litte after Atlas stop sending queries (> 8:45). We see,
however, that only a fraction of resolvers remain active after Atlas
stops sending queries (Figure 21b).
Figure 22 shows the top 10 ASes for this experiment. We see that
it is similar to the ASes from the New Domain Experiment (Figure 6)
ś except for the fact that GDNS (AS15169) has been fixed in the
meantime, reducing the number of queries.
Figure 21 shows the timeseries results. We see that, differenlty
from the normal cyclic dependent domains, a triple cyclic depen-
dency query volume does not reduce as fast as the previous ones.
So making longer cycles will make the problem even worse.
D.2 CNAME cycles
We also ran an experiment with loops done with CNAME records [28],
which are like ‘aliases’ for a domain. We configured the experi-
ment CNAME in Table 3, in which we configure cyclic CNAMES:
 0 50 100 150 20012:0016:0020:0000:0004:0008:0012:0016:0020:0000:0004:0008:00Resolvers in Loop Oﬀ.Queries (k)Time (UTC) -- 2020-06-09cachetest.netverfwinkel.netAtlas active 0 2000 4000 6000 8000 1000016:0020:0000:0004:0008:0012:0016:0020:0000:0004:0008:00Resolvers in LoopOﬀ.Unique ResolversTime (UTC) -- 2020-06-09cachetest.netverfwinkel.netAtlas active 0 5 10 15 20151692000501526721085146884624255330781restMillion Queries 0 5 10 15 20151692000501526721085146884624255330781rest 1 10 100 1000 10000 5 10 15 20 25 30 35 40 45 50 1000 10000 100000 1x106 1x107 1x108msQueriesResolver (sorted by queries) 0 20 40 60 80 10008:3008:4509:0009:1509:3009:4510:0010:1510:3010:4511:0011:1511:30Resolvers in LoopOﬄineQueries (k)Time (UTC) -- 2021-04-13 -- 5min binscachetest.nlverfwinkel.netessedarius.net 0 5 10 15 2008:3008:4509:0009:1509:3009:4510:0010:1510:3010:4511:0011:1511:30Resolvers in LoopOﬄineResolvers (k)Time (UTC) -- 2021-04-13 -- 5min binscachetest.nlverfwinkel.netessedarius.netTsuNAME
IMC ’21, November 2–4, 2021, Virtual Event, USA
Zone
NS
TTL
jupiter.essedarius.net
mars.verfwinkel.net
vulcan.cachetest.nl
ns1.mars.verfwinkel.net
ns1.vulcan.cachetest.nl
ns1.jupiter.essedarius.net
1s
Table 12: Triple cyclic dependency configuration
1s
1s
Zones
Zones
platypus.essedarius.net
liger.verfwinkel.net
ns1.liger.verfwinkel.net
ns3.platypus.essedarius.net
60s
60s
NS
TTL
Table 13: Cyclic dependency for new one-off measurement.
loop by itself, it was its client population that would. Given Google
did not cache cyclic dependent records, queries from looping clients
were amplified and sent to authoritative servers.
Then, on Feb. 3rd, 2021, Google mitigated this vulnerability on
their Public DNS services, but implementing a cyclic dependent
detector and caching such records, so once it was cached, it would
not pass along any client queries ś blocking the effects of looping
downstream resolvers.
In this section, we reproduce the measurements made with RIPE
Atlas to determine the impact of Google’s mitigation.
E.1 Repeating lower-bound experiment
In ğ4.1, we configure ∼ 10k Atlas probes to send 1 query only to
each of their local resolvers, in order to measure the lower-bound of
amplification. In this section, we repeat that experiment in order to
determine how much of a problem is stil is after Google’s mitigation.
Table 13 shows the cyclic dependency we configured ś third
level domains not used before. We delete the record on Wed 10 Feb
2021 08:30 UTC, after keeping the cyclic dependency active for 12h
and 30min.
Figure 24 shows the results. We see that altogether, after no
more user queries, the authoritative servers receiving roughly 88k
queries/5min combined (both zones, in Figure 24a). Previously, this
value in Figure 5 was around 135k queries/5min. That is a 35%
reduction in the total query volume. We also found 1560 problem-
atic resolvers (Figure 24b), which are unique IP addresses sending
queries after the initial round of queries from the Atlas probes ś
resolvers in the Cyclic dependent phase. This number is, however,
larger than the one from Figure 5 ś but they generate fewer queries.
Table 14 shows the details of this measurement. We see that
18.5k VPs sent 18.6k queries, which resulted in 12.3M queries at the
authoritative server, in the 12.5h that this measurement lasted.
Figure 25 show the top10 ASes for this experiment. Compared
with before the mitigation (Figure 6), Google significantly reduce
its volume of queries, from roughly 4.5M to 400k (90%), even if this
measurement lasted for 12.5h instead of 6.
E.2 Repeating recurrent queries measurement
Next, we set out to repeat the measurement with recurrent queries
from Appendix B, after Google’s mitigation. Table 15 shows the
cyclically dependent zones we configured.
Figure 22: Top 10 ASes for TripleDep experiment
(a) Queries
(b) Resolvers
Figure 23: CNAME measurement: Queries and unique re-
solvers querying authoritative servers (5min bins)
minuano.essedarius.net ↔ tramontana.verfwinkel.net. Figure 23
shows the timeseries of queries. We see that most resolvers detect
the cycle, and do not begin to loop.
E IMPACT OF GOOGLE PUBLIC DNS
MITIGATION
We worked together with Google in helping to understand the
CycleHunter vulnerability. We determine that Google would not
414
 0 0.2 0.4 0.6 0.8 1 1.22000503084436692151695146829208846279228473RestMillion QueriesAS number 0 0.2 0.4 0.6 0.8 1 1.22000503084436692151695146829208846279228473Rest 0 10 20 30 40 5012:3012:4513:0013:1513:3013:4514:0014:1514:3014:4515:00Resolvers in LoopQueries (k)Time (UTC) -- 2021-04-13 -- 5min binsverfwinkel.netessedarius.net 0 5 10 15 2012:3012:4513:0013:1513:3013:4514:0014:1514:3014:4515:00Resolvers in LoopResolvers (k)Time (UTC) -- 2021-04-13 -- 5min binsverfwinkel.netessedarius.netIMC ’21, November 2–4, 2021, Virtual Event, USA
G. C. M. Moura et al.
(a) Queries
Figure 25: One-off-AfterGoogle: top 10 ASes by query vol-
ume with problematic resolvers
Zones
gioia.essedarius.net
infinita.verfwinkel.net
ns3.infinita.verfwinkel.net
ns5.gioia.essedarius.net
60s
60s
NS
TTL
Table 15: Cyclic dependency for new one-off measurement.
(b) Resolvers
Figure 24: Ripe Atlas: Queries and unique resolvers query-
ing authoritative servers (5min bins)
Measurement
Frequency
Qname
Query Type
Date
Duration
Atlas Probes
VPs
Queries
Responses
SERVFAIL
Timeout
REFUSED
FORMERR
NOERROR
NXDOMAIN
One-Off-AfterGoogle
One-off
$P-$r.platypus.essedarius.net.
A
2021-02-09
12,5h
Client Side
9594
18539
18655
17051
13054
3865
100
10
22
32