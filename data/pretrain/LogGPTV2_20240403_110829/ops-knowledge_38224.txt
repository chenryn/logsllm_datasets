User: I am trying to use Celery to output to multiple files. The task is very simple:

Get some data along with a file path
Append that data to the file path (and create the file if it doesn't exist)

I do not want to open/close the file handle each time, since I would write to the same file in many cases. So I made a simple FileHandlePool.
However, when running I noticed that for each thread/instance, celery will make a new FileHandlePool! So, I have files that are being overwritten.
What is the best way to handle this situation? Is it possible to have m FileHandlePool in the same scope as the main thread and have other celery threads access it?
Thanks!
Assistant: If I didn't want to have a separate service (outside of Celery) sync to file, the way I would accomplish this in Celery is to bind a one worker pool (a pool with concurrency 1) to a specific queue that accepts only file write tasks.  This way tasks run serially and there won't be any race conditions while writing.
Alternately, and as you originally suggested, you could change your CELERYD_POOL mode to use threading and then store the file handle reference on your task instance so you can access it from the different worker threads.  I'm assuming then that the file handle is thread safe.