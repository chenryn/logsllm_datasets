O
16
32
1
Δ value (bytes) : aggressiveness of padding 
256
512
64
128
3 keystrokes
4 keystrokes
mouse-select
find-a-doctor
overhead
Figure 12: Reduction power and network overhead of OnlineHealthA 
Figure 12 suggests that Δ=128 is clearly unsatisfactory: 
the attacker’s reduction powers are still 67×, 25×, 37× and 
8.3× for 4-keystroke, 3-keystroke, mouse-select and find-a-
doctor  respectively.  When  Δ=256,  the  overhead  becomes 
14.8%, while the information leak then is still realistic: the 
reduction  powers  are  31×  and  8×  for  mouse-select  and  4-
keystroke,  which  means  that  if  the  attacker  suspects  a 
person  having  one  of  31  (or  8)  possible  illnesses  and  the 
person  uses  the  mouse-select  (or  manual  input)  feature, 
there  is  a  good  chance  that  the  attacker  can  identify  the 
illness. This reduction power is worrisome because: (1) the 
set of suspected illnesses may not be very big in reality. For 
example, the health concern surrounding the aforementioned 
CEO  is  basically  whether  he  is  having  pancreatic  cancer, 
hormone  imbalance  (as  the  company  announced)  or  some 
types  of  weight  loss  [21];  (2)  the  state  information  of  the 
application has not been fully exploited yet in our research. 
Particularly, we did not utilize the probabilistic correlations 
among  conditions,  medications  and  procedures,  due  to  our 
lack of medical knowledge: for example, a pancreatic cancer 
patient is more likely to receive chemotherapy than wisdom-
tooth  removal.  Such  information  can  be  leveraged  to 
achieve  an  even  bigger  reduction  power.    Finally,  when Δ 
reaches 512 bytes, the reduction power for the mouse select 
scenario  is  reduced  to  11×,  and  the  powers  for  other 
scenarios  basically  vanish.  The  network  overhead  then  is 
that  application-agnostic 
32.3%.  This  analysis  shows 
202
mitigation  incurs  a  large  overhead,  one  third  of  the 
application’s bandwidth consumption, but still cannot fully 
subdue the information leaks.  
2)  On the Mitigation of OnlineTaxA Leaks 
identifiable 
the  rounding  strategy 
Figure 13 shows our evaluation of the effectiveness and 
the  overhead  of  applying 
to 
OnlineTaxA.  The  overhead  here  was  calculated  under  the 
scenario  where  a  user  was  working  on  Personal  Info, 
Income  and  Credits  &  Deductions  modules.  In  absence  of 
any  mitigation  measures,  15 
income  ranges  can  be 
distinguished. Because the differences in traffic patterns are 
big, Δ=64 does not have any mitigation effect. When Δ=256, 
which significantly mitigates the leaks in OnlineHealthA, the 
attacker can still distinguish 13 ranges. Even with Δ=1024, 
there  are  still  7 
ranges.  More 
interestingly,  increasing  Δ  beyond  1024  bytes  does  not 
lower  the  attack  power,  because  the  remaining  7  income 
ranges are identifiable due to the asymmetric path situation 
discussed earlier: a user eligible for a tax deduction needs to 
answer  more  questions 
ineligible  user.  The 
communication overhead for Δ=2048 is already 38.10%. Of 
course, in an extreme case, if a padding policy could make 
all state-transitions in the application indistinguishable, i.e., 
from the attacker’s perspective the state diagram is just one 
state looping back to itself, the remaining 7 income ranges 
would be hidden. However, since the number and the sizes 
of  packets 
in  each  state-transition  varies 
significantly, our measurement showed that such a treatment 
results in a prohibitively high overhead of 21074%. 
involved 
income 
than  an 
n
o
i
t
c
u
d
e
R
r
e
w
o
P
15
12
9
6
3
0
1
16
64
128 256 512 1024 2048
40%
30%
20%
10%
0%
d
a
e
h
r
e
v
o
Figure 13: Reduction power and network overhead of OnlineTaxA 
To effectively solve the problem, the application needs 
to merge multiple states along the longer execution paths, or 
produce  superfluous  packets  to  fake  extra  states  along  the 
shorter  paths.  These  policies,  however,  are  clearly 
application-specific, which are built upon the understanding 
of the state transitions within the application. 
3)  On the Mitigation of Search Engine Leaks 
There are two reasons why the information-leaks in the 
high-profile  search  engines  are  hard  to  mitigate  in  an 
application-agnostic  way:  (1)  these  search  engines  need  to 
handle high-volume search traffic, which makes the cost of 
applying  any  universal  mitigations  to  the  entire  traffic 
unsustainably high. A more realistic alternative seems to be 
identifying  vulnerable  features  (such  as  auto-suggestion) 
and applying a mitigation specifically; (2) more importantly, 
203
as  we  discuss  below,  whether  certain  policies  can  be 
effectively enforced also depends on application scenarios. 
For  example,  Δ=128  seems  to  work  for  the  auto-
suggestion  feature,  because  the  response  size  generated  by 
entering  one  of  the  26  letters  usually  varies  in  a  200-byte 
range.  However,  choice  of  a  specific  padding  policy,  i.e., 
rounding  or  random-padding,  is  still  application-specific, 
depending  on  the  understanding  of  how  the  application 
operates.  For  example,  we  found  that  the  auto-suggestion 
responses of Google/Yahoo/Bing were GZip-compressed by 
web  servers.  Typically  in  corporate  networks,  web  traffic 
needs  to  go  through  HTTP  proxies  which  inspect  the 
contents  to  enforce  security  and  compliance  rules.  The 
inspection requires the traffic to be decompressed. In other 
networks  (e.g.,  university  or  home  networks),  there  are 
typically no inspection proxies. As a result, the “round-up-
to-Δ” policy performed on the server side becomes difficult 
in  simultaneously  hiding  the  packet  differences  in  both 
types  of  environments.  Thus  the  differences  will  be 
preserved in the Wi-Fi traffic. Other related considerations 
include  (1)  when  to  pad,  before  or  after  the  compression, 
and  (2)  where  to  pad,  to  the  HTTP  header  (not  subject  to 
compression) or to the HTTP body (subject to compression). 
For the search engines, we feel that random-padding could 
be a suitable mitigation if Δ is reasonably big, which may be 
able  to  ensure  that  the  sizes  of  both  the  uncompressed 
packet  and 
the  compressed  packet  have  sufficient 
randomness. Of course, the exact effectiveness needs more 
thorough evaluations.  
This  example,  again,  demonstrates 
the  need  for 
application-specific mitigations – even after the effective Δ 
value  is  decided,  selection  of  the  right  padding  policy  and 
the practical way to enforce the policy requires application-
specific  information.  This  type  of  consideration  was  also 
found  to  be  crucial  for  mitigating  the  information  leaks  in 
OnlineInvestA, which we elaborate below. 
4)  On the Mitigation of OnlineInvestA Leaks 
OnlineInvestA  is  an  example  to  show  that  even  for  a 
single  application,  developers  need  to  consider  different 
factors  to  find  effective  policies.  Such  considerations  can 
only  be  made  based  on  the  assumption  that  the  vulnerable 
application features are identified.  
Hiding  the  side-channel  information  of  the  pie  chart 
does not require too aggressive padding. Actually, Δ=32 can 
already  defeat  a  side-channel  analysis,  as  it  increases  the 
ambiguity sets, which are already quite large, by 32 times. 
Alternatively, a 256-bit block cipher can be used. 
However,  the  other  two  leak  problems,  i.e.,  the  price-
history charts and the mutual fund details pages, cannot be 
addressed  without  applying  aggressive  padding.  Figure  14 
shows that although Δ=128 may be satisfactory for the price 
history  problem,  protecting  the  fund  detail  pages  requires 
Δ=1024.  Once  Δ=1024  has  been  applied  application-wide, 
the network overhead is 18.8%. 
9
7
5
3
1
20.1%
56.9%
20.1%
56.9%
94.6%
94.6%
20.00%
15.00%
10.00%
5.00%
0.00%
Fund detail pages
Price history charts
Network overhead
64
128
256
32
16
1
Figure 14: Account holdings anonymity, network overhead and 
512 1024
degradations of random-padding effects upon 7-visits 
More  interestingly,  we  found  that  the  enforceability 
issue,  again,  needs  to  be  considered  here:  contrary  to  the 
search  engine  scenario,  OnlineInvestA  should  use  the 
rounding  policy,  rather  than  random  padding,  because 
repeatedly  applying  a  random  padding  policy  to  same 
responses  significantly  reduces  its  effects.  Consider  the 
price history chart problem as an example. Suppose random-
[0,128)-padding has been applied several times to the same 
image response, making its observable sizes vary in a 100-
byte  range,  which  essentially  degrades  the  effect  of  the 
padding  to  Δ=28.  In  our  research,  we  ran  a  simulation 
program  to  calculate  the  probability  of  such  degradations 
after  applying  random-padding  7  times.  The  program 
performed  2000  simulations,  each  generating  7  random 
numbers, calculating their range and subtracting it from the 
Δ. We observed that the padding effect was degraded to Δ/2, 
Δ/4 and Δ/8 with a probabilities of 94.6%, 56.9% and 20.1% 
respectively  when  a  page  is  visited  7  times  (including  the 
page visits by history-back and reload). Similarly, 10 visits 
degraded  the  padding  effect  to  Δ/2,  Δ/4  and  Δ/8  with 
probabilities of 99.0%, 74.7% and 33.9% respectively. The 
rounding policy is not subject to such degradations, and thus 
may be more suitable for protecting the OnlineInvestA. 
Finally, there is an enforcement difficulty for mashups 
(i.e.,  functionalities  that  import  data  from  third-party 
services). Because the price history charts are fetched by the 
browser from the public website https://FinancialDataA.com, 
OnlineInvestA  is  unable  to  fix  the  problem.  They  must 
convince  FinancialDataA 
the  charts  are 
embedded  in  the  pages  of  OnlineInvestA,  FinancialDataA 
should fix the problem, though FinancialDataA only  shows 
public data with no confidentiality concern. Since mashups 
are a widely-used means for integrating third-party services, 
it is not realistic to require all services to pad their packets 
aggressively without first knowing the actual vulnerabilities. 
B.  Impacts on the Application Development Practice  
that  because 
The above analyses suggest that it is unlikely to have a 
universal  remedy  that  fixes  the  whole  problem  without 
understanding  the  specific  vulnerabilities  in  individual 
applications.  Instead,  the  mitigation  often  needs  to  be 
considered as part of application development practice. Here, 
we summarize the technical challenges identified above and 
discuss the measures that need to be taken. 
Challenge  1  –  identifying  vulnerabilities.  The  first 
technical  challenge 
the  side-channel 
vulnerabilities  within  individual  web  applications.  As  we 
to  find 
is  how 
204
and 
there 
today  fit 
in 
should  be  more 
discussed in Section III, when an application makes stateful 
communications  and  the  communications  are  associated 
with  user  inputs  or  stored  data,  information  leaks  become 
this 
possible.  However,  many  applications 
description, 
the 
future.   Identification  of  such  side-channel  vulnerabilities 
requires an in-depth analysis of the information flows within 
individual applications, and in some cases, acquisition of the 
background knowledge on how the applications are used: an 
example is the correlation between an illness and medicines 
in OnlineHealthA.  Given the trend of increasing use of web 
applications  as  substitutes  for  their  desktop  counterparts, 
more and  more confidential  user data in  these applications 
will  be  subject  to  the  side-channel  threat.   This  urges  the 
developer to treat the problem seriously and come up with 
proper testing measures to identify such weaknesses in their 
products during the development and testing stage.  
that  effectively  and  efficiently  suppress 
Challenge  2  –  specifying  mitigation  policies.  Also  of 
great  importance  is  how  to  design  application-specific 
policies 
the 
discovered  information  leaks.  We  have  shown  in  the 
previous section that specifying such policies often requires 
nontrivial efforts to understand a web application, its traffic 
patterns,  program  structure  and  state  transitions,  and  even 
semantic  knowledge  about  its  utilization.   This  makes  the 
application developer the most suitable party for specifying 
those  policies.   As  a  result,  an  improvement  is  needed  for 
the current web development practices, which calls for new 
technologies  to  be  built  to  help  the  developer  design  and 
evaluate such policies.  
A  necessary  collaborative  effort  –  building  policy 
enforcement  infrastructures.  Our  study,  as  reported  in 
Section  V.A,  indicates  that  enforcing  well-defined  policies 
can  also  be  nontrivial.  The  enforcement  often  needs  the 
collaboration among multiple parties, including the vendors 
of browsers (e.g., IE, Firefox) and web servers (e.g., Apache, 
IIS).  This is because of the following observations. Unlike 
low-level  socket  programming,  the  design  of  today’s  web 
application  often  renders  an  application  hard  to  determine 
the  sizes  of  the  packets  it  generates,  as  its  dynamic  web 
pages are essentially collections of element tags and macros 
to be expanded by server-side engines such as ASP.NET or 
PHP. Adding to this complexity is the encoding (usually by 
escaping  special  characters)  and  compression  (by  GZIP  or 
DEFLATE) typically performed by web servers. This makes 
packet sizes even more difficult to gauge by the application 
developer. As a result, only the web server and the browser 
that work directly on the layer of network protocols, such as 
HTTP(S),  know  the  exact  sizes  of  the  packets  to  be  sent 
onto  the  network.  On  the  other  hand,  the  protocol  layers 
have  little  ideas  about  the  mitigation  policies,  as  these 
policies often  need to be application-specific, related to its 
state 
transitions.  Therefore,  web  applications  must 