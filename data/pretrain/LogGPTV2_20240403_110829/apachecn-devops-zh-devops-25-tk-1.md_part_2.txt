  namespace: go-demo-5
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
      - name: db
        ...
        resources:
          limits:
            memory: "150Mi"
            cpu: 0.2
          requests:
            memory: "100Mi"
            cpu: 0.1
        ...
      - name: db-sidecar
    ... 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api
  namespace: go-demo-5
spec:
  ...
  template:
    ...
    spec:
      containers:
      - name: api
        ...
        resources:
          limits:
            memory: 15Mi
            cpu: 0.1
          requests:
            memory: 10Mi
            cpu: 0.01
...
```
我们有两个形成应用的 Pods。`api`部署是一个后端应用编程接口，使用`db`状态集作为其状态。
定义的基本部分是`resources`。`api`和`db`都为内存和中央处理器定义了`requests`和`limits`。该数据库使用一个 sidecar 容器，该容器将把 MongoDB 副本连接到一个副本集中。请注意，与其他容器不同，边车没有`resources`。这背后的重要性将在后面揭示。现在，只要记住两个容器定义了`requests`和`limits`，而那个没有。
现在，让我们创建这些资源。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-no-sidecar-mem.yml \
 3      --record
```
输出应该显示已经创建了相当多的资源，我们的下一步行动是等待`api`部署的展开，从而确认应用已经启动并运行。
```
 1  kubectl -n go-demo-5 \
 2      rollout status \
 3      deployment api
```
过一会儿，你应该会看到消息说`deployment "api" was successfully rolled out`。
为了安全起见，我们将在`go-demo-5`命名空间中列出 Pods，并确认每个 Pods 的一个副本正在运行。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS  RESTARTS AGE
api-... 1/1   Running 0        1m
db-0    2/2   Running 0        1m
```
到目前为止，除了常规的创建状态集和部署之外，我们还没有做任何事情。
反过来，他们创造了复制集，从而创造了豆荚。
![](img/ed5f3b30-98d3-4735-b3f4-7a4a79755f72.png)
Figure 1-3: Creation of the StatefulSet and the Deployment
希望大家知道，我们的目标应该是每个 Pod 至少有两个副本，只要它们是可扩展的。不过，两者都没有给出“to”的定义。这是故意的。我们可以指定 Deployment 或 StatefulSet 的复制副本数量，但这并不意味着我们应该这样做。至少，并非总是如此。
If the number of replicas is static and you have no intention to scale (or de-scale) your application over time, set `replicas` as part of your Deployment or StatefulSet definition. If, on the other hand, you plan to change the number of replicas based on memory, CPU, or other metrics, use HorizontalPodAutoscaler resource instead.
让我们看一个简单的水平缩放器的例子。
```
 1  cat scaling/go-demo-5-api-hpa.yml
```
输出如下。
```
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: api
  namespace: go-demo-5
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 80
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 80
```
该定义使用`HorizontalPodAutoscaler`瞄准`api`部署。它的边界是最少两个，最多五个副本。这些限制是根本性的。没有它们，我们将面临扩大到无限或缩小到零副本的风险。`minReplicas`和`maxReplicas`油田是一张安全网。
定义的关键部分是`metrics`。它提供了 Kubernetes 应该用来决定是否应该缩放(或缩小)资源的公式。在我们的例子中，我们使用`Resource`类型条目。他们的目标是内存和中央处理器的平均利用率达到 80%。如果两者中任何一个的实际使用量有所偏离，Kubernetes 将缩放(或缩小)资源。
请注意，我们使用了`v2beta1`版本的应用编程接口，您可能会想知道为什么我们选择了那个版本，而不是稳定且生产就绪的`v1`。毕竟，`beta1`版本还远远没有达到通用的程度。原因很简单。horizontalpodocautoscaler`v1`太基础了。它只允许基于 CPU 进行缩放。甚至我们的简单例子也通过增加内存来超越这一点。稍后，我们将进一步扩展它。因此，虽然`v1`被认为是稳定的，但它并没有提供太多的价值，我们可以等到`v2`发布，或者马上开始实验`v2beta`的发布。我们选择后者。当您阅读本文时，更稳定的版本可能已经存在，并在您的 Kubernetes 集群中得到支持。如果是这种情况，在应用定义之前，请随意更改`apiVersion`。
现在让我们应用它。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-api-hpa.yml \
 3      --record
```
我们应用了创建**水平水平标尺** ( **HPA** )的定义。接下来，我们将看看通过检索 HPA 资源获得的信息。
```
 1  kubectl -n go-demo-5 get hpa
```
如果你很快，输出应该与下面的类似。
```
NAME REFERENCE      TARGETS                      MINPODS MAXPODS REPLICAS AGE
api  Deployment/api /80%, /80% 2       5       0        20s
```
我们可以看到 Kubernetes 还没有实际的 CPU 和内存利用率，而是输出``。我们需要给它多一点时间，直到从度量服务器收集数据的下一次迭代。在我们重复同样的问题之前，给自己弄点咖啡。
```
 1  kubectl -n go-demo-5 get hpa
```
这一次，输出没有未知数。
```
NAME REFERENCE      TARGETS          MINPODS MAXPODS REPLICAS AGE
api  Deployment/api 38%/80%, 10%/80% 2       5       2        1m
```
我们可以看到 CPU 和内存利用率都远低于`80%`的预期利用率。尽管如此，Kubernetes 还是将副本数量从一个增加到了两个，因为这是我们定义的最小值。我们签订了合同，规定`api`部署不得少于两个副本，而 Kubernetes 遵守了这一点，即使资源利用率远低于预期的平均利用率。我们可以通过 HorizontalPodAutoscaler 的事件来确认这种行为。
```
 1  kubectl -n go-demo-5 describe hpa api
```
输出仅限于事件消息，如下所示。
```
...
Events:
... Message
... -------
... New size: 2; reason: Current number of replicas below Spec.MinReplicas
```
事件的信息应该是不言自明的。由于当前数量(1)低于`MinReplicas`值，水平缩放器将副本数量更改为`2`。
最后，我们将列出 Pods，以确认所需数量的副本确实正在运行。
```
 1  kubectl -n go-demo-5 get pods
```
输出如下。
```
NAME    READY STATUS  RESTARTS AGE
api-... 1/1   Running 0        2m
api-... 1/1   Running 0        6m
db-0    2/2   Running 0        6m
```
到目前为止，HPA 还没有根据资源使用情况执行自动扩展。相反，它只增加了 Pod 的数量，以满足指定的最小值。它通过操纵部署来实现这一点。
![](img/c9a6db6e-d3a9-485e-a687-b92b0629e19e.png)
Figure 1-4: Scaling of the Deployment based on minimum number of replicas specified in the HPA
接下来，我们将尝试创建另一个 HorizontalPodAutoscaler，但是这一次，我们将针对运行我们的 MongoDB 的 StatefulSet。那么，让我们看看另一个 YAML 定义。
```
 1  cat scaling/go-demo-5-db-hpa.yml
```
输出如下。
```
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: db
  namespace: go-demo-5
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: db
  minReplicas: 3
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 80
  - type: Resource
    resource:
      name: memory
      targetAverageUtilization: 80
```
这个定义和我们以前用的几乎一样。唯一不同的是，这次我们的目标是名为`db`的`StatefulSet`，副本的最小数量应该是`3`。
让我们应用它。
```
 1  kubectl apply \
 2      -f scaling/go-demo-5-db-hpa.yml \
 3      --record
```
让我们再来看看 HorizontalPodAutoscaler 资源。
```
 1  kubectl -n go-demo-5 get hpa
```
输出如下。
```
NAME REFERENCE      TARGETS                      MINPODS MAXPODS REPLICAS AGE
api  Deployment/api 41%/80%, 0%/80%              2       5       2        5m
db   StatefulSet/db /80%, /80% 3       5       0        20s
```
我们可以看到创建了第二个 HPA，当前利用率为`unknown`。那一定是和以前类似的情况。我们应该给它一些时间让数据开始流入吗？稍等片刻，然后再次检索 HPA。目标还是`unknown`吗？
可能有问题，因为资源利用率仍然未知。让我们描述一下新创建的 HPA，看看我们是否能够找到问题背后的原因。
```
 1  kubectl -n go-demo-5 describe hpa db
```
输出仅限于事件消息，如下所示。