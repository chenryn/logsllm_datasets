title:Predicting resource usage and estimation accuracy in an IP flow
measurement collection infrastructure
author:Nick G. Duffield and
Carsten Lund
Predicting Resource Usage and Estimation Accuracy
in an IP Flow Measurement Collection Infrastructure
Nick Dufﬁeld
AT&T Labs—Research
180 Park Avenue
Florham Park, NJ 07932, USA
dufﬁPI:EMAIL
Carsten Lund
AT&T Labs—Research
180 Park Avenue
Florham Park, NJ 07932, USA
PI:EMAIL
ABSTRACT
This paper describes a measurement infrastructure used to collect
detailed IP trafﬁc measurements from an IP backbone. Usage,
i.e, bytes transmitted, is determined from raw NetFlow records
generated by the backbone routers. The amount of raw data is
immense. Two types of data sampling in order to manage data
volumes: (i) (packet) sampled NetFlow in the routers; (ii) size-
dependent sampling of NetFlow records. Furthermore, dropping of
NetFlow records in transmission can be regarded as an uncontrolled
form of sampling.
We show how to manage the trade-off between estimation accu-
racy and data volume. Firstly, we describe the sampling error that
arises from all three types of sampling when estimating usage per
trafﬁc class: how it can be predicted from models and raw data,
and how it can be estimated directly from the sampled data itself.
Secondly, we show how to determined the usage of resources—
bandwidth, computational cycle, storage—within the components
of the infrastructure. These two sets of methods allow dimension-
ing of the measurement infrastructure in order to meet accuracy
goals for usage estimation.
Categories and Subject Descriptors
C.2.3 [Computer–Communications Networks]: Network Opera-
tions—Network monitoring; C.4 [Performance of Systems]; G.3
[Probability and Statistics]
General Terms
Measurement, Performance, Theory
Keywords
Sampling, Estimation, Variance, Bandwidth
1.
INTRODUCTION AND MOTIVATION
The collection of network usage data is essential for the engi-
neering and management of communications networks. Until re-
cently, the usage data provided by network elements (e.g. routers)
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’03, October 27–29, 2003, Miami Beach, Florida, USA.
Copyright 2003 ACM 1-58113-773-7/03/0010 ...$5.00.
has been coarse-grained, typically comprising aggregate byte and
packet counts in each direction at a given interface, aggregated over
time windows of a few minutes. However, these data are no longer
sufﬁcient to engineer and manage networks that are moving be-
yond the undifferentiated service model of the best-effort Inter-
net. Network operators need more ﬁnely differentiated informa-
tion on the use of their network. Examples of such information
include (i) the relative volumes of trafﬁc that use different proto-
cols or applications; (ii) trafﬁc matrices, i.e., the volumes of traf-
ﬁc originating from and/or destined to ranges of Internet Protocol
(IP) addresses or Autonomous Systems (AS’s); (iii) the aggregate
statistics of packet and byte volumes and durations of user sessions.
Such information can be used to support network management, in
particular:
trafﬁc engineering, network planning, peering policy,
customer acquisition, usage-based pricing, and network security;
some applications are presented in details in [2, 11, 12]. An impor-
tant application of trafﬁc matrix estimation is to efﬁciently redirect
trafﬁc from overloaded links.
A prototype Trafﬁc Analysis Platform (TAP) has been developed
in order to achieve these goals.
It allows for the collection and
processing of ﬂow measurements from a wide area backbone net-
work. The main challenge for the TAP is the immense amount of
backbone trafﬁc, and hence the proportionately immense amount of
ﬂow measurements to be collected. The TAP meets this challenge
with a distributed architecture and extensive use of sampling and
aggregation at multiple measurement locations. Sampled NetFlow
(see Section 2.5.2) is conﬁgured on the routers, reporting aggregate
measured from sampled packet streams. The resulting ﬂow records
are subject to aggregation and sampling on their passage through
the measurement infrastructure. A form of non-uniform sampling
introduced in [6] (here called smart sampling; see Section 2.5.4) of
the completed NetFlow records is implemented at collection points.
Inherent in sampling is the consequence that network usage is esti-
mated rather than known exactly. However the sampling methods,
in particular smart sampling, are optimized in order to yield esti-
mates of minimal variance subject to a given constraint on resource
usage in the TAP.
This paper provides a detailed description of the TAP, the sam-
pling methods that operate in it, and established the relationship
between resource usage in the measurement infrastructure and sta-
tistical accuracy of usage estimates from the sampled data. This
enables the dimensioning of the measurement infrastructure in or-
der to meet accuracy goals. In doing this, we build on and extend
prior work on smart sampling [6] and on the statistical properties
of packet sampled ﬂows [7]. In particular:
• We derive bounds for the sampling variance of usage esti-
mates due to the cumulative effect of packet Sampled Net-
Routers
CPU
RAM
Collectors/ 
Aggregators
Data 
Warehouse
Bandwidth
Bandwidth
CPU
RAM
Disk
CPU
RAM
Figure 1: TAP Architecture and Resources
Flow, smart sampling, and transmission loss, in terms of the
sampling parameters and simple trafﬁc characteristics. Fur-
thermore, we show how this variance of a given usage esti-
mate can itself be estimated on the ﬂy from the sampled data.
• We derive bounds and estimates for the usage of different
resource in the TAP architecture in terms of the sampling
parameters and trafﬁc ﬂow characteristics. These bounds can
be used to predict resource usage from models or traces, or to
predict the effect on resource usage of a change in parameter
settings.
The purpose of this paper is to describe the set of analytical tools
that enable planning of resources in a TAP measurement infras-
tructure, that enable the correct setting of sampling parameters and
dimensioning of resource, compatible with accuracy goals for the
estimation of network usage. The paper is organized as follows.
Section 2 describes the TAP architecture, and the sampling oper-
ations that take place within it. Section 3 describes the model for
sampling process and relevant trafﬁc properties.
With this setup, the main work of the paper is to show how the se-
lection of sampling parameters determines both the variance of us-
age estimates and volumes of samples selected. Section 4 contains
the main results on bounding sampling errors. Section 5 shows how
to estimate the rate of production of sampled ﬂow records from a
router. Section 6 establishes bounds and estimates for the rate of
production of smart sampled records, and the rate at which aggre-
gates of these are formed. Section 7 reports some examples of us-
ing these methods with NetFlow data. We conclude in Section 8.
Mathematical proofs are deferred to an Appendix.
2. THE TAP ARCHITECTURE
2.1 Components
The components of the TAP architecture are shown in Figure 1:
• Routers: these collect raw NetFlow records on the trafﬁc that
they route. These are exported in UDP packets to a local
collection server.
• Collector/Aggregators: these have three tasks. First, they
receive the raw NetFlow records from the routers and write
them to local disk. Second, they aggregate raw records and
create various higher level aggregates. Third, the aggregates
are shipped to a central Data Warehouse. Collection servers
are placed at major geographical locations in the backbone
network. This makes the architecture scalable and reduced
bandwidth consumption by the transmission of raw ﬂows in
the backbone.
• Data Warehouse: this stores the aggregate data, which can
generate reports and ﬁeld ad-hoc queries from an end-user
community including engineering, product management and
research organizations.
2.2 Resources
The resources of these components, and their usage, is as fol-
lows. The load on transmission and CPU resources at a given com-
ponent is proportional to the rate which ﬂow records arrive at it.
During aggregation, memory usage is proportional to the number
of distinct ﬂow keys that present during the aggregation period. At
the end of each such period, the aggregated ﬂows are written to
disk; thus the rate of consumption of disk storage space is propor-
tional to the number of distinct aggregate ﬂow keys, divided by
the duration of the aggregation period. A substantial part of the
the work of this paper is to predict the usages of these resources
through a combination of measurement and analysis.
2.3 Aggregation and Queries
The software running on the collection servers was required to be
efﬁcient and ﬂexible in the following sense. It needs to be efﬁcient,
since it needs to process an immense amount of data. It needs to be
ﬂexible since, due to changes in end user requirements and the need
to ﬁeld ad-hoc queries, it is not possible to determine in advance a
set of aggregates that would support all potential queries. Indeed,
the requirement for ﬂexibility is a reason that aggregate records
should not be formed at the router.
The ﬂexibility of TAP is achieved by implementation of a do-
main speciﬁc language tapquery that allows the users to write
high-level queries that the system then will run on the collection
servers. The language contains constructs that allow:
1. Deﬁnition of ﬂow keys and outputs for aggregation. For ex-
ample, using source and destination IP address as the key and
ﬂow bytes as output yields the host-to-host trafﬁc matrix.
2. Joining the raw ﬂow data with external data sources. For
example, joining with a table of IP address block used by
user groups yields trafﬁc usage by user group.
3. Filtering. Some applications focus on a subset of trafﬁc, e.g,
ﬁltering by TCP/UDP port number can be used to restrict
scope to trafﬁc using speciﬁc protocols or applications. Fil-
tering by interface also restricts focus to trafﬁc associated
with a given user, or a given peer,
4. Smart sampling. As further explained in Section 2.5.4, smart
sampling selects a subset of NetFlow records as input for
queries or aggregation, and performs appropriate renormal-
ization of measured usage in order that usage estimates are
unbiased.
5. Correction for data loss in the raw measurement stream. Net-
Flow records may be lost in transmission from router to col-
lection server, or for other reasons. For example, a surge in
NetFlow records may occur during a denial of service attack
due to the presence of a large number of short ﬂows with
spoofed source IP address. Correction enables the tracking
of actual network usage even if NetFlow records are lost.
Packet Sampling
(e.g. 1 in 3 sampling)
4
4
2
2
Flow Creation
1
1
Netflow Data Loss
(e.g. 25% loss)
1
Smart Sampling
(e.g. threshold = 9)
16
= 4*3/0.75
12
= max{9,3}/0.75
Figure 2: TAP Sampling Operations. See Section 2.5.6 for de-
scription of the examples.
Finally the aggregation systems allows computing multiple queries
at the same time, dynamically add, delete or change queries on the
ﬂy, and dynamically use updated external data sources.
2.4 NetFlow Records
The fundamental measurements collected by routers in the TAP
architecture are ﬂow records. We review how these are formed. An
IP ﬂow is a set of packets, observed in the network within some
time period, and that share some common property known as its
key. The fundamental example is that of so-called “raw” ﬂows: a
set of packets observed at a given network element, whose key is
the set of values of IP and other protocol header ﬁelds. A router
keeps records on active ﬂows passing through it. When a packet ar-
rives at the router, the router performs a lookup on its cache of cur-
rently active ﬂows, to determine if a ﬂow is active for the packet’s
key. If not, is instantiates a new record for the packet’s key. The
record include counters for packets and bytes that are updated ac-
cording to each packet that matches the key.
When the ﬂow is terminated, its record is ﬂushed for export, and
the associated memory released for use by new ﬂows. A router will
terminate the ﬂow if any one of a number of criteria are met, includ-
ing (i) timeout: the interpacket time within the ﬂow will not exceed
some threshold; (ii) protocol: e.g., observation a FIN packet of the
Transmission Control Protocol (TCP) [18] that terminates a TCP
connection; (iii) memory management: the ﬂow is terminated in
order to release memory for new ﬂows; (iv) aging: to prevent data
staleness, ﬂows are terminated after a given elapsed time since the
arrival of the ﬁrst packet of the ﬂow. Flow deﬁnition schemes have
been developed in research environments, see e.g. [1, 5], and are
the subject of standardization efforts [16]. Flow records typically
include the properties that make up ﬂows deﬁning key, its start and
end times, and the number of packets and bytes in the ﬂow.
In the TAP architecture, routers generate ﬂow records from a
sampled subset of the packet stream using Sampled NetFlow [4].
In the following section we motivate and describe this and other
sampling methods used in the TAP architecture.
2.5 Sampling in the TAP Architecture
Sampling is employed in the TAP architecture in order to con-
trol resource usage. The set of sampling operations available is
illustrated in Figure 2. (The numbers relate to an example that is
worked in Section 2.5.6). The top line of the ﬁgure illustrates a
sequence of packets incident at the router. During the operation of
sampled NetFlow, a proportion of these packets are selected and
ﬂow records constructed from them. Dropping of NetFlow records
in transit from the router to the aggregator can be viewed as another
type of sampling. In the aggregator, smart sampling is applied to
the ﬂow records themselves. We describe each of these sampling
operations in the following paragraphs.
2.5.1 Renormalization of the Samples
Sampling progressively thins the information that ﬂows through
TAP by discarding packets and ﬂows. In order to obtain an unbi-
ased estimate of usage in the original trafﬁc stream, it is necessary
to compensate for the effects of this discard by renormalizing the
usage that survives sampling. Speciﬁcally, the usage represented in
each surviving packet or ﬂow must be divided by the probability of
its selection. We shall see in Section 4 that this yields an unbiased
estimate for the usage. So-called unequal probability sampling is
frequently used in sample design in order to sample preferentially
from amongst larger components of a population; see [15].
For each of TAP’s sampling operations described in the follow-
ing paragraph, we also describe the renormalization that is applied
to usage data that survives sampling.
2.5.2 Sampled NetFlow
In order to perform ﬂow cache lookups at line rate, a high end
router would need to be equipped with large amounts of fast—
and hence expensive—memory, in order to maintain records on the
expected numbers of concurrently active ﬂows. In order to limit
the frequency of ﬂow cache lookups, sampled NetFlow forms ﬂow
records from a substream of packets. In current implementations
this is performed by periodically selecting every N th packet. Other
potential implementations include pseudorandom independent se-
lection of packets with probability 1/N, and randomized selection
driven by the entropy of the packet contents itself; see [9]. What-
ever the implementation, in order to form unbiased usage estimates,
the usage attributed to each selected packet of size b is multiplied
by N (the reciprocal of the selection probability), yielding N b.
A different approach to packet sampling has been taken in [10],
where prospective new ﬂow cache entries are sampled, with only
those selected being instantiated. This favors the recording of longer
ﬂows, while suppressing recording of short ﬂows that contribute lit-
tle to usage. Other work has considered adapting packet sampling
rates in order to maintain estimation accuracy; see [3].
2.5.3 Dropping Flow Records
Routers export NetFlow records to the collector using UDP. Since
UDP possesses no ability to detect or correct for losses in transmis-
sion, ﬂow records may be lost during periods of congestion. The
ﬂow records contain a sequence number that enables the loss to be
detected by the collector, and to determine the rate at which loss oc-
curs. If the average rate of successful transmission is q, the number
of bytes reported is normalized through division by q.
2.5.4 Smart Sampling
In the collector, ﬂow records are selected by a form of non-
uniform sampling called smart sampling. Smart sampling is con-
trolled through a parameter known as the sampling threshold, which
we shall denote by z.
In smart sampling, a ﬂow record repre-
senting a ﬂow of x bytes is sampled with probability pz(x) =
min{1, x/z}. Flows of size greater than the threshold z are always
selected, while smaller ﬂows are selected with probability propor-
tional to their size.
The motivation for smart sampling comes from the empirical fact
that ﬂow sizes have a heavy tailed distribution; [13]. In this case,
7
6
5
4
3
2
1
0
unsampled 
 z = 100kBytes
z = 1MByte
z = 10MBytes
z = 100MBytes
0
5
10
15
20
7
6