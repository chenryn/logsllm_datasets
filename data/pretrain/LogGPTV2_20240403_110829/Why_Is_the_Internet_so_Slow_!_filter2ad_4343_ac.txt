our measurements between RIPE Atlas platform [6] probes, which are small
network devices that are typically deployed in end-user networks. The locations
of the RIPE Atlas probes are known within 1 km resolution, obviating the need
for IP geolocation.
Why is the Internet so slow?!
183
Fig. 5. (a) Minimum pings between RIPE Atlas nodes are highly inﬂated regardless
of IPv4 or IPv6, inter- or intra-AS connections; (b) comparison of ﬁber lengths of the
Internet2 network to road distances.
We collected ICMP pings over IPv4 (IPv6) between 935 (1012) sources in 26
(34) countries and 72 (97) destinations in 29 (40) countries every 30 min for 24 h.
The data set contains ping measurements between 288,425 (63,884) unique IPv4
(IPv6) endpoint (or source-destination) pairs; 85% (78%) of the IPv4 (IPv6)
endpoint pairs are inter-AS pairs with the source and destination belonging to
diﬀerent ASes. To account for the skew in inter-AS and intra-AS pairs, we com-
pute the round-trip distance between the endpoints and bin them into 5 km wide
buckets. From each bucket, we uniformly sample an equal number of inter-AS and
intra-AS pairs and compute the inﬂation of the min. pings (minimum across the
entire day of measurements) of these endpoint pairs. Figure 5(a) shows that the
median inﬂation in minimum ping times (ranging from 7.2–11.6 times) is signiﬁ-
cantly larger than that in our PlanetLab measurements, where median inﬂation
in minimum ping latency was 3.1 times. That the latencies between Atlas probes
(typically attached to home networks) are larger than that between PlanetLab
nodes and Web servers should not be suprising—home networks surely add more
latency than servers in a university cluster or a data center. Perhaps paths from
clients to Web servers are also much shorter than between arbitrary pairs of
end-points on the Internet, since Web servers are deliberately deployed for fast
access, and the Internet’s semi-hierarchical nature can make paths between arbi-
trary end-points long. Interference from concurrent measurements may also be
a contributing factor [16], albeit the eﬀect on inﬂation might be marginal.
4 Infrastructural Latency
In line with the community’s understanding, our measurements aﬃrm that TCP
transfer and DNS resolution are important factors causing latency inﬂation.
However, as we shall detail in this section, our measurements also reveal that
the Internet’s infrastructural ineﬃciencies are an equally, if not more important
culprit.
In Fig. 1(b), the router-path is only 2.1 times inﬂated in the median. The
long tail is, in part, explained by ‘hairpinning’, i.e., packets between nearby end
184
I.N. Bozkurt et al.
Fig. 6. (a) Comparison of ﬁber lengths of the ESnet and G´EANT network to road
distances; (b) various components of latency inﬂation normalized by minimum ping
time.
points traversing circuitous routes across the globe. Note that 1.5 times inﬂation
would occur even along the shortest path along the Earth’s surface because the
speed of light in ﬁber is roughly 2/3rd the speed of light in vacuum. In that light,
the router-path inﬂation of 2.1× (which already includes the 1.5× factor) may
appear small, but this estimate is optimistic.
The gap between minimum ping time and the router-path latency may be
explained by two factors: (a) we perhaps see artiﬁcially shorter paths, since
traceroute often does not yield responses from all the routers on the path; and
(b) even between successive routers, the physical path may be longer than the
shortest arc along the Earth’s surface. We investigate the latter aspect using data
from 3 research networks: Internet2 [5], ESnet [2], and G´EANT [3]. We obtained
point-to-point ﬁber lengths for these networks and calculated end-to-end ﬁber
distances between all pairs of end points in each network. We also computed the
shortest distance along the Earth’s surface between each pair of end points, and
obtained the road distances for comparison using the Google Maps API [4]. In
Fig. 6(a), road distances are close to shortest distances (i.e., smaller inﬂations),
while ﬁber lengths are signiﬁcantly larger and have a long tail. The median
inﬂation in the three networks, after accounting for the lower speed of light in
ﬁber is 2.6× (Internet2), 2.7× (ESnet), and 3.6× (G´EANT). A recent analysis
of US long-haul ﬁber infrastructure [12] found results that support ours: even for
cities directly connected by ﬁber conduits, the mean conduit’s latency was in the
median more than 2× worse than the line-of-sight latency. Of course, we expect
end-to-end inﬂation between cities not connected directly to be higher. Thus,
infrastructural inﬂation (which includes routing sub-optimalities and inﬂation
of end-to-end ﬁber-distances over geodistance) is likely to be larger than the
optimistic estimate from router-path latency (2.1 times), bringing it closer to
the inﬂation in minimum ping latency (3.1 times).
As Fig. 1(b) shows, DNS resolution (6.6× inﬂated over c-latency), TCP
handshake (3.2×), request-response time (6.5×), and TCP transfer (12.6×),
all contribute to a total time inﬂation of 36.5×. With these numbers, it may
be tempting to dismiss the 3.1× inﬂation in the minimum ping time. But
Why is the Internet so slow?!
185
this would be incorrect because lower-layer inﬂation, embodied in RTT, has
a multiplicative eﬀect on each of DNS, TCP handshake, request-response, and
TCP transfer time. The total time for a page fetch (without TLS) can be bro-
ken down roughly (ignoring minor factors like the client stack) as: Ttotal =
TDN S + Thandshake + Trequest + Tserverproc + Tresponse + Ttransf er. If we changed
the network’s RTTs as a whole by a factor of x, everything on the RHS except
the server processing time (which can be made quite small in practice) changes
by a factor of x (to an approximation; TCP transfer time’s dependence on RTTs
is a bit more complex), thus changing Ttotal by approximately a factor of x as
well.
What if there was no inﬂation in the lower layers, i.e., RTTs were the same as
c-latencies? For an approximate answer, we can normalize DNS, TCP handshake,
request-response (excluding the server processing time, i.e., only the RTT) and
TCP transfer time by the minimum ping time instead of c-latency, as shown in
Fig. 6(b).
The medians are 2 times (DNS), 1.02 times (TCP handshake), 4 times (TCP
transfer), and 10.7 times (Total time) respectively. (Request-response is excluded
because processing time at the server does not depend on the RTT.) When the
3.1 times inﬂation in minimum ping time is compared to these numbers, instead
of the medians without such normalization, it appears much more signiﬁcant.
Also consider that if, for example, TCP transfer could be optimized such that
it happens within an RTT, the Internet would still be more than ∼25 times
slower than the c-latency in the median, but if we could cut inﬂation at the
lower layers from 3.1 times to close to 1, even if we made no transport protocol
improvements, we would get to around ∼10.7 times.
5 Related Work
There is a large body of work on reducing Internet latency. However, this work
has been limited in its scope, its scale, and most crucially, its ambition. Several
eﬀorts have focused on particular pieces; for example, [23,31] focus on TCP
handshakes; [11] on TCP’s initial congestion window; [28] on DNS resolution; [14,
20] on routing inﬂation due to BGP policy. Other work has discussed results from
small scale experiments; for example, [26] presents performance measurements
for 9 popular Web sites; [15] presents DNS and TCP measurements for the
most popular 100 Web sites. The WProf [29] project proﬁles 350 pages and
produces a break down of time spent in various browser activities. Wang [30]
investigate latency on mobile browsers, but focus on the compute aspects rather
than networking.
The central question we have not seen answered, or even posed before, is
‘Why are we so far from the speed of light?’. Even the ramiﬁcations of a speed-
of-light Internet have not been explored in any depth. The 2013 Workshop on
Reducing Internet Latency [8] focused on potential mitigation techniques, with
buﬀerbloat and active queue management being among the centerpieces. The
goal of achieving latencies imperceptible to humans was also articulated [27]. Our
186
I.N. Bozkurt et al.
measurements and analysis put the focus on an aspect of the latency problem
that has been largely ignored so far: infrastructural ineﬃciencies. We hope that
our work urges greater consideration for latency in eﬀorts for expanding Inter-
net’s reach to under-served populations. However, so far, infrastructural latency
has only garnered attention in niche scenarios, such as the ﬁnancial markets, and
isolated submarine cable projects aimed at shortening speciﬁc routes [21,22].
6 Discussion and Conclusion
Speed-of-light Internet connectivity would be a technological
leap with the
potential for new applications, instant response, and radical changes in the inter-
actions between people and computing. To shed light on what’s keeping us from
this vision, in this work, we quantify the latency gaps introduced by the Inter-
net’s physical infrastructure and its network protocols. Our analysis suggests
that the networking community should, in addition to continuing eﬀorts for
protocol improvements, also explore methods of reducing latency at the lowest
layers.
Acknowledgments. Dhruv Diddi helped process the ESnet data. Data on ﬁber
mileages from G´EANT, the high-speed pan-European research and education network,
was obtained through personal communication with Xavier Martins-Rivas, DANTE.
DANTE is the project coordinator and operator of G´EANT.
References
1. cURL. http://curl.haxx.se/
2. ESnet. http://www.es.net/
3. G´EANT. http://www.geant.net/
4. Google Maps API. http://goo.gl/I4ypU
5. Internet2. http://www.internet2.edu/
6. RIPE Atlas. https://atlas.ripe.net
7. Top 500 sites in each country or territory, Alexa. http://goo.gl/R8HuN6
8. Workshop on reducing internet latency (2013). http://goo.gl/kQpBCt
9. Akamai: State of the Internet, Q1 (2016). https://goo.gl/XQt324
10. Brutlag, J.: Speed matters for Google Web search (2009). http://goo.gl/t7qGN8
11. Dukkipati, N., Reﬁce, T., Cheng, Y., Chu, J., Herbert, T., Agarwal, A., Jain,
A., Sutin, N.: An argument for increasing TCP’s initial congestion window. In:
SIGCOMM CCR (2010)
12. Durairajan, R., Barford, P., Sommers, J., Willinger, W.: Intertubes: a study of the
US long-haul ﬁber-optic infrastructure. In: ACM SIGCOMM (2015)
13. Schurman, E., (Bing), Brutlag, J., (Google): Performance related changes and their
user impact. http://goo.gl/hAUENq
14. Gao, L., Wang, F.: The extent of AS path inﬂation by routing policies. In: GLOBE-
COM (2002)
15. Habib, M.A., Abrams, M.: Analysis of sources of latency in downloading web pages.
In: WEBNET (2000)
Why is the Internet so slow?!
187
16. Holterbach, T., Pelsser, C., Bush, R., Vanbever, L.: Quantifying interference
between measurements on the RIPE Atlas platform (2015)
17. Grigorik, I., (Google): Latency: the new web performance bottleneck. http://goo.
gl/djXp3
18. Liddle, J.: Amazon Found Every 100ms of Latency Cost Them 1% in Sales. http://
goo.gl/BUJgV
19. Maynard-Koran, P.: Fixing the Internet for real time applications: Part II. http://
goo.gl/46EiDC
20. M¨uhlbauer, W., Uhlig, S., Feldmann, A., Maennel, O., Quoitin, B., Fu, B.: Impact
of routing parameters on route diversity and path inﬂation. Comput. Netw. 54(14),
2506–2518 (2010)
21. NEC: SEA-US: Global Consortium to Build Cable System Connecting Indonesia,
the Philippines, and the United States. http://goo.gl/ZOV3qa
22. Nordrum, A.: Fiber optics for the far North [News]. IEEE Spectr. 52(1), 11–13
(2015)
23. Radhakrishnan, S., Cheng, Y., Chu, J., Jain, A., Raghavan, B.: TCP fast open.
In: CoNEXT (2011)
24. Rexford, J., Wang, J., Xiao, Z., Zhang, Y.: BGP routing stability of popular des-
tinations. In: ACM SIGCOMM Workshop on Internet Measurment (2002)
25. Singla, A., Chandrasekaran, B., Godfrey, P.B., Maggs, B.: The Internet at the
speed of light. In: HotNets. ACM (2014)
26. Sundaresan, S., Magharei, N., Feamster, N., Teixeira, R.: Measuring and mitigating
web performance bottlenecks in broadband access networks. In: IMC (2013)
27. T¨aht, D.: On reducing latencies below the perceptible. In: Workshop on Reducing
Internet Latency (2013)
28. Vulimiri, A., Godfrey, P.B., Mittal, R., Sherry, J., Ratnasamy, S., Shenker, S.: Low
latency via redundancy. In: CoNEXT (2013)
29. Wang, X.S., Balasubramanian, A., Krishnamurthy, A., Wetherall, D.: Demystify
page load performance with WProf. In: NSDI (2013)
30. Wang, Z.: Speeding up mobile browsers without infrastructure support. Master’s
thesis, Duke University (2012)
31. Zhou, W., Li, Q., Caesar, M., Godfrey, P.B.: ASAP: a low-latency transport layer.
In: CoNEXT (2011)