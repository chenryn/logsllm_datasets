WebWeb
The fields in the Web data model describe web server and/or proxy server data in a security or operational context.
Tags used with the Web event objects
The following tags act as constraints to identify your events as being relevant to this data model. For more information, see "How to use these reference tables".
| Object name  | Tag name |
|---|---|
| Web |web |
| |____  Proxy |proxy || Web |web |
| |____  Proxy |proxy |
Fields for Web event objects
The following table lists the extracted and calculated fields for the event objects in the model. Note that it does not include any inherited fields. For more information, see "How to use these reference tables."
| Object name | Field name | Data 
type | Description | Possible values |
|---|---|---|---|---||---|---|---|---|---|
| Web |action |string |The action taken by the server or proxy. | |
| Web |app |string | | |
112
|  |  |  | The app recording the data, such as IIS, Squid, or 
Bluecoat. |  |
|---|---|---|---|---|
| Web |bytes |number |The total number of bytes  transferred  (bytes_in +  bytes_out). | |
| Web |bytes_in |number |The number of inbound bytes transferred. | || Web |bytes_out |number |The number of outbound bytes transferred. | |
| Web |cached |boolean |Indicates whether the event data is cached or not. |true,  false, 1, 0 |
| Web |category |string |The category of  traffic, such as  may be provided by a proxy server. | |
| Web |cookie |string |The cookie file recorded in the event. | || Web |dest |string |The destination of the network traffic (the remote host). You can alias this from more specific fields, such as  dest_host,  dest_ip, or  dest_name. | |
| Web |dest_bunit |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk || Web |dest_category |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk || Web |dest_priority |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk |
113
|  |  |  | App for Enterprise Security. They should be left blank when writing add-ons. | App for Enterprise Security. They should be left blank when writing add-ons. ||---|---|---|---|---|
| Web |duration |number |The time taken by the proxy event, in milliseconds. | |
| Web |http_content_type |string |The content-type of the requested HTTP resource. | |
| Web |http_method |string |The HTTP  method used in the request. |GET,  PUT,POST, DELETE,  etc. |
| Web |http_referrer |string |The HTTP referrer used in the  request. The W3C specification and many  implementations  misspell this as  http_referer. A  FIELDALIAS is  recommended to handle both key  names. | || Web |http_user_agent |string |The user agent used in the  request. | |
| Web |http_user_agent_length  |number |The length of the user agent used in the request. | |
| Web |response_time |number |The amount of time it took to receive a  response, if  applicable, in milliseconds. | |
|  | | |The amount of time it took to receive a  response, if  applicable, in milliseconds. | ||  | | |The amount of time it took to receive a  response, if  applicable, in milliseconds. | |
| Web |site |string |The virtual site  which services the | |
114
|  |  |  | request, if applicable. |  |
|---|---|---|---|---|
| Web |src |string |The source of the network traffic  (the client  requesting the  connection). | || Web |src_bunit |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |src_category |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |src_priority |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |status |string |The HTTP  response code  indicating the  status of the proxy request. |404, 302, 500, and so on. |
| Web |tag |string |This automatically generated field is used to access  tags from within  datamodels. Add-on builders do not need to populate it. | |
| Web |uri_path |string |The universal  resource indicator path of the  resource served by the webserver or proxy. | || Web |uri_query |string |The universal  resource indicator path of the  resource  requested by the client. | |
115
| Web | url | string | The URL of the requested HTTP resource. |  |
|---|---|---|---|---|
| Web |url_length |number |The length of the URL. | |
| Web |user |string |The user that  requested the  HTTP resource. | || Web |user_bunit |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |user_category |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |user_priority |string |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. |These are derived fields  provided by Asset and  Identity correlation features of certain advanced  applications like the Splunk App for Enterprise Security. They should be left blank when writing add-ons. || Web |vendor_product |string |The vendor of the proxy server, such as Squid Proxy  Server. | |
116
Using the Common Information Model
Approaches to using the CIM
This chapter provides a comprehensive overview of how Splunk Enterprise app and add-on developers, knowledge managers, or administrators can use the Common Information Model to work with data at search time.
Not all sections apply for all users and use cases.If you want to normalize some newly indexed data from a source type that is unfamiliar to Splunk Enterprise, go to "Use the CIM to normalize data at search time."
If you want to validate that your indexed data conforms to the CIM for all the models that you expect, go to "Use the CIM to validate your data."
If you are using Pivot to work with data that has already been normalized to the CIM, go to "Use the CIM to generate reports and dashboards."If you want to accelerate one or more data models to improve performance, see "Accelerate CIM data models."
Use the CIM to normalize data at search time
If you are working with a new data source, you can manipulate youralready-indexed data at search time so that it conforms to the common standard used by other Splunk applications and their dashboards. Your goal might be to create a new application or add-on specific to this data source for use with Splunk Enterprise Security or other existing applications, or you might just want to normalize the data for your own dashboards.This topic guides you through the steps to normalize your data to the Common Information Model, following established best practices.
117
To see these steps applied in real use cases, see the examples provided at the end of this manual:
• "Use the CIM to normalize OSSEC data"
• "Use the CIM to normalize CPU performance metrics"
1. Get your data in
If you have not already done so, get your data into the Splunk platform.Do not be concerned about making your data conform to the CIM in the parsing or indexing phase. You normalize your data to be CIM compliant at search time. See Getting Data In if you need more direction for capturing and indexing your data.
2. Examine your data in the context of the CIM
Determine which data models are relevant for the data source you are working with.Use the CIM reference tables to find fields that are relevant to your domain and your data. You might need to normalize data from a single event or source of events against more than one data model. Some events may be logs tracking CRUD changes to a system, others may log the login/logout activities for that system. For each different kind of event, look for data models that match the context of your data. For example, CRUD events map to the Change Analysis data model. Login events map to the Authentication data model.Refer to "How to use these reference tables" for a description of how to compare the information in the reference tables with the data models in the Data Model Editor page in Splunk Web. Keep both the documentation and the Data Model Editor open for reference, because you need to refer to them in the following steps.
3. Configure CIM-compliant event tags
Apply tags to categorize your event data according to type.Categorizing your data allows you to specify the dashboards in which the data should appear, something that cannot necessarily be determined just by field names and sources. Many of the CIM data models have the same field names, so the tags act as constraints to filter the data to just the relevant events for that
118model. Also, many different sources may produce events relevant to a particular data model. For example, web applications, VPN servers, and email servers all have authentication events, yet the source and structure of these authentication events are considerably different for each type of device. Tagging all of the authentication related events appropriately makes it possible for your dashboards to pull data from the correct events automatically.To apply the CIM-compliant tags to your data, follow these steps.
1. Determine what tags are necessary for your data. Refer to the data models that use similar domain data to choose what tags from the Common Information Model are needed. Remember to look for inherited tags from parent objects. See "How to use these reference tables" for more information.2. Create the appropriate event types using the Event types manager in Splunk Web by accessing Settings > Event types. You can also edit the 
eventtypes.conf file directly. For detailed instructions, refer to "Data 
Classification: Event types and transactions" chapter of the Knowledge Manager Manual, part of the Splunk Enterprise documentation.3. Create the appropriate tags in Splunk Web. Click Settings > Event types, locate the event type that you want to tag and click on its name. On the detail page for the event type, add or edit tags in the Tags field, then click Save. You can also edit the tags.conf file directly. For example:
[eventtype=nessus]
vulnerability = enabled
report = enabledreport = enabled 
For more detailed information about managing tags in Splunk Web, see "Data normalization: tags and aliases" in the Knowledge Manager Manual, part of the Splunk Enterprise documentation.
Repeat this process for each of the tags needed to to map your events to the correct objects in the data models. These event type and tag modifications that you make are saved in$SPLUNK_HOME/etc/users/$USERNAME$/$APPNAME$/local/eventtypes.conf and $SPLUNK_HOME/etc/users/$USERNAME$/$APPNAME$/local/tags.conf.
4. Verify tags
To verify that the data is tagged correctly, display the event type tags and review the events.
119
1. Search for the source type.
2. Use the field picker to display the field tag::eventtype at the bottom of each event.3. Look at your events to verify that they are tagged correctly.
4. If you created more than one event type, also check that each event type is finding the events you intended.
5. Make your fields CIM-compliantExamine the fields available in the data model, and look for the equivalent fields in your indexed data. Some, or perhaps many, of the fields may already be present with the correct field names and value types that match the expectations of the Common Information Model. If you are not certain if your values match what is expected by the model, check the description of that field in the data model reference tables in this documentation.Make note of all fields in the data model that do not correspond exactly to your event data. Some may not exist in your data, have different field names, or have the correct field names but have values that do not match the expected type of the model. One by one, normalize your data for each of these fields using a combination of field aliases, field extractions, and lookups.a. Create field aliases to normalize field names
First, look for field alias opportunities. Determine whether any existing fields in your data have different names than the names expected by the data models. For example, the Web data model has a field called http_referrer. This field may be misspelled as http_referer in your source data. Define field aliases to capture the differently named field in your original data and map it to the field name that the CIM expects.Also check your existing fields for field names that match the CIM field names but do not match the expected values, as described in the "Description" field in the data model reference tables. Your event may have an extracted field such as id that refers to the name of a completely different entity than the description of the field id in the CIM data model. Define a field alias to rename the id field from your indexed data to something else, such as vendor_id, to divert that data from spuriously appearing in reports and dashboards for which it is not intended. To capture the correct id field that you need for CIM compliance, you can either extract the field from elsewhere in your event, or write a lookup file to add that120
field from a csv file.
See "Add aliases to fields" in the Splunk Enterprise documentation for more information about aliasing fields.
b. Create field extractions to extract new fields
After you have aliased all the fields you can, you can work on adding the fields that are missing. When the values that you need exist in the event data, extract the necessary fields using the field extraction capabilities of the Splunk platform.Be sure to name the fields to exactly match the field names in the CIM data models.
See "Build field extractions with the field extractor" and "Create and maintain search-time field extractions through configuration files" in the Splunk Enterprise documentation for more information.
c. Write lookups to add fields and normalize field valuesAfter you have aliased or extracted all the fields that you can in your indexed data, you may have to create lookup files to finish normalizing your data.
There are two reasons to create lookup files:• Add fields that cannot be extracted from the event data. For example, your events may not contain the name of the vendor, product, or app of the system logging the event, but the data model you are mapping to expects all three of these fields. In this case, populate a csv file with the source type(s) generating the events and map each to the appropriate vendor name, product name, and application name.Normalize field values to make them compliant with the CIM. For example,• 
the Network Traffic data model includes a rule field which expects string values that define the action taken in the network event. If your network traffic data contains a numeric value for the field rule, create a field alias for that field to something like rule_id so that it does not clash with the rule field expected by the data model, which must be a string. Then, add a lookup to map your rule_id values to a new rule field with theircorresponding string values.
See "Add fields from external data sources" in the Knowledge Manager Manual, part of the Splunk Enterprise product documentation, for more information about writing lookups using the configuration files. See "Use field lookups to add information to your events" for the same information using Splunk Web.
121
d. Verify fields and values121
d. Verify fields and values
After you finish normalizing your fields and values, validate that the fields appear in your events as you intended.
1. Search for the source type containing the data you are working to map to the CIM.
2. Use the field picker to select all the fields you just aliased, extracted, or looked up in your data.
3. Scan your events and verify that each field is populated correctly.4. If one of the normalized fields has an incorrect value, edit the extraction, re-alias the field, or correct your lookup file to correct the value.
6. Validate your data against the data model
After you have added your event tags and normalized your data by adding fields, aliasing fields, and writing lookups, the data from your source type should map to the CIM data models that you targeted. You can validate that your data is fully CIM compliant by using the data model itself, either via Pivot or by searching using the datamodel command.a. Validate using Pivot
Validate your data using Pivot with specific goals in mind. For each field that you normalized within each unique event type, think of a useful metric that you can build with Pivot to assess whether your data appears as you expect.
For example, if you are testing your authentication data, you might use Pivot to check whether your own login activity appears in your data.1. In the Search and Reporting app, click Pivot.
2. Select the data model against which you want to validate your data, then click into a relevant object in the model. For the example above, select 
Authentication, then Successful Authentication.
3. Set the date range to an appropriate time range to speed up the search. For the example above, set it to Last 15 minutes if you just recently logged in to the system.122
4. Apply a filter to match your source type.
5. Split rows and columns by other relevant attributes in the model. For example, you might split the rows by user to see a list of usernames that have logged in during the past 15 minutes.
b. Validate using the datamodel command
1. Open the Search and Reporting app.
2. Construct a search using the datamodel command, a filter for your source type, the table command, and the field summary command. Here is therecommended structure:
| datamodel   search
| search sourcetype=
| table * | fields -  | fieldsummary 
This structure, when applied to check that Cisco ISE data is mapping as expected to the Authentication data model for successful login activities, looks like this:| datamodel Authentication Successful_Authentication search
| search sourcetype=cisco:ise* | table *
| fields - date_* host index punct _raw time* splunk_server sourcetype
source eventtype linecount
| fieldsummary3. Observe the results. The datamodel command performs a query against the data model and returns a list of all fields in the model, some statistics about them, and sample output from your data in the values column. You can configure which statistics columns display with the  | fields - portion of the search string. To flag problems with your field normalizations, scan this table to look for empty values, incorrect values, or statistics that do not match your expectations.Here is the result using the example search string above.
123
For more information about the datamodel command, see the datamodel entry in the Search Reference manual.
7. (Optional) Package your configurations as an add-on
Now that you have tested your field extractions, lookups, and tags, you can choose to package the search-time configurations as an add-on and publish it to the community. Using your add-on, other Splunk platform users with the same data source can map their data to the CIM without having to repeat the steps you completed above.See "Package your app or add-on" in Developing Views and Apps for Splunk Web, part of the Splunk Enterprise documentation.
Use the CIM to validate your data
The Common Information Model offers several built-in validation tools.
Use the datamodelsimple command
If you want to determine the available fields for a data model, you can run the custom command datamodelsimple. Use or automate this command torecursively retrieve available fields for a given object of a data model. The format
124
expected by the command is shown below.
| datamodelsimple type= datamodel= object= nodename= 
For full documentation on datamodelsimple usage, see searchbnf.conf in $SPLUNK_HOME/etc/apps/Splunk_SA_CIM/default.
Use the CIM Validation (S.o.S.) datamodelVersion 4.2.0 of the Common Information Model moves the CIM Validation objects into their own data model. Previously, the validation objects were located within each relevant model.
Access the CIM Validation (S.o.S.) model in Pivot. From there, you can select a top-level object, a Missing Extractions search, or an Untagged Events search for a particular category of data.Top level objects tell you what is feeding the model. Selecting a top-level object in Pivot is equivalent to searching for the constraints that define the top level of the data model, but Pivot allows you to validate that you are getting what you expect from the source types that you expect. For best results, split rows by source type and add a column to the table to show counts for how many events in that source type are missing extractions. If you see values in the missing extractions column, you can go to the datamodel audit report for moreinformation if the data model is accelerated, or access the appropriate Missing Extractions object in Pivot to drill further into the attributes.Missing Extractions objects run searches that return all missing field extractions that are expected in order to fully populate that object of the data model, provided that data exists with the appropriate tags for the object that you have selected. In other words, Splunk Enterprise finds tagged events for this object in this model, but there are field extractions for this event type that Splunk Enterprise expects, but which are not present. If you get results, split rows by source type to find which data source is contributing events for this model but is not fully mapping to the CIM.Untagged Events runs a search for events that have a strong potential for CIM compliance but are not tagged with the appropriate tag or tags. For example, the Untagged Authentication search is:
(login OR "log in" OR authenticated) sourcetype!=stash NOT
tag=authentication
125
For best results, split by source type. Click the results to drill into the untagged events.
Use the CIM to create reports and dashboardsIf you are working with data that has already been normalized to the Common Information Model (either you or someone else in your organization have already completed the normalizing steps described in "Use the CIM to normalize data at search time", or you are using an add-on that takes care of the CIM compliance) you can use the CIM data models to generate visualizations, reports, and dashboards, the same way you would use any other data model in the Splunk platform.Example: Analyzing Authorization events using CIM data models
For example, you want to build a dashboard to monitor authorization events on your systems.
1. In the Search and Reporting App, click Pivot.
2. Select the Change Analysis data model. Observe that it has a child object called Account Management.
3. Click > next to the Account Management object and its sub-objects to browse the available events and fields contained in the model.4. Decide on a useful metric to display, then use Pivot to generate the relevant search. Need more guidance? See the Resources for using Pivot, below.
5. When you are satisfied with the results, save your search as a report.
6. Repeat as needed until you have saved several reports tracking metrics of interest.
7. Switch to the Authentication data model and browse the available events and fields contained in this model for additional relevant metrics.8. Click into the objects or attributes and develop searches using Pivot, saving your results as reports.
126
9. Create a new dashboard and add your saved reports to it.
Resources for using Pivot
For more information about data models and using Pivot to create reports, see "About Data Models" in the Knowledge Manager Manual, part of the Splunk Enterprise documentation.For a tutorial about using Pivot with data models, see "Part 3: Designing a Pivot Report" in the Data Model and Pivot Tutorial in the Splunk Enterprise 
documentation.
For a full guide to using Pivot, see the Pivot Manual in the Splunk Enterprise documentation.
Use the Data Model Audit and Predictive Analytics dashboards
You can also use the dashboards included with the Common Information Model to monitor your data model accelerations and searches. The CommonInformation Model includes two preconfigured dashboards:
• The Data Model Audit dashboard helps you analyze the performance of 	your data model accelerations.
• The Predictive Analytics dashboard helps you identify outliers in your data 	based on the predictive analysis functionality in the Splunk platform.Access these dashboards by going to the Search and Reporting app. From there, click Dashboards to view your list of dashboards. When the Splunk Common Information Model Add-on is installed, these two dashboards appear in the list.
Further documentation about these dashboards is available in the Splunk Enterprise Security documentation at the links below.
• Data Model Audit dashboard• Data Model Audit dashboard
• Predictive Analytics dashboard
Splunk Enterprise Security is not required for these dashboards to work.
Accelerate CIM data models
127
You can accelerate a data model to speed up the data set represented by that data model for reporting purposes. After you accelerate a data model, pivots, reports, and dashboard panels that use that data model should complete faster than they did before. See "Enable data model acceleration" in the Knowledge Manager Manual, part of the Splunk Enterprise documentation, for more information about accelerating data models.By default, all data model acceleration for the models included in the Splunk Common Information Model Add-on is disabled. To accelerate a data model, follow these steps.
1. In Splunk Web, click Settings > Data models and click the data model that you want to accelerate to view its details.
2. Under Acceleration, click Add next to the sentence "Model is not accelerated."3. Click the check box to accelerate the model, then select a Summary Range.
4. Click Save.
Some apps that depend on certain data models (for example, Splunk Enterprise Security) require that certain CIM data models be accelerated in order for their reports and dashboards to work. Those apps automatically enable acceleration of the relevant data models during installation.For more information about accelerated data models and data model 
acceleration jobs, run the datamodelinfo command. You can use this command on an ad-hoc basis if you need additional information about acceleration. You can also access the Data Model Audit dashboard, included with the Common Information Model add-on, to get a graphical view of the data model acceleration status.
128