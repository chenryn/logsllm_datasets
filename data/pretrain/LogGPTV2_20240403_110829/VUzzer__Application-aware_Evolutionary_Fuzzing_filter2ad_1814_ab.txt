p r i n t f ( ” Magic b y t e s matched !\ n ” ) ;
EXIT ERROR ( ” I n v a l i d f i l e \n ” ) ;
( buf [ 1 0 ] == ’%’ && buf [ 1 1 ] == ’@’ ) {
p r i n t f ( ” 2nd s t o p : on t h e way . . . \ n ” ) ;
i f
e l s e {
( s t r n c m p (& buf [ 1 5 ] , ”MAZE” , 4 ) == 0 )
... some bug here ...
p r i n t f ( ” you j u s t missed me . . . \ n ” ) ;
. . .
t a s k
c l o s e ( f d ) ; return 0 ;
ERROR( ” I n v a l i d b y t e s ” ) ;
. . .
. . .
t a s k
c l o s e ( f d ) ; return 0 ;
some o t h e r
}
c l o s e ( f d ) ; return 0 ;
// notice the order of CMPs
}
} e l s e {
some o t h e r
. . .
// nested IF
Listing 3. Motivating example that illustrates issues in existing fuzzers
It is interesting to note that, when we ran the code snippet
in Listing 3 with AFL [52], we could not reach the buggy state
within 24 hours. What is so special about this code snippet and
what is missing in fuzzers like AFL? We address this question
by considering the following code properties:
1) Magic bytes: The second and the ﬁrst byte are ﬁrst
compared to validate the input (line 11). If these bytes
are not properly set at certain input offsets, the input
is discarded immediately. In our example, offset 1 is
checked ﬁrst and offset 0 next. We observed this behavior
in real applications, such as the djpeg utility. This also
explains that it took millions of inputs for AFL to generate
a valid jpeg image2. As AFL is not application-aware, it
has no idea of such bytes and offsets. It will simply keep
on guessing a valid combination of bytes and offsets.
2) Deeper execution: In order to go deeper in the execution,
one has to get past another check at
line 15, which
compares offsets 10 and 11 (note that such offsets may
be read from the input and thus vary across inputs, unlike
2http://lcamtuf.blogspot.nl/2014/11/pulling-jpegs-out-of-thin-air.html
3
the case of magic bytes). Irrespective of the result of this
check, a new path is taken. However, the true branch
will lead to buggy spot at line 18. Again, when processing
this example, AFL spends a long time guessing the valid
combination of bytes and offsets. In general, after a few
iterations of input generation, a large percentage of inputs
will be falling into the error-handling code. AFL and
any other coverage-based fuzzer that searches for new
basic blocks are likely to further explore from such inputs
as these inputs have indeed found new code. However,
if we consider the exploration of more meaningful and
interesting paths, reusing such inputs yields no beneﬁt
and hinders further exploration of the application code.
3) Markers: In order to reach the buggy spot at line 18, there
is a branch constraint to satisfy at line 17. It should be
noted that such bytes may not be present at ﬁxed offsets,
but rather work as markers for certain ﬁelds in many input
formats, such as JPEG, PNG, or GIF. Miller & Peterson
show that the presence (and absence) of such markers has
a direct impact on the executed code [36]. As often such
markers are multibytes, AFL struggles with generating
such bytes to execute certain paths.
4) Nested conditions: In the context of coverage-based
fuzzing, each path is important. However, reaching certain
paths may be more difﬁcult than others. For example, in
order to reach line 18, an input has to satisfy the check
at line 17, which is only triggered when the constraint
at line 15 is satisﬁed. Therefore, in order to increase the
chance of reaching line 18, we need to fuzz any input that
reaches line 15 more often. In the case of AFL, even if it
passes or fails constraints at line 15, it discovers new paths
in both cases and it tries to fuzz inputs corresponding to
both the branches with equal probability. In this process, it
spends a long time mutating the input executing the easier
path and thereby minimizing the chances of reaching
line 18. This is the result of spending less time in
satisfying the constraint at line 17. Clearly, this strategy
is not able to prioritize efforts to focus on the interesting
path. A better strategy would be to optimize efforts based
on the control-ﬂow characteristics of the application.
Interestingly, one of the LAVA authors noted similar issues
with AFL in a recently published post [16]. This supports
our observation that black/greybox fuzzers like AFL tend to
be application-agnostic, which makes them signiﬁcantly less
effective at discovering hard-to-reach bugs.
We note that some of the issues discussed above can be, in
principle, handled by symbolic/concolic-based approaches [9],
[20], [22], [33] such as Driller [47]. Driller combines AFL
and concolic execution to explore deeper execution paths.
With symbolic execution, we may be able to learn magic
bytes quickly and assist AFL in crossing the ﬁrst hurdle at
line 11. However, AFL will get stuck again in the following
lines. Moreover, this combination is again agnostic to nested
conditions and thus path prioritization remains an issue. A
more general and practical problem is the poor scalability
of symbolic execution-based solutions. Although not an issue
in this small motivating example, real-world applications are
complex enough to drive symbolic execution into a state-
explosion scenario. This is evident from the results presented
in the Driller paper [47]: out of 41 binaries from DARPA
CGC, Driller’s concolic engine could generate new meaningful
inputs only for 13 binaries. Another study [50] empirically
established that symbolic execution is not suitable for ﬁnding
inputs that explore interesting paths. Therefore, in spite of
promising results on CGC binaries, the poor scalability of
symbolic/concolic execution-based approaches is still a strong
limiting factor on real-world applications.
B. Evolutionary Input Generation
Despite some pitfalls, AFL is a very promising fuzzer. The
success of AFL is mainly attributed to its feedback loop, i.e,
incremental input generation. In the case of our motivating
example, it is almost impossible to generate an input that
will reach the buggy state in one mutation. This motivated
us to adopt an evolutionary fuzzing strategy, that is a fuzzing
strategy that relies on an evolutionary algorithm (EA) for input
generation. In the following, we brieﬂy describe the main
steps that a typical EA follows (see Algorithm 1). In the later
sections, we will refer to these steps while detailing the main
components of VUzzer.
Algorithm 1 Pseudo-code of a typical evolutionary algorithm
INITIALIZE population with seed inputs
repeat
SELECT1 parents
RECOMBINE parents to generate children
MUTATE parents/children
EVALUATE new candidates with FITNESS function
SELECT2 ﬁttest candidates for the next population
until TERMINATION CONDITION is met
return BEST Solution
Every EA starts with a set of initial inputs (seeds), which
undergo the evolutionary process as follows. With some se-
lection probability, one or two inputs (parents) are selected
(SELECT1 state). Such inputs are then processed by two
genetic operators, namely crossover (RECOMBINE state) and
mutation (MUTATE state). In crossover, two inputs are com-
bined by choosing an offset (cut-point) and exchanging the
corresponding two parts to form two children. In mutation,
we apply several mutation operators (like addition, deletion,
replacement of bytes) on a single parent input to form one
child. With this strategy, we get a new set of inputs which
undergo the evaluation state (EVALUATE). In this state, we
monitor the execution of each new input based on a set of
properties. These properties are used in a ﬁtness function to
assess the suitability of the input. We choose the input with
the highest ﬁtness score for the next generation of inputs. The
whole process continues until a termination condition is met:
either the maximum number of generations is reached or the
objective is met (in case of fuzzing, a crash is found).
III. OVERVIEW
To address the challenges mentioned in the previous sec-
tion, we propose VUzzer, an application-aware evolutionary
fuzzer. Figure 1 provides an overview of its main components.
As VUzzer is an evolutionary fuzzer, there is a feedback loop
to help generate new inputs from the old ones. When generat-
ing new inputs, VUzzer considers features of the application
based on its execution on the previous generation of inputs. By
considering such features, we make the feedback loop “smart”
and help the fuzzer ﬁnd inputs with non-zero IG with high
frequency.
4
Fig. 1. A high-level overview of VUzzer. BB: basic block, CMP imm: cmp
instruction with one immediate operand, DTA: dynamic taint analysis, LEA:
load effective address instruction.
A. Features
The two main components of VUzzer are a static analyzer
(shown on the left) and the main (dynamic) fuzzing loop
(shown on the right). We use these components to extract
a variety of control- and data-ﬂow features from the appli-
cation. Figure 1 shows that VUzzer continuously pumps this
information back into the evolutionary mutation and crossover
operators to help generate better inputs in the next generation.
We ﬁrst introduce the features and then discuss the static
analyzer and the main fuzzing loop.
Data-ﬂow features: Data-ﬂow features provide infor-
mation about the relationship between input data and com-
putations in the application. VUzzer extracts them using well-
known techniques such as taint analysis and uses them to infer
the structure of the input in terms of the types of data at certain
offsets in the input. As an example, it ﬁnds input bytes that
determine branches (“branch constraints”) by instrumenting
each instruction of the cmp family of the x86 ISA to determine
which input bytes (offsets) it uses and against which values
it compares them. In this way, VUzzer can determine which
offsets are interesting to mutate and what values to use at
those offsets (providing partial answers to the questions in
Section I). VUzzer is now able to mutate more sensibly by
targeting such offsets more often and by using the intended
values at those offsets to satisfy branch constraints. Doing
so solves the problem of magic bytes, without resorting to
symbolic execution.
Likewise, VUzzer monitors the lea instruction to check if
the index operand is tainted. If so, it can determine that the
value at the corresponding offset is of type int and mutate
the input accordingly. Besides these two simple, but powerful
features, many others are possible.
Control-ﬂow features: Control-ﬂow features allow
VUzzer to infer the importance of certain execution paths.
For example, Figure 2 shows a simpliﬁed CFG of the code in
Listing 3. Inputs that exercise error blocks are typically not
interesting. Therefore, identifying such error-handling blocks
may speed up the generation of interesting inputs. We show
how we detect error-handling code in the following sections.
For now, we assume that we can heuristically identify the basic
TestfcaseApplicationbinaryCrossoverMutationFitnesslistBBfmonitoringDTABBfweightsCMPfimmStaticfanalysisMagicfbytesLEAfoffsetsKnowledgeFitnessffunctionInterestingfoffsetsdetectionExecutedBBsAppendinputevolutionaryffuzzingloopfcloseErrorBBsEvolutionaryfFuzzingfLoopKnowledgeKnowledgeblocks containing error handlers.
Another example concerns the reachability of nested
blocks. Any input that reaches block F is more likely to
descend deeper into the code than an input that reaches block
H, since the latter is not nested. We use control-ﬂow features
to deprioritize and prioritize paths. As enumerating all the
possible paths in the application is infeasible, we implement
this metric by assigning weights to individual basic blocks.
Speciﬁcally, basic blocks that are part of error-handling code
get a negative weight, while basic blocks in hard-to-reach code
regions obtain a higher weight.
Fig. 2. A high-level CFG of the code shown in Listing 3. The number
at each edge denotes the probability of the corresponding branch outcome.
The number at each node denotes the overall probability of reaching the
corresponding basic block. For example, if all edge probabilities are 0.5 and
the program can reach a node N2 either from N0 directly or indirectly via
N1, the node probability of N2 ← 0.5 + 0.5 ∗ 0.5 = 0.75. The number next
to the node probability is the assigned weight.
Figure 1 shows that a single iteration of fuzzing consists
of several steps. VUzzer expects an initial pool SI of valid
inputs, called seed inputs. The ﬁrst step is to perform an
intraprocedural static analysis to derive a few control-ﬂow
and data-ﬂow features (Section III-B), which is followed by
the main evolutionary fuzzing loop. In the remainder of this
section, we walk through all the steps to describe the whole
process.
B. The static analyzer
intraprocedural
static analysis
At
the beginning of
the fuzzing process, we use a
lightweight
to (i) obtain
immediate values of the cmp instructions by scanning the
binary code of the application and (ii) compute the weights
for the basic blocks of the application binary.
The presence of many immediate values from cmp in-
structions in the application’s code typically indicates that the
application expects the input to have many of these values at
certain offsets. For example, the analysis for the program in
Listing 3 yields a list LBB of weights for each basic block and
a list Limm of byte sequences containing {0xEF, 0xFD,
%, @, MAZE}. To determine the basic block weights, we
model the CFG of each function as a Markov model and
5
compute the probability pb of reaching each basic block b in a
function. We then calculate the weight wb of each basic block
b as 1/pb. Thus, the lower the probability of reaching a basic
block, the higher the weight. Using this model, the probability
and the weight of each basic block is shown next to each node
in Figure 2 (see Section IV-A3). We observe that, for example,
the probability of reaching basic block G is less than that of
reaching basic block F , which in turn has lower probability
than basic block H. VUzzer uses these lists in later steps of
the fuzzing loop.
C. The main fuzzing loop
We describe the main fuzzing loop by using the steps
in Algorithm 1. Before the main loop starts, we execute the
application with the set of seed inputs SI to infer an initial
set of control-ﬂow and data-ﬂow features. For all the inputs in
SI, we run dynamic taint analysis (DTA) to capture common
characteristics of valid inputs. Speciﬁcally, we do so for
the magic-byte and error-handling code detection mentioned
earlier. Using these features, we generate an initial population
of inputs as part of the INITIALIZE step in Algorithm 1. Note
that our magic-byte detection ensures that these new inputs
cross the ﬁrst such check of the application. As DTA has a
high overhead, we use it as sparingly as possible after the
main loop starts.
Input execution: We execute the application with each
of the inputs from the previous step and generate the corre-
sponding traces of executed basic blocks. If any of the inputs
executes previously unseen basic blocks, we taint the input
and use DTA to infer its structural properties by monitoring
the data-ﬂow features of the application.
Fitness calculation: In the EVALUATE step of Algo-
rithm 1, we calculate the ﬁtness of each input as the weighted
sum of the frequencies of executed basic blocks. We distribute
the weights over the basic blocks using the weights list LBB.
Basic blocks that belong to error-handling code get a negative
weight—for now we still assume that we can identify such
basic blocks. The intuition behind this ﬁtness calculation is to
provide high scores to inputs that execute basic blocks with
higher weights and thereby prioritize the corresponding paths,
while also executing certain basic blocks with high frequencies
to catch large loops. For example, let us consider two paths
p1 and p2, executed by two inputs i1 and i2 respectively
such that p1 = A → B → D → E → H → J and
p2 = A → B → D → E → F → J. For simplicity, let
us assume the error-handling basic block J gets weight -1 and
the frequency of execution of each basic block is 1. Using the
weights from Figure 2, the weighted sums of the frequencies of
p1 and p2 are 7 (1+1+2+2+2-1) and 9 (1+1+2+2+4-1). Hence,
input i2 gets a higher ﬁtness score and will participate more in