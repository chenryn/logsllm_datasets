(cid:37)(cid:1)
(cid:7)(cid:25)(cid:25)(cid:22)(cid:32)(cid:26)(cid:1)(cid:14)(cid:23)(cid:21)(cid:16)(cid:18)(cid:1)
(cid:38)(cid:1)
(cid:8)(cid:6)(cid:2)(cid:1)(cid:40)(cid:1)(cid:14)(cid:32)(cid:29)(cid:20)(cid:36)(cid:1)(cid:26)(cid:14)(cid:29)(cid:20)
(cid:19)(cid:25)(cid:27)(cid:1)(cid:14)(cid:23)(cid:21)(cid:16)(cid:18)(cid:1)(cid:40)(cid:1)(cid:10)(cid:11)(cid:9)(cid:1)
(cid:4)(cid:23)(cid:21)(cid:18)(cid:24)(cid:29)(cid:1)
(cid:2)(cid:1)
(cid:13)(cid:18)(cid:27)(cid:21)(cid:19)(cid:34)(cid:1)(cid:14)(cid:32)(cid:29)(cid:20)(cid:36)(cid:1)(cid:26)(cid:14)(cid:29)(cid:20)(cid:1) (cid:39)(cid:1)
(cid:12)(cid:28)(cid:18)(cid:27)(cid:1)(cid:3)(cid:25)(cid:15)
Figure 3: Steps taken when a client looks up a user’s
public key at her identity provider.
(cid:4)(cid:16)(cid:17)(cid:23)(cid:29)(cid:28)(cid:34)(cid:1)
(cid:7)(cid:26)(cid:24)(cid:32)(cid:20)(cid:16)(cid:17)(cid:26)(cid:1)
(cid:4)(cid:6)(cid:6)(cid:7)(cid:3)(cid:6)(cid:5)(cid:1)
(cid:40)(cid:1)
(cid:7)(cid:5)(cid:2)(cid:1)(cid:42)(cid:1)(cid:13)(cid:31)(cid:28)(cid:19)(cid:36)(cid:1)(cid:25)(cid:13)(cid:28)(cid:19)(cid:1)
(cid:18)(cid:24)(cid:26)(cid:1)(cid:14)(cid:24)(cid:14)(cid:1)(cid:42)(cid:1)(cid:9)(cid:10)(cid:8)(cid:1)
(cid:39)(cid:1)
(cid:6)(cid:24)(cid:24)(cid:21)(cid:31)(cid:25)(cid:1)(cid:14)(cid:24)(cid:14)(cid:1)
(cid:12)(cid:17)(cid:26)(cid:20)(cid:18)(cid:34)(cid:1)(cid:32)(cid:13)(cid:22)(cid:20)(cid:16)(cid:20)(cid:28)(cid:34)(cid:1)(cid:24)(cid:18)(cid:1)
(cid:7)(cid:5)(cid:2)(cid:1)(cid:38)(cid:1)(cid:13)(cid:31)(cid:28)(cid:19)(cid:36)(cid:1)(cid:25)(cid:13)(cid:28)(cid:19)(cid:1)
(cid:15)(cid:24)(cid:23)(cid:27)(cid:20)(cid:27)(cid:28)(cid:17)(cid:23)(cid:28)(cid:1)(cid:33)(cid:37)(cid:1)(cid:9)(cid:10)(cid:8)(cid:1)
(cid:41)(cid:1)
(cid:3)(cid:22)(cid:20)(cid:17)(cid:23)(cid:28)(cid:1)
(cid:2)(cid:1)
(cid:11)(cid:27)(cid:17)(cid:26)(cid:1)(cid:2)(cid:24)(cid:14)
Figure 4: Steps taken when a client monitors its own
user’s binding for spurious keys every epoch.
that are properly included in the STR. Clients do not mon-
itor other user’s bindings as they may not have enough
information to determine when another user’s binding has
changed unexpectedly.
Fig. 4 summarizes the steps taken during the monitor-
ing protocol. The client begins monitoring by performing
a key lookup for its own user’s name to obtain a proof of
inclusion for the user’s binding. Next, the client checks
the binding to ensure it represents the public key data
the user believes is correct. In the simplest case, this is
done by checking that a user’s key is consistent between
epochs. If the keys have not changed, or the client detects
an authorized key change, the user need not be notiﬁed.
In the case of an unexpected key change, by default the
user chooses what course of action to take as this change
may reﬂect, for example, having recently enrolled a new
device with a new key. Alternatively, security-conscious
users may request a stricter key change policy which can
be automatically enforced, and which we discuss further
in §4.3. After checking the binding for spurious keys, the
client veriﬁes the authentication path as described in §3,
including verifying the user’s private index.
4.1.3 Monitoring for Spurious Keys
4.1.4 Auditing for Non-Equivocation
CONIKS depends on the fact that each client monitors
its own user’s binding every epoch to ensure that her key
binding has not changed unexpectedly. This prevents a
malicious identity provider from inserting spurious keys
Even if a client monitors its own user’s binding, it still
needs to ensure that its user’s identity provider is pre-
senting consistent versions of its key directory to all par-
ticipants in the system. Similarly, clients need to check
388  24th USENIX Security Symposium 
6
USENIX Association
No response 
Get provider's 
STR for 
epoch t 
    STRt 
Check 
signature on 
STR 
Valid 
STRprev 
Compare hash of 
cached STRprev with 
H(STRprev) in STRt 
Match 
Check passed 
Figure 5: Steps taken when verifying if a provider’s STR history is linear in the auditing protocol.
Invalid 
Not matching 
Fail 
(cid:3)(cid:11)(cid:12)(cid:18)(cid:25)(cid:24)(cid:29)(cid:1)
(cid:5)(cid:22)(cid:19)(cid:28)(cid:15)(cid:11)(cid:12)(cid:22)(cid:1)
(cid:4)(cid:3)(cid:11)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
(cid:32)(cid:1)
(cid:4)(cid:9)(cid:24)(cid:12)(cid:23)(cid:24)(cid:1)(cid:7)(cid:8)(cid:6)(cid:1)
(cid:33)(cid:1)
(cid:19)(cid:10)(cid:23)(cid:12)(cid:22)(cid:28)(cid:12)(cid:11)(cid:1)
(cid:13)(cid:22)(cid:19)(cid:17)(cid:1)(cid:7)(cid:10)(cid:10)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
(cid:3)(cid:11)(cid:12)(cid:18)(cid:25)(cid:24)(cid:29)(cid:1)
(cid:5)(cid:22)(cid:19)(cid:28)(cid:15)(cid:11)(cid:12)(cid:22)(cid:1)
(cid:11)(cid:3)(cid:9)(cid:6)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
(cid:2)(cid:14)(cid:19)(cid:23)(cid:12)(cid:18)(cid:1)(cid:22)(cid:9)(cid:18)(cid:11)(cid:19)(cid:17)(cid:16)(cid:29)(cid:31)(cid:1)
(cid:22)(cid:12)(cid:21)(cid:27)(cid:12)(cid:23)(cid:24)(cid:1)(cid:16)(cid:9)(cid:24)(cid:12)(cid:23)(cid:24)(cid:1)(cid:7)(cid:8)(cid:6)(cid:1)(cid:1)
(cid:13)(cid:22)(cid:19)(cid:17)(cid:1)(cid:7)(cid:10)(cid:10)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
(cid:32)(cid:1)
(cid:33)(cid:1)
(cid:4)(cid:9)(cid:24)(cid:12)(cid:23)(cid:24)(cid:1)(cid:7)(cid:8)(cid:6)(cid:1)
(cid:19)(cid:10)(cid:23)(cid:12)(cid:22)(cid:28)(cid:12)(cid:11)(cid:1)
(cid:13)(cid:22)(cid:19)(cid:17)(cid:1)(cid:7)(cid:10)(cid:10)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
(cid:2)(cid:16)(cid:15)(cid:12)(cid:18)(cid:24)(cid:1)
(cid:2)(cid:1)
(cid:34)(cid:1)
(cid:2)(cid:19)(cid:17)(cid:20)(cid:9)(cid:22)(cid:12)(cid:1)(cid:19)(cid:10)(cid:23)(cid:12)(cid:22)(cid:28)(cid:12)(cid:11)(cid:1)
(cid:7)(cid:8)(cid:6)(cid:23)(cid:1)(cid:13)(cid:22)(cid:19)(cid:17)(cid:1)(cid:7)(cid:10)(cid:10)(cid:12)(cid:5)(cid:10)(cid:8)(cid:1)
Figure 6: Steps taken when comparing STRs in the
auditing protocol.
that the identity provider of any user they contact is not
equivocating about its directory. In other words, clients
need to verify that any provider of interest is maintaining
a linear STR history. Comparing each observed STR with
every single other client with which a given client com-
municates would be a signiﬁcant performance burden.
Therefore, CONIKS allows identity providers to facili-
tate auditing for their clients by acting as auditors of all
CONIKS providers with which their users have been in
communication (although it is also possible for any other
entity to act as an auditor). Providers achieve this by dis-
tributing their most recent STR to other identity providers
in the system at the beginning of every epoch.5
The auditing protocol in CONIKS checks whether an
identity provider is maintaining a linear STR history. Iden-
tity providers perform the history veriﬁcation whenever
they observe a new STR from any other provider, while
clients do so whenever they request the most recent STR
from a speciﬁc identity provider directly. We summa-
rize the steps required for an auditor to verify an STR
history in Fig. 5. The auditor ﬁrst ensures that the pro-
vider correctly signed the STR before checking whether
the embedded hash of the previous epoch’s STR matches
what the auditor saw previously. If they do not match, the
provider has generated a fork in its STR history.
Because each auditor has independently veriﬁed a pro-
vider’s history, each has its own view of a provider’s STR,
so clients must perform an STR comparison to check for
possible equivocation between these views (summarized
in Fig. 6). Once a client has veriﬁed the provider’s STR
history is linear, the client queries one or more CONIKS
5 CONIKS could support an auditing protocol in which clients di-
rectly exchange observed STRs, obviating the need of providers to act
as auditors. The design of such a protocol is left as future work.
identity providers at random.6 The client asks the auditor
for the most recent STR it observed from the provider
in question. Because the auditor has already veriﬁed the
provider’s history, the client need not verify the STR re-
ceived from the auditor. The client then compares the
auditor’s observed STR with the STR which the provider
directly presented it. The client may repeat this process
with different auditors as desired to increase conﬁdence.
For an analysis of the number of checks necessary to
detect equivocation with high probability, see App. B.
CONIKS auditors store the current STRs of CONIKS
providers; since the STRs are chained, maintaining the
current STR commits to the entire history. Because this
is a small, constant amount of data (less than 1 kB) it
is efﬁcient for a single machine to act as an auditor for
thousands of CONIKS providers.
4.2 Secure Communication with CONIKS
When a user Bob wants to communicate with a user Al-
ice via their CONIKS-backed secure messaging service
foo.com, his client client B performs the following steps.
We assume both Alice’s and Bob’s clients have registered
their respective name-to-key bindings with foo.com as
described in §4.1.1.
1. Periodically, client B checks the consistency of Bob’s
binding. To do so, the client ﬁrst performs the
monitoring protocol (per §4.1.3), and then it audits
foo.com (per §4.1.4).
2. Before sending Bob’s message to client A, client B
looks up the public key for the username alice at
foo.com (§4.1.2). It veriﬁes the proof of inclusion
for alice and performs the auditing protocol (§4.1.4)
for foo.com if the STR received as part of the lookup
is different or newer than the STR it observed for
foo.com in its latest run of step 1.
3. If client B determines that Alice’s binding is consis-
tent, it encrypts Bob’s message using alice’s public
key and signs it using Bob’s key. It then sends the
message.
Performing checks after missed epochs. Because STRs
are associated with each other across epochs, clients can
“catch up” to the most recent epoch if they have not veri-
6We assume the client maintains a list of CONIKS providers acting
as auditors from which it can choose any provider with equal probability.
The larger this list, the harder it is for an adversary to guess which
providers a client will query.
USENIX Association  
7
24th USENIX Security Symposium  389
ﬁed the consistency of a binding for several epochs. They
do so by performing a series of the appropriate checks un-
til they are sure that the proofs of inclusion and STRs they
last veriﬁed are consistent with the more recent proofs.
This is the only way a client can be sure that the security
of its communication has not been compromised during
the missed epochs.
Liveness. CONIKS servers may attempt to hide mali-
cious behavior by ceasing to respond to queries. We
provide ﬂexible defense against this, as servers may also
simply go down. Servers may publish an expected next
epoch number with each STR in the policy section P.
Clients must decide whether they will accept STRs pub-
lished at a later time than previously indicated.
Whistleblowing. If a client ever discovers two inconsis-
tent STRs (for example, two distinct versions signed for
the same epoch time), they should notify the user and
whistleblow by publishing them to all auditors they are
able to contact. For example, clients could include them
in messages sent to other clients, or they could explicitly
send whistleblowing messages to other identity providers.
We also envision out-of-band whistleblowing in which
users publish inconsistent STRs via social media or other
high-trafﬁc sites. We leave the complete speciﬁcation of
a whistleblowing protocol for future work.
4.3 Multiple Security Options
CONIKS gives users the ﬂexibility to choose the level of
security they want to enforce with respect to key lookups
and key change. For each functionality, we propose two
security policies: a default policy and a strict policy,
which have different tradeoffs of security and privacy
against usability. All security policies are denoted by
ﬂags that are set as part of a user’s directory entry, and
the consistency checks allow users to verify that the ﬂags
do not change unexpectedly.
4.3.1 Visibility of Public Keys
Our goal is to enable the same level of privacy SMTP
servers employ today,7 in which usernames can be queried
(subject to rate-limiting) but it is difﬁcult to enumerate
the entire list of names.
Users need to decide whether their public key(s) in the
directory should be publicly visible. The difference be-
tween the default and the strict lookup policies is whether
the user’s public keys are encrypted with a secret sym-
metric key known only to the binding’s owner and any
7 The SMTP protocol deﬁnes a VRFY command to query the exis-
tence of an email address at a given server. To protect user’s privacy,
however, it has long been recommended to ignore this command (report-
ing that any usernames exists if asked) [42].
other user of her choosing. For example, if the user Al-
ice follows the default lookup policy, her public keys are
not encrypted. Thus, anyone who knows Alice’s name
PI:EMAIL can look up and obtain her keys from her
foo.com’s directory. On the other hand, if Alice follows
the strict lookup policy, her public keys are encrypted
with a symmetric key only known to Alice and the users
of her choosing.
Under both lookup policies, any user can verify the
consistency of Alice’s binding as described in §4, but if
she enforces the strict policy, only those users with the
symmetric key learn her public keys. The main advantage
of the default policy is that it matches users’ intuition
about interacting with any user whose username they
know without requiring explicit “permission”. On the
other hand, the strict lookup policy provides stronger
privacy, but it requires additional action to distribute the
symmetric key which protects her public keys.
4.3.2 Key Change
Dealing with key loss is a difﬁcult quandary for any secu-
rity system. Automatic key recovery is an indispensable
option for the vast majority of users who cannot perpet-
ually maintain a private key. Using password authenti-
cation or some other fallback method, users can request
that identity providers change a user’s public key in the
event that the user’s previous device was lost or destroyed.
If Alice chooses the default key change policy, her iden-
tity provider foo.com accepts any key change statement
in which the new key is signed by the previous key, as
well as unsigned key change requests. Thus, foo.com
should change the public key bound to PI:EMAIL
only upon her request, and it should reﬂect the update to
Alice’s binding by including a key change statement in
her directory entry. The strict key change policy requires
that Alice’s client sign all of her key change statements
with the key that is being changed. Thus, Alice’s client
only considers a new key to be valid if the key change
statement has been authenticated by one of her public
keys.
While the default key change policy makes it easy for
users to recover from key loss and reclaim their username,
it allows an identity provider to maliciously change a
user’s key and falsely claim that the user requested the
operation. Only Alice can determine with certainty that
she has not requested the new key (and password-based
authentication means the server cannot prove Alice re-
quested it). Still, her client will detect these updates and
can notify Alice, making surreptitious key changes risky
for identity providers to attempt. Requiring authenticated
key changes, on the other hand, does sacriﬁce the ability
for Alice to regain control of her username if her key is
390  24th USENIX Security Symposium 
8
USENIX Association
ever lost. We discuss some implications for key loss for
strict users in §6.