sume temporal correlation of packet delays. Removing the
dependence on this assumption is beneﬁcial in many ways,
as explained in Sec. 1.
Besides packet delay measurement techniques, sketching
is also very relevant to this work. Most relevant to us are
two similar data structures: Multi-Stage Filters [13], which
are designed for elephant ﬂow detection, and the Count-Min
Sketch [9], which can provide per-ﬂow estimates with proba-
bilistic accuracy guarantees. Other sketching techniques are
reviewed and compared in [8].
7. CONCLUSIONS
We have presented a sketch-based data structure capable
of producing per-ﬂow one-way delay estimates. Although
sketching naturally produces the best estimates for larger
ﬂows, this data structure can enhance the accuracy of arbi-
trary ﬂows. For measurement in networks with packet loss,
we have combined our sketching technique with a recently
appeared data structure called Lossy Diﬀerence Aggregator.
State-of-art techniques rely on temporal correlation of de-
lays to produce their estimates. However, in practice, routers
can use various queueing policies for diﬀerent kind of traﬃc,
which greatly reduces the eﬀective of said techniques.
In
our evaluation, we show how our technique achieves higher
accuracy than such techniques when using a similar amount
of memory, even in the presence of packet loss.
We have also presented a practical deployment scenario
where our technique and its ability to improve measurement
for arbitrary ﬂows could be very useful. In particular, our
technique could very well cater a data center with shared re-
sources, where various applications present diverse degrees
of dependency on network delay.
In such a scenario, our
technique can be used to obtain extremely precise measure-
ments for the most critical applications, while still providing
an acceptable degree of accuracy for other applications.
8. ACKNOWLEDGMENTS
This research was funded by the Spanish Ministry of Sci-
ence and Innovation under contract TEC2011-27474 (NO-
MADS project), and by the Comissionat per a Universi-
tats i Recerca del DIUE de la Generalitat de Catalunya (ref.
2009SGR-1140).
9. REFERENCES
[1] Corvil. http://www.corvil.com/.
[2] Juniper Networks T series Core Routers Architecture
Overview. www.juniper.net/us/en/local/pdf/
whitepapers/2000302-en.pdf.
[3] M. Alizadeh, A. Greenberg, D. A. Maltz, J. Padhye,
P. Patel, B. Prabhakar, S. Sengupta, and
495M. Sridharan. Data center TCP (DCTCP). In Proc. of
ACM SIGCOMM, 2010.
[4] P. Barlet-Ros, G. Iannaccone, J. Sanju`as-Cuxart,
D. Amores-L´opez, and J. Sol´e-Pareta. Load shedding
in network monitoring applications. In Proc. of
USENIX Annual Technical Conf., 2007.
[5] J. Bolot. Characterizing end-to-end packet delay and
loss in the internet. Journal of High Speed Networks,
2(3):289–298, 1993.
[6] B. Choi, S. Moon, R. Cruz, Z. Zhang, and C. Diot.
Practical delay monitoring for ISPs. In Proc. of ACM
CoNEXT, 2005.
[7] Cisco. NetFlow.
http://www.cisco.com/web/go/netﬂow.
[8] G. Cormode and M. Hadjieleftheriou. Methods for
ﬁnding frequent items in data streams. The VLDB
Journal, 19(1):3–20, 2010.
[9] G. Cormode and S. Muthukrishnan. An improved
data stream summary: the count-min sketch and its
applications. Journal of Algorithms, 55(1):58 – 75,
2005.
[10] L. De Vito, S. Rapuano, and L. Tomaciello. One-way
delay measurement: State of the art. IEEE
Transactions on Instrumentation and Measurement,
57(12):2742–2750, 2008.
[11] N. Duﬃeld and M. Grossglauser. Trajectory sampling
for direct traﬃc observation. IEEE/ACM
Transactions on Networking, 9(3):280–292, 2001.
[12] Endace. DAG network monitoring cards.
http://www.endace.com.
[13] C. Estan and G. Varghese. New Directions in Traﬃc
Measurement and Accounting: Focusing on the
Elephants , Ignoring the Mice. ACM Transactions on
Computer Systems, 21(3):270–313, 2003.
[14] H. Finucane and M. Mitzenmacher. An improved
analysis of the lossy diﬀerence aggregator. ACM
SIGCOMM Computer Communication Review,
40(2):4–11, 2010.
[15] S. Fred, T. Bonald, A. Proutiere, G. Regnie, and
J. Roberts. Statistical bandwidth sharing: a study of
congestion at ﬂow level. In Proc. of ACM SIGCOMM,
2001.
[16] IEEE. IEEE/ANSI 1588 standard for a precision clock
synchronization protocol for networked measurement
and control systems, 2002.
[17] R. Kompella, K. Levchenko, A. Snoeren, and
G. Varghese. Every microsecond counts: tracking
ﬁne-grain latencies with a lossy diﬀerence aggregator.
In Proc. of ACM SIGCOMM, 2009.
[18] M. Lee, N. Duﬃeld, and R. Kompella. Not all
microseconds are equal: ﬁne-grained per-ﬂow
measurements with reference latency interpolation. In
Proc. of ACM SIGCOMM, 2010.
[19] M. Lee, N. Duﬃeld, and R. Kompella. Two samples
are enough: opportunistic ﬂow-level latency estimation
using netﬂow. In Proc. of IEEE INFOCOM, 2010.
[20] M. Lee, S. Goldberg, R. Kompella, and G. Varghese.
Fine-grained latency and loss measurements in the
presence of reordering. In Proc. of ACM
SIGMETRICS, 2011.
[21] R. Martin. Wall street’s quest to process data at the
speed of light.
www.informationweek.com/news/infrastructure/
showArticle.jhtml?articleID=199200297.
[22] S. Moon, P. Skelly, and D. Towsley. Estimation and
removal of clock skew from network delay
measurements. In Proc. of IEEE INFOCOM, 1999.
[23] K. Park, G. Kim, and M. Crovella. On the
relationship between ﬁle sizes, transport protocols,
and self-similar network traﬃc. In Proc. of
International Conference on Network Protocols, 2002.
[24] V. Paxson. Measurements and analysis of end-to-end
Internet dynamics. Technical Report CSD-97-945,
University of California at Berkeley, 1998.
[25] V. Paxson. On calibrating measurements of packet
transit times. In ACM SIGMETRICS Performance
Evaluation Review, volume 26, pages 11–21. ACM,
1998.
[26] C. Y. Robert and J. Segers. Tails of random sums of a
heavy-tailed number of light-tailed terms. Insurance:
Mathematics and Economics, 43(1):85 – 92, 2008.
[27] J. Sanjuas-Cuxart, P. Barlet-Ros, and J. Sol´e-Pareta.
Validation and Improvement of the Lossy Diﬀerence
Aggregator to Measure Packet Delays. Traﬃc
Monitoring and Analysis Workshop, 2010.
[28] J. Sommers, P. Barford, N. Duﬃeld, and A. Ron.
Accurate and eﬃcient SLA compliance monitoring. In
Proc. of ACM SIGCOMM, 2007.
[29] L. Zhang, Z. Liu, and C. Honghui Xia. Clock
synchronization algorithms for network measurements.
In Proc. of IEEE INFOCOM, 2002.
496Summary Review Documentation for 
“Sketching the Delay: Tracking Temporally Uncorrelated 
Flow-Level Latencies” 
Authors:  J. Sanjuas-Cuxart, P. Barlet-Ros, N. Duffield, R. Kompella 
Reviewer #1 
Strengths:  Entire  scheme  has  been  implemented  and  tested  on 
real traces. 
Reasonable  analysis  of  data  structure  space  requirements  and 
accuracy. 
Weaknesses: Relatively incremental approach.  Scheme requires 
O(#flows)  state;  perhaps  this  is  unavoidable.    Some  claims 
(accuracy/state requirement) in paper are inflated.  The paper does 
not describe how to set many different parameters. 
Comments to Authors: The assumption of synchronized clocks 
is big, but is not paid due attention.  The accuracy of the algorithm 
depends entirely on the synchronization of the sender and receiver 
clocks:  how  expensive  are  the  DAG  cards  used  to  timestamp 
packets?  How does this cost compare to the high frequency active 
probes mentioned in the Introduction? 
The  LDS  algorithm  is  a  relatively  simple  merge  of  existing 
techniques.  Handling  lost/reordered  packets  is  the  most  difficult 
problem, and that is dealt with, rather inelegantly, by smearing the 
measurements  over  multiple  buckets  and  hoping  that  some 
measurements survive. 
The virtual LDS scheme is not likely to be effective if some flows 
incur  heavy  losses,  as  might  be  the  case  with  best  effort  flows.  
The  evaluations  only  assume  <1% 
is  overly 
conservative. 
How is the \alpha parameter set?  Does choosing a small \alpha 
lead to high variance in results? 
The  x  parameter  (threshold  of  collision  by  number  of  packets) 
ignores per-flow variability.  If a low latency flow gets mapped to 
flows with less than x packets but each with much higher latency, 
then 
flow's  estimates  will  be  affected 
disproportionately.  It is not clear why the number of interfering 
packets is chosen as the measure of interference. 
Evaluation: 
The base parameters use half as many counters as flows.  Is the 
total  memory  used  not  sufficient  to  maintain  per  flow  statistics?  
Some of the experiments use 10 times more counters than flows - 
might as well keep per-flow state? 
In general, the parameters in the experiments are chosen given the 
trace statistics, which says nothing about how one would set the 
parameters on a live network.   
loss,  which 
the 
low 
latency 
The  experiments  were  performed,  post-hoc,  on  a  trace.    Is  it 
possible to perform experiments, live, on a high speed link?  The 
other methods, NetFlow MPE for instance, are operating on a live 
link,  and  a  offline  comparison  does  not  seem  fair.    Especially 
when  the  comparison  requires    O(#flow)  state  to  provide  a  per-
flow measure of latency. 
Nits: 
Section  2.3.3:    How  are  individual  packets  mapped  to  one  of  k 
cells? 
Figure 7: how many cells were used in the experiments? 
The  paper  is  unnecessarily  long:  A  lot  of  the  simple  ideas 
presented in pseudocode can be removed.                                                                        
Reviewer #2 
Strengths:  The  authors  provide  nice  and  intuitive  algorithmic 
optimizations to advance the state of the art in delay estimation at 
the flow level. 
Weaknesses: The work appears too incremental to a large body of 
prior work by some of the authors. 
Comments to Authors:  The paper does a nice job of building up 
a nice algorithmic solution to the problem proposed. The results 
indicate the performance advantages of the proposed scheme and 
its accuracy. 
However,  my  understanding  of  the  paper  is  that  it  is  very 
incremental to prior work. The LDS scheme as described, appears 
to  be  the  LDA  scheme  enhanced  with  some  sketch  based  data 
structures  to  track  flows  better.  Seems  like  a  very  simple 
optimization beyond prior work. 
Unfortunately, I am unable to judge how this paper is a significant 
enhancement over prior art. 
Reviewer #3 
Strengths: -cute idea 
- relevant problem 
- extensive evaluation with real traces 
- well written. 
Weaknesses: - fairly incremental to the authors’ own prior work 
- not sure how feasible the synchronization assumption is 
Comments  to  Authors:  How  feasible  is  microsecond  level 
synchronization? The paper depends quite heavily on it. I imagine 
497the 
that it should be fine, given that such synchronization is regularly 
achieved  in  some  systems  (e.g.  cellular  wireless  networks).  But 
what is the cost? 
Some  of  the  parameters  in  the  experiments  are  unclear.  For 
example, how is the \alpha parameter set? 
What  happens  if  packets  are  lost?  Does  it  not  distort  the 
measurements? 
Reviewer #4 
Strengths: - Novel approach for estimating delays in the network, 
even when there is no assumption on the temporal dependencies 
of the flows.  
- Experimental evidence shows the improvement over state of the 
art approaches in realistic scenarios. 
Weaknesses: There are not enough theoretical guarantees on error 
that validate the goodness of the LDS approach. 
Comments to Authors:  1. This paper removes the assumption of 
temporal  correlation  but 
flows  are  not  necessarily 
"uncorrelated". 
2.  In  Section  3.2,  it  is  not  clear  why  the  minimization  problem 
(U_l  +  V_l)  is  reduced  to  minimization  problem  of  V_l.  Is  it 
practical to make the assumption? 
3.  Under  packet  loss  scenario,  the  result  shows  the  MB-LDS 
performs better than LDS.  But it does not have any comparison 
with other state of the art approaches. 
4. How MB-LDS performs under higher packet loss scenario? 
5.  In  Figure  8,  the  bronze  customers'  accuracy  does  not  look 
affected with the higher weights in gold and silver. The proportion 
of  flows  is  the  reason.  It  will  be  interesting  to  first  see  how  the 
proportion are affecting the bronze customers when they are not 
that asymmetric. 
Reviewer #5 
Strengths: A more practical and effective technique for per-flow 
delay measurement; solid presentation; good evaluation. 
Weaknesses: Evaluation focuses on average delay. 
Comments to Authors: The paper present LDS, a new sketching-
based  technique  and  associated  data  structure  to  obtain  per-flow 
latency measurements. LDS does not rely on model assumptions 
about the relation between delays across flows, has lower memory 
requirement and network overhead than existing techniques and a 
data structure that can resized based on necessary accuracy.  
I  expected  to  see  but  did  not  find  references  to  papers  that 
evaluate  the  impact  of  prioritization,  load  balancing,  etc  on  the 
effectiveness of other techniques.  
The  presentation  of  LDS  is  well  done,  with  a  step-by-step 
introduction  of  the  ideas  starting  with  SDS  and  relaxing 
assumptions  to  introduce  LDS,  flow  weighting  and  multibank-
LDS. 
The presentation includes results from an evaluation of LDS using 
data  collected  from  links  connecting  a  research  and  a  university 
networks  to  (rest  of)  the  Internet.  The  evaluation  section  does  a 
pretty good job at presenting the advantages and potential issues 
with the technique.  
I did not see an analysis of the effectiveness of the technique in 
capturing other estimates than average. Sec. 4.3 briefly discusses 
how other information could be mined but there is no follow-up in 
the evaluation on the effectiveness of the approach to capture, for 
instance, delay variations. 
It  would  be  good  to  drop  an  example  of  number  of  flows  that 
makes  collecting  and  exchanging  per-flow  state  prohibitively 
expensive 
Response from the Authors 
The first and third reviewers raise concerns over the assumption 
of  clock  synchronization.  This  assumption  is  common  to  many 
one-way delay measurement methods, including active techniques 
based on probing. The authors agree that it is an assumption that 
raises  difficulties,  even  if  they  can  be  solved  with  the  methods 
presented in the paper. Removing this assumption was out of the 
scope  of  this  paper.  We  have  provided  references  to  papers  that 
specifically deal with the clock synchronization issue.   
The  paper  introduces  a  "half  as  many  counters  as  flows" 
configuration since it has the advantage that results make for a fair 
comparison with other methods that require similar memory usage 
(e.g., MPE). The evaluation also tests a configuration with fewer 
counters  satisfactorily  (fig.  5).  We  further  stress  that  LDS  still 
outperforms  the  competition  using  10%  of  this  amount  of 
memory. 
The  reviewers  raise  the  question  of  whether  LDS  works  under 
higher loss. Low loss is an assumption of our paper (Sec. 2.1). We 
argue 
that  delay  measurements  might  not  be  particularly 
interesting when loss is very high, since TCP does not work under 
high  loss.  We  now  point  that  under  such  conditions,  other  loss-
tolerant  methods  might  be  a  better  option  than  LDS,  since  k 
should be larger and would require more memory. 
The number of packets in each bucket provides an assessment of 
the amount of interfering packets (x) although the reviewers raise 
the  valid  point  that  the  measurements  can  be  damaged  if  delays 
differ  largely  in  magnitude.  While  other  alternatives  exist  (e.g., 
combining multiple cells), we defend our choice in Sec. 2.2. Also, 
we have extended the discussion on how to map packets to each 
virtual LDA cell (Sec. 2.3.3) 
In the evaluation, we have included our choice of the α parameter. 
We also explain that the results of the experiments are equivalent 
to  an  on-line  setting,  that  LDS  can  actually  run  on-line,  and 
discuss  the  accuracy  of  reference  methods  under  loss.  The 
evaluation  also  acknowledges  that  weighting  is  only  useful  to 
increase the accuracy for a small set of flows. 
We  ensured  that  other  less  critical  concerns  raised  by  the 
reviewers were discussed in the paper to our best ability. 
498