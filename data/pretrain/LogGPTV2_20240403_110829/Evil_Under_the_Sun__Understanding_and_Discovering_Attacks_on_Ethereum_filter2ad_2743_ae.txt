be too Dapp-speciﬁc and noisy to capture the operational
intent, since the execution trace may contain many opera-
tions that happen inside the Dapp, for example, invocation
of the Dapp’s internal libraries to generate a pseudo-random
number (Figure 5), which is less relevant to the EOA-Dapp
interactions of interest to us (attack preparation, exploitation,
propagation and completion). To address this issue, we em-
ploy an EOA-Dapp-execution attention model to highlight the
useful information related to the EOA’s intent on the Dapp.
Here the attention ai is used to adjust the vector representation
of the transaction graph tgi. It is determined by a weighted
combination of the vector representations of EOA eoai, Dapp
di (produced by a vertex embedding [25]) and that of tgi
(produced by graph embedding [19]). Its weights are learnt
through an LSTM model (Figure 9) within an end-to-end
deep neural network that ultimately outputs the feature vector
characterizing whole input (the vector sequence representing
a transaction sequence).
ai = so f tmax(NE(eoai) ⊕ NE(di) · GE(tgi)T ),
ei = ai · GE(tgi)
(2)
where ⊕ is the concatenate operation, NE() is the vertex
embedding (e.g., node2vec [25]) of the input, which gener-
ates a vector representation for each node, GE() is the graph
embedding (e.g., structure2vec [19]) of the input, which gen-
erates a vector representation for each transaction graph, and
so f tmax(x)i = exp(xi)
∑ j exp(x j)) . In our implementation, the length
of the node embedding is set to 64. We construct the con-
catenation of the EOA and the Dapp vertex embedding into a
vector with a length of 128.
In the deep neural network, we further utilize a standard
combination gate [28] to determine how much information
from the EOA, the Dapp and the transaction execution will be
used through adjusting their weights. In this way, we obtain
the representation xi of the transaction txi:
ci = σ(W · (NE(eoai) ⊕ NE(di) ⊕ ei)T + b),
xi = (1 − ci) ◦ ei + ci ◦ (GE(tgi))
(3)
where W is a weight matrix, b is a bias, σ is the sigmoid
function, and ◦ is the element-wise multiplication. Given
transaction encoding xi, we use a Bidirectional LSTM [24],
which has been trained with the classiﬁer (see below) on
labeled dataset (Section 4.4), to capture the inner relationship
between transactions. In this way, the transaction sequence
can be converted into a vector h by the trained model.
Sequence classiﬁcation. The output of the attention model, h,
serves as the input to a multilayer perception (MLP) classiﬁer.
The MLP is used by DEFIER to generate the probability y′
for a given attack stage the sequence is associated with. The
Table 6: Dataset and evaluation results.
Results
Dataset
# transactions
badset 57,855
goodset 39,124
Groundtruth set
Unknown set
2,350,779
Sampled testset
30,888
premicro 98.2%, premacro 92.4%
recmicro 98.1%, recmacro 98.4%
positive 476,334
premicro 91.7%
premacro 83.6%
premicro and premacro: micro of precision, macro of precision
recmicro and premacro: micro of recall, macro of recall
positive: transactions that labeled as one of attack stages
(a) Model performance with dif-
ferent window size
(b) ROC
Figure 10: Evaluation results.
whole Sequence-based classiﬁcation module, including the
LSTM and the MLP, can be trained together through stochas-
tic gradient descent, a typical way to train such a complicated
model [14], on labeled data (Section 4.4). In our study, we
built a Bi-LSTM with three folds, whose convolution sizes
were 128, hidden sizes were 256 and batch sizes were 128.
The epochs were set as 20 and learning rate was set as 0.0001.
The hidden size of MLP was set as 256.
4.4 Evaluation
Here we evaluate DEFIER and elaborate on the challenges in
multi-stage exploit transaction identiﬁcation.
Evaluation with groundtruth set. We evaluated DEFIER
over the following ground-truth dataset as shown in Table
6: for the bad set, we collected 57,855 transaction sequences
associated with Dapp attacks from our measurement study. In
particular, for exploit transactions in the same attack stage,
we ﬁrst order them by timestamp, and then deﬁne a sliding
context window with the size of w (w=8 in our implemen-
tation) to chunk the time-ordered transactions into transac-
tion sequences. Finally, we label those transaction sequences
by their attack stages. We detail the annotation process in
Appendix 7.3. In this way, we built a bad set with 57,855
transactions (469 at the attack preparation stage, 22,333 at the
exploit stage, 34,763 at the attack propagation stage and 290
at the mission completion stage). The transactions of good
set were gathered from 56 victim Dapps related to the bad
set and 318 manually checked normal EOAs on these Dapps.
Speciﬁcally, we ran the module of Preprocessing to generate
the transaction sequences with the same size of context win-
dow. In this way, we construct a good set with 39,124 normal
transaction sequences. Running on these sets under 10-fold
cross validation, DEFIER shows a micro-precision of 98.2%,
a macro-precision of 92.4%, a micro-recall of 98.1% and a
macro-recall of 98.4%.
Table 7: Performance comparison in different models
Method
RNN
RNN
LSTM
LSTM
Attention
no attention
attention
no attention
attention
precision
0.965
0.974
0.977
0.982
recall
0.962
0.969
0.975
0.981
F1
0.963
0.971
0.976
0.981
Missed cases. On the ground-truth dataset, seven cases were
missed by DEFIER. These transactions fell through the cracks
due to inadequate attack-related semantic content in their
clusters. In three cases, we found that the size of the sliding
context window is not large enough to capture some attack
behaviors, and as a result, the adversary’s operational intents
and the attack stages could not be determined. In other cases,
the problem comes from the presence of reverted transactions,
whose original execution traces cannot be obtained, which
prevents DEFIER from building up their transaction graphs.
Determining the number of missed malicious transactions
in the large-scale unknown set (with more than 2.3 million
transactions, 342K clusters) is challenging. What we did in
our research was to ﬂag a transaction cluster as the class
types with the largest predicted probability, as well as the
second largest predicted probability when it is greater than 0.5.
This strategy will include more ﬂagged cases, at the expense
of precision. In this way, our approach ﬂagged 1,069 more
transaction clusters. We manually analyzed all of them and
found 167 new exploit transaction clusters. Looking into these
missed cases, we found that 146 cases were caused by the
window size or reverted transactions, as mentioned above. The
remaining 21 cases resulted from the lack of Dapp information
for transaction graph node labeling (see Section 3.1). This
problem can be handled by a more comprehensive Dapp list.
Falsely detected cases. We also found two major causes for
the 322 false positives observed in our study (Section 4.5).
Those transaction clusters are either semantically similar to
the clusters in another attack stage, or having attack patterns
of multiple attack stages. For example, when attackers evolve
their attack strategy (Section 3.2) frequently without exploita-
tion behavior, our model may misclassify these exploitation
clusters as attack preparation clusters. This is because the
transactions during attack strategy evolution can be semanti-
cally similar to those for attack preparation: the adversary kept
using new exploit contracts to interact with a Dapp, and attack
costs were transferred to the new exploit contract to bootstrap
attack. The second type of false positives is caused by the
incorrect transaction clustering. For example, one transaction
cluster of CityMayor consists of the transactions at attack
preparation stage and exploitation stage, because the time
interval between these transactions is small (≤ 10 minutes),
and the similarity of these transactions is large (average TG
distance ≤ 0.33).
Window=5  Window=8     Window=1086889092949698100percentage(%)94.395.795.293.795.595.093.895.695.1precisionrecall f1-scoreTable 8: Performance comparison in different epochs
Table 10: Victim Dapps in different categories.
Epoch
learningrate
precision
10
20
50
100
0.001
0.001
0.001
0.001
0.965
0.982
0.980
0.994
recall
0.962
0.981
0.980
0.980
F1
0.963
0.981
0.980
0.980
Table 9: Performance comparison in different learning rates
Epoch
learningrate
precision
20
20
20
20
20
0.1
0.01
0.001
0.0001
0.00001
0.958
0.978
0.982
0.985
0.918
recall
0.914
0.977
0.981
0.982
0.906
F1
0.932
0.977
0.981
0.983
0.908
Parameter and model selection. In Section 4.2, the size
of the sliding context window w controls the length of the
transactions used to inspect the operational context. Here
a small window size might contain inadequate information
about the operational context, while a large window may bring
in the information across different stages, which leads to noise.
In our research, we analyzed the impact of various w (5, 8, 10),
as illustrated in Figure 10(a) and 10(b), over the ground-truth
dataset, and chose the one with the best performance (w = 8).
Parameters such as the number of epochs and the learning
rates for the LSTM model are used to control the performance
of the model. In our study, we tuned the model by varying
the number of epochs from 10 to 100 and the learning rates
from 0.00001 to 0.1. From the result shown in Table 8 and
Table 9, we can see that the classiﬁcation performs best under
20 epochs and a learning rate of 0.0001.
In our study, we compared the effectiveness of RNN and
LSTM models on the sequence classiﬁcation tasks. Speciﬁ-
cally, we implemented four models: RNN, RNN with atten-
tion, LSTM, LSTM with attention on the groundtruth dataset
and evaluated their effectiveness using 10-fold cross valida-
tion. Similar to the LSTM model we used (Section 4.3), the
backbone of the RNN is also three layers 128 * 256 * 128 with
the batch size of 128. Table 7 shows the results. We observe
that the LSTM with attention outperforms other sequence
classiﬁcation models.
4.5 Discovery and New Findings
We collected 104 popular Dapps and their corresponding con-
tract addresses from a Dapp ranking list [8]. On these Dapps,
we ran the Preprocessing to gather 2,350,779 transactions
from Ethereum and construct 342,224 transaction clusters.
Note that we eliminate all the transactions used in the mea-
surement study (Section 3). DEFIER inspected these trans-
actions and labeled 476,342 of them (100,081 clusters) with
one of the attack stages. These transactions are related to
attacks on 85 victim Dapps. For each victim Dapp, we ran-
domly sampled 4% of the reported transaction clusters for
manual validation. In total, we manually investigated 4,003
#
Type
Dapps/0-
Gam-
bling
Game
Finance
Token
day
51/43
5/5
2/1
Total
85/75
28/27
959/919
# attacker
EOAs/0-day
65,778
/11,339
183/183
# exploit
transactions/0-
day
360,524
/114,473
52,673
/52,176
59,872
/59,872
279/167
4,478/472
67,199
/12,608
476,342
/226,763
ex. of victim
Dapps
Lucky
Blocks
SpaceWar
STOX
Power of
Bubble
Table 11: Unknown set result.
Attack stage
Attack
preparation
Exploitation
Attack
propagation
# Dapps/0-