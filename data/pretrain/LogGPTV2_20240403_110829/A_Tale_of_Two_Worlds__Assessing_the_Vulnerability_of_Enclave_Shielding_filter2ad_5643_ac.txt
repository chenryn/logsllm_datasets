considered runtimes. However, the example of Keystone, and prior
research on ARM TrustZone [33, 34], shows that the attack surface
studied here is not necessarily limited to TEEs using the single-
address-space approach taken by SGX. As part of our analysis, we
found that certain TEE-specific design considerations may some-
times significantly impact exploitability. When applicable, such
TEE design considerations are discussed throughout the paper.
4 ESTABLISHING A TRUSTED ABI
Similarly to traditional user/kernel isolation, TEE-enabled proces-
sors typically only take care of switching to a fixed entry point
and thereafter leave it up to trusted runtime software to securely
bootstrap the enclaved execution. In practice, this implies that ad-
versaries may still control a large fraction of the low-level machine
state (e.g., CPU registers) on enclave entry. Hence, a trusted as-
sembly entry routine is responsible to establish an ABI-compliant
machine state when transferring control to the shielded application,
and to save and scrub low-level machine state on enclave exit.
4.1 Sanitizing machine state on entry
After reviewing well-documented ABI-level calling conventions [10]
expected by popular C compilers, we concluded that most CPU reg-
isters can be left unmodified, apart from the stack pointer explored
in the next section. However, a more subtle concern relates to the
expected state of certain status register flags on function entry.
Attack vector #1 (status flags): Entry code should sanitize register flags
that may adversely impact program execution. ▷ Prevalent in production
and research runtimes, but exclusively Intel SGX (x86 CISC).
TEE design. The underlying processor architecture used in the
specific TEE design may greatly impact the resulting ABI-level at-
tack surface. That is, in comparison to Intel’s notoriously complex
x86 CISC architecture [8], simpler RISC-based TEEs such as San-
cus [32], Keystone [21], or ARM TrustZone [34] tend to impose less
obligations for trusted software to sanitize low-level machine state.
For instance, we found that the Sancus runtime should only take
care to clear the interrupt flag. Likewise, TrustZone even transpar-
ently takes care to save/restore secure world stack pointer registers.
Our analysis further reveals the trade-offs for implementing register
and status flag clearing in either hardware or software. For instance,
we show that the Intel SGX design leaves this responsibility largely
to software, exposing a larger attack surface.
We methodically examined all the software-visible flags in the
x86 flags register [17] and discovered two potentially dangerous
flags that may adversely impact enclaved execution if not properly
cleared. First, the Alignment Check (AC) flag may be set before
entering the enclave in order to be deterministically notified of
every unaligned memory access performed by the trusted enclave
software. This novel side-channel attack vector is closely related to
well known page fault [54] or segmentation fault [15] controlled-
channels, but this time abuses x86 #AC alignment-check exceptions.
Also, note that #PF side-channels ultimately reflect fundamental
hardware-level TEE design decisions that cannot be avoided in soft-
ware, whereas we argue that #AC leakage originates from the trusted
runtime’s failure to clear the associated status register control flag.
A second and more dangerous ABI-level attack vector arises from
the Direction Flag (DF), which can be set to change the loop behav-
ior of x86 string instructions (e.g., rep movs) from auto-increment to
auto-decrement. Commonly used x86 ABIs [10] allow for compiler
optimizations by mandating that DF shall always be cleared on func-
tion call/return. However, in case this subtle ABI requirement is not
explicitly enforced in the assembly entry routine, SGX adversaries
may change DF to an unexpected “decrement” direction before the
ecall and thereby hijack the intended direction of all subsequent
x86 string instructions executed by the enclave. This opens a severe
vulnerability that can be successfully exploited to trigger enclave
memory corruption and erroneous computation results.
Intel SGX-SDK. We experimentally confirmed that the trusted
runtime in Intel’s official SGX-SDK [19] does not clear AC or DF on
enclave entry. The latter can be tracked via CVE-2019-14565 (Intel
SA-00293), leading to enclave TCB recovery.
While unaligned data accesses (e.g., fetching a 16-bit word at an
odd byte address) are explicitly supported in the x86 architecture,
the processor may optionally be forced to generate an exception
for such accesses when software sets the AC bit in the flags reg-
ister. We developed a minimal sample enclave to showcase how
#AC exceptions may in certain scenarios reveal secret-dependent
data accesses at an enhanced byte-level granularity as compared
to state-of-the-art SGX side-channel attacks that are restricted to a
coarser-grained 64 B cacheline [39] or 4 KiB page-level [47, 54] gran-
ularity. Figure 2 illustrates the key idea behind the attack, where
a 16-bit word is loaded by specifying a byte-granular index in a
small lookup table that has been explicitly aligned to a cacheline
boundary (e.g., as might also be performed in a streamed data or
string processing enclave application). In the example, secret index
0 returns the data AB, whereas secret index 1 returns BC. Our exploit
deterministically reconstructs the intra-cacheline secret-dependent
data access by observing whether or not the enclaved execution
generates an #AC alignment-check exception. One of the challenges
we encountered is to make the enclave progress after returning
from the untrusted signal handler. Since the processor automati-
cally restores the previous value of the flags register (including
the set AC bit) from enclave-private SSA memory when resuming
the enclave [8], the unaligned data access will never be allowed to
Figure 2: Misaligned, intra-cacheline secret data access.
complete. To overcome this challenge, we make use of the adver-
sary’s root privileges to load a simple kernel module that clears the
processor’s Alignment Mask (CR0.AM) to temporarily disable align-
ment checking. Combined with a single-stepping attack primitive
like SGX-Step [45], this approach allows to determine noise-free
alignment side-channel information for every single instruction in
the victim enclave.
It should be noted that the oversight of not clearing the AC flag
in the trusted runtime merely leaks address-related side-channel
information, which falls explicitly outside of SGX’s threat model [8].
However, this is distinctly not the case for the DF flag, which di-
rectly intervenes with the semantics of the enclaved execution. We
confirmed that the popular gcc v5.4 compiler replaces for instance
common strlen() and memset() invocations with inlined x86 string
instructions at optimization level -Os. We developed a start-to-end
attack scenario to show how forcibly inverting the direction of such
string operations when entering the enclave through an ecall can
lead to controlled heap corruption and memory disclosure. Our
PoC exploit targets edger8r bridge code that is automatically gen-
erated to copy input and output buffers to and from the enclave
(cf. Section 5.1 and Fig. 3). Particularly, we abuse that edger8r code
allocates the output buffers on the enclave heap and thereafter uses
memset() to securely initialize the newly allocated buffer to all-zero.
However, setting DF before the ecall causes the memset() direction
to be inverted and any preceding heap memory to be corrupted (i.e.,
zeroed). Due to the way the SGX-SDK enclave heap is organized,
this will ultimately lead to a crash on the next free() invocation in
the edger8r code. Every heap frame is preceded by a size field and
a pointer to a meta-data bookkeeping structure. Such pointers are
stored in xor-ed form with a randomly generated secret constant
to harden the code against traditional heap corruption attacks. We
confirmed that after erroneously zeroing the preceding heap frames,
the resulting pointer will most likely end up as a non-canonical
64-bit address and halt the enclave by means of a general protec-
tion fault. However, before finally calling free() and detecting the
heap corruption, the trusted edger8r-generated code still copies the
allocated output buffer outside the enclave, potentially leading to
secret disclosure (as this buffer has never been properly zeroed).
We note that the heap corruption in itself may also be leveraged in
application-specific scenarios, e.g., zeroing out a cryptographic key
residing in the preceding heap frame.
Microsoft Open Enclave SDK. We experimentally confirmed
that OE suffers from the same DF vulnerability described above
(tracked via CVE-2019-1370). However, we found that after enter-
ing the enclave with the DF flag set, the trusted runtime already
crashes early-on in the entry path. The reason for this is that on
our machines (gcc v5.4 using the default Makefile), one of the
compiled entry functions uses a rep string instruction to initialize a
local variable on the call stack. Hence, setting DF leads to memory
unaligned data access #AC exception64B cacheline   ABDindex (secret)C; % RDI = attacker arg
cmp $RETURN_FROM_OCALL , % rdi
je .Lreturn_from_ocall
...
1
2
3
4 .Lreturn_from_ocall
5 ⭑ mov % gs : SGX_LAST_STACK , % rsp
6
7
...
ret
Listing 1: Low-level ocall return path in Graphene-SGX.
corruption by overwriting a piece of the trusted call stack with
zeroes. We have not attempted to further exploit this behavior.
Other SGX runtimes. When reviewing the assembly entry rou-
tines of the other SGX-based shielding systems (cf. Table 1), we
found that none of them sanitizes AC, whereas interestingly both
Rust-EDP and Graphene-SGX clear DF on enclave entry. Note that
Google’s Asylo framework is built on top of the Intel SGX-SDK and
hence inherits all of the vulnerabilities described above.
4.2 Maintaining the call stack abstraction
In order to safeguard enclave confidentiality and integrity, it is
essential that enclaves features their own private call stack. When
exiting the TEE by means of an ocall, the trusted stack pointer
should be stored and control flow should continue at a location
outside the enclave. After having performed an ocall, upon receiv-
ing the next ecall, the private call stack should be restored so the
runtime can “return” into the shielded application.
Attack vector #2 (call stack): Entry code should safeguard the call stack
abstraction for ecalls and ocalls. ▷ Not applicable to TrustZone, well-
understood in production SGX-SDKs, but not always in research code.
TEE design. We observed that TEE-specific design decisions
may largely impact the attack surface arising from call stack switch-
ing. That is, in ARM TrustZone [34] the stack pointer CPU register is
duplicated and fully transparently stored/restored on secure world
context switches. More versatile TEE designs like Intel SGX [8]
or Sancus [32], on the other hand, support multiple mutually dis-
trusting enclaves and leave it up to trusted runtime software to
store and restore the stack pointer across enclave boundaries. An-
other illustration of the trade-offs between hardware and software
responsibilities arises in SGX’s eexit instruction, which was de-
signed to explicitly fault when supplying in-enclave continuation
addresses [8]. Alternative TEE designs like Sancus [32], on the other
hand, expect such continuation pointer checks to be performed by
the trusted software, leaving a larger attack surface.
Graphene-SGX. After scrutinizing Graphene’s low-level boot-
strapping code, we discovered that enclave_entry.S does not prop-
erly safeguard the ocall return abstraction. Listing 1 shows how
the code unconditionally jumps to the stack pointer restore logic
after merely receiving an unchecked magic value in the %rdi register.
We experimentally confirmed that this can be abused to illegally
“return” into an enclave thread that is not waiting for a previous
ocall return. An adversary can exploit this weakness to erroneously
initialize the trusted in-enclave stack pointer of a newly started
thread with the value of the last ocall. The memory content at
these locations determine the values popped into registers, and
ultimately ret control flow.
SGX-LKL. We found a highly similar vulnerability in the way
SGX-LKL’s low-level entry code distinguishes different ecall types.
Specifically, we noticed that the unchecked parameter in %rdi can be
poisoned to trick the entry routine into erroneously calling a signal
handler for a thread that was never interrupted. This is especially
problematic as the signal handler code will then illegally restore
the stack pointer register from an uninitialized memory location.
Sancus. We reviewed the assembly code inserted at the entry
point of a Sancus enclave, and noticed that the Sancus TEE suffers
from similar call stack switching vulnerabilities. Particularly, we
experimentally confirmed that it is possible to supply illegal CPU
register arguments and trick the enclave into “returning” into a
thread that was not waiting for a previous ocall return. In such a
case, the enclave stack will be falsely restored to the value of the
last valid ocall, leading to memory-safety violations from incorrect
control flow and register values. Sancus’s enclave entry assembly
routine further expects a CPU register parameter to specify the
address where execution is continued after leaving the enclave. The
software does not properly validate this parameter. Unlike SGX’s
eexit hardware primitive, which refuses to jump to illegal continu-
ation addresses, Sancus enclaves are exited by means of an ordinary
jmp instruction. We experimentally confirmed the possibility of
code reuse attacks [41] by forcing the vulnerable entry routine to
jump to an arbitrary in-enclave continuation address.
4.3 Storing and scrubbing machine state on exit
Prior to exiting the TEE, the trusted runtime’s assembly routine
should save and clear all CPU registers that are not part of the
calling convention, and restore them on subsequent enclave re-
entry. This is highly similar to how a traditional operating system
needs to context switch between processes, and hence we found
this to be a generally well-understood requirement.
Attack vector #3 (register state): Exit code should save and scrub CPU
registers. ▷ Generally well-understood across runtimes and architectures.
TEE design. Similar to parameter passing across traditional
user/kernel boundaries, widespread TEE designs commonly pre-
serve CPU register contents when context switching between the
normal and secure worlds. Prior research [3, 22] on exploiting mem-
ory safety vulnerabilities in SGX enclaves has for instance exploited
that the eexit instruction does not clear register values, leaving this
as an explicit software responsibility. Further, while scrubbing CPU
registers on enclave interrupt is a hardware responsibility in the In-
tel SGX design [8], we found that the AEX operation in current SGX
processors does not clear the x86 DF flag (cf. Section 4.1). We ex-
perimentally confirmed that this can be exploited as a side-channel
to learn the direction of private in-enclave string operations.
SGX-LKL. When reviewing the respective assembly routines,
we noticed that SGX-LKL is the only SGX runtime which does not
properly scrub registers before invoking eexit. The reason for this
oversight is that LKL attempts to leverage the setjmp/longjmp stan-
dard C library functions to easily store and restore the execution
state on enclave entry/exit without needing dedicated assembly
code. While indeed functionally correct, i.e., the integrity of CPU
registers is preserved across enclave calls, the approach cannot
guarantee confidentiality. This is because setjmp() still behaves
as a normal C function, which—adhering to calling conventions—
does not clear all CPU state. We therefore advise to use a dedicated
assembly routine which overwrites confidential CPU registers be-
fore invoking eexit. This issue highlights the necessity to explicate
and properly separate ABI and API-level shielding concerns in
consecutive stages of the trusted runtime (cf. Section 3). We exper-
imentally confirmed this vulnerability by loading an elementary
AES-NI application binary inside SGX-LKL, and modifying the un-
trusted runtime to dump x86 xmm registers—including the AES state
and round keys—after enclave exit.
5 SANITIZING THE ENCLAVE API
Once a trustworthy ABI state has been established, the trusted
bootstrapping assembly code can safely transfer control to ma-
chine code emitted by a compiler from a program description
written in a higher-level language. Remarkably, almost all run-
times [13, 19, 21, 29, 32, 35, 43] we studied are written in C or C++,
with the notable exception of Fortanix’s EDP platform [11], which
is written in the memory-safe Rust language. While the use of safe
languages is indeed preferable to rule out an important class of
application-level memory-safety vulnerabilities in the trusted run-
time implementation, we show that safe languages by themselves
cannot guarantee that the enclave interface is safe.
That is, it remains the responsibility of the trusted runtime im-
plementation to marshal and scrutinize untrusted input parameters
before passing them on to the shielded application written by the
enclave developer. Depending on the specific runtime, develop-
ers may communicate trusted API sanitization and marshalling
requirements explicitly (e.g., using a domain-specific language like
in Intel’s edger8r or Microsoft’s oeedger8r), or the enclave interface
may be completely hidden from the programmer (e.g., libOS-based
approaches).
In this section, we analyze shielding requirements for API san-
itization based on the different types of arguments that can be
passed across the enclave boundary. We pay particular attention
to pointers and (variable-sized) input buffers, given the prevalent
weaknesses found in real-world code.
5.1 Validating pointer arguments
Whenever untrusted side and enclave share at least part of their
address spaces, an important new attack surface arises: malicious
(untrusted) code can pass in a pointer to enclave memory where a
pointer to untrusted memory is expected. Therefore, it is the respon-
sibility of the shielding system to be careful in never dereferencing
untrusted input pointers that fall outside of the shared memory
region and point into the enclave. In case such sanity checks are
missing, the trusted enclave software may unintentionally disclose
and/or corrupt enclave memory locations. This is an instance of the
well-known “confused deputy” [16] security problem: the attacker
is architecturally prohibited from accessing secure enclave mem-
ory, but tricks a more privileged enclaved program to inadvertently
dereference a secure memory location chosen by the attacker.
Attack vector #4 (pointers): Runtimes should sanitize input pointers to
lie inside the expected shared memory region. ▷ Generally understood,
but critical oversights prevalent across research and production code.
Figure 3: Automatically generated edger8r bridge code han-
dles shielding of application input and output buffers.
TEE design. TEEs commonly support some form of shared mem-
ory which allows trusted in-enclave code to directly read or write
an untrusted memory region outside the enclave (cf. Section 3.2).
Input and output data transfers can now easily be achieved by
bulk-copying into the shared memory region and passing pointers.