Further, since |M1|
|M| = α·, we get
|M1
SOU T
|M1|
|
≥ 1 −
σk∗ · (1−α)
α .
α
Discussion of Theorem 2 Let the false negative of a sig-
nature S be the fraction of worm ﬂows in M that are not
covered by S. Theorem 2 implies that the false negative rate
of the output signature SOUT is at most σk∗ ·(1−α)
which is
inversely proportional to α, the fraction of worm samples
in the suspicious pool. So as this fraction decreases, the
false negative increases. In other words, the signature has a
higher false negative if there is more noise in the suspicious
pool. However the false positive of the output signature is
always low ( u(i), then goto Step 2
2. Output Si which maximizes score(COVSi
, FPSi).
5.3 Performance
Guarantees
for
GNTMSG
Let α be the coverage of the true worm and let β be the
false positive of its invariant content.
Theorem
model
Γ(k∗, u(1), . . . , u(k∗)), if the fraction of worm trafﬁc ﬂows
(cid:3)
in M is α, then Algorithm 2 outputs a signature SOU T such
that for all i ≤ k, score(α, β) ≤ score
adversary
Under
(cid:4)
the
4.
.
+σi
COVSi
1+σi
, 0
5.
Under
After executing Algorithm GNTMSG and ﬁnding all the
Si’s, Theorem 4 can be used to get an upper bound on the
score of the true worm. This way we can determine how
far could the score of our signature be from that of the true
worm.
Theorem
Γ(k∗, u(1), . . . , u(k∗)),
trafﬁc ﬂows
puts a signature SOU T such that
score(COVSOU T
model
the
the
of worm
then Algorithm 2 out-
i ≤ k,
, FPSOU T ) ≥ score(α − σi(1 − α), u(i)).
Theorem 5 is a guarantee on the performance of the al-
gorithm. That is independent of the run of the algorithm,
we can lower bound the score of the signature that our algo-
rithm is guaranteed to output.
adversary
fraction
in M is α,
for all
if
6 Implementation Details
6.1 Scoring Function
As discussed in Section 5.1, to select a reasonable scor-
ing function score(COVS, FPS) is to make a subjective
trade off between the coverage and false positive to catch
the intuition of what is a good signature. [9] proposes an
information theoretic approach to address this issue. How-
ever, for our implementation we use the following scoring
function:
score(COVS, FPS, LENS) = − log((δ + FPS), 10)
+ a ∗ COVS + b ∗ LENS
a >> b
δ is used to avoid the log term becoming too large for
FPS close to 0. We add some weight to the length of the
token LENS to break ties between signatures that have the
same coverage and false positive rate. This is because even
though two signatures may have the same false positive on
our limited normal pool size, the longer signature is likely
to have smaller false positive over the entire normal trafﬁc
and is therefore preferable.
For our experiments, we found δ = 10−6, a = 20 and
b = 0.01 yields good results.
6.2 Token Extraction
Like Polygraph, we extract tokens with a minimum
length (cid:6)min and a minimum coverage λ in the suspicious
pool. However, Polygraph’s token extraction algorithm
does not include a token if it is a substring of another to-
ken, unless its unique coverage (i.e. without counting the
occurrences where it is a substring of other tokens) is larger
than λ. This may potentially miss some invariant tokens,
e.g.“%u” may occur only as either “%uc” and “%uk”, which
means that the unique coverage of “%u” is 0. However, it
might be possible that “%u” covers all of the worm sam-
ples, but “%uc” and “%uk” do not, and so “%u” yields a
better signature. Therefore, for our token extraction algo-
rithm, every string with a coverage larger than λ is treated
as a token.
Problem 3 (Token Extraction).
INPUT: Suspicious trafﬁc pool M = {M1, M2 . . .}; the
minimum token length (cid:6)min and the minimum coverage λ.
OUTPUT: A set of
tokens T = {t1, t2, . . .} which
meet
the minimum length and coverage requirements
and for each token the associated sample vector
V(ti) = [ai1, . . . , ai|M|], i ∈ [1, |M|] where aij de-
note the number of times token ti occurs in ﬂow Mj.
Polygraph used a sufﬁx tree based approach for token
extraction. The basic idea is to do a bottom up traversal
of the sufﬁx tree to calculate a frequency vector of occur-
rences for each node (token candidate), and then via a top
down traversal output the tokens and corresponding sam-
ple vectors which meet the minimum length and coverage
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:34 UTC from IEEE Xplore.  Restrictions apply. 
requirement.
Although asymptotically linear, the space consumption
of a sufﬁx tree is quite large. Even recently improved imple-
mentations of linear time constructions require 20 bytes per
input character in the worst case. [1] have proposed tech-
niques that allows us to replace the sufﬁx tree data structure
with an enhanced sufﬁx array for the token extraction algo-
rithm. The sufﬁx array based algorithm runs in linear time
and requires a space of at most 8 bytes per input character.
Another advantage of sufﬁx array based approach is that it
allows some pruning techniques to further speed up token
extraction and improve memory consumption.
Though there are linear time sufﬁx array creation algo-
rithms, some lightweight algorithms with a worse bound on
the worst case time complexity perform better for typical
input sizes (such as less than 1000 samples). The reason as
discussed in [23] is that the linear time algorithm makes too
many random accesses to the main memory which makes
the cache hit ratio low and result in poor performance. So
for our implementation we choose a lightweight algorithm,
deepsort [15], which is one of fastest sufﬁx array con-
struction algorithm in practice. Our experiments with one
of the best known sufﬁx tree libraries [11] show that we
get around 100 times speedup for token extraction by using
sufﬁx arrays.
6.3 False Positive Calculation
For false positive estimation, we build a sufﬁx array [15]
of the normal trafﬁc pool in a preprocessing step and store it
on the disk. To calculate the false positive of a given token,
we use binary search on the sufﬁx array. We can employ
a variety of different policies for maintaining the normal
trafﬁc pool in order to prevent an attacker from polluting it.
The normal trafﬁc pool could be large, e.g., 100MB and
a sufﬁx array for 100MB requires around 400MB of mem-
ory. Currently, we use mmap to map the sufﬁx array to
the memory space of our program. When we need to ac-
cess some part of the array, a page fault happens and the
relevant page (4KB) is loaded to the memory. In our expe-