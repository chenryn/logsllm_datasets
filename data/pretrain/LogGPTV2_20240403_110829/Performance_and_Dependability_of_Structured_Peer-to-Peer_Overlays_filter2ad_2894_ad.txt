n
f
o
r
e
b
m
u
n
e
v
i
t
l
a
a
m
u
C
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
5 minutes
30 minutes
0
100
200
400
Session Time (Minutes)
300
500
600
0
100
200
400
Session Time (Minutes)
300
500
600
0
5
10
15
25
Time (seconds)
20
30
35
40
Figure 5: RDP, control trafﬁc, and join delays for the Poisson traces.
hop acks is 17% higher than using both techniques when
nodes generate 0.01 lookups per second and it is 61% higher
if nodes generate 0.001 lookups per second. Using active
probing reduces delay because it reduces the number of per-
hop timeouts. In an application whose trafﬁc is non-uniform
or experiences daily/weekly trafﬁc variations, it is important
to use both techniques.
The active probing rate can be tuned to achieve a tar-
get raw loss rate Lr (to achieve a target delay). Results for
all traces show that self-tuning can effectively achieve the
target raw loss rate. For example without per-hop acks, it
achieves a message loss rate of 5.3% when tuning to 5%
and 1.2% when tuning to 1%. A lower raw loss rate results
in lower delay but decreasing the target Lr increases control
trafﬁc. For example, changing the target from 5% to 1% in-
creases control trafﬁc by 2.6 times. We chose tuning to 5%
in the base conﬁguration because it provides a good trade-
off between overhead and delay with per-hop acks.
Active probing generates extra control trafﬁc that pro-
vides little beneﬁt when application trafﬁc is high. MSPas-
try uses application trafﬁc to suppress probes and heartbeats
to reduce the overhead. Increasing application trafﬁc from
0 to 1 lookups per second per node suppresses over 70%
of the active probes. Additionally, RDP improves by 13%
because the average time to failure detection is reduced.
5.3.1. Simulator Validation We have been running sev-
eral applications that are built using MSPastry. We ran a
video broadcast using SplitStream [6] on 108 desktop ma-
chines on the Microsoft network (about 40 in Cambridge,
UK and the rest in Redmond, Washington). The Squirrel
web cache [12] has been the primary web cache for 52 ma-
chines at Microsoft Research Cambridge for the last few
months. We used traces collected from the Squirrel deploy-
ment to validate our simulator.
Squirrel users run an instance of the Squirrel proxy on
their machine and Web requests from the browser are redi-
e
d
o
n
r
e
p
d
n
o
c
e
s
r
e
p
s
e
g
a
s
s
e
M
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0
simulator
deployment
20
40
80
60
Time (hours)
100
120
140
Figure 8: Total trafﬁc generated in Squirrel deployment and
validated in simulator.
rected through the Squirrel proxy running on the local ma-
chine. Squirrel generates keys for Web objects by hashing
the object’s URL using SHA-1. Lookup messages are sent
through MSPastry to the key of the requested object. The
root node of each key is responsible for caching the object
identiﬁed by the key.
We logged node arrivals, node failures, and page lookups
in the Squirrel deployment. This log was used to generate a
workload trace that we fed to our simulator. Figure 8 shows
the total trafﬁc per node in the simulator and the deployment
from the morning of the 11th December 2003 to the night
of the 17th December 2003. The six day trace contains 4
week days and one weekend, which are clearly visible. The
simulation results are very similar to the statistics obtained
from the real deployment.
6. Conclusions
Structured peer-to-peer overlays provide a useful sub-
strate for building distributed applications but there are con-
cerns about their performance and dependability. This paper
has described MSPastry which incorporates techniques to
achieve good performance and high dependability in realis-
tic environments with high churn rates. Previous implemen-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:47:52 UTC from IEEE Xplore.  Restrictions apply. 
2.5
2
1.5
1
P
D
R
0.5
0
0.00%
1.00%
2.00%
3.00%
Network message loss rate
Control traffic
e
d
o
n
r
e
p
d
n
o
c
e
s
r
e
p
s
e
g
a
s
s
e
M
0.28
0.27
0.26
0.25
0.24
Lookup loss rate
Incorrect delivery rate
3.50E-05
3.00E-05
2.50E-05
e
t
a
R
2.00E-05
1.50E-05
1.00E-05
5.00E-06
0.00E+00
4.00%
5.00%
0.00%
1.00%
2.00%
3.00%
4.00%
5.00%
Network message loss rate
0.00% 1.00% 2.00% 3.00% 4.00% 5.00%
Network message loss rate
e
d
o
n
r
e
p
d
n
o
c
e
s
r
e
p
s
e
g
a
s
s
e
M
Figure 6: RDP, control trafﬁc, lookup loss rate, and incorrect delivery rate as a function of varying network loss rate.
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
8
16
24
32
40
48
56
64
l
2.5
2
1.5
1
0.5
P
D
R
0
8
P
D
R
3.2
3
2.8
2.6
2.4
2.2
2
1.8
1.6
16
24
32
40
48
56
64
1
2
Figure 7: The effect of varying b and l.
l
3
b
4
5
tations failed to provide routing consistency guarantees and
performed poorly in environments with high churn rates.
The paper has presented results of large-scale simulations
with fault injection guided by real traces of node arrivals
and departures showing that MSPastry achieves dependable
routing with low delay stretch and a maintenance overhead
of less than half a message per second per node. Further-
more, the results show that the performance of MSPastry
degrades gracefully with failures.
Squirrel, SplitStream, MSPastry, and the simulator are
available to academic institutions upon request.
References
[1] R. Bhagwan, S. Savage, and G. Voelker. Understanding availability.
In IPTPS’03, Feburary 2003.
[2] W. J. Bolosky, J. R. Douceur, D. Ely, and M. Theimer. Feasibility
of a serverless distributed ﬁle system deployed on an existing set of
desktop pcs. In SIGMETRICS’2000, pages 34–43, 2000.
[3] M. Castro, P. Druschel, A. Ganesh, A. Rowstron, and D. S. Wallach.
Security for structured peer-to-peer overlay networks. In OSDI, Dec.
2002.
[4] M. Castro, P. Druschel, Y. C. Hu, and A. Rowstron. Exploiting net-
work proximity in peer-to-peer overlay networks. Technical Report
MSR-TR-2002-82, Microsoft Research, May 2002.
[5] M. Castro, P. Druschel, Y. C. Hu, and A. Rowstron. Proximity neigh-
bor selection in tree-based structurd peer-to-peer overlays. Technical
Report MSR-TR-2003-52, Microsoft Research, June 2003.
[6] M. Castro, P. Druschel, A.-M. Kermarrec, A. Nandi, A. Rowstron,
and A. Singh. Splitstream: High-bandwidth multicast in a coopera-
tive environment. In SOSP’03, Oct. 2003.
[7] M. Castro, P. Druschel, A.-M. Kermarrec, and A. Rowstron. Scribe:
A large-scale and decentralized application-level multicast infras-
tructure. IEEE JSAC, 20(8), October 2002.
[8] F. Dabek, M. F. Kaashoek, D. Karger, R. Morris, and I. Stoica. Wide-
area cooperative storage with CFS. In Proc. ACM SOSP’01, Banff,
Canada, Oct. 2001.
[9] F. Dabek, J. Li, E. Sit, J. Robertson, M. F. Kaashoek, and R. Morris.
Designing a DHT for Low Latency and High Throughput. In NSDI,
March 2004.
[10] K. P. Gummadi, R. Gummadi, S. D. Gribble, S. Ratnasamy,
S. Shenker, and I. Stoica. The impact of DHT routing geometry on
resilience and proximity. In SIGCOMM, 2003.
[11] K. Hildrum, J. D. Kubiatowicz, S. Rao, and B. Y. Zhao. Distribted
data location in a dynamic network. In SPAA’02, Aug. 2002.
[12] S. Iyer, A. Rowstron, and P. Druschel. Squirrel: A decentralized peer-
to-peer web cache. In PODC, July 2002.
[13] P. Karn and C. Partridge. Improving round-trip estimates in reliable
transport protocols. Theoretical Computer Science, 4(9):364–373,
1991.
[14] J. Li, J. Stribling, T. M. Gil, R. Morris, and F. Kaashoek. Comparing
the performance of distributed hash tables under churn. In IPTPS,
February 2004.
[15] R. Mahajan, M. Castro, and A. Rowstron. Controlling the cost of
reliability in peer-to-peer overlays. In IPTPS’03, Feb. 2003.
[16] A. Muthitacharoen, R. Morris, T. Gil, and B. Chen. Ivy: A read/write
peer-to-peer ﬁle system. In OSDI, Dec. 2002.
[17] C. G. Plaxton, R. Rajaraman, and A. W. Richa. Accessing nearby
copies of replicated objects in a distributed environment. In SPAA,
pages 311–320, June 1997.
[18] S. Ratnasamy, P. Francis, M. Handley, R. Karp, and S. Shenker. A
scalable content-addressable network. In SIGCOMM’01, San Diego,
CA, Aug. 2001.
[19] S. Rhea, D. Geels, T. Roscoe, and J. Kubiatowicz. Handling Churn
in a DHT. In Usenix, June 2004.
[20] A. Rowstron and P. Druschel. Pastry: Scalable, distributed object
location and routing for large-scale peer-to-peer systems. In Middle-
ware, Heidelberg, Germany, Nov. 2001.
[21] A. Rowstron and P. Druschel. Storage management and caching
In
in PAST, a large-scale, persistent peer-to-peer storage utility.
SOSP’01, Banff, Canada, Oct. 2001.
[22] S. Saroiu, K. Gummadi, and S. Gribble. A measurement study of
peer-to-peer ﬁle sharing systems. In MMCN, Jan. 2002.
[23] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan.
Chord: A scalable peer-to-peer lookup service for Internet applica-
tions. In SIGCOMM’01, San Diego, CA, Aug. 2001.
[24] H. Tangmunarunkit, R. Govindan, D. Estrin, and S. Shenker. The
impact of routing policy on internet paths. In Proc. 20th IEEE IN-
FOCOM, Alaska, USA, Apr. 2001.
[25] E. Zegura, K. Calvert, and S. Bhattacharjee. How to model an inter-
network. In INFOCOM, 1996.
[26] S. Q. Zhuang, B. Y. Zhao, A. D. Joseph, R. H. Katz, and J. Kubiatow-
icz. Bayeux: An architecture for scalable and fault-tolerant wide-area
data dissemination. In NOSSDAV, June 2001.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 11:47:52 UTC from IEEE Xplore.  Restrictions apply.