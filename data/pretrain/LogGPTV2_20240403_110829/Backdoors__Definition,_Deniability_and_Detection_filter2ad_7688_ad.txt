i
s
u
d
e
l
l
e
d
o
m
s
r
o
o
d
k
c
a
b
d
l
r
o
w
-
l
a
e
R
.
1
e
l
b
a
T
Backdoors: Deﬁnition, Deniability and Detection
109
ngx_int_t ngx_http_parse_header_line(/* ... */) {
u_char badc; /* last bad character */
ngx_uint_t hash; /* hash of header, same size as pointer */
/* ... */
}
void ngx_http_finalize_request(ngx_http_request_t *r, ngx_int_t rc) {
uint8_t have_err; /* overlaps badc */
void (*err_handler)(ngx_http_request_t *r); /* overlaps hash */
/* ... */
if(rc == NGX_HTTP_BAD_REQUEST && have_err == 1 && err_handler) {
err_handler(r); /* points to hidden code, set by trigger */
}
}
void ngx_http_process_request_headers(/* ... */) {
rc = ngx_http_parse_header_line(/* ... */);
/* ... */
ngx_http_finalize_request(r, NGX_HTTP_BAD_REQUEST); /* bad header */
}
Fig. 9. Source-code listing for Nginx backdoor trigger.
have err == 1 && err handler != NULL
1
2
3
ngx http parse header line(...)
ngx http finalize request(...)
Fig. 10. Multi-layered FSM for Nginx backdoor.
states are possible, for example, if the attacker provides a diﬀerent input packet
to that expected by the implementers. The privileged state depends on the back-
door payload. We visualise the backdoor in Fig. 10; the trigger is captured by
state 1 and the non-explicit, bug-based transition to state 2; the payload consists
of state 2 and the transition between state 2 and 3; state 3 is the privileged state.
From a technical standpoint the backdoor is deniable (by Deﬁnition 4), this
is due to its trigger transition being bug-based, whilst its payload, if discovered,
is arguably intentional. The componentisation using our framework allows us
to visualise a complex backdoor succinctly, which would otherwise be buried
across multiple functions in thousands of lines of source code. Further, its com-
ponentisation allows us to reason about how such a backdoor can be detected:
for example, we could attempt to detect its bug-based trigger condition using
symbolic execution; alternatively, we could heuristically attempt to identify its
110
S. L. Thomas and A. Francillon
payload by scanning for misaligned instruction sequences that branch to other
instruction sequences of the same kind, where the combination of those sequences
would serve to elevate an attacker’s privileges.
6.1 Backdoor Detection Methodologies
Our framework provides not only a means to reason about backdoors, but also
backdoor detection techniques. Table 2 shows the decomposition of the detection
methodologies of four state-of-the-art backdoor detection tools. Each tool claims
to detect a particular subset of backdoor types. However, while these tools are
all eﬀective, none consider a complete model of backdoors, and, as a result, are
limited in their eﬀectiveness.
Table 2. Tool detection methodology decomposed using framework.
Tool
Input source Trigger Payload Privileged state
Firmalice [19]
Partial
Partial No
Partial
HumIDIFy [22] Partial
No
Partial No
Stringer [21]
Weasel [14]
No
No
Partial Partial No
Partial Partial Partial
Firmalice [19] is designed to detect authentication bypass vulnerabilities. It
uses a so-called security policy to deﬁne the observable side-eﬀects of a program
being in a privileged state. Using a speciﬁed input source, it attempts to ﬁnd
data provided via this input source that satisﬁes the conditions – i.e., akin to a
backdoor trigger – required to observe the side-eﬀects speciﬁed by the security
policy. Firmalice has no notion of a payload state; when entered, a payload state
might leave a program in a privileged state that is not captured by a given
security policy, for instance, where the privileged state reached by a backdoor
user is diﬀerent from that of a legitimate user reaches, e.g., the Q-See DVR
backdoor from Table 1. Firmalice is able to detect such a privileged state by
modiﬁcation of the input security policy, however, to do so will require the same
amount of manual analysis to detect the entire backdoor as it would to identify
the privileged state.
HumIDIFy [22] aims to detect if a program can execute functionality it should
never execute under normal circumstances. This might be the establishment of
a suspicious input source, or the execution of API that is considered anomalous,
i.e., what might be part of a backdoor payload. However, since it does not consider
the notion of a trigger, it is unable to distinguish between abnormal program
behaviour that is benign – because it can only be performed by a legitimate user,
and behaviour that is genuinely anomalous – that is part of a backdoor. Again,
this is due to their approach not considering a complete model of a backdoor.
Stringer [21] attempts to detect static data used as program input that is
responsible for either enabling authentication bypass vulnerabilities, or used for
Backdoors: Deﬁnition, Deniability and Detection
111
triggering the execution of undocumented functionality. To do this it uses a
scoring metric, which ranks static data, that when matched against, leads to
the execution of unique functionality, i.e., functionality not reachable by other
program paths. Stringer considers the partial notion of a backdoor trigger and
uses heuristics for identifying payload-like constructs. It does not consider the
notion of input source, or privileged states, and as a result of the latter, is unable
to meaningfully score data that leads to states that are actually privileged higher
than those that are not.
Weasel [14] detects both authentication bypass vulnerabilities and undocu-
mented commands in server-like program binaries. It works by attempting to
automatically identify so-called deciders (akin to backdoor triggers) and han-
dlers (akin to the combination of a backdoor payload and privileged state) which
then serve to aid in detection of backdoors. Their approach does not fully model
the notion of a backdoor; it does not consider an input source at all, rather,
the approach models a single input for the program, and data from that source,
when processed, is assumed to reveal all deciders and handlers. The Tenda web-
server backdoor in Table 1 acts as an undocumented command interface, its input
source is a UDP port; in this case, the backdoor uses a separate input source
from the standard input to the program, i.e., TCP port 80 or 443. Since Weasel
does not capture the notion of an input source, it will be unable to detect such a
backdoor – not due to a deﬁciency in its detection method, but because it does
not consider a complete model of a backdoor.
7 Future Work
Our framework does not intend to provide a direct means to detect backdoors,
rather it serves as a general means to decompose backdoors in an abstract way.
In Sect. 6.1, we discuss concrete implementations of detection methodologies; in
each case we are able to highlight deﬁciencies in those methods due to them not
fully capturing the rigorous deﬁnition of a backdoor, as outlined in this work.
Thus, a backdoor detection methodology based upon our proposed framework
would be a natural extension of this work. Further, while our formalisations
attempt to capture any backdoor-like functionality, backdoors introduced into a
system by, e.g., a deliberate side-channel vulnerability would prove diﬃcult to
model using our FSM-based abstraction; we view this as an additional area for
investigation.
8 Conclusion
In summary, we have provided a deﬁnition for the term backdoor, deﬁnitions for
backdoor detection, deniable backdoors, and a means to discern between inten-
tional backdoors and accidental vulnerabilities. We have presented a framework
to aid in identifying backdoors based upon their structure, which also serves
as a means to compare existing backdoor detection approaches, and as a basis
112
S. L. Thomas and A. Francillon
for developing new techniques. To demonstrate the eﬀectiveness of our app-
roach, we have analysed twelve backdoors of varying complexity. In each case,
we have been able to concisely model those backdoors, which previously, might
have manifested as hundreds or thousands of assembly language instructions in
a disassembler. We have used our framework to evaluate four state-of-the-art
backdoor detection approaches, and in all cases, have shown that none consider
a complete model of backdoors, and, as a result, their potential eﬀectiveness is
limited.
References
1. An attempt to backdoor the kernel (2003). https://lwn.net/Articles/57135/
2. From China with Love (2013). http://www.devttys0.com/2013/10/from-china-
with-love/
3. How a Crypto ‘Backdoor’ Pitted the Tech World Against the NSA (2013). https://
www.wired.com/2013/09/nsa-backdoor/
4. Multiple Vulnerabilities in D-Link DIR-600 and DIR-300 (rev B) (2013). http://
www.s3cur1ty.de/node/672
5. Reverse Engineering a D-Link Backdoor (2013). http://www.devttys0.com/2013/
10/reverse-engineering-a-d-link-backdoor/
6. TCP-32764 Backdoor (2013). https://github.com/elvanderb/TCP-32764
7. Why everyone is left less secure when the NSA doesn’t help ﬁx security ﬂaws
(2013). https://bit.ly/2JJ9Zsg
8. Inside the EquationDrug Espionage Platform (2015). https://securelist.com/
inside-the-equationdrug-espionage-platform/69203/
9. Adups Backdoor (2016). https://www.kryptowire.com/adups security analysis.
html
10. Backdoor in Sony IPELA Engine IP Cameras (2016). https://sec-consult.com/en/
blog/2016/12/backdoor-in-sony-ipela-engine-ip-cameras/
11. Multiple vulnerabilities found in Quanta LTE routers (2016). http://pierrekim.
github.io/blog/2016-04-04-quanta-lte-routers-vulnerabilities.html
12. Netis Router Backdoor Update (2016). https://blog.trendmicro.com/netis-router-
backdoor-update/
13. Hacking the Western Digital MyClound NAS (2017). https://blog.exploitee.rs/
2017/hacking wd mycloud/
14. Andriesse, D., Bos, H.: Instruction-level steganography for covert trigger-based
malware. In: Dietrich, S. (ed.) DIMVA 2014. LNCS, vol. 8550, pp. 41–50. Springer,
Cham (2014). https://doi.org/10.1007/978-3-319-08509-8 3
15. Dullien, T.F.: Weird machines, exploitability, and provable unexploitability. IEEE
Transactions on Emerging Topics in Computing Preprint (2017)
16. Oakley, J., Bratus, S.: Exploiting the hard-working DWARF: Trojan and exploit
techniques with no native executable code. In: 5th USENIX Conference on Oﬀen-
sive Technologies (2011)
17. Schuster, F., Holz, T.: Towards reducing the attack surface of software backdoors.
In: 2013 ACM SIGSAC Conference on Computer & Communications Security
(2013)
18. Shapiro, R., Bratus, S., Smith, S.W.: “Weird Machines” in ELF: a spotlight on the
underappreciated metadata. In: 7th USENIX Conference on Oﬀensive Technologies
(2013)
Backdoors: Deﬁnition, Deniability and Detection
113
19. Shoshitaishvili, Y., Wang, R., Hauser, C., Kruegel, C., Vigna, G.: Firmalice - auto-
matic detection of authentication bypass vulnerabilities in binary ﬁrmware. In:
2015 Network and Distributed System Security Symposium (2015)
20. Tan, S.J., Bratus, S., Goodspeed, T.: Interrupt-oriented bugdoor programming: a
minimalist approach to bugdooring embedded systems ﬁrmware. In: 30th Annual
Computer Security Applications Conference (2014)
21. Thomas, S.L., Chothia, T., Garcia, F.D.: Stringer: measuring the importance of
static data comparisons to detect backdoors and undocumented functionality. In:
Foley, S.N., Gollmann, D., Snekkenes, E. (eds.) ESORICS 2017. LNCS, vol. 10493,
pp. 513–531. Springer, Cham (2017). https://doi.org/10.1007/978-3-319-66399-
9 28
22. Thomas, S.L., Garcia, F.D., Chothia, T.: HumIDIFy: a tool for hidden function-
ality detection in ﬁrmware. In: Polychronakis, M., Meier, M. (eds.) Detection of
Intrusions and Malware, and Vulnerability Assessment. LNCS. Springer, Cham
(2017). https://doi.org/10.1007/978-3-319-60876-1 13
23. Wysopal, C., Eng, C.: Static Detection of Application Backdoors. Black Hat USA
(2007)
24. Zaddach, J., et al.: Implementation and implications of a stealth hard-drive back-
door. In: 29th Annual Computer Security Applications Conference (2013)
25. Zhang, Y., Paxson, V.: Detecting backdoors. In: 9th USENIX Conference on Secu-
rity Symposium (2000)