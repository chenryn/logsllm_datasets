第一类，无固定目标地控制网络资产。他们每天会盯着全网漏洞的输出源头（如seclist，exploitdb，metasploit等），一旦有可用做控制的poc，他们会写出exp，直接做持久化控制；数据泄漏也归属到这个范围。
第二类，针对特定商业目标的敏感数据窃取。目标是商业公司，有特定范围，所以他们做的第一件事就是给目标建立攻击面的梳理。漏洞的流程与第一种类似。
第三类，针对特定影响国计民生的关基单位进行敏感数据获取或者直接进行破坏。这种也要梳理攻击面，不过一般就不是一两个目标单位了，而是一个行业或者多个行业。同时，漏洞也不是从来源获取，更多的用上了自挖掘或者购买的0day漏洞。
如上三类黑客不是大家认为的那样泾渭分明，所谓的理想大部分情况下是逐利的幌子，他们的行为方式是根据行情来的，所以他们会在其中游走穿梭。
针对第三种的防护，你必须假设对方有0day，这也是为什么未知威胁的检测是未来必须具备的能力之一。Nday也能结束战斗，但是0day的隐蔽性更强。最初都是特定目标的针对性攻击，后来出现了范目标攻击，这批人小打小闹还好，高价值的最后还是回归到特定目标的打击，这个本质一直存在，只不过从以前硬怼到目前可以悠哉悠哉地先拿下所有，再确定是否重要目标的过程。这个过程的核心就是两个库：每天更新的漏洞库，以及特定目标的攻击面。
漏洞库实在没有值得讲的，它们很重要，它们掌握在极少部分人手里，如何挖掘是一门科学，如何收集也是一门科学，它一定时间内很难自动化。但是攻击面就不一样了，特定目标的攻击面梳理也是一门科学，但是这门科学可以比较快的实现一定的自动化。攻击面梳理的全面性会往两个方向发展：一是特定目标对外开放的实体，比如最直接的IP；二是实体上承载的各组成部分，比如中间件软件系统等各种属性。我们可以简单地理解，一个是宏观，一个是微观，宏观解决的是面的宽度，微观解决的是单个实体的刻画深入度。这里我放一张防护者和攻击者眼里的差异，这种差异也决定了思考方式的不同。
防护方眼里的攻击面，偏财务的台账管理，偏硬件设备和IP系统管理，而在攻击者的眼里，更侧重业务系统，中间件，员工，以及外围的一切可被利用的脆弱点。所以当防守方拿出一万个IP来的时候，黑客眼里可能是十万个攻击点。
我们把上面提到的宏观微观分开来讨论。先来解决企业在互联网上接入了多少ip的问题。一个最简单的模式当然是找到这个企业的根域名，然后通过找到所有的子域名，再解析所有的子域名到ip。看上去很简单，但是这种方式能找出30%就很不错了，谁说根域名只有一个？谁说ip都绑定了域名？你又衍生出几个小问题：如何找到所有的根域名？如何找到没有域名但是有归属的ip地址？黑客比较聪明，他们说我们用备案库查一查，whois查一查，证书查一查（这个方法很有用），C段查一查，icon查一查（这个在shodan中已经支持了，好在它还不支持域名，不然杀伤力更大），再不济用关键字查一查，黑客有一堆的方法，而且他们有的是耐性，也会充分的利用现有的工具。结果就是，当黑客们通过各种入口进来的时候，防护方就震惊了，各种批评追责，然后说“谁他娘的开放了这些IP，为什么不在监控范围”！
总结一下，宏观上的发展就是数据会越来越多，一个是全网IP的采集越来越多（从IPv4到IPv6），一个是端口和协议的支持数越来越多，再一个就是字段的越来越多。如何解决通过一个证书反向推导出所有使用这个SSL证书的IP和域名列表？那就先采集所有的IP和域名，再分析上面部署的证书信息，这个工作量没有难度，就是投资源。没有企业想去建立全球的库，所以企业的资产管理是自顶向下的，而黑客用的方法是自底向上的，先全采集了再说，后续再分析。给出几个案例，大家稍微感受一下就好：
目前来看，各有各的强项，谈不上谁一统天下。
再后续分析的过程就是往微观发展，同样的IP，同样的端口和协议，会对应不同的设备和应用，当然也会对应不同的归属主体。所以微观的发展就是尽可能多的从数据中分析出这个IP对应的各种属性特征。比如你可以给它打上ADSL的标签，可以打上物联网的标签，也可以打上金融行业的标签，可以打上街道的标签。这些都是非常典型的细粒度分析的结果，这些细粒度就对应不同场景的业务需求。比如可以针对数据库输出大小、记录数等属性，再比如可以针对视频给出截图。我们可以认为对应如下的五层分类图代表其中最基础的业务标签属性（数据图来自Goby）：
上图可以看到，硬件层我们可以分析出来为vmware，上面的操作系统层面是CentOS，服务层有Nginx/Mysql/Reidis/OpenSSH，支撑层看到有Struts2，业务层有Jenkins/Kibana系统。这些微观的数据刻画的越细，在未来安全应急中的响应速度就越快。一个IP大家并没有感觉，但是如果有百万台设备，假设Jeninks突发了一个漏洞，这时候你就能快速的从百万台设备里面筛选出来小于100台的范围进行应急。有些企业说，这些应用我们有登记啊，实际情况下，有很多是员工私自搭建的测试环境没有登记，也有人为疏忽漏掉的情况，这样形成了缝隙，黑客一定会进来。最好的方法是自动化的方式解决人为引发的问题，我们通过技术和管理的方式来解决问题。事实上，黑客从漏洞出来到完成全网攻击的时间不超过大约在小时级（我们就能模拟做到同类效果），企业可以想象一下咱们应该如何应对。
对于细粒度的深入分析，我们可以通过shodan来稍微感受一下来能输出的效果，比如数据库，它能刻画出数据库类型，数据库数量，数据大小，数据库列表，数据库字段等等：
有什么用？你觉得有什么用？每一个它能分析出来的数据库都能被下载。任何一个黑客能快速完成全网的数据窃取，当然它们也能掌握全球数据威胁的实时情报，这是态势感知需要具备的高级能力。
或者再看看视频截图的属性，每一个开放的摄像头都可能被用于分析环境，是仓库还是街道，是学校还是政府部门，是卧室还是输油管道。什么？艳照门？这么大威力的武器你们就用来干这种龌蹉事？
粒度越细越深入，对应的产出价值就越高，场景就越具体。可以再看一下原始数据，里面都带有更多细粒度的内容，比如打上云的标签。或者工业控制的标签：
里面涉及的内容太多，甚至是包括CVE的历史漏洞标签，下一篇我会对不同平台的核心区别进行对比分析，着重讲一下。现实远比大家想得更复杂，你看到的只是我想让你看到的，我不想让你看到的你一无所知。目前的这些只是刚刚拉开序幕，很多场景正在不断的涌现，就跟Google出来时只是一个搜索数据库一样，然后他们就做了新闻聚合，做了视频，做了指数，做了舆情分析……我担心的反而不是公开的全资产检索引擎，这方面shodan，censys，fofa，zoomeye各有各的优劣势，很难再有颠覆式的平台出来，但是，对于特定细分领域的搜索平台，其实是一个大家要关注的点。比如expanse这类，专注于物联网设备，这种是未来马上回兴起的新机会。
现在大家都在提态势感知，这个方向我无比认同。但是我并不认同国内的一些炒作概念的做法，概念日新月异，很多安全理念是从欧美国家开始提出来并发展起来的，但是人家是一步一个脚印踩出来的，每一个细分领域都有很踏实的公司完成，每一个细分领域的公司都能活的很好，这在以色列和硅谷非常明显，十几个人能卖几个亿，知识很值钱。但是国内前十几年的发展是选择跳级式的发展，什么数据都没有，也敢跟着喊，直接忽略了前期的积累阶段，但是有并不代表好。所以相对而言，目前国内的大一点的安全公司大多是综合型的解决方案公司，中国的安全市场以前也多是合规型市场，很难给细分领域的安全能力团队留出足够的机会。
我认为，态势感知也好，网络整体防御也罢，你都要知道自己的基本情况。你要时刻清楚有多少攻击面，这是基础中的基础，并且确保攻击面已经全部处在监控和防护体系之下，只有这样才能形成正确的认知和做出快速的决策。显然国内重要单位在这方面路还很长，太多次的成功入侵证明，被攻击并非防火墙没用，而是排兵布阵的方式不对。我经常用的一个比喻是：企业用坚不可摧的钢铁头盔护住了头部，谁也打不穿，但是脖子以下全然不顾，你可以伤害他的心脏，肚子，四肢，而血液是内部贯穿着的，所以防护方构建了马其顿防线，敌人绕开防线为所欲为。
网络安全是一门及其复杂也存在很多分支的科学，随着IT技术的不断变化，衍生了太多的场景以及对应的技术，比如从最初的PC安全开始，有杀毒，有系统安全，然后有了网络安全，网站安全，数据库安全，又有了移动安全，无线安全，再有了物联网安全，云安全，大数据安全，车联网安全，5G安全。我的结论有两个：一）没有任何一家能把这些全做精做深，如果有，那他一定是一个集成商。未来会越来越多的给细分领域的能力者提供机会，因为只有这样才能保证技术的领先性以及防御的全面性；二）安全将会回归本质，不管技术如何发展，武器再变战场不变，攻防的前提是一本地图。只有展开这本正确无误的详细地图，才能从有勇无谋的瞎子进化成指点江山的将才，才能真正做到知己知彼百战百胜。网络空间测绘就是提供地图的方式。