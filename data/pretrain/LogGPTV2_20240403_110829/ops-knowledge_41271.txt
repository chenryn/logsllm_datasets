User: I have trouble running my a little bit complex python program in a remote directory, mounted by SSHFS. It takes a few seconds to perform imports when executing in a remote directory and a fraction of a second in a local directory. The program should not access anything in the remote directory on its own, especially in the import phase.
By default, there is current (remote) directory I sys.path, but when I remove it before (other) imports, speed does not change. I confirmed with python -vv that this remote directory is not accessed in the process of looking for modules. Still, I can see a stable flow of some data from the network with an external network monitor during the import phase.
Moreover, I can't really identify what exectly it is doing when consuming most time. It seems to happen after one import is finished, according to my simple printouts, and before a next import is started...
I'm running Fedora 25 Linux
Assistant: In my case it were the Cern ROOT libraries import. When importing, they look in the current directory, no matter what I do. So the solution is to 

store the current directory
cd to some really local directory, like "/" or "/home" before imports
come back to the stored directory after imports