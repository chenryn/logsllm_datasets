and line 6 in Fig. 2b introduce syntax errors, and the parser
detects these errors and bails out. Line 7–8 in Fig. 2a and line
11–12 in Fig. 2b contain semantic errors which will be caught
by the backend optimizer or translator.
B. Limitations of Current Fuzzers
Fuzzing is a well-received technique of discovering bugs
and vulnerabilities in software [7, 17, 77]. However, current
fuzzers have limitations in testing language processors. General-
purpose mutation-based fuzzers [30, 38, 76, 77] are unaware of
input structures and randomly flip the bits or bytes of the inputs,
so they can hardly generate syntax-correct inputs. Recent works
adopt higher level mutation in AST or IR to guarantee the
syntactic correctness [44, 63]. Alternatively, generation-based
fuzzers [1, 51] utilize a model or grammar to generate structural
inputs effectively. These fuzzers have shown their advantages in
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:53 UTC from IEEE Xplore.  Restrictions apply. 
643
(cid:43)(cid:76)(cid:74)(cid:75)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:86)(cid:82)(cid:88)(cid:85)(cid:70)(cid:72)(cid:3)(cid:70)(cid:82)(cid:71)(cid:72)(cid:54)(cid:92)(cid:81)(cid:87)(cid:68)(cid:91)(cid:3)(cid:83)(cid:68)(cid:85)(cid:86)(cid:76)(cid:81)(cid:74)(cid:47)(cid:82)(cid:90)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:80)(cid:68)(cid:70)(cid:75)(cid:76)(cid:81)(cid:72)(cid:3)(cid:70)(cid:82)(cid:71)(cid:72)(cid:54)(cid:92)(cid:81)(cid:87)(cid:68)(cid:91)(cid:3)(cid:72)(cid:85)(cid:85)(cid:82)(cid:85)(cid:54)(cid:72)(cid:80)(cid:68)(cid:81)(cid:87)(cid:76)(cid:70)(cid:86)(cid:3)(cid:72)(cid:85)(cid:85)(cid:82)(cid:85)(cid:47)(cid:68)(cid:81)(cid:74)(cid:88)(cid:68)(cid:74)(cid:72)(cid:3)(cid:51)(cid:85)(cid:82)(cid:70)(cid:72)(cid:86)(cid:86)(cid:82)(cid:85)(cid:86)(cid:41)(cid:85)(cid:82)(cid:81)(cid:87)(cid:72)(cid:81)(cid:71)(cid:54)(cid:72)(cid:80)(cid:68)(cid:81)(cid:87)(cid:76)(cid:70)(cid:3)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:86)(cid:37)(cid:68)(cid:70)(cid:78)(cid:72)(cid:81)(cid:71)passing the syntactic checks over random bitflip mutation-based
fuzzers. Yet they ignore the semantic correctness of generated
test cases and fail to find deep bugs in the optimization or
execution code of language processors. We did a quick test
to understand how semantic correctness helps fuzzers reach
deeper logic: compiling the code in Fig. 2a with "-O3" covers
56,725 branches in gcc-10, while those invalid variants starting
with "+" only trigger less than 27,000 branches as they are
rejected during or right after the parsing.
Researchers try to specialize their fuzzers for higher semantic
correctness [42, 53, 74, 78]. CSmith [74] performs heavy
analyses to generate valid C programs without undefined
behaviors. JavaScript fuzzers [42, 53] consider the types of
expressions to avoid semantic errors in generated test cases.
Squirrel [78] tackles the data dependency of SQL to generate
valid queries to test DBMSs. Unfortunately, these approaches
are highly specialized for one programming language. Users
need to put huge development efforts to adopt them on new pro-
gramming languages, which is time-consuming and impractical
considering the large number of real-world languages [3].
test cases for different
Recent language-based fuzzers [22, 44] try to generate
correct
languages. LangFuzz [44]
replaces every variable in the mutated code randomly while
Nautilus [22] uses a small set of predefined variable names and
relies on feedback guidance to improve semantic correctness.
However, these strategies are only effective in testing languages
which allow more implicit type conversion, such as JavaScript
and PHP.
C. Common Semantic Errors
We manually investigate 1,500 invalid test cases generated
by existing language fuzzers [22, 51, 53] and summarize four
common types of semantic errors. Two of them are related
to the scope of variables and functions, and the rest two are
related to the types of variables and expressions. These errors
violate the common rules of types and scopes on definitions
and are language-independent.
Undefined Variables or Functions. Variables or functions
should be defined before they can be used. Otherwise, the
behaviors of the program can be undefined or illegitimate. For
example, line 8 of Fig. 2a uses an undefined variable res and
C compilers refuse to compile the code.
Out-of-scope Variables or Functions. In a program, variables
or functions have their scopes, which determine their visibility.
We cannot use an out-of-scope invisible variable or function.
For example, arr is visible at line 10 of Fig. 2b, while arr2 is
not since its scope is within the if statement at line 4.
Undefined Types. Many programming languages allow users
to define custom types, such as class in JavaScript and
struct in C. Like variables, such types should be defined
before their instances can be used.
Unmatched Types. Usually, assigning a value to a variable
of incompatible type or comparing incompatible types intro-
duces semantic errors. In some cases, programming languages
allow type conversions, which convert mismatched types to
compatible ones explicitly or implicitly. For example, e of type
pointer of short and s of type S are not compatible in C,
so line 7 of Fig. 2a introduces an error. Line 7 of Fig. 2b is
correct because in JavaScript numbers can convert to strings.
D. Our Approach
The goal of this paper is to build a generic fuzzing framework
that generates semantically correct inputs to test different
language processors. We achieve the goal in two steps. First,
we neutralize the difference in syntax and semantics of
programming languages by embedding them into a uniform IR,
so we can perform uniform mutation or analysis regardless of
the underlying languages. Second, we constrain our mutation to
generate new test cases, which might contain semantic errors,
and then we perform semantic validation to fix these errors.
Neutralizing Difference in Programming Languages. Dif-
ferent programming languages have unique syntax and seman-
tics. To neutralize their differences, we design a new inter-
mediate representation to map the language-specific features,
both syntactic and semantic, into a uniform format. Given the
BNF grammar of a language, we can generate a frontend to
translate a source program into an IR program. The IR program
consists of a list of IR statements or IRs as we call them in this
paper. This IR program keeps the syntactic structures of source
programs so we can easily translate it back into the original
source. Regarding semantics, we design a simple annotation
format for users to describe the scopes and types of a language.
These descriptions will be encoded into the semantic properties
of the IR and guide our system to fix semantic errors. After
the language-specific grammar and semantics are captured by
the IR, we can perform mutation or analyses regardless of the
underlying language.
Improving Language Validity. We improve the language
validity with constrained mutation and semantic validation.
Our constrained mutation tries to preserve two aspects of the
program: the syntactic correctness of the whole program, and
the semantic correctness of the unmutated part. First, we mutate
the IRs based on their IR types that reflect the underlying
grammar structures. This preserves the syntactic correctness of
the test case. For example, we replace an IF statement (in the
form of IR) with another IF statement instead of a function call
expression. Second, we only mutate IRs with local effects to
preserve the semantic validity of the unmutated code. Such IRs
contain no definitions or create new local scopes. For example,
in Fig. 2b, line 7 has local effects because it only uses the
variable arr and contains no new definition. Without line 7, the
rest of the program is still valid. Therefore, assuming the initial
test case is correct, a mutated variant produced by constrained
mutation only has potential semantic errors in the mutated
part, which might use invalid variables. To fix these errors in
a systematic way, our semantic validation first utilizes IR’s
semantic properties to collect type and scope information of the
mutated test case. We integrate the collected information into
the symbol tables, which contain the types, scopes and names
of every definition. These symbol tables guide POLYGLOT
to replace the invalid use of variables properly. Afterward,
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:53 UTC from IEEE Xplore.  Restrictions apply. 
644
A. Intermediate Representation
Our IR is in a uniform format and captures the syntax and
semantics of the source program. It includes an order, a type,
an operator, no more than two operands, a value, and a list
of semantic properties. The IR order and the type correspond
to the statement order in source code and the symbol in the
BNF grammar respectively. The IR operator and the IR value
store the original source code. All the IRs are connected by
the IR operands, which are also IRs. These parts carry the
syntactic structures, while the semantic properties describe the
semantics of the source program, as discussed below.
Syntactic Structures. Syntactic structures keep all the gram-
mar information of the source program. As we see earlier,
some IRs store a small piece of the source code (e.g., a function
name is stored in an IR of type FuncName). Also, the IRs are
connected in a directed way that forms a tree view of the
source program. If we perform inorder traversal on the IR
program, we can reconstruct the original source program.
Semantic Properties. Semantic properties capture the se-
mantics about the scopes and types of definitions. They tell
us which IRs belong to variable definitions. Additionally, for
scopes, they tell which IRs create new scopes so that we can
decide the visibility of the variables within the scopes. For
types, they describe the predefined and user-defined types in a
language and their type conversion rules. They also describe
the expected operand types and the output type of operators,
which perform mathematical, relational, or logical operations
and produce a result.
For example, ir9 in Fig. 4a has the semantic property
FunctionDefinition, indicating that it relates to a function
definition. Line 14-15 in Fig. 4c describe the inference rule
for the operator "+", which accepts two operands of type long
and outputs a result of type long. Assuming number literals
are of type long, we know 11 + 12 produces a result of long.
B. Generating IR Translator
To generate a translator, users should provide the BNF
grammar, which describes the unique syntax, and semantic
annotations, which capture the specific semantics of a language.
The language information of these two files is embedded
into the syntactic structures and semantic properties of IR
respectively. First, the frontend generator treats every different
symbol in the grammar as a different object. Then it analyzes
the semantic annotations to decide which symbols should have
what semantic properties. Finally, it generates for each object
unique parsing and translation methods, which parse the source
code and generate IRs with required semantic properties. These
generated methods composite an IR translator.
V. CONSTRAINED MUTATION
As the first step towards language validity, we apply two
rules to constrain our mutation on an initially correct test case
to preserve its syntactic correctness (§V-A) and the semantic
correctness of its unmutated part (§V-B). The former is the
base for semantic correctness, and the latter makes it possible
Fig. 3: Overview of POLYGLOT. POLYGLOT aims to discover bugs
that crash language processors. POLYGLOT accepts the BNF grammar,
semantic annotations, and seeds from users as input. First, the frontend
generator generates an IR translator that converts a source program
to an IR program. Second, the constrained mutator mutates the IR
program to get new ones, which might contain semantic errors. Next,
the semantic validator fixes the semantic errors. Finally, the fuzzer
runs validated programs to detect bugs.
the validated test cases should be correct and are helpful for
thoroughly fuzzing language processors.
III. OVERVIEW OF POLYGLOT
Fig. 3 shows an overview of POLYGLOT. Given the BNF
grammar, semantic annotations and initial test cases of the
targeted programming language, POLYGLOT aims to find inputs
that trigger crashes in the language processor. First, the frontend
generator generates an IR translator using the BNF grammar
and the semantic annotations (§IV). Then, for each round of
fuzzing, we pick one input from the corpus. The IR translator
lifts this input into an IR program. Next, the constrained mutator
mutates the IR program to produce new syntax-correct ones,
which might contain semantic errors (§V). Afterward, the
semantic validator tries to fix the semantic errors in the new IR
programs (§VI). Finally, the IR program is converted back to
the form of source code and fed into the fuzzing engine. If the
test case triggers a crash, we successfully find a bug. Otherwise,
we save the test case to the corpus for further mutation if it
triggers a new execution path.
IV. FRONTEND GENERATION
To achieve generic applicability, our frontend generation
generates a translator that transforms a source program into
an IR program. This lowers the level of mutation and analysis
from language-specific source code to a uniform IR.
In Fig. 4, we show the IR (Fig. 4a) of a simple C program
to demonstrate how the BNF grammar (Fig. 4b) and semantic
annotations (Fig. 4c) help construct the IR statements. Each
symbol in the BNF grammar generates IRs of a unique type
(e.g., symbol  generates ir9 of type FuncDef). The
original source code is stored in the op or val of the IRs (e.g.,
the val of ir2 stores the name main). We predefine semantic
properties about types and scopes of variables for users to use.
The generated IRs will carry these properties as described in
the annotations (e.g., ir9 has property FunctionDefinition).
Users can easily use the BNF grammar and semantic anno-
tations to describe the specific syntax and semantics of a
programming language.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:53 UTC from IEEE Xplore.  Restrictions apply. 
645
Frontend GenerationIR translatorConstrained MutationSemantic ValidationFuzzing EngineGrammarA:= xA | CC:= ySeedsCorpusSemantic annotationGenerateUser InputsInteresting test casesPOLYGLOTIR programValidated program Mutated programSource Programval
NIL,
NIL,
ir0,
NIL,
NIL,
NIL,
NIL,
NIL,
NIL,
NIL,
[FunctionName]>
left, right, op,
[, semantic_property]>
"int">
NIL >
"main",
ir0
NIL,
23 >
NIL,
"+",
NIL >
"return ;", NIL >
"{ }",
ir8
NIL,
NIL,
ir4,
NIL,
NIL,
[FunctionDefinition]>
ir10
NIL,
NIL >
"()",
NIL,
( 
"(" ? ")" )
( | )*
1  ::=
2
3 ...
4
5  ::=
6
7
8
9  ::= 
10
11  ::=
12
13
14  ::=
15
16 ...
(b) Part of the BNF grammar for
C programs.
 "+" 
("int" | "short" | ...)
{"short": ["int", "..."]}
"func-def":["FunctionDefinition"],
"func-name":["FunctionName"],
"func-body":["FunctionBody", "NewScope"],
"Comment2": "Types and conversion rules",
"BasicType": ["int", "short", "..."],
"ConversionRule": [
1 { "Comment1": "Scopes and composite types",
2
3
4
5
6
7
8
9
10
11
12
13
14