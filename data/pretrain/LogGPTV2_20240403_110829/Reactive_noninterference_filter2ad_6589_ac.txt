Standard deﬁnitions of noninterference [21, 17] usually im-
ply some sort of functional dependency between the inputs
and outputs of a program. The same is true here (and this
fact is convenient for proving subsequent properties of our
system).
3.12 Lemma: If a state Q is ID-secure, then for all I,
Q(I) ⇒ O and Q(I) ⇒ O(cid:2)
implies O = O(cid:2)
.
To be precise, this does not mean a reactive system must
be deterministic in order to be ID-secure: state transitions
can be nondeterministic as long as they do not aﬀect the
output behavior.
It is straightforward to demonstrate a relationship be-
tween ID-similarity and NC-similarity.
3.13 Lemma: S ≈ID
implies S ≈NC
l S(cid:2)
l S(cid:2)
.
More interesting is the fact that ID-security is stronger
than NC-security. (This is not as straightforward to show
because ID-similarity appears contravariantly in the deﬁni-
tion of security.)
3.14 Lemma: If a transducer in a state Q is ID-secure,
then it is NC-secure.
83From a practical standpoint, we don’t see any setting
where NC-security is preferable to ID-security. We will see
later that ID-security for RIMP programs can be guaranteed
with a simple and ﬂexible type system, and it is not clear
how one would weaken the type system to include programs
that are NC-secure but not ID-secure.
is
Security. ID-security
Coproductive
termination-
insensitive because it does not give the observer the power
to distinguish non-silent output streams from silent but
inﬁnite ones. We can ensure that such streams are always
considered distinct with a more direct, coinductive deﬁni-
tion of similarity, called coproductive similarity, which can
be viewed as a weak bisimulation between the two streams,
in which invisible elements correspond to internal τ actions.
3.15 Deﬁnition: Coinductively deﬁne S ≈CP
similar to S(cid:2)
(S is CP-
l S(cid:2)
at l) with the following rules:
silent l(S(cid:2)
silent l(S)
)
S (cid:2)l s :: S1
S1 ≈CP
l S(cid:2)
1
S ≈CP
l S(cid:2)
S(cid:2) (cid:2)l s :: S(cid:2)
S ≈CP
l S(cid:2)
1
Deﬁne CP-security as Deﬁnition 3.1, instantiated with CP-
similarity.
Unlike the earlier deﬁnitions of similarity, this one is an
equivalence relation. It is easy to check that Example 3.11
is not CP-secure, using the same input and output pairs
mentioned above. Although we use a coinductive deﬁnition
here, it should be possible to draw a very close correspon-
dence between this deﬁnition and the ones used recently for
“interactive programs” [16, 9, 2].
The inductive deﬁnitions of NC-similarity and ID-
similarity resemble one another, so it was easy to prove
Lemma 3.13; on the other hand, proving the following lemma
requires a bit more work.
3.16 Lemma: S ≈CP
l S(cid:2)
implies S ≈ID
l S(cid:2)
.
What is the relationship between CP-security and ID-
security, though? Again, since CP-similarity appears both
co- and contravariantly in the deﬁnition of CP-security, their
relationship is not at all obvious. The proof of the following
lemma rests on several auxiliary deﬁnitions and lemmas, and
additionally makes use of the bisimulation-based technique
we introduce in Section 4.
3.17 Lemma: If a state Q is CP-secure, then it is ID-
secure.
Coproductive-Coterminating Security. CP-security is
quite strong, but it is possible to go a step further by deﬁn-
ing similarity in such a way that ﬁnite and inﬁnite silent
streams can be distinguished (coproductive-coterminating
similarity).
3.18 Deﬁnition: Coinductively deﬁne S ≈CPCT
CPCT-similar to S(cid:2)
at l) with the following rules:
(S is
S(cid:2)
l
silent l(S)
silent l(S(cid:2)
)
S ≈CPCT
l
ﬁn(S)
ﬁn(S(cid:2)
)
S(cid:2)
silent l(S)
silent l(S(cid:2)
)
S ≈CPCT
l
inf (S)
inf (S(cid:2)
)
S(cid:2)
S (cid:2)l s :: S1
S(cid:2) (cid:2)l s :: S(cid:2)
S ≈CPCT
S(cid:2)
1
l
S1 ≈CPCT
l
S(cid:2)
1
Here is an example of a program that is secure by every
other deﬁnition thus far but is not CPCT-secure.
3.19 Example: The following program is not CPCT-
secure:
input ch(cid:3)(x) { r := x;
if x = 0 then while 1 do skip }
This is the entire program. Low inputs are consumed but
produce no low-visible output because there is no handler for
them. (If this were not the case, then this program would
fail to be CP-secure.)
The deﬁnitions of CP-similarity and CPCT-similarity
aren’t too diﬀerent; so the following results shouldn’t be
too surprising, although the latter one is still not trivial.
3.20 Lemma: S ≈CPCT
l
S(cid:2)
implies S ≈CP
l S(cid:2)
.
3.21 Lemma: If a transducer in a state Q is CPCT-secure,
then it is CP-secure.
CPCT-security guarantees that a reactive system can
never make a choice between entering a input-accepting
state or silently diverging based on a high input. However,
this additional guarantee over CP-security is unimportant
in practice because an attacker does not have the power to
observe the results of such a choice in a CP-secure system.
Consider a CP-secure machine that will silently diverge upon
receiving a high input of 0 but will immediately return to a
consumer state upon receiving a nonzero high input. A low
observer who wishes to determine if the ﬁrst high input was
nonzero can only send a message to the machine and wait
for a response (in our attack model, there is no other way to
probe the system). A response would not be given to the low
observer if the high input were 0; thus, CP-security guaran-
tees that, even if the machine eventually consumes the low
input, no response will be given to the low observer after
(or even before) any high input. Since there is no possibility
for getting feedback, there is no way for the low observer to
determine if the system accepted the low input or whether
the input is sitting in a buﬀer while the machine runs for-
ever. Thus, CP-security is weaker than CPCT-security only
on paper.
Summary. We have presented four deﬁnitions of security
based on four deﬁnitions of similarity. Of these, two appear
to be of practical interest: ID-security and CP-security. En-
forcing CP-security through language-based techniques in-
volves diﬃcult trade-oﬀs. For instance, O’Neill, Clarkson,
and Chong [16] choose to disallow looping over high-level
data, a very severe restriction.
Instead, we choose to fo-
cus on termination-insensitive ID-security at this point. Al-
though the type system we’ll use to enforce this looks quite
standard, we ﬁrst need to break down the deﬁnition of ID-
security from a property on the input/output behavior of a
system to a property on the states of a reactive system.
844. PROVING ID-SECURITY
We now present a generic technique for proving the ID-
security of a state in a reactive system. This is an “un-
winding lemma” in the sense of Goguen and Meseguer [6]:
it is a logically suﬃcient condition on the states of a transi-
tion system to ensure a high-level property of the system’s
input/output behavior. One can alternatively view it as a
bisimulation technique, given that it involves a binary rela-
tion that facilitates the coinductive proof of the unwinding
lemma.
4.1 Deﬁnition: An ID-bisimulation on a reactive system is
a label-indexed family of binary relations on states (written
∼l) with the following properties:
, then Q(cid:2) ∼l Q;
(a) if Q ∼l Q(cid:2)
and C i→ P and C(cid:2)
(b) if C ∼l C(cid:2)
;
and ¬ visible l(i) and C i→ P , then P ∼l C(cid:2)
(c) if C ∼l C(cid:2)
;
(d ) if P ∼l C and P o→ Q, then ¬ visible l(o) and Q ∼l C;
(e) if P ∼l P (cid:2)
, then P ∼l P (cid:2)
, then either
i→ P (cid:2)
or else
implies o = o(cid:2)
• P o→ Q and P (cid:2) o(cid:2)→ Q(cid:2)
• P o→ Q implies ¬ visiblel(o) and Q ∼l P (cid:2)
• P (cid:2) o(cid:2)→ Q(cid:2)
) and P ∼l Q(cid:2)
implies ¬ visiblel(o(cid:2)
.
and Q ∼l Q(cid:2)
,
, or else
We will see below that, if Q ∼l Q for all l, then Q is ID-
secure. We do not use a standard form of bisimulation (as is
done in [4]) because we need a technique that gives rise to a
termination-insensitive security property. Note that, in the
ﬁrst of the three cases under item (e), if one side can make
a step with an output o, then all steps taken by the other
side must produce the same output o. On the other hand,
the other two cases under item (e) permit one side to take a
silent step without being matched by the other side, which
allows one side to get inﬁnitely far ahead of the other when
this deﬁnition is used coinductively.
Before we can prove that this deﬁnition gives us the prop-
erty we want, we need to introduce one more deﬁnition of
similarity between streams.
4.2 Deﬁnition: Coinductively deﬁne S ≈VS
l-similar to S(cid:2)
[] ≈VS
[]
¬ visiblel(s)
) with the following rules:
visible l(s)
(S is visibly
l S(cid:2)
l S(cid:2)
S ≈VS
s :: S(cid:2)
S ≈VS
S ≈VS
l S(cid:2)
l S(cid:2)
l
l
s :: S ≈VS
¬ visiblel(s)
S ≈VS
l
s :: S(cid:2)
s :: S ≈VS
l S(cid:2)
Observe that this is a natural relation to deﬁne between
two streams with invisible elements. It is easy to write down
because it does not depend on auxiliary deﬁnitions such as
l-reveals. Does this relation give rise to yet another notion
of similarity and security? No, in fact, it coincides exactly
with ID-similarity.
4.3 Lemma: S ≈VS
iﬀ S ≈ID
l S(cid:2)
l S(cid:2)
.
4.4 Lemma: Suppose that Q ∼l Q(cid:2)
and Q(cid:2)
. Then I ≈VS
) ⇒ O(cid:2)
(I(cid:2)
I(cid:2)
l
, and that Q(I) ⇒ O
implies O ≈VS
l O(cid:2)
.
The previous two lemmas lead us directly to our goal.
4.5 Theorem: If Q ∼l Q for all l, then Q is ID-secure.
5. RIMP
Rather than using our technique from Section 4 to prove
programs secure one at a time, we would like to demon-
strate that we can use a type system to show that all of the
well-typed programs in a language are secure, in line with
the previous work on language-based security [19]. To this
end, we complete our technical development with a formal
presentation of the RIMP language, along with a static type
system that will ensure that well-typed programs are secure.
We will prove this result by deﬁning a relation on program
states and showing that it is an ID-bisimulation for which
well-typed programs are related to themselves.
Operational Semantics. We ﬁrst deﬁne consumer and
producer states of the RIMP reactive system. A consumer
state, C, is a store paired with a program. A producer state,
P , also includes the currently executing command and is
tagged by the channel that triggered the execution. Stores,
μ, map global variables to the natural numbers they contain.
C ::= (μ, p)
P ::= (μ, p, c)ch
The transition between states in the RIMP reactive sys-
tem is deﬁned by the following four judgments of the oper-
ational semantics, whose deﬁnitions appear below.
1. μ (cid:14) e ⇓ n, a big step evaluation of closed expressions
to numeric values, using the store to look up variables.
(This deﬁnition is an entirely straightforward one, in
which we use 0 for the boolean value false and nonzero
numbers for true. See Appendix B for the formal def-
inition.)
2. (μ, c)
o→ (μ(cid:2), c(cid:2)
), a small step execution of a closed com-