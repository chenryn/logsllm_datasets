Ext
Net
client
check
From
Client
Rules at the leaf
Generic
Fig. 3. An example evaluation tree that checks protocol ﬁelds to determine the set of
rules for matching an incoming packet
to the multi-pattern search algorithm and the only objective of this hierarchi-
cal evaluation is to reduce the number of applicable rules, so that a packet is
matched with as few rules as possible.
Figure 3 shows an example of an evaluation tree in which protocol ﬁelds are
hierarchically evaluated to determine the set of applicable rules. It ﬁrst checks
for destination port. If the destination port matches a value for which the set
of rules is maintained then those groups of rules are further analyzed, or else
the generic set of rules is picked. If the destination port is 21, the connection
table is checked to determine if the packet came from the client who initiated
the connection, and the corresponding rules are picked. If the destination port
is 80, then the destination IP address of the packet is checked. Then, depending
on whether the packet is destined to the Home Network or not, the correct set
of rules are picked to further evaluate on the packet. However, maintaining a
naive hierarchical index structure, in which every speciﬁc value of a protocol
ﬁeld is separated, consumes a signiﬁcant amount of memory for the following
two reasons:
1. Groups require memory: Multiple patterns from a set of rules have to be
searched in a payload in only one pass of the payload. Therefore, additional
data structures are maintained for fast multi-pattern matching. This struc-
ture can be a hash table as in the case of the Wu-Manber [11] algorithm,
or a state table as in the case of the Aho-Corasick [10] algorithm. These
structures consume a signiﬁcant amount of memory.
2. Rules are duplicated across groups: If groups are formed by composing
two protocol ﬁelds hierarchically, then the number of distinct groups may
increase signiﬁcantly. For example, assume that the rules are ﬁrst divided by
destination port, and then each group so formed is further divided by source
298
S. Sinha, F. Jahanian, and J.M. Patel
port. A rule that is speciﬁc in source port but matches any destination
port has to be included in all groups with a particular destination port. If
the groups that are separated by destination port are further divided by
source port, then separate source port groups would be created within all
the destination port groups. For a set of rules with n source port groups and
m destination port groups, the worst number of groups formed, when rules
are hierarchically arranged by the two protocol ﬁelds, is n × m.
To investigate the memory consumed when rules are grouped hierarchically
by diﬀerent protocol ﬁelds, we instrumented Snort to construct this structure
for a given list of protocol ﬁelds. We then measured the memory consumed for
diﬀerent combinations of protocol ﬁelds. Figure 4 shows the memory consumed
when diﬀerent protocol ﬁelds are hierarchically arranged, and a separate bin is
maintained for every speciﬁc value in a protocol ﬁeld (trace data was 99-w4-thu
from DARPA dataset and the 2059 rules of Snort-2.1.3 distribution). This shows
that the memory consumed by the combination of destination port and client
check is 50% more than just the destination port. The memory required for the
combination of destination port and destination IP address is two times, and for
the combinations of destination port, destination IP address and client check, the
memory consumed is three times than only using the base destination port. From
the graph, the increase in memory is evident when the rules are hierarchically
grouped by destination port and source port. Therefore, constructing such a
hierarchy immediately raises two important questions:
memory usage (MB)
 0
 100
 200
 300
 400
 500
 600
destination_port
actual_snort
destination_port+from_client
destination_port+destination_ip
destination_port+destination_ip+from_client
destination_port+source_port
Fig. 4. Memory usage when rules are hierarchically arranged by protocol ﬁelds in the
speciﬁed order using the DARPA dataset (99-w4-thu)
WIND: Workload-Aware INtrusion Detection
299
1. What is the order in which the protocol ﬁelds are evaluated in the hierarchy?
2. What are the values of a protocol ﬁeld for which groups are maintained?
In what follows, we ﬁrst present a mathematical description of this problem,
analyzing the cost and beneﬁt of diﬀerent orders of protocol ﬁelds and the ﬁeld
values for which the rules are maintained. We then argue that these questions
can be answered by capturing properties of the workload, namely the traﬃc-mix
characteristics and the input rule set characteristics.
3.2 Formal Description
1, vi
2, . . . , vi
j1 ) ∧ (Fr2 = vr2
j2 ) ∧ . . . ∧ (Fri = vri
Consider n protocol ﬁelds F1, F2, . . . , Fn. Let vi
In this section, we formulate the problem of determining the order of evaluation
and the values of protocol ﬁelds for which the groups are maintained. As argued
earlier, the cost in maintaining a separate group is mostly the memory consumed
by the group. Intuitively, the beneﬁt obtained by maintaining a group of rules
can be measured by how many rules this group separates from the rule set
and how frequently this group is rejected for an incoming packet. We begin by
formalizing the problem.
mi be mi speciﬁc
values of the protocol ﬁeld Fi present in various rules in the rule set. Let P =
(Fr1 = vr1
ji ) be the predicate for a group
that is picked only when the packet matches speciﬁc values for i protocol ﬁelds,
and f(P) denote the probability that the protocol ﬁelds for an incoming packet
matches the predicate P, i.e., vr1
j2 for protocol ﬁeld Fr2,
ji for protocol ﬁeld Fri. f(P) actually captures statistics on the network
. . . , vri
traﬃc. The probability that an incoming packet does not have the values for
protocol ﬁelds as the predicate P is 1 − f(P). Let the beneﬁt of rejecting rule R
be measured by improvement of bR in run time. Then, every time a packet does
not have the values for protocol ﬁelds as P, beneﬁt of
R=rule with value P bR is
obtained by maintaining a separate group of rules with values P. Therefore, the
overall beneﬁt of creating a group with speciﬁc values for protocol ﬁelds present
in the predicate P includes traﬃc characteristics in f(P) and rule properties in
the rule set as:
j1 for protocol ﬁeld Fr1, vr2
(cid:1)
(1 − f(P)) ×
bR
R=rule with value P
(1)
Assume that c(P) is the memory cost of creating a group for a set of rules that
satisﬁes the predicate P. Then, the problem of an eﬀective hierarchical structure
is to determine the set of groups such that they maximize the beneﬁt measured
by improvement in run time for a given total cost, measured by the total amount
of memory that is available. Formally, the objective is to determine m and m
distinct predicates P1,P2, . . . ,Pm that maximizes
(cid:2)
m(cid:2)
(cid:2)
[(1 − f(Pi)) ×
i=1
R=rule with value Pi
bR]
(2)
300
S. Sinha, F. Jahanian, and J.M. Patel
with the cost constraint
m(cid:2)
i=1
3.3 Our Approach
c(Pi) ≤ maximum memory
(3)
In this section, we design an algorithm that captures the properties of input rules
and traﬃc characteristics to produce an eﬀective set of rule groups, separated
by values of protocol ﬁelds. These groups are then arranged in a hierarchical
evaluation structure, which determines the order in which protocol ﬁelds are
evaluated on an incoming packet. We begin with some assumptions that simplify
the above mathematical model for a realistic treatment and then present our
algorithm.
Assumptions. It is not easy to precisely determine the cost of creating a data
structure for matching multiple patterns and the absolute beneﬁt achieved by
rejecting a rule. For some exact substring-match algorithms (like Aho-Corasick),
the memory space occupied by the data structure may not grow linearly with
the number of patterns. For hash-based algorithms, the memory consumed is
independent of the number of patterns. This makes estimating cost for a multi-
pattern-matching algorithm diﬃcult. At the same time, for most algorithms that
perform multi-pattern matching, it is hard to estimate the beneﬁt of excluding a
single pattern. Therefore, we will make two simplifying assumptions that allows
us to easily compute the cost and beneﬁt:
1. The cost of creating a multi-pattern data structure for any group of patterns
is constant. This assumption is valid for hash-based matching algorithms,
like Wu-Manber, that allocate ﬁxed hash space. However, this assumption
is incorrect for the Aho-Corasick algorithm in which the required space may
increase with the increase in the number of patterns.
2. The beneﬁt of rejecting any rule is a one-unit improvement in run time (i.e.,
bR = 1) except for rules that have content of maximum length one. The rules
that have content length one signiﬁcantly degrade multi-pattern matching
and should be separated if possible. Therefore, rules with a content length
of one are assigned a large beneﬁt (mathematically inﬁnity). It is possible
that other patterns may adversely impact the performance in multi-pattern
search, but we choose to ignore such interactions for simplicity.
It is important to note that our assumptions help us to easily estimate the cost
and beneﬁt of creating a group, and more accurate estimates will only improve
our scheme.
The Algorithm. Instead of specifying a ﬁxed memory cost and then maxi-
mizing the beneﬁt, we specify the trade-oﬀ between the cost and the beneﬁt.
We say that any speciﬁc value of a protocol ﬁeld that rejects at least a mini-
mum THRESHOLD number of rules should be assigned a separate group and
WIND: Workload-Aware INtrusion Detection
301
hence, memory space. This speciﬁcation allows us to more easily tune real-time
performance.
The mathematical model allows us to compare two groups with speciﬁc values
for a number of protocol ﬁelds. The problem is then to determine a set of groups
in which each group rejects at least a THRESHOLD number of rules and the
set maximizes the overall beneﬁt. However, this may require generating all pos-
sible sets, which is computationally infeasible. Therefore, we do not attempt to
produce an optimal set of groups, but instead to discover possible groups heuris-
tically. The main intuition behind our algorithm is to place all rules in a bin
and iteratively split that bin by the protocol ﬁeld that produces the maximum
beneﬁt, and at each split separate values of the chosen protocol ﬁeld that reject
at least a THRESHOLD number of rules on average.
j
(cid:1)
j) and
R=rule with value P bR reduces to SFi=vi
We now explain our algorithm in detail. First, all rules are placed in a bin.
Then, a few packets are read from the network and protocol ﬁelds in each rule are
evaluated. Then, the beneﬁt obtained by a value in a protocol ﬁeld is computed
j of the protocol ﬁeld Fi, f(P) reduces
using the beneﬁt Equation 1. For value vi
where SP indicates
to f(Fi = vi
the number of rules with protocol ﬁeld values speciﬁed by the predicate P. This
simpliﬁcation is possible because bR is one. The overall beneﬁt of a protocol
ﬁeld is the sum of beneﬁt of all values, and the protocol ﬁeld is chosen that
produces maximum beneﬁt. Then groups are formed for each speciﬁc value in
the protocol ﬁeld that rejects at least THRESHOLD number of rules, or has
a rule with content length one. Then, we partition the bin into those speciﬁc
values and recursively compute other protocol ﬁelds for each of these bins. We
stop splitting a bin if none of the protocol ﬁelds can reject at least THRESHOLD
number of rules.
When we partition a bin into speciﬁc values, we replicate a rule that may
match multiple of these speciﬁc values in all those bins. For example, if the rules
are divided by destination port, then a rule that matches ‘any’ destination
port is included in all of those bins. This ensures that when a set of rules with
a speciﬁc value for a protocol ﬁeld are picked, other applicable rules are also
matched with the packet. This is essential for correctness. Generally a rule with
value vj for a protocol ﬁeld is included in a rule set with speciﬁc value vi if
vj ∩ vi (cid:11)= 0. If there is an order in which the values are checked during run-time,
then a rule vj is included in vi only if it appears before it, and if it satisﬁes the
previous property.
Packets rejected by a protocol ﬁeld may correlate with packets rejected by
another protocol ﬁeld, and so computing protocol ﬁelds independently may give
misleading information. For example, a source port and a source IP address
may reject exactly the same packets, in which case we do not gain anything by
checking both of them. Our recursive splitting of a bin removes this problem of
correlated values. This is because for a bin, we evaluate the beneﬁt of remain-
ing protocol ﬁelds only on those packets that match the values speciﬁed in the
bin. For example, to split a bin containing port-80 rules, we only evaluate the
302
S. Sinha, F. Jahanian, and J.M. Patel
remaining protocol ﬁelds on packets that have port 80. This ensures that the
remaining protocol ﬁelds reject only the rules that were not rejected by port 80.
By choosing the protocol ﬁeld that produces maximum beneﬁt for each bin,
we get an order in which the protocol ﬁeld is checked for a packet. By choosing
values that produce beneﬁt above a threshold, we get the values that determines
which groups should be maintained.
Implementation. We implemented two distinct components to develop a work-
load-aware Intrusion Detection System. The ﬁrst component proﬁles the work-
load (i.e., the input rules and the live traﬃc) to generate the evaluation tree.
The second component takes the evaluation tree, pre-processes the rules, and
matches any incoming packet on the tree. These components are general enough
to be applied to any IDS. We implemented our algorithm that generates an eval-
uation tree for a given workload over Snort 2.1.3. We chose Snort as it already
provides an interface to read the rules into proper data structures. It also pro-
vides an interface to read the incoming traﬃc and check for diﬀerent protocol
ﬁelds.
As a second component, we modiﬁed Snort 2.1.3 to take the bin proﬁles and
construct a hierarchical evaluation plan. Snort 2.0 [14] introduced an interface for
parallel evaluation of rules on a packet. Our hierarchical evaluation tree provides
the set of applicable rules for a packet according to its values for diﬀerent protocol
ﬁelds. We pre-computed the data structure required for parallel matching for
each of these groups. For every packet, we used our evaluation tree to determine
the set of applicable rules and allowed Snort to perform the evaluation. We
implemented three protocol ﬁelds by which the hierarchical structure can be
constructed, namely: destination port, source port, destination IP address, and
whether the packet is from the client. Since rules contain a large number of
distinct protocol ﬁelds and we want to immediately detect the applicable rules,
we implemented a check for destination port using an array of 65,536 pointers.
Source port and destination IP address was checked by looking for possible match
in a linked list. We did this because only a few destination IP addresses/source
ports have to be checked, and because maintaining a pointer for each speciﬁc
value consumes signiﬁcant memory. For client checks the rules were divided into
two parts: those that required to check if the packet is coming from client, and
the rest were others. Every time a bin was split, we ensured that a rule was
included in all new bins whose speciﬁc value can match the value in the rule.
This ensured the correctness of our approach. We also validated our system by
matching the number of alerts that our system raises, when compared to the
number of alerts raised by unmodiﬁed Snort on a large number of datasets.
4 Evaluation
In this section, we evaluate Wind on a number of publicly-available datasets and
on traﬃc from a border router at a large academic network. On these datasets, we
compared real-time performance of Wind with existing IDSs using two important
metrics: the number of packets processed per second and the amount of memory
WIND: Workload-Aware INtrusion Detection
303
consumed. To measure the number of packets processed per second, we compiled
our system and the unmodiﬁed Snort with gprof [21] options and then evaluated
the dataset with each one of them. Then we generated the call graph, using
gprof, and examined the overall time taken in the Detect function, which is
the starting point of rule application in Snort. Finally, using the time spent
in Detect and the number of times it was called, we computed the number of
packets processed per second. To compute the memory used, we measured the
maximum virtual memory consumed during the process execution by polling
each second the process status and capturing the virtual memory size of the
process. We now describe the datasets and the computing systems that we used
for our experiments.
4.1 Datasets and Computing Systems
We evaluated the performance of our system on a number of publicly-available
datasets and on traﬃc from a large academic network. For publicly available
datasets, we used traces that DARPA and MIT Lincoln Laboratory have used
for testing and evaluating IDSs. We used two-week testing traces from 1998 [22],
and two-week testing traces from 1999 [23]. This gave us 20 diﬀerent datasets