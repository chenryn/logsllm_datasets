Figure 12: The classiﬁcation results of operation models. (a) Layer Movement Model; (b) Head Movement
Model; (c) Axial Movement Model; (d) X Directional Movement Model; (e) Y Directional Movement Model.
We employ the supervised learning model, support vector
machines (SVM), as the classiﬁers to predict the primitive
movement. More speciﬁcally, we use the Sequential Mini-
mal Optimization (SMO) implementation of SVM which is
provided in the Weka machine learning toolkit [4].
5.3
IP Reconstruction
IP reconstruction is a procedure which converts the printer
status set in time series to the G-code format using an IP
conversion function. Since the G-code combines both the
printer mechanical and the object-related information, we
develop a G-code reconstruction algorithm (ALGORITHM
1) to derive the IP from the printer status set.
6. EVALUATION
In this section, we analyze the performance of the primi-
tive models and evaluate our method in the real-case study.
6.1 System Setup
As previously shown in Figure 8, the 3D printers we em-
ploy in this study are Ultimaker 2 Go, one of the most
used open-source 3D printers in the market [9]. Our ap-
proach is also compatible with other FDM-type 3D print-
ers, such as MakerBot Replicator [2] since they share the
same mechatronic architecture. The smartphone, Nexus 5
[1] is equipped with multiple built-in sensors, including mi-
crophone with Qualcomm WCD9320 audio codec [8] and
Asahi Kasei 3D Magnetometer Sensor AK8963 [6].
To collect the side-channel information, we implement a
data recording application with Android OS v6.01. The
smartphone is placed near the printer (within 20cm) to col-
lect the audio and magnetic data while the printer is work-
ing. Both the printer and the smartphone’s built-in sensor
have their own coordinates and conﬁgurations. Speciﬁcally,
the audio data is recorded in mono channel with a sampling
frequency of 44.1kHz and the encoding rate of 16 bit. The
magnetic data, on the other hand, is collected with a sam-
pling frequency of 100Hz in the unit of micro-Tesla (µT).
The conﬁguration of the printing speed determines a trade-
oﬀ between the product yield and the time eﬃciency. Faster
printing speed can improve the time eﬃciency yet reduce
the product quality. In our work, we aim to ensure the high
quality of printed product. Therefore, we set the nozzle
printing speed as 180 mm/min and the alignment speed as
7800 mm/min.
6.2 Quantitative Accuracy Analysis
In this part, we address the concerns in two aspects: 1)
What is the performance of each primitive operation model?
2) What is the performance variation of each model with
diﬀerent parameter settings?
6.2.1 Primitive Operation Models
We ﬁrst apply Savitzky-Golay ﬁlter on the side-channel
data and segment the signal into separate frames with a
ﬁxed frame size of 200 ms. Then we partition the operation
frames into the training and testing set according to diﬀerent
models. Figure 12 shows the classiﬁcation results.
Figure 12(a) is Layer Movement Model, which determines
whether the printer prints in the X-Y plane or moves the
platform in the Z axis. The training set involves 2000 mag-
netic frames in each category and the testing set includes
4000 magnetic frames in total. The model can diﬀerenti-
ate the two operations with an average accuracy of 99.92%.
The mechanical diﬀerence in two sets of actuation system
provides rich operation information in the acoustic data.
Figure 12(b) is Head Movement Model, which detects
whether the nozzle is printing or aligning in the X-Y plane.
Speciﬁcally, acoustic side channel is utilized in the model
training. The training and testing set both contain 1000 au-
dio frames (half in each type). The result shows that 95.7%
and 96.1% of the testing data are correctly classiﬁed in each
group. As a result, we can infer whether the machine ex-
trudes material in each timestamp.
Figure 12(c) is Axial Movement Model, which is used to
predict whether the nozzle moves along the X or Y axis. The
training set involves 2000 magnetic and audio frames of the
X and Y axial movement (half in each direction) respectively.
Afterwards, we veriﬁes the model with 4000 testing frames.
The confusion matrix indicates that the overall accuracy of
the model reaches 93.55%.
Figure 12(d)(e) are X and Y Directional Movement Model
respectively. In one axis, we train the corresponding model
upon 1000 magnetic frames for each direction (2000 in total).
We validate the performance by applying the model on the
test set of 4000 frames. The confusion matrix shows that
the model correctly classiﬁes the moving direction of 90.55%
frames in the X axis. Correspondingly, the accuracy in the
Y axis achieves 93.98%.
6.2.2 Model Performance and Frame Size
Frame size is an important factor that directly aﬀects the
performance of the models. Small frame size increases the
We introduce an error metric to evaluate the reconstruc-
tion performance in 3D printing attacks. The traditional
error metrics, such as Mean Square Error Metrics [16] and
Quadric Error Metrics [20], cannot quantify the true geomet-
ric error because these metrics consider each reconstructed
point independently and estimate the error according to the
absolute diﬀerence. In this case, local sparse outliers (e.g.,
a large error on a single segment) or global oﬀsets will bias
the entire quality value.
We argue that the error metric in 3D printing attack appli-
cations should reﬂect the global reconstruction quality and
estimate the error according to the relative distortions. For
example, the error from certain rigid transformation eﬀects,
such as translation, can be eliminated in the error metric be-
cause they will not alter the IP information. Therefore, we
propose the Mean Tendency Error (MTE), which assesses
the geometrical reconstruction based on the relative shape
diﬀerence. Speciﬁcally, MTE is a geometric similarity de-
scriptor that calculates the direction consistency between
the design pattern and reconstructed pattern. It is formu-
lated as:
(cid:80)n
i=2{|GXi − GXi−1) − (HXi − HXi−1)|
+|(GYi − GYi−1) − (HYi − HYi−1)|},
M T E = 1
n
(15)
where n is the number of sample points, GX, GY are the
reconstructed points and HX, HY are the original points.
MTE
Layer1 Layer2 Layer3 Layer4 Avg.
6.06%
4.57% 5.87%
7.12%
5.71%
Table 2: The MTE results of four layers when re-
constructing the regular design.
Table 2 shows the calculated MTE for each layer respec-
tively. The results range from 4.57% to 7.12%, with an av-
erage MTE of 5.87%. The low MTE over diﬀerent layers in-
dicates that the attack method can accurately and robustly
reconstruct the original design IP.
Figure 13: The accuracy results of the primitive op-
eration models in 3D printing with diﬀerent frame
sizes.
temporal resolution, enabling us to reconstruct the printing
process in ﬁne-grained detail. However, it will correspond-
ingly reduce the frequency resolution in spectral features,
which could eventually lower the classiﬁcation accuracy. As
a result, we explore the performance of the models under
diﬀerent frame sizes. As depicted in Figure 13, the perfor-
mance of the models gradually improve with the increase
of the frame size. Larger frame size means there are more
characteristic information contained in each frame, hence
the data frame will be more accurately deduced in the high
dimensional feature domain. Based on the performance ten-
dency showed in the graph, we select the frame size of 200
ms in our evaluation.
6.3 Real World Evaluation
Figure 14: The reconstructed shape based on the
magnetic-enhanced side-channel attack. The rect-
angle in red line is the designed shape in each layer.
The shape in black line is the reconstructed one.
To evaluate our approach upon the real printing scenario,
we ﬁrst select rectangle as a regular shape since it involves
all the primitive operations. Speciﬁcally, we generate a G-
code ﬁle for a four-layer object, each layer of which is a
90mm*90mm rectangle and in the height of 1mm. The re-
constructed shapes in each layer are depicted in Figure 14.
In each layer, the reconstructed shape ﬁts the original rect-
angle in general. There are outliers in the reconstructed ones
due to the mis-classiﬁcation in certain operations. Most out-
liers are in the Y axis. Such oﬀsets (e.g. in Layer 1, 3) are
generated by the mis-classiﬁcations in the previous X direc-
tional movements. This result is in coherence with the ob-
servation that the Y Directional Movement Model performs
better than the X Direction Movement Model (see Section
6.2.1).
(a) The original shape of
the complex design and the
reconstructed results of ten
layers.
(b) The result after ap-
plying Layer Smooth Al-
gorithm on all layers.
Figure 15: The demonstration of the reconstructed
IP on a complex design.
The real complex design usually contains free-form seg-
ments and inner structures (e.g., a hollow structure can lead
to multiple contours in the same layer), which traditional 3D
scanning cannot detect. Free-form segments can be repre-
sented by a series of motion primitives in X, Y and Z di-
rections. Inner structures can also be reconstructed by the
proposed method because it can recognize the alignment in
printing.
We test the attack approach on a complex shape. Specif-
ically, the designed object contains ten layers (layer height is
1mm) and the contour dimension in each layer is 90mm*45mm.
As shown in Figure 15(a), the original complex shape is col-
ored in red and the reconstructed result in each layer is plot-
ted in black. The triangle shape is reconstructed by a set
of primitive movements in X and Y. Overall, the shape drift
in the X axis is smaller than the one in the Y axis, which
means that the Y axis movements are better predicted. In
detail, the performance for X Directional Movement Model
and Y Directional Movement Model is 89.83% and 93.67%
in accuracy, respectively.
MTE
Layer5
Layer1 Layer2 Layer3 Layer4
8.36%
10.15%
8.77%
Layer6 Layer7 Layer8 Layer9 Layer10
8.97%
7.14%
MTE 15.87% 10.64%
8.35%
9.83%
8.64%
Table 3: Calculated MTE of each reconstructed
layer for the complex shape.
Algorithm 2 Layer Smooth Algorithm
Input: Layer: G-code for each layer in time series t =
1, ..., n L: Layer number
upon all layers in time series
Output: result: G-code of the smoothed layer contour
1: for t = 1 → n do: // in each time stamp
2:
3:
4: end for
5: result ⇐ [smoothX; smoothY ] //integrate the smooth
smoothXi = 1
L
smoothYi = 1
L
k=1 Layerk(x)
k=1 Layerk(y)
(cid:80)L
(cid:80)L
result
We can observe that most reconstructed layers are similar
to the original contour. The MTE results for the recon-
structed layers are calculated in Table 3. The mean MTE
upon the entire ten layers is 9.67%, with a standard devia-
tion of 2.40%. To address the variation between the layers,
we perform Layer Smooth Algorithm (ALGORITHM 2) to
adjust the contour outliers.
The post-processing result is displayed in Figure 15(b).
The algorithm well regulates the abnormal outliers in par-
ticular parts and generates a smooth contour similar to the
original shape. The real printed objects is exhibited in Fig-
ure 16.
6.4 Practice Enhancement
In this above setting, we keep the orientation of the smart-
phone in both the training and attacking scenarios. For
the sake of the attack feasibility, we explore a software so-
lution to grant the side-channel data with the orientation-
independent characteristics. With this approach, the train-
ing and attacking scenarios are not necessary to be per-
formed with the same smartphone orientation. Considering
the mono audio signal propagates in sphere and is naturally
independent of orientation, we focus on the magnetic side-
channel measures.
According to Euler’s rotation theorem [22], any rotation
of a rigid structure in three dimensions can be represented
as a combination of a vector (cid:126)u and a scalar θ. Speciﬁ-
cally, the rotation vector represents a rotation angle around
a speciﬁed axis and is usually encoded in the form of unit
quaternion [18, 33]. In Android OS, the rotation vector can
be derived from a combination of sensor data from 6-axis
accelerometer, 6-axis gyroscope (Invensense MPU-6515 [7])
and 3-axis magnetometer. The result is returned by sensor
service Sensor.T Y P E ROT AT ION V ECT OR. A typical
function, getQuaternionFromVector(), converts the rotation
vector to a normalized quaternion. Therefore, the rotation
matrix R can be calculated as:
 a2 + b2 − c2 − d2
2bc + 2ad
2bd − 2ac
2bc − 2ad
a2 − b2 + c2 − d2
2cd + 2ab
2bd + 2ac
2cd − 2ab
a2 − b2 − c2 + d2
(16)
 ,
where normalized quaternion q is:
q = a + bx + cy + dz,|q| = 1.
(17)
Therefore, by applying the rotation matrix R upon the mag-
netic data in smartphone-frame orientation, we can achieve
the orientation-independent data in world-frame orientation:
magDatarot−f ree = R ∗ magDataoriginal.
(18)
To evaluate the orientation-independent solution, we em-
ploy diﬀerent rotation angles and record the normalized quater-
nion q, which remains constant when the smartphone is
placed in a particular orientation. The converted magnetic
data in each axis is calculated based on the equations above.
38.0156
37.7480
37.9613
38.2078
10.0244
10.2021
10.2554
10.1768
Angle Mean M agx Mean M agy Mean M agz
−51.7069
0◦
−52.0877
30◦
−51.3041
60◦
−52.3945
90◦
Var. M agz
Angle Var. M agx
0◦
−0.74%
30◦
−0.78%
60◦
90◦
+1.33%
Var. M agy
−0.70%
−0.14%
+0.51%
+1.77%
+2.3%
+1.52%
–
–
–
(a) The original designed
complex shape.
(b) The replicated object
based on the smoothed re-
construction result.
Figure 16: The real demonstration of the original
design and the replicated one based on the recon-
structed IP.
Table 4: The converted magnetic data with diﬀerent
rotation angles.
As shown in Table 4, the converted magnetic data re-
mains stable in each axis while the smartphone’s orienta-
tion changes. The average variations are +1.87%, −0.11%,
+0.43% respectively in each axis. In this way, we are able to
achieve the orientation-independent magnetic data regard-
less of the smartphone rotation.
7. DISCUSSION
In this section, we discuss the current limitations and then
describe the future work.
Distance Eﬀect: Attack eﬀectiveness highly depends on
the side-channel range. Compared to the acoustic side chan-
nel, the eﬀective magnetic side channel diminishes much
faster (∝ 1
r3 ). We evaluate the attack eﬀectiveness with
three diﬀerent distance setups, i.e., 20cm, 30cm and 40cm,
respectively. Reconstruction results are shown in Table 5.