(b) Decompiled snippets for outputs of Debin.
Figure 4: Debin predicts the statically linked library functions setsockopt, sendto and open. Identifying such functions helps
in finding potentially unsecure I/O operations.
for such sensitive names in the output of Debin and quickly de-
cide where security issues may be located. We demonstrate the
usefulness of searching for sensitive names in Section 5.4.
Training and Prediction Speed. The training phase for name
and type prediction lasts about five hours for each architecture:
around four hours to train two ET classification models (one for
registers and another for memory offsets), and one hour to train
the CRF model with the pseudo likelihood learning algorithm. We
used 60 threads to run the learning algorithms. The average predic-
tion time for every binary (with one thread) is about two minutes
where around 80% is spent on variable recovery, and 20% is spent
on running our analysis to construct the dependency graph and
perform MAP inference over this graph. A possible future work
item would be to increase the efficiency of the variable recovery
module.
5.4 Malware Inspection
We now discuss how Debin can be helpful for the task of inspecting
behaviors of malicious binaries. Using VirusShare [9], we then
search for around 180 categories of Linux malwares defined by
Symantec [52] and tried to download the latest 10 fully stripped
ELF x86 malwares for each category. Since there are usually less
than 10 qualified malwares for most categories, our test dataset
consists of 35 binaries over 13 categories ranging from 5.0KB to
1.7MB. We provide the malware binaries as input to Debin, whose
models are trained on benign binaries as already discussed above,
and search for security-related names in the outputs. Note that we
cannot report Debin’s accuracy on malwares because they are all
stripped and contain no debug information. The original malwares
and output binaries of Debin are further decompiled into Pseudo
C code with the popular Hex-Rays decompiler in IDA Pro [3]. We
then manually insepct the decompiled outputs. An example for
how Debin reveals a DNS resolver reader was already shown in
Section 1. We next report another use case where Debin can be
helpful in identifying suspicious statically linked library functions.
Identifying Suspicious Statically Linked Library Uses. Mali-
cious binaries are often compiled statically and stripped to hide
library function uses. In our malware dataset, 26 out of 35 sam-
ples are statically built. While library usages are a crucial part
for identifying malicious behaviors, it would be tedious and time-
consuming for analysts to manually inspect assembly code and
rename them. During our inspection, we found that Debin can be
helpful with finding potentially harmful library uses (as it automat-
ically renames them). In Figure 4, we show code snippets where
Debin renames suspicious library calls for two malware exam-
ples (one5 of category Linux.Xorddos and another6 of category
Linux.Mirai). In the first snippet, Debin recovers setsockopt
and sendto, which indicates potential leakage of sensitive data. In
the second snippet, Debin reveals sensitive behavior of opening the
file "/proc/net/tcp", which stores active IPv4 TCP connections.
Apart from our examples, Debin can also recover other library
calls, such as string manipulations. Library function renaming can
greatly reduce efforts for security analysts to examine malware.
Debin is able to rename these library functions likely due to their
existence (either statically or dynamically linked) in the training
set.
Limitations. With our probabilistic models, Debin learns pat-
terns of binary code from our training binaries, which we assume
are benign. However, malicious binaries often exhibit more complex
behaviors than benign ones. For example, we found samples in our
malware dataset that use customized string encoding. Obfuscation
techniques such as control flow flattening may also be performed to
hinder analysis. Debin may make less accurate predictions on ob-
fuscated binaries. Security analysts could combine de-obfuscation
methods with Debin to tackle these issues.
6 RELATED WORK
We survey some of the works that are most closely related to ours.
Comparison with Existing Approaches.
In Table 6, we com-
pare Debin with several existing approaches in terms of capabilities.
For variable recovery, DIVINE [13], TIE [38] and SecondWrite [23]
employ a static analysis algorithm called Value Set Analysis [12],
while Debin, to our best knowledge, is the first to use a learning-
based classifier. For type recovery, TIE and SecondWrite adopt
constraint-based type inference. Eklavya learns a Recurrent Neu-
ral Network to predict 7 types for function arguments, while Debin
5SHA1: 3f1f4ba2434d0ad07838ebc694ad4a4cf8c9641a.
6SHA1: 5ab78c427e1901adf38ade73b8414340f86b6227.
Approach
DIVINE [13]
TIE [38]
SecondWrite [23]
Eklavya [20]
Debin
Variable
Recovery Recovery Prediction Based
Name
Type
Learning Architectures
✓
✓
✓
✗
✓
✗
✓
✓
partial1
✓
✗
✗
✗
✗
✓
✗
✗
✗
✓
✓
Supported
x86
x86
x86
x86, x64
x86, x64, ARM
1 Eklavya only predicts 7 types for function arguments.
Table 6: Comparison of Debin against existing approaches
for recovering variable or type information from binaries.
is capable of predicting 17 types for both function arguments and
variables. Moreover, Debin is also the first system capable of re-
covering names, a desirable functionality for decompilation and
important for malware inspection. We remark that it is difficult to
compare Debin and those works quantitatively because they have
different prediction granularity, benchmarks and measurements.
Binary Analysis. To perform binary analysis, usually the first
step is to choose an analysis platform that translates assembly
code into a corresponding IR (thereby abstracting the semantics of
various instruction sets). Potential open source candidates for per-
forming this task are BAP [17], Mcsema [4] and angr.io [50]. They
lift binary code into BAP-IR, LLVM-IR and VEX-IR, respectively.
A recent framework, rev.ng [25], can recover control flow graphs
and function boundaries for binaries over multiple architectures.
Kim et al. [35] tested a wide range of binary analysis frameworks
on different tasks. For Debin, we currently choose BAP-IR for the
advantages discussed in Section 4.1. An interesting future work
item is to experiment with our learning-based techniques using
other frameworks.
There is a wide range of literature on extracting semantic infor-
mation from binaries. Apart from the ones discussed above, IDA
FLIRT [3] and UNSTRIP [30] identify library functions by gener-
ating fingerprints for them. However, their approaches are not
capable of suggesting names for other functions.
Machine Learning for Binaries. Machine learning methods
have been adopted for different binary analysis tasks. Several works
focus on function identification [14, 49, 54], which is the basis for
many further analysis steps. We adopt ByteWeight [14] in our sys-
tem since it is publicly available in BAP [17]. Chua et al. [20] train
a Recurrent Neural Network to predict function argument counts
and types. Statistical language models [33, 34] have been employed
to predict types in binaries, but with rather different focus on object
types and class hierarchy reconstruction.
Apart from recovering source-level information from binaries,
there are also several works that predict other valuable character-
istics. Rosenblum et al. [46] focus on toolchain provenance. Their
work predicts compiler family and version, optimization level and
programming language with high accuracy. Caliskan et al. [19]
build an effective set of features and utilizes a random forest classi-
fier to predict programmer identity.
There are other works that utilize machine learning to classify
malware [11, 36, 48] and research that adopts statistical methods to
calculate binary similarity [21, 22, 55]. Those tasks are complemen-
tary to the problem addressed in this work and can benefit from
the recovered names and types.
Probabilistic Models for Code.
In recent years, the development
of large codebases has triggered studies of probabilistic models for
software related tasks such as code summarization [26], method
and class name suggestions [10], code completion [45], program
synthesis [42, 43] and programming language translation [32].
From this set of works, the ones most related to us are [44] and
[15]. Their tools also leverage structured prediction algorithms
with Nice2Predict [5] so to infer types and names for Javascript
and Android programs, respectively. Our work differs from these
approaches in that it works on lower-level binary code, which is
inherently a more difficult task. Therefore, we need to first perform
variable recovery that classifies the program elements used for
structured prediction, while these works use a fixed set of rules.
We also support more expressive feature functions, i.e., not only
pairwise kinds but also richer factors relating multiple elements.
Further, these methods only work on a single high-level language
(e.g., Java, JavaScript). In the context of binary analysis however,
our probabilistic models work on low-level code across multiple
architectures and compilation settings, in turn dictating a more
general and richer classes of features. Finally, our work utilizes
one model to jointly predict names and types while [44] uses two
separate models (one to predict names and another to predict types).
The work of [15] only uses one model to predict names for Android.
A Statistical Machine Translation model is employed to suggest
identifier names for Javascript [53] and decompiled code [31]. While
the latter is close to our work, its model only achieved around 25%
accuracy. Further, their method relies on decompilation, which al-
ready suffers from great information loss. Our prediction directly
works on binary code, achieves higher accuracy and shows success-
ful cases on decompilation tasks.
7 CONCLUSION
We presented a novel approach for predicting debug information
in stripped binaries. The key idea is to formalize the problem as
a machine learning task and to leverage a combination of two
complementary probabilistic models: an Extremely Randomized
Trees classifier and structured prediction with Conditional Random
Fields. To instantiate the idea, we introduced a comprehensive set of
features suitable for the task of predicting binary debug information,
and used this set to train our probabilistic models on a large number
of non-stripped binaries.
The resulting system, called Debin, uses these probabilistic mod-
els to recover debug information of new, unseen binaries. Our ex-
tensive experimental evaluation of Debin indicates the approach is
accurate enough to correctly infer large portions of stripped debug
information and is helpful for practical security analysis.
ACKNOWLEDGMENTS
We would like to thank the anonymous reviewers for their con-
structive feedback and Rong Jian for the helpful discussions on
malware inspection.
REFERENCES
[1] 2018. Debug Symbol Packages. https://wiki.ubuntu.com/Debug%20Symbol%
20Packages
[2] 2018. ELFIO. http://elfio.sourceforge.net/.
[3] 2018. IDA Pro. https://www.hex-rays.com/.
[4] 2018. Mcsema. https://github.com/trailofbits/mcsema.
[5] 2018. Nice2Predict. http://nice2predict.org/.
[6] 2018. pyelftools. https://github.com/eliben/pyelftools.
[7] 2018. scikit-learn. http://scikit-learn.org.
[8] 2018. The DWARF Debugging Standard. http://dwarfstd.org/.
[9] 2018. VirusShare. https://virusshare.com/.
[10] Miltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles A. Sutton. 2015.
Suggesting accurate method and class names. In Proceedings of Foundations of
Software Engineering (ESEC/FSE). pages 38–49.
[11] Ben Athiwaratkun and Jack W. Stokes. 2017. Malware classification with LSTM
and GRU language models and a character-level CNN. In Proceedings of Inter-
national Conference on Acoustics, Speech and Signal Processing (ICASSP). pages
2482–2486.
[12] Gogul Balakrishnan and Thomas W. Reps. 2004. Analyzing Memory Accesses in
x86 Executables. In Proceedings of Compiler Construction (CC). pages 5–23.
[13] Gogul Balakrishnan and Thomas W. Reps. 2007. DIVINE: DIscovering Vari-
ables IN Executables. In Proceedings of Verification, Model Checking, and Abstract
Interpretation (VMCAI). pages 1–28.
[14] Tiffany Bao, Jonathan Burket, Maverick Woo, Rafael Turner, and David Brumley.
2014. BYTEWEIGHT: Learning to Recognize Functions in Binary Code. In
Proceedings of USENIX Security Symposium. pages 845–860.
[15] Benjamin Bichsel, Veselin Raychev, Petar Tsankov, and Martin Vechev. 2016.
Statistical Deobfuscation of Android Applications. In Proceedings of Computer
and Communications Security (CCS). pages 343–355.
[16] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32.
[17] David Brumley, Ivan Jager, Thanassis Avgerinos, and Edward J. Schwartz. 2011.
BAP: A Binary Analysis Platform. In Proceedings of Computer Aided Verification
(CAV). pages 463–469.
[18] David Brumley, JongHyup Lee, Edward J. Schwartz, and Maverick Woo. 2013.
Native x86 Decompilation Using Semantics-Preserving Structural Analysis and
Iterative Control-Flow Structuring. In Proceedings of USENIX Security Symposium.
pages 353–368.
[19] Aylin Caliskan, Fabian Yamaguchi, Edwin Dauber, Richard Harang, Konrad Rieck,
Rachel Greenstadt, and Arvind Narayanan. 2018. When Coding Style Survives
Compilation: De-anonymizing Programmers from Executable Binaries. In Pro-
ceedings of Network and Distributed System Security Symposium (NDSS).
[20] Zheng Leong Chua, Shiqi Shen, Prateek Saxena, and Zhenkai Liang. 2017. Neural
Nets Can Learn Function Type Signatures From Binaries. In Proceedings of USENIX
Security Symposium. pages 99–116.
[21] Yaniv David, Nimrod Partush, and Eran Yahav. 2016. Statistical similarity of
binaries. In Proceedings of Programming Language Design and Implementation
(PLDI). pages 266–280.
[22] Yaniv David, Nimrod Partush, and Eran Yahav. 2017. Similarity of binaries
through re-optimization. In Proceedings of Programming Language Design and
Implementation (PLDI). pages 79–94.
[23] Khaled Elwazeer, Kapil Anand, Aparna Kotha, Matthew Smithson, and Rajeev
Barua. 2013. Scalable variable and data type detection in a binary rewriter. In
Proceedings of Programming Language Design and Implementation (PLDI). pages
51–60.
[24] Sebastian Eschweiler, Khaled Yakdan, and Elmar Gerhards-Padilla. 2016. discovRE:
Efficient Cross-Architecture Identification of Bugs in Binary Code. In Proceedings
of Network and Distributed System Security Symposium (NDSS).
[25] Alessandro Di Federico, Mathias Payer, and Giovanni Agosta. 2017. rev.ng: a
unified binary analysis framework to recover CFGs and function boundaries. In
Proceedings of Compiler Construction (CC). pages 131–141.
[26] Jaroslav M. Fowkes, Pankajan Chanthirasegaran, Razvan Ranca, Miltiadis Al-
lamanis, Mirella Lapata, and Charles A. Sutton. 2017. Autofolding for Source
Code Summarization. IEEE Transactions on Software Engineering 43, 12 (2017),
1095–1109.
[27] Brendan Frey, Frank Kschischang, Hans-Andrea Loeliger, and Niclas Wiberg. 1997.
Factor graphs and algorithms. In Proceedings of the Annual Allerton Conference
on Communication Control and Computing. pages 666–680.
[28] Pierre Geurts, Damien Ernst, and Louis Wehenkel. 2006. Extremely randomized
trees. Machine Learning 63, 1 (2006), 3–42.
[29] Ilfak Guilfanov. 2008. Decompilers and beyond. In Black Hat USA.
[30] Emily R. Jacobson, Nathan E. Rosenblum, and Barton P. Miller. 2011. Labeling
library functions in stripped binaries. In Proceedings of workshop on Program
analysis for software tools (PASTE). pages 1–8.
[31] Alan Jaffe. 2017. Suggesting meaningful variable names for decompiled code: a
machin translation approach. In Proceedings of Foundations of Software Engineer-
ing (ESEC/FSE). pages 1050–1052.
[32] Svetoslav Karaivanov, Veselin Raychev, and Martin Vechev. 2014. Phrase-Based
Statistical Translation of Programming Languages. In Proceedings of International
Symposium on New Ideas, New Paradigms, and Reflections on Programming &
Software (Onward!). pages 173–184.
[33] Omer Katz, Ran El-Yaniv, and Eran Yahav. 2016. Estimating types in binaries
using predictive modeling. In Proceedings of Principles of Programming Languages
(POPL). pages 313–326.
[34] Omer Katz, Noam Rinetzky, and Eran Yahav. 2018. Statistical Reconstruction of
Class Hierarchies in Binaries. In Proceedings of Architectural Support for Program-
ming Languages and Operating Systems (ASPLOS). pages 363–376.
[35] Soomin Kim, Markus Faerevaag, Minkyu Jung, SeungIl Jung, DongYeop Oh,
JongHyup Lee, and Sang Kil Cha. 2017. Testing intermediate representations for
binary analysis. In Proceedings of Automated Software Engineering (ASE). pages
353–364.
[36] Bojan Kolosnjaji, Ghadir Eraisha, George D. Webster, Apostolis Zarras, and Clau-
dia Eckert. 2017. Empowering convolutional networks for malware classification
and analysis. In Proceedings of International Joint Conference on Neural Networks
(IJCNN). pages 3838–3845.
[37] John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Con-
ditional Random Fields: Probabilistic Models for Segmenting and Labeling Se-
quence Data. In Proceedings of International Conference on Machine Learning
(ICML). pages 282–289.
[38] JongHyup Lee, Thanassis Avgerinos, and David Brumley. 2011. TIE: Principled
Reverse Engineering of Types in Binary Programs. In Proceedings of Network and
Distributed System Security Symposium (NDSS).
[39] Beng Heng Ng and Atul Prakash. 2013. Expose: Discovering Potential Binary
Code Re-use. In Proceedings of Computer Software and Applications Conference
(COMPSAC). pages 492–501.
[40] Jannik Pewny, Felix Schuster, Lukas Bernhard, Thorsten Holz, and Christian
Rossow. 2014. Leveraging semantic signatures for bug search in binary programs.
In Proceedings of Annual Computer Security Applications Conference (ACSAC).
pages 406–415.
[41] Igor V. Popov, Saumya K. Debray, and Gregory R. Andrews. 2007. Binary Obfus-
cation Using Signals. In Proceedings of USENIX Security Symposium.
[42] Veselin Raychev, Pavol Bielik, and Martin Vechev. 2017. Program Synthesis for
Character Level Language Modeling. In Procceedings of International Conference
on Learning Representations (ICLR).
[43] Veselin Raychev, Pavol Bielik, Martin Vechev, and Andreas Krause. 2016. Learning
programs from noisy data. In Proceedings of Principles of Programming Languages
(POPL). pages 761–774.
[44] Veselin Raychev, Martin Vechev, and Andreas Krause. 2015. Predicting Program
Properties from "Big Code". In Proceedings of Principles of Programming Languages
(POPL). pages 111–124.
[45] Veselin Raychev, Martin Vechev, and Eran Yahav. 2014. Code completion with
statistical language models. In Proceedings of Programming Language Design and
Implementation (PLDI). pages 419–428.
[46] Nathan E. Rosenblum, Barton P. Miller, and Xiaojin Zhu. 2011. Recovering the
toolchain provenance of binary code. In Proceedings of International Symposium
on Software Testing and Analysis (ISSTA). pages 100–110.
[47] Andreas Sæbjørnsen, Jeremiah Willcock, Thomas Panas, Daniel J. Quinlan, and
Zhendong Su. 2009. Detecting code clones in binary executables. In Proceedings of
International Symposium on Software Testing and Analysis (ISSTA). pages 117–128.
[48] Matthew G. Schultz, Eleazar Eskin, Erez Zadok, and Salvatore J. Stolfo. 2001. Data
Mining Methods for Detection of New Malicious Executables. In Proceedings of
IEEE Symposium on Security and Privacy (S&P). pages 38–49.
[49] Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi. 2015. Recognizing
Functions in Binaries with Neural Networks. In Proceedings of USENIX Security
Symposium. pages 611–626.
[50] Yan Shoshitaishvili, Ruoyu Wang, Christopher Salls, Nick Stephens, Mario Polino,
Andrew Dutcher, John Grosen, Siji Feng, Christophe Hauser, Christopher Krügel,
and Giovanni Vigna. 2016. SOK: (State of) The Art of War: Offensive Techniques
in Binary Analysis. In Proceedings of IEEE Symposium on Security and Privacy
(S&P). pages 138–157.
[51] Charles Sutton and Andrew McCallum. 2012. An Introduction to Conditional
Random Fields. Foundations and Trends in Machine Learning 4, 4 (2012), 267–373.
[52] Symantec Coporation. 2018. A-Z Listing of Threats & Risks. https://www.
symantec.com/security-center/a-z.
[53] Bogdan Vasilescu, Casey Casalnuovo, and Premkumar T. Devanbu. 2017. Re-
covering clear, natural identifiers from obfuscated JS names. In Proceedings of
Foundations of Software Engineering (ESEC/FSE). pages 683–693.
[54] Shuai Wang, Pei Wang, and Dinghao Wu. 2017. Semantics-Aware Machine Learn-
ing for Function Recognition in Binary Code. In Proceedings of IEEE International
Conference on Software Maintenance and Evolution (ICSME). pages 388–398.
[55] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 2017.
Neural Network-based Graph Embedding for Cross-Platform Binary Code Simi-
larity Detection. In Proceedings of Computer and Communications Security (CCS).
pages 363–376.