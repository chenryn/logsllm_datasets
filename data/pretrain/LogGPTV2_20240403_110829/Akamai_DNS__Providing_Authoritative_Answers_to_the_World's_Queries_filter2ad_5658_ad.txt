gradually. Queries originating from sources not in the allowlist are
assigned a penalty, de-prioritizing them further.
3) Random Subdomain[52]: This unique attack deserves spe-
cial attention because of how common it is and its ability to “pass-
through” resolvers. By randomizing the hostname in each query and
sending the query to resolvers, an attacker can force extremely low
cache hit rates in resolvers, causing the resolvers – including ones
on the allowlist – to send a high volume of queries to Akamai DNS.
Because the traffic originates from resolvers, the above described
filters are ineffective as the rate limiting filter is equally likely to
Figure 10: Percent legitimate queries answered with & with-
out NXDOMAIN filter.
assign a penalty for a legitimate query as a random subdomain
attack query from the same resolver.
To combat this class of attacks, our query scoring module uses
the NXDOMAIN filter that exploits the fact that the random host-
names4 used in attack do not exist, resulting in an NXDOMAIN
response. Thus, during a random subdomain attack, early identifi-
cation of queries that will result in an NXDOMAIN response and
filtering them can potentially mitigate the attack. Legitimate traffic
is unlikely to be penalized by this filter as NXDOMAIN responses
are rare in legitimate traffic, accounting for only ∼0.5% of the DNS
responses Akamai DNS typically returns.
The NXDOMAIN filter functions by tracking NXDOMAIN re-
sponses per zone and if the count exceeds a threshold, the filter
builds a tree of all valid hostnames in the zones above the thresh-
old. Queries for hostnames in the zones that are not present in the
tree are assigned a penalty score. An alternate approach is to build
a tree from all zones, rather than just those zones that exceed a
threshold number of NXDOMAINs. However, this approach results
in a tree that is much larger and updating such a tree results in
greater contention due to locking.
We use a testbed comprised of two machines connected via
a switch to demonstrate the effectiveness of query scoring and
prioritization. We focus on the NXDOMAIN filter. The other filters
described in this section behave similarly when applied to the
attack traffic that they are designed to mitigate. One machine in
the testbed acts as the source of DNS query traffic while the other
is a nameserver. From the source, we drive both legitimate traffic
sampled from observed production traffic and attack traffic where
the hostnames are selected from a test domain prepended with
a random string. The legitimate traffic is set at a fixed rate of L
queries/sec while the attack rate of A queries/sec is ramped up
over time. Figure 10 shows the percentage of the legitimate traffic
answered versus the attack rate A and has three regions of interest.
In the first region where A ≤ A1, the cumulative query rate A +
L is smaller than the processing capacity of the nameserver, so
all legitimate queries are answered with or without the filter. In
the second region A1  A2, we
reach the I/O capacity of the nameserver machine. The nameserver
software is unable to read queries off of the network stack as fast
as they arrive causing drops below the application layer of both
legitimate and attack queries. These results demonstrate that the
NXDOMAIN filter can effectively increase the cumulative rate that
the nameserver can handle before dropping legitimate queries.
4) Spoofed Source IP: A modification of direct query attacks
occurs when attackers spoof the source IP address, both hiding the
origins of the attack and enabling the use of many more source
IP addresses than physical machines. The rate limit filter quickly
becomes ineffective due to the large set of source IPs an attacker
is likely to use, while the allowlist filter remains effective. But,
an attacker may intelligently spoof IP addresses to impersonate
known resolvers (e.g. Google Public DNS[18]), including ones on
the allowlist, causing allowlist filtering to also be ineffective.
To combat this class of attacks, we use the well-established tech-
nique of hop-count filtering [22]. The hopcount filter learns the IP
TTL of DNS queries for resolvers on the allowlist using historical
data. When the IP TTL of a DNS query diverges from the expected
value, the query is assigned a penalty score. We observe in the DNS
traffic arriving at our nameservers that the IP TTL is consistent per
source IP address, with only 12% of source IP addresses showing any
variation in IP TTL over one hour and 4.7% ever varying by more
than ±1. On the other hand, when an attacker spoofs a resolver IP
address from a different topological location than that resolver, it
is likely that the spoofed query will arrive at the nameserver with
a different IP TTL.
5) Spoofed Source IP & IP TTL: Further enhancing the pre-
vious attack, we hypothesize that an attacker can spoof both the
source IP address and IP TTL of allowlisted resolvers. This implies
that the attacker knows the number of hops from the allowlisted
resolver to Akamai DNS. To combat this sophisticated attack, the
query scoring module contains a loyalty filter. Each nameserver in-
dependently tracks the resolvers that historically send DNS queries
to it. Recall the use of anycast for our nameservers and that each
resolver is routed to a PoP via BGP. Thus, allowlisted resolvers only
appear in the loyalty filter of nameservers to which the allowlisted
resolver is routed. When a nameserver receives a query from a
resolver that is not in the loyalty filter, the query is assigned a
penalty score. Thus, the attacker must not only spoof the source
IP address and IP TTL but also be routed to the same PoP as the
allowlisted resolver in order for the attack traffic to not be filtered.
Further, since the resolvers that drive the most DNS queries to
nameservers are consistent over several days (Figure 4), they will
with high probability be in the loyalty filter.
Discussion. Mitigating attacks by shifting the resolver traffic
via traffic engineering actions such as those described in §4.3.2
can negate the efficacy of filters that rely on leveraging historical
traffic patterns. In such a situation, the filters described here do not
differentiate between legitimate and attack traffic in the worst-case,
and our work-conserving query processing attempts to answer all
queries (§4.3.3). This is one reason why the preferred action during
an attack is to take no action.
While all of the mechanisms described above can together effec-
tively mitigate a wide range of attacks, we recognize that there is
still the possibility of an attack that cannot be distinguished from
legitimate traffic. Such a “perfect” attack would have to mimic legiti-
mate traffic so well that the likelihood of its occurrence is extremely
low, yet extremely costly. Thus, Akamai DNS is designed for this
event, by overprovisioning both bandwidth and compute, and by
compartmentalizing the infrastructure as described in §4.3.1.
5 DNS PERFORMANCE
While resiliency of Akamai DNS is critical due to its role in the
Internet ecosystem, its performance is also important. A significant
fraction of requests for Internet content and services start with a
query to Akamai DNS, so it is critical that Akamai DNS provides
answers with low latency.
5.1 Anycast Performance Tuning
Because Akamai DNS uses anycast routing, BGP path selection
plays an important part in performance. All 24 anycast clouds are
advertised from PoPs spread around the globe, so that there is
always a geographically nearby PoP for any resolver to provide
low RTT DNS resolutions for all 24 clouds. However, ensuring
that the route to the nearest PoP is selected by BGP is non-trivial
and requires significant engineering as well as communication
with our peers to align our routing policies. Common practice in
anycast optimization is to ensure that the peering links at PoPs
consist of the same major providers [55] and that the advertisements
from those PoPs appear identical upstream. We use these common
practices to select which PoPs should advertise which of our 24
anycast clouds and modify our BGP advertisements per peer to
achieve similarity. Recent work on modeling anycast catchments
[49], measuring performance [16], and automated configuration
of advertisements [30] help. However, today anycast optimization
remains a challenging and operationally time-consuming task. One
that we view deserves further study.
5.2 Two-Tier Delegation System
Akamai DNS is the entry point for the Akamai CDN, as each con-
tent request to the CDN is prefaced by a DNS query to Akamai DNS.
To accelerate DNS resolutions for the CDN, Akamai DNS uses the
Two-Tier delegation system. Continuing the example from §3.1, the
zone “akamai.net” is delegated to 13 anycast clouds, called toplevels
in Two-Tier context. From the toplevels, the zone “w10.akamai.net”
is delegated to a set of unicast lowlevel nameservers co-located
with the wide CDN footprint. The Akamai mapping system [11, 36]
tailors the set of lowlevel delegations to be near the resolver issuing
the query. The CDN hostnames use very low TTLs – currently 20
seconds – to enable quick reaction to changing network conditions
and edge server liveness. So, the resolvers’ cache must be frequently
refreshed. The lowlevels provide rapid responses to queries for CDN
hostnames, minimizing the cost of refreshes. The delegation from
toplevel to lowlevel has a large TTL – currently 4000 seconds –
so that resolvers need to refresh the lowlevel delegation set in-
frequently, Thus, the majority of resolutions occur between the
resolver and the lowlevels.
474
Akamai DNS
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
The Two-Tier system accrues two separate advantages over a
single-tier of IP anycast toplevels. First, the Two-Tier system is
able to utilize lowlevel nameservers deployed with the CDN’s edge,
including those in co-location sites where it is not possible to in-
ject eBGP route advertisements, and hence not usable for IP any-
cast. Second, in the Two-Tier system, Akamai is able to route re-
quests from resolvers to a proximal nameserver using its mapping
system[11, 36], often achieving lower RTTs than anycast.
We now develop an analytical model of Two-Tier and use it to
measure the performance impact of Two-Tier in isolation from
other components of DNS performance. The performance achieved
by Two-Tier depends upon the resolvers’ cache state and the RTTs
between the resolver and the lowlevels/toplevels. Consider the reso-
lution of “a1.w10.akamai.net” and let L be the RTT to the lowlevels
and T be the RTT to the toplevels5. If the resolver has the A/AAAA
records for “a1.w10.akamai.net” in cache, there is no need to contact
any authoritative nameservers and the resolution takes no time.
There is no performance impact to using Two-Tier in this case.
However, if “a1.w10.akamai.net” is not in cache but the NS records
(and associated A/AAAA records) for “w10.akamai.net” are cached,
then the resolver must only contact the lowlevels and the resolution
time is L msec. If the records for “w10.akamai.net” are not cached,
then the resolver must contact the toplevels first, resolution time
L + T msec. We define rT as the fraction of DNS resolutions that
require contacting the toplevels, the value of which depends upon
many factors including (i) the TTLs of the NS/A/AAAA records in-
volved and (ii) the frequency and inter-arrival times of DNS queries
from end-users to the resolver for Akamai CDN hostnames. Thus,
we can calculate the average resolution time using Two-Tier and
find the speedup over answering from the single-tier of toplevels
as:
T
S =
(1 − rT ) · L + rT · (L + T)
(1)
When S > 1 , Two-Tier reduces resolution time on average in
comparison to answering directly from the single-tier of toplevels.
Intuitively, Two-Tier is most beneficial when rT is small – the
resolver has to consult the toplevels infrequently – and the differ-
ence between T and L is large – the resolver has a shorter RTT to
lowlevels than to toplevels.
Measuring T & L: We use RIPE Atlas [41] to measure T and
L, scheduling DNS measurements on 1,663 probes, selected with
1 probe per ASN/country combination. The DNS measurements
instruct the probes to send a query directly from the probe to the
toplevel delegations and lowlevel delegations. For the toplevels, we
configure the measurement target as one of the toplevel anycast
addresses. For the lowlevels, the measurement target should be
the unicast address of a lowlevel tailored to be near the probe. We
achieve this by setting the measurement target to the hostname of
one of the unicast lowlevel delegations, and using the “Resolve on
Probe” option [42], causing the probe to look up the hostname using
the probe’s resolver first. The experiment ran for one month with
hourly measurements and we compute the median RTT against
each toplevel and lowlevel delegation, and use the per delegation
RTTs to compute T and L as follows. Research in [34, 44, 56] shows
5Note that both the toplevel and lowlevel delegation sets contain multiple IP addresses
and thus multiple RTTs. In this formulation, we assume an aggregate RTT is used and
discuss its computation below.
475
Figure 11: Speedup in average resolution time using Two-
Tier over a single-tier of toplevels.
a range of behaviors among resolvers in sending DNS queries to
delegations, from apparent uniformity to preferencing delegations
with lower RTT. The former is a best case scenario for Two-Tier as
toplevel delegation RTTs vary widely due to anycast routing, often
not coinciding with lowest RTT. Similarly, the latter is a worst sce-
nario for Two-Tier since the highest toplevel RTTs contribute less
to the aggregate. Per RIPE Atlas probe, we simulate both behaviors
to bound the expected RTT. For the former we calculate the average
RTT, while for the latter we assume that a resolver’s preference
for a nameserver is inversely proportional to the delegation RTT
and calculate the weighted RTT. The lowlevel RTT L is less than
the toplevel RTT T for 98% of the probes using the average RTT
and 87% of the probes using the weighted RTT. Thus, Akamai map-
ping reduces the RTT between the resolver and the authoritative
nameserver over the RTT of anycast routing for the majority of
probes.
Measuring rT : Next, we investigate values of rT using resolvers
in the wild. Collecting logs from toplevels and lowlevels over one
day, we compute the number of queries received per resolver IP
address by toplevels and lowlevels for the domain “w10.akamai.net”.
For each of the 575K resolver IP addresses in the dataset, the number
of queries received by toplevels divided by the number of queries
received by lowlevels provides an estimate of rT . The mean value
of rT is 0.48. However, as previously noted in §2, the distribution of
DNS queries among resolvers is highly skewed. So, when weighted
by the lowlevel DNS queries sent by the resolvers, the weighted
mean rT is only 0.008.
Results: Combining the RTT dataset from RIPE Atlas with the
traffic logs from resolvers in the wild, we calculate the value of S
(Eq. 1). As RIPE Atlas probes are not resolvers themselves, they do
not appear in the traffic logs and there is no direct way to merge
the datasets. Instead, we choose to combine all (T , L) and rT values
from both datasets to produce a collection of simulated resolvers
based upon our real world measurements. These simulated resolvers
cover a wide range of situations for resolvers, including situations
encountered by real-world resolvers and situations not at present
encountered by any real-world resolvers, while also missing some
situations that real-world resolvers may encounter. Figure 11 in the
lines “wgt RTT - R” and “avg RTT - R” shows CDFs of the speedup