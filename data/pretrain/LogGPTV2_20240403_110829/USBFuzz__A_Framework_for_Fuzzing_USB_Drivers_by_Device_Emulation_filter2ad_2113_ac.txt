### 5.3 Fuzzing Device

The fuzzing device is a crucial component of USBFuzz, enabling the fuzzing of the kernel's hardware input space. It is implemented as an emulated USB device within the QEMU device emulation framework, mimicking a malicious device controlled by an attacker in real-world scenarios.

Hypervisors intercept all read/write requests from the guest kernel to the device. Each read/write operation from the guest OS kernel is dispatched to a registered function in the emulated device implementation, which performs the necessary actions and returns data according to the hardware specification.

The fuzzing device is implemented by registering "read" functions that forward fuzzer-generated data to the kernel. Specifically, the bytes read by device drivers are sequentially mapped to the fuzzer-generated input, with the exception of device and configuration descriptors, which are handled separately (as discussed in § 4.1).

### 5.4 User Mode Agent

The user mode agent is designed to run as a daemon process in the guest OS and is automatically started when the target OS boots. It monitors the execution status of tests based on the kernel log and communicates this information to the fuzzer via the communication device. After initialization, it notifies the fuzzer that the target kernel is ready for testing.

On Linux and FreeBSD, the user mode agent monitors the kernel log file (`/dev/kmsg` in Linux, `/dev/klog` in FreeBSD) for error messages indicating a kernel bug or the end of a test. If such an event is detected, it notifies the fuzzer—using the device file exported to user space by the communication device driver—to stop the current iteration and proceed to the next one. The set of error messages is borrowed from the report package [44] of syzkaller. On Windows and MacOS, due to the lack of clear signals from the kernel when devices are attached/detached, the user mode agent uses a fixed timeout (1 second on MacOS and 5 seconds on Windows) to allow the device to initialize properly.

### 5.5 Adapting Linux kcov

To apply coverage-guided fuzzing to USB drivers in the Linux kernel, we use static instrumentation to collect coverage from the target kernel. This implementation is adapted from kcov [67], which is already supported by the Linux kernel, with the following modifications to accommodate our design:

```c
index = (hash(IP) ^ hash(prev_loc)) % BITMAP_SIZE;
bitmap[index]++;
prev_loc = IP;
```

**Listing 2: Instrumentation used in USBFuzz**

USBFuzz implements an AFL-style [72] edge coverage scheme by extending kcov. Our modification supports multiple paths of execution across multiple threads and interrupt handlers, untangling non-determinism. We save the previous block whenever non-determinism occurs. For processes, we save `prev_loc` (see Listing 2) in the `struct task` (the data structure for the process control block in the Linux kernel), and for interrupt handlers, we save `prev_loc` on the stack. Whenever non-determinism happens, the current previous location is spilled (in the `struct task` for kernel threads, or on the stack for interrupt handlers) and set to a well-defined location in the coverage map, untangling non-determinism to specific locations. When execution resumes, the spilled `prev_loc` is restored. This careful design allows us to track the execution of interrupts (and nested interrupts) and separate their coverage without polluting the coverage map through false updates.

The instrumented code is modified to write the coverage information to the memory area of the communication device instead of the per-process buffer. The Linux build system is also modified to limit the instrumentation to only the code of interest. In our evaluation, we restrict coverage tracking to anything related to the USB subsystem, including drivers for both host controllers and devices.

### 6 Evaluation

We evaluate various aspects of USBFuzz. First, we perform an extensive evaluation of our coverage-guided fuzzing implementation on the USB framework and its device drivers (broad fuzzing) in the Linux kernel. Section 6.1 presents the discovered bugs, and Section 6.3 provides a performance analysis. Second, we compare USBFuzz to the usb-fuzzer extension of syzkaller based on code coverage and bug discovery capabilities (Section 6.2). In Section 6.4, we demonstrate the flexibility of USBFuzz by fuzzing (i) USB drivers in FreeBSD, MacOS, and Windows (broad fuzzing); and (ii) a webcam driver (focused fuzzing). Finally, we showcase one of the discovered bugs in the USB core framework of the Linux kernel (Section 6.5).

#### Hardware and Software Environment

Our evaluation is conducted on a small cluster where each of the four nodes runs Ubuntu 16.04 LTS with a KVM hypervisor. Each node is equipped with 32 GB of memory and an Intel i7-6700K processor with Intel VT [20] support.

#### Guest OS Preparation

For evaluating FreeBSD, Windows, and MacOS, we use VM images with unmodified kernels and a user mode agent component running in userspace. When evaluating Linux, the target kernel is built with the following customizations: (i) we adapt kcov as mentioned in Section 5.5; (ii) we configure all USB drivers as built-in; (iii) we enable Kernel Address Sanitizer (KASAN) [25, 26] to improve bug detection capability. At runtime, to detect abnormal behavior triggered by the tests, we configure the kernel to panic in case of "oops" or print warnings by customizing kernel parameters [62].

#### Seed Preparation

To start fuzzing, we create a set of USB device descriptors as seeds. We leverage the set of expected identifiers (of devices, vendors, products, and protocols) and matching rules of supported devices that syzkaller [16] extracted from the Linux kernel [64]. A script converts the data into a set of files containing device and configuration descriptors as fuzzing seeds.

### 6.1 Bug Finding

To demonstrate the ability of USBFuzz to find bugs, we ran USBFuzz on nine recent versions of the Linux kernel: v4.14.81, v4.15, v4.16, v4.17, v4.18.19, v4.19, v4.19.1, v4.19.2, and v4.20-rc2 (the latest version at the time of evaluation). Each version was fuzzed with four instances for approximately four weeks (reaching, on average, about 2.8 million executions) using our small fuzzing cluster.

Table 1 summarizes all the bugs USBFuzz found in our evaluation. In total, 47 unique bugs were found. Of these, 36 are memory bugs detected by KASAN [25], including double-free (2), NULL pointer dereference (8), general protection error (6), out-of-bounds memory access (6), and use-after-free (14). Sixteen of these memory bugs are new and have never been reported. The remaining 20 memory bugs were previously reported and used as part of our ground truth testing. Memory bugs detected by KASAN are serious and may potentially be used to launch attacks. For example, NULL pointer dereference bugs lead to a crash, resulting in denial of service. Other types of memory violations, such as use-after-free, out-of-bounds read/write, and double frees, can be used to compromise the system through a code execution attack or to leak information. We discuss one of our discovered memory bugs and analyze its security impact in detail in our case study in Section 6.5.

The remaining 11 bugs (WARNING, BUG) are caused by the execution of (potentially) dangerous statements (e.g., assertion errors) in the kernel, which usually represent unexpected kernel states. The impact of such bugs is hard to evaluate in general without a case-by-case study. However, providing a witness of such bugs enables developers to reproduce and assess their impact.

#### Bug Disclosure

We are working with the Linux and Android security teams to disclose and fix all discovered vulnerabilities, focusing first on the memory bugs. Table 2 shows the 11 new memory bugs that we have fixed so far. These new bugs were dispersed in different USB subsystems (USB Core, USB Sound, or USB Network) or individual device drivers. From these 11 new bugs, we have received 10 CVEs. The remaining bugs fall into two classes: those still under embargo/being disclosed and those that were concurrently found and reported by other researchers. Note that our approach of also supplying patches for the discovered bugs reduces the burden on the kernel developers when fixing the reported vulnerabilities.

### 6.2 Comparison with syzkaller

Due to challenges in porting the kernel-internal components of syzkaller, we had to use a version of the Linux kernel that is supported by syzkaller. We settled on version v5.5.0 [17], as it is maintained by the syzkaller developers. In this version, many of the reported USB vulnerabilities had already been fixed. Note that USBFuzz does not require any kernel components and supports all recent Linux kernels, simplifying porting and maintenance. In this syzkaller comparison, we evaluate coverage and bug-finding effectiveness, running five 3-day campaigns of both USBFuzz and syzkaller.

#### Bug Finding

In this heavily patched version of the Linux kernel, USBFuzz found one bug in each run within the first day, and syzkaller found three different bugs (two runs found two, and three runs found three). The bug USBFuzz found is a new bug that triggers a `BUG_ON` statement in a USB camera driver [32]. The bugs found by syzkaller trigger `WARNING` statements in different USB drivers.

#### Code Coverage

We collected accumulated code coverage in the USB-related code (including the USB core framework, host controller drivers, gadget subsystem, and other device drivers) by replaying inputs generated from both fuzzers. The line, function, and branch coverage of five runs are shown in Table 3. Overall, syzkaller outperforms USBFuzz in maximizing code coverage. We attribute the better coverage to the manual analysis of the kernel code and custom tailoring the individual generated USB messages to the different USB drivers and protocols. The manual effort results in messages adhering more closely to the standard [55]—at a high engineering cost.

Table 3 shows that both syzkaller and USBFuzz only triggered limited code coverage. There are three reasons: (i) some drivers are not tested at all; (ii) some code (function routines) can be triggered only by operations from userspace and are thus not covered; (iii) some host controller drivers can only be covered with a specific emulated host controller.

Figure 4 demonstrates the differences between USBFuzz and syzkaller. First, syzkaller triggered zero coverage in the host controller drivers. This is because syzkaller uses a USB gadget and a software host controller (dummy HCD) while USBFuzz leverages an emulated USB device to feed fuzzer-generated inputs to drivers. Though syzkaller may find bugs in the USB gadget subsystem, which is only used in embedded systems as firmware of USB devices and not deployed on PCs, it cannot find bugs in host controller drivers. We show a bug found in the XHCI driver in our extended evaluation in Section 6.4.

Syzkaller achieves better overall coverage for device drivers due to the large amount of individual test cases that are fine-tuned. These syzkaller test cases can be reused for focused, per-device fuzzing in USBFuzz to extend coverage. USBFuzz achieves better coverage in the USB core, which contains common routines for handling data from the device side. This is caused by the difference in the input generation engines of the two fuzzers. As a generational fuzzer, syzkaller’s input generation engine always generates valid values for some data fields, thus prohibiting it from finding bugs triggered by inputs that violate the expected values in these fields. USBFuzz, on the other hand, generates inputs triggering such code paths. Note that the driver in which USBFuzz found a bug was previously tested by syzkaller. However, as the inputs it generated are well-formed, the bug was missed. We show an example of this in Section 6.5.

In summary, syzkaller leverages manual engineering to improve input generation for specific targets but misses bugs that are not standard-compliant or outside of where the input is fed into the system. USBFuzz follows an out-of-the-box approach where data is fed into the unmodified subsystem, allowing it to trigger broader bugs. These two systems are therefore complementary and find different types of bugs and should be used concurrently. As future work, we want to test the combination of the input generation engines, sharing seeds between the two.

### 6.3 Performance Analysis

To assess the performance of USBFuzz, we evaluate execution speed and analyze the time spent in different fuzzing phases.

#### Fuzzing Throughput

Figure 5(a) shows the execution speed of USBFuzz over a sampled period of 50 hours while running on Linux 4.16. The figure demonstrates that USBFuzz achieves a fuzzing throughput ranging from 0.1–2.6 exec/sec, much lower than that of userspace fuzzers, where the same hardware setup achieves up to thousands of executions per second. Note that the low fuzzing throughput in this scenario is mostly not caused by USBFuzz, as tests on USB drivers run much longer than userspace programs. For example, our experiment with physical USB devices shows that it takes more than 4 seconds to fully recognize a USB flash drive on a physical machine. A similar throughput (0.1–2.5 exec/sec) is observed in syzkaller and shown in Figure 5(b).

#### Overhead Breakdown

To quantify the time spent for each executed test and to evaluate possible improvements in fuzzing throughput, we performed an in-depth investigation on the time spent at each stage of a test. As mentioned in Section 5, a test is divided into three stages: (i) virtually attaching the fuzzing device to the VM; (ii) test execution; and (iii) detaching the fuzzing device. We measure the time used for attaching/detaching and the time used in running a test when device drivers perform I/O operations. The result is shown in Figure 7. The blue line and red line show the time used in the attaching/detaching and test execution stages, respectively.