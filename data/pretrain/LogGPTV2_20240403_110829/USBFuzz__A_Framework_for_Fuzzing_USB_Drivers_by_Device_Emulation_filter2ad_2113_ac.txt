is received from the control pipe. When execution status
information is received from the user mode agent via the com-
munication device, the other callback detaches the fuzzing
device from the hypervisor and forwards execution status
information to the fuzzer via the status pipe.
5.3 Fuzzing Device
The fuzzing device is the key component in USBFuzz that
enables fuzzing of the hardware input space of the kernel. It
is implemented as an emulated USB device in the QEMU de-
vice emulation framework and mimics an attacker-controlled
malicious device in real-world scenarios.
Hypervisors intercept all device read/write requests from
the guest kernel. Every read/write operation from the kernel
of the guest OS is dispatched to a registered function in the
emulated device implementation, which performs actions and
returns data to the kernel following the hardware speciﬁcation.
The fuzzing device is implemented by registering “read”
functions which forward the fuzzer-generated data to the ker-
nel. To be more speciﬁc, the bytes read by device drivers
are mapped sequentially to the fuzzer-generated input, except
the device and conﬁguration descriptors, which are handled
separately (as mentioned in § 4.1).
5.4 User Mode Agent
The user mode agent is designed to be run as a daemon process
in the guest OS and is automatically started when the target
OS boots up. It monitors the execution status of tests based
on the kernel log and passes information to the fuzzer via
the communication device. After initialization, it notiﬁes the
fuzzer that the target kernel is ready to be tested.
On Linux and FreeBSD, our user mode agent component
monitors the kernel log ﬁle (/dev/kmsg in Linux, /dev/klog
in FreeBSD), and scans it for error messages indicating a ker-
nel bug or end of a test. If either event is detected, it notiﬁes
the fuzzer—using the device ﬁle exported to user space by
the communication device driver—to stop the current itera-
tion and proceed to the next one. The set of error messages
is borrowed from the report package [44] of syzkaller. On
Windows and MacOS, due to the lack of a clear signal from
the kernel when devices are attached/detached, our user mode
agent uses a ﬁxed timeout (1 second on MacOS and 5 seconds
on Windows) to let the device properly initialize.
5.5 Adapting Linux kcov
To apply coverage-guided fuzzing on USB drivers for the
Linux kernel, we use static instrumentation to collect coverage
from the target kernel. The implementation is adapted from
kcov [67] which is already supported by the Linux kernel
with the following modiﬁcations to accommodate our design.
1
2
3
index = ( hash ( IP ) ^ hash ( prev_loc ))% BITMAP_SIZE ;
bitmap [ index ] ++;
prev_loc = IP ;
Listing 2: Instrumentation used in USBFuzz
USBFuzz implements an AFL-style [72] edge coverage
scheme by extending kcov. Our modiﬁcation supports multi-
ple paths of execution across multiple threads and interrupt
handlers, untangling non-determinism. We save the previous
block whenever non-determinism happens. For processes, we
save prev_loc (see Listing 2) in the struct task (the data
structure for the process control block in the Linux kernel),
and for interrupt handlers we save prev_loc on the stack.
Whenever non-determinism happens, the current previous lo-
cation is spilled (in the struct task for kernel threads, or
on the stack for interrupt handlers) and set to a well-deﬁned
location in the coverage map, untangling non-determinism
to speciﬁc locations. When execution resumes, the spilled
prev_loc is restored. Note that this careful design allows
us to keep track of the execution of interrupts (and nested
interrupts) and separates their coverage without polluting the
coverage map through false updates.
The instrumented code is modiﬁed to write the coverage
information to the memory area of the communication device,
instead of the per-process buffer. The Linux build system is
modiﬁed to limit the instrumentation to only code of interest.
In our evaluation, we restrict coverage tracking to anything
related to the USB subsystem, including drivers for both host
controllers and devices.
6 Evaluation
We evaluate various aspects of USBFuzz. First, we perform
an extensive evaluation of our coverage-guided fuzzing im-
plementation on the USB framework and its device drivers
(broad fuzzing) in the Linux kernel. § 6.1 presents the dis-
covered bugs, and § 6.3 presents the performance analysis.
Second, we compare USBFuzz to the usb-fuzzer extension
2566    29th USENIX Security Symposium
USENIX Association
of syzkaller based on code coverage and bug discovery ca-
pabilities (§ 6.2). In § 6.4, we demonstrate the ﬂexibility of
USBFuzz by fuzzing (i) USB drivers in FreeBSD, MacOS,
and Windows (broad fuzzing); and (ii) a webcam driver (fo-
cused fuzzing). Finally, we showcase one of the discovered
bugs in the USB core framework of the Linux kernel (§ 6.5).
Hardware and Software Environment. We execute our
evaluation on a small cluster in which each of the four nodes
runs Ubuntu 16.04 LTS with a KVM hypervisor. Each node
is equipped with 32 GB of memory and an Intel i7-6700K
processor with Intel VT [20] support.
Guest OS Preparation. To evaluate FreeBSD, Windows,
and MacOS, we use VM images with unmodiﬁed kernels and
a user mode agent component running in userspace. When
evaluating Linux, the target kernel is built with the following
customization: (i) we adapt kcov as mentioned in § 5.5; (ii)
we conﬁgure all USB drivers as built-in; (iii) we enable kernel
address sanitizer (KASAN) [25, 26] to improve bug detection
capability. At runtime, to detect abnormal behavior triggered
by the tests, we conﬁgure the kernel to panic in case of “oops”
or print warnings by customizing kernel parameters [62].
Seed Preparation. To start fuzzing, we create a set of USB
device descriptors as seeds. We leverage the set of expected
identiﬁers (of devices, vendors, products, and protocols) and
matching rules of supported devices that syzkaller [16] ex-
tracted from the Linux kernel [64]. A script converts the data
into a set of ﬁles containing device and conﬁguration descrip-
tors as fuzzing seeds.
6.1 Bug Finding
To show the ability of USBFuzz to ﬁnd bugs, we ran USBFuzz
on 9 recent versions of the Linux kernel: v4.14.81, v4.15,
v4.16, v4.17, v4.18.19, v4.19, v4.19.1, v4.19.2, and v4.20-rc2
(the latest version at the time of evaluation). Each version was
fuzzed with four instances for roughly four weeks (reaching,
on average, approximately 2.8 million executions) using our
small fuzzing cluster.
Table 1 summarizes all of the bugs USBFuzz found in our
evaluation. In total, 47 unique bugs were found. Of these 47
bugs, 36 are memory bugs detected by KASAN [25], includ-
ing double-free (2), NULL pointer dereference (8), general
protection error (6), out-of-bounds memory access (6), and
use-after-free (14). 16 of these memory bugs are new and have
never been reported. The remaining 20 memory bugs were
reported before, and so we used them as part of our ground
truth testing. Memory bugs detected by KASAN are serious
and may potentially be used to launch attacks. For example,
NULL pointer dereference bugs lead to a crash, resulting in
denial of service. Other types of memory violations such as
use-after-free, out-of-bounds read/write, and double frees can
be used to compromise the system through a code execution
attack or to leak information. We discuss one of our discov-
ered memory bugs and analyze its security impact in detail in
Type
Memory Bugs (36)
Unexpected state
reached (11)
Bug Symptom
double-free
NULL pointer dereference
general protection
slab-out-of-bounds access
use-after-free access
WARNING
BUG
#
2
8
6
6
14
9
2
Table 1: Bug Classiﬁcation
our case study in § 6.5.
The remaining 11 bugs (WARNING, BUG) are caused by
execution of (potentially) dangerous statements (e.g., asser-
tion errors) in the kernel, which usually represent unexpected
kernel states, a situation that developers may be aware of but
that is not yet properly handled. The impact of such bugs is
hard to evaluate in general without a case-by-case study. How-
ever, providing a witness of such bugs enables developers to
reproduce these bugs and to assess their impact.
Bug Disclosure. We are working with the Linux and An-
droid security teams on disclosing and ﬁxing all discovered
vulnerabilities, focusing ﬁrst on the memory bugs. Table 2
shows the 11 new memory bugs that we ﬁxed so far. These
new bugs were dispersed in different USB subsystems (USB
Core, USB Sound, or USB Network) or individual device
drivers. From these 11 new bugs, we have received 10 CVEs.
The remaining bugs fall into two classes: those still under em-
bargo/being disclosed and those that were concurrently found
and reported by other researchers. Note that our approach
of also supplying patches for the discovered bugs reduces
the burden on the kernel developers when ﬁxing the reported
vulnerabilities.
6.2 Comparison with syzkaller
Due to challenges in porting the kernel-internal components
of syzkaller, we had to use a version of the Linux kernel that
is supported by syzkaller. We settled on version v5.5.0 [17],
as it is maintained by the syzkaller developers. In this version,
many of the reported USB vulnerabilities had already been
ﬁxed. Note that USBFuzz does not require any kernel com-
ponents and supports all recent Linux kernels, simplifying
porting and maintenance. In this syzkaller comparison we
evaluate coverage and bug ﬁnding effectiveness, running ﬁve
3-day campaigns of both USBFuzz and syzkaller.
Bug Finding. In this heavily patched version of the Linux
kernel, USBFuzz found 1 bug in each run within the ﬁrst day
and syzkaller found 3 different bugs (2 runs found 2, 3 runs
found 3). The bug USBFuzz found is a new bug that triggers
a BUG_ON statement in a USB camera driver [32]. The bugs
found by syzkaller trigger WARNING statements in different
USB drivers.
USENIX Association
29th USENIX Security Symposium    2567
Kernel Subsystem Conﬁrmed Version
Kernel bug summary
4.14.81 - 4.20-rc2
USB Core
KASAN: SOOB Read in __usb_get_extra_descriptor
4.14.81 - 4.20-rc2
USB Sound
KASAN: UAF Write in usb_audio_probe
4.14.81 - 4.20-rc2
USB Sound
KASAN: SOOB Read in build_audio_procunit
USB Sound
4.14.81 - 4.18
KASAN: SOOB Read in parse_audio_input_terminal
4.14.81 - 4.20-rc2
USB Sound
KASAN: SOOB Read in parse_audio_mixer_unit
4.14.81 - 4.20-rc2
USB Sound
KASAN: SOOB Read in create_composite_quirks
4.14.81 - 4.20-rc2
USB Sound
KASAN: SOOB Write in check_input_term
USB Network
4.14.81 - 4.20-rc2
KASAN: SOOB Read in hso_get_conﬁg_data
4.14.81 - 4.20-rc2
KASAN: NULL deref in ath{6kl,10k}_usb_alloc_urb_from_pipe Device Driver
4.14.81 - 4.17
Device Driver
KASAN: SOOB Read in lan78xx_probe
KASAN: double free in rsi_91x_deinit
Device Driver
4.17 - 4.20-rc2
Fixed











Table 2: USBFuzz’s new memory bugs in 9 recent Linux kernels (SOOB: slab-out-of-bounds, UAF: use-after-free) that we ﬁxed.
syzkaller
USBFuzz
Line (%)
18,039 (4.5)
10,325 (2.5)
Function (%) Branch (%)
7,259 (3.2)
4,564 (2.0)
1,324 (5.6)
813 (3.5)
Table 3: Comparison of line, function, and branch coverage
in the Linux kernel between syzkaller and USBFuzz. The
results are shown as the average of 5 runs.
Code Coverage. We collected accumulated code coverage
in the USB related code (including the USB core framework,
host controller drivers, gadget subsystem, and other device
drivers) by replaying inputs generated from both fuzzers. The
line, function, and branch coverage of 5 runs are shown in
Table 3. Overall, syzkaller outperforms USBFuzz on maxi-
mizing code coverage. We attribute the better coverage to the
manual analysis of the kernel code and custom tailoring the in-
Figure 4: Comparison of line coverage between syzkaller and
USBFuzz in USB Core, host controller drivers, gadget
subsystem, and other device drivers.
dividual generated USB messages to the different USB drivers
and protocols. The manual effort results in messages adhering
more closely to the standard [55]—at a high engineering cost.
Table 3 shows that both syzkaller and USBFuzz only trig-
gered limited code coverage. There are three reasons: (i) some
drivers are not tested at all; (ii) some code (function routines)
can be triggered only by operations from userspace, and are
thus not covered; (iii) some host controller drivers can only
be covered with a speciﬁc emulated host controller.
Figure 4 demonstrates the differences between USBFuzz
and syzkaller. First, syzkaller triggered zero coverage in the
host controller drivers. This is because syzkaller uses a USB
gadget and a software host controller (dummy HCD) while
USBFuzz leverages an emulated USB device to feed fuzzer
generated inputs to drivers. Though syzkaller may ﬁnd bugs in
the USB gadget subsystem, which is only used in embedded
systems as ﬁrmware of USB devices and not deployed on
PCs, it cannot ﬁnd bugs in host controller drivers. We show a
bug found in XHCI driver in our extended evaluation in § 6.4.
Syzkaller achieves better overall coverage for device drivers
due to the large amount of individual test cases that are ﬁne-
tuned. These syzkaller test cases can be reused for focused,
per device fuzzing in USBFuzz to extend coverage. USBFuzz
achieves better coverage in USB core, which contains com-
mon routines for handling data from the device side. This is
caused by the difference in the input generation engines of
the two fuzzers. As a generational fuzzer, syzkaller’s input
generation engine always generates valid values for some
data ﬁelds, thus prohibiting it from ﬁnding bugs triggered by
inputs that violate the expected values in these ﬁelds. USB-
Fuzz, on the other hand, generates inputs triggering such code
paths. Note that the driver in which USBFuzz found a bug
was previously tested by syzkaller. However, as the inputs it
generated are well-formed, the bug was missed. We show an
example of this in § 6.5.
In summary, syzkaller leverages manual engineering to
improve input generation for speciﬁc targets but misses bugs
that are not standard compliant or outside of where the input
2568    29th USENIX Security Symposium
USENIX Association
1300014000syzkallerUSBFuzzCoreHostGadgetDevice Drivers020004000is fed into the system. USBFuzz follows an out-of-the box
approach where data is fed into the unmodiﬁed subsystem,
allowing it to trigger broader bugs. These two systems are
therefore complementary and ﬁnd different types of bugs and
should be used concurrently. As future work, we want to test
the combination of the input generation engines, sharing seeds
between the two.
6.3 Performance Analysis
To assess the performance of USBFuzz we evaluate execution
speed and analyse time spent in different fuzzing phases.
Fuzzing Throughput. Figure 5(a) shows the execution
speed of USBFuzz in a sampled period of 50 hours while run-
ning on Linux 4.16. The ﬁgure demonstrates that USBFuzz
achieves a fuzzing throughput ranging from 0.1–2.6 exec/sec,
much lower than that of userspace fuzzers where the same
hardware setup achieves up to thousands of executions per
second. Note the low fuzzing throughput in this scenario is
mostly not caused by USBFuzz, because tests on USB drivers
run much longer than userspace programs. E.g., our experi-
ment with physical USB devices shows that it takes more than
4 seconds to fully recognize a USB ﬂash drive on a physical
machine. A similar throughput (0.1–2.5 exec/sec) is observed
in syzkaller and shown in Figure 5(b).
(a) A sample of execution speed of USBFuzz
(b) A sample of execution speed of syzkaller
Figure 5: Comparison of execution speed between USBFuzz
(0.1–2.6 exec/sec) and syzkaller (0.1- 2.5 exec/sec).
Figure 6: Cumulative distribution of test run time, collected
by tracing the inputs generated by USBFuzz.
Overhead Breakdown. To quantify the time spent for
each executed test, and to evaluate possible improvements
in fuzzing throughput, we performed an in-depth investiga-
tion on the time spent at each stage of a test. As mentioned
in § 5, a test is divided into 3 stages, (i) virtually attaching
the fuzzing device to the VM; (ii) test execution; and (iii)
detaching the fuzzing device. We measure the time used for
attaching/detaching, and the time used in running a test when
device drivers perform IO operations. The result is shown in
Figure 7. The blue line and red line show the time used in the