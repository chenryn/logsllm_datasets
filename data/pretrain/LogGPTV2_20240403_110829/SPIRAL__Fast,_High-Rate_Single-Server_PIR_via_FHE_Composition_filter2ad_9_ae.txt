the Chinese remainder theorem (CRT), Rq
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:41 UTC from IEEE Xplore.  Restrictions apply. 
10939
p
We implement arithmetic operations in Rα and Rβ using
native 64-bit arithmetic. We choose α, β = 1 mod 2d so Zα
and Zβ have a subgroup of size 2d (i.e., the (2d)th roots
of unity). Polynomial multiplication in Rα and Rβ can be
efﬁciently implemented using a standard “nega-cyclic” fast
Fourier transform (also called the number-theoretic transform
(NTT)) [48, 49]. To allow faster modular reduction, we also
choose α, β to be of the form 2i − 2j + 1 for integers i, j
where 2i > 2j > 2d.
Database representation. Database elements in our system
are elements of Rn×n
. We represent all ring elements in their
evaluation representation (i.e., the FFT/NTT representation).
This enables faster homomorphic operations during query
processing.
SIMD operations. Like previous constructions [23], we take
advantage of the Intel Advanced Vector Extensions (AVX) to
∼=
accelerate arithmetic operations in Rα and Rβ (recall Rq
Rα × Rβ). In particular, we use the AVX2 and AVX-512
instructions when computing the scalar multiplications and
homomorphic additions for the ﬁrst dimension processing in
Construction IV.1.
Code. Our implementation consists of roughly 4,000 lines of
C++.6 We adapt the procedure from the SEAL homomorphic
encryption library [50] to implement the FFTs for homomorphic
evaluation. We use the Intel HEXL library [51] to implement
FFTs in the response decoding procedures.
Experimental setup. We compare our PIR protocol against
the public implementations of SealPIR [5], FastPIR [22],
and OnionPIR [23]. Since the memory requirements vary
between protocols, we use an implicit representation of the
database across all of our measurements to ensure a consistent
comparison. To minimize any variance in running time due
to cache accesses, we set the minimal size of the implicitly-
represented database to be 1 GB. Based on our measurements,
using this implicit database representation only has a small
effect on the measurements (at most a 1% difference in server
compute time).
We measure the performance of our system on an Amazon
EC2 c5n.2xlarge instance running Ubuntu 20.04. The
machine has 8 vCPUs (Intel Xeon Platinum 8124M @ 3
GHz) and 21 GB of RAM. We use the same benchmarking
environment for all experiments, and compile all of the systems
using Clang 12. The processor supports the AVX2 and AVX-
512 instruction sets, and we enable SIMD instruction set
support for all systems. We use a single-threaded execution
for all of our experiments and report running times averaged
over a minimum of 5 trials.
Metrics. For each database conﬁguration, we measure the total
computation and communication for the client and the server,
as well as the size of the public parameters. Similar to previous
works [5, 23, 22], we assume the public parameters have been
generated and transmitted in a separate ofﬂine phase, and focus
exclusively on the online computation and communication.
6Our implementation is available here: https://github.com/menonsamir/spiral.
This is often justiﬁed since the public parameters only needs
to be generated once and can be reused for many PIR queries.
We also estimate the server’s monetary cost to respond to
a single query. This is the sum of the server’s CPU cost and
the cost of the network communication. We estimate these
costs based on the current rates for a long-term Amazon EC2
instance: $0.0195/CPU-hour and $0.09/GB of outbound trafﬁc
at the time of writing [52]. Finally, we report the rate of the
protocol (i.e., the ratio of the record size to the response size),
and the server’s throughput (i.e., the number of database bytes
the server can process each second). We generally do not report
the response-decoding times, since they are very small (Fig. 4).
C. Evaluation Results for SPIRAL
We start by comparing the performance of SPIRAL and
SPIRALSTREAM to existing systems on three different database
conﬁgurations in Table I:
• A database with many small records (220 records of size
256 B). This is a common baseline for PIR [4, 25, 22].
• A database with moderate-size records (218 records of size
30 KB). This is the optimal conﬁguration for OnionPIR [23].
• A database with a small number of large records (214 records
of size 100 KB).
When the record size is small, all of the lattice-based PIR
schemes have low rate. This is because lattice ciphertexts
encode a minimum of a few KB of data, so there is a signiﬁcant
amount of unused space for small records. When the record
size is comparable or greater than the amount of data that can
be packed into a lattice ciphertext, the rate essentially becomes
the inverse of the ciphertext expansion factor. Due to better
control of noise growth, the use of matrix Regev encodings, and
improved modulus switching, SPIRAL and SPIRALSTREAM
achieve a higher rate than previous implementations of single-
server PIR.
In all three settings, SPIRAL has the smallest query size.
For the databases with 30 KB and 100 KB records, SPIRAL’s
throughput is at least 2.2× higher than competing schemes
(while achieving a higher rate and smaller queries). In the small
record case, SPIRAL’s server throughput is only outperformed
by FastPIR, which is optimized for the streaming setting and
requires a query that is over 2400× larger. The main limitation
of SPIRAL is its larger public parameter size. This is due to
the additional keys needed for the query compression approach
from Section III. Note though that these public parameters are
reusable and the cost of communicating them can be amortized
over multiple queries.
Turning next to SPIRALSTREAM, we see that it achieves
a higher rate and server throughput compared to all previous
schemes. For instance, on the database with moderate-size
records, SPIRALSTREAM achieves a throughput of over 800
MB/s, which is 5.6× higher than the previous state-of-the-art;
SPIRALSTREAM simultaneously achieves a 2× increase in rate
as well. Measured in terms of monetary cost, SPIRALSTREAM
is 5.4× less expensive compared to OnionPIR for this database
conﬁguration. The trade-off is SPIRALSTREAM requires larger
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:41 UTC from IEEE Xplore.  Restrictions apply. 
11940
Database
220 × 256B
(268 MB)
218 × 30KB
(7.9 GB)
214 × 100KB
(1.6 GB)
Metric
Param. Size
Query Size
Response Size
Computation
Rate
Throughput
Server Cost
Query Size
Response Size
Computation
Rate
Throughput
Server Cost
Query Size
Response Size
Computation
Rate
Throughput
Server Cost
SealPIR
3 MB
66 KB
328 KB
3.19 s
0.0008
84 MB/s
$0.000047
66 KB
3 MB
74.91 s
0.0092
105 MB/s
$0.000701
66 KB
11 MB
19.03 s
0.0092
86 MB/s
$0.001076
FastPIR MulPIR* OnionPIR
1 MB
33 MB
66 KB
1.44 s
0.0039
186 MB/s
$0.000014
8 MB
262 KB
50.52 s
0.1144
156 MB/s
$0.000297
524 KB
721 KB
23.27 s
0.1387
70 MB/s
$0.000191
-
122 KB
119 KB
-
0.0024
-
-
-
-
-
-
-
-
-
-
-
-
-
-
5 MB
63 KB
127 KB
3.31 s
0.0020
81 MB/s
$0.000029
63 KB
127 KB
52.73 s
0.2363
149 MB/s
$0.000297
63 KB
508 KB
14.38 s
0.1969
114 MB/s
$0.000124
SPIRAL
14–18 MB
14 KB
21 KB
1.69 s
0.0122
159 MB/s
$0.000011
14 KB
84 KB
24.46 s
0.3573
322 MB/s
$0.000140
14 KB
242 KB
4.92 s
0.4129
333 MB/s
$0.000048
SPIRALSTREAM
344 KB–3 MB
8 MB
20 KB
0.85 s
0.0125
314 MB/s
$0.000006
15 MB
62 KB
8.99 s
0.4803
875 MB/s
$0.000054
8 MB
208 KB
2.38 s
0.4811
688 MB/s
$0.000032
∗ To date, there is not a public implementation of the MulPIR system. Here, we report the query and response sizes on a similar
database of size 220 × 288B from [25].
TABLE I: Comparison of SPIRAL and SPIRALSTREAM with recent PIR protocols (SealPIR [5], FastPIR [22], MulPIR [25],
OnionPIR [23]) on different database conﬁgurations. All measurements are collected on the same computing platform using a
single-threaded execution. SealPIR and OnionPIR provide 115 and 111 bits of security, respectively. All other schemes provide
at least 128 bits of security. The public parameter size (“Param. Size” column) for SPIRAL (and SPIRALSTREAM) varies
depending on database conﬁguration and we report the range here. The rate is the ratio of the record size to the response size,
the throughput is the ratio of the server’s computation time to database size, and the server cost is the estimated monetary cost
needed to process a single query based on current AWS prices (see Section V-B).
queries, though this is a less signiﬁcant factor in streaming
settings where the same query is reused across multiple
requests.
Packing. In Table II (Appendix D), we compare the packed ver-
sions of SPIRAL and SPIRALSTREAM with the vanilla versions
on each of the main benchmarks. As shown in Table II, packing
enables higher rates and throughput, but requires larger public
parameter for the packing keys (Section IV-A). For instance,
the size of the public parameters ranges from 14–18 MB for
SPIRAL and increases to 14–47 MB for SPIRALPACK. On
the ﬂip side, when considering larger databases, SPIRALPACK
achieves a 30% increase in the rate with comparable or higher
server throughput. If we consider the streaming variant (which
optimizes for throughput and rate at the expense of public
parameter size and query size), the packed variant achieves
substantially higher throughput compared to previous PIR
schemes and the other SPIRAL variants. On the larger databases,
SPIRALSTREAMPACK achieves 10× higher throughput com-
pared to previous systems (1.5 GB/s) and a 1.7× improvement
over the non-packed scheme SPIRALSTREAM.
System scaling. Fig. 3 shows how the server’s computation
time for different PIR schemes scales with the number of
records N in the database. When the database consists of
relatively small records (10 KB), SPIRAL achieves similar
performance as existing systems when the numbers of records
is small, but is up to 2× faster for databases with a million
records. When considering databases with larger records (100
KB), SPIRAL is always 1.8–3× faster for all choices of N
we considered. The server computation time of SPIRALPACK
is generally comparable to that of SPIRAL. Packing is most
beneﬁcial when the number of records is large; in these
cases SPIRALPACK achieves up to a 1.5× reduction in server
computation time. As we discuss next, packing makes the most
difference in the streaming setting.
Throughput in the streaming setting. As noted in Sec-
tion V-B, we also consider using PIR in a streaming setting,
where the same query is reused across multiple PIR invocations
(on different databases). In this case, query expansion only
needs to happen once and its cost can be amortized over the
lifetime of the stream. Thus, when considering the streaming
setting, we measure the server’s processing time without the
query expansion process. We apply the same methodology to
all SPIRAL variants, SealPIR, OnionPIR, and FastPIR. The
effective server throughput for different schemes is shown
in Fig. 5 and Table III (Appendix D). When choosing the
parameters for the streaming protocol variants SPIRALSTREAM
and SPIRALSTREAMPACK, we impose a maximum query
size of 33 MB to ensure a balanced comparison with the
FastPIR protocol [22] which have queries of the same size.
FastPIR is a PIR protocol tailored for the streaming setting that
leverages a large query size to achieve better server throughput.
We note that increasing the query size in SPIRALSTREAM
and SPIRALSTREAMPACK beyond 33 MB can enable further
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:41 UTC from IEEE Xplore.  Restrictions apply. 
12941
102
101
100
)
s
(
e
t