the true mapping. It appears likely that human intelli-
gence can be used to complete the de-anonymization
in many of these cases.
• 55% of
the incorrectly identiﬁed mappings (6.7%
overall) were mapped to nodes where the same geo-
graphic location was reported.5 Thus, even when re-
identiﬁcation does not succeed, the algorithm can often
identify a node as belonging to a cluster of similar
nodes, which might reveal sensitive information (recall
the discussion in Section 4.4).
• The above two categories overlap; of all the incorrect
mappings, only 27% (or 3.3% overall) fall into neither
category and are completely erroneous.
7. Conclusion
The main lesson of this paper is that anonymity is not
sufﬁcient for privacy when dealing with social networks. We
developed a generic re-identiﬁcation algorithm and showed
that it can successfully de-anonymize several thousand users
in the anonymous graph of a popular microblogging ser-
vice (Twitter), using a completely different social network
(Flickr) as the source of auxiliary information.
Our experiments underestimate the extent of the privacy
risks of anonymized social networks. The overlap between
Twitter and Flickr membership at
the time of our data
collection was relatively small. Considering only the users
who supplied their names (about a third in either network),
24% of the names associated with Twitter accounts occur
in Flickr, while 5% of the names associated with Flickr ac-
counts occur in Twitter. Since human names are not unique,
this overestimates the overlap in membership. By contrast,
64% of Facebook users are also present on MySpace [58].
As social networks grow larger and include a greater frac-
tion of the population along with their relationships, the
overlap increases. Therefore, we expect that our algorithm
can achieve an even greater re-identiﬁcation rate on larger
networks.
5. This was measured by sampling 200 of the erroneous mappings and
using human analysis. We consider the geographical location to be the same
if it is either the same non-U.S. country, or the same U.S. state.
We demonstrated feasibility of successful re-identiﬁcation
based solely on the network topology and assuming that
the target graph is completely anonymized. In reality,
anonymized graphs are usually released with at
least
some attributes in their nodes and edges, making de-
anonymization even easier. Furthermore, any of the thou-
sands of third-party application developers for popular on-
line social networks, the dozens of advertising companies,
governments who have access to telephone call logs, and
anyone who can compile aggregated graphs of the form
described in Section 2 have access to auxiliary information
which is much richer than what we used in our experiments.
At the same time, an ever growing number of third parties
get access to sensitive social-network data in anonymized
form. These two trends appear to be headed for a collision
resulting in major privacy breaches, and any potential so-
lution would appear to necessitate a fundamental shift in
business models and practices and clearer privacy laws on
the subject of Personally Identiﬁable Information.
Acknowledgements. The ﬁrst author is grateful to Cynthia
Dwork for introducing him to the problem of anonymity
in social networks. Kamalika Chaudhuri deserves special
thanks for collaborating on an earlier unpublished work on
social network anonymity; some of the broader themes car-
ried over to this paper. Over the last year and a half, we have
had many interesting discussions with Ilya Mironov, Frank
McSherry, Dan Boneh, and many others. David Molnar’s
help in reviewing a draft of this paper is appreciated.
This material is based upon work supported in part by the
NSF grants IIS-0534198, CNS-0716158, and CNS-0746888.
References
[1] Add Health. Deductive disclosure. http://www.cpc.unc.edu/
projects/addhealth/data/dedisclosure, 2008.
[2] The National Longitudinal Study of Adolescent Health. http:
//www.cpc.unc.edu/projects/addhealth, 2008.
[3] A. Anagnostopoulos, R. Kumar, and M. Mahdian. Inﬂuence
and correlation in social networks. In KDD, 2008.
[4] C. Anderson. Social networking is a feature, not a des-
http://www.thelongtail.com/the long tail/2007/09/
tination.
social-networki.html, 2007.
[5] M. Anderson. Mining social connections. Adweek. http:
//tinyurl.com/6768nh, May 19 2008.
[6] M. Arrington. Don’t post the evidence unless it supports your
case. Techcrunch. http://tinyurl.com/6otok7, 2008.
[7] L. Backstrom, C. Dwork, and J. Kleinberg. Wherefore art
thou R3579X? Anonymized social networks, hidden patterns,
and structural steganography. In WWW, 2007.
[8] Norman T. Bailey. The Mathematical Theory of Infectious
Diseases (2nd edition). Hafner Press, 1975.
185
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
[9] A-L. Barab´asi and R. Albert. Emergence of scaling in random
[28] M. Granovetter. The strength of weak ties. American Journal
networks. Science, 286:509–512, 1999.
of Sociology, 78:1360–1382, 1983.
[10] P. Bearman, J. Moody, and K. Stovel. Chains of affection:
The structure of adolescent romantic and sexual networks.
American Journal of Sociology, 110(1):44–91, 2004.
[29] M. Granovetter. Economic action and social structure: The
problem of embeddedness. American Journal of Sociology,
91:481–510, 1985.
[11] P. Bonacich. Power and centrality: A family of measures.
American Journal of Sociology, 92(5):1170–1182, 1987.
[30] R. Gross, A. Acquisti, and H. Heinz. Information revelation
and privacy in online social networks. In WPES, 2005.
[12] A. Campan and T. Truta. A clustering approach for data and
structural anonymity in social networks. In PinKDD, 2008.
[31] S. Guha, K. Tang, and P. Francis. NOYB: Privacy in online
social networks. In WOSN, 2008.
[13] R. Carthy.
Will
IRSeeK have
chilling effect
http://www.techcrunch.com/2007/11/30/
on IRC chat?
[Note:
will-irseek-have-a-chilling-effect-on-irc-chat/, 2007.
A privacy outcry erupted over a search engine for (public)
IRC channels.].
a
[14] M. Chew, D. Balfanz, and B. Laurie. (Under)mining privacy
in social networks. In W2SP, 2008.
[15] S. Clifford. Web privacy on the radar in Congress. New York
Times. http://tinyurl.com/6l2tcw, Aug 10 2008.
[16] D. Crandall, D. Cosley, D. Huttenlocher, J. Kleinberg, and
Feedback effects between similarity and social
S. Suri.
inﬂuence in online communities. In KDD, 2008.
[17] H. D’Andrade. MySpace and Facebook plan to use personal
http://tinyurl.com/2yp7br,
data for “targeted advertising”.
2007.
[18] The DataPortability project. http://dataportability.org, 2008.
[32] Peter Haggett and Richard J. Chorley. Network analysis in
geography. Hodder & Stoughton, 1969.
[33] R. Hanneman and M. Riddle. Introduction to social network
http://www.
methods. Chapter 10: Centrality and power.
faculty.ucr.edu/∼hanneman/nettext/C10 Centrality.html,
2005.
[34] M. Hay, G. Miklau, D. Jensen, P. Weis, and S. Srivastava.
Anonymizing social networks. Technical Report 07-19, Uni-
versity of Massachusetts Amherst, 2007.
[35] B. Hayes. Connecting the dots: Can the tools of graph
theory and social-network studies unravel the next big plot?
American Scientist, 94(5):400–404, 2006.
[36] W. Hwang, T. Kim, M. Ramanathan, and A. Zhang. Bridging
centrality: Graph mining from element level to group level.
In KDD, 2008.
[37] T. Jagatic, N. Johnson, M. Jakobsson, and F. Menczer. Social
phishing. Commun. ACM, 50(10):94–100, 2007.
[19] R.I.M. Dunbar. Neocortex size as a constraint on group size
in primates. Journal of Human Evolution, 22:469–493, 1992.
[38] F. Kerschbaum and A. Schaad. Privacy-preserving social
network analysis for criminal investigations. In WPES, 2008.
[20] E. Eldon. VentureBeat: Adisn, another company that uses
social data to target ads, raises $1.6 million. http://tinyurl.
com/65lsd5, 2008.
[21] E. Eldon. VentureBeat: MediaSixDegrees targets ads using
social graph information. http://tinyurl.com/662q3o, 2008.
[39] A. Korolova, R. Motwani, S. Nabar, and Y. Xu. Link privacy
in social networks. In ICDE, 2008.
[40] G. Kossinets, J. Kleinberg, and D. Watts. The structure of
information pathways in a social communication network. In
KDD, 2008.
[22] European Parliament.
Directive 95/46/EC.
http:
//eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:
31995L0046:EN:HTML, 1995.
[41] M. Kurucz, A. Bencz´ur, K. Csalog´any, and L. Luk´acs. Spec-
In WebKDD/SNA-
tral clustering in telephone call graphs.
KDD, 2007.
[23] Facebook.
Facebook’s privacy policy.
http://www.new.
facebook.com/policy.php, 2007.
[24] A. Felt and D. Evans. Privacy protection for social networking
APIs. In W2SP, 2008.
[25] B. Fitzpatrick and D. Recordon. Thoughts on the social graph.
http://bradﬁtz.com/social-graph-problem/, 2007.
[26] D. Fono and K. Raynes-Goldie. Hyperfriends and beyond:
Friendship and social norms on LiveJournal.
In Internet
Research Annual Volume 4: Selected Papers from the Asso-
ciation of Internet Researchers Conference, 2007.
[42] R. Lambiotte, V. Blondel, C. de Kerchove, E. Huens,
C. Prieur, Z. Smoreda, and P. Van Dooren. Geographical
dispersal of mobile communication networks. http://arxiv.org/
abs/0802.2178, 2008.
[43] K. Lewis, J. Kaufman, M. Gonzales, A. Wimmer, and
N. Christakis. Tastes, ties, and time: a new social network
dataset using Facebook.com. Social Networks, 30:330–342,
2008. [Note: six research assistants were paid to download
friends-only information from Facebook].
[44] D. Liben-Nowell and J. Kleinberg.
The link prediction
problem for social networks. In CIKM, 2003.
[27] K. Frikken and P. Golle. Private social network analysis: How
[45] K. Liu and E. Terzi. Towards identity anonymization on
to assemble pieces of a graph privately. In WPES, 2006.
graphs. In SIGMOD, 2008.
186
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
[46] M. Lucas and N. Borisov. ﬂyByNight: Mitigating the privacy
risks of social networking. In WPES, 2008.
[47] M. McGlohon, L. Akoglu, and C. Faloutsos. Weighted graphs
In
and disconnected components: Patterns and a generator.
KDD, 2008.
[48] Medical News Today. WellNet launches online social net-
working program for health care coordination. http://www.
medicalnewstoday.com/articles/118628.php, 2008.
[49] Microformats. http://microformats.org, 2008.
[50] E. Mills. Facebook suspends app that permitted peephole.
http://news.cnet.com/8301-10784 3-9977762-7.html, 2008.
[51] A. Mislove, M. Marcon, K. Gummadi, P. Druschel, and
B. Bhattacharjee. Measurement and analysis of online social
networks. In IMC, 2007.
[52] C. Morrison. VentureBeat: Lotame raises $13M for customiz-
able social media ads. http://tinyurl.com/65pvux, 2008.
[53] A. Nanavati, S. Gurumurthy, G. Das, D. Chakraborty, K. Das-
gupta, S. Mukherjea, and A. Joshi. On the structural proper-
ties of massive telecom call graphs: ﬁndings and implications.
In CIKM, 2006.
[54] A. Narayanan and V. Shmatikov. Robust de-anonymization
of large sparse datasets. In S&P, 2008.
[55] N. O’Neill. Senate begins discussing privacy implications of
online advertising. http://tinyurl.com/5aqqhe, 2008.
[56] J.-P. Onnela, J. Saram¨aki, J. Hyv¨onen, G. Szab´o, D. Lazer,
K. Kaski, J. Kert´esz, and A.-L. Barab´asi. Structure and tie
strengths in mobile communication networks. http://arxiv.org/
abs/physics/0610104, 2006.
[57] OpenID. http://openid.net, 2008.
[58] A. Patriquin. Compete: Connecting the social graph: member
http://tinyurl.com/
overlap at OpenSocial and Facebook.
ynp7t4, 2007.
[59] Plaxo. Building an open social graph. http://www.plaxo.com/
info/opensocialgraph, 2007.
[60] B. Popescu, B. Crispo, and A. Tanenbaum. Safe and private
data sharing with Turtle: Friends team-up and beat the system.
In Cambridge Workshop on Security Protocols, 2004.
[61] D. Recordon.
Is SocialMedia overstepping Facebook’s
http://radar.oreilly.com/2008/07/
privacy
is-socialmedia-overstepping-fa.html, 2008.
line?
[65] E. Schonfeld.
ing spammers.
twitter-starts-blacklisting-spammers/, 2008.
starts blacklist-
Techcrunch: Twitter
http://www.techcrunch.com/2008/05/07/
[66] Georg Simmel.
Soziologie. Duncker & Humblot, 1908.
[Note: Simmel proposed a new and quantitative approach to
sociology, one that would fall under Social Network Analysis
in modern terms.].
[67] C. Soghoian. Widespread cell phone location snooping
by NSA? http://news.cnet.com/8301-13739 3-10030134-46.
html, 2008.
[68] Z. Stone, T. Zickler, and T. Darrell. Autotagging Facebook:
Social network context improves photo annotation. In Work-
shop on Internet Vision, 2008.
[69] L. Story. A company promises the deepest data mining
yet. New York Times. http://www.nytimes.com/2008/03/20/
business/media/20adcoside.html, Mar 20 2008.
[70] G. Swamynathan, C. Wilson, B. Boe, B. Zhao, and
K. Almeroth. Can social networks improve e-commerce: a
study on social marketplaces. In WOSN, 2008.
[71] M. Sweney. Google and Viacom reach deal over YouTube
user data. Guardian. http://tinyurl.com/59b3ou, Jul 15 2008.
[72] R. Topolski.
ISPs: Wiretapping,
forgery and browser hijacking. http://www.freepress.net/ﬁles/
NebuAd Report.pdf, 2008.
NebuAd and partner
[73] J. Travers and S. Milgram. An experimental study of the
small world problem. Sociometry, 32(4):425–443, 1969.
[74] E. Weinstein. Phase transition. http://mathworld.wolfram.
com/PhaseTransition.html.
[75] G. Wills. NicheWorks — interactive visualization of very
Journal of Computational and Graphical
large graphs.
Statistics, 8(2):190–212, 1999.
[76] J. Winter. Disgraced former NBA referee Tim Donaghy’s
phone calls to second ref raise questions. http://www.foxnews.
com/story/0,2933,381842,00.html, 2008.
[77] H. Yu. Freedom to Tinker: Bad Phorm on privacy. http:
//tinyurl.com/6qkstm, 2008.
[78] H. Yu, P. Gibbons, M. Kaminsky, and F. Xiao. SybilLimit:
A near-optimal social network defense against sybil attacks.
In S&P, 2008.
[79] E. Zheleva and L. Getoor. Preserving the privacy of sensitive
relationships in graph data. In PinKDD, 2007.
[62] M. Richardson and P. Domingos. Mining knowledge-sharing
sites for viral marketing. In KDD, 2002.
[80] B. Zhou and J. Pei. Preserving privacy in social networks
against neighborhood attacks. In ICDE, 2008.
[63] T. Rohan, T. Tunguz-Zawislak, S. Sheffer, and J. Harm-
sen. Network node ad targeting. U.S. Patent Application
0080162260, 2008.
[64] R. Rumford.
Facebook applications break 10000.
http:
//tinyurl.com/5hnqh9, 2007.
187
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply.