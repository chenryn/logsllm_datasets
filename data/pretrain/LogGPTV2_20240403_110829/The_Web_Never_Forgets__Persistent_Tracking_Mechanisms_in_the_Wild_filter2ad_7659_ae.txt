terface does not clear localStorage if the user doesn’t select
“Everything” as the time range of removal16and there is no
uniﬁed interface for checking what is stored in localStor-
age and IndexedDB. Similarly, Oﬄine Website Data (App-
Cache and Cache) can only be checked by visiting a separate
about:cache page.
Even if the user manages to clear all storage vectors, the fact
that Flash storage is not isolated17 between browsers which
use the Adobe Flash plugin (e.g. Firefox, Chromium, and
Internet Explorer) still creates an opportunity for respawn-
ing. Consider the common scenario of a multi-user environ-
ment where Alice uses browser A and Bob uses browser B,
without any OS-level separation of user accounts. Assume
that Alice is privacy-conscious and clears browser state fre-
quently, but Bob does not. Consider an ID on Browser A is
shared between Browser A’s Flash Cookies and HTTP Cook-
ies. When Bob browses, X may be respawned as an HTTP
cookie in browser B. In Section 4.2, we showed that this be-
havior occurs in the wild. Now when Alice completely clears
the state of Browser A, the ID X will be removed from com-
mon ﬂash storage and Browser A’s HTTP storage. Crucially,
however, when Bob browses again, it could be respawned
from B’s HTTP storage to common ﬂash storage and later
when Alice browses again, back to A’s HTTP storage. We
showed in Section 4.3 that HTTP-to-Flash respawning oc-
curs in the wild as well. Thus the only way to defend against
this attack in a multi-browser environment is to clear state
on all browsers simultaneously. As a proof-of-concept, we
manually tested the ﬁrst-party domains on which we ob-
serve HTTP-to-Flash respawning (Appendix Table 8) and
we found this exact scenario occurs on both casino.com and
xlovecam.com.
Cookie syncing: We’re not aware of any tools that speciﬁ-
cally block cookie syncing. The bluntest approach, of course,
is to simply block third-party cookie placement and HTTP
traﬃc. EFF’s newly released tool Privacy Badger18 uses
heuristics to block third-party cookies with the goal of pre-
venting third-party tracking, erring on the side of false pos-
itives (i.e., blocking too many cookies). The Tor Browser
Bundle (TBB) prevents cross-site cookie tracking by dis-
abling all third-party cookies, and not storing any persis-
tent data such as cookies, cache or localStorage. A more
targeted solution would be to block third-party traﬃc con-
taining strings that are cookie values, but this approach will
16Bug 527667 https://bugzilla.mozilla.org/show_bug.
cgi?id=527667
17Conﬁrmed through manual analysis
18https://www.eff.org/privacybadger
684
likely suﬀer from false negatives. However, even a perfect
blocking tool is ﬂawed if it is not used immediately from
a completely fresh browsing state. For instance, if a user
browses for a short amount of time before installing such a
tool, trackers may have already placed and synced cookies
— enabling them to merge data in the back-end. If these
IDs are maintained through a hard-to-block technique such
as canvas ﬁngerprinting, the trackers can still follow a user as
he browses and link their records through these previously-
established syncing relationships even if all future syncs are
blocked.
6.2 The effect of opt-out
In order to study the eﬀect of ad-industry opt-out tools
on the tracking mechanisms we study, we opted-out from
all the listed companies on the Network Advertising Initia-
tive (NAI)19 and European Interactive Digital Advertising
Alliance (EDAA)20 opt-out pages.
Canvas ﬁngerprinting: For each canvas ﬁngerprinting
script we visited two sites that included this script. We
did not observe any website that stopped collecting can-
vas ﬁngerprint due to opt-out.21 This was despite the fact
that AddThis was listed on the NAI opt-out page and Lig-
atus (second most popular canvas ﬁngerprinter) was listed
on EDAA’s page.
We also tried opting-out by on AddThis’ own Data Collec-
tion Opt-Out website22, which again, did not stop AddThis’s
script collecting the canvas ﬁngerprint.
Respawning: We did not observe any change in cookie
respawning from HTTP to Flash cookies. This is expected
as the parties involved are not participants in the advertising
opt-out initiatives.
Cookie syncing: The use of opt-out cookies reduces the
number of IDs involved in cookie synchronization by 30%.
However, we see only a 5% reduction in the number of par-
ties involved in synchronization. This reduction is compar-
atively smaller than the reduction seen when the browser
is set to block third-party cookies. The composition of the
top parties involved in synchronization is nearly the same as
in the ﬁrst-party cookie only case seen in Appendix B. In
Section 5.3 we show how, even under the larger reduction
in sync activity aﬀorded by blocking all third-party cookies,
it is possible to recover a large portion of a user’s browsing
history using just a small number of the parties involved.
Note that most companies oﬀering or honoring the opt-outs
we evaluated do not promise to stop tracking when a user
opts out, but only behavioral advertising. While we ob-
served tiny or nonexistent reductions in various forms of
tracking due to opt-out, we make no claims about how opt-
outs aﬀect behavioral advertising.
19http://www.networkadvertising.org/choices/
20http://www.youronlinechoices.com/uk/your-ad-
choices
21We observed that two of the 20 ﬁngerprinting scripts
(revtrax.com and vcmedia.vn) were missing on the sites we
found them before, though we checked to ensure that this
was not related to opt-out.
22http://www.addthis.com/privacy/opt-out
6.3
Implications
Let us consider the level of user eﬀort and sophistication
required for eﬀective mitigation. First, users must be very
careful in their use of existing tools, such as clearing state
on all browsers at once or installing blocking tools before
cookie syncing has occurred. Second, users must accept us-
ability drawbacks such as the prompt for Canvas API access.
Third, there are also trade-oﬀs in functionality and content
availability. Finally, the rapid pace at which new tracking
techniques are developed and deployed implies that users
must constantly install and update new defensive tools. It
is doubtful that even privacy-conscious and technologically-
savvy users can adopt and maintain the necessary privacy
tools without ever experiencing a single misstep.
Evercookies were at the center of ﬁerce debates when
Soltani et al. reported their ﬁndings [43] a few years ago.
Although this resulted in a lawsuit and a $500,000 settle-
ment [14], we ﬁnd an increasing number of websites using
these tracking technologies as well as signiﬁcant advances in
the technologies themselves.
The World Wide Web Consortium (W3C) standards doc-
uments that describe three new storage APIs (localStorage,
IndexedDB and WebStorage APIs) have the same boiler-
plate warning about the tracking potentials of these mech-
anisms23 and mention the necessity of an interface to com-
municate the evercookie risk. Perhaps a fruitful future di-
rection for standards bodies is to consider privacy issues at
the design stage, acknowledging that without such a proac-
tive eﬀort, tracking techniques are likely to have the upper
hand over defenses. W3C’s draft speciﬁcation “Fingerprint-
ing Guidance for Web Speciﬁcation Authors” is a notable
eﬀort in this direction, for providing a guideline to Web
speciﬁcation authors about privacy risks of browser ﬁnger-
printing [15].
6.4 A Path Forward
Blocking tools are currently the primary solution to third-
party tracking for the informed user. We believe that these
tools can be greatly improved by a back-end consisting of
regular web-scale crawls. Crawlers can incorporate sophisti-
cated rules to detect unwanted tracking, as we have shown,
whereas it would be diﬃcult to deploy these directly into
browser tools. Accordingly, we plan to further scale our
crawling infrastructure, while continuing to release results
in a machine-readable format.
Crawler-supported blocking tools could also beneﬁt from
machine learning and crowd-sourcing (instead of rules hand-
coded by experts) for minimizing false positives and neg-
atives. For example, we have produced an initial classi-
ﬁcation of canvas ﬁngerprinting scripts on 100,000 sites,
but there are surely many more such scripts in the web’s
long tail, which suggests that a semi-supervised learning ap-
proach could be eﬀective. The resulting classiﬁer would label
scripts that access the canvas API as canvas ﬁngerprinters
or non-canvas-ﬁngerprinters. Turning to crowdsourcing, a
browser tool could default to blocking all canvas write/read
attempts, but slowly incorporate user feedback about bro-
ken functionality to train a model for identifying true ﬁn-
23http://www.w3.org/TR/webstorage/#user-tracking,
http://www.w3.org/TR/IndexedDB/#user-tracking,
http://www.w3.org/TR/webdatabase/#user-tracking
685
gerprinting attempts. Of course, these two approaches can
be combined.
Finally, publishers have little insight into the types of
tracking occurring on their own sites. The tools that we and
others have built can be re-purposed to provide transparency
not just to end-users but also allow publishers an in-depth
look into how trackers collect data from their sites, where
the data ﬂows, and how it is used. This will allow them
to discriminate between advertising or analytics providers
on the basis of privacy practices.24 If combined with public
pressure to hold ﬁrst parties accountable for online tracking
and not just third parties, it can move online tracking in a
more transparent and privacy-friendly direction.
7. CONCLUSION
We present a large-scale study of tracking mechanisms
that misuse browser features to circumvent users’ tracking
preferences. We employed innovative measurement meth-
ods to reveal their prevalence and sophistication in the wild.
Current options for users to mitigate these threats are lim-
ited, in part due to the diﬃculty of distinguishing unwanted
tracking from benign behavior.
In the long run, a viable
approach to online privacy must go beyond add-ons and
browser extensions. These technical eﬀorts can be but-
tressed by regulatory oversight. In addition, privacy-friendly
browser vendors who have hitherto attempted to take a neu-
tral stance should consider integrating defenses more deeply
into the browser.
8. ACKNOWLEDGEMENTS
The authors would like to thank Joseph Bonneau, Edward
Felten, Georg Koppen, Lukasz Olejnik, Mike Perry, Vitaly
Shmatikov, Roland Illig, and Matthew Wright for valuable
feedback, Dillon Reisman and Pete Zimmerman for helping
develop some of the infrastructure used, Oscar Reparaz for
chroot tips and Junjun Chen for earlier work on cookie sync-
ing that helped our understanding of the practice. For KU
Leuven, this work was partially funded by the projects IWT
SBO SPION, FWO G.0360.11N, FWO G.0686.11N, and the
KU Leuven BOF OT project ZKC6370 OT/13/070.
9. REFERENCES
[1] Privacychoice - get a free privacy scan of your site.
http://privacychoice.org/assessment.
[2] Bug 757726 - disallow enumeration of
navigator.plugins. https:
//bugzilla.mozilla.org/show_bug.cgi?id=757726,
May 2012.
[3] Manage, disable Local Shared Objects | Flash Player.
http://helpx.adobe.com/flash-player/kb/
disable-local-shared-objects-flash.html, 2014.
[4] Doubleclick ad exchange real-time bidding protocol:
Cookie matching.
https://developers.google.com/ad-
exchange/rtb/cookie-guide, February 2014.
[5] Selenium - Web Browser Automation.
http://docs.seleniumhq.org/, 2014.
24In fact, there is a ﬂedgling commercial market for such tools
[1], but they are not very sophisticated.
[6] G. Acar, M. Juarez, N. Nikiforakis, C. Diaz,
S. G¨urses, F. Piessens, and B. Preneel. FPDetective:
Dusting the Web for ﬁngerprinters. In ACM
Conference on Computer and Communications
Security (CCS), pages 1129–1140. ACM, 2013.
[7] M. Ayenson, D. J. Wambach, A. Soltani, N. Good,
and C. J. Hoofnagle. Flash cookies and privacy II:
Now with HTML5 and ETag respawning. World Wide
Web Internet and Web Information Systems, 2011.
[8] M. Backes, A. Kate, M. Maﬀei, and K. Pecina.
Obliviad: Provably secure and practical online
behavioral advertising. In IEEE Security and Privacy
(S&P), pages 257–271. IEEE, 2012.
[9] R. Balebako, P. Leon, R. Shay, B. Ur, Y. Wang, and
L. Cranor. Measuring the eﬀectiveness of privacy tools
for limiting behavioral advertising. In Web 2.0
Workshop on Security and Privacy (W2SP). IEEE,
2012.
[10] F. Besson, N. Bielova, T. Jensen, et al. Enforcing
Browser Anonymity with Quantitative Information
Flow. 2014.
[11] M. Bilenko, M. Richardson, and J. Y. Tsai. Targeted,
not tracked: Client-side solutions for privacy-friendly
behavioral advertising. In Privacy Enhancing
Technologies (PETS). Springer, 2011.
[12] P. E. Black. Ratcliﬀ/Obershelp pattern recognition.
http://xlinux.nist.gov/dads/HTML/
ratcliffObershelp.html, December 2004.
[13] K. Brade. gitweb.torproject.org - torbrowser.git/blob -
src/current-patches/ﬁrefox/0019-add-canvas-image-
extraction-prompt.patch.
https://gitweb.torproject.org/torbrowser.git/
blob/HEAD:/src/current-patches/firefox/0019-
Add-canvas-image-extraction-prompt.patch,
November 2012.
[14] W. Davis. KISSmetrics Finalizes Supercookies
Settlement. http://www.mediapost.com/
publications/article/191409/kissmetrics-
finalizes-supercookies-settlement.html, 2013.
[Online; accessed 12-May-2014].
[15] N. Doty. Fingerprinting Guidance for Web
Speciﬁcation Authors.
http://w3c.github.io/fingerprinting-guidance/,
2014.
[16] P. Eckersley. How unique is your web browser? In
Privacy Enhancing Technologies (PETs), pages 1–18.
Springer, 2010.
[17] C. Eubank, M. Melara, D. Perez-Botero, and
A. Narayanan. Shining the ﬂoodlights on mobile web
tracking - a privacy survey. In ”Web 2.0 Security and
Privacy”, May 2013.
[18] E. W. Felten. If You’re Going to Track Me, Please Use
Cookies.
https://freedom-to-tinker.com/blog/felten/if-
youre-going-track-me-please-use-cookies/, 2009.
[19] M. Fredrikson and B. Livshits. Repriv: Re-imagining
content personalization and in-browser privacy. In
IEEE Security and Privacy (S&P), pages 131–146.
IEEE, 2011.
[20] S. Guha, B. Cheng, and P. Francis. Privad: practical
privacy in online advertising. In USENIX Conference
686
on Networked Systems Design and Implementation,
pages 169–182. USENIX Association, 2011.
[21] S. Kamkar. Evercookie - virtually irrevocable
persistent cookies. http://samy.pl/evercookie/, Sep
2010.
[22] M. Kerrisk. strace(1) - linux manual page. http:
//man7.org/linux/man-pages/man1/strace.1.html,
May 2014.
[23] T. Kohno, A. Broido, and K. C. Claﬀy. Remote
physical device ﬁngerprinting. IEEE Transactions on
Dependable and Secure Computing, 2(2):93–108, 2005.
[24] R. Kotcher, Y. Pei, P. Jumde, and C. Jackson.
Cross-origin pixel stealing: timing attacks using CSS
ﬁlters. In ACM Conference on Computer and
Communications Security (CCS), pages 1055–1062.
ACM, 2013.
[25] B. Krishnamurthy and C. Wills. Privacy diﬀusion on
the Web: a longitudinal perspective. In International
Conference on World Wide Web, pages 541–550.
ACM, 2009.
[26] B. Krishnamurthy and C. E. Wills. On the leakage of
personally identiﬁable information via online social
networks. In ACM Workshop on Online Social
Networks, pages 7–12. ACM, 2009.
[27] B. Liu, A. Sheth, U. Weinsberg, J. Chandrashekar,
and R. Govindan. AdReveal: Improving transparency
into online targeted advertising. In ACM Workshop on
Hot Topics in Networks, page 12. ACM, 2013.
[28] J. Mayer. Tracking the trackers: Self-help tools.
https://cyberlaw.stanford.edu/blog/2011/09/
tracking-trackers-self-help-tools, September