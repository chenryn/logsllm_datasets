• Non-Technical–PP Link: Same as Technical–PP Link, but
using non-technical language (“your data” instead of “cook-
ies”).
• Non-Technical–No PP Link: Same as Non-Technical–PP
Link, but with the privacy policy sentence replaced with
whitespace.
For participants who saw a notice with non-technical language,
we replaced other occurrences of the term “cookie” in our setup:
In the study invitation, “cookie notice” was replaced with “privacy
notice,” and we adjusted the wording of some survey questions and
response options as described in Appendix B.
3.5 Research Ethics
Our study was conducted on a website with real users, which raises
ethical concerns as we did not ask for consent prior to measur-
ing their interactions with consent notices. We did so to ensure
ecological validity and be able to capture non-biased results as we
expected the majority of visitors to not pay attention to a study
consent notice asking them to opt in, which was supported by our
findings.
While our institution does not require IRB review for minimal
risk studies, we ensured that we did not deceive or harm website
visitors and their privacy. All displayed consent notices functioned
as described and respected the visitor’s choice. To test the effect of
no-option consent notices, we had to offer fewer choices than we
believe is required by the GDPR. We added a paragraph describing
our study to the website’s privacy policy. The data we collected
was pseudonymized. Logs were stored on the website’s server and
access was limited to two researchers conducting the analysis and
the website’s owner. After the study, the data was removed from
the server and copied to the researchers’ data center.
All visitors were informed about the study after 30 seconds when
we showed a notice asking them for participation in the survey.
Survey participants were asked for explicit consent and to confirm
they were over 18 and wanted to participate. Email addresses of
participants who opted to participate in the prize draw were stored
separately from the dataset, without the participant ID.
3.6 Data Analysis
3.6.1 Event logs. When we started the data analysis, we noticed
inconsistencies in some entries. The event logs created by our plu-
gin indicated that some website visitors had seen multiple notice
versions. This could have happened because users had deactivated
cookies completely, visited the website in multiple sessions using
private browsing mode, or opened the website in multiple tabs si-
multaneously. For another set of users, we detected multiple screen
resolutions, mostly because the screen orientation had changed.
Rotating the screen could lead to the notice covering different
parts of the website, so we removed these participants to preserve
consistency. In total, we removed 2,1 % of participants across all
experiments.
Survey. We considered a survey response complete if the
3.6.2
participant had at least answered Q1–Q6 but did not provide a free-
text answer to Q7 and Q8. Due to a low survey response rate we
received few responses for some conditions. We therefore refrained
from a quantitative analysis of survey responses. In Section 4, we
evaluate responses to the open-ended questions (parts of Q1; Q6–
Q8). We coded these responses using emergent thematic coding.
Two of the authors independently devised a set of codes for each
7
question and coded the responses. The results were discussed and
yielded a final codebook, which was used to re-code all responses.
Any remaining disagreements were reconciled by the two coders.
We report the codes and their distribution in Appendix B, along
with the answers to all closed-ended questions.
4 RESULTS
4.1 Dataset and Website Visitors
Our cleaned dataset contained event logs of 82,890 unique website
visitors: 14,135 in Experiment 1, 36,530 in Experiment 2, and 32,225
in Experiment 3. 21.72 % of all visitors accessed the website on a
desktop or laptop computer and 78.28 % with a mobile device (of
which 5.1 % were tablets)4. Overall, 6.95 % of participants used an
ad blocker. The rate was much higher on desktop (29.1 %) than
on mobile devices (0.8 %). These numbers are consistent with a
2017 report for Germany [35], the highest rate of ad block users
in Western Europe (20 % on average), and North America (18 % on
average). For 16.45 % of visitors, we could not detect whether they
used an ad blocker. These visitors did not stay long enough on the
website to complete ad blocker detection. On average, users spent a
short time on the website. Pre-study Google Analytics data provided
by the partner website showed that 84.81 % of visitors spend less
than 10 seconds on the site, 5.21 % 11 to 60 seconds, and 5.83 % up to
3 minutes. Our dataset includes all users for whom the event logs
indicated a fully loaded site, regardless of how long they stayed
on the page, resulting in a high number of “no action” visitors. As
described in Section 4.3, the median time until an interaction with
any version of the notice was 4 to 8 seconds. About 11,800 users
stayed on the page for 10 seconds or more.
The link to our survey was clicked 804 times (168 in Experiment
1, 445 in Experiment 2, and 191 in Experiment 3). We received a
total of 110 responses (16 in Experiment 1, 60 in Experiment 2, and
34 in Experiment 3), which means that 0.37 % of the 29,712 visitors
who interacted with the notice or stayed on the site for longer
than 30 seconds participated in the survey. To get an impression of
visitors’ expectations about the website’s data collection practices,
we asked Q2: What do you think – what data does [the website]
collect about you when you access the website? This question was
answered by all participants. Across all three studies, the data most
commonly expected to be collected were links clicked on the site
(78 %), IP address (65 %), posts read on the site (61 %), and the device
used (59 %). Less often mentioned were other sites visited (29 %)
and the visitor’s place of residence (25 %). 13 % thought the website
collected their name, even though the site never asks for it. Only 5 %
thought the site did not collect any data about them. These answers
indicate that the survey participants had a good understanding of
what data websites can collect even without user accounts.
4.2 Experiment 1: Banner Position
Interaction rates. Figure 3 shows how visitors interacted
4.2.1
with the consent notices displayed at different positions. Overall
the notices shown at the bottom-left position received the most
interactions, 37.1 % of visitors interacted with them regardless of
device type or choice made. The notice positions most commonly
4We count as “desktop computer” actual desktop machines as well as laptops. “Mobile”
devices include smartphones and tablets; the latter were used by 5.1 % of visitors.
8
Figure 3: Interaction rates in Experiment 1 (notice position),
arranged pairwise for mobile and desktop users.
observed in practice, small bars at the top or bottom, resulted in
low interaction (2.9 % and 9.6 %, respectively).
While we were mainly interested in position in Experiment 1,
we also analyzed the influence of other variables, such as ad blocker
use, screen resolution, browser, operating system, and device type
(desktop/mobile). We estimated the effect size of different properties
by calculating Cramér’s V (CV) and over all visitors the banner posi-
tion showed the largest effect size (CV=.31). Unless noted otherwise,
χ2-tests for effects in this experiment are statistically significant
(p<.001).
Ad blocker use also had a small impact on whether someone in-
teracted with the notice. While on average 15.8 % of visitors without
an ad blocker interacted with any notice, only 12.6 % of ad blocker
users did so, but the effect size was rather small (CV=.11). The im-
pact of screen resolution was much higher on desktop (CV=0.33)
than on mobile (CV=0.16): Only 5.5 % of visitors with screen resolu-
tions of 1,920 by 1,080 pixels or higher interacted with the notice,
while the average was 25.6 % for smaller screens. Although the de-
cline/accept ratio varied between conditions, we could not identify
a single factor to explain the differences. Across all conditions the
number of users who accepted cookies was higher than the number
of those that declined.
4.2.2 Discussion. A possible explanation for higher interaction
rates with notices displayed at the bottom is that these notices
are more likely to cover the main content of the website, while
notices shown at the top mostly hide design elements like the
95.1%4.5%0.4%97.8%1.8%0.4%67.1%18.8%94.4%3.3%2.3%75.4%16.0%8.6%95.7%2.4%1.9%025%50%75%100%86.8%8.9%4.3%88.3%8.5%3.2%62,7%30.3%7.0%61.7%29.8%8.5%96.5%2.8%0.7%85.6%11.9%2.5%No ActionAcceptDecline14,1%website header or logo. If one uses their thumb to navigate websites
on a smartphone, it is also easier to tap elements on the bottom
part of the screen than those at the top. An explanation for higher
interaction rates with notices displayed on the left of the viewport
might be the left-to-right directionality of Latin script: Line breaks
cause the information density of a text to be skewed to the left, so
consent notices positioned on the left are more likely to obstruct
visitors’ reading and trigger an interaction with the notice.
We looked for qualitative feedback in the survey responses. In
Experiment 1, we received 16 responses, with eight participants
having interacted with the notice and another eight that did not. All
six participants who answered they had clicked the notice “because
it prevented them from reading the website content” had seen a
notice shown at the bottom or left side.
Both on desktop and mobile, the notice positioned in the bottom-
left corner received the most attention. Thus, we decided to display
the notices in Experiments 2 and 3 in the bottom-left corner.
4.3 Experiment 2: Choices & Nudging
In Experiment 2 there were 36,395 participants in total. Each of the
nine conditions was shown to 4,044 website visitors on average.
Interaction rates. Figure 4 provides an overview of the recorded
4.3.1
visitor interactions. Compared to Experiment 1, the overall percent-
age of visitors who interacted with the notice increased (13,8 %–
55,3 %), especially on mobile devices, likely because we had in-
creased the font size, resulting in larger notices. The highest in-
teraction rate (55 %) was measured for binary notices on mobile
devices.
The experiment revealed a strong impact of nudges and pre-
selections. Overall the effect size between nudging (as a binary
factor) and choice was CV=.50. For example, even for confirmation-
only notices, more users clicked “Accept” in the nudge condition,
in which it was highlighted (50.8 % mobile, 26.9 % desktop), than
in the non-nudging condition, in which “Accept” was displayed as
a text link (39.2 % m, 21.1 % d). The effect was most pronounced
for category- and vendor-based notices, in which all checkboxes
were pre-selected in the nudging conditions, but not in the privacy-
by-default conditions. The pre-selected versions led around 30 % of
mobile users and 10 % of desktop users to accept all third parties.
In contrast, only a small fraction (< 0.1 %) allowed all third parties
when given the opt-in choice and 1 to 4 % allowed one or more
third parties (“other” in Figure 4), indicating that some users still
engaged with the offered choices. No desktop visitors allowed all
categories. Interestingly, the number of non-interacting users was
highest on average for the vendor-based conditions, although they
took up the largest amount of screen space due to six options being
offered. We discuss qualitative survey feedback on the category-
and vendor-based notices in Section 4.5.2.
4.3.2 Choices. Results were mixed in terms of the consent choices
users made when given options (in all but the no-option and confir-
mation conditions). Surprisingly, more participants accepted cook-
ies in both binary conditions, where they had the option to decline
cookies, than in the non-nudging confirmation condition, where
they could only accept cookies or not interact with the notice.
Figure 4: Visitors’ consent choices in Experiment 2. “Ac-
cept”/“Decline” indicate that (all) options were accepted
or declined. “Other” includes those who accepted/declined
only some options. Bold figures indicate default options.
Figure 5 lists the specific choices participants made on category-
and vendor-based notices. Few visitors chose specific categories
or vendors if they were not pre-selected (non-nudging conditions).
Interestingly, more visitors selected specific vendors than categories.
Vendors YouTube and Ionic were selected most, even though survey
responses (Q6) indicated that Ionic was lesser known than other
listed vendors. We observe a similar pattern for the de-selection of
specific categories and vendors: More visitors unchecked one or
more vendors (10.0 %) than categories (6.9 %).
6 % of visitors who saw a category- or vendor-based notice
clicked at least one of the checkboxes more than once. 48 visi-
tors (0,08 %) toggled an even number of times, reversing previous
9
% VisitorsNo ActionAcceptOther0%25%50%75%100%60.8 %30.3 %1.2 %7.7 %81.9 %0.9 %8.5 %8.7 %45.5 %44.6 %10.1 %68.0 %20.1 %11.9 %59.7 %40.3 %47.5 %52.5 %66.3 %0.03 %3.8 %29.9 %86.2 %1.5 %12.3 %0.0 %60.8 %39.2 %78.9 %21.1 %60.4 %33.1 %0.8 %5.7 %82.5 %11.9 %5.6 %0 %49.2 %50.8 %73.1 %26.9 %44.7 %41.0 %14.3 %65.9 %20.9 %13.2 %63.3 % 0.1 %0.9 %35.7 %83.7 %0.2 %16.1 %0.0 %DismissDeclinenon nudgingConﬁrmationBinarynon nudgingnudgingCategoriesnon nudgingnudgingVendorsnon nudgingnudgingNo OptionnudgingTable 2: Comparison of interactions with category notices
Dataset
Cookiebot
Our Data
Decision None pre-selected
Accept
Decline
Accept
Decline
(n = 1,135,090)
5.59 %
94.41 %
(n = 1,239)
0.16 %
99.84 %
all pre-selected
(n = 1,988,681)
98.84 %
1.16 %
(n = 1,380)
83.55 %
16.45 %
decisions. Interestingly, 47 of those users saw a “nudging” notice
so that they actively reactivated one of the categories.
We also recorded how long it took visitors to submit their choice.
The median time to submit for no-option, confirmation and binary-
choice notices was 4–5 seconds; 7–8 seconds for category- or vendor-
based notices.5 For details see Appendix A.
4.3.3 External validation. To verify the generalizability of our re-
sults, which are only based on visitors to our partner website, we
compared our data to internal data from Cookiebot, a company
offering cookie consent notices (similar to our category-based con-
ditions) as a service to websites. Their dataset from February 2019
contains 3 million user logs for 2,000 different websites. The Cook-
iebot notices also show purpose categories, so we compare their
data with our data for the category-type notices. In their case, some
of the checkbox selections cannot be changed by users, as website
owners can argue that the use of certain cookie categories is based
on different legal grounds (e. g., “legitmate interest”, Art. 6 (1) (f)
GDPR). Therefore (de)selecting all consent-based cookie categories
in Cookiebot notices sometimes requires fewer clicks to be made,
and we were not able to compare decisions we labeled as “other”.
As shown in Table 2, Cookiebot has a slightly higher acceptance
rate (5.6 % compared to 0.16 % in our dataset) and a lower decline
rate when all boxes are pre-selected (1.2 % compared to 16.5 % in
our dataset). This means that our findings are generally comparable,
but specific results may differ based on website and category, which
is what we would expect given that privacy preferences are highly
contextual [3]. A related 2017 study (n = 300) found that about
3 % of users are willing to accept marketing cookies [34], which
is between marketing acceptance in our non-nudging (0.6 %) and
nudging (7.3 %) conditions.
4.3.4 Discussion. Experiment 2’s results show that nudges and
pre-selection had a high impact on users’ consent decisions. It
also underlines that the GDPR’s data protection by default require-
ment, if properly enforced, could ensure that consent notices collect
explicit consent. We further find that most visitors make binary
decisions even when more choices are offered by agreeing to all or
no options. Only very few visitors selected specific categories or
vendors, while even in the non-nudging binary condition a consid-
erable number accepted the use of cookies. An explanation for this
behavior might be that those who are somewhat OK with cookie
5We report the median as the data showed a high standard deviation since we had no
way to check when the interaction with a notice started, and sometimes the choice
was submitted minutes after the page had been loaded.
10
use are not willing to expend effort on enabling it. Another expla-
nation, suggested by previous work [27], is that showing the actual
practices decreases the trust in a website and therefore leads to
more users making an informed decision to decline cookies.
4.4 Experiment 3: Language & Privacy Policy
Link
In Experiment 3, we tested four conditions with combinations of (a)
the notice including a link to the privacy policy (or not) and (b) the
text either referring to “cookies” or “your data” more generally. All
conditions were variants of the category-based, non-nudging notice
from Experiment 2. Figure 6 summarizes the results. All conditions
were shown to 6,032 visitors on average. Again, interaction rates
were higher for mobile visitors. As in Experiment 2, very few visi-
tors accepted all categories (0–0.1 %), but some visitors (0.3–1.4 %)
explicitly allowed one or more. More people make a choice when
technical language is used, i. e., “cookie” is mentioned in the notice.
While this difference is significant (χ2-test, (p<.01), the effect size
is low (CV=.08), as are the differences between conditions. Presence
of the privacy policy link had no significant effect (p<.08).
4.4.1 Discussion. Experiment 3 showed that mentioning of cook-
ies has a minor influence on users’ consent behavior. However,
differences between conditions are small. This is not surprising
given that most users either submit the default choice or do not
interact with the notice at all. We could not confirm previous stud-
ies [27] that showed a negative effect on trust in a website when
a privacy policy was mentioned, but we found that more visitors
decline the use of cookies if a privacy policy is linked. Our findings
indicate that position and choice have a more pronounced effect on
consent behavior than notice language or pointers to more privacy
information.
4.5 Survey Results
4.5.1 Reasons for (Non-)Interaction with Notices. In the survey (see
Appendix B), we asked participants why they did or did not click
on the consent notice. Participants could select multiple reasons.
44 of 61 survey participants who had clicked the notice reported
they had done so because they were annoyed by it. 16 thought the
website would not work otherwise, and 13 stated they had clicked
the notice out of habit. 11 participants interacted with the notice to
protect their privacy, 6 for security reasons, and 5 to see fewer ads.
49 participants had not interacted with the consent notice, 20 of
which reported they had not seen the notice. Nine thought clicking
the notice would not have any effect, six did not care what cookies
the website used or what data it collected, and three thought it did
not offer enough choices. Two reported to not know what cookies
were or what data the question was referring to. 13 participants se-
lected “other” and provided a free-text response. Recurring themes
in these responses include that the notices were “annoying [...], so
I just ignore them out of frustration” (Participant 2-94)6 and that
participants thought no cookies would be set if they did not interact
with the notice. One participant mentioned that they “[found] all
of the partners suspicious” (2-255). One had opened the website in
6The first digit in our participant identifiers denotes the experiment and the second
the response ID assigned by LimeSurvey.
Figure 5: Decisions to allow or decline specific categories (1) or vendors (2) in the the specific conditions of Experiment 2.
Subgraphs (a) show how many visitors checked specific boxes, subgraphs (b) how many unchecked pre-selected boxes.
vendor-based notice stated: “Having options makes me feel secure”
(2-619).
However, participants had diverging opinions regarding the no-
tices’ clarity. Some found the categories “self-explanatory” (3-118).
Others pointed out that “Necessary [from a technical perspective]
does not say much. Cookies aren’t necessary to view a website”
(3-215) and that “something could be hidden” (2-557) behind the
Necessary category. 6 (of 7) participants who saw a vendor-based
notice in Experiment 2 reported it had “too much text, too many
options. I’m interested in the website’s content, not in the consent
notice” (2-116), and one suggested “it would be perfect to have a
button to (de)activate all cookies” (2-199). Seven participants based
their choices on privacy considerations: “I don’t tick anything. I only
need advice [from] the website” (3-108), “I don’t want personalized
web pages, ads, [... and] pointers to social media” (3-165).
These responses indicate that more complex notices are not
necessarily problematic, as long as options are not pre-selected.
While some express concerns, do not trust the categorizations, or
find the choices too complex, others appreciate the privacy-by-
default approach.
4.5.3 Understanding of Consent Notice Behavior. The survey fur-
ther investigated participants’ general understanding of how con-
sent notices work and what it meant to accept or decline cookies.
This section was identical in all three studies. The participant was
shown the binary notice depicted in Figure 1 (a) (bb). Then we
asked the following two free-text questions: Q7: What do you think