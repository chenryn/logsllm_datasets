that rm descends into a subdirectory using chdir, and then
ascends out of this subdirectory using chdir(".."). In
the window of time between the descend and ascend opera-
tions, an attacker can move the subdirectory higher up. This
will result in the second chdir operation going out of the
directory on which it was invoked. For instance, consider
an operation rm -r /tmp/a/, where a contains a subdi-
rectory b. When rm descends into /tmp/a/b, the attacker
can rename /tmp/a/b to /tmp/b. Now, when rm executes
a chdir(".."), it will go into /tmp, and will start delet-
ing all ﬁles in /tmp, which is different from the original
intent of removing the subdirectory /tmp/a. In this attack,
typically the rm will be invoked by root to clean up some
directories of /tmp, while the attacker has write permission
on the subdirectory /tmp/a.
In our experiments, we inserted sleep command in the rm
program to obtain a sufﬁcient time window to launch the ac-
tual attack. For the rm program, our implementation learnt a
relationship between its command-line argument and all of
the arguments to unlink and rmdir system calls made by
it: namely, that the arguments to these system calls should
be within the directory name given by the command-line
argument. This relationship was violated during the attack,
and hence it was detected. Other types of race conditions
can also be detected as violations to path relationships. For
a more robust detection technique, one can rely on inode
numbers instead of ﬁlenames obtained using realpath.
Attacks on ﬁle descriptors. Programs may make assump-
tions about the meanings of ﬁle descriptors, e.g., that de-
scriptor 2 corresponds to stderr. An example setuid pro-
gram with such a vulnerability is described in [4]:
fd = open("/etc/passwd");
str = read_from_user();
L1: fprintf(stderr,
"The user entered:\n%s\n", str);
If the attacker execve’d this program after closing
stderr, then a open of "/etc/passwd" will return ﬁle
descriptor 2, and subsequently, the fprintf will have the
effect of writing user provided data into the password ﬁle.
This attack is detected as a violation of unary relationships
learnt on ﬁle descriptors.
5.1.2 Verifying Security Properties Using Models
Note that if a security policy P can be statically veriﬁed
with respect to a model M learnt by our technique, then one
can be assured that an intrusion detection system based on
M will detect any attack that violates P . Clearly, it would
be beneﬁcial if one can make such deterministic assertions
about an anomaly detection system.
For veriﬁcation, security policies are expressed as an ex-
tended ﬁnite-state automaton, i.e., a ﬁnite-state automaton
that can remember a ﬁnite number of values such as ﬁle
names. Technically, these automata capture negations of
safety properties, so they accept traces that violate the de-
sired security property. The models are also extended ﬁnite-
state machines accepting normal execution traces. The ver-
iﬁcation then amounts to taking the intersection of the prop-
erty and model automata, and checking if the language ac-
cepted by this automata is nonempty. If so, then the prop-
erty is violated. The veriﬁer is written in XSB Prolog [35],
a system well-suited to writing veriﬁcation tools. The focus
of this section is on the results of veriﬁcation rather than the
veriﬁcation process, so we omit the technical details of this
process.
Following are three of the properties that we actually ver-
iﬁed for tar, gzip and find:
• find executes only those programs that are speciﬁed
using a “-exec” command-line option. To verify this
property, we need an application-speciﬁc command-line
parser to recognize the parameter following “-exec”
switch and generate a corresponding synthetic event. The
property itself states that the ﬁrst argument to any execve
made by find is equal to the “-exec” argument. Since
an equality relationship is learnt in the model involving
the “-exec” parameter and the argument to execve, this
property is easily veriﬁed.
• All ﬁles read by tar would reside within the direc-
tory speciﬁed on the command-line. Again, we need an
application-speciﬁc command-line parser to generate a
synthetic event that captures the value of this directory
argument. Once this is done, our model learns that ﬁles
read by tar are within this directory, or are conﬁguration
ﬁles and shared libraries that get loaded during process
start-up. A policy that allows reading of conﬁguration
ﬁles, libraries, and the ﬁles below the speciﬁed directory
is veriﬁed against this model.
• The only ﬁle written by gzip is obtained by adding a
".gz" sufﬁx to its argument. Similar to the previous two
examples, this property is veriﬁed without any problem1
1Note that
this property holds only if gzip is used with typical
command-line options. Otherwise, one would need a more complex policy
that correlates command-line parameters to the ﬁles accessed by it.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
Training
Program Trace length
(# Syscalls)
(×106)
httpd
sshd
1.75
4.15
Trace length
(# Syscalls)
(×106)
3.10
14.74
Detection
False alarm rates
Base
(×10−5)
Unary
(×10−5)
Binary
(×10−5)
16.6
0.35
0.97
0.79
64.12
0.02
Figure 6. False alarm rates.
In some instances, we could not verify properties in the
manner we expected. For instance, in the case of httpd, we
tried verifying the property that the only ﬁles executed by it
were within a cgi-bin directory. The veriﬁcation succeeded,
but we subsequently realized that this was because the num-
ber of distinct executables seen during the training trace
was small enough that no approximation had taken place.
If more scripts had been executed, then an approximation
using common preﬁx (unary isWithinDir) relation would
have been applied. However, since (a) there were multi-
ple cgi-bin directories, (b) our learning algorithm currently
learns only a single common preﬁx, and (c) the common
preﬁx for these two directories is just /, the model would
only capture that all executed ﬁles are within /. As a re-
sult, veriﬁcation would not succeed in this case. To handle
this problem, our learning algorithm needs to be extended
to handle disjunctions: that certain variables satisfy one of
many binary relations, and/or one of many unary relations.
This is a topic of our continuing research.
5.2. False Alarm Analysis
To determine false positive rates, we trained the system with
system call traces of different lengths. After training, the
system was run in detection mode against a different sys-
tem call trace. To be useful, false alarm analysis should be
performed with live trafﬁc, rather than being based on train-
ing scripts. This limited our choice of applications. In our
laboratory, the two main servers that are well-exercised are
httpd and sshd, so we limited our false alarm analysis to
these two programs.
The results tabulated in Figure 6 show that the false
alarm rates are of the order of 10−4. Note that this cor-
responds to “raw” false alarm rates, i.e., the fraction of sys-
tem calls that caused violations, without any regard to the
nature of violations. In a practical system, these raw alarms
will be further evaluated, based on the nature of violation.
Moreover, series of alarms would be aggregated into one.
These factors typically result in a further signiﬁcant reduc-
tion in false alarm rates. For this reason, it is hard to evalu-
ate the false alarm rates directly.What we can do is to com-
pare them with those reported by previous techniques such
as the FSA method, which is known to produce a modest
false alarm rate.
The addition of unary relations increases the false alarm
rate modestly. Note that binary relations add a very low
false positive rate for sshd, but a much higher rate is ob-
served for httpd. We investigated the reason for this, and
found that this is due to the fact that in the training trace,
a single system call was very rarely executed. Moreover,
for the few values of the parameters to these calls, it turned
out that they bore strong relations with arguments of many
subsequent system calls. However, during detection, this
same system call was executed several more times, and this
broke the relations involving this argument value. In fact,
we found that 95% of the false positives were due to this.
To address this problem, one could add a notion of conﬁ-
dence level with each relation, which can be based on the
number of times it has been veriﬁed during training. We are
currently investigating such an approach to further reduce
false alarms. Such measures may reduce the level of binary
relation false positives to a fraction of the false alarm rate
of the base method.
5.3. Model Precision
Average branching factor metric, originally developed by
Wagner and Dean [30], has been used in the context of in-
trusion detection [14, 13] to measure precision of models.
Basically, the idea is to determine the degree of freedom that
an attacker has at each state of the model. This is roughly
measured by the average number of branches that can be
taken by the program at each state of the automaton during
the program execution. A lower branching factor translates
to improved model precision.
According to the deﬁnition in [30], system calls are par-
titioned into two sets, dangerous and harmless, and the av-
erage branching factor is deﬁned in terms of branches that
correspond to dangerous system calls. However, danger-
ous system calls are considered harmless if their arguments
are known in advance. For example, execv("/bin/ls")
is considered harmless, but
if its argument were not
known, attacker can potentially substitute the argument with
"/bin/sh" to obtain a shell. We applied a similar metric to
compute average branching factor in presence of argument
information. For each dangerous system call, if argument
values are learnt without approximations, then the system
call is considered harmless. If approximations have been
made while learning values, we further check if there are
binary relations present for the corresponding argument or
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:47:23 UTC from IEEE Xplore.  Restrictions apply. 
Program Program
size(KB)
# States/
# Binary
#Transitions Relations
sshd
wu-ftpd
httpd
ﬁnd
tar
gv
gzip
260
435
292
68
156
292
68
228/633
207/492
281/755
29/71
55/181
195/729
29/59
2309
2281
3638
107
647
3637
151
Program Without With argument learning
argument
learning
5.0615
2.1211
0.0711
1.1728
4.7779
Unary
only
0.0127
0.0352
0.0003
0.1615
0.8709
Unary &
Binary Rels
0.0004
0.0064
0.0002
0.0807
0.2032
sshd
wu-ftpd
httpd
ﬁnd
tar
Figure 7. Sample model sizes of the test pro-
grams used in the experiments.
Program
Workload
gzip
gv
tar
ﬁnd
Compress a 12MB ﬁle.
Open and browse through a 500KB post script ﬁle.
Archive 600 ﬁles into a 6MB tar ﬁle.
Search C header ﬁles in a directory tree of 12000 ﬁles.
Figure 8. Average branching factor
% Enforcement overhead
realpath() overhead Detection overhead
0
0
2
41
2
5
3
11
Figure 9. Overhead for intrusion detection
not. If there exists a lossless binary relation, the call is con-
sidered to be harmless. Relation equal is considered to be
lossless. Relations isWithinDir and contains are consid-