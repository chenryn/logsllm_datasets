HTTP response header
HTTP response header
-
-
-
C. Tor Hidden Service analyzer
We focus on improving the crawling performance. While
parallel crawling with multiple Tor browser agents increase
the crawling performance, we tend to collect the redundant
crawling job, because the Tor hidden servers often have
multiple onion addresses.
Fig. 6. Tor Hidden Service analyzer
We have designed the Tor crawler such that it maintains the
minimum set of onion addresses by clustering multiple onion
addresses of the same Tor hidden service. Fig. 6 is Tor hidden
service analyzer, which uses page similarity analyzer for onion
address clustering. The page similarity analyzer consists of a
cosine similarity computation module and an HTTP response
header comparison module. Data for onion address clustering
uses Tor hidden service data from Tor data storage. This data
consists of a Tor hidden service HTML ﬁle and an HTTP
response header.
The cosine similarity computation module parses hidden
service web pages through HTML ﬁles and extracts word
vectors. Then, it computes the cosine similarity between word
vectors to compare web pages. Calculating cosine similarity
for one hidden service with all hidden services signiﬁcantly
increases the amount of unnecessary computation. Generally,
to ﬁnd pages that are similar to one page, need to compare
similarity with all pages. In this case, n operations are per-
formed to obtain the similarity of n pages, and it takes a lot
of time to increase the number of pages to be compared.
We assume that the same hidden services are use the same
page title. Based on this assumption, use the HTML title
tag to avoid calculating the cosine similarity between the
unnecessary HTML ﬁles. First, we classify the collect HTML
ﬁles into hidden services with the same title tag. Next, we
calculate the respective cosine similarities for each HTML set
based on the title tag. If the hidden service has the same title
and the similarity is greater than the threshold (e.g., 80%), we
conclude that the two hidden service web pages are the same.
HTTP response header comparison module compares the
HTTP response header of the hidden service. If there are
two or more hidden services using the same server,
is
assumed that the hidden services will respond to the same
type of HTTP response header. These comparison also uses the
clustered HTML ﬁles to reduce the computational complexity.
The module compares the cosine similarity between the HTTP
response headers collected from the hidden service of the
clustered HTML ﬁle. Through this module, we can determine
the same hidden service provided by the same server. For the
same hidden service using different servers, the value of the
HTTP response header will be signiﬁcantly different.
it
In addition to clustering existing onion addresses, we ﬁnd
new onion addresses. In the Tor network, there are hidden
services that advertise only on the Dark web, not on the
Surface Web. We extract a new onion address from the
collected hidden service page to ﬁnd the hidden service of
this classiﬁcation. The onion address extractor uses the HTML
link parsing module to obtain the hyperlink text from the
Tor hidden service HTML ﬁle. We look up texts by using
regular expressions with random 16 alphabets and numbers
and .Onion TLDs.
Newly found onion address by onion address extractor
are added to Tor data storage to collect data for clustering
pages. Clustered onion addresses through similarity analyzer
is updated on Tor data storage and is used to avoid duplicate
crawling operations in next crawling.
D. Cloud manager
The cloud manager in Fig. 7 controls the launch and
termination of compute instances on the cloud service and
Docker container conﬁguration. In addition, we build a cloud
manager that can communicate with different cloud services.
To increase the crawling performance, we can scale out
compute instances from the cloud service.
The cloud manager controls the cloud service using the
azure API and boto3 API, which are APIs provided by
MicroSoft Azure and Amazon AWS. Through this API, cloud
manager’s modules can check instance information of cloud
service and control service such as creation and deletion
of instance. The cloud conﬁguration module determines the
types and number of cloud instances available based on the
user’s budget and collection period. We calculate the optimal
number of Docker containers that can be executed with the
given resources such as CPU core and RAM. Cloud instance
launcher runs as many instances as the cloud conﬁguration
determines. Then, when the instance runs, it tells the instance’s
Docker manager how many containers it will run and will
manage the speciﬁed number of containers. The onion address
distribution module also distributes the onion address set,
divided by the number of instances, to each instance when
the instance is in the run.
Fig. 7. Cloud manager
IV. PERFORMANCE EVALUATION
A. Colleted data and Hidden Service contents
TABLE III
COLLECTED DATA
Onion address
Live Hidden Service
Collected HTML Page
25,261
2,527
456,739
Table III shows the collected data using the crawler. Crawler
used 12,511 of the addresses collected by the Tor Onion
Address Collector from June 1, 2017 to July 31, 2017 as the
seed onion address. We used three Docker-based Tor crawlers
in each of the ﬁve Cloud Instances for crawling. The Docker-
based Tor crawler uses ﬁve browsers and crawls twice a day
at 00:00 and 12:00. Crawling took place from January 1, 2018
to May 31, 2018.
During the crawl period, we received at least once HTTP
response header value of 200 from 2,527 unique hidden
services and observed that
the web page was open. We
collected 456,739 HTML pages for ﬁve months from these
hidden services. We collected a total of 25,261 onion addresses
including newly discovered addresses.
HIDDEN SERVICE CONTENTS CLASSIFICATION
TABLE IV
Contents Category
Percentage(%)
Legal Hidden Service
Adult/Porno
Black Market
Bitcoin Mixer/Laundary
Drug
Hacking & Cyber Attack
Counterfeit
Weapon & Hitman
Gamble
Unknown
43
11
10
7
4
4
3
2
1
15
Table IV shows the results of classiﬁed contents of 722
hidden services from in 2,527 live hidden services. In order
to determine the proportion of illegal hidden services among
the total content in hidden services, we classiﬁed them into
illegal categories and legal categories. The black market is
distinguished from the counterfeit, drug, weapon & hitman
categories. In this study, black market is a market that sells
a combination of two or more categories of goods. For the
unknown category, it is difﬁcult to specify the content of a
hidden service, or only image ﬁles without text data.
B. Tor Hidden Service crawling time
To look into the performance of the crawler using multiple
browsers, we measured the crawling time using 100 random
onion addresses. We increased from one to ﬁve crawler con-
tainers running on a single cloud instance. We also measured
the average collection time variation when the number of Tor
browsers used by the Docker-based Tor crawler was changed
to 1, 3 and 5.
In Fig. 8, we can know that the crawling time decreases as
the Docker container count increases. Two containers improve
the crawling time by 50% and three containers by 70%
compared to a single container. Five containers reduce the
crawling time by 79%. The throughput in terms of pages
per minute increases linearly when the number of Docker
containers varies.
The page collection rate per minute based on the number of
containers shows that when using three browsers, we collected
ﬁve times more pages than 5 containers in 1 container. The
page collection rate also increases linearly with the number of
containers. The page collection rate for the number of browsers
increases by an average of 10% when using the same number
of containers, compared to using 1 browser with 5 browsers.
Given ﬁve Tor browsing agents on three Docker containers,
we can achieve the crawling time enhancement by 69% com-
pared to a single browser on one Docker container. However,
the reduction in crawling time is reduced from using more than
four containers. Crawling time is reduced by 34% compared
to using three containers in ﬁve containers.
Too many containers and browsers affect the amount of
bandwidth and memory. Therefore, to improve the perfor-
mance of the crawler, it is important to consider the number
of containers and browsers that are optimized for computer
resources.
Fig. 8. Crawling time and page collection rate by the number of browser
agents and Docker containers.
C. Clustering of Tor Hidden Service
TABLE V
CLUSTERING RESULT DATA
Before Clustering
After Clustering
Total Hidden Services
Average Crawling Time (min)
2,527
713
2,014
433
Table V summarizes hidden services clustering results.
We clustered 2,527 unique hidden services. As a result of
classifying the HTML of each hidden service into the title
tag, more than half hidden services with the same title were
detected. Among them, the web hosting page and the title of
the web server’s default pages such as Apache or Nginx are
ﬁltered out. As a result of the ﬁltering, hidden services are
categorized into pages with meaningful duplicate titles, using
at least two onion addresses.
In the page similarity analyzer, the threshold value of the
cosine similarity computation module is set to 80% and the
threshold value of the header similarity is set to 90% in the
HTTP response header comparison module. As a result, after
clustering, the total address is reduced by 21% from 2,527 to
2,014.
We tried to measure the accuracy of the clustering, but we
can not conﬁrm that the collected hidden service is actually the
same or different site. Therefore, only the recall was measured.
The hidden services judged to be the same in the clustering
target pages were manually labeled. The recall showed 92%
when the cosine similarity threshold was 80%.
We compare the crawling time using the clustered address
set and the original address set. The instance used is the same
as the Tor hidden service crawling time experiment, and each
instance uses ﬁve browsers in three containers. The average
crawling time measured in each instance is 713 minutes for the
original address set and 433 minutes for the clustered address
set. Crawling time with clustered addresses was 39% faster.
D. Tor Hidden Service dynamics
Fig. 9. Hidden Service live state frequency during the period
We collected 456,739 HTML pages through crawling twice
a day for ﬁve months. We analyzed collected hidden service
HTML pages and crawler’s log to ﬁnd the live state hidden
service. We are trying to ﬁgure out the Tor hidden service
dynamics by analyzing the hidden service’s live state. We
observed live days of hidden services that have been live state
for at least one day.
Fig. 9 shows the CDF for the day when the hidden services
were observed in the live state for 5 months. Typical surface
webs have a lifetime of more than 100 days[14]. However,
52% of hidden services have 100 days or less lifetime. The
long-term web services for typical surface webs are always
accessible during the entire observation period. But with
hidden services, we can always access to just 7% of hidden
services. A large number of hidden services are not always
accessible. We considered hidden services that run for more
than 145 days for a total of 151 days as a long-term hidden
service. These are 32% of the total hidden services.
In Fig. 9, we consider short-term hidden services with a
live state of less than a week as a web service with the
unusual lifetime. The short-term hidden services occupy for
7% of the total hidden services. The illegal hidden services
that appear in short-term hidden services are 4% of the total,
and the legal hidden services are 2%. In contrast, the long-
term hidden services have 18% illegal hidden services and
14% legal hidden services. As the operation of hidden services
becomes longer, the number of difference between illegally
hidden services and legal hidden services to increase.
The short-term hidden service contents have a high percent-
age of illegal services such as adult/porno or black market that
can be easily opened or closed immediately after the transac-
tion. In contrast, the long-term hidden services have a wide
variety of illegal services compared to the short-term hidden
service. For example, gamble, counterfeit and hacking&cyber
attack does not appear in short term hidden services. These
contents are require many customers or professional skills to
operate.
V. CONCLUSION
In this paper, we present an efﬁcient Tor hidden service
crawling method that is based on the virtualization Docker
on the cloud service. To maximize the utilization, we used
multiple Tor browsers for a Docker container. In addition, we
have analyzed the Tor hidden services ad found that many
hidden services use multiple onion address. Therefore, we can
decrease the crawling time by removing the redundant set of
onion addresses for the same hidden service. Based on our Tor
crawling tool, we can observe the overall Tor hidden service
trends for ﬁve months.
In addition, we observed the accessible hidden services
for 5 months and identiﬁed their lifetime and content. As a
result, we found that the percentage of illegal services such as
adult/porno and black market was higher in the hidden services
actually in service.
ACKNOWLEDGMENTS
This research was supported by the MSIT(Ministry of
Science and ICT), Korea, under the ITRC(Information Tech-
nology Research Center) support program(IITP-2018-2016-0-
00304) supervised by the IITP(Institute for Information &
communications Technology Promotion)
REFERENCES
[1] Giacomo Marciani, Michele Porretta, Matteo Nardelli, Giuseppe F. Ital-
iano. A Data Streaming Approach to Link Mining in Criminal Networks.
In: Future Internet of Things and Cloud Workshops (FiCloudW), 2017
5th International Conference on. IEEE, 2017. p. 138-143.
[2] Andriy Panchenko, Asya Mitseva, Martin Henze, Fabian Lanze, Klaus
Wehrle, Thomas Engel. Analysis of Fingerprinting Techniques for Tor
Hidden Services. In: Proceedings of the 2017 on Workshop on Privacy
in the Electronic Society. ACM, 2017. p. 165-175.
[3] MERKEL, Dirk. Docker: lightweight linux containers for consistent
development and deployment. Linux Journal, 2014, 2014.239: 2.
[4] THOMAS, Matthew; MOHAISEN, Aziz. Measuring the Leakage of
Onion at the Root. ACM WPES, 2014.
[5] Zhen Ling, Junzhou Luo, Kui Wu, Xinwen Fu. Protocol-level hidden
server discovery. In: INFOCOM, 2013 Proceedings IEEE. IEEE, 2013.
p. 1043-1051.
[6] Alex Biryukov, Ivan Pustogarov, Fabrice Thill, Ralf-Philipp Weinmann.
Content and popularity analysis of Tor Hidden Services. In: Distributed
Computing Systems Workshops (ICDCSW), 2014 IEEE 34th Interna-
tional Conference on. IEEE, 2014. p. 188-193.
[7] Ahmed T Zulkarnine, Richard Frank, Bryan Monk, Julianna Mitchell,
Garth Davies. Surfacing collaborated networks in dark web to ﬁnd illicit
and criminal content. In: Intelligence and Security Informatics (ISI),
2016 IEEE Conference on. IEEE, 2016. p. 109-114.
[8] SANCHEZ-ROLA, Iskander; BALZAROTTI, Davide; SANTOS, Igor.
The Onions have eyes: A comprehensive structure and privacy analysis
of tor Hidden Services. In: Proceedings of the 26th International Confer-
ence on World Wide Web. International World Wide Web Conferences
Steering Committee, 2017. p. 1251-1260.
[9] BARAVALLE, Andres; LOPEZ, Mauro Sanchez; LEE, Sin Wee. Mining
the Dark Web: Drugs and Fake Ids. In: Data Mining Workshops
(ICDMW), 2016 IEEE 16th International Conference on. IEEE, 2016.
p. 350-356.
[10] Metrics.torproject.org.
(2018). Onion Service - Tor Metrics.
[on-
line] Available
at: https://metrics.torproject.org/hidserv-dir-Onions-
seen.html?start=2015-01-01&end=2018-05-31 [Accessed 31 May 2018].
[11] SANATINIA, Amirali; NOUBIR, Guevara. HOnions: Towards detection
and identiﬁcation of misbehaving tor hsdirs. In: Workshop on Hot Topics
in Privacy Enhancing Technologies (HotPETs). 2016.
[12] Rebekah Overdorf, Mark Juarez, Gunes Acar, Rachel Greenstadt, Clau-
dia Diaz. How Unique is Your. Onion?: An Analysis of the Finger-
printability of Tor Onion Services. In: Proceedings of the 2017 ACM
SIGSAC Conference on Computer and Communications Security. ACM,
2017. p. 2021-2036.
[13] Jonghyeon Park, Youngseok Lee. POSTER: Probing Tor Hidden Service
with Dockers. In: Proceedings of the 2017 ACM SIGSAC Conference
on Computer and Communications Security. ACM, 2017. p. 2571-2573.
[14] Internet users per 100 inhabitants, 2001-2011: ITU Statistics. Avail-
able from: http://www.webcitation.org/6IV8qT1QC (Archived by We-
bCite).[Accessed 8 Sept. 2018].