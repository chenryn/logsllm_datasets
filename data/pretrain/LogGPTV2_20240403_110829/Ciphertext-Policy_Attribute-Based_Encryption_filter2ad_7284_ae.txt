1997.
[29] N. P. Smart. Access control using pairing based cryp-
tography. In CT-RSA, pages 111{121, 2003.
[30] T. Yu and M. Winslett. A uni(cid:12)ed scheme for resource
protection in automated trust negotiation. In IEEE
Symposium on Security and Privacy, pages 110{122,
2003.
[31] R. Zippel. Probabilistic algorithms for sparse polyno-
mials.
In E. W. Ng, editor, EUROSAM, volume 72
of Lecture Notes in Computer Science, pages 216{226.
Springer, 1979.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:20 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007A Security Proof
In this section, we use the generic bilinear group
model of [6, 28] and the random oracle model [2] to
argue that no e(cid:14)cient adversary that acts generically
on the groups underlying our scheme can break the se-
curity of our scheme with any reasonable probability.
At an intuitive level, this means that if there are any
vulnerabilities in our scheme, then these vulnerabilities
must exploit speci(cid:12)c mathematical properties of ellip-
tic curve groups or cryptographic hash functions used
when instantiating our construction.
While from a security standpoint, it would be prefer-
able to have a proof of security that reduces the
problem of breaking our scheme to a well-studied
complexity-theoretic problem, there is reason to believe
that such reductions will only exist for more complex
(and less e(cid:14)cient) schemes than the one we give here.
We also stress that ours is the (cid:12)rst construction which
o(cid:11)ers the security properties we are proposing here; we
strongly encourage further research that can place this
kind of security on a (cid:12)rmer theoretical foundation.
The generic bilinear group model. We follow [6]
here: We consider two random encodings  0;  1 of the
additive group Fp, that is injective maps  0;  1 : Fp !
f0; 1gm, where m > 3 log(p). For i = 0; 1 we write Gi =
f i(x) : x 2 Fpg. We are given oracles to compute
the induced group action on G0; G1 and an oracle to
compute a non-degenerate bilinear map e : G0 (cid:2) G0 !
G1. We are also given a random oracle to represent the
hash function H. We refer to G0 as a generic bilinear
group.
The following theorem gives a lower bound on the
advantage of a generic adversary in breaking our CP-
ABE scheme.
Theorem 1 Let  0;  1; G0; G1 be de(cid:12)ned as above.
For any adversary A, let q be a bound on the total num-
ber of group elements it receives from queries it makes
to the oracles for the hash function, groups G0 and G1,
and the bilinear map e, and from its interaction with
the CP-ABE security game. Then we have that the ad-
vantage of the adversary in the CP-ABE security game
is O(q2=p).
Proof. We (cid:12)rst make the following standard obser-
vation, which follows from a straightforward hybrid ar-
gument: In the CP-ABE security game, the challenge
ciphertext has a component ~C which is randomly either
M0e(g; g)(cid:11)s or M1e(g; g)(cid:11)s. We can instead consider a
modi(cid:12)ed game in which ~C is either e(g; g)(cid:11)s or e(g; g)(cid:18),
where (cid:18) is selected uniformly at random from Fp, and
the adversary must decide which is the case. It is clear
that any adversary that has advantage (cid:15) in the CP-
ABE game can be transformed into an adversary that
has advantage at least (cid:15)=2 in the modi(cid:12)ed CP-ABE
game. (To see this consider two hybrids: one in which
the adversary must distinguish between M0e(g; g)(cid:11)s
and e(g; g)(cid:18); another in which it must distinguish be-
tween e(g; g)(cid:18) and M1e(g; g)(cid:11)s. Clearly both of these
are equivalent to the modi(cid:12)ed game above.) From now
on, we will bound the adversary’s advantage in the
modi(cid:12)ed game.
We now introduce some notation for the simulation
of the modi(cid:12)ed CP-ABE game. Let g =  0(1) (we will
write gx to denote  0(x), and e(g; g)y to denote  1(y)
in the future).
At setup time, the simulation chooses (cid:11); (cid:12) at ran-
dom from Fp (which we associate with the integers from
0 to p (cid:0) 1). Note that if (cid:12) = 0, an event that happens
with probability 1=p, then setup is aborted, just as it
would be in the actual scheme. The public parame-
ters h = g(cid:12), f = g1=(cid:12), and e(g; g)(cid:11) are sent to the
adversary.
When the adversary (or simulation) calls for the
evaluation of H on any string i, a new random value
ti is chosen from Fp (unless it has already been cho-
sen), and the simulation provides gti as the response
to H(i).
When the adversary makes its j’th key generation
query for the set Sj of attributes, a new random value
r(j) is chosen from Fp, and for every i 2 Sj, new ran-
dom values r(j)
are chosen from Fp. The simulator
then computes: D = g((cid:11)+r(j))=(cid:12) and for each i 2 Sj,
we have Di = gr(j)+tir(j)
. These values
are passed onto the adversary.
i = gr(j)
i
i
and D0
i
When the adversary asks for a challenge, giving two
messages M0; M1 2 G1, and the access tree A, the sim-
ulator does the following. First, it chooses a random s
from Fp. Then it uses the linear secret sharing scheme
associated with A (as described in Section 4) to con-
struct shares (cid:21)i of s for all relevant attributes i. We
stress again that the (cid:21)i are all chosen uniformly and
independently at random from Fp subject to the lin-
ear conditions imposed on them by the secret sharing
scheme. In particular, the choice of the (cid:21)i’s can be per-
fectly simulated by choosing ‘ random values (cid:22)1; : : : (cid:22)‘
uniformly and independently from Fp, for some value
of ‘, and then letting the (cid:21)i be (cid:12)xed public linear com-
binations of the (cid:22)k’s and s. We will often think of
the (cid:21)i as written as such linear combinations of these
independent random variables later.
Finally, the simulation chooses a random (cid:18) 2 Fp,
and constructs the encryption as follows: ~C = e(g; g)(cid:18)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:20 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007titi0
tir(j)
i0
(cid:21)i(cid:21)i0
(cid:21)i
ti(cid:21)i
i r(j 0)
r(j)
i0
(cid:21)iti0
ti
ti(cid:21)i(cid:21)i0
titi0 (cid:21)i(cid:21)i0
(r(j) + tir(j)
r(j)
i
i
)(r(j) + ti0 r(j 0)
i0
)
titi0(cid:21)i0
(cid:11) + r(j)
(cid:21)i0 r(j) + (cid:21)i0tir(j)
ti(cid:21)ir(j)
(r(j) + tir(j)
s
i0
i + titi0(cid:21)ir(j)
i
i0
)r(j 0)
i
tir(j) + titi0 r(j)
i0
(cid:11)s + sr(j)
(cid:21)ir(j)
ti(cid:21)ir(j)
i0
r(j) + tir(j)
i
i
Table 1. Possible query types from the adversary.
and C = hs. For each relevant attribute i, we have
Ci = g(cid:21)i , and C 0
i = gti(cid:21)i . These values are sent to the
adversary.
(Note, of course, that if the adversary asks for a de-
cryption key for a set of attributes that pass the chal-
lenge access structure, then the simulation does not
issue the key; similarly if the adversary asks for a chal-
lenge access structure such that one of the keys already
issued pass the access structure, then the simulation
aborts and outputs a random guess on behalf of the
adversary, just as it would in the real game.)
We will show that with probability 1 (cid:0) O(q2=p),
taken over the randomness of the the choice of variable
values in the simulation, the adversary’s view in this
simulation is identically distributed to what its view
would have been if it had been given ~C = e(g; g)(cid:11)s.
We will therefore conclude that the advantage of the
adversary is at most O(q2=p), as claimed.
When the adversary makes a query to the group ora-
cles, we may condition on the event that (1) the adver-
sary only provides as input values it received from the
simulation, or intermediate values it already obtained
from the oracles, and (2) there are p distinct values in
the ranges of both (cid:30)0 and (cid:30)1. (This event happens with
overwhelming probability 1(cid:0)O(1=p).) As such, we may
keep track of the algebraic expressions being called for
from the oracles, as long as no \unexpected collisions"
happen. More precisely, we think of an oracle query
as being a rational function (cid:23) = (cid:17)=(cid:24) in the variables
(cid:18); (cid:11); (cid:12); ti’s, r(j)’s, r(j)
’s, s, and (cid:22)k’s. An unexpected
collision would be when two queries corresponding to
two distinct formal rational functions (cid:17)=(cid:24) 6= (cid:17)0=(cid:24)0 but
where due to the random choices of these variables’ val-
ues, we have that the values of (cid:17)=(cid:24) and (cid:17)0=(cid:24)0 coincide.
We now condition on the event that no such unex-
pected collisions occur in either group G0 or G1. For
any pair of queries (within a group) corresponding to
distinct rational functions (cid:17)=(cid:24) and (cid:17)0=(cid:24)0, a collision oc-
curs only if the non-zero polynomial (cid:17)(cid:24)0 (cid:0) (cid:24)(cid:17)0 evaluates
to zero. Note that the total degree of (cid:17)(cid:24)0 (cid:0) (cid:24)(cid:17)0 is in our
case at most 5. By the Schwartz-Zippel lemma [25, 31],
i
the probability of this event is O(1=p). By a union
bound, the probability that any such collision happens
is at most O(q2=p). Thus, we can condition on no such
collision happening and still maintain 1 (cid:0) O(q2=p) of
the probability mass.
Now we consider what the adversary’s view would
have been if we had set (cid:18) = (cid:11)s. We will show that
subject to the conditioning above, the adversary’s view
would have been identically distributed. Since we are
in the generic group model where each group element’s
representation is uniformly and independently chosen,
the only way that the adversary’s view can di(cid:11)er in the
case of (cid:18) = (cid:11)s is if there are two queries (cid:23) and (cid:23) 0 into
G1 such that (cid:23) 6= (cid:23)0 but (cid:23)j(cid:18)=(cid:11)s = (cid:23)0j(cid:18)=(cid:11)s. We will
show that this never happens. Suppose not.
Recall that since (cid:18) only occurs as e(g; g)(cid:18), which
lives in G1, the only dependence that (cid:23) or (cid:23) 0 can have
on (cid:18) is by having some additive terms of the form (cid:13) 0(cid:18),
where (cid:13)0 is a constant. Therefore, we must have that
(cid:23) (cid:0) (cid:23)0 = (cid:13)(cid:11)s (cid:0) (cid:13)(cid:18), for some constant (cid:13) 6= 0. We can
then arti(cid:12)cially add the query (cid:23) (cid:0) (cid:23) 0 + (cid:13)(cid:18) = (cid:13)(cid:11)s to
the adversary’s queries. But we will now show that the
adversary can never construct a query for e(g; g)(cid:13)(cid:11)s
(subject to the conditioning we have already made),
which will reach a contradiction and establish the the-
orem.
What is left now is to do a case analysis based on
the information given to the adversary by the simula-
tion. For sake of completeness and ease of reference for
the reader, in Table 1 we enumerate over all rational
function queries possible into G1 by means of the bilin-
ear map and the group elements given the adversary in
the simulation, except those in which every monomial
involves the variable (cid:12), since (cid:12) will not be relevant to
constructing a query involving (cid:11)s. Here the variables i
and i0 are possible attribute strings, and the variables
j and j0 are the indices of secret key queries made by
the adversary. These are given in terms of (cid:21)i’s, not
(cid:22)k’s. The reader may check the values given in Table 1
against the values given in the simulation above.
In the group G1, in addition to the polynomials in
the table above, the adversary also has access to 1 and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:20 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007cancel this term. Therefore, any adversary query
polynomial of this form cannot be of the form (cid:13)(cid:11)s.
(cid:3)
(cid:11). The adversary can query for arbitrary linear combi-
nations of these, and we must show that none of these
polynomials can be equal to a polynomial of the form
(cid:13)(cid:11)s. Recall that (cid:13) 6= 0 is a constant.
As seen above, the only way that the adversary
can create a term containing (cid:11)s is by pairing s(cid:12) with
((cid:11) + r(j))=(cid:12) to get the term (cid:11)s + sr(j). In this way,
the adversary could create a query polynomial contain-
ing (cid:13)(cid:11)s +Pj2T (cid:13)jsr(j), for some set T and constants
(cid:13); (cid:13)j 6= 0.
In order for the adversary to obtain a query poly-
nomial of the form (cid:13)(cid:11)s, the adversary must add other
linear combinations in order to cancel the terms of the
form Pj2T (cid:13)jsr(j).
We observe (by referencing the table above) that
the only other term that the adversary has access to
that could involve monomials of the form sr(j) are ob-
tained by pairing r(j) + tir(j)
i with some (cid:21)i0 , since the
(cid:21)i0 terms are linear combinations of s and the (cid:22)k’s.
In this way, for sets T 0
j and constants (cid:13)(i;j;i0) 6= 0,
the adversary can construct a query polynomial of the
form:
(cid:13)(cid:11)s+Xj2T
0
@(cid:13)jsr(j) + X(i;i0)2T 0
j
i (cid:17)1
(cid:13)(i;j;i0)(cid:16)(cid:21)i0 r(j) + (cid:21)i0 tir(j)
A+other terms
Now, to conclude this proof, we do the following case
analysis:
Case 1 There exists some j 2 T such that the set of secret
jg do not allow for
shares Lj = f(cid:21)i0 : 9i : (i; i0) 2 T 0
the reconstruction of the secret s.
If this is true, then the term sr(j) will not be
canceled, and so the adversary’s query polynomial
cannot be of the form (cid:13)(cid:11)s.
Case 2 For all j 2 T the set of secret shares Lj = f(cid:21)i0 :
jg do allow for the reconstruction of
9i : (i; i0) 2 T 0
the secret s.
Fix any j 2 T . Consider Sj, the set of attributes
belonging to the j’th adversary key request. By
the assumption that no requested key should pass
the challenge access structure, and the properties
of the secret sharing scheme, we know that the set
L0
j = f(cid:21)i : i 2 Sjg cannot allow for the reconstruc-
tion of s.
Thus, there must exist at least one share (cid:21)i0 in Lj
such that (cid:21)i0 is linearly independent of L0
j when
written in terms of s and the (cid:22)k’s. By the case
analysis, this means that in the adversary’s query
there is a term of the form (cid:21)i0 tir(j)
for some i 2 Sj.
However, (examining the table above), there is no
term that the adversary has access to that can
i
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:20 UTC from IEEE Xplore.  Restrictions apply. 
2007 IEEE Symposium on Security and Privacy(SP'07)0-7695-2848-1/07 $20.00  © 2007