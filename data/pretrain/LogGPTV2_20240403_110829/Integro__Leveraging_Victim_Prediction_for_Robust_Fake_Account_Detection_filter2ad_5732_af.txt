assigned high weights, leading to a lower AUC in user ranking.
Maintenance. While an attacker does not control real accounts
nor their activities, it can still trick users into befriending fakes.
In order to achieve a high-quality ranking, the victim classiﬁer
should be regularly retrained to capture new and changing user
behavior in terms of susceptibility to social inﬁltration. This is,
in fact, the case for supervised machine learning when applied
to computer security problems [8]. Also, as the ranking scheme
13
0 10 20 30 40 50 60 70 80 90 100 1 2 3 4 5 6 7 8 9 Percentage(of(fakes((%)(20K(node(interval(in(ranked(list(IntegroYRF(SybilRank(0 10 20 30 40 50 60 70 80 90 100 0 10 20 30 40 50 Percentage(of(fakes((%)(20K(node(interval(in(ranked(list(IntegroYRF(SybilRank(0 2 4 6 8 10 12 14 10 20 30 40 50 Percentage(of(fakes((%)(20K(node(interval(in(ranked(list(IntegroYRF(SybilRank(0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 100 200 300 400 500 600 CDF(Number(of(friends((degree)(Fake(Real(and is designed to detect automated fake accounts that be-
friend many victims for subsequent attacks. Íntegro has been
deployed at Tuenti along side a feature-based detection system
and a user-based abuse reporting system.
IX. CONCLUSION
OSNs today are faced with the problem of detecting fake
accounts in a highly adversarial environment. The problem
is becoming more challenging as such accounts have become
sophisticated in cloaking their operation with patterns resem-
bling real user behavior. In this paper, we presented Íntegro,
a scalable defense system that helps OSN operators to detect
fake accounts using a meaningful user ranking scheme.
Our evaluation results show that SybilRank, the state-of-
the-art in fake account detection, is ineffective when the fakes
inﬁltrate the target OSN by befriending a large number of real
users. Íntegro, however, has proven more resilient to this effect
by leveraging in a novel way the knowledge of benign victim
accounts that befriend fakes . We have implemented Íntegro on
top of standard data processing platforms, Mahout and Giraph,
which are scalable and easy to deploy in modern data centers.
In fact, Tuenti, the largest OSN in Spain with more than 15M
active users, has deployed our system in production to thwart
fakes in the wild with at least 10 time more precision.
X. ACKNOWLEDGMENT
We would like to thank our shepherd, Gianluca Stringhini,
and our colleagues for their help and feedback on an earlier
version of this paper. The ﬁrst author is thankful to the Univer-
sity of British Columbia for a generous doctoral fellowship.
REFERENCES
[1]
J. R. Douceur, “The sybil attack,” in 1st International Workshop on
Peer-to-Peer Systems. Springer-Verlag, 2002, pp. 251–260.
[2] Facebook, “Quarterly earning reports,” Jan 2014. [Online]. Available:
http://goo.gl/YujtO
[3] CBC, “Facebook shares drop on news of fake accounts,” Aug 2012.
[Online]. Available: http://goo.gl/6s5FKL
[4] K. Thomas and et al., “Suspended accounts in retrospect: an analysis
of Twitter spam,” in Proc. IMC’11. ACM, 2011, pp. 243–258.
[5] G. Yan and et al., “Malware propagation in online social networks:
nature, dynamics, and defense implications,” in Proc. ASIACCS’11.
ACM, 2011, pp. 196–206.
J. Ratkiewicz and et al., “Truthy: mapping the spread of astroturf in
microblog streams,” in Proc. WWW’11. ACM, 2011, pp. 249–252.
[6]
[7] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu, “The
socialbot network: when bots socialize for fame and money,” in Proc.
ACSAC’11. ACM, 2011, pp. 93–102.
[8] T. Stein, E. Chen, and K. Mangla, “Facebook immune system,” in
Proceedings of the 4th Workshop on Social Network Systems. ACM,
2011, pp. 8–14.
[9] L. Alvisi, A. Clement, A. Epasto, U. Sapienza, S. Lattanzi, and A. Pan-
conesi, “SoK: The evolution of sybil defense via social networks,” In
Proceedings of the IEEE Symposium on Security and Privacy, 2013.
[10] L. Bilge, T. Strufe, D. Balzarotti, and E. Kirda, “All your contacts are
belong to us: automated identity theft attacks on social networks,” in
Proc. WWW’09. ACM, 2009, pp. 551–560.
[11] C. Wagner, S. Mitter, C. Körner, and M. Strohmaier, “When social bots
attack: Modeling susceptibility of users in online social networks,” in
WWW Workshop on Making Sense of Microposts, vol. 12, 2012.
[12] M. N. Ko, G. P. Cheek, M. Shehab, and R. Sandhu, “Social-networks
connect services,” Computer, vol. 43, no. 8, pp. 37–43, 2010.
(a) Mahout
(b) Giraph
Fig. 9: System scalability on both platforms. In (a), the execution time
includes the time to train an RF classiﬁer and compute a vulnerability
score for each node in the graph. In (b), the execution time includes
the time to weight the graph, rank nodes, and ﬁnally sort them.
is sensitive to seed-targeting attacks, the set of trusted accounts
should be regularly updated and validated in order to reduce
the negative impact of these attacks, even if they are unlikely
to occur or succeed in practice, as discussed in Section IV-D.
Impact. By using Íntegro, Tuenti requires nearly 67 man hours
to manually validate the 20K lowest ranking user accounts, and
discover about 19K fake accounts instead of 8.6K fakes with
SybilRank. With its user-based abuse reporting system that has
5% hit rate, and assuming all fakes get reported, Tuenti would
need 1,267 man hours instead to discover 19K fake accounts.
This improvement has been useful to both Tuenti and its users.
VIII. LIMITATIONS
We next outline two design limitations which are inherited
from SybilRank [13] and similar ranking schemes [34]:
• Íntegro’s design is limited to only undirected social graphs.
In other words, OSNs whose users declare lateral relationships
are not expected to beneﬁt from our proposal. This is the
case because directed graphs, in general, have a signiﬁcantly
smaller mixing time than their undirected counterparts [62],
which means a random walk on such graphs will converge in
a much small number of steps, rendering short random walks
unsuitable for robust user ranking.
• Íntegro delays the consideration of new user accounts. This
means that an OSN operator might miss the chance to detect
fakes at their early life-cycle. However, as shown in Figure 7a,
only 7% of new users who joined Tuenti in the last month
had more than 46 friends. To estimate the number of fakes in
new accounts, we picked 100 accounts at random for manual
veriﬁcation. We found that only 6% of these accounts were
fake, and the most successful fake account had 103 victims.
In practice, the decision of whether to exclude these account
is operational, and it depends on the actions taken on low-
ranking users. For example, an operator can enforce abuse
mitigation technique, as discussed in Section II-C, against low-
ranking users, where false positives can negatively affect user
experience but slow down fake accounts that just joined the
network. This is a security/usability trade-off which we leave to
the operator to manage. Alternatively, the operator can use fake
account detection systems that are designed to admit legitimate
new users using, for example, a vouching process [63].
Íntegro is not a stand-alone fake account detection system.
It is intended to complement existing abuse detection systems
14
1.0 1.5 2.0 2.5 3.0 3.5 4.0 10 60 110 160 ExecuSon(Sme((minutes)(Number(of(nodes((millions)(0 5 10 15 20 25 10 60 110 160 ExecuSon(Sme((minutes)(Number(of(nodes((millions)([13] Q. Cao, M. Sirivianos, X. Yang, and T. Pregueiro, “Aiding the detection
of fake accounts in large scale social online services,” in Proc. NSDI’12.
USENIX Association, 2012, pp. 15–15.
[14] S. Yardi, N. Feamster, and A. Bruckman, “Photo-based authentication
using social networks,” in Proceedings of the ﬁrst workshop on Online
social networks. ACM, 2008, pp. 55–60.
[15] S. D. Kamvar and et al., “The EigenTrust algorithm for reputation
management in P2P networks,” in Proceedings of 12th international
conference on World Wide Web. ACM, 2003, pp. 640–651.
[16] H. Yu, M. Kaminsky, P. B. Gibbons, and A. Flaxman, “Sybilguard:
defending against sybil attacks via social networks,” ACM SIGCOMM
Computer Communication Review, vol. 36, no. 4, pp. 267–278, 2006.
[17] H. Yu and et al., “Sybillimit: A near-optimal social network defense
against sybil attacks,” in Proc. S&P’08.
IEEE, 2008, pp. 3–17.
[18] G. Danezis and P. Mittal, “Sybilinfer: Detecting sybil nodes using social
networks.” in Proceedings of the 9th Annual Network & Distributed
System Security Symposium. ACM, 2009.
[19] B. Viswanath, A. Post, K. P. Gummadi, and A. Mislove, “An analysis
of social network-based sybil defenses,” in Proceedings of ACM SIG-
COMM Computer Communication Review. ACM, 2010, pp. 363–374.
[20] N. Tran, J. Li, L. Subramanian, and S. S. Chow, “Optimal sybil-
resilient node admission control,” in INFOCOM, 2011 Proceedings
IEEE.
J. Dean and S. Ghemawat, “Mapreduce: simpliﬁed data processing on
large clusters,” Comm. of ACM, vol. 51, no. 1, pp. 107–113, 2008.
IEEE, 2011, pp. 3218–3226.
[21]
[22] G. Malewicz and et al., “Pregel: a system for large-scale graph
processing,” in Proceedings of the 2010 ACM SIGMOD International
Conference on Management of data. ACM, 2010, pp. 135–146.
[23] Y. Boshmaf, I. Muslukhov, K. Beznosov, and M. Ripeanu, “Design and
analysis of a social botnet,” Computer Networks, vol. 57, no. 2, pp.
556–578, 2013.
[24] T. Hwang, I. Pearce, and M. Nanis, “Socialbots: Voices from the fronts,”
interactions, vol. 19, no. 2, pp. 38–45, 2012.
[25] M. Egele and et al., “COMPA: Detecting compromised accounts on
social networks.” in Proc. NDSS’13, 2013.
[26] M. Motoyama and et al., “Dirty jobs: The role of freelance labor in web
service abuse,” in Proceedings of the 20th USENIX Security Symposium.
USENIX Association, 2011, pp. 14–14.
[27] Z. Yang, C. Wilson, X. Wang, T. Gao, B. Y. Zhao, and Y. Dai,
“Uncovering social network sybils in the wild,” in Proceedings of 2011
ACM Internet Measurement Csonference. ACM, 2011, pp. 259–268.
[28] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting spammers on
social networks,” in Proceedings of the 26th Annual Computer Security
Applications Conference. ACM, 2010, pp. 1–9.
[29] G. Wang and et al., “You are how you click: Clickstream analysis
the 22nd USENIX Security
for sybil detection,” in Proceedings of
Symposium. USENIX Association, 2013, pp. 1–8.
[30] G. Karypis and V. Kumar, “Multilevel k-way partitioning scheme
for irregular graphs,” Journal of Parallel and Distributed computing,
vol. 48, no. 1, pp. 96–129, 1998.
J. Tygar, “Adversarial machine learning.” IEEE Internet Computing,
vol. 15, no. 5, 2011.
[31]
[32] D. Lowd and C. Meek, “Adversarial learning,” in Proceedings of the
11th ACM SIGKDD. ACM, 2005, pp. 641–647.
[33] Y. Boshmaf and et al., “Key challenges in defending against malicious
socialbots,” in Proc. LEET’12, vol. 12, 2012.
[34] H. Yu, “Sybil defenses via social networks: a tutorial and survey,” ACM
SIGACT News, vol. 42, no. 3, pp. 80–101, 2011.
[35] B. Viswanath and et al., “Exploring the design space of social network-
the 4th International
IEEE, 2012,
based sybil defenses,” in In Proceedings of
Conference on Communication Systems and Networks.
pp. 1–8.
[36] Y. Boshmaf and et al., “Graph-based sybil detection in social and
information systems,” in Proc. ASONAM’13.
J. Leskovec, K. Lang, A. Dasgupta, and M. Mahoney, “Community
structure in large networks: Natural cluster sizes and the absence of
large well-deﬁned clusters,” Internet Mathematics, vol. 6, no. 1, pp.
29–123, 2009.
IEEE, 2013.
[37]
[38] S. Fortunato, “Community detection in graphs,” Physics Reports, vol.
486, no. 3, pp. 75–174, 2010.
[39] A. Mislove and et al., “You are who you know: inferring user proﬁles in
online social networks,” in Proc. WSDM’10. ACM, 2010, pp. 251–260.
[40] G. Wang, M. Mohanlal, C. Wilson, X. Wang, M. Metzger, H. Zheng,
and B. Y. Zhao, “Social turing tests: Crowdsourcing sybil detection,”
in Proc. NDSS’13. ACM, 2013.
[41] S. Ghosh and et al., “Understanding and combating link farming in the
twitter social network,” in Proceedings of 21st international conference
on World Wide Web. ACM, 2012, pp. 61–70.
[42] A. Elyashar, M. Fire, D. Kagan, and Y. Elovici, “Homing socialbots:
intrusion on a speciﬁc organization’s employee using socialbots,” in
Proc. ASONAM’13. ACM, 2013, pp. 1358–1365.
[43] G. Stringhini and et al., “Follow the green: growth and dynamics in
twitter follower markets,” in Proc. IMC’13. ACM, 2013, pp. 163–176.
[44] C. Yang and et al., “Analyzing spammers’ social networks for fun and
proﬁt: a case study of cyber criminal ecosystem on twitter,” in Proc. of
WWW’12. ACM, 2012, pp. 71–80.
[45] D. A. Spielman and S.-H. Teng, “Nearly-linear time algorithms for
graph partitioning, graph sparsiﬁcation, and solving linear systems,” in
Proc. TC’04. ACM, 2004, pp. 81–90.
[46] L. Breiman, “Random forests,” Machine learning, vol. 45, no. 1, pp.
5–32, 2001.
[47] T. Hastie, R. Tibshirani, and J. Friedman, The elements of statisti-
cal learning: Data mining, inference, and prediction, second edition.
Springer, 2009.
[48] Z. Gyöngyi, H. Garcia-Molina, and J. Pedersen, “Combating web spam
with trustrank,” in Proceedings of VLDB, 2004, pp. 576–587.
[49] G. H. Golub and H. A. Van der Vorst, “Eigenvalue computation in the
20th century,” Journal of Computational and Applied Mathematics, vol.
123, no. 1, pp. 35–65, 2000.
[50] E. Behrends, Introduction to Markov chains with special emphasis on
rapid mixing. Vieweg, 2000, vol. 228.
[51] M. Dellamico and Y. Roudier, “A measurement of mixing time in social
networks,” in Proceedings of the 5th International Workshop on Security
and Trust Management, Saint Malo, France, 2009.
[52] A. Mohaisen, A. Yun, and Y. Kim, “Measuring the mixing time of
social graphs,” in Proceedings of the 10th annual conference on Internet
measurement. ACM, 2010, pp. 383–389.
J. Leskovec, K. J. Lang, A. Dasgupta, and M. W. Mahoney, “Statistical
properties of community structure in large social and information
networks,” in Proc. WWW’08. ACM, 2008, pp. 695–704.
[53]
[54] V. Blondel, J. Guillaume, R. Lambiotte, and E. Lefebvre, “Fast unfold-
ing of communities in large networks,” Journal of Statistical Mechanics:
Theory and Experiment, vol. 2008, no. 10, 2008.
[55] M. E. Newman, “Modularity and community structure in networks,”
Proceedings of the National Academy of Sciences, vol. 103, no. 23, pp.
8577–8582, 2006.
[56] Y. Boshmaf, D. Logothetis, G. Siganos, J. Lería, J. Lorenzo, M. Ri-
peanu, and K. Beznosov, “Íntegro: Leveraging victim prediction for
robust fake account detection in OSNs,” LERSSE technical report, 2014.
[57] A. Sinclair, “Improved bounds for mixing rates of Markov chains and
multicommodity ﬂow,” in Proceedings of Latin American Symposium
on Theoretical Informatics. Springer-Verlag, 1992, pp. 474–487.
[59]
[58] D. N. Tran, B. Min, J. Li, and L. Subramanian, “Sybil-resilient online
content voting.” in NSDI, vol. 9, 2009, pp. 15–28.
J. Leskovec and C. Faloutsos, “Sampling from large graphs,” in Pro-
ceedings of the ACM SIGKDD Conference. ACM, 2006, pp. 631–636.
[60] D. J. Watts and S. H. Strogatz, “Collective dynamics of small-world
[61]
networks,” nature, vol. 393, no. 6684, pp. 440–442, 1998.
J. L. Herlocker, J. A. Konstan, L. G. Terveen, and J. T. Riedl, “Evalu-
ating collaborative ﬁltering recommender systems,” ACM Transactions
on Information Systems (TOIS), vol. 22, no. 1, pp. 5–53, 2004.
[62] A. Mohaisen, H. Tran, N. Hopper, and Y. Kim, “On the mixing time
of directed social graphs and security implications,” in Proceedings of
the ASIACCS Conference. ACM, 2012, pp. 36–37.
[63] Y. Xie and et al., “Innocent by association: early recognition of
legitimate users,” in Proc. CCS’12. ACM, 2012, pp. 353–364.
15