# 优化后的文本

## Table 4: Additional WAPTEC Results
| Time (sec) | Client-Side Constraints | Server-Side Constraints | Database Constraints | Average Trace Size (KB) | Average Time (sec) |
|------------|------------------------|------------------------|----------------------|-------------------------|--------------------|
| 41         | 738                    | 10,042                 | 12                   | 60                      | 2,082              |

## 5. False Positives and Required Variables

### Hostile Input and Length Constraints
The hostile input was generated by negating a length constraint found in `fclient`, while `fserver` did not contain the replicated length constraint. However, the database implicitly enforced the length check, preventing the attack from succeeding. Without considering sanitization and database constraints, such false positives cannot be avoided.

### Required Variables
Another source of false positives for NOTAMPER is due to required variables that are enforced only on the server-side. In these cases, the client lacks sufficient information to generate a truly benign input that satisfies the server’s requirements. For example, NOTAMPER failed to detect the category hijacking exploit in the mybloggie application because it missed required variables. The server-side code required the client to set the value of either the `submit` or `preview` parameter. Since NOTAMPER did not set any of these values, the server generated a response page containing the same form for both benign and hostile inputs, resulting in a false positive.

## 6. Comparison of WAPTEC and NOTAMPER

WAPTEC demonstrated that a whitebox approach produces better results than the blackbox approach used by NOTAMPER. WAPTEC uncovered more exploits and eliminated false positives and false negatives by precisely reasoning about form inputs across the entire application (client and server). In contrast, NOTAMPER is limited to using constraints implied by the client-side code and employs heuristics to determine if the server-side code accepted or rejected inputs, leading to inherent false positives and false negatives.

Although WAPTEC consistently outperforms NOTAMPER, both approaches have their own utility. NOTAMPER, which does not rely on analyzing server-side code, can be applied to a wider range of applications and websites. If the source code is available, a whitebox analysis like WAPTEC can be employed to perform deeper code analysis and pinpoint more security issues. Additionally, by ensuring the construction of exploits, the whitebox approach can reduce the human effort needed to confirm exploits, which may be unavoidable in blackbox approaches.

## 6.3 Complexity and Performance

For each evaluated application, Table 4 captures the complexity of generated formulas (columns 2-4), the average size of generated traces (column 5 - kilobytes), and the average time taken to run the tool (column 6 - seconds).

### Outliers
The most notable application we tested, `dcpportal`, had the largest formula complexities, the largest number of exploits, and the longest running time. Larger formula complexity corresponds to larger and more complex forms, which naturally require longer running times. The large number of exploits is partially attributed to the high formula complexity, as the potential number of exploit generation attempts is greater. However, the presence of many confirmed exploits also points to poor server-side validation of inputs.

### Manual Intervention
In a preliminary analysis of the chosen applications, we selected forms with interesting client-side specifications and collected login credentials necessary to access them (in five applications). We also extracted form action parameters in cases where applications reused processing code between multiple forms (total of four). These hints were necessary to facilitate automatic analysis and restrict exploration of server-side code pertaining to other forms. Overall, it typically took less than five minutes to collect this data for each form.

## 7. Related Work

The related work is organized along the dimensions of various contributions of WAPTEC.

### Multi-tier Reasoning of Web Applications
Web applications, especially those following the LAMP model, are inherently multi-tiered: client-side code written in HTML/JavaScript, server-side code written in PHP, and database schema expressed in MySQL. To construct parameter tampering exploits, WAPTEC reasons across these tiers and expresses them uniformly in the language of the solver. To the best of our knowledge, WAPTEC is the first work that offers a systematic multi-tiered analysis for legacy web applications. Most existing works on web application analysis do not reason across all tiers.

### Specification Inference
AutoISES [25] is an approach for C program bug detection that mines for common security-related patterns and identifies deviations as vulnerabilities. Engler [12] detects security bugs in C programs by mining temporal safety patterns and checking for inconsistencies. Srivastava et al. [23] exploit the differences between multiple implementations of the same API to detect security violations. Felmetsger et al. [13] monitor normal execution of a web application to infer behavioral specifications and find paths that violate these specifications, indicating missing checks.

### Test Input Generation
A rich literature exists on automating test input generation [21, 16, 19, 11, 14, 15, 22]. Saxena et al. [21] combine random test generation and symbolic execution for testing JavaScript applications, aiming to find code injection vulnerabilities. Halfond et al. [16] use symbolic execution and constraint solving to infer web application interfaces for improved testing. Kie˙zun et al. [19] use symbolic execution and a library of attack strings to find code injection attacks. Sen et al. [22] propose a technique combining concrete and symbolic execution to avoid redundant test cases and false warnings. Other works [15, 14] record actual runs of the program under test, symbolically evaluate the recorded trace, and gather constraints on inputs to generate new inputs that exercise different control paths.

### Input Validation
The lack of sufficient input validation is a major source of security vulnerabilities in web applications. There is a well-developed body of literature on server-side techniques to curb the impact of untrusted data. Attacks such as SQL injection and Cross-site Scripting (XSS) are well-studied examples where untrusted data can result in unauthorized actions. WAPTEC can find vulnerabilities that could be exploited by SQL injection or XSS attacks. Unlike other studies, WAPTEC uses client-side code as a specification of expected server-side behavior and can find logic vulnerabilities that do not necessarily require code injection.

### Sanitization
Sanitization of inputs is an effective layer of defense against attacks that ride user inputs. Typically, sanitization aims to rewrite hostile inputs to render them benign. Unfortunately, there is no standard technique for sanitizing user inputs, often resulting in vulnerable applications. Saner [4] attempts to identify and validate the adequacy of sanitization routines in web applications. BEK [17] proposes a language for writing sanitizers that enables systematic reasoning about their correctness. WAPTEC generates inputs that satisfy client-side validation, leading to the selection of paths in the server-side code that do not sanitize user inputs. For cases where sanitization is performed on all control paths, WAPTEC offers limited reasoning. These research works provide starting points for sound reasoning about sanitization in web applications, an important area that needs further research.

## 8. Conclusion

In this paper, we presented WAPTEC, an approach and tool for automatically generating exploits for parameter tampering vulnerabilities. Our approach uses a combination of formal logic, constraint solving, symbolic evaluation, and dynamic analysis. We evaluated six open-source applications, and our tool found at least one exploit in every single application. This illustrates that it is possible to extract and use specifications of intended behavior from the client-side code. The numerous exploits found by our approach further highlight the gap between the validation checks that must happen in a web application and those that actually occur.

## Acknowledgements

This work was partially supported by National Science Foundation grants CNS-0845894, CNS-0917229, and CNS-1065537. Thanks are due to Kalpana Gondi for her helpful comments. Finally, we thank the anonymous referees for their feedback.

## 9. References

[1] Google Web Toolkit. http://www.google.com/webtoolkit/.
[2] Ruby on Rails. http://www.rubyonrails.org/.
[3] BALDUZZI, M., GIMENEZ, C. T., BALZAROTTI, D., AND KIRDA, E. Automated Discovery of Parameter Pollution Vulnerabilities in Web Applications. In 18th Annual Network and Distributed System Security Symposium (San Diego, CA, USA, 2011).
[4] BALZAROTTI, D., COVA, M., FELMETSGER, V., JOVANOVIC, N., KRUEGEL, C., KIRDA, E., AND VIGNA, G. Saner: Composing Static and Dynamic Analysis to Validate Sanitization in Web Applications. In SP’08: Proceedings of the 29th IEEE Symposium on Security and Privacy (Oakland, CA, USA, 2008).
[5] BALZAROTTI, D., COVA, M., FELMETSGER, V. V., AND VIGNA, G. Multi-Module Vulnerability Analysis of Web-based Applications. In CCS’07: Proceedings of the 14th ACM Conference on Computer and Communications Security (Alexandria, Virginia, USA, 2007).
[6] BETHEA, D., COCHRAN, R., AND REITER, M. Server-side Verification of Client Behavior in Online Games. In NDSS’10: Proceedings of the 17th Annual Network and Distributed System Security Symposium (San Diego, CA, USA, 2010).
[7] BISHT, P., HINRICHS, T., SKRUPSKY, N., BOBROWICZ, R., AND VENKATAKRISHNAN, V. NoTamper: Automatic Blackbox Detection of Parameter Tampering Opportunities in Web Applications. In 17th ACM Conference on Computer and Communications Security (Chicago, Illinois, USA, 2010).
[8] CHONG, S., LIU, J., MYERS, A. C., QI, X., VIKRAM, K., ZHENG, L., AND ZHENG, X. Secure Web Application via Automatic Partitioning. SIGOPS Oper. Syst. Rev. 41, 6 (2007), 31–44.
[9] COOPER, E., LINDLEY, S., WADLER, P., AND YALLOP, J. Links: Web programming without tiers. In FMCO (2006).
[10] CORCORAN, B. J., SWAMY, N., AND HICKS, M. Cross-tier, label-based security enforcement for web applications. In Proceedings of the ACM SIGMOD International Conference on Management of Data (SIGMOD) (June 2009), pp. 269–282.
[11] EMMI, M., MAJUMDAR, R., AND SEN, K. Dynamic Test Input Generation for Database Applications. In ISSTA’07: Proceedings of the 2007 International Symposium on Software Testing and Analysis (London, UK, 2007).
[12] ENGLER, D., CHEN, D. Y., HALLEM, S., CHOU, A., AND CHELF, B. Bugs as Deviant Behavior: A General Approach to Inferring Errors in Systems Code. In 18th ACM Symposium on Operating Systems Principles (Banff, Alberta, Canada, 2001).
[13] FELMETSGER, V., CAVEDON, L., KRUEGEL, C., AND VIGNA, G. Toward Automated Detection of Logic Vulnerabilities in Web Applications. In 19th USENIX Security Symposium (Washington, DC, USA, 2010).
[14] GODEFROID, P., KLARLUND, N., AND SEN, K. DART: Directed Automated Random Testing. SIGPLAN Not. 40, 6 (2005), 213–223.
[15] GODEFROID, P., LEVIN, M. Y., AND MOLNAR, D. A. Automated Whitebox Fuzz Testing. In NDSS’08: Proceedings of the 15th Annual Network and Distributed System Security Symposium (San Diego, CA, USA, 2008).
[16] HALFOND, W., ANAND, S., AND ORSO, A. Precise Interface Identification to Improve Testing and Analysis of Web Applications. In ISSTA’09: Proceedings of the ACM SIGSOFT International Symposium on Software Testing and Analysis (Chicago, IL, USA, 2009).
[17] HOOIMEIJER, P., LIVHSITS, B., MOLNAR, D., SAXENA, P., AND VEANES, M. Fast and Precise Sanitizer Analysis with BEK. In 20th USENIX Security Symposium (San Francisco, CA, USA, 2011).
[18] JAYARAMAN, K., LEWANDOWSKI, G., TALAGA, P. G., AND CHAPIN, S. J. Enforcing Request Integrity in Web Applications. In DBSec’10: Proceedings of the 24th Annual IFIP WG 11.3 Working Conference on Data and Applications Security and Privacy (Rome, Italy, 2010).
[19] KIE ˙ZUN, A., J. GUO, P., JAYARAMAN, K., AND D. ERNST, M. Automatic Creation of SQL Injection and Cross-site Scripting Attacks. In ICSE’09: Proceedings of the 31st International Conference on Software Engineering (Washington, DC, USA, 2009).
[20] KING, J. C. Symbolic execution and program testing. Commun. ACM 19, 7 (1976).
[21] SAXENA, P., AKHAWE, D., HANNA, S., MAO, F., MCCAMANT, S., AND SONG, D. A Symbolic Execution Framework for JavaScript. In 31st IEEE Symposium on Security and Privacy (Oakland, CA, USA, 2010).
[22] SEN, K., MARINOV, D., AND AGHA, G. CUTE: A Concolic Unit Testing Engine for C. In 10th European Software Engineering Conference.
[23] SRIVASTAVA, V., BOND, M. D., MCKINLEY, K. S., AND SHMATIKOV, V. A Security Policy Oracle: Detecting Security Holes using Multiple API Implementations. In ACM Conference on Programming Language Design and Implementation (San Jose, CA, USA, 2011).
[24] SU, Z., AND WASSERMANN, G. The Essence of Command Injection Attacks in Web Applications. In 33rd symposium on Principles of programming languages (Charleston, SC, USA, 2006).
[25] TAN, L., ZHANG, X., MA, X., XIONG, W., AND ZHOU, Y. AutoISES: Automatically Inferring Security Specifications and Detecting Violations. In 17th USENIX Security Symposium (San Jose, CA, USA, 2008).