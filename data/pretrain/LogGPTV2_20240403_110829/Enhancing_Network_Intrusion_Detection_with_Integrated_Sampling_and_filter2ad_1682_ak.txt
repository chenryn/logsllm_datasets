PDA-based program models.
Model-based anomaly detection restricts allowed execution to a precomputed model
of allowed behavior. A program model M is a language acceptor of system call se-
quences and is an abstract representation of the program’s expected execution behavior.
If Σ denotes the alphabet of system calls, then L(M) ⊆ Σ
denotes the language
accepted by M . A system call sequence in L(M) is valid; sequences outside L(M)
indicate anomalous program execution. In this paper, we implement a program model
as a non-deterministic pushdown automaton (PDA).
∗
J.T. Gifﬁn, S. Jha, and B.P. Miller
48
Deﬁnition 1. A pushdown automaton (PDA) is a tuple M = (cid:8)S, Σ, Γ, δ, s0, Z0, F(cid:9),
where
(cid:3)
∗
, γ
(cid:3) ∈ S, γ
(cid:3) ∈ Γ ∪ };
is an initial stack conﬁguration;
(cid:3)(cid:9)| s ∈ S, γ ∈ Γ ∪ , σ ∈ Σ ∪ , s
– S is a set of states;
– Σis a set of alphabet symbols;
– Γ is a set of stack symbols;
– δ ⊆ {(cid:8)s, γ(cid:9) σ→ (cid:8)s
– s0 ∈ S in an initial state;
– Z0 ∈ Γ
– F ⊆ S is a set of ﬁnal states.
A PDA model has close ties to program execution. A state corresponds to a program
point in the program’s code. The initial state corresponds to the program’s entry point.
The ﬁnal states correspond to program termination points, which generally follow an
exit system call. The alphabet symbols are the system calls generated by a program as
it executes. The stack symbols are return addresses specifying to where a function call
returns. The initial stack Z0 is empty, as a program begins execution with no return
addresses on its call stack.
The transition relation δ describes valid control ﬂows within a program. Our PDA
model has three types of transitions:
– System calls: (cid:8)s, (cid:9) σ→ (cid:8)s
(cid:3)
(cid:3)
– Function calls: (cid:8)s, (cid:9) σ→ (cid:8)s
system call σ when transitioning from state s to state s
call return addresses remains unchanged.
address γ onto the call stack when transitioning from state s to s
sponds to a function call-site in the program and s
of the call’s destination.
, (cid:9) for σ (cid:11)=  indicates that the program can generate
. The PDA stack of function
, γ(cid:9) for γ (cid:11)=  indicates that the program pushes return
. Here, s corre-
corresponds to the entry point
, (cid:9) for γ (cid:11)=  indicates that the program returns
from a function call and pops return address γ from the call stack. This transition
can be followed only when γ is the top symbol of the PDA stack. The state s
is
corresponds to a program point containing a function return instruction and s
the program point to which control is actually returned.
– Function returns: (cid:8)s, γ(cid:9) σ→ (cid:8)s
(cid:3)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
Many program model designs proposed in academic literature are not presented as
pushdown automata. However, the generality of a PDA allows us to characterize those
models as PDA suitable for analysis using the techniques presented later in this paper.
The context-free languages recognized by PDA completely contain the class of regular
languages. All program models of which we are are aware accept either regular or
context-free languages, and hence can always be characterized by a PDA. This includes:
– window-based models, such as the Stide model [8] (Fig. 3a) or the digraph model
[23] (Fig. 3b);
– non-deterministic ﬁnite automata (NFA) [23, 19, 14, 12] (Fig. 3c);
– bounded-stack PDAs [11];
– deterministic PDAs, such as the VPStatic model [6];
– stack-deterministic PDAs, such as the Dyck model [6]; and
– non-deterministic PDAs [23] (Fig. 3d).
Automated Discovery of Mimicry Attacks
49
read
write
setreuid
write
execve
stat
open
mmap
write
read
write
stat
setreuid
write
execve
open
mmap
write
read
write
stat
setreuid
write
execve
open
mmap
write
push A
read
pop A
setreuid
push B
push C
write
pop B
pop C
execve
stat
open
mmap
write
(a) Stide Model
(b) Digraph Model
(c) NFA Model
(d) PDA Model
Fig. 3. Four different program models for the code of Fig. 2, each expressed as a pushdown
automaton. For simplicity, we assume that the gets function call generates the system call read
and the syslog function call generates write.
When a model accepts a regular language, we simply have Γ = ∅ and transitions in
δ are only of the form (cid:8)s, (cid:9) σ→ (cid:8)s
, (cid:9). Although the experiments in Sect. 7 consider
the Stide model, a regular language acceptor, we intentionally designed our system to
analyze pushdown automata so that it is relevant to a wide collection of program models
of varying strength.
(cid:3)
Commensurate with our threat model, we assume that an attacker has prior knowl-
edge of the particular program model used to constrain execution of a vulnerable pro-
gram. The security of the system then relies entirely upon the ability of the program
model to detect attacks.
3.3 Finding Undetected Attacks
We have developed a model analysis system that evaluates a PDA-based program model
and ﬁnds undetected attacks. Our design has three features of note:
– It operates automatically. A user must provide an initial, one-time operating system
abstraction that can then be reused to analyze the model of any program execut-
ing on that operating system. This subsequent analysis requires no human input,
allowing the analysis to scale easily to large collections of program models.
– Attacks, which are sequences of system calls, do not need to be known. In fact, our
system provides attack sequences as output.
– System call arguments can signiﬁcantly alter the semantic meaning of the calls.
When our system ﬁnds an undetected attack sequence of system calls, it addition-
ally provides the system call arguments necessary to effect the attack.
We construct an abstraction of the operating system with respect to its security-critical
state. This abstraction can be repeatedly used to ﬁnd attacks in the models of programs
that execute on that operating system. Consider a simple example:
50
J.T. Gifﬁn, S. Jha, and B.P. Miller
Example 1. Running our tool for each of the four models in Fig. 3 shows that none de-
tect all attacks that execute a shell with root privilege. The tool automatically identiﬁes
a system call sequence, with arguments, that defeats each model:
read(0);
setreuid(0, 0);
write(0);
execve(“/bin/sh”);
The read and write calls are nops that are irrelevant to the attack. The setreuid call
alters OS state to gain root access, and the execve call executes a shell with that access.
One of our long-term goals is to use discovered undetected attacks to guide the future
design of program models and intrusion detection systems. Comparing the undetected
attack sequence with the original program code of Fig. 2 suggests a model alteration
that would eliminate this undetected attack. If the model constrains statically-known
system call argument values, then an attacker cannot undetectably use the setreuid call
to set the effective user ID to root. Although the attacker remains able to execute the
shell, that shell will not have increased privilege.
We will consider additional examples in Sect. 5.
4 Operating System Model
Given a program model M , answering the question ﬁrst posed in Sect. 1, what attacks
does M fail to detect?, requires understanding of what “attack” means. Previous work
deﬁned attacks as known, malicious sequences of system calls [24]. Directly searching
program models for these sequences unfortunately has two drawbacks:
– An attacker could transform an attack sequence detected by the program model into
a different sequence that produces the same malicious effect but is allowed by the
model. For example, meaningless nop system calls could be inserted into the attack,
and system calls such as write could be changed to other calls such as mmap. In
previous work, the onus of ﬁnding all attack variants was upon the human.
– This approach poorly handles program models that monitor both system calls and
system call arguments [23, 11]. Identifying nop system calls is not straightforward
when the allowed system call arguments are constrained by the model.
We decouple our approach from the need to know particular system call sequences
that execute attacks. Instead, we observe that regardless of the system call sequence
transformations used by an attacker, their attack will still impart the same adverse effect
upon the operating system. It is precisely this adverse effect that characterizes an attack:
it captures the malicious intent of the attacker. The actual system call sequence used
by the attacker to bring about their intent need not be known a priori, and in fact is
discovered automatically by our system.
To formalize attacks by their effect upon the operating system, we must ﬁrst formal-
ize the operating system itself. Our formalization has three components:
Automated Discovery of Mimicry Attacks
51
– a set of state variables,
– a set of initial assignments to those variables, and
– a set of system call transition relations that alter the state variables.
After developing the deﬁnitions of these components, we ﬁnally deﬁne attack effects.
4.1 State Variables
A collection of state variables model security-critical internal operating system state,
such as user IDs indicating process privilege, access permissions for ﬁles in the ﬁlesys-
tem, and active ﬁle descriptors. A state variable v has a value in the ﬁnite domain
dom(v) which contains either boolean values or integer values.
Deﬁnition 2. The set of all state variables is V . The set of all assignments of values
to variables in V is S. A conﬁguration is a boolean formula over V that characterizes
zero or more assignments.
Model checking algorithms operate over boolean variables; variables in a ﬁnite domain
are simply syntactic sugar and are represented internally as lists of boolean variables.
We additionally allow variables to be aggregated into arrays and C-style structures, both
of which our implementation automatically expands into ﬂat lists of variables.
Consider the example of the operating system’s per-process ﬁle descriptor table. We
abstract this structure as an array of ﬁle descriptors, each of which has a subset of actual
ﬁle descriptor data that we consider relevant to security:
FILEDESCRIPTORTABLE : array [0 .. MAXFD] of FILEDESCRIPTOR
FILEDESCRIPTOR : struct of
INUSE
: boolean
FORFILE
: integer
CANREAD : boolean
CANWRITE : boolean
: boolean
ATEOF
The INUSE ﬁeld indicates whether or not this ﬁle descriptor is active. The remaining
ﬁelds have meaning only for active descriptors. FORFILE is an index into an array of
ﬁle structures, not shown here, that abstract the ﬁle system. CANREAD and CANWRITE
indicate whether the ﬁle descriptor can be used to read or write the ﬁle pointed to by
the FORFILE ﬁeld. ATEOF is true when the ﬁle descriptor’s offset is at the end of the
ﬁle and allows us to distinguish between writes that overwrite data in the ﬁle and writes
that simply append data to the ﬁle.
Identifying what operating system data constitutes “security-relevant state” is cur-
rently a manual operation. Whether the subsequent model checking procedure ﬁnds an
undetected attack or reports that no attack exists, these results hold only with respect
to the chosen OS abstraction. An attack sequence is executable and can be validated
against the real operating system by actually running the attack in a sandboxed envi-
ronment and verifying that it was successful. However, when the model checker ﬁnds
no attack, there is no tangible artifact that may be veriﬁed. If relevant OS data is not
included in the abstraction, then our system may fail to discover a mimicry attack. As
52
J.T. Gifﬁn, S. Jha, and B.P. Miller
setuid (uid t uid)
{
}
(cid:1) = uid ∧ suid
[uid (cid:3)= −1 ∧ euid = 0 =⇒ ruid
[uid (cid:3)= −1 ∧ euid (cid:3)= 0 ∧ (ruid = uid ∨ suid = uid) =⇒ euid
[uid = −1 ∨ (euid (cid:3)= 0 ∧ ruid (cid:3)= uid ∧ suid (cid:3)= uid) =⇒ true]
(cid:1) = uid ∧ euid
(cid:1) = uid]∧
(cid:1) = uid]∧
(1)
(2)
(3)
Fig. 4. Speciﬁcation for the setuid system call. Unprimed variables denote preconditions that
must hold before the system call, and primed variables denote postconditions that hold after the
system call. Any variable not explicitly altered by a postcondition remains unchanged.
a result, the absence of an attack in the abstract OS provides evidence but not a mathe-
matical proof that the model will detect the attack when operating in a real OS.
The initial assignments of values to OS state variables encodes the OS state conﬁg-
uration present when a process is initialized for execution. We write these assignments
as a boolean formula I over the state variables V ; any assignment satisfying I is a
valid initial state. In our work, we developed two different boolean formula for differ-
ent classes of programs. The formula I for setuid root programs set the initial effective
user ID to root; the formula for all other programs set the user ID to a low-privilege
user.
4.2 System Call Transformers
System calls transform the state variables. For each system call, we provide a relation
specifying how that call changes state based upon the previous state.
Deﬁnition 3. Let π be a system call. Recall that V is the set of all OS state variables
and S is the set of all value assignments. The set of parameter variables for π is Λπ
where Λπ ∩ V = ∅. The system call transformer for π is a relation ∆π ⊆ S × S.
In English, each system call transformer produces new assignments of values to OS
state variables based upon the previous values of the OS state. We write each trans-
formation function as a collection of preconditions and postconditions that depend on
parameter variables. Preconditions are boolean formulas over V ∪ Λπ, and postcondi-
tions are boolean formulas over V . If a precondition formula holds before the system
call executes, then the corresponding postcondition formula will hold after the system
call.
Consider the example in Fig. 4. The speciﬁcation for setuid shows that the system
call has one parameter variable of type uid t, which is an integer valued type. The
boolean formula encodes three sets of preconditions and postconditions. From line (1),
if the uid argument is valid and the effective user ID before the setuid call is root, then
after the call, the real, effective, and saved user IDs are all set to the user ID speciﬁed
as the argument to setuid. Implicitly, all other OS state variables remain unchanged by
the call. Line (2) handles the case of a non-root user calling setuid. If either the real or
saved user IDs match the argument value, then the effective user ID is changed to that
value. Again, all other state is implicitly unchanged. Line (3) allows setuid to be used
as a nop transition that does not change OS state when neither the line (1) nor line (2)
Automated Discovery of Mimicry Attacks
53
preconditions hold true. We note that line (3) is redundant and can be omitted from the
setuid speciﬁcation; we show it here only to emphasize the ability of setuid to be used
as a nop.
We now have all components of the operating system abstraction:
Deﬁnition 4. The operating system (OS) model is Ω = (cid:8)V, I, ∆(cid:9) where V is the collec-
tion of OS state variables, I is a boolean formula over V indicating the initial OS state