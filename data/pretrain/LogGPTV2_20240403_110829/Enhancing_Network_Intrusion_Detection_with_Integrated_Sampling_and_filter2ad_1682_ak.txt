### PDA-based Program Models

**Model-based Anomaly Detection:**
Model-based anomaly detection restricts program execution to a precomputed model of allowed behavior. A program model \( M \) is a language acceptor for sequences of system calls, representing the expected execution behavior of the program. If \( \Sigma \) denotes the alphabet of system calls, then \( L(M) \subseteq \Sigma^* \) represents the language accepted by \( M \). A system call sequence in \( L(M) \) is considered valid; sequences outside \( L(M) \) indicate anomalous program execution. In this paper, we implement the program model as a non-deterministic pushdown automaton (PDA).

**Definition 1: Pushdown Automaton (PDA)**
A pushdown automaton (PDA) is defined as a tuple \( M = (S, \Sigma, \Gamma, \delta, s_0, Z_0, F) \), where:
- \( S \) is a set of states.
- \( \Sigma \) is a set of alphabet symbols (system calls).
- \( \Gamma \) is a set of stack symbols.
- \( \delta \subseteq \{ (s, \gamma) \xrightarrow{\sigma} (s', \gamma') \mid s, s' \in S, \gamma, \gamma' \in \Gamma \cup \{\epsilon\}, \sigma \in \Sigma \cup \{\epsilon\} \} \) is the transition relation.
- \( s_0 \in S \) is the initial state.
- \( Z_0 \in \Gamma \) is the initial stack symbol.
- \( F \subseteq S \) is a set of final states.

**PDA and Program Execution:**
A PDA model closely mirrors program execution:
- Each state \( s \) corresponds to a program point in the code.
- The initial state \( s_0 \) corresponds to the program's entry point.
- Final states \( F \) correspond to program termination points, typically following an exit system call.
- Alphabet symbols \( \Sigma \) are the system calls generated during program execution.
- Stack symbols \( \Gamma \) represent return addresses for function calls.
- The initial stack \( Z_0 \) is empty, as a program starts with no return addresses on its call stack.

**Transition Relation:**
The transition relation \( \delta \) describes valid control flows within the program. Our PDA model includes three types of transitions:
- **System Calls:** \( (s, \epsilon) \xrightarrow{\sigma} (s', \epsilon) \) for \( \sigma \neq \epsilon \) indicates that the program can generate a system call \( \sigma \) when transitioning from state \( s \) to state \( s' \). The PDA stack of function call return addresses remains unchanged.
- **Function Calls:** \( (s, \epsilon) \xrightarrow{\sigma} (s', \gamma) \) for \( \gamma \neq \epsilon \) indicates that the program pushes a return address \( \gamma \) onto the call stack when transitioning from state \( s \) to state \( s' \). Here, \( s \) corresponds to a function call-site, and \( s' \) is the entry point of the called function.
- **Function Returns:** \( (s, \gamma) \xrightarrow{\sigma} (s', \epsilon) \) for \( \gamma \neq \epsilon \) indicates that the program returns from a function call and pops the return address \( \gamma \) from the call stack. This transition is only valid if \( \gamma \) is the top symbol of the PDA stack. The state \( s \) corresponds to a function return instruction, and \( s' \) is the program point to which control is returned.

**Generalization to Other Models:**
Many program models proposed in academic literature are not presented as PDAs. However, the generality of PDAs allows us to characterize these models as PDAs suitable for analysis using the techniques presented later in this paper. Context-free languages recognized by PDAs completely contain the class of regular languages. All program models we are aware of accept either regular or context-free languages and can be characterized by a PDA. This includes:
- Window-based models, such as the Stide model [8] (Fig. 3a) or the digraph model [23] (Fig. 3b).
- Non-deterministic finite automata (NFA) [23, 19, 14, 12] (Fig. 3c).
- Bounded-stack PDAs [11].
- Deterministic PDAs, such as the VPStatic model [6].
- Stack-deterministic PDAs, such as the Dyck model [6].
- Non-deterministic PDAs [23] (Fig. 3d).

**Figure 3: Four Different Program Models**
Four different program models for the code in Fig. 2, each expressed as a pushdown automaton. For simplicity, we assume that the `gets` function call generates the system call `read`, and the `syslog` function call generates `write`.

**Regular Language Acceptors:**
When a model accepts a regular language, we have \( \Gamma = \emptyset \) and transitions in \( \delta \) are only of the form \( (s, \epsilon) \xrightarrow{\sigma} (s', \epsilon) \). Although the experiments in Sect. 7 consider the Stide model, a regular language acceptor, our system is designed to analyze pushdown automata to be relevant to a wide range of program models.

**Threat Model:**
We assume that an attacker has prior knowledge of the specific program model used to constrain the execution of a vulnerable program. The security of the system then relies entirely on the ability of the program model to detect attacks.

### Finding Undetected Attacks

We have developed a model analysis system that evaluates a PDA-based program model and finds undetected attacks. Our design has three key features:
- **Automatic Operation:** A user must provide an initial, one-time operating system abstraction, which can be reused to analyze the model of any program executing on that operating system. Subsequent analyses require no human input, allowing the system to scale easily to large collections of program models.
- **Unknown Attack Sequences:** Attacks, which are sequences of system calls, do not need to be known. Our system provides attack sequences as output.
- **System Call Arguments:** System call arguments can significantly alter the semantic meaning of the calls. When our system finds an undetected attack sequence, it also provides the necessary system call arguments to effect the attack.

**Operating System Abstraction:**
We construct an abstraction of the operating system with respect to its security-critical state. This abstraction can be repeatedly used to find attacks in the models of programs executing on that operating system. Consider a simple example:

**Example 1:**
Running our tool for each of the four models in Fig. 3 shows that none detect all attacks that execute a shell with root privilege. The tool automatically identifies a system call sequence, with arguments, that defeats each model:
```c
read(0);
setreuid(0, 0);
write(0);
execve("/bin/sh");
```
The `read` and `write` calls are nops that are irrelevant to the attack. The `setreuid` call alters OS state to gain root access, and the `execve` call executes a shell with that access.

**Future Design Guidance:**
One of our long-term goals is to use discovered undetected attacks to guide the future design of program models and intrusion detection systems. Comparing the undetected attack sequence with the original program code suggests a model alteration that would eliminate this undetected attack. If the model constrains statically-known system call argument values, an attacker cannot undetectably use the `setreuid` call to set the effective user ID to root. Although the attacker can still execute the shell, it will not have increased privilege.

**Additional Examples:**
We will consider additional examples in Sect. 5.

### Operating System Model

Given a program model \( M \), answering the question "What attacks does \( M \) fail to detect?" requires understanding what constitutes an "attack." Previous work defined attacks as known, malicious sequences of system calls [24]. Directly searching program models for these sequences has two drawbacks:
- An attacker could transform a detected attack sequence into a different sequence that produces the same malicious effect but is allowed by the model. For example, meaningless nop system calls could be inserted into the attack, and system calls like `write` could be changed to other calls like `mmap`.
- This approach poorly handles program models that monitor both system calls and system call arguments [23, 11]. Identifying nop system calls is not straightforward when the allowed system call arguments are constrained by the model.

**Decoupling from Known Sequences:**
We decouple our approach from the need to know particular system call sequences that execute attacks. Instead, we observe that regardless of the system call sequence transformations used by an attacker, their attack will impart the same adverse effect on the operating system. It is this adverse effect that characterizes an attack, capturing the malicious intent of the attacker. The actual system call sequence used by the attacker to bring about their intent need not be known a priori and is discovered automatically by our system.

**Formalizing the Operating System:**
To formalize attacks by their effect on the operating system, we first formalize the operating system itself. Our formalization has three components:
- A set of state variables.
- A set of initial assignments to those variables.
- A set of system call transition relations that alter the state variables.

**State Variables:**
A collection of state variables models security-critical internal operating system state, such as user IDs indicating process privilege, access permissions for files in the filesystem, and active file descriptors. A state variable \( v \) has a value in the finite domain \( \text{dom}(v) \), which contains either boolean values or integer values.

**Definition 2: State Variables and Configurations**
- The set of all state variables is \( V \).
- The set of all assignments of values to variables in \( V \) is \( S \).
- A configuration is a boolean formula over \( V \) that characterizes zero or more assignments.

Model checking algorithms operate over boolean variables; variables in a finite domain are represented internally as lists of boolean variables. We allow variables to be aggregated into arrays and C-style structures, which our implementation automatically expands into flat lists of variables.

**Example: File Descriptor Table**
Consider the example of the operating system's per-process file descriptor table. We abstract this structure as an array of file descriptors, each of which has a subset of actual file descriptor data that we consider relevant to security:
```c
FILEDESCRIPTORTABLE : array [0 .. MAXFD] of FILEDESCRIPTOR
FILEDESCRIPTOR : struct of
    INUSE : boolean
    FORFILE : integer
    CANREAD : boolean
    CANWRITE : boolean
    ATEOF : boolean
```
- The `INUSE` field indicates whether the file descriptor is active.
- The remaining fields have meaning only for active descriptors.
- `FORFILE` is an index into an array of file structures that abstract the filesystem.
- `CANREAD` and `CANWRITE` indicate whether the file descriptor can be used to read or write the file pointed to by the `FORFILE` field.
- `ATEOF` is true when the file descriptor's offset is at the end of the file, allowing us to distinguish between writes that overwrite data in the file and writes that simply append data to the file.

**Manual Identification:**
Identifying what operating system data constitutes "security-relevant state" is currently a manual operation. Whether the subsequent model checking procedure finds an undetected attack or reports that no attack exists, these results hold only with respect to the chosen OS abstraction. An attack sequence can be validated against the real operating system by running the attack in a sandboxed environment and verifying its success. However, if relevant OS data is not included in the abstraction, our system may fail to discover a mimicry attack. The absence of an attack in the abstract OS provides evidence but not a mathematical proof that the model will detect the attack in a real OS.

**Initial Assignments:**
The initial assignments of values to OS state variables encode the OS state configuration present when a process is initialized for execution. We write these assignments as a boolean formula \( I \) over the state variables \( V \); any assignment satisfying \( I \) is a valid initial state. In our work, we developed two different boolean formulas for different classes of programs:
- The formula \( I \) for setuid root programs sets the initial effective user ID to root.
- The formula for all other programs sets the user ID to a low-privilege user.

**System Call Transformers:**
System calls transform the state variables. For each system call, we provide a relation specifying how that call changes state based on the previous state.

**Definition 3: System Call Transformer**
- Let \( \pi \) be a system call.
- \( V \) is the set of all OS state variables.
- \( S \) is the set of all value assignments.
- The set of parameter variables for \( \pi \) is \( \Lambda_\pi \) where \( \Lambda_\pi \cap V = \emptyset \).
- The system call transformer for \( \pi \) is a relation \( \Delta_\pi \subseteq S \times S \).

Each system call transformer produces new assignments of values to OS state variables based on the previous values. We write each transformation function as a collection of preconditions and postconditions that depend on parameter variables. Preconditions are boolean formulas over \( V \cup \Lambda_\pi \), and postconditions are boolean formulas over \( V \). If a precondition formula holds before the system call executes, the corresponding postcondition formula will hold after the system call.

**Example: setuid System Call**
Consider the example in Fig. 4. The specification for `setuid` shows that the system call has one parameter variable of type `uid_t`, which is an integer-valued type. The boolean formula encodes three sets of preconditions and postconditions:
- From line (1), if the `uid` argument is valid and the effective user ID before the `setuid` call is root, then after the call, the real, effective, and saved user IDs are all set to the user ID specified as the argument to `setuid`. All other OS state variables remain unchanged.
- Line (2) handles the case of a non-root user calling `setuid`. If either the real or saved user IDs match the argument value, then the effective user ID is changed to that value. Again, all other state is implicitly unchanged.
- Line (3) allows `setuid` to be used as a nop transition that does not change OS state when neither the line (1) nor line (2) preconditions hold true. We note that line (3) is redundant and can be omitted from the `setuid` specification; it is shown here to emphasize the ability of `setuid` to be used as a nop.

**Complete OS Model:**
We now have all components of the operating system abstraction:

**Definition 4: Operating System (OS) Model**
The operating system (OS) model is \( \Omega = (V, I, \Delta) \), where:
- \( V \) is the collection of OS state variables.
- \( I \) is a boolean formula over \( V \) indicating the initial OS state.
- \( \Delta \) is the set of system call transformers.