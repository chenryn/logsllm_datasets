title:TEAVAR: striking the right utilization-availability balance in WAN
traffic engineering
author:Jeremy Bogle and
Nikhil Bhatia and
Manya Ghobadi and
Ishai Menache and
Nikolaj Bjørner and
Asaf Valadarsky and
Michael Schapira
TeaVaR: Striking the Right Utilization-Availability Balance in
WAN Traffic Engineering
Jeremy Bogle Nikhil Bhatia Manya Ghobadi
Ishai Menache∗ Nikolaj Bjørner∗ Asaf Valadarsky† Michael Schapira†
Massachusetts Institute of Technology ∗ Microsoft Research
† Hebrew University
ABSTRACT
To keep up with the continuous growth in demand, cloud providers
spend millions of dollars augmenting the capacity of their wide-
area backbones and devote significant effort to efficiently utilizing
WAN capacity. A key challenge is striking a good balance between
network utilization and availability, as these are inherently at odds;
a highly utilized network might not be able to withstand unex-
pected traffic shifts resulting from link/node failures. We advocate
a novel approach to this challenge that draws inspiration from finan-
cial risk theory: leverage empirical data to generate a probabilistic
model of network failures and maximize bandwidth allocation to
network users subject to an operator-specified availability target.
Our approach enables network operators to strike the utilization-
availability balance that best suits their goals and operational reality.
We present TeaVaR (Traffic Engineering Applying Value at Risk), a
system that realizes this risk management approach to traffic engi-
neering (TE). We compare TeaVaR to state-of-the-art TE solutions
through extensive simulations across many network topologies,
failure scenarios, and traffic patterns, including benchmarks extrap-
olated from Microsoft’s WAN. Our results show that with TeaVaR,
operators can support up to twice as much throughput as state-of-
the-art TE schemes, at the same level of availability.
CCS CONCEPTS
• Networks → Network algorithms; Traffic engineering al-
gorithms; Network economics; Network performance evalu-
ation;
KEYWORDS
Utilization, Availability, Traffic engineering, Network optimization
ACM Reference Format:
Jeremy Bogle, Nikhil Bhatia, Manya Ghobadi, Ishai Menache, Nikolaj Bjørner,
Asaf Valadarsky, Michael Schapira. 2019. TeaVaR: Striking the Right Utilization-
Availability Balance in WAN Traffic Engineering. In SIGCOMM ’19: 2019
Conference of the ACM Special Interest Group on Data Communication, Au-
gust 19–23, 2019, Beijing, China. ACM, New York, NY, USA, 15 pages. https:
//doi.org/10.1145/3341302.3342069
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’19, August 19–23, 2019, Beijing, China
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-5956-6/19/08...$15.00
https://doi.org/10.1145/3341302.3342069
Figure 1: Link2’s utilization is kept low to sustain the traffic
shift when failures happen.
1 INTRODUCTION
Traffic engineering (TE), the dynamic adjustment of traffic split-
ting across network paths, is fundamental to networking and has
received extensive attention in a broad variety of contexts [1, 2, 8,
21, 27, 29, 31, 34, 35, 38, 43, 57]. Given the high cost of wide-area
backbone networks (WANs), large service providers (e.g., Ama-
zon, Facebook, Google, Microsoft) are investing heavily in opti-
mizing their WAN TE, leveraging Software-Defined Networking
(SDN) to globally optimize routing and bandwidth allocation to
users [27, 29, 37, 42, 43].
A crucial challenge faced by WAN operators is striking a good
balance between network utilization and availability in the pres-
ence of node/link failures [5, 25, 28, 43, 48]. These two objectives
are inherently at odds; providing high availability requires keep-
ing network utilization sufficiently low to absorb shifts in traffic
when failures occur. To attain high availability, today’s backbone
networks are typically operated at fairly low utilization so as to
meet user traffic demands while providing high availability (e.g.,
99%+ [28]) in the presence of failures.
Fig. 1 plots the link utilization of two IP links in a backbone net-
work in North America with the same source location but different
destinations. The utilization of each link is normalized by the maxi-
mum achieved link utilization, hence, the actual link utilization is
lower than plotted. On August 4, Link1 failed, and its utilization
dropped to zero. This, in turn, increased the utilization of Link2.
Importantly, however, under normal conditions, the normalized
utilization of Link2 is only around 20%, making Link2 underutilized
almost all the time. While network utilization can be increased by
sending low-priority background traffic over underutilized links,
this does not improve network utilization for high priority traffic,
which is the focus of this paper (§6).
Aug. 4Aug. 6Aug. 8Rest of the yearAug. 2Aug. 10Aug. 12Jul. 3100.20.40.60.81NormalizedUtilizationLink1Link2SIGCOMM ’19, August 19–23, 2019, Beijing, China
Bogle et al.
We show that state-of-the-art TE schemes fail to maximize the
traffic load that can be supported by the WAN for the desired level
of availability (§5). Under these schemes, the ratio of the bandwidth
allocated to users to the available capacity must be kept lower
than necessary, resulting in needlessly low network utilization. We
argue that to remedy this, operators should explicitly optimize net-
work utilization subject to target availability thresholds. Today’s TE
schemes do not explicitly consider availability. Instead, the number
of concurrent link/node failures the TE configuration can withstand
(e.g., by sending traffic on link-disjoint network paths) is sometimes
used as a proxy for availability. However, the failure probability of a
single link can greatly differ across links, sometimes by three orders
of magnitude [23]. Consequently, some failure scenarios involving
two links might be more probable than others involving a single
link. Alternatively, some failure scenarios might have negligible
probability, and so lowering network utilization to accommodate
them is wasteful and has no meaningful bearing on availability.
Operators actually have high visibility into failure patterns and
dynamics. For example, link failures are more probable during
working hours [25] and can be predicted based on sudden drops
in optical signal quality, “with a 50% chance of an outage within
an hour of a drop event and a 70% chance of an outage within
one day” [23]. We posit that this wealth of timely empirical data
on node/link failures in the WAN should be exploited to explicitly
reason about the probability of different failure scenarios when
optimizing TE. We present TeaVaR (Traffic Engineering Applying
Value at Risk), a TE optimization framework that enables operators
to harness this information to tune the tradeoff between network
utilization and availability and, by so doing, strike a balance that
best suits their goals. To the best of our knowledge, TeaVaR is the
first formal TE framework that enables operators to jointly optimize
network utilization and availability. We refer the reader to Section 7
for a discussion of related work on TE, capacity planning, and other
risk-aware approaches to networking.
Under TeaVaR, a probabilistic model of failure scenarios is first
generated from empirical data. Then, TE optimization that draws
on the notion of Conditional Value at Risk (CVaR) [50] minimization
is applied to assign bandwidth shares to network users. TeaVaR
enables formulating guarantees such as “user i is guaranteed bi net-
work bandwidth at least β% of the time,” and computing bandwidth
assignments that achieve these guarantees for a operator-specified
value of β.
To realize this approach to TE, we grapple with the algorithmic
challenges of formulating CVaR-based TE, such as how to achieve
fairness across network users, and also with various operational
challenges, such as ensuring that the running time of our algorithm
scales well with the size and complexity of the network. In partic-
ular, we cast the CVaR-based TE as a Linear Program (LP) with a
manageable number of constraints for realistic network topologies,
thus enabling the efficient computation of optimal TE solutions.
To evaluate TeaVaR, we conduct extensive simulations, compar-
ing its performance with that of other TE systems across a variety
of scenarios, traffic matrices, and topologies. We first analyze the
failure data collected from the inter-datacenter backbone network
of Microsoft. Our dataset consists of time-to-failure and failure
duration of links over a year at 15-minute granularity. We compute
the failure probability for individual links as well as for Shared
Risk Groups (SRGs) [54] corresponding to correlated link failures.
We then apply these probability distributions to various network
topologies, including ATT, B4, IBM, and Microsoft.
Our results show that with TeaVaR the operator can support up
to twice as much traffic as with state-of-the-art TE schemes, at the
same level of availability. Importantly, TeaVaR, which optimizes
how user traffic is split across network tunnels, can be coupled
with any scheme for WAN tunnel selection, including oblivious
routing [38], k-shortest paths, and link-disjoint routes. We also
show that our optimization is fairly robust to inaccuracies in failure
probability estimations. Indeed, a surprising takeaway from our
evaluation results is that as long as the probabilistic failure model
used is within 20% of actual failure probabilities, the optimization
results in roughly only 6% error in loss calculation.
To enable the community to explore our ideas and to facilitate
the reproducibility of our results, our code is available online.1 This
work does not raise any ethical issues.
2 MOTIVATING TEAVAR
The number of concurrent node/link failures a TE configuration
can withstand is sometimes used as a proxy for availability. This
can be manifested, e.g., in sending user traffic on multiple network
paths (tunnels) that do not share any, or share only a few, links, or
in splitting traffic across paths in a manner resilient to a certain
number of concurrent link failures, as advocated in [43]. In this
section we explain why reasoning about availability in terms of
the number of concurrent failures that can be tolerated is often not
enough. We demonstrate this using the recently proposed Forward
Fault Correction (FFC) TE scheme [43].
FFC as an illustration. FFC maximizes bandwidth allocation to be
robust for up to k concurrent link failures, for a configurable value
k. To accomplish this, FFC optimization sets a cap on the maximum
bandwidth bi each network flow i (identified by source/destination
pair) can utilize and generates routing (and rerouting) rules, such
that the network can simultaneously support bi bandwidth for each
flow i in any failure scenario that involves at most k failures.
We illustrate FFC in Fig. 2, where source node s is connected to
destination node d via three links, each of capacity 10Gbps. Suppose
that the objective is to support the maximum total amount of traffic
from s to d in a manner that is resilient to at most two concurrent
link failures. Fig. 2(b) presents the optimal solution under FFC:
rate-limiting the (s, d) flow to send at 10Gbps and always splitting
traffic equally between all links that are intact; e.g., when no link
failures occur, traffic is sent at 10
3 Gbps on each link, when a single
link failure occurs, each of the two surviving links carries 5Gbps,
and with two link failures, all traffic is sent on the single surviving
link. Thus, this solution guarantees the flow-reserved bandwidth of
10Gbps without exceeding link capacities under any failure scenario
that involves at most two failed links. Observe, however, that this
comes at the cost of keeping each link underutilized (one-third
utilization) when no failures occur.
Striking the right balance. We ask whether high availability can
be achieved without such drastic over-provisioning. Approaches
such as FFC are compelling in that they provide strong availability
1http://teavar.csail.mit.edu
Striking the Right Utilization-Availability Balance in WANs
SIGCOMM ’19, August 19–23, 2019, Beijing, China
(a)
(b)
(a)
(b)
Figure 2: (a) A network of three links each with 10Gbps band-
width; (b) Under conventional TE schemes, such as FFC [43],
the total admissible traffic is always 10Gbps, split equally be-
tween paths (each carrying 10
3 Gbps).
Figure 3: (a) The same network as in Fig. 2(a), with added
information about link failure probabilities; (b) A possible
flow allocations under TeaVaR with total admissible traffic
of 20Gbps 99.8% of the time.
guarantees; in Fig. 2(b), the (s, d) flow is guaranteed a total band-
width of 10Gbps even if two links become permanently unavailable.
Suppose, however, that the availability, i.e., the fraction of time
a link is up, is consistently 99.9% for each of the three links. In
this scenario, the network can easily support 30Gbps throughput
(3× improvement over FFC) around 99.9% of the time simply by
utilizing the full bandwidth of each link and never rerouting traffic.
This example captures the limitations of failure probability ag-
nostic approaches to TE, such as FFC; specifically, they ignore the
underlying link availability (and the derived probability of failure).
As discussed in [23, 25], link availability greatly varies across differ-
ent links. Consequently, probability-oblivious TE solutions might
lead to low network efficiency under prevailing conditions to accom-
modate potentially highly unlikely failure scenarios (i.e., with little
bearing on availability). However, not only might a probability-
oblivious approach overemphasize unlikely failure scenarios, it
might even disregard likely failure scenarios. Consider a scenario
where three links in a large network have low availability (say,
99% each), and all other links have extremely high availability (say,
99.999%). When the operator’s objective is to withstand two con-
current link failures, the scenario where the three less available
links might be simultaneously unavailable will not be considered,
whereas much less likely scenarios in which two of the highly
available links fail simultaneously will be considered.
To motivate our risk-management approach, we revisit the ex-
ample in Fig. 2. Now, suppose the probability of a link being up
is as described in the figure, and the link failure probabilities are
uncorrelated (we will discuss correlated failures in §4). In this case,
the probability of different failure scenarios can be expressed in
terms of individual links’ failure probabilities (e.g., the probability
of all three links failing simultaneously is 10−7). Under these failure
probabilities, the network can support 30Gbps traffic almost 90%
of the time simply by utilizing the full bandwidth of each link and
not rerouting traffic in the event of failures. FFC’s solution, shown
in Fig. 2(b), can be regarded as corresponding to the objective of
maximizing the throughput for a level of availability in the order
of 7 nines (99.99999%), as the scenario of all links failing concur-
rently occurs with probability 10−7. Observe that the bandwidth
assignment in Fig. 3(b) guarantees a total throughput of 20Gbps at