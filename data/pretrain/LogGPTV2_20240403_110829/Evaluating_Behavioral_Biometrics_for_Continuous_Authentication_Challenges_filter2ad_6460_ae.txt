augment them with three datasets gathered speciﬁcally for
this study.
A.1 Gait Biometric
There are a number of approaches to capture human bait
patterns, they are typically based on video recordings [32,
20] or accelerometer data [23, 17, 2]. As accelerometer data
can be readily captured with smartphones (and then be
used to protect the device after a theft), we focus on this
approach. We adapt the classiﬁcation process of [17] to
support continuous authentication.
We recruited 14 volunteers, 9 male, 5 female. The ex-
periment was carried out with the approval of the ethics
committee of the University of Oxford, reference number
SSD/CUREC1/13- 064. During the experiment, each subject
walked an identical 300 meter long route on a footpath in the
university parks and returned to the starting point, resulting
in two datasets of roughly identical length for each partici-
pant. The route was straight and did not involve turns, data
collection was manually stopped before the halfway turn and
resumed afterwards. The accelerometer data was collected
with an oﬀ-the-shelf Samsung Galaxy Note 4 smartphone
at a sampling rate of 200Hz. The phone was contained in
a standard running armband strapped to the participant’s
lower leg, just above the calf muscle. On average each dataset
contained 190 seconds of accelerometer data, or 38,000 raw
samples.
Using this data we obtained an average EER of 8.44%.
A.2 Second Gait Dataset
The second gait dataset was obtained from the authors
of [7]. The set contains data from 27 participants that
walked along a footpath at three diﬀerent paces. While
the data was collected for the purpose of evaluating step-
counting algorithms, the data format makes it suitable for
authentication as well. The data was collected through the
accelerometer of a smartphone held in various positions (in
a front or back trouser pocket, in a backpack/handbag, or in
a hand with or without simultaneous typing). Not all sensor
positions are available for each subject. In order to remove
potential distinguishing information resulting purely from
the sensor position, we only use the subset of traces in which
the device was held by the subject without simultaneous
typing, limiting the number of subjects to 24. The data was
collected at a rate of 100Hz, with an average of 4400 samples
(or 44 seconds) per subject. For each subject we extract the
portion of the trace during which the subject was walking,
using the timestamps provided as part of the dataset. As the
ﬁrst half of the data is used for training it contains mostly
slow movements, unlike the testing timeframe during most
of which the subjects were moving at a quicker pace.
The system shows an EER of 28.4%. This relatively high
value (especially compared to the dataset collected by us)
397Hyperparameters
Available Online
training data
ordered
ordered
CV-10
CV-3

CV


all users

GS+CV

subset


Ref Biometric Classiﬁer Values Method att-model
[16]
[15]
[35]
[8]
[18]
[36]
[12]
[9]
[10]
[29]
[28]
[31]
[13]
[22]
[14]
SVM,knn
knn
SVM
DT
SVM
sim-score
NN
knn
NN,SVM 

SVM,RF

HMM

SVM
SVM,knn
UBM
SVM,knn
N/A




random
ordered

random 5

AD
AD
no-attacker 4
all users
AD
all users
AD
all users
all users
AD, all users CV-5
ordered
ordered
CV-5

CV-5

GS+CV

GS+CV








Touch
Gaze
N/A

()
[26]
[11]
[33]
[2]
[27]
[25]
[1]
[30]
[37]
[24]
Pulse
Response
SVM,knn

Gait
Mouse
sim-score
sim-score
sim-score
sim-score
DT
NN
sim-score
SVM
SVM
N/A
N/A
N/A
N/A
N/A

N/A



N/A
N/A
N/A
N/A
N/A

N/A


all users
CV-5
AD
AD
AD
AD
all users
no-attacker
AD
no-attacker
all users
ordered
ordered
ordered
random
ordered
random

ordered
random
Reported () Partially reported Not reported
Unless indicated otherwise, only the mean of each metric is reported
1 Only feature extraction
2 Uses data from [16]
3 Dead URL 10/07/2016
4 Training data consists of all other users, excluding the attacker
5 Sampling repeated 10 times
sample agg Data Code
weighted


2
3
2






2

1





































majority


N/A
N/A



mean
N/A
majority
N/A
majority
N/A
N/A
N/A
N/A
N/A
weighted
N/A
N/A
mean
N/A
Table 3: Simulation Design Choices in Related Work
might also be a consequence of a mismatch between training
and test data (which were gathered at diﬀerent walking
speeds).
A.3 Mouse Movement Biometric
In addition to the gait data, we conduct an experiment
to collect volunteers’ mouse movements. Our experimental
design is conceptually close to that in [34]. During the ex-
periment, each participant was shown 25 rectangles arranged
in a 5x5 grid, one of which was red. The user is then asked
to click on the red rectangle. This task is repeated 200
times, with the red rectangle appearing in a new, random
location for each iteration. The random seed to generate the
sequence was kept identical for all users in order to limit the
eﬀects of the rectangle’s position on our features. The size
of the window displaying the rectangles was ﬁxed in order to
avoid any distinctiveness created solely by diﬀerent screen
resolutions. In order to control for artiﬁcial bias created by
diﬀerent input devices [21] we collect two datasets. The ﬁrst
set was obtained by sending our software to subjects, to be
run on their own home or work machine. For the second
set we invited a (diﬀerent) set of volunteers to take part
in the experiment on our lab machine. If any features are
more distinctive in the ﬁrst set this would imply that their
distinctiveness is at least partially due to the properties of
diﬀerent devices, rather than diﬀerences in user behavior.
We achieve an EER of 9.98% for the lab dataset that
decreases to 9.22% when using the data gathered on subjects’
machines.
A.4 Eye Movement Biometric
The eye movement biometric, as proposed in [13], is based
on involuntary ﬁxational eye movements. The distinctiveness
of eye movements is not limited to a certain task and features
can be computed regardless of screen content. As such, the
biometric can be used in a continuous authentication scenario
without limiting the user. The set of 20 features used in the
398paper reﬂect the properties of microsaccades (high velocity
and acceleration), the steadiness of the gaze and both static
pupil diameter as well as the pupil diameter’s changes over
a short time. The pupil diameter generally outperforms the
remaining features in terms of distinctiveness.
A.5 First Eye Movement Dataset
The ﬁrst dataset was obtained from the authors of [13].
In order to test the features’ time stability, three identical
sessions are performed, with a time distance of one hour
and two weeks, respectively. In line with the presentation
in the paper we form three datasets from the sessions: The
intra-session set contains data only from the ﬁrst session
and involved 30 subjects. The inter-session set combines the
second and third session (i.e., with the two parts being one
hour apart) and the ﬁrst and second session form the 2-weeks
dataset.
In order to reﬂect diﬀerent threat models the authors pro-
pose the use of diﬀerent featuresets, speciﬁcally describing
a set that excludes features based on the pupil diameter.
Using this reduced feature set increases the EER from 6.9%
to 19.83% as some identifying information is lost. The com-
bination of three sessions and two featuresets results in six
distinct datasets.
A.6 Second Eye Movement Dataset
The second dataset was provided by the authors of [14]
and extends the previous study with several real-world tasks.
These tasks include reading, writing, web browsing and watch-
ing two diﬀerent videos. We consider each of these tasks
separately (by sampling training and testing data from the
same task) and jointly (by merging all tasks before sampling
training and testing data).
A.7 Touch Input Biometric
The touch input dataset is based on the data shared in [16].
The biometric’s features describe the properties of swiping
motions on touchscreens, including their position, curvature
and pressure. Data was collected over two weeks, resulting
in an intra-session, inter-session and 1-week dataset. The
error rates range from 0% for intra-session authentication to
4% when authentication is performed a week after enrolment.
As we are interested in determining the distribution and
causes of errors we do not use the intra-session dataset for
our comparison.
399