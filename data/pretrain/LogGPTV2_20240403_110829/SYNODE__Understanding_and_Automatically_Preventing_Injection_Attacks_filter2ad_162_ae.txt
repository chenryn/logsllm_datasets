ily complex, no static analysis can guarantee to detect all
sink calls. As Synode targets code that is vulnerable by
accident, and not malicious on purpose, we consider the
problem of hidden sink calls to be negligible in practice.
Second, Synode prevents the addition of new commands
to the templates, but it does not defend against data only
attacks. For example, sometimes it is insuﬃcient to ensure
that the input is a literal:
exec("rm " + userInput)
Computational cost: Our static analysis identiﬁes a
total of 1,560 templates for the injection APIs in the
considered modules. For each of them, we construct a
PAST with a median computation time of 2 milliseconds
per module. We note that for some modules this number is
signiﬁcantly higher due to our simple PAST construction
algorithm and due to the high number of templates per
module.
The last column of Figure 14 shows the average runtime
overhead per call of an injection API that is imposed by the
runtime mechanism (in milliseconds). We report absolute
times because the absolute overhead is more meaningful
than normalizing it by a fairly arbitrary workload. Our
enforcement mechanism costs 0.74 milliseconds per call, on
 0 10000 20000 30000 40000 50000 60000 1 10 100Number of call sitesNumber of holes (upper bound) 49000 49500 50000 50500 51000 51500 52000 1 10 100 1000 10000 100000 1x106Number of call sitesNumber of templates (upper bound) 0 10 20 30 40 50 60 70 80 90 100 0 20000 40000 60000 80000 100000 120000Time (ms)AST sizeaverage over 100 runs of the modules using all the inputs.
This result demonstrates that the overhead of enforcement
is generally negligible in practice.
To demonstrate the scalability of our runtime enforce-
ment, we consider input data of diﬀerent size and com-
plexity and pass it to the injection APIs. Here, we focus
on eval call sites from Figure 14 only. As inputs, we use
a diverse sample of 200 JavaScript programs taken from a
corpus of real-world code13. For every call to eval, we pass
all 200 JavaScript programs 100 times each and measure
the variance in enforcement times. Figure 13c shows the
enforcement time, in milliseconds, depending on the size
of the JavaScript program, measured as the number of
AST nodes. For each input size, the ﬁgure shows the 25%
percentile, the median value, and the 75% percentile. We
ﬁnd that the enforcement time scales linearly. The reason is
that all steps of the runtime enforcement, i.e., parsing the
input, matching the AST with the PASTs, and checking
whether nodes are on a whitelist, are of linear complexity.
IX. Related Work
Analysis of Node.js code: Injections into Node.js code
are known to be exploitable [43] and there is a community-
driven eﬀort14 to identify such problems. Ojamaa and
D¨u¨una [28] identify denial of service as one of the main
threats for the Node.js platform and also mention eval
as a security risk. We take these observation further by
presenting an in-depth study of injection vulnerabilities on
Node.js and presenting a technique to prevent injections.
NodeSentry [7] is a security architecture for least-privilege
integration of Node.js modules. Using their terminology,
Synode’s runtime enforcement is a lower-bound policy
check on exec and eval. Our mechanism is more powerful
since it uses a static analysis to perform ﬁne-grained
policy enforcement. Madsen et al. [22] enhance the call
graph construction for Node.js applications with event-
based dependencies. Our static analysis is intra-procedural
but could beneﬁt from integrating an inter-procedural
approach, which may further reduce the false positive rate.
Staicu and Pradel show that many real-world web
sites suﬀer from ReDoS vulnerabilities [38], a form of
algorithmic complexity attack that may cause web sites
to be unreachable. Their work underlines the importance
of ﬁxing vulnerabilities in popular Node.js modules, but
addresses a diﬀerent kind of vulnerability than this paper.
Program analysis for JavaScript: Studies of client-
side JavaScript [49], [32] show that eval is prevalent but
often unnecessary. We extend these ﬁndings to server-side
JavaScript, add a new category of eval uses, and categorize
uses of exec, an API not studied by existing work. Other
studies focus on inclusions of third-party libraries [27],
the postMessage API [36], injection attacks on JavaScript-
based mobile applications [15], and the use of outdated
libraries [17]. In contrast, we study Node.js code and
address vulnerabilities speciﬁc to this platform.
13http://learnbigcode.github.io/datasets/
14https://nodesecurity.io/advisories
Blueprint [44] prevents XSS attacks by enforcing that
the client-side DOM resembles a parse tree learned at the
server-side. Their work shares the idea of comparing data
prone to injections to a tree-based template. Our work
diﬀers by learning templates statically and by focusing
on command injections in Node.js code. Stock et al. [40]
study DOM-based XSS injections and propose dynamic
taint tracking to prevent them. Similar to Synode, their
prevention policy is grammar-based. However, their strict
policy to reject any tainted data that inﬂuences JavaScript
code except for literals and JSON would break many
uses of eval found during our study. Another diﬀerence is
that we avoid taint tracking by statically computing sink-
speciﬁc templates.
Defenses against XSS attacks [37], [25] use signature-
based whitelisting to reject scripts not originating from the
website creator. SICILIAN [37] uses an AST-based signa-
ture; nsign [25] creates signatures from script-dependent
elements and context-based information. Both rely on a
training phase to discover valid signatures. Our work also
uses templates as a white-listing mechanism. However,
we do not rely on testing to collect these templates but
compute them statically. As we show in our evaluation,
there may be hundreds or even thousands of paths that
reach an injection API call site, i.e., constructing valid
signatures for every path is infeasible.
CSPAutoGen [29] presents an automatic way to gen-
erate CSP policies on the server-side in order to protect
against illegitimate script execution on the client-side. It
uses gASTs, partial ASTs similar in structure with ours,
but diﬀerent in many ways. First of all, gASTs are created
during a training session, which limits the approach to
behavior observed during the training phase. gASTs also
diﬀer from our partial ASTs in the way they are enforced:
gASTs are synthesized into a JavaScript function that
replaces the actual call to the sink. Such a step cannot be
easily implemented for sinks other than eval since these
sinks call outside the JavaScript world. For example, to
refactor a call to exec that uses the awk system utility
on Linux, we would need to completely rewrite awk in
JavaScript.
DLint [10] is a dynamic checker for violations of code
including uses of eval missed by static
quality rules,
analysis. Dynamic [12] and hybrid (static and dynamic) [6]
information ﬂow analyses for JavaScript track how values
at some program location inﬂuence values at another
program location. The FLAX system [34] and a system
proposed by Lekies et al. [18] use dynamic taint analysis
to detect vulnerabilities caused by missing input validation
and then generate inputs that exploit these vulnerabilities.
Jin et al. [15] use a static taint analysis to detect code
injection vulnerabilities. In contrast to these approaches,
we do not require an information ﬂow (or taint) analysis,
performing lightweight runtime checks at possible injection
locations, without tracking the values that ﬂow to these
locations.
Several approaches rewrite JavaScript code to enforce
security policies. Yu et al. [48] propose a rewriting tech-
nique based on edit automata that replaces or modiﬁes
particular calls. Gatekeeper [11] is a static analysis for
13
a JavaScript subset that enforces security and reliability
policies. Instead of conservatively preventing all possibly
insecure behavior, our approach defers checks to runtime
when hitting limitations of purely static analysis. Other
techniques [14], [24] replace eval calls with simpler, faster,
and safer alternatives. Their main goal is to enable more
precise static analysis; our focus is on preventing injections
at runtime.
Program analysis for other languages: CSAS [33]
uses a type system to insert runtime checks that prevent
injections into template-based code generators. Livshits et
al. [20] propose to automatically place sanitizers into .NET
server applications. Similar to our work, these approaches
at ﬁrst statically address some code locations and use
runtime mechanisms only for the remaining ones. CSAS
diﬀers from our work by checking code generators instead
of ﬁnal code. The approach in [20] addresses the problem
of placing generic sanitizers, whereas we insert runtime
checks speciﬁc to injection call sites.
There are several purely dynamic approaches to prevent
injections. XSS-Guard [4] modiﬁes server applications to
compute a shadow response along each actual response and
compares both responses to detect unexpected, injected
content. Instead of comparing two strings with each other,
our runtime mechanism compares runtime strings against
statically extracted templates. ScriptGard [35] learns dur-
ing a training phase which sanitizers to use for particu-
lar program paths and detects incorrect sanitization by
comparing executions against the behavior seen during
training. Their approach is limited by the executions ob-
served during training and needs to check all execution
paths, whereas Synode statically identiﬁes some locations
as safe.
Su and Wassermann [42]
formalize the problem of
command injection attacks and propose grammar-based
runtime prevention. Their work shares the idea to re-
ject runtime values based on a grammar that deﬁnes
which parts of a string may be inﬂuenced by attacker-
controlled values. Their analysis tracks input data with
special marker characters, which may get lost on string
operations, such as substring, leading to missed injections.
Instead, our analysis does not need to track input values
through the program. Buehrer et al. [5] take a similar
approach to mitigate SQL injections. They construct two
parse trees at runtime, one representing the developers
intentions only and one including the user input. They
use these trees to ensure that the user input contains
only literals. Their approach is purely dynamic and em-
ploys markers for tracking user input, similar to Su and
Wassermann [42]. Ray and Ligatti [30] propose a novel
formulation of command injections that requires dynamic
taint tracking and a set of trusted inputs. For Node.js
libraries, example inputs are rarely available.
Constraint-based static string analysis, e.g., Z3-str [50]
is a more heavy-weighted alternative to our static anal-
ysis. Even though such techniques have the potential of
producing more precise templates, we opted for eﬃciency,
enabling us to apply the analysis easily to thousands of
npm modules. Wassermann et al. address the problem
of ﬁnding inputs that trigger SQL injections [46] and
XSS vulnerabilities [45] in PHP code. Ardilla [16] ﬁnds
and exploits injection vulnerabilities in PHP through a
combination of taint analysis and test generation. Instead
of triggering attacks, our work addresses the problem of
preventing attacks. Similar to our preliminary study of
dependences on injection APIs, a recent work analyzes the
usage of the unsafe API in Java [23]. Existing analyses
for Java [31] and Android applications [3], [19] focus on
security risks due to libraries, which shares with Synode
the idea to consider third-party code as a potential security
threat.
X. Conclusions
This paper studies injection vulnerabilities in Node.js
and shows that the problem is widespread and not yet
adequately addressed. We present Synode, an auto-
mated technique for mitigating injection vulnerabilities in
Node.js applications. At the same time, the approach
eﬀectively prevents a range of attacks while causing very
few false positives and while imposing sub-millisecond
overheads. To aid with its adoption, our technique requires
virtually no involvement on the part of the developer.
Instead, Synode can be deployed automatically as part
of module installation.
In a broader scope, this work shows the urgent need
for security tools targeted at Node.js. The technique
presented in this paper is an important ﬁrst step toward
securing the increasingly important class of Node.js ap-
plications, and we hope it will inspire future work in this
space.
Acknowledgements
This work was supported by the German Federal
Ministry of Education and Research and by the Hessian
Ministry of Science and the Arts within CRISP, by the
German Research Foundation within the Emmy Noether
project “ConcSys”, and by the Royal Society Wolfson Merit
Award.
References
[1] A. V. Aho, R. Sethi, and J. D. Ullman. Compilers. Principles,
Techniques and Tools. Addison Wesley, 1986.
[2] E. Andreasen, L. Gong, A. Møller, M. Pradel, M. Selakovic,
K. Sen, and C.-A. Staicu. A survey of dynamic analysis and
test generation for javascript. ACM Computing Surveys, 2017.
[3] M. Backes, S. Bugiel, and E. Derr. Reliable third-party library
In CCS,
detection in android and its security applications.
pages 356–367, 2016.
[4] P. Bisht and V. N. Venkatakrishnan. XSS-GUARD: precise
dynamic prevention of cross-site scripting attacks. In DIMVA,
pages 23–43, 2008.
[5] G. Buehrer, B. W. Weide, and P. A. G. Sivilotti. Using parse
tree validation to prevent SQL injection attacks. In Workshop
on Software Eng. and Middleware, pages 106–113, 2005.
[6] R. Chugh, J. A. Meister, R. Jhala, and S. Lerner. Staged
information ﬂow for JavaScript. In PLDI, pages 50–62. ACM,
2009.
[7] W. De Groef, F. Massacci, and F. Piessens. NodeSentry:
least-privilege library integration for server-side JavaScript. In
ACSAC, pages 446–455, 2014.
14
[8] A. Doup´e, B. Boe, C. Kruegel, and G. Vigna. Fear the EAR:
discovering and mitigating execution after redirect vulnerabil-
ities. In CCS, pages 251–262, 2011.
[29] X. Pan, Y. Cao, S. Liu, Y. Zhou, Y. Chen, and T. Zhou.
CSPAutoGen: Black-box enforcement of content security policy
upon real-world websites. In CCS, pages 653–665, 2016.
[30] D. Ray and J. Ligatti. Deﬁning code-injection attacks.
In
POPL, pages 179–190, 2012.
[31] M. Reif, M. Eichberg, B. Hermann, J. Lerch, and M. Mezini.
Call graph construction for java libraries. In FSE, pages 474–
486, 2016.
[32] G. Richards, C. Hammer, B. Burg, and J. Vitek. The eval that
men do - A large-scale study of the use of eval in JavaScript
applications. In ECOOP, pages 52–78, 2011.
[33] M. Samuel, P. Saxena, and D. Song. Context-sensitive auto-
sanitization in web templating languages using type qualiﬁers.
In CCS, pages 587–600, 2011.
[34] P. Saxena, S. Hanna, P. Poosankam, and D. Song. FLAX:
Systematic discovery of client-side validation vulnerabilities in
rich web applications. In NDSS, 2010.
[35] P. Saxena, D. Molnar, and B. Livshits. SCRIPTGARD: auto-
matic context-sensitive sanitization for large-scale legacy web
applications. In CCS, pages 601–614, 2011.
[36] S. Son and V. Shmatikov. The postman always rings twice:
Attacking and defending postmessage in HTML5 websites. In
NDSS, 2013.
[37] P. Soni, E. Budianto, and P. Saxena. The SICILIAN defense:
Signature-based whitelisting of web JavaScript. In CCS, pages
1542–1557, 2015.
[38] C.-A. Staicu and M. Pradel. Freezing the web: A study of
redos vulnerabilities in javascript-based web servers. Technical
Report TUD-CS-2017-0305, TU Darmstadt, 2017.
[39] C.-A. Staicu, M. Pradel, and B. Livshits. Understanding and
automatically preventing injection attacks on node.js. Techni-
cal Report TUD-CS-2016-14663, TU Darmstadt, Department
of Computer Science, 2016.
[40] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and M. Johns.
Precise client-side protection against DOM-based cross-site
scripting. In USENIX Security, pages 655–670, 2014.
[41] B. Stock, G. Pellegrino, C. Rossow, M. Johns, and M. Backes.
Hey, you have a problem: On the feasibility of large-scale web
vulnerability notiﬁcation.
In USENIX Security, pages 1015–
1032, 2016.
[42] Z. Su and G. Wassermann. The essence of command injection
attacks in web applications. In POPL, pages 372–382, 2006.
[43] B. Sullivan. Server-side JavaScript injection. Black Hat USA,
2011.
[44] M. Ter Louw and V. N. Venkatakrishnan. Blueprint: Robust
prevention of cross-site scripting attacks for existing browsers.
In Sec. and Privacy, pages 331–346, 2009.
[45] G. Wassermann and Z. Su.
Static detection of cross-site
scripting vulnerabilities. In ICSE, pages 171–180, 2008.
[46] G. Wassermann, D. Yu, A. Chander, D. Dhurjati, H. Inamura,
and Z. Su. Dynamic test input generation for web applications.
In ISSTA, pages 249–260, 2008.
[47] S. Wei. Practical analysis of the dynamic characteristics of
JavaScript, 2015.
[48] D. Yu, A. Chander, N. Islam, and I. Serikov.
JavaScript
instrumentation for browser security. In POPL, pages 237–249,
2007.
[49] C. Yue and H. Wang. Characterizing insecure JavaScript
practices on the web. In WWW, pages 961–970, 2009.
[50] Y. Zheng, X. Zhang, and V. Ganesh. Z3-str: a Z3-based string
solver for web application analysis. In ESEC/FSE, pages 114–
124, 2013.
[9] Z. Durumeric, J. Kasten, D. Adrian, J. A. Halderman, M. Bai-
ley, F. Li, N. Weaver, J. Amann, J. Beekman, M. Payer, and
V. Paxson. The matter of heartbleed. In IMC, pages 475–488,
2014.
[10] L. Gong, M. Pradel, M. Sridharan, and K. Sen. DLint: Dynam-
ically checking bad coding practices in JavaScript. In ISSTA,
pages 94–105, 2015.
[11] S. Guarnieri and B. Livshits. GATEKEEPER: mostly static
enforcement of security and reliability policies for JavaScript
code. In USENIX Security, pages 151–168, 2009.
[12] D. Hedin, A. Birgisson, L. Bello, and A. Sabelfeld. JSFlow:
tracking information ﬂow in JavaScript and its APIs. In SAC,
pages 1663–1671, 2014.
[13] P. Hooimeijer, B. Livshits, D. Molnar, P. Saxena, and
M. Veanes. Fast and precise sanitizer analysis with BEK. In
USENIX Security, pages 1–16, Aug. 2011.
[14] S. H. Jensen, P. A. Jonsson, and A. Møller. Remedying the eval
that men do. In ISSTA, pages 34–44, 2012.
[15] X. Jin, X. Hu, K. Ying, W. Du, H. Yin, and G. N. Peri. Code
injection attacks on HTML5-based mobile apps: Characteriza-
tion, detection and mitigation. In Conference on Computer and
Communications Security, pages 66–77, 2014.
[16] A. Kiezun, P. J. Guo, K. Jayaraman, and M. D. Ernst. Auto-
matic creation of SQL injection and cross-site scripting attacks.
In ICSE, pages 199–209, 2009.
[17] T. Lauinger, A. Chaabane, S. Arshad, W. Robertson, C. Wil-
son, and E. Kirda. Thou shalt not depend on me: Analysing
the use of outdated javascript libraries on the web. 2017.
[18] S. Lekies, B. Stock, and M. Johns. 25 million ﬂows later: large-
scale detection of DOM-based XSS. In CCS, pages 1193–1204,
2013.
[19] M. Li, W. Wang, P. Wang, S. Wang, D. Wu, J. Liu, R. Xue,
and W. Huo. Libd: Scalable and precise third-party library
detection in android markets. In ICSE, 2017.
[20] B. Livshits and S. Chong. Towards fully automatic placement
of security sanitizers and declassiﬁers. In POPL, pages 385–398,
2013.
[21] B. Livshits, M. Sridharan, Y. Smaragdakis, O. Lhot´ak, J. N.
Amaral, B. E. Chang, S. Z. Guyer, U. P. Khedker, A. Møller,
and D. Vardoulakis.
In defense of soundiness: a manifesto.
Commun. ACM, 58(2):44–46, 2015.
[22] M. Madsen, F. Tip, and O. Lhot´ak. Static analysis of event-
In OOPSLA, pages
driven Node.js JavaScript applications.
505–519, 2015.
[23] L. Mastrangelo, L. Ponzanelli, A. Mocci, M. Lanza,
M. Hauswirth, and N. Nystrom. Use at your own risk:
the Java unsafe API in the wild. In OOPSLA, pages 695–710,
2015.
[24] F. Meawad, G. Richards, F. Morandat, and J. Vitek. Eval
begone!: semi-automated removal of eval from JavaScript pro-
grams. In OOPSLA, pages 607–620, 2012.
[25] D. Mitropoulos, K. Stroggylos, D. Spinellis, and A. D.
Keromytis. How to train your browser: Preventing XSS attacks
using contextual script ﬁngerprints. Trans. Priv. and Sec.,
19(1):2, 2016.
[26] F. Nielson, H. R. Nielson, and C. Hankin. Principles of Program
Analysis. Springer, second edition edition, 2005.
[27] N. Nikiforakis, L. Invernizzi, A. Kapravelos, S. Van Acker,
W. Joosen, C. Kruegel, F. Piessens, and G. Vigna. You are
what you include: large-scale evaluation of remote JavaScript
inclusions. In ACM Conference on Computer and Communi-
cations Security, pages 736–747, 2012.
[28] A. Ojamaa and K. D¨u¨una. Assessing the security of Node.js
platform. In Intl. Conf. f. Internet Techn. and Secured Trans-
actions, pages 348–355, 2012.
15