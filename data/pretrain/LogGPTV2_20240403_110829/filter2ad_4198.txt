title:PieBridge: A Cross-DR scale Large Data Transmission Scheduling System
author:Yuchao Zhang and
Ke Xu and
Guang Yao and
Miao Zhang and
Xiaohui Nie
PieBridge: A Cross-DR scale Large Data
Transmission Scheduling System (cid:3)
Yuchao Zhang1;3
y
3Tsinghua National Laboratory for Information Science and Technology
PI:EMAIL, PI:EMAIL
{yaoguang,zhangmiao02}@baidu.com, PI:EMAIL
, Ke Xu1;3, Guang Yao1;2, Miao Zhang2, Xiaohui Nie1
1Tsinghua University
2Baidu
ABSTRACT
Cross-DR WAN (Datacenter Region Wide Area Net-
work) with various services are deployed to provide
timely data information and analytics for users in a wide
range of geographical locations. For its reliability and
performance, data duplication synchronization is essen-
tial among diﬀerent IDCs (Internet datacenters). How-
ever, this problem poses a challenge. First, data dupli-
cation requires huge amount of bandwidth whereas the
bandwidth of cross-DR links and the upload/download
rates of server interfaces are limited. Second, data
transmissions are time sensitive, but the current net-
work cannot complete such tasks in a timely manner.
In this work, we present PieBridge, a cross-RD data du-
plicate transmission platform that accommodates hun-
dreds of TBs of data generated from user applications
online data analytics. We deployed PieBridge on the
IDCs of Baidu and obtained promising performance re-
sults in comparison with the prevalent approaches.
CCS Concepts
(cid:15)Networks ! Network algorithms; Network services;
Keywords
Cross-DR WAN; Large-scale Data Transmission
(cid:3)
This work has been supported by NSFC (61472212),
863 Project of China (2015AA010203) and EU
MARIE CURIE ACTIONS EVANS (PIRSES-GA-
2013-610524).
y
Work partly done when author is interned in Baidu.
Permission to make digital or hard copies of all or part of this work for person-
al or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22–26, 2016, Florianopolis, Brazil
c⃝ 2016 ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2959046
Figure 1: There are three geographically distributed
DRs, each has a super core and handles numbers of
IDCs. In each IDC, there are a series of clusters that
consists of tens of thousands of servers.
1.
INTRODUCTION
Large information platform providers, such as Mi-
crosoft [2, 4], Google [3, 5] and Baidu, provide time-
ly data information services for end users in a wide
range of geographical locations, and multiple IDCs are
built for the services. Fig.1 contains IDCs distribution
of Baidu that is the largest Chinese search engine in
the world. However, timely duplication of large amoun-
t of data across these geographically distributed IDCs
is known to be a challenge: 1) A service may have hun-
dreds of millions of users and generate several TBs of
data on daily basis. The data information is supposed
to be synchronized among IDCs through links, which
have limited bandwidth and cross traﬃc from other ap-
plications. On the other hand, upload/download serv-
er interfaces have limited data rates. 2) Transmission
completion time has to be short; users can access the
data only after the data synchronization transmission
is completed.
In this work we present PieBridge, a centralized data
transmission platform in WAN-scale. It schedules da-
ta transmission among IDCs, enhances system upload,
maximizes the total data traﬃc, and reduces the data
transmission completion time.
553
(cid:258)(cid:258)Super coreIDCCross-DR linkIDC link(a) Completion time.
(b) Upload link utilization.
Figure 3: The evaluation results.
2.3 Evaluation
We implement and evaluate PieBridge on the real
topology and data traﬃc matrices of Baidu’s WAN net-
works in go language. For a 30 Tbs data duplication,
which are stored in src IDCs in a distributed way, there
are 12 clusters and each downloads one data copy where
each cluster is typically equipped with 1,000 server-
s. We measure PieBridge’s completion time versus the
most popular approach - P2P. For a particular clus-
ter of 1,000 servers, we show the completion time in
Fig.3a. Obviously, PieBridge completes the transmis-
sion 3 times faster than P2P, and eliminates the long
tail phenomenon. Furthermore, Fig.3b displays the uti-
lization of upload links of the origin source server (src)
and two destination servers (s1 and s2), which are in d-
iﬀerent DRs. PiBridge substantially out performs P2P.
3. CONCLUSION
WAN-scale large data transmission is indispensable
for the service reliability and cost control. We design,
implement, deploy and experiment PieBridge at Baidu
network with promising results. It maximizes the com-
munication link bandwidth utilization and signiﬁcantly
reduces the data synchronization completion time.
4. REFERENCES
[1] J. Edmonds and R. M. Karp. Theoretical
improvements in algorithmic eﬃciency for network
ﬂow problems. Journal of the ACM (JACM),
19(2):248–264, 1972.
[2] C.-Y. Hong, S. Kandula, R. Mahajan, et al.
Achieving high utilization with software-driven
wan. In ACM SIGCOMM Computer
Communication Review.
[3] S. Jain, A. Kumar, S. Mandal, et al. B4:
experience with a globally-deployed software
deﬁned wan. Acm Sigcomm Computer
Communication Review, 43(4):3–14, 2013.
[4] S. Kandula, I. Menache, R. Schwartz, and S. R.
Babbula. Calendaring for wide area networks. In
Proceedings of the 2014 ACM conference on
SIGCOMM, pages 515–526. ACM, 2014.
[5] A. Verma, L. Pedrosa, M. Korupolu, and others.
Large-scale cluster management at google with
borg. In Proceedings of the Tenth European
Conference on Computer Systems, page 18, 2015.
Figure 2: The architecture of PieBridge
2. PIEBRIDGE
PieBridge has centralized control with an eﬃcient
scheduler that selects the data transmission source for
reducing the completion time of data synchronization.
2.1 A Scheduling Algorithm
PieBridge scheduling algorithm contains three pro-
cedures in one data transmission period: subtask se-
lection, max-traﬃc scheduling, and subtask merging.
First, when a transmission task arrives at the scheduler,
we ﬁrst split it into subtasks to be queued. Second, we
maximize the total weighted bandwidth allocation by
working on the residual network, a network that keep-
s track of the residual capacity. We then apply the
path augmentation algorithm [1] and add the amount
of data of the selected subtask to the chosen path. We
repeat the process on the residual network until there
is no more augmenting paths. Third, at the end of a
scheduling period, we merge the subtasks with the same
source/destination into one subtask to cut down the cal-
culation cost in the next scheduling period.
2.2 System Design
The architecture of PieBridge is shown in Fig.2 with
two main components: 1) A logically centralized con-
troller that accepts tasks from users and makes schedul-
ing decision. It consists of two parts: a scheduler and an
agent-monitor. The scheduler is a computation module
that executes our scheduling algorithm, and the agent-
monitor supports communications with agents. 2) A-
gents implement tasks at each node, control the data
transmission, and report the processing status to the
agent-monitor. It performs the functions of setting the
upload/download rate limits, maintaining the local sta-
tus information, and managing tasks.
When a user request arrives at PieBridge the con-
troller maintains admission control, and the scheduler
makes scheduling decision and informs the involved a-
gents through the agent monitor. Upon receiving an
assignment, an agent executes the scheduled data trans-
mission.
554
Meta serviceHdfsstatisticsWeb UIDBkylinNetwork MonitorauditAPIController(cid:36)(cid:74)(cid:72)(cid:81)(cid:87)(cid:3)(cid:80)(cid:82)(cid:81)(cid:76)(cid:87)(cid:82)(cid:85)(cid:54)(cid:70)(cid:75)(cid:72)(cid:71)(cid:88)(cid:79)(cid:72)(cid:85)(cid:36)(cid:74)(cid:72)(cid:81)(cid:87)(cid:48)(cid:68)(cid:81)(cid:68)(cid:74)(cid:72)(cid:85)(cid:36)(cid:74)(cid:72)(cid:81)(cid:87)(cid:48)(cid:68)(cid:81)(cid:68)(cid:74)(cid:72)(cid:85)(cid:36)(cid:74)(cid:72)(cid:81)(cid:87)(cid:48)(cid:68)(cid:81)(cid:68)(cid:74)(cid:72)(cid:85)(cid:36)(cid:74)(cid:72)(cid:81)(cid:87)(cid:48)(cid:68)(cid:81)(cid:68)(cid:74)(cid:72)(cid:85)(cid:48)(cid:50)(cid:48)(cid:48)(cid:52)(cid:48)(cid:48)(cid:54)(cid:48)(cid:48)(cid:56)(cid:48)(cid:48)(cid:49)(cid:48)(cid:48)(cid:48)(cid:48)(cid:53)(cid:48)(cid:49)(cid:48)(cid:48)(cid:49)(cid:53)(cid:48)(cid:50)(cid:48)(cid:48)(cid:50)(cid:53)(cid:48)(cid:51)(cid:48)(cid:48)(cid:51)(cid:53)(cid:48)(cid:52)(cid:48)(cid:48)(cid:67)(cid:111)(cid:109)(cid:112)(cid:108)(cid:101)(cid:116)(cid:105)(cid:111)(cid:110)(cid:32)(cid:84)(cid:105)(cid:109)(cid:101)(cid:32)(cid:40)(cid:109)(cid:41)(cid:32)(cid:32)(cid:80)(cid:105)(cid:101)(cid:66)(cid:114)(cid:105)(cid:100)(cid:103)(cid:101)(cid:80)(cid:50)(cid:80)(cid:48)(cid:53)(cid:49)(cid:48)(cid:49)(cid:53)(cid:50)(cid:48)(cid:50)(cid:53)(cid:51)(cid:48)(cid:51)(cid:53)(cid:52)(cid:48)(cid:52)(cid:53)(cid:53)(cid:48)(cid:48)(cid:49)(cid:48)(cid:50)(cid:48)(cid:51)(cid:48)(cid:52)(cid:48)(cid:53)(cid:48)(cid:54)(cid:48)(cid:55)(cid:48)(cid:56)(cid:48)(cid:57)(cid:48)(cid:49)(cid:48)(cid:48)(cid:84)(cid:105)(cid:109)(cid:101)(cid:32)(cid:40)(cid:109)(cid:41)(cid:85)(cid:112)(cid:108)(cid:111)(cid:97)(cid:100)(cid:32)(cid:76)(cid:105)(cid:110)(cid:107)(cid:32)(cid:85)(cid:116)(cid:105)(cid:108)(cid:105)(cid:122)(cid:97)(cid:116)(cid:105)(cid:111)(cid:110)(cid:32)(cid:40)(cid:37)(cid:41)(cid:32)(cid:32)(cid:115)(cid:114)(cid:99)(cid:115)(cid:49)(cid:115)(cid:50)