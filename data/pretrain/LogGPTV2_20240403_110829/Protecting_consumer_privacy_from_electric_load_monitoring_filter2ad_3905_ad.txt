390279 (7.8%)
Features (%)
18292 (50.8%)
5248 (39.6%)
8814 (56.6%)
7456 (24.1%)
Residual
Sisters (%)
3363 (60.8%)
1414 (45.3%)
2524 (69.1%)
2172 (28.4%)
in low battery states. Here, we see only 24-56% of the residual fea-
tures are present in the low state (which occurs less than 10% of the
time). Thus, while low state charging explains some of the residual
features, many are present in the also steady (non-charging) state.
One can partition residual features into three classes. The ﬁrst
class of features contains very small changes, e.g., less than 60
W, about the load of a typical light bulb. Such loads, the most
common in load proﬁles, are driven by numerous causes including
small lighting ﬁxtures, appliance state changes, and small electron-
ics requiring standby power. Because they reside in the band on
the smaller end of the power spectrum, it would not be difﬁcult for
a NILL system to mimic their arrivals and departures using small
variations in the battery charge and discharge rate. We thus do not
consider them for the remainder of this analysis.
A second class of features contains large transitions caused by
often short-lived heavy loads, e.g., kitchen microwave. The aggre-
gate draw of the large loads combined with ongoing draws exceeds
the target load (KL) plus the maximum output of the battery (60
A for the simulated battery we tested). There is little NILL can do
about these loads because it simply cannot safely supply the nec-
essary current. The last class are legitimate loads that are not man-
aged by NILL because of low state. Table 8 provides a breakdown
of the residual features present in the simulated environment. Inter-
estingly, 70-85% of the features and 92-98% of the sister features
are of the small variety.
Regardless of the reason for their presence, the features usable
by NILM to correctly uncover are the large and medium residual
sister features. To summarize:
 60 65 70 75 80 85 90 95 100 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Percent (of total time)RFMH1H2A1T194Table 8: Classiﬁcation of residual features
Residence
H1
H2
A1
T1
Small (%)
25334 (70.4%)
11319 (85.5%)
13139 (84.4%)
25823 (83.7%)
Features
Medium (%)
6257 (17.4%)
1193 (9.0%)
1249 (8.0%)
4717 (15.3%)
Large (%)
4378 (12.1%)
718 (5.4%)
1168 (7.5%)
321 (1.0%)
Small (%)
5167 (93.50%)
3079 (98.94%)
3555 (97.45%)
7512 (98.32%)
Sister Features
Medium (%)
214 (3.87%)
21 (0.67%)
45 (1.23%)
118 (1.54%)
Large (%)
145 (2.62%)
12 (0.39%)
48 (1.32%)
10 (0.13%)
Residence
H1
H2
A1
T1
Sister features
359 (0.11%)
33 (0.03%)
93 (0.05%)
128 (0.09%)
Per Day
5.9
1.1
3.1
4.4
Fewer than ten and as little as one true feature per day that are
available to NILM algorithms in our simulated environment. This
represents about 3 to 11 out of a thousand features exposed, a mi-
nuscule exposure of privacy.
One of the challenges a NILM algorithm might have in the pres-
ence of NILL is that it must identify which of the features out of
the total trace are legitimate. For example, there are 473 true sister
features hidden in 10,552 for H1. Unless there is a clear marker
identifying a true feature in the timing/amplitude, then it would be
virtually impossible to separate the real and synthetic transitions.
4.6 Entropy Analysis
In addition to comparing the number of features between the load
seen by the battery and that seen by the utility, comparing the em-
pirical entropy of two loads is also useful. As in the above discus-
sion, distinguishing information about which appliance or type of
appliance was just turned ON (or OFF) lies not in the d and u time
series of aggregate load versus time but rather lies in the features
(i.e., non-zero impulses) that. Deﬁne δd(t) = d(t) − d(t − 1) and
δu(t) = u(t)−u(t−1) as the time series of impulses generated by
the appliances and seen by the utility, respectively. For each time
series we deﬁne a probability mass function, Pδd and Pδu, respec-
tively, which takes a bin size b as a parameter. For concreteness
deﬁne the ith bin as being the range [ib, (i + 1)b) in units of watts.
Pδd(i|b) is just the fraction of the values of δd that are in bin i.
Pδu is deﬁned similarly. Given an empirical probability mass func-
tion P (i) we calculate the empirical entropy using base 2 in the
standard way:
X
i∈I
H(P ) = − 1
|I|
P (i) log2 P (i),
where I is the support of P , i.e., I = {i|P (i) > 0}.
Here, H(Pδd) can be interpreted as an upper bound on the num-
ber of bits of information a NILM algorithm could extract on av-
erage for each impulse sample in δd (if it had access to δd, as it
would in the case that our NILL hardware and software were not
deployed). Likewise, H(Pδu) can be interpreted as upper bound on
the number of bits of information a NILM algorithm could extract
on average for each impulse sample in δu, i.e., after the signal has
been smoothed by our NILL algorithm. Table 9 reports the empiri-
cal entropies for our four data sets, computed using a bin size of 1
W. The bin size was chosen this small to allow for the potential of
higher entropy due to higher precision but not any smaller in order
to mitigate the introduction of undue noise.
As noted above, the empirical entropy is an upper bound on the
information extractable by a NILM algorithm from a time series.
Strictly speaking, showing a gap between an upper bound on the
information extractable from d and an upper bound on the infor-
mation extractable from u does not prove that the NILL algorithm
decreases the information content of d. That is, the actual informa-
tion content extractable from d may be below the upper bound on
the information extractable from u. However, this would require
that the information content of the two signals have signiﬁcantly
different characteristics. In the event that the sequences have simi-
lar characteristics, the ratio between the upper bound and the actual
information extractable should be similar for each time series.
Note that if a time series is highly correlated, the empirical en-
tropy will overestimate the information in the series. (For example,
a series of 100 1’s followed by 100 2’s will have empirical entropy
of 1 bit per time step although the series clearly does not contain
200 bits of information.) There are clearly examples of correla-
tions in our time series. As mentioned above, when a home theatre
system was turned on in H1 and H2, several features occurred in
succession over a short period of time. In addition to such intra-
appliance correlations, some home loads have quasi-periodic be-
havior. Examples of such loads include refrigerator compressors
and home furnace systems.
To understand the extent of these time correlations we computed
the autocorrelation function (Pearson variant) of δd and δu. The
autocorrelation on input k of an n element times series s compares
s(i) with s(i + k) for all 1 ≤ i ≤ n − k. The autocorrelation
is always at most 1 and at least -1, with values near 1 implying a
high degree of correlation, values near -1 implying a high degree
of anti-correlation, and values near 0 implying a high degree of in-
dependence. The autocorrelation of δd had absolute value less than
0.02 for all values of the lag k. Thus, in spite of the fact that there
are some correlated impulses in the data set, the vast majority of
impulses appear to be uncorrelated. The non-zero impulses of δu
essentially constitute a subsequence of δd. (That is, if at time t,
δu(t) is non-zero then at the same time δd(t) is non-zero as well.
If fact, the size of the impulse is often the same in this case.) Since a
subsequence of a sequence of independent events is itself indepen-
dent, it follows that the impulses of δu are largely uncorrelated as
well. Indeed, the autocorrelation of the δu time series was similarly
small. This argues against the introduction of a systematic bias in
empirical entropy of one series versus the other due to differences
in time correlations between the two series.
In Table 9, the entropy is computed in two ways: one in which
zero values of the respective time series are included when calcu-
lating a probability mass function for the time series, and one in
which the zero values are excluded. Including the zero values has
intuitive appeal as the fact that there are many more zeroes in the
NILL time series does reﬂect that fact that the NILL time series
conveys less information to a NILM algorithm. However, to en-
sure that the number of zeroes in the NILL time series were not
biasing the results unduly, we also calculated the entropy of the
various time series without the zeroes included. As the entropy
represents the average amount of information per sample, and as
there are more samples in the Non-NILL time series, we have in-
95Table 9: Empirical Entropy
Residence Non-NILL
0.633267
0.235150
0.363826
0.360635
H1
H2
A1
T1
NILL
0.054265
0.029554
0.038459
0.019137
Ratio
0.085690
0.125681
0.1057071
0.0530647
5.663782
4.516394
4.468669
5.114588
Non-NILL w/o zeroes NILL w/o zeroes Normalized Ratio
7.519812
6.340144
6.526919
6.460732
0.078346
0.101323
0.039289
0.084519
Table 10: NILL Cost Reduction per Month in Simulated Envi-
ronments
Residence
H1
H2
A1
T1
O&R
$8.94 (2.09%)
$2.49 (5.16%)
$3.41 (3.37%)
$2.67 (2.53%)
Ont.
$11.11 (2.00%)
$3.78 (4.27%)
$4.96 (3.81%)
$3.72 (2.97%)
PG&E
$18.67 (1.81%)
$6.17 (4.28%)
$10.22 (4.67%)
$6.92 (2.62%)
cluded a ratio which normalizes for this fact. The numerator of the
ratio represents the total information available in the NILL time se-
ries (i.e., the entropy times the number of terms in the NILL series
without zeroes) and the denominator represents the total informa-
tion available in the Non-NILL time series (i.e., the entropy times
the number of terms in the Non-NILL series without zeroes).
Table 9 reports the empirical entropies for our four data sets.
When including the zeroes of the time series, the ratio of the NILL
to Non-NILL entropies varies from 0.53 on the low side for data set
T1 to 0.126 on the high side for data set H2. When the zeroes are
included, the normalized ratio varies from 0.039 on the low side for
data set A1 to 0.101 on the high side for data set H2.
5. DISCUSSION
5.1 Energy Efﬁciency and Consumer Cost
Because the cost of energy generation increases substantially
with mid-day demand, the Time of Use (TOU) pricing scheme is
being introduced to shave demand during peak hours [17]. TOU
creates a cost schedule that is tied to the demand curve observed by
the provider. Energy costs rise with expected demand. For exam-
peak use (10:00am-9:00pm) October through May. During June
ple, Orange and Rockland power in New York charges 1.280¢/kWh
for off-peak use (9:00pm-10:00am year round), and 7.17¢/kWh for
through September, peak charges increase to 7.17¢/kWh for shoul-
der peak use (10:00am-noon and 7:00pm-9:00pm) and 19.899¢/kWh
for high peak use (noon-7:00pm) [30]. TOU is touted as a way to
control costs by creating incentives for customers to use energy
during non-peak hours.
NILL may positively or negatively impact consumer cost under
a TOU schedule. Consider a simpliﬁed model of consumer cost
in a NILL and non-NILL household. Assume that the total kWh
usage for the home is U, the percentage of use at peak is Up, and
the provider costs for peak and off-peak are Cp and Co per kWh,
respectively. The total monthly bill for the home is:
T = (U ∗ Up) ∗ Cp + (U ∗ (1 − Up)) ∗ Co
According to the U.S. Energy Information Administration, the av-
erage home uses 920 kWh per month [39]. Using this ﬁgure, we
can bound on the cost or savings observable by an average res-
idence under Orange and Rockland TOU cost schedule.
In the
extreme cases, the costs of using NILL can increase by $24.84
(where the home uses no energy during peak hours) or decrease
by as much as $29.35 (where the home no energy during off-peak
hours). Based on usage statistics, the load of the average home
will use slightly more energy during peak hours (Up > %50), with
more pronounced peak loads in the summer months (due to air con-
ditioning).
Table 10 shows the energy costs in the simulated environments