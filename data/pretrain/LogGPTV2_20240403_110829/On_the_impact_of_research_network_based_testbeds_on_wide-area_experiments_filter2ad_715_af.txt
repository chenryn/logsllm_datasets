A/0.061
I/0.131
A/0.040
I/0.058
I/0.539
I/0.037
I/0.398
I/0.510
I/0.430
A/0.017
I/0.795
A/0.435
A/0.430
A/0.541
I/0.038
A/0.783
A/0.559
A/0.505
I/0.503
I/0.609
A/0.105
I/0.008
I/0.006
I/0.004
I/0.280
I/0.013
I/0.885
A/0.515
I/0.008
I/0.001
I/0.048
I/0.010
I/0.003
I/0.002
I/0.028
I/0.019
I/0.056
A/0.013
I/0.010
A/0.005
I/0.001
A/0.008
I/0.039
A/0.008
A/0.034
A/0.008
I/0.049
I/0.091
A/0.001
I/0.040
I/0.017
A/0.196
A/0.051
I/0.445
-/-
I/0.007
I/0.305
I/0.999
I/0.195
A/0.004
I/0.002
I/0.003
I/0.005
I/0.005
A/0.175
I/0.013
I/0.003
I/0.000
I/0.123
-/-
CP3
A/0.070
I/0.135
A/0.006
A/0.028
I/0.011
I/0.012
I/0.016
A/0.038
I/0.016
I/0.035
I/0.019
I/0.002
I/0.001
A/0.002
I/0.007
A/0.014
I/0.003
I/0.036
I/0.010
A/0.001
I/0.043
I/0.020
I/0.020
I/0.005
I/0.049
A/0.319
I/0.014
-/-
A/0.441
-/-
-/-
A/0.200
I/0.020
-/-
I/0.017
I/0.035
I/0.022
I/0.034
I/0.034
-/-
I/0.009
A/0.008
A/0.006
-/-
I/0.023
I/0.012
I/0.013
A/0.026
-/-
-/-
A/0.001
A/0.038
A/0.000
I/0.003
I/0.001
A/0.010
A/0.000
I/0.016
I/0.001
I/0.003
I/0.004
I/0.001
-/-
I/0.036
I/0.000
I/0.007
I/0.007
I/0.039
I/0.044
-/-
I/0.037
I/0.015
-/-
-/-
I/0.682
-/-
I/0.005
I/0.010
I/0.729
A/0.073
I/0.000
I/0.001
I/0.003
A/0.002
I/0.002
I/0.140
A/0.002
A/0.002
I/0.000
-/-
-/-
Table 2: Bottleneck locations in C2C paths. “-/-” de-
notes that the tool failed to locate any choke points.
Paths from atcorp and a few other paths are not de-
picted due to failure in detecting bottlenecks.
Paths
RTT
G2C-G2G 13.7
G2C-C2C
13.0
C2G-G2G 15.1
14.1
C2G-C2C
Loss
77.01
67.66
139.8
97.6
Cap. Av. BW Thrput.
267.5
843.2
49.2
123.3
1359.1
292.2
76.3
307.0
793.1
68.7
704.3
45.3
Table 3: Summary of comparisons using the relative
change metric.
(a) PlanetLab data set
(b) King data set
F
D
C
 100
 80
 60
 40
 20
 0
G2G
C2C
 0  0.2 0.4 0.6 0.8  1  1.2 1.4
Relative error
F
D
C
 100
 80
 60
 40
 20
 0
G2G
C2C
G-C
 0
 0.5
 1
 1.5
 2
Relative error
Figure 16: GNP performance in mixed testbeds.
Princeton and Pittsburgh that achieves 4 Mbps.
In conclusion, application performance can signiﬁcantly
vary depending on how the testbed is utilized. The research
network can signiﬁcantly aﬀect the measured performance.
If a multicast tree was indiscriminately constructed with
nodes belonging to both G and C, the G2G branches would
typically have higher throughput than a C2C link of similar
RTT. However if the tree is chosen only to have G2C or
C2G links, the performance is similar to C2C. For example
in Tree 1, we made the source node 1 a GREN node and
chose the remaining nodes in the given locations such that
all links are either G2C or C2G3. Figure 15(a) shows that
this G-C case is similar to C2C. Similarly, for Tree 2 we
chose the source node 5 to be a commercial node and again
chose the remaining nodes maintaining G2C/C2G links and
the performance is similar to C2C (Figure 15(b)).
6.2 Network Distance Prediction
Network distance prediction is an important network ser-
vice that allows the prediction of N 2 RTTs between N nodes
using only O(N ) measurements. The performance, i.e., ac-
curacy, of such prediction services depend on the RTT, con-
nectivity, peering policies, etc. Here we study the impact
of a mixed testbed on network distance prediction using
GNP [11], one of several systems proposed to perform net-
work distance prediction. GNP uses a ﬁxed set of landmarks
which ﬁrst compute their coordinates. Each end host then
derives its coordinates by minimizing the error between mea-
sured and estimated distances to landmarks.
6.2.1 Results
We used two real Internet latency datasets to evaluate
GNP (PlanetLab and “King” [34]). Each data set is es-
sentially an all-pair RTT matrix between a set of nodes.
For each data set we ﬁltered out the hosts into GREN and
commercial nodes and extracted smaller all-pair RTT ma-
trices. The PlanetLab data set is based on all-pair RTT
measurements among 8 GREN nodes and among 8 com-
mercial nodes from Section 5. The King data set originally
had RTT measurements between 1,953 nodes. We found
350 GREN nodes were part of this set so we also extracted
3The tree is 1∈G, 2∈C, 4∈C, 3∈G, 5∈G.
out 350 commercial nodes randomly from the trace. Since
the GNP algorithm requires a completely ﬁlled matrix, we
ran the Bron-Kerbosch clique generation algorithm [5] and
found a complete all-pair RTT matrix among 164 GREN
nodes and among 172 commercial nodes. We ran the pub-
licly available GNP code [30] on these traces to ﬁnd the
relative error in the predicted and measured distances, i.e.,
|dpredicted−dmeasured|
with 15 randomly chosen GREN land-
marks for the GREN nodes and commercial landmarks for
the commercial nodes.
dmeasured
Figure 16 shows that for both the smaller PlanetLab data
set and the larger King data set, running GNP on a G2G
testbed has much lower relative error than on a C2C testbed.
Thus the performance of network distance prediction de-
pends on the nature of nodes selected in the testbed. We
believe the G2G data set has lower errors because the G2G
network has fewer routing ineﬃciencies and its RTTs are
closely related to the node placement rather than queuing
and peering policies. The C2C testbed can have many such
variable quantities that make it diﬃcult to accurately pre-
dict network distances. Finally, we used a mixed trace with
210 commercial nodes and 140 GREN nodes selected ran-
domly from the larger King data set localized by 15 com-
mercial landmark nodes. The error distribution in this case
is more representative and similar to the C2C scenario since
a good number of G2C/C2G links were involved. The error
is slightly worse than C2C since localizing G2G links using
commercial landmarks can cause triangle inequalities.
In summary, G2G links are not representative of C2C
links, both with respect to performance properties and ap-
plication metrics. On the other hand, G2C and C2G better
represent C2C links. Thus, when a mixed testbed is used
to evaluate applications, G2G links should be avoided. In
the next section, we advocate a technique to leverage the
existing mixed testbeds while remedying the G2G links.
7. RECOMMENDATIONS ON
USING MIXED TESTBEDS
Based on the observations in the previous sections, we
now propose a node partitioning principle that minimizes
the impact of mixed testbeds on application performance
while leveraging the available GREN nodes simultaneously.
Node partitioning takes a set of N nodes from a testbed and
partitions them into sets C and G where C contains nodes
with only commercial connectivity and G contains nodes
that can route over GREN. A NP graph is then built such
that an edge between nodes i and j is inserted if and only
if (1) i ∈ G and j ∈ C or (2) i ∈ C and j ∈ G or (3) i ∈ C
and j ∈ C. This graph is then used by applications running
on the testbed nodes.
7.1 Using Node Partitioning
We have shown that Cases 2 and 3 result in traﬃc predom-
inantly ﬂowing over commercial networks and that the per-
formance properties observed are similar to Case 4, thereby
reducing the impact on application performance. Based on
this insight, a simple approach to improve the representa-
tiveness of application performance is to integrate node par-
titioning into distributed applications. For example, con-
sider overlay multicast applications. These typically use
neighbor beaconing to form multicast trees. Such appli-
cations can then be modiﬁed so that their neighbor view is
Overlay Route G−C−G
C
iT
G
G
Figure 17: Illustration of NP.
restricted as per the rules (1), (2) and (3) above. In this case,
the entire multicast tree constructed will be such that traf-
ﬁc ﬂows primarily over commercial networks and is thereby
representative.
A limitation with the above approach is that not all dis-
tributed applications can tolerate such disconnection. Con-
sider a DHT application on top of Pastry [20]. Assume when
all the overlay members are considered, the closest node to
item K is D. When S hashes K, if D is in S’s leafset but
S → D does not satisfy the rules above, data item K cannot
be inserted. This will lead to inconsistencies in the DHT.
Thus we need a method that improves representativeness
transparently to the applications. To this end, we propose
a toolkit, NP.
NP leverages the techniques from overlay routing [1, 7]
while partitioning nodes into those with GREN connectiv-
ity. NP transparently captures packets from applications
on particular slices based on pre-speciﬁed port numbers. If
the host node is a commercial node, then packets are left
unchanged.
If the host node is a GREN node, the desti-
nation IP is extracted from the packets and looked up in
a database to identify whether it is a GREN host. If the
destination is a GREN host, NP resorts to overlay rout-
ing (as shown in Figure 17 and routes all further packets
to this destination via an appropriately chosen intermediate
commercial host using an overlay route G-C-G. This can be
easily done using the same technique used to repair routes
in SOSR. The intermediate commercial host is chosen such
that it lies en-route to the GREN destination. For example,
the commercial host chosen could be a node closest in net-
work distance (i.e., minimizes Ti) to the source/destination
GREN node so as to minimize detours.
Applicability: Using NP should be a choice made by the
application designer when using the testbed and not a gen-
eral purpose service. For example, research that performs
network measurements should not use NP since the overlay
routing will not reﬂect the intent of the measurements and
will provide erroneous results.
NP is also limited by the number of commercial nodes
available in the testbed. However, we argue that it may be
useful just to increase the number of machines at commercial
sites4. This allows for a limited number of commercial sites
to be used for a large number of connections. However, NP
will not be useful for sender/receiver GREN node pairs that
have no commercial site close (in network distance) to either
the sender or the receiver.
7.2 Improving G2G Path Diversity
While NP eliminates G2G links, another approach to im-
proving representativeness in a mixed testbed is to include
G2G links that come from diverse GREN ASes [3]. From our
current measurements in PlanetLab, we found that out of a
total of 1322 GREN ASes, our all pair traceroutes (between
155 GREN nodes) traversed only 182 unique ASes. Further,
4It is typically easier (cheaper and convenient) to add more
machines at a current site than add an entirely new site.
out of all possible GREN AS → GREN AS links, only 901
unique links were visited. Thus there is a need and scope to
improve the diversity in PlanetLab. Also, when such diverse
GREN ASes become part of the testbed, it is essential to re-
visit the performance properties of G2G paths (which may
then have increased diversity) and compare them to C2C
paths. Note that even if there is improvement in network
diversity within GREN, an inherent limitation is that traﬃc
in GREN is much lesser than in commercial ISP networks.
As part of our future work, we are investigating if the dis-
tribution of performance properties of C2C links can be em-
ulated over G2G links in order to leverage G2G links while
improving the representativeness of wide-area experiments.
8. CONCLUSIONS
In this paper, we assessed the potential impact of cur-
rently used wide area network testbeds on the measured per-
formance of distributed systems and network services that
are widely deployed and prototyped on such testbeds. We
found that the fact that a large fraction of nodes are con-
nected to research networks can impact the representative-
ness of testbed evaluation results. Speciﬁcally, we found that
G2G paths have signiﬁcantly diﬀerent topological and per-
formance properties (available bandwidth, throughput, etc.)
than commercial network paths over which the distributed
systems and network services are to be deployed. Encour-
agingly, we found that traﬃc that traverses from a G to a
C node and vice-versa is more representative of commer-
cial networks since such paths primarily traverse commer-
cial networks and were found to have similar performance
properties to C-C paths. We demonstrated how the testbed
connectivity can impact application evaluation results and
proposed a technique that can be leveraged by applications
to improve the representativeness of their evaluation results
while maximally leveraging the existing infrastructure.
Our future work includes using routing data to assess the
routing stability of mixed GREN and commercial paths and
use it as an additional metric to measure the testbed rep-
resentativeness, as well as implementing the NP technique
and evaluating its performance in practice.
Acknowledgments
We would like to thank the anonymous reviewers for their
helpful comments. This work was supported in part by the
National Science Foundation under grants CNS-0430204 and
CAREER award CCF-0238379.
9. REFERENCES
[1] D. G. Andersen, H. Balakrishnan, M. F. Kaashoek, and
R. Morris. Resilient Overlay Networks. In Proc. of ACM
SOSP, 2001.
[2] S. Banerjee, B. Bhattacharjee, and C. Kommareddy.
Scalable Application Layer Multicast. In Proc. of ACM
SIGCOMM, 2002.
[3] S. Banerjee, T. G. Griﬃn, and M. Pias. The Interdomain
Connectivity of PlanetLab Nodes. In Proc. of PAM, 2004.
[4] A. Bavier, N. Feamster, M. Huang, J. Rexford, and
L. Peterson. In VINI Veritas: Realistic and Controlled
Network Experimentation. In Proc. of SIGCOMM, 2006.
[5] C. Bron and J. Kerbosch. Algorithm 457: Finding All
Cliques of an Undirected Graph. Commun. ACM, 16(9),
1973.
[6] C. Dovrolis, P. Ramanathan, and D. Moore. What Do
Packet Dispersion Techniques Measure? In Proc. of IEEE
Infocom, 2001.
[7] K. P. Gummadi, H. Madhyastha, S. D. Gribble, H. M.
Levy, and D. J. Wetherall. Improving the Reliability of
Internet Paths with One-hop Source Routing. In Proc. of
OSDI, 2004.
[8] N. Hu, L. E. Li, Z. M. Mao, P. Steenkiste, and J. Wang.
Locating internet bottlenecks: algorithms, measurements,
and implications. In Proc. of SIGCOMM, 2004.
[9] Y. hua Chu, S. G. Rao, and H. Zhang. A Case for End
System Multicast. In Proc. of ACM SIGMETRICS, 2000.
[10] R. Mahajan, N. Spring, D. Wetherall, and T. Anderson.
User-level internet path diagnosis. In Proc. of SOSP, 2003.
[11] T. S. E. Ng and H. Zhang. Predicting Internet Network
Distance with Coordinates-Based Approaches. In
Proceedings of IEEE INFOCOM, June 2002.
[12] U. of Oregon Route Views Archive Project.
http://www.routeviews.org.
[13] K. Park, V. S. Pai, L. Peterson, and Z. Wang. CoDNS:
Improving DNS Performance and Reliability via
Cooperative Lookups. In Proc. of OSDI, 2004.
[14] V. Paxson. Strategies for sound internet measurement. In
Proc. of IMC, 2004.
[15] L. Peterson, T. Anderson, D. Culler, and T. Roscoe. A
Blueprint for Introducing Disruptive Technology Into the
Internet. In Proc. of ACM HotNets, 2002.
[16] PlanetLab. http://www.planet-lab.org.
[17] S. Rhea, B. Godfrey, B. Karp, J. Kubiatowicz,
S. Ratnasamy, S. Shenker, I. Stoica, and H. Yu. OpenDHT:
A Public DHT Service and Its Uses. In Proc. of
SIGCOMM, 2005.
[18] RipeNCC: Routing Information Service Raw Data.
http://abcoude.ripe.net/ris/rawdata/.
[19] RON. http://nms.csail.mit.edu/ron/sites/.
[20] A. Rowstron and P. Druschel. Pastry: Scalable, Distributed
Object Location and Routing for Large-Scale Peer-to-peer
Systems. In Proc. of ACM/IFIP/USENIX Middleware,
November 2001.
[21] A. Rowstron and P. Druschel. Storage management and
caching in PAST, a large-scale, persistent peer-to-peer
storage utility. In Proc. of SOSP, 2001.
[22] J. Sommers, P. Barford, N. Duﬃeld, and A. Ron.
Improving accuracy in end-to-end packet loss measurement.
In Proc. of SIGCOMM, 2005.
[23] N. Spring, R. Mahajan, and T. Anderson. Quantifying the
causes of internet path inﬂation. In Proc. of SIGCOMM,
2003.
[24] J. Strauss, D. Katabi, and F. Kaashoek. A measurement
study of available bandwidth estimation tools. In Proc. of
IMC, 2003.
[25] L. Subramanian, I. Stoica, H. Balakrishnan, and R. Katz.
OverQoS: An Overlay Based Architecture for Enhancing
Internet QoS. In Proc. of USENIX NSDI, 2004.
[26] L. Wang, K. Park, R. Pang, V. S. Pai, and L. Peterson.
Reliability and security in the codeen content distribution
network. In Proc. of USENIX ATC, 2004.
[27] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad,
M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An
Integrated Experimental Environment for Distributed
Systems and Networks. In Proc. of OSDI, 2002.
[28] P. Yalagandula, P. Sharma, S. Banerjee, S.-J.Lee, and
S. Basu. S3: A Scalable Sensing Service for Monitoring
Large Networked Systems. In Proc. of the Workshop on
Internet Network Management, 2006.
[29] R. Zhang and Y. C. Hu. Assisted Peer-to-Peer Search with
Partial Indexing. In Proc. of IEEE INFOCOM, 2005.
[30] GNP Homepage.
http://www.cs.rice.edu/ Eugeneng/research/gnp/.
[31] Iperf. http://dast.nlanr.net/Projects/Iperf/.
[32] PlanetLab IPerf. http://www.planet-lab.org/logs/iperf/.
[33] S3: Scalable Sensing Service.
http://networking.hpl.hp.com/s-cube/.
[34] The P2PSim Project. http://pdos.csail.mit.edu/p2psim/.
[35] The Gnutella protocol speciﬁcation, 2000.
http://dss.clip2.com/GnutellaProtocol04.pdf.