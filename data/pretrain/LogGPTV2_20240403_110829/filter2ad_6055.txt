title:Rethinking congestion control architecture: performance-oriented congestion
control
author:Mo Dong and
Qingxi Li and
Doron Zarchy and
Brighten Godfrey and
Michael Schapira
Rethinking Congestion Control Architecture:
Performance-oriented Congestion Control
Mo Dong
University of Illinois at
Urbana-Champaign
Qingxi Li
University of Illinois at
Urbana-Champaign
Doron Zarchy
Hebrew University of
Jerusalem
Brighten Godfrey
University of Illinois at
Urbana-Champaign
Michael Schapira
Hebrew University of
Jerusalem
ABSTRACT
After more than two decades of evolution, TCP and its end host
based modiﬁcations can still suffer from severely degraded per-
formance under real-world challenging network conditions. The
reason, as we observe, is due to TCP family’s fundamental ar-
chitectural deﬁciency, which hardwires packet-level events to con-
trol responses and ignores emprical performance. Jumping out of
TCP lineage’s architectural deﬁciency, we propose Performance-
oriented Congestion Control (PCC), a new congestion control ar-
chitecture in which each sender controls its sending strategy based
on empirically observed performance metrics. We show through
preliminary experimental results that PCC achieves consistently
high performance under various challenging network conditions.
Categories and Subject Descriptors
C.2.1 [Computer-Communication Networks]: Network Archi-
tecture and Design—Network Communication
Keywords
congestion control
1.
INTRODUCTION
In the roughly 25 years since its deployment, TCP’s conges-
tion control architecture has been notorious for degraded perfor-
mance in numerous real-world scenarios. TCP performs poorly on
lossy links, penalizes high-RTT ﬂows, has difﬁculty utilizing high
bandwidth-delay product (BDP) connections, can collapse in an in-
cast [3] scenario and incurs bufferbloat [4].
Two broad avenues of research have been pursued to improve the
performance of TCP. The ﬁrst is for network devices to give end-
hosts explicit feedback. However, because these designs require
hardware and conﬁguration changes and (for [6]) packet header
changes, in-network solutions have rarely seen widespread deploy-
ment.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage, and that copies bear this notice and the full ci-
tation on the ﬁrst page. Copyrights for third-party components of this work must be
honored. For all other uses, contact the owner/author(s). Copyright is held by the
author/owner(s).
SIGCOMM’14, August 17–22, 2014, Chicago, IL, USA.
ACM 978-1-4503-2836-4/14/08.
http://dx.doi.org/10.1145/2619239.2631456 .
In the second avenue of research, end-host-based modiﬁcations
have addressed problems in speciﬁc network conditions, result-
ing in an innumerably long string of designs tweaking TCP. These
include using latency rather than just loss as a signal of conges-
tion [8], sophisticated window expansion algorithms [5] for high
bandwidth-delay produce link, coordinated adjustment of the re-
ceive window across connections at the receiver to mitigate in-
cast [10], viewing a certain amount of packet loss as unrelated to
congestion [7] for lossy wireless networks, expanding the window
quicker by setting up a reference RTT [2] to speed up TCP on satel-
lite links and so on.
Although they use distinct congestion control algorithms, all end-
host-based TCP variants inherit the very same TCP-based conges-
tion control architecture: hardwiring certain packet-level events
(e.g. packet-loss) directly to certain control responses (e.g. halv-
ing the window size) like a mapping function. New TCP variants
change the mapping function, but the mapping-based design itself
has not changed.
Unfortunately, two critical problems remain unsolved. First, the
very fact that there are such a large number of modiﬁcations in-
dicates that each is only a point solution:
they yield better per-
formance in certain cases, but break in others, i.e. consistently
high performance is not achieved. Second, and actually worse, we
found through real-world experiments that in many cases the per-
formance of these modiﬁcations is still far from optimal even in the
network conditions towards which they are specially engineered.
We believe these two problems are due to the fundamental deﬁ-
ciency in the TCP-based congestion control architecture. The de-
sign rationale behind the mapping function architecture is to make
assumptions about the packet-level events. When seeing a packet-
level event, TCP assumes the network is in a certain state and thus
tries to optimize the performance by triggering a predeﬁned con-
trol behavior as response to that assumed network state. How-
ever, in real networks, it is very common that the observed packet-
level events were not a result of the assumed network condition.
When this assumed link breaks, TCP still mechanically carries out
the mismatched control response without even being aware of the
severely degraded performance. Take an event-control pair from
textbook TCP for example: a packet loss halves the congestion
window size. TCP assumes that the packet loss event indicates
congestion in the network.
If the assumptions about this packet
loss event are valid, halving the window size will result in reduced
loss rate and may improve performance. However, this assump-
tion can be easily violated: packet loss can be random and unre-
lated to congestion and thus halving the window size will cause
365Figure 2: Large scale Internet experiment demonstrating PCC’s perfor-
mance improvement over TCP CUBIC
and low loss rate, competing PCC senders will provably converge
to a fair share point (unique Nash Equlibrium).
3.
IMPLEMENTATION AND EVALUATION
We built a PCC prototype on top of UDP and evaluated it in ex-
periments spanning PlanetLab, the GENI network, Emulab, and a
local testbed. These experiments, carried out without any tweak-
ing of control algorithm, show PCC signiﬁcantly beating or at least
matching specially engineered TCPs on challenging network envi-
ronments: a. provisioned very high capacity backbone networks
for scientiﬁc data transfer, b. incast in data center networks, c. lossy
satellite links, d. links with tiny buffers, e. links with bufferbloat,
f. unfairness of RTT, g. the wild and complex conditions of the real
Internet, h. unusually high loss rate and i. latency sensitive appli-
cations requiring high throughput and low latency. We also show
that PCC’s convergence is more stable than TCP even though it has
no explicit concern for fairness in its design. Due to the space limit,
we only brieﬂy expand two interesting examples here.
High performance satellite communication: satellite links serve
critical missions but have packet loss and excessively high latency.
State-of-the-art solutions use relay nodes [1] and the purpose-built
TCP Hybla [2]. PCC achieves 17× higher throughput than Hybla
on links with satellite characteristics, reaching 90% capacity.
5X faster data delivery over Internet: In our global-scale eval-
uation over 480 sender-receiver pairs across the commercial Inter-
net (Fig. 2), PCC outperforms high BDP optimized TCP CUBIC
by 5.52× in the median and achieves ≥ 10× for 41% of source-
destination pairs.
Acknowledgement: This work was supported by National Sci-
ence Foundation grant CNS 1149895.
4. REFERENCES
[1] TCP accelarate on satellite link. http://goo.gl/E6q6Yf.
[2] C. Caini and R. Firrincieli. TCP Hybla: a tcp enhancement for heterogeneous
networks. International Journal of Satellite Communications and Networking,
2004.
[3] Y. Chen, R. Grifﬁth, J. Liu, R. H. Katz, and A. D. Joseph. Understanding tcp
incast throughput collapse in datacenter networks. Proc. ACM SIGCOMM
Workshop on Research on Enterprise Networking, 2009.
[4] J. Gettys and K. Nichols. Bufferbloat: Dark buffers in the internet. December
2011.
[5] S. Ha, I. Rhee, and L. Xu. CUBIC: a new TCP-friendly high-speed TCP
variant. Proc. ACM SIGOPS, 2008.
[6] D. Katabi, M. Handley, and C. Rohrs. Congestion control for high
bandwidth-delay product networks. Proc. ACM SIGCOMM, August 2002.
[7] S. Liu, T. Ba¸sar, and R. Srikant. Tcp-illinois: A loss-and delay-based
congestion control algorithm for high-speed networks. Performance Evaluation,
65(6):417–440, 2008.
[8] D. Wei, C. Jin, S. Low, and S. Hegde. FAST TCP. IEEE/ACM Trans.
Networking, December 2006.
[9] K. Winstein and H. Balakrishnan. Tcp ex machina: Computer-generated
congestion control. Proc. ACM SIGCOMM, 2013.
[10] H. Wu, Z. Feng, C. Guo, and Y. Zhang. ICTCP: Incast congestion control for
TCP in data center networks. Proc. CoNEXT, 2010.
Figure 1: The TCP and PCC architectures compared.
severe performance and fairness degradation. Even the recently
proposed TCP exMachina [9] still follows TCP’s architecture: in a
computationally-intensive ofﬂine optimization, it generates a TCP-
like event-control mapping function optimized for a set of assumed
network conditions. This helps improve performance when the net-
work conforms to the assumptions, but when underlying network
condition become different from the input model (e.g.
the num-
ber of concurrent senders exceeds the expected value), performance
still degrades. Therefore, achieving consistently high performance
across a range of challenging network conditions within the 25-
year-old TCP based mapping architecture is fundamentally hard.
To solve these problems, we rethink congestion control archi-
tecture design and propose Performance-oriented Congestion Con-
trol (PCC). PCC makes control decisions directly based on empir-
ically observed performance outcomes and we show through pre-
liminary but large scale experiments that it is a promising path to-
wards a congestion control architecture that achieves consistently
high performance over a range of challenging network scenarios.
2. ARCHITECTURE OVERVIEW
Unlike the TCP family’s congestion control architecture, PCC
does not use any predeﬁned packet-level event to trigger certain
control behavior. Instead, PCC, as shown in Fig. 1, optimizes ap-
plications’ performance objectives based on real performance met-
rics: it picks a sending rate, continuously observes the resulting ef-
fect on its performance such as loss rate, throughput, and RTT; and
feeds these performance values into a utility function to produce a
numerical performance value reﬂecting the application’s objective
such as “high throughput and low loss rate”. The sender then runs
an online learning control algorithm to selﬁshly adjust its sending
rate to maximize this utility over time. Intuitively, this performance
oriented congestion control architecture is more robust than tradi-
tional TCP’s event-control design because it makes fewer assump-
tions. Rather than using packet-level events to trigger hardwired
responses, PCC observes meaningful performance and learns the
empirically best strategy to optimize this performance.
Though PCC has no notion of fairness in its design, it turns out
that PCC’s selﬁsh optimization need not equate to loss of stability,
convergence, or fairness. When choosing a certain kind of utility
function expressing the widely-applicable goal of high throughput
NetworkNetworkPacket-level EventsPCC ArchitectureNetworkNetworkPacket-level EventsHardwired Control ResponsesTCP ArchitectureLearningControl AlgorithmNew Control ActionAggregatePerformanceAggregate PerformanceNew Control Action1.2X-2X2X-5X5X-10X 10X - 100X >100X<1.2X366