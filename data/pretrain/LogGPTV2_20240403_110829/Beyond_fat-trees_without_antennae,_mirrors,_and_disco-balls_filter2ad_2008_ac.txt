course, if there were no additional cost for flexibility, i.e., δ = 1,
unrestricted dynamic networks would have an advantage: trivially,
they can at least do anything a static network can.
4.1 Static v. un/restricted dynamic nets: a toy example
Consider a network with 54 switches, each with 12 ports, 6 of which
are attached to servers. The devices and links necessary for this
discussion are shown in Fig. 4. Now assume that the TM involves
servers on only the 9 racks at the bottom. Thus, servers on each
of the other 45 switches are inactive and irrelevant, and one can
think of these switches as just 6-port devices. These 45 switches
can then be connected in a standard fat-tree topology with k = 6,
while exposing 54 of their ports to traffic sources and sinks between
which they provide full bandwidth. These 54 ports can be connected
in any convenient manner to the 9 switches with active servers,
thus providing full bandwidth between all active servers.
Using the topology in Fig. 4, the unrestricted model can, of course,
achieve full throughput. Even if the limitation of direct-connection
Matchings aren’t a great thing!… total 9 switches…… total 18 switches…… total 9 switches…Inactive servers Fat-tree (k = 6)… total 18 switches…SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
S. Kassing et al.
heuristics was imposed, but unlimited buffering was allowed,
full throughput could still be achieved by moving the dynamic
connections between the 9 racks in a round-robin fashion – at any
moment, the network can deliver the same capacity as the servers
need. (The number of servers on active racks equals their outgoing
links, and each packet consumes one unit capacity in the network
via the direct connection.) However, in practice, buffering cannot be
unlimited, and at relatively small time intervals, the reconfiguration
overhead must be incurred. ProjecToR’s recommended duty cycle,
for instance, could achieve 90% of full throughput.
Notice that the topology in Fig. 4 does not connect any of the 9
switches with traffic demands directly, unlike a restricted dynamic
network. Additionally, the absence of buffering will require that all
flows be concurrently serviced, implying that for all-to-all traffic
between these switches, there is no advantage to moving links
around. This makes the restricted dynamic model no better than
the best possible static topology connecting the 9 racks using their
direct links. The performance of any such a topology is upper
bounded (computed as in [30]) at 80% of the full throughput.
Interestingly, the best known static networks of the same
cost achieve full throughput for near-worst-case traffic patterns
across the same number of communicating servers, without being
designed with any awareness of which servers will be active. We
verified this with experiments over Jellyfish in two configurations
supporting the same number of servers: (a) with 9 network ports
at each of the 54 switches, instead of a dynamic network’s 6 (i.e.,
δ = 1.5); and (b) with the same port count of 12 for all switches as
in the above discussion, but with 81 such switches (again, δ = 1.5).
Other expander-based data centers would achieve the same result.
This toy example illustrates the question at the heart of this
work: do a dynamic network’s fewer / more expensive, but flexible
connections compare favorably to a larger number of cheaper static
connections? We shall later explore this question in greater depth
quantitatively, but it is also useful to point out the several qualitative
factors that may put dynamic networks at a disadvantage.
4.2 Barriers to the deployment of dynamic networks
Dynamic topologies are an intuitive and exciting idea, but bear
little resemblance to present practice in data centers, thus posing
unique challenges for deployment:
• Unfamiliar problems in device packaging, spatial planning.
• Monitoring and debugging the highly ephemeral networks.
• The impact of environmental factors like dust, vibration, and
temperature on device alignment and functioning.
• Lack of clarity on the reliability and lifetime of the used devices
in environments they are not intended for.
• Lack of operator experience with the devices involved.
Certainly, not all the above criticisms apply across all proposals
in this direction, but some are fundamental, e.g., monitoring and
debugging networks that are themselves changing. Deploying a
different static topology like Xpander may also require changes, e.g.,
to any automation and operator training specific to Clos networks,
but these barriers are substantially lower, as evidenced by the
recent deployment of the DragonFly [23] topology in the high-
performance computing space.
5 Static (cid:44) Inflexible
This section presents a head-to-head comparison of static and
dynamic networks, focused on the topology models themselves,
neglecting any inefficiencies from routing and congestion control,
and additionally, in the case of dynamic networks, the dynamic
topology optimization. §6 will address, for static networks, the
problem of translating results from this idealized setting to low
flow-completion times under dynamic, skewed network traffic.
We verified that Xpander and Jellyfish achieve identical per-
formance. Experiments in this section use Jellyfish as its ease of
construction with arbitrary switch and port counts allows us to
include two other recent static networks for comparison. Results in
§6 use Xpander to side-step concerns about Jellyfish’s randomness.
Both dynamic and static networks are evaluated here under
skewed but difficult (ideally, worst-case) TMs — in line with the
definition of TP (§2.2), we want oversubscribed networks to provide
high throughput for any TM involving small subsets of servers.
We borrow heavily from recent work on comparing topolo-
gies [20], using the associated throughput evaluation tool [21]. We
use a series of skewed TMs, increasing the fraction of server racks
participating in the TM, with no flows between non-participating
racks. For static networks, we use longest matching TMs [20],
whereby each participating rack sends all its traffic to one other rack,
and the rack pairings maximize distance between communicating
racks using a heuristic: maximum-weight matching, with the
weights being the distances between racks. Intuitively, flows along
long paths consume resources on many edges, and the large rack-
to-rack flows reduce opportunities for load balancing traffic. These
TMs have been shown (empirically) to be harder than TMs such
as all-to-all [20]. Thus, while finding the worst-case TM is a
computationally non-trivial problem, we made our best efforts to
evaluate static networks under difficult TMs.
In the context of dynamic networks, longest matching TMs are
meaningless: by changing the topology, distances between racks
can be changed. The unrestricted model is simple to dispose of,
regardless of TM. As long as the bottlenecks are not at the servers,
independent of the number of ToRs networked, it can achieve per-
server throughput min{1, r
s }, if every ToR has r network ports and
s server ports — at any moment, a ToR can be delivering r units
of traffic directly to a destination, and at most producing s units.
The independence from the number of racks comes from ignoring
the reconfiguration time and buffering, which would be important
concerns in any evaluation of latency or flow completion time.
For the restricted model, instead of evaluating specific mecha-
nisms for computing topologies, we compute an upper-bound on
the performance of any topology which could be built using the
fixed network degree r at each ToR, as explained in §4.1.
Results: All the non-fat-tree networks achieve much higher
performance than a same-cost oversubscribed fat-tree, particularly
as fewer servers participate in the TM (leftward along the x-axis).
Fig. 5(a) shows results for SlimFly (578 ToRs, 25 network- and
24 server-ports per ToR) [9], Jellyfish built with exactly the same
equipment, and the throughput proportionality (TP) curve using
the throughput achieved for Jellyfish at x=1.0 as the base3 (i.e.,
3Our interest is in assessing how well the best-performing static networks compare
to TP, and thus we only show the TP curve for Jellyfish. Given that Jellyfish is not
Beyond fat-trees without antennae, mirrors, and disco-balls
SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
(a)
(b)
Figure 5: Throughput proportionality and dynamic networks compared with (a) SlimFly and a same-equipment Jellyfish; and (b) Longhop and a same-equipment
Jellyfish. According to measurements used to make the case for dynamic topologies, the shaded region is the regime of interest. For both cases, the unrestricted
model would achieve full throughput for δ = 1, i.e., if there were no additional cost for flexibility.
(a)
(b)
Figure 6: A direct comparison between a full bandwidth fat-tree and an oversubscribed Jellyfish network: (a) Jellyfish with fewer switches — 80%, 50%, and 40%
— as a k = 20 fat-tree, while supporting the same number of servers. With 50% fewer switches, it still provides nearly full bandwidth connectivity between any
40%-subset of servers. (b) This advantage is consistent or improves with larger k (12, 24, 36). Jellyfish supports 2× the fat-tree’s servers in each case.
α in Fig. 2). For a hypothetical TP-network built at the same
oversubscription as Jellyfish, in this case, when fewer than 35%
of servers are involved, each would obtain full throughput. The
restricted dynamic topology model (with two-thirds the network
ports used by the static networks, i.e., δ = 1.5) performs poorly. The
unrestricted dynamic model (δ = 1.5) achieves lower throughput
than Jellyfish when a smaller fraction of servers is involved. It is
noteworthy, that this is the operating regime for many deployments
— recent measurements across 4 large production clusters showed
46-99% of rack-pairs exchanging no traffic [13] in a representative
5-minute window. Fig. 5(b) shows broadly similar results in a
configuration based on the Longhop topology [32] (512 ToRs, 10
network- and 8 server-ports per ToR).
far from TP, combining this experimental result with the analysis in §2.2 implies that
static networks cannot exceed Jellyfish’s scaling characteristic, and more generally,
that of expander-based networks, by a large margin.
Clearly, reducing the number of network ports hurts the dynamic
topologies due to ToR-level bottlenecks. Thus, in an alternative
approach to equal-cost comparisons, instead of reducing the
network ports for the dynamic networks, we also evaluated Jellyfish
with δ× the network ports. As in the example in §4, we evaluated
two possibilities: (a) giving Jellyfish δ× switches of the same port-
count, and (b) giving Jellyfish the same number of switches, but
each with δ× network ports. In both settings, even with δ = 1.5,
Jellyfish achieved full throughput in the regime of interest.
Beyond comparisons with dynamic networks, we also attempt
to quantify how much more efficient expander-based networks can
be than fat-trees for such skewed traffic. Fig. 6(a) shows the results
for Jellyfish built using the same number of servers, and 80%, 50%,
and 40% of the switches available to a full fat-tree with k=20 (i.e.,
500 switches, with 20 ports each, and 2000 servers). With 50% of the
fat-tree’s switches (and 37.5% its network cables; the server-switch
 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Throughput proportionalJellyfishUnrestricted dyn (δ=1.5)SlimFlyRestricted dyn (δ=1.5)Equal-cost fat-treeThroughput per serverFraction of servers with traffic demand 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Throughput proportionalJellyfishUnrestricted dyn (δ=1.5)LonghopRestricted dyn (δ=1.5)Equal-cost fat-treeThroughput per serverFraction of servers with traffic demand 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Throughput per serverFraction of servers with traffic demand80% fat50% fat40% fat 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Throughput per serverFraction of servers with traffic demandk = 36k = 24k = 12SIGCOMM ’17, August 21–25, 2017, Los Angeles, CA, USA
S. Kassing et al.
(a)
(b)
(c)
Figure 7: Failure scenarios for ECMP and VLB: (a) ECMP fails to use path diversity between directly connected ToRs. (b) Average FCT, in a scenario where only 10
servers on two adjacent racks in Xpander are active. For the fat-tree, servers on two racks in the same pod are active. (c) Average FCT for all-to-all traffic.
cables are the same number, of course), Jellyfish can provide nearly
full bandwidth as long as <40% of servers participate in the TM.
Fig. 6(b) shows that Jellyfish’s advantage is consistent, or
improves with scale, as it is built using the same set of switches as
full fat-trees built with k=12, 24, and 36, but with twice the servers
in each case. Note that Jellyfish topologies are being impaired more
severely than may be evident: adding more servers at a switch with
the same port-count also reduces the number of network ports
available to connect to other switches.
6.1 ECMP does not always suffice
Expander-based static networks connect ToRs directly to each other.
Consider any pair of ToRs which are direct neighbors (Fig. 7(a)),
and a traffic matrix consisting of only traffic between these two
racks. For this traffic, ECMP enables the use of only the direct link
between these racks, even though the rest of the network is unused.
This inability to use multiple paths creates a bottleneck, degrading
throughput. The result of packet-level simulations for this scenario
is shown in Fig. 7(b), where just 10 servers on two adjacent racks
send each other traffic. (Details of the experiment are unimportant
for now, but curious readers can refer to §6.4.) As soon as the load
is enough to saturate the bottleneck, the average flow completion
time (FCT) becomes much higher in Xpander-ECMP.
Using Valiant Load Balancing [39] in Xpander on the other hand,
achieves much better results; using random via points to bounce
traffic through enables the use of path diversity that ECMP prohibits.
Perhaps VLB is the right answer, then?
6.2 VLB does not always suffice
Unfortunately, VLB has not one, but two shortcomings: first, as is
already clear from Fig. 7(b), the use of longer paths inflates network
RTTs, and thus FCT for short flows which are RTT bound, even
though high throughput can be achieved. Second, when there is
in fact high traffic demand throughout the network, VLB’s use of
random via points makes inefficient use of network bandwidth.
FCT results for such a scenario, with Xpander with an all-to-
all traffic matrix, are shown in Fig. 7(c). As the load increases,
VLB’s performance deteriorates, and ECMP achieves much better
results, matching the full-bandwidth fat-tree because the workload
is uniformly spread, and the optimal choice is indeed to use shortest
paths for all traffic.
6.3 A robust ECMP-VLB hybrid
These corner-cases already yield useful information: for workloads
like the one described by Facebook [28], ECMP on Xpander would
indeed perform well, matching the fat-tree’s performance at much
lower cost, as we shall see later. Further, for skewed workloads
like those considered by dynamic networks such as ProjecToR [13],
VLB suffices, modulo the increase in FCT for short flows, which
is determined more by RTT than bandwidth. These observations
provide the intuition for a simple hybrid scheme that achieves high
performance across a diversity of workloads.
Results in Fig. 5 and 6 cover oversubscription (1: 1
α
) ranging from
1:4 through nearly 1:1. Throughout the regime of interest, for large
α, both unrestricted dynamic networks (with δ = 1.5) and Jellyfish
achieve full throughput, and for smaller values of α, both fall short,
but Jellyfish compares well with dynamic networks.
To summarize, in a fluid-flow model ignoring inefficiencies in
routing, congestion control, and dynamic optimization, known
static topologies provide substantial efficiency gains over fat-trees.
Further, particularly under the skewed workloads used to make
the case for dynamic topologies, they fail to provide an advantage
over these static topologies.
6 Simple, effective routing on static networks
Routing on expander-based networks is nontrivial [31, 33], and
so far, solutions have depended on MPTCP [36] over k-shortest
paths [38]. While this approach has been shown to achieve