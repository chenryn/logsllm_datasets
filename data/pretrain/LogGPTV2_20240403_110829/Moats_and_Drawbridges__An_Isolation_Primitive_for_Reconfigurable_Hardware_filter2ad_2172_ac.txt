tures.
Figures 5 and 6 show the experimental results, where we
provide the average hardware area cost and critical path per-
formance for all the benchmarks over four conﬁgurations.
The existence of longlines has little impact on the ﬁnal qual-
ity of the mapped circuits. However, signiﬁcant degradation
occurs when we eliminate segments of length 2 and 6. This
is caused by the increased demand for switch boxes, result-
ing in a larger hardware cost for these additional switch re-
sources. Moreover, the signal from one pin to another pin is
more likely to pass more switches, resulting in an increase
in the critical path timing.
If we eliminate hex and long
lines, there is a 14.9% area increase and an 18.9% increase
in critical path delay, on average. If the design performance
is limited directly by the cycle time, the delay in critical
path translates directly into slowdown.
3.4 Overall Area Impact
While the results from Figures 5 and 6 show that there
is some area impact from constraining the routing, there is
Effective Utilization vs. Number of Cores
)
%
(
n
o
i
t
a
z
i
l
i
t
U
e
v
i
t
c
e
f
f
E
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
Moat Size = 1
Moat Size = 2
Moat Size = 6
 1
 10
 100
Number of Cores on Chip
Figure 7. The trade-off between the number
of cores, the size of the moat, and the utiliza-
tion of the FPGA. An increasing number of
cores results in larger total moat area, which
reduces the overall utilization of the FPGA.
Larger moat sizes also will use more area re-
sulting in lower utilization.
Soft
AES
Core
Soft
µP Core
Switchbox
Moat
Soft
µP Core
FPGA Chip Floor Plan
Core 1
Moat
Core 2
Figure 4. We use moats to physically isolate cores for security. In this example, segments can either
span one or two switch boxes, which requires the moat size to have a length of two. Since the
delay of a connection on an FPGA depends on the number of switch boxes it must pass through,
restricting the length of segments reduces performance, but the moats can be smaller. Allowing
longer segments improves performance, but the moats must waste more area.
also a direct area impact in the form of resources required
to implement the actual moats themselves. Assuming that
we have a ﬁxed amount of FPGA real estate, we really care
about how much of that area is used up by a combination
of the moats and the core inﬂation due to restricted routing.
We can call this number the effective utilization. Speciﬁ-
cally, the effective utilization is:
Uef f =
AAllRoutes
ARestrictedRoutes + AM oats
Figure 7 presents the trade-offs between the moat size,
the number of isolated cores on the FPGA, and the utiliza-
tion of the FPGA. The FPGA used for these calculations
was a Xilinx Virtex-4 Device which has 192 CLB rows
and 116 CLB columns. The ﬁgure examines three differ-
ent moat sizes: 1, 2 and 6 for a variable number of cores on
the chip (conservatively assuming that a moat is required
around all cores). As the number of cores increases, the uti-
lization of the FPGA decreases since the area of the moats,
which is unusable space, increases. However, when a small
number of cores is used, a larger moat size is better because
it allows us to make more efﬁcient use of the non-moat parts
of the chip. If you just need to isolate a single core (from the
I/O pads) then a moat of width 6 is the best (consuming 12%
of the chip resources). However, as the curve labeled “Moat
Size = 2” in Figure 7 shows, a moat width of two has the op-
timal effective utilization for designs that have between two
and 120 cores. As a point of reference, it should be noted
that a modern FPGA can hold on the order of 100 stripped
down microprocessor cores. The number of cores is heav-
ily dependent on the application, and the trade-off presented
here is somewhat speciﬁc to our particular platform, but our
analysis method is still applicable to other designs. In fact,
as FPGAs continue to grow according to Moore’s Law, the
percent overhead for moats should continue to drop. Be-
√
cause the moats are perimeters, as the size of a core grows
n).
by a factor of n, the cost of the moat only grows by O(
3.5 Eﬀective Scrubbing and Reuse of Re-
conﬁgurable Hardware
Moats allow us to reason about isolation without any
knowledge of the inner workings of cores, which are far too
complex to feasibly determine whether a particular element
of a core is connected to another core. Furthermore, moats
also allow us to isolate cores designed with a less trustwor-
thy tool chain from cores that are the result of a more trust-
worthy tool chain. While these are both useful properties,
we need to make sure we can actually implement them. In
fact, a few of the latest FPGAs available have the ability to
change a selective part of their conﬁguration, one column at
a time [34]. A specialized core on the FPGA can read one
frame of the conﬁguration, change part of this frame, and
write the modiﬁed frame back. This core must therefore be
part of the trusted computing base of the system.
Partial reconﬁguration improves the ﬂexibility of a sys-
tem by making it possible to swap cores. If the number of
possible conﬁgurations is small, then static veriﬁcation is
sufﬁcient, but if the space of possible cores is inﬁnite, then
dynamic veriﬁcation is necessary. For example, Baker et
al. have developed an intrusion detection system based on
reconﬁgurable hardware that dynamically swaps the detec-
tion cores [2] [1]. Since the space of intrusion detection
rule sets is inﬁnite, the space of detection cores is also in-
ﬁnite. Huffmire et al. have developed a memory protec-
tion scheme for reconﬁgurable hardware in which a recon-
ﬁgurable reference monitor enforces a policy that speciﬁes
the legal sharing of memory [19]. Partial reconﬁguration
6
0
1
x
s
a
e
r
A
r
o
t
s
i
s
n
a
r
T
h
t
d
W
n
M
i
i
20
18
16
14
12
10
8
6
4
2
0
Average Area vs. Configuration
)
s
n
0
1
(
g
n
m
T
h
t
a
P
i
i
l
a
c
i
t
i
r
C
e
g
a
r
e
v
A
Baseline
1-2-6
1-2
1
(Moat Size = 6)
(Moat Size = 2)
(Moat Size = 1)
Configuration
16
14
12
10
8
6
4
2
0
Average Timing vs. Configuration
Baseline
1-2-6
1-2
1
(Moat Size = 6)
(Moat Size = 2)
(Moat Size = 1)
Configuration
Figure 5. Comparison of area for different
conﬁgurations of routing segments.
The
baseline system has segments with length 1,
2, 6 and longline. The distribution is close
to that of Virtex II: 8% (1), 20% (2), 60% (6)
and 12% (longline). Other conﬁgurations are
created by eliminating one or more classes
of segments. For example, conﬁguration 1-2-
6 removes the longlines and distributes them
proportionally to other types of segments.
Figure 6. Comparison of critical path timing
for different conﬁgurations of routing seg-
ments. Unlike Figure 7, the graphs in Figures
5 and 6 do not include the overhead of the
moat itself. The error bars show one standard
deviation.
could allow the system to change the policy being enforced
by swapping in a different reference monitor. Since the
space of possible policies is inﬁnite, the space of possible
reference monitors is also inﬁnite. Lysaght and Levi have
devised a dynamically reconﬁgurable crossbar switch [33].
By using dynamic reconﬁguration, their 928x928 crossbar
uses 4,836 CLBs compared to the 53,824 CLBs required
without reconﬁguration.
To extend our model of moats to this more dynamic case,
we not only need to make sure that our static analysis must
be simple enough to be performed on-line by a simple em-
bedded core (which we argue it is), but we also need to make
sure that nothing remains of the prior core’s logic when it
is replaced with a different core.
In this section, we de-
scribe how we can enable object reuse through conﬁgura-
tion cleansing.
By rewriting a selective portion of the conﬁguration bits
for a certain core, we can erase any information it has stored
in memory or registers. The ICAP (Internal Conﬁguration
Access Port) on Xilinx devices allows us to read, modify,
and write back the conﬁguration bitstream on Virtex II de-
vices. The ICAP can be controlled by a Microblaze soft
core processor or an embedded PowerPC processor if the
chip has one. The ICAP has an 8-bit data port and typi-
cally runs at a clock speed of 50 MHz. Conﬁguration data
is read and written one frame at a time. A frame spans the
entire height of the device, and frame size varies based on
the device.
Table 1 gives some information on the size and number
of frames across several Xilinx Virtex II devices. The small-
est device has 404 frames, and each frame requires 5.04 us
to reconﬁgure, or equivalently, erase. Therefore, reconﬁg-
uring (erasing) the entire devices takes around 2 ms.
To sanitize a core we must perform 3 steps. First we must
read in a conﬁguration frame. The second step is to modify
the conﬁguration frame so that the ﬂip-ﬂops and memory
are erased. The last step is to write back the modiﬁed con-
ﬁguration frame. The number of frames and how much of
the frame we must modify depend on the size of the core
that is being sanitized. This process must be repeated since
each core will span the width of many frames. In general,
the size of the core is linearly related to the time that is
needed to sanitize it.
Our object reuse technique can also disable a core if ex-
treme circumstances should require it, such as tampering.
Embedded devices such as cell phones are very difﬁcult to
sanitize [38]. Smart phones contain valuable personal data,
and the theft or loss of a phone can result in serious conse-
quences such as identity theft. Embedded devices used by
the military may contain vital secrets that must never fall
into enemy hands. Furthermore, valuable IP information of
the cores is stored in the form of the bitstream on the FPGA.
A method of disabling all or part of the device is needed to
protect important information stored on the FPGA in the
Table 1. Reconﬁguration Time
Device