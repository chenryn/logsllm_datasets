title:E2E: embracing user heterogeneity to improve quality of experience
on the web
author:Xu Zhang and
Siddhartha Sen and
Daniar Kurniawan and
Haryadi Gunawi and
Junchen Jiang
E2E: Embracing User Heterogeneity to Improve Quality of
Experience on the Web
Xu Zhang1, Siddhartha Sen2, Daniar Kurniawan1, Haryadi Gunawi1, Junchen Jiang1
1University of Chicago, 2Microsoft Research
ABSTRACT
Conventional wisdom states that to improve quality of experience
(QoE), web service providers should reduce the median or other
percentiles of server-side delays. This work shows that doing so
can be inefficient due to user heterogeneity in how the delays impact
QoE. From the perspective of QoE, the sensitivity of a request to
delays can vary greatly even among identical requests arriving at
the service, because they differ in the wide-area network latency
experienced prior to arriving at the service. In other words, saving
50ms of server-side delay affects different users differently.
This paper presents E2E, the first resource allocation system that
embraces user heterogeneity to allocate server-side resources in a
QoE-aware manner. Exploiting this heterogeneity faces a unique
challenge: unlike other application-level properties of a web request
(e.g., a user’s subscription type), the QoE sensitivity of a request to
server-side delays cannot be pre-determined, as it depends on the
delays themselves, which are determined by the resource allocation
decisions and the incoming requests. This circular dependence
makes the problem computationally difficult.
We make three contributions: (1) a case for exploiting user het-
erogeneity to improve QoE, based on end-to-end traces from Mi-
crosoft’s cloud-scale production web framework, as well as a user
study on Amazon MTurk; (2) a novel resource allocation policy
that addresses the circular dependence mentioned above; and (3) an
efficient system implementation with almost negligible overhead.
We applied E2E to two open-source systems: replica selection in
Cassandra and message scheduling in RabbitMQ. Using traces and
our testbed deployments, we show that E2E can increase QoE (e.g.,
duration of user engagement) by 28%, or serve 40% more concurrent
requests without any drop in QoE.
CCS CONCEPTS
• Information systems → Web services; • Human-centered com-
puting;
KEYWORDS:
Web Services, Quality of Experience, Resource Allocation
ACM Reference Format:
Xu Zhang, Siddhartha Sen, Daniar Kurniawan, Haryadi Gunawi, Junchen
Jiang. 2019. E2E: Embracing User Heterogeneity to Improve Quality of
Experience on the Web. In SIGCOMM’19: 2019 Conference of the ACM Special
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SIGCOMM ’19, August 19–23, 2019, Beijing, China
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-5956-6/19/08...$15.00
https://doi.org/10.1145/3341302.3342089
Figure 1: (a) An example of three requests with different QoE sen-
sitivities to server-side delays, and (b) the potential QoE/throughput
improvement if we leverage user heterogeneity. These figures are illus-
trative; actual figures from our evaluation and trace analysis appear
later (e.g., Figures 3, 6).
Interest Group on Data Communication, August 19-23, 2019, Beijing, China.
ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3341302.3342089
1 INTRODUCTION
Improving end-to-end performance is critical for web service providers
such as Microsoft, Amazon, and Facebook, whose revenues depend
crucially on high quality of experience (QoE). More than ten years
have passed since Amazon famously reported every 100ms of la-
tency cost them 1% in sales, and Google found 0.5s of additional
load time for search results led to a 20% drop in traffic [5]. Today,
latency remains critical but the consequences have gotten steeper:
an Akamai study in 2017 showed every 100ms of delay in website
load time hurt conversion rates by 7% [6], and Google reported
higher mobile webpage load times more than double the proba-
bility of a bounce [7]. Naturally, web service providers strive to
cut server-side delays—the only delays they can control—to im-
prove the end-to-end performance of each web request. Following
this conventional wisdom, a rich literature has developed around
reducing web service delays (e.g., [21, 26, 28, 32, 45, 47, 49]).
Our work is driven by a simple observation: although reducing
server-side delay generally improves QoE, the amount of QoE im-
provement varies greatly depending on the external delay of each
web request, i.e., the total delay experienced prior to arriving at
the web service due to ISP routing, last-mile connectivity, and so
forth. In other words, if we define QoE sensitivity as the amount
QoE would improve if the server-side delay were reduced to zero,
there is substantial heterogeneity in QoE sensitivity across users.
This heterogeneity results from two empirical findings. First, as
illustrated in Figure 1(a), QoE typically decreases along a sigmoid-
like curve as delay increases. When the external delay is very short
or very long (e.g., A or C on the curve), QoE tends to be less sen-
sitive to the server-side delay than when the external delay is in
the middle (e.g., B on the curve). We verified this trend using traces
from Microsoft’s cloud-scale production web framework, as well as
a user study we ran on Amazon MTurk to derive QoE curves for
several popular websites (§2.2).
Second, external delays are inherently diverse across user re-
quests to the same web service, due to factors that are beyond the
QoEDelayABC(a) User heterogeneity(b) Better QoEand throughputQoEThroughputTodayThis workSIGCOMM ’19, August 19–23, 2019, Beijing, China
control of the web service provider: e.g., ISP routing, last-mile con-
nectivity, DNS lookups, and client-side (browser) rendering and
processing. Our analysis of our traces reveals substantial variabil-
ity in external delays even among requests received by the same
frontend web server, for the same web content (§2.2).
The heterogeneity in QoE sensitivity implies that following the
conventional wisdom of minimizing server-side delays uniformly
across all requests can be inefficient, because resources may be used
to optimize requests that are not sensitive to this delay. Instead, we
should reallocate these resources to requests whose QoE is sensitive
to server-side delay.
At a high level, user heterogeneity is inherent to the Internet’s
loosely federated architecture, where different systems are con-
nected together functionally (client devices, ISPs, cloud providers,
etc.), but delay optimization is handled separately by each system.
Our work does not advocate against this federated architecture;
rather, we argue that web service providers should embrace the
heterogeneity of QoE sensitivity across users to better allocate server-
side resources to optimize QoE. Using our traces, we show that if
we could reshuffle server-side delays among concurrent requests
so that requests with more sensitive QoE get lower server-side
delays, we could increase the average duration of user engagement
(a measure of QoE) by 28% (§2.3).
To explore the opportunities of leveraging user heterogeneity, we
present E2E, a resource allocation system for web services that opti-
mizes QoE by allocating resources based on each user’s sensitivity
to server-side delay.1 E2E can be used by any shared-resource ser-
vice; for example it can be used for replica selection in a distributed
database to route sensitive requests to lighter-loaded replicas.
The key conceptual challenge behind E2E is that, unlike static
properties of a request (e.g., basic vs. premium subscription, wireless
vs. wired connectivity), one cannot determine the QoE sensitivity of
an arriving request based solely on its external delay. Instead, QoE
sensitivity depends on the server-side delay as well. As we show in
§3.2, if the server-side delay is large enough, it could cause a seem-
ingly less sensitive request (A) to suffer more QoE degradation than
a seemingly more sensitive request (B). Thus, one cannot prioritize
the allocation of resources without taking into account both the
external delay distribution and the server-side delay distribution.
The latter distribution, in turn, is affected by the resource alloca-
tion itself, which makes the problem circular and computationally
expensive to solve at the timescale of a web serving system.
E2E addresses this challenge from both the algorithmic perspec-
tive and the systems perspective. From the algorithmic perspective,
E2E decouples the resource allocation problem into two subprob-
lems, each of which can be solved efficiently: (1) a workload alloca-
tion process, which determines the server-side delay distribution
without considering QoE sensitivity; and (2) a delay assignment
process, which uses graph matching to “assign” the server-side
delays to individual requests in proportion to their QoE sensitivity.
E2E solves the two subproblems iteratively until it finds the best
workload allocation and delay assignment (§4).
From the systems perspective, E2E further reduces the cost of
processing each request by coarsening the timescale and the gran-
ularity of resource allocation decisions. Observing that the optimal
Page loads (K)
Web sessions (K)
Unique URLs (K)
Unique users (K)
Page Type 1
682.6
564.8
3.8
521.5
Page Type 2
314.1
265.7
1.5
264.2
X. Zhang et al.
Page Type 3
600.2
512.2
3.2
481.8
Table 1: Dataset summary (date: 02/20/2018)
allocation is insensitive to small perturbations in the external delay
and server-side delay distributions, we allow the system to cache
allocation decisions in a lookup table and only update them when
a significant change is detected in either distribution (§5).
We demonstrate the practicality of E2E by integrating it into two
open-source systems to make them QoE-aware: replica selection
in a distributed database (Cassandra) and message scheduling in a
message broker (RabbitMQ) (§6). We use a trace-driven evaluation
and our testbed deployments to show that (1) E2E can improve
QoE (e.g., duration of user engagement) by 28%, or serve 40% more
concurrent requests without any drop in QoE; and (2) E2E incurs
negligible (4.2%) system overhead and less than 100µs delay (§7).
This paper focuses on applying E2E to an individual service, or to
multiple services that serve unrelated requests. In a production web
framework, it is often the case that multiple backend services work
together to complete the same (high-level) web request. Focusing
on individual backend services allows us to develop our key idea
of prioritizing requests based on how sensitive their QoE is to
server-side delays, without the added complexity introduced by
dependencies across services. We discuss these issues in §9.
2 MOTIVATION
We first use our traces to show the prevalence of heterogeneity
in how server-side delays impact the QoE of different users (§2.2).
Then, we analyze the potential QoE improvement that could be
attained by exploiting this heterogeneity for server-side resource
allocation (§2.3).
2.1 Dataset
Our dataset consists of the traces of all web requests served by a
production web framework cluster during one day in February 2018.
The cluster is one of several located in an Eastern US datacenter
serving the major websites and online storefront properties of Mi-
crosoft.2 Importantly, the traces include both client-side (browser)
and server-side event logs: the client-side logs record all page ren-
dering events and issued requests, while the server-side logs record
all backend processing operations required to fulfill each request.
Overall, the dataset spans 1.17M unique users and 1.6M page load
events, as summarized in Table 1.
For each web request, we define three delay metrics, shown
visually in Figure 2:
• The total delay (also known as page load time) is the duration
between when a user clicks a link that issues the request and
when the last object associated with the request is rendered.
• The server-side delay is the time to process all server-side opera-
tions on the backend, which may involve multiple steps, such as
fetching product IDs from a database and then querying a product
catalog for HTML description snippets, before aggregating the
results and sending them to the user.
1E2E takes an “end-to-end” view of web request delays.
2Examples include: microsoft.com, xbox.com, msn.com, etc..
E2E: Embracing User Heterogeneity to Improve QoE on the Web
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 2: The life cycle of a web request, showing the total delay,
server-side delay, and external delay.
• The external delay includes all delays beyond the purview of
server-side operations, e.g., transferring data over the wide-area
network, routing the request to the service, decoding and render-
ing the response in the client-side browser, etc..
We measure these delay metrics for each web request using the
timestamps recorded in our traces. The total delay is measured by
the difference between the first and the last timestamps associated
with the request. The server-side delay is measured by the total
delay of all backend operations (with overlapping delays excluded).
As mentioned above, we assume there is a single backend service;
we discuss complex dependencies between backend services in
§9. Finally, the external delay of a web request is calculated by
subtracting the server-side delay from the total delay; it includes
both wide-area network and datacenter delays, as shown in Figure 2.
Note that this estimate of external delay is conservative because the
actual delay may be smaller if server-side processing overlaps with
wide-area transfers or browser rendering—our results improve as