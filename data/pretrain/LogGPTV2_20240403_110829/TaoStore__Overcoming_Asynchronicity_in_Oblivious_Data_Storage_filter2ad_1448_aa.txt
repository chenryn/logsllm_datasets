title:TaoStore: Overcoming Asynchronicity in Oblivious Data Storage
author:Cetin Sahin and
Victor Zakhary and
Amr El Abbadi and
Huijia Lin and
Stefano Tessaro
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
TaoStore: Overcoming Asynchronicity in Oblivious
Data Storage
Cetin Sahin, Victor Zakhary, Amr El Abbadi, Huijia Lin, Stefano Tessaro
Department of Computer Science
University of California, Santa Barbara
{cetin, victorzakhary, amr, rachel.lin, tessaro}@cs.ucsb.edu
Santa Barbara, California, USA
Abstract—We consider oblivious storage systems hiding both
the contents of the data as well as access patterns from an un-
trusted cloud provider. We target a scenario where multiple users
from a trusted group (e.g., corporate employees) asynchronously
access and edit potentially overlapping data sets through a trusted
proxy mediating client-cloud communication.
The main contribution of our paper is twofold. Foremost,
we initiate the ﬁrst formal study of asynchronicity in oblivious
storage systems. We provide security deﬁnitions for scenarios
where both client requests and network communication are
asynchronous (and in fact, even adversarially scheduled). While
security issues in ObliviStore (Stefanov and Shi, S&P 2013) have
recently been surfaced, our treatment shows that also CURIOUS
(Bindschaedler at al., CCS 2015), proposed with the exact goal
of preventing these attacks,
is insecure under asynchronous
scheduling of network communication.
Second, we develop and evaluate a new oblivious storage
system, called Tree-based Asynchronous Oblivious Store, or
TaoStore for short, which we prove secure in asynchronous
environments. TaoStore is built on top of a new tree-based
ORAM scheme that processes client requests concurrently and
asynchronously in a non-blocking fashion. This results in a
substantial gain in throughput, simplicity, and ﬂexibility over
previous systems.
I. INTRODUCTION
Outsourcing data to cloud storage has become increasingly
popular and attractive. However, conﬁdentiality concerns [9]
make potential users skeptical about joining the cloud. En-
cryption alone is not sufﬁcient to solve all privacy challenges.
Typically, the access patterns are not hidden from the cloud
provider, i.e., it can for example detect whether and when the
same data item is accessed repeatedly, even though it does not
learn what the item actually is. Data access patterns can leak
sensitive information using prior knowledge, as shown e.g. in
the setting of searchable symmetric encryption [24], [7].
This work targets cloud storage where multiple users from
a trusted group (e.g., employees within the same company)
need to access (in a read/write fashion) data sets which may
overlap. To achieve this, users’ accesses are mediated by a
shared (trusted) proxy which coordinates these accesses and,
at the same time, reduces the amount of information leaked
to the cloud. Oblivious RAM (ORAM) – a cryptographic
primitive originally proposed by Goldreich and Ostrovsky [17]
for software protection – is the standard approach to make
access patterns oblivious. Most ORAM solutions [38], [11],
2375-1207/16 $31.00 © 2016 IEEE
© 2016, Cetin Sahin. Under license to IEEE.
DOI 10.1109/SP.2016.20
DOI 10.1109/SP.2016.20
198
198
[10], [4] are not suitable for our multi-user scenario, as they
handle operation requests sequentially, i.e., a new request is
not processed until a prior ongoing request
is completed,
thus creating a bottleneck under concurrent loads. To date,
only a handful of solutions leverage parallelism to increase
throughput [36], [13], [44], [4]. PrivateFS [44] is based on
hierarchical ORAM and supports parallel accesses from a
limited number of clients. ObliviStore [36] (which is based
on SSS-ORAM [37]) was the ﬁrst work to consider the proxy
model we also assume in this work. ObliviStore was recently
revisited by Bindschaedler et al. [4], who proposed a new
system called CURIOUS ﬁxing a subtle (yet serious) security
ﬂaw arising in concurrent environments.
Our contributions, in a nutshell: Motivated by [4], this
work initiates a comprehensive study of asynchronicity in
oblivious storage. We make contributions along two axes:
1) We observe that the previous treatment has not cap-
tured crucial security issues related to asynchronicity
in oblivious storage. We develop a comprehensive se-
curity framework, and present an attack showing that
access patterns in CURIOUS are not oblivious in an
asynchronous environment as captured by our model.
2) We design and evaluate a new provably secure sys-
tem, called TaoStore, that fully resists attacks in asyn-
chronous settings and also leverages the beneﬁts of asyn-
chronicity for better performance. Our system follows
a completely different paradigm than previous works –
in particular it departs from the SSS framework and
is completely tree based – with substantial gains in
simplicity, ﬂexibility, and efﬁciency.
A. Asynchronicity vs Security
Asynchronicity is an important variable in the design of
secure storage systems, and there are at least two ways in
which it can affect them:
• Asynchronous client requests. Multiple client requests can
come at any time point in time (either from the same
client or from different ones), and should be answered
independently of each other, possibly as soon as the data
item is retrieved from the server in order not to slow
down the applications requiring these accesses.
• Asynchronous network communication. The communica-
tion between the clients and the proxy, and the commu-
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:10 UTC from IEEE Xplore.  Restrictions apply. 
nication between the proxy and the server, is in general
asynchronous.
Needless to say, we would like our systems to be secure in
such asynchronous environments. The ﬁrst question we thus
ask is:
existing systems
Are
scheduling of communication and operations?
secure under arbitrary
The answer is negative: all existing approaches of handling
concurrent requests on the same data item can leak substantial
information under asynchronous scheduling. The authors of
CURIOUS [4] have already shown that the sequentialization
of accesses to the same block in ObliviStore renders the
system insecure. We will go one step further, and show that
CURIOUS itself has not completely resolved the issue, and is
also insecure when operations are scheduled concurrently and
communication is asynchronous.
Our attack assumes that the adversary learns the timings
of the proxy’s answers back to the client. We ﬁnd this
assumption reasonable. For example, the attacker may observe
(encrypted) network trafﬁc between the proxy and the clients,
and moreover, a client may only schedule a new access (or
perform some other noticeable action) when a previous access
terminates. These timings were however kept secret in the
original security deﬁnition of [36], also used in [4]. Therefore,
our attack does not invalidate any of the claims from [36]. Still,
it motivates us to develop a deﬁnitional security framework for
asynchronous oblivious storage systems, which we believe to
be of independent interest.
B. Asynchronicity vs Efﬁciency
Our security assessment calls for a system which is fully
secure in an asynchronous environment. Instead of simply
ﬁxing existing approaches (e.g., CURIOUS), we ﬁrst take the
chance to address the following question:
How well do existing systems leverage parallelism
to handle concurrent asynchronous requests?
Indeed, existing systems have some undesirable features. CU-
RIOUS relies on data partitioning, and accesses to the same
partition are sequentialized. In contrast, here, we would like to
develop a system which is “natively” concurrent – we would
like our system to achieve high throughput even when using
a single partition. ObliviStore achieves higher concurrency on
individual partitions, yet, as pointed out in [4], the system
relies on a fairly complex background shufﬂing process which
is responsible for writing data back to the server and which
signiﬁcantly affects performance of the system.
TaoStore: Motivated by the above concerns, we develop
and evaluate TaoStore, a fully-concurrent provably secure
multi-user oblivious data store. TaoStore departs from the
traditional partition-based SSS approach [37] used in current
systems. Instead, it relies on a tree based ORAM scheme
aimed at fully concurrent data access. Tree-based ORAMs
organize server storage as a tree, and server access is in form
of retrieving or overwriting data contained in a path from the
root to some leaf. Our new scheme features a novel approach
to manage multiple paths fetched concurrently from the server.
In particular, the write back of updated path contents to the
server occurs in an entirely non-blocking way, i.e., new paths
overlapping with paths being written back can still be retrieved
and updated while the write back operation is under way.
TaoStore is substantially simpler than ObliviStore and en-
ables better concurrency than CURIOUS. We can in particular
dispense with running the expensive background shufﬂing pro-
cess from the former, and different from the latter, operations
can be executed concurrently even on individual partitions.
Security and correctness: We prove the ORAM scheme
underlying TaoStore secure using our new security frame-
work, which guarantees security against adversaries which can
schedule both operations and network messages. In particular,
a key contribution of our construction is the introduction of a
sequencer module aimed at preventing our attacks affecting
other systems. Correctness (i.e., atomic semantics) remains
guaranteed, regardless of the scheduling of messages sent
over the network, which is asynchronous and can even be
in total adversarial control. Our concurrency handling calls
for a rigorous proof of correctness, which was not necessary
in previous systems due to simpler approaches to accessing
shared objects.
Evaluation: We present two different evaluations of Tao-
Store: (1) A local evaluation (with the same experimental setup
as in [36]) to compare it with ObliviStore, and (2) A cloud-
based evaluation (using Amazon EC2) to test our system in
real-world connectivity scenarios. The ﬁrst evaluation shows
for example that TaoStore can deliver up to 57% more through-
put with 44% less response time compared to ObliviStore. Our
cloud-based evaluations show that while TaoStore’s throughput
is inherently limited by bandwidth constraints, this remains
its main limitation – our non-blocking write-back mechanism
indeed allows TaoStore’s performance scale very well with
increasing concurrency and decreasing memory availability
at the proxy. That is, the frequency of write backs does not
substantially slow down the system.
We emphasize that we do not implement recent bandwidth-
reducing techniques using server-side computation [33], [14],
[29] – we explicitly target usage on a simple storage server
which only allows for read-write access and no computation
(except for basic time-stamping), and these newer schemes –
while extremely promising – are not relevant for our setting.
Partitioning: Previous works use data partitioning in a
fundamental way. In particular, CURIOUS [4] relies on data
partitioning to ensure concurrency (access to the same partition
are sequentialized). TaoStore does not rely on partitioning –
indeed, the performance of our system is competitive even
without
there are scenarios where partitioning is
desirable, as it can help overcome storage, bandwidth, and
I/O limitations. If desired, our tree-based approach enables
partitioning as a simple add-in – one breaks up the tree into
a forest of sub-trees, maintaining the tree-top in the proxy.
it – yet
199199
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:10 UTC from IEEE Xplore.  Restrictions apply. 
C. Overview of TaoStore
Developing an ORAM scheme for a concurrent setting is
indeed far from obvious. To see why this is the case, we ﬁrst
review the main ideas behind tree-based ORAM schemes, such
as Path ORAM by Stefanov et al. [38].
These schemes have their storage space organized as a tree,
with each node containing a certain number of (encrypted)
blocks. A single client keeps a position map mapping each
(real) block address to a path from the root to a leaf in the
tree, together with some local memory containing a (usually
small) number of overﬂowing blocks, called the stash. To
achieve correctness, the ORAM client maintains a block-path
invariant ensuring that at each point in time, a block is either
on its assigned path or in the stash. Under this invariant,
processing each access (either read or write) for a block
involves three operations—read-path, ﬂushing and write-back.
First, the ORAM client fetches the path P assigned to the
block, and uses it together with the stash to answer the request.
To maintain obliviousness, the block is immediately assigned
to a new random path in the position map, so that a future
access for the same block would fetch an independent random
path (hiding repetition in accesses). Next, the contents of
the path P and stash are re-arranged so that every block
ends up at the lowest possible node on P and also on its
assigned path; only blocks that do not ﬁt remain in the stash.
This re-arrangement is referred to as ﬂushing and is crucial
for ensuring that the stash never “overﬂows”. Finally, a re-
encrypted version of P is written back to the server, keeping
the server up-to-date.
How do we make Path ORAM concurrent and asyn-
chronous, while retaining both security and correctness? Even
after a ﬁrst glance, several issues immediately arise. First off,
multiple paths may need to be retrieved simultaneously, as one
request may be made while a path is being retrieved from the
server – however, what if the requests are for the same item?
Second, every path needs to be written back to the server, but
what if just after the contents of a path have been sent back to
the server, one of the items contained in this path needs to be
updated? Finally, if the attacker can observe when the clients
receive responses to their requests, how does one ensure that
the timing of these responses are oblivious? All of this must be
considered in a truly asynchronous setting, where we do not
want to make any timing assumptions on the communication
between the proxy and the server.
Our ORAM scheme – TaORAM – resembles Path ORAM,
but allows multiple paths to be retrieved concurrently, with-
out waiting for on-going ﬂush and write-back operations to
complete. All operations are done asynchronously:
• At
the arrival of a request for a certain block,
the
appropriate read-path request is sent immediately to the
server.
• Upon the retrieval of a path from the server, the ap-
propriate read/write requests are answered, and the path
is ﬂushed and then inserted into a local subtree data
structure.
• Immediately after ﬂushing a certain number k of paths,
their re-encrypted contents are written back to the server
(and appropriate nodes deleted from the local subtree).
Here, we highlight the fundamentals of our approach, and how
we address the challenges outlined above; see Section IV for
more details.
Consider obliviousness: Path ORAM crucially relies on the
fact that a block is assigned to a fresh new random path
after each access to hide future accesses to the same block.
However, in TaORAM, a request for a block is processed
immediately, without waiting for other concurrent accesses to
the same block to properly complete and “refresh” the assigned
path. If handled naively, this would lead to fetching the same
path multiple times, leaking repetition. TaORAM resolves this
issue by keeping track of all concurrent requests for the same
block (via a data structure called request map) so that at each
point, only one request triggers reading the actual assigned
path, whereas all others trigger fake reads for a random path.
Correctness is potentially jeopardized when there are mul-
tiple on-going read-path and write-back operations to the
server. The most prominent issue is that before all write-back
operations complete, the contents at the server are potentially
out-of-date; hence answering requests using paths read from
the server could be incorrect. To overcome this, TaORAM
keeps a so-called fresh-subtree invariant: The contents on the
paths in the local subtree and stash are always up-to-date,
while the server contains the most up-to-date content for the
remaining blocks. Moreover, every path retrieved from the
server is ﬁrst “synched up” with the local subtree, and only
then used for ﬁnding the requested blocks, which is now
guaranteed to be correct by the fresh-subtree invariant. Several
technical challenges need to be addressed to maintain the
invariant, as the local subtree and the server are constantly
concurrently updated, and read-path and write-back operations
are completely asynchronous.