lfence
rdtsc
shl $32, %rax
or %rsi, %rax
mov %rax, (%rdi)
add $8, %rdi
dec %rcx
jnz 1b
Fig. 3. The PORTSMASH technique with multiple build-time port conﬁgura-
tions P1, P5, and P0156.
choose to store the counter values and not only the latency, as
the former helps identify interrupts (e.g., context switches) and
the latter can always be derived ofﬂine from the former, but
the converse is not true. It is also worth mentioning the Spy
must ensure some reasonable number of instructions retired
between successive rdtsc calls to be able to reliably detect
port contention; we expand later.
In general, strategies are architecture dependent and on
each architecture there are several strategies, depending on
what port(s) the Spy wishes to measure. We now provide
and describe three such example strategies (among several
others that naturally follow) for Intel Skylake and Kaby Lake:
one that leverages instruction level parallelism and targets
multiple ports with a latency-1 instruction, and two that
leverage pipelining and target a single port with higher latency
instructions.
Multiple ports: In Figure 3, the P0156 block targets ports
0, 1, 5, and 6. These four add instructions do not create
hazards, hence all four can execute in parallel to the four
integer ALUs behind these ports, and as a latency-1 instruction
in total they should consume a single clock cycle. To provide
a window to detect port contention, the Spy replicates these
instructions 64 times. With no port contention, this should
execute in 64 clock cycles, and 128 clock cycles with full
port contention.
Single port: In Figure 3, the P1 and P5 blocks target port
1 and 5, respectively, in a similar fashion. Since these are
latency-3 instructions, we pipeline three sequential instructions
with distinct arguments to avoid hazards and ﬁll the pipeline,
achieving full throughput of one instruction per cycle. Here
the window size is 48, so the block executes with a minimum
3 · 48 + 2 = 146 clock cycles with no port contention, and
with full port contention the maximum is roughly twice that.
A. Comparison
Our PORTSMASH technique relies on secret-dependent ex-
ecution port footprint, a closely related concept to secret-
(cid:25)(cid:24)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:44:40 UTC from IEEE Xplore.  Restrictions apply. 
dependent
instruction execution cache footprint. Although
similar in spirit to L1 icache attacks or LLC cache attacks,
since both rely on a secret-dependent footprint in a microarchi-
tecture component, we demonstrate that PORTSMASH offers
ﬁner granularity and is stealthier compared to other techniques.
To differentiate PORTSMASH from previous techniques, we
compare them with respect to spatial resolution, detectability,
cross-core, and cross-VM applicability. We admit that de-
tectability is extremely subjective, especially across different
microarchitecture components; our rating is with respect to a
malicious program while the target victim is idle, i.e., waiting
to capture.
Initially, Osvik et al. [18] proposed the PRIME+PROBE
technique against the L1 dcache, relying on SMT technology
to provide asynchronous execution. Newer enhancements to
this technique allowed cross-core (and cross-VM) successful
attacks [22–24]. The spatial resolution of this attack is limited
to cache-set granularity, that is usually a minimum of 512
bytes. Typically, the PRIME+PROBE technique occupies all
cache sets, moderately detectable if cache activity monitoring
takes place.
Later, Yarom and Falkner [19] proposed the FLUSH+RE-
LOAD technique, a high resolution side-channel providing
cache-line granularity with an improved eviction strategy.
Closely related, Gruss et al. [20] proposed FLUSH+FLUSH, a
stealthier version of FLUSH+RELOAD. Both techniques rely
on shared memory between Victim and Spy processes, in
addition to the clflush instruction to evict cache lines
from the LLC. While this is a typical setting in cross-core
scenarios due to the use of shared libraries, the impact in cross-
VM environments is limited due to the common practice of
disabling page de-duplication [25, Sec. 3.2].
More recently, Gras et al. [4] proposed TLBLEED as another
microarchitecture attack technique. Even if this is not a “pure”
cache technique, it exploits TLBs, a form of cache for memory
address translations [7]. Interestingly, this subtle distinction is
sufﬁcient for making it stealthier to cache countermeasures [4].
On the downside, the spatial resolution of this attack is limited
to a memory page (4 KB). Since no cross-core improvements
have been proposed for either TLBLEED or PORTSMASH,
it could be seen as a drawback of these attacks. However,
attackers can launch multiple Spy processes to occupy all cores
and ensure co-location on the same physical core; see [26,
Sec. 3.1] for a related discussion.
Recent microarchitecture attacks have been proposed
achieving intra cache-line granularity. Yarom et al. [5] demon-
strated that intra-cache granularity is possible—at least in older
Intel microprocessors—with their CacheBleed attack. This
attack proposes two techniques to achieve this granularity:
cache bank conﬂicts and write-after-read false dependencies.
Cache bank conﬂicts have a limited impact, considering the
authors discovered that current Intel microprocessors no longer
have cache banks; thus this technique does not apply to newer
2Cache-set size depends on the microprocessor speciﬁcations and can be
calculated as (cache line size × cache associativity).
:
test
je
jmpq
%rdi,%rdi
4100 
4120 
:
test
je
jmpq
%rdi,%rdi
5100 
5140 
30f0
30f0
30f3
30f9
....
4100
4105
410a
410f
4114
4119
411e
4120
4125
412a
412f
4134
4139
413e
4140
4100 
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
jmp
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
jmp
retq
4120 
4150
4150
4153
4159
....
5100
5105
510a
510f
5114
5119
511e
5123
5128
512d
5132
5137
513c
513e
5140
5145
514a
514f
5154
5159
515e
5163
5168
516d
5172
5177
517c
517e
5100 
%ax,%ax
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
popcnt %r8,%r8
popcnt %r9,%r9
popcnt %r10,%r10
jmp
xchg
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
vpbroadcastd %xmm0,%ymm0
vpbroadcastd %xmm1,%ymm1
vpbroadcastd %xmm2,%ymm2
jmp
retq
5140 
Fig. 4. Two Victims with similar port footprint, i.e., port 1 and port 5, but
different cache footprint. Left: Instructions span a single cache-line. Right:
Instructions span multiple cache-lines.
microprocessors. To that end, Moghimi et al. [21] improved
the previous work and proposed a read-after-write false depen-
dency side-channel. The authors highlight the potential 5 cycle
penalty introduced when a memory write is closely followed
by a read, a more critical condition compared to a read closely
followed by a memory write. This technique gives a 4-byte
granularity on the cache-lines, thus allowing them to exploit
the 5 cycle delay to perform a key recovery attack against a
constant-time AES implementation on Intel IPP library.
To understand our detectability criteria in Table III, consider
the following example. During a typical round of attack,
a FLUSH+RELOAD process constantly reloads a previously
ﬂushed memory address, observing a large number of cache-
misses, thus highly detectable. In contrast, a FLUSH+FLUSH
process does not perform explicit loads, instead it relies on
the time of clflush execution to determine the existence
of data in the cache, thus lowly detectable. Sitting in the
middle, a PRIME+PROBE process reloads data from cache at a
slower rate compared to FLUSH+RELOAD, but still observing
a signiﬁcant amount of cache-misses, hence fairly detectable.
On the other hand, TLBLEED, MemJam and CacheBleed
attacks do not follow the same combination of cache eviction
and memory load operations,
instead they rely on timing
variations observed when executing typical instructions during
a computation, i.e., no clflush, thus their detectability is
low.
Table III compares the previously mentioned techniques
in their original version. As can be appreciated, our PORT
SMASH technique enjoys the highest spatial resolution among
them, since it goes beyond the cache-line and instead,
it
considers individual uops dispatched to the execution units.
As an example, consider the two functions x64_foo and
x64_bar in Figure 4. These two functions get passed an
argument of either zero or one (e.g., a secret bit): in the former
(cid:25)(cid:24)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:44:40 UTC from IEEE Xplore.  Restrictions apply. 
COMPARISON OF MICROARCHITECTURE ATTACK TECHNIQUES (ORIGINAL VERSIONS)
TABLE III
Attack
TLBLEED [4]
PRIME+PROBE [18]
FLUSH+RELOAD [19]
FLUSH+FLUSH [20]
CacheBleed [5]
MemJam [21]
PORTSMASH
Spatial Resolution
Memory Page (Very low)
Cache-set (Low)
Cache-line (Med)
Cache-line (Med)
Intra cache-line (High)
Intra cache-line (High)
Execution port (Very High)
Size
4 KB
512 bytes2
64 bytes
64 bytes
8 bytes
4 bytes
uops
Detectability
Cross-Core
Low
Medium
High
Low
Medium
Medium
Low
No
Yes
Yes
Yes
No
No
No
Cross-VM
Yes/SMT
Yes/SharedMem
Yes/SharedMem
Yes/SharedMem
Yes/SMT
Yes/SMT
Yes/SMT
case, they start executing pipelined popcnt instructions in
a loop, and vpbroadcastd instructions in the latter. The
x64_foo function has all its functionality for both branches
within a single cache line (64B), starting at address 0x4100.
In contrast, the x64_bar function has distinct cache lines
for each branch:
the zero case starts at address 0x5100
and the one case at 0x5140, and the control ﬂow for each
corresponding loop restricts to its single cache line.
The x64_bar function is a potential target for L1 icache
attacks, FLUSH+RELOAD attacks, FLUSH+FLUSH attacks, etc.
since there are two different targets that span two different
cache lines. In contrast, the x64_foo control ﬂow resides