title:Coco: Co-Design and Co-Verification of Masked Software Implementations
on CPUs
author:Barbara Gigerl and
Vedad Hadzic and
Robert Primas and
Stefan Mangard and
Roderick Bloem
CoCo: Co-Design and Co-Verification of 
Masked Software Implementations on CPUs
Barbara Gigerl, Vedad Hadzic, and Robert Primas, Graz University of Technology; 
Stefan Mangard, Graz University of Technology, Lamarr Security Research; 
Roderick Bloem, Graz University of Technology
https://www.usenix.org/conference/usenixsecurity21/presentation/gigerl
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.COCO: Co-Design and Co-Veriﬁcation of Masked Software Implementations on
CPUs
Barbara Gigerl
Graz University of Technology
Vedad Hadzic
Graz University of Technology
Robert Primas
Graz University of Technology
Stefan Mangard
Graz University of Technology
Lamarr Security Research
Abstract
The protection of cryptographic implementations against
power analysis attacks is of critical importance for many ap-
plications in embedded systems. The typical approach of
protecting against these attacks is to implement algorithmic
countermeasures, like masking. However, implementing these
countermeasures in a secure and correct manner is challeng-
ing. Masking schemes require the independent processing of
secret shares, which is a property that is often violated by CPU
microarchitectures in practice. In order to write leakage-free
code, the typical approach in practice is to iteratively explore
instruction sequences and to empirically verify whether there
is leakage caused by the hardware for this instruction se-
quence or not. Clearly, this approach is neither efﬁcient, nor
does it lead to rigorous security statements.
In this paper, we overcome the current situation and present
the ﬁrst approach for co-design and co-veriﬁcation of masked
software implementations on CPUs. First, we present COCO,
a tool that allows us to provide security proofs at the gate-level
for the execution of a masked software implementation on a
concrete CPU. Using COCO, we analyze the popular 32-bit
RISC-V IBEX core, identify all design aspects that violate
the security of our tested masked software implementations
and perform corrections, mostly in hardware. The resulting
secured IBEX core has an area overhead around 10%, the
runtime of software on this core is largely unaffected, and the
formal veriﬁcation with COCO of an, e.g., ﬁrst-order masked
Keccak S-box running on the secured IBEX core takes around
156 seconds. To demonstrate the effectiveness of our sug-
gested design modiﬁcations, we perform practical leakage
assessments using an FPGA evaluation board.
1 Introduction
Since the rise of the Internet of Things (IoT), embedded de-
vices are integrated into a wide range of everyday services.
Often, these simple devices are part of larger software ecosys-
tems, which makes the protection of cryptographic keys on
Roderick Bloem
Graz University of Technology
these devices an essential but challenging task. Physical side-
channel attacks, such as power analysis, allow attackers to
extract cryptographic keys by observing a device’s power
consumption [11, 29, 42]. To prevent such attacks, embedded
devices typically employ dedicated countermeasures on the
algorithmic level. The most prominent example of such algo-
rithmic countermeasures against power analysis is masking,
essentially a secret sharing technique that splits input and in-
termediate variables of cryptographic computations into d +1
random shares such that the observation of up to d shares
does not reveal any information about their corresponding
native value [4, 6, 12, 21, 22, 26, 45].
Masking schemes typically have in common that they rely
on certain assumptions such as independence of leakage, i.e.,
independent computations result in independent leakage [44].
However, as pointed out by many academic works in the past,
such assumptions are typically not satisﬁed on CPUs. Coron
et al. [13] were among the ﬁrst who showed that, e.g., memory
transitions in the register ﬁle or RAM can leak the Hamming
distance between two shares, thereby reducing the protection
order of masking schemes on CPUs. Later publications fol-
low up on these observations [14,32,40], and amongst others,
formulate the so-called order reduction theorem [1]. This the-
orem states that dth-order protection under the assumption of
independent leakage reduces to(cid:4) d
(cid:5)-th protection if effects
2
like memory transitions are taken into account. Consequently,
and without further assumptions on the hardware, achieving
second-order protection using masked software implementa-
tions can require computations with up to 5 shares.
This is a very signiﬁcant overhead, and also the reason why
the goal in practice is to ﬁnd strategies to cope with the leak-
age caused by the underlying CPUs and to achieve dth-order
protection with d + 1 random shares. In order to test if such
implementations indeed provide the desired security level in
practice, research on the veriﬁcation of masked cryptographic
implementations has gained a lot of attention during the last
years. The existing works can be roughly divided into two
sets: works based on empirical veriﬁcation, and works based
on formal veriﬁcation.
USENIX Association
30th USENIX Security Symposium    1469
On the empirical side, authors have studied masking-related
side effects of certain microprocessors via leakage assess-
ments and then built corresponding hardened software im-
plementations [14, 40]. While their resulting masked imple-
mentations do in fact maintain their theoretical protection
in practice, they also come with a noticeable performance
overhead (by up to a factor of 15) that is caused by the nec-
essary software tweaks. Since leakage assessments are quite
labor-intensive, tools like PINPAS [16], or more recently,
ELMO [31] have been developed that can emulate power leak-
age for certain microprocessors. The authors of ROSITA [46]
have pushed this automation even further by also automating
the software patching process after leakage detection. A quite
different take on providing side-channel protection on CPUs
is presented by Gross et al. [20], who propose a masked CPU
design that can perform unprotected software implementa-
tions in a side-channel protected manner. Similar work exists
for RISC-V processors [34], also on instruction set architec-
ture level [24, 27, 43].
On the formal side, tools like REBECCA [8] and
maskVerif [2] represent the ﬁrst steps toward formal ver-
iﬁcation of masked implementations. Both tools are mainly
tailored to hardware implementations; maskVerif does of-
fer some support for software implementations but (1) can
only deal with code that is written in a special intermediate
language, and (2) uses a probing model that only considers
simple CPU side-effects such as register overwrites. More
recently, Belaid et al. presented Tornado [7], a compiler that
automatically generates masked software implementations
that are secure in the same model. A more ﬁne-grained soft-
ware veriﬁcation approach that utilizes annotated assembly
implementations is presented by Barthe et al. [5], while with
Silver [28], Knichel et al. promise improved veriﬁcation ac-
curacy and performance for hardware implementations.
Our Contribution So far, the veriﬁcation of masked soft-
ware implementations was only done in simpliﬁed settings
that require modiﬁed software implementations and do not
consider a wider range of side-effects, such as glitches at the
gate level, that occur when software runs on an actual CPU.
There still exists a noticeable gap between correctness proofs
and the resulting practical protection for masked software im-
plementations. We close this gap by providing the following
contributions:
• We present COCO, a tool inspired by REBECCA, that
can formally verify the security of (any-order) masked,
RISC-V assembly implementations that are executed
on concrete CPUs deﬁned by gate-level netlists. COCO
essentially provides hardware-level veriﬁcation includ-
ing glitches for software implementations with constant
control ﬂow.
• Using COCO, we analyze the design of the popular 32-
bit IBEX1 core and identify all hardware design aspects
that could prevent the leakage-free execution of our test
suite of masked software implementations on this CPU.
• Based on this analysis, we present design strategies for
CPU and memory, that with low hardware overhead,
eliminate most of our discovered ﬂaws in hardware,
while leaving behind a few select and easy-to-check con-
straints for masked software implementations.
• We show the practicality of this work by verifying a
variety of masked assembly implementations, includ-
ing various types of (higher-order) masked AND-gates,
a second-order masked Keccak S-box [23], and a ﬁrst-
order masked AES S-box implementation [9]. We also
show examples where COCO identiﬁes ﬂaws in broken
masked software implementations and reports the cor-
responding execution cycle, as well as the location of
the leakage source within the IBEX netlist. To show the
effective robustness of our secured design, we perform
leakage assessments on an FPGA evaluation board.
• We publish COCO and our secured IBEX on Github2.
Outline
In Section 2, we present COCO, a tool that can for-
mally verify the leakage-free execution of masked software
implementations directly on CPU netlists. Section 3 explains
how we analyze the popular 32-bit RISC-V IBEX core using
COCO, the discovered issues, and the resulting hardware mod-
iﬁcations which enable leakage-free software execution. In
a similar spirit, Section 4 takes a look at data memory and
proposes solutions for how SRAM can be added to a CPU
core such that it can be included in COCO’s veriﬁcation. Sec-
tion 5 describes COCO’s veriﬁcation workﬂow in detail and
presents various veriﬁcation runtime benchmarks as well as
the practical evaluation. We conclude our work in Section 6.
2 Verifying Software Implementations on
Hardware
In this section, we describe how we built COCO, a tool in-
spired by REBECCA [8], for the veriﬁcation of masked soft-
ware implementations directly on CPU netlists. More con-
cretely, we show how the problem of verifying masked soft-
ware implementations can be mapped to a hardware veriﬁca-
tion problem by treating software as a sequence of control
signals that dictate the data/control ﬂow within a CPU. This
approach comes with the advantage that we can directly verify
assembly implementations and observe a wider range of side-
effects that could reduce the protection order of the tested
software implementations. Previous works in this direction
1https://github.com/lowRISC/ibex
2https://github.com/IAIK/coco-alma,
https://github.com/IAIK/coco-ibex
1470    30th USENIX Security Symposium
USENIX Association
require modiﬁed software implementations and only consider
a select amount of CPU side-effects that have been discovered
in empirical evaluations [2, 5].
First, we cover necessary background on masking and RE-
BECCA. We then show that the classical probing model [26]
is not suitable for hardware/software co-veriﬁcation and pro-
pose the so-called time-constrained probing model that can be
seen as a stricter version of previously used models for soft-
ware veriﬁcation. We then discuss all improvements that we
performed on top of REBECCA, such that hardware/software
co-veriﬁcation becomes feasible, ultimately leading to COCO.
COCO’s complete veriﬁcation ﬂow is described in Section 5.
2.1 Background on Masking
Masking is a prominent algorithmic countermeasure against
power analysis attacks [10]. In a nutshell, masking is a secret-
sharing technique that splits intermediate values of a computa-
tion into d + 1 uniformly random shares, such that observing
up to d shares does not leak any information about the under-
lying value. The used masking scheme determines the number
of masks d, and results in a dth-order masking scheme. In
classical Boolean masking, the sharing of a native variable
s, when split into d + 1 random shares s0 . . .sd, must satisfy
s = s0 ⊕ . . .⊕ sd. Hereby, s0 . . .sd−1 is chosen uniformly at
random while sd = s0 ⊕ . . .⊕ sd−1 ⊕ s. This ensures that each
share si is uniformly distributed and statistically independent
of s. For example, in a ﬁrst-order masking scheme (d = 1),
the secret variable s is split up into two shares s0 and s1, such
that s = s0 ⊕ s1. s0 is chosen runiformly at random, while
s1 = s⊕ s0.
When implementing masked cryptographic algorithms,
dealing with linear functions is trivial as they can simply be
computed on each share individually. However, implement-
ing masking for non-linear functions requires computations
on all shares of a native value, which is more challenging to
implement in a secure and correct manner, and thus the main
interest in literature [4, 6, 12, 21, 22, 26, 45].
2.2 Background on REBECCA
REBECCA [8] is a tool for the formal veriﬁcation of masked
hardware implementations. Simply speaking, given the netlist
of a masked hardware circuit, together with labels that indicate
which input shares belong together, REBECCA can determine
if the separation between shares is preserved throughout the
circuit. More formally, REBECCA checks if a circuit is se-
cure in the glitch-extended version of the original probing
model by Ishai et al. [26], which we refer to as the classi-
cal probing model. In general, the probing model deﬁnes the
attacker’s abilities in terms of the number of used probing
needles, which are placed on a wire in a circuit and allow to
observe the respective value from the wire. In the classical
probing model, an attacker can place up to d probing needles
in a circuit, which allows the observation of up to d intermedi-
ate values throughout the computation. A circuit is said to be
dth-order protected if an attacker who combines the recorded
information cannot infer information about native values.
The Veriﬁcation Flow of REBECCA REBECCA operates
on the netlist of a pipelined masked hardware circuit. A
masked hardware circuit consists of linear gates (XOR, XNOR),
non-linear gates (AND, OR), registers and constants, that are
all connected by wires. Inputs are gates with indegree zero,
such as the clock signal or the input state of a cipher.
The circuit inputs are annotated with labels to express their
purpose in the masking scheme, which can either be a share,
a mask, or public. A share represents a share of a secret value,
a mask is a fresh uniformly-distributed random value, and
public means that it is not important for the masked imple-
mentation. These labels are propagated through all gates of
the circuit, following a list of propagation rules. The circuit is
not secure in the classical probing model if there is a gate that
correlates with a native secret, i.e., allows an attacker probing
the gate to deduce information about the native secret.
REBECCA is able to prove the glitch-resistance of masked
hardware circuits. Glitches may arise in the combinatorial
logic, and are caused by various physical hardware properties,
including different wire lengths. REBECCA takes glitches
into account by modeling the stable and transient correlation
of gates. Stable correlations refer to the ﬁnal values of the
signals, whereas transient correlations refer to all intermediate
signal values before the circuit stabilizes.
Fourier Expansions and Leakage Checks
In order to
check for correlation, REBECCA uses correlation sets. A cor-
relation set is bound to a speciﬁc gate in the circuit and de-
scribes which information an attacker can learn by placing
a probe on the gate. These sets are derived from the Fourier
expansion of Boolean functions [37]. Fourier expansions rep-
resent Boolean functions as a polynomial over the real domain
{1,−1}. Examples of Fourier expansions are shown in Ap-
pendix A.
A function correlates to a linear combination of its inputs if
the correlation term representing the linear combination has
a non-zero correlation coefﬁcient. REBECCA applies a very
conservative over-approximation of these coefﬁcients and
derives correlation sets from these. Correlation sets contain
terms with non-zero correlation coefﬁcients while omitting
the exact value of the coefﬁcients. A ﬁrst-order leakage test
for a secret s checks whether a correlation set of any gate con-
tains a term where all shares of s are present without being
masked by a random value (a mask or an incomplete sharing
of another secret). Explicitly constructing the correlation sets
and performing these checks is infeasible, which is why RE-
BECCA encodes everything as a pseudo-Boolean formula and
checks for satisﬁability with the SMT solver Z3 [15].
USENIX Association
30th USENIX Security Symposium    1471
2.3 Probing Models for Software Veriﬁcation
The complexity of a power analysis attack is determined by
the number of intermediate values that an attacker needs to
learn from a power trace by placing probing needles (probes)
in a circuit. The number of probes corresponds to the order
of an attack and the attack complexity grows exponentially
with the order [10]. The classical probing model for hardware
allows an attacker to observe all values and transitions at
a chosen location within a hardware circuit, and therefore
does not express this increase of complexity, but corresponds
to a much more powerful attacker. For example, consider
the case where an attacker is probing the write port of a
CPU register ﬁle. Then, an attacker will always observe all
intermediate values and can break masking schemes with
arbitrary protection order. Consequently, authors have fallen
back to more restrictive probing models for the veriﬁcation
of masked software implementations.
Tools like maskVerif or Tornado are based on a probing