that the discriminator had full access to the training data
and thus easily memorizes the private information about the
training data. Similarly, the release of the generator and/or
the control over the input noise ùëß also incurs a relatively
high privacy risk.
‚Ä¢ The vulnerability of different generative models under MIA
varies. Although the effectiveness of MIA mainly depends on
the generation quality of victim models, the objective func-
tion and training paradigm also play important roles. Specif-
ically, when data reconstruction is explicitly formulated in
the training objective to improve data mode coverage, e.g.
in VAEGAN and VAE, the resulting models become highly
vulnerable to MIA.
‚Ä¢ A smaller training dataset leads to a higher risk of revealing
information of individual samples. In particular, if the magni-
tude of training set size is less than 10ùëò where most existing
GAN models have sufficient modeling capacity for overfit-
ting to individual sample, the membership privacy is highly
likely to be compromised once the GAN model and/or its
generated sample set is released. This causes special concern
when dealing with real-world privacy sensitive datasets (e.g.
medical records), which typically contain very limited data
samples.
‚Ä¢ Differential private defense on GAN training is effective
against practical MIA, but at the cost of high computation
burden and deteriorated generation quality.
7 CONCLUSION
We have established the first taxonomy of membership inference at-
tacks against GANs, with which we hope to benchmark research in
this direction in the future. We have also proposed the first generic
attack model based on reconstruction, which is applicable to all the
settings according to the amount of the attacker‚Äôs knowledge about
the victim model. In particular, the instantiated attack variants in
the partial black-box and white-box settings are another novelty
that bridges the assumption gap and performance gap in the previ-
ous work [25, 29]. In addition, we proposed a novel theoretically
grounded attack calibration technique, which consistently improve
the attack performance in all cases. Comprehensive experiments
show consistent effectiveness and a broad spectrum of performance
in a variety of setups spanning diverse dataset modalities, various
victim models, two directions of analysis study, attack calibration,
as well as differential privacy defense, which conclusively provide
a better understanding of privacy risks associated with deep gener-
ative models.
ACKNOWLEDGMENTS
This work is partially funded by the Helmholtz Association within
the projects "Trustworthy Federated Data Analytics‚Äù (TFDA) (fund-
ing number ZT-I-OO1 4) and "Protecting Genetic Data with Syn-
thetic Cohorts from Deep Generative Models" (PRO-GENE-GEN)
(funding number ZT-I-PF-5-23).
REFERENCES
[1] Martin Abadi, Andy Chu, Ian Goodfellow, Brendan McMahan, Ilya Mironov,
Kunal Talwar, and Li Zhang. 2016. Deep Learning with Differential Privacy. In
ACM SIGSAC Conference on Computer and Communications Security (CCS). ACM,
308‚Äì318.
[2] Gergely Acs, Luca Melis, Claude Castelluccia, and Emiliano De Cristofaro. 2017.
Differentially Private Mixture of Generative Neural Networks. In International
Conference on Data Mining (ICDM). IEEE, 715‚Äì720.
[3] Martin Arjovsky, Soumith Chintala, and L√©on Bottou. 2017. Wasserstein Gen-
erative Adversarial Networks. In International Conference on Machine Learning
(ICML). JMLR, 214‚Äì223.
[4] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. 2017. General-
ization and Equilibrium in Generative Adversarial Nets (GANs). In International
Conference on Machine Learning (ICML). JMLR, 224‚Äì232.
[5] Michael Backes, Pascal Berrang, Mathias Humbert, and Praveen Manoharan. 2016.
Membership Privacy in MicroRNA-based Studies. In ACM SIGSAC Conference on
Computer and Communications Security (CCS). ACM, 319‚Äì330.
[6] Michael Backes, Mathias Humbert, Jun Pang, and Yang Zhang. 2017. walk2friends:
Inferring Social Links from Mobility Profiles. In ACM SIGSAC Conference on
Computer and Communications Security (CCS). ACM, 1943‚Äì1957.
[7] Brett K Beaulieu-Jones, Zhiwei Steven Wu, Chris Williams, Ran Lee, Sanjeev P
Bhavnani, James Brian Byrd, and Casey S Greene. 2019. Privacy-Preserving
Generative Deep Neural Networks Support Clinical Data Sharing. Circulation:
Cardiovascular Quality and Outcomes 12, 7 (2019), e005122.
[8] Apratim Bhattacharyya, Mario Fritz, and Bernt Schiele. 2019. ‚ÄúBest-of-Many-
Samples‚Äù Distribution Matching. CoRR abs/1909.12598 (2019).
[9] Oren Boiman, Eli Shechtman, and Michal Irani. 2008. In Defense of Nearest-
Neighbor based Image Classification. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR). IEEE.
[10] Andrew Brock, Jeff Donahue, and Karen Simonyan. 2019. Large Scale GAN
Training for High Fidelity Natural Image Synthesis. In International Conference
on Learning Representations (ICLR).
[11] Dingfan Chen, Tribhuvanesh Orekondy, and Mario Fritz. 2020. GS-WGAN: A
Gradient-Sanitized Approach for Learning Differentially Private Generators.
CoRR abs/2006.08265 (2020).
[12] Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter F. Stewart,
and Jimeng Sun. 2018. Generating Multi-label Discrete Patient Records using
Generative Adversarial Networks. CoRR abs/1703.06490 (2018).
pendent Components Estimation. CoRR abs/1410.8516 (2015).
[14] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. 2017. Density Estimation
using Real NVP. In International Conference on Learning Representations (ICLR).
[15] Richard O Duda, Peter E Hart, and David G Stork. 2012. Pattern Classification.
John Wiley & Sons.
[16] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
brating Noise to Sensitivity in Private Data Analysis. In Theory of Cryptography
Conference (TCC). Springer, 265‚Äì284.
[17] Cynthia Dwork and Aaron Roth. 2014. The Algorithmic Foundations of Differential
Privacy. Now Publishers Inc.
[18] Cynthia Dwork, Adam D. Smith, Thomas Steinke, Jonathan Ullman, and Salil P.
Vadhan. 2015. Robust Traceability from Trace Amounts. In Annual Symposium
[13] Laurent Dinh, David Krueger, and Yoshua Bengio. 2015. NICE: Non-linear Inde-
on Foundations of Computer Science (FOCS). IEEE, 650‚Äì669.
[19] Maayan Frid-Adar, Eyal Klang, Michal Amitai, Jacob Goldberger, and Hayit
Greenspan. 2018. Synthetic Data Augmentation using GAN for Improved Liver
Lesion Classification. In IEEE International Symposium on Biomedical Imaging
(ISBI). IEEE, 289‚Äì293.
[20] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative Adversarial
Nets. In Annual Conference on Neural Information Processing Systems (NIPS). NIPS,
2672‚Äì2680.
[21] Alex Graves, Abdel rahman Mohamed, and Geoffrey E. Hinton. 2013. Speech
Recognition with Deep Recurrent Neural Networks. In IEEE International Confer-
ence on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6645‚Äì6649.
[22] Jinjin Gu, Yujun Shen, and Bolei Zhou. 2019. Image Processing Using Multi-Code
GAN Prior. CoRR abs/1912.07116 (2019).
[23] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and
Aaron C. Courville. 2017. Improved Training of Wasserstein GANs. In Annual
Conference on Neural Information Processing Systems (NIPS). NIPS, 5767‚Äì5777.
[24] Inken Hagestedt, Yang Zhang, Mathias Humbert, Pascal Berrang, Haixu Tang,
XiaoFeng Wang, and Michael Backes. 2019. MBeacon: Privacy-Preserving Bea-
cons for DNA Methylation Data. In Network and Distributed System Security
Symposium (NDSS). Internet Society.
[25] Jamie Hayes, Luca Melis, George Danezis, and Emiliano De Cristofaro. 2019.
LOGAN: Evaluating Privacy Leakage of Generative Models Using Generative
Adversarial Networks. Symposium on Privacy Enhancing Technologies Symposium
(2019).
[26] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual
Learning for Image Recognition. In IEEE Conference on Computer Vision and
Pattern Recognition (CVPR). IEEE, 770‚Äì778.
[27] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen. 2018.
AttGAN: Facial Attribute Editing by Only Changing What You Want. CoRR
abs/1711.10678 (2018).
[28] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and
Sepp Hochreiter. 2017. GANs Trained by a Two Time-Scale Update Rule Con-
verge to a Local Nash Equilibrium. In Annual Conference on Neural Information
Processing Systems (NIPS). NIPS, 6626‚Äì6637.
[29] Benjamin Hilprecht, Martin H√§rterich, and Daniel Bernau. 2019. Monte Carlo
and Reconstruction Membership Inference Attacks against Generative Models.
Symposium on Privacy Enhancing Technologies Symposium (2019).
[30] Geoffrey Hinton, Li Deng, Dong Yu, George Dahl, Abdel rahman Mohamed,
Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Brian Kings-
bury, et al. 2012. Deep Neural Networks for Acoustic Modeling in Speech Recog-
nition. IEEE Signal Processing Magazine 29 (2012).
[31] Gary B Huang, Marwan Mattar, Tamara Berg, and Eric Learned-Miller. 2008.
Labeled Faces in the Wild: A Database for Studying Face Recognition in Uncon-
strained Environments.
[32] Ali Jahanian, Lucy Chai, and Phillip Isola. 2019. On the ‚ÄúSteerability‚Äù of Generative
Adversarial Networks. CoRR abs/1907.07171 (2019).
[33] Jinyuan Jia, Ahmed Salem, Michael Backes, Yang Zhang, and Neil Zhenqiang
Gong. 2019. MemGuard: Defending against Black-Box Membership Inference
Attacks via Adversarial Examples. In ACM SIGSAC Conference on Computer and
Communications Security (CCS). ACM, 259‚Äì274.
[34] Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-wei, Mengling Feng,
Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and
Roger G Mark. 2016. MIMIC-III, A Freely Accessible Critical Care Database.
Scientific Data 3 (2016), 160035.
[35] James Jordon, Jinsung Yoon, and Mihaela van der Schaar. 2019. PATE-GAN:
Generating Synthetic Data with Differential Privacy Guarantees. OpenReview
(2019).
[36] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. 2018. Progressive
Growing of GANs for Improved Quality, Stability, and Variation. In International
Conference on Learning Representations (ICLR).
[37] Tero Karras, Samuli Laine, and Timo Aila. 2019. A Style-Based Generator Archi-
tecture for Generative Adversarial Networks. In IEEE Conference on Computer
Vision and Pattern Recognition (CVPR). IEEE, 4401‚Äì4410.
[38] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
Timo Aila. 2020. Analyzing and Improving the Image Quality of StyleGAN.
In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE,
8107‚Äì8116.
[39] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-
mization. In International Conference on Learning Representations (ICLR).
[40] Diederik P. Kingma and Prafulla Dhariwal. 2018. Glow: Generative Flow with In-
vertible 1x1 Convolutions. In Annual Conference on Neural Information Processing
Systems (NeurIPS). NeurIPS, 10236‚Äì10245.
[41] Diederik P. Kingma and Max Welling. 2014. Auto-Encoding Variational Bayes. In
International Conference on Learning Representations (ICLR).
[42] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet Clas-
sification with Deep Convolutional Neural Networks. In Annual Conference on
Neural Information Processing Systems (NIPS). NIPS, 1106‚Äì1114.
[43] Anders Boesen Lindbo Larsen, S√∏ren Kaae S√∏nderby, Hugo Larochelle, and Ole
Winther. 2016. Autoencoding beyond Pixels Using a Learned Similarity Metric.
In International Conference on Machine Learning (ICML). JMLR, 1558‚Äì1566.
[44] Chuan Li and Michael Wand. 2016. Precomputed Real-Time Texture Synthesis
with Markovian Generative Adversarial Networks. In European Conference on
Computer Vision (ECCV). Springer, 702‚Äì716.
[45] Zheng Li and Yang Zhang. 2020. Label-Leaks: Membership Inference Attack with
Label. CoRR abs/2007.15528 (2020).
[46] Dong C Liu and Jorge Nocedal. 1989. On the Limited Memory BFGS Method for
Large Scale Optimization. Mathematical Programming 45, 1-3 (1989), 503‚Äì528.
[47] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep Learning
Face Attributes in the Wild. In IEEE International Conference on Computer Vision
(ICCV). IEEE, 3730‚Äì3738.
[48] Yunhui Long, Vincent Bindschaedler, Lei Wang, Diyue Bu, Xiaofeng Wang, Haixu
Tang, Carl A. Gunter, and Kai Chen. 2018. Understanding Membership Inferences
on Well-Generalized Learning Models. CoRR abs/1802.04889 (2018).
[49] Soroush Mehri, Kundan Kumar, Ishaan Gulrajani, Rithesh Kumar, Shubham
Jain, Jose Sotelo, Aaron C. Courville, and Yoshua Bengio. 2017. SampleRNN:
An Unconditional End-to-End Neural Audio Generation Model. In International
Conference on Learning Representations (ICLR).
[50] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov.
2019. Exploiting Unintended Feature Leakage in Collaborative Learning. In IEEE
Symposium on Security and Privacy (S&P). IEEE, 497‚Äì512.
[51] Milad Nasr, Reza Shokri, and Amir Houmansadr. 2019. Comprehensive Privacy
Analysis of Deep Learning: Passive and Active White-box Inference Attacks
against Centralized and Federated Learning. In IEEE Symposium on Security and
Privacy (S&P). IEEE, 1021‚Äì1035.
[52] Deepak Pathak, Philipp Kr√§henb√ºhl, Jeff Donahue, Trevor Darrell, and Alexei A.
Efros. 2016. Context Encoders: Feature Learning by Inpainting. In IEEE Conference
on Computer Vision and Pattern Recognition (CVPR). IEEE, 2536‚Äì2544.
[53] Michael JD Powell. 1964. An Efficient Method for Finding the Minimum of a
Function of Several Variables without Calculating Derivatives. Comput. J. 7, 2
(1964), 155‚Äì162.
[54] Alec Radford, Luke Metz, and Soumith Chintala. 2015. Unsupervised Representa-
tion Learning with Deep Convolutional Generative Adversarial Networks. CoRR
abs/1511.06434 (2015).
[55] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. 2014. Stochastic
Backpropagation and Approximate Inference in Deep Generative Models. CoRR
abs/1401.4082 (2014).
[56] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C.
Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual Recognition Challenge.
CoRR abs/1409.0575 (2015).
[57] Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Yann Ollivier, and
Herv√© J√©gou. 2019. White-box vs Black-box: Bayes Optimal Strategies for Mem-
bership Inference. In International Conference on Machine Learning (ICML). JMLR,
5558‚Äì5567.
[58] Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Berrang, Mario Fritz, and
Michael Backes. 2019. ML-Leaks: Model and Data Independent Membership
Inference Attacks and Defenses on Machine Learning Models. In Network and
Distributed System Security Symposium (NDSS). Internet Society.
[59] Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Rad-
ford, and Xi Chen. 2016. Improved Techniques for Training GANs. In Annual
Conference on Neural Information Processing Systems (NIPS). NIPS, 2226‚Äì2234.
[60] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Mem-
bership Inference Attacks Against Machine Learning Models. In IEEE Symposium
on Security and Privacy (S&P). IEEE, 3‚Äì18.
[61] Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Net-
works for Large-Scale Image Recognition. In International Conference on Learning
Representations (ICLR).
[62] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed,
Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabi-
novich. 2015. Going Deeper with Convolutions. In IEEE Conference on Computer
Vision and Pattern Recognition (CVPR). IEEE, 1‚Äì9.
[63] Tijmen Tieleman and Geoffrey Hinton. 2012. Lecture 6.5-rmsprop: Divide the
Gradient by a Running average of its Recent Magnitude. COURSERA: Neural
Networks for Machine Learning 4, 2 (2012), 26‚Äì31.
[64] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
2016. WaveNet: A Generative Model for Raw Audio. CoRR abs/1609.03499 (2016).
[65] Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. 2015. Show
and Tell: A Neural Image Caption Generator. In IEEE Conference on Computer
Vision and Pattern Recognition (CVPR). IEEE, 3156‚Äì3164.
[66] Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou. 2018. Differen-
tially Private Generative Adversarial Network. CoRR abs/1802.06739 (2018).
[67] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. 2016. Attribute2Image:
Conditional Image Generation from Visual Attributes. In European Conference on
Computer Vision (ECCV). Springer, 776‚Äì791.
[68] Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and Somesh Jha. 2018. Privacy
Risk in Machine Learning: Analyzing the Connection to Overfitting. In IEEE
Computer Security Foundations Symposium (CSF). IEEE, 268‚Äì282.
[69] Xin Yi, Ekta Walia, and Paul Babyn. 2019. Generative Adversarial Network in
Medical Imaging: A Review. Medical Image Analysis (2019), 101552.
[70] Ning Yu, Connelly Barnes, Eli Shechtman, Sohrab Amirghodsi, and Michal Luk√°c.
2019. Texture Mixer: A Network for Controllable Synthesis and Interpolation of
Texture. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
IEEE, 12164‚Äì12173.
[71] Ning Yu, Ke Li, Peng Zhou, Jitendra Malik, Larry Davis, and Mario Fritz. 2020.
Inclusive GAN: Improving Data and Minority Coverage in Generative Models. In
European Conference on Computer Vision (ECCV). Springer.
[72] Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, and Oliver Wang.
2018. The Unreasonable Effectiveness of Deep Features as a Perceptual Metric.
In IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE,
586‚Äì595.
[73] Xinyang Zhang, Shouling Ji, and Ting Wang. 2018. Differentially Private Releasing
via Deep Generative Model (Technical Report). CoRR abs/1801.01594 (2018).
A PROOF
Theorem 5.1. Given the victim model with parameter ùúÉùë£, a query
dataset ùëÜ, the membership probability of a query sample ùë•ùëñ is well
approximated by the sigmoid of minus calibrated reconstruction error.
(15)
ùëÉ(ùëöùëñ = 1|ùúÉùë£, ùë•ùëñ, ùëÜ) ‚âà ùúé(‚àíùêøcal(ùë•ùëñ, R(ùë•ùëñ|Gùë£))
And the optimal attack is equivalent to
A(ùë•ùëñ,M(ùúÉùë£)) = 1[ùêøcal(ùë•ùëñ, R(ùë•ùëñ|Gùë£)) < ùúñ]
(16)
i.e., the attacker checks whether the calibrated reconstruction error of
the query sample ùë•ùëñ is smaller than a threshold ùúñ.
(cid:18)
Proof. By applying the Bayes rule and the property of sigmoid
function ùúé, the membership probability can be rewritten as fol-
lows [57]:
(cid:18) ùëÉ(ùúÉùë£|ùëöùëñ = 1, ùë•ùëñ, ùëÜ‚àíùëñ)ùëÉ(ùëöùëñ = 1)
ùëÉ(ùúÉùë£|ùëöùëñ = 0, ùë•ùëñ, ùëÜ‚àíùëñ)ùëÉ(ùëöùëñ = 0)
(cid:19)(cid:19)
ùëÉ(ùëöùëñ = 1|ùúÉùë£, ùë•ùëñ, ùëÜ) = ùúé
log
(17)
where ùëÜ‚àíùëñ = ùëÜ\(ùë•ùëñ, ùëöùëñ), i.e., the whole query set except the query
sample ùë•ùëñ.
Assuming independence of samples in S while applying Bayes rule
and Product rule, we obtain the following posterior approximation
ùëÉ(ùúÉùë£|ùëÜ) ‚àù 
‚àù exp(‚àí
{ ùëó |ùëö ùëó =1}
ùëÉ(ùë• ùëó|ùúÉùë£)ùëÉ(ùúÉùë£)
ùëö ùëó ¬∑ ùëô(ùë• ùëó , ùúÉùë£))
ùëó
with ùëô(ùë• ùëó , ùúÉùë£) = ùêø(ùë• ùëó , R(ùë•|Gùë£))for brevity. The Equation 18 means
that the probability of a certain model parameter is determined by
its i.i.d. training set samples. Subsequently, by assuming a uniform
prior of the model parameter over the whole parameter space and
plug in the results from Equation 4 we obtain Equation 19.
By normalizing the posterior in Equation 19, we obtain
ùëÉ(ùúÉùë£|ùëöùëñ = 1, ùë•ùëñ, ùëÜ‚àíùëñ) =
ùëÉ(ùúÉùë£|ùëöùëñ = 0, ùë•ùëñ, ùëÜ‚àíùëñ) =
exp(‚àíùëó ùëö ùëó ¬∑ ùëô(ùë• ùëó , ùúÉùë£))
‚à´
ùúÉ‚Ä≤ exp(‚àíùëó ùëö ùëó ¬∑ ùëô(ùë• ùëó , ùúÉ‚Ä≤))ùëëùúÉ‚Ä≤
exp(‚àíùëó‚â†ùëñ ùëö ùëó ¬∑ ùëô(ùë• ùëó , ùúÉùë£))
‚à´
ùúÉ‚Ä≤ exp(‚àíùëó‚â†ùëñ ùëö ùëó ¬∑ ùëô(ùë• ùëó , ùúÉ‚Ä≤))ùëëùúÉ‚Ä≤
(18)