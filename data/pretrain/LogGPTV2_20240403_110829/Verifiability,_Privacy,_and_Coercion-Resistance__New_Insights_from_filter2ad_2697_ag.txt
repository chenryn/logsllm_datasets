is supposed to submit (x
x), each with probability
1
2. Analogously for a voter that wants to vote for candidate 2.
By this, in 50% of the cases, an honest voter reveals her vote,
namley in the case where she does not have x
x as receipt. That
means that this variant provides a very low level of privacy
(δ ≥ 0.5), i.e. the observer can with quite high probability tell
which candidate a given voter voted for. However, this variant
is not that bad in terms of coercion-resistance, as here, the
coerced voter is not bound to follow the honest strategy and
can choose patterns in a more clever way. In fact, we can
use here the same counter-strategy we used previously—take
the receipt required by the coercer and adjust the remaining
ballots to form a valid vote for the favorite candidate. Note
that, following this strategy, the coerced voter may submit
patterns which are valid but never chosen by the program of
an honest voter. For this counter-strategy, although the coercer
might learn approximatively half of the votes of the honest
voters, the actual vote of the coerced voter is still hidden
behind the votes of the honest voters that submitted (x
o, o
o)
or (x
o), i.e. that did not reveal their votes to the coercer.
This results in a reasonably small δ .
x, o
x, o
x, x
VII. CONCLUSION
In this paper, we presented new insights into central se-
curity properties, namely veriﬁability, privacy, and coercion-
resistance. Our ﬁndings, in part, come from a case study, in
which we precisely measure the level of veriﬁability, privacy,
and coercion-resistance of different variants of ThreeBallot
and VAV proposed in the literature.
insufﬁcient
For veriﬁability we have demonstrated that the combination
of individual and universal veriﬁability is, unlike commonly
believed,
to provide overall/global veriﬁability.
Our case study shows that the main problem with individual
and universal veriﬁability is that these notions ignore that
dishonest authorities/voters can break the integrity of ballots
of honest voters by ill-formed ballots. We therefore advocate
the concept of global veriﬁability, as captured by the deﬁnition
of veriﬁability in [19] and used in the present paper.
We also demonstrated that the relationship between pri-
vacy and coercion-resistance is more subtle than what can
be gathered from the literature. Our case study highlighted
interesting phenomena for existing protocols: i) improving
privacy may degrade the level of coercion-resistance, ii) the
level of coercion-resistance may be higher than the level of
privacy. The latter is due to the fact that the counter-strategy
a coerced voter uses maybe “smarter” in hiding information
than the honest voting program. For the case that this is not
so, we were able to prove that δ -coercion-resistance implies
δ -privacy. As discussed in Section VI-E, for many protocols,
the counter-strategy does indeed not outperform the honest
voting program. We conjecture that if it does, then it should
be possible to improve the honest voting program.
Besides these general ﬁndings on veriﬁability, privacy, and
coercion-resistance, our case study also provides the ﬁrst
551
comprehensive picture on the security of prominent voting
systems, ThreeBallot and VAV.
Acknowledgment. This work was partially supported by
Deutsche Forschungsgemeinschaft (DFG) under Grant KU
1434/5-1 and KU 1434/6-1.
REFERENCES
[1] B. Adida
and C.A. Neff.
Ballot Casting Assurance.
In
USENIX/ACCURATE Electronic Voting Technology (EVT 2006), 2006.
[2] J. C. Benaloh and D. Tuinstra. Receipt-free secret-ballot elections
(extended abstract).
In Proceedings of the Twenty-Sixth Annual ACM
Symposium on Theory of Computing (STOC 1994), pages 544–553.
ACM Press, 1994.
[3] J.-M. Bohli, J. M¨uller-Quade, and S. R¨ohrich. Bingo Voting: Secure
and Coercion-Free Voting Using a Trusted Random Number Generator.
In A. Alkassar and M. Volkamer, editors, E-Voting and Identity (VOTE-
ID 2007), volume 4896 of Lecture Notes in Computer Science, pages
111–124. Springer, 2007.
[4] D. Chaum. Elections with unconditionally-secret ballots and disruption
equivalent to breaking rsa. In Advances in Cryptology – Eurocrypt ’88,
volume 330 of Lecture Notes in Computer Science, pages 177–182.
Springer, 1988.
[5] D. Chaum, R. Carback, J. Clark, A. Essex, S. Popoveniuc, R. L.
Rivest, P. Y. A. Ryan, E. Shen, and A. T. Sherman.
Scantegrity
II: End-to-End Veriﬁability for Optical Scan Election Systems using
Invisible Ink Conﬁrmation Codes. In USENIX/ACCURATE Electronic
Voting Technology (EVT 2008). USENIX Association, 2008. See also
http://www.scantegrity.org/elections.php.
[6] D. Chaum, P.Y.A. Ryan, and S. Schneider. A Practical, Voter-veriﬁable
Election Scheme.
In Proceedings of the 10th European Symposium
on Research in Computer Security (ESORICS 2005), volume 3679 of
Lecture Notes in Computer Science, pages 118–139. Springer, 2005.
[7] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward a Secure
Voting System. In 2008 IEEE Symposium on Security and Privacy (S&P
2008), pages 354–368. IEEE Computer Society, 2008.
[8] O. de Marneffe, O. Pereira, and J.-J. Quisquater. Simulation-Based
Analysis of E2E Voting Systems.
In A. Alkassar and M. Volkamer,
editors, E-Voting and Identity (VOTE-ID 2007), volume 4896 of Lecture
Notes in Computer Science, pages 137–149. Springer, 2007.
[9] S. Delaune, S. Kremer, and M. D. Ryan. Verifying Privacy-type
Properties of Electronic Voting Protocols. Journal of Computer Security,
17(4):435–487, 2009.
[10] S. Delaune, S. Kremer, and M.D. Ryan. Coercion-Resistance and
Receipt-Freeness in Electronic Voting. In Proceedings of the 19th IEEE
Computer Security Foundations Workshop (CSFW’06), pages 28–39.
IEEE Computer Society Press, 2006.
[11] Kevin Henry, Douglas R. Stinson, and Jiayuan Sui. The Effectiveness
of Receipt-based Attacks on ThreeBallot. IEEE Transactions on Infor-
mation Forensics and Security, 4(4):699–707, 2009.
[12] M. Hirt and K. Sako. Efﬁcient receipt-free voting based on homo-
morphic encryption.
In B. Preneel, editor, Advances in Cryptology –
EUROCRYPT 2000, volume 1807 of Lecture Notes in Computer Science,
pages 539 – 556. Springer, 2000.
[13] A. Juels, D. Catalano, and M. Jakobsson. Coercion-resistant Electronic
In Proceedings of Workshop on Privacy in the Eletronic
Elections.
Society (WPES 2005), pages 61–70. ACM Press, 2005.
[14] Steve Kremer, Mark Ryan, and Ben Smyth. Election Veriﬁability in
Electronic Voting Protocols.
In Dimitris Gritzalis, Bart Preneel, and
Marianthi Theoharidou, editors, 15th European Symposium on Research
in Computer Security (ESORICS2010), volume 6345 of Lecture Notes
in Computer Science, pages 389–404. Springer, 2010.
[15] R. K¨usters. Simulation-Based Security with Inexhaustible Interactive
Turing Machines. In Proceedings of the 19th IEEE Computer Security
Foundations Workshop (CSFW-19 2006), pages 309–320. IEEE Com-
puter Society, 2006.
[16] R. K¨usters and T. Truderung. An Epistemic Approach to Coercion-
Resistance for Electronic Voting Protocols. In 2009 IEEE Symposium
on Security and Privacy (S&P 2009), pages 251–266. IEEE Computer
Society, 2009.
[17] R. K¨usters, T. Truderung, and A. Vogt. Proving Coercion-Resistance of
Scantegrity II. In Miguel Soriano, Sihan Qing, and Javier L´opez, editors,
Proceedings of the 12th International Conference on Information and
Communications Security (ICICS 2010), volume 6476 of Lecture Notes
in Computer Science, pages 281–295. Springer, 2010.
[18] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. A Game-based
Deﬁnition of Coercion-Resistance and its Applications. In 23th IEEE
Computer Security Foundations Symposium, CSF 2010, pages 122–136.
IEEE Computer Society, 2010.
[19] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. Accountability:
Deﬁnition and Relationship to Veriﬁability. In Proceedings of the 17th
ACM Conference on Computer and Communications Security (CCS
2010), pages 526–535. ACM, 2010.
[20] Ralf K¨usters, Tomasz Truderung, and Andreas Vogt. Veriﬁability,
Privacy, and Coercion-Resistance: New Insights from a Case Study.
Technical report, University of Trier, 2011. Available at http://infsec.
uni-trier.de/publications.html.
[21] T. Moran and M. Naor. Receipt-Free Universally-Veriﬁable Voting
With Everlasting Privacy. In C. Dwork, editor, Advances in Cryptology
- CRYPTO 2006, 26th Annual International Cryptology Conference,
Proceedings, volume 4117 of Lecture Notes in Computer Science, pages
373–392. Springer, 2006.
[22] T. Moran and M. Naor. Split-ballot voting: everlasting privacy with
distributed trust.
In P. Ning, S. De Capitani di Vimercati, and P. F.
Syverson, editors, Proceedings of the 2007 ACM Conference on Com-
puter and Communications Security, CCS 2007, pages 246–255. ACM,
2007.
[23] T. Okamoto. Receipt-Free Electronic Voting Schemes for Large Scale
Elections. In B. Christianson, B. Crispo, T. M. A. Lomas, and M. Roe,
editors, Proceedings of
the 5th International Workshop on Security
Protocols, volume 1361 of Lecture Notes in Computer Science, pages
25–35. Springer, 1997.
[24] B. Riva and A. Ta-Shma. Bare-Handed Electronic Voting with Pre-
processing. In USENIX/ACCURATE Electronic Voting Technology (EVT
2007), 2007.
[25] R. L. Rivest and W. D. Smith. Three Voting Protocols: ThreeBallot,
VAV and Twin. In USENIX/ACCURATE Electronic Voting Technology
(EVT 2007), 2007.
[26] Charlie E. M. Strauss. A critical review of the triple ballot voting
system, part 2: Cracking the triple ballot encryption. http://www.cs.
princeton.edu/∼appel/voting/Strauss-ThreeBallotCritique2v1.5.pdf, Oc-
tober 8, 2006. Draft V1.5.
A. Proof Sketch of Theorem 1
APPENDIX
For the ﬁrst condition of Deﬁnition 1, we have to show that
whenever, in a run of the system, the machine and the bulletin
board are honest, ver accepts this run with overwhelming
probability. This is easy to see: If the machine and the bulletin
board are honest in a run of the system, only well-formed
ballots are sent to the bulletin board, (with overwhelming
probability) no serial numbers occur twice, and the bulletin
board correctly displays the ballots received from the machine.
Now, by the deﬁnition of the veriﬁer, it follows that ver accepts
such a run.
Ver or δ o
For the second condition of Deﬁnition 1, we have to show
that the probability that the system produces a run which is
accepted by ver, even though the goal is violated, is bounded
by δ p
Ver, respectively. In such a run, since it is accepted
by ver, the bulletin board must be consistent. Furthermore,
because the goal is violated, there must exist a candidate, say
candidate i, such that the sum of all votes of honest voters for
all candidates except i is at least (cid:2) + 1.
As we have already shown, the machine can safely change
m votes. Therefore, in order to violate the goal γ(cid:2), it remains
(cid:2) = (cid:2) +1−min((cid:2) +1,m) votes of honest voters that
to change k
552
did not vote for candidate i. One can verify that the best (the
(cid:2) multi-ballots cast by
safest) way of doing this is to change k
(cid:2) different honest voters, who voted for some j (cid:14)= i, in the
k
following way: A dishonest party (the voting machine or the
bulletin board) chooses one simple ballot of such a voter with
marked j-th position, but not i-th position, and replaces it by
a similar ballot, but with the markings on the i-th and j-th
position swapped (one can show that this is always possible).
Every time this is done, the probability that this is detected by
· pcheck in
an honest voter is 1
6
So
TB. These probabilities can be computed by some elementary
(cid:2) times and, as mentioned,
calculation. As it must be done k
there must exist (cid:2) + 1 voters who voted not for candidate i,
we conclude that the probability that the goal γ(cid:2) is violated
Ver and δ o
and the observer accepts the run is bounded by δ p
Ver,
respectively, and that these bounds are optimal.
· pcheck in the system Sp
TB and 1
3
B. Veriﬁability of VAV
Let Ps
VAV and Pp
VAV denote the VAV protocol in the sim-
ple variant and the privacy enhanced variant, respectively.
Based on analogous assumptions as those for ThreeBallot
(see Section V-B), it is straightforward to formally deﬁne the
protocol instantiations Ss
VAV
and Sp
VAV({ver},q,VH ,k,(cid:3)p) of Ps
TB({ver},q,VH ,k,(cid:3)p) of Pp
VAV = Pp
VAV = Ps
To state the following theorem, we need to introduce the
following notation. For a given run of the protocol, we denote
by A the set of those candidates j for which the sum of all
votes of honest voters for all candidates except
j is at least
(cid:2) + 1. Moreover, by Xj we denote the number of multi-ballots
in a run submitted by honest voters for which the following
holds: i) The multi-ballot forms a vote for a candidate different
from j and ii) On the multi-ballot, not the same candidate
is marked on all three simple ballots; these multi-ballots can
VAV.
safely be changed to votes for j, as explained in Section IV.
Finally, we deﬁne pr = Pr[A (cid:14)= /0 and max j∈A Xj = r], where
the probability is over runs of the protocol. (Note that pr only
depends on choices made by honest voters.)
Theorem 7. Let B be the set containing the voting ma-
chine and the bulletin board and x ∈ {s, p}. The goal γ(cid:2) is
guaranteed in Sx
VerVAV-veriﬁable by a, where
δ s
VerVAV
VAV by B and δ x
Ver with δ o
(cid:2)
Ver as in Theorem 1 and
(cid:3)max((cid:2)+1−r−m,0)
= δ o
,
δ p
VerVAV
=
n∑
r=0
pr
1− 1
4
· pckeck
where m is the number of dishonest voters and pr is deﬁned
as above.
The statement for Ss
VAV follows as in the proof of The-
orem 1. The intuition behind the statement for Sp
VAV is the
following. The best strategy of the adversary for violating
the goal in a given run is as follows: First, he determines
those candidates j such that the number of submitted multi-
ballots not for j is bigger than (cid:2). (Those candidates form the
set A introduced above). Second, among those candidates, he
determines a candidate j for which the number Xj is maximal.
The probability of this number being r is pr. Now, if Xj = r,
then the adversary can safely change r votes. If there are
some further votes to be changed (i.e. if r < (cid:2) + 1), then
the adversary can use dishonest voters to change additional
m votes, as described in Section V-B. Only if there are still
some votes to be changed (i.e. r + m < (cid:2) + 1), the adversary
has to change further ballots, namely (cid:2) + 1− r− m, which is
· pcheck for each ballot. Hence, the
detected with probability 1
(cid:6)
4
probability that the adversary goes undetected when changing
(cid:2) + 1− r− m ballots is
1− 1
(cid:7)(cid:2)+1−r−m.
· pckeck
4
553