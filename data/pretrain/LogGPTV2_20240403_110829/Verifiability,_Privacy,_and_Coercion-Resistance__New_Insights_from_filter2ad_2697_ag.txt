### Optimized Text

#### Voting Privacy and Coercion-Resistance Analysis

A voter is required to submit (x, x) with a probability of 1/2. Similarly, a voter who wishes to vote for candidate 2 follows the same process. In 50% of the cases, an honest voter reveals their vote, specifically when they do not have (x, x) as a receipt. This implies that this variant provides a very low level of privacy (δ ≥ 0.5), meaning the observer can, with high probability, determine which candidate a given voter voted for.

However, this variant is not entirely inadequate in terms of coercion-resistance. A coerced voter is not bound to follow the honest strategy and can choose patterns more strategically. The counter-strategy previously discussed—where the coerced voter takes the receipt required by the coercer and adjusts the remaining ballots to form a valid vote for their preferred candidate—can be applied here. Using this strategy, the coerced voter may submit patterns that are valid but would never be chosen by an honest voter's program. Although the coercer might learn approximately half of the votes from honest voters, the actual vote of the coerced voter remains hidden behind the votes of honest voters who submitted (x, o, o) or (x, o), i.e., those who did not reveal their votes to the coercer. This results in a reasonably small δ.

#### Conclusion

In this paper, we present new insights into central security properties: verifiability, privacy, and coercion-resistance. Our findings, in part, come from a case study where we precisely measure the levels of these properties in different variants of ThreeBallot and VAV proposed in the literature.

For verifiability, we demonstrate that the combination of individual and universal verifiability is insufficient to provide overall/global verifiability. Our case study shows that the main problem with individual and universal verifiability is that these concepts ignore the possibility of dishonest authorities or voters breaking the integrity of honest voters' ballots through ill-formed ballots. We advocate for the concept of global verifiability, as defined in [19] and used in this paper.

We also show that the relationship between privacy and coercion-resistance is more nuanced than what is typically presented in the literature. Our case study highlights interesting phenomena:
1. Improving privacy may degrade the level of coercion-resistance.
2. The level of coercion-resistance may be higher than the level of privacy, due to the fact that the counter-strategy a coerced voter uses might be "smarter" in hiding information than the honest voting program.

If the counter-strategy does not outperform the honest voting program, we prove that δ-coercion-resistance implies δ-privacy. For many protocols, the counter-strategy indeed does not outperform the honest voting program. We conjecture that if it does, it should be possible to improve the honest voting program.

In addition to these general findings on verifiability, privacy, and coercion-resistance, our case study provides the first comprehensive picture of the security of prominent voting systems, such as ThreeBallot and VAV.

#### Acknowledgment

This work was partially supported by the Deutsche Forschungsgemeinschaft (DFG) under Grant KU 1434/5-1 and KU 1434/6-1.

#### References

[1] B. Adida and C.A. Neff. Ballot Casting Assurance. In USENIX/ACCURATE Electronic Voting Technology (EVT 2006), 2006.

[2] J. C. Benaloh and D. Tuinstra. Receipt-free secret-ballot elections (extended abstract). In Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing (STOC 1994), pages 544–553. ACM Press, 1994.

[3] J.-M. Bohli, J. Müller-Quade, and S. Röhrich. Bingo Voting: Secure and Coercion-Free Voting Using a Trusted Random Number Generator. In A. Alkassar and M. Volkamer, editors, E-Voting and Identity (VOTE-ID 2007), volume 4896 of Lecture Notes in Computer Science, pages 111–124. Springer, 2007.

[4] D. Chaum. Elections with unconditionally-secret ballots and disruption equivalent to breaking RSA. In Advances in Cryptology – Eurocrypt ’88, volume 330 of Lecture Notes in Computer Science, pages 177–182. Springer, 1988.

[5] D. Chaum, R. Carback, J. Clark, A. Essex, S. Popoveniuc, R. L. Rivest, P. Y. A. Ryan, E. Shen, and A. T. Sherman. Scantegrity II: End-to-End Verifiability for Optical Scan Election Systems using Invisible Ink Confirmation Codes. In USENIX/ACCURATE Electronic Voting Technology (EVT 2008). USENIX Association, 2008. See also http://www.scantegrity.org/elections.php.

[6] D. Chaum, P.Y.A. Ryan, and S. Schneider. A Practical, Voter-verifiable Election Scheme. In Proceedings of the 10th European Symposium on Research in Computer Security (ESORICS 2005), volume 3679 of Lecture Notes in Computer Science, pages 118–139. Springer, 2005.

[7] M. R. Clarkson, S. Chong, and A. C. Myers. Civitas: Toward a Secure Voting System. In 2008 IEEE Symposium on Security and Privacy (S&P 2008), pages 354–368. IEEE Computer Society, 2008.

[8] O. de Marneffe, O. Pereira, and J.-J. Quisquater. Simulation-Based Analysis of E2E Voting Systems. In A. Alkassar and M. Volkamer, editors, E-Voting and Identity (VOTE-ID 2007), volume 4896 of Lecture Notes in Computer Science, pages 137–149. Springer, 2007.

[9] S. Delaune, S. Kremer, and M. D. Ryan. Verifying Privacy-type Properties of Electronic Voting Protocols. Journal of Computer Security, 17(4):435–487, 2009.

[10] S. Delaune, S. Kremer, and M.D. Ryan. Coercion-Resistance and Receipt-Freeness in Electronic Voting. In Proceedings of the 19th IEEE Computer Security Foundations Workshop (CSFW’06), pages 28–39. IEEE Computer Society Press, 2006.

[11] Kevin Henry, Douglas R. Stinson, and Jiayuan Sui. The Effectiveness of Receipt-based Attacks on ThreeBallot. IEEE Transactions on Information Forensics and Security, 4(4):699–707, 2009.

[12] M. Hirt and K. Sako. Efficient receipt-free voting based on homomorphic encryption. In B. Preneel, editor, Advances in Cryptology – EUROCRYPT 2000, volume 1807 of Lecture Notes in Computer Science, pages 539–556. Springer, 2000.

[13] A. Juels, D. Catalano, and M. Jakobsson. Coercion-resistant Electronic Voting. In Proceedings of Workshop on Privacy in the Electronic Society (WPES 2005), pages 61–70. ACM Press, 2005.

[14] Steve Kremer, Mark Ryan, and Ben Smyth. Election Verifiability in Electronic Voting Protocols. In Dimitris Gritzalis, Bart Preneel, and Marianthi Theoharidou, editors, 15th European Symposium on Research in Computer Security (ESORICS2010), volume 6345 of Lecture Notes in Computer Science, pages 389–404. Springer, 2010.

[15] R. Küsters. Simulation-Based Security with Inexhaustible Interactive Turing Machines. In Proceedings of the 19th IEEE Computer Security Foundations Workshop (CSFW-19 2006), pages 309–320. IEEE Computer Society, 2006.

[16] R. Küsters and T. Truderung. An Epistemic Approach to Coercion-Resistance for Electronic Voting Protocols. In 2009 IEEE Symposium on Security and Privacy (S&P 2009), pages 251–266. IEEE Computer Society, 2009.

[17] R. Küsters, T. Truderung, and A. Vogt. Proving Coercion-Resistance of Scantegrity II. In Miguel Soriano, Sihan Qing, and Javier López, editors, Proceedings of the 12th International Conference on Information and Communications Security (ICICS 2010), volume 6476 of Lecture Notes in Computer Science, pages 281–295. Springer, 2010.

[18] Ralf Küsters, Tomasz Truderung, and Andreas Vogt. A Game-based Definition of Coercion-Resistance and its Applications. In 23rd IEEE Computer Security Foundations Symposium, CSF 2010, pages 122–136. IEEE Computer Society, 2010.

[19] Ralf Küsters, Tomasz Truderung, and Andreas Vogt. Accountability: Definition and Relationship to Verifiability. In Proceedings of the 17th ACM Conference on Computer and Communications Security (CCS 2010), pages 526–535. ACM, 2010.

[20] Ralf Küsters, Tomasz Truderung, and Andreas Vogt. Verifiability, Privacy, and Coercion-Resistance: New Insights from a Case Study. Technical report, University of Trier, 2011. Available at http://infsec.uni-trier.de/publications.html.

[21] T. Moran and M. Naor. Receipt-Free Universally-Verifiable Voting With Everlasting Privacy. In C. Dwork, editor, Advances in Cryptology - CRYPTO 2006, 26th Annual International Cryptology Conference, Proceedings, volume 4117 of Lecture Notes in Computer Science, pages 373–392. Springer, 2006.

[22] T. Moran and M. Naor. Split-ballot voting: everlasting privacy with distributed trust. In P. Ning, S. De Capitani di Vimercati, and P. F. Syverson, editors, Proceedings of the 2007 ACM Conference on Computer and Communications Security, CCS 2007, pages 246–255. ACM, 2007.

[23] T. Okamoto. Receipt-Free Electronic Voting Schemes for Large Scale Elections. In B. Christianson, B. Crispo, T. M. A. Lomas, and M. Roe, editors, Proceedings of the 5th International Workshop on Security Protocols, volume 1361 of Lecture Notes in Computer Science, pages 25–35. Springer, 1997.

[24] B. Riva and A. Ta-Shma. Bare-Handed Electronic Voting with Preprocessing. In USENIX/ACCURATE Electronic Voting Technology (EVT 2007), 2007.

[25] R. L. Rivest and W. D. Smith. Three Voting Protocols: ThreeBallot, VAV and Twin. In USENIX/ACCURATE Electronic Voting Technology (EVT 2007), 2007.

[26] Charlie E. M. Strauss. A critical review of the triple ballot voting system, part 2: Cracking the triple ballot encryption. http://www.cs.princeton.edu/~appel/voting/Strauss-ThreeBallotCritique2v1.5.pdf, October 8, 2006. Draft V1.5.

### Appendix

#### Proof Sketch of Theorem 1

**First Condition:**
To satisfy the first condition of Definition 1, we need to show that whenever the machine and the bulletin board are honest, the verifier accepts the run with overwhelming probability. This is straightforward: if the machine and the bulletin board are honest, only well-formed ballots are sent to the bulletin board, (with overwhelming probability) no serial numbers occur twice, and the bulletin board correctly displays the ballots received from the machine. By the definition of the verifier, it follows that the verifier accepts such a run.

**Second Condition:**
For the second condition of Definition 1, we need to show that the probability that the system produces a run accepted by the verifier, even though the goal is violated, is bounded by δ. In such a run, since it is accepted by the verifier, the bulletin board must be consistent. Furthermore, because the goal is violated, there must exist a candidate, say candidate i, such that the sum of all votes of honest voters for all candidates except i is at least (cid:2) + 1.

As we have shown, the machine can safely change m votes. Therefore, to violate the goal γ(cid:2), it remains to change (cid:2) = (cid:2) + 1 − min((cid:2) + 1, m) votes of honest voters who did not vote for candidate i. The best (safest) way to do this is to change k(cid:2) multi-ballots cast by k(cid:2) different honest voters, who voted for some j ≠ i, by swapping the markings on the i-th and j-th positions. Each time this is done, the probability that it is detected by an honest voter is 1/6 · pcheck in TB. These probabilities can be computed by elementary calculation. Since it must be done k(cid:2) times and there must exist (cid:2) + 1 voters who did not vote for candidate i, the probability that the goal γ(cid:2) is violated and the observer accepts the run is bounded by δ and δ, respectively, and these bounds are optimal.

#### Verifiability of VAV

Let PsVAV and PpVAV denote the VAV protocol in the simple variant and the privacy-enhanced variant, respectively. Based on analogous assumptions as those for ThreeBallot (see Section V-B), it is straightforward to formally define the protocol instantiations SsVAV and SpVAV({ver}, q, VH, k, (cid:3)p) of PsTB({ver}, q, VH, k, (cid:3)p) of PpVAV = PpVAV = PsVAV.

To state the following theorem, we introduce the following notation. For a given run of the protocol, let A be the set of candidates j for which the sum of all votes of honest voters for all candidates except j is at least (cid:2) + 1. Let Xj denote the number of multi-ballots in a run submitted by honest voters for which the following holds: i) The multi-ballot forms a vote for a candidate different from j, and ii) On the multi-ballot, not the same candidate is marked on all three simple ballots; these multi-ballots can be safely changed to votes for j, as explained in Section IV. Finally, we define pr = Pr[A ≠ /0 and max j∈A Xj = r], where the probability is over runs of the protocol. (Note that pr only depends on choices made by honest voters.)

**Theorem 7:**
Let B be the set containing the voting machine and the bulletin board, and x ∈ {s, p}. The goal γ(cid:2) is guaranteed in SxVAV by B and δxVer with δoVer as in Theorem 1 and
\[
\delta pVerVAV = \sum_{r=0}^{n} pr \left(1 - \frac{1}{4} \cdot pcheck\right)^{\max((cid:2)+1-r-m,0)}
\]
where m is the number of dishonest voters and pr is defined as above.

The statement for SsVAV follows as in the proof of Theorem 1. The intuition behind the statement for SpVAV is as follows: The best strategy for the adversary to violate the goal in a given run is to first determine the candidates j for which the number of submitted multi-ballots not for j is greater than (cid:2). Among those candidates, the adversary determines a candidate j for which the number Xj is maximal. The probability of this number being r is pr. If Xj = r, the adversary can safely change r votes. If there are additional votes to be changed (i.e., if r < (cid:2) + 1), the adversary can use dishonest voters to change additional m votes, as described in Section V-B. Only if there are still votes to be changed (i.e., r + m < (cid:2) + 1), the adversary has to change further ballots, namely (cid:2) + 1 − r − m, which is detected with probability 1/4 · pcheck for each ballot. Hence, the probability that the adversary goes undetected when changing (cid:2) + 1 − r − m ballots is
\[
\left(1 - \frac{1}{4} \cdot pcheck\right)^{(cid:2)+1-r-m}.
\]