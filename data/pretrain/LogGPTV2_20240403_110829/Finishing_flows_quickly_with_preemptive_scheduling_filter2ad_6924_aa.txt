title:Finishing flows quickly with preemptive scheduling
author:Chi-Yao Hong and
Matthew Caesar and
Brighten Godfrey
Finishing Flows Quickly with Preemptive Scheduling
Chi-Yao Hong
UIUC
PI:EMAIL
Matthew Caesar
UIUC
PI:EMAIL
P. Brighten Godfrey
UIUC
PI:EMAIL
ABSTRACT
Today’s data centers face extreme challenges in providing
low latency. However, fair sharing, a principle commonly
adopted in current congestion control protocols, is far from
optimal for satisfying latency requirements.
We propose Preemptive Distributed Quick (PDQ) ﬂow
scheduling, a protocol designed to complete ﬂows quickly
and meet ﬂow deadlines. PDQ enables ﬂow preemption to
approximate a range of scheduling disciplines. For exam-
ple, PDQ can emulate a shortest job ﬁrst algorithm to give
priority to the short ﬂows by pausing the contending ﬂows.
PDQ borrows ideas from centralized scheduling disciplines
and implements them in a fully distributed manner, making
it scalable to today’s data centers. Further, we develop a
multipath version of PDQ to exploit path diversity.
Through extensive packet-level and ﬂow-level simulation,
we demonstrate that PDQ signiﬁcantly outperforms TCP,
RCP and D3 in data center environments. We further show
that PDQ is stable, resilient to packet loss, and preserves
nearly all its performance gains even given inaccurate ﬂow
information.
Categories and Subject Descriptors: C.2.2 [Computer-
Communication Networks]: Network Protocols
General Terms: Algorithms, Design, Performance
Keywords: Data center, Flow scheduling, Deadline
1.
INTRODUCTION
Data centers are now used as the underlying infrastruc-
ture of many modern commercial operations, including web
services, cloud computing, and some of the world’s largest
databases and storage services. Data center applications
including ﬁnancial services, social networking, recommen-
dation systems, and web search often have very demanding
latency requirements. For example, even fractions of a sec-
ond make a quantiﬁable diﬀerence in user experience for
web services [7]. And a service that aggregates results from
many back-end servers has even more stringent requirements
on completion time of the back-end ﬂows, since the service
must often wait for the last of these ﬂows to ﬁnish or else
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’12, August 13–17, 2012, Helsinki, Finland.
Copyright 2012 ACM 978-1-4503-1419-0/12/08 ...$15.00.
reduce the quality of the ﬁnal results.1 Minimizing delays
from network congestion, or meeting soft-real-time deadlines
with high probability, is therefore important.
Unfortunately, current transport protocols neither mini-
mize ﬂow completion time nor meet deadlines. TCP, RCP [10],
ICTCP [22], and DCTCP [3] approximate fair sharing, di-
viding link bandwidth equally among ﬂows. Fair sharing
is known to be far from optimal in terms of minimizing
ﬂow completion time [4] and the number of deadline-missing
ﬂows [5]. As a result, a study of three production data cen-
ters [20] showed that a signiﬁcant fraction (7 − 25%) of ﬂow
deadlines were missed, resulting in degradation of applica-
tion response quality, waste of network bandwidth, and ul-
timately loss of operator revenue [3].
This paper introduces Preemptive Distributed Quick
(PDQ) ﬂow scheduling, a protocol designed to complete
ﬂows quickly and meet ﬂow deadlines. PDQ builds on tra-
ditional real-time scheduling techniques: when processing a
queue of tasks, scheduling in order of Earliest Deadline First
(EDF) is known to minimize the number of late tasks, while
Shortest Job First (SJF) minimizes mean ﬂow completion
time. However, applying these policies to scheduling data
center ﬂows introduces several new challenges.
First, EDF and SJF assume a centralized scheduler which
knows the global state of the system; this would impede our
goal of low latency in a large data center. To perform dy-
namic decentralized scheduling, PDQ provides a distributed
algorithm to allow a set of switches to collaboratively gather
information about ﬂow workloads and converge to a stable
agreement on allocation decisions. Second, unlike “fair shar-
ing” protocols, EDF and SJF rely on the ability to preempt
existing tasks, to ensure a newly arriving task with a smaller
deadline can be completed before a currently-scheduled task.
To support this functionality in distributed environments,
PDQ provides the ability to perform distributed preemp-
tion of existing ﬂow traﬃc, in a manner that enables fast
switchover and is guaranteed to never deadlock.
Thus, PDQ provides a distributed ﬂow scheduling layer
which is lightweight, using only FIFO tail-drop queues, and
ﬂexible, in that it can approximate a range of scheduling
disciplines based on relative priority of ﬂows. We use this
primitive to implement two scheduling disciplines: EDF to
minimize mean ﬂow completion time, and SJF to minimize
the number of deadline-missing ﬂows.
Through an extensive simulation study using real data-
center workloads, we ﬁnd that PDQ provides strong bene-
ﬁts over existing datacenter transport mechanisms. PDQ is
1See discussion in [3], §2.1.
127most closely related to D3 [20], which also tries to meet ﬂow
deadlines. Unlike D3, which is a “ﬁrst-come ﬁrst-reserve” al-
gorithm, PDQ proactively and preemptively gives network
resources to the most critical ﬂows. For deadline-constrained
ﬂows, our evaluation shows PDQ supports 3 times more con-
current senders than [20] while satisfying their ﬂow dead-
lines. When ﬂows have no deadlines, we show PDQ can
reduce mean ﬂow completion times by ∼30% or more com-
pared with TCP, RCP, and D3.
Flow ID Size Deadline
fA
fB
fC
1
2
3
(a)
1
4
6
(b)
The key contributions of this paper are:
• We design and implement PDQ, a distributed ﬂow
scheduling layer for data centers which can approxi-
mate a range of scheduling disciplines.
• We build on PDQ to implement ﬂow scheduling disci-
plines that minimize mean ﬂow completion time and
the number of deadline-missing ﬂows.
• We demonstrate PDQ can save ∼30% average ﬂow
completion time compared with TCP, RCP and D3;
and can support 3× as many concurrent senders as D3
while meeting ﬂow deadlines.
• We show that PDQ is stable, resilient to packet loss,
and preserves nearly all its performance gains even
given inaccurate ﬂow information.
• We develop and evaluate a multipath version of PDQ,
showing further performance and reliability gains.
2. OVERVIEW
We start by presenting an example to demonstrate poten-
tial beneﬁts of PDQ over existing approaches (§2.1). We
then give a description of key challenges that PDQ must
address (§2.2).
2.1 Example of Beneﬁts
Consider the scenario shown in Figure 1, where three con-
3
current ﬂows (fA, fB, and fC ) arrive simultaneously.
Deadline-unconstrained Case: Suppose that the ﬂows
have no deadlines, and our objective is to minimize the av-
erage ﬂow completion time. Assuming a ﬂuid traﬃc model
(inﬁnitesimal units of transmission), the result given by fair
[fA,fB,fC ] ﬁnish at time
sharing is shown in Figure 1b:
[3,5,6], and the average ﬂow completion time is 3+5+6
=
4.67. If we schedule the ﬂows by SJF (one by one according
to ﬂow size), as shown in Figure 1c, the completion time
= 3.33, a savings of ∼29% compared to
becomes 1+3+6
fair sharing. Moreover, for every individual ﬂow, the ﬂow
completion time in SJF is no larger than that given by fair
sharing.
Deadline-constrained Case: Suppose now that the ﬂows
have deadlines, as speciﬁed in Figure 1a. The objective be-
comes minimizing the number of tardy ﬂows, i.e., maximiz-
ing the number of ﬂows that meet their deadlines. For fair
sharing, both ﬂow fA and fB fail to meet their deadlines, as
shown in Figure 1b. If we schedule the ﬂows by EDF (one
by one according to deadline), as shown in Figure 1c, every
ﬂow can ﬁnish before its deadline.
3
Now we consider D3, a recently proposed deadline-aware
protocol for data center networks [20]. When the network is
congested, D3 satisﬁes as many ﬂows as possible according
to the ﬂow request rate in the order of their arrival.
In
particular, each ﬂow will request a rate r = s
d , where s is the
ﬂow’s size and d is the time until its deadline. Therefore, the
(c)
(d)
Figure 1: Motivating Example. (a) Three concurrent ﬂows
competing for a single bottleneck link; (b) Fair sharing; (c)
SJF/EDF; (d) D3 for ﬂow arrival order fB;fA;fC .
result of D3 depends highly on ﬂow arrival order. Assuming
ﬂows arrive in the order fB;fA;fC , the result of D3 is
shown in Figure 1d. Flow fB will send with rate 2
4 = 0.5
and will ﬁnish right before its deadline. However, ﬂow fA,
which arrives later than fB, will fail to meet its deadline
using the remaining bandwidth, as evident in Figure 1d.
In fact, out of 3! = 6 possible permutations of ﬂow arrival
order, D3 will fail to satisfy some of the deadlines for 5 cases,
the only exception being the order fA;fB;fC , which is
the order EDF chooses. Although D3 also allows senders
to terminate ﬂows that fail to meet their deadlines (to save
bandwidth), termination does not help in this scenario and
is not presented in Figure 1d.
2.2 Design Challenges
Although attractive performance gains are seen from the
example, many design challenges remain to realize the ex-
pected beneﬁts.
Scheduling
Decentralizing Scheduling Disciplines:
disciplines like EDF or SJF are centralized algorithms that
require global knowledge of ﬂow information, introducing a
single point of failure and signiﬁcant overhead for senders
to interact with the centralized coordinator. For example, a
centralized scheduler introduces considerable ﬂow initializa-
tion overhead, while becoming a congestive hot-spot. This
problem is especially severe in data center workloads where
the majority of ﬂows are mice. A scheduler maintaining only
elephant ﬂows like DevoFlow [8] seems unlikely to succeed in
congestion control as deadline constraints are usually asso-
ciated with mice. The need to address the above limitations
leads to PDQ, a fully distributed solution where switches
collaboratively control ﬂow schedules.
Switching Between Flows Seamlessly: The example
of §2.1 idealistically assumed we can start a new ﬂow im-
mediately after a previous one terminates, enabling all the
transmission schedules (Figure 1b, 1c and 1d) to fully uti-
lize the bottleneck bandwidth and thus complete ﬂows as
quickly as possible. However, achieving high utilization dur-
ing ﬂow switching in practice requires precise control of ﬂow
transmission time. One could simplify this problem by as-
suming synchronized time among both switches and senders,
but that introduces additional cost and eﬀort to coordinate
clocks. PDQ addresses this problem by starting the next
set of waiting ﬂows slightly before the current sending ﬂows
ﬁnish.
Prioritizing Flows using FIFO Tail-drop Queues: One
fABottleneck Bandwidthtime35611/32/3fBfCBottleneck Bandwidthtime316fAfBfC1Bottleneck Bandwidthtime216fB4fA1/21fC128could implement priority queues in switches to approximate
ﬂow scheduling by enforcing packet priority.
Ideally, this
requires that each of the concurrent ﬂows has a unique pri-
ority class. However, a data center switch can have several
thousand active ﬂows within a one second bin [6], while mod-
ern switches support only ∼10 priority classes [20]. There-
fore, for today’s data center switches, the number of priority
classes per port is far below the requirements of such an ap-
proach, and it is unclear whether modifying switches to sup-
port a larger number of priority classes can be cost-eﬀective.
To solve this, PDQ explicitly controls the ﬂow sending rate
to regulate ﬂow traﬃc and retain packets from low-priority
ﬂows at senders. With this ﬂow pausing strategy, PDQ only
requires per-link FIFO tail-drop queues at switches.
3. PROTOCOL
We ﬁrst present an overview of our design. We then de-
scribe the design details implemented at the sender (§3.1),
receiver (§3.2) and switches (§3.3). This section assumes
each ﬂow uses a single path. In §6, we will show how PDQ
can be extended to support multipath forwarding.
Centralized Algorithm:
To clarify our approach, we
start by presenting it as an idealized centralized scheduler
with complete visibility of the network, able to communicate
with devices in the network with zero delay. To simplify ex-
position, the centralized scheduler assumes that ﬂows have
no deadlines, and our only goal is to optimize ﬂow comple-