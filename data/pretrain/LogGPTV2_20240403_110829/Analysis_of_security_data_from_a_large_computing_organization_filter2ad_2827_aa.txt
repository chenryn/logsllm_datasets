# Analysis of Security Data from a Large Computing Organization

**Authors:**
- Aashish Sharma
- Zbigniew Kalbarczyk
- James Barlow
- Ravishankar K. Iyer

**Affiliation:**
University of Illinois at Urbana-Champaign  
1308 Main St., Urbana, IL 61801, USA  
Email: {kalbarcz, jbarlow, rkiyer}@illinois.edu

## Abstract
This paper presents an in-depth study of forensic data on security incidents that occurred over a five-year period at the National Center for Supercomputing Applications (NCSA) at the University of Illinois. The proposed methodology combines automated analysis of data from security monitors and system logs with human expertise to extract and process relevant data. This approach aims to: (i) determine the progression of an attack, (ii) establish incident categories and characterize their severity, (iii) associate alerts with incidents, and (iv) identify incidents missed by monitoring tools and examine the reasons for these omissions. The analysis conducted provides a foundation for incident modeling and the design of new techniques for security monitoring.

**Keywords:** Incident/attack data analysis, security monitoring, alerts, large-scale computing systems.

## 1. Introduction
In this paper, we analyze security incidents that have occurred over a five-year period across 5,000 machines monitored at the NCSA. The monitored systems include:
- Eight high-performance computational clusters (each consisting of 2,000 to 12,000 processors) participating in grid computing and accessed by users worldwide.
- Smaller research clusters.
- Production infrastructure systems, such as mail, web, domain name, and authentication servers, and certification authorities.
- File servers (including NFS, AFS, GPFS, and Luster file systems).
- Over 1,000 desktops and laptops located in a class B (/16) network.

The target system has evolved over the years, and the analysis is an aggregate over the measurement period. The usage of the network studied is similar to other networks with heterogeneous sets of computing systems.

To illustrate the complexity of the target system, Figure 1 shows a section of a five-minute snapshot of traffic for systems within NCSA. The light-colored ovals represent IP addresses, and the lines correspond to network connections. Figure 2 shows the connections of a system involved in a security incident, with red ovals representing malicious IP addresses. These examples highlight the challenge of navigating through large volumes of traffic and data to identify compromised hosts and relevant information for a given attack.

Our goal is to understand how attacks progress as seen by monitoring tools and traces recorded in data logs. Reconstructing the attack steps—from an alert to a compromise—provides the foundation for categorizing security incidents and characterizing their severity. While the analysis of real security data is valuable, such studies are rare due to privacy issues and the difficulty in comprehending and correlating large quantities of multimodal data from various logs and alerting tools.

This paper makes an important step in overcoming these challenges by introducing and illustrating a methodology that combines automated analysis and human intervention. Specifically, the methodology extracts and processes relevant data from different logs to:
- Identify the progression of an attack.
- Associate alerts with incidents.
- Identify incidents missed by monitoring tools and analyze the reasons for these omissions.

### Key Findings
- Over half (57%) of incidents are detected by IDS-Bro (31%) and NetFlows (26%) monitors, while a significant fraction (27%) are not detected by any alert but identified by third-party external notifications.
- Almost 26% of the analyzed incidents involved credential stealing. In most cases (97%), attackers enter with already-stolen credentials, making their behavior similar to that of a malicious insider.
- Association of alerts with incidents reveals that usually one (or at most two) alert(s) is(are) responsible for identifying an incident, and the same alert can be triggered by different attacks.
- Nearly 50% of the incidents are detected in the last phase of an attack, when attackers start misusing the system.
- Anomaly-based detectors are seven times more likely to capture an incident than signature-based detectors, although the latter have fewer false positives.
- Alerts detecting the most incidents are not necessarily the most efficient; for example, the TopN alert detects 15% of low-to-medium severity incidents but has a 33% false positive rate.

Although this work focuses on the NCSA network, many of the analyzed incidents pertain to other campus or open research networks. In a fully closed environment, such as a corporate network with firewalls on the perimeter, the types of attacks and misuses may differ. However, a significant fraction (about 26%) of the incidents we analyzed are due to compromised credentials, which can occur in virtually any network accessible from the Internet or managed by an IT department within a corporation. Therefore, insights from this work are representative of many different environments and can guide the better design and organization of defense mechanisms.

## 2. Monitoring Tools
NCSA employs a variety of monitoring tools and corresponding detection techniques to provide comprehensive coverage. Figure 3 depicts the monitoring and alert generation architecture used to collect measurements at both the network and host layers.

### Network Layer
- **Bro IDS (www.bro-ids.org)**: Performs deep packet inspection of network traffic going through the border router to detect anomalous activity.
- **NetFlow Collectors**: Distributed to monitor and log network flows from the border router using Argus (www.qosient.com/argus/) and from internal routers using nfdump (sourceforge.net/projects/nfdump). These collectors provide visibility into traffic within internal subnets and traffic going in and out of the network.

### Host Layer
- **Syslog Data**: Collected by a central syslog collector with built-in redundancy for failsafe operation.
- **File Integrity Monitor (FIM)**: Samhain Labs (la-samhna.de/samhain) generates file change logs. The installation of FIMs and central syslog servers is limited due to performance and scalability concerns, but network monitoring can compensate for the selective deployment of FIMs to identify attacks and provide relevant forensic information.

### Additional Detection
- **Partner Sites and Security Mailing Groups**: Information gathered from partner sites, security mailing groups, or blacklists of malicious IP addresses provided by peers.
- **Anti-Virus and Anti-Malware Tools**: Deployed within the network but used primarily for post-incident investigation and cleanup rather than proactive alerting. High false positive rates and decentralized management are the primary reasons for not using these tools as primary alert mechanisms.

### Analyzers and Alerts
Data collected by all four monitoring tools (network-based: Bro IDS and NetFlow analyzers; host-based: syslog server and FIM) is analyzed for anomalies and signature matches. For example, Bro IDS alerts are generated when a protocol-based rule or policy is violated, such as a DNS query to/from a hostile domain or an internal host downloading a binary from a blacklisted URL. Custom policy rules are designed to monitor NCSA’s cluster based on network traffic characteristics. NetFlows trigger alerts based on predetermined network traffic characteristics, and the FIM watches for unauthorized modifications, creations, deletions, or permission changes in specified system files. A Simple Event Correlation engine (SEC) uses syslog data to generate alerts on anomalies based on rule sets, such as new user creation, user authentication, and command history profiles.

In addition to the generated alerts, data from all monitoring sources is archived for forensic analysis during specific attacks. The Security Team determines the response action warranted for the alerts generated by the monitoring tools. Some alerts result in proactive actions, such as sending reset packets to a scanned IP address. Other actionable alerts (determined to be true positives) are forwarded to the Incident Response and Security Team (IRST) for investigation and mitigation. At the end of every investigation, the Security Team performs an internal analysis to calibrate the monitoring tools based on the lessons learned.

While each monitoring tool provides important data, it is also limited in scope by its nature and deployment. A combination of these tools provides a comprehensive view of activity inside the network and the systems.

## 3. Security Implications of an Open Network Architecture
NCSA supports an open network architecture that ranges from high-performance scientific computations and web, email, and file servers to small research clusters and user desktops/laptops. Due to very high bandwidth requirements (support of multiple 10 Gb links), traditional firewall strategies are not sufficient for providing security protection. Researchers and operational staff are allowed to run their own flavors of operating systems and software, resulting in a highly heterogeneous computing environment. There is no mandatory software stack requirement for the systems except for certain production and critical infrastructure machines. Kernel upgrades are often delayed due to stringent dependency requirements of exclusive scientific and proprietary code and grid-based file systems (e.g., GPFS).

Furthermore, the Grid computing component of the NCSA network environment brings the challenge of having a broad base of users, each needing a way to authenticate to systems and with specific requirements for running jobs. The widespread user base often blurs network boundaries, and any successful adversarial action at NCSA may affect peer sites. Similarly, security breaches at peer sites directly affect the security state at NCSA. The NCSA security team has limited control over the security of end users’ computers, and different administrative boundaries for grid computing environments make it difficult to have a unified security policy that addresses local and grid-wide concerns.

## 4. Related Work
While many techniques to protect against attacks are available, little has been published on comprehensive measurement-based analysis of different types of attacks, from alerts to identifiable incidents. Databases like those provided by CERT (www.cert.org) and CVE (cve.mitre.org) document vulnerabilities and possible exploits, often used for analyzing and modeling vulnerabilities. For example, [21] uses data mining techniques to study traffic data during an attack for identifying signatures of intrusion detection; [4] uses vulnerability data to develop a finite-state machine model for analyzing vulnerabilities and attacks at the code level. [19] describes the analysis of a single denial-of-service attack on a server. Several studies [12], [13], [23] have analyzed attack data to build formal models involving both single and multiple nodes. 

Several authors have proposed models that correlate alerts to incidents. For instance, [10] proposes and verifies a capability-based model using real attack data, and [15] discusses prerequisites and consequences models. [22] views attacks as a set of capabilities that support abstract attack concepts, introduces a model for computer attacks, and a language for specifying the model, showing how it can be used in vulnerability analysis, intrusion detection, and attack generation.

Other sources that collect attack data include honeypot experiments and the DETERlab Testbed (www.isi.edu/deter). Red teams have often been used to collect network vulnerability data, though these data are generally unpublished. Several studies focus on the classification of security flaws, vulnerabilities, and attacks, such as [3], [14], and [5]. [17] describes an attack as a natural progression through seven unique phases, a classification we use in our analysis. The Bro team (bro-ids.org) has conducted extensive studies of attacks for developing monitoring tools. [24] is a comprehensive report on the analysis of security incidents between 1989 and 1995, but it does not concentrate on how incidents were detected. More recently, the Verizon Business RISK Team investigated 90 security breaches in 2009, encompassing 285 million compromised records [24]. This report also focuses on the effects of the incidents rather than their detection.

Modeling can be useful in understanding attack patterns and building more efficient protection mechanisms. For example, [4] introduces a finite state machine model methodology to analyze operations involved in exploiting application vulnerabilities and to identify the elementary activity level to foil an attack. More recently, [9] proposes a state machine-based attack model verified in an emulated environment using real security monitors. This approach is limited in scope, with an independent state machine built for each incident. [26] proposed a state machine model-based language to describe computer penetrations as sequences of actions an attacker performs to compromise a computer system.

## Figures
- **Figure 1**: Five-Minute Snapshot of In-and-Out Traffic within NCSA.
- **Figure 2**: Connections of a System Involved in a Security Incident.
- **Figure 3**: Monitoring Architecture Deployed at NCSA.

---

This revised version of the text is more organized, clear, and professional, with improved coherence and flow.