buffer capacity (Figure 6, top), several features stand out. First,
we note that because we keep the test short in order to not un-
duly load the user’s link, sometimes Netalyzr cannot completely
ﬁll the buffer, leading to noise, which also occurs when the band-
width is quite small (so we do not have a good “quiescence” base-
line). Next, horizontal banding reﬂects commonly provided levels
of service and/or access network characteristics (such as 802.11b
network speeds).
Most strikingly, we observe frequent instances of very large
buffers. Vertical bands reﬂect common buffer sizes, which we ﬁnd
fall into powers of two, particularly 128 KB or 256 KB. Even with
a fast 8 Mbps uplink, such buffers can easily induce 250 ms of ad-
ditional latency during ﬁle transfers, and for 1 Mbps uplinks, well
over 1 sec.
We can leverage the biases in our data to partially validate these
results. By examining only Comcast customers (Figure 6, bottom),
we would naturally expect only one or two buffer sizes to predom-
inate, due to more homogeneous hardware deployments—and in-
deed the plot shows dominant buffer sizes at 128 KB and 256 KB.
In this ﬁgure, another more subtle feature stands out with the small
cluster that lies along a diagonal. Its presence suggests that a small
7 A major reason for overly large buffers is the lack of device con-
ﬁgurability in the presence of a wide range of access-link band-
widths. For example, a DOCSIS cable modem designed to operate
with an uplink between 1 and 50 Mbps might have a buffer per-
fectly sized for 50 Mbps operation, yet 50 times too large for a
1 Mbps uplink.
253INTERFERENCE (%)
PROXIED
CLOSED
1.0
0.9
1.1
8.0
3.7
SERVICE
NetBIOS
SMB
RPC
SMTP
FTP
MSSQL
SNMP
BitTorrent
AuthSMTP
SecureIMAP
Netalyzr Echo
SIP
SecureSMTP
PPTP Control
DNS
IMAP/SSL
OpenVPN
TOR
POP3/SSL
IMAP
POP3
SSH
HTTPS
HTTP
PORT
139 T
445 T
135 T
25 T
21 T
1434 U
161 T
6881 T
587 T
585 T
1947 T
5060 T
465 T
1723 T
53 T
993 T
1194 T
9001 T
995 T
143 T
110 T
22 T
443 T
80 T
1KB
4KB
16KB
64KB
256KB
1MB
4MB
Inferred Buffer Capacity
BLOCKED
50.6
49.8
45.8
26.0
19.4
11.3
7.1
6.5
6.3
5.9
5.9
5.5
5.4
5.1
5.0
4.8
4.8
4.7
4.7
4.7
3.8
3.5
2.1
1.0
0.1
0.7
<0.1
<0.1
<0.1
<0.1
0.2
6.4
<0.1
<0.1
5.3
0.2
0.5
0.2
0.2
4.6
0.3
5.1
0.8
0.2
0.2
0.2
0.3
6.3
6.9
0.1
0.5
3.6
h
t
i
d
w
d
n
a
B
d
a
o
p
U
l
h
t
i
d
w
d
n
a
B
d
a
o
p
U
l
16Mb/s
4Mb/s
1Mb/s
256Kb/s
64Kb/s
16Kb/s
16Mb/s
4Mb/s
1Mb/s
256Kb/s
64Kb/s
16Kb/s
Table 1:
Reachability for services examined by Netalyzr.
“Blocked” reﬂects failure to connect to the servers, “Closed”
are cases where an in-path proxy or ﬁrewall terminated the es-
tablished connection after the request was sent. “Proxied” in-
dicates cases where a proxy revealed its presence through its
response. Omitted values reﬂect zero occurrences.
cluded some reordering. For downlink tests, 2% exhibited repli-
cation and 33% included reordering. The prevalence of reorder-
ing qualitatively matches considerably older results [2]; more di-
rect comparisons are difﬁcult because the inter-packet spacing in
our tests varies, and reordering rates fundamentally depend on this
spacing.
For the RELEASE data we also check for transient outages, de-
ﬁned as a period losing ≥ 3 background test packets (sent at 5 Hz)
in a row. We ﬁnd fairly frequent outages, with 10% of sessions
experiencing one or more such events (44% of these reﬂect only a
single outage event, while 29% included ≥ 5 loss events). These
bursts of packet loss are generally short, with 48% of sessions with
losses having outages ≤ 1 sec. 10% of wireless sessions exhibited
at least one outage, vs. only 5% for wired ones. (The wired/wireless
determination is here based on user feedback, per § 3.5.)
Finally, analysis of the server-side packet traces ﬁnds no in-
stances of TCP or IP checksum errors. We do see UDP checksum
errors at an overall rate of about 1.6 · 10−5, but these are heavily
dominated by bursts experienced by just a few systems. 0.12% of
UDP datagrams have checksumming disabled, likewise typically in
packet trains from individual systems, with no obvious commonal-
ity. The presence of UDP errors but not TCP might suggest use of
selective link-layer checksum schemes such as UDP Lite.
5.3 Service Reachability
Table 1 summarizes the prevalence of service reachability for
the application ports Netalyzr measures. As explained above, for
TCP services we can distinguish between blocking (no success-
ful connection), application-aware connectivity (established con-
nection terminated when our server’s reply violates the protocol),
and proxying (we directly observe altered requests/responses). For
1KB
4KB
16KB
64KB
256KB
1MB
4MB
Inferred Buffer Capacity
Figure 6:
Inferred upload packet-buffer capacity (x-axis) vs.
bandwidth (y-axis), for all sessions (top) and Comcast (bottom).
number of customers have access modems that size their buffers
directly in terms of time, rather than memory.
In both plots, the scattered values above 256 KB that lack any
particular power-of-two alignment suggest the possible existence
of other buffering processes in effect for large UDP transfers. For
example, we have observed that some of our notebook wireless
connections occasionally experience larger delays during this test
apparently because the notebook buffers packets at the wireless in-
terface (perhaps due to use of ARQ) to recover from wireless con-
gestion.
Clearly, over-buffering is endemic in access devices. Simply siz-
ing the active buffer dynamically, considering the queue full if the
head-of-line packet is more than 200 ms old, would alleviate this
problem substantially. While the task of ﬁxing millions of such de-
vices is daunting, one could also consider implementing Remote
Active Queue Management [1] elsewhere in the network in order
to mitigate the effects of these large buffers.
Packet Replication, Reordering, Outages, and Corruption.
The bandwidth tests also provide an opportunity to observe repli-
cation or reordering. For these tests, the bottleneck point receives
1000 B packets at up to 2x the maximum rate of the bottleneck.
1% of the uplink tests exhibited packet replication, while 16% in-
254UDP services we cannot in general distinguish the second case due
to the lack of explicit connection establishment.
The ﬁrst four entries likely reﬂect ISP security policies in terms
of limiting exposure to services well-known for vulnerabilities and
not signiﬁcantly used across the wide-area (ﬁrst three) or to prevent
spam. That the fraction of blocking appears low suggests that many
ISPs employ other methods to thwart spam, rather than wholesale
blocking of all SMTP.8
The prevalence of blocking and termination for FTP, however,
likely arises as an artifact of NAT usage: in order to support FTP’s
separate control and data connections, many NATs implement FTP
proxies. These presumably terminate our FTP probing when ob-
serving a protocol violation in the response from our server. A
NAT’s FTP proxy causes Netalyzr to report a “blocked” response
if the proxy checks the server’s response for FTP conformance be-
fore generating a SYN/ACK to the client, while it causes a “closed”
response if it completes the TCP handshake with the client before
terminating the connection after failing to validate the server’s re-
sponse format.
Somewhat
surprising is
the prevalence of blocking for
1434/udp, used by the Slammer worm of 2003. Likely these
blocks reﬂect legacy countermeasures that have remained in place
for years even though Slammer no longer poses a signiﬁcant threat.
The large fraction of terminated or proxied POP3 connections
appears due to in-host antivirus software that attempts to relay all
email requests. In particular, we can identify almost all of the prox-
ying as due to AVG antivirus because it alters the banner in the
POP3 dialog. We expect that the large number of terminated IMAP
connections has a similar explanation.
We found the prevalence of terminated SIP connections surpris-
ing. Apparently a number of NATs and Firewalls are SIP-aware and
take umbrage at our echo server’s protocol violation. We learned
that this blocking can even occur without the knowledge of the net-
work administrators—a Netalyzr run at a large university ﬂagged
the blockage, which came as a surprise to the operators, who re-
moved the restriction once we reported it.
Finally, services over TLS (particularly HTTPS, 443/tcp) are
generally unmolested in the network, as expected given the end-
to-end security properties that TLS provides. Thus, clearly if one
wishes to construct a network service resistant to network disrup-
tion, tunneling it over HTTPS should prove effective.
5.4 DNS Measurements
Selected DNS Server Properties. We measured several DNS
server properties of interest, including glue policy, IPv6 queries,
EDNS, and MTU. Regarding the ﬁrst, most resolvers behave con-
servatively, with only 21% of sessions accepting any glue records
present in the Additional ﬁeld, and those only doing so for records
for subdomains of the authoritative server. (The proportion is es-
sentially the same when weighted by distinct resolvers.) Similarly,
only 25% accept A records corresponding to CNAMEs contained
in the reply. On the other hand, resolvers much more readily (61%)
accept glue records when the glue records refer to authoritative
nameservers.
We ﬁnd 0x20 usage scarce amongst resolvers (2.3% of ses-
sions). However, only 4% removed capitalizations from requests,
which bodes well for 0x20’s deployability. Similarly, only a mi-
nuscule number of sessions incorrectly cached a 0-TTL record, and
none cached a 1 sec TTL record for two seconds.
We quite commonly observe requests for AAAA (IPv6) records
(13% of sessions), largely due to a common Linux default to re-
8Some ISPs publicly disclose that they use dynamic blocking [6].
quest AAAA records even if the host lacks a routable IPv6 address
rather than a resolver property, as 42% of sessions with a Linux-
related User-Agent requested AAAA records. (10% of non-Linux
systems requested AAAAs.)
The prevalence of EDNS and DNSSEC in requests is signiﬁ-
cant but not universal, due to BIND’s default behavior of request-
ing DNSSEC data in replies even in the absence of a conﬁgured
root of trust.9 52% of sessions used EDNS-aware DNS resolvers,
with 49% DNSSEC-enabled. Most cases where we observe an ad-