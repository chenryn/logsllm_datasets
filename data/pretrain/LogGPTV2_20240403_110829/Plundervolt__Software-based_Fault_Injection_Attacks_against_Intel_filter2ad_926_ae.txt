tographic algorithms, memory safety implications of faulty
instruction results have received comparatively little attention.
In the context of physically injected faults, Govindavajhala
et al. [20] demonstrated how a single-bit memory error can
be exploited to achieve code execution in the Java/.NET
VM, using a lightbulb to overheat the memory chip. Barbu
et al. [5] used laser fault injection to bypass a type check
on a Javacard and load a malicious applet afterwards. In the
context of software-based Rowhammer attacks, on the other
hand, Seaborn and Dullien [60] showed how to ﬂip operand
bits in x86 instruction streams to escape a Native Client
sandbox, and more recently Gruss et al. [21] ﬂipped opcode
bits to bypass authentication checks in a privileged victim
binary. While ﬂipping bits in instruction opcodes enables the
application control ﬂow to be illegally redirected, none of these
approaches directly produce incorrect computation results.
Furthermore, Rowhammer attacks originate outside the CPU
package and are hence fully mitigated through SGX’s memory
integrity protection [24], which reliably halts the system if an
integrity check fails [21, 38].
To the best of our knowledge, we are the ﬁrst to explore
the memory safety implications of faulty multiplications in
compiler-generated code. Compared to prior work [65] that
demonstrated frequency scaling fault injection attacks against
ARM TrustZone cryptographic implementations, we show that
undervolting is not exclusively a concern for cryptographic
algorithms. As explored in the following Section VII, this
observation has profound consequences for reasoning about
secure enclave code,
i.e., merely relying on fault-resistant
cryptographic primitives is insufﬁcient to protect against Plun-
dervolt adversaries at the software level.
While there is a long line of work on dismantling SGX’s
conﬁdentiality guarantees [69, 11, 46, 73, 50, 25, 72] as
well as exploiting classical memory safety vulnerabilities in
enclaves [45, 8, 70], Plundervolt represents the ﬁrst attack
that directly violates SGX’s integrity guarantees for func-
tionally correct enclave software. By directly breaking ISA-
level processor semantics, Plundervolt ultimately undermines
even relaxed “transparent enclaved execution” paradigms [66]
that solely require integrity of enclave computations while
assuming unbounded side-channel leakage.
The differences and ramiﬁcations of violating integrity
vs. conﬁdentiality guarantees for enclaved computations can
often be rather subtle. For instance, the authors of the Fore-
shadow [69] attack extracted enclave private sealing keys
(conﬁdentiality breach), which subsequently allowed an active
man-in-the-middle position to be established - enabling all
trafﬁc to be read and modiﬁed from an enclave (integrity
breach). Likewise, we showed that faulty multiplications or
encryptions can lead to unintended disclosure of enclave se-
crets. Our Launch Enclave application scenario of Section V-A
is another instance of the tension between conﬁdentiality
and integrity. That is, the aforementioned Foreshadow attack
showed how to bypass enclave launch control by extracting
the platform’s “launch key” needed to authenticate launch
tokens, whereas our attack intervened much more directly
with the integrity of the enclaved execution by faulting pointer
arithmetics and redirecting the trusted white list into attacker-
controlled memory.
VII. COUNTERMEASURES
In Intel SGX’s threat model, the operating system is con-
sidered untrusted. However, we showed that while an enclave
is running, privileged adversaries can manipulate MSR 0x150
and reliably fault in-enclave computations. Hence, counter-
measures cannot be implemented at the level of the untrusted
OS or in the untrusted runtime components. Instead,
two
possible approaches to mitigating Plundervolt are possible:
preventing unsafe undervolting directly at the level of the CPU
hardware and microcode, or hardening the trusted in-enclave
code itself against faults. Respective methods can be used
separately or—to increase the level of protection—in com-
bination, as is common practice for high-security embedded
devices like smartcards.
In the following, we ﬁrst overview potential approaches
to mitigate Plundervolt attacks at the hardware and software
levels. Next, we conclude this section by summarizing the
speciﬁc mitigation strategy adopted by Intel.
A. Hardware-Level and Microcode-Level Countermeasures
a) Disabling MSR Interface: Given the impact of our
ﬁndings, we recommend initiating SGX trusted computing
base recovery by applying microcode updates that completely
disable the software voltage scaling interface exposed via MSR
0x150. However, given the apparent complexity of dynamic
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:35 UTC from IEEE Xplore.  Restrictions apply. 
1476
voltage and frequency scaling functionality in modern Intel
x86 processors, we are concerned that this proposed solution
is still rather ad-hoc and does not cover the root cause for Plun-
dervolt. That is, other yet undiscovered vectors for software-
based fault injection through power and clock management
features might exist and would need to be disabled in a similar
manner.
Ultimately, even if all software-accessible interfaces have
been disabled, adversaries with physical access to the CPU are
also within Intel SGX’s threat model. Especially disturbing in
this respect is that the SerialVID bus between the CPU and
voltage regulator appear to be unauthenticated [30, 31]. Hence
adversaries might be able to physically connect to this bus and
overwrite the requested voltage directly at the hardware level.
Alternatively, advanced adversaries could even replace the
voltage regulator completely with a dedicated voltage glitcher
(although this may be technically non-trivial given the required
large currents).
b) Scaling Back Voltage during Enclave Operation:
Plundervolt relies on the property that CPU voltage changes
outside of enclave mode persist during enclave execution. A
straw man defense strategy could be to automatically scale
back any applied undervolting when the processor enters en-
clave mode. Interestingly, we noticed that Intel seems to have
already followed this path for its (considerably older) TXT
trusted computing extensions. In particular, the documentation
of the according SENTER instruction mentions that [36, 6-21]:
“Before loading and authentication of the target code module is
performed, the processor also checks that the current voltage and
bus ratio encodings correspond to known good values supportable by
the processor. [. . . ] the SENTER function will attempt to change the
voltage and bus ratio select controls in a processor-speciﬁc manner.”
However, we make the crucial observation that this defense
strategy does not sufﬁce to fully safeguard Intel SGX enclaves.
That is, in contrast to Intel TXT which transfers control to a
measured trusted environment, SGX features a more dynamic
design where attacker code and trusted enclaves are interfaced
at runtime. Hence, while one core is in enclave mode, another
physical core could attempt to trigger the undervolting for
the shared voltage plane in parallel after entering the victim
enclave. Therefore, such checks would need to be continuously
enforced every time any core is in enclave mode. This defense
strategy is further complicated by the observation that the time
between a write to MSR 0x150 and the actual voltage change
manifesting is relatively large (order of magnitude of 500k
TSC cycles, cf. Fig. 2). Therefore, removing and restoring
undervolting on each enclave entry and exit would likely add
a substantial overhead.
c) Limiting to Known Good Values: Even slightly under-
volting the CPU creates signiﬁcant power and heat reductions;
properties that are highly desirable in data centers, for mobile
computing and for other end user applications like gaming.
Completely removing this feature might
incur substantial
limitations in practice. As an alternative solution, the exposed
software interface could be adjusted to limit the amount of
permitted undervolting to known “safe” values whitelisted
by the processor. However, this mitigation strategy is fur-
ther complicated by our observations that safe voltage levels
depend on the current operating frequency and temperature
and may even differ between CPUs of the same model (cf.
Section III-A). Hence, establishing such safe values would
require a substantial amount of additional per-chip testing at
each frequency. Even then, circuit-aging effects can affect safe
values as the processor gets older [40].
d) Multi-variant Enclave Execution: A perpendicular ap-
proach, instead of trying to prevent undervolting faults directly,
would be to modify processors to reliably detect faulty compu-
tation results. Such a defense may, for instance, leverage ideas
from multi-variant execution [28, 76, 43] software hardening
techniques. Speciﬁcally: processors could execute enclaved
computations twice in parallel on two different cores and halt
once the executions diverge. To limit the performance penalty
of such an approach, we propose leveraging commodity Hy-
perThreading [36] features in Intel CPUs and turn them from
a security concern into a security feature for fault resistancy.
After a long list of SGX attacks [69, 75, 59, 50] demonstrated
how enclave secrets can be reconstructed from a sibling CPU
core, Intel ofﬁcially recommended disabling hyperthreading
when using SGX enclaves [32]. However, this also imposes a
signiﬁcant performance impact on any non-SGX workloads.
injection attacks is re-
dundancy [4], either in hardware, by duplicating potentially
targeted circuits, or in software by duplicating potentially tar-
geted parts of the instruction stream, and frequently checking
for mismatches in both cases. For instance, Oh et al. [52]
and later Reis et al. [56] proposed duplicating the instruction
stream to produce software that is tolerant against hardware-
induced faults. In the case of SGX, such a solution might also
be applied at the microarchitectural level. The processor would
simply run the duplicated instructions in parallel on the two
hyperthreads of a core. Faults would be reliably detected if the
probability that the attacker induced the exact same fault in two
immediately subsequent executions of the same instructions is
signiﬁcantly lower than the probability of observing a single
fault at some point in time.
A well known solution to fault
B. Software-Level Hardening
a) Fault-Resistant Cryptographic Primitives: There is a
large body of work regarding fault injection countermeasures
for cryptographic algorithms,
including (generic) temporal
and/or spatial redundancy [26] and algorithm-speciﬁc ap-
proaches such as performing the inverse operation or more
advanced techniques like ineffective computation [19].
For the example of RSA-CRT signature/decryption (cf.
Section IV-B), the result could be veriﬁed before outputting by
performing a (in the case of RSA with small public exponent)
cheap signature veriﬁcation/encryption operation. Indeed, such
a check is present by default in some cryptographic libraries,
e.g., mbedtls. However, for the Intel SGX-SDK this might
require changes to the API speciﬁcation of tcrypto, as the
public key is currently not supplied as a parameter to private
key operations.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:04:35 UTC from IEEE Xplore.  Restrictions apply. 
1477
For AES-NI (cf. Section IV-C), an encryption operation
could be followed by a decryption to verify that the plaintext
remains unchanged. However,
this would incur substantial
performance overhead, doubling the runtime of an encryption.
Trade-offs like storing the intermediate state after k rounds
and then only performing 10 − k inverse rounds (for AES-
128) can defeat DFA but might still be susceptible to statistical
attacks [18].
b) Application and Compiler Hardening: It is important
to note that SGX supports general-purpose, non-cryptographic
code that can also be successfully exploited with Plundervolt,
as demonstrated in Section V. To further complicate matters,
typical enclave runtime libraries contain numerous, potentially
exploitable mul and imul instructions. For instance, we
found that the trusted runtime code for a minimalistic enclave
using the Intel SGX-SDK [35] contains 23 multiplications,
with many in standard library functions like free(). For
comparison, the trusted runtime part of Microsoft’s OpenEn-
clave SDK [48] contains 203 multiplications, while Graphene-
SGX’s [67] libpal-Linux-SGX.so features 71 mul/imul
instructions.
Certain standard library functions like calloc() could be
hardened manually by inserting checks for the correctness of a
multiplication, e.g., through a subsequent division, as already
implemented in the Intel SGX-SDK (see Section V-B). How-
ever, in functions where many “faultable” multiplications are
being used (e.g., public-key cryptography, signal processing,
or machine learning algorithms), this would incur signiﬁcant
overhead. Furthermore, each case of a problematic instruction
needs to be analyzed separately, often at the assembly level
to understand the exact consequences of a successful fault
injection. Finally,
it should be noted that while we have
focused on multiplications in our analysis, defenses should
also take into account the possibility of faulting other high-
latency instructions.
c) Traditional Memory Safety Hardening: As a ﬁnal
consideration, we recommend applying more general counter-
measures known from traditional memory safety application
hardening [16] in an enclave setting. One approach to hinder
Plundervolt-induced memory safety exploitation would be to
randomize the enclave memory layout using systems like
SGX-Shield [61]. Yet, it is important to note that these tech-
niques can only raise the bar for actual exploitation, without
removing the actual root cause of the attack.
users will receive a ‘CONFIGURATION NEEDED’ message from
platforms that do not disable the overclocking mailbox interface.”
We note that Intel’s strategy to disable MSR 0x150 (i.e.,
said “mailbox interface”) corresponds to our recommended
mitigation outlined in Section VII-A. However, this strategy
may not cover the root cause for Plundervolt. Other, yet
undiscovered, avenues for fault injection through power and
clock management features might exist (and would have to
be disabled in a similar manner). Finally, we want to stress
that, similiar to previous high-proﬁle SGX attacks like Fore-
shadow [69], Intel’s mitigation plan for Plundervolt requires
trusted computing base recovery [1, 14]. That is, after the
microcode update, different sealing and attestation keys will be
derived depending on whether or not the undervolting interface
at MSR 0x150 has been disabled at boot time. This allows
remote veriﬁers to re-establish trust after resealing all existing
enclave secrets with the new key material.
VIII. CONCLUSION
In this paper we have identiﬁed a new, powerful attack
surface of Intel SGX. We have shown how voltage scaling can
be reliably abused by privileged adversaries to corrupt both
integrity and conﬁdentiality of SGX enclaved computations.
To the best of our knowledge, this represents the ﬁrst practical
attack that directly breaches the integrity guarantees in the
Intel SGX security architecture. We have proven that this
attack vector is realistic and practical with full key recovery
PoC attacks against RSA-CRT and AES-NI. Furthermore, we
have provided evidence that other micro-instructions can be
faulted as well. Some of these instructions, like EGETKEY
and EREPORT, are the basic building blocks that underpin the
security of the whole SGX ecosystem.
We have shown that Plundervolt attacks are not limited to
cryptographic primitives, but also enable more subtle memory
safety violations. We have exploited multiplication faults in
fundamental programming constructs such as array indexing,
and shown their relevance for widespread memory allocation
functionality in Intel SGX-SDK edger8r-generated code and
in the SGX-LKL runtime. In conclusion, our work provides
further evidence that the enclaved execution promise of out-
sourcing sensitive computations to untrusted remote platforms
creates new and unexpected attack surfaces that continue to
be relevant and need to be studied further.
C. Intel’s Mitigation Plan
ACKNOWLEDGMENTS
Following the responsible disclosure, Intel’s Product Secu-
rity Incident Response Team informed us of their mitigation
plans with the following statement:
“After carefully reviewing the CPU voltage setting modiﬁcation, Intel
is mitigating the issue in two parts, a BIOS patch to disable the
overclocking mailbox interface conﬁguration. Secondly, a microcode
update will be released that reﬂects the mailbox enablement status
as part of SGX TCB [Trusted Computing Base] attestation. The
Intel Attestation Service (IAS) and the Platform Certiﬁcate Retrieval
Service will be updated with new keys in due course. The IAS
This research is partially funded by the Research Fund KU
Leuven, and by the Agency for Innovation and Entrepreneur-
ship (Flanders). Jo Van Bulck is supported by a grant of
the Research Foundation – Flanders (FWO). This research