Simpliﬁcation A simpliﬁcation nudge promotes building
upon existing and established infrastructures and programs.
We apply this nudge by integrating our system in Stack Over-
ﬂow, a platform that is already used by the majority of soft-
ware developers worldwide. By integrating developer tools
on a platform that is already used by almost everyone, we
unburden developers from installing additional tools. More-
over, it allows us to create awareness of the problem of cryp-
tographic misuse in general.
Warnings A warning nudge aims at raising the user’s at-
tention in order to counteract the natural human tendency
towards unrealistic optimism [5]. We apply this nudge by in-
tegrating security warnings on Stack Overﬂow. Whenever an
insecure code example has been detected, a warning is dis-
played to the developer to inform about the security problem
and potential risks in reusing the code sample.
Increases in Ease and Convenience (IEC) Research has
also shown that users oftentimes discount security warnings.
However, if they additionally describe available alternative
options to make a less risky decision, warnings tend to be
much more effective [5]. Therefore, our design combines se-
curity warnings with recommendations for similar code ex-
amples with strong cryptography. With this nudge, we make
code examples with better security visible to the user. To
provide an easy choice, we present the recommended code
examples by displaying a list of the related posts. This aims
at encouraging the user to consider the recommendations as
it only demands clicking on a link.
Reminders Users might not engage in the expected con-
duct of paying attention to the warning and following the
recommendations. This might be due to inertia, procrastina-
tion, competing priorities, and simple forgetfulness [5]. Of-
tentimes seeking functional solutions is considered as a com-
peting priority to secure solutions [2]. Therefore, we apply a
reminder nudge, which is triggered whenever the user copies
an insecure code example.
Defaults The default nudge is the most popular and
effective nudge in improving decision-making.
Popular
in healthcare plans
examples are automated enrollment
The goal of our approach is to thoughtfully develop a
new user interface (UI) design that implements the proposed
nudges (see Section 6) and to test whether it improves de-
veloper behavior on Stack Overﬂow. Please note that we do
not intend to comparatively evaluate multiple UI candidates
for our design patterns to identify the most effective one. We
consider this out of scope for this paper and leave this task
for future work.
5 Neural Network-Based Learning of Crypto-
graphic Use Cases and Security
The nudge-based system design requires algorithmic deci-
sions about the security and similarity of code examples. In
order to display security warnings, code examples have to be
scanned for encryption ﬂaws. To further recommend help-
ful alternatives without common encryption problems, Stack
Overﬂow posts have to be scanned for similar examples with
strong cryptography.
Due to Simpliﬁcation (see Section 4), we already chose
a platform that provides us with a large amount of secure
and insecure samples that contain cryptographic API usage
patterns to learn from in order to design the code analysis
approach [17].
Instead of deﬁning rule-based algorithms
[12, 13, 20] that would have to be updated whenever sam-
ples with unknown patterns are added to Stack Overﬂow, we
simplify and increase the ﬂexibility of our system by apply-
ing deep learning to automatically learn the similarity, use-
case and security features from the ever-increasing dataset
of available code on Stack Overﬂow. Based on the learned
features, our models are able to predict insecure code exam-
ples and similar but secure alternatives that serve the same
use case. However, newly added code examples that provide
unknown use cases and security ﬂaws might be underrepre-
sented in the data and therefore difﬁcult to learn. Therefore,
we apply transfer learning where we reuse already obtained
knowledge that facilitates learning from a small sample set
of a similar domain.
5.1 Cryptographic Use Cases
Stack Overﬂow offers a valuable source for common use
cases of cryptographic APIs in Android. As developers post
questions whenever they have a particular problem with an
API, a collection of error-prone or difﬁcult cryptographic
problems is aggregating over time. Moreover, frequen-
cies of similar posted questions, view counts, and scores of
questions posted on Stack Overﬂow indicate very common
and important problems developers encounter when writing
342    28th USENIX Security Symposium
USENIX Association
(a) Example for an insecure pattern: The initialization vector (IV) is created from a
static string value stored in the code.
(b) Example for a secure pattern: A secure random source is used to generate the IV.
Figure 2: Example for a secure and insecure usage pattern of new IvParameterSpec. It shows the program dependency graph
(PDG) of the 5-hop neighborhood of the seed statement s1 for the secure and insecure code example displayed in (a) and (b).
Next to each node in the graph we provide the shortened signature of the related statement, highlighting a subset of its attributes
we store in the feature vector. Bytecode instruction types are highlighted yellow, Java types blue and constants magenta.
security-related code. Therefore, Stack Overﬂow can be seen
as a dataset of different cryptographic use cases that are fre-
quently required in production code. Previous work iden-
tiﬁed the most popular and error-prone use cases of cryp-
tography in Android apps [17]. The authors scanned Stack
Overﬂow for insecure code examples that use popular cryp-
tographic APIs, e g. Oracle’s Java Cryptography Architec-
ture (JCA), and detected their reuse in Android applications.
We summarize the identiﬁed use cases in Table 1.
Use Case
Identiﬁer
Cipher
Key
IV
Hash
TLS
HNV
HNVOR
TM
Usage Pattern
Description
Initialization of cipher, mode and
padding
Generation of symmetric key
Generation of initialization
vector
Initialization of cryptographic
hash function
Initialization of TLS protocol
Setting the hostname veriﬁer
Overriding the hostname veriﬁcation
Overriding server
certiﬁcate veriﬁcation
API
Seed Statement
Cipher.getInstance
new SecretKeySpec
new IvParameterSpec
MessageDigest.
getInstance
SSLContext.getInstance
setHostnameVeriﬁer
verify
checkServerTrusted
Table 1: Common cryptographic use cases in Android
5.2 Learning API Usage Patterns
In order to predict similarity, use case and security of encryp-
tion code, we need to learn a numerical representation of the
related patterns that can be understood by a neural network.
Therefore, our ﬁrst step is learning an embedding of crypto-
graphic API usage patterns.
Usage Pattern As shown in Table 1, a cryptographic API
element, e. g., javax.crypto.Cipher.getInstance, can have dif-
ferent usage patterns that belong to the same use case. A
usage pattern consists of a particular API element, all state-
ments it depends on, and all its dependent statements within
the given code. In other words, a pattern can be seen as a sub-
graph of the PDG, which represents the control and data de-
pendencies of statements. The subgraph is created by prun-
ing the graph from anything but the forward and backward
slices of the API element, as shown in Figure 2. We call this
element the seed statement. This pruned graph can become
very large and therefore might contain noise with respect to
the identiﬁcation of patterns. Our goal is to learn an optimal
representation of usage patterns that allows accurate classiﬁ-
cation of their use cases and security. Ideally, the related sub-
graph is minimized to a neighborhood of the seed statement
in the pruned PDG such that it provides enough information
to solve the classiﬁcation tasks.
Neighborhood Aggregation Our approach learns pattern
embeddings for the K-hop neighborhood of cryptographic
API elements within the PDG, as shown in Figure 2.
To generate these embeddings we use the neighborhood-
aggregation algorithm provided by Structure2vec [11]. This
method leverages node features (e. g., instruction types of a
statement node) and graph statistics (e. g., node degrees) to
USENIX Association
28th USENIX Security Symposium    343
invokestaticnew invokespecial([B)V >invokespecial()V >returnnewnew s0s5s4s3s2s1s6invokevirtual new  invokespecial  s9s8s7Insecure PatternSecure PatternSeedStatement5-hop Neigbourhoodinform their embeddings. It provides a convolutional method
that represents a node as a function of its surrounding neigh-
borhood. The parameter K allows us to search for a neigh-
borhood that optimally represents usage patterns to solve
given classiﬁcation tasks. In other words, we learn the code
representation in a way such that its features improve use
case and security prediction of the code. As we will show
throughout this work, this representation is very helpful for
classifying cryptographic API usage patterns. We further ar-
gue that the learned pattern representation is not restricted
to cryptographic APIs, as the used features are general code
graph properties.
Neighborhood Similarity We learn pattern embeddings
such that similar patterns have similar embeddings by min-
imizing their distance in the embedding space. Therefore,
next to the neighborhood information, pattern embeddings
additionally encode their similarity information. On the one
hand, this allows us to apply efﬁcient and accurate search for
similar usage patterns on Stack Overﬂow [33]. On the other
hand, we can transfer knowledge from the similarity domain
to the use case and security domain. This knowledge trans-
fer is leveraged by our use case and security classiﬁcation
models.
Code similarity is very helpful to predict code security.
Therefore, we expect that the similarity feature of our pat-
tern embeddings will improve the accuracy and efﬁciency of
the security classiﬁcation model. However, code similarity
is oftentimes not enough for predicting security. Therefore,
the main effort of our classiﬁcation models lies in learning
the additional unknown conditions where code similarity be-
comes insufﬁcient.
To learn our embeddings, we apply a modiﬁed architecture
of the graph embedding network Gemini [33].
5.3 Feature Engineering
The embedding network should learn a pattern embedding
that is general enough to allow several classiﬁcation tasks.
This means that the embedding has to be learned from gen-
eral code features or attributes, e. g., statistical and structural
features [33] from each statement within the PDG represen-
tation of the code. Further, pattern embeddings should repre-
sent very small neighborhoods. As we want to minimize the
neighborhood size K, patterns might consist only of a few
lines of code. Therefore, considering only graph statistics
as features might not be sufﬁcient and may result in similar
features for dissimilar patterns. In order to overcome these
insufﬁciencies, we additionally combine structural and sta-
tistical with lexical and numerical features for each statement
in a neighborhood.
Structure and Statistics We ﬁrst create the PDG of the
given input program using WALA3, a static analysis frame-
work for Java. Note that WALA creates a PDG for each Java
method. Then, we extract the resulting statistical and struc-
tural features for each statement. We store the bytecode in-
struction type of a statement using a one-hot indicator vector.
Additionally, we store the count of string and numerical con-
stants that are used by the statement. We further add struc-
tural features by storing the offspring count and node degree
of a statement in the PDG [33]. Finally, we store the indexes
of the statement’s direct neighbors in the graph.
Element Names and String Constants Method and ﬁeld
names of APIs are strings and have to be transformed into a
numerical representation ﬁrst. We learn feature vectors for
these tokens by training a simple unsupervised neural net-
work to predict the Java type that deﬁnes the given method or
ﬁeld name. Thereby, each name is represented in a one-hot
encoding vector with dimension 23,545, corresponding to
the number of unique element names provided by the cryp-
tographic APIs [17]. To learn features, we use a network ar-
chitecture with one hidden layer and apply categorical cross-
entropy as a loss function during training. Finally, we apply
the trained model on all names and extract the neurons of the
hidden layer as they can be seen as learned features necessary
to solve the classiﬁcation task. This way, each name obtains
a unique feature vector which preserves its type information.
We use the same approach for learning feature vectors for
the 763 unique string constants given by the APIs.
5.4 Pattern Embedding Network
Many code examples on Stack Overﬂow typically do not pro-
vide sound programs as they mostly consist of loose code
parts [17]. In contrast to complete programs, compiling these
partial programs might introduce multiple types of ambi-
guities in the resulting PDG such that the extracted state-
ment features xu are not sound [10]. Whenever we generate
sound and unsound features xs, xu from a complete and a par-
tial program, respectively, that provide the same usage pat-
tern for a given seed statement, both sets of feature vectors
extracted from the patterns might be different. Therefore,
we need to learn a representation for patterns that preserves
their similarity properties independently from the shape of
the containing program. With a Siamese network architec-
ture [33], we can learn similar pattern embeddings indepen-
dently from the completeness of the code example. It learns
embeddings from similar and dissimilar input pairs. We cre-
ate similar input pairs by extracting sound and unsound fea-
tures for the same pattern and dissimilar pairs by extract-
ing sound and unsound features from different patterns. The
3https://github.com/wala/WALA
344    28th USENIX Security Symposium
USENIX Association
Algorithm 1 Neighborhood-aggregation algorithm
Input: PDG G(V,E) input features {xv,∀v ∈ V};
Output: Pattern embedding pv,∀v ∈ V
1: φ 0
v ← 0,∀v ∈ V ,
2: for k = 1...K do
for v ∈ V do
3:
4:
,∀n ∈ N(v))
5:
φ k
N(v) ← AGGREGAT E(φ k−1
φ k
v ← tanh(W1xv · σ (φ k
v ,∀v ∈ V}
n
N(v))
return {pv = W2φ K
trained model will then generate similar embeddings inde-
pendently from the completeness of the program.
n
The pattern embeddings are generated with Structure2vec
as depicted in Algorithm 1. We provide the abstract descrip-
tion of the algorithm and refer to Gemini’s neural network
architecture that gives information about its implementation,
which we use as the basis for our approach. The update func-
tion calculates a pattern embedding pv for each feature vec-
tor xv of statements (i. e., nodes) v ∈ V in the PDG G(V,E).
An embedding pv is generated by recursively aggregating
previously generated embeddings {φ k−1
,∀n ∈ N(v)} of di-
rect neighbors N(v) in the graph, combining it with the
weighted feature vector xv. Unlike Gemini, which outputs
an aggregation of pv to return an embedding for the com-
plete graph, our network returns the set of pattern embed-
dings P = {pv,∀v ∈ V}.
We give an overview of the pattern embedding network in
Figure 3. Here, the insecure pattern G(x3,x4,x5,E) informs
the embedding of its direct neighbors in each iteration step,
ﬁnally informing the seed statement in iteration k = 2. Af-