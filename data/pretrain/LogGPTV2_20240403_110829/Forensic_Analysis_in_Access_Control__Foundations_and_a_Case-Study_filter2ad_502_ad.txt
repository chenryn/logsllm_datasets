### Case Analysis

#### Case 1: Single Rule Change (No Split Required)
- **T1, GET, /proj/1.htm DENY**
- **T2, GET, /proj/1.htm ALLOW**
- **T3, GET, /proj/2.htm DENY**
- **T4, GET, /proj/2.htm ALLOW**

#### Case 2: Multiple Rule Changes (Split Required)
- **T1, GET, /proj/1.htm DENY**
- **T2, GET, /proj/2.htm DENY**
- **T3, GET, /proj/1.htm ALLOW**
- **T4, GET, /proj/2.htm ALLOW**

### Policy Change and Access Log Subset
- **GET, /proj/1.htm DENY → ALLOW**
- **GET, /proj/2.htm DENY → ALLOW**

### Purity Metrics
- **pallow: 0.5, pdeny: 0.5**
- **Gini Impurity: 0.5**
- **Entropy: 1**
- **ChangeCount: 3**

### If Not Split
- **pallow: 0.5, pdeny: 0.5**
- **Gini Impurity: 0.5**
- **Entropy: 1**
- **ChangeCount: 3**

### If Split
- **Condition: if prefix2 == "/proj/1.htm"**
- **pallow_left: 0.5, pallow_right: 0.5**
- **Gini Impurity: 0.5**
- **Entropy: 1**
- **ChangeCount: 0**

### Figure 8: Example of TCDT Learning Algorithm
- **Description**: This example demonstrates that the TCDT learning algorithm can infer rules even when there is no rule change. In this case, a splitting is required on the condition: `if prefix2 == "/proj/1.htm"`. The time-series change count favors this splitting as the change count decreases from 3 to 0 after splitting.

## 9. Use Cases
P-DIFF supports two use cases: change validation and forensic diagnosis, based on its TCDT-based access control policy learning described in Sections 6–8. This section details how the learned TCDT can be used to support these use cases.

### 9.1. Change Validation
P-DIFF continuously monitors new access results from the access logs. For each access, P-DIFF calculates the expected access result (ALLOW or DENY) based on the policy maintained in the TCDT. If the observed access result deviates from the expected result, P-DIFF treats it as a potential policy change and notifies the system administrators (sysadmins) with the changed access control rules for validation. If the sysadmins confirm the change, P-DIFF updates the TCDT. Otherwise, P-DIFF detects an access control misconfiguration, discards the access result, and continues monitoring.

**Example**:
- **Timestamp T5, PUT, /proj/1.htm ALLOW**
- **Expected Result (based on TCDT): DENY**
- **Actual Result (from access log): ALLOW**
- **Action**: Notify sysadmins for validation.

### 9.2. Forensic Analysis
Given an access of interest (e.g., an illegal access that steals confidential information), P-DIFF can pinpoint the policy change that permitted the access by searching the policy evolution history maintained in the TCDT. This is achieved by finding the path in the TCDT that determines the access result and backtracking through the time series to find the root-cause policy change.

**Example**:
- **Target Access at T4, GET, /proj/1.htm ALLOW**
- **Action**: Backtrack through the TCDT to find the root-cause policy change between T2 and T3.

Note that forensic analysis can be performed in real-time or postmortem using historical access logs to build the TCDT.

## 10. Evaluation
We evaluate P-DIFF using controlled experiments based on datasets collected from five real-world deployments, including the Wikipedia website, a software company's firewall, and three websites hosted by academic organizations. Table 4 describes these datasets.

### 10.1. Systems and Datasets
- **Wikipedia**: A free online encyclopedia with 33 million registered users. Access logs are collected from a public dataset of request traces in September 2007.
- **Center**: A web server hosting home pages and personal pages for a research center with more than 10 faculty members and 50 graduate students.
- **Course**: A department-wide course website hosting 300+ courses each year.
- **Company**: An Iptable firewall deployed by a software company serving millions of users.
- **Group**: A website hosting group pages and personal pages for a research group with more than 20 researchers.

### 10.2. Experimental Design
To evaluate P-DIFF, we need:
1. Access logs recording access requests and results.
2. Ground truth access control policy changes.

For the Wikipedia dataset, policy changes are obtained from the page protection change history. For other datasets, we randomly generate policy changes and synthesize access results. We generate different types of policy changes to cover various scenarios, including file permissions, user access, and method access.

### 10.3. Overall Results
#### 10.3.1. Change Validation
We evaluate P-DIFF’s effectiveness in detecting policy changes by dividing the access logs into training and testing parts. Table 6 shows the number and percentage of policy changes detected by P-DIFF, with a high detection rate and low false positives and negatives.

#### 10.3.2. Forensic Analysis
To evaluate forensic analysis, we select an access of interest after each policy change. P-DIFF pinpoints the root-cause policy change for 283 (93%) out of 303 accesses of interest, demonstrating its effectiveness.

### Table 4: Datasets Used in Our Evaluation
| Time Span | # Access | Dataset | Configuration |
|-----------|----------|---------|---------------|
| 2 weeks   | 369M     | Wikipedia | Application logic |
| 11 months | 5.9M     | Center    | Web server configuration |
| 11 months | 3.8M     | Course    | File permission |
| 1 month   | 100K     | Company   | Firewall |
| 3 hours   | 32K      | Group     | File permission |

### Table 5: Different Types of Access Control Policy Changes
| Category | Change Types (# Changes) | Dataset Applied |
|----------|--------------------------|-----------------|
| File Permission | Type 1: allow file access (15) | Course, Group, Center, Company |
|               | Type 2: block file access (15) | Course, Group, Center, Company |
|               | Type 3: allow directory access (15) | Course, Group, Center, Company |
|               | Type 4: block directory access (15) | Course, Group, Center, Company |
| Web Server | Type 5: allow user access (15) | Course, Group, Center, Company |
|            | Type 6: block user access (15) | Course, Group, Center, Company |
| ACL | Type 7: allow GET/PUT method (15) | Course, Group, Center, Company |
|     | Type 8: block GET/PUT method (15) | Course, Group, Center, Company |
| Iptable | Type 9: allow ip access (15) | Course, Group, Center, Company |
|        | Type 10: block ip access (15) | Course, Group, Center, Company |
|        | Type 11: allow subnet (15) | Course, Group, Center, Company |
|        | Type 12: block subnet (15) | Course, Group, Center, Company |

### Table 6: Policy Changes Detected by P-DIFF
| Dataset | # Total Changes | # Detected Changes | Precision | Recall (FN) | False Positives (FP) |
|---------|-----------------|--------------------|-----------|-------------|----------------------|
| Wikipedia | 25 | 25 (100%) | 1.0 (0) | 1.0 (0) | 0.76 (5) |
| Center | 18 | 16 (89%) | 0.89 (2) | 0.94 (1) | 0.85 (3) |
| Course | 18 | 17 (94%) | 0.86 (3) | 1.0 (0) | 0.81 (4) |
| Company | 21 | 18 (86%) | 1.0 (0) | 1.0 (0) | 1.0 (0) |
| Group | 17 | 17 (100%) | 0.94 (6) | 1.0 (0) | 0.89 (12) |
| Total | 99 | 93 (94%) | 0.94 (6) | 0.94 (6) | 0.89 (12) |

### Table 7: Forensic Analysis Results
| Dataset | # Access of Interest | Pinpointing Root-Cause Changes |
|---------|----------------------|--------------------------------|
| Wikipedia | 63 | 61 (97%) |
| Center | 60 | 53 (88%) |
| Course | 60 | 59 (98%) |
| Company | 60 | 59 (98%) |
| Group | 60 | 51 (85%) |
| Total | 303 | 283 (93%) |

This structured and detailed approach ensures clarity, coherence, and professionalism in the text.