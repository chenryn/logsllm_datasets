# Optimized Text

## Figure 12: Graph showing how errors injected into the register file propagate through the system.

### Calculations and Register Checkpoints
While the register checkpoints in our current work store more state than in our prior work [8], we have implemented this in an area-neutral way by reducing the number of entries stored. This adjustment is reflected in our performance numbers.

### Fault Injection Study
ParaMedic re-executes all computations performed by the main core on checker cores, capturing all observable errors that dual-core lockstep would detect. The key difference is that computation may be checked in a different order due to the exploitation of parallelism. 

At the end of each segment, the manifestation of errors may differ from dual-core lockstep. In lockstep, these errors would appear at the retirement of an instruction, and in other sequential error detection mechanisms [15], [4], [16], they would either affect a future load or store, or be masked entirely. In contrast, ParaMedic requires additional checks on register files to ensure continuity between parallel checked segments. Figure 12 illustrates this by injecting a random bit error in a random integer register at the start of each checkpoint, tracking the error's propagation. We observe that errors are distributed among load addresses, store addresses, data, and register files. Up to half of all injected errors in the register file do not affect the resulting computation because they occur in registers that are never used by the application and are overwritten before the checkpoint is completed.

### Summary
For single-threaded code without shared memory, the extra slowdown from error correction is minimal, at just 2.0% compared to 1.9% for error detection. When shared memory is introduced, mandating communication limitations to prevent data escape from the L1 cache before it is committed using timestamps, the overhead increases to 4.6%. However, this can be reduced to 3.1% by dynamically scaling the size of timestamps using an additive-increase-multiplicative-decrease (AIMD) scheme, thereby reducing cache capacity evictions from unchecked data. For multithreaded code, the pattern is similar: overheads of 1% for error detection increase to 1.5% for correction.

ParaMedic rolls back speculative execution in the presence of errors, making it comparable to transactional-memory systems [12]. Error propagation can be seen as akin to conflict detection, both within-core to subsequent checkpoints and out-of-core when errors may propagate due to shared memory. There are clear and necessary implementation differences between our technique and typical hardware transactional-memory (HTM) schemes. Most real-world HTM implementations are best-effort [12], meaning forward progress is not guaranteed. Our error correction solution, in transactional-memory terms, is an eager versioning, optimistic conflict-detecting system up until the L1, and a lazy versioning, pessimistic conflict-detecting system between cores [30].

We disallow uncommitted data to leave the L1 and prevent the sharing of uncommitted data between cores, effectively making the transaction policy between cores a lazy versioning, pessimistic conflict-detection system. This makes rollback easier by avoiding error propagation. A more optimistic solution might let potential errors propagate and detect them at commit time, but this would be significantly more complicated from a verification and protocol perspective.

### Related Work
A wide design space exists for providing processor fault tolerance, with the main categories being hardware redundancy, software redundancy, and heterogeneous redundancy.

#### Hardware Redundancy
Hardware-only redundancy can be categorized as space-based and time-based. Space-based schemes, such as lockstepping, duplicate hardware for redundancy. Lockstepping is used in ARM’s Cortex-R series [14] and other commercial designs like the IBM G5 [31] and Compaq Himalaya [32]. Time-based schemes run the same code on the same hardware at different times, often with hardware support to forward loads and stores between two threads. AR-SMT [15] is an example of a time-based redundant-multithreading scheme. With ParaMedic, we can reuse many architectural elements from heterogeneous error detection [8], reducing the hardware necessary for arbitrary error recovery and allowing precise matching of checking and recovery granularity.

#### Software Redundancy
Redundancy can also be achieved without hardware support by re-executing code and comparing results in software, though at a significant performance penalty. SWIFT [35] runs two copies of each instruction within a single thread. Khudia and Mahlke [36] extend this by only repeating computation for error-intolerant parts of an application. Wang et al. [37] run the second execution in a separate thread to better use multicore and multithreaded systems. Hybrid schemes like CRAFT [17] use compiler assistance to duplicate instructions, coupled with special hardware detection structures.

#### Heterogeneous Redundancy
Our prior work [8] presented a heterogeneous parallel error detection scheme, exploiting the parallelism inherent in fault detection to reduce power-performance-area (PPA) overheads. Other work includes Austin’s DIVA [39], which uses a superscalar in-order core to verify the correctness of a larger out-of-order superscalar core. Ansari et al. [40] pair an older and newer version of the same microarchitecture series on a chip, while LaFrieda et al. [41] couple cores dynamically for lockstep execution based on profiling to maximize system performance.

### Conclusion
We have designed ParaMedic, an architecture for exploiting parallelism for error correction. It couples a hardware undo log for rolling back errors with using the L1 cache as a buffer for forwarding unchecked values to future computation, without allowing it to escape to other cores. The system also allows recovery from hard faults by detecting repeated errors and triggering hardware migration. Performance is slightly reduced relative to detection alone, but typically, this is very minor. With an adaptive technique to set checkpoint lengths, the overheads increase from 1.9% with detection to 3.1% with correction. Thus, we provide a practical architecture for full error correction in commodity out-of-order superscalar systems.

### Acknowledgements
This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) through grant references EP/K026399/1 and EP/M506485/1, and Arm Ltd. Additional data related to this publication is available in the data repository at https://doi.org/10.17863/CAM.37963.