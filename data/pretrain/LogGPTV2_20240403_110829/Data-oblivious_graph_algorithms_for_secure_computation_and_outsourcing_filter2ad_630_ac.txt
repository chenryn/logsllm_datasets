domly shuﬄe vector C and directly access its element to re-
trieve the next node on the path. This shuﬄing guarantees
that there is no correlation between the row accessed during
BFS and vertices accessed during path reconstruction. Un-
fortunately, translating parent information of the accessed
location to its shuﬄed version cannot be performed oblivi-
ously in constant time and we are back to either scanning
the entire vector or applying ORAM techniques to access the
mapping information. For these reasons, we next describe a
simple solution of O(|V |2) complexity.
In the description that follows, we conservatively assume
that the location of destination node t in the adjacency ma-
trix is not known (i.e., it is protected). This algorithm can
then be easily modiﬁed for the case when the location of t
in M and C is known. The initial solution, i.e., the one that
does not hide the size of the path, is as follows:
Algorithm 2:
1. Execute BFS to compute shortest distances from source
2. Initialize the path P to (cid:104)[t](cid:105). Set the current working
s to all other nodes.
node [v] to [t].
3. Scan vector C to ﬁnd node [w] such that [w] = [Cv.parent].
In more detail, we execute:
1. [w] = 0
2. for i = 1 to 2|V | − 1 do
3.
4.
[cond] = ([v] ?= i)
[w] = [cond] · [Ci.parent] + (1 − [cond]) · [w]
4. Update the path as P = (cid:104)[w], P(cid:105) and set [v] to [w].
5. Repeat steps 3–5 until [v] = s.
When the location of t in the adjacency matrix is known,
we can skip step 3 in the ﬁrst iteration and directly add
[Ct.parent] to P and set [v] to value [Ct.parent] in step 4.
3.3.2 Hiding the length of the path
To protect information about the length of the path, we
need to ensure that the algorithm always performs |V | − 1
iterations and produces a path of length |V |. To achieve
this, we instruct the algorithm to continue adding nodes to
the path if the source s is reached, but the path is shorter
than |V | vertices long.
To be able to hide the length of the path from s to t, we
must hide the fact that v = s and proceed with adding nodes
to the path. For that reason, we add s to the path, but set
one of the fake nodes as the current working node [v]. The
algorithm will then keep adding fake nodes to the path until
its length becomes |V | − 1.
To ensure that a suﬃcient number of fake nodes is added
without repetitions, we set their parent information to form
a cycle of length |V |− 1. Because the algorithm is oblivious,
the parents of the fake nodes can be assigned in an arbitrary
manner. We choose to assign them sequentially to form one
cycle. More precisely, the parent of fake node v is set to fake
node w with the highest index less than v (and the parent of
the fake node with the lowest index is set to the fake node
with the highest index). For that purpose, we utilize vector
F to update parent information of fake nodes in vector C.
In more detail, the computation that we need to perform
after step 1 of Algorithm 2 is as follows. We ﬁrst scan F to
ﬁnd the index of the fake node with the highest number. It
will be used to initialize the parent value (to be used for the
fake node with the lowest index). We then scan the nodes
in C updating parent values of fake nodes and the current
parent value.
1. [parent] = 0
2. for i = 1 to 2|V | − 1 do
3.
4. for i = 1 to 2|V | − 1 do
5.
6.
[parent] = [Fi] · i + (1 − [Fi])[parent]
[Ci.parent] = [Fi] · [parent] + (1 − [Fi])[Ci.parent]
[parent] = [Fi] · i + (1 − [Fi])[parent]
The only other change that we need to make to Algorithm 2
is to hide the fact that source s has been reached by selecting
a fake node. To achieve this, we randomly select one of the
fake nodes and set the current working node to that fake
node if the source has been reached. Because we do not
know at which step of the computation the source might be
reached, we have to perform such testing at each iteration of
the algorithm. Fortunately, because the source node can be
reached only once, we can pre-select one of the fake nodes at
the beginning of the algorithm (instead of doing it at each
iteration), but test each time whether it should be chosen.
This means that after assigning parent node information to
the fake nodes as described above, we select one of the nodes
at random as follows:
1. choose (protected) random permutation π(·)
2. for i = 1 to 2|V | − 1 do [vi] = [Fi] · [π(i)]
3. [u] = 0
4. for i = 1 to 2|V | − 1 do
?
5.
> [u])
6.
[condi] = ([vi]
[u] = [condi] · i + (1 − [condi])[u]
Lastly, we modify steps 4–5 of Algorithm 2 to the following:
4. Prepend [w] to the path, i.e., P = (cid:104)[w], P(cid:105). If [w] is
diﬀerent from s, set [v] to [w]; otherwise, set [v] to a
randomly chosen fake node. That is, compute:
1. [cond] = ([w] ?= s)
2. [v] = [cond] · [u] + (1 − [cond])[w]
5. Repeat steps 3–5 |V | − 2 times.
3.3.3 Handling unreachable destination
The algorithm that we described so far for shortest path
computation works if there is a path from s to t. If, how-
ever, node t cannot be reached from the source node, the
algorithm must still proceed with the computation protect-
ing the fact that there is no path. According to our BFS
algorithm, node t will have its parent set to ⊥ if there is
no path from s to t. We can use this information to slightly
modify the algorithm and proceed with one of the fake nodes
if ⊥ has been reached. This introduces a very minor change
to the algorithm described in section 3.3.2 because we can
reuse the selected fake node for our purposes. This is a safe
modiﬁcation to the algorithm because a path will never si-
multaneously contain s and ⊥. We therefore update step 4
of Algorithm 2 to the following:
4. Prepend [w] to the path, i.e., P = (cid:104)[w], P(cid:105). If [w] is
diﬀerent from s or ⊥, set [v] to [w]; otherwise, set [v]
to a randomly chosen fake node. That is, compute:
1. [cond1] = ([w] ?= s)
2. [cond2] = ([w] ?=⊥)
3. [cond] = [cond1] + [cond2] − [cond1][cond2]
4. [v] = [cond] · [u] + (1 − [cond])[w]
In the above, we use a + b − a · b to implement a ∨ b.
3.4 Analysis
For all of our oblivious graph algorithms, we ﬁrst analyze
their time complexity followed by their security analysis.
3.4.1 Complexity analysis
In this section, we analyze the complexities of our BFS
algorithm and shortest path reconstruction.
It is easy to see that the complexity of steps 1–2 and 4–5 of
the BFS algorithm (both the basic and general versions) is
O(|V |), while the complexity of steps 3 and 6 is O(1). Then
because steps 4–6 are executed |V | times, the overall run-
time of O(|V |2), which is optimal for the adjacency matrix
representation and for graphs with |E| = Θ(|V |2). It also
outperforms any solution that combines the conventional al-
gorithm with ORAM when |E| = Ω(|V |2/ log(|V |)2).
If the labeling of the graph nodes is not guaranteed to be
random (i.e., the labeling can reveal information about the
structure of the graph) or the graph is not guaranteed to be
connected and the fake nodes need to be placed at random
locations in the graph, the nodes of the graph will need to be
randomly permuted. When this step is implemented using
oblivious sorting, its complexity is O(|V |2 log(|V |)), which
dominates the complexity of the algorithm.
Our algorithm for SSSD shortest path computation also
has O(|V |2) time. In particular, after executing BFS in step
1 of the algorithm, the only steps that have non-constant
time is one-time pre-processing of fake nodes and step 3,
both with complexity O(|V |). Because steps 3–4 are per-
formed |V |−1 times, we obtain the overall runtime of O(|V |2).
3.4.2
To show security of our BFS and shortest path algorithms,
we show that they are oblivious with respect to Deﬁnition 1.
Security analysis
Theorem 1. The BFS algorithm is data-oblivious.
Proof. To prove this theorem, we analyze each major
operation in the algorithm with respect to Deﬁnition 1. We
show that for any given input graph G = (V, E) and source
s, (i) the sequence of executed instructions is the same as for
all other input graphs with the same number of nodes |V |
and (ii) the memory accesses are indistinguishable from the
memory accesses when the input G is a randomly generated
graph with |V | nodes.
The ﬁrst three steps of the algorithm are independent of
the input graph G, and step 1 is also independent of the
source node s. This means that step 1 is exactly the same
for all possible inputs. Step 2 performs the same operations
for all inputs, but accesses and updates node s in C with
diﬀerent information than other nodes. Because according
to the solution, s has a random location in the graph, its
position is indistinguishable for real and randomly generated
input graphs G. The same applies to step 3 of the algorithm.
Steps 4 and 5 execute the same sequence of instructions
for all input graphs and access all memory locations of C and
Mv in exactly the same manner, therefore they are identi-
cal for all input graphs. The only part that remains is to
show that revealing the locations of |V | nodes which are be-
ing processed by the algorithm cannot be used to extract
information about the input (cid:104)G, s(cid:105). In particular, because
of randomized order of the nodes, the revealed locations are
random and cannot be used to extract information about
the structure of the graph. Furthermore, when selecting
the next candidate node, one of them is selected at ran-
dom, which also protects information about the number of
candidate nodes. We obtain that the revealed locations are
random and the memory accesses are indistinguishable from
those of randomly generated graphs.
Theorem 2. The SSSD shortest path algorithm is data-
oblivious.
Proof. Similar to the proof of BFS algorithm, we con-
sider all steps of the SSSD shortest path algorithm and show
that they are data-oblivious according to our deﬁnition.
Step 1 executes BFS and is data-oblivious according to
Theorem 1. All remaining steps (including fake node selec-
tion) execute exactly the same sequence of operations for
all inputs graphs and access exactly the same memory lo-
cations for all input graphs. This means that the execution
and memory accesses are identical for all inputs and the
algorithm is data-oblivious.
4. MAXIMUM FLOW
In this section we provide an oblivious solution to another
graph problem, namely, maximum ﬂow. Before we can pro-
ceed with its description, we need to provide background
information.
4.1 Background
A ﬂow network is a directed graph G = (V, E), where each
edge (v, u) ∈ E has a non-negative capacity c(v, u) ≥ 0 (and
if (v, u) (cid:54)∈ E, c(v, u) = 0). Given a source vertex s ∈ V and a
sink vertex t ∈ V , a ﬂow f in G is a function f : V × V → R
that must satisfy the properties of capacity constraint (i.e.,
for all v, u ∈ V , f (v, u) ≤ c(v, u)), skew symmetry (i.e.,
for all v, u ∈ V , f (v, u) = −f (u, v)), and ﬂow conservation
u∈V f (v, u) = 0). The value
of a ﬂow in the ﬂow network is deﬁned as the total ﬂow out
u∈V f (s, u), and the maximum-ﬂow
(i.e., for all v ∈ V \ {s, t}, (cid:80)
of the source s |f| =(cid:80)
problem is to ﬁnd a ﬂow of maximum value.
A standard way of computing maximum ﬂow relies on
the Ford-Fulkerson method, which proceeds as follows: We
initialize the ﬂow to 0, and while there exists an augmenting
path p, we augment the ﬂow f along the path p. Here an
augmenting path is deﬁned as a path from the source s to
the sink t which can admit more ﬂow and therefore can be
used to increase the overall ﬂow of the network.
In implementing the above high-level logic, existing algo-
rithms rely on the notion of residual network, which intu-
itively consists of edges that can admit more ﬂow. In more
detail, given a ﬂow network G = (V, E) and a ﬂow f , the
residual network of G induced by f is Gf = (V, Ef ) with
edges of positive capacity Ef = {(v, u) ∈ V × V | cf (v, u) >
0}, where cf (v, u) = c(v, u)− f (v, u) is the residual capacity
of (v, u). An augmenting path p is then a simple path from s
to t in the residual network Gf . This means that each edge
on the path admits additional positive ﬂow, and the (resid-
ual) capacity of p is deﬁned as cf (p) = min{cf (v, u) | (v, u)
is on p}.
The basic structure of the approach, which corresponds to
the Ford-Fulkerson algorithm, is then as follows: On input
G = (V, E), s ∈ V , and t ∈ V ,
1. for each (v, u) ∈ E do
2.
3.
4. while there exists path p from s to t in residual
f (v, u) = 0
f (u, v) = 0
network Gf do
cf (p) = min{cf (v, u) | (v, u) is on p}
for each (v, u) in p do
f (v, u) = f (v, u) + cf (p)
f (u, v) = −f (v, u)
5.
6.
7.
8.
This algorithm has complexity O(|E| · |fmax|), where fmax
is the maximum ﬂow returned by the algorithm, as ﬁnding
a path in each iteration of the algorithm involves O(|E|)
time. For networks with integral capacities and small fmax,
the runtime of this algorithm is good; however, in the gen-
eral case a variant known as the Edmonds-Karp algorithm
is preferred. If we use a shortest path from s to t on line
4 of the algorithm, we obtain the Edmonds-Karp algorithm
with complexity O(|V | · |E|2). It is guaranteed to ﬁnd the
maximum ﬂow in O(|V | · |E|) iterations, each of which in-
volves O(|E|) time (see, e.g., [16]). Finding a shortest path
can be accomplished using BFS.
4.2 Oblivious algorithm
In our oblivious solution, we follow the overall structure of
the algorithm and use the implementation of BFS and short-
est path computation from Section 3. Because our oblivious
BFS algorithm processes one node at a time and reveals
its location in the adjacency matrix, we need to shuﬄe the
rows and columns of the matrix between each iteration of
the maximum ﬂow solution to hide all access patterns. We
also now must maintain the residual network and obliviously
update it after computing the augmenting path p.
We obtain the solution, which takes as the input a ﬂow
network G = (V, E) with the capacity function stored in the
(protected) adjacency matrix M , source node s, and sink
node t. We assume that positive capacity of edge (v, u) is
stored in [Mv,u], and Mv,u = 0 indicates that there is no
edge from v to u. The algorithm proceeds as follows:
Algorithm 3:
1. Expand matrix M with |V |−1 fake nodes inserted into
M consistently as rows and columns. The capacity of
all edges (v, u) and (u, v) connecting two fake nodes v
and u is set to cmax, where cmax refers to the maxi-
mum possible capacity of an edge. The capacity of all
edges (v, u) and (u, v), where v is a node of the original
graph G and u is a fake node is set to 0. As before,
the information about which nodes of M are fake is
maintained in bit vector F . The location of fake nodes
does not need to be randomized at this step.
2. Create (protected) matrix M(cid:48) for storing residual net-
work Gf and initialize each element of it M(cid:48)
i,j to Mi,j.
Also create (protected) matrix L for storing the ﬂow
function and initialize each element of it Li,j to 0.
3. Repeat the computation that follows |V | · |E| times.
4. Apply a random permutation to the rows and columns
of M(cid:48) and L as well as to the elements of F consis-