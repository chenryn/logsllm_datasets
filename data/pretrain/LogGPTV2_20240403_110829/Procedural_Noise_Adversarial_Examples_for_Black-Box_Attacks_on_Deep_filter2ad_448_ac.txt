max
Random
26.0
26.8
27.0
27.1
27.9
Gabor
24.7
39.9
49.1
53.3
61.8
Perlin
26.4
47.2
57.7
63.7
73.2
For Gabor noise, the parameters σ, ω, and ξ have low correlation
(≤ 0.16) with universal evasion. (cid:140)e remaining parameter λ how-
ever has a high correlation (≥ 0.52) with the universal evasion rate
across all classi(cid:128)ers; this peaks at 0.90 for IRv2ens. λ corresponds to
the wavelength of the harmonic kernel. Visually, lower values of λ
indicate thinner and more frequent bands, which is why λ can also
be thought of as an inverse frequency. (cid:140)e correlations suggest that
low-frequency Gabor noise pa(cid:138)erns correlate with high universal
evasion, and this appears to be more pronounced as we move to
the more robust models.
For Perlin noise, the parameters λx and λy have low correlation
(≤ 0.25) with universal evasion. (cid:140)e universal evasion rates have a
moderate negative correlation with the number of octaves Ω and
have a moderately-high positive correlation with ϕsine for the non-
adversarially trained models. (cid:140)is suggests that high-frequency
Perlin noise pa(cid:138)erns correlate with high universal evasion. (cid:140)e
number of octaves indicate the amount of detail or the number
of curvatures within the image, so a slight negative correlation
indicates that some pa(cid:138)erns that achieve high evasion have fewer
curvatures and details. Visually, the frequency of the sine function
ϕsine can be thought of as the thinness of the bands in the image.
(cid:140)is is the opposite of the λ in Gabor noise, so we have a similar
result where IRv2ens is more susceptible to low-frequency pa(cid:138)erns.
Low-frequency pa(cid:138)erns are also more e(cid:130)ective on IRv2ens be-
cause this model was adversarially trained on gradient-based at-
tacks, which we hypothesize generated mostly high-frequency per-
turbations. (cid:140)e frequency appears to be an important factor in
determining the strength of the UAP even when Gabor and Per-
lin noise have opposite correlations between their frequency and
their universal evasion. (cid:140)is di(cid:130)erence shows that these noise pat-
terns have notably di(cid:130)erent characteristics. Complete correlation
matrices are available in Appendix C.
Cross-model Universality. (cid:140)e UAPs with high universal eva-
sion on one model o(cid:137)en have high universal evasion on the other
models. For example, a Perlin noise perturbation has 86.7%, 77.4%,
73.2%, 58.2%, and 45.9% universal evasion on VGG-19, ResNet-50,
Inception v3, IRv2, and IRv2ens respectively.
(cid:140)e correlation of the universal evasion rates across models is
high (≥ 0.80), which shows the transferability of our UAPs across
models. For Gabor noise, there is a high correlation across all mod-
els. For Perlin noise, there appears to be a noticeable di(cid:130)erence
between IRv2ens and the remaining four models. (cid:140)e strongest Per-
lin noise on the undefended models have high-frequency pa(cid:138)erns
that the adversarial training partially mitigated.
Overall, the results show that procedural noise perturbations act
as UAPs across all models. (cid:140)is is the (cid:128)rst black-box generation of
5
(a) Universal Evasion Rate
Figure 2: Histogram of (a) universal evasion rate over all perturbations and (b) average sensitivity over all inputs across all
models. For example, VGG-19 in (a) shows that about 12% of the Gabor noise perturbations have a universal evasion rate of
approximately 0.8.
(b) Average Sensitivity
cross-model UAPs, and the procedural noise allows us to draw per-
turbations from a distribution with high average universal evasion.
We now look at the results from an input-speci(cid:128)c perspective.
4.3 Model Sensitivity on Inputs
(cid:140)e model’s sensitivity could vary across the input dataset, i.e. the
model’s predictions are stable for some inputs while others are
more susceptible to small perturbations. We measure this with the
average sensitivity of single inputs over all perturbations. Results
in Fig. 2b show that the average sensitivity of the dataset is bimodal
for all models and both procedural noise functions. (cid:140)ere are two
distinct subsets of the data: one on the right that is very sensitive
and the other on the le(cid:137) that is very insensitive to the perturbations.
(cid:140)e remaining data points are somewhat uniformly spread in the
middle. (cid:140)e number of points on the le(cid:137) peak of the histogram in
Fig. 2b is larger for the most robust models. Similarly to Fig. 2a,
this progression indicates that the order of most to least sensitive
models align with the most to least robust models. We omit results
for random noise since more than 60% of the input dataset are
barely a(cid:130)ected by it across all models. (cid:140)is manifests as a tall peak
on the le(cid:137) and a short peak on the right.
When comparing the average sensitivity of inputs between the
two procedural noise functions on the same models, the correlations
range between 0.89-0.92, which shows that both procedural noise
perturbations a(cid:130)ect very similar groups of inputs for each model.
(cid:140)e correlation between the average sensitivities for each input
across the Inception models is at least 0.79, which suggests that
these models are sensitive to procedural noise on similar inputs.
6
(cid:140)is is less so between ResNet-50 and VGG-19 whose correlations
with the other models range from 0.56-0.81.
Input-speci(cid:128)c Evasion. We consider the case when our untar-
geted black-box a(cid:138)ack is used as an input-speci(cid:128)c a(cid:138)ack, i.e. the
adversary only needs to (cid:128)nd at least one adversarial perturbation
that evades each input. (cid:140)us, Evasion on input x is achieved when
∃s ∈ S such that arg max f (x + s) (cid:44) τ(x). (cid:140)is is in contrast to the
universal a(cid:138)ack where the adversary cra(cid:137)s a single perturbation to
fool the model on as many inputs as possible.
Note that the random noise is optimized for the (cid:96)∞-norm. We
draw the random noise perturbation from {−ε, ε}d×d×3. (cid:140)us, for
each pixel the added noise is either −ε or ε, rather than drawing
from the continuous domain (−ε, ε). It is reasonable to think that a
larger perturbation is more likely to cause evasion.
Table 2 shows that VGG-19 and ResNet-50 are particularly fragile
as even random noise greatly degrades their performance. Although
the Inception models are more robust, both procedural noise pertur-
bations still achieve more than 72% evasion on all of them. Although
ensemble adversarial training improved the robustness of IRv2, it
still does not mitigate the impact of the procedural noise a(cid:138)ack.
(cid:140)e idea of ensemble adversarial training was to decouple the gen-
eration of the adversarial training set from the original model, but
this was limited since it was only done for gradient-based a(cid:138)acks.
We argue that defences should be more input-agnostic to avoid
having to train against all types of a(cid:138)acks.
Label Analysis. (cid:140)e procedural noise perturbations were not
designed to be a targeted a(cid:138)ack, but intuitively, the same universal
perturbation would cause misclassi(cid:128)cation towards class labels that
Table 2: Input-speci(cid:128)c evasion rate (in %) for random and
procedural noise perturbations. Original refers to the top 1
error on the unaltered original images. Strongest attack on
each classi(cid:128)er is highlighted.
Classi(cid:128)er
VGG-19
ResNet-50
Inception v3
IRv2
IRv2ens
Original
Random
29.4
25.9
22.3
20.1
20.1
57.1
55.7
46.8
38.7
37.5
Gabor
97.7
96.2
89.2
81.1
72.7
Perlin
98.3
96.3
93.6
87.0
79.4
have visually similar textures to the procedural noise pa(cid:138)ern. We
(cid:128)nd that this holds true for only a few of the procedural noise UAPs.
For a given procedural noise perturbation, we de(cid:128)ne its top label
to be the class label it causes the most misclassi(cid:128)cation towards.
When looking at procedural noise UAPs across all models, about 90%
of Gabor noise perturbations have their top label apply to at most
9% of the inputs. For Perlin noise, about 80% of its perturbations
have their top label on at most 10% of the input. (cid:140)ere are however
a few outliers that have their top label appear above 10% of the
inputs. For example, on Inception v3, the top Gabor noise with
61.8% universal evasion has “window screen” as its top label and it
applies for 37.8% of the evaded inputs. In contrast, another Gabor
noise perturbation with 58.9% universal evasion has “quilt” as its
top label, but it only applies for 6.0% of the evaded inputs. As a
consequence, it is still possible to use procedural noise to create
universal targeted UAPs aimed at speci(cid:128)c class labels like “window
screen” or “brain coral”. However the class labels we can target
is dependent on the procedural noise and the overall success of
universal targeted a(cid:138)acks may be limited, as it is more di(cid:129)cult to
make a perturbation both universal and targeted.
Perlin noise has a relatively large amount of “brain coral” clas-
si(cid:128)cations, with other labels such as “maze” and “shower curtain”
also appearing frequently in the top (cid:128)ve most classi(cid:128)ed labels per
classi(cid:128)er. For Gabor noise, there was no label that consistently
appeared at the top across all models. (cid:140)ese results indicate that
Perlin noise has a larger bias towards certain classes, while Gabor
noise is more indiscriminate.
4.4 Discussion
Adversarial examples exploit the model’s sensitivity, causing large
changes in the model’s output by applying speci(cid:128)c small changes
to the input. More speci(cid:128)cally, recent work has shown adversarial
examples exploit ”non-robust” features that the model learns but
that are incomprehensible to humans [26]. It is likely that UAPs
may be exploiting ”universal” non-robust features that the DCN
has learned.
Textures. Previous results have shown ImageNet-trained DCNs
to be more reliant on textures rather than shapes [14]. (cid:140)ough
not explicitly shown in the later Inception architectures (Inception
v3, IRv2), these are still likely to have a strong texture-bias due
to similarities in the training. (cid:140)e texture bias however does not
fully explain why small, and sometimes imperceptible, changes
to the texture can drastically alter the classi(cid:128)cation output. We
a(cid:138)ribute adversarial perturbations more to the sensitivity of the
7
Generalizability of Procedural Noise. From the label analy-
sis of procedural noise UAPs, we observe that most perturbations
with high universal evasion do not have a strong bias towards
any particular class label—no particular class is targeted more
than 10% for over 80% of the procedural noise UAPs. (cid:140)is suggest
that UAPs leverage more generic low-level features that the model
learns, which would explain their universality and indiscriminate
behaviour in causing misclassi(cid:128)cation.
Amongst white-box UAP a(cid:138)acks, our procedural noise has the
closest visual appearance to perturbations from the Singular Vector
A(cid:138)ack (SVA) by Khrulkov and Oseledets [30]. (cid:140)ey generate UAPs
targeting speci(cid:128)c layers of DCNs, and found that targeting earlier
layers of the network generated more successful UAPs. (cid:140)e pa(cid:138)erns
obtained for these earlier layers share a visual appearance with
procedural noise. (cid:140)ese layers also correspond to the low-level
features learned by the network. Other evidence also suggests that
procedural noise exploits low-level features, as feature visualization
of earlier layers in neural networks share the same visual appear-
ance with some procedural noise pa(cid:138)erns. Convolutional layers
induce a prior on DCNs to learn local spatial information [17], and
DCNs trained on natural-image datasets learn convolution (cid:128)lters
that are similar in appearance to Gabor kernels and colour blobs
[49, 78]. Gabor noise appears to be a simple collection of low-level
features whereas Perlin noise seems to be a more complex mixture
of low-level features. (cid:140)is di(cid:130)erence in the complexity of their
visual appearance may explain why Perlin noise is a stronger a(cid:138)ack
than Gabor noise.
Procedural noise a(cid:138)acks transfer with high correlation across
the models most likely because they share the same training set
(ImageNet), learning algorithms (e.g. backpropagation), and have
similar components in their architectures (e.g. convolutional lay-
ers). (cid:140)is increases the likelihood that they share input-agnostic
vulnerabilities. In this way, our results appear to support the idea
that DCNs are sensitive to aggregations of low-level features.
Security Implications. In transfer learning, a model trained
on one task is re-purposed as an initialization or (cid:128)xed feature
extractor for another similar or related task. When used as a feature
extractor, the initial layers are o(cid:137)en frozen to preserve the low-level
features learned. (cid:140)e subsequent layers, closer to the output, are
then re-trained for the new task [78]. Hidden layers from models
pre-trained on the ImageNet dataset are o(cid:137)en re-used for other
natural-image classi(cid:128)cation tasks [50]. (cid:140)is makes it a notable
target as vulnerabilities that exploit low-level features encoded in
the earlier layers carry over to the new models.
model. Moreover, we test our a(cid:138)ack against an object detection
model in Sect. 6, and show that it also degrades the performance of
models that have a spatial component in their learning task.
Transfer learning has many bene(cid:128)ts as training entire models
from scratch for large-scale tasks like natural-image classi(cid:128)cation
can be costly both computationally in training and in terms of
gathering the required data. However, this creates a systemic threat,
as subsequent models will also be vulnerable to a(cid:138)acks on low-level
features like procedural noise. Precisely characterizing the extent
of the vulnerability of re-purposed models to the same a(cid:138)ack is an
interesting direction for future work.
Procedural noise is an accessible and inexpensive way for gener-
ating UAPs against existing image classi(cid:128)ers. In our experiments
the Gabor and Perlin noise functions modi(cid:128)ed only four parameters,
and each parameter was bounded in a closed interval. Drawing from
this space of perturbations has generated UAPs with high universal