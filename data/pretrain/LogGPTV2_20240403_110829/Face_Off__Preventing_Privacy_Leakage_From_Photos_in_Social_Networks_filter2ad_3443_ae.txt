anism, while about 35% reported a neutral opinion. In most
cases, users responded negatively due to a false belief that
current access control mechanisms are eﬀective. The re-
maining negative answers were from users that were not in-
terested in privacy implications created by widely accessible
photos. The users that had selected a neutral stance, recog-
nized the need that other users may have for preserving their
privacy, but did not have a strong motivation in using such
a mechanism. However, these users were also not aware of
the true visibility of their photos. On the other hand, 38.4%
of the participants immediately shaped a positive opinion of
OSNs adopting a ﬁne-grained access control mechanism.
Interestingly, there was a remarkable shift in user opinions
after introducing the problem of conﬂicting interests, and
 0 10 20 30 40 50Strong NoNoNeutralYesStrong YesUsers (%)Adoption willingnessBefore DemoAfter DemoLegislation. European data protection agencies have
pressured Facebook into removing the tag-suggestion mecha-
nism due to privacy concerns over face recognition software
processing uploaded photos without users’ consent [1, 12].
This resulted in the tag-suggestion mechanism being tem-
porarily disabled and the deletion of biometric data col-
lected, for users located in European countries [2, 14]. To
that end, many consider that face recognition software will
have limited adoption. Fortunately, there is active research
towards privacy-preserving face recognition [24,36] and, there-
fore, we envision that this very eﬀective technology will be
adopted by such services. Nevertheless, this paper is orthog-
onal to privacy concerns and legislation issues related to face
recognition. In actuality, our approach takes advantage of
automated face recognition for enhancing user privacy.
8. RELATED WORK
In [18] Besmer et al. studied the behavior of users regard-
ing photo sharing applications, and identiﬁed the reasons
users choose to tag or un-tag a photo. During their study
they demonstrated a simple prototype that obfuscates faces,
in an attempt to initiate a discussion about user privacy and
photo ownership. Their ﬁndings highlighted user concerns
in regards to the visibility of images and the lack of eﬀective
access control mechanisms. Their results argue that users
are interested in shaping their identity in order to manage
impressions and avoid exposing situations they are not com-
fortable with. In a follow-up [19], they presented a “negoti-
ation” tool that allows each tagged user to send an out-of-
band request to the photo uploader, for requesting the photo
to become non accessible by particular users. However, it
remains entirely up to the uploader to accept or reject user’s
request. Even though users can contribute in access control
by sending a request, this does not solve conﬂicts of interest.
Multiple works [20, 21, 29, 40] follow the rule-based access
control approach. In [29] users are allowed to annotate their
photos with semantically meaningful tags and to specify ac-
cess control rules based on these tags. The work presented
in [40] uses previously uploaded photos, and their access con-
trol rules, for classifying each new photo by its content and
for predicting an access control rule that will be acceptable
by the uploader. The advantage of this approach is that the
prediction is adaptive to the behavior of the user. However,
all these approaches create a complex set of rules and also
consider access control at the photo level.
Al Bouna et al. presented a system for preserving privacy
regarding multimedia objects [21], which can be speciﬁcally
used for photos [20]. They have designed a security model
and built a security rule speciﬁcation toolkit that uses the
SWRL language for specifying content-based access control
rules. Their prototype has the ability to hide faces among
others, but it does not distinguish access control from the
conﬂict resolving mechanism.
Importantly, this approach
does not allow each depicted individual to set his/her own
rules, but only the uploader. When two or more rules are
conﬂicting, a security administrator is required to set prior-
ity values on the execution of the rules. This, of course, is
not feasible at the large scale of an OSN.
In [45] Thomas et al. highlighted the lack of a multi-party
access control mechanisms for shared content that is up-
loaded by other users in OSNs. They studied the conﬂicting
privacy settings between friends and how these settings can
reveal sensitive information that was intended to be private.
But, their proposed approach is very strict and far from us-
able, as objects are revealed only to the mutual friends of the
related users. Also, [26, 27, 39] proposed multi-party mecha-
nisms for allowing collaboration between the users regarding
the speciﬁcation of the access control policy. However, even
if collaboration is allowed, the access control is enforced at
photo level, which cannot eﬀectively accommodate the pri-
vacy preferences of all the depicted users.
Cutillo et al. [23] presented a demanding cryptography-
based face obfuscation mechanism for a speciﬁc decentral-
ized OSN, namely, the Safebook. This mechanism is far
from applicable within the environment of existing OSNs,
as it leverages the multi-hop routing protocol of the speciﬁc
OSN. On the other hand, our approach is designed for easy
integration with existing social networks, relying on techno-
logical capabilities widely available to such services.
9. CONCLUSIONS
In this work we tackled the problem of conﬂicting interests
that arise from photos being shared in social networks. The
problem stems from the current design of OSNs, as users
associated with a shared photo have limited control over its
visibility, and their privacy settings usually are overridden
by those of other users. As such, we identiﬁed the diﬀerent
scenarios where conﬂicts of interests can occur, and we con-
ducted a case study in order to quantify the privacy risks
presented. We collected a large number of photos, along
with their tags, for assessing users’ tagging behavior, and
for determining the true visibility of shared photos.
We designed a ﬁne-grained access control mechanism that
allows depicted users to deﬁne the exposure of their own face,
by setting their preferred permissions. When a photo is re-
quested, our mechanism determines which faces should be
hidden and which should be revealed based on the request-
ing user, and presents a “processed” version of the photo.
Our mechanism can be implemented on top of the existing
access control mechanisms and smoothly interoperate with
them, as demonstrated by our proof-of-concept implemen-
tation. The proposed approach is scalable, as it imposes
only a small processing overhead. Finally, we conducted a
user study to evaluate the eﬀectiveness of our approach, and
found that hiding users’ faces is an eﬀective measure for en-
abling privacy in shared photos. Our study also revealed the
misconceptions users have regarding existing access control
mechanisms, and showed that users are positive towards the
adoption of a face-level access control mechanism.
Acknowledgements
We thank the anonymous reviewers for their valuable com-
ments. This work was supported by the FP7 Marie-Curie
ITN iSocial funded by the EC under grant agreement no
316808, by the NSF under Grant CNS-13-18415, and by the
MIUR under the FIRB2013 FACE grant. Any opinions,
fundings, conclusions, or recommendations expressed herein
are those of the authors, and do not necessarily reﬂect those
of the US Government or the NSF.
10. REFERENCES
[1] Data Protection Commissioner - Facebook Ireland
Audit. [accessed Aug-2015].
[2] Data Protection Commissioner - Facebook Ireland
Re-Audit. [accessed Aug-2015].
[3] Facebook - Stats. [accessed Aug-2015].
[4] Facebook - Tag Review. [accessed Aug-2015].
[5] Facebook Privacy Selector. [accessed Aug-2015].
[6] Bussiness Insider - Facebook Users Are Uploading 350
Million New Photos Each Day. [accessed Aug-2015].
[7] Business Insider - A High School Coach Was Fired For
Facebook Photo. [accessed Aug-2015].
[8] CBS news - Did the Internet Kill Privacy? [accessed
Aug-2015].
[9] Germany Sues Facebook For Violating Users’ Privacy.
[accessed Aug-2015].
[10] Social, Digital Video Drive Further Growth in Time
Spent Online. [accessed Aug-2015].
[11] Pew Research Center - Facebook Survey. [accessed
Aug-2015].
[12] Telegraph - Facebook defends using proﬁle pictures for
facial recognition. [accessed Aug-2015].
[13] Wired - Facebook Envisions AI That Keeps You From
Uploading Embarrassing Pics. [accessed Aug-2015].
[14] Wired - Facebook complies with EU data protection
law. [accessed Aug-2015].
[15] Microsoft - Online Reputation in a Connected World,
2009.
[16] A. Acquisti and C. M. Fong. An experiment in hiring
discrimination via online social networks. 2013.
[17] M. Bertalmio, G. Sapiro, V. Caselles, and C. Ballester.
Image inpainting. In SIGGRAPH ’00.
[18] A. Besmer and H. R. Lipford. Privacy perceptions of
photo sharing in facebook. SOUPS ’08.
[19] A. Besmer and H. R. Lipford. Moving beyond
untagging: Photo privacy in a tagged world. In
Proceedings of CHI ’10, 2010.
[20] B. A. Bouna, R. Chbeir, A. Gabillon, and
P. Capolsini. A ﬂexible image-based access control
model for social networks. In Security and Privacy
Preserving in Social Networks. Springer, 2013.
[21] B. A. Bouna, R. Chbeir, A. Gabillon, et al. The image
protector-a ﬂexible security rule speciﬁcation toolkit.
In SECRYPT, 2011.
[22] A. Criminisi, P. P´erez, and K. Toyama. Region ﬁlling
and object removal by exemplar-based image
inpainting. Transactions on Image Processing, 13(9).
[23] L. A. Cutillo, R. Molva, and M. ¨Onen. Privacy
preserving picture sharing: Enforcing usage control in
distributed on-line social networks. In SNS ’12, 2012.
[24] Z. Erkin, M. Franz, J. Guajardo, S. Katzenbeisser,
I. Lagendijk, and T. Toft. Privacy-preserving face
recognition. In PETS, 2009.
[25] B. Henne, M. Linke, and M. Smith. A study on the
unawareness of shared photos in social network
services. In Web 2.0 Security Privacy (W2SP), 2014.
[26] H. Hu, G.-J. Ahn, and J. Jorgensen. Detecting and
resolving privacy conﬂicts for collaborative data
sharing in online social networks. In ACSAC ’11.
[27] H. Hu, G.-J. Ahn, and J. Jorgensen. Enabling
collaborative data sharing in google+. In
GLOBECOM’12, 2012.
[28] G. B. Huang and E. Learned-Miller. Labeled faces in
the wild: Updates and new reporting procedures.
Technical Report UM-CS-2014-003, UMass Amherst.
[29] P. Klemperer, Y. Liang, M. Mazurek, M. Sleeper,
B. Ur, L. Bauer, L. F. Cranor, N. Gupta, and
M. Reiter. Tag, you can see it!: Using tags for access
control in photo sharing. In CHI ’12.
[30] B. P. Knijnenburg, A. Kobsa, and H. Jin.
Dimensionality of information disclosure behavior.
IJHCS, 71(12):1144 – 1162, 2013.
[31] B. Krishnamurthy and C. E. Wills. Characterizing
privacy in online social networks. In WOSN ’08.
[32] Y. Liu, K. P. Gummadi, B. Krishnamurthy, and
A. Mislove. Analyzing facebook privacy settings: User
expectations vs. reality. In IMC ’11.
[33] I. Polakis, P. Ilia, F. Maggi, M. Lancini, G. Kontaxis,
S. Zanero, S. Ioannidis, and A. D. Keromytis. Faces in
the distorting mirror: Revisiting photo-based social
authentication. CCS’14.
[34] I. Polakis, M. Lancini, G. Kontaxis, F. Maggi,
S. Ioannidis, A. Keromytis, and S. Zanero. All your
face are belong to us: Breaking facebook’s social
authentication. In ACSAC ’12, 2012.
[35] P. Rao, D. Lin, E. Bertino, N. Li, and J. Lobo.
Fine-grained integration of access control policies.
Computers & Security, 30(2-3):91–107, 2011.
[36] A.-R. Sadeghi, T. Schneider, and I. Wehrenberg.
Eﬃcient privacy-preserving face recognition. ICISC’09.
[37] Y. Shoshitaishvili, C. Kruegel, and G. Vigna. Portrait
of a privacy invasion: Detecting relationships through
large-scale photo analysis. In PETS, 2015.
[38] J. Shotton, T. Sharp, A. Kipman, A. Fitzgibbon,
M. Finocchio, A. Blake, M. Cook, and R. Moore.
Real-time human pose recognition in parts from single
depth images. Commun. ACM, 56(1), Jan. 2013.
[39] A. C. Squicciarini, M. Shehab, and F. Paci. Collective
privacy management in social networks. WWW ’09.
[40] A. C. Squicciarini, S. Sundareswaran, D. Lin, and
J. Wede. A3P: Adaptive policy prediction for shared
images over popular content sharing sites. HT ’11.
[41] Z. Stone, T. Zickler, and T. Darrell. Autotagging
facebook: Social network context improves photo
annotation. In CVPRW ’08.
[42] M. M. Strano and J. Wattai Queen. Covering your
face on facebook. Journal of Media Psychology:
Theories, Methods, and Applications, 24(4), 2012.
[43] K. Strater and H. R. Lipford. Strategies and struggles
with privacy in an online social networking
community. In BCS HCI ’08.
[44] Y. Taigman, M. Yang, M. Ranzato, and L. Wolf.
DeepFace: Closing the Gap to Human-Level
Performance in Face Veriﬁcation. In CVPR ’14.
[45] K. Thomas, C. Grier, and D. M. Nicol. Unfriendly:
Multi-party privacy risks in social networks. In
Proceedings of PETS’ 10, 2010.
[46] A. Yamada, T. H.-J. Kim, and A. Perrig. Exploiting
privacy policy conﬂicts in online social networks.
Technical report, CMU, 2012.
[47] J. Yang, K. Hua, Y. Wang, W. Wang, H. Wang, and
J. Shen. Automatic objects removal for scene
completion. In INFOCOM Workshop on Security and
Privacy in Big Data ’14.