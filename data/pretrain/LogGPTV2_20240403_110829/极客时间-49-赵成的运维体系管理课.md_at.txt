## 第二个维度，压测接口及流量构造方式 {#24.html#-}接口一般分为 HTTP 接口和 RPC接口，这一点应该不难理解，就不做过多讲解了。流量构造方式上，根据压测粒度的不同，会采用不同的方式，我们常见的有以下几种方案。``{=html}1.**线上流量回放**这种方式直接利用了线上流量模型，比较接近真实业务场景，常见的技术手段如TCPCopy，或者 Tcpdump抓包保存线上请求流量。但是这种方式也存在一些代价，比如需要镜像请求流量，当线上流量非常大的时候就很难全部镜像下来，而且还需要大量额外的机器来保存流量镜像。到了回放阶段，还需要一些自动化的工具来支持，还要解决各种session 问题，真正实施的时候，还是会有不少的工作量。2.**线上流量引流**既然线上回放比较麻烦，那为什么不直接使用线上流量进行压测呢？这个思路确实是可行的，我们前面讲过，压测的主要是HTTP 和 RPC两种类型的接口，为了保证单个应用的流量压力足够大，这里可以采取两种模式。一个是将应用集群中的流量逐步引流到一台主机上，直到达到其容量阈值；另一个方案是，可以通过修改负载均衡中某台主机的权重，将更多的流量直接打到某台主机上，直到达到其容量阈值。这个过程中，我们可以设定单台主机的 CPU、Load 或者 QPS、RT等阈值指标，当指标超出正常阈值后就自动终止压测，这样就可以获取到初步的容量值。这种方式的好处是，不需要额外的流量模拟，直接使用最真实的线上流量，操作方便，且更加真实。下图是两种引流的方案示例。![](Images/8a0fb85397ceee0c398e4f1c7aceb321.png){savepage-src="https://static001.geekbang.org/resource/image/51/f9/51385cd8c40d401c0f2a55742f99adf9.jpg"}3.**流量模拟**上述两种流量模拟方式，更适合日常单机单应用的容量压测和规划，但是对于大促这种极端业务场景，真实流量就很难模拟了，因为这种场景只有特定时刻才会有，我们在日常是无法通过线上流量构造出来的。所以这里就需要利用数据工厂，最终通过流量平台来形成压测流量。这里的工具用到了Gatling，是一款开源的压测工具，用 Scala开发的，后来我们针对自己的需求，比如自动生成压测脚本等，做了一些二次开发。![](Images/e5457dbbc2c35ad146286d7ec259b274.png){savepage-src="https://static001.geekbang.org/resource/image/19/71/19a2690fca9316a17cfe2b5ccd659971.jpg"}如果会有多种流量模型的话，就要生成多个流量模型，具体可见下图：![](Images/eaef1a136a9cbf18e512416a44f970c3.png){savepage-src="https://static001.geekbang.org/resource/image/a0/d3/a0d0fc33ecc3e56b3569d22a47b070d3.jpg"}
## 第三个维度，施压方式 {#24.html#-}上面介绍了容量压测的构造过程，那接下来我们要做的就是对真实的线上系统施加压力流量了。很自然的，这里就需要有施加压力的机器，在上面"全链路压测系统"那张图中，你可以看到，我们的施压方式是通过上百台的机器根据压测脚本和压测数据对系统施压的，我来简单介绍一下大致过程。1.  通过实现在 Web 控制台配置好的压测场景，自动生成压测脚本。2.  利用数据工厂构造出压测数据，这个就是业务场景的模拟，像阿里做得比较完善，就可以借助    AI 和 BI    的技术手段生成很多压测模型，且基本都接近于现实情况下的业务场景。3.  通过 Web    控制台，根据压测脚本和压测数据，生成压测任务，推送到压测集群的    Master 节点，再通过 Master 节点推动到上百台的 Slave    节点，然后就开始向线上系统施加模拟的流量压力了。关于施压机的分布，大部分仍然是跟线上系统在同机房内，少量会在公有云节点上。但是对于阿里，因为其自身的CDN 节点遍布全球，所以他就可以将全球（主要是国内）的 CDN节点作为施压机，更加真实地模拟真实用户从全球节点进入的真实访问流量。这种方式对于蘑菇街就显得成本过高，技术条件和细节也还达不到这个程度。当前阿里已经将这种压测能力输出到了阿里云之上，可以说是对其云生态能力的有力补充，同时也为中小企业在容量规划和性能压测方面提供了很好的支持。
## 第四个维度，数据读写 {#24.html#-}压测过程中，对于读的流量更好构造，因为读请求本身不会对线上数据造成任何变更，但是对于写流量就完全不一样了，如果处理不好，会对线上数据造成污染，对商家和用户造成资损。所以，对于写流量就要特殊处理，这块也有比较通用的解决方案，就是**对压测的写请求做专门的标记**。当请求要写数据库时，由分布式数据库的中间件框架中的逻辑来判断这个请求是否是压测请求，如果是压测写请求则路由到对应的影子库中，而不是直接写到线上正式的库中。在这之前，要提前创建好对应的影子库。假设建立影子库的原则是原 schema +mirro，如果正式库是 order，则影子库为order_mirror，这时两个库中的数据量必须是一致的。对于非敏感信息，数据内容也可以保持一致，这样可以在最大程度上保证数据模型一致。这里再呼应一下我们最开始提到的基础服务标准化工作，如果这个工作在前面做得扎实，它的优势在这里就体现出来了。我们刚刚提到的影子库的路由策略是基于中间件框架来实现的，如果使用的框架不一样，不是标准的，这个功能可能就很难应用起来。这一点在后面全链路以及开关等稳定性方案中，还会涉及到。今天我们介绍了容量压测的技术方案，比较复杂，而且需要对相应场景进行针对性的建设。关于细节部分，你还有什么问题，欢迎留言与我讨论。如果今天的内容对你有帮助，也欢迎你分享给身边的朋友，我们下期见！![](Images/3ef6e72a283656e2668a23a796e1acca.png){savepage-src="https://static001.geekbang.org/resource/image/60/0e/60151e9d25d6751800506e2460f5660e.jpg"}
# 34 \| 稳定性实践：限流降级本周我们继续来讨论稳定性实践的内容。在现实情况下，当面对极端的业务场景时，瞬时的业务流量会带来大大超出系统真实容量的压力。为了应对，前面我们介绍了容量规划方面的实践经验。不过，我们不会无限度地通过扩容资源来提升容量，因为无论从技术角度，还是从成本投入角度，这样做都是不划算的，也是不现实的。所以，我们通常采取的策略就是**限流降级**，以保障承诺容量下的系统稳定；同时还有业务层面的**开关预案**执行，峰值时刻只保障核心业务功能，非核心业务功能就关闭。今天我们就先来介绍一下**限流降级的解决方案**。
## 什么是限流和降级 {#25.html#-}首先，我们先梳理清楚限流和降级的概念，明白它们会发挥怎样的作用，这样才便于我们理解后续的解决方案。-   **限流**，它的作用是根据某个应用或基础部件的某些核心指标，如 QPS    或并发线程数，来决定是否将后续的请求进行拦截。比如我们设定 1 秒 QPS    阈值为 200，如果某一秒的 QPS 为 210，那超出的 10    个请求就会被拦截掉，直接返回约定的错误码或提示页面。-   **降级**，它的作用是通过判断某个应用或组件的服务状态是否正常，来决定是否继续提供服务。以    RT 举例，我们根据经验，一个应用的 RT 在 50ms    以内，可以正常提供服务，一旦超过    50ms，可能就会导致周边依赖的报错或超时。所以，这时我们就要设定一个策略，如果应用的    RT 在某段时间内超过 50ms 的调用次数多于 N    次，那该应用或该应用的某个实例就必须降级，不再对外提供服务，可以在静默一定时间后（比如    5s 或 10s）重新开启服务。这里再特别说一下降级，今天我们讲的内容可以理解为服务降级，后面我会介绍业务开关，可以理解为业务降级。这里只是叫法不同，不同的人有不同的理解，所以我们在讨论概念时，还是尽量回到我们要解决的问题和场景上来，上下文保持一致了，在观点和思路上也更容易达成一致。讲到这里，再提个问题，我们讲的降级，和熔断这个概念是什么关系？你不妨停下来，按照我们刚刚讲过的思路思考一下。
## 常见的限流解决方案 {#25.html#-}我们先看几种常见的限流类型。``{=html}**第一类，接入层限流。**作为业务流量的入口，我们限流的第一道关卡往往会设置在这里，而且接入层限流往往也是最有效的。这里又有两类解决方案，根据接入层所使用的技术方案而定。1.**Nginx 限流**Nginx 或其开源产品是最常用的 Web 服务器，我们使用的是 TEngine。对于一个Web 类应用，如 Web 页面或 H5页面，我们通常会将限流策略增加到这一层，会设置 QPS、并发数以及 CPU 的Idle 作为限流指标。Nginx有对应的函数接口，可以获取到以上指标信息，然后通过 Lua脚本实现限流的逻辑，并作为 TEngine 的插件安装即可。2.**API 路由网关模式**对于客户端模式的接入，我们使用了 API路由网关模式，一方面可以更方面地管理客户端与服务端的链接，另一方面也可以通过配置的方式管理服务接口，这里的服务管理会复用到微服务架构的配置中心，并实现相应的路由策略。对于QPS 和并发限流，直接在配置中心中进行配置即可。**第二类，应用限流。**这一类的限流策略跟上面 API路由网关模式的限流相似，同样是依赖配置中心管理，限流逻辑会配套服务化的框架完成。**第三类，基础服务限流。**主要针对数据库、缓存以及消息等基础服务组件的限流而设定。同样，限流逻辑会配套分布式数据库中间件，缓存或消息的框架来实现。讲到这里，我来解释几个关键的技术点。-   **资源和策略**。资源是我们要进行限流的对象，可能是一个应用，或者一个方法，也可能是一个接口或者    URL，体现了不同的限流粒度和类型。策略就是限流的规则，比如下面我们要提到的    QPS 和并发数限流。-   **时间精度**。主要指对于 QPS、并发数或 CPU 的阈值判断。比如对于    QPS，我们就会设定一个 QPS 时间精度（假设    3s），如果低于阈值则不启用策略，如果超过阈值就启动限流策略。-   **指标计数**。对于并发限制请求，会统计当前的并发数，1    次请求进入到限流模块加 1，等请求结束退出时减    1，当前正在处理的请求数就是并发数。对于 QPS 限流，统计 QPS    不能按照秒统计，因为第 1s，系统可能就被打挂了，所以 QPS    得按照毫秒级别去统计，统计的级别越小，性能损耗越大。所以定在    10ms\~100ms 的级别去统计会更平滑一些，比如将 1s 切成 10 份，每一份    100ms，一个请求进来肯定会落在某一份上，这一份的计数值加    1。计算当前的 QPS，只需要将当前时间所在份的计数和前面 9    份的计数相加，内存里面需要维护当前秒和前面 2 秒的数据。-   **限流方式**。对于 Nginx    就针对总的请求进行限流即可，但是粒度会比较粗。对于应用层，因为配置中心的灵活性，其限流就可以做得更细化。比如可以针对不同来源限流，也可以针对去向限流，粒度上可以针对类级别限流，也可以针对不同的方法限流，同时还可以针对总的请求情况限流，这些灵活策略都可以在微服务的配置中心实现。![](Images/b4257d3363f18f40b9e03fd0620dc7f6.png){savepage-src="https://static001.geekbang.org/resource/image/ce/76/ceaba63c6820d82e6e12ff47122d4d76.jpg"}-   **Spring AOP**。对于 Java 应用，绝大多数公司都会用到 Spring    框架，包括我们上面讲到的分布式数据库等组件，也一样会依赖 Spring    框架，比如我们用到的 MyBatis 开源组件。而 Spirng    框架中的关键技术点，就是 IoC 和    AOP，我们在限流方案的实现上，也会利用到相关技术。简单来说就是，我们通过配置需要限流的方法作为    AOP 的切入点，设定 Advice    拦截器，在请求调用某个方法，或请求结束退出某个方法时，进行上述的各种计数处理，同时决定是否要进行限流，如果限流就返回约定好的返回码，如果不限流就正常执行业务逻辑。基于    AOP    这样一个统一的技术原理，我们就可以开发出与业务逻辑无关的限流组件，通常会在对外的服务调用、数据库调用、缓存调用、消息调用这些接口方法上设置默认的切面，并在业务代码运行时注入，这样就可以做到对业务透明，无侵入性。-   **Web 类型的限流**。对于 Web 类型 URL 接口限流，我们就利用 Servlet    的 Filter 机制进行控制即可。-   **控制台**。上面我们讲了各种配置和策略，如果都是通过人工来操作是不现实的，这时就需要开发对应的限流降级的控制台，将上述的各种配置和策略通过界面的方式进行管理，同时在配置完成之后，能够同步到对应的服务实例上。比如对于    Nginx，当一个策略配置完成后，就要同步到指定的服务器上生成新的配置文件并    Reload。对于配置中心模式的策略，也就是 Spring AOP    模式的限流，在控制台上配置完成后，就要将配置值同步更新到配置中心里，同时再通过运行时的依赖注入，在线上运行的业务代码中生效。整体简化的示意图如下：![](Images/eb2586cd2a4e2be52dc9f1ae64f4d027.png){savepage-src="https://static001.geekbang.org/resource/image/e2/ce/e2295ae12fc4b83e7efc51c456f421ce.jpg"}