authenticated parts of the sites. Therefore, we also tested
the impact of TabShots on the daily use of several highly
dynamic web applications, for example social networking
applications (e.g. Facebook, Twitter) and webmail clients
(e.g. GMail, Outlook Web Access). One noticeable eﬀect is
that the addition of a single element can cause a shifting of
content within a page, which is currently ﬂagged as a major
change by the comparison algorithm. In future work, we can
implement a comparison algorithm that detects such shifts
and only marks the newly added content as a change.
5. BLACKLISTING TABNABBING
In the previous section, we described in detail the idea
and implementation of TabShots. While this is suﬃcient
for the protection of a user who has installed our browser
extension, we deem it desirable to also protect users who are
using diﬀerent browsers or have not installed TabShots. This
can be achieved through an optional server-side component
which can aggregate information sent by individual browsers
and, after validation, add the reported URLs in a blacklist.
This server-side component would be the logical next step,
to transition from a protection of a selected number of users
(those with TabShots installed) to a more global protection,
similar to Google’s SafeBrowsing list of malicious sites [15]
which is currently utilized by many modern browsers.
In
the rest of this section, we describe the possible workings of
such a service.
In the stand-alone version of TabShots, once a user realizes
that she is being targetted by a tabnabbing attack, she is
instructed to simply navigate away from the malicious site
without entering any private information. With a server-
side component in place, the user can mark the current page
as a “tabnabbing attack” through the UI of our extension.
452Figure 7: Before and after shots of americanexpress.com (#354), which has 38.93% of changed blocks, due to
a background image that took longer to load.
Figure 8: Before and after shots of mlb.com (#355), which has 97.31% of changed blocks, due to an overlay
that changed the intensity of the site to present an advertisement.
Once this happens, TabShots transfers to a server-side, data
aggregator the following information:
1. The URL of the current page
2. The image of the page before the user switched tabs
3. The image of the page after the user switched tabs
The server-side aggregator has the responsibility of receiv-
ing reports from multiple users, ﬁltering-out false reports
and then adding the true positives on a blacklist. Filtering
is necessary to stop attackers who wish to harm the reputa-
tion of the TabShots blacklist, by submitting legitimate sites
that would then be automatically blocked. Our server-side
service operates as follows:
For every previously unreported URL received by a user
with TabShots installed, our service spawns an instrumented
browser which visits the reported URL and captures a screen-
shot. Assuming that the current page is indeed performing
tabnabbing, the malicious scripts will try to get information
about their “visibility” through the window.onBlur event.
Since our browsers are instrumented, we can trigger a win-
dow.onBlur event without requiring the actual presence of
extra tabs. In the same way, any callbacks that the script
registers using the setTimeout method, are immediately
triggered, i.e., the malicious code is tricked into performing
the tabnabbing attack, without the need of waiting. Once
the callbacks are executed, our system takes another snap-
shot of the resulting page. The set of screenshots captured
by the user is then compared with the set that was captured
by our system. To account for changes in the pages due
to advertisements and other legitimately-dynamic content,
the screenshots are accepted if either the server-generated
set is an identical copy of the user-generated one, or if they
match over a certain conﬁgurable threshold (i.e. everything
matches except certain dynamic areas).
Once the above process is complete, the URLs recognized
as true positives are then sent to a human analyst who will
verify that the resulting page is indeed a phishing page. A
human analyst is necessary since our system cannot reason
towards the maliciousness or legitimacy of the ﬁnal changed
page. Note, that human-assisted phishing veriﬁcation is cur-
rently one of the most successful approaches, e.g., Phish-
Tank [13], and its results are more trustworthy than any
automated phishing-detection solution. The URLs that are
marked as “tabnabbing”, can then be added to a blacklist
that browsers can subscribe to.
The users who report URLs that either never reach a hu-
man analyst (because the server-side screenshots did not
match the user-provided ones), or reached a human analyst
and were classiﬁed as “non-phishing” are logged, so that if
they are found to consistently submit false positives, our
system may adapt to ignore their future submissions.
Submitting screenshots to a third party service might be
considered privacy-sensitive, so we take care to address these
issues accordingly. Therefore, TabShots only submits a screen-
shot after explicit user approval. Additionally, the screen-
shot submission is only triggered after the user ﬂagged a
tabnabbing attack, so it is very likely that the captured site
is malicious of nature, and does not contain any sensitive
information.
6. RELATED WORK
Raskin was the ﬁrst to present the tabnabbing attack
in 2010 [14]. Others, presented variations of the attack,
for instance redirecting the user through a meta-refresh tag
to a new page, instead of changing the existing page with
JavaScript [1], which would circumvent protections such as
NoScript [12]. This attack however does not depend on user
activity, but rather on a predeﬁned timeout, by which the
attacker hopes that the victim will have changed tabs and
thus will not notice the changing web-site.
453Unlu and Bicakci [20] proposed NoTabNab, a browser ex-
tension that monitors tabs in search for tabnabbing attacks.
When a page loads, the extension records the title of the
page, the URL, the favicon and several attributes of the
topmost elements3, as determined by the browser API call
document.elementFromPoint(x,y). While this approach is
conceptually similar to ours, NoTabNab suﬀers from several
issues that render it ineﬀective.
A ﬁrst issue is that by capturing a tab when it is loaded,
the extension will miss all content that is added dynami-
cally (e.g. using AJAX) between loading a tab and actually
switching to another tab. Second, the design of the detec-
tion mechanism oﬀers an attacker several ways to evade it.
For instance, an attacker can place all of the page’s content
in an iframe that spans the entire visible window. The docu-
ment.elementFromPoint cannot “pierce” through the iframe,
and will always return the iframe element, regardless of any
changes that may happen inside the iframe. Another pos-
sible bypass, is through the overlay of a transparent ele-
ment, that again stretches the entire page’s content and al-
lows clicks and interactions to “fall-through” to the actual
phishing form under it. On the contrary, TabShots uses the
screen-capturing API of the browser and is essentially using
the same data as actually seen by the user. This design de-
cision makes TabShots invulnerable to the aforementioned
bypasses.
Suri et al. [19] propose the detection of tabnabbing through
the use of tabnabbing “signatures”. The authors claim that
the combination of certain JavaScript APIs with HTML ele-
ments are tell-tale signs of a tabnabbing attack, and present
two signatures, based on the presence of onBlur, onFocus,
and other events within an iframe. Unfortunately, the au-
thors make no attempt to characterize the false positives
that their system would incur. Additionally, the presence of
an iframe is by no means necessary for a tabnabbing attack.
JavaScript code is capable to drastically change the appear-
ance of a page through the addition and removal of styled
HTML elements, thus allowing an attacker to bypass the
authors’ monitor. TabShots on the other hand, does not de-
pend on anything other than the visual diﬀerences between
the old and the new version of the tab, and thus will detect
all visible changes, regardless of the technical means through
which they are achieved.
While tabnabbing is a relatively new phishing technique,
attackers have been trying to convince users to voluntarily
give up their credentials for at least the last 17 years [3].
Several studies have been conducted, trying to identify why
users fall victim to phishing attacks [5, 7] and various solu-
tions have been suggested, such as the use of per-site “page-
skinning” [4], security toolbars [23], images [2, 17], trusted
password windows [16], use of past-activity knowledge [11]
and automatic analysis of the content within a page [24].
Unfortunately, the problem is hard to address in a com-
pletely automatic way, and thus, the current deployed anti-
phishing mechanisms in popular browsers are all black-list
based [15]. The blacklists themselves are either generated
automatically by automated crawlers, searching for phish-
ing pages on the web [22] or are crowdsourced [13].
3When seeing a page as a stack of elements, the topmost
elements potentially overlay other elements
7. CONCLUSION
Tabnabbing attacks are a type of phishing attacks where
the attacker exploits the trust a user places in previously
opened browser tabs, by making the malicious tab look like a
legitimate login form of a known web application. This hap-
pens when the user is looking at another tab in the browser,
making it very hard to detect and very easy to fall victim
to.
Currently available countermeasures typically depend on
several speciﬁc characteristics of a tabnabbing attack, and
are easily bypassed or circumvented. Our countermeasure,
TabShots, is the ﬁrst to do a fully visual comparison, de-
tecting any changes in an out-of-focus page and highlighting
them, aiding the user in the decision whether to trust this
page or not.
Our evaluation shows that TabShots protects users against
potential tabnabbing attacks, with a minimal performance
impact. Furthermore, an experimental evaluation using Alexa’s
top 1000 sites shows that 78% of these sites fall within the
safe threshold of less than 5% changes in subsequent snap-
shots. This means that TabShots is fully compatible with
these sites, and has very little impact on another 19%.
8. ACKNOWLEDGEMENTS
This research is partially funded by the Research Fund
KU Leuven, IWT and the EU-funded FP7 projects NESSoS
and Web- Sand.
With the ﬁnancial support from the Prevention of and
Fight against Crime Programme of the European Union
European Commission – Directorate-General Home Aﬀairs.
This publication reﬂects the views only of the authors, and
the European Commission cannot be held responsible for
any use which may be made of the information contained
therein.
9. REFERENCES
[1] E. Adler. Tabnabbing without JavaScript .
http://blog.eitanadler.com/2010/05/
tabnabbing-without-javascript.html.
[2] N. Agarwal, S. Renfro, and A. Bejar. Yahoo!’s Sign-in
Seal and current anti-phishing solutions.
[3] AOL acts to thwart hackers. http://simson.net/
clips/1995/95.SJMN.AOL_Hackers.html.
[4] R. Dhamija and J. D. Tygar. The battle against
phishing: Dynamic security skins. In Proceedings of
the 2005 symposium on Usable privacy and security,
SOUPS ’05, pages 77–88, New York, NY, USA, 2005.
ACM.
[5] R. Dhamija, J. D. Tygar, and M. Hearst. Why
phishing works. In Proceedings of the SIGCHI
conference on Human Factors in computing systems,
CHI ’06, pages 581–590, New York, NY, USA, 2006.
ACM.
[6] P. Dubroy. How many tabs do people use? (Now with
real data!). http://dubroy.com/blog/
how-many-tabs-do-people-use-now-with-real-data/.
[7] S. Egelman, L. F. Cranor, and J. Hong. You’ve been
warned: an empirical study of the eﬀectiveness of web
browser phishing warnings. In Proceedings of the
SIGCHI conference on Human factors in computing
systems, CHI ’08, pages 1065–1074, New York, NY,
USA, 2008. ACM.
454[8] D. Jang, R. Jhala, S. Lerner, and H. Shacham. An
[18] StatCounter. Screen resolution alert for web
empirical study of privacy-violating information ﬂows
in JavaScript Web applications. In Proceedings of CCS
2010, pages 270–83. ACM Press, Oct. 2010.
[9] J. Leyden. Hackers break onto White House military
network. http://www.theregister.co.uk/2012/10/
01/white_house_hack/.
[10] L. Masinter. The “data” url scheme. 1998.
[11] N. Nikiforakis, A. Makridakis, E. Athanasopoulos, and
E. P. Markatos. Alice, What Did You Do Last Time?
Fighting Phishing Using Past Activity Tests. In
Proceedings of the 3rd European Conference on
Computer Network Defense (EC2ND), volume 30,
pages 107–117, 2009.
[12] NoScript - JavaScript/Java/Flash blocker for a safer
Firefox experience! http://noscript.net/.
[13] PhishTank | Join the ﬁght against phishing.
http://www.phishtank.com.
[14] A. Raskin. Tabnabbing: A new type of phishing
attack. http://www.azarask.in/blog/post/
a-new-type-of-phishing-attack/.
[15] Safe Browsing API – Google Developers.
https://developers.google.com/safe-browsing/.
[16] D. R. Sandler and D. S. Wallach. must die! In Proceedings of W2SP
2008: Web 2.0 Security & Privacy 2008, Oakland,
CA, May 2008.
[17] SiteKey Security from Bank of America.
https://www.bankofamerica.com/privacy/
online-mobile-banking-privacy/sitekey.go.
developers.
[19] R. K. Suri, D. S. Tomar, and D. R. Sahu. An approach
to perceive tabnabbing attack. In Internation Journal
of Scientiﬁc & Technology Research, volume 1, 2012.
[20] S. Unlu and K. Bicakci. Notabnab: Protection against
the “tabnabbing attack”. In eCrime Researchers
Summit (eCrime), 2010, pages 1 –5, oct. 2010.
[21] Z. Weinberg, E. Y. Chen, P. R. Jayaraman, and
C. Jackson. I still know what you visited last summer:
Leaking browsing history via user interaction and side
channel attacks. In Proceedings of the 2011 IEEE
Symposium on Security and Privacy, SP ’11, pages
147–161, 2011.
[22] L. Wenyin, G. Huang, L. Xiaoyue, Z. Min, and
X. Deng. Detection of phishing webpages based on
visual similarity. In Special interest tracks and posters
of the 14th international conference on World Wide
Web, WWW ’05, pages 1060–1061, New York, NY,
USA, 2005. ACM.
[23] M. Wu, R. C. Miller, and S. L. Garﬁnkel. Do security
toolbars actually prevent phishing attacks? In
Proceedings of the SIGCHI conference on Human
Factors in computing systems, CHI ’06, pages
601–610, New York, NY, USA, 2006. ACM.
[24] Y. Zhang, J. I. Hong, and L. F. Cranor. Cantina: a
content-based approach to detecting phishing web
sites. In Proceedings of the 16th international
conference on World Wide Web, WWW ’07, pages
639–648, New York, NY, USA, 2007. ACM.
455