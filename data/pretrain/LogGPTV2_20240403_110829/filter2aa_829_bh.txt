the tool onto the target’s filesystem and executing it from there, but it’s not 
without risk. In fact, the EDR could catch us in a whole slew of ways:
Child Process Creation
The EDR’s process-creation callback routine could detect the creation 
of the sacrificial process. If the child of the parent process is atypical, it 
could trigger an alert.
Abnormal Module Loading
The sacrificial process spawned by the parent may not typically load the 
common language runtime if it is an unmanaged process. This may tip 
off the EDR’s image-load callback routine that in-memory .NET tra-
decraft is being used.
Common Language Runtime ETW Events
Whenever the common language runtime is loaded and run, it emits 
events through the Microsoft-Windows-DotNETRuntime ETW pro-
vider. This allows EDRs that consume its events to identify key pieces 
Evading EDR (Early Access) © 2023 by Matt Hand
248   Chapter 13
of information related to the assemblies executing on the system, such 
as their namespace, class and method names, and Platform Invoke 
signatures.
The Antimalware Scan Interface
If we’ve loaded version 4.8 or later of the .NET common language run-
time, AMSI becomes a concern for us. AMSI will inspect the contents of 
our assembly, and each registered provider will have the opportunity to 
determine whether its contents are malicious.
Common Language Runtime Hooks
While the technique isn’t directly covered in this book, many EDRs use 
hooks on the common language runtime to intercept certain execu-
tion paths, inspect parameters and return values, and optionally block 
them. For example, EDRs commonly monitor reflection, the .NET fea-
ture that enables the manipulation of loaded modules, among other 
things. An EDR that hooks the common language runtime in this way 
may be able to see things that AMSI alone couldn’t and detect tamper-
ing with the loaded amsi.dll.
Tool-Specific Indicators
The actions our tooling takes after being loaded can generate addi-
tional indicators. Seatbelt, for instance, queries many registry keys.
In short, most vendors know how to identify the execution of .NET 
assemblies in memory. Thankfully for us, there are some alternative pro-
cedures, as well as tradecraft decisions we can make, that can limit our 
exposure.
An example of this is the InlineExecute-Assembly Beacon object file, an 
open source plug-in for Cobalt Strike’s Beacon that allows operators to do 
everything that the normal execute-assembly module allows but without 
the requirement of spawning a new process. On the tradecraft side, if our 
current process is managed (as in, is .NET), then loading the common lan-
guage runtime would be expected behavior. Couple these with bypasses for 
AMSI and the .NET Runtime ETW provider and we’ve limited our detec-
tion risk down to any hooks placed into the common language runtime and 
the indicators unique to the tool, which can be addressed independently. If 
we implement these tradecraft and procedural changes, we’re in a decent 
spot to be able to run Seatbelt.
Privilege Escalation
We know that we need to expand our access to other hosts in Binford’s 
environment. We also know, from our point of contact, that our current 
user has low privileges and hasn’t been granted administrative access to 
remote systems. Remember, though, that Binford grants all domain users 
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   249
local administrator rights on their designated workstation so that they can 
install applications without overburdening their helpdesk team. All of this 
means that we won’t be able to move around the network unless we can 
get into the context of another user, but we also have options for how to 
do that.
To take on the identity of another user, we could extract credentials 
from LSASS. Unfortunately, opening a handle to LSASS with PROCESS_VM 
_READ rights can be a death sentence for our operation when facing a mod-
ern EDR. There are many ways to get around opening a handle with these 
rights, such as stealing a handle opened by another process or opening 
a handle with PROCESS_DUP_HANDLE rights and then changing the requested 
rights when calling kernel32!DuplicateHandle(). However, we’re still running 
in excel.exe (or explorer.exe, if our persistence mechanism has fired), and 
opening a new process handle may cause further investigation to occur, if it 
doesn’t generate an alert outright.
If we want to act as another user but don’t want to touch LSASS, we still 
have plenty of options, especially since we’re local administrators.
Getting a List of Frequent Users
One of my favorite ways is to target users who I know log in to the system. 
To view the available users, we can run Seatbelt’s LogonEvents module, which 
tells us which users have logged on recently. This will generate some indica-
tors related to Seatbelt’s default namespace, classes, and method names, but 
we can simply change those prior to compilation of the assembly. Once we 
get the results from Seatbelt, we can also check the subdirectories under  
C:\Users\ using dir or an equivalent directory-listing utility to see which users 
have a home folder on the system.
Our execution of the LogonEvents module returns multiple login events 
from the user PI:EMAIL over the past 10 days. We 
can assume from the name that this user is an administrator to something, 
though we’re not quite sure to what.
Hijacking a File Handler
Here are two methods for targeting users of the system on which you’re 
operating: backdooring a .lnk file on the user’s desktop for an application 
they frequently open, such as a browser, and hijacking a file handler for 
the target user through registry modification. Both techniques rely on the 
creation of new files on the host. However, the use of .lnk files has been cov-
ered extensively in public reporting, so there are likely detections around 
their creation. File-handler hijacks have gotten less attention. Therefore, 
their use may pose a smaller risk to the security of our operation.
For readers unfamiliar with this technique, let’s cover the relevant 
background information. Windows needs to know which applications open 
files with certain extensions. For instance, by default, the browser opens 
.pdf files, though users can change this setting. These extension-to-appli-
cation mappings are stored in the registry, under HKLM:\Software\Classes\ 
Evading EDR (Early Access) © 2023 by Matt Hand
250   Chapter 13
for handlers registered for the whole system and HKU:\\SOFTWARE\
Classes\ for per-user registrations.
By changing the handler for a specific file extension to a program 
that we implement, we can get our code to execute in the context of the 
user who opened the hijacked file type. Then we can open the legitimate 
application to fool the user into thinking everything is normal. To make 
this work, we must create a tool that first runs our agent shellcode and then 
proxies the path of the file to be opened to the original file handler.
The shellcode runner portion can use any method of executing our 
agent code and as such will inherit the indicators unique to that execution 
method. This is the same as was the case with our initial access payload, 
so we won’t cover the details of that again. The proxying portion can be as 
simple as calling kernel32!CreateProcess() on the intended file handler and 
passing in the arguments received from the operating system when the 
user attempts to open the file. Depending on the target of the hijack, this 
can create an abnormal parent–child process relationship as our malicious 
intermediary handler will be the parent of the legitimate handler. In other 
cases, such as .accountpicture-ms files, the handler is a DLL that is loaded 
into explorer.exe, making it so that the child process could look like a child of 
explorer.exe rather than another executable.
Choosing a File Extension
Because we’re still running in excel.exe, the modification of arbitrary file-
handler binaries may seem odd to an EDR monitoring the registry events. 
Excel is, however, directly responsible for certain file extensions, such as 
.xlsx and .csv. If detection is a concern, it’s best to choose a handler that is 
appropriate for the context.
Unfortunately for us, Microsoft has implemented measures to limit 
our ability to change the handler associated with certain file extensions 
via direct registry modification; it checks hashes that are unique to each 
app and user. We can enumerate these protected file extensions by look-
ing for registry keys with UserChoice subkeys containing a value called Hash. 
Among these protected file extensions are Office file types (like .xlsx and 
.docx), .pdf, .txt, and .mp4, to name a few. If we want to hijack Excel-related 
file extensions, we need to somehow figure out the algorithm that Microsoft 
uses to create these hashes and reimplement it ourselves.
Thankfully, GitHub user “default-username-was-already-taken” offers 
a PowerShell version of the necessary hashing algorithm, Set-FileAssoc.ps1. 
Working with PowerShell can be tricky; it’s subject to high levels of scrutiny 
by AMSI, script-block logging, and consumers monitoring the associated 
ETW provider. Sometimes the mere fact of powershell.exe spawning can trig-
ger an alert for a suspicious process.
Thus, we’ll aim to use PowerShell in the safest way possible, with the 
least risk of exposure. Let’s take a closer look at how the execution of this 
script on the target might get us caught and see what we can mitigate.
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   251
Modifying the PowerShell Script
If you review the script yourself, you’ll see that it isn’t too alarming; it 
appears to be a standard administrative tool. The script first sets up a  
P/Invoke signature for the advapi32!RegQueryInfoKey() function and adds a 
custom C# class called HashFuncs. It defines a few helper functions that inter-
act with the registry, enumerate users, and calculate the UserChoice hash. 
The final block executes the script, setting the new file handler and hash 
for the specified file extension.
This means we won’t need to modify much. The only things we need 
to worry about are some of the static strings, as those are what sensors 
will capture. We can remove a vast majority of them, as they’re included 
for debugging purposes. The rest we can rename, or mangle. These 
strings include the contents of variables, as well as the names of the vari-
ables, functions, namespaces, and classes used throughout the script. 
All of these values are fully under our control, so we can change them to 
whatever we want.
We do need to be careful with what we change these values to, 
though. EDRs can detect script obfuscation by looking at the entropy, or 
randomness, of a string. In a truly random string, the characters should 
all receive equal representation. In the English language, the five most 
common letters are E, T, A, O, and I; less commonly used letters include 
Z, X, and Q. Renaming our strings to values like z0fqxu5 and xyz123 could 
alert an EDR to the presence of high-entropy strings. Instead, we can 
simply use English words, such as eagle and oatmeal, to perform our string 
replacement.
Executing the PowerShell Script
The next decision we need to make is how we’re going to execute this 
PowerShell script. Using Cobalt Strike Beacon as an example agent, we have 
a few options readily available to us in our command-and-control agent:
 1. Drop the file to disk and execute it directly with powershell.exe.
 2. Execute the script in memory using a download cradle and powershell.exe.
 3. Execute the script in memory using Unmanaged PowerShell (powerpick) 
in a sacrificial process.
 4. Inject Unmanaged PowerShell into a target process and execute the 
script in memory (psinject).
Option 1 is the least preferrable, as it involves activities that Excel would 
rarely perform. Option 2 is slightly better because we no longer have to 
drop the script onto the host’s filesystem, but it introduces highly suspicious 
indicators, both in the network artifacts generated when we request the 
script from the payload-hosting server and in the invocation of powershell.exe 
by Excel with a script downloaded from the internet.
Option 3 is slightly better than the previous two but isn’t without its 
own risks. Spawning a child process is always dangerous, especially when 
Evading EDR (Early Access) © 2023 by Matt Hand
252   Chapter 13
combined with code injection. Option 4 is not much better, as it drops the 
requirement of creating a child process but still necessitates opening a han-
dle to an existing process and injecting code into it.
If we consider options 1 and 2 to be off the table because we don’t want 
Excel spawning powershell.exe, we’re left deciding between options 3 and 4. 
There is no right answer, but I find the risk of using a sacrificial process 
more palatable than the risk of injecting into another one. The sacrificial 
process will terminate as soon as our script completes its execution, remov-
ing persistent artifacts, including the loaded DLLs and the in-memory 
PowerShell script, from the host. If we were to inject into another process, 
those indicators could remain loaded in the host process even after our 
script completes. So, we’ll use option 3.
Next, we need to decide what our hijack should target. If we wanted to 
expand our access indiscriminately, we’d want to hijack an extension for 
the entire system. However, we’re after the user TTAYLOR.ADMIN. Since 
we have local administrator rights on the current system, we can modify the 
registry keys of a specific user through the HKU hive, assuming we know 
the user’s security identifier (SID).
Thankfully, there’s a way to get the SID from Seatbelt’s LogonEvents 
module. Each 4624 event contains the user’s SID in the SubjectUserSid field. 
Seatbelt comments out this attribute in the code to keep the output clean, 
but we can simply uncomment that line and recompile the tool to get that 
information without needing to run anything else.
Building the Malicious Handler
With all the requisite information collected we can hijack the handler 
for the .xlsx file extension for only this user. The first thing we need to do 
is create the malicious handler. This simple application will execute our 
shellcode and then open the intended file handle, which should open 
the file selected by the user in a way they’d expect. This file will need to 
be written to the target filesystem, so we know we’re going to be scanned, 
either at the time we upload it or on its first invocation based on the con-
figuration of the EDR’s minifilter. To mitigate some of this risk, we can 
obfuscate the evil handler in a way that will hopefully allow us to fly under 
the radar.
The first big issue we’ll need to conceal is the huge blob of agent shell-
code hanging out in our file. If we don’t obfuscate this, a mature scanner 
will quickly identify our handler as malicious. One of my favorite ways to 
obscure these agent shellcode blobs is called environmental keying. The gen-
eral gist is that you encrypt the shellcode using a symmetric key derived 
from some attribute unique to the system or context under which you’ll be 
running. This can be anything from the target’s internal domain name to 
the serial number of the hard drive inside the system.
In our case, we’re targeting the user TTAYLOR.ADMIN@BINFORD.
COM, so we use their username as our key. Because we want the key to 
be difficult to brute-force should our payload fall into the hands of an 
incident responder, we pad it out to 32 characters by repeating the string, 
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   253
making our symmetric key the following: TTAYLOR.ADMIN@BINFORD 
.COMTTAYLOR. We could also combine it with other attributes, such as the 
system’s current IP address, to add some more variation to the string.
Back on our payload development system, we generate the agent shell-
code and encrypt it using a symmetric key algorithm—say, AES-256—
along with our key. We then replace the non-obfuscated shellcode with 
the encrypted blob. Next, we need to add key-derivation and decryption 
functions. To get our key, our payload needs to query the executing user’s 
name. There are simple ways to do this, but bear in mind that the more 
simplistic the derivation method, the easier it will be for a skilled analyst to 
reverse the logic. The more obscure the method of identifying the user’s 
name, the better; I’ll leave finding a suitable strategy as an exercise to the 
reader. The decryption function is much more straightforward. We simply 
pad the key out to 32 bytes and then pass the encrypted shellcode and key 
through a standard AES-256 decryption implementation, then save the 
decrypted results.
Now here comes the trick. Only our intended user should be able 
to decrypt the payload, but we have no guarantees that it won’t fall into 
the hands of Binford’s SOC or managed security service providers. To 
account for this possibility, we can use a tamper sensor, which works like this. 
If decryption works as expected, the decrypted buffer will be filled with 
known contents we can hash. If the wrong key is used, the resultant buffer 
will be invalid, causing a hash mismatch. Our application can take the hash 
of the decrypted buffer before executing it and notify us if it detects a hash 
mismatch. This notification could be a POST request to a web server or 
something as subtle as changing the timestamp of a specific file on the sys-
tem we monitor. We can then initiate a full infrastructure teardown so that 
incident responders can’t start hitting our infrastructure or simply collect 
information about the failure and adjust accordingly.
Since we know we’ll deploy this payload on only one host, we opt for 
the timestamp-monitoring approach. The implementation of this method 
is irrelevant and has a very low detection footprint; we merely change 
the timestamp of some file hidden deep in some directory and then use 
a persistent daemon to watch it for changes and to notify us if it detects 
something.
Now we need to figure out the location of the legitimate handler so 
that we can proxy requests to open .xlsx files to it. We can pull this from 
the registry for a specific user if we know their SID, which our modified 
copy of Seatbelt told us is S-1-5-21-486F6D6549-6D70726F76-656D656E7-1032 
for TTAYLOR.ADMIN@BINFORD.COM. We query the xlsx value in HKU: 
\S-1-5-21-486F6D6549-6D70726F76-656D656E7-1032\SOFTWARE\Microsoft\
Windows\CurrentVersion\Extensions, which returns C:\Program Files (x86)\
Microsoft Office\Root\Office16\EXCEL.EXE. Back in our handler, we write a 
quick function to call kernel32!CreateProcess() with the path to the real 
excel.exe, passing along the first parameter, which will be the path to the 
.xlsx file to open. This should execute after our shellcode runner but 
should not wait for it to complete so that the agent being spawned is appar-
ent to the user.
Evading EDR (Early Access) © 2023 by Matt Hand
254   Chapter 13
Compiling the Handler
When it comes to compiling our handler, there are a couple of things we 
need to do to avoid detection. These include:
Removing or mangling all string constants  This will reduce the 
chance that signatures will trigger or be created based on strings used 
in our code.
Disabling the creation of program database (PDB) files  These files 
include the symbols used for debugging our application, which we 
won’t need on our target. They can leak information about our  
build environment, such as the path at which the project was 
compiled.
Populating image details  By default, our compiled handler will con-
tain only basic information when inspected. To make things look a little 
bit more realistic, we can populate the publisher, version, copyright 
information, and other details you’d see after opening the Details tab 
in the file’s properties.
Of course, we could take additional measures to further protect our 
handler, such as using LLVM to obfuscate the compiled code and signing 
the .exe with a code-signing certificate. But because the risk of this tech-
nique being detected is already pretty low and we have some protections in 
place, we’ll save those measures for another time.
Once we’ve compiled our handler with these optimizations and tested 
it in a lab environment that mimics the Binford system, we’ll be ready to 
deploy it.
Registering the Handler
Registering a file or protocol handler may seem relatively simple at face 
value; you overwrite the legitimate handler with a path to your own. Is 
that it? Not quite. Nearly every file handler is registered with a program-
matic identifier (ProgID), a string used to identify a COM class. To follow 
this standard, we need to either register our own ProgID or hijack an 
existing one.
Hijacking an existing ProgID can be risky, as it may break some func-
tionality on the system and tip the user off that something is wrong, so this 
probably isn’t the right strategy in this case. We could also look for an aban-
doned ProgID: one that used to be associated with some software installed 
on the system. Sometimes, when the software is removed, its uninstaller 
fails to delete the associated COM registration. However, finding these is 
relatively rare.
Instead, we’ll opt to register our own ProgID. It’s hard for an EDR to 
monitor the creation of all registry keys and all values being set at scale, so 
the odds are good that our malicious ProgID registration will go unnoticed. 
Table 13-3 shows the basic changes we’ll need to make under the target 
user’s registry hive.
Evading EDR (Early Access) © 2023 by Matt Hand
Case Study: A Detection-Aware Attack   255
Table 13-3: Keys to Be Created for Handler Registration
Key
Value
Description
SOFTWARE\Classes\Excel.
WorkBook.16\CLSID
{1CE29631-7A1E-4A36-
8C04-AFCCD716A718}
Provides the ProgID-to-