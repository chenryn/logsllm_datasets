worm instance even though it may be reordered within the packet datagram. Thus, by 
correlating  the  ingress  and  egress  malicious  payload,  we  are  able  to  detect  the  very 
initial  worm  propagation,  and  compute  its  signature  immediately.  Further,  if  we 
distribute these strings to collaborating sites, they too can leverage the added benefit 
of  corroborating  suspects  they  may  have  detected,  and  they  may  choose  to  employ 
content filters, preventing them from being exploited by a new, zero-day worm.  
Anomalous Payload-Based Worm Detection and Signature Generation 
239 
4.3   Evaluation 
In  this  section,  we  evaluate  the  performance  of  ingress/egress  correlation  and  the 
quality of the automatically generated signatures. 
Since  none  of  the  machines  were  attacked  by  worms  during  our  data  collection 
time  at  the  three  sites,  we  launched  real  worms  to  un-patched  Windows  2000 
machines in a controlled environment. For testing purposes, the packet traces of the 
worm  propagation  were  merged  into  the  three  sites’  packet  flows  as  if  the  worm 
infection actually  happened at each site. Since PAYL only uses payload, the source 
and target IP addresses of the merged content are irrelevant.  
Without  a  complete  collection  of  worms,  and  with  limited  capability  to  attack 
machines, we only tested CodeRed and CodeRed II out of the executable worms we 
collected. After launching these in our test environment and capturing the packet flow 
trace,  we  noticed  interesting  behavior:  after  infection,  these  two  worms  propagate 
with  packets  fragmented  differently  than  the  ones  that  initially  infected  the  host.  In 
particular,  CodeRed  can  separate  “GET.”  and  “/default.ida?”  and  “NNN…N”  into 
different  packets  to  avoid  detection  by  many  signature-based  IDSes.  The  following 
table shows the length sequences of different packet fragmentation for CodeRed and 
CodeRed II. 
Table 2. Different fragmentation for CR and CRII 
Code Red (total 4039 bytes) 
Incoming 
1448, 1448, 1143 
Code Red II (total 3818 bytes) 
Incoming 
1448, 1448, 922 
Outgoing 
1460, 1460, 898 
Outgoing 
4, 13, 362, 91, 1460, 1460, 649 
4, 375, 1460, 1460, 740 
4, 13, 453, 1460, 1460, 649 
To  evaluate  the  accuracy  of  worm  propagation  detection,  we  appended  the 
propagation trace at the very end of one full day’s network data from each of the three 
sites. When we collected the trace from our attack network, we not only captured the 
incoming  port  80  requests,  but  also  all  the  outgoing  traffic  directed  to  port  80.  We 
checked  each  dataset  manually,  and  found  there  is  a  small  number  of  outgoing 
packets for the servers that produced the datasets W and W1, as we expected, and not 
a  single  one  for  the  EX  dataset.  Hence,  any  egress  packets  to  port  80  would  be 
obviously anomalous without having to inspect their content. For this experiment, we 
captured  all  suspect  incoming  anomalous  payloads  in  an  unlimited  sized  buffer  for 
comparison across all of the available data in our test sets. We also purposely lowered 
PAYL’s threshold setting (after calibration) in order to generate a very high number 
of  suspects  in  order  to  test  the  accuracy  of  the  string  comparison  and  packet 
correlation strategies.  In other words, we increased the noise (increasing the number 
of false positives) in order to determine how well the correlation can still separate out 
the important signal in the traffic (the actual worm content).  
240 
K. Wang, G. Cretu, and S.J. Stolfo 
Table 3. Results of correlation for different metrics 
SE 
LCS(0.5) 
LCSeq(0.5) 
Detect propagate 
No 
Yes  
Yes 
False alerts 
No 
No 
No 
The  result  of  this  experiment  is  displayed  in  the  following  table  for  the  different 
similarity  metrics.  The  number  in  the  parenthesis  is  the  threshold  used  for  the 
similarity score. For an outgoing packet, PAYL checks the suspect buffer and returns 
the highest similarity score. If the score is higher than the threshold, we judge there is 
a worm propagation. False alerts suggest that an alert was mistakenly generated for a 
normal  outgoing  packet.  The  reason  why  SE  does  not  work  here  is  obvious:  worm 
fragmentation blinds the method from seeing the worm’s entire matching content. The 
other  two  metrics  worked  perfectly,  detecting  all  the  worm  propagations  with  zero 
false alerts. 
To evaluate the false alerts more carefully, we decided to use some other traffic to 
simulate the outgoing traffic of the servers. For EX data, we used the outgoing port 80 
traffic of other clients in that enterprise as if it originated from the EX server itself. 
For  the  W1  and  W  datasets,  we  used  the  outgoing  port  80  traffic  from  the  CS 
department.  Then  we  repeated  the  previous  experiments  to  detect  the  worm 
propagation with the injected outgoing traffic on each server. The result remains the 
same - using the same thresholds as before, we can successfully detect all the worm 
propagations without any false alerts. 
As  we  mentioned  earlier,  the  worm  signature  is  a  natural  byproduct  of  the 
ingress/egress correlation. When we identified a possible worm propagation, the LCS 
or  LCseq  can  be  used  as  the  worm  signature.  Figure  6  displays  the  actual  content 
signatures computed for the CR II propagations detected by PAYL in a style suitable 
for deployment in Snort. Note the signature contains some of the system calls used to 
infect  a  host,  which  is  one  of  the  reasons  the  false  positive  rate  is  so  low  for  these 
detailed signatures. 
We  replicated  the  above  experiments  in  order  to  test  if  any  normal  packet  is 
blocked when we filter the real traffic against all the worm signatures generated. For 
our experiments we used the datasets from all the three sites, which have had the CRII 
attacks cleaned beforehand, and in all cases no normal packet was blocked.  
|d0|$@|0 ff|5|d0|$@|0|h|d0| @|0|j|1|j|0|U|ff| 
5|d8|$@|0 e8 19 0 0 0 c3 ff|%`0@|0 ff|%d0@|0  
ff|%h0@|0 ff|%p0@|0 ff|%t0@|0 ff|%x0@|0 ff|%| 
0@|fc fc fc fc fc fc fc fc fc fc fc fc fc fc  
fc fc fc fc fc 0 0 0 0 0 0 0 0 0 0 0 0 0|\EXP 
LORER.EXE|0 0 0|SOFTWARE\Microsoft\Windows NT 
\CurrentVersion\Winlogon|0 0 0|SFCDisable|0 0 
 9d ff ff ff|SYSTEM\CurrentControlSet\Service 
s\W3SVC\Parameters\Virtual Roots|0 0 0 0|/Scr 
ipts|0 0 0 0|/MSADC|0 0|/C|0 0|/D|0 0|c:\,,21 
7|0 0 0 0|d:\,,217|fc fc fc fc fc fc fc fc fc 
 fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc 
… 
Fig. 6. The initial portion of the PAYL generated signature for CodeRed II 
Anomalous Payload-Based Worm Detection and Signature Generation 
241 
In  these  experiments,  we  used  an  unlimited  buffer  for  the  incoming  suspect 
payloads.  The  buffer  size  essentially  stores  packets  for  some  period  of  time  that  is 
dependent upon the traffic rate, and the  number of anomalous packet alerts that are 
generated from that traffic. That amount is indeterminate a priori, and is specific to 
both the environment being sniffed and the quality of the models computed by PAYL 
for that environment. Since CR and CR II launch their propagations immediately after 
infecting their victim hosts, a buffer holding only the most recent 5 or 10 suspects is 
enough to detect their propagation. But for slow-propagating or stealthy worms which 
might  start  propagating  after  an  arbitrarily  long  hibernation  period,  the  question  is 
how  many  suspects  should  we  save  in  the  suspect  buffer? If  the  ingress  anomalous 
payloads  have  been  removed  from  the  suspect  buffer  before  such  a  worm  starts 
propagating, PAYL can no longer detect it by correlation. Theoretically, the larger the 
buffer the better, but there is tradeoff in memory usage and computation time. But for 
those worms that may hibernate for a long period of time, cross-site collaboration and 
exchange of suspect packet payloads might provide a solution. We discuss this in the 
next section.  
5   Anomalous Payload Collaboration Among Sites 
Most current attack detection systems are constrained to a single ingress point within 
an  enterprise  without  sharing  any  information  with  other  sites.  There  are  ongoing 
efforts that share suspicious source IP address [5, 10], but to our knowledge no such 
effort exists to share content information across sites in real time until now. Here we 
focus  on  evaluating  the  detection  accuracy  of  using  collaboration  among  sites, 
assuming  a  scaleable,  privacy-preserving  secured  communication  infrastructure  is 
available. (We have implemented a prototype in Worminator [10].) 
Recall that, in Section 3.4, we described experiments measuring the diversity of the 
models computed at multiple sites. As we saw, the different sites tested have different 
normal  payload  models.  This  implies  from  a  statistical  perspective  that  they  should 
also  have  different  false  positive  alerts.  Any  “common  or highly  similar  anomalous 
payloads” detected among two or more sites logically would be caused by a common 
worm  exploit  targeting  many  sites.    Cross-site  or  cross-domain  sharing  may  thus 
reduce the false positive problem at each site, and may more accurately identify worm 
outbreaks in the earliest stages of an infection.  
To test this idea, we used the traffic from the three sites. There are two goals we 
seek  to  achieve  in  this  experiment.  One  is  to  test  whether  different  sites  can  help 
confirm with each other that a worm is spreading and attacking the Internet. The other 
is  to  test  whether  false  alerts  can  be  reduced,  or  even  eliminated  at  each  site  when 
content alerts are correlated.  
In this experiment, we used the following simple correlation rule: if two alerts from 
distinct sites are similar, the  two alerts are considered true  worm attacks; otherwise 
they  are  ignored.  Each  site’s  content  alerts  act  as  confirmatory  evidence  of  a  new 
worm  outbreak,  even  after  two  such  initial  alerts  are  generated.  This  is  very  strict, 
aiming for the optimal solution to the worm problem.  
This is a key observation. The optimal result we seek is that for any payload alerts 
generated from the same worm launched at two ore more sites, those payloads should 
242 
K. Wang, G. Cretu, and S.J. Stolfo 
be  similar  to  each  other,  but  not  for  normal  data  from  either  site  that  was  a  false 
positive. That is to say, if a site generates a false positive alert about normal traffic it 
has  seen,  it  will  not  produce suspect  payloads  that  any  other  site  will  deem  to  be  a 
worm propagation. Since we conjectured that each site’s content models are diverse 
and highly distinct, even the false positives each site may generate will not match the 
false  positives  of  other  sites;  only  worms  (i.e.,  true  positives)  will  be  commonly 
matched as anomalous data among multiple sites.  
To make the experiment more convincing, we no longer test the same worm traffic 
against each site as in the previous section, since the sensor will obviously generate 
the  exact  same  payload  alert  at  all  the  sites.  Instead,  we  use  multiple  variants  of 
CodeRed  and  CodeRed  II,  which  were  extracted  from  real  traffic.  To  make  the 
evaluation strict, we tested different packet payloads for the same worm, and all the 
variant packet fragments it generates. We purposely lowered the PAYL threshold to 
generate many more false positives from each site than it otherwise would produce.  
As in the case described above the cross-site correlation uses the same metrics (SE, 
LCS  and  LCSeq)  to  judge  whether  two  payload  alerts  are  “similar”.    However, 
another  problem  that  we  need  to  consider  when  we  exchange  information  between 
sites is privacy. It may be the case that a site is unwilling to allow packet content to be 
revealed to some external collaborating site. A false positive may reveal true content.  