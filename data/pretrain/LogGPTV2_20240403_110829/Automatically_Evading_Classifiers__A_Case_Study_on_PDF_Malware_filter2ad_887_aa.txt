title:Automatically Evading Classifiers: A Case Study on PDF Malware
Classifiers
author:Weilin Xu and
Yanjun Qi and
David Evans
In Network and Distributed System Security Symposium 2016 (NDSS), San Diego, February 2016
Automatically Evading Classiﬁers
A Case Study on PDF Malware Classiﬁers
Weilin Xu, Yanjun Qi, and David Evans
University of Virginia
http://www.EvadeML.org
Abstract—Machine learning is widely used to develop classi-
ﬁers for security tasks. However, the robustness of these methods
against motivated adversaries is uncertain. In this work, we
propose a generic method to evaluate the robustness of classiﬁers
under attack. The key idea is to stochastically manipulate a
malicious sample to ﬁnd a variant that preserves the malicious
behavior but is classiﬁed as benign by the classiﬁer. We present
a general approach to search for evasive variants and report on
results from experiments using our techniques against two PDF
malware classiﬁers, PDFrate and Hidost. Our method is able to
automatically ﬁnd evasive variants for both classiﬁers for all of
the 500 malicious seeds in our study. Our results suggest a general
method for evaluating classiﬁers used in security applications, and
raise serious doubts about the effectiveness of classiﬁers based
on superﬁcial features in the presence of adversaries.
I.
INTRODUCTION
Machine learning models are popular in security tasks such
as malware detection, network intrusion detection and spam
detection. From the data scientists’ perspective, these models
are effective since they achieve extremely high accuracy on
test datasets. For example, Dahl et al. reported achieving
99.58% accuracy in classifying Win32 malware using an
ensemble deep neural network with dynamic features [9].
ˇSrndic et al. achieved over 99.9% accuracy in a PDF malware
classiﬁcation task using an SVM-RBF model with structural
path features [28].
However, it is important to realize that these results are for
particular test datasets. Unlike when machine learning is used
in other ﬁelds, security tasks involve adversaries responding to
the classiﬁer. For example, attackers may try to generate new
malware deliberately designed to evade existing classiﬁers.
This breaks the assumption of machine learning models that
the training data and the operational data share the same
data distribution. As a result, it is important to be skeptical
of machine learning results in security contexts that do not
consider attackers’ efforts to evade the generated models.
The risk of evasion attacks against machine learning mod-
els under adversarial settings has been discussed in the ma-
chine learning community, mainly focused on simple models
for spam detection (e.g.,
[10, 18]). However, evasion attacks
against malware classiﬁcation can be much more complex in
terms of the classiﬁcation algorithm and the feature extrac-
tion as well as the mutability of highly-structured samples.
Consequently, though evading malware classiﬁers has been
partially explored by classiﬁer authors as well as security
researchers, previous studies signiﬁcantly under-estimate the
attackers’ ability to manipulate samples. For example, previous
studies may mistakenly assume the attackers can only insert
new contents because removing existing contents would easily
corrupt maliciousness [4, 20, 28]. In addition, previous works
are ad hoc and limited to particular target classiﬁers or speciﬁc
types of samples [20, 29]. Other than suggesting point solu-
tions, they do not provide methods to automatically evaluate
the effectiveness of a classiﬁer against adaptive adversaries.
We present a generic method to assess the robustness of a
classiﬁer by simulating attackers’ efforts to evade the classiﬁer.
We do not assume the adversary has any detailed knowledge of
the classiﬁer or the features it uses, or can use targeted expert
knowledge to manually direct the search for an evasive sample.
Instead, drawing ideas from genetic programming (GP) [11,
15], we perform stochastic manipulations and then evaluate
the generated variants to select promising ones. By repeating
this procedure iteratively, we aim to generate evasive variants.
A sophisticated attacker, of course, can do manipulations that
would not be found by a stochastic search, so we cannot claim
that a classiﬁer that resists such an attack is necessarily robust.
On the other hand, if the automated approach ﬁnds evasive
samples for a given classiﬁer, it is a clear sign that the classiﬁer
is not robust against a motivated adversary.
We evaluated the proposed method on two PDF malware
classiﬁers, and found that it could automatically ﬁnd evasive
variants for all the 500 sample seeds selected from the Con-
tagio PDF malware archive [5]. The evasive variants exhibit
the same malicious behaviors as the original samples, but
are sufﬁciently different in the classiﬁer’s feature space to be
classiﬁed as benign by the machine learning-based models.
Our analysis of the discovered evasive variants reveals that
both classiﬁers are vulnerable because they employ non-robust
features, which can be manipulated without disrupting the
desired malicious behavior. Superﬁcial features may work well
on test datasets, but if the features used to classify malware
are shallow artifacts of the training data rather than intrinsic
properties of malicious content, it is possible to ﬁnd ways to
preserve the malicious behavior while disrupting the features.
Contributions. Our primary contributions involve developing
and evaluating a general method for automatically ﬁnding
variants that evade classiﬁers. In particular:
• We propose a general method to automatically ﬁnd
evasive variants for target classiﬁers. The method
does not rely on any speciﬁc classiﬁcation algorithms
or assume detailed knowledge of feature extraction,
but only needs the classiﬁcation score feedback on
generated variants and rough knowledge of the likely
features used by the classiﬁer (Section II).
• We implement a prototype system that automatically
ﬁnds variants that can evade structural feature-based
PDF malware classiﬁers. This involves designing op-
erators that perform stochastic manipulations on PDF
ﬁles, an oracle that determines if a generated variant
preserves maliciousness, a selection mechanism that
promotes promising variants during the evolutionary
process, and a ﬁtness function for each target classiﬁer
(Section IV).
• We evaluate the effectiveness of our system in evading
two recent PDF malware classiﬁers: PDFrate [25] and
Hidost [28], a classiﬁer designed with the explicit goal
of resisting evasion attempts. Our system achieves
100% success rates in ﬁnding evasive variants against
both classiﬁers in an experiment with 500 malware
sample seeds. An analysis of the discovered evasive
variants in the feature space of each classiﬁer shows
that many non-robust features employed in the classi-
ﬁcation facilitate evasion attacks (Sections V and VI).
We provide background on machine learning classiﬁers in
Section II and on PDF malware in Section III. Section VIII
discusses related work on evasion attacks.
II. OVERVIEW
We propose an automated method to simulate an attacker
attempting to ﬁnd an evasive variant for a desired malware
sample which is detected by a target classiﬁer. The attacker’s
goal is to ﬁnd a malware variant that preserves the malicious
behavior of the original sample, but that is misclassiﬁed as
benign by the target classiﬁer. In addition to improving our
understanding of how classiﬁers work in the presence of
adaptive adversaries, we hope our results will lead to strategies
for constructing classiﬁers that are more robust to adversaries,
but in this work we focus on assessing evadability.
A. Machine Learning Classiﬁers
Machine learning learns from and makes predictions on
data. A machine learning-based classiﬁer attempts to ﬁnd a
hypothesis function f
that maps data points into different
classes. For example, a malware classiﬁcation system would
ﬁnd a hypothesis function f that maps a data point (a piece
of malware sample) into either benign or malicious.
The effort to train a machine learning system starts with
feature extraction. As most machine learning algorithms cannot
operate on highly-structured data, the data samples are usually
represented in a specially-designed feature space. For example,
a malware classiﬁer may extract the ﬁle size and the function
call traces as features. Each feature is a dimension in the
feature space; consequently, every sample is represented as
a vector. An extra step of feature selection may be performed
to reduce the number of features when the number of features
is too large for the classiﬁcation algorithm.
The most widely used machine learning algorithms in
security tasks use supervised learning, in which the training
dataset comes with labels identifying the class of every training
sample. The hypothesis function f
is trained to minimize
the prediction error on the training set. This function usually
results in a low error rate on the operational data under the
stationarity assumption that the distribution over data points
encountered in the future will be the same as the distribution
over the training set.
Machine learning has produced impressive results and is
widely deployed for speciﬁc security tasks including malware
classiﬁcation. Without examining the behavior of suspicious
malware in a real system, malware classiﬁers often employ
static properties to predict maliciousness such as the ﬁle
structure, ﬁle size, metadata, grams of tokens or system
calls. Although this approach often achieves high accuracy
in validation tests, the classiﬁer may learn properties that are
superﬁcial artifacts of the training data, rather than properties
that are inherently associated with malware. This is because
malware samples in the training data are likely to differ from
the benign samples in many ways that are not essential to their
malicious behavior.
B. Threat Model
We assume an attacker starts with a desired malicious
is (correctly) classiﬁed by a target classiﬁer
sample that
as malicious, and wants to create a sample with the same
malicious behavior, but that is misclassiﬁed as benign. The
attacker is capable of manipulating the malicious sample in
many ways, and is likely to have knowledge of samples that
are (correctly) classiﬁed as benign.
We assume the attacker has black-box access to the target
classiﬁer, and can submit many variants to that classiﬁer. For
each submitted variant, the attacker learns its classiﬁcation
score. The classiﬁcation score is a number (typically a real
number between 0 and 1) that indicates the classiﬁer’s predic-
tion of maliciousness, where values above some threshold (say
0.5) are considered malicious and samples with lower classi-
ﬁcation scores are considered benign. We do not assume the
attacker has any internal information about the classiﬁer, only
that it can use it as a black-box that outputs the classiﬁcation
score for an input sample. We assume the classiﬁer operator
does not adapt the classiﬁer to submitted variants (which must
be the case if the attacker has ofﬂine access to the classiﬁer).
C. Finding Evasive Samples
Our method uses genetic programming techniques to per-
form a directed search of the space of possible samples to
ﬁnd ones that evade the classiﬁer while retaining the desired
malicious behavior.
Genetic programming (GP) is a type of evolutionary al-
gorithm, originally developed for automatically generating
computer programs tailored to a particular task [11, 15]. It
is essentially a stochastic search method using computational
analogs of biological mutation and crossover to generate vari-
ants, and modeling Darwinian selection using a user-deﬁned
ﬁtness function. Variants with higher ﬁtness are selected for
continued evolution, and the process continues over multiple
generations until a variant with desired properties is found (or
the search is terminated after exceeding a resource bound).
Genetic programming has been shown to be effective in many
tasks including ﬁxing legacy software bugs [17], software
reverse engineering [13], and software re-engineering [23].
Method. Our procedure is illustrated in Figure 1. It starts with
a seed sample that exhibits malicious behavior, and is classiﬁed
as malicious by the target classiﬁer. Our method aims to ﬁnd
an evasive sample that preserves the malicious behavior but is
misclassiﬁed as benign by the target classiﬁer.
2
Fig. 1. Generic classiﬁer evasion method.
First, we initialize a population of variants by performing
random manipulations on the malicious seed. Then, each
variant is evaluated by a target classiﬁer as well as an oracle.
The target classiﬁer is a black box that outputs a number that
is a measure of predicted maliciousness of an input sample.
There is a prescribed threshold used to decide if it is malicious
or benign. The oracle is used to determine if a given sample
exhibits particular malicious behavior. In most instantiations,
the oracle will involve expensive dynamic tests.
A variant that is classiﬁed as benign by the target classiﬁer,
but found to be malicious by the oracle, is a successful evasive
sample. If no evasive samples are found in the population,
a subset of the generated variants are selected for the next
generation based on a ﬁtness measure designed to reﬂect
progress towards ﬁnding an evasive sample. Since it is unlikely
that the transformations will re-introduce malicious behaviors
into a variant, corrupted variants that have lost the malicious
behavior are replaced with other variants or the original seed.
Next, the selected variants are randomly manipulated by
mutation operators to produce next generation of the popula-
tion. The process continues until an evasive sample is found
or a threshold number of generations is reached.
To improve the efﬁciency of the search, we collect traces
of the mutation operations used and reuse effective traces. If
a search ends up ﬁnding any evasive variants, the mutation
traces on the evasive variants will be stored as successful
traces. Otherwise, the mutation trace of a variant with the
highest ﬁtness score is stored. These traces are then applied to
other malware seeds to generate variants for their population
initialization. Because of the structure of PDFs and the nature
of the mutation operators, the same sequence of mutations can
often be applied effectively to many initial seeds.
III. PDF MALWARE AND CLASSIFIERS
This section provides background on PDF malware and the
two target PDF malware classiﬁers.
A. PDF Malware
The Portable Document Format (PDF) is a popular docu-
ment format designed to enable consistent content and layout
in rendering and printing on different platforms. Although it
was not openly standardized until 2008 [1], and there are
Fig. 2. The physical and logical structure of a PDF ﬁle.
various non-standard extensions supported by different PDF
reader products, all PDF ﬁles roughly share the same basic
structure depicted in Figure 2.
A PDF ﬁle consists of four parts: header, body, cross-
reference table (CRT) and trailer. The header contains the
PDF magic number and a format version indicator. The body
is a set of PDF objects that comprise the content of the ﬁle,
while the CRT indexes the objects in body. The trailer speciﬁes
how to ﬁnd the CRT and other special objects such as the root
object. Thus, PDF readers typically start reading a PDF from
the end of the ﬁle for efﬁciency.
The body is the most important to a PDF since it holds
almost all the visible document data. It contains eight basic
types of objects, namely Booleans, numbers, strings, names,
arrays, dictionaries, streams and the null objects. The objects
can be labeled with a pair of integer identiﬁers as indirect
objects so that they can be referenced by other objects. The
inter-referencing objects form a tree-like logical structure, as
is shown in the right of Figure 2. This tree-like structure is
ideally suited to genetic programming techniques since it is
easy to alter and move sub-trees to generate new variants.
PDF malware is becoming increasing prevalent because
PDF is a widely accepted document format and victims are
more willing to open PDFs than other ﬁles. According to a
recent Internet security threat report [30], PDF is in top 7
attachment types in spear-phishing emails in 2014. We expect
there will be continuing opportunities for PDF malware attacks
because 128 new vulnerabilities in Acrobat readers have been
reported in CVE so far in 2015 (through 8 December), which
3
Population InitializationYesNoMutationSelect VariantsMalicious SamplePopulationTarget ClassifierOracleFitnessFunctionEvasive Variants Found?FailureMax GenerationReached?YesNoSuccessBenign Samples1 0 obj >>> endobj2 0 obj > endobj3 0 obj > endobjHeaderBodyCross-reference tableTrailer/Catalog/JavaScriptalert(‘hello’);/Type/Type/OpenAction/Pages/Kids/Pages/Page001285461.../Count/MediaBox/Resources/S/JS0/Type2 0 R/Parentis almost three times the total number in 2014 [8].
PDF malware typically contains exploits in JavaScript
objects or other objects that take advantage of vulnerabilities
of particular PDF readers (most commonly, Adobe Acrobat).
PDF malware may also carry other encoded payloads in stream
objects which will be triggered after exploits [25].
B. Target Classiﬁers
Several projects have built PDF malware classiﬁers using
machine learning techniques. Earlier works, such as Wepawet
[7] and PJScan [16], focused on the embedded malicious
JavaScript in PDF malware. These tools consist of a JavaScript
code extractor and a dynamic or static malicious JavaScript
classiﬁer.
Since not all PDF malware involves embedded JavaScript,
and PDF malware authors have found many tricks for hiding
JavaScript code [24], recent PDF malware classiﬁers have
focused on structural features of PDF ﬁles. In this work, we
target state-of-the-art structural feature-based classiﬁers.
Structural feature-based classiﬁers assume that the mali-
cious PDFs have different patterns in their internal object
structures than those found in benign PDFs. For example,
the PDF Malware Slayer tool uses the object keywords as
features, where each feature corresponds to the occurrences
of a given keyword [19]. For our experiments, we selected
PDFrate [25, 26] and Hidost [28] as the target classiﬁers.
They are representatives of recent PDF malware classiﬁers,
and Hidost was developed with a particular goal of being
resilient to evasion attacks. Both classiﬁers achieve extremely
high accuracy in malware detection on their testing datasets.
The other reason for choosing these classiﬁers as our targets is
the availability of the open source implementations. Although
our method only requires black-box access to the classiﬁer,
having access to the internal feature space is beneﬁcial for
understanding our results (Section VI).
PDFrate. PDFrate is a random forest classiﬁer that uses an
ensemble learning model consisting of a large number of de-
cision trees designed to reduce variance in predictions. With a
random subset of training data and a random subset of features,
each decision tree is trained to minimize the prediction error on
its training subset. After training, the output score of PDFrate
is the fraction of trees that output “malicious”, ranging from 0
to 1. The threshold value is typically 0.5, although the PDFrate
authors claim that adjusting the threshold from 0.2 to 0.8 has
little impact on accuracy because most samples have scores
very close to either 0 or 1.
Besides object keywords, PDFrate also employs the PDF
metadata and several properties of objects as the classiﬁcation
features. The PDF metadata includes the author, title, and
creation date. The object properties includes positions, counts,
and lengths.
PDFrate was trained with a random subset of the Contagio
dataset [5] with 5,000 benign and 5,000 malicious PDFs. The
two parameters are respectively the number of trees (ntree =
1,000) and the number of features in each tree (mtry = 43).
The feature set is a total of 202 integer, ﬂoating point, and
Boolean features, but only 135 of the features are described in
the PDFrate documentation.
What we use in this work is an open-source re-
implementation of PDFrate named Mimicus [27], implemented
by Nedim ˇSrndic and Pavel Laskov to mimic PDFrate for
malware evasion experiments [29]. Mimicus was trained with
the 135 documented PDFrate features and the same training set
as PDFrate.1 Mimicus has been shown to have classiﬁcation
performance nearly equivalent to PDFrate [29].
Hidost. Hidost is a support vector machine (SVM) classiﬁ-
cation model. SVM is an optimal margin classiﬁer that tries
to ﬁnd a small number of support vectors (data points) that
separate all data points of two classes with a hyperplane of a
high-dimensional space. With kernel tricks, it can be extended
as a nonlinear classiﬁer to ﬁt more complex classiﬁcation
problems. Hidost uses a radial basis function (RBF) kernel to
map data points into an inﬁnite dimensional space. At testing
time, the (positive or negative) distance of a data point to
the hyper-plane is output as the prediction result. A positive
distance is interpreted as malicious, and negative as benign.
Hidost uses the structural paths of objects as classiﬁcation
features. For example, the structural path of a typical Pages
object is /Root/Pages. If that object appears in the PDF ﬁle,
its feature value is 1; if not, its feature value is 0. Since the
number of possible structural paths of PDF objects is inﬁnite,
Hidost uses 6,087 selected paths as features. The selected paths
are those which appeared in at least 1,000 of the ﬁles in a
pool of 658,763 benign and malicious PDFs collected from