issued (say n). We can use such a t-bounded FE to instan-
tiate a CPE facing t corrupted users. Unfortunately, the
parameters in [15] were chosen in a way that the ciphertext
size is as big as O(D2t6λτ ), where D is the maximum de-
gree of the polynomial representing the circuits describing
the functions that FE supports, and τ is the ciphertext size
of the underlying 1-query secure FE. For some parameters
d, N , in the construction, there are N 1-query secure FE in-
stances. The encryption algorithm will do a (d+1, N ) secret
sharing on the message and will encrypt each share indepen-
dently under the N 1-query FE instances. Each user will be
assigned a random subset (denoted by Γi, and |Γi| = dD+1)
of keys each of which is generated using the corresponding
master secret key. Note that prior to encrypting each share
is padded with additional randomness to ensure the simu-
lation can succeed.
In total there are N ciphertexts each
encrypting O(t2λ) plaintext elements. (See [15] for details.)
Reference [15] requires that the collusion of size t can not
break enough 1-query secure FE instances to get d+1 shares
and obtain extra information about the message. More
speciﬁcally, it requires |∪i(cid:54)=j(Γi∩Γj)| ≤ d. We observe that if
we can replace this condition to be |∪i1,...,ia (∩ia
Γij )| ≤ d,
for any integer a ≥ 2, through a probabilistic analysis, we
can bring down N to O((Dt)1+eλ) (for e = 1/(a − 1)). Do-
ing this optimization requires us to use an a-query secure FE
as the underlying building block. We can obtain a succinct
a-query secure FE for some polynomially bounded a by ap-
plying the technique of [15] to the succinct 1-query secure
FE of [14].
In this way we obtain a a-query FE that has
ciphertext size O(poly(λ)) which is independent from the
number of users. Then we can apply the extended proba-
bilistic analysis explained above and to obtain a t-query FE
with ciphertext O(t3+epoly(λ)). Note that we are using cir-
cuits for the comparison predicate only and thus the degree
D of the polynomial representing the circuits is at most λ.
Our CPE instantiation. Our ﬁnal CPE instantiation will
be a hybrid of the two instantiations above. When t ≤
1
3+e , we use instantiation-II, the optimized t-FE; when t >
n
1
3+e , we simply use instantiation-I of n-query secure FE.
n
The resulting TDS will be with ciphertext size min[O(t3+e ·
poly(λ)), O(n · poly(λ))]. As the succinct 1-query FE can
be built on fully homomorphic encryption [6] and attribute
based encryption [16], both of which can be based on the
LWE assumption [29] eﬃciently. We summarize the above,
and refer detailed analysis to the appendix.
Corollary 4.5 Under the subexponential LWE assumption,
there exists a TDS satisfying: fully collusion resilient, black-
box traitor deterring w.r.t to any message distribution D with
H∞(D) ≥ − log(δ− α) for some non-negligible α, where δ is
the correctness probability provided by the pirate box and δ ≥
1.5α, and the parameters N = α−2log2 λ, n0 = (δ − α
2 )N .
It has ciphertext length min[O(t3+e · poly(λ)), O(n· poly(λ))],
where n, t are total number of users and corrupted users,
e = 1/poly(λ), and λ the security parameter.
5. TRAITOR DETERRING IN THE KNOWN
CIPHERTEXT MODEL
In the known ciphertext model for TDS, the adversary has
a weaker goal: it aims to produce a pirate box that works
w.r.t. a given sequence of ciphertexts.
Because the sequence of ciphertexts is ﬁxed there is a triv-
ial way to implement the pirate decoder: simply store a
database of all the plaintexts. Thus, in the known cipher-
text model, the adversary should only win when the size of
the decoder is smaller than the trivial attack; formally, we
will associate an attack in this model with a “space rate”
that is equal to the size of the pirate box divided by the
length of the total plaintext contained in the known cipher-
text. An ideally secure scheme should work with respect to
any space rate o(1).
The known ciphertext model is applicable to the setting
of distributing content via CDs, or granting access to an
encrypted database, since in these cases, the attack occurs
after the target ciphertexts become known. (In contrast, the
original traitor deterring model is applicable to all other set-
tings, e.g., online streaming, and movie distribution in Pay-
TV etc.). Traitor deterring in the known ciphertext model
reformulates in the black-box public-key setting the prob-
lem of constructing digital signets as posed in [12]. In [12] a
construction for any space rate o(1) is presented however
it requires the unfalsiﬁable assumption that the function
f (x) = gx
is incompressible (as well as they
assume non-black-box recoverability). They leave as open
question whether a construction exists that is secure under
a falsiﬁable assumption; using our TDS’s we resolve this
open question in this section.
5.1 Deﬁnition: the known ciphertext model.
2|| . . .||gx
1||gx
(cid:96)
We provide the formal deﬁnition of the known ciphertext
model that strengthens our traitor deterring deﬁnition.
(1 − )-correctness. Since the pirate box B may work only
for the ﬁxed set of ciphertext SC = {c1, . . . , cn}, we require
for SC, it almost always works, i.e., Pr[B(i, ci) = mi] ≥ 1−
negl(λ), where mi is the Θ(λ) bit plaintext that is encrypted
in ci (note we also allow B to receive the index of ci).
Privacy: This is the same as in section 2.
Traitor Deterring for Known Ciphertexts. The main diﬀer-
ence with the traitor deterring property is that the adversary
is aware of the ciphertexts before making the device B, and
hence can embed some information into B so that B is able
to check the decryption queries and only works for the given
ciphertexts. Formally,
• The challenger C simulates the Setup algorithm and
the adversary A receives pk. A then sends to C a vec-
tor of secret information s1, . . . , sn, an arbitrary subset
T ⊆ {1, . . . , n} as well as a distribution Pk with sup-
port set that contains k-long vectors of plaintexts for
some k = O(poly(λ)). 3 A receives the secret keys
of all users in T , {ski | i ∈ T} as well as the public
parameter para.
• C samples (m1, . . . , mk) from Pk and sends A, the se-
quence of ciphertexts SC = (cid:104)c1, . . . , ck(cid:105) where ci =
Enc(pk, mi); ﬁnally, A outputs an implementation B.
• C outputs 1 if and only if RecB(pk, para) (cid:54)∈ {si1 , . . . , sit}.
A
We denote the event that C outputs 1 in the above game by
(1λ). We say a scheme achieves black-box traitor
SuccKCdeter
deterring for known ciphertexts with space rate s(k, λ) if for
any PPT adversary A,
3This includes the case of encrypting one single long message
(e.g., a movie ﬁle): it is ﬁrst divided into k blocks and each
block is encrypted individually.
239A
(1λ)]
kλ
Pr[B is (1 − )-correct w.r.t SC∧|B|
≤ s(k, λ)∧SuccKCdeter
is a negligible function on λ, where |B| denotes the size of
the program B. Note that for s(k, λ) = Θ(1) it is trivial to
construct a device B that allows the adversary to win the
above game — simply store all plaintexts m1, . . . , mk in B.
Thus, the question that is raised is whether it is possible to
deter with space rate that is o(1).
5.2 Feasibility and infeasibility for the known
ciphertext model.
At ﬁrst sight, it may seem impossible to have a black-
box recovering algorithm in the known ciphertext setting,
since the Rec algorithm is restricted by the fact that the
adversarial box is only guaranteed to work for a ﬁxed set of
ciphertexts. Indeed, although the size of B can be smaller
than the size of the ciphertexts it is supposed to work for,
there are ways for the adversary to embed some information
and check whether a submitted ciphertext belongs to the
targeted sequence, while reject all other ciphertexts submit-
ted to it. We formalize this intuition and we show a simple
attack following this principle that rules out the possibility
of black-box traitor deterring for known ciphertexts for a
range of space rates. However, we also observe that in order
for the box B to perform a membership test in the tar-
geted ciphertext sequence, the false positive probability of
the testing algorithm increases as the storage used by B gets
smaller. When the false positive probability becomes suﬃ-
ciently high, a random sample of ciphertext will be answered
by the box B with non-negligible probability δ, and thus B
becomes a δ−correct box in the regular model (as deﬁned
section 2); in this way, we can still apply our constructions
of TDS’s against known ciphertext type of attacks. For ease
of presentation, we consider only the 1-correct case, while
all results will also follow for the case of (1 − )-correctness.
The intuition behind the proof of the following theorem
is that when the suitable space bound is imposed on the pi-
rate device, it will have to resort to using the secret-key in a
suﬃciently large plaintext distribution that can be sampled
with a non-negligible probability from the plaintext space.
As a result, the decryption box, is a general purpose decryp-
tion box that is δ-correct for some non-negligible δ and thus
our recoverability algorithms developed for traitor deterring
can be applied in the known ciphertext model as well.
Theorem 5.1 There exists a TDS with superpolynomial in
λ plaintext space that satisﬁes black-box traitor deterring for
known ciphertexts with space rate s(k, λ) = O(log(λ)/λ) =
o(1) for any k = Ω(λ).
Proof. We will show that a TDS satisfying black-box
traitor deterring with any pirate box with λ−c-correctness
is also a TDS with black-box traitor deterring in the known
ciphertext model for any c ∈ N for the stated space rate.
First, we recall a lower bound of the false positive proba-
bility in the approximate membership testing problem (see
deﬁnition A.1 in the appendix) fwhen the space of the tester
is upper bounded. For a universe U with size u, and V ⊂ U
with size v, and v (cid:28) u, using space τ , the false positive η
of any membership tester satisﬁes 2τ ≤ (2η)v. (see Lemma
A.2 in the appendix).Applying logarithm to both sides, we
v −1, thus if τ ≤ c· v · log λ, we have η ≥ λ−c.
can get η ≥ 2− τ
Next, we will use the above result to show that a useful de-
cryption box B with size O(k· log λ) will have non-negligible
correctness w.r.t. uniform distribution over the message
space. Speciﬁcally, we will build an approximate member-
ship tester T (using B) for V = {(m1, c1), . . . , (mk, ck)}, a
subset of the universe U of all plaintext/ciphertext pairs,
with a similar storage as follows. Whenever queried a uni-
formly random pair (m, c), T queries B with c, if B outputs
m, T outputs 1, otherwise T outputs 0. It is easy to see that
if (m, c) ∈ V , T always accepts; if (m, c) (cid:54)∈ V , T accepts
with probability δ, where δ = Pr[B(c) = m ∧ (m, c) (cid:54)∈ V ].
Furthermore, T only needs an extra storage of O(λ) bits
to store the query and compare whether the answer of B
is valid. In the setting that k = Ω(λ), the storage of T is
still O(k · log(λ)). Observe that if δ is negligible, T is a
membership tester which violates the bound in Lemma A.2.
With the above claim, we can see that for a randomly
sampled ciphertext, the box B will answer with some prob-
ability δ and thus we can run the Rec algorithm and retrieve
the corresponding secret information of one of the colluders
assuming that the TDS works for δ w.r.t any distribution
D for which it holds that δ ≥ 2−H∞(D) + α where α is an
arbitrary non-negligible function.
Impossibility results. Next we will show that the above
bound of the size of B is essentially tight, by describing
a generic attack against any traitor deterring scheme for
known ciphertexts. The attacking strategy is simple: using
Bloom ﬁlters [1] the adversary produces a box that contains
a membership tester built in so that it will answer only when
the decryption query belongs to the ciphertext set. This
makes two boxes implemented using diﬀerent keys indistin-
guishable via only oracle access, thus black-box recoverabil-
ity will contradict privacy in this setting. For details of the
proof we refer to the appendix.
Proposition 5.2 There does not exist any, even 1-resilient,
black-box TDS in the known ciphertext model for space rate
s(k, λ) = Ω(log2 λ/λ) for any k.
6. USING BITCOIN AS COLLATERAL
Bitcoin is a decentralized cryptocurrency [25] that uses a
publicly maintained ledger to store transactions and record
transfers between bitcoin accounts. Each bitcoin account
is essentially a hash of a public-key and the owner of the
secret-key has the ability to transfer funds from the account
by posting a transaction in the bitcoin network that con-
tains a signature generated by the account’s secret-key. The
characteristic of bitcoin accounts is that the secret-keys rep-
resent complete ownership of the account.
We consider a TDS deployment for a broadcast service
where a service provider (SP) wants to use a certain amount
of bitcoin as collateral. Upon initiation of the service the
SP generates bitcoin accounts corresponding to each of the
n users setting si = (ai, ki) where ai is the bitcoin address
and ki is the associated secret-key. When a user joins the
system it requests from the user to transfer some amount
of x bitcoin to the ai bitcoin account. The SP shares the
account information (ai, ki) with the user so that it is en-
sured that the x bitcoin is a collateral and the user has the
option to obtain the collateral back whenever she wishes
(and cancel her subscription). The SP then embeds si into
the public directory. At the same time the SP gives to the
user the secret-key ski that corresponds to the account, and
sets a service agreement that the account should be “frozen”
such that no outgoing transaction is allowed until the user
240unsubscribes the service. The user from this point on can
use the service and decrypt ciphertexts associated with the