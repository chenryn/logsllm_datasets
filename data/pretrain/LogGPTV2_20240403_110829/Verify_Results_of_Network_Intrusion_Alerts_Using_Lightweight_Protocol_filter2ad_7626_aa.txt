title:Verify Results of Network Intrusion Alerts Using Lightweight Protocol
Analysis
author:Jingmin Zhou and
Adam J. Carlson and
Matt Bishop
Verify Results of Network Intrusion Alerts Using Lightweight Protocol Analysis
Jingmin Zhou, Adam J. Carlson, Matt Bishop
Computer Security Laboratory
University of California, Davis
{zhouji, carlsona, bishop}@cs.ucdavis.edu
Abstract
We propose a method to verify the result of attacks de-
tected by signature-based network intrusion detection sys-
tems using lightweight protocol analysis. The observation
is that network protocols often have short meaningful status
codes saved at the beginning of server responses upon client
requests. A successful intrusion that alters the behavior of
a network application server often results in an unexpected
server response, which does not contain the valid protocol
status code. This can be used to verify the result of the intru-
sion attempt. We then extend this method to verify the result
of attacks that still generate valid protocol status code in the
server responses. We evaluate this approach by augmenting
Snort signatures and testing on real-world data. We show
that some simple changes to Snort signatures can effectively
verify the result of attacks against the application servers,
thus signiﬁcantly improve the quality of alerts.
1. Introduction
An intrusion is traditionally deﬁned as an action that suc-
cessfully violates the security policy. Anderson deﬁnes a
penetration as a successful attack [2]. Mukherjee et. al.
deﬁne intrusions as unauthorized use, misuse and abuse of
computer systems [17]. Denning deﬁnes intrusions as secu-
rity violations [8]. All these deﬁnitions state that an intru-
sion is a successful violation of the security policy.
However, today’s intrusion detection systems (IDSes)
often try to detect not only intrusions, but also unsuccess-
ful intrusion attempts. This is because it can be difﬁcult for
an IDS to determine the result of an intrusion attempt [21];
therefore the IDS assumes the worst and reports alerts for
every observed intrusion attempt. Moreover, an intruder of-
ten tries several unsuccessful attacks until he ﬁnally suc-
ceeds. Each attack raises its own alerts. Detecting on-
going attempts can help intrusion prevention by blocking
attacks before they succeed. These have contributed to a
well-known problem: too many alerts are reported to be ef-
fectively audited [15, 18]. People often ﬁnd it difﬁcult to
analyze an overwhelming amount of alerts and instead wish
to focus on the successful intrusions, ignoring unsuccess-
ful ones until necessary. It means that an IDS must be able
to determine the result of intrusion attempts rather than just
detecting them. Thus, successful and unsuccessful intrusion
attempts can be distinguished and prioritized.
A popular approach to verifying intrusion attempt results
is to let an IDS be aware of the environment and conﬁgu-
ration of the systems under attack [15, 16]. For example,
assuming a Windows worm is attacking a host H running
a Linux system, if an IDS is aware of the operating system
of host H, it can determine that the attack will fail. This
approach requires the mapping and modeling of run-time
environment and system conﬁguration [15, 23]. It can be a
burden to collect and update the conﬁguration database in
large or dynamic settings. Moreover, collecting such infor-
mation can potentially interfere with the execution of the
systems [15] and expose the IDS to the intruder.
Observing the fact that intrusions like buffer overﬂows
often alter program behavior, we propose to verify intrusion
attempt results via lightweight protocol analysis. After an
intrusion attempt against a network server is detected, the
IDS will monitor the server response and use it to determine
intrusion attempt results. This approach is completely pas-
sive and eliminates mapping of monitored systems and host
based veriﬁcation. In addition, we show that often a simple
protocol analysis on the header ﬁeld of a server response
is adequate to effectively determine attack result. Even if a
server response obeys the protocols, meaningful status code
in the response can still help verify the attack results.
The contributions of this paper include: (1) a passive
method based on lightweight protocol analysis to verify the
result of network attacks; (2) the methodologies and amount
of information needed for this approach, (3) the efﬁcacy of
this method with real-world data, and (4) a simple ﬁx to
Snort signatures to successfully apply our approach.
To avoid confusion, we informally deﬁne some terms
used throughout this paper:
Deﬁnition 1.1 (Intrusion Attempt, Attack) A malicious
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:07:27 UTC from IEEE Xplore.  Restrictions apply. 
action that intends to violate the security policy.
Deﬁnition 1.2 (Intrusion) An attack that successfully vio-
lates the security policy.
The rest of the paper is structured as follows. In Sec-
tion 2 we discuss the related work. In Section 3 we present
our method to verify intrusion attempt results. We describe
the implementation in Section 4, and present the experimen-
tal results in Section 5. Section 6 discusses several issues in
our approach and experiments. Section 7 concludes the pa-
per and future work.
2. Related Work
Intrusion detection techniques are generally categorized
into misuse detection, anomaly detection and speciﬁcation-
based detection [3]. Misuse detectors identify intrusions
based on signatures of known attacks, such systems include
Bro [20], Snort [22], and NetSTAT [28]. Anomaly detec-
tors, such as NIDES [12], detect intrusions that behave sig-
niﬁcantly different from the statistical proﬁle of normal ac-
tivities. Speciﬁcation-based detectors [13, 30] look for in-
trusions that violate the speciﬁcations of normal behavior.
Nowadays, misuse (signature-based) detection is the most
popular approach in intrusion detection and is widely used
in network IDSes (NIDSes).
Misuse detection has a well-known problem [15]: it of-
ten detects attacks and raises alerts regardless of attack re-
sults. If a Windows worm is attacking a Linux system, a
misuse IDS reports alerts even though the attack cannot suc-
ceed. Thus, misuse IDSes often report so many alerts for
unsuccessful attacks that they become unmanageable. A se-
curity ofﬁcer usually ignores these unsuccessful attacks, re-
garding them as harmless. Fine-tuning IDS rules according
to the monitored systems can avoid alerts of unsuccessful
attacks. This requires manual reﬁning and testing of the
signatures, which is error prone for large or dynamic com-
puting environment.
A popular antidote [11, 15, 23] is to proﬁle the systems
under attack using network mapping software and vulnera-
bility scanners either before or after an attack, and compare
the proﬁle to the vulnerability that the attack exploits. If
they do not match, the attack will fail. This approach has
several drawbacks. Information of the monitored systems
collected before an attack can be out of date or inaccurate at
the time of the attack in a dynamic environment. Actively
gathering data at runtime can expose the existence of IDSes,
and even disturb the normal functioning of the system when
using vulnerability scanners [15].
Almgren et. al. [1] propose to detect failed attacks
against CGI scripts that do not exist on the web server
by checking the “404 Not Found” response from the web
server. However, an in-depth analysis of other possi-
ble responses and their relations with the attacks is miss-
ing. Snort [22] includes several signatures to detect typi-
cal responses from a victim system under successful attack.
However, these signatures are ﬁxed and are logically sepa-
rated from the signatures detecting the attacks.
Sommer and Paxson [24] implement Request/Reply sig-
natures for Bro [20] to check both directions of a connec-
tion in order to avoid alerts of unsuccessful attacks. For
example, a signature that checks for “4XX” 1 in web server
response code can ﬁlter out unsuccessful attacks. However,
they do not consider those responses that violate protocol
speciﬁcations. Moreover, methodologies to analyze and
generate such signatures, how much and what information
is needed to determine the attack results, and the efﬁcacy of
this method remain unanswered.
Vigna et. al. [29] propose an approach to verify success-
ful buffer overﬂow attacks against web servers. They sug-
gest that unlike normal web server activities that create en-
tries in server log ﬁles, successful buffer overﬂow attacks
usually leave no trace in the log ﬁles. Thus, after detecting
an attack in a network connection, the web server log ﬁle is
inspected to check whether the entry is created. The missing
of entry indicates a successful attack. This method requires
both network and host-based IDSes. On the contrary, our
approach only requires NIDSes.
Vigna and Kemmerer study state transition analysis tech-
niques in NetSTAT [28]. Our approach is similar to state
transition analysis in general. In our method, a malicious re-
quest and its response trigger a simple three-state transition.
The request establishes a possible compromised state and
the response moves the state to either compromised state if
the attack has succeeded or non-compromised state if the at-
tack has failed. NetSTAT establishes the compromised state
solely based on detection of malicious requests.
Our approach is also similar to protocol analysis, e.g.,
NATE [25]. Unlike approaches that detect attacks via pro-
tocol analysis, our method uses protocol analysis to verify
attack results. Moreover, our analysis focuses on applica-
tion protocols and is lightweight - it only examines header
information in server responses, and the domain of values
to examine is often limited.
Several different approaches [6, 7, 18] correlate IDS
alerts. The goal of these approaches is to aggregate and
correlate alerts that are generated from logically related at-
tacks, thereby reducing the total number of alerts and time
needed to inspect them. However, the reduction obtained
from these approaches thus far does not seem as satisfactory
as that of Gula [11], Kruegel and Robertson [15], and ours.
In addition, alerts of unsuccessful attacks can have negative
impact on alert correlation [19]. Finally, these approaches
1Here ‘X’ is any ASCII digital character. The two ‘X’s are not neces-
sarily the same digit. We shall use the same notation in what follows.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:07:27 UTC from IEEE Xplore.  Restrictions apply. 
usually need signiﬁcant work on modeling and analyzing
alerts.
3. Network Intrusion Attempt Veriﬁcation
Program behavior usually follows certain speciﬁcations.
For example, a web server must follow the HTTP proto-
col to interact with clients. Here the HTTP protocol is the
speciﬁcation that deﬁnes the legitimate behavior of the web
server and its clients.
In fact, most network applications
follow some well-deﬁned application protocols. In this pa-
per, we shall limit the scope of our discussion to verifying
network intrusion attempts based on application protocols.
The methodology, however, is general and can be applied to
verify host-based intrusion attempts as well.
An intrusion, like a successful buffer overﬂow attack, of-
ten causes a vulnerable application to change its program
logic and enter into an unexpected state, therefore making
it behave differently from its speciﬁcations. For example,
a successful buffer overﬂow attack against a vulnerable ftp
server often invokes a shell program, whose functionality is
very different from the ftp server. The interactions between
the malicious client and the shell program will not follow
the FTP protocol any longer. An IDS can utilize this feature
to determine the result of the attack.
However, many attacks do not alter the program logic of
the applications. We notice that protocol status code in the
header of an application response often provides some hints
about the result for a request, e.g., whether the application
has successfully processed a request. This status code can
help determine the result of the attack.
3.1. Assumptions
To simplify the discussions we make several assump-
tions:
1. A NIDS is able to detect attacks against network appli-
cation servers and to report alerts accordingly.
2. A network application server and its clients interact
with well-deﬁned network application protocols.
3. An attacker cannot arbitrarily manipulate application
server responses in the intrusions.
4. The result of an attack is successful with respect to the
6. An application server does not use any IDS evasion
techniques like packet fragmentation in its normal re-
sponses.
Assumption 1 is three-fold. First, our purpose is to verify
the result of an attack. Sometimes an IDS cannot detect
certain attacks. For example, a lack of high-level semantic
models makes it difﬁcult for Snort to detect attacks crossing
5. A NIDS is placed logically between a network appli-
violation of security policy.
cation server and its clients.
persistent HTTP sessions. We consider this as the problem
of detection, not veriﬁcation. Secondly, our method only
inspects network connections that are ﬂagged by the IDSes
as containing malicious packets. Thirdly, we only study the
attacks launched by the client side against the server side.
Most attacks that today’s NIDSes try to detect fall in this
category.
Assumption 2 means a client and a server do not inter-
act using arbitrary protocols or protocol extensions. For
example, some web servers may issue “200” status code
with a customized “Not Found” page even if the requested
web page does not exist on the server. This violates the
HTTP protocol speciﬁcation. We consider such cases as
non-typical and ignore them unless absolutely necessary.
Assumption 3 limits the scope of our approach. Some at-
tacks, such as buffer overﬂows, often grant an attacker full
control of a process. In theory, a clever attacker can hijack
an application to produce a response that looks perfectly
normal, making it difﬁcult to verify the attack result. This
is a limitation of our method. In fact, advanced attacks [14]
also cause problems for other veriﬁcation approaches or
even host-based intrusion detection. For example, after a
successful buffer overﬂow attack, the intruder can insert a