---
author: Kade Killary
category: 技术
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 1
  viewnum: 7451
date: '2018-12-13 22:11:41'
editorchoice: false
excerpt: 立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。
fromurl: http://kadekillary.work/post/cli-4-ds/
id: 10342
islctt: true
largepic: /data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png
permalink: /article-10342-1.html
pic: /data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png.thumb.jpg
related: []
reviewer: wxy
selector: lujun9972
summary: 立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。
tags:
- 命令行
- 数据科学
thumb: false
title: 数据科学家的命令行技巧
titlepic: true
translator: GraveAccent
updated: '2018-12-13 22:11:41'
---
![](/data/attachment/album/201812/13/221149dirhh8vthq2vll9j.png)
对于许多数据科学家来说，数据操作从始至终就是 Pandas 或 Tidyverse。从理论上讲，这样做没有任何问题。毕竟，这就是这些工具存在的原因。然而，对于像分隔符转换这样的简单任务，这些工具是大材小用了。
立志掌握命令行应该在每个开发人员的学习清单上，特别是数据科学家。学习 shell 的来龙去脉将无可否认地提高你的生产力。除此之外，命令行还是计算领域的一个重要历史课程。例如，awk —— 一种数据驱动的脚本语言。1977 年，在 [Brain Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan)（即传奇的 [K&R 书](https://en.wikipedia.org/wiki/The_C_Programming_Language)中 K）的帮助下，awk 首次出现。今天，大约五十年过去了，awk 仍然活跃在每年[新出版的书](https://www.amazon.com/Learning-AWK-Programming-cutting-edge-text-processing-ebook/dp/B07BT98HDS)里面。因此，可以安全地假设对命令行魔法的付出不会很快贬值。
### 我们将涵盖什么
* ICONV
* HEAD
* TR
* WC
* SPLIT
* SORT & UNIQ
* CUT
* PASTE
* JOIN
* GREP
* SED
* AWK
### ICONV
文件编码可能会很棘手。现在大部分文件都是 UTF-8 编码的。要了解 UTF-8 背后的一些魔力，请查看这个出色的[视频](https://www.youtube.com/watch?v=MijmeoH9LT4)。尽管如此，有时我们收到的文件不是这种编码。这可能引起对改变编码模式的一些胡乱尝试。这里，`iconv` 是一个拯救者。`iconv` 是一个简单的程序，它将获取采用一种编码的文本并输出采用另一种编码的文本。
```
# Converting -f (from) latin1 (ISO-8859-1)
# -t (to) standard UTF_8
iconv -f ISO-8859-1 -t UTF-8  output.txt
```
实用选项：
* `iconv -l` 列出所有已知编码
* `iconv -c` 默默丢弃无法转换的字符
### HEAD
如果你是一个 Pandas 重度用户，那么会很熟悉 `head`。通常在处理新数据时，我们想做的第一件事就是了解其内容。这就得启动 Pandas，读取数据然后调用 `df.head()` —— 要说这有点费劲。没有任何选项的 `head` 将打印出文件的前 10 行。`head` 的真正力量在于干净利落的测试操作。例如，如果我们想将文件的分隔符从逗号更改为管道。一个快速测试将是：`head mydata.csv | sed 's/,/|/g'`。
```
# Prints out first 10 lines
head filename.csv
# Print first 3 lines
head -n 3 filename.csv
```
实用选项：
* `head -n` 打印特定行数
* `head -c` 打印特定字节数
### TR
`tr` 类似于翻译。这个功能强大的实用程序是文件基础清理的主力。理想的用例是替换文件中的分隔符。
```
# Converting a tab delimited file into commas
cat tab_delimited.txt | tr "\t" "," comma_delimited.csv
```
`tr` 另一个功能是你可以用内建 `[:class:]` 变量（POSIX 字符类）发挥威力。这些包括了：
* `[:alnum:]` 所有字母和数字
* `[:alpha:]` 所有字母
* `[:blank:]` 所有水平空白
* `[:cntrl:]` 所有控制字符
* `[:digit:]` 所有数字
* `[:graph:]` 所有可打印字符，但不包括空格
* `[:lower:]` 所有小写字母
* `[:print:]` 所有可打印字符，包括空格
* `[:punct:]` 所有标点符号
* `[:space:]` 所有水平或垂直空白
* `[:upper:]` 所有大写字母
* `[:xdigit:]` 所有 16 进制数字
你可以将这些连接在一起以组成强大的程序。以下是一个基本的字数统计程序，可用于检查 README 是否被滥用。
```
cat README.md | tr "[:punct:][:space:]" "\n" | tr "[:upper:]" "[:lower:]" | grep . | sort | uniq -c | sort -nr
```
另一个使用基本正则表达式的例子：
```
# Converting all upper case letters to lower case
cat filename.csv | tr '[A-Z]' '[a-z]'
```
实用选项：
* `tr -d` 删除字符
* `tr -s` 压缩字符
* `\b` 退格
* `\f` 换页
* `\v` 垂直制表符
* `\NNN` 八进制字符
### WC
单词计数。它的价值主要来自其 `-l` 选项，它会给你提供行数。
```
# Will return number of lines in CSV
wc -l gigantic_comma.csv
```
这个工具可以方便地确认各种命令的输出。所以，如果我们在转换文件中的分隔符之后运行 `wc -l`，我们会期待总行数是一样的，如果不一致，我们就知道有地方出错了。
实用选项：
* `wc -c` 打印字节数
* `wc -m` 打印字符数
* `wc -L` 打印最长行的长度
* `wc -w` 打印单词数量
### SPLIT
文件大小的范围可以很广。对于有的任务，拆分文件或许是有好处的，所以使用 `split` 吧。`split` 的基本语法是：
```
# We will split our CSV into new_filename every 500 lines
split -l 500 filename.csv new_filename_
# filename.csv
# ls output
# new_filename_aaa
# new_filename_aab
# new_filename_aa
```
它有两个奇怪的地方是命名约定和缺少文件扩展名。后缀约定可以通过 `-d` 标志变为数字。要添加文件扩展名，你需要运行以下 `find` 命令。它将通过附加 `.csv` 扩展名来更改当前目录中所有文件的名称，所以小心了。
```
find . -type f -exec mv '{}' '{}'.csv \;
# ls output
# filename.csv.csv
# new_filename_aaa.csv
# new_filename_aab.csv
# new_filename_aac.csv
```
实用选项：
* `split -b N` 按特定字节大小分割
* `split -a N` 生成长度为 N 的后缀
* `split -x` 使用十六进制后缀
### SORT & UNIQ
上面两个命令很明显：它们的作用就是字面意思。这两者结合起来可以提供最强大的冲击 (例如，唯一单词的数量)。这是由于 `uniq` 只作用于重复的相邻行。这也是在输出前进行 `sort` 的原因。一个有趣的事情是 `sort -u` 会达到和典型的 `sort file.txt | uniq` 模式一样的结果。
`sort` 对数据科学家来说确实具有潜在的有用能力：能够根据特定列对整个 CSV 进行排序。
```
# Sorting a CSV file by the second column alphabetically
sort -t"," -k2,2 filename.csv
# Numerically
sort -t"," -k2n,2 filename.csv
# Reverse order
sort -t"," -k2nr,2 filename.csv
```
这里的 `-t` 选项将逗号指定为分隔符，通常假设分隔符是空格或制表符。此外，`-k` 选项是为了确定我们的键。这里的语法是 `-km,n`，`m` 作为开始列，`n` 作为结束列。
实用选项：
* `sort -f` 忽略大小写
* `sort -r` 反向排序
* `sort -R` 乱序
* `uniq -c` 统计出现次数
* `uniq -d` 只打印重复行
### CUT
`cut` 用于删除列。作为演示，如果我们只想删除第一和第三列。
```
cut -d, -f 1,3 filename.csv
```
要选择除了第一行外的所有行。
```
cut -d, -f 2- filename.csv
```
结合其他命令，将 `cut` 用作过滤器。
```
# Print first 10 lines of column 1 and 3, where "some_string_value" is present
head filename.csv | grep "some_string_value" | cut -d, -f 1,3
```
查出第二列中唯一值的数量。
```
cat filename.csv | cut -d, -f 2 | sort | uniq | wc -l
# Count occurences of unique values, limiting to first 10 results
cat filename.csv | cut -d, -f 2 | sort | uniq -c | head
```
### PASTE
`paste` 是一个带有趣味性功能的特定命令。如果你有两个需要合并的文件，并且它们已经排序好了，`paste` 帮你解决了接下来的步骤。
```
# names.txt
adam
john
zach
# jobs.txt
lawyer
youtuber
developer