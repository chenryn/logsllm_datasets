HORNECYBER.COM
SECURE PENETRATION 
TESTING OPERATIONS: 
DEMONSTRATED 
WEAKNESSES IN LEARNING 
MATERIAL AND TOOLS
PRE-PUBLICATION VERSION FOR CONFERENCE RELEASE | FOR THE FINAL REPORT, INCLUDING CODE AND 
DETAILED DESCRIPTION OF THE DEMONSTRATED TOOL, VISIT HORNECYBER.COM
ABSTRACT
Following previous presentations on the dangers penetration testers face in using current 
off-the-shelf tools and practices (Pwn the Pwn Plug and I Hunt Penetration Testers), this 
paper and presentation explores how widely available learning materials used to train 
penetration testers lead to inadequate protection of client data and penetration testing 
operations. Widely available books and other training resources target the smallest 
set of prerequisites, in order to attract the largest audience. Many penetration testers 
adopt the techniques used in simpliﬁed examples to real world engagements, where 
the network environment can be much more dangerous. Malicious threat actors are 
incentivized to attack and compromise penetration testers, and given current practices, 
can do so easily and with dramatic impact.
The accompanying presentation to this paper includes a live demonstration of techniques 
for hijacking a penetration tester’s normal practices, as well as guidance for examining 
and securing penetration testing procedures. The tool shown in this demonstration will 
be released publicly (with code) along with the ﬁrst presentation of this talk.
INTRODUCTION
This paper is a companion piece to the talk of the same title. In both this paper and 
the correlating talk, previous work is presented, followed by a review of the threats to 
penetration testers. A study was performed on a large body of penetration testing 
learning materials, illustrating the lack of secure practices being taught—
practices that have been observed to be repeated on real engagements. 
WESLEY MCGREW, PH.D.
DIRECTOR OF CYBER OPERATIONS, 
HORNE CYBER
PI:EMAIL
@MCGREWSECURITY
HORNECYBER.COM
  PAGE 2
Recommendations are made for improving secure processes. Finally, a tool is presented that illustrates the threat that 
penetration testers face. This is demonstrated live in the corresponding talk, showing how penetration testers’ post-
exploitation activities can be easily hijacked by attackers.
PREVIOUS WORK
Vulnerabilities in penetration testing tools, techniques, and devices have been explored in two prior talks by the author:
• DEF CON 21 – Pwn The Pwn Plug: Analyzing and Counter-Attacking Attacker-Implanted Devices[1]
• DEF CON 23 – I Hunt Penetration Testers: More Weaknesses in Tools and Procedures[2]
In Pwn the Pwn Plug, an off-the-shelf penetration testing device meant to be hidden and left behind within an organization 
was analyzed for vulnerabilities that would affect the security of operating it in this conﬁguration. In the “left behind” 
scenario, the device is uniquely susceptible to tampering and monitoring by third-parties with physical access to the same 
locations. It was established and demonstrated in this talk that the vulnerabilities were not simply limited to physical 
access: third party attackers could remotely execute commands on the device through a combination of vulnerabilities in 
the penetration tester’s user interface to the device. In this, the ﬁrst talk on the subject, the work was presented both in 
terms of targeting penetration testers, as well as in the context of incident response: performing forensics on malicious 
threat actors’ implanted devices.
In the next talk, I Hunt Penetration Testers, focus was placed on the security of penetration testers that use software 
and hardware tools on remote and in-person engagements. In this talk, a set of common security tools were examined to 
determine the inherent safety of their default conﬁgurations and options. It was determined that many penetration testing 
tools lack, at least by default, the capability to secure command-and-control information and sensitive client data both in 
transit and at rest. Scenarios were described that illustrate why a malicious threat actor would ﬁnd a penetration testing 
ﬁrm to be an attractive target. Finally, a vulnerability was demonstrated that allows attackers within range of the popular 
WiFi Pineapple device the ability to remotely gain control of it. This illustrated the risks of operating in hostile network 
environments with devices that have not been hardened. 
This talk, Secure Penetration Testing Operations: Demonstrated Weaknesses in Learning Material and Tools, builds upon 
the previous work by exploring the root causes of insecure practices in penetration testing, practical demonstration 
of more vulnerabilities in common procedures, and recommendations for more secure practices for engagements. It is 
worth mentioning that the closer examination of post-exploitation payloads undertaken as part of the work for this talk 
reveals that the dangers posed by current practices in the use of these payloads/agents is far worse than was described 
previously in I Hunt Penetration Testers.
THE THREAT
Previous presentations on this topic have established a description of the threat model for malicious third party actors 
targeting penetration testers. While the purpose of this talk is not to retread ground, it is worth brieﬂy revisiting some of 
the major points for the purposes of deﬁning the scope and motivation behind this paper. 
In I Hunt Penetration Testers, it was proposed that penetration testing professionals and ﬁrms represent attractive 
targets due to their level of access to client organizations and their position outside of the rules of normal 
HORNECYBER.COM
  PAGE 3
business operation. Penetration testers are expected to break rules, elevate privileges, and perform exﬁltration of sensitive 
data. For these reasons, a penetration test can serve as an opportunity both for cover and for the opportunity to discover 
vulnerabilities “over the shoulder” of a penetration tester. 
Penetration testers, apart from their clients, might be the target of compromise as well. More advanced testers might 
be in possession of tools and exploits that are not publicly available and would represent a value to the attacker. As 
security professionals, a compromise of a penetration tester also represents an embarrassing situation if made public 
by a hacktivist or other malicious party. While the focus of earlier talks on this topic were on compromising penetration 
tester tools themselves, the demonstration in this talk, and the questions examined about learning material are focused 
on weaknesses in procedures opening up access to client systems and data.
WE OPERATE AS WE LEARN – A SURVEY OF PRACTICES IN PUBLICLY AVAILABLE RESOURCES
While some standards documents exist for penetration testing [3,8,9,10], most circumstances and requirements for 
penetration testing do not currently require rigorous adherence to formal standards. Existing documents of this nature 
generally describe phases of a penetration test, but stop short of providing hard requirements for all tests. In this way, 
these documents largely constitute “guidance” (as described in the PCI supplement on penetration testing [10]) more 
than serving as standards to be met.
This is appropriate in some ways, as the value in a penetration test is only realized when an experienced and talented 
team is able to use human ingenuity to ﬁnd vulnerabilities in complex systems where an automated scan simply would 
not provide value. Current guidance/standards allows for the ﬂexibility needed to do this. The mind’s capability to intuit 
the intended and unintended operation of software written by other humans, recognize patterns in complex data, and 
apply complex ad-hoc processes to solve problems (i.e. the location and exploitation of vulnerabilities) all contribute to 
a penetration testing team providing results that cannot be obtained using an automated vulnerability scanning tool. A 
formal standard for conducting tests would not be able to encompass the breadth and depth of potential activity, and 
would therefore be counterproductive.
While the lack of a formal standard does not impair the technical value of penetration testing, it does result in a lack of 
rigor. Without deﬁned expectations for protecting the security of client data and systems, to say nothing of the operations of 
the penetration testing individual of the ﬁrm, there is no control on the low bar for such protection. Without a standardized 
set of expectations, we fall back upon what is most convenient or expedient to implement. In this work’s examination of 
operational security issues in penetration testing in learning and reference materials, standards documents did address 
some, but not all issues of security in penetration testing. Out of the standards documents surveyed, the open source 
Penetration Testing Execution Standard addressed more issues of client and penetration test operational security than 
the rest, including the protection of client data in transit, client data at rest, operational security during the intelligence 
gathering phase, communications security for contact with client staff, and the security of client systems during and after 
the test.
If we look to current and common practices in safely (or, not so safely) conducting penetration testing, it is reasonable 
to expect that most testers will conduct their tests in accordance to their background and training. There are no 
requirements for formal education to enter the profession, nor are there very many formal programs that extensively 
cover offensive security testing. Training programs in penetration testing (taught in a matter of days or weeks) 
HORNECYBER.COM
  PAGE 4
typically have few pre-requisites. While this paper will avoid bemoaning the minimal depth or breadth of background 
knowledge required or gained by most new penetration testers, it is safe to say: for many, their tools and techniques will 
be deﬁned by the learning material they have used without much improvisation or improvement. 
If we consider that most penetration testers will tend to operate in a way that is consistent with the material they 
learned from (and continue to reference), then we can draw conclusions on the security of common penetration testing 
techniques by examining that material. For this paper and talk, a selection of popular books and training material on 
penetration testing was examined with the goal of applying a set of feature-extracting questions. These questions are 
designed to determine the presence and nature of operational security advice for penetration testers that is contained 
within material used to learn the profession.
The questions are as follows:
1. [Host Security – Penetration Tester] Does the work address precautions for preventing penetration testers’ 
systems from being compromised? Describing how to set the Kali/Backtrack password is not, by itself, sufﬁcient for 
this to be a “yes”.
2. [Host Security – Client] Does the work address precautions for maintaining the security of client systems during 
the test? Penetration testing procedures should not leave the tested systems in a more insecure state then they were 
in when the test began.
3. [COMSEC] Does the work address establishing secure means of communicating with the client about the engagement? 
This would include emergency contact and report delivery, as well as any other email or teleconferencing.
4. [Client Data in Transit] Does the work address issues surrounding the transmission of sensitive client data between 
targets and penetration testers’ systems in the course of the engagement? This would include data that is being 
extracted for proof of impact, as well as information about the hosts that would be transmitted across command-
and-control channels.
5. [Client Data at Rest] Does the work discuss procedures for securing client data at rest, during and/or after the 
engagement? This includes data that has been extracted from targets and stored on penetration testers’ workstations 
and penetration testing devices. Procedures might include encryption, hardening, and/or secure deletion.
6. [OSINT OPSEC] Does the work address operational security during intelligence gathering phases? This would address 
conﬁdentiality of the information one might be transmitting about the client in the course of seeking information 
about the client from publicly available sources.
7. [Potential Threats] Does the work address issues with conducting tests against systems over hostile networks, 
such as the public Internet or unencrypted wireless?
8. [Insecure Practices] Does the work demonstrate or teach at least one example of an insecure practice without 
describing how it might leave the tester or client vulnerable?
OBSERVATIONS FROM EXAMINING LEARNING MATERIAL
This section discusses the results of examining a set of material with the goal of answering the above questions. This 
set of material included 16 books, four standards/guidance documents, and the publicly-available material for 
three classes. The stated goal, of all of these works, is to serve as learning or training material for penetration 
testing. All of the materials used for this study are publicly available outside the context of a paid training 
HORNECYBER.COM
  PAGE 5
class. Paid training classes’ material were not studied as a part of this work due to usage agreements and a lack of easy 
access (at a reasonable cost) to recent materials for the purposes of this study. This is not seen as a signiﬁcant loss, 
however, as it is in the author’s experience that such classes do not differ greatly from publicly published material with 
regards to this study.
This paper does not disclose the titles, authors, or sources of the works examined, as the point of this study is to 
demonstrate an across-the-board lack of focus on the security of penetration testing procedures in works that many 
new testers are using to build their skill set, rather than to describe the deﬁciencies or virtues of one set of material over 
another. While moving forward, it is important for new material to incorporate secure practices and describe the due care 
needed in testing, it might be unfair to point out speciﬁc works as being “bad” when there was no widespread education/
understanding of the risks at the time the content was created.
METHODOLOGY
The methodology used for this study was to examine how each work addresses the eight questions posed. Standards/
Guidance documents were chosen through internet searches and references to penetration testing standards documents 
identiﬁed and used in other recent work on this topic. Class material was gathered from publicly available materials not 
encumbered by usage agreements. Books were gathered based on popularity in Amazon searches for penetration testing 
books. A brief examination of each studied work was made to verify that it directly stated its purpose as being a learning 
resource for penetration testers. In the results, no distinguishing markings are made for the different types of material 
(standards/guidance, classes, books), as each, for the purposes of this study, serves the same role as learning materials 
that penetration testers will implement in practice.
Reading and analyzing every sentence on every page of every targeted work in the context of the eight questions would 
make the duration of the study prohibitively long. Therefore, the examination of each work was performed in two phases. 
The ﬁrst phase took the approach of examining the table of contents to determine sections that seemed likely to contain 
information that would provide a positive answer to each question, and then examining those sections for the information 
is being sought. 
After this initial phase, to more exhaustively test the remaining questions, each page of the work was brieﬂy examined (in 
most cases on the order of a few seconds) to seek out text relevant to the security of penetration testing procedures. With 
the author of this paper’s experience in quickly consuming written works, and the ease at which relevant coverage should 
be identiﬁed, this approach, while subjective, should be considered fair. The potential for false negative results should be 
considered with the justiﬁcation that coverage of secure penetration testing practices should have been easily located, if 
that coverage was meant to be effective.
For simplicity in illustrating the point of this paper, a simple “yes” or “no” was recorded for each studied work and each 
question. The threshold for “yes” was intentionally very low. For example, a single paragraph in a book of over ﬁve hundred 
pages on the topic of encrypting a report for transmitting to a client would be sufﬁcient for a “yes”. While this may exhibit 
positive results for studied works that do not provide an extensive coverage of these topics, it causes the results of the 
study as a whole to more effectively demonstrate the negative case: that a large amount of resources available to learn 
penetration testing techniques do not have any coverage at all of these concerns.
HORNECYBER.COM
  PAGE 6
This chart represents the results of applying the study methodology to the resources selected. For questions 1 through 7, 
“Y” indicates that the topic was addressed in the work (and is colored green as a positive result), “N” indicates that it 
was not (colored red as a negative result). For question 8, “Y” indicates that vulnerable practices were taught without 
disclaimer, and those cells are colored in red, opposite to the rest of the columns (as the “Y” response is negative in 
this context). For question 8, “N” indicates that no vulnerable practices were taught. If the “N” for question 8 is colored 
yellow, the resource did not cover any technical matters of penetration testing and focused only on procedural issues. 
RESOURCE
1 - HOST - PENETRATION 
TESTERT SECURITY 
2 - HOST SECURITY - CLIENT
3 - COMSEC
4 - CLIENT DATA - IN TRANSIT
5 - CLIENT DATA - AT REST
6 - OSINT OPSEC
7 - POTENTIAL THREATS
8 - INSECURE PRACTIICES
1
Y
N
N
N
Y
N
N
N
2
N
N
N
N
N
N
N
Y
3
N
N
N
N
N
N
N
Y
4
N
N
N
N
N
N
N
Y
5
Y
Y
Y
Y
Y
Y
Y
N
6
N
N
N
Y
Y
N
N
Y
7
N
N
N
N
N
N
N
Y
8
N
N
N
N
N
N
N
Y
9
N
Y
N
N
Y
N
N
Y
10
N
N
N
N
N
N
N
Y
11
N
N
N
N
N
N
N
Y
12
N
N
N