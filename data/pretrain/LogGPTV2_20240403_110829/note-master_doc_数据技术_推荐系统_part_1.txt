# 推荐系统
> 一种信息过滤系统，手段是预测用户（User）对物品（Item）的评分和偏好
- 能做什么：把那些最终会在用户（User）和物品（Item）之间产生的连接提前找出来
- 需要什么：根据存在的连接，从已有的连接去预测未来的连接
- 怎么做：机器推荐与人工推荐
## 问题
### 模型
1. 评分预测 假如用户消费完一个物品之后会给出一个打分，能不能提前预测一个用户对每一个物品会打多少分，找出那些他可能会打高分的物品，推荐给他
2. 行为预测 利用隐式反馈数据预测隐式反馈的发生概率
评分预测的问题在于评分比较难收集，并且评分更偏主观，这种主动告知评分称之为显式反馈，与之相对的还有隐式反馈，通常根据各类用户行为对物品进行打分
隐式反馈能收集的数据更多，并且更代表用户的真实想法，常常和模型的目标函数关联更密切
### 顽疾
1. 冷启动 缺乏相关数据的用户和物品，很难直接加入到推荐系统
2. 探索与利用 EE 问题，已知用户喜好，如何给他推荐
3. 安全问题 推荐系统攻击问题，不靠谱的推荐、难以消除的脏数据、损害商业利益
## 特性
- 不确定性
- 追求的是目标的增长
## 内容推荐
![内容推荐框架](/assets/2022125203834.webp)
- 内容源：推荐系统必须有源源不断的新鲜数据
- 内容分析：主要是为了结构化内容库，以及产出内容分析模型
- 内容推荐算法：最基本的就是基于向量的相似度算法，更复杂的则是基于机器学习的算法
### 用户画像
- 对用户信息的向量化表示，是构建推荐系统的过程中产生的一个关键环节的副产品
#### 关键因素
1. 维度
2. 维度的量化
这两个关键因素很主观，取决于设计者
#### 构建方法
1. 直接使用原始数据作为用户画像的内容，对于用户冷启动等场景非常有用
2. 通过统计手段从历史数据挖掘出标签
3. 机器学习，提炼出人类无法理解也无法解释的稠密向量
#### 文本构建用户画像
1. 把所有非结构化的文本结构化，去粗取精，保留关键信息
2. 根据用户行为数据把物品的结构化结果传递给用户，与用户自己的结构化信息合并
结构化文本的方法：
1. [TF-IDF](/数据技术/检索技术.md#TF-IDF%2d算法)
2. TextRank
3. 内容分类 SVM算法
4. 命名实体识别 进行NLP，分词后识别为定义的命名实体集合之一，可以用提前准备好的实体字典来识别
5. 文本[聚类](/数据技术/数据挖掘.md#聚类)
6. 词嵌入 除了 LDA，其他都是得到一些标签，而这些标签无一例外都是稀疏的，而词嵌入则能够为每一个词学习得到一个稠密的向量
   1. Word2Vec
选择标签：
- [卡方检验和信息增益](/数学/概率论与数理统计.md#特征选择)
## 近邻推荐
### 协同过滤
- 基于记忆的协同过滤（Memory-Based）
- 基于模型的协同过滤（Model-Based）
假设已知物品特征为$X(x^{(1)},x^{(2)},...,x^{(n)})$，用户喜欢的物品特征为$W(w^{(1)},w^{(2)},...,w^{(n)})$，那么对于一个物品i，求出用户j对它可能喜欢的程度可以定义为
$$
W^{(j)}\cdot X^{(i)} + b^{(i)}
$$
就可以通过求该回归的代价函数求出w与b，i:r(i,j) 只对用户评过分的物品进行计算：
$$
\mathbf{J}\big(w^{(j)},b^{(j)}\big)=\frac{1}{2}\sum_{i:r(i,j)=1}\big(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\big)^{2}+\frac{\lambda}{2}\sum_{k=1}^{n}\big(w_{k}^{(j)}\big)^{2}\\
$$
如果没有物品的特征，那么对于代价函数，我们还需要再多求一个物品的特征$X$
$$
\mathbf{J}\big(w^{(j)},b^{(j)},x^{(i)}\big)=\frac{1}{2}\sum_{i:r(i,j)=1}\big(w^{(j)}\cdot x^{(i)}+b^{(j)}-y^{(i,j)}\big)^{2}+\begin{aligned}\frac{\lambda}{2}\sum_{j=1}^{n_{u}}\sum_{k=1}^{n}\left(w_{k}^{(j)}\right)^2+\frac{\lambda}{2}\sum_{i=1}^{n_{m}}\sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^2\end{aligned}
$$
对代价函数进行梯度下降，这样对于每个用户，都有自己的参数W,b了。同时物品的特征也求出来了
如果对于物品的评价是 0 1 二进制标签，则需要对代价函数做个调整：
$$
J(w,b,x)=\sum_{(i,j):r(i,j)=1}L(f_{(w,b,x)}(x),y^{(i,j)})\\
L\left(f_{\{w,b,x\}}(x),y^{(ij)}\right)=-y^{(i,j)}\log\left(f_{(w,b,x)}(x)\right)-(1-y^{(i,j)})\log\left(1-f_{\{w,b,x\}}(x)\right)
$$
#### 均值归一化
$$
Y=\begin{bmatrix}5&5&0&0&?\\5&?&?&0&?\\?&4&0&?&?\\0&0&5&4&?\\0&0&5&0&?\end{bmatrix}\quad\mu=\begin{bmatrix}2.5\\2.5\\2\\2.25\\1.25\end{bmatrix}\rightarrow Y=\begin{bmatrix}2.5&2.5&-2.5&-2.5&?\\2.5&?&?&-2.5&?\\?&2&-2&?&?\\-2.25&-2.25&2.75&1.75&?\\-1.25&-1.25&3.75&-1.25&?\end{bmatrix}
$$
将用户的评分减去均值，预测时，线性回归就变成 $w^{(j)} + x^{(i)} + b^{(j)} = \mu_i$
它将促使对新用户的评分预测会更偏向于其他用户的平均值
#### 基于用户
> 将用户的喜欢的物品转为向量，通过向量计算与用户之间的相似度
一些工程上的问题：
1. 相似度计算，如果物品很多，即向量很长，为了降低复杂度，有两种方法
   1. 对向量采样计算 随机选取n个维度来计算
   2. 向量运算
2. 如果用户量很大，两两之间计算代价就很大，这个时候就需要引入Map Reduce之类的并行计算来加快速度
3. 推荐计算：为每一个用户计算每一个物品的推荐分数，优化方式是只有相似用户喜欢过的物品需要计算，另外一个就是并行计算
4. 权重，一般来说，热门、过期的物品，权重值越低
#### 基于物品
> 首先计算相似物品，然后再根据用户消费过、或者正在消费的物品为其推荐相似的
设某个物品的特征向量为$X[x_1,x_2,x_3,...x_n]$，用户的偏好向量为$W[w_1,w_2,w_3...w_n]$，要求用户对该物品的喜欢程度就是$W\cdot X$
需要做的就是把用户的特征向量转为用户的偏好向量，把两个不同维度的向量转为统一维度的向量，并进行组合：
![](/assets/20231027192041.png)
使用以下代价函数促使神经网络找到合适的路，以根据用户特征向量及物品特征向量预测用户喜欢物品的可能性
$$
J=\sum_{(i,j):r(i,j)=1}(v_u^{(j)}\cdot v_m^{(i)}-y^{(i,j)})^2\color{red}{+\text{NN regularization term}}
$$
相似度算法改进：
1. 物品中心化。把矩阵中的分数，减去的是物品分数的均值，可以去掉评分中的非理性因素
2. 用户中心化。把矩阵中的分数，减去对应用户分数的均值，一定程度上仅仅保留了偏好，去掉了主观成分
推荐结果：
1. 计算用户对所有物品的喜欢度，进行TOPK推荐
2. 相关推荐
**Slope One 算法**
#### 相似度算法
- [向量距离](/数学/线性代数.md#距离)
欧式距离度量的是空间中两个点的绝对差异，适用于分析用户能力模型之间的差异，比如消费能力、贡献内容的能力
余弦相似度则是对两个向量进行归一化处理，对绝对值不敏感
皮尔逊相关度度量的是两个变量的变化趋势是否一致，所以不适合用作计算布尔值向量之间相关度
杰卡德（Jaccard）相似度：两个集合的交集元素个数在并集中所占的比例，适合用于隐式反馈数据
#### 局限性
- 冷启动问题：没有用户的评价数据初期很难过，对于很少进行评价的用户如何对其推荐
- 无法很好地利用用户特征
## 矩阵分解
近邻模型的问题：
1. 物品之间存在相关性，信息量并不随着向量维度增加而线性增加
2. 矩阵元素稀疏，计算结果不稳定
矩阵分解，直观上说来简单，就是把原来的大矩阵，近似分解成两个小矩阵的乘积，在实际推荐计算时不再使用大矩阵，而是使用分解得到的两个小矩阵，也就是降维，[SVD](/数学/线性代数.md#SVD%20奇异值分解)是其中的一种算法
$$\min_{q^*,p^*}\sum_{(u,i)\in\kappa}(r_{ui}-p_uq_i^T)^2+\lambda(||q_i||^2+||p_u||^2)$$
整个 SVD 的学习过程就是：
1. 准备好用户物品的评分矩阵，每一条评分数据看做一条训练样本
2. 给分解后的 U 矩阵和 V 矩阵随机初始化元素值
3. 用 U 和 V 计算预测后的分数
4. 计算预测的分数和实际的分数误差
5. 按照梯度下降的方向更新 U 和 V 中的元素值
6. 重复步骤 3 到 5，直到达到停止条件
偏置信息：一个用户给一个物品的评分会由全局平均分、物品的评分偏置、用户评分的偏置、用户和物品之间的兴趣偏好四部分相加
历史行为：用户有过行为的物品集合也都有一个隐因子向量，维度是一样的。把用户操作过的物品隐因子向量加起来，用来表达用户的兴趣偏好。另外一个是用户属性，全都转换成 0-1 型的特征后，对每一个特征也假设都存在一个同样维度的隐因子向量，一个用户的所有属性对应的隐因子向量相加，也代表了他的一些偏好
时间因素：让久远的评分更趋近平均值、不同的时间区间内分别学习出隐因子向量
### 交替最小二乘
要把一个矩阵分解为两个矩阵的相似解：
1. 初始化随机矩阵 Q 里面的元素值
2. 把 Q 矩阵当做已知的，直接用线性代数的方法求得矩阵 P
3. 得到了矩阵 P 后，把 P 当做已知的，故技重施，回去求解矩阵 Q
4. 上面两个过程交替进行，一直到误差可以接受为止
加权交替最小二乘对待隐式反馈：
- 对物品无隐式反馈则认为评分是 0
- 用户对物品有至少一次隐式反馈则认为评分是 1，次数作为该评分的置信度