up in the same bucket, the server keeps only the latest pair
and discards any earlier pairs.
To delete an existing key ğ¾, the servers add a pair (ğ¾, ğ‘‰âŠ¥)
to the topmost bucket, where ğ‘‰âŠ¥ âˆˆ {0, 1}â„“ is some special
value. (If the set of possible values for a key is {0, 1}â„“ in
its entirety, we can extend the bit-length of the value space
by a single bit.) When, as a result of ï¬‚ushing, (ğ¾, ğ‘‰âŠ¥) ends
up in the same bucket as other pairs with the same key ğ¾,
the servers only keep the latest pair and discard any earlier
pairs. At the bottom-most bucket, the servers can discard all
remaining (ğ¾, ğ‘‰âŠ¥) pairs.
Analysis. The client needs a new hint for bucket ğ‘ only each
time all of the buckets {1, . . . , ğ‘ âˆ’ 1} overï¬‚ow. When this
ğ‘–=1 2ğ‘– = 2ğ‘ elements into
bucket ğ‘. Intuitively, if the server generates a new hint after
each update, then after ğ‘¢ updates, the server has generated
ğ‘¢/2ğ‘ hints for bucket ğ‘, each of which takes time roughly
ğœ†â„“2ğ‘ to generate, on security parameter ğœ†. (This is because
our oï¬„ine/online scheme has hint-generation time ğœ†â„“ğ‘›, on
security parameter ğœ† and a database of ğ‘› â„“-bit records.)
happens, the servers ï¬‚ush 1 +ğ‘âˆ’1
âˆš
The total hint generation time with this waterfall scheme
after ğ‘¢ updates, on security parameter ğœ†, with ğµ = log ğ‘›
buckets, is then at most ğœ†ğ‘¢â„“ğµ = ğœ†ğ‘¢â„“ log ğ‘›. In contrast, if we
generate a hint for the entire database on each change using
the simple scheme, the total hint generation time is ğœ†ğ‘¢â„“ğ‘› =
ğœ†ğ‘¢â„“2ğµ (since ğ‘› = 2ğµ). That is, the waterfall scheme gives an
exponential improvement in server-side hint-generation time
over the simple scheme.
2ğ‘) =
ğ‘‚(â„“
ğ‘›). So, we achieve an exponential improvement in hint-
generation cost at a modest (less than fourfold) increase in
online query time.
The query time of this scheme is ğµ
ğ‘‚(â„“ Â·
One subtlety is that in our base oï¬„ine/online PIR scheme,
the length of a hint for a bucket of size 2ğ‘ is roughly ğœ†â„“
2ğ‘. For
buckets smaller than ğœ†2, using oï¬„ine-online PIR would require
more communication than just downloading the contents of
the entire bucket. We thus use a traditional â€œonline-only" PIR
scheme for those small buckets.
ğ‘=1
âˆš
âˆš
6 Use case: Safe Browsing
Every major web browser today, including Chrome, Firefox,
and Safari, uses Googleâ€™s â€œSafe Browsingâ€ service to warn
users before they visit potentially â€œunsafeâ€ URLs. In this
context, unsafe URLs include those that Google suspects are
hosting malware, phishing pages, or other social-engineering
content. If the user of a Safe-Browsing-enabled browser tries
to visit an unsafe URL, the browser displays a warning page
and may even prevent the user from viewing the page.
6.1 How Safe Browsing works today
At the most basic level, the Safe Browsing service maintains
a blocklist of unsafe URL preï¬xes. The browser checks each
URL it visits against this blocklist before rendering the page to
the client. Since the blocklist contains URL preï¬xes, Google
can add an entire portion of a site to the blocklist by adding
just the appropriate preï¬x. (In reality, there are multiple Safe
Browsing blocklists, separated by the type of threat, but that
detail is not important for our discussion.)
Two factors complicate the implementation:
â€¢ The blocklist is too large for clients to download and
store. The Safe Browsing blocklist contains roughly three
million URL preï¬xes. Even sending a 256-bit hash of
each blocklisted URL preï¬x would increase a browserâ€™s
download size and storage footprint by more than 90MB.
This would more than double the download size of Firefox
on Android [66].
â€¢ The browser cannot make a network request for every
blocklist lookup. For every webpage load, the browser
must check every page resource (image, JavaScript ï¬le,
etc.) against the Safe Browsing blocklist. If the browser
made a call to the Safe Browsing API over the network for
every blocklist lookup, the latency of page loads, as well
as the load on Googleâ€™s servers, would be tremendous.
The current Safe Browsing system (API v4) [43] addresses
both of these problems using a two-step blocklisting strategy.
Step 1: Check URLs against an approximate local blocklist.
Google ships to each Safe Browsing client a data structure
that represents an approximate and compressed version of
the Safe Browsing blocklist, similar to a Bloom ï¬lter [11,18].
Before the browser renders a web resource, it checks the
corresponding URL against its local compressed blocklist.
This local blocklist data structure has no false negatives (it
will always correctly identify unsafe URLs) but it has false
positives (sometimes it will ï¬‚ag safe URLs as unsafe). In
other words, when given a URL, the local blocklist either
replies â€œdeï¬nitely safeâ€ or â€œpossibly unsafe.â€ Thus, whenever
the local blocklist identiï¬es a URL as safe, the browser can
immediately render the web resource without further checks.
In practice, this local data structure is a list of 32-bit
hashes of each blocklisted URL preï¬x. Delta-encoding
the set [42] further reduces its size to less than 5MBâ€”
roughly 18Ã— smaller than the list of all 256-bit hashes
of the blocklisted URL preï¬xes. The browser checks a
URL (e.g., http://a.b.c/1/2.html?param=1) by splitting it
into substrings (a.b.c/1/2.html?param=1, a.b.c/1/2.html,
a.b.c./1, a.b.c/, b.c/, etc.), hashing each of them, and
USENIX Association
30th USENIX Security Symposium    883
checking each hash against the local blocklist.
Step 2: Eliminate false positives using an API call. Whenever
the browser encounters a possibly unsafe URL, as determined
by its local blocklist, the browser makes a call to the Safe
Browsing API over the network to determine whether the
possibly unsafe URL is truly unsafe or whether it was a false
positive in the browserâ€™s local blocklist.
To execute this check, the browser identiï¬es the 32-bit
hash in its local blocklist that matches the hash of the URL.
The browser then queries the Safe Browsing API for the full
256-bit hash corresponding to this 32-bit hash.
Finally, the browser hashes the URL in question down to
256 bits and checks whether this full hash matches the one
that the Safe Browsing API returned. If the hashes match, then
the browser ï¬‚ags the URL as unsafe. Otherwise, the browser
renders the URL as safe.
This two-step blocklisting strategy is useful for two reasons.
First, it requires much less client storage and bandwidth,
compared to downloading and storing the full blocklist locally.
Second, it adds no network traï¬ƒc in the common case. The
client only queries the Safe Browsing API when there is
a false positive, which happens with probability roughly
ğ‘›/232 â‰ˆ 2âˆ’11. So, only one in every 2,000 or so blocklist
lookups requires making an API call.
However, as we discuss next, the current Safe Browsing
architecture leaks information about the userâ€™s browsing
history to the Safe Browsing servers.
6.2 Safe Browsing privacy failure
Prior work [9,38,45,70] has observed that the Safe Browsing
protocol leaks information about the userâ€™s browsing history
to the servers that run the Safe Browsing APIâ€”that is, to
Google. In particular, whenever the user visits a URL that
is on the Safe Browsing blocklist, the userâ€™s browser sends
a 32-bit hash of this URL to Googleâ€™s Safe Browsing API
endpoint. Since Google knows which unsafe URLs correspond
to which 32-bit hashes, Google then can conclude with good
probability which potentially unsafe URL a user was visiting.
(To provide some masking for the clientâ€™s query, Firefox mixes
the clientâ€™s true query with queries for four random 32-bit
hashes. Still, the server can easily make an educated guess at
which URL triggered the clientâ€™s query.)
There is some chance (a roughly one in 2,000) that a user
queries the Safe Browsing API due to a false positiveâ€”when
the 32-bit hash of a safe URL collides with the 32-bit hash
of an unsafe URL. Even in this case, Google can identify a
small list of candidate safe URLs that the user could have
been browsing to cause the false positive.
6.3 Private Safe Browsing with Checklist
We design a private Safe-Browsing service based on Checklist,
which uses our new PIR scheme of Section 4. Our scheme
requires two non-colluding entities (e.g., CloudFlare and
Figure 2: Using Checklist for Safe Browsing. Â– The browser checks
whether the URLâ€™s partial hash appears in its local blocklist. Â— If
so, the browser issues a Safe Browsing API query for the full hash
corresponding to the matching partial hash. Â˜ The Checklist client
proxy issues a PIR query for the full hash to the two Checklist servers.
Â™ The Checklist client proxy returns the full hash of the blocklisted
URL to the browser. Âš The browser warns the user if the URL hash
matches the hash of the blocklisted URL.
Google) to host copies of the blocklist, but it has the privacy
beneï¬t of not revealing the clientâ€™s query to either server.
Our Checklist-based Safe Browsing client works largely
the same as todayâ€™s Safe Browsing client does (Figure 2). The
only diï¬€erence is that when the client makes an online Safe
Browsing API call (to check whether a hit on the clientâ€™s local
compressed blocklist is a false positive), the client uses our
PIR scheme to perform the lookup. In this way, the client
can check URLs against the Safe Browsing blocklist without
revealing any information about its URLs to the server (beyond
the fact that the client is querying the server on some URL).
When the client visits a URL whose 32-bit hash appears
in the clientâ€™s local blocklist, the client needs to fetch the
full 256-bit SHA256 hash of the blocked URL from the Safe
Browsing servers. To do this, the client identiï¬es the index
ğ‘– âˆˆ [ğ‘›] of the entry in its local blocklist that caused the hit.
(Here ğ‘› is the total number of entries in the local blocklist.)
The client then executes the PIR protocol of Section 4 with
the Safe Browsing servers to recover the ğ‘–th 256-bit URL hash.
If the full hash from the servers matches the full hash of the
clientâ€™s URL, the browser ï¬‚ags the webpage as suspect. If not,
it is a false positive and the browser renders the page.
As the Safe Browsing blocklist changes, the client can fetch
updates to its local blocklist using the method of Section 5.2.
When two or more full hashes in the blocklist have the
same 32-bit preï¬x, the Checklist servers can lengthen the
partial hashes for the colliding entries. This way, a partial
hash on the clientâ€™s local list always maps to a single full
hash on the serversâ€™ blocklist. Safe Browsing already supports
variable-length partial hashes.
Partial hashes as PIR-by-keywords. The clientâ€™s local list of
partial hashes essentially serves as a replacement for using a
general PIR-by-keywords transformation [23]. The downside
of this replacement is that it uses oï¬„ine communication that
is linear in the number of records in the database. In Safe
Browsing, the primary purpose of the local list is to reduce
latency, bandwidth, and server computation, by allowing the
browser to respond to most queries locally. Checklist takes
884    30th USENIX Security Symposium
USENIX Association
Firefox browserPartialhashesChecklist client proxyLookup0x24C123Full hash0x24C1A8â€¦40x1040x1300x1F30x1FF0x24C0x2B2...ChecklistPIR queryChecklist client stateServerBBlocklistServerABlocklist5Warn?Oï¬„ine-Online
)
s
Âµ
(
e
m
i
t
r
e
v
r
e
S
106
105
104
103
102
101
0
2000
4000
6000
Num Queries
(a) Server CPU time
8000 10000
online
)
s
e
t
y
b
(
n
o
i
t
a
c
i
n
u
m
m
o
C
106
105
104
103
102
101
oï¬„ine
amortized
DPF
Matrix
)
s
Âµ
(
e
m
i
t
t
n
e
i
l
C
0
2000
4000
6000
Num Queries
(b) Communication
8000 10000
106
105
104
103
102
101
0
2000
4000
6000
Num Queries
(c) Client CPU time
8000 10000
Figure 3: For a static database of three million 32-byte records, we show the query cost in server time, client time, and communication. The
ï¬gure also shows the oï¬„ine cost of the new oï¬„ine-online PIR scheme and its total cost (oï¬„ine and online), amortized over a varying number of
queries. The oï¬„ine phase of the new scheme is expensive but its per-query server-side time is lower than in prior PIR schemes.
Implementation and evaluation
advantage of the existence of this local list, additionally using
it to map partial hashes to their positions in the blocklist. In
principle, both for Safe Browsing and for other applications,
Checklist could use other PIR-by-keywords techniques or a
local blocklist of a diï¬€erent size, allowing diï¬€erent tradeoï¬€s
between storage, communication, and latency.
Remaining privacy leakage. Checklist prevents the Safe Brows-
ing server from learning the partial hash of the URL that the
client is visiting. However, the fact that the client makes a
query to the server at all leaks some information to the server:
the server learns that the client visited some URL whose par-
tial hash appears on the blocklist. While this minimal leakage