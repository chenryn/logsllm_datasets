title:EarArray: Defending against DolphinAttack via Acoustic Attenuation
author:Guoming Zhang and
Xiaoyu Ji and
Xinfeng Li and
Gang Qu and
Wenyuan Xu
EarArray: Defending against DolphinAttack
via Acoustic Attenuation
Guoming Zhang
Zhejiang University
PI:EMAIL
Xiaoyu Ji∗
Xinfeng Li
Zhejiang University
PI:EMAIL
Zhejiang University
PI:EMAIL
Gang Qu
University of Maryland
Wenyuan Xu∗
Zhejiang University
PI:EMAIL
PI:EMAIL
Abstract—DolphinAttacks (i.e.,
inaudible voice commands)
modulate audible voices over ultrasounds to inject malicious
commands silently into voice assistants and manipulate controlled
systems (e.g., doors or smart speakers). Eliminating DolphinAt-
tacks is challenging if ever possible since it requires to modify
the microphone hardware. In this paper, we design EarArray,
a lightweight method that can not only detect such attacks but
also identify the direction of attackers without requiring any
extra hardware or hardware modiﬁcation. Essentially, inaudible
voice commands are modulated on ultrasounds that inherently
attenuate faster than the one of audible sounds. By inspecting
the command sound signals via the built-in multiple microphones
on smart devices, EarArray is able to estimate the attenuation
rate and thus detect the attacks. We propose a model of the
propagation of audible sounds and ultrasounds from the sound
source to a voice assistant, e.g., a smart speaker, and illustrate
the underlying principle and its feasibility. We implemented
EarArray using two specially-designed microphone arrays and
our experiments show that EarArray can detect inaudible voice
commands with an accuracy of 99% and recognize the direction
of the attackers with an accuracy of 97.89%.
I.
INTRODUCTION
More than 3.25 billion voice assistants (e.g., Siri, Alexa)
have been installed around the world, and it is anticipated that
by 2023 the number will reach up to eight billion [1]. Re-
searchers have identiﬁed various attacks against such systems,
and one of the most devastating attacks is DolphinAttack [14],
whereby attackers can inject inaudible voice commands and
performs various malicious attacks, such as open a door, make
a phone call, or place an order. DolphinAttacks modulate
malicious voice commands onto ultrasounds and thus create
inaudible voice commands. As the ultrasound is received by a
microphone, its non-linearity vulnerability will demodulate the
voice command from the ultrasound carrier into the baseband
and the injected command exhibits almost no difference from
the audible command.
To defend against DolphinAttacks, researchers have pro-
posed two types of strategies. The ﬁrst class detects the
attacks by analyzing the subtle yet distinct characteristics
*Corresponding author
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24551
www.ndss-symposium.org
Fig. 1. When an inaudible voice command (i.e., DolphinAttack) is played
to a smart speaker, the inherent frequency difference will result in measurable
discrepancy in terms of propagation attenuation. By measuring the attenuation
properties of the incoming sound, EarArray can recognize whether it is an
inaudible voice command and even tell the direction of the attacker. The sig
1 represents the voice signal captured by the ﬁrst microphone.
embedded in the received sound signals, e.g, the unique high-
frequency components caused by the demodulation process
in the microphones [14] or the nonlinearity distortion created
when the malicious voice commands pass through microphone
circuits [35]. However, a sophisticated attacker [36] can re-
move such distinct characteristics and bypass the detection.
The second class is to actively cancel the malicious inaudible
voice commands by emitting an inverted ultrasound [36]. Such
methods not only rely on extra ultrasound devices but also
require to constantly emit ultrasound, which has shown to
induce health issues, e.g., hearing loss, nausea, headache [2],
[3], and to repel pets, such as dog and cat.
In this paper, we proposed a lightweight detection method,
EarArray, which requires no extra hardware or hardware
modiﬁcation. Instead of utilizing the signal distortion caused
by the microphones, EarArray looks into the propagation
difference between inaudible voice commands (i.e., ultrasound)
and audible ones. As depicted in Fig. 1, when a voice
command is played by a speaker, the voice propagates to
the smart device (e.g., smartphone and smart speaker) and
reaches to its microphones at various times depending on the
distances between the speaker and the microphones. On the
smart device side, each microphone will receive a sound with
the amplitude inversely proportional to the square of distance
as well as the attenuation rate. Notably, the attenuation rate
is, in terms, proportional to the square of sound frequency.
Therefore, EarArray shall be able to estimate whether the
command is an audible one or an inaudible one with the
measurements obtained by multiple microphones (microphone
array, for example) on a smart device because the decaying
rate of ultrasounds (> 20kHz) is larger than audible sounds
(typically below 5kHz for human voice). The advantage of
EarArray is that it relies on the physics of sound propaga-
EarArrayAllowAttackerVictim DeviceInaudiblesig1sigm…sig1sigm…Denytion, and will not be affected by the microphones’ hardware
characteristics.
EarArray utilizes an interesting yet challenging intuition,
and the effectiveness of EarArray depends on answering the
following questions. (1) Is the attenuation rate difference be-
tween the audible sounds and ultrasound sound large enough to
be measured and utilized? (2) How to estimate the propagation
attenuation efﬁciently? (3) Since the attacker may hide at any
direction to the smart devices, will it always be possible to
detect inaudible commands regardless of where she is? To
answer the aforementioned questions, we ﬁrst theoretically
model the propagation of sound in terms of attenuation to
quantify the measurable difference between ultrasound and
sound. Then we specially designed two microphone arrays
with three (mimicking the case of a smartphone) and ﬁve
microphones (mimicking the case of a smart speaker like Ama-
zon Echo) respectively. The specially-designed microphone
arrays are placed on a cuboid and a cylinder and a multiplex
data acquisition card is used to collect audio data from the
channels of the microphone array simultaneously. By doing
this, EarArray is able to estimate the attenuation rate by
measuring the amplitude of the recordings from each of the
microphone channels, calculates the power spectral density of
the measured signal, and extracts three representative features.
To be lightweight, EarArray is a software-based solution
and can be integrated into existing commercial products such
as smartphones and Amazon Echo without involving any extra
hardware. EarArray makes use of the three key features and
can utilize a simple machine learning algorithm, i.e., a support
vector machine (SVM) to identify inaudible commands. In
practice, EarArray can be installed on smart speakers and
smartphones, as long as the device has three or more micro-
phones ∗. To better defend against inaudible voice commands
with EarArray, the smart speaker manufacturer can further
optimize the distribution of microphones, e.g., keeping the
angles of microphones in different plane, which is already a
solution for most smart speakers such as Amazon Echo, as
shown in Fig. 4. We extensively evaluated the performance
of EarArray by varying the attack location, angles, ambient
noises, and the carrier frequency of inaudible voice commands,
etc. Our experiments show that EarArray can be effective
and robust in various conditions.
In summary, our contributions are summarized as follows:
• We discovered that
the propagation attenuation of
audible commands and inaudible ones is different and
thus can be used to detect DolphinAttacks. We theoret-
ically analyze the attenuation difference by simulating
the sound propagation over a microphone array.
• We designed EarArray that detects DolphinAttacks
by estimating the propagation attenuation of voice
commands.
• We implemented two prototypes of EarArray and
evaluated the performance of EarArray with two
specially-designed microphone arrays. EarArray
can detect inaudible voice commands with an accuracy
of 99% and recognize the direction of the attackers
with an accuracy of 97.89%.
Fig. 2.
The transformation progress of inaudible voice commands. By
modulating audible voice commands on ultrasound (e.g., Amplitude Modu-
lation), the voice commands can be inaudible. By utilizing the nonlinearity
of microphones, the voice commands can be demodulated from the high-
frequency carrier and then recognized by a speech recognition system.
II. RATIONALE OF DEFENDING DOLPHINATTACK BY
ACOUSTIC ATTENUATION
In this section, we ﬁrst review the inaudible voice command
attack known as DolphinAttack [14], then we present the basics
of the attenuation of acoustic waves and give the rationale why
it can be used to detect DolphinAttack. Finally, we analyze
popular smart devices and show the feasibility of detecting
DolphinAttacks from the support of multiple microphones.
A. DolphinAttack: An Inaudible Voice Commands Attack
The key idea of inaudible voice commands attack [14] is
to modulate voice commands on ultrasonic carriers such that
these inaudible commands can be captured by the microphone
and demodulated back to the original voice commands. Since
the frequencies at which the modulated voice commands
propagate in the air are above 20 kHz, this kind of attack
is completely inaudible to human ears and hard to be detected
by human.
Fig. 2 shows the three stages of how the inaudible voice
commands are transformed. In Stage 1, the voice commands
are Amplitude-modulated (AM) on ultrasound carrier (e.g., 25
kHz) and therefore there are only high-frequency ultrasound
components shown in the frequency domain. In Stage 2,
both ultrasound and the low-frequency voice commands are
recovered by using the nonlinearity of microphone hardware.
In the ﬁnal Stage 3, high-frequency ultrasound component
has been ﬁltered by the low-pass ﬁlter and only the voice
commands remain. Thus the demodulated voice command
will be the same as normal voice commands, making it very
difﬁcult to directly detect the inaudible voice commands attack.
Especially, the attack voice commands appear just after the
microphone module.
Our defense method against such attacks is inspired by
the physical phenomenon that the incident wave of different
frequencies traveling around a geometrical object (such as
smart devices) will have different attenuation properties. This
is because that the attenuation of the acoustic wave is directly
related to the frequency, distance, and obstacle, etc. As we
will elaborate next in Section II-B. Therefore, we can use the
attenuation distinction of ultrasound and sound perceived from
the smart devices to detect inaudible voice command attacks.
B. Attenuation of Acoustic Sounds
∗Nowadays almost all smartphones have at least three microphones for
noise reduction, as shown in Tab. I
Acoustic attenuation describes that
the intensity of an
acoustic wave decreases as the wave propagates in the medium.
2
ADCSR SystemAMPLPFStage2: Ultrasound & SoundStage3: SoundStage1: UltrasoundHere we consider three main sources for the acoustic attenu-
ation: 1) the inverse-square law; 2) sound absorption; and 3)
diffraction.
1) The inverse-square law: The inverse-square law states
that the intensity of waves is inversely proportional to the
square of the distance (d) from the source of the wave. As the
acoustic wave propagates in the air, the circumference of the
acoustic circle expands larger with the increase of the traveling
distance. So the energy per unit length decreases. Theoretically,
the attenuation of wave (Linv) can be expressed as:
Linv ∝ d2
(1)
According to Eq.1, the sound pressure level (SPL) of sound
received by microphones located at places with different dis-
tances from the sound source will vary. This type of attenuation
is related to the traveling distance.
2) Absorption Attenuation: This type of attenuation is
caused by thermal or viscous effects and is related to the
acoustic frequency. The thermal effect is that the coherent
molecular motion of the sound waves is transformed into
the incoherent molecular motion in the air, which directly
transmits the vibration to the medium as heat. Another cause
is the energy consumption caused by the viscosity of the
air and the attenuation of sound in air also varies with
temperature and humidity [15]. This type of attenuation is a
power law frequency-dependent acoustic attenuation, and can
be expressed as:
E(d + ∆d) = E(d)e−a(w)∆d
(2)
where E denotes the amplitude of an acoustic ﬁeld variable,
∆d represents wave traveling distance, w denotes the angular
frequency of wave, a(w) is the attenuation coefﬁcient, and
a(w) = a0wn, n ∈ [0, 2]
(3)
and a0 and n are tissue-dependent attenuation parameters [16].
From Eq. (2) and (3), we can conclude that attenuation in-
creases with acoustic frequency and distance. Therefore, high-
frequency signals received by different microphones placed at
different positions will differ more than low-frequency signals.
This phenomenon inspires us to detect the inaudible voice
commands by using multiple microphones.
3) Diffraction Attenuation: Diffraction [15] occurs when
the spreading of the wave bends around obstacles, corners, and
through openings. For example, when an obstacle is in the path
of a spreading wave, the wave will bend around the obstacle
and spread into the shadow regions behind it. The amount
of diffraction will be inversely proportional to the acoustic
frequency (f):
Ldif ∝ f
(4)
where Ldif represents the attenuation caused by diffraction.
When the wavelength of a low-frequency sound is equal
to or larger than the size of a smart device, the effect of
diffraction of low-frequency sound will be obvious. Large
wavelength waves will diffract around the edge of the smart