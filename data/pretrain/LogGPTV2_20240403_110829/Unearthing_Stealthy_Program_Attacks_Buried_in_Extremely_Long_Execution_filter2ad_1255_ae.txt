a
t
s
n
i
r
o
i
0.4
0.35
0.3
0.25
0.2
0.15
0.1
1.3
1.2
1.1
1
0.9
0.8
0.7
(C.A.+F.A.)
(C.A.)
(C.A.+F.A.)
(C.A.)
(a) libpcre
(b) sendmail
C.A.+F.A.: Inter- and intra-cluster detection combined.
C.A.: Inter-cluster detection only.
Figure 8: Detection (analysis) overhead of our approach.
Compared with the analysis procedure, dynamic function
call tracing incurs a noticeable overhead. sshd experiences
a 167% overhead on average when our Pintool is loaded. A
similar 141% overhead is reported by Jalan and Kejariwal in
their dynamic call graph Pintool Trin-Trin [24]. Advanced
tracing techniques, e.g., probe mode pintool, branch target
store [48], etc., can potentially reduce the tracing overhead
to less than 10% toward a real-time detection system.
Another choice to deploy our detection solution is to pro-
ﬁle program behaviors through system calls as we demon-
strate using sendmail. System calls can be traced through
SystemTap with near-zero overhead [43], but it sacriﬁces the
capability to reveal user-space program activities and down-
grades the modeling/detection accuracy.
Our approach can support oﬄine detection or forensics of
program attacks, in which case accuracy is the main concern
instead of performance [42]. Our Pintool enables analysts to
locate anomalies within execution windows, and our matri-
ces provide caller information for individual function calls.
This information helps analysts quickly reduce false alarms
and locate vulnerable code segments.
Summary We evaluate the detection capability, accuracy,
and performance of our detection prototype on Linux.
• Our approach successfully detects all reproduced aber-
rant path attack attempts against sshd, libpcre and
sendmail with less than 0.0001 false positive rates.
• Our approach is accurate in detecting diﬀerent types of
synthetic aberrant path anomalies with a high detection
rate (> 0.9) and a low false positive rate (< 0.01).
• Our approach analyzes program behaviors fast; it only
incurs 0.1~1.3 ms analysis overhead (excluding tracing)
per behavior instance (1k to 50k function/system calls
in our experiments).
7. RELATED WORK
Conventional program anomaly detection systems (aka
host-based intrusion detection systems) follow Denning’s in-
trusion detection vision [7]. They were designed to detect
illegal control ﬂows or anomalous system calls based on two
i) n-gram short call sequence validation
basic paradigms:
that was introduced by Forrest et al. [11]; and ii) automaton
transition veriﬁcation, which was ﬁrst described by Kosore-
sow and Hofmeyr [26] (DFA) and formalized by Sekar et
al. [39] (FSA) and Wagner and Dean [45] (NDPDA).
The basic n-gram model was further studied in [10,21] and
several advanced forms of it were developed, e.g., machine
learning models [22, 29] and hidden Markov models [14, 47].
The essence of n-gram is to model and analyze local fea-
tures of program traces with a small n. Enlarging n results
in exponential convergence and storage issues. However,
small n (local feature analysis) makes it possible for attack-
ers to evade the detection by constructing a malicious trace
of which any small fragment is normal. Wagner and Soto
ﬁrst demonstrated such a mimicry attack with a malicious
sequence of system calls diluted to normal [46].
Although Wagner and Soto’s attack evades the detection
from n-gram methods, it is system-call-level tactics, and it
may introduce illegal control ﬂows, which can be captured
by pushdown automaton (PDA) methods [8, 9, 15, 16]. This
mimicry attack could also involve anomalous call arguments,
which can be detected by argument analysis [15, 31].
Research on automaton detection started with the goal
of performing trace analysis on a large scale. However, all
existing automaton models are equivalents to FSA/PDA.
They only verify state transitions individually, i.e., they are
ﬁrst-order models. Program counter and call stack infor-
mation were used to help precisely deﬁne each state (a sys-
tem call) in an automaton [8, 9, 39]. Function calls/returns
are included as automaton states in the Dyck model [16].
Models combining static and dynamic analysis were devel-
oped [23,30], and individual transition frequencies have been
employed to detect DoS attacks [13].
All existing automaton detection methods cannot be di-
rectly used for detecting aberrant path anomalies, as ex-
plained earlier in the paper. Existing detection methods
lack the ability to correlate events in diﬀerent control-ﬂow
segments in a large-scale execution window. An automaton
that is capable to do so would have an exponential complex-
ity in term of training overhead and storage.
The relation among events that occur far away has not
been systematically studied in the literature.
In this pa-
per, we formalize the problem of event correlation analysis
within large-scale execution windows and bring forward the
ﬁrst solution that correlates events in a large-scale execution
window for anomaly detection purpose.
Clustering and classiﬁcation techniques have been widely
used in malware classiﬁcation [2, 12, 25, 36]. Malware clas-
siﬁcation aims at extracting abstract malware behavior sig-
natures and identiﬁes a piece of malware using one or multi-
ple signatures. However, program anomaly detection mod-
els normal behaviors and exams an entire proﬁle to decide
whether it is normal. It is not suﬃcient to conclude an in-
coming behavior is normal that one feature of it is normal.
Correlation analysis techniques were developed to detect
network intrusions. Valeur et al. described a comprehensive
framework to correlate alerts from various IDS systems [44].
Perdisci et al. proposed 2v-gram scheme to discover related
bytes v positions apart in traﬃc payload [35]. Gu et al.
developed a system to correlate temporal network events
for detecting botnets under speciﬁc bot behavior hypothe-
ses [17]. In comparison, we address the program anomaly de-
tection problem by developing new algorithms to overcome
the unique behavior diversity and scalability challenges.
Defenses against speciﬁc known program attacks have been
investigated besides anomaly detection. For example, Moore
411introduced backscatter analysis to discover DoS at-
et al.
tacks [33], and Brumley et al.
invented RICH to prevent
integer overﬂow [4]. These defenses target speciﬁc attack sig-
natures and cannot detect unknown attacks. Therefore, they
are diﬀerent from general anomaly detection approaches.
8. CONCLUSIONS AND FUTURE WORK
In this paper, we studied aberrant path attacks and de-
signed a two-stage anomaly detection approach to unearthing
these attacks from extreme long program traces. The sig-
niﬁcance of our work is the new capability to eﬃciently dis-
cover subtle program inconsistencies and anomalies that oc-
cur far apart. Our work advances the state-of-the-art pro-
gram anomaly detection by demonstrating the eﬀectiveness
of large-scale program behavioral modeling and enforcement
against runtime anomalies that are buried in extremely long
execution paths. In future work, we plan to adopt advanced
dynamic tracing techniques and build real-time security in-
cidence response systems on top of our detection solution.
9. ACKNOWLEDGMENTS
This work has been supported by ONR grant N00014-
13-1-0016 and ARO YIP W911NF-14-1-0535. The authors
would like to thank Barbara Ryder for her feedback on the
work. The authors would like to thank Changhee Jung and
Dongyoon Lee for their comments on performance analysis.
10. REFERENCES
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti.
Control-ﬂow integrity. In Proceedings of the ACM
Conference on Computer and Communications
Security, pages 340–353, 2005.
[2] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kr¨ugel,
and E. Kirda. Scalable, behavior-based malware
clustering. In Proceedings of the Network and
Distributed System Security Symposium, 2009.
[3] S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataﬂow
anomaly detection. In Proceedings of the IEEE
Symposium on Security and Privacy, May 2006.
[4] D. Brumley, D. X. Song, T. cker Chiueh, R. Johnson,
and H. Lin. RICH: Automatically protecting against
integer-based vulnerabilities. In Proceedings of the
Network and Distributed System Security Symposium,
2007.
[5] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K.
Iyer. Non-control-data attacks are realistic threats. In
Proceedings of the USENIX Security Symposium,
volume 14, pages 12–12, 2005.
[6] M. Cova, D. Balzarotti, V. Felmetsger, and G. Vigna.
Swaddler: An approach for the anomaly-based
detection of state violations in web applications. In
Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
63–86, 2007.
[7] D. E. Denning. An intrusion-detection model. IEEE
Transactions on Software Engineering, 13(2):222–232,
1987.
[8] H. H. Feng, J. T. Giﬃn, Y. Huang, S. Jha, W. Lee,
and B. P. Miller. Formalizing sensitivity in static
analysis for intrusion detection. In Proceedings of the
IEEE Symposium on Security and Privacy, pages
194–208, 2004.
[9] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and
W. Gong. Anomaly detection using call stack
information. In Proceedings of the IEEE Symposium
on Security and Privacy, pages 62–75, 2003.
[10] S. Forrest, S. Hofmeyr, and A. Somayaji. The
evolution of system-call monitoring. In Proceedings of
the Annual Computer Security Applications
Conference, pages 418–430, 2008.
[11] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A.
Longstaﬀ. A sense of self for Unix processes. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 120–128, 1996.
[12] M. Fredrikson, S. Jha, M. Christodorescu, R. Sailer,
and X. Yan. Synthesizing near-optimal malware
speciﬁcations from suspicious behaviors. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 45–60, 2010.
[13] A. Frossi, F. Maggi, G. L. Rizzo, and S. Zanero.
Selecting and improving system call models for
anomaly detection. In Detection of Intrusions and
Malware, and Vulnerability Assessment, pages
206–223. Springer, 2009.
[14] D. Gao, M. K. Reiter, and D. Song. Behavioral
distance measurement using hidden Markov models.
In Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
19–40, 2006.
[15] J. T. Giﬃn, D. Dagon, S. Jha, W. Lee, and B. P.
Miller. Environment-sensitive intrusion detection. In
Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
185–206, 2006.
[16] J. T. Giﬃn, S. Jha, and B. P. Miller. Eﬃcient
context-sensitive intrusion detection. In Proceedings of
the Network and Distributed System Security
Symposium, 2004.
[17] G. Gu, P. A. Porras, V. Yegneswaran, M. W. Fong,
and W. Lee. BotHunter: Detecting malware infection
through IDS-driven dialog correlation. In Proceedings
of the USENIX Security Symposium, volume 7, pages
1–16, 2007.
[18] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu.
LEAPS: Detecting camouﬂaged attacks with
statistical learning guided by program analysis. In
Proceedings of the Annual IEEE/IFIP International
Conference on Dependable Systems and Networks,
pages 491–502, 2014.
[19] The heartbleed bug, http://heartbleed.com/.
[20] N. Hubballi, S. Biswas, and S. Nandi. Sequencegram:
n-gram modeling of system calls for program based
anomaly detection. In Proceedings of the International
Conference on Communication Systems and Networks,
pages 1–10, January 2011.
[21] H. Inoue and A. Somayaji. Lookahead pairs and full
sequences: a tale of two anomaly detection methods.
In Proceedings of the Annual Symposium on
Information Assurance, pages 9–19, 2007.
[22] M. R. Islam, M. S. Islam, and M. U. Chowdhury.
Detecting unknown anomalous program behavior
using API system calls. In Informatics Engineering
and Information Science, pages 383–394. Springer
Berlin Heidelberg, 2011.
412[23] J. H. Jafarian, A. Abbasi, and S. S. Sheikhabadi. A
gray-box DPDA-based intrusion detection technique
using system-call monitoring. In Proceedings of the
Annual Collaboration, Electronic messaging,
Anti-Abuse and Spam Conference, pages 1–12, 2011.
[24] R. Jalan and A. Kejariwal. Trin-Trin: Who’s calling?
a Pin-based dynamic call graph extraction framework.
International Journal of Parallel Programming,
40(4):410–442, 2012.
[25] S. Karanth, S. Laxman, P. Naldurg, R. Venkatesan,
J. Lambert, and J. Shin. Pattern mining for future
attacks. Technical Report MSR-TR-2010-100,
Microsoft Research, 2010.
[26] A. P. Kosoresow and S. A. Hofmeyr. Intrusion
detection via system call traces. IEEE software,
14(5):35–42, 1997.
[27] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and
G. Vigna. Automating mimicry attacks using static
binary analysis. In Proceedings of the USENIX
Security Symposium, pages 11–11, 2005.
[28] J. P. Lanza. SSH CRC32 attack detection code
contains remote integer overﬂow. Vulnerability Notes
Database, 2001.
[29] W. Lee and S. J. Stolfo. Data mining approaches for
intrusion detection. In Proceedings of the USENIX
Security Symposium, pages 6–6, 1998.
[37] G. K. Pullum. Context-freeness and the computer
processing of human languages. In Proceedings of the
annual meeting on Association for Computational
Linguistics, pages 1–6, Stroudsburg, PA, USA, 1983.
[38] B. Sch¨olkopf, R. C. Williamson, A. J. Smola,
J. Shawe-Taylor, and J. C. Platt. Support vector
method for novelty detection. In Proceedings of the
annual conference on Neural Information Processing
Systems, volume 12, pages 582–588, 1999.
[39] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A
fast automaton-based method for detecting anomalous
program behaviors. In Proceedings of the IEEE
Symposium on Security and Privacy, pages 144–155,
2001.
[40] H. Shacham, M. Page, B. Pfaﬀ, E.-J. Goh,
N. Modadugu, and D. Boneh. On the eﬀectiveness of
address-space randomization. In Proceedings of the
ACM Conference on Computer and Communications
Security, pages 298–307, 2004.
[41] A. Sotirov. Heap Feng Shui in JavaScript. Black Hat
Europe, 2007.
[42] S. Sundaramurthy, J. McHugh, X. Ou,
S. Rajagopalan, and M. Wesch. An anthropological
approach to studying CSIRTs. IEEE Security &
Privacy, 12(5):52–60, September 2014.
[43] Systemtap overhead test, https://sourceware.org/
[30] Z. Liu, S. M. Bridges, and R. B. Vaughn. Combining
ml/systemtap/2006-q3/msg00146.html.
static analysis and dynamic learning to build accurate
intrusion detection models. In Proceedings of IEEE
International Workshop on Information Assurance,
pages 164–177, 2005.
[44] F. Valeur, G. Vigna, C. Kruegel, and R. A. Kemmerer.
A comprehensive approach to intrusion detection alert
correlation. IEEE Transactions on Dependable and
Secure Computing, 1(3):146–169, July 2004.
[31] F. Maggi, M. Matteucci, and S. Zanero. Detecting
[45] D. Wagner and R. Dean. Intrusion detection via static
intrusions through system call sequence and argument
analysis. IEEE Transactions on Dependable and
Secure Computing, 7(4):381–395, 2010.
analysis. In Proceedings of the IEEE Symposium on
Security and Privacy, pages 156–168, 2001.
[46] D. Wagner and P. Soto. Mimicry attacks on
[32] J. S. Mertoguno. Human decision making model for
autonomic cyber systems. International Journal on
Artiﬁcial Intelligence Tools, 23(06):1460023, 2014.
host-based intrusion detection systems. In Proceedings
of the ACM Conference on Computer and
Communications Security, pages 255–264, 2002.
[33] D. Moore, C. Shannon, D. J. Brown, G. M. Voelker,
[47] C. Warrender, S. Forrest, and B. Pearlmutter.
and S. Savage. Inferring internet Denial-of-Service
activity. ACM Transactions on Computer Systems,
24(2):115–139, 2006.
[34] The paradyn project, http://www.paradyn.org/.
[35] R. Perdisci, G. Gu, and W. Lee. Using an ensemble of
one-class SVM classiﬁers to harden payload-based
anomaly detection systems. In Proceedings of the
International Conference on Data Mining, pages
488–498, December 2006.
[36] R. Perdisci, W. Lee, and N. Feamster. Behavioral
clustering of HTTP-based malware and signature
generation using malicious network traces. In
Proceedings of the USENIX Symposium on Networked
Systems Design and Implementation, pages 26–26,
2010.
Detecting intrusions using system calls: Alternative
data models. In Proceedings of the IEEE Symposium
on Security and Privacy, pages 133–145, 1999.
[48] Y. Xia, Y. Liu, H. Chen, and B. Zang. CFIMon:
Detecting violation of control ﬂow integrity using
performance counters. In Proceedings of the Annual
IEEE/IFIP International Conference on Dependable
Systems and Networks, pages 1–12, June 2012.
413