erly protected (e.g., read access to ‘other’ users and no passphrase
encryption). With elevated privileges, more powerful attacks can
be performed (e.g., beyond accessing/modifying TLS traffic). We do
not consider such privileged attackers, assuming having root access
on the appliance would be much more difficult than compromising
other low-privileged accounts. Note that, in most cases, the appli-
ance is simply an ordinary Linux/Windows box with specialized
software/kernel, resulting a large trusted code base (TCB).
3 RELATED WORK
Several studies have been recently conducted on TLS interception,
TLS certificate validation, and forged TLS certificates. We briefly
review studies that are closely related to our work.
Interception. Jarmoc [41] uncovered several TLS vulnerabilities
in the certificate validation process of four network appliances
using a test framework with seven certificate validation checks.
Dormann [6, 17] relied on badssl.com’s tests to check for vulnera-
bilities in two network appliances, finding flaws in the certificate
validation process and the acceptance of insecure TLS parameters.
Dormann also compiled a list of possibly affected software and
hardware appliances.
Carnavalet and Mannan [32] proposed an extensive framework
for analyzing client-end TLS intercepting applications, such as anti-
virus and parental control software. They analyzed 14 applications
(under Windows 7), revealing major flaws such as pre-generated
certificates, faulty certificate validation, insecure private key protec-
tion, improper TLS parameter mapping, vulnerabilities to known
TLS attacks, and unsanitized trusted CA stores. Durumeric et al. [35]
later additionally included 5 TLS proxies under Mac OS, and 12
network appliances. They found that TLS proxies under Mac OS
introduce more flaws than their Windows counterparts. They also
showed that web servers can detect TLS interception, through the
HTTP User-Agent header and protocol fingerprinting.
In March 2017, US-CERT [22] published an alert regarding TLS
interception, to raise awareness of the dangers of TLS interception
and its impact. Ruoti et al. [44] surveyed 1976 individuals regarding
TLS inspection, to understand user opinion regarding legitimate
uses of TLS inspection. Over 60% of the surveyed individuals had
a negative response towards TLS inspection, and cited malicious
hackers and governments as their main concerns.
Certificates scans. Huang et al. [40] analyzed over three million
real-world TLS connections to facebook.com to detect forged cer-
tificates. They found that around 0.2% of the analyzed connections
make use of a forged certificate, caused mainly by anti-virus soft-
ware, network appliances and malware. O’Neill et al. [42] analyzed
over 15 million real-world TLS connections using Google AdWords
campaigns. They found that nearly 0.4% of the TLS connections
were intercepted by TLS proxies, mostly by anti-virus products and
network appliances, with the highest interception rates in France
and Romania. In addition, Issuer Organization fields in some cer-
tificates matched the names of malware, such as ‘Sendori, Inc’,
‘Web-MakerPlus Ltd’, and ‘IopFailZeroAccessCreate’.
Certificates validation. Fahl et al. [36] analyzed 13,500 free An-
droid apps for MITM vulnerabilities. They found that 8% of the
analyzed apps contain potentially vulnerable TLS modules. They
also performed manual inspection of 100 apps, and successfully
executed MITM attacks on 41, capturing credentials for widely used
commercial and social websites, e.g., Google, Facebook, Twitter,
Paypal, and several banks. Their attacks relied on exploiting flaws
in the certificate validation process; many apps ignored the chain of
trust validation, accepting self-signed certificates, and mismatched
common names.
Georgiev et al. [37] demonstrated that several widely used ap-
plications and development libraries, such as Amazon’s EC2 Java
library, Amazon and Paypal’s SDK, osCommerce, and Java web
services, among others, suffered from certificate validation vulnera-
bilities, leading to generic MITM attacks. These vulnerabilities were
attributed to be caused by (primarily) the use of poorly designed
APIs, such as JSSE and OpenSSL.
Brubaker et al. [30] designed an automated approach for testing
the certificate validation modules of several well-known TLS imple-
mentations. They first scanned the Internet for servers with port
443 open using ZMap [25], and collected all the available certificates.
Then, they permuted the certificate parameters and possible X509
values, compiling a list of 8 million Frankencerts. Using Frankencerts
and differential testing, Brubaker et al. found over 200 discrepan-
cies in these commonly used TLS implementations (e.g., OpenSSL,
GnuTLS and NSS). He et al. [38] designed an automated static anal-
ysis tool for analyzing TLS libraries and applications. They then
evaluated Ubuntu 12.04 TLS packages, and found 27 zero-day TLS
vulnerabilities, related to faulty certificate/hostname validation.
Sivakorn et al. [45] proposed a black-box hostname verification
testing framework for TLS libraries and applications. They evalu-
ated the hostnames accepted by seven TLS libraries and applications,
and found eight violations, including: invalid hostname characters,
incorrect null characters parsing, and incorrect wildcard parsing.
Chau et al. [31] made use of a symbolic execution approach to
test the certificate validation process of nine TLS libraries, com-
pared to RFC 5280 [39]. They found 48 instances of noncompliance;
libraries ignored several X509 certificate parameters, such as the
pathLenConstraint, keyUsage, extKeyUsage, and ‘notBefore’ valid-
ity dates.
Comparison. The most closely related work is by Durumeric et
al. [35] (other studies mostly involved analyzing TLS libraries and
Analyzing TLS Interception in Network Appliances
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Figure 2: Framework components and test architecture with
a router
Figure 1: Framework components and the overall test archi-
tecture
client-end proxies). While their work focuses primarily on finger-
printing TLS interception, in addition to a brief security measure-
ment for several HTTPS proxies, we develop an extensive frame-
work dedicated for analyzing the TLS interception on network
appliances. They checked/rated the highest TLS version supported
by a target proxy, while we examine all the supported versions by
the proxy, in addition to their respective mapping/mirroring to the
client side. Durumeric et al.’s certificate validation tests include:
expired, self-signed, invalidly signed certificates, and certificates
signed by CAs with known private keys; we include more tests for
this important aspect (a total of 32 distinct tests). We also include
several new tests such as: checking the content of the CA trusted
store and the certificate parameter mapping, locating the private
signing keys of the proxies and examining their security (including
checking pre-generated root certificates); these tests are mostly
added/extended from [31, 32].
In terms of results, for the four overlapping products with Du-
rumeric et al. [35], we observed a few differences; note that our
analysis was performed on newer versions of the products and
Durumeric et al. shared their results to the affected vendors more
than a year prior to our tests. They found that WebTitan Gateway
had a broken certificate validation process and offered RC4 and
modern ciphers; we found that WebTitan does not perform any
certificate validation and still offers RC4, in addition to weak ci-
phers, with 3DES and IDEA. We found that Untangle no longer
offers RC4 ciphers (3DES is offered). Cisco Ironport WSA no longer
offers RC4 and export-grade ciphers. According to [35], Microsoft
TMG performed no certificate validation and the highest supported
SSL/TLS version was SSLv2.0; it now performs certificate validation,
and supports SSL versions 2.0, 3.0 and TLS 1.0.
4 PROPOSED FRAMEWORK
In this section, we present the setup/architecture of the proposed
framework, and the major components and tests included in it.
4.1 Test Setup/Architecture
Our framework consists of three virtual machines: a client, a web
server, and the TLS intercepting network appliance; see Figure 1.
The client machine (Windows 7 SP1) is located behind the network
appliance; we update the client with all available Windows updates,
and install up-to-date Mozilla Firefox, Google Chrome, and Internet
Explorer 11 on it. We insert the TLS proxy’s root certificate into the
client’s trusted root stores (both Windows and Mozilla stores). We
use a browser to initiate HTTPS requests to our local Apache web
server, and the online TLS security testing suites (for certain tests).
These requests are intercepted by the TLS proxy being analyzed.
The second machine hosts a web server (Apache under Ubuntu
16.04), configured to accept HTTP requests on port 80 and HTTPS
requests on port 443; all port 80 requests are redirected to port
443. The web server is initially configured to accept all TLS/SSL
protocol versions, and all available cipher suites. The server name
is configured to be apache.host, as the crafted certificates must hold
a domain name instead of an IP address. We generate the faulty
certificates using OpenSSL, which are served from the Apache web
server. It also hosts the patched howsmyssl.com code [10].
The pre-installed OpenSSL version on the Ubuntu 16.04 distribu-
tion is not compiled with SSLv3 support. Thus, in order to test the
acceptance and mapping of SSLv3 only, we rely on an identically
configured older version of Ubuntu (14.04), with an older OpenSSL
version that supports SSLv3.
The third machine is the virtual network appliance that we want
to test. These appliances are typically available as a trial version
from a vendor’s website, with a pre-configured OS, either as an ISO
image file or an Open Virtualization Format file. The appliances
are configured to intercept TLS traffic either as a transparent or
explicit proxy, depending on the available modules. If both are
available, transparent proxies are prioritized, as they do not require
any client-side network configuration. We disable services such as
firewall and URL filtering, if bundled in the appliances, to avoid any
potential interferences in our TLS analysis. The root CA certificates
corresponding to our faulty test certificates are injected into the
trusted stores of the network appliances.
We setup a local DNS entry for apache.host on the client, web
servers and network appliances machines. Operating systems match
local DNS entries, found typically in the hosts file, before remote
DNS entries, resulting in the correct mapping of our test server’s
domain name to its corresponding IP address.
The framework requires the use of three different interfaces
on each virtual network appliance. The Client Interface is used to
connect to the Windows 7 client. The traffic incoming from this
interface is intercepted by the TLS proxy. Transparent proxies only
NetworkApplianceWindows 7 ClientApache Web ServerInternetServer InterfaceClient InterfaceNATInterfaceNetworkApplianceWindows 7 ClientApache Web ServerInternetClient InterfaceServer InterfaceNATInterfaceRegular Router(e.g. pfSense)Client InterfaceASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Louis Waked, Mohammad Mannan, and Amr Youssef
require the network appliance to be the default gateway for the
client, while explicit proxies require the client to configure the proxy
settings with the appliance’s socket details. The Server Interface is
used to connect to the Apache web server. The WAN Interface is used
to connect to the Internet, through Network Address Translation
(NAT). However, some appliances support one or two interfaces.
In such cases, we add a fourth virtual machine, that acts solely
as a router with multiple interfaces. We use pfSense as the router
(without TLS interception), relying on it for NATting and routing
traffic of the three interfaces required in our setup; see Figure 2.
The client and the network appliance are connected to the Client
Interface, the web server is connected to the Server Interface, and the
Internet connectivity is provided through NAT on a third interface
on via pfSense. A local DNS entry for apache.host is also added to
this router.
4.2 CA Trusted Store
We first need to locate the CA trusted store of the TLS proxy. This
allows us to inject our root CA certificates into the stores, required
for most of our tests.
Injecting custom certificates into a trusted store could be trivial,
if the appliance directly allows adding custom root CAs (e.g., via
its user interface). If no such interface is offered, we attempt to get
a command line (shell) access through the SSH service, if available,
by enabling the SSH server first through the settings panels. If SSH
is unavailable, we mount the virtual disk image of the appliance
on a separate Linux machine. When mounting, we perform several
attempts to find the correct filesystem type and subtype used by
the appliance (undocumented). After a successful mount, we search
the entire filesystem for digital certificates in known formats, such
as “.crt”, “.pem”, “.cer”, “.der”, and “.key”. We thus locate several
directories with candidate certificates, and subsequently delete the
content of each file, while trying to access regular websites from the
client. When an “untrusted issuer” warning appears at the client,
we then learn the exact location/directory of the trusted store. This
methodology is used to eliminate duplicate certificates found in
several directories.
We then inject the custom crafted root certificates into the trusted
CA stores. We also parse (via custom scripts) the certificates avail-
able in the trusted stores to identify any expired certificates, or
certificates with short key lengths (e.g., RSA-512 and RSA-1024).
We also check for the presence of root CA certificates from issuers
that are no longer trusted by major browser/OS vendors. Our list
of misbehaving CAs includes: China Internet Network Information
Center (CNNIC [4]), TÜRKTRUST [19], ANSSI [16], woSign [5],
Smartcom [5], and Diginotar [3].
4.3 TLS Version Mapping
To test the SSL/TLS version acceptance and TLS parameter map-
ping/mirroring, we alter the Apache web server’s configuration. We
use a valid certificate whose root CA certificate is imported into the
trusted stores of the client (to avoid warnings and errors). We then
subsequently force one TLS version after another at the web server,
and visit the web server from the client, while documenting the
versions observed in the browser’s HTTPS connection information.
Using this methodology, we are able to analyze the behavior of a
proxy regarding each SSL/TLS version: if a given version is blocked,
allowed, or altered in the client-to-proxy HTTPS connection.
4.4 Certificate Parameters Mapping
We check if the proxy-to-server certificate parameters are mapped
or mirrored to the client-to-proxy certificate parameters. The pa-
rameters studied are signature hashing algorithms, certificate key
lengths, and the EV/DV status.
For testing signature hashing algorithms, we craft multiple valid
certificates with different secure hash algorithms, such as SHA-
256, SHA-384 and SHA-512. We import their root CA certificates
into the trusted stores of the client to avoid warnings and errors.
We subsequently load each certificate and its private key into the
web server, and visit the web page from the browser. We track
the signature algorithms used in the certificates generated by the
TLS proxy for each connection, and learn if the proxy mirrors the
signature hashing algorithms, or use a single hard-coded one.
For testing certificate key lengths, we craft multiple certificates
with different acceptable key sizes, such as RSA-2048, RSA-3072
and RSA-4096. We import their correspondent root CA certificates
into the trusted stores of the client. We subsequently load each
certificate and its private key into the web server, and visit the
web page from the browser. We check the key length used for the
client-to-proxy server certificate generated by the TLS proxy for
each connection, and learn if the proxy mirrors the key-length, or
uses on a single hard-coded length.
We rely on Twitter’s website to study the network appliance’s
behavior regarding EV certificates. We visit twitter.com on the client
machine, and check the client-to-proxy certificate displayed by the
browser. TLS proxies can identify the presence of EV certificates
(e.g., to avoid downgrading them to DV), by parsing the content
and locating the CA/browser forum’s EV OID: 2.23.140.1.1 [7].
4.5 Cipher Suites
Cipher suites offered by the TLS proxy in the proxy-to-server TLS
connection can be examined in multiple ways. We initially rely on
publicly hosted TLS testing suites, howsmyssl.com and the Qualys
client test [18]. Since the connection is proxied, the displayed re-
sults found on the client’s browser are the results of the proxy-to-
server connection, and not the client-to-proxy connection. If the
mentioned web pages are not filtered, for reasons such as the use
unfiltered or non-standard ports, we use Wireshark to capture the
TLS packets and inspect the Client Hello message initiated by the
proxy to locate the list of ciphers offered.
We then compare the list of ciphers offered by the proxy to the
list of ciphers offered by the browsers, learning if the TLS proxy
performs a cipher suite mirroring or uses a hard-coded list. We also
parse the list of ciphers offered by the proxy for weak and insecure
ciphers that could lead to insecure and vulnerable TLS connections.
4.6 Known TLS Attacks
We test TLS proxies for vulnerabilities against well-known TLS
attacks, including: BEAST, CRIME, FREAK, Logjam, and Insecure
Renegotiation. We rely on the Qualys SSL Client Test [18] to confirm
if the TLS proxy is patched against FREAK, Logjam, and Insecure
Analyzing TLS Interception in Network Appliances
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Renegotiation, in addition to checking if TLS compression is en-
abled, which could result in a possible CRIME attack. We visit the
web page from the client browser, which displays the results for
the proxy-to-server TLS connection. Regarding the BEAST attack,
we rely on howsmyssl.com [10], with the modifications from Car-
navalet and Mannan’s [32] to test the proxies that support TLS 1.2
and 1.1.
4.7 Crafting Faulty Certificates
We use OpenSSL to craft our invalid test certificates, specifying
apache.host as the Common Name (CN), except for the wrong CN
test. We then deploy each certificate on our Apache web server, and
request the HTTPS web page from the proxied client, and thus learn
how the TLS proxy behaves when exposed to faulty certificates;
if a connection is allowed, we consider the proxy is at fault. If the
proxy replaces the faulty certificate with a valid one (generated by
itself), leaving no way even for a prudent client (e.g., an up-to-date
browser) to detect the faulty remote certificate, we consider this as a
serious vulnerability. If the proxy passes the unmodified certificate
and relies on client applications to react appropriately (e.g., showing
warning/error messages, or terminating the connection), we still
consider the proxy to be at fault for two reasons: (a) we do not see
any justification for allowing plain, invalid certificates by any TLS
agent, and (b) not all TLS client applications are as up-to-date as
modern browsers, and thus may fail to detect the faulty certificates.
When the certificate’s chain of trust contain intermediate certifi-
cate(s), we place the leaf certificate and intermediate certificate(s) at
the web server, by appending the intermediate certificate(s) public
keys after the server leaf certificate, in SSLCertificateFile. Note that
we inject the issuing CA certificates of the crafted certificates into
the TLS proxy’s trusted store for all tests, except for the unknown
issuer test and the fake GeoTrust test.
We enumerate the list of invalid certificate validation tests that
we used (for details, see Appendix A); we compile this list using
several sources (including [31, 32, 39]).
- Self-signed Certificate: A leaf certificate whose issuer is itself.
- Signature Mismatch: A leaf certificate with a tempered signature.
- Fake GeoTrust: A leaf certificate without an Authority Key Iden-
tifier, and whose untrusted issuer has the same subject name as
the GeoTrust root CA.
- Wrong CN: A leaf certificate with a CN not matching apache.host.
- Unknown Issuer: A leaf certificate with an untrusted issuer.
- Non-CA Intermediate: An intermediate certificate with the CA
basic constraint parameter set to be false.
- X509v1 Intermediate: An intermediate X509v1 certificate with
no CA basic constraint parameter.
- Invalid pathLenConstraint: An intermediate certificate with a
pathLenConstraint of 0 issuing another intermediate certificate.
- Bad Name Constraint Intermediate: An intermediate certificate
constrained for a different domain issues a leaf certificate for
apache.host.
- Unknown Critical X509v3 Extension: A leaf certificate with an un-
known certificate extension object identifier (OID), set to critical.
- Malformed Extension Values: A leaf certificate with an atypical
value for a certificate extension.
- Revoked: A leaf certificate issued by a revoked issuer.
- Expired Leaf, Intermediate and Root: Three tests with either an
expired leaf, intermediate or root certificate.
- Not Yet Valid Leaf, Intermediate and Root: Three tests with either
a leaf, intermediate or root certificate, which is not yet valid.
- Wrong keyUsage in Leaf and Root: Two tests with invalid
keyUsage parameters for a root and a leaf certificate.
- Wrong extKeyUsage in Leaf and Root: Two tests with invalid
extKeyUsage parameters for a root and a leaf certificate.
- Short Key Length in Root and Leaf: Multiple tests using short