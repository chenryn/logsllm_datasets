ceptible to cache attacks [4, 24, 26, 33, 35, 51].
In this
implementation, AES performs 16 lookups to 4 different
T-tables for each of the 10 rounds and combines the val-
ues using xor. The table lookups in the ﬁrst round of
AES are Tj[xi = pi ⊕ ki] where pi is a plaintext byte, ki a
key byte, and i ≡ j mod 4. A typical attack scenario is
a known-plaintext attack. By learning the cache line of
the lookup index xi an attacker learns the upper 4 bits of
the secret key byte xi ⊕ pi = ki. We wrap the entire AES
computation together with the preloading step into a sin-
gle TSX transaction. The preloading step fetches the 4
T-Tables, i.e., it adds 4 KB of data to the read set.
We performed roughly 2 billion encryptions in an
asynchronous attack and measured the cache hits on
the T-table cache lines using Prime+Probe and Flush+
Reload. Figure 7 is a color matrix showing the number of
cache hits per cache line and plaintext-byte value. When
protecting the T-tables with Cloak (cf. Figure 8), the
leakage from Figure 7 is not present anymore.
We ﬁxed the time for which the fully-asynchronous
known-plaintext attack is run. The amount of time cor-
responds to roughly 2 billion encryptions in the baseline
implementation. For the AES T-Table implementation
protected with Cloak we observed a signiﬁcant perfor-
mance difference based on whether or not an attack is
running simultaneously. This is due to the TSX transac-
tion failing more often if under attack.
While not under attack the implementation protected
with Cloak started 0.8% more encryptions than the base-
line implementation (i.e., with preloading) and less than
0.1% of the transactions failed. This is not surprising, as
the execution time of the protected algorithm is typically
below 500 cycles. Hence, preemption or interruption of
the transaction is very unlikely. Furthermore, cache evic-
tions are unlikely because of the small read set size and
optimized preloading (cf. Section 5.2.1). Taking the ex-
ecution time into account, the implementation protected
with Cloak was 0.8% faster than the baseline implemen-
tation. This is not unexpected, as Zacharopoulos [64]
already found that TSX can improve performance.
Next, we measured the number of transactions fail-
ing under Prime+Probe and Flush+Reload. We observed
82.7% and 99.97% of the transactions failing for each
attack, respectively. Failing transactions do not consume
the full amount of time that one encryption would take
as they abort earlier in the function execution. Thus,
the protected implementation started over 37% more en-
cryptions as compared to the baseline implementation
when under attack using Prime+Probe and 2.53 times
the encryptions when under attack using Flush+Reload.
However, out of these almost 3 billion transactions only
500 million transactions succeeded in the case of Prime+
Probe.
In the case of Flush+Reload only 1.4 million
out of 4.9 billion transactions succeeded. Thus, in total
the performance of our protected implementation under a
Prime+Probe attack is only 23.7% of the performance of
the baseline implementation and only 0.06% in the case
of a Flush+Reload attack.
The slight performance gain of Cloak while not being
actively attacked shows that deploying our countermea-
sure for this use case does not only eliminate cache side-
channel leakage but it can also be beneﬁcial. The lower
performance while being attacked is still sufﬁcient given
that leakage is eliminated, especially as the attacker has
to keep one whole CPU core busy to perform the at-
tack and this uses up a signiﬁcant amount of hardware
resources whether or not Cloak is deployed.
6.2 Secret-dependent execution paths
attacks
allow to recover
Powerful
cryptographic
keys [62] and generated random numbers by monitoring
execution paths in libraries [67].
In this example,
we model such a scenario by executing one of 16
functions based on a secret value that the attacker tries
to learn—adapted from the AES example. Like in
previous Flush+Reload attacks [62, 67],
the attacker
USENIX Association
26th USENIX Security Symposium    225
Function
4
8
12 15
Function
4
8
12 15
0
0
4
e
n
i
l
8
e
h
c
a
C
12
15
0
0
4
e
n
i
l
8
e
h
c
a
C
12
15
Figure 9: Color matrix showing cache hits on function
code. Darker means more cache hits. Measurement per-
formed over roughly 100 million function executions for
Prime+Probe (left) and 10 million function executions
for Flush+Reload (right).
Function
4
8
12 15
Function
4
8
12 15
0
0
4
e
n
i
l
8
e
h
c
a
C
12
15
0
0
4
e
n
i
l
8
e
h
c
a
C
12
15
Figure 10: Color matrix showing cache hits on func-
tion code protected using Cloak. Darker means more
cache hits. Measurement performed over roughly 1.5 bil-
lion transactions (77314 function executions) for Prime+
Probe (left) and 2 billion transactions (135211 function
executions) for Flush+Reload (right). Side-channel leak-
age is not visible in both cases.
monitors the function addresses for cache hits and thus
derives which function has been called. Each of the 16
functions runs only a small code snippet consisting of
a loop counting from 0 to 10 000. We wrap the entire
switch-case together with the preloading step into a
single TSX transaction. The preloading step fetches the
16 functions, each spanning two cache lines, i.e., 2 KB
of code are added to the read set.
As in the previous example, Cloak eliminates all leak-
age (cf. Figure 10). While not under attack the victim
program protected with Cloak started 0.7% more func-
tion executions than the baseline implementation. Less
than 0.1% of the transactions failed, leading to an overall
performance penalty of 1.2%. When under attack using
Prime+Probe, 11.8 times as many function executions
were started and with Flush+Reload, 19 times as many.
However, only 0.005% of the transactions succeeded in
the case of Prime+Probe and only 0.0006% in the case
of Flush+Reload. Thus, overall the performance is re-
duced to 0.03% of the baseline performance when under
a Prime+Probe attack and 0.14% when under a Flush+
Reload attack. The functions are 20 times slower than
s
t
i
h
e
h
c
a
C
1
0.8
0.6
0.4
0.2
0
·104
Cloak
Baseline
10000000000000000000 10000000000000000000 100000000000 10000000 1
0
2
4
6
8
Time (in cycles)
·104
Figure 11: Cache traces for the multiply routine (as used
in RSA) over 10000 exponentiations. The secret expo-
nent is depicted as a bit sequence. Measurement per-
formed over 10000 exponentiations. The variant pro-
tected with Cloak does not have visual patterns that cor-
respond to the secret exponent.
the AES encryptions from the previous example. Thus,
the high failure rate is not unexpected, as there is more
time for cache evictions caused by other processes.
It is important to note that the performance under at-
tack is not essential as the attacker simultaneously keeps
one or more CPU cores on full load, accounting for a
signiﬁcant performance loss with and without Cloak.
6.3 RSA Square-and-Multiply example
We now demonstrate an attack against a square-and-
multiply exponentiation and how Cloak allows to pro-
tect it against cache side-channel attacks. Square-and-
multiply is commonly used in cryptographic implemen-
tations of algorithms such as RSA and is known to
be vulnerable to side-channel attacks [54, 62]. Though
cryptographic libraries move to constant-time exponen-
tiations that are intended to not leak any information
through the cache, we demonstrate our attack and pro-
tection on a very vulnerable schoolbook implementation.
A square-and-multiply algorithm takes 100 000 cycles to
complete. Thus, wrapping the whole algorithm in one
TSX transaction has only a very low chance of success
by itself.
Instead we split the loop of the square-and-
multiply algorithm into one small TSX transaction per
exponent bit, i.e., adding the xbegin and xend instruc-
tions and the preloading step to the loop. This way, we
increase the success rate of the TSX transactions signif-
icantly, while still leaking no information on the secret
exponent bits. The preloading step fetches 1 cache line
per function, i.e., 128 B of code are added to the read set.
Figure 11 shows a Flush+Reload cache trace for the
multiply routine as used in RSA. The plot is generated
over 10000 exponentiation traces. Each trace is aligned
by the ﬁrst cache hit on the multiply routine that was
measured per trace. The traces are then summed to pro-
duce the functions that are plotted. The baseline imple-
226    26th USENIX Security Symposium
USENIX Association
In order to demonstrate the general applicability of
Cloak, we reproduced the attack by Gruss et al. [24]
on a recent version of the GDK library (3.18.9) which
comes with Ubuntu 16.10. We attack the binary search in
gdk keyval from name which is executed upon every
keystroke in a GTK window. As shown in Figure 12, the
cache template matrix of the unprotected binary search
reveals the search pattern, narrowing down on the darker
area where the letter keys are and thus the search ends.
In case of the implementation protected by Cloak, the
search pattern is disguised. With the keystroke informa-
tion protected by Cloak, we could neither measure a dif-
ference in the perceived latency when typing through a
keyboard, nor measure and overall increase of the system
load or execution time of processes. The reason for this
is that keystroke processing involves hundreds of thou-
sands of CPU cycles spent in drivers and other functions.
Furthermore, keystrokes are rate-limited by the OS and
constrained by the speed of the user typing. Thus, the
overhead we introduce is negligible for the overall la-
tency and performance.
We conclude that Cloak can be used as a practical
countermeasure to prevent cache template attacks on
ﬁne-grained information such as keystrokes.
7 Side-Channel Protection for SGX
Intel SGX provides an isolated execution environment
called enclave. All code and data inside an enclave is
shielded from the rest of the system and is even protected
against hardware attacks by means of strong memory en-
cryption. However, SGX enclaves use the regular cache
hierarchy and are thus vulnerable to cache side-channel
attacks. Further, as enclaves are meant to be run on un-
trusted hosts, they are also susceptible to a range of other
side-channel attacks such as OS-induced page faults [61]
and hardware attacks on the memory bus. In this sec-
tion, we ﬁrst retroﬁt a common machine learning algo-
rithm with Cloak and evaluate its performance in SGX.
Afterwards, we explore the special challenges that en-
clave code faces with regard to side channels and design
extended countermeasures on top of Cloak. Speciﬁcally,
we augment sensitive enclave code with Cloak and re-
quire that the potentially malicious OS honors a special
service contract while this code is running.
7.1 Secure Decision Tree Classiﬁcation
To demonstrate Cloak’s applicability to the SGX envi-
ronment and its capability to support larger working sets,
we adapted an existing C++ implementation of a deci-
sion tree classiﬁcation algorithm [49] using the toolset
described in Section 5.3. The algorithm traverses a de-
cision tree for an input record. Each node of the tree
Figure 12: Cache template matrix showing cache hits on
the binary search in gdk keyval from name without
protection (left) and with Cloak (right). Darker means
more cache hits. All measurements were performed with
Flush+Reload. The pattern of the binary search is clearly
visible for the unprotected implementation and not visi-
ble anymore when protected with Cloak.
mentation has a clear peak for each 1 bit in the secret ex-
ponent. The same implementation protected with Cloak
shows no signiﬁcant changes in the cache hits over the
full execution time.
While not under attack, the performance of the im-
plementation protected with Cloak is only slightly lower
than the performance of the unprotected baseline imple-
mentation. To evaluate the performance in this case we
performed 1 million exponentiations. During these 1
million exponentiations, only 0.5% of the transactions
failed. The total runtime overhead we observed while
not under attack was 1.1%. Unsurprisingly, while un-
der attack we observed a signiﬁcantly higher overhead
of factor 982. This is because 99.95% of the transac-
tions failed, i.e., the transactions for almost every single
bit failed and had to be repeated.