SPIE places three major restrictions on the family of hash functions,
F, used in its Bloom ﬁlters. First, each member function must
distribute a highly correlated set of input values (IP packet preﬁxes),
P, as uniformly as possible over the hash’s result value space. That
is, for a hash function H : P → 2m in F, and distinct packets
x (cid:7)= y ∈ P, Pr[H(x) = H(y)] = 1/(2m). This is a standard
property of good hash functions.
SPIE further requires that the event that two packets collide in one
hash function (H(x) = H(y) for some H) be independent of col-
(cid:7)= H).
lision events in any other functions (H(cid:3)(x) = H(cid:3)(y), H(cid:3)
Intuitively, this implies false positives at one router are independent
of false positives at neighboring routers. Formally, for any func-
tion H ∈ F chosen at random independently of the input packets
x and y, Pr[H(x) = H(y)] = 2−m with high probability. Such
hash families, called universal hash families, were ﬁrst deﬁned by
Carter and Wegman [6] and can be implemented in a variety of
fashions [3, 10, 11].
Finally, member functions must be straightforward to compute at
high link speeds. This requirement is not impractical because SPIE
hash functions do not require any cryptographic “hardness” prop-
erties. That is, it does not have to be difﬁcult to generate a valid
input packet given a particular hash value. Being able to create a
packet with a particular hash value enables three classes of attacks,
all of which are fairly benign. One attack would ensure that all at-
tack packets have the same ﬁngerprint in the Bloom ﬁlter at some
router (which is very difﬁcult since there are multiple, independent
hashes at each router), but this merely elicits a packet trace that
reveals a larger set of systems from which the attacker can attack.
Another attack is to ensure all attack packets have different ﬁnger-
5 SOURCE PATH ISOLATION ENGINE
SPIE-enhanced routers maintain a cache of packet digests for re-
cently forwarded trafﬁc. If a packet is determined to be offensive
by some intrusion detection system (or judged interesting by some
other metric), a query is dispatched to SPIE which in turn queries
routers for packet digests of the relevant time periods. The results of
this query are used in a simulated reverse-path ﬂooding (RPF) algo-
rithm to build an attack graph that indicates the packet’s source(s).
5.1 Architecture
The tasks of packet auditing, query processing, and attack graph
generation are dispersed among separate components in the SPIE
system. Figure 5 shows the three major architectural components
of the SPIE system. Each SPIE-enhanced router has a Data Gener-
ation Agent (DGA) associated with it. Depending upon the type of
router in question, the DGA can be implemented and deployed as a
software agent, an interface card plug to the switching background
bus, or a separate auxiliary box connected to the router through
some auxiliary interface.
The DGA produces packet digests of each packet as it departs the
router, and stores the digests in bit-mapped digest tables. The tables
are paged every so often, and represent the set of trafﬁc forwarded
by the router for a particular interval of time. Each table is anno-
tated with the time interval and the set of hash functions used to
compute the packet digests over that interval. The digest tables are
stored locally at the DGA for some period of time, depending on
the resource constraints of the router. If interest is expressed in the
trafﬁc data for a particular time interval, the tables are transferred
to a SPIE Collection and Reduction (SCAR) agent for longer-term
storage and analysis.
SCARs are responsible for a particular region of the network, serv-
ing as data concentration points for several routers. SCARs monitor
and record the topology of their area and facilitate traceback of any
packets that traverse the region. Due to the complex topologies of
today’s ISPs, there will typically be several SCARs distributed over
an entire network. Upon request, each SCAR produces an attack
graph for its particular region. The attack graphs from each SCAR
are grafted together to form a complete attack graph by the SPIE
Traceback Manager (STM).
The STM controls the whole SPIE system. The STM is the inter-
face to the intrusion detection system or other entity requesting a
packet trace. When a request is presented to the STM, it veriﬁes
the authenticity of the request, dispatches the request to the appro-
priate SCARs, gathers the resulting attack graphs, and assembles
them into a complete attack graph. Upon completion of the trace-
back process, STMs reply to intrusion detection systems with the
ﬁnal attack graph.
5.2 Traceback processing
Before the traceback process can begin, an attack packet must be
identiﬁed. Most likely, an intrusion detection system (IDS) will de-
termine that an exceptional event has occurred and provide the STM
with a packet, P, victim, V , and time of attack, T . SPIE places two
constraints on the IDS: the victim must be expressed in terms of the
last-hop router, not the end host itself, and the attack packet must
be identiﬁed in a timely fashion. The ﬁrst requirement provides the
query process with a starting point; the latter stems from the fact
that traceback must be initiated before the appropriate digest tables
are overwritten by the DGAs. This time constraint is directly re-
lated to the amount of resources dedicated to the storage of trafﬁc
digests. (We discuss timing and resource tradeoffs in section 7).
Upon receipt of traceback request, the STM cryptographically ver-
iﬁes its authenticity and integrity. Any entity wishing to employ
SPIE to perform a traceback operation must be properly authorized
in order to prevent denial of service attacks. Upon successful ver-
iﬁcation, the STM immediately asks all SCARs in its domain to
poll their respective DGAs for the relevant trafﬁc digests. Time
is critical because this poll must happen while the appropriate di-
gest tables are still resident at the DGAs. Once the digest tables
are safely transferred to SCARs, the traceback process is no longer
under real-time constraints.
Beginning at the SCAR responsible for the victim’s region of the
network, the STM sends a query message consisting of the packet,
egress point, and time of receipt. The SCAR responds with a partial
attack graph and the packet as it entered the region (it may have
been transformed, possibly multiple times, within the region). The
attack graph either terminates within the region managed by the
SCAR, in which case a source has been identiﬁed, or it contains
nodes at the edge of the SCAR’s network region, in which case the
STM sends a query (with the possibly-transformed packet) to the
SCAR abutting that edge node.
This process continues until all branches of the attack graph termi-
nate, either at a source within the network, or at the edge of the
SPIE system. The STM then constructs a composite attack graph
which it returns to the intrusion detection system.
Digest
Type I
Packet Data
29 bits
3 bits
32 bits
Figure 6: A Transform Lookup Table (TLT) stores sufﬁcient infor-
mation to invert packet transformations at SPIE routers. The table
is indexed by packet digest, speciﬁes the type of transformation,
and stores any irrecoverable packet data.
5.3 Transformation processing
IP packets may undergo valid transformation while traversing the
network, and SPIE must be capable of tracing through such trans-
formations. In particular, SPIE must be able to reconstruct the origi-
nal packet from the transformed packet. Unfortunately, many trans-
formations are not invertible without additional information due to
the stateless nature of IP networks. Consequently, sufﬁcient packet
data must be recorded by SPIE at the time of transformation such
that the original packet is able to be reconstructed.
The packet data chosen as input to the digesting function deter-
mines the set of packet transformations SPIE must handle—SPIE
need only consider transformations that modify ﬁelds used as input
to the digest function. SPIE computes digests over the IP header
and the ﬁrst eight bytes of the packet payload but masks out (or
omits in the case of IP options) several frequently updated ﬁelds
before digesting, as shown in ﬁgure 2 of section 4. This hides
most hop-by-hop transformations from the digesting function, but
forces SPIE to explicitly handle each of the following transfor-
mations: fragmentation, network address translation (NAT), ICMP
messages, IP-in-IP tunneling, and IP security (IPsec).
Recording the information necessary to reconstruct the original
packet from a transformed packet requires additional resources.
Fortunately for SPIE, the circumstances that cause a packet to un-
dergo a transformation will generally take that packet off of the
fast path of the router and put it onto the control path, relaxing
the timing requirements. The router’s memory constraints remain
unchanged, however; hence, transformation information must be
stored in a scalable and space-efﬁcient manner.
5.3.1 Transform lookup table
Along with each packet digest table collected at a DGA, SPIE main-
tains a corresponding transform table for the same interval of time
called a transform lookup table, or TLT. Each entry in the TLT con-
tains three ﬁelds. The ﬁrst ﬁeld stores a digest of the transformed
packet. The second ﬁeld speciﬁes the type of transformation—
three bits are sufﬁcient to uniquely identify the transformation type
among those supported by SPIE. The last ﬁeld contains a variable
amount of packet data the length of which depends upon the type
of transformation being recorded.
For space efﬁciency, the data ﬁeld is limited to 32 bits. Some trans-
formations, such as network address translation, may require more
space. These transformations utilize a level of indirection—one bit
of the transformation type ﬁeld is reserved as an indirect ﬂag. If
the indirect, or I, ﬂag is set, the third ﬁeld of the TLT is treated as a
pointer to an external data structure which contains the information
necessary to reconstruct the packet.
The indirect ﬂag can also be used for ﬂow caching. In many cases,
packets undergoing a particular transformation are related. In such
cases, it is possible to reduce the storage requirements by suppress-
ing duplicate packet data, instead referencing a single copy of the
required data that can be used to reconstruct any packet in the ﬂow.
Such a scheme requires, however, that the SPIE-enabled router it-
self be capable of ﬂow caching, or at least identiﬁcation, so that the
packets within the ﬂow can be correlated and stored appropriately.
In order to preserve alignment, it is likely efﬁcient implementations
would store only 29 bits of the packet digest resulting in 64-bit wide
TLT entries. This width implies eight distinct packet digests will
map to the same TLT entry. The relative rarity of packet transfor-
mations [12], the sparsity of the digest table, and the uniformity of
the digesting function combine to make collisions extremely rare
in practice. Assuming a digest table capacity of roughly 3.2Mpkts
(16Mb SRAM, see section 7.2) and a transformation rate of 3%, the
expected collision rate is approximately 1:5333 packets. Even if a
collision occurs, it simply results in an additional possible trans-
formation of the queried packet. Each transformation is computed
(including the null transformation) and traceback continues.
In-
correctly transformed packets likely will not exist at neighboring
routers and, thus, will not contribute any false nodes to the attack
graph.
5.3.2 Special-purpose gateways
Some classes of packet transformations, notably NAT and tunnel-
ing, are often performed on a large fraction of packets passing
through a particular gateway. The transform lookup table would
quickly grow to an unmanageable size in such instances; hence,
SPIE considers the security gateway or NAT functionality of routers
as a separate entity. Standard routing transformations are handled as
above, but special purpose gateway transformations require a differ-
ent approach to transformation handling. Transformations in these
types of gateways are generally computed in a stateful way (usually
based on a static rule set); hence, they can be inverted in a similar
fashion. While the details are implementation-speciﬁc, inverting
such transformations is straightforward; we do not consider it here.
5.3.3 Sample transformations
A good example of transformation is packet fragmentation. To
avoid needing to store any of the packet payload, SPIE supports
traceback of only the ﬁrst packet fragment. Non-ﬁrst fragments
may be traced to the point of fragmentation which, for fragment-
based attacks [13], is the attacker. (If only a subset of the fragments
is received by the victim the packet cannot be reassembled; hence,
the only viable attack is a denial of service attack on the reassembly
engine. But, if the fragmentation occurs within the network itself,
an attacker cannot control which fragments are received by the vic-
tim so the victim will eventually receive a ﬁrst fragment to use in
traceback.) Packet data to be recorded includes the total length,
fragment offset, and more fragments (MF) ﬁeld. Since properly-
behaving IP routers cannot create fragments with less than 8 bytes
of payload information [17], SPIE is always able to invert fragmen-
tation and construct the header and at least 64 bits of payload of the
pre-fragmented packet which is sufﬁcient to continue traceback.
Observe that SPIE never needs to record any packet payload infor-
mation. ICMP transformations can be inverted because ICMP error
S2
S3
A
S4
S1
R1
R2
R3
R4
R6
S5
R5
R7
R8
R9
V
Figure 7: Reverse path ﬂooding, starting at the victim’s router, V ,
and proceeding backwards toward the attacker, A. Solid arrows
represent the attack path; dashed arrows are SPIE queries. Queries
are dropped by routers that did not forward the packet in question.
messages always include at least the ﬁrst 64 bits of the offending
packet [16]. Careful readers may be concerned that encapsulation
cannot be inverted if the encapsulated packet is subsequently frag-
mented and the fragments containing the encapsulated IP header
and ﬁrst 64 bits of payload are not available. While this is strictly
true, such transformations need to be inverted only in extreme cases
as it takes a very sophisticated attacker to cause a packet to be ﬁrst
encapsulated, then fragmented, and then ensure fragment loss. If
all the fragments are received, the original header can be extracted
from the reassembled payload. It seems extremely difﬁcult for an
attacker to insure that packet fragments are lost. It can cause packet
loss by ﬂooding the link, but to do so requires sending such a large
number of packets that it is extremely likely that all the fragments
for at least one packet will be successfully received by the decapsu-
lator for use in traceback.
5.4 Graph construction
Each SCAR constructs a subgraph using topology information
about its particular region of the network. After collecting the
digest tables from all of the routers in its region, a SCAR sim-
ulates reverse-path ﬂooding (RPF) by examining the digest ta-
bles in the order they would be queried if an actual reverse path
ﬂood was conducted on the topology that existed at the time the
packet was forwarded. Figure 7 shows how reverse-path ﬂood-
ing would discover the attack path from V to A, querying routers
R8, R9, R7, R4, S5, R5, and R2 along the way. It is important to
note that the routers are not actually queried—the SCAR has al-
ready cached all the relevant hash digests locally.
In order to query each router, a SCAR computes the appropriate set
of digests as indicated by the table, and then consults the table for
membership. If an entry exists for the packet in question, the router
is considered to have forwarded the packet. The SCAR adds the
current node to the attack graph and moves on to each of its neigh-
bors (except, of course, the neighbor already queried). If, however,
the digest is not found in the table, it may be necessary to search
the digest table for the previous time period. Depending on the link
latency between routers, SCARs may need to request multiple di-
gest tables from each router in order to assure they have the digest
for the appropriate time frame. Once a digest is located, the packet
arrival time is always considered to be the latest possible time in the
interval. This insures the packet must have been seen at an earlier
time at adjacent routers.
If the packet is not found in any of the digest tables for the relevant
time period, that particular branch of the search tree is terminated
and searching continues at the remaining routers. A list of previ-
ously visited nodes is kept at all times, and cycles are pruned to
assure termination.
The result of this procedure is a connected graph containing the set
of nodes believed to have forwarded the packet toward the victim.
Assuming correct operation of the routers, this graph is guaranteed
to be a superset of the actual attack graph. But due to digest col-
lisions, there may be nodes in the attack graph that are not in the
actual attack graph. We call these nodes false positives and base the
success of SPIE on its ability to limit the number of false positives
contained in a returned attack graph.
6 PRACTICAL IMPLEMENTATION
For our FreeBSD SPIE prototype, we simulate a universal hash
family using MD5 [18]. A random member is deﬁned by selecting
a random input vector to prepend to each packet. The properties
of MD5 ensure that the digests of identical packets with different