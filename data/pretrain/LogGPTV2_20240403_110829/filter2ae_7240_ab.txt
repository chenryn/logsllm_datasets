**污点跟踪：** 识别 DOM XSS
漏洞最相关的动态分析是污点跟踪。该技术将来自潜在攻击者控制的来源的数据标记为受污染，并在执行时传播污染信息。当在敏感接收器中使用受污染的字符串时，污点跟踪引擎会将此信息流标记为潜在的
DOM XSS 漏洞；称之为未经证实的漏洞。第一个使用污点跟踪来发现 DOM XSS 漏洞的工具是基于 Firefox 的
DOMinator。后来，通过添加字节精确污点跟踪来提高其精度，将污点信息附加到 JavaScript 引擎中的特定字节，减少误报。
虽然污点跟踪可以在运行时有效地防御 DOM XSS 漏洞，但这是以某些基准测试中 7% 到 17% 的开销为代价的
。浏览器供应商对性能开销异常敏感，本文解决方案提供了一个机会，通过使用 ML 在分类器确定代码可能易受攻击时有选择地启用污点跟踪来缓解这种性能下降。
#### （2）确认潜在易受攻击的流量
由于受污染的数据可能会被程序员清理，因此此类流可能不一定是可利用的。研究人员使用启发式方法自动生成漏洞来确认这些漏洞。在之前的工作中，研究人员通过分析受污染字符串周围的上下文来生成漏洞利用，使用预先配置的导致漏洞利用的注入列表或符号分析来确认具有测试注入的流。在本文工作中，利用上述解决方案来生成已确认漏洞的标记实例。
### E.程序分析中的机器学习
有几个项目使用 ML 来分析 JavaScript 中的程序，成功识别出许多恶意
JavaScript例子。然而，这些解决方案依赖于手工设计的特征（例如流的位置、流中涉及的函数数量、流的源和汇）。本文避免使用此类技术，使解决方案可以推广到不同的上下文并适应不断变化的源代码习语。从数据中进行程序分析的构建块也可以通过训练决策树来学习。相比之下，本文工作选择了深度学习，它可以学习复杂数据的潜在表示。
最密切相关的工作是使用深度学习来分析程序中的信息流，以便在C中更有效地进行污点跟踪或漏洞检测。在这些项目中，ML模型必须识别程序中的关键点以进行分析信息流，依赖于C程序的高度静态性。本文工作关注浏览器中的
DOM XSS 漏洞，主要执行动态 JavaScript 代码。这使得很难自信地确定程序的关键点并提取数据依赖关系，因此上述解决方案不适用于本文设置。
#### （1）程序的向量表示
研究人员开发了 code2vec，它通过将起始节点和终止节点与 AST 树的一系列上下运动联系起来，将 AST
转换为用于机器学习的向量。树卷积分析树结构上的 AST
节点信息，其方式类似于卷积神经网络处理其像素上的图像。树卷积基于使用神经网络卷积在靠近它的节点上对每个节点进行分类，并且之前已用于从源代码中检测算法性能错误。
在分析用于程序分析的图形结构数据方面也进行了工作。还探索了一种使用门控图神经网络的方法，该网络最近已被用于对源代码的某些属性进行建模，例如惯用的编码风格。然而通过实验发现这些技术无法准确地模拟
JavaScript 语义。
## 0x03 Data Collection Methodology
本章描述了收集两个真实数据集以训练和评估 ML
分类器的方法。使用启用污点跟踪的浏览器来收集大规模网络爬行中未经证实的漏洞（数据集1），然后将这些未经证实的漏洞的实例标记为已确认的漏洞（数据集2），最后讨论数据收集的属性和局限性。
### A.数据收集
#### （1）污点跟踪浏览器
利用先前工作中修改后的启用污点跟踪的 Chromium 浏览器版本来收集一系列网站执行跟踪，识别可能容易受到 DOM XSS
注入攻击的代码。修改后的浏览器由与服务器端数据库交互的扩展程序驱动，通过 HTTP 交互引导爬取活动并存储受污点流的记录。
浏览器的 V8 引擎和 WebKit 基础设施通过污点跟踪进行了修改，以识别潜在的易受攻击的流。在每个网页的 JavaScript
执行期间，修改后的浏览器存储：所有浏览器执行的源代码的记录、该源代码的解析 V8
表示、所有受污染的接收器执行和其他簿记信息。对于带有污染数据的接收器的每次执行，额外记录：污染参数的值、特定的污染字符、是否应用了任何特定的内置编码方法（例如，escape
或 encodeURI），以及完整的跟踪JavaScript 调用堆栈。
#### （2）爬取方法
总共爬取了 Alexa 前 10,000的网站，并访问了这些网站上的 289,392 个网页。通过访问网站的根网页并在同一域内对 40
个子链接进行采样，总共尝试了 410,000 次网页访问。在爬取过程中，并非所有页面都被加载；遵守了
robots.txt规则，其他网页在爬取过程中没有正确加载。如果单个网页未成功加载，会尽可能尝试加载同一域中的另一个示例网页。在加载网页时，爬虫首先等待页面就绪事件，然后再等待
90 秒以执行页面。凭经验观察到 90 秒足以检测绝大多数污点汇聚点。
由于爬虫是非确定性的，因此汇总了多次执行的结果。使用 GZIP 压缩时，抓取的执行日志文件为
26TB。许多脚本在多次爬取中重复，因此删除了所有重复的源代码，将聚合数据库的压缩大小减少到 382GB。
### B.标记和确认流
接下来，检测哪些脚本包含潜在易受攻击的接收器的受污染参数以及这些接收器的位置。如果流在任何执行中被标记为易受攻击，将在聚合中将其标记为易受攻击。为了在源代码中定位对
sink 函数的特定调用，在执行期间输出函数调用的带注释的堆栈跟踪，其中包含所有已执行 JavaScript 的解析 AST。使用最靠近调用堆栈底部的
JavaScript 堆栈帧的 AST
节点作为漏洞的指示。不在堆栈跟踪中使用其他函数，因为没有关于受污点流源位置的信息，也无法标记此类节点。下图显示了如何转换和标记地面实况数据的概述。  
#### （1）发现未经证实的漏洞
为了确定敏感接收器是否应该被标记为未经证实的漏洞，观察应用于受污染数据的编码方法是否与应用污点的上下文相匹配，使用与先前工作类似的逻辑。例如，如果污点跟踪表明document.write函数是使用来自网页
URL 的受污染参数调用的，而没有应用任何编码函数，就会将该流程标记为未经证实的漏洞。但是，如果 encodeURI
函数后来在接收器中使用之前应用于受污染的字节，那么会将函数标记为安全的，因为 encodeURI 函数会清理输入并防止漏洞。根据数据爬取结果，收集了大约
32,000,000 个未经证实的漏洞实例，发生在大约 180,000 个不同的、独特的函数中。
#### （2）确认漏洞
对于剩余的未确认漏洞，通过利用先前工作中的技术生成确认测试注入。结合应用编码函数的知识为每个未确认的漏洞生成概念验证测试注入，并使用测试注入重新执行网页以查看注入是否成功。这一步是必要的，因为开发人员可以在不使用内置编码方法的情况下对流进行临时清理，例如检查受污染的输入是否与数字的正则表达式匹配，这种技术可以消除未经证实的漏洞.在使用概念验证漏洞利用后，收集了大约
4,500,000 个已确认漏洞的实例，发生在 2,300 多个不同的独特函数中。
因此创建了两个用于训练 ML
模型的数据集：（1）基于污点跟踪浏览器输出的未确认漏洞数据集，以及（2）基于已确认漏洞的数据集概念验证测试注入。已确认漏洞集是未确认漏洞的子集；使用这些数据集训练两个单独的分类器并在两者上执行实验。
### C.真实数据集的属性
在收集真实数据后，想了解常用脚本（如 jQuery）对训练和评估的影响程度。如果一小组频繁脚本占数据集的很大一部分，则 ML
模型的性能可能取决于其识别这些频繁脚本的能力。数据集和漏洞分布的总结如下表所示。发现虽然数据集包含一些频繁出现的脚本，但也有明显的长尾独特脚本；数据集包括
23,013,705 个独特脚本的 240,830,867
个观察结果。该数据集明显是片面的：与负标签（非脆弱函数）相比，正标签（漏洞）极为罕见。所有函数中只有 0.17% 是未确认漏洞，所有函数中只有 0.024%
是已确认漏洞。此外在考虑独特脚本时，这些比例甚至更小（0.038% 和 0.0005%）。  
### D.限制
本研究的浏览器基础架构基于旧版 Chromium，版本 57（2016 年 8 月的版本）。原则上观察到的漏洞可能不适用于其他浏览器。此版本的
Chromium 处理散列后值的编码与最新版本的 Chromium 不同，这可能会影响未经证实的漏洞是否可利用。但是，较新版本的 Chromium
中的防御机制在其他浏览器中并不普遍，因此依赖较新版本的 Chromium 可能会忽略仍然影响许多浏览器的漏洞。
真实数据也受到用于标记的动态分析的限制。数据仅包含来自实际执行的标记 AST
节点，不能对未执行的代码做出声明。然而，虽然数据集包含误报，但它不包含误报：所有 2,326
个已确认的漏洞都被证明在至少一个生成的概念验证漏洞中容易受到攻击。
如果一个函数的任何实例被标记为易受攻击，那么将该函数的所有实例都标记为易受攻击。但是，利用该漏洞可能需要仅出现在某些网页上的跨函数交互。可以说，将此类函数标记为易受攻击仍然是合适的，因为它们在所有情况下都不是安全的。在任何一种情况下，分析此类跨职能交互都很复杂，超出了这项工作的范围。
## 0x04 Classifier Design