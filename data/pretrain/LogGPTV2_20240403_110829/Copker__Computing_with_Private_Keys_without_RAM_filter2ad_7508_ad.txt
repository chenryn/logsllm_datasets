SMP support. In particular, SET_CNT is the number of sepa-
rate cache sets. Semaphores are used to avoid multiple cores
in the same cache-sharing set to execute Copker concurrently,
as only one cacheCryptoEnv is allocated for each separate
cache set. They are implemented with down() and up(), the
PV functions of semaphores in Linux.
At the beginning, the task is restricted in the core where
it
is running, by setting the thread’s afﬁnity to idCore.
smp_processor_id(current) gets the core index of
the current task. This avoids inconsistency of idCore if the
task is scheduled onto another core after Line 1 is executed.
Then, cache_set_id(id) and cache_set(id) return
the index and the members of the separate cache-sharing core
set, which contains the core identiﬁed by id, respectively. The
information is used to force the cores to enter the no-ﬁll mode.
The function private_key_compute() implements
the requested private key operations (as described in Sec-
tion III-D) using the switched stack, whose bottom is
pointed by env->cacheStack+CACHE_STACK_SIZE-4.
Here we subtract 4 from the end of cacheStack, because in
x86 architecture with 32-bit mode, the stack grows downwards
in units of 4 bytes.
3Here we refer to real concurrent tasks, not time-sharing concurrency.
Algorithm 2: Copker with SMP support
Global Variables: struct CACHE CRYPTO ENV
cacheCryptoEnv[SET CNT];
semaphore semCopker[SET CNT];
Input: message, privateKeyId
Output: result
1 idCore   smp processor id(current)
2 set the current thread’s afﬁnity to core idCore
3 idCache   cache set id(idCore)
4 if get memory type(cacheCryptoEnv[idCache]) 6=
WRITEBACK then
exit
5
6 down(semCopker[idCache])
7 preempt disable()
8 C   cache set(idCore)
9 C   C\{idCore}
10 for id 2 C do
enter no ﬁll(id)
11
12 end
13 local irq save(irq ﬂag)
14 env   cacheCryptoEnv+idCache
15 ﬁll L1D(env)
16 env->in   message
17 env->privateKeyId   privateKeyId
18 switch stack(env, private key compute,
env->cacheStack+CACHE STACK SIZE-4)
exit no ﬁll(id)
19 clear env(env)
20 for id 2 C do
21
22 end
23 local irq restore(irq ﬂag)
24 preempt enable()
25 up(semCopker[idCache])
26 return env->out
C. Kernel Patch
The Linux kernel is patched to ensure that the sensitive
information is stored only in caches and registers. First, the
TRESOR patch [38] is installed so that
the debug regis-
ters that contain the master key are not accessible to other
tasks except Copker. The native_get_debugreg() and
native_set_debugreg() system calls accessing debug
registers in kernel space are patched, as well as the ptrace()
system call accessing debug registers in user space. Sec-
ond, we consider the situations when other tasks interfere
with Copker in shared caches. Although direct access to
cacheCryptoEnv is restricted by the process isolation
mechanism of the OS, other tasks in the same separate cache-
sharing core set could directly issue cache-related instructions
to break our assumption (Criterion 3 in Section III-B). In
particular, the following operations on other cores could violate
Copker’s protection mechanisms, when Copker is in the atomic
section.
1)
2)
Exit from the no-ﬁll mode by setting cr0.
Issue wbinvd to ﬂush caches that Copker is access-
ing.
In (1), when the other core exits from no-ﬁll cache mode,
malicious tasks can evict Copker’s caches by intensive memory
8
operations. In (2), Copker’s caches are directly ﬂushed.
Setting cr0 and issuing wbinvd can only be performed
in ring 0, so we only need to patch the corresponding code
in kernel. The patch is simple but effective: wbinvd and
write operations to cr0 can only be executed if there are
no Copker thread running within the same cache-sharing set.
This is achieved by requiring the semaphore allocated to the
separate cache set. The introduced overhead is negligible, as
these operations (e.g., wbinvd) are rarely used.
In the Linux kernel for x86 platforms,
the instruction
wbinvd and write operation to cr0 are both implemented
as inline functions, namely wbinvd() and write_cr0(),
in /arch/x86/include/asm/special_insns.h. We
searched all usages of these two operations in Linux kernel
source code, and found that all occurrences strictly invoke
wbinvd() and write_cr0(). The patches to them are
similar, hence, we only list the patch to wbinvd(). Note
that lines marked by “+” indicate code added by the patch,
while all other lines belong to the original Linux kernel code.
Listing 2: Kernel patch to wbinvd()
static inline void wbinvd(void)
{
+ cpumask_t tempSet,savedSet;
+ int r;
+ unsigned int id;
+ savedSet = current->cpu_allowed;
+ id = smp_processor_id();
+ cpumask_clear(&tempSet);
+ cpumast_set_cpu(id,&tempSet);
+ set_cpus_allowed_ptr(current,&tempSet);
+ r = down_interruptible(semCopker +
cache_set_id(id));
+ if(r == -EINTR)
+
return;
native_wbinvd();
+ up(semCopker + cache_set_id(id));
+ set_cpus_allowed_ptr(current,&savedSet);
}
Note that there are other operations that might violate
Copker’s protection mechanism, e.g., setting MTRRs to change
the memory type of cacheCryptoEnv. However, such oper-
ation must be executed on the same core as Copker is running
on, so it cannot be executed when Copker is in the atomic
section. Moreover, we assume PAT cannot be changed, as the
OS kernel is trustworthy.
Although instruction clflush can ﬂush the speciﬁed
cache lines both in ring 0 and ring 3, it cannot be exploited
to break Copker’s security protection. First, the user-space
code does not have permission to access kernel space, where
the sensitive information of Copker is located. Second, Linux
kernel does not export any system call that can ﬂush a user-
speciﬁed memory range. Third, in a trusted kernel, no piece
of code would ﬂush cacheCryptoEnv directly.
Attackers may ﬂush the translation lookaside buffer (TLB),
which is the speciﬁc cache for the translation information
between virtual and physical addresses. However, but ﬂushing
TLB would not affect the corresponding data cache lines for
Copker tasks [27].
V. EVALUATION
A. Validation
We have designed a mechanism to experimentally prove
that the sensitive data in caches are not ﬂushed from caches
to RAM. Theoretically, based on the analysis of Algorithm
2, we are sure that cacheCryptoEnv in the L1D cache
cannot be evicted before it is erased explicitly. However, we
would expect to have empirical evidence that we can conﬁrm
the data is “locked” in cache. This is considered to be a
challenging task, because of the lack of cache control utilities
in x86 platform [38, 39]. Memory consistency is automatically
maintained by CPU and the RAM controller. However, these
are no instruction that can be employed to query the cache line
status.
The basic idea of the validation mechanism is as follows:
(1) we make a copy of RAM (C) before private key operations;
(2) we invalidate cache lines with invd after Copker is exe-
cuted; (3) the data in RAM should not be changed compared
with C, unless the cache line has been ﬂushed before invd
is executed. In practice, we do not make copies of memory.
Instead, we ﬁrst place canary words in cacheCryptoEnv in
the RAM before any private key operations. After the private
key operations, invd is issued to invalidate all the modiﬁed
cache lines, including cacheCryptoEnv. Then the copy of
cacheCryptoEnv in the RAM is checked. If canary words
are not crashed, the sensitive data is not written back to the
RAM.
Based on Algorithm 2, we add the following steps to
validate the correctness of Copker.
1)
4)
5)
Fill cacheCryptoEnv with canary words, except
in, out and privateKeyId, when Copker is
initializing. This operation is only performed once.
The placed canary words should never be changed
afterwards.
3)
2) When entering the atomic section, other cores in
the same separate cache-sharing core set execute
wbinvd before entering no-ﬁll mode. This ﬂushes
all the modiﬁed data in caches to the RAM on other
cores. Then, these cores run without caches.
Before calling private_key_compute(), Cop-
ker executes wbinvd. This ﬂushes all the modiﬁed
data in caches to the RAM on Copker’s cores. The
wbinvd instruction in Steps 2 and 3, is executed
to avoid data inconsistency, caused by the invd
instruction.
After private_key_compute() returns, Copker
ﬂushes out the result by using clflush and then
executes invd. At this time, all the modiﬁed data in
caches are lost.
Check whether canary words are crashed. If so,
sensitive data has been potentially leaked into RAM.
6) When leaving atomic section, other cores switch back
to normal mode.
It’s worth mentioning that caches are ﬂushed in unit of
lines, aligned by the cache line size CACHE_LINE_SIZE,
9
which is typically 64 bytes for lower level caches in x86 plat-
form. To avoid ﬂushing data more than out, out should be
aligned by CACHE_LINE_SIZE. Therefore, the deﬁnition of
out in CACHE_CRYPTO_ENV is changed into the following
form:
unsigned char out[(KEY_LENGTH_IN_BYTE +
CACHE_LINE_SIZE - 1)
/ CACHE_LINE_SIZE * CACHE_LINE_SIZE]
__attribute__ ((aligned(CACHE_LINE_SIZE)));
We run several Copker threads using the above algorithm
concurrently with a memory-intensive program for more than
10 days, and found no cache leakage ever happened. As
the above algorithm almost shares the same procedure with
Algorithm 2, we are convinced that Copker in Algorithm 2
can effectively protect sensitive data from being ﬂushed into
RAM. In the validation, Copker is integrated into the Apache
web server to provide RSA decryption services, in response to
continuous external HTTPS requests from a client. The HTTPS
client runs at the concurrency level of 10. Another memory-
intensive program is a inﬁnite loop. In each iteration, it simply
requests a 4 MB memory block using malloc(), adds up
each byte, and then frees the memory block.
Last, we would like to illustrate the slight differences
between the validation mechanism and the original Copker
approach (presented in Algorithm 2). In Copker, all other cores
that share (L2) caches with the Copker core works in no-ﬁll
mode. In the validator, the other cores are running without
cache, since wbinvd is invoked before entering no-ﬁll mode.
Furthermore, the validator frequently invokes wbinvd and
invd, both of which are quite expensive. Therefore, although
the validator is also capable of keeping sensitive information
in caches, we only use it as a validation method. The original
Copker prototype is much more efﬁcient than the validator.
B. Performance
We have evaluated the efﬁciency of Copker and its impact
on the overall system performance. We have compared Copker
with the modiﬁed PolarSSL and the original PolarSSL. The
modiﬁed PolarSSL is the PolarSSL with modiﬁcations by
Copker (i.e., static long integer and different sliding window
value) but running in the same environment as the original
PolarSSL (i.e.,
the modiﬁed PolarSSL does not guarantee
that sensitive information only stays in cache). The perfor-
mance difference between Copker and the modiﬁed PolarSSL
indicates the loss in performance introduced by adding the
protection mechanisms to defeat against cold-boot attacks.
In the following experiments, all
these approaches are
invoked through OpenSSL engine API to perform 2048-bit
RSA decryptions. They use the same RSA keys. The testing
machine is a Dell OPTIPLEX 760 PC with an Intel Q8200
processor, which has 4 cores.
Maximum Decryption Operations per Second. We ﬁrst
measure the maximum decryption speed. The client program
requests decryption services on each approach, running at
different concurrency levels. We record the number of served
requests in 10 minutes.
As shown in Figure 5, Copker runs even a little faster
than the modiﬁed PolarSSL when there are 1 or 2 concurrent
threads. This can be explained by the fact that Copker is
not affected by scheduling. However, as the concurrency
level increases, the modiﬁed PolarSSL surpasses Copker: the
maximum speed of Copker is only doubled comparing with
the single-thread performance, while others are quadrupled.
This result is expected: the maximum effective concurrency
level of Copker is 2, which is restricted by the number of
separate cache sets in the CPU, while the maximum effective
concurrency level of other approaches is 4, which is restricted
by the number of processor cores.
d
n
o
c
e
s
r
e
p
s
n
o
i
t
p
y
r
c
e
d
A
S
R
 450
 400
 350
 300
 250
 200
 150
 100
 50
 0
Copker
Modified PolarSSL
Original PolarSSL
1
2
4