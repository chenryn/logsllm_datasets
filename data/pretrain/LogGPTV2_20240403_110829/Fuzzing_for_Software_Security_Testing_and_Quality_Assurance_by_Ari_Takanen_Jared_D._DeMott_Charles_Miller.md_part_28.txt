Some compilers, like GCC and Clang, offer different options to add run-time
instrumentation to the code generated during compile. One example of these
6760 Book.indb 183 12/22/17 10:50 AM
184 Target Monitoring
instrumentations is AddressSanitizer.3 AddressSanitizer is a memory error detection
tool similar to Valgrind Memcheck. In comparison to Memcheck, AddressSanitizer
does not detect uninitialized reads and memory leaks, but the compile-time instru-
mentation is faster, has smaller memory overhead and can also detect overflows
from stack and global objects. For detection of uninitialized reads and memory
leaks, two additional sanitizers are available: MemorySanitizer3 and LeakSanitizer3.
6.3.5 Virtualization
Using virtualization, most of the results of the methods discussed in this section can
be achieved. This can be done with any available technology including commercial
offerings such as VMware, as well as open source options such as Xen and Bochs.
By running the target program in a virtualized environment, it can be monitored
and controlled by looking at how the operating system is interacting with the virtual
hardware. Likewise, exceptions generated by programs can be caught and acted
upon. Additionally, when supported, virtual machines have the advantage that they
can restore the entire operating system and target application to a known good state
using snapshot technology. This can have a big advantage over simply restarting a
troubled target application since the file system, configuration files, registry entries,
or back-end databases may have been corrupted during fuzz testing. Overall, this
shows great promise, but is still a topic of research.
6.4 Monitoring Overview
• Valid case instrumentation:
+ Will detect state-machine failures;
+ Platform independent;
– Will not detect exceptions that the application tries to hide.
• System monitoring:
+ Can catch file system abnormalities;
+ No need for source code;
– Will catch crash-level exceptions only;
– Platform dependent.
• Remote monitoring:
+ Can access information on many system resources;
+ Monitoring from fuzzing system;
– Will catch crash-level exceptions only;
– Will not have the same access as on the system;
– Not always supported.
• Application monitoring:
+ Will detect all exceptions;
– Platform dependent;
– May miss nonexception-related vulnerabilities.
3 https://github.com/google/sanitizers/wiki.
6760 Book.indb 184 12/22/17 10:50 AM
6.5 Deduplication 185
6.5 Deduplication
Because no two fuzz test cases are identical, fuzz test automation is often coupled
with deduplication system that aims to identify if the detected error is the same,
or similar enough, to a previously detected error and should be considered origin
from the same root cause. Errors, related logs and reproducing information are then
written to a database, or in a file systems, so that user can focus to unique errors
instead of viewing all the detected errors.
In this section we will discuss different techniques commonly used when group-
ing large amounts of fuzzing results. Other than with identical test case and test
environment, there is no 100% sure way to say that two errors are from the same
root cause, so even with a deduplication system, all test cases triggering an error
should always be recorded and retested after a fix has been applied.
6.5.1 Test Case Generator Information
Model-based fuzzers often have functionality that allow recording of a log with all
the fields that were generated and which fields were injected with anomalous value.
When a crash is detected that information can be used to cross check if any earlier
crashes had the same fields and anomalies, or just the same anomalies.
This technique is simple and does not have any requirements for the fuzz test
target, but it is not always very accurate. For example, if our log shows that a crash
occurred when a length field was injected with an anomaly, we can have different
bugs, like integer overflow in length value and missing boundary check where the
length is used, in the same group. Also when injecting anomalies to multiple fields
in the same test case, there is no way to say if two test cases that have some overlap
in fields with anomalies are triggering the same bug or a different one.
6.5.2 Operating System Logs
All operating systems have some internal logging for misbehaving applications.
These logs commonly offer information about the executable that caused the error
and the type of the error detected. For example, Windows operating systems have
a Windows Event Log that shows record for application crashes. Windows event
log entries can be easily queried, for example from PowerShell:
PS C:\Users\attekett> (Get-EventLog -LogName Application -Source
“Application Error” -Newest 1).Message
Faulting application name: MicrosoftEdge.exe, version:
11.0.15063.447, time stamp: 0x5948acf2
Faulting module name: CoreUIComponents.dll, version:
10.0.15063.502, time stamp: 0x7bbd6c5e
Exception code: 0xc0000005
Fault offset: 0x0000000000077bd2
Faulting process ID: 0xf68
Faulting application start time: 0x01d3150523a63a7e
Faulting application path: C:\Windows\SystemApps\Microsoft.
MicrosoftEdge_8wekyb3d8bbwe\MicrosoftEdge.exe
6760 Book.indb 185 12/22/17 10:50 AM
186 Target Monitoring
Faulting module path: C:\Windows\SYSTEM32\CoreUIComponents.dll
Report ID: 3bc64d30-6ceb-4a23-ab24-b70beb6595ed
Faulting package full name: Microsoft.
MicrosoftEdge_40.15063.0.0_neutral__8wekyb3d8bbwe
Faulting package-relative application ID: MicrosoftEdge
Our example query shows the newest Application Error event from the applica-
tion event log. From the information shown we can see that an exception with code
“0xc0000005”, an access violation, has occurred in MicrosoftEdge executable in
CoreUIComponents module. This information together with Fault offset could be
used to group this and similar crashes.
Ubuntu Linux has very similar information available in a different format via
dmesg log:
attekett@ubuntu:~ $ dmesg | grep segfault | tail -2
[261653.491807] auplink[32164]: \
segfault at 7ffec0f0b4f8\
ip 00007f515dbaf579 \
sp 00007ffec0f0b500 \
error 6 \
in libc-2.23.so[7f515dab6000+1c0000]
This example shows that an executable auplink caused a segmentation fault in the
libc.2.23.so library; the lowest three bytes of instruction pointer (ip) can also be
used to create a good grouping fingerprint for this crash. One example fingerprint
could look like this: auplink-segfault-ip-578-error-6-libc-2.23.so.
Using operating system logs is often the most practical solution for local black-
box fuzzing. It does not require intrusion to the target, but still produces pretty
accurate information about the crash. As a downside, it does require access to the
operating system where the target is executed and bugs can end up being grouped
in the same group if crashes occur in common code. For example, for all typical
invalid uses of memcpy the fingerprint would be the same, even though the root
causes for those uses would be in different locations in the code. Also, if instruction
pointer can change between different builds of the target, so if used the fingerprint
has to be updated for every build.
6.5.3 Stack Traces
Stack traces are a report of the active stack frames at a given point of execution of
a program. Stack traces are commonly used in debugging of an error, but they can
also be used for grouping of errors. In many cases, for example Python or NodeJS
applications, stack trace is printed by default when an unhandled error occurs. With
programming languages like C and C++, you have to use a separate debugger or
tools like AddressSanitizer and Valgrind.
For example, below is a stack trace of an invalid write detected by Valgrind:
[cmiller@LinuxForensics pcre-6.2]$ valgrind ./pcredemo ‘[[**]]’ a
==12840== Invalid write of size 1
6760 Book.indb 186 12/22/17 10:50 AM
6.6 Test Program 187
==12840== at 0x804B5ED: compile_regex (pcre_compile.c:3557)
==12840== by 0x804C50F: pcre_compile2 (pcre_compile.c:4921)
==12840== by 0x804CA94: pcre_compile (pcre_compile.c:3846)
==12840== by 0x804864E: main (pcredemo.c:76)
==12840== Address 0x401F078 is 0 bytes after a block of size 80
alloc’d
From the Valgrind output, we can collect information like the type of the error,
the function and the source code line where the error occurred, which functions were
in the stack before the error occurred, and the source code lines where each func-
tion call was made. One example fingerprint, built from the function names, could
look like this: pcredemo-invalid-write-compile_regex-pcre_compile2-pcre_compile.
6.5.4 Advanced Tools
Tools like Microsoft’s !exploitable4 and SkyLined’s BugId5 can be used to build
unique hashes or identification numbers, that can be used identify separate issues
from each other. These tools are designed to be used together with a debugger.
When an error is detected, they collect detailed information about the program
state and produce detailed reports of the error. Both !exploitable and BugId have
been designed automated fuzzing in mind and addition to deduplication help, they
also provide information about potential security impact of the issue and human-
readable summaries.
6.6 Test program
Now that we’ve had the chance to see some of the tools at our disposal, let us run
them on a small test program to see how effective they can be.
6.6.1 The program
#include 
#include 
#include 
char static_buffer1[16];
char static_buffer2[16];
void (*fn)(int);
int main(int argc, char *argv[]){
char stack_buffer1[16];
char stack_buffer2[16];
char *heap_buffer1 = (char *) malloc(16);
char *heap_buffer2 = (char *) malloc(16);
char *dummy;
4 https://msecdbg.codeplex.com/.
5 https://github.com/SkyLined/BugId.
6760 Book.indb 187 12/22/17 10:50 AM
188 Target Monitoring
fn = exit;
if(argc < 3){
printf(“Need 2 arguments\n”);
exit(-1);
}
int x = atoi(argv[1]);
switch(x){
case 0:
// Stack overflow
strcpy(stack_buffer2, argv[2]);
break;
case 1:
// Heap overflow
strcpy(heap_buffer1, argv[2]);
break;
case 2:
// Static overflow
strcpy(static_buffer2, argv[2]);
break;
case 3:
// wild write
heap_buffer1[atoi(argv[2])] = 0;
break;
case 4:
// memory exhaustion (and buffer overflow)
dummy = (char *) malloc(atoi(argv[2]));
memset(dummy, 0x41, atoi(argv[2]));
strcpy(dummy, “hello”);
break;
}
free(heap_buffer2);
free(heap_buffer1);
fn(0);
}
This program accepts two arguments. The first is an integer that controls what the
program does, and the second is an argument to that particular functionality of the
program. Obviously, this program has a number of serious issues.
6.6.2 Test Cases
Below are a number of test cases that trigger various vulnerabilities in the test program,
1. ./test 0 AAAAAAAAAAAAAAAAAAAA
2. ./test 0
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAA
6760 Book.indb 188 12/22/17 10:50 AM
6.6 Test Program 189
3. ./test 1 AAAAAAAAAAAAAAAAAAA
4. ./test 1 AAAAAAAAAAAAAAAAAAAAAAAAAAAA
5. ./test 2 AAAAAAAAAAAAAAAAAAAAAAAAAA
6. ./test 2 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
7. ./test 3 18
8. ./test 3 20
9. ./test 4 10
10. ./test 4 914748364
These test cases have the property that they all cause some kind of security
problem in the program. The first four types of input cause a memory corruption,
and the final one can cause a memory consumption denial of service. In the last
one, the vulnerability really is that the user controls the size of a malloc without a
check on the length. The odd-numbered test cases execute the vulnerable lines of
code, but do not cause the program to crash or exhibit obviously bad behavior. The
even-numbered test cases do cause a program failure:
[cmiller@Linux ~]$ ./test 0 AAAAAAAAAAAAAAAAAAAA
[cmiller@Linux ~]$ ./test 1 AAAAAAAAAAAAAAAAAAA
[cmiller@Linux ~]$ ./test 2 AAAAAAAAAAAAAAAAAAAAAAAAAA
[cmiller@Linux ~]$ ./test 3 18
[cmiller@Linux ~]$ time ./test 4 10
real 0m0.002s
user 0m0.000s
sys 0m0.004s
So despite the fact the vulnerable lines are executed and in the first four, memory
is corrupted, the program shows no sign of harm. The even-numbered test cases
demonstrate the fact the vulnerabilities are real:
[cmiller@Linux ~]$ ./test 0 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAA
Segmentation fault
[cmiller@Linux ~]$ ./test 1 AAAAAAAAAAAAAAAAAAAAAAAAAAAA
*** glibc detected *** ./test: double free or corruption (out):
0x086c8020 ***
...
[cmiller@Linux ~]$ ./test 2 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA
Segmentation fault
[cmiller@Linux ~]$ ./test 3 20
*** glibc detected *** ./test: free(): invalid pointer:
0x09d91020 ***
...
[cmiller@Linux ~]$ time ./test 4 914748364
real 0m54.942s
user 0m0.228s
sys 0m1.516s
6760 Book.indb 189 12/22/17 10:50 AM
190 Target Monitoring
Therefore, the odd-numbered test cases illustrate the fact that inputs can be sent
into the program, which, without detailed monitoring, would fail to find the vulner-
ability. Let us see if the advanced monitoring solutions we’ve discussed would be
able to detect the five vulnerabilities, even if only the less-effective, odd-numbered
test cases were available.
6.6.3 Guard Malloc
Guard Malloc is used by running the target program with the appropriate environ-
ment variables set. For example,
charlie-millers-computer:~ cmiller$
DYLD_INSERT_LIBRARIES=/usr/lib/libgmalloc.dylib ./test 1
AAAAAAAAAAAAAAAAAAA
GuardMalloc: Allocations will be placed on 16 byte boundaries.
GuardMalloc: - Some buffer overruns may not be noticed.
GuardMalloc: - Applications using vector instructions (e.g.,
SSE or
Altivec) should work.
GuardMalloc: GuardMalloc version 18
Bus error
So in this case, running the program with Guard Malloc enabled caused a bus
error and thus did find the vulnerability that would have otherwise been missed.
Not surprisingly, it did not find the vulnerability associated with the input 0 since