facilitates linking the click trace to an identity.
To emphasize possible threats, we describe two common-
place scenarios, which provide trackers with the possibility to
identify the users behind click traces in their databases, given
that some of them are unique.
We ﬁrst consider a tracking company that partakes in a
user data exchange, like BDEX, BIG, onAudience, or Lotame.
Most websites employ a combination of trackers, and some
user data inevitably ends up in databases of different trackers,
causing an overlap of page views between trackers. This
overlap can be used to identify click traces in acquired data, to
enrich the owned database with additional proﬁles. This also
allows for the re-identiﬁcation of click traces in acquired data,
thus learning additional, potentially sensitive, and explicitly
identiﬁed activities.
Second, we consider different types of shoulder surﬁng.
Assuming the tracking database contained pseudonymous click
traces that are unique in less than the entirety of their clicks,
partial knowledge could sufﬁce to identify individuals that
are represented in the data. This requires observation of an
identifying subset of clicks, which is easy to imagine: The
textbook example is a colleague or bystander who watches
another user. Considering frequent public sharing of links on
social media, a much more scalable and globally available way
to collect such identifying sets of clicks is to automatically
scrape social media sites, and ﬁlter the posts of real-name
proﬁles for shared links.
Tracking companies argue they are not interested in iden-
tifying individuals. The data of a large fraction of them,
however,
is readily available for low prices at user data
exchanges, and data loss incidents happen to even the largest
and most proﬁtable companies7,8.
To evaluate the occurrence of pseudonyms in tracking
databases, we will analyze a representative, real dataset.
III. IDENTIFICATION METRICS AND ANONYMIZATION
STRATEGIES
In this section, we will introduce the metrics we use to
measure pseudonymity and identiﬁability. We subsequently
discuss strategies that commonly are suggested to anonymize
tracking databases.
The data collected by trackers upon a page call is commonly
stored as a tuple of page and client information, which we
call a click. It is possible to assemble the set of clicks of a
client by selecting the tuples with identical client identiﬁers.
Depending on browser settings, these client identiﬁers may
change frequently, resulting in very small sets of clicks, or
remain stable over long periods of time resulting in very
large collections of clicks of the same client. To obtain a
more consistent dataset, we do not consider these client sets
7https://www.theverge.com/2018/10/8/17951914/google-plus-data-breach-
exposed-user-proﬁle-information-privacy-not-disclosed
8https://www.wired.com/story/facebook-security-breach-50-million-
accounts/
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:30 UTC from IEEE Xplore.  Restrictions apply. 
779
and instead only retain information pertaining to individual
browsing sessions. We call the sequence of clicks representing
a browsing session a click trace.
Deﬁnition 1 (Clicks and click traces): A click is a tuple
representing a page impression. It may contain information
about the page, a client identiﬁer, other characteristic data
about the client as well as a timestamp. Consider a database
of browsing data consisting of individual clicks. A click trace
is an ordered sequence of clicks. All clicks of a click trace
belong to the same user and are ordered chronologically.
A click trace β is a subsequence of click trace α, or β ⊆ α,
if all its clicks are contained in α in the same order (not
necessarily subsequently, so AC ⊆ ABC, but BA (cid:54)⊆ ABC).
A traceset is an unordered set of click traces. The n-subset
of a click trace α is the collection of all its subsequences
of length n, or more formally: Nn(α) = {β | β ⊆ α,|β| =
n} with |Nn(α)| =(cid:0)|α|
(cid:1).
In this paper we want to assess how easily pseudonyms
emerge, and tracking data can be identiﬁed using secondary
sources.
n
A pseudonym can be seen as the lowest form of identity.
It does not directly identify the subject, but
it uniquely
corresponds to one. Once that link is found out, for example
through some external data, the pseudonymity is broken and
the data subject is identiﬁed. By measuring the degree to
which pseudonyms exist in a collection of click traces, we can
determine how vulnerable it is to simple de-anonymization.
Applied to a database of click traces, our deﬁnition of
pseudonyms relates to k-anonymity. A database contains no
pseudonyms if it is k-anonymous with k ≥ 2; in other words,
if no click trace is unique. However, the binary nature of k-
anonymity severely limits its utility for our purpose. It is to
be expected that at least one click trace will remain unique
under most coarsening measures, for example because a web
page may only have a single visitor or a location only a
single browser. k-anonymity would never be fulﬁlled, even if
coarsening measures were relatively successful. Instead, the
fraction of unique click traces allows for a more nuanced
observation. For that reason we adopt the approach used by De
Montjoye et al. [15], which deﬁnes unicity as the proportion
of unique pieces of information. Unicity in this case serves as
a measure of how close the database is to being anonymous.
A unicity of 0 implies k-anonymity, a unicity of 0.5 means
half the click traces in our traceset are pseudonyms.
Deﬁnition 2 (Unicity): We say that click traces α and β
are equal, or α = β, if and only if α ⊆ β and β ⊆ α. If
and only if two click traces are equal they belong to the same
anonymity set. A click trace is unique if it is the only member
of its anonymity set. The unicity of a traceset is its ratio of
unique click traces over all click traces.
As previously mentioned it is not always necessary to know
all clicks from a trace to make it uniquely identiﬁable. While
the pseudonymity of a unique click trace is by itself ﬁrst
and foremost a theoretical issue, unique partial traces present
an immediate practical adversary model. Note that Partial
information is more easily obtained and, once identiﬁed, the
click trace contains previously unknown information. We want
to ﬁnd out how little information is necessary for successful
identiﬁcation and call the corresponding metric identiﬁability.
The idea behind that metric is as follows: given an adversary
with some well deﬁned capability of obtaining partial informa-
tion of some browsing session, an identiﬁability of 0.2 means
that the corresponding full click trace has a 20% chance to
be identiﬁed. It is important to note that the adversary in this
model does not actually have the partial information, in which
case the corresponding click trace would either be or not be
identiﬁed. Rather he has the abstract capability, represented
by a set of possible partial traces he can draw from, and
identiﬁability is then the share of samples in this set uniquely
identifying the original trace.
Deﬁnition 3 (identiﬁability): The compatibility class θ(β, T )
of click trace β given traceset T consists of all click traces
α ∈ T such that β ⊆ α. We say that a click trace α ∈ T is
identiﬁed by β, or β identiﬁes α, if α is the only member of
its compability class, or θ(β, T ) = α. Given traceset Iα, the
identiﬁability ρα(T, Iα) of click trace α ∈ T is the ratio of
click traces β ∈ Iα that α is identiﬁed by.
{Iα|α ∈ T} is
The weighted identiﬁability of a trace set T given I =
(cid:80)
(cid:80)
α∈T (|α|ρα(T, Iα))
β∈T |β|
ρ(T, I) =
Iα represents the adversary, or rather all the possible ways
with which they might attempt to identify α. For example, Iα
might consist of all subtraces β ⊆ α of length |β| = n ≤ |α|,
or Iα = Nn(α), representing an adversary making exactly n
random observations of click trace α.
Success of the adversary measured in the identiﬁcation
ratio depends on the adversary’s prior knowledge. An ad-
versary knowing the entire dataset can clearly identify every
pseudonym, but gains no information in the process. An
adversary knowing very little may identify only a few click
traces, but learn much more in the process, relatively speaking.
We now describe the implementation of click trace genera-
tion, as well as the calculation of unicity and identiﬁability.
A. Extracting Click Traces
The dataset which we are going to use for our evaluation
does not contain click traces, rather it contains the full brows-
ing history of each client, including a unique ID. As a ﬁrst
data processing step we thus need to turn the full browsing
history into individual browsing sessions.
The database we analyze is extremely comprehensive, we
made some implementation decisions to achieve feasible cal-
culation. Due to technical considerations the database can only
be accessed sequentially. We can choose an order in which
entries are processed a priori, but we cannot access them out of
order. Following the industry deﬁnition of a browsing session
(ref. to section II), we build click traces iteratively by pushing
clicks from a chronological click stream until two consecutive
clicks are more than 1800 seconds apart or the trace exceeds
a given maximum length (Algorithm 1).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:30 UTC from IEEE Xplore.  Restrictions apply. 
780
input : chronologically sorted stream C, max length ml;
all c ∈ C contain timestamp ct and click trace ID ci
output: traceset T
T ← {}; TempTraces ← {}; LastTime ← {};
for c ∈ C do
if ci ∈ TempTraces and ct − LastTime[ci] < 1800 and
TempTraces[ci] < ml then
else
TempTraces[ci] ← TempTraces[ci] ∪ c;
T ← T ∪ TempTraces[ci];
TempTraces[ci] ← c;
end
LastTime[ci] ← ct;
end
for trace ∈ TempTraces do
T ← T ∪ trace;
end
Algorithm 1: Calculating click traces from data stream
B. Calculating Unicity
Computing unicity requires a number of comparisons be-
tween click traces to determine whether they belong to the
same anonymity set. By hashing click traces and using an
index we only require logarithmic time to determine whether
a click trace is unique or not. The overall complexity of
Algorithm 2 is thus O(n log n).
input : traceset T , click trace properties w, hash function h
output: unicity and anonymity sets Anon of T
Anon ← {}
for wi ∈ w do
for t ∈ T (wi) do
/* check if t’s anonymity set already exists*/
if t ∈ Anon then
Anon(t) ← Anon(t) +1;
Anon(t) ← 1;
else
end
end
end
unique ← 0;
for t ∈ Anon do
if Anon(t) = 1 then
unique ← unique + 1;
end
end
unicity ← unique
|T|
Algorithm 2: Unicity and anonymity sets given a traceset
We can further reduce the computation time by grouping
click traces by their coarsened timestamp range and length.
Doing so does not reduce time complexity, but signiﬁcantly
increases performance.
C. Evaluating Identiﬁability
Algorithm 3 calculates identiﬁability according to deﬁni-
tion 3. We assess identiﬁability with two realistic threats in
mind: (1) the case of database trading, and (2) shoulder surﬁng.
Identiﬁability depends on prior knowledge of the adversary,
which differs between these scenarios and is represented in
the adversary set.
For web trackers we deﬁne prior knowledge as the fraction
of the acquired dataset overlapping with their own data.
Recalling deﬁnition 3, for each adversary we need to deﬁne
the adversary set I. For an acquired dataset T and a given
overlap σ ∈ [0, 1], we consider all possible sets of websites
W such that the fraction of clicks belonging to each such set is
within an  of the overlap: ∀ω ∈ W,
with γα,ω being the maximal subtrace of α such that each
click belongs to a website in ω. Analogous to deﬁnition 3 we
obtain the adversary set
(cid:12)(cid:12)(cid:12)(cid:80)
(cid:80)
α∈T |γα,ω|
α∈T |α| − σ
(cid:12)(cid:12)(cid:12) < ,
I = {Iα,W|α ∈ T} with Iα,W = {γα,ω|ω ∈ W}.
For example with an overlap of 0.2 an identiﬁability of
0.5 means that an adversary, who acquired an external dataset
with 20% of its clicks appearing in his own data, can uniquely
identify half of the click traces in the acquired dataset. Having
re-identiﬁed click traces in the acquired data, the adversary
learns additional actions of the client on sites that he does not
track. We deﬁne gain accordingly to be the fraction of clicks
of the acquired dataset belonging to identiﬁed click traces,
which are not contained in the known dataset.
For the shoulder surfer, we deﬁne prior knowledge as the
number n of observations known to the adversary, therefore
I = {Iα|α ∈ T} with Iα = Nn(α).
input : acquired traceset T , adversary set I, sample size s
output: identiﬁability ident of T
index ← 0;
for t ∈ T do
/* build associative array assigning clicks to their trace */
traces[index, index + |t|] ← t;
index ← index + |t|;
end
IndexSamples ← draw s samples from [1, size(T)];
count ← 0;
for i in IndexSamples do
α ← traces(i);
subsample ← draw sample from Iα;
matched ← False;
for β ∈ T do
if subsample ⊆ β then
matched ← True;
end
end
if not matched then
count ← count +1;
end
end
ident ← count
s ;