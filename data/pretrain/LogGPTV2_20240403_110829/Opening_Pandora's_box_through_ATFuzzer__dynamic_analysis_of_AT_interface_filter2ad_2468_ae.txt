is a phone call or not. Whenever he detects there is a phone call,
the attacker injects AT + CHUP to cut the phone call. To make the
matters worse, the attack is transparent to the victim, i.e., there
is no indication on the mobile screen that an attack is going on.
The victim device user perceives either there is no incoming call or
abrupt call drops due to poor signal quality or network congestions.
CVE-2019-16400 [5] has been assigned for this along with other
reported denial of service attacks in Samsung phones.
Call forwarding. If the victim device is subscribed to call for-
warding service, the adversary may exploit the ATD command to
forward victim device’s incoming calls to an attacker-controlled
device. Exploiting this, the adversary first prevents the victim de-
vice from receiving the incoming calls and then learns sensitive
information, such as password or pin for two-factor authentication
possibly sent by an automated teller. Note that, such call forward-
ing is also transparent to the user since the user is unaware of any
incoming calls.
Activating do not disturb mode. The adversary using a malicious
Bluetooth peripheral or MitM instance can turn on the do not dis-
turb mode of the carrier through ATD command. Similar to call
forwarding attack, it is also completely transparent to the user as
no visible indication of do not disturb mode is displayed on the
device. While the user observes all the network status bars and the
Internet connectivity, the device, however, does not receive any call
from the network.
Selective call blocking. A variation of the previous attack is also
possible in which the adversary may allow the victim phone to
receive selective calls by intermittently turning on/off the do not
disturb mode. This may force the user to receive calls only from
selective users not affecting others.
5.4 Findings over USB (RQ2)
We now discuss findings over USB.
(1) Syntactic errors – responds ok with composite actions. It is
one of the interesting classes of problematic grammars for which the
AT interface of the affected devices respond to invalid AT commands
with ok, but performs multiple actions together. These invalid com-
mands are compositions of invalid characters and two valid AT com-
mands with no semicolon as their separator. For instance, ATFuzzer
generated an invalid command ATIHD + 4632048034; using two
valid grammars for ATD and ATI (as shown in Figure 3) and in-
valid characters for which the target device returns ok but places
a phone call to 4632048034 and shows the manufacturer, model
revision, and IMEI information simultaneously.
(2) Syntactic errors – responds ok with an action. In this type
of syntactically problematic grammars, the target device responds
to an invalid command instance with ok but performs an action.
For instance, the grammar cmd →Arg1. I .Arg2 in Table 3 can
be instantiated with an invalid command instance ATHIX which
returns sensitive device information.
(3) Syntactic errors – responds error with an action. In this
class of syntactic errors, the AT interface recognizes the inputs as
faulty by acknowledging with error, but it still executes the action
associated with the command and even does worse by crashing
the RIL daemon and inducing complete disruptions in the cellular
Internet connectivity. It basically reveals a fundamental flaw in the
AT interface— if a command is considered as erroneous, it should
not be executed. For example, the grammar cmd →D . Dnum in
Table 3 can be instantiated with ATD+4632048034 (a variation of
the ATD production rule in Figure 3) which is supposed to start a
cellular voice call. Instead, the grammar returns error in the form of
NO CARRIER and induces the cellular Internet connectivity to go
down completely for a certain amount of time (15-20 seconds). We
have also found grammars for which the device returns other error
statuses, e.g., ERROR, NO CARRIER, CME ERROR, ABORTED, and
NOT SUPPORTED, but still executes those invalid commands.
(4) Semantic errors. This class of grammars conforms with the
input pattern defined by the standards [11], but induces disrup-
tions in the cellular connectivity for which the recovery requires
rebooting the device. The grammars of this class are shown in Table
3.
Possible exploitation. It may appear that the implications of in-
valid AT commands over USB are negligible as compared to the
valid AT commands which may wreak havoc by taking full control
of the device. We, however, argue that if AT interface exposure
is restricted through blacklisting the critical and unsafe valid AT
commands by the parser in the first place, the adversary will still
be able to induce the device to perform same semantic function-
alities using invalid AT commands. This is due to the uncovered
vulnerabilities for which the parser will fail to identify the invalid
AT commands as the blacklisted commands and thus allows the
adversary to achieve same functionalities as the valid ones.
5.4.1 Efficacy of grammar-aware crossover (RQ3). ATFuzzer with-
out crossover (by disabling the crossover in ATFuzzer) uncovered
only 3 problematic grammars as compared to ATFuzzer with all
proposed crossover and mutations (Table 4). This is due to the fact
that ATFuzzer without crossover cannot induce enough changes in
the structure and type of the arguments of parent grammars, as a
result of which it reduces the search space.
5.4.2 Efficacy of grammar-aware mutation (RQ4). Since ATFuzzer
without mutation cannot induce changes in the arguments and the
respective conditions, it uncovered only 2 problematic grammars.
ATFuzzer without crossover, however, performs slightly better than
that of the ATFuzzer without crossover. This also justifies our in-
tuition that mutation strategies play a vital role in any fuzzer as
compared to crossover techniques. Without mutation, a fuzzer un-
likely generates interesting inputs for the system under test.
5.4.3 Efficacy of timing feedback (RQ5). We observed that ATFuzzer
without feedback performs better than the other two (RQ2 and RQ3)
variations. ATFuzzer without feedback uncovered 5 problematic
grammars and thus is less effective than ATFuzzer with feedback.
AT interface being a complete black box with little to no feedback
539of
Class
Bugs
Syntatctic
–returns
OK
with
composite
actions
Syntatctic –
returns OK
with an ac-
tion
Syntatctic –
returns ER-
ROR with
an action
Semantic –
returns OK
with an ac-
tion
Grammar and Command Instance
cmd →I.Arg.D.Dnum.Darg;
Arg →[a − zA − Z]
Dnum →[a − zA − Z 0 − 9 + ∗#]∗
Darg →I |G |ϵ
E.g. ATIHD + 4642048034I;
cmd →+COPN; Arg
Arg →[i |I]∗
E.g. AT + COPN; III
cmd →Arg1.I.Arg1
→[X |H]
E.g. ATHIX
cmd →Arg1.I.Arg1.Arg1
Arg1 →X
E.g. ATXIX
cmd →Arg1.Arg2.Arg3
Arg1 →+CI MI | I | +CEER
Arg2 →∗|;
Arg3 →Q|Z
E.g. AT + CIMI ∗ Q
cmd →+CLCC;Arg1
Arg1 →[a − zA − Z 0 − 9]∗
E.g. AT + CLCC; ABC123
cmd →Arg1; Arg2
Arg1 →+COP N | + CGMI |
+CGMM | + CGMR
Arg2 →[X |E]
E.g. AT + COPN; X
cmd →Arg1.Arg2.Arg3
Arg1 →+CI MI | I | +CEER
Arg2 →; |∗
Arg3 →ˆ[Q |Z]
E.g. ATI; L
cmd →Arg1; Arg2
Arg1 →+COP N | + CGMI |
+CGMM | + CGMR
Arg2 →ˆ[X |E]
E.g. AT + CGMM; O
cmd →Arg.D.Dnum.Darg;
Arg →[a − zA − Z]
Dnum →[a − zA − Z 0 − 9 + #]∗
Darg →I |G |ϵ
E.g. ATMD + 4632048034
cmd →+CUSD=,String
String →[a − zA − Z 0 − 9 + ∗#]∗
E.g. AT + CUSD =, ABC
cmd →+CCFC=Arg1,Arg2,Arg3,
145,32,Arg4,13,27
Arg1 →[1 − 5]
Arg2 →[1 − 2]
Arg3 →[0 − 9]∗
Arg4 →[a − zA − z0 − 9]∗
E.g. AT + CCFC = 3, 2, 732235, 145,
32, cA4{NYv, 13, 27
cmd →+COPS = 0,Arg1,Arg2,2
Arg1 →[0|1]
Arg2 →[a − zA − z]∗
E.g. AT + COPS = 0, 1, c19v6fC, 2
action/implication
Nexus5
LG G3
Nexus6
Nexus6P HTC
S8plus
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
read, execution/
manufacturer,
revision and IMEI
leaks
model
read/ leaks list of opera-
tors, manufacturer, model
revision and IMEI
read/ leaks manufacturer,
model revision and IMEI
read/ leaks manufacturer,
model revision and IMEI
read/ leaks IMSI, manu-
facturer, model revision
and IMEI
read/leaks current call list
read/leaks list of opera-
tors, IMEI, model and re-
vision information of the
device
read/ leaks IMSI, manu-
facturer, model revision
and IMEI
read /leaks list of opera-
tors, IMEI, model and re-
vision information of the
device
crash/ internet connectiv-
ity disruption
crash/ internet connec-
tion disruption
crash/ internet connectiv-
ity disruption
✓
crash/internet connectiv-
ity disruption
✓
Table 3: Summary of ATFuzzer’s findings over USB.
we had to resort to various creative ways including timing informa-
tion to generate feedback score. However, This resorts to an upper
bound for the coverage information and loosely dictates ATFuzzer.
5.4.4 Comparison with other state-of-the-art fuzzer (RQ6). We com-
pare the effectiveness of ATFuzzer against AFL (American Fuzzy
Lop) [59]. Since current versions of AFL require instrumenting the
test programs, we implemented a modest string fuzzer that adopts
five mutation strategies (walking bit flips, walking byte flips, known
integers, block deletion and block swapping) employed by AFL and
incorporated our proposed timing-based feedback loop to it. We
evaluate this AFL variant with 80 different seeds (consisting of valid
and invalid command instances of randomly chosen 40 different
AT reference grammars).
540ATFuzzer
Fuzzing Approach
ATFuzzer w/o feedback
ATFuzzer w/o crossover
ATFuzzer w/o mutation
Modified AFL
Problematic Grammars
9
5
3
2
2
Table 4: Result obtained with different fuzzing approaches on
Nexus5 over a period of 3days for each approach.
Table 4 shows that the AFL variant uncovered 2 different prob-
lematic grammars whereas ATFuzzer uncovers 9 unique grammars
after running for 3 days. Though we decided to compare our tool
with AFL, which is the best choice we had as AFL is considered the
state-of-the-art tool for fuzzing, we do not claim the comparison
to be ideal. Because AFL relies heavily on code average informa-
tion and for our case, we replaced the code coverage with the best
available substitute (i.e., coarse-grained timing information as a
loose indicator to code coverage). We acknowledge that this is a
best-effort approach and the evaluation may be sub-optimal.
6 RELATED WORK
In this section, we mainly discuss the relevant work on the following
four topics: AT commands, mutation-based fuzzing, grammar-based
mutation, grammar-based generation.
AT commands. Most of the previous work related to AT com-
mands follow investigate how an adversary can misuse valid AT
commands to attack various systems. The work from Tian et al.
[53] can be considered the most relevant to our work, however, it is
significantly different in the following three aspects: (i) Firstly, they
only show the impact of AT commands over USB as they consider
the functionality and scope of AT commands over Bluetooth too lim-
ited to study. We, however, demonstrate the dire consequences of
AT commands over Bluetooth interface with the uncovered invalid
and valid AT commands. (ii) Secondly, they only show the impact of
valid AT commands whereas we demonstrate the impact of invalid
AT commands exploring different attack surfaces. (iii) Finally, one