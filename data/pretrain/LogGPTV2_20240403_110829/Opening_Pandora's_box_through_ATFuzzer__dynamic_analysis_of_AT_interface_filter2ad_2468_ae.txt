### Call Interception and Manipulation Attacks

#### Call Interruption
The attacker monitors the victim's device to detect an incoming or ongoing phone call. Upon detection, the attacker injects the `AT + CHUP` command to terminate the call. This attack is particularly insidious because it is transparent to the victim; there are no visible indications on the mobile screen that an attack is in progress. The user may perceive the call as either not being received or as having been dropped due to poor signal quality or network congestion. This vulnerability has been assigned the CVE-2019-16400, along with other reported denial of service (DoS) attacks on Samsung phones.

#### Call Forwarding
If the victim's device is subscribed to a call forwarding service, the attacker can exploit the `ATD` command to redirect all incoming calls to a device controlled by the attacker. This allows the adversary to intercept and potentially eavesdrop on sensitive information, such as passwords or PINs for two-factor authentication, which might be sent via automated teller systems. Similar to the call interruption attack, this call forwarding is also transparent to the user, as they remain unaware of any incoming calls.

#### Activating Do Not Disturb Mode
Using a malicious Bluetooth peripheral or a Man-in-the-Middle (MitM) instance, the attacker can activate the "Do Not Disturb" mode on the victim's device via the `ATD` command. This attack is also completely invisible to the user, as no indication of the "Do Not Disturb" mode is displayed on the device. While the user sees all network status bars and Internet connectivity indicators, the device does not receive any calls from the network.

#### Selective Call Blocking
A more sophisticated variant of the "Do Not Disturb" attack involves the attacker intermittently turning the "Do Not Disturb" mode on and off. This can force the user to receive calls only from specific numbers, effectively blocking calls from other users without their knowledge.

### Findings Over USB (RQ2)

#### Syntactic Errors – Responds OK with Composite Actions
One class of problematic grammars involves the AT interface responding with "OK" to invalid AT commands but performing multiple actions. These invalid commands are composed of invalid characters and two valid AT commands without a semicolon separator. For example, the ATFuzzer generated an invalid command `ATIHD + 4632048034;` using valid grammars for `ATD` and `ATI` and invalid characters. The target device responds with "OK" but simultaneously places a call to `4632048034` and displays the manufacturer, model revision, and IMEI information.

#### Syntactic Errors – Responds OK with an Action
In this type of syntactically problematic grammar, the target device responds with "OK" to an invalid command but still performs an action. For instance, the grammar `cmd → Arg1. I .Arg2` can be instantiated with an invalid command `ATHIX`, which returns sensitive device information.

#### Syntactic Errors – Responds ERROR with an Action
This class of syntactic errors involves the AT interface recognizing the input as faulty and responding with "ERROR," but still executing the associated action. This can lead to the RIL daemon crashing and causing complete disruptions in cellular Internet connectivity. For example, the grammar `cmd → D . Dnum` can be instantiated with `ATD+4632048034`, which is supposed to start a cellular voice call. Instead, the device returns "NO CARRIER" and disrupts cellular Internet connectivity for 15-20 seconds.

#### Semantic Errors
These grammars conform to the input pattern defined by standards but induce disruptions in cellular connectivity, requiring a device reboot for recovery. Examples of such grammars are shown in Table 3.

### Possible Exploitation
While the implications of invalid AT commands over USB may seem less severe compared to valid AT commands, we argue that if critical and unsafe valid AT commands are blacklisted, adversaries can still achieve the same functionalities using invalid AT commands. This is due to uncovered vulnerabilities where the parser fails to identify the invalid AT commands as blacklisted, allowing the adversary to perform the same actions.

### Efficacy of Grammar-Aware Crossover (RQ3)
ATFuzzer without crossover (by disabling the crossover in ATFuzzer) uncovered only 3 problematic grammars, compared to 9 when using all proposed crossover and mutation techniques. This is because ATFuzzer without crossover cannot induce enough structural changes in the parent grammars, reducing the search space.

### Efficacy of Grammar-Aware Mutation (RQ4)
ATFuzzer without mutation uncovered only 2 problematic grammars, while ATFuzzer without crossover performed slightly better. This highlights the importance of mutation strategies in fuzzers, as they generate more diverse and interesting inputs for the system under test.

### Efficacy of Timing Feedback (RQ5)
ATFuzzer without feedback uncovered 5 problematic grammars, making it less effective than ATFuzzer with feedback. Given the AT interface's black-box nature with little to no feedback, we resorted to creative methods, including timing information, to generate feedback scores. However, this approach provides an upper bound for coverage information and loosely dictates ATFuzzer's performance.

### Comparison with Other State-of-the-Art Fuzzers (RQ6)
We compared ATFuzzer's effectiveness against AFL (American Fuzzy Lop). Since current versions of AFL require instrumenting test programs, we implemented a modest string fuzzer that adopted five mutation strategies from AFL and incorporated our timing-based feedback loop. We evaluated this AFL variant with 80 different seeds (valid and invalid command instances of 40 different AT reference grammars).

Table 4 shows that the AFL variant uncovered 2 problematic grammars, while ATFuzzer uncovered 9 unique grammars after running for 3 days. Although AFL is considered the state-of-the-art tool for fuzzing, our comparison is not ideal because AFL relies heavily on code coverage information, which we replaced with coarse-grained timing information. We acknowledge that this is a best-effort approach and the evaluation may be sub-optimal.

### Related Work
Previous work on AT commands primarily focuses on how adversaries can misuse valid AT commands to attack various systems. The work by Tian et al. [53] is the most relevant, but it differs in three key aspects: (i) They only consider the impact of AT commands over USB, while we demonstrate the consequences over Bluetooth. (ii) They focus on valid AT commands, whereas we explore the impact of both valid and invalid AT commands. (iii) Finally, one additional difference is...