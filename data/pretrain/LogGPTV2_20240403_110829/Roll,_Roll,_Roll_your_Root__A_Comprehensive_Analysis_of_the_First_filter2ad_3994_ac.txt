When receiving an HTTP request, exit nodes send a DNS request to
their resolver and then issue the HTTP/S request. This allows us to
measure resolver behavior. For more details on using Luminati for
network and DNS measurements, we refer to Chung et al. [27, 28].
3.3 Ethical Considerations
The measurement data collected at the root of the DNS consists of
aggregate data (RSSAC002), telemetry signals (RFC 8145), DNSKEY
queries and aggregates of popular queries for telemetry sources
identified as showing non-standard behavior. Only in rare cases
do we identify specific resolver operators (not end users) so we
can contact them in order to gain an understanding of unexpected
resolver behavior (cf. Section 4.3.2).
Most of our active measurements leverage well-established pub-
lic measurement platforms, such as RIPE Atlas, where strict guide-
lines exist. The exception to this are our Luminati measurements.
To use the Luminati service, we first note that we paid the op-
erators of Luminati for access, and strictly follow their License
Agreement [29]. The owners of exit nodes agreed to route Lumi-
nati traffic through their hosts. Furthermore, we took great care
to ensure that all traffic only flowed toward domains under the
authors’ control, which serve empty web pages. Given that we are
only interested in information about the RFC 8509 behavior of DNS
resolvers, we discard any end user IP addresses from our logs.
4 ANALYSIS
The next sections discuss the most relevant events of the rollover
(I – VI in Fig. 2), starting before the rollover (I – III) in Section 4.1,
followed by the rollover itself (IV) in Section 4.2 and ending after
the rollover (V – VI) in Section 4.3.
4.1 Before the Roll
4.1.1 Early RFC 8145 Data. RFC 8145, published April 2017, was
quickly adopted by open source resolver implementers. BIND sup-
ports it from mid-2016 with the functionality enabled by default,
Unbound since April 2017, enabling it by default in October 2017,
and Knot since November 2017, again enabled by default.
We began looking for evidence of RFC 8145 signals in A/J Root
data from May 2017. By September 2017 we see trust anchor signals
from approximately 1,300 unique source IPs per day. Fig. 4 shows
these early trust anchor signals. The KSK-2010 line shows what
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Müller et al.
Figure 4: Early RFC 8145 trust anchor signals (2017).
Figure 6: Addresses signaling only KSK-2010.
Description
A Unique sources in ICANN data
Sources from A signaling KSK-2010
B
Sources from B sending only one signal
C
D Unique Sources in ICANN data to B Root
E
F
G
Sources from D signaling KSK-2010
Sources from E signaling just once
Sources from F sending 1-9 queries
Count
1,206,840
508,533
310,839
309,140
113,467
16,403
6,702
Table 4: Narrowing the observed data.
Query-Name
_ta-4a5c
.
VPN-PROVIDER.com
VPN-PROVIDER-ALTERNATE.com
_sip._udp.OTHER-DOMAIN.com
Count
15,447
9,182
3,156
415
86
Table 5: Top query names from anomalous sources.
unusual artifacts: (i) a large fraction of resolvers failed to pick up and
trust KSK-2017, as measured by resolvers sending only RFC 8145
KSK-2010 signals and seen in Fig. 6, and (ii) many of the data points
came from IP addresses sending only small numbers of queries, as
seen in Fig. 5. Note that the fraction of resolvers not trusting KSK-
2017 actually got worse, not better, between the end of Fig. 4 and
the beginning of Fig. 6. These artifacts led to the question “Why do
so many new addresses appear that send RFC 8145 signals indicating
they only trust KSK-2010?”
To answer this question, we compare the RFC 8145 signal data
from ICANN to all DNS queries arriving at B Root over a four week
period from March 1st–29th, 2018. We focus this analysis on B Root,
because unlike the data from ICANN which only contains RFC 8145
signals, for B Root we have full access to all queries received. We
narrow the data to those addresses that behave unexpectedly: they
send a single signal for KSK-2010 to B Root, and send only 1–9 other
queries to B Root in the period covered. The narrowing down of the
full list of IP addresses ICANN observed to just these anomalously
behaving addresses is shown in Table 4.
To test if there is any commonality in other query names sent by
these sources, we extract and correlate the top query names sent
by these addresses (shown in Table 5). Beyond the RFC 8145 signals
Figure 5: CDF of addresses vs. queries in B Root data sending
only KSK-2010 signals.
fraction of RFC 8145 sources sends signals for the old trust anchor,
and the KSK-2017 line shows signals for the new trust anchor. Note
that these signals are independent; in other words: a single source
may send signals for both KSK-2010 and KSK-2017.
As Fig. 4 shows, initially almost all sources had only KSK-2010.
There is some slight increase in uptake of KSK-2017 starting in June,
before KSK-2017 was published in the root zone. This increase can
be explained by installations that received the new trust anchor
as part of a software update, or from those where an administra-
tor manually added it. ISC, for example, added the new key to
BIND’s code repository on the same day it was made operational
and published by IANA (February 2nd, 2017).
When KSK-2017 is published in the root zone on July 11th, 2017,
validators that implement RFC 5011 begin the process of accepting
the new key. After seeing the key published (and correctly signed)
for 30 continuous days (the RFC 5011 Add Hold-Down Time), a
validator adds the new key to its trust anchor set. Thus, from August
10th, we observe a rapid rise in signalers reporting KSK-2017 over
the two days after the hold-down period ends. Because the TTL of
the DNSKEY record set is 48 hours, the shift is not immediate.
After the 30-day hold-down ends, some 8% of signalers still do
not report having KSK-2017. Operators watching this data hoped
this population would continue to shrink. However, it remained at
this level through the end of September. This is the primary reason
why, on September 27th 2017, ICANN made the difficult decision
to postpone the rollover [4]. As late as August 2019, around 1% of
signalers still report only having KSK-2010.
4.1.2 Unusual KSK-2010 RFC 8145 signalers. During continued
monitoring of the RFC 8145 signals, ICANN began observing two
KSK−2017 added to zoneRFC 5011addhold−down0.000.250.500.751.00MayJunJulAugSepOctFraction of signallersKSK−2010KSK−20170.50.60.70.80.91.0110100100010000100000106107Number of queriesCDF of Source IPs)VPN release 1VPN release 2VPN release 3Actual rollover0.00.10.20.30.40.5Feb '18Apr '18Jun '18Aug '18Oct '18Dec '18Fraction of RFC 8145 signallersIPv4IPv6Roll, Roll, Roll your Root
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Figure 7: Key transition for all VPs.
Figure 8: Reported DNSKEY TTL.
Figure 9: KSK-2017 on large resolvers.
(“_ta-4a5c”) and queries for root-zone data (“.” (period)), the next
highest two requested names are a Virtual Private Network (VPN)
provider’s primary and secondary domain (anonymized in Table 5).
This commonality in top queries strongly indicates the discovery of
a likely cause of KSK-2010 signals from sources sending otherwise
low-volume traffic. Searching the VPN provider’s software, taken
from their Android release, revealed an embedded “root.key” file
containing just KSK-2010 and not KSK-2017. The embedded libraries
found in the software also revealed a library name matching the
Unbound project [30], a popular DNSSEC-validating resolver.
We contacted the VPN provider on April 17th, 2018. They con-
firmed our findings and indicated that multiple products were af-
fected. Subsequently, they released updated versions of their prod-
uct to address the issue, as marked in Fig. 6. The desktop software
update had the most dramatic impact, significantly decreasing the
number of KSK-2010 signals seen at the root. The first mobile update
with the new key set also showed a small dip in KSK-2010 signals,
though the second mobile update exhibited a less visible impact.
Key Takeaway Before the Roll. A single application can signifi-
cantly influence trust anchor signaling, and the fact that it was an
end-user application is largely responsible for the high number of
signals. Given that DNSSEC validation in end-user applications will
become more common in the future, this needs to be considered
for future rollovers.
4.2 During the Roll
As KSK-2010 signals returned to the 8% range by mid-2018, ICANN
revised its plans for the rollover [31]. After community feedback
on these plans, ICANN proceeded with the rollover [32]. On Oc-
tober 11th, 2018, at 16:00h UTC the KSK is rolled (event IV). From
then on, root servers return a DNSKEY RRset signed with KSK-2017.
In this section we show how resolvers picked up the new RRset. We
then examine what happens to resolvers that do not have KSK-2017
as a trust anchor, and how operators solve the problems this causes.
4.2.1 The Key Transition. To measure the transition from the old
to the new RRset, we use RIPE Atlas probes (see Section 3.2) to send
DNSKEY queries and then analyzed the results. Fig. 7 shows when
resolvers drop the old RRset from their cache and query the root
for the new one. 3 Right after the new key is published, resolvers
begin showing cached signatures from KSK-2017. Within the first
3We published updates of this figure on social media and on the website of NLnet Labs
to give the community insight into the progress of the roll.
hour 7% of the resolvers have the new RRset. Sixteen hours later
over 50% of resolvers have the new RRset. At 48 hours after the
roll, the old RRset should have been removed from the caches of all
resolvers; 99.5% of our vantage points return KSK-2017 signatures
at that point. After 11 more days, the last “lagging" vantage points
pick up the new RRset (not shown in Fig. 7).
Because the root DNSKEY RRset has a TTL of 48 hours, we ex-
pected half of vantage points to have the new RRset after 24 hours.
As Fig. 7 shows, however, this point is already reached after just
16 hours. In Fig. 8 we plot the TTLs for the root DNSKEY RRset as
reported by each vantage point when it receives the new RRset
for the first time. More than 20% of vantage points report a TTL
that is lower than 1 day, and around 10% even report a TTL lower
than three hours. This indicates that some resolvers cut the TTL to
a value lower than 48 hours, also explaining why the new RRset
was picked up earlier than expected.4 What this also means is that
had a failure occurred during the rollover, we would likely have
seen this sooner than intuitively expected, which is important to
consider for future rollovers.
Another thing that stands out in Fig. 7, are sudden “jumps” in
the adoption of KSK-2017 (marked ①–③). We correlate these jumps
with adoption at resolvers often used by RIPE Atlas probes in Fig. 9.
The jumps respectively correspond to adoption of the new RRset
by Cloudflare (①), a German ISP (②) and Google (③). Operators of
the Cloudflare resolvers publicly commented that someone used
their web interface to purge the DNSKEY RRset of the root from the
cache right after the rollover [34]. This explains why the resolvers
fetched the new RRset soon after the roll. This spurred us to check
if other operators purposely flushed their caches before or after the
rollover to either keep the old status for as long as possible, or
force the new situation as soon as possible. To find evidence, we
looked for vantage points that report a TTL close to 48 hours just
before or after the rollover. We find three resolvers that fetched the
keyset just before the roll (effectively locking in the old situation
for almost 48 hours). A large European ISP privately confirmed
they did this to avoid problems right after the rollover, allowing
them to monitor the news from other operators after the roll [35].
Impact on Validating Resolvers. Now that we know how re-
4.2.2
solvers picked up the new RRset, we check if they experience any
problems once they have the new RRset. For resolvers that do expe-
rience problems, we expect them to either fail validating signatures
(become bogus) or turn off validation altogether (become insecure).
4E.g., Unbound caches RRsets for a maximum of 24 hours by default [33].
1230%25%50%75%100%Oct 11−16:00hOct 12−00:00hOct 12−08:00hOct 12−16:00hOct 13−00:00hOct 13−08:00hOct 13−16:00hOct 14−00:00hOct 14−08:00hOct 14−16:00h% VPs with Key CachedKSK−2010KSK−2017TTL cappedat 10800s(3 hours)TTL cappedat 86400s(1 day)0.000.250.500.751.001080086400172800TTLECDF of TTL1230%25%50%75%100%Oct 11−16:00hOct 12−00:00hOct 12−08:00hOct 12−16:00hOct 13−00:00hOct 13−08:00hOct 13−16:00hOct 14−00:00hOct 14−08:00hOct 14−16:00h% VPs with Key CachedAll VPsCloudflareGoogleISPIMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Müller et al.
Figure 10: DNSKEY queries from ISP “EIR” to A/J Root.
Figure 11: Root Sentinel observations with RIPE Atlas
We use RIPE Atlas measurements (see Section 3.2) to identify re-
solvers that were continuously secure 88 hours before the roll but
turned bogus or insecure at any point within 56 hours after the roll.
We summarize resolver behavior observed through RIPE Atlas
in Table 6. Row A shows the total number of resolvers observed
during the rollover. Of these, 1,717 (B+C) always validate signatures
correctly before the roll but 970 (2.7%) turn bogus and 747 (2.1%)
insecure some time after. We check how often problematic resolvers
query for the DNSKEY of the root, using DNS-OARC DITL data
collected during the rollover (see Section 3.1). If a resolver changes
state and sends more DNSKEY-queries, we conclude that this change
is caused by problems with the rollover. We see DNSKEY queries
from 519 sources at the root (D). Of these, 509 (E) send more DNSKEY
queries after than before the roll. For 359 resolvers, the increase in
DNSKEY queries exceeds 1.5 times (F). The majority, 342 resolvers
(G), return to their normal DNSKEY query pattern within an hour.
We assume operators intervened and fixed these resolvers. For