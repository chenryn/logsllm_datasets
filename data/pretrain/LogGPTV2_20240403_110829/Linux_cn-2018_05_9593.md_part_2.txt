  "author": "PI:EMAIL",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/triestpa/guttenberg-search/issues"
  },
  "homepage": "https://github.com/triestpa/guttenberg-search#readme",
  "dependencies": {
    "elasticsearch": "13.3.1",
    "joi": "13.0.1",
    "koa": "2.4.1",
    "koa-joi-validate": "0.5.1",
    "koa-router": "7.2.1"
  }
}
```
这个文件定义了应用程序启动命令和 Node.js 包依赖。
> 
> 注意：不要运行 `npm install` —— 当它构建时，依赖会在容器内安装。
> 
> 
> 
#### 2.6 - 测试它的输出
现在一切新绪，我们来测试应用程序的每个组件的输出。从应用程序的主目录运行 `docker-compose build`，它将构建我们的 Node.js 应用程序容器。
![docker build output](/data/attachment/album/201804/29/230009hbbjxdgxxwkfddxg.png)
接下来，运行 `docker-compose up` 去启动整个应用程序栈。
![docker compose output](/data/attachment/album/201804/29/230010o50854mg2sggzgqc.png)
> 
> 这一步可能需要几分钟时间，因为 Docker 要为每个容器去下载基础镜像。以后再次运行，启动应用程序会非常快，因为所需要的镜像已经下载完成了。
> 
> 
> 
在你的浏览器中尝试访问 `localhost:8080` —— 你将看到简单的 “Hello World” Web 页面。
![frontend sample output](/data/attachment/album/201804/29/230011r1eehrkmgrq4ekx3.png)
访问 `localhost:3000` 去验证我们的 Node 服务器，它将返回 “Hello World” 信息。
![backend sample output](/data/attachment/album/201804/29/230012uaczcnck1q9smmae.png)
最后，访问 `localhost:9200` 去检查 Elasticsearch 运行状态。它将返回类似如下的内容。
```
{
  "name" : "SLTcfpI",
  "cluster_name" : "docker-cluster",
  "cluster_uuid" : "iId8e0ZeS_mgh9ALlWQ7-w",
  "version" : {
    "number" : "6.1.1",
    "build_hash" : "bd92e7f",
    "build_date" : "2017-12-17T20:23:25.338Z",
    "build_snapshot" : false,
    "lucene_version" : "7.1.0",
    "minimum_wire_compatibility_version" : "5.6.0",
    "minimum_index_compatibility_version" : "5.0.0"
  },
  "tagline" : "You Know, for Search"
}
```
如果三个 URL 都显示成功，祝贺你！整个容器栈已经正常运行了，接下来我们进入最有趣的部分。
### 3 - 连接到 Elasticsearch
我们要做的第一件事情是，让我们的应用程序连接到我们本地的 Elasticsearch 实例上。
#### 3.0 - 添加 ES 连接模块
在新文件 `server/connection.js` 中添加如下的 Elasticsearch 初始化代码。
```
const elasticsearch = require('elasticsearch')
// Core ES variables for this project
const index = 'library'
const type = 'novel'
const port = 9200
const host = process.env.ES_HOST || 'localhost'
const client = new elasticsearch.Client({ host: { host, port } })
/** Check the ES connection status */
async function checkConnection () {
  let isConnected = false
  while (!isConnected) {
    console.log('Connecting to ES')
    try {
      const health = await client.cluster.health({})
      console.log(health)
      isConnected = true
    } catch (err) {
      console.log('Connection Failed, Retrying...', err)
    }
  }
}
checkConnection()
```
现在，我们重新构建我们的 Node 应用程序，我们将使用 `docker-compose build` 来做一些改变。接下来，运行 `docker-compose up -d` 去启动应用程序栈，它将以守护进程的方式在后台运行。
应用程序启动之后，在命令行中运行 `docker exec gs-api "node" "server/connection.js"`，以便于在容器内运行我们的脚本。你将看到类似如下的系统输出信息。
```
{ cluster_name: 'docker-cluster',
  status: 'yellow',
  timed_out: false,
  number_of_nodes: 1,
  number_of_data_nodes: 1,
  active_primary_shards: 1,
  active_shards: 1,
  relocating_shards: 0,
  initializing_shards: 0,
  unassigned_shards: 1,
  delayed_unassigned_shards: 0,
  number_of_pending_tasks: 0,
  number_of_in_flight_fetch: 0,
  task_max_waiting_in_queue_millis: 0,
  active_shards_percent_as_number: 50 }
```
继续之前，我们先删除最下面的 `checkConnection()` 调用，因为，我们最终的应用程序将调用外部的连接模块。
#### 3.1 - 添加函数去重置索引
在 `server/connection.js` 中的 `checkConnection` 下面添加如下的函数，以便于重置 Elasticsearch 索引。
```
/** Clear the index, recreate it, and add mappings */
async function resetIndex (index) {
  if (await client.indices.exists({ index })) {
    await client.indices.delete({ index })
  }
  await client.indices.create({ index })
  await putBookMapping()
}
```
#### 3.2 - 添加图书模式
接下来，我们将为图书的数据模式添加一个 “映射”。在 `server/connection.js` 中的 `resetIndex` 函数下面添加如下的函数。
```
/** Add book section schema mapping to ES */
async function putBookMapping () {
  const schema = {
    title: { type: 'keyword' },
    author: { type: 'keyword' },
    location: { type: 'integer' },
    text: { type: 'text' }
  }
  return client.indices.putMapping({ index, type, body: { properties: schema } })
}
```
这是为 `book` 索引定义了一个映射。Elasticsearch 中的 `index` 大概类似于 SQL 的 `table` 或者 MongoDB 的 `collection`。我们通过添加映射来为存储的文档指定每个字段和它的数据类型。Elasticsearch 是无模式的，因此，从技术角度来看，我们是不需要添加映射的，但是，这样做，我们可以更好地控制如何处理数据。
比如，我们给 `title` 和 `author` 字段分配 `keyword` 类型，给 `text` 字段分配 `text` 类型。之所以这样做的原因是，搜索引擎可以区别处理这些字符串字段 —— 在搜索的时候，搜索引擎将在 `text` 字段中搜索可能的匹配项，而对于 `keyword` 类型字段，将对它们进行全文匹配。这看上去差别很小，但是它们对在不同的搜索上的速度和行为的影响非常大。
在文件的底部，导出对外发布的属性和函数，这样我们的应用程序中的其它模块就可以访问它们了。
```
module.exports = {
  client, index, type, checkConnection, resetIndex
}
```
### 4 - 加载原始数据
我们将使用来自 [古登堡项目](https://www.gutenberg.org/) 的数据 —— 它致力于为公共提供免费的线上电子书。在这个项目中，我们将使用 100 本经典图书来充实我们的图书馆，包括《福尔摩斯探案集》、《金银岛》、《基督山复仇记》、《环游世界八十天》、《罗密欧与朱丽叶》 和《奥德赛》。
![Book Covers](/data/attachment/album/201804/29/230012dngaozogh81o85zn.jpg)
#### 4.1 - 下载图书文件
我将这 100 本书打包成一个文件，你可以从这里下载它 —— 
将这个文件解压到你的项目的 `books/` 目录中。
你可以使用以下的命令来完成（需要在命令行下使用 [wget](https://www.gnu.org/software/wget/) 和 [The Unarchiver](https://theunarchiver.com/command-line)）。
```
wget https://cdn.patricktriest.com/data/books.zip
unar books.zip
```
#### 4.2 - 预览一本书
尝试打开其中的一本书的文件，假设打开的是 `219-0.txt`。你将注意到它开头是一个公开访问的协议，接下来是一些标识这本书的书名、作者、发行日期、语言和字符编码的行。
```
Title: Heart of Darkness
Author: Joseph Conrad
Release Date: February 1995 [EBook #219]
Last Updated: September 7, 2016
Language: English
Character set encoding: UTF-8
```
在 `*** START OF THIS PROJECT GUTENBERG EBOOK HEART OF DARKNESS ***` 这些行后面，是这本书的正式内容。
如果你滚动到本书的底部，你将看到类似 `*** END OF THIS PROJECT GUTENBERG EBOOK HEART OF DARKNESS ***` 信息，接下来是本书更详细的协议版本。
下一步，我们将使用程序从文件头部来解析书的元数据，提取 `*** START OF` 和 `***END OF` 之间的内容。
#### 4.3 - 读取数据目录
我们将写一个脚本来读取每本书的内容，并将这些数据添加到 Elasticsearch。我们将定义一个新的 Javascript 文件 `server/load_data.js` 来执行这些操作。
首先，我们将从 `books/` 目录中获取每个文件的列表。
在 `server/load_data.js` 中添加下列内容。
```
const fs = require('fs')
const path = require('path')
const esConnection = require('./connection')
/** Clear ES index, parse and index all files from the books directory */
async function readAndInsertBooks () {
  try {
    // Clear previous ES index
    await esConnection.resetIndex()
    // Read books directory
    let files = fs.readdirSync('./books').filter(file => file.slice(-4) === '.txt')
    console.log(`Found ${files.length} Files`)
    // Read each book file, and index each paragraph in elasticsearch
    for (let file of files) {
      console.log(`Reading File - ${file}`)
      const filePath = path.join('./books', file)
      const { title, author, paragraphs } = parseBookFile(filePath)
      await insertBookData(title, author, paragraphs)
    }
  } catch (err) {
    console.error(err)
  }
}
readAndInsertBooks()
```