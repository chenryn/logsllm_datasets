one server. However, in modern cloud-computing platforms,
applications must be able to scale and run on different servers
during their lifetime. This may already be caused by system
maintenance. For the end-user this should be completely
transparent, but a trusted execution context cannot be stopped
on one server and restarted on a different server with the same
TMC; this is exactly what trusted hardware should prevent.
Therefore this would require a migration protocol that needs
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
the help of a trusted party.
For these reasons, we do not consider any solution that
requires extra hardware or restricts the application to be
deterministic in this paper. Instead we exploit the guarantees
available with standard TEEs.
B. Ensuring consistency at the clients
In the model considered here the TEE does not prevent a
malicious server from mounting rollback and forking attacks
and from isolating the clients from each other. The best possi-
ble option is to ensure that the clients remain “synchronized”
with each other as much as possible and to mitigate attacks
through this.
1) Fork-linearizability: Fork-linearizability [30] denotes
the strongest consistency notion among the clients that can be
achieved in the presence of rollback attacks and without client-
to-client communication. This well-established notion ensures
that whenever the malicious server has separated two clients,
they can never be joined again to see mutually inconsistent
responses from the server, without one of them detecting
the attack. In essence,
the
inconsistency remains forever. Clearly, the clients can detect
this though a lightweight, out-of-band mechanism.
the server has to pretend that
Protocols that ensure fork-linearizability work by embed-
ding information about the causal past of each operation into
the requests from client to severs [30], [11], [7]. They use
hash chains, Merkle trees, and vector clocks for representing
the past history of operations and their context. Such protocols
are very similar to the use of hash chains in blockchain
platforms [6], cryptocurrencies such as Bitcoin, and Certiﬁcate
Transparency [25].
The standard notion of linearizability [20] requires that the
operations of all clients appear to execute atomically in one
sequence, and that the atomic sequence respects the real-time
partial order of the operations that the clients observe. Fork-
linearizability is deﬁned as an extension of this, which relaxes
the condition of one sequence to permit multiple “forks”
of an execution [30], [12]. Under fork-linearizability, every
client observes a linearizable history and when an operation is
observed by multiple clients, the history of events occurring
before the operation is the same. In this context, the view of
a client Ci denotes a correct, serialized history of operations
for the functionality F , which includes all operations of Ci.
For a more formal treatment we refer to the literature [12].
taking into account
Unfortunately, fork-linearizability cannot be achieved with-
that some client operations on a
out
correct server are blocked until other, concurrent operations
terminate [12]. This inherent limitation has led to the relaxed
notions, such as weak fork-linearizability. In FAUST [10], for
instance, an operation returns a response to the client that is not
guaranteed to be immediately fork-linearizable or linearizable,
but the protocol notiﬁes the client later when it knows that
other clients have observed the operation as well. This is
captured by the notion of stability, discussed next.
2) Operation stability: We now deﬁne a way to inform
those of its operations that have reached
the client about
some level of consistency with respect to other clients. More
precisely, we call an operation o by a client Ci stable with
respect to another client Cj if the views of Ci and Cj both
include o. In other words, Ci knows that Cj has observed o
and that S was forced to take into account any effects of o in
later service responses to Cj.
Operation stability has also been used by [39], [10]. Here
we use it as follows. We augment the response event of every
operation with two numbers: an sequence number, which is
assigned by the protocol to the operation that completes; and
a stable sequence number, which denotes the latest stable
sequence number of this client. The sequence numbers re-
turned at one client are strictly increasing; the stable sequence
numbers never decrease.
Deﬁnition 1 (Operation stability). Let o be a complete
operation of Ci that returns sequence number t. We say that
o is stable w.r.t. a client Cj (cid:2)= Ci after Cj completes any
operation that returns an sequence number that is bigger than t.
Operation o of Ci is always stable w.r.t. Ci.
For a set of clients G that includes Ci, an operation o
of Ci is stable w.r.t. the set of clients G, when o is stable
w.r.t. all Cj ∈ G. An operation that is stable w.r.t. all clients
is simply called stable.
One may use different strengths of stability; for example,
an operation might take a long time until it becomes stable
(because all clients must observe it), but it might already be
stable at a subset of the clients much earlier. A particularly
useful subset is a majority quorum of the clients.
Deﬁnition 2 (Operation stability among a majority [35]).
An operation o of Ci is stable among a majority of clients,
when o is stable w.r.t. a set of clients C, where |C| > n/2.
Note that any subsequence of a history that contains only
operations that are stable among a majority is linearizable.
IV. LIGHTWEIGHT COLLECTIVE MEMORY
This section introduces Lightweight Collective Memory
(LCM), a protocol that allows a group of mutually trusting
clients to run a service on a (potentially malicious) remote
server. It beneﬁts from a trusted execution context T that runs
on the server and executes the operations on behalf of the
clients. LCM facilitates the detection of forking and rollback
attacks against T by ensuring fork-linearizability for every
client operation. Moreover, LCM indicates which operations
are stable among a majority; this permits clients to infer when
their operations are linearizable. The LCM protocol beneﬁts
from the security guarantees of the TEE; in contrast to all
previous protocols in the line of work originating with Maz-
ières and Shasha [30], aiming at fork-linearizable semantics,
the clients do not verify operation results here. Clients only
handle metadata and rely on the TEE for producing correct
responses.
A. Overview
LCM executes a stateful functionality F inside a trusted
execution context T that is instantiated with the LCM protocol
160
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
Server
TEE
arbitrary length to a short, unique hash value h.
Client
invoke
(cid:17)(cid:18)
send
(cid:3)(cid:6)(cid:10)(cid:7)(cid:4)(cid:2)(cid:1)(cid:16)(cid:20)(cid:14)(cid:14)
return
(cid:19)(cid:13)(cid:20)(cid:22)(cid:15)(cid:21)
forward
(cid:9)(cid:2)(cid:8)(cid:5)(cid:11)(cid:1)(cid:16)(cid:20)(cid:14)(cid:14)
forward
(cid:3)(cid:6)(cid:10)(cid:7)(cid:4)(cid:2)(cid:1)(cid:16)(cid:20)(cid:14)(cid:14)
store
(cid:20)(cid:21)(cid:12)(cid:21)(cid:13)
send
(cid:9)(cid:2)(cid:8)(cid:5)(cid:11)(cid:1)(cid:16)(cid:20)(cid:14)(cid:14)
Process
(cid:17)(cid:18)
B. Protocol
1) Invocation at the client (Alg. 1): The client uses vari-
ables tc and ts to hold sequence numbers for the last operation
by Ci and the last operation stable among a majority, respec-
tively. In addition, the client stores hc, the hash chain value
computed by T corresponding to its most recent operation
(with sequence number tc). When Ci invokes an operation o,
it buffers o in a variable u and sends an encrypted INVOKE
message containing i, o, tc, and hc. The latter two values
represent the context in which Ci invokes o; they result from
Ci’s last operation.
2) Execution at T (Alg. 2): The trusted execution context T
maintains the sequence number of the most recently executed
operation in a counter t and a corresponding hash-chain value
in h. T processes the operations of the clients sequentially.
When T receives an INVOKE message from Ci, it decrypts the
message with kC and signals a violation if the message does
not have valid authentication. Then T veriﬁes that (tc, hc)
sent by the client correspond to the last operation response
that T has returned to Ci. For this purpose, T maintains a
map V indexed by client identiﬁer, where entry V [i] holds
the sequence number of the last acknowledged operation by
Ci, the sequence number and corresponding hash-chain value
after the last operation by Ci. Again, when an inconsistency
is detected, then T halts. This veriﬁcation is essential for
the protocol and has three goals: First, it acknowledges the
previous operation by Ci in the sense that T learns that Ci has
actually received the reply for its last invocation. Second, this
detects message-replay attacks. When a malicious S forwards
the same INVOKE message multiple times, T can easily ﬁlter
these out with V . Finally, the veriﬁcation detects rollback or
forking attacks because the client sends the condensed view
of its own history contained in tc and hc.
If sequence number and hash-chain value veriﬁcation is
successful, then T increments the sequence number t, and
calls execF , which applies the operation o to state s and yields
the corresponding result r according to F . Next, T extends
the hash chain h by setting this to hash(h(cid:4)o(cid:4)t(cid:4)i). With the
information from the INVOKE message, T also determines if
more operations have become stable. It uses the data in V and
a function majority-stable that returns q, the highest sequence
number of an operation stable among a majority.
Then T sends a REPLY message to Ci encrypted with kC,
containing the sequence number t, the hash-chain value h,
the result r, the stable operation q, and the client’s previous
hash chain value hc. Before sending REPLY, T also needs to
store the current state for recovering from a crash. For this,
T encrypts the service state s, the protocol state V , and the
key kC using auth-encrypt with kP and stores this as a blob
through S.
3) Veriﬁcation at the client: When Ci receives a REPLY
message, it uses kC to decrypt the contents and extracts t, h,
r, q, and h(cid:2)
c. The client veriﬁes that the previous hash chain
value h(cid:2)
c is equal to its own hc, in order to match the REPLY
Fig. 2. Protocol messages in Lightweight Collective Memory
and also runs F . The trusted T constructs a hash chain from
the history of all operations that it executes and embeds this
information in its responses to the clients.
A client
invokes an operation by sending an encrypted
INVOKE message to the (untrusted) server S, which forwards
all incoming messages to T . After T has decrypted this, it
ﬁrst veriﬁes that the view of the client is consistent with T ’s
own history. Then T executes the operation and assigns a
sequence number to it. The operation produces an output for
the client and may modify the state of F . The output is
returned to the client in a REPLY message, together with the
sequence number and the latest stable operation (represented
as a sequence number). When the client receives the REPLY
message, it completes the operation and returns the result, the
assigned sequence number, and the majority-stable sequence
number. The latter informs the client about the stability of its
earlier operations.
Fig. 2 shows the protocol interaction. For simplicity we
assume that each client invokes operations sequentially, that
is,
invokes a new operation only after completing the
previous operation. For protecting T against a malicious S,
three cryptographic keys are used:
it
1) To safeguard the protocol’s consistency data in the hash
chain and the service state, T encrypts it with a protocol-
state encryption key kP before storing it in the server’s
stable storage and decrypts it again after a load. This
key is generated by an admin during bootstrapping and
required for migrating T to another server.
2) A sealing key kS is initially generated by the TEE using
get-keyT,LCM when T starts. It encrypts the protocol-
state key kP when T stores this in persistent storage to
tolerate crashes.
3) A communication key kC protects all messages ex-
changed between the clients and T . The key is also
generated by an admin and made known to all clients
and to T .
All encryption operations use authenticated encryption with
a symmetric-key k and two functions auth-encrypt(m, k) and
auth-decrypt(c, k) for a message m and ciphertext c. Au-
thenticated encryption produces a ciphertext integrated with
a message-authentication code (MAC); it protects the content
from leaking information to S and prevents that S tampers
with messages or stored data by altering ciphertext. The hash
function in LCM, denoted hash(), can be any cryptographically
secure collision-free hash function; it maps a bit string x of
161
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:47 UTC from IEEE Xplore.  Restrictions apply. 
message to its most recent INVOKE. Next, Ci stores the new
sequence number and hash-chain value (t, h) and outputs the
operation result r and the majority-stable operation q. These
two sequence numbers allow the client to keep track of the
operation history. In particular, a majority of clients have
observed all operations with sequence numbers up to q. Any
operation of Ci with the sequence number t(cid:2) ≤ q is now stable
among a majority. For correct functioning of the protocol, the
state of each client must be recoverable from stable storage if a
client crashes. For simplicity this is not part of the pseudocode.
4) Server: The (correct) server S runs a TEE and hosts T ,
which is initially created by an admin. Whenever S reboots or
crashes, it restarts T . Recall that a malicious S may restart the
trusted execution context at any time or even spawn multiple
instances. Furthermore, a correct S forwards all messages
between the clients and the trusted execution context in FIFO
order. A malicious server, in contrast, can discard, reorder or
delay messages.
5) Protocol details: In the pseudocode in Alg. 1–2, the
symbol (cid:4) denotes the concatenation of bit strings, and the
assert statement, parameterized by a condition (where ∗
matches any value), immediately terminates the protocol when
the condition is false. The clients and T use this to signal that
the server misbehaved. Note that auth-decrypt may also signal
an error; this is equivalent to an assert FALSE statement.
Algorithm 1 LCM Protocol for client Ci
state
tc ∈ N0: last sequence number, initially 0
ts ∈ N0: last majority-stable sequence number, initially 0
hc ∈ {0, 1}∗
kC ∈ K: protocol key
: last hash chain value, initially hc = h0
function invoke(o)
invoke ← auth-encrypt([INVOKE, tc, hc, o, i], kC)
send message invoke to S
upon receiving message reply from S do
c] ← auth-decrypt(reply, kC)
[REPLY, t, h, r, q, h(cid:3)
assert h(cid:3)
(tc, ts, hc) ← (t, q, h)
return (r, t, q)
c = hc
// response of operation
C. Bootstrapping
Bootstrapping sets up the necessary cryptographic keys and
security contexts for trusted execution. It consists of three
phases: (1) creating a trusted execution context T on a remote
server; (2) remote attestation and provisioning of T ; and (3)
key distribution among the group of clients.
In the ﬁrst phase, a special admin client instructs the server
to create a new trusted execution context T for running
protocol LCM (Alg. 2). When T starts this protocol, it enters
init ﬁrst. Function init is also executed after a reboot, where
it ﬁrst loads the encrypted state from stable storage. During
initialization no such state exists yet.
Second, the admin initiates the remote attestation process,
to verify that T has been started correctly and is running
LCM. Remote attestation is a core function of the TEE and
Algorithm 2 LCM Protocol for trusted execution context T
state
: last hash chain value, initially h = ⊥
t ∈ N0: sequence number, initially 0
h ∈ {0, 1}∗
V : N → N0 × N0 × {0, 1}∗
s ∈ S: state of the service, initially s = s0
kS ∈ K: sealing key, initially kS = ⊥
kP ∈ K: state encryption key, initially kP = ⊥
kC ∈ K: communication encryption key, initially kC = ⊥
: current protocol state, init. [0]N
function init
kS ← get-keyT,P
(blobkey, blobstate) ← load
if blobkey = ⊥
else
perform bootstrapping as described in the text
kP ← auth-decrypt(blobkey, kS)
(s, V, kC) ← auth-decrypt(blobstate, kP )
(·, t, h) ← V [ argmax(V ) ]
// get sealing key
// possible rollback attack
upon receiving message invoke from Ci do
[INVOKE, tc, hc, o, i] ← auth-decrypt(invoke, kC)
assert V [i] = (∗, tc, hc)
t ← t + 1
(r, s) ← execF (s, o)
h ← hash(h(cid:7)o(cid:7)t(cid:7)i)
V [i] ← (tc, t, h)
q ← majority-stable(V )
blob ← auth-encrypt((s, V, kC), kseal)
store(blob)
reply ← auth-encrypt([REPLY, t, h, r, q, hc], kC)
send message reply to Ci
produces a cryptographic proof, which convinces the admin
that T indeed runs LCM. If a malicious S would instantiate T