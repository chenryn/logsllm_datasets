gered within a short time window into a single generalized
alert. We preserve the timestamp of the ﬁrst alert of the
merged sequence. We select an aggregation window of 5
seconds. Our calibration showed that this is suﬃcient to
substantially reduce the number of alerts, while further in-
creasing this window had a negligible eﬀect on the volume
of alerts. Alert bundling reduced the total number of alerts
in our data by 19%.
3.2 Alert Classiﬁcation
Our dataset includes alerts triggered from 37,388 thou-
sand unique rules. Snort rules are mainly community-contributed
and follow a loose two-level classiﬁcation scheme. Each rule
is part of a ruleset, which groups related rules. For exam-
ple, the ruleset imap.rules groups rules associated with the
IMAP protocol. The second level of classiﬁcation is based on
the class ﬁeld that is contained within each rule. The class
ﬁeld associates each rule with a unique class that provides
information regarding the intended goal of an intrusion.
For our purposes, we ﬁnd the default two-level classiﬁca-
tion scheme insuﬃcient to extract alerts that relate to at-
tacks and compromised hosts, which are the types of alerts
we are interested in. The ﬁrst shortcoming is that rules are
grouped into rulesets based on diﬀerent criteria. For exam-
ple, some rulesets, like imap.rules and voip.rules, group
rules based on the protocol or the application that is tar-
geted, while some other rulesets, like ddos.rules, groups
rules based on the type of the intrusion. A second prob-
lem is that rulesets often contain very diverse rules. For
example sql.rules contains rules that range from access-
ing a database, which could correspond to benign behavior,
to SQL worm propagation, which could indicate an infected
host. Moreover, the classes associated with the classtype
ﬁeld are scarcely documented and in some cases ambiguous.
In Table 1 we list the classes for alerts in the sql.rules
ﬁle and provide the oﬃcial documentation for each class.
Some classes are quite intuitive, for example Attempted ad-
ministrator privilege gain denotes that a privilege escalation
attack took place. However, some other classes, like Mis-
cellaneous activity, are quite cryptic and can result in loose
classiﬁcations.
To address this problem, we use a hierarchical approach
to classify the rules included in our data into three classes,
namely Attacks, Compromised hosts, and Policy violations
(similarly to [30]). In the ﬁrst step, we manually examined
all the rulesets and identiﬁed the ones that clearly character-
31Table 2: Rulesets and classtypes assigned to the Compromise class
Rulesets
Description
attack-responses.rules
Privilege escalation attempts
backdoor.rules
Trojan activity operating as Backdoor
ddos.rules
virus.rules
Bot initiating a DDoS attack
Malicious code attempting to propagate
emerging-botcc.rules
emerging-compromised.rules
emerging-user agents.rules
Bot-related trojan activity
Attacks from blacklisted IPs
Data stealing malware
emerging-virus.rules
Malicious code attempting to propagate
Classtypes
trojan-activity
Description
A network Trojan was detected
ize an attack or a compromised host. With this step we were
able to classify 72.5% of the total number of rules. For the
remaining set of rules, we used the classtype ﬁeld and iden-
tiﬁed 16 classes that can be clearly associated with attacks
or compromised host activity. Finally, for the remaining
681 rules, we manually classiﬁed them by examining the de-
tails of the signature, the assigned default priority level, the
exact byte sequence, and when possible we validated our
results with information provided in security archives and
bulletins [47, 20]. In Table 2 we summarize the rulesets and
classtypes we used for our Compromise class.
Finally, the alerts that are not classiﬁed as attacks or com-
promised hosts, mostly occur when a user does not comply
with a speciﬁc policy. Typically these alerts correspond to
P2P, VoIP, and chat related rules. We discard these rules
since they do not provide any useful information about infec-
tions. For the remaining sections, we only work with alerts
of the Attack and Compromise class.
3.3 Identifying Infections
A naive approach in identifying infections of internal hosts
is to rely on occurrences of Attack and Compromise related
alerts. However, the excessive amount of false positives,
makes it very hard to have any level of conﬁdence that we
can infer an actual infection using a single alert.
We build our heuristic to extract infections based on the
following design goals.
• Keep it simple: We opt to keep our heuristic sim-
ple as parsimony provides a number of advantages: 1)
inferences are interpretable and easier to trace and val-
idate both for a scientist and an IDS operator; and 2)
the heuristic can eﬃciently analyze large archives of
millions of IDS alerts.
• Reduce false positives: The number of false posi-
tives is involved in a fundamental trade-oﬀ with the
sensitivity of the detector. Presently, IDSs suﬀer from
a very large number of false positives. In this trade-
oﬀ, we opt to make our heuristic conservative, i.e., less
sensitive, so that the inferences it produces include a
small number of false positives. This also means that
we may incur some false negatives, which we prefer
than triggering a large number of false positives. In
order to reduce the number of false positives, we engi-
neer our heuristic to combine multiple evidence.
• Detect recurring multi-stage behavior: Pre-sently,
malware developers bundle a plethora of features and
capabilities to make their product more attractive. For
example, malware attempt to redirect users to mali-
cious websites and download additional trojans; they
update, receive instructions, share conﬁdential data,
and participate in (D)DoS attacks or spamming cam-
paigns; they attempt to propagate by scanning for
exposed nodes and by exploiting vulnerabilities, etc.
This means that most modern malware exhibit a multi-
stage network footprint. Additionally, the multi-stage
behavior is typically recurring. For example, a host in-
fected with an SQL worm, will scan for vulnerable ma-
chines running an unpatched version of the Microsoft
SQL server. Every time a target is found, the infected
host will initiate a buﬀer overﬂow attack in order to
exploit the vulnerability and eventually infect the vic-
tim. A Zeus trojan will attempt to inject fake HTML
code every time the user visits an online bank page,
in order to steal conﬁdential data. The collected de-
tails will be then delivered to databases residing in a
remote site. Based on these observations, our heuristic
attempts to reduce the number of IDS false positives
by searching for malware that exhibit a recurring mul-
tistage behavior.
• Focus on extrusion detection: Our heuristic aims
at detecting hosts within an organization that are al-
ready infected. It does not try to proactively prevent
an infection.
Detection Heuristic: Our approach aims at detecting a
recurring multi-stage footprint generated by infected hosts.
In the simplest case, a multi-stage footprint resolves into
tuples of strongly correlated alerts. Such tuples capture dif-
ferent actions undertaken by an infected host that occur
frequently and consistently over time, increasing our cer-
tainty that an actual infection has indeed occured. We use
an entropy-based information-theoretic criterion to detect
signiﬁcant tuples of alerts.
Our input data is a time series of alerts, where each alert
is identiﬁed by the following ﬁve ﬁelds: . We examine each internal host sepa-
rately, discretize its sequence of alerts into time windows of
length T , and mine for tuples of the type: if alert X occurs,
then alert Y occurs within the time window T . We denote
the above tuple with X ⇒ Y . Each tuple is associated with
a frequency and a conﬁdence, where the frequency is the
normalized number of occurrences of the ﬁrst alert X and
the conﬁdence is the fraction of occurrences that alert X
32is followed by alert Y within T . A well-known measure of
tuple signiﬁcance that combines these two basic metrics and
enables to rank tuples is the J-Measure [46] (for an overview
of tuple ranking methods refer to [40]):
Algorithm 1 Pseudo-code of our heuristic for detecting in-
fections
Require: Set L of alerts triggered by internal hosts
Ensure: Signiﬁcant tuples Si for internal node i
J-Measure(Y ; X) = P (X)(P (Y |X)log(
P ( ¯Y |X)log(
P (Y |X)
P (Y )
P ( ¯Y |X)
P ( ¯Y )
)+
)),
where P (X) is the probability that alert X occurs; P (Y ) is
the probability of at least one Y occurring at a randomly
chosen window; P (Y |X) is the probability that alert X is
followed by at least one alert Y within T ; and ¯Y denotes the
event that Y does not occur. Intuitively, the ﬁrst term P (X)
captures the frequency of X, while the second term is the
well-known cross-entropy and captures the average mutual
information between the random variables X and Y . In this
way, the J-Measure ranks tuples in a way that balances the
trade-oﬀ between frequency and conﬁdence.
The cross-entropy between X and Y drops when the two
events tend to occur together. In particular, there are two
cases when the corresponding entropy of Y drops. When X
happens, Y always happens, or it doesn’t ever happen. Clearly,
the ﬁrst case is of interest to us, since it reﬂects the probabil-
ity of the two alerts co-occurring in a speciﬁc time window
T . The second case is irrelevant since there will always be
numerous alerts that do not occur when a speciﬁc alert hap-
pens, resulting in an inﬂated J-Measure value. Therefore,
we only keep the left term of the cross-entropy to evaluate
the signiﬁcance of a tuple.
1
One desirable characteristic of the J-Measure is its limit-
ing properties. Its value ranges from 0, when random vari-
ables X and Y are independent, to
P (Y ) , when they are
completely dependent, which facilitates the process of deﬁn-
ing a threshold above which tuples are considered signiﬁcant.
An internal host that produces at least one signiﬁcant tuple
is considered infected. We ﬁne-tune the threshold to 0.85
P (Y ) as
described in Section 4.4 using validated infections from our
most reliable source, which is security tickets about infected
and remediated systems by our security group. From the
set of signiﬁcant tuples we can easily extract the infection
timestamps. For each tuple X ⇒ Y , if there is no other tu-
ple Z ⇒ W involving the same internal host within a time
window Tinf , then this is a new infection at the timestamp
of alert X. Otherwise, this is an ongoing infection and we
ignore the corresponding tuple.
In Algorithm 1 we show the pseudo-code of our heuristic.
Its complexity is O(n2), where n is the number of unique
alerts triggered by an internal node during T . In our experi-
ments n is quite low and on average equal to 3.1. To run our
heuristic on one day of data takes on average 19.3 minutes
on a system running Debian Etch with a 2GHz Quad-Core
AMD Opteron.
Parameter Tuning: For the window size T we conserva-
tively select one hour, since most alerts related to the same
infection in our data occur within minutes. Selecting a larger
window has negligible impact on the results. Moreover, we
consider that a host is re-infected if the host is active in our
dataset, but for a period of Tinf it is not detected as infected
by our heuristic. We set the Tinf threshold to two weeks.
We select this value in a conservative way based on two ob-
servations. Incidents identiﬁed and investigated in the past
for all internal nodes i do
for all hourly timebins Tk do
for all tuples (Ai, Bi) in L, triggered in Tk, where
Ai 6= Bi do
if Ai ⇒ Bi in candidate tuple set Ri then
Ri.UpdateTupleStats(Ai ⇒ Bi)
else
Ri.AddTuple(Ai ⇒ Bi)
end if
end for
end for
for all tuples Mi ⇒ Ni in Ri do
if J-Measure(Mi ⇒ Ni) > Jthresh then
Si.AddTuple( Mi ⇒ Ni )
end if
end for
end for
in our infrastructure suggest that the worst case delay re-
quired by our security group to ﬁx a reported problem is
approximately one week. This time frame covers the stages
of threat identiﬁcation, threat assessment, and remediation
of the host either by completely removing the malware or
by rebuilding the entire system. On the other hand it is
known, that some malware infections stay dormant for pre-
deﬁned time periods or wait for an external command to
trigger their behavior [4]. In this case, the host will be re-
ported as benign by our heuristic, since no network trace
of malicious activity is being generated. However, after the
initial stimulus and assuming that the malicious behavior
has been manifested, it is highly unlikely that the malware
will fall again into idle mode for a time period longer than
Tinf [44]. Out of the total infections we ﬁnd in our charac-
terization, 4.9% are re-infections.
4. VALIDATING INFECTIONS
In this section we present the process we follow to validate
inferred infections and to assess the false positive rate of our
heuristic. Remotely validating several suspected infections
on unmanaged hosts within a production infrastructure is
a very challenging problem that to the best of our knowl-
edge has not been previously addressed in the literature. A
ﬁrst challenge is that typically no single tool or information
source provides suﬃcient evidence that an actual security
incident has occurred. A second challenge is that the types
of malicious behaviors we examine are diverse, ranging from
multi-stage attacks and worm propagation events to com-
plex trojan and malware communication patterns.
Our validation follows a three step process as shown in
Figure 3. Given a suspected infection, we ﬁrst extract useful
information from six security-related independent informa-
tion sources about the infected host and the remote hosts it
communicates. We refer to this information as evidence. A
collection of evidence about suspected infections is passed
in real-time (e.g., within a day of the ﬁrst time an infection
was detected) to a security expert. The expert correlates
the expected behavior of the malware with the collected ev-
idence. If all the evidence agree with the expected behavior,
33then a positive assessment is made about the suspected in-
fection, otherwise it is concluded that the infection could
not be validated, i.e., it is unknown if the suspected host is
indeed infected or not. We conservatively consider the latter
a false positive.
IDS Data
Repository
Blacklists
Database
Retrieve alerts related  to infection
[**] ET DROP Known Bot C&C Server Traffic
[Classification: Network Trojan detected]  
129.132.128.XXX:18859 -> 204.74.YYY.YY:53
Are involved IPs blacklisted?
spamhaus.org       204.74.YYY.YY    MISS
urlblacklist.com    204.74.YYY.YY   HIT
Query Google for information
regarding involved hosts
204.74.YYY.YY   Frequent Tags
‘botnet’,’irc server’,’trojan’,’malicious’
What is the reputation of 
contacted domains?
ThreatExpert record 204.74.YYY.YY
IRC channel used by Mal/VB-G trojan
Active scanning and
vulnerability enumeration
DCOM RPC running , vulnerability MS03-026
Figure 3: Validation Process
Validated 
Infections
This process is very demanding and time consuming for
the analyst, therefore, we limit ourselves to a subset of the
reported infections. Speciﬁcally, we analyze 200 consecutive
incidents that were reported by our heuristic and validate
the existence or absence of a variety of malware types. Al-
though, this sample of infections is rather small compared
to the total number of infections we report, the analyzed
nodes are diverse spanning from servers, to desktop PCs in
oﬃces and wireless guests in labs and social areas. Also, the
malicious software we investigate is quite diverse and can be
categorized based on its goals and propagation methods into
the following classes [37]:
• backdoors/bots allow an external entity to remotely
control an infected machine.
• trojans masquerade as benign programs, but clandes-
tinely perform illegal actions, such as information leak-
age and url -redirection.
• worms are self-replicating and propagating programs
that attach themselves to processes or ﬁles making
them carriers of a malicious behavior.
• spyware are useful pieces of software that are bundled
with some hidden fraudulent activity.
4.1 Information Sources
IDS Alerts: For infected nodes we examine the relevant
IDS alerts we have collected. We focus on alerts that are