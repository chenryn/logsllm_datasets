title:On the Impact of Bursting on TCP Performance
author:Ethan Blanton and
Mark Allman
On the Impact of Bursting on TCP Performance
Ethan Blanton1 and Mark Allman2
1 Purdue University
PI:EMAIL
2 ICSI/ICIR
PI:EMAIL
Abstract. Periodically in the transport protocol research community,
the idea of introducing a burst mitigation strategy is voiced. In this paper
we assess the prevalence and implications of bursts in the context of
real TCP traﬃc in order to better inform a decision on whether TCP’s
congestion control algorithms need to incorporate some form of burst
suppression. After analyzing traﬃc from three networks, we ﬁnd that
bursts are fairly rare and only large bursts (of hundreds of segments)
cause loss in practice.
1
Introduction
Within the transport protocol research community, an idea that crops up peri-
odically is that of introducing bursting mitigation into the standard congestion
control algorithms. Transport protocols can naturally send line-rate bursts of
segments for a number of reasons (as sketched below). Studies have shown that
these line-rate bursts can cause performance problems by inducing a rapid build-
up of queued segments at a bottleneck link, and ultimately dropped segments
and a reduced transmission rate when the queue is exhausted.
In this paper we focus on the study of micro-bursts and exclude macro-
bursts from consideration. A micro-burst is a group of segments transmitted at
line rate in response to a single event (usually the receipt of an acknowledg-
ment). A macro-burst, on the other hand, can stretch across larger time scales.
For instance, while using the slow start algorithm [APS99], TCP1 increases the
congestion window (and therefore the transmission rate) exponentially from one
round-trip to the next. This is an increase in the macro-burstiness of the connec-
tion. The micro-burstiness, however, is unaﬀected as TCP sends approximately
2–3 segments per received acknowledgment (ACK) throughout slow start (de-
pending on whether the receiver employs delayed ACKs [Bra89, APS99]).
An example of naturally occurring bursting behavior is given in [Hay97],
which shows that TCP connections over long-delay satellite links with adver-
tised windows precisely tuned to the appropriate size for the delay and band-
width of the network path suﬀer from burst-induced congestion when loss occurs.
1 The measurements and discussions presented in this paper are in terms of TCP, but
also apply to SCTP [SXM+00] and DCCP’s [KHF04] CCID 2 [FK04], since they use
similar congestion control techniques.
C. Dovrolis (Ed.): PAM 2005, LNCS 3431, pp. 1–12, 2005.
c(cid:1) Springer-Verlag Berlin Heidelberg 2005
2
E. Blanton and M. Allman
Ideally, a TCP connection is able to send both retransmissions and new data
segments during a loss recovery phase [FF96]. However, if there is no room in
the advertised window, new segments cannot be sent during loss recovery. Upon
exiting loss recovery (via a large cumulative ACK), TCP’s window will slide
and a line-rate burst of segments will be transmitted. [Hay97] shows that this
burst — which is roughly half the size of the congestion window before loss —
can result in an overwhelmed queue at the bottleneck link, causing further loss
and additional performance sacriﬁce. [Hay97] also shows this bursting situation
to apply to a number of TCP variants (Reno [APS99], NewReno [Hoe96, FF96],
FACK [MM96], etc.). Finally, [Hay97] shows that bursts can impact TCP per-
formance, but the experiments outlined are lab-based and oﬀer no insight into
how often the given situation arises in the Internet. In this paper we assess the
degree to which these micro-bursting situations arise in the wild in an attempt
to inform a decision as to whether TCP should mitigate micro-bursting. While
out of scope for this paper we note that [AB04] compares a number of burst
mitigation techniques. In addition to advertised window constraints discussed
above, micro-bursts can be caused by several other conditions, including (but
not limited to):
– ACK loss. TCP uses a cumulative acknowledgment mechanism that is ro-
bust to ACK loss. However, ACK loss causes TCP’s window to slide by a
greater amount with less frequency, potentially triggering longer than desired
bursts in the process.
– Application Layer Dynamics. Ultimately, the application provides TCP
with a stream of data to transmit. If the application (for whatever reason)
provides the data to TCP in a bursty fashion then TCP may well transmit
micro-bursts into the network. Note: an operating system’s socket buﬀer
provides a mechanism that can absorb and smooth out some amount of
application burstiness, especially in bulk transfer applications. However, the
socket buﬀer does not always help in applications that asynchronously obtain
data to send over the network.
– ACK Reordering. Reordered ACKs2 cause an ACK stream that appears
similar to a stream containing ACK loss. If a cumulative ACK “passes”
ACKs transmitted earlier by the endpoint, then the later ACK (which now
arrives earlier) triggers the transmission of a micro-burst, while the earlier
ACKs (arriving later) will be thrown away as “stale”.
The causes of bursting discussed above are outlined in more detail in [JD03] and
[AB04]. Also note that the causes of bursts are not TCP variant speciﬁc, but
rather apply to all common TCP versions (Reno, NewReno, SACK, etc.).
[JD03] also illustrates the impact of micro- and macro-bursts on aggregate
network traﬃc. In particular, [JD03] ﬁnds that these source-level bursts create
2 Reordered data segments can also cause small amounts of bursting, if the reordering
is modest. However, if the reordering is too egregious then false loss recovery will be
induced, which is a diﬀerent problem from bursting. For a discussion of the issues
caused by data segment reordering, see [BA02, ZKFP03].
On the Impact of Bursting on TCP Performance
3
scaling in short timescales and can cause increased queuing delays in interme-
diate nodes along a network path. In contrast, in this paper we concentrate on
characterizing bursts and determine the frequency of bursts. We then use the
analyzed data to inform a discussion on whether it behooves TCP to prevent
bursts from a performance standpoint, as proposed in the literature (e.g., in
[FF96, HTH01]).
We oﬀer several contributions in this paper after outlining our measurement
methodology in § 2. First, we characterize observed, naturally occurring micro-
bursts from three networks in § 3. Next, we investigate the implications of the
observed micro-bursts in § 4. Finally, in § 5 we conclude with some preliminary
discussion into the meaning of the results from § 3 and § 4 as they relate to
the question of whether a burst mitigation mechanism should be introduced
into TCP.
2 Measurement Methodology
First, we deﬁne a “burst” for the remainder of the paper as a sequence of at
least 4 segments sent between two successive ACKs (i.e., a “micro-burst”). The
“magic number” of 4 segments comes from the speciﬁcation of TCP’s congestion
control algorithms [APS99]. On each ACK during slow start, and roughly once
every 1–2 round-trip times (RTT) in congestion avoidance, TCP’s algorithms
call for the transmission of 2–3 segments at line-rate. Therefore, micro-bursts of
3 or fewer segments have been deemed reasonable in ideal TCP and are common
in the network. We consider bursts of more than 3 segments to be “unexpected”,
in that they are caused by network and application dynamics rather than the
speciﬁcation of the congestion control algorithms. That is not to say that TCP is
in violation of the congestion control speciﬁcation in these circumstances — just
that outside dynamics have caused TCP to deviate from the envisioned sending
pattern. These unexpected bursts are the impetus for the various proposals to
mitigate TCP’s burstiness, and therefore they are the focus of our study. We do
note that [AFP02] allows TCP to transmit an initial 4 segment burst when the
maximum segment size is less than 1096 bytes. However, this is not taken into
account in our deﬁnition of a burst since it is a one-time only allowance.
In principle, the above deﬁnition of a burst is sound. However, in analyzing
the data we found a signiﬁcant vantage point problem in simply using the number
of segments that arrive between two successive ACKs. As shown in [Pax97] there
is a general problem in TCP analysis with matching particular ACKs with the
packets they liberate — even when the monitoring point is the end host involved
in the TCP connection. However, when the monitoring point is not the end
host the problem is exacerbated. Table 1 illustrates the problem by showing
the diﬀerent order of events observed inside the TCP stack of the end host
and at our monitor point. In the second column of this example, two ACKs
arrive at the end host and each trigger the transmission of two data segments,
as dictated by TCP’s sliding window mechanism. However, the third column
shows a diﬀerent (and frequently observed) story from the monitor’s vantage
4
E. Blanton and M. Allman
Table 1. Example of vantage point problem present in our datasets
Event Number End Host Monitor
ACKn+1
ACKn+2
DAT Am+1
DAT Am+2
DAT Am+3
DAT Am+4
ACKn+1
DAT Am+1
DAT Am+2
ACKn+2
DAT Am+3
DAT Am+4
0
1
2
3
4
5
point. In this case, the monitor observes both ACKs before observing any of
the data segments and subsequently notes all four data segments transmitted.
Using the notion sketched above, these four data segments would be recorded as
a burst when in fact they were not. This scenario can, for example, be caused by
ACK compression [Mog92]. If the ACKs are compressed before the monitor such
that they arrive within t seconds, where t is less than the round-trip time (RTT)
between the monitor and the end host, r, then the situation illustrated in table 1
will be found in the traces. An even thornier problem occurs when a group of
compressed ACKs arrives over an interval a bit longer than r. In this case, the
overlap between noting ACKs and data packets makes it nearly impossible to
untangle the characteristics of the bursts (or, even their presence).
We cope with this problem by accumulating the ACK information. For in-
stance, in table 1 since two ACKs without any subsequent data segments are
recorded our analysis allows up to 6 data segments to be sent before determining
a burst occurred. This heuristic does not always work. For instance, if 6 data
segments were observed between two subsequent ACKs in a trace ﬁle there is no
way to conclusively determine that 3 data segments were sent per ACK. The case
when the ﬁrst ACK triggered 2 data segments and the second ACK triggered
4 data segments (a burst) is completely obfuscated by this heuristic. Another
problem is that ACKs could conceivably be lost between the monitor and the
end host which would likewise cause the analysis to mis-estimate the bursting
characteristic present on the network. In our analysis, if we note more than 3N
segments sent in response to N ACKs we determine a burst has been trans-
mitted. The length of this burst is simply recorded as the number of segments
noted. In other words, we do not attempt to ascribe some of the data segments
to each ACK. This is surely an overestimate of the size of the burst. However,
as will be shown in the following sections, this small vantage point problem is
unlikely to greatly impact the results because the results show that the diﬀer-
ence between bursts of size M and bursts of size M ± x for some small value of
x (e.g., 1–10) is negligible. Therefore, while the numbers reported in this paper
are slight mis-estimates of the true picture of bursting in the network we believe
the insights are solid.
To assess the prevalence and impact of micro-bursting, we gathered four sets
of packet traces from three diﬀerent networks. We analyze those connections
involving web servers on the enterprise network. That is, we focus on local web
On the Impact of Bursting on TCP Performance
5
Table 2. Dataset characteristics
Dataset Start Duration Servers Clients (/24s) Conns. Bogus
7/24/03 ≈26 hours
Anon
LBN L 10/22/03 ≈11 hours
1/4/04 ≈14 days
ICSI1
9/18/04 ≈14 days
ICSI2
295,019 5,955 (2.0%)
5,319 (4,541)
22,788 (19,689) 196,085 2,362 (1.2%)
24,752 (21,571) 223,906 221 (0.1%)
23,956 (20,874) 198,935 114 (0.1%)
1,202
947
1
1
servers’ sending patterns, rather than the sending patterns of remote servers
that are responding to local web clients’ requests. The characteristics of the four
trace ﬁles used in our study are given in table 2. The ﬁrst trace, denoted Anon,
consists of roughly 26 hours of web traﬃc recorded near web servers at a biology-
related research facility that asked not to be identiﬁed. The tracing architecture
is, however, outlined in [MHK+03]. The second trace represents roughly 11 hours
of web server traﬃc at the Lawrence Berkeley National Laboratory (LBNL) in
Berkeley, CA, USA. The ﬁnal two datasets represent requests to a single web
server at the International Computer Science Institute (ICSI), also in Berkeley,
during two diﬀerent two week periods in 2004.
These packet traces are analyzed with a custom-written tool called conninfo,
which analyzes the data-carrying segments sent by web servers on the enterprise
network. Conninfo mainly tracks the number of data segments sent between two
subsequent pure acknowledgment (ACK) segments as sketched above. In addi-
tion to recording micro-burst sizes, conninfo also records which (if any) segments
within a burst are retransmitted. Finally, conninfo records several ancillary met-
rics such as the total data transfer size, the duration of the connection, etc.
Conninfo attempts to process each connection in the dataset. However, as
indicated in the last column of table 2, a small fraction of connections were
removed from each dataset. These connections exhibit strange behavior that
conninfo either does not or cannot understand; for example, several “connec-
tions” (which are perhaps some sort of attack or network probe) consist of a
few random data segments with noncontiguous sequence numbers. As the table
shows, the fraction of connections removed from further analysis is relatively
small and, therefore, we do not believe this winnowing of the datasets biases the
overall results presented in this paper.
3 Characterizing Bursts
In this section we provide a characterization of the bursts observed in the traces
we studied. Figure 1 shows the distributions of burst sizes in each of the datasets
in terms of both segments, bytes and time. Figure 1(a) shows that the distri-
bution of burst sizes when measured in terms of segments is similar across all
datasets. In addition, the ﬁgure shows that over 90% of the bursts are less than
15 segments in length. Figure 1(b) shows the burst size in terms of bytes per
burst. This distribution generally follows from the segment-based distribution if
1500 byte segments are assumed. While the LBNL and ICSI datasets are similar
6
E. Blanton and M. Allman
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
F
D
C
F
D
C
F
D
C
Anon
LBNL
ICSI1
ICSI2
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
 50
Burst length (segments)
(a) Segments
Anon
LBNL
ICSI1
ICSI2
 0
 5000  10000  15000  20000  25000  30000  35000
Burst length (bytes)
(b) Bytes
Anon
LBNL
ICSI1
ICSI2
 0.0001
 0.001
 0.01
Burst length (seconds)
 0.1
 1
 0
 1e-06
 1e-05
(c) Time
Fig. 1. Distribution of burst sizes
On the Impact of Bursting on TCP Performance
7
in terms of byte-based burst size, the Anon distribution indicates smaller bursts.
Since we did not observe smaller bursts in the Anon dataset when measuring in
terms of segments, it appears that the segment sizes used in the Anon network
are generally smaller than at LBNL and ICSI. We generated packet size distri-
butions for all networks and there is a clear mode of 20% in the Anon dataset
at 576 bytes that is not present in either the ICSI or LBNL datasets. Other-
wise, the distributions of packet sizes are roughly the same, thus explaining the
discrepancy in ﬁgure 1.
Figure 1(c) shows the distribution of the amount of elapsed time covered by
each burst. This plot conﬁrms that the vast majority of bursts happen within a
short (less than 10 msec) window of time. This is essentially a double-check that
our methodology of checking data between subsequent ACKs and our analysis
tool are both working as envisioned. While we found bursts that encompass a
fairly long period of time (over a second) these are the exception rather than
the rule and upon close examination of the time-sequence plots these look to
be artifacts of network dynamics mixing with application sending patterns that
are diﬃcult to systematically detect. Therefore, we believe that our analysis
techniques are overall sound.
F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Anon
LBNL
ICSI1
ICSI2
 0
 2
 4
 6
 8
 10
Bursts per connection
Fig. 2. Distribution of bursts per connection
Next we turn our attention to the prevalence of bursts. Figure 2 shows the
distribution of the number of bursts per connection in our four datasets. The
ﬁgure shows that the burst prevalence is roughly the same across datasets. As
shown, over 75% of the connections across all the datasets experienced no bursts
of 4 or more segments. However, note that many of the connections that did not
burst could not because of the limited amount of data sent or because TCP’s
congestion window never opened far enough to allow 4 or more segments to be
transmitted.
Next we look beyond the on-the-wire nature of bursts and attempt to deter-