                                                                  QUERY PLAN                                                                    
----------------------------------------------------------------------------------------------------------------------------------------------  
 Function Scan on pg_catalog.generate_series n  (cost=14425.00..14447.50 rows=1000 width=1) (actual time=233.871..446.120 rows=10000 loops=1)  
   Output: (n.n = ANY ($0))  
   Function Call: generate_series(1, 10000)  
   Buffers: shared hit=4425, temp read=19 written=18  
   InitPlan 1 (returns $0)  
     ->  Seq Scan on public.t  (cost=0.00..14425.00 rows=1000000 width=4) (actual time=0.014..119.976 rows=1000000 loops=1)  
           Output: t.id  
           Buffers: shared hit=4425  
 Planning time: 0.085 ms  
 Execution time: 447.666 ms  
(10 rows)  
```  
4、exists, work_mem需求量较少(exists由于优化器在匹配到1条后即刻返回，所以会选择使用索引，性能就非常好。)  
```  
postgres=# set work_mem ='64kB';  
SET  
postgres=# explain (analyze,verbose,timing,costs,buffers) select exists (select 1 from t where t.id=n.n) from generate_series(1,10000) as n;  
                                                              QUERY PLAN                                                                
--------------------------------------------------------------------------------------------------------------------------------------  
 Function Scan on pg_catalog.generate_series n  (cost=0.00..2852.50 rows=1000 width=1) (actual time=1.172..18.893 rows=10000 loops=1)  
   Output: (SubPlan 1)  
   Function Call: generate_series(1, 10000)  
   Buffers: shared hit=40027, temp read=19 written=18  
   SubPlan 1  
     ->  Index Only Scan using idx_t_1 on public.t  (cost=0.42..2.84 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=10000)  
           Index Cond: (t.id = n.n)  
           Heap Fetches: 10000  
           Buffers: shared hit=40027  
 Planning time: 0.118 ms  
 Execution time: 19.902 ms  
(11 rows)  
postgres=# set work_mem ='64MB';  
SET  
postgres=# explain (analyze,verbose,timing,costs,buffers) select exists (select 1 from t where t.id=n.n) from generate_series(1,10000) as n;  
                                                              QUERY PLAN                                                                
--------------------------------------------------------------------------------------------------------------------------------------  
 Function Scan on pg_catalog.generate_series n  (cost=0.00..2852.50 rows=1000 width=1) (actual time=0.642..17.635 rows=10000 loops=1)  
   Output: (alternatives: SubPlan 1 or hashed SubPlan 2)  
   Function Call: generate_series(1, 10000)  
   Buffers: shared hit=40027  
   SubPlan 1  
     ->  Index Only Scan using idx_t_1 on public.t  (cost=0.42..2.84 rows=1 width=0) (actual time=0.001..0.001 rows=1 loops=10000)  
           Index Cond: (t.id = n.n)  
           Heap Fetches: 10000  
           Buffers: shared hit=40027  
   SubPlan 2  
     ->  Seq Scan on public.t t_1  (cost=0.00..14425.00 rows=1000000 width=4) (never executed)  
           Output: t_1.id  
 Planning time: 0.129 ms  
 Execution time: 18.612 ms  
(14 rows)  
```  
5、如果把索引干掉，exists性能就会下降了，同时性能也和是否使用哈希表有关。  
```  
postgres=# drop index idx_t_1;  
postgres=# set work_mem ='64kB';  
SET  
postgres=# explain (analyze,verbose,timing,costs,buffers) select exists (select 1 from t where t.id=n.n) from generate_series(1,10000) as n;  
                                                                 QUERY PLAN                                                                   
--------------------------------------------------------------------------------------------------------------------------------------------  
 Function Scan on pg_catalog.generate_series n  (cost=0.00..16925010.00 rows=1000 width=1) (actual time=1.072..3036.590 rows=10000 loops=1)  
   Output: (SubPlan 1)  
   Function Call: generate_series(1, 10000)  
   Buffers: shared hit=226260, temp read=19 written=18  
   SubPlan 1  
     ->  Seq Scan on public.t  (cost=0.00..16925.00 rows=1 width=0) (actual time=0.303..0.303 rows=1 loops=10000)  
           Filter: (t.id = n.n)  
           Rows Removed by Filter: 5000  
           Buffers: shared hit=226260  
 Planning time: 0.087 ms  
 Execution time: 3037.904 ms  
(11 rows)  
postgres=# set work_mem ='64MB';  
SET  
postgres=# explain (analyze,verbose,timing,costs,buffers) select exists (select 1 from t where t.id=n.n) from generate_series(1,10000) as n;  
                                                                 QUERY PLAN                                                                    
---------------------------------------------------------------------------------------------------------------------------------------------  
 Function Scan on pg_catalog.generate_series n  (cost=0.00..16925010.00 rows=1000 width=1) (actual time=517.150..521.142 rows=10000 loops=1)  
   Output: (alternatives: SubPlan 1 or hashed SubPlan 2)  
   Function Call: generate_series(1, 10000)  
   Buffers: shared hit=4425  
   SubPlan 1  
     ->  Seq Scan on public.t  (cost=0.00..16925.00 rows=1 width=0) (never executed)  
           Filter: (t.id = n.n)  
   SubPlan 2  
     ->  Seq Scan on public.t t_1  (cost=0.00..14425.00 rows=1000000 width=4) (actual time=0.027..127.111 rows=1000000 loops=1)  
           Output: t_1.id  
           Buffers: shared hit=4425  
 Planning time: 0.098 ms  
 Execution time: 527.986 ms  
(13 rows)  
```  
## 小结  
1、使用= any的写法，不会走subplan，因此不涉及hash table的问题。和work_mem设置大小无关。性能比较暴力，特别是当它不是在subquery里面时，性能贼好。  
很多场景都可以使用，例如update limit, delete limit(阅后即焚），又或者就是简单的IN查询需求。  
```  
delete from tbl where ctid = any(array( select ctid from tbl where xxx limit xxx ));  
update tbl set xxx=xxx where ctid = any(array( select ctid from tbl where xxx limit xxx ));  
select * from tbl where id = any (array( query.... ));  
```  
推荐指数，五星。  
2、exists，由于优化器会默认它只需要搜索到1条命中目标就不搜了，所以优化器评估是否使用hash table时，需要的内存相对较少，即使较小的work_mem也可能使用hashtable。  
推荐指数，四星。  
3、in ()，当出现在subquery中时，优化器评估这个subquery是否要构建哈希TABLE，直接和subquery的大小相关，所以需要较大的work_mem才会选择使用hashtable。  
推荐指数，三星。  
最后，由于这些SQL语义都相同，在内核优化时，可以考虑做一些QUERY REWRITE，来优化这样的SQL。  
这样的话，用户可以不改SQL，就达到提高效率的目的。  
感谢为此付出努力的所有PostgreSQL内核开发的小伙伴们。  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")