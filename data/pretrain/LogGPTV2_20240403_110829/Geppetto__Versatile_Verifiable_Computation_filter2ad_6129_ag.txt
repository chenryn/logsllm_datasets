degree by one, so with Geppetto, the degree only increases by
∼0.03/byte, a savings of 375×. Even if we want to operate on
32-bit values, instead of full ﬁeld elements, Geppetto only costs
0.25/byte, a savings of 45×.
At a macro level, for MapReduce, Pantry and Geppetto share
the same costs for proving that the core mapper and reducer
computations were performed correctly; on top of that, to han-
dle state transferred between mappers and reducers, Pantry
proves the correctness of 2M· R hashes (since both the mappers
and the reducers must prove they hashed the state correctly),
while Geppetto proves the correctness of M · R bus digests. As
a result, Geppetto’s keys end up being a bit smaller; Geppetto’s
266266
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:17 UTC from IEEE Xplore.  Restrictions apply. 
Geppetto
Pantry
Geppetto
Pantry
Geppetto
Pantry
Geppetto
Pantry
MR: Dot product
(m = 10K)
MR: Dot product
(m = 160K)
MR: Nucleotide substring
(m = 6K,d = 10)
MR: Nucleotide substring
(m = 60K,d = 32)
Loop: Matrix exponentiation Geppetto
(n = 10,e = 40)
Loop: Matrix exponentiation Geppetto
(n = 20,e = 40)
Pantry
Pantry
QAP Degree
10K
1.1M (103×)
161K
16.8M (104×)
1K
98K (84×)
26K
327K (13×)
8K
32K (4.0×)
37K
131K (3.5×)
KeyGen
5s
(114×)
643s
49s
14130s† (283×)
0.7s
(55×)
39s
21s
(7×)
155s
5s
(3.1×)
15s
15s
(3.5×)
54s
Prover
Veriﬁer
Baseline
3s
(1169×)
3696s
53s
22187s† (412×)
1s
(72×)
126s
43s
(21×)
909s
51s
(8×)
405s
253s
(6×)
1463s
10ms
58ms
10ms
58ms†
36ms
58ms
35ms
58ms
411ms
211ms
421ms
211ms
(5.8×)
(5.8×)
(1.6×)
(1.7×)
(0.5×)
(0.5×)
0.5ms
6.3ms
0.2ms
0.3ms
0.9ms
1.1ms
Figure 7: Apps with Shared State. For MapReduce (MR) apps, we give per-mapper statistics. For Loop, we consider the entire computation.
These apps do not use bootstrapping. Parenthetical values show Pantry’s relative overhead. Entries with † indicate simulated Pantry values.
keys save further relative to Pantry, as Pantry needs key mate-
rial for R hashes for each mapper and M hashes for each reducer,
while Geppetto only needs max(M,R) shared buses (§6.2).
A na¨ıve alternative to MultiQAPs and hashing is to build one
gigantic Pinocchio QAP, so that the shared state becomes sim-
ply internal circuit wires. However, our experiments quickly
showed the futility of this approach; even for the relatively
modest applications shown in Figure 7 and assuming only 10
mappers, this approach would require a QAP with a degree of
10M+, while the Pinocchio prover keels over (i.e., begins swap-
ping) before it can reach 3M on a 16 GB machine.
7.2.1 Applications
To measure the end-to-end effect of MultiQAPs, we evaluate
Geppetto on the following applications. We compare Gep-
petto’s results against Pantry’s implementation running on the
same hardware, except when Pantry runs out of memory, in
which case we use Pantry’s validated cost model [16]. We bor-
row the ﬁrst two examples from Pantry [16] to give a direct com-
parison with their work. We adopt Pantry’s ratio of 10 mappers
to 1 reducer, and we use their extension of Pinocchio to ensure
an apples-to-apples comparison.
MapReduce: Dot Product [16] The veriﬁer speciﬁes (in
Pantry via hash, in Geppetto via a digest) two vectors of in-
tegers; each mapper receives m integers and computes a partial
dot product, and the reducer sums the mapper outputs.
MapReduce: Nucleotide Substring Search [16] The veri-
ﬁer speciﬁes a DNA string that is divided amongst the mappers,
each receiving m nucleotides. The mapper then searches for
dynamically supplied length-d substrings reporting a match (if
any) to the reducer which combines the matches.
Loop: Matrix Exponentiation The veriﬁer supplies a dy-
namically chosen n × n matrix M and an exponent e, and the
prover returns Me. Matrix exponentiation is useful for many
applications, e.g., to compute the width of a graph represented
as an adjacency matrix [52].
This example shows the beneﬁts of intertwined MultiQAPs.
With Pinocchio, the QAP would scale with e, limiting the size of
the problem, whereas, with MultiQAPs, we only need to com-
pile the loop body (after some loop unfolding), which can then
be used for arbitrary values of e. With Pantry, the loop body
needs to hash a matrix on the way in and again on the way out,
whereas MultiQAPs incur a handful of crypto operations per
intermediate state generated.
7.2.2 MultiQAP Results
Figure 7 summarizes the impact of using MultiQAPs for shared
state. The results only show CPU costs and do not include net-
work latency or bandwidth, though the latter is unlikely to be
a problem for either Pantry or Geppetto, given that proofs and
digests are only a few hundred bytes each.
For MapReduce, we see the largest discrepancy between
Geppetto and Pantry on the dot-product app. For this app, the
QAP for the computation itself is quite simple, so for Pantry,
the cost of hashing dwarfs the cost of the computation. For the
nucleotide app, the shared state is still a dominant portion of the
calculation for Pantry (though not as dominant as in dot prod-
uct), and hence Geppetto maintains a wide margin.
For the Loop application, the QAP for the computation itself
is non-trivial and grows faster than the IO between loop itera-
tions; thus, the cost of state sharing relative to the computation
is lower than for dot product, and the ratio drops further for
larger matrices. Since Geppetto and Pantry generate essentially
the same QAP for the computation itself, Geppetto’s relative
advantage drops accordingly.
7.3 Verifying Cryptography and Bootstrapping
In §5, we claimed that embedding cryptographic operations
without matching ﬁeld sizes was exorbitantly expensive. To
validate this claim, we combined data from a basic ECC pairing
operation coded in Magma with cost models from Pinocchio
267267
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:17 UTC from IEEE Xplore.  Restrictions apply. 
for various operations such as bit splitting. Our calculations es-
timate that the pairing alone would require a QAP with degree
of 44 million.
Fortunately, our choice of matching curves in §5 brings this
cost down signiﬁcantly. For example, a pairing only requires a
QAP of degree 14K, an improvement of 3100× vs. the na¨ıve
approach, while an exponentiation, i.e., gx, increases the degree
by ∼60 per bit in x.
Furthermore, as discussed in §5, for a comparable security
level, our initial curves for bounded bootstrapping provide ap-
proximately 34-77× better performance than curves supporting
unbounded bootstrapping [9]. As §7.1 shows, however, perfor-
mance degrades with each level added, and hence will eventu-
ally reach a point where they fall short of the unbounded curves’
performance.
7.3.1 Bootstrapping
From the veriﬁer’s perspective, one level of bootstrapping is at-
tractive, since she only receives (and only veriﬁes) one constant-
sized, 512-bit proof, and one constant-sized, 448-byte digest.
Without bootstrapping, the only way for the prover to gen-
erate such concise proofs would be via one massive Pinocchio-
style QAP, which our results above (§7.2) show is infeasible.
Nonetheless, bootstrapping does come at a cost. While boot-
strapping, the “outer” QAP’s degree grows with each digest or
proof that it must verify. We summarize these costs below as-
suming that the veriﬁcation keys are known at compile-time.
• For each recomputed digest, we increase the degree by 2K
• For each full digest veriﬁcation, we pay 79.6K (including
the pairings needed for the checks from Equations (6)-(9)).
• For each bus digest veriﬁcation, we pay 33.8K (since, as
noted in §4.2, buses require fewer checks).
• For each proof veriﬁcation (Eqn (10)), we pay 28.2K.
for each 32-bit integer value committed.
With keys unknown at compile-time, we pay instead 89.8K and
30.6K for full digest and proof veriﬁcation, respectively.
We also observe that the prover’s cryptographic cost for
“outer” proofs and digests is typically higher than for work on
the “inner” instance, even for QAPs of the same size. One rea-
son is that the outer CP curve is less efﬁcient than the inner BN
curve (§7.1). A second reason is that many of the values the
prover commits to for the inner instance arise from the program
being veriﬁed, and hence they are often 1, 32, or 64 bits. In con-
trast, the outer curve veriﬁes elliptic curve operations and hence
many values are full-ﬂedged 254-bit values.
While these costs are substantial, they are low enough that
we can employ bootstrapping to scale the prover to much larger
computations. For example, with our existing implementation,
we could bootstrap up to 14 “inner” proofs sharing 16 buses; ap-
plying this to, say, the matrix exponentiation example allows us
to produce a single, constant-size proof for a computation with
a useful (i.e., not counting bootstrapping costs) QAP degree of
over 50 M. When evaluating the computation, the prover exe-
cutes 24M LLVM instructions and generates a proof in 152 min-
utes. While slow, this is ﬁve orders of magnitude faster than the
e
t
u
p
m
o
c
o
t
e
m
i
t
d
e
z
i
l
a
m
r
o
N
s
f
o
o
r
p
d
n
a
s
t
n
e
m
t
i
m
m
o
c
5.00
4.00
3.00
2.00
1.00
0.00