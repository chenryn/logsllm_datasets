for i = 2 . . . n do
i ··= R1
0
if Ui = U1 then R
i ··= f(vUi)G
0
else R
eR ··= R1 +Pn
if Tsig(eX,eR, m) = ⊥ then
Tsig(eX,eR, m) ··= c
Indsig(eX,eR, m) ··= js
i=2 R0
i
else abort algorithm and return ⊥
send (R1, π1)
receive ((R2, π2), . . . , (Rn, πn))
for i = 2 . . . n do
if Π.Ver(crs, (Ui, V, Ri), πi) = 0 then
return ⊥
if Ui = U1 ∧ Ri 6= R1 then
abort algorithm and return ⊥
if Ui 6= U1 ∧ Ri 6= f(vUi)G then
abort algorithm and return ⊥
Q ··= Qk(X, m)
return s1
Fig. 10. Wrapper algorithm V. Changes to Game10 are highlighted.
38
V returns (ˆs, outV) where outV = (hsig,ˆs, ˆa, X, µ, eR, s). Clearly, the accepting probability of
V (as deﬁned in Lemma 3) is
acc(V) = Advgame10
MS,A (λ).
(8)
Before deﬁning the second algorithm W, we prove a number of properties of V and ForkV.
Lemma 4. Consider a successful (i.e., not returning ⊥) execution
(ˆs, (hsig, ˆa, X, µ, eR, s)) ← V(p, G, G, X∗, hagg,1, . . . , hagg,q, hsig,1, . . . , hsig,q)
and let {X1, . . . , Xn} ··= X, (µ1, . . . , µn) ··= µ, and eX ··= Pn
i=1 µiXi. Then the following
properties hold:
(i) X∗ ∈ X;
(iii) sG = eR + hsigeX.
(ii) µi = hagg,ˆa for any i such that Xi = X∗;
Moreover, consider a successful execution
((hsig, ˆa, X, µ, eR, s), (h0
a, X0, µ0, eR0, s0)) ← ForkV(p, G, G, X∗, hagg,1, . . . , hagg,q).
sig, ˆ0
.
sig,ˆs
sig;
a, X = X0, µ = µ0, and eR = eR0.
Then one has
(iv) hsig 6= h0
(v) ˆa = ˆ0
Proof. Property (i) follows from the fact that V returns ⊥ in case X1 = X∗ /∈ X. Property (ii)
follows easily by inspection of the code of Fig. 10. Property (iii) simply expresses the validity
of the forgery returned by A (as V returns ⊥ if the forgery is invalid). Property (iv) follows
directly from the deﬁnition of ForkV as it returns ⊥ if hsig,ˆs = h0
It remains to prove property (v). Consider the ﬁrst execution of V run by ForkV:
(ˆs, (hsig, ˆa, X, µ, eR, s)) ← V(p, G, G, X∗, hagg,1, . . . , hagg,q, hsig,1, . . . , hsig,q; ρV)
and let {X1, . . . , Xn} ··= X, (µ1, . . . , µn) ··= µ, and eX ··= Pn
message for which A returned its forgery (i.e., A’s output was (X, m, eR, s)). We ﬁrst show that
i=1 µiXi. Let also m be the
Tsig(eX, eR, m) was necessarily assigned during a call to ROsig. Note that Tsig(eX, eR, m) can
only be assigned during a call to ROsig or a call to Sign. Assume towards contradiction that
it is during a call Sign( ˆK, m), and let ˆX be the multiset of veriﬁcation keys corresponding to
ˆK. We distinguish two cases:
1. If ˆX = X, then (X, m) would be appended to Q at the end of the execution of Sign and
consequently V would return ⊥ after A returns its forgery.
eX (for ˆX this follows from the assumption that Tsig(eX, eR, m) was assigned during the
2. If ˆX 6= X, then, since the aggregate keys corresponding to X and ˆX are both equal to
call Sign( ˆK, m)), necessarily V would abort and return ⊥ during either the ﬁrst call
ROagg(X,·) (which occurs at the latest during the ﬁnal call to MS.Ver) or the ﬁrst call
ROagg( ˆX,·) (which occurs at the latest during the call to Sign( ˆK, m)).
39
In both cases we reach a contradiction, which proves the claim.
Consider now the second execution of V run by ForkV:
a, X0, µ0, eR0, s0))
(ˆs, (h0
sig, ˆ0
n
i
sig,ˆs
; ρV)
sig,q
(= h0
i=1 µ0
1, . . . , µ0
1, . . . , X0
) ··= µ0, and eX0 ··= Pn
Before proving other equalities, we show that in both executions, there is necessarily a call
← V(p, G, G, X∗, hagg,1, . . . , hagg,q, hsig,1, . . . , hsig,ˆs−1, h0
n} ··= X0, (µ0
iX0
sig,ˆs, . . . , h0
and let {X0
. By inspection, the
Tsig(eX, eR, m) ··= hsig,ˆs(= hsig) in the ﬁrst execution and Tsig(eX0, eR0, m0) ··= h0
two executions are identical up to the ˆs-th assignment in Tsig: by deﬁnition of ˆs, it is
sig) in
execution. Moreover, by the claim above this assignment occurs during a call ROsig(eX, eR, m)
the second execution, where m0 is the message for which A returns its forgery in the second
in the ﬁrst execution, resp. ROsig(eX0, eR0, m0) in the second execution. This implies that the
arguments of the two calls are equal, which implies in particular that eR = eR0 and eX = eX0.
ROagg(X,·) and a call ROagg(X0,·) before the call ROsig(eX, eR, m). Indeed, if this were not
the case, then necessarily V would abort and return ⊥ in the ﬁrst (resp., second) execution
ﬁnal call to MS.Ver) since Tsig(eX, eR, m) 6= ⊥ at this moment.
during the ﬁrst call ROagg(X,·) (resp., ROagg(X0,·)) (which occurs at the latest during the
corresponding to X and X0 are both equal to eX, necessarily V would abort and return ⊥ in
This in turns implies that X = X0. Indeed, assume that X 6= X0. Since the aggregate keys
which occurs ﬁrst, since eX ∈ AggKeys: a contradiction.
both executions during the ﬁrst call ROagg(X,·) or the ﬁrst call ROagg(X0,·), depending on
the assignment of Tsig(eX, eR, m).
a and µ = µ0 since both executions are identical until
Finally, this also implies that ˆa = ˆ0
Algorithm W. From V, we deﬁne a second algorithm W as follows. It takes as main
input inpW = (p, G, G, X∗) and uniformly random elements hagg,1, . . . , hagg,q of S = Fp
Otherwise, let the output of ForkV be ((hsig, ˆa, X, µ, eR, s), (h0
sig, ˆa, X, µ, eR, s0)), where we
and runs ForkV(p, G, G, X∗, hagg,1, . . . , hagg,q). If ForkV returns ⊥ then W returns ⊥ as well.
(µ1, . . . , µn) ··= µ, and eX ··=Pn
used Lemma 4 (v) to equate elements of the two outputs of V, and let {X1, . . . , Xn} ··= X,
i=1 µiXi. By Lemma 4 (iii), one has
sG = eR + hsigeX and s0G = eR + h0
sigeX
sig by Lemma 4 (iv). Hence, W can compute the discrete logarithm ˜x of eX as
with hsig 6= h0
˜x ··= (s − s0)(hsig − h0
sig)−1 mod p.
Then W returns (ˆa, outW) where outW = (hagg,ˆa, X, µ, ˜x).
By Lemma 3 with S = Fp, the accepting probability of W satisﬁes
− 1
2λ−1 .
acc(W) ≥ acc(V)2
|Fp| ≥ acc(V)2
− acc(V)
q
q
As for V, we prove a number of properties regarding W and ForkW.
40
(9)
Lemma 5. Consider a successful execution
and let {X1, . . . , Xn} ··= X, (µ1, . . . , µn) ··= µ, and eX ··= Pn
(ˆa, (hagg, X, µ, ˜x)) ← W(p, G, G, X∗, hagg,1, . . . , hagg,q)
i=1 µiXi. Then the following
properties hold:
(i) X∗ ∈ X;
(iii) eX = ˜xG.
(ii) µi = hagg for any i such that Xi = X∗;
Moreover, consider a successful execution
((hagg, X, µ, ˜x), (h0
agg, X0, µ0, ˜x0)) ← ForkW(p, G, G, X∗)
agg;
.
agg,ˆa
1, . . . , µ0
n0) ··= µ0. Then one has
i for any i such that Xi 6= X∗.
and let {X1, . . . , Xn} ··= X, (µ1, . . . , µn) ··= µ, and (µ0
(iv) hagg 6= h0
(v) X = X0, n = n0, and µi = µ0
Proof. Properties (i) and (ii) follow directly from the corresponding properties in Lemma 4,
while property (iii) follows from the discussion above. Property (iv) follows directly from the
deﬁnition of ForkW as it returns ⊥ if hagg,ˆa = h0
To prove property (v), consider the two executions of W run by ForkW, which in turn run
V twice each. By inspection, the four executions are identical up to the ˆa-th assignment in
Tagg of the form Tagg(·, X∗): in the ﬁrst two executions it is Tagg(X, X∗) ··= hagg,ˆa(= hagg)
and in the last two executions it is Tagg(X0, X∗) ··= h0
agg). This ˆa-th assignment
might happen either because of a call to ROagg or to ROsig made by A or during the ﬁnal
call to MS.Ver. In all cases, the argument of the call are the same and it can easily be checked
that this implies X = X0. Moreover, since n = |µ|= |X| and n0 = |µ0|= |X0| this also implies
n = n0. Finally, since all four executions are identical up to this ˆa-th assignment and since all
assignments Tagg(X, X0) for x0 6= X happen before, this implies that µi = µ0
for any i such
that Xi 6= X∗.
Reduction Bdl. Finally, we deﬁne Bdl. On input (p, G, G, X∗), it runs ForkW(p, G, G, X∗). If
ForkW returns ⊥ then Bdl returns ⊥ as well. Otherwise, let ((hagg, X, µ, ˜x), (h0
agg, X, µ0, ˜x0))
be the output of ForkW and let {X1, . . . , Xn} ··= X, (µ1, . . . , µn) ··= µ, and (µ0
) ··= µ0
1, . . . , µ0
(using Lemma 5 (v) to equate elements of the two outputs of W).
Let n∗ be the number of times X∗ appears in X. Then, by Lemma 5 (ii), (iii), and (v),
(= h0
agg,ˆa
n
i
one has
˜xG = nX
˜x0G = nX
i=1
µiXi = n∗haggX∗ + X
aggX∗ + X
µ0
iXi = n∗h0
i∈[n]:Xi6=X∗
µiXi
µiXi.
i=1
i∈[n]:Xi6=X∗
Since n∗ 6= 0 and hagg 6= h0
logarithm of X∗ as
agg by Lemma 5 (i) and (iv) respectively, Bdl computes the discrete
x∗ = (˜x − ˜x0)(n∗)−1(hagg − h0
agg)−1.
41
By Lemma 3, Eq. (8), and Eq. (9), one has
(λ) ≥ acc(W)2
− acc(W)
2λ−1 ≥ acc(V)4
q3
Advdl
GrGen,Bdl
q
which concludes the proof.
(cid:16)Advgame10
MS,A (λ)(cid:17)4
(qh + qs + 1)3 − 3
2λ−1 ,
− 3
2λ−1
=
D Rerandomization of DDH Instances
We prove the following result.
Lemma 6. Let (q, E, P) be a group description. Let U = uP, V = vP, and W = wP be
three group elements. Consider the three following ways of sampling a pair of group elements
(V 0, W 0):
(i) α, β ←$ Zq; V 0 ··= αP + βV ; W 0 ··= αU + βW;
(ii) v0 ←$ Zq; V 0 ··= v0P; W ··= uv0P;
(iii) v0, w0 ←$ Zq; V 0 ··= v0P; W 0 ··= w0P.
Then (i) and (ii) result in identically distributed pairs if w = uv and (i) and (iii) result in
identically distributed pairs if w 6= uv.
Proof. When (V 0, W 0) is sampled according to (i), one has V 0 = (α + βv)P and W 0 =
(αu + βw)P. If w = uv, then W 0 = u(α + βv)P and hence (i) and (ii) are equivalent since
(α + βv) is uniformly distributed. If w 6= uv, then the system
(
α + βv = v0
αu + βw = w0
has a unique solution (α, β) ∈ (Fp)2 for any pair (v0, w0) ∈ (Fp)2, hence (i) and (iii) result in
identically distributed pairs.
42