next node to forward a packet, it may never overhear the
packet being transmitted.
In this case, the detector algorithm D is the watchdog
mechanism that monitors the medium to see if the packet
was forwarded F or if it did not hear the packet being for-
warded (unheard U) during a speciﬁed amount of time. Fol-
lowing [20] (where it is shown that the number of false
alarms can be quite high) we assume that a given watch-
dog D has a false alarm rate of ˆPFA = 0.5 and a detection
rate of ˆPD = 0.75. Given this detector algorithm, a (non-
randomized) decision maker DM has to be one of the fol-
lowing rules (where intuitively, h3 is the more appealing):
h1(F) = 0
h2(F) = 1
h3(F) = 0
h4(F) = 1
h1(U) = 0
h2(U) = 0
h3(U) = 1
h4(U) = 1
Now notice that since the operator wants to check the
consistency of the reports, the selﬁsh nodes will try to max-
imize the probability of error (i.e. C(0,0) = C(1,1) = 0 and
C(0,1) = C(1,0) = 1) of any watchdog with a chosen intru-
sion rate attack. As stated in lemma 2, this is a zero-sum
game where the adversary is the maximizer and the watch-
dog is the minimizer. The matrix of this game is given in
Table 2.
h
4
h
2
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
]
r
o
r
r
E
[
r
P
h
1
h
3
0
0
0.1
0.2
0.3
0.4
0.5
p
0.6
0.7
0.8
0.9
1
Figure 8. Probability of error for hi vs. p
It is a well known fact that in order to achieve a Nash
equilibrium of the game, the players should consider mixed
strategies (i.e. consider probabilistic choices).
For our
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:52:29 UTC from IEEE Xplore.  Restrictions apply. 
I = 0
I = 1
h0
R(0,0)
R(1,0)
h1
R(0, ˆPD)
R(1, ˆPFA)
h2
R(0, ˆPFA)
R(1, ˆPD)
h3
R(0,1)
R(1,1)
Table 2. Matrix for the zero-sum game theo-
retic formulation of the detection problem
fore, after ﬁxing DM , it does not matter if p deviates from
∗
because we are guaranteed that the probability of error
p
will be no worse (but no better either) than 2/5, therefore
the IDS can be claimed to be 2/5-robust.
5.4. Example: Robust Evaluation of IDSs
example the optimal mixed strategy for the selﬁsh node
∗ =
(see Figure 8) is to drop a packet with probability p
ˆPFA/( ˆPFA1 + ˆPD). On the other hand the optimal strategy
for DM is to select h3 with probability 1/( ˆPFA + ˆPD) and
h1 with probability ( ˆPFA − (1− ˆPD))/( ˆPFA − (1− ˆPD) + 1).
This example shows that sometimes in order to minimize
the probability of error (or any general cost) against an
adaptive attacker, DM has to be a probabilistic algorithm.
Lemma 2 also presents a way to get this optimal point
from the ROC, however it is not obvious at the begin-
ning how to get the same results, as there appear to be
only three points in the ROC: (PFA = 0,PD = 0) (by se-
lecting h1), ( ˆPFA = 1/2, ˆPD = 3/4) (by selecting h3) and
(PFA = 1,PD = 1) (by selecting h4). The key property of
ROC curves to remember is that the (optimal) ROC curve
is a continuous and concave function [23], and that in fact,
the points that do not correspond to deterministic decisions
are joined by a straight line whose points can be achieved
by a mixture of probabilities of the extreme points.
In
our case, the line y = 1 − x intercepts the (optimal) ROC
= ˆPFA/( ˆPD + ˆPFA) and
at the optimal operating points ˆP
∗
ˆP
is the
D
value required to make the slope of the isoline parallel to
∗
the ROC line intersecting (P
FA
∗
= ˆPD/( ˆPFA + ˆPD) (see Figure 9). Also note that p
∗
, P
D
∗
FA
).
ROC of a watchdog
h3
h4
1
0.9
0.8
0.7
0.6
D
P
0.5
(x*,y*)
0.4
0.3
0.2
0.1
0
0
h1
0.2
0.4
0.6
0.8
1
PFA
Figure 9. The optimal operating point
The optimal strategy for the intruder is therefore p
∗ =
2/5, while the optimal strategy for DM is to select h1 with
probability 1/5 and h3 with probability 4/5. In the robust
∗
= 3/5. There-
operating point we have P
FA
∗
= 2/5 and P
D
As a second example, we chose to perform an intrusion
detection experiment with the 1998 MIT/Lincoln Labs data
set [1]. Although several aspects of this data set have been
criticized in [22], we still chose it for two main reasons. On
one hand, it has been (and arguably still remains) the most
used large-scale data set to evaluate IDSs.
In the second
place we are not claiming to have a better IDS to detect at-
tacks and then proving our claim with its good performance
in the MIT data set (a feat that would require further test-
ing in order to be assured on the quality of the IDS). Our
aim on the other hand is to illustrate our methodology, and
since this data set is publicly available and has been widely
studied and experimented with (researchers can in princi-
ple reproduce any result shown in a paper), we believe it
provides the basic background and setting to exemplify our
approach.
Of interest are the Solaris system log ﬁles, known as
BSM logs. The ﬁrst step of the experiment was to record
every instance of a program being executed in the data set.
Next, we created a very simple tool to perform buffer over-
ﬂow detection. To this end, we compared the buffer length
of each execution with a buffer threshold, if the buffer size
of the execution was larger than the threshold we report an
alarm.
We divided the data set into two sets.
In the ﬁrst one
(weeks 6 and 7), our IDS performs very well and thus we
assume that this is the ”evaluation” period. The previous
three weeks were used as the period of operation of the IDS.
Figure 10(a)3 shows the results for the ”evaluation” period
when the buffer threshold ranges between 64 and 780. The
dotted lines represent the suboptimal points of the ROC or
equivalently the optimal points that can be achieved through
randomization. For example the dotted line of Figure 10(a)
can be achieved by selecting with probability λ the detector
with threshold 399 and with probability 1− λ the detector
with threshold 773 and letting λ range from zero to one.
tions monitored and 13 attacks, therefore ˆp = 1.6× 10
During the evaluation weeks there were 81108 execu-
−4.
3Care must always be taken when looking at the results of ROC curves
due to the ”unit of analysis” problem [22]. For example comparing the
ROC of Figure 10(a) with the ROC of [14] one might arrive to the erro-
neous conclusion that the buffer threshold mechanism produces an IDS
that is better than the more sophisticated IDS based on Bayesian networks.
The difference lies in the fact that we are monitoring the execution of ev-
ery program while the experiments in [14] only monitor the attacked pro-
grams (eject, fbconfig, fdformat and ps). Therefore although we
raise more false alarms, our false alarm rate (number of false alarms di-
vided by the total number of honest executions) is smaller.
Proceedings of the 2006 IEEE Symposium on Security and Privacy (S&P’06) 
1081-6011/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 02:52:29 UTC from IEEE Xplore.  Restrictions apply. 
ROC for Evaluation
ROC during operation
α,β
ROC
1
0.8
0.6
D
P
0.4
0.2
0
0
1
2
3
4
5
6
PFA
7
x 10−4
1
0.8
0.6
D
P
0.4
0.2
0
0
1
2
3
4
5
6
PFA
7
x 10−4
1
0.8
0.6
D
P
0.4
0.2
0
0
1
2
3
4
5
6
PFA
7
x 10−4
(a) Original ROC obtained during the evaluation
period
(b) Effective ROC during operation time
(c) Original ROC under adversarial attack ROCα,β
Figure 10. Robust expected cost evaluation
Assuming that our costs (per execution) are C(0,0) =
C(1,1) = 0, C(1,0) = 850 and C(0,1) = 100 we ﬁnd that
the slope given by equation 8 is mC, ˆp = 735.2, and therefore
the optimal point is (2.83×10
−4,1), which corresponds to a
threshold of 399 (i.e. all executions with buffer sizes bigger
than 399 raise alarms). Finally, with these operating condi-
tions we ﬁnd out that the expected cost (per execution) of
the IDS is E[C(I, A)] = 2.83× 10
−2.
In the previous three weeks used as the ”operation” pe-
riod our buffer threshold does not perform as well, as can be
seen from its ROC (shown in Figure 10(b).) Therefore if we
use the point recommended in the evaluation (i.e. the thresh-
old of 399) we get an expected cost of Eoperation[C(I, A)] =
6.934× 10
−2. Notice how larger the expected cost per ex-
ecution is from the one we had evaluated. This is very no-
ticeable in particular because the base-rate is smaller during
the operation period ( ˆpoperation = 7 × 10
−5) and a smaller
base-rate should have given us a smaller cost.
To understand the new ROC let us take a closer look at
the performance of one of the thresholds. For example, the
buffer length of 773 which was able to detect 10 out of the
13 attacks at no false alarm in Figure 10(a) does not perform
well in Figure 10(b) because some programs such as grep,
awk, find and ld were executed under normal operation
with long string lengths. Furthermore, a larger percent of
attacks was able to get past this threshold. This is in general
the behavior modeled by the parameters α and β that the
adversary has access to in our framework.
Let us begin the evaluation process from the scratch by
−4,0.1)− intruder, where
assuming a ([1× 10
δ = [1× 10
−5,0] means the IDS evaluator believes that the
base-rate during operation will be at most ˆp and at least
−5. α = 1 × 10
ˆp − 1 × 10
−5 means that the IDS evalua-
tor believes that new normal behavior will have the chance
of ﬁring an alarm with probability 1× 10
−5. And β = 0.1
means that the IDS operator has estimated that ten percent
of the attacks during operation will go undetected. With
−5,0],1× 10
these parameters we get the ROCα,β shown in Figure 10(c).