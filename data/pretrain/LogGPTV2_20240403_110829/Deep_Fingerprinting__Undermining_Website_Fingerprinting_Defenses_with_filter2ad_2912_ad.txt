Finally, we investigate the impact of dataset size on classifier ac-
curacy. The results shown in Figure 5 indicate that DF and CUMUL
consistently outperform the other attacks for all training sizes. With
just 50 traces per site, both DF and CUMUL achieve 90% accuracy.
k-NN, k-FP and AWF require 250 traces to reach this accuracy, and
SDAE requires 750 traces. The observed accuracies mostly saturate
after 550 traces, except for SDAE. The results show that the var-
ious techniques used in the DF model lead to significantly better
performance compared to the simpler AWF model.
5.5 Training Cost
We now examine the training time for WF attacks using DL in
comparison to state-of-the-art WF attacks. We found that with
GPU acceleration by using NVIDIA GTX 1070 with 8 GB of GPU
Memory, SDAE required 16 minutes for training (13 minutes for
pre-training and 3 minutes for fine-tuning processes), DF required
64 minutes for 30-epoch training. The relatively simpler AWF model
requires 4 minutes for 30-epoch training. Without a GPU, SDAE
required 96 minutes, DF required approximately 10 hours, and
AWF required 1 hour. For training the other attacks, we found it
required 12.5 hours for k-NN, 57 hours for CUMUL (parallelized
with 4 processes), and 1 hour for k-FP. Overall, SDAE, DF and AWF
have reasonable training times, particularly when using a GPU.
5.6 Closed-world Evaluation on the Defended
Dataset
We next examine the performance of WF attacks against Tor traf-
fic with defenses in the closed-world scenario. It is important to
note that the attacker needs to train the classifiers with defended
datasets to perform this attack. As mentioned in Section 3, several
WF defenses have been proposed that they can reduce the accuracy
of state-of-the-art WF attacks to less than 50%. Notably, WTF-PAD
and Walkie-Talkie offer both effective protection and reasonable
overheads, such that they are realistic for adoption in Tor. With
our larger dataset, we conduct an evaluation on SDAE, DF, AWF
and prior attacks against these defenses, as well as BuFLO and
Tamaraw.
Table 3 shows the overheads of each defense and the accuracy
of the attacks against defended datasets. BuFLO and Tamaraw,
the two high-overhead defenses, hold up well with less than 17%
accuracy. The attacks also manage at most 49.70% accuracy against
Walkie-Talkie due to symmetric collisions. A surprising result is
that DF achieves over 90% accuracy against WTF-PAD. Our tests
of WTF-PAD showed 64% overhead, which means that there was
more padding on average than in the Juarez et al.’s study [20], and
yet the attack was successful. More generally, it seems that the
larger amount of traces per site compared to the original WTF-
PAD evaluation has played a role in the higher accuracy attained
by the attack. For example, k-FP achieved nearly 69% accuracy in
our experiment, whereas Hayes and Danezis tested k-FP against
their own implementation of adaptive padding and obtained 30%
accuracy [14].
DF significantly outperforms AWF on the dataset protected by
WTF-PAD, with a much larger gap in performance than observed
on the undefended dataset. We believe that the deeper network
is able to better extract useful features in the WTF-PAD data that
the AWF model is unable to find, leading to this result. The model
architecture in DF plays a key role in its flexibility to generalize to
defended traffic.
We note that the overheads for BuFLO and Tamaraw are higher
than reported in prior work at 246% and 328% bandwidth overheads,
respectively. Furthermore, we found that the larger the dataset, the
greater the packet timing variance is, which is fundamental to
determine the padding rate. Also, Tamaraw has higher overheads
than BuFLO, which contradicts the purposed intended with its
design and the overheads reported in previous evaluations. The
cause of this is a greater amount of padding after the transmission
has finished in Tamaraw compared to BuFLO. BuFLO stops padding
immediately after the transmission has finished, as long as the
transmission has lasted for longer than ten seconds, which is the
case for most of the traces in our dataset.
With such heavy overheads, BuFLO and Tamaraw are not practi-
cal to deploy as a WF defense in Tor. WTF-PAD and Walkie-Talkie
have lower overheads, and Tor Project developers have already
shown an interest in deploying adaptive padding as a possible de-
fense [29, 30]. We thus select WTF-PAD and Walkie-Talkie for our
open-world evaluation.
5.7 Open-world Evaluation
We now evaluate the performance of the attack in the more realistic
open-world setting. As mentioned in Section 2, in the open-world
scenario, the adversary not only classifies traffic traces based on a
limited set of monitored sites, but he must also distinguish whether
the trace comes from a monitored site or an unmonitored one.
In our evaluation, we assess the performance of classifiers in
the open-world scenario on each model by showing true positive
rate (TPR) and false positive rate (FPR), but also with precision and
recall curves, recommended in the WF literature [20, 27] as more
appropriate metrics for the open-world evaluation than TPR and
FPR. The size of the monitored and unmonitored sets are heavily
unbalanced, so using only TPR and FPR can lead to incorrect inter-
pretation due to the base-rate fallacy. We also provide ROC curves
in Appendix C.
In previous studies on WF in the open-world set-
Standard Model.
ting [14, 27, 38], it has been assumed that if the attacker included
unmonitored traces when training the classifier, it could help the
classifier better distinguish between monitored and unmonitored
traces. This assumption is also common in machine learning, and
we thus call it the Standard model. Fundamentally, the process of
training and creating datasets used during open-world evaluation
is the same as in the closed-world scenario, except that we addi-
tionally train on unmonitored websites traces as another class. To
investigate the impact of more training data on the performance
of the classifiers in the open-world scenario, we train the classifier
with different portions of the unmonitored dataset.
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada1936Table 3: Accuracy in a closed-world scenario on defended datasets, SDAE, DF, and AWF vs. the state-of-art WF attacks
Defenses
BuFLO
Tamaraw
WTF-PAD
Walkie-Talkie
Overhead
Bandwidth
Latency
246%
328%
64%
31%
137%
242%
0%
34%
Accuracy of WF attacks on defended datasets
k-FP
13.1%
11.0%
69.0%
7.0%
k-NN CUMUL
10.4%
9.7%
16.0%
20.2%
13.5%
16.8%
60.3%
38.4%
SDAE
9.2%
11.8%
36.9%
23.1%
AWF
DF
11.7%
12.6%
11.8%
12.9%
90.7% 60.8%
49.7%
45.8%
1.0
0.8
0.6
0.4
0.2
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
kNN
kFP
AWF
CUMUL
DF
SDAE
0.0
0
5000
10000
Size
(a) TPR
15000
20000
e
t
a
r
e
v
i
t
i
s
o
p
e
s
l
a
F
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
kNN
kFP
AWF
CUMUL
DF
SDAE
0
5000
10000
Size
(b) FPR
15000
20000
Figure 6: Open World: The impact of the amount of unmonitored training data on TPR and FPR (Non-defended dataset).
In our open-world evaluation, we use the prediction probability
to classify the input traces. In particular, if the input trace is a mon-
itored website trace and the maximum output probability belongs
to any monitored site and is greater than a threshold, we consider
this as a true positive. We used different thresholds for different WF
attacks. We selected the thresholds for each WF attack such that
they have high TPR and low FPR. Figure 9 in Appendix C shows
examples of ROC curves for WF attacks against Non-defended,
WTF-PAD, and W-T datasets. Following the experimental proce-
dures of Rimmer et al. [31] and Panchenko et al. [27], we focus
on the binary results of whether the input trace is classified as
monitored (predicted to be in any of the monitored classes) or un-
monitored. Note that if the trace is determined to be monitored, the
attacker can then use the multi-class classification to predict which
website the user has actually visited.
k-NN and k-FP attacks use the k-nearest neighbors algorithm in
their predictions and do not output the probability of predictions.
For these attacks, we consider the prediction probability of a site as
the fraction of the nearest neighbors belonging to that site among
the k nearest neighbors. We explored the performance of these
attacks as the value of k varies from 2 to 10. We found that above
k = 5, the TPR and FPR do not change significantly. For our open-
world evaluation, we used k = 6 in both k-NN and k-FP.
5.7.1 Results. We first evaluate efficacy of our WF attack in the
Standard model as amounts of unmonitored training data varies
and compare it with other state-of-the-art WF attacks on the non-
defended traces. Our training set in this experiment contains 85,500
monitored traces (900 instances for each of 95 monitored sites) and
we varied the number of unmonitored sites from 900 to 20,000 sites
(one instance for each). Our testing set includes 9500 monitored
traces (100 instances for 95 monitored sites) and 20,000 unmonitored
traces (one instance for 20,000 unmonitored sites). Note that the
20,000 unmonitored sites in the testing are different from those in
the training.
As shown in Figures 6a and 6b, the TPR tends to slightly decrease
with the reduction of FPR as the size of unmonitored training data
increase for all the WF attacks. The results show that the DF model
consistently performs best on both TPR and FPR, with 0.957 TPR
and 0.007 FPR for 20,000 unmonitored training sites. k-NN has the
lowest TPR and k-FP has the highest FPR. The DF, CUMUL and
AWF have the same FPR trend as the training size increases, but DF
has higher TPR than CUMUL and AWF over all the training sizes.
Our results show that as we increase the size of the unmonitored
class in the training, the FPR drops and it reaches its lowest amount
at size 20,000. In the next experiment, we fix the number of training
samples for the unmonitored class to 20,000 and we evaluate the
diagnostic ability of WF attacks as the discrimination threshold is
varied. We next perform the experiment on our non-defended, WTF-
PAD and Walkie-Talkie (W-T) datasets. As mentioned in Section 4,
for W-T, we cannot use the same dataset to W-T traces as it required
to be directly captured from half-duplex connections from Tor
browser. Our training set for the W-T evaluation contains 91,000
monitored traces (910 instances for each of 100 monitored sites) and
we varied the number of unmonitored sites from 900 to 20,000 sites
(one instance for each). Our testing set includes 9,000 traces (90
instances for each of 100 monitored sites) and 20,000 unmonitored
Session 10A: TORCCS’18, October 15-19, 2018, Toronto, ON, Canada19371
0.8
0.6
0.4
0.2
n
o
i
s
i
c
e
r
P
0
0
0.2
0.4