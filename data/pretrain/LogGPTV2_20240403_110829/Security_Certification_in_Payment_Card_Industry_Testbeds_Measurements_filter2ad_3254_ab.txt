The code of the website2 is based on OpenCart. We rewrote the
OpenCart system by integrating all 35 security vulnerabilities and
testing cases. We deployed the website using Apache HTTP server
and MySQL database. Our testbed automatically spawns a website
instance following a pre-defined configuration. We used OpenSSH
as the remote access software and Phpmyadmin to remotely manage
the MySQL database. We hosted our website in Amazon AWS in a
single t2.medium server instance with Ubuntu 16.04. We obtained a
valid SSL certificate to enable HTTPS from Let’s Encrypt [25].
We set up the website solely for research experiment purposes.
Thus, it does not have a real payment gateway. Instead, we set up a
dummy payment gateway that imitates the real gateway Cardcon-
nect [22]. The website forwarded credit card transactions to this
dummy payment gateway. The dummy endpoint for Cardconnect
is implemented using flask-restful framework. We modified the
/etc/hosts file of our web server to redirect the request. During
our experiments, our server did not receive any real payment trans-
action requests. We further discuss research ethics in Section 3.3.
Implementing Security Test Cases. Next, we describe the im-
plementation details of the 35 security test cases in Table 3.
For the network security category, we implement test cases i1 to
i3 by changing inbound traffic configurations within the Amazon
AWS security group. Test case i4 (administer access over Internet) is
implemented by changing phpmyadmin configuration. For test case
i5 (default SQL password), we do not set any password for “root”
and enable access from any remote host. Test case i5 is implemented
by configuring phpmyadmin (no password for user “root”). Test
case i7 is set to keep port 80 (HTTP) open without a redirection to
port 443 (HTTPS). Test cases i12, i14, i16, and i17 are implemented
by using default certificates from Apache. Test cases i13 and i18 are
implemented by changing SSLCipherSuite and SSLProtocol of the
Apache server. For test case i15, we configure the Apache server to
use a valid certificate but with a wrong domain name.
For the system security category, we implement test cases i19–
i20 by installing software that are known to be vulnerable. For
test case i19, we use OpenSSL 7.2, which is vulnerable to privilege
escalation and timing side channel attacks. For test case i20, we
used phpmyadmin 4.8.2 which is known to be vulnerable to XSS. We
implemented test cases i29 to i33 by changing the configurations
of the Apache server. For test case i33 (HTTP security header)
in particular, we consider X-Frame-Options, X-XSS-Protection, X-
Content-Type-Options, and Strict-Transport-Security.
For the web application security category, we implement test
cases i21 to i28 by modifying OpenCart source code [26]. Regarding
secure password guidelines, we disable password retry restrictions
2The URL was www.rwycart.com. We took the site offline after the experiment.
for both users and administrators (test case i23), disable the length
checking of passwords (test case i24). For SQL injection, we modify
the admin login (test case i21) and customer login (test case i22)
code to implement SQL injection vulnerabilities. For admin login,
we simply concatenate user inputs without sanitation for the login
query. For the customer login, we leave an SQL injection vulner-
ability at the login form. Given that the user password is stored
as unsalted MD5 hashes, we run the login query by concatenating
the MD5 hash of the user-provided password, which is known to
be vulnerable to SQL injection [5]. For XSS and CSRF, we implant
an XSS vulnerability in the page of editing customer profiles, by
allowing HTML content in the “first name” field (test case i27). By
default, Opencart does not have any protection against CSRF (test
case i28). For test case i26 (displaying errors), we configure Open-
Cart to reveal crash reports (an insecure practice, which gives away
sensitive information). Opencart by default does not check the in-
tegrity of Javascript code loaded from external sources (test case
i25).
For the secure storage category, we modify the Cardconnect
extension to store CVV in our database (test case i8) and the full
PAN (instead of the last 4 digits) in the database in plaintext (test
case i10). We add an option to encrypt PANs before storing, but
the encryption key is hardcoded (test case i11). We also update the
customers’ order history page to show the unmasked PAN for each
transaction (test case i9). Finally, the testbed stores the raw unsalted
MD5 hash of passwords for customers (test case i34) and plaintext
passwords for admins (test case i35).
3.3 Research Ethics
We have taken active steps to ensure research ethics for our mea-
surement on PCI scanners (Section 4). Given that our testbed is
hosted on the public Internet, we aim to prevent real users from
accidentally visiting the website (or even putting down credit card
information). First, we only put the website online shortly before
the scanning experiment. After each scanning, we immediately
take down the website. Second, the website domain name is freshly
registered. We never advertise the website (other than giving the
address to the scanners). Third, we closely monitor the HTTP log of
the server. Any requests (e.g., for account registration or payment)
that are not originated from the scanners are dropped. Network
traffic from PCI scanners are easy to distinguish (based on IP and
User-Agent) from real user visits. We did not observe any real user
requests or payment transactions during our experiments.
All PCI scanners run automatically without any human involve-
ment from the companies. We order and use the scanning services
just like regular customers. We never actively generate traffic to
the scanning service, and thus our experiments do not cause any
interruptions. Our experiments follow the terms and conditions
specified by the scanning vendors, which we carefully examined.
We choose to anonymize the PCI scanners’ names since some scan-
ning vendors strictly forbid publishing any benchmark results. We
argue that publishing our work with anonymized scanner names is
sufficient for the purpose of describing the current security practice
in the payment card industry, as the security issues reported are
likely industry-wide, not unique to the individual scanners eval-
uated. In addition, anonymization would help alleviate the bias
toward individual scanners and potential legal issues [54].
Table 2: Prices of PCI scanners and the actual costs.
PCI Scanners
Scanner1
Scanner2
Scanner3
Scanner4
Scanner5
Scanner6
Scanner7
Scanner8
Total
Price
$2,995/Year
$2,190/Year
$67/Month
$495/Year
$250/Year
$59/Quarter
Unknown
$350/Year
-
Spent Amount
$0 (Trial)
$0 (Trial)
$335
$495
$250
$118
N/A
N/A
$1198
PCI SSC Approved?
Yes
Yes
No
Yes
Yes
No
Yes
Yes
-
organization policies). During our search, we also found that some
website owners used non-ASV scanners. Thus, we also included
2 non-ASVs that have good self-reported quality. Non-approved
scanners offer commercial PCI scanning services, but are not on the
ASV list [20] of the PCI council4. Because of the legal constraints
imposed by the terms and conditions of scanners, we cannot reveal
scanners’ names. Researchers who wish to reproduce or extend our
work for scientific purposes without publishing scanner names are
welcome to contact the authors.
We conducted experiments successfully with 6 of the scanners
(without Scanner7 and Scanner8 for the reason mentioned above).
We use the email address (PI:EMAIL) associated with
the testbed e-commerce website to register accounts at the scanning
vendors. Table 2 shows the prices of these 6 vendors. For Scanner2
and Scanner1, we completed our experiments within the trial period
(60 days for Scanner2 and 30 days for Scanner1). The trial-version
and the paid-version offer the same features and services.
Iterative Test Design. Given a PCI scanner, we carry out the eval-
uation in two high-level steps shown in Figure 2. Every scanner
first runs on the same baseline testbed with all the vulnerabili-
ties built in. Then we remove a minimal set of vulnerabilities to
get the testbed certified for PCI DSS compliance. The final certi-
fied instance of the testbed may be different for different scanners,
as high-quality scanners require more vulnerabilities to be fixed,
having fewer remaining (undetected) vulnerabilities on the testbed.
(1) Baseline Test. We spawn a website instance where all 35 vul-
nerabilities are enabled (29 of them are remotely verifiable).
Then we order a PCI scanning service for this testbed. During
the scanning, we monitor the incoming network traffic. We
obtain the security report from the scanner, once the scanning
is complete.
(2) Certified Instance Test. After the baseline scanning, we mod-
ify the web server instance according to the obtained report.
We perform all the fixes required by the PCI scanner and order
another round of scanning. The purpose of this round of scan-
ning is to identify the minimal set of vulnerabilities that need to
be fixed in order to pass the PCI DSS compliance certification.
In summary, we perform the following steps for each scanner: i)
implant vulnerabilities under each test case in the testbed, ii) run
Figure 2: Illustration of the baseline scanning and the certi-
fied version. A PCI scanner iteratively scans the testbed. The
initial scan (baseline) is on the original testbed with all 35
vulnerabilities. The certified version is the testbed version
where the testbed successfully passes the scanning after we
iteratively fix a minimal set of vulnerabilities in the testbed.
In Table 3, we report the scanning results on both versions
of the testbed for each scanner.
In Section 5, we also carefully design our experiments when
evaluating the compliance of 1,203 websites. The experiment is
designed in a way that generates minimal footprints and impact on
the servers, in terms of the number of connection requests to the
servers. Our client is comparable to a normal client and does not
cause any disruption to the servers. For example, we quickly closed
the connection, after finding out whether or not an important port
is open. More details are be presented in Section 5.
tion capabilities? (Section 4.1)
and premature certification? (Section 4.2)
4 Evaluation of PCI Scanners
Our first set of experiments is focused on evaluating PCI scanners
to answer the following research questions. Later in Section 5, we
will introduce our second set of experiments on measuring the
security compliance of real-world e-commerce websites.
• How do various PCI scanners compare in terms of their detec-
• What are the security consequences of inadequate scanning
• How are web scanners (commercial or open-source ones) com-
pared with PCI scanners in terms of detection capabilities?
(Section 4.3)
We selected 8 U.S. based PCI DSS scanners as shown in Table 2.
The selection process is as follows. From the list of approved ven-
dors [20]3, we found 85 of them operate globally. Out of these 85,
we aimed to identify a set of ASVs that appear to be of high quality
(e.g., judging from the company’s reputations and websites) and
somewhat affordable (due to our limited funding), while also cov-
ering different price ranges. We identified 6 such scanners. For 3
of them, the prices are publicly available. For the other 3 scanners,
we emailed them through our rwycart.com email addresses. 2 of
them (Scanner7 and Scanner8) did not provide their price quota-
tions, which forced us to drop them from our evaluation (due to our
3As of April 30, 2019, 97 companies are approved by the PCI Council as the approved
scanning vendors (ASVs) [20].
4To become an ASV, a scanner service needs to pay a fee and go through a testbed-based
approval evaluation supervised by the PCI Council.
Baseline VersionCerti(cid:127)ed VersionPCI ScannerFixing a minimalset of vulnerabilitiesto get PCI DSS certi(cid:127)edScanning ReportsScanningScanningBuggyCart TestbedTable 3: Testbed scanning results. “Baseline” indicates the scanning results on our testbed when all the 35 vulnerabilities are
active. “Certified” indicates the scanning results after fixing the minimum number of vulnerabilities in order to be compliant.
“(cid:35)”, “(cid:71)(cid:35)”, “(cid:32)” means severity level of low, medium, and high respectively according to the scanners. “✗” mean “undetected”, “✓”
means “fixed in the compliant version”, “✓∗” means “fixed as a side-effect of another case”. The “website scanners” represent
a separate experiment to determine whether website scanners can help to improve coverage. We ran the website scanners
on test cases that were not detected by the PCI ASV scanners. “N/A” means "not testable by an external scanner". “-” means
"testable but do not need to tested". The "Must Fix" column shows the vulnerabilities that must be fixed by the e-commerce
websites in order to be certified as PCI DSS compliant.
Rq. Test Cases
Vul.
Location
e
r
o
c
S
S
S
V
C
?
e
p
o
c
S
V
S
A
n
I
? Scanner2
x
i
F
Scanner5
Scanner4
/ Scanner1
Scanner6
(not aprvd.)
Scanner3
(not aprvd.)
Website
Scanners
t
s
u
M
e
n
i
l
e
s
a
B
d
e
fi
i
t
r
e
C
e
n
i
l
e
s
a
B
d
e
fi
i
t
r
e
C
e
n
i
l
e
s
a
B
d
e
fi
i
t
r
e
C
e
n
i
l
e
s
a
B
d
e
fi
i
t
r
e
C
e
n
i
l
e
s
a
B
d
e
fi
i
t
r
e
C
W
W
2
r
e
n
n
a
c
S
5
r
e
n
n
a
c
S
f
a
3
W
P
A
Z
-
-
-
-
-
-
✗
-
-
-
-
-
-
✗
-
-
-
-
-
-
✓
-
-
-
-
-
-
✗
N/A N/A N/A N/A
N/A N/A N/A N/A
N/A N/A N/A N/A
N/A N/A N/A N/A
-
-
-
-
-
-
-
-
-
✗
✗
✗
✗
-
✗
✗
-
-
-
-
-
-
N/A N/A N/A N/A
N/A N/A N/A N/A
-
-
-
-
-
-
-
-
-
-
-
✗
✓