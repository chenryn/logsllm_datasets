在上面的优化问题中求解出e后，我们可以得到如下的噪声向量
现在还剩下两个约束，他们是高度非线性的，为此，我们将他们加入目标函数中
因为防御分类器的输出层有sigmoid激活函数，因此我们有
分母中的h()那一项是当防御分类器以噪声置信度向量softmax(x+e)为输入时的倒数第二层的神经元的输出。g(softmax (z + e)) =
0.5 也就意味着h(softmax(z + e)) = 0
因此，我们将最后一个约束条件转换成了下面的损失函数：
当h(sof tmax(z + e))接近0时，L1会比较小
接下来要把剩下的最后一个约束转换成目标函数
我们设查询样本的预测标签为l，即：
那么剩下的那个约束就意味着zl + el是向量z + e中的最大项，因此我们有如下不等式约束
进一步将不等式约束转换为如下损失函数:
其中的ReLU函数定义为
如果下式成立
则损失函数L2为0
将每个约束都转换为目标函数后，我们就可以得到下面的无约束优化问题
其中
接下来的问题就是求解上式。我们设计了一种基于梯度下降的求解无约束优化问题的算法。
算法如下
由于我们的目标是找到一个具有小的置信分数失真的噪声向量，我们迭代地搜索一个大的c3。对于每个给定的c3，我们使用梯度下降法求出满足约束条件的e。当我们找不到满足这两个约束条件的向量e时，搜索c3的过程就停止了。在给定c2、c3和学习速率β后,我们迭代更新矢量变量e。
因为我们将约束条件转换为了目标函数方程,这并不能保证他们迭代梯度下降过程中符合要求。因此，在梯度下降的每次迭代中，我们检查这两个约束是否满足(即算法1中的第8行)。具体来说，当预测的标签发生变化或logit
h的符号没有变化时，我们继续梯度下降过程。换句话说，当两个约束条件都满足时，我们停止梯度下降过程。我们用
来近似前面的最后一个约束。
###  阶段2
在第一阶段结束之后，我们有两个有代表性的噪声向量。在第二阶段中，我们假设随机噪声添加机制是两个代表性噪声向量上的概率分布，而不是整个噪声空间。具体地说，我们认为防御者以概率p和1
– p分别选取具有代表性的噪声向量r和0，防御者将选取的代表性噪声向量加到真实置信度分数向量中。通过这样的简化，可以将优化问题简化如下:
上式的约束意味着期望的置信度失真受预算限制。我们可以推导出简化后的优化问题的解析解。解析解如下:
## 实验分析
作者在文中是使用三类不同的数据集：
Location:每个特征表示用户是否访问了特定的区域或位置类型
Texas100:每个特征代表损伤的外因(如自杀、药物滥用)、诊断、患者所经历的程序和一些通用信息(如性别、年龄和种族)
CH-MNIST:该数据集用于对结直肠癌患者组织学上的不同组织类型进行分类
先来看看随着置信度失真预算(即ε)的增加，不同攻击的推断准确性
a,b,c分别对应着不同的数据集，而不同颜色的线代表不同的攻击分类器，我们可以看到，MemGuard可以有效地防御成员推理攻击，由于我们的防御被允许在置信度得分向量中添加更大的噪声，所有攻击的推理准确性都会下降。例如，在Location中，当我们的防御被允许添加预算l1
-范数在0.8左右的噪音时，我们的防御可以将所有评估攻击降低为随机猜测(RG)攻击，都处于0.5的水平;在CH-MNIST上，我们的防御可以将NSH攻击(或其余攻击)减少到随机猜测，当允许添加预期L1-norm在0.3左右的噪声时
然后设计实验来评估成员数据与非成员数据的置信分数向量的不可区分性，给定一个置信度向量s，计算其归一化熵:
根据这个指标进行测量，结果如下
上面一行是没有防御的，下面是有防御的。图中两条曲线之间的距离对应目标分类器训练数据集的信息泄漏，从图中可以看到，MemGuard大大减少了这种差距。
## 实战
###  训练目标分类器
我们使用location数据集，首先训练一个目标分类器
训练过程如下
###  训练防御分类器
训练过程如下
然后是防御框架的训练部分
加载目标模型并后去所需置信度分数等信息
加载防御分类器并设置c1,c2,c3
寻找满足优化问题且符合约束条件的噪声向量
求解过程如下
###  训练攻击所需的影子模型
###  评估防御效果
攻击者所用的模型
评估攻击效果
从结果可以看到，在应用了MemGuard进行防御之后，成员推理攻击的效果下降到了50%
## 参考
1.Jia J, Salem A, Backes M, et al. Memguard: Defending against black-box
membership inference attacks via adversarial examples[C]//Proceedings of the
2019 ACM SIGSAC conference on computer and communications security. 2019:
259-274.
2.Shokri R, Stronati M, Song C, et al. Membership inference attacks against
machine learning models[C]//2017 IEEE Symposium on Security and Privacy (SP).
IEEE, 2017: 3-18.
3.Truex S, Liu L, Gursoy M E, et al. Towards demystifying membership inference
attacks[J]. arXiv preprint arXiv:1807.09173, 2018.