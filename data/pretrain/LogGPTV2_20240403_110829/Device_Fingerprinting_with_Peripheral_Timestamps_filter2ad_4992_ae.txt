0.1% FPR (denoted as TPR@10−3), which is the same metric
reported by FaceNet [54].
Identiﬁcation and veriﬁcation performance metrics are sum-
marized in Table IV. With 10k devices, FPNET achieves a
56.17% rank-1 accuracy and 87.74% TPR@10−3. For compar-
ison, FaceNet achieves 99.63% TPR@10−3 with a population
size of about 5.7k users. FPNET rank-1 accuracy drops to only
29.7% with 100k devices, while TPR@10−3 remains relatively
unchanged. This is consistent with prior work using triplet
networks for veriﬁcation that found the EER to plateau rather
than decrease as more classes are added [37].
B. User+Device pairing
Recent work has shown that keystroke dynamics enables
user veriﬁcation to be performed at a large scale [37]. TypeNet
is a recurrent architecture that embeds 5-dimensional keystroke
sequences (4 timing features and the JavaScript event keycode)
in a low-dimensional feature space. The model was trained
with triplet loss, albeit without triplet mining, and achieved a
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1027
0100200300400500600Event2575125175225275325375425475Frequency (Hz)0100200300400500600Event2575125175225275325375425475Frequency (Hz)0100200300400500600Event2575125175225275325375425475Frequency (Hz)0100200300400500600Event2575125175225275325375425475Frequency (Hz)SUMMARY OF IDENTIFICATION AND VERIFICATION ACCURACY FOR EACH DATASET AND FEATURE TYPE.
TABLE IV
Population Size
Dataset
Features
10k
Desktop
Mobile
Combined
100k
Combined
Device only
User+Device
Device only
User+Device
Device only
User+Device
Device only
User+Device
Identiﬁcation Accuracy (%)
Rank-1
53.52
85.17
38.74
68.61
56.17
84.75
29.70
63.14
Rank-10
84.47
98.39
77.07
93.18
88.34
98.07
62.89
90.14
Rank-100
96.10
99.77
96.27
98.65
97.70
99.65
88.43
98.21
82.80
96.33
76.00
93.36
87.74
97.31
87.35
97.36
Veriﬁcation Accuracy (%)
TPR@10−3
EER
1.99
0.47
1.84
1.17
1.50
0.54
1.50
0.51
are calculated for population sizes ranging from 10k to 100k
in the combined dataset. Figure 6 compares the device only
and user+device features. The rank-1 accuracy of modern
face recognition systems decreases according to a power law
with population size [59], and we note a similar trend here.
Examining asymptotic behavior in depth, which is necessary
to understand how this kind of system might perform in the
wild, remains an item for future work.
VII. DISCUSSION
A. User vs. device behavior
With timestamps obtained from user input (e.g., typing on
keyboard or moving a mouse), there is an opportunity to
measure both user and device behavior. This was performed
in Section VI-B where we combined phase image embeddings
with time interval embeddings to produce a concatenated
user+device ﬁngerprint. Signiﬁcantly higher identiﬁcation ac-
curacy is achieved with the combined ﬁngerprint. It would
be ideal, however, to control for both the user and device
during data collection in order to measure each ﬁngerprint in
isolation of the other. This is an issue that has actually plagued
keystroke biometrics research in which device-speciﬁc effects
can distort measured typing characteristics [39].
We perform a Mantel test to determine whether user and
device features are independent of each other, considering the
correlation between phase image embedding distances (pre-
sumed device behavior) and time interval embedding distances
(presumed user behavior). The Mantel test is frequently used
in ecology to, e.g., determine whether genetic distances are
correlated with geographic distances [60].
The test works by repeatedly permuting the rows and
columns of one distance matrix and taking Spearman’s rank
correlation coefﬁcient ρ (or another correlation metric) be-
tween the two sets of n(n − 1)/2 unique distances. If the
distances are correlated,
the test statistic of the permuted
distances should be lower than the original distances. The
signiﬁcance p of the test
is given by the proportion of
permutations that have a higher correlation than the original.
The results of the Mantel test indicate negligible correlation for
both desktop (ρ = 0.038, p = 0.001) and mobile (ρ = 0.181,
p = 0.001) devices, supporting feature independence.
Fig. 6.
Identiﬁcation (left) and veriﬁcation (right) accuracy vs pop. size.
2.2% EER with samples containing up to 50 keystrokes and
a population size of 100k users.
We consider pairing user and device behavior by combining
the FPNET embedded vectors with another model inspired
by TypeNet. Summarized in Appendix C, TAUNET (Time
Interval Network) is a RNN that predicts an embedding vector
from the sequence of inter-event times, τ = [τi:{2, . . . , 600} ]
which contains 599 time intervals between 600 events. Note
that unlike TypeNet, TauNet does not require a keycode,
operating only on the time interval between events. Thus, it
could be used for other DOM event types besides keydown
and keyup. TAUNET is trained separately from FPNET but
in a similar regime, using triplet loss with semi-hard online
mining. User+device pairing is performed by concatenating the
FPNET and TAUNET embeddings together, forming a single
256 element feature vector which is then L2 normalized.
Device identiﬁcation and veriﬁcation is performed similar
to the previous section: one-shot learning with a 1-nearest-
neighbor classiﬁer for identiﬁcation. The results are summa-
rized in Table IV, showing performance metrics separately for
phase image (device only) and concatenated (user+device) fea-
tures in addition to device type (desktop, mobile, combined).
One of the main results we’d like to highlight is that rank-1
user+device identiﬁcation can be performed at 63.14% accu-
racy with a population size of 100k. The signiﬁcant increase in
performance with concatenated features suggests that FPNET
and TAUNET each capture very different aspects of the event
timestamps. We discuss and verify this in Section VII-A.
The scaling of accuracy with population size is of interest
to better understand the asymptotic behavior of device ﬁn-
gerprinting. Rank-1 identiﬁcation accuracy and TPR@10−3
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1028
0.20.40.60.81.0Population size (k)1e5020406080100Rank-1 ACC (%)User+deviceDevice only0.20.40.60.81.0Population size (k)1e5020406080100TPR@103(%)User+deviceDevice onlyDEVICE PROFILING ACCURACY. BASELINE=MODE PREDICTION.
TABLE V
Attribute
Num. Unique
Baseline (%)
Proﬁling (%)
Desktop vs. mobile
OS family
Browser family
Device brand
2
2
13
15
70.0
58.0
41.9
47.9
98.7
96.5
74.8
80.8
a particular device model; process scheduling is based on the
particular OS family; and browser families may use different
strategies to optimize the event loop.
To evaluate the potential for system proﬁling, the embedded
phase images are used to predict several host attributes parsed
from the User-Agent (UA) string including: device type (desk-
top vs mobile), OS family, browser family, and device brand.
The problem is treated as a multi-class classiﬁcation problem
using a random forest classiﬁer trained separately for each
target and an 80/20 grouped split between train and test sets,
i.e., train/test set devices are mutually exclusive.
Proﬁling results are summarized in Table V, which reports
the rank-1 classiﬁcation accuracy of each attribute in addition
to the baseline accuracy obtained by labeling everything as the
mode value. Comparison to the baseline accuracy is necessary
since the attributes are largely imbalanced (e.g., there are 15
different device brands in the mobile dataset, but 47.9% are
Apple devices). Despite FPNET not explicitly being trained
to differentiate between host attributes, the embeddings are
indeed representative of various platforms. These results could
perhaps be improved with a model trained explicitly to predict
host attributes from phase images.
D. Ethics
Using a dataset that contains human-computer interaction to
investigate the privacy of Internet users presents several ethical
concerns. First, the data was collected from human subjects on
the Internet and contains observations in the wild [51], [52].
Although the data is publicly available, we obtained IRB
approval to use the dataset in our own study to ensure the
collection protocol met IRB standards at our institution.
Second, the dataset allows training a reasonably accurate
model able to identify users and devices based on peripheral
timestamps. There are indeed valid use cases for such a model,
for example as a transparent second authentication factor
during website interaction or the detection of bots (i.e., as a
CAPTCHA). However, there is a risk that this approach could
be used as a stateless tracking mechanism. We identity some
ways to mitigate this risk in the following section.
E. Mitigations
The ability to measure time from within a sandboxed
environment underlies many side-channel attacks that break
basic browser security policies [64]. Besides conventional
time sources (e.g., the Date and performance APIs), there
exist a variety of implicit clocks within JavaScript, includ-
ing SharedArrayBuffer and the Channel Messaging
Fig. 7. Fingerprint permanence. Embedding distance vs time between samples
for desktop (left) and mobile (right) devices. r=Pearson correlation coefﬁcient.
B. Fingerprint permanence
Reliably identifying devices over extended periods of time
requires the device ﬁngerprint to have permanence such that
the ﬁngerprint is invariant to environmental and operating con-
ditions [61]. Prior work has examined the evolution of browser
ﬁngerprints over time and found that as users make software
upgrades, connect new peripherals, and adjust browser set-
tings, the browser ﬁngerprint can signiﬁcantly change [62].
Like browser ﬁngerprints, peripheral timestamp ﬁngerprints
may evolve over time. Properties of the phase image depend
largely on peripheral hardware, OS family, and browser. As
these elements change, periodic behavior of the device might
also change. Similarly, environmental conditions could affect
DOM event timings, for example as crystal oscillators speed
up or slow down in response to temperature changes [8].
A longitudinal study to evaluate the invariance of phase
image embeddings with respect to environmental conditions
remains an item for future work. Instead through a preliminary
investigation, we quantify the extent to which phase images
change over the relatively short observation periods observed.
The relationship between embedding distance and sample
collection period is shown in Figure 7. The lack of any
signiﬁcant correlation indicates that embedding distance is
consistent over the time periods observed, which ranged from
about 1-5mins on desktop and 1-20mins on mobile devices.
C. System proﬁling
We observed evidence of device clustering, noting at a
minimum that many devices share the same fundamental
frequency (see Section IV). The presence of clusters indicates
that device ﬁngerprints may be partially attributed to software
or hardware properties that are common to a group of devices,
including OS family or device brand, and suggests a potential
for system proﬁling from DOM event timings.
The goal of system proﬁling is to predict host attributes
of some previously unseen device [1]. Compared to device
ﬁngerprinting, which leverages the uniqueness of a device
to track users, system proﬁling reveals private attributes of
the host due to similarities with other known hosts. Doing
so enables an attacker to target exploits that may depend on
browser family, version, or device architecture [63]. Proﬁling
from peripheral timestamps is possible due to platform-speciﬁc
(rather than device-speciﬁc) behaviors in the event processing
pipeline. For example, touch sampling rate may be unique to
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:57:54 UTC from IEEE Xplore.  Restrictions apply. 
1029
050100150200250300350400Time between samples (s)0.000.250.500.751.001.251.50Embedding distancer=0.003Desktop020040060080010001200Time between samples (s)0.250.500.751.001.251.50Embedding distancer=0.008MobileA similar capability could be built into the peripheral itself,
e.g., as a device that sits between the keyboard and the
host [72]. However,
the buffering approach comes with a
tradeoff in that it introduces additional latency between the
user physically pressing a key and seeing a character appear
on screen, adding to the already signiﬁcant input latency that
exists on some systems [12]. Additional complications arise
for touch and mouse pointer input where latency on the order
of 10ms can generally be perceived and spatial (in addition
to timing) features enable user proﬁling [36]. As behavioral
ﬁngerprinting techniques advance, the need for these kinds of
behavioral privacy tools will continue to increase.
VIII. CONCLUSIONS
We introduced a new method to ﬁngerprint devices based
on peripheral input. Keyboard and touchscreen events must
typically pass through a low-frequency polling process before
reaching the browser, and this process can exhibit device-
speciﬁc behavior. Device ﬁngerprints are extracted from a
phase image that contains modular residues of the timestamps.
Within a population of 100k devices observed in the wild,
approximately 29.7k have a unique device ﬁngerprint derived
from 300 keystrokes. Combined with features that capture user
behavior, this increases to 63.1k unique user+device pairs.
The ability to sense user input is ubiquitous among per-
sonal computers, thus the techniques described in this work
have wide applicability. Device ﬁngerprinting could increase
security [25], for example as an additional factor part of a risk-
based authentication scheme [73]. At the same time, device
ﬁngerprinting could be used to illegitimately track users [28].
It is perhaps worth considering these dual uses in the context of
applying mitigations, for example by making high resolution
time sources permission-based [66]. This idea has previously
been proposed but faces a number of challenges, such as
constructing normative language that users can understand (see
[74] and [75] for an informative discussion).
Future work may consider remote device ﬁngerprinting
using the techniques described. Recent work has shown that
some web trafﬁc is highly correlated with user input, opening
the possibility for remote device ﬁngerprinting [76], [77].
The timing of other peripheral sensors is also of interest.
Our approach can be applied to mouse motion events, which
typically occur at a much higher rate than keyboard events
and thus enable ﬁngerprinting with a shorter collection period.
Scroll events can also be generated at a high rate and on
touchscreen devices may reveal touchscreen sampling behavior
in the same way as keydown and keyup events.
Finally, it is worth further investigating what device prop-
erties inﬂuence the timing of peripheral events. Section VII-B
contains a preliminary analysis of ﬁngerprint permanence but
did not examine how device behaviors (e.g., OS processes,
activity in concurrent browser tabs, USB hub contention, etc.)
affect peripheral event timestamps. If any of these sources did
have an effect on event timing, a side or covert channel may