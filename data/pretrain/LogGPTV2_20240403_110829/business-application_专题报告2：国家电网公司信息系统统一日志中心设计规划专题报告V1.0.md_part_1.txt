# 国家电网公司信息系统统一日志中心设计规划专题报告
**信息系统行为安全审计顶层设计组**
**二○一六年三月**

## 目录
1. 日志产品与技术现状 [3](#日志产品与技术现状)
   1.1 主要产品 [3](#主要产品)
   1.2 主要技术 [4](#主要技术)
2. 统一日志管理需求分析 [10](#统一日志管理需求分析)
   2.1 全面的日志采集需求 [10](#全面的日志采集需求)
   2.2 运维可用性监控及应用性能监控需求 [11](#运维可用性监控及应用性能监控需求)
   2.3 安全信息与事件管理需求 [11](#安全信息与事件管理需求)
   2.4 事件关联分析需求 [11](#事件关联分析需求)
   2.5 在线业务统计分析需求 [12](#在线业务统计分析需求)
   2.6 日志快速检索需求 [12](#日志快速检索需求)
   2.7 日志统一存储需求 [12](#日志统一存储需求)
   2.8 符合标准政策规定内控需求 [13](#符合标准政策规定内控需求)
   2.9 业务审计需求 [13](#业务审计需求)
   2.10 其他数据分析支撑需求 [13](#其他数据分析支撑需求)
3. 总体架构 [13](#总体架构)
4. 技术构架 [16](#技术构架)
   4.1 日志采集技术 [16](#日志采集技术)
   4.2 日志存储技术 [18](#日志存储技术)
   4.3 集群资源同步与管理 [19](#集群资源同步与管理)
   4.4 日志分析与计算 [20](#日志分析与计算)
   4.5 搜索引擎技术 [21](#搜索引擎技术)
   4.6 前端服务 [21](#前端服务)
5. 安全保障技术 [22](#安全保障技术)
   5.1 访问控制 [23](#访问控制)
   5.2 网络隔离技术 [23](#网络隔离技术)
   5.3 加密技术 [24](#加密技术)
   5.4 防火墙技术 [24](#防火墙技术)
   5.5 采用入侵检测系统 [24](#采用入侵检测系统)
   5.6 网络安全管理规范 [24](#网络安全管理规范)
6. 非功能性相关设计 [25](#非功能性相关设计)
   6.1 性能 [25](#性能)
   6.2 安全 [25](#安全)
   6.3 易用性 [26](#易用性)
   6.4 可维护性 [29](#可维护性)
   6.5 权限 [30](#权限)

# 日志产品与技术现状

## 主要产品

### 1. Splunk
Splunk 是一款商业化的顶级日志分析软件，能够收集、索引和利用所有应用程序、服务器和设备（物理、虚拟和云端）生成的快速移动型计算机数据。通过单一位置，用户可以搜索并分析所有实时和历史数据。然而，Splunk 收费昂贵，并且在国内缺乏足够的技术支持团队。

### 2. 日志易
日志易是一款配置简单、易于使用的商业化日志管理工具，它支持集中采集和实时索引，提供搜索、分析、可视化和监控告警等功能。尽管如此，该工具在日志的关联分析和深入挖掘方面存在不足，并且缺少对核心资产信息的管理。

### 3. ELK (Elasticsearch, Logstash, Kibana)
ELK 是一套开源的日志管理方案，通过搜集、过滤、传输和存储海量系统和组件日志进行集中管理和准实时搜索、分析。这套方案提供了搜索、监控、事件消息和报表等简单易用的功能。由于是开源框架，很多功能需要二次开发实现，且在二次开发过程中会受到底层基础框架的限制，难以达到预期效果。

## 主要技术

### 1. 监测管理技术
- **OpenTSDB**：一个构建在 HBase 系统之上的实时监控信息收集和展示平台。
- **Ambari**：作为 Hadoop 生态系统的一部分，Apache Ambari 提供了基于 Web 的直观界面，用于配置、管理和监控 Hadoop 集群。此外，Ambari 为开发者提供了 REST API，以便将其功能整合到自定义应用程序中。

### 2. 基准测试技术
- **YCSB**：Yahoo 开发的一款云服务基准测试工具，旨在促进新一代云数据服务系统的性能比较。
- **GridMix**：Hadoop 的集群基准测试组件。

### 3. 数据摄取技术
- **Flume**：一种从其他应用程序收集日志数据并将其送入 Hadoop 的工具，具有强大的容错性和可靠性机制。
- **Sqoop**：用于在关系数据库与 Hadoop 之间传输数据的工具，支持将数据导入 Hive 或 HBase，并从 Hadoop 导出到 RDBMS。
- **Kafka**：一种高吞吐量的分布式发布订阅消息系统，适用于处理大规模网站中的所有动作流数据。

### 4. 序列化技术
- **Avro**：Apache Avro 是一种数据序列化系统，支持丰富的数据结构和紧凑格式，模式使用 JSON 定义，易于与动态语言集成。
- **Protocol Buffers**：一种轻便高效的结构化数据存储格式，适用于数据存储或 RPC 数据交换，具有语言无关和平台无关的特点。

### 5. ETL（提取、转换、加载）技术
- **Crunch**：一个基于 Hadoop 的 ETL 和特征抽取工具，以 Go 语言开发，特点是速度快。
- **Apache Falcon**：面向 Hadoop 的数据处理和管理平台，支持数据移动、协调、生命周期管理和发现。
- **Cascading**：基于 Hadoop 的应用程序开发平台，提供商业支持和培训服务。
- **Oozie**：专为管理 Hadoop 任务而设计的工作流程调度工具，能够根据时间和数据可用情况触发任务，并与 MapReduce、Pig、Hive 和 Sqoop 等工具集成。

### 6. 元数据技术
- **HCatalog**：Apache HCatalog 是一个表和底层数据管理的统一服务平台。

### 7. 分析类库
- **MLlib**：Spark 中常用的机器学习算法实现库，包括相关的测试和数据生成器。
- **SparkR**：一个 R 语言包，使用户能够在 R 语言中使用 Apache Spark。
- **Mahout**：Apache Mahout 是一个开源项目，提供了可扩展的机器学习领域经典算法的实现，支持聚类、分类、推荐过滤和频繁子项挖掘等功能。

### 8. 交互式技术
- **Dremel**：Google 的交互式数据分析系统，能够处理 PB 级别的数据。
- **Drill**：Apache Drill 是一个基于 SQL 的数据分析和商业智能（BI）工具，支持查询固定架构、演化架构以及各种格式的数据。
- **Tez**：建立在 Apache Hadoop YARN 之上，允许构建复杂的有向无环图来处理数据，简化 Hive 和 Pig 的复杂任务。
- **Impala**：Cloudera 开发的新型查询系统，提供 SQL 语义，能够查询存储在 HDFS 和 HBase 中的 PB 级大数据，具有较快的查询速度。
- **Shark**：Hive on Spark，通过 HQL 解析将 HQL 转换为 Spark 上的 RDD 操作，利用 Hive 的元数据获取表信息并在 Spark 上运算。
- **Presto**：一个开源的分布式 SQL 查询引擎，适用于交互式分析查询，支持 GB 到 PB 级别的数据。
- **BlinkDB**：一个大规模并行查询引擎，允许用户通过权衡数据精度来提升查询响应时间。
- **Dryad**：微软的分布式并行计算基础平台，使程序员可以利用数据中心的服务器集群对数据进行并行处理。

### 9. 流式技术
- **Storm**：一个 Apache 项目，提供实时处理大数据的功能，广泛应用于推特、美国天气频道、WebMD、阿里巴巴等公司。