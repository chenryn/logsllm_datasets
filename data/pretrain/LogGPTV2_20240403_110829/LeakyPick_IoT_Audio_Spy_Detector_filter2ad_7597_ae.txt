camera monitors a change in the bitrate of the video can be enforced.
Finally, by correlating scene changes and traffic bitrate changes
cameras, monitoring can be identified.
Cheng et al. [11] propose using the person being monitored to
change the scene by letting them move around. The resulting traffic
is then classified using machine learning. Similarly Liu et al. [29]
focus on altering the light condition of a private space to manipulate
the IP camera’s monitored scene. The resulting stream also changes
its bitrate and can therefore be distinguished from non-altered
streams, e.g., by using the statistical t-test. The above proposals are
completely orthogonal to our approach, as they are customized for
cameras. In addition, they make assumptions that are not applicable
to microphone-enabled IoT devices, e.g., utilizing a variable bit rate
encoding (VBR) and continuous data transmission.
Traffic Analysis: Numerous classification techniques have been
proposed to learn the behavior of IoT devices, distinguishing and
identifying IoT devices based on their traffic profile. Sivanathan
et al. [41] use network traffic analysis to characterize the traffic
corresponding to various IoT devices. They use the activity pat-
tern (traffic rate, burstiness, idle duration) and signalling overheads
(broadcasts, DNS, NTP) as features to distinguish between IoT and
non-IoT traffic. However, the approach requires training. Nguyen et
al. [33] propose an autonomous self-learning distributed system for
detecting compromised IoT devices. Their system builds on device-
type-specific communication profiles without human intervention
nor labeled data which are subsequently used to detect anoma-
lous deviations in devices’ communication behavior, potentially
caused by malicious adversaries. However, these proposals focus
on detecting anomalous behavior not consistent with benign device
actions. In contrast, our goal is to detect benign actions in response
to audio events, which may or may not be falsely detected. Also
our approach does not require the system to identify IoT devices
based on their traffic.
Eavesdropping Avoidance: Microphone, and more specifically,
voice assistant jamming attacks have been proposed by several
prior works. Roy et al. [37] present an approach for inaudibly in-
jecting audio to jam spy microphones using ultrasonic frequencies
and ultrasound modulated noise. As it is inaudible to humans, the
jamming is not interfering with human conversations. Zhang et
al. [50] build upon this work to inaudibly inject commands into
voice assistants, demonstrating that voice assistants and possibly
other commodity IoT devices are susceptible to the proposed ultra-
sonic control. Mitev et al. [30] further build upon these findings
to precisely jam human voice and inject recorded voice into voice
assistants. As discussed in Section 6, inaudible jamming approaches
could be used by LeakyPick to prevent a device from recording
meaningful audio when the user is not aware of it. In future work
we aim to use these approaches as an additional component of
LeakyPick, further increasing the privacy gains of our approach.
Voice Assistant Attacks: Voice assistants using voice recognition
are fairly new and many security and privacy aspects are still to be
improved.The common goal of such attacks is to control the voice
assistant of a user without him noticing.Diao et al. [14] present
attacks against the Google Voice Search (GVS) app on Android. A
Pre-print of paper to be published at ACSAC2020
acmDOI: 10.1145/3427228.3427277
malicious app on the smart phone can activate GVS and simulta-
neously play back a recorded or synthesized command over the
built-in speakers which is then picked up by the microphone, to
control the victim’s voice assistant. Alepis et al. [3] extend upon this
attack. They then proceed to use use multiple devices to overcome
implemented countermeasures by showing that infected devices
can issue commands to other voice-activated devices such as the
Amazon Echo or other smart phones.
Vaidya et al. [46] present a method to change a recording of
human voice so that it is no longer comprehensible by humans but
still correctly recognizable by voice recognition systems. Carlini et
al. [7] extended this work by presenting voice mangling on a voice
recognition system where the underlying mechanics are known,
resulting in a more precise attack. Since a mangled voice may alert
nearby users, Schönherr et al. [40] and Yuan et al. [49] propose
methods for hiding commands inside other audio files (e.g., music
files) such that they are not recognizable by humans. Similarly,
Carlini et al. [8] create audio files with similar waveforms, which
Mozilla’s DeepSpeech interprets as different sentences.
Voice assistant extensions have also been attacked. Kumar et
al. [28] showed that utterances exist such that Alexa’s speech-to-
text engine systematically misinterprets them. Using these findings
they proposed Skill Squatting, which tricks the user into opening
a malicious Skill. Simultaneously, Zhang et al. [51] proposed us-
ing malicious Skills with a similarly pronounced or paraphrased
invocation-name to re-route commands meant for that Skill.
These attacks show that an attacker is able to manipulate the
interaction flow with a voice assistant by, e.g., issuing commands
without the victim noticing, turning voice assistants into a potential
privacy and security risk for the user. LeakyPick can warn the user
if their voice assistant is under attack without him noticing it. When
combined with eavesdropping avoidance (e.g., jamming), the attacks
could be mitigated or even prevented.
8 CONCLUSION
As smart home IoT devices increasingly adopt microphones, there
is a growing need for practical privacy defenses. In this paper,
we presented the LeakyPick architecture that enables detection
of smart home devices that unexpectantly stream recorded audio
to the Internet in response to observing a sound. Conceptually,
LeakyPick periodically “probes” other devices in its environment
and monitors the subsequent network traffic for statistical patterns
that indicate audio transmission. We built a prototype of LeakyPick
on a Raspberry Pi and demonstrate an accuracy of 94% in detecting
audio transmissions from eight different devices with voice assistant
capabilities without any a priori training. It also identified 89 words
that could unknowingly trigger an Amazon Echo Dot to transmit
audio to the cloud. As such, LeakyPick represents a promising
approach to mitigate a real threat to smart home privacy.
ACKNOWLEDGMENTS
We thank our anonymous reviewers for their valuable and construc-
tive feedback. This work was funded by the Deutsche Forschungs-
gemeinschaft (DFG) – SFB 1119 – 236615297.
11
Pre-print of paper to be published at ACSAC2020
acmDOI: 10.1145/3427228.3427277
Richard Mitev, Anna Pazii, Markus Miettinen, William Enck, and Ahmad-Reza Sadeghi
Conference on Mobile Systems, Applications, and Services (MobiSys).
[30] Richard Mitev, Markus Miettinen, and Ahmad-Reza Sadeghi. 2019. Alexa Lied to
Me: Skill-based Man-in-the-Middle Attacks on Virtual Assistants. In Proceedings
of the ACM Asia Conference on Computer and Communications Security (ASIACCS).
[31] David Monsees. [n.d.]. More information about our processes to safeguard speech
data. https://www.blog.google/products/assistant/more-information-about-
our-processes-safeguard-speech-data/
[32] Alfred Ng. 2019. Alexa and Google Assistant fall victim to eavesdropping
https://www.cnet.com/news/alexa-and-google-voice-assistants-app-
apps.
exploits-left-it-vulnerable-to-eavesdropping/
[33] Thien Duc Nguyen, Samuel Marchal, Markus Miettinen, Minh Hoang Dang, N.
Asokan, and Ahmad-Reza Sadeghi. 2018. DÏoT: A Crowdsourced Self-learning
Approach for Detecting Compromised IoT Devices. CoRR abs/1804.07474 (2018).
arXiv:1804.07474 http://arxiv.org/abs/1804.07474
[34] TJ OConnor, Reham Mohamed, Markus Miettinen, William Enck, Bradley Reaves,
and Ahmad-Reza Sadeghi. 2019. HomeSnitch: behavior transparency and control
for smart home IoT devices. In Proceedings of the ACM Conference on Security
and Privacy in Wireless and Mobile Networks (WiSec).
[35] Lawrence Philips. 1990. Hanging on the metaphone. Computer Language 7, 12
(1990).
[36] Raspberry Pi Foundation. [n.d.].
Raspberry Pi 3 Model B.
www.raspberrypi.org/products/raspberry-pi-3-model-b/
[37] Nirupam Roy, Haitham Hassanieh, and Romit Roy Choudhury. 2017. BackDoor:
Making Microphones Hear Inaudible Sounds. In Proceedings of the ACM Interna-
tional Conference on Mobile Systems, Applications, and Services (MobiSys).
[38] Nirupam Roy, Sheng Shen, Haitham Hassanieh, and Romit Roy Choudhury. 2018.
Inaudible voice commands: The long-range attack and defense. In Proceedings of
the USENIX Symposium on Networked Systems Design and Implementation (NSDI).
http://
The CMU Pronouncing Dictionary.
[39] Alex Rudnicky. [n.d.].
https://
www.speech.cs.cmu.edu/cgi-bin/cmudict
[40] Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea
Kolossa. 2018. Adversarial Attacks Against Automatic Speech Recognition Sys-
tems via Psychoacoustic Hiding. arXiv preprint arXiv:1808.05665 (2018).
[41] Arunan Sivanathan, Daniel Sherratt, Hassan Habibi Gharakheili, Adam Radford,
Chamith Wijenayake, Arun Vishwanath, and Vijay Sivaraman. 2017. Charac-
terizing and classifying IoT traffic in smart cities and campuses. Proceedings of
the IEEE INFOCOM Workshop on Smart Cities and Urban Computing (SmartCity)
(2017).
[42] Liwei Song and Prateek Mittal. 2017. Inaudible voice commands. arXiv preprint
arXiv:1708.07238 (2017).
[43] Texas Instruments. [n.d.]. Low-Power, Low-OffsetVoltage, Dual Comparators. https:
//www.ti.com/lit/ds/symlink/lm393-n.pdf
[44] Kevin C. Tofel. 2018. Here’s why smart home hubs seem to be dying a slow,
painful death. https://staceyoniot.com/heres-why-smart-home-hubs-seem-to-
be-dying-a-slow-painful-death/
[45] tp-link. [n.d.]. 150Mbps High Gain Wireless USB Adapter - TL-WN722N. https:
//www.tp-link.com/en/home-networking/adapter/tl-wn722n/
[46] Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine
noodles: exploiting the gap between human and machine speech recognition. In
Proceedings of the USENIX Workshop on Offensive Technologies (WOOT).
[47] Vladimir Vapnik. 2013. The nature of statistical learning theory. Springer science
& business media.
[48] Merriam Webster. [n.d.]. .
[49] Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, and Carl A Gunter. 2018. Com-
manderSong: A Systematic Approach for Practical Adversarial Voice Recognition.
arXiv preprint arXiv:1801.08535 (2018).
[50] Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and
Wenyuan Xu. 2017. Dolphinattack: Inaudible voice commands. In Proceedings of
the ACM Conference on Computer and Communications Security (CCS).
[51] Nan Zhang, Xianghang Mi, Xuan Feng, XiaoFeng Wang, Yuan Tian, and
Feng Qian. 2018. Understanding and Mitigating the Security Risks of Voice-
Controlled Third-Party Skills on Amazon Alexa and Google Home. arXiv preprint
arXiv:1805.01525 (2018).
learn/
REFERENCES
[1] 2020. Scikit-learn Python machine learning library. https://github.com/scikit-
[2] David W Aha, Dennis Kibler, and Marc K Albert. 1991. Instance-based learning
algorithms. Machine learning 6, 1 (1991).
[3] Efthimios Alepis and Constantinos Patsakis. 2017. Monkey says, monkey does:
security and privacy on voice assistants. IEEE Access 5 (2017).
[4] Amazon.
[n.d.].
nizer.
service/speechrecognizer.html
Alexa Built-in Products with AVS - SpeechRecog-
https://developer.amazon.com/de-DE/docs/alexa/alexa-voice-
[5] Leo Breiman. 2001. Random forests. Machine learning 45, 1 (2001).
[6] Dell Cameron. 2018. Hack Can Turn Robotic Vacuum Into Creepy Rolling
Surveillance Machine. https://gizmodo.com/hack-can-turn-robotic-vacuum-
into-creepy-rolling-survei-1827726378
[7] Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
Clay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden voice commands.
In Proceedings of the USENIX Security Symposium.
[8] Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted
attacks on speech-to-text. arXiv preprint arXiv:1801.01944 (2018).
[9] G. Casella and B. Roger. 199. Statistical Inference. Duxbury, 2nd edition.
[10] Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree Boosting Sys-
tem. In Proceedings of the ACM International Conference on Knowledge Discovery
and Data Mining (KDD).
[11] Yushi Cheng, Xiaoyu Ji, Tianyang Lu, and Wenyuan Xu. 2018. DeWiCam: De-
tecting Hidden Wireless Cameras via Smartphones. In Proceedings of the ACM
Asia Conference on Computer and Communications Security (ASIACCS).
[12] Maximilian Christ, Nils Braun, Julius Neuffer, and Andreas W. Kempa-Liehr. 2018.
Time Series FeatuRe Extraction on basis of Scalable Hypothesis tests (tsfresh
– A Python package). Neurocomputing 307 (2018). https://doi.org/10.1016/
j.neucom.2018.03.067
[13] Joseph Cox. [n.d.].
Revealed: Microsoft Contractors Are Listening to Some
Skype Calls. https://www.vice.com/en_us/article/xweqbq/microsoft-contractors-
listen-to-skype-calls
[14] Wenrui Diao, Xiangyu Liu, Zhe Zhou, and Kehuan Zhang. 2014. Your voice
assistant is mine: How to abuse speakers to steal information and control your
phone. In Proceedings of the ACM Workshop on Security and Privacy in Smartphones
& Mobile Devices (SPSM).
[15] DIODES Incorporated. [n.d.]. FILTERLESS 3W CLASS-D STEREO AUDIO AMPLI-
FIER. https://www.diodes.com/assets/Datasheets/PAM8403.pdf
[16] Education First. [n.d.]. 1000 most common words in English. https://www.ef.com/
wwen/english-resources/english-vocabulary/top-1000-words/
[17] Yoav Freund, Robert E Schapire, et al. 1996. Experiments with a new boosting
algorithm. In Proceedings of the International Conference on Machine Learning
(ICML), Vol. 96.
[18] Sarah Frier. 2019.
Facebook Paid Contractors to Transcribe Users’ Audio
Chats. https://www.bloomberg.com/news/articles/2019-08-13/facebook-paid-
hundreds-of-contractors-to-transcribe-users-audio
[19] Google. [n.d.]. Learn about Nest Protect’s automatic Sound Check test. https:
//support.google.com/googlenest/answer/9242130?hl=en
[20] Google. [n.d.]. Learn how Nest cameras and Nest Hello detect sound and motion.
https://support.google.com/googlenest/answer/9250426?hl=en
[21] Andy Greenberg. 2017. This hack lets Amazon Echo ’remotely snoop’ on users.
https://www.wired.co.uk/article/amazon-echo-alexa-hack
[22] Caroline Haskins. 2019. Amazon Is Coaching Cops on How to Obtain Surveillance
https://www.vice.com/en_us/article/43kga3/
Footage Without a Warrant.
amazon-is-coaching-cops-on-how-to-obtain-surveillance-footage-without-a-
warrant
[23] Lente Van Hee, Ruben Van Den Heuvel, Tim Verheyden, and Denny Baert. [n.d.].
Google employees are eavesdropping, even in your living room, VRT NWS has
discovered. https://www.vrt.be/vrtnws/en/2019/07/10/google-employees-are-
eavesdropping-even-in-flemish-living-rooms/
[24] Alex Hern. 2019. Apple contractors ’regularly hear confidential details’ on
Siri recordings. https://www.theguardian.com/technology/2019/jul/26/apple-
contractors-regularly-hear-confidential-details-on-siri-recordings
[25] Hive. [n.d.]. Hive Hub 360. https://www.hivehome.com/products/hive-hub-360
(Accessed June 2020).
[26] Infochimps.com.
[n.d.].
350000
simple
english words.
http:
//www.infochimps.com/datasets/word-list-350000-simple-english-words-
excel-readable
[27] Business Insider. [n.d.]. Google says the built-in microphone it never told Nest users
about was ’never supposed to be a secret’. https://www.businessinsider.com/nest-
microphone-was-never-supposed-to-be-a-secret-2019-2
[28] Deepak Kumar, Riccardo Paccagnella, Paul Murley, Eric Hennenfent, Joshua
Mason, Adam Bates, and Michael Bailey. 2018. Skill squatting attacks on amazon
alexa. In Proceedings of the USENIX Security Symposium.
[29] Tian Liu, Ziyu Liu, Jun Huang, Rui Tan, and Zhen Tan. 2018. Detecting Wireless
Spy Cameras Via Stimulating and Probing. In Proceedings of the ACM International
12