20
C60s
am
250
V60s
pm
y
t
i
s
n
e
D
3
0
0
.
2
0
0
.
1
0
0
.
0
0
0
.
10
20
300
350
40
50
60
30
C60s
pm
0
0
0
0
.
0
50
100
150
V60s
am
Fig. 2. Distributions for Oracle over March 12–16, 2007, ﬁtted to normal distributions
π begins at a time indicated on the x-axis, and continues for dur = 60s. Traﬃc
between servers internal to the monitored network and their clients (internal
or external to the monitored network) was recorded. Plots including external
servers show the same business-cycle dependencies and stability. However, we
ignore external servers because the vantage point of our monitored network will
not allow us to see an external attack on an external server.
Figure 1(a) is plotted logarithmically due to the anomalous activity visible
after 18:00GMT. At this time, multiple bots scanned the monitored network for
Oracle servers. These types of disruptive events are common to all the training
data; we identify and eliminate these scans using Jung et al.’s sequential hy-
pothesis testing method [8]. In this method, scanners are identiﬁed when they
attempt to connect to servers that are not present within the targeted network.
This method will not succeed against hit-list attackers, as a hit-list attacker will
only communicate with servers that are present on the network. Figure 1(b)–(c)
is a plot of the same activity after the scan events are removed: Figure 1(b) plots
|V (Λπ)|, while Figure 1(c) plots |C(Λπ)|.
Once scans are removed from the traﬃc logs, the distribution of traﬃc can
be satisfactorily modeled with normal distributions. More precisely, we divide
the day into two intervals, namely am = [00:00GMT, 11:59GMT] and pm =
[12:00GMT, 23:59GMT]. For each protocol we consider, we deﬁne random vari-
ables V 60s
pm , of which the points on the left and right halves of Figure 1(b)
are observations for Oracle, respectively. Similarly, we deﬁne random variables
am and C60s
C60s
pm , of which the points on the left and right halves of Figure 1(c)
are observations, respectively. By taking such observations from all of March
12–16, 2007 for each of V 60s
pm , we ﬁt a normal distribution to
am and V 60s
am and C60s
am , V 60s
pm , C60s
pm ) and t σ(V 60s
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
pm ) on the right half, and with μ(C60s
283
each eﬀectively; see Figure 2.2 On the left half of Figure 1(b), we plot μ(V 60s
am )
as a horizontal line and t σ(V 60s
am ) as error bars with t = 3.5. We do similarly
with μ(V 60s
am ) and
pm ) and t σ(C60s
μ(C60s
pm ) on the left and right halves of Figure 1(c), respectively.
The choice of t = 3.5 will be justiﬁed below.
In exactly the same way, we additionally ﬁt normal distributions to V 30s
am ,
am , V 30s
C30s
pm for each protocol, with equally good results. And, of course,
we could have selected ﬁner-granularity intervals than half-days (am and pm),
resulting in more precise means and standard deviations on, e.g., an hourly basis.
Indeed, the tails on the distributions of V 60s
am in Figure 2 are a result of
the coarse granularity of our chosen intervals, owing to the increase in activity
at 07:00GMT (see Figure 1(b)). We elect to not reﬁne our am and pm intervals
here, however, for presentational convenience.
am ) and t σ(C60s
pm , and C30s
am and C60s
4.2 Detection and the False Alarm Rate
Our detection system is a simple hypothesis testing system; the null hypothesis
is that an observed log ﬁle Λ does not include a worm propagation. Recall from
Section 4.1 that for a ﬁxed interval Π ∈ {am, pm}, graph size V dur
Π and largest
component size Cdur
Π normally distributed with mean and standard deviation
μ(V dur
Π ) and σ(Cdur
Π ), respectively. As such, for a dur-length period π ⊆ Π, we
raise an alarm for a protocol graph G(Λπ) = (cid:3)V (Λπ), E(Λπ)(cid:4) if either of the
following conditions holds:
|V (Λπ)| > μ(V dur
|C(Λπ)| > μ(Cdur
Π ) + t σ(V dur
Π )
Π ) + t σ(Cdur
Π )
(1)
(2)
Recall that for a normally distributed random variable X with mean μ(X ) and
standard deviation σ(X ),
Pr[X ≤ x] =
1
2
(cid:3)
1 + erf
(cid:5)(cid:6)
(cid:4)
x − μ(X )
√
σ(X )
2
where erf(·) is the “error function” [10]. This enables us to compute the contribu-
tion of condition (1) to the false rejection (alarm) rate frr for a given threshold
t as 1 − Pr[V dur
Π ) + t σ(V dur
Π )], and similarly for the contribution of
−1(·) exists, given a desired frr we can
condition (2) to frr. Conversely, since erf
compute a threshold t so that our frr is not exceeded:
(cid:4)
≤ μ(V dur
(cid:5)
Π
√
2 erf
−1
t =
1
2
− frr
2
(3)
Note that the use of frr
2 in (3) ensures that each of conditions (1) and (2) con-
tribute at most half of the target frr and consequently that both conditions
combined will yield at most the target frr.
2 For all protocols, the observed Shapiro-Wilk statistic is in excess of 0.94.
284
M.P. Collins and M.K. Reiter
Finally, recall that each Λπ represents one dur-length time period π, and frr is
expressed as a fraction of the log ﬁles, or equivalently, dur-length time intervals,
in which a false alarm occurs. We can obviously extrapolate this frr to see its
implications for false alarms over longer periods of time. For the remainder of
this paper, we will take as our goal a false alarm frequency of one per day (with
dur = 60s), yielding a threshold of t = 3.5. This threshold is chosen simply as
a representative value for analysis, and can be adjusted to achieve other false
alarm frequencies.
Π ), σ(V dur
Π ),
and σ(Cdur
Π ) for the time interval Π in which the monitoring occurs. In the
remainder of this paper, we will compute these values based on data collected
on March 12–16, 2007.
This estimate depends on accurate calculations for μ(V dur
Π ), μ(Cdur
5 Protocol Graph Change During Attack
We showed in Section 4 that, for the protocols examined, Cdur
pm and V dur
pm
are normally distributed (Section 4.1), leading to a method for computing the
false alarm rate for any given detection threshold (Section 4.2). In this section,
we test the eﬀectiveness of this detection mechanism against simulated hit-list
attacks. Section 5.1 describes the model of attack used. Section 5.2 describes the
experiment and our evaluation criteria. The detection results of our simulations
are discussed in Section 5.3.
am , V dur
am , Cdur
5.1 Attack and Defense Model
We simulate hit-list attacks, as described by Staniford et al. [20]. A hit list is a
list of target servers identiﬁed before the actual attack. An apparent example of a
Fig. 3. Illustration of attacks, where “C”, “S” and “A” denote a client, server and
attacker-controlled bot, respectively. Attack on left aﬀects total graph size (|V (Λπ)|),
and so depicts graph inﬂation. Attack on right aﬀects largest component size (|C(Λπ)|),
and so depicts component inﬂation.
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
285
hit-list worm is the Witty worm: reports by Shannon and Moore [18] hypoth-
esized that Witty initially spread via a hit list. Further analyses by Kumar et
al. [11] identiﬁed Witty’s “patient zero” and demonstrated that this host be-
haved in a distinctly diﬀerent fashion from subsequently-infected Witty hosts,
lending support to the theory that patient zero used a hit list to infect targets.
We hypothesize that an attacker who has a hit list for a targeted network will
be detectable by examining |C(Λπ)| and |V (Λπ)| where Λπ is a log ﬁle recorded
during a time interval π in which a hit-list worm propagated. We assume that
the attacker has the hit list but no knowledge of the targeted servers’ current
activity or audience. If this is the case, the attacker contacting his hit list will
alter the observed protocol graph through graph inﬂation or component inﬂation.
Figure 3 shows how these attacks impact protocol graphs. Graph inﬂation
occurs when an attacker communicates with servers that are not active during
the observation period π. When this occurs, the attacker artiﬁcially inﬂates the
number of vertices in the graph, resulting in a value of |V (Λπ)| that is detectably
large. The vertices of a protocol graph include both clients and servers, while
the attacker’s hit list will be composed exclusively of servers. As a result, we
expect that graph inﬂation will require communicating with many of the hit-list
elements (roughly t σ(V dur
Π ) for dur-length π ⊆ Π) to trigger condition (1).
Component inﬂation occurs when the attacker communicates with servers al-
ready present in Λπ during the observation period π. When this occurs, the
attacker might merge components in the graph, and |C(Λπ)| will then be de-
tectably large. In comparison to graph inﬂation, component inﬂation can happen
very rapidly; e.g., it may trigger condition (2) if an attacker communicates with
only two servers. However, if the graph already has a small number of compo-
nents (as is the case with SMTP), or the attacker uses multiple bots to attack,
then the attack may not be noticed.
5.2 Experiment Construction
am , Cdur
am , V dur
The training period for our experiments was March 12–16, 2007. We considered
two diﬀerent values for dur, namely 30s and 60s. Table 1 contains the means
and standard deviations for V dur
pm for the training period and
for each choice of dur, which are needed to evaluate conditions (1) and (2). As
shown in Table 1, the largest components for HTTP and SMTP were close to
the total sizes of the protocol graphs on average.
pm and Cdur
An important point illustrated in Table 1 is that the graph sizes can diﬀer by
orders of magnitude depending on the protocol. This demonstrates the primary
argument for generating per-protocol graphs: the standard deviations in graph
size and largest component size for HTTP and SMTP are larger than the mean
sizes for Oracle and FTP.
For testing, we model our attack as follows. During a period π, we collect
a log ctrlπ of normal traﬃc. In parallel, the attacker uses a hit-list set HitList
to generate its own traﬃc log attk. This log is merged with ctrlπ to create a
new log Λπ = ctrlπ ∪ attk. We then examine conditions (1) and (2) for interval
Π ∈ {am, pm} such that π ⊆ Π; if either condition is true, then we raise an
286
M.P. Collins and M.K. Reiter
Table 1. Means and standard deviations (to three signiﬁcant digits on standard devi-
ation) for Vdur
pm for dur ∈ {30s, 60s} on March 12–16, 2007
pm and Cdur
am , Cdur
am , Vdur
HTTP
SMTP
Oracle
FTP
μ
10263
9502
16460
15420
14760
13940
23280
22140
σ
878
851
2540
2420
1210
1180
3480
3320
μ
2653
2100
3859
3454
4520
4069
6540
6200
σ
357
367
336
570
634
650
935
937
μ
65.3
17.52
128.7
30.60
111.8
12.92
240.3
28.84
σ
18.7
4.00
32.4
6.28
28.1
4.24
31.7
8.44
μ
291.9
65.30
359.8
80.02
467.4
37.3
555.5
45.9
σ
57.0
8.10
67.1
8.23
76.9
11.3
94.8
12.2
pm
r.v.
V30s
C30s
V30s
C30s
V60s
C60s
V60s
C60s
pm
pm
am
am
am
am
pm
Table 2. Count of servers observed between 12:00GMT and 13:00GMT on each of
March 12–16, 2007
Protocol Servers
SMTP 2818
HTTP 8145
262
Oracle
FTP
1409
alarm. In our tests, we select periods π of length dur from March 19, 2007, i.e.,
the next business day after the training period.
To generate the HitList sets, we intersect the sets of servers which are observed
as active on each of March 12–16, 2007 between 12:00GMT and 13:00GMT. The
numbers of servers so observed are shown in Table 2. The attacker attacks the