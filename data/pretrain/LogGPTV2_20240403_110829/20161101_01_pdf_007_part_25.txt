 Device: rrqm/s wrqm/s r/s w/s rsec/s wsec/s avgrq-sz avgqu-sz await svctm %util
 cciss/c0d0 0.00 6.00 0.00 1.50 0.00 60.00 40.00 0.01 6.67 6.67 1.00
 cciss/c0d0p1 0.00 6.00 0.00 1.50 0.00 60.00 40.00 0.01 6.67 6.67 1.00
 ...
 cciss/c0d2 0.00 638.50 10.00 217.50 160.00 6444.00 29.03 152.58 707.89 4.40 100.10
 ...
 dm-1 0.00 0.00 10.00 866.50 160.00 6932.00 8.09 446.26 510.49 1.14 100.10
 ...
 平均IO请求等待700多毫秒, PostgreSQL数据文件所处的块设备使用率100%.
 每秒合并的IO写请求638, 读请求没有.
 存在严重的写IO性能瓶颈.
 另外我们还可以观察csvlog的连接记录, 从而得到是否使用短连接.
 如果没有开启连接和断开连接的审计, 因为PostgreSQL是进程模式的, 那么我们可以通过查看操作系统的每秒创建进程数来反映是否存在短连接的情
况.
优化案例
 使用pg_stat_statements查看total_time TOP SQL
 (实际生产场景中, 通过pg_stat_statements可以定位到哪些SQL是最耗CPU或者IO的)
优化案例
 6. 优化手段
 使用异步提交, 或合并wal flush写请求降低写请求数 .
 两种优化手段选一种即可.
 异步提交, 不需要等待wal buffer flush.
 synchronous_commit = off
 wal_writer_delay = 10ms
 pg_ctl reload
 当数据库异常DOWN 机或数据库所在服务器异常DOWN机时, 最多丢失2* wal_writer_delay时间段内的wal信息.
 即数据库恢复时最坏可能只能恢复到DOWN机发生的前2* wal_writer_delay毫秒, 但是可以保证数据一致性.
 合并wal flush写请求. 9.3开始对高并发的短事务wal合并非常有效. 以前的版本没有什么效果.
 commit_delay = 10ms
 commit_siblings = 5
 pg_ctl reload
优化案例
 调整后重新进行压力测试
 pgbench -M simple -n -r -f ./login.sql -f ./logout.sql -c 8 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
 性能提升百分比
 优化后结果分析
 对比每条SQL的耗时, 是否达到预期.
优化案例
 [优化阶段2]
 瓶颈分析与优化
 通过pg_stat_statements查看调用次数较多的SQL, 分析执行计划.
 对于读SQL, 把相关的对象尽量的缓存到内存.
 对于写SQL, 把相关的对象尽量的缓存到内存, 并使用更好的IOPS的块设备(即使用不同的表空间来区分存储).
 同时还需要考虑到大表的年龄, 年龄老化后需要freeze, 会带来大量的读写, 以及wal的写操作. 这些自动或手动的维护性操作要和业务峰值错开.
优化案例
 优化手段
 首先使用pgfincore降低TOP SQL的读物理IO请求数.
 pgfincore的相关文章可参考如下, 利用posix_fadvise接口改变文件访问策略. 可以使文件持久化到内存.
 《use posix_fadvise pre-cache frequency data》
 http://blog.163.com/digoal@126/blog/static/163877040201062944945126/
 《a powerful upgrade from pgfincore 1.0》
 http://blog.163.com/digoal@126/blog/static/1638770402011630102117658/
 《TOAST table with pgfincore》
 http://blog.163.com/digoal@126/blog/static/16387704020120524144140/
 -- 将TOP SQL涉及的对象相对应的活跃数据载入os cache , 前提是内存足够大.
 例如 :
 select pgfadvise_loader('user_info', segment, true, false, databit) from pgfincore('user_info',true);
 以及用到的索引 , toast 对象等.
 如果本地内存不够的话, 可以考虑使用外部缓存, 例如redis, memcache.
 如果想减少缓存和数据库之间的交互, 甚至可以使用PostgreSQL的插件pgmemcache. 已经将memcache的API封装到PostgreSQL的函数中.
 http://blog.163.com/digoal@126/blog/static/163877040201210172341257/
优化案例
 -- 如果内存足够大的话, 也可以将整个对象加载到内存, 例如
 digoal=> select reltoastrelid from pg_class where relname='user_info';
 reltoastrelid
 ---------------
 16424
 (1 row)
 digoal=> select relname from pg_class where oid=16424;
 relname
 ----------------
 pg_toast_16421
 (1 row)
 digoal=> \c digoal postgres
 seYou are now connected to database "digoal" as user "postgres".
 digoal=# select * from pgfadvise_willneed('pg_toast.pg_toast_16421');
 relpath | os_page_size | rel_os_pages | os_pages_free
 ----------------------------------------------+--------------+--------------+---------------
 pg_tblspc/16385/PG_9.1_201105231/16386/16424 | 4096 | 0 | 243865
 (1 row)
优化案例
 digoal=# select * from pgfadvise_willneed('digoal.user_info');
 relpath | os_page_size | rel_os_pages | os_pages_free
 ------------------------------------------------+--------------+--------------+---------------
 pg_tblspc/16385/PG_9.1_201105231/16386/16421 | 4096 | 262144 | 243834
 pg_tblspc/16385/PG_9.1_201105231/16386/16421.1 | 4096 | 262144 | 243834
 pg_tblspc/16385/PG_9.1_201105231/16386/16421.2 | 4096 | 244944 | 243834
 (3 rows)
 digoal=# select * from pgfadvise_willneed('digoal.user_session');
 relpath | os_page_size | rel_os_pages | os_pages_free
 ------------------------------------------------+--------------+--------------+---------------
 pg_tblspc/16385/PG_9.1_201105231/16386/16431 | 4096 | 262144 | 243834
 pg_tblspc/16385/PG_9.1_201105231/16386/16431.1 | 4096 | 33640 | 243834
 (2 rows)
优化案例
 digoal=# select reltoastrelid from pg_class where relname='user_session';
 reltoastrelid
 ---------------
 0
 (1 row)
 digoal=# select * from pgfadvise_willneed('digoal.pk_user_session');
 relpath | os_page_size | rel_os_pages | os_pages_free
 ----------------------------------------------+--------------+--------------+---------------
 pg_tblspc/16385/PG_9.1_201105231/16386/16438 | 4096 | 109680 | 243865
 (1 row)
 digoal=# select * from pgfadvise_willneed('digoal.pk_user_info');
 relpath | os_page_size | rel_os_pages | os_pages_free
 ----------------------------------------------+--------------+--------------+---------------
 pg_tblspc/16385/PG_9.1_201105231/16386/16436 | 4096 | 109680 | 235567
 (1 row)
优化案例
 调整后重新进行压力测试
 pgbench -M simple -n -r -f ./login.sql -f ./logout.sql -c 8 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
 性能提升百分比
 优化后结果分析
 对比每条SQL的耗时, 是否达到预期.
优化案例
 [优化阶段3]
 瓶颈分析与优化
 分析程序代码或数据库csvlog查看是否存在使用简单调用(非绑定变量)的情形.
 本场景客户端连接使用simple协议, 存在一定的可优化空间.
 修改协议为extended, 以及prepared, 查看性能提升多少.
 调整后重新进行压力测试
 pgbench -M extended -n -r -f ./login.sql -f ./logout.sql -c 8 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 8 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段4]
 瓶颈分析与优化
 程序与数据库目前使用的是SQL交互, 使用数据库函数可以减少客户端和数据库的交互次数, 性能还会有一定提升.
 调整后重新进行压力测试
 1. 登陆脚本
 cat login.sql
 \setrandom userid 1 2000000
 SELECT f_user_login(:userid);
 2. 退出脚本
 cat logout.sql
 \setrandom userid 1 2000000
 SELECT f_user_logout(:userid);
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 8 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段5]
 瓶颈分析与优化
 根据经验, 数据库所在服务器的物理CPU核数与活动连接数的比例为2时, 可以发挥CPU的最大性能, 因此如果服务器为8核的话, 压力测试使用16个连
接是能发挥最大效能的.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
 使用更大的连接数(以增加活跃连接)不会再有性能提升.
优化案例
 [优化阶段6]
 瓶颈分析与优化
 IO分布的调整, 适用于物理块设备足够多的硬件环境.
 将xlog, pgdata, 活跃表, 活跃索引的物理块设备隔开, 减少IO争抢.
 通过在不同的块设备上创建表空间, 将对象分布存放到不同的表空间里面.
 块设备遇到IO瓶颈时, 可以考虑使用SSD, 或高端存储.
 分配原则 :
 读活跃索引和读活跃表分开存放, 在内存足够的情况下, 对IOPS能力可以降低要求.
 写活跃索引和写活跃表分开存放, 同时要求IOPS能力足够强大.
 在没有使用异步提交的情况下, xlog要求放在IOPS能力最好的块设备上, 如果开启了异步提交, 可以适当降低IOPS的要求.
 pgdata目录, 在不使用默认表空间存储数据的情况下, 一般对IOPS没有太高的要求.
 stats_temp_directory 对应的统计信息临时存放目录, 选择IOPS能力足够强大的块设备存储
 log_directory和存放数据的块设备隔开存储.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段7]
 瓶颈分析与优化
 当活跃表的SIZE达到一定大小(例如2GB)后, 建议分表.
 例如我们这里把user_info和user_session 这两个频繁更新和读取的表分表后进行测试.
 为了方便测试, 我们直接把表压缩到200万进行测试.
 测试前同样先加载到os cache.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段8]
 瓶颈分析与优化
 SQL语句层面的优化, 本案例不涉及可优化项, 仅仅针对实际的生产场景.
 通过pg_stat_statements找到CPU耗时排前的SQL, 各个击破.
 索引, 改变SQL写法, 改变逻辑, 使用一些插件等.
 例如
 中文分词, 创建分词的gin/gist索引加速检索.
 http://blog.163.com/digoal@126/blog/static/163877040201422410175698/
 数组或多值变量的空间索引, gin索引
 近似度查询
 http://blog.163.com/digoal@126/blog/static/1638770402013416102141801/
 分区优化
 http://blog.163.com/digoal@126/blog/static/163877040201422293824929/
 减少数据库运算开销
 count优化, 随机访问优化, ...
 更多参考
 http://blog.163.com/digoal@126/blog/#m=0&t=1&c=fks_084071080084080064085080095095085080082075083081086071084
优化案例
 [优化阶段9]
 瓶颈分析与优化
 横向扩展1, 日志表和业务表分开到独立的数据库集群.
 降低CPU争用, 解决CPU瓶颈.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段10]
 瓶颈分析与优化
 横向扩展2, 读写分离
 适用于业务库CPU瓶颈, 使用流复制或第三方插件如(londiste3)将可以进行读写分离的表复制到额外的数据库集群.
 读负载均衡分发到slave节点, 写还在master节点.
 注意slave节点的延迟, 流复制带来的延迟最小, londiste3对DML频繁的场景延时比流复制大.
 读写分离的实现 :
 不推荐使用pgpool-II, pgpool本身比较容易产生瓶颈, 建议使用pgbouncer或者jdbc-HA或者程序内分配多数据源.
 http://blog.163.com/digoal@126/blog/static/1638770402014413104753331/
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段11]
 瓶颈分析与优化
 横向扩展3, shared nothing
 业务库推荐使用plproxy来做shared nothing.
 《A Smart PostgreSQL extension plproxy 2.2 practices》
 http://blog.163.com/digoal@126/blog/static/163877040201192535630895/
 http://blog.163.com/digoal@126/blog/static/1638770402013102242543765/
 注意跨库事务的问题, plproxy不支持跨库事务. 需要程序在逻辑层面解决.
 还需要考虑事务一致性备份和还原. 目前plproxy不能简单的实现整个shared nothing集群的一致性备份和还原, pg-xc可以.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
优化案例
 [优化阶段12]
 瓶颈分析与优化
 本优化案例的未来扩展方向
 select能力可以通过数据库流复制扩展, 9.2以后可以级联复制因此基本上可以做到不影响主库性能的情况下无限扩展.
 insert能力可以通过增加logdb服务器扩展, 无限扩展.
 update能力可以通过将表拆分到多个服务器上, 无限扩展.
 调整后重新进行压力测试
 pgbench -M prepared -n -r -f ./login.sql -f ./logout.sql -c 16 -j 8 -T 180 -h 172.16.3.33 -p 5432 -U digoal digoal
Thanks
 Q&A