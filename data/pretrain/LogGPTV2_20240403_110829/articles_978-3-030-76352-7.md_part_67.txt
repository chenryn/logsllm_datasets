# Makers Enact Laws and Regulations to Promote Trust through Appropriate Security, Privacy, and Reliability

As defined by Kosseff [1], "Cybersecurity law promotes the confidentiality, integrity, and availability of public and private information, systems, and networks through forward-looking regulations and incentives. The goal is to protect individual rights and privacy, economic interests, and national security."

© Springer Nature Switzerland AG 2021  
H. Hacid et al. (Eds.): ICSOC 2020 Workshops, LNCS 12632, pp. 433–443, 2021.  
https://doi.org/10.1007/978-3-030-76352-7_40

## 434 G. Delorme et al.

This contribution will not be limited to cybersecurity laws but will also incorporate laws that contain sections related to regulating data processing, even if their primary purpose is not cybersecurity.

### Challenges in Implementing Legal Requirements

The implementation of all requirements found in these laws can be challenging for organizations subject to multiple laws. Since non-compliance is sanctioned, understanding the risks these laws may represent is vital. As new laws are continuously enacted, the complexity of complying with different requirements increases, as does the risk of non-compliance.

We introduce a new risk definition: **Data Regulation Risk (DRR)**. DRR originates from the possibility of a penalty from a regulatory agency following evidence of non-compliance with a norm governing data processing, ICT governance, and processes, and/or information technologies and services. We then discuss the need for adequate methodologies, frameworks, and tools for risk managers to effectively assess DRR and ensure compliance at an acceptable cost.

### Structure of the Contribution

This contribution is structured as follows:
- **Section 2** will present trust as the foundation of data regulations.
- **Section 3** will introduce how these laws create a new risk for organizations, which we call DRR. Based on a literature review, **Section 4** will discuss the limits of existing frameworks and risk management methodologies in regard to Data Regulation Risk management.

## 2. Data Regulation as the Baseline for Trust

Organizations operate in highly competitive and uncertain markets, requiring them to identify, assess, mitigate, and, if needed, take risks. They develop their risk strategies considering their relationships and available information on other market actors. Crafting such strategies involves managing future uncertain events. Market actors must find ways to establish and ensure lasting trust among them by reducing uncertainty [2].

### 2.1 Defining Trust

Scholars from diverse disciplines have discussed and presented insightful views regarding the causes, nature, and effects of trust in different contexts and areas of research. Various contrasting concepts of trust have been developed across disciplines and domains, resulting in distinctive definitions [3]. Among these, operational and internal definitions of trust dominate. The former relates to game theory [4], implying rational decision-making processes and risk aversion based on foreseen gains and losses. The latter describes trust as a state of belief, referring to one's acceptance of vulnerability based on their belief or positive expectations regarding the motivations and behaviors of others [5]. Uncertainty decreases as communication and the exchange of information increase [6].

#### Trust as the Intersection of Privacy, Security, and Reliability

As raised by Gefen et al. [7], trust evolves and can grow over time. Trust is then considered a requirement for a stable relationship by affecting one’s risk appetite [8]. Camp presented the three-dimensional concept of trust, defining it as the intersection of privacy, security, and reliability [9]. By focusing on the existence of a risk rather than its quantification, this operational definition is based on risks rather than risk perception.

On the basis of the three-dimensional concept of trust, security is not privacy but a means to provide the ability to generate privacy by enabling the control of digital information. Security by itself, therefore, does not necessarily imply privacy or trust [5]. Similarly, security is not reliability but a means to provide resilience, contributing to the belief in the integrity or authority of the trusted party. Finally, security is not a separable element of trust. In other words, not only does trust include technological challenges, but it also requires a deep understanding of the interactions and motivations of the involved parties to build both the human concept of trust and privacy [9].

#### Trust in IT Context

In the context of cloud services, data processing, and more broadly, IT-related topics, trust might be referred to as increasing positive predictability. It is then reached by ensuring sufficient security, accuracy, transparency, and accountability regarding data processing. Trust draws the ambition of reaching a perceived risk level sufficiently low for an organization to use third-party services or for a consumer to entrust organizations with the handling of personal data. As perfect competition is not realistic, reaching an absolute uncertainty-free state is not possible [10]. Organizations must, therefore, reduce uncertainty by increasing predictability through commitment, transparency, and security. They may develop and implement controls to prevent undesirable and harmful events, which reinforce overall confidence if combined with adequate communication and commitment [5].

### 2.2 Data Regulation Addressing the Three Aspects of Trust

To achieve the protection of individuals' rights and privacy, economic interests, and national security, policymakers have enacted countless laws and regulations [1]. The focal point of these regulations is promoting trust through the confidentiality, integrity, and availability of public and private information, systems, and networks. Policymakers can ensure the expected state of trust through different ways: regulating data processing or the use of technology and services.

#### Privacy and Security

Policymakers and governments attempt to protect individuals' rights and privacy by regulating individuals' data processing and empowering individuals to take ownership of their personal data and rights. Their goals are to guarantee the confidentiality of personal data by setting security requirements and ensuring full transparency over their processing, access, or disclosure. Moreover, they ensure personal data integrity by providing individuals the right to access their personal data and request corrections if needed. Trust is then obtained by increasing transparency, empowerment of individuals, and information sharing.

In Europe, the General Data Protection Regulation (GDPR) is a legal framework that sets the rules and guidelines for the collection and processing of personal information from individuals [11]. Article 1 of the GDPR states that the purpose of the regulation is to "lay down rules relating to the protection of natural persons with regard to the processing of personal data and rules relating to the free movement of personal data, protecting fundamental rights and freedoms of natural persons and, in particular, their right to the protection of personal data while ensuring the free movement of personal data within the European Union" [11]. Similar privacy regulations have been enacted worldwide, such as the California Consumer Privacy Act (CCPA) or the Personal Data Protection Act in Singapore (PDPA) [12, 13].

#### Reliability and Security

Data processing encompasses the collection, consultation, use, disclosure, storage, and erasure of data [11]. Policymakers may regulate these actions in multiple ways. Data access and disclosure may be supervised, controlled, and limited. Access to regulated data may be limited to certain nationalities, a need-to-know basis, the geographical localization of the request or accessing the data, or the data storage location. Limiting and controlling data processing by controlling access or storage in a fragmented IT environment with many parties inevitably reinforces the trust of the different market actors.

For instance, the Export Administration Regulations (EAR) state that exporting any item subject to the EAR to another country or re-exporting any item of U.S. origin may require a license and, therefore, prior authorization from the Bureau of Industry and Security (BIS). Additionally, the EAR also forbids access to EAR items and related data to specific countries and end-users [14].

The use of certain types of technology can be fully allowed, restricted, or forbidden by regulations. Since only trusted technology is allowed in the processing of such regulated data, it reinforces the trust in the different actors by increasing transparency and security. One key component in ensuring the security of information systems and, thus, data, is encryption technology. The use of encryption technology can be prohibited, subject to conditions such as providing the keys to the government, or subject to prior government approval [15]. For example, U.S. regulations such as the Defense Federal Acquisition Regulation Supplement (DFARS) [16], International Traffic in Arms Regulations (ITAR) [18], and EAR only allow encryption modules validated by the Cryptographic Module Validation Program. Laws may also supervise the export or import of certain technologies, such as "dual-use" technologies [14], which may restrict firms' access to specific technology.

Some regulations may limit the choice of a supplier or service provider, as they require compliance with specific certifications or place restrictions on certain nationalities of the provider in addition to technological requirements [11, 14]. A service provider's information systems may also be conditioned to specific security requirements, restrictive internal processes, certification, or government approvals [14].

## 3. A Risk Originating from Data Regulation Enforcement

Policymakers establish, through legal texts, different sets of rules and obligations that both public and private organizations must follow. Following the basis of reduction theory [17] and information theory [18], policymakers ensure trust through greater exchange of information, decrease of uncertainty, and increase of perceived predictability. For the purpose of this contribution, this section will focus on laws regulating data processing, information technology, and services. Finally, we present a definition of a new multi-disciplinary risk class inherent to Data Regulation.

### 3.1 Enforcing Data Regulation

It is necessary for companies to understand the different legal requirements to ensure their compliance and reach the Data Regulations' objectives. Provided with official technical documentation, guidelines, and reference points, companies are able to meet these requirements by reducing their margin of errors and misinterpretation [11, 14]. The possibility of foreseen penalties in case of non-compliance forces organizations to consider and properly assess Data Regulation Risk.

#### Assessing Non-compliance

To ensure the respect of the laws, policymakers may force the company to be audited by either external or regulatory agencies. The audit may arise prior to an event at the discretion of the authorities or after evidence of a security breach to determine whether the company was compliant at the time the breach occurred. Only regulatory agencies or appointed institutions can perform such audits and are not always required to notify a given company ahead of time. In case of litigation with a third party or an individual, the authorized authority may request a company audit at its sole discretion. Policymakers may also make companies accountable for assessing the compliance of their service providers by foreseeing audit clauses in their contractual agreements [11]. In addition to the audit right, laws may embed a voluntary disclosure clause, forcing the enterprise to disclose security breaches within a limited time after their discovery [11]. Finally, laws may also foster company self-denouncement or individual denunciation of a company's non-compliance [14, 19, 20].

#### The Penalties Resulting from Non-compliance

Once non-compliance is proven and known to a regulatory agency, the company may be sanctioned. Based on the interpretation of the law, jurisprudence, and foreseen penalties in the text, a company may be sanctioned economically in a monetary fine or in capacity to perform activities in markets for a period of time [16]. In addition, data breach disclosure may be required by authorities, forcing firms to notify impacted individuals [11]. A disclosure may lead to indirect consequences such as an impact on the company's reputation, loss of trust, or impact on stock prices [21].

Another impact for individuals is the personal risk they take when making decisions subject to compliance issues. Individuals are made to engage their personal liability and are personally accountable for the decisions taken while performing their job. Purposely failing to comply with or violating regulatory compliance may not only expose the company to administrative penalties but also the individual at the origin of the non-compliance to criminal penalties [14, 19, 20].

#### The Documentation to Meet the Requirements

Laws and regulations do not always define how to implement the necessary controls but may only refer to appropriate technical and organizational measures that are to be defined by each enterprise. To avoid misinterpretation and provide organizations with the freedom to adapt the technical requirements to cope with evolving technologies, regulations may refer to additional documents such as frameworks, certifications, or guidelines [13, 14, 16]. These documents may change over time and may originate from appointed public entities such as the Singaporean Personal Data Protection Commission [22], the French Data Protection Commission (Commission Nationale de l'Informatique et des Libertés) [23], the American National Institute of Standards and Technology (NIST) [24], governments, or other private organizations like the International Organization for Standardization (ISO) [25]. The documents address various points such as technological solutions [13], monitoring of activities [24], governance, roles, and responsibilities [11, 20], or even audit methodology SOX AS5 [26]. Organizations may refer to the available documents to guide them in implementing adequate controls and ensuring compliance.

### 3.2 Data Regulation Risk

The above sections allow us to identify that first, the different data regulations promote trust while ensuring the protection of individuals' rights and privacy, economic interests, or national safety. Second, the Data Regulation frames organizations' data processing, internal governance, and processes along with the use of technology and services. Finally, these norms ensure their application through diverse means and force organizations' compliance or risk sanctions from a regulatory agency.

#### A Unique Risk

The norms foresee two different types of sanctions in case of non-compliance: business sanctions and criminal charges. The penalties may only be pronounced by a norm authority, are context-dependent, and depend on an external appreciation of the norm.

Indeed, Data Regulation Risk (DRR) does not originate from classic IT-related risks such as data breaches but from the possibility of being sanctioned following a proven non-compliance. Only the awareness of the failure to comply with the different restrictions on data processing, internal governance, and processes, information technologies, and services may lead to a penalty. In other words, a security breach may not necessarily lead to penalties if compliance with the law is proven. Additionally, based on jurisprudence and interpretations, non-compliance may not necessarily result in penalties. For instance, the absence of prejudice caused by a data breach may not trigger a GDPR penalty. Non-compliance that does not lead to a sanction may, therefore, not constitute a DRR.

DRR, therefore, derives from the possibility of a penalty and not the non-compliance, nor a security breach or legal uncertainty. Only penalties originating from a regulatory agency may be the source of DRR, despite the risk being based on external and internal factors. Internal factors may be the decision not to comply with the norm, voluntary disclosure, or involuntary failure to comply. External factors may be the disclosure of a data breach, the result of an external audit, etc.

#### The Definition

DRR arises from specific laws that seek to address IT risks to protect individuals' rights and privacy, economic interests, and national security. The risk is, therefore, intrinsically linked to data processing, information technologies, and services. Legal norms that are not regulating data or the technology and services around them are, therefore, excluded from the scope of DRR. Penalties can only be pronounced based on documented non-compliance of a company. They are based on antecedents, which are events occurring under the scope of a law and that are proven and known. They only occur if a company fails to demonstrate its compliance and if the regulatory agency is aware of the established non-compliance. Penalties or any kind of negative impact that are not resulting from the evidence of a firm's non-compliance are, therefore, not in the scope of DRR. In summary, a DRR is a risk originating from the possibility of a penalty from a regulatory agency following evidence of non-compliance with a norm governing data processing and/or ICT governance and processes and/or information technologies and services.

## 4. Addressing Data Regulation Risk

This section contains a brief description of the existing work focusing on IT frameworks, information security, and risk management. This literature review aims to highlight the impact and contribution of our definition in respect to existing works.

### 4.1 Frameworks to Address Data Regulation Risk

Following the guidelines of Reconstructing the Giant: On the Importance of Rigor in Documenting the Literature Search Process [26], we used a wide scope of sources to cover relevant publications in cybersecurity, compliance, information risk management, information security, and legal disciplines. We focused on relevant publications from business, public administration, and academia, querying for the keywords: Information Security, IT Framework, IT compliance, Information Security Risk Management (ISRM), and regulatory risk in Google Scholar.

#### Frameworks Specificities

This literature review aims to highlight the impact and contribution of our definition in respect to existing works. We, therefore, conducted an exhaustive review including English literature only, with the following selective criteria: articles discussing one or more industry-leading IT frameworks (limits, scope, deployment, and implementation, selection), articles comparing IT frameworks (complementarity, overlaps, and controls mapping), and articles discussing Information Security Risk Management.

As a result of our literature review, we constructed Table 1 to evaluate the adequacy of industry-leading frameworks with the mandatory elements present in our definition. Numerous works can be found on how to efficiently map different frameworks to group similar controls, ensure broader coverage, and optimize integration costs [27–30].

| **Framework** | **Data Processing** | **ICT Governance** | **ICT Processes** | **Information Technologies and Services** |
|---------------|---------------------|--------------------|-------------------|------------------------------------------|
| **COBIT**     | -                   | -                  | -                 | ++                                       | ++                                      | -                                       | -                                       |
| **ITIL**      | -                   | -                  | -                 | +                                        | ++                                      | +                                       | ++                                      |

Table 1: Topics addressed by Frameworks