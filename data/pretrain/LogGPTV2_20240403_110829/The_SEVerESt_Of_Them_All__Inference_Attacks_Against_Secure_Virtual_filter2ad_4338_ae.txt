We exploit the fact that the target of the attack (i.e., the OpenSSH
server) performs a series of sanity checks during the public-key au-
thentication process. Specifically, first it checks whether the auth
orized_keys file exists, and if so, verifies the permissions of the
directory structure holding the file. If the checks are satisfied, the
contents of the file are read and the authentication process attempts
to verify the key. This sequence allows one to build a unique appli-
cation profile. In our instantiation of the attack, when the trigger
(i.e., a sequence of system calls that indicate the reading of the user
authorized_keys) is detected, the malicious hypervisor executes
the man in the middle attack.
Next, we need only hyper-step the copy_user_generic() rou-
tine in the kernel. First, the contents of the kernel buffer are copied
to the userspace buffer. Next, when the copy is complete (i.e., when
the counter value in register ECX reaches 0), we artificially increase
the amount of data to be copied. We then feed the faux key to
the user space buffer by modifying the data in the source register.
Finally, the return value of the system call (stored in a register) is
adjusted to reflect the new length of the data.
5.2.1 Under the hood. Similar to the TLS proof of concept, the
change in RIP, the register changes, and the type of memory ac-
cesses are all used to unmask the sequence of instructions. In Fig-
ure 4, the order of the registers used in the store section (red arrow)
is guessed based on the order of the instructions in the load section
(green arrow). That is, we assume the information is written in
the same order as it was read. In the case of the inferred jnz we
know from the change of the instruction pointer that the instruc-
tion is a jump, because of the negative change of RIP. Additionally,
the previously decoded instructions indicate a decrement of the
counter register RCX, and so we surmise that the jump is of the form
“jump if zero flag is not set" (i.e., jnz). The other instructions and
operands are exactly unmasked from the observed change in RIP,
the identification of the memory access type, and the determination
of what register was accessed.
However, unlike in the previous case, the initial cost of finding
the fine-grained trigger is significantly less. Based on the semantics
6Static analysis of the Nginx binary and the 35 shared libraries it loads revealed that
the sequence we use is unique.
7 https://elixir.bootlin.com/linux/v4.15/source/arch/x86/include/asm/uaccess_64.h#L36
8See https://elixir.bootlin.com/linux/v4.15/source/arch/x86/kernel/cpu/amd.c#L623
Session 2A: SGX-based SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand815.3 Attack on SEV-ES: Application
Fingerprinting
To show that we can successfully identify applications running in
a SEV-ES protected enclave, we performed an empirical evaluation
using Cloudsuite [39]. Cloudsuite offers a series of benchmarks for
cloud services, and uses real world software stacks under realistic
workloads. The web serving benchmark consists of a web server
(Nginx) with the accompanying infrastructure (i.e., PHP, MySQL,
Memcached) serving an open source social network engine called
Elgg. In our setup, the benchmark is hosted in a virtual machine
running Ubuntu.
Our reference datastore, R, consists of binary fingerprints gen-
erated from the disassembly of all the system binaries of Ubuntu
(i.e., /bin/ /sbin /usr/sbin /usr/bin /systemd). R consists of 1465
entries. At runtime, we generate partial fingerprints for unknown
applications using a custom tool based on the AMD IBS Research
Toolkit [3]. The modifications were done to reduce the number of
samples collected from the host OS and to restrict data collection
to the CPU core running the guest VM. We are able to sample once
every eight hundred instructions due to the skid in IBS.
To get a sense of the diversity of the layouts in R, for all pairs
i, j, we examine the matching subsequences in (cid:174)ri and (cid:174)rj. We say
that two applications have identical layouts if they have the same
number of functions |(cid:174)ri| = | (cid:174)rj|, and the lengths of the respective
functions are equal. Our analyses show that the length of matching
subsequences is indeed a strong indicator of binary similarity; for
example, the longest matching sequence for distinct applications
in R had only six elements. Obviously, the load on the server and
the duration of the observation period have direct impact on the
quality of the fingerprints we collect at runtime. Intuitively, an
idle application will generate a limited amount of performance
data. Additionally, given the sampling frequency limitations of IBS
(see §4.3), there is no way to guarantee that the observed IBS data
will contain return instructions. Thus, the longer (cid:174)u is, the more
confidence we can have in knowing whether it matches one of the
target applications in R.
5.3.1 Results. To that end, the load of the VM was varied by is-
suing varying number of login requests to the Elgg community
site running in the targeted VM. Our results show that in cases in
which we collected fingerprints comprising more than three dis-
tances, we can successfully identify all the applications belonging
to the Cloudsuite web serving benchmark (i.e., Nginx, PHP, MySQL
and memcached) as well as other system applications (e.g., systemd,
snapd). Table 3 presents the relationship between the average num-
ber of return instruction given varying number of web requests,
as well as the true and false positive rates. At |(cid:174)u| > 3, we attain
a TP rate of 1 and FP rate of 0.000006. If we allow the adversary
to collect more data, the FP drops to 0.0 once |(cid:174)u| > 6. Even at that
threshold, the overhead is negligible. To measure overhead, we
averaged the processing time of 100 login requests. We observed an
average overhead of 30 µs, which is imperceptible to an end-user.
More interestingly, we find that this binary fingerprinting tech-
nique can even distinguish between applications and compiler ver-
sions. To demonstrate that, we extended R to include the disassem-
bly of 10 different versions of Nginx compiled using two versions
of GCC. For example, two recent versions of Nginx (v1.15.8 and
Figure 4: Abstraction of going from observed register changes to
unmasked instructions. The underlined instructions are inferred
based on contextual information within the scope of the analysis.
of the observed system call, the target code section, and the informa-
tion available when the trigger is detected, we can limit the amount
of hyper-steps required to reach the critical instructions. Specifi-
cally, when the trigger (i.e., read system call) is detected, arguments
of that system call including the pointer to the destination buffer are
visible to the introspection mechanism. We set a hardware break-
point on the destination buffer pointed to by the second argument
of the SYS_read system call. This allows us to avoid hyper-stepping
through the kernel virtual file system function stack and instead
start the introspection inside the copy_user_generic() function.
To be sure that we can now safely extend the loop without un-
wanted side effects in the guest, we assure that in the observed trace
there is a change of register state matching the tuple [RIP+4,RSI+64;
RIP+4,RDI+64; RIP+2,RCX -1] and RCX has reached zero. Once
satisfied, we inject our faux key.
5.2.2 Results. For the attack, we inject a 2048-bit RSA public key
belonging to the adversary. The key length (512 bytes) mandates
that we complete 8 iterations of the loop (in Figure 4) to inject the
key into the SEV-protected guest. Pulling off the attack requires
a mere 160 hyper-steps, which is imperceptible during the SSH
session establishment process. Henceforth, the adversary is free
to execute any code within the VM and poke around at will.
Recovered InstructionsObserved SequenceRIP DeltaRegister changeMemory Accessstart:movq r8,   [rsi]3r8readmovq r9,   [rsi+8]4r9readmovq r10, [rsi+16]4r10readmovq r11, [rsi+24]4r11readmovq [rdi],       r83writemovq [rdi+8] ,  r94writemovq [rdi+16], r104writemovq [rdi+24], r114writemovq r8,   [rsi+32]4r8readmovq r9,   [rsi+40]4r9readmovq r10, [rsi+48]4r10readmovq r11, [rsi+56]4r11readmovq [rdi+32], r83writemovq [rdi+40], r94writemovq [rdi+48], r104writemovq [rdi+56], r114writeleaq rsi, [rsi+64]4rsi+=64leaq rdi, [rdi+64]4rdi+=64decl ecx2ecx-=1jnz start-72S t o r eL o a dT r i g g e rS t o r eL o a dSession 2A: SGX-based SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand82Table 3: Application Identification Success Rate
# of HTTP
requests
5
10
25
50
Avg. #of
return instr.
3.78
6.91
14.06
23.48
TP rate
1
1
1
1
FP rate
(|(cid:174)u | > 3)
7.1 ∗ 10−6
1.42 ∗ 10−5
0
0
v1.14.2) compiled using the same compiler (GCC version 7.3) shared
a sequence of 108 distances. On the other hand, the same version
of Nginx compiled using two different versions of GCC (v7.3 vs
v5.4) had no shared sequences. Our evaluation shows that given
fingerprints longer than four distances we are able to distinguish
the exact version of an application. As long as we collect one re-
turn instruction that falls outside of the matching sequence of two
versions of the same application, we can distinguish between them.
The ability to precisely identify software running within an en-
crypted VM has far reaching implications. First, an honest cloud
provider can use application fingerprinting to identify potentially
unwanted software and violations of acceptable use policy. On the
other hand, a malicious adversary performing reconnaissance using
the IBS-based inference attack gains valuable insight that can be
leveraged for further attacks, e.g., ROP. Identifying the specific ver-
sion of an application has the advantage that it allows an adversary
to target specific vulnerabilities. Third, the IBS data can be used
to undermine user space Address Space Layout Randomization
(ASLR). Recall that ASLR randomizes module base addresses (i.e.,
the address at which the application is loaded in memory). Since
(cid:174)u is built using the virtual addresses of return instructions, once
(cid:174)u is matched to some (cid:174)r, the adversary can use that knowledge to
compute the base address of r — thereby defeating ASLR.
6 DISCUSSION AND POTENTIAL
MITIGATIONS
Although AMD is the first vendor to provide a commodity solution
for transparently encrypting guest memory, there is a large body
of work that attempts to protect the confidentiality and integrity of
application data even in the event of OS or hypervisor compromise
[5, 9, 11, 15, 18, 25, 47, 48, 50, 51, 55, 56]. Henson and Taylor [23]
provide a systematic assessment of many of these approaches. Per-
tinent to this work are the ideas in Overshadow [9], where isolation
capabilities of the virtualization layer are extended to allow protec-
tion of entities inside of a virtual machine via a technique called
cloaking. A similar idea was also proposed by Xia et al. [56], but
with the touted advantage of having a smaller trusted computing
base for their shim. Our work demonstrates in a definitive way that
the access to general purpose registers and an ability to interrupt
the guest, are sufficient to unveil executing instructions and recover
data that is otherwise stored in an encrypted memory and storage.
None of these works take into account protection against this new
class of inference attacks presented herein.
Unfortunately, while SEV-ES prevents the hypervisor from in-
specting and modifying general purpose registers, virtualization
support for this extension has only just become available.9 Until
the support for SEV-ES matures, we offer an interim solution that
limits the ability of the hypervisor to force automatic exits as a way
9A modified Linux kernel is available at: https://github.com/AMDESE/linux/commits/sev-
es-4.19-v2. The code enabling SEV-ES was made available on May 17, 2019
to mitigate the register inference attacks. The hypervisor should
never be allowed to intercept any events that are under the control
of the guest. But, this is no easy feat, as there is an extensive list [2,
§15.9-15.12] of intercepts and traps, many of which are supported
for legacy reasons (e.g., access to control register 3 that was used
in shadow page table implementations), debugging functions, or
obscure functionality. Nevertheless, we suggest the use of trap and
interrupt masks that are applied by the processor to the trap and
interrupt vectors saved in the virtual machine control block. During
the transition from the hypervisor to the guest using the VMRUN
instruction, the processor should raise the general protection fault
if the intercept and trap controls in the VMCB do not conform to the
allowed masks. The masks and the change of the VMRUN instruction
could be delivered in the form of a microcode update for the main
CPU, similarly to the way microcode patches were distributed to
mitigate the Spectre and Meltdown vulnerabilities [1].
Per our structural inference attack on SEV-ES, the knee-jerk re-
action might be to disable the IBS subsystem. However, it is possible
to use software workarounds [3] to enable IBS in software. Worse,
it is not possible for the guest to determine whether IBS is enabled
or not, since the hypervisor ultimately controls the Model Specifics
Registers used to program the IBS subsystem. Moving forward, to
prevent the application fingerprinting attack, we suggest that the
performance measurement subsystem differentiate the data col-
lected from the guest and the host and discard the samples from
the guest when secure encrypted virtualization is enabled.
7 CONCLUSION
To address cloud confidentiality, virtualization technologies have re-
cently offered encrypted virtualization features that support trans-
parent encryption of memory as a means of protection against
malicious tenants or even untrusted hypervisors. In this paper, we
examine the extent to which these technologies meet their goals.
In particular, we introduce a new class of inference attacks and
show how these attacks can breach the privacy of tenants relying
on secure encrypted virtualization technologies. As a concrete case
in point, we show how the security of the Secure Encrypted Vir-