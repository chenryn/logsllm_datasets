除了可以使用默认的策略，也支持灵活的自定义策略。相较于jsoup，自带了正则匹配内容的方法。
简单解释下上面的代码中自定义策略的部分。
allowElements(allowTags)，表示允许指定的所有标签；
allowAttributes(safeAttributes)，表示允许的属性，后面接的globally()方法表示全局，也就是对所有标签生效；
allowUrlProtocols(“http”,”https”).allowAttributes(“src”).onElements(“img”)，表示允许img标签使用src属性，并且属性值仅支持http、https协议的url；
allowAttributes(“href”).matching(whiteUrl).onElements(“a”)，表示a标签的href必须能够通过正则表达式的校验，否则该属性会被删除掉，后面接requireRelNofollowOnLinks()，表示强制增加rel=nofollow属性。
更多使用方法请参考官方文档：
官方的例子中还有Ebay和Slashdot的过滤策略，写的比较复杂，感兴趣的读者也可以学习一下：  
OWASP还有一个AntiSamy项目： 
，主要用法是使用xml配置文件配置白名单策略。源码：
OWASP Java HTML Sanitizer的页面介绍里讲自己比AntiSamy快4倍，这里就不展开了。
**其他服务端开发语言过滤组件**
.NET：  
Golang：  
PHP：  
Python：  
Django框架（Python）：
###  前端过滤
**js-xss**
前端将数据渲染到页面呈现之前，也可以对内容进行一次过滤。这里推荐使用js-xss模块。除了可以在页面里直接引入js使用，同时也支持node.js，当使用node.js做服务端时，也可以参照前面的方案，在数据传入时使用该模块进行过滤。
源码：  
项目主页： 
Demo：
    options = {
        whiteList: {
        a: ["href", "title", "target","xxx"],
          },
      };  // 自定义规则
    html1 = filterXSS("aaa", options);
    console.log(html1);
    html2 = filterXSS("aaa");
    console.log(html2)
执行结果：
支持通过wihteList字段自定义规则，如果未指定规则，将会使用默认规则。
默认的白名单在getDefaultWhiteList函数中。
    function getDefaultWhiteList() {
      return {
        a: ["target", "href", "title"],
        abbr: ["title"],
        address: [],
        area: ["shape", "coords", "href", "alt"],
        article: [],
        aside: [],
        audio: [
          "autoplay",
          "controls",
          "crossorigin",
          "loop",
          "muted",
          "preload",
          "src",
        ],
        b: [],
        bdi: ["dir"],
        bdo: ["dir"],
        big: [],
        blockquote: ["cite"],
        br: [],
        caption: [],
        center: [],
        cite: [],
        code: [],
        col: ["align", "valign", "span", "width"],
        colgroup: ["align", "valign", "span", "width"],
        dd: [],
        del: ["datetime"],
        details: ["open"],
        div: [],
        dl: [],
        dt: [],
        em: [],
        figcaption: [],
        figure: [],
        font: ["color", "size", "face"],
        footer: [],
        h1: [],
        h2: [],
        h3: [],
        h4: [],
        h5: [],
        h6: [],
        header: [],
        hr: [],
        i: [],
        img: ["src", "alt", "title", "width", "height"],
        ins: ["datetime"],
        li: [],
        mark: [],
        nav: [],
        ol: [],
        p: [],
        pre: [],
        s: [],
        section: [],
        small: [],
        span: [],
        sub: [],
        summary: [],
        sup: [],
        strong: [],
        strike: [],
        table: ["width", "border", "align", "valign"],
        tbody: ["align", "valign"],
        td: ["width", "rowspan", "colspan", "align", "valign"],
        tfoot: ["align", "valign"],
        th: ["width", "rowspan", "colspan", "align", "valign"],
        thead: ["align", "valign"],
        tr: ["rowspan", "align", "valign"],
        tt: [],
        u: [],
        ul: [],
        video: [
          "autoplay",
          "controls",
          "crossorigin",
          "loop",
          "muted",
          "playsinline",
          "poster",
          "preload",
          "src",
          "height",
          "width",
        ],
      };
    }
node.js安装：
    npm install xss
使用方法：
    var xss = require('xss');
    var options =  {
        whiteList: {
        a: ["href", "title", "target","xxx"],
          },
      };
    var html = xss('aaa', options);
    console.log(html);
执行结果：
    aaa
源文件xss.js中safeAttrValue(tag, name, value,
cssFilter)函数中对标签属性进行了过滤。项目文档里写了常见的用法，代码也写的比较清晰，有需要的可以直接查阅文档或代码。
## 四、标签属性安全使用建议
1、href、src属性需要校验协议  
如果未校验，攻击者可以使用javascript:伪协议插入执行恶意的js代码。
2、什么情况a标签要加rel=”nofollow”属性？
这个属性的意思是告诉搜索引擎不要追踪此链接。如果A网页上有一个链接指向B网页，但A网页给这个链接加上了rel=”nofollow”
标注，那么搜索引擎不会把A网页计算入B网页的反向链接。搜索引擎看到这个属性就会取消链接的投票权重。
简单来讲，有些搞SEO的人，会在各大网站插入很多带有超链接的垃圾信息，如果强制加了rel=“nofollow”属性，搜索引擎爬到了，也不会给对方增加权重。这样搞恶意SEO的人，就没兴趣在你的网站里插垃圾信息了。
所以要不要加这个属性，取决于你的业务是否需要防止上述情形。
3、哪些属性被认为是安全的？
`align, alink, alt, bgcolor, border, cellpadding, cellspacing, class, color,
cols, colspan, coords, dir, face, height, hspace, ismap, lang, marginheight,
marginwidth, multiple, nohref, noresize, noshade, nowrap, ref, rel, rev, rows,
rowspan, scrolling, shape, span, summary, tabindex, title, usemap, valign,
value, vlink, vspace, width.`
以上是OWASP整理的安全属性，可以放心使用。参考：  
4、iframe标签安全使用建议
建议不要使用，如果一定要用，可以通过下面几个方式降低风险：
  * src属性必须校验协议，限制http和https，同时进行url白名单正则校验，限制内容为可信域名，防止攻击者插入恶意页面。
  * 固定长宽，或限制最大长宽，防止子页面覆盖父页面。
  * 使用沙箱（sandbox）机制，遵循权限最小化原则配置相应选项满足业务需求。
sandbox 详细可参考  
iframe特性全解读：   
sandbox 属性：
5、style属性，建议不要使用。
原因参考：基于css注入的向量  
如果需要支持用户控制样式，建议使用class属性，针对不同的值提前定好对应的样式。
实在非要使用style属性的话，那就自己把属性值提取出来，解析后再做一层白名单过滤吧（如果写不好，会存在绕过的可能）。
6、script标签严禁用户插入，这个相信不用解释了。
7、上面提到的这些内容不能保证全面，超出范围的，建议咨询熟悉的专业安全人员。
## 五、其他常见场景、对应问题和解决方案
###  1、富文本内容被WAF（Web应用防火墙）拦截
有些公司的WAF规则比较严格，对请求中包含某些标签内容的，会直接判定为攻击，进行拦截。
通常WAF是站在企业整体安全的角度去做防护的，不能因为业务的某一个功能点，去降低整体的防护能力。这时，可以考虑使用以下方案去满足业务需求：
图中蓝色线条是在原有常规方案基础上的改动。即在前端解析富文本内容的DOM树，转换为json格式，之后提交给服务端，服务端进行白名单过滤。
html和json的转换，可以考虑使用类似html2json功能的组件来实现：  
注意，这种方案绕过了WAF的防护，请务必保证白名单策略的安全！请务必保证白名单策略的安全！请务必保证白名单策略的安全！
###  2、内容来自文件导入
有的业务场景，需要从文件批量导入内容，并且内容还要支持富文本，流程如下：
这种场景下，可以在服务端提取到内容后对富文本内容进行白名单过滤，之后再进行持久化存储。对于业务上不需要支持富文本的字段，直接按照传统XSS的防护方案进行特殊字符转义就好。
###  3、内容从用户指定的外部网页爬取
除非有特别强烈的需求，否则不建议做这样的功能，从安全角度讲绝对是坑。
这种场景里，由于要爬取用户指定的第三方页面，所以首先需要完善的SSRF漏洞防护方案（这是另一个话题，这里不展开）。之后按照前面讲的方案对内容进行过滤。
###  4、生成html文件存储到服务器上
不建议使用这样的方案实现功能，小网站有这样做的，通常互联网企业里这种实现方式本身就违背了开发规范。
笔者以前有一次做渗透时，遇见过某个系统生成的还是jsp文件，插入java后门代码直接就拿到了服务器控制权。
###  5、服务端生成html文件上传至云存储
这里我们要假设云存储的html页面会对业务造成安全威胁，比如钓鱼攻击、业务子域名cname解析或者cdn到云存储服务，可以导致XSS影响业务。
这种场景与文章开头的方案之间的区别只是内容持久化存储的位置发生了变化，只要在服务端上传文件之前，对内容进行过滤即可。
###  6、前端生成html文件上传至云存储
不要使用这种方案！不要使用这种方案！不要使用这种方案！这种方案由于内容不经过自己的业务服务器，没有办法对内容进行过滤处理。在这样的方案里，前端的无论怎么做，对安全都是不起作用的。
###  小结
以上是笔者见过的一些比较经典的场景，有些业务场景可能是上面每个场景不同部分的组合。  
从中抽象出本质，不外乎“输入->白名单过滤->持久化->白名单过滤->输出”。通常更多的富文本使用场景会选择在输入时后端做过滤。如果有特殊需求，比如想完整保留用户输入的数据，那么也可以选择在输出时进行过滤。
行文仓促，考虑不足之处，欢迎各位师傅给出指导、建议或补充。
* * *
**漏洞悬赏计划：涂鸦智能安全响应中心（ ）欢迎白帽子来探索。**
**招聘内推计划：涵盖安全开发、安全测试、代码审计、安全合规等所有方面的岗位，简历投递sec#tuya.com，请注明来源。**