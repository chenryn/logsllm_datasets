O
t
t
O
O
*
*
t
t
This means observable network trafﬁc—the common assump-
tion of a network attacker with Dolev-Yao capabilities.
2
1
in tr1,
1 and trn(cid:6)
In general, having strong communication infrastructure and
observable network trafﬁc still does not entirely solve our
problem. Part of it concerns not communication alone, but also
the order of the individual component transitions. Consider
, trn2(cid:8) where trn1
(cid:8) and tr2 = (cid:7)trn(cid:6)
the traces tr1 = (cid:7)trn1, trn(cid:6)
and trn2 match and produce local observations o1 and o2,
respectively, and trn(cid:6)
2 are local transitions that produce
local secrets s1 and s2, respectively. Then sl = (cid:7)(1, s1), (2, s2)(cid:8)
and ol = (cid:7)(o1, o2)(cid:8) are valid shufﬂes of these secrets and
the secret comes after the
observations. However,
(communicating) observation, while in tr2 it comes before.
Hence, it is not possible to shufﬂe tr1 and tr2 to a trace that
(cid:6) =(cid:7)(2, s2), (1, s1)(cid:8)).
produces sl (since the only possibility is sl
This difﬁculty resides at the heart of our security model:
BD Security prescribes a relation, or
rather a lack of
(co)relation, between observations and secrets produced by a
trace, but does not, in general, constrain the time ordering
between the production of these observations and secrets. This
loose coupling is useful for the local veriﬁcation of individual
systems: not having to worry about the time ordering between
observations and secrets allows for ﬂexibility in the proof
strategy. However, when composing systems, it leads to the
problem that, in general, the bound of the compound system
cannot “foresee” which time orderings that arise from freely
mixing the component secrets and observations are actually
possible, potentially causing compositionality to fail.
Our case study suggests a way out of this conundrum:
The above cannot occur because the second component never
produces secrets by individual transitions, but only via commu-
nication: isSec2(trn2) always implies isCom2(actOf2(trn2)).
Let us analyze this last property. In a system composed of
several nodes, such as CoSMeDis, it is natural to think of a
source of a secret as a node that produces the secret not by
communication with other nodes, but by communication with
the outside world. Note that, for simplicity, (P1) considers the
conﬁdentiality of only one arbitrary but ﬁxed post PID of Aut1.
(Appendix E shows an extension to multiple posts in arbitrary
nodes across the network.) Hence, users can “upload” secrets
in Aut1 via updatePost actions, but the only contact of Aut2
with this secret is via receivePost actions in pair with sendPost
actions by Aut1. In this context, Aut2 is never the source of
the secret, but can only receive it (as well as, possibly, send it
back to the issuer or make it available to its users). Thus, we
have secret polarization, with Aut1 being the issuing pole.
VI. ABSTRACT FRAMEWORK FOR COMPOSING SECURITY
We distill the previous discussion into a framework for
composing security in arbitrary communicating I/O automata.
A. Compositionality Theorem for Two Components
Let Aut1 and Aut2 be two I/O automata and let match :
Trans1 × Trans2 → Bool be a predicate for matching transi-
tions. We let Aut be the match-product of Aut1 and Aut2,
written Aut1×match Aut2, deﬁned in Section IV-B. We use the
notations and terminology from that section, e.g., isComi.
737
Furthermore, we ﬁx the security property (P1) for Aut1,
with its attacker model consisting of the secrecy infrastruc-
ture (Secret1, isSec1, getSec1) and observation infrastructure
(Obs1, isObs1, getObs1) and its security policy consisting of
the trigger T1 and the bound B1. We also ﬁx the security
policy (P2) for Aut2, with similar notations.
Finally, we ﬁx two matching predicates for observations,
matchO : Obs1 × Obs2 → Bool, and secrets, match : Sec1 ×
Sec2 → Bool. We call the triple (match, matchO, matchS) the
communication infrastructure.
In summary, the parameters of our compositionality the-
orems are two I/O automata, one security property for each,
and a communication infrastructure. We now deﬁne the as-
sumptions of the theorem, as discovered in Section V-B.
Deﬁnition 2. (1) The communication infrastructure is called
compatible if, for all trn1 and trn2, match(trn1, trn2) implies:
• isSec1(trn1) holds iff isSec2(trn2) holds, and in this case
matchS(getSec1(trn1), getSec2(trn2)) holds
• isObs1(trn1) holds iff isObs2(trn2) holds, and in this case
matchO(getObs1(trn1), getObs2(trn2)) holds
(2) The communication infrastructure is called strong if,
for all trn1 and trn2, assuming
• isCom1(actOf1(trn1)) ∧ isCom2(actOf2(trn2))
•
•
isObs1(trn1) ∧ isObs2(trn2) →
matchO(getObs1(trn1), getObs2(trn2))
isSec1(trn1) ∧ isSec2(trn2) →
matchS(getSec1(trn1), getSec2(trn2))
then match(trn1, trn2) holds.
(3) The attacker models of
(P2) are
trn1
isCom1(actOf1(trn1)) implies isObs1(trn1) and
said to have observable network trafﬁc if,
and trn2,
isCom2(actOf2(trn2)) implies isObs2(trn2).
(P1) and
for all
(4) The attacker models of
for all
to be secret-polarized if,
isCom2(actOf2(trn2)).
(P1) and (P2) are said
isSec2(trn2) implies
trn2,
sl ∈ sl1 || sl2 ∧ sl
The composed security property, (P) = (P1) || (P2), is de-
ﬁned as follows. Its attacker model ((Secret, isSec, getSec),
(Obs, isObs, getObs)) is deﬁned as in Section V-B, e.g.,
Obs = Obs1 + Obs2 + Obs1 × Obs2. Moreover,
its security
policy (B, T) is deﬁned as indicated in that section, namely,
in more formal notation (where || is the shufﬂe operator for
secrets, deﬁned using matchS):
(cid:6)) iff ∀sl1, sl2, sl
(cid:6)
(cid:6)
B(sl, sl
1, sl
2.
2 → B1(sl1, sl
(cid:6) ∈ sl
1 || sl
(cid:6)
(cid:6)
T(trn) iff (∃trn1, σ2. trn = sep1(trn1, σ2) ∧ T1(trn1)) ∨
(∃σ1, trn2. trn = sep2(σ1, trn2) ∧ T2(trn2)) ∨
(∃trn1, trn2. trn = com(trn1, trn2) ∧ (T1(trn1) ∨ T2(trn2)))
Theorem 1. Assume
• the communication infrastructure is compatible and strong
• the attacker models of (P1) and (P2) have observable
network trafﬁc and are secret-polarized.
(P1) holds for Aut1 and (P2) holds for Aut2,
If
(P1) || (P2) holds for Aut1 ×match Aut2.
1) ∧ B2(sl2, sl
(cid:6)
then
(cid:6)
2)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:13 UTC from IEEE Xplore.  Restrictions apply. 
Let us discuss the requirements of this theorem:
Compatible Communication Infrastructure, asking that
not only the component transitions, but also their secrets and
observations are composable. This is essential for being able
to formulate,
the composition of security
guarantees—so this is a prerequisite to the very question about
compositionality. As this paper’s examples illustrate, producing
a compatible communication infrastructure comes naturally
from inspecting the interaction between communication on the
one hand and secrets and observations on the other.
let alone prove,
Strong Communication Infrastructure and Observable
Network Trafﬁc, asking that communication between the
components be substantially exposed. This requirement
is
clearly an artifact for achieving compositionality. It may be
argued that it is counter-intuitive to “allow” the attacker such
power. However, the requirement needs to be regarded from
the opposite angle: It is not about weakening the system by
offering power to the attacker, but about showing that, even
if the attacker could observe most of the communication, he
would still not learn the secrets. In our case study, we achieved
communication strength by letting the attacker observe every-
thing in a communication except for sensitive information.
Secret Polarization, asking that only one of the compo-
nents can issue secrets. For multi-user systems, this means
that, once we agree on what the secrets are, only users of
one component can upload secrets. Note that this does not
prevent us from considering another notion of secret, where
the other component is the issuer. For example, in our case
study the secrets are the post contents for a post ID, which can
belong to either component—the requirement only prevents us
from considering two sources at the same time, e.g., in order
to speak of the concatenation of secrets from two sources.
The requirement seems to be fulﬁlled by a speciﬁc category
of secrets, namely,
those produced and stored locally, on
a single node (and possibly communicated to other nodes).
However, it is easy to imagine situations when it breaks—if we
allowed users of different nodes to upload versions of the same
(shared) post or Facebook-like photo album, or to jointly edit
documents asynchronously. Consequently, secret polarization
is the major limitation of our result. One workaround is to
communicate each modiﬁcation of a secret on a different node
back to the source immediately, which is then responsible for
merging and propagating such modiﬁcations. This is similar to
a single-master (or master-slave) model in database replication
[60], with a designated master node for each secret. In contrast,
a multi-master model, where different nodes perform modiﬁca-
tions of a secret concurrently and merge them asynchronously,
is not supported by our framework. In Appendix E, we discuss
another workaround for combining multiple sources of secrets
after composition, provided these sources are independent of
each other in a certain sense—this applies to the secret sources
in CoSMeDis, but does not address the limitation in general.
The main strength of our result is its policy agnosticism:
While the theorem requirements restrict the component at-
tacker models, they say nothing about the security policies, i.e.,
their bounds and triggers. Hence, the theorem composes any
given security policies, no questions asked. This “quantitative”
ﬂavor makes our theorem applicable in a variety of contexts,
to seamlessly combine arbitrarily complex policies—as we
illustrate in Section VII. These include declassiﬁcation during
the process of inter-component communication. Indeed, as our
examples abundantly illustrate, communication transitions can
inﬂuence both the attacker models and the security policies.
However, policy agnosticism has an inconvenience: Its
general-purpose property composition may not be, in concrete
cases, the most natural desired property for the compound
system. For our running example, such a natural property is:
(P’) A coalition consisting of two groups of users, UIDs1 of
Aut1 and UIDs2 of Aut2, can learn nothing about the updates
to the content the Aut1’s post PID beyond the existence of an
update unless one of the following holds:
1) one of UIDs1 is the admin or PID’s owner, or becomes
friends with the owner, or PID is marked as public
2) PID is being shared between Aut1 and Aut2 and [one of
UIDs2 is the admin or becomes a remote friend of PID’s
owner, or PID is marked as public]
This reads almost like (P1) || (P2). In particular, the trigger
T is clearly that formalized by (P1) || (P2): the disjunction
of the component triggers. However, (P’)’s bound, phrased as
“beyond the existence of an update,” is not verbatim captured
by (P1) || (P2)’s bound B.
Fortunately, we can easily derive (P’) from (P1) || (P2)
using a general-purpose theorem for transfer between two
security policies. Let Aut be an I/O automaton and (P) and
(P’) two security properties operating on it. (P) is said to have
a stronger security model than (P’) if there are two partial
functions f : Sec (cid:3) Sec
from the secrets
and observations of (P) to those of (P’) that preserve the
secrecy and observation infrastructures, the bounds and the
triggers. (Details are given in Appendix A.)
Theorem 2. Assume (P) has a stronger security model than
(P’). If (P) holds for Aut, then so does (P’).
and g : Obs (cid:3) Obs
(cid:6)
(cid:6)
B. The N-ary Case
We aim to establish conﬁdentiality for the entire distributed
system, not just for two components. For our case study, we
want to prove the following for every post PID belonging to a
component Auti in a network of n components Aut1, . . . , Autn:
(P”) A coalition of n groups of users, UIDsk for each Autk,
can learn nothing about the updates to PID’s content beyond
the existence of an update unless one of the following holds:
friends with the owner, or PID is marked as public
1) one of UIDsi is the admin, or is PID’s owner, or becomes
2) the post is being shared by Auti with some Autk for k (cid:10)= i
and [one of UIDsk is the admin or becomes a remote
friend of PID’s owner, or PID is marked as public]
To this end, we generalize the communicating product
automaton construction from 2 to n mutually communicating
components Autk. We ﬁx, for each k, k(cid:6) with k (cid:10)= k(cid:6), a matching
predicate matchk,k(cid:6) : Transk × Transk(cid:6) → Bool (between the
transitions of Autk and Autk(cid:6)). We write match for the family
(matchk,k(cid:6))k,k(cid:6) and isComk,k(cid:6) : Actk → Bool for the correspond-
ing notion of communication action (belonging to Autk, and
pertaining to communication with Autk(cid:6)). We assume that
communication is pairwise dedicated, in that the predicates
isComk,k(cid:6) and isComk,k(cid:6)(cid:6) are disjoint for k(cid:6) (cid:10)= k(cid:6)(cid:6).
738
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:13 UTC from IEEE Xplore.  Restrictions apply. 
SEPi
σi
ai−→
oi
σ(cid:6)
i
(σk)k
∀ j. ¬ isComi, j(ai)
(σk)k[i := σ(cid:6)
]
i
(i,ai)−→
(i,oi)
σi
ai−→
oi
σ(cid:6)
i
σ j
a j−→
o j
σ(cid:6)
j
COM
(σk)k
i (cid:10)= j matchi, j((σi, ai, oi, σ(cid:6)
−→
, j := σ(cid:6)
((i,ai),( j,a j))
((i,oi),( j,o j))
(σk)k[i := σ(cid:6)
]