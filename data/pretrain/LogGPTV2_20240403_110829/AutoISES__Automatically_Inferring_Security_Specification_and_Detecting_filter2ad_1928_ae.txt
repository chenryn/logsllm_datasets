same operation
Interprocedural analysis with
function pointer analysis
Sec.
1.2 &
3.2
3.1
4.2.1
4.2.4
4.3
6.2 Generalization
Although many of the solutions described above are de-
signed for inferring security speciﬁcations and detecting
security violations, some of the ideas are general, and
can be applied to other applications. For example, our
security rules are an important type of function-data cor-
relation. Such function-data correlations widely exist in
programs. Violating these implicit constraints results in
buggy programs that may cause severe damage. Our
techniques can be used to infer those general function-
data correlations, e.g., a lock acquisition function re-
quired before accessing shared data structures, which can
be used for detecting concurrency bugs. In addition, the
strategy of using multiple implementations of the same
virtual API to generate more precise rules is generally
applicable to situations where source code at the virtual
API level is not sufﬁcient to generate reliable rules.
6.3 Limitations
False Negatives Similar to previous static analysis
work, our approach can miss security violations. First,
USENIX Association  
17th USENIX Security Symposium 
391
if a security check function is not invoked at all (e.g.,
security sk classify flow is not used in Linux
2.6.11 yet) or the list of security check functions is in-
complete, we would not be able to infer rules or detect
violations related to these missing check functions.
Additionally, our analysis uses only data structure ac-
cesses to represent a security operation. Therefore, if the
source code of such low-level accesses is not available,
AutoISES will not be able to extract information about
them, and the representation of the sensitive operation
would be incomplete, potentially causing false negatives.
Moreover, AutoISES does not verify if the security
check is performed on the same object as the sensitive
operation. Therefore, if the proper security check is in-
voked, but on a different object, AutoISES will not de-
tect this violation. Matching the actual object remains as
our future work. Additionally, our ﬂow-insensitive anal-
ysis could introduce false negatives. For example, if a se-
curity check is missing on a taken branch, but the check
is invoked on the non-taken branch, AutoISES may not
be able to detect the violation. Using a ﬂow-sensitive
analysis could address this problem.
Difﬁculty in Verifying Violations We manually exam-
ine error reports and warning reports to determine if a
report is a true violation or a false positive. Unlike er-
rors such as buffer overﬂows and null pointer derefer-
ences, which are usually easy to conﬁrm after the error
is detected, the manual veriﬁcation process for security
violations is more difﬁcult. To decide if a violation is ex-
ploitable, one needs to understand the semantics of the
code, knowing what operations can interact with the un-
trusted space, such as the user space for Linux, and de-
sign a feasible way to exploit the attack. Conversely, to
determine if a violation is a false positive, one needs to
prove that either the operation is security insensitive, or
that it is indeed covered by a security check that was not
included due to analysis imprecision. Sometimes it re-
quires deep knowledge of not only the target software,
but also how the APIs are used by client software (e.g.,
the example discussed in Section 5.1.2). Such difﬁculties
are mostly due to the inherent characteristics of security
violations. However, we imagine that the task would be
much easier for the original developers as they possess
deep semantics knowledge of the code.
Non-authorization Checks A small number of se-
curity checks are not authorization checks, which do
not protect any security operations.
For example,
security sk free() should be called after using a
kernel sk buffer to clear sensitive data. Our current im-
plementation does not support such rules where a secu-
rity check function must be invoked after a certain opera-
tion. However, such rules can be easily supported by ex-
tending our current implementation to include the post-
operation checks.
7 Related Work
Mining Security Sensitive Operations Ganapathy et
al. used concept analysis to ﬁnd ﬁngerprints of security
sensitive operations [15]. While both this approach and
AutoISES try to map the high level security sensitive
operation (e.g., rmdir) to its implementation (e.g., the C
code sequences that actually perform the remove direc-
tory operation), there are two major differences. First,
the goals and assumptions are different. We aim to iden-
tify the pairing relationship between a security check and
the code level representation of the sensitive operation
that the check guards. Thus we assume the code already
implements a reference monitor and is mostly correct;
our goal is therefore to discover cases where the refer-
ence monitor is bypassed. Ganapathy’s goal, on the other
hand, is to retroﬁt code with security. Thus they assume
that the code does not have security built in. Rather, they
need to identify sequences of code that represent a unit of
security sensitive operation and that should be guarded
by a security hook. In order to do that they need more
prior knowledge with regard to the API and the secu-
rity sensitive data structures. In our case, all informa-
tion except the list of security check functions, and the
list of system call functions and hypercall functions, is
inferred from the code itself. Second, while our inferred
operations are used directly by our checker without being
examined manually, their operations still require manual
reﬁnement prior to use.
Although automatic hook placement is promising, it
has not been adopted in reality yet. Therefore, while we
should encourage automatic hook placement, it is still
highly desirable to seek alternative, complementary so-
lutions that can automatically infer security rules from
existing or legacy source code and detect security vul-
nerabilities.
Detection and Veriﬁcation Tools The past years have
seen a proliferation of program analysis and veriﬁcation
tools that can be used to detect security vulnerabilities or
verify security properties [2, 4, 5, 6, 9, 12, 14, 16, 18, 27,
30]. However, no previous work can automatically gen-
erate code-level security speciﬁcations and instead re-
quire developers or users to provide these speciﬁcations.
Previous work [30] takes manually identiﬁed simple se-
curity rules to check for security vulnerabilities. As dis-
cussed in details in Section 1, the rules are coarse and
imprecise, resulting in many false alarms. Additionally,
the approach can potentially fail to detect cases where the
check and the operation does not match because the rules
do not specify which check is required for which opera-
tion. Edwards et al. dynamically detect inconsistencies
392 
17th USENIX Security Symposium 
USENIX Association
between data structure accesses to identify security vul-
nerabilities [9]. While a dynamic approach is generally
more accurate, it suffers from coverage problem - only
code that is executed can be analyzed. In addition, it re-
quires manually written ﬁltering rules to guide the trace
analysis in order to detect security violations.
Inferring Programming Rules Several
techniques
have been proposed to infer different types of program-
ming rules from source code or execution trace [3, 10,
11, 20, 22, 24]. As already discussed in Section 1, pre-
vious techniques is not directly applicable to our prob-
lem, because they are limited by the types of rules they
can infer. Speciﬁcally, Engler et al. extract programming
rules based on several manually identiﬁed rule templates,
such as function A and B should be paired, func-
tion F  must be checked for failure, and null pointer
P  should not be dereferenced [10]. PR-Miner fo-
cuses on inferring correlations among functions [20].
Variable value related program invariants are inferred
by Daikon [11], and MUVI[22] infers variable-variable
correlations for detecting multi-variable inconsistent up-
date bugs and multi-variable concurrency bugs. A few
other approaches infer API and/or abstract data type re-
lated rules[3, 24]. Different from all these studies, we in-
fer rules related to security functions protecting a group
of data structure accesses based on our key observa-
Inferring different types of rules requires differ-
tion.
ent techniques.
In addition, dynamic analysis is used
in [3, 11], therefore the coverage is limited because only
instrumented and executed code is used for rule learning.
Moreover, unlike PR-Miner which uses only intraproce-
dural analysis, our analysis is interprocedural, which is
one of the key techniques that allow us to infer com-
plicated and detailed security rules. Additionally, while
PR-Miner uses more complex data mining techniques
to infer programming rules, we leverage readily avail-
able prior knowledge about part of our rules, the secu-
rity check functions, so that we can extract security rules
without expensive data mining techniques.
Inferring Models and Rules in General The general
idea of automatically extracting models from low-level
implementation has been discussed in previous litera-
ture [8, 17, 21]. For example, Lie et al. proposed au-
tomatic extraction of speciﬁcations from actual proto-
col code and then running the extracted speciﬁcations
through a model checker [21]. While conceptually these
approaches bear some resemblance to the approach taken
by AutoISES, we are the ﬁrst to show the feasibility of
automatic extraction of security speciﬁcations from ac-
tual implementation. In addition, none of the previous
tools have demonstrated the ability to scale to programs
the size of the Linux kernel.
Lee et al. [19] use data mining techniques to learn
intrusion detection model for adaptive intrusion detec-
tion. Tongaonkar et al. [26] infer high-level security pol-
icy from low level ﬁrewall ﬁltering rules. None of these
work infer access control related security rules.
8 Conclusions and Future Work
This paper makes two contributions. One is to automat-
ically infer code-level security rules and detect security
violations. Our tool, AutoISES, automatically inferred
84 security rules from the latest versions of Linux ker-
nel and Xen, and used them to detect 8 security vulnera-
bilities, demonstrating the effectiveness of our approach.
The second contribution is to take the ﬁrst step to quan-
titatively study the impact of the rule granularity on rule
generation and veriﬁcation. This approach is orthogonal
to our ﬁrst contribution, and can be applied to other rule
inference tools.
While this work focuses on rule inference and viola-
tion detection in Linux kernel and Xen, our techniques
can be used to generate rules and detect violations in
other access control systems. In addition, the techniques
can be applied to infer general function-data correlation
type of rules, such as lock acquisition functions protect-
ing shared variables accesses. In the future, we plan to
improve our analysis and detection accuracy by employ-
ing a more advanced static analysis tool and using ﬁner
rule granularity.
9 Acknowledgments
We greatly appreciate the anonymous reviewers for their
feedback. We thank Mihai Christodorescu, Brett Daniel,
Darko Marinov and Vugranam Sreedhar for their invalu-
able comments and observations during this work. This
research is supported by NSF CCF-0325603 grant, NSF
CNS-0615372 grant, NSF CNS-0347854 (career award),
DOE Early Career Award DE-FG02-05ER25688,and In-
tel gift grants.
References
[1] Vulnerability
summary
CVE-2006-1856.
http://nvd.nist.gov/nvd.cfm?cvename=CVE-2006-1856.
[2] A. Aiken, S. Bugrara, I. Dillig, T. Dillig, B. Hackett, and
P. Hawkins. An overview of the Saturn project. In Pro-
ceedings of the 7th ACM SIGPLAN-SIGSOFT workshop
on program analysis for software tools and engineering,
2007.
[3] G. Ammons, R. Bodik, and J. R. Larus. Mining speci-
In Symposium on Principles of Programming
ﬁcations.
Languages, 2002.
USENIX Association  
17th USENIX Security Symposium 
393
modules framework. ACM Transactions on Information
and System Security, 2004.
[19] W. Lee, S. J. Stolfo, and K. W. Mok. Adaptive intrusion
detection: A data mining approach. Artiﬁcial Intelligence
Review, 2000.
[20] Z. Li and Y. Zhou. PR-Miner: Automatically extract-
ing implicit programming rules and detecting violations
in large software code. In 13th ACM SIGSOFT Sympo-
sium on the Foundations of Software Engineering, 2005.
[21] D. Lie, A. Chou, D. Engler, and D. L. Dill. A simple
method for extracting models from protocol code. In Pro-
ceedings of the 28th Annual International Symposium on
Computer Architecture, 2001.
[22] S. Lu, S. Park, C. Hu, X. Ma, W. Jiang, Z. Li, R. A. Popa,
and Y. Zhou. MUVI: Automatically inferring multi-
variable access correlations and detecting related seman-
tic and concurrency bugs. In Proceedings of the 21st ACM
Symposium on Operating Systems Principles, 2007.
[23] NSA. Security-Enhanced Linux (SELinux). Available at
http://www.nsa.gov/selinux.
[24] S. Shoham, E. Yahav, S. Fink, and M. Pistoia. Static spec-
iﬁcation mining using automata-based abstractions.
In
Proceedings of the International Symposium on Software
Testing and Analysis (ISSTA ’07), pages 174–184.
[25] K. Thompson. Reﬂections on Trusting Trust. Communi-
cations of the ACM, 1995.
[26] A. Tongaonkar, N. Inamdar, and R. Sekar.
Inferring
higher level policies from ﬁrewall rules. In Proceedings
of the 21st Large Installation System Administration Con-
ference, 2007.
[27] D. Wagner, J. S. Foster, E. A. Brewer, and A. Aiken. A
ﬁrst step towards automated detection of buffer overrun
vulnerabilities. In Proceedings of the 2000 Network and
Distributed Systems Security Conference, 2000.
[28] C. Wright, C. Cowan, J. Morris, S. Smalley, and
G. Kroah-Hartman. Linux security modules: General se-
curity support for the linux kernel. In Proceedings of the
11th USENIX Security Symposium, 2002.
[29] C. Wysopal
and C. Eng.
Static
Available
detec-
at
of
application
tion
http://www.veracode.com/images/stories/static-
detection-of-backdoors-1.0.pdf.
backdoors.
[30] X. Zhang, A. Edwards, and T. Jaeger. Using cqual for
static analysis of authorization hook placement. In Pro-
ceedings of the 11th USENIX Security Symposium, 2002.
Notes
1Portions of the work performed while Lin Tan was a summer intern
at IBM Research.
[4] T. Ball and S. Rajamani. The SLAM project: Debug-
ging system software via static analysis. In Proceedings
of the 29th ACM Symposium on Principles of Program-
ming Languages, 2002.
[5] D. Beyer, A. J. Chlipala, T. A. Henzinger, R. Jhala, and
R. Majumdar. The BLAST query language for software
In Proceedings of the 11th International
veriﬁcation.
Static Analysis Symposium, 2004.
[6] H. Chen and D. Wagner. MOPS: An infrastructure for ex-
amining security properties of software. In Proceedings
of the 9th ACM Conference on Computer and Communi-
cations Security, 2002.
[7] G. S. Coker.
Xen security modules:
http://lists.xensource.com/archives/html/xense-
devel/2006-09/msg00000.html.
Intro.
[8] J. C. Corbett, M. B. Dwyer, J. Hatcliff, S. Laubach, C. S.
P˘as˘areanu, Robby, and H. Zheng. Bandera: Extracting
Finite-State Models from Java Source Code. In Proceed-
ings of the 22nd International Conference on Software
Engineering, 2000.
[9] A. Edwards, T. Jaeger, and X. Zhang. Runtime veriﬁca-
tion of authorization hook placement for the linux secu-
rity modules framework. In Proceedings of the 9th ACM
Conference on Computer and Communications Security,
2002.
[10] D. R. Engler, D. Y. Chen, S. Hallem, A. Chou, and
B. Chelf. Bugs as deviant behavior: A general approach
to inferring errors in systems code. In Proceedings of the
18th ACM Symposium on Operating Systems Principles,
2001.
[11] M. D. Ernst, A. Czeisler, W. G. Griswold, and D. Notkin.
In Pro-
Quickly detecting relevant program invariants.
ceedings of the 22nd International Conference on Soft-
ware Engineering, 2000.
[12] J. Foster, M. Fahndrich, and A. Aiken. A theory of type
In ACM SIGPLAN Conference on Program-
qualiﬁers.
ming Language Design and Implementation, 1999.
[13] V. Ganapathy, T. Jaeger, and S. Jha. Retroﬁtting legacy
In Proceed-
code for authorization policy enforcement.
ings of the 2006 IEEE Symposium on Security and Pri-
vacy, 2006.
[14] V. Ganapathy, S. Jha, D. Chandler, D. Melski, and
D. Vitek. Buffer overrun detection using linear program-
ming and static analysis. In Proceedings of the 10th ACM
Conference on Computer and Communications Security,
2003.
[15] V. Ganapathy, D. King, T. Jaeger, and S. Jha. Mining
security-sensitive operations in legacy code using concept
analysis. In Proceedings of the 29th International Confer-
ence on Software Engineering, 2007.
[16] S. Hallem, B. Chelf, Y. Xie, and D. Engler. A system and
language for building system-speciﬁc static analyses. In
ACM SIGPLAN Conference on Programming Language
Design and Implementation, 2002.
[17] G. J. Holzmann and M. H. Smith. Software model check-
ing: Extracting veriﬁcation models from source code.
Software Testing, Veriﬁcation and Reliability, 2001.
[18] T. Jaeger, A. Edwards, and X. Zhang. Consistency analy-
sis of authorization hook placement in the linux security
394 
17th USENIX Security Symposium 
USENIX Association