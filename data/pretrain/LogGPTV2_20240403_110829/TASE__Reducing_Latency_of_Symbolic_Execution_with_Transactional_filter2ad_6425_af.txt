A temporal view of the lag is pictured in Fig. 5, which
shows the distribution of lag across all 21 TLS sessions with
messages binned according to their arrival times, where arr (i)
denotes the arrival time of message i; for example, the ﬁrst bin
contains the messages that arrived within the ﬁrst 30s of each
of the 21 TLS sessions. Arrival time is measured relative to
the start of the individual TLS session. Within each bin, a box-
and-whisker plot shows the ﬁrst, second, and third quartiles,
with the whiskers extended to 1.5× the interquartile range.
The average is shown as a diamond, and outliers appear as
individual points.
(a) basic conﬁguration
(b) optimized conﬁguration
Fig. 5: Veriﬁcation lag for 21 TLS sessions in the Gmail trace,
each veriﬁed in isolation. The box plot at arrival time t includes
{lag(i) : t ≤ arr (i) < t + 30s} across all 21 TLS sessions.
Fig. 5a shows lag in verifying the Gmail traces using TASE
and CliVer in a basic deployment without protocol-speciﬁc
optimizations, and Fig. 5b shows lag in a conﬁguration with
optimizations leveraging protocol knowledge; see Sec. VI-B1.
11
05101520050100150200Time(s)TLS Connectionsllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll036912150306090120150180Arrival Time (s)Verification Lag (s)TASECliVerllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0123450306090120150180Arrival Time (s)Verification Lag (s)TASECliVerThe lags for the basic deployment lacking protocol-speciﬁc
optimizations are shown in Fig. 5a, and the lags for the op-
timized deployment leveraging protocol-speciﬁc optimizations
are shown in Fig. 5b. Both TASE and CliVer suffered lag in the
ﬁrst 30s of each connection, though TASE’ median lag in this
interval was < 15% of CliVer’s in both the basic and optimized
conﬁgurations. Indeed, the 25th percentile of CliVer’s lag in
this ﬁrst 30s exceeded essentially all lags induced by TASE in
the same interval. By the end of the ﬁrst 30s, both tools “caught
up” and maintained lags capable of sustaining interactive use
until about 90s into the traces; at this point, large server-to-
client transfers caused CliVer to lag considerably in the basic
conﬁguration, while TASE was able to better keep up. These
lags were smaller in the optimized conﬁguration, since server-
to-client data messages were ignored.
In Fig. 6 we report the cost for verifying each message
in these connections as a function of the message’s size.
The datapoints in Fig. 6 represent all 21 TLS sessions in
the Gmail dataset but, in the case of CliVer, omit points for
the ClientHello message and selected handshake messages of
each TLS connection. These messages were omitted because
CliVer’s excessive veriﬁcation costs for them skewed the y-axis
range considerably, rendering the other trends more difﬁcult
to distinguish visually. (All messages are included in the
TASE datapoints, however.) Fig. 6a represents the costs in
the basic conﬁguration, and Fig. 6b shows the costs in the
optimized conﬁguration. As can be seen in Fig. 6b, the costs
for most messages scaled linearly in message size for both
TASE and CliVer, but the slope of this growth was ﬂatter
with TASE, resulting in lower costs (and so less lag) for
veriﬁcation. In Fig. 6a, the datapoints for TASE fell along
two lines corresponding to the client-to-server and server-to-
client messages (the latter are mostly omitted from Fig. 6b),
and similarly for the datapoints for CliVer.
(a) basic conﬁguration
(b) optimized conﬁguration
Fig. 6: Veriﬁcation cost vs. message size
While TASE is designed to reduce the latency of symbolic
execution, a secondary concern is the number of processes
and amount of memory incurred by its use in behavioral
veriﬁcation. In Appendix A we show these statistics. Brieﬂy,
the number of processes remained roughly ﬂat during veriﬁca-
tion, and the amount of memory used during veriﬁcation grew
slowly and never exceeded 3.6GB. We believe we can further
reduce this memory footprint with better engineering; memory
usage has not been a limiting factor for us so far.
12
C. Other Applications: Defending Against Memory Exploits
TASE’s method of speculatively executing application code
within hardware transactions and detecting when the appli-
cation reads or overwrites poison values has applications for
several tasks beyond full-blown symbolic execution, with min-
imal changes to the tool. As one example, we have prototyped
a simple adaptation of TASE that places the poison value as a
canary [21] adjacent to the return address in each stack frame;
any application instruction that tries to overwrite the canary
would then invoke the interpreter. We have further extended
this design with a slightly modiﬁed memory allocator that
places the poison value immediately before and after each
heap-allocated buffer, providing detection of reads or writes off
the beginning or end of the buffer. This modiﬁcation of TASE
will thus detect many common types of memory exploits, and
requires only small changes to the TASE compiler to emit
modiﬁed function prologues and epilogues, minor changes to
the memory allocator, and small changes to the KLEE-based
interpreter to diagnose an encountered error. In total, these
changes comprised fewer than 140 source lines of code.
We summarize this application of TASE primarily to em-
phasize the ﬂexibility of its techniques. As such, we do not
quantitatively evaluate it against the plethora of available tools
that provide similar properties. Qualitatively, however,
this
adaptation of TASE to detect memory exploits adds essentially
the same latency overheads as purely concrete execution in
TASE—runtimes of the same benchmarks in Table I were
changed by only at most 15% when these protections were
applied to every stack frame and heap-allocated buffer—and
should impose memory overheads comparable to or less than
similar tools that leverage shadow memories (e.g., [15], [42],
[37], [8], [44]) or that use specialized memory allocators
to achieve similar protections using page-level permissions
(e.g., [3], [34], [23]). Moreover, by diverting execution to the
interpreter when a memory exploit is detected, the interpreter
can attempt to permit execution to continue safely (e.g., [47]),
though we have not implemented these extensions presently.
We could extend this basic implementation to similarly
detect use-after-free exploits, i.e., by poisoning buffers when
they are freed. So,
if a stale pointer were dereferenced,
TASE would either trap safely with a segmentation fault if
the dereferenced memory was unmapped or trigger a poison
check if the memory was freed but not unmapped. Either
way, the interpreter could consult its bitmap after the trap
and unambiguously conclude that the pointer is no longer
valid. We anticipate that this extension would induce only the
runtime overhead of poisoning each buffer when it was freed
and require minimal additional code modiﬁcations.
VII. LIMITATIONS
In this section we discuss several limitations of TASE.
A. Hardware Dependence on Intel TSX
To our knowledge,
Intel currently provides the only
widespread implementation of hardware transactional memory,
limiting TASE to executing only on Intel machines with
support for TSX instructions. Nevertheless,
in the future,
transactional memory could be implemented by other vendors;
llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.000.050.100.150.20051015Message Size (KB)Verification Cost (s)lTASECliVerllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0.000.050.100.150.200123Message Size (KB)Verification Cost (s)lTASECliVeras early as 1993, Herlihy and Moss proposed an implementa-
tion for hardware transactional memory based on “straight-
forward extensions to any multiprocessor cache-coherence
protocol“ [27].
B. Equivalence of Interpretation and Native Execution
Inevitable differences between the behaviors of native exe-
cution and interpretation of the same project imply that TASE
results are not necessarily semantically equivalent to those
obtained using symbolic execution based on interpretation
only. For example, KLEE detects out-of-bounds accesses to
concrete buffers, while native execution (without additional
instrumentation) does not. It would seem that differences in
the results of applying KLEE and TASE to a project could
arise, however, only due to the project’s processing on concrete
values, since processing on symbolic values would trigger
interpretation in TASE, as well.
In the context of the client veriﬁcation application dis-
cussed in Sec. VI-B, this means that those behaviors permitted
by CliVer, which uses KLEE to interpret the client program in
full, are not identical to those permitted by TASE. However, a
behavior permitted by TASE but not by CliVer, if caused by an
input validation error of the client program, would presumably
need to be an artifact of server-to-client messages, which are
concrete to the veriﬁer. Since the veriﬁer is deployed to defend
the server and is trusted to cooperate with it, malicious server-
to-client messages are outside the scope of those techniques.
C. Interpreting x86 Instructions
Although the use of native state as the primary representa-
tion for program execution in TASE introduces opportunities
for speculative native execution on concrete data, this design
choice also introduces some difﬁculties.
Because KLEE requires LLVM IR to perform symbolic
execution, we needed to produce LLVM IR models for the
effects of each x86 instruction to be interpreted by KLEE on
the program’s state. In addition to providing a burdensome
engineering challenge, we found (as did S2E’s authors [18])
that modeling a given x86 instruction’s impact on program
state using the RISC-like LLVM IR required several LLVM
IR instructions to fully capture all side effects, including the
changes to the FLAGS register.
As a result, a machine-independent
interpretation of a
source program in vanilla KLEE could require fewer LLVM
IR instructions to model
the program’s execution than in
TASE. We feel that our use cases contain a sufﬁciently large
usage of concrete data to justify the optimizations for native
execution in TASE, but a tradeoff nevertheless exists between
the additional instructions needed for interpretation in TASE
and the speed gained in native execution.
D. Instrumentation
In order to ensure that reads or writes to memory ad-
dresses containing symbolic values are accurately recorded,
TASE uses a custom LLVM backend to emit and instrument
code. Although LLVM provides many utilities for writing
compiler passes to analyze or modify machine code as it
is emitted, signiﬁcant engineering challenges must still be
overcome to ensure that all code emitted for TASE is properly
instrumented. Speciﬁcally, the large number and variety of
x86 instructions available, combined with their side effects
and implicit operands, make it difﬁcult
to write a catch-
all compiler pass that determines how an instruction touches
memory. Furthermore, determining exactly where in the LLVM
backend to inject instrumentation can be nontrivial, given that
LLVM applies a large number of stages of optimization, some
of which may modify code emitted earlier during compilation.
To simplify the instrumentation process, TASE’s LLVM
backend restricts the pool of x86 instructions available to the
compiler during instruction selection. Our anecdotal evidence
suggests that
the slowdown imposed by choosing from a
more limited set of instructions is negligible compared to
the overhead of setting up and committing transactions and
periodically interpreting when needed, but we may expand the
set of allowed instructions in the future.
E. Controlled Forking
TASE was designed to use native forking to explore dif-
ferent execution paths, each in a different process, in order
to avoid the overhead of software-based copy-on-write mech-
anisms as used in KLEE and S2E [10], [18]. Although forking
allows TASE to explore distinct paths in parallel, exploring dis-
tinct execution paths within distinct address spaces complicates
the process of applying search heuristics across these many
processes, sharing cached SMT query results across paths, etc.
Furthermore, even if it were desirable to move all or some
aspects of path exploration into a single address space, the
TSX transactions utilized for our speculative execution scheme
would likely abort more often due to their original intended
use—detecting conﬂicting concurrent accesses—thereby im-
pinging on performance.
As discussed in Sec. IV-E, our present
implementation
leverages a central manager process to guide path exploration,
which it does simply by prioritizing which worker processes it
allows to proceed (and temporarily suspending others). Some
applications might require more sophisticated mechanisms for
state management in which this simple prioritization is insuf-
ﬁcient. For example, hybrid symbolic execution as introduced
in Mayhem [13], in which symbolic states can be archived
to relieve memory pressure and restored later for further
exploration, might be needed for analyzing some types of
applications efﬁciently.
VIII. CONCLUSION
In this paper, we presented the design, implementation,
and evaluation of TASE. To our knowledge, TASE is the ﬁrst
symbolic execution engine that leverages specialized hard-
ware capabilities to accelerate native execution to optimize
workloads in which operations on concrete data are a major
bottleneck. The two technical innovations in TASE to make
this possible are (i) batching tests to detect native accesses
to symbolic data into a few instructions, and (ii) undoing the
potentially erroneous effects of having accessed symbolic data
natively by leveraging hardware transactions.
We illustrated an application of TASE for verifying whether
the messaging behavior of a client as seen by the server is con-
sistent with the software the client is believed to be executing.
13
We showed that the use of TASE in this application dramati-
cally reduced the lag associated with verifying OpenSSL TLS
1.2 trafﬁc, e.g., as driven by Gmail. This reduction bolsters
the prospects of deploying this veriﬁcation on the critical