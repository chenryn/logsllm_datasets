tics for identifying automated spammers [51], [52],
these
heuristics have limited utility in identifying compromised
accounts and incur a delay between a fraudulent account’s
detection and creation to develop a history of (mis-)activity.
In contrast, Monarch operates independently of account prop-
erties, generalizes to all web services that receive URL spam,
and requires no monitoring window.
Characterizing Spam. Monarch builds on a large founda-
tion of previous efforts to characterize spam properties. This
includes the lexical characteristics of phishing URLs [16],
the locality of email spammer IP addresses [17], hosting
infrastructure and page layout that is shared across email spam
campaigns [18], and the content of spam websites [27]. In
turn, these properties have been used to develop techniques
to detect algorithmically generated spam domains [21] and to
identify spam domains based on nameserver and registration
times [20]. We expand upon these properties, adding our own
study of spam behavior including a comparison between email
and tweet spam as well as services abused by each.
Detecting Scams, Phishing, and Malware. Detecting scams,
phishing, and malware based on URL and page properties is by
no means new. Particular attention has been paid to identifying
phishing URLs, where a number of solutions rely on HTML
forms, input ﬁelds, page links, URL features, and hosting
properties for detection [15], [28], [53]. Malware, speciﬁcally
drive-by-downloads, has also been the target of recent study,
with most solutions relying on exposing sandboxed browsers
to potentially malicious content [54], [55]. An exception is
Wepawet, which relies on detecting anomalous arguments
passed to plugins to prevent attacks [56]. Our own system
generalizes to all forms of scams, phishing, and malware and
allows for real-time URL submission by web services.
Of the closest works to our own, Ma et al. show that
one can classify spam URLs based on lexical structure and
underlying hosting infrastructure including DNS and WHOIS
information [22], [23]. We employ these same metrics in
our system, but crawl URLs to resolve redirect URLs that
would otherwise obscure the ﬁnal landing page and its hosting
460
infrastructure. A similar approach is taken by Wittaker et
al. [24] for speciﬁcally classifying phishing pages. We expand
upon their research and generalize Monarch to detect all forms
of spam, adding features such as JavaScript behavior, redirect
chains, and the presence of mashup content, while developing
our own classiﬁcation engine and collection infrastructure to
fulﬁll real-time requirements.
Spam Filtering and Usability Challenges. In this paper, we
particularly focus on providing accurate decisions for whether
a URL directed to spam content. However, a second challenge
remains for web services, as they must decide how to appropri-
ately address spam content. Currently, Twitter and Facebook
prevent messages containing known spam content from being
posted [57], [58], while bit.ly implements a warning page that
users must click past to access potentially harmful content [9].
Warnings provide users with an opportunity to bypass false
positives, but burden users with making (un-)informed security
decisions.
The effectiveness of warnings in the context of phishing
sites was examined in several studies [59], [60],
the re-
sults of which showed that unobtrusive warning messages
are ineffective compared to modal dialogs and active, full-
screen warnings. These works lead to a discussion of the
best approach for educating users of security practices and
making informed decisions [61]. While advances in usability
are orthogonal to Monarch, web services relying on Monarch’s
decisions can take heed of these studies when determining the
best mechanism for conveying the potential harm of a URL
to users.
9. Conclusion
Monarch is a real-time system for ﬁltering scam, phishing,
and malware URLs as they are submitted to web services.
We showed that while Monarch’s architecture generalizes to
many web services being targeted by URL spam, accurate clas-
siﬁcation hinges on having an intimate understanding of the
spam campaigns abusing a service. In particular, we showed
that email spam provides little insight into the properties of
Twitter spammers, while the reverse is also true. We explored
the distinctions between email and Twitter spam, including the
overlap of spam features, the persistence of features over time,
and the abuse of generic redirectors and public web hosting.
We have demonstrated that a modest deployment of Monarch
on cloud infrastructure can achieve a throughput of 638,000
URLs per day with an overall accuracy of 91% with 0.87%
false positives. Each component of Monarch readily scales to
the requirements of large web services. We estimated it would
cost $22,751 a month to run a deployment of Monarch capable
of processing 15 million URLs per day.
10. Acknowledgments
This material is based upon work supported by the Na-
tional Science Foundation under Grant No. 0311808, 0832943,
461
0448452, 0842694, 0627511, 0842695, 0831501, 0433702,
0905631, CCF-0424422, and CNS-0509559. Any opinions,
ﬁndings, and conclusions or recommendations expressed in
this material are those of the authors and do not necessarily
reﬂect the views of the National Science Foundation. This
work is partially supported by the Ofﬁce of Naval Research
under MURI Grant No. N000140911081. This material is
based upon work supported by the MURI program under
AFOSR Grant No: FA9550-08-1-0352. This research is also
supported by gifts from Sun Microsystems, Google, Microsoft,
Amazon Web Services, Cisco Systems, Cloudera, eBay, Face-
book, Fujitsu, Hewlett-Packard, Intel, Network Appliance,
SAP, VMWare and Yahoo! and by matching funds from the
State of California’s MICRO program (grants 06-152 and
07-010), and the University of California Industry/University
Cooperative Research Program (UC Discovery) grant COM07-
10240.
We thank Matei Zaharia and John Duchi for discussions
about the distributed learning implementation. We also thank
our shepherd Ben Livshits and our anonymous reviewers for
their valuable feedback.
References
[1] G. Cluley, “This you????: Phishing attack hits
twitter users.”
http://www.sophos.com/blogs/gc/g/2010/02/24/phishing-attack-hits-
twitter-users/, 2010.
[2] E. Mills, “Facebook hit by phishing attacks for a second day,” CNET
News, 2009.
[3] John E. Dunn, “Zlob Malware Hijacks YouTube,” 2007. http://www.
pcworld.com/article/133232/zlob malware hijacks youtube.html.
[4] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Zhao, “Detecting and
characterizing social spam campaigns,” in Proceedings of the Internet
Measurement Conference (IMC), 2010.
[5] C. Grier, K. Thomas, V. Paxson, and M. Zhang, “@spam: the un-
the ACM
derground on 140 characters or less,” in Proceedings of
Conference on Computer and Communications Security (CCS), 2010.
[6] Kim Zetter, “Trick or Tweet? Malware Abundant in Twitter URLs,”
Wired, 2009.
[7] B. Stone, “Facebook Joins With McAfee to Clean Spam From Site,”
New York Times, 2010.
[8] HootSuite,
Malware,
2010.
hootsuite-ﬁghts-malware-phishing/.
“Kapow! HootSuite Fights
and
Spam,”
the Evils of Phishing,
http://blog.hootsuite.com/
[9] bit.ly, “Spam and Malware Protection,” 2009. http://blog.bit.ly/post/
138381844/spam-and-malware-protection.
[10] A. Ramachandran, N. Feamster, and S. Vempala, “Filtering spam with
behavioral blacklisting,” in Proceedings of the 14th ACM Conference on
Computer and Communications Security, 2007.
[11] S. Sinha, M. Bailey, and F. Jahanian, “Shades of grey: On the effective-
ness of reputation-based blacklists,” in 3rd International Conference on
Malicious and Unwanted Software, 2008.
[12] F. Benevenuto, G. Magno, T. Rodrigues, and V. Almeida, “Detecting
Spammers on Twitter,” in Proceedings of the Conference on Email and
Anti-Spam (CEAS), 2010.
[13] K. Lee, J. Caverlee, and S. Webb, “Uncovering social spammers:
social honeypots+ machine learning,” in Proceeding of the International
ACM SIGIR Conference on Research and Development in Information
Retrieval, 2010.
[14] G. Stringhini, C. Kruegel, and G. Vigna, “Detecting Spammers on
Social Networks,” in Proceedings of the Annual Computer Security
Applications Conference (ACSAC), 2010.
[15] C. Ludl, S. McAllister, E. Kirda, and C. Kruegel, “On the effectiveness
of techniques to detect phishing sites,” Detection of Intrusions and
Malware, and Vulnerability Assessment, 2007.
[16] D. McGrath and M. Gupta, “Behind phishing: an examination of phisher
modi operandi,” in Proceedings of the 1st Usenix Workshop on Large-
Scale Exploits and Emergent Threats, 2008.
[17] S. Venkataraman, S. Sen, O. Spatscheck, P. Haffner, and D. Song, “Ex-
ploiting network structure for proactive spam mitigation,” in Proceedings
of 16th USENIX Security Symposium on USENIX Security Symposium,
2007.
[18] D. Anderson, C. Fleizach, S. Savage, and G. Voelker, “Spamscatter:
Characterizing internet scam hosting infrastructure,” in USENIX Secu-
rity, 2007.
[19] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich, G. Voelker,
V. Paxson, N. Weaver, and S. Savage, “Botnet Judo: Fighting spam with
itself,” in Proceedings of the Network and Distributed System Security
Symposium (NDSS), 2010.
[20] M. Felegyhazi, C. Kreibich, and V. Paxson, “On the potential of proac-
tive domain blacklisting,” in Proceedings of the USENIX Conference on
Large-scale Exploits and Emergent Threats, April 2010.
[21] S. Yadav, A. Reddy, A. Reddy, and S. Ranjan, “Detecting Algorith-
mically Generated Malicious Domain Names,” in Proceedings of the
Internet Measurement Conference (IMC), 2010.
[22] J. Ma, L. Saul, S. Savage, and G. Voelker, “Beyond blacklists: learning
to detect malicious web sites from suspicious urls,” in Proceedings of the
15th ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, 2009.
[23] J. Ma, L. Saul, S. Savage, and G. Voelker, “Identifying suspicious URLs:
an application of large-scale online learning,” in Proceedings of the 26th
Annual International Conference on Machine Learning, 2009.
[24] C. Whittaker, B. Ryner, and M. Nazif, “Large-Scale Automatic Classiﬁ-
cation of Phishing Pages,” in Proceedings of the Network and Distributed
System Security Symposium (NDSS), 2010.
[25] K. Chellapilla and A. Maykov, “A taxonomy of JavaScript redirection
spam,” in Proceedings of the 3rd International Workshop on Adversarial
Information Retrieval on the Web, 2007.
[26] Dan Goodin, “Scammers skirt spam shields with help from Adobe
http://www.theregister.co.uk/2008/09/04/
Flash,” The Register, 2010.
spammers using adobe ﬂash/.
[27] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly, “Detecting spam
web pages through content analysis,” in Proceedings of the 15th Inter-
national Conference on World Wide Web, 2006.
[28] Y. Zhang, J. Hong, and L. Cranor, “Cantina: a content-based approach to
detecting phishing web sites,” in Proceedings of the 16th international
conference on World Wide Web, 2007.
[29] K. Thomas and D. M. Nicol, “The Koobface botnet and the rise of
social malware,” in Proceedings of The 5th International Conference on
Malicious and Unwanted Software (Malware 2010), 2010.
[30] K. Q. Weinberger, A. Dasgupta, J. Langford, A. Smola, and J. Attenberg,
“Feature Hashing for Large Scale Multitask Learning,” in Proceedings
of the International Conference on Machine Learning (ICML), pp. 681–
688, June 2009.
[31] R. McDonald, K. Hall, and G. Mann, “Distributed Training Strategies
for the Structured Perceptron,” in Proceedings of the North American
Association for Computing Linguistics (NAACL), (Los Angeles, CA),
June 2010.
[32] J. Duchi and Y. Singer, “Efﬁcient Online and Batch Learning Using
Forward Backward Splitting,” Journal of Machine Learning Research,
vol. 10, pp. 2899–2934, Dec. 2009.
[33] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical
Learning: Data Mining, Inference, and Prediction. New York, NY:
Springer, 2009.
[34] Hadoop, “Hadoop Distributed File system.” http://hadoop.apache.org/
hdfs/, 2010.
plugins/, 2004.
api, 2010.
[35] Amazon Web Services, “Amazon EC2 Instance Types,” 2009. http:
//aws.amazon.com/ec2/instance-types/.
[36] Twitter, “Twitter API wiki.” http://apiwiki.twitter.com/Twitter-API-
Documentation, 2010.
[37] Twitter, “Building on open source.” http://blog.twitter.com/2009/01/
building-on-open-source.html, 2010.
[38] Mozilla, “API & Language References.” https://addons.mozilla.org/
en-US/developers/docs/reference, 2010.
[39] Mozilla,
“Netscape plugin API.” http://www.mozilla.org/projects/
[40] MaxMind, “Resources for Developers.” http://www.maxmind.com/app/
[41] Advanced Network Technology Center, “Univeristy of Oregon route
views project.” http://www.routeviews.org/, 2010.
[42] M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica,
“Spark: Cluster Computing with Working Sets,” in Proceedings of the
2nd USENIX Conference on Hot topics in Cloud Computing, (Boston,
MA), June 2010.
[43] B. Zadrozny, J. Langford, and N. Abe, “Cost-Sensitive Learning by
Cost-Proportionate Example Weighting,” in Proceedings of the IEEE
International Conference on Data Mining (ICDM), (Melbourne, FL),
Nov. 2003.
[44] S. Sinha, M. Bailey, and F. Jahanian, “Improving spam blacklisting
through dynamic thresholding and speculative aggregation,” in Pro-
ceedings of the 17th Annual Network & Distributed System Security
Symposium, 2010.
[45] L. Rao, “Twitter seeing 90 million tweets per day, 25 percent con-
tain links.” http://techcrunch.com/2010/09/14/twitter-seeing-90-million-
tweets-per-day/, September 2010.
[46] T. Holz, C. Gorecki, F. Freiling, and K. Rieck, “Detection and mitigation
the 15th Annual
of fast-ﬂux service networks,” in Proceedings of
Network and Distributed System Security Symposium (NDSS08), 2008.
[47] N. Dalvi, P. Domingos, S. Mausam, and D. Verma, “Adversarial classi-
ﬁcation,” in Proceedings of the International Conference on Knowledge
Discovery and Data Mining, 2004.
[48] D. Lowd and C. Meek, “Adversarial learning,” in Proceedings of the
International Conference on Knowledge Discovery in Data Mining,
2005.
[49] M. Barreno, B. Nelson, R. Sears, A. Joseph, and J. Tygar, “Can
machine learning be secure?,” in Proceedings of the ACM Symposium
on Information, Computer and Communications Security, 2006.
[50] P. Eckersley, “How Unique Is Your Web Browser?,” in Privacy Enhanc-
[51] Twitter,
“The
twitter
rules.”
http://support.twitter.com/entries/
ing Technologies (PET), 2010.
18311-the-twitter-rules, 2010.
[52] C. Ghiossi, “Explaining Facebook’s Spam Prevention Systems.” http:
//blog.facebook.com/blog.php?post=403200567130, 2010.
[53] S. Garera, N. Provos, M. Chew, and A. Rubin, “A framework for
detection and measurement of phishing attacks,” in Proceedings of the
2007 ACM Workshop on Recurring Malcode, 2007.
[54] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose, “All your
iFRAMEs point to us,” in Proceedings of the 17th Usenix Security
Symposium, pp. 1–15, July 2008.
[55] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen, and
S. King, “Automated Web patrol with Strider HoneyMonkeys: Finding
Web sites that exploit browser vulnerabilities,” in Proceedings of the
2006 Network and Distributed System Security Symposium (NDSS),
February 2006.
[56] M. Cova, C. Kruegel, and G. Vigna, “Detection and analysis of drive-
by-download attacks and malicious JavaScript code,” in Proceedings of
the 19th International Conference on World Wide Web, 2010.
[57] F-Secure, “Twitter now ﬁltering malicious URLs.” http://www.f-
secure.com/weblog/archives/00001745.html, 2009.
[58] Facebook,
“Explaining
Facebook’s
spam prevention
systems.”
http://blog.facebook.com/blog.php?post=403200567130, 2010.
[59] M. Wu, R. Miller, and S. Garﬁnkel, “Do security toolbars actually
prevent phishing attacks?,” in Proceedings of the SIGCHI conference
on Human Factors in computing systems, 2006.
[60] S. Egelman, L. Cranor, and J. Hong, “You’ve been warned: an empirical
study of the effectiveness of web browser phishing warnings,” in
Proceeding of the Conference on Human Factors in Computing Systems,
2008.
[61] C. Herley, “So long, and no thanks for the externalities: The rational
the 2009
rejection of security advice by users,” in Proceedings of
Workshop on New Security Paradigms Workshop, 2009.
462