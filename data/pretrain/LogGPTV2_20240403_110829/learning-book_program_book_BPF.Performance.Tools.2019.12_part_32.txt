sk_xait_data
tcp_recvmsg
Inet_recvmag
sock_recvmsg
SYSC_recvfron
sys_recvfron
do_syscal1_64
entry_SYscALL_64_after_hmframe
recv
iperf 14659)
1021497
[..-]
---
## Page 258
6.3 BPF Tools  221
finish_task_svitch
schedule
schedule_hrtineout_cange_clock
schedule_hxtineout_range
po1l_schedule_tineout
do_select
core_sys_select
sys_select
do_sysca11_64
entzy_SYscALl_64_after_hvfxase
_libc_select
[unknon]
offcputime (14667)
5004039
The output has been truncated to only show three stacks from the hundreds that were printed.
Each stack shows the kernel frames (if present), then user-level frames, then the process name and
PID, and finally the total time this combination was seen, in microseconds. The first stack shows
iperf(1) blocking in sk_stream_wait_memory() for memory, for a total of 5 milliseconds. The
second shows iperf(1) waiting for data on a socket via sk_wait_data(0), for a total of 1.02 seconds.
The last shows the offcputime(8) tool itself waiting in a select(2) syscall for 5.00 seconds; this is
likely for the 5-second timeout specified at the command line.
Note that, in all three stacks, the user-level stack traces are incomplete. This is because they
ended at libc, and this version does not support the frame pointer. This is more evident in
offcputime(8) than profile(8), since blocking stacks often pass through system libraries such as
libc or libpthread. See the discussions on broken stack traces and solutions in Chapters 2, 12, 13,
and 18, in particular Section 13.2.9.
offcputime(8) has been used to find various production issues, including finding unexpected time
blocked in lock acquisition and the stack traces responsible.
thread leaves the CPU to when it returns, along with the stack trace. The times and stack traces
offcputime(8) works by instrumenting context switches and recording the time from when a
are frequency-counted in kernel context for efficiency. Context switch events can nonetheless be
very frequent, anxd the overhead of this tool can become significant (say, >10%) for busy produc-
tion workloads. This tool is best run for only short durations to minimize production impact.
Off-CPU Time Flame Graphs
As with profile(8), the output of offcputime(8) can be so verbose that you may find it preferable to
CPU flame graph, offcputime(8) can be visualized as an off-CPU time flame graph.17
examine it as a flame graph, though of a different type than introduced in Chapter 2. Instead of a
17 These were first published by Yichun Zhang [80]
---
## Page 259
222
Chapter 6 CPUs
This example creates an off-CPU time flame graph of kernel stacks for five seconds:
offcputime -fKu 5 > out.offcputime01.txt
 out offcputine01 .svg
I used  bgco1ors to change the background color to blue as a visual differentiator from CPU
flame graphs. You can also change the frame colors with co1ors, and Ive published many
off-CPU flame graphs using a blue palette for the frames".
These commands produced the flame graph shown in Figure 6-6.
Figure 6-6 Off-CPU time flame graph
This flame graph is dominated by threads sleeping, waiting for work. Applications of interest can
Snpnus 'sudeig areg d-go uo aro rog u uooz op saueu npau Suo q paexa aq
examples with full user stack traces, see Chapters 12, 13, and 14.
BCC
Command line usage:
offcputine[optlons][duratlon]
Options include:
 f: Prints output in folded format
Ajuo saoud spi sanseap :a1a d-*
 u: Traces only user threads
▪k: Traces only kernel threads
U: Shows only user stack traces
•R: Shows only kernel stack traces
ette as CPU flame graphs for consistency
color to vse the same pe
---
## Page 260
6.3 BPF Tools
223
Some of these options can help reduce overhead by filtering to record only one PID or stack
type
bpftrace
The following is the code for the bpftrace version of offcputime(8), which summarizes its core
functionality. This version supports an optional PID argument for the target to trace:
+1/usr/local/bin/bpftrace
include 
BEGIN
printf(*Tracing nanosecond tine in off-CP0 stacks, Ctrl-C to end.\o*)
kprobe :flnish_task_svltch
 / /record previous thzead sleep tine
$prer = (struct task_struct *)arg0:
1f ($1 == 0 11 Sprev=>tgid == $1] [
rsoasα = [ptdc.aads]4re426
/
// get the current thzead start tine
$last = estart [tid] :
1f ($last = 0) (
e[kstack, ustack, corn] = sun(nsecs - $last)
delete (Bstart [t.id]
END
clear (8start) 
This program records a timestamp for the thread that is leaving the CPU and also sums the
off-CPU time for the thread that is starting, in the one finish_task_switch() kprobe.
---
## Page 261
224
Chapter 6 CPUs
6.3.10
syscount
syscount(8)° is a BCC and bpftrace tool for counting system callsystem-wide. It is included in
this chapter because it can be a starting point for investigating cases of high system CPU time.
The following output shows syscount(8) from BCC printing per-second syscall rates (1 1) on
a production instance:
syscount -1 1
Tracing syscalls, printing top 10... Ctrl+C to quit.
[00:04:18]
SYSCALL
COUNT
futex
E2625
read
29973
epol1_walt
27865
vrite
21707
epo1l_ct1
4696
po11
2625
vz1tev
2460
recvfrom
1594
c10s4
1385
sendto
1343
[..]
This output shows the top 10 syscalls every second, with a timestamp. The most frequent syscall
is futex(2), at more than 15o,000 calls per second. To further explore each syscall, check the man
pages for documentation, and use more BPF tools to trace and inspect their arguments (e.g, BCC
trace(8) or bpftrace one-liners). In some situations, running strace(1) can be the quickest path for
mentation of strace(1) can slow the target application one hundredfold, which can cause serious
understanding how a given syscall is used, but keep in mind that the current ptrace-based imple-
(sasoey Bupua8S; ro soTs Aouape Supaaoxa *8·a) squauuouaua uogonpoad Kueu us sansst
strace(1) should be considered a last resort after you've tried BPF tooling.
The P option can be used to count by proces ID instead:
+syscount -Pi 1
Tzacing syscalls, printing top 1o.., Ctxl+C to qult.
[00:04:25]
PID
CONK
COUNT
3622
Javs
294783
990
snnpd
124
2392
redis-server
64
19 Origin: 1 first created this using Ptrace and perf(1) for the perftools collection on 7-Jul-201.4, and Sssha Goldshtein
developed the BCC version on 15-Feb-2017.
---
## Page 262
6.3BPF Tools 225
esed-duus06
32
31
pqss0697
24
2380
sVscan
11
2441
at.las-systen-ag
5
2453
apache2
2
4786
2sedduus
1
[..]
The java process is making almost 300,000 syscalls per second. Other tools show that this is
consuming only 1.6% system time across this 48-CPU system.
This tool works by instrumenting the raw_syscalls:sys_enter tracepoint rather than the usual
syscalls:sys_enter_* tracepoints. The reason is that this is one tracepoint that can see all syscalls,
making it quicker to initialize instrumentation. The downside is that it only provides syscall IDs,
which must be translated back into the names. BCC provides a library call, syscall_name),
to do this.
The overhead of this tool may become noticeable for very high syscall rates. As an example,
I stress-tested one CPU with a syscall rate of 3.2 million syscalls/second/CPU. While running
syscount(8), the workload suffered a 30% slowdown. This helps estimate the overhead for
production: The 48-CPU instance with a rate of 300,000 syscalls/second is performing
about 6000 syscalls/second/CPU, so it would be expected to suffer a 0.06% slowdown
(30% × 6250 / 3200000). I tried to measure this directly in production, but it was too small to
measure with a variable workload.
BCC
Command line usage:
syscount [opticns][-iinterval][-d duration]
Options include:
• -7 rop: Prints the specified number of top entries
 L: Shows the total time (latency) in syscalls
• P: Counts by process
fquo saoosd stu sa1nsea :aIa d- 
An example of the 1 option is shown in Chapter 13.
---
## Page 263
226
Chapter 6 CPUs
bpftrace
one-liner:
[ : (1 umoo = [9qoz]a 1 ,zegusss:stteoss:, 8- soexagdg 
Attaching 316 probes...
°C
[.--]
[tracepoint:syscalls:sys_enter_ioct]] : 9465
e[tracepoint:ayscalls:sys_entex_epoll_xalt] : 9807
e[tracepoint:syscalls:sys_enter_gettid] : 10311
e[tracepoint:ayscalls:sys_entex_futex] : 14062
[tracepoint:syscalls:sys_enter_recvnsg] : 22342
In this case, all 316 syscall tracepoints were instrumented (for this kernel version), and a frequency
count was performed on the probe name. Currently there is a delay during program startup and
shutdlown to instrument all 316 tracepoints. It's preferable to use the single raw_syscalls:sys_enter
tracepoint, as BCC does, but that then requires an extra step to translate from syscall ID back to
syscall name. This is included as an example in Chapter 14.
6.3.11 argdist and trace
argdlist(8) and trace(8) are introduced in Chapter 4, and are BCC tools that can examine events in
custom ways. As a follow-on from syscount(8), if a syscall was found to be called frequently, you
can use these tools to examine it in more detail.
For example, the read(2) syscall was frequent in the previous syscount(8) output. You can use
argdlist(8) to summarize its arguments and return value by instrumenting either the syscall trace-
BCC tool tplist(8) prints out with the v option:
point or its kernel functions. For the tracepoint, you need to find the argument names, which the
 tplist -v sysca1ls:sys_enter_read
peaa"xaqua"s1stteoss
Int ayscal1_nr;
unsigned int fd;
chaz * buf;
size_t count:
The count argument is the size of the read(2). Summarizing this using argdist(8) as a histogram
(B):
 argdist -H *t:syscalls:sys_enter_read() :int:args->count
[09:08 : 31.]
args=>count
: count
distr1butlon
0 > 1
: 169
---
## Page 264
6.3 BPF Tools
227
2 -> 3
: 243
  ×
4 -> 7
: 1
8 -> 15
: 0
16 -> 31
b8E :
32 -> 63
: 0
64 -> 127
: 0
128 -> 255
: 0
25 6 -> 511
: 0
512 -> 1023
: 0
1024 -> 2047
: 267
2048 -> 4095
: 2
409 6 > 8191
: 23
| * +
[. . -]
This output shows that there were many reads in the 16- to 31-byte range, as well as the
1024- to 2047-byte range. The C option to argdist(8) can be used instead of H to summarize
as a frequency count of sizes rather than a histogram.
This is showing the read requested size since the entry to the syscall was instrumented. Compare
it with the return value from the syscall exit, which is the number of bytes actually read:
 argdist -H 't:syscal1s:sys_exit_read () :int:args->ret'
[09:12:58]
x 1
: 481
E 7
: 1
8 -> 15
: 29
| * *
16 > 31
: 6
∈9  127
: 8
128 -> 255
256 -> 511
: 2
:1
512 -> 1023
: 2
1024 > 2047
: 13
2048 -> 4095
: 2
[..-]
These are mostly zero- or one-byte reads.
Thanks to its in-kernel summary, argdist(8) is useful for examining syscalls that were called
frequently. trace(8) prints per-event output and is suited for examining less-frequent syscalls,
showing per-event timestamps and other details.
---
## Page 265
228
Chapter 6 CPUs
bpftrace
This level of syscall analysis is possible using bpftrace one-liners. For example, examining the
requested read size as a histogram:
 : (xunosret) : }'
Attaching l pzobe,
^C
9 :
88081 501
[0]
181
[1]
1161 1eeeeeeeeee8ee8eeeeeeeeeeeeee8eeeee88ee8ee8ee8eeeeeee1
[2, 4)
196 188988988
[4, B]
B1
[8, 16}
86e888886886886881 980
[16, 32)
6881 .8
1
[32, 64)
118 188988
[64, 128]
81LE