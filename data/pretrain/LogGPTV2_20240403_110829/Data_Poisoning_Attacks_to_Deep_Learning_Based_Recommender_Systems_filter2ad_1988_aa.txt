title:Data Poisoning Attacks to Deep Learning Based Recommender Systems
author:Hai Huang and
Jiaming Mu and
Neil Zhenqiang Gong and
Qi Li and
Bin Liu and
Mingwei Xu
Data Poisoning Attacks to Deep Learning Based
Recommender Systems
Hai Huang1, Jiaming Mu1, Neil Zhenqiang Gong2, Qi Li1, Bin Liu3, Mingwei Xu1
1Institute for Network Sciences and Cyberspace & Department of Computer Science and Technology, Tsinghua University
1Beijing National Research Center for Information Science and Technology (BNRist)
3Department of Management Information Systems, West Virginia University
2Duke University
Abstract—Recommender systems play a crucial role in helping
users to ﬁnd their interested information in various web services
such as Amazon, YouTube, and Google News. Various recom-
mender systems, ranging from neighborhood-based, association-
rule-based, matrix-factorization-based, to deep learning based,
have been developed and deployed in industry. Among them,
deep learning based recommender systems become increasingly
popular due to their superior performance.
In this work, we conduct the ﬁrst systematic study on data
poisoning attacks to deep learning based recommender systems.
An attacker’s goal is to manipulate a recommender system such
that the attacker-chosen target items are recommended to many
users. To achieve this goal, our attack injects fake users with
carefully crafted ratings to a recommender system. Speciﬁcally,
we formulate our attack as an optimization problem, such that
the injected ratings would maximize the number of normal
users to whom the target items are recommended. However,
it is challenging to solve the optimization problem because it
is a non-convex integer programming problem. To address the
challenge, we develop multiple techniques to approximately solve
the optimization problem. Our experimental results on three real-
world datasets, including small and large datasets, show that our
attack is effective and outperforms existing attacks. Moreover, we
attempt to detect fake users via statistical analysis of the rating
patterns of normal and fake users. Our results show that our
attack is still effective and outperforms existing attacks even if
such a detector is deployed.
I.
INTRODUCTION
In the era of data explosion, people often encounter infor-
mation overload problems in their daily lives. For example,
when they are shopping online, reading news, listening to
music or watching videos,
they often face challenges of
choosing their interested items from a huge number of candi-
dates. Recommender systems help people ﬁnd their interested
items easily by mining historical user-item interaction data.
Therefore, recommender systems have been widely used in
the real world, which brings huge economic beneﬁts.
Unlike the non-personalized recommender system that rec-
ommends the same items to all users, personalized recom-
mender system that we focus in this work uses users’ historical
Network and Distributed Systems Security (NDSS) Symposium 2021
21-25  February  2021, Virtual 
ISBN  1-891562-66-5
https://dx.doi.org/10.14722/ndss.2021.24525
www.ndss-symposium.org
behavior (e.g., ratings or clicks) to model their preferences and
make personalized recommendations for each user [37]. In a
typical personalized recommender system setting, we are given
a set of users, a set of items, and a log of the users’ historical
interactions (e.g., ratings) with the items, and the goal is to
recommend each user a list of top ranked items based on
user preferences learned from the historical interactions. Tradi-
tional recommender systems include neighborhood-based [38],
association-rule-based [10], matrix-factorization-based (a.k.a
latent factor model) [26], and graph-based [14]. Recently,
with the rapid development of deep learning techniques, deep
neural networks have been applied to empower recommender
systems [6], [8], [20], [34]. Moreover, due to various ad-
vantages, such as nonlinear transformation and representation
learning that cannot be realized by traditional techniques, deep
learning is gradually becoming a technology trend in the ﬁeld
of recommender systems [50].
Meanwhile, various studies have shown that recommender
systems are vulnerable to data poisoning attacks [12], [13],
[27], [28], [32], [45], [46] (a.k.a shilling attacks [18]). Par-
ticularly, in a data poisoning attack, an attacker injects fake
users with carefully crafted ratings to a recommender system
such that the recommender system makes recommendations
as the attacker desires, e.g., an attacker-chosen target item is
recommended to many normal users. Data poisoning attacks
pose severe threats to the trustworthiness of recommender
systems and could manipulate Internet opinions. For instance,
if an attacker manipulates a news recommender system such
that a particular type of news are always recommended to
users, then the attacker may be able to manipulate the users’
opinions. However, existing data poisoning attacks are either
agnostic to recommender system algorithms [27], [32] or
optimized to traditional recommender system algorithms such
as association-rule-based [46], graph-based [13], and matrix-
factorization-based [12], [28]. Although deep learning based
recommender systems gain increasing attention and are de-
ployed in industry, their security against data poisoning attacks
is largely unknown.
In this work, we aim to bridge this gap. Speciﬁcally,
we propose data poisoning attacks that are optimized for
deep learning based recommender systems. We consider an
attacker’s goal is to promote a target item in a deep learning
based recommender system, i.e., an attacker-chosen target item
is recommended to a large number of users. To achieve this
goal, an attacker injects fake users with carefully crafted
ratings to the recommender system. As resources are limited
in an attack, we assume that the attacker can only inject a
limited number of fake users and each fake user rates a limited
number of items (including the target item and other non-
target items) to evade trivial detection. The key challenge
of constructing the attack is to choose the rated items for
each fake user. To address the challenge, we formulate the
attack as an optimization problem with an objective function
of maximizing the hit ratio of the target item, where the hit
ratio of an item is the fraction of normal users to whom the
item is recommended.
However, the optimization problem is difﬁcult to solve
because of the following reasons: i) the inputs of the problem,
i.e., data of users and items in deep learning based recom-
mender systems, are discrete variables, and ii) the training
process for a deep neural network is time-consuming, which
makes it impossible for any method to require a large number
of training iterations for solving the problem. Thus, we develop
heuristics to approximately solve the optimization problem.
Instead of directly generating the desired rated items for fake
users, we train a surrogate model called poison model and
carefully modify it to simulate the target deep learning based
recommender system. Then, we utilize this poison model to
predict the rating score vector of each fake user, and then we
process the vector to assist in selecting the rated items for each
fake user, so as to achieve our goal effectively.
We evaluate our attack and compare it with existing data
poisoning attacks using three real-world datasets with different
sizes, i.e., MovieLens-100K [19], Last.fm [2], and MovieLens-
1M [19]. Our results show that our attack can effectively
promote target items and signiﬁcantly surpasses the baseline
attacks under the white-box setting. For example, via inserting
only 5% of fake users, our attack can make unpopular target
items recommended to about 52.6 times more normal users
in the Last.fm dataset. Moreover, on the larger MovieLens-
1M [19] dataset, our attack achieves a hit ratio of 0.0099
for random target
items when injecting only 5% of fake
users, which is about 1.2 times of the best hit ratio achieved
by the baseline attacks. We further explore the impact of
partial knowledge on our poisoning attack under two different
partial knowledge settings. We observe that our attack remains
effective and signiﬁcantly outperforms the baseline attacks in
these settings. For example, when the attacker only knows 30%
of ratings in the original user-item rating matrix, our attack
obtains a hit ratio of 0.0092 for random target items when in-
jecting 5% of fake users on the MovieLens-1M dataset, which
is at least 1.3 times of the hit ratio of the baseline attacks. In
addition, our attack is transferable to structure-unknown deep
learning based recommender systems. In particular, even if we
do not know the exact neural network architecture used by
the target recommender system, our attack still makes random
target items recommended to about 5.5 times more normal
users when injecting 5% of fake users in the MovieLens-100K
dataset. Our results demonstrate that our attack poses a severe
security threat to deep learning based recommender systems.
Moreover, we explore detecting fake users via statistical
analysis of their rating patterns and measure the attack ef-
fectiveness under such detection. The intuition behind the
detection is that fake users may have rating patterns that are
statistically different from those of normal users as they are
generated according to speciﬁc rules. Particularly, for each
2
user, we extract multiple features from its ratings. Then,
we train a binary classiﬁer to distinguish between fake and
normal users based on the feature values and utilize the SVM-
TIA [51] method to detect potential fake users. The service
provider removes the detected fake users before training the
recommender system. Our experimental results show that such
a method can effectively detect the fake users generated by
existing attacks. However, the method falsely identiﬁes a large
fraction (e.g., 30%) of the fake users constructed by our
attack as normal users. As a result, our attack is still effective
and signiﬁcantly outperforms existing attacks even if such a
detection method is deployed.
The contributions of our paper are summarized as follows:
• We perform the ﬁrst systematic study on data poi-
soning attacks to deep learning based recommender
systems.
• We formulate our attack as an optimization problem
and develop multiple techniques to approximately
solve it.
• We evaluate our attack and compare it with existing
ones on three real-world datasets.
• We study detecting fake users via statistical analysis
of their ratings and its impact on the effectiveness of
data poisoning attacks.
II. BACKGROUND AND RELATED WORK
In this section, we brieﬂy introduce recommender systems
and existing data poisoning attacks to them.
A. Recommender Systems
We consider a typical collaborative ﬁltering based rec-
ommender system setting where we have M users and N
items, and we are given a record of the users’ past user-item
interactions {(cid:104)u, i, yui(cid:105)}, where yui denotes the preference
of user u to item i. The observed user-item interactions
{(cid:104)u, i, yui(cid:105)} can be represented as a user-item interaction
matrix Y ∈ RM×N . Typically, Y is extremely sparse, i.e.,
on average each user would have interactions with only a
small portion of all the N items. We use a row vector of
Y, indicated as y(u) (i.e., y(u) = {yu1, yu2, . . . , yuN}), to
represent each user u, and a column vector of Y, indicated as
y(i) (i.e., y(i) = {y1i, y2i, . . . , yM i}) , to represent each item
i. Then, the task of a recommender system can be transformed
into inferring a complete predicted interaction-matrix (cid:98)Y based
on Y, where(cid:98)yui in (cid:98)Y denotes the predicted score of yui. The
inferred interaction-matrix (cid:98)Y is then used to recommend to
row vector (cid:98)y(u) (i.e., (cid:98)y(u) = {(cid:98)yu1,(cid:98)yu2, . . . ,(cid:98)yuN}) of (cid:98)Y.
users a list of items that the users have not experienced yet.
Speciﬁcally, if we want to recommend K items for user u, we
select the top K items that (1) they have not been rated by the
user, and that (2) they have the highest predicted sores in the
Depending on how to analyze the user-item interaction
matrix, traditional collaborative ﬁltering based recommender
systems can be roughly divided into four categories,
i.e.,
neighborhood-based [38], association-rule-based [10], matrix-
factorization-based (a.k.a latent factor model) [26], and graph-
based [14]. Due to good performance and ﬂexibility in com-
positing more sophisticated models, matrix factorization (MF)
has become the most widely used approach among them.
More recently, with the rapid development of the deep
learning techniques, deep neural networks have been applied
to recommender systems and have been found to outperform
traditional methods in various aspects. Deep learning based
recommender systems use different neural networks struc-
tures to model user-item interactions to boost recommenda-
tion performance [50]. For example, Multilayer Perceptron
(MLP) [20], [21], Autoencoder (AE) [5], Adversarial Networks
(AN) [17], and Deep Reinforcement Learning (DRL) [30], [50]
have been applied to recommender systems to improve the
recommendation accuracy.
In this paper, without loss of generality, we focus on a
general deep learning based recommender system framework,
Neural Collaborative Filtering (NCF) [20]. NCF explores deep
neural networks to model sophisticated nonlinear user-item
interactions. Note that MF-based recommendation methods
assume a latent factor vector to represent each user and
each item, and apply a simple linear model on the user and
item vectors to capture the user-item interactions. In contrast,
NCF uses deep neural networks to capture nonlinear user-item
interactions by passing the user and item latent factor vectors
through multilayer perceptron (MLP). The output layer of NCF
is the prediction of the user-item interaction yui.
In particular, we consider neural matrix factorization
(NeuMF) [20], an instantiation of NCF, to model user-item
interactions. As shown in Figure 1, NeuMF is a fusion of MF
and MLP, which allows them to learn separate embeddings
and then combines the two models by concatenating their
last hidden layers. The input layer consists of two binarized
sparse vectors with one-hot encoding for the user u and item i,
respectively. These sparse vectors are then separately projected
into four dense latent vectors, i.e., MF user vector, MF item
vector, MLP user vector, and MLP item vector, two of which
are the embeddings for the user and the item in the MF model,
and the others are those in the MLP model. There are then two
parts separately processing latent vectors. One is a linear MF
part, which uses a MF layer to compute the inner product
of MF user vector and MF item vector, and the other is a
nonlinear MLP part, which adds a standard MLP with X
layers on the concatenated latent vector to learn the nonlinear
interaction between user u and item i, where X is the number
of MLP layers and the activation function in the MLP layers
is ReLU [15]. Finally, the last hidden layers of MF part and
MLP part are concatenated and fully connected to the output
interactions, this model can predict the missing entries in the
original sparse interaction matrix Y to constitute a predicted
layer to predict(cid:98)yui. After training using the observed user-item
interaction matrix (cid:98)Y which can be further used for constructing
recommendation list for each user.
B. Attacks to Recommender Systems
Existing studies showed that recommender systems are
vulnerable to various security attacks [1], [27], [28], [46],
which deceive a recommender system, e.g., to promote a target
3
Fig. 1: Neural matrix factorization model (NeuMF), an instan-
tiation of Neural Collaborative Filtering (NCF) [20].
item and recommend it to as many users as possible. Roughly
speaking, there are two categories of such attacks, i.e., data
poisoning attacks (a.k.a shilling attacks) [11]–[13], [18], [27],
[28], [46] and proﬁle pollution attacks [45], which compromise
a recommender system at training and testing, respectively.
Speciﬁcally, data poisoning attacks aim to spoof a recom-
mender system to make attacker-desired recommendations by
injecting fake users to the recommender system, while proﬁle
pollution attacks intend to pollute the historical behavior of
normal users to manipulate the recommendations for them.
Data Poisoning Attacks. Data poisoning attacks inject fake
users to a recommender system and thereby modify the recom-
mendation lists. Speciﬁcally, to construct a poisoning attack,