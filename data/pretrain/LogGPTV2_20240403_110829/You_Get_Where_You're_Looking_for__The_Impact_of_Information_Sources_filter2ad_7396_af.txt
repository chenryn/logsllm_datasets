r
a
t
e
d
a
s
s
i
g
n
a
t
u
r
e
i
n
s
e
c
u
r
e
.
a
r
e
r
a
t
e
d
o
r
s
i
g
n
a
-
S
e
r
v
i
c
e
s
a
n
o
r
m
a
l
o
r
d
a
n
g
e
r
o
u
s
p
e
r
m
i
s
-
t
o
t
r
u
e
,
u
s
e
s
i
n
t
e
n
t
Ô¨Å
l
t
e
r
s
,
o
r
A
s
e
r
v
i
c
e
t
h
a
t
h
a
s
t
h
e
e
x
p
o
r
t
e
d
Ô¨Ç
a
g
296296
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 


	

	

)#
 
)#
 
	
#$

!(
#$(
$!(
%$(
"!!(




	









	






Fig. 3. Comparison of programming experience for participants in our online
survey and lab study.
"
"
"
"
"
	
We also asked how participants learned to program (multiple
answers allowed). Almost all (83.3%, 45/54) said they were at
least partially self-taught, and 79.6% (43) had formally studied
programming at the undergraduate or graduate level. More
than half (63.0%, 34) had taken at least one security class,
and slightly fewer than half (46.3%, 25) had taken a class
in Android programming. Overall, our lab study participants
had notably more education than the developers in our online
survey.
B. Functional Correctness Results
Our results demonstrate that the assigned resource condition
had a notable impact on participants‚Äô ability to complete
the tasks functionally correctly; SO and book participants
performed best, and ofÔ¨Åcial participants performed worst. SO
participants solved 67.3% (35/52) of tasks correctly, compared
to 66.1% (37/56) for book, 51.8% (29/56) for free, and 40.4%
(21) for ofÔ¨Åcial. Figure 4 (top) provides more detail on the
breakdown of correctness across tasks and conditions. The
CLMM model (see Table III) indicates that when controlling
for task type, professional status, and multiple tasks per
participant, participants in ofÔ¨Åcial were signiÔ¨Åcantly less likely
than baseline SO participants to functionally complete tasks.
Factor
free
ofÔ¨Åcial
book
ICC
secure storage
least permissions
professional
Coef. Exp(coef)
0.349
-1.054
0.215
-1.535
-0.142
0.868
2.215
0.795
3.597
1.280
27.092
3.299
1.004
2.728
SE
0.613
0.634
0.602
0.455
0.468
0.632
0.501
p-value
0.085
0.015*
0.814
0.081
0.006*
< 0.001*
0.045*
TABLE III
CLMM REGRESSION TABLE FOR FUNCTIONAL CORRECTNESS. THE
NON-INTERACTION MODEL INCLUDING PROFESSIONAL STATUS WAS
SELECTED. NON-SIGNIFICANT VALUES ARE GREYED OUT; SIGNIFICANT
VALUES ARE INDICATED WITH AN ASTERISK. THE BASELINE FOR
CONDITION IS SO, AND THE BASELINE FOR TASK IS SECURE
NETWORKING.
Participants‚Äô perceptions of the tasks only partially dove-
tailed with these results. We asked participants, on a 5-point
Likert scale, whether they were conÔ¨Ådent they had gotten the
297297








#
#
	

#
 #
#
Fig. 4. Top: Percentage of participants who produced functionally correct
solutions, by task and condition. Bottom: Percentage of participants whose
functionally correct solutions were scored as secure, by task and condition.
right answer for each task.6 Participants in condition free were
most conÔ¨Ådent: They agreed or strongly agreed they were
conÔ¨Ådent for 55.4% of tasks. Participants in each of the other
three conditions were conÔ¨Ådent for slightly fewer than half
of tasks: 47.3% in book and 46.2% in both SO and ofÔ¨Åcial.
Figure 5 illustrates these results.


	
	

	



	


%
 !%





!%
"!%
%
	




	

Fig. 5. Participants‚Äô conÔ¨Ådence in their tasks‚Äô correctness, by condition, on
a 1-5 Likert scale (1 = Strongly disagree, 5 = Strongly agree).
Using Cohen‚Äôs Œ∫, we examined whether participants‚Äô self-
reported conÔ¨Ådence in their tasks‚Äô correctness (binned as
strongly agree/agree and strongly disagree/disagree/neutral)
matched with our functional correctness result. We found
Œ∫ = 0.55, indicating that participants were assessing their
functional correctness only somewhat effectively.
Correctness per Task.
Observed correctness varied
strongly among the four tasks, as shown in Figure 4 (top). In
the least permissions task, 87.0% (47) of participants produced
6One book participant‚Äôs conÔ¨Ådence answer for the least permissions task
was inadvertently not recorded; we exclude that participant from conÔ¨Ådence
analyses only.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
in the secure networking task only
a functional solution;
33.3% (18) did. These results were mirrored in self-reported
conÔ¨Ådence: 81.1% of participants were conÔ¨Ådent about the
least permissions task, compared to 53.7% for secure storage,
40.7% for ICC, and only 20.1% for secure networking. The
CLMM analysis (Table III) indicates that both the secure
storage and least permissions tasks were signiÔ¨Åcantly more
likely to be functionally correct
than the baseline secure
networking task.
C. Security Results
Our results suggest that choice of resources has the opposite
effect on security than it did on functionality: SO participants
performed worst on this metric. As described in Section IV-E,
we scored tasks that had been solved correctly for security,
privacy, and adherence to least-privilege principles. In the SO
condition, only 51.4% (18/35) of functional solutions were
graded as secure, compared to 65.5% (19/29) for free, 73.0%
(27/37) for book, and 85.7% (18/21) for ofÔ¨Åcial. Figure 4
(bottom) illustrates these results. Using a CLMM that includes
only tasks that were graded as functionally correct (Table IV),
we Ô¨Ånd that both ofÔ¨Åcial and book produce signiÔ¨Åcantly more
secure results than . The difference between and free, in which
many participants elected to use Stack OverÔ¨Çow for most of
their tasks (see Section V-D), was not signiÔ¨Åcant.
Factor
free
ofÔ¨Åcial
book
ICC
least permissions
Coef. Exp(coef)
3.040
1.112
2.218
9.184
4.660
1.539
2.144
0.763
0.856
2.353
SE p-value
0.074
0.005*
0.011*
0.252
0.160
0.623
0.796
0.604
0.666
0.609
TABLE IV
CLMM REGRESSION TABLE FOR SECURITY. ONLY TASKS GRADED AS
FUNCTIONALLY CORRECT ARE INCLUDED IN THE MODEL. THE
NON-INTERACTION MODEL WITHOUT PROFESSIONAL STATUS WAS
SELECTED. NON-SIGNIFICANT VALUES ARE GREYED OUT; SIGNIFICANT
VALUES ARE INDICATED WITH AN ASTERISK. THE BASELINE FOR
CONDITION IS SO, AND THE BASELINE FOR TASK IS SECURE
NETWORKING.
Security per Task. As with correctness, security results dif-
fered noticeably among tasks. For example, every participant
who produced a functional solution to the storage task (31)
produced a secure solution. On the other hand, only 38.9%
(7/18) of participants who produced a functional solution to
the networking task were scored as secure. This discrepancy is
illustrated in Figure 4 (bottom). Our CLMM results (Table IV)
indicate that neither the ICC nor least permissions task was
signiÔ¨Åcantly different from the networking task. Because all
functional solutions to the storage task were graded as secure
regardless of condition, the regression coefÔ¨Åcient for that task
approaches inÔ¨Ånity, and the results of the model estimates for
that task are not interpretable. We omit it from the table.
Considering Security while Programming. We were also
interested in the extent to which participants thought about se-
curity while solving each task. We measured this in two ways.
298298
First, we considered the participants‚Äô think-aloud comments
for each task, classifying them as having either explicitly
mentioned security; mentioned security but later decided to
ignore it for the task at hand; or not mentioned security at all.
These classiÔ¨Åcations were independently coded by two coders
who then reached agreement, as discussed in Section IV-E.
We refer to this as observed security thinking. Second, we
asked participants during the exit interview to self-report for
each task whether or not they had considered security, as
a yes/no question. We refer to this metric as self-reported
security thinking. For both metrics, we considered all tasks,
not just those that participants completed correctly.
In the observed metric, most participants did not mention
security at all (79.2% of all tasks, 171). In the storage task, 16
participants (29.6%) mentioned security and all stuck with it;
in the networking task 20 mentioned security (37.0%) but nine
later abandoned it. In contrast, only Ô¨Åve and four participants
ever mentioned security or privacy in the least permissions
and ICC tasks, respectively. Common reasons for abandoning
security included that Ô¨Ånding a secure solution proved too
difÔ¨Åcult, that the task was for a study rather than real, and
that the participant was running short of time.
In the self-reported metric, more participants reported con-
sidering security: 60.2% of all tasks (130). Using this metric,
security was most frequently considered for secure networking
(79.6%), followed by ICC (70.4%) and secure storage (68.5%).
Only 22.2% of participants reported considering security for
the least permissions task. The higher rate of security thinking
using this metric is most likely attributable to the participants
being prompted.
To compare conditions, we assign each participant a sepa-
rate score for each metric, corresponding to the number of
tasks in which the participant considered security. In both
metrics the average scores were highest in book (0.93, 2.86)
and lowest in SO (0.69, 1.92), but neither difference was
signiÔ¨Åcant (Kruskal-Wallis, observed: X 2 = 0.507, p = 0.917,
self-report: X 2 = 4.728, p = 0.192).
Comparing Professionals and Non-Professionals.
Al-
though the relatively small sample of professionals we were
able to recruit makes comprehensive comparisons difÔ¨Åcult,
we examined differences in correctness and security between
these two groups. For purpose of this analysis, we categorize
14 participants as professionals,
including those who are
currently or recently had been professional developers. The
non-professional participants are primarily university students.
The professionals were randomly distributed across conditions:
Ô¨Åve in free, three in SO, two in ofÔ¨Åcial and four in book.
Overall, professionals were slightly more likely to produce
a functional solution, with a median three functionally correct
tasks (mean = 2.79, sd = 0.70) compared to two functionally
correct tasks (mean = 2.08, sd = 1.23) for non-professionals.
We observed essentially no difference in security results:
professionals‚Äô solutions were median 66.7% secure (mean =
69.0%, sd = 0.20), compared to 66.7% for non-professionals
(mean = 66.2%, sd = 0.36). These observations Ô¨Åt with
the CLMM results: professional status predicts a small but
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
signiÔ¨Åcant increase in functional correctness, but professional
status is excluded from the best-Ô¨Åtting security model.
D. Use of Resources
During the tasks, we collected the search terms used and
pages visited by all participants in non-book conditions. In
addition, during the exit
interview, we asked participants
several questions about the resources they were assigned to
use. In this section, we analyze participants‚Äô search and lookup
behavior as well as their self-reported opinions.
Lookup Behavior Across Conditions.
We deÔ¨Åne ‚Äúsearch queries" as submitting a search string
to a search engine or to the search boxes provided by Stack
OverÔ¨Çow and the ofÔ¨Åcial Android documentation. Participants
in the SO condition made on average 22.8 queries across
the four tasks, compared to 14.5 for the ofÔ¨Åcial condition.
Participants in free were closer to SO than ofÔ¨Åcial, with an
average of 21.1 queries. We also observed that participants
in the ofÔ¨Åcial, free and SO conditions visited on average
35.4, 36.1, and 53.2 unique web pages across the four tasks.
We offer two hypotheses for these results, based on on our
qualitative observations: First, ofÔ¨Åcial participants were more
likely to scroll through a table of contents or index and click
topics that seemed relevant (as opposed to doing a keyword
search) than those in other conditions, presumably because the
ofÔ¨Åcial documentation is more structured. Second and perhaps
more importantly, SO participants seemed to be more likely
to visit pages that turned out to be unhelpful and restart their
searches.
Participants in the free condition were given their choice of
Internet resources to help them solve the programming tasks.
Every free participant started every attempt to get help with
a Google search. Undoubtedly this was partially inÔ¨Çuenced
by Chrome using Google as the default start page as well as
automatically using Google search for terms entered in the
URL bar, but the complete unanimity (along with results from
the online survey) suggests that many or most attempts would
have started there anyway. From within their Google results,
every participant selected at least one page within the ofÔ¨Åcial
Android API documentation, and all but one visited Stack
OverÔ¨Çow as well. A few visited blogs, and one visited an
online book. These results are consistent with the online survey
results reported in Section III. In terms of frequency, ofÔ¨Åcial
documentation was most popular, representing between 50 and
85% of non-google-search pages for all participants except one
outlier who visited it 98% of the time. Most participants visited
Stack OverÔ¨Çow for between 10 and 40% of their pages, with
outliers at 0 and 2.4% as well as 50%. While participants in the
group visited more ofÔ¨Åcial documentation pages than pages at
Stack OverÔ¨Çow, their functionality and security results more
closely resemble the group than the ofÔ¨Åcial group. This may
be partially explained by a behavior pattern that we observed
several times in the free condition: participants spent some
time reading through the ofÔ¨Åcial documentation, but as the
time limit approached used content (often a copied and pasted
code snippet) from Stack OverÔ¨Çow.
Search Query Selection. We also examined the search
query text chosen by participants. Queries were normalized for
capitalization and spacing, and any queries within one string
edit of each other were consolidated (to account for plurals
and typos). Because few participants exactly duplicated one
another‚Äôs queries, in order to discern trends, one researcher
manually coded similar terms into categories. For example,
‚Äúrestrict access developers," ‚Äúrestrict app access for same de-
veloper," and ‚Äúrestrict apps same developer" were categorized
together. For the secure networking task, the most common
queries involved hostname exceptions and HTTPS, together
with just a few searches for certiÔ¨Åcates, certiÔ¨Åcate errors, and
hostname veriÔ¨Åers. For the ICC task, the most popular searches
included manifest, permissions, services, external access, and
restricting access. A few more knowledgeable participants
searched for intent Ô¨Ålters, user IDs, and signatures. For secure
storage, the most popular choices included storage, persistent
storage, and shared preferences; for least permissions partic-
ipants most frequently searched for call and phone call, with
a few searching for dial. Only four participants searched for
‚Äúsecure" or ‚Äúsecurity," including two in free and one each in
SO and ofÔ¨Åcial.
Participants‚Äô Opinions about Information Sources. We
asked our non-free participants whether they had previously
used their assigned resource. All 14 SO participants had
previously used Stack OverÔ¨Çow, and most (10/13) ofÔ¨Åcial
participants had used the ofÔ¨Åcial documentation. However,
only six of 14 book participants had used books. We also asked
participants to rate, on a Ô¨Åve-point Likert scale, the extent to
which the resources they used were easy to use, helpful, and
correct. Results are shown in Figure 6. As might be expected,
participants found free choice easiest to use and books least
easy; in contrast, they were most likely to consider books and
the ofÔ¨Åcial documentation to be correct.
We also asked about the effect of participants‚Äô assigned
resource on their performance. In every non-free condition, the
large majority (ofÔ¨Åcial: 92.3% (12/13); book: 92.9% (13/14);
SO: 78.6% (11/14)) said they would have performed better on
the tasks if they had been allowed to use different resources.
In particular, ofÔ¨Åcial and book participants said they would
have liked to access Stack OverÔ¨Çow or search engines such as
Google, so that they could search for their speciÔ¨Åc problems
rather than reading background information. One book user
mentioned the ‚Äúdanger that books could be outdated.‚Äù On the
other hand, many SO participants said they would have liked
to access the ofÔ¨Åcial documentation to read up on background
information for their problems.
Time constraints were also a concern for our participants.
Most (61.1%, 33) said they would probably have performed
better had they been given more time, while nine (16.7%)
mentioned (unprompted) that more time would have allowed
them to make their solutions more secure. One participant in
ofÔ¨Åcial, for example, said that ‚ÄúTwenty minutes is very limited
to consider security.‚Äù The remaining 38.9% said more time
would not have helped, either because they solved the tasks to
their satisfaction, or because they believed the resource they
299299
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:53 UTC from IEEE Xplore.  Restrictions apply. 
to-use if it was syntactically correct and a developer could
copy and paste it into an app. Each thread in which at least
one answer qualiÔ¨Åed was marked as containing a code snippet.
Each code snippet was individually rated as secure or insecure
relative to the programming tasks described in Section IV-C.
External Links. Within each thread, we looked for answers
containing external links. We classiÔ¨Åed threads as containing
links to GitHub, to other code repositories, to other Stack
OverÔ¨Çow threads, or to anywhere else. Additionally, we clas-
siÔ¨Åed the linked content as either secure or insecure.
Security Implications. We investigated whether any answer
in the thread discussed security implications of possible solu-
tions. For example, if two solutions existed and one included
an extra permission request, we checked whether any of the
answers discussed a violation of the least-privilege principle. If
an answer contained a NullHostnameVeriÔ¨Åer, we would check
if at least one of the answers would advise that veriÔ¨Åcation
should not be disabled.
B. ClassiÔ¨Åcation Results
Overall, our participants accessed 139 threads on Stack
OverÔ¨Çow. We categorized 41 threads as being on-topic. Table
V summarizes the classiÔ¨Åcation results for these 41 threads. Of
these, 20 threads contained code snippets. Half of the threads
containing code snippets contained only insecure snippets,
such as instructions to use NullHostnameVeriÔ¨Åers and Null-
TrustManagers, which will accept all certiÔ¨Åcates regardless
of validity. Among these 10 threads containing only insecure
code snippets, only three described the security implications
of using them. This creates the possibility for developers
to simply copy and paste a ‚Äúfunctional‚Äù solution that voids
existing security measures, without realizing the consequences
of their actions. More encouragingly, seven of the 10 remain-
ing threads with code snippets contained only secure code
snippets.
We next investigated how threads with different properties
compared in terms of popularity (measured by total upvotes for
the thread). Unsurprisingly, we found that threads with code
snippets were more popular than those without (W = 319.5,
p = 0.00217, Œ± = 0.025, Wilcoxon-Signed-Rank Test (B-H)).
Discouragingly, we found no statistical difference between
threads with secure and insecure code snippets (W = 73,
p = 0.188). On the other hand, threads that discuss security
implications are slightly more popular than those that don‚Äôt
(W = 239.5, p = 0.0308, Œ± = 0.05 (B-H)).
Although these results cover only a very small sample of
Stack OverÔ¨Çow threads, they provide some insight into why
our SO participants had lower security scores than those in
the ofÔ¨Åcial condition.
VII. PROGRAMMING TASK VALIDITY
To provide evidence for the validity of our lab study
tasks and results, we examined how the APIs used in our
programming tasks (cf. Table I) are used in real-world apps.
In particular, we were interested in how frequently these APIs
are used in real Google Play apps, as well as whether secure or
300300
Fig. 6.
Participants‚Äô agreement (on a Ô¨Åve-point Likert scale) with the
statements that the resources they used were easy to use, helpful, and correct,
by condition.
were using did not allow them to Ô¨Ånd a (better) solution.
VI. QUALITY OF STACK OVERFLOW RESPONSES
To better contextualize the performance of the participants
‚Äì in both, the SO and free condition ‚Äì, we examined in detail
all Stack OverÔ¨Çow pages (threads) visited by our participants
during the programming tasks. In particular, we were curious
about whether these pages contained secure and/or insecure
examples and code snippets, and whether the security im-
plications were explained. As might be expected, we found
many discouraging instances of insecure examples and few
discussions of security implications.
A. ClassiÔ¨Åcation Methodology
We rated each thread on Ô¨Åve different attributes, described