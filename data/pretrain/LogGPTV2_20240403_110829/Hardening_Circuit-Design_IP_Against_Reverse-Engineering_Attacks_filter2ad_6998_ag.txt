[33] R. S. Chakraborty and S. Bhunia, “Harpoon: an obfuscation-based soc
design methodology for hardware protection,” IEEE Transactions on
Computer-Aided Design of Integrated Circuits and Systems, vol. 28,
no. 10, pp. 1493–1502, 2009.
[34] Y. Alkabani, F. Koushanfar, and M. Potkonjak, “Remote activation of
ics for piracy prevention and digital right management,” in Proceedings
of the 2007 IEEE/ACM international conference on Computer-aided
design.
IEEE Press, 2007, pp. 674–677.
[35] A. R. Desai, M. S. Hsiao, C. Wang, L. Nazhandali, and S. Hall,
“Interlocking obfuscation for anti-tamper hardware,” in Proceedings of
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1685
the eighth annual cyber security and information intelligence research
workshop. ACM, 2013, p. 8.
[36] J. Dofe and Q. Yu, “Novel dynamic state-deﬂection method for gate-level
design obfuscation,” IEEE Transactions on Computer-Aided Design of
Integrated Circuits and Systems, vol. 37, no. 2, pp. 273–285, 2017.
[37] M. Fyrbiak, S. Wallat, J. D´echelotte, N. Albartus, S. B¨ocker, R. Tessier,
and C. Paar, “On the difﬁculty of fsm-based hardware obfuscation,”
IACR Transactions on Cryptographic Hardware and Embedded Systems,
pp. 293–330, 2018.
[38] M. E. Massad, J. Zhang, S. Garg, and M. V. Tripunitara, “Logic
locking for secure outsourced chip fabrication: A new attack and
provably secure defense mechanism,” CoRR, vol. abs/1703.10187,
2017. [Online]. Available: http://arxiv.org/abs/1703.10187
[39] M. Li, K. Shamsi, T. Meade, Z. Zhao, B. Yu, Y. Jin, and D. Z.
Pan, “Provably secure camouﬂaging strategy for ic protection,” in
Proceedings of the 35th International Conference on Computer-Aided
Design, ser. ICCAD ’16. New York, NY, USA: ACM, 2016, pp. 28:1–
28:8. [Online]. Available: http://doi.acm.org/10.1145/2966986.2967065
[40] S. Engels, M. Hoffmann, and C. Paar, “The end of logic locking?
a critical view on the security of logic locking,” Cryptology ePrint
Archive, Report 2019/796, 2019, https://eprint.iacr.org/2019/796.
[41] J.-M. Cioranesco, J.-L. Danger, T. Graba, S. Guilley, Y. Mathieu,
D. Naccache, and X. T. Ngo, “Cryptographically secure shields,” in
2014 IEEE International Symposium on Hardware-Oriented Security
and Trust (HOST).
IEEE, 2014, pp. 25–31.
[42] E. Kushilevitz and Y. Mansour, “Learning decision trees using the fourier
spectrum,” SIAM Journal on Computing, vol. 22, no. 6, pp. 1331–1348,
1993.
[43] P. Gopalan, R. O’Donnell, R. A. Servedio, A. Shpilka, and K. Wimmer,
“Testing fourier dimensionality and sparsity,” SIAM Journal on Com-
puting, vol. 40, no. 4, pp. 1075–1100, 2011.
[44] J. Rajendran, Y. Pino, O. Sinanoglu, and R. Karri, “Security analysis of
logic obfuscation,” in DAC Design Automation Conference 2012, June
2012, pp. 83–89.
[45] ——, “Logic encryption: A fault analysis perspective,” in Proceedings
of the Conference on Design, Automation and Test in Europe, ser.
DATE ’12. San Jose, CA, USA: EDA Consortium, 2012, pp. 953–958.
[Online]. Available: http://dl.acm.org/citation.cfm?id=2492708.2492947
[46] S. Dupuis, P.-S. Ba, G. Di Natale, M.-L. Flottes, and B. Rouzeyre,
“A novel hardware logic encryption technique for thwarting illegal
overproduction and hardware trojans,” in On-Line Testing Symposium
(IOLTS), 2014 IEEE 20th International.
IEEE, 2014, pp. 49–54.
[47] S. M. Plaza and I. L. Markov, “Protecting integrated circuits from
piracy with test-aware logic locking,” in 2014 IEEE/ACM International
Conference on Computer-Aided Design (ICCAD), Nov 2014, pp. 262–
269.
[48] R. S. Chakraborty and S. Bhunia, “Security against hardware trojan
attacks using key-based design obfuscation,” Journal of Electronic
Testing, vol. 27, no. 6, pp. 767–785, 2011.
[49] A. Baumgarten, A. Tyagi, and J. Zambreno, “Preventing ic piracy
using reconﬁgurable logic barriers,” IEEE Design & Test of Computers,
vol. 27, no. 1, 2010.
[50] M. Yasin, B. Mazumdar, O. Sinanoglu, and J. Rajendran, “Security
analysis of anti-sat,” in 2017 22nd Asia and South Paciﬁc Design
Automation Conference (ASP-DAC).
IEEE, 2017, pp. 342–347.
[51] R. De Wolf, “A brief introduction to fourier analysis on the boolean
cube,” Theory of Computing, pp. 1–20, 2008.
[52] Z. Brakerski and G. N. Rothblum, “Virtual black-box obfuscation for
all circuits via generic graded encoding,” in Theory of Cryptography
Conference. Springer, 2014, pp. 1–25.
[53] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan,
and K. Yang, “On the (im) possibility of obfuscating programs,” in
Annual International Cryptology Conference. Springer, 2001, pp. 1–18.
[54] A. C.-C. Yao, “Protocols for secure computations,” in FOCS, vol. 82,
1982, pp. 160–164.
[55] D. Evans, V. Kolesnikov, M. Rosulek et al., “A pragmatic introduction to
secure multi-party computation,” Foundations and Trends® in Privacy
and Security, vol. 2, no. 2-3, pp. 70–246, 2018.
[56] M. Bellare, V. T. Hoang, and P. Rogaway, “Foundations of garbled
circuits,” in Proceedings of the 2012 ACM conference on Computer and
communications security. ACM, 2012, pp. 784–796.
[57] Y. Lindell, “Secure multiparty computation for privacy preserving data
mining,” in Encyclopedia of Data Warehousing and Mining. IGI Global,
2005, pp. 1005–1009.
[58] M. Bellare, V. T. Hoang, S. Keelveedhi, and P. Rogaway, “Efﬁcient
garbling from a ﬁxed-key blockcipher,” in 2013 IEEE Symposium on
Security and Privacy.
IEEE, 2013, pp. 478–492.
[59] V. Kolesnikov, P. Mohassel, and M. Rosulek, “Flexor: Flexible garbling
for xor gates that beats free-xor,” in Annual Cryptology Conference.
Springer, 2014, pp. 440–457.
[60] S. Zahur, M. Rosulek, and D. Evans, “Two halves make a whole,” in
Annual International Conference on the Theory and Applications of
Cryptographic Techniques. Springer, 2015, pp. 220–250.
[61] J. B. Nielsen, P. S. Nordholt, C. Orlandi, and S. S. Burra, “A new
approach to practical active-secure two-party computation,” Cryptology
ePrint Archive, Report 2011/091, 2011, https://eprint.iacr.org/2011/091.
[62] H. Carter and P. Traynor, “Opfe: Outsourcing computation for private
function evaluation.” IACR Cryptology ePrint Archive, vol. 2016, p. 67,
2016.
[63] S. Kamara, P. Mohassel, and B. Riva, “Salus: a system for server-aided
secure function evaluation,” in Proceedings of the 2012 ACM conference
on Computer and communications security, 2012, pp. 797–808.
[64] T. P. Jakobsen, J. B. Nielsen, and C. Orlandi, “A framework for
outsourcing of secure computation,” in Proceedings of the 6th edition
of the ACM Workshop on Cloud Computing Security, 2014, pp. 81–92.
[65] D. Malkhi, N. Nisan, B. Pinkas, Y. Sella et al., “Fairplay-secure two-
party computation system.” in USENIX Security Symposium, vol. 4. San
Diego, CA, USA, 2004, p. 9.
[66] B. Kreuter, A. Shelat, B. Mood, and K. Butler, “{PCF}: A portable
circuit format for scalable two-party secure computation,” in Presented
as part of the 22nd {USENIX} Security Symposium ({USENIX} Security
13), 2013, pp. 321–336.
[67] L. Malka, “Vmcrypt: modular software architecture for scalable secure
computation,” in Proceedings of the 18th ACM conference on Computer
and communications security, 2011, pp. 715–724.
[68] E. M. Songhori, S. U. Hussain, A.-R. Sadeghi, T. Schneider, and
F. Koushanfar, “Tinygarble: Highly compressed and scalable sequential
garbled circuits,” in 2015 IEEE Symposium on Security and Privacy.
IEEE, 2015, pp. 411–428.
[69] E. Boyle, N. Gilboa, and Y. Ishai, “Function secret sharing,” in Annual
international conference on the theory and applications of cryptographic
techniques. Springer, 2015, pp. 337–367.
A. Historical context
APPENDIX
In 2008, the ﬁrst logic-locking scheme (random-logic lock-
ing (RLL) [6]) was designed. The ostensible security goal of
RLL was to construct an opaque circuit that hides the full
functionality F of the IP author’s circuit from an adversarial
foundry who has unrestricted access to the opaque circuit and
oracle access to F . However, the authors of RLL claimed
that their scheme is secure because it prevents an adversary
from recovering the correct key using a brute-force key-search
attack.
Note that the security goal of preventing key recovery (KR)
misses the original intent; namely, to prevent the adversary
from learning the functionality of the IP author’s circuit. Thus,
preventing function recovery (FR) is arguably a more pertinent
security goal.
Between 2008 and 2015, several variants [6], [44]–[46], [49]
of RLL were designed. Each claimed security by (empirically)
showing that their scheme is resilient against few KR attacks.
In 2015, Subramanyan et al. [17] gave a KR attack (popularly
known as the SAT attack) and empirically showed that the
correct key can be efﬁciently recovered from circuits locked
with RLL and its variants.
From 2015 to 2021 (before our work), several new logic-
locking schemes [15], [27]–[32] were designed, primarily to
thwart the SAT attack.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1686
At a high level, prior works use the following steps to design
a logic-locking scheme:
1) generate an opaque circuit using some structural modiﬁ-
cations of the original circuit;
2) show that the opaque circuit has low power, performance
and area overhead;
3) claim security by empirically showing that the scheme is
resilient against few KR attacks.
Strangely, these schemes (implicitly) claim that circuits with
very small domain can be hidden. This is impossible since
an adversary can use its oracle access to a restored chip
(purchased from the market) to build the full truth table of
the original circuit. Not only that, almost all logic-locking
schemes have been shown to be vulnerable to efﬁcient KR
attacks, e.g., [16]–[26] that allows the foundry to deﬁne the
functionality F in full.
B. Relation to Existing Cryptographic Primitives
Our security notions capture an attack on the privacy of
the IP author’s circuit design. Thus, it is natural to think of
related cryptographic primitives: program obfuscation, multi-
party computation, encryption and function secret sharing.
PROGRAM OBFUSCATION. Design hiding is orthogonal to
recent work in cryptography on program/circuit obfuscation
(e.g. [52], [53]). Loosely, obfuscation in the latter setting
makes the syntactic requirement that the obfuscated circuit
have the same input-output functionality as the original circuit.
In the design-hiding setting, at an abstract level, the opaque
circuit implements a set of functions. It is only when the chip
is restored, via the secret key, that the chip must faithfully
compute the intended function.
MULTIPARTY COMPUTATION. Secure multi-party computa-
tion [54]–[57] allows two or more parties to “securely” com-
pute some arbitrary function on inputs that are secrets of the
respective parties.
Though MPC has become increasingly feasible to deploy
in real-world systems [58]–[68], we cannot use it to design
secure DH schemes in the logic-locking setting because of
the fundamental differences in the threat models.
Logic locking involves two parties: the IP author (whose
IC design needs to be protected), and the adversarial foundry
(who is responsible for fabricating multiple opaque chips from
the opaque circuit). The two popular settings of two-party
computation that have some similarity to the logic-locking
setting are: secure-function evaluation (SFE) [55], [56], [63]
and private-function evaluation (PFE) [55]–[57], [62], and the
threat models of both are different compared to logic locking.
In SFE, the function that is evaluated is public, and the
input of the other party is private. Clearly, SFE is not suitable
in the logic-locking setting as it requires the IC design of the
IP author to be public. In PFE, the function that is evaluated
is a private input of one party, and the input to the function
is private to the other party. The logic-locking setting satisﬁes
this aspect of PFE as the IC design is the private input of
the IP author. However, the adversarial foundry gets a lot
of side information about the concealed IC design due to its
unrestricted access to the opaque circuit and oracle access to
an honestly-restored chip. This violates the PFE security goal
as the party that does not have access to the function — secret
input of the other party — should learn only the value of the
function on the secret input. Hence, PFE is also not suitable
in the logic-locking setting.
ENCRYPTION. In order to fabricate chips, the foundry parses
the layout (described using the GDSII format) of a circuit
design to replace the API calls to its hardware library with
physical circuits. Thus, one cannot simply encrypt (say) the
layout ﬁle before handing it to the foundry: secure encryption
schemes produce ciphertexts that are indistinguishable from
random bit-string, which almost certainly will not encode
a valid circuit. Even if it did, that circuit would have no
relationship to one realizing the intended functionality, thereby
forfeiting the economic beneﬁt of outsourced fabrication. And
clearly the foundry cannot be allowed to decrypt the ciphertext,
if it is not trusted in the ﬁrst place.
FUNCTION SECRET SHARING. In 2015, Boyle et al. [69]
introduced a cryptographic primitive called function secret
sharing (FSS) that partitions a function F into multiple shares
— the shares are distributed among multiple parties — such
that an adversary that does not have access to all the shares
learns nothing about F . The threat model of FSS prevents the
adversary to learn the value of F on any input. In fact, if
the adversary gets oracle access to F akin to the DH setting,
the security of the FSS construction [69][Section 3] for point
functions in the two-party setting falls apart as the adversary
can use a single oracle query to identify the point function
that was protected by FSS in the security experiment.
C. Fully-malicious adversaries break KR security
Hardware trojans are malicious modiﬁcations to a target
circuit that are hard to detect [48]. For example, a key-leaking
hardware trojan in a cryptographic IP core (say, AES) leaks
the secret key, when the IP core is run on a small and speciﬁc
sequence of triggering inputs. A standard assumption in trojan-
insertion attacks requires the adversary to have unrestricted
access to the target circuit in order to make trojans stealthy.
In our security experiments, an adversarial foundry gets un-
restricted access to the opaque circuit CL that the experiments
generate using Hide. When the foundry is fully malicious, it
can insert a key-leaking hardware trojan (T ) in CL to leak the
key KO.
Consider the following (slightly informal) KR attack in
the fully-malicious setting against any DH scheme Π where:
Restore ﬁxes the ko(θ) key-input bits to restore the original,
intended functionality. (Logic-locking schemes like RLL [6]
and its variants [44]–[46] and SAT-attack-resistant schemes
[15], [27]–[29], [32] ﬁt this description perfectly.)
• Query FAB with C T
L to get a chip CT
the opaque circuit CL with trojan T .
• Query RESTORE with CT
L to get the index p of an honestly-
restored chip CP . Let I be the sequence of triggering inputs
L, where C T
L denotes
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:33:25 UTC from IEEE Xplore.  Restrictions apply. 
1687
Fig. 5: Representation of F and H using Xi(·). The orange
(resp. blue) box denotes the distinguishing inputs that fall in
set X1(H) (resp. X0(H)). By construction of OneChaffhd, the
orange (resp. blue) box belongs to X0(F ) (resp. X1(F )).
for the trojan T . By design, CP contains the trojan T and
leaks the key Ko when CP is run on inputs in I.
• Query RUN with inputs (p,I[1]), (p,I[2]), . . . , (p,I[v]) to
recover KO. Here, v = |I|.
This attack breaks the KR security of Π. In order to
thwart this attack, Restore has to detect arbitrary, key-leaking
hardware trojans. We do not know how this can be achieved in
the setting of design-hiding schemes such as logic locking —
the main focus of our work — where the IP author outsources
the entire fabrication process to an external foundry. Therefore,
our security theorems assume that the adversary is honest-
but-curious. Recall that none of the existing DH schemes
considered Fab as part of the syntax. Hence, by default, these
schemes are designed in the honest-but-curious setting.
Note that Dziembowski et al. [13] showed that it is possible
to design “trojan-resilient” circuits using split manufacturing
as a DH scheme; as mentioned earlier, split manufacturing
requires the IP author to fabricate a portion of the circuit and
hence is not a common setting in IC supply chain; instead we
focus on the stronger logic-locking setting in this work.
D. Delayed Proofs and a Theorem
Proof of Claim 1. Any Boolean function H can be described
fully using sets X0(H) and X1(H). Recall that Xi(H) denotes
the set of all inputs for which H’s value is i. In Fig. 5, we
show the representation of F and H using their respective Xi.
For i ∈ {0, 1} and for any ˆF ∈ RL, let Si(H, ˆF ) = Si =
I(cid:54)=(H, ˆF ) ∩ Xi(H). By construction: S1, S0 are disjoint, and
Si ⊂ X1−i( ˆF ) as ˆF (X) = ¬H(X) for all X ∈ I(cid:54)=(H, ˆF ).
We can build X1( ˆF ) using the sets X1(H) and Si in three
steps. First, initialize X1( ˆF ) = X1(H). Then, remove all
elements in set S1 from X1( ˆF ), and in the ﬁnal step, add
all elements of set S0, i.e., X1( ˆF ) = (X1(H) \ S1) ∪ S0.