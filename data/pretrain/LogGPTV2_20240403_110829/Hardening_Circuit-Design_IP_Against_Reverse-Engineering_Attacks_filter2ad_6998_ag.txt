### References

1. R. S. Chakraborty and S. Bhunia, "Harpoon: An Obfuscation-Based SoC Design Methodology for Hardware Protection," *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, vol. 28, no. 10, pp. 1493–1502, 2009.
2. Y. Alkabani, F. Koushanfar, and M. Potkonjak, "Remote Activation of ICs for Piracy Prevention and Digital Right Management," in *Proceedings of the 2007 IEEE/ACM International Conference on Computer-Aided Design*. IEEE Press, 2007, pp. 674–677.
3. A. R. Desai, M. S. Hsiao, C. Wang, L. Nazhandali, and S. Hall, "Interlocking Obfuscation for Anti-Tamper Hardware," in *Proceedings of the Eighth Annual Cyber Security and Information Intelligence Research Workshop*. ACM, 2013, p. 8.
4. J. Dofe and Q. Yu, "Novel Dynamic State-Deflection Method for Gate-Level Design Obfuscation," *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, vol. 37, no. 2, pp. 273–285, 2017.
5. M. Fyrbiak, S. Wallat, J. Déchelotte, N. Albartus, S. Böcker, R. Tessier, and C. Paar, "On the Difficulty of FSM-Based Hardware Obfuscation," *IACR Transactions on Cryptographic Hardware and Embedded Systems*, pp. 293–330, 2018.
6. M. E. Massad, J. Zhang, S. Garg, and M. V. Tripunitara, "Logic Locking for Secure Outsourced Chip Fabrication: A New Attack and Provably Secure Defense Mechanism," *CoRR*, vol. abs/1703.10187, 2017. [Online]. Available: http://arxiv.org/abs/1703.10187
7. M. Li, K. Shamsi, T. Meade, Z. Zhao, B. Yu, Y. Jin, and D. Z. Pan, "Provably Secure Camouflaging Strategy for IC Protection," in *Proceedings of the 35th International Conference on Computer-Aided Design (ICCAD '16)*. New York, NY, USA: ACM, 2016, pp. 28:1–28:8. [Online]. Available: http://doi.acm.org/10.1145/2966986.2967065
8. S. Engels, M. Hoffmann, and C. Paar, "The End of Logic Locking? A Critical View on the Security of Logic Locking," *Cryptology ePrint Archive*, Report 2019/796, 2019. [Online]. Available: https://eprint.iacr.org/2019/796
9. J.-M. Cioranesco, J.-L. Danger, T. Graba, S. Guilley, Y. Mathieu, D. Naccache, and X. T. Ngo, "Cryptographically Secure Shields," in *2014 IEEE International Symposium on Hardware-Oriented Security and Trust (HOST)*. IEEE, 2014, pp. 25–31.
10. E. Kushilevitz and Y. Mansour, "Learning Decision Trees Using the Fourier Spectrum," *SIAM Journal on Computing*, vol. 22, no. 6, pp. 1331–1348, 1993.
11. P. Gopalan, R. O’Donnell, R. A. Servedio, A. Shpilka, and K. Wimmer, "Testing Fourier Dimensionality and Sparsity," *SIAM Journal on Computing*, vol. 40, no. 4, pp. 1075–1100, 2011.
12. J. Rajendran, Y. Pino, O. Sinanoglu, and R. Karri, "Security Analysis of Logic Obfuscation," in *DAC Design Automation Conference 2012*, June 2012, pp. 83–89.
13. ——, "Logic Encryption: A Fault Analysis Perspective," in *Proceedings of the Conference on Design, Automation and Test in Europe (DATE '12)*. San Jose, CA, USA: EDA Consortium, 2012, pp. 953–958. [Online]. Available: http://dl.acm.org/citation.cfm?id=2492708.2492947
14. S. Dupuis, P.-S. Ba, G. Di Natale, M.-L. Flottes, and B. Rouzeyre, "A Novel Hardware Logic Encryption Technique for Thwarting Illegal Overproduction and Hardware Trojans," in *On-Line Testing Symposium (IOLTS), 2014 IEEE 20th International*. IEEE, 2014, pp. 49–54.
15. S. M. Plaza and I. L. Markov, "Protecting Integrated Circuits from Piracy with Test-Aware Logic Locking," in *2014 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, Nov 2014, pp. 262–269.
16. R. S. Chakraborty and S. Bhunia, "Security Against Hardware Trojan Attacks Using Key-Based Design Obfuscation," *Journal of Electronic Testing*, vol. 27, no. 6, pp. 767–785, 2011.
17. A. Baumgarten, A. Tyagi, and J. Zambreno, "Preventing IC Piracy Using Reconfigurable Logic Barriers," *IEEE Design & Test of Computers*, vol. 27, no. 1, 2010.
18. M. Yasin, B. Mazumdar, O. Sinanoglu, and J. Rajendran, "Security Analysis of Anti-SAT," in *2017 22nd Asia and South Pacific Design Automation Conference (ASP-DAC)*. IEEE, 2017, pp. 342–347.
19. R. De Wolf, "A Brief Introduction to Fourier Analysis on the Boolean Cube," *Theory of Computing*, pp. 1–20, 2008.
20. Z. Brakerski and G. N. Rothblum, "Virtual Black-Box Obfuscation for All Circuits via Generic Graded Encoding," in *Theory of Cryptography Conference*. Springer, 2014, pp. 1–25.
21. B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich, A. Sahai, S. Vadhan, and K. Yang, "On the (Im) Possibility of Obfuscating Programs," in *Annual International Cryptology Conference*. Springer, 2001, pp. 1–18.
22. A. C.-C. Yao, "Protocols for Secure Computations," in *FOCS*, vol. 82, 1982, pp. 160–164.
23. D. Evans, V. Kolesnikov, M. Rosulek et al., "A Pragmatic Introduction to Secure Multi-Party Computation," *Foundations and Trends® in Privacy and Security*, vol. 2, no. 2-3, pp. 70–246, 2018.
24. M. Bellare, V. T. Hoang, and P. Rogaway, "Foundations of Garbled Circuits," in *Proceedings of the 2012 ACM Conference on Computer and Communications Security*. ACM, 2012, pp. 784–796.
25. Y. Lindell, "Secure Multiparty Computation for Privacy Preserving Data Mining," in *Encyclopedia of Data Warehousing and Mining*. IGI Global, 2005, pp. 1005–1009.
26. M. Bellare, V. T. Hoang, S. Keelveedhi, and P. Rogaway, "Efficient Garbling from a Fixed-Key Blockcipher," in *2013 IEEE Symposium on Security and Privacy*. IEEE, 2013, pp. 478–492.
27. V. Kolesnikov, P. Mohassel, and M. Rosulek, "Flexor: Flexible Garbling for XOR Gates That Beats Free-XOR," in *Annual Cryptology Conference*. Springer, 2014, pp. 440–457.
28. S. Zahur, M. Rosulek, and D. Evans, "Two Halves Make a Whole," in *Annual International Conference on the Theory and Applications of Cryptographic Techniques*. Springer, 2015, pp. 220–250.
29. J. B. Nielsen, P. S. Nordholt, C. Orlandi, and S. S. Burra, "A New Approach to Practical Active-Secure Two-Party Computation," *Cryptology ePrint Archive*, Report 2011/091, 2011. [Online]. Available: https://eprint.iacr.org/2011/091
30. H. Carter and P. Traynor, "OPFE: Outsourcing Computation for Private Function Evaluation," *IACR Cryptology ePrint Archive*, vol. 2016, p. 67, 2016.
31. S. Kamara, P. Mohassel, and B. Riva, "Salus: A System for Server-Aided Secure Function Evaluation," in *Proceedings of the 2012 ACM Conference on Computer and Communications Security*. 2012, pp. 797–808.
32. T. P. Jakobsen, J. B. Nielsen, and C. Orlandi, "A Framework for Outsourcing of Secure Computation," in *Proceedings of the 6th Edition of the ACM Workshop on Cloud Computing Security*. 2014, pp. 81–92.
33. D. Malkhi, N. Nisan, B. Pinkas, Y. Sella et al., "Fairplay—Secure Two-Party Computation System," in *USENIX Security Symposium*, vol. 4. San Diego, CA, USA, 2004, p. 9.
34. B. Kreuter, A. Shelat, B. Mood, and K. Butler, "PCF: A Portable Circuit Format for Scalable Two-Party Secure Computation," in *Presented as Part of the 22nd USENIX Security Symposium (USENIX Security 13)*. 2013, pp. 321–336.
35. L. Malka, "VMCrypt: Modular Software Architecture for Scalable Secure Computation," in *Proceedings of the 18th ACM Conference on Computer and Communications Security*. 2011, pp. 715–724.
36. E. M. Songhori, S. U. Hussain, A.-R. Sadeghi, T. Schneider, and F. Koushanfar, "TinyGarble: Highly Compressed and Scalable Sequential Garbled Circuits," in *2015 IEEE Symposium on Security and Privacy*. IEEE, 2015, pp. 411–428.
37. E. Boyle, N. Gilboa, and Y. Ishai, "Function Secret Sharing," in *Annual International Conference on the Theory and Applications of Cryptographic Techniques*. Springer, 2015, pp. 337–367.

### Appendix

#### A. Historical Context

In 2008, the first logic-locking scheme, Random-Logic Locking (RLL), was introduced. The primary security goal of RLL was to construct an opaque circuit that conceals the full functionality \( F \) of the IP author's circuit from an adversarial foundry, which has unrestricted access to the opaque circuit and oracle access to \( F \). The authors of RLL claimed that their scheme is secure because it prevents an adversary from recovering the correct key using a brute-force key-search attack.

However, preventing key recovery (KR) misses the original intent, which is to prevent the adversary from learning the functionality of the IP author's circuit. Thus, preventing function recovery (FR) is a more pertinent security goal.

Between 2008 and 2015, several variants of RLL were designed, each claiming security by empirically showing resilience against KR attacks. In 2015, Subramanyan et al. [17] introduced a KR attack (popularly known as the SAT attack) and demonstrated that the correct key can be efficiently recovered from circuits locked with RLL and its variants.

From 2015 to 2021, several new logic-locking schemes were designed primarily to thwart the SAT attack. Prior works generally followed these steps:
1. Generate an opaque circuit using structural modifications of the original circuit.
2. Show that the opaque circuit has low power, performance, and area overhead.
3. Claim security by empirically demonstrating resilience against KR attacks.

These schemes implicitly claim that circuits with very small domains can be hidden, which is impossible since an adversary can use oracle access to a restored chip (purchased from the market) to build the full truth table of the original circuit. Almost all logic-locking schemes have been shown to be vulnerable to efficient KR attacks, allowing the foundry to define the functionality \( F \) in full.

#### B. Relation to Existing Cryptographic Primitives

Our security notions address an attack on the privacy of the IP author's circuit design. Related cryptographic primitives include program obfuscation, multi-party computation, encryption, and function secret sharing.

**PROGRAM OBFUSCATION**: Design hiding is orthogonal to recent work in cryptography on program/circuit obfuscation (e.g., [52], [53]). Obfuscation in the latter setting requires the obfuscated circuit to have the same input-output functionality as the original circuit. In the design-hiding setting, the opaque circuit implements a set of functions, and only when the chip is restored via the secret key does it compute the intended function.

**MULTIPARTY COMPUTATION**: Secure multi-party computation (MPC) [54]–[57] allows two or more parties to securely compute some arbitrary function on inputs that are secrets of the respective parties. While MPC has become increasingly feasible to deploy in real-world systems [58]–[68], it cannot be used to design secure DH schemes in the logic-locking setting due to fundamental differences in threat models.

Logic locking involves two parties: the IP author (whose IC design needs to be protected) and the adversarial foundry (responsible for fabricating multiple opaque chips from the opaque circuit). The two popular settings of two-party computation that have some similarity to the logic-locking setting are secure-function evaluation (SFE) [55], [56], [63] and private-function evaluation (PFE) [55]–[57], [62].

In SFE, the function evaluated is public, and the input of the other party is private. This is not suitable for logic locking, as it requires the IC design of the IP author to be public. In PFE, the function evaluated is a private input of one party, and the input to the function is private to the other party. The logic-locking setting satisfies this aspect of PFE, but the adversarial foundry gets side information about the concealed IC design due to unrestricted access to the opaque circuit and oracle access to an honestly-restored chip. This violates the PFE security goal, making PFE unsuitable in the logic-locking setting.

**ENCRYPTION**: To fabricate chips, the foundry parses the layout (described using the GDSII format) of a circuit design to replace API calls to its hardware library with physical circuits. Encrypting the layout file before handing it to the foundry is not feasible, as secure encryption schemes produce ciphertexts indistinguishable from random bit-strings, which almost certainly will not encode a valid circuit. Even if they did, the circuit would have no relationship to the intended functionality, forfeiting the economic benefit of outsourced fabrication. The foundry cannot be allowed to decrypt the ciphertext if it is not trusted.

**FUNCTION SECRET SHARING**: In 2015, Boyle et al. [69] introduced function secret sharing (FSS), which partitions a function \( F \) into multiple shares distributed among multiple parties. An adversary without access to all shares learns nothing about \( F \). The threat model of FSS prevents the adversary from learning the value of \( F \) on any input. If the adversary gets oracle access to \( F \) akin to the DH setting, the security of the FSS construction [69][Section 3] for point functions in the two-party setting falls apart, as the adversary can use a single oracle query to identify the point function protected by FSS.

#### C. Fully-Malicious Adversaries Break KR Security

Hardware trojans are malicious modifications to a target circuit that are hard to detect [48]. For example, a key-leaking hardware trojan in a cryptographic IP core (e.g., AES) leaks the secret key when the IP core is run on a specific sequence of triggering inputs. A standard assumption in trojan-insertion attacks requires the adversary to have unrestricted access to the target circuit to make trojans stealthy.

In our security experiments, an adversarial foundry gets unrestricted access to the opaque circuit \( C_L \) generated using Hide. When the foundry is fully malicious, it can insert a key-leaking hardware trojan \( T \) in \( C_L \) to leak the key \( K_O \).

Consider the following KR attack in the fully-malicious setting against any DH scheme \( \Pi \) where Restore fixes the \( k_o(\theta) \) key-input bits to restore the original, intended functionality (logic-locking schemes like RLL [6] and its variants [44]–[46] and SAT-attack-resistant schemes [15], [27]–[29], [32] fit this description):

1. Query FAB with \( C_T^L \) to get a chip \( C_T \) (the opaque circuit \( C_L \) with trojan \( T \)).
2. Query RESTORE with \( C_T^L \) to get the index \( p \) of an honestly-restored chip \( C_P \). Let \( I \) be the sequence of triggering inputs for the trojan \( T \). By design, \( C_P \) contains the trojan \( T \) and leaks the key \( K_O \) when \( C_P \) is run on inputs in \( I \).
3. Query RUN with inputs \((p, I[1]), (p, I[2]), \ldots, (p, I[v])\) to recover \( K_O \). Here, \( v = |I| \).

This attack breaks the KR security of \( \Pi \). To thwart this attack, Restore must detect arbitrary, key-leaking hardware trojans. We do not know how this can be achieved in the setting of design-hiding schemes such as logic locking, where the IP author outsources the entire fabrication process to an external foundry. Therefore, our security theorems assume that the adversary is honest-but-curious. None of the existing DH schemes considered FAB as part of the syntax, so these schemes are designed in the honest-but-curious setting.

Note that Dziembowski et al. [13] showed that it is possible to design "trojan-resilient" circuits using split manufacturing as a DH scheme. However, split manufacturing requires the IP author to fabricate a portion of the circuit, which is not a common setting in IC supply chains. Instead, we focus on the stronger logic-locking setting in this work.

#### D. Delayed Proofs and a Theorem

**Proof of Claim 1**: Any Boolean function \( H \) can be described fully using sets \( X_0(H) \) and \( X_1(H) \). Recall that \( X_i(H) \) denotes the set of all inputs for which \( H \)'s value is \( i \). In Fig. 5, we show the representation of \( F \) and \( H \) using their respective \( X_i \).

For \( i \in \{0, 1\} \) and for any \( \hat{F} \in R_L \), let \( S_i(H, \hat{F}) = S_i = I \neq (H, \hat{F}) \cap X_i(H) \). By construction, \( S_1 \) and \( S_0 \) are disjoint, and \( S_i \subset X_{1-i}(\hat{F}) \) as \( \hat{F}(X) = \neg H(X) \) for all \( X \in I \neq (H, \hat{F}) \).

We can build \( X_1(\hat{F}) \) using the sets \( X_1(H) \) and \( S_i \) in three steps:
1. Initialize \( X_1(\hat{F}) = X_1(H) \).
2. Remove all elements in set \( S_1 \) from \( X_1(\hat{F}) \).
3. Add all elements of set \( S_0 \), i.e., \( X_1(\hat{F}) = (X_1(H) \setminus S_1) \cup S_0 \).