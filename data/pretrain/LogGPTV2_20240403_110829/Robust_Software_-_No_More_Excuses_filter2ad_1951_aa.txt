# Robust Software - No More Excuses

**Authors:**
- John DeVale, Intel Corporation, Intel Labs
- Philip Koopman, Carnegie Mellon University, ECE Department

## Abstract
Software developers often cite two primary reasons for not making software systems robust: performance and practicality. This paper demonstrates the effectiveness of general techniques to improve robustness that are both practical and high-performing. We present data from three systems where robustness was improved by a factor of 5 or more, with a measured performance penalty of under 5% in nearly every case, and usually under 2%.

We also identify a third reason for the lack of robustness: developer awareness. A case study involving three professional development groups evaluated their ability to estimate the robustness of their software. Two groups could estimate robustness to some extent, while one group showed more divergent results. Although we can overcome the technical challenges, it appears that even experienced developers can benefit from tools to locate robustness failures and training in robustness issues.

## 1. Introduction
As society becomes increasingly dependent on complex electronic systems, the ability of these systems to tolerate defects, errors, and exceptions is critical. Every aspect of life, from banking to traffic control, weapons systems to grocery shopping, now relies on the correct functionality of computing systems.

This is not a new problem. Military, aerospace, medical, and financial systems have always been built to be as fault-tolerant as possible. However, they have not always achieved the desired level of robustness [21] [27] [28]. Unfortunately, many system developers still pay insufficient attention to building robust systems. Operating systems and commercial distributed computing frameworks, such as CORBA, have shown poor robustness [24][12][31]. Even complex military distributed simulation frameworks have a significant rate of robustness problems [9].

Recent research efforts have measured various aspects of software fault tolerance and robustness [22][6][16][4]. While these tools provide useful insights, they are not widely used. Some groups use them to improve their systems, but many do not. We found this puzzling and sought to understand why.

Through interactions with several development groups during the Ballista Project, we gained insight into the reluctance to fix robustness issues. The primary concerns cited were performance and practicality. Any approach to address robustness must be easy to implement and must not significantly impact run-time performance, especially since most systems use commodity hardware optimized for speed, cost, and quality rather than fault tolerance.

To address these concerns, we demonstrate the effectiveness of general techniques to improve robustness that are both practical and high-performing. We present data from three systems where all detectable robustness failures were removed, with a performance penalty of under 5% in nearly every case, and usually under 2%.

Additionally, we explore the issue of developer awareness, first studied by Maxion [30], who concluded that exposure to simple robustness concepts can lead to more robust code. We conducted a case study with three professional development teams to determine their ability to predict the exception handling characteristics of their code. Accurate predictions suggest that, given the right tools and time, they could build robust systems. Inaccurate predictions indicate a need for better tools and training.

## 2. Previous Work
The literature on exceptions and exception handling is extensive, covering how to describe, perform, and optimize exception handling.

### 2.1 Describing Exception Handling
Exception handling code is challenging to represent in design and documentation because it falls outside normal program flow. Early work explored multiple ways to handle exceptional conditions [17] [13]. Today, the termination model and resumption model [11] dominate. These models manifest as error return codes and signals in current systems.

The termination model, which uses error return codes, is generally considered superior to the resumption model, which uses signals. Signals provide only large-grain control, typically at the task level, leading to process termination (e.g., SIGSEGV). This makes it difficult to diagnose and recover from problems, especially in real-time systems.

### 2.2 Performing Exception Handling
Exception handling mechanisms can complicate code generation and understanding. To ease this burden, various approaches have been developed, including code and macro libraries [26] [19] [15] [3] and more aggressive frameworks [14] [33] or language constructs [29].

Our focus is on identifying exceptional conditions before an exception is generated, rather than developing easier-to-use exception handling mechanisms. Xept [36] is a related tool that encapsulates error checking in wrappers, reducing flow-of-control disruption and improving modularity. Xept has influenced our research, which uses the idea of avoiding exception generation to harden software interfaces against robustness failures.

### 2.3 High Performance Exception Handling
In today's high-performance culture, fast exception handling is crucial. Once exceptions are generated, recovery can be difficult. Previous work focuses on generating, propagating, and handling exceptions quickly. Our work aims to include enhanced error detection to detect incipient exceptional conditions before they generate exceptions, without sacrificing performance.

Exception delivery costs can be substantial, especially in layered operating systems. Hardware/software solutions [35] and multithreading [38] have been proposed to reduce these costs. Our approach performs checks in the main thread, leveraging enhanced multiple branch prediction hardware [32] and block caches [2] to execute checks in parallel with minimal performance cost.

## 3. Methodology
Allowing exceptions to occur and cleaning up afterward is risky due to the uncertain viability of post-exception cleanup. POSIX does not guarantee process state after signal delivery, and some processors do not support precise exceptions. Therefore, our approach is to detect all possible exceptional conditions before any calculations or actions are taken, through rigorous input data validation.

Preemptive detection allows the process to respond gracefully to exceptional conditions before altering the process state. While providing mechanisms to handle exceptional conditions within applications is beyond our scope, we note that a simple retry can often be effective. The main goal is to handle exceptions without incurring the overhead of a process restart.

A generically applicable method for hardening a software interface is to harden each element of a function's incoming parameters. This involves creating wrappers on a per-parameter basis. Linking hardening code to data types enhances modularity and reusability. Upon entering a hardened function, a wrapper function is invoked for each incoming parameter value (see Figure 1).

For memory-related robustness issues, we modified `malloc()` to provide function hooks that can read the data needed to validate dynamically allocated memory at the user level. This technique can store and retrieve other context-dependent information about the memory block, enabling better detection of memory-related exceptional conditions.

```c
ReturnType function foo(dataTypeA a) {
    if (!checkDataTypeA(a)) {
        return ErrorCondition;
    }
    // Perform normal calculations
    // Return result
}
```

**Figure 1. Pseudocode illustrating entry checks for exceptional conditions.**

---

This revised version of the text is more coherent, structured, and professionally presented. It clearly outlines the problem, methodology, and findings, making it easier for readers to follow and understand the research.