(α1,α2, . . .αk) and access to oracles O1,O2, . . . ,Ol. Let E denote a
policy-based encryption scheme for multiple recipients with policy
secrecy.
Given that we want to protect both message and policy secrecy
we deﬁne the notions of message indistinguishability and policy in-
distinguishability against adaptive chosen ciphertext attacks similar
to the ones deﬁned in [30].
Deﬁnition 5.1. Message Indistinguishability
E has message indistinguishability against an adaptive chosen
ciphertext attack if the guessing advantage, of any PPT adversary,
A = (A1,A2), as deﬁned below is negligible.
Phase 2 A2 is provided with a decryption oracle access for E and
is allowed to do everything A1 is allowed in Phase 1 with the
constraint that either Restriction 2a or 2b must be satisﬁed
and that it cannot query the decryption oracle on C∗.
Output A2 outputs his guess b0 ∈ {0,1}. A wins if b0 = b.
That is, an adversary cannot distinguish between encryptions of
a given message under two policies. Restriction 2a or 2b is needed
because otherwise the adversary can trivially win the game by pick-
ing two policies such that he (i.e., one of the corrupted users) satis-
ﬁes one of them and not the other.
We now deﬁne a security notion called pairwise indistinguish-
ability for pairs (m0, pol0), (m1, pol1) which is motivated by the
following scenario. Let us say an adversary knows that either mes-
sage “Buy” is encrypted under policy “Aggressive” or message
“Sell” is encrypted under policy “Moderate” (where “Aggressive”
and “Moderate” are known investor proﬁles) but doesn’t know which
action is being recommended by a paid investment service.
Deﬁnition 5.3. Pairwise Indistinguishability
E has pairwise indistinguishability against an adaptive chosen
ciphertext attack if the guessing advantage, of any PPT adversary,
A = (A1,A2), as deﬁned below is negligible.
E,A
(k) =
AdvE−pw−ind−cca2
where GE−pw−ind−cca2
Setup The environment generates a key-pair (sk, pk) and gives pk
(k) is the game described below:
(k) = b
E,A
(cid:12)(cid:12)(cid:12)Pr
h
GE−pw−ind−cca2
E,A
i− 1/2
(cid:12)(cid:12)(cid:12)
to A.
Phase 1 A1 is provided with a decryption oracle for E with above
generated key-pair. It is also allowed to arbitrarily and adap-
tively add/corrupt users. That is it can get access to arbitrary
sets of attributes represented by corrupted users ui.
Challenge A outputs two messages, m0, m1, of equal length and
two policies p0, p1, of equal length along with state informa-
tion St under the following restriction:
Restriction 3: None of the corrupted users satisfy either pol-
icy p0 or p1 throughout the game.
The environment then picks a random bit, b $←− {0,1}, and en-
crypts message mb under policy pb and returns the challenge
ciphertext (C∗) along with state information St to A2.
Phase 2 A2 is provided with a decryption oracle for E and is
allowed to do everything A1 is allowed in Phase 1 with the
constraints that Restriction 3 must be satisﬁed and that it
cannot query the decryption oracle on C∗.
Output A2 outputs his guess b0 ∈ {0,1}. A wins if b0 = b.
That is, an adversary cannot distinguish between encryptions of
two message and policy pairs. Restriction 3 is needed because oth-
erwise the adversary can trivially win the game by decrypting the
challenge ciphertext as he has access to keying material of a user
who satisﬁes the policy. By deﬁnition, pairwise indistinguishabi-
lity implies message indistinguishability (when both policies are
the same) and policy indistinguishability with restriction 2b (when
both messages are the same) and hence is a stronger notion of se-
curity. Furthermore, we note that using standard hybrid argument
one can show that message indistinguishability together with policy
indistinguishability (with restriction 2b) imply pairwise indisting-
uishability. In all the above deﬁnitions the adversary is allowed to
corrupt multiple users and obtain their keying material thus user-
collusion attacks are taken into account.
5.2 Encryption Scheme and System
Our encryption scheme is based on KEM-DEM hybrid encryp-
tion paradigm [15] and uses Key Encapsulation Mechanism (KEM)
and Data Encapsulation Mechanism (DEM) as building blocks. For
ease of exposition we deﬁne and use a construction Policy and Key
Encapsulation Mechanism (PKEM) to build our scheme dubbed
PKEM-DEM. In our PKEM-DEM encryption scheme a ﬁle/message,
m, is encapsulated using a DEM where the key used by the DEM
and the policy associated with the message, pol, are encapsulated
using PKEM as deﬁned below.
PKEM-DEM.KeyGen(1k) :
(sk, pk) $←− PKEM.KeyGen(1k)
Return (sk, pk)
PKEM-DEM.Encrypt(m, pol, pk) :
(K2,C1) $←− PKEM.Encrypt(pol, pk)
C2 ← DEM.Encrypt(m,K2)
C ← C1kC2
Return C
PKEM-DEM.Decrypt-I(sk, f ,C1,u) :
m0 ← PKEM.Decrypt(sk,C1)
if m0 =⊥ Return ⊥
else parse m0 as (pol,K2)
if f (u, pol) = 1 Return K2
else Return ⊥
PKEM-DEM.Decrypt-II(K2,C2) :
if K2 =⊥ Return ⊥
m ← DEM.Decrypt(K2,C2)
Return m
Where PKEM is constructed as follows:
PKEM.KeyGen(1k) :
(sk, pk) $←− KEM.KeyGen(1k)
Return (sk, pk)
PKEM.Encrypt(pol, pk) :
(K1,C1) $←− KEM.Encrypt(1k, pk)
(K2,C2) $←− SPKEM.Encrypt(pol,K1)
C ← C1kC2
Return (K2,C)
PKEM.Decrypt(sk,C) :
parse C as C1kC2
K1 ← KEM.Decrypt(sk,C1)
if K1 6=⊥
m0 ← SPKEM.Decrypt(K1,C2)
if m0 =⊥ return ⊥
else Return m0 = (pol,K2)
And where SPKEM is constructed as follows:
SPKEM.Encrypt(pol,K) :
K0 $←− DEM.KeyGen(1k)
m0 ← polkK0
C ← DEM.Encrypt(m0,K)
Return (K0,C)
SPKEM.Decrypt(K,C) :
m0 ← DEM.Decrypt(K,C)
if m0 =⊥ or parsing m0
as polkK0 fails return ⊥
else Return (pol,K0)
Here, u represents a user and his associated attributes along with
contextual attributes and f represents the policy evaluation function
and is a deterministic polynomial-time function that takes as input
u, and a policy, pol, and returns a 1 if the user along with context
satisﬁes the policy or a 0 otherwise. A PKEM-DEM scheme can be
constructed using any KEM and DEM where the two schemes are
independent3. Figure 3 shows encryption in PKEM-DEM scheme
instantiated using RSA-KEM and DEM1 deﬁned in [15]
We use our PKEM-DEM encryption scheme to develop the PBES
policy based encryption system whose architecture is illustrated in
Figure 2 and described in Section 4.2. The data owner in our system
speciﬁes a policy pol and uses the PKEM-DEM scheme to securely
associate the policy with the data m and generate an encrypted ob-
ject E(o) that hides both the policy and the data. In order to do so
it chooses a KDC that it trusts to enforce the policy and release the
DEM object encryption key to recipient(s) that satisfy the policy. It
then obtains the public key of the KDC, PK, via a trusted source
3KEM-DEM schemes built using secure KEM and secure DEM
that are related may not be secure as shown in [26]
(e.g., a Certiﬁcate Authority − CA) and encrypts the object using
the PKEM-DEM scheme.
Once a recipient obtains the encrypted object it must contact the
KDC represented by the public key PK in the encrypted object in
order to obtain the DEM object decryption key. To do so it ini-
tiates a protected transaction (e.g., over TLS) with the KDC and
submits the PKEM part of the encrypted object (i.e., it excludes
the encrypted object in the DEM part). The KDC then contacts
the Attribute Database that manages user attributes and privileges
and enviromental attributes (i.e., context). The KDC uses these
attributes of the user and the environment and the PKEM part of
the object as inputs to PKEM-DEM.Decrypt-I to obtain the DEM
keys. The KDC releases the object decryption key, K, to the re-
cipient and the recipient uses this key to decrypt the object using
PKEM-DEM.Decrypt-II.
5.3 Security Analysis
Since pairwise indistinguishability (in Def. 5.3) implies mes-
sage indistinguishability (in Def. 5.1) and policy indistinguishabi-
lity (in Def. 5.2) with restriction 2b, we prove that PKEM-DEM
is pairwise indistinguishable in Theorem 5.1 and that it is policy
indistinguishable with restriction 2a in Theorem 5.2 to show that
PKEM-DEM system is secure against adaptive chosen ciphertext
attacks.
Theorem 5.1. If DEM is secure against one-time chosen cipher-
text attacks and PKEM is secure against chosen ciphertext attacks
against both key and policy indistinguishability then PKEM-DEM
is secure against chosen ciphertext attacks on pairwise indisting-
uishability as given in Deﬁnition 5.3.
In particular we have
Advpkem−dem−pw−ind−cca2
PKEM-DEM
5· Advkem−ind−cca2
KEM
(k) ≤
(k) + 3· Advdem−ind−otcca
DEM
(1)
(k)
Theorem 5.2.
If PKEM is secure against chosen ciphertext at-
tacks against policy-indistinguishability then PKEM-DEM is se-
cure against chosen ciphertext attacks on policy indistinguishabi-
lity as given in Deﬁnition 5.2 with restriction 2a.
In particular we have
Advpkem−dem−pol−ind−2a−cca2
(k) ≤
PKEM-DEM
Advkem−ind−cca2
KEM
(k) + Advdem−ind−otcca
DEM
(2)
(k)
Due to space constraints, deﬁnition of PKEM, associated se-
curity notions along with their proofs sketches are given in Ap-
pendix A. Proof for Theorem 5.1 and proof sketch for Theorem 5.2
are given in Appendix B. Full proofs will be given in an extended
version of the paper.
6. PBES APPLICATION INTEGRATION
Table 1: Example of Policy Elements
Policy Element
Identity
Group or Role
Attribute
Context
Example
Email address, Distinguished Name
Transmission System Operator, Reliability Engi-
neer
Certiﬁed Dispatcher
Location of voltage disturbance, Status of a relay,
Time of the day
In this section we illustrate how PBES is used to enable pol-
icy based data sharing in the power grid using an example usage
scenario. First, we note that policies in our system are arbitrary
strings that can be parsed and enforced by the KDC. Therefore,
they are very ﬂexible in nature. Policy elements of interest for
object encryption and in particular for data sharing in power grid
include: 1) identities where recipients must demonstrate ownership
of identiﬁers, 2) groups or roles where recipients must demonstrate
membership to a group or role, 3) attributes where recipients must
demonstrate ownership of attributes that satisfy an attribute expres-
sion, and 4) context where the KDC must verify environmental
properties. Policies may combine any of these elements and some
example elements in the power grid are shown in Table 1.
As an example, consider a Utility A under the jurisdiction of an
ISO B. While Utility A is not willing to share its data with all other
utilities in the area under normal circumstances, it might ﬁnd that it
is in its interest to share that data with some of them when they are
experiencing a combination of events that might potentially lead to
a voltage collapse especially if no coordinated mitigation actions
are taken. Possible combination of events for voltage collapse are
identiﬁed by system planning static load ﬂow analysis undertaken
by NERC or the ISO B. Speciﬁcally, the policy of utility A for
sharing data with any Utility X is as follows:
Grant Access if
(Reliability Engineer in Utility X) AND (Utility X in ISO B) AND
(Overloaded Tie Line between Utility X and Utility A) AND ((Below
Critical Reactive Power Reserves in Utility X) OR (Reactive Limiters ac-
tive in Utility X))
Utility A associates this policy with the data and encrypts it us-
ing the PKEM-DEM scheme entrusting access control enforcement
to (local) ISO B, i.e., ISO acts as the KDC. It then posts this data
on its public data repository (which may use coarse-grained ac-
cess control, for example, to limit write operations). If and when
the Transmission System Operator in utility C in the neighboring
BAA notices an overload on the tie line connecting utility C with
A and the Generation System Operator notices low reactive power
reserves or reactive limiters turning on they initiate mitigation pro-
cedures along with the Reliability Engineer. Reliability Engineer
obtains the relevant encrypted data from utility A’s repository based
on the meta data associated with encrypted objects. Example of
useful meta data are the start time and end time of data samples
contained in the encrypted object and coarse grained PMU location
information. Reliability Engineer then submits the encrypted data
key to the ISO for decryption. ISO upon verifying that the asso-
ciated policy is satisﬁed returns the data decryption key. Note that
ISO having a wider view of the grid than Utility A is able to ver-
ify the occurrence of speciﬁed conditions in Utility C. Reliability
Engineer may repeat this action with all utilities with which their
organization shares a tie line that is overloaded. He may or may not
be successful in obtaining data based on the current policies of in-
dividual utilities. Reliability Engineer then feeds the data obtained
into his contingency planning tool and coordinates the mitigation
plan with data sharing utilities based on the results.
Utility A might also have additional time constraints in its pol-
icy limiting the data shared to a time window starting 30 minutes
before the event (i.e., tie line overload) and ending 30 minutes af-
ter the conditions are mitigated. We omitted this detail in the policy
example above for brevity. Furthermore, Utility A might be sharing
the data from its sensors with different entities under different con-
ditions. So in practice the policy associated with the data will be
a complex policy consisting of many sub polices similar to the one