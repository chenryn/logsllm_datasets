A
B
Figure 2. Augmented chain with 
3=a
, 
.2=p
2.2.  Erasure codes
When a stream of packets are sent from the source to
the destination via the Internet, fraction of the packets are
lost during transit. A standard solution to this problem is
to  request  retransmission  of  data  that  is  not  received.  In
some applications, this solution is not practical. For real-
time  data,  this  can  lead  to  unacceptable  delays.  In
multicast  transmission,  different  receivers  lose  different
sets  of  packets,  thus  retransmissions  can  overburden  the
resources of the sender and the network.
(FEC) 
techniques.  Using 
An  alternative  solution  is  to  use  forward  error
correction 
this  method,
robustness  to  loss  can  be  provided  without  imposing  an
unreasonable  amount  of  space  overhead.  Among  FEC
codes,  erasure  codes  are  of  particular  interest  to  our
application. In this subsection, we briefly review the basic
characteristics of two well-known erasure codes—Rabin’s
Information Dispersal Algorithm (IDA) [12] and Tornado
codes [8].
IDA  was  originally  developed  as  an  algorithm  for
providing  safe  and  reliable  storage  or  transmission  of
information in distributed systems. The basic idea of IDA
is to process the source, say a file F, by introducing some
amount  of  redundancy  and  splitting  the  result  into  n
pieces,  which  are 
transmitted.  Reconstruction
(decoding)  of  F  is  possible  with  any  combination  of  m
mn −   pieces  are 
pieces 
lost  during
nm ≤ . Each distributed piece is of
transmission), where 
, which clearly shows that the scheme is space
size 
optimal.  The  space  overhead  for  transmission  can  be
controlled by adjusting the parameters  n  and  m .
(assuming 
mF /
then 
in 
Unlike  IDA,  which  has  a  quadratic  decoding  time,
Tornado codes can encode and decode data in linear time.
The number of  segments  needed  for  decoding  is  slightly
larger than the number of pre-encoded segments, and thus
they  are  sub-optimal 
terms  of  space  overhead.
Specifically,  for  a  set  of  n  segments,  encoding  with
)},
Tornado  codes  increase  the  number  to 
where  p   and  ε  are  positive  fractions.  If  the  receiver
the  encoded
acquires  more 
than 
segments, 
the  original  data  segments  can  be
then 
reconstructed with high probability in time proportional to
n
  fraction  of 
/1ln( ε
)
p−1
− p
ε+
1{
1(
n
.
3. Our scheme for message authentication
3.1. Rationale for our approach
there  are 
In  EMSS, 
three  factors 
that  affect
verification  probability—number  of  signature  packets,
number  of  hashes  contained  in  the  signature  packet,  and
number  of  hashes  contained  in  the  data  packet.  The
number of hashes in the signature  and  data  packets  (i.e.,
second  and  third  factors)  is  always  greater  than  one,
improving  the  robustness  of  the  scheme  to  packet  loss
compared  to  the  single  hash-per-packet  configuration  of
the  stream-signing 
tradeoff  of
increased  space  overhead  for  packet  loss  robustness  is
unavoidable, but can be done in a more efficient way by
using  erasure  codes.  This  is  best  illustrated  using  the
following simple example.
technique  [5].  This 
,
The  sender  transmits  the  hash  of  a  packet  appended
to  k  other  packets  for  increased  resistance  to  loss.  We
assume that a block consists of n packets. If independent
packet  loss  is  assumed,  then  the  probability  that  at  least
one  out  of  the  k  packets  will  reach  the  destination  is
kq−
1
  where  q  is  the  packet  loss  probability.  The
communication overhead would be kh, where h is the size
of the hash. Using the same overhead, one can encode the
hash using IDA and append the encoded n segments to the
n  packets  of  the  block  (i.e.,  each  packet  in  the  block
would  contain  one  of  the  encoded  segments).  The
minimum  number  of  encoded  segments  needed  for
, where   x
reconstruction of the hash is only 
denotes  the  smallest  integer  not  less  than  x.  The
probability that the hash can be reconstructed successfully
at the receiver is given by
−∑
n
i
                         (1)
knm
−
1(
)
qq
−
in
=
1
−
1
/
m
.
i
=
i
0
Again, independent packet loss was assumed.
Instead of using IDA, the sender could  also  use  one
of  the  probabilistic  codes  such  as  Tornado  codes  for  the
same  purpose.  In  this  case,  the  minimum  number  of
segments needed for decoding is
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
=
nm
=
−
1(
n
k
1
p
+
)
εk
−
(
)1
ε
+
1
                          (2)
,
where  p   and  ε  are  the  performance  parameters  of  the
Tornado  code  (see  Subsection  2.2).  The  probability  of
successful reconstruction of the hash is given by (1) using
the  value  of  m  specified  by  (2).  It  is  obvious  that  the
probability given by (1) is much higher than 
 and
the probability for IDA is higher than that for the Tornado
code.
kq−
1
,
The above example suggests that using some type of
an erasure code to encode the hash values would be more
efficient  than  simply  appending  duplicate  hash  values  to
the  packets.  As  an  extended  version  of  EMSS,  Perrig  et
al. [11] suggested using universal hash functions or IDA
to split the hash value of each packet into multiple pieces
before appending them onto other packets. This certainly
produces  a  more  loss-resistant  scheme  with  the  same
amount  of  communication  overhead.  However, 
it
introduces  complexities—the  time-consuming  process  of
encoding and decoding must be performed for each hash.
This  can  be  a  bottleneck,  especially  when  one  of  the
erasure codes from the Reed-Solomon family,  which  has
quadratic  decoding  times,  are  employed.  We  suggest  a
simple  method  of  avoiding  this  problem  at  the  cost  of
sender  delay.  Instead  of  encoding  individual  hashes,  we
suggest  concatenating  all  the  hashes  within  the  block  to
form  a  single  piece  before  encoding.  This  strategy
requires only one encoding/decoding per block. The space
overhead  can  be  minimized  by  employing  space  optimal
erasure codes such as IDA.
The  main  advantage  of  EMSS  is  that  there  is  no
sender  delay  incurred  by  the  authentication  process—a
given packet can be transmitted immediately after its hash
value is computed without the buffering of other packets.
This  can  be  an  advantage  in  situations  where  data  is
generated  in  real  time,  and  immediate  dissemination  is
crucial (e.g., stock-quote broadcasts). However,  for  most
multicast applications, the sender has a priori knowledge
of  at  least  a  portion  of  the  data  (e.g.,  pre-recorded  news
footage 
fact,  most
authentication schemes incur some degree of sender delay
to  gain  other  advantages  [GoM01,  MiS01,  WoL98].
Therefore, the sender delay caused by our technique is not
a restrictive requirement in most multicast applications.
software  updates). 
and 
In 
If a certain amount of sender delay is allowed, then a
more significant problem can be addressed. It is obvious
that the delivery of the signature packets is crucial for any
authentication  scheme.  In  previous  work  [GoM01,
MiS01,  PeC00],  the  performance  results  (both  analytical
and  empirical)  were  based  on  the  assumption  that  the
signature  packet 
is  received.  The  authors  suggest
accomplishing  this  task  by  empowering  the  receivers  to
request  retransmissions  of  the  lost  signature  packets  or
sending the signature packet multiple times. However, the
retransmission  of  signature  packets  can  put  considerable
strain  on  the  resources  of  the  sender  and  the  network,
especially in a large multicast network consisting of tens
of  thousands  of  users.  In  [18],  Yajnik  et  al.  observed
packet  loss  characteristics  of  actual  multicast  sessions,
and  showed  that  considerable  amounts  of  the  packets
would  need  to  be  retransmitted,  if  reliable  multicast
services  are  to  be  provided  through  retransmissions.  In
one particular data set, 62.6% of  the  packets  sent  by  the
source were lost by at least one receiver. This implies that
retransmission  would  have  been  necessary  for  62.6%  of
the packets.
Sending the signature packet several times can be an
alternate solution, but this also has drawbacks. Signature
packets  are  generally  large  (e.g.,  128  bytes,  if  1024-bit
RSA is used) and sending these packets several times can
increase the communication overhead noticeably. There is
another drawback to sending the signature packet multiple
times.  Because  actual  losses  in  the  Internet  are  highly
correlated  and  bursty,  each  copy  of  the  signature  packet
would  have  to  be  interspersed  uniformly  among  the
packets to ensure maximum effectiveness. If the copies of
the signature packets are distributed in the current block,
then  this  would  cause  sender  delays  in  schemes  that
utilize  hash  chaining  techniques  with  edges  directed
rightward  (i.e.,  hash  of  a  packet  is  appended  to  the
packets  following  it)—schemes  like  EMSS.  The  sender
delay  is  caused  by  the  fact  that  the  data  packets  in  the
block cannot be transmitted before the signature packet is
created, and replicas of it are interspersed among the data
packets.  In  contrast,  distributing  copies  of  the  signature
packets in the current block would not add any additional
sender delay in schemes that utilize leftward edges (these
schemes  already  incur  some  amount  of  sender  delay)—
techniques like the piggybacking scheme [10].
The obvious alternative is to distribute the  copies  in
the  next  block  to  avoid  the  sender  delay.  However  this
can cause increased delay on the receiver side—a receiver
might  have  to  buffer  a  maximum  of  2n  data  packets
before verifying a given packet, where n is the number of
data packets per block. This case is illustrated as a simple
example  in  Figure  3.  In  the  figure,  circles  and  squares
represent data packets and signature packets, respectively.
The  first  two  signature  packets  in  the  (i+1)-th  block  are
assumed  to  be  lost  and  are  represented  as  darkened
,1,1+iD
squares.  The  receiver  needs  to  buffer 
  before  verifying  the  data  packets  of  the  i-th
and 
2,1+iD
iS (signature  packet  of
block  (i.e., 
the i-th block).
2,iD )  using 
1,iD   and 
,1,iD
,2,iD
Considering  these  problems,  the  obvious  alternative
is to apply FEC techniques to the signatures packets. We
can  easily  make  the  signature  packets  robust  against
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
packet  loss  by  using  erasure  codes  and  appending  each
encoded  piece  to  the  data  packets.  If  IDA  is  used,  the
same  set  of  vectors  used  for  encoding/decoding  the
concatenated  hash  values  can  be  used,  and  hence  no
additional (computational) encoding/decoding overhead is
added. In  addition,  there  is  no  additional  sender/receiver
delay involved with encoding/decoding signature packets.
The  details  of  our  authentication  scheme  are  given  in
Section 3.2.
block i
block i+1
...
...
Si-1
D i,1
Si-1
D i,2
Si-1 Si
D i+1,1
Si
D i+1,2
Si
Figure 3. Increase in receiver delay caused by multiple
signature packet transmissions.
For  our  authentication  scheme,  we  employed  IDA
instead  of  probabilistic  codes  such  as  Tornado  codes.
Tornado codes can encode/decode data very rapidly (i.e.,
linear time), but do so with a high probability only when
the  number  of  segments  to  encode  is  large.  For  this
reason, Tornado codes are appropriate when large number
(hundreds  to  thousands)  of  segments  are  being  encoded
[16].  We  chose  to  use  IDA,  because  the  encoding
involves a fairly small number of segments, and IDA has
the added advantage of being space optimal. It should be
noted that our authentication scheme is independent of the
type  of  erasure  code,  and  other  erasure  codes  (e.g.,
Tornado  codes)  that  have  other  attractive  properties  can
be employed in the scheme.
3.2. Signature amortization using IDA
The  biggest  challenge  in  using  digital  signatures  for
authentication  is  the  computationally  intensive  nature  of
the  asymmetric-key-based  signatures.  For  this  reason,
previous authentication schemes approached this problem
in  two  directions—designing  faster  signature  techniques
and  amortizing  the  signature  operation  over  multiple
packets.
In general, making the signature scheme faster comes
at the cost of increased space overhead. In [13], Rohatgi
proposes  using  a  combination  of  k-time  signatures  and
certificates  for  the  k-time  public  keys  (created  with  a
regular signature scheme) to authenticate packets. Despite
its improvement over the one-time signature scheme, this
method  still  requires  a  space  overhead  on  the  order  of
several hundred bytes per packet.
is  reducing 
the  size  of 
Our  main  focus 
the
authentication overhead, and therefore we took the second
approach,  which  offers  better  space  efficiency.  We
propose a scheme that employs IDA to amortize a single
digital  signature  over  a  block  of  packets.  Our  scheme,
appropriately  named  Signature  Amortization  using  IDA
K=
to  provide  space-efficient
(SAIDA),  was  designed 
authentication even in high packet-loss environments. The
following  steps  describe  the  authentication  procedure  in
detail:
1. Let || denote concatenation. A stream of packets is first
divided into groups (or blocks). We denote a stream as
1 GG=*
is  a
(i.e.,
concatenated 
L+
c
||1
 for
PG
some constant  c . The same operations are performed
on  every  group,  so  we  will  only  focus  on  the  first
group.
,  where  each  group 
string 
||
iG  
packets 
), and each packet 
}1,0{∈
K||
P
in
of 
n  
iP
)1(
i
=
||
−
2
n
i
2. A  packet  hash 
,)
iPH i
  for  each  packet  is
computed  using  a  hash  function  H   such  as  MD5  or
SHA-1.
,1
n
(
,
1
(
||
0
≤
=
L
||)
to 
 or 
( 1
PH
3. The  packet  hashes  are  concatenated 
 of size  N  (i.e., 
F
nPH
of  N  characters). Let 
1F . In practice, 
≤
byte,  hence 
257Z
form
1F  consists
)
ib  represent the i-th character in
ib may be  considered  as  an  eight-bit
,  and  all  computations  are
ib
1F  is stored in
GF
done in 
a temporary buffer while another copy is divided into
blocks of length m as follows:
b
2
. One copy of 
255
)2( 8
(,
b
To simplify the following discussion, let
≤≤
/
mNi
≤≤
,
n
(
b
−
)1(
i
a
4. Choose n vectors 
.
 such that
every  subset  of  m  different  vectors  are  linearly
independent, as specified in [12].
=
(
n
1F  is processed and divided into n pieces as follows:
5. Using  the  set  of  vectors 
1,)
a
b
im
K
,
≤≤
+
1
m
=
+−
1
mN
a
im
(
b
1
1,)
1),
a
1
i
b
m
b
m
(),
K
K
K
K
K
K
,
(
,
,
=
=
F
).
),
S
a
b
a
+
1
im
i
i
1
i
m
,
,
,
,
,
,
,
,
,
N
1
i
i
i
1
iF
where 
⋅
(
=
⋅
SaSa
,
1
i
⋅
⋅
=
Sa