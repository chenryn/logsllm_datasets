title:Fuzzy extractors for continuous distributions
author:Ileana Buhan and
Jeroen Doumen and
Pieter H. Hartel and
Raymond N. J. Veldhuis
Fuzzy extractors for continuous distributions
Abstract
We show that there is a direct relation between the maximum length of
the keys extracted from biometric data and the error rates of the biometric
system. The length of the bio-key depends on the amount of distinguishing
information that can be extracted from the source data. This information can
be used a-priori to evaluate the potential of the biometric data in the context
of a speciﬁc cryptographic application. We model the biometric data more
naturally as a continuous distribution and we give a new deﬁnition for fuzzy
extractors that works better for this type of data.
1 Introduction
Databases with biometric information are a serious threat to the privacy of
users. The ability to track users across multiple databases is an example
of this threat. The usual solution of using different passwords in different
systems does not apply for obvious reasons - a person only has a limited
number of biometric identiﬁcation available: ten ﬁngers, two eyes, etc. If
one of these is compromised nothing can be done to undo the harm. This
means that the template of a user, which stores his biometric information,
needs protection.
Template protection can be used to store securely a biometric identity of a
user. Tracking is no longer possible if different template protection schemes
are used in different databases. A protected template will reveal almost noth-
ing about the biometric data.
If by some means a database with secured
biometric data is compromised, the attacker cannot learn anything about the
biometric data. Moreover if such an intrusion is detected the biometric is not
lost, since at any time the protection scheme can be reapplied on the original
data.
As one needs measurements to obtain biometric data, another inherent
problem with biometrics is noise. One cannot use biometric data directly as
a password (or key), since classical cryptography cannot cope with the noisi-
ness of the biometric data. Uniform and reproducible randomness is the main
ingredient for a good password. Unfortunately, biometric measurements do
1
not ﬁt this directly. Template protection schemes can be applied as a trans-
formation function on biometric data to make the password reproducible. By
this transformation, biometrics can be used as passwords.
In the literature often the source of biometric data is considered to be
either continuous or discrete. Therefore template protection schemes can
be divided in two classes. Representatives of the ﬁrst class are continuous
source shielding functions [5], the reliable component scheme [7] and the
multi-bit scheme [3]. The fuzzy vault [8] and the secure sketch [4] belong to
the second class.
It is difﬁcult to compare the performance of these schemes because there
is no uniﬁed view on the evaluation strategy. All authors estimate the error
rate of their system in terms of FAR and FRR , but when it comes to eval-
uating the security of the resulting binary sequence different authors have
different opinions. Monrose et al. [6] compute the guessing entropy while
Zhang et al. [9] try to estimate the number of effective bits in the result-
ing key and propose a weighting system for choosing the best combination.
Chang et al. [3] analyze the security of a sketch by investigating the remain-
ing entropy of the biometric data, given that the sketch is made public. The
same approach is taken by [2].
Contribution. Fuzzy extractors [4] where proposed as a general model
capable of describing any template protection scheme that assumes a dis-
crete source initial data. In this paper we extend the scope of the classical
fuzzy extractors to continuous source data. We propose CS-fuzzy extractors
as a unifying view on template protection schemes. This give us new in-
sights. We show that the length and the quality of the bio-key depends on the
amount of distinguishing information that can be extracted from the initial
data. This gives a bound on the number of uniformly distributed bits that can
be extracted from a given set of data. This information can be used a-priori
to evaluate the potential of the biometric data in the context of a speciﬁc
cryptographic application.
2 Preliminaries
Before we delve into the differences between discrete and continuous source
biometrics, we need to establish some background ﬁrst. We start by giving
our notations, as well as some basic deﬁnitions. Secondly, we introduce the
fuzzy extractor for a discrete source as given by [2, 4]. Thirdly, we brieﬂy dis-
cuss the chosen model of the continuous source and its implications. Lastly,
we remind the reader of the deﬁnitions of biometric error rates common in
the literature.
Notation and Deﬁnitions. We will use Ul to denote the set of uniformly
distributed binary sequences of length l. When referring to keys extracted
2
from biometric data we are interested in the probability that an adversary
can guess the value of the key on the ﬁrst try. The min-entropy or the
predictability of a random variable X denoted by H∞(X) is deﬁned as
the logarithm of the most probable element in the distribution: H∞(X) =
− log2(maxxP (X = x)). The min-entropy tells us the number of nearly
uniform bits that can be extracted from the variable X.
The Kolmogorov distance or statistical distance between two probability
distributions A and B is deﬁned as: SD(A, B) = supv|P r(A = v) −
P r(B = v)|.
For modelling the process of randomness extraction from fuzzy data
Dodis et al. [4] deﬁne the notion of a fuzzy extractor.
The purpose of a fuzzy extractor is to extract robustly a binary sequence
s from a noisy measurement w’ with the help of some public string Q. This
process is presented in ﬁgure 1. Enrollment is performed by a function Gen,
that on input of the noise free biometric w and the binary string s,will com-
pute a public string Q. The binary string s can be extracted from the biometric
data itself as in the reliable component scheme, presented in more detail in
section 3.5, or s can be generated independently as in [5]. The dotted lines
in ﬁgure 1 illustrate these alternatives.
Figure 1: A fuzzy extractor.
For a discrete source M endowed with a metric d, the formal deﬁnition
of a fuzzy extractor [2, 4] is:
Deﬁnition 1 (Fuzzy extractor) An (M, m, l, t, ) fuzzy extractor is a pair
of randomized procedures, (cid:104)Gen, Reg(cid:105), where:
Gen is a (necessarily randomized) generation function that on input w ∈ M
extracts a private string s∈ {0, 1}l and a public string Q, such that for
all random variables W over M such that H∞[W ] ≥ m and depen-
dent variables (cid:104)s, Q(cid:105) ← Gen[w], it holds that SD[(cid:104)s,Q(cid:105),(cid:104)Ul, Q(cid:105)] ≤ 
Reg is a regeneration function that given a word w(cid:48) ∈ M and a public string
Q outputs a string s ∈ {0, 1}l, such that for any words w, w(cid:48) ∈ M
satisfying d(w, w(cid:48)) ≤ t and any possible pair (cid:104)s,Q(cid:105) ← Gen[w] , it
holds that s = Reg[w(cid:48), Q]
3
GenRegwsQQw’sEnrollmentAuthenticationDuring authentication, function Reg takes as input a noisy measurement
w(cid:48) and the public string Q and it will output the binary string s if w and w(cid:48)
come from the same user.
Distribution modelling. The biometric identity of a user is described by
multiple features. We assume that the features are independent. For simplic-
ity, in this paper all examples and deﬁnitions are presented for one feature
only. The extension to higher dimensions is natural.
Let Sa (the subscript a meaning authentic) be the probability distribu-
tion that describes a user in the system. We denote with Sg the probability
distribution of the whole population; in this case the subscript means global.
We use the Gaussian distribution for both Sa and Sg, since it represents
a common model for real world raw data. The imposter distribution can then
be written as Sg = N(µg, σg). Any user distribution Sa is described by a
standard deviation σa and a mean µa drawn from µa ∈ N(µg, σg − σa).
To estimate w, which represents the biometric identity of a user, multiple
measurements are taken and a mean is estimated. The small perturbations be-
tween measurements hold important information. They represent an estimate
on how far from the mean other genuine samples will be. We can call this
information noise which can be represented as the standard deviation. This
is used to establish suitable probabilities of value acceptance and rejection
area.
A noise free biometric, in the case of a discrete distribution is denoted by
w. When a continuous distribution is assumed, the closest to the notion of w
is µa, the mean of the authentic distribution Sa. We will use µa when a noise
free biometric template is computed from continuous source initial data and
w when the initial data is discretely distributed.
For consistency, we use the same notation for a noisy measurement, w(cid:48)
both for discrete and continuous source data.
Error rates. The error rates of a biometric system are determined by the
accuracy with which the matching engine can determine the similarity be-
tween a measured sample w(cid:48) and the expected value µa of distribution Sa [1].
We can construct two possible hypotheses:
H0 the measured w(cid:48) is coming from the authentic user;
H1 the measured w(cid:48) is not coming from the authentic user;
The matching engine has to decide whether H0 or H1 is true. To express
the accuracy of a biometric system the terms false acceptance rate (FAR )
and false rejection rate (FRR ) are used. The false acceptance rate is a type I
error and represents the probability that H0 will be accepted when in fact H1
is true. The false rejection rate is a type II error and represents the probability
that the outcome of the matching engine is H1 but H0 is true. In the setting
of ﬁgure 2 we have a false acceptance every time another user, from the dis-
tribution Sg is generating a measurement which is in the acceptance region
4
Figure 2: Threshold (cid:104)T1, T2(cid:105) determines acceptance and rejection regions
(cid:82) T2
T1
T1
pdf(Sa)dx.
=1 −(cid:82) T2
described by the interval (cid:104)T1, T2(cid:105). We can then write FAR =
pdf(Sg)dx,
where pdf stands for probability density function. Every time user Sa pro-
duces a sample that is in the rejection area, he will be rejected, thus FRR
Dodis et al. [4] assume that the data source M is discrete for the deﬁni-
tion of fuzzy extractor. However, the class of template protection schemes
that uses continuous sources does not ﬁt this model. Instead of trying to ﬁt
this class by implicitly discretizing the continuous source, the fuzzy extractor
deﬁnition should be extended to model both classes. This is the subject of
the next section.
3 Fuzzy extractors for continuous distributions
We show in this section that in the fuzzy extractor (M, m, l, t, ) there is a
natural link between parameter m, the threshold t, the length of the resulting
binary sequence l and  the distance between the distribution of the key and
the uniform distribution. For the cs-fuzzy extractors we choose slightly dif-
ferent parameters which are more natural for biometric data that are suited
for continuous distributions.
3.1 From continuous to discrete sources
Deﬁnition 1 relies on a source M with min-entropy m. How can we con-
struct a source with min-entropy m out of a continuous distribution like Sg?
A common solution is to divide the measurement axis into intervals. To each
interval di a discrete string si will be associated.
In the setting of ﬁgure 3 the result of this division is the
discrete distribution Dg = (cid:104)di(cid:105), i = 1..n.
In ﬁgure 3, n is equal to 8.
The public string Q contains the representation of the quantization. The
Example.
5
SgaSFARFRRTT12MeasurementsProbabilityFigure 3: Discretization of a continuous distribution
(cid:82)
(cid:82)
di
probability of selecting an interval is computed as pi = P r[Dg = di] =
pdf(Sg|Q)dx where the integral is taken over the interval di. The con-
di
tinuous distribution Sg has been transformed into the discrete distribution
Dg = (cid:104)di(cid:105), i = 1, . . . , n where n=8. A user Sa can be described by only
one authentic interval. We denote with pauth the probability associated to
the authentic interval. We chose the authentic interval di for which the value
pauth =
pdf(Sa)dx is maximized since this describes best our user. In
ﬁgure 3, d7 best describes user Sa.
deﬁned as m = −log2pmax where pmax = maxi(P r[Dg = di]).
Now we are able to speak of the min-entropy of Dg denoted by m and
The effects of the discretization on the error rates, the FAR and the FRR
are shown in ﬁgure 4. If we associate to user Sa the discrete variable di the
FAR for this user will be equal to pauth, in ﬁgure 4 the crosshatched area.
The probability of a false rejection is determined by what is left from the
distribution of Sa after removing pauth, in ﬁgure 4 the FRR is the dashed
area.
3.2 Relating min-entropy m and FAR
The above construction using the biometric data creates a tight relation be-
tween the min-entropy m of distribution Dg and the error rates of the bio-
metric system. For the output sequence s to have a small chance of guessing
the correct value from the ﬁrst try we have to maximize the min-entropy by
lowering the values of all the probabilities pi. Unfortunately, by lowering pi
we increase the FRR .
Proposition 1 For the above deﬁned distribution Dg we have m ≤ −log2FAR
with equality when pauth = pmax.
6
45Sgad1d2d3d4d5d6d8d7SMeasurementsProbabilityFigure 4: Effects on the error rates of discretization of a continuous distribution
Proof: We take pmax = maxipi. Since pmax ≥ pauth, we know that:
m = −log2pmax ≤ −log2pauth = −log2FAR
Corrolary 1 FAR ≤ 2m with equality when pauth = pmax.
Fact: m is maximized when the probabilities associated with the discrete
distribution Dg are uniform.
3.3 Parameters t and FRR
According to deﬁnition 1 the Reg[w(cid:48), Q] procedure will output the same bi-
nary sequence s as Gen[w] whenever w and w(cid:48) are close. The idea behind
closeness is that w and w(cid:48) probably belong to the same user. In deﬁnition 1
this is written as d(w, w(cid:48)) < t, where d is some metric, for example the Eu-
clidian distance or the set difference metric. The value of t is a number. This
value as such, does not say anything about the acceptance or the rejection
probability of a user which, we feel, is more relevant. Also a suitable metric
is not always available in the case of continuous sources.
The probability of correctly identifying that two measurements belong to
the same user is the opposite of a type II error, thus the detection probability
Pd = 1 − FRR is a suitable generalization of the threshold t.
3.4 Relating min-entropy and l to 
We show in this section that given the number of bits l that we want to extract,
and the min-entropy, m = H∞(Dg) for a feature we can estimate , the
distance of the output sequence distribution to the uniform distribution.
We are interested in the statistical distance between the ideal distribution
in Ul, and the
of s where the generated key is distributed uniformly, i.e.
7
Sgad1d2d3d4d5d6d8d7SFARFRRProbabilityMeasurements(cid:175)(cid:175)P (s, Q) − 2−l
(cid:189)
(cid:175)(cid:175) .
 = sup
s
= max
s
sup
s
(cid:161)
P (s, Q) − 2−l(cid:162)
(cid:161)
while in the second case we get
2−l − P (s, Q)
sup
s
(cid:181)
(cid:162)
sups(P (s, Q) − 2−l) when P (s, Q) ≥ 2−l
sups(2−l − P (s, Q)) when P (s, Q) < 2−l
Note that the true value of  will be the largest of these two cases. Studying
the ﬁrst case, we get
(cid:182)
P (s, Q)
− 2−l = 2−m − 2−l,
=
sup
s
actual distribution of s given the helper data Q.
 = SD[(cid:104)S, Q(cid:105),(cid:104)Ul, Q(cid:105)]
|P (s ∈ S|Q ∈ Q) − P (s ∈ Ul|Q ∈ Q)|
= sup
s
Looking at the last term, since the uniform distribution is independent of the