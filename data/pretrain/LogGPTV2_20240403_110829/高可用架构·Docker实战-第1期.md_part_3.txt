然后 App Runtime 和 AppServer Runtime 就成了这样：
进入 2013 年，Docker 在 3 月默默地发布了第一个版本，我们
开始关注起来。紧接着我就离职出发去横穿亚洲大陆了，一路上提
着 AK 躲着子弹想着 Docker（大雾）并思考如何通过它来做一个
或者改造一个类似 DAE 一样的 PaaS，直到我回国。机缘巧合之下，
我加入到芒果TV，隶属于平台部门，有了环境便开始尝试我在路
上产生的这些想法。
芒果 TV 的 Nebulium Engine
加入芒果TV之后，一开始我实现了类似 DAE 架构的一个新的
PaaS —— Nebulium Engine（a.k.a NBE），只不过运行时完全
用 Docker 来隔离，控制层移到了 Container 之外。除此之外，
整体架构上和 DAE 并未有太多差别。
高可用架构 22
同时我遇到了一个很是头疼的问题——那就是在芒果 TV ，我们并
没有一个大一统的强势语言，我们必须把 Runtime 的控制权完全
交给业务方去决定。综合大半年线上运行结果来看，在资源管理和
工作流整合上面，其实 NBE 做得并不是很好。原因很多，一方面
是基础设施和豆瓣比实在太糟糕，如果说豆瓣是21世纪互联网的话，
我们现在还停留在19世纪的传声筒，另外一方面五花八门的语言
都需要支持，放开 Runtime 之后，对资源竞争和预估我们是完全
没有任何能力去做的，恰恰业务方又希望平台能 hold 住这些事。
举个例子，Python GIL 限定在非多进程模式下顶多吃死一个
核，然后隔壁组上了个 Java 的 Middleware……然后我们就看到
Python 业务方过来哭天喊地了。
在这个时期，我们的架构是这样的：
于是在挫折的 2014 年底，我们重新回顾了一遍 Borg 和 Omega
相关的信息，开始了第二代 NBE ，也就是今天的主角——
高可用架构 23
Project Eru ——的开发。这一次我们抛弃了以前做一个 PaaS 的
思路，而是决定去实现一个类似于 Borg 一样的服务编排和调度平台。
Project Eru
有了第一代 NBE 的开发经验，我们开发速度明显快了很多，第二
周的时候就已经有了一个大体上能用的 demo。到目前为止，Eru
平台可以混编 Offline 和 Online 的服务（binary/script），对于
资源尤其是 CPU 资源实现了自由维度（0.1，0.01，0.001等）
的弹性分配，使用 Redis 作为数据总线对外进行消息发布，动
态感知集群所有的 Containers 状态并监控其各项数据等。基于
Docker 的 Image Layer 特性，我们把其和 Git version 结合起来，
实现了自动化的 build/test 流程，统一了线上部署环境。同时顺
便解决了 Runtime 的污染问题，使得业务能快速的扩容/缩容。
然后，我们的架构变成了这个样子：
高可用架构 24
看上去变化不大，实际上里面的设计和反馈回路什么的和第一代已
经完全不一样了。
业务层方面在逻辑上我们使用了类似于 Kubernetes 的 Pod 来
描述一组资源，使得 Eru 有了 Container 的组资源控制的能力。
但是和 Kubernetes 不同的是，我们 Pod 仅仅是逻辑上的隔离，
主要用于业务的区分，而实际的隔离则基于我们的网络层。对于
Dockefile，我们不允许业务方自行写 Dockerfile。通过标准化的
App.yaml 统一 Dockerfile 的生成，通用化的 Entrypoint 则满
足了业务一份代码多个角色的复用和切换，使得任何业务几乎都可
以完全无痛的迁移上来。
另外我不知道大家发现没有，之前第一代 NBE 是个完整的闭环，
一个业务有生到死都有 NBE 本身各个组件的身影。但是在第二代
NBE 中我们放弃了以前考虑的完整闭环设计。之前实现的 NBE 第
一代打通了项目整个生命周期的每一个环节，但实际上落地起来困
难重重，并且使得 Dot（Master）的状态太重没法 Scale Out，因为
是它是单点部署，可靠性上会糟糕一些。所以 Eru 中每一个 Core
都是一个完整的无状态的逻辑核心，使得其可以 Scale Out 的同时
可靠性上也比 NBE 第一代要健壮得多。所以第三幅图你们可以看到，
我画了好多个 Eru-Core 来表明它是个可以 Scale out 的幺蛾子。
因此在这个体系下，我们推荐业务根据自身业务特性，通过监控自
身数据，订阅 Eru 广播，调用 Eru-Core 的 API ，实现复杂的自
高可用架构 25
定义的部署扩容等操作。我们并不会去强行干涉或者建立一系列规
则去限定这些事情。这也是它不属于 PaaS 的原因。
细节
大体介绍完这个项目之后，我来说说实现细节。主要有几个方面，
首先是项目部署结构总体技术选择，然后是网络、存储、资源分配、
服务发现等等。
首先 Eru 主要分 Core 和 Agent 两个部分。Agent 和 Core 并
没有很强的耦合，通过 Redis 来交互信息（依赖于我们自己的
Redis Cluster 集群技术），主要用来汇报本机 Containers 情况
和做一些系统层面的操作（比如增加减少 veth）。Core 则是刚才
所说无状态的逻辑核心，控制所有的 Docker Daemon 并且和
Agent 进行控制上的交互。
容器内存储上，我们目前大部分使用了 Devicemapper 小部分是
Overlay，因此我们有的 Docker Host 上使用了内核 3.19 的内
核，并外挂了一个 MooseFS 作为容器间数据共享的卷。考虑到
Docker 本身大部分时间是版本越新越靠谱（但是幺蛾子的 1.4 是
个杯具），因此基本上我们使用的都是最新版的 Docker。网络方
面对比了若干个解决方案之后，在隧道类（Weave/OVS等）和路
由类（MacVLAN/Calico等）中我们选择了后者中的 MacVLAN。
下面是我当时做的方案对比图：
高可用架构 26
网络
既然说到网络，那我就从网络开始说起，为啥当时我们会选择
MacVLAN 相对而言这个比较简单和冷门的方案？
相比于 Route 方案，Tunnel 方案灵活度会更高，但是会带来两
个问题：
 性能，比如 Weave，通过 UDP 封装数据包然后广播到其他跑
着 Weaver 的 Host，封包解包的过程就会带来一些开销。另外
大多数 OVS 方案性能其实都不太乐观，之前和某公司工程师交
流过，大体上会影响 20%~30% 左右的吞吐性能。（所以他们都
用上 FPGA了……）
 Debug 困难。Tunnel 的灵活是构建在 Host 间隧道上的，物
理网络的影响其实还没那么大，但是带来一个弊端就是如果现在
出了问题，我怎样才能快速的定位是物理链路还是隧道本身自己
的问题。
高可用架构 27
而 Route 方案也会有自己的问题：
 Hook，Route 方案需要 Container Host 上有高权限进程去
Hook 系统 API 做一些事情。
 依赖于物理链路，因此在公有云上开辟新子网做 Private SDN
使得同类 Containers 二层隔离就不可能了。
 如果是基于 BGP 的 Calico，那么生效时间差也可能带来 Container
应用同步上的一些问题。
所以最后我们选择了 MacVLAN，一来考虑到我们组人少事多，
隧道类方案规模大了之后 Debug 始终是一件比较麻烦的事情，二
来 MacVLAN 从理解上和逻辑上算是目前最简单的一个方案了。
使用这种方案后，我们可以很容易在二层做 QoS，按照 IP 控流等，
这样避免了使用 tc（或者修改内核加强 tc）去做这么一件事件，毕
竟改了内核你总得维护对吧。因为是完全独立的网络栈，性能上也
比 Weave 等方案表现得好太多，当然还有二层隔离带来的安全性。
某种意义上 MacVLAN 对 Container 耦合最小，但是同时对物理
链路耦合最大。在混合云上，无论是 AWS 也好还是青云亦或者微
软的 Azure，对二层隔离的亲和度不高，主要表现在不支持自定
义子网上。因此选取这个方案后，在混合云上是没法用的。所以目
前我们也支持使用 Host 模式，使得容器可以直接在云上部署，不
过这样一来在云上灵活度就没那么高了。
高可用架构 28
存储
容器内存储我们目前对这个需求不是太高，小部分选取 Overlay
主要是为了我们 Redis Cluster 集群方案上 Eru 之后 Redis 的
AOF 模式需要，目前来看情况良好。考虑 Overlay 也是因为来自
百度的一哥们告诉我们这货是 Container 杀人越货必备，尤其是
小文件，所以我们的另外一个工程师也做了一个测试。
在 Devicemapper 和 Overlay 的性能对比上，大量小文件持续写
Overlay 的性能要高不少。然后我们就小部分上 Overlay 了。对
于我们现有的 Redis Cluster 集群，我们采用内存分割的方式部
署 Container。一个 Container 内部的 Redis 限制在 Host 总
内存数/ Container 数这么大。举个例子，我们给 Redis 的 CPU
高可用架构 29
分配为 0.5 个，一台机器 24 Core 可以部署 48 个 Container，
而我们的 Host 申请下来的一般只有 64G，因此基本上就是 1G
左右一个 Redis Container 了。
这样会有2个好处：
 AOF 卡顿问题得到缓解。
 数据量或者文件碎片量远远达不到容器内存储的性能上限，意外
情况可控。
在这个量级下，其实 DM 和 Overlay 还是差不多的
当然如果 instance 内存上限提高了，那么 Overlay 的优势就会很
明显了。
Scale
扩容和缩容，我们更加希望是业务方去定制这个组件去做。我们所
有的容器基础监控数据均存储在了 influxdb 上面，虽然现在来看
它不是蛮靠谱（研究 Open-falcon 中）。同时业务方也可以写自己
想监控的一些数据按照自己喜欢的姿势到任何地方，然后通过读
取这些数据，判断并决策，最后调取 Core 的 API 去干扩容和缩
容。我们在第一代 NBE 中是我们自己定义了一套扩容缩容的规则，
主要是效果不好，业务有时候要监控的并不是什么 CPU、MEM、
IO，可能就是某个请求的耗时来决定是否扩容缩容。
高可用架构 30
因此 Eru 中，我们完全放开了权限。
核心宗旨就是“谁关心，谁做”。
资源分配和集群调度
资源的分配和集群调度，我们在第二代 NBE 中采取了以CPU 为主，
MEM 半人工审核机制。磁盘 IO 暂时没有加入到 Eru 豪华午间套餐，
而流量控制交给了二层控制器。之所以这么选择主要是因为考虑到
一个机房建设成本的时候，CPU 的成本是比较高的，因此以 CPU
为主要调度维度。在 QCon 上和腾讯的讲师聊过之后，关于 CPU
的利用率上我们也实现了掰开几分用这么个需求，当然，我们是可
以按照 Pod 来设置的，我们不会局限于 0.1 这个粒度，0.01或者
0.5 都可以。但是内存方面明显我们的研发力量表示改内核并自行
维护还不如在 520 陪女朋友看电影，所以我们没有实现腾讯讲师
说的 softlimit subsystem 。主要还是通过数据判断 Host 内存
余量和在上面 Container 内存使用量/申明量对比来做旁路 OOM
Kill。
以 CPU 为主维度的来调度上，我们把应用申请 CPU 的数目计
算为两类，一类称之为独占核，一类为碎片核。一个 Container
有且仅有一个碎片核，比如申请为 3.2 个 CPU 的话（假定一个
Cpu 分为 10 份），我们会通过 CpuSet 参数设定 4 个核给这个
Container，然后统一设定 CpuShare 为 1024*2。其中一个核
会跟其他 5个 Container 共享，实现 Cpu 资源的弹性。
高可用架构 31
目前我们暂不考虑容器均匀部署这么个需求，因为我们对应的都是
一次调度几台甚至几十台机器的情况，单点问题并不严重。
其实主要还是懒……
所以在应用上线时，会经过这些步骤：
 申报内存最大使用量和单个 Container CPU 需求。比如 1G 1.3
个 CPU。