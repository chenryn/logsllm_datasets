the 
Anderson  Panel,  this  activity  was  spurred  by  research 
funding  falling  out  from  the  Vietnam  War  and  related 
activities.  The  U.S.  Department  of  Defense  and  its 
agencies  were 
the  principal  funding  sources  for 
research as well as for development.  
findings  of 
from 
the 
The  private  sector  developed  several  security-
oriented  commercial  products  and  prototypes.  Among 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
the  independently-developed  products  were:  IBM’s 
Resource  Access  Control  Facility  (RACF)  add-on  to 
MVS  and  the  Virtual  Machine  Facility/370  (VM/370) 
operating  system,  and  Tymshare’s  capability-based 
operating system Gnosis. 
The  U.S.  DoD  sponsored  system  and  prototype 
developments  for  several  prototypes  and  operational 
systems, including: 
•  Multilevel AFDSC Multics 
•  MITRE UNIX 11/45 prototype 
•  Stanford  Research  Institute’s  Provably  Secure 
Operating System (PSOS) design 
•  Two  attempts  at  a  multilevel  secure  version  of 
and 
(Ford  Aerospace’s  KSOS-11 
UNIX 
Honeywell’s KSOS-6) 
•  SDC’s Kernelized VM/370 (KVM/370) 
•  Ford Aerospace’s AUTODIN II 
•  ITT/IBM’s SACDIN 
•  SDC’s BLACKER project. 
In  addition  to  these,  two  forays  into  multilevel 
database  management  were  conducted.  At  SDC,  Clark 
Weissman reassigned me to perform computer security 
research,  abandoning  my  chosen  research  study  on 
applications of Petri nets. Tom Hinke and I produced a 
study, model and design, under sponsorship from Rome 
Air  Development  Center  (RADC),  for  a  multilevel 
relational  database  management  system  that  could  run 
under  an  unmodified  AFDSC  Multics.  My  Petri  net 
research proved to have an application and was used in 
our  model  as  a  multilevel  secure  solution 
to 
synchronizing  database  queries  and  updates.15  David 
Bonyun  and  colleagues  at  I.P.  Sharp  Associates 
(Canada)  produced  a  multilevel  DBMS  model  for  the 
Air  Force  Electronic  Systems  Division.  The  IP  Sharp 
model  was  designed  to  have  been  implemented  within 
Rings 1 and 2 of Multics and identified various security 
primitives to support multilevel database management.  
The  Hinke-Schaefer  multilevel  DBMS  work  is 
noteworthy  because  its  implementation  would  contain 
no  security  relevant  code  and  was  contractually 
required not to require any modifications to the Multics 
Security  Kernel.  It  was  instead  constrained  to  operate, 
under  the  Least  Privilege  concept,  as  a  completely 
unprivileged process in user rings. 
2.6. Toward system security evaluation criteria 
By  1978  researchers  and  developers  had  begun  to 
claim  that  they  knew  precisely  how  to  implement 
15  A  variation  of  our  technique  was  independently  developed 
by Reed and Kanodia, and is known as event counts.
secure  (or  “secure  enough”)  systems.  While  few 
projects  had  produced  fully  operational,  well-tuned 
secure  systems,  such  products  were  not  readily 
available.  Although  multilevel  AFDSC  Multics  and 
ADEPT-50  had  been  fielded  and  accredited,  there  was 
an understanding that their performance left something 
to be desired. They were far from being “user friendly”. 
AUTODIN  had  been  accredited  for  full  multilevel  use 
(UNCLASSIFIED  through  compartmented  TOP  SECRET),
the consensus was that if AUTODIN were subjected to 
recertification  and  accreditation  analysis,  it  would  fail 
based  on  contemporary 
technical  knowledge  of 
vulnerability analysis. 
The  research  community  had  moved  forward  to 
achieve  a  preliminary  understanding  of  covert  channel 
analysis  (CCA).  The  hubris  of  the  moment  had  led 
many  to  claim  that  with  the  new  secure  systems, 
unauthorized  direct  access  to  files,  spooling  files, 
printer  queues,  the  address  spaces  of  other  processes, 
etc.,  would  be  impossible.  Thus,  only  by  timed 
modulation  of  various  system  artifacts  could  a  pair  of 
coöperating  Trojan  horses  communicate  with  each 
other  in  violation  of  the  system  security  policy 
interpretation  of  confinement  or  the  Bell-LaPadula  *-
property.  Various  technologies  had  been  created  for 
identifying,  measuring  and  using  covert  channels [24], 
and some formal analysis tools had been created [18] to 
discover 
system 
specifications. 
channels 
covert 
in 
formal 
2.6.1.  Security  kernels  bad,  TCBs  good.  For  several 
reasons, many in the security research and development 
community  began  to  oppose  the  reference  monitor 
concept and its implementation as a security kernel. For 
the  most  part,  the  criticism  focused  on  the  perceived 
inefficiency of central mediation and context switching 
forced by the RVM’s complete mediation requirement. 
Many  argued  against  the  strict  notion  of  having  to 
validate every reference to every system object.  
One divide-and-conquer strategy, represented in the 
Bell-LaPadula  models,  was  achieved  by  having  the 
security  kernel  apply  full  policy  mediation  to  every 
initial  request  or  attempt  by  a  subject  to  access  an 
object  in  a  specific  mode.  If  that  mode  of  access  was 
consistent  with  policy,  a  descriptor  or  token  would  be 
generated that the kernel could rapidly consult to allow 
or reject all subsequent access attempts.  
This  resolved  most  of  the problem. But it left open 
the  question  of  how  the  controller  of  an  object  could 
immediately  revoke  all  or  selective  access  modes  to 
that  object.  The  custom  hardware  descriptor-based 
architecture  of  Multics  allowed  this  to  be  done 
immediately.  However,  in  other  system  architectures, 
such  a  feature  was  deemed  too  costly,  and  system 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
to  have  access 
security  policies  were  modified 
revocations  become  effective  only  on  new  access 
requests. For capability-based systems, where a process 
could  endure  for  days  or  weeks,  this  problem  resulted 
in many emotional arguments and dissents. 
to 
to 
or 
protection 
supporting 
To  some,  a  more  significant  issue  became  apparent 
with  respect  to  certain  modules  that  were  included 
inside  the  security  perimeter  that  were  not  directly 
related 
the 
implementation  of  protection-critical  modules.  Their 
inclusion  as  security  relevant  code  was  clear,  for  their 
improper  operation  could  lead  to  a  security  policy 
compromise.  For  example,  a  resource  scheduler  or 
dispatcher  could,  in  principle,  operate  in  a  less 
privileged domain than that of the security kernel. But 
many argued that a scheduler needed to have access to 
system-wide information, as scheduling decisions made 
only  within  a  single  security  level  could  result  in 
thrashing  or  other  inefficiencies.  The  only  way  a 
scheduler  could  view  such 
information  under  a 
multilevel security policy model would be if it executed 
as if it were a system-high subject. But in that case, any 
request it made to dispatch a specific subject could be 
misused  to  signal  information  as  a  covert  channel  in 
violation of the *-property.  
flow  confinement 
Indeed,  no  matter  how  it  was  structured,  every 
multilevel  system  had  to  have  some  internal  processes 
that  allocated  or  modulated  global  system  resources. 
Covert  channel  analysis  techniques  showed  that  such 
processes  could  always  be  conscripted  to  violate 
information 
requirements—even 
when  such  processes were implemented correctly (i.e.,
in full conformity with their specifications). There was 
growing awareness of this problem in KVM/370, which 
called them the Global Processes and in KSOS and the 
SCOMP, where they were called Non-Kernel Security-
Related  processes  (NKSR).  In  all  cases,  their  direct 
verification  against the constraints of information flow 
analysis was impossible. 
to 
The  Bell-LaPadula  models  had  provided  for  the 
notion of trusted subjects whose functionality required 
transferring  information  between  classified  containers 
in  apparent  violation 
the  *-property.  Global 
processes  were  less  obviously  in  this  class.  Isolating 
such  processes  to  operate  in  less  privileged  domains 
only  led  to  additional  context-switching  inefficiencies, 
as  nothing  could  be  done  directly  to  ensure  that  their 
use  would  not  compromise  security.  This  observation 
led to two dénouements:
1.  It was concluded that because of the uncertainties of 
the  potential 
discretionary 
exploitation  of  covert  channels 
in  multilevel 
systems,  and  the  nettlesome  questions  of  global 
controls, 
access 
process  efficiencies,  a  system  could  no  longer  be 
called  secure  but  would  henceforth  be  called 
trusted;
2.  The  term  security  kernel  was  scrapped  in  favor  of 
the neologistic term trusted computing base (TCB). 
As  was  to  be  seen  in  the  sequel,  ‘TCB’  was  a 
vaguely-defined  term,  and  its  adaptation  as  a  concept 
resulted  in  abandoning  the  third  requirement  of  the 
Anderson Study, conceptual simplicity of the RVM. 
itself 
2.6.2.  Distributed  mediation,  capabilities,  PSOS, 
and Gnosis. Still, the prejudice against the centralized 
security  kernel  concept  manifested 
in  an 
altogether  different  way.  It  was  argued  that  automated 
formal  code  verification  (or  mechanical  “proof  of 
correctness”)  was  closer  to  becoming  available,  and 
soon  all  operating  system  code  –  and  then  hardware 
design  and  implementation  –  correctness  could  be 
established  as  mathematical  fact.  Thus,  it  would  be 
possible  to  include  all  required  security  checking  as 
part  of  each  system  module  or  function,  thereby 
eliminating needless access-checking function calls and 
their  costly  context  switching.  Moreover,  there  would 
be  no  separation  of  call  from  function,  and  hence  no 
need  for  the  access-checking  functions  to  derive  or 
establish the relevant context of the requested operation 
in concert with the semantics of the application.  
And  so,  a  movement  gained  momentum  to  design 
and  field  systems  structured  along 
lines  of 
distributed  mediation  and  that  had  no  distinct  security 
perimeter  other  than  the  [most]  privileged  (or  most 
primitive)  part  of  the  operating  system  itself.  The  first 
such  research  study,  the  capability-based  Provably 
Secure Operating System (PSOS) [19] project yielded: 
the 
•  A methodology for the design, implementation, and 
proof of properties of large computing systems 
•  The  design  of  a  secure  operating  system  using  this 
methodology 
•  The  security  properties  to  be  proven  about  the 
system 
•  Formal verification methods and tools that came to 
be  known  as 
the  Hierarchical  Development 
Methodology  (HDM)  and  the  formal  specification 
language SPECIAL 
•  Considerations for implementing such a system, and 
•  An 
and 
to  monitoring 
approach 
security 
performance. 
PSOS  was 
rigorously  decomposed 
a 
that  had  no  upward 
hierarchical 
functional- 
unique 
protection  mechanism  was  a  capability,  a  form  of 
specification 
or 
data-dependencies.  The 
into 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
unforgeable,  immutable  token,  possession  of  which 
granted  a  set  of  specific  access  rights  to  the  object  to 
which  it  was  linked.  The  PSOS  concept  yielded 
considerable new research, but left open the question of 
how  a  secure  system  is  to  be  initially  configured,  how 
the  first  capability  was  to  be  created,  and  how  one 
could algorithmically examine a capability distribution 
and determine whether or not a system was in a secure 
state.  In  addition,  there  were  no  efficient  means  of 
determining  which  users  possessed  capabilities  to 
which  objects.  Despite  the  open  questions,  it  was 
asserted  that  PSOS  and  its  proven  design  could 
implement a secure multilevel operating system. 
Norm  Hardy,  Charlie  Landau  and  Bill  Frantz 
designed  the  Great  New  Operating  System  In  the  Sky 
(GNOSIS)  [12]  while  at  Tymshare,  Inc.  GNOSIS,  unlike 
PSOS,  was  commercially  developed  and  implemented 
a  capability-based  time  sharing  environment  similar to 
that  of  VM/370’s  Cambridge  Monitor  System  (CMS) 
interface.  Questions  similar  to  those  raised  in  PSOS 
remained  to  be  answered  in  GNOSIS  and  its  successor 
system KeyKOS. 
2.6.3.  Lee  Panel,  NBS  1978.  The  National  Bureau  of 
Standards  organized  an 
invitational  workshop  on 
standards  for  computer  security  and  audit.  One  of  its 
panels  focused  on  standardizing  the  assessment  of 
security  controls  in  processors,  operating  systems  and 
nearby peripherals. This panel was chaired by Ted Lee, 