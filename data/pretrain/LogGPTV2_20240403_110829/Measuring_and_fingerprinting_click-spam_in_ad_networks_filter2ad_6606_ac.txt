 1
 0.8
 0.6
 0.4
 0.2
 0
5s dwell, 1 mouse ev
15s dwell, 5 mouse ev
30s dwell, 15 mouse ev
e
t
a
m
i
t
s
e
l
a
n
i
f
m
o
r
f
a
t
l
e
D
100%
50%
0%
-50%
-100%
Original
Control
Original
Control
(a) Interstitial page performance
(b) Gold-standard user deﬁnition
4: Design space exploration
ad=yoga, intst=click, gstd=5s+1mev
ad=celebrity, intst=delay, gstd=5s+1mev
ad=celebrity, intst=click, gstd=5s+1mev
ad=celebrity, intst=click, gstd=15s+5mev
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
# gold-standard users
(c) Convergence
tails). We were charged for at least 48 of these clicks. Our estimates
match the search ad network’s estimates recomputed after discount-
ing these clicks. Furthermore, as seen for network C where syndi-
cated search partners are excluded, our estimates closely match that
reported by the network. There were no clicks on the control ads
on network C, which further supports our high estimate.
Our absolute numbers also agree with public estimates of av-
erage click-spam for these networks [3]. Next we drill deeper to
validate our design decisions.
4.5.1 Interstitial Pages
Figure 4a plots the fraction of clicks for each interstitial page that
reach the landing page for the celebrity ad, and for the correspond-
ing control ad. Note that this fraction drops as the interstitial page
changes from clicking a link (29%), to waiting 5 seconds (13%), to
solving a CAPTCHA (4%), demonstrating the increasingly higher
bar set by the interstitial pages.
Interestingly, we ﬁnd users are
more likely to click through to the landing-page than wait 5 sec-
onds. Except for the CAPTCHA interstitial, the fraction reaching
the landing page is signiﬁcantly lower for the control ad than for
the original ad; this validates Assumption 1 from the previous sec-
tion that the interstitial page concentrates non-click-spam trafﬁc (by
some unknown amount). Despite the varied interstitial page perfor-
mance, the estimates computed from the delay and click interstitial
converge (in Figure 3) for the experiments where we have a bal-
anced number of converters through the interstitial and direct path,
which supports Assumption 2. The CAPTCHA seems to reduce
both normal and control trafﬁc to the same low base level regardless
of user intent; as a result, it is unsuitable for use in our framework.
4.5.2 Gold-Standard Users
Figure 4b plots the fraction of gold-standard users for the origi-
nal celebrity ad and the control ad, for three different deﬁnitions of
gold-standard users. The ﬁrst deﬁnition is, as before, 5s of dwell
time and 1 mouse event. The second deﬁnition is 15s of dwell time
and 5 mouse events. The third deﬁnition is 30s of dwell time and 15
mouse events. Note that the fraction of gold-standard users for the
control ad is zero for the second and third deﬁnition. This validates
Assumption 3 that very few users are curious enough to click the
control ad. In a real-world setting, we expect advertisers to deﬁne
gold-standard users based on ﬁnancial transactions (much tighter
than any of our deﬁnitions).
We focus next on the sensitivity of the click-spam estimate to the
number of gold-standard users. Figure 4c plots the convergence
of our click-spam estimate as a function of the number of gold-
standard users for various combinations of our ad, interstitial page,
and deﬁnition of gold-standard user. X-values are driven by the
periodicity of ad network reports. Y-values are deltas from our best
estimate (last data-point for that series). In each case our estimate
converges at or before 25 gold-standard users.
)
.
m
r
o
n
(
d
i
l
a
v
n
o
i
t
c
a
r
F
 1
 0.75
 0.5
 0.25
 0
A
B
C
D
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
0s
A
D
B
C
2s
4s
6s
8s
10s
(a) Mobile Ad Network
(b) Dwell Time
5: Normalized estimates and dwell times for mobile ads
4.6 Search Ad Networks
Figure 3 shows that while reputed search ad networks generally
have a good handle on click-spam, a single average click-spam met-
ric across the entire network is of little use due to different key-
words experiencing different levels of click-spam. An advertiser
cares only about click-spam rates for keywords he is interested in
bidding on. The difference in click-spam rates between the celebrity
ad and lawnmower ad is up to 20% (normalized).
We omit discussion of 7Search since we did not get any gold-
standard users through that network to base our estimates on.
4.7 Mobile Ad Networks
Figure 5a plots our click-spam estimates and the networks’ own
estimates for the celebrity ad across the four mobile ad networks
we measured. Despite running our ads for over a month, and weak-
ening our deﬁnition of gold-standard users to only 5s of dwell time
(i.e., user spent 5s on our landing page; no tap event required),
we failed to attract even ﬁve gold-standard users for the yoga and
lawnmower ads, and attracted fewer than twenty for the celebrity ad.
While, our estimates are below the convergence threshold, to inves-
tigate the huge difference in our interim estimates and ad network
numbers, we plot the CDF of user dwell-time in Figure 5b.
Ad network A charged us for over a third of the clicks (non-
normalized), yet as illustrated by the y-intercept in Figure 5b, over
95% of network A users spent under a second on our landing-page!
We ﬁnd evidence of an attack that would result in such a signature
in Section 5.4.1. Network D appears to be quite well aware of the
poor trafﬁc quality on their network; they charged us for less than
1% of the clicks. Mobile ad network C is a curious case. There is
practically no difference between the click-through-rate (CTR) of
our original ad and the CTR of our control ad with junk text, sug-
gesting that the content of the ad is irrelevant for users clicking ads
on this network. Our Bayesian formula understandably estimates
click-spam to be nearly 100% for this network despite the network
charging us for most of these clicks.
Our data, although inconclusive, suggests that charges on mobile
ad networks do not currently reﬂect actual user intent.
180celebrity
yoga
lawnmower
)
.
m
r
o
n
(
d
i
l
a
v
n
o
i
t
c
a
r
F
 1.25
 1
 0.75
 0.5
 0.25
 0
A
B
C
6: Normalized estimates for contextual and social ads
4.8 Contextual and Social Ad Networks
Figure 6 plots our click-spam estimates, and those reported by
contextual and social ad networks we measured. Network B ap-
proved only our yoga ad. Click-spam is uniformly higher than that
on reputed search ad networks (not apparent due to normalization).
The networks do a better job than mobile ad networks in track-
ing this higher rate of click-spam. Nevertheless, our estimates are
uniformly lower than the numbers reported suggesting that these
networks do not yet discount all click-spam. Interestingly, network
B consistently charged us for more unique clicks than we logged on
our server. We speculate network B does not follow the standard
practice of suppressing duplicate/double-clicks by a user [39].
5. FINGERPRINTING CLICK-SPAM
Recall in previous sections we assumed that very few people
would intentionally click on our control ads (e.g., Figure 2), and
substantiated the assumption through the lack of gold-standard users
for these ads. Nevertheless, convincing ad networks requires in-
controvertible evidence of fraud. One needs to discover the full
sequence of events that culminate in the fraudulent click. We man-
ually investigate clicks we receive on control ads. The sophistica-
tion and diversity of attacks makes this non-trivial. In this section
we describe seven ongoing click-spam attacks we discovered.
5.1 Scale
We were charged approximately $1000 for about 30,000 clicks
on all the control ads we created across all ad networks. Our inves-
tigations cover 26% of the trafﬁc our control ads attracted on re-
puted networks; as expected by design, all these clicks were found
to be fraudulent in nature. The ad networks typically discounted
substantially less than this fraction (between 6–20%). Thus we can
conﬁdently claim that some of this fraudulent trafﬁc is currently
not caught by ad networks. Note that 26% covers only the trafﬁc
we actually investigated; we expect the disparity in discounts vs.
fraudulent trafﬁc to grow as we investigate more clicks. That being
said, our manual approach is too laborious and not scalable. More
automated methods for investigating click-spam are needed.
5.2 Methodology
To prioritize manual investigation of the large number of clicks,
we use simple graph-clustering over features in the HTTP request,
and detecting heavy-hitting clusters. A naïve approach would be
to use the HTTP Referer domain. We found groups of websites
on unrelated domains but with nearly-identical layouts (Figure 7),
all driving click-spam trafﬁc to our site. This is done presumably
to spread out the click-spam through multiple sources in order to
operate below detection-thresholds of existing ad networks. Using
additional features to cluster such publishers allows us to aggregate
them back together and do proper heavy-hitter accounting.
7: Some Sybil [21] websites driving click-spam to our ads
letscelebrate.com
fuckwapi.com
jattg.com
balawap.net
housecentral.com
houseradar.com
premierfurnishings.com
chewonit.com
wiseshop.com
localpages.com
modelfor.com
homeshine.com
industrialhq.com
healthdesk.com
odometer.com
topicologist.com
google.com
items.com
cheapstuff.com
freshdeals.com
localxpress.com
dietbasics.com
dotellall.com
searchmylocal.com
rateit.com
discoveryourtrueessence.com
jamthefilm.com
healthynow.com
stayingfit.com
savingmore.com
yahoo.com
bizzire.com
healthyweb.com
smartask.com
livingfrugal.com
grandblancoutdoors.com
pagesinxt.com
phorobucket.com
coolsearchresults.com
whowhatwhere.com
allcelebz.net
yogisupplements.com
4283greenview.com
mywebsearch.com
hopmovies.com
ddc.com
onebeing.com
searchignited.com
keywordblocks.com
searchdiscovered.com
crypt2000.org
hotactress.biz
beautifulfeel.com
shalma.com
mapsyoga.net
celebrity4ever.com
ask.com
asthangayoga.com
movieedu.com
clickshield.net
rapsongcd.com
deansplanet.com
searchignited.com
machomedia.com