231
27
3827
4046
1789
1778
1582
434
4
ses
419
63
7787
9551
3543
3275
2449
631
7
Clean
Respon-
ses
185
0
9
342
186
124
10
486
210
0
Table 7: Top 10 locations serving malware in Limewire.
Infected Mal- Clean
Respon- ware
Files
ware
IP
Infected
Files
24.185.43.12
200.193.133.181
68.199.111.60
24.108.148.47
67.70.44.58
24.73.2.236
200.63.211.100
69.157.73.229
67.8.149.155
69.253.47.181
101
12
24
1
1
23
3
1
2
1
ses
4512
91
83
63
50
44
42
33
32
30
1
1
1
1
1
2
2
1
2
1
55
0
3
8
11
99
2
23
11
0
Table 8: Top 10 locations serving malware in OpenFT.
malware sources in Limewire are also serving good ﬁles, although
in smaller numbers in most cases.
In OpenFT, most are serving
good ﬁles as well, but two are not.
In OpenFT, none of the top 10 sources of malicious ﬁles is also
one of the top 10 sources of good downloads. In Limewire several
of the top malicious sources are also top good sources, although all
of these are private IP addresses. Note that the cases of private IP
addresses, NAT and DHCP effect make it impossible to determine
if the ﬁles are really coming from the same host.
A total of only 1.5% of all responses in Limewire come from pri-
vate IP addresses when they are responsible for 20% of our failed
downloads. They are also responsible for a disproportionately high
amount of the malicious responses: 28%. The top source of in-
fected responses in Limewire, 192.168.1.11 is a private address
and is responsible for 7.8% of infected replies we see. The top
offender in OpenFT, 24.185.43.12 is responsible for 67.2% of in-
fected replies in this system. This address is registered to a New
York (USA) based cable Internet provider.
Further, in Limewire, we also see a difference between how many
hosts are serving individual infected ﬁles vs how many hosts are
serving individual clean ﬁles. On average, we see 22.9 distinct IP
addresses serving each infected ﬁle, but only 6.2 for clean ﬁles.
Interestingly, we see somewhat of the opposite effect in OpenFT,
with 3.8 hosts serving each clean ﬁle but only 1.5 for infected ﬁles.
4. FILTERING MALWARE
4.1 Filtering in Limewire
criteria: 1) the ﬁle name or metadata does not match the query; 2)
the extension of the returned ﬁle is not considered by Limewire to
match the ﬁle type asked for; or 3) Limewire believes the response
contains the Mandragore worm4.
In all of query responses we have seen, only 22, all with the ﬁle-
name “control.exe,” have been classiﬁed by Limewire as the Man-
dragore worm. No malware is detected in this ﬁle by ClamAV. It is
likely that this check is outdated and this ﬁle is legitimate.
Limewire determined that 3.5% of responses contained malware
because they did not match the query sent. This check produces
a very high false positive: 15.6%! Similarly, 3.0% of responses
containing malware were determined by Limewire not to match the
requested ﬁle type. The false positive rate for this check was 3.5%.
We conclude that ﬁltering checks in Limewire are inadequate, pro-
ducing nearly 17% false positives.
4.2 File Size-based Filtering
We now perform a preliminary investigation of a simpler and
more effective ﬁltering mechanism for P2P networks based on ﬁle
sizes. We ﬁrst look into the names and sizes of the ﬁles containing
malware. As shown in Table 9, much of the malware is seen at only
a few distinct ﬁle sizes, with a very large proportion in a single size.
In fact, much of the top malware occurs in its top size over 90% of
the times it is seen. This seems to indicate that the size of a ﬁle
may be a good indicator of malware. Thus we hypothesize that
adding ﬁlters to discard responses whose size match that of known
malware can be used as a simple and effective heuristic to block
malware on P2P systems.
Name
VB-100
Alcan.D
VB-16
Poom.A
Somefool.P
Limewire
Sizes % Largest
99.95%
99.85%
99.98%
93.13%
99.09%
7
6
2
34
6
OpenFT
Sizes % Largest
99.22%
96.29%
100%
99.67%
100%
3
2
1
6
1
Table 9: Number of ﬁle sizes and the percent of responses con-
taining each malware at the most common ﬁle size in both
Limewire and OpenFT (for top 5 malware).
We now test this heuristic for false positives. Table 10 shows
the percentage of blocked ﬁles at each size which would have been
false positives, if this ﬁlter was in place. We assume that the most
frequently occurring size of the malware is used in the ﬁlter. We
conclude the percentage of false positives is negligible in most
cases, with the exception of VB-16 in OpenFT. While a deeper
analysis of the heuristic is needed before any ﬁrm conclusion can
be drawn, it is important to note that VB-16 shows up only four
times in OpenFT.
5. LIMITATIONS AND FUTURE WORK
This paper presented an initial look at malware in P2P systems
and how to ﬁlter responses containing malware. The current study
has several limitations: 1) a relatively short duration of the study;
2) it was possible only to observe malware returned in the search
queries and the distribution of malware may be different in down-
loaded ﬁles and across all the ﬁles available for download; 3) mal-
While OpenFT does not attempt to ﬁlter malware, Limewire has
a built in capability to ﬂag some query responses as suspicious.
Such responses are not shown to the user. It bases this on three
4Limewire determines if a response is the Mandragore worm by
checking if the ﬁle size is 8192 bytes and the ﬁle name is the same
as the query string with the addition of .exe.
Name
VB-100
Alcan.D
VB-16
Poom.A
Somefool.P
Posi-
tives
796
98
2
0
0
0.10
0.07
0.04
0
0
Limewire
OpenFT
Total False % Total False %
Resp-
onses
776666
140832
5330
4768
2176
Resp-
onses
510
385
29
4497
149
Posi-
tives
2
5
25
0
0
0.39
1.30
86.2
0
0
Table 10: False positives for our size based ﬁlter for top 5 mal-
ware. For each malware, the most common occurring ﬁle size
is used in the ﬁlter.
ware could be present in ﬁle formats other than executable, archival,
and Microsoft Ofﬁce; 4) ClamAV [16] may fail to detect some mal-
ware; and 5) it was not possible to observe malware in other pop-
ular P2P networks, which are either not decentralized or are not
open source. It is possible to eliminate several of these limitations
in favor of drawing more comprehensive conclusions. We plan to
undertake a more detailed study in the future.
We believe the simple size based ﬁltering we propose is a signiﬁ-
cant step in ﬁltering malware in P2P networks. It has the additional
advantage that it allows ﬁltering to be done before any download
is performed. However, an aspect of this ﬁltering technique re-
mains to be investigated: When should the size-based ﬁltering rules
be updated to avoid false positives due to outdated malware? A
knowledge of malware life-cycle is necessary to propose a reason-
able heuristic for this. Unfortunately, our data duration is not long
enough to propose such a study. We plan to look into this issue with
on-going data collection.
Acknowledgements
We would like to thank Rob Henderson for support in data collec-
tion. Michel Salim and Nikhil Balchandani worked on the class
project that led to this paper. Their input is appreciated.
6. REFERENCES
[1] Computer associates virus information center. http:
//www3.ca.com/securityadvisor/virusinfo.
[2] The giFT project homepage.
http://gift.sourceforge.net.
[3] Gnutella protocol speciﬁcation.
http://www.the-gdf.org/wiki/index.php?
title=Gnutella_Protocol_Development.
[4] K. Gummadi, R. Dunn, S. Saroiu, S. Gribble, H. Levy, and
J. Zahorjan. Measurement, modeling, and analysis of
peer-to-peer ﬁle-sharing workload. In ACM SOSP, 2003.
[5] L. Guo, S. Chen, Z. Xiao, E. Tan, X. Ding, and X. Zhang.
Measurement, analysis, and modeling of bittorrent-like
systems. In ACM SIGCOMM Internet Measurement
Conference (IMC), 2005.
[6] T. Holgers, D. Watson, and S. Gribble. Cutting through the
confusion: A measurement study of homograph attacks. In
USENIX Annual Technical Conference (USENIX), 2006.
[7] J. Liang, R. Kumar, and K. W. Ross. The fasttrack overlay: A
measurement study. Computer Networks, 50(6):842–858,
2006.
[8] LimeWire homepage. http://www.limewire.org.
[9] D. Moore, V. Paxson, S. Savage, C. Shannon, S. Staniford,
and N. Weaver. Inside the slammer worm. In IEEE Security
and Privacy, 2003.
[10] D. Moore, C. Shannon, and J. Brown. Code red: A case
study on the spread and victims of an internet worm. In
ACM/USENIX IMW, 2002.
[11] A. Moshchuk, T. Bragin, S. Gribble, and H. Levy. A
crawler-based study of spyware on the web. In Internet
Society Network and Distributed System Security Symposium
(NDSS), Feb. 2006.
[12] S. Saroiu, S. Gribble, and H. Levy. Measurement and
analysis of spyware in a university environment. In USENIX
Networked Sytems Design and Implementation (NSDI), 30
Mar. 2004.
[13] S. Shin, J. Jung, and H. Balakrishnan. Malware prevalence in
the kazaa ﬁle-sharing network. In ACM SIGCOMM Internet
Measurement Conference (IMC), 2006.
[14] Sophos virus analyses.
http://www.sophos.com/virusinfo/analyses.
[15] Symantec security response.
http://www.symantec.com/avcenter.
[16] Tomasz Kojm. ClamAV homepage.
http://www.clamav.net.
[17] Kapersky lab virus encyclopedia. http://www.
viruslist.com/en/viruses/encycolpedia.
[18] V. Yegneswaran, P. Barford, and J. Ullrich. Internet
intrusions: Global characteristics and prevalence. In ACM
SIGMETRICS, 2003.
[19] W. Yu. Analyze the worm-based attack in large scale p2p
networks. 8th IEEE International Symposium on
High-Assurace Systems Engineering, pages 308–309, Mar.
2004.
[20] L. Zhou, L. Zhang, F. McSherry, N. Immorlica, M. Costa,
and S. Chien. A ﬁrst look at peer-to-peer worms: Threats and
devenses. In Proceedings of the IPTPS, Feb. 2005.