Vector OLE (VOLE) is the arithmetic analogue of string OT. Concretely, the VOLE func-
tionality is a two-party functionality that takes a pair of vectors from the sender P0, and
allows the receiver P1 to learn a chosen linear combination of these vectors. More formally,
given a ﬁnite ﬁeld F, the VOLE functionality takes a pair of vectors (u, v) ∈ Fn × Fn from
P0 and a scalar x ∈ F from P1. It outputs w = ux + v to P1. We will also consider a
randomized version of VOLE where the sender’s inputs (u, v) are picked at random by the
functionality and delivered as outputs to the sender. The deterministic VOLE functionality
can be easily reduced to the randomized one analogously to the reduction of OT to random
OT [Bea95] (see Section 6.1).
We note that our results can apply to generating VOLE over non-ﬁeld rings (e.g., Z
2k)
under suitable variants of the underlying intractability assumptions [IPS09]. This can be
useful in turn for secure arithmetic computation over rings [CFIK03,IPS09,CDE+18]. For
simplicity, we focus here on the case of VOLE over ﬁelds.
2.2 Function Secret Sharing
Informally, a function secret sharing (FSS) scheme [BGI15] splits a function f : I → G
into two functions f0 and f1 such that f0(x) + f1(x) = f (x) for every input x, and each
fb computationally hides f. In this work we rely on eﬃcient constructions of FSS schemes
for simple classes of functions, including multi-point functions and comparison functions.
6
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
Deﬁnition 1 (Adapted from [BGI16]). A 2-party function secret sharing (FSS) scheme
for a class of functions F = {f : I → G} with input domain I and output domain an abelian
group (G, +), is a pair of PPT algorithms FSS = (FSS.Gen, FSS.Eval) with the following
syntax:
– FSS.Gen(1λ, f ), given security parameter λ and description of a function f ∈ F, outputs
– FSS.Eval(b, Kb, x), given party index b ∈ {0, 1}, key Kb, and input x ∈ I, outputs a
a pair of keys (K0, K1);
group element yb ∈ G.
(cid:80)
Given an allowable leakage function Leak : {0, 1}∗ → {0, 1}∗, the scheme FSS should satisfy
the following requirements:
– Correctness. For any f : I → G in F and x ∈ I, we have Pr[(K0, K1) R←FSS.Gen(1λ, f ) :
– Security. For any b ∈ {0, 1}, there exists a PPT simulator Sim such that for any
polynomial-size function sequence fλ ∈ F, the distributions {(K0, K1) R←FSS.Gen(1λ, fλ) :
Kb} and {Kb
R← Sim(1λ, Leak(fλ))} are computationally indistinguishable.
b∈{0,1} FSS.Eval(b, Kb, x) = f (x)] = 1.
Unless otherwise speciﬁed, we assume that for f : I → G, the allowable leakage Leak(f )
outputs (I, G), namely a description of the input and output domains of f.
Some applications of FSS require applying the evaluation algorithm on all inputs. Given
an FSS (FSS.Gen, FSS.Eval), we denote by FSS.FullEval an algorithm which, on input a bit
b, and an evaluation key Kb, outputs a list of |I| elements of G corresponding to the
evaluation of FSS.Eval(b, Kb,·) on every input x ∈ I (in some arbitrary speciﬁed order).
While FSS.FullEval can always be realized with |I| invocations of FSS.Eval, it is typically
possible to obtain a more eﬃcient construction. Below, we recall some results from [BGI16]
on FSS schemes for useful classes of functions.
Distributed Point Functions. A distributed point function (DPF) [GI14] is an FSS
scheme for the class of point functions fα,β : {0, 1}(cid:96) → G which satisfy fα,β(α) = β, and
fα,β(x) = 0 for any x (cid:54)= α. A sequence of works [GI14, BGI15, BGI16] has led to highly
eﬃcient constructions of DPF schemes from any pseudorandom generator (PRG), which
can be implemented in practice using block ciphers such as AES.
Theorem 2 ( [BGI16]). Given a PRG G : {0, 1}λ → {0, 1}2λ+2, there exists a DPF
for point functions fα,β : {0, 1}(cid:96) → G with key size (cid:96) · (λ + 2) + λ + (cid:100)log2 |G|(cid:101) bits. For
m = (cid:100) log |G|
λ+2 (cid:101), the key generation algorithm Gen invokes G at most 2((cid:96) + m) times, the
evaluation algorithm Eval invokes G at most (cid:96) + m times, and the full evaluation algorithm
FullEval invokes G at most 2(cid:96)(1 + m) times.
Note that a naive construction of FullEval from Eval would require 2(cid:96)((cid:96)+m) invocations
of G.
FSS for Multi-Point Functions Our results crucially rely on FSS schemes for multi-
point functions, a natural generalization of point functions. A t-point function evaluates to
0 everywhere, except on t speciﬁed points. When specifying multi-point functions we often
view the domain of the function as [n] for n = 2(cid:96) instead of {0, 1}(cid:96). Formally:
Deﬁnition 3 (Multi-Point Function). An (n, t)-multi-point function over an abelian
group (G, +) is a function fS,y : [n] → G, where S = {s1,··· , st} is a subset of [n] of
size t, y = (y1,··· , yt) ∈ Gkt, and fS,y(si) = yi for any i ∈ [t], and fS,y(x) = 0 for any
x ∈ [n] \ S.
Compressing Vector OLE
7
We assume that the description of S includes the input domain [n] so that fS,y is fully
speciﬁed.
A Multi-Point Function Secret Sharing (MPFSS) is an FSS scheme for the class of
multi-point functions, where a point function fS,y is represented in a natural way. An
MPFSS can be easily obtained by adding t instances of DPF. We discuss optimizations of
this simple MPFSS construction in Section 4.
We assume that an MPFSS scheme leaks not only the input and output domains but
also the number of points t that the multi-point function speciﬁes.
2.3 Learning Parity with Noise
Our constructions rely on variants of the Learning Parity with Noise (LPN) assumption
over large ﬁelds. Unlike the LWE assumption, here the noise is assumed to have a small
Hamming weight: namely it takes a random value from the ﬁeld in a small fraction of the
coordinates and 0 elsewhere. Similar assumptions have been previously used in the context
of secure arithmetic computation [NP06, IPS09, ADI+17, DGN+17, GNN17]. Unlike most
of these works, the ﬂavors of LPN on which we rely do not require the underlying code
to have an algebraic structure and are thus not susceptible to algebraic (list-)decoding
attacks.
For a ﬁnite ﬁeld F, we denote by Berr(F) the Bernoulli distribution obtained by sampling
a uniformly random element of F with probability r, and 0 with probability 1−r. We deﬁne
below the Learning Parity with Noise assumption over a ﬁeld F.
Deﬁnition 4. Let C be a probabilistic code generation algorithm such that C(k, q, F) out-
puts (a description of) a matrix A ∈ Fk×q. For dimension k = k(λ), number of queries (or
block length) q = q(λ), and noise rate r = r(λ), the LPN(k, q, r) assumption with respect
to C states that for any polynomial-time non-uniform adversary A, it holds that
Pr[F ← A(1λ), A R← C(k, q, F), e R← Berr(F)q,
s R← Fk, b ← s · A + e : A(A, b) = 1]
≈ Pr[F ← A(1λ), A R← C(k, q, F), b R← Fq : A(A, b) = 1].
By default, we assume that C outputs a uniformly random matrix, but other distributions
of codes will be used for better eﬃciency.
Note that the decision LPN assumption, given above, can be reduced in polynomial
time to its search variant (where the attacker must ﬁnd the secret vector s). While this
reduction is not tight, in practice, no substantially better attacks are known on decision
LPN compared to search LPN. Note also that the LPN assumption is equivalent to its
dual version, which states that it is infeasible to distinguish e · B from a random vector,
where e is a noise vector and B is the parity-check matrix of the matrix A ∈ Fk×q (i.e.,
B is a full-rank matrix in Fq×(q−k) such that A · B = 0). The equivalence to LPN follows
immediately from the relation e · B = (s · A + e) · B for any s ∈ Fk. The dual variant of
LPN is also known as the syndrome decoding problem.
Attacks on the LPN Problem. In spite of its extensive use in cryptography, few crypt-
analytic results are known for the general LPN assumption. We brieﬂy outline below the
main results; we refer the reader to [EKM17] for a more comprehensive overview.
8
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
– Gaussian elimination. The most natural attack on LPN recovers s from b = s· A + e
by guessing k non-noisy coordinates of b, and inverting the corresponding subsystem
to verify whether the guess was correct. This approach recovers s in time at least
(1/(1− r))k using at least O(k/r) samples. For low-noise LPN, with noise rate 1/kc for
some constant c ≥ 1/2, this translates to a bound on attacks of O(ek1−c) time using
O(k1+c) samples.
– Information Set Decoding (ISD) [Pra62]. Breaking LPN is equivalent to solving
its dual variant, which can be interpreted as the task of decoding a random linear code
from its syndrome. The best algorithms for this task are improvements of Prange’s ISD
algorithm, which attempts to ﬁnd a size-t subset of the rows of B (the parity-check
matrix of the code) that spans e · B, where t = rq is the number of noisy coordinates.
– The BKW algorithm [BKW00]. This algorithm is a variant of Gaussian elimination
which achieves subexponential complexity even for high-noise LPN (e.g. constant noise
rate), but requires a subexponential number of samples: the attack solves LPN over F2
in time 2O(k/ log(k/r)) using 2O(k/ log(k/r)) samples.
– Combinations of the above [EKM17]. The authors of [EKM17] conducted an
extended study of the security of LPN, and described combinations and reﬁnements of
the previous three attacks (called the well-pooled Gauss attack, the hybrid attack, and
the well-pooled MMT attack). All these attacks achieve subexponential time complexity,
but require as many sample as their time complexity.
– Scaled-down BKW [Lyu05]. This algorithm is a variant of the BKW algorithm, tai-
lored to LPN with polynomially-many samples. It solves LPN in time 2O(k/ log log(k/r)),
using k1+ε samples (for any constant ε > 0) and has worse performance in time and
number of samples for larger ﬁelds.
– Low-Weight Parity Check [Zic17]. Eventually, all the previous attacks recover the
secret s. A more eﬃcient attack (by a polynomial factor) can be used if one simply
wants to distinguish b = s · A + e from random: by the singleton bound, the minimal
distance of the dual code of C is at most k + 1, hence there must be a parity-check
equation for C of weight k +1. Then, if b is random, it passes the check with probability
at most 1/|F|, whereas if b is a noisy encoding, it passes the check with probability at
least ((q − k − 1)/q)rq.
In this paper, we will rely on the LPN assumption with high dimension k, low-noise
(noise rate 1/kε for some constant ε), and a polynomially bounded number of samples
(q < k2, or even q = k + o(k)). We note that in this regime of parameters, no improvement
is known over the standard Gaussian elimination attack for the search version of LPN,
both in the asymptotic setting (BKW and the attacks of [EKM17] require a subexponential
number of samples, and the attack of [Lyu05] does not perform well on low-noise LPN),
and in the concrete setting for any reasonable parameters (according to the detailed recent
estimations of [EKM17]). For a very limited number of samples (which is the case in our
setting), variants of ISD are expected to provide relatively good results. However, they
do not perform well in our speciﬁc scenario: when the LPN instance has high dimension
and very low error rate (r(λ) → 0 when λ → ∞), according to the analysis of [TS16], all
known variants of ISD (e.g. [Pra62, Ste88, FS09, BLP11, MMT11, BJMM12, MO15]) have
essentially the same asymptotic complexity 2cw(1+o(1)) for a constant c ≈ − log(1 − k/q)
(with w = rq the number of noisy coordinates). Therefore, their gain compared to the
initial algorithm of Prange vanishes in our setting.
For the decision version of LPN, the low-weight parity check attack essentially elimi-
nates the need for solving a large linear system (which is only necessary to fully recover
the seed), hence it improves upon Gaussian elimination by polynomial factors in general.
Compressing Vector OLE
9
In the concrete instances we consider, we estimated the security of the corresponding LPN
instance using low-weight parity check, Gaussian attacks, and ISD (using the detailed
concrete eﬃciency analysis of ISD given in [HOSSV18]).
LPN-friendly codes For the purpose of optimizing the computational complexity of LPN-
based constructions, one can use a code generator C that outputs (the description of) an
encoding matrix C such that encoding is fast and yet LPN is still conjectured to hold. (For
the dual version of the construction, we need LPN to hold for the dual code.) For instance,
if C is a random Toeplitz matrix, encoding can be done in quasi-linear time but no better
attacks on LPN are known compared to a random choice of C. There are in fact candidates
for asymptotically good LPN-friendly codes that can be encoded by linear-size circuits over
F [DI14,ADI+17]. Finally, since we do not require the code to have good minimal distance
or support fast erasure-decoding, there is a big space of heuristic LPN-friendly encoding
procedures whose systematic exploration remains for further study.
3 Pseudorandom VOLE Generator
In this section, we formally deﬁne our main notion of a pseudorandom VOLE generator (or
VOLE generator for short), and provide two constructions that are dual to each other (in a
sense that will be made formal). These constructions form the core technical contribution
of our paper.
3.1 Deﬁning VOLE Generator
Informally, a VOLE generator allows stretching a pair of short, correlated seeds into a
long (pseudo)random VOLE, by locally applying a deterministic function Expand to the
seeds. Deﬁning the security notion for this primitive requires some care. Ideally, we would
have liked to require that the protocol in which a trusted dealer distributes the seeds
and the parties output the result of applying Expand to be a secure realization of the
VOLE correlation according to the standard real vs. ideal paradigm for deﬁning secure
computation. However, as pointed out in [GI99], this security notion cannot be achieved in
general. Intuitively, this stems from the fact that each party holds a short representation
of its correlated string. For instance, consider a very simple correlation, where both parties
should obtain the same long pseudorandom string. Then any generator for this correlation
will reveal to the ﬁrst party a short representation of the string of the other party, which
cannot happen in an ideal implementation.
To overcome this issue, we rely on an alternative security notion, which roughly asserts
the following. Consider the real-world experiment of distributing the two seeds and locally
expanding them. We require that the seed seedσ observed by party σ together with the
expanded second output Expand(seed1−σ) are indistinguishable from seedσ together with a
random output of party 1− σ conditioned on Expand(seedσ) in a perfect VOLE correlation.
We prove that this notion suﬃces for securely instantiating the standard protocol for
computing a chosen-input VOLE from a random VOLE (see Section 6.1), and is hence
suﬃcient for the applications we consider.
We allow the setup algorithm of the VOLE generator to ﬁx the receiver’s input x rather
than choose it at random. This stronger ﬂavor of VOLE generator, which is needed by some
of the applications, is formalized below.
Deﬁnition 5 (Pseudorandom VOLE generator). A pseudorandom VOLE generator is
a pair of algorithms (Setup, Expand) with the following syntax:
10
Elette Boyle, Geoﬀroy Couteau, Niv Gilboa, and Yuval Ishai
– Setup(1λ, F, n, x) is a PPT algorithm that given a security parameter λ, ﬁeld F, output
length n, and scalar x ∈ F outputs a pair of seeds (seed0, seed1), where seed1 includes
x;
– Expand(σ, seedσ) is a polynomial-time algorithm that given party index σ ∈ {0, 1} and
a seed seedσ, outputs a pair (u, v) ∈ Fn × Fn if σ = 0, or a vector w ∈ Fn if σ = 1;
The algorithms (Setup, Expand) should satisfy the following:
– Correctness. For any ﬁeld F and x ∈ F, for any pair (seed0, seed1) in the image
of Setup(1λ, F, n, x) (for some n), denoting (u, v) ← Expand(0, seed0), and w ←
Expand(1, seed1), it holds that ux + v = w.
– Security. For any (stateful, nonuniform) polynomial-time adversary A, it holds that
(cid:21)
(cid:21)
: A(seed0) = 1
: A(seed0) = 1
.
 .
: A(u, v, seed1) = 1
: A(u, v, seed1) = 1
Similarly, for any (stateful, nonuniform) adversary A, it holds that
≈ Pr