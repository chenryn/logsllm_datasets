d
n
o
c
e
S
160
140
120
100
80
60
40
20
0
8
7
6
5
4
3
2
1
0
FacesperUIDusedastraining
SolvedSApages(outof7-min.5topass)
Figure 4: Percentage of successfully-passed tests as a function
of the size of the training set. For each iteration, 30 randomly-
generated ofﬂine SA tests were used.
Figure 5: Time required to lookup photos from SA tests in the
face recognition system.
4.1 Overall Dataset
Our dataset contains data about real Facebook users, including
their UIDs, photos, tags, and friendship relationships, as summa-
rized in Table 1. Through public crawling we collected data re-
garding 236,752 distinct Facebook users. 71% (167,359) of them
have at least one publicly-accessible album. We refer to these users
as public UIDs (or public users). The remaining 29% of UIDS
(69,393) keep their albums private (i.e., private UIDs, or private
users). We found that 38% of them (26,232 or 11% of the total
users) are still reachable because their friends have tagged them in
one of the photos in their own proﬁle (to which we have access).
We refer to these UIDs as semi-public UIDs (or semi-public users).
Data about the remaining 62% of UIDs (43,161 or 18% of the to-
tal users) is not obtainable because these users keep their albums
private, and their faces are not found in any of the public photos of
their friends. The public UIDs lead us to 805,930 public albums, to-
taling 16,141,426 photos and 2,107,032 tags that point to 1,877,726
distinct UIDs. It is therefore evident that people exposing (or mak-
ing otherwise available) their photos are not only revealing infor-
mation about themselves but also about their friends. This presents
a subtle threat against these friends who cannot control the leakage
of their names and faces. Albeit this dataset only covers a very
small portion of the immense Facebook user base, we consider it
adequate enough to carry out thorough evaluation experiments.
4.2 Breaking SA: Determined Attacker
The following experiment provides insight concerning the num-
ber of faces per user needed to train a classiﬁer to successfully
solve the SA tests. We create simulated SA tests using the fol-
lowing methodology. We train our system using a training set
of K = 10, 20, . . . , 120 faces per UID. We extract the faces auto-
matically, without manual intervention, using face detection as de-
scribed in §3.1.3. We then generate 30 SA tests. Each test contains
3 target photos per 7 pages showing the face of the same victim.
The photos are selected randomly from the pool of public photos
we have for each person, from which we exclude the ones used
for the training. For each page and K we record the output of the
name-lookup step (step 4), that is the prediction of the classiﬁer as
described in §3.1.4, and the CPU-time required. Fig. 4 shows the
9On 11 April 2012, our crawler had collected 2,107,032 of such
tags, although the crawler’s queue contains 7,714,548 distinct tags.
7
6
5
4
3
2
1
0
)
s
s
a
p
o
t
5
.
n
i
m
-
7
f
o
t
u
o
(
s
e
g
a
p
A
S
d
e
v
l
o
S
Fullsolution
Solutionaid
0 5
0
1
5
1
0
2
5
2
0
3
5
3
0
4
5
4
0
5
5
5
0
6
5
6
0
7
5
7
0
8
5
8
0
9
5
9
0
0
1
5
0
1
0
1
1
5
1
1
0
2
1
5
2
1
0
3
1
ActualFacebookSAtests
Figure 6: Efﬁciency of automated SA breaker against actual
Facebook tests.
number of pages solved correctly out of 7, and Fig. 5 shows the
CPU-time required to solve the full test (7 pages).
For an SA test to be solved successfully, Facebook requires that
5 out of 7 challenges are solved correctly. Our results show that our
attack is always successful (i.e., at least 5 pages solved over 7) on
average, even when a scarce number of faces is available. Clearly,
having an ample training dataset such as K > 100 ensures a more
robust outcome (i.e., 7 pages solved over 7). Thus, our attack is
very accurate. As summarized in Fig. 5, our attack is also efﬁcient
because the time required for both “on the ﬂy” training—on the
K faces of the 6 suggested users—and testing remains within the
5-minute timeout imposed by Facebook to solve a SA test. An at-
tacker may choose to implement the training phase ofﬂine using
faces of all the victim’s friends. This choice would be mandatory
if Facebook—or any other Web site employing SA—decided to in-
crease the number of suggested names, or remove them completely,
such that “on the ﬂy” training becomes too expensive.
4.3 Breaking SA: Casual Attacker
In the following experiment we assume the role of a casual at-
tacker, with signiﬁcantly more limited access to tag data for the
training of a face recognition system. At the same time we attempt
to solve real Facebook SA tests using the following methodology.
405
We have created 11 dummy accounts that play the role of victims
and populate them with actual Facebook users as friends and ac-
tivity. Then, we employ a graphical Web browser scripted via Sele-
nium6 to log into these accounts in an automated fashion. To trigger
the SA mechanism we employ Tor7 which allows us to take advan-
tage of the geographic dispersion of its exit nodes, thus appearing
to be logging in from remote location in a very short time. By pe-
riodically selecting a different exit node, as well as modifying our
user-agent identiﬁer, we can arbitrarily trigger the SA mechanism.
Once we are presented with an SA test, we iterate its pages and
download the presented photos and suggested names, essentially
taking a snapshot of the test for our experiments. We are then able
to take the same test ofﬂine as many times necessary. Note that this
is done for evaluation purposes and that the same system in produc-
tion would take the test once and online. Overall, we collected 127
distinct SA tests.
We tried breaking the real SA tests using our module for face.
com described in §3.2. Fig. 6 presents the outcome of the tests.
Overall we are able to solve 22% of the tests (28/127) with people
recognized in 5–7 of the 7 test pages and signiﬁcantly improve the
power of an attacker for 56% of the tests (71/127) where people
were recognized in 3–4 of the 7 test pages. At the same time, it
took 44 seconds on average with a standard deviation of 4 seconds
to process the photos for a complete test (21 photos). Note that the
time allowed by Facebook is 300 seconds.
We further analyzed the photos from the pages of the SA tests
In about 25%
that failed to produce any recognized individual.
of the photos face.com was unable to detect a human face. We
manually inspected these photos and conﬁrmed that either a human
was shown without his face being clearly visible or no human was
present at all. We argue that humans will also have a hard time
recognizing these individuals unless they are very close to them so
that they can identify them by their clothes, posture or the event.
Moreover, in 50% of the photos face.com was able to detect a hu-
man face but marked it as unrecognizable. This indicates that it is
either a poor quality photo (e.g., low light conditions, blurred) or
the subject is wearing sunglasses or is turned away from the cam-
era. Finally, in the last 25% of the photos a face was detected but
did not match any of the faces in our training set.
Overall, the accuracy of our automated SA breaker signiﬁcantly
aids an attacker in possession of a victim’s password. A total stranger,
the threat assumed by Facebook, would have to guess the correct
individual for at least 5 of the 7 pages with 6 options per page to
choose from. Therefore, the probability 8 of successfully solving
−4), assuming photos
an SA test with no other information is O(10
of the same user do not appear in different pages during the test. At
the same time, we have managed to solve SA tests without guess-
ing, using our system, in more than 22% of the tests and reduce the
need to guess to only 1–2 (of the 5) pages for 56% of the tests, thus
−2) to solve those SA tests
having a probability of O(10
correctly. Overall in 78% of the real social authentication tests pre-
sented by Facebook we managed to either defeat the tests or offer
a signiﬁcant advantage in solving them.
−1) to O(10
After these experiments, we deleted all the photos collected from
the real SA tests, as they could potentially belong to private albums
of our accounts’ friends, not publicly accessible otherwise.
6http://seleniumhq.org
7http://www.torproject.org
8Calculated using the binomial probability formula used to ﬁnd
probabilities for a series of Bernoulli trials.
5. ETHICAL CONSIDERATIONS
In this paper we explore the feasibility of automated attacks against
the SA mechanism deployed by Facebook. As our experiments in-
volve actual users, the question of whether this is ethically justiﬁ-
able arises. We believe that research that involves the systematic
exploration of real attacks is crucial, as it can reveal weaknesses
and vulnerabilities in deployed systems, and provide valuable in-
sight that can lead better solutions. This opinion is also shared
among other security researchers [5, 16].
Nonetheless, we designed our experiments such that we mini-
mize the impact of our research and preserve the privacy of these
users. First, we never retained verbatim copies of sensitive infor-
mation, besides the photos that we clearly needed for running the
experiments. Secondly, our attack can optionally issue friend re-
quests with the purpose of expanding the number of accessible pho-
tos. However, we issued friendship requests exclusively to reach
the 50-friends threshold, required by Facebook to trigger the SA
mechanism. We never took advantage of accepted requests to col-
lect photos or other private information otherwise unavailable; we
solely collected public photos. In particular, in §4.2 we simulated a
determined attacker, by assuming he has obtained access to all the
photos (both public and private) needed to launch the attacker un-
der ideal conditions. We simulated these conditions using publicly-
available photos.