(4)spawn(O)
x.x.x.x:80
x.x.x.x:80
(1)read(I)
(1)read(I)
(5)read(I)
ls
ﬁrefox
(2)spawn(O)
(3)write(O)
(8)delete(D)
(6)write(O)
backdoor
x.so
stdout
.permission
(7)delete(D)
ﬁrefox
ﬁrefox
(3)delete(D)
(2)delete(D)
...
(2)create(O)
...
.permission
.permission
(a)
(b)
(c)
Figure 3: Causal graph examples. Ovals, diamonds and boxes represent processes, sockets and ﬁles, respectively. Edges denote events, annotated
with numbers representing their order in the audit log, event names and types (i.e., I for input, O for output, and D for dead-end). The shaded shapes
represent those no longer live at the GC time. Events in light blue denote those garbage-collected following Algorithm 1.
is a special ﬁle such that the “output-to-stdout” event at step (6) is
considered a dead-end event (Table 1) and hence garbage-collected.
We cannot simply keep all dead-end events. Intuitively, keeping
a dead-end event means that it may be of importance for foren-
sic analysis. As such, events that may have led to the event must
also be important. In other words, we cannot garbage-collect the
input events preceding the dead-end event. Consider the example
in Fig. 3 (b). It shows another hypothetical scenario in which (1)
firefox visited a malicious web site and was exploited and (2)
the infected firefox removed an important ﬁle .permission
as part of the malicious payload. Suppose firefox has been ter-
minated when GC is performed. If we keep the dead-end event 2,
we need to keep the preceding input event 1 in order to understand
its cause. However, if we were to keep all dead-end events and their
preceding input events, garbage collection would not be effective at
all.
One observation is that we do not need to consider all kinds of
dead-end events as not all of them are of interest to forensic anal-
ysis. In particular, only those that cause destructive effects on the
system are of interest, such as ﬁle removal and process termination.
We call these events destruction events, such as the ones annotated
with ‘*’ in Table 1.
Log
Accessed Files
Deleted Files
User1
User2
User3
User4
User5
Total
14,909
2,373
2,991
7,611
2,988
30,872
Total
11,981 (80.36%)
1,211 (51.03%)
2,046 (68.41%)
4,902 (64.41%)
1,416 (47.39%)
21,556 (69.82%)
Temp Files
10,118 (84.45%)
1,197 (98.92%)
1,985 (97.02%)
2,610 (53.24%)
1,401 (98.94%)
17,311 (80.31%)
Table 2: Number of deleted ﬁles and temporary ﬁles
Unfortunately, considering destruction events only is still too ex-
pensive as many programs generate and delete a large number of
ﬁles in their life time. Note that since a ﬁle deletion is a destruc-
tion event, it prevents us from garbage-collecting all the preced-
ing input events. Fig. 3 (c) shows a typical execution pattern in
firefox: it involves creating and removing a large number of
ﬁles. These ﬁles are used to save/cache pages temporarily. They
will be deleted when firefox is closed. In this scenario, if we
retain all ﬁle deletions, there would not be many events that can be
garbage-collected.
In Table 2, we have collected and analyzed ﬁve different audit
logs from machines of different users with different settings (de-
tailed settings in Section 6). Each log corresponds to one day’s
execution. The table shows the number of accessed ﬁles in each ex-
ecution (column two) and the number of ﬁles that are deleted (col-
umn three). Observe that most of the accessed ﬁles are deleted. If
we retain such deletions, the saving from garbage collection would
be small.
Fortunately, another observation comes to the rescue: Most of
the deleted ﬁles are temporary ﬁles. A temporary ﬁle is deﬁned as a
ﬁle whose entire life time belongs exclusively to a single process. In
other words, a temporary ﬁle is only accessed (created/read/written/
deleted) by a single process. Besides web browsers, document
viewer applications and compilers also use temporary ﬁles very of-
ten. As shown in the fourth column, 80.31% deleted ﬁles are tem-
porary ﬁles. Such deletions have little forensic value and hence can
be garbage-collected, which will transitively provide other garbage
collection opportunities.
Hence, our ﬁnal solution that supports forward attack analysis is
as follows. Upon a dead-end event, we check if it is a destruction
event. If not, it will be garbage-collected. Otherwise, we will fur-
ther determine if it is a ﬁle deletion event. If so, it will be retained
and its process is set reachable, except when it is a temporary ﬁle
deletion, which will be garbage-collected. We perform a forward
preprocessing to identify all temporary ﬁles before each GC proce-
dure. When we retain a destruction event, we do not set the object
being destroyed reachable, because the content of the object is not
important but rather the deletion action itself is. As such, the pre-
ceding outputs to the object are still eligible for garbage collection.
One possible concern is that the attacker may exploit an appli-
cation in such a way that the compromised application downloads
a malicious library ﬁle, executes it and ﬁnally removes it. Since
all these events occur within the same process, according to our
policy, we consider the malicious library a temporary ﬁle and may
garbage-collect its history. In this case, if the malicious library has
ever affected or changed the system, such as changing other ﬁles
or sending packets, its events will be marked as reachable by our
traversal algorithm and thus retained. Otherwise, the event will
never appear in any causal graph even though it is the deletion of a
malicious library ﬁle. Therefore, it is safe to remove the event.
4. PROVENANCE TRACING WITH FINER
GRANULARITY
In the basic design, attack provenance tracing is conducted at the
system level, meaning that audit log entries are events captured by
the OS. This is also the default setting of the Linux audit system.
However, we observe that system-level tracing is overly coarse-
grained, which substantially limits the effectiveness of audit log
GC. In particular, the following two problems are dominant.
First, since we cannot afford tracing instruction level depen-
dences in practice, we have to conservatively assume that an event
is dependent on all preceding input events involving the same pro-
10081  read(I)
3 (I)
6 (I)
8 (I)
11 (I)
1  read(I)
3 (I)
6 (I)
8 (I)
11 (I)
2  read(I)
4 (I)
5 (I)
7 (O)
10 (O)
12 (O)
9 (O)
13 (O)
Unit1
U2 U3
U4
2  read(I)
4 (I)
5 (I)
7 (O)
10 (O)
12 (O)
9 (O)
13 (O)
Figure 4: Partitioning a process execution into units. Event names may be omitted if inferable from context.
cess. Consequently, during garbage collection, if an event of a pro-
cess becomes reachable, meaning that it may directly/transitively
affect live processes or objects, the process becomes reachable,
making all the preceding input events of the process reachable. It
further implies that the objects operated in those events will also be-
come reachable. This is particularly problematic for long running
processes.
Consider a sample execution of firefox in Fig. 4. It accessed a
number of URLs with different IP addresses, read and wrote a num-
ber of ﬁles, and spawned two processes. At the time of garbage col-
lection, the process has terminated and many of the ﬁles accessed
are also removed. The child process p1 and ﬁle f5 are still alive.
Following the basic GC algorithm, live ﬁle f5 makes firefox
process reachable when the backward traversal reaches event 12,
preventing garbage-collection of any input event before that. Con-
sequently, only events 7, 10, and 13 are removed. In practice, audit
logs are dominated by event entries from long running processes
that may run for hours or even days.
Second, treating a ﬁle as a single object such that any read of the
ﬁle is considered dependent on all preceding writes is too coarse-
grained for some applications, especially those that need to repeat-
edly read/write to a ﬁle. For example, mysql creates an index ﬁle
and a data ﬁle for each table. Upon receiving a query, mysql usu-
ally ﬁrst reads the index ﬁle to ﬁnd the location of a tuple (in the
data ﬁle) given the tuple id. Then it reads the tuple from the data
ﬁle and sends it back to the user. The index and data ﬁles need to
be frequently updated. They also stay alive as long as the table is
alive. According to our basic GC strategy, none of the reads/writes
to these ﬁles can be garbage-collected.
Fig. 5 (a) shows three SQL queries executed by three mysql
processes. In the ﬁrst update query, mysql ﬁrst reads the index
ﬁle, which stores ids and locations of tuples in a B-Tree as shown
in the ﬁgure. The corresponding table is shown in the data ﬁle. In
this case, mysql ﬁrst reads the root node in the index ﬁle which is
the requested node (id=3) and ﬁnds the location of the tuple (event
1). Then it updates both the index ﬁle and the data ﬁle. In the sec-
ond select query, mysql ﬁrst reads the root node from the index
ﬁle (event 4), which does not satisfy the where clause. It then fur-
ther reads the child node in the index ﬁle (event 5), which satisﬁes
the clause. Then mysql reads the data ﬁle to get the tuple (event 6)
and returns it (event 7). In the third delete query, mysql reads in-
dividual tuples from the data ﬁle (events 8 and 10) and then checks
them against the where condition. If the condition is satisﬁed, tu-
ple deletion is performed by updating the index ﬁle (events 9 and
11).
According to Algorithm 1, since both the data and index ﬁles are
alive, none of the writes to them can be garbage-collected, making
the preceding reads non-garbage-collectable. Consequently, none
of the events can be removed. Note that a simple idea that uses
ﬁle offsets [23] to detect more precise dependences does not work
here because mysql tends to read many input tuples to memory to
process a query, but only a (possibly small) subset of them are used
in computing the result tuples (e.g., the delete query in the previous
example).
We have conducted an experiment in which we applied the ba-
sic GC algorithm to audit logs of firefox and mysql. Our re-
sults show that only 0.07% and 0.0004% of them can be garbage-
collected, respectively. And the log entries from mysql can be as
large as 90.68% of the overall audit log in a server system.
4.1 Dividing Process into Execution Units
To overcome the ﬁrst problem discussed earlier in this section
(i.e., treating a process as a single subject), we adopt our earlier so-
lution called BEEP [20] by dividing a process into execution units.
The basic idea is that the execution of a long running program is
dominated by event handling loops. According to our study of over
100 applications [20], event handling loops are present in most of
those applications and each loop iteration can be considered as a
logical execution unit that handles an individual external request.
Hence, instead of considering an event dependent on all preceding
input events in the life time of an entire process, BEEP considers
that it is only dependent on the preceding input events in the same
unit.
Consider the example in Fig. 4 (b). The execution of firefox
in (a) is divided into four units corresponding to four event handling
loop iterations, each accessing an individual URL. As such, events
1-6 can be garbage-collected. This is because the reachable output
events 12 and 9 only cause the input events in their units (i.e., u4
and u3) to be marked as reachable. Note that the history of live
objects, i.e., process p1 and ﬁle f5, is correctly preserved.
We adapt the binary proﬁling technique in BEEP to identify event
handling loops in a binary program. Loop entries and exits are in-
strumented to emit special system events that serve as unit delim-
iters. We also identify workﬂows between units that may introduce
cross-unit dependences. Details can be found in [20]. Since these
are not our contribution, details are elided.
4.2 Dividing File into Data Units
To address the second problem (i.e., treating a ﬁle as a single
object), we propose to divide a ﬁle into data units such that depen-
dences can be deﬁned with respect to the smaller data units.
Consider the example in Fig. 5 (b). The data ﬁle is divided into
units with each unit being a tuple. Furthermore, since index ﬁles
are completely internal to mysql, reads and writes on them are
of no forensic interest and hence removed. We are now able to
garbage-collect all events except 6 and 7. Observe that with the
ﬁner granularity, we can claim that tuple 3 is not reachable hence
event 3 can be garbage-collected.
However, dividing ﬁles into data units is highly challenging. One
may have to have knowledge about the internal structure of a ﬁle.
Also, one has to identify all operations on data units. When an
1009update T set val=11 where id=3
select * from T where id=2
delete from T where val>8
update T … 
select * from T … 
7 (O)
7 (O)
delete from T … 
3 (O)
1 read(I)
2 write(O)
4 (I)
5 (I)
6 (I)
8 (I)
9 (O)
10 (I)
10 (I)
…………
11 (O)
1 read(I)
2 write(O)
3 (O)
4 (I)
5 (I)
6 (I)
8 (I)
9 (O)
…………
11 (O)
10 (I)
Figure 5: Partitioning data ﬁles into units improves garbage collection.
operation is performed, the speciﬁc units being operated on need to
be ﬁgured out. For instance, mysql has 1.2M lines of code. It is
prohibitively difﬁcult for a non-mysql developer to identify such
information manually. Instruction-level tracing may determine data
provenance precisely down to the byte level. However, it is too
expensive to be useful for production systems.
Solution Overview. Our solution is to leverage a proﬁler to iden-
tify and instrument a small number of places in the application pro-
gram such that special system events will be emitted by our instru-
mentation to disclose the provenance of data units. Take mysql
as an example, given a query, the result tuples are computed from
some input tuples that may come from multiple tables. We identify
the code locations that exclusively access those input tuples used in
computing the result tuples and instrument the code to emit the ids
of the input tuples to the audit log. When an output tuple is written
to disk, we also emit a write event tagged with its tuple id. Since
all such events occur within the execution unit handling a single
query, by following the default strategy that considers an output
event (i.e., tuple write) as dependent on all preceding input events
(i.e., input tuple reads), we can correctly determine the tuple-level
dependences and allow more garbage collection.
Consider the example in Fig. 6 (a). It shows a piece of pseudo-
code1 that models the procedure that mysql handles the query on
top of the ﬁgure, which performs a join query between tables t1
and t2 and writes the result table to t3. Mysql ﬁrst loads all the
tuples of t1 and stores them to the cache. It then loads individ-
ual tuples of t2 and compares their value ﬁelds with those in the
cache.
If there is a matching pair, the corresponding data ﬁelds
are extracted (lines 12-14) and used to compose the result tuple.
Finally, the result tuple is written at line 18.
With our solution, we will identify and instrument lines 12 and
13 for input tuples. Particularly, we will add a special system call
after line 12 to emit the tuple id of t1 and another one after line
13 to emit the tuple id of t2. According to the semantics of the
code snippet, since lines 12 and 13 are within the true branch of
the comparison at line 11, the tuples represented by the two lines
must be the input tuples used to compute the output tuple. The
result tuple composition at line 17 is also instrumented to emit the
output tuple id. As such, we can associate the output tuple with the
corresponding input tuples via the default audit log analysis.
In the following, we explain our techniques to identify those in-
strumentation points. Our discussion will be mainly focused on
mysql as it is the core database engine for many web service ap-
plications.
1The real code is too complex to present and explain with limited
space.
Deﬁnitions:
Pv[&x] - the provenance of a variable x, which is a set of
input tuple ids.
pc: op (y1, ..., yn) - an instruction at pc that has op as the
opcode and y1,..., yn the operand variables.
S[pc] - aggregated provenance set for the instruction at pc.
Instruction
id=readRecord(“t”,&bu f ,&s...)
Action
for (i=0 to s-1)
pc: x=op (y1,...,yn)
Pv[bu f + i]={ id}
Pv[&x]= Pv[&y1] ∪ ...∪ Pv[&yn]
S[pc]=S[pc] ∪ Pv[&x]
Table 3: Instruction-level provenance proﬁler
Algorithm 2 Identifying instrumentation points for input tuples
1: execute mysql on a given query with the provenance proﬁler
2: Let “pc: writeRecord(...,out_bu f ,s...)” be the instruction emitting the
output tuple
3: pv←Pv[out_bu f ]∪...∪Pv[out_bu f + s − 1]
4: R← {}
5: for each executed instruction i do
6:
l ← the program counter of i
7:
if S[l]⊂ pv and all tuples in S[l] belong to one table then
8:
9: return the minimum subset(s) of R whose provenance covers pv
R← R ∪ {l}