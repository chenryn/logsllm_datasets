(c) Logitech C910 webcam positioned on top
of a 20“ Soyo screen.
(operated by touch or mouse) are offered by all mainstream
operating systems, and also used by some websites as a
security mechanism for password entry, reducing the threat
of keyloggers.5 Using an on-screen keyboard also protects
against attackers with acoustic probes that try to characterize
individual key acoustic emanations [3], [35], [51]. We show,
however, that the pressed on-screen keys can be inferred from
the screen’s acoustic emanations.
A. Machine learning attack methodology
Our attack works in two stages: ﬁrst, in an off-line stage,
the attacker collects training data (audio traces) to characterize
the acoustic emanations of a given type of screen, and uses
machine-learning to train a model that distinguishes the screen
content of interest (e.g., websites, text, or keystrokes). In the
on-line stage, the attacker records an audio trace of the actual
screen under attack (whether in person or remotely), and then
uses the trained model to deduce the on-screen content.
Why machine learning?
The algorithm in Section II-D
produces relatively clean output traces, where sample values
are clearly dependent on the screen’s content.
The correspondence between pixel intensities and sample
values is intricate and difﬁcult to accurately model. It even
seems to vary within a refresh period, with different time spans
within the period presenting slightly different relationships
between signal amplitude and pixel
intensities. Moreover,
although we produce relatively clean output traces, they do
contain noise. Two output traces of recordings of the same
screen content will not be entirely the same.
5On-screen keyboards resist keyboard logging by malware (unless the
malware is adapted to log screen content), and also low-level keyboard device
snooping, e.g., by leaky USB hubs [45].
Fig. III.4: (Left) alternating Zebra patterns displayed on a Dell
2208WFPt monitor, recorded by a Google Home device and
archived on Google’s cloud. (Right) the spectrogram of the
recorded signal. Note the frequency axis ends at 8 kHz, since
Google’s archived recordings play at 16 kHz sample rate.
mode to recognize and response to commands. An audio
recording of the interaction, including the wake phrase utter-
ance, is then archived in cloud servers (“to learn your voice
and how you speak to improve the accuracy of the results
provided to you and to improve our services” [47]).
We set out to ascertain that the screen’s visual content
is indeed acoustically captured and subsequently uploaded
to Google’s and Amazon’s cloud servers. First, we placed
a Google Home device next
to a Dell 2208WFPt screen
displaying alternating Zebra patterns. We then woke the device
up by using its wake phrase (“Hey Google”) and kept the the
recording running during the Zebra alternations. Finally, we
retrieved the recorded audio from Google’s servers. Figure III.4
shows the spectrogram representation of the retrieved audio,
where the alternation of Zebra patterns is clearly visible.
We proceeded to perform the exact same procedure with an
Amazon Echo (2nd Gen.), and observed similar results.
IV. ON-SCREEN KEYBOARD SNOOPING
In this attack,
the attacker aims to extract words or
sentences from an on-screen keyboard. On-screen keyboards
861
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
Neural networks, and speciﬁcally convolutional neural net-
works (CNNs) [50], are very good at inferring such intricate
dependencies in time series data, even in the presence of
noise [42]. In many cases, when CNNs are conﬁgured cor-
rectly, we can expect them to be able to directly perform the
processing task at hand, especially for supervised learning and
where enough data is at hand.
Using classiﬁers. We employ a CNN-based architecture for
solving our task. We deﬁne, train, and use CNN classiﬁers:
a classiﬁer’s input is a sample, represented (in our case) as a
time-series vector. Speciﬁcally, our classiﬁer inputs will be the
outputs of the signal processing procedure in Section II-D. A
classiﬁer’s output is a vector of probabilities, one for each
class. A sample’s prediction is the class with the highest
assigned probability. Before the classiﬁer can produce mean-
ingful output, it has to be trained. The training procedure feeds
the classiﬁer with sample traces and correct predictions.
Simpler ML architectures. We ﬁne-tuned neural networks
for speed and accuracy. Alternatively, our traces (after signal
processing) are often clean enough to train a rudimentary
logistic regression model (at the cost of much slower train-
ing, due to slow convergence). For the lower-frequency non-
modulated signals acquired through VoIP and used without
trace averaging (Section VI-B), the rudimentary model attains
low accuracy, but a carefully tuned CNN is effective.
B. Attack simulation and results
We simulated this attack in the smartphone and close-
range attack vectors. We assume the on-screen keyboard is
sufﬁciently large, depending on screen attributes.
Data collection and preprocessing. We captured audio
recordings of a Soyo 20” DYLM2086 in the close-range and
smart phone settings (Section III-A and III-B, while displaying
screen shots of the mouse pressing varying keys. We used the
native Ubuntu on-screen keyboard with a phone-style layout,
“High Contrast” theme and size 700x900. We used portrait
screen layout (see discussion below on screen layouts).
For each attack vector, we iterated 100 times over the 26
letters of the alphabet. To reliably simulate the acoustic leakage
during hundreds of key-presses on the on-screen keyboard
required for training, we used screenshots containing the on-
screen keyboard with the respective key being pressed. In each
iteration, for each key, we collected a 0.5 s long trace when
key is pressed (simulated by the screen shot). We split these
traces to train (90%) and validation (10%) sets. 6
For testing our snooping attack, we also recorded audio
while words are typed on the virtual keyboard. Words were
chosen randomly from from a list of the most common 1000
English words [39] (see results). We use the traces of 50 such
words for testing both classiﬁers. Characters of the words were
typed consecutively, with 3 s between each transition. We also
experiment with words recorded at 1 s speed (see results).
We applied our signal processing procedure in Section II-D.
Training procedure.
Trace processing and training was
performed on an Intel(R) Xeon(R) CPU E5-2609 v4 processor
with two Titan X GPUs. We uses the Keras Python library
6Here and in Section V, we use just 10% of the initial recordings for
validation. In both, validation sets are still in the hundreds, and we record
an additional trace set, 100% of which was used for testing.
with a Tensorﬂow backend to program and train the networks.
Keras is used with a Tensorﬂow 1.4 backend and CUDA 8.0,
CUDNN 6.0. We defer the details of the neural network’s
architecture and hyperparameters to Appendix B1.
Each on-keyboard keystroke results in a speciﬁc image
displayed on the screen. We can train a classiﬁer to identify
the different characters for a given trace. Some pairs of keys
are completely horizontally aligned on this virtual keyboard.
We expect keys in such pairs to be less easily distinguishable
from the signal (see below discussion about screen layouts),
and group each such pair into one class label. Our labels were
thus ‘b’, ‘c’, ‘m’, ‘n’, ‘p’, ‘v’, ‘x’, ‘z’, ‘aq’, ‘sw’, ‘de’, ‘fr’,
‘gt’, ‘hy’, ‘ju’, ‘ki’, ‘lo’, and space.
Testing procedure.
To process a trace, we shift a 0.5 s
window across the duration of the trace. The window offset is
advanced in 3200 sample (1/60 s) intervals. For each offset,
we apply our processing algorithm on the sub-trace contained
in the window. We then apply our classiﬁer.
This process outputs an array of class labels of size
60 · l − 30, where l is the original trace length. We traverse
it from start to ﬁnish, outputting class labels appearing more
than 15 times contiguously for the smart phone attack and 35
times contiguously for the close-range attack. Assuming the
CNN always predicts the right class, this produces sequences
of class labels that correspond to the letters typed on the
screen. However, these sequences do not distinguish (1) letters
grouped into the same class, and (2) letters in the same class
that were typed sequentially. For example, for a trace of the
word “love”, the sequence [’lo’, ‘v’, ‘de’] will be produced.
The ‘l’ and ‘o’ keys are grouped into the same class, and there
is only one instance of this class label. Similarly, the expected
trace of the word “screen” is [’sw’, ‘c’, ‘fr’, ‘de’, ‘n’].
To disambiguate each produced trace, we go over the
102000 words in the dictionary. For each, we compute its
expected trace, and check it against the trace. We return the
list of words that matched the trace, or the prediction list.
Results. Our classiﬁer reaches 100% accuracy on the vali-
dation set, for both the smartphone and close-range. For the
close range attack’s word traces, the correct word was always
contained in our prediction list. The size of the prediction list
varied from 2 to 23 with an average of 9.8 words per trace.
For the smartphone attack, the correct word was contained in
the prediction list for 49 out of 50 traces.
To further test the limits of this attack, we repeated the
attack using a different screen, Soyo 22" (model DYLM2248),
in the close-range setting. Again, the validation set accuracy
was 100%. This time, we collected traces of 100 additional
words, twice: once while waiting 3 seconds between each
transition, and once when waiting 1 second. For the 3 s
collection, the correct word was in the prediction list 94 times
out of 100. For the 1 s recordings, the correct word was in the
prediction list 90 times. The average candidate list size was 8.
Portrait vs. landscape layout. A pressed key’s color changes
from white to black; we expect this to affect the amplitude of
the signal emitted while the corresponding black pixels are
rendered. Pixels are rendered in a raster pattern, i.e., line by
line. Because of that, keys that are horizontally aligned, and
span the same pixel lines, are rendered during very similar
times in every refresh period. We therefore expect that pressing
horizontally-aligned keys will induce very similar, temporally-
862
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:34 UTC from IEEE Xplore.  Restrictions apply. 
close effects in the leakage signal. Conversely, keys positioned
in completely different pixel-lines will be rendered during very
different times, and the corresponding amplitude changes will
be more distinguishable.
For this reason, in this section, we ﬁrst built a classiﬁer that
only distinguishes between non-aligned keys, and test it on a
portrait layout where far fewer keys are horizontally aligned.
To ascertain whether horizontally-aligned keys can be at all
distinguished, we repeated data collection using the Soyo 22"
in landscape layout. We trained the classiﬁer on both landscape
and portrait datasets, but without grouping horizontally aligned
keys. The portrait layout classiﬁer reaches 96.4%, and the
landscape layout classiﬁer reaches 40.8%. Top-3 accuracies
are much higher: 99.6% and 71.9%. We conclude that even
changes within pixel lines, where pixels are rendered at very
small temporal offsets from each other, can still be distinguish-
able in the signal. Moreover, that on-screen keyboards remain
vulnerable even in landscape layouts.
Cross-screen results. We veriﬁed that the attacker’s training
can be done on a different screen than the victim’s. To this
end, we used a smartphone to collect about 130 recordings,
0.5 s each, for each key on a Dell 2208WFPt screen in portrait
layout. We then switched to a different 2208WFPt instance,
and collected 10 traces, 0.5 s each, per key. We followed the
same preprocessing procedure as above, and assigned classes
to traces, again grouping horizontally-aligned keys. We then
trained our classiﬁer using the traces from the ﬁrst screen
and tested it on the traces of the second screen. The resulting
accuracy is 99.0%. For comparison, this classiﬁer had a 99.4%
accuracy on a similar-sized validation set of traces of the ﬁrst
screen (not used for training). We conclude that the keyboard
snooping attack in the smartphone setting is possible for a
remote attacker without access to the victim’s screen. This
supports the results of Section VII which indicate that using
more than one screen for training would likely result in even
better generalization.
V. TEXT EXTRACTION
In this attack, the attacker aims to extract text from the
attacked screen. This could be used to extract various types
of sensitive data, such as identifying information, private
messages, search queries, and ﬁnancial information.
In this attack, we explore the possibility of extracting
content from the screen rather than classifying it. We simulate
an open-world setting where the word base rate is as low
as 1/55000, i.e., a speciﬁc word has a 1/55000 probability
of appearing in a trace. To simulate the low base rate, our
implementation assumes that all characters and words are
equally likely: it does not use any knowledge of actual word
or character distribution. Notably,
this is conservative for
evaluating natural language word extraction, where the average
base rate is much higher in practice.
We simulate an attack on a portrait-layed victim screen
displaying black-on-white text in very large monospace font
(we discuss these assumptions in Section VIII).
Data collection and preprocessing. We layed a Soyo 22"
DYLM2248 in portrait layout, and captured traces in the close-
range setting (see Section III-A). We collected 10,000 traces,
each 5 s long. In each trace, a different sequence of randomly
chosen letters was displayed on the screen. The length of
sequences was chosen randomly from {3, 4, 5, 6}. Letters were
chosen from the English alphabet. Letters were capitalized, in
font type Fixedsys Excelsior and size 175 pixels in width.
Letters were black on a white screen. We attach each trace to
its corresponding sequence of characters, and again split the
traces to train (90%) and validation (10%), and employ the
same machine learning methodology as in Section IV-A.
Similarly, we also collected a test set: the traces of 100
English words, 25 for each possible length, chosen randomly
similarly to Section IV-B. We apply the signal processing
algorithm described in Section II-D.
Training procedure. We build one classiﬁer
for each
character location. Each character location is rendered at a
speciﬁc time segment during each refresh cycle. We match
every character location with its time segment.7 We construct
training and validation data for each character by extracting
the respective output trace segment, thus collecting pairs of
output trace segment and corresponding character value.
Appendix B2 details the CNN’s architecture. We again
trained it on a GPU-enhanced machine (see Section IV-B).
Testing procedure.
For each of our 100 test set words,
each classiﬁer outputs a probability vector for each character.
To predict which word was typed in, we use the Webster’s
dictionary [49]. We extract
the ﬁrst 6 characters of each
dictionary word, sum the log-probabilities of each word’s
characters, and output the words sorted by their probabilities.
Results. The per-character validation set accuracy (containing
10% of our 10,000 trace collection) ranges from 88% to 98%,
except for the last character where the accuracy was 75%. Out
of 100 recordings of test words, for two of them preprocessing
returned an error. For 56 of them, the most probable word on
the list was the correct one. For 72 of them, the correct word