Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
more information about the system’s structure (e.g., she could
compromise a set of servers in the network and monitor trafﬁc
and communications), we assume that attacking it maximizes
the efﬁciency of the attack. We assume that the attacker has
knowledge about the monitoring system.
First, we make a few reasonable assumptions about the
capability of the attacker for compromising hosts. We assume
that attackers can compromise monitoring servers, but these
compromises are rare events. We assume that some effort is
required for compromising an additional monitoring server
(i.e., an attacker cannot compromise all servers at the same
time with no effort). Such an effort can represent the difﬁculty
of acquiring an additional set of credentials, or the difﬁculty
of compromising another machine located in the network
of the monitoring server so that ﬁrewall protections can be
circumvented.
Then, we deﬁne more clearly the goals of the attackers.
We assume that the attacker is interested in both the presence
of policy violations and in the raw events collected by the
monitoring system. Policy violations indicate directly possible
venues for attacks, but they are generally ﬁxed quickly by
network administrators. This provides a limited window of
opportunity to attackers. Other data can be used to identify
critical systems or plan the next step of the attack.
The type of raw events interesting to an attacker can change
depending on the type of monitoring performed by organiza-
tions. We consider multiple types of attackers interested in
acquiring different types of information from the monitoring
system. We classify attackers as follows:
1) MAX ALL: An attacker wants to maximize her overall
knowledge about the system.
2) MAX RESOURCE CRITICAL: An attacker wants to
maximize her knowledge about a limited set of critical
resources.
3) MAX TYPE CRITICAL: An attacker wants to obtain
information about speciﬁc critical types of events (e.g.,
the presence of a vulnerability on machines)
We evaluate the protection provided by our system to these
different types of attackers, and we show that our resource-
based distribution of events provides a better protection than
other solutions.
V. DISTRIBUTED EVENT-BASED COMPLIANCE
An architecture for event correlation is generally composed
of two types of devices: event sources and monitoring hosts.
Event sources are the end-devices subject to the monitoring.
Information about these devices is provided directly to the
monitoring system in form of events, or is translated into
events from information collected by SNMP queries, IDS
alerts, Syslog, application-log parsing, or network scanning.
When new information about the state of a device is detected,
event sources generate events and deliver them to the mon-
itoring hosts. The monitoring hosts receive these events and
correlate them to identify policy violations. For the type of
policies we consider, a simple way to perform the correlation
process is to integrate information into a single knowledge
base and apply reasoning. If the conditions of one of the rules
are satisﬁed, a statement indicating the presence of a violation
is generated in the knowledge base.
Distributing the knowledge about the system to multiple
monitoring servers improves the security of the system toward
our attack model for several reasons. First, the fact that a single
compromise is not sufﬁcient anymore for acquiring the infor-
mation searched by attackers forces them to perform multiple
actions. The increased activity gives multiple opportunities
to IDS systems to detect such malicious behavior. To get a
qualitative idea of this effect, we use a simple probability
model. If we consider the probability of detecting an attack
at each action independent pa, we have that the probability
of detection pdt grows with the number of servers k as
pdt = 1 − (1 − pa)k. With no distribution, this number is
constant and equal to pa.
Second, a centralized monitoring system provides a simple
target for attack. While rare, zero-day vulnerabilities or stolen
credentials can be used by an attacker for compromising
the system and, hence, accessing the entire monitoring infor-
mation. In our distributed approach, we rely on monitoring
servers managed by different organization units. The servers
are placed in different networks and they are managed using
different credentials. In such a conﬁguration, accessing the
entire state of the system requires compromising multiple
credentials or exploiting multiple zero-days vulnerabilities to
communicate with the different servers. Even when a single
monitoring server is compromised, such an exploit has limited
effects on the amount of information obtained by the attacker.
We can qualitatively estimate the effects of this advantage.
For ease of calculation, we consider a simpliﬁed attack model
where we assume that an attacker has a probability p of
successfully compromising a host. Such a probability is related
to a simpliﬁed notion of the “effort” required for comprising
an additional server: p represents the probability of success
given a constant effort. In the centralized case, the probability
pc of compromising the central server is equal to p and
represents the probability that the entire knowledge about the
system is compromised. In our case, an attacker that wants to
have access to the information needs to compromise multiples
servers. We call pd the probability of compromising at least
k servers over the n monitoring servers, and we deﬁne it as
follows:
pd =
n
Xi=k
(cid:18)n
i(cid:19)pi(1 − p)(n−i)
(2)
i.e.,
if pd < pc,
Distributing the information across n servers is better than
if the probability pd of
centralizing it
compromising at least k servers containing the information
searched by the attacker is lower than the probability pc
of compromising the centralized server. To maximize the
difference between the pd and pc we need to have an high
value of k: we need to force attackers to compromise multiple
machines to ﬁnd the information they need. Such a number
k does not need to be very large: if we have 20 monitoring
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
servers and we consider a probability p = 0.01 for an attacker
to compromise one of the monitoring servers, a value of k = 3
leads to a probability pd = 0.001. This value is robust to
changes in probability p. For example, we can consider the
common belief that “securing one server is easier than securing
multiple machines.” To analyze its effects, we can assume that
compromising the centralized monitoring server is twice as
hard as compromising one of the monitoring servers. Even in
this case, if we take a probability pc = 0.01 and a probability
of compromising one of the monitoring servers as p = 0.02,
the probability pd with k = 3 is 0.007. With k = 4, this
probability goes down to 0.0006.
Hence, while distributing the information increases the
attack surface and might make ﬁnding one single vulnerable
monitoring server more likely, attackers need to compromise
multiple machines to acquire the information relevant for their
attacks. The multiple steps of the attack make it easier to
detect and less likely to succeed completely. Based on this
observation, we build our policy-based monitoring system
so that information is distributed uniformly across several
monitoring nodes. Our experiments show that we can maintain
the value k large for the attack models we consider.
The process of matching events within each monitoring
host is performed by a service called “broker.” A broker is
a software service that can run in a dedicated machine or can
be co-located with other services. Each broker receives events
related to a limited subset of the resources of the organization.
They use our algorithm for exchanging information and, hence,
for ﬁnding all violations presents in the system. In this way,
event load and information about the system are distributed
across a large number of hosts. Resources are assigned to
brokers at random, so that no single host concentrates the
knowledge about the resources of a critical organization unit.
Each monitoring server can subscribe to violations of speciﬁc
rules or to violations involving speciﬁc resources. These
subscriptions are distributed across brokers. Once a broker
ﬁnds a violation, it delivers a notiﬁcation to the subscribed
monitoring servers. We limit
the amount of subscriptions
that each server can submit. While communication between
brokers is necessary, such communication is limited only to
the event-correlation service. Other services can be isolated
through ﬁrewalls to reduce the attack surface. An architecture
supporting our algorithm is shown in Fig. 1.
A. Distributed Event Correlation Algorithm
Our distributed algorithm deﬁnes 1) how events are dis-
tributed across brokers and 2) what
information needs to
be shared across brokers to verify compliance. As policy
compliance policies deﬁne conditions over resources and their
relations, we base our algorithm on resources.
We use the intuition that events taking part in the violation
of a monitoring rule are related to each other as they provide
information about a limited set of resources that, together,
create the violation of the policy. For example, we can consider
a policy that speciﬁes that a user in a computer lab should not
be logged on two machines at the same time. A monitoring
!"#$%"&$#’((
)*&+*&,(
-".$/$*,(
-".$/$*,(
-".$/$*,(
8$".19"#((
7*%*/%*7(
-".$/$*,(
-".$/$*,(
/0/12#’
51.$/$"0,((
%&16/((
7*%*/%*7(
+0.#*&12.*(
,"341&*(
!"#$%&’(’!)*+’
,-.!’
!)*+’
Fig. 1. Architecture of a policy-based event correlation system supporting
our algorithm. Devices send events to different brokers depending on the
resources involved in the event. The monitoring servers interact and identify
violations by correlating events in a distributed manner. Each server maintains
limited information about the overall state.
system could generate an event when a user logs into a
machine and when the user logs out. A violation would
be represented by two logins of the same user on different
computers. We can validate compliance by integrating events
about the same user on the same broker. Different users can
be managed by different brokers without limiting the ability
of the system to detect violations. We generalize this intuition
to complex policies by identifying events that share resources.
We partition the process of validating policies by resources.
Our algorithm validates compliance by aggregating events in
a series of steps. Each step correlates events related to a
single resource. If the single-step correlation identiﬁes that
the resource can potentially contribute to a violation, we send
a summary to the next step so that it can be correlated with
additional resources.
We distribute resources uniformly across brokers using a
hash function. If the entire policy is deﬁned on a single
resource r, then the policy is validated completely in the broker
managing r. Events about r are directly delivered to the broker
and inserted into a local knowledge base. For example, we
can take the resource hosta (associated to a broker x) and the
policy critical(A), poweroff(A) → violation. The two
events critical(hosta) and poweroff(hosta) are delivered
to the broker x and inserted in its local knowledge base. The
knowledge base matches both events and ﬁnds a violation. It is
easy to prove that if two single-resource events are correlated
by a policy, both events are always sent to the same broker.
When events are related to multiple resources, the problem
becomes more complex. For example, a policy that relates IDS
events with the presence of vulnerable programs running on
a computer system requires integrating events about several
resources such as computer systems, software, and speciﬁc
network ﬂows. In general, events involved in a violation
cannot be related to a single resource. For example, an
event could state that a computer system hosta is running
a program runs(hosta, p) that is untrusted untrusted(p).
Another event could specify that a system hostb is criti-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:20:22 UTC from IEEE Xplore.  Restrictions apply. 
cal for the system critical(hostb). A third event could
state that there is a connection between hosta and hostb,
connection(hosta, hostb). Even if these events are related
to each other, no single resource is shared across all of them.
!"#$
B. Rule Rewriting
Our algorithm performs the distributed resource-based cor-
relation by rewriting monitoring rules. We analyze a policy
and create an equivalent set of rules that we call resource
ruleset. Each rule requires information about a single re-
source and represents a partial violation of the policy. If
a partial violation of the policy is found, a new event is
generated. We forward the event
to the broker managing
one of the resources connected to the potential violation.
For example, a policy could specify that there is a violation
if a machine connected to an internal network receives a
connection directed to a vulnerable program. We represent this
policy as connected(H, N ), internal(N ), runs(H, S),
vulnerable(S), conn(H, S, IP ) → violation(H, S, IP ).
We can rewrite the policy as follows:
runs(H, S),vulnerable(S) →partialS(H, S)
internal(N ),connected(H, N ) → partialN (H)
partialS(H, S),partialN (H),conn(H, S, IP ) →
(3)
violation(H, S, IP )
The ﬁrst rule relates events about the resource identiﬁed by
the value of the variable S. The second rule relates events
about the resource identiﬁed by the value of the variable N .
The third rule relates the partial information from the previous
rules with events about the resource H. The conclusions of
the ﬁrst two rules are events of type partial representing a
partial processing of the original rule. This new set of rules
generates the same statements violation(H, S, IP ) as the
original statements, but it is formulated as a sequence of rules
that ﬁlter events in different steps.
As the body of each new rule relates events about a
speciﬁc resource, we can ﬁnd all of its conclusions by
aggregating in the same broker all events about such a
resource. For example, if the two events internal(net1)
and connected(H, net1) (for all H) are sent to the broker
associated with the resource net1, such a broker is able to
compute all the couples of resources (net1, H) that match the
body of the rule. We summarize the partial evaluation with
the statements partialN (H). Changing the value net1 (i.e.,
value of the variable N ) changes the broker in charge of the
correlation. For example, if we consider N = net2, the two
events internal(net2) and connected(H, net2) are sent
to a different broker associated with the resource net2. The
partial conclusions computed by each broker are forwarded
to the brokers managing the resource identiﬁed by the value
of the variable H of partialN . On the brokers associated
with the different values of the variable H, we perform the
same process and we integrate the partial events partialN ,
partialS, and the event conn. Using our algorithm, brokers
share data only if such an interaction is necessary for detecting
a possible violation.
)+
-+
,+
./+
!"#$%"&’()*+
01""$0#$2(-3+)*+
%4"5(-3+,*+
64’"$%&7’$(,*+
9/.8/03’()*3,)*9/.8/0+’(,)*!"##’()3)67,*
!*4-"0/8"#’()*3)*67,$
!%#$
-+
.1#2’()*3,)*
410#$./50$’3,*
!*9/.8/03’()*3,$
-#%$.#/0’+,)**
!"##$!%$&’()+,
!*9/.8/0+’(,$
01""(-3+,3+./*+
,+
)+
01""(-3+,3+./*+
%4"5(-3+,*+
!"#$%"&’()*+
64’"$%&7’$(,*+
01""$0#$2(-3+)*+
!"##$!%$&’()*+,)*-#%$.#/0’+,)*.1#2’()*3,)**410#$./50$’3,)*!"##’()*3)*67,*!*4-"0/8"#’()*3)*67,*
Fig. 2.
(a) Policy graph. Dashed lines are added during the conversion
process; (b) Policy tree generated by choosing H as root. Dotted lines are
graph edges removed during the conversion process.
1) Basic Algorithm: The process of rule rewriting starts
with the identiﬁcation of the resources used in the rule. We
represent this information in a policy graph. The policy graph
is a bipartite graph where one set of nodes represents variables
and constants used in the rule, and the other represents
predicates. We create an edge between a predicate node and a
variable node if the predicate contains the variable. A policy