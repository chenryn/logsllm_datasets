kernel cannot do sanity checking of the data that is written to its raw memory.
Several approaches have been used in operating systems to address these issues. The sysctl
() system call was introduced in 4.4BSD as a safe, reliable, and portable (across kernel
versions) way to perform user-kernel data exchange. The Plan 9 operating system extended
the file metaphor to export servicessuch as I/O devices, network interfaces, and the
windowing systemas files. With these services, one could perform file I/O for most things
that would require access to /dev/kmem on traditional systems. The /proc file system uses
the file metaphor to provide both a view of currently running processes and an interface to
control them. Linux extended the concept further by providing formatted I/O to files
in /proc. For example, kernel parameters can be modified by writing strings to the
appropriate filesthe Linux kernel will parse, validate, and accept or reject the information.
Newer versions of Linux provide sysfs, which is another in-memory file system used to
export kernel data structures, their properties, and interconnections to user space.
8.2.2. Querying Physical Memory Size
The size of physical memory on a system can be programmatically determined through the sysctl() or
sysctlbyname() functions. Figure 84 shows an example. Note that the retrieved size is the value of the
max_mem kernel variable, which, as we saw in earlier chapters, can be artificially limited.
Figure 84. Determining the size of physical memory on a system
// hw_memsize.c
#include 
#include 
int
main(void)
{
int ret;
unsigned long long memsize;
size_t len = sizeof(memsize);
if (!(ret = sysctlbyname("hw.memsize", &memsize, &len, NULL, 0)))
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 9 of 135
printf("%lld MB\n", (memsize >> 20ULL));
else
perror("sysctlbyname");
return ret;
}
$ gcc -Wall -o hw_memsize hw_memsize.c
$ ./hw_memsize
4096 MB
8.3. Mach VM
In this section, we will discuss the Mach VM architecture as it is implemented in the Mac OS X kernel.
Mach's VM design has the following noteworthy aspects:
A clean separation between machine-dependent and machine-independent parts. Only the latter part
has complete VM-related information.
Large, sparse virtual address spacesone for each task, and fully shared by all threads within that
task.
Integration of memory management and interprocess communication. Mach provides IPC-based
interfaces for working with task address spaces. These interfaces are especially flexible in allowing
one task to manipulate the address space of another.
Optimized virtual copy operations through symmetric or asymmetric copy-on-write (COW)
algorithms.
Flexible memory sharing between related or unrelated tasks, with support for copy-on-write, which
is useful during fork() and during large IPC transfers. In particular, tasks can send parts of their
address spaces to one another in IPC messages.
Memory-mapped files.
A variety of backing store types usable through multiple pagers. Although not supported in Mac OS
X, Mach provides support for user-space pagers, wherein user programs can implement facilities
such as encrypted virtual memory and distributed shared memory.
Figure 85 shows an overview of the relationships between the key components of Mach's VM
architecture.
Figure 85. The Mac OS X implementation of the Mach VM architecture
[View full size image]
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 10 of 135
8.3.1. Overview
Each task's address space is represented in the kernel by an address mapa VM map, which contains a
doubly linked list of memory regions and a machine-dependent physical map (pmap) structure. The pmap
handles virtual-to-physical address translations. Each memory regiona VM map entryrepresents a
contiguous range of virtual addresses, all of which are currently mapped (valid) in the task. However,
each range has its own protection and inheritance attributes, so even if an address is valid, the task may
not be able to access it for one or more types of operations. Moreover, the VM map entries are ordered by
address in the list. Each VM map entry has an associated VM object, which contains information about
accessing the memory from its source. A VM object contains a list of resident pages, or VM pages. Each
VM page is identified within the VM object by its offset from the start of the object. Now, some or all of
the VM object's memory may not be resident in physical memoryit may be in a backing store, for
example, a regular file, a swap file, or a hardware device. The VM object is backed[3] by a memory
object, which, in the simplest sense, is a Mach port to which messages can be sent by the kernel to retrieve
the missing data. The owner of a memory object is a memory manager (often called a pager). A pager is a
specialized task (an in-kernel piece of code in Mac OS X) that supplies data to the kernel and receives
modified data upon eviction.
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 11 of 135
[3] A portion of a VM object can also be backed by another VM object, as we will see when
we discuss Mach's copy-on-write mechanism.
Figure 86 is a more detailed version of Figure 85, showing a finer-grained view of the relationships
between the VM subsystem data structures.
Figure 86. Details of the Mac OS X Mach VM architecture
[View full size image]
Let us now look at the important constituents of Mach's VM subsystem in detail.
8.3.2. Task Address Spaces
Each task has a virtual address space defining the set of valid virtual addresses that any thread within the
task is allowed to reference. A 32-bit task has a 4GB virtual address space, whereas a 64-bit task's virtual
address space is much largerMac OS X 10.4 provides a 64-bit user task with a 51-bit virtual address
space, which amounts to over 2 petabytes[4] of virtual memory. For a typical task, its virtual address space
is "large" in that it uses only a subset of the available virtual memory. At any given time, several
subranges of a task's address space may be unused, leading to a typically sparsely populated virtual
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 12 of 135
memory. It is, however, possible for special-purpose programs to have virtual memory requirements that
exceed what a 32-bit address space can provide.
[4] A petabyte is approximately 1015 bytes.
8.3.3. VM Maps
Each task's virtual address space is described by a VM map data structure (struct vm_map
[osfmk/vm/vm_map.h]). The task structure's map field points to a vm_map structure.
The task structure also contains information used by the task working set detection subsystem and the
global shared memory subsystem. We will look at these subsystems in Sections 8.14 and 8.13,
respectively.
A VM map is a collection of memory regions, or VM map entries, with each region being a virtually
contiguous set of pages (a virtual range) with the same properties. Examples of these properties include
the memory's source and attributes such as protection and inheritance. Each entry has a start address and
an end address. The VM map points to an ordered doubly linked list of VM map entries.
8.3.4. VM Map Entries
A VM map entry is represented by a vm_map_entry structure (struct vm_map_entry
[osfmk/vm/vm_map.h]). Since each entry represents a virtual memory range that is currently mapped in
the task, the kernel searches the entry list at various timesin particular, while allocating memory.
vm_map_lookup_entry() [osfmk/vm/vm_map.c] is used to find a VM map entry, if any, containing the
specified address in the given VM map. The search algorithm is simple: The kernel searches the list
linearly, either from the head of the list or from a hint that it previously saved after a successful lookup.
The hint is maintained in the VM map, which also maintains a "free space" hint used to determine a free
address quickly. If the given address cannot be found, vm_map_lookup_entry() returns the immediately
preceding entry.
The kernel can split or merge VM map entries as necessary. For example, changing one or more attributes
of a subset of a VM entry's pages will result in the entry being split into either two or three entries,
depending on the offset of the modified page or pages. Other operations can lead to the merging of entries
describing adjacent regions.
8.3.5. VM Objects
A task's memory can have several sources. For example, a shared library mapped into the task's address
space represents memory whose source is the shared library file. We noted earlier that all pages in a single
VM map entry have the same source. A VM object (struct vm_object [osfmk/vm/vm_object.h])
represents that source, with a VM map entry being the bridge between a VM object and a VM map. A VM
object is conceptually a contiguous repository of data, some of which may be cached in resident memory,
and the rest can be retrieved from the corresponding backing store. The entity in charge of transferring
pages between physical memory and a backing store is called a pager, or more appropriately, a memory
manager. In other words, a VM object is backed by a memory manager. As we will shortly see, when
Mach uses copy-on-write optimizations, a VM object can be partially backed by another VM object.
Although we will use the terms pager and memory manager synonymously, it must be noted that besides
paging, a memory manager also plays an important role in maintaining consistency between the contents
of the backing store and the contents of resident pages corresponding to a VM object. Sometimes a
memory manager is also called a data manager.
8.3.5.1. Contents of a VM Object
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 13 of 135
A VM object contains a list of its resident pages, along with information about how to retrieve the pages
that are not resident. Note that resident pages are not shared between VM objectsa given page exists
within exactly one VM object. The list of resident page structures attached to a VM object is especially
useful in releasing all pages associated with an object when it is destroyed.
A VM object data structure also contains properties such as the following:
Object's size
Number of references to the object
Associated memory object (pager) and the offset into the pager
Memory object control port
Pointers to shadow and copy objects (see Section 8.3.7), if any
"Copy strategy" that the kernel should use while copying the VM object's data
Flag indicating whether the object is internal (and thus is created by the kernel and managed by the
default pager)
Flag indicating whether the object is temporary (and thus cannot be changed externally by a
memory manager; in-memory changes to such an object are not reflected back to the memory
manager)
Flag indicating whether the object can persist (i.e., whether the kernel can keep the object's data
cached, along with rights to the associated memory object) after all address map references to the
object are deallocated
As shown in Figure 86, a memory object is implemented as a Mach port to which a pager owns receive
rights.[5] When the kernel needs a VM object's pages to be brought into physical memory from the
backing store, it communicates with the associated pager through the memory object port. The memory
object control port, to which the kernel owns receive rights, is used to receive data from the pager.
[5] We will discuss Mach port rights in Chapter 9.
With this knowledge, we can redescribe the bigger picture as follows: A VM map maps each valid region
of a task's virtual address space to an offset within some memory object. For each memory object used in
a VM map, the VM subsystem maintains a VM object.
8.3.5.2. Backing Stores
A backing store is a place for data to live when it is not resident. It can also be the source of the data, but
not necessarily. In the case of a memory-mapped file, the backing store is the file itself. When the kernel
needs to evict from physical memory a page that is backed by a file, it can simply discard the page unless
the page has been modified while it was resident, in which case the change can be committed to the
backing store.
Dynamically allocated memory, such as that obtained by calling malloc(3), is anonymous in that it has
no named source to begin with. When an anonymous memory page is used for the first time, Mach simply
provides a physical page filled with zeros (hence, anonymous memory is also called zero-filled memory).
In particular, there is no backing store initially associated with anonymous memory. When the kernel
must evict such a page, it uses swap space as the backing store. Anonymous memory does not persist
across system reboots. The corresponding VM objects, which are created by the kernel, are also called
internal objects.
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 14 of 135
When allocating anonymous memory, the kernel checks whether an existing VM map entry can be
extended so that the kernel can avoid creating a new entry and a new VM object.
8.3.6. Pagers
A pager manipulates memory objects and pages. It owns the memory object port, which is used by the
pager's clients (such as the kernel) as an interface to the memory object's pages, with operations for
reading and writing those pages being part of the interface. The memory object is essentially a Mach port
representation of the underlying backing storage[6]it represents the nonresident state of the memory ranges
backed by the memory object abstraction. The nonresident state (e.g., on-disk objects such as regular files
and swap space) is essentially secondary memory that the kernel caches in primary (physical) memory.
[6] Here's another way to look at this: A memory object is an object-oriented encapsulation of
memory, implementing methods such as read and write.
As shown in Figure 81, Mac OS X provides three in-kernel pagers:
The default pager, which transfers data between physical memory and swap space
The vnode pager, which transfers data between physical memory and files
The device pager, which is used for mapping special-purpose memory (such as framebuffer
memory, PCI memory, or other physical addresses mapped to special hardware), with the necessary
WIMG characteristics
The letters in WIMG each specify a caching aspect, namely: write-through, caching-inhibited, memory
coherency required, and guarded storage.
A pager may provide any number of memory objects, each of which represents one range of pages that the
pager manages. Conversely, a task's address space may have any number of pagers managing separate
pieces of it. Note that a pager is not directly involved in paging policiesit cannot alter the kernel's page
replacement algorithm beyond setting memory object attributes.
8.3.6.1. External Pagers
The term external memory manager (or external pager) can be used to mean two things. In the first case, it
refers to any pager other than the defaultspecifically, one that manages memory whose source is external
to the kernel. Anonymous memory corresponds to internal objects, whereas memory-mapped files
correspond to external objects. Therefore, the vnode pager would be termed as an external pager in this
sense. This is the meaning we use in this chapter.
The other meaning refers to where the pager is implemented. If we designate an in-kernel pager as an
internal pager, an external pager would be implemented as a specialized user task.
User-Space Pagers
User-space pagers allow flexibility in the types of backing stores that can be introduced
without changing the kernel. For example, a pager can be written whose backing store is
encrypted or compressed on disk. Similarly, distributed shared memory can be easily
implemented via a user-space pager. Mac OS X does not support user-space pagers.
8.3.6.2. A Pager's Port
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 15 of 135
Whereas a memory object represents a source of data, the memory object's pager is the provider and
manager of that data. When a portion of memory represented by a memory object is used by a client task,
there are three parties primarily involved: the pager, the kernel, and the client task. As we will see in
Section 8.6.1, a task directly or indirectly uses vm_map() (or its 64-bit variant) to map some or all of the
memory object's memory into its address space. To do this, the caller of vm_map() must have send rights
to the Mach port that represents the memory object. The pager owns this port and can therefore provide
these rights to others.
A pager could advertise a service port to which clients could send messages to obtain memory objects. For
example, a user-space pager could register its service port with the Bootstrap Server.[7] However, Mac OS
X currently does not provide support for adding your own pagers. The three in-kernel pagers in Mac OS X
have hardcoded ports. When pager-independent VM code needs to communicate with a pager, it
determines the pager to call based on the value of the memory object passed, since the value must
correspond to one of the known pagers.
[7] We will discuss details of the Bootstrap Server in Section 9.4.
kern_return_t
memory_object_init(memory_object_t memory_object,
memory_object_control_t memory_control,
memory_object_cluster_size_t memory_object_page_size)
{
if (memory_object->pager = &vnode_pager_workaround)
return vnode_pager_init(memory_object, memory_control,
memory_object_page_size);
else if (memory_object->pager == &device_pager_workaround)
return device_pager_init(memory_object, memory_control,
memory_object_page_size);
else // default pager
return dp_memory_object_init(memory_object, memory_control,
memory_object_page_size);
}
The operation of a pager in the Mac OS X kernel uses a combination of the following: a subset of the
original Mach pager interface, universal page lists (UPLs), and the unified buffer cache (UBC).
Note that the kernel implicitly provides the memory object for an internal pagerthe calling task does not
have to acquire send rights to one directly. For example, when a regular file is opened, the vnode pager's
port is stashed into the UBC structure referenced from the vnode.
8.3.6.3. The Mach Pager Interface
Mach paging can be summarily described as follows: a client task obtains a memory object port directly
or indirectly from a memory manager. It requests the kernel by calling vm_map() to map the memory
object into its virtual address space. Thereafter, when the task attempts to accessread or writea page from
the newly mapped memory for the first time, a page-not-resident fault occurs. In handling the page fault,
the kernel communicates with the memory manager by sending it a message requesting the missing data.
The memory manager fetches the data from the backing store it is managing. Other types of page faults
are handled as appropriate, with the kernel calling the memory manager and the latter responding
asynchronously.
This is how the kernel uses physical memory as a cache for the contents of various memory objects. When
the kernel needs to evict resident pages, it maydepending on the nature of the mappingsend
"dirty" (modified while resident) pages to the memory manager.
When a client task is done using a mapped memory range, it can call vm_deallocate() to unmap that
range. When all mappings of a memory object are gone, the object is terminated.
file://C:\Dokumente und Einstellungen\Silvia\Lokale Einstellungen\Temp\~hhCF85.htm 20.08.2007
Chapter 8. Memory Page 16 of 135
Figure 87 shows several messages (routines) that are part of the dialog between a memory manager and a
kernel.[8] Let us look at some of these.
[8] We say "a kernel" because, pedantically speaking, a pager could be serving multiple
kernels.
Figure 87. The Mach pager interface in Mac OS X
[View full size image]
When a memory object is mapped for the first time, the kernel needs to notify the pager that it is using the
object. It does so by sending a memory_object_init() message[9] to the pager. Regardless of where it is
implemented, if you consider the pager as being logically external to the kernel, this is an upcall from the