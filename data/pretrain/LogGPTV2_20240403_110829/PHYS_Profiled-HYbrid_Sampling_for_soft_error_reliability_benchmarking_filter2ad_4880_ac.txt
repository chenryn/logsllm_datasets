simulation to get an estimate of the FIT rate as follows: 
(1) 
ܨܫܶ=sampled_counts+skipped_counts
sampled_counts
ܨܫܶ෢  is the sampled FIT rate. 
where  FIT  is  the  estimated  FIT  rate  of  the  population  and 
×ܨܫܶ෢  
IV.  RELIABILITY-AWARE SAMPLING 
Set sampling is biased because sampled sets may not be 
representative. A program may access only a small number 
of  sets.  Interval  sampling  typically  results  in  smaller  error 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
than set sampling as it samples accesses in all sets. However, 
in  reliability  simulations,  each  VC  interval  has  different 
merit  with  respect  to  the  simulation  time  as  well  as  to  the 
accuracy  of  the  reliability  estimate.  Hybrid  sampling 
exploits both set and interval sampling to efficiently sample 
VCs with higher merit. 
We also need to determine the sampling rates (or sample 
sizes)  to  effectively  use  random  sampling  methods.  We 
exploit a statistical approach to determine the sampling rate. 
This  approach  is  itself  based  on  sampling.  We  call  it 
sampling  rate  profiling  in  the  context  of  reliability-aware 
sampling. 
A.  Hybrid sampling  
than  others, 
Interval  sampling  provides  better  FIT  rate  estimates  by 
reducing  sampling  bias  while  set  sampling  provides  better 
speedup  as it  does  not suffer from the runtime  overhead of 
BST  management.  Motivated  by  these  insights  we  now 
explore a hybrid sampling technique where we dynamically 
change 
the  sampling  rate  of  each  cache  set  while 
maintaining the overall  target sampling  rate.  Because some 
sets  are  more  frequently  accessed 
the 
contribution  of  each  set  to  the  overall  cache  vulnerability 
varies.  In  performance  evaluation  studies  that  measure 
cache miss rates  it  is reasonable to  focus on the activity  of 
frequently accessed sets. However, in reliability studies, we 
have  to  give  priority  to  infrequently  accessed  sets.  The 
reason  is  that  when  a  set  is  frequently  accessed,  the 
probability  that  one  of  the  accesses  to  that  set  is  randomly 
selected  by  interval  sampling  is  high.  Furthermore,  each 
access to frequently accessed sets has shorter VCs meaning 
their contribution to overall reliability is smaller. When a set 
is less frequently accessed, fewer accesses to it are sampled 
but  these  accesses  have  longer  VCs.  When  using  pure 
random interval sampling, accesses with large VCs may slip 
away  from  the  sampling  net.  Hence  the  goal  of  hybrid 
sampling  is  to  start  with  interval  sampling  but  give 
preference  to  events  that  happen  in  sets  that  are  least 
frequently accessed. A collateral advantage of this approach 
is the lower sampling rate to more frequently accessed sets, 
which  also  improves  simulation  speed  by  cutting  the 
number of searches in the BST. 
To  implement  hybrid  sampling,  we  maintain  a  three-
element array per set to hold the sets’ sampling rate, access 
counts and sampled counts. The array size is quite small: 12 
bytes  per  L2  cache  set.  Whenever  the  target  cache  is 
accessed  a  given  number  of  times,  we  adjust  the  sampling 
rates of every set using the following formula:  
(2) 
ݐ௝ =ܰ×ܶܰ−1×ܣ−ܽ௝ܣ  
where j is the index of a set, N is the total number of sets in 
the  target  cache,  T  is  the  overall  target  sampling  rate,  A  is 
the total number of accesses to all the sets from the start of 
the workload, aj is the total number of accesses to the jth set, 
and tj is the target sampling rate of the jth set. In (2), (A-aj) is 
the  total  number  of  accesses  made  to  all  sets  other  than  j. 
Because  ଵ
ேࢣ
ே௝ୀଵ
ݐ௝ =ܶ
,  the  mean  sampling  rate  remains 
within  the  target  sampling  rate.  FIT  estimates  are  adjusted 
using  (1)  applied  to  each  set  since  now  the  contribution  of 
each set must be weighted accordingly.  
In  our  experiments  we  adjust  the  sampling  rate  of  sets 
after    a number of cycles equal to 10 times the number of 
cache sets, with the assumption that every set is likely to be 
touched at least once within that interval. 
B.  Sampling rate profiling 
One  major  drawback  of  the  hybrid  sampling  scheme  is 
that  the  best  overall  sampling  rate  for  a  benchmark  is  a-
priori unknown. The purpose of this section is to provide a 
method to decide on a minimum sampling rate so as to have 
a  measure  of  confidence  that  the  FIT  error  is  within  the 
allowed margin of error. 
The  well-known  central  limit  theorem  establishes  that 
the  sum  of  random  variables  picked  from  any  arbitrary 
distribution  converges  to  a  normal  distribution  as  the 
number  of  random  variables  in  the  sum  increases.  Because 
the  FIT  rate  is  estimated  by  accumulating  VCs  during  a 
benchmark execution, and because there are tens of millions 
of  VCs  to  sample  from,  the  FIT  estimate  obtained  by 
sampling is a random variable with a normal distribution by 
virtue of the central limit theorem.  
If one can simulate  all  workloads to  completion to  find 
the  distribution  of  the  complete  population  of  VCs,  then 
calculating  the  required  sampling  rates  to  satisfy  a  given 
confidence  interval  is  very  straightforward.  However  it  is 
impossible to  complete the reliability  simulations of  all  the 
benchmarks.  It  would  take  months  and  it  would  defeat  the 
purpose of sampling.  
Fortunately, estimating the required sampling rate in the 
absence  of  knowledge  about  the  complete  population  is 
possible. An unbiased estimate of population variance from 
a sampled run is given by [19]: 
ݏଶ = 1݊−1൝෍ሺݔ௜−ߤıሻଶ
௡
௜ୀଵ
ൡ 
(3) 
where s2 is an unbiased estimate of the population variance, 
xi’s  are  members  of  the  sample  set  of  size  n  from  the 
population  and ߤı is  the  sample  mean.  Using  the  unbiased 
sample  mean  (s/ߤı ).  This  CV  obtained  from  sampling  is 
estimate  of  the  population  variance,  we  can  obtain  the 
coefficient  of  variation  (CV)  by  dividing  the  unbiased 
estimate  of  the  standard  deviation  of  the  population  by  its 
unbiased  and  accurate  as  long  as  the  number  of  samples  is 
large  (see  [11]).  Because  there  are  millions  of  memory 
accesses  in  a  typical  program  run,  even  with  a  very  low 
target  sampling  rate,  we  still  get  a  very  large  number  of 
samples  numbering  in  the  ten  to  hundred  thousand. 
Calculating the CV is done very efficiently with a one-pass 
algorithm  [25].  Then,  from  the  normal  distribution,  the 
sample  size  to  target  a  specific  margin  of  error  and 
confidence level is computed as follows [1]:  
݊௥ =ቀ2×ݖଵିഀమቁଶ× CVଶ×ሺ1+݂ଶሻ
where ݖଵିഀమ is  the z-score (or standard  score)  obtained from 
the  standard  normal  distribution  for  two-sided  confidence 
ሺ1−݂ଶሻ
(4) 
5
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
TABLE I.  
CHARACTERISTICS OF 26 MINNESPEC BENCHMARKS (LARGE REDUCED INPUT SETS) WITH AVF SIMULATION STATISTICS AND FITS 
Name 
ammp
applu
apsi
art
bzip2
crafty
eon
equake
facerec
fma3d
galgel
gap
gcc
gzip
lucas
mcf
mesa
mgrid
parser
perlbmk
sixtrack
swim
twolf
vortex
vpr
wupwise
Average
# of retired 
instructions (-O3) 
1,247,236,930
88,150,710
340,286,707
1,660,422,529
2,643,937,077
834,909,917
852,172,831
1,021,607,627
252,196,175
668,404,801
347,613,499
762,001,846
5,117,276,757
593,346,464
187,127,842
793,869,426
2,337,178,215
114,854,927
4,527,012,521
2,061,234,507
1,517,455,161
431,492,911
972,727,788
1,153,664,453
1,566,705,501
5,216,797,714
1,434,987,878
# of cycles 
12,409,953,566
98,791,107
257,108,260
5,238,034,181
2,010,038,299
735,979,095
464,096,183
674,458,162
164,515,545
477,252,184
152,639,980
803,385,993
4,716,470,915
346,206,810
74,314,956
2,215,853,048
973,997,101
141,652,594
6,700,657,595
1,530,327,815
1,167,983,904
801,590,618
680,670,746
864,609,974
914,632,391
3,078,886,972
1,834,388,796
# of Tracked 
L2 blocks 
Workload size [KB]  SDC FIT  AVF 
Execution time [sec] 
Slowdown 
26,384
4,624
196,656
2,736
14,272
2,448
1,128
12,224
5,240
2,168
6,256
66,880
19,296
3,728
1,096
189,336
10,496
2,144
22,432
9,304
28,824
75,968
960
15,288
680
145,040
33,293
198,113
24,616
---
77,077
409,097
64,953
13,202
380,742
138,964
10,093
25,168
---
579,363
49,346
6,291