(9,001 samples) has become a popular triggering mechanism to-
wards the beginning of 2021, clearly in an attempt to evade analysis
tools. Moreover, Figure 5 also shows how malicious documents (18
samples) leverage DCONN records, which allows Excel to perform
a web query and insert new formulas inside a spreadsheet. Despite
not being an entry point per se, we observed that samples use a
combination of DCONN and Auto Open. In these cases, a part of the
malicious macros is downloaded using the DCONN functionality,
while the execution is started with Auto Open.
These alternative triggering mechanisms have been used
recently—we observed VBA code used as an entry point starting
from March 2021—by the malware authors to create samples
that are harder to analyze. For instance, at the time of writing,
XLMMacroDeobfuscator does not support the parsing of VBA
entry points. Similarly, the analysis of any sample that uses the
DCONN functionality is complicated by the fact that part of the
Excel 4.0 payload is stored remotely and, thus, cannot be retrieved
unless the analysis sandbox is connected to the Internet and the
remote server is still reachable.
B. Evasion Techniques
This section discusses the evolution of the evasion techniques
used in different waves of Excel 4.0 malicious macros. Initially,
we observe such malicious macros separately using hidden macro
sheets, control-flow obfuscation, data-flow obfuscation, and
sandbox detection checks. However, in later waves, we observe a
particular interleaving of sandbox detection checks and data-flow
obfuscation that makes the correctness of the deobfuscated code
depend directly on the system configuration of the host machine.
Finally, in the latest waves of Excel 4.0 macros, we observe
a series of evasion techniques that break the parsing logic of
the xlrd2 parser, as well as the Excel grammar and evaluation
logic implemented in XLMMacroDeobfuscator, making the
samples harder to analyze. In the following paragraphs, we
classify the evasion techniques observed in our dataset into seven
categories: hidden macro sheets, control-flow obfuscation, data-flow
obfuscation, sandbox detection, xlrd2 parsing confusion, Excel
4.0 macro grammar confusion, and evaluation logic confusion.
Hidden Macro Sheet. Hidden macro sheets are one of the first
types of evasion techniques observed in malicious Excel 4.0
macros [28]; our dataset contains samples submitted as early as 2013
that leverage this technique. The visibility of an Excel sheet can be
set to Visible, Hidden, or Very Hidden. In particular, while the Hidden
setting can be changed using the standard Excel User Interface, the
Very Hidden setting can only be changed using a VBA macro or by
manually modifying the binary representation of the macro sheet.
Control-Flow Obfuscation. Multiple functions are used to
obfuscate the original control flow of the malicious macro, making
the control flow harder to follow by human analysts. First, the
GOTO and RUN functions are used as a trampoline to transfer the
execution to target cells, which can reside in different macro sheets.
Calls to subroutines—which are linked to either a cell or a defined
name—are used along with the RETURN function to execute
program routines, such as a subsequent stage in a multi-stage macro
or a cipher implementation. Finally, the REGISTER function is
heavily used to register functions from the Windows API with
custom names and evade any static deobfuscator attempts to extract
strings representing function names, DLL names, URLs, etc.
Data-Flow Obfuscation. We observe several techniques used to
obfuscate the data flow of malicious macros. In particular, functions
such as CHAR or MID are heavily used in combination with
both basic arithmetic and the FORMULA.FILL and FORMULA
functions to concatenate sets of characters and dynamically generate
additional malicious formulas. Moreover, many samples use the
defined names as a form of temporary storage for strings and
intermediate values in general. Finally, recent samples use various
types of ciphers to re-arrange, shift, and combine the values in the
document to generate the malicious macro.
Sandbox Detection. Malicious Excel 4.0 samples use various
strategies to detect a sandbox environment during execution. For
example, as described in previous sections, samples use functions
such as GET.WINDOW, GET.WORKSPACE, GET.DOCUMENT,
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:02 UTC from IEEE Xplore.  Restrictions apply. 
1073
Fig. 5: Distribution of the number of malicious samples using each entry point over time.
GET.CELL, etc., to read values from the environment configuration.
Moreover, we observed malicious samples that check multiple prop-
erties of the host system, such as the existence of a working system
clock and a functional file system implementation, or the presence of
Alternate Data Streams (ADT), a file attribute specific of NTFS that
is commonly leveraged by other types of Windows malware. Some
of the samples export and check the contents of the Excel Macro
Security Windows registry key. Finally, some of the samples use
the Xlcall32:Excel4 API to fork the execution and continue
executing the macro in a new process, in an attempt to confuse
dynamic analysis techniques that monitor the process execution.
What makes these techniques particularly interesting for SYM-
BEXCEL is that they evolved from being used as mere environment
fingerprinting/evasion mechanisms to playing a key role in the
generation of the final malware payload. Instead of simply aborting
the execution, these evasion mechanisms provide values that are used
to generate the final payload and, therefore, lead to a subtle incorrect
deobfuscation of the malware sample. However, SYMBEXCEL can
correctly analyze these samples because it treats values related to
the execution environment configuration as symbolic.
Static Parsing Confusion. Some samples in our dataset tamper
with the Excel file format to cause the static parsing logic to fail.
However, at the same time, these samples remain compliant with
the parser implemented in Excel, which executes the malicious
macro without errors. For example, a common strategy among
malware authors is to insert null bytes to alter the representation of
the defined names and Shared String Table (SST)—which causes
the parsing library to process the malicious file incorrectly (e.g.,
because of missing defined names).
Excel 4.0 Macro Grammar Confusion. Instead of tampering
with the parsing logic, some samples alter the formulas to confuse
the XL4 grammar implementation. In fact, the grammar commonly
used to parse malicious formulas is a manual approximation of the
grammar used by Excel. This approximation allows malware authors
to leverage imprecision in the implementation and cause the analysis
to fail. For example, Cyrillic and Unicode characters were initially
not supported, and parsing a formula with one such character would
cause the analysis to abort. Similarly, an incorrect specification of
the comparison operator in the grammar resulted in the incorrect
parsing of formulas such as =TRUE=TRUE=TRUE (a sequence of
two comparisons). After noticing this problem, we improved the
grammar used by SYMBEXCEL to support such formulas.
Evaluation Logic Confusion. Finally, some samples target
the analysis tools at a higher level and introduce functions for
which the handlers are either partially implemented or incorrectly
implemented. For example, some of the samples observed by the
VMware Threat Research Unit [28] make heavy use of arithmetic
operations on floating-point numbers to test the correctness of the
underlining engine.
C. Malware Evolution
This section discusses how we can leverage the data extracted
by SYMBEXCEL to analyze the malware samples contained
in our dataset, and classify them into behavioral clusters. This
analysis aims to show how malware families evolve, and to identify
sub-clusters that represent variations of the same malware family.
Figure 7 in the Appendix presents an overlay of two triangular
matrices representing the behavioral (below the diagonal, in the
lower triangle) and structural (above the diagonal) similarities
between different malware samples. Lighter shades of red indicate
lower similarity, while darker shades indicate higher similarity.
In particular, to compute the behavioral similarity clusters, we first
pre-process the SRFs, extracting the function names and relevant ar-
guments (e.g., CALL urlmon URLDownloadToFileA). We
then transform such tokens using the Term-Frequency Inverse-
Document-Frequency (TF-IDF) and calculate their cosine similarity.
Finally, we perform hierarchical agglomerative clustering using the
nearest point distance algorithm (i.e., single linkage) with Euclidean
distance, and show the resulting hierarchically-clustered heatmap in
the lower triangle in Figure 7. With a cutoff threshold of 2, we obtain
40 behavioral clusters (of which 13 are singletons) with an average
size of 57 samples. We exclude the clusters with less than 20 samples,
and identify nine distinct behavioral clusters with an average size of
239 samples (highlighted in Figure 7) that cover 95% of the distinct
samples in our dataset. Specifically, the distinct behaviors identified
by the hierarchical clustering can be recognized by observing red-
colored blobs close to the diagonal of the matrix, which are marked
with incremental numbers ranging from one to nine.
To compute the structural similarity clusters, we similarly process
the list of all functions executed by each sample. We then preserve
the ordering from the lower triangle (below the diagonal) and overlay
the structural similarities in the upper triangle (above the diagonal).
This representation allows us to observe clusters of samples with
similar behavior and, at the same time, to compare their structure.
Figure 6 presents a timeline with the number of observations per
cluster over time. For the sake of clarity, we only include the six
clusters with more than 50 distinct samples in the timeline. Interest-
ingly, this timeline shows that samples belonging to the same cluster
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:02 UTC from IEEE Xplore.  Restrictions apply. 
1074
2013-042014-122016-082018-042019-122021-08Month100101102103104Number of Samples (log)all samplesAUTO_OPENAUTO_CLOSEAUTO_ACTIVATEDCONNVBAFig. 6: Timeline of the number of clusters observations over time.
are focused around a given time. This distribution supports our
observation that the malware authors will develop new variants as
the previous ones are detected and, therefore, are no longer effective.
In the following sections, we present our study of the identified
clusters and provide insights into the temporal evolution of the
observed behaviors.
Cluster 1. The samples in Cluster 1 display different behaviors
depending on the architecture of the machine where the sample is
executed. On a 32-bit system, the samples download and execute
a malicious DLL file. On the other hand, if a 64-bit system is
detected, these samples create on the file-system two VBScripts
using the FOPEN and FWRITELN functions, and execute them
using explorer.exe. The first script file downloads a malicious DLL
from a remote server, while the second one executes this DLL
using the rundll32.exe executable. We observe two variants of the
samples belonging to Cluster 1. Both variants use three consecutive
stages, and heavily use the SET.NAME function to update the
values of the defined names during the deobfuscation. The first
two stages are used to detect sandboxes and to deobfuscate the
third stage using values from the environment. The only difference
between these two variants is their usage of different functions (e.g.,
FORMULA.FILL instead of FORMULA) to write the third-stage
payload in the macro sheet.
We first observed Cluster 1 on November 2020 and—considering
their structural and behavioral similarity—it likely represents an
evolution of the first cluster described by the VMware Threat
Research Unit in October 2020 [67].
Cluster 2. The behavior of the samples in Cluster 2 is equivalent
to that of the samples in Cluster 1, as also observed in Figure 7.
However, the structure of these samples shows some different
characteristics. In particular, samples from Cluster 2 use a first
stage with two nested loops that combine values from both the cells
and the environment to generate the second stage. As a result, the
correct execution of both the second and third stages depends on the
correctness of the environment values. Similarly, we observe three
variants of this cluster. The main difference between these variants is
the usage of different functions—such as TRIM, CONCATENATE,
SUM, MAX, MIN—during the deobfuscation stage. One of the vari-
ants, in particular, uses the MIN and MAX functions with symbolic
arguments in a loop to generate additional possible behaviors.
Cluster 2 was first observed on December 2020 and is likely an
evolution of Cluster 1, given their behavioral similarity. Moreover,
the timeline presented in Figure 6 shows how this cluster was
deployed after Cluster 1 retired, and our observations suggest that
these two events are correlated.
Cluster 3. The samples in Cluster 3 are behaviorally similar to the
samples observed in Cluster 2, but introduce a two-stage structure
with two distinct deobfuscation routines. Also, there is a common
second stage that is executed for both 32-bit and 64-bit systems.
Cluster 3 was first observed on February 2021, when the number
of reports for Cluster 2 started to decrease. Indeed, after a closer
comparison, we observe that Cluster 3 exhibits a behavior similar
to Cluster 2, but uses a Javascript (.js) file instead of VBScript to
download and run a DLL.
Cluster 4. The samples in Cluster 4 were first observed in a
simplified form in December 2019. Interestingly, they use two
distinct deobfuscation routines and novel evasion techniques in
the deobfuscation stage, such as checking the value of the Excel
Macro Security Windows registry key. The samples of this
family evolved around February 2021 and started using more
sophisticated evasion techniques, such as the Xlcall32:Excel4
API to fork the execution. We then observe a wave of samples
belonging to this cluster starting on February 2021, at the same
time as Cluster 3. In fact, we observe that this cluster also uses two
distinct routines to deobfuscate its four stages.
Cluster 5. The samples in Cluster 5 all share a simple structure
(on average, 18 formulas) and display a behavior that consists of
the download and execution of one or more files. The distinctive
trait of this cluster is its heavy usage of the REGISTER function.
In particular, the majority of these samples use the REGISTER
function to register a custom function that downloads a file, call
the custom function, and finally execute the file with the EXEC
function. However, some of the samples in this cluster additionally
use the NOW function to retrieve the current timestamp and generate
the target URLs. Cluster 5 was first observed on January 2021.
These samples do not use sophisticated evasion or deobfuscation
techniques, likely as a way to blend in with other benign samples.
Cluster 6. The samples in Cluster 6 are samples that are currently
unsupported by SYMBEXCEL (for example, because of imprecisions
in the implementation of our functions handlers). That is why
the corresponding behavior is shown as a white area in Figure 7.
However, SYMBEXCEL can partially execute these samples, which
offers a way to measure their structural similarity with other
samples in our dataset. In particular, by looking at the structural
similarity matrix (above the diagonal in Figure 7), we observe that
many of these samples are structurally similar to the samples in
Cluster 1, indicating that more than 50% of the samples in this
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:02 UTC from IEEE Xplore.  Restrictions apply. 
1075
2019-102020-032020-082021-012021-06Month100101102103Number of Samples (log)distinct samplesCLUSTER_1CLUSTER_2CLUSTER_3CLUSTER_4CLUSTER_5CLUSTER_7cluster could belong to a new cluster that is a variant of Cluster 1.
Cluster 7. We observe two main variants of Cluster 7, respectively,
in March 2020 and May 2020. Both the variants first check the Ex-
cel Macro Security settings (a technique already observed
in Cluster 4). Then, they request the office-msi-non-security-updates
web page from docs.microsoft.com, possibly to mimic a benign
behavior. Finally, the samples download and execute a malicious file.
The first variant of Cluster 7 (observed in March 2020) has
a very simple structure (32 formulas) that first deobfuscates a
sequence of environment checks and then executes them. The
second variant (first observed in May 2020) introduces multiple
stages of deobfuscation interleaved with the environment checks.
This variant is generally more complex (244 formulas) and also
makes heavier use of control-flow obfuscation (RUN and GOTO
functions). Finally, we observe a third variant first used in February
2020 and then deployed again in April 2021. This third variant is
less prevalent and uses a series of calls to the SET.NAME function
during the deobfuscation stage.
Other Clusters. We observe some smaller clusters in the bottom
right part of Figure 7, namely Cluster 8 and Cluster 9. The samples
in Cluster 8 are behaviorally very similar to the samples observed in
Cluster 5. However, these samples do not use the REGISTER func-
tion, but only download and execute an executable file. Despite being
behaviorally similar, the samples from Cluster 8 do not share a sim-
ilar structure. Instead, we observe that such samples often use func-
tions that are otherwise rarely used, such as CEILING.PRECISE,
RADIANS, SUMPRODUCT, ACOS, SUMXMY2, etc., possibly as a
way to break existing analysis techniques.
Cluster 9 contains samples that heavily use control-flow
obfuscation (out of 157 formulas executed, 135 use the
RUN function). The behavior displayed by these samples is
straightforward and consists of the creation of two nested directories
using the Kernel32:CreateDirectoryA API followed by
the download and execution of an executable file.
D. Malware Families
To study the malware families in our dataset, we retrieve and an-
alyze the VT labels of the public samples. In particular, we find Mi-
crosoft Defender to be the most reliable for XL4 malware samples.
We first assign a family name to each sample by parsing the
Microsoft Defender labels and matching them against a list of
verified family names from multiple sources [1], [59], [63]. Quite
interestingly, we observe that 15% of the public samples are
unlabeled, and 36% have a generic, non-meaningful label (e.g.,
TrojanDownloader:O97M/EncDoc). This clearly shows that XL4
malware remains difficult to analyze, and even authoritative engines
are not always able to correctly label these samples, and correlate
them with a specific threat actor. Nonetheless, from the remaining
49% of the samples, we identify nine different families— Donoff,
Dridex, Gozi, Hancitor, IcedID, Mailcab, Qbot, TrickBot, and
Zloader—suggesting that multiple threat actors have abused this
infection vector. We select the three most prominent families and
present their observations timeline in Figure 8 in the Appendix.
Excel 4.0 malware samples often do not directly infect the
host machine, but rather download a secondary infection payload.
For this reason, while our behavioral clustering is based on the
Cluster