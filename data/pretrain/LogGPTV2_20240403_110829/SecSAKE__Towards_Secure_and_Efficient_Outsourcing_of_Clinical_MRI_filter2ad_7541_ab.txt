subject to rank (A) = ˆr, x = H† (A)
where y and x are the k-space data acquired from coils and to
be reconstruction, respectively. To solve this problem, an initial
estimate on k-space data is first given to the problem solver, which
is usually selected as D†y. In the iterative process, the data matrix
generated from the current estimate is successively enforced by low-
rankness projection, structural consistency projection, and data
Figure 1: The procedure of generating data matrix and en-
forcing structural consistency projection in [26]. The white
dots represent non-sampled points.
consistency projection. The iteration ends when the consecutive
estimates are within a predefined bound. Finally, the image can be
recovered by computing the 2D inverse Fourier transform over the
reconstructed k-space data.
2.2 Cartesian and Non-Cartesian Sampling
In modern MRI, there roughly exist two categories of traversal
strategies for k-space data sampling, known as Cartesian Sampling
and non-Cartesian Sampling. In the Cartesian Sampling case, the
data is sampled with regular intervals in the k-space, which en-
ables convenient implementation. The non-Cartesian Sampling ap-
proaches, including spiral, zig-zag, radial, etc, are more popular in
recent years [30]. These approaches acquire data in a non-uniform
manner, which cause fewer motion artifacts and then can recon-
struct high-resolution images.
The sampling operator D in Equation (5) has different imple-
mentations given the sampling strategy. In Cartesian Sampling,
the DO only needs to substitute the k-space data ˆxn at the sam-
pled locations with the original data acquired from the multiple
coils. In this way, the estimate of the k-space data is easily updated
to xn+1. Differently, the operator D in non-Cartesian Sampling
refers to an interpolation operator which transforms the Cartesian
reconstructed data to non-Cartesian locations and remains fixed
according to the sampling approach. This step can be approximately
implemented by Equation (5) and is required to be repeated a few
times before getting good results. Despite the various sampling ap-
proaches, the MRI scanning machine usually holds only one piece
of sampling code in clinical settings.
3 PROBLEM STATEMENT
3.1 System Architecture
In this paper, we focus on securely outsourcing the computations
of solving low-rank matrix completion problem to the cloud server,
as stated in Section 2. In SecSAKE, two system architectures are
considered corresponding to two of our different designs, both
of which are composed of two group of entities, the Data Owner
DO and Cloud Servers CS. Under the circumstance of performing
MRI in the clinic, the collected data from scanning patient’s body
is supposed to be securely kept by the clinic. As the DO in our
system, however, the clinic may not be able to reconstruct the
diagnosable image by itself efficiently, due to the large-scale data
samples and its limited computation resources. Then the DO is
Session 13: Privacy 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea539Figure 2: Left: System Architecture of SecSAKE I. The DO keeps online to communicate with the CS in each iteration;
Right: System Architecture of SecSAKE II. The data owner keeps offline while the servers communicate with each other.
inclined to outsource the most computational expensive parts to the
CS, while preserving both the data confidentiality and computation
functionality. Based on the capability of the computation and the
security requirement of the DO, the settings within the CS of two
designs are differentiated as shown in Figure 2.
In our first design, only one server is included in the CS. In each
iteration, the DO will locally generate the data matrix from the
acquired data. By carefully encrypting the data matrix, the DO
can outsource the computation task of SVD to the CS in a privacy-
preserving manner. The solution is then returned and decrypted by
the DO before it performs the structural consistency projection.
To enforce the data consistency projection, the DO pre-stores an
encrypted form of the matrix related to the sampling mechanism on
the CS. Then the DO can securely outsource the current estimate
to the CS for updating. Finally, the DO can stop the iteration when
the requirement of the convergence is met.
In our second design, four independent cloud servers are in-
cluded: one executor and three shareholders. At first, the scanned
imaging data is randomly split into three shares. In the initialization
phase, the DO distributes the first-round key matrices along with
the shares to the shareholders. Besides, the data owner encrypts
the imaging data and outsources it to the executor. The executor
computes SVD, applies an additional mask to hide the temporary
results and then securely passes different units of results to differ-
ent shareholders. With the encrypted results, the shareholders can
jointly compute their own share of the estimate but none of them
can reveal the imaging data individually. These shares along with
the stored imaging data shares will then be securely aggregated
and sent to the executor, as the input of the next iteration. At last,
the DO can reveal the results by transformation of imaging data
after it manually stops the iteration.
3.2 Threat Model
In reality, the exposure of imaging data, including both the interme-
diate and the final reconstruction estimates in the k-space domain,
may incurs an increased the risk of patient’s identity and physical
condition. Meanwhile, we observe that the clinics seldom update
their sampling method. The adversary may take advantage of the
fixed sampling operator to track a specific patient. Hence, in this
paper, we address that two parts of the data involved in the compu-
tation may potentially lead to privacy leakage: the imaging data y
(and x) and the sampling operator D.
In addition, in our first design, we assume the CS to be malicious.
The CS can intentionally undermine the integrity of the computa-
tion results, in the hope of not being detected. In the second design,
we assume all the servers are semi-honest. They will follow the
algorithm to execute the communication and computation and may
also attempt to derive meaningful information from the data. We
assume any two of the servers are non-colluding. Such model is
reasonable and can be guaranteed by the co-statement between
cloud service providers in practice [4].
3.3 Design Goals
We aim to provide a secure and efficient outsourcing scheme for
the MRI reconstruction. Several key design objectives are listed as
follows:
Imaging Data Privacy: None of the entities in the CS should
get access to the exact value of the imaging data, including both
of the sampled value and the estimates during the iteration, or can
reconstruct diagnose image based on its accessible data. Besides, in
our first design, the locations where the data are sampled should
also be protected according to the DO’s preference.
Efficiency Gain: In SecSAKE, the time cost for computation on
the DO’s side should be lower than solving the computational
problem by himself. Moreover, any entity in the CS should be able
to compute the problem within the comparable time complexity
with an existing efficient algorithm.
In our first design, the DO should be capable to
validate the correctness of the returned results from the CS in each
loop of the iteration.
Verifiablity:
4 SECSAKE I: SYSTEM DESIGN
In this section, we focus on our first design of SecSAKE. We fol-
low the sequence of operations within one iteration in SAKE, as
illustrated in Section 2. Among all the related computation tasks
in SAKE, we identify two of them are computationally intensive –
SVD in the low rankness projection (Section 4.1 and Section 4.2)
and matrix multiplication in the data consistency projection (Sec-
tion 4.3). Then the approach to verify both of the results is given in
Section 4.4. We follow the same notations in Section 2 to keep the
consistency.
Session 13: Privacy 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea5404.1 Secure Singular Value Decomposition
At the beginning of one iteration of SAKE, the DO aims to securely
outsource the computation of SVD over the complex field to the CS.
Before proceeding to this step, the DO has either 1) just initialized
the first estimate as x0 = D†y, where y is the acquired data or 2)
received the estimate of k-space data xn from the previous iteration
in the (n − 1)th loop. Without loss of generality, we only consider
the second case throughout this section.
Algorithm 1 Secure SVD and Low-rankness Projection
Input: A block-wise Hankel structured data matrix An
Output: The best rank-ˆr approximation of An
0, Λ1 and Λ2 by Equation (6)
0PΛ1AnΛ2Q and send ˜A′
1: Generate η0, η′
2: Generate P and Q by Equation (9)
3: Compute ˜A′
n = η0η′
4: Receive U′, Σ′, V′
5: Compute U′′ = (PΛ1)∗U′, Σ′′ = (1/|η0η
6: Retain the first ˆr columns of U′′, Σ′′ and V′′
7: Compute ˆAn via Equation (13)
n to the CS
0|)Σ′, V′′ = Λ2QV′
′
Firstly, the k-space data xn can be trivially mapped into a data
matrix An with block-wise Hankel structure by enforcing Hw as
illustrated in Section 2. The DO then aims to encrypt the data
matrix An ∈ Cp×q before outsourcing the computation of SVD
to the cloud. In order to to preserve the value privacy and the
structure of data matrix, two random diagonal unitary matrices and
random permutations are applied in this step, respectively. Suppose
the diagonal unitary matrices we use are named Λ1 ∈ Cp×p and
Λ2 ∈ Cq×q, respectively. To construct Λ1 = diaд(λ1, λ2, ..., λp ) and
Λ2 = diaд(γ1, γ2, ..., γq ), on input the security parameter κ, the DO
applies a pseudorandom function Fκ to generate the ratio of real to
the imaginary part of each non-zero entry.
More precisely, we take Λ1 as an example. Denote R(z) and I(z)
as the real part and imaginary part of a complex value z, respectively.
If Fκ is defined over {0, 1}κ × {0, 1}κ → {0, 1}κ , the sequence of
numbers are given as follows:
(cid:113)
(cid:113)
ηl = Fκ (rl , c),∀l ∈ [0, p]
2
l ), I(λl ) = ηl
1/(1 + η
R(λl ) =
1/(1 + η
2
l ),∀l ∈ [1, p]
(6)
˜An = η0η
′
0Λ1AnΛ2
where rl is a random string and c is the constant. Suppose Λ2 has
the same construction and denote the outputs of the pseudorandom
function as η′
k ,∀k ∈ [0, q]. After that, the DO can hide the data
matrix An by
(7)
Besides the matrices Λ1 and Λ2, the DO needs to apply two
random permutation matrices to hide the locations of zero elements.
In brief, two pseudorandom permutations, π1 and π2 are applied to
˜An through multiplications of the matrices P ∈ Rp×p , Q ∈ Rq×q,
i.e.
(8)
where all the non-zero entries in P = (pi, j ) and Q = (qi, j ) are filled
with 1’s, whose positions can be denoted by:
pπ1 (i ), j ,∀i ∈ [1, p], i = j
qπ2 (i ), j ,∀i ∈ [1, q], i = j
˜A′
n = P ˜AnQ = η0η
′
0PΛ1AnΛ2Q
(9)
2
2
(cid:113)1/1 + η
(cid:113)1/(1 + η
l )i. Hence, Λ1Λ∗
1 = PΛ1(PΛ1)∗ = PΛ1Λ∗
Next, we show that both the matrices P1 = PΛ1 and Q1 =
(Λ2Q)∗ = QT Λ∗
2 are unitary matrices. Recall the construction of
Λ1, the complex conjugate of the lth diagonal element is given by
l − ηj
1 = I. According to
λl =
the definition of P, each column is mutually perpendicular and
normalized. Thus P1P∗
1PT = I. In this way,
we can also find Q1 unitary.
The property of the unitary enables the DO to recover the cor-
rect solution of SVD by reversing the matrix transformation. More
precisely, the DO outsources the transformed matrix ˜A′
n to the
CS, who later finds the eigenvalues and eigenvectors of ˜A′
′∗
n ˜A
n
denoted as σ ′ and u′, respectively. With the descending order of
eigenvalues found on the diagonal entries of diagonal matrix Σ′,
the eigenvectors uniquely form the columns of the left-singular
matrix U′. This procedure can be represented by
˜A′
n ˜A′∗
n U′ = η
2
0η
0 (P1AnQ∗
′2
1)(Q1A∗
nP∗
1)U′ = Σ′2U′
(10)
nP∗
Then the equation can be rewritten as
AnA∗
1U′ = (1/η
0 )Σ′2P∗
′2
2
(11)
0η
1U′ and Σ′′ = (1/|η0η
0|)Σ′. It is obvious that U′′
′
and Σ′′ are the left-singular matrix and diagonal matrix containing
the non-increasing singular values of An. Symmetrically, the right-
singular matrix can be computed by the CS as follows:
Let U′′ = P∗
1U′
2
0η
0 )Σ′2Q∗
1V′
′2
A∗
nAnQ∗
1V′ = (1/η
(12)
let V′′ = Q∗
1V′. Then V′′ becomes the right singular matrix of An.
The CS, however, has access to neither P1 nor Q1. Hence, the CS
will send the U′, V′ and Σ′ to the DO. The DO can apply the
reverse transformation to these matrices to get the singular vectors
and values of An.
4.2 Low-rankness and Structural Consistency
Projection
After computing the SVD, the DO needs to enforce the low-rankness
to U′′, V′′ and Σ′′. Suppose the pre-estimated rank value is ˆr. Then
the projection is simply done by deleting columns ˆr + 1, ˆr + 2, ...,
p of U′′, and the columns ˆr + 1, ˆr + 2, ..., q of V′′ and Σ′′. Let Tˆr
be the operator to retain the first ˆr columns of the matrix. Denote
U′′
|| = Tˆr (U′′), V′′
= Tˆr (Σ′′). Then above low-
rankness projection is formulated as a hard-thresholding procedure
and can be formed as
|| = Tˆr (V′′) and Σ′′