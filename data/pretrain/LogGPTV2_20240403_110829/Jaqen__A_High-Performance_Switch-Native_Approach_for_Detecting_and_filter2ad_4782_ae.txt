Update Alloci, j with MCapi, j,k and BCapi, j,k
Output: ∀i, j: Alloci, j
routing decisions and detection results on the controller.
• Eq. (6) captures all the allocated mitigation modules on the
ingress-egress path (d,e) and ensures the attack trafﬁc on
the path has been taken care of.
• Similarity, eq. (7) captures all the allocated modules on the
egress-ingress path to make sure the response trafﬁc has
been handled. Eq. (8) conﬁrms the capacity of allocated
modules does not exceed the processing bandwidth.
Fast mitigation module allocation. We design a greedy
heuristic to achieve real-time mitigation module allocation.
We present the pseudocode of the heuristic in Algorithm 1.
The high-level intuition is the following: For each pair of
ingress and egress that has potential attack trafﬁc, we use
Breadth First Search (BFS) with the given routing decisions
to ﬁnd the attack volume distribution on each of the switches.
We then sort the switches along the path by their hybrid at-
tack volume and allocate the mitigation modules to cover the
largest volumes ﬁrst in a greedy manner.
Updating mitigation modules for dynamic attacks. When
mitigation modules need to change due to dynamic attacks,
Jaqen follows a three-step procedure to update a switch: (1)
Rerouting: the controller disables the ﬁltering components on
all activated switches and then computes and distributes new
forwarding rules with the current switch excluded, in order to
reroute the legitimate trafﬁc on this switch. (2) Replication:
Once the new rules have been applied, replicate the switch
states about the legitimate connections (if not expired) in the
3838    30th USENIX Security Symposium
USENIX Association
Figure 10: L to R: (1) SYN proxy mode 1 workﬂow (2) Abstract P4 code (3) SYN cookie example.
Impl.
Original [20]
Our impl.
322
151
50
46
Match Units
Hash Bits
SRAM Action Slots
133
41
Table 5: Resource utilization of a universal sketch.
245
60
controller. (3) Swapping: reprogram the switch with the new
set of modules and required states. Report to the controller to
include this switch into the forwarding rules.
7 Jaqen Implementation
We have implemented a Jaqen prototype based on Barefoot
Toﬁno using P4-14 for switch modules and using Python for
switch controller. For P4 code compilation, we use Barefoot
P4 Studio SDE [72]. In this section, we brieﬂy describe how
we implement the detection and mitigation API and demon-
strate the convenience for developers to build new defenses.
We open-source the prototype of Jaqen in [73].
Detection API and logic. To implement Query(proto,func
,mode,freq), we need multiple universal sketches [20] and
signature-based counters in the switch data plane. We imple-
ment a universal sketch using a smaller number of ALUs than
its original model implementation. As presented in Table 5,
we achieve better resource efﬁciency by combining redundant
sketch constructions and merge multiple hash computations
and register operations into a single ALU operation. These
optimizations are chosen depending on the speciﬁc resource
numbers from Barefoot Toﬁno switch [12] and the accuracy
guarantees we want to achieve. Thus these conﬁgurations are
subject to change for other types of programmable switches.
When implementing signature-based counters, we write
custom packet parsers to count some particular packets (e.g.,
TCP SYN, ICMP, and UDP DNS requests). Based on the
conﬁgured mode and freq, the counters in the switch will
either be self-reported or pulled by the switch controller. We
will use these counters to compute attack-speciﬁc signatures
(e.g., the number of unacked/terminated SYN requests) based
on detection logic.
Mitigation API. We implement mitigation API using P4 and
macro functions with several underlying structures described
below. We also give an example workﬂow of Jaqen’s SYN
proxy and its abstract code in Figure 10. We refer reads to the
project repository for more examples.
1. Blocked Bloom ﬁlters: We split Bloom ﬁlter’s single array
into multiple registers as a blocked Bloom ﬁlter. This split
will maintain asymptotically the same error bounds [29].
We implement the blocked ﬁlter with one CRC32 hash per
block of 1-bit registers. In each switch pipeline stage, we
parallelize multiple blocks of ﬁlters for resource efﬁciency.
2. Counting Bloom ﬁlters: The goal of CBF is to record the
inserted ﬂow identities while supporting deletions from
the ﬁlter. We implement CBF using an efﬁcient two-part
structure, where the controller maintains a complete CBF
with 8-bit counters and the switch data plane stores an
equivalent bloom ﬁlter with 1-bit registers.
3. LRU cache: We implement a lossy hash table with multi-
layer of Least Recently Used (LRU) caches (r register ar-
rays of d entries). When insertion, we hash the item to
select one of d columns to conduct a rolling replacement
of the r entries in the column by replacing the ﬁrst one
with the new entry, the second with the ﬁrst, the third with
the second, etc. When query, we check if the current item
appears in one of the corresponding r entries in one of the
d columns based on the hash.
4. Key-value store: We implement a key-value store based
on the P4 logic of [68]. We offer a store that stores up to
64K entries with 16-byte keys (up to 64-byte) and 128-byte
values. This store can be used for DNS or ARP caches in
the local network for high-performance lookups.
5. Switch-embedded structures: We leverage the embedded
exact, range, or ternary5 match-action tables (using
SRAM and TCAM) where we specify a set of ﬂow identi-
ties to match and deﬁne the action as allow, drop, rate_limit.
5The term “ternary” refers to the memory’s ability to store and query data
using three different inputs: 0, 1, and wildcard.
USENIX Association
30th USENIX Security Symposium    3839
PacketPacket type?Not TCPVerify cookie RSTSYNMatched cookie?New out-of-windowSYN-ACKNoTo updateAllowListUpdateYesAdd cookie andreply backtablecompute_syn_cookie{ actions { compute_cookie;  }  }actioncompute_cookie( ) {modify_field_with_hash_based_offset( cookie, 0, syn_cookie_hash, 0x80000000);  }field_list_calculationsyn_cookie_hash{input {  syn_cookie_seed;  }algorithm : crc32;output_width: 32;  }field_listsyn_cookie_seed{ ipv4.srcAddr;ipv4.dstAddr;tcp.srcPort;tcp.dstPort;metadata.nonce1;  }#define SYNProxyMode1apply ( check_packet_type); apply ( nonce1 ); apply ( nonce2 );if( pkt_type== RST) {apply ( compute_syn_cookie);apply ( verify_syn_cookie);if( metadata.cookie_diff== 0) {apply ( cookie_match);  }}if ( pkt_type== SYN or( pkt_type== RST andcookie_match)) {apply ( check_or_update_allowlist);}if( pkt_type== SYN andallowlist_match) {apply ( syn_ack_generate);  } apply ( forward );}In ReportCtr and Recirculate, we encapsulate the corre-
sponding P4 copy_to_cpu and recirculation primitives
with the packet header modiﬁer.
Network Controller. The control part of Jaqen is imple-
mented in Python and is connected to the switch control
via RPC. This controller has three major functionalities: (a)
Query statistics from the switch data planes and compute a
detection logic via the detection API and Thrift API [74]; (b)
Run or rerun the resource management heuristic by fetching
current routing information and detection information from
each switch as a global state; (b) Deploy mitigation modules
via RPC to switch control and conﬁgure the stored mitigation
modules via switchd daemon.
8 Evaluation
We evaluate Jaqen extensively on defending prevalent volu-
metric DDoS attacks [18] and demonstrate that:
1. Jaqen’s obtains signiﬁcantly more accurate metrics than
out-of-band sampling approach. Jaqen’s mitigation func-
tions are more salable and effective than Poseidon [3].
2. Jaqen detects DDoS attacks with high accuracy and esti-
mates the volumes of attacks with low errors (< 3%).
3. Jaqen mitigates attacks with high effectiveness — low false
positive and negative rates varying from 0.0 to 0.073.
4. Jaqen adapts to dynamic and variable-sized attacks within
end-to-end 15 seconds with high effectiveness. Our larger
scale network-wide simulator shows that Jaqen returns near-
optimal resource allocation decisions within 1 sec.
Testbed. We deploy Jaqen on a testbed of one 6.5 Tbps Bare-
foot Toﬁno switch and eleven Dell R230 servers (Intel Xeon
E2620 v4, 64GB RAM, 40Gbps Intel Network Interface Card).
For single attack experiments, we use ten 40 Gbps servers to
generate trafﬁc and the remaining one as the targeted victim.
We enable Intel DPDK [75] library on each server to achieve
high-performance trafﬁc generation. When sending legitimate
trafﬁc, we replay one-hour Internet traces from CAIDA [76]
in a loop6, at an aggregated packet rate of 59 Million pack-
ets per second (Mpps). For TCP related attacks, the sender
maintains up to 1,048,576 legitimate TCP connections using
virtual IP addresses. The controller of the switch pulls the
detection result every 5 seconds.
Attack trafﬁc generation. To evaluate Jaqen, we use real-
world attack traces [77, 78] and launch a set of seven repre-
sentative volumetric attacks: (1) To launch SYN ﬂood, we
use MoonGen [79] with DPDK [75] to send SYN requests
with random source IP addresses. (2) To launch ICMP ﬂood
and TCP/UDP elephant ﬂows, we implement custom Lua
scripts to send ICMP, ACK/UDP trafﬁc via MoonGen. (3)
When launching DNS and NTP ampliﬁcation attacks, we
cannot exploit the public DNS and NTP servers to reﬂect the
6When replaying traces, the TCP SYNs are sent without establishing
actual connections.
(a) Errors in example detection tasks.
(b) Entropy-based detection
Figure 11: Comparison with NetFlow [16].
trafﬁc. Instead, we set up local DNS and NTP servers for-
warded to Google public DNS [80] and the server pool from
ntp.org, and the local DNS responses will ﬂood the victim
servers. (4) To launch a Memcached ampliﬁcation attack,
we deploy Memcached [81] onto servers and send GET re-
quests with forged source IPs to the targeted victim.
Evaluation metrics and parameters. In estimating the at-
tack volumes, we use relative error as |detected_vol−true_vol|
,
where detected_vol is the volume reported, and true_vol is
the true volume of attack trafﬁc. In the mitigation, we evaluate
the false positive rate (FPR) and false negative rate (FNR).
FPR is the rate of how much benign trafﬁc is mistakenly
mitigated as malicious trafﬁc (false positives FP), deﬁned as
FP+true_negatives. FNR is the rate of how much malicious traf-
ﬁc is identiﬁed as benign trafﬁc and is not mitigated (false
negatives FN), deﬁned as
FN+true_positives.
true_vol
FP
FN
For every period of time T (e.g., 5 sec in our experiments),
the detection can be pulled by the controller to identify the
occurrence, type, and volume of an attack. By default, if Jaqen
detects the occurrence of the DDoS attacks for two consec-
utive time windows, the resource manager on the controller
will compute the mitigation module allocation and deploy the
needed modules to the switch. Thus, we measure the total
reaction time as |2× T + TRes_allocation + TSo f t_update|.
When conﬁguring the probabilistic structures in the mit-
igation functions, the default blocked Bloom ﬁlters use 7
different hash functions with 44.04M entries (5.25MB mem-
ory). For DNS, NTP, and Memcached ampliﬁcation attacks,
the counting Bloom ﬁlters use 4 different hash functions with
11.01M entries (1.31MB memory) by default.
8.1 Comparison with Existing Solutions
Comparison with NetFlow on detection. NetFlow [16] is a
standard network monitoring tool to conduct out-of-band net-
work trafﬁc analysis. Despite its processing delay in handling
large batches of sampled packets, we compare the accuracy of
ﬁve different DDoS-related detection tasks between Jaqen and
NetFlow using two real-world attack traces [77, 78]. The tasks
include T1: Unique source IPs, T2: Distinct 5-tuple ﬂows, T3:
Unique SYN connections, T4: Top sources in volume, and
T5: Top victims in volume. We conﬁgure the sampling rate
of NetFlow as 1/100 in order to keep up with the line-rate
and low detection delay. Note that at this sampling rate, Net-
Flow stores a large number of packets and uses signiﬁcantly
3840    30th USENIX Security Symposium
USENIX Association
T1T2T3T4T5Detection Tasks0.00.20.40.60.8Relative ErrorsNetFlowJaqen020406080100Time (s)051015Estimated EntropyAttack detectedTrue valueJaqen valueNetFlow valueDefense (40G)
SYN proxy
DNS/NTP defense
Poseidon (FPR / FNR)
2M, 25.2% / 1.3%
2M, 1.2% / 3.7%
Jaqen (FPR / FNR)
2M, 0.0% / 1.3%
2M, 0.7% / 3.1%
Table 6: Jaqen vs. Poseidon on defense effectiveness.
more memory space than Jaqen. As shown in Figure 11(a),
Jaqen’s sketch-based detection has better accuracy than Net-
Flow across the tasks.
To evaluate entropy-based detection, we generate an HTTP
ﬂood attack. We manually inject source IPs from 50 randomly
picked subnets and a range of victims that share a single 16-bit
subnet. To launch the attack, we replay the Internet trace [76]
with 70% probability to replace a packet with an attack packet.
As presented in Figure 11(b), Jaqen captures the changes in
the source IP entropy values and detects the occurrence of the
attack, while NetFlow cannot accurately track the changes in
the entropy values.
Comparison with Poseidon on mitigation. Poseidon[3] de-
signs a hybrid DDoS mitigation solution with programmable
switches and x86 servers. In handling 40Gbps volumetric
attacks with 2M legitimate connections, both Poseidon and
Jaqen can operate at the line-rate with µs-level latency, show-
ing the promise of programmable switches. Further, we com-
pare the mitigation FPRs/FNRs of the two approaches. With
Poseidon [3], we conﬁgure their SYN proxy to use a large
session table of size 221 (8MB SRAM) while Jaqen uses
1.31MB SRAM. The monitor of Poseidon for DNS defense
has a Count-Min sketch and we conﬁgure it to the same num-
ber of counters for both approaches. As reported in Table 6,
Jaqen has a signiﬁcantly better FPR (0% vs. 25.2%) than
Poseidon in SYN proxy using 6× less memory. In handling
DNS attacks, Jaqen’s defense strategy (Figure 7) is more ef-
fective in reducing the FPR/FNR. We envision that Jaqen will
support more sophisticated mitigation strategies to reduce the
FPR/FNR for other attacks using the mitigation API.