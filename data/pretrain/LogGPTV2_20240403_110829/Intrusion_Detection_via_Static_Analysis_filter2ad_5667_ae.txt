We have  also  examined the generated models by  hand 
to evaluate  how  much harm  a sophisticated attacker  could 
cause using  mimicry  techniques.  We  are confident that  all 
three of  the  f i n g e r  models leave  very  little  room for at- 
tack, due to the fact that the f i n g e r  source code does lit- 
tle  else but  open a  network  connection and access world- 
readable files on the system.  Results for the other applica- 
tions, though, are mixed. The digraph model seems unlikely 
to resist  a mimicry attack, and generally we feel  it should 
not be relied  upon  for defense against malicious code spe- 
cially  tailored  to  fool  our system.  However, the  abstract 
stack model  seems to do fairly  well:  we  believe  it  would 
successfully limit the harmful effects of any compromise in 
qpopper or procmail. On the other hand, for sendmail, 
the generated abstract stack model is too complex for us to 
make any determination. 
We consider it an  important open problem to develop a 
metric or methodology for quantifying the resistance of in- 
trusion detection systems to unforeseen attacks, such as the 
mimicry attacks introduced above. 
Attacks detected  We have tested our system on a number 
of known attacks from the past decade or so.  For instance, 
each of the four applications discussed above has a known 
security vulnerability; we  confirmed  that  we  were able to 
detect the known attack on those applications. 
Probably  the  most  common class  of  attacks we  detect 
are buffer overruns, which seem to account for perhaps half 
of  all  attacks in recent years [S,  351.  Because most exist- 
ing  exploit  scripts  grab full  root  privilege  and  take  other 
distinctive actions (such as launching a shell  under the at- 
tacker’s control)  immediately after exploiting the  overrun 
vulnerability, detection is typically  straightforward for our 
tool. Our tool may even be overkill for detecting misbehav- 
other systems will  also detect these 
ior this blatant-many 
attacks, albeit with substantial false alarm rates-but 
an un- 
usual feature of our tool  is that  it is also designed to detect 
some ‘stealthy’ attacks, as well. 
Our  approach  is  also  able  to  detect  Trojan  horses  in 
trusted software.  One current favorite  of today’s attackers 
is the r o o t k i t  toolkit, which  replaces some system utili- 
ties  with  a  version  that  contains a  backdoor.  We  verified 
that  our implementation was  able to detect when  some of 
these backdoors were exercised (which causes the behavior 
to deviate from that specified by the original source code). 
The most interesting feature of our approach is that it can 
also detect more exotic attacks, even ones that the designers 
themselves did not know about. For instance, one extremely 
subtle attack exploited the ability to pass environment vari- 
ables to t e l n e t d  to cause the dynamic linker to link with a 
shared library provided by the adversary; our system would 
have  detected  this  attack,  and  any  other  dynamic-linking 
attack that  might be  discovered in  the future, because our 
model is generated statically  with the correct library. More 
recently,  format  string  attacks have  provided  another  un- 
expected way  to  introduce malicious code into vulnerable 
applications; since our detection mechanism makes no as- 
sumptions about  how  malicious  code may  be  introduced, 
we can expect our system to apply to format string attacks, 
as well  as to any  other ways to take control of  vulnerable 
applications that may be discovered in  the future.  We feel 
that  these examples illustrate  the  importance of  detecting 
unforeseen attacks. 
Despite  these  successes, we feel strongly that  our tool 
should not be used as the sole defense against any of these 
attacks,  but  instead  should  be  used  to  complement  other 
techniques.  Prevention  is  often  a  more  effective  barrier, 
and intrusion  detection systems are usually  best  viewed as 
a backup layer in case the main line of defense is breached. 
7. Future work 
This work opens up many  avenues for future research. 
The main  limitation  of  our  approach  is  that  the  run-time 
overhead  is  very  high  for  some  automata;  however,  we 
expect that  we could achieve better performance by  using 
more advanced static  analysis to get more precise  models. 
Also, the prototype was written in Java; we could recode our 
system in C or assembly language and directly  integrate  it 
into the operating system kernel to reduce the performance 
overhead substantially.  This work  also raises the  intrigu- 
ing possibility  of reusing the specification  that we generate 
to  automatically  verify  properties of  security-critical  pro- 
grams with  a  model  checker.  We  note  that  our  callgraph 
model  is a finite automaton that  appears nearly  ideal  for a 
model checker.  Our stack model will be more challenging 
to model check, but there has been theoretical  work in this 
area [5, 13, 32, 36,41. 
8  Conclusions 
We have successfully applied static program analysis to 
intrusion detection. Our system scales to handle real  world 
programs.  Also,  our approach is automatic:  the  program- 
mer or system administrator merely needs to run  our tools 
166 
on  the.program at  hand.  All  other automatic approaches 
to intrusion detection  to date have  been  based on statisti- 
cal inference, leading to many false alarms; in contrast, our 
approach is provably  sound - when  the alarm  goes off, 
something has definitely gone wrong. Nonetheless, we can 
immediately  detect if a program behaves in an  impossible 
(according to its source) way, thus detecting intrusions that 
other systems miss. 
We  relied on a  strategic combination of static analysis 
and dynamic monitoring.  This combination yields better 
results than either method alone and presents a promising 
new approach to the intrusion detection problem. 
Acknowledgements 
We thank Alex Aiken, Nikita Borisov, Eric Brewer, Jeff 
Foster, David Gay, Steve Gribble, Alan Hu, Adrian Perrig, 
and Dawn Song for useful discussions about this work. 
References 
J. :P. Anderson.  Computer security  threat  monitoring  and 
surveillance. Technical report, James P. Anderson Company, 
Fort Washington, Pennsylvania, April  1980. 
S. Axelsson.  The base-rate  fallacy and its implications for 
the difficulty  of intrusion  detection.  In Proceedings of the 
6th ACM Conference on Cornpurer and Communications Se- 
curiry, 1999. 
M.  Bernaschi,  E. Gabrielli, and L. V.  Mancini.  Operating 
system enhancements to prevent the misue of system calls. 
in Proc. ofihe 7th ACM Conference on Computer and Com- 
munications Securify, pages  1 7 6 1  83, Athens, Greece. 
A. Bouajjani, B. Jonsson,  M. Nilsson, and T. Touili.  Reg- 
ular model  checking.  In  12th Computer Aided  Verificaiion. 
Springer-Verlag, 2000. 
0. Burkart.  Automatic  verijcaiion of  sequeniial  infniie- 
state processes, volume 1354 of Lecture Noies in Computer 
Science.  Springer-Verlag, 199 1. 
T.  Colcombet  and  P.  Fradet.  Enforcing  trace  properties 
by  program  transformation. 
In  Proceedings  of  ihe  27ih 
ACM Symposium on Principles of Programming  Languages. 
ACM, 2000. 
P. Cousot and R. Cousot.  Temporal abstract interpretation. 
In Proceedings  of  the  27th ACM  Symposium on Principles 
of Programming  Languages. ACM, 2000. 
C. Cowan,  P.  Wagle,  C. Pu,  S. Beattie,  and  J.  Walpole. 
Buffer overflows: Attacks and defenses for the vulnerability 
of  the decade.  In Proc.  2000 DARPA  Informaiion  Surviv- 
ability Con$  and Exp. (DISCEX '00). pages 154-1  63. IEEE 
Comp. Soc., 1999. 
D. E. Denning.  An intrusion-detection  model.  IEEE Trans- 
acrions on Soffware Engineering, 13(2), February  1987. 
J. Earley. An efficient context-free parsing algorithm. Cotn- 
municutions of the ACM, 13:94-102,  1970. 
167 
[I I]  M. Emami, R. Ghiya, and L. J. Hendren.  Context-sensitive 
interprocedural points-to analysis in the presence of function 
pointers.  In Proceedings of the SIGPOIN  '94 Conference on 
Programming  Lanugage Design and Implementation, pages 
242-256.  ACM SIGPLAN, 1994. 
[I21  M. D. Ernst, J .   Cockrell, W.  G. Griswold,  and D. Notkin. 
Dynamically discovering  likely  program  invariants to sup- 
port program evolution. IEEE Transaciions in Soffivare En- 
gineering, 27(2): 1-25,  Feb. 2001. 
[I31  A. Finkel, B.  Willems,  and P.  Wolper.  A direct symbolic 
approach to model  checking pushdown  systems.  Electronic 
Notes in Theoretical Computer Science, 9, 1997.  Proceed- 
ings of Infinity'97. 
[I41  S. Forrest, S. Hofmeyr, A. Somayaji, and T. Longstaff.  A 
sense of self for unix processes. In Proceedings 1996 IEEE 
Symposium on Security and Privacy, 1996. 
[I51  I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer.  A 
secure environment for untrusted  helper applications: Con- 
fining the wily hacker. In Sixih USENIX Securiy S?mposium 
Proceedings, pages 1-12,  San Jose, CA, July  1996. 
[I61  S.  Graham,  M.  Harrison,  and  W.  Ruzzo.  An  improved 
context-free recognizer.  ACM  Transactions  on  Progrum- 
ming Languages and Swiems, 2(3):415-462, July  1980. 
[I71  N. Heintze and J. G. Riecke. The SLam calculus: program- 
ming  with secrecy and integrity.  In Conference Record of 
the Twenty-Fifih Annual ACM  Symposium on Principles of 
Programming  Lnnguages, pages 365-377.  ACM, 1998. 
[18]  J .  E. Hopcroft  and J. D. Ullman.  Introduction  IO  auiomaia 
iheory, languages, and computation. Addison-Wesley, 1979. 
[ 191  C. KO. E-recurion Monitoring of  Securiry-Crirical Programs 
in  Disiributed  Systems:  A  Spec8caiion-based Approach. 
PhD thesis, U.C. Davis, September 1996. 
[20]  C. KO. Logic induction  of valid behavior specifications for 
intrusion detection.  In Proceedings of  the 2000 IEEE Syn- 
posium on Security and  Privacy, pages  142-153,  Oakland, 
CA, May 2000. IEEE. 
[21]  C. KO, G. Fink, and K. Levitt.  Automated detection of vul- 
nerabilities  in privileged programs by execution monitoring. 
In Proceedings of  the Tenih Compuier Security Applications 
Conference, pages  134-144,  Orlando, FL, Dec.  1994. IEEE 
Computer Society Press. 
[22]  C. KO, M. Ruschitzka,  and  K.  Levitt.  Execution  monitor- 
ing of  security-critical programs in  distributed  systems:  A 
specification-based  approach.  In Proceedings  of  the  1997 
IEEE Symposium on Securic and Privacy, pages  175-1 87, 
Oakland, CA, May  1997. IEEE. 
municaiions ofihe ACM, 16(10):613-615,  Oct. 1973. 
[23]  B. W. Lampson. A note on the confinement problem.  Coin- 
[24]  G. Morrisett, D. Walker, K. Crary, and N. Clew.  From sys- 
tem F to typed  assembly language.  ACM  Transaciions on 
Programming  Languages and Systems, 2 1 (3):527-568,  May 
1999. 
[25]  G. C. Necula.  Proof-carrying  code.  In Proceedings ofihe 
24ih ACM  SIGPLAN-SIGACT Symposium on Principles of 
Programming  Languages, pages  106-1  19, Jan. 1997. 
[26]  T. H. Ptacek and T. N. Newsham.  Insertion, evasion, and de- 
nial of service:  Eluding network intrusion detection.  Tech- 
nical report, Secure Networks, January  1998. 
[27]  T. Reps, S. Horwitz, and M. Sagiv.  Precise interprocecural 
dataflow analysis via graph reachability.  In Proceedings of 
the 22nd  ACM  Symposium  on  Principles of  Programming 
Languages. ACM, 1995. 
[28]  D. A. Schmidt. Data flow analysis is model checking of ab- 
stract interpretation.  In Proceedings of  rhe 25th ACM  Sym- 
posium  on  Principles  of Programming  languages.  ACM, 
1998. 
[29]  F. B. Schneider. Enforceable security policies. Technical Re- 
port 98- 1664, Comell University, Department of Computer 
Science, Cornell University, Ithaca, NY,  14853, Jan. 1998. 
[30]  M.  Shapiro  and  S.  Horwitz.  Fast  and  accurate  flow- 
insensitive  points-to analysis.  In  Proceedings of rhe  24th 
ACM  SIGPLAN-SIGACT Symposium on Principles of  Pro- 
gramming Languages, pages 1-14,  Jan. 1997. 
[31]  B.  Steensgaard. 
Points-to  analysis  in  almost  linear 
time.  In  Conference Record  of  the 23rd ACM  SIGPLAN- 
SIGACT  Symposium  on  Principles  of Programming  lan- 
guages  (POPL’96), pages  32-41,  St. Petersburg, Florida, 
Jan. 21-24,  1996. ACM Press. 
[32]  B. Steffen and 0. Burkart.  Model checking the full modal 
mu-calculus  for  infinite  sequential  processes.  Theoreti- 
cal  Cornputer  Science  (TCS), 1999.  Special  Issue  for 
lCALP’97, to appear August 1999. 
[33]  M. Tomita.  An efficient augmented-context-free parsing al- 
gorithm. Cornputational  Linguistics,  13( l-2):31-46,  1987. 
[34]  D. Wagner.  Static  analysis  and  computer security:  New 
techniques for sofhvare  assurance.  PhD thesis, University 
of California at Berkeley, Dec. 2000. 
[35]  D.  Wagner,  J.  S. Foster, E.  A. Brewer,  and  A. Aiken.  A 
first step towards automated detection of buffer overrun vul- 
nerabilities.  In Proceedings 2000 Network and Distributed 
System Security Symposium. Internet Society, 2000. 
U61  P. Wolper  and B. Boigelot.  Verifying systems with infinite 
but regular state spaces. In Computer Aided Ver$cation  ’98, 
pages 88-97.  Springer, 1998. 
[37]  D. H. Younger.  Recognition and parsing of context-free lan- 
guages in time n3. Information and Control, lO(2): 189-208, 
1967. 
168