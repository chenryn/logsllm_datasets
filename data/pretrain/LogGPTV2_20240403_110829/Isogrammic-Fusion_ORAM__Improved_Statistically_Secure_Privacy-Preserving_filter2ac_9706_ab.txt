access sequence to be isogrammic, so that we can then make our
accesses oblivious using our isogrammic OS scheme. In particular,
let us apply a simple scheme inspired by an observation of Wang
et al. [21], where we reference each node in R using a random key
comprising Θ(log n) bits. That is, for each node, u, in R, we store a
random nonce, ru, comprising Θ(log n) bits, which is replaced with
a new random nonce each time we access u. Initially, each node u
in R is given an initital random nonce, ru, which is stored at u and
is chosen uniformly and independently in the range from 0 to nc,
for some constant, c ≥ 3. Furthermore, for each node w in R that
is an internal node, we store at u the random nonces for u’s two
children, as well as the indexing information to support our doing
binary searches in R to search for a given index, i, from the root to
the leaf cell for index i.
Initially, we create the nodes in R according to a standard bottom-
up binary tree construction algorithm, so that when we create a
node, u, we assign it to have a freshly-chosen random nonce, ru. In
addition, since we are constructing R using a bottom-up algorithm,
at the time we create u, we know the random nonces for u’s two
children, x and y; hence, we can store these values at u. In terms
of our associated isogrammic sequence, then, when we create an
internal node, u, we issue a put(k, v) operation, where k = (ru , u)
and v = (I , rx , x, ry , y), and I is the indexing information that
allows us to do binary searches (e.g., the smallest index for u’s right
child, y). If u is a leaf, then we issue a put(k, v) operation, where
k = (ru , u) and v = (i, V ), and V is the data value that is stored
at the memory cell, i, for this leaf. Note that none of these put
operation can cause an error due to there already being an item
present with the given key, k, since each key, (ru , u), is unique.
Moreover, each such key also comprises O (log n) random bits. We
also create and maintain a global variable that stores the random
nonce for the root.
Suppose, then, that we are to process a read(i) or write(i, v)
operation in Alice’s access sequence, converting it to a sequence
of (isogrammic) put(k, v) and get(k ) operations. We perform a
binary search in R, for the index, i, beginning by reading the
global variable storing the random nonce, ru, for the root, u, of
R and issuing an operation, get((ru , u)). This get operation returns
the contents of the memory record for the root, which has the
form v = (I , rx , x, ry , y), where I is the index that allows us to
determine, based on i, if we should continue searching at x or
at y. Suppose, without loss of generality, that we should next
search at x. Before we continue our search at x, we push the
record, (I , u, rx , x, ry , y), onto a stack stored at the server, using
our isogrammic stack implementation, to keep track of our search
path in R. Next, we issue an operation, get((rx , x )), and we repeat
the above search steps until we reach a leaf node in R. Once we
have the data for the leaf node at index i, Alice performs whatever
steps of her algorithm, A, required for i.
Next, we rebuild the path that we just searched in R, giving
each node in this path a new random nonce, issuing a sequence
of O (log n) get(k ) and put(k, v) operations. Specifically, we first
give the leaf node, u, in R, at index i, a new new random nonce,
ru. Also, let V be the data value for this cell as determined by
this step in Alice’s algorithm, A. Then we issue an operation
put(k, v), where k = (ru , u) and v = (i, V ). Next, we pop the
top record, (I , u, rx , x, ry , y), from the stack stored at the server,
using our isogrammic stack implementation. Suppose, without loss
of generality, that we had next gone to the node x when we first
encountered this node u. Then we create a new random nonce, ru,
for the node u. Also, we can know at this point the random nonce,
rx , for the new child node, x, we just created for u, and from the
record we just popped off the stack, we can recall the random nonce,
ry, for the other child, y, of u. At this point, therefore, we issue a
put(k, v) operation, where k = (ru , u) and v = (I , rx , x, ry , y). Note
that this put operation cannot cause an error due to there already
being an item with key k. Furthermore, note that this pattern of put
and get operations reveals no information about Alice’s data values
or memory indices, since these operations form a data-oblivious
pattern that consists of a sequence of get operations (to search down
the tree R) followed by a sequence of put operations (to rebuild this
search path in R using new random nonces), and each sequence
contains exactly log n operations. We repeat the above computation
in this way until the stack is empty, at which point we store in
our global variable the information for the root. Also, note that
by using this global stack at the server, we can implement each
step of this algorithm using O (1) client-side memory, as well as
O (1)-sized messages. Our ORAM simulation continues in this way,
so that each step in Alice’s algorithm, A, involves a root-to-leaf
traveral in R followed by a leaf-to-root replacement of the nodes
and nonces we just “used up.” This pattern of functionality reveals
no information about Alice’s data values or memory addresses
and each key includes a random nonce chosen uniformly and
independently at random from a key space of polynomial size,
since the key used for each put operation includes a random nonce
comprising Θ(log n) bits. Furthermore, note that each get operation
is indexed using a key that we know was issued by a previous put
operation. Thus, the resulting sequence is isogrammic.
Theorem 1. Given a RAM algorithm, A, with memory size, n,
where n is a power of 2, we can simulate the memory accesses of A
using an isogrammic access sequence that initially creates O (n) put
operations and then O (log n) get and put operations for each step
of A. Moreover, each key used in a get or put operation comprises a
random nonce of Θ(log n) bits.
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea7011/2
) bits.
3 FUSION-TREE OS FOR SMALL SETS
The main “inner-loop” component of our algorithms is an adap-
tation of the binary-tree ORAM method of Damgård et al. [6] to
fusion trees and to the OS setting. Our construction applies only
for small sets, however, because fusion-tree nodes need to address
other fusion-tree nodes using just O (w
Initially, we start with a fusion tree, F, with an address space of
potential total size O (n), which stores any initial set of elements,
such that the nodes of F are stored in an array of size n whose
elements are randomly shuffled, using a data-oblivious shuffling
algorithm (e.g., see [1, 6, 10, 12]). In addition, we store in the
same array as the nodes of F a singly linked list of Dn′ “dummy”
nodes, which have the same size as fusion-tree nodes and are
randomly shuffled with the nodes of the fusion tree, F, where
D = 2⌈log n/ log w⌉ is the depth of F and n′ is the number of
initial items. We store a global header pointer for F that points to
the next unused dummy node in this linked list. This initialization
can occur, for example, as a part of a global initialization of multiple
such fusion trees.
Each cache, Ci, contains two types of nodes:
We have a hierarchy of arrays, C1, C2, . . ., Cℓ, which serve as
caches, where ℓ is O (log n), such that each cache, Ci, contains
⌈n/2i⌉ (D + 1) real and dummy nodes stored in a shuffled order.
The last cache, Cℓ, contains O (log2
n/ log w ) nodes. Initially, these
caches are empty, but as the simulation progresses, these caches
will be constructed and shuffled.
• A fusion tree node, v, which is a node belonging to our fusion
tree, F, and is in the cache Ci due to v being accessed in a previous
simulation step. If v is an external node, then it contains an item
from our set, S. Otherwise, if v is an internal node, then it contains
1/2
the O (w
) compressed keys to identify its children, as well as
1/2
) pointers to the fusion tree nodes for these children. We
O (w
maintain the invariant that each of these children nodes are stored
either in F or in a cache, Cj, such that j ≤ i. Because lower-indexed
caches are always “older” than higher-indexed caches, we can
maintain this invariant every time we build and shuffle a cache.
There are at most n/2i fusion tree nodes in any cache, Ci.
• A dummy node, v. The other type of node in a cache, Ci, is a
dummy node. Each dummy node has the same size as a fusion-tree
node and these dummy nodes are linked to form a single simply
linked list of dummy nodes in Ci, which are stored in random
locations in the array for Ci, due to Ci having been randomly
shuffled. We store a header pointer for each Ci (at a fixed location
for Ci at the server) and any time we need to access a dummy node
in such a Ci for the sake of obliviousness, we follow this header to
the next available dummy node. Once we read this dummy node, we
then update this header to point to the next unused dummy node
in the linked list (using the pointer stored in the node we would
have just accessed). Likewise, for the sake of obliviousness, even
if we are accessing Ci to lookup a fusion node, we first access this
global header for dummy nodes, then we lookup the fusion node,
and then we do a write back to this header node (to write back its
unchanged value in way that the server cannot tell is different to
our writing back a changed value as if we just accessed a dummy
node). The number of dummy nodes in Ci is set to make the total
size of Ci be ⌈n/2i⌉ (D + 1).
To perform a put(k, v) or get(k ) operation, we traverse a path
in F from the root to the leaf that is either holding k (in the case
of a get(k ) operation) or is the location where we would need to
add a new item (in the case of a put(k, v) operation). In addition, to
maintain the balance of F, we may need to access other nodes, but
the number will always be O (log n/ log w ), and we can pad this set
with dummy nodes so that it is always the same number, D (for the
sake of obliviousness). Let π denote the set of D = O (log n/ log w )
nodes that are traversed. After performing the search for the set,
π, of D nodes in F (possibly padded with dummy nodes), we store
all the nodes in π in Cℓ, and we obliviously shuffle Cℓ. In a general
step of the algorithm, we are interested in performing an search
for some key, k, in F, following a search set, π, of nodes in F (plus
dummy nodes as needed to make the number exactly D). At the
time of this search, each node for the search set, π, is stored in one
of the caches C1, . . . , Cℓ, or in the bottom level in F. The root of F,
which forms the first node in π, is stored in a global location in Cℓ
(e.g., Cℓ[0]). So we begin by reading the root, r, of F from Cℓ.
For each node, u, that we discover in π (starting with u = r), we
do a comparison with our key k to determine which child of u we
should read next (for our search). This node is either in one of the
caches or the bottom level in F, and at this point we now know
the exact location for this child, x, of u. Nevertheless, for the sake
of obliviousness, we perform a read in each of Cℓ to C1 and also
the bottom level for F. If such a lookup is for a cache (or F) that
does not contain x, then we do a lookup for the next dummy node
in this cache (or F), and if this cache (or F) contains x, we do the
lookup for x. We repeat his sequence of lookups for each node in
the search/update set, π, and for each one we add it a queue, Q,
stored at the server. Once we have reached the leaf in F for k, Alice
performs whatever internal computation for k (e.g., for her RAM
algorithm), and we then repeat this entire lookup procedure for the
next access that Alice makes. Thus, this approach fully obfuscates
each get or put operation. Also, Alice performs O (log2
n/ log w )
I/Os between herself and Bob for each such access.
Each time Alice has performed (n/2i )D lookups in a cache Ci
(that is, she has done n/2i accesses in her OS sequence since Ci
was constructed), then she does a rebuild action. If the rebuilding
is for C1, then she re-initializes the entire structure. If it is for some
Ci, for i > 1, then she obliviously shuffles Ci with Ci−1, leaving
Ci empty and merging all its fusion nodes into Ci−1, obliviously
adding a sufficient number of dummy nodes to bring the total size
of Ci−1 to be ni−1 = (n/2i−1
)(D + 1). The details for this procedure
are based on using oblivious-sorting, but the important thing to
observe is that it runs with an overhead of O (log ni ), if M is O (1)
(e.g., see [1, 6, 10]), and an overhead of O (1) if M is O (nϵ
i ), for some
constant 0 < ϵ ≤ 1/2 (e.g., see [12]). Moreover, these bounds hold
with probability 1 − 1/2O (w ), since we can do such shuffling steps
by sorting n random numbers of O (w ) bits each.
√
Theorem 2. Suppose we have a set, S, of n ≤ 2
w items. Then we
can perform an OS for S that has an I/O overhead that is O (log3
with O (1)-sized client private-memory, or O (log2
n/ log w ), with
O (nϵ )-sized client private-memory, for a constant 0 < ϵ ≤ 1/2.
In either case, messages are of constant size. This simulation is statis-
tically secure, even for non-isogrammic access sequences, and the I/O
overhead bounds hold with probability 1 − 1/2O (w ).
n/ log w ),
Session 16: Applied Crypto 2ASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea7024 OUR ISOGRAMMIC OS ALGORITHM
In this section, we describe our isogrammic OS algorithm, which
has an I/O overhead of O (log n log log n) or O (log n), depending
on whether M = O (1) or M = O (logϵ n), for some constant
0 < ϵ ≤ 1/2. So suppose we wish to support a data set of size
O (n) subject to put(k, v) and get(k ) operations that come from an
isogrammic access sequence. Recall that the keys used in such an
access sequence have O (log n) random bits, that is, O (w ) random
bits, since w = Θ(log n). We use the random part of each key as the
primary index for each key.
Our primary data structure for implementing an oblivious stor-
age for isogrammic access sequences is a static complete fusion tree,
H, for S, stored at the server, Bob, which has O (n/ logc n) leaves,
numbered from 0 to O (n/ logc n), where c ≥ 3 is a chosen constant.
Each node, u, of H has an associated “bucket,” bu, of capacity 4L,
where L = Θ(logc n), which is maintained using the fusion-tree OS
scheme described above in Section 3. Note that we can apply this
method for each such bucket, because the number of items ever
stored in any such bucket is O (logc n). Let W = ⌈w
1/2⌉ be the arity
of our fusion tree, H, so each internal node of H has W children.
Let us further assume we have constructed H so that each root-