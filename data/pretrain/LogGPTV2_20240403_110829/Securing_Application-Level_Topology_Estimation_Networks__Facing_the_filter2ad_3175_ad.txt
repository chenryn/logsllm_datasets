30% attackers 0.96 0.05 0.94 0.08 0.85 0.14
10% attackers 0.99 0.03 0.98 0.03 0.92 0.16
20% attackers 0.99 0.01 0.99 0.01 0.96 0.07
30% attackers 0.99 0.014 0.99 0.013 0.94 0.11
Table 4. PlanetLab - Complex Scenarios - Classiﬁcation Results
(a) Two Attack Scenarios
Attack Strategy
C4.5
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
10% attackers 0.93 0.07 0.94 0.06 0.83 0.16
20% attackers 0.88 0.11 0.89 0.10 0.86 0.13
30% attackers 0.93 0.07 0.91 0.08 0.87 0.13
10% attackers 0.95 0.05 0.95 0.05 0.92 0.085
20% attackers 0.97 0.03 0.96 0.04 0.90 0.095
30% attackers 0.97 0.03 0.97 0.03 0.89 0.11
10% attackers 0.92 0.078 0.915 0.085 0.80 0.20
20% attackers 0.89 0.11 0.90 0.09 0.84 0.16
30% attackers 0.91 0.09 0.93 0.07 0.85 0.15
Deﬂation -
Boiling
Oscillation -
Inﬂation
Network-Partition -
Oscillation
(b) Sequence Attack Scenar-
ios
C4.5
SimpleCart
LibSVM
TPR FPR TPR FPR TPR FPR
A 0.93 0.83 0.93 0.65 0.93 0.93
B 0.95 0.95 0.94 0.52 0.95 0.95
C 0.86 0.26 0.84 0.31 0.78 0.78
D 0.87 0.21 0.89 0.22 0.73 0.71
E 0.95 0.06 0.96 0.05 0.95 0.06
F 0.87 0.14 0.88 0.12 0.80 0.19
Complex Attack Strategies. In addition, we also evaluate the more complex sequences
as shown in Table 4. Table 4(a) provides results for the two-attack sequences. We note
that, similar to the single attacks, the results for support vector machines are much
improved for PlanetLab over the simulator. However, the opposite is true for the two
decision trees, which did not perform as well on PlanetLab as they did for the sim-
ulations, especially for the 20% and 30% of malicious nodes. Overall, the results are
still satisfying though, as the TPR is around 90% and the FPR does not exceed 11%.
Table 4(b) illustrates the classiﬁcation results for the sequence attack strategies.
Local Classiﬁcation. Furthermore, we also analyze PlanetLab results when each indi-
vidual node decides locally if an attack is taking place or not based only on its individ-
ual information. We show the results in Figure 8. We illustrate the C4.5 classiﬁcation
technique, as it outperforms LibSVM, has similar performance to SimpleCart, and has
been widely adopted. Similar to the simulations, we evaluate the results when there
are 10% malicious nodes and for a set of ﬁfty randomly chosen nodes to have again
a statistical overview of the data. To illustrate the evaluation we again use box-and-
whisker-diagrams.
(a) Single attacks -TPR
(b) Two attacks -TPR
(c) Sequences - TPR
(d) Single attacks - FPR
(e) Two attacks - FPR
(f) Sequences - FPR
Fig. 8. PlanetLab Local Results
Figure 8 illustrates that C4.5 has a very high TPR in all the diﬀerent attack strate-
gies, which mirrors the results for the global classiﬁcation. We also see that sequences
A and B have high FPRs, which is similar to the global classiﬁcation. Overall, except
for sequences A and B, the results have good FPRs. This shows that the deﬁned classi-
ﬁcation technique also work on a local basis when applied on a real Internet testbed.
6 Related Work
Anomaly detection has been extensively leveraged in developing intrusion detection
systems [7, 19, 22], where for instance Bolzoni et al. [7] showed how to automatically
and systematically classify detected attacks. The main idea was to compute similarities
of the payloads of attack data, and later classify it automatically, semi-automatically,
and even manually. One proposed method used support vector machines [36] and a
rule learner algorithm for classiﬁcation. While support vector machines have proved
to be eﬃcient (when tuned properly), in our case, we were surprised to discover that
their potential usage was quite limited, despite extensive tuning with the most common
kernel functions parameter calibration. This anecdotally conﬁrms Sommer et al.’s [33]
 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEF 0 0.2 0.4 0.6 0.8 1Boil.Defl.Osc.Infl.Part.Ran. 0 0.2 0.4 0.6 0.8 1Defl/BoilOsc/InflPart/Osc 0 0.2 0.4 0.6 0.8 1ABCDEFﬁndings that Machine Learning techniques have often not been successful in real-world
IDS applications due to that a detected anomaly does not immediately imply an attack.
One major problem with any detection framework is given by the small drifts that might
slowly bias the detection process. Repetitive training [14, 25] might be a general solu-
tion for decreasing the ratio of false positives, but in our work we show that such a
process is not necessary for securing virtual coordinates systems.
Virtual coordinate systems have been protected against attacks in the past in sev-
eral diﬀerent ways. Kaafar et al. [20] use a trusted node set and anomaly detection
using a Kalman ﬁlter to detect and discard malicious updates. Zage et al. [37] also
use anomaly detection, but focus on a decentralized VCS without any trusted compo-
nents. Outlier detection is performed by setting two diﬀerent thresholds, a spatial and
respectively a temporal one. Furthermore, Veracity [32] is a decentralized VCS that in-
troduces the notion of a veriﬁcation set. Each node maintains a veriﬁcation set where
several other nodes attest to whether a particular update increases their estimation er-
ror above a certain threshold, and if so, ignores it. We note, as described in Section 2,
that all of these proposed systems have been shown to be insecure against the frog-
boiling attack [10, 11]. Frog-boiling attacks have been mitigated before in a diﬀerent
context by ANTIDOTE [31]. ANTIDOTE is a principal component analysis-based poi-
soning attack detector that constructs a low dimensional subspace which reﬂects most
of the dispersion in the data. The required computations are relatively expensive and
assumes an existing multidimensional input space. Such assumptions do not hold in
our case, where we had ﬁrst to map the one dimensional data to a higher dimensional
space (which is the opposite of ANTIDOTE’s subspace construction) and then rely on
an eﬃcient and online decision mechanism.
7 Conclusion
In this paper, we have addressed the detection of diﬀerent types of attacks against vir-
tual coordinate systems. A detection method is presented for the known attacks, such
as inﬂation, deﬂation and oscillation, as well as the recently identiﬁed frog-boiling and
network-partition attacks. Besides these existing attacks, we have elaborated more com-
plex attack strategies, the single-random attack scenario, two attack scenario, and se-
quence attack scenario. We have proposed, as a detection method, to apply supervised
machine learning techniques that leverage decision trees, namely SimpleCart and C4.5,
and support vector machines to detect all diﬀerent attack strategies. For this reason a
feature set is proposed and while representing this set in a multidimensional manifold,
attacks can be revealed as these feature variables are used for the prediction and decision
task.
We have validated our detection method through simulation using the King data set
for the p2psim simulator as well as through real deployment on the PlanetLab testbed.
The detection method is evaluated in a global manner, where the local information of
all nodes are together analyzed, as well as in a local manner, where each node has only
the local information to analyze and evaluate if an attack is happening or not. We have
shown that in our setting, decision trees outperform support vector machines by achiev-
ing a much lower false positive rate. Regarding the two diﬀerent types of decision trees,
the results are similar, thus there is no clear better choice. The outcome for the sequence
attack scenarios illustrates that a minimal set of normal data is needed for correctly clas-
sifying normal behavior, pointing to at most 25% of the data is needed to do so. Fur-
thermore, we compared the proposed detection technique, the decision tree, to existing
detection and mitigation techniques, outlier detection which is based on a threshold.
This comparison has conﬁrmed that the decision tree as a detection method outper-
forms the existing outlier detection not only for the frog-boiling, network-partition, or
complex attack strategies but also for the inﬂation, deﬂation, and oscillation attacks. In
future work, we plan on further reﬁning the defense and attack strategies by using a
game theoretical model, this will help in ﬁnding the most appropriate of the two dif-
ferent decision trees for the diﬀerent attacks, as they have similar performance. To our
knowledge, this is the ﬁrst work that is capable of mitigating all known attacks against
virtual coordinate systems.
References
1. Libsvm – a library for support vector machines. http://www.csie.ntu.edu.tw/ cjlin/libsvm/.
2. p2psim: A simulator for peer-to-peer protocols. http://pdos.csail.mit.edu/p2psim/.
3. Planetlab: An open platform for developing, deploying, and accessing planetary-scale ser-
vices. http://www.planet-lab.org.
4. Weka—machine learning software in java. http://sourceforge.net/projects/weka/.
5. V. Aggarwal, A. Feldmann, and C. Scheideler. Can ISPs and P2P systems co-operate
for improved performance? ACM SIGCOMM Computer Communications Review (CCR),
37(3):29–40, July 2007.
6. M. A.Kaafar, L. Mathy, T. Turletti, and W. Dabbous. Real attacks on virtual networks:
Vivaldi out of tune. In Proc. of LSAD, 2006.
7. D. Bolzoni, S. Etalle, and P. H. Hartel. Panacea: Automating attack classiﬁcation for
In Proceedings of the 12th Interna-
anomaly-based network intrusion detection systems.
tional Symposium on Recent Advances in Intrusion Detection, RAID ’09, pages 1–20, 2009.
8. L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. Classiﬁcation and Regression
Trees. Wadsworth International Group, Belmont, California, 1984.
9. C.J.C. Burges. A tutorial on support vector machines for pattern recognition. Data mining
and knowledge discovery, 2(2):121–167, 1998.
10. E. Chan-tin, D. Feldman, and Y. Kim. The frog-boiling attack: Limitations of anomaly
detection for secure network coordinate systems. In SecureComm, 2009.
11. E. Chan-Tin and N. Hopper. Accurate and provably secure latency estimation with treeple.
In NDSS, 2011.
12. B. Cohen. Incentives build robustness in BitTorrent. In Proc. of P2P Economics, 2003.
13. M. Costa, M. Castro, R. Rowstron, and P. Key. PIC: practical Internet coordinates for dis-
tance estimation. In Proc. of ICDCS, 2004.
14. G. F. Cretu-Ciocarlie, A. Stavrou, M. E. Locasto, and S. J. Stolfo. Adaptive anomaly detec-
tion via self-calibration and dynamic updating. In RAID, 2009.
15. F. Dabek, R. Cox, F. Kaashoek, and R. Morris. Vivaldi: a decentralized network coordinate
system. In Proc. of ACM SIGCOMM, 2004.
16. B. Donnet, B. Gueye, and M. A. Kaafar. A survey on network coordinates systems, design
and security. IEEE Communications Surveys and Tutorials, 2009.
17. P. Francis, S. Jamin, C. Jin, Y. Jin, D.y Raz, Y. Shavitt, and L. Zhang. IDMaps: A Global
Internet Host Distance Estimation Service. IEEE/ACM Trans. Netw., 9:525, 2001.
18. K. P. Gummadi, S. Saroiu, and S. D. Gribble. King: Estimating latency between arbitrary
internet end hosts. In Proc. of ACM SIGCOMM-IMW, 2002.
19. I. U. Haq, S. Ali, H. Khan, and S. A. Khayam. What is the impact of p2p traﬃc on anomaly
detection? In Proceedings of the 13th international conference on Recent advances in intru-
sion detection, RAID’10, pages 1–17, 2010.
20. M. A. Kaafar, L.Mathy, C. Barakatand Kave Salamatian, T. Turletti, and W. Dabbous. Se-
curing internet coordinate embedding systems. In Proc. of SIGCOMM, 2007.
21. M. A. Kaafar, L. Mathy, T. Turletti, and W. Dabbous. Virtual networks under attack: Dis-
rupting internet coordinate systems. In Proc. of CoNext, 2006.
22. A. Lakhina, M. Crovella, and C. Diot. Diagnosing network-wide traﬃc anomalies. In SIG-
COMM, 2004.
23. L. Lehman and S. Lerman. Pcoord: Network position estimation using peer-to-peer mea-
surements. In Proc. of NCA, 2004.
24. L. Lehman and S. Lerman. A decentralized network coordinate system for robust internet
distance. In Proc. of ITNG, 2006.
25. F. Maggi, W. Robertson, C. Kruegel, and G. Vigna. Protecting a moving target: Addressing
web application concept drift. In RAID, 2009.
26. E. Ng and H. Zhang. Predicting internet network distance with coordinates-based ap-
proaches. In Proc. of INFOCOM, 2002.
27. T.S.E. Ng and H. Zhang. A network positioning system for the internet. In Proc. of USENIX,
2004.
28. M. Pias, J. Crowcroft, S. Wilbur, S. Bhatti, and T. Harris. Lighthouses for scalable distributed
location. In Proc. of IPTPS, 2003.
29. J. R. Quinlan. C4.5: programs for machine learning. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA, 1993.
30. I. Rimac, V. Hilt, M. Tomsu, V. Gurbani, and E. Marocco. A Survey on Research on the
Application-Layer Traﬃc Optimization (ALTO) Problem. RFC 6029 (Informational), Octo-
ber 2010.
31. B. I.P. Rubinstein, B. Nelson, L. Huang, A. D. Joseph, S. Lau, S. Rao, N. Taft, and J. D.
Tygar. Antidote: understanding and defending against poisoning of anomaly detectors. In
IMC, 2009.
32. M. Sherr, M. Blaze, and B. Thau Loo. Veracity: Practical secure network coordinates via
vote-based agreements. In Proc. of USENIX ATC, 2009.
33. R. Sommer and V. Paxson. Outside the closed world: On using machine learning for network
intrusion detection. Security and Privacy, IEEE Symposium on, 0:305–316, 2010.
34. M. Steiner and E. W. Biersack. Where is my peer? evaluation of the vivaldi network coordi-
nate system in azureus. In NETWORKING, 2009.
35. L. Tang and M. Crovella. Virtual landmarks for the internet. In Proc. of SIGCOMM, 2003.
36. V Vapnik and A Lerner. Pattern recognition using generalized portrait method. Automation
and Remote Control, 24(6):774–780, 1963.
37. D. Zage and C. Nita-Rotaru. On the accuracy of decentralized network coordinate systems
in adversarial networks. In Proc. of CCS, 2007.