The above gives a risk ranking relative to all apps in all cate-
gories. An alternative is to rank apps in each category separately,
so that one has a risk ranking for an app relative to other apps in the
same category.
Probabilistic generative models. We propose to use probabilistic
generative models for risk scoring. That is, we assume that some
parameterized random process generates the app datasets and learn
the parameter value θ that best explain the data. Next, for each app
we compute p(ai|θ), the probability that the app’s data is generated
by the model.
The risk score of an app can be any function that is monoton-
ically decreasing with respect to the probability of an app being
generated, such that a lower probability means a higher risk score.
For example, using rscore(ai) = − ln p(ai|θ) satisﬁes the condi-
tion.
In the rest of this section we describe three generative models—
from simple Naive Bayesian models, to mixture of Naive Bayes
models and to novel hierarchical Bayesian models. We present es-
timation methods to learn the parameters for these models from the
data, and evaluate whether they satisfy our desiderata.
4.1 Naive Bayes Models
In the Naive Bayes models, we ignore the category information
ci; thus each app is given by xi = [xi,1, . . . , xi,M ]. We assume
that each xi is generated by M independent Bernoulli random vari-
ables, where M is the number of permissions:
M(cid:89)
M(cid:89)
p(xi) =
p(xi,m) =
m=1
m=1
m (1 − θm)(1−xi,m)
θxi,m
(1)
where θm ≡ p(xi,m = 1) is the Bernoulli parameter.
To avoid overﬁtting in our estimation (i.e., ﬁtting the model to
noise), we use a Beta prior Beta(θm|a0, b0) over each Bernoulli
parameter θm. Using this prior, the Maximum a posteriori (MAP)
estimation is
(cid:80)N
ˆθm =
i xi,m + a0
N + a0 + b0
(2)
where N is the total number of apps for this Naive Bayes model
estimation.
The Basic Naive Bayes Model (BNB). In the Basic Naive Bayes
(BNB) mode, we use uninformative prior and set a0 = b0 = 1, so
that the Beta prior becomes a uniform distribution on [0,1]. With
245such an uninformative prior, ˆθm is very close to the the frequency
of the m’th permission being requested in the dataset.
The BNB model is easy to explain, satisfying the third desider-
atum. Furthermore, if θm < 0.5 for every m, then the probability
provided by this model satisﬁes the monotonicity property. Chang-
ing any xi,m from 0 to 1 changes the probability by a factor of
, which is less than 1 when θm < 0.5, and thus decreases
θm
1−θm
the probability and increases the risk score. As there is only one
permission, namely Internet, requested by over 50% of the apps,
removing the INTERNET permission from the feature set sufﬁces
to ensure the monotonicity property. Finally, the BNB model intu-
itively satisﬁes the second desideratum, i.e., known malicious apps
generally have lower generated probabilities, because as we have
seen in Section 3.3, malicious apps generally request more permis-
sions.
NB with Informative Priors (PNB). BNB treats all permissions
equally, and a malicious app can reduce its risk by not request-
ing rare permissions that are not critically needed for carrying out
malicious activities. We thus consider a Naive Bayes model with
informative priors to incorporate semantic information of app per-
missions. Such approach is commonly used in Naive Bayes models
to model knowledge not available in the dataset. The desired goal is
to make requesting a more critical permission to increase risk more
than requesting a less critical one, even though the two permissions
have similar frequencies.
To identify critical permissions, we start from a list of 26 per-
missions identiﬁed in [24] as critical. We remove the INTERNET
permission, and add another that we believe is critical, namely IN-
STALL_PACKAGES. Furthermore, among the 26 permissions, we
manually selected 9 of them as very high risk permissions.1
the
semantic
To incorporate
information in the Naive
Bayes models, we uenckse informative Beta prior distributions
Beta(θm|am, bm): for the most risky 9 permissions, we set am =
1, bm = 2N and N is the number of apps in our data set, discour-
aging the use of these permissions; for the other 17 risky permis-
sions, we set am = 1, bm = N with less penalty effect; and for the
remaining permissions, we set am = 1, bm = 1 as in BNB models.
When compared with BNB, PNB is slightly more complex than
BNB. However, it has the advantage that requesting a more critical
permission results in higher risk, when compared with requesting a
similarly rare but less critical permission. One key beneﬁt of PNB
is that it is more difﬁcult for malware apps to reduce their risks
by removing rare permissions that they do not need, since it likely
needs some of the critical permissions to carry out its malicious ac-
tivities. For this reason, we prefer PNB to BNB when other things
are equal.
4.2 Mixture of Naive Bayes (MNB) Models
The assumption in BNB and PNB that all apps follow a simple
factorized Bernoulli distribution does not appear to be very realis-
tic. Thus, we develop more sophisticated probabilistic generative
models and experimentally compare the effectiveness of BNB with
these models.
We improve the Naive Bayes model by assuming each app is
sampled from multiple—instead of only one—latent topics, each
of which follows a factorized Bernoulli distribution. Unlike the
Naive Bayes model, this mixture model allows us to use different
latent topics to capture different aspects of the apps. These topics
are
ACCESS_COARSE_LOCATION,
1They
AC-
CESS_FINE_LOCATION,
PROCESS_OUTGOING_CALLS,
CALL_PHONE, READ_CONTACTS, WRITE_CONTACTS,
READ_SMS, SEND_SMS, INSTALL_PACKAGES.
could describe ﬁne grained classes of applications, such as geotag-
ging apps that request LOCATION, INTERNET, and CAMERA
permissions, or applications that leverage common frameworks.
Speciﬁcally, we use an unknown indicator variable z =
1, . . . , K (K is the number of latent topics) to represent which
topic an app is sampled from. We assign an uninformative uni-
(cid:81)M
form prior over z and assume that the topic distribution is the same
as the Naive Bayes model conditioned on z; that is, p(xi|z, θz) =
m=1 p(xi,m|z, θzm) is a factorized Bernoulli distribution where
θz = [θz1, . . . , θzM ]. Let Θ = [θ1, . . . , θk] denote parameters for
the app distributions for all the topics. Then the probability of the
data is
p(x|Θ) =
p(z)
p(xi|z, θz),
(3)
(cid:88)
N(cid:89)
z
i=1
which is a mixture of Naive Bayes models.
To obtain the MAP estimation of both assignments, we use an
expectation maximization approach that loops over two steps, Ex-
pectation (E) and Maximization (M) steps, until convergence. In
the E step, we compute the posterior of z given the current estimate
of Θ:
(cid:81)
(cid:80)
(cid:81)
k
m θ
(cid:80)N
(cid:80)N
k,m
i=1 xi,m
(1 − θk,m)N−(cid:80)N
(1 − θk,m)N−(cid:80)N
i=1 xi,m
p(z = k|x, Θ) =
i=1 xi,m
k,m
m θ
(cid:80)N
In the M step, we maximize the expected joint probability Q =
i=1 Ez[ln p(xi|z, Θ) + ln p(z) + ln p(Θ)]. Note that we use the
updated p(z = k|x, Θ) in the E step to obtain the expectation. We
thus obtain
i=1 xi,m
(cid:80)N
(cid:80)N
i p(z = k|x, Θ)xi,m + a0
i p(z = k|x, Θ) + a0 + b0
θkm =
.
(4)
MNB models, however, no longer guarantee the monotonicity
property. We have observed that the learned hidden topics can
request certain permissions with probability over 0.5, resulting in
the estimated θkm being greater than 0.5. When this happens, the
monotonicity property does not hold.
Mixture of Naive Bayes with Categories (MNBC). We also ex-
tend MNB to consider category information and call the result-
ing models Mixture of Naive Bayes with Categories (MNBC). In
MNBC, teh latent topics are shared among all categories, but each
category has a different multinomial distribution describing how
likely an app in this category is from a particular latent topic.
4.3 Hierarchical Mixture of Naive Bayes
(HMNB) Models
Finally, we develop Bayesian hierarchical mixture models that
we can train using apps across all categories and, at the same time,
account for the difference between categories. We still produce a
mixture model for each category. To share information between
categories we set the latent topics to be the same across categories
and sample the probabilities of choosing these topics from a com-
mon Dirichlet distribution—thus these probabilities (i.e., mixture
weights) are similar. Our model extends Latent Dirichlet Alloca-
tion (LDA) models [8], a popular document model, to the case of
binary vector observations (each app corresponds to a word in a
document and each category is a document in the latent Dirichlet
allocation models).
Let us succinctly denote the permissions of app i in category
c by xci, the parameter in the multinomial topic distribution for
category c by ψc, the topic assignment variable for each each app i
in category c by zci, and the hyparameter of the Dirichlet prior on
246the topic distribution by α. Then formally speaking, we have the
following stochastic data generation process:
1. For each topic k and permission m, draw the app probabili-
ties θk,m ∼ Beta(a0, b0).
2. For each category c, sample the parameter for topic distribu-
tions ψc ∼ Dir(α).
3. For each app i in category c,
(a) Sample the topic assignment zci ∼ Multi(ψc).
(b) Generate the permissions via the factorized Bernoulli
(cid:80)N
k,m
i=1 xim
m θ
(1 − θk,m)N−(cid:80)N
i=1 xim .
distribution (let zci = k)
xk ∼(cid:81)
To estimate this Bayesian model, we develop a variational algo-
rithm. It enables us to accurately approximate the exact Bayesian
posterior distributions of the model parameters with a low compu-
tational cost. We give the detailed variational updates in the Ap-
pendix.
5. EXPERIMENTAL RESULTS
In the experiments we aim at understanding how well the dif-
ferent models satisfy the second desideratum, namely, able to as-
signing high risks to known malware apps, and compare them to
methods in the literature [11, 24].
Methodology. Most of our experiments are conducted with the
2011 dataset, with 10 fold cross validation. We divide the 2011
dataset randomly into ten groups.
In each of the 10 rounds, we
choose one different group as the test dataset, and the remaining 9
groups as the training dataset. The models are trained on the train-
ing set, the generated model is used to compute the probabilities
of apps in the testing set and the malware dataset, and rank them
together.
When reporting the results, we use ROC curves, which plot the
true positive rate against false positive rate if one chooses a par-
ticular risk value as indicative of malicious app. We use Area Un-
der Curve (AOC) to quantify the quality of the ROC curves for a
method. Here, AUC is the probability that a randomly selected ma-
licious application will have a higher risk score than a randomly
selected benign application. When reporting AUC values resulted
from 10-fold cross validation, we plot the mean and stand error of
the AUCs of the ten rounds.
Parameter Selection. Both MNB and HMNB can be used with
different parameters, and we need to select the best parameters for