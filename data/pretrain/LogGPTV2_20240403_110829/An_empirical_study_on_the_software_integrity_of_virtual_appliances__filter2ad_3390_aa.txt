# An Empirical Study on the Software Integrity of Virtual Appliances: Are You Really Getting What You Paid For?

**Authors:**
- Jun Ho Huh, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)
- Mirko Montanari, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)
- Derek Dagit, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)
- Rakesh Bobba, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)
- Dongwook Kim, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)
- Yoonjoo Choi, Dartmouth College, USA (PI:EMAIL)
- Roy H. Campbell, University of Illinois at Urbana-Champaign, USA (PI:EMAIL)

## Abstract
Virtual appliances (VAs) are pre-configured virtual machine images designed for specific purposes. For example, a VA might include all the necessary software to develop and host a JSP-based website. Users can download VAs from various repositories and deploy them on Infrastructure-as-a-Service (IaaS) clouds, enabling quick service launch. However, there is a lack of mechanisms to verify if a VA contains the software it claims to have. This paper evaluates the integrity of software packages in real-world VAs using a whitelist-based framework. Our analysis of 151 Amazon VAs reveals that approximately 9% of these VAs contain a significant number of software packages with unknown files, making them potentially untrusted. Virus scanners flagged only half of these 9% as malicious, indicating that virus scanning alone is insufficient for selecting trustworthy VAs. Thus, a priori software integrity assessment is essential.

**Categories and Subject Descriptors**
- D.4.6 [Software]: OPERATING SYSTEMS—Security and Protection

**Permission to make digital or hard copies**
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

**ASIA CCS’13, May 8–10, 2013, Hangzhou, China.**
Copyright 2013 ACM 978-1-4503-1767-2/13/05 ...$15.00.

**General Terms**
- Security, Experimentation, Measurement, Verification

**Keywords**
- IaaS, Virtual appliances, Whitelists, Software integrity

## 1. Introduction
Cloud computing has gained popularity as organizations seek to reduce the complexities and costs of deploying and maintaining internal IT infrastructure. The Infrastructure-as-a-Service (IaaS) model allows users to build and configure virtual computing infrastructure by renting computing resources, typically in the form of virtual machines (VMs). Users have administrative privileges to install and configure software on these VMs. Many services provide pre-configured VM disk images, known as virtual appliances (VAs), which are tailored for specific workflows. 

A VA, such as a VM image with a fully configured Tomcat web server for Java web services, offers convenience for consumers and potential revenue for publishers. However, the marketplace lacks adequate mechanisms for users to assess whether a VA contains the software it claims to have. This paper investigates the integrity of software packages in real-world VAs and highlights the need for a mechanism to evaluate their software integrity.

There are several security challenges associated with cloud computing, including the risks posed by the publisher-consumer model in VA stores. A malicious publisher could install malware, while a careless publisher might unintentionally publish an infected or insecurely configured VA. Additionally, an irresponsible publisher might release an incomplete VA missing critical software packages. Currently, checking the integrity and identity of installed software packages is a time-consuming, manual process. Providing this information during the selection process would help consumers make informed decisions. 

This paper presents an empirical study on the integrity of software packages in real-world VAs using a whitelist-based framework. Our findings show that about 9% of evaluated VAs have significant software integrity issues. We argue that consumers should be informed about such VAs when making their selections. While a well-configured VA with authentic software packages can still be vulnerable to legitimate software vulnerabilities, the whitelisting approach can mitigate the risk of partially installed or modified packages.

Whitelist-based approaches are generally challenging due to the variety and volume of existing software. However, in the appliance store model, most consumers use well-known, popular software, making the whitelist more manageable. We constructed a whitelist for our sample VAs and found that the whitelist size growth decelerates.

**Contributions:**
1. An empirical evaluation of the software integrity in real-world VAs, showing significant variation.
2. Demonstration of the usefulness of assessing software integrity in VAs to help customers choose correctly configured VAs.
3. Demonstration of the feasibility and scalability of using whitelists for integrity assessment.

**Organization:**
- Section 2 covers related work.
- Section 3 provides an overview of the assessment framework.
- Section 4 analyzes real-world VAs.
- Section 5 discusses the security implications.
- Section 6 presents conclusions and future work.

## 2. Related Work
Researchers and industry practitioners have been addressing the security and reliability challenges of cloud computing. Here, we focus on work that addresses the security risks and challenges associated with VA stores and the management of VAs.

Reimer et al. [26] proposed the Mirage Image Format (MIF) to simplify the maintenance and administration of VM images. Wei et al. [32] identified security challenges in the VA store model and proposed an image management framework with access control, filtering, provenance tracking, and image maintenance. Later, they introduced Nüwa, a scalable offline patching tool leveraging MIF. Accountability through provenance tracking, virus scanning, and software patching are good security practices but are not sufficient. Our approach provides more explicit information about a VA's software configuration and complements these efforts.

Bugiel et al. [17] analyzed over a thousand Amazon Machine Images and found sensitive information and SSH backdoors. They suggested countermeasures like filters, scanners, and ratings based on verifiable properties and reputation. However, user opinion-based ratings may not be objective and take time to accumulate. Our software integrity assessment approach provides a means to rate VAs before publishing them, either independently or as part of a larger ratings ecosystem.

Jayaram et al. [21] studied the similarity between VAs to enable efficient design of VA management systems. Their work focused on block-level similarity for de-duplication, storage reduction, and image distribution. Our work focuses on software or file-level similarity to gauge the size of whitelists needed by VA store providers. To our knowledge, we are the first to comprehensively analyze the software integrity of real-world VAs.

File analysis techniques similar to ours have been used to detect changes in critical files, such as those introduced by rootkits. Kim et al. [23] and Vincenzetti et al. [31] developed mechanisms for detecting illicit modifications. More recent work [25] extended these approaches to virtual environments. While these techniques aim to identify runtime malware, our focus is on analyzing the initial configuration of VAs and providing ratings for assessed software.

## 3. Software Integrity Assessment Framework
To study the integrity of software packages in real-world VAs, we designed an integrity assessment framework based on software whitelisting techniques. At the core of the framework is a Configuration Resolver (described in Section 3.1) that uses a VM Configuration Verification Tool (VM-CVT) to generate a "verification report" on a given VA (see Figure 2). These tools use information provided by publishers and software producers to verify the integrity of the installed software and identify any modified or missing files. Based on this information, we introduce a simple rating system to score the installed software.

The verification reports provide consumers with explicit information about the system configuration, allowing them to gauge its suitability without downloading and instantiating the VA. Providers can use the verification reports to ensure that published VAs meet basic requirements by specifying policies. For example, a cloud provider could create a more trustworthy store by requiring that all installed software and updates be fully verified.

Our integrity validation is based on reference integrity measurements (RIMs) [30] published by vendors, which contain signed hash values of all files and metadata. This is a common practice, and many software vendors provide signed checksums for files. The U.S. National Institute of Standards and Technology (NIST) maintains the National Software Reference Library (NSRL) [7], which provides RIMs for software. Bit9, a private security company, also maintains a large software registry [3].

The framework can leverage additional information from publishers and software vendors. VAs are often generated from trusted base images, which can speed up the analysis. Publishers can submit logs detailing the installed software and version information, simplifying the analysis. Fabricated logs will result in low integrity scores, as the installed files will not match the RIMs and appear unreliable. Software vendors can provide additional metadata associated with the RIMs to identify file types.

![](Figure_2: Software_integrity_assessment_framework_overview)

---

This optimized text aims to improve clarity, coherence, and professionalism, ensuring that the content is well-structured and easy to follow.