Since we perform disassembly and control ﬂow extraction
of unknown malware samples, we need to overcome the
problem of packed executables (according to [18], more than
40% of the samples are packed with a known packer; a
number which is likely only a lower bound). To unpack
samples, we use a very simple but effective technique.
In existing generic unpackers [15], [19], a malware under
analysis is ﬁrst executed in a dynamic malware analysis
environment. Since we already execute the analyzed code
in Anubis for several minutes, unpacking happens naturally.
At the end of the analysis run, we simply take a snapshot
of the memory content and perform analysis directly on this
dump. This allows us to not only report the results from
the dynamic analysis run, but also to report all dormant
functionality that was identiﬁed.
Our experience showed that this simple unpacking ap-
proach worked very well for the malware samples in our
evaluation dataset, and it is also sufﬁcient for most contem-
porary malware that we have encountered. However, we are
aware that there are advanced packers that require the use
of alternative unpacking techniques [20], [21].
V. EVALUATION
The goal of the evaluation is to show that REANIMATOR
can extract accurate and robust genotype models for a variety
of phenotypes. Moreover, we want
to demonstrate that
these models are capable of efﬁciently identifying dormant
functionality in real-world malware.
A. Genotype Model Extraction
Phenotypes. To be able to extract genotype models, it is ﬁst
necessary to deﬁne appropriate phenotypes. To this end, we
ﬁrst speciﬁed rules to detect nine phenotypes that correspond
to common malware behaviors. Although the following list
is clearly not exhaustive, we believe that it is sufﬁcient to
demonstrate the ﬂexibility of our approach.
• spam: send unsolicited email. This behavior is detected
as SMTP trafﬁc at the network level.
• scan: perform a port scan. To detect this phenotype, we
rely on Anubis’ existing network-level portscan detection
heuristics.
• sniff: perform packet snifﬁng. This phenotype is detected
when a program opens a socket in promiscuous mode.
70
• keylog: log the keys that the user presses. This phenotype
is detected when a program invokes one of several Windows
API calls that can be used to register callbacks that receive
keyboard information.
• rpcbind: exploit a Windows DCE/RPC vulnerability over
the SMB/CIFS protocol. This is detected at the network
level, using appropriate intrusion detection (Snort) signa-
tures.
• killproc: kill a process (typically, an anti-virus process).
This phenotype is detected when an analyzed program uses
a Windows API call to terminate a process that it did not
spawn itself.
• backdoor: open a back-door. This phenotype is detected
when the analyzed program opens and listens on a TCP port.
• packetﬂood: simple denial-of-service. This phenotype is
detected when the malware sends more than a certain
number of packets per second to a single destination.
• drop: “drop” and execute a binary. This behavior is
detected when the taint analysis observes a data ﬂow from
the network to a ﬁle, and this ﬁle is later executed.
Genotypes. Using the previously-deﬁned phenotypes, we
executed the following four malware samples in our dynamic
analysis environment:
• rbot: This malware sample is a representative of a classic
IRC-based bot. The corresponding source code was available
to us. Therefore, we were able to force the bot to connect
to our own IRC server, and we instructed it to execute a
variety of actions.
• pushdo: Pushdo is a sophisticated, modern download-
er/dropper Trojan. It connects to a hard-coded list of IP
addresses over HTTP and attempts to download and install
additional components. We did not have access to Pushdo’s
source code. Hence, we started the program and allowed it
to connect to its command and control infrastructure.
• cutwail: Cutwail is a template-based spam engine that is
one of the typical payloads of the Pushdo dropper. Initially,
we did not have a sample of Cutwail, but we could use
Pushdo to download it and run it for us. For details on the
Pushdo/Cutwail botnet, we refer the interested reader to [22].
• allaple: Allaple [23] is a well-known polymorphic net-
work worm. When started, our variant performs a network
scan on TCP ports 135, 139 and 445. Then, it attempts to
compromise the services identiﬁed by the scan.
We selected these four malware samples because they
exhibit (or, in case of rbot, they could be instructed to
exhibit) a wide range of behaviors in the Anubis sandbox.
Also, these samples represent a good mix of a classic and
two more advanced bots and a well-known worm.
We then applied REANIMATOR to the executions of the
four malware samples, and automatically extracted ten geno-
type models. These models are shown in Table I. The table
also shows the size of the genotype that was captured by the
corresponding model, both in terms of lines of code (when
LINES OF CODE (WHERE AVAILABLE) AND NUMBER OF BASIC BLOCKS
OF GENOTYPE EXTRACTED IN (S)TATIC AND (D)YNAMIC MODE.
Table I
Genotype
Sample
Phenotype
LoC
rbot
sniff
rbot
udpﬂood
rbot
keylog
rbot
killproc
httpd
rbot
simplespam rbot
drop
spam
scan
rpcbind
pushdo
cutwail
allaple
allaple
sniff
packetﬂood
keylog
killproc
backdoor
spam
drop
spam
scan
rpcbind
95
60
84
65
392
37
n/a
n/a
n/a
n/a
Basic Blocks
S
59
51
59
42
302
27
150
532
99
333
D
31
41
49
27
236
26
126
290
62
133
Figure 2. Distribution of MOSS scores by percentage, along with the
number of matches generated by our genotype models.
source code was available) and in terms of basic blocks.
Note that the number of basic blocks is shown both for
the dynamic and the static CFG extraction approach used
during the germination step. As expected, the static approach
covers more code (i.e., regions that were not executed during
dynamic analysis). Also, it is interesting to observe that a
single phenotype (in this case, spam) can be implemented in
different ways, which results in different genotype models.
B. Genotype Model Accuracy
In the next step, we wanted to analyze how accurate
our extracted genotype models are. To this end, we ﬁrst
examined whether REANIMATOR is successful
in using
a particular genotype model to detect the corresponding
genotype in other malware binaries. For this analysis, we
could make use of a dataset of 208 bot programs that were
available to us as source code. This dataset was provided
by the authors of [24]. Many of the 208 bots are variants
of rbot, and indeed, we randomly chose one rbot program
from this dataset as one of the four malware sample used
for genotype model extraction.
Using the source code of this rbot sample, we manually
extracted code snippets that we considered to be responsible
for each of the six observed rbot phenotypes (shown in
71
Table I), one code snippet for each behavior. Then, we
checked the source of the remaining 207 bot programs for
code that is similar to these six code snippets. Of course,
even with source code available, manually checking for the
presence of similar code in hundreds of programs is a tedious
task. Therefore, we took advantage of MOSS [25], a free,
web-based service for plagiarism detection. MOSS is widely
used for detecting plagiarism in computer science classes,
and it allowed us to identify those samples that contain code
that is similar to one of the manually extracted code snippets.
At this point, we used REANIMATOR to match the six
genotype models generated for the single rbot
instance
against the 207 remaining bot binaries. These binaries were
obtained by compiling each bot source code using Mi-
crosoft Visual Studio 2005. We then compared the matches
identiﬁed by REANIMATOR with the source code similarity
measurements obtained by MOSS. Of course, the hope is
that the matches that are independently produced by both
techniques have a high overlap. That is, we expect that
REANIMATOR reports a certain (dormant) functionality in
a malware binary whenever MOSS reports that the cor-
responding program source contains the code snippet that
implements this functionality (or, at least, code that is similar
to this snippet).
As one can see in Figure 2, REANIMATOR’s genotype
matching results are closely correlated with source code
similarity obtained from MOSS. On the right hand side,
the code snippet
indicates the conﬁdence that
Figure 2 shows a comparison between the matches iden-
tiﬁed by REANIMATOR and the similarity scores produced
by MOSS. For each of the six behaviors j, and for each
of the 207 binaries i, MOSS produces a similarity score
that
that
implements behavior j is present in binary i. We call this
similarity score Mi,j. Figure 2 shows a histogram that
displays the distribution of the scores Mi,j. It can be seen
that many scores are very high, which conﬁrms the previous
observation that the dataset contains many variants of rbot.
In addition to the similarity scores for MOSS, Figure 2
also contains the results for REANIMATOR. In particular,
whenever our technique ﬁnds a match for genotype model
j in binary i, we ﬁrst check the similarity score that MOSS
reported for this combination, which is Mi,j. Then, we add
1 to the REANIMATOR results for the bin that corresponds
to this score. The intuition is that we expect that whenever
our technique reports a match, the corresponding similarity
score is high. In other words, we would expect that our
system reports a match whenever MOSS’ similarity score
is high (on the right side of the graph), and nothing when
the similarity score is low (on the left side of the graph).
The static and dynamic bars for REANIMATOR represent the
results achieved by using either a static or a dynamic CFG
during the germination step (as discussed in Section IV-B3).
For this dataset, the results are identical. However, as we
show, this is not the case on other datasets.
where the MOSS similarity scores are high, genotype match-
ing is almost invariably successful. On the left hand side,
where MOSS produces a low score, there are almost no
REANIMATOR matches.
We then manually inspected those cases for which MOSS
and REANIMATOR reported different
results. First, we
looked at instances where our technique detected a match,
but the similarity scores reported by MOSS were low (in-
dicating different code). In particular, we checked the code
where MOSS reported low scores (lower than 50%). We
found that in all ﬁve cases, REANIMATOR was correct. That
is, the sample did indeed implement the functionality that
REANIMATOR found. The low MOSS scores were caused
by the fact that large parts of the corresponding source code
had been modiﬁed, or re-implemented. However, enough of
the genotype had been preserved that REANIMATOR could
recognize it. We also inspected the 27 opposite cases where
MOSS reported a high similarity, but REANIMATOR did not
ﬁnd a genotype model match. We found that, in 13 cases,
the implementation of the i-th phenotype was present in the
j-th bot’s source code, but not in its binary. The code was
excluded from the build process either at the compilation
stage (because of #ifdef directives), or at the linking
stage, because the linker decided not to include an object
that was not required. The remaining 14 cases were false
negatives, due to the fact that code was changed to an extent
that our models failed to detect the similarity.
Finally, we wanted to verify that the genotype models
produced by REANIMATOR do not match arbitrary binary
code. That is, we wanted to understand the risk of false
positives produced by our models. To this end, we used
our ten genotype models and applied them to a dataset that
consisted of 1,949 ﬁles found in the system32 directory
of a Windows XP installation. Of course, we do not expect
any of our genotypes to match on benign Windows program.
Indeed, no matches were found.
C. Robustness
In this section, we evaluate the effects of different
compilers and optimizations on REANIMATOR’s accuracy.
Speciﬁcally, we aim to test whether a genotype model
extracted from a binary can be successfully matched against
binaries that were compiled with different compiler versions
or optimization options. For this, we use the same dataset of
208 bot sources, and the same genotype models discussed
in the previous section.
As a ﬁrst test, we re-compiled the bot sources using the
same compiler (Microsoft Visual Studio 2005), but with
different optimization and inlining options. The results are
summarized in Table II. The table shows that for all the
genotype models, except for simplespam, different compiler
options have a very limited effect on the REANIMATOR
results. The number of matching binaries are reduced by
less than 7%. The simplespam genotype model is more
brittle. This is because the rbot sample implements this
functionality in only 37 lines of code, as opposed to 60
to 392 lines for the other behaviors. Clearly, code re-use is
easier to detect when larger code fragments are involved.
For the second test, we re-compiled ten of the 208
bot samples using different versions of the Visual Studio
compiler, as well as the Intel C++ Compiler Professional
Edition 11.1. We restricted this test to ten samples because
we were not able to completely automate the compilation
process with different compilers. More precisely, we learned
that different compilers accept slightly different dialects of
C source code, and hence, source code needed to be adapted
to be accepted by a different compiler.
As can be seen in Table III, REANIMATOR is robust
to different compiler versions, but mostly fails to match
genotypes in binaries produced by a completely different
compiler. Nonetheless, our results compare favorably to the
state-of-the-art work on binary clone detection [26]. Results
from [26] show false negative rates of over 96% on identical
functions when simply changing compiler options.
While a malware author could still attempt to evade our
tool by re-compiling malware with different compilers, this
only allows him to generate a limited number of variants.
To correctly match against all samples, REANIMATOR would
simply need to generate a genotype model for each variant.
D. Genotype Matching Results
In this section, we discuss REANIMATOR’s effectiveness
is similar
on four real-world datasets:
• irc bots: This dataset consists of 10,238 binaries that
performed IRC trafﬁc when analyzed in Anubis, and are,
therefore, likely to be IRC-based bot samples. Furthermore,
these samples were selected based on the output of the
SigBuster tool for not being packed with a known packer.
• packed bots: This dataset
to the irc bots
dataset. It consist of 4,523 binaries that perform IRC trafﬁc