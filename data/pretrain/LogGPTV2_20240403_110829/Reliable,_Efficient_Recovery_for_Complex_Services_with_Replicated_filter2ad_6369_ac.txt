Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:35:43 UTC from IEEE Xplore.  Restrictions apply. 
176
SEND(et) to leader
(Vr, ET, nid(cid:2)) ← RECEIVE from leader
et ← ET
if et.vid = ue.vid then
Algorithm 3 A non-leader node’s behavior
1: Vc ← READ(view log)
2: et ← READ(epoch termination log)
3: ue ← READ(update log).end
4: SEND(Vc, nidme, Vc.my sid, ue.seqno) to leader
5: if et (cid:5)= {} ∧ et.vid = Vc.vid then
6:
7: commit ← ⊥
8: while ¬commit do
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27: Vc ← Vr
28: WRITE(view log, Vc)
if ¬success then
TRUNCATE(update log, trim seqno)
success ← STATE TRANSFER(nid(cid:2), nidme, Vr)
if ¬success then
p ← RECEIVE from leader
if p = “Prepare” then
success ← SEND(∅) to(cid:2)
trim seqno ← et.last[Vc.my sid]
success ← SEND(ue.vid) to(cid:2)
trim seqno ← RECEIVE from (cid:2)
d ← RECEIVE from leader
commit ← (d = “Commit”)
continue
continue
else
leader computes the assignment of nodes to shards in Vr by
solving an instance of the min-cost ﬂow problem [11].
It ﬁrst creates a bipartite graph from shards to failure
correlation sets as follows: For each shard there is a vertex
si, and for each failure correlation set (FCS) there is a vertex
f csj. There is one “shard” vertex u representing unassigned
nodes, one source vertex, and one sink vertex. If mi is the
required number of nodes from different failure correlation sets
for shard i, then there is an edge from the source vertex to si
with cost 0 and capacity mi. An edge with cost 0 and capacity
0 extends from the source vertex to u. An edge extends from
each shard vertex si to each FCS vertex f csj, with cost 0 if
shard i contained a node from FCS j in Vc, cost 1 otherwise,
and capacity 1. For vertex u, these edges always have cost 0
and capacity 1. Finally, there is an edge from each FCS vertex
f csj to the sink vertex with cost 0 and capacity equal to the
number of nodes in FCS j in Vr.
The leader solves min-cost ﬂow on the generated bipartite
graph, increasing ﬂow along augmenting paths until all shard
vertices si have at least mi ﬂow and a solution is generated,
or no augmenting path can be generated for the graph. If a
solution is generated, then the leader translates that solution
into a node assignment, where shard i is assigned one node
from failure correlation set j if an edge contains ﬂow between
vertices si and f csj. If min-cost ﬂow halts without a solution,
then there is no solution that satisﬁes mi for all shards, and
there is not yet a restart quorum.
if nid(cid:2) = nidme then
seqnon ← FIND MAX(U L, vidn).seqno
succ1 ← SEND(seqnon) ton
U L ← READ(update log)
for all n ∈ Vr.shards[Vr.my sid] do
vidn ← RECEIVE from n
if vidn (cid:5)= ∅ then
Algorithm 4 The state-transfer function
1: function STATE TRANSFER(nid(cid:2), nidme, Vr)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
ue ← READ(update log).end
success ← SEND(ue.seqno) to(cid:2)
if ¬success then
{ue+1, ue+2, . . . , u(cid:2)} ← RECEIVE from (cid:2)
APPEND(update log, {ue+1, ue+2, . . . , u(cid:2)})
seqnoe ← RECEIVE from n
succ2 ← SEND({U L[seqnoe], . . . U L.end}) ton
if ¬succ1 ∨ ¬succ2 then
return ⊥
return ⊥
return (cid:10)
else
C. Completing Epoch Termination
For each shard, the restart leader sends to each node that
will be a member in Vr the identity of the node on which the
latest update for that shard resides (denoted node (cid:2)), as well
as Vr itself and the epoch termination information.
When sending this information to node n, the restart leader
might discover that n has crashed because it does not re-
spond to the leader’s connection attempts (we assume TCP-
like semantics for our network operations). In this case, the
leader removes n from the set of restarted nodes, sends an
“Abort” message to all the nodes that have already received
its message, and recomputes whether it has a restart quorum.
If there is still a restart quorum, the leader recomputes Vr and
starts over at sending ET and Vr to each live node. If not, it
returns to step 2 and waits for additional nodes to restart.
Meanwhile, when a non-leader node receives Vr, ET , and
nid(cid:2), it compares ET ’s view ID to the view ID associated with
its last logged update. If these IDs match, the node completes
epoch termination by deleting from its update log any updates
with a sequence number higher than the last commit point for
its shard. If the epoch termination structure is from a later
view, though, all the updates in the node’s log are from an
earlier view that might have had its own epoch termination.
In order to ensure that it also trims any updates that were
aborted by the earlier epoch termination, the node contacts
node (cid:2) and sends it the VID of its last logged update. Node
(cid:2), upon receiving this message, inspects its update log and
ﬁnds the last update with that VID, then replies with that
update’s sequence number. The sending node then deletes
from its log any updates with a higher sequence number.
(Node (cid:2)’s behavior in this exchange is implemented in the
STATE TRANSFER function).
D. Transferring State
Once each node, including the leader, has truncated from
its log any updates that would have aborted, it must download
177
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:35:43 UTC from IEEE Xplore.  Restrictions apply. 
any committed updates that are not in its log. Each node that
has been designated as the location of the longest log must,
conversely, listen for connections from the other nodes that
will be members of its shard in Vr and send them the updates
they are missing. This is shown in the STATE TRANSFER
function in Algorithm 4. In this phase, a non-leader node may
discover that the node with the longest log has failed when it
attempts to contact it. In that case, the node can conclude that
the Vr it has received from the leader will not commit, and
return to waiting to receive a new Vr and longest-log location
from the leader.
E. Committing to a Restart View
When a non-leader node ﬁnishes its state transfer operations,
it awaits a “prepare” message from the leader. Meanwhile,
when the leader has ﬁnished its own state transfer operations,
it begins sending “prepare” messages to each node. If it
discovers while sending these that a node has crashed (because
the connection is broken), it sends an “abort” message to
all nodes that it has already sent “prepare” messages to, and
recomputes the post-restart view to exclude the crashed node.
The leader might then discover that it no longer has a sufﬁcient
quorum for restart without the crashed node, in which case it
returns to step 2 and waits for additional nodes to restart. If
it still has a quorum, however, the leader can return to step 3,
calculating the new shard membership and sending the new
Vr and longest log location to all nodes. Once the leader has
successfully sent “prepare” messages to all nodes in Vr, it
can send a “commit” message to all of them conﬁrming that
this view can be installed. Once a non-leader node receives the
leader’s commit message, it can install Vr and begin accepting
new messages and committing new updates. At this point,
the restart leader no longer has a leader role, and all future
failures and reconﬁgurations can be handled by the normal
view-change protocol for a running system.
IV. ANALYSIS
We will now prove that this protocol satisﬁes the goals
we set out in section II-B. We ﬁrst show that the protocol
is correct in the case where there are no failures during the
restart process, and then show that failures of any node do not
affect its correctness.
Regardless of which view the restart leader has logged on
disk when it ﬁrst starts up, it is guaranteed to discover the last
view that was installed in the pre-crash system before it exits
the await-quorum loop, because a restart quorum requires a
majority of nodes from the current view Vc to contact it. The
view-change protocol in virtual synchrony requires a majority
of the members of the current view to be members of the next
view, which means that if the restart leader starts with some
obsolete view Vk, a majority of members of Vk were also
members of Vk+1, and the restart leader will discover at least
one member of Vk+1 by waiting for a majority of members of
Vk. When a member of Vk+1 restarts, it will send Vk+1 to the
leader, which will then use Vk+1 as Vc and begin waiting for
a majority of Vk+1’s members. If Vk+1 is not the latest view,
then by the same logic, the leader is guaranteed to discover
Vk+2 on at least one of the members of this majority. Thus,
the leader must have discovered and installed the last known
view V(cid:2) by the time it has satisﬁed the quorum condition of
contacting a majority of Vc.
Furthermore, by the time the leader exits the await-quorum
loop, it is guaranteed to discover at least one log containing
all committed updates for each shard in the system. This is
because an additional condition of a restart quorum is that
the leader must contact at least one member of each shard
according to Vc. As we have just shown, Vc must equal V(cid:2)
before the majority condition of the quorum can be satisﬁed,
so the leader will contact at least one member of each shard
in V(cid:2). Since updates that commit in a view are by deﬁnition
logged on every member of a shard in that view, any node
that was a member of a shard in V(cid:2) will have a log containing
all committed updates for that shard up to the point of the
total crash. Thus, every shard will have a designated longest-
log location that contains all of its committed updates by the
time the leader exits the await-quorum loop. Recovery into a
mutually consistent state follows because membership epochs
are totally ordered with respect to SMR events in shards or
subgroups: the end of each epoch is a consistent cut [12].
The epoch termination decision ET that the leader sends out
after achieving quorum is guaranteed to preserve any decision
made by the group prior to the crash, and to include only
updates that were safe to commit. Since the system’s epoch
termination process (as augmented in section III) requires all
members of a view to log the epoch termination decision
before acting on it, by the time the leader reaches a majority
of V(cid:2), it must ﬁnd at least one copy of the epoch termination
information that was computed for V(cid:2) if any node acted upon
it. Using this epoch termination structure as ET preserves
the decision made by V(cid:2)’s reconﬁguration leader about which
updates to include. Conversely, if the leader does not ﬁnd any
epoch termination information for V(cid:2), then no node had yet
delivered or aborted any updates that were in-progress at the
time of the crash. This means it is safe for the restart leader
to construct ET using the longest sequence of updates that is
available on at least one node in each shard, and unilaterally
decide to commit any pending updates at the tail of that log.
Before any node installs a view in which those updates are
committed (Vr), the state transfer process ensures that any
pending updates are fully replicated to all members of their
shard. Thus, for each shard, every update up to the last commit
point in ET will be present on all members of that shard in
the new view, which is the same guarantee provided by the
epoch termination process during a normal run of the system.
Finally, the post-restart view Vr that the leader installs is
guaranteed to have the same stability and durability guarantees
as any other view in the running system. As we just showed,
all nodes that will be members of a shard in Vr will have the
exact same update log for that shard before Vr is installed,
which means that the updates committed in Vr are just as fault-
tolerant as updates in any prior view. Vr itself is also durable,
and guaranteed to be recovered by a future restart leader during
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:35:43 UTC from IEEE Xplore.  Restrictions apply. 
178
the recovery process, because a majority of members of V(cid:2) are
also members of Vr.
A. Tolerance of Failures of Non-Leaders
Our approach to failed non-leader nodes is to treat them as
nodes that have not yet restarted. Upon detecting a failure at
any point after reaching a restart quorum, the leader removes
the failed node from its restarted set, and recomputes both Vr
and whether it has a restart quorum. By sending an “abort”
message to all other nodes that may already have received
Vr, the leader ensures that they will return to waiting for
Vr and the epoch termination information. Regardless of how
many times nodes fail and restart during the restart process,
the leader still cannot proceed past the await-quorum loop
until it has reached a restart quorum, which means it must
reach at least one node from each shard that has all the
committed updates for that shard. Since nodes never truncate
updates from their logs that had actually committed in V(cid:2) (due
to the correctness of the epoch termination procedure), and
committed updates were present on every member of their
shard in V(cid:2), this will always be possible as long as enough
members of V(cid:2) eventually restart.
It is safe for the nodes that received ET and Vr from
the leader before it detected a failure to begin the epoch
termination and state transfer process, because at the point
the leader started sending Vr it had reached a restart quorum.
This means that ET only included updates that were safe to
commit, and only excluded updates that had deﬁnitely aborted.
Although Vr will change whenever there is a failure, the
only way that ET could change after a failure is to include
or exclude a different number of pending-but-uncommitted
updates at the tail of a shard’s log, and that will only happen
if the node that failed was the location of the longest log for
a shard. In that case, the new ET may include fewer of the
uncommitted updates at the tail of the shard’s log, but it is
equally safe to abort these updates, since they had not yet
committed at the end of V(cid:2). Nodes that had downloaded some
of these updates at the time of the failure will simply truncate
them when they re-run the epoch termination process.
The two-phase commit at
the end of the state-transfer
process ensures that all of the nodes in Vr are still live and
have ﬁnished state transfer before any of them can commit to