term “tickers”. Tickers are frequent cache probes that measure
how long it takes to access cache lines that contain program
instructions. A cache hit on a ticker gives the attacker a
signal she can use to determine whether to probe the cache
lines containing the T-Table used in the last AES encryption
round. In our case, we set two tickers. The ﬁrst ticker queries
instructions at the start of the encryption code (as loaded into
the process’ address space), and the second queries instructions
at the end of the encryption code. When either ticker is
triggered, we probe the T-Table cache lines, ideally measuring
cache state before and after encryptions.
Handling Drift. While tickers provide some signal, variations
in how the probe process is scheduled with respect to the
victim process introduce imperfections in the signal provided
by the tickers. Therefore, we also use timing heuristics to
match traces to corresponding ciphertexts. More speciﬁcally,
we iterate through the traces we collect, and keep a counter
identifying the next ciphertext to be matched to a trace. Then,
for each trace, we either match it to the current ciphertext and
increment the counter or discard it. We base this decision on
the accompanying ticker and timing data.
Our default case is to match the trace and ciphertext only
if the ticker indicating a recent end-of-encryption event was
triggered for that trace. However, to account for false negatives,
the ticker indicating a recent start-of-encryption event is used if
the interval between the last matched trace’s timestamp and the
current trace’s timestamp exceeds a threshold we determined
empirically. Similarly, if neither ticker was triggered, but the
elapsed time is greater than another empirically-determined
threshold, we match the trace and ciphertext.
Finally, using a ticker to determine when to start collecting
traces may cause the attacker miss some traces belonging to
the initial encryptions. We overcome this by running the key
recovery algorithm with each possible set of matchings, for a
small number of potential initial matches.
Overcoming Prefetching. Modern CPUs attempt to learn
a program’s cache access pattern and fetch data into caches
before this data is actually needed. This data prefetching
frustrates cache side-channel attacks against T-Table AES by
reducing the extent to which a recorded cache hit corresponds
to an actual–rather than predicted–access. If an entire AES
T-Table is preemptively fetched into memory, a naïve cache
side-channel attack will not succeed because the attacker will
record cache hits for every memory line.
We mitigated the effect of the prefetcher by accessing cache
lines in an irregular order, using the pointer chasing technique
of Osvik et al. [64]. This reduces the prefetcher’s ability to
predict our cache accesses and prefetch those lines.
Performance Degradation.
If the time it takes to probe the
cache state is too long relative to the duration of an encryption,
an attacker will not be able to generate traces that accurately
capture the state of the cache after each encryption. Allan
et al. [1] showed that this difﬁculty could be mitigated by
continuously ﬂushing cache lines containing victim program
instructions, so that the victim process was signiﬁcantly slowed
down. Flushing cache lines requires the victim to repeatedly
fetch code from main memory, increasing access times. On our
system, this slowed down the average duration of an encryption
from 2 μsec to 32 μsec, giving us a large 34μsec window
between successive last AES rounds for cache probing.
Validating Key Candidates.
In our setting, plaintexts
encrypted within a single call to the CTR_DRBG generate
function are sequential integers, providing a test to determine
the correctness of a recovered key. Given a series of ciphertexts
and a candidate key, we validate the key by decrypting the
PRG output and checking if the plaintexts form a successive
series of integers. The ﬁnal integer in the sequence is the last
counter value before the state is updated. Given the recovered
key K, counter value V, and a valid guess for addin (if any is
used), the subsequent state and output of CTR_DRBG can be
generated by executing the update subroutine.
D I F F E R E N T I A L C R Y P TA N A LY S I S D E TA I L S
A P P E N D I X B
Differential Propagation.
In a differential attack we can
only recover state bytes that differ in the two encryptions. Our
attacks thus follows the “differential propagation” in the AES
rounds as shown in Fig. 4. This will allow us to recover one
byte of state of round 0, 4 bytes of the state of round 1, and
the entire states from round 2 and above.
From State to Key and Plaintext Recovery. Assuming we
were able to recover the full values of the states in rounds j
and j + 1, we can now recover the key for round j + 1:
Si, j+1 = Kj+1 ⊕ P(Si, j )
and
Kj+1 = Si, j+1 ⊕ P(Si, j )
As the AES key schedule for deriving the round keys is
invertible, we can use any 128 bit round keys to recover the
original 128 bit AES key (we need two consecutive round keys
for 256 bit AES keys). From the recovered key and state we
can calculate both the plaintext and ciphertext.
Iterative State Guess Elimination.
In the beginning of
step j of our attack we have one or more possible guesses
for the values of the state bytes of round j. For each guess
Authorized licensed use limited to: University of New South Wales. Downloaded on October 18,2020 at 16:24:55 UTC from IEEE Xplore.  Restrictions apply. 
1257
Algorithm 5 Find possible guesses for byte 0, 5, 10 and 15
of round 2.
1: function
B Y T E 0 - 5 - 1 0 - 1 5 - R O U N D 2(L0,2,(0,5,10,15),
Δ2,(0,5,10,15), LΔ3,0..3)
GuessList2 ← Empty
IndxList ← [0,5,10,15]
for Guess ← 0 to 216 − 1 do
Δ3,0..3 = 0
for i ← 0 to 3 do
Nibble = (Guess >> (i ∗ 4))&0x f
G0,2, I ndx List[i] = L0,2, I ndx List[i]⊕ Nibble
Δ3,0..3 ⊕= Ti[G0,2, I ndx List[i]]
Δ3,0..3 ⊕= Ti[G0,2, I ndx List[i] ⊕ Δ2, I ndx List[i]]
if (cid:10)Δ3,0..3(cid:11)U = LΔ3,0..3 then
GuessList2.append(G0,2,(0,5,10,15), Δ3,0..3)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
Byte:
Round 0
Round 1
Round 2
0
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
Round 3
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
*
Fig. 4: Single byte differential propagation in AES state.
GuessList1 ← Empty
for Nibble ← 0 to 24 − 1 do
Algorithm 4 Find possible guesses for byte 0 of Round 1.
1: function B Y T E 0 R O U N D 1(L0,1,0, Δ1,0, LΔ2,0..3)
2:
3:
4:
5:
6:
7:
G0,1,0 = L0,1,0⊕ Nibble
Δ2,0..3 = T0[G0,1,0] ⊕ T0[G0,1,0 ⊕ Δ1,0]
if
(cid:10)Δ2,0..3(cid:11)U = LΔ2,0..3 then
GuessList1.append(G0,1,0, Δ2,0..3)
8:
return GuessList1
we enumerate all possible guesses for state bytes in round
j + 1, and efﬁciently eliminating guesses that does not satisfy
the above equations for the “differential propagation”. The
remaining guess are used as input for the next step of the
attack. When we have a guess for the state of two full rounds
we can try to recover the plaintext of the traces and verify that
they are indeed a part of an incriminating counter.
Note that using 3 or more traces helps in eliminating wrong
guesses, usually leaving just a single guess after each step.
The Full Attack. As we have seen we can retrieve GuessList0
that contains all possible guess for G0,0,15 and Δ1,0..3 using
Algorithm 3. For each guess in GuessList0 we now try to
recover 4 bytes from round 1 using a similar method. As
each of the 4 bytes affect different 4 bytes in round 2, we
run the same algorithm as in step 1 using different values.
In Algorithm 4 we show how to ﬁnd the possible guesses
for G0,1,0. A similar function will ﬁnd the possible guesses
for G0,1,1, G0,1,2 and G0,1,3. As there may be more than one
guess for each byte value, the full guess list GuessList1 is the
set of possible combinations of guesses for each of the bytes.
In the third phase of our attack, we try to generate all of
the possible guesses for the entire state of round 2. Due to
the “Shift Row” transformation of AES, the value of each of
the 4 bytes in round 1 affect the values of distinct 4 bytes
in round 2 (see Fig. 4). The same guessing logic as before
allows us to create the new guess list (see Algorithm 5 for
example). The guess list GuessList2 is created from all the
possible combinations of the guess for each 4 byte group
(this is done separately for each guess in GuessList1). We can
repeat the same process to use GuessList2 to create the guess
list GuessList3 for the state of round 3 (and in the case of
AES 256 continue another round to get GuessList4).
As we have shown, for each guess in GuessList3 (GuessList4
for AES256) we can now recover a guess for the full key state
and the plaintext for each trace. For each such guess, we check
if the resulting plaintexts form an incrementing counter.
return GuessList2
C O N T R O L L E D - C H A N N E L AT TA C K O N S G X
A P P E N D I X C
To generate the required traces, an attacker with OS level
privileges (root) monitors cache access through Prime+Probe.
The attack obtains ﬁne-grained temporal resolution through
a controlled-channel [90] attack. A controlled-channel attack
involves disabling the present bit on the enclave’s page tables,
which by necessity are handled by the OS. By marking the
page containing the T-Tables as not-present, the attacker forces
an asynchronous enclave exit upon access to the table, thereby
transferring control to the attacker controlled OS.
Since all of the T-Tables lie in the same page, the attacker
must ‘toggle’ between accesses by performing a controlled-
channel attack on a page access that occurs in between each
access. We use the page containing the topmost frame of the
stack for this, as the mbedTLS implementation must ﬁrst read
the index into the T-Table from the stack before each access.
Unlike the T-Table addresses, however, the location of the
stack is randomized by the SGX loader. We overcome this by
ﬁrst using a controlled-channel attack to force an enclave exit
upon entrance to the AES function. We then mark all pages
in the enclave, except for the thread control structure (TCS),
saved state area (SSA), and the pages containing code, as not-
present. We then resume execution within the enclave; since
the ﬁrst instruction of the function prologue is push_rbp,
control immediately returns to our segmentation fault handler.
Within the handler, we can determine which page caused
the segmentation fault, which in this case will be the page
containing the top of the stack.
In this manner, we learn the location of the stack for use in
our controlled-channel attack. Then, by forcing enclave exits
upon each access to the T-Tables, we use a last-level cache
Prime+Probe attack to measure each T-Table access separately.
To reduce error, we used Intel’s cache allocation technology
to partition a single way of the LLC to both the victim
and attacking process, and used the isolcpus kernel boot
parameter to isolate them on a single physical core.
Authorized licensed use limited to: University of New South Wales. Downloaded on October 18,2020 at 16:24:55 UTC from IEEE Xplore.  Restrictions apply. 
1258