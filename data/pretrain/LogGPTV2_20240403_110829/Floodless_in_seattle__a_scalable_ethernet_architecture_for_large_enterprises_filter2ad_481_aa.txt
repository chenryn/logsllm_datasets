title:Floodless in seattle: a scalable ethernet architecture for large enterprises
author:Changhoon Kim and
Matthew Caesar and
Jennifer Rexford
Floodless in SEATTLE: A Scalable Ethernet Architecture
for Large Enterprises
Changhoon Kim
Princeton University
Princeton, NJ
PI:EMAIL
Matthew Caesar
University of Illinois
Urbana-Champaign, IL
PI:EMAIL
Jennifer Rexford
Princeton University
Princeton, NJ
PI:EMAIL
ABSTRACT
IP networks today require massive effort to conﬁgure and man-
age. Ethernet is vastly simpler to manage, but does not scale be-
yond small local area networks. This paper describes an alterna-
tive network architecture called SEATTLE that achieves the best
of both worlds: The scalability of IP combined with the simplicity
of Ethernet. SEATTLE provides plug-and-play functionality via
ﬂat addressing, while ensuring scalability and efﬁciency through
shortest-path routing and hash-based resolution of host informa-
tion. In contrast to previous work on identity-based routing, SEAT-
TLE ensures path predictability and stability, and simpliﬁes net-
work management. We performed a simulation study driven by
real-world trafﬁc traces and network topologies, and used Emulab
to evaluate a prototype of our design based on the Click and XORP
open-source routing platforms. Our experiments show that SEAT-
TLE efﬁciently handles network failures and host mobility, while
reducing control overhead and state requirements by roughly two
orders of magnitude compared with Ethernet bridging.
Categories and Subject Descriptors
C.2.1 [Computer-Communication Network]: Network Archi-
tecture and Design; C.2.2 [Computer-Communication Net-
work]: Network Protocols; C.2.5 [Computer-Communication
Network]: Local and Wide-Area Networks
General Terms
Design, Experimentation, Management
Keywords
Enterprise network, Routing, Scalablity, Ethernet
1.
INTRODUCTION
Ethernet stands as one of the most widely used networking tech-
nologies today. Due to its simplicity and ease of conﬁguration,
many enterprise and access provider networks utilize Ethernet as
an elementary building block. Each host in an Ethernet is as-
signed a persistent MAC address, and Ethernet bridges automat-
ically learn host addresses and locations. These “plug-and-play”
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’08, August 17–22, 2008, Seattle, Washington, USA.
Copyright 2008 ACM 978-1-60558-175-0/08/08 ...$5.00.
semantics simplify many aspects of network conﬁguration. Flat
addressing simpliﬁes the handling of topology changes and host
mobility, without requiring administrators to reassign addresses.
However, Ethernet is facing revolutionary challenges. Today’s
layer-2 networks are being built on an unprecedented scale and with
highly demanding requirements in terms of efﬁciency and avail-
ability. Large data centers are being built, comprising hundreds
of thousands of computers within a single facility [1], and main-
tained by hundreds of network operators. To reduce energy costs,
these data centers employ virtual machine migration and adapt to
varying workloads, placing additional requirements on agility (e.g.,
host mobility, fast topology changes). Additionally, large metro
Ethernet deployments contain over a million hosts and tens of thou-
sands of bridges [2]. Ethernet is also being increasingly deployed in
highly dynamic environments, such as backhaul for wireless cam-
pus networks, and transport for developing regions [3].
While an Ethernet-based solution becomes all the more impor-
tant in these environments because it ensures service continuity and
simpliﬁes conﬁguration, conventional Ethernet has some critical
limitations. First, Ethernet bridging relies on network-wide ﬂood-
ing to locate end hosts. This results in large state requirements and
control message overhead that grows with the size of the network.
Second, Ethernet forces paths to comprise a spanning tree. Span-
ning trees perform well for small networks which often do not have
many redundant paths anyway, but introduce substantial inefﬁcien-
cies on larger networks that have more demanding requirements for
low latency, high availability, and trafﬁc engineering. Finally, crit-
ical bootstrapping protocols used frequently by end hosts, such as
Address Resolution Protocol (ARP) and Dynamic Host Conﬁgura-
tion Protocol (DHCP), rely on broadcasting. This not only con-
sumes excessive resources, but also introduces security vulnerabil-
ities and privacy concerns.
Network administrators sidestep Ethernet’s inefﬁciencies today
by interconnecting small Ethernet LANs using routers running the
Internet Protocol (IP). IP routing ensures efﬁcient and ﬂexible use
of networking resources via shortest-path routing. It also has con-
trol overhead and forwarding-table sizes that are proportional to
the number of subnets (i.e., preﬁxes), rather than the number of
hosts. However, introducing IP routing breaks many of the desir-
able properties of Ethernet. For example, network administrators
must now subdivide their address space to assign IP preﬁxes across
the topology, and update these conﬁgurations when the network de-
sign changes. Subnetting leads to wasted address space, and labo-
rious conﬁguration tasks. Although DHCP automates host address
conﬁguration, maintaining consistency between DHCP servers and
routers still remains challenging. Moreover, since IP addresses are
not persistent identiﬁers, ensuring service continuity across loca-
tion changes (e.g., due to virtual machine migration or physical
mobility) becomes more challenging. Additionally, access-control
policies must be speciﬁed based on the host’s current position, and
updated when the host moves.
Alternatively, operators may use Virtual LANs (VLANs) to build
IP subnets independently of host location. While the overhead of
address conﬁguration and IP routing may be reduced by provision-
ing VLANs over a large number of, if not all, bridges, doing so
reduces beneﬁts of broadcast scoping, and worsens data-plane efﬁ-
ciency due to larger spanning trees. Efﬁciently assigning VLANs
over bridges and links must also consider hosts’ communication
and mobility patterns, and hence is hard to automate. Moreover,
since hosts in different VLANs still require IP to communicate with
one another, this architecture still inherits many of the challenges
of IP mentioned above.
In this paper, we address the following question: Is it possible to
build a protocol that maintains the same conﬁguration-free proper-
ties as Ethernet bridging, yet scales to large networks? To answer,
we present a Scalable Ethernet Architecture for Large Enterprises
(SEATTLE). Speciﬁcally, SEATTLE offers the following features:
A one-hop, network-layer DHT: SEATTLE forwards packets
based on end-host MAC addresses. However, SEATTLE does not
require each switch to maintain state for every host, nor does it re-
quire network-wide ﬂoods to disseminate host locations. Instead,
SEATTLE uses the global switch-level view provided by a link-
state routing protocol to form a one-hop DHT [4], which stores the
location of each host. We use this network-layer DHT to build
a ﬂexible directory service which also performs address resolu-
tion (e.g., storing the MAC address associated with an IP address),
and more ﬂexible service discovery (e.g., storing the least loaded
DNS server or printer within the domain). In addition, to provide
stronger fault isolation and to support delegation of administrative
control, we present a hierarchical, multi-level one-hop DHT.
Trafﬁc-driven location resolution and caching: To forward pack-
ets along shortest paths and to avoid excessive load on the direc-
tory service, switches cache responses to queries.
In enterprise
networks, hosts typically communicate with a small number of
other hosts [5], making caching highly effective. Furthermore,
SEATTLE also provides a way to piggyback location information
on ARP replies, which eliminates the need for location resolution
when forwarding data packets. This allows data packets to directly
traverse the shortest path, making the network’s forwarding behav-
ior predictable and stable.
A scalable, prompt cache-update protocol: Unlike Ethernet which
relies on timeouts or broadcasts to keep forwarding tables up-to-
date, SEATTLE proposes an explicit and reliable cache update pro-
tocol based on unicast. This ensures that all packets are delivered
based on up-to-date state while keeping control overhead low. In
contrast to conventional DHTs, this update process is directly trig-
gered by network-layer changes, providing fast reaction times. For
example, by observing link-state advertisements, switches deter-
mine when a host’s location is no longer reachable, and evict those
invalid entries. Through these approaches, SEATTLE seamlessly
supports host mobility and other dynamics.
Despite these features, our design remains compatible with ex-
isting applications and protocols running at end hosts. For exam-
ple, SEATTLE allows hosts to generate broadcast ARP and DHCP
messages, and internally converts them into unicast queries to a di-
rectory service. SEATTLE switches can also handle general (i.e.,
non-ARP and non-DHCP) broadcast trafﬁc through loop-free mul-
ticasting. To offer broadcast scoping and access control, SEATTLE
also provides a more scalable and ﬂexible mechanism that allows
administrators to create VLANs without trunk conﬁguration.
1.1 Related work
Our quest is to design, implement, and evaluate a practical re-
placement for Ethernet that scales to large and dynamic networks.
Although there are many approaches to enhance Ethernet bridg-
ing, none of these are suitable for our purposes. RBridges [6,
7] leverage a link-state protocol to disseminate information about
both bridge connectivity and host state. This eliminates the need
to maintain a spanning tree and improves forwarding paths. CMU-
Ethernet [8] also leverages link-state and replaces end-host broad-
casting by propagating host
information in link-state updates.
Viking [9] uses multiple spanning trees for faster fault recovery,
which can be dynamically adjusted to conform to changing load.
SmartBridges [10] allows shortest-path forwarding by obtaining
the network topology, and monitoring which end host is attached to
each switch. However, its control-plane overheads and storage re-
quirements are similar to Ethernet, as every end host’s information
is disseminated to every switch. Though SEATTLE was inspired by
the problems addressed in these works, it takes a radically different
approach that eliminates network-wide dissemination of per-host
information. This results in substantially improved control-plane
scalability and data-plane efﬁciency. While there has been work on
using hashing to support ﬂat addressing conducted in parallel with
our work [11, 12], these works do not promptly handle host dy-
namics, require some packets to be detoured away from the shortest
path or be forwarded along a spanning tree, and do not support hi-
erarchical conﬁgurations to ensure fault/path isolation and the del-
egation of administrative control necessary for large networks.
The design we propose is also substantially different from re-
cent work on identity-based routing (ROFL [13], UIP [14], and
VRR [15]). Our solution is suitable for building a practical and
easy-to-manage network for several reasons. First, these previous
approaches determine paths based on a hash of the destination’s
identiﬁer (or the identiﬁer itself), incurring a stretch penalty (which
is unbounded in the worst case). In contrast, SEATTLE does not
perform identity-based routing. Instead, SEATTLE uses resolution
to map a MAC address to a host’s location, and then uses the loca-
tion to deliver packets along the shortest path to the host. This re-
duces latency and makes it easier to control and predict network be-
havior. Predictability and controllability are extremely important in
real networks, because they make essential management tasks (e.g.,
capacity planning, troubleshooting, trafﬁc engineering) possible.
Second, the path between two hosts in a SEATTLE network does
not change as other hosts join and leave the network. This substan-
tially reduces packet reordering and improves constancy of path
performance. Finally, SEATTLE employs trafﬁc-driven caching of
host information, as opposed to the trafﬁc-agnostic caching (e.g.,
ﬁnger caches in ROFL) used in previous works. By only caching
information that is needed to forward packets, SEATTLE signif-
icantly reduces the amount of state required to deliver packets.
However, our design also consists of several generic components,
such as the multi-level one-hop DHT and service discovery mech-
anism, that could be adapted to the work in [13, 14, 15].
Roadmap: We summarize how conventional enterprise networks
are built and motivate our work in Section 2. Then we describe
our main contributions in Sections 3 and 4 where we introduce a
very simple yet highly scalable mechanism that enables shortest-
path forwarding while maintaining the same semantics as Ethernet.
In Section 5, we enhance existing Ethernet mechanisms to make
our design backwards-compatible with conventional Ethernet. We
then evaluate our protocol using simulations in Section 6 and an im-
plementation in Section 7. Our results show that SEATTLE scales
to networks containing two orders of magnitude more hosts than
a traditional Ethernet network. As compared with ROFL, SEAT-
TLE reduces state requirements required to achieve reasonably low
stretch by a factor of ten, and improves path stability by more than
three orders of magnitude under typical workloads. SEATTLE also
handles network topology changes and host mobility without sig-
niﬁcantly increasing control overhead.
2. TODAY’S ENTERPRISE AND ACCESS
NETWORKS
To provide background for the remainder of the paper, and to
motivate SEATTLE, this section explains why Ethernet bridging
does not scale. Then we describe hybrid IP/Ethernet networks and
VLANs, two widely-used approaches which improve scalability
over conventional Ethernet, but introduce management complexity,
eliminating the “plug-and-play” advantages of Ethernet.
2.1 Ethernet bridging
An Ethernet network is composed of segments, each comprising
a single physical layer 1. Ethernet bridges are used to interconnect
multiple segments into a multi-hop network, namely a LAN, form-
ing a single broadcast domain. Each host is assigned a unique 48-
bit MAC (Media Access Control) address. A bridge learns how to
reach hosts by inspecting the incoming frames, and associating the
source MAC address with the incoming port. A bridge stores this
information in a forwarding table that it uses to forward frames
toward their destinations.
If the destination MAC address is not
present in the forwarding table, the bridge sends the frame on all
outgoing ports, initiating a domain-wide ﬂood. Bridges also ﬂood
frames that are destined to a broadcast MAC address. Since Ether-
net frames do not carry a TTL (Time-To-Live) value, the existence
of multiple paths in the topology can lead to broadcast storms,
where frames are repeatedly replicated and forwarded along a loop.
To avoid this, bridges in a broadcast domain coordinate to compute
a spanning tree [16]. Administrators ﬁrst select and conﬁgure a
single root bridge; then, the bridges collectively compute a span-
ning tree based on distances to the root. Links not present in the
tree are not used to carry trafﬁc, causing longer paths and inefﬁ-
cient use of resources. Unfortunately, Ethernet-bridged networks
cannot grow to a large scale due to following reasons.
Globally disseminating every host’s location: Flooding and
source-learning introduce two problems in a large broadcast do-
main. First, the forwarding table at a bridge can grow very large
because ﬂat addressing increases the table size proportionally to the
total number of hosts in the network. Second, the control overhead
required to disseminate each host’s information via ﬂooding can be
very large, wasting link bandwidth and processing resources. Since
hosts (or their network interfaces) power up/down (manually, or dy-
namically to reduce power consumption), and change location rela-
tively frequently, ﬂooding is an expensive way to keep per-host in-
formation up-to-date. Moreover, malicious hosts can intentionally
trigger repeated network-wide ﬂoods through, for example, MAC
address scanning attacks [17].
Inﬂexible route selection: Forcing all trafﬁc to traverse a single
spanning tree makes forwarding more failure-prone and leads to
suboptimal paths and uneven link loads. Load is especially high on
links near the root bridge. Thus, choosing the right root bridge is
extremely important, imposing an additional administrative burden.
Moreover, using a single tree for all communicating pairs, rather
than shortest paths, signiﬁcantly reduces the aggregate throughput
of a network.
1In modern switched Ethernet networks, a segment is just a point-
to-point link connecting an end host and a bridge, or a pair of
bridges.
Dependence on broadcasting for basic operations: DHCP and
ARP are used to assign IP addresses and manage mappings be-
tween MAC and IP addresses, respectively. A host broadcasts a
DHCP-discovery message whenever it believes its network attach-
ment point has changed. Broadcast ARP requests are generated
more frequently, whenever a host needs to know the MAC address
associated with the IP address of another host in the same broad-
cast domain. Relying on broadcast for these operations degrades
network performance. Moreover, every broadcast message must be
processed by every end host; since handling of broadcast frames
is often application or OS-speciﬁc, these frames are not handled by
the network interface card, and instead must interrupt the CPU [18].
For portable devices on low-bandwidth wireless links, receiving
ARP packets can consume a signiﬁcant fraction of the available
bandwidth, processing, and power resources. Moreover, the use of
broadcasting for ARP and DHCP opens vulnerabilities for mali-
cious hosts as they can easily launch ARP or DHCP ﬂoods [8].
2.2 Hybrid IP/Ethernet architecture
One way of dealing with Ethernet’s limited scalability is to build
enterprise and access provider networks out of multiple LANs in-
terconnected by IP routing. In these hybrid networks, each LAN
contains at most a few hundred hosts that collectively form an IP
subnet. Communication across subnets is handled via certain ﬁxed
nodes called default gateways. Each IP subnet is allocated an IP
preﬁx, and each host in the subnet is then assigned an IP address
from the subnet’s preﬁx. Assigning IP preﬁxes to subnets, and as-
sociating subnets with router interfaces is typically a manual pro-
cess, as the assignment must follow the addressing hierarchy, yet
must reduce wasted namespace, and must consider future use of
addresses to minimize later reassignment. Unlike a MAC address,
which functions as a host identiﬁer, an IP address denotes the host’s
current location in the network.
The biggest problem of the hybrid architecture is its massive con-
ﬁguration overhead. Conﬁguring hybrid networks today represents
an enormous challenge. Some estimates put 70% of an enterprise
network’s operating cost as maintenance and conﬁguration, as op-
posed to equipment costs or power usage [19].
In addition, in-
volving human administrators in the loop increases reaction time
to faults and increases potential for misconﬁguration.
Conﬁguration overhead due to hierarchical addressing: An IP
router cannot function correctly until administrators specify sub-
nets on router interfaces, and direct routing protocols to advertise
the subnets. Similarly, an end host cannot access the network un-
til it is conﬁgured with an IP address corresponding to the sub-
net where the host is currently located. DHCP automates end-host
conﬁguration, but introduces substantial conﬁguration overhead for
managing the DHCP servers. In particular, maintaining consistency
between routers’ subnet conﬁguration and DHCP servers’ address
allocation conﬁguration, or coordination across distributed DHCP
servers are not simple. Finally, network administrators must con-
tinually revise this conﬁguration to handle network changes.
Complexity in implementing networking policies: Administrators
today use a collection of access controls, QoS (Quality of Ser-
vice) controls [20], and other policies to control the way packets
ﬂow through their networks. These policies are typically deﬁned
based on IP preﬁxes. However, since preﬁxes are assigned based on
the topology, changes to the network design require these policies
to be rewritten. More signiﬁcantly, rewriting networking policies
must happen immediately after network design changes to prevent
reachability problems and to avoid vulnerabilities. Ideally, admin-
istrators should only need to update policy conﬁgurations when the
policy itself, not the network, changes.
Limited mobility support: Supporting seamless host mobility is
becoming increasingly important. In data centers, migratable vir-
tual machines are being widely deployed to improve power efﬁ-
ciency by adapting to workload, and to minimize service disruption
during maintenance operations. Large universities or enterprises
often build campus-wide wireless networks, using a wired back-
haul to support host mobility across access points. To ensure ser-
vice continuity and minimize policy update overhead, it is highly
desirable for a host to retain its IP address regardless of its loca-
tion in these networks. Unfortunately, hybrid networks constrain
host mobility only within a single, usually small, subnet. In a data
center, this can interfere with the ability to handle load spikes seam-
lessly; in wireless backhaul networks, this can cause service disrup-
tions. One way to deal with this is to increase the size of subnets
by increasing broadcast domains, introducing the scaling problems
mentioned in Section 2.1.
2.3 Virtual LANs
VLANs address some of the problems of Ethernet and IP net-
works. VLANs allow administrators to group multiple hosts shar-
ing the same networking requirements into a single broadcast do-
main. Unlike a physical LAN, a VLAN can be deﬁned logically,
regardless of individual hosts’ locations in a network. VLANs can
also be overlapped by allowing bridges (not hosts) to be conﬁg-
ured with multiple VLANs. By dividing a large bridged network