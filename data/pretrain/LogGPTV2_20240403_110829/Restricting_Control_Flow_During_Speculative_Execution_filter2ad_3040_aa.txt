title:Restricting Control Flow During Speculative Execution
author:Zhuojia Shen and
Jie Zhou and
Divya Ojha and
John Criswell
POSTER: Restricting Control Flow During Speculative Execution
Zhuojia Shen
University of Rochester
PI:EMAIL
Divya Ojha
University of Rochester
PI:EMAIL
Jie Zhou
University of Rochester
PI:EMAIL
John Criswell
University of Rochester
PI:EMAIL
ABSTRACT
Speculative execution is one of the key techniques that modern
processors use to boost performance. However, recent research
shows that speculative execution can be used to steal sensitive data.
We present a software-based solution to mitigate Spectre attacks by
restricting the control flow of speculatively-executed instructions.
CCS CONCEPTS
• Security and privacy → Side-channel analysis and counter-
measures; Systems security;
KEYWORDS
speculative execution, side-channel defenses, Spectre attacks
ACM Reference Format:
Zhuojia Shen, Jie Zhou, Divya Ojha, and John Criswell. 2018. POSTER: Re-
stricting Control Flow During Speculative Execution. In 2018 ACM SIGSAC
Conference on Computer and Communications Security (CCS ’18), October
15–19, 2018, Toronto, ON, Canada. ACM, New York, NY, USA, 3 pages.
https://doi.org/10.1145/3243734.3278522
1 INTRODUCTION
Modern high-performance processors support speculative execu-
tion and out-of-order execution. Speculative execution [11] is a
technique in which the processor speculatively executes instruc-
tions prior to knowing that they are required in order to improve
performance; if the processor later determines that the instructions
should not have been executed, it discards the computation, rolling
back all the architectural effects resulting from the speculatively-
executed instructions. Out-of-order execution [11] is a performance
improvement in which the processor executes instructions out of
program order to maximize throughput. While these features are
meant to improve processor performance, recent research (Melt-
down [10] and Spectre [7]) has shown that attackers can leverage
these optimizations to launch powerful side-channel attacks. Melt-
down [10] exploits out-of-order execution and a security defect
in which the processor performs the hardware MMU protection
check late in the pipeline, using them to bypass hardware-enforced
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278522
memory isolation. Spectre [7] tricks the processor into specula-
tively executing instructions that load a victim’s secret data into
registers and then leaks the data via a cache side channel. To date,
at least four new variants of Meltdown and Spectre have been
discovered [4–6, 8].
While there exist compiler-based transformations that defend
against Meltdown [10] and Spectre [7] (such as Spectre-resistant
software fault isolation (SFI) [3]), they typically cannot mitigate
Branch Target Injection (i.e., Spectre Variant 2 [7]) which mistrains
the processor’s Branch Target Buffer (BTB) to hijack speculative
control flow. To mistrain, or poison, the BTB, the attacker pro-
gram repeatedly executes a set of branches that jump to a target
address [7]. Since the BTB is shared, branches in the victim will
reuse these BTB entries that were trained by the attacker. This
causes the processor to mistakenly jump to the desired address
while executing victim code, causing it to speculatively execute
code of the attacker’s choosing. Since there is no way for existing
software defenses to prevent BTB poisoning, they cannot prevent
such attacks. Worse yet, the retpoline defense [12] does not work as
it is susceptible to a new Spectre variant called SpectreRSB [8] that
manipulates the processor’s Return Stack Buffer (RSB). SpectreRSB
works similarly to BTB poisoning except that it poisons the RSB to
influence the target prediction of return instructions.
In this paper, we present Venkman, a novel software-based solu-
tion to enhance existing software defenses against Spectre. Venkman
employs compiler techniques to create bundles of instructions that
are equally power-of-two sized and aligned. By bit-masking all in-
direct branch targets at run-time, Venkman restricts all branches to
jump to the beginning of bundles. By transforming all code on the
system with Venkman, all BTB entries can only be trained to jump
to the beginning of bundles. If all instructions to mitigate Spectre
attacks are contained within a bundle, training of the BTB will not
be able to jump into the middle of a bundle to avoid executing them.
For processors that use dedicated return instructions, Venkman
transforms returns to indirect jumps so that they use the BTB in-
stead of the RSB for prediction. Bundle alignment and branch target
restrictions are the key to ensuring that existing defenses are not
bypassed: with Venkman, existing compiler-based Spectre defenses
such as load fences [5] and Spectre-resistant SFI [3] on loads are
always guaranteed to be executed on any program path taken dur-
ing speculative execution. Venkman also utilizes Spectre-resistant
SFI [3] on stores to protect the program’s code segment from a
new Meltdown variant [6] that breaks read-only memory protec-
tion. Our defenses are self-protecting; bundle alignment and branch
target restrictions prevent SFI on stores from being speculatively
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2297bypassed, while SFI on stores ensures that the code segment is not
modified during speculative execution.
Venkman instruments programs to resist Spectre. However, the
instrumentation must be performed on every program in the system
in order to take effect: one single uninstrumented program can mis-
train the BTB to attack instrumented programs. Several solutions
exist for ensuring that all code is transformed by Venkman. One is
to use a system like Secure Virtual Architecture (SVA) [2] which
forces all code to be shipped as virtual instruction set code; the
SVA virtual machine will translate the code to native code before
execution, transforming it with Venkman during code generation.
Alternatively, the operating system and dynamic loader can use a
binary code verifier like that in Google’s Native Client (NaCl) [13]
to verify that all programs it loads into memory for execution have
been previously transformed with Venkman (the operating system
kernel must be transformed with Venkman as well). If a program is
found to be non-compliant with Venkman’s restrictions, the oper-
ating system kernel can refuse to load the code for execution.
2 DESIGN
Venkman consists of two defenses: one combining bundle align-
ment and branch target restrictions that constrain the addresses
to which branches can jump, and the other leveraging Spectre-
resistant SFI [3] on memory writes to prevent speculative writes
to the code segment. We show that our first defense mitigates mis-
training of the processor’s BTB, and our second defense defeats
Read-only Protection Bypass attacks on the code segment [6].
2.1 Restricting Branch Targets to Bundles
Bundle Alignment. A bundle is a sequence of instructions that
has a fixed power-of-two size and alignment in which the size and
alignment are the same value. Venkman ensures that the target of
all branches is at the beginning of a bundle. In this way, Venkman
ensures that all the instructions inside a bundle are executed as
a whole in the control flow. This requirement also implies that
branches such as function calls must be at the end of a bundle so
that their return addresses are aligned at the beginning of the next
bundle. This is similar to NaCl [13].
Venkman transforms code during code generation to create bun-
dles. It searches for basic blocks of instructions that are larger than
the bundle size and breaks them into smaller basic blocks. When it
breaks up larger basic blocks, Venkman ensures that instructions
that must be co-located within the same bundle are not separated.
For example, if the Spectre defense that Venkman is enhancing adds
two instructions before every load, then Venkman will ensure that
the load and the two instructions before it will end up in the same
bundle, adding NOP instructions to the beginning of the bundle
if keeping the instructions together results in a basic block that is
smaller than the bundle size. For basic blocks with fewer instruc-
tions than the bundle size, Venkman adds NOP instructions to the
beginning of the basic block to increase its size to the bundle size.
Once all the basic blocks are of the correct size, Venkman aligns
each basic block. It also aligns the start address of each function to
ensure it falls on a bundle boundary.
Branch Target Restrictions. Venkman uses compiler instrumen-
tation to restrict the targets of a branch to be at the beginning of
a bundle. This is similar to NaCl’s control flow policy [13] that
prevents jumps around required compiler instrumentation.
For direct branches, no instrumentation is needed; all basic
blocks and functions are aligned, so the target address of all di-
rect branches is also aligned. For indirect branches, Venkman adds
two bit-masking instructions before every indirect branch. First,
it adds an instruction which aligns the target address to a bundle
boundary; for a bundle size of 2S bytes, the bit-masking instruction
clears the lowest-order S bits. Second, it adds a bit-masking instruc-
tion that ensures that the target is within the code segment; for
example, if we place the code segment in the first 2S bytes of the
virtual address space, then our instrumentation clears the upper
(64 − S) bits of the target address.
If all code on a system is transformed in this way, and if all code
segments reside in the same region of the virtual address space in all
processes, then these restrictions on control flow prevent mistrain-
ing of the BTB with arbitrary addresses: only the starting address
of a bundle can go into the BTB. Additionally, Venkman converts
all return instructions into indirect branches. If such instructions
use the RSB, it ensures that all addresses in the RSB reside on a
bundle boundary (since all call instructions occur at the end of a
bundle). If the conversion causes the branch to use the BTB instead
of the RSB, then it still ensures that all targets are bundle addresses.
2.2 Speculative Code Segment Integrity
Not only can speculative execution leak secret data, but it can also
corrupt memory locations temporarily during speculative execution
via speculative memory writes [6]. Even if the operating system
configures the code segment to be non-writeable, speculative cor-
ruption of the code segment may still be possible if the processor
checks page permissions too late in the processor pipeline [6] and
the result of the speculative write is forwarded to the instruction
fetch unit for subsequent reads. To solve this problem, we use
Spectre-resistant SFI [3] on store instructions to ensure that they
do not speculatively write to the code segment. Spectre-resistant
SFI works by creating a data dependence between the bit-masking
SFI code and the subsequent memory access so that the memory
access are stalled until the SFI code completes execution [3]. By
using Spectre-resistant SFI on stores, Venkman ensures that the
target address of stores are outside the code segment before the
store begins to write memory speculatively.
In order to make Spectre-resistant SFI on stores efficient, Venkman
must ensure that all code resides in one portion of the virtual ad-
dress space and the heap, stack, globals, and memory mapped files
occupy a separate region of the virtual address space. If the different
regions for code and data are chosen carefully, a simple bit-masking
operation with a constant value suffices to ensure that store instruc-
tions write to the region of the virtual address space that contains
program data.
Venkman instruments each store with a bit-masking instruction
to ensure that the target address of the store is outside the code
segment. Additionally, Venkman ensures that the store and the
bit-masking instruction before it are always in the same bundle.
In this way, no changes in the control flow can execute the store
without first executing the bit-masking instruction that prevents it
from writing to the code segment.
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2298Table 1: SPEC CPU 2017 Performance Results. NV = Normalized Venkman.