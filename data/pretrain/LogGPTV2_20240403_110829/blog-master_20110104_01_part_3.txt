\$PGDATA/pg_log中查看最近一个日志文件,  
```  
2011-01-04 15:17:43.268 CST,"digoal","digoal",26232,"127.0.0.1:39324",4d22c709.6678,4,"SELECT waiting",2011-01-04 15:06:49 CST,2/19,0,LOG,00000,"process 26232 still waiting for AccessShareLock on relation 16404 of database 16402 after 1000.302 ms",,,,,,"select count(*) from tbl_users;",22,,"psql"  
```  
主节点执行完后,slave节点的waiting很快消失,不会像log shipping模式可能出现继续等待含有SQL结束的WAL的情况.  
8\. (on master)测试checkpoint  
在PostgreSQL中发生checkpoint后,在此之前的WAL在做数据库恢复时就用不到了,因为确保数据都写入数据文件了.  
pg_archivecleanup也是根据checkpoint来判断和删除不需要的WAL的.  
9\. (on slave)测试cleanarchive  
在做checkpoint前,去看$PGARCHIVE目录,已经被apply的文件还存在,并没有被pg_archivecleanup命令清除掉,原因就是这些文件是最近一次checkpoint以来的WAL文件,在数据库恢复时是需要用到的.  
如果你手工执行pg_archivecleanup $PGARCHIVE 000000010000000200000031 (假设000000010000000200000031这个是在$PGARCHIVE中的一个WAL的文件名)  
这条命令将删除000000010000000200000031以前生成的所有WAL文件,一定要小心操作,万一不小心把最近一次CHECKPOINT以来的WAL删除了,  
补救的方法是赶紧到master上做一次checkpoint,让slave知道这次checkpoint,否则的话下次slave启动还会读到000000010000000200000031这个文件以前的文件,那时候就只能找到这些文件或重建slave了.  
10\. (on slave)测试active slave  
激活SLAVE很简单,了解到已经apply了最新的WAL后,执行以下  
```  
su - postgres  
touch /database/pgdata/tbs1/pg_root/postgresql.trigger.1921  
```  
数据库会触发激活的动作,激活后/database/pgdata/tbs1/pg_root/postgresql.trigger.1921这个文件会自动删掉,并且recovery.conf被重命名为recovery.done.  
激活后的slave不可逆转为slave了.需要重建.  
11\. (on slave)测试write操作  
```  
postgres=# create table tbl_test (id int);  
ERROR:  cannot execute CREATE TABLE in a read-only transaction  
```  
12\. 监控  
```  
pg_current_xlog_insert_location  
pg_current_xlog_location  
pg_last_xlog_receive_location  
pg_last_xlog_replay_location  
top  
CREATE OR REPLACE VIEW pg_stat_replication AS  
    SELECT  
            S.procpid,  
            S.usesysid,  
            U.rolname AS usename,  
            S.application_name,  
            S.client_addr,  
            S.client_port,  
            S.backend_start  
    FROM pg_stat_get_activity(NULL) AS S, pg_authid U  
    WHERE S.usesysid = U.oid AND S.datid = 0;  
```  
13\. 优化  
13\.1\.   
```  
Both the WALSender and WALReceiver will work continuously on any outstanding data to be   
replicated until the queue is empty. If there is a quiet period, then the WALReceiver will sleep   
for 100ms at a time, and the WALSender will sleep for wal_sender_delay. Typically, the   
value of wal_sender_delay need not be altered, because it only affects behavior during   
momentary quiet periods. The default value is a good balance between effciency and data   
protection. If the Master and Standby are connected by a low bandwidth network, and the   
write rate on the Master is high, you may wish to lower this value to perhaps 20ms or 50ms.   
Reducing this value will reduce the amount of data loss if the Master becomes permanently   
unavailable, though will also marginally increase the cost of streaming the transaction log   
data to the Standbys.  
```  
13\.2\.   
```  
If the connection drops between Master and Standby, it will take some time for that to be   
noticed across an indirect network. To ensure that a dropped connection is noticed as soon    
as possible, you may wish to adjust the keepalive settings.  
If you want a Standby to notice that the connection to the Master has dropped, you need    
to set the keepalives in the primary_conninfo in the recovery.conf on the Standby   
as follows:  
primary_conninfo = '….keepalives_idle= 60 …'  
If you want the Master to notice that a streaming Standby connection has dropped, you can   
set the keepalive parameters in postgresql.conf on the Master, such as:  
tcp_keepalives_idle = 60   # time before we send keepalives  
That setting will then apply to all connections from users and replication. If you want to be very   
specifc, and just set that for replication, you must supply this as an option to be passed to the   
Master, which is specifed like the following:  
primary_conninfo = '….options="-c tcp_keepalives_idle= 60" …'  
All of the preceding examples set the length of time the connection will be idle before we start   
sending keepalives to be 60 seconds. The default is two hours, and is not recommended.   
There are multiple keepalive parameters we can set; I have avoided showing those here   
for clarity. A related option is connection_timeout. Remember, you can hide all of this   
complexity in a connection service fle, so that primary_conninfo only refers to a single   
service name, as described in the First Steps chapter.  
```  
13\.3\.   
```  
One thing that is a possibility is to set archive_command only until the end of the catch   
up period. After that you can reset it to the dummy value ("cd") and then continue just with   
streaming replication. Data is only transferred from the Master to the Standby once that data   
has been written (or more precisely, fsynced) to disk. So setting synchronous_commit =   
off will not improve the replication delay, even if that improves performance on the Master.   
Once WAL data is received by the Standby, the WAL data is fsynced to disk on the Standby to   
ensure that it is not lost if the Standby system restarts.  
```  
13\.4\.   
```  
For streaming replication, the Master keeps a number of fles that is at least wal_keep_  
segments. If the Standby database server has been down for long enough, the Master will have   
moved on and will no longer have the data for the last point of transfer. If that should occur, then   
the Standby needs to be re-confgured using the same procedure with which we started.  
```  
13\.5\.   
```  
You may also wish to increase max_wal_senders, so that it will be possible to reconnect   
even before a dropped connection is noted; this allows a manual restart to re-establish   
connections more easily. If you do this, then also increase the connection limit for the   
replication user.  
Data transfer may stop because the connection drops or the Standby server or the Standby   
system is shutdown. If replication data transfer stops for any reason, it will attempt to restart   
from the point of last transfer.  
```  
14\. 注意事项  
14\.1. 清除归档时需要考虑到master-slave是一对多的情况,使用一对多的PGARCHIVE或者是全局的pg_archivecleanup  
## 八、附pgctl.sh脚本  
```  
#!/bin/bash  
# environment.  
# Get the aliases and functions  
if [ -f ~/.bashrc ]; then  
        . ~/.bashrc  
fi  
# User specific environment and startup programs  
export PGHOME=/opt/pgsql  
export PATH=$PGHOME/bin:$PATH  
export PGDATA=/database/pgdata/tbs1/pg_root  
export PGPORT=1921  
export LANG='en_US.utf8'  
export LD_LIBRARY_PATH=$PGHOME/lib:/lib64:/usr/lib64:/usr/local/lib64:/lib:/usr/lib:/usr/local/lib  
RETVAL=1  
start() {  
su - postgres -c "/usr/bin/nohup $PGHOME/bin/postgres -D $PGDATA -p $PGPORT >/dev/null 2>>$PGDATA/pg_log/start_err.log  </dev/null &"  
         RETVAL=$?  
         return $RETVAL  
}  
stop() {  
su - postgres -c "$PGHOME/bin/pg_ctl stop -D $PGDATA -m fast"  
         RETVAL=$?  
         return $RETVAL  
}  
reload() {  
su - postgres -c "$PGHOME/bin/pg_ctl reload -D $PGDATA"  
         RETVAL=$?  
         return $RETVAL  
}  
# See how we were called.  
case "$1" in  
  start)  
        start  
        ;;  
  stop)  
        stop  
        ;;  
  restart)  
        stop  
        start  
        ;;  
  reload)  
        reload  
        ;;  
  *)  
        echo $"Usage: $prog {start|stop|restart|reload}"  
        exit 2  
esac  
exit $RETVAL  
# Auth Digoal.Zhou  
# Corp. Sky-Mobi  
```  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")