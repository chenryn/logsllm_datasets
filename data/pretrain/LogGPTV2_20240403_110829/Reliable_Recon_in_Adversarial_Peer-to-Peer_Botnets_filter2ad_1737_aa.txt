title:Reliable Recon in Adversarial Peer-to-Peer Botnets
author:Dennis Andriesse and
Christian Rossow and
Herbert Bos
Reliable Recon in Adversarial Peer-to-Peer Botnets
Dennis Andriesse
Christian Rossow
Herbert Bos
VU University Amsterdam
Saarland University, Germany
VU University Amsterdam
The Netherlands
PI:EMAIL
crossow@mmci.uni-
saarland.de
The Netherlands
PI:EMAIL
ABSTRACT
The decentralized nature of Peer-to-Peer (P2P) botnets pre-
cludes traditional takedown strategies, which target dedi-
cated command infrastructure. P2P botnets replace this
infrastructure with command channels distributed across
the full infected population. Thus, mitigation strongly re-
lies on accurate reconnaissance techniques which map the
botnet population.While prior work has studied passive dis-
turbances to reconnaissance accuracy —such as IP churn
and NAT gateways—, the same is not true of active anti-
reconnaissance attacks. This work shows that active attacks
against crawlers and sensors occur frequently in major P2P
botnets. Moreover, we show that current crawlers and sen-
sors in the Sality and Zeus botnets produce easily detectable
anomalies, making them prone to such attacks. Based on
our ﬁndings, we categorize and evaluate vectors for stealthier
and more reliable P2P botnet reconnaissance.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—In-
vasive Software; C.2.0 [Computer-Communication Net-
works]: General—Security and Protection
General Terms
Security
Keywords
Peer-to-Peer Botnet, Crawling, Reconnaissance
1.
INTRODUCTION
The decentralized nature of Peer-to-Peer (P2P) botnet
architectures eliminates the need for centralized Command-
and-Control (C2) servers. As a result, P2P botnets are im-
mune to traditional takedown strategies, designed to disrupt
centralized C2 channels. Instead, takedown eﬀorts against
P2P botnets require large-scale distributed attacks, such as
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
IMC’15 , October 28-30 2015, Tokyo, Japan
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3848-6/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2815675.2815682.
sinkholing, which target all bots in the network [28]. Due
to the high resilience of P2P botnet architectures, many
high-proﬁle botnets have migrated from centralized to P2P
networks. Among the most resilient of these are Sality [10]
and P2P (GameOver) Zeus [2].
The recent takedown of GameOver Zeus underscores the
resilience of botnets like these. This notorious banking trojan
has been active since 2011, and has survived despite multiple
intensive sinkholing eﬀorts [28, 4], until ﬁnally being crippled
in May 2014, following a massive collaboration between the
FBI, VU University Amsterdam, Saarland University, Crowd-
strike, Dell SecureWorks, and other agencies, universities and
malware analysis labs [5, 3].
Attacks against botnets like these are fundamentally based
on knowledge about the composition of the botnet [28]. For
instance, sinkholing attacks disrupt C2 connections between
bots, and thus require a view of the botnet connectivity
graph. Similarly, banks use P2P botnet mappings to identify
infected customers, and several nations are currently setting
up centralized repositories for reporting infected IPs [31].
Knowledge about the nodes in a botnet and the connections
between them is obtained using intelligence gathering (recon-
naissance/recon) techniques. Reliable recon techniques for
P2P botnets are thus crucial for both invasive attacks (e.g.,
sinkholing) and non-invasive countermeasures (e.g., infection
notiﬁcations). All recent P2P botnet takedowns required
accurate recon, including the ZeroAccess and GameOver
Zeus attacks [5, 3, 22, 35, 19]. Note that connectivity graph-
agnostic Sybil attacks, which could eﬀectively disrupt early
DHT-based P2P botnets [6], are not eﬀective against modern
unstructured networks like Sality and Zeus, which use dense,
dynamic connectivity graphs to propagate signed commands
between bots.
To maximize the reliability of reconnaissance results, prior
work has studied a myriad of passive disruptive factors, such
as bots behind NAT gateways and IP address aliasing [28,
17]. In contrast, very little attention has been devoted in the
literature to the hardening of recon against active disruption
by botnet operators.
We believe this issue calls for closer analysis, as botmas-
ters increasingly implement active anti-recon strategies in
P2P botnets, largely in response to recent successful take-
downs. These upcoming anti-recon strategies are aimed at
compromising the intelligence gathered by malware analysts
in P2P botnets, using attacks such as (automatic) black-
listing [2], reputation schemes [10], and even DDoS against
recon nodes [4]. Botmasters use anti-recon strategies to aug-
ment previously disabled botnets, and redeploy hardened
129versions of them, which are more diﬃcult to take down. For
instance, the Hlux botnet has already respawned three times,
each time with additional hardening strategies [35, 19, 11].
These patterns suggest that next-generation P2P botnets will
incorporate stronger anti-recon techniques. Because take-
down and disinfection eﬀorts against P2P botnets hinge on
reliable reconnaissance, our work is aimed at proactively in-
vestigating the full extent of anti-recon implemented by P2P
botmasters, and the range of possible defenses to safeguard
reconnaissance in next-generation botnets.
We show that recon tools used by malware analysts to
monitor high-proﬁle botnets suﬀer from serious protocol de-
ﬁciencies, making them easily detectable. Speciﬁcally, we
inﬁltrate the Sality v3 and GameOver Zeus botnets by insert-
ing passive sensors, which scan incoming traﬃc for anomalies
and deviations from the botnet protocol. Additionally, we
use active peer list requests to locate sensor nodes which
do not actively initiate communication. (At the time of our
analysis, the attack against GameOver Zeus had not yet
been launched.) We identify 21 Zeus crawlers, 10 distinct
Zeus sensors, and 11 Sality crawlers belonging to well-known
malware analysis laboratories, network security companies,
and CERTs. We ﬁnd that all of these have shortcomings
which make them easy to identify among the bot populations
(200.000 bots for Zeus, and 900.000 for Sality) [28].
At ﬁrst glance, it may seem that the situation could be
remedied by eliminating syntactic protocol deﬁciencies in
crawlers and sensors. We show that this is not so; even syn-
tactically sound recon tools can be detected by anomalous in-
or out-degrees. This is commonly true especially for crawlers,
as they strive to contact as many bots in as short a time span
as possible. To evaluate the magnitude of this problem, we
design and implement a novel distributed crawler detection
model, and show that it can automatically detect all crawlers
in GameOver Zeus without false positives. We illustrate that
the algorithm is applicable not only to Zeus, but also to other
P2P botnets, including Sality. Based on these results, we
propose and evaluate techniques to evade out-degree-based
detection, such as rate limiting and distributed crawling,
and we measure the impact of these techniques on crawling
accuracy and completeness.
We also discuss an alternative reconnaissance strategy
which has been widely proposed for use in P2P botnets,
namely Internet-wide scanning [9]. We show that it is applica-
ble to some P2P botnets, but is unfortunately not compatible
with all P2P botnet protocols.
Summarizing, our main contributions are:
1. We identify and classify anti-recon attacks taking place
in current P2P botnets, and generalize to potential
attacks which could be implemented in future botnets.
2. We categorize recon strategies and their susceptibility
to passive and active disruption.
3. We analyze the quality of crawlers and sensors used in
Sality and Zeus, and classify major shortcomings.
4. We design and implement a syntax-agnostic crawler
detection algorithm, and use it to analyze tradeoﬀs
between reconnaissance stealthiness versus speed, ac-
curacy, and completeness.
5. We discuss strategies for covert P2P botnet recon based
on our results.
a
e
b
d
c
Figure 1: An example botnet connectivity graph. An arrow from
node a to node b indicates that a knows b. Non-routable nodes
are shaded.
2. RECON IN P2P BOTNETS
Reconnaissance methods for P2P botnets can be divided
into two classes, namely crawler-based and sensor-based
methods (though hybrids are feasible [28]). This section
introduces both of these classes, and compares their tradeoﬀs
and resilience to passive disruption. We discuss active recon
disruption in Section 3.
Throughout this paper, we consider a botnet to be a
digraph G = (V, E), where V is the set of vertices (e.g.
bots), and E is the set of edges (e.g. is-neighbor connections
between bots). We refer to the number of outgoing edges
from a bot v as its out-degree deg+(v), and the number of
incoming edges as in-degree deg−(v).
2.1 Crawlers
Crawler-based reconnaissance relies upon the peer list
exchange mechanism available in all P2P botnets [28, 2, 10,
13, 33, 35]. In P2P botnets, every bot maintains a list of
addresses of other peers it has been contacted by or has
learned about from other bots. To maintain connectivity
with the network despite the constant churn of bots that
join and leave the botnet, peers regularly exchange (parts
of) their peer list with their neighbors. Support for peer list
exchanges is typically implemented through special request
messages included in the botnet protocol, called peer list
requests, which each bot can use to request a set of peer
addresses from another. Crawlers abuse this mechanism
by recursively requesting peer lists from all bots they learn
about, starting from an initial bootstrap peer list (usually
obtained from a bot sample).
Due to its simplicity and ability to rapidly request peers
from many bots, crawling is a highly popular intelligence
gathering method used by malware analysts [15, 28]. Never-
theless, crawlers have been reported to suﬀer from a myriad
of inaccuracy problems. For instance, address aliasing can
occur with bots that use dynamic IP addresses, leading to
signiﬁcant botnet size overestimations if the crawling period
is too long [17]. In addition, crawlers cannot contact and
verify the liveness of non-externally reachable (non-routable)
bots, such as bots protected by a ﬁrewall or NAT gateway [17,
28]. This is a signiﬁcant shortcoming, since the percentage
of non-routable bots can range up to 60–87% [28].
Figure 1 shows the inaccuracy that may result from the
inability of crawlers to verify non-routable bots. The ﬁgure
depicts a connectivity graph containing bots a, . . . , e, of which
bots c, . . . , e are non-routable (shaded). A crawler can only
directly contact the externally reachable (routable) bots a
and b; non-routable bots are only discoverable if they actively
advertise themselves.
The only way for a crawler to learn about bots c, . . . , e
is by relying on the peer lists returned by a and b. The
130addresses returned in these peer lists may be outdated, and
the lists may include multiple aliases for bots with dynamic
IPs. The crawler cannot be sure of this, and cannot actively
establish contact with bots c, . . . , e to verify their existence.
On the other extreme of the scale, the botnet protocol may
not allow non-routable bots to push themselves into the peer
lists of other bots at all, making it impossible for crawlers to
ﬁnd non-routable bots. As an example, node e in Figure 1
has no incoming edges from any routable bot, making it
undetectable to crawlers regardless of the protocol.
2.2 Sensors
In contrast to crawlers, sensors are largely passive. When
injecting a new sensor node into a botnet, its address is
actively announced (as is done for new bots joining the
network) until a suﬃcient number of bots learn about the
existence of the sensor. After that, the active announcement
is ceased, and the sensor relies upon peer list exchanges
between bots to propagate its address. Sensors map the
network by waiting for bots to contact them, instead of
actively contacting bots.
Compared to crawlers, sensors achieve better coverage of
routable bots [28]. In addition, sensors can ﬁnd and verify
all non-routable bots which contact them after learning the
sensor addresses from other bots. This allows sensors to
more precisely and reliably map the nodes in the botnet than
crawlers [28].
Sensors are currently not as widely used by malware an-
alysts as crawlers are.
In part, this is due to the larger
implementation and reverse engineering eﬀort required to
build and maintain a sensor. Since most botnets have mech-
anisms to evict unresponsive or incorrectly responding peers
from peer lists, sensors must implement most or all of the bot-
net protocol to avoid being evicted. In contrast, crawlers only
need support for peer list requests and responses. Further-
more, sensor injection can be complicated by botnet resilience
measures like reputation schemes [10] and non-persistent peer
list entries [36].
In contrast to crawlers, sensors map only the nodes in a
botnet, but not the connectivity information. However, since
sinkholing attacks overwrite peer list entries, they require
connectivity information to determine which entries to target.
To obtain this information, sensors must be expanded to
request peer lists from bots which contact them. Compared
to crawlers, sensors which are augmented with active peer
list requests have the advantage that they can even reach
the majority of non-routable bots through NAT punch holes.
3. ANTI-RECON ATTACKS
Recon tools like crawlers and sensors are open to a range
of attacks which impair intelligence gathering. This section
categorizes the anti-recon measures which we have observed
in the wild in all major P2P botnets since 2007 [28]. We
summarize these in Table 1, and categorize anti-recon into
four categories: (1) deterrence, (2) passive attacks (i.e., black-
listing), (3) active disinformation, and (4) retaliation attacks.
3.1 Deterrence
Deterrence encompasses P2P botnet protocol characteris-
tics designed to complicate recon. This includes measures
meant to deter crawling or sensor injection.
As shown in Table 1, deterrence is currently the most
common class of anti-recon: all major P2P botnets include
some form of recon deterrence. Speciﬁcally, all botnets except
Storm include an IP ﬁlter which prevents the injection of
multiple sensors on a single IP [10, 25, 35, 19, 6, 13, 34, 33].
Zeus goes further than this, disallowing more than a single
peer list entry per /20 subnet [2].
All botnets also include a form of information limiting
designed to slow crawling, usually by returning only a small
set of peer list entries at once. This is most extreme in Hlux,
where at any moment there is only a small list of around
500 relay nodes (externally reachable bots) circulating in
the network [19]. Another form of information limiting is
clustering, observed in Zeus, Storm, and Hlux [2, 13, 35].
Zeus and Storm restrict the returned peer list entries based on
a (Kademlia-like) XOR metric, returning only entries “close”
to the requester according to this metric. Hlux clusters the
bot population around a small core of relay bots shared in
peer lists.
Finally, some bots also feature more specialized recon
deterrence. For instance, Sality actively tries to prevent
sensor injection by using a reputation scheme based on a
goodcount, which reﬂects how well-behaved peers have been
in the past [10]. Sensors are only propagated to other bots if
they achieve a high goodcount ﬁrst. Additionally, ZeroAccess
prevents injection of persistent links to sensors by pushing a
continuous ﬂux of peer list updates, constantly overwriting
the full peer list of each routable bot [25].
3.2 Blacklisting
Blacklisting is a passive attack, designed to starve crawlers
and sensors of information by prohibiting bots from commu-
nicating with them. It is already used in ZeroAccess, and
in particular also in GameOver Zeus, which features two
distinct blacklisting mechanisms [2]. (1) Each bot binary is
shipped and periodically updated with a hardcoded blacklist
of IPs which the botmasters identiﬁed on the network due
to anomalous behavior. (2) In recent versions of Zeus, an
automatic blacklisting mechanism was introduced, which is
a rudimentary approach to identify and block crawlers and
nodes attempting to poison the network. Each bot tracks
the request frequencies of its peers, and blocks peers send-
ing many requests in quick succession. To prevent blocking
of multiple NATed bots using the same IP, the maximum
frequency is high enough to be circumventable by relatively
eﬃcient crawlers. Nevertheless, this mechanism is suﬃcient
to thwart naive crawlers, and could be more ﬁnely tuned.
Blocked IPs become unusable for malware analysis not only
on the botnet in question, but also on other botnets, as
(hardcoded) blacklists are often publicly visible.
3.3 Disinformation
Disinformation attacks actively supply crawlers and sensors
with spurious peer list entries containing forged addresses,
in order to divert them from the main bot population. This
is problematic especially for crawlers, as they lack the ability
to verify non-routable bot addresses. The attack can be
expanded to thwart sensors by leading them into a “shadow
botnet”, containing a set of responsive peers which are iso-
lated from the main bot population. Disinformation attacks
can cause collateral damage by polluting lists of infected
addresses reported to ISPs, and even rerouting sinkholing
attacks to shadow nodes or uninfected hosts.
We have observed (possibly unintended) disinformation
in ZeroAccess, where peer lists frequently include junk ad-
131IP ﬁlter Reputation
Deterrence
Info limit Flux
Clustering Auto
Static
Blacklisting
Disinformation Retaliation
Spurious IPs
DDoS
By /20
Zeus
By IP
Sality
ZeroAccess
By IP
Kelihos/Hlux By IP
By IP
Waledac
-