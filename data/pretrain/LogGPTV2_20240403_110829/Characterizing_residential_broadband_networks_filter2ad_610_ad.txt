0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
Cable
DSL
5
10
15
20
25
30
Minimum RTT distance from the host to the router (milliseconds)
Figure 10: Last-hop delay and jitter in cable and DSL
networks: DSL shows higher last-hop RTTs than cable,
while cable exhibits higher jitter than DSL.
Figure 11: Diﬀerence in transmission delays between
large and small packets: DSL shows longer transmission
delays than cable.
minimum RTT to the last-hop router from the minimum
RTT to the broadband host. We used the minimum RTT
estimates to avoid transient jitter as a result of queueing at
intermediate routers.
Figure 10 shows our results for last-hop RTTs for cable
and DSL networks. DSL hosts exhibit considerably higher
propagation delays than cable hosts. 75% of all DSL hosts
have last-hop delays larger than 10 ms, while 15% have prop-
agation delays larger than 20 ms. These delays are surprising
because many last-hop routers are located in the same city
as their end hosts.4
Figure 10 also shows the jitter in our latency measure-
ments. We used the RTTs of the small-TCP trickle to esti-
mate the jitter of the broadband link. We calculated jitter
by subtracting the 10th percentile RTT from the 90th per-
centile highest RTT. Compared to cable, DSL links have
higher last-hop delays but lower jitter. We believe that the
characteristics of the upstream cable links are responsible for
these diﬀerences. We examine this next.
4.2.2 How do cable’s time-slotted policies affect
transmission delays?
Transmission delay refers to time elapsed between a router
starting to transmit a packet and ending its transmission.
It is usually calculated by dividing the packet length by the
link bandwidth. However, cable links use a reservation policy
to transmit packets in the upstream direction. This policy
can cause additional delays to a packet’s transmission. We
examined the eﬀects of such transmission policies under both
low and high network loads.
First, we studied transmission delays under low network
loads. We used the large-ICMP trickle to calculate the last-
hop delays, similar to the experiment conducted in the previ-
ous section. We compared these last-hop large-packet delays
to the last-hop small-packet delays measured in the earlier
experiment. The diﬀerences in the last-hop delays between
large (1,488-byte) and small (100-byte) packets are mostly
due to the additional transmission delays incurred by send-
ing larger packets.
Figure 11 shows the diﬀerence in transmission delays be-
tween large and small packets for cable and DSL hosts. We
found that the transmission delays for DSL are large, on the
same order of magnitude as their propagation delays, shown
4We inferred the locations of hosts and routers from their
DNS names as suggested in [47].
in Figure 10. By contrast, the transmission delays for cable
are surprisingly low – 99% of hosts show an increase of less
than 1 ms to send an extra 1,388 bytes.
We believe that the time-slotted nature of cable links is re-
sponsible for these short transmission delays. All our probes,
both large and small, experience similar waiting times for a
time slot. When a slot has been granted, packets are trans-
mitted at the full link speed (10.24 Mbps according to the
DOCSIS 1.0 speciﬁcation). This matches our data very well;
our measured transmission delays correspond to an upstream
link speed of 11 Mbps.
Next, we examined transmission delays under high net-
work load. In this case, packets have to wait longer to re-
serve a time slot. When the reservation is granted, multiple
waiting packets can be concatenated (see Section 2.1) and
sent in a single burst. Although concatenation reduces the
overhead of scheduling many small packets, such as TCP
ACKs, it introduces a systematic jitter, which we refer to as
the concatenation jitter.
We used the small-TCP ﬂood to examine the eﬀects of
concatenation because it saturates the upstream link with a
large number of small packets, which are well suited for con-
catenation. We clustered probe responses received in very
close succession (separated by less than 100 µs) as part of
a single bursty transmission, and we calculated the number
of packets in the largest cluster. Because there is no known
concatenation feature for DSL, we expected these links to
show only minimal burst sizes.
Figure 12(a) shows the extent of packet concatenation in
DSL and cable ISPs. As expected, DSL links show only very
short bursts, whereas 50% of cable links can concatenate
19 packets or more in a single burst. We used the link’s
speed and the number of packets in a burst to estimate a
lower bound on the amount of concatenation jitter when the
link is saturated. Figure 12(b) shows the results. Whereas
the mean concatenation jitter for cable networks is about
5 ms, many links experience 10 ms or more of jitter due to
concatenation.
In cable networks, the concatenation jitter under high net-
work load can be higher than the end-to-end jitter over the
entire path under normal load (shown in Figure 10). The
presence of high jitter in cable networks has important con-
sequences for protocols such as TCP Vegas [9] and PCP [3],
which interpret changes in RTT as a sign of incipient con-
gestion. High jitter could cause these protocols to enter con-
gestion avoidance too early, leading to poor performance.
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
DSL
Cable
5
10
15
20
25
30
Number of packets
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
DSL
Cable
5
10
15
20
Jitter (milliseconds)
(a) Maximum number of packets per burst
(b) Lower bound estimate of concatenation jitter
Figure 12: Cable links show high RTT variation: In addition to a high level of basic jitter, cable modems can send small
packets in a single burst and thus cause additional jitter.
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
PacBell
BellSouth
SWBell
BT Broadband
Qwest
Ameritech
100
200
300
400
500
Queue length (milliseconds)
(a) DSL (downstream)
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
SWBell
Qwest
PacBell
BT Broadband
BellSouth
Ameritech
0
0
500
1,000
1,500
2,000
2,500
Queue length (milliseconds)
(c) DSL (upstream)
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
0
0
Chello
Rogers
Charter
Road Runner
Comcast
100
200
300
400
500
Queue length (milliseconds)
(b) Cable (downstream)
Comcast
Chello
Charter
Road Runner
Rogers
1,000
2,000
3,000
4,000
5,000
Queue length (milliseconds)
(d) Cable (upstream)
Figure 13: Downstream and upstream queue length in milliseconds: Some downstream queue lengths follow the
recommendation for voice calls (150 ms), but most are signiﬁcantly longer. The upstream queue length can be massive,
especially for cable links.
4.2.3 How large are broadband queueing delays?
Sizing router queues is a popular area of research (e.g., [4]).
A common rule of thumb (attributed to [49]) suggests that
router queues’ lengths should be equal to the RTT of an av-
erage ﬂow through the link. Larger queues lead to needlessly
high queueing delays in the network. We investigated how
well this conventional wisdom holds in broadband environ-
ments.
We measured queue lengths in milliseconds by calculating
the RTT variation of our probe streams’ packets. To esti-
mate downstream queue lengths, we used large-TCP ﬂood
probe trains, which saturate the downstream but not the up-
stream link. We calculated the diﬀerence between the mini-
mum RTT and the 95th percentile highest RTT. To estimate
upstream queue lengths, we ﬁrst measured the diﬀerence
between the minimum RTT and the 95th percentile high-
est RTTs of large-ICMP ﬂood probe trains. This diﬀerence
corresponds to the sum of downstream and upstream queue
lengths. We then subtracted the estimate of the downstream
queue length to obtain the length of the upstream queue.
Figures 13(a) and 13(b) show the cumulative distributions
of downstream queue lengths for diﬀerent cable and DSL
providers. Across most cable ISPs and two DSL ISPs (Pac-
Bell and SWBell), the curves show a sharp rise at 130 ms.
This value is consistent with that recommended by the ITU
Cable
DSL
1
0.8
0.6
0.4
0.2
s
t
s
o
h
f
o
n
o
i
t
c
a
r
F
3%
e
t
a
r
s
s
o
L
2%
1%
Ameritech
Chello
0
0.0%
0.2%
0.4%
0.6%
Round-trip loss rate
0.8%
1.0%
0%
Sun
0:00
Mon
0:00
Tue
0:00
Wed
0:00
Local time
Thu
0:00
Fri
0:00
Sat
0:00
Sun
0:00
Figure 14: Observed round-trip loss rate for residen-
tial broadband paths: DSL and cable paths show similar
loss rates. 95% of all DSL and cable hosts have loss rates of
less than 1%.
Figure 15: Packet loss over time: The loss rate is gener-
ally low and shows heavy diurnal variations with intermit-
tent spikes. Note that this graph includes both upstream
and downstream losses; the time axis shows local time (EST
for Ameritech and CET for Chello).
G.114 standard for maximum end-to-end latency in a net-
work running interactive traﬃc – 150 ms. Nevertheless, these
queue lengths are signiﬁcantly higher than a typical ﬂow’s
average delay, which ranges between 50 and 75 ms within
North America or Europe. By contrast, we observed queue-
ing delays of up to 2 s for a signiﬁcant number of Comcast
and Qwest hosts and up to 6 s for some BT Broadband
hosts (not shown). Our ﬁndings show diverse queue con-
ﬁgurations for broadband links, with most hosts exhibiting
queue lengths signiﬁcantly higher than 130 ms.
Figures 13(c) and 13(d) show the cumulative distributions
of upstream queue lengths for the diﬀerent cable and DSL
providers. Compared with downstream queues, the lengths
of upstream queues are very large. Most DSL links exhibit
queues of 600 ms or higher, and many cable links allow their
upstream queues to grow to several seconds. Although some
of the upstream queues’ build-up results from the low up-
stream link bandwidths, the excessive lengths will negatively
aﬀect interactive traﬃc like VoIP whenever users upload con-
tent, such as when using BitTorrent.
4.3 Packet loss
In this section, we characterize packet loss in residential
broadband networks. We contrast our results with the com-
monly held idea that broadband networks have high packet
loss rates. Our tools cannot measure the access links’ loss