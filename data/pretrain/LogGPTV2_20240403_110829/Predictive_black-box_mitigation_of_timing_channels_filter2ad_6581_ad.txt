match, the server returns the same error message as for an invalid
username, to conceal username validity. This captures the essence
of a login service. However, despite its simplicity, this service also
exhibits a possible timing channel, because the computation of the
SHA-1 hash depends on username validity.
To reduce network timing noise, we measure the query time 20
times for each username, and choose the smallest one as our sam-
ple. For each experiment, we randomly choose 400 valid user-
names from a valid username list, as well as 400 randomly gener-
ated invalid usernames to determine the timing difference between
them. As in the RSA experiment, we use a sequential attacker
model, where the attacker issues a query immediately after the re-
sponse. To make the difference more precise, we alternately issue
valid and invalid queries.
For the basic mitigation mechanism, instead of modifying the
Tomcat source code, we wrap the doGet function in our login ser-
vice servlet with code implementing the basic mitigation scheme,
to control leakage of the time needed to look up and check the
password. Because it is not implemented as part of Tomcat, this
implementation cannot mitigate timing information communicated
by web service setup time. However, the experiment still shows that
timing mitigation can defend against this timing channel attack.
5.2.2 Results
Figure 8(a) shows how query time differs for valid and invalid
usernames. Queries for valid usernames take signiﬁcantly longer,
so a timing channel attack is easy to mount. Web server setup adds
about 1.5ms latency to queries in the beginning of the run, but the
(b) With mitigation
Figure 8: Simple mitigation of the web server timing attack
query time stabilizes after around 50 queries. An attacker could de-
termine the validity of an arbitrary username with high conﬁdence.
Figure 8(b) shows the response time with the basic mitigation
mechanism. Since server replies only at the end of the current quan-
tum, the time difference is independent of the validity of username.
Close inspection of the results reveals that there is an initial 1.5ms
timing difference that is not mitigated by our implementation. This
timing difference is caused by the setup of the web service, rather
than by the login service we mitigated, and underscores the im-
portance of mitigating timing end-to-end rather than on individual
system components.
Another observation not shown in the time difference graph of
RSA experiment is that our simple timing mitigation mechanism
also adds a latency penalty to the web service, since the service
time is uniﬁed to the closest power of 2 of the largest service time.
This latency can be seen in Figure 8(b), where mitigation is seen to
add about 9 ms latency.
5.2.3 Expected leakage
We applied the expected-leakage approach of Section 3.7 to the
web service. Using 1000 random requests, we determined that 99%
of them are below 8 ms. Replacing Tbig = (cid:100)log 8(cid:101) and p = 0.99
with these two numbers, the expected leakage for this application as
shown in Figure 9, with q0 = 1 ms. Clearly, the mitigated version
leaks information slowly in practice.
00.511.522.530100200300400500600Time (hours)Leakage (bits)  Expected leakagelog2(T+1)100200300400Number of queries3.03.54.0Response time in millisecondsvalid usernameinvalid username100200300400Number of queries111213Response time in millisecondsvalid usernameinvalid username305tions, which reduces the bandwidth of the timing channel, as in [14,
11]. Adding random delays sacriﬁces performance, and it does not
asymptotically eliminate timing channels, since the noise can be
eliminated to whatever degree is desired by averaging over a se-
quence of identical requests. Methods for creating covert timing
robust against added noise have been demonstrated [21].
A second approach to mitigation, also used in [14], is that pro-
grams that read clocks are given results with random noise. This
method only applies to internal timing channels that are based on
reading clocks directly.
Wray [32] views every covert channel that originates from com-
paring two clocks as a timing channel. In this light, we focus on the
channels that arise from comparing timing of the events to external
reference clock that is not modulated by the attacker. Our results of
Section 3.5 can be interpreted as mixing external timing channels
and all other covert channels.
The line of work on NRL Pump [15, 16] addresses timing chan-
nels that arise when high conﬁdentiality processes acknowledge re-
ceipt of messages from low conﬁdentiality processes.
In a language-based setting, it is possible to reason about ways
the program can measure time, and language-based methods have
been proposed for controlling internal timing channels by analy-
sis [33] and by transformation [1, 29]. Coppens et al. [7] explore
automating compiling techniques to defend against timing-based
side-channel attacks on x86 processors. Language-based methods
for mitigating general external timing channels have also been pro-
posed, but rely on unrealistic assumptions. For example, Agat’s
work [1] ignores the effect of the code cache on timing, and is lim-
ited to programs that lack loops and recursion. Shroff and Smith
lift some of Agat’s limitations [31], but at the cost of possibly dis-
rupting computations.
7. CONCLUSION
This paper has introduced a new class of schemes for mitigating
timing channels for general computer systems. The key intuition
is that the timing mitigator can often predict the future availability
of events to deliver. Mitigator predictions divide time into epochs.
When a prediction fails, a new epoch begins and some information
is leaked. The mitigator is able to track the amount of information
leaked at each epoch transition and to enforce whatever leakage
bound has been speciﬁed. When the information bound permits,
the mitigator can also adaptively start a new epoch for improved
performance.
This paper has identiﬁed the key conditions that an epoch-based
mitigator must satisfy, and described some useful adaptive mecha-
nisms. However, there is no doubt more work to be done on under-
standing the space of epoch-based timing mitigators. The problem
of generating schedules of predictions for these mitigators, partic-
ularly for various classes of applications, appears interesting.
This paper has considered combining timing mitigation with other
mechanisms for controlling information ﬂow through storage chan-
nels, and shown that it is possible to conservatively bound the ca-
pacity of the combined channel by building on the analysis of tim-
ing channel capacity given here. However, we have not yet imple-
mented such a combined mechanism for information ﬂow control;
this is clearly a useful future direction. Exploring epoch-based tim-
ing mitigation in real-world systems is an obvious next step.
8. REFERENCES
[1] J. Agat. Transforming out timing leaks. In Proc. 27th ACM
Symp. on Principles of Programming Languages (POPL),
pages 40–53, Boston, MA, Jan. 2000.
Figure 9: Expected leakage for web server timing attack
6. RELATED WORK
Timing channels have been widely studied in the literature. We
brieﬂy explore related work below.
Cryptographic side-channels.
One major motivation for controlling timing channels is the pro-
tection of cryptographic keys against side-channels arising from
timing cryptographic operations. A variety of attacks that exploit
timing side-channelshave been demonstrated [4, 17]. Cryptographic
blinding [5, 17] is a standard technique for mitigating such chan-
nels.
In recent works, Köpf et al. [18, 19] utilize blinding with
quantization (referred in there as bucketing) to derive tight bounds
on leakage of cryptographic operations.
Quantitative information ﬂow.
We advocate a quantitative approach to controlling information
ﬂow through timing channels. Like much other work on quantita-
tive information ﬂow [6, 23, 18, 19] we draw on information the-
ory to obtain bounds on leakage. Millen [24] ﬁrst observed that
noninterference implies zero channel capacity between high and
low. DiPierro et. al [28] quantify timing leaks in a language-based
setting. Epoch-based mitigation is similar in spirit to Mode Secu-
rity [3] which reduces covert channels to changes in modes. Unlike
Mode Security, we also account for leakage within epochs, via a
combinatorial analysis.
Detection of timing attacks.
Some prior work on timing channels has focused on detecting
the perturbation in the distribution of times introduced by timing
attacks [10]; however, stealthy timing attacks have been demon-
strated [21, 22].
Mitigation of timing attacks.
Giles and Hajek present a comprehensive study of timing chan-
nels [11] in which packet arrival is represented by continuous or
discrete waveforms. Similarly to us, they employ periodic quan-
tization. However, because of the constant periods, the reduction
of the timing channel bandwidth is only linear. Another difference
lies in the semantics of buffer bounds: while they assume that a
jammer has to release a packet from the queue when a buffer is
full, our mitigators block the input source.
One prior approach to timing channel mitigation is adding noise
to timing measurements. There are two ways to do this. First,
we can add random delays to the time taken by various opera-
00.511.522.530100200300400500600Time (hours)Leakage (bits)  Expected leakagelog2(T+1)306[2] A. Bortz and D. Boneh. Exposing private information by
timing web applications. In Proc. 16th Int’l World-Wide Web
Conf., May 2007.
[3] R. Browne. Mode security: An infrastructure for covert
channel suppression. In IEEE Symposium on Research in
Security and Privacy, pages 39–55, May 1994.
[4] D. Brumley and D. Boneh. Remote timing attacks are
practical. Computer Networks, Jan. 2005.
[5] D. Chaum. Blind signatures for untraceable payments. In
CRYPTO, pages 199–203, 1982.
[6] M. R. Clarkson, A. C. Myers, and F. B. Schneider.
Quantifying information ﬂow with beliefs. Journal of
Computer Security, 17(5):655–701, 2009.
[7] B. Coppens, I. Verbauwhede, K. D. Bosschere, and B. D.
Sutter. Practical mitigations for timing-based side-channel
attacks on modern x86 processors. IEEE Symposium on
Security and Privacy, pages 45–60, 2009.
[8] D. Coppersmith. Small solutions to polynomial equations,
and low exponent RSA vulnerabilities. Journal of
Cryptology, 10(4), Dec. 1997.
[9] R. G. Gallagher. Basic limits on protocol information in data
communication networks. IEEE Transactions on Information
Theory, 22(4), July 1976.
[10] S. Gianvecchio and H. Wang. Detecting covert timing
channels: an entropy-based approach. In CCS ’07, Oct. 2007.
[11] J. Giles and B. Hajek. An information-theoretic and
game-theoretic study of timing channels. IEEE Transactions
on Information Theory, 48(9):2455–2477, 2002.
[12] J. A. Goguen and J. Meseguer. Security policies and security
models. In Proc. IEEE Symposium on Security and Privacy,
pages 11–20, Apr. 1982.
[13] D. M. Goldschlag. Several secure store and forward devices.
In CCS ’96, pages 129–137, Mar. 1996.
[14] W.-M. Hu. Reducing timing channels with fuzzy time. In
IEEE Symposium on Security and Privacy, pages 8 – 20,
1991.
[15] M. H. Kang and I. S. Moskowitz. A pump for rapid, reliable,
secure communication. In CCS ’93, pages 119–129, Nov.
1993.
[16] M. H. Kang, I. S. Moskowitz, and S. Chincheck. The pump:
A decade of covert fun. In ACSAC ’05, pages 352–360, 2005.
[17] P. Kocher. Timing attacks on implementations of
Difﬁe–Hellman, RSA, DSS, and other systems. In Advances
in Cryptology—CRYPTO’96, Aug. 1996.
[18] B. Köpf and M. Dürmuth. A provably secure and efﬁcient
countermeasure against timing attacks. In 2009 IEEE
Computer Security Foundations, July 2009.
[19] B. Köpf and G. Smith. Vulnerability bounds and leakage
resilience of blinded cryptography under timing attacks. In
2010 IEEE Computer Security Foundations, July 2010.
[20] B. W. Lampson. A note on the conﬁnement problem. Comm.
of the ACM, 16(10):613–615, Oct. 1973.
[21] Y. Liu, D. Ghosal, F. Armknecht, A. Sadeghi, and S. Schulz.
Hide and seek in time—robust covert timing channels. In
ESORICS, 2009.
[22] Y. Liu, D. Ghosal, F. Armknecht, A. Sadeghi, S. Schulz, and
S. Katzenbeisser. Robust and undetectable steganographic
timing channels for i.i.d. trafﬁc. In Information Hiding 2010,
June 2010.
[23] G. Lowe. Quantifying information ﬂow. Proc. IEEE
Computer Security Foundations Workshop, June 2002.
[24] J. K. Millen. Covert channel capacity. In Proc. IEEE
Symposium on Security and Privacy, Oakland, CA, 1987.
[25] M. A. Olson, K. Bostic, and M. Seltzer. Berkeley DB. In
Proc. USENIX Annual Technical Conference, 1999.
[26] D. Osvik, A. Shamir, and E. Tromer. Cache attacks and
countermeasures: the case of AES. Topics in
Cryptology–CT-RSA 2006, Jan. 2006.
[27] M. Padlipsky, D. Snow, and P. Karger. Limitations of
end-to-end encryption in secure computer networks.
Technical Report ESD TR-78-158, Mitre Corp., 1978.
[28] A. D. Pierro, C. Hankin, and H. Wiklicky. Quantifying
timing leaks and cost optimisation. Information and
Communications Security, 2010.
[29] A. Russo, J. Hughes, D. Naumann, and A. Sabelfeld. Closing
internal timing channels by transformation. In Proc. 11th
Annual Asian Computing Science Conference (ASIAN), 2006.
[30] G. Shah, A. Molina, and M. Blaze. Keyboards and covert
channels. Proc. 15th USENIX Security Symp., Aug. 2006.
[31] P. Shroff and S. F. Smith. Securing timing channels at
runtime. Technical report, The John Hopkins University, July
2008.
[32] J. C. Wray. An analysis of covert timing channels. In IEEE
Symposium on Security and Privacy, pages 2–7, 1991.
[33] S. Zdancewic and A. C. Myers. Observational determinism
for concurrent program security. In Proc. 16th IEEE
Computer Security Foundations Workshop, pages 29–43,
Paciﬁc Grove, California, June 2003.
APPENDIX
A more precise bound on leakage of the basic scheme.
This derivation is based on the fact that each possible string can
be determined by the placement of the misses, that is, the locations
of “–” in the string. For m misses in time T , there are at most(cid:0) T
(cid:33)
All possible strings ≤ log T(cid:88)
≤ (log T + 1)
different strings. So
(cid:32)
(cid:33)
(cid:1)
m
(cid:32)
T
log T
T
m
m=0
≤ (log T + 1)
T log T
(log T )!
Thus, the leakage can be no more than log(log T + 1) + log2 T −
log((log T )!), and by Stirling’s approximation,
log((log T )!) = log T log log T − log T + o(log T )
So the whole leakage term is O(log T (log T − log log T ))).
Proof of Theorem 1.
We prove the theorem by using the deﬁnition of I(X; Y ) to show
that the expression H(Z) + I(X; Y )− I(X; Y, Z) is nonnegative.
H(Z) + I(X; Y ) − I(X; Y, Z)
= H(Z) + H(X) + H(Y ) − H(X, Y )
− H(X) − H(Y, Z) + H(X, Y, Z)
= H(Z) + H(Y ) − H(X, Y ) − H(Y, Z) + H(X, Y, Z)
≥ H(Z) + H(Y ) − H(X, Y ) − H(Y ) − H(Z) + H(X, Y, Z)
= H(X, Y, Z) − H(X, Y ) ≥ 0
2
307