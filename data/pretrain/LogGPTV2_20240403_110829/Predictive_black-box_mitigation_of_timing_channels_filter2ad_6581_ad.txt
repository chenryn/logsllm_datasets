### 5.2.1 Experimental Setup

In the login service, if a username does not match, the server returns the same error message as for an invalid username to conceal the validity of the username. This approach captures the essence of a secure login service. However, despite its simplicity, this service also exhibits a possible timing channel, as the computation of the SHA-1 hash depends on the validity of the username.

To reduce network timing noise, we measure the query time 20 times for each username and select the smallest value as our sample. For each experiment, we randomly choose 400 valid usernames from a valid username list and 400 randomly generated invalid usernames to determine the timing difference between them. Similar to the RSA experiment, we use a sequential attacker model where the attacker issues a query immediately after receiving the response. To increase the precision of the difference, we alternate between issuing valid and invalid queries.

For the basic mitigation mechanism, instead of modifying the Tomcat source code, we wrap the `doGet` function in our login service servlet with code implementing the basic mitigation scheme. This controls the leakage of the time needed to look up and check the password. Since it is not implemented as part of Tomcat, this implementation cannot mitigate timing information communicated by web service setup time. However, the experiment still shows that timing mitigation can defend against this timing channel attack.

### 5.2.2 Results

Figure 8(a) illustrates the difference in query time for valid and invalid usernames. Queries for valid usernames take significantly longer, making a timing channel attack easy to mount. Web server setup adds about 1.5 ms latency to queries at the beginning of the run, but the query time stabilizes after around 50 queries. An attacker could determine the validity of an arbitrary username with high confidence.

Figure 8(b) shows the response time with the basic mitigation mechanism. Since the server replies only at the end of the current quantum, the time difference is independent of the username's validity. Close inspection of the results reveals an initial 1.5 ms timing difference that is not mitigated by our implementation. This timing difference is caused by the setup of the web service rather than the login service, underscoring the importance of mitigating timing end-to-end rather than on individual system components.

Another observation, not shown in the time difference graph of the RSA experiment, is that our simple timing mitigation mechanism also adds a latency penalty to the web service. The service time is unified to the closest power of 2 of the largest service time. This latency can be seen in Figure 8(b), where mitigation adds about 9 ms latency.

### 5.2.3 Expected Leakage

We applied the expected-leakage approach from Section 3.7 to the web service. Using 1000 random requests, we determined that 99% of them are below 8 ms. Replacing \( T_{\text{big}} = \lfloor \log 8 \rfloor \) and \( p = 0.99 \) with these values, the expected leakage for this application, as shown in Figure 9, is with \( q_0 = 1 \) ms. Clearly, the mitigated version leaks information slowly in practice.

### 6. Related Work

Timing channels have been widely studied in the literature. We briefly explore related work below.

#### Cryptographic Side-Channels
One major motivation for controlling timing channels is the protection of cryptographic keys against side-channels arising from timing cryptographic operations. Various attacks exploiting timing side-channels have been demonstrated [4, 17]. Cryptographic blinding [5, 17] is a standard technique for mitigating such channels.

Recent works by Köpf et al. [18, 19] utilize blinding with quantization (referred to as bucketing) to derive tight bounds on leakage of cryptographic operations.

#### Quantitative Information Flow
We advocate a quantitative approach to controlling information flow through timing channels. Like much other work on quantitative information flow [6, 23, 18, 19], we draw on information theory to obtain bounds on leakage. Millen [24] first observed that noninterference implies zero channel capacity between high and low. DiPierro et al. [28] quantify timing leaks in a language-based setting. Epoch-based mitigation is similar in spirit to Mode Security [3], which reduces covert channels to changes in modes. Unlike Mode Security, we also account for leakage within epochs via a combinatorial analysis.

#### Detection of Timing Attacks
Some prior work on timing channels has focused on detecting the perturbation in the distribution of times introduced by timing attacks [10]; however, stealthy timing attacks have been demonstrated [21, 22].

#### Mitigation of Timing Attacks
Giles and Hajek present a comprehensive study of timing channels [11], where packet arrival is represented by continuous or discrete waveforms. Similarly to us, they employ periodic quantization. However, because of the constant periods, the reduction of the timing channel bandwidth is only linear. Another difference lies in the semantics of buffer bounds: while they assume that a jammer must release a packet from the queue when a buffer is full, our mitigators block the input source.

One prior approach to timing channel mitigation is adding noise to timing measurements. There are two ways to do this. First, we can add random delays to the time taken by various operations, which reduces the bandwidth of the timing channel, as in [14, 11]. Adding random delays sacrifices performance and does not asymptotically eliminate timing channels, since the noise can be eliminated to whatever degree is desired by averaging over a sequence of identical requests. Methods for creating covert timing robust against added noise have been demonstrated [21].

A second approach, also used in [14], is that programs that read clocks are given results with random noise. This method only applies to internal timing channels based on reading clocks directly.

Wray [32] views every covert channel that originates from comparing two clocks as a timing channel. In this light, we focus on the channels that arise from comparing the timing of events to an external reference clock that is not modulated by the attacker. Our results in Section 3.5 can be interpreted as mixing external timing channels and all other covert channels.

The line of work on NRL Pump [15, 16] addresses timing channels that arise when high confidentiality processes acknowledge receipt of messages from low confidentiality processes.

In a language-based setting, it is possible to reason about ways the program can measure time, and language-based methods have been proposed for controlling internal timing channels by analysis [33] and by transformation [1, 29]. Coppens et al. [7] explore automating compiling techniques to defend against timing-based side-channel attacks on x86 processors. Language-based methods for mitigating general external timing channels have also been proposed but rely on unrealistic assumptions. For example, Agat’s work [1] ignores the effect of the code cache on timing and is limited to programs that lack loops and recursion. Shroff and Smith lift some of Agat’s limitations [31], but at the cost of possibly disrupting computations.

### 7. Conclusion

This paper introduces a new class of schemes for mitigating timing channels in general computer systems. The key intuition is that the timing mitigator can often predict the future availability of events to deliver. Mitigator predictions divide time into epochs. When a prediction fails, a new epoch begins, and some information is leaked. The mitigator can track the amount of information leaked at each epoch transition and enforce the specified leakage bound. When the information bound permits, the mitigator can also adaptively start a new epoch for improved performance.

This paper identifies the key conditions that an epoch-based mitigator must satisfy and describes some useful adaptive mechanisms. However, there is more work to be done on understanding the space of epoch-based timing mitigators. The problem of generating schedules of predictions for these mitigators, particularly for various classes of applications, appears interesting.

This paper considers combining timing mitigation with other mechanisms for controlling information flow through storage channels and shows that it is possible to conservatively bound the capacity of the combined channel by building on the analysis of timing channel capacity given here. However, we have not yet implemented such a combined mechanism for information flow control; this is clearly a useful future direction. Exploring epoch-based timing mitigation in real-world systems is an obvious next step.

### 8. References

[1] J. Agat. Transforming out timing leaks. In Proc. 27th ACM Symp. on Principles of Programming Languages (POPL), pages 40–53, Boston, MA, Jan. 2000.

[2] A. Bortz and D. Boneh. Exposing private information by timing web applications. In Proc. 16th Int’l World-Wide Web Conf., May 2007.

[3] R. Browne. Mode security: An infrastructure for covert channel suppression. In IEEE Symposium on Research in Security and Privacy, pages 39–55, May 1994.

[4] D. Brumley and D. Boneh. Remote timing attacks are practical. Computer Networks, Jan. 2005.

[5] D. Chaum. Blind signatures for untraceable payments. In CRYPTO, pages 199–203, 1982.

[6] M. R. Clarkson, A. C. Myers, and F. B. Schneider. Quantifying information flow with beliefs. Journal of Computer Security, 17(5):655–701, 2009.

[7] B. Coppens, I. Verbauwhede, K. D. Bosschere, and B. D. Sutter. Practical mitigations for timing-based side-channel attacks on modern x86 processors. IEEE Symposium on Security and Privacy, pages 45–60, 2009.

[8] D. Coppersmith. Small solutions to polynomial equations, and low exponent RSA vulnerabilities. Journal of Cryptology, 10(4), Dec. 1997.

[9] R. G. Gallagher. Basic limits on protocol information in data communication networks. IEEE Transactions on Information Theory, 22(4), July 1976.

[10] S. Gianvecchio and H. Wang. Detecting covert timing channels: an entropy-based approach. In CCS ’07, Oct. 2007.

[11] J. Giles and B. Hajek. An information-theoretic and game-theoretic study of timing channels. IEEE Transactions on Information Theory, 48(9):2455–2477, 2002.

[12] J. A. Goguen and J. Meseguer. Security policies and security models. In Proc. IEEE Symposium on Security and Privacy, pages 11–20, Apr. 1982.

[13] D. M. Goldschlag. Several secure store and forward devices. In CCS ’96, pages 129–137, Mar. 1996.

[14] W.-M. Hu. Reducing timing channels with fuzzy time. In IEEE Symposium on Security and Privacy, pages 8 – 20, 1991.

[15] M. H. Kang and I. S. Moskowitz. A pump for rapid, reliable, secure communication. In CCS ’93, pages 119–129, Nov. 1993.

[16] M. H. Kang, I. S. Moskowitz, and S. Chincheck. The pump: A decade of covert fun. In ACSAC ’05, pages 352–360, 2005.

[17] P. Kocher. Timing attacks on implementations of Diffie–Hellman, RSA, DSS, and other systems. In Advances in Cryptology—CRYPTO’96, Aug. 1996.

[18] B. Köpf and M. Dürmuth. A provably secure and efficient countermeasure against timing attacks. In 2009 IEEE Computer Security Foundations, July 2009.

[19] B. Köpf and G. Smith. Vulnerability bounds and leakage resilience of blinded cryptography under timing attacks. In 2010 IEEE Computer Security Foundations, July 2010.

[20] B. W. Lampson. A note on the confinement problem. Comm. of the ACM, 16(10):613–615, Oct. 1973.

[21] Y. Liu, D. Ghosal, F. Armknecht, A. Sadeghi, and S. Schulz. Hide and seek in time—robust covert timing channels. In ESORICS, 2009.

[22] Y. Liu, D. Ghosal, F. Armknecht, A. Sadeghi, S. Schulz, and S. Katzenbeisser. Robust and undetectable steganographic timing channels for i.i.d. traffic. In Information Hiding 2010, June 2010.

[23] G. Lowe. Quantifying information flow. Proc. IEEE Computer Security Foundations Workshop, June 2002.

[24] J. K. Millen. Covert channel capacity. In Proc. IEEE Symposium on Security and Privacy, Oakland, CA, 1987.

[25] M. A. Olson, K. Bostic, and M. Seltzer. Berkeley DB. In Proc. USENIX Annual Technical Conference, 1999.

[26] D. Osvik, A. Shamir, and E. Tromer. Cache attacks and countermeasures: the case of AES. Topics in Cryptology–CT-RSA 2006, Jan. 2006.

[27] M. Padlipsky, D. Snow, and P. Karger. Limitations of end-to-end encryption in secure computer networks. Technical Report ESD TR-78-158, Mitre Corp., 1978.

[28] A. D. Pierro, C. Hankin, and H. Wiklicky. Quantifying timing leaks and cost optimisation. Information and Communications Security, 2010.

[29] A. Russo, J. Hughes, D. Naumann, and A. Sabelfeld. Closing internal timing channels by transformation. In Proc. 11th Annual Asian Computing Science Conference (ASIAN), 2006.

[30] G. Shah, A. Molina, and M. Blaze. Keyboards and covert channels. Proc. 15th USENIX Security Symp., Aug. 2006.

[31] P. Shroff and S. F. Smith. Securing timing channels at runtime. Technical report, The John Hopkins University, July 2008.

[32] J. C. Wray. An analysis of covert timing channels. In IEEE Symposium on Security and Privacy, pages 2–7, 1991.

[33] S. Zdancewic and A. C. Myers. Observational determinism for concurrent program security. In Proc. 16th IEEE Computer Security Foundations Workshop, pages 29–43, Pacific Grove, California, June 2003.

### Appendix

**A More Precise Bound on Leakage of the Basic Scheme**

This derivation is based on the fact that each possible string can be determined by the placement of the misses, that is, the locations of “–” in the string. For \( m \) misses in time \( T \), there are at most \( \binom{T}{m} \) different strings. So, the total number of possible strings is:

\[
\sum_{m=0}^{\log T} \binom{T}{m} \leq (\log T + 1) \cdot \frac{T^{\log T}}{(\log T)!}
\]

Thus, the leakage can be no more than \( \log(\log T + 1) + \log_2 T - \log((\log T)!) \), and by Stirling’s approximation:

\[
\log((\log T)!) = \log T \cdot \log \log T - \log T + o(\log T)
\]

So the whole leakage term is \( O(\log T (\log T - \log \log T)) \).

**Proof of Theorem 1**

We prove the theorem by using the definition of \( I(X; Y) \) to show that the expression \( H(Z) + I(X; Y) - I(X; Y, Z) \) is nonnegative.

\[
H(Z) + I(X; Y) - I(X; Y, Z)
\]
\[
= H(Z) + H(X) + H(Y) - H(X, Y) - H(X) - H(Y, Z) + H(X, Y, Z)
\]
\[
= H(Z) + H(Y) - H(X, Y) - H(Y, Z) + H(X, Y, Z)
\]
\[
\geq H(Z) + H(Y) - H(X, Y) - H(Y) - H(Z) + H(X, Y, Z)
\]
\[
= H(X, Y, Z) - H(X, Y) \geq 0
\]

\(\blacksquare\)