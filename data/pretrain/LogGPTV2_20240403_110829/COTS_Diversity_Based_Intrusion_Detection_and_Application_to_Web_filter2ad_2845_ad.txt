### Analysis and Elimination of Alerts

Each generated alert must be analyzed to determine its root cause and to eliminate potential residual false positives. As shown in Figure 5, only the first four types of alerts (22% of the total) are likely to be false positives. However, these have not been eliminated because they appear to be symptoms of unsuccessful attacks. The first three types of winsys access requests are indicative of an intrusion: one server (IIS) delivers a response while the others refuse, suggesting that confidentiality attacks on IIS have succeeded. The comparison algorithm detects a significant number of output differences, but 99.63% of these differences are masked by design difference masking mechanisms (see Figure 4). For example, a rule allows masking differences generated for an HTTP request on a directory without appending a final '/' (thttpd and IIS servers respond with a 302 status code, while Apache responds with a 301 status code). At the proxy level, we transform all resource names to lowercase, addressing case sensitivity issues between Windows and Linux/MacOS-X. Without such masking mechanisms, the output differences would generate a large number of false positives.

Currently, we have defined 36 rules, with more to be added in the future. Even with additional rules, the rule base is expected to remain manageable (only 5 rules mask 90% of the design differences). This suggests that the effort required to define these rules is relatively low compared to building a complete behavior model for classical anomaly detectors, making this mechanism viable in a real environment.

### Comparison with Snort and WebStat

Comparing the outputs of the three IDSs (our tool, WebStat, and Snort) is challenging due to differences in detected attacks and false positives. To provide a rough comparison, we present the results obtained from the same dataset using our tool, WebStat, and Snort, both configured with their standard signature sets (Figure 6).

We fed the three IDSs with the same HTTP traffic (800,000 requests logged on our campus web server in March 2003). The mean number of alerts per day is a key performance metric, given that there are very few successful attacks in the log (at most 1.4% of the requests may be harmful). Figure 6 shows that Snort and WebStat each generate about 10 alerts per day, while our tool generates about 5. This can be attributed to the fact that our IDS specifically detects intrusions, whereas Snort and WebStat detect attack attempts without confirming their success or failure. Therefore, our approach produces fewer alerts without missing known attacks. However, this conclusion should be interpreted cautiously, as Snort and WebStat were not fully tuned for this experiment.

### Detection Time and Time Overheads

Evaluating the time overheads induced by the detection process is crucial when applying intrusion detection to a service. Since the detection is performed online in real-time, it introduces a time overhead. Table 2 summarizes the results, measured from the client's perspective (the time between a request and the reception of its answer).

- **IDS Inactive**: Mean time necessary to process a request by each web server.
- **IDS Active**: Mean time required to process a request when the proxy and IDS are active.
- **IDS Overhead**: Additional time introduced by the IDS.

Activating the proxy and IDS increases the request processing time by approximately six times. The communications and detection algorithm contribute to this overhead. Although the prototype IDS is not optimized, the induced overhead (about 0.1 seconds) is acceptable for real-time use.

### Discussion

Our IDS successfully detects attacks against the availability and confidentiality of COTS servers. Availability attacks are detected when a server fails to respond to further requests, and confidentiality attacks are identified when the responses from COTS servers differ. However, some integrity attacks may go undetected if the responses are equivalent according to the detection algorithm, even if one server has been compromised. This is because we do not currently investigate the internal actions of web services. Future work will address this issue.

Another challenge is the dynamic nature of web servers, which often use functionalities like script execution and database access. These functionalities are considered separate applications and require additional specific IDSs at the application level. For example, COTS diversity (e.g., database diversity, script interpreter diversity) can be applied to each of them.

In some cases, the identification of the compromised server is not possible, especially if there is no majority in the responses. While output difference masking mechanisms help, some differences may be symptoms of both design differences and faults, making it difficult to mask them without introducing false negatives.

### Conclusion and Future Work

In conclusion, our approach provides high detection coverage and a low level of false positives. However, applying the method to COTS requires managing a high number of output differences not related to vulnerabilities. Currently, we use off-line generated rules to eliminate these differences, but this requires administrative effort and expertise. Future work will focus on characterizing detected differences online to avoid explicit rule definitions, leading to the development of diagnosis functions to identify server failures and ensure response correctness.

### Acknowledgements

This work was partially supported by the Conseil Régional de Bretagne and is part of the French Ministry of Research (CNRS ACI-SI) DADDi project.

### References

1. Shannon, C., Moore, D.: The spread of the witty worm. Security and Privacy 2 (2004)
2. Moore, D., Paxson, V., Savage, S., Shannon, C., Staniford, S., Weaver, N.: Inside the slammer worm. Security and Privacy 1 (2003) 33–39
3. Kantz, H., Veider, A.: Design of a vital platform for railway signalling applications. In: Proceedings of the 10th European Workshop on Dependable Computing (EWDC-10), Vienna, Austria (1999) 37–41
4. Adelsbach, A., Cachin, C., Creese, S., Deswarte, Y., Kursawe, K., Laprie, J.C., Pfitzmann, B., Powell, D., Randell, B., Riodan, J., Stroud, R.J., Veríssimo, P., Waidner, M., Welch, I.: MAFTIA conceptual model and architecture. Maftia deliverable d2, LAAS-CNRS (2001)
5. Valdes, A., Almgren, M., Cheung, S., Deswarte, Y., Dutertre, B., Levy, J., Saïdi, H., Stravidou, V., Uribe, T.E.: An adaptive intrusion-tolerant server architecture. In: Proceedings of the 10th International Workshop on Security Protocols, Cambridge, U.K. (2002)
6. Just, J., Reynolds, J., Clough, L., Danforth, M., Levitt, K., Maglich, R., Rowe, J.: Learning Unknown Attacks - A Start. In: Proceedings of the 5th International Symposium on Recent Advances in Intrusion Detection (RAID 2002), Zurich, Switzerland (2002)
7. Veríssimo, P.E., Neves, N.F., Correia, M.P.: Intrusion-tolerant architectures: Concepts and design. In: Architecting Dependable Systems. Volume 2677. (2003)
8. Porras, P.A., Neumann, P.G.: EMERALD: Event monitoring enabling responses to anomalous live disturbances. In: Proceedings of the 20th National Information Systems Security Conference. (1997) 353–365
9. Ko, C., Fink, G., Levitt, K.: Automated detection of vulnerabilities in privileged programs by execution monitoring. In: Proceedings of the 10th Annual Computer Security Applications Conference, IEEE Computer Society Press (1994) 134–144
10. Sekar, R., Bendre, M., Dhurjati, D., Bollineni, P.: A fast automaton-based method for detecting anomalous program behaviors. In: Proceedings of the 2001 IEEE Symposium on Security and Privacy, Oakland, CA (2001) 144–155
11. Avizienis, A., Kelly, J.P.J.: Fault tolerance by design diversity: Concepts and experiments. IEEE Computer (1984) 67–80
12. Randell, B.: System structure for software fault tolerance. In: Proceedings of the International Conference on Reliable Software. (1975) 437–449
13. Laprie, J.C., Arlat, J., Béounes, C., Kanoun, K.: Definition and analysis of hardware-and-software fault-tolerant architectures. IEEE Computer 23 (1990) 39–51
14. Avizienis, A., Chen, L.: On the implementation of n-version programming for software fault tolerance during execution. In: Proceedings of the IEEE COMPSAC 77. (1977) 149–155
15. Lyu, M., He, Y.: Improving the N-version programming process through the evolution of a design paradigm. IEEE Transactions on Reliability 42 (1993) 179–189
16. Gashi, I., Popov, P., Stankovic, V., Strigini, L. In: On Designing Dependable Services with Diverse Off-The-Shelf SQL Servers. Volume 3069 of Lecture Notes in Computer Science. Springer-Verlag (2004) 196–220
17. Wang, R., Wang, F., Byrd, G.T.: Design and implementation of acceptance monitor for building scalable intrusion tolerant system. In: Proceedings of the 10th International Conference on Computer Communications and Networks, Phoenix, Arizona (2001) 200–5
18. Saidane, A., Deswarte, Y., Nicomette, V.: An intrusion tolerant architecture for dynamic content internet servers. In Liu, P., Pal, P., eds.: Proceedings of the 2003 ACM Workshop on Survivable and Self-Regenerative Systems (SSRS-03), Fairfax, VA, ACM Press (2003) 110–114
19. Tombini, E., Debar, H., Mé, L., Ducassé, M.: A serial combination of anomaly and misuse IDSes applied to HTTP traffic. In: Proceedings of ACSAC’2004. (2004)
20. Debar, H., Tombini, E.: Webanalyzer: Accurate and fast detection of HTTP attack traces in web server logs. In: Proceedings of EICAR, Malta (2005)
21. Vigna, G., Robertson, W., Kher, V., Kemmerer, R.: A stateful intrusion detection system for world-wide web servers. In: Proceedings of the Annual Computer Security Applications Conference (ACSAC 2003), Las Vegas, NV (2003) 34–43
22. Roesch, M.: Snort - lightweight intrusion detection for networks. In: 13th Administration Conference, LISA’99, Seattle, WA (1999)

### Description of the Attacks Against BuggyHTTP

1. **Confidentiality Attack**: The BuggyHTTP server does not verify the URL of a request, allowing access to files outside the served site by using a sequence of "../". Running the BuggyHTTP server as root on a Linux computer, we accessed the /etc/shadow file, which contains encrypted user passwords, with a request like "GET /../../../../../../etc/shadow HTTP/1.0". The violation of confidentiality was detected; the BuggyHTTP server responded with a 200 status code and sent the file, while the other COTS servers (Apache and IIS) responded with 404 and 400 status codes, respectively.

2. **Integrity Attack**: The same vulnerability was exploited to modify files on the system. No checks are performed in the code that allows access to scripts, enabling the execution of any binary on the system. A request like "GET /cgi-bin/../../bin/sh -c 'echo root::12492::::: > /etc/shadow'" modified the /etc/shadow file. The BuggyHTTP server accepted the request, while the Apache and IIS servers refused it, responding with 400 status codes. Thus, the violation of integrity was detected.

3. **Availability Attack**: We modified the BuggyHTTP server to use a "select" approach instead of a "fork" approach for handling network connections. This allowed us to exploit a buffer overflow vulnerability to crash the server, resulting in a loss of availability. The BuggyHTTP server did not respond to the request, while the other servers (Apache and IIS) responded with 400 and 414 status codes, respectively. This intrusion was also detected.