23 These lists will always be disjoint, as we do not allow corrupted keys to be used for encryption operations. Fully
removing this restriction would lead to a non-committing encryption level of security, not a goal for AWS KMS.
However, in Appendix B we describe how our proof extends to a simple relaxation where corrupt keys can be used
after corruption.
15
holds and the key with hdl has not been corrupted by A, the functionality ﬁrst computes sk ←
TkReveal(tk, hdl, cmd) and cph ← E(sk, 0|msg|, ad). It then updates the table with (hdl, cph, ad) →
msg and returns cph to Z. Otherwise, an error symbol is returned.
– Dec(hdl, cph, ad) passes control to A, indicating that Z requested the decryption of ciphertext
cph with associated data ad, under the key corresponding to handle hdl. Adversary A is expected
to eventually return a tuple (tk, cmd) and, if valid(trace, tk, hdl, cmd) holds and the key with hdl
has not been corrupted by A, then Z receives T [(hdl, cph, ad)]. Otherwise, an error symbol is
returned.
This ends the presentation of the interface oﬀered to Z.
Adversarial interface. The oracles available to A reﬂect precisely the capabilities of a malicious
insider adversary with direct access to the cryptographic API. As a worst case scenario, we let this
adversary control the scheduling of API management and key generation operations, which in par-
ticular means that such an adversary may decide not to allow the API to answer the environment’s
requests.
We follow common practice in cryptographic API security deﬁnitions and allow A to corrupt
keys using a CorruptR oracle, through which it can explicitly learn any secret key with handle hdl,
even if such a key would otherwise be hidden from its view, i.e. even if such a key is meant to
be protected by the API. Importantly, this captures a common real-world issue where keys are
(maliciously or inadvertently) leaked, and ensures that non-leaked keys remain secret under those
circumstances. To prevent the adversary from trivially distinguishing the real world from the ideal
world, we never allow A to corrupt a key that is used by the environment Z for encryption/de-
cryption operations.
Security goal. We say a cryptographic service is secure if, for all (Z,A), the views of Z in the
real and ideal worlds are computationally indistinguishable. This means that the real-world system
is not allowed to leak more than the ideal-world functionality, which reveals nothing about client
payloads to insider adversaries interacting with the API.
5 Machine-checked Security Proof
We describe the machine-checked proof in EasyCrypt in three steps, corresponding to the three
layers introduced in Section 2. We ﬁrst describe the formalization of indistinguishability-based
security, and show that this can be used as a convenient stepping stone in the analysis of the
DMP, as it implies our real-vs-ideal world notion of security. This corresponds to the top layer
in Figure 1. Then, we describe a set of low-level abstractions that we constructed in order to
tame the complexity of the proof of indistinguishability-based security. We also discuss how we
proved that the security guarantees that we modularly obtain from these abstractions follow from
standard cryptographic assumptions, which allows us to state our main result in concrete terms.
This corresponds to the lower-level layer in Figure 1. Finally we describe the core theorem that
establishes the indistinguishability-based security of the DMP, and highlight the most interesting
technical aspects of its proof. This corresponds to the intermediate layer shown in Figure 1.
5.1 From key hiding to real-vs-ideal security
The indistinguishability-based security of a cryptographic API [23] guarantees that cryptographic
keys managed by the API remain hidden from the adversary. We adapt this notion to our formalism
via a game where, in addition to interacting with the API to create and manage tokens, the
16
game SecA(1λ) :
Tested ← [ ];
Corrupted ← [ ];
$←− {0, 1};
b
b(cid:48) ← AO(1λ);
return b = b(cid:48);
CorruptR(tk, hdl, cmd) :
key ←⊥;
if hdl (cid:54)∈ Tested ∧
key ← TkReveal(tk, hdl, cmd);
Corrupted ← hdl : Corrupted;
return key;
valid(tk, hdl, cmd)
Test(tk, hdl, cmd) :
key1 ← K(1λ); key0 ←⊥;
if hdl (cid:54)∈ Corrupted ∧
valid(tk, hdl, cmd)
key0 ← TkReveal(tk, hdl, cmd);
if hdl ∈ Tested
key1 ← Tested[hdl];
else Tested[hdl] ← key1;
key ← keyb;
return key;
InsideR(tk, hdl, cmd) :
key ←⊥;
if ¬(honest(tk, hdl, cmd))
key ← TkReveal(tk, hdl, cmd);
return key;
O = {TkManage, TkNewKey, Test, InsideR, CorruptR}
Fig. 9. Indistinguishability-based security.
adversary gets access to three oracles that capture the key hiding property. The Test oracle internally
uses the TkReveal operator in order to model a real-or-random style challenge oracle on keys. The
CorruptR and InsideR oracles use TkReveal to model explicit leakage of secret keys via corruption
and execution traces recognized as dishonest by the security deﬁnition (note that such queries only
strengthen the deﬁnition, as they state that domain keys will be protected even if one speciﬁc key is
leaked by some external means). In particular, the CorruptR oracle allows the adversary to expose
keys that it might otherwise be challenged on, and the InsideR oracle permits capturing CCA-style
attacks. The game is shown in Figure 9. In this experiment, the adversary interacts with a set
of oracles, which it can use to test valid, non-corrupt handles, receiving either the real key or a
randomly generated one (depending on bit b). We require that no adversary can win this game
other than with small probability over the random guess.
The following theorem, formalized and proved in EasyCrypt, implies that any cryptographic
API that satisﬁes indistinguishability-based security will give rise to an encryption service that
achieves our notion of UC-style security, when used together with an AEAD scheme satisfying the
standard notions of correctness and security.
Theorem 1 (Informal). If a cryptographic API satisﬁes indistinguishability-based security, and
(E,D) satisfy the standard notions of AEAD security then, for all adversaries (Z,A) the views of
Z in the real world and ideal worlds are indistinguishable.
The proof proceeds as follows. One ﬁrst uses the indistinguishability-based security of the API
to show that Dec is eﬀectively operating on a consistent secret key for each hdl, which are all
hidden from the adversary. Note that consistency is implied by the indistinguishability deﬁnition,
as the random branch b = 1 enforces that the same key is always returned for the same handle.
Consistency is essential to ensure that standard AEAD security suﬃces in the next step of the
proof, as otherwise one would need robust-encryption-level guarantees to ensure that operations
with diﬀerent keys on the same ciphertext do not leak information or allow forgeries.
The second step is to use AEAD correctness and unforgeability to switch to the table-like
computation of Dec performed by the ideal functionality. Note that, when reducing to the security
of the API, the validity predicate on traces enforced by the ideal functionality directly matches
identical conditions in the oracles available in the indistinguishability-based deﬁnition. In particular,
the corrupt oracles exactly match.
17
In EasyCrypt, the theorem is stated as follows. Notice that the reduction is tight, even though
the bound includes the advantage of correctness and indistinguishability-security twice. This is
because the proof requires symmetric game hops that ﬁrst replace API managed keys with random
ones using the IND-property and, after using AEAD security, restore the correct keys in order to
match the ideal functionality exactly.
+ AdvC(API,Z,A)
AEAD
+ AdvB1(Z,A)
.
API
lemma IndImpliesUC:
AdvZ,A
RI ≤ AdvB(Z,A)
API
RI =
where
AdvZ,A
|Pr[Real(Z, A, API).main():res] − Pr[Ideal(Z, A, API).main():res]|
AdvD
|Pr[Ind(D, API).main(false):¬res] − Pr[Ind(D, API).main(true):res]|
AdvD
AEAD =
|Pr[AEAD LoRCondProb(D).game(false):¬res]
− Pr[AEAD LoRCondProb(D).game(true):res]|