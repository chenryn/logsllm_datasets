methodologies for assessing unicast and multicast performance in switches and routers. 
These same methodologies still apply in the virtual world. 
Does a virtual switch support the same protocols and functions as a physical switch? 
When assessing Ethernet switches, network managers often put at least as much emphasis 
on reliability and features as on performance. Functional testing is just as important for 
virtual switches as performance and scalability testing, and should be a part of any data 
center test methodology. 
A network manager can reasonably expect any modern Ethernet switch to support 
features such as virtual LANs (VLANs), access control lists (ACLs), and Internet group 
management protocol (IGMP) for forwarding multicast traffic. These protocols (and 
often many others) are often included as part of physical switch performance testing; they 
should also be included as well when testing virtual switches.   
Fibre Channel over Ethernet (FCoE) 
Fibre Channel (FC), by far the most widely used transport in storage-area networks 
(SANs), presents special challenges when it is converged into Ethernet-based data 
centers. FC employs management frames to identify endpoints and switch fabrics and to 
provide flow-control features not found in Ethernet. Also unlike Ethernet, FC is intended 
to operate in a loss-free manner; in contrast, Ethernet networks can tolerate loss. And FC 
traffic is highly sensitive to increases or changes in latency and jitter.  
Fibre Channel over Ethernet (FCoE) encapsulates FC traffic into Ethernet frames, thus 
substantially reducing interface count and cabling in the data center. However, it does not 
by itself protect the FC-specific features mentioned above. The IEEE has developed 
several new specifications to ensure reliable delivery of FC traffic – and each of these 
require testing, especially in the mixed Ethernet/FCoE deployments that will be 
increasingly common in many data centers. 
The new IEEE specifications include the following: 
•  802.1Qbb priority flow control (PFC): This congestion control mechanism that 
allows multiple traffic types, such as FCoE and non-FCoE, to share an Ethernet 
link. PFC uses Ethernet pause frames to delay non-preferred traffic when a 
transmitter has a preferred-class frame ready to send.  
Like the earlier version of Ethernet flow control defined in IEEE 802.3x, PFC 
Spirent Communications White Paper 
9 
Data Center Testing: A Holistic Approach 
works by sending XOFF and XON messages to signal that an interface should 
stop and resume transmitting, respectively. Unlike 802.3x flow control, PFC 
works on a per-priority basis, allowing different traffic classes to use different 
XOFF/XON intervals. 
•  802.1Qaz priority groups: This scheduling mechanism aims to ensure consistent 
quality of service levels for multiple traffic classes. 
•  Data center bridge exchange (DCBX): This set of extensions to the IEEE’s link-
layer discovery protocol (LLDP) allows data-center devices to exchange 
capabilities information upon link establishment. DCBX uses LLDP to carry 
messages specific to data-center networking, such as the use of PFC or 802.1Qaz 
priority groups. 
Basic FCoE testing covers functional validation of the new protocol. An FCoE-capable 
test instrument should help answer questions such as whether FCoE interfaces correctly 
use the FC initialization protocol (FIP) to discover and then log in and out of switch 
fabrics; whether FC endpoint IDs (FCIDs) are correctly mapped into Ethernet MAC 
addresses; and whether FCoE devices will accept static assignment of Fibre Channel’s 
World-Wide Names (WWNs). 
In more advanced FCoE benchmarking, the test instrument generates and analyzes a mix 
of multiple traffic FCoE and non-FCoE classes. Of key importance here is how well 
FCoE-compliant devices observe priority flow control messages during periods of 
congestion. Timing is a critical factor in assessing PFC efficiency. 
Like conventional Ethernet pause frames, PFC messages contain a pause quanta 
indicating how long a device should refrain from transmitting. One pause quanta equals 
512 bit times, which is equivalent to 51.2 nanoseconds at 10-Gbit/s rates. Note that a 
pause quanta indicates the maximum amount of time an interface should defer 
transmission; the actual time may be shorter if the device sends an XON message 
indicating congestion has cleared. 
After generating PFC frames, the test instrument can measure both pause duration and 
also pause response time, the interval between receipt of the PFC message and the actual 
pause. Also, pause response times may differ for PFC XOFF and XON messages. 
By generating multiple traffic classes with different pause quanta (and also using multiple 
frame sizes), the test instrument can create complex loads to simulate the stresses an 
FCoE switch may experience in production networks.  
Spirent Communications White Paper 
10 
Data Center Testing: A Holistic Approach 
Consider the example of a test instrument generating three traffic classes labeled P1, P2 
and P3, initially all at the same time: 
Traffic class 
P1 
P2 
P3 
XOFF/XON  
interval (µsec) 
Inter-PFC burst 
interval (µsec) 
200 
150 
300 
500 
450 
700 
The test instrument uses different XOFF/XON intervals for each class, and repeats each 
at different intervals: 
In this example, all three priorities initially send PFC XOFF messages at the same time, 
each with pause quanta of 65535. Some 150 µsec later, the P2 class sends an XON 
message, followed 50 µsec after that by an XON message for P1 traffic. At 300 µsec, the 
test instrument then sends an XON message for P3 traffic. The entire cycle then repeats, 
beginning with an XOFF message for P2 traffic 450 µsec after the first message.  
By using a mix of frame sizes and inter-PFC burst intervals, the different traffic classes 
quickly will become desynchronized, placing a heavy burden on FCoE devices.  
Moreover, the test grows significantly more stressful as port count increases. When 
testing data center switches with hundreds or thousands of ports, each handling a mix of 
multiple FCoE and non-FCoE frames, the switch’s flow control logic will need to keep 
up with a constant barrage of PFC messages at 10-Gbit/s Ethernet line rate (or beyond, as 
discussed in the next section). As with any emerging technology, it is prudent to stress-
test PFC functionality under load to determine the limits of system performance. 
40‐ and 100‐Gbit/s Ethernet 
Another major technology driver for data centers is the impending introduction of 40-
Gbit/s and 100-Gbit/s versions of Ethernet. In one sense, these new transports are “just 
Ethernet,” only faster. In another, they will pose fundamental challenges for test 
equipment, even including the ability to count packets. 
Spirent Communications White Paper 
11 
Data Center Testing: A Holistic Approach 
A major driver for higher-speed Ethernet in the data center is that edge ports are getting 
faster. Just as gigabit Ethernet interfaces in servers has driven the deployment of 10-
Gbit/s Ethernet uplinks in switches and routers, so too will the upcoming introduction of 
10-Gbit/s connections in servers and access switches drive a need for 40- and 100-Gbit/s 
Ethernet in data center backbones. Even when servers and downstream switches use 
interim solutions such as IEEE 802.3ad link aggregation instead of 10-Gbit/s 
connectivity, the extra traffic still places an additional burden on network backbones.  
Another major driver for faster Ethernet versions is the growing popularity of high-
bandwidth video traffic. With the growing use of high-definition television and on-
demand video services, data centers tasked with providing video-only or triple-play 
content may find gigabit and 10-gigabit links saturated. Higher-capacity backbones 
provide a natural solution for data centers serving up video traffic. 
These new versions of Ethernet pose new testing challenges, including the following: 
•  Can my test instrument count? 
•  Can my test instrument provide accurate latency and jitter measurements? 
•  Can my test instrument measure 40/100-Gbit/s Ethernet as a single entity? 
•  Can my test instrument determine sequencing? 
The first of these points, about counting frames, seems almost too obvious to mention. 
But obtaining accurate packet counts on 40/100-Gbit/s Ethernet will pose a significant 
technical challenge for test instruments. To understand why, it is useful to explore the 
concept of timestamp resolution. 
Timestamp resolution describes the precision with which a test instrument clocks the 
departure and arrival of frames on each test interface. To measure transmission time and 
count packets, test instruments embed a “signature field” in every frame. For example, to 
measure latency a test instrument subtracts the time when each frame is received from the 
time when it is transmitted. To do this, the instrument compares the timestamp in the 
received frame (the transmit time) with its system time (the receive time). 
For any time-based measurement, it also is important to know the timestamp resolution. 
For example, if a latency measurement is 1.000 microsecond and the test instrument has a 
timestamp resolution of 20 nanoseconds (a commonly used value in the field), then the 
actual measured latency may be anywhere in the range of 0.980 to 1.020 microseconds. 
At 40/100-Gbit/s speeds, a 20-ns resolution is not sufficiently precise for latency and 
jitter – or, for that matter, to see all traffic in the first place. The reason: The time needed 
to create a frame is less than 20 nanoseconds, both for 40- and 100-Gbit/s Ethernet. 
Some simple illustrations make the problem clear. With 10-Gbit/s Ethernet, the minimum 
time to insert a 64-byte frame onto the medium is 67.2 ns. In this case a 20-ns resolution 
is adequate since there are always multiple clock “ticks” per frame: 
Spirent Communications White Paper 
12 
Data Center Testing: A Holistic Approach 
With the higher transmission rates of 40- and 100-Gbit/s Ethernet, a 20-µsec timestamp 
resolution will not be sufficient. At 40-Gbit/s rates, the minimum frame insertion time 
falls to 16.8 ns. While 20-ns clock ticks are sufficient to measure the first few frames, the 
test instrument’s clock ticks and the frame rate will quickly become desynchronized, with 
two frames seen within a single tick of the clock: 
In this scenario, the test instrument may not be able to count all frames, let alone provide 
accurate latency and jitter measurements for those frames. 
The situation grows even more dire with 100-Gbit/s Ethernet, where the minimum frame 
insertion time drops to 6.72 ns. At 100-Gbit/s rates, there will always be multiple frames 
present per 20-ns clock tick: 
Spirent Communications White Paper 
13 
Data Center Testing: A Holistic Approach 
In this situation, the test instrument is virtually blind. Since it cannot provide an accurate 
count of the number of frames seen per clock tick, there is no chance for accurate 
measurements of any kind. This applies to all measurements provided by the test 
instrument – not just time-based metrics such as latency and jitter, but other key metrics 
such as throughput and frames in sequence. 
Clearly, 40- and 100-Gbit/s Ethernet will require finer timestamp resolution. A key 
question in selecting test equipment will be what level of precision the instrument 
provides. 
Another consideration specific to 40-Gbit/s Ethernet is whether the test instrument can 
track traffic from each interface as a single entity. This requirement may seem 
counterintuitive; after all, test instruments have provided per-port measurements for 
many years. But the IEEE specification for 40-Gbit/s Ethernet creates a flow by 
aggregating four 10-Gbit/s streams into one. Test instruments will need to reassemble 
these four streams, potentially at line rate, while still providing accurate measurements. 
A final issue that applies to both 40- and 100-Gbit/s Ethernet involves sequence counting. 
Applications such as FCoE-based storage and high-bandwidth video aggregation expect 
frames transmitted in order to be received in that same order, with even a small amount 
of reordering leading to degraded performance1.  
The signature fields that test instruments embed in each Ethernet frame contain sequence 
numbers the instrument uses to track frame order. Given the concerns discussed earlier 
about timestamp resolution and reassembly of multiple streams, it is reasonable to ask 
when assessing 40- and 100-Gbit/s test instruments whether they can provide 
comprehensive sequence analysis for all frames. 
1 TCP, which carries 90 percent or more of Internet backbone traffic according to studies by CAIDA and 
Sprint, can tolerate some reordering. However, excessive reordering of TCP traffic also can degrade 
performance and even lead to connection loss. 
Spirent Communications White Paper 
14 
Data Center Testing: A Holistic Approach 
Putting it all together 
The emerging model for data center network design converges many types of traffic – 
data, voice, video, storage – onto a single high-speed Ethernet platform, using a mix of 
virtual and physical components. Testing this complex design is greatly simplified with a 
holistic approach to protocol validation and performance measurement. 
In the new data center model, there are thousands of potential points of attachment for 
test instruments, some virtual and some physical. Consider the three-layer data center 
design – access, aggregation and core – in the following figure: 
Working from the access layer up, this data center design includes a mix of virtual 
servers running on blade chassis along with physical servers and mainframes, all 
connected to the aggregation layer over a combination of gigabit and 10-Gbit/s Ethernet 
links. The access layer also includes some physical switches and routers, and also virtual 
switches running on some of the blade chassis. The aggregation and core layers use a 
combination of switches and routers linked with 10-Gbit/s Ethernet (and 40- and 100-
Gbit/s Ethernet in the future) to interconnect all hosts with the public Internet. 
A holistic approach to testing can help make sense of this a complex mix of 
interconnected devices. In this context, “holistic testing” means the ability to measure 
performance not only of individual data center components, but also of the entire data 
center, and to make sense of the results. Holistic testing covers all layers of the 
networking stack and measures traffic across any arbitrary path through the data center. 
Spirent Communications White Paper 
15 
Data Center Testing: A Holistic Approach 
Holistic testing delivers many benefits: 
•  The test instrument provides a single unified environment for generating and 
analyzing test traffic. Test engineers should not need to “post-process” test 
results from multiple applications or test platforms to characterize the 
performance of the entire data center. 
•  Test instruments offer any-to-any connectivity between virtual and physical 
endpoints. This may mean testing between virtual servers; between physical 
servers; between virtual or physical network devices; or any permutation of 
multiple virtual and physical devices. 
•  Flow counts are highly scalable to assess the quality of service and quality of 
experience delivered by the data center. A complex data center design may 
handle thousands or millions of distinct flows, each with different service-level 
requirements. A holistic approach to testing allows the generation and analysis of 
many distinct traffic classes, all on a single platform. 
•  The entire test instrument scales so that measurements from the Nth port are 
just as accurate as those from the first port. A holistic approach requires a test 
instrument design that does not affect test measurements as test instrument 
interfaces and/or chassis are added. For example, a latency measurement between 
two test ports in the same chassis should yield the same result as a measurement 
between any two test ports on multiple, linked chassis. 
•  The test instrument can accommodate future bandwidth growth. The 
forthcoming introduction of 40- and 100-Gbit/s Ethernet not only requires test 
interfaces running at these speeds; it also demands that the test instrument will be 
able to provide the same measurements, with the same level of precision, as at 
lower speeds. This requires a test architecture designed from the ground up to 
accommodate 100-Gbit/s rates across the data center. 
In short, holistic testing means testing the entire data center – and that, in turn, requires a 
test instrument that can measure performance of the data center as a unified whole.  
Spirent Communications White Paper 
16