The authors thank all reviewers and proofreaders of the
paper for their useful comments. We also explicitly thank
Gijs Vanspauwen for his work on the compiler.
This research was done with the ﬁnancial support from
the Prevention against Crime Programme of the European
Union, the IBBT, the IWT, the Research Fund KU Leuven,
and the EU-funded FP7 project NESSoS.
9. REFERENCES
[1] Abadi, M., and Plotkin, G. D. On protection by
layout randomization. In Computer Security
Foundations Symposium (CSF) (2010), pp. 337–351.
11[2] Agten, P., Strackx, R., Jacobs, B., and
Piessens, F. Secure compilation to modern
processors. In Computer Security Foundations
Symposium (2012), pp. 171–185.
[3] Appel, A. W. Compiling with Continuations.
Cambridge University Press, New York, NY, USA,
2007.
[4] Azab, A., Ning, P., and Zhang, X. Sice: a
hardware-level strongly isolated computing
environment for x86 multi-core platforms. In
Proceedings of the 18th ACM conference on Computer
and communications security (2011), ACM,
pp. 375–388.
[5] Chen, X., Garfinkel, T., Lewis, E. C.,
Subrahmanyam, P., Waldspurger, C. A., Boneh,
D., Dwoskin, J., and Ports, D. R. K. Overshadow:
A virtualization-based approach to retroﬁtting
protection in commodity operating systems. In
ASPLOS (2008).
[6] Cohen, E., Dahlweid, M., Hillebrand, M.,
Leinenbach, D., Moskal, M., Santen, T.,
Schulte, W., and Tobies, S. Vcc: A practical
system for verifying concurrent c. In Proceedings of the
22nd International Conference on Theorem Proving in
Higher Order Logics (Berlin, Heidelberg, 2009),
TPHOLs ’09, Springer-Verlag, pp. 23–42.
[7] Datta, A., Franklin, J., Garg, D., and Kaynar,
D. A logic of secure systems and its application to
trusted computing. In 30th IEEE Symposium on
Security and Privacy (2009), IEEE, pp. 221–236.
[8] Dolev, D., and Yao, A. C. On the security of public
key protocols. IEEE Transactions on Information
Theory 29, 2 (1983), 198–208.
[9] El Defrawy, K., Aur´elien Francillon, D., and
Tsudik, G. Smart: Secure and minimal architecture
for (establishing a dynamic) root of trust. In
Proceedings of the Network & Distributed System
Security Symposium (NDSS), San Diego, CA (2012).
[10] England, P., Lampson, B., Manferdelli, J., and
Willman, B. A trusted open platform. Computer 36,
7 (July 2003), 55 – 62.
[11] Erlingsson, ´U. Low-level software security: Attacks
and defenses. Foundations of Security Analysis and
Design IV (2007), 92–134.
[12] Erlingsson, U., Younan, Y., and Piessens, F.
Low-level software security by example. In Handbook
of Information and Communication Security. Springer,
2010.
[13] Garfinkel, T., Pfaff, B., Chow, J., Rosenblum,
M., and Boneh, D. Terra: A virtual machine-based
platform for trusted computing. ACM SIGOPS
Operating Systems Review 37, 5 (2003), 193–206.
[14] Kauer, B. Oslo: improving the security of trusted
computing. In SS’07: Proceedings of 16th USENIX
Security Symposium on USENIX Security Symposium
(Berkeley, CA, USA, 2007), USENIX Association,
pp. 1–9.
[15] King, S., Chen, P., Wang, Y., Verbowski, C.,
Wang, H., and Lorch, J. SubVirt: Implementing
malware with virtual machines. IEEE Symposium on
Security and Privacy (Oakland) (2006).
[16] Klein, G., Elphinstone, K., Heiser, G.,
Andronick, J., Cock, D., Derrin, P., Elkaduwe,
D., Engelhardt, K., Kolanski, R., Norrish, M.,
et al. seL4: Formal veriﬁcation of an OS kernel. In
Proceedings of the ACM SIGOPS 22nd symposium on
Operating systems principles (2009), ACM,
pp. 207–220.
[17] Longley, D., and Rigby, S. An automatic search
for security ﬂaws in key management schemes.
Computers & Security 11, 1 (1992), 75–89.
[18] Martignoni, L., Paleari, R., and Bruschi, D.
Conqueror: tamper-proof code execution on legacy
systems. In Proceedings of the 7th Conference on
Detection of Intrusions and Malware and Vulnerability
Assessment (DIMVA) (July 2010), Lecture Notes in
Computer Science, Springer, pp. 21–40. Bonn,
Germany.
[19] Martignoni, L., Poosankam, P., Zaharia, M.,
Han, J., McCamant, S., Song, D., Paxson, V.,
Perrig, A., Shenker, S., and Stoica, I. Cloud
terminal: Secure access to sensitive applications from
untrusted systems.
[20] McCune, J. M., Li, Y., Qu, N., Zhou, Z., Datta,
A., Gligor, V., and Perrig, A. TrustVisor:
Eﬃcient TCB reduction and attestation. In
Proceedings of the IEEE Symposium on Security and
Privacy (May 2010).
[21] McCune, J. M., Parno, B., Perrig, A., Reiter,
M. K., and Isozaki, H. Flicker: An execution
infrastructure for TCB minimization. In Proceedings
of the ACM European Conference in Computer
Systems (EuroSys) (Apr. 2008), ACM, pp. 315–328.
[22] McCune, J. M., Perrig, A., and Reiter, M. K.
Safe passage for passwords and other sensitive data. In
Proceedings of the Symposium on Network and
Distributed Systems Security (NDSS) (Feb. 2009).
[23] One, A. Smashing the stack for fun and proﬁt. Phrack
magazine 7, 49 (1996).
[24] Parno, B., Lorch, J. R., Douceur, J. R.,
Mickens, J., and McCune, J. M. Memoir: Practical
state continuity for protected modules. In Proceedings
of the IEEE Symposium on Security and Privacy
(May 2011).
[25] Parno, B., Mccune, J. M., and Perrig, A.
Bootstrapping trust in commodity computers. In In
Proceedings of the IEEE Symposium on Security and
Privacy (2010).
[26] Reynolds, J. Deﬁnitional interpreters for
higher-order programming languages. In proceedings
25th ACM National Conference (1972), pp. 717–740.
[27] Rutkowska, J. Subverting VistaTM Kernel For Fun
And Proﬁt. Black Hat Brieﬁngs (2006).
[28] Sahita R, Warrier U., D. P. Protecting Critical
Applications on Mobile Platforms. Intel Technology
Journal 13 (2009), 16–35.
[29] Saltzer, J., and Schroeder, M. The protection of
information in computer systems. Proceedings of the
IEEE 63, 9 (1975), 1278–1308.
[30] Seshadri, A., Luk, M., Qu, N., and Perrig, A.
SecVisor: A tiny hypervisor to provide lifetime kernel
code integrity for commodity OSes. In Proceedings of
twenty-ﬁrst ACM SIGOPS symposium on Operating
systems principles (2007), ACM, pp. 335–350.
[31] Seshadri, A., Luk, M., Shi, E., Perrig, A., van
Doorn, L., and Khosla, P. Pioneer: Verifying
integrity and guaranteeing execution of code on legacy
platforms. In Proceedings of ACM Symposium on
Operating Systems Principles (SOSP) (Oct. 2005),
ACM, pp. 1–15.
[32] Shacham, H. The geometry of innocent ﬂesh on the
bone: return-into-libc without function calls (on the
x86). In Proceedings of the 14th ACM conference on
Computer and communications security (New York,
NY, USA, 2007), CCS ’07, ACM, pp. 552–561.
[33] Singaravelu, L., Pu, C., H¨artig, H., and
Helmuth, C. Reducing tcb complexity for
security-sensitive applications: three case studies. In
EuroSys ’06: Proceedings of the 1st ACM
SIGOPS/EuroSys European Conference on Computer
Systems 2006 (New York, NY, USA, 2006), ACM,
pp. 161–174.
12[34] Strackx, R., Piessens, F., and Preneel, B.
Eﬃcient Isolation of Trusted Subsystems in Embedded
Systems. Security and Privacy in Communication
Networks (2010), 344–361.
[35] Strackx, R., Younan, Y., Philippaerts, P.,
Piessens, F., Lachmund, S., and Walter, T.
Breaking the memory secrecy assumption. In
Proceedings of the Second European Workshop on
System Security (2009), ACM, pp. 1–8.
[36] Ta-Min, R., Litty, L., and Lie, D. Splitting
interfaces: Making trust between applications and
operating systems conﬁgurable. In Proceedings of the
7th symposium on Operating systems design and
implementation (2006), USENIX Association,
pp. 279–292.
[37] Thekkath, D. L. C., Mitchell, M., Lincoln, P.,
Boneh, D., Mitchell, J., and Horowitz, M.
Architectural support for copy and tamper resistant
software. SIGOPS Oper. Syst. Rev. 34 (November
2000), 168–177.
[38] Williams, P., and Boivie, R. Cpu support for
secure executables. Trust and Trustworthy Computing
(2011), 172–187.
[39] Younan, Y., Joosen, W., and Piessens, F. Code
injection in c and c++ : A survey of vulnerabilities
and countermeasures. Tech. rep., Department of
Computer Science, KULeuven, 2004.
[40] Zhou, Z., Gligor, V., Newsome, J., and McCune,
J. Building veriﬁable trusted path on commodity x86
computers. In IEEE Symposium on Security and
Privacy (2012).
APPENDIX
A. THE VAULT
The Vault is an SPM that stores sensitive information on
behalf of other SPMs. It oﬀers two services. First, an SPM
can ask the Vault to store persistent secret data. The Vault
will append the identity of the requesting SPM (its layout
and cryptographic hash of the public section), encrypt and
sign the data and store it using the (untrusted) services of
the legacy operating system.
Second, only an SPM that previously stored secret data
can retrieve it again. After mutual authentication, the Vault
retrieves the encrypted data from the legacy operating sys-
tem, checks its integrity, decrypts it and sends it over a
secure channel to the requesting SPM.
The Vault is treated specially by Fides: it is created when
Fides is booted, and it receives its own secret data directly
from the secure storage space on the TPM.
Besides oﬀering secure storage, the Vault also ensures
state continuity [24]. In particular, protection against two
possible attacks is provided. First, in a rollback attack, an
attacker passes a stale version of an SPM’s stored data from
disk to the Vault. Depending on the module’s functionality,
this may result in a security vulnerability, such as the reuse
of cryptographic keys.
Second, the Vault should also provide crash resilience. As
a compromised legacy kernel may allow an attacker to cause
the system to crash, persistent storage of fresh data could
be prevented based on subtle timing diﬀerences. This essen-
tially enables an attacker to prevent the system from making
progress.
Our prototype implementation does not yet implement
state continuity guarantees, but the techniques proposed by
Parno et al. [24] are also applicable to Fides: each SPM could
request persistent storage of service requests before they are
Figure 8: Using Fides’ access control model and fast
local communication, attestation can be supported
easily and transparently to any attested module.
handled. The Vault in turn, keeps a request history for each
module. The Vault thus acts as an intermediate module that
stores state information of other modules. This reduces the
number of modules that require storage for state-continuity
on the TPM chip to one, limiting the wear on NVRAM.
B. REMOTE ATTESTATION
Fides’ access control model and local communication mech-
anism can also be leveraged to attest correct execution of
modules with two key characteristics. First, meaningful at-
testation can be provided to the remote party, called the
veriﬁer. Only a small TCB consisting of the Fides archi-
tecture, an attestation module, the Vault and the attested
module(s), are included in the measurement. Second, the
attestation is transparent: the correct execution of any mod-
ule can be attested without any modiﬁcation. This improves
reusability of modules.
Attestation in Fides is based on a two-layered approach
where each layer attests its correct execution. Due to page
constraints, only a sketch of the mechanism is presented. It
relies however on µTPMs presented by McCune et al. [20].
Interested readers are referred there.
At the lowest level, the TPM chip ensures the correct load-
ing of Fides and boots trust on the next layer. To achieve
this, PCR registers 17, 18 and 19 are extended with a mea-
surement of Fides, the security report of an attestation mod-
ule and the Attestation Identity Key (AIKSP M ) respectively.
At the second level, attestation modules provide an attes-
tation service and implement PCR extend and quote func-
tionality similar to a hardware TPM chip. This prevents
hardware PCR registers from being cluttered. As several
identical attestation modules can also be loaded in the sys-
tem, the number of SPMs that can be attested at the same
time is virtually unlimited.
Figure 8 displays how the correct execution of an Attested
SPM can be proven. First, the veriﬁer provides two nonces
n1 and n2 and an attestation module is created. Next, the
attestation module extends its measurement with the Vault
and requests its AIKSP M key. Similarly the attested module
is measured and contacted in step 3. Finally, the attestation
module extends its measurement with the received result
and signs it together with n2. A similar request is sent to the
lower level with n1, but is only granted when the request is
made from a module compliant with the measured security
report in PCR 18. In step 4, both quotes are sent to the
veriﬁer.
In case the attested SPM calls other SPMs, the veriﬁer is
able to rely on the authenticated communication mechanism
to ensure that no untrusted SPMs are used in the compu-
tation of the result. Alternatively, attestation-aware SPMs
could notify the attestation module which SPMs are used.
13