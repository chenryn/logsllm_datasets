0
6
0
13
5
1
17
1
0
3
22
1
31
18
4
11
1
22
2
20
11
10
52
2
2
86%
73%
100% 100%
99%
90%
96%
90%
98%
93%
91%
69%
67%
65%
100% 100%
72%
80%
90%
99%
68%
65%
89%
93%
80%
70%
80%
100% 100%
97%
73%
99%
100%
69%
100%
100%
60%
67%
69%
100%
67%
67%
77%
61%
71%
65%
100%
100%
75%
79%
100%
84%
82%
67%
61%
100%
79%
100%
61%
69%
91%
75%
67%
100%
structure of the program. Our results show that the features we
extracted can detect vulnerabilities with reasonable accuracy.
Therefore we assume both the code structure patterns and the
complexity have an impact on the existence of vulnerabilities.
Another advantage of using an ML based security vulnerability
analysis is the support of traceability from the binary labels to
one, or a subset of static code analyzers. This feature allows
developers to focus on one or a subset of analyzers for further
investigation and consequently save their time and resources.
For example, for Integer overﬂow,
is associated
with Mythril in our system. If the vulnerability is present,
developers can only focus on Mythril and rule out Slither for
further investigation.
the label
We found certain ML algorithms outperform others for
some speciﬁc vulnerabilities. For example, as shown in Ta-
ble III, SVM performed better for Integer underﬂow, while NN
achieved better accuracy for Re-entrancy vulnerability with
balance change. Therefore, there is no single machine learning
algorithm that is suitable to ﬁnd all types of vulnerabilities.
Among 36 vulnerabilities, described in Table II, 16 of
them were identiﬁed with high accuracy. This is a major
limitation of our study that might have caused for the following
reasons. First, the size of the dataset could be a limitation. Our
dataset was limited to 1,013 currently veriﬁed smart contracts
which were not rich in terms of not-identiﬁed vulnerabilities.
By expanding the dataset with more diverse occurrence of
vulnerabilities, it is possible for the ML model to detect other
vulnerabilities. Second, we have only used two static code an-
alyzers in this model. Increasing the number of analyzers will
improve the results of intersected detectable vulnerabilities,
and increase the covering range of vulnerabilities. Third, the
17 extracted features were not sufﬁcient to capture the patterns
of code for some vulnerabilities. Related to the limitation
of the dataset size, number of features can be expanded by
extracting more features from the byte codes as proposed in
[8]. We also aware that, there might be certain vulnerability
cases, that cannot be associated with the features extracted
from code complexity and structure.
Applying our ML model to predict the security vulnerabili-
Fig. 2. Elapsed computation time for our ML models vs. Static code analyzers
ties in a smart contract achieved a signiﬁcant improvement in
terms of efﬁciency comparing to static code analysis. In Fig. 2,
we illustrate that the elapsed execution time for two static
code analyzers (Mythril and Slither) to ﬁnd the vulnerabilities
in about 1,000 smart contracts was approximately 7.31e3
seconds. Meanwhile, the execution time for running 184 ML
models was only 3.20e−1 seconds to ﬁnd the 16 vulnerabil-
ities form the same dataset as listed in Table III. The results
show that the ML model-based approach is about 2.28e4
times faster than the static code analyzers. We are aware that
we achieved this efﬁciency with the expenses of accuracy
and the number of detectable vulnerabilities. However, smart
contracts often have a rapid development process where the
developers are rushing to release the code at the earliest time
possible [2]. Thus, our ML model provides the possibility of
ﬁnding vulnerabilities with substantially less time while retains
reasonable accuracy.
Another reason for using the ML approach is that even
though static code analyzers are deterministic in principle, the
reported results carry a notion of probability. As described in
Section III-C, for one semantically consistent vulnerability,
two analyzers may report a conﬂicting result. Therefore,
adopting more analyzers in the ML model can greatly increase
the probability of ﬁnding the intersected vulnerabilities.
V. RELATED WORK
We have examined literature on three related areas of formal
veriﬁcation, static code analysis, and machine learning based
code analysis. Bhargavan et al. [4] proposed a framework
that veriﬁes security vulnerabilities with formal veriﬁcation
method. This proposal translates smart contracts source code
or bytecode into F ∗, and checks both functional correctness
and run time safety of a smart contract. Park et al. [3] adopted
full formal semantics of EVM to verify smart contracts.
However, these proposals could not be wildly used in practical
smart contract development as formal veriﬁcation methods
require deep knowledge of developing complex abstractions.
Several proposals addressed software vulnerabilities with static
code analysis. Oyente [1] and Mythril [6] are two static
analyzers that detect bugs through symbolic execution with
EVM bytecode. Tikhomirov et al. [2] introduced a static
analysis tool for Solidity that detects vulnerabilities through
pattern matching using XPath. These tools can only verify
defects that are predeﬁned. Also, there is a requirement for
manual auditing of the process to ﬁx the results when there is
a high false-positive rate. Other studies have utilized machine
learning algorithms to reveal potential security threats. Pang et
al. [7] presented a vulnerability code pattern matching method.
This proposal combined texting-mining with statistical feature
selection to identify vulnerable code pattern in Java. Harer et
al. [8] proposed a data-driven approach to reveal vulnerabilities
in C and C++ code. Existing ML based approaches are only
applicable to certain programming languages. To the best of
our knowledge, there is no machine learning based proposal
to detect security vulnerabilities for Solidity.
VI. CONCLUSION
In this research, we proposed a machine learning based
model to detect security vulnerabilities of smart contracts
on the Ethereum platform. We used static code analysis as
the underlying technology and trained an array of machine
learning models for different security vulnerabilities. Our
model was able to ﬁnd 16 different vulnerabilities with the
average accuracy of 95%. Our approach made a signiﬁcant
improvement on computational time and resources compared
to directly using static code analyzer tools. Checking a large
number of smart contracts using different static code analyzers
is a huge burden on developers. In addition, they need to learn
how each analyzer works and combine the results for a full
evaluation. Furthermore, our model can be used to identify
security vulnerabilities parallel to the development process
of smart contracts, thus decreasing the cost of development
by preventing the security vulnerabilities to be introduced
in early stages. Our proposed model is also applicable to
other languages and platforms since there are no language
or platform dependencies in the model. Training the model
with different dataset of the attentive language and choose
the corresponding static code analyzers and AST builders,
new machine learning code analyzers can be generated by
following the steps described in Section III.
VII. ACKNOWLEDGEMENT
Supports from NSERC, MITACS and Vector Institute for
Artiﬁcial Intelligence are acknowledged.
REFERENCES
[1] L. Luu, D.-H. Chu, H. Olickel, P. Saxena, and A. Hobor, “Making smart
contracts smarter,” in Proc 23rd ACM CCS, 2016, pp. 254–269.
[2] S. Tikhomirov, E. Voskresenskaya,
Ivanitskiy, R. Takhaviev,
E. Marchenko, and Y. Alexandrov, “Smartcheck: Static analysis of
ethereum smart contracts,” in Proc 1st WETSEB of 40th ICSE.
IEEE/ACM, 2018, pp. 9–16.
I.
[3] D. Park, Y. Zhang, M. Saxena, P. Daian, and G. Ros¸u, “A formal
veriﬁcation tool for ethereum vm bytecode,” in Proc. 26th ACM Joint
Meeting Eur. Soft. Eng. Conf. Symp. Oxford, U.K, 2018, pp. 912–915.
[4] K. Bhargavan, A. Delignat-Lavaud, C. Fournet, A. Gollamudi,
G. Gonthier, N. Kobeissi, A. Rastogi, T. Sibut-Pinote, N. Swamy, and
S. Zanella-Beguelin, “Formal veriﬁcation of smart contracts,” in Proc.
ACM Workshop Programming Lang. Analysis Sec., 2016, pp. 91–96.
[5] Crytic, “Slither, the solidity source analyzer,” 2019. [Online]. Available:
https://github.com/crytic/slither
[6] B. Mueller, “Smashing ethereum smart contracts for fun and real proﬁt,”
in Proc 9th Annual HITB Sec. Conf., 2018.
[7] Y. Pang, X. Xue, and A. S. Namin, “Predicting vulnerable software
components through n-gram analysis and statistical feature selection,”
in Proc. 14th Int. Conf. Machine Learning and Applications (ICMLA).
IEEE, 2015, pp. 543–548.
[8] J. A. Harer, L. Y. Kim, R. L. Russell, O. Ozdemir, L. R. Kosta,
A. Rangamani, L. H. Hamilton, G. I. Centeno, J. R. Key, P. M.
Ellingwood et al., “Automated software vulnerability detection with
machine learning,” arXiv preprint arXiv:1803.04497, 2018.
[9] N. Atzei, M. Bartoletti, and T. Cimoli, “A survey of attacks on ethereum
smart contracts (sok),” in PST. Springer, 2017, pp. 164–186.
[10] “What is ethereum,” 2016. [Online]. Available: http://www.ethdocs.org/
en/latest/introduction/what-is-ethereum.html
[11] L. Hollander, “The ethereum virtual machine how does it work?” 2019.
[Online]. Avaliable: https://medium.com/mycrypto/the-ethereum-virtual-
machine-how-does-it-work-9abac2b7c9e.
[12] V. Buterin,
“Vyper,”
2017.
[Online]. Available:
https://vyper.
readthedocs.io/en/latest/index.html
[13] K. Delmolino, M. Arnett, A. Kosba, A. Miller, and E. Shi, “A
programmer’s guide to ethereum and serpent,” 2015. [Online]. Available:
URL:https://mc2-umd.github.io/ethereumlab/docs/serpent tutorial.
[14] C. Chinchilla, “Solidity v0.5.6,” 2019. [Online]. Available: https://
solidity.readthedocs.io/en/v0.5.6/
code
[15] M. Grincalaitis,
“Don’t
contract without
understanding the 4 languages in 6 minutes ﬁrst,” 2018. [Online].
Avaliable:
https://medium.com/@merunasgrincalaitis/dont-code-
another-smart-contract-without-understanding-the-4-languages-in-10-
minutes-ﬁrst-1c2dea165fcf.
another
smart
[16] E. J. Schwartz, T. Avgerinos, and D. Brumley, “All you ever wanted to
know about dynamic taint analysis and forward symbolic execution (but
might have been afraid to ask),” in Proc. Sympos. Sec. Privacy.
IEEE,
2010, pp. 317–331.
[17] Etherscan, “Veriﬁed smart contracts,” 2018. [Online]. Available: https://
etherscan.io/contractsVeriﬁed
[18] Ethereum,
“Solidity
line].
after=untagged-3024eaee36d028412763
Available:
version
[On-
https://github.com/ethereum/solidity/releases?
0.4.0,”
2016.
[19] ConsenSys, “Ethereum smart contract best practices,” 2019. [Online].
https://consensys.github.io/smart-contract-best-practices/
Available:
security tools/
[20] ——,
“Mythril
line]. Available:
Mythril-Detection-Capabilities
detection
[On-
https://github.com/ConsenSys/mythril-classic/wiki/
capabilities,”
2018.
[21] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vander-
plas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-
esnay, “Scikit-learn: Machine learning in Python,” Journal of Machine
Learning Research, vol. 12, pp. 2825–2830, 2011.
[22] M.
B.
Fraj,
“In
2018.
in-depth-parameter-tuning-for-svc-758215394769
[Online].
depth:
Available:
Parameter
svc,”
https://medium.com/all-things-ai/
tuning
for
[23] A. L. Maas, A. Y. Hannun, and A. Y. Ng, “Rectiﬁer nonlinearities
improve neural network acoustic models,” in Proc. ICML, vol. 30, no. 1,
2013, p. 3.
[24] M. B. Fraj, “In depth: Parameter tuning for decision tree,” 2017. [On-
line]. Avaliable: https://medium.com/@mohtedibf/indepth-parameter-
tuning-for-decision-tree-6753118a03c3.
[25] ——,
“In
2017.
depth:
Parameter
[Online]. Available:
tuning
for-
https://medium.com/all-things-ai/
random
for
est,”
in-depth-parameter-tuning-for-random-forest-d67bb7e920d
[26] D. M. Powers, “Evaluation: from precision, recall and f-measure to roc,
informedness, markedness and correlation,” 2011.