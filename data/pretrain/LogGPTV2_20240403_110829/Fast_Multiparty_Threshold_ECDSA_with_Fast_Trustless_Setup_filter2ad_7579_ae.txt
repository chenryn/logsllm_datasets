Before moving to the simulation of Phase 5, let’s look at the MtAwc protocol for the computation
of the shares σi.
We note that since F0 knows the decryption key for E1 he also knows all the shares µ1j from
the invocation of the MtAwc protocol between P1 and Pj on input k1 and wj respectively7.
For the MtAwc protocol between P1 and Pj on input w1 and kj respectively, F0 knows the
value kj input by Pj since he has extracted the secret key of Ej. However F0 does not know w1
therefore he sends a random µj1 to Pj and sets (implicitly) νj1 = kjw1 − αj1.
At the end we have that the share σ1 held by P1 is
σ1 = k1w1 +
νj1
µ1j +
(cid:88)
(cid:88)
µ1j −(cid:88)
(cid:88)
j>1
j>1
j>1
j>1
by rearranging the terms and substituting the above we get
σ1 = ˜kw1 +
µj1
where ˜k = (cid:80)
R = gk−1
.
Since w1 = b − wA we have
i ki. Remember that since this is not a semi-correct execution then ˜k (cid:54)= k where
where
µ1 =
(cid:88)
σ1 = ˜kb + µ1
µ1j −(cid:88)
µj1 − ˜kwA
with µ1, ˜k known to F0.
Note that this allows F0 to compute the correct value
j>1
j>1
gσ1 = ˜B
˜kgµ1
and therefore the correct value of Rs1 as
Rs1 = Rk1m+rσ1 = gk−1(k1m+rσ1) = gk−1(k1m+rµ1) ˜Bk−1 ˜kr
or
Rs1 = g ˆµ1 ˜B
ˆβ1
where ˆµ1 = k−1(k1m + rµ1) and ˆβ1 = k−1˜kr and ˆµ1 and ˆβ1 are known to F0.
We now continue the simulation
– 5A/5B F0 selects a random (cid:96)1 and sets V1 = Rs1 g(cid:96)1 A1 = gρ1 = ˜A = ga It simulates the
ZK proof (since it does not know ρ1 or s1). It extracts si, (cid:96)i, ρi from the adversary such that
Vi = Rsig(cid:96)i = gk−1sig(cid:96)i and Ai = gρi. Let sA =(cid:80)
i>1 k−1si
7 In this case we do not need to extract anything from Pj’s ZK proof, but we still need to check that the
value sent by Pj is correct.
18
Rosario Gennaro and Steven Goldfeder
Note that
(cid:89)
and therefore substituting the above relations (and setting (cid:96) =(cid:80)
V = g−my−r(cid:89)
Vi = g−my−rV1
i
Vi
i>1
i (cid:96)i )
Note that y = ˜B so y−r = ˜B−r. Therefore
V = g(cid:96)Rs1gsA−my−r
V = g(cid:96)g ˆµ1 ˜B
ˆβ1 gsA−m ˜B−r
or
V = g(cid:96)gθ ˜Bκ
where θ = ˆµ1 + sA − m and κ = ˆβ1 − r known to F0.
Note that for executions that are not semi-correct κ (cid:54)= 0
– 5C/5D F0 computes T1 = A(cid:96)1 correctly (which he can do since he knows (cid:96)1) but for U1 outputs
U1 = ˜A(cid:96)+θ ˜C κ and it aborts.
Note what happens when ˜C = gab. By our choice of a = ρ1 and b = x we have that U1 = V ρ1 as
in Game G0. However when ˜C is a random group element, U1 is uniformly distributed as in G1.
Therefore under the DDH assumption G0 and G1 are indistinguishable.
Indistinguishability of G1 and G2 We note that in G2 the simulator broadcasts a random ˜V1 = R˜s1g(cid:96)1
which is indistinguishable from the correct V1 = Rs1g(cid:96)1 because of the “mask” g(cid:96)1 which (under
the DDH) is computationally indistinguishable from a random value, given that the adversary only
has A1.
More in detail, let ˜A = ga−δ, ˜B = gb and ˜C = gab be the DDH challenge where δ = 0 or
random in Zq.
The simulator here proceeds as in G0 (i.e. the regular protocol) until Phase 5.
– 5A/5B F0 broadcasts V1 = Rs1 ˜A and A1 = ˜B. It simulates the ZK proof (since it does not
know (cid:96)1 or ρ1). It extracts si, (cid:96)i, ρi from the adversary such that Vi = Rsi g(cid:96)i = gk−1sig(cid:96)i and
Ai = gρi.
– 5C/5D F0 computes U1 as a random element and T1 = ˜C ˜A
Note what happens when ˜A = ga. By our choice, a = (cid:96)1 and b = ρ1 and we have that
V1‘ = Rs1g(cid:96)1 and T1 = A(cid:96)1 as in Game G1. However when ˜A = gag−δ with a random δ, then this
is equivalent to have V1‘ = R˜s1g(cid:96)1 and T1 = A(cid:96)1 with a randomly distributed ˜s1 as in Game G2
ρj and it aborts.
(cid:80)
j>1
Therefore under the DDH assumption G1 and G2 are indistinguishable.
4.9 Finishing up the proof
Before we conclude the proof we note that our protocol detects the presence of a malicious adversary
by noticing that the signature does not verify. As pointed out by Lindell in [27] this strategy is
not immediately simulatable against a malicious adversary for the following reason. Consider what
happens in Phase 5: In the semi-correct simulation F rewinds the adversary to “hit” the correct
s. But if the adversary had decided to be malicious and terminate the protocol with an invalid
signature, then the protocol would not be simulatable. If F hits an invalid signature “on purpose”
(e.g. by not rewinding), then the simulation is distinguishable by a semi-honest adversary who
does hit the correct signature.
Luckily for a “game-based” deﬁnition of security, this is not an issue as discussed in [27]. Let
Q  q3.
– The Attacker submits a message m and three arbitrary numbers λ1, λ2, ˆρ1.
– The Challenger chooses ρ(cid:48) ∈R Zq and β1, β2 ∈R ZN . If λ1x(cid:48) + β1 and λ2ρ(cid:48) + β2 are less than N ,
the Attacker receives (r, s) a valid DSA signature on m and also α = ρk mod q where k ∈R Zq
and r = gk−1
Otherwise the game stops.
.
The Attacker wins if he forges a signature on a message for which the Challenger did not output
a signature. The assumption is that winning this game is infeasible.
We believe this assumption to be reasonable because it appears that the Attacker receives only
limited information about the values x, k.
Note that we can’t simulate Alice’s view in this case, but we are arguing that the information
leaked is minimal and does not aﬀect security in a game-based deﬁnition of unforgeability.
Information Leaked to Bob by removing the ZK Consistency Proof. Here instead we
are able to simulate Bob’s view under a stronger assumption on the Paillier cryptosystem.
If Bob is corrupted, then the simulated Alice sends the encryption of a random value cA = E(ˆa).
But then it must decide if to accept or reject at the end of step (2) (where the real Alice checks
that gα = BaB(cid:48)) without knowing ˆa. Here we assume that the simulator is provided with an oracle
ΩcA (cB, b, β) which answers 1 if and only if Dec(cB) = b · Dec(cA) + β mod q. Then the simulator
will extract b, β from the malicious Bob’s proof of knowledge, and query ΩcA(cB, b, β) and accepts
if the oracle answers 1.
Security cannot be based on the semantic security of the Paillier’s encryption scheme anymore
since the presence of the oracle immediately implies that Paillier is not semantically secure anymore.
However consider the following experiment:
– Generate a Paillier key (E, D)
– Generate two random values a0, a1 ∈R Zq and publish A = ga0
– Choose a random bit b and publish c = E(ab)
– Let b(cid:48) be the output of the adversary who is allowed restricted access to the oracle Ωc – by
restricted we mean that the oracle will stop working after it outputs 0.
We say that the Paillier-ECR assumption holds if for every PPT adversary, the probability that
b = b(cid:48) is negligible. Under the Paillier-ECR assumption we can prove that no adversary given ga0
can distinguish if the MtA protocol was run with a0 or a1 (with both values being ”high entropy” in
particularly randomly chosen). This is suﬃcient to simulate MtA with high entropy inputs, which
is what is needed to prove security of our threshold DSA protocol.
We note that our Paillier-ECR assumption is a weaker version of the Paillier-EC assumption in
[27]. In the latter the oracle access is not restricted, which makes the assumption much stronger.
In our case it is suﬃcient to consider the restricted oracle since the real protocol stops if Alice
detects cheating.
Fast Multiparty Threshold ECDSA with Fast Trustless Setup
21
6 Extensions
Here we present the following natural extensions to our result.
6.1 Other additively homomorphic schemes.
Our scheme works with any additively homomorphic scheme with no modiﬁcation. It requires an
assumption analogous to the Paillier-EC or an eﬃcient ZK Proof for the statement in the MtAwc
protocol.