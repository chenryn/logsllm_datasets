title:CONIKS: Bringing Key Transparency to End Users
author:Marcela S. Melara and
Aaron Blankstein and
Joseph Bonneau and
Edward W. Felten and
Michael J. Freedman
CONIKS: Bringing Key Transparency to End Users
Marcela S. Melara and Aaron Blankstein, Princeton University; Joseph Bonneau,  
Stanford University and The Electronic Frontier Foundation; Edward W. Felten and  
Michael J. Freedman, Princeton University
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/melara
This paper is included in the Proceedings of the 
24th USENIX Security Symposium
August 12–14, 2015 • Washington, D.C.
ISBN  978-1-939133-11-3
Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXCONIKS: Bringing Key Transparency to End Users
Marcela S. Melara, Aaron Blankstein, Joseph Bonneau†, Edward W. Felten, Michael J. Freedman
Princeton University, †Stanford University/Electronic Frontier Foundation
Abstract
We present CONIKS, an end-user key veriﬁcation ser-
vice capable of integration in end-to-end encrypted com-
munication systems. CONIKS builds on transparency
log proposals for web server certiﬁcates but solves sev-
eral new challenges speciﬁc to key veriﬁcation for end
users. CONIKS obviates the need for global third-party
monitors and enables users to efﬁciently monitor their
own key bindings for consistency, downloading less than
20 kB per day to do so even for a provider with billions
of users. CONIKS users and providers can collectively
audit providers for non-equivocation, and this requires
downloading a constant 2.5 kB per provider per day. Ad-
ditionally, CONIKS preserves the level of privacy offered
by today’s major communication services, hiding the list
of usernames present and even allowing providers to con-
ceal the total number of users in the system.
1
Introduction
Billions of users now depend on online services for sensi-
tive communication. While much of this trafﬁc is trans-
mitted encrypted via SSL/TLS, the vast majority is not
end-to-end encrypted meaning service providers still have
access to the plaintext in transit or storage. Not only are
users exposed to the well-documented insecurity of cer-
tiﬁcate authorities managing TLS certiﬁcates [10, 11, 64],
they also face data collection by communication provid-
ers for improved personalization and advertising [25] and
government surveillance or censorship [24, 57].
Spurred by these security threats and users’ desire for
stronger security [43], several large services including
Apple iMessage and WhatsApp have recently deployed
end-to-end encryption [19, 62]. However, while these
services have limited users’ exposure to TLS failures and
demonstrated that end-to-end encryption can be deployed
with an excellent user experience, they still rely on a
centralized directory of public keys maintained by the
service provider. These key servers remain vulnerable
to technical compromise [17, 48], and legal or extralegal
pressure for access by surveillance agencies or others.
Despite its critical importance, secure key veriﬁcation
for end users remains an unsolved problem. Over two
decades of experience with PGP email encryption [12,
55, 70] suggests that manual key veriﬁcation is error-
prone and irritating [22, 69]. The EFF’s recent Secure
Messaging Scorecard reported that none of 40 secure
messaging apps which were evaluated have a practical
and secure system for contact veriﬁcation [50]. Similar
conclusions were reached by a recent academic survey on
key veriﬁcation mechanisms [66].
To address this essential problem, we present CONIKS,
a deployable and privacy-preserving system for end-user
key veriﬁcation.
Key directories with consistency. We retain the basic
model of service providers issuing authoritative name-
to-key bindings within their namespaces, but ensure that
users can automatically verify consistency of their bind-
ings. That is, given an authenticated binding issued by
foo.com from the name PI:EMAIL to one or more
public keys, anybody can verify that this is the same bind-
ing for PI:EMAIL that every other party observed.
Ensuring a stronger correctness property of bindings is
impractical to automate as it would require users to verify
that keys bound to the name PI:EMAIL are genuinely
controlled by an individual named Alice. Instead, with
CONIKS, Bob can conﬁdently use an authenticated bind-
ing for the name PI:EMAIL because he knows Alice’s
software will monitor this binding and detect if it does
not represent the key (or keys) Alice actually controls.
These bindings function somewhat like certiﬁcates in
that users can present them to other users to set up a secure
communication channel. However, unlike certiﬁcates,
which present only an authoritative signature as a proof of
validity, CONIKS bindings contain a cryptographic proof
of consistency. To enable consistency checking, CONIKS
servers periodically sign and publish an authenticated
data structure encapsulating all bindings issued within
their namespace, which all clients automatically verify is
consistent with their expectations. If a CONIKS server
ever tries to equivocate by issuing multiple bindings for
a single username, this would require publishing distinct
data structures which would provide irrefutable proof of
the server’s equivocation. CONIKS clients will detect the
equivocation promptly with high probability.
Transparency solutions for web PKI. Several proposals
seek to make the complete set of valid PKIX (SSL/TLS)
certiﬁcates visible by use of public authenticated data
USENIX Association  
1
24th USENIX Security Symposium  383
structures often called transparency logs [4, 34, 38, 39,
53, 60]. The security model is similar to CONIKS in that
publication does not ensure a certiﬁcate is correct, but
users can accept it knowing the valid domain owner will
promptly detect any certiﬁcate issued maliciously.
Follow-up proposals have incorporated more advanced
features such as revocation [4, 34, 38, 60] and ﬁner-
grained limitations on certiﬁcate issuance [4, 34], but all
have made several basic assumptions which make sense
for web PKI but not for end-user key veriﬁcation. Specif-
ically, all of these systems make the set of names and
keys/certiﬁcates completely public and rely to varying
degrees on third-party monitors interested in ensuring the
security of web PKI on the whole. End-user key veriﬁ-
cation has stricter requirements: there are hundreds of
thousands of email providers and communication appli-
cations, most of which are too small to be monitored by
independent parties and many of which would like to keep
their users’ names and public keys private.
CONIKS solves these two problems:
1. Efﬁcient monitoring. All previous schemes in-
clude third-party monitors since monitoring the certiﬁ-
cates/bindings issued for a single domain or user requires
tracking the entire log. Webmasters might be willing to
pay for this service or have their certiﬁcate authority pro-
vide it as an add-on beneﬁt. For individual users, it is
not clear who might provide this service free of charge or
how users would choose such a monitoring service, which
must be independent of their service provider itself.
CONIKS obviates this problem by using an efﬁcient
data structure, a Merkle preﬁx tree, which allows a single
small proof (logarithmic in the total number of users) to
guarantee the consistency of a user’s entry in the direc-
tory. This allows users to monitor only their own entry
without needing to rely on third parties to perform expen-
sive monitoring of the entire tree. A user’s device can
automatically monitor the user’s key binding and alert the
user if unexpected keys are ever bound to their username.
2. Privacy-preserving key directories. In prior sys-
tems, third-party monitors must view the entire system
log, which reveals the set of users who have been is-
sued keys [34, 39, 53, 60]. CONIKS, on the contrary, is
privacy-preserving. CONIKS clients may only query for
individual usernames (which can be rate-limited and/or
authenticated) and the response for any individual queries
leaks no information about which other users exist or
what key data is mapped to their username. CONIKS also
naturally supports obfuscating the number of users and
updates in a given directory.
CONIKS in Practice. We have built a prototype CON-
IKS system, which includes both the application-agnostic
CONIKS server and an example CONIKS Chat appli-
cation integrated into the OTR plug-in [8, 26, 65] for
Pidgin [1]. Our CONIKS clients automatically monitor
their directory entry by regularly downloading consis-
tency proofs from the CONIKS server in the background,
avoiding any explicit user action except in the case of
notiﬁcations that a new key binding has been issued.
In addition to the strong security and privacy features,
CONIKS is also efﬁcient in terms of bandwidth, compu-
tation, and storage for clients and servers. Clients need to
download about 17.6 kB per day from the CONIKS server
and verifying key bindings can be done in milliseconds.
Our prototype server implementation is able to easily sup-
port 10 million users (with 1% changing keys per day) on
a commodity machine.
2 System Model and Design Goals
The goal of CONIKS is to provide a key veriﬁcation sys-
tem that facilitates practical, seamless, and secure com-
munication for virtually all of today’s users.
2.1 Participants and Assumptions
CONIKS’s security model includes four main types of
principals: identity providers, clients (speciﬁcally client
software), auditors and users.
Identity Providers.
Identity providers run CONIKS
servers and manage disjoint namespaces, each of which
has its own set of name-to-key bindings.1 We assume
a separate PKI exists for distributing providers’ public
keys, which they use to sign authenticated bindings and
to transform users’ names for privacy purposes.
While we assume that CONIKS providers may be mali-
cious, we assume they have a reputation to protect and do
not wish to attack their users in a public manner. Because
CONIKS primarily provides transparency and enables
reactive security in case of provider attacks, CONIKS
cannot deter a service provider which is willing to attack
its users openly (although it will expose the attacks).
Clients. Users run CONIKS client software on one or
more trusted devices; CONIKS does not address the prob-
lem of compromised client endpoints. Clients monitor
the consistency of their user’s own bindings. To support
monitoring, we assume that at least one of a user’s clients
has access to a reasonably accurate clock as well as access
to secure local storage in which the client can save the
results of prior checks.
We also assume clients have network access which can-
not be reliably blocked by their communication provider.
This is necessary for whistleblowing if a client detects
1Existing communication service providers can act as identity pro-
viders, although CONIKS also enables dedicated “stand-alone” identity
providers to become part of the system.
384  24th USENIX Security Symposium 
2
USENIX Association
misbehavior by an identity provider (more details in §4.2).
CONIKS cannot ensure security if clients have no means
of communication that is not under their communication
provider’s control.2
Auditors. To verify that identity providers are not equiv-
ocating, auditors track the chain of signed “snapshots” of
the key directory. Auditors publish and gossip with other
auditors to ensure global consistency. Indeed, CONIKS
clients all serve as auditors for their own identity provider
and providers audit each other. Third-party auditors are
also able to participate if they desire.
Users. An important design strategy is to provide good
baseline security which is accessible to nearly all users,
necessarily requiring some security tradeoffs, with the op-
portunity for upgraded security for advanced users within
the same system to avoid fragmenting the communication
network. While there are many gradations possible, we
draw a recurring distinction between default users and
strict users to illustrate the differing security properties
and usability challenges of the system.
We discuss the security tradeoffs between these two
user security policies in §4.3.
2.2 Design Goals
The design goals of CONIKS are divided into security,
privacy and deployability goals.
Security goals.
G1: Non-equivocation. An identity provider may at-
tempt to equivocate by presenting diverging views of the
name-to-key bindings in its namespace to different users.
Because CONIKS providers issue signed, chained “snap-
shots” of each version of the key directory, any equivoca-
tion to two distinct parties must be maintained forever or
else it will be detected by auditors who can then broad-
cast non-repudiable cryptographic evidence, ensuring that
equivocation will be detected with high probability (see
Appendix B for a detailed analysis).
G2: No spurious keys. If an identity provider inserts a
malicious key binding for a given user, her client software
will rapidly detect this and alert the user. For default
users, this will not produce non-repudiable evidence as
key changes are not necessarily cryptographically signed
with a key controlled by the user. However, the user will
still see evidence of the attack and can report it publicly.
For strict users, all key changes must be signed by the
user’s previous key and therefore malicious bindings will
not be accepted by other users.
2Even given a communication provider who also controls all network
access, it may be possible for users to whistleblow manually by reading
information from their device and using a channel such as physical mail
or sneakernet, but we will not model this in detail.
Privacy goals.
G3: Privacy-preserving consistency proofs. CONIKS
servers do not need to make any information about their
bindings public in order to allow consistency veriﬁcation.
Speciﬁcally, an adversary who has obtained an arbitrary
number of consistency proofs at a given time, even for
adversarially chosen usernames, cannot learn any infor-
mation about which other users exist in the namespace or
what data is bound to their usernames.
G4: Concealed number of users.
Identity providers
may not wish to reveal their exact number of users. CON-
IKS allows providers to insert an arbitrary number of
dummy entries into their key directory which are indis-
tinguishable from real users (assuming goal G3 is met),
exposing only an upper bound on the number of users.
Deployability goals.
G5: Strong security with human-readable names.
With CONIKS, users of the system only need to learn
their contacts’ usernames in order to communicate with
end-to-end encryption. They need not explicitly reason
about keys. This enables seamless integration in end-to-
end encrypted communication systems and requires no
effort from users in normal operation.
G6: Efﬁciency. Computational and communication over-
head should be minimized so that CONIKS is feasible to
implement for identity providers using commodity servers
and for clients on mobile devices. All overhead should
scale at most logarithmically in the number of total users.
3 Core Data Structure Design
At a high level, CONIKS identity providers manage a
directory of veriﬁable bindings of usernames to public