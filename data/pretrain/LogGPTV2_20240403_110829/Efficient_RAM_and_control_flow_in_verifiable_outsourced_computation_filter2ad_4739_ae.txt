Benchmarks. Figure 8 lists our benchmarks. We implemented
each for native execution, Pantry, BCTV, and Buffet.
Native benchmarks are written in C or C++, compiled with
Intel’s C++ compiler v14 with maximum optimizations (-O3).
9This optimization interferes with self-modifying code if the program generates
instructions that do not otherwise appear in the program text.
11
The Pantry benchmarks are written in Pantry-C. The straight
line code is identical to the native benchmarks. For memory
benchmarks, the size of verifiable RAM is the minimum re-
quired for each computation, based on the input size.
The BCTV benchmark implementations are written for a
simulated CPU comprising 32 registers of 32 bits. Each bench-
mark is written in heavily optimized, hand coded assembly. In
producing the constraint set for each benchmark, we parameter-
ize based on the exact values required for t, |x|, and |xΨ| (§2.3);
our hand optimizations mean that t and |xΨ| are small.
The Buffet benchmark implementations are written in the
Buffet subset of C. For the straight line benchmarks we use the
native benchmark code, as in Pantry. For the RAM and data
dependent benchmarks, Buffet uses the code from the native
implementations, except that in the data dependent benchmarks,
we inserted the buffet::fsm attribute (§4.1, §5.1).
5.3 Setup
Configuration. We standardize the back-end protocol to be
Pinocchio [62], as described earlier (§2.1). We use the libsnark
implementation [3], which is optimized for speed, and includes
a minor protocol modification that improves V’s costs [19]. We
run in public verifier mode at 128-bit equivalent security [19].
Our testbed is a cluster of machines, each of which runs
Linux on a 16-core Intel Xeon E5-2680 with 32 GB RAM; the
nodes are connected by a 56 Gb/s InfiniBand network.
Measurement procedure. For each system and benchmark,
we execute the computation ten times, averaging the result.
The Pantry and Buffet compilers report |C|, the number of con-
straints. The Pantry compiler also reports |C| for the simulated
CPU’s constraint set in each BCTV benchmark. V and P each
track resource costs with getrusage and PAPI [2].
Calibrating baselines. Our BCTV implementation (§5.2) re-
sults in slightly larger values of |C| than are reported in [19,
§5.1] for the same execution lengths. We have carefully an-
alyzed this discrepancy. It results, first, from the fact that
our implementation and the original apply different optimiza-
tions (§5.2). Second, we experiment with a simulated CPU that
has 32 registers of 32 bits each; by contrast, the relevant results
in [19] are for a CPU with 16 such registers. We use the “more
powerful” CPU because it tends to reduce t and hence BCTV’s
costs. These choices can increase ccpu by 15% in the worst
case (note from Figure 5 that reducing t and increasing ccpu are
opposing effects). At the very worst, then, we are overstating
BCTV’s costs by 15%—but this difference is swamped by the
multiple orders of magnitude that separate BCTV and Buffet.
For the data dependent benchmarks (Fig. 8), we measure Buf-
fet not against Pantry but against a related system, BuffetStatic;
BuffetStatic requires static loop bounds, like Pantry, but uses
Buffet’s memory abstraction. The purpose of BuffetStatic is to
isolate the effects of Section 4, versus Pantry.
5.4 Method and results
We wish to do an apples-to-apples comparison of the three
systems: an examination of their running times on the same
benchmark
system
size
Matrix mult.
BCTV
Pantry
native: 4610 µs Buffet
PAM
BCTV
Pantry
native: 2140 µs Buffet
Fannkuch
BCTV
Pantry
native: 96.1 µs Buffet
Pointer chase
Pantry
BCTV
native: 40.2 µs Buffet
Merge sort
Pantry
BCTV
native: 25.3 µs Buffet
Boyer-Moore
Pantry
BCTV
native: 7.64 µs Buffet
K-M-P search BCTV
6.67
m=7
9.94
m=215
9.94
m=215
†
10.2
‡
10
‡
10
9.9
m=7, l=20
10
m=13, l=850
10
m=13, l=850
2.41
m=32
9.98
m=1664
7.54
m=16384
2.44
m=8
5.37
m=32
7.9
m=512
3.13
m=16, k=32
10.1
m=32, k=448
m=512, k=16128 7.55
9.71
m=16, k=160
7.77
BuffetStatic m=36, k=432
8.56
Buffet
8.75
BuffetStatic m=128
10
m=432
BCTV
native: 2.35 µs Buffet
8.37
m=5450
10.1
Sparse mat–vec BuffetStatic m=125, k=250
10.5
m=150, k=300
m=1150, k=2300 8.03
‡: m=20, d=128, k=2, l=30
|C| (millions) V setup
21.0 min
29.3 min
29.3 min
30.7 min
29.2 min
29.2 min
30.5 min
30.5 min
30.5 min
10.5 min
31.2 min
21.7 min
10.8 min
16.8 min
22.2 min
13.8 min
31.0 min
21.7 min
30.2 min
22.2 min
24.7 min
24.8 min
31.0 min
23.3 min
28.0 min
32.8 min
23.0 min
native: 7.7 µs
RLE decode
m=256, k=2900
BCTV
native: 4.19 µs Buffet
†: m=4, d=4, k=2, l=5
P exec
8.8 min
17.0 min
17.0 min
12.6 min
13.8 min
13.8 min
12.1 min
13.7 min
13.7 min
3.5 min
12.2 min
9.4 min
3.5 min
6.8 min
9.2 min
4.3 min
12.4 min
9.3 min
11.9 min
9.1 min
10.3 min
10.3 min
12.3 min
9.7 min
12.2 min
14.2 min
9.5 min
FIGURE 9—Scaling limits of BCTV, Pantry, and Buffet: the problem
sizes (in terms of input size and resulting number of constraints, |C|)
for each benchmark that each system is able to handle. V’s setup time
and P’s execution time (depicted) depend largely on C (§2.4). V’s
verification time is not depicted because it is nearly the same for all
systems, independent of |C| (Figure 3), and not the principal protocol
cost (§1, §2). Native execution times correspond to the largest input
size. The first three benchmarks are straight line computations; the
middle three are RAM benchmarks; the final three use data dependent
control flow. Computations are limited (by available testbed RAM)
to about ten million constraints or less. This corresponds to different
computation sizes per system because of the different efficiency with
which each system represents the execution of Ψ in constraints.
computations, on the same input sizes. However, the maximum
input size for which each system is able to execute a given
benchmark differs. Thus, our method is as follows. First, we
obtain measurements of each system by running it on the maxi-
mum input size that it can handle, in our testbed. These mea-
surements both give us ground truth and indicate the qualitative
performance of the systems. Second, we use these measure-
ments to extrapolate the performance of the baseline systems to
the input size at which Buffet executes the benchmark. Third,
we perform a three-way comparison of the systems, using this
extrapolated performance.
Ground truth and extrapolation
Figure 9 details our measurements. The results demonstrate,
first, that all computations are limited to about ten million con-
straints or less in all of the systems (using our experimental
12
configuration). The limiting factor is testbed memory. Specifi-
cally, V’s setup and P’s “argue” step (§2.1, step 3) use multi-
exponentiation, and P also does polynomial arithmetic based
on the fast Fourier transform; these operations require mem-
ory proportional to |C| [19, 32, 40, 62, 70]. Second, for each
system, this constraint budget corresponds to very different
computation sizes. The reason is that the systems vary widely
in their efficiency at representing computations in constraints.
To extrapolate to larger input sizes, we do the following
for BCTV: (1) compute the per-cycle cost, |Cmeasured|/tmeasured;
(2) determine the number of cycles needed to execute the larger
computation; and (3) account for the logarithmic increase in
the per-cycle cost due to the growth of the permutation network.
This yields the per-cycle constraint cost at the larger compu-
tation size and thus |Cextrapolated|. We also check the measured
and computed per-cycle constraint costs against the published
BCTV figures [19, §5.1] to ensure that our model and imple-
mentation accurately represent BCTV’s performance. We apply
analogous procedures for the other baseline systems. Further-
more, we verify our extrapolation model for each baseline with
a series of measurements at different computation sizes.
Three-way comparison
We report P’s execution time normalized to Buffet, as this
quantity captures the front-end efficiency of each system; the
reason is that V’s setup costs are roughly proportional to P’s
execution time (≈ 3×, per Figs. 3 and 9), and both end-to-end
figures are driven by |C|. Figure 10 summarizes the results.
Pantry and BCTV. In comparing Pantry and BCTV, we con-
sider the straight line and RAM benchmarks of Figure 8. Be-
cause Pantry turns arithmetic operations into at most tens of
constraints (§2.2), we expect excellent performance on straight
line computations; conversely, we expect these computations
to be inefficient under BCTV because every operation pays
ccpu (§3.1, Fig. 5) to represent the logic of a CPU cycle (§2.3,
Fig. 2). For computations involving random memory access,
however, BCTV should outperform Pantry because of the lat-
ter’s expensive hashing (§2.2).
The predicted performance is evident in Figure 10: on
straight line computations, Pantry outperforms BCTV by 2–
4 orders of magnitude, while BCTV is consistently 1–2 orders
of magnitude more efficient for random memory access.
RAM performance in Buffet. As summarized in Figure 5,
we expect Buffet to retain Pantry’s performance on straight