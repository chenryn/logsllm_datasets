              cgh.parallel_for(n_items,
                  [=](cl::sycl::id wiID) {
                      out_accessor[wiID] = in_accessor[wiID]*2;
                  });
         });
     }
}
```
我会把它划分为一个个片段。
```
#include 
```
我们做的第一件事就是包含 SYCL 头文件，它会在我们的命令中添加 SYCL 运行时库。
```
const size_t array_size = 1024*512;
std::array in,out;
std::iota(begin(in),end(in),0);
```
这里我们构造了一个很大的整型数组并用数字 `0` 到 `array_size-1` 初始化（这就是 `std::iota` 所做的）。注意我们使用 `cl::sycl::cl_int` 确保兼容性。
```
{
    //...
}
```
接着我们打开一个新的作用域，其目的为二：
1. `device_queue` 将在该作用域结束时解构，它将阻塞，直到内核完成。
2. `in_buffer` 和 `out_buffer` 也将解构，这将强制数据传输回主机并允许我们从 `in` 和 `out` 中访问数据。 `cl::sycl::queue device_queue;`
现在我们创建我们的命令队列。命令队列是所有工作（内核）在分发到设备之前需要入队的地方。有很多方法可以定制队列，例如说提供设备用于入队或者设置异步错误处理器，但对于这个例子默认构造器就可以了；它会查找兼容的 GPU，如果失败的话会回退到主机 CPU。
```
cl::sycl::range n_items{array_size};
```
接下来我们创建一个范围，它描述了内核在上面执行的数据的形状。在我们简单的例子中，它是一个一维数组，因此我们使用 `cl::sycl::range`。如果数据是二维的，我们就会使用 `cl::sycl::range`，以此类推。除了 `cl::sycl::range`，还有 `cl::sycl::ndrange`，它允许你指定工作组大小以及越界范围，但在我们的例子中我们不需要使用它。
```
cl::sycl::buffer in_buffer(in.data(), n_items);
cl::sycl::buffer out_buffer(out.data(), n_items);
```
为了控制主机和设备之间的数据共享和传输，SYCL 提供了一个 `buffer` 类。我们创建了两个 SYCL 缓存用于管理我们的输入和输出数组。
```
      device_queue.submit([&](cl::sycl::handler &cgh) {/*...*/});
```
设置好了我们所有数据之后，我们就可以入队真正的工作。有多种方法可以做到，但设置并行执行的一个简单方法是在我们的队列中调用 `.submit` 函数。对于这个函数我们传递了一个运行时调度该任务时会被执行的“命令组伪函数”（伪函数是规范，不是我创造的）。命令组处理器设置任何内核需要的余下资源并分发它。
```
constexpr auto sycl_read = cl::sycl::access::mode::read_write;
constexpr auto sycl_write = cl::sycl::access::mode::write;
auto in_accessor = in_buffer.get_access(cgh);
auto out_accessor = out_buffer.get_access(cgh);
```
为了控制到我们缓存的访问并告诉该运行时环境我们会如何使用数据，我们需要创建访问器。很显然，我们创建了一个访问器用于从 `in_buffer` 读入，一个访问器用于写到 `out_buffer`。
```
cgh.parallel_for(n_items,
    [=](cl::sycl::id wiID) {
         out_accessor[wiID] = in_accessor[wiID]*2;
    });
```
现在我们已经完成了所有设置，我们可以真正的在我们的设备上做一些计算了。这里我们根据范围 `n_items` 在命令组处理器 `cgh` 之上分发一个内核。实际内核自身是一个使用 work-item 标识符作为输入、输出我们计算结果的 lamda 表达式。在这种情况下，我们从 `in_accessor` 使用 work-item 标识符作为索引读入，将其乘以 `2`，然后将结果保存到 `out_accessor` 相应的位置。`` 是一个为了在标准 C++ 范围内工作的不幸的副产品，因此我们需要给内核一个唯一的类名以便编译器能完成它的工作。
```
}
```
在此之后，我们现在可以访问 `out` 并期望看到正确的结果。
这里有相当多的新概念在起作用，但使用这些技术你可以看到这些能力和所展现出来的东西。当然，如果你只是想在你的 GPU 上执行一些代码而不关心定制化，那么你就可以使用 SYCL 并行 STL 实现。
### SYCL 并行 STL
SYCL 并行 STL 是一个 TS 的并行化实现，它分发你的算法函数对象作为 SYCL 内核。在这个页面前面我们已经看过这样的例子，让我们来快速过一遍。
```
#include 
#include 
#include 
#include 
#include 
using namespace std::experimental::parallel;
using namespace sycl::helpers;
int main() {
  constexpr size_t array_size = 1024*512;
  std::array in,out;
  std::iota(begin(in),end(in),0);
  {
    cl::sycl::buffer in_buffer(in.data(), cl::sycl::range(in.size()));
    cl::sycl::buffer out_buffer(out.data(), cl::sycl::range(out.size()));
    cl::sycl::queue q;
    sycl::sycl_execution_policy sycl_policy(q);
    transform(sycl_policy, begin(in_buffer), end(in_buffer), begin(out_buffer),
              [](int x) { return x*2; });
  }
}
```
```
  constexpr size_t array_size = 1024*512;
  std::array in, out;
  std::iota(begin(in),end(in),0);
```
到现在为止一切如此相似。我们再一次创建一组数组用于保存我们的输入输出数据。
```
cl::sycl::buffer in_buffer(in.data(), cl::sycl::range(in.size()));
cl::sycl::buffer out_buffer(out.data(), cl::sycl::range(out.size()));
cl::sycl::queue q;
```
这里我们创建类似上个例子的缓存和队列。
```
sycl::sycl_execution_policy sycl_policy(q);
```
这就是有趣的部分。我们从我们的队列中创建 `sycl_execution_policy`，给它一个名称让内核使用。这个执行策略然后可以像 `std::execution::par` 或 `std::execution::seq` 那样使用。
```
transform(sycl_policy, begin(in_buffer), end(in_buffer), begin(out_buffer),
          [](int x) { return x*2; });
```
现在我们的内核分发看起来像提供了一个执行策略的 `std::transform` 调用。我们传递的闭包会被编译并在设备上执行，而不需要我们做其它更加复杂的设置。
当然，除了 `transform` 你可以做更多。开发的时候，SYCL 并行 STL 支持以下算法：
* `sort`
* `transform`
* `for_each`
* `for_each_n`
* `count_if`
* `reduce`
* `inner_product`
* `transform_reduce`
这就是这篇短文需要介绍的东西。如果你想和 SYCL 的开发保持同步，那就要看 [sycl.tech](http://sycl.tech/)。最近重要的开发就是移植 [Eigen](https://github.com/ville-k/sycl_starter) 和 [Tensorflow](http://deep-beta.co.uk/setting-up-tensorflow-with-opencl-using-sycl/) 到 SYCL ，为 OpenCL 设备带来引入关注的人工智能编程。对我个人而言，我很高兴看到高级编程模型可以用于异构程序自动优化，以及它们是怎样支持类似 [HPX](https://github.com/STEllAR-GROUP/hpx) 或 [SkelCL](https://github.com/skelcl/skelcl) 等更高级的技术。
---
via: 
作者：[TartanLlama](https://www.twitter.com/TartanLlama) 译者：[ictlyh](https://github.com/ictlyh) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出