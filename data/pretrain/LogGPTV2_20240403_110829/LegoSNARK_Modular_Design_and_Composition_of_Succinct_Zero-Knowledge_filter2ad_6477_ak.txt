of a Merkle tree of height N with respect to a public root; the corresponding relation can be seen
as the parallel check of 2N − 1 hash veriﬁcation relations (i.e., RH (x1, x2, y) := H(x1, x2) ?= y) that
share some of the inputs. Another example is proving correctness of the output of a sequential
computation whose internal step is always the same (e.g., the square-and-multiply algorithm).
j) where each u(cid:48)
j=1 R(cid:48)(u(cid:48)
18 Using our CPlin for PolyCom would give us an instantiation with a universal CRS, but unfortunately one of size
Q · N, that is quadratic in circuit size.
38
(a) In Rpar, R(cid:48) inputs are disjoint
(b) In Rparjnt, R(cid:48) inputs are joint
Figure 8: Inputs structures for parallel relations.
One way to deal with Rparjnt is by deﬁning the arithmetic circuit that computes it (cf. Fig. 8b).
The Hyrax system is particularly designed for parallel circuits [WTs+18]; they deal with non-parallel
input by introducing a (non-parallel) redistribution layer (RDL) layer that redistributes the input
and feeds it to the identical sub-circuits at the next level. Unfortunately an eﬀect of using an RDL
is that the veriﬁer must pay an additional cost linear in the total width of the circuit. This makes
veriﬁcation time pretty high in applications like the Merkle tree example above.
Here we propose another natural modelling of relations with joint inputs, that is the simple
conjunction of two relations: Rpar that models fully parallel checks of some R(cid:48) on disjoint inputs,
and another relation that models the consistency of the shared inputs across the (fully) parallel
executions. The advantage of this encoding is that Rpar is now fully parallel and one could use for
it a system for parallel computation without any caveat, whereas to check the consistency of shared
input one can use a system for the Rveq relation from Deﬁnition 6.1. More formally, we deﬁne a
parallel relation on disjoint inputs as follows.
Deﬁnition 6.4 (Parallel relation on disjoint inputs). For a relation R(cid:48) over D(cid:48) and an integer
N ≥ 1, a parallel relation Rpar
j=1 R(cid:48)(uj), where
u := (uj)j∈[N ] ∈ (D(cid:48))N.
R(cid:48) on disjoint inputs is deﬁned as Rpar
R(cid:48) (u) := (cid:86)N
From Rpar and Rveq we deﬁne a relation for parallel checks on joint inputs.
Deﬁnition 6.5 (Parallel relation on joint inputs). Let n0, n1, n(cid:48), N ∈ N be integers such that
n(cid:48), N ≥ 1 and n0, n1 ≥ 0, and let m = n0 + n1 + N · n(cid:48). Let D be some domain, R(cid:48) be a relation
over D(cid:48) := Dn(cid:48), and S a set of the form S = {(i1, k1), . . . , (il, kl)} ⊂ [m] × [m]. Rparjnt
R(cid:48),S is a relation
over Dx × D1 × D2, with Dx := Dn0, D1 := Dn1 and D2 := DN n(cid:48), such that:
Rparjnt
R(cid:48),S (x, u1, u2) := Rpar
R(cid:48) (u2) ∧ Rveq
S (x, u1, u2)
Basically, Rparjnt
R(cid:48),S models the parallel checking of R(cid:48) on N diﬀerent subsets of the entries of (x, u1)
(consisting of a public x and committed u1) where such subsets are deﬁned by the set S, and their
concatenation is the vector u2. Alternatively, if x, u1 are empty, Rparjnt
R(cid:48),S models the parallel checking
of R(cid:48) on N diﬀerent sets of inputs with some shared values (as speciﬁed by S).
From the deﬁnition of Rparjnt and our Theorem 3.1 we obtain the following corollary.
Corollary 6.3. If there exist CP-SNARKs CPpar and CPveq for a commitment scheme Com rela-
tions Rpar and Rveq respectively, then there is a CP-SNARK CPparjnt for Com and relations Rparjnt.
Instantiations. Following the corollary above, we consider an instantiation of CPparjnt (that we
call LegoPar) obtained as follows. As CPveq we use our scheme CPPed
lin using the encoding of Rveq
with linear constraints. As CPpar we use an adaptation of Hyrax using the polynomial commitment
PolyCom of zk-vSQL. We call HyrPoly-Par this scheme invoked on circuits without RDL (i.e., it
supports Rpar), and HyrPoly-RDL the same scheme for circuits with an RDL (i.e., it supports Rparjnt).
39
We compare the eﬃciency of LegoPar and HyrPoly-RDL on Rparjnt relations. Let d and G be
depth and width of the arithmetic circuit evaluating R(cid:48). Proving time and proof size have the same
complexity in both solutions; veriﬁer time is O(d(G+log(N G))) in LegoPar and O(d(G+log(N G))+
|u| + N G) in HyrPoly-RDL. We note that due to the use of CPPed
lin , the CRS of LegoPar becomes
speciﬁc to the input wiring of Rparjnt, whereas in HyrPoly-RDL the CRS is just the commitment key.
On the other hand, this one-time preprocessing allows the veriﬁer to later check any number of proofs
in shorter time.19 In Section 7 we discuss an experimental comparison based on an implementation.
7 Experimental Evaluation
We provide an implementation for LegoSNARK20 that includes the following gadgets: our CPlink
lin , the Hadamard product CP-SNARK of [Lip16], and the CPpoly from [ZGK+17b]21. Lego-
and CPPed
SNARK is written in C++; for polynomial operations and bilinear pairings we use the libraries under-
lying libsnark [librk]. We executed our experiments on a virtual machine running Debian GNU/Linux
with 8 Xeon Gold 6154 cores and 30 GB of RAM. We ran all tests single threaded. In our experi-
ments, we tested the performance of some of our instantiations and compared to diﬀerent baseline
systems.
7.1 Commit-and-Prove SNARKs
We consider a generic application of proving commit-and-prove relations where commitments are
created using the Pedersen scheme for vectors, i.e., proving ∃(u, o, ω)R(u, ω)∧VerCommit(ck, c, u, o).
As baseline system, we use the Groth16 zkSNARK in libsnark on the libsnark gadget circuit for
multi-scalar additions over a SNARK-friendly elliptic curve (to model the Pedersen computation).
We call this CPGro16. We compare CPGro16 to a CP-SNARK, LegoGro16, obtained by applying
our cc-SNARK-lifting compiler with our CPlink scheme to the cc-variant of [Gro16], ccGro16, that
we present in Appendix H.5. We measured the overhead of dealing with the commitment in both
schemes (the R-dependent costs would be the same in both cases) at the increase of the committed
vector’s size (from 8 to 2048).22 On the largest instance (n = 2048) LegoGro16’s proving time is
5K× (0.08 vs. 428 s) faster than CPGro16, at the price of a veriﬁcation that is 1.2× slower (4.1
vs 3.4 ms), and a slightly larger proof (191 vs. 127 Bytes). LegoGro16’s CRS is also 7K× shorter
(130KB vs. 950MB).
In the case of LegoGro16, such overhead in proving time is essentially that of creating the
additional element D of the proof that contains a commitment to the data and to create a CPlink
proof to link D to the external commitment. The LegoGro16 proof is longer because of these two
additional elements of G1. And for veriﬁcation, the CPlink veriﬁcation must be executed. With
respect to the CRS, in LegoGro16 we have the additional elements of the CRS needed to create D
and the CPlink CRS, that is essentially one vector of n elements of G1. In CPGro16, all the overhead
in proving time and CRS is related to the size and degree of the QAP that models the computation
19 We do not see a way to run a similar preprocessing in HyrPoly. We evaluated the possibility to commit, in
preprocessing, to the MLE of the RDL wiring so that the prover would compute this on behalf of the veriﬁer
and prove its correct evaluation using CPpoly. This idea however would require a commitment key quadratic in the
circuit width, which is prohibitively large.
20 The GitHub repository for the code is https://github.com/imdea-software/legosnark .
21 For this we adapted to our library the code provided by the authors of [ZGK+17b].
22 At n = 4096 CPGro16 ran out of memory.
40
of the Pedersen commitment. This was done by selecting an appropriate gadget in libsnark, which
optimizes the task by selecting a suitable elliptic curve.
Table 3 shows our experimental results that compare the schemes LegoGro16 and CPGro16 with
respect to the overhead for dealing with data committed using a Pedersen vector commitment. The
experiments considered vectors of diﬀerent length n.
7.2 Matrix Multiplication
We evaluate our CPmmp scheme for matrix multiplication against a solution based on Groth16
[Gro16]. We remind the reader that in this version of matrix product relation the output matrix is
given in the clear as part of the statement to be proven (rather than being committed as in CPmm).
Our scheme has a faster prover and smaller crs using an asymptotically more eﬃcient veriﬁer with
a longer, but still succinct, proof. Our experiments conﬁrm the theoretical costs of these schemes.
We evaluate both proving and veriﬁcation time when delegating a square matrix multiplication
with size N = n × n ﬁeld elements, ranging from n = 16 to n = 256. We observe our scheme
noticeably improves on proving time as our prover runs in linear time in the number of elements
in the matrix (n2), whereas Groth’s runs in quasicubic time in n. Even if our veriﬁer is slower for
smaller matrices, the O(n2) work in our scheme involves only ﬁeld operations whereas in Groth16
one needs to do a O(n2)-wide multiexponentiation. On the largest instance we measured (square
matrices with n = 128 rows and columns), our proving time is roughly 1300× faster (109 seconds
vs. 84 milliseconds) and veriﬁcation time is 1.8× faster (51 vs. 28 milliseconds). This is a tradeoﬀ
between the running time and the proof length: only 3 group elements in Groth16 vs O(log n) in
our scheme (127 bytes vs. 32 kilobytes).
Table 4 shows concrete performance measurements of both schemes, showing a clear proving
time improvement in our scheme.
7.3 LegoAC1 for Arithmetic Circuits
We tested our LegoAC1 scheme (see Section 6.2) for arithmetic circuits and compared it to Groth16
as a baseline system. We considered two benchmark applications:
(a) proving knowledge of a SHA256 pre-image on 512-bit inputs; for this we used the existing circuit
gadgets implemented in libsnark (for Groth16), and in Bulletproofs [bulk1] (for LegoAC1).
(b) matrix factoring, i.e., proving knowledge of two n × n matrices A, B whose product is a public
matrix C; for this we designed suitable constraints systems, considering 32-bit integers entries and
a varying n = 16, 32, 64, 128.
Overall, our experiments show that LegoAC1 performs slightly worse than Groth16. For exam-
ple, for SHA256 proving time is 1.2× slower (0.7 vs. 0.9 s); veriﬁcation is up to 2× slower (0.9 vs.
1.8 ms) and improves with larger inputs; our key generation is about 5 − 6× slower. Proof size is
constant: 350B in LegoAC1 and 127B in Groth16. Noteworthy that most of LegoAC1 key generation
time (about 70%) is taken by the corresponding algorithm for CPPed
lin ; this is mainly due to an unop-
timized technique for dealing with sparse matrices like the ones that encode the linear constraints
W L, W R, W O, and we expect this to be improved in the future.
In a way this result is not surprising: Groth16 is an extremely optimized and well explored
scheme, whereas for LegoAC1 we believe that more optimizations could be explored (in a similar
way as Groth16 optimized Pinocchio). More remarkably, LegoAC1 has a built-in commit-and-prove
capability, which means its proofs are done with respect to matrices that committed in a Pedersen
41
Time
P
V
Space
crs
π
CPmmp
O(n2)
O(n2) O(n2) O(log n)
Groth16 O(n3 log n) O(n2) O(n3) O(1)
LegoGro16
P
(ms)
n KG
crs
(KB)
(ms)
8 3.677 3.044 0.51
16 5.949 4.202 1.02
32 10.90 5.201 2.04
64 19.37 8.979 4.08
128 32.49 15.58 8.16
256 57.76 19.50 16.32
512 117.8 30.84 32.64
1024 241.2 55.35 65.28
2048 466.6 84.09 130.6
CPGro16
crs
P
(s)
KG
(MB)
(s)
3.928 1.185 3.653
7.307 2.252 7.305
13.78 4.461 14.61
26.04 8.685 29.22
50.69 16.50 58.44
102.8 33.02 116.9
292.0 65.42 233.7
876.3 133.3 467.5
1011 428.7 935.0
|π| (B)
V (ms)
191.13
4.129
127.38
3.4
Table 3: Performance comparison of LegoGro16
and CPGro16. Numbers for the two schemes are
in diﬀerent units. Those for CPGro16 are three or-
ders of magnitude larger.
CPmmp
P
(ms)
n
16 35.36 22.74
32 46.26 23.19
64 55.78 24.00
128 83.78 28.03
256 149.7 40.01
|π|
V
(ms) KB
21
24
28
32
36
Groth16
V
(ms)
4.312
6.060
12.60
50.99
P
(s)
0.181
1.379
11.61
109.3
Table 4: Comparing CPmmp and Groth16 for
n × n matrices
LegoAC1
P
(s)
V
n KG
(ms)
(s)
16 1.105 0.278 3.097
32 7.569 1.680 4.697
64 52.86 11.90 10.73
128 419.8 89.70 35.71
Groth16
P
(s)