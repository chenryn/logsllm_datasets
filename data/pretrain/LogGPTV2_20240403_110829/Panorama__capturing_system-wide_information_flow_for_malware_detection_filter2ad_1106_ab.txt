are necessary in our problem setting:
(1) Our system is
OS-aware—in addition to hardware-level taint tracking, we
need to understand the high-level representations of hard-
ware states for the analysis; (2) We also need to identify
what actions are performed by or on behalf of the sample
under analysis, even if the sample performs code unpacking
and dynamic code generation, and executes actions through
libraries, etc.; (3) Our monitoring needs to be whole-system
and ﬁne-grained, in order to precisely detect all actions of
the sample.
The system-wide information behavior is captured by a
graph representation, which we call taint graph. Taint graphs
capture the taint propagation from the initial taint source
(i.e., the sensitive information introduced in the tests) through-
out the system. Using taint graphs, we can determine whether
the unknown sample has performed malicious actions.
In
general, the decision whether an information access and pro-
cessing behavior is considered malicious or benign is made
with the help of policies. One characteristic property of
many types of malicious code (such as keyloggers, spyware,
stealth backdoors, and rootkits) is that they steal, leak or
tamper with sensitive user information. Consider the fol-
lowing examples: (1) The user is typing input into an appli-
cation such as a Microsoft Notepad, or is entering his user
name and password into a web login form through a browser,
while an unknown sample also accesses these keystrokes; (2)
The user is visiting some websites, while an unknown sam-
ple accesses the web pages or URLs and sends them to a
remote host; (3) The user is browsing a directory or search-
ing a ﬁle, while an unknown sample intercepts the access to
the directory entries and tampers with one or more entries.
We devise a set of policies, which are used by the malware
detection engine to detect malware from unknown samples.
Finally, since taint graphs present invaluable insights about
the samples’ information access and processing behaviors,
analysts can use the malware analysis engine to examine
the taint graphs, for detailed analysis information. More
information on taint-graph-based analysis and detection is
provided in Section 4.
3. DESIGN AND IMPLEMENTATION
In this section, we describe the design and implementation
of Panorama. First, we describe the hardware-level taint
tracking in Section 3.1. Then we discuss the mechanisms
that can map hardware-level operations (such as instructions
executed on the processor) to the corresponding operating-
system objects (such as processes), in Section 3.2. Finally,
we describe our approach to performing automated testing
and generating taint graphs in Section 3.3.
3.1 Hardware-level Dynamic Taint Tracking
To perform whole-system, ﬁne-grained taint tracking, we
need to monitor how tainted data propagates throughout the
whole system including the OS and the applications. Since
the source code for commodity software such as the Windows
operating system and applications are usually not available,
we choose the approach of dynamic instrumentation—i.e.,
we monitor the whole system execution in a processor em-
ulator and dynamically instrument code to keep track of
how tainted data propagates during program execution. We
choose to implement Panorama on QEMU [29, 3], a generic
and open source processor emulator, because of its eﬃciency
(achieved through dynamic translation and caching ) when
compared to previous processor emulators such as Bochs [5].
Our hardware-level taint tracking is similar in spirit to a
number of previous systems [10, 26, 13, 35, 12]. However,
since our goal is to enable whole-system ﬁne-grained taint
analysis, our design and implementation is the most com-
plete. For example, previous approaches either operate on
a single process only [12, 26, 35], or they cannot deal with
memory swapping and disks [10, 13].
Shadow Memory.
We use a shadow memory to store the taint status of each
byte of the physical memory, CPU’s general-purpose regis-
ters1, the hard disk and the network interface buﬀer. Each
tainted byte is associated with a small data structure stor-
ing the original source of the taint and some other book
keeping information (which is necessary for generating taint
graphs). The shadow memory is organized in a page-table-
like structure to ensure eﬃcient memory usage. With the
shadow memory for the hard disks, the system can continue
to track the tainted data that has been swapped out. Obvi-
ously, this also enables the tracking of the tainted data that
has been saved to a ﬁle and is then read in.
Taint Sources.
All sensitive information that is introduced into the sys-
tem in the automated tests is marked as a taint source.
Panorama supports taint input from hardware, such as the
keyboard, network interface, and hard disk. Tainting a high-
level abstract data object (e.g. the output of a function call,
or a data structure in a speciﬁc application or the OS ker-
nel) would also be appropriate. Note that taint sources have
to be speciﬁed as close to the hardware (i.e., low-level) as
possible. For example, tainting the input typed at the key-
board level is better than tainting the input in a browser
form. Otherwise, malware may try to evade detection by
creating hooks that are invoked before the input arrives at
the browser.
Taint Propagation.
After a data source is tainted, we need to monitor each
CPU instruction and DMA operation that manipulates this
data in order to determine how the taint propagates. For
data movement instructions and DMA operations, the des-
tination will be tainted if and only if the source is tainted.
For arithmetic instructions, the result will be tainted if and
only if any byte of the operands is tainted. We also handle
the following special situations.
Constant function: some instructions or instruction se-
quences always produce the same results, independent of the
values of their operands. A good example is the instruction
“xor eax, eax” that commonly appears in IA-32 programs
as a compiler idiom. After executing this instruction, the
value of eax is always zero, regardless of its original value.
1For the sake of simplicity,
in the current implementa-
tion, ﬂags, debug registers, control registers and SIMD (e.g.
MMX and SSE) registers are not considered. However,
adding the necessary tracking for these registers would be
straightforward.
We recognize a number of such special cases and untaint the
result.
Table lookup: a tainted input may be used as an in-
dex to access an entry of a table. The taint propagation
policy above will not propagate taint to the destination, be-
cause the value that is actually read is untainted. Unfortu-
nately, such table lookup operations appear frequently, such
as for Unicode/ASCII conversion in Windows. Thus, we
augmented our propagation policy with the following rule:
if any byte used to calculate the address of a memory loca-
tions is tainted, then, the result of a memory read using this
address is tainted as well.
Control ﬂow evasion: the taint information may also
propagate through control ﬂow. The following example il-
lustrates this situation.
switch(x) {
case ’a’: y=’a’; break;
case ’b’: y=’b’; break; ...
}
Note that the above code fragment copies the value of
variable x to y, without propagating the taint status. That
is, y will always be untainted, even when x is tainted.
The situation outlined above occurs rarely in regular code.
However, it does appear in the keystroke handling routines
in Windows 2000 and later versions.
In our experiments
with Windows XP, we observed that the Unicode characters
derived from keystrokes were not tainted as expected. After
reviewing the raw taint propagation events and examining
the Windows kernel code using IDA Pro [22], we determined
that taint tracking stops at a keystroke Unicode conversion
routine called _xxxInternalToUnicode (which is in part of
the win32k.sys system ﬁle). Interestingly, Chow et al. faced
the same problem in their TaintBochs [10]. Unfortunately,
they did not have a solution. The translation of scancode
into corresponding unicode characters involves a loop that
contains a switch statement such as the example discussed
previously. We solved the problem by specially instrument-
ing an instruction within the function _xxxInternalToUni-
code. This instrumentation checks the taint status of the
input parameter of the function, and appropriately propa-
gates the taint status to its output parameter.
Being aware of this property, malicious code may exploit
control ﬂow evasion in the future to cut oﬀ the taint ﬂow
in order to thwart detection. The current implementation
of Panorama does not handle this situation. This does not
cause problems for now, because to the best of our knowledge
no existing malware has used this technique. Furthermore,
we will incorporate the static analysis approach proposed in
[14] into the future implementation of Panorama to prevent
this potential evasion.
3.2 OS-Aware Taint Tracking
Resolving process and module information.
When an instruction is operating on tainted data, we need
to know which process and module this instruction comes
from. In some rare situations, instructions may also be dy-
namically generated and executed on the heap.
Maintaining a mapping between addresses in memory and
modules requires information from the guest operating sys-
tem. To obtain this information, we developed a kernel
module called module notiﬁer. We load this module into
the guest operating system to collect the updated memory
map information. The module notiﬁer registers two callback
routines. The ﬁrst callback routine is invoked whenever a
process is created or deleted. The second callback routine
is called whenever a new module is loaded and gathers the
address range in the virtual memory that the new module
occupies. In addition, the module notiﬁer obtains the value
of the CR3 register for each process. As the CR3 register
contains the physical address of the page table of the cur-
rent process, it is diﬀerent (and unique) for each process. All
the information described above is passed on to Panorama
through a predeﬁned I/O port.
Since our module notiﬁer component resides in the guest
operating system, malicious code may attempt to tamper
with it. For example, malware could attempt to send incor-
rect information to the predeﬁned I/O port or tamper with
the code image of the module. To ensure the authenticity of
the messages that Panorama receives from the module no-
tiﬁer, we check the program counter of the instruction that
is responsible for sending this message. Of course, only in-
structions that belong to the module notiﬁer are permitted
to send messages. We also protect the integrity of the code
of the module notiﬁer by marking the corresponding mem-
ory region read-only. As a result, any attempts to tamper
with the code of the module notiﬁer can be detected and
prevented. Note that a more secure approach to resolving
process and module information is to directly examine the
process and module objects from the outside. The disadvan-
tage of this approach is less of portability. That is, diﬀerent
versions of Windows, and even diﬀerent service packages,
need be handled diﬀerently. Thus, we decided to use the
ﬁrst, more portable approach in our proof-of-concept proto-
type implementation.
Resolving ﬁlesystem and network information.
In addition to mapping instructions executed on the pro-
cessor to operating-system processes, we are also interested
in obtaining more information when data is exchanged be-
tween the memory and hardware devices. In particular, we
are interested in more details about when tainted data is
written to the hard disk or sent over the network. More
precisely, when tainted data is written to the hard disk, we
wish to identify which ﬁle it is written to. Analogously, when
tainted data is transmitted over the network, we would like
to know which TCP (or UDP virtual) connection it is sent
over or received from.
We integrated a disk forensic tool called “The Sleuth Kit”
(TSK) [36] into Panorama for gathering ﬁlesystem informa-
tion. Speciﬁcally, when tainted data is written to a block
on the hard disk, TSK can determine which ﬁle this block
belongs to. In addition, when a ﬁle on disk is selected as a
taint source, TSK will identify all data blocks that belong
to this ﬁle (so that all blocks can be appropriately tainted).
The toolkit achieves these goals by scanning and parsing the
on-disk meta-data structures.
Resolving network information is straightforward. When
tainted data is sent out, we simply check the packet header
to ﬁnd out which connection it belongs to.2 Similarly, when
selectively tainting the incoming traﬃc of a speciﬁc connec-
2We may not be able to obtain transport-layer information
directly from IP fragments. In the current prototype imple-
mentation, we do not solve this infrequent case. However,
re-assembling the fragments and extracting this information
is quite straightforward if desired.
tion, we check its packet header and taint the packet accord-
ingly. Tainting incoming network packets from the network
card is performed at the granularity of (virtual) connections.
Identifying the code under analysis and its actions.
An important task of our system is to identify the actions
of the code under analysis. In particular, we are interested
in observing cases in which the potential malware sample
accesses tainted data. It is clear that the code under anal-
ysis operates on tainted data if an instruction in it accesses
the taint directly. This can be checked in a straightforward
fashion by consulting the mapping between instruction ad-
dresses and modules. However, there are two important
cases in which it is not the malicious sample itself that ac-
cesses tainted data, but code that operates on its behalf.
The ﬁrst case occurs when the sample under analysis dy-
namically generates new code (either by decrypting data
regions, or by generating code on the ﬂy). In this case, the
derived code belongs to the sample under analysis, but the
origin of the code is not reﬂected in our module mapping. To
handle this situation, we taint the complete code segment of
the sample under analysis, using a special label. Whenever
an instruction is executed that is marked with the special
label, the output of this instruction receives the special la-
bel as well. This strategy helps identify all code regions
derived from the original sample, such as uncompressed and
decrypted instructions from packed executables, or those dy-
namically generated.
The second case occurs when the given code calls a piece
of trusted code in order to perform tainted operations on
its behalf. In this case, the program counter would point to
the trusted code, and we would miss the potential malicious
behavior of the given sample, if we only look at the program
counter. We use the following observation to identify taint
propagation that is performed by trusted system modules on
behalf of the malware: Whenever the malicious code calls
a trusted function to propagate tainted data, the value of
the stack pointer at the time of the function call must be
greater than the value of the stack pointer at the time when
the tainted data is actually propagated. This is because one
or more stack frames have to be pushed onto the stack when
making function calls, and the stack grows toward smaller
addresses on the x86 architecture.
Based on our observation, we use the following approach
to identify the case when trusted functions propagate tainted
values on behalf of the code under analysis: Whenever the