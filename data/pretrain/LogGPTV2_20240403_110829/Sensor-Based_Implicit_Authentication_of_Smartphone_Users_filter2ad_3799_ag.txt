# Confidence Score Over Time

Figure 7 illustrates the confidence score of a user over time. After approximately one week, the confidence score drops below the threshold (CS = 0.2) for a period. Following automatic retraining, it returns to normal values.

## H. Smartphone Overhead

We now evaluate the system overhead of SmarterYou on smartphones. Specifically, we analyze the computational complexity, CPU and memory usage, and battery consumption.

### 1. Computational Complexity

The computational complexity of Kernel Ridge Regression (KRR) in Section V-F2 is directly related to the data size according to Equation 6. Here, we further show that the computational complexity can be significantly reduced to be directly related to the feature size. (For readability, the detailed proof is provided in the Appendix.)

According to Equation 6, the classifier is \( w^* = \Phi[K + \rho I_N]^{-1} y \).

Define \( S = \Phi \Phi^T \) where \( \Phi = [\phi(x_1), \phi(x_2), \ldots, \phi(x_N)] \).

By utilizing the matrix transformation method in [45], the optimal solution \( w^* \) in Equation 6 is equivalent to:

\[ w^* = \Phi[K + \rho I_N]^{-1} \Phi y = [S + \rho I_J]^{-1} \Phi y \]

The dominant computational complexity for \( w^* \) comes from taking the inversion of a matrix. Therefore, based on Equations 6 and 7, the computational complexity is approximately \( \min(O(N^{2.373}), O(J^{2.373})) \). If we use the identity kernel, the computational complexity can be reduced from \( O(N^{2.373}) \) to \( O(M^{2.373}) \) and is independent of the data size. Specifically, we construct 28-dimensional feature vectors (4 time-domain features and 3 frequency-domain features for each of two sensors, for each device).

Thus, our time complexity is reduced from \( O((800 \times 9/10)^{2.373}) = O(720^{2.373}) \) to only \( O(28^{2.373}) \). In our experiments, the average training time is 0.065 seconds, and the average testing time is 18 milliseconds, demonstrating the effectiveness of our system in real-world scenarios.

### 2. CPU and Memory Overhead

The testing module of SmarterYou runs as threads within the smartphone's system process. We developed an application to monitor the average CPU and memory utilization while running the SmarterYou app, which continuously requests sensor data at a rate of 50 Hz on a Nexus 5 smartphone and a Moto 360 smartwatch. The average CPU utilization is 5% and never exceeds 6%. The CPU utilization (and hence energy consumption) scales with the sampling rate. The average memory utilization is 3 MB. Thus, we believe that the overhead of SmarterYou is small enough to have a negligible effect on overall smartphone performance.

### 3. Battery Consumption

To measure battery consumption, we consider the following four testing scenarios:
1. Phone is locked (i.e., not being used) and SmarterYou is off.
2. Phone is locked and SmarterYou is running.
3. Phone is in use and SmarterYou is off.
4. Phone is in use and SmarterYou is running.

For scenarios (1) and (2), the test duration is 12 hours each. We charge the smartphone battery to 100% and check the battery level after 12 hours. The average difference in the battery charged level from 100% is reported in Table VIII.

For scenarios (3) and (4), the phone is periodically used. During the usage period, the user types notes. The usage and non-usage periods are five minutes each, and the total test time is 60 minutes.

Table VIII shows the results of our battery consumption tests in terms of extra battery drain for SmarterYou. We find that in scenarios (1) and (2), the SmarterYou-on mode consumes 2.1% more battery power than the SmarterYou-off mode. We believe this additional battery consumption will not affect user experience in daily use. For scenarios (3) and (4), SmarterYou consumes 2.4% more battery power in one hour, which is also an acceptable cost for daily usage.

## I. Retraining Authentication Models

The behavioral drift of the legitimate user must be considered. The user may change their behavioral pattern over weeks or months, leading to more false alarms in implicit authentication. SmarterYou, therefore, will automatically and continuously retrain the authentication models based on previous authentication performance.

Here, we define the confidence score (CS) as \( CS(k) = x_k^T w^* \), where \( x_k \) is the k-th authentication feature vector, and \( w^* \) is the corresponding authentication classifier. The distance between \( x_k \) and \( w^* \) represents the confidence score.

As the authentication classifier \( w^* \) represents the classification boundary to distinguish the legitimate user from adversaries, a lower confidence score (smaller distance) indicates a less confident authentication result. This suggests a change in the user’s behavioral pattern, necessitating retraining. For an authenticated user, if the confidence score is lower than a certain threshold \( \Delta CS \) for a period of time \( T \), the system automatically retrains the authentication models.

In Figure 7 (right), we show the confidence score of the time-series authentication feature vectors for a user. The confidence score decreases slowly in the first week. At the end of the first week, the confidence score experiences a period of low values (below our threshold \( \Delta CS = 0.2 \)), indicating that the user’s behavior has changed. Therefore, it would be helpful for the system to automatically retrain the authentication models. Note that there are some earlier points below the threshold, but they do not occur for a long enough period to trigger retraining. It is also difficult for an attacker to trigger retraining because the probability of continuously passing authentication for a long period is low, as described in Section V-G.

As our system recognizes user’s behavior drift by checking the confidence score, it then goes back to the training module, uploading the legitimate user’s authentication feature vectors until the new behavior (authentication model) is learned. Advanced approaches in machine unlearning [46] can be explored to update the authentication models faster than retraining from scratch. After retraining the user’s authentication models, the confidence score increases to normal values from Day 8.

As discussed earlier, an attacker who has taken over a legitimate user’s smartphone must not be allowed to retrain the authentication model. Fortunately, the attacker cannot trigger retraining since the confidence score should be positive and last for a period of time. However, the attacker is likely to have negative confidence scores, which cannot last long enough to trigger retraining, as they will be detected in less than 18 seconds by SmarterYou, according to Figure 6.

## VI. Conclusions

We have proposed a new re-authentication system, SmarterYou, to enhance the security of smartphones and the sensitive data and code accessible through them. SmarterYou is an authentication system using multiple sensors built into a user’s smartphone, supplemented by auxiliary information from a wearable device, such as a smartwatch, owned by the same user. Our system continuously monitors the user’s sensor data and authenticates without any human cooperation. We first collect context features from the sensors’ data in the smartphone (and the smartwatch if present) to detect the current user's context. Based on the detected context and the authentication features in both the time and frequency domains, our system implements fine-grained authentication efficiently and stealthily.

We systematically evaluate design alternatives for each parameter of the sensor-based implicit authentication system. Based on our design choices, our evaluations demonstrate the advantage of combining the smartphone and smartwatch and the enhancement in authentication accuracy with context detection and time-frequency information. SmarterYou can achieve authentication accuracy up to 98.1% (FRR 0.9% and FAR 2.8%) with negligible system overhead and less than 2.4% additional battery consumption. We believe this is the highest accuracy and lowest FAR reported by any sensor-based authentication method to date. We hope that the SmarterYou system and design techniques can help advance the field of implicit user authentication and re-authentication for deployment in real-world scenarios.

## References

[1] Y. Kim, T. Oh, and J. Kim, “Analyzing user awareness of privacy data leak in mobile applications,” Mobile Information Systems, 2015.

[2] J. Achara, C. Castelluccia, J.-D. Lefruit, V. Roca, F. Baudot, and G. Delcroix, “Mobilitics: Analyzing privacy leaks in smartphones,” ERCIM Newsletter, 2013.

[3] M. Qi, Y. Lu, J. Li, X. Li, and J. Kong, “User-specific iris authentication based on feature selection,” in CSSE, 2008.

[4] K. Xi, J. Hu, and F. Han, “Mobile device access control: an improved correlation-based face authentication scheme and its Java ME application,” Concurrency and Computation: Practice and Experience, 2012.

[5] K. Niinuma, U. Park, and A. K. Jain, “Soft biometric traits for continuous user authentication,” IEEE TIFS, 2010.

[6] ConsumerReports, “Keep your phone safe: How to protect yourself from wireless threats,” Consumer Reports, Tech., 2013.

[7] A. De Luca, A. Hang, F. Brudy, C. Lindner, and H. Hussmann, “Touch me once and I know it’s you!: implicit authentication based on touch screen patterns,” in ACM CHI, 2012.

[8] N. L. Clarke and S. M. Furnell, “Authenticating mobile phone users using keystroke analysis,” International Journal of Information Security, vol. 6, no. 1, pp. 1–14, 2007.

[9] S. Buthpitiya, Y. Zhang, A. K. Dey, and M. Griss, “n-gram geo-trace modeling,” in Pervasive Computing, 2011.

[10] O. Riva, C. Qin, K. Strauss, and D. Lymberopoulos, “Progressive authentication: Deciding when to authenticate on mobile phones.” in USENIX Security, 2012.

[11] J. Zhu, P. Wu, X. Wang, and J. Zhang, “Sensec: Mobile security through passive sensing,” in ICNC, 2013.

[12] J. Mäntyjärvi, M. Lindholm, E. Vildjiounaite, S.-M. Mäkelä, and H. Ailisto, “Identifying users of portable devices from gait pattern with accelerometers,” in ICASSP, 2005.

[13] Z. Xu, K. Bai, and S. Zhu, “Taplogger: Inferring user inputs on smartphone touchscreens using on-board motion sensors,” in conference on Security and Privacy in Wireless and Mobile Networks, 2012.

[14] A. J. Aviv, K. L. Gibson, E. Mossop, M. Blaze, and J. M. Smith, “Smudge attacks on smartphone touch screens.” Woot, 2010.

[15] M. Conti, I. Zachia-Zlatea, and B. Crispo, “Mind how you answer me!: transparently authenticating the user of a smartphone when answering or placing a call,” in CCS, 2011.

[16] C. Nickel, T. Wirtl, and C. Busch, “Authentication of smartphone users based on the way they walk using k-NN algorithm,” in IIH-MSP, 2012.

[17] M. Trojahn and F. Ortmeier, “Toward mobile authentication with keystroke dynamics on mobile phones and tablets,” in WAINA, 2013.

[18] F. Okumura, A. Kubota, Y. Hatori, K. Matsuo, M. Hashimoto, and A. Koike, “A study on biometric authentication based on arm sweep action with acceleration sensor,” in ISPACS, 2006.

[19] M. Frank, R. Biedert, E.-D. Ma, I. Martinovic, and D. Song, “Touchalytics: On the applicability of touchscreen input as a behavioral biometric for continuous authentication,” IEEE TIFS, 2013.

[20] L. Li, X. Zhao, and G. Xue, “Unobservable re-authentication for smartphones,” in NDSS, 2013.

[21] T. Feng, Z. Liu, K.-A. Kwon, W. Shi, B. Carbunar, Y. Jiang, and N. K. Nguyen, “Continuous mobile authentication using touchscreen gestures,” in Homeland Security, Conference on Technologies for, 2012.

[22] H. Xu, Y. Zhou, and M. R. Lyu, “Towards continuous and passive authentication via touch biometrics: An experimental study on smartphones,” in Symposium On Usable Privacy and Security, 2014.

[23] N. Zheng, K. Bai, H. Huang, and H. Wang, “You are how you touch: User verification on smartphones via tapping behaviors,” in Network Protocols, International Conference on, 2014.

[24] H. G. Kayacık, M. Just, L. Baillie, D. Aspinall, and N. Micallef, “Data driven authentication: On the effectiveness of user behaviour modelling with mobile device sensors,” Mobile Security Technologies, 2014.

[25] W.-H. Lee and R. B. Lee, “Multi-sensor authentication to improve smartphone security,” in ICISSP, 2015.

[26] L. Yang, Y. Guo, X. Ding, J. Han, Y. Liu, C. Wang, and C. Hu, “Unlocking smartphone through handwaving biometrics,” IEEE Transactions on Mobile Computing, 2015.

[27] L. Hong and A. Jain, “Integrating faces and fingerprints for personal identification,” IEEE TPAMI, 1998.

[28] A. Serwadda and V. V. Phoha, “When kids’ toys breach mobile phone security,” in CCS, 2013.

[29] S. Mare, A. M. Markham, C. Cornelius, R. Peterson, and D. Kotz, “Zebra: Zero-effort bilateral recurring authentication,” in SP, 2014.

[30] J. A. Suykens, T. Van Gestel, J. De Brabanter, B. De Moor, J. Vandewalle, J. Suykens, and T. Van Gestel, Least squares support vector machines. World Scientific, 2002.

[31] W.-H. Lee, X. Liu, Y. Shen, H. Jin, and R. Lee, “Secure pick up: Implicit authentication when you start using the smartphone,” in Symposium on Access Control Models and Technologies, 2017.

[32] T. Y.-H. Chen, A. Sivaraman, S. Das, L. Ravindranath, and H. Balakrishnan, “Designing a context-sensitive context detection service for mobile devices,” 2015.

[33] N. Kern, B. Schiele, and A. Schmidt, “Multi-sensor activity context detection for wearable computing,” in Ambient Intelligence. Springer, 2003.

[34] A. ARM, “Security technology-building a secure system using TrustZone technology,” ARM Technical White Paper, 2009.

[35] F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shafi, V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and software model for isolated execution,” in International Workshop on Hardware and Architectural Support for Security and Privacy, 2013.

[36] P. Wu, J. Zhu, and J. Y. Zhang, “Mobisens: A versatile mobile sensing platform for real-world applications,” Mobile Networks and Applications, 2013.

[37] R. O. Duda, P. E. Hart, and D. G. Stork, Pattern classification. Wiley & Sons, 2012.

[38] Google, “Android sensor manager,” http://developer.android.com/guide/topics/sensors/sensors_overview.html.

[39] B. Boashash, Time frequency analysis. GPP, 2003.

[40] W. W. Daniel et al., “Applied nonparametric statistics,” 1990.

[41] T. K. Ho, “Random decision forests,” in ICDAR.

[42] S. An, W. Liu, and S. Venkatesh, “Face recognition using kernel ridge regression,” in CVPR, 2007.

[43] W.-H. Lee and R. Lee, “Implicit authentication for smartphone security,” in Information Systems Security and Privacy. Springer, 2015.

[44] ——, “Implicit sensor-based authentication of smartphone users with smartwatch,” in HASP 2016, 2016.

[45] R. A. Horn and C. R. Johnson, Matrix analysis. Cambridge University Press, 2012.

[46] Y. Cao and J. Yang, “Towards making systems forget with machine unlearning,” in Security and Privacy, 2015.

## VII. Appendix

### A. Proof of Equivalence between Equation 6 and Equation 7

Equation 6 is \( w^* = \Phi[K + \rho I_N]^{-1} y \), and Equation 7 is \( w^* = [S + \rho I_J]^{-1} \Phi y \).

To prove that they are equivalent, we first prove \( P B^T (B P B^T + R)^{-1} = (P^{-1} + B^T R^{-1} B)^{-1} B^T R^{-1} \) as follows:

\[ B^T + B^T R^{-1} B P B^T = B^T R^{-1} B P B^T + B^T \]
\[ \Rightarrow (P^{-1} + B^T R^{-1} B) P B^T = B^T R^{-1} (B P B^T + R) \]
\[ \Rightarrow P B^T (B P B^T + R)^{-1} = (P^{-1} + B^T R^{-1} B)^{-1} B^T R^{-1} \]

Then, we let \( P = \rho I_J \), \( B = \Phi^T \), and \( R = \rho I_N \) in the above equation. We observe that the left-hand side of the equation is Equation 6 and the right-hand side is Equation 7. Thus, we prove the equivalence between Equation 6 and Equation 7.