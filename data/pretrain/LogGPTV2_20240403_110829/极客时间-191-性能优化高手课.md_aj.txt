# 09 \| 性能模式（上）：如何有效提升性能指标？你好，我是尉刚强。构建高性能的软件，可以说是所有程序员的共同追求。不过，当我们碰到性能问题时，一般都只会想到数据结构和算法，而忘记系统性能是由运行态的各个硬件所承载的。比如说，当你的代码中遇到一个复杂数学计算的时候，你可能只会想到通过修改优化算法的方式来提升性能。可实际上，一个潜在更优的解决方案是提前计算好放到内存中，使用的时候直接取用，这时候具体的算法性能已经不是最重要的了。所以，当我们从**硬件运行态的视角**去思考问题的时候，其实就会很容易地找到一些之前没发现，但性能收益比较大的解决方法，这就是我接下来的两节课要给你介绍的性能模式。所谓的性能模式，就是**在软件设计的过程中针对一些特定的上下文场景，以性能提升作为出发点的通用解决方案。**下面我所讲解的各种性能模式，在很多场景下都已经被实际验证过了，你可以在特定的性能优化场景下去套用和实现，从而少走一些性能优化上的弯路。另外，与软件设计模式不同，一般来说这些性能模式都是比较独立的，你可以将其看作是在时间、空间等不同维度去解决问题的参考思路，在很多的场景下都可以同时使用。所以我希望，你也不要局限于这几种性能模式，而是可以**借鉴这些性能模式的解题思路，来掌握这种全局性地、软硬协同地、动态地思考和解决问题的思路**。好了，接下来，我就根据我的实践经验，按照常用度从高到低的顺序，来分别给你介绍下快速通道模式、并行分解模式、批处理模式、弹性时间模式、预计算模式、耦合模式、搬移计算模式、丢弃模式这八种性能模式的优化实现原理。这节课我们先来了解下前四种性能模式。另外，在开始介绍之前我还要说明一点，通常情况下性能模式的抽象级别会比较高，不太适合直接使用举例。为了更清楚地给你展示性能模式的核心思想，我在课程里单独增加了代码示例，这些代码示例很多时候并没有实际意义，你千万不要抄作业且不改名字。快速通道模式好，我们先来学习下第一种性能模式：快速通道模式。不知道你平常在逛超市的时候有没有发现这种现象：人们经常购买的商品可能只是整个超市商品的一小部分，大部分商品实际上很少有人购买。基于这个现象，二十世纪初意大利的经济学家维弗雷提出了著名的**二八效应**，即 80/20 法则（The 80/20Rule）：在通常情况下，事物的发展都是由少数决定多数的，体现了不公平的特点。这个法则在计算机领域中也非常适用：系统中大部分用户使用的通常只是少数的一些业务场景；系统中的大部分性能负载是由少量的代码决定的。二八效应在软件系统中的各个维度不断重复着，所以我们能找到那20%的决定性场景，寻找定制化方案，就能在很大程度上提升系统的性能。而这正是快速通道模式的核心思想，下面我们就来看看它的具体实现流程：![](Images/b6574c409960baf40484a79ddaf45867.png)savepage-src="https://static001.geekbang.org/resource/image/1b/e4/1be61a330b698a935c6dca5f04f4cae4.jpg?wh=2000*1125"}图上矩形块中的数字代表的是执行开销，我们可以看到在优化前，系统的总执行开销为10。而通过分析业务流程和度量数据，我们会发现绝大部分用户使用的少量典型场景，其实可以找到简化处理的方案。因此，如图上的右半部分所示，针对少数典型场景定制化实现的方案，其执行开销从原来的3+5+2 变成了 4，系统的总执行开销变为了6.2，可以说性能提升非常明显。不过，从解决方案上我们也可以看出，系统在优化过程中增加了额外的业务流程，所以它的业务复杂度就提升了。这也是性能优化实现中经常需要面对的问题，为了追求极致的性能，而不得已舍弃了软件实现的部分简洁性。这里我给你举个例子。下面是一个数学阶乘的递归实现，我们能看出程序在运行过程中会触发多次函数的调用，这就导致执行时间会比较长（注意，该实现在num数字较大的时候会计算越界，不过这不是我们的关注点，可以先忽略）。    long factBeforeOptimize(int num)    {        if ( num == 1)        {            return 1;        }        else        {            return num * fact(num - 1);        }    }在对这个函数使用统计数据分析后，可以发现 80%以上的接口调用传入的参数都是8，所以我们就可以针对这个典型场景实现快速处理，以此来提升性能。修改后的代码实现如下：    long factAfterOptimize(int num)    {        if (num == 8)        {            return 40320;        }        else if (ip == 1)        {            return 1;        }        else        {            return ip * fact(ip - 1);        }    }通过对比前面的代码，我们能发现改写后的代码实现只是增加了很小一段代码，但系统处理性能却有了很大程度的提升。所以，**快速通道模式的核心思想，就是找到系统中频繁使用的典型场景，然后针对性地提供定制化方案来优化性能。**不过实际上，针对 CPU资源紧张、内存资源相对充足的场景，前面所讲的阶乘计算实现是非常糟糕的。因为在该场景下，首先递归运算本身是非常低效的；其次，如果阶乘运算输入参数比较少的话，我们其实可以通过查表来减少执行的运算量。因此在实际的场景中，快速通道模式的典型应用主要有两类：1.  **一类是数据库 Cache    场景。**        业务代码经常访问的数据往往是全量数据中很少的一部分，所以在内存中对这部分数据进行    Cache，就可以获得比较明显的性能改善。        2.  **另一类针对的是 Web    业务用户经常访问的页面。**        在前端交互设计中，你可以通过给用户提供快速入口来直接跳转至常用页面，减少很多中间过程页面的访问，从而能够减少系统整体的业务负载。        但是，快速通道模式也存在一定的**局限性**，也就是如果对典型场景分支的预测有错误，就可能会导致系统性能更加恶化。比如，有些数据库Cache 场景由于 Cache 的命中失败率太高，如果继续引入Cache，反而会恶化性能表现。看到这里，你可能还存在一个疑问，那就是**快速通道模式只能用于优化时延吗？**显然不是的！我一直强调，我们不应该只看到性能模式的外部表现形式，而是应该理解性能模式背后的思维逻辑。我曾经设计过一款内容资源受限的系统应用，该系统中包含了很多用户实例，而且每个用户的实例结构体比较大，内存总开销超过了设备的内存上限。而通过分析发现，大部分的用户实例其实只使用了结构体内的少部分字段，因此针对用户实例，我设计了精简版结构体和复杂版结构体，由于大部分用户实例使用了精简版结构体，所以系统总内存开销就被控制在了规定的范围内。所以你看，这就说明了快速通道模式其实也可以用于内存的优化设计。并行分解模式OK，我们接着来看第二种性能模式：并行分解模式。并行其实是一种常态化的解决问题的模式，比如在工作当中，一件任务会被拆分成很多份，交付给不同的人，通过并行来加速任务的完成。随着计算机技术的不断发展，并行计算也越来越方便可得，因此我们可以在业务处理的过程中，去挖掘并行执行的部分，借助并行计算来优化性能。这种并行分解的性能解决方案的主要目标，是**减少业务的处理时延**，虽然在调整优化后，系统的执行开销可能会增加，但是从用户的角度来看，处理时延却降低了。下面我们就具体来看看：![](Images/5f78aa9fdf9bfcb91be059214666f4b3.png)savepage-src="https://static001.geekbang.org/resource/image/69/01/6921cdbf9b1a4d2f833e4ea822fe3a01.jpg?wh=2000*1125"}如上图所示，矩形方块中的数字表示执行开销，在正常业务流程中可以分为两个大的代码块。在原来的业务流程中，虽然业务是串行执行的，但通过分析业务流程和度量数据后，我们会发现这两个代码块之间是独立可并行的。所以，图上左侧优化前的总执行开销为13，借助并行分解模式，将两个代码块并行执行，优化后的总开销降为11。 不过从图上我们也能看出，右侧优化后的应用占用的 CPU 资源为1+2+4+2+5=14，总执行消耗资源变多了。但从用户的角度来看，其实是可以感知到处理时延变低了。下面我们来看一个具体的例子，这是一个使用并发性能模式前后的实现代码对比样例（为了简化代码内容，我隐藏了loadStudents() 和 loadTeachers()的具体代码）：    void loadStudentsAndTeachersBeforeOptimize()    {        loadStudents(); //加载学生信息列表        loadTeachers(); //加载老师信息列表    }    void loadStudentsAndTeachersAfterOptimize()    {        std::thread first(loadStudents); //创建独立线程加载学生信息列表        std::thread second(loadTeachers); //创建独立线程加载老师信息列表        first.join();        second.join();    }如上述代码所示，loadStudentsAndTeachersBeforeOptimize 中，两个代码块loadStudents 和 loadTeachers之间是可以并行执行的。loadStudentsAndTeachersAfterOptimize中使用了两个独立线程，分别加载学生和老师信息，从而加速了系统的处理时延。注意，这里我使用线程来举例，只是为了给你说明并行模式的核心价值，并不是只有线程可以提升并发。要知道，**并行任务分解模式通常是站在系统运行的视角来审视系统，寻找并发增益的。**在第 2 讲slate-object="inline"中我已经给你介绍过并行系统设计的相关话题，你可以去回顾复习下。我给你举两个典型的场景案例吧：1.  很多大型数据库的计算引擎就是典型的应用案例。在大数据处理场景中，根据数据拆分、并行计算再规约的典型框架，本质上就是通过增加计算资源实现处理时延降低的目标。        2.  基于控制流的并发处理也很有价值。这里我以 Web    后端服务的异步机制为例，很多后端服务支持系统同一时刻触发多个 REST    请求，通过并行异步回调处理，从而就在很大程度上降低了后端的处理时延。        不过，并行分解模式使用会引入一些额外的挑战。一般来说，我们习惯使用串行编程思维来解决性能问题，这时心智模型会比较简单，而修改为并行方式后不仅程序的复杂度会提升，还很容易引起很多并发互斥问题。而且并不是并发度越高，系统的性能就越好，人月神话slate-object="inline"就是一个很好的反例。一个项目的实现可能需要 10 人 /月，但这并不意味着让 300人来做就可以在一天内完成该项工作。OK，接着这个思路，我们再来思考一个问题：**在单核场景下，有必要创建线程吗？**我认为实际上，在单核场景下你可能也需要创建线程。早期的操作系统在创建线程时，主要想解决的是CPU 资源共享的问题。当时线程工作的特点是：少许 CPU 操作和较多异步 IO操作，在这种场景下创建多个线程时，能够实现当某个线程阻塞时，CPU资源可以分配给其他线程，从而提升系统的整体性能。但随着计算机 CPU硬件多核技术的普及，在很多场景下，线程的工作目标主要在于充分发挥 CPU硬件多核的价值，线程的工作特点也向不间断执行 CPU指令的方向演进，因此并行设计的架构与模式也发生了很大的变化。批处理模式好，我们接着来学习第三种性能模式：批处理模式。这里我们先来思考一个问题：当我们去超市购买商品时，每次只买一件商品，然后分别购买10 次所用的时间，跟去超市一次性买足 10件商品使用的时间，是不是肯定不一样？。在计算机领域中也是同样的道理，同样的计算任务，分别执行 10次和一次批处理 10个，它们需要的时间也是不一样的。所以找出这样的典型业务场景，通过采用批处理方式，就可以很大程度地提升系统性能。接下来我们就具体看看这种性能模式的优化特点：![](Images/1ec4adfa724993108602fc42d4f44cd3.png)savepage-src="https://static001.geekbang.org/resource/image/6f/90/6f1d5ccb0aff193687efa8febcffb190.jpg?wh=2000*1125"}如上图所示，左侧优化前循环中第一个矩形代码块执行开销为2。这个操作在循环体执行了 10 次，需要消耗的计算资源为20，当修改成批量计算后，执行开销从 20 降低到了5，从而极大地提升了性能。另外，从图上我们也能看到，左侧优化前的执行开销为 60，而优化后开销为45，总的性能提升也比较明显。同样地，我们还是来看一个具体的例子。这是一个用 C语言实现的案例，案例中对比了循环遍历处理数据和批处理两种不同的代码实现：    typedef struct Student    {        int age;        char name[20];    } Student;    Student students[10];    void init(Student *student)    {        student->age = 0;        memset((void*) student->name, (int) 0, sizeof(student->name));    }    void initAllStudentsBeforeOptimize()    {        for (int i = 0; i   > 注：代码中我省略了很多关于数据库的相关配置与代码，因为这对理解耦合模式并无太大帮助。> > >    public class User {            private String name;            private Integer age;            public String getName() {            return name;            }            public void setName(String name) {            this.name = name;            }            public Integer getAge() {            return age;            }            public void setAge(Integer age) {            this.age = age;            }    }    public interface UserMapperBeforeOptimize {         public String findNameById(String Id);  //单一职责接口        public String findAgeById(String Id);   //单一职责接口    }    public interface UserMapperAfterOptimize {         public String findNameById(String Id);  //单一职责接口        public String findAgeById(String Id);  //单一职责接口        public User FindUserById(String Id);  //新增的获取多个字段的耦合接口    }可以发现，优化之前的接口中包含了两个方法：根据 ID 获取名字、根据 ID获取年龄。当很多的客户代码同时需要获取名字和年龄时，就可以通过在接口中增加一次性返回姓名和年龄信息的方法，来减少业务两次访问数据库带来的网络和查询的额外开销。耦合模式的应用场景比较多，比如说：1.  在数据库设计的过程中，基于性能考虑，我们可以将多个表中的字段信息融合记录到一个大表内，从而实现原来需要多次查询操作，变成一次查询就全部获取。        2.  在微服务接口设计中，通常 REST    接口并不是正交的，其中会包含一些基本功能接口和一些复合功能接口。而在一些典型的性能优化场景下，使用复合接口就可以一次实现原来多个基本功能接口请求的功能，从而就能通过减少    REST    接口调用次数来优化性能。        3.  在嵌入式场景中，子系统间交互使用的    TLV（Tag、Length、Value）数据结构类型，也是典型的耦合模式的应用。        另外，**耦合模式也并不局限在接口层面，你也可以在计算逻辑中去使用**。同时你需要注意，在实现包含复合功能的接口与业务逻辑时，不建议删除掉原来的单一功能实现，这是为了防止对只使用简单接口与功能的客户带来额外的开销。搬移计算模式不论在工作还是生活中，你可能很擅长基于时间来统筹安排每个时间段中要做的事情。那么在软件的业务计算过程当中，你同样可以基于性能和效率考量，去调整安排计算逻辑在运行时间与物理位置上的分布。在实时高性能的系统中，软件工程师在设计时通常会把业务逻辑划分为关键路径和非关键路径。而我们知道，系统时延在更大程度上取决于关键业务逻辑的处理时延。所以，如果你可以**把计算逻辑从关键路径搬移到非关键路径，就可以提升产品的性能**。在使用搬移计算模式来调整计算业务逻辑的过程中，你要重点关注的是处理时延的性能提升。但你也要注意，在这样优化处理之后，其实系统的总负荷通常并没有减少。所以，你可以在系统核心目标是追求用户侧的时延最小化的业务场景中，选择使用这种性能模式。下面我们就来看一下搬移计算模式的具体实现流程：![](Images/06e08c7b36eaedb67a5087f9121493ef.png)savepage-src="https://static001.geekbang.org/resource/image/c2/49/c2cddbf27d6c380ae48ae36906806c49.jpg"}在图中左侧第一个矩形执行代码块中，我们通过分析业务流程和度量数据，发现部分业务逻辑可以推后计算，于是把这部分业务拆分到另外一个任务中去执行，从而就减少了客户关注的处理时延。这里我给你举一个真实的使用案例。在互联网 SaaS服务中，对我们这样的普通用户而言，会对请求的响应时延十分感兴趣，而并不关注服务器处理业务的全部处理时间，所以这时候，我们就可以使用搬移计算模式来进行优化。因此，我曾经就在这类项目的优化过程中，引入了延迟计算服务，并通过对业务逻辑优化，剥离了非关键业务，交给延迟计算任务进行处理，从而实现了在短时间内，将时延性能指标提升到40% 以上的目标。而除了与 SaaS服务相关的业务场景，在**嵌入式场景和云服务场景**中，使用搬移计算模式优化性能也都能取得很好的效果。但是你需要认识到，**搬移计算的设计与实现其实容易引起整个系统的复杂度提升，进而也容易引入额外的故障**，所以你在引用这种性能模式时，一定要注意进行充分的功能验证与性能优化的提升分析。丢弃模式好，现在我们来学习下最后一种性能模式，也就是丢弃模式。你可以先来试想这样一种场景：在正常情况下，你每天早上起来上班前，都会洗脸、刷牙，然后再带上电脑出门；而当某天起来晚了，你可能就会把洗脸、刷牙这步省掉了，直接背着电脑出门。所以发现没有，我们做的很多事情在特定场景下其实都是可以丢弃的。那么回到软件业务处理的过程中，也是一样的道理。在软件系统中，我们在一些特殊的场景下使用丢弃模式，就可以达到非常好的性能优化效果，这里我们先来了解下它的具体工作流程：![](Images/67c6005fd0c0f90daca7770be5e20866.png)savepage-src="https://static001.geekbang.org/resource/image/da/29/da5dc6cb18ce9823e6c6547de108fb29.jpg"}在上图的左侧部分，可以看到第一个矩形代码块的执行开销为3，而我们通过分析业务流程和度量数据，发现这个功能的优先级比较低。因此可以使用的优化策略就是：把优先级比较低的代码块放到业务最后，在极端场景下，也可以通过直接丢弃不处理来保证系统性能不恶化。丢弃模式，在实时嵌入式的场景中使用的比较多，这种模式非常好理解和操作。你在实际的业务场景下，要注意先识别出业务中的非关键部分逻辑，确认其支持可关闭，这样当系统处于超负荷运行时，就可以直接将这部分业务停掉。小结通过这两节课的介绍和讲解，现在你应该就能理解这八种性能模式的核心优化思想了。这里我想提醒你一点，在前面的代码示例中，我使用的是非常小的代码来进行演示的，因此并不建议你在实际代码实现的细粒度级别中去使用这些代码例子。最后我想说，性能模式是软件优化中非常重要的手段之一，但是很多的性能优化工程师，目光只停留在编译层面的优化性能，而忽略了最直接且高效的性能模式。所以我希望，你在碰到具体的性能问题与挑战时，可以运用今天学到的性能模式，并可以在较大的业务粒度上使用，来帮助产品提升性能竞争力。思考题在你以往参与的性能优化项目中，有没有也使用过一些巧妙的处理模式，却带来了很明显的性能提升呢？欢迎在留言区中分享你的答案，我们一起交流讨论。如果觉得有收获，也欢迎你把今天的内容分享给更多的朋友。