In most cases
the evaluated protocols are not algorithmically identical. This is
unavoidable, as a key design point of the DSL is to simplify the
optimization and exploration of protocols. The protocols in C++
are long (the C++ division protocol spans over 1500 lines of code
whereas all DSL protocols combined span less than 3000) and dif-
ﬁcult to read. It is often not clear if their implementation matches
Figure 5: Sharemind architecture
holds. We have attempted to construct the protocols of Sharemind
in such a way that they would provide privacy [5, 37] against one
malicious computing party.
We use the universal composability (UC) [11] framework to ar-
gue about the security and privacy properties of our protocol set. In
this framework, a protocol — a real functionality — is modeled as
a collection of interactive Turing machines (ITM). These machines
communicate with each other over a number of named tapes. In a
closed collection, each named tape has a single machine writing it,
and a single machine reading it. Only closed collections of ITMs
are executable. The interface of a collection of ITMs is the set of
named tapes occurring in it that lack a reader or writer. In the UC
framework, the interface of a functionality is split into two parts —
the interface for the intended user (called the environment) of the
functionality, and the interface for the adversary.
Let π be a real functionality (a protocol — a collection of ITMs)
and F an ideal functionality (usually expressed as a single ITM).
We say that π is black-box at least as secure as F , if there exists an
ITM Sim, such that all environments Z and all adversaries A, the
views of Z in closed collections Z(cid:107)π(cid:107)A and Z(cid:107)F (cid:107)(Sim(cid:107)A) are
indistinguishable [11]. Here (cid:107) denotes the parallel composition of
ITM-s or their collections, together with the identiﬁcation of tapes
with the same name.
If π is an SMC protocol for performing a particular operation
op on shared values, then the ITMs of π receive the shares of the
inputs over the interface with Z at the beginning of the protocol.
Also, the adversary may corrupt some ITMs at the beginning of the
protocol. During the protocol, the ITMs exchange messages and
compute the shares of the outputs. Corrupt ITMs send everything
they receive also to the adversary. If the adversary is malicious,
then the corrupt ITMs do not follow the protocol but the adversary’s
orders. Finally, the ITMs of π hand the shares of the outputs back
to Z. A corresponding ideal functionality Fop also receives the
shares of the inputs from Z and the corruption requests from A.
The functionality Fop reconstructs the actual inputs from the shares,
applies op to them and shares the results, thereby obtaining the
output shares which it gives back to Z. The functionality Fop also
sends the input and output shares of corrupt parties to A. If the
adversary is malicious, then it can also change the output shares
returned to corrupt parties.
An SMC protocol π for the operation op is secure if it is at least
as secure as the corresponding ideal functionality Fop. E.g.
the
resharing protocol in Listing 1 is a secure protocol for the identity
function. The privacy of a protocol can be deﬁned similarly. Let the
protocol ¯π be obtained from π and the functionality ¯F be obtained
from Fop by removing from them the ﬁnal sendings of output shares
to Z and A. We say that π is private if ¯π is at least as secure as ¯F .
It is known that the sequential composition of two protocols
(where the output shares from the ﬁrst protocol are directly given as
inputs to the second protocol, without going through Z) preserves
SharemindProtocolsMUL8MUL16DIV8...LLVMcompileMUL8SecreCcodebytecompileevalcodecallspecify callsthe speciﬁcation – and frequently it does not as the concrete imple-
mentations tend to employ undocumented optimizations.
Another factor that makes identical comparison diﬃcult is that
the DSL ﬂoating-point protocols provide better (accuracy) guaran-
tees. For instance, we found out that some of the C++ protocols do
not handle 0 properly, some operations have poor relative errors,
and double-precision ﬂoating-point numbers provide very poor ac-
curacy guarantees (only in the range of 10−7). Providing fair com-
parison would either mean incorporating those defects into DSL
protocols or improving the C++ protocols. In both cases valuable
time is wasted. The poor accuracy guarantees of C++ protocols
are due to double-precision operations requiring the use of larger
than 128-bit integers which the old framework had diﬃculties with.
These diﬀerences give a performance advantage to C++ protocols
as they do not handle some of the cases and do not operate on inte-
gers as large as those used in the new protocols.
Experiments were performed on a cluster of 3 identical comput-
ers connected with a 10 Gigabit Ethernet network. Each computer
was equipped with 128GB DDR4 RAM, two 8 core Intel Xeon
(E5-2640 v3) processors and was running Debian Jessie (14th May
2015). Every protocol was benchmarked on various numbers of in-
puts: when executing a protocol in parallel on multiple inputs, the
round count remains the same while the amount of network com-
munication increases. On a decent network connection, the eval-
uation of the multiplication protocol on scalars, and on vectors of
length 10000, takes roughly the same time.
On each input length we have evaluated every protocol at least
twenty times; and up to few hundred times on smaller input sizes
in order to reduce variance. To estimate the execution time of a
protocol on some input length, we computed the mean of all mea-
surements on that length. The speedup was computed by dividing
the estimated execution time of the old protocol with the estimated
execution time of the respective DSL generated protocol. Speedup
greater than one means that the new protocol was, on average, faster
than the old one. All of the measurements were performance in an
identical setup, using the same unmodiﬁed software versions.
In Fig. 6(a) we can see the running time of the DSL and C++
ﬂoating-point multiplication protocols depending on the input size.
Notice how the running time is roughly constant up to around 500
elements after which the execution time grows linearly. We call this
point a saturation point because from this point on the execution
time is no longer latency bound and is limited by some other factors
(such as bandwidth or computation). Fig. 6(b) shows the speedup
of the protocol compared to the C++ version. We can see that the
new ﬂoating-point multiplication is between two to six times faster.
Complete benchmarking results are presented in Table 2. The
integer operations have been benchmarked on 32-bit integers and
ﬂoating-point protocols on single-precision numbers. We chose to
display only 32-bit versions because 64-bit integer division proto-
cols are not implemented in C++ and for the rest of the operations
the results are quite similar, mostly favouring DSL protocols. The
shift-right with a private value (a (cid:29) b) protocol has beneﬁted a lot
from a redesign in the DSL.
We can see that in every case the protocol DSL provides us an
improved ﬂoating-point arithmetic operation as we can expect the
protocols to run at least twice as fast. In many cases the DSL pro-
vides up to 10 times faster protocols. Some slowdown with integer
division operations was to be expected as they are very well tuned
medium-sized protocols. Still, past 10-element inputs we can see
some speedup in favour of the DSL. Integer multiplication is pro-
vided here as a pathological worst case for us: multiplication is a
very small and simple protocol that is easy to hand-tune and thus
we should not expect the DSL generated version to compete. This
a × b
a (cid:29) n
a (cid:29) b
a / n
a / b
x + y
x × y
√
1 / x
x
sin x
ln x
ex
erf x
100
1.12
0.90
2.13
0.78
0.90
2.62
1.74
1.91
2.50
9.23
12.29
5.33
4.71
101
0.96
1.07
4.31
0.73
1.02
2.87
1.89
2.42
3.33
10.62
12.68
6.55
12.32
102
0.90
1.36
13.56
1.54
1.33
3.65
3.28
3.79
5.01
13.10
14.32
10.47
29.02
103
1.05
2.36
28.35
2.65
1.27
4.38
4.21
3.95
5.81
12.62
11.12
11.48
36.32
104
1.10
2.11
35.97
2.67
1.05
3.93
4.18
3.95
5.81
9.50
7.83
10.97
41.73
105
0.68
1.32
27.99
3.03
0.95
3.79
4.37
3.90
5.96
Note: a and b denote 32-bit additively shared integers; n denotes 32-bit
public integer; x and y denote single-precision private ﬂoating-point num-
bers.
Table 2: Speedup in comparison to non-DSL protocols
is exactly so and we see a drastic drop in performance past 104-
element input vectors. We do not have a full explanation for this
drop, but one possibility is that the current multiplication proto-
col continues to compute intermediate values while some network
messages are being sent. The hand-tuned implementation might
also send messages in a more suitable pattern for the Sharemind’s
network layer.
We have also benchmarked private satellite collision analysis
from [23] using the new protocols. We see roughly 5-fold speedup,
going from 0.5 satellite pairs per second to 2.5 pairs per second.
When processing 100 pairs in parallel we gain a roughly 8-fold
speedup going from processing 0.7 pairs per second to 6 pairs per
second. This demonstrates that improving low-level ﬂoating-point
protocols can have a great eﬀect on high-level applications.
6. RELATED WORK
A fair number of languages for SMC have been proposed over
the years, aiming to simplify the implementation of SMC proto-
cols, and to allow the developer to concentrate on application logic.
Most of the languages concentrate purely on application logic, ex-
pecting the SMC runtime to invoke a speciﬁc protocol for each
operation on private values that occurs in the program. Such lan-
guages include SecreC [6] used in the Sharemind framework, and
SFDL, compiled into Boolean circuits in the FairplayMP frame-
work [2] based on garbled circuits [42].
In several systems, the privacy-preserving application is expressed
in some widely used programming language, possibly with some
restrictions and privacy-related annotations. The program is an-
alyzed and operations on private data replaced with calls to the
implementations of protocols for these operations. The resulting
program can be compiled, and results in an executable, distributed
application making use of SMC. The language used may be C [43],
Java [40], Python [24] or Haskell [35]. Alternatively, the program
may be translated into Boolean circuits [21], which are then opti-
mized [26] and garbled.
A number of proposed languages can express both the compu-
tations performed through SMC protocols, and the computations
performed privately by each participant [36, 20, 39, 33, 38]. They