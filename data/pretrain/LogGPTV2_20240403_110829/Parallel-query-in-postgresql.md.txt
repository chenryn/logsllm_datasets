# Parallel Query in PostgreSQL
**Amit Kapila | 2016.11.02**

© 2013 EDB All rights reserved.

## Contents
- Parallel Query Capabilities in 9.6
- Tuning Parameters
- Operations Where Parallel Query is Prohibited
- TPC-H Results
- Parallel Query Capabilities in Pipeline

## Parallel Query
PostgreSQL leverages parallel query to enhance the execution speed of queries on multi-CPU machines. This parallelism is achieved using background worker processes, allowing multiple processes to collaborate on a single SQL statement, which can significantly improve the performance of data-intensive operations.

## Parallel Query Capabilities in 9.6
### Parallel Sequential Scans
- **Transformation:**
  - `Seq Scan on foo` becomes:
    ```sql
    Gather
    Workers Planned: 2
    Workers Launched: 2
    -> Parallel Seq Scan on foo
    ```
  - **Description:**
    - Two workers and the master backend work together to scan the table 'foo'.
    - Such scans are particularly beneficial when the filter is highly selective or involves costly expressions like parallel-safe functions.

### Parallel Nested Loop Joins
- **Transformation:**
  - ```sql
    Gather
    Workers Planned: 2
    Workers Launched: 2
    -> Nested Loop
      -> Parallel Seq Scan on foo
      -> Index Scan using bar_pkey
        Index Cond: (b = foo.b)
    ```
  - **Description:**
    - Two workers and the master backend collaborate to perform a join between 'foo' and 'bar'.
    - This plan is advantageous if the join eliminates many rows, and a filter on the parallel sequential scan further enhances performance.

### Parallel Hash Joins
- **Transformation:**
  - ```sql
    Gather
    Workers Planned: 2
    -> Hash Join
      Hash Cond: (foo.b = bar.b)
      -> Parallel Seq Scan on foo
      -> Hash
        -> Seq Scan on bar
    ```
  - **Description:**
    - Each backend constructs its own copy of the hash table, using N copies of memory and N times the CPU.
    - This plan is effective if there is sufficient `work_mem` to accommodate the hash table in memory.

### Parallel Aggregates
- **Transformation:**
  - ```sql
    Finalize Aggregate
    -> Gather
      -> Partial Aggregate
        -> Nested Loop
          -> Parallel Seq Scan on foo
          -> Index Scan using bar_pkey
            Index Cond: (b = foo.b)
    ```
  - **Description:**
    - A new `PartialAggregate` node outputs transition states instead of final aggregate results, and a `FinalizeAggregate` node combines these transition states into the final result.
    - The aggregation step cannot be pushed below the `Gather`.

## Tuning Parameters
- **max_parallel_workers_per_gather:** 
  - Must be set to a value greater than 0. A value between 1 and 4 is recommended.
- **Other Parameters:**
  - `parallel_setup_cost`: Planner's estimate for launching parallel workers and initializing dynamic shared memory.
  - `parallel_tuple_cost`: Planner's estimate of the cost of transferring one tuple from a parallel worker process to another.
  - `min_parallel_relation_size`: Minimum size of relations to be considered for a parallel scan.
- **Table-Specific Setting:**
  - `CREATE TABLE … WITH (parallel_workers = 2);` sets the number of workers for a parallel scan of the table.
- **Worker Pool:**
  - Parallel workers are taken from the pool established by `max_worker_processes`.
  - If the actual number of workers used is less than planned, increase `max_worker_processes`.

## When Parallel Query is Prohibited
- **Data Modification:**
  - SQL statements that write data or lock any database rows.
- **Incremental Execution:**
  - Queries where partial or incremental execution might occur, such as those using `DECLARE CURSOR`.
- **Unsafe Functions:**
  - Queries using functions or aggregates marked as `PARALLEL UNSAFE`.
- **Unsupported Aggregations:**
  - Ordered set aggregates or queries involving `GROUPING SETS`.
- **Nested Parallel Queries:**
  - Queries running inside another query that is already parallel.
- **Transaction Isolation:**
  - Transactions with a serializable isolation level.
- **Single-User Mode:**
  - The system must not be running in single-user mode, as no background workers will be available.

## TPC-H Results
### Test Setup
- **Benchmark:**
  - TPC-H benchmark from http://tpc.org/tpch/default.asp
- **Environment:**
  - IBM POWER8 box
  - PostgreSQL 9.6
  - Non-default settings: `shared_buffers=8GB`, `work_mem=64MB`, `max_parallel_workers_per_gather = 0 vs 4`
  - 20GB of input data, 43GB database size

### Summary of Results
- **Parallelism Usage:**
  - 15 out of 22 queries used parallelism.
  - All 15 queries that used parallelism saw performance improvements.

### Query Results
- **Performance Improvements:**
  - Q1: 341 seconds → 77 seconds (4.4x)
  - Q3: 73 seconds → 38 seconds (1.9x)
  - Q4: 14 seconds → 10 seconds (1.4x)
  - Q5: 75 seconds → 38 seconds (1.9x)
  - Q6: 24 seconds → 11 seconds (2.2x)
  - Q7: 69 seconds → 31 seconds (2.2x)
  - Q8: 17 seconds → 8 seconds (2.1x)
  - Q9: 115 seconds → 112 seconds (1.02x)
  - Q10: 59 seconds → 31 seconds (1.9x)
  - Q12: 61 seconds → 19 seconds (3.2x)
  - Q16: 24 seconds → 23 seconds (1.04x)
  - Q17: 191 seconds → 91 seconds (2.1x)
  - Q19: 35 seconds → 14 seconds (2.5x)
  - Q21: 163 seconds → 129 seconds (1.3x)
  - Q22: 79 seconds → 63 seconds (1.3x)

### Take-Away
- **Scaling:**
  - Linear scaling with 4 workers would result in a 4.4x speedup; only 1 of the 22 queries achieved this.
  - Only 1 query had a speedup of 3x.
- **Resource Utilization:**
  - Each of the 15 queries that used parallelism consumed up to 5x the resources to produce a speedup that was sometimes much less than 5x.
  - 9 of those 15 queries ran close to twice or more than twice as fast, which is significant.

## Parallel Query Capabilities in Pipeline
### Gather Merge
- **Transformation:**
  - ```sql
    Gather Merge
    -> Sort
    -> Parallel Seq Scan on foo
    ```
  - **Description:**
    - The `Gather Merge` node assumes that the results from each worker are ordered and then performs a final merge.
    - This helps in cases where sorting tuples after a scan is required (both for sequential and index scans).

### TPC-H Q9 – Plan Without Gather Merge
- **Execution Time:**
  - 98206.793 ms
- **Plan:**
  - ```sql
    Limit (97.9 s, 1 row)
    -> GroupAggregate (97.9 s, 1 row)
    -> Sort (97.8 s, 11440 rows)
    -> Hash Join (74.7 s, 3246126 rows)
    -> Nested Loop (37.5 s, 3246126 rows)
    -> Hash Join (2.6 s, 432928 rows)
    -> Hash Join (2.2 s, 432928 rows)
    -> Gather (1.6 s, 432928 rows)
    Workers Launched: 4
    -> Nested Loop (1.01 s, 86586 rows, 5 loops)
    -> Parallel Seq Scan on public.part (0.4 s, 21646 rows, 5 loops)
    -> Index Scan using idx_partsupp_partkey (0.023 ms, 4 rows, 108232 loops)
    -> Hash (0.14 s, 100000 rows)
    -> Seq Scan on public.supplier (69.6 ms, 100000 rows)
    -> Hash (0.058 ms, 25 rows)
    -> Seq Scan on public.nation (0.026 ms, 25 rows)
    -> Index Scan using idx_lineitem_part_supp (0.072 ms, 7 rows, 432928 loops)
    -> Hash (20.4 s, 15000000 rows)
    -> Seq Scan on public.orders (10.2 s, 15000000 rows)
    ```

### TPC-H Q9 – Plan With Gather Merge
- **Execution Time:**
  - 52613.132 ms
- **Plan:**
  - ```sql
    Limit (52.5 s, 1 row)
    -> Finalize GroupAggregate (52.5 s, 1 row)
    -> Gather Merge (52546.571, 6 rows)
    Workers Launched: 4
    -> Partial GroupAggregate (50.9 s, 79 rows, 5 loops)
    -> Sort (49.6 s, 234178 rows, 5 loops)
    -> Hash Join (45 s, 649225 rows, 5 loops)
    -> Nested Loop (13.3 s, 649225 rows, 5 loops)
    -> Hash Join (1.9 s, 86586 rows, 5 loops)
    -> Nested Loop (1.3 s, 86586 rows, 5 loops)
    -> Parallel Seq Scan on public.part (0.6 s, 21646 rows, 5 loops)
    -> Index Scan using idx_partsupp_partkey (0.031 ms, 4 rows, 108232 loops)
    -> Hash (248 ms, 100000 rows, 5 loops)
    -> Hash Join (167 ms, 100000 rows, 5 loops)
    -> Seq Scan on public.supplier (48.532 ms, 100000 rows, 5 loops)
    -> Hash (0.044 ms, 25 rows, 5 loops)
    -> Seq Scan on public.nation (0.025 ms, 25 rows, 5 loops)
    -> Index Scan using idx_lineitem_part_supp (0.118 ms, 7 rows, 432928 loops)
    -> Hash (22.5 s, 15000000, 5 loops)
    -> Seq Scan on public.orders (11.5 s, 15000000 rows, 5 loops)
    ```

### Parallel Bitmap Scans
- **Transformation:**
  - ```sql
    Bitmap Heap Scan on foo
    -> Bitmap Index Scan on idx_foo
    ```
  - Becomes:
    ```sql
    Gather
    -> Parallel Bitmap Heap Scan on foo
    -> Bitmap Index Scan on idx_foo
    ```
  - **Description:**
    - One backend builds the TIDBitmap, and all workers collaborate to scan the table.
    - Benefits are visible up to 4 workers, after which a Parallel Seq Scan plan provides more benefit.

### TPC-H Q6 – Serial Plan
- **Execution Time:**
  - 40922.569 ms
- **Plan:**
  - ```sql
    Limit (actual time=40921.437..40921.438 rows=1 loops=1)
    -> Aggregate (actual time=40921.435..40921.435 rows=1 loops=1)
    -> Bitmap Heap Scan on lineitem (actual time=7032.075..38997.369 rows=1140434 loops=1)
    Recheck Cond: (..)
    -> Bitmap Index Scan on idx_lineitem_shipdate (actual time=6951.408..6951.408 rows=1140434 loops=1)
    Index Cond: (..)
    ```

### TPC-H Q6 – Parallel Plan
- **Execution Time:**
  - 21915.931 ms
- **Plan:**
  - ```sql
    Limit (actual time=21895.008..21895.009 rows=1 loops=1)
    -> Finalize Aggregate (actual time=21895.006..21895.006 rows=1 loops=1)
    -> Gather (actual time=21894.341..21894.970 rows=3 loops=1)
    Workers Planned: 2
    Workers Launched: 2
    -> Partial Aggregate (actual time=21890.990..21890.990 rows=1 loops=3)
    -> Parallel Bitmap Heap Scan on lineitem (actual time=8517.126..21215.469 rows=380145 loops=3)
    Recheck Cond: (..)
    -> Bitmap Index Scan on idx_lineitem_shipdate (actual time=8307.291..8307.291 rows=1140434 loops=1)
    Index Cond: (..)
    ```

### Parallel Index Scans
- **Transformation:**
  - ```sql
    Index Scan using idx_foo on foo
    Index Cond: (c < 10)
    ```
  - Becomes:
    ```sql
    Parallel Index Scan using idx_foo on foo
    Index Cond: (c < 10)
    ```

### Parallel Append
- **Current Implementation:**
  - ```sql
    Gather
    Workers Planned: 2
    -> Append
      -> Parallel Seq Scan on t1
      -> Parallel Seq Scan on t2
    ```
  - **Improved Plan:**
    - ```sql
      Gather
      Workers Planned: 2
      -> Append
        -> Parallel Seq Scan on t1
        -> Seq Scan on t2
      ```
  - **Description:**
    - Currently, each worker runs each partial plan serially, leading to suboptimal parallelism.
    - Allowing workers to run partial or non-partial nodes in parallel can help parallelize I/O when tables are on separate disks.

### Parallel Maintenance / DDL Commands
- **Vacuum:**
  - Parallel Heap Scan
  - Worker Per Index
- **Create Index:**
  - Parallel-aware tuplesort

## Acknowledgements
Thanks to Robert Haas for presenting the paper on Parallel Query in PostgreSQL at PGConf US 2016. Some slides in this presentation are from his paper, which can be downloaded from [here](https://sites.google.com/site/robertmhaas/presentations).

## Thanks!
---