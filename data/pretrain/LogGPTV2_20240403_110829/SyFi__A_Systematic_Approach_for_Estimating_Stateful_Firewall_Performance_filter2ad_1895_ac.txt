### Minimal Impact on Performance: Key Observations

Our approach is characterized by its minimal impact on performance, a key observation that enables it to be both simple and highly accurate. As we will demonstrate in Section 4, this simplicity does not compromise the accuracy of our method.

Once we have determined the firewall's performance in packets per second (pps), it is straightforward to convert this metric into any other unit preferred by the user. For example, the Traffic Translator II in our approach can compute firewall throughput in bytes per second (bps) if the average packet size is known.

### 4. Validation of the Model

In this section, we validate the accuracy of our model by comparing its predictions with actual measurements. We perform this validation in two scenarios:
1. Estimating a firewall's performance on normal traffic.
2. Estimating a firewall's performance under a SYN flood attack.

#### Normal Traffic

For the first part of our validation, we use the HP TMSzl firewall [4], which is different from the devices used to develop our model in Sections 2 and 3. We measure packet processing costs using the mechanism described in Section 2 for the four types of packets considered in our model.

We evaluate our model on four distinct profiles of normal traffic, which test variations in protocol type, packet size, and packet counts per flow. The four traffic profiles (TP1, TP2, TP3, and TP4) are as follows:

- **TP1 (Baseline Profile):** 20% of flows are TCP and 80% are UDP. UDP flows send 100 pps with an average packet size of 64 bytes, while TCP flows send 1000 pps with an average packet size of 512 bytes.
- **TP2 (Shorter Flows):** All parameters are the same as in TP1, but the number of packets per TCP and UDP flow is reduced to 10 and 1, respectively. This results in a higher rate of session creation, which is an expensive operation for stateful firewalls.
- **TP3 (Larger Packets):** Average packet sizes for TCP and UDP flows are increased to 1024 bytes and 512 bytes, respectively.
- **TP4 (HTTP-32K Profile):** Standard HTTP-32K traffic profile generated by our BPS traffic generation tool. Each HTTP flow contains 52 packets, including 3 packets each for TCP connection setup and teardown, 1 HTTP GET, 1 ACK for the HTTP GET, 22 TCP data packets, and 22 TCP ACK packets.

For each traffic profile, we measure the maximum throughput that the HP TMSzl firewall can support by generating the corresponding traffic and scaling up the rate until packet drops are observed. Figure 6(a) shows that our model's estimates are within 6% of the measured values for all four traffic profiles, highlighting its ability to accurately predict the effects of variations in flow duration, packet sizes, and protocol types.

#### Attack Traffic

To evaluate the utility of our model in scenarios involving attacks, we consider the problem of estimating firewall throughput under a SYN flood attack. We use three standard traffic patterns in our traffic generation tool: UDP flows with 1518 bytes of data, HTTP flows with 32 KB of data, and HTTP flows with 512 bytes of data on average. We subject the SonicWall firewall to these traffic patterns and launch 10,000 SYN packets per second in parallel. Figure 6(b) compares the measured values of the throughput sustained by the firewall with the corresponding estimates from our model. Our model's estimates are accurate with less than 10% error in all three traffic profiles.

The experiments reveal significant throughput changes when the traffic profile varies. Thus, the 5 Gbps data sheet throughput for the HP TMSzl [4] and the 3.9 Gbps throughput for the SonicWall [6] are overly optimistic.

Finally, we performed a preliminary investigation of the effect of the firewall's ruleset (i.e., the set of ACLs used to filter traffic) on session rate. We populated the firewall's ruleset with several DENY rules that do not match our test traffic and added a single rule at the bottom to permit the test traffic. We repeated this experiment on all three firewalls, varying the number of rules and the test traffic. In all cases, we found that the maximum session rate significantly declines with an increase in the number of rules.

### 5. Related Work

RFC 2544 [11] has been the leading network interconnecting device benchmarking methodology since 1999. RFC 2647 [22] extends the terminology established with definitions specific to firewalls, specifying device throughput to be tested with frames sized 64, 128, 256, 512, 1024, and 1518 bytes. Firewall vendors often exploit RFC 2544 by publishing throughput measurements in bytes/second conducted with full-sized (1,518 bytes) UDP packets only, which does not reflect a typical enterprise traffic mix.

Third-party testing agencies such as NSS [23] have challenged vendors by evaluating and comparing firewalls with respect to their performance, security, and stability. Although this is a step in the right direction, it does not address the customer's basic question of how the firewall will perform in their specific network, as the firewall's throughput varies significantly across traffic profiles.

The research community has focused on:
1. Optimizing firewall rules by reordering or removing redundant rules [7, 12, 17].
2. Detecting policy errors in a firewall's ruleset [21, 18, 9].
3. Detecting anomalies and vulnerabilities in firewalls [9, 24, 14].
4. Improving firewall design [16, 15] to prevent policy errors and anomalies.

To the best of our knowledge, there is no prior work that answers the question of what performance a given customer can expect from a particular firewall. Customers may end up buying a low-performing device that introduces a bottleneck or a high-performing device that is more expensive than necessary. In this paper, we resolve this issue systematically, and our model accurately computes the expected performance of a firewall using a profile of the traffic from the deployment environment.

Perhaps the most closely related work in terms of resource-based performance analysis is that of Dreger et al. [13]. They developed nidsconf, a tool that examines Intrusion Detection Systems' resource utilization on a sample traffic profile and derives configurations that prevent bursts of packet drops due to spikes in CPU and memory utilization.

### 6. Conclusions

Since performance numbers in firewall datasheets are often inflated, customers of stateful firewalls today rely on word-of-mouth recommendations. To make the process more scientific, we examined two state-of-the-art enterprise-level stateful firewalls to highlight the factors that affect their performance. Based on our observations that protocol and packet type matter for performance, but packet sizes and the number of concurrent sessions do not, we developed a model of firewall performance that takes as input characteristics of the particular firewall and the traffic at a target network. Our evaluations on a third firewall showed that our model can estimate throughput across different traffic profiles with over 90% accuracy.

In the future, we will study the performance impact of payload inspection and connection teardown packets.

### References

1. Comparison shopping for scalable firewall products, http://tinyurl.com/7smaqet
2. Data sheets lie: How to measure the performance, security and stability of network devices, http://resources.breakingpoint.com/acton/form/567/0024:d-0004/0/
3. Fortinet FortiGate-ONE, http://www.fortinet.com/products/fortigate/one.html
4. HP Threat Management Services zl module, http://h20195.www2.hp.com/v2/GetPDF.aspx/4AA2-6512ENN.pdf/
5. Next Generation Firewalls not ready to replace all legacy firewalls, http://searchnetworking.techtarget.com/news/1520651/Next-generation-firewalls-not-ready-to-replace-all-legacy-firewalls/
6. SonicWALL E-class network security appliance E5500, http://www.firewalls.com/sonicwall/sonicwall-firewall/sonicwall-e-class-series/
7. Acharya, S., Wang, J., Ge, Z., Zane, T.F., Greenberg, A.: Traffic-aware firewall optimization strategies. In: ICC (2006)
8. Al-Shaer, E., Hamed, H., Boutaba, R., Hasan, M.: Conflict classification and analysis of distributed firewall policies. In: IEEE JSAC (2005)
9. Baboescu, F., Varghese, G.: Fast and scalable conflict detection for packet classifiers. In: IEEE ICNP (2002)
10. BreakingPoint firewall performance testing, http://www.breakingpointsystems.com/solutions/firewall-testing/
11. Bradner, S., McQuaid, J.: Benchmarking methodology for network interconnect devices. RFC 2544 (1999)
12. Cohen, E., Lund, C.: Packet classification in large ISPs: Design and evaluation of decision tree classifiers. In: ACM SIGMETRICS (2005)
13. Dreger, H., Feldmann, A., Paxson, V., Sommer, R.: Predicting the Resource Consumption of Network Intrusion Detection Systems. In: Lippmann, R., Kirda, E., Trachtenberg, A. (eds.) RAID 2008. LNCS, vol. 5230, pp. 135â€“154. Springer, Heidelberg (2008)
14. El-Atawy, A., Al-Shaer, E., Tran, T., Boutaba, R.: Adaptive early packet filtering for protecting firewalls against DoS attacks. In: IEEE INFOCOM (2009)
15. Gouda, M.G., Liu, A., Jafry, M.: Verification of distributed firewalls. In: IEEE GLOBECOM (2008)
16. Gouda, M.G., Liu, A.X.: Structured firewall design. Computer Networks (2007)
17. Hamed, H., Al-Shaer, E.: Dynamic rule-ordering optimization for high-speed firewall filtering. In: ASIACCS (2006)
18. Hari, A., Suri, S., Parulkar, G.: Detecting and resolving packet filter conflicts. In: IEEE INFOCOM (2000)
19. Liu, A.X.: Change-impact analysis of firewall policies. In: European Symp. Research Computer Security (2007)
20. Liu, A.X.: Firewall policy verification and troubleshooting. In: ICC (2008)
21. Liu, A.X., Gouda, M.G.: Firewall policy queries. IEEE Trans. on Parallel and Distributed Systems (2009)
22. Newman, D.: Benchmarking terminology for firewall devices. RFC 2647 (1999)
23. NSS Labs. IPS, UTM, Web application firewall testing lab, http://nsslabs.com
24. Shaer, E.A., Hamed, H.: Discovery of policy anomalies in distributed firewalls. In: IEEE INFOCOM (2004)
25. Caceres, R.: Measurements of Wide-Area Internet Traffic, UCB/CSD.89/550, Univ. CA, Berkeley (1989)