```
import numpy as np
metrics.groupby(['node_id', 'http_status']).latency.aggregate(np.percentile, 99.999)
```
更多内容请参考 Jupyter notebook 在数据上的分析示例。
### 我应该监测什么？
一个软件系统有许多的变量，这些变量的值在它的生命周期中不停地发生变化。软件是运行在某种操作系统上的，而操作系统同时也在不停地变化。在我看来，当某些东西出错时，你所拥有的数据越多越好。
我建议去监测的关键操作系统指标有：
* CPU 使用
* 系统内存使用
* 文件描述符使用
* 磁盘使用
还需要监测的其它关键指标根据你的软件应用程序不同而不同。
#### 网络应用程序
如果你的软件是一个监听客户端请求和为它提供服务的网络应用程序，需要测量的关键指标还有：
* 入站请求数（计数器）
* 未处理的错误（计数器）
* 请求延迟（柱状图/计时器）
* 排队时间，如果在你的应用程序中有队列（柱状图/计时器）
* 队列大小，如果在你的应用程序中有队列（计量器）
* 工作进程/线程用量（计量器）
如果你的网络应用程序在一个客户端请求的环境中向其它服务发送请求，那么它应该有一个指标去记录它与那个服务之间的通讯行为。需要监测的关键指标包括请求数、请求延迟、和响应状态。
#### HTTP web 应用程序后端
HTTP 应用程序应该监测上面所列出的全部指标。除此之外，还应该按 HTTP 状态代码分组监测所有非 200 的 HTTP 状态代码的大致数据。如果你的 web 应用程序有用户注册和登录功能，同时也应该为这个功能设置指标。
#### 长时间运行的进程
长时间运行的进程如 Rabbit MQ 消费者或任务队列的工作进程，虽然它们不是网络服务，它们以选取一个任务并处理它的工作模型来运行。因此，我们应该监测请求的进程数和这些进程的请求延迟。
不管是什么类型的应用程序，都有指标与合适的**元数据**相关联。
### 将监测集成到一个 Python 应用程序中
将监测集成到 Python 应用程序中需要涉及到两个组件：
* 更新你的应用程序去计算和报告指标
* 配置一个监测基础设施来容纳应用程序的指标，并允许去查询它们
下面是记录和报告指标的基本思路：
```
def work():
    requests += 1
    # report counter
    start_time = time.time()
    # 
    # calculate and report latency
    work_latency = time.time() - start_time
    ...
```
考虑到上面的模式，我们经常使用修饰符、内容管理器、中间件（对于网络应用程序）所带来的好处去计算和报告指标。在 Demo 1 和 Demo 2 中，我们在一个 Flask 应用程序中使用修饰符。
#### 指标报告时的拉取和推送模型
大体来说，在一个 Python 应用程序中报告指标有两种模式。在 拉取 模型中，监测系统在一个预定义的 HTTP 端点上“刮取”应用程序。在推送 模型中，应用程序发送数据到监测系统。
![Pull and push models](/data/attachment/album/201809/14/095113wherxv3ghhy1xo1y.png "Pull and push models")
工作在 拉取 模型中的监测系统的一个例子是 [Prometheus](https://prometheus.io/)。而 [StatsD](https://github.com/etsy/statsd) 是 推送 模型的一个例子。
#### 集成 StatsD
将 StatsD 集成到一个 Python 应用程序中，我们将使用 [StatsD Python 客户端](https://pypi.python.org/pypi/statsd)，然后更新我们的指标报告部分的代码，调用合适的库去推送数据到 StatsD 中。
首先，我们需要去创建一个客户端实例：
```
statsd = statsd.StatsClient(host='statsd', port=8125, prefix='webapp1')
```
`prefix` 关键字参数将为通过这个客户端报告的所有指标添加一个指定的前缀。
一旦我们有了客户端，我们可以使用如下的代码为一个计时器报告值：
```
statsd.timing(key, resp_time)
```
增加计数器：
```
statsd.incr(key)
```
将指标关联到元数据上，一个键的定义为：`metadata1.metadata2.metric`，其中每个 metadataX 是一个可以进行聚合和分组的字段。
这个演示应用程序 [StatsD](https://github.com/amitsaha/python-monitoring-talk/tree/master/statsd) 是将 statsd 与 Python Flask 应用程序集成的一个完整示例。
#### 集成 Prometheus
要使用 Prometheus 监测系统，我们使用 [Promethius Python 客户端](https://pypi.python.org/pypi/prometheus_client)。我们将首先去创建有关的指标类对象：
```
REQUEST_LATENCY = Histogram('request_latency_seconds', 'Request latency',
    ['app_name', 'endpoint']
)
```
在上面的语句中的第三个参数是与这个指标相关的标识符。这些标识符是由与单个指标值相关联的元数据定义的。
去记录一个特定的观测指标：
```
REQUEST_LATENCY.labels('webapp', request.path).observe(resp_time)
```
下一步是在我们的应用程序中定义一个 Prometheus 能够刮取的 HTTP 端点。这通常是一个被称为 `/metrics` 的端点：
```
@app.route('/metrics')
def metrics():
    return Response(prometheus_client.generate_latest(), mimetype=CONTENT_TYPE_LATEST)
```
这个演示应用程序 [Prometheus](https://github.com/amitsaha/python-monitoring-talk/tree/master/prometheus) 是将 prometheus 与 Python Flask 应用程序集成的一个完整示例。
#### 哪个更好：StatsD 还是 Prometheus？
本能地想到的下一个问题便是：我应该使用 StatsD 还是 Prometheus？关于这个主题我写了几篇文章，你可能发现它们对你很有帮助：
* [使用 Prometheus 监测多进程 Python 应用的方式](http://echorand.me/your-options-for-monitoring-multi-process-python-applications-with-prometheus.html)
* [使用 Prometheus 监测你的同步 Python 应用](https://blog.codeship.com/monitoring-your-synchronous-python-web-applications-using-prometheus/)
* [使用 Prometheus 监测你的异步 Python 应用](https://blog.codeship.com/monitoring-your-asynchronous-python-web-applications-using-prometheus/)
### 指标的使用方式
我们已经学习了一些关于为什么要在我们的应用程序上配置监测的原因，而现在我们来更深入地研究其中的两个用法：报警和自动扩展。
#### 使用指标进行报警
指标的一个关键用途是创建警报。例如，假如过去的五分钟，你的 HTTP 500 的数量持续增加，你可能希望给相关的人发送一封电子邮件或页面提示。对于配置警报做什么取决于我们的监测设置。对于 Prometheus 我们可以使用 [Alertmanager](https://github.com/prometheus/alertmanager)，而对于 StatsD，我们使用 [Nagios](https://www.nagios.org/about/overview/)。
#### 使用指标进行自动扩展
在一个云基础设施中，如果我们当前的基础设施供应过量或供应不足，通过指标不仅可以让我们知道，还可以帮我们实现一个自动伸缩的策略。例如，如果在过去的五分钟里，在我们服务器上的工作进程使用率达到 90%，我们可以水平扩展。我们如何去扩展取决于云基础设施。AWS 的自动扩展，缺省情况下，扩展策略是基于系统的 CPU 使用率、网络流量、以及其它因素。然而，让基础设施伸缩的应用程序指标，我们必须发布 [自定义的 CloudWatch 指标](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html)。
### 在多服务架构中的应用程序监测
当我们超越一个单应用程序架构时，比如当客户端的请求在响应被发回之前，能够触发调用多个服务，就需要从我们的指标中获取更多的信息。我们需要一个统一的延迟视图指标，这样我们就能够知道响应这个请求时每个服务花费了多少时间。这可以用 [分布式跟踪](http://opentracing.io/documentation/) 来实现。
你可以在我的博客文章 《[在你的 Python 应用程序中通过 Zipkin 引入分布式跟踪](http://echorand.me/introducing-distributed-tracing-in-your-python-application-via-zipkin.html)》 中看到在 Python 中进行分布式跟踪的示例。
### 划重点
总之，你需要记住以下几点：
* 理解你的监测系统中指标类型的含义
* 知道监测系统需要的你的数据的测量单位
* 监测你的应用程序中的大多数关键组件
* 监测你的应用程序在它的大多数关键阶段的行为
以上要点是假设你不去管理你的监测系统。如果管理你的监测系统是你的工作的一部分，那么你还要考虑更多的问题！
### 其它资源
以下是我在我的监测学习过程中找到的一些非常有用的资源：
#### 综合的
* [监测分布式系统](https://landing.google.com/sre/book/chapters/monitoring-distributed-systems.html)
* [观测和监测最佳实践](http://www.integralist.co.uk/posts/monitoring-best-practices/?imm_mid=0fbebf&amp;cmp=em-webops-na-na-newsltr_20180309)
* [谁想使用秒？](https://www.robustperception.io/who-wants-seconds/)
#### StatsD/Graphite
* [StatsD 指标类型](https://github.com/etsy/statsd/blob/master/docs/metric_types.md)
#### Prometheus
* [Prometheus 指标类型](https://prometheus.io/docs/concepts/metric_types/)
* [Prometheus 计量器如何工作？](https://www.robustperception.io/how-does-a-prometheus-gauge-work/)
* [为什么用 Prometheus 累积柱形图？](https://www.robustperception.io/why-are-prometheus-histograms-cumulative/)
* [在 Python 中监测批量作业](https://www.robustperception.io/monitoring-batch-jobs-in-python/)
* [Prometheus：监测 SoundCloud](https://developers.soundcloud.com/blog/prometheus-monitoring-at-soundcloud)
### 避免犯错（即第 3 阶段的学习）
在我们学习监测的基本知识时，时刻注意不要犯错误是很重要的。以下是我偶然发现的一些很有见解的资源：
* [如何不测量延迟](https://www.youtube.com/watch?v=lJ8ydIuPFeU&amp;feature=youtu.be)
* [Prometheus 柱形图：悲伤的故事](http://linuxczar.net/blog/2017/06/15/prometheus-histogram-2/)
* [为什么平均值很讨厌，而百分位很棒](https://www.dynatrace.com/news/blog/why-averages-suck-and-percentiles-are-great/)
* [对延迟的认知错误](https://bravenewgeek.com/everything-you-know-about-latency-is-wrong/)
* [谁动了我的 99% 延迟？](https://engineering.linkedin.com/performance/who-moved-my-99th-percentile-latency)
* [日志、指标和图形](https://grafana.com/blog/2016/01/05/logs-and-metrics-and-graphs-oh-my/)
* [HdrHistogram：一个更好的延迟捕获方式](http://psy-lob-saw.blogspot.com.au/2015/02/hdrhistogram-better-latency-capture.html)
---
想学习更多内容，参与到 [PyCon Cleveland 2018](https://us.pycon.org/2018/) 上的 Amit Saha 的讨论，[Counter, gauge, upper 90—Oh my!](https://us.pycon.org/2018/schedule/presentation/133/)
### 关于作者
Amit Saha — 我是一名对基础设施、监测、和工具感兴趣的软件工程师。我是“用 Python 做数学”的作者和创始人，以及 Fedora Scientific Spin 维护者。
[关于我的更多信息](https://opensource.com/users/amitsaha)
---
via: 
作者: [Amit Saha](https://opensource.com/users/amitsaha) 选题者: [lujun9972](https://github.com/lujun9972) 译者: [qhwdw](https://github.com/qhwdw) 校对: [wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出