rows are discussed further in text.
ID
1
2
3
4
5
Source Script:Line Number
/lib/udev/console-setup-tty:76
/etc/rcS.d/S70x11-common:33,47
/usr/lib/pm-utils/functions:30
Source Type
Target Type
udev t
initrc t
initrc t
tty device t
tmp t
initrc var run t
/etc/NetM/dispatcher.d/01ifupdown:27,29 NetworkManager t
/etc/init/mounted-tmp.conf:44,45
init t
tmp t
tmp t
Table 3: Entry points in Bash scripts.
server/util.c:879
ID Source File:Line Number Object Type Accessed
1
2
3
4
5
server/core ﬁlters.c:155
server/core ﬁlters.c:383
server/connection.c:153
httpd user htaccess t
os/unix/unixd.c:410
httpd user script exec t
httpd user content t
httpd t
httpd t
Description
read user .htaccess ﬁle
read tcp socket
read user HTML ﬁle
read remaining tcp data
execute CGI user script
Conﬁg Option
AccessFileName
-
UserDir
-
Script
Table 4: Apache entry points receiving low-integrity data
generated by the Apache developers. We found 30 entry
points for the Apache webserver, of which 5 received un-
trusted operations. Details are in Table 4.
We located several entry points accessible to adversaries.
Network attacks being well understood, we list implications
of the entry points accessing local untrusted data (1, 3 and
5 in Table 4). httpd_user_htaccess_t denotes the user-
deﬁned conﬁguration ﬁle .htaccess. Previous problems with
this entry point are Bugtraq IDs 8911, 11182, 15177.
httpd_user_content_t are user-deﬁned web pages that
Apache serves. A vulnerability due to incorrect parsing of
the HTML ﬁles is BID 11471. Entry point 5 is where Apache
forks a child to execute a user-deﬁned CGI script - the exec
operation reads an untrusted executable is untrusted (BID
8275), and could easily be missed by manual analysis.
Secure Shell Daemon
As mentioned before, our tool was able to associate some
entry points with the conﬁguration option that controlled
the entry point; diﬀerent application conﬁgurations may ex-
pose diﬀerent attack surfaces. This knowledge is helpful to
administrators, who can view the eﬀect of their conﬁgura-
tion on the attack surface.
5.2.3
We also performed a study on the SSH daemon, sshd (v.
5.1p1). In total, there were 78 entry points, of which 27 re-
quired ﬁltering. 14 of these which correspond to overt input
are listed in Table 5. Entry points 12, 13 and 14 were opened
by non-default conﬁguration options. Of key interest, is that
OpenSSH has been re-engineered to separate the privileged
operations from those that are unprivileged to prevent vul-
nerabilities [25]. This work focuses on two attack surface
entry points that communicated data from the unprivileged
SSH daemon process to the privileged, master SSH daemon
process. Using our tool, we found another entry point (7)
that reads the authorized_keys ﬁle in the .ssh/ directory
of users. Since this is modiﬁable by users, it could be of low
integrity [28], and our wall indicates this. This entry point
was also missed in a manual analysis to conﬁgure SELinux
policies to enforce privilege separation [29], showing the im-
portance of an automated technique like ours. Entry points
13, 14 may present similar issues for those conﬁgurations.
Icecat
5.2.4
We also performed a study on the GNU version of Fire-
fox, Icecat. The objective of this study was to look at a
relatively less-known project, to see if we could ﬁnd any
problems using our tool. We envision this to be a typical
use-case of our tool. In total, we found 18 entry points for
Icecat, of which 4 accessed untrusted data. On closer exam-
ination of the attack surface, we found an entry point that
searched the directory user_home_dir_t, whose code was
in the dynamic loader/linker library ld.so. We suspected
an untrusted library search path, and conﬁrmed that this
indeed was the case. This could easily be exploited by an
adversary-controlled library that the user downloads to her
home directory. The developers accepted our patch [5].
5.3 Performance
Micro- and macro-benchmarks showed acceptable perfor-
mance overheads for online logging and enforcement. For
example, stat system call takes an unmodiﬁed kernel took
8.5µs on average. Overhead for checking if the subject was
trusted and the object was untrusted took an additional
0.2µs. If the access was untrusted, the logging mode added
an overhead of 1µs, whereas the enforcement mode added
an overhead of 0.1µs. The sshd test suite ran in 318.29s on
the unmodiﬁed kernel, whereas conﬁgured with an integrity
wall for sshd with both enforcement and logging enabled
took 318.81s.
6. RELATED WORK
Taint tracking has been used to track the ﬂow of untrusted
input to a program, and ﬁnd places where it may aﬀect the
integrity of the program. Tracking can be done for whole
systems [4, 8] or for speciﬁc processes [19, 26]. However,
these systems expect manual speciﬁcations of taint entry
points. For example, [19] considers data “originating from
or arithmetically derived from untrusted sources such as the
network as tainted”. However, it is not clear that all entry
points that receive low integrity data are locatable manually.
Our tool provides this origin input to taint tracking systems.
Manadhata et al. [17] calculate an attack surface metric
for programs based on methods, channels and data. They
prepare a list of input and output library calls from libc
that are used to determine the methods. Although this is
msg.c:72
msg.c:84
sshd.c:442
dispatch.c:92
packet.c:1005
misc.c:627
monitor wrap.c: 123
ID Source File:Line Number Object Type Accessed
1*
2
3
4
5
6
7*
8*
10
11
12
13*
14*
channels.c:1496
serverloop.c:380
loginrec.c:1423
session.c:1001
hostﬁle.c:222
initrc var run t
user home ssh t
user home ssh t
user home ssh t
sshd t
sshd t
sshd t
sshd t
sshd t
sshd t
user home ssh t
ptmx t
sshd t
auth-rhosts.c:82
Description
Conﬁg Option
Master-slave Unix socket read
UsePrivilegeSeparation
Unix socket read
Unix socket read
TCP socket read
TCP socket read
TCP socket read
∼/.ssh/.authorized keys ﬁle read
pseudo-terminal read
ﬁfo ﬁle read
read utmp
∼/.ssh/.environment ﬁle read
∼/.ssh/known hosts ﬁle read
∼/.ssh/.rhosts ﬁle read
-
-
-
-
-
AuthorizedKeysFile
-
-
-
PermitUserEnvironment
IgnoreUserKnownHosts
IgnoreRhosts
Table 5: sshd entry points that may receive low-integrity data. Entry points marked with * are in the master part of the privilege-
separated daemon.
useful for a ﬁrst approximation, it does not distinguish be-
tween entry points receiving high-integrity input and those
receiving low-integrity input. In our analysis, only a small
percentage (13.8%) of the entry points were found to re-
ceive data of low-integrity. Hence, a simple listing of all
such library methods may not give a true picture of work
required to secure an application. Further, a library may be
called through several layers of libraries, and the context of a
lower-layer library call may not be relevant through several
layers. We identify the point in the application that receives
low-integrity input, which is more helpful to application de-
velopers than a low-level library function that may be called
in diﬀerent contexts.
Several practical integrity models [16, 31, 29, 15] are re-
lated to our work. UMIP [16] and PPI [31] identify trusted
subjects that need to maintain their integrity on receiving
low-integrity input. Though their goals diﬀer from ours,
they also build integrity walls. UMIP builds integrity walls
system-wide based on the DAC policy, whereas PPI uses
package dependencies for the same. However, they iden-
tify trusted processes as a whole and do not identify entry
points within a process, which we have seen to be necessary.
Further, they only consider system-wide integrity walls, and
not per-application. Flume [15] allows entry point-level con-
trol, but leaves the speciﬁcation of the policy up to the user,
who has to decide which entry points to allow to receive un-
trusted input. Such policy could beneﬁt from knowledge of
the attack surface. Shankar et. al [29] identify that we need
to verify input ﬁltering for entry points that receive low-
integrity input. However, they identify entry points manu-
ally, and missed an entry point in sshd that we identiﬁed
using our automated approach.
Bouncer is a system that uses knowledge of vulnerabili-
ties to generate ﬁlters automatically [10].
It symbolically
executes the vulnerable program to build a ﬁlter that covers
the particular attack and generalizes the ﬁlter to cover other
unauthorized inputs without preventing legitimate function.
EXE automatically generates inputs that will crash a pro-
gram [6]. Both of these systems would beneﬁt from knowl-
edge of the attack surface of a program. In the latter case,
this will focus use on legitimate entry points for consider-
ation. The inputs that cause failure may then be used to
generate ﬁlters via Bouncer.
We could also have leveraged system call interposition [24,
12, 1, 3, 11] to monitor objects accessed by a program, in-
stead of doing it in the kernel. However, as noted in Sec-
tion 3.2, we have to maintain a list of system calls that causes
inputs, know the sets of objects accessed by each of these
calls, and fetch the security contexts of these objects from
the kernel – all duplicating information readily available in
the kernel. Also, system call interposition has high overhead
and is challenging to do system-wide.
7. CONCLUSION
In this paper, we introduced an approach to identify at-
tack surfaces in programs with respect to an integrity wall
constructed from the system’s security policy. We imple-
mented a system in the Linux kernel that enabled precise
identiﬁcation of attack surface entry points, even in inter-
preter scripts. Our results indicate that accurate location
of attack surfaces requires considering a program in relation
to the system’s access control policy. For the system TCB
in an Ubuntu 10.04.2 Desktop system, we obtained an at-
tack surface of 81 entry points, some subtle; 35 of these have
had past vulnerabilities, many recently. Our attack surface
indicated an entry point in sshd that was missed by ear-
lier manual analysis, and an entry point in the GNU Icecat
browser that was due to an untrusted search path bug. Fur-
ther, our attack surface helped us ﬁnd a bug in an entry
point of the system TCB of Ubuntu that has been around
for several years. We envision that our tool will be used on
new programs to identify attack surfaces before an adver-
sary does and prepare defenses, moving us away from the
current penetrate-and-patch paradigm.
8. REFERENCES
[1] A. Acharya et al. MAPbox: Using parameterized
behavior classes to conﬁne untrusted applications. In
USENIX Security, 2000.
[2] J. P. Anderson. Computer Security Technology
Planning Study, Volume II. Technical Report
ESD-TR-73-51, Deputy for Command and
Management Systems, HQ Electronics Systems
Division (AFSC), L. G. Hanscom Field, Bedford, MA,
October 1972.
[3] A. Berman et al. TRON: Process-speciﬁc ﬁle
protection for the UNIX operating system. In
USENIX TC ’95, 1995.
[4] E. Bertino et al . A system to specify and manage
multipolicy access control models. In POLICY, 2002.
[5] run-icecat.sh possible vulnerability.
http://lists.gnu.org/archive/html/
bug-gnuzilla/2011-06/msg00006.html.
[6] C. Cadar el. al . EXE: Automatically Generating
Inputs of Death. ACM Trans. Inf. Syst. Secur., 2008.
[7] H. Chen et al . Analyzing and Comparing the
Protection Quality of Security Enhanced Operating
Systems. In NDSS, 2009.
[8] J. Chow et al . Understanding data lifetime via whole
system simulation. In USENIX Security ’04, 2004.
[9] D. D. Clark et al . A Comparison of Military and
Commercial Security Policies. In IEEE SSP ’87, 1987.
[10] M. Costa et al . Bouncer: securing software by
blocking bad input. In SOSP ’07, 2007.
[11] T. Garﬁnkel et al. Ostia: A delegating architecture for
secure system call interposition. In NDSS ’04, 2004.
[12] I. Goldberg et al. A secure environment for untrusted
helper applications. In USENIX Security ’96, 1996.
[13] M. Howard et al . Measuring Relative Attack
Surfaces. In WADIS ’03, 2003.
[14] T. Jaeger, R. Sailer, and X. Zhang. Analyzing
integrity protection in the SELinux example policy. In
Proceedings of the 12th USENIX Security Symposium,
pages 59–74, Aug. 2003.
[15] M. N. Krohn et al . Information ﬂow control for
standard OS abstractions. In SOSP ’07, 2007.
[16] N. Li et al . Usable Mandatory Integrity Protection
For Operating Systems. In IEEE SSP ’07, 2007.
[17] P. Manadhata et al . An Approach to Measuring A
System’s Attack Surface. Technical Report
CMU-CS-07-146, CMU, 2007.
[18] P. K. Manadhata et al . An attack surface metric.
IEEE Trans. Software Eng., 2011.
[19] J. Newsome et al . Dynamic taint analysis for
automatic detection, analysis, and signaturegeneration
of exploits on commodity software. In NDSS, 2005.
[20] S. Noel et al . Eﬃcient minimum-cost network
hardening via exploit dependency graphs. In ACSAC,
2003.
[21] Novell. AppArmor Linux Application Security.
http://www.novell.com/linux/security/apparmor/.
[22] Selinux. http://www.nsa.gov/selinux.
[23] X. Ou et al . A scalable approach to attack graph
generation. In CCS ’06, New York, NY, USA, 2006.
[24] N. Provos. Improving host security with system call
policies. In USENIX Security ’02, 2002.
[25] N. Provos et al . Preventing privilege escalation. In
USENIX Security ’03, 2003.
[26] F. Qin et al . LIFT: A Low-Overhead Practical
Information Flow Tracking System for Detecting
Security Attacks. In MICRO 39, 2006.
[27] S. Rueda, D. King, and T. Jaeger. Verifying
Compliance of Trusted Programs. In Proceedings of
the 17th USENIX Security Symposium, 2008.
[28] SecurityFocus. BugTraq Mailing List.
http://www.securityfocus.com/bid/1334.
[29] U. Shankar, T. Jaeger, and R. Sailer. Toward
Automated Information-Flow Integrity Veriﬁcation for
Security-Critical Applications. In Proceedings of the
2006 ISOC Networked and Distributed Systems
Security Symposium, February 2006.
[30] O. Sheyner et al . Automated generation and analysis
of attack graphs. In IEEE SSP ’02, 2002.
[31] W. Sun et al . Practical Proactive Integrity
Preservation: A Basis for Malware Defense. In IEEE
SSP ’08, 2008.
[32] Sun Microsystems. Trusted solaris operating
environment. http://www.sun.com.
[33] Tresys. Setools - policy analysis tools for selinux.
http://oss.tresys.com/projects/setools.
[34] Tresys. SETools - Policy Analysis Tools for SELinux.
Available at http://oss.tresys.com/projects/setools.
http://oss.tresys.com/projects/setools.
[35] R. N. M. Watson. TrustedBSD: Adding trusted
operating system features to FreeBSD. In USENIX
ATC ’01 FREENIX Track, 2001.
[36] C. Wright et al . Linux security modules: General
security support for the Linux kernel. In USENIX
Security ’02, 2002.
[37] N. Zeldovich et al . Making information ﬂow explicit
in HiStar. In OSDI ’06, 2006.