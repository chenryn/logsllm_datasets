# 18 \| 消息投递：如何保证消息仅仅被消费一次？你好，我是唐扬。 经过上一节课，我们在电商系统中增加了消息队列，用它来对峰值写流量做削峰填谷，对次要的业务逻辑做异步处理，对不同的系统模块做解耦合。因为业务逻辑从同步代码中移除了，所以，我们也要有相应的队列处理程序来处理消息、执行业务逻辑，**这时，你的系统架构变成了下面的样子：** ![](Images/9beb91f6e58db63dd73b610b8b681999.png)savepage-src="https://static001.geekbang.org/resource/image/c9/a6/c9f44acbc4025b2ff1f0a4b9fd0941a6.jpg"}这是一个简化版的架构图，实际上，随着业务逻辑越来越复杂，会引入更多的外部系统和服务来解决业务上的问题。比如说，我们会引入Elasticsearch来解决商品和店铺搜索的问题，也会引入审核系统，来对售卖的商品、用户的评论做自动的和人工的审核，你会越来越多地使用消息队列与外部系统解耦合，以及提升系统性能。 比如说，你的电商系统需要上一个新的红包功能：用户在购买一定数量的商品之后，由你的系统给用户发一个现金的红包，鼓励用户消费。由于发放红包的过程不应该在购买商品的主流程之内，所以你考虑使用消息队列来异步处理。**这时，你发现了一个问题：**如果消息在投递的过程中发生丢失，那么用户就会因为没有得到红包而投诉。相反，如果消息在投递的过程中出现了重复，那么你的系统就会因为发送两个红包而损失。 那么我们如何保证，产生的消息一定会被消费到，并且只被消费一次呢？这个问题虽然听起来很浅显，很好理解，但是实际上却藏着很多玄机，本节课我就带你深入探讨。 消息为什么会丢失如果要保证消息只被消费一次，首先就要保证消息不会丢失。那么消息从被写入到消息队列，到被消费者消费完成，这个链路上会有哪些地方存在丢失消息的可能呢？其实，主要存在三个场景： 1.  消息从生产者写入到消息队列的过程。        2.  消息在消息队列中的存储场景。        3.  消息被消费者消费的过程。        ![](Images/9e964c10da0ba91dc736e70481ce7f3a.png)savepage-src="https://static001.geekbang.org/resource/image/4c/bc/4c43b9c64c6125ad107fd91e4fcc27bc.jpg"}接下来，我就针对每一个场景，详细地剖析一下，这样你可以针对不同的场景选择合适的，减少消息丢失的解决方案。 1. 在消息生产的过程中丢失消息在这个环节中主要有两种情况。 首先，消息的生产者一般是我们的业务服务器，消息队列是独立部署在单独的服务器上的。两者之间的网络虽然是内网，但是也会存在抖动的可能，而一旦发生抖动，消息就有可能因为网络的错误而丢失。 **针对这种情况，我建议你采用的方案是消息重传：**也就是当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试2～3 次就可以了。 不过，这种方案可能会造成消息的重复，从而导致在消费的时候会重复消费同样的消息。比方说，消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功，但在生产端却超时了，生产者重传这条消息就会形成重复的消息，那么针对上面的例子，直观显示在你面前的就会是你收到了两个现金红包。 那么消息发送到了消息队列之后是否就万无一失了呢？当然不是，**在消息队列中消息仍然有丢失的风险。** 2. 在消息队列中丢失消息拿 Kafka 举例，消息在 Kafka中是存储在本地磁盘上的，而为了减少消息存储时对磁盘的随机I/O，我们一般会将消息先写入到操作系统的 Page Cache中，然后再找合适的时机刷新到磁盘上。 比如，Kafka可以配置当达到某一时间间隔，或者累积一定的消息数量的时候再刷盘，**也就是所说的异步刷盘。** 来看一个形象的比喻：假如你经营一个图书馆，读者每还一本书你都要去把图书归位，不仅工作量大而且效率低下，但是如果你可以选择每隔3小时，或者图书达到一定数量的时候再把图书归位，这样可以把同一类型的书一起归位，节省了查找图书位置的时间，这样就可以提高效率了。 不过，如果发生机器掉电或者机器异常重启，那么 Page Cache中还没有来得及刷盘的消息就会丢失了。**那么怎么解决呢？** 你可能会把刷盘的间隔设置很短，或者设置累积一条消息就就刷盘，但这样频繁刷盘会对性能有比较大的影响，而且从经验来看，出现机器宕机或者掉电的几率也不高，**所以我不建议你这样做。** ![](Images/a7142c181d1b27175355f080e637015f.png)savepage-src="https://static001.geekbang.org/resource/image/6c/43/6c667c8c21baf27468c314105e522243.jpg"}如果你的电商系统对消息丢失的容忍度很低，**那么你可以考虑以集群方式部署 Kafka服务，通过部署多个副本备份数据，保证消息尽量不丢失。** 那么它是怎么实现的呢？ Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower负责数据的备份。Follower 中有一个特殊的集合叫做 ISR（in-syncreplicas），当 Leader 故障时，新选举出来的 Leader 会从 ISR 中选择，默认Leader 的数据会异步地复制给 Follower，这样在 Leader发生掉电或者宕机时，Kafka 会从 Follower中消费消息，减少消息丢失的可能。 由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader宕机，那些还没有来得及复制到 Follower的消息还是会丢失。为了解决这个问题，Kafka为生产者提供一个选项叫做"acks"，当这个选项被设置为"all"时，生产者发送的每一条消息除了发给Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR都挂了，消息才会丢失。 ![](Images/189daf5760b2761c90bc4ee10a45273f.png)savepage-src="https://static001.geekbang.org/resource/image/64/3f/648951000b3c7e969f8d04e42da6ac3f.jpg"}从上面这张图来看，当设置"acks=all"时，需要同步执行 1，3，4三个步骤，对于消息生产的性能来说也是有比较大的影响的，所以你在实际应用中需要仔细地权衡考量。**我给你的建议是：** 1.如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是需要使用集群的方式来解决，可以配置当所有ISR Follower都接收到消息才返回成功。 2.如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个Follower 就可以返回成功了。 3.我们的业务系统一般对于消息的丢失有一定的容忍度，比如说以上面的红包系统为例，如果红包消息丢失了，我们只要后续给没有发送红包的用户补发红包就好了。 3. 在消费的过程中存在消息丢失的可能我还是以 Kafka为例来说明。一个消费者消费消息的进度是记录在消息队列集群中的，而消费的过程分为三步：接收消息、处理消息、更新消费进度。 这里面接收消息和处理消息的过程都可能会发生异常或者失败，比如说，消息接收时网络发生抖动，导致消息并没有被正确的接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，那么这条失败的消息就永远不会被处理了，也可以认为是丢失了。 **所以，在这里你需要注意的是，**一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。 如何保证消息只被消费一次从上面的分析中，你能发现，为了避免消息丢失，我们需要付出两方面的代价：一方面是性能的损耗；一方面可能造成消息重复消费。 性能的损耗我们还可以接受，因为一般业务系统只有在写请求时才会有发送消息队列的操作，而一般系统的写请求的量级并不高，但是消息一旦被重复消费，就会造成业务逻辑处理的错误。那么我们要如何避免消息的重复呢？ 想要完全的避免消息重复的发生是很难做到的，因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的，在工业上并没有成熟的方法，因此我们会把要求放宽，只要保证即使消费到了重复的消息，从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是"幂等"的。 1. 什么是幂等幂等是一个数学上的概念，它的含义是多次执行同一个操作和执行一次操作，最终得到的结果是相同的，说起来可能有些抽象，我给你举个例子： 比如，男生和女生吵架，女生抓住一个点不放，传递"你不在乎我了吗？"（生产消息）的信息。那么当多次埋怨"你不在乎我了吗？"的时候（多次生产相同消息），她不知道的是，男生的耳朵（消息处理）会自动把N多次的信息屏蔽，就像只听到一次一样，这就是幂等性。 如果我们消费一条消息的时候，要给现有的库存数量减1，那么如果消费两条相同的消息就会给库存数量减2，这就不是幂等的。而如果消费一条消息后，处理逻辑是将库存的数量设置为0，或者是如果当前库存数量是 10 时则减1，这样在消费多条消息时，所得到的结果就是相同的，**这就是幂等的。** **说白了，你可以这么理解"幂等"：**一件事儿无论做多少次都和做一次产生的结果是一样的，那么这件事儿就具有幂等性。 2. 在生产、消费过程中增加消息幂等性的保证消息在生产和消费的过程中都可能会产生重复，所以你要做的是，在生产过程和消费过程中增加消息幂等性的保证，这样就可以认为从"最终结果上来看"，消息实际上是只被消费了一次的。 **在消息生产过程中，**在 Kafka0.11 版本和 Pulsar 中都支持"produceridempotency"的特性，翻译过来就是生产过程的幂等性，这种特性保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。 它的做法是给每一个生产者一个唯一的ID，并且为生产的每一条消息赋予一个唯一 ID，消息队列的服务端会存储 \的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID是否与存储的最后一条 ID一致，如果一致，就认为是重复的消息，服务端会自动丢弃。 ![](Images/e2d05a7c4d501b7fe69f258947788006.png)savepage-src="https://static001.geekbang.org/resource/image/aa/bd/aab832cee23258972c41e03493b8e0bd.jpg"}**而在消费端，****幂等性的保证会稍微复杂一些，你可以从****通用层和业务层**两个层面来考虑。 在通用层面，你可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息ID，消息被处理之后，把这个 ID存储在数据库中，在处理下一条消息之前，先从数据库里面查询这个全局 ID是否被消费过，如果被消费过就放弃消费。 你可以看到，无论是生产端的幂等性保证方式，还是消费端通用的幂等性保证方式，它们的共同特点都是为每一个消息生成一个唯一的ID，然后在使用这个消息的时候，先比对这个 ID是否已经存在，如果存在，则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式，**你在项目之中可以拿来直接使用，**它在逻辑上的伪代码就像下面这样：     boolean isIDExisted = selectByID(ID); // 判断 ID 是否存在    if(isIDExisted) {      return; // 存在则直接返回    } else {      process(message); // 不存在，则处理消息      saveID(ID);   // 存储 ID    }**不过这样会有一个问题：**如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败，但是这样消息处理的成本就更高了，所以，如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务。 **在业务层面怎么处理呢？**这里有很多种处理方式，其中有一种是增加乐观锁的方式。比如，你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。 **具体的操作方式是这样的：**你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额SQL的时候带上版本号，类似于执行：     update user set amount = amount + 20, version=version+1 where userId=1 and version=1;你看，我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version值为 1，SQL 可以执行成功，并且同时把 version 值改为了2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL不能执行成功，也就保证了消息的幂等性。 课程小结本节课，我主要带你了解了在消息队列中，消息可能会发生丢失的场景，和我们的应对方法，以及在消息重复的场景下，你要如何保证，尽量不影响消息最终的处理结果。我想强调的重点是： 1.  消息的丢失可以通过生产端的重试、消息队列配置集群模式，以及消费端合理处理消费进度三个方式来解决。        2.  为了解决消息的丢失通常会造成性能上的问题以及消息的重复问题。        3.  通过保证消息处理的幂等性可以解决消息的重复问题。        虽然我讲了很多应对消息丢失的方法，但并不是说消息丢失一定不能被接受，毕竟你可以看到，在允许消息丢失的情况下，消息队列的性能更好，方案实现的复杂度也最低。比如像是日志处理的场景，日志存在的意义在于排查系统的问题，而系统出现问题的几率不高，偶发的丢失几条日志是可以接受的。 **所以方案设计看场景，这是一切设计的原则，**你不能把所有的消息队列都配置成防止消息丢失的方式，也不能要求所有的业务处理逻辑都要支持幂等性，这样会给开发和运维带来额外的负担。 思考时间我提到了消息队列在生产和消费端需要保证消息处理的幂等性，那么你还了解哪些保证消息处理幂等性的方法呢？欢迎在留言区与我分享你的经验。 最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。 ![](Images/5cef34b7fbf24f9dd9c2c4c485c9dd17.png)savepage-src="https://static001.geekbang.org/resource/image/72/1a/72b203e2c1ec97d268a5eead610bf71a.jpg"}
# 19 \| 消息队列：如何降低消息队列系统中消息的延迟？你好，我是唐扬。 学完前面两节课之后，相信你对在垂直电商项目中，如何使用消息队列应对秒杀时的峰值流量已经有所了解。当然了，你也应该知道要如何做，才能保证消息不会丢失，尽量避免消息重复带来的影响。**那么我想让你思考一下：**除了这些内容，你在使用消息队列时还需要关注哪些点呢？ **先来看一个场景：**在你的垂直电商项目中，你会在用户下单支付之后，向消息队列里面发送一条消息，队列处理程序消费了消息后，会增加用户的积分，或者给用户发送优惠券。那么用户在下单之后，等待几分钟或者十几分钟拿到积分和优惠券是可以接受的，但是一旦消息队列出现大量堆积，用户消费完成后几小时还拿到优惠券，那就会有用户投诉了。 这时，你要关注的就是消息队列中，消息的延迟了，这其实是消费性能的问题，那么你要如何提升消费性能，保证更短的消息延迟呢？**在我看来，**你首先需要掌握如何来监控消息的延迟，因为有了数据之后，你才可以知道目前的延迟数据是否满足要求，也可以评估优化之后的效果。然后，你要掌握使用消息队列的正确姿势，以及关注消息队列本身是如何保证消息尽快被存储和投递的。 接下来，我们先来看看第一点：如何监控消息延迟。 如何监控消息延迟在我看来，监控消息的延迟有两种方式： 1.  使用消息队列提供的工具，通过监控消息的堆积来完成；        2.  通过生成监控消息的方式来监控消息的延迟情况。        接下来，我带你实际了解一下。 假设在开篇的场景之下，电商系统中的消息队列已经堆积了大量的消息，那么你要想监控消息的堆积情况，首先需要从原理上了解，在消息队列中消费者的消费进度是多少，因为这样才方便计算当前的消费延迟是多少。比方说，生产者向队列中一共生产了1000 条消息，某一个消费者消费进度是 900 条，那么这个消费者的消费延迟就是100 条消息。 **在 Kafka中，消费者的消费进度在不同的版本上是不同的。** 在 Kafka0.9 之前的版本中，消费进度是存储在 ZooKeeper中的，消费者在消费消息的时候，先要从 ZooKeeper中获取最新的消费进度，再从这个进度的基础上消费后面的消息。 在 Kafka0.9 版本之后，消费进度被迁入到 Kakfa 的一个专门的 topic叫"\_\_consumer_offsets"里面。所以，如果你了解 kafka的原理，你可以依据不同的版本，从不同的位置，获取到这个消费进度的信息。 当然，作为一个成熟的组件，Kafka也提供了一些工具来获取这个消费进度的信息，帮助你实现自己的监控，这个工具主要有两个： **首先，Kafka提供了工具叫做"kafka-consumer-groups.sh"**（它在 Kafka 安装包的 bin目录下）。 为了帮助你理解，我简单地搭建了一个 Kafka节点，并且写入和消费了一些信息，然后我来使用命令看看消息累积情况，具体的命令如下：     ./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group test-consumer-group结果如下： ![](Images/91124eb04311dced57d71777a607f387.png)savepage-src="https://static001.geekbang.org/resource/image/40/4b/404811b07db8edb4c1bb9f1cfc0bc94b.jpg"}1.  图中的前两列是队列的基本信息，包括话题名和分区名；        2.  第三列是当前消费者的消费进度；        3.  第四列是当前生产消息的总数；        4.  第五列就是消费消息的堆积数（也就是第四列与第三列的差值）。        通过这个命令你可以很方便地了解消费者的消费情况。 **其次，第二个工具是 JMX。** Kafka 通过 JMX 暴露了消息堆积的数据，我在本地启动了一个 consoleconsumer，然后使用 jconsole 连接这个 consumer，你就可以看到这个 consumer的堆积数据了（就是下图中红框里的数据）。这些数据你可以写代码来获取，这样也可以方便地输出到监控系统中，**我比较推荐这种方式。** ![](Images/d224de8d9bbf2f46f354ec20a355fb2f.png)savepage-src="https://static001.geekbang.org/resource/image/33/2c/3384d3fcb52f98815fac667e5b543e2c.jpg"}除了使用消息队列提供的工具以外，你还可以通过生成监控消息的方式，来监控消息的延迟。**具体怎么做呢？** 你先定义一种特殊的消息，然后启动一个监控程序，将这个消息定时地循环写入到消息队列中，消息的内容可以是生成消息的时间戳，并且也会作为队列的消费者消费数据。业务处理程序消费到这个消息时直接丢弃掉，而监控程序在消费到这个消息时，就可以和这个消息的生成时间做比较，如果时间差达到某一个阈值就可以向我们报警。 ![](Images/860b86fc68b1991427c6d1d7556965ae.png)savepage-src="https://static001.geekbang.org/resource/image/34/7f/34820c0b27e66af37fda116a1a98347f.jpg"}这两种方式都可以监控消息的消费延迟情况，**而从我的经验出来，我比较推荐两种方式结合来使用。**比如在我的实际项目中，我会优先在监控程序中获取 JMX中的队列堆积数据，做到 dashboard报表中，同时也会启动探测进程，确认消息的延迟情况是怎样的。 在我看来，消息的堆积是对于消息队列的基础监控，这是你无论如何都要做的。但是，了解了消息的堆积情况，并不能很直观地了解消息消费的延迟，你也只能利用经验来确定堆积的消息量到了多少才会影响到用户的体验；而第二种方式对于消费延迟的监控则更加直观，而且从时间的维度来做监控也比较容易确定报警阈值。 了解了消息延迟的监控方式之后，我们再来看看如何提升消息的写入和消费性能，这样才会让异步的消息得到尽快的处理。 减少消息延迟的正确姿势想要减少消息的处理延迟，我们需要在**消费端和消息队列**两个层面来完成。 在消费端，我们的目标是提升消费者的消息处理能力，你能做的是： 1.  优化消费代码提升性能；        2.  增加消费者的数量（这个方式比较简单）。        不过，第二种方式会受限于消息队列的实现。比如说，如果消息队列使用的是Kafka就无法通过增加消费者数量的方式，来提升消息处理能力。 因为在 Kafka 中，一个 Topic（话题）可以配置多个Partition（分区），数据会被平均或者按照生产者指定的方式，写入到多个分区中，那么在消费的时候，Kafka约定一个分区只能被一个消费者消费，为什么要这么设计呢？在我看来，如果有多个consumer（消费者）可以消费一个分区的数据，那么在操作这个消费进度的时候就需要加锁，可能会对性能有一定的影响。 所以说，话题的分区数量决定了消费的并行度，增加多余的消费者也是没有用处的，那么你可以通过增加分区来提高消费者的处理能力。 ![](Images/d9553a438389c6427d9e67eda2118b36.png)savepage-src="https://static001.geekbang.org/resource/image/cd/39/cdd960f49f982f8b96ab466d7e4b2739.jpg"}那么，如何在不增加分区的前提下提升消费能力呢？ 既然不能增加 consumer，那么你可以在一个 consumer中提升处理消息的并行度，所以可以考虑使用多线程的方式来增加处理能力：你可以预先创建一个或者多个线程池，在接收到消息之后，把消息丢到线程池中来异步地处理，这样，原本串行的消费消息的流程就变成了并行的消费，可以提高消息消费的吞吐量，在并行处理的前提下，我们就可以在一次和消息队列的交互中多拉取几条数据，然后分配给多个线程来处理。 ![](Images/436f61a4f8fc674c76c1d2b0a88efeee.png)savepage-src="https://static001.geekbang.org/resource/image/2c/79/2c0eefd526eed3a1fe4df89f068daf79.jpg"}另外，你在消费队列中数据的时候还需要注意消费线程空转的问题。 **我是最初在测试自己写的一个消息中间件的时候发现的。**当时，我发现运行消费客户端的进程会偶发地出现 CPU跑满的情况，于是打印了 JVM 线程堆栈，找到了那个跑满 CPU的线程。这个时候才发现，原来是消息队列中，有一段时间没有新的消息，于是消费客户端拉取不到新的消息就会不间断地轮询拉取消息，这个线程就把CPU 跑满了。 所以，你在写消费客户端的时候要考虑这种场景，拉取不到消息可以等待一段时间再来拉取，等待的时间不宜过长，否则会增加消息的延迟。我一般建议固定的10ms\~100ms，也可以按照一定步长递增，比如第一次拉取不到消息等待10ms，第二次 20ms，最长可以到 100ms，直到拉取到消息再回到10ms。 说完了消费端的做法之后，**再来说说消息队列本身在读取性能优化方面做了哪些事情。** 我曾经也做过一个消息中间件，在最初设计中间件的时候，我主要从两方面考虑读取性能问题： 1.  消息的存储；        2.  零拷贝技术。        **针对第一点，**我最初在设计的时候为了实现简单，使用了普通的数据库来存储消息，但是受限于数据库的性能瓶颈，读取QPS 只能到 2000，后面我重构了存储模块，使用本地磁盘作为存储介质。PageCache的存在就可以提升消息的读取速度，即使要读取磁盘中的数据，由于消息的读取是顺序的，并且不需要跨网络读取数据，所以读取消息的QPS 提升了一个数量级。 **另外一个优化点是零拷贝技术，**说是零拷贝，其实，我们不可能消灭数据的拷贝，只是尽量减少拷贝的次数。在读取消息队列的数据的时候，其实就是把磁盘中的数据通过网络发送给消费客户端，在实现上会有四次数据拷贝的步骤： 1.数据从磁盘拷贝到内核缓冲区； 2.系统调用将内核缓存区的数据拷贝到用户缓冲区； 3. 用户缓冲区的数据被写入到 Socket缓冲区中； 4. 操作系统再将 Socket缓冲区的数据拷贝到网卡的缓冲区中。 ![](Images/84bab62bf39598f5168e77244f7e6950.png)savepage-src="https://static001.geekbang.org/resource/image/52/8f/52c74ecac57e7a437442860029476d8f.jpg"}操作系统提供了 Sendfile 函数，可以减少数据被拷贝的次数。使用了Sendfile之后，在内核缓冲区的数据不会被拷贝到用户缓冲区，而是直接被拷贝到 Socket缓冲区，节省了一次拷贝的过程，提升了消息发送的性能。高级语言中对于Sendfile 函数有封装，比如说在 Java 里面的 java.nio.channels.FileChannel类就提供了 transferTo 方法提供了 Sendfile的功能。 ![](Images/9039407b81f6c8d17d0046ab26514d61.png)savepage-src="https://static001.geekbang.org/resource/image/e3/ed/e38d36c7f077c6ce5b0b276efb8d4eed.jpg"}课程小结本节课我带你了解了，如何提升消息队列的性能来降低消息消费的延迟，这里我想让你明确的重点是： 1.  我们可以使用消息队列提供的工具，或者通过发送监控消息的方式，来监控消息的延迟情况；        2.  横向扩展消费者是提升消费处理能力的重要方式；        3.  选择高性能的数据存储方式，配合零拷贝技术，可以提升消息的消费性能。        其实，队列是一种常用的组件，只要涉及到队列，任务的堆积就是一个不可忽视的问题，**我遇到过的很多故障都是源于此。**比如说，前一段时间处理的一个故障，前期只是因为数据库性能衰减有少量的慢请求，结果这些慢请求占满了Tomcat 线程池，导致整体服务的不可用。如果我们能对 Tomcat线程池的任务堆积情况有实时地监控，或者说对线程池有一些保护策略，比方说线程全部使用之后丢弃请求，也许就会避免故障的发生。在此，我希望你在实际的工作中能够引以为戒，只要有队列就要监控它的堆积情况，把问题消灭在萌芽之中。思考时间在实际的项目中，你可能对于消息队列的使用已经很熟练了，那么结合今天的内容，你可以和我分享一下，在研发过程中，你在降低消息延迟方面做过哪些事情呢？欢迎在留言区和我一起讨论，或者将你的实战经验分享给更多的人。最后，感谢你的阅读，如果这篇文章让你有所收获，也欢迎你将它分享给更多的朋友。![](Images/5cef34b7fbf24f9dd9c2c4c485c9dd17.png)savepage-src="https://static001.geekbang.org/resource/image/72/1a/72b203e2c1ec97d268a5eead610bf71a.jpg"}