PGAs on the path from zero (direct wire) to three. Packets
were sent at a rate of 25 packets/second; both sending and
receiving was implemented directly in the FreeBSD kernel.
The delay caused by the Bloom ﬁlter matching code is
56ns (7 clock cycles), which is insigniﬁcant compared to
the measured 3μs delay of the whole NetFPGA processing.
With background traﬃc, the average latency per NetFPGA
increased to 5μs.
To get an idea of the achievable throughput, we compared
our implementation with the Stanford reference router. This
was quantiﬁed by comparing ICMP echo requests processing
times through a plain wire, our implementation, and the ref-
erence IP router with ﬁve entries in the forwarding table. To
compensate the quite high deviation, caused by sending and
receiving ICMP packets and involving user level processing,
we averaged over 100 000 samples. The results are shown in
Table 5.
While we did not directly measure the bandwidth (due to
lack of test equipment to reliably ﬁll the pipes), there are no
reasons why the implementation would not operate at full
bandwidth. The code is straightforward and should be able
to keep the pipeline full under all conditions.
7. RELATED WORK
Related work falls into various categories, which we brieﬂy
discuss in the following paragraphs.
Network level multicast: Our basic communication
scheme is functionally similar to IP-based source speciﬁc
multicast (SSM) [19], with IP multicast groups replaced by
topic identiﬁers. The main diﬀerence is that we support
stateless multicast for sparse subscriber groups, with uni-
cast being a special case of multicast; IP multicast typically
creates lot of state in the network if one needs to support a
large set of small multicast groups.
In “Revisiting IP multicast” [31], Ratnasamy et al propose
source border routers to include an 800-bit Bloom-ﬁlter-
based shim header (TREE_BF) in packets. TREE BFs rep-
resent AS-level paths of the form ASa : ASb in the dissemi-
nation tree of multicast packets. Moreover, a second type of
Bloom ﬁlters is used to aggregate active intra-domain mul-
ticast groups piggybacked in BGP updates. The presented
method uses standard IP-based forwarding mechanisms en-
riched with the built-in TREE BF to take the inter-domain
forwarding decisions. However, our multicast fabric uses the
in-packet Bloom ﬁlter directly for the forwarding decisions,
removing the need for IP-addresses and proposing Link IDs
as a generic indirection primitive.
Figure 8: FreeBSD prototype structure
packets; cf. [3, 14]. The ﬁne-grain path control allows us to
easily determine those nodes that may have copies of recent
packets in their memory. Multicast, in turn, allows local
control queries to be sent eﬃciently. The falling prices of
memory compared to bandwidth indicates the economical
feasibility of our model.
6.
IMPLEMENTATION
There are currently two partial prototypes of the sys-
tem. The FreeBSD-based end-node prototype consists of
some 10000 lines of C code, implementing both the pub/sub
subsystem and the forwarding fabric. Our NetFPGA-based
forwarding node prototype has currently some 390 lines of
Verilog, implementing the main ideas from this paper. In
this section, we brieﬂy describe the implementation details
and present early measurements of the NetFPGA forward-
ing module.
6.1 End node
The structure of the end-node prototype is depicted in
Fig. 8. The I/O module implements a few new system
calls for creating new publications (reserving memory ar-
eas), publishing, and subscribing. When allocating mem-
ory for a publication, the pager is set to be a vnode pager,
and the backing ﬁle to be in the Filesystem in Userspace
(FUSE)[38]. Hence, each publication is backed up by a vir-
tual ﬁle, located in a separate virtual ﬁle system running
under FUSE.
Currently, forwarding and other network traﬃc is handled
in separate threads running within the Pub/Sub daemon,
simply sending and receiving raw Ethernet frames with lib-
net and libpcap. Ethernet frames are always broadcasted,
basically using each Ethernet cable as a point-to-point link,
disregarding any Ethernet bridging or switching.
6.2 Forwarding node
We have implemented an early prototype of a forward-
ing node using Stanford NetFPGA [25]. Starting from the
Stanford reference switch implementation, we removed most
of the for-us-unnecessary code in the reference pipeline and
replaced it with a simple zFilter switch. At this point, we
have implemented the basic LIT and virtual link ideas, and
tested it with 4 real and 4 virtual LITs per interface. With
this conﬁguration, the total usage of NetFPGA resources
for the logic is 4.891 4-input LUTs out of 47.232, and 1.861
Slice Flip/Flops (FF) out of 47.232. No BRAMs are re-
served. For the whole system, the corresponding numbers
are 20.273 LUTs, 15.347 FFs, and 106 BRAMs.
204Path
Avg. latency
Std. Dev.
Plain wire
IP router
LIPSIN
94μs
102μs
96μs
28μs
44μs
28μs
Table 5: Ping through various implementations
In Xcast [7], source nodes encode the list of multicast
channel destinations into the Xcast header. Each router
along the way parses the header, partitions the destinations
based on each destination’s next hop, and forwards a packet
appropriately until there is only one destination left where
the Xcast packet is unicasted. Our ﬁxed size Bloom ﬁlter
approach shares the simplicity and stateless operations of
Xcast while it avoids costly header re-writings and the des-
tination IP packet header overhead.
Data-center applications and multicast: In [4] Bhar-
gava et al discuss the performance achieved with kernel-level
multicast for distributed databases. Due to the problems of
IP multicast, such approaches are not commonly used in
data-center applications. Recently, there has been some ef-
forts on mapping traditional IP multicast to new models to
ease wider use of IP multicast in these applications [42]. Our
approach provides some new ground for considering multi-
cast and explicit routing (e.g., middlebox serialization) in
data-center environments.
Explicit routing: The simplest form of source routing
[37] is based on concatenating the forwarding nodes’ net-
work identiﬁers on the path between senders and receivers.
Our approach addresses the main caveats of source routing,
including the overhead of having to carry all the routing in-
formation in the packet. Moreover, our approach does not
reveal node or link identiﬁers, not even to the sending nodes,
nor the sequence or exact amount of hops involved.
GMPLS [26] is being marketed as a solution to provide fast
forwarding. By separating control and forwarding planes, it
introduces more ﬂexibility and promises performance gains,
with the hardware-based fast label switching. However, it
does not directly scale for massive multicast due to the lim-
ited label space and no capability for label aggregation.
In PoMo [29], Poutievski, Calvert, and Griﬃoen suggest
an approach that trades overdeliveries for reduced state and
reduced dependence of node network locators. In [10], the
same authors propose an architectural approach with link
identities having a pivotal role.
The BANANAS framework [22] is based on encoding each
path as a short hash (PathID) of a sequence of globally
known identiﬁers. The focus of BANANAS is on host-centric
multipath communications, while ours is centered around
non-global, opaque Link IDs and their compact represen-
tation. Some of the schemes developed in [22] for route
computation and deployability over existing connectionless
routing protocols (e.g., OSPF and BGP extensions) may be
used to support LIPSIN over legacy networks.
Routing and forwarding with Bloom ﬁlters: Mul-
tiple ﬂavours of Bloom ﬁlters [9] have been proposed to as-
sist the forwarding operations of diverse systems (e.g., P2P,
WSN, pub/sub). In the ﬁeld of content-based pub/sub [21],
Bloom ﬁlters are employed to represent a conjunction of
subscriptions’ predicates (SBSTree) used at content-based
event forwarding time. In comparison, our pub/sub prim-
itives are topic-based and the Bloom ﬁlters are built into
packets to carry link IDs and not summarized subscriptions
stored in network elements. Other forms of in-packet Bloom
ﬁlters include the loop detection mechanism in Icarus [43],
the credentials-based data path authentication in [44], and
the aforementioned AS-level path representation for IP mul-
ticast [31].
8. CONCLUSIONS
Building on the idea of placing a Bloom ﬁlter into data
packets, we have proposed a new forwarding fabric for mul-
ticast traﬃc. With reasonably small headers, comparable
to those of IPv6, we can handle the large majority of Zipf-
distributed multicast groups, up to some 20 subscribers, in
realistic metropolitan-sized topologies, without adding any
state in the network and with negligible forwarding over-
head. For the remainder of traﬃc, the approach provides
the ability to balance between stateless multiple sending and
stateful approaches. With the stateful approach, we can
handle dense multicast groups with very good forwarding
eﬃciency. The forwarding decisions are simple, energy eﬃ-
cient, parallelised in hardware, and have appealing security
properties. All these attributes make our work, in its current
form, a potential choicer for data-center applications.
While a lot of work remains, the results indicate that it
may be feasible to support Internet-wide massive multicast
in a scalable manner. Technically, the main remaining ob-
stacles are related to determining the right local delivery
tree for traﬃc arriving from outside of a domain. Our cur-
rent proposal scales only linearly. The problems related to
the deployment and business aspects are likely to be even
harder, but fall beyond the scope of this paper.
From a larger point of view, support for massive multi-
cast is but one component needed for Internet-wide pub-
lish/subscribe. The other two components, data-oriented
naming and in-network caching, we touched only indirectly.
However, we hope that our work allows others to build upon
it, allowing experimentation with network architectures that
are fundamentally diﬀerent from the currently deployed ones.
9. ACKNOWLEDGEMENTS
This research was supported by the EU’s PSIRP project
(FP7-INFSO-IST 216173). The authors thank the SIG-
COMM reviewers and our shepherd Jon Crowcroft for the
comments that helped to improve the paper. We also thank
NomadicLab’s implementation team for their eﬀorts.
10. REFERENCES
[1] Rocketfuel ISP topology data.
http://www.cs.washington.edu/research/networking/
rocketfuel/maps/weights-dist.tar.gz.
[2] B. Ahlgren, L. Eggert, A. Feldmann, A. Gurtov, and
T. R. Henderson. Naming and addressing for
next-generation internetworks. Technical report,
Dagstuhl, 2007.
[3] M. Balakrishnan, K. Birman, A. Phanishayee, and
S. Pleisch. Ricochet: Lateral Error Correction for
Time-Critical Multicast. In NSDI’ 07, 2007.
[4] B. Bhargava, E. Maﬂa, and J. Riedl. Communication
in the Raid distributed database system. Comput.
Netw. ISDN Syst., 1991.
205[5] K. Birman, M. Balakrishnan, D. Dolev, T. Marian,
K. Ostrowski, and A. Phanishayee. Scalable Multicast
Platforms for a New Generation of Robust Distributed
Applications. In COMSWARE’ 07, 2007.
[6] B. H. Bloom. Space/time trade-oﬀs in hash coding
with allowable errors. Commun. ACM, 1970.
[7] R. Boivie, N. Feldman, Y. Imai, W. Livens, and
D. Ooms. Explicit multicast (Xcast) concepts and
options. IETF RFC 5058, 2007.
[8] R. Briscoe. The implications of pervasive computing
on network design. BT Technology Journal,
22(3):170–190, 2004.
[9] A. Z. Broder and M. Mitzenmacher. Survey: Network
applications of Bloom ﬁlters: A survey. Internet
Mathematics, 2004.
[10] K. L. Calvert, J. Griﬃoen, and L. Poutievski.
Separating Routing and Forwarding: A Clean-Slate
Network Layer Design. In In proc. of the Broadnets
Conf., 2007.
[11] M. Cha, P. Rodriguez, S. Moon, and J. Crowcroft. On
next-generation telco-managed P2P TV architectures.
In IPTPS ’08, 2008.
[12] J. Day. Patterns in Network Architecture: A Return to
Fundamentals. Prentice Hall, 2008.
[13] S. E. Deering and D. Cheriton. Multicast routing in
datagram internetworks and extended LANs. ACM
Trans. on Comp. Syst., 1990.
[14] F. Dogar, A. Phanishayee, H. Pucha, O. Ruwase, and
D. Andersen. Ditto - A System for Opportunistic
Caching in Multi-hop Wireless Mesh Networks. In
ACM Mobicom, 2008.
[15] P. T. Eugster, P. A. Felber, R. Guerraoui, and A.-M.
Kermarrec. The many faces of publish/subscribe.
ACM Comput. Surv., 2003.
[16] P. Faratin, D. Clark, P. Gilmore, S. Bauer, A. Berger,
and W. Lehr. Complexity of Internet interconnections:
Technology, incentives and implications for policy. In
TPRC’ 07, 2007.
[17] P. Gill, M. Arlitt, Z. Li, and A. Mahanti. YouTube
Traﬃc Characterization: A View From the Edge. In
ACM SIGCOMM IMC’07., 2007.
[18] A. Gulli and A. Signorini. The indexable web is more
than 11.5 billion pages. In WWW ’05, 2005.
[19] H. Holbrook and B. Cain. Source-speciﬁc multicast for
IP. RFC 4607. 2006.
[20] J.D.Touch and V.K.Pingali. The RNA metaprotocol.
In ICCCN ’08, 2008.
[21] Z. Jerzak and C. Fetzer. Bloom ﬁlter based routing for
content-based publish/subscribe. In DEBS ’08, 2008.
[22] H. T. Kaur, S. Kalyanaraman, A. Weiss, S. Kanwar,
and A. Gandhi. Bananas: an evolutionary framework
for explicit and multipath routing in the internet.
SIGCOMM Comput. Commun. Rev., 2003.
[23] T. Koponen, M. Chawla, B.-G. Chun, A. Ermolinskiy,
K. H. Kim, S. Shenker, and I. Stoica. A data-oriented
(and beyond) network architecture. In SIGCOMM ’07,
2007.
[24] H. Liu, V. Ramasubramanian, and E. G. Sirer. Client
behavior and feed characteristics of RSS, a publish-
subscribe system for web micronews. In IMC’05, 2005.
[25] J. W. Lockwood, N. McKeown, G. Watson, G. Gibb,
P. Hartke, J. Naous, R. Raghuraman, and J. Luo.
NetFPGA–an open platform for gigabit-rate network
switching and routing. In MSE ’07, 2007.
[26] E. Mannie. Generalized Multi-Protocol Label
Switching (GMPLS) Architecture. RFC 3945, 2004.
[27] A. Markopoulou, G. Iannaccone, S. Bhattacharyya,
C. Chuah, and C. Diot. Characterization of failures in
an IP backbone. In INFOCOM 2004, 2004.
[28] S. Orlowski, M. Pi´oro, A. Tomaszewski, and
R. Wess¨aly. SNDlib 1.0–Survivable Network Design
Library. In INOC’ 07, 2007.
[29] L. B. Poutievski, K. L. Calvert, and J. N. Griﬃoen.
Routing and forwarding with ﬂexible addressing.
Journal Of Communication and Networks, 2007.
[30] J. Rajahalme, M. S¨arel¨a, P. Nikander, and
S. Tarkoma. Incentive-compatible caching and peering
in data-oriented networks. In ReArch’08, 2008.
[31] S. Ratnasamy, A. Ermolinskiy, and S. Shenker.
Revisiting IP multicast. In SIGCOMM’06, 2006.
[32] M. S¨arel¨a, T. Rinta-aho, and S. Tarkoma. RTFM:
Publish/subscribe internetworking architecture. ICT
Mobile Summit, 2008.
[33] J. Scott, J. Crowcroft, P. Hui, and C. Diot. Haggle: a
networking architecture designed around mobile users.
In Annual IFIP Conference on Wireless On-demand
Network Systems and Services, 2006.
[34] A. Sharma, A. Bestavros, and I. Matta. dPAM: a
distributed prefetching protocol for scalable
asynchronous multicast in P2P systems. In
INFOCOM’ 05, 2005.
[35] R. Sherwood, A. Bender, and N. Spring. Discarte: a
disjunctive Internet cartographer. SIGCOMM
Comput. Commun. Rev., 2008.
[36] I. Stoica, D. Adkins, S. Zhuang, S. Shenker, and
S. Surana. Internet indirection infrastructure. In
SIGCOMM’02, 2002.
[37] C. A. Sunshine. Source routing in computer networks.
SIGCOMM Comput. Commun. Rev., 1977.
[38] M. Szeredi. Filesystem in Userspace. Located at
http://fuse. sourceforge. net.
[39] S. Tarkoma, D. Trossen, and M. S¨arel¨a. Black boxed
rendezvous based networking. In MobiArch ’08, 2008.
[40] N. Tolia, M. Kozuch, M. Satyanarayanan, B. Karp,
and T. Bressoud. Opportunistic use of content
addressable storage for distributed ﬁle systems. In
USENIX’ 03, 2003.
[41] D. Trossen (edit.). Architecture deﬁnition, component
descriptions, and requirements. Deliverable D2.3,
PSIRP project, 2009.
[42] Y. Vigfusson, H. Abu-Libdeh, M. Balakrishnan,
K. Birman, and Y. Tock. Dr. multicast: Rx for
datacenter communication scalability. In HotNets-VII,
2008.
[43] A. Whitaker and D. Wetherall. Forwarding without
loops in Icarus. In Proc. of OPENARCH, 2002.
[44] T. Wolf. A credential-based data path architecture for
assurable global networking. In IEEE MILCOM, 2007.
[45] A. Zahemszky, A. Csaszar, P. Nikander, and
C. Esteve. Exploring the pubsub routing/forwarding
space. In International Workshop on the Network of
the Future, 2009.
206