of the error terms for the values x with lbb(i)  0):
(cid:88)
i
Dα+1 =
1
α
log
B(i) · f αi
A pair of distributions A, B satisﬁes (ξ, ρ)-Concentrated DP if the R´enyi divergence is bounded by an aﬃne
linear function: Dα ≤ ξ + ρα (for all α ≥ 0). R´enyi diﬀerential privacy directly characterizes the privacy
bound by the R´enyi divergences: (α, Dα)α. R´enyi diﬀerential privacy can be translated to (ε, δ)-ADP as
follows: whenever (α, Dα)α, then also (ε, αDα − αε)-ADP holds. The moments accountant uses the same
characterization and proposes (ε, minα(αDα − αε)) as ADP bounds. Consequently, we search for the value
α that minimizes this bound.
In our implementation, we approximated the R´enyi divergence by using our buckets. Figure 22 (in the
appendix) compares this approximation with the original implementation of the DP-SGD paper [1] and
shows that the two implementations coincide.
5.8 Comparison results
Figure 12 and Figure 13 graphically depicts our results. We used in the computation of all these graphs
100, 000 buckets. We consistently see that our bounds are tighter than prior bounds. We use our results to
evaluate other bounds. For the Laplace mechanism and randomized response, KOV is tight. As a side-note,
this observation suggests that there is no mechanism with the same, or smaller, initial ε and δ values that
composes signiﬁcantly worse than the Laplace mechanism. For the Gauss mechanism, KOV is far away from
our bounds and, for large values of eε is even outperformed by both CDP and MA. Similar to the Gauss
mechanism, MA outperforms KOV for large values of eε. For the analysis of the stochastic gradient, we
omit the KOV bound, since the large number of r = 216 observations makes a calculation of the KOV bound
diﬃcult.
In summary, we see that previous bounds have their strengths and weaknesses: KOV is tight for Laplace,
but not for other scenarios; MA outperforms KOV for large values of eε, but not for smaller values; CDP
is signiﬁcantly tighter than MA whenever it can be applied, but requires the ﬁtting of a Gaussian over the
privacy loss variable, which often isn’t tight and sometimes is impossible. Figure 13 shows that the KOV
bound becomes inaccurate with an increasing number of compositions. In all cases our bounds derived from
the privacy buckets are tight.
11This theoretical characterization assumes a suﬃciently high number of buckets such that no approximations need to be
made.
39
Figure 12: A group of (ε, δ)-graphs for the Laplace mechanism, the Gauss mechanism, the CoverUp mecha-
nism and the stochastic gradient descent mechanism. The ﬁrst three are for r = 512, the latter for r = 216.
6 Comparison of the Gaussian and the Laplace mechanism
As we have seen in Section 5.8, Kairouz et al.’s composition theorem is fairly tight for the Laplace mechanism
but not for the Gauss mechanism. Figure 14 (upper two graphs) compares a truncated Laplace and a
truncated Gauss mechanism and ﬁnd that for the same variance the Gauss mechanism provides a signiﬁcantly
higher degree of privacy.12 For a ﬁxed variance of 80, 000, a sensitivity of 1 (mu1 = 0 and µ2 = 2), and
a truncation at −2500 and 2500 for µ1 (and −2499 and 2501 for µ2), the upper left graph in Figure 14
depicts how, for diﬀerent but ﬁxed epsilon values, the delta increases over the course of 512 evaluations. The
graph clearly shows that in the course of 512 compositions, the reduced leakage of the Gauss mechanism
becomes visible. The lower left graph in Figure 14 shows the full epsilon-delta graphs of a Gaussian and a
Laplace mechanism after 512 compositions, where the two mechanisms use noise that has the same variance
(80, 000). In particular, the delta-value where the (ε, δ) graph levels out is 4 orders of magnitude lower for
Gaussian noise than it is for Laplace noise, since the Gaussian distribution falls much steeper than Laplace
12All computations have been conducted with 100, 000 buckets.
40
1.001.101.201.301.401.501.6010−6.0010−5.0010−4.0010−3.0010−2.0010−1.00eεδLaplacemechanismMALPKOVLPCDPLPBucketsLPlowerbound1.001.021.041.061.081.101.121.1410−7.0010−6.0010−5.0010−4.0010−3.0010−2.0010−1.00eεCoverUpMACUKOVCUBucketsCUlowerbound1.001.051.101.151.201.251.301.3510−6.0010−5.0010−4.0010−3.0010−2.0010−1.00eεδGaussmechanismMAGSKOVGSCDPGSBucketsGSlowerbound2.004.006.008.0010−4.0010−3.0010−2.0010−1.00eεStochachsticgradientdescentMASGDBucketsSGDlowerboundFigure 13: Comparison with the bounds from R´enyi Privacy and CDP for the Gauss mechanism, i.e., the
distributions GS(0, 2 ∗ 2002) and GS(1, 2 ∗ 2002). Left: (ε, δ)-graph for 512 compositions. Right: growth of
eε over the number of compositions for δ ≤ 10−5.
distribution. This diﬀerence of the Gaussian and the Laplace mechanisms becomes even more pronounced in
our analysis and improvement of the Vuvuzela protocol in Section 7. The analysis of Vuvuzela also illustrates
that the steepness of the Gaussian distribution enables a much tighter truncation, i.e., the distribution can
be truncated much earlier than a Laplace distribution without sacriﬁcing privacy. This tighter truncation,
in turn, leads to a smaller range of noise that is required to achieve the same privacy goals as with Laplace
noise.
Additionally, we found evidence that the epsilon-delta graph of the Laplace mechanism converges toward
the epsilon-delta graph of a Gauss mechanism with half the variance of the Laplace mechanism. For the same
sensitivity, and truncations as above, the two right graphs in Figure 14 illustrate that after 512 compositions
these two graphs converge toward each other. The upper right graph in Figure 14 depicts how, for diﬀerent
but ﬁxed epsilon values, the delta increases over the course of 512 evaluations. The graph clearly shows
how in the course of 512 compositions, the delta values of the Laplace mechanism converge toward the delta
41
1002003004005001.001.101.201.301.401.501.60numberofcompositionseεLaplacemechanismMALPKOVLPBucketsLPlowerbound1002003004005001.001.051.101.151.201.25numberofcompositionseεCoverUpdataMACUKOVCUBucketsCUlowerbound1002003004005001.001.502.002.503.003.504.004.50numberofcompositionseεGaussmechanismMAGSKOVGABucketsGSlowerbound1002003004002.004.006.008.0010.0012.0014.00numberofepochseεStochasticgradientdescentMASGDBucketsSGDlowerbound(a) Laplace vs Gaussian with the same variance (left, 2 · 2002 = 2γ2 = σ2) vs. Gaussian having half the variance
(right, 2002 = γ2 = σ2): eε over the number of compositions for ﬁxed δ values, δ1 = 0.01, δ2 = 0.001, δ3 = 0.0001
(diﬀerent line-styles) for a growing number of compositions. The legend is in the same order as the graphs.
(b) The ε, δ graphs (upper and lower bounds) after k = 512 compositions applied to a Gaussian and a Laplace
mechanism with δ on the y-axis and eε on the x-axis.
Figure 14: Truncated Gauss mechanisms (red) vs. truncated Laplace mechanism (blue) both with sensitivity
= 1. For both mechanism truncation is at µi − 2500 and µi + 2500 (µ1 = 0 and µ2 = 1). At twice the
variance the Laplace mechanism converges towards the Gauss mechanism, so much that the blue lines almost
completely cover the red lines.
values of the Gauss mechanism. The lower right graph in Figure 14 shows the full epsilon-delta graphs
of a Gaussian and a Laplace mechanism after 512 compositions, where the Laplace mechanism has twice
the variance (80, 000) of the Gauss mechanism (40, 000). This ﬁgure shows how close the two epsilon-delta
graphs are and that they almost only diﬀer due to their diﬀerent y-values at the point where they have
been truncated. This diﬀerence, however, is crucial. As explained above, it is caused by the steepness of
the Gaussian distribution and enables a much tighter truncation, which in turn can lead to signiﬁcantly less
42
1002003004005001.001.101.201.301.40numberofcompositionseεGSvsLPLPδ3LPδ2GSδ3GSδ2LPδ1GSδ11002003004005001.001.101.201.301.40numberofcompositionsGSvsLPGSδ3LPδ3GSδ2LPδ2GSδ1LPδ111.11.21.31.41.51.61.710−1510−1210−910−610−3eεδGSvsLPLPLPlowGSGSlow11.21.41.61.8210−1210−1010−810−610−410−2eεGSvsLPLPLPlowGSGSlownoise overhead, as we illustrate in our analysis of Vuvuzela.
Dwork and Rothblum [7] presented a related result. They characterized the composition behavior of a
mechanisms (i.e., a pair of distributions A, B) for which the privacy loss distribution eL(A||B) is Subgaussian,
i.e., the moment-generating function (MGF) is smaller than the MGF of a Gaussian. They show that such for
mechanisms the privacy loss distribution after r-fold composition can be bounded by a Gaussian. Moreover,
showed that the privacy loss distribution, i.e., the privacy buckets distribution, of the Gauss mechanism is
a Gaussian distribution. Complementarily, our ﬁndings show that the privacy loss distribution of a Laplace
mechanism converges towards a Gaussian, already after 512 compositions. We leave it for future work
to investigate the connection between the Laplace distribution and a Gaussian distribution with half the
variance.
7 Application to Vuvuzela
In this section, we show how aiming for tight bounds in a privacy analysis can signiﬁcantly improve the
bandwidth overhead of a protocol. As a case study, we use the Vuvuzela [26] protocol, which is an anonymous
communication system tailored towards messengers. Vuvuzela uses Laplace noise to achieve strong privacy
properties. Using the insights from Section 6, we not only estimate tighter bounds for the Laplace noise but
also propose to change the shape of the noise distribution to Gaussian noise. With our bucketing approach,
we show that already 5 to 10 times less noise13 suﬃces to achieve the same strong privacy properties. 14
We refer to the original Vuvuzela paper for a full presentation and restrict our presentation to the
bare bones that are needed to understand the noise messages that Vuvuzela uses to achieve strong privacy
properties.
We stress that our work contributes to improving the epsilon-delta bounds and thus to improve a given
privacy analysis. This work is not meant to help in ﬁnding a suitable attacker model, a suitable deﬁnition
or accurate usage proﬁles. Hence, we stick to Vuvuzela’s privacy analysis, as it was presented in the original
paper.
7.1 Protocol overview
Vuvuzela clients communicate by deposing their encrypted messages in virtual locations in the one of the
mixes (the locations are called dead drops). For agreeing on such a dead drops, Vuvuzela deploys a dialing
protocol where the dialer sends the ID of a dead drop to dedicated invitation dead drops. This ID is encrypted
with the peer’s public key with an encryption schemes that is designed to hide the recipient’s identity. On
the dialer’s side directly the conversation protocol is started where the client regularly retrieves the chat
messages from and deposits chat messages to the dead drop from the invitation. If the recipient receives and
accepts the invitation, the recipient also starts the conversation protocol.
Privacy analysis Vuvuzela assumes a global network-level attacker that is additionally able to compromise
some mixes. To achieve strong resistance against compromised servers, each path in Vuvuzela traverses all
nodes. To counter traﬃc correlation attacks, Vuvuzela clients produce dummy traﬃc at a constant rate. The
Vuvuzela paper argues that the only remaining source of leakage is the patterns of registering invitations
and patterns of access requests to these dead drops: single requests to dead drops, corresponding to dummy
messages or messages before the peer accepted the conversation, and pairs of requests to the same dead drop,
corresponding to an active conversation.
Privacy-enhancing measures Vuvuzela reduces the information that an attacker can learn by triggering
each mix to produce cover stories for potentially communicating parties. For the dialing protocol, the mixes
produce cover stories (i) by sending dummy invitation registrations and invitation requests to the dedicated
invitation dead drops. The number of these dummy registrations and dummy requests is in each round
13The more observations are estimated, the higher the error of the advanced composition result, which is used in the original
analysis from the Vuvuzela paper; hence, in those cases the tightness of our bounds leads to a more signiﬁcant improvement.
14We acknowledge that for the analysis of the Laplace noise previous results [14] would already yield tight results, but for
the Gaussian noise our approach yields much tighter results (see Section 6).
43
drawn from the truncated Laplace distribution (cid:100)max(0, Laplace(γd, µd))(cid:101) for some system parameters γd
and µd. For the conversation protocol, the mixes produce cover stories (ii) for idle parties, by sending pairs
of dummy access requests to uniform-randomly chosen dead drops, and (iii) for (bi-directionally) commu-
nicating parties, by sending (single) dummy access requests to uniform-randomly chosen dead drops. The
number of (single) dummy access requests (ii) is in each round drawn from the truncated Laplace distribu-
tion (cid:100)max(0, Laplace(γc, µc))(cid:101) for system parameters γc and µc, and the number of pairs of dummy access
requests (iii) is in each round drawn from the truncated Laplace distribution (cid:100)max(0, Laplace(µc/2, γc/2))(cid:101).
The system parameters µd, µc, γd, γc determine how much noise-overhead the protocol produces and how
much privacy it will oﬀer.
Privacy-impact of the dummy requests The goal of the these dummy requests and invitations is to
produce a cover stories for dialing parties (i), for idle parties (ii), and for conversing (iii). The Vuvuzela
paper separately conducts a privacy analysis for the dialing protocol ((i)) and the conversation protocol
((ii) and (iii) combined). For the dialing protocol, the paper concludes that it suﬃces to bound the r-fold
(, δ) diﬀerential privacy of max(0, Laplace(µd, γd)) and max(0, Laplace(µd + 2, γd)), i.e., the (, δ) diﬀer-
ential privacy of the product distributions max(0, Laplace(µd, γd))r and max(0, Laplace(µd + 2, γd))r. The
parameter r indicates the number of rounds at which that the attacker conducts an observation. For the
conversation protocol, the paper concludes that it suﬃces to estimate the r-fold (, δ) diﬀerential privacy of
max(0, Laplace(µc, γc))+max(0, Laplace(µc/2, γc/2)) and max(0, Laplace(µc+2, γc))+max(0, Laplace(µc/2+
1, γc/2)). The Vuvuzela paper uses the advanced composition theorem for diﬀerential privacy [8] to bound
 and δ. The paper analyzes for the conversation protocol three system parameters: µ = 150k, γ = 7.5k,
µ = 300k, γ = 13.8k, and µ = 450k, γ = 20k. We show that the resulting bounds can be signiﬁcantly
improved and we indicate all new bounds with a “∗” sign in the respective ﬁgures.
We apply our method to estimate tighter ε and δ bounds for Vuvuzela, and to reduce the recommended
noise. Recall that we observed in Section 6 that Gaussian noise for the same variance behaves better under
composition than Laplacian noise. This section studies how much our tighter bounds enable us to reduces