suggests altering the location of the grid slightly every time a user
tries to unlock a device. An example is shown in Figure 15. When
a target device is wrongly positioned, the pattern area could be mis-
matched by our smug attack tool.
Figure 13: The average time taken to draw the real pattern (in
blue), and the average time taken to draw the random pattern
(in red) for pattern length between 4 and 9.
With the obscuring technique in place, the total number of cracked
patterns was 124 (34.44%), which is close to the smug attack suc-
cess rate (31.94%) for the Facebook scenario. This is a huge im-
provement from the original result (without obscuring technique),
where 267 (74.17%) patterns were cracked (p< 0.001, FET). The
average number of guessing attempts made for patterns that were
cracked increased signiﬁcantly from 3.79 (without obscuring tech-
nique) to 5.24. Those results clearly demonstrate the effectiveness
of the obscuring technique.
The key advantage of the obscuring technique is that it ensures
backward compatibility such that existing patterns can be used with-
out making any change unlike the existing smudge attack mitiga-
tion schemes (e.g., [17]). The only additional logic introduced is
the generation of a random pattern at run time, and requiring users
to draw a random pattern after unlocking their device. The usabil-
ity compromise here is the additional pattern that user has to draw
after unlocking their device. The graph in Figure 13 shows the av-
erage time taken for the participant to draw the real pattern (blue),
and the additional time taken to draw a given random pattern. On
average, it took the participant about 2-3 times longer to draw a ran-
dom pattern for each pattern length (4-9), which is the login time
tradeoff for increasing obscurity (adding security). For random pat-
terns with length between 4 and 8, the participant took about 3-5
seconds on average to draw them, which would be a reasonable de-
lay. However, for random patterns of length 9, the participants took
about 7 seconds on average to draw them—this delay might annoy
users. Hence, random patterns with length equal to 9 are not ideal
candidates for this mitigation technique.
7.2 Allowing repeated points
The performance of smug attack heavily depends on the size of
the possible pattern space:
i.e., the larger the pattern space, the
more challenging it is for smug attack to make accurate guesses.
Hence, an intuitive strategy is to increase the possible pattern space.
Android enforces a pattern creation policy that prohibits points
and lines from being used more than once in a pattern.
In Fig-
ure 14(a), for example, a possible pattern that contains points 1, 2,
3 and 6 can be inferred from smudge residuals as either “1236” or
“6321”. Smug attack only needs to try two different possibilities to
guess that pattern, which is straightforward. However, if we amend
the Android pattern creation policy to allow multiple use of points
and segments in a given pattern, we can increase the workload of
Figure 15: An example of mismatched pattern area.
Based on our experience in developing smudge attacks, it will
be hard for the smug attack tool to extract patterns from smudges
as they will no longer match the points from a given template such
as the original grid. In fact, Schneegass et al. [17] have proposed
a similar mitigation technique that uses geometric image transfor-
mations such as grid translation, rotation, or scaling. Such tech-
niques can be effective in mitigating template-based smudge at-
tacks. However, it is likely to downgrade the usability of pattern
drawing process as this technique is quite similar to random key-
board arrangements used to defeat keyloggers.
8. DISCUSSION
This section discusses the smug attack performance and its limi-
tations.
8.1 Effectiveness of smug attacks
To show the effectiveness of smug attack, we compared its per-
formance against the pure Markov model-based guessing attack
(see Section 6.2). For the naive device unlocking scenario, the
fully optimized smug attack (GT-2) signiﬁcantly outperformed the
pure guessing attack in the attack success rate, successfully crack-
ing 267 (out of 360) more patterns. The difference in the attack
success rates was about 60.84% (p< 0.001, FET). We also demon-
strated that the pure Markov model is not so effective against pat-
terns longer than length 5 whereas smug attack is much more ca-
pable of cracking longer patterns. Moreover, we have shown that
our tool can effectively recognize patterns that are hard to see with
naked human eyes (see Figure 16). Smudge attacks can signif-
icantly boost the performance of a probabilistic password model
(e.g., the n-gram Markov model), and can be used to develop a
fully automated guessing tool. Even when obscuring smudges were
added under the Facebook scenario, the proposed smug attack, at
31.94%, still outperformed the pure guessing attack, at 13.33%, in
the attack success rate.
(a) 15369
(b) 123695
Figure 16: Examples of patterns that cannot be easily recog-
nized by the naked human eyes.
8.2 Limitations of smug attacks
Despite the performance boost, Table 3 also shows a clear lim-
itation of smug attacks where the attack success rate signiﬁcantly
decreased as the tasks became more complex, requiring the partic-
ipant to perform more actions. The attack success rate (patterns
cracked within 20 guessing attempts) started from 74.17% when
the task was to merely unlock the given device, and that rate de-
creased to 52.50%, 37.22%, and 31.94% as the participant was
asked to also make a call, send text messages, and use the Face-
book app, respectively. This reduction in the effectiveness of smug
attack is due to the increased volume of obscuring smudges, and
more relevant smudges being erased.
Our real-world dataset- and implementation-based ﬁndings con-
trast with the speculative ﬁndings from previous literature that only
highlighted the strong effectiveness of smudge attacks based on
user feedback. Our results, for the ﬁrst time, demonstrate how ob-
scurity can affect the performance of smudge attacks based on real
data analyses.
Moreover, our results showed that physical characteristics and/or
pattern drawing behaviors of individuals could impact smug attack
success rates, creating variances in the results. With the calling
task (µ= 52.50%, σ = 11.72%), in particular, we observed high
variances in the results (even though each participant had to draw
different pattern sets). As part of the future work, we will study
how personalization of smug attack conﬁgurations could affect its
performance.
8.3 Mitigation through adding obscurity
In Section 7, we discussed three possible mitigation techniques
for smug attack. From those three techniques, we implemented and
evaluated the obscurity based mitigation technique where users are
also asked to draw a random pattern upon log in to deliberately add
obscuring smudges. Our experiment results showed that this ob-
scuring technique is highly effective (conﬁrming our observations
on the limitations of smug attack), but the main tradeoff in usabil-
ity is the time taken for a user to draw the second random pattern,
which takes about 3-5 seconds on average. We could improve user
experience by selectively asking users to enter the second random
pattern, e.g., only when a user is at a public place like libraries or
cafes. Location technologies like GPS can be used to automatically
detect when a user is at a public place, and enable it. Users do not
have to remember anything extra.
9. RELATED WORK
In this section, we summarize recent research ﬁndings on attacks
performed against popularly used authentication mechanisms on
mobile devices: (1) smudge attacks and (2) guessing attacks.
Smudge attacks guess a user’s password or pattern using ﬁnger-
print traces left on the touchscreen of a target mobile device. Aviv
et al. [5] discussed the feasibility of performing smudge attacks
to guess Android patterns, and experimented with different cam-
era orientations and light positions. Their attack method, however,
was not fully automated, and their results were based on the partici-
pants’ self reports on the perceived difﬁculty of identifying patterns
from smudges visible on a touchscreen.
Several researchers have worked on defense mechanism for smudge
attacks. Zezschwitz et al. [24] proposed three new pattern grid
layouts, and evaluated their usability and security through a lab
experiment. Kwon et al. [12] suggested the use of a small grid
layout with mandating user interactions to remove smudge traces.
Schneegass et al. [17] proposed a geometrically transformed graph-
ical password scheme for a similar purpose. Their security eval-
uation, however, was conducted using 32 synthetically-generated
graphical passwords in a lab environment. None of those research
groups developed a fully automated tool for performing smudge
attacks or guessing attacks against graphical passwords.
Guessing attack is one of the most commonly performed at-
tacks on password-based authentication schemes. The main goal
of this attack is to build a comprehensive dictionary for cracking
passwords efﬁciently. Since the distribution of user chosen pass-
words (including Android patterns) tends to be heavily skewed to-
ward small number of popularly used passwords, they are gener-
ally vulnerable to guessing attacks. For example, Van Oorschot et
al. [16] showed that the actual password space of “Draw-A-Secret”
graphical passwords tends to be signiﬁcantly smaller than the the-
oretically full password space. For Android patterns, Uellenbeck
et al. [21] particularly conducted a survey to collect user patterns
and found that their actual pattern space is much smaller than the
theoretical space. Andriotis et al. [3] also analyzed the Android
pattern security based on user chosen patterns. They conducted an
online survey to collect user patterns, asking participants to cre-
ate patterns that are easy-to-remember and secure. Their results
showed that user chosen patterns are biased; for example, memo-
rable pattern shapes such as “ç” or “ç” were popularly used, and
users frequently chose the upper-left grid point as the starting point
in their patterns. Song et al. [19] collected a small number of real
user patterns, and constructed an n-gram Markov model with the
collected data. Based on the Markov model, they presented a list
of most likely occurring real-world patterns and suggested that this
list could be used as a dictionary for guessing patterns. Intuitively,
it is believed that the use of password meter [19] and bigger grid
layout [4] could be helpful to improve the security of user chosen
patterns but existing studies [4,19] demonstrated that their impacts
are practically limited. For example, even with the 4×4 grid, 19%
15% of the attack success rate with the 3×3 grid [4].
of patterns can successfully be cracked, which is comparable to
Aviv et al. [5] previously claimed that smudge data could be
combined with statistical information about human behaviors such
as pattern usage distribution to perform an effective attack. This pa-
per ﬁnally implements this idea, and demonstrates the effectiveness
of the combined attack based on a real-world pattern dataset.
10. CONCLUSION
This paper studies the effectiveness of combining guessing at-
tacks with smudge attacks on unlocking Android devices within 20
guessing attempts (this is the number of consecutive fail attempts
allowed on Android). We trained a Markov model-based guessing
attack using 219 (70%) of 312 real-world patterns, and recruited
12 participants to individually draw 30 patterns which were ran-
domly chosen from the remaining 30% of those patterns on Sam-
sung Galaxy S4 in a lab environment.
Our results showed that smudge attacks can indeed boost the per-
formance of guessing attacks by providing a way to pre-compute
only the possible pattern candidates based on the detected seg-
ments. In the case of a naive device unlock scenario, the attack
performance signiﬁcantly improved from 13.33% when the pure
guessing attack was performed alone to 74.17% when the smug at-
tack was performed. Even when obscuring smudges were added
under a more complex scenario that involved the use of the Face-
book app, our smug attack, at 31.94%, still outperformed the pure
guessing attack. However, the limitation of smudge-based attacks
was also clear, showing that obscuring smudges can signiﬁcantly
downgrade their performance, and mitigation techniques should be
designed to help users add obscurity.
The proposed technique, with some parameter adjustments, could
be used to effectively crack other types of authentication mecha-
nisms used on touchscreens (e.g., a PIN or password). As part of
future work, we plan to further investigate the performance of the
combined attack on PINs, experimenting with 4- and 6-digit PINs.
Acknowledgement
This work was supported in part by the ITRC (IITP-2016-R0992-16-1006),
the MSIP/IITP (R-20160222-002755) and the MISP (R2215-16-1005). Note
that Hyoungshick Kim is the corresponding author.
11. REFERENCES
[1] OpenCV. http://docs.opencv.org/, 2015.
[2] ANDRIOTIS, P., TRYFONAS, T., AND OIKONOMOU, G. Complexity
metrics and user strength perceptions of the pattern-lock graphical
authentication method. In Human Aspects of Information Security,
Privacy, and Trust (2014), Springer, pp. 115–126.
[3] ANDRIOTIS, P., TRYFONAS, T., OIKONOMOU, G., AND YILDIZ,
C. A pilot study on the security of pattern screen-lock methods and
soft side channel attacks. In Proceedings of the 6th ACM conference
on Security and Privacy in Wireless and Mobile Networks (2013).
[4] AVIV, A. J., BUDZITOWSKI, D., AND KUBER, R. Is bigger better?
comparing user-generated passwords on 3x3 vs. 4x4 grid sizes for
android’s pattern unlock. In Proceedings of the 31st Annual
Computer Security Applications Conference (2015).
[5] AVIV, A. J., GIBSON, K., MOSSOP, E., BLAZE, M., AND SMITH,
J. M. Smudge Attacks on Smartphone Touch Screens. In
Proceedings of the 4th USENIX Conference on Offensive
Technologies (2010).
[6] AVIV, A. J., SAPP, B., BLAZE, M., AND SMITH, J. M. Practicality
of accelerometer side channels on smartphones. In Proceedings of
the 28th Annual Computer Security Applications Conference (2012).
[7] BALLARD, D. H. Generalizing the hough transform to detect
arbitrary shapes. Pattern recognition 13, 2 (1981), 111–122.
[8] BBC NEWS. ‘60,000’ devices are left in cabs. Online. Access at:
http://news.bbc.co.uk/2/hi/technology/7620569.stm, 2008.
[9] BBC NEWS. FBI-Apple case: Investigators break into dead San
Bernardino gunman’s iPhone. Online. Access at:
http://www.bbc.com/news/world-us-canada-35914195, 2016.
[10] CANNY, J. A computational approach to edge detection. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 6 (1986),
679–698.
[11] GALE, W. A. Good-turing smoothing without tears. Journal of
Quantitative Linguistics (1995).
[12] KWON, T., AND NA, S. Tinylock: Affordable defense against
smudge attacks on smartphone pattern lock systems. Computers &
Security 42 (2014), 137–150.
[13] LEE, J., HARALICK, R., AND SHAPIRO, L. Morphologic edge
detection. IEEE Journal of Robotics and Automation 3, 2 (1987),
142–156.
[14] MA, J., YANG, W., LUO, M., AND LI, N. A study of probabilistic
password models. In IEEE Symposium on Security and Privacy
(2014).
[15] MATAS, J., GALAMBOS, C., AND KITTLER, J. Robust detection of
lines using the progressive probabilistic hough transform. Computer
Vision and Image Understanding 78, 1 (2000), 119–137.
[16] OORSCHOT, P. C. V., AND THORPE, J. On predictive models and
user-drawn graphical passwords. ACM Transactions on Information
and System Security 10, 4 (2008), 5:1–5:33.
[17] SCHNEEGASS, S., STEIMLE, F., BULLING, A., ALT, F., AND
SCHMIDT, A. Smudgesafe: Geometric image transformations for
smudge-resistant user authentication. In Proceedings of the ACM
International Joint Conference on Pervasive and Ubiquitous
Computing (2014).
[18] SHANNON, C. E. A mathematical theory of communication. ACM
SIGMOBILE Mobile Computing and Communications Review 5, 1
(2001), 3–55.
[19] SONG, Y., CHO, G., OH, S., KIM, H., AND HUH, J. H. On the
Effectiveness of Pattern Lock Strength Meters: Measuring the
Strength of Real World Pattern Locks. In Proceedings of the 33rd
Annual ACM Conference on Human Factors in Computing Systems
(2015).
[20] TAO, H., AND ADAMS, C. Pass-go: A proposal to improve the
usability of graphical passwords. International Journal of Network
Security 7, 2 (2008), 273–292.
[21] UELLENBECK, S., DÜRMUTH, M., WOLF, C., AND HOLZ, T.
Quantifying the security of graphical passwords: the case of android
unlock patterns. In Proceedings of the 20th ACM conference on
Computer and Communications Security (2013).
[22] VAN BRUGGEN, D., LIU, S., KAJZER, M., STRIEGEL, A.,
CROWELL, C. R., AND D’ARCY, J. Modifying Smartphone User
Locking Behavior. In Proceedings of the Ninth Symposium on
Usable Privacy and Security (2013).
[23] VON ZEZSCHWITZ, E., DUNPHY, P., AND DE LUCA, A. Patterns in
the Wild: A Field Study of the Usability of Pattern and Pin-based
Authentication on Mobile Devices. In Proceedings of the 15th
International Conference on Human-computer Interaction with
Mobile Devices and Services (2013).
[24] VON ZEZSCHWITZ, E., KOSLOW, A., DE LUCA, A., AND
HUSSMANN, H. Making graphic-based authentication secure against
smudge attacks. In Proceedings of the International Conference on
Intelligent User Interfaces (2013).
[25] ZAKARIA, N. H., GRIFFITHS, D., BROSTOFF, S., AND YAN, J.
Shoulder Surﬁng Defence for Recall-based Graphical Passwords. In
Proceedings of the Seventh Symposium on Usable Privacy and
Security (2011).
APPENDIX
A. PATTERN LOCK AUTHENTICATION IN
ANDROID
Figure 17 shows a typical interface of pattern lock authentication
in Android.
Figure 17: Pattern lock authentication in Android.
B. ANDROID APP FOR DATA COLLECTION
To achieve complete ecological validity for real-world patterns,
we developed an independent application called Private Notes (see
Figure 18), which allows users to encrypt their personal notes and
made it available on Google Play (https://play.google.com/store/
apps/details?id=com.Seclab.Notes).
(a) Pattern setup