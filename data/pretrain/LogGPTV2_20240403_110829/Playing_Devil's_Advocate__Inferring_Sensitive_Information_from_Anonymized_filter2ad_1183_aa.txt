title:Playing Devil's Advocate: Inferring Sensitive Information from Anonymized
Network Traces
author:Scott E. Coull and
Charles V. Wright and
Fabian Monrose and
Michael P. Collins and
Michael K. Reiter
Inferring Sensitive Information from Anonymized Network Traces
Playing Devil’s Advocate:
Scott E. Coull∗ Charles V. Wright∗ Fabian Monrose∗ Michael P. Collins† Michael K. Reiter‡
Abstract
Encouraging the release of network data is central to
promoting sound network research practices, though the
publication of this data can leak sensitive information about
the publishing organization. To address this dilemma, sev-
eral techniques have been suggested for anonymizing net-
work data by obfuscating sensitive ﬁelds.
In this paper,
we present new techniques for inferring network topology
and deanonymizing servers present in anonymized network
data, using only the data itself and public information. Via
analyses on three different network datasets, we quantify
the effectiveness of our techniques, showing that they can
uncover signiﬁcant amounts of sensitive information. We
also discuss prospects for preventing these deanonymiza-
tion attacks.
1 Introduction
In order to provide a sound scientiﬁc foundation for
some types of research on network systems, it is impera-
tive that trace and log data be made publicly available for
veriﬁcation and comparison of results. Indeed, the lack of
public datasets has been identiﬁed as a key weakness in cur-
rent networking research [22], and work is underway to con-
struct a large, shared repository of network trace data [23].
To protect the privacy of end users and the security
of the networks themselves, it is clearly necessary to ob-
scure certain identifying information (e.g., IP addresses)
before it is published. Several methods for such network
trace anonymization have recently been proposed (e.g.,
[19, 26, 10]). The authors of these schemes generally ac-
knowledge both the difﬁculty in creating an anonymization
scheme free from all forms of information leakage, and that
∗Department of Computer Science, Johns Hopkins University, Balti-
†CERT/Network Situational Awareness, Software Engineering Insti-
‡Electrical & Computer Engineering Department and Computer Sci-
ence Department, Carnegie Mellon University, Pittsburgh, PA, USA;
PI:EMAIL
more, MD, USA; {coulls,cwright,fabian}@cs.jhu.edu
tute, Carnegie Mellon University; PI:EMAIL
more in-depth analysis of anonymization schemes is needed
(e.g., [19]). Lacking such analysis, however, the community
continues to move forward with the release of network data
anonymized using these and similar techniques (e.g., [23]).
In this paper, we conduct such an analysis in order to in-
form the continuing debate over the release of anonymized
network trace data. Speciﬁcally, we detail new techniques
to infer sensitive information from such traces, and using
these techniques we show that current anonymization tech-
niques might not protect sensitive information as well as ini-
tially thought. While the existence of some classes of infor-
mation leakage from individual header ﬁelds had been ac-
knowledged [19, 26, 10], these attacks are often dismissed
as easily mitigated by changes to the anonymization pol-
icy. Our study demonstrates that there are more substantial
forms of information leakage that inherently compromise
current anonymization methodology. Fundamentally, these
leaks result from patterns that naturally occur as artifacts of
useful anonymized network data. The ability to subvert cur-
rent anonymization methodology with only public informa-
tion sources provides attackers with a dangerous new tool
for passive network reconnaissance.
To demonstrate the validity of these attacks, we explore
the information leaked by the state-of-the-art anonymiza-
tion system of Pang et al. [19] when used under the rec-
ommended policy settings. As a concrete example, we ap-
ply our techniques to anonymized traces from three distinct
networks with different trafﬁc mixes and numbers of hosts.
Our results show that sensitive network topology and host
behavioral information can be extracted from patterns ob-
served in the anonymized IP addresses and port numbers.
Using this topology and behavioral information, along with
purely public information from search engines and DNS
records, we are able to deanonymize between 28 and 100%
of targeted servers. While we choose to focus on the Pang
et al. approach, we also show that our ﬁndings are equally
applicable to a number of other recent techniques in the
literature, thereby calling into question the overall beneﬁts
provided by current anonymization strategies.
The remainder of this paper is organized as follows. In
Section 2, we review various methods for anonymizing net-
1
work data, as well as the pragmatic requirements on the
resulting data. The primitives used in our inference tech-
niques are introduced in Section 3, and their speciﬁc use in
inferring topology information and selectively deanonymiz-
ing hosts is presented in Section 4. In Section 5, we apply
our techniques to anonymized network data taken from a
variety of networks, and show that our techniques are effec-
tive in deanonymizing hosts in a passive manner using only
publicly available information. Finally, we suggest possible
mitigation strategies in Section 6, and conclude with direc-
tions for future work in Section 7.
2 Background and Related Work
Anonymization systems, in general, are designed to ac-
complish three primary goals while providing usable net-
work trace data. These goals, as described by Pang et al.,
are aimed at preventing i) the true identities of speciﬁc
hosts from being leaked such that an audit trail of user
activity could be formed, ii) the true identities of internal
hosts from being leaked such that a map of supported ser-
vices can be constructed, and iii) the leakage of speciﬁc
security practices within the publishing organization’s net-
work [19]. Several methods of data obfuscation are uti-
lized in practice to achieve these goals [2, 20, 26]. De-
struction of information in a ﬁeld (e.g., by outright removal
from the dataset) is often used to anonymize the payload
ﬁelds of packet traces. Fixed transformation provides a
single pseudonym value for all values of the ﬁeld. Vari-
able transformation allows for different pseudonym values
based on the context of the ﬁeld. One example of vari-
able transformation is to replace an IP address with different
pseudonyms based upon the type of application layer proto-
col, such as HTTP or SMTP. Typed transformation allows
for a single pseudonym value for each distinct value of the
original ﬁeld. Preﬁx-preserving address anonymization is a
version of typed transformation.
There have been several attempts to provide anonymiza-
tion techniques appropriate for network trace data. The
TCPurify tool, for example, implements the destruction by
randomizing IP addresses, and removing packet payloads
[28]. By randomizing the addresses, TCPurify provides
protection for the true identity of hosts, but also destroys
useful network preﬁx information. TCPdPriv uses another
approach known as preﬁx-preserving anonymization to pro-
vide typed transformation of the addresses, whereby the
longest common preﬁxes within the trace data are mapped
to the same pseudonym preﬁx [27]. The preﬁx table used by
TCPdPriv is created on a per trace basis, and therefore it is
likely that a particular host will map to different pseudonym
addresses in different network traces.
Recently, Fan et al. developed a cryptographic approach,
known as CryptoPAn, for the creation of preﬁx-preserving
pseudonym addresses without the need for a preﬁx table
[10]. The cryptographic approach to anonymization uses
keyed hash functions to produce consistent anonymized
preﬁx-preserving addresses, thereby allowing for the pub-
lication of several traces with consistent network informa-
tion throughout. The approach of Fan et al. [10] has been
widely used in several recent systems that provide policy-
based anonymization of trace data. These policy-based sys-
tems allow for the application of any of the transformations
described above based on the security policy provided by
the user. One such example, suggested by Pang and Paxson,
provides a method for deﬁning policy-based anonymization
scripts utilizing the Bro scripting language [20]. A differ-
ent approach, called CANINE [25, 26], operates on Net-
Flow [6] data, but limits the abilities of the dataset pub-
lisher by allowing only for certain classes of anonymiza-
tion on a particular subset of ﬁelds. In particular, the CA-
NINE’s preﬁx-preserving anonymization only allows the
use of CryptoPAn, and provides no methods to implement
other anonymization techniques.
Of course, while the aforementioned deﬁnitions suggest
various ways in which network data may be sanitized, the
use of anonymization techniques in practical network re-
search forces the anonymization systems to adhere to sev-
eral requirements with regard to the resulting data. Here,
we attempt to summarize what appears to be a minimum
set of requirements that show up repeatedly in networking
research.
One of the most obvious and intuitive requirements is
that the network and hardware addresses provided within
the trace data be consistently anonymized, within and pos-
sibly across traces. Several areas of research (e.g., trafﬁc
matrix estimation [5, 11, 21, 34], characterization of con-
nection and packet arrival processes [15], and other work
that rely on counting the number of distinct hosts in a trace
over some period of time [17, 16]), require that metrics
be evaluated on a per host, or per network basis. Without
consistent anonymization, these metrics could be applied
only to each individual trace, rather than to the dataset as a
whole. As such, the resulting data would be of little value to
researchers in search of large, realistic, datasets — indeed,
the main impetus behind the current trend towards making
more anonymized datasets available in the ﬁrst place. For
the remainder of this paper, we refer to this requirement
on anonymized data as the pseudonym consistency require-
ment.
Similarly, while payload destruction has been standard
practice in providing privacy, the transport, network, and
link layer headers typically remain intact. Use of header in-
formation remains central to providing a ﬂexible dataset for
use in many areas of fundamental network research (e.g.,
the effects of packet loss and reordering on TCP dynamics
[14, 13, 1, 30, 32]). To remain appealing to the network re-
2
Destruction
Fixed Transformation
Variable Transformation
Typed Transformation
Pseudonym Consistency Requirement
Header Requirement
Transport Protocol Requirement
Port Number Assumption
Requirements met
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Pang et al.
CANINE
Transformation
TCPdPriv
TCPurify
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Examples
[11] [21] [34] [15]
[13] [14] [1] [30]
[17] [16]
[12] [24]
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Table 1. Summary of anonymization techniques and the corresponding requirements they meet
search community, the anonymization approach must there-
fore respect this requirement for header information, which
we herein refer to as the header requirement.
In addi-
tion, records corresponding to transport layer trafﬁc must
be present within the dataset to facilitate studies on round
trip times, reassembly, and fragmentation. This minimum
amount of transport layer trafﬁc is subsequently referred to
as the transport protocol requirement.
Finally, the ability to uniquely map well-known applica-
tion layer services to their constituent port numbers is often
used in practice for protocol classiﬁcation schemes (e.g.,
[12, 24]). While the requirement that port numbers faith-
fully map to their related well-known services may seem
onerous, we note that there are still many ways to infer the
correct service being offered from anonymized or destroyed
port numbers. Recent research, for example, has indicated
that application layer services can be accurately identiﬁed
through the use of timing and size information [31], as well
as the unique behaviors of the application layer protocols
[9, 18, 7]. The ability to map port numbers to services is
subsequently called the port number assumption.
A cursory examination of anonymized network data
repositories, such as CRAWDAD [8], reveals that these
requirements are frequently relied upon in practice. Of
all the trace anonymization techniques suggested to date
[28, 27, 25, 19], we focus on what we believe to be the most
comprehensive approach, namely that of Pang et al. [19].
We believe their approach best meets the pragmatic require-
ments outlined previously, and is arguably the most ﬂexi-
ble in satisfying the privacy of publishing organizations. A
comparison of the anonymization systems, their methods
of anonymization, and their adherence to the pragmatic re-
quirements is given in Table 1.
Additionally, our choice to examine the Pang et al.
anonymization system is further motivated by a weak-
ness in CryptoPAn [10]. Speciﬁcally, the preﬁx-preserving
methodology of CryptoPAn anonymizes addresses such that
any given bit of the anonymized address is dependent on
all previous bits of the unanonymized address. This de-
pendence causes a single deanonymization to affect all
In fact, Brekne et al.
anonymized addresses that share a preﬁx with the true ad-
dress.
recently demonstrated how
active probing attacks can be used to systematically under-
mine the CryptoPAn anonymization scheme [4, 3].
Pang et al., however, only use CryptoPAn to anonymize
addresses external to the enterprise where the trace was col-
lected. To anonymize internal addresses, Pang et al. break
the dependency across bits by anonymizing the subnet and
host portion of the addresses as independent blocks using
a pseudo-random permutation. Although the separation of
the anonymization into two independent permutations may
still lend itself to attacks where the adversary learns the
deanonymized host’s true address, only that host’s speciﬁc
subnet is compromised in this case; that is, no information is
discovered about other host mappings and subnet permuta-
tions from this single deanonymization. A more detailed re-
view of the CryptoPAn weakness can be found in Appendix
A.
3 Primitives
The deanonymization techniques we develop in this pa-
per are based on a few simple primitives. These primi-
tives, with the exception of Subnet Clustering, were ﬁrst
proposed by Xu et al. [33] to provide summary informa-
tion about the trafﬁc at backbone routers. We apply these
techniques to determine the statistically signiﬁcant values
within the network trace data. In addition, we also apply our
own Subnet Clustering technique to infer the subnets of net-
works from only the observed addresses. Discovery of the
proper subnets and their sizes aid in the passive inference of
topology from the provided trace data. However, unlike Xu
et al. [33], we apply these techniques to anonymized net-
work traces, and our deanonymization techniques require
additional analysis on top of that provided by these tools.
For the remainder of the paper, we represent network
data, in the form of packet traces or NetFlow logs, as a set
of connections, C. Each connection c ∈ C is described
by a feature vector (cid:104)c1, c2, ..., ck(cid:105). In our case, k = 4, and
the features are: c1 = source IP address, c2 = destination
3
IP address, c3 = source port number, and c4 = destination
port number. Several of our techniques employ analysis of
the normalized entropy (H) of one or more features of the
data. The normalized entropy provides a measure of the un-
certainty of outcomes for the given feature, relative to the
maximum possible uncertainty of a random variable taking
on the same values. Speciﬁcally, we denote the ith feature
across all connections in C as Ci, and treat it as a random
variable. Then, if Ci takes on ni > 1 distinct values in our
data, we calculate its normalized entropy as
H(Ci) = H(Ci)
log ni
where for each c, the probability PC(Ci = ci) is the number
of occurrences of value ci in feature Ci, divided by |C|.
Thus, normalized entropy values near zero indicate a
highly peaked distribution for that attribute, while values
near one indicate a nearly uniform distribution of values.
Given an anonymized dataset, we will use this measure to
ﬁnd a set of hosts within that data whose presence is most
signiﬁcant—the so-called ‘heavy-hitters’.
Intuitively, if a
few IP addresses occur much more frequently than others
in the data, then the normalized entropy of the addresses
will be low. Because of this fact, we can employ an itera-
tive algorithm, shown in Algorithm 1, to obtain the set
of the most signiﬁcant IP addresses in the data. This al-
gorithm works by repeatedly removing very frequent (ini-