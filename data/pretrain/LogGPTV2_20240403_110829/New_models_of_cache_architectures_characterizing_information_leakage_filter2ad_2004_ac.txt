fake interference. The mutual information can accurately
reﬂect the interference between the attacker and the victim
through cache side channels.
(cid:88)
(cid:88)
(cid:18) PI,O(Ip(cid:48) , Oq(cid:48) )
(cid:19)
I(I;O) =
PI,O(Ip(cid:48) , Oq(cid:48) ) log
0≤q(cid:48)<n
0≤p(cid:48)<n
PI(Ip(cid:48) )PO(Oq(cid:48) )
(6)
We can also use the Interference Probabilities to identify
cases of no information leakage, based on the three non-
interference conditions in Equations 2, 3 and 4.
C1 (Output Elimination) For all 0 ≤ q < n, PO(Oq)
is close to 0. Then the attacker can not observe any in-
formation through the cache side channel, and there is no
information leakage.
C2 (Noise Domination) For all 0 ≤ q < n, PI|O(I−1|Oq )
is close to 1. Then all of the attacker’s observations are
caused by the channel’s noise, the victim’s actions do not
aﬀect the attacker’s observations. Hence there is no infor-
mation leakage.
C3 (Input Ambiguity) For all 0 ≤ p < n and 0 ≤ q < n,
PI|O(Ip|Oq) is close to PI(Ip). Then the victim’s actions
cannot be distinguished by the attacker’s observations, and
there is no information leakage.
5.2 Case Study: Type I Attacks
In Section 2.1 we classify the side-channel attacks into
four categories based on the root causes of the attacks: the
interference due to cache behaviors. Our cache modeling
technique targets the root causes, so it can cover all the
categories. As a case study, we pick type I attacks based on
cache misses due to external interference, and study diﬀerent
caches’ vulnerability to this type of side-channel attacks.
Other attack types can be evaluated in a similar way.
For Type I cache attacks, the attacker observes cache
misses due to external interference. Whenever a cache line
occupied by an attacker is over-written (replaced) by a cache
line belonging to a victim, the attacker will have an obser-
vation by detecting a cache miss when he next accesses this
cache line that he had previously ﬁlled with his own data.
Speciﬁcally, when the victim’s cache line with a cache index
of p wants to replace the attacker’s cache line with a cache
index of q (for conventional caches, p = q), a cache state
transition from A to V happens, and this will be an Ex-
ternal Interference (shown in Figure 1). The cause of this
External Interference is the victim’s input Ip to the cache
side channel, and the result of this External Interference is
the attacker’s output Oq from the cache side channel later.
So this is the interference Ip → Oq.
It is also possible that the eviction of the attacker’s cache
line is not due to the victim’s actions. This happens in RE
cache when the attacker’s cache line is randomly selected to
be evicted out, or in RP cache when the attacker’s cache
line is invalidated due to the update of permutation tables.
Speciﬁcally, when the attacker’s cache line with a cache in-
dex of q is evicted out of the cache due to such noise, a cache
state transition from A to INV happens, and we call this
Fake Interference (Figure 1). The cause of this Fake Inter-
ference is the side channel’s inherent noise, and the result of
this Fake Interference is the attacker’s later observations of
output Oq from the cache side channel. The interference is
labelled I−1 → Oq.
To evaluate the caches’ vulnerability to Type I attacks,
we count the number of each kind of External Interference
and Fake Interference. Then we use Equation 5 to calculate
Interference Probabilities. Finally we calculate the mutual
information in Equation 6 and use the three non-interference
conditions to conﬁrm the absence of information leakage.
We use Murphi [25] to implement our cache security mod-
els with the interference property. Murphi is a ﬁnite state
machine model checker, used to verify the invariants of the
system by enumerating all the explicit states.
Instead of
checking invariants, we use Murphi to go over all the pos-
sible cache states and record the Information Flow Log
for each transition. Without loss of generality, we assume a
3-set, 2-way set-associative conventional cache as the base-
line for this study. We used 10 rounds of memory accesses,
which was enough to get stable interference probabilities.
Murphi will analyze all the possible states, for all the cache
lines in the cache.
5.3 Evaluation Results
5.3.1 Analysis of Non-interference Conditions
For each cache, we collect counts for the Information
Flow Log, including counts of the number of each type of
interference. From this, we calculate the joint Interference
Probability between each input and each output.
Conventional Cache: Table 3 gives the results for the
baseline conventional cache. We observe that for a conven-
tional cache, PI,O(Ip, Oq) is very distinguishable for (q = p)
compared to (q (cid:54)= p), and none of the three conditions C1,
C2 or C3 are satisﬁed. So the input I interferes highly with
the output O. We conclude that the conventional cache is
very leaky, and hence insecure.
Table 3: Interference Probability for conventional cache
PI,O(I, O)
O0
O1
O2
I2
I1
Io
I−1
33.3% 0.0% 0.0% 0.0%
0.0% 33.3% 0.0% 0.0%
0.0% 0.0% 33.3% 0.0%
(27,996 interferences in total)
Static-Partitioning Cache: Table 4 shows the Interference
Probability of an SP cache. There are no attacker’s observa-
tions from SP cache, satisfying condition C1. So SP cache
can eﬀectively reduce Type I side-channel leakage to zero.
Table 4: Interference Probability for SP cache
PI,O(I, O)
O0
O1
O2
I2
I0
I1
I−1
0.0% 0.0% 0.0% 0.0%
0.0% 0.0% 0.0% 0.0%
0.0% 0.0% 0.0% 0.0%
(0 interferences in total)
Partition-Locked Cache: Tables 5a and 5b display the In-
terference Probability of PL cache without and with preload.
PL cache without preload has the same interference distribu-
tion as conventional caches, indicating that PL cache with-
out preload can leak information when loading the victim’s
cache lines into the cache for the ﬁrst time. PL cache with
preload has the same interference distribution as SP cache,
indicating that with proper usage like preloading the victim’s
sensitive cache lines, PL cache prevents information leakage.
This example demonstrates the power of our methodol-
ogy: even though the PL cache without preload may survive
the ”Prime and Probe” attack during experimentation, our
security modeling of PL cache still reveals its vulnerability:
there can still be information leakage targeting the cache
warm-up stage. This agrees with the observation in [26].
Table 5: Interference Probability for PL cache
(a) without preload
(b) with preload
PI,O(I, O)
O0
O1
O2
I2
I1
I0
I−1
33.3% 0.0% 0.0% 0.0%
0.0% 33.3% 0.0% 0.0%
0.0% 0.0% 33.3% 0.0%
PI,O(I, O)
O0
O1
O2
I2
I1
I0
I−1
0.0% 0.0% 0.0% 0.0%
0.0% 0.0% 0.0% 0.0%
0.0% 0.0% 0.0% 0.0%
(13,794 interferences in total)
(0 interferences in total)
Random-Eviction Cache: Now let us consider the ran-
domization approach. The Interference Probability of RE
cache is shown in Table 6. The results show that a large
amount of interference is fake (70.8%). Although it is still
possible for the attacker to retrieve side-channel information
from the rest of the interferences (29.2%), it will be a hard
job to ﬁlter out the noise due to fake interference from the
observations. According to C2, the larger the proportion of
fake interference, the more diﬃcult it is for the attacker to
retrieve useful information.
Table 6: Interference Probability for RE cache
PI,O(I, O)
I0
I1
I2
I−1
O0
O1
O2
9.7% 0.0% 0.0% 23.6%
0.0% 9.7% 0.0% 23.6%
0.0% 0.0% 9.7% 23.6%
(117,349,797 interferences in total)
Random-Permutation Cache: Table 7 displays the Inter-
ference Probability for RP cache. We can see that Fake
Interference constitutes a very high percentage of the total
interferences (80.4 %). This is due to the cache line inval-
idations done when swapping mappings in the permutation
table.
In addition, the interference of each Ip on each Oq
has about the same probability. This is due to the random
mapping from memory address to cache set. When the at-
tacker observes a cache miss in set q, it is hard for him to tell
which set is accessed by the victim. Both non-interference
conditions C2 and C3 hold, thus enhancing the security of
RP cache against Type I side-channel leakage.
Table 7: Interference Probability for RP cache
PI,O(I, O)
I0
I1
I2
I−1
O0
O1
O2
2.17% 2.19% 2.19% 26.8%
2.19% 2.17% 2.19% 26.8%
2.19% 2.19% 2.17% 26.8%
(7,842,324 interferences in total)
NewCache: We simulate a NewCache with 3 logical cache
lines and 2 physical cache lines. Table 8 shows the Inter-
ference Probability. Due to the fully-associative mappings
from the Logical Direct Mapped cache to the physical cache,
the interference of Ip on any Oq happens with the same
probability. According to non-interference condition C3,
the attacker’s observations are not aﬀected by the victim’s
actions. This means NewCache does not leak information
through Type I side-channel attacks.
Table 8: Interference Probability for NewCache
PI,O(I, O)
O0
O1
O2
I0
I1
I2
I−1
11.1% 11.1% 11.1% 0.0%
11.1% 11.1% 11.1% 0.0%
11.1% 11.1% 11.1% 0.0%
(1,368,954 interferences in total)
5.3.2 Mutual Information
For each cache architecture, we calculate the mutual in-
formation between the victim’s actions and the attacker’s
observations based on Equation 6 (the logarithm base is 2
and information leakage is measured in bits), as shown in
Table 9. This shows that the conventional cache and PL
cache without preload leak the most information. RE cache
has a smaller mutual information value, but still gives the
attacker some chances to retrieve critical information. The
mutual information of RP cache is close to zero, indicating
that it will be hard for the attacker to leak secrets with Type
I side-channel attacks. SP cache, PL cache with preload and
NewCache have zero mutual information, so the attacker can
not get the victim’s secrets from his observations.
The conclusions from mutual information are consistent
with our previous analysis of non-interference conditions.
Table 9: Mutual Information for each cache architecture
Cache Architecture
I(I, O) (bits)
Conventional
SP
PL-w/o preload
PL-w/ preload
RE
RP
New
1.585
0.000
1.585
0.000
0.461
2.586×10−6
0.000
5.4 Discussion
From the above analysis we observe that diﬀerent defenses
usually focus on diﬀerent non-interference conditions. For
the partitioning approach, the defenses usually try to realize
C1. The attacker cannot observe output from the channel as
it is isolated from the victim (SP cache and PL cache). For
the randomization approach, the defenses usually try to re-
alize C2 and C3. For C2, the cache adds a large amount of
random noise to the attacker’s observations (RE cache and
RP cache). For C3, the cache randomizes the mappings be-
tween the victim’s actions and the attacker’s observations
(RP cache and NewCache). This ambiguity makes it hard
for the attacker to get accurate conclusions about the vic-
tim’s actions. Any of the three conditions is eﬀective at
reducing the side-channel leakage. We hope this will inspire
researchers to propose more defenses beyond the partition-
ing and randomization approaches discussed in this paper.
Our modeling methodology provides diﬀerent usages: (1)
a general evaluation of a cache’s vulnerability to side-channel
attacks, as in this paper, considers all possible cache state
transitions for successive rounds of memory accesses. This
will cover all possible attacks on all ciphers; (2) an evaluation
of a cache’s vulnerability to a speciﬁc attack on a speciﬁc
cipher, can be achieved by feeding the cache models with
the victim’s and attacker’s actual memory access traces.
6. MODELING OTHER ATTACKS
We discuss how to apply our modeling methodology to
other cache side-channel attacks and cache features.
6.1 Other Cache Attacks
Our case study focused on Type I attacks:
the cache
misses that cause external interference between the attacker
and the victim. So we consider the transitions of V miss,
from state A to V. Our model can also be applied to the
other three attack categories in Table 1.
(1) Type II Attacks: These are based on cache misses due
to internal interference, so we consider the transitions of
V miss from state V to V. The channel’s input Ip is the
victim’s access with a cache index of p, and the output Oq
is the victim’s replaced cache line with a cache index of q.
A random cache mapping for the victim can make Ip → Oq
ambiguous, reducing the vulnerability to leak information.
(2) Type III Attacks: These are based on cache hits due to
external interference. We need a fourth type of state A/V,
indicating this line contains a memory line shared by the
victim and the attacker. Then we consider the transitions
of A hit from state A/V to A/V. The channel’s input Ip is
the victim’s access of a shared line with address index p, and
the output Oq is the event that the attacker gets a cache hit
in the cache set q. Ip → Oq denotes the interference that the
attacker’s line with address index p gets a cache hit in the
cache set q, due to the victim’s placement of this shared line.
We denote I−1 as the event that brings the victim’s line into
the cache for non-critical operations like prefetching, then
I−1 → Oq is a Fake Interference which can introduce noise.
(3) Type IV Attacks: These are based on cache hits due to
internal interference. We consider the transitions of V hit
from state V to V. The input Ip to the channel is the event
that the victim brings its line with index p into the cache,
and the output Oq is the event that the victim gets a cache