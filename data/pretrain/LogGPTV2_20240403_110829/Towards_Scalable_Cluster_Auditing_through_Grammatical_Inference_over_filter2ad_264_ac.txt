expect all workers to follow the same general workﬂow, we
treat UIDs as immutable; in other words, the presence of a
new agent on a given node will be visible in the ﬁnal model.
Graph Abstraction Algorithm. Graph abstraction is trig-
gered by a cluster-wide conﬁgurable epoch t, after which each
node performs abstraction locally. In Figure 6, we outline
the pseudocode for efﬁcient traversal of provenance graph
and apply abstraction on each vertex. Because all activities
are connected to their child activities, traversing the activity
nodes while inspecting their immediate artifact/agent children
is sufﬁcient to perform a complete traversal of the prove-
nance DAG. In Figure 6, the functions ABSTRACTACTIVITIES,
ABSTRACTFILES, ABSTRACTSOCKETS, and ABSTRACTA-
GENTS apply the transformations discussed above to the input
DAG.
Discussion. Performing the abstractions discussed above will
invariably lead to a loss of context in the resulting global
model. Eventually, we may need this instance-speciﬁc infor-
mation to perform further attack investigation and incident
response. Therefore, an unmodiﬁed record of each worker’s
provenance (Dag) is maintained on the local node. An ad-
ditional concern is that our abstraction techniques can lead to
mimicry attacks [66] by launching attack process with the same
Function GRAPHABSTRACT(Dag, sysF iles, τF ile, τSock)
/* Root is always Process Vertex
Root ← Get Root from Dag
Dag(cid:48) ← Dag.copy()
Queue.push(Root)
while Queue is not empty do
currentV ertex ← Queue.pop()
children ← currentV ertex.Children()
θf iles ← children.getFileSubtype()
θsocks ← children.getSocketSubtype()
θprocs ← children.getProcessSubtype()
θagent ← children.getAgentType()
Queue.push(θprocs)
Dag(cid:48) ← ABSTRACTACTIVITIES(Dag(cid:48),θprocs)
Dag(cid:48) ← ABSTRACTFILES(Dag(cid:48), sysF iles,θf iles, τF ile)
Dag(cid:48) ← ABSTRACTSOCKETS(Dag(cid:48),θsocks, τSock)
Dag(cid:48) ← ABSTRACTAGENTS(Dag(cid:48),θagent)
end
/* Return Abstracted Provenance DAG
return Dag(cid:48)
*/
*/
Fig. 6: Pseudocode of Provenance Graph Abstraction Function. Func-
tions getFileSubtype, getSocketSubtype, getProcessSubtype,
getAgentType extract ﬁle, socket, process and agent vertices respec-
tively from children list.
name and commandline arguments. However, as we never
remove process vertices during abstraction and further, the
causal path of attack process vertex will be different, mimicry
attacks will always be visible in the ﬁnal model. Finally, we
note that Section V considers the compression beneﬁts of graph
abstraction in isolation to our other techniques; abstraction
reduces overall log size by roughly 27% in our experiments.
E. Provenance Graph Induction
To generate a global model of worker activity, Winnower
makes use of graph grammar learning techniques. However,
graph grammars as described in Section II-C are not
im-
mediately applicable to provenance graphs. Operations like
parsing and induction in prior approaches are prohibitively
costly in terms of runtime complexity [41]; this is in part
because they consider the general class of directed graphs, in
which cycles are common. More importantly, graph grammar
techniques are prone to over generalization; in the case of
data provenance, this creates the risk of erasing important
causal relations between system objects. Consider for example
the provenance of the httpd process in Figure 7. Here the
WasTriggeredBy edges encode an important series of causal
relations; However, in experimentation with past techniques
we discovered that the learning system would treat all httpd
6
ftppid:2788ftp workerpid:2797192.168.0.2/etc/login.defsversion 0ftp listenerpid:2789192.168.0.1/usr/lib/libpq.soversion 0ftp listenerpid:2791ftp workerpid:2795192.168.0.2192.168.0.2/output/ﬁle1version 0/output/ﬁle2version 0AbstractionInduction(a)CFDEBHGA:= SS := C…. [other production rules]A := /usr/lib/libpq.so (File)B := /etc/login.defs (File)C := ftp (Process)E := ftp listener(Process)F := ftp worker(Process)G := *(File)H := 192.168.0.0/24(Socket)(c)ftpftp worker192.168.0.0/24/etc/login.defsftp listener192.168.0.0/24/usr/lib/libpq.softp listenerftp worker192.168.0.0/24192.168.0.0/24**(b)Function INDUCTION(InputDags)
/* Bootstrapping Step
Dag ← COMBINEROOTS(InputDags)
Dag ← TOPOLOGICALSORT(Dag)
Gram ← ∅
foreach vertex ∈ Dag do
τpref ix ← GETPREFIXTREE(vertex)
τsuf f ix ← GETSUFFIXTREE(vertex)
Gram ← Gram ∪ {τpref ix, τsuf f ix, vertex.label}
end
/* Search Step
Gramf inal ← SEARCH(Dag, Gram)
return Gramf inal
*/
*/
Function SEARCH(Dag, Gram)
cost ← Map from grammar to mdl cost
cost[Gram] ← MDL(Dag,Gram)
explore ← PriorityQueue()
explore.push(Gram)
while explore is not empty do
Grammin ← explore.pop()
foreach state1,state2 ∈ Grammin do
Gramnew ← MERGE(Dag, Grammin,state1,state2)
if Gramnew was not seen then
cost[Gramnew] ← MDL(Dag,Gramnew)
explore.push(Gramnew)
if terminated early then
/* Final minimum mdl cost grammar
Gramf inal ← GETMIN(cost)
return Gramf inal
end
end
/* Final minimum mdl cost grammar
Gramf inal ← GETMIN(cost)
return Gramf inal
Function PARSE(Dag, Gram)
Dag ← TOPOLOGICALSORT(Dag)
Gnew ← Gram.copy()
/* Go through each vertex and confirm the pairing is
acceptable
foreach vertex ∈ Dag do
τpref ix ← GETPREFIXTREE(vertex)
τsuf f ix ← GETSUFFIXTREE(vertex)
if not ACCEPT(Gram,τpref ix,τsuf f ix,vertex) then
Gnew ← Gnew ∪ {τpref ix, τsuf f ix, vertex.label}
end
/* Perform search step from induction function on Gnew
Gramf inal ← SEARCH(Dag, Gnew)
return Gramf inal
*/
*/
*/
*/
Fig. 8: Pseudocode Graph Grammar Induction and Parsing Functions.
Functions GetPrefixTree and GetSuffixTree return preﬁx and
sufﬁx tree of input vertex respectively while Function GetMin returns
minimum cost grammar from input map.
grammar Gram for Dag. After bootstrapping, if two vertices
are deﬁned by the same tuple they are considered equivalent
and merged implicitly in the ﬁnal grammar. For example, in
Figure 5b, the preﬁx/sufﬁx state trees of the two ftp worker
vertices are considered the same, and therefore share an entry
in Gram.
Searching.
In this step, the algorithm searches for graph
grammars that improve on the na¨ıve initial speciﬁc grammar
by attempting to minimize the MDL equation 1. The MERGE
function applies a “state merging” procedure from DFA learn-
ing systems [32], [68]. The main purpose of state merging is
to ﬁnd repetitive structures in the graph and combine them in
the grammar. The MERGE function takes two states from the
Fig. 7: A simpliﬁed provenance graph of an Apache webserver
serving a single user request. Past approaches to graph grammar
learning would overgeneralize this graph.
worker activities as identical, regardless of their ancestry or
progeny. In other words, we discovered that the rich contextual
information of a provenance graph is difﬁcult to encode as a
grammar.
To solve this problem, we adapt techniques from DFA
learning. In standard DFA learning [32], [68], the present
state of a vertex includes the path taken to reach the vertex.
We extend DFA learning to data provenance by deﬁning the
state of a vertex not only by its label, but also its preﬁx
state tree (τpref ix) and sufﬁx state tree (τsuf f ix). A vertex
v’s preﬁx state tree is its provenance ancestry – a subgraph
describing all the system principles and events that directly or
transitively affected by v. v’s sufﬁx state tree is its provenance
progeny – a subgraph describing all of the system principles
and events that were in part derived or affected by v. In other
words, each system object is deﬁned by its label, the system
entities that informed its present state,
the system entities
whose state it informed. In this way, we can be sure that
graph induction will retain all causal information needed to
describe provenance of system objects. In the example shown
in Figure 5b, ftp worker’s τpref ix consist of ftp listener,
ftp, /usr/lib/libpq.so, and /etc/login.defs. Similarly, its
τsuf f ix consists of 192.168.0.0/24 and a summarized * ﬁle
vertex.
for
our
graph
grammar
induction
Pseudocode
(INDUCTION)
function is given in Figure 8, which is
MDL-based DFA learning algorithm [13]. We use MDL
principle as a guiding metric to choose the best grammar from
candidate grammars which minimizes the description cost of
the given graph (see §II-C). The algorithm is comprised of
the following two steps:
Bootstrapping.
In this initial step, a given worker’s input
provenance graphs InputDags merged by adding a dummy
root vertex and joining all the InputDags’s root vertices
to the dummy root.4 A single Dag is returned after apply-
ing the CombineRoots function. Next,
the preﬁx state tree
set τpref ix and sufﬁx state tree set τsuf f ix are generated
for each vertex in Dag, with the results stored in Gram.
Note that every vertex is uniquely identiﬁed by the tuple
{τpref ix, τsuf f ix, vertexlabel}. Further, the set of these com-
binations for every vertex deﬁnes the initial (speciﬁc) graph
4This step is necessary for our implementation because we make use of a
user-space provenance recorder that cannot fully track the system’s process
tree. A dummy root would not be needed if a whole-system provenance
recorder (e.g., [20]) was used instead.
7
UID:1000 Process name:bash  PID:2389 WasControlledBy  Process name:httpd main   WasTriggeredBy  Process name:httpd listener  WasTriggeredBy  Process name:httpd worker  WasTriggeredBy  Socket Address:128.0.0.0/24   Used  File Path:htdocs/index.html Version:0  operation:read  Used  Socket Address:128.0.0.0/24  WasGeneratedBy  File Path:/usr/lib/libc.so  Used  Finally, the algorithm determines for every vertex of given
DAG Dag whether or not its preﬁx tree state and sufﬁx state
tree are present in Gram. If input tree state and output state
tree of any vertex are not present in Gram then, function
ACCEPT returns F alse, meaning that Dag cannot be parsed
with Gram. Note that parsing in DFA is linear time operation
due to its equivalence to regular grammars.
In Winnower, if and only if parsing fails, it is necessary
for the worker to transmit additional provenance records to the
Monitor. To do so, the worker updates Gram to incorporate the
instance Dag by adding the unparsable vertices to it. It then
generates a new grammar by locally invoking the SEARCH
step of the INDUCTION function. The resulting new grammar
Gramf inal, is then transmitted to the Monitor.
IV. SYSTEM IMPLEMENTATION
We have implemented a prototype version of Winnower
for Linux OS with Docker Swarm version 1.2.6 and Docker
version 1.13. An architectural overview of the Winnower
system is shown in Figure 10. A complete workﬂow for
how Winnower enables auditing and attack investigation is as
follows: 1 a provenance graph for each container is generated
by the host machine using auditd; 2 a Winnower client
agent running on each worker node applies graph grammar
induction locally to produce a local model that is pushed
to the central Monitor; 3 the central Winnower monitor
performs induction to unify the local models from all worker
nodes into a single global model, maintaining a conﬁdence ζ
value for each vertex representing how many workers reported
each behavior, then transmits the global model back to the
worker nodes; 4 administrators can quickly view anomalous
activities (i.e., vertices with low ζ values) and decide whether
to investigate; 5 during an investigation, the administrator
can issue queries to the Winnower monitor, or 6 request
a complete (unabstracted) copy of the workers high-ﬁdelity
provenance graph, which is maintained on the worker nodes.
This ﬁnal step is necessary to ensure that no important forensic
context is lost during the model generation.
Worker Components. Winnower requires auditd to be
enabled on all connected worker nodes, as well as SELinux5.
SVirt [57] runs each Docker container in its own SELinux
contexts if the docker daemon is started with option –selinux-
enabled. The Docker daemon generates unique SELinux la-
bels called Multi-Category Security (MCS) labels and assigns
them to each process, ﬁle, and network socket of a speciﬁc
container. Finally, Winnower workers run a modiﬁed version
of the SPADE system [37], which parses auditd logs and
generates causal dependencies in the form of OPM-compliant
provenance graphs [39]. While our prototype makes use of
SPADE for ease-of-deployment, the provenance recorder used
by Winnower is largely modular and could be quickly replaced
by a kernel-level provenance recorder [20], [54], [61] to
achieve stronger security or completeness guarantees
When a system call occurs on the worker, the execution
and associated call arguments are captured by auditd based on
5SELinux is a Linux kernel feature that allows ﬁne-grained restrictions
on application permissions. In an SELinux enabled OS, each process has an
associated context, and a set of rules deﬁne the interactions permitted between
contexts. This allows strict limits to be placed on how processes can interact
and which resources they can access.
Fig. 9: State merging applied on two chained Hadoop jobs’ prove-
nance graph. State merging combines the repetitive subgraphs.
grammar Gram and attempts to make them indistinguishable
by merging both τpref ix trees of two selected states, leading
to the creation of a new grammar Gramnew that remains
consistent with the input Dag. Our merge function uses an
evidence driven strategy [49], which attempts to merge every
pair of states from the graph grammar to produce a new
candidate graph grammar, To support data provenance, our
MERGE function restricts merging of vertices to only those
of same type, e.g., process vertices can only be merged with
other process vertices.
A thorough description of how state merging works is out
of the scope of this paper, we refer readers to [41] for a detailed