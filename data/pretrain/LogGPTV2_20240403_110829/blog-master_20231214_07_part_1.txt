## 某音, 我要用PostgreSQL|PolarDB挑战你的短视频核心推荐算法        
### 作者                            
digoal                            
### 日期                            
2023-12-14                            
### 标签                            
PostgreSQL , PolarDB , DuckDB , 某音 , 短视频 , 推荐算法                 
----                            
## 背景                       
某音，我不得不把你卸载, 因为你知道我太多秘密.     
大家都知道抖音的算法牛掰, 看过什么就推荐你什么.  让你越看越依赖, 越用越久, 他的广告费却赚得盆满钵满, 你说气不气人, 该不该卸载.    
比如我看过王祖贤, 刘亦菲的小视频, 你就不断给我推, 咋地, 怕全天下不知道我喜欢王祖贤, 刘亦菲拍的倩女幽魂啊?      
家里领导一发现, 一吃醋, 榴莲都不够用, 关键榴莲还要我买, 吃确没我的份.      
所以把某音卸载还不解恨, 我还要掀桌子.      
你的推荐算法不是牛吗, 你不是很丝滑吗?  我让你算法牛, 让你懂我, 让你丝滑.      
今天, 我要把你的核心推荐算法按在地上摩擦, 把这个算法的门槛降低到地板难度. 让所有人都能用上, 让天下冒出无数个某音的友商, 卷死你.      
## 算法的核心     
1、给视频贴标签. 简单, 阿里云就有类似的视频服务, 可以完成涉黄赌毒、暴力、zz敏感等的识别过滤, 以及根据特征打标.  并给出视频标签s, 以及每个标签对应的权重.     
2、刷新视频的推荐指数. 简单, 根据 `浏览量 * 各标签的权重` 计算出视频的各标签的推荐分数.       
3、视频的地域池设计. 简单, 要让本地的好视频可以有上升到全国推荐的池子, 同时要让付费的广告主的视频有VIP通道(推荐特权): 设计三个池: 本地视频池(geohash, table_suffix. 或者以邮编, 或电话区号为后缀.)、全国流量池、付费推荐视频池        
- 说白了就是视频浏览量越多, 就把视频放到更大的池子里.   池子的个数, 级别可以根据业务需求自由设计.  
4、用户喜好和权重计算. 简单, 1方面是注册的时候勾选喜好, 另一方面是根据用户浏览的视频的(主、副标签及权重, 算出用户每个标签的喜好). 可以使用 JSONB / array 存储.      
5、推荐视频. 从3个池子中提取视频, 简单, 本地池: 根据用户的位置查询对应的本地表, 根据喜好标签搜索喜好的视频, 根据权重Limit返回条数; 全国池和付费推荐池以此类推; 总共就查3张表.       
6、过滤已读视频. 简单又不简单, 提取过程中, 把用户已读的视频ID剔除即可.      
- 不简单的地方1:  一个人可能浏览了很多视频; 视频被很多人浏览过;  所以列表会非常大, 如果每读一次写一条记录, 会很多条, 使用not in过滤会非常慢, 怎么办?       
    - 简单, 使用roaring bitmap, hll, datasketch 把已读列表存储成1条记录, 由于是lossy type或压缩type, 哪怕存数亿个值也只需要几十KB.      
    - [《沉浸式学习PostgreSQL|PolarDB 1: 短视频推荐去重、UV统计分析场景》](../202308/20230819_02.md)      
    - PS: [《PostgreSQL 15 preview - Use a hash table to speed up NOT IN(values)》](../202107/20210707_02.md)
    - hll其实有点类似于bloom, 可以参考 [《UID编码优化 - 用户画像前置规则 (bloom, 固定算法等)》](../201911/20191130_01.md)  bit占位图示参考:  
    - ![pic](../201804/20180409_01_pic_001.jpg)  
    - ![pic](../201605/20160523_01_pic_002.png)  
    - ![pic](../201605/20160523_01_pic_003.png)  
- 不简单的地方2:  如果已读列表非常大, 会耗费大量的CPU和IO过滤已读, 才能拿到未读的可推荐视频.  怎么解?
    - 可以借鉴广度优先和深度优先的思路, 默认是采用类似“广度优先”搜索策略, 所以会遇到大量已读. 但是我们可以使用partial index, 加个hash mod条件, 相对于全局视频数据就变成类似“深度优先”, 可以大幅度减少大量已读.  详细请看后面的SQL设计和索引设计.  
- 不简单的地方3:  把已读列表 正向存在视频表(已读的用户)? 还是 反向存在用户表(已读的视频)?     
    - 简单, 我推荐反向存在用户表里, 不会有锁冲突问题.     
- 不简单的地方4:  实时更新还是异步更新已读列表?      
    - 简单, 推荐异步存储, 先存储在redis/程序临时缓存, 后期合并到数据库内.  如果是异步更新, 在收到数据库提取的推荐视频后, 程序端要根据缓存再过滤一下.      
7、如果资源不足导致雪崩了怎么办? 简单: 
- 方法1, 预加载, 例如每次给用户批量推荐100条视频, 当用户刷到80条时, 后台已经在请求后面的100条了. 这样用户就会感到丝般柔滑.  
- 方法2, 降级到随机推荐.  使用随机采样, 不管数据量多大, 1毫秒以内就可以返回.       
[我是谁](../me/readme.md)? 没有2把刷子, 我怎么敢掀桌子? 大家说说是不是已经把某音核心推荐算法的门槛降低到地板难度. 让所有人都能用上, 让天下冒出无数个某音的友商.    
 今天, 你只需要1个PostgreSQL或PolarDB数据库, 普通macbook pro每秒就可以按喜好推荐26.7万个视频, 卷死某音.         
其实我在之前公众号的文章中已经透露了一部分demo: [平民的劳斯莱斯, 笔记本玩转短视频推荐](https://mp.weixin.qq.com/s?__biz=MzA5MTM4MzY1Mw==&mid=2247483935&idx=1&sn=aa1cd0693b66d3a06f7c7b382f83bd4c&chksm=907c7015a70bf903d4b3a756176a3fb58cb59fe88dc7e7916cd16b783878d0359d6ab49d893a&token=405049769&lang=zh_CN#rd)    
欢迎大家关注我的公众号:  PostgreSQL码农集散地        
更详细的Demo如下.      
## 测试场景      
采用[《最好用的PostgreSQL学习镜像, 不接受反驳》](https://mp.weixin.qq.com/s?__biz=MzA5MTM4MzY1Mw==&mid=2247483947&idx=1&sn=8a62a35d42d9ffc02a20f41338e5b4c6&chksm=907c7021a70bf9377680438364619075c33af7c404c9124d400f0075cad9e13b7cfd1998b820&token=405049769&lang=zh_CN#rd)    
AMD64 Chip's OS:    
```    
# 拉取镜像, 第一次拉取一次即可. 或者需要的时候执行, 将更新到最新镜像版本.      
docker pull registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts      
# 启动容器      
docker run --platform linux/amd64 -d -it -P --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg --shm-size=1g registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts    
##### 如果你想学习备份恢复、修改参数等需要重启数据库实例的case, 换个启动参数, 使用参数--entrypoint将容器根进程换成bash更好. 如下:     
docker run -d -it -P --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg --shm-size=1g --entrypoint /bin/bash registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts    
##### 以上启动方式需要进入容器后手工启动数据库实例: su - postgres; pg_ctl start;      
# 进入容器      
docker exec -ti pg bash      
# 连接数据库      
psql    
```    
ARM64 Chip's OS:    
```    
# 拉取镜像, 第一次拉取一次即可. 或者需要的时候执行, 将更新到最新镜像版本.      
docker pull registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts_arm64      
# 启动容器      
docker run -d -it -P --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg --shm-size=1g registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts_arm64    
##### 如果你想学习备份恢复、修改参数等需要重启数据库实例的case, 换个启动参数, 使用参数--entrypoint将容器根进程换成bash更好. 如下:     
docker run -d -it -P --cap-add=SYS_PTRACE --cap-add SYS_ADMIN --privileged=true --name pg --shm-size=1g --entrypoint /bin/bash registry.cn-hangzhou.aliyuncs.com/digoal/opensource_database:pg14_with_exts_arm64      
##### 以上启动方式需要进入容器后手工启动数据库实例: su - postgres; pg_ctl start;      
# 进入容器      
docker exec -ti pg bash      
# 连接数据库      
psql    
```
如果你的机器实在是拿不出手, 也可以尝试在云起实验室里面完成, 只是可能需要修改一下demo里面的数据量, 改小一点, 否则空间不够.  
 云起实验室地址:    
- https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31
## Demo    
生产请使用非unlogged table, 例子只是为了快速生成数据.      
1、3张视频表, 分别代表 本地视频池、全国视频池、VIP视频池. 三个池子总共生成3000万条记录.      
1\.1、本地视频池    
```    
create unlogged table t_videos_local_pool (    
  vid int8,  -- 视频ID      
  lid int,  -- 地区市, 电话区号      
  tag int,  -- 视频标签      
  score float4,  -- 视频标签权重      
  unique (vid,lid),    
  unique (vid,tag)    
);     
```    
PS: 你高兴的话可以按地域设置更多级别: 例如 市、省、全国.      
写入数据: 1000万条记录.    
- 100万个视频,     
- 每个视频10个标签,     
- 标签取值空间 `1 ~ 100` (也就是假设总共有100个标签, 标签越多性能越好, 因为过滤性越强, 但是为了压测可以获取到更多视频, 这里选择了更容易压出问题的少量标签).      
- lid 取值空间 `1 ~ 360` (也就是假设有360个地区市).      
```    
insert into t_videos_local_pool     
select generate_series(1,1000000), ceil(random()*360), ceil(random()*100), random()*10 from generate_series(1,10) on conflict do nothing;      
```    
1\.2、创建全国视频池    
```    
create unlogged table t_videos_top_pool (    
  vid int8,  -- 视频ID    
  tag int,  -- 视频标签    
  score float4,  -- 视频标签权重    
  unique (vid,tag)    
);     
```    
写入数据: 1000万条记录: 100万个视频, 每个视频10个标签, 标签取值空间`1 ~ 100`.      
```    
insert into t_videos_top_pool     
select generate_series(1000001,2000000), ceil(random()*100), random()*10 from generate_series(1,10) on conflict do nothing;      
```    
1\.3、创建VIP视频池    
```    
create unlogged table t_videos_vip_pool (    
  vid int8,  -- 视频ID    
  tag int,  -- 视频标签    
  score float4,  -- 视频标签权重    
  unique (vid,tag)    
);    
```    
写入数据: 1000万条记录: 100万个视频, 每个视频10个标签, 标签取值空间`1 ~ 100`.      
```    
insert into t_videos_vip_pool     
select generate_series(2000001,3000000), ceil(random()*100), random()*10 from generate_series(1,10) on conflict do nothing;      
```    
1\.4、创建 64个 partial index(分区索引), 避免过滤巨大已读列表带来巨大的无效扫描和CPU开销, 之前已经讲过:       
- [《重新发现PostgreSQL之美 - 23 彭祖的长寿秘诀》](../202106/20210613_02.md)        
```      
do language plpgsql $$      
declare      
begin      
  for i in 0..63 loop      
    execute format('create index on t_videos_local_pool (lid, tag, score desc) where abs(mod(hashint8(vid),64))=%s', i,i);      
    execute format('create index on t_videos_top_pool (tag, score desc) where abs(mod(hashint8(vid),64))=%s', i,i);      
    execute format('create index on t_videos_vip_pool (tag, score desc) where abs(mod(hashint8(vid),64))=%s', i,i);      
  end loop;      
end;      
$$;      
```      
2、创建用户标签类型      
用于存储喜欢的视频标签, 以及对应的权重      
```      
create type tag_score as (      