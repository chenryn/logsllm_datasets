title:9th International Workshop on Artificial Intelligence and Security:
AISec 2016
author:David Mandell Freeman and
Katerina Mitrokotsa and
Arunesh Sinha
9th International Workshop on
Artiﬁcial Intelligence and Security
(AISec 2016)
David Mandell Freeman
LinkedIn Corporation, USA
PI:EMAIL
Katerina Mitrokotsa
Chalmers University of
Technology, Sweden
PI:EMAIL
Arunesh Sinha
University of Michigan, USA
PI:EMAIL
Background
Artiﬁcial Intelligence (AI) and Machine Learning (ML) pro-
vide a set of useful analytic and decision-making techniques
that are being leveraged by an ever-growing community of
practitioners, including many whose applications have security-
sensitive elements. However, while security researchers of-
ten utilize such techniques to address problems and AI/ML
researchers develop techniques for Big Data analytics appli-
cations, neither community devotes much attention to the
other. Within security research, AI/ML components are
usually regarded as black-box solvers. Conversely, the learn-
ing community seldom considers the security/privacy impli-
cations entailed in the application of their algorithms when
they are designing them. While these two communities gen-
erally focus on diﬀerent directions, where these two ﬁelds do
meet, interesting problems appear. Researchers working in
this intersection have raised many novel questions for both
communities and created a new branch of research known
as secure learning. The AISec workshop has become the
primary venue for this unique fusion of research.
In recent years, there has been an increase of activity
within the AISec/secure learning community. There are sev-
eral reasons for this surge. Firstly, machine learning, data
mining, and other artiﬁcial intelligence technologies play a
key role in extracting knowledge, situational awareness, and
security intelligence from Big Data. Secondly, companies
like Google, Facebook, Amazon, and Splunk are increasingly
exploring and deploying learning technologies to address Big
Data problems for their customers. Finally, these trends are
increasingly exposing companies and their customers/users
to intelligent technologies. As a result, these learning tech-
nologies are being explored by researchers both as potential
solutions to security/privacy problems and also as a poten-
tial source of new privacy/security vulnerabilities that need
to be addressed. The AISec Workshop meets this need and
serves as the sole long-running venue for this topic.
AISec, having been annually co-located with CCS for nine
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS’16 October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4139-4/16/10.
DOI: http://dx.doi.org/10.1145/2976749.2990479
consecutive years, is the premier meeting place for researchers
interested in the junction of security, privacy, AI, and ma-
chine learning. Its role as a venue has been to merge prac-
tical security problems with advances in AI and machine
learning. In doing so, researchers also have been develop-
ing theory and analytics unique to this domain and have
explored diverse topics such as learning in game-theoretic
adversarial environments, privacy-preserving learning, and
applications to spam and intrusion detection.
AISec 2016
The ninth annual event in this series, AISec 2016 drew a
record 38 submissions, of which approximately ten were se-
lected for publication and presentation. Submissions arrived
from researchers in 16 countries, from a wide variety of insti-
tutions both academic and corporate. Paper topics included
the following:
• Theoretical topics related to security: adversarial learn-
ing, robust statistics, learning in games, economics of
security, diﬀerential privacy.
• Security applications: computer forensics, spam detec-
tion, phishing detection and prevention, botnet detec-
tion, intrusion detection and response, malware iden-
tiﬁcation, authorship identiﬁcation.
• Security-related AI problems: distributed inference and
decision making for security, privacy-preserving data
mining, adaptive side-channel attacks, design and anal-
ysis of captchas, AI approaches to trust and reputa-
tion, vulnerability testing, security policy management
& access control, anomalous behavior detection.
• Machine learning and security at scale: high-throughput
abuse detection systems, large-scale active learning,
big data analytics for security, techniques dealing with
well-resourced adversaries.
The keynote address was given by Elie Bursztein of Google,
Inc., who discussed challenges in the reproducibility of sci-
entiﬁc results from machine learning algorithms and what
we can do about it. Dr. Bursztein’s talk touched on is-
sues arising from proprietary hardware, dataset availability,
adversarial machine learning, and the ethics of data. He
also considered several privacy questions related to machine
learning models.
1881