sions to the categories she is in charge. New editors are initially
allowed to edit only a few categories, but once they have accumu-
lated a sufficient number of edits they are allowed to edit additional
areas. Community senior editors are responsible for evaluating
new editors’ applications in a transparent process that assures high
quality labeling of URLs [29]. Curlie contains 3.3 millions annotated
web pages, that cover 1 million different categories organized as
a hierarchical ontology. At the top of the hierarchy there are the
15 top-categories visible at https://curlie.org, with the addition of a
16th, not listed, Adult category. Each one of the top-categories is
The Web1,525,865 URLs344,227 categories5,100 keywords48,042 categories265,588 URLsCrowd-sourcingManualAutomatedThe Sensitive WebAutomated + ManualClassiﬁcationAutomatedCurlieCommon Crawl301 sensitivekeywordsIMC ’20, October 27–29, 2020, Virtual Event, USA
Matic et al.
Table 1: Top-10 FQDNs contributing with the largest num-
ber of URLs. For each domain we report the total number
of categories and top-categories associated to it. A ✔in the
last column indicates that multiple users are allowed to con-
tribute with the creation of new content.
FQDN
# URLs
# Cat.
# Top-Cat. Multi-user
www.angelfire.com
en.wikipedia.org
www.newadvent.org
www.imdb.com
www.weather.com
groups.yahoo.com
members.tripod.com
wunderground.com
www.facebook.com
tools.ietf.org
19,918
15,070
11,658
10,112
5,737
5,350
4,731
3,929
3,435
3,196
12,970
14,026
1,828
10,020
5,752
3,245
4,044
3,918
2,833
99
16
15
6
9
2
14
16
4
15
4
✔
✔
-
✔
-
✔
✔
-
✔
✔
Table 2: Unique categories and top-categories associated to
FQDNs and ESLDs with two or more URLs.
# Categories
FQDNs
ESLDs
FQDNs
ESLDs
Cat.
Top-Cats.
1
2
3
4
5+
2,307
17,683
8,779
4,232
10,838
1,622
13,278
6,933
3,347
9,375
18,772
17,325
4,672
1,500
1,570
14,260
13,709
3,717
1,259
1,610
and members.tripod.com) or they are encouraged to contribute by
adding comments and documents on a particular topic (e.g., www.
imdb.com and tools.ietf.org). A third dominant category which is
not visible in Table 1, are news websites that account for 20% of the
top-100 FQDNs. In such case, the content creators are the numerous
journalists and editors. In general, those three types of service are
extremely popular and 84% of the top-100 FQDNs belongs to one
of them. The remaining 16 FQDNs are specialized services offering
information on aviation, plants and hotels. After isolating the URLs
associated with these 16 FQDNs, we observe that they account only
for 1.4% of the dataset, and thus their impact on the training set
can only be marginal.
As final assessment we study the differences among per-URL and
per-domain categorization. Our goal is to understand the possible
benefits of having categories assigned to individual URLs instead
of using a the same category for all the elements under an ESLD.
To this end, for all the FQDNs associated to two or more URLs, we
extract the corresponding ESLDs as well as the overall number of
categories assigned to those domains. The results of this process
are shown in Table 2. When we use full category names only 5% of
all the URLs under a particular FQDNs or ESLDs belong to the same
category. This is somehow expected since Curlie has more than
340,000 extremely fine-grained categories. These values change
significantly if we adopt a more coarse-grained grouping, using
the top-categories; in this case 42% of the URLs under a particular
domain belong to the same category. Despite having only 16 top-
categories, and even if they include extremely generic types such
as Society or Regional, still 18% of the domains are flagged with
at least three different top-category names. Those results suggest
that any commercial solution that uses a unique category for all
the URLs under the same ESLD, in 58% of the cases would erro-
neously categorize at least one of the URLs. Our analysis on Curlie
demonstrates that the collected dataset (i) contains enough variety
for building a well-assorted training set, and (ii) offers significant
advantages compared to commercial solutions. In the next section
we explain how we leverage this dataset to create the training set
for our classifier.
2.3 Building the Classifier Training Set
Using the Article 9 of GDPR we define five sensitive categories
that include Ethnicity, Health, Political Beliefs, Religion and Sexual
Orientation. According to GDPR, the collection and processing of
information about any of these categories should be subjected to
special rules [36]. Our goal is to create a classifier that can identify
web pages that belong to those five sensitive categories. To this
end, we first identify the Curlie categories that are related to the 5
sensitive categories under GDPR, and then we collect the resulting
URLs from Curlie. Finally, we download the content associated to
those URLs and use it as training set for our classifier.
Identifying sensitive categories. Curlie contains hundreds of thou-
sands of categories and, thus, we cannot simply inspect them man-
ually to determine which ones meet the requirements for being
considered sensitive. We cannot leverage the organization of cat-
egories into a hierarchy, because we do not know the maximum
depth at which to stop the exploration without missing elements
contained in deeper branches (e.g., the category Regional/United_
States/Illinois/Localities/C/Chicago might seem not rele-
vant to health without knowing that it contains a sub-branch called
Addictions). Finally, as we do not have a list of descriptive key-
words associated to each category, we cannot either select URLs
by looking in the web pages for those keywords. It is extremely
challenging to craft such a list because the keywords we might
choose might not be representative for the Curlie dataset. For ex-
ample, a lookup of the łLGBTž across the Curlie dataset, generates
a set of 240 URLs, while searching for the keyword łgayž selects
3,873 URLs. By using our own list we incur in the risk of including
many ambiguous keywords (e.g., łvirusž) that characterize both
sensitive and non-sensitive content, or others that are too specific
(e.g., łHIVž). In both cases the consequence of the inability to in-
clude enough elements for particular categories, would result in a
significant loss in performance or even the impossibility to use the
classifier on other datasets.
We develop a technique that extracts structured knowledge from
the Curlie dataset, see Figure 1, and we use it to generate our train-
ing set. Our approach leverages the names that Curlie editors choose
for their categories to detect relevance with sensitive categories. In
detail, we first create a list of all the keywords included in the names
of the Curlie categories. Next, by selecting all the categories that con-
tain a particular keyword, we associate a keyword to the list of URLs
under those categories. For example, let’s assume that the dataset
contains only three categories Health, Health/Addictions/Food
and Health/Animals/Food with respectively 3, 100 and 20 URLs.
In such case, the list with the counting of the URLs associated to
each keyword would be: (Health, 123), (Addictions, 100), (Food,
120), (Animals, 20).
Identifying Sensitive URLs at Web-Scale
IMC ’20, October 27–29, 2020, Virtual Event, USA
Table 3: Content retrieved from the URLs of our training set,
grouped into the GDPR sensitive categories.
GDPR Cat.
#URLs GDPR Cat.
Ethnicity
Pol. Beliefs
Sex. Orientation
9,547 Health
15,668
3,924 Non-sensitive
Religion
#URLs
59,025
68,625
64,923
Figure 2 shows how representative the 301 keywords are for each
sensitive category. With respect to the specificity of the keywords,
we notice that in general 249 of the keywords (the red boxes in
the figure) are unambiguous and they uniquely identify only one
category. This is the case of łLocal_Churchesž or łMarxismž, which
immediately recall to the sensitive categories łReligionž and łPolit-
ical Beliefsž. Generic terms such as łClubs_and_Associationsž or
łOrganizationsž, that can be related to several sensitive categories,
appear to be rare and account only for 4% of all the keywords. Not
all of the sensitive categories have an equal number of keywords
and some categories are less represented. Moreover, categories such
as Ethnicity, Political Beliefs and Sexual Orientation also contain
higher percentage of generic keywords which can be associated to
multiple sensitive categories (the non-red boxes in Figure 2). A di-
rect consequence is that these sensitive categories are less likely to
generate many candidates for the corresponding Curlie categories.
At the end of the validation process, we are left with 265,558 URLs,
each one tagged with at least one GDPR-sensitive category, drawn
from 48,042 Curlie categories.
2.4 Final Labeled Dataset
After successfully mapping the GDPR sensitive categories on the
Curlie dataset, we use the labeled URLs to download the content
to train our classifier. As first step, we filter out all the URLs that
received more than one sensitive category as label. Since those
multi-category URLs will not be used to create the training set we
can avoid download the corresponding content. Next, we connect
to each URL from four different locations, two in Europe and two
in US, to maximize the likelihood of obtaining the content. We
also apply a mechanism to detect the presence of error pages, to
avoid training the classifier with spurious content. To this end, from
each web site associated to a URL, we download also a randomly
generated resource. The intuition behind this is that a request to
a non-existing resource will likely return an error page. We build
a list of hashes for the error pages, and we filter any content that
results being an error page. After this step, we generate a dataset
with 221,712 web pages that we use to train our classifier. The
dataset contains the five sensitive categories defined by GDPR, as
well as a sixth non-sensitive category. In this additional category
we include all web pages that our manual validation confirm that
do not belong to anyone of the five GDPR-sensitive categories. Table 3
shows the GDPR categories and the number of URLs associated
to each category; each URL belongs to only one GDPR category.
Health and Religion are the sensitive categories with the highest
number of URLs.
Figure 2: Sensitive categories and corresponding set of key-
words. For each set of keywords, we report how many other
sensitive categories might be associated to this same set.
After applying this process on the entire Curlie dataset, we ob-
tain a set of 110,475 unique keywords. Next, we manually inspect
those keywords to identify those that could be could be potentially
associated to sensitive categories. For this process we restrict the
focus on a subset of 5,1000 most representative keywords, which
are associated to at least 100 URLs. Moreover, we apply a greedy
approach and we include as many generic keywords as possible
(e.g., łHealthž) while discarding only those that are unlikely to
be associated with any sensitive content (e.g., łAnimalsž). At the
end of this analysis, we generate a set of 301 carefully selected
keywords which we annotate with all of the sensitive categories
that could be connected to them. Some keywords are extremely
specific (e.g., łJudaismž), while others could be linked to multiple
sensitive categories (e.g., łCommunitiesž). In the final step, we man-
ually inspect 48,042 the Curlie categories where the 301 keywords
appear, and we verify if they are indeed sensitive. When a Curlie
category is confirmed to be sensitive, all the URLs contained under
this category are added to the corresponding GDPR sensitive cate-
gory. This is a slow and time-consuming activity, but is necessary
to ensure that all the URLs are included in the correct category.
Furthermore, this manual step needs to be done only once, and we
can then re-draw URLs from Curlie with high confidence that they
will indeed be sensitive. For some elements we were able to assess
the sensitivity of the URLs by leveraging only the keyword that
appears in the category name (e.g., all the URLs under the 553 cate-
gories that embed the łLocal_Churchesž keyword). In other cases,
we inspected the structure of the Curlie categories together with
the location of the keyword. For example, of the 13,299 categories
that include the łHealthž keyword, 4,927 were under the łRegionalž
top-category and łHealthž always appeared as final sub-category
(e.g., Regional/Asia/India/Punjab/Health). After checking a
few dozen samples, in all those cases the URLs were pointing to
local services or clinics and we label all the URLs under those 4,927
categories as health-related. To facilitate the analysis, we use several
tricks including: sorting alphabetically the categories, leveraging
the information from sub-categories, checking URLs strings and
web page content. As side effect of the manual validation, all the
URLs in categories that are not sensitive are included into a sixth
Non-sensitive category.
Ethnicity372081012PoliticalBeliefs2014912Religion76127912SexualOrient.971512020406080100120# of keywords#Sensitive Categories:Health107471241-cat.2-cat.3-cat.4-cat.5-cat.IMC ’20, October 27–29, 2020, Virtual Event, USA
Matic et al.
3 BUILDING A CLASSIFIER FOR SENSITIVE
WEB PAGES
In this section we describe how we build an accurate classifier for
identifying sensitive web pages. Our objective is not to propose a
new text classification method, but rather combine existing work
in the area [12, 89] in the best possible manner for our goal.
3.1 Designing the Classifier
To develop the classifier we test different options for the algorithm,
the data preprocessing step, and the feature selection.
Classification algorithms. There is a wide range of popular algo-
rithms that are suitable for classifying web pages. Examples are
K-Nearest-Neighbors [19, 41, 49], Naïve Bayes [32, 33, 48], Sup-