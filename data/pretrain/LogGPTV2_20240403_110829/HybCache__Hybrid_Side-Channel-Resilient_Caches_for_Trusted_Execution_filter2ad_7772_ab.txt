29th USENIX Security Symposium    453
addresses from the caches. Consequently, s/he measures the
timing latency of its own memory accesses after a time in-
terval to deduce whether the victim has accessed these target
addresses.
Algorithm 1: Montgomery Ladder RSA Implementa-
tion
Input: base b, modulo m, exponent e = (en−1...e0)2
Output: be mod m
if ei = 0 then
1 R0 ← 1; R1 ← b;
2 for i from n-1 downto 0 do
3
4
5
6
7
8
9
10
11 end
12 return R0;
end
if ei = 1 then
end
R1 ← R0 × R1 mod m;
R0 ← R0 × R0 mod m;
R0 ← R0 × R1 mod m;
R1 ← R1 × R1 mod m;
The online phase of these attacks consists of three main
steps: Eviction, Waiting and Analysis. The attacker uses the
eviction set to evict the victim’s target addresses from the
cache. Next, the attacker waits an interval of time to allow
the victim to access the target addresses. Then the attacker
measures and analyzes its access time measurements to de-
termine if the victim has accessed the target addresses. This
is repeated as many times as the attacker requires to collect
sufﬁcient traces to recover the exponent bits.
The different techniques used by the attacker to perform
the eviction can be classiﬁed into two main approaches, either
access-based or contention-based. In access-based attacks
such as Flush + Reload [29, 78], Flush + Flush [26], Invali-
date + Transfer [35], and Flush + Prefetch [25], the attacker
accesses the target addresses directly by ﬂushing them out
of the cache using the dedicated clﬂush instruction [2] and
possibly exploiting timing leakage from the execution of the
clﬂush instruction [26]. This invalidates the lines containing
these addresses and writes them back to memory. Evict +
Reload [27] attacks have also been shown which do not re-
quire the clﬂush instruction, but instead evict speciﬁc cache
sets by accessing physically congruent addresses. These at-
tacks are only feasible in case of shared memory pages be-
tween the attacker and victim, usually in the form of shared
libraries. Otherwise, an attacker resorts to contention-based
attacks such as Prime + Probe [34, 38, 54, 61, 77], Prime +
Abort [15], Evict + Time [23, 61], alias-driven attacks [28],
and indirect Memory Management Unit (MMU)-based cache
attacks [71], where s/he constructs an eviction set and uses it
to trigger and exploit a cache contention in the same cache set
as the target addresses, thus evicting cache lines containing
the target addresses from the pertinent cache set.
The waiting interval should be selected and synchronized
such that the victim is expected to access the target address
at least once before the attacker analyzes the collected obser-
vations. By analyzing the collected observations, the attacker
determines whether the target address was indeed accessed by
the victim. This is achieved by different techniques depend-
ing on the attack approach, either the adversary measures the
overall time needed by the victim process to perform certain
computations [8, 10], or probes the cache with eviction sets
and proﬁles cache activity to deduce which memory addresses
were accessed [34, 38, 54, 77, 78], or accesses target memory
addresses and measures the timing of these individual ac-
cesses [29, 61]. Alternatively, the adversary can also read
values of addresses from the main memory to see whether
cache lines that contain cacheable target addresses have been
evicted to memory [28].
Cache-collision timing attacks exploit cache collisions that
the victim experiences due to its cache utilization, e.g., after
a sequence of lookups performed by a table-driven software
implementation of an encryption scheme, such as AES [10].
These attacks are out of scope in this work since they are not
common, are speciﬁc to certain software implementations,
and can only be mitigated by adapting the implementation or
locking the relevant cache lines after pre-loading them.
2.3 Limitations of Existing Defenses
To mitigate these attacks, software-based countermeasures
and modiﬁed cache architectures have been proposed in re-
cent years, which we cover in depth in the Related Work
(Section 8). These can be classiﬁed into two main paradigms:
1) applying cache partitioning to provide strict isolation, or
2) applying randomization or noise to make the attacks com-
putationally impractical. However, all proposed countermea-
sures to date either impact performance signiﬁcantly, require
explicit programmer’s annotations, are not seamlessly com-
patible with existing software requirements such as the use
of shared libraries, are architecture-speciﬁc, or do not defend
against all classes of attacks. Most importantly, all existing
defenses apply their side-channel cache protection for the
entire execution workload.
In practice, cache side-channel resilience is only required
for the security-critical (usually smaller) portion of the work-
load that is allocated to execute in isolation. Thus, non-
isolated execution should not suffer any resulting performance
costs. To address this in this work, we propose a modiﬁed
hybrid cache microarchitecture that enables side-channel re-
silience only for the isolated portion of execution, while re-
taining the conventional cache behavior and performance for
the non-isolated execution.
3 Adversary Model and Assumptions
To provide side-channel-resilient cache accesses for only
security-critical isolated execution, we propose a hybrid soft
partitioning scheme for set-associative memory structures.
454    29th USENIX Security Symposium
USENIX Association
In this work, we apply it to caches and call it HYBCACHE.
HYBCACHE aims to provide cache-based side-channel re-
silience to the security-critical or privacy-sensitive workload
that is allocated to one or more Isolated Execution Domains
(I-Domains), while maintaining conventional cache behavior
for non-critical execution that is allocated to the Non-Isolated
Execution Domain (NI-Domain). HYBCACHE assumes an
adversary capable of mounting the attacks described in Sec-
tion 2.2 and is designed to mitigate them.
Furthermore, the construction of HYBCACHE is based on
the following assumptions:
A1 Security-critical code that requires side-channel re-
silience is already allocated to an isolated component,
like a process or a TEE (enclave).
A recent trend in the design of complex applications, like web
browsers, is to compartmentalize them using multiple pro-
cesses. As an example, all major browsers spawn a dedicated
process for every tab [43] and some even use a dedicated pro-
cess to better isolate privileged components [58]. Similarly,
the widespread availability of TEEs, like SGX, encourages
developers to encapsulate sensitive components of their code
in protected environments.
A2 Isolated execution is the minority of the workload.
Isolation works best when the isolated component is as small
as possible, thus reducing the attack surface. This complies
with the intended usage of TEEs like SGX where only small
sensitive components of the code would be allocated to the
TEE. Hence, we assume only the minority of the workload
needs to be isolated. HYBCACHE still provides the same
security guarantees if the majority of the workload is isolated,
but the performance of the isolated execution would suffer.
A3 Sensitive code only uses writable shared memory for I/O
(if at all), and access patterns to this shared memory do
not leak any information.
Isolated code should focus on processing some local data,
while I/O needs should be limited to copying the input(s)
into the isolated component, and copying the output(s) out
of the component. Both of these procedures just access the
data sequentially; thus, the access patterns during I/O do not
depend on the data and does not leak any information.
A4 The attacker is not in the same I-Domain as the victim.
HYBCACHE is designed to isolate mutually distrusting I-
Domains and thus, we must assume the attacker and the vic-
tim are not in the same I-Domain. Note that, as a consequence
of A3, if a process handles sensitive data and has multiple
threads, they must all be in the same I-Domain, since they
share the entire address space. In cases where isolation be-
tween threads sharing the same address space is also required,
HYBCACHE can, in principle, provide intra-process isolation
as discussed later in Section 7.
4 Hybrid Cache (HYBCACHE)
We systematically analyzed existing contention-based and
access-based cache attacks in the literature (Section 2.2) to
identify their common root causes (besides the intrinsic shar-
ing of cache entries and latency difference between a cache
hit and miss). Cache side-channel attacks are, by nature, very
speciﬁc to the victim program and may exploit attack-speciﬁc
features such as the side-channel leakage of the clﬂush [26]
or prefetch instructions [25]. Nevertheless, each one of these
attacks is primarily caused by one or both of the following
root causes: shared memory pages (and cache lines) between
mutually distrusting code, and deterministic and ﬁxed set-
associativity of cache structures, which enables targeted cache
set contention by pre-computed eviction sets.
4.1 Requirements Derivation
In light of the above, HYBCACHE should provide side-
channel resilience between different isolation domains with
respect to their cache utilization. An adversary process shar-
ing the cache with a victim process should not be able to
distinguish which memory locations a victim accesses. Nev-
ertheless, we emphasize that the only approach to enforce
complete non-interference between different domains is by
strict static cache partitioning, such that no cache resources
are shared, and thus zero information leakage occurs. On
the other hand, this is impractical, and results in inefﬁcient
cache utilization from a performance standpoint. Our key
objective in this work is to practically address and accommo-
date this persistent performance/security trade-off of cache
structures by providing sufﬁciently strong cache side-channel-
resilience, such that practical and typical cache side-channel
attacks become effectively infeasible without necessarily en-
forcing complete non-interference. Additionally, we desire
that this security guarantee is run-time conﬁgurable, such that
it is only in effect when required.
This builds on our insight that it is neither practical nor
required to provide cache side-channel resilience for all the
code in the workload. This additional security guarantee is
only required for security-critical execution, which is a mi-
nority of the workload (Assumption A2), and usually isolated
in a Trusted Execution Environment (TEE) (Assumption A1).
Thus, we require to provide a cache architecture that provides
non-isolated execution with conventional cache utilization
(with no performance costs), and simultaneously side-channel-
resilient cache utilization (with a tolerable performance degra-
dation) only for the smaller portion of the execution workload
that is security-sensitive and isolated. We also require that
our architecture is portable, can be easily deployed, and is
backward compatible when a system does not support it. We
summarize these requirements below:
R1 Strong side-channel resilience guarantees between the
isolated and non-isolated execution domains, sufﬁcient to
USENIX Association
29th USENIX Security Symposium    455
thwart typical contention-based and access-based cache
attacks
R2 Dynamic and scalable cache isolation between multiple
different isolation domains
R3 Addressing the cache performance/security trade-off by
conﬁguring the non-isolated/isolated workload balance
(compliant with how TEEs are intended and designed to
be used) such that the performance of the non-isolated
execution workload is not degraded
R4 Usability: backward-compatible, architecture-agnostic,
no usage restrictions and no code modiﬁcations required
Next, we present the high-level construction of HYBCACHE
in Section 4.2 and its microarchitecture in more detail in
Sections 4.3 and 4.4.
4.2 High-Level Idea
In HYBCACHE, a subset of the cache, named subcache, is re-
served to form an orthogonal isolated cache structure. Specif-
ically, nisolated cache ways within the conventional cache sets
form the subcache. While these subcache ways are available
for the NI-Domain to utilize, the I-Domains are restricted to
utilize only these subcache ways. However, the I-Domains
utilize this subcache in a fully-associative way and using
a random-replacement policy. In doing so, all mutually dis-
trusting processes executing in the I-Domains can share the
subcache without leaking information on the actual mem-
ory locations they access. Since these subcache ways are
not reserved exclusively for isolated execution and can also
be utilized by non-isolated execution with least priority, the
NI-Domain still retains unaltered cache capacity usage and
non-degraded performance.
The key purpose of HYBCACHE, unlike existing defenses,
is to selectively enable side-channel-resilient cache utilization
only for the I-Domains. Hence, only the isolated execution is
subjected to the resulting performance overhead, while still
maintaining conventional cache behavior and performance for
the NI-Domain, as outlined in Requirement R3. We describe
next the architecture of HYBCACHE and how it achieves this.
4.3 Controller Algorithm
HYBCACHE modiﬁes how memory lines are mapped to cache
entries for the I-Domains. nisolated ways (at least a way in each
set) of the conventional set-associative cache are designated
to the orthogonal subcache. Cache lines are mapped fully-
associatively to the subcache entries and evicted and replaced
in the subcache using a random replacement policy. This
means that a given memory line can be cached in any of the
nisolated entries. This breaks the deterministic link between
memory addresses and their corresponding cache locations,
thus defeating an attacker that attempts to infer the victim’s
memory accesses by triggering and observing contention in a
particular cache set.
Figure 1 illustrates how the HYBCACHE controller man-
ages cache requests. HYBCACHE supports multi-core proces-
sors with simultaneous multithreading (SMT) and assumes
that each process is assigned an IsolationDomainID (IDID)
that identiﬁes whether the process is in an I-Domain (and
which isolation domain) or in the NI-Domain. Any incoming
cache request is accompanied by the IDID of the issuing pro-
cess. In A , HYBCACHE controller queries the IDID of the
cache request and the request is serviced accordingly. If it is
in the NI-Domain, the complete cache is queried convention-
ally using the set index and tag bits of the requested address
to locate the cache set and line respectively ( B & C ). If a
match is found, the controller checks whether the cache line
was found in one of the subcache ways in D . Recall that
these ways are not reserved exclusively for isolated execution,
i.e., they can be used by non-isolated execution but with least
priority in case a cache set becomes over-utilized. Therefore,
if a matching cache line is found in one of these ways, the
controller checks whether it was cached by an isolated or non-
isolated process ( E ). The requesting process can only hit and
access the cache line if that line was placed by a process in
the NI-Domain. Otherwise, it is not allowed to hit on it.
Checks in the controller are implemented to occur in par-
allel, i.e., all cache hits are generated in the same number of
clock cycles (as well as cache misses), to eliminate respective
timing side channels. In case of a cache miss, the memory
block is fetched from main memory and cached in F . The
eviction and replacement are performed according to the de-
ployed policy. All ways are available for eviction, including
the subcache ways to provide the NI-Domain execution with
unaltered cache capacity. However, the usage of the subcache
ways by the I-Domains is considered while recording the re-