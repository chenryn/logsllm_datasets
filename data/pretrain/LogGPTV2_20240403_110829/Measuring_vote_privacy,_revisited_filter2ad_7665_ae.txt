### 6.2 Relation with δ-Privacy

In this section, we establish a relationship between the privacy notion introduced by Küsters, Truderung, and Vogt [23] at IEEE S&P 2011 and the privacy measure introduced in this paper.

#### Definition of δ-Privacy
A protocol achieves δ-privacy if, for any two votes \(i\) and \(j\), there exists a negligible function \(\nu\) such that:
\[
\text{Adv}_{\text{dist}}^{A,i,j}(k) = P[A\pi(D_i) = 1] - P[A\pi(D_j) = 1] \leq \delta + \nu(k).
\]
A protocol is exactly δ-private if it achieves δ-privacy and does not achieve \(\delta'\)-privacy for any \(\delta' < \delta\). We denote the exact level of privacy achieved by protocol \(\pi\) when the honest votes are selected according to distribution \(D\) as \(\delta(\pi, D)\). By a slight abuse of notation, we write \(\delta(\pi, D_{ij})\) for the maximum level of privacy achieved if \(i\) and \(j\) are fixed and only the adversary is allowed to vary.

#### Relation Between Entropy-Based Privacy and δ-Privacy

First, we link δ-privacy with the ability of any adversary to correctly guess the vote of the first voter, if this vote is either \(i\) or \(j\). Specifically, let the distribution \(D_{ij}\) be such that the vote of the first voter is selected uniformly at random from the set \(\{i, j\}\), and the votes of the remaining honest voters are selected according to \(D\).

Consider a modified version of the experiment that defines δ-privacy. In this modified version, the votes of the honest voters are distributed according to \(D_{ij}\), and the goal of the adversary is to output a guess \(g \in \{i, j\}\) as to what the vote of the first voter is. We refer to such an adversary as a guessing adversary. The adversary wins if it guesses correctly, i.e., we define its guessing advantage as:
\[
\text{Adv}_{\text{guess}}^{A,i,j} = P[A\pi(D_{ij}) = v_1],
\]
where \(v_1 \in \{i, j\}\) is the vote cast by the first voter in the execution. The following lemma establishes a well-known relation between winning a "distinguishing game" and guessing the value to be distinguished.

**Lemma 8.** Let \(i, j\) be fixed. For any admissible (distinguishing) adversary \(D\), there exists an admissible (guessing) adversary \(G_D\) such that:
\[
\text{Adv}_{\text{guess}}^{G_D,i,j}(k) \geq \frac{1}{2} \cdot \text{Adv}_{\text{dist}}^{D,i,j}(k) + \frac{1}{2}.
\]
Conversely, for any admissible (guessing) adversary \(G\), there exists an admissible (distinguishing) adversary \(D_G\) such that:
\[
\text{Adv}_{\text{dist}}^{D_G,i,j}(k) \geq 2 \cdot \text{Adv}_{\text{guess}}^{G,i,j}(k) - 1.
\]

One implication of the above lemma is that for protocols which achieve δ-privacy only for large \(\delta\), there are adversaries that are successful in guessing the vote of the first party. This relation between δ-privacy and guessing abilities suggests a link between δ-privacy and a privacy measure that captures the ability of the adversary to guess a target vote.

We make this intuition formal by instantiating our privacy measure in a particular way. We set the distribution on the votes to be \(D_{ij}\) (the vote of the first voter is \(i\) or \(j\) with probability a half), we set the target function to \(T_1\), the function that returns the vote of the first voter, and set the underlying entropy measure to be \(\tilde{H}_\infty\), the average conditional min-entropy (that measures precisely the ability of the adversary to guess the target). We thus relate δ-privacy with \(\tilde{M}_\infty(D_{ij}, T_1, \pi)\), where \(i, j\) are the votes of the first voter that yield the largest possible \(\delta\).

The relation between guessing probability and average min-entropy is the following. Consider \(T\) and \(L\) two (possibly correlated) random variables. Then for any adversary \(A\), the probability that \(A\) guesses \(T\) given that it sees \(L\) is \(P[A(L(T)) = T]\), which is the same as:
\[
\sum_{l} P[L = l] \cdot P[A(L(T)) = T | L = l] = 2^{-\tilde{H}_\infty(T|L)}.
\]

We use this connection to relate δ-privacy with \(\tilde{M}_\infty(D, T, \pi)\) for the case of bounded adversaries, and with \(\tilde{M}_{I\infty}(D, T, \pi)\) for unbounded ones. For unbounded adversaries, the connection is made precise by the following theorem, which says that δ-privacy in the sense of [23] is equivalent to privacy as captured by \(\tilde{M}_{I\infty}(D_{ij}, T_1, \pi)\).

**Theorem 9.** Let \(i, j\) be arbitrary votes. For unbounded adversaries:
\[
\delta(\pi, D_{ij}) = 2^{1 - \tilde{M}_{I\infty}(D_{ij}, T_1, \pi)} - 1.
\]

For bounded adversaries, we were able to prove a connection only in one direction. Specifically, if a protocol is not δ-private (i.e., there exists \(i, j\) votes for the first voter, and a distinguishing adversary with advantage larger than \(\delta\)), then our computational privacy measure \(\tilde{M}_\infty(D_{ij}, T_1, \pi)\) is also upper-bounded appropriately.

**Theorem 10.** Let \(\pi\) be an arbitrary protocol, \(T_1\) the target function that returns the vote of the first voter, and \(D\) a distribution on the honest votes. Then for any \(i, j\):
\[
\delta(\pi, D_{ij}) \leq 2^{1 - \tilde{M}_\infty(D_{ij}, T_1, \pi)} - 1.
\]

The following corollary (obtained by setting \(i\) and \(j\) appropriately) makes the relation between δ-privacy and \(\tilde{M}_\infty\) precise.

**Corollary 11.** Let \(\pi\) be an arbitrary protocol that is not δ-private. Then there exist \(i\) and \(j\) such that:
\[
\tilde{M}_\infty(D_{ij}, T, \pi) \leq 1 - \log(1 + \delta).
\]

#### Discussion

The results of this section show that security in the sense captured by one instantiation of our privacy notion implies security in the sense defined by δ-privacy. Furthermore, for information-theoretically secure protocols (e.g., ideal ones) and for specific distributions, the two notions coincide. We think that the relations exhibited in this section between our entropy-based notion, the cryptographic notion of [5], and δ-privacy [23] support all three notions and their respective approaches to privacy. Our privacy measure allows us to make statements about privacy in cryptographic voting protocols that would be much harder to establish using the game-based model of [5] directly. Our measure also applies to a more general class of protocols, vote distributions, and targets than those that have been studied previously using δ-privacy.

### 7. Conclusion

Entropy is a natural choice to measure privacy in an information-theoretic setting, and we demonstrate how different formulations of conditional entropy answer different intuitive questions about vote privacy. Through an appropriate notion of computational conditional entropy, we have extended the reach of this idea to the computational setting and have established a theorem that enables accurate analysis of privacy offered by complex cryptographic voting protocols while simply disregarding the details of their implementation. Furthermore, the underlying entropy-based approach makes our measure applicable to non-cryptographic protocols, and we have shown through the Takoma Park example how to obtain meaningful results for a real election. We completed the investigation of our notion by establishing powerful connections with two existing privacy notions for votes [23, 5].

As our definition does not concentrate on any specific election rule or on any specific target function, in future work, we plan to explore if and how it can be applied to related problems, e.g., sealed-bid auctions [25, 20] or more generally any secure function evaluation problem.

### Acknowledgments

The research leading to these results has received funding from the European Research Council under the European Union’s Seventh Framework Programme (FP7/2007-2013) / ERC grant agreement no 258865, project ProSecure, under the ICT-2007-216676 European Network of Excellence in Cryptology II, under the HOME/2010/ISEC/AG/INT-011 project B-CCENTRE, and under the SCOOP Action de Recherche Concertées. Olivier Pereira is a Research Associate of the F.R.S.-FNRS.

### References

[References listed here as in the original text.]

This optimized version aims to improve clarity, coherence, and professionalism, making the content more accessible and easier to follow.