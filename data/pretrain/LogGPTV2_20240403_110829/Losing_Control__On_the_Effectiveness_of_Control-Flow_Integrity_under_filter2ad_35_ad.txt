. . .
; Load d e s t i n a t i o n f u n c t i o n a d d r e s s
l e a ecx , v t a b l e+i n d e x
; PATCH: Reload ebx with c u r r e n t e i p ,
i n s t e a d o f
u n t r u s t e d ,
. n e x t 2
;
c a l l
. n e x t 2 :
c o r r u p t i b l e v a l u e
pop ebx
add ebx , GLOBAL OFFSET TABLE
; Load jump t a b l e e n t r y r e l a t i v e t o ebx
mov eax ,
c a l l ecx
[ ebx + jump table @GOT ]
Listing 4: Example IFCC assembly after ﬁx
Figure 3 shows that our patched version of IFCC performs
between 0.12% and 1.19% slower (0.46% on average) than
unpatched IFCC. Tice et al. [50] also found cases where
IFCC outperforms the baseline, and we did not analyze these
cases further. The patch for the 64-bit version is similar and
was omitted for brevity.
We reported the weaknesses in IFCC and VTV and our
mitigation for IFCC to the original developers of these mit-
igations.
6.2 Securing Stack
It is highly challenging to secure the machine stack against
all types of attacks, since it must be readable and writable by
the program. Similar to other exploit mitigation schemes,
stack protection schemes can be categorized into schemes
that rely on applying randomization to the stack or ensur-
ing the integrity of the stack through isolation. We found
that current stack randomization schemes introduce a lower
performance overhead but remain vulnerable to our attack
as the randomization secret can be disclosed, as we will dis-
cuss in the next section. On the other hand, isolating the
stack can potentially mitigate our attacks. However, current
Figure 3: SPEC CPU2006 performance of IFCC-
protected programs before and after we applied our
ﬁx relative to an unprotected baseline.
stack mitigation techniques are either not eﬀective or suﬀer
from non-negligible performance overheads.
Next, we shortly discuss the eﬀectiveness of these mitiga-
tion schemes under our threat model.
6.2.1 Randomization-based Defenses
StackGuard [13] attempts to prevent stack-based buﬀer
overﬂows by inserting a random stack cookie between po-
tentially vulnerable buﬀers and the return address. How-
ever, this defense is insuﬃcient against current attackers.
An attacker with the capability to read the stack, as we
have demonstrated with our attacks, can read and forge this
cookie, even without an arbitrary memory write vulnerabil-
ity.
The recently proposed StackArmor [11] further protects
the stack not only against buﬀer overﬂows, but also stack
buﬀer over/under reads and stack-based temporal vulnera-
bilities. However, StackArmor’s protections are conﬁned to
the stack itself. Without any heap protection, an attacker
can use heap-memory corruption to read and write arbi-
trary memory locations and can disclose metadata used by
the StackArmor allocator to ﬁnd and modify the stack.
6.2.2
One possible mitigation strategy against our attacks is to
Isolation-based Defenses
isolate the stack from the regular data memory.
Lockdown [39] is a DBI-based (dynamic binary instrumen-
tation) CFI implementation with a shadow stack. DBI re-
writes the binary code of the application at run time, hence,
it can control application memory accesses. This allows it
to prevent access and leakage of the shadow stack address.
However, these security guarantees come with an average
run time overhead of 19% which is considered impractical.
Recently LLVM integrated a component of CPI, called
SafeStack [32, 48].
It aims to isolate critical stack data,
like return addresses or spilled registers from buﬀers that
potentially can be overﬂown. During a static analysis phase
-­‐2%	
  0%	
  2%	
  4%	
  6%	
  8%	
  10%	
  12%	
  14%	
  16%	
  astar	
  dealII	
  namd	
  omnetpp	
  perlbench	
  povray	
  soplex	
  xalancbmk	
  Mean	
  IFCC	
  IFCC+Fix	
  959the compiler identiﬁes buﬀers that are located on the stack
and relocates them to a separate stack, called the unsafe
stack. The regular stack is then assumed to be the safe
stack. The separation of buﬀers and critical values is likely
to prevent most stack-based memory vulnerabilities from
being exploitable. However, if we can leak the stack pointer
register (see Section 5.2), i.e., the pointer to the safe stack,
we can overwrite the protected values.
Full CPI [32] provides more comprehensive protection of
code pointers by isolating them from other memory objects.
On 32-bit x86 the isolation is enforced through segmenta-
tion. In principle this can prevent our attacks, however, on
64-bit x86 or other architectures, e.g., ARM, this feature is
not available. The authors suggest alternative implemen-
tations to the segmentation-based isolation. All come with
their own pros and cons: While the randomization approach
provides good performance, it was shown to be prone to in-
formation leakage attacks [20]. A more secure implementa-
tion is based on software fault isolation (SFI) [52], however,
this adds an additional 7% [42] to the 8% average run-time
overhead induced by CPI itself [32]. In general the overhead
depends on the number of objects that must be protected,
e.g., the authors report of CPI an overhead of 138% for a web
server that serves dynamic webpages, which is impractical.
6.3 Securing CFI Implementations
Zeng et al. [56] compiled a list of requirements to imple-
ment a secure inline-reference monitor, in which they also
mention the danger of stack-spilled variables. However, the
threat of stack-spilled registers was not considered in two
major compiler implementations. Our work proves that reg-
ister spills are a severe threat to CFI, which should be ad-
dress by future implementations.
Ultimately, while stack-oriented defenses help to mitigate
stack vulnerabilities, they do not oﬀer suﬃcient protection
to complex software such as web browsers, where dynamic
code generation, heap vulnerabilities and attacker-controlled
scripting provide many alternative attack vectors to the ad-
versary. Defenders must combine these types of defenses
with other protection against heap-based memory corrup-
tion to be secure.
7. RELATED WORK
Memory disclosure poses a crucial threat to application se-
curity. Previous research on memory disclosure focused on
leaking information about the code layout to bypass code
randomization whereas we focus on data structures to iden-
tify memory locations that contain values that are critical
for the enforcement of CFI.
Many exploit mitigations introduce randomness into the
in-memory representation of applications. Such mitigations
rely on the assumption that the adversary cannot read the
memory. However, in the presence of memory disclosure
vulnerabilities, assuming memory secrecy is neither justiﬁed
nor realistic. We ﬁrst discuss related oﬀensive work on va-
riety of memory disclosure vulnerabilities and bypasses of
ﬁne-grained CFI, and then devote our attention to defensive
works that aim at resisting memory leakage.
7.1 Memory Disclosure Attacks
Bhatkar et al. [7] note that contemporary schemes (ASLR,
StackGuard, PointGuard) are vulnerable if an adversary can
read arbitrary values in memory. Strackx et al. [47] later
demonstrated that memory disclosure through buﬀer over-
read errors allows attackers to bypass ASLR and stack ca-
naries. Roglia et al. [22] then used return-oriented program-
ming to disclose the randomized location of libc.
Observing that ASLR was highly vulnerable to memory
disclosure, researchers argued that ﬁne-grained code ran-
domization solutions would provide suﬃcient resilience [19,
24, 27, 28, 33, 37, 53].
Snow et al. [45] introduced a novel type of memory dis-
closure attacks called just-in-time return-oriented program-
ming (JIT-ROP) that is able to bypass not only ASLR but
ﬁne-grained code randomization as well. JIT-ROP exploits
the design of memory paging in modern systems: it (i) iden-
tiﬁes the page start and end of a leaked function pointer,
(ii) disassembles the code page, and (iii) identiﬁes code ref-
erences on the disassembled page to repeat this process on
other memory pages. Since JIT-ROP attacks must disas-
semble and analyze the disclosed code, it must be launched
against scripting-capable victim applications such as web
browsers or document viewers.
Bittau et al. [8] developed another memory disclosure at-
tack against services that automatically restart after crashes.
This attack exploits the fact that some servers (created us-
ing fork without execve) do not re-randomize after a crash.
By sending such servers a malformed series of requests and
by analyzing whether the requests cause the server to crash,
hang, or respond, the adversary can guess the locations of
the gadgets required to launch a simple ROP attack that
sends the program binary to the remote adversary. Like
JIT-ROP, this attack undermines ﬁne-grained code random-
ization.
Siebert et al. [43] presented a memory disclosure attack
against servers that uses a timing side-channel. By sending a
malformed request to a web server, the adversary can control
a byte pointer that controls the iteration count of a loop.
This creates a correlation between the target of the pointer
and the response time of the request that the adversary can
use to (slowly) scan and disclose the memory layout of the
victim process. In a similar vein, Hund et al. [29] exploit
a timing side-channel to infer the memory of the privileged
ASLR-randomized kernel address space.
Lastly, Evans et al. [20] were able to use memory disclo-
sure to bypass an implementation of the code pointer in-
tegrity (CPI) defense by Kuznetsov et al. [32]. CPI works
by storing control ﬂow and bounds information in a “safe
region” which is separate from non-sensitive data. This pre-
vents control-ﬂow hijacking and spatial memory corruption.
Whereas the 32-bit x86 implementation uses memory seg-
mentation to isolate the safe region, the fastest 64-bit x86
implementation uses information hiding. However, it turns
out that the hidden safe region was suﬃciently large to be
located and parsed using a modiﬁed version of the memory
disclosure attack by Siebert et al. [43]. Kuznetsov et al. also
provide a 64-bit CPI implementation where the safe region
is protected by SFI which has not been bypassed.
7.2 Attacks against ﬁne-grained CFI
Carlini et al [9] provide evidence that static ﬁne-grained
CFI provides insuﬃcient protection, and that a shadow stack
is required to provide precise enforcement of the CFG. Fur-
thermore, they demonstrate that CFI cannot defend against
non-control-data attacks, where the control ﬂow stays within
the boundaries of the enforced CFG but the attacker mod-
960iﬁes variables or function arguments such that the targeted
application behaves maliciously.
CFI is only as eﬀective as the CFG that is derived for the
application.
In Control Jujutsu Evans et al. [21], explore
the limits of the state-of-the-art algorithm [34] that is used
to derive forward edges in the CFG. They found that the
derived CFG contains imprecisions that can be exploited
and allow arbitrary code execution.
7.3 Preventing Memory Disclosure
Backes and N¨urnberger [6] proposed Oxymoron, the ﬁrst
defense that aims at preventing JIT-ROP. Oxymoron pre-
vents the step of the JIT-ROP attack in which it identiﬁes
references to other code pages. Oxymoron does so by mak-
ing all references between code pages opaque using legacy
x86 segmentation features. Davi et al. [17] show that Oxy-
moron can be bypassed in practice since JIT-ROP can be
modiﬁed not to rely on following references between code
pages by harvesting code pointers from C++ virtual tables
instead.
Backes et al. [5] proposed an alternative defense against
JIT-ROP called eXecute-no-Read (XnR). The goal of XnR
is to improve upon DEP under which execute permissions
imply read permissions. To emulate execute permissions
without read permissions, XnR marks all but a small num-
ber of code pages as “not present”. A modiﬁed page fault
handler marks pages as executable (and readable) and si-
multaneously marks the last recently used executable page
as “not present”. As our experiments in Section 8 indicate,
XnR in combination with function permutation does not
provide protection against code-pointer leakage.
The HideM approach by Gionta et al. [23] implements
execute-only memory via “TLB-desynchonization”. This ap-
proach, which relies on pre-2008 hardware, directs read ac-
cesses to a diﬀerent memory page than instruction fetches
by the CPU. This avoids the small window of executable
and readable pages. Nevertheless, HideM does not protect
against code pointer leaks.
The Readactor approach by Crane et al. [14] implements
execute-only memory using the second level address trans-
lation feature in modern processors with support for hard-
ware accelerated virtualization. Redactor introduces code-
pointer hiding, a technique which decouples all code point-
ers in attacker observable memory from the code layout.
For instance, a return pointer does not point into a func-
tion, instead it points to a “return trampoline” which jumps
to the original return address. Because the return tram-
poline is mapped with execute-only permissions, the adver-
sary cannot read the original return address.
In general,
Readactor resists our attacks as it is resilient to code-pointer
leakage. On the other hand, the trampoline addresses are
still allocated on the stack and subject to StackDeﬁler. The
adversary can collect trampoline addresses to identify call-
preceded gadgets. However, it is not yet shown that the col-
lected call-preceded gadgets are suﬃcient to mount a gadget-
stitching attack [10, 18, 25, 26, 41].
8. DISCUSSION
Memory disclosure was previously used to attack code-
randomization schemes [45]. Although attacking code ran-
domization is not the main focus of this paper, it suggests
itself to use stack disclosure against code randomization. In
particular, we investigated the impact of stack disclosure
against mitigation schemes that aim to prevent direct mem-
ory disclosure by marking the code segment as execute-only:
XnR [5] and HideM [23]. We performed some preliminary
experiments in which we used our capabilities to read the
stack of a parallel thread to disclose a large number of return
addresses. Considering that we can control which functions
are executed in the parallel thread, we were able to leak the
addresses of speciﬁc gadgets. The results of our experiments
are that indirect code disclosure via return addresses can be
used to bypass ﬁne-grained code-randomization. In particu-
lar, we can bypass function permutation [31] or basic-block
permutation [53] even when XnR or HideM are in place to
protect against memory disclosure. Readactor by Crane et
al. [14] performs code-pointer hiding and is not vulnerable to
return address leakage. Further, the authors extended their
work to protect function tables [15] which prevents vTable
hijacking as described in Section 5.1.2.
9. CONCLUSION