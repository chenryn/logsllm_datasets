lowing, we present an example that illustrates users’ privacy
risk and we determine certain privacy leakage scenarios.
2.1 Privacy Leakage Example
To provide a visual illustration of the extent of the risk
presented to users due to the existing access control mecha-
nism, we present an example. We recreate a segment of the
actual social graph collected in our user study (Section 3),
and extend it by crawling publicly available data from Face-
book. Speciﬁcally, we select four out of the 128 users that
participated in our study that are connected (e.g., friends),
and we re-create their social graph. We also use publicly
available data regarding the users that were two hops away
from them within the Facebook graph (i.e., friends of friends).
This results in a social graph that contains 55,109 users.
Note that, since certain users and friendships might not be
publicly viewable and, thus, not collected by our crawler,
these numbers are conservative estimates (i.e., lower bounds).
We consider an example case where a photo depicting the
four users is uploaded, and calculate the privacy risk for one
of those users (i.e., Bob) depending on who the uploader is.
We quantify the risk as the number of people (i.e., nodes in
the graph) that are not connected to Bob, but can access it in
spite of Bob’s settings. Recall that the uploader controls the
photo’s general visibility setting and also controls which of
the tagged users’ friends can view the photo. For simplicity
we apply the default setting for each tagged users.
Figure 1a presents the ideal case, where Bob is tagged in a
photo and only his 339 friends have access. In Figures 1c to
1e we illustrate which users can access the photo in diﬀerent
cases, and if they have been granted access by the user of
interest (Bob), or by others.
In these cases, the uploader
allows users two hops away within the social graph to ac-
cess the photo, i.e., the visibility setting is set to “friends of
friends”. For the remaining tagged users the setting is set
to “friends only”. As can be seen, depending on the position
of the uploader in the social graph, the combined eﬀect of
(i) the coarse granularity of access control and (ii) multiple
users appearing in the photo, the extent of privacy leakage
covers up to 86.78% of the social graph (47,829 users).
This example highlights the extent of the problem, as the
current mechanism allows users to access a photo that a user
might want to restrict, even if the uploader does not set the
privacy setting to “public”. While these numbers will vary
depending on the structure of each user’s social graph, they
are indicative of the risk-propagation eﬀect.
Here we present certain scenarios that highlight the pri-
vacy implications that arise in everyday situations, due to
the current access control mechanisms for managing the vis-
ibility of photos published in OSNs.
Scenario 1: The Malicious Tagger. Alice and Bob,
who are coworkers, attend a party. During the event, Al-
ice takes multiple photos, some of which depict Bob in an
inebriated state. Despite that fact, Alice uploads the whole
collection of photos and, subsequently, Bob is tagged in the
embarrassing photos. In fear of other colleagues and super-
visors seeing the photos, potentially creating negative im-
plications, Bob sends Alice a request to remove the photos.
Alice, however, does not remove them, and even though Bob
un-tags himself, the photos are still viewable by colleagues.
Scenario 2: The Silent Uploader. The settings are
similar to the previous scenario. Worse, in this case, Bob is
never tagged in the photos and, thus, remains oblivious to
the existence of the embarrassing photos. As such, even if
Alice was willing to remove them upon request, the photos
will be viewable by others until Bob becomes aware of their
existence. A recent study [25] explored the extent to which
users are aware of photos being shared by others that depict
them or contain their tag. Results showed that users are not
really aware of the extent of such content, and that there is
a signiﬁcant gap between users’ expectations and reality.
Scenario 3: The Group Photographer. This is a very
common case of privacy leakage due to conﬂicting interests.
Alice uploads a group picture with Bob being one of the de-
picted friends. Although Bob is very wary of his privacy and
has a strict privacy setting, with his photos being viewable
only by his friends, Alice sets the photo to be viewable by all.
Despite Bob having actively tried to ensure his privacy, the
settings of another user overrules his settings, which results
in a loss of privacy. This case is also reported by Yamada
et al. [46]. A user study by Liu et al. [32] found that 18% of
the users allow users two hops away (i.e., friends of friends)
to view their photos, while 26% allow everyone.
Scenario 4: The Accidental Over-sharer. This is
also a common case of privacy leakage, where users acciden-
tally, or due to insuﬃcient understanding of their privacy
setting, end up sharing photos with a much larger audience
than they intended. In [32], it is reported that 63% of the
photos have privacy settings diﬀerent from what intended,
and almost always more open. Alarmingly, the privacy set-
ting for 51% of those photos was set to public, allowing
anyone to view them. Thus, overall, about one out of every
three photos will be publicly viewable by accident. If Alice
is the uploader, Bob’s face may be accidentally viewable by
anyone. This scenario can be attributed to the complexity
of current mechanisms, and the uploader being responsible
for setting the visibility options for the photo. We propose a
simpliﬁed scheme where each user is responsible for its own
face, and a user’s privacy setting is enforced automatically.
Scenario 5: The Friendly Stranger. This case fur-
ther exempliﬁes the ineﬀectiveness of current access control
models. Consider that Alice uploads a photo of herself and
Bob, and that both of them are cautious with their privacy
settings and have opted for a strict setting where photos are
only viewable by their friends. This oﬀers a false sense of
privacy because, while their interests seem to coincide, that
is far from true. Unless Alice and Bob’s social graphs per-
fectly overlap (i.e., identical sets of friends), both users will
(a) Image is uploaded and user of interest
is tagged: his 339 friends have access.
(b) Legend
(c) The image is uploaded by the 2nd user.
2,871 red nodes (5.2%) have access.
(d) The image is uploaded by the 3rd user.
7,465 red nodes (13.54%) have access.
(e) The image is uploaded by the 4th user.
47,829 red nodes (86.78%) have access.
Figure 1: Risk for a “privacy-conscious” user tagged in a photo. In each case, a diﬀerent user is considered the uploader (among
the depicted users), allowing “friends of friends” to view the photo, while the remaining tagged users are set to “friends only”.
be viewable by strangers; e.g., any of Alice’s friends that
Bob does not know will still be able to see him.
3. RISK ANALYSIS: USER STUDY
In this section we present the ﬁndings of our user study
that explores the extent of conﬂicting user interests due to
photos shared in social networks. As our focus is on the pri-
vacy risks they present to users, we study the characteristics
of their social graph and their tagging behaviour.
IRB Approval. Before inviting users to participate in
our user study, we issued an IRB protocol request to the re-
view board of our institution, where we described our study
and the type of data we would be gathering. After our re-
quest was approved, we invited users to participate.
Data and demographics. 128 users participated in our
study by installing a Facebook application that collects in-
formation regarding the users, their social graph and their
photos along with any tag information. The participants
are from 14 diﬀerent countries, with 71% of them belonging
to the 20-29 age group and 17.9% to the 30-39 age group.
Furthermore, not all the users disclose information regard-
ing their gender, with 55% identifying as male and 16.4% as
female. In summary, we analyse data for 4,064,445 photos
that contain 4,621,064 tags.
The participants have an average of 344 friends, with a
recent survey [11] reporting a similar value of 338. Moreover,
about 7% of them have less than 100 friends, while 3% can be
considered as hub users with more than 1,000 connections.
In Figure 2 we plot the cumulative distribution of the
photos that are accessible from each user’s proﬁle, i.e., the
photos uploaded by each user (or containing a tag of the
user) and all the photos belonging to that user’s friends (or
containing their tags). We will refer to a user and all his/her
immediate friends as a clique. We found that, on average,
each clique has a collection of 31,753 photos belonging to a
user and his friends, and 20% of the cliques have more than
44,700 photos. We also discovered that certain cliques of
friends are proliﬁc uploaders, with 4% having collections of
over 100,000 photos. Based on the numbers stated in [32],
we can infer that average users and their friends will acciden-
tally allow almost 15,000 photos to be viewable by anyone,
while for proliﬁc uploaders that number will exceed 33,000.
In Figure 3 we plot the cumulative distribution of the total
number of tags within the photo collection of each clique,
and the number of tagged friends (i.e., unique userIDs). In
the average case, a clique’s photo collection contains 36,102
tags and has 250 tagged users. Furthermore, we ﬁnd that
20% of the cliques have over 340 diﬀerent tagged users in
their photos, and have over 50,000 photos in their collection.
In three cases, the clique has over 1,000 tagged UIDs. These
numbers signify the risk of the aforementioned scenarios that
arises from the current access control mechanism; within a
clique of users, the ownership and visibility of thousands of
photos (some being potentially embarrassing) is handled by
multiple users that may have conﬂicting interests.
As described in the silent uploader scenario, users may
never be tagged in the “embarrassing” photos and, therefore,
never be alerted of their existence. To gain an estimation of
this risk we conduct an experiment where we ﬁrst manually
inspect 2,000 randomly selected photos. Figure 4 shows the
Tags | Faces
1
2
3
4
5
6+
Photos (# of Faces)
Photos (# of Tags)
15.2% (304)
87.6% (1753)
32.5% (651)
9.9% (199)
17.9% (359)
1.6% (33)
10.7% (214)
0.3% (7)
8.3% (166)
0.25% (5)
15 .3% (306)
0.15% (3 )
Table 1: Percentage (and number) of photos in our 2,000 photo dataset that contain a given number of tags or faces.
Figure 2: Cumulative distribution
of uploaded photos depicting (or be-
longing to) users and their friends.
Figure 3: Cumulative distribution of
total number of tags within a clique’s
photo collection, and the number of
unique tagged UIDs.
Figure 4: Cumulative distribution
of number of tags per photo,
for
the complete dataset, and the set of
2,000 randomly chosen photos.
number of tags from the photos of our entire dataset, and of
the 2,000 randomly chosen photos. As we can see, the ran-
domly selected photos form a representative sample of our
dataset, in terms of the number of tagged users per photo.
Subsequently, we inspect these 2,000 photos and count the
depicted faces that are discernible, both in the foreground
and the background. We only take into consideration faces
that could be identiﬁed by their friends, and overlook any
non-identiﬁable faces (e.g., being too blurry, obstacles etc.).
Table 1 presents the number of photos that contain identi-
ﬁable faces. The photos depict a total of 7,244 faces (3.62
faces per photo) out of which 2,331 have been tagged (1.16
per photo). Only 15.2% of the photos depict one user, and
about half of them depict two or three users. But, the vast
majority (87.6%) contain only one tag. Thus, on average, ev-
ery photo depicts at least two users that have not been tagged
and could be at risk due to the silent uploader scenario.
According to the user study by Liu et al. [32], one out of
four users has a public privacy setting for his photos. Thus,
there is a high probability that photos depicting at least
four people, will result in conﬂicting interests, as described
in the group photographer scenario.
In our dataset of
2,000 manually inspected photos, we found that 34.3% of
them depicted at least four identiﬁable people.
To further explore how users are tagged, in Figure 5 we
plot the number of tags for each userID in our collection.
We have tags from 35,809 userIDs, and 30% of the users
are being depicted in 72.4% of the tags. The majority of
tags depict a small set of users that are tagged extensively,
with the top 10% of users having an average of 594.9 tags
and, when combined, amounting to 39.5% of the total tags.
We do not have the information to conclude if this is due to
these users not being concerned about privacy, or wrongfully
“relaxed” privacy settings. The data, however, does suggest
that certain users are more cautious about their privacy, as
those from the least-tagged 10% have 3.41 tags on average.
Next, we focus on the risk that arises for users even when
the uploader has strict privacy settings (i.e., photos are only
visible to uploader’s friends). In this experiment, we con-
sider our participants as the “adversaries” of the friendly
Figure 5: The number of tags contained in our dataset re-
garding every test subject and their friends, which follows a
power law distribution. We sort users based on the number
of times they have been tagged, and also depict the number