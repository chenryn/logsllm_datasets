they are part of the same scam. Finally, even for con-
tent downloaded from the same URL over time, we need
to determine whether the content fundamentally changes
(e.g., the server has stopped hosting the scam but returns
valid HTTP responses to requests, or it has transitioned
to hosting a different scam altogether).
Various kinds of aliasing make determining scam
equivalence across multiple hosts, as well as over time, a
challenging problem. One possibility is to compare spam
messages within a window of time to identify emails
advertising the same scam. However, the randomness
and churn that spammers introduce to defeat spam ﬁl-
ters makes it extremely difﬁcult to use textual informa-
tion in the spam message to identify spam messages for
the same scam (e.g., spam ﬁlters continue to struggle
with spam message equivalence). Another possibility is
to compare the URLs themselves. Unfortunately, scam-
mers have many incentives not to use the same URL
across spams, and as a result each spam message for
a scam might use a distinct URL for accessing a scam
server. For instance, scammers may embed unique track-
ing identiﬁers in the query part of URLs, use URLs that
contain domain names to different virtual servers, or sim-
ply randomize URLs to defeat URL blacklisting.
A third option is to compare the HTML content down-
loaded from the URLs in the spam for equivalence. The
problem of comparing Web pages is a fundamental oper-
ation for any effort that identiﬁes similar content across
sites, and comparing textual Web content has been stud-
ied extensively already. For instance, text shingling tech-
niques were developed to efﬁciently measure the simi-
larity of Web pages, and to scale page comparison to the
entire Web [4, 29]. In principle, a similar method could
be used to compare the HTML text between scam sites,
but in practice the downloaded HTML frequently pro-
vides insufﬁcient textual information to reliably identify
a scam. Indeed, many scams contained little textual con-
tent at all, and instead used images entirely to display
content on the Web page. Also, many scams used frames,
iframes, and JavaScript to display content, making it dif-
ﬁcult to capture the full page context using a text-based
Web crawler.
Finally, a fourth option is to render screenshots of
the content downloaded from scam sites, and to com-
pare the screenshots for equivalence. Screenshots are
an attractive basis for comparison because they sidestep
the aforementioned problems with comparing HTML
source. However, comparing screenshots is not without
USENIX Association
16th USENIX Security Symposium
139
its own difﬁculties. Even for the same scam accessed by
the same URL over time — much less across different
scam servers — scam sites may intentionally introduce
random perturbations of the page to prevent simple im-
age comparison, display rotating advertisements in vari-
ous parts of a page, or rotate images of featured products
across accesses. Figure 2 presents an example of screen-
shots from different sites for the same scam that show
variation between images due to product rotation.
Considering the options, we selected screenshots as
the basis for determining spam equivalence. To over-
come the problems described earlier, we developed
an image-clustering algorithm, called image shingling,
based on the notion of shingling from the text similar-
ity literature. Text shingling decomposes a document
into many segments, usually consisting of a small num-
ber of characters. Various techniques have been devel-
oped to increase the efﬁciency and reduce the space com-
plexity of this process [11]. Next, these hashed “shin-
gles” are sorted so that hashes for documents containing
similar shingles are close together. The ordering allows
all the documents that share an identical shingle to be
found quickly. Finally, documents are clustered accord-
ing to the percentage of shared shingles between them.
The power of the algorithm is that it essentially performs
O(N 2) comparisons in O(N lg N ) time.
Our image shingling algorithm applies a similar pro-
cess to the image domain. The algorithm ﬁrst divides
each image into ﬁxed size chunks in memory; in our ex-
periments, we found that an image chunk size of 40x40
pixels was an effective tradeoff between granularity and
shingling performance. We then hash each chunk to cre-
ate an image shingle, and store the shingle on a global list
together with a link to the image (we use the MD4 hash
to create shingles due to its relative speed compared with
other hashing algorithms). After sorting the list of shin-
gles, we create a hash table, indexed by shingle, to track
the number of times two images shared a similar shingle.
Scanning through the table, we create clusters of images
by ﬁnding image pairs that share at least a threshold of
similar images.
To determine an appropriate threshold value, we took
one day’s worth of screenshots and ran the image shin-
gling algorithm for all values of thresholds in increments
of 1%. Figure 4 shows the number of clusters created
per threshold value. The plateau in the ﬁgure starting
at 70% corresponds to a fair balance between being too
strict, which would reduce the possibility of clustering
nearly similar pages, and being too lenient, which would
cluster distinct scams together. Manually inspecting the
clusters generated at this threshold plateau and the cluster
membership changes that occur at neighboring threshold
values, we found that a threshold of 70% minimized false
negatives and false positives for determining scam page
250
200
150
100
50
s
r
e
t
s
u
C
l
f
o
r
e
b
m
u
N
0
0
10
20
40
30
70
Comparison Threshold (%)
50
60
80
90
100
Figure 4: The choice of a threshold value for image shin-
gling determines the number of clusters.
equivalence.
We have developed a highly optimized version of this
basic algorithm that, in practice, completes an all-pairs
comparison in roughly linear time.
In practice, image
shingling is highly effective at clustering similar scam
pages, while neatly side-stepping the adversarial obfus-
cations in spam messages, URLs, and page contents.
Clearly, a determined scammer could introduce steps to
reduce the effectiveness of image shingling as described
(e.g., by slightly changing the colors of the background
or embedded images on each access, changing the com-
pression ratio of embedded images, etc.). However, we
have not witnessed this behavior in our trace. If scam-
mers do take such steps, this methodology will likely
need to be reﬁned.
4.3 Spam feed and limitations
The source of spam determines the scams we can mea-
sure using this methodology. For this study, we have
been able to take advantage of a substantial spam feed:
all messages sent to any email address at a well-known
four-letter top-level domain. This domain receives over
150,000 spam messages every day. We can assume that
any email sent to addresses in this domain is spam be-
cause no active users use addresses on the mail server
for the domain. Examining the “From” and “To” ad-
dresses of spam from this feed, we found that spam-
mers generated “To” email addresses using a variety of
methods, including harvested addresses found in text on
Web pages, universal typical addresses at sites, as well
as name-based dictionary address lists. Over 93% of
“From” addresses were used only once, suggesting the
use of random source addresses to defeat address-based
spam blacklists.
140
16th USENIX Security Symposium
USENIX Association
Characteristic
Trace period
Spam messages
Spam w/ URLs
Unique URLs
Unique IP addresses
Unique scams
Summary Result
11/28/06 – 12/11/06
1,087,711
319,700 (30% of all spam)
36,390 (11% of all URLs)
7,029 (19% of unique URLs)
2,334 (6% of unique URLs)
Table 1: Summary of spamscatter trace.
We analyze Internet scam hosting infrastructure using
spam from only a single, albeit highly active, spam feed.
As with other techniques that use a single network view-
point to study global Internet behavior, undoubtedly this
single viewpoint introduces bias [2,8]. For example, the
domain that provides our spam feed has no actual users
who read the email. Any email address harvesting pro-
cess that evaluates the quality of email addresses, such
as correlating spam email targets with accesses on scam
sites, would be able to determine that sending spam to
these addresses yields no returns (that is, until we began
probing).
While measuring the true bias of our data is impos-
sible, we can anecdotally gauge the coverage of scams
from our spam feed by comparing them with scams iden-
tiﬁed from an entirely different spam source. As a com-
parison source, we used the spam posted to the Usenet
group news.admin.net-abuse.sightings, a forum for ad-
ministrators to contribute spam [22]. Over a single 3-day
period, January 26–28th, 2007, we collected spam from
both sources. We captured 6,977 spam emails from the
newsgroup and 113,216 spam emails from our feed. The
newsgroup relies on user contributions and is moderated,
and hence is a reliable source of spam. However, it is
also a much smaller source of spam than our feed.
Next we used image shingling to distill the spam from
both sources into distinct scams, 205 from the newsgroup
and 1,687 from our feed. Comparing the scams, we
found 25 that were in both sets, i.e., 12% of the news-
group scams were captured in our feed as well. Of the
30 most-prominent scams identiﬁed from both feeds (in
terms of the number of virtual hosts and IP addresses),
ten come from the newsgroup feed. These same ten, fur-
thermore, were also in our feed. Our goal was not to
achieve global coverage of all Internet scams, and, as ex-
pected, we have not. The key question is how representa-
tive our sample is; without knowing the full set of scams
(a very challenging measurement task), we cannot gauge
the representativeness of the scams we ﬁnd. Character-
izing a large sample, however, still provides substantial
insight into the infrastructure used to host scams. And
it is further encouraging that many of the most exten-
sive scams in the newsgroup feed are also found in ours.
Moving forward, we plan to incorporate other sources of
Scam category
Uncategorized
Information Technology
Dynamic Content
Business and Economy
Shopping
Financial Data and Services
Illegal or Questionable
Adult
Message Boards and Clubs
Web Hosting
% of scams
29.57%
16.67%
11.52%
6.23%
4.30%
3.61%
2.15%
1.80%
1.80%
1.63%
Table 2: Top ten scam categories.
spam to expand our feed and further improve representa-
tiveness.
5 Analysis
We analyze Internet scam infrastructure using scams
identiﬁed from a large one-week trace of spam mes-
sages. We start by summarizing the characteristics of
our trace and the scams we identify. We then evaluate
to what extent scams use multiple hosts as distributed
infrastructure; using multiple hosts can help scams be
more resilient to defenses. Next we examine how hosts
are shared across scams as an indication of infrastructure
reuse. We then characterize the lifetime and availability
of scams. Scammers have an incentive to use host infras-
tructure that provides longer lifetimes and higher avail-
ability; at the same time, network and system administra-
tors may actively ﬁlter or take down scams, particularly
malicious ones. Lastly, we examine the network and geo-
graphic locations of scams; again, scammers can beneﬁt
from using stable hosts that provide high availability and
good network connectivity.
Furthermore, since spam relay hosts are an integral as-
pect of Internet scams, where appropriate in our analyses
we compare and contrast characteristics of spam relays
and scam hosts.
5.1 Summary results
We collected the spam from our feed for a one-week pe-
riod from November 28, 2006 to December 4, 2006. For
every URL extracted from spam messages, we probed
the host speciﬁed by the URL for a full week (inde-
pendent of whether the host responded or not) starting
from the moment we received the spam. As a result, the
prober monitored some hosts for a week beyond the re-
ceipt of the last spam email, up until December 11. Ta-
ble 1 summarizes the resulting spamscatter trace. Start-
ing with over 1 million spam messages, we extracted
USENIX Association
16th USENIX Security Symposium
141
t
n
e
c
r
e
P
100
99
98
97
96
95
94
93
92
91
90
IPs per scam
Virtual domains per scam
0
20
40
60
Count
80
100
Figure 5: Number of IP address and virtual domains per
scam.
36,390 unique URLs. Using image shingling, we iden-
tiﬁed 2,334 scams hosted on 7,029 machines. Spam is
very redundant in advertising scams: on average, 100
spam messages with embedded URLs lead to only seven
unique scams.
What kinds of scams do we observe in our trace? We
use a commercial Web content ﬁltering product to de-
termine the prevalence of different kinds of scams. For
every URL in our trace, we use the Web content ﬁlter to
categorize the page downloaded from the URL. We then
assign that category to the scams referenced by the URL.
Table 2 shows the ten most-prevalent scam categories.
Note that we were not able to categorize all of the scams.
We did not obtain access to the Web content ﬁlter until a
few weeks after taking our traces, and 30% of the scams
had URLs that timed out in DNS by that time (“Uncate-
gorized” in the table). Further, 12% of the scams did not
categorize due to the presence of dynamic content. The
remaining 58% of scams fell into over 60 categories. Of
these the most prevalent scam category was “Information
Technology”, which, when examining the screenshots of
the scam sites, include click afﬁliates, survey and free
merchandise offers and some merchandise for sale (e.g.,
hair loss, software). Just over 2% of the scams were la-
beled as malicious sites (e.g., containing malware).
5.2 Distributed infrastructure
We start by evaluating to what extent scams use multi-
ple hosts as distributed infrastructure. Scams might use
multiple hosts for fault-tolerance, for resilience in antici-
pation of administrative takedown or blacklisting, for ge-
ographic distribution, or even for load balancing. Also,
reports of large-scale botnets are increasingly common,
and botnets could provide a large-scale infrastructure for
hosting scams; do we see evidence of botnets being used
as a scalable platform for scam hosting?
Scam category
Watches
Pharmacy
Watches
Pharmacy
Software
Male Enhancement
Phishing
Viagra
Watches
Software
# of domains
3029
695
110
106
99
94
91
90
81
80
# of IPs
3
4
3
1
3