### Behavioral Distance for Intrusion Detection

#### 4.2 Behavioral Distance Between System Call Sequences

In our experimental setup, we utilize three different HTTP server programs: Apache [11], Myserver [1], and Abyss [32]. These servers were chosen because they are compatible with both Linux and Windows operating systems. A collection of HTML files ranging from 0 to 5 MB in size is served by these HTTP servers. Training and testing data are generated by simulating a client that randomly selects a file to download. The client sends 1,000 requests, with 800 used for training and the remaining 200 for testing.

We conducted two sets of tests:

1. **Same Server Implementation on Replicas:**
   - In the first set of tests, the same server implementation (Apache, Myserver, or Abyss) was run on both replicas, L and W.
   - Training data was used to learn the distances between system call phrases, which were then used to calculate the behavioral distance between system call sequences in the testing data.
   - The results of the behavioral distance calculations on the testing data are presented in Figure 3 as cumulative distribution functions (CDFs). The x-axis represents the behavioral distance, and the y-axis shows the percentage of requests with a behavioral distance smaller than the corresponding value on the x-axis.
   - Figure 3 clearly demonstrates that legitimate requests result in system call sequences with small behavioral distances.

2. **Different Servers on Replicas:**
   - In the second set of tests, different servers were run on L and W. Specifically, Figure 4(a) shows the results when L runs Myserver and W runs Apache, and Figure 4(b) shows the results when L runs Apache and W runs Myserver.
   - Although the behavioral distances calculated in this set of tests are not as small as those in the first set, the results are still encouraging.
   - This set of tests indicates that our system can be effective even when replicas are running different servers, making it a viable alternative to output voting for server implementations that do not always provide identical responses to the same request.

#### 4.3 Resilience Against Mimicry Attacks

Section 4.2 demonstrated that legitimate requests to the replicas result in system call sequences with small behavioral distances. In this section, we show that attack traffic will result in system call sequences with large behavioral distances. Our focus is on more sophisticated attacks, specifically mimicry attacks [36, 31].

- **Mimicry Attack Analysis:**
  - A mimicry attack involves injecting code into the address space of a running process, causing it to execute the injected code. The injected code is designed to embed "attack" system calls within a longer sequence that appears consistent with the program's normal behavior.
  - We analyzed a general mimicry attack where the attacker attempts to make a `system call open` followed by a `system call write` when the vulnerable server processes a carefully crafted HTTP request with embedded attack code.
  - We assume the attacker can launch such an attack on only one of the replicas using a single request, either due to a vulnerability existing only on one replica or because the attacker can inject code on only one replica.

- **Tests and Results:**
  - We performed two tests with different assumptions:
    - **Test 1:** The attacker tries to evade detection by an existing anomaly detection technique running on one of the replicas, assuming the attacker does not know about the behavioral distance calculation.
    - **Test 2:** The attacker knows about the behavioral distance calculation and has a copy of the distance table used in the calculation.
  - The results of both tests are shown in Table 1, which presents the behavioral distance of the best mimicry attack and the percentage of testing data with a smaller behavioral distance.
  - The percentages in Table 1 indicate the true acceptance rate of our system when the detection threshold is set to detect the best mimicry attack. The high percentages (close to 100%) suggest a low false alarm rate, even when detecting sophisticated mimicry attacks.

#### 4.4 Performance Overhead

Sections 4.2 and 4.3 have shown that our method for calculating behavioral distance is more resilient against mimicry attacks and has a low false positive rate. In this section, we evaluate the performance overhead of our implementation by measuring the throughput of the HTTP servers and the average latency of the requests.

- **Performance Evaluation:**
  - We conducted two experiments to assess the performance overhead:
    1. **Single Server Performance Degradation:**
       - We evaluated the performance degradation of a single server due to the overhead of extracting and sending system call information to another machine for behavioral distance calculation.
    2 - **Comparison with Output Voting:**
       - We compared our performance overhead with a fault-tolerant system that compares the responses from replicas before returning the response to the client ("output voting").
  - The performance evaluation shows that the performance overhead is moderate. Additionally, our current implementation is unoptimized, so the performance overhead can be further reduced with optimization.

- **Experimental Setup:**
  - The experiments were run on a single server running Windows with a 2.0 GHz Pentium IV processor and 512 MB of RAM.