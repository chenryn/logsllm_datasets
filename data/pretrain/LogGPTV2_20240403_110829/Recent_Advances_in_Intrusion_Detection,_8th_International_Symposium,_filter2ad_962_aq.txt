Behavioral Distance for Intrusion Detection
75
P accepts client http requests and forwards them to both L and W. Af-
ter processing the requests, L and W send out responses and the system call
sequences made by the server programs. P calculates the behavioral distance be-
tween the two system call sequences, raising an alarm if the behavioral distance
exceeds a threshold, and forwards the response to the client if responses from L
and W are the same.
4.2 Behavioral Distance Between System Call Sequences
We run our experiments on three diﬀerent http server programs: Apache [11],
Myserver [1] and Abyss [32]. We choose these servers mainly because they work
on both Linux and Windows. A collection of html ﬁles of size from 0 to 5 MB are
served by these http servers. Training and testing data is obtained by simulating
a client that randomly chooses a ﬁle to download. The client sends 1000 requests,
out of which 800 are used as training data and the remaining 200 are used as
testing data.
We run two sets of tests. In the ﬁrst set of tests we run the same server
implementation on the replicas, i.e., both L and W run Apache, Myserver or
Abyss. Training data is used to learn the distances between system call phrases,
which are then used to calculate the behavioral distance between system call
sequences in the testing data. Results of the behavioral distance calculations on
the testing data are shown in Figure 3 in the form of cumulative distribution
functions (x-axis shows the behavioral distance, and y-axis shows the percentage
of requests with behavioral distance smaller than the corresponding value on
x-axis.). Figure 3 clearly shows that legitimate requests result in system call
sequences with small behavioral distance.
In the second set of tests, we run diﬀerent servers on L and W. Figure 4(a)
shows the results when L is running Myserver and W is running Apache, and
Figure 4(b) shows results when L is running Apache and W is running Myserver.
Although the behavioral distances calculated are not as small as those obtained
in the ﬁrst set of tests, the results are still very encouraging. This set of tests
shows that our system cannot only be used when replicas are running the same
servers on diﬀerent operating systems, but also be used when replicas are running
diﬀerent servers. Our approach is thus an alternative to output voting for server
100
80
60
40
20
s
t
s
e
u
q
e
r
f
o
e
g
a
t
n
e
c
r
e
P
0
0
5
10
Behavioral distance
(a) Apache
100
80
60
40
20
s
t
s
e
u
q
e
r
f
o
e
g
a
t
n
e
c
r
e
P
0
0
5
10
Behavioral distance
(b) Myserver
100
80
60
40
20
s
t
s
e
u
q
e
r
f
o
e
g
a
t
n
e
c
r
e
P
0
0
1
4
3
2
5
Behavioral distance
(c) Abyss
6
7
Fig. 3. CDF of behavioral distances when replicas are running the same server
76
D. Gao, M.K. Reiter, and D. Song
100
80
60
40
20
s
t
s
e
u
q
e
r
f
o
e
g
a
t
n
e
c
r
e
P
0
0
100
80
60
40
20
s
t
s
e
u
q
e
r
f
o
e
g
a
t
n
e
c
r
e
P
0
0
5
Behavioral distance
10
10
5
Behavioral distance
15
(a) Myserver (L) and Apache (W)
(b) Apache (L) and Myserver (W)
Fig. 4. CDF of behavioral distances when replicas are running diﬀerent servers
implementations that do not always provide identical responses to the same
request (c.f., [4]).
4.3 Resilience Against Mimicry Attacks
Section 4.2 shows that legitimate requests to the replicas result in system call
sequences with small behavioral distances. In this section, we show that at-
tack traﬃc will result in system call sequences of large behavioral distances.
However, our emphasis is not on simple attacks which can be detected by intru-
sion/anomaly detection systems on individual replicas. (We did try two known
attacks on an Abyss webserver, and results show that they are detected by iso-
lated anomaly detection systems [37] on any one of the replicas.) Instead, we
focus on more sophisticated attacks, namely mimicry attacks [36, 31].
An attack that injects code into the address space of a running process, and
then causes the process to jump to the injected code, results in a sequence of
system calls issued by the injected code. In a mimicry attack, the injected code is
crafted so that the “attack” system calls are embedded within a longer sequence
that is consistent with the program that should be running in the process. As
shown in [36, 13], mimicry attacks are typically able to evade detection by host-
based intrusion/anomaly detection systems that monitor system call sequences.
We analyze a very general mimicry attack, in which the attacker tries to make
system call open followed by system call write, when the vulnerable server is
processing a carefully crafted http request with attack code embedded. This
simple attack sequence is extremely common in many attacks, e.g., the addition
of a backdoor root account into the password ﬁle. We assume that the attacker
can launch such an attack on only one of the replicas using a single request; i.e.,
either the vulnerability exists only on one of the replicas, or if both replicas are
vulnerable, an attacker can inject code that makes system calls of his choice on
only one of the replicas. To our knowledge, there is no existing code-injection
attacks that violate this assumption, when the replicas are running Linux and
Microsoft Windows; nor do we know how to construct one except in very spe-
cialized cases.
We perform two tests with diﬀerent assumptions. The ﬁrst test assumes that
the attacker is trying to evade detection by an existing anomaly detection tech-
Behavioral Distance for Intrusion Detection
77
Table 1. Behavioral distance of mimicry attacks
Apache
Apache
Server on L
Server on W
Abyss Myserver Myserver Apache
Abyss Myserver Apache Myserver
Mimicry on L (test 1) 10.283194 9.821795 26.656983 6.908590 32.764897
100 % 99.4555 % 100 %
5.492936 9.967780 13.354194 5.280875
Mimicry on W (test 1) 6.842813
99.4555 % 99.9093 % 99.4555 % 100 % 99.4555 %
3.736
99.9093 % 100 %
Mimicry on L (test 2)
1.828
13.813
98.9111 % 99.8185 % 100 % 98.9111 % 100 %
2.64
13.657
2.731
2.687
2.174
2.187
Mimicry on W (test 2)
2.65
98.7296 % 99.8185 % 98.0944 % 98.9111 % 97.8221 %
nique running on one of the replicas. In particular, the anomaly detection tech-
nique we consider here is one that uses variable-length system call phrases in
modeling normal behavior of the running program [37]. In other words, the ﬁrst
test assumes that the attacker does not know that we are utilizing a behavioral
distance calculation between replicas (or indeed that there are multiple replicas).
In the second test, we assume that the attacker not only understands that our
behavioral distance calculation between replicas is being used, but also has a
copy of the distance table that is used in the behavioral distance calculation.
This means that an attacker in the second test is the most powerful attacker,
who knows everything about our system. In both tests, we exhaustively search
for the best mimicry attack. In the ﬁrst test, the “best” mimicry attack is that
which makes the minimal number of system calls while remaining undetected.
In the second test, the “best” mimicry attack is that which results in the small-
est behavioral distance between system call sequences from the two replicas.
We assume that the mimicry attack in both cases results in a request to the
uncorrupted replica that produces a “page not found” response.
Results of both tests are shown in Table 1. For each individual test, Table 1
shows the behavioral distance of the best mimicry attack, and the percentage of
testing data (from Section 4.2) that has a smaller behavioral distance. That is,
the percentage shown in Table 1 indicates the true acceptance rate of our system
when the detection threshold is set to detect the best mimicry attack. As shown,
these percentages are all very close to 100%, which means that the false alarm
rate of our technique is relatively low, even when the system is conﬁgured to
detect the most sophisticated mimicry attacks. Moreover, by comparing results
from the two sets of tests, we can also see the trade-oﬀ between better detection
capability and lower false positive rate. For example, by setting the threshold
to detect any mimicry attacks that could have evaded detection by an isolated
intrusion/anomaly detection system on one of the replicas (results in test 1), our
system will have a much lower false positive rate (between 0% and 0.5%).
4.4 Performance Overhead
Section 4.2 and Section 4.3 show that our method for behavioral distance is
more resilient against mimicry attacks than previous approaches and has low
78
D. Gao, M.K. Reiter, and D. Song
false positive rate. In this section, we evaluate the performance overhead of our
implementation of the behavioral distance calculation by measuring the through-
put of the http servers and the average latency of the requests. The performance
evaluation shows that the performance overhead is moderate. Also note that our
current implementation is unoptimized, so the performance overhead will be
even lower with an optimized implementation.
We run two experiments to evaluate our performance overhead. First, we
evaluate the performance degradation of a single server due to the overhead of
having to extract and send the system call information to another machine to
compute the behavioral distance. Second, we show our performance overhead in
comparison to a fault-tolerant system that compares the responses from replicas
before returning the response to the client (“output voting”).
Performance Overhead of Extracting and Sending System Call Infor-
mation. In this experiment, we run two diﬀerent tests on one single server
running Windows operating system (with a 2.0 GHz Pentium IV processor and