access.
VI. VALIDATION
We experimentally validate our approach along two axes:
ﬁrst, the scalability and coverage of the GROK data inven-
tory, and second,
the usability and expressiveness of the
LEGALEASE language.
A. Scale
Fig. 9 shows the number of new nodes added to the GROK
each day over a 100 day period for our operational system.
On average, we process over 77 thousand jobs each day,
submitted by over 7 thousand entities in over 300 functional
units. We process daily, on average, 1.1 million unique lines
of code (including generated code), 21% of which changes (on
average) on a day-to-day basis, covering 46 million dynamic
table schemas. These jobs process tables persisted to 32
million ﬁles. Building the ﬁne-grained column-level GROK
data dependency graph takes, on average, 20 minutes daily
on our production cluster. Performing data ﬂow analysis over
graph nodes added (in millions)
 60
 55
 50
 45
 40
 35
 30
 25
 20
 15
08/10
08/24
09/07
09/21
10/05
10/19
11/02
Fig. 9. Number of GROK data ﬂow graph nodes added each day
 100
 80
 60
 40
 20
l
d
e
e
b
a
l
t
u
p
t
u
o
%
 0
 0
Veriﬁcation
Dataﬂow
Baseline
 20
 40
 60
 80
 100
% input labeled
Fig. 10. Coverage of labeling by successive phases of GROK bootstrapping.
all data use on the cluster in a four week period takes 10
minutes.
Note that
this last number, 10 minutes,
is the time it
takes the system to take an unlabeled data dependency graph
over the past several weeks, label it with attributes based
on syntactic analysis and past veriﬁcation, perform data ﬂow
analysis, and evaluate the conﬁgured policy over historical
data. This quick turnaround allows us to perform rapid what-
if analysis for proposed policy changes; a capability that is
unattainable with manual reviews and audits that operate at
the time-scale of months.
B. Coverage
We seek to understand the overall coverage of accurate
DataType labels in GROK. The overall coverage depends on
the coverage of the bootstrap syntactic analysis, improvements
we get from data ﬂow analysis, and boost in coverage and
conﬁdence values we get from manual veriﬁcation. Fig. 10
plots how data ﬂow analysis, and targeted manual veriﬁcation
improve the GROK coverage relative to the baseline.
We establish a baseline by simulating a syntactic analysis
with varying degrees of coverage on our real-world data
dependency graph. Speciﬁcally, we ﬁrst pick x% of all unique
column names uniformly at random, and ﬂag them in our
simulation as correctly labeled. We note ﬁrst that a linear
baseline is not a trivial result since the overall graph nodes
labeled correctly is a function of the popularity of column
338
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
(a) A snapshot from the pre-survey training
(b) Coding and Policy experience levels
(c) Overview of Survey Performance
Fig. 11. Summary of the Usability Survey
names. There is no knee or shoulder that would imply a sweet-
spot for the coverage vs. effort trade-off in syntactic analysis.
Improvements in coverage of accurate labels in syntactic
analysis translate linearly to overall improvement.
The overall coverage is improved using data ﬂow analysis.
This improvement is because correctly labeling a node in a
connected component allows the entire connected component
to be labeled. The dataﬂow line in Fig. 10 shows overall
coverage as a function of connected components, ordered by
size, that are labeled correctly using syntactic analysis and
then the label ﬂowed using data ﬂow analysis. We ﬁnd that
by focusing on only 10% of the top connected components,
we can boost overall coverage to 50%. However, we observe
that labeling more connected components leads to diminishing
returns.
The biggest improvement to overall coverage comes from
limited manual veriﬁcation. As mentioned, we analyze jobs to
identify columns in sub-expressions in shared code modules
that, if veriﬁed, allow us to ﬂow the labels most broadly. The
veriﬁcation line in Fig. 10 shows that manual veriﬁcation of
only 0.2% of code modules (maintained by 12 teams) and
adding code annotations to 182 lines of source code (out
of several millions), combined with data ﬂow and syntactic
analysis,
increases overall coverage of accurate DataType
labels to 60%.
C. Usability
To develop a preliminary understanding of the ability for
non-technical subject matter experts in privacy to understand
and use the LEGALEASE language, we conducted an online
survey targeting privacy champions in Microsoft. In the survey,
we described the LEGALEASE language and asked participants
to encode clauses of a privacy policy that we found online.
Survey design: We provided a 1-page deﬁnition of
LEGALEASE terms, example clauses, and lattice elements
(Fig. 11a); this single page of text and tables was our sole
training tool2. After reading through the training informa-
tion, participants were presented with 9 policy clauses to
encode. The clauses increased in complexity as they pro-
gressed through the survey. For each question, participants
were provided with a set of lattice elements to choose from
2Particpants had the ability to open the page of training information in a
new window while completing the encoding tasks.
(so that participants would not be required to memorize the
lattice presented on the training page), and a text box to type
in the LEGALEASE policy clause.
Participants: Participants (n = 12) were recruited via a
company mailing list and were not provided with compensa-
tion. They were primarily privacy champions who had been
in their position from 2 weeks to over 6 years. As shown
in Fig. 11b, in general, based on their ratings of how much
coding experience they had ranging from “No experience
at all” (1) to “Expert” (5),
they were not experienced in
coding (mean 2.25)3. As privacy champions, they did have
more experience reading privacy policies (mean 3.83)4, and
were neither experienced nor inexperiened in writing privacy
policies (mean 3.17)5 on the same scale. After the coding
tasks, participants were neutral about the difﬁculty of the task
(mean 3.17)6 on the scale of "Very Difﬁcult” (1) to "Very
Easy” (5).
Results: After reading the training information (the average
time spent on the tutorial page was 2.4 minutes), the majority
of participants were able to code each policy clause with the
correct answer (see Fig. 11c for a question by question break-
down of correctness, ranging from “Incorrect” (1) to “Correct”
(5).) The overall correctness rating for all participants was 4.65
(standard deviation 0.48). The time spent on encoding clauses
was 14.3 minutes on average. Overall, our sample of privacy
champions was able to use LEGALEASE to code policy clauses
at a high level of correctness with very little training in a short
amount of time.
D. Expressiveness
To demonstrate the expressiveness of LEGALEASE, We
now present a complete encoding of externally-visible privacy
policies7 of Google and Bing that applies to data storage and
use. We also demonstrate the LEGALEASE goal of usability
through 1-1 correspondence with the English policy clauses
by presenting a side-by-side view (Tables V and VI).
Note that the policies in Table V were part of the survey
above. The LEGALEASE clauses for them are the actual (ma-
3M=2.25, t(11)=3, p=0.01, as compared to the midpoint in a one-sample t-test
4M=3.83, t(11)=2.59, p=0.03, as compared to the midpoint in a one-sample t-test
5M=3.17, t(11)=0.39, p=0.7, as compared to the midpoint in a one-sample t-test
6M=3.17, t(11)=0.56, p=0.59, as compared to the midpoint in a one-sample t-test
7As of 14th October 2013
339
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:21 UTC from IEEE Xplore.  Restrictions apply. 
 0 1 2 3 4 5CodingExperienceReadingPoliciesWritingPoliciesAmount of Experience  0 1 2 3 4 5Q1Q2Q3Q4Q5Q6Q7Q8Q9Level of CorrectnessQuestionALLOW
EXCEPT
DENY DataType IPaddress:Expired
DENY DataType UniqueIdentiﬁer:Expired
DENY DataType SearchQuery, PII InStore Store
DENY DataType UniqueIdentiﬁer, PII InStore Store
DENY DataType BBEPData UseForPurpose Advertising
DENY DataType BBEPData, PII InStore Store
DENY DataType BBEPData:Expired
DENY DataType UserProﬁle, PII InStore Store
DENY DataType PII UseForPurpose Advertising
DENY DataType PII InStore AdStore
DENY DataType SearchQuery UseForPurpose Sharing
EXCEPT
ALLOW DataType SearchQuery:Scrubbed
⊳ “we remove the entirety of the IP address after 6 months”
⊳ “[we remove] cookies and other cross session identiﬁers, after 18 months”
⊳ “We store search terms (and the cookie IDs associated with search terms)
separately from any account information that directly identiﬁes the user, such
as name, e-mail address, or phone numbers.”
⊳ “we do not use any of the information collected through the Bing Bar
Experience Improvement Program to identify, contact or target advertising to
you”
⊳ “we take steps to store [information collected through the Bing Bar
Experience Improvement Program] separately from any account information
we may have that directly identiﬁes you, such as name, e-mail address, or
phone numbers”
⊳ “we delete the information collected through the Bing Bar Experience
Program at eighteen months.”
⊳ “we store page views, clicks and search terms used for ad targeting separately
from contact information you may have provided or other data that directly
identiﬁes you (such as your name, e-mail address, etc.).”
⊳ “our advertising systems do not contain or use any information that can
personally and directly identify you (such as your name, email address and
phone number).”
⊳ “Before we [share some search query data], we remove all unique identiﬁers
such as IP addresses and cookie IDs from the data.”
ALLOW
EXCEPT
AN ENCODING OF PRIVACY PROMISES BY BING AS OF OCTOBER 2013
TABLE V
DENY DataType PII UseForPurpose Sharing
EXCEPT
ALLOW DataType PII:OptIn
EXCEPT
ALLOW AccessByRole Afﬁliates
EXCEPT
ALLOW UseForPurpose Legal
DENY DataType DoubleClickData, PII
EXCEPT
ALLOW DataType DoubleClickData, PII:Optin
⊳ “We do not share personal information with companies, organiza-
tions and individuals outside of Google unless one of the following
circumstances apply:”
⊳ “We require opt-in consent for the sharing of any sensitive
personal information.”
⊳ “We provide personal information to our afﬁliates or other trusted
businesses or persons to process it for us”
⊳ “We will share personal information [if necessary to] meet any
applicable law, regulation, legal process or enforceable governmen-
tal request.”
⊳ “We will not combine DoubleClick cookie information with
personally identiﬁable information unless we have your opt-in
consent”
AN ENCODING OF PRIVACY PROMISES BY GOOGLE AS OF OCTOBER 2013
TABLE VI
jority) response provided by the surveyed privacy champions,
who are the intended target users of LEGALEASE.
VII. DISCUSSION
In this section we discuss some non-goals of LEGALEASE
and GROK, some limitations and mitigating factors.
Expressiveness: LEGALEASE does not support expressing
policies based on ﬁrst-order temporal-logic. It supports a
restricted form of temporal policies, implemented with help
from the GROK. LEGALEASE is intended as a bridge between
developers and policy makers in Web service companies like
Bing and its expressiveness is restricted to policy elements
encountered in practice that apply to the big data system. In
particular, policies such as those related to cookie management
and the use of secure communication channels are beyond the
scope of our analysis.
Inference of Sensitive Data: Sensitive data can often be
inferred from non-sensitive data [21], [22]. Unless explicitly
labeled, GROK cannot detect such inferences. A careful choice
of the DataType lattice may help reduce some of these risks
by classifying together data that can be reasonably inferred
from each other.
Precision: The information ﬂow analysis in GROK is con-
servative, but not necessarily precise. A major source of im-
precision is our overly conservative treatment of user deﬁned
functions. In the future, we hope to leverage static code
analysis of C# user deﬁned functions in the ﬂavor of [23],
[24] to make GROK more precise.
False Negatives: The semantics of LEGALEASE are precise
and the information ﬂow analysis in GROK is conservative.
Therefore, bootstrapping that leads to more coverage of the
graph with labels, would generally imply a reduction in
false positives. However, due to the lack of ground truth for
labels, we are unable to characterize the exact nature of false