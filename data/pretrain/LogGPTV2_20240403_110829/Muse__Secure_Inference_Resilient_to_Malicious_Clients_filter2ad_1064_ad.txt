i ∈ [(cid:96)], the client obtains {Mi(ri) − si}i∈[(cid:96)] along with
{(cid:104)βi · ri(cid:105)1,(cid:104)αi(Mi(ri)− si(cid:105))1} whereas the server receives
{(cid:104)βi · ri(cid:105)2,(cid:104)αi(Mi(ri)− si(cid:105))2}. In Fig. 11 we describe the
ideal functionality in more detail, and give a protocol for
achieving it in Fig. 5.
3. For each i ∈ [(cid:96)], let inpi := (Mi(ri)− si,ri+1) denote the
client’s input to the i-th non-linear layer and |inpi| denote
its size in bits. The server chooses a set of random garbled
circuit input labels {labC
4. Conditional disclosure of secrets: For each i ∈ [(cid:96)], the
client and the server invoke functionality FCDS on the
client’s input inpi and the MAC shares received from FACG.
If the client honestly inputs the correct shares, the function-
ality outputs the garbled input labels {labC
i,k,inpi}k∈[|inpi|]
corresponding to inpi to the client. In Fig. 12, we describe
the ideal functionality in more detail, and give a protocol
for securely computing this functionality in Fig. 6.
i,k,1}k∈[|inpi|].
i,k,0, labC
Figure 3: MUSE preprocessing phase.
Figure 4: MUSE online phase.
DELPHI, we additionally need to prevent tampering by ma-
licious clients. To this end, we extend the linear correlations
generator (CG) used in DELPHI (see Fig. 2) to additionally
support authentication. We formalize this via functionality
FACG for generating authenticated correlations. See Fig. 11
for a formal description.
To construct a protocol ΠACG that realizes FACG, we ex-
tend the techniques based on the leveled fully-homomorphic
encryption used in DELPHI to additionally authenticate and
secret share the relevant ciphertexts (see Fig. 5). We also re-
quire the client to provide zero-knowledge proofs that assert
that their input ciphertexts are well-formed.
Non-linear layers. Like in DELPHI, we use garbled circuits
to efﬁciently evaluate ReLUs. However, unlike DELPHI, we
can no longer use oblivious transfer to send garbled labels to
the client, because we have no way to check that the input to
the oblivious transfer corresponds to the output from FACG.
Instead we introduce a functionality which conditionally out-
2208    30th USENIX Security Symposium
USENIX Association
i,k,0, labS
{labS
layer.7
5. For each i ∈ [(cid:96)], the server chooses random labels
i,k,1}k∈[|inpi|] for its input to the ith non-linear
6. Ofﬂine garbling: For each i ∈ [(cid:96)], the server gar-
(described in Fig. 7) using
to obtain the garbled circuit (cid:101)Ci. It chooses a key ki ←
i,k,1}k∈[|inpi|] as the input labels
{0,1}λ and sends H(ki)⊕(cid:101)Ci to the client where H is a
the circuit Ci
i,k,1, labS
i,k,0, labC
bles
{labC
i,k,0, labS
random oracle.
5.2 Online phase
The online phase is divided into two stages: the preamble and
the layer evaluation. (See Fig. 4 for a graphical overview.)
5.2.1 Preamble
The client sends (x− r1) to the server.
5.2.2 Layer evaluation
At the beginning of evaluating the i-th layer, the client holds
ri and the server holds xi − ri where xi is the vector obtained
by evaluating the ﬁrst (i− 1) layers of the neural network on
input x (with x1 = x). This invariant will be maintained for
each layer. We now describe the protocol for evaluating the
i-th layer, which consists of linear functions and activation
functions:
Linear layer. The server computes Mi(xi − ri) + si which
ensures that the client and server hold an additive secret share
of Mixi.
Non-linear layer. After the linear layer, the server holds
Mi(xi − ri) + si and the client holds Miri − si. The parties
evaluate the non-linear garbled circuit layer as follows:
1. The server chooses a random masking vector s(cid:48)
i+1 and
sends the labels from the set {labS
i,k,1}k∈[|inpi|] cor-
responding to its input Mi(xi − ri) + si and s(cid:48)
i+1 to the
2. The client uses ki to unmask H(ki)⊕(cid:101)Ci to obtain (cid:101)Ci. The
client along with the key ki.
client evaluates the garbled circuit (cid:101)Ci using its input labels
obtained in the preprocessing phase and labels obtained
from the server in the online phase. The client decodes the
output labels and sends xi+1 − ri+1 + s(cid:48)
i+1 along with the
hash of the output labels to the server.
recovers xi+1 − ri+1.
3. The server checks if the hash computation is correct and
Output phase. The server sends s(cid:48)
(cid:96)+1 to the client and the
client unmasks the output of the garbled circuit using this to
learn the output of the inference y.
Theorem 5.1. Assuming the security of garbled circuits and
the protocols for securely computing FACG and FCDS, the pro-
tocol described above is a private inference protocol against
malicious clients and semi-honest servers (see Deﬁnition 3.2)
in the random oracle model.
i,k,0, labS
7We slightly abuse the notation and use |inpi| to also denote the size of
the server input to the garbled circuit.
Protocol ΠACG
1. Both parties engage in a two-party computation protocol
with security against malicious clients and semi-honest
servers to generate (pk, sk) for HE. The client learns pk
and sk whereas the server only learns pk.
2. The client sends {Enc(pk,ri)}i∈[(cid:96)] to the server along with
a zero-knowledge proof of well-formedness of the cipher-
text. The server veriﬁes this proof before continuing.
3. For every i ∈ [(cid:96)],
server
(a) The
homomorphically
computes
Enc(pk,Mi(ri) − si), Enc(pk,αi(Mi(ri) − si)),
and Enc(pk,βi · ri).
(b) The server randomly samples (cid:104)αi(Mi(ri)− si)(cid:105)2 and
(cid:104)βi · ri(cid:105)2, homomorphically creates additive shares
of the MAC values, and sends (Enc(pk,Mi(ri) −
si), Enc(pk,(cid:104)αi(Mi(ri) − si)(cid:105)1), Enc(pk,(cid:104)βi · ri(cid:105)1))
to the client.
(c) The client decrypts the above ciphertexts and obtains
(Mi(ri) − si), (cid:104)αi(Mi(ri) − si)(cid:105)1, and (cid:104)βi · ri(cid:105)1. The
server holds (cid:104)αi(Mi(ri)− si)(cid:105)2 and (cid:104)βi · ri(cid:105)2.
Figure 5: Our construction of an authenticated correlations genera-
tor (ACG).
Protocol ΠCDS
input
client’s
consists
Denote the bit decomposition of inpi = (Mi(ri)− si,ri+1) as
{bi
k}k∈[|inpi|].
1. The client and server input securely compute the follow-
ing function fCDS using a secure two-party computation
protocol against malicious clients and semi-honest servers:
(a) The
of
({bi
k}k∈[|inpi|],(cid:104)αi(Mi(ri) − si)(cid:105)1,(cid:104)βi+1 · ri+1(cid:105)1) and
the server’s input consists of (αi,βi+1,(cid:104)αi(Mi(ri)−
si)(cid:105)2,(cid:104)βi+1 · ri+1(cid:105)2,{labC
i,k,0, labC
for
some i ∈ [(cid:96)− 1].
i,k,0 − labC
i,k,0 − (labC
(b) Denote gk = labC
tively secret share gk into ((cid:104)gk(cid:105)1,(cid:104)gk(cid:105)2).
(c) Reconstruct Mi(ri)− si and ri+1 from {bi
(d) Sample random vectors c1 ← Z|ri+1|
1 · Mi(ri)− si)− cT
(e) Denote ρ = αi(cT
si)(cid:105)1 +(cid:104)αi(Mi(ri)− si)(cid:105)2) and σ = βi+1(cT
2 · ((cid:104)βi+1 · ri+1(cid:105)1 +(cid:104)βi+1 · ri+1(cid:105)2).
cT
(f) Output ρ, σ, {(cid:104)gk(cid:105)2}k∈[|inpi|]
{(cid:104)gk(cid:105)1}k∈[|inpi|] to the client.
,c2 ← Z|ri+1|
1 · ((cid:104)αi(Mi(ri)−
2 · ri+1)−
i,k,1}k∈[|inpi|])
i,k,1) · bi
k. Addi-
k}k∈[|inpi|].
to the server and
2. If either of them are non-zero, the server aborts the proto-
col. Else, it sends {(cid:104)gk(cid:105)2}k∈[|inpi|] to the client. The client
reconstructs {gk}k∈[|inpi|] and outputs it.
p
p
Figure 6: Our protocol for conditional disclosure of secrets.
Server’s input: Mi(xi − ri) + si,s(cid:48)
Client’s input: ri+1, Mi(ri)− si
1. Compute Mi(xi) = Mi(xi − ri) + si + Mi(ri)− si).
2. Compute ReLU(Mi(xi)) to obtain xi+1.
3. Output xi+1 − ri+1 + s(cid:48)
i+1.
i+1.
Figure 7: Description of circuit Ci.
USENIX Association
30th USENIX Security Symposium    2209
Correctness follows from inspection; see the full version of
this paper for the security proof.
Remark 5.2 (ACG for subsequent linear layers). Many net-
work architectures contain consecutive linear layers between
two ReLU activations. For simplicity of exposition, we have
composed these linear layers in our protocol description. How-
ever, doing so in the actual implementation would be inefﬁ-
cient since our homomorphic algorithms are highly special-
ized for speciﬁc layer types. As a result, in practice ΠACG
must be modiﬁed so that on consecutive linear layers the
client only receives MAC shares of the layer output on the ﬁ-
nal linear layer in the sequence. In the online phase, the client
additionally sends MAC shares of their input on intermediate
linear layers since they are not checked inside of the CDS.
Remark 5.3 (Checking client CDS inputs).
fCDS must check
that the client’s bit decomposition is correct. That is, it must
check that the claimed bit decomposition (a) consists of
boolean values, (b) corresponds to an integer with value less
than p. For efﬁciency reasons, we perform only the ﬁrst check
in the preprocessing phase, and move the second check to our
garbled circuits in the online phase.
Remark 5.4 (Fixed-point arithmetic in ﬁnite ﬁelds). Neural
networks work over the real numbers, but our cryptographic
protocols work over ﬁnite prime ﬁelds. To emulate real arith-
metic, we rely on ﬁxed-point arithmetic. However, to maintain
precision, one needs to occasionally truncate intermediate val-
ues to ensure that the result does not wrap around the ﬁeld.
In DELPHI, both parties perform truncation directly on
their local secret shares following the technique of [Moh+17]
which correctly truncates the shared value with a small, addi-
tional error. While this error does not greatly impact accuracy,
it is unacceptable in the client-malicious setting as it would
invalidate the MAC of the share. As a result, MUSE must
perform trunction directly on the shared value using a secure
MPC. We perform this truncation for free within our garbled
circuits by always returning zero labels for the upper bits of
the ReLU output.
5.3 An efﬁcient protocol for computing fCDS
To securely compute the function fCDS, MUSE adapts
the state-of-the-art arithmetic MPC framework Overdrive
[Kel+18] (which achieves malicious security) to the simpler
client-malicious 2PC setting. Doing so results in great efﬁ-
ciency improvements, as we now explain.8
The heaviest cryptographic costs when using Overdrive for
fCDS are due to (a) MAC key generation, (b) triples generation,
and (c) authentication of secret client and server inputs. We
now describe how we optimize all of these procedures in the
client-malicious setting.
8While the protocol of [Che+20] offers better performance than Overdrive,
at the time of writing the source code for it was unavailable, and so we could
not build upon it. Our optimizations in this section apply also to the [Che+20]
protocol, so it is plausible that in the future MUSE could instead rely on it.
MAC key generation.
In Overdrive, a MAC key must be
secret-shared among the parties, since any party may be ma-
licious and could use knowledge of the key to cheat. In the
client-malicious setting, the server will never cheat so they
can simply generate and hold the MAC key themselves.
Triples generation.
In order to generate multiplication
triples in Overdrive, all parties must generate ciphertexts of
their shares, prove knowledge of these ciphertexts in zero-
knowledge, homomorphically compute a triple from the ci-
phertexts, and run a distributed decryption algorithm so all
parties receive a share of the result. Note that the distributed
decryption allows a malicious adversary to inject an authenti-
cated additive shift, so parties must “sacriﬁce” a triple in order
to ensure correctness [Dam+12], which harms performance.
In the client-malicious setting, we can avoid distributed
decryption, triple sacriﬁce, and a number of zero-knowledge
proofs by taking advantage of the fact that the server knows
the MAC key. In particular, we devise the following efﬁcient
protocol: the client sends the encryption of their shares di-
rectly to the server (along with a zero-knowledge proof of
plaintext knowledge). The server homomorphically computes
the shares of the triple, and returns it to the client. Since the
server performs the computation, correctness is guaranteed
and no distributed decryption or triple sacriﬁce is necessary.
We provide benchmarks of our optimized generation in Sec-
tion 6.5. See Fig. 17 for a full description of ΠTriple.
Input authentication. Overdrive [Kel+18] optimizes the
input sharing method of [Dam+12], by assuming that the
encryption scheme they employ achieves linear-targeted mal-
leability (LTM) [Bit+13]. The LTM assumption for an encryp-
tion scheme informally states that only afﬁne transformations
can be computed on ciphertexts. This assumption is non-
falsiﬁable, and, when applied to the encryption schemes used
in Overdrive, has received insufﬁcient scrutiny.
In our protocol, we avoid relying on this strong assumption
by observing that the majority of secret inputs originate with
the server, and because the server holds the MAC keys, it can
easily authenticate its inputs without cryptography. In more
detail, the protocol proceeds as follows.
• The server shares their inputs by producing a random au-
thenticated share of their input using the MAC key and
sends it to the client.
• The client shares their input by following the same method-
ology as [Dam+12]. Note that generating random authenti-
cated shares can be implemented using our triple generation
procedure from above, thus inheriting the same speedups.
We benchmark these techniques in Section 6.5. See Fig. 14
for a full description of ΠInputAuth.
6 Evaluation
We divide the evaluation into three sections which answer the
following questions:
• Section 6.3: What are the latency and communication costs
2210    30th USENIX Security Symposium
USENIX Association
r CG
a
e
n
i
L
ACG
Garbling
Garbling
DELPHI
MUSE
DELPHI
MUSE
DELPHI
OT
CDS Triple Gen. MUSE