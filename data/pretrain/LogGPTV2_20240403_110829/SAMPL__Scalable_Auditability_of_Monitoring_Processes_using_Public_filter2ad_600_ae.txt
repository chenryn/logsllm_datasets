setup in Protocol 1 (only establishment of PI: ref. Protocol 11). The
average ZKP generation time was 1.02 ms with a standard deviation
of 0.236 ms. This time is expended when an I signs up for a new
account with C or whenever I establishes a new PI with C. The
verification time is calculated for an E verifying the user data inside
SRR (calculated once per SRR). The verification time was found to
be 1.066 ms with standard deviation of 0.096 ms.
Figure 4a shows the verification time of SRR by E for different
number of Is in SR, and different surveillance periods, for a batch
size of 32 messages. Figure 4b shows the SRR verification time,
for a batch size of 64 messages. We observed a linear increase in
computation time with an increase in the number of users. We
note that the computation time includes the ZKP verifications, the
Merkle tree generation and root signature verification (one per
user), and doing the date range checks on the data.
Comparison of Figures 4a and 4b shows that the verification
of SRR for batch size of 64 messages is faster by roughly 0.65 s.
This difference is because for the same number of total messages,
larger batch sizes will result in less Merkle tree roots and signature
verification operations when compared to smaller batch sizes. In
our simulations, SRR verification for 10 users for a surveillance
period of 30 days involved processing 299 batches with the batch
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2259size of 32 messages, as opposed to 153 batches with 64 messages.
Similarly, number of batches processed for 30 users over 30 days
involved processing 898 batches with 32 messages and 460 batches
with 64 messages.
Figure 4c shows the computation time at C at the end of each
batch. Batch sizes of 16, 32, 64, 128, and 256 messages were simulated
for messages sizes of 1 KB, 75 KB, 1 MB, and 2 MB, averaged over 50
runs. The larger message sizes represent emails with attachments.
The computation time for the different message sizes converges
as the batch size grows. This is because once the hashes of the
messages are calculated for leaves of the Merkle tree, the rest of
the operations on Merkle trees of given batch size are the same for
messages of different sizes. For Merkle trees with larger messages
initial hash computation of the leaves of the tree has to deal with
larger data size.
To give a fine-grained analysis of components of SRR verification
at E, we give a break down of the computation time in Table 3. For
each step, it does follow that the amount of time taken is linear, as
the number of users and/or surveillance period is increased, hence
showing the scalability of our approach.
Table 2: Zero Knowledge Proof Timings
Operation
ZKP Generation
ZKP Verification
Mean
1.02 ms
1.066 ms
Standard Deviation
0.236 ms
0.096 ms
We note that the total time for operations performed on a given
SRR depicted in Table 3 are lower than the computation time de-
picted in Figures 4a. This is due to the extra operations for look ups
and other input-output operations performed by E on SRR during
the verification.
9 DISCUSSION
In this section we discuss some generalizations and possible en-
hancements of SAMPL.
9.1 Generalization
SAMPL can apply to other types of surveillance criteria by mod-
ifying the way user records are stored by C. In case of email, the
sender and receiver names and their IP addresses could be salted
and hashed separately and stored along with other details such as
date and time as the metadata. This information could be listed in
the SO and subsequently verified by E without learning the actual
values. This will enable search based on sender/receiver names
and/or IP addresses. Searchable encryption [9] can be implemented
to search based on specific keywords in the data records. Although
this increases the types of surveillance auditable, it leaks more
information to E.
SAMPL can also be extended to allow a user to delete historical
records. The user would update the data record to a generic “deleted
message,” the Merkle root for the given historical batch would be
recalculated with the new message, and the user would sign the
updated Merkle root with the current SKP I . Every time V KPI gets
updated by the user, C verifies the ZKP and also verifies the signa-
tures on the Merkle root so that I cannot inject fake data/signatures
to frame an honest C. For practicality, the management of users’
V KPIs can be handled by software like keystores, plugins, etc.
There can be instances where a single user is part of multiple
surveillance requests. In that case, each SO has V KAI, and E can
link it to the corresponding V KPI using the ZKP provided by C.
Our framework does not provide unlinkability of the independent
surveillances to a user’s V KPI. The problem of malicious enforcers
leaking information about the V KAIs is not addressed by us.
SR can also include requests for system logs showing activity
of a certain user identified by V KAI. If the logs contain V KRI, to
preserve privacy, C can replace it with V KAI. If the logs contain
V KPI, then C furnishes the ZKP associated with V KPI. Unlike data
such as emails, users do not see the logs, hence do not sign them.
9.2 Enhancements and Adaptability
There are several design choices in our system that are implementation-
specific. We list some below:
(1) Set of Enforcers: We can relax the assumption on the E from
honest to being honest but curious. To provide unlinkability of users’
PIs over multiple surveillances for a given time period, nonoverlap-
ping striping of data across the set of Es, when sending SR or SRR
could be used. Note that the sets of enforcers chosen by L and C
need not be the same. This would increase the efficiency of verifica-
tion of the system, as data for verification is not duplicated between
different Es. As long as the number of SOs for a given AI does not
exceed the number of enforcers in the system, the unlinkability
assumption will hold (due to the non-overlapping striping).
(2) Internal decision procedures of J, L, and C: Certain actions
are largely dependent on the specific jurisdiction, and are governed
by the laws of the country where J, L, and C operate. What exactly
J, L, and C do when any of their internal decision procedures return
a “reject” in the course of operation is beyond the scope of SAMPL.
For example, what happens when C decides to reject the IO when
the IO violates statutory company policy in some way? Or what
is the course of action for L to follow if J decides to reject its
surveillance request?
(3) Handling Multiple Users: We described, prototyped, and an-
alyzed SAMPL with an example of a single user being surveilled
by L, this can easily be extended to multiple users (I ∈ [1..α]) by
modifying the SO to include a list of users’ identities. We would
, · · · , V Kα
AI, · · · , V Kα
1
, and V K
then have V K
.
PIi
When multiple identities are surveilled, J needs to add a random
string (salt) to each user’s identity(V K
RI, · · · , V Kα
RI) and hash it
1
before putting it in P1 of SO. This randomization added to each
identity will help protect the identities of each of the surveilled
users from each other whenever the SO expires and is released to
the individuals being surveilled. The random salts for all the V KRI’s
are shared with L and C.
(4) Hard reject/soft reject: Whenever an SR or SRR is rejected by
E, perhaps due to clerical errors, administrative errors, or otherwise
honest mistakes on the part of C or L, E just responds with a reject
message and takes no further action (soft reject). E can assess how
many times a certain party’s request/response has been rejected.
Once this number of rejections reaches a threshold, which can be
a system parameter, E informs the party whose request/response
was rejected, and the judge J, and stores a local copy of the reason
RI, · · · , V Kα
1
, V K
1
PIi
RI
AI
Session 9E: Web Censorship and AuditingCCS ’19, November 11–15, 2019, London, United Kingdom2260Table 3: SRR Verification time (sec) break-down at E for bNum = 32 and message size of 75 KB.
Surveillance Period (Days)
Number of Users
ZKP Verification for PIi (s)
Merkle Root Generation (s)
Merkle Sign Verification (s)
5
5
0.039
0.140
0.015
10
0.0795
0.259
0.0304
15
0.1207
0.382
0.046
30
0.2003
0.619
0.0767
5
0.0750
0.246
0.0286
10
0.1528
0.475
0.0583
10
15
0.229
0.705
0.0875
30
0.459
1.390
0.1757
5
0.369
1.1178
0.141
50
10
0.740
2.224
0.282
15
1.109
3.32
0.423
30
2.219
6.64
0.846
for the rejection (to provide to J upon request), and writes a “fail”
message to the BC – a hard reject. Note that for fined grained
information on errors/malicious behaviors, E can choose to post
soft reject on BC.
(5) Auditable data structures: Auditable data structures [26] im-
plemented on C’s servers could also be used by E to verify that C is
non-malicious and complying with court orders. This implementa-
tion would need careful system design with read/write counters on
the data stores with E having access to the counters.
(6) Forward Security: If one of I’s previously used SKPI gets com-
promised and C gets access to it, C can fake I’s historical data by
modifying the Merkle trees for past batches and signing them with
the compromised key. To guard against this, each time I chooses a
new PI, a new Merkle tree is created between I and C whose leaves
are the signed root hashes of the past batches. The root of this new
hierarchical Merkle tree is signed with the new PI. This operation
can be repeated for each new PIs to make it harder for a malicious
C to frame I, since C would need to compromise multiple SKPIs
belonging to I.
10 CONCLUSION
In this paper, we present a practical mechanism for secure auditing
of surveillance orders by an overseer called Enforcer, E. The E checks
if law enforcement agencies and companies are over-requesting
and over-sharing user data, respectively, beyond what is permitted
by the surveillance order, in a privacy-preserving way, such that
E does not know the real identities of the users getting surveilled,
nor does it get to read the users’ unencrypted data. Our system also
has inbuilt checks and balances to require unsealing of surveillance
orders at the appropriate times, thus enabling accounting of the
surveillance operation being surveilled to verify that lawful proce-
dures were followed, protecting users from government overreach,
and helping law enforcement agencies and companies demonstrate
that they followed the rule of law.
ACKNOWLEDGMENT
The authors thank Dr. Dennis Giever, Head, Department of Criminal
Justice, New Mexico State University, and an anonymous, retired
FBI agent for their valuable comments.
Research supported by US NSF awards #1800088; #1719342; #1345232,
#1914635, EPSCoR Cooperative agreement OIA-1757207; and US
Army Research Office grant #W911NF-07-2-0027. Any opinions,
findings, and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reflect the
views of the federal government.
REFERENCES
[1] Dept. of Justice Office of Inspector General: A review of the federal bureau of
investigations’s use of national security letters. https://oig.justice.gov/reports/
2016/o1601b.pdf.
[2] Dept. of Justice Office of Inspector General: A review of the federal bureau of
investigations’s use of exigent letters and other informal requests for telephone
records. https://oig.justice.gov/special/s1001r.pdf.
[3] Government Publishing Office.
https://www.govinfo.gov/app/details/
USCODE-2015-title29/USCODE-2015-title29-chap28-subchapI-sec2616.
[4] Government Publishing Office.
https://www.govinfo.gov/app/details/
USCODE-2011-title18/USCODE-2011-title18-partI-chap121-sec2703.
[5] Foreign Intelligence Surveillance. http://uscode.house.gov/view.xhtml?path=
/prelim@title50/chapter36&edition=prelim.
[6] American civil liberties union. https://www.aclu.org.
[7] Akinyele, J. A., Garman, C., Miers, I., Pagano, M. W., Rushanan, M., Green,
M., and Rubin, A. D. Charm: a framework for rapidly prototyping cryptosystems.
J. Cryptographic Engineering 3, 2 (2013), 111–128.
[8] Bates, A. M., Butler, K. R. B., Sherr, M., Shields, C., Traynor, P., and Wallach,
D. S. Accountable wiretapping -or- I know they can hear you now. In 19th Annual
Network and Distributed System Security Symposium, NDSS (2012).
[9] Bellare, M., Boldyreva, A., and O’Neill, A. Deterministic and efficiently
searchable encryption. In Annual International Cryptology Conference (2007),
Springer, pp. 535–552.
[10] Boneh, D. The decision diffie-hellman problem. In Algorithmic Number Theory,
Third International Symposium, ANTS, Proceedings (1998), pp. 48–63.
[11] Bovard, J. Terrorism and Tyranny: Trampling Freedom, Justice, and Peace to Rid
the World of Evil. Palgrave Macmillan, 2004.
[12] Canetti, R. Universally composable security: A new paradigm for cryptographic
protocols. In 42nd Annual Symposium on Foundations of Computer Science, FOCS
(2001), pp. 136–145.
[13] Canetti, R. Universally composable signature, certification, and authentication.
[15] Chase, M., and Lysyanskaya, A. On signatures of knowledge.
In 17th IEEE Computer Security Foundations Workshop, (CSFW-17 (2004).
[14] Canetti, R., Lindell, Y., Ostrovsky, R., and Sahai, A. Universally composable
two-party and multi-party secure computation. In Proceedings on 34th Annual
ACM Symposium on Theory of Computing (STOC) (2002), pp. 494–503.
In Annual
International Cryptology Conference (2006), Springer, pp. 78–96.
[16] Chaum, D., and Pedersen, T. P. Wallet databases with observers. In Advances in
Cryptology - CRYPTO (1992), pp. 89–105.
[17] ECPA. https://it.ojp.gov/privacyliberty/authorities/statutes/1285.
[18] Ethereum project. https://www.ethereum.org.
[19] Facebook
https://transparency.facebook.com/
transparency
report.