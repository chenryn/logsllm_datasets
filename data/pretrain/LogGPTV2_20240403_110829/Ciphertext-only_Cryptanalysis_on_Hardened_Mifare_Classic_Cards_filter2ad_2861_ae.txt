LFSR-stream resulting from feeding {b} and {b′} as input,
respectively.
deﬁnition of a49+j , we obtain
a49+j ⊕ a′
49+j =f (a10+j a12+j . . . a48+j ) ⊕ {bj+1} ⊕ uj+1⊕
Suppose {b} and {b′} have a common preﬁx of i bits, i.e.
{bj } = {b′
j } for all j < i. In step (iii) of the methodology
from the previous paragraph we, for each pair (p, q), iterate
through all pairs (r, s). Within this iteration, we will now
also go through all values r′ ∈ [0, 16], for which a value
S{b′} = r′(16 − k) + (16 − r′)k exists, where k ∈ [0, 16].
Recall that every y ∈ TOr is a candidate for a17a19 . . . a55.
Per lemma 5.2, we know that a48+j = a′
48+j for all j < i.
Therefore, a y′ ∈ TOr′ must exist such that yj = y′
j for all
j < 16 + ⌊ 1
2 i⌋. If this is not the case, we can eliminate y as
a candidate for a17a19 . . . a55.
Next we focus on the remainder of {b},
the bits
beyond the constant preﬁx of i bits, to further eliminate
candidates. We eliminate the entry y ∈ TOr if we can prove
that the candidate is invalid, regardless of what value is
stored in the even bits of the LFSR.
i.e.
We follow deﬁnitions 3.5 and 3.6 and obtain, for 0 ≤ k < 8
a48+k =f (a9+ka11+k . . . a47+k) ⊕ {bk} ⊕ uk⊕
L(a0+ka5+k . . . a43+k)
We take j := i (note that later we want to increase j) and
take the diﬀerence between {a48+j } and {a′
48+j }. We get
a48+j ⊕ a′
48+j =f (a9+ja11+j . . . a47+j ) ⊕ {bj } ⊕ uj ⊕
L(a0+ja5+j . . . a43+j )⊕
f (a′
L(a′
11+j . . . a′
5+j . . . a′
9+ja′
0+ja′
47+j ) ⊕ {b′
43+j )
j } ⊕ uj ⊕
Obviously, uj is XOR-ed twice, so it is canceled out.
Recall that we are concerned with odd bits, thus j is
odd. Therefore, f (a9+ja11+j . . . a47+j ) depends only on even
LFSR stream bits. We introduce an invariant stating that
the even bits are equal:
47+j
9+ja′
9+ja′
11+j . . . a′
11+j . . . a′
a9+ja11+j . . . a47+j = a′
(1)
Given that j = i, we know that the invariant holds. Hence,
also f (a9+ja11+j . . . a47+j ) = f (a′
47+j ), regard-
less of what the actual value for a9+ja11+j . . . a47+j is. Fur-
thermore, since all even positioned bits fed to the feedback
function L are equal, they are canceled out. Thus, the above
is equivalent to
a48+j ⊕ a′
43+j
Hence, in order for candidate y to be valid, a y′ must exist
such that
48+j = {bj } ⊕ {b′
41+j ⊕ a43+j ⊕ a′
j } ⊕ a41+j ⊕ a′
y16+⌊ 1
2
j⌋ ⊕ y′
16+⌊ 1
2
j⌋ ={bj } ⊕ {b′
j }⊕
j⌋ ⊕ y′
j⌋ ⊕ y′
y13+⌊ 1
2
y14+⌊ 1
2
13+⌊ 1
2
14+⌊ 1
2
j⌋⊕
j⌋
Suppose such a y′ indeed exists such that the above is true.
At this point, we need not immediately accept y as a valid
candidate. Rather, we may test whether the above also holds
for j ← j +2. However, in order to do so, we must ﬁrst check
whether invariant (1) still holds. Given that it holds for j,
all we need to do is verify that a49+j = a′
49+j . Following the
L(a1+ja6+j . . . a44+j )
f (a′
L(a′
12+j . . . a′
6+j . . . a′
10+j a′
1+ja′
44+j )
48+j ) ⊕ {b′
j+1} ⊕ uj+1⊕
Similar as before, uj+1 is XOR-ed twice and hence canceled
out. Also the even positioned bits and all odd bits positioned
between 0 and 47 + i fed to the feedback function are equal,
thus canceled out. Hence, the above becomes
a49+j ⊕ a′
j+1} ⊕ f (a10+j a12+j . . . a48+j )⊕
49+j ={bj+1} ⊕ {b′
f (a′
10+j a′
12+j . . . a′
48+j ) ⊕ a42+j ⊕ a′
42+j
Translating this into terms of y and y′ again, we obtain
(recall x in step (iii) from the methodology described in the
last paragraph)
{bj+1} ⊕ {b′
j+1} ⊕ f (x[1+⌊ 1
f (x[1+⌊ 1
2
j⌋,3]y′
[0,16+⌊ 1
2
j⌋]) ⊕ y14+⌊ 1
2
14+⌊ 1
2
i⌋
2
j⌋,3]y[0,16+⌊ 1
i⌋ ⊕ y′
2
j⌋])⊕
If the above evaluates to 0, we have proven that, in case
y is valid, then a49+j = a′
49+j, and hence we have proven
that invariant (1) still holds. We proceed by attempting
to disprove the validity of y once more with j ← j + 2.
Otherwise, we stop and accept y as a candidate. In case we
reach j = 7 we always stop and accept y as a candidate.
In case no y′ exists such that y is accepted, we have proven
the invalidity of y and eliminate it.
Obviously, the diﬀerential analysis presented here can be
repeated with other input bytes {b′}, which will result in the
elimination of additional key candidates.
Due to the sheer complexity of analyzing the average size
of the leftover complexity yielded by the diﬀerential anal-
ysis, we will not concern ourselves with this. Practical ex-
periments indicate that it is sensible to assume a drop of
approximately 1 bit per byte {b′} involved in the analysis.
However, it is important to note that a single incorrect guess
for S{b′} will likely cause the correct key to be absent from
the resulting leftover search space.
In the next section, we present another independent prop-
erty of the cipher’s internal state that we can deduce by
observing the ciphertext. We may use this property to elim-
inate additional key candidates, hence even further dropping
the computational complexity.
5.6 Filter Flip Property
The second property that can be observed by analyzing the
ciphertext is what we name the ﬁlter ﬂip property. It was
ﬁrst documented in the literature by Garcia et al.
in 2009
[GRVS09].
Lemma 5.10. Suppose we obtained two encrypted nonces
{nT } and {n′
T }. Their corresponding LFSR-streams are
a0a1 . . . and a′
0a′
1 . . . , respectively and their parity bits are pi
and p′
i for all i ∈ N. Suppose that we observe that all bytes
before byte i, where i ∈ [0, 3], are equal and that only the
last bit of byte i diﬀers, i.e. {nT[0,8i+7] } = {n′
T[0,8i+7] } ⊕ 1.
Furthermore, we ﬁnd that {pi} = {p′
i}.
Then f (α8i+8) 6= f (α8i+8 ⊕ 1).
Proof. Published in [Mei15].
Suppose that we ﬁnd a case of {nT[8i,8i+7] } where the
above is not the case. Then we can observe the ﬁlter ﬂip
property on even bits. The following lemma states this.
T } such that {nT[0,8i+7] } = {n′
Lemma 5.11. Suppose we obtained two encrypted nonces
{nT } and {n′
T[0,8i+7] } ⊕ 2,
where i ∈ [0, 3]. Furthermore, we observe that {pi} = {p′
i},
and we have deduced through lemma 5.10 that f (α8i+7) =
f (α8i+7 ⊕ 1).
Then f (α8i+7) 6= f (α8i+7 ⊕ 1).
Proof. Published in [Mei15].
We continue with the lemma showing that only approxi-
mately 9.4% of the possible inputs to the ﬁlter function f
have this property.
Lemma 5.12. Let Y0, . . . , Y4 be independent uniformly dis-
tributed random variables over F2. Then
P [fb(Y0, Y1, Y2, Y3) 6= fb(Y0, Y1, Y2, Y3)] = 1
4
P [fc(Y0, Y1, Y2, Y3, Y4) 6= fc(Y0, Y1, Y2, Y3, Y4)] = 3
8 .
Proof. By inspection.
Since only the twenty bits that are input to f are relevant,
such that f (x) 6= f (x ⊕ 1) can be easily
all states x ∈ F20
2
generated. Below the set of these states F is deﬁned
F := {x | x ∈ F20
2 and f (x) 6= f (x ⊕ 1)}
We can use the diﬀerential analysis described in the pre-
vious section to further narrow down the search space. We
may do so by applying it to F , rather than TOr in case we
observe that f (α8) 6= f (α8 ⊕ 1) for a certain input byte {b′}.
Practical experiments indicate that, for every ﬁlter ﬂip
property observed, we may assume a complexity drop of ap-
proximately 1
2 bits during the diﬀerential analysis described
in the previous section.
In the next section we shall more concretely analyze the
performance of the attack by means of simulations.
6 Performance analysis
In this section, we analyze the performance of the attack.
We implemented the attack and ran simulations, wherein
we vary the number of nonces gathered and the probability
threshold. The performance of the attack is expressed by
the size of the resulting leftover search space, which is de-
termined as described in step (iv) in Section 5.5. The sum
property value and the ﬁlter ﬂip property being present both
depend on the cipher’s internal state. Hence, the resulting
complexity depends heavily on the key. Due to this fact, in
order to assess the overall eﬃciency of the attack, we simu-
lated the attack using 100 randomly chosen keys.
Figure 6.1 contains a graph depicting the median leftover
complexity. The translucent planes depict the second and
third quartile. From this ﬁgure we can observe that the
leftover complexity quickly becomes within reach of solv-
ing on ordinary hardware within minutes. Typically, after
collecting approximately 10,000 - 20,000 nonces, the leftover
complexity is solvable even within seconds. The trade-oﬀ be-
tween gathering additional nonces or starting a brute force
attempt within the leftover search space depends on which
is on the upper hand: the nonce-retrieving hardware or the
computational power we have at our disposal.
Contrary to the expectations, the leftover complexity may
increase slightly when the number of nonces increases. We
suspect this is due to the fact that, in our implementation,
we select a single byte {b} and perform the diﬀerential anal-
ysis presented in Section 5.5 against all other bytes {b′}.
The selection of {b} is based on heuristics which we will not
Figure 6.1: Median leftover complexity
explain in detail. The consequence of this is that the anal-
ysis runs signiﬁcantly faster than when we would perform
the analysis for every possible {b} against all other bytes
{b′} and subsequently select the smallest resulting set, at
the cost of the resulting search space becoming somewhat
suboptimal. However, the total time needed to recover a
key is decreased.
Every time we choose to involve another input byte/sum
property pair in the diﬀerential analysis (i.e. the sum prop-
erty value is known with a probability exceeding the thresh-
old chosen), the leftover search space decreases in size. Since
sum property values at time 8 are determined probabilisticly,
the probability that the correct keys exists within the left-
over search space also decreases. Therefore, another aspect
of the performance analysis is determining the actual prob-
ability that the correct key lies within the leftover search
space, given the probability threshold chosen.
Figure 6.2 depicts the probability of the correct key ly-
ing within the leftover search space. One may expect it to
rapidly decrease in case we involve a large number of input
bytes in the analysis. Fortunately for the adversary, this is
not the case. This is because the sum property values for
each input byte are not statistically independent from one
another.
Figure 6.2: Leftover search space with the correct key.
Finally, we should highlight that our implementation of
the attack only returns the leftover search space if at least
a single input byte is involved in the analysis, i.e. the prob-
ability of guessing the sum property correctly exceeds the
chosen threshold for at least a single input byte at time 8).
Though this is not strictly necessary, as one could simply
take the set of all possible values for the internal state at
time 8. However, implementing the attack this way resulted
in cleaner code. Therefore, in the statistics depicted above,
every sample wherein we do not assign a sum property value
to any of the input bytes is not taken into account.
Figure 6.3 depicts the number of samples having at least
a single sum property guess exceed the probability thresh-
old. Thus, depicting the number of samples being taken into
account in the other statistics presented in this section.
Figure 6.3: Number of samples involved in the statistics
7 Conclusion
Over the last years there are a number of vulnerabilities and
attacks identiﬁed in the cryptography and implementation
of mifare Classic cards. The most serious of them are the
card-only attacks, which can recover the secret key simply
through wireless interaction with a card in an uncontrolled
environment. System integrators consider these attacks as
one of most serious threats to their mifare Classic based
systems, since it allows the adversary to avoid camera de-
tection.
We are the ﬁrst to discover a card-only attack that de-
pends solely on the design issues of the cipher and authen-
tication protocol. To the best of our knowledge, every mi-
fare Classic compatible card that is currently in circulation