e
t
a
l
i
n
m
0
0
100
200
400
300
500
throughput [1/s]
600
700
800
Figure 4. Latency vs.
normal-steady scenario.
throughput in the
ments. This explains why the GM algorithm shows slightly
better performance with the same number of crashes.
For the GM algorithm, it does not matter which pro-
cess(es) crash. For the FD algorithm, the crash of the coor-
dinator of Round 1 gives worse performance than the crash
of another process. However, the performance penalty when
the coordinator crashes is easily avoided: (1) each process
tags its consensus proposal with its own identiﬁer, and (2)
upon decision, each process re-numbers all processes such
that the process with the identiﬁer in the decision becomes
the coordinator of Round 1 in subsequent consensus exe-
cutions. This way, crashed processes will stop being co-
ordinators eventually, hence the steady-state latency is the
same regardless of which process(es) we forced to crash.
Moreover, the optimization incurs no cost. Hence Fig. 5
shows the latency in runs in which non-coordinator pro-
cesses crash.
Note also that the GM algorithm has higher resiliency on
the long term if crashes occur, as the group size decreases
with the crashes. E.g., with n = 7 and 3 crashes, the GM
algorithm can still tolerate one crash after excluding the
crashed processes, whereas the FD algorithm can tolerate
none.
Suspicion-steady scenario (Fig. 6, 7). The occurence of
wrong suspicions are quantiﬁed with the TMR and TM QoS
metrics of the failure detectors. As this scenario involves
crashes, we expect that the mistake duration TM is short.
In our ﬁrst set of results (Fig. 6) we hence set TM to 0,
and latency is shown as a function of TMR. We have four
graphs: the left column shows results with 3 processes, the
right column those with 7; the top row shows results at a
−1) and the bottom row at a moderate load
low load (10 s
−1); recall from Fig. 4 that the algorithms can take a
(300 s
−1 in the absence of suspicions.
throughput of about 700 s
The results show that the GM algorithm is very sensitive
−1, it
to wrong suspicions: even at n = 3 and T = 10 s
only works if TMR ≥ 50 ms, whereas the FD algorithm still
works at TMR = 10 ms; the latency of the two algorithms
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:12:39 UTC from IEEE Xplore.  Restrictions apply. 
]
s
m
[
y
c
n
e
t
a
l
i
n
m
]
s
m
[
y
c
n
e
t
a
l
i
n
m
50
45
40
35
30
25
20
15
10
5
0
90
80
70
60
50
40
30
20
10
0
n = 3
FD and GM, no crash
FD, 1 crash
GM, 1 crash
0
100
200
400
300
500
throughput [1/s]
n = 7
600
700
800
FD and GM, no crash
FD, 1 crash
GM, 1 crash
FD, 2 crashes
GM, 2 crashes
FD, 3 crashes
GM, 3 crashes
0
100
200
400
300
500
throughput [1/s]
600
700
800
Figure 5. Latency vs. throughput in the crash-
steady scenario. The legend lists the curves
from the top to the bottom.
is only equal at TMR ≥ 5000 ms.
In the second set of results (Fig. 7) TMR is ﬁxed and TM
is on the x axis. We chose TM R such that the latency of the
two algorithms is close but not equal at TM = 0: (i) TMR =
−1; (ii) TMR = 10000 ms
1000 ms for n = 3 and T = 10 s
−1;
for n = 7 and T = 10 s
and (iii) TMR = 100000 ms for n = 7 and T = 300 s
−1 and for n = 3 and T = 300 s
−1.
The results show that the GM algorithm is sensitive to the
mistake duration TM as well, not just the mistake recurrence
time TMR.
Crash-transient scenario (Fig. 8).
In this scenario, we
only present the latency after the crash of the coordinator
and the sequencer, respectively, as this is the case result-
ing in the highest transient latency (and the most interesting
comparison). If another process is crashed, the GM algo-
rithm performs roughly the same, as a view change occurs.
In contrast, the FD algorithm outperforms the GM algo-
rithm: it performs slightly better than in the normal-steady
scenario (Fig. 4), as fewer messages are generated, just like
in the crash-steady scenario (Fig. 5).
Figure 8 shows the latency overhead, i.e., the latency mi-
nus the detection time TD, rather than the latency. Graphs
showing the latency overhead are more illustrative; note that
the latency is always greater than the detection time TD in
this scenario, as no atomic broadcast can ﬁnish until the
crash of the coordinator/sequencer is detected. The latency
overhead of both algorithms is shown for n = 3 (left) and
]
s
m
[
y
c
n
e
t
a
l
i
n
m
]
s
m
[
y
c
n
e
t
a
l
i
n
m
]
s
m
[
y
c
n
e
a
t
l
i
n
m
]
s
m
[
y
c
n
e
t
a
l
i
n
m
n = 3, throughput = 10 1/s
n = 7, throughput = 10 1/s
100
FD
GM
80
60
40
20
0
1
100
FD
GM
80
60
40
20
0
1
]
s
m
[
y
c
n
e
t
a
l
i
n
m
]
s
m
[
y
c
n
e
t
a
l
i
n
m
100
FD
GM
80
60
40
20
0
1
100
FD
GM
80
60
40
20
0
1
10
100
1000
10000 100000 1e+06
mistake recurrence time TMR [ms]
n = 3, throughput = 300 1/s
10
100
1000
10000 100000 1e+06
mistake recurrence time TMR [ms]
10
100
1000
10000 100000 1e+06
mistake recurrence time TMR [ms]
n = 7, throughput = 300 1/s
10
100
1000
10000 100000 1e+06
mistake recurrence time TMR [ms]
Figure 6. Latency vs. TMR in the suspicion-
steady scenario, with TM = 0.
n = 3, throughput = 10 1/s, TMR = 1000 ms
n = 7, throughput = 10 1/s, TMR = 10000 ms
200
180
160
140
120
100
80
60
40
20
0
FD
GM
1
10
100
1000
mistake duration TM [ms]
FD
GM
250
200
150
100
50
]
s
m
[
y
c
n
e