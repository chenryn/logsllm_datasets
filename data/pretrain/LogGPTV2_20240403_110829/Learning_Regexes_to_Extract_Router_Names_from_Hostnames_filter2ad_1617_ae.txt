also replacing digits in the CSs with regex components that match
digits. For the routers in figure 6, we obtain \d+ge\d+, ge\d+, and
esnet\.\d+gigabitethernet\d+.
Figure 7b shows how we build an intermediate regex set, where
we replace the extraction in the regex with these patterns. We
evaluate each regex in the intermediate set using the method in
§4.2 and rank the regexes using the ATP method in §4.3. We add the
highest ranked regex from the intermediate set to a working set, and
^([^-]+)-[^\.]+\.(core[^\.]+\.[^\.]+)\.he\.net$100ge4|core3.fmt2esnet.10gigabitethernet5|core1.ash1ge2|core1.atl12a1a 1bge6|core1.atl12b4a100ge5|core1.ash110ge16|core1.ash13c3a 3b^\d+ge\d+-[^\.]+\.(core[^\.]+\.[^\.]+)\.he\.net$^ge\d+-[^\.]+\.(core[^\.]+\.[^\.]+)\.he\.net$^esnet\.\d+gigabitethernet\d+-[^\.]+\.(core[^\.]+\.[^\.]+)\.he\.net$core3.fmt2core1.ash1core1.atl11a 1b3a 3b 3c2a 2b^(?:\d+ge\d+|ge\d+)-[^\.]+\.(core[^\.]+\.[^\.]+)\.he\.net$FNU: 1c, 1d. SN: 4a, 5a1, 2, 5, 6, 7, 91, 3ash1, atl1, fmt2\d+\d+[a-z\d]+, [a-z]+\d+§5.3:FNE§5.4:classes^(?:\d+ge\d+|ge\d+)-\d+\.(core\d+\.[a-z]+\d+)\.he\.net$§5.5:FNU1c: v11191d: v1832v\d+^v\d+\.(core\d+\.[a-z]+\d+)\.he\.net$core3.fmt2core1.ash1core1.atl11a 1b 1c 1d3a 3b 3c2a 2b^(?:\d+ge\d+|ge\d+)-\d+\.(core\d+\.[a-z]+\d+)\.he\.net$SN: 4a, 5a§5.6:build sets^v\d+\.(core\d+\.[a-z]+\d+)\.he\.net$ATP: 9ATP: 7(a)(b)(c)(d)(e)FNU: 1c, 1d. FNE: 2a, 2b, 3c. SN: 5aATP: 1IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Matthew Luckie, Bradley Huffaker, and k claffy
Figure 8: Refinement of comcast.net regexes in phase §5.7. NC #1 incorrectly clusters hostnames assigned to client interfaces
together, and extracts portions of IP address literals, so we build filter regexes to exclude these hostnames in NC #2.
5.7 Build Filter Regexes
A regex may cluster hostnames together that are not clustered
in training data, and the operator might use a convention that
allows them to be distinguished. A regex may also infer candidate
names for hostnames that embed a portion of a literal IP address.
This phase identifies filter regexes that match incorrectly clustered
hostnames (FP or FIP), so we do not use an extractor regex on those
hostnames. In figure 8, ([^-]+)\.comcast\.net$ incorrectly clusters
hostnames 4a, 5b, and 6a into c.ashburn.va.ibone, and interfaces
4b and 5a into c.chicago.il.ibone. Similarly, this regex incorrectly
extracts 230.hsd1.md and 77.hsd1.ut, which contain a component
of a literal IP address embedded in the hostname.
We assemble the hostnames with false assignments (i.e., FP and
FIP) and recursively extract CSs from these components. For the
FPs we extract as13385|c-ashburn.va.ibone, as7272-1-c|ibone, and
as|c|ibone, and for the FIPs we extract c|hsd1. We then build filter
regexes, embedding CSs in the regexes, and rank the regexes by
the number of false assignments filtered (descending), then by the
number of true positives filtered (ascending). We expand a candidate
regex with the best filter regex, provided the following conditions
hold. First, the regex must correctly filter false assignments from
at least three routers for us to have confidence that the regex is
capturing a component of the naming scheme. Second, the regex
must filter more false assignments than true positives, i.e., must
improve the PPV of the naming convention. Finally, for the FP case,
the regex must reduce the inferred FPs by at least 10%, to avoid
overfitting to the training data. We embed additional filter regexes
until we find no additional filter that meets these conditions.
Figure 9: The best naming convention for he.net given the
training set in figure 6. This convention is simpler than the
one in figure 7 and results in a single FP.
5.8 Select Best Convention
It is possible to assemble a naming convention that contains mul-
tiple regexes, each covering a small portion of a suffix’s routers.
However, complex naming conventions may overfit to the training
data, which can contain errors, and miss operator intent. We there-
fore penalize model complexity when selecting a best convention,
with the following approach.
We rank naming conventions by ATP (§4.3) and select the high-
est ranked convention. Then, we consider conventions with a lower
ATP value. If a lower ranked convention has an ATP value within
4% of the higher ranked convention, i.e., the higher ranked conven-
tion is not significantly better than the lower ranked convention,
then we select the lower ranked convention if either of the follow-
ing conditions hold. First, if the PPV of inferences unique to the
higher ranked convention is at least 10% lower than the PPV of the
lower ranked convention – that is, the delta of the higher ranked
convention is poor, then we choose the lower ranked convention.
ar01.area4.il.chicago.comcast.nethe-0-10-0-0-ar01.area4.il.chicago.comcast.nethe-0-12-0-0-ar01.area4.il.chicago.comcast.netbe-10-pe04.ashburn.va.ibone.comcast.netbe-11-pe04.ashburn.va.ibone.comcast.nette-0-6-0-0-pe04.ashburn.va.ibone.comcast.net1a1b1c2a2b2c4a4b5a5b8abe-10-cr01.miami.ﬂ.ibone.comcast.netbe-11-cr01.miami.ﬂ.ibone.comcast.net3a3b^c-\d+-\d+-\d+-\d+\.hsd1\.[a-z]+\.comcast.net$ar01.area4.il.chicago1a 1b 1ccr01.miami.ﬂ.ibonepe04.ashburn.va.ibone2a 2b 2c3a 3b  ^as\d+-\d+-c\.[a-z]+\.[a-z]+\.ibone\.comcast\.net$  6a6b7aas13385-10-c.chicago.il.ibone.comcast.net as13385-17-c.ashburn.va.ibone.comcast.netas13385-10-c.ashburn.va.ibone.comcast.netas13385-2-c.miami.ﬂ.ibone.comcast.netas7272-1-c.ashburn.va.ibone.comcast.netas7272-1-c.chicago.il.ibone.comcast.netc-98-233-46-230.hsd1.md.comcast.netc-174-52-116-77.hsd1.ut.comcast.netRouter #1: ar01.area4.il.chicagoRouter #2: pe04.ashburn.va.iboneRouter #3: cr01.miami.ﬂ.iboneRouter #4: unnamedRouter #5: unnamedRouter #6: unnamedRouter #7: unnamedRouter #8: unnamedNC #1:c.chicago.il.ibonec.ashburn.va.ibone4b 5a4a 5b 6a230.hsd1.md77.hsd1.ut7a8ac.miami.ﬂ.ibone6bFPsFIPsas|c|ibonec|hsd1  ([^-]+)\.comcast\.net$  ar01.area4.il.chicago1a 1b 1ccr01.miami.ﬂ.ibonepe04.ashburn.va.ibone2a 2b 2c3a 3bNC #2:  ([^-]+)\.comcast\.net$    ^as\d+-\d+-c\.[a-z]+\.[a-z]+\.ibone\.comcast\.net$  ^c-\d+-\d+-\d+-\d+\.hsd1\.[a-z]+\.comcast.net$core3.fmt2core1.ash1core1.atl11a 1b 1c 1d3a 3b 3c2a 2bFP: 5a, SN: 4a^[^\.]+\.(core\d+\.[a-z]+\d+)\.he\.net$5aATP: 8Learning Regexes to Extract Router Names from Hostnames
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Figure 10: Routers with names not delimited by punctuation. NC #1 separates hostnames belonging to the same training router.
NC #2, which we do not currently build, retains the clustering by building a regex that separates on change in character class.
Otherwise, if the lower ranked convention consists of fewer regexes
and yields no more than one additional FP, then we choose the lower
ranked convention according to the principle outlined in §4.1 to
avoid overfitting to the training data.
We illustrate this by comparing the clustering by a more complex
convention with a higher ATP (9) in figure 7 with the clustering
by a less complex convention with a lower ATP (8) in figure 9. The
less complex convention has only a single additional FP (caused by
a stale hostname) but captures the operator intent, so we choose
the less complex convention.
6 LIMITATIONS
Zhang et al. established in 2006 that because operators do not
necessarily maintain hostnames in DNS, Internet topology mapping
efforts using hostnames can be distorted [29]. Errors in hostnames
can impact the accuracy of alias inferences using our regexes.
Our method currently builds regexes that extract names delim-
ited by punctuation from hostnames, but operators do not always
delimit names with punctuation. Figure 10 illustrates the problem,
where NC #1 separates interfaces belonging to the same training
routers in odn.ad.jp, because it extracts part of the hostname, de-
limited by punctuation, it should not. This limitation could be fixed
by including additional heuristics in our method to build NC #2.
A fundamental limitation is that our technique cannot always
cluster hostnames in different suffixes. Figure 11 illustrates the prob-
lem, where yahoo.net operators assigned addresses belonging to
other networks on two of their routers, in order to connect to those
networks. Because the operators of these different networks control
the assignment of hostnames to their addresses, and operators can
choose their own naming convention, there is no opportunity to
cluster these interfaces using hostnames. In the April 2019 ITDK,
18.9% of training routers had hostnames in more than one suffix.
7 RESULTS
We evaluated our algorithm by applying it across 16 ITDKs assem-
bled by CAIDA between July 2010 and April 2019; all ITDKs contain
IPv4 topology data, and two ITDKs contain IPv6 topology data. We
classify a naming convention as poor if it clusters interfaces on
fewer than three routers (because we cannot have confidence we
Figure 11: There is usually no way to cluster interfaces for
routers with hostnames in more than one suffix because in-
dividual networks have their own naming conventions.
have found a convention), or has a PPV on the training data of less
than 80% (because it did not perform well). We classify a naming
convention as promising if it clusters interfaces on at least three
but fewer than seven routers with a PPV of at least 80% (because a
single FP in a small network has a significant impact on the PPV),
or has a PPV of less than 90% (because the convention has pre-
dictive power but does not evaluate well). Finally, we classify the
remaining naming conventions with a PPV at least 90% on more
than three routers as good.
Figure 12 shows that we classified ≈33.5% of conventions for each
IPv4 ITDK as good, covering ≈1K suffixes in each ITDK; promising
conventions covered ≈3.8% of suffixes. Good conventions covered
≈60 suffixes (≈31.6%) for the two IPv6 ITDKs. We inferred at least
one good convention for 2550 different suffixes across the 16 IPv4
ITDKs. However, the fraction of suffixes we inferred good conven-
tions for IPv4 ITDKs has reduced over time: for July 2010, 35.7%
of suffixes had a good convention; by April 2019, the fraction was
30.6%. This drop may reflect a reduction in coverage of active alias
resolution techniques, as some operators configure their routers to
ignore probes or do not announce routes for their infrastructure,
and some routers do not respond to probes with a signature that is
useful to active alias resolution techniques (§2.4).
Router #1: fkhrw-01Router #2: fkhrw-02fkhrw-01gi1-1.nw.odn.ad.jpfkhrw-01gi1-2.nw.odn.ad.jpfkhrw-01gi3-1.nw.odn.ad.jpfkhrw-01gi3-9.nw.odn.ad.jpfkhrw-02gi1-1.nw.odn.ad.jpfkhrw-02gi1-2.nw.odn.ad.jpfkhrw-02gi3-1.nw.odn.ad.jpfkhrw-02gi3-9.nw.odn.ad.jpkajrc-02te0-0-0-1.nw.odn.ad.jpkajrc-02te0-0-2-2.nw.odn.ad.jpRouter #3: kajrc-021a1b1c1d2a2b2c2d3a3bfkhrw-01fkhrw-02kajrc-021a 1b 1c 1d2a 2b 2c 2d^([a-z]+-\d+)[a-z]+\d+-[^\.]+\.nw\.odn\.ad\.jp$NC #2:3a 3bTP: 10ATP: 10^([a-z]+-[a-z\d]+)-[^\.]+\.nw\.odn\.ad\.jp$fkhrw-01gi1kajrc-02te01a 1bNC #1:3a 3bfkhrw-01gi31c 1dfkhrw-02gi12a 2bfkhrw-02gi32c 2dTP: 6, FNE: 4ATP: 2^[^\.]+\.([a-z]+\d+\.[a-z]+)\.yahoo\.com$Router #1: msr2.aueRouter #2: pat1.atzxe-0-0-0.msr2.aue.yahoo.comxe-2-1-0.msr2.aue.yahoo.comyah2817952.lnk.telstra.netas17457.bdr01.syd03.nsw.vocus.net.auae0.pat1.atz.yahoo.comae1.pat1.atz.yahoo.comae2.pat1.atz.yahoo.comverizon.com.customer.alter.netyahoo-inc.ear1.atlanta2.level3.netyahoo-ic-325257-atl-b22.c.telia.netIMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Matthew Luckie, Bradley Huffaker, and k claffy
A Large North American content provider.
117 TR, 99.7% PPV, 301 TP, 1 FP, 4 FNE.
Correct. Semi-automated, PTR record auto-derived
from manually entered A record.
European Tier-1 transit provider, eurorings.net.
37 TR, 100% PPV, 110 TP, 3 FNE.
Semi-correct. Manual. Two regexes, one overfitted.
B
C Large European transit provider.
70 TR, 99.4% PPV, 174 TP, 1 FP, 2 FNE.
Correct. Semi-automated, once per month.
D Medium North American access network.
26 TR, 100% PPV, 52 TP.
4 TR, 100% PPV, 8 TP.
Correct. Manual.
E Medium North American access network.
8 TR, 100% PPV, 20 TP.
Correct. No DNS maintenance followup.
F Medium North American access network, ebox.ca.
5 TR, 92.8% PPV, 64 TP, 5 FP, 7 FNU.
Semi-correct. Errors in training data.
G Small North American access network, clearrate.com.
4 TR, 100% PPV, 9 TP, 11 FNU.
Correct. Script periodically manually run against
RANCID database. FNU are customer interfaces.
H Small U.K. hosting provider.
3 TR, 100% PPV, 6 TP.
Correct. Small, relatively static network.
Manual, automation not a priority.
North American university.
6 TR, 100% PPV, 14 TP.
Correct. No DNS maintenance followup.
European university, bme.hu.
2 TR, 100% PPV, 4 TP.
Correct. Semi-automated from router configs.
I
J
Table 4: Summary of validation data received, with the num-
ber of training routers (TR) in each suffix.
7.2 Incongruity with the ITDK
We investigated two classes of incongruity between the April 2019
ITDK and the outcome of applying the IPv4 naming conventions
we classed as good or promising. The incongruity could be because
the hostnames are stale, or because the ITDK contained false nega-
tives. The first class of incongruity is where the naming convention
clustered interfaces from different training routers together. The
second class of incongruity is where the naming convention clus-
tered interfaces in the application set with interfaces on training
routers; we would expect these interfaces from the application set
to be on training routers in the ITDK because the training routers
were responsive to alias resolution techniques used in the ITDK.
We conducted additional alias resolution probing in May 2019
to estimate the lower bound of false negatives in the April 2019
ITDK. Because we were investigating if pairs of interfaces were
Figure 12: Summary statistics for 16 IPv4 ITDKs across nine
years, and two IPv6 ITDKs. We classified ≈33.5% of conven-
tions inferred for each IPv4 ITDK (≈1K) as good, and ≈31.6%
conventions inferred for each IPv6 ITDK (≈60) as good.
7.1 Validation
We created webpages showing the naming conventions inferred
over time for each suffix across the 16 ITDKs we used, and sent the
webpage to NANOG in April 2019. We asked operators for each
suffix whether the regexes we learned reflected their intent. We re-
ceived private feedback for 11 suffixes from 10 operators. We asked
each operator about discrepancies between the training data and
the inferred naming convention, and about how they maintained
their zones. These operators maintained zones either manually, or
semi-automatically, with different approaches to automation. We
summarize the validation data in table 4, identifying suffixes where
the operators consented to their suffix being shared.
Of the 11, all but two naming conventions were reported as
correct. Operator B confirmed that most of our inferred names
were correct, but that our convention failed to extract a portion of
the router name for some of their routers. Some of their routers
also had incorrect hostnames; we inferred a second convention that
clustered these incorrect hostnames congruently with the training