title:Aging through cascaded caches: performance issues in the distribution
of web content
author:Edith Cohen and
Haim Kaplan
Aging Through Cascaded Caches:
Performance Issues in the Distribution of Web Content
Edith Cohen
AT&T Labs–Research
180 Park Avenue
Florham Park, NJ 07932, USA
PI:EMAIL
ABSTRACT
The Web is a distributed system, where data is stored and
disseminated from both origin servers and caches. Origin
servers provide the most up-to-date copy whereas caches
store and serve copies that had been cached for a while.
Origin servers do not maintain per-client state, and weak-
consistency of cached copies is maintained by the origin
server attaching to each copy an expiration time. Typically,
the lifetime-duration of an object is ﬁxed, and as a result,
a copy fetched directly from its origin server has maximum
time-to-live (TTL) whereas a copy obtained through a cache
has a shorter TTL since its age (elapsed time since fetched
from the origin) is deducted from its lifetime duration. Thus,
a cache that is served from a cache would incur a higher
miss-rate than a cache served from origin servers. Simi-
larly, a high-level cache would receive more requests from
the same client population than an origin server would have
received. As Web caches are often served from other caches
(e.g., proxy and reverse-proxy caches), age emerges as a per-
formance factor. Guided by a formal model and analysis, we
use diﬀerent inter-request time distributions and trace-based
simulations to explore the eﬀect of age for diﬀerent cache
settings and conﬁgurations. We also evaluate the eﬀective-
ness of frequent pre-term refreshes by higher-level caches
as a means to decrease client misses. Beyond Web content
distribution, our conclusions generally apply to systems of
caches deploying expiration-based consistency.
1.
INTRODUCTION
Web objects are typically associated with one author-
ity that can originate and modify them (their authorita-
tive server), but can be cached and further distributed from
multiple replicating servers. Indeed, caching and replication
are widely deployed for reducing Web-servers load, network
load, and user-perceived latency. Replicating servers are lo-
cated in diﬀerent points in the network and include reverse
proxies, proxy caches, and browser caches.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA.
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
Haim Kaplan
School of Computer Science
Tel-Aviv University
Tel Aviv 69978, Israel
PI:EMAIL
Replication necessitates some form of consistency, and to
this end, the sole widely-supported protocol provides weak
consistency in a client-driven expiration-based fashion: each
cached copy has an expiration time, beyond which it must be
validated or discarded. We brieﬂy mention that proprietary
strong consistency mechanism are deployed by Web host-
ing services and mirroring applications [1, 14], and various
server-driven mechanisms, where servers notify subscribed
clients when objects are modiﬁed, had been proposed. These
protocols, however, are not widely supported or used.
The distribution of Web content is governed by the HTTP
protocol [12]. Each object is identiﬁed by a URL which spec-
iﬁes its “location” and authoritative server. The object is
requested by sending an HTTP request and a copy of the
content is sent back on a corresponding HTTP response.
The response includes headers with important information,
including cache directives. The headers specify if the copy
can be cached, and may provide an explicit expiration time
or information that can be used to compute one. When an
object is requested from the cache then if the cache has a
fresh (non-expired) copy, the response is generated locally.
If the cached copy has expired, it must be validated by con-
tacting a server with a fresh copy. To this end, the HTTP
protocol provides conditional (If-Modified-Since or E-tag
based) GET requests. Similarly, if there is no cached copy,
the cache must obtain a fresh copy.
Requests for which the cache does not have a fresh copy
are termed cache misses. Cache misses require the cache to
communicate with an external server before the response can
be sent to the client. Remote communication, in turn, con-
stitutes a signiﬁcant portion of overall cache service times.
Our focus here are the eﬀects of age on the miss-rate of
the cache. The age of a cached copy is the elapsed time since
it was ﬁrst obtained from an authoritative server. When a
cache receives an aged copy, the age is eﬀectively subtracted
from the freshness lifetime value which was provided by the
authoritative source. Thus, a copy obtained through a cache
expires earlier than a copy obtained from an authoritative
source. Therefore, even caches that always have fresh copies
are somewhat less eﬀective than origin servers. A cache
which forwards requests to a cache incurs a higher miss rate
than a cache that forwards requests to the respective origin.
We refer to the increase in the miss rate of a client cache
using a replicating rather than authoritative source as the
age penalty.
While extensive work concerned improving cache eﬀective-
ness (including document prefetching [18, 11], prefetching
41validations [17, 9, 10], and proactively refreshing selected
content as it becomes stale [3, 15, 8]), age-eﬀects had been
by and large overlooked. Age becomes a performance fac-
tor for caches that function as either clients or sources to
other caches, that is, when there is more than one cache
placed between the end user and the origin server. Thus,
age is becoming increasingly relevant with the deployment
of caching hierarchies [16], and placement of caches both
as proxy caches in local ISPs and reverse proxies closer to
Web servers [22, 13]. Content delivery networks (CDNs)
also function somewhat like caches [1, 21] and can induce
age-penalty on client caches [7]. Age also impacts cooper-
ative caches, the potential beneﬁts of which were recently
explored [23]. The study observed that caching hierarchies
are not eﬀective for very unpopular objects, since for them
there is no value in sharing and there is increased latency of
forwarding a request through a cache. Age was not consid-
ered by [23] but constitutes a complementary performance
facet that also aﬀects popular objects. Overall, the impact
of age on performance seems not to be suﬃciently recog-
nized, understood, or addressed.
Our main contribution is introducing and studying age-
related performance issues, and exploring the eﬀectiveness
of mechanisms that address them. Guided by Web prac-
tices and the HTTP protocol we model diﬀerent cache con-
ﬁgurations and behaviors of low-level and high-level caches.
Speciﬁcally, we compare the performance of the following
three conﬁgurations: 1) client-cache that uses origin servers,
2) client-cache that uses consistently the same higher-level
cache per-object, and 3) client-cache that alternates between
several higher-level caches. We show that even when all
higher-level caches always serve fresh copies, there are deﬁ-
nite performance gaps between the conﬁgurations. We also
study these gaps for speciﬁc distributions, including Pois-
son, Pareto, and ﬁxed-frequency arrivals, and ﬁnally, using
trace-based simulations.
We then explore two practices: pre-term refreshes at higher-
level caches and extended freshness lifetimes at client-caches.
A cache performs a pre-term refresh when a request forces
it to contact an origin server, even when it has a fresh copy.
Conﬁgured pre-term refreshes can also be used as a mecha-
nism to reduce the age penalty. Surprisingly, we show that
pre-term refreshes can degrade performance of client caches.
On the positive side, we show how to guarantee that no
client-cache suﬀers performance losses. Moreover, we show
that well-timed pre-term refreshes can be very eﬀective in re-
ducing the age penalty. Again, we demonstrate, via analysis
and simulations, that these phenomena are fairly universal
as they apply to large families of sequences.
Extended freshness lifetimes at client caches trades de-
creased miss-rate at the cost of decreased coherence (serv-
ing a higher fraction of outdated content). We demonstrate,
however, that in some cases extending the freshness lifetime
can decrease coherence without a corresponding decrease in
miss-rate. We provide guidelines for more eﬀective choices
of the extension factor value (the factor of increase in the
lifetime).
Section 2 provides an overview of the HTTP freshness con-
trol mechanism. Our model, which includes the basic cache
conﬁgurations, is presented in Section 3. Section 4 discusses
our choice of speciﬁc distributions and explains the method-
ology and data used for our trace-based simulations. Our
results are presented in Sections 5–7, each containing a sep-
arate summary: Section 5 is concerned with the relation and
gaps between basic source-conﬁgurations. Section 6 explores
pre-term refreshes. Section 7 studies client-caches which use
longer lifetime durations than their source. We conclude in
Section 8.
2. HTTP FRESHNESS CONTROL
We provide a quick overview of the freshness control mech-
anism speciﬁed by HTTP and supported by compliant caches.
For further details see [12, 2, 22]. Caches compute for each
object a time-to-live (TTL) value during which it is con-
sidered fresh and beyond which it becomes stale. When a
request arrives for a stale object, the cache must validate
it before serving it, by communication either with an en-
tity with a fresh copy (such as another cache) or with the
origin server. The cachability and TTL computation are
performed using directives and values found in the object’s
HTTP response headers.
Upon receiving a request for an object a cache acts as fol-
lows. If the object is not in the cache, the cache forwards
the request to the origin server or another cache, and the
request constitutes a content miss. If the object is cached
then the cache checks whether its cached copy is fresh or
stale. If the cached copy is fresh then the cache sends it to
the client and the request constitutes a hit. If the cached
copy is stale the cache issues a conditional HTTP GET re-
quest to the origin server (or to another cache). If the source
response is Not-Modified then the cached object is sent to
the client and we consider the request as a freshness miss.
Otherwise, a new copy is obtained and sent to the client
and we consider the request as a content miss. We use the
general term miss for all requests that can not be processed
locally, that is, content or freshness misses. It is important
to note at this point that HTTP requests may be speciﬁed
with a no-cache header. When a cache received such a re-
quest it must forward it to the origin server even if it has a
fresh copy. The cache uses the response to replace or refresh
its older copy of the object.
HTTP/1.1 speciﬁcation considers every object as cachable
unless an explicit no-cache directive is present (there are
few exceptions, but they are not really used in practice).
The TTL calculation for a cachable object, as speciﬁed by
HTTP/1.1, compares the age of the object with its freshness
lifetime. If the age is smaller than the freshness lifetime the
object is considered fresh and otherwise it is considered stale.
The TTL is the freshness lifetime minus the age (or zero if
negative).
The age of an object is the diﬀerence between the current
time (according to the cache’s own clock) and the timestamp
speciﬁed by the object’s date response header (which indi-
cates when the response was generated at the origin). If an
age header is present, the age is taken to be the maximum
of the above and what is implied by the age header.
Freshness lifetime calculation is done as follows. First, if
a max-age directive is present, the value from this header
is taken to be the freshness lifetime. Otherwise, if expires
header (indicating absolute expiration time) is present, the
freshness lifetime is the diﬀerence between the time speciﬁed
by the expires header and the time speciﬁed by the date
header (zero if this diﬀerence is negative). Thus, the TTL is
the diﬀerence between the value of the expires header and
the current time (as speciﬁed by the cache’s clock). Other-
wise, no explicit freshness lifetime is provided by the origin
server and a heuristic is used: The freshness lifetime is as-
signed to be a fraction (HTTP/1.1 mentions 10% as an ex-
ample) of the time diﬀerence between the timestamp at the
date header and the time speciﬁed by the last-Modified
header, subject to a maximum allowed value (usually 24
hours, since HTTP/1.1 requires that the cache must attach
a warning if heuristic expiration is used and the object’s age
exceeds 24 hours).1
We distinguish between diﬀerent freshness control mech-
anisms by the type of the headers used for calculating the
freshness lifetime. There are basically four diﬀerent mech-
anisms: (1) Using max-age header. (2) Using an expires
header such that it is set in a relative way. I.e. the diﬀer-
ence between the values of expires and date is ﬁxed for the
object. (3) Using an expires header set to some absolute
point in the future. (4) Using a heuristic based on the date
and last-Modified headers.
We estimated the usage frequency of diﬀerent freshness
control mechanisms as follows. We downloaded a 6 day log
of the UC NLANR cache [16]. For a random sample of URLs
in the log we carried out a GET request and by analyzing
the headers in the response we deduced which freshness con-
trol mechanism is being used. For each URL we weighted
the freshness control mechanism it uses by the number of
requests to the URL in the log, and we summed the weights
for each freshness control mechanism. We found that 3.4%
of the requests were to objects with max-age speciﬁed, 1.4%
were to objects with no max-age header but with expires
set in a relative way (or to a time no greater than the one
speciﬁed by the date header), and 0.8% were with expires
speciﬁed in an absolute way. The vast majority, 70% of the
requests, did not have either max-age or expires speci-
ﬁed but had a last-Modified header which allowed for a
heuristic calculation of freshness lifetime. Other requests
either had neither of these 3 header ﬁelds, were explicit
noncachables (3%), or corresponded to objects with HTTP
response status codes other than 200 (On separate GET
requests), the most common of which was 302 (HTTP redi-
rect).
A CDF of TTL values of objects in the log weighted by
respective number of client requests [7] shows a dominant
(60%) TTL duration of 24 hours, which is mostly due to the
heuristic calculation (using last-Modified) with a maxi-
mum setting of 24 hours. About 25% of TTLs are 0 (due to
max-age or expires directive). These statistics also show
that most TTLs are in fact ﬁxed , where the freshness life-
time is the same for subsequent checks with the origin.
Figure 1 plots the TTL of an object with max-age or “rel-
ative” expires freshness control mechanism when fetched
either from an origin server (the ﬂat line) or from a top-
level cache. The illustrated top-level cache refreshes its copy
only when the copy is stale and the ﬁgure reﬂects three re-
freshes (where the TTL goes up to the max-age value). The
zero-TTL region corresponds to a time period for which the
cached copy is stale and no requests are received.
A Pre-term refresh by a cache is a refresh of a non-expired
copy of an object. A pre-term refresh can occur when the
cache receives a client request with a no-cache request header.
With pre-term refreshes, the TTL of an object as in Figure 1
would look as illustrated in Figure 2.
1Squid calls these two constants CONF PERCENT and
CONF MAX [22]. The TTL is min{CONF PERCENT ∗
(date − (last-Modified)), CONF MAX}.
from origin
from cache
max_age
L
T
T
time
Figure 1: TTL of an object with max-age re-
sponse header (i) when fetched from the origin and
(ii) when fetched from a cache.
from origin
from cache
max_age
L
T
T
no−cache requests
time
Figure 2: TTL of an object with max-age re-
sponse header (i) when fetched from the origin and
(ii) when fetched from a cache. Two client requests
with a no-cache directive are illustrated.
3. MODELING BASIC TYPES OF SOURCES
We present a model for the distribution of copies of ob-
jects. Our setup is a collection of distributed servers that
cache, request from each other, and distribute copies of
an object. We distinguish between origin (authoritative)
servers, that originate, continuously host the object, and
may modify it over time, and caches (replicating servers)
that may hold cached copies of the object. Following the
HTTP protocol our model assumes a TTL based weak con-
sistency mechanism. Each copy has a freshness lifetime du-
ration which is set when the copy originates (is obtained
from an authoritative server). The copy can be further dis-
tributed and used only for the length of its lifetime duration.
Much of our analysis focuses on values that are ﬁxed, that
is, each time a copy originates its freshness lifetime is set to
the same value which we denote by T . The age of a copy
is the elapsed time since it originated. The TTL of a copy
equals the lifetime T minus its age. If the age is larger than
T , the copy is stale. Otherwise, the copy is fresh. Thus, a
copy obtained from an origin server has initial age of zero
and TTL of T whereas a copy obtained from a cache would
generally have a positive age. A cache can distribute its
copy only if it is fresh. Otherwise, it may attempt to obtain
a fresh copy from an authoritative server or another cache.
Thus, two caches can have a source-client relationship.
In the Web context, authoritative server can be in prin-
ciple any server that returns copies of zero age (TTL that
equals the freshness lifetime). This includes origin servers,
mirrors, and sometimes CDN servers.
A client-cache can ﬁll requests for objects for which it
has stale or missing copies by contacting another cache, a
selected cache from a set, or an origin server. In practice, the
destination may be forced on a cache through a transparent
conﬁguration or may be selectable. We use the term source
for the destination entity to which the client cache sends
requests. We consider several types of sources and look at
how the type of the source aﬀects the miss rate at the client
cache. The base line for comparison would be the miss rate
when the source is authoritative. Let ms be the miss rate of
the client cache when it works through a source s, and ma
the miss rate of the client cache through an authoritative
source. The age penalty of source s is deﬁned as the relative
increase in miss rate with respect to the authoritative source,
i.e. the age penalty of source s is equal to (ms − ma)/ma.
Our modeled sources are such that objects remain cached
until they expire. Hence, the behavior of the system on
diﬀerent objects is independent and it is suﬃcient to analyze
requests for each object separately. Since we focus on age-
induced eﬀects, our modeled sources always have a fresh
cached copy of the object. Cached copies, however, may be
aged.
We say that a client-cache is synchronized with a source
if whenever the client cache contains a copy of the object
which expires at some time t, then requests directed to the
source at times t + ∆ (∆ > 0) obtain an object with age
at most ∆. By deﬁnition, a client-cache is always synchro-
nized with an authoritative source. Synchronization does
not generally occur with sources consisting of caches but it
does hold when the source is a single cache which never per-
forms pre-term refreshes. As we shall see, synchronization
helps performance.
3.1 Demonstrating the effects of age
We motivate some issues through an illustrative example.
Consider a proxy server, low-cache, a heavily used reverse
proxy cache, top-cache, and an origin server, www.s.com,
containing the object www.s.com/obj1. We assume that
if low-cache fetches www.s.com/obj1 from www.s.com then
the TTL of obj1 is T . If low-cache fetches the object from
top-cache we assume that the age of the object is the time
passed since it was last fetched by top-cache (Here we ne-
glect the transmission time from top-cache to low-cache.)
As mentioned before, we assume that obj1 is requested very
frequently at top-cache so top-cache always has a fresh
copy of it. We also assume that obj1 is never evicted from
low-cache.
Consider the case where obj1 is requested at low-cache
with inter-request times of T /2. If directing requests to the
origin server www.s.com, low-cache would incur miss rate
of 1/3 (every third request would be a miss). If all requests
are directed to top-cache then the miss rate is 1/2. (Except
for the case when top-cache happens to be in-sync with the
stream of requests at low-cache and refreshes obj1 exactly
every third request from low-cache. We assume that this
case occurs with probability 0.) Hence, the age penalty is
1/2, or in other words, if low-cache always fetches obj1
from top-cache there is a 50% increase in misses compare
to the case where low-cache communicates directly with
www.s.com. Denote the estimated response time of the par-
ent cache by dc and that of the origin server by do (we
assume dc < d0). If our performance metric was the sum of
induced latencies, then it is worthwhile directing requests of
www.s.com/obj1 to top-cache only if 1.5dc < do (that is, if