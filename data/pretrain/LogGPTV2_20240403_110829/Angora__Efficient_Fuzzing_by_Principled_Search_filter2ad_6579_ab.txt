// some code
}
char buf[1024];
int i = 0, j = 0;
if(fread(buf, sizeof(char), 1024, fp)
 b
a >= b
a == b
a! = b
f
f = a − b
f = a − b
f = b − a
f = b − a
f = abs(a − b)
f = −abs(a − b)
Constraint
f < 0
f <= 0
f < 0
f <= 0
f == 0
f < 0
3.4. Search algorithm based on gradient descent
Byte-level taint tracking discovers which byte offsets
in the input ﬂow into a conditional statement. But how
to mutate the input to run the unexplored branch of the
statement? Most fuzzers mutate the input randomly or using
crude heuristics, but those strategies are unlikely to ﬁnd
an appropriate input value quickly. By contrast, we view
this as a search problem and take advantage of search
algorithms in machine learning. We used gradient descent in
our implementation, but other search algorithms might also
work.
In this approach, we view the predicate for executing a
branch as a constraint on a blackbox function f (x), where
x is a vector of the values in the input that ﬂow into the
predicate, and f () captures the computation on the path from
the start of the program to this predicate. There are three
types of constraints on f (x):
1) f (x) < 0.
2) f (x) <= 0.
3) f (x) == 0.
the predicate of a conditional
Table 2 shows that we can transform all forms of
comparison into the above three types of constraints.
If
statement contains
logical operators && or ||, Angora splits the state-
ment
into multiple conditional statements. For exam-
ple, it splits if (a && b) { s } else { t } into
if (a) { if (b) { s } else { t } }.
Algorithm 5 shows the search algorithm. Starting from
an initial x0, ﬁnd x such that f (x) satisﬁes the constraint.
Note that to satisfy each type of constraint, we need to min-
imize f (x), and we use gradient descent for this purpose.
Gradient descent ﬁnds a minimum of a function f (x).
The method is iterative. Each iteration starts from an x,
716
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:42 UTC from IEEE Xplore.  Restrictions apply. 
computes ∇xf (x) (the gradient of f (x) at x), and updates
x as x − ∇xf (x) where  is the learning rate.
When training neural networks, researchers use gradient
descent to ﬁnd a set of weights that minimize the training
error. However, gradient descent has the problem that it
sometimes may be stuck in a local minimum that is not
a global minimum. Fortunately, this is often not a problem
in fuzzing, because we only need to ﬁnd an input x that is
good enough instead of a globally optimal x. For example,
if the constraint is f (x) < 0, then we just need to ﬁnd an x
where f (x) < 0 instead of where f (x) is a global minimum.
However, we face unique challenges when applying gra-
dient descent to fuzzing. Gradient descent requires comput-
ing the gradient ∇xf (x). In neural networks, we can write
∇xf (x) in an analytic form. However, in fuzzing, we have
no analytic form of f (x). Second, in neural networks, f (x)
is a continuous function because x contains the weights
of the network, but in fuzzing f (x) is usually a discrete
function. This is because most variables in a typical program
are discrete, so most elements in x are discrete.
δ
∂xi =
f (x+δvi)−f (x)
We solve these problems using numerical approxima-