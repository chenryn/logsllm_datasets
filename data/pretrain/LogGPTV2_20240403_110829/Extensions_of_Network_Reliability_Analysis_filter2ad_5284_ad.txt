we want
uncertainty contributes the most
to the uncertainty in the
system reliability, where uncertainty is measured as the
standard deviation relative to the mean, also known as the
coefﬁcient of variation, and (ii) which component, if we can
make it reliable, contributes the most to the improvement in
the expected system reliability. These two questions can be
formally expressed as ﬁnding i1 and i2 such that
Var(Y |Xi = EXi),
E(Y |Xi = 1).
i1 = argmin
i=1,2,...,9
i2 = argmax
i=1,2,...,9
By sampling, we obtain i1 = i2 = 8, which again points
to the software library Lib. The normalized histograms of
Y |X8 = EX8 and Y |EX8 = 1 are shown in Figure 5.
We can see that Y |X8 = EX8 has a narrower peaked shape
than Y , which indicates the reduction in uncertainty. On the
other hand, although Y |EX8 = 1 has higher expected value
than Y , it also has a wider peaked shape. In other words, by
making Lib reliable, we increase not only the expected system
reliability but also, inadvertently, the uncertainty associated
95
Fig. 6: California gas distribution network with earthquake
epicenter (ﬁgure reprinted from [22]).
with it. Figure 5 also shows that the cdfs of the approximating
Betas (black curves) computed using MLE match well with
the histograms.
B. California gas distribution network
1) Model description: In the second example, we study the
reliability of the California gas distribution network subjected
to pipeline break due to earthquakes. This example is adopted
from [22] and reprinted in Figure 6. The gas distribution
network is modeled as an undirected graph where each edge
represents a pipeline and each vertex a substation. We are
interested in studying the reliability of the network, deﬁned
as the probability that there exists a path between the source
vertex (black square) and the destination vertex (black circle),
subjected to an earthquake whose epicenter is marked by
the red star in the ﬁgure. On the event of an earthquake,
we assume that edges fail independently of the others while
nodes do not fail. Although the ﬁrst assumption might not
be realistic, this example serves better as a demonstration
of Hypothesis 1 on a Beta UG of nontrivial size. Hence,
we model the edge failure probabilities using mutually inde-
pendent Beta random variables, whose parameters depend on
the earthquake’s magnitude, propagation model, and fragility
model of the pipelines. Using a combination of optimization
techniques, we are able to obtain the reliability polynomial
of the gas network and compute the exact system reliability
given a probability assignment vector. One effective technique
is to look for subgraphs that can be equivalently replaced by
uncertain edges. Another trick is to use the recursive form in
Equation 8 and store the reliability polynomial in a binary tree
data structure, but (i) prune the tree at the earliest point when
there is no longer a path between the source and the destination
and (ii) propagate the tree only to a certain depth, below which
the polynomials can be generated using Algorithm 1.
2) Numerical results: We parameterize the Beta random
variables using data from [22], where the expected failure
probability of each edge is computed from the model with
respect to a 6.5 degree earthquake. Given the parameters, we
apply the two mentioned methods to obtain two estimates
of FY . Then, we measure the KS distance between each
estimate and the empirical cdf FYk. We repeat this process
(cid:2) and report the results in
200 times for each choice of k
(cid:2) ∈ {20, 100, 500, 1000, 2000}. Overall, the Beta
Figure 8 for k
approximation method yields signiﬁcantly better estimates
(cid:2).
than the empirical cdf method for every given choice of k
= 100 on the left, to get a
Looking at the box plot for k
distribution on the right with KS distance as least as small we
= 1000 samples. The ten-fold reduction in the
need over k
number of samples is particularly useful when analyzing large
graphs, since generating one sample is equivalent to solving
the reliability of a Bernoulli UG, a problem known to be
computationally hard. This result is but a single instance, but
does illustrate the technique’s promise.
(cid:2)
(cid:2)
VIII. RELATED WORK
Uncertain graphs, also known as probabilistic graphs, ex-
tend the deﬁnition of deterministic graphs by allowing edges
to exist with certain probabilities. While the term uncertain
graph mainly resides in the database community, the formalism
was developed in the 50’s by Moore and Shannon [15] in
their study of reliable circuits. As a generic mathematical
framework, UGs have been successfully applied to studying
problems across different domains, for example, interaction be-
tween proteins using noisy and error-prone experimental data
[1], optimal reachability in intermittently connected network
with known routing algorithm [7], information propagation in
social networks [13], network security under lateral movement
attacks [19], and many others.
Properties of UGs have been widely studied under the
term network reliability [4]. However, due to the combinatorial
nature of UGs, most network reliability problems are compu-
tationally hard. For example, counting the number of possible
worlds of an UG in which vertex s reaches vertex t is #P-
complete [23]. Potamias et. al. [21] derived sampling-based
approximation algorithms for the k-nearest neighbor problem
of UGs. Jin et. al. [11] formulated the distance-constraint
reachability problem and introduced efﬁcient recursive sam-
pling schemes to estimate the reachability of large UGs.
More recently, [14] proposed recursive stratiﬁed sampling-
based estimators to reduce the variance of standard Monte
Carlo approach in estimating UG properties.
The majority of work in the literature on UGs assumes that
edge existence (or failure) are uncorrelated. In contrast, [21]
relaxed this assumption by deﬁning the conditional probability
of an edge given the existence of others. Recently, [13]
proposed to extend UG by deﬁning the conditional probability
of an edge given the outcome of a predeﬁned set of events. Our
work is motivated by the same need for capturing correlation
but deviates in the way correlation is being constructed. We
describe the joint distribution of edges using explicit Boolean
expressions of mutually independent random variables, a con-
cept similar to probabilistic logic [20]. Furthermore, our work
is also motivated by the need to express uncertainty in the edge
existence probability, and be able to observe the impact of the
uncertainty on the overall reliability of the graphs. To the best
of our knowledge, this aspect is novel.
There are similarities between our model and Bayesian
networks; both are concerned with ﬁnding a distribution at
Fig. 7: (top) Histogram of the reliability of the California
gas distribution network subjected to a 6.5 degree earthquake.
(bottom) The conﬁdence band for the distance between FY
and FX∗ in Equation 22 evaluated at 95th percentile.
Fig. 8: Performance comparison between Beta approximation
method and empirical cdf method using small numbers of
samples.
collect k = 106 random samples of the reliability polynomial
Y and use this large collection of samples to evaluate Equation
22. The normalized histogram of Y and the pdf of the
approximating Beta computed using MLE is shown in the
top sub-ﬁgure of Figure 7, while the difference between the
empirical cdf of Y and the cdf of the approximating Beta,
−F ˆXk, is shown in the bottom sub-ﬁgure. Using
denoted as FYk
bootstrap resampling, the 90th, 95th, and 99th percentile of the
conﬁdence band Jk in Equation 22 is computed as Jk(0.9) =
0.0092, Jk(0.95) = 0.0096, and Jk(0.99) = 0.0107. Only the
conﬁdence band at 95th percentile is plotted in the bottom sub-
ﬁgure. Given 106 samples and with 95% conﬁdence, the KS
distance between the reliability polynomial Y and its closest
Beta approximation X
∗ is less than 0.02.
We have not yet spoken to the computational advantage of
Hypothesis 1. Given a collection of samples, we now have
two options, either (i) constructing the empirical reliability
distribution without distributional assumption or (ii) assuming
the reliability distribution is approximately Beta and using
the samples to estimate the parameters of the approximating
Beta, similar to what we have done to obtain the black
curves in Figure 5 and the top sub-ﬁgure of Figure 7. To
determine whether the latter method offers beneﬁt, we utilize
the data generated from this case study. Speciﬁcally, we ﬁrst
(cid:2) samples from the k = 106 samples and
randomly select k
96
some node in the network. Bayesian networks are more limited
in their structural assumptions (directed edges, no cycles),
and take on the direct computation of the resulting distribu-
tion, which in the general case at scale is computationally
intractable. Our model does not have those restrictions, and
we are addressing the scale problem through Monte Carlo
estimation of distributional parameters rather than Monte Carlo
estimation of the distribution. Even though our technique as
presented involves an analytic solution which has its own
scaling issues, we could ﬁnesse this by using Monte Carlo in
an inner loop to estimate reliability distributions of seriously
large graphs.
IX. CONCLUSION
Parameter uncertainty and correlation between random
events are important characteristics of probabilistic models that
emerges from practical situations. In this paper, we propose an
extension to [19] by replacing Bernoulli random variables with
Betas to capture the uncertainty in failure probabilities. We
derive several properties of the reliability polynomials of Beta
UGs as multivariate polynomials of Betas. Using numerical
results from Monte Carlo simulation of an approximation
scheme and from two case studies, we show that the reliability
distributions of monotone Beta UGs can be well-approximated
by Beta distributions. Using data from one case study, we
further demonstrate that the Beta approximation method yields
better estimate of the reliability distribution than the traditional
method of constructing the empirical probability distribution.
While the result is encouraging, there are many other questions
about the model that we have not answered. For example,
can we analytically derive the goodness of approximation for
some special case, say, when the Beta UG is series-parallel
or when the Betas are identically distributed? How does the
goodness of approximation relate to the structure of the graph,
the assignment function, and the parameters of the Betas?
How to model correlation using explicit Boolean expressions
of Betas when only implicit information such as the covariance
matrix of edge failures is available? We hope to address some
of those questions in subsequent studies.
ACKNOWLEDGEMENTS
We thank the anonymous reviewers and Susanna Donatelli
for their helpful comments and suggestions. This material is
based upon work supported by the Maryland Procurement
Ofﬁce under Contract No. H98230-18-D-0007. Any opinions,
ﬁndings and conclusions or recommendations expressed in this
material are those of the authors and do not necessarily reﬂect
the views of the Maryland Procurement Ofﬁce.
APPENDIX A
SELECTED PROPERTIES OF BETA DISTRIBUTIONS
Let X ∼ Beta(a, b) where a, b > 0. The pdf of X is
fX (u) =
B(a, b)
a−1
u
(1 − u)
b−1
for u ∈ [0, 1] where B(a, b) is the Beta function deﬁned as
1
1(cid:11)
B(a, b) =
0
a−1
(1 − u)
b−1
u
du.
97
A special case is Beta(1, 1), which is also known as the
Uniform distribution U nif orm(0, 1). The k-th raw moment
of X is
k(cid:2)
k
EX
=
a + i
.
a + b + i
i=1
In particular, the mean and variance of X is given by
EX =
a
a + b
, VarX =
ab
(a + b)2(a + b + 1)
.
While the expected value of a Beta is determined by the
ratio between its a and b, the variance is determined by their
magnitudes – the larger a and b are, the smaller the variance
becomes. For a complete list of properties, please refer to [8].
APPENDIX B
KULLBACK-LEIBLER DIVERGENCE
(cid:11)
If we deﬁne the Kullback-Leibler (KL) divergence as a
measure of closeness between pdfs
DKL(Y ||X) =
fY (u) log
R
fY (u)
fX (u)
du,
(21)
∗
∗
, b
where fX and fY are the pdfs of X and Y , and let
∗ ∼ Beta(a
) be the Beta random variable that
X
minimizes
the KL divergence from Y ,
=
argmina,b>0 DKL(Y ||X),
then Hypothesis 1 implies that
there exists a small  such that DKL(Y ||X
) ≤ . To estimate
∗
∗, we can apply the maximum likelihood estimation
∗ and b
a
(MLE) method for Beta distributions using samples of Y .
(cid:13)
Speciﬁcally, given k samples y1:k = (y1, y2, . . . , yk) of Y ,
the (quasi) log-likelihood function is deﬁned as
i.e. a
∗
, b
∗
L(y1:k|a, b) =
log fX (yi)
= − log B(a, b)+
k(cid:6)
log(1 − yi),
b − 1
k
i=1
log(yi) +
i=1
(cid:12)
k(cid:6)
k(cid:6)
i=1
1
k
a − 1
k
where B is the Beta function (Appendix A). The MLE method
simply selects a, b as the maximizer of the log-likelihood
function, i.e. ˆak, ˆbk = argmaxa,b>0 L(y1:k|a, b).
Classical results have drawn several connections between
MLE and KL divergence. Deﬁne Yk as a random variable
whose cdf is the empirical cdf of y1:k. It was shown that MLE
minimizes the KL divergence from Yk [17]. Moreover, [24]
showed that even for the case of unknown or misspeciﬁed
models, i.e. Y may or may not belong to the family of Beta
random variables, under some conditions MLE is proven to be
consistent, meaning the estimator converges to the minimizer
of the KL divergence from the data generating distribution and
with probability one. In our case, those conditions are met,
therefore (ˆak, ˆbk) → (a
∗