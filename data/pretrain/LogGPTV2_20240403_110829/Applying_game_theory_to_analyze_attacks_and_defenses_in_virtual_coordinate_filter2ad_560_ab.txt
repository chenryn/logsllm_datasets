a small error
a small error
• Deﬂation: malicious nodes report a small coordinate and
• Oscillation: malicious nodes report a random coordinate,
a small error, and inﬂuence the honest nodes to measure
a large RTT by delaying the response.
IV. DEFENSE STRATEGIES
The defense strategies we consider are based on outlier
detection. We selected outlier detection because previous
work showed experimentally that outlier detection can be
an effective mechanism in improving the accuracy of virtual
coordinate systems in the presence of attacks under the restric-
tive assumption that an attacker is unaware of the associated
defense mechanisms.
An important conﬁguration parameter for outlier detection is
the threshold that is used to decide if a data point is accepted
by the system or is suspected of coming from a malicious
node. We ﬁrst overview spatial and temporal outlier detection
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:28:05 UTC from IEEE Xplore.  Restrictions apply. 
135defenses that use a ﬁxed threshold, then show how control
theory techniques can be leveraged to make the threshold
adaptive and exemplify such a strategy for spatial outlier
detection.
A. Outlier Detection
Outlier detection can be used to identify malicious behavior
and take action to mitigate its effects. Instead of allowing
malicious coordinate mappings to occur and then trying to
detect them, statistical outlier detection reduces the likelihood
of a node computing incorrect coordinates by ﬁltering out
malicious updates. Each node independently performs outlier
detection before updating its coordinates in order to identify
and ﬁlter out outliers in the received metrics. As the evidence
of malicious activity is distributed across space and time we
consider both spatial and temporal outlier detection techniques.
Spatial outlier detection identiﬁes observations which are
inconsistent with their surrounding neighbors, forcing nodes to
report metrics consistent with what other peers are reporting.
When a node queries a peer, it receives an observation tuple
(as seen in Algorithm 1). Upon receiving the tuple, the node
records the response and tracks the most recent u updates
in a queue. The size of the history queue, u, is equal to
the size of the reference set which allows the queue, on
average, to contain one entry from each reference set nodes.
Once the tuple has been received, the node ﬁrst computes the
centroid of the data set consisting of observation tuples from
the stored u updates. The node then computes the Mahalanobis
distance [10] between the received observation tuple and the
centroid and accepts the update if it is less than a designated
spatial outlier threshold. We note that this technique is an
instance of spatial outlier detection since it examines metrics
across various system nodes and not time.
Temporal outlier detection identiﬁes inconsistencies in the
metrics over time, forcing a node to report metrics consistent
with what
it has reported in the past. A node tracks the
temporal centroid of the observation tuple from each node
in its peer set and the change in the reported coordinates
using incremental learning. We assume each of the reported
metrics is statistically independent, necessitating the storage of
just the mean, standard deviation, and sample count computed
from the received query responses over time. We note that
the assumption of statistical independence is reasonable, even
though nodes may collude, as the temporal outlier detection is
computed individually for each node. Once a query response
is received from a remote node, the node performing the
detection compares the received observation tuple with the
corresponding temporal centroid using the “simpliﬁed Maha-
lanobis distance” presented by Wang and Stolfo [10] and based
on a temporal threshold. The tuple is accepted if the distance
to the temporal centroid is below the threshold.
Finally, spatial-temporal outlier detection takes advantage
of both techniques by combing them using a codebook tech-
nique similar to that by Jiang and Cybenko [11]. As a node
receives observation tuples, it checks each one to ensure that
the tuple is not a spatial or temporal outlier. If the tuple is
Fig. 1.
Block diagram describing how we integrate control theory. For
example, if updates that increase the system prediction error bypass the outlier
detection then the spatial threshold is lowered.
found to be an outlier, the update is discarded. Otherwise, it
is used to update the receiver node’s coordinates. For further
details on the detection techniques, we refer the reader to [6].
B. Adaptive Threshold Selection
Many outlier detection schemes, including the ones pro-
posed in [6] use a ﬁxed threshold usually determined ex-
perimentally. Such an approach is inﬂexible, prone to errors,
and may be exploited by an adversary to remain undetected.
Below, we show how by leveraging control theory [12, 13]
we design an adaptive threshold technique to improve the
threshold selection.
Figure 1 shows how the adaptive threshold selection is
integrated with the outlier detection mechanism. A feedback
control loop is regularly updating the spatial threshold with
the objective to tighten the threshold and adapt to attacks. The
update of the threshold is based on the observation that more
severe attacks (as per the nature of the attack and percentage of
malicious nodes) will result in higher differences between the
estimated RTT (predicted by the coordinates resulted from the
virtual coordinate system) and the actual RTT. Speciﬁcally, at
time n, the new threshold Tn is updated based on the threshold
at time n − 1, Tn−1, and the difference between the current
prediction error Errorattack(n) and an ideal value for the
prediction error Errorno attack(n) as follows:
Tn = Tn−1 − c
(Errorattack(n) − Errorno attack(n))
RT TEst(n)
(1)
where c is a constant
to deﬁne the importance of the
prediction error Errorattack(n) and RT TEst(n) is the current
estimated RTT. The prediction error Errorattack(n) is based
on all the prediction errors calculated during each update
of each single node, one can either take an averaged value
or percentile values. The average value is more likely to be
affected by potential malicious values that bypassed the outlier
detection. Thus, different defense strategies in the case of the
adaptive threshold selection involve using different percentile
values in the prediction error.
We take into account that the prediction error varies over
time, as before the system stabilizes nodes have high predic-
tion error and must update their coordinates by large amounts.
However, after some iterations the nodes converge to their
correct coordinates which results in low prediction errors. To
deﬁne an independent evaluation of the ideal value, we ran
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:28:05 UTC from IEEE Xplore.  Restrictions apply. 
136several experimental runs without the presence of attacks and
without outlier detection.
In summary, the effectiveness of an outlier detection tech-
nique that uses the adaptive threshold selection depends on
the value of c, which deﬁnes the importance of the prediction
error, and the percentile values on which the prediction error
used in updating the threshold is computed.
V. GAME THEORETICAL FRAMEWORK
We use techniques from game theory [14] to analyze the
behavior of the different
types of defense mechanisms in
virtual coordinate systems by investigating strategic choices
made by the players. This allows us to identify the best attack
strategies and corresponding defense techniques. The game
model considers two players, the defender i and the attacker
−i, and is a silent game, assuming that the players do not have
any knowledge about the other player’s history of actions.
We consider that an attacker can perform three different
types of attacks {deﬂation; inﬂation; oscillation} described in
Section III-B and vary the percentage of malicious nodes to
consist of 10%, 20%, or 30% of the nodes in the network
so that the set of actions A for the attacker consists of nine
attack strategies in total. In order to counteract the attacker,
we deﬁne the set of actions D for the defender as follows: the
defender has the possibility to use one of the following defense
mechanisms: spatial, temporal, and spatial-temporal outlier
detection using a ﬁxed threshold. The defender can also use
the adaptive threshold variant of outlier detection adapting the
closed-loop for the threshold by varying the constant c {0.04;
0.06; 0.08; 0.1} and the percentile {25th; 50th; 75th} of the
system prediction error. We exemplify the adaptive threshold
selection strategy only for the spatial outlier detection.
For every chosen action, each of the players receives a
payoff, the attacker receives a payoff that measures the ef-
fectiveness of the attack, while the defender receives a payoff
that measures the effectiveness of the defense. We ﬁrst adopt
a solution concept from game theory and deﬁne our payoff
functions for both players, the defender and the attacker. We
then evaluate the payoffs and identify the best strategies for
each player.
A. Solution Concept
Many different game theoretical solution concepts exist,
with the Nash Equilibrium [15] being one of the best known. It
introduces and deﬁnes methods for the mathematical analysis
of non-cooperative games in which the players, the defender
and the attacker, do not communicate or cooperate. The Nash
equilibrium deﬁnes the optimal strategic choices for all the
players, given that no player will diverge from the equilibrium
point as they cannot gain greater payoffs with any other
strategy; this behavior is known as rational acting. In a game
consisting of a set of n players, there exists for each player i
an associated ﬁnite set of pure strategies as well as a payoff
function Pi.
Calculating the Nash equilibrium results in either a pure
strategy, where it is deﬁned that a player, attacker or defender,
: D → [0, 1] and S−i
plays constantly the same action out of the corresponding
action set (A or D), or a mixed strategy Si. A mixed strategy
is a probabilistic distribution over the corresponding pure
: A → [0, 1]. The
strategies, Si
player will randomly play each strategy while each strategy
is selected with the associated probability. The mixed strategy
proﬁle Si is a Nash equilibrium if for each player i there is no
other strategy proﬁle S(cid:48)
i that will lead to a higher gain with
respect to the strategy proﬁle S−i applied by the opponent
−i, meaning that for player i there is no average payoff
Qi greater than the one for the strategy proﬁles Si, S−i :
Qi(Si, S−i) ≥ Qi(S(cid:48)
i, S−i) where
n(cid:88)
k(cid:88)
Qi(Si, S−i) =
Si(dq)
S−i(ap) ∗ Mi(dq, ap)
q=1
p=1
In this equation Mi represents the payoff matrix of player i
and Mi(dq, ap) is the payoff for player i while choosing dq
as action while the opponent plays ap.
The regular quantal response equilibrium (QRE) [16] is
a solution concept that generalizes the Nash equilibrium by
introducing an error parameter to the payoff function. This is
motivated by the fact that payoff functions may be erroneous
and one can not have total certainty about the payoff value.
In this manner, the regular QRE provides an equilibrium with
bounded rationality in contrast to the Nash equilibrium which
deﬁnes all the players to be completely rational.
The error parameter λ, also called the rationality parameter,
is varied until the regular QRE converges to the Nash equi-
librium. Rationality in this sense means that no player has a
motivation to diverge from the Nash Equilibrium as there is no
other strategy where one can gain more than the ones speciﬁed
in the resulting strategy proﬁle of the Nash Equilibrium. On the
opposite, irrationality means that even though the attacker can
not gain greater payoff, he will chose another strategy than the
one deﬁned by the Nash Equilibrium. When λ = 0, the player
is completely irrational, in this case he could, for instance,
chose the strategy randomly and when λ → ∞, the player
becomes perfectly rational and follows the Nash equilibrium.
We calculate the QRE by using the following equation which
deﬁnes the probability of player i to choose strategy dq out of
action set D:
Sidq =
(cid:80)
exp λ × Ui(dq)(S−i)
expλ×Ui(ap)(S−i)
ap
with a probability distribution S−i: Ui(dq) =(cid:80)k
where Ui(dq)(S−i) describes the expected utility for player
i using strategy dq while considering other players to play
p=1 S−i(ap) ∗
We use the QRE to quantify how irrational a player can be
M(dq, ap)
while still maintaining the same equilibrium proﬁles.
B. Payoff Functions
The payoff functions have to reﬂect
the gain a player
receives when playing one strategy. The deﬁnition of the
payoff depends on the goal a player wants to achieve during
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:28:05 UTC from IEEE Xplore.  Restrictions apply. 
137the game. As the attacker and the defender are opponents, their
respective payoffs will reﬂect different goals. The attacker
wants to disturb the network by distorting the coordinate
space. The larger the impact on the coordinate space, the
larger the gain for the attacker. Conversely, the defender wants
the coordinate space to behave correctly and provide correct
latency estimates. Thus, the smaller the impact of the attacks
on the coordinate space, the larger the gain for the defender.
A different goal for the attacker is to remain undetected as
otherwise the attack is ignored due to the outlier detection.
Another goal for the defender is that the coordinate space
converges to a stable state and thus wants the error values to
be low.
We consider two scenarios in our analysis. The ﬁrst scenario
considers the different outlier detection defenses when using a
ﬁxed threshold. The second scenario focuses on spatial outlier
detection and analyses the different parameters that can be
chosen by the defender in the adaptive threshold mechanism.
Analysis of outlier detection mechanisms with ﬁxed
thresholds. We use the system prediction error (Errorpred)
and the relative error (Errorrel) as the basis for the following
payoff functions:
Prediction error based payoffs:
Pattacker = Errorpred
% attackers
, Pdef ender = −Errorpred
Intuitively, Pattacker describes the gain of the attacker in direct
relation to the prediction error. If the prediction error increases,
the payoff increases as well. We include the percentage of
malicious nodes in the payoff function to integrate the notion
of cost for the attackers since they need to invest time and
effort in becoming part of the system to conduct the attacks.
Pdef ender describes the gain of the defender in inverse relation
to the prediction error. If the prediction error increases, the
gain of the defender will decrease. We do not integrate into
the defender payoff function the notion of cost in terms of
number of defender nodes, since the nodes are already part of
the system.
Relative error based payoffs:
Pattacker = Errorrel
% attackers
, Pdef ender =
1
Errorrel
For the attacker, Pattacker describes the gain in direct relation
to the relative error. Just as in the payoff deﬁnition for the
prediction error, we include the notion of cost for the attackers
by dividing the error by the percentage of malicious nodes in
the system. For the defender, Pdef ender describes the gain in
inverse relation to the relative error.
Furthermore, we take into account different percentiles of