... ----  ... -------
... 10m   ... New size: 6; reason: Ingress metric http_req_per_second_per_replica above target
... 7m10s ... New size: 9; reason: Ingress metric http_req_per_second_per_replica above target
... 2m9s  ... New size: 3; reason: All metrics below target
```
输出中最有趣的部分是事件部分。我们将关注`Age`和`Message`字段。请记住，如果当前值高于目标值，则每三分钟执行一次放大事件，而每五分钟执行一次缩小迭代。
就我而言，三分钟后，住房管理局再次调整了部署规模。复制品的数量从六个激增到九个。由于适配器使用的表达式使用五分钟速率，因此一些请求进入了第二次 HPA 迭代。即使在我们停止发送请求后，扩大规模似乎也不是一个好主意(事实并非如此)，但在“现实世界”中，这种情况不应该发生，因为流量比我们生成的要多得多，我们不会将`50m`(每秒 0.2 个请求)作为目标。
上次扩展事件后五分钟，`current`值为`0`，HPA 将部署缩减至最小副本数量(`3`)。不再有交通堵塞，我们又回到了起点。
我们确认普罗米修斯的指标，由普罗米修斯适配器获取，并转换成库贝伦特斯的自定义指标，可以在高性能计算中使用。到目前为止，我们使用了普罗米修斯通过出口商提取的指标(`nginx_ingress_controller_requests`)。考虑到适配器从普罗米修斯那里获取度量，它们是如何到达那里的并不重要。尽管如此，我们将确认也可以使用仪表化度量。这将给我们一个机会巩固到目前为止所学的知识，同时，也许还会学到一些新的技巧。
```
 1  cat mon/prom-adapter-values-svc.yml
```
输出是另一组普罗米修斯适配器图表值。
```
image:
  tag: v0.5.0
metricsRelistInterval: 90s
prometheus:
  url: http://prometheus-server.metrics.svc
  port: 80
rules:
  default: false
  custom:
  - seriesQuery: 'http_server_resp_time_count{kubernetes_namespace!="",kubernetes_name!=""}'
    resources:
      overrides:
        kubernetes_namespace: {resource: "namespace"}
        kubernetes_name: {resource: "service"}
    name:
      matches: "^(.*)server_resp_time_count"
      as: "${1}req_per_second_per_replica"
    metricsQuery: 'sum(rate(>{>}[5m])) by (>) / count(>{>}) by (>)'
  - seriesQuery: 'nginx_ingress_controller_requests'
    resources:
      overrides:
        namespace: {resource: "namespace"}
        ingress: {resource: "ingress"}
    name:
      as: "http_req_per_second_per_replica"
    metricsQuery: 'sum(rate(>{>}[5m])) by (>) / sum(label_join(kube_deployment_status_replicas, "ingress", ",", "deployment")) by (>)'
```
这一次，我们结合了包含不同度量系列的规则。第一个规则基于起源于`go-demo-5`的`http_server_resp_time_count`仪表化度量。我们在[第 4 章](4.html)、*调试通过指标和警报发现的问题*中使用了它，它的定义没有什么特别之处。它遵循与我们之前使用的规则相同的逻辑。第二个规则是我们以前使用的一个规则的副本。
这些规则的有趣之处在于，有两个完全不同的查询会产生不同的结果。但是，这两种情况下的名称是相同的(`http_req_per_second_per_replica`)。
“等一下”，你可能会说。名字不一样。一个叫`${1}req_per_second_per_replica`，一个叫`http_req_per_second_per_replica`。虽然这是真的，但最终名称(不包括资源类型)确实是一样的。我想让你知道你可以用正则表达式来命名。在第一个规则中，名称由`matches`和`as`条目组成。`matches`条目的`(.*)`部分成为第一个变量(可以有其他变量)，随后用作`as`值(`${1}`)的一部分。由于度量是`http_server_resp_time_count`，它将从`^(.*)server_resp_time_count`中提取`http_`，在下一行中，将使用`http_`代替`${1}`。最后的结果是`http_req_per_second_per_replica`，和第二条规则的名字一样。
既然我们已经确定这两个规则将提供同名的自定义指标，我们可能会认为这会导致冲突。如果两者被称为相同的，HPA 如何知道使用哪个指标？适配器是否必须丢弃一个而保留另一个？答案在`resources`部分。
度量的真正标识符是它的名称和与之相关的资源的组合。第一个规则生成两个自定义指标，一个用于服务，另一个用于名称空间。第二个还为名称空间生成自定义指标，但也为 Ingresses 生成自定义指标。
总共有多少个指标？在我们检查结果之前，我会让你考虑一下答案。要做到这一点，我们必须`upgrade`图表中的新值生效。
```
 1  helm upgrade -i prometheus-adapter \
 2      stable/prometheus-adapter \
 3      --version v0.5.0 \
 4      --namespace metrics \
 5      --values mon/prom-adapter-values-svc.yml
 6
 7  kubectl -n metrics \
 8      rollout status \
 9      deployment prometheus-adapter
```
我们用新的值升级了图表，并一直等到部署推出。
现在我们可以回到悬而未决的问题“我们有多少定制指标？”让我看看...
```
 1  kubectl get --raw \
 2      "/apis/custom.metrics.k8s.io/v1beta1" \
 3      | jq "."
```
输出限于相关部分，如下所示。
```
{
  ...
    {
      "name": "services/http_req_per_second_per_replica",
      ...
    },
    {
      "name": "namespaces/http_req_per_second_per_replica",
      ...
    },
    {
      "name": "ingresses.extensions/http_req_per_second_per_replica",
      ...
```
现在我们有三个自定义指标，而不是四个。我已经解释过，唯一标识符是与它相关的 Kubernetes 资源相结合的度量的名称。所有的指标都被称为`http_req_per_second_per_replica`。但是，由于两个规则都覆盖了两个资源，并且`namespace`设置在两个中，因此必须丢弃一个。我们不知道哪个被移走了，哪个留了下来。或者，也许，他们被合并了。这并不重要，因为我们不应该用相同名称的度量来覆盖相同的资源。我没有实际的理由将`namespace`包含在适配器的规则中，除了向您展示可以有多个覆盖，以及当它们相同时会发生什么。
除了那个愚蠢的理由，你可以在精神上忽略`namespaces/http_req_per_second_per_replica`指标。
我们使用了两个不同的普罗米修斯表达式来创建两个不同的自定义度量，它们具有相同的名称，但与其他资源相关。一个(基于`nginx_ingress_controller_requests`表达式)来自入口资源，另一个(基于`http_server_resp_time_count`)来自服务。尽管后者起源于`go-demo-5`豆荚，普罗米修斯通过服务发现了它(如前一章所述)。
我们可以使用`/apis/custom.metrics.k8s.io`端点不仅发现我们有哪些自定义指标，还可以检查细节，包括值。例如，我们可以通过下面的命令检索`services/http_req_per_second_per_replica`度量。
```
 1  kubectl get --raw \
 2      "/apis/custom.metrics.k8s.io/v1beta1/namespaces/go-demo5
    /services/*/http_req_per_second_per_replica" \
 3       | jq .
```
输出如下。
```
{
  "kind": "MetricValueList",
  "apiVersion": "custom.metrics.k8s.io/v1beta1",
  "metadata": {
    "selfLink": "/apis/custom.metrics.k8s.io/v1beta1/namespaces/go-demo-5/services/%2A/http_req_per_second_per_replica"
  },
  "items": [
    {
      "describedObject": {
        "kind": "Service",
        "namespace": "go-demo-5",
        "name": "go-demo-5",
        "apiVersion": "/v1"
      },
      "metricName": "http_req_per_second_per_replica",
      "timestamp": "2018-10-27T23:49:58Z",
      "value": "1130m"
    }
  ]
}
```
`describedObject`部分向我们展示了项目的细节。目前，我们只有一个具有该指标的服务。
我们可以看到该服务驻留在`go-demo-5`名称空间中，它的名称是`go-demo-5`，并且它使用的是`v1`应用编程接口版本。
再往下，我们可以看到指标的当前值。在我的例子中，它是`1130m`，或者略高于每秒一个请求。由于没有人向`go-demo-5`服务发送请求，考虑到每秒执行一次运行状况检查，该值是预期的。
接下来，我们将探索使用基于服务的指标的更新的 HPA 定义。
```
 1  cat mon/go-demo-5-hpa-svc.yml
```
输出如下。
```
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: go-demo-5
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: go-demo-5
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Object
    object:
      metricName: http_req_per_second_per_replica
      target:
        kind: Service
        name: go-demo-5
       targetValue: 1500m
```
与之前的定义相比，唯一的变化是在`target`和`targetValue`字段。请记住，完整的标识符是`metricName`和`target`的组合。所以这次我们把`kind`改成了`Service`。我们还必须更改`targetValue`，因为我们的应用不仅通过入口接收外部请求，还接收内部请求。它们可能源自其他可能与`go-demo-5`通信的应用，或者像我们的例子一样，源自 Kubernetes 的健康检查。由于它们的频率是一秒，我们将`targetValue`设置为`1500m`，即每秒 1.5 个请求。这样，如果我们不向应用发送任何请求，就不会触发扩展。通常，你会设定一个更大的值。但是，目前，我们只是试图观察它在缩放前后的行为。
接下来，我们将对 HPA 进行更改，并对其进行描述。
```
 1  kubectl -n go-demo-5 \
 2      apply -f mon/go-demo-5-hpa-svc.yml
 3
 4  kubectl -n go-demo-5 \
 5      describe hpa go-demo-5
```
后一个命令的输出限于相关部分，如下所示。
```
...
Metrics:                                                  ( current / target )
  "http_req_per_second_per_replica" on Service/go-demo-5: 1100m / 1500m
...
Deployment pods:                                           3 current / 3 desired
...
Events:
  Type    Reason             Age    From                       Message