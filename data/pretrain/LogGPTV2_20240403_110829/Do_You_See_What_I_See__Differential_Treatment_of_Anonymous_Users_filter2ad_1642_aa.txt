title:Do You See What I See? Differential Treatment of Anonymous Users
author:Sheharbano Khattak and
David Fifield and
Sadia Afroz and
Mobin Javed and
Srikanth Sundaresan and
Damon McCoy and
Vern Paxson and
Steven J. Murdoch
Do You See What I See?
Differential Treatment of Anonymous Users
Sheharbano Khattak(cid:63), David Fiﬁeld†, Sadia Afroz†, Mobin Javed†
Srikanth Sundaresan‡, Vern Paxson‡†, Steven J. Murdoch(cid:45), Damon McCoy‡
(cid:63)University of Cambridge
†University of California, Berkeley
‡International Computer Science Institute, Berkeley
(cid:45)University College London
PI:EMAIL,{ﬁﬁeld,sadia.afroz,mobin.javed,vern}@berkeley.edu
PI:EMAIL,{srikanth,mccoy}@icsi.berkeley.edu
Abstract—The utility of anonymous communication is un-
dermined by a growing number of websites treating users of
such services in a degraded fashion. The second-class treatment
of anonymous users ranges from outright rejection to limiting
their access to a subset of the service’s functionality or imposing
hurdles such as CAPTCHA-solving. To date, the observation of
such practices has relied upon anecdotal reports catalogued by
frustrated anonymity users. We present a study to methodically
enumerate and characterize, in the context of Tor, the treatment
of anonymous users as second-class Web citizens.
We focus on ﬁrst-line blocking: at the transport layer, through
reset or dropped connections; and at
the application layer,
through explicit blocks served from website home pages. Our
study draws upon several data sources: comparisons of Internet-
wide port scans from Tor exit nodes versus from control hosts;
scans of the home pages of top-1,000 Alexa websites through every
Tor exit; and analysis of nearly a year of historic HTTP crawls
from Tor network and control hosts. We develop a methodology
to distinguish censorship events from incidental failures such as
those caused by packet loss or network outages, and incorporate
consideration of the endemic churn in web-accessible services
over both time and geographic diversity. We ﬁnd clear evidence
of Tor blocking on the Web, including 3.67% of the top-1,000
Alexa sites. Some blocks speciﬁcally target Tor, while others result
from fate-sharing when abuse-based automated blockers trigger
due to misbehaving Web sessions sharing the same exit node.
I.
INTRODUCTION
Anonymity networks serve an important purpose on the
Internet. They often provide the only means for citizens to
access or distribute censored or restricted content without a
threat to their privacy or even safety. A predominant example
of such a network is Tor [6], the ‘king of high-secure, low-
latency Internet anonymity’ according to the NSA [25]. The
success of such networks depends on their utility, i.e., the
degree to which they provide not only acceptable performance
but also unfettered access to the global Internet.
Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’16, 21-24 February 2016, San Diego, CA, USA
Copyright 2016 Internet Society, ISBN 1-891562-41-X
http://dx.doi.org/10.14722/ndss.2016.23342
Traditional threats to Tor involve deanonymization attacks
that reduce user privacy, or governments blocking access to the
Tor network. A different kind of threat, which we explore in
this paper, involves websites providing Tor users with degraded
service, resulting in them effectively being relegated to the role
of second-class citizens on the Internet [4]. Such differential
treatment ranges from websites employing wholesale blocking
of Tor-related IP addresses to requiring Tor clients to complete
CAPTCHAs before continuing. The problem becomes ampli-
ﬁed when ‘bottleneck’ web services (e.g., CloudFlare, Akamai)
whose components are used by many other websites block or
discriminate against Tor users, or when third-party blacklists
used by a large number of websites include Tor infrastructure
(in particular, exit node) IP addresses.
Addressing the Web’s second-class treatment of Tor users
begins with enumerating and characterizing its prevalence.
Thus far, efforts to do so have been ad hoc; effectively by
cataloging reports from frustrated users about services that
routinely employ such practices [27]. In this work, we carry
out a broad, systematic enumeration and characterization of
websites and IP addresses that treat Tor users differently from
normal connections. We run two complementary measurement
campaigns. 1) At the network layer, we scan the entire IPv4
address space (with a small exclusion list) using a modiﬁed
version of ZMap [8]. We run the scans from a select number
of active Tor exit nodes as well as non-Tor control nodes. 2) At
the application layer, we probe the top 1,000 Alexa Web sites
using Exitmap [29]. We fetch home pages of these sites using
Tor and non-Tor nodes and analyze the responses to uncover
evidence of Tor blocking.
We demonstrate the existence of differential treatment of
Tor users at both the network and application layers. At the
network layer, we estimate that at least 1.3 million IP addresses
that would otherwise allow a TCP handshake on port 80 block
the handshake if it originates from a Tor exit node. We also
show that at least 3.67% of the top 1,000 Alexa web sites
block Tor users at the application layer.
We explore the reasons and techniques used by these
websites, and how much of this differential treatment is due to
explicit decisions to block Tor versus the consequence of fate-
sharing due to automated abuse-based blocking. We identify
two kinds of network-layer blocking: wholesale blocking by
Autonomous Systems (ASes) such as access ISPs, and more
targeted (likely abuse-driven, and thus implicit) blocking prac-
ticed by content hosting sites and service providers.
While wholesale blocking of Tor as a matter of ISP or
national policy will likely always exist, our results highlight a
growing concern that anonymity networks are being negatively
affected beyond explicit blocking, due to the desire of web
services to block abuse. In this work we contribute a systematic
methodology and measurement study of the scale of blocking
of anonymity networks, both at the network layer (Section IV)
and the application layer (Section V). Our work provides a ﬁrst
step towards addressing this problem by methodically uncov-
ering and characterizing the nature of blocking of anonymity
networks as seen at scale.
II. BACKGROUND
For our anonymity system case study, we analyse Tor [7],
the most widely used anonymous communication system, with
over 2 million daily users [22]. Tor was designed to allow
users to access TCP-based services (predominantly websites)
privately and securely, preventing any intermediate agent from
linking the user’s identity to their activities. However, many
Tor users primarily seek to circumvent censorship rather than
to obtain privacy. Blocking access from Tor imposes serious
limitations for Tor users, and has signiﬁcant implications for
Tor itself, potentially reducing its utility substantially. We
provide a brief background on Tor’s design and the different
ways it is blocked.
A. Tor
Tor works by routing users’ trafﬁc over a three-hop ‘cir-
cuit’, with each hop being a volunteer-operated ‘node’ running
the Tor software in server mode. Tor uses both per-link and
end-to-end cryptography to provide conﬁdentiality, integrity,
and unlinkability between incoming and outgoing trafﬁc at
each hop. Tor users typically install the Tor Browser Bundle,
which consists of a hardened Firefox-based browser and the
Tor software conﬁgured as a client. When a user makes a
request, the Tor client selects three nodes out of those available
to form a circuit, connecting ﬁrst to the ‘entry guard’, then
through it to the ‘middle node’ and ﬁnally to the ‘exit node’.
The exit node makes the TCP connection to the desired
service and so is also the ﬁrst target for abuse complaints from
operators. For this reason, not everyone is willing to operate
an exit node, and the Tor server conﬁguration allows operators
to set an ‘exit policy’ stating to which IP addresses and ports
the node will carry exit trafﬁc. When a node activates (and
periodically afterwards), it publishes a ‘descriptor’ to each
of the ‘directory authorities’ which includes the IP address
and port at which circuits can connect to the node, its exit
policy, and its public key. The directory authorities together
form and digitally sign the ‘directory consensus’, which they
make available to clients both directly and via Tor nodes that
act as ‘directory mirrors’.
The directory consensus includes the information from
each node’s descriptor, but also includes a set of ﬂags indi-
cating in which positions a node can serve in the circuit (only
sufﬁciently fast and stable nodes can serve as entry guards,
and only nodes with a sufﬁciently permissive exit policy as
exit nodes). Furthermore, the consensus includes a ‘consensus
weight’ for each node, which is an integer proportional to the
node’s bandwidth capacity as measured by a set of ‘bandwidth
authorities’. When selecting a node for each position in the
circuit, clients ﬁrst identify all the nodes that can take the
respective position, and then select from these randomly, but
biased by the consensus weights such that in aggregate they
place a network load on Tor nodes in proportion to their
capacity [23].
Due to its ability to circumvent censorship, the Tor network
itself is subject to censorship. The simplest form consists of
blocking access to the entry nodes by their IP addresses (which
are easily found from the directory consensus). To counter this
threat, Tor maintains a set of Tor nodes (‘bridges’) that act
as entry points to the network but are not publicly listed in
the consensus. Bridges are instead distributed to individuals in
censored countries, making them harder to block reliably [6].
In reaction to this move, some countries ﬁngerprint Tor
trafﬁc to block it, so Tor now allows the integration of
‘pluggable transports’ [24] that disguise the characteristics of
Tor trafﬁc. The use of bridges and/or pluggable transports does
not affect how trafﬁc exits the Tor network, so for the purposes
of our study we do not deal with them specially.
B. Blocking/Filtering Tor
It is technically easy for Internet sites to block trafﬁc from
Tor relays on a wholesale basis, as there exist readily accessible
and regularly updated lists of Tor relays. Internet services may
have different reasons to apply such blocking: to discourage
contributions by anonymous users, or avoid abuse such as
comment spam. Inevitably, some well-meaning users will be
excluded due to how widely Tor shares exit nodes across many
users.
The ﬁrst step to construct a Tor-speciﬁc blacklist is to
collect the IP addresses of exit nodes. The easiest approach
is to collect the IP addresses from the node descriptors in
the directory consensus. However, these addresses denote the
incoming IP address for nodes, and for nodes with multiple
IP addresses this will not necessarily be the IP address for
outgoing connections. As a result, using the IP addresses from
the consensus could lead to both overblocking (by blocking the
incoming IP address even though it is never used for outgoing
exit trafﬁc, but may have other uses) and underblocking (by
failing to block the outgoing IP address because it is not an
incoming address for any node). A more robust approach is
‘active probing’ by making Tor circuits that use each exit
node in turn to establish a connection to a test server, and
observing the originating IP address. This approach increases
the accuracy of the list but puts more load on the network and
reduces the frequency at which the list can be easily updated.
The second decision is which nodes to consider to be exits.
The easiest option is to use the ‘exit’ ﬂag assigned by the
directory authorities if the node’s exit policy permits at least
two ports from 80 (HTTP), 443 (HTTPS) and 6667 (IRC)
to at least one /8 IP address range [23]. Relying on the exit
ﬂag results in overblocking because it is possible that an exit
node will never be selected for a connection to a particular
service using the blacklist even if it has the exit ﬂag set
(perhaps the service’s IP address and/or port is excluded by the
node’s exit policy). Therefore non-Tor users of the computer
hosting the exit node will be blocked from accessing the
service even though there is no possibility that this computer
2
will be the origin of Tor-originated abuse. There may also be
underblocking if the node does not meet the criteria for the exit
ﬂag but its exit policy still permits connecting to the service
in question.
Finally, the blacklist operator may decide to include some
non-exits in the list (e.g., including nodes that have a ‘deny all’
exit policy and so can only be entry guards or middle nodes,
or including IP addresses on the same netblock as Tor nodes).
This approach is especially pernicious, as it leads to blocks
of bystander IP addresses in ways that have little to do with
Tor-sourced abuse. Motivations for doing so may include a
desire to deter people from running Tor servers, or to mitigate
underblocking that may occur as a result of missing Tor server
conﬁguration changes or mismatches between incoming and
outgoing IP addresses for the node.
Examples of publicly available Tor blacklists include
dan.me.uk [1], which optionally includes non-exit Tor
nodes, and dnsbl.sectoor.de [19], which includes all
IP addresses on the same /24 as the Tor exit by default. The
Tor project itself maintains TorDNSEL [21], which uses active
probing to increase accuracy, and also takes into account the
speciﬁc service using the blacklist so as to reduce overblocking
and underblocking.
To avoid complications resulting from these different ap-
proaches to blacklisting, we run our control probes from
systems that did not share a /24 IP address with any Tor node,
and our Tor-based probes from exit nodes that had the exit ﬂag
for at least a month, as well as permitting access to almost all
IP addresses on port 80 (the destination port for our probes).
III. RELATED WORK
We consider Internet censorship relevant to Tor from three