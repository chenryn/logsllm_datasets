# Title: Do You See What I See? Differential Treatment of Anonymous Users

## Authors:
- Sheharbano Khattak (University of Cambridge)
- David Fifield (University of California, Berkeley)
- Sadia Afroz (University of California, Berkeley)
- Mobin Javed (University of California, Berkeley)
- Srikanth Sundaresan (International Computer Science Institute, Berkeley)
- Vern Paxson (University of California, Berkeley and International Computer Science Institute, Berkeley)
- Steven J. Murdoch (University College London)
- Damon McCoy (International Computer Science Institute, Berkeley)

## Abstract
The utility of anonymous communication is increasingly compromised by websites that treat users of such services in a degraded manner. This second-class treatment ranges from outright rejection to limited access to a subset of the service's functionality or imposing hurdles such as CAPTCHA-solving. To date, observations of such practices have been based on anecdotal reports from frustrated anonymity users. This study aims to methodically enumerate and characterize the differential treatment of anonymous users, specifically in the context of Tor.

We focus on first-line blocking at both the transport layer (through reset or dropped connections) and the application layer (through explicit blocks served from website home pages). Our study draws upon several data sources, including comparisons of Internet-wide port scans from Tor exit nodes versus control hosts, scans of the home pages of the top 1,000 Alexa websites through every Tor exit node, and analysis of nearly a year of historic HTTP crawls from Tor network and control hosts. We develop a methodology to distinguish censorship events from incidental failures and consider the endemic churn in web-accessible services over time and geographic diversity. Our findings indicate clear evidence of Tor blocking, with 3.67% of the top 1,000 Alexa sites engaging in such practices. Some blocks are specifically targeted at Tor, while others result from fate-sharing when abuse-based automated blockers trigger due to misbehaving Web sessions sharing the same exit node.

## 1. Introduction
Anonymity networks play a crucial role on the Internet, often providing the only means for citizens to access or distribute censored or restricted content without compromising their privacy or safety. A prominent example is Tor, which the NSA has referred to as the 'king of high-secure, low-latency Internet anonymity.' The success of these networks depends on their utility, which includes not only acceptable performance but also unfettered access to the global Internet.

While traditional threats to Tor involve deanonymization attacks and government-level blocking, a different kind of threat involves websites providing Tor users with degraded service, effectively relegating them to the status of second-class citizens on the Internet. This differential treatment can range from wholesale blocking of Tor-related IP addresses to requiring Tor clients to complete CAPTCHAs. The problem is exacerbated when bottleneck web services (e.g., CloudFlare, Akamai) or third-party blacklists used by many websites include Tor infrastructure IP addresses.

To address this issue, we need to systematically enumerate and characterize the prevalence of such differential treatment. Previous efforts have been ad hoc, relying on user reports. In this work, we conduct a broad, systematic enumeration and characterization of websites and IP addresses that treat Tor users differently. We run two complementary measurement campaigns: 1) At the network layer, we scan the entire IPv4 address space using a modified version of ZMap, comparing results from Tor exit nodes and non-Tor control nodes. 2) At the application layer, we probe the top 1,000 Alexa websites using Exitmap, fetching home pages and analyzing responses for evidence of Tor blocking.

Our results show differential treatment of Tor users at both the network and application layers. At the network layer, we estimate that at least 1.3 million IP addresses block TCP handshakes on port 80 if they originate from a Tor exit node. At the application layer, at least 3.67% of the top 1,000 Alexa sites block Tor users. We explore the reasons and techniques behind this differential treatment, distinguishing between explicit decisions to block Tor and the consequences of fate-sharing due to automated abuse-based blocking.

## 2. Background
### 2.1 Tor
Tor is the most widely used anonymous communication system, with over 2 million daily users. It allows users to access TCP-based services (primarily websites) privately and securely, preventing any intermediate agent from linking the userâ€™s identity to their activities. Many Tor users seek to circumvent censorship rather than obtain privacy. Blocking access from Tor imposes serious limitations for users and reduces the utility of the network.

Tor works by routing traffic over a three-hop circuit, with each hop being a volunteer-operated node running the Tor software in server mode. Tor uses both per-link and end-to-end cryptography to provide confidentiality, integrity, and unlinkability. Users typically install the Tor Browser Bundle, which consists of a hardened Firefox-based browser and the Tor software configured as a client. When a user makes a request, the Tor client selects three nodes to form a circuit, connecting to an entry guard, then to a middle node, and finally to an exit node. The exit node makes the TCP connection to the desired service and is the first target for abuse complaints.

### 2.2 Blocking/Filtering Tor
Internet sites can easily block traffic from Tor relays using publicly available and regularly updated lists of Tor relays. Reasons for such blocking include discouraging contributions by anonymous users or avoiding abuse like comment spam. However, this can also exclude well-meaning users due to the shared nature of exit nodes.

To construct a Tor-specific blacklist, one can collect IP addresses from the directory consensus. However, this approach can lead to overblocking and underblocking. A more robust approach is active probing, where Tor circuits are made to each exit node to establish a connection to a test server, observing the originating IP address. This increases accuracy but puts more load on the network and reduces the frequency of updates.

Blacklist operators may also include non-exit nodes or IP addresses on the same netblock as Tor nodes, leading to the blocking of bystander IP addresses. Examples of publicly available Tor blacklists include dan.me.uk and dnsbl.sectoor.de. The Tor project maintains TorDNSEL, which uses active probing to increase accuracy and reduce overblocking and underblocking.

To avoid complications, our control probes were run from systems that did not share a /24 IP address with any Tor node, and our Tor-based probes were run from exit nodes with the exit flag for at least a month and permitting access to almost all IP addresses on port 80.

## 3. Related Work
We consider Internet censorship relevant to Tor from three perspectives: traditional threats, government-level blocking, and differential treatment by websites.