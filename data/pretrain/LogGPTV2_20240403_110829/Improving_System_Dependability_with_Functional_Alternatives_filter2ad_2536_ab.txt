sight was that dependencies among components due to data
flow in the architecture greatly reduced the number of valid
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:39 UTC from IEEE Xplore.  Restrictions apply. 
configurations that must be considered. In the systems we
evaluated, over 90% of the total possible configurations of
the system were invalid because missing components broke
data flow from sensors to actuators necessary for function-
ality. The second insight was that we could use the feature
subset definitions to form a hierarchical structure that en-
abled us to calculate system utility based on feature subset
component configurations rather than a flat system compo-
nent configuration. Since feature subsets generally had sig-
nificantly fewer components than the entire system, this
reduced the number of configurations to be manually eval-
uated. We used this model to aid our analysis of the eleva-
tor system and identify where functional alternatives could
be applied to achieve dependability improvements.
4. Implementing functional alternatives
This section describes our approach for designing func-
tional alternatives, some initial techniques we have identi-
fied for applying them to a system architecture, and our
evaluation mechanism. The model we have developed
identifies all feature subsets in the system and the depend-
encies among them, which we use as a basis for identifying
functional alternatives. The model also enables us to evalu-
ate the relative utility of any configuration of failed compo-
nents in the system, which means we can determine
combinations of component or feature subset failures that
may cause greatly reduced system utility or a complete sys-
tem failure. The model alone does not provide insight on
how we should apply functional alternatives in the system
to maximize dependability, but it does give us a means to
evaluate design choices as to where we allocate resources
for functional alternatives or redundancy. We can also use
the model as a validation tool to ensure that the configura-
tions evaluated in the architecture model provide their
specified relative utility in the system implementation.
4.1. Designing functional alternatives
Alternative functionality encompasses many existing
redundancy mechanisms. Triplex modular hardware re-
dundancy [14], recovery blocks [12], and multi-version
software redundancy [1] are all examples of possible alter-
native functionality mechanisms that could be applied to a
system to improve dependability. However, each of these
techniques has a significant cost in terms of resources re-
quired in the system as well as design complexity.
Other functional alternatives may be implemented as
heterogeneous redundancy. Heterogeneous redundancy
can take many forms. One example is analytical redun-
dancy [11], where there may be several related sensors
available in the system. These sensors may monitor differ-
ent aspects of the environment that are physically related,
such that one sensor’s data can be synthesized by applying
a transform function to another sensor’s data. For example,
if a system has sensors that monitor temperature, pressure,
and volume of a gas, a software component can be designed
to implement a transform function to synthesize the output
of one sensor based on the readings of the other two. Thus,
one sensor failure could be tolerated with this transformer
component, without having to add redundant sensors.
The simplex architecture [2] is another technique that
can be used for implementing functional alternatives. It is a
control system architecture for using design diversity to im-
prove the reliability of a software control system. It explic-
itly defines tradeoffs between low-performance, more
reliable controllers and high performance controllers that
may contain more residual design defects. Rather than de-
velop multiple versions of software from the same specifi-
cation and with the same requirements as in traditional
multi-version software redundancy, the simplex architec-
ture requires at least two different control algorithms with
different specifications and requirements to be imple-
mented as separate software controllers. The simplex
method specifically targets each alternate algorithm to sat-
isfy different levels of system objectives: one focusing on
high reliability, and the other on high performance.
We can also improve the effectiveness of alternative
functionality on system dependability by designing indi-
vidual components (and feature subsets) to be robust to in-
put failures.
If a component can tolerate the loss of a
system variable when all of its input sources have failed, it
may still provide reduced utility and prevent a system fail-
ure. This may not be possible in all situations, but we can
identify some guidelines that might help implement this de-
sign approach. One approach might be to initially specify
the component’s outputs to provide some “base level” util-
ity with a minimum of system variable inputs and a default
behavior. Then any other inputs that are available should
be treated by the component as “advice” that modifies the
default behavior in specific ways. This technique assumes
that received inputs will not be erroneous, which is compat-
ible with our fail-fast, fail-silent component fault model.
4.2. Applying functional alternatives
Each alternative functionality mechanism can poten-
tially improve system dependability by providing redun-
dant functions for satisfying primary system objectives.
However, it is not feasible to add alternative functionality
to every feature subset in the system. Each additional func-
tional alternative has increased design or resource costs.
Ideally, we would like to identify existing feature sub-
sets that may serve as functional alternatives for primary
system objectives with little or no modification. For exam-
ple, if one feature subset's output is semantically similar to
another, it may be a candidate for a functional alternative
with the addition of an adapter component to transform its
output to match the other feature subset's interface. This
process requires domain knowledge to recognize similar
interfaces across feature subsets and components. This has
the benefit of adding additional redundancy to the system
with little or no additional resources, but requires signifi-
cant analysis effort from the designer. Our model provides
a basis for this analysis with all of the feature subset inter-
faces identified.
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:39 UTC from IEEE Xplore.  Restrictions apply. 
Configuration with
no failed components
(Maximum Utility)
Invalid Configurations
(Zero Utility)
e
s
a
C
a l
e
I d
y
t
i
l
i
t
U
m
e
t
s
y
S
d
e
r
u
s
a
e
M
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Predicted Model Utility
Figure 1. Graph of ideal case of predicted model
utility vs. measured system utility.
There are several properties in the architecture that indi-
cate which parts of the system could best be augmented
with functional alternatives. For example, using the system
model, we can evaluate the utility of every configuration
with a single failed component or feature subset. If any of
these configurations are invalid (provide zero system util-
ity) we have identified a single point of failure, which could
benefit from a functional alternative mechanism.
Another approach to identifying where functional alter-
natives should be installed could be to analyze which sys-
tem variables are required inputs to a large number of
components in the system. The more components that re-
quire any one system variable as an input, the more impor-
tant that variable is to system utility. Therefore, we should
provide adapters to increase the number of components and
feature subsets that can output that system variable.
to combine these properties along with system functionality
and performance into a single utility metric.
Rather than focus on absolute utility measurements that
may be inaccurate, we can use the relative utility values of
system configurations to rank all 2N configurations in order
of increasing utility according to the model. Then we may
select a system property or set of properties such as perfor-
mance and reliability that may be measurable for the system
implementation, and use these measurements as a proxy for
a system utility metric. If we graph the system configura-
tions by comparing their utility values as predicted by the
model and their system property metrics that substitute for
system utility measurements, we expect a graph that may
not be linear, but will be monotonically increasing such that
configurations with higher utility values in the model will
have higher system property measurements.
If there are
configurations that do not fit the curve in this graph (e.g.
configurations ranked as low utility that have unusually
high measured system properties or configurations ranked
as high utility that have low measured system properties),
they may indicate either an inaccuracy in the system model,
a dependability problem in the system implementation, or a
violation of the model’s assumptions. We can apply this
analysis iteratively to both refine the system model and
identify dependability bottlenecks.
This analysis assumes that the utility values specified by
the system model for all 2N configurations are reasonably
accurate, and that the properties selected to measure the
system implementation are indicators of system utility as
defined by the system's objectives. The system designer
should choose properties for this metric that are both quan-
tifiable and general indicators of overall system utility.
This may be difficult depending on which properties are
considered important by the system requirements, and
whether these properties have tradeoffs with one another.
The current best practice for combining properties into a
single utility metric is multi-attribute utility theory [3, 4].
4.3. Evaluating the system implementation of
functional alternatives
5. Case study: elevator system
In addition to using the model at design time to deter-
mine where functional alternatives should be applied in the
system, the model can also be used to validate whether or
not the system implementation can tolerate the component
failure configurations evaluated. In an ideal case a utility
model should perfectly reflect each component and feature
subset’s contribution to system utility. If we have a utility
metric that incorporates all of the desired system properties
defined in the system’s requirements, and these attributes
can be measured in the system implementation, then every
system configuration’s actual measured utility should equal
the utility predicted by the model. If we were to graph each
configuration’s utility from the model versus its measured
utility for all 2N configurations, the result should be a
straight line with a slope of 1 as shown in Figure 1. Unfor-
tunately, in general this ideal case is not possible. Many
system properties such as usability, maintainability, and de-
pendability cannot be readily quantified, and it is nontrivial
To illustrate how we can apply alternative functionality,
we use a design of a relatively complex distributed elevator
control system. This system was designed by an engineer
with industrial experience in elevator architecture (the sec-
ond author) and has been implemented in a discrete event
simulator written in Java as a course project for several se-
mesters. Since we have a complete architectural specifica-
tion as well as an implementation, we can directly observe
how alternative functionality affects the system's ability to
tolerate combinations of component failures by performing
simulation experiments.
A requirements document specifies each system compo-
nent’s inputs and outputs, as well as its functional behavior.
Component interfaces are specified by a message dictio-
nary. We created a system model and used the analysis
techniques described in Section 4 to apply functional alter-
natives and improve the system's dependability. We then
ran a set of experiments on the elevator system using imple-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:39 UTC from IEEE Xplore.  Restrictions apply. 
{Up, Down}
Hoistway Limit
Sensors
Drive Speed
{1 … f} AtFloor
Sensor
Sensors
{Left, Right}
Door Open
Sensors
{Left, Right}
Door Reversal
Sensors
Drive Motor and
Car Position
Controller
Sensor
Car Weight
Sensor
{Left, Right}
Door Closed
Sensors
Safety Monitor
Controller and
Emergency Brake
Fault Tolerant
Broadcast Network
Dispatcher
Controller
{1 … f} Car Call
Button Sensors,
Controllers, and Lights
{1 … f} Hall Call
{Up, Down}
Button Sensors,
{Up, Down}
Lantern Controllers
and Lights
Hardware Node
Software Component
Sensor
Actuator
Network Connection
Controllers, and Lights
{Left, Right} Door
Motors and
Controllers
Car Position
Indicator Controller
and Lights
Figure 2. Original elevator system architecture.
mentations of both the original system architecture and the
new architecture with our alternative functionality im-
provements. We failed several combinations of compo-
nents and observed the effect on the system’s ability to
deliver passengers.
Figure 2 shows a high level view of the original elevator
system architecture, with software components, sensors,
and actuators allocated to distributed processors connected
by a fault tolerant broadcast network. The elevator consists
of a single car in a hoistway with access to a set number of
floors f. The car has two independent left and right doors
and door motors, a drive that can accelerate the car to two
speeds (fast and slow) in the hoistway, an emergency stop
brake for safety, and various buttons and lights for deter-
mining passenger requests and providing feedback [17].
5.1. Applying functional alternatives to the
elevator system
An elevator system’s most basic requirements are that it
protect passenger safety while using the system and trans-
port passengers to their destination floors without stranding
them or trapping them in the elevator. We specified these
requirements as the minimum primary objectives. Other
services typically associated with an elevator system, such
as providing appropriate passenger feedback, efficiently
processing passenger requests, and minimizing passenger
travel time, were considered auxiliary objectives. As long
as the elevator maintains passenger safety, and can (eventu-
ally) service all floors, it can still be considered “working.”
Based on the software components defined for this ele-
vator system, the safety, drive control, and door control