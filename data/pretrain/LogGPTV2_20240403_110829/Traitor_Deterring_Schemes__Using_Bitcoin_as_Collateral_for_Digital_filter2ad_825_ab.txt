thority gains access to the pirate box, while in a TDS, the
mere act of sharing a decryption key (or any, even partially
working, implementation of a decryption algorithm contain-
ing such key) will lead to the leakage of one of the traitors’
secrets. We show that a traitor deterring scheme implies a
publicly traceable traitor tracing scheme [8] (cf. Section 2).
Another closely related notion to a TDS is digital signets
for self-enforcement [12]. In this multi-user encryption sys-
tem, the adversary that controls a set of traitor user keys
and wants to retransmit a certain plaintext that was trans-
mitted, will either send a message as long as the plaintext
itself, or will have to leak some of the traitors’ private data.
The formalization of the problem in [12] assumes that re-
coverability of the collateral information requires direct ac-
cess to the traitor keys (also called white-box access).
In
our terminology, they provide a symmetric-key TDS that
is only secure in the non-black-box sense. The construc-
tion provided by [12] relies on the unfalsiﬁable assumption
that f (x) = gx
(cid:96) is incompressible (incompress-
ible means given x, f , no adversary can come up with an
intermediate value y, such that: (1). |y|/|f (x)| = o(1); (2).
one can recover f (x); (3). x remains hidden).
2|| . . .||gx
1||gx
Kiayias and Tang studied the problem of leakage deter-
ring (LD) public key cryptography [21]. If a key owner leaks
any partially working decryption box, a piece of secret infor-
mation that is embedded in her public key will be revealed
to the recipient. Our notion of TDS is a generalization of
LD from the single user setting to the multi-user setting.
We note that because of collusion attacks in the multi-user
setting the techniques for recoverability from [21] are not
directly applicable for building a TDS (even a scheme with
ciphertext size linear in the number of users is not obvious).
2. DEFINITIONS AND SECURITY MODELS
We provide the formal deﬁnition and security model of
TDS’s and demonstrate their relationship to TTS’s.
Syntax of traitor deterring schemes. Informally, a traitor de-
terring scheme is a multi-user encryption scheme with a de-
terring mechanism such that if some of the receivers collude
to leak an implementation of a (potentially only partially
working) decryption device, any recipient of the device will
be able to recover one of the colluding user’s secret informa-
tion which is hidden in the public parameter of the system.
Formally we have the following:
• Setup(1λ, s1, . . . , sn): This algorithm is composed of
two parts: KeyGen, which, on input the security pa-
rameter it outputs an encryption key pk, and a set of
decryption keys sk1, . . . , skn; and ParGen that on in-
put pk, sk1, . . . , skn and the users’ secrets s1, . . . , sn ∈
{0, 1}λ it outputs public parameter para.
• Enc(pk, m): on input para, pk and a message m, it
outputs a ciphertext c.
• Dec(ski, c): on input para, pk, one of the secret keys
ski and a ciphertext c, it outputs a plaintext m.
• RecB,D(pk, para): on input para, pk with has oracle
access to a device B and a distribution D it outputs a
string in {0, 1}λ or ⊥.
The correctness of the scheme is standard and entails
that Enc(pk,·) can be inverted by Dec(ski,·) for any i =
1, . . . , n. The intended functionality of the algorithm Rec
is that if B is created by a collusion of receivers with se-
cret keys ski1 , . . . , skit and operates correctly for ciphertexts
whose corresponding plaintext follows a distribution D, the
algorithm outputs at least one of the strings si1 , . . . , sit . We
clarify the conditions under which this is supposed to hap-
pen (as well as the other necessary security properties) in
the next paragraph.
Security model. There are three security requirements for
a traitor deterring scheme, security of plaintexts, privacy of
user’s secrets, and traitor deterring.
IND-CPA security. Regarding security of plaintexts we
consider a security property of IND-CPA deﬁned in a stan-
dard fashion: the challenger C runs setup to obtain s1, . . . , sn
and provides the adversary A with para, pk. In response, A
provides two plaintexts m0, m1 to C. Subsequently C com-
putes ψ = Enc(pk, mb) for a random b ∈ {0, 1} and provides
ψ to A. A returns a bit b(cid:48) and C terminates with 1 if b = b(cid:48)
and 0 otherwise. The probability that C returns 1 means
that A is successful and we denote it by SuccindcpaA
(1λ). For
(1λ)] ≤ 1/2 +
security to hold it must be that Pr[SuccindcpaA
negl(λ). The notion of security can be extended in a straight-
forward manner to IND-CCA2.
Privacy. Regarding the privacy of user secret information it
should be the case that each si value remains hidden within
the public parameter even all other users are corrupted. For-
mally, consider the following game:
• The challenger C ﬁrst simulates the KeyGen part of
the Setup algorithm and returns pk to the adversary.
• The adversary A sends an index i as well as private
information {sj}j(cid:54)=i and the pair si,0, si,1 to C.
• The challenger C randomly ﬂips a bit b, and simulates
the ParGen part of Setup on input pk, sk1, . . . , skn,
s1, . . . , si−1, si,b, si+1, . . . , sn. C sends to A the values
para, sk1, . . ., ski−1, ski+1, . . . , skn.
• A returns a single bit b(cid:48) and C returns 1 if b = b(cid:48).
233The event that C returns 1 means A is successful and we
denote it by SuccprivA (1λ). For privacy of secret information
to hold it must be that Pr[SuccprivA (1λ)] ≤ 1/2 + negl(λ) for
any PPT adversary A. Note that letting the challenger send
the public key ﬁrst makes the deﬁnition stronger. It is also
possible to deﬁne weaker variants of the above deﬁnition,
e.g., where A is restricted to a number t of secret-keys or
the pk is returned together with the secret keys.
Traitor-Deterring. Finally we deﬁne the traitor deter-
ring property.
In order to specify the deﬁnition we need
ﬁrst to deﬁne the notion of δ-correctness with respect to a
public-key pk and a plaintext distribution D. A device B
is δ−correct with respect to D and pk if it satisﬁes that
Pr[B(Enc(pk, m)) = m : m ← D] ≥ δ. With the public
parameter, and a non-trivial pirate decryption box B which
is created by the collusion of all users, the recovering algo-
rithm should determine of the colluder’s secret information
si. Formally, consider the following game:
• The challenger C simulates the Setup algorithm and
the adversary A receives pk. A then provides a vector
of secret information s1, . . . , sn as well as an arbitrary
subset T ⊆ {1, . . . , n} to the challenger C and A re-
ceives the secret keys of all users in T , {ski | i ∈ T} as
well as the public parameter para.
• A outputs an implementation B and a distribution D.
• C returns 1 iﬀ RecB,D(pk, para) (cid:54)∈ {si | i ∈ T}.
We deﬁne by SuccdeterA (1λ) the event that C returns 1.
We say a scheme achieves fully collusion resilient, black-box
traitor deterring w.r.t. a class of distributions D (that may
depend on δ) if for any PPT adversary A it holds that
Pr[B is δ-correct w.r.t. D∧D ∈ D∧SuccdeterA (1λ)] = negl(λ).
In the above experiment we assume that Rec has reset-
table black-box access to B. Weaker variants of the above
formulation may be relevant in some settings and can be “t-
collusion resilient” (as opposed to fully-collusion resilient) or
they may extend Rec’s access to B (e.g., in a non-black-box
setting Rec may have access to the traitor keys).
Deﬁnition 2.1 (cid:104)Setup, Enc, Dec, Rec(cid:105) is a (fully-collusion
resistant, black-box) traitor deterring scheme if it satisﬁes,
(i) correctness, (ii) IND-CPA security, (iii) privacy and (iv)
fully-collision resistant, black-box traitor deterring.
TDS and TTS. We conclude the section by a brief argu-
ment that a traitor deterring scheme is a strict generalization
of a traitor tracing scheme (in fact of a TTS with “public-
traceability” [8]). Given a TDS: (cid:104)Setup, Enc, Dec, Rec(cid:105),
the reduction is easy with the following simple observation.
First we set si = i for all i = 1, . . . , n. It follows that the
Setup algorithm requires no other input other than the se-
curity parameter λ. Observe now that the Rec algorithm
will output one of the indices of the colluding users who
jointly produce the decryption box B with only access to
pk, hence it is a TTS with public-traceability.
3. TRAITOR DETERRING FROM FINGER-
PRINTING CODES
In this section, we will present our ﬁrst technique of con-
structing a TDS from ﬁngerprinting codes. We ﬁrst formal-
ize a new encryption scheme we call fuzzy locker (w.r.t a
ﬁngerprinting scheme), from which together with a public
key encryption, we will construct a TDS. We then give a
concrete construction of fuzzy locker for CFN codes [9].
First, let us recall the deﬁnition of ﬁngerprinting codes
[20]. A q-ary ﬁngerprinting code is a pair of algorithms
(Gen, Accuse). Gen is a probabilistic algorithm with input
a security/error parameter  and two numbers n, t denoting
the number of users and the maximum collusion size respec-
tively, and t ∈ [n] = {1, . . . , n}. It outputs n q-ary strings
C = {C1, . . . , Cn} (called codewords), where Ci = ci
1 . . . ci
for i ∈ [n], j ∈ [(cid:96)], ci
j ∈ Q–the alphabet set with size q and
(cid:96)
a tracing key tk. Accuse is a deterministic algorithm with
input a “pirate” codeword C∗, and a user codeword Ci and
the tracing key tk; it outputs a bit in {0, 1}.
Suppose adversary A corrupts up to t users (whose indices
form a set Ucor ⊂ [n]), and outputs a pirate codeword C∗ =
(cid:96) . We deﬁne the accused user set as Uacc = {i ∈
1 . . . c∗
c∗
[n] : Accuse(tk, C∗, Ci) = 1]. A ﬁngerprinting code is called
t−collusion resistant (fully collusion resistant if t = n) if
it satisﬁes: (i) traceability, if the strategy of producing C∗
satisﬁes the “marking assumption”, (for each i ∈ [n], c∗
i =
i for some j ∈ Ucor), then one of the colluders must be
cj
accused, i.e., Pr[Uacc ∩Ucor = ∅] ≤ ; and (ii) soundness, the
probability that an innocent user is accused is bounded by
, i.e., Pr[([n] − Ucor) ∩ Uacc (cid:54)= ∅] ≤ .
3.1 TDS from fuzzy lockers.
Fingerprinting codes are combinatorial designs that en-
able testing whether a codeword is used in generating a pi-
rate codeword. They were demonstrated to be very useful in
building TTS in a line of previous works, e.g., [3, 9, 22]. The
basic idea is that each user will be assigned an “identity”
which is represented by a codeword, and the secret keys for
the user will be selected from a group of keys according to
his codeword. The encryption algorithm will cover all the
user keys. The tracing algorithm will ﬁrst recover a “pirate
codeword” by feeding the pirate decryption device with mal-
formed (but seemingly valid in the view of A) ciphertexts,
and then it will run the tracing algorithm of the ﬁngerprint-
ing code to identify at least one of the colluding users who
participated in producing the pirate codeword.
The main challenge of upgrading the above paradigm to
a TDS is the way of embedding and recovering of the secret
information of the users. To address this, we formalize a new
primitive we call fuzzy locker w.r.t. a (publicly traceable)
ﬁngerprinting code. In a fuzzy locker, a message is encrypted
using a random codeword Ci. The message can be decrypted
(“unlocked”) only if one provides a pirate codeword C∗ such
that Ci will be accused by the accusation algorithm, other-
wise, the message will remain IND-CPA secure. Given such
a primitive, one can construct a TDS as follows: the em-
bedding of the user private information can be simply done
via encryption using the user’s codeword (which is normally
randomly selected according to the Gen algorithm). The pri-
vacy requirement can be easily achieved via the security of
the fuzzy locker. The recover algorithm will ﬁrst retrieve a
“pirate codeword” from the pirate box and then it will try
decrypting all locked data using this pirate codeword. The
traitor deterring property can be guaranteed by the traitor
tracing property of the ﬁngerprinting code, since at least one
of the codewords used in producing the pirate codeword will
be accused and thus the private user data can be retrieved.
We ﬁrst give the formal deﬁnition and security model of
234a fuzzy locker. W.l.o.g., we can think of the Gen algorithm
of the ﬁngerprinting code C to operate in two phases, ﬁrst,
using n, t and the security parameter produces a secret state
st and then uses a C.Sample subroutine that produces the
codewords one-by-one while updating the state st.
Deﬁnition 3.1 A fuzzy locker w.r.t a (publicly traceable)
ﬁngerprinting code C consists of the following two algorithms:
• FL.Enc(Ci, m): Given a codeword Ci ← C.Sample
and a message m, the encryption algorithm outputs
a ciphertext c.
• FL.Dec(C∗, c): Given a ciphertext c and a string C∗,
the algorithm outputs a message m or ⊥.
Correctness: If C.Accuse(tk, Ci, C∗) = 1:
Pr[FL.Dec(C
∗
, c) = m] ≥ 1 − negl(λ).
Security of a fuzzy locker. We deﬁne t-resilient security (fully
resilient if t = n) of a fuzzy locker scheme in the sense of
IND-CPA security, by considering the following game be-
tween a challenger C and an adversary A:
• The challenger produces st using Gen on input , t, n
and sends C1, . . . , Ct ← C.Sample(st) to A.
• A selects two messages m0, m1 and sends them to C.
• The challenger randomly samples a codeword C0 ←
C.Sample(st), randomly ﬂips a coin b, and sends c =
FL.Enc(C0, mb) to the adversary A.
• A outputs her guess b(cid:48).
A fuzzy locker is t-resilient IND-CPA secure if:
| ≤ negl(λ).
FL = | Pr[b
A
Adv
(cid:48)
= b] − 1