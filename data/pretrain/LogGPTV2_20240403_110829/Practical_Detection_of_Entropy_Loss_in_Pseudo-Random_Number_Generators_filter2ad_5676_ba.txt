i = M(Si, HK(Si))
S∗
u = M(Su, Ti)
Ei = Ei − 8αu
Eu = Eu + 8αu
S0
u = M(S∗
u, HK(S∗
u))
R = F ◦ HK ◦ M(S∗
u, HK(S∗
u))
Eu = Eu − 8t
R = F ◦ HK ◦ M(Su, HK(Su))
Eu = 0
i, S0
u, S0
r)
This illustrates the diﬀerence between /dev/urandom and /dev/random: If the estimated entropy
of the blocking pool Sr is less than 8t and no transfer is done, then /dev/random blocks, whereas
/dev/urandom does never block and outputs the requested t bytes from the non-blocking pool
Su.
The Entropy Estimator
A built-in estimator Ent is used to give an estimation of the entropy of the input data used to
refresh Si. It is implemented in function add_timer_randomness which is used to refresh the
input pool. A timing tn is associated with each event (system or user call) that is used to refresh
the internal state. Entropy is estimated when new input data is used to refresh the internal
state, entropy is not estimated using input distribution but only using the timings of the data.
A description of the estimator is given in [GPR06],
[LRSV12] and [GLSV12]. The estimator
takes as input a sequence of inputs Ii = [jiﬃeskget_cyclesknum], it calculates diﬀerences between
timings of events, where t0, t1, t2, . . . are the jiﬃes associated with each input: δi = ti − ti−1,
i |) and ﬁnally applies a
i − δ2
i = δi − δi−1, δ3
δ2
logarithmic function to give the estimated entropy Hi = 0 if ∆i  212, and
Hi = blog2(∆i)c otherwise.
i−1. Then, it calculates ∆i = min(|δi|,|δ2
i |,|δ3
i = δ2
— 119 —
Chapter 7. Security Analysis
Algorithm 10 LINUX Entropy Estimator
Require: Ii = [numkjiﬃeskget_cycles]
Ensure: Hi = Ent(Ii)
1: ti = jiﬃes
2: δi = ti − ti−1
i = δi − δi−1
3: δ2
i − δ2
4: δ3
i = δ2
i−1
5: ∆i = min(|δi|, |δ2
i |, |δ3
i |)
6: if ∆i  212 then Hi = 11
8: else Hi = blog2(∆i)c
9: return Hi = Ent(Ii)
The Folding and the Hash Functions
The folding function F and the hash function HK are used when random bytes are generated by
LINUX and when data is transferred from Si to Sr or Su. The folding function is implemented in
built-in function extract_buf. It take as input ﬁve 32-bit words and output 80 bits of data. This
function F is deﬁned by F(w0, w1, w2, w3, w4) = (w0 ⊕ w3, w1 ⊕ w4, w2[0···15] ⊕ w2[16···31]), where wi
for i ∈ {0, . . . , 4} are the input words.
The hash function HK is implemented in the built-in function extract_buf by a call to a Linux
system function sha_transform.
The Mixing Function
The Mixing function M is the core of generator LINUX. It is implemented in the built-in function
mix_pool_bytes. It is used in two contexts, once to refresh the internal state with new input
and secondly to transfer data between the input pool and the output pools. We give a complete
description of M as it is used to refresh the input pool Si, its description when it is used to
transfer data between pools diﬀers only from internal parameters.
The function M takes as input I of size one byte, the input pool Si that is considered as a table
of 128 32-bits words. It selects 7 words in Si and mixes them with I and replaces one word of
Si with the result. The pool Si therefore maintains an internal parameter, named k, which is
used to select the word that will be modiﬁed. Another internal parameter, named d, is used in
function M. This parameter is a multiple of 7 used in a rotation done at word level. We name
the rotation of d bits Rd. The mixing function involves the following operations:
• The byte containing the entropy source is converted into a 32-bit word, using standard C
implicit cast, and rotated by d bits. Before initialization, d = 0, and each time the mixing
function M is used, d is incremented using k : if k = 0 mod 128 then d = d + 14 mod 32
and d = d + 7 mod 32 otherwise.
• The obtained word is xor-ed with words from the pool. If we note S0, . . . , S127 the words
of Si, chosen words will be Sk+j mod 128 for j ∈ {0, 1, 25, 51, 76, 103}2.
• The obtained word is mixed with a built-in table (named twist table). This table contains
the binary representations of the monomials {0, α32∗j}, j = 1, . . . 7, in the ﬁeld (F2)/(Q),
where Q(x) = x32+x26+x23+x22+x16+x12+x11+x10+x8+x7+x5+x4+x2+x+1 is the
CRC32 polynomial used for Ethernet protocol [Koo02]. Denoting the primitive element
α, this operation can be described as W → W.α3 + R(Q(W, α29).α32, Q), where Q(A, B)
(resp. R(A, B)) the quotient (resp. the remainder) in polynomial division A/B.
2Similarly, the words chosen from Sr and Su will be Sk+j mod 32 for j ∈ {0, 1, 7, 14, 20, 26}.
— 120 —
• Then the word at index k in Si is replaced by the previously generated word and k is
incremented.
7.2. Security of Linux Generators
Algorithm 11 LINUX Mixing function
Require: I, S = (S0, . . . , Sk, . . . , S127)
Ensure: S0
1: W = Rd[0||I]
2: if k = 0 mod 128 then d = d + 14 mod 32 else d = d + 7 mod 32 end if
3: W = W ⊕ Sk+j mod 128, j ∈ {0, 1, 25, 51, 76, 103}
4: W = W.α3 + R(Q(W, α29).α32, Q)
5: S0
k = W
6: k = k + 1
7: return S = (S0, . . . , S0
k, . . . , S127)
Distributions Used for Attacks
Distributions Used in Attacks based on the Entropy Estimator As shown previously, the
generator LINUX uses an internal Entropy Estimator on each input that continuously refreshes
its internal state. We show that this estimator can be fooled in two ways. First, it is possible to
deﬁne a distribution of zero entropy that the estimator will estimate of high entropy, secondly,
it is possible to deﬁne a distribution of arbitrary high entropy that the estimator will estimate of
zero entropy. This is due to the estimator conception: as it considers the timings of the events
to estimate their entropy, regular events (but with unpredictable data) will be estimated with
zero entropy, whereas irregular events (but with predictable data) will be estimated with high
entropy. These two distributions are given in the following Lemma 11 and 12.
Lemma 11. There exists a stateful distribution D0 such that H∞(D0) = 0, whose estimated
entropy by LINUX is high.
Proof. Let us deﬁne the 32-bits word distribution D0. On input a state i, D0 updates its
1 = 212, W i1 =
state to i + 1 and outputs a triple (i + 1, [W i1, W i2, W i3])
|bcos(i).220c| + W i−1
, W i2 = W i3 = 0. For each state, D0 outputs a 12-bytes input containing 0
bit of random data, we have H∞(D0) = 0 conditioned on the previous and the future outputs
(i.e. D0 is legitimate only with γi = 0 for all i). Then ∆i > 212 and Hi = 11.
Lemma 12. There exists a stateful distribution D1 such that H∞(D1) = 64, whose estimated
entropy by LINUX is null.
Proof. Let us deﬁne the 32-bits word distribution D1. On input a state i, D1 updates its state
to i + 1 and outputs a triple: (i + 1, [W i1, W i2, W i3]) $← D1(i), where Wi = i, W2
$←
U32. For each state, D1 outputs a 12-bytes input containing 8 bytes of random data, we have
H∞(D1) = 64 conditioned on the previous and the future outputs (i.e. D1 is legitimate with
γi = 64 for all i). Then δi = 1, δ2
Distribution Used in Attack based on the Mixing Function The generator LINUX uses
an internal Mixing function M, used to refresh the internal state with new input and to transfer
data between the pools. It is possible to deﬁne a distribution of arbitrary high entropy for which
the Mixing function is completely counter productive, i.e. the entropy of the internal state does
not increase, whatever the size of the input is. This is due to the conception of the Mixing
function and its linear structure. This distribution is given in Lemma 13.
Lemma 13. There exists a stateful distribution D2 such that H∞(D2) = 1, for which H∞(S) = 1
after t refresh, for arbitrary high t.
i = 0, ∆i = 0 and Hi = 0.
$← D0(i), where W 0
$← U32 and W3
1
i = 0, δ2
i−1 = 0, δ3
— 121 —
Chapter 7. Security Analysis
R0
4 ← B7,$ :
B0
S127, S0, S24, S50, S75, S102 :
S127 ⊕ S0 ⊕ S24 ⊕ S50 ⊕ S75 ⊕ S102 ⊕ R0(B0
S0
127 :
Position = 10
0) :
5 ← B3,b :
B0
R7
S0
127 :
S0, S24, S50, S75, S102 :
127 ⊕ S0 ⊕ S24 ⊕ S50 ⊕ S75 ⊕ S102 ⊕ R0(B0
S0
0) :
S0
126 :
⊕
⊕
T
⊕
⊕
⊕
T
Figure 7.2 – Attack Against the Mixing Function of LINUX
Proof. Let us deﬁne the byte distributions Bi,b and Bi,$:
Bi,b = {(0,··· , b,··· , 0), bi ← b, bj = 0 if i 6= j}
Bi,$ = {(b0,··· , b7), bi
$← {0, 1}, bj = 0 if i 6= j}
← B1,b, B10i+8
Let us deﬁne the 12 bytes distribution D2. On input a state i, D2 updates its state to i + 1 and
outputs 12 bytes:
(i + 1, [Bi0, . . . , Bi11]) $← D2(i), where B10i4 ← B7,$, B10i5 ← B3,b, B10i+2
B10i+6
6
For each state i, D2 outputs a 12-bytes input containing 1 bit of random data (for i = 0 mod 10)
or 0 bit of random data (for i 6= 0 mod 10). If d = 0, k = 127 and S is known, and noting
St = refresh(S, refresh(St−1, [Bt−1
11 ])), St = St0, . . . , St127, then St contains 1 random bit
in word St127, at position 10, for all t. Distribution D2 outputs B0
5 are illustrated in
Figure 7.2.
10 ← B0,b, with b = Bi4,7
, . . . , Bt−1
4 and B0
0
← B2,b, B10i+4
7
← B5,b,
4
Attacks Against the Robustness of LINUX
In this section we describe attacks on LINUX that prove Theorem 21. The ﬁrst three attacks use
distributions (described in Lemma 11 and Lemma 12) that fool the Entropy Estimator and the
last attack uses the distribution for which the Mixing function is counter productive (described
in Lemma 13). For this last attack, we show indeed that LINUX is not even backward secure.
Remark 5. It is important to mention that our attacks do not use any computation of the
adversary A that is correlated with the hash function family HK. Note however that the attack
based on the mixing function uses as a prerequisite that computation of the adversary A is done
knowing the deﬁnition of the mixing function. In particular, the set {0, 1, 25, 51, 76, 103} that
is used to mix new inputs in the internal state could have been randomly chosen and selected
as seed. In this situation, the proposed attack does not ﬁt in the security model because the
assumption about the independence between seed and the input distribution is not satisﬁed.
Attacks Based on the Entropy Estimator As shown in Section 7.2, it is possible to build
a distribution D0 of null entropy for which the estimated entropy is high (cf. Lemma 11) and
— 122 —
7.2. Security of Linux Generators
a distribution D1 of high entropy for which the estimated entropy is null (cf. Lemma 12). It is
then possible to mount attacks on both /dev/random and /dev/urandom, which show that these
two generators are not robust. At ﬁrst we describe two attacks that use the blocking behavior on
input, one attack on /dev/random and one attack on /dev/urandom and secondly we describe
an attack (that works on both /dev/random and /dev/urandom) that does not use this behavior
but uses the way entropy estimation evolves when data is transferred between the pools.
/dev/random is not robust. Let us consider an adversary A against the robustness of the
generator /dev/random, and thus in the game ROB(γ∗), that makes the following oracle queries:
one get-state, several next-ror, several D-refresh and one ﬁnal next-ror.
Then the state (Si, Sr, Su), the parameters k, d, Ei, Eu, Er and the counter c deﬁned in ROB(γ∗)
evolve the following way:
• get-state: After a state compromise, A knows all parameters (but needs Si, Sr, Ei, Er)
and c = 0.
• next-ror: After bEi/10c + bEr/10c queries to next-ror, Ei = Er = 0, A knows Si and Sr
and c = 0.
• D-refresh: In a ﬁrst stage, A refreshes LINUX with input from D0. After 300 queries,
Ei = 3584 and Er = 0. A knows Si and Sr and c = 0.
$← U128. As Ei = 3584, these inputs
In a second stage, A refreshes LINUX with input J
are ignored as long as I contains less than 4096 bytes. After 30 queries, A knows Si and
Sr and c = 3840.
• next-ror: Since Er = 0, a transfer is necessary between Si and Sr before generating R.
Since Ei = 3584, then αr = 10, such a transfer happens. But as A knows Si and Sr, then
A knows R.
Therefore, in the game ROB(γ∗) with b = 0, A obtains a 10-bytes string in the last next-ror-
oracle that is predictable, whereas when b = 1, this event occurs only with probability 2−80. It
is therefore straightforward for A to distinguish the real and the ideal world.
The attack on /dev/urandom is very similar to the previous one, using the blocking behavior on
input.
/dev/urandom is not robust. Similarly, let us consider an adversary A against the robustness
of the generator /dev/urandom in the game ROB(γ∗) that makes the following oracle queries: one
get-state that allows it to know Si, Su, Ei, Eu; bEi/10c+bEu/10c next-ror, making Ei = Eu = 0;
100 D-refresh with D1; and one next-ror, so that R will only rely on Su as no transfer is done
between Si and Su since Ei = 0. Then A is able to generate a predictable output R and to
distinguish the real and the ideal worlds in ROB(γ∗).
Now we present a third attack, on both /dev/random and /dev/urandom, that exploits the way
entropy estimation evolves when data is transferred between the input pool and the output pools.
We describe it for /dev/random, but this attack is indeed exactly the same for /dev/urandom.
/dev/random and /dev/urandom are not robust. Let us consider an adversary A against