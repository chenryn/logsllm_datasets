values  coming  from  a  replication  domain.    Once  a 
replication domain element is determined to be faulty, 
it  must  be  removed  from  its  replication  domain  to 
preserve  confidential  communications. 
  Currently, 
ITDOS  does  not  replace  replication  domain  elements 
that it determines to be faulty; it merely removes them 
from 
to  be 
implemented. 
the  system  -  replacement  remains 
The  Group  Manager  handles  replication  domain 
membership  and  virtual  connection  management  in 
ITDOS.  The Group Manager consists of a replication 
domain  of  Group  Manager  processes.  Each  Group 
Manager replication domain element is not a CORBA 
server  since  the  connection  management  functions  as 
part  of  the  middleware  transport,  rather  than  at  the 
application  level.    These  processes  work  together  to 
regulate  replication  domain  formation,  replication 
domain  membership,  and  connection  establishment 
between clients and servers.  The Group Manager also 
provides 
(called 
communication keys), used to protect communications. 
The  ITDOS  prototype  is  built  on  the  ACE  ORB 
(TAO)  [38],  which  is  an  open-source  CORBA  ORB. 
The target platforms include Solaris and Linux.  
session  keys 
symmetric 
the 
Threats 
2.1 
The ITDOS system protects against any threats that 
would cause an observable deviation in expected server 
behavior.  ITDOS  relies  upon  the  underlying  BFT 
multicast  protocol  to  tolerate  f  simultaneous  protocol 
failures and upon the voting mechanism to detect and 
mask faulty values. 
Provided that no more than f simultaneous  failures 
occur, ITDOS guarantees service availability, integrity, 
the 
and communications confidentiality.  However, there is 
a  caveat  to  the  confidentiality  guarantee.    Since 
symmetric  keys  protecting 
traffic  provide 
confidentiality,  a  compromise  of  a  replicated  server 
provides keys to all the traffic within groups of which 
that server is a member, until the keys can be reissued 
faulty  server. 
without 
Furthermore,  a  malicious 
that 
remains 
undetected  can  leak  server  state  to  unauthorized 
recipients. 
the  participation  of 
the 
server 
While  the  underlying  BFT  protocol  provides  some 
defense  against  DoS  attacks  against 
individual 
replication domain elements [7], ITDOS is not resilient 
against unrestricted DoS attacks. 
used 
that 
integrity, 
algorithms 
cryptographic 
Assumptions 
and  non-repudiation  of 
2.2 
The  ITDOS  system  is  constrained  by  several 
assumptions that provide a basis for our claims. These 
assumptions  cover  the  operating  environment,  the 
technologies  used,  and  other  security  measures  that 
may  be  required  for  a  fully  operational  system.  The 
following assumptions apply: 
•  The network does not partition such that more than 
f of the replicated servers becomes unreachable [6]. 
•  The 
for 
authentication [33, 34] and confidentiality [12]  remain 
authentication, 
unbroken 
so 
confidentiality 
ITDOS 
messages are preserved. 
•  There will not be more than f simultaneous faults 
in a replication domain, where the number of servers in 
the replicated group is greater than (3f + 1) [4]. 
•  The deployment environment is not susceptible to 
common-mode 
failures 
supports 
language  and 
implementation  diversity 
platform.  
• 
correct processes will eventually deliver a message. 
•  Correct servers exhibit deterministic behavior. 
•  The  authentication  tokens  for  each  process  are 
adequately  protected  and  only  available  to  authorized 
users.  
•  Additional  assumptions  driven  by  the  Byzantine 
fault tolerant protocol [7]  
If  one  correct  process  delivers  a  message,  all 
since 
in  both 
ITDOS 
3. Architectural Features 
issues  encountered 
This  section  discusses  in  more  detail  some  of  the 
technical 
in  designing  and 
implementing ITDOS.  Figure 2 shows an expansion of 
the  Secure  Multicast  Inter  ORB  Protocol  (SMIOP) 
stack,  providing  an  exploded  view  of  integrating  a 
Byzantine  Fault  Tolerant  Multicast  into  TAO.    The 
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:17 UTC from IEEE Xplore.  Restrictions apply. 
following  sections  discuss  many  Figure  2  elements.  
ITDOS  provides  connection 
(ITDOS 
Sockets) on top of a Byzantine fault tolerant multicast 
protocol  (Secure  Reliable  Multicast),  which,  in  turn, 
uses  IP  Multicast  to  send  messages  to  a  group  of 
processes.    The  SMIOP  Pluggable  protocol  allows  us 
to integrate the transport with TAO. 
semantics 
SMIOP
Replication Domain Element
ITDOS Pluggable
Protocol
Marshal
Application
Object
A
Object
B
Object
C
Group
Mgr
IT ORB
Connection
Manager
Voter
SRM
Socket
ITDOS
Sockets
Queue Management
SMIOP Transport
Secure Reliable Multicast
IP Multicast
Figure 2.  ITDOS Protocol Stack 
Secure Reliable Multicast 
3.1 
Our  project  plan  was  to  adapt  and  integrate  an 
existing BFT multicast protocol rather than create our 
own.  In the literature of BFT multicast protocols, we 
encountered 
two  basic  models  of  client-server 
communication:  message passing and request/response 
protocols.    The  message  passing  protocols  essentially 
provide a transport that delivers messages to a group in 
total-order;  every  member  of  the  group  receives  all 
messages  sent  to  the  group  in  the  same  sequence.  
These  protocols  depend  upon  virtual  synchrony  to 
accomplish  this  task,  expelling members  of  the group 
that  are  not  participating  according  to  the  protocol 
specification  to  make  progress.    The  request/response 
protocol we encountered is modeled on a state-transfer 
paradigm. 
  The  protocol  attempts  to  deliver  all 
messages  to  the  replicas  in  the  group;  however, 
replicas are allowed to become unsynchronized.  In this 
case,  a  “faulty”  replica is  proactively  recovered  –  the 
replica’s  state  is  synchronized  with  the  rest  of  the 
replica  group  by  transferring  state  data  from  correct 
replicas.  
We  selected  the  BFT  mechanism  developed  by 
Miguel  Castro  and  Barbara  Liskov  [6].  Hereafter,  we 
refer to the protocol as “Castro-Liskov”.  The Castro-
Liskov protocol uses a state-transfer approach coupled 
with a request/response mechanism as the interface to 
its client-server protocol.  In a simplified explanation, a 
singleton  client  sends  an  invocation  message  to  a 
replica group.  The replicas decide on the total order of 
the message (among other client requests), and deliver 
it  to  the  application  to  be  executed.    Each  replica 
computes  the  response  and  delivers  it  to  the  client 
directly. The client waits for f + 1 replies with the same 
result; this is the result of the operation [6]. Each server 
is  a  state  machine,  keeping  its  state  in  a  contiguous 
block of memory. 
These 
two  characteristics,  state 
transfer  and 
request/response,  do  not  lend  themselves  easily  to  a 
CORBA  system.    (While  a  message  passing  protocol 
may  have  been  more  appropriate  to  the  ITDOS 
implementation,  we  could  not  obtain  a  prototype.) 
Object state synchronization could create performance 
problems,  and  create  scalability  issues.    Another 
difficulty  is  efficiently  obtaining  state  from  an  object 
implementation. 
  Additionally,  a  request/response 
protocol  must  support  concurrency  to  enable  nested 
invocations.  For example, if a replicated state machine 
processing  a  request  needs  to  also  send  a  request  (as 
part of the servant implementation), it must be able to 
receive  the  intermediate  reply  over  the  same  reliable 
and  totally  ordered  multicast  channel  on  which  it 
received  the  original  request,  before  returning  from 
that  original  request.    ITDOS  solves  both  the  state 
synchronization  and  concurrency  problems  with 
minimal modifications to the Castro-Liskov library.  
An  ITDOS server implements a message queue that 
is 
the  state  machine. 
  Whenever  Castro-Liskov 
synchronizes  the  replica  state,  the  message  queue  is 
synchronized. 
  Each  replication  domain  element 
maintains equivalent object state since each processes 
messages in the same order as delivered by the Castro-
Liskov  transport.  Obviously,  the  size  of  this  message 
queue is limited by the size of the contiguous block of 
memory; the message queue must be garbage-collected 
and  more  memory  made  available  for  incoming 
messages.  We are still developing the algorithm to do 
so;  however, 
this  step  essentially  adds  virtual 
synchrony  [2]  to  the  system  –  replicas  that  do  not 
participate  according 
the  queue  management 
protocol  must  be  expelled  to  make  progress.    It  is 
important  to  note  here  that  the  request/response 
protocol of Castro-Liskov is effectively changed into a 
message  passing  protocol.    The  original  intent  of 
Castro-Liskov,  which  is  to  eliminate  the  need  for 
virtual  synchrony  through  proactive  recovery  [6],  is 
somewhat  maligned.    However,  this  approach  seems 
the  best  way  to  integrate  Castro-Liskov  into  an  ORB 
architecture  and  provides  greater  scalability  for  large 
object servers. 
to 
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:16:17 UTC from IEEE Xplore.  Restrictions apply. 
protocol 
replication  domain  element  may  be  expelled  from  its 
replication  domain.    The  ordering  protocol  itself  can 
detect  faulty  servers  if  they  do  not  participate  in  the 
specified 
ITDOS 
implementation  does  not  modify  Castro-Liskov  to 
expel replicas based on faulty participation; in fact, one 
of the main features of Castro-Liskov is to keep faulty 
replicas  in  the  system  until  they  are  proactively 
recovered [6]. 
correctly. 
  The 
Connection Management 
3.3 
CORBA’s  General  Inter-ORB  Protocol  (GIOP) 
requires  connection  semantics  to  integrate  the  Castro-
Liskov transport into an ORB architecture; the ITDOS 
prototype  creates  virtual  connections  over  the  Castro-
Liskov transport layer.  Furthermore, state information 
like cryptographic keys, needs to be associated with a 
“connection”  abstraction.    This  necessitates  having  a 
mechanism  by  which  all  of  the  members  of  a 
replication  domain  can  open  a  connection  to  another 
replication  domain  with  multiple  members. 
  A 
centralized  service,  the  Group  Manager,  manages 
connections,  but  is  implemented  in  an  intrusion 
tolerant  manner.    The  Group  Manager  is  an  ITDOS 
replication  domain,  providing  high  availability  and 
integrity.  
To  allow  nested  invocations,  ITDOS  executes  the 
Castro-Liskov  transport as  a  message  delivery  system 
running  in  one  thread  of  the  CORBA  server  process.  
All  messages  sent  to  the  replication  domain  are 
delivered through this thread to the ORB thread.  The 
reply  expected  at  the  Castro-Liskov  layer  is  a  static 
reply that acts as an acknowledgement message for the 
protocol.  The CORBA reply is sent to the client as all 
messages  are  sent  to  that  client  –  through the  Castro-
Liskov  transport  making  it  essentially  unidirectional.  
There  are  two  threads  for  each  replication  domain 
element;  one  for  ORB  execution  and  one  for  Castro-
Liskov  message  delivery.    This  technique  allows 
ITDOS  to  support  nested  invocations  where  a  server 
needs  to  receive  a  reply  on  the  Castro-Liskov  thread 
from an invocation before completing its execution for 
a particular request. 
3.2 
Ordering  group 
Group Membership 
  BFT 
cardinality  directly 
impacts 
performance  and  scalability. 
total-ordering 
protocols  are  expensive;  additionally,  the  number  of 
messages  exchanged  is  directly  related  to  the number 
of  members  in  the  ordering  group.    Given  the  non-
linear performance penalties in large ordering groups, 
the ordering groups should be as small as possible.  For 
that reason,  clients  cannot  be  in  the  same  ordering 
group as  the  servers.    With the  transitive  nature  of 
nested invocations, all the hosts of the entire system 
would  then  tend  to  aggregate  into  some  small 
number of  very large groups.  Of course, the more 
interconnected  the  architecture,  the  larger  these 
groups  will  be  required  to  be,  and  therefore,  the 
higher  the  performance  penalty.    In  ITDOS,  the 
replication domain is the ordering group; the clients 
do not participate in the message ordering with the 
servers.    While this approach limits  the  size  of  the 