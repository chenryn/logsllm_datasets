暂时没有进行优化的情况下，CPU使用情况如下    
```    
Cpu(s): 35.2%us, 17.4%sy, 13.8%ni, 33.2%id,  0.3%wa,  0.0%hi,  0.1%si,  0.0%st    
主机上其他不相干进程的开销    
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                                                                                             
16725 digoal    20   0 18.4g  11m  948 S 320.6  0.0   1:15.63 pgbench -M prepared -n -r -P 1 -f ./test.sql -c 256 -j 256 -T 120                                                                                                                  
18411 root      20   0  445m  58m 7048 R 98.8  0.0   0:03.25                                                            
18434 root      20   0  445m  58m 7040 R 87.5  0.0   0:02.71     
```    
持续压测like，产生2亿文章的LIKE数据，然后进入测试2。    
### 生成用户关系数据    
1\. 用户ID范围    
1-1亿    
2\. 用户好友分布    
90% 100个以下，8%长尾分布300-1000, 2% 1000-10000    
```    
关系表    
create table user_like_agg(uid int8 primary key, like_who int8[]);    
产生指定元素个数范围的数组    
create or replace function gen_uids(c1 int, c2 int) returns int8[] as    
$$     
select array(select (random()*100000000)::int8 from generate_series(1, c1+(random()*(c2-c1))::int));    
$$ language sql strict;    
序列    
create sequence seq cache 100;    
```    
产生90%的用户关系    
```    
vi gen90.sql    
insert into user_like_agg select nextval('seq'), gen_uids(1,100);    
pgbench -M prepared -n -r -P 1 -f ./gen90.sql -c 100 -j 100 -t 900000    
```    
产生8%的用户关系    
```    
vi gen8.sql    
insert into user_like_agg select nextval('seq'), gen_uids(300,1000);    
pgbench -M prepared -n -r -P 1 -f ./gen8.sql -c 100 -j 100 -t 80000    
```    
产生2%的用户关系    
```    
vi gen2.sql    
insert into user_like_agg select nextval('seq'), gen_uids(1000,10000);    
pgbench -M prepared -n -r -P 1 -f ./gen2.sql -c 100 -j 100 -t 20000    
```    
最终生成1亿用户，占用123GB空间，2.7GB索引。    
```    
pipeline=#     
pipeline=# \dt+ user_like_agg     
                        List of relations    
 Schema |     Name      | Type  |  Owner   |  Size  | Description     
--------+---------------+-------+----------+--------+-------------    
 public | user_like_agg | table | postgres | 123 GB |     
(1 row)    
pipeline=# \di+ user_like_agg_pkey     
                                   List of relations    
 Schema |        Name        | Type  |  Owner   |     Table     |  Size   | Description     
--------+--------------------+-------+----------+---------------+---------+-------------    
 public | user_like_agg_pkey | index | postgres | user_like_agg | 2706 MB |     
(1 row)    
pipeline=# select count(*) from user_like_agg ;    
   count       
-----------    
 100000000    
(1 row)    
```    
## 压测2    
1\. 查询文章被谁like？    
2\. 查询文章被like了多少次？    
3\. 查询LIKE某文章的用户中，哪些是我的好友？    
压测脚本1, 查询文章被谁like？   
```    
vi test1.sql    
\setrandom id 1 200000000    
select who_like from cv_obj where id=:id;    
pgbench -M prepared -n -r -P 1 -f ./test1.sql -c 128 -j 128 -T 120    
```    
压测脚本2, 查询文章被like了多少次？     
```
vi test2.sql    
\setrandom id 1 200000000    
select like_cnt from cv_obj where id=:id;    
pgbench -M prepared -n -r -P 1 -f ./test2.sql -c 128 -j 128 -T 120    
```
压测脚本3, 查询LIKE某文章的用户中，哪些是我的好友？    
```    
vi test3.sql    
\setrandom id 1 200000000    
\setrandom uid 1 100000000    
select array_intersect(t1.who_like, t2.like_who) from (select who_like from cv_obj where id=:id) t1,(select array[like_who] as like_who from user_like_agg where uid=:uid) t2;    
pgbench -M prepared -n -r -P 1 -f ./test3.sql -c 128 -j 128 -T 120    
```    
压测结果1，查询文章被谁like？ 达到 101万/s 并不意外。    
```    
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 128
number of threads: 128
duration: 120 s
number of transactions actually processed: 121935264
latency average: 0.125 ms
latency stddev: 0.203 ms
tps = 1016035.198013 (including connections establishing)
tps = 1016243.580731 (excluding connections establishing)
statement latencies in milliseconds:
        0.001589        \setrandom id 1 1000000000
        0.123249        select who_like  from cv_obj where id=:id;
```    
压测结果2，查询文章被like了多少次？  104万/s。    
```    
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 128
number of threads: 128
duration: 120 s
number of transactions actually processed: 124966713
latency average: 0.122 ms
latency stddev: 0.204 ms
tps = 1041268.730790 (including connections establishing)
tps = 1041479.852625 (excluding connections establishing)
statement latencies in milliseconds:
        0.001708        \setrandom id 1 1000000000
        0.120069        select like_cnt from cv_obj where id=:id;
```    
压测结果3，查询LIKE某文的用户中，哪些是我的好友？  64.8万/s。    
```    
transaction type: Custom query
scaling factor: 1
query mode: prepared
number of clients: 128
number of threads: 128
duration: 120 s
number of transactions actually processed: 77802915
latency average: 0.196 ms
latency stddev: 1.649 ms
tps = 648273.025370 (including connections establishing)
tps = 648368.477278 (excluding connections establishing)
statement latencies in milliseconds:
        0.001719        \setrandom id 1 1000000000
        0.000695        \setrandom uid 1 100000000
        0.193728        select array_intersect(t1.who_like, t2.like_who) from (select who_like from cv_obj where id=:id) t1,(select array[like_who] as like_who from user_like_agg where uid=:uid) t2;
```    
## 优化思路
1\. 数组越长，一条记录占用的空间会越大，使用TOAST切片存储，可以有效的提高查询非数组字段的效率。   
```
例如
alter table cv_obj alter column who_like set (storage=extended);
```
2\. profiling，针对性的优化。   
3\. 压缩接口，降低PGLZ压缩CPU消耗。  
https://commitfest.postgresql.org/21/1294/   
## 小结    
微博、facebook最常用的操作：    
1\. 关注人或者喜欢某条消息、微博等。    
这个属于写操作，要求写入快，并且要求写入（LIKE或关注）后立即反映出来。    
2\. 查询好友列表    
为了查询快速，最快的方法是PK查询，但是一个人可能关注很多人，如果是查询多条记录，很显然会比较慢。    
因此考虑使用数组存储好友列表。    
但是，使用数组存储列表，又需要考虑写入速度的问题。    
所以使用流计算聚合是最好的，因为PG有流计算插件，可以在数据库中完成流计算。    
3\. 查询被关注的好友列表    
反向好友关系，同样要求查询快速，使用正向关系一样的方法。    
4\. 查询文章（微博）被关注的次数，被关注人，被关注的人里有哪些是我的好友。    
首先被关注的次数，实际上就是个计数器。为了提高查询速度，它必须是一个VALUE而不是查询时使用COUNT(*)进行聚合。    
查询文章（微博）被关注的人，为了提高查询速度，同样考虑使用数组存储。使用PG内置的流计算进行聚合。    
被关注的人里面有哪些是我的好友，这个问题就很简单了，好友关系与文章（微博）被关注人的两个数组求交集即可。    
使用PG的流计算解决了实时写入，实时聚合的问题。    
同时由于数据实时被聚合，所以几个查询需求就显得非常轻松。    
测试得到的性能指标（未优化）：    
1\. 关注微博（文章）    
17.7万/s，预计可以优化到30万。    
2\. 查询文章被谁like？  
101.6万/s    
3\. 查询文章被like了多少次？   
104.1万/s    
4\. 查询LIKE某文章的用户中，哪些是我的好友？    
64.8万/s    
![pic](20170512_02_pic_003.jpg)    
5\. 机器:    
（10W左右价位的X86，12*8TB SATA盘，1块SSD作为BCACHE）    
数据库内置流计算功能，是一件不错的事情。    
## 参考    
[《facebook linkbench 测试PostgreSQL社交关系图谱场景性能》](../201609/20160911_01.md)      
[《流计算风云再起 - PostgreSQL携PipelineDB力挺IoT》](../201612/20161220_01.md)      
[《PostgreSQL on Linux 最佳部署手册》](../201611/20161121_01.md)      
[《生成泊松、高斯、指数、随机分布数据 - PostgreSQL pg_bench 》](.../201506/20150618_01.md)   
[《PostgreSQL 流计算插件 - pipelinedb 1.x 参数配置介绍》](../201811/20181120_02.md)  
[《PostgreSQL pipelinedb 流计算插件 - IoT应用 - 实时轨迹聚合》](../201811/20181101_02.md)  
[《PostgreSQL 流计算插件pipelinedb sharding 集群版原理介绍 - 一个全功能的分布式流计算引擎》](../201803/20180314_04.md)  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")