1
HTTP IDS Evasions Revisited 
Daniel J. Roelker 
Abstract—This paper describes two general IDS evasion 
techniques and applies them to the HTTP protocol.  These 
techniques are illustrated using some older types of HTTP 
evasions and some new HTTP evasions. 
The different types of evasions occur in both the Request URI 
portion of the HTTP protocol and by using the protocol standard 
in HTTP/1.0 and HTTP/1.1. 
The evasions within the Request URI address evasion types 
possible in encoding and obfuscating the URL and parameter 
fields in the Request URI.  The various methods of valid URL 
encodings for both the Apache and Internet Information Server 
are explained and examples given for each type of encoding.  
HTTP IDS evasions are also demonstrated using the HTTP 
protocol properties against the IDS.  These evasions incorporate 
the request pipeline property and the content-encoding header.   
This paper should help explain how HTTP IDS evasions work 
and give the reader enough knowledge to generate their own 
HTTP IDS evasions using these general principles and examples.   
Index Terms—computer security, hypertext transfer protocol, 
intrusion detection, web scanning 
I. INTRODUCTION 
H 
TTP IDS evasions have been popular since Rain Forest 
Puppy’s (RFP) web scanner, whisker, was first released 
to the public [1].  Many of the original HTTP IDS evasions 
were contained in that first release, from multiple slashes that 
would obfuscate directories, to the more advanced evasions, 
like inserting HTTP/1.0 in the URL to evade an algorithm that 
an IDS might use to find the URL in a packet. 
 Besides the evasions that whisker presented, there were 
other types of HTTP obfuscations that were being propagated 
as well.  One of these was obfuscating a URL by using an 
absolute URI vs. a relative URI [2].  While these other types 
of evasions were interesting, they were not as evasive or 
popular as the basic whisker scans. 
 The next popular evasion came about with the public 
release by RFP of the UTF-8 unicode encoding exploit for the 
Microsoft Internet Information Server (IIS) [3].  Besides being 
a serious vulnerability for IIS, the unicode exploit also 
presented an encoding method for URLs in a way that had not 
been implemented in IDSs.  Up until this point, most IDSs had 
instituted safeguards against the previous whisker evasions of 
ASCII encoding and directory traversal, but did not protect 
against UTF-8 encoding of Unicode code points.  One of the 
more professional write-ups that explained this type of HTTP 
IDS evasion was done by Eric Hacker [4].  Some of the 
insights in Hacker’s paper are examined and explained in this 
paper as well.  We will take the points that Hacker illustrates 
and delve into what these encodings mean and how they can 
work together to provide more bizarre encodings. 
 The other type of HTTP IDS evasions that are covered in 
this paper utilizes the HTTP protocol properties.  One of these 
evasions uses the property of request pipelining.  The other 
evasion uses the content-encoding header to encoding HTTP 
request parameters  in a request payload. 
II. IDS HTTP PROTOCOL ANALYSIS 
In order for an IDS to handle URL attacks, the IDS must 
inspect the HTTP URL field for malicious attacks.  The two 
most popular IDS inspection methodologies, pattern matching 
and protocol analysis, currently behave similarly because each 
methodology must search for malicious URLs and this entails 
some form of pattern matching and some form of HTTP 
protocol analysis. 
  In the beginning, the differences between these two 
methodologies were what you would expect.  The protocol 
analysis methodology only searched the URL field of the 
HTTP stream for malicious URLs, while the pattern matching 
methodology searched the whole packet for the malicious 
URL. 
The two methodologies performed similarly until the 
malicious URLs started to be encoded and obfuscated.  At this 
point, the protocol analysis methodology merely had to add 
the appropriate decoding algorithms to the URL field.  They 
had already built in HTTP protocol decoding to their engine.  
But the pattern matching methodology had no way of 
knowing which part of the packet to normalize.  The pattern 
matching methodology had to incorporate some form of 
protocol analysis to find the URL field so that it could apply 
the appropriate decoding algorithms.  A form of HTTP 
protocol analysis was added to the pattern matching 
methodology and the two methodologies once again began to 
behave similarly. 
Because of the current similarities in these IDS 
methodologies, the HTTP IDS evasions that are discussed 
here apply to both types. 
The first general IDS evasion is invalid protocol parsing.  
For example, if the HTTP URL is not found correctly then the 
malicious URLs will not be detected if they are encoded.  The 
reason being that if the IDS does not find the URL, it cannot 
decode it. 
If the URL is found correctly, the IDS must know the 
D. J. Roelker is with the IDS development team at Sourcefire Inc., 
Columbia, MD 21044 USA (email: PI:EMAIL). 
2
proper decoding algorithms, otherwise the URL will again be 
decoded incorrectly.  This is the second general type of IDS 
evasion, invalid protocol field decoding. 
A. Invalid Protocol Parsing 
IDS evasions that use invalid protocol parsing are 
demonstrated by RFP’s whisker[1] and Bob Graham’s 
SideStep[5].  The difference between these two programs are 
that whisker used flawed IDS protocol parsing to evade 
detection, whereas SideStep used valid aspects of application 
layer protocols to evade IDSs that had implemented naïve 
protocol decoders. 
In this spirit, invalid protocol parsing evasions are 
particularly effective against two HTTP protocol fields, the 
URL and the URL parameters. 
For example, if the IDS HTTP decoder assumes that there 
is only one URL per HTTP request packet, then if  two URLs 
are sent in one packet, the IDS does not parse the second URL 
correctly.  This is explained in the section on request 
pipelining evasions.  
B. Invalid Protocol Field Decoding 
Invalid protocol field decoding tests an IDS capability in the 
various types of encoding and normalization that is capable in 
a specific protocol field. 
In the case of HTTP, this is most clearly seen in the URL 
field.  An IDS can be tested for compliance to HTTP RFC 
encoding standards and also against the unique encoding types 
for different web servers, like IIS.  If the IDS cannot decode 
certain types of URL encoding, then the attacker will use 
these encodings to bypass detection of malicious URLs. 
Another method of invalid protocol field decoding for 
HTTP is through directory obfuscation.  Directory obfuscation 
is accomplished through the manipulation of directory 
properties.  For example, /cgi-bin/phf can be manipulated 
using multiple slashes instead of one slash, or it could use 
directory traversals to obfuscate the exact directory path. 
It is important to realize that directory obfuscation can only 
obscure a malicious URL if the IDS looks for a URL that 
includes at least one directory besides the file to access.  In the 
instance of our attack example, /cgi-bin/phf, directory 
obfuscation will work because the IDS is looking for the 
“phf” file in the “cgi-bin” directory.  However, if the IDS is 
looking for just the “phf” file, the directory obfuscation would 
not work, since there is no directory path in that particular 
content.   
III. INVALID PROTOCOL FIELD DECODING 
URL obfuscation starts out with the various types of 
encoding methods that HTTP servers accept.  Admittedly, 
most of the encoding types are attributed to the IIS server, but 
for the sake of completeness, every type of encoding should 
be tested against each HTTP server. 
The idea behind using URL encoding for obfuscating web 
attacks stems from the lack of research in most IDS 
methodologies to adequately define and implement the 
different encoding types for web servers. 
If an IDS cannot decode an encoded type for a web server, 
then the IDS cannot tell whether a URL is malicious.  Both 
pattern matching and protocol inspection IDS technologies 
have this problem. 
There are only two RFC standards for encoding a Request 
URI: hex encoding and UTF-8 Unicode encoding.  These two 
methods are encoded using the ‘%’ character to escape a one 
encoded byte.  It should also be noted that these are the only 
two URL encoding types that Apache accepts. 
Most of the other encoding types that we will be looking at 
are server specific and non-RFC compliant.  The Microsoft 
IIS web server falls in this category.  
URL obfuscations are also covered in this section and 
follow the different encodings. 
A. Hex Encoding 
The hex encoding method is one of the RFC compliant 
ways for encoding a URL.  It is also the simplest method of 
encoding a URL.  The encoding method consists of escaping a 
hexadecimal byte value for the encoded character with a ‘%’.  
If we wanted to hex encode a capital A (ASCII map 
hexadecimal value of 0x41), the encoding would look like the 
following: 
• 
%41 = ‘A’ 
B.  Double Percent Hex Encoding 
Double percent hex encoding is based on the normal method 
of hex encoding.  The percent is encoded using hex encoding 
followed by the hexadecimal byte value to be encoded.   To 
encode a capital A, the encoding is: 
• 
%2541 = ‘A’ 
As can be seen, the percent is encoded with the %25 (this 
equals a ‘%’).  The value is then decoded again with the value 
this time being %41 (this equals the ‘A’). 
This encoding is supported by Microsoft IIS. 
C. Double Nibble Hex Encoding 
Double nibble hex encoding is based on the standard hex 
encoding method.  Each hexadecimal nibble value is encoded 
using the standard hex encoding.  For example, to encode a 
capital A, the encoding would be: 
• 
%%34%31 = ‘A’ 
The normal hex encoding for A is %41.  How double nibble 
hex encoding works, is that the hexadecimal nibble values are 
each encoded in the normal hex encoding format.  So, the first 
nibble, 4, is encoded as %34 (the ASCII value for the numeral 
4), and the second nibble, 1, is encoded as %31 (the ASCII 
value for the numeral 1). 
 In the first URL decoding pass the nibble values are 
translated into the numerals 4 and 1.  Since the 4 and 1 are 
preceded by a %, the second pass recognizes %41 and 
decodes that as a capital A. 
 This encoding is supported by Microsoft IIS. 
D. First Nibble Hex Encoding 
First nibble hex encoding is very similar to double nibble 
hex encoding.  The difference is that only the first nibble is 
3
encoded.  So a capital A, instead of being encoded %%34%31 
for double nibble hex, is encoded in the following example 
using first nibble hex encoding: 
• 
%%341 = ‘A’ 
As before, during the first URL decoding pass the %34 is 
decoded as the numeral 4, which leaves %41 for the second 
pass.   During the second pass, the %41 is decoded as a capital 
A. 
 This encoding is supported by Microsoft IIS. 
E. Second Nibble Hex Encoding 
Second nibble hex encoding is exactly the same as first 
nibble hex encoding, except the second hexadecimal nibble 
value is encoded with normal hex encoding.  So a capital A is 
encoded as: 
• 
%4%31 = ‘A’ 
The %31 gets decoded to a numeral 1 in the first decoding 
pass, which then the %41 gets decoded as a capital ‘A’. 
 This encoding is supported by Microsoft IIS. 