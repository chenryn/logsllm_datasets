0.5%
5%
27%
21%
23%
42%
Table 3: Percentage (%) of campaigns that have different ratios
of outliers after clustering.
)
f
d
c
(
s
n
g
a
p
m
a
c
f
i
o
%
0.8
1
0
0
50
100
200
250
300
150
std (hour)
(b)
0.4
0.6
% of botnets (cdf)
(a)
Figure 13: (a) Similarity of email content shingles (b) CDF of
sending time standard variations (in hours) for each campaign.
most common k shingles (where k varies as showed in the ﬁgure).
For the majority of campaigns (> 60%), most emails share at least
one shingle. However, the likelihood of these emails sharing all
shingles is very low. In fact, around 50% of the campaigns have
no two emails sharing 10 common shingles, suggesting that the
contents are quite different even though their target web pages are
similar.
7.2.2
Similarity of Sending Time
We proceed to examine the synchronous degree of spam send-
ing time for each campaign. For each campaign, we compute the
standard deviation (std) of spam email sending time (Figure 13(b)).
50% of campaigns have std less than 1.81 hours, meaning they sent
almost simultaneously and were likely triggered by a single com-
mand. The rest of the campaigns have a larger variation, suggesting
those bots might start sending whenever they come online. Over-
all, 90% of campaigns have stds less than 24 hours and were likely
located at different time zones.
7.2.3
Similarity of Email Sending Behavior
We now broaden our analysis to the set of email sending features
discussed in Section 7.1.2. Our goal is to systematically investigate
whether botnet hosts could be grouped into a well-formed cluster
(in the previously deﬁned three-dimensional coordinate space). For
each campaign, we use a Gaussian model with full covariance ma-
trix to model the data and learn the Gaussian parameters.
Table 3 lists the percentage of outliers that do not ﬁt into the
learned Gaussian models. We see that for each spam campaign,
the host sending patterns are generally well clustered (with <10%
outliers). Figure 14 shows two such clusters. Figure 14 (a) in-
volves 191 botnet hosts with 9 outliers. The majority of the hosts
are tightly clustered by having a similar number of recipients per
-1
(a)
(b)
Figure 14: Two examples of well-clustered botnets. Outliers are
shown using circles.
email. These hosts sent emails with a long To or Cc list. The second
example in Figure 14 (b) shows a campaign with 162 hosts span-
ning 80 ASes. A unique aspect with regard to this particular exam-
ple is that the participating hosts (except for the 4 outliers) shared
a constant connection rate (3 connections per second) in their com-
munication with the server, suggesting that the botnet software may
have applied rate-control in initiating connections.
For the few cases with a high number of outliers, we found that
many of them are bi-modal. We are investigating these cases further
to understand whether this could be attributed to the heterogenous
nature of bot hosts in terms of computation power, network access
speed, etc.
7.3 Comparison of Different Campaigns
In this section, we study the overlaps among different spam cam-
paigns and compare the botnet host email sending patterns. Sec-
tion 5 showed that a large number of campaigns share the same
domain-agnostic regular expression signatures (refer to Figure 7
(b)). So the ﬁrst question we explore is whether the correspond-
ing botnets essentially correspond to the same set of hosts. For
each domain-agnostic signature, we identify the set of spam cam-
paigns (say a total of k) that all share this signature. We then plot
in Figure 15 the ratio of the number of unique IPs across the k bot-
nets to the sum of their IPs as a function of k. Quite surprisingly,
s
P
I
f
o
r
e
b
m
u
n
l
a
t
o
t
/
s
P
I
e
u
q
n
u
i
f
o
r
e
b
m
u
N
1.1
1
0.9
0.8
0.7
0.6
0.5
100
103
Num. of campaigns per domain agnostic signature
102
101
Figure 15: For each domain-agnostic signature, we show the
number of botnets that share the signature vs the ratio of
unique IPs to all IPs.
(a) Non-polymorphic case
(b) Polymorphic case
-1
-1
Figure 16: Super clusters obtained by aggregating the June
2007 botnet sending patterns.
the ratio is close to 1 when k is small, meaning botnets sharing a
domain-agnostic signature barely overlap with each other in most
of the cases. With k increasing, the ratio increased gradually to 0.8,
meaning 20% of the botnet IPs participated in multiple campaigns
characterized by the same signature.
Finally, we examine the similarity of sending patterns across bot-
net campaigns using the learned Gaussian models in Section 7.2.3.
Speciﬁcally, we group individual botnet clusters into super clusters
based on the similarity of the estimated mean; we discard clus-
ters whose covariance matrices are not compact (and hence the
data is well spread out). Interestingly, for botnets that sent non-
polymorphic URLs, the resulting super clusters correspond to three
speciﬁc operating modes (Figure 16 (a)): in two cases, the number
of recipients per email feature is held at a constant value, while
the connection rate feature varies signiﬁcantly. The converse of the
above is evident in the third (middle) cluster. For the botnets that
sent polymorphic URLs, they map to only two models. The small
number of super clusters suggests spammers may all utilize a few
common programs to launch botnet spamming attacks.
7.4 Correlation with Scanning Trafﬁc
We now analyze the network scanning behavior of the identiﬁed
botnet hosts using the distributed telescope data. In particular, we
use the Dshield trace collected in 2006 over a large network of
more than 400,000 hosts [7]. This log contains failed connection
attempts rejected by ﬁrewalls and scanning trafﬁc to non-existing
hosts. In our study, we focus on the source IP address and the port
number ﬁelds and we consider the botnet IPs generated using the
dataset from November 2006.
Due to dynamic IP address assignment, using IP address as a
host identiﬁer for correlation is not robust. Therefore, for dynamic
botnet IP addresses, instead of correlating the exact addresses, we
check all the scanning activities from the corresponding dynamic
IP ranges obtained from [24]. Using the dynamic IP ranges to-
s
t
s
o
h
t
e
n
t
o
b
i
g
n
d
n
o
p
s
e
r
r
o
c
f
o
n
o
i
t
c
a
r
F
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
August scanning
November scanning
1026 1027 135 139 1433 1434 2296733770 445 8886 25
Scanning port number
Figure 17: Scanning trafﬁc from botnet IPs captured by
Dshield.
gether with the remaining “likely static" IPs, we plot in Figure 17
the number of scans originating from these IP addresses into a set
of popular scanning destination ports in Aug 2006 and Nov 2006,
respectively. Besides ports 1026, 1027 and 25, all other ports are
used for exploiting host vulnerabilities. For these ports, the amount
of scanning trafﬁc in August is higher than in November, when
these botnet IPs were actually used to send spam. One reason could
be that botnet attacks have different phases. In August, they were
used to actively seek victim computers with the purpose of expand-
ing the botnet size. In November, these botnets reached their tar-
get size and were used to launch spam attacks. Hence, monitoring
scanning trafﬁc in advance could be potentially helpful in defend-
ing against botnet-based spam attacks and is an interesting future
topic to investigate.
8. DISCUSSION
Although, in this work, AutoRE serves as a post-mortem tool
for botnet spam detection, it has the potential to work in real time
mode. Due to the aggressive sampling rate (1:25000), the number
of data points in our dataset was not sufﬁcient to perform real-time
experiments. But given a live mail feed, AutoRE can be designed to
produce signatures as soon as there is enough information to con-
clude that a distributed botnet spam campaign has commenced. In-
deed, we have demonstrated that the signatures of June 2007 caught
a non-trivial portion of July 2007’s spam, suggesting that AutoRE
can potentially stop a large portion of botnet spam in real-time ser-
vice. The success of this approach depends on how quickly signa-
tures can be generated and deployed, and how long a spam cam-
paign lasts. The extension of AutoRE into a real time setting is left
for future work.
Spammers may attempt to craft emails to evade the AutoRE URL
selection process. For example, they may add legitimate URLs to
confuse the URL selection process. Since spammers have no con-
trol of the sending frequency of legitimate URLs, it will be hard for
them to select which URLs to include. A popular URL would be
discarded as background noise, and a rarely used URL will stand
out as a spike for identifying the botnet 7. Spammers may also
wish to pollute the "bursty" feature by sending a spam URL from
a few hosts before launching a large-scale attack. Such pollution
can be easily detected by a more robust signal processing method-
ology that captures signal spikes in the existence of low frequency
background noise.
In the extreme case, spammers may wish to evade detection by
having no patterns in their URLs. For example, each URL points
to just a domain string (e.g., a.com, b.com, etc). We expect such
a scenario to be rare as the cost of registering domains makes this
economically less attractive to spammers.
7In this case, the legitimate URL itself servers as a signature
AutoRE leverages the “bursty" and “distributed" features of bot-
net attacks for detection. Legitimate emails sent by a big company
advertising a product or event could also be bursty. But they will
be unlikely sent from hosts spanning more than a few ASes. One
false positive case could be email ﬂash crowd, where people for-
ward each other a few popular URL links. We expect such events
to be very rare. In our experience of using three months of data and
the source AS threshold of 20, we did not encounter a single such
event. Studying legitimate email trafﬁc can potentially guide the
source AS number threshold selection in the AutoRE framework.
More sophisticated spammers may leverage URL redirection tech-
niques to hide the real spamming Web sites. In this case, hosts from
a botnet may send out seemingly unrelated URLs, but these URLs
all redirect to the same ﬁnal destination. To detect such botnets,
we can potentially construct an entire redirection path consisting of
a sequence of IP addresses and intermediate URLs, and then ap-
ply AutoRE in a similar way to the redirection paths. We do not
advocate this approach because constructing the redirection paths
requires extensive querying of the destination URLs. Such process
might encourage spammers to send even more spam, as they might
view the visiting trafﬁc to be from users (and regard these users as
vulnerable to spam or phishing).
9. CONCLUSION
In this paper, we presented AutoRE, a framework that automat-
ically generates URL signatures for spamming botnet detection.
AutoRE requires neither pre-classiﬁed inputs nor other training data
or white lists. Furthermore, AutoRE generates regular expression
signatures, which were previously written by human experts only.
Using sampled emails from Hotmail, AutoRE identiﬁed 7,721 botnet-
based spam campaigns, comprising 340,050 distinct IP addresses
spanning 5,916 ASes. The false positive rate of applying AutoRE
signatures for botnet spam detection is less than 0.002, and the false
positive rate of botnet host detection is less than 0.005. We expect
the generated spam signatures and the botnet membership infor-
mation to be useful for capturing future spam and reducing other
malicious Internet activities.
Our extensive analysis of the identiﬁed botnets revealed several
important ﬁndings. First, our exploration showed botnet hosts are
wide-spread across the Internet, with no distinctive sending pat-
terns from normal servers when viewed individually. This suggests
that detecting and blacklisting individual botnet host will continue
to remain a challenging task. Second, in our work, we demon-
strated the existence of botnet spam signatures and the feasibility
of detecting botnet hosts using them. Our analysis also shows that
botnet host sending patterns, such as the number of recipients per
email, connection rates, and the frequency of sending to invalid
users, are clusterable and their sending times are synchronized.
Thus an interesting future direction is to further explore mecha-
nisms that capture aggregated activities of botnets. Finally, compar-
ison of spam trafﬁc patterns from 2007 to 2006 clearly showed that
botnets are evolving and getting increasingly sophisticated. For ex-
ample, the adoption of polymorphic URLs increased signiﬁcantly,
and the number of static IP address based bots doubled from Nov
2006 to July 2007. These trends for evading existing detection sys-
tems suggests that we need to take a holistic view of various mech-
anisms and explore the invariable attack features in order to get an
upper hand in the spam arms race.
10. REFERENCES
[1] M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch. Replacing sufﬁx trees
with enhanced sufﬁx arrays. J. of Discrete Algorithms, 2(1), 2004.
[2] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker.
Spamscatter: Characterizing Internet scam hosting infrastructure. In
14th conference on USENIX Security Symposium, 2007.
[3] T. Berners-Lee, R. Fielding, and L. Masinter. Uniform resource
identiﬁers (URI): Generic syntax. RFC 2396, 1998.
[4] K. Chiang and L. Lloyd. A case study of the Rustock rootkit and
spam bot. In The First Workshop in Understanding Botnets, 2007.
[5] D. Dagon, C. Zou, and W. Lee. Modeling botnet propagation using
time zones. In Proc. of the 13th Annual Network and Distributed
System Security Symposium (NDSS), 2006.
[6] N. Daswani, M. Stoppelman, and the Google click quality and
security teams. The anatomy of Clickbot.A. In The First Workshop in
Understanding Botnets, 2007.
[7] Dshield: Cooperative network security community.
[8] Dynablock dynamic IP list. http://www.njabl.org/, recently
aquired by spamhaus, http://www.spamhaus.org/pbl/index.lasso,
2007.
[9] D. Fetterly, M. Manasse, M. Najork, and J. L. Wiener. A large-scale
study of the evolution of web pages. Softw. Pract. Exper., 34(2),
2004.
[10] T. Holz, M. Steiner, F. Dahl, E. Biersack, and F. Freiling.
Measurements and mitigation of peer-to-peer-based botnets: A case
study on storm worm. In LEET 08: First USENIX Workshop on
Large-Scale Exploits and Emergent Threats, 2008.
[11] C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, and S. Savage.
The Heisenbot uncertainty problem: Challenges in separating bots
from chaff. In LEET ’08: First USENIX Workshop on Large-Scale
Exploits and Emergent Threats, 2008.
[12] H.-A. Kim and B. Karp. Autograph: Toward automated, distributed
worm signature detection. In the 13th conference on USENIX
Security Symposium, 2004.
[13] C. Kreibich and J. Crowcroft. Honeycomb: Creating intrusion
detection signatures using honeypots. In 2nd Workshop on Hot Topics
in Networks (HotNets-II), 2003.
[14] F. Li and M.-H. Hsieh. An empirical study of clustering behavior of
spammers and group-based anti-spam strategies. In CEAS 2006:
Proceedings of the 3rd conference on email and anti-spam, 2006.
[15] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez. Hamsa: Fast
signature generation for zero-day polymorphic worm with provable
attack resilience. In IEEE Symposium on Security and Privacy, 2006.
[16] J. Newsome, B. Karp, and D. Song. Polygraph: Automatically
generating signatures for polymorphic worms. In Proceedings of the
2005 IEEE Symposium on Security and Privacy, 2005.
[17] M. A. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multifaceted
approach to understanding the botnet phenomenon. In IMC ’06:
Proceedings of the 6th ACM SIGCOMM conference on Internet
measurement, 2006.
[18] A. Ramachandran, D. Dagon, and N. Feamster. Can DNS based
blacklists keep up with bots? In Conference on Email and
Anti-Spam, 2006.
[19] A. Ramachandran and N. Feamster. Understanding the network-level
behavior of spammers. In Proceedings of Sigcomm, 2006.
[20] A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with
behavioral blacklisting. In Proceedings of the 14th ACM conference
on computer and communications security, 2007.
[21] S. Singh, C. Estan, G. Varghese, and S. Savage. Automated worm
ﬁngerprinting. In OSDI, 2004.
[22] Spamhaus policy block list (PBL).
http://www.spamhaus.org/pbl/, Jan 2007.
[23] S. Webb, J. Caverlee, and C. Pu. Introducing the web spam corpus:
Using email spam to identify web spam automatically. In
Proceedings of the Third Conference on Email and Anti-Spam
(CEAS), 2006.
[24] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and T. Wobber.
How dynamic are IP addresses? In ACM Sigcomm, 2007.
[25] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, I. Osipkov,
G. Hulten, and J. Tygar. Characterizing botnets from email spam
records. In LEET 08: First USENIX Workshop on Large-Scale
Exploits and Emergent Threats, 2008.