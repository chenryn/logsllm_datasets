# Table 3: Percentage of Campaigns with Different Ratios of Outliers After Clustering

| Outlier Ratio (%) | 
|------------------|
| 0.5              |
| 5                |
| 27               |
| 21               |
| 23               |
| 42               |

## Figure 13: (a) Similarity of Email Content Shingles (b) CDF of Sending Time Standard Deviations (in hours) for Each Campaign

- **(a)** The similarity of email content shingles, showing the most common k shingles (where k varies as shown in the figure).
- **(b)** The cumulative distribution function (CDF) of sending time standard deviations (in hours) for each campaign.

### 7.2.1 Similarity of Email Content
For the majority of campaigns (>60%), most emails share at least one shingle. However, the likelihood of these emails sharing all shingles is very low. In fact, around 50% of the campaigns have no two emails sharing 10 common shingles, suggesting that the contents are quite different even though their target web pages are similar.

### 7.2.2 Similarity of Sending Time
We examine the synchronous degree of spam sending times for each campaign. For each campaign, we compute the standard deviation (std) of spam email sending times (Figure 13(b)). 

- 50% of campaigns have a std less than 1.81 hours, indicating they were sent almost simultaneously and likely triggered by a single command.
- The remaining campaigns have a larger variation, suggesting that bots might start sending whenever they come online.
- Overall, 90% of campaigns have stds less than 24 hours, indicating they are likely located in different time zones.

### 7.2.3 Similarity of Email Sending Behavior
We broaden our analysis to the set of email sending features discussed in Section 7.1.2. Our goal is to systematically investigate whether botnet hosts can be grouped into well-formed clusters in the previously defined three-dimensional coordinate space. For each campaign, we use a Gaussian model with a full covariance matrix to model the data and learn the Gaussian parameters.

Table 3 lists the percentage of outliers that do not fit into the learned Gaussian models. We see that for each spam campaign, the host sending patterns are generally well-clustered (with <10% outliers). Figure 14 shows two such clusters:

- **(a)** Involves 191 botnet hosts with 9 outliers. The majority of the hosts are tightly clustered by having a similar number of recipients per email. These hosts sent emails with a long To or Cc list.
- **(b)** Shows a campaign with 162 hosts spanning 80 ASes. A unique aspect of this example is that the participating hosts (except for the 4 outliers) shared a constant connection rate (3 connections per second) in their communication with the server, suggesting that the botnet software may have applied rate control in initiating connections.

For the few cases with a high number of outliers, many are bimodal. We are investigating these cases further to understand whether this could be attributed to the heterogeneous nature of bot hosts in terms of computational power, network access speed, etc.

### 7.3 Comparison of Different Campaigns
In this section, we study the overlaps among different spam campaigns and compare the botnet host email sending patterns. Section 5 showed that a large number of campaigns share the same domain-agnostic regular expression signatures (refer to Figure 7(b)). 

- **Overlap Analysis:** For each domain-agnostic signature, we identify the set of spam campaigns (say a total of k) that share this signature. We then plot in Figure 15 the ratio of the number of unique IPs across the k botnets to the sum of their IPs as a function of k.
- **Findings:** The ratio is close to 1 when k is small, meaning botnets sharing a domain-agnostic signature barely overlap with each other in most cases. As k increases, the ratio gradually increases to 0.8, meaning 20% of the botnet IPs participated in multiple campaigns characterized by the same signature.

### 7.4 Correlation with Scanning Traffic
We analyze the network scanning behavior of the identified botnet hosts using distributed telescope data. Specifically, we use the Dshield trace collected in 2006 over a large network of more than 400,000 hosts [7]. This log contains failed connection attempts rejected by firewalls and scanning traffic to non-existing hosts. In our study, we focus on the source IP address and port number fields, considering the botnet IPs generated using the dataset from November 2006.

- **Dynamic IP Address Assignment:** Using IP addresses as host identifiers for correlation is not robust due to dynamic IP address assignment. Therefore, for dynamic botnet IP addresses, we check all the scanning activities from the corresponding dynamic IP ranges obtained from [24].
- **Scanning Traffic Analysis:** Using the dynamic IP ranges together with the remaining "likely static" IPs, we plot in Figure 17 the number of scans originating from these IP addresses into a set of popular scanning destination ports in August 2006 and November 2006, respectively. Besides ports 1026, 1027, and 25, all other ports are used for exploiting host vulnerabilities. The amount of scanning traffic in August is higher than in November, when these botnet IPs were actually used to send spam. This suggests that botnet attacks have different phases: in August, they were used to actively seek victim computers to expand the botnet size, while in November, they reached their target size and were used to launch spam attacks.

### 8. Discussion
Although AutoRE serves as a post-mortem tool for botnet spam detection, it has the potential to work in real-time mode. Due to the aggressive sampling rate (1:25000), the number of data points in our dataset was not sufficient to perform real-time experiments. However, given a live mail feed, AutoRE can be designed to produce signatures as soon as there is enough information to conclude that a distributed botnet spam campaign has commenced. 

- **Real-Time Potential:** We demonstrated that the signatures of June 2007 caught a non-trivial portion of July 2007's spam, suggesting that AutoRE can potentially stop a large portion of botnet spam in real-time service. The success of this approach depends on how quickly signatures can be generated and deployed, and how long a spam campaign lasts.
- **Evasion Techniques:** Spammers may attempt to craft emails to evade the AutoRE URL selection process. For example, they may add legitimate URLs to confuse the URL selection process. Since spammers have no control over the sending frequency of legitimate URLs, it will be hard for them to select which URLs to include. A popular URL would be discarded as background noise, and a rarely used URL will stand out as a spike for identifying the botnet.
- **Pollution Detection:** Spammers may also wish to pollute the "bursty" feature by sending a spam URL from a few hosts before launching a large-scale attack. Such pollution can be easily detected by a more robust signal processing methodology that captures signal spikes in the presence of low-frequency background noise.
- **No Patterns in URLs:** In the extreme case, spammers may wish to evade detection by having no patterns in their URLs. For example, each URL points to just a domain string (e.g., a.com, b.com, etc.). We expect such a scenario to be rare as the cost of registering domains makes this economically less attractive to spammers.

### 9. Conclusion
In this paper, we presented AutoRE, a framework that automatically generates URL signatures for spamming botnet detection. AutoRE requires neither pre-classified inputs nor other training data or white lists. Furthermore, AutoRE generates regular expression signatures, which were previously written by human experts only. Using sampled emails from Hotmail, AutoRE identified 7,721 botnet-based spam campaigns, comprising 340,050 distinct IP addresses spanning 5,916 ASes. The false positive rate of applying AutoRE signatures for botnet spam detection is less than 0.002, and the false positive rate of botnet host detection is less than 0.005. We expect the generated spam signatures and the botnet membership information to be useful for capturing future spam and reducing other malicious Internet activities.

Our extensive analysis of the identified botnets revealed several important findings:

- **Wide-Spread Botnet Hosts:** Botnet hosts are widespread across the Internet, with no distinctive sending patterns from normal servers when viewed individually. This suggests that detecting and blacklisting individual botnet hosts will continue to remain a challenging task.
- **Feasibility of Detection:** We demonstrated the existence of botnet spam signatures and the feasibility of detecting botnet hosts using them. Our analysis also shows that botnet host sending patterns, such as the number of recipients per email, connection rates, and the frequency of sending to invalid users, are clusterable, and their sending times are synchronized.
- **Future Directions:** An interesting future direction is to further explore mechanisms that capture aggregated activities of botnets. Finally, the comparison of spam traffic patterns from 2007 to 2006 clearly showed that botnets are evolving and getting increasingly sophisticated. For example, the adoption of polymorphic URLs increased significantly, and the number of static IP address-based bots doubled from November 2006 to July 2007. These trends for evading existing detection systems suggest that we need to take a holistic view of various mechanisms and explore the invariable attack features to get an upper hand in the spam arms race.

### 10. References
[1] M. I. Abouelhoda, S. Kurtz, and E. Ohlebusch. Replacing suffix trees with enhanced suffix arrays. J. of Discrete Algorithms, 2(1), 2004.
[2] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker. Spamscatter: Characterizing Internet scam hosting infrastructure. In 14th conference on USENIX Security Symposium, 2007.
[3] T. Berners-Lee, R. Fielding, and L. Masinter. Uniform resource identifiers (URI): Generic syntax. RFC 2396, 1998.
[4] K. Chiang and L. Lloyd. A case study of the Rustock rootkit and spam bot. In The First Workshop in Understanding Botnets, 2007.
[5] D. Dagon, C. Zou, and W. Lee. Modeling botnet propagation using time zones. In Proc. of the 13th Annual Network and Distributed System Security Symposium (NDSS), 2006.
[6] N. Daswani, M. Stoppelman, and the Google click quality and security teams. The anatomy of Clickbot.A. In The First Workshop in Understanding Botnets, 2007.
[7] Dshield: Cooperative network security community.
[8] Dynablock dynamic IP list. http://www.njabl.org/, recently acquired by spamhaus, http://www.spamhaus.org/pbl/index.lasso, 2007.
[9] D. Fetterly, M. Manasse, M. Najork, and J. L. Wiener. A large-scale study of the evolution of web pages. Softw. Pract. Exper., 34(2), 2004.
[10] T. Holz, M. Steiner, F. Dahl, E. Biersack, and F. Freiling. Measurements and mitigation of peer-to-peer-based botnets: A case study on storm worm. In LEET 08: First USENIX Workshop on Large-Scale Exploits and Emergent Threats, 2008.
[11] C. Kanich, K. Levchenko, B. Enright, G. M. Voelker, and S. Savage. The Heisenbot uncertainty problem: Challenges in separating bots from chaff. In LEET ’08: First USENIX Workshop on Large-Scale Exploits and Emergent Threats, 2008.
[12] H.-A. Kim and B. Karp. Autograph: Toward automated, distributed worm signature detection. In the 13th conference on USENIX Security Symposium, 2004.
[13] C. Kreibich and J. Crowcroft. Honeycomb: Creating intrusion detection signatures using honeypots. In 2nd Workshop on Hot Topics in Networks (HotNets-II), 2003.
[14] F. Li and M.-H. Hsieh. An empirical study of clustering behavior of spammers and group-based anti-spam strategies. In CEAS 2006: Proceedings of the 3rd conference on email and anti-spam, 2006.
[15] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez. Hamsa: Fast signature generation for zero-day polymorphic worm with provable attack resilience. In IEEE Symposium on Security and Privacy, 2006.
[16] J. Newsome, B. Karp, and D. Song. Polygraph: Automatically generating signatures for polymorphic worms. In Proceedings of the 2005 IEEE Symposium on Security and Privacy, 2005.
[17] M. A. Rajab, J. Zarfoss, F. Monrose, and A. Terzis. A multifaceted approach to understanding the botnet phenomenon. In IMC ’06: Proceedings of the 6th ACM SIGCOMM conference on Internet measurement, 2006.
[18] A. Ramachandran, D. Dagon, and N. Feamster. Can DNS based blacklists keep up with bots? In Conference on Email and Anti-Spam, 2006.
[19] A. Ramachandran and N. Feamster. Understanding the network-level behavior of spammers. In Proceedings of Sigcomm, 2006.
[20] A. Ramachandran, N. Feamster, and S. Vempala. Filtering spam with behavioral blacklisting. In Proceedings of the 14th ACM conference on computer and communications security, 2007.
[21] S. Singh, C. Estan, G. Varghese, and S. Savage. Automated worm fingerprinting. In OSDI, 2004.
[22] Spamhaus policy block list (PBL). http://www.spamhaus.org/pbl/, Jan 2007.
[23] S. Webb, J. Caverlee, and C. Pu. Introducing the web spam corpus: Using email spam to identify web spam automatically. In Proceedings of the Third Conference on Email and Anti-Spam (CEAS), 2006.
[24] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt, and T. Wobber. How dynamic are IP addresses? In ACM Sigcomm, 2007.
[25] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, I. Osipkov, G. Hulten, and J. Tygar. Characterizing botnets from email spam records. In LEET 08: First USENIX Workshop on Large-Scale Exploits and Emergent Threats, 2008.