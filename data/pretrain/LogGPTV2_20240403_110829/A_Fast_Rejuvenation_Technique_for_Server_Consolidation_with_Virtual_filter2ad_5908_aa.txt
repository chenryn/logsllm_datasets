title:A Fast Rejuvenation Technique for Server Consolidation with Virtual
Machines
author:Kenichi Kourai and
Shigeru Chiba
A Fast Rejuvenation Technique for Server Consolidation with Virtual Machines
Kenichi Kourai
Shigeru Chiba
Tokyo Institute of Technology
Tokyo Institute of Technology
2-12-1 Ookayama, Meguro-ku, Tokyo
2-12-1 Ookayama, Meguro-ku, Tokyo
152-8552, Japan
152-8552, Japan
PI:EMAIL
PI:EMAIL
Abstract
As server consolidation using virtual machines (VMs)
is carried out, software aging of virtual machine monitors
(VMMs) is becoming critical. Performance degradation or
crash failure of a VMM affects all VMs on it. To counter-
act such software aging, a proactive technique called soft-
ware rejuvenation has been proposed. A typical example
of rejuvenation is to reboot a VMM. However, simply re-
booting a VMM is undesirable because that needs reboot-
ing operating systems on all VMs. In this paper, we pro-
pose a new technique for fast rejuvenation of VMMs called
the warm-VM reboot. The warm-VM reboot enables efﬁ-
ciently rebooting only a VMM by suspending and resum-
ing VMs without accessing the memory images. To achieve
this, we have developed two mechanisms: on-memory sus-
pend/resume of VMs and quick reload of VMMs. The warm-
VM reboot reduces the downtime and prevents the perfor-
mance degradation due to cache misses after the reboot.
1. Introduction
The phenomenon that the state of software degrades with
time is known as software aging [16]. The causes of this
degradation are the exhaustion of system resources and data
corruption. This often leads to performance degradation of
the software or crash failure. Recently, software aging of
virtual machine monitors (VMMs) is becoming critical as
server consolidation using virtual machines (VMs) is being
widely carried out. Many VMs run on top of a VMM in
one machine consolidating multiple servers and aging of the
VMM directly affects all the VMs.
To counteract such software aging, a proactive tech-
nique called software rejuvenation has been proposed [16].
Software rejuvenation occasionally stops a running VMM,
cleans its internal state, and restarts it. A typical example
of rejuvenation is to reboot a VMM. However, operating
systems running on the VMs built on top of a VMM also
have to be rebooted when the VMM is rejuvenated. This
increases the downtime of services provided by the operat-
ing systems. It takes long time to reboot many operating
systems in parallel when the VMM is rebooted. After the
operating systems are rebooted with the VMM, their perfor-
mance is degraded due to cache misses. The ﬁle cache used
by the operating systems is lost by the reboot. Such down-
time and performance degradation are critical for servers.
In this paper, we propose a new technique for fast reju-
venation of VMMs called the warm-VM reboot. The ba-
sic idea is that a VMM preserves the memory images of
all VMs through the reboot of the VMM and reuses those
memory images after the reboot. The warm-VM reboot en-
ables efﬁciently rebooting only a VMM by using the on-
memory suspend/resume mechanism of VMs and the quick
reload mechanism of VMMs. Using the on-memory sus-
pend/resume mechanism, a VMM suspends VMs running
on it before it is rebooted. At that time, the memory images
of the VMs are preserved on main memory and they are not
saved to any persistent storage. The suspended VMs are
quickly resumed by directly using the preserved memory
images after the reboot. To preserve the memory images
during the reboot, the VMM is rebooted using the quick
reload mechanism without a hardware reset. The warm-VM
reboot can reduce the downtime of operating systems run-
ning on VMs and prevent performance degradation due to
cache misses because it does not need to reboot operating
systems.
To achieve this fast rejuvenation, we have developed
RootHammer based on Xen [9]. From our experimental re-
sults, the warm-VM reboot reduced the downtime due to
rebooting the VMM by 83 % at maximum. For compari-
son, when we simply used the suspend/resume mechanism
of the original Xen, the downtime was increased by 173 %.
After the warm-VM reboot, the throughput of a web server
was not degraded at all. When we did not use the warm-VM
reboot, the throughput was degraded by 69 % just after the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:26 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007reboot of the VMM.
The rest of this paper is organized as follows. Section 2
describes the problems of current software rejuvenation of
VMMs. Section 3 presents a new technique for fast reju-
venation of VMMs and estimates the downtime reduced by
it. Section 4 explains our implementation based on Xen
and Section 5 shows our experimental results. Section 6
discusses the advantage of the warm-VM reboot in a clus-
ter environment. Section 7 examines related work and Sec-
tion 8 concludes the paper.
2. Software Rejuvenation of VMMs
As server consolidation using VMs is widely carried out,
software aging of VMMs is becoming critical. Recently,
multiple server machines are consolidated into one machine
using VMs. In such a machine, many VMs are running on
top of a VMM. Since a VMM is long-running software, it
is affected by software aging more largely than the other
components. For example, a VMM may leak its memory
by failing to release a part of memory. In Xen [9], the size
of the heap memory of the VMM is only 16 MB by default
in spite of the size of physical memory. If the VMM leaks
its heap memory, it would become out of memory easily.
Xen had a bug that caused available heap memory to de-
crease whenever a VM was rebooted [19] or when some
error paths were executed [11]. Out-of-memory errors can
lead performance degradation or crash failure of the VMM.
Such problems of the VMM directly affect all the VMs.
In addition to the aging of VMMs, that of privileged
VMs can also affect the other VMs. Privileged VMs are
used in some VM architectures such as Xen and VMware
ESX server [26] to help the VMM for VM management
and/or I/O processing of all VMs. They run normal oper-
ating systems with some modiﬁcations. For operating sys-
tems, it has been reported that system resources such as
kernel memory and swap spaces were exhausted with time
[13]. In privileged VMs, memory exhaustion easily occurs
because the typical size of the memory allocated to them is
not so large. Since privileged VMs do not run large servers,
they do not need a large amount of memory. For example,
Xen had a bug of memory leaks in its daemon named xen-
stored running on a privileged VM [15]. If I/O processing
in the privileged VM slows down due to out of memory, the
performance in the other VMs is also degraded. Since xen-
stored is not restartable, restoring from such memory leaks
needs to reboot the privileged VM. Furthermore, the reboot
of the privileged VM causes the VMM to be rebooted be-
cause the privileged VM strongly depends on the VMM.
For this reason, we consider such privileged VMs as a part
of a VMM and we do not count them as normal VMs.
To counteract such software aging, a proactive tech-
nique called software rejuvenation has been proposed [16].
privileged
VM
OS
VM
VM
VM
OS
OS
OS
VMM
Figure 1. An assumed VM architecture.
Software rejuvenation occasionally stops a running VMM,
cleans its internal state, and restarts it. A typical example
of rejuvenation is to reboot a VMM. Since the state of long-
running software such as VMMs degrades with time under
aging conditions, preventive maintenance by software reju-
venation would decrease problems due to aging.
However, when a VMM is rejuvenated, operating sys-
tems on the VMs built on top of the VMM also have to be
rebooted. Operating systems running on VMs have to be
shut down to keep the integrity before the VMM terminates
the VMs. Then, after the reboot of the VMM, newly cre-
ated VMs have to boot the operating systems and restart all
services again.
This increases the downtime of services provided by op-
erating systems. First of all, many operating systems are
shut down and booted in parallel when the VMM is re-
booted. The time for rebooting each operating system is
proportional to the number of VMs because shutting down
and booting multiple operating systems in parallel cause re-
source contention among them. Unfortunately, the num-
ber of VMs that can run simultaneously is increasing due
to processor support of virtualization such as Intel VT [17]
and AMD Virtualization [3] and multi-core processors. In
addition, recent servers tend to provide heavy-weight ser-
vices such as the JBoss application server [18] and the time
for stopping and restarting services is increasing. Second,
shutting down operating systems, rebooting the VMM, and
booting operating systems are performed sequentially. The
in-between reboot of the VMM increases the service down-
time. The reboot of the VMM includes shutting down the
VMM, resetting hardware, and booting the VMM. In par-
ticular, a hardware reset involves power-on self-test by the
BIOS such as a time-consuming check of large amount of
main memory and SCSI initialization.
In addition, the performance of operating systems on
VMs is degraded after they are rebooted with the VMM.
The primary cause is to lose the ﬁle cache. An operating
system stores ﬁle contents in main memory as the ﬁle cache
when it reads them from storage. An operating system
speeds up ﬁle accesses by using the ﬁle cache on memory.
When an operating system is rebooted, main memory is ini-
tialized and the ﬁle cache managed by the operating system
is lost. Therefore, just after the reboot of the operating sys-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:26 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007tem, the execution performance of server processes running
on top of it is degraded due to frequent cache misses. To ﬁll
the ﬁle cache after the reboot, an operating system needs to
read necessary ﬁles from storage. Since modern operating
systems use most of free memory as the ﬁle cache, it takes
long time to ﬁll free memory with the ﬁle cache. The size
of memory installable to one machine tends to increase due
to 64-bit processors and cheaper memory modules. Conse-
quently, more memory is allocated to each VM.
3. Fast Rejuvenation Technique
We claim that only a VMM should be rebooted when
only the VMM needs rejuvenation. In other words, reboot-
ing operating systems should be independent of rebooting
an underlying VMM. Although an operating system may be
rejuvenated occasionally as well as a VMM, the timing does
not always the same as that of the rejuvenation of a VMM. If
some operating systems do not need to be rejuvenated when
the VMM is rejuvenated, rebooting these operating systems
is simply wasteful.
3.1. Warm-VM Reboot
To minimize the inﬂuences of the rejuvenation of
VMMs, we propose a new technique for fast rejuvenation
called the warm-VM reboot. The basic idea is that a VMM
preserves the memory images of all the VMs through the
reboot of the VMM and reuses those memory images after
the reboot. The warm-VM reboot enables efﬁciently reboot-
ing only a VMM by using the on-memory suspend/resume
mechanism for VMs and the quick reload mechanism for
VMMs. A VMM suspends all VMs using the on-memory
suspend mechanism before it is rebooted, reboots itself by
the quick reload mechanism, and resumes all VMs using the
on-memory resume mechanism after the VMM is rebooted.
The on-memory suspend mechanism simply “freezes”
the memory image used by a VM as it is. The memory im-
age is preserved on memory through the reboot of the VMM
until the VM is resumed. This mechanism needs neither to
save the image to any persistent storage such as disks nor to
copy it to non-volatile memory such as ﬂash memory. This
is very efﬁcient because the time needed for suspend hardly
depends on the size of memory allocated to the VM. Even
if the total memory size of all VMs becomes larger, the on-
memory suspend mechanism can scale. At the same time,
this mechanism saves the execution state of the suspended
VM to the memory area that is also preserved through the
reboot of the VMM.
On the other hand,
the on-memory resume mecha-
nism “unfreezes” the frozen memory image to restore the
suspended VM. The frozen memory image is preserved
through the reboot of the VMM by using quick reload. This
mechanism also needs neither to read the saved image from
persistent storage nor to copy it from non-volatile memory.
Since the memory image of the VM is restored completely,
performance degradation due to cache misses is prevented
even just after the reboot. At the same time, the saved ex-
ecution state of a VM is also restored. These mechanisms
are analogous to ACPI S3 state (Suspend To RAM) [2] in
that they can suspend and resume a VM without touching
its memory image on main memory.
The quick reload mechanism preserves the memory im-
ages of VMs through the reboot of a VMM and furthermore
makes the reboot itself faster. Usually, rebooting a VMM
needs a hardware reset to reload a VMM instance, but a
hardware reset does not guarantee that memory contents are
preserved during it. In addition, a hardware reset takes long
time as described in the previous section. The quick reload
mechanism can bypass a hardware reset by loading a new
VMM instance by software and start it by jumping to its en-
try point. Since the software mechanism can manage mem-
ory during the reboot, it is guaranteed that memory contents
are preserved. Furthermore, the quick reload mechanism
prevents the frozen memory images of VMs from being cor-
rupted when the VMM initializes itself.
Although many VMMs provide suspend/resume mech-
anisms, they are not suitable to use for rejuvenation of
VMMs because they have to use disks as persistent storage
to save memory images. These traditional suspend/resume
mechanisms are analogous to ACPI S4 state (Suspend To
Disk), so-called hibernation. These mechanisms need
heavy disk accesses and they are too slow. On the other
hand, our on-memory suspend/resume mechanism does not
need to save the memory images to disks before the reboot
of a VMM. Our quick reload mechanism allows the VMM
to reuse the memory images on volatile main memory by
preserving them during the reboot.
3.2. Downtime Estimation
To estimate the downtime reduced by using the warm-
VM reboot, let us consider the usage model of software re-
juvenation. Usually the rejuvenation of a VMM (VMM re-
juvenation) is used with the rejuvenation of operating sys-
tems (OS rejuvenation).
In general, the OS rejuvenation
is performed more frequently than the VMM rejuvenation.
For simplicity, we assume that each operating system is re-
juvenated by relying on the time elapsed since the last OS
rejuvenation, which is called time-based rejuvenation [12].
When the warm-VM reboot is used, the VMM rejuvenation
can be performed independently of the OS rejuvenation as
shown in Figure 2 (a). This is because the warm-VM reboot
does not involve the OS rejuvenation. On the other hand,
when a VMM is rejuvenated by a normal reboot, which we
call the cold-VM reboot in contrast to the warm-VM reboot,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:50:26 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007(a) warm-VM reboot
OS rejuvenation
4. Implementation
VMM rejuvenation
(b) cold-VM reboot
OS rejuvenation
α
VMM rejuvenation
time
time
Figure 2. The timing of two kinds of rejuvena-
tion. The rejuvenation of all but one operat-
ing system is omitted.
the VMM rejuvenation affects the timing of the OS rejuve-
nation as shown in Figure 2 (b) because the VMM rejuve-
nation involves the OS rejuvenation. The OS rejuvenation
after the VMM rejuvenation will be performed at ﬁxed in-
tervals again.
When the warm-VM reboot is used, the downtime due
to the VMM rejuvenation is caused by suspending all VMs,
rebooting the VMM, and resuming all VMs. The increase
of the downtime is:
dw(n) = rebootvmm(n) + resume(n)
where n is the number of VMs, rebootvmm(n) is the time
needed to reboot a VMM when n VMs are suspended and
resumed, and resume(n) is the time needed to perform on-