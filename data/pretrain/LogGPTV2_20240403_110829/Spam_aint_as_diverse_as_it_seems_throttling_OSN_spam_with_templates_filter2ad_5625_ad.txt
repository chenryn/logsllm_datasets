Campaign No. 5
 0
 0.1
 0.2
 0.3
 0.4
 0.5
% of messages used as training samples
Figure 3: The TP rate when template generation is
performed separately for each campaign, varying the
size of training set. Most observation points reach
100% TP rate.
of the testing set that the generated template can match.
Figure 3 shows the results. We observe that all campaigns
achieve almost 100% coverage even with only 0.15% of mes-
sages as training samples. Three campaigns have lower cov-
erage when only 0.05% of messages are used to generate
the template, because the system has not observed all pos-
sible values of dictionary macros due to insuﬃcient train-
ing samples. Nonetheless, the coverage quickly climbs up
to almost 100% when the percentage of training samples
increases. The result indicates that when new spam cam-
paigns emerge, the system can react quickly and generate
eﬀective templates to throttle them.
5. DISCUSSIONS
How to increase the attack resilience of the aux-
iliary spam ﬁlter? In practice, Tangram needs an auxil-
iary ﬁlter with a low false positive rate. This is a reason-
able requirement, since we can tune the auxiliary ﬁlter to
be conservative in reporting spam. Spammers can try to
evade Tangram by evading the auxiliary spam ﬁlter, so that
no training samples are available for template generation.
We can address this by introducing heterogeneity into the
auxiliary ﬁlter. Using a combination of multiple inherently
diﬀerent existing spam detection systems as the auxiliary
ﬁlter makes it very hard for spammers to evade all of them.
How to mitigate training sample poisoning? Power-
ful adversaries can manipulate the training samples to mis-
lead the training of the detection system. One possible way
is to inject popular legitimate content into spam, hoping that
the generated template matches a large number of legitimate
messages. However, our experimental results show that Tan-
gram will not generate template for spam with seemingly
legitimate content. As a second precaution, we can set a
threshold and only deploy the templates that incur a false
positive rate lower than the threshold.
Another popular attack is to send spam with diﬀerent pat-
terns from the training samples after the detection system
ﬁnishing training. Tangram is inherently immune to such
attack, because it does not have separate training and test-
ing phase. If spammers produce spam from a non-stationary
distribution, Tangram can also detect it as long as suﬃcient
large amount of spam is produced from each distribution.
How to mitigate paraphrase spam? The major dif-
ﬁculty for Tangram to detect paraphrase spam is the lack
of ordering among semantically meaningful segments, which
is assumed by the template model. Nonetheless, semantic
analysis techniques that do not consider the word ordering
may be used to mitigate such spam, e.g., clustering based
on cosine similarity using bag-of-words model. In addition,
paraphrase generation is still an active area of research in
Natural Language Processing [20]. So is paraphrase detec-
tion [5]. The detection of paraphrase spam can leverage
existing paraphrase detection approaches, and is one of our
future research directions.
How to mitigate spam that re-uses legitimate con-
tent? Since spammers need to use popular content to at-
tract the audience and generate a large number of spam, the
OSN administrator will observe the popular content with
replaced URLs in large volume, which defeats the spam-
mers’ purpose to evade detection. Also, in practice, we can
equip Tangram with multiple heterogeneous detection mod-
ules that do not rely on spam content.
6. RELATED WORK
Spam Detection. Judo [22] also infers the underlying
template used to generate spam. However, Judo (as well
as its adaptation to web spam [33]) assume the presence
of invariant substring in the template, and requires a clean
spam trace instantiating the same template as input. These
requirements are hard to satisfy in the OSN environment.
We also show via experiments that the Judo design does not
yield satisfactory detection accuracy on a real-world OSN
trace.
In contrast, our system is designed speciﬁcally for
OSN and is not limited by the above two requirements.
Researchers have proposed other approaches that ﬁght
spam using the textual content, including using the syntac-
tical textual similarity within the same campaign [6,34] and
extracting signature of embedded URLs [30]. Meanwhile,
other features of spam/spammers are used to ﬁght spam as
well. Egele et al. model account proﬁles and use anomaly
detection to identify compromised accounts in OSNs [4].
Song et al. propose to use the social graph property to de-
tect spam tweets [24]. Yang et al. use sender proﬁle features
among others [31]. Other proposed techniques include focus-
ing on embedded URL information like redirection chains,
DNS and WHOIS information and so on [15, 18, 19], classi-
fying URLs’ landing pages [2, 26] and using sender’s reputa-
tion [3, 9, 25, 29]. Building sender proﬁle features takes time
and it is diﬃcult to adopt for real-time detection. Compared
with our work, although some of the above approaches re-
port higher spam coverage, they incur signiﬁcantly higher
false positive rate, showing that the features they use are
less precise than spam templates. More importantly, very
few existing works can do real-time detection and ﬁlter spam
without URLs simultaneously, where as Tangram by design
can achieve both.
Spam Measurement. Thomas et al. examine a large
corpus of suspended Twitter accounts in [27], which provides
rich knowledge on Twitter spammers that inspires our work
from multiple aspects. In addition, Grier et al. and Gao et
al. discovered the popularity of compromised spamming ac-
counts in Twitter and Facebook, respectively [7, 8]. Due
to the diﬀerent data collection method, most spamming ac-
counts in our dataset are created by spammers. Yang et
al. analyze the social network formed by spamming ac-
counts and reveal diﬀerent categories of legitimate accounts
that follow spamming accounts [32]. Levchendo et al. and
Kanich et al. study the monetization of spam campaigns [11,
16].
In comparison, our work focuses on detecting spam,
whereas the above works focus on revealing spammers’ char-
acteristics using known spam.
Signature Generation. The problem of spam template
generation bears similarity with polymorphic worm signa-
ture generation [17, 21]. The worm signature generation is
based on the assumption that polymorphic worm content
contains invariant substrings, which is reasonable because
some invariant bytes are crucial for successfully exploiting
the vulnerability. However, this assumption is not solid in
the context of spam detection, where spammers can express
the same message using diﬀerent expressions in human lan-
guage. Our Twitter spam analysis supports this argument.
Venkataraman et al.
formalize the limits on the pattern-
extraction algorithms for signature generation in the pres-
ence of powerful adversaries [28]. Due to the diﬀerence in
the underlying assumptions, i.e., with and without invariant
substrings, it is hard to directly apply their conclusions to
our spam template generation problem.
7. CONCLUSION
We have proposed and evaluated Tangram, a template-
based system for accurate and fast OSN spam detection.
Our measurement study reveals that 63% of Twitter spam
is likely to instantiate underlying templates. Based on the
empirical ﬁndings, Tangram mainly employs template gen-
eration/matching to mitigate OSN spam. Tangram distin-
guishes from existing template generation work in that it can
construct template in the absence of invariant substrings.
Tangram detects OSN spam in real-time without a separate
training phase. Experimental results show that Tangram
can detect 95.7% of the most prevalent template-based spam
in the collected Twitter dataset. Equipped with one neces-
sary auxiliary spam ﬁlter, the combined system achieves an
overall true positive rate of 85.4% and a false positive rate
of 0.33%.
Acknowledgement
This work is supported in part by the following grants:
NSF awards CCF-1029166, ACI-1144061, IIS-1343639, and
CCF-1409601; DOE award DESC0007456; DARPA contract
D11AP00268; Fundamental Research Funds for the Central
Universities under Grant No. 2014QNA5012. We would also
like to sincerely thank ACSAC 2014 chairs and reviewers for
their helpful feedback.
8. REFERENCES
[1] What the trend. http://www.whatthetrend.com/.
[2] D. S. Anderson, C. Fleizach, S. Savage, and G. M.
Voelker. Spamscatter: characterizing internet scam
hosting infrastructure. In USENIX Security, 2007.
[3] F. Benevenuto, G. Magno, T. Rodrigues, and
V. Almeida. Detecting spammers on Twitter. In
CEAS, 2010.
[4] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna.
COMPA: Detecting Compromised Accounts on Social
Networks. In NDSS, 2013.
[5] S. Fernando and M. Stevenson. A semantic similarity
approach to paraphrase detection. In CLUK, 2008.
[6] H. Gao, Y. Chen, K. Lee, D. Palsetia, and
A. Choudhary. Towards Online Spam Filtering in
Social Networks. In NDSS, 2012.
[7] H. Gao, J. Hu, C. Wilson, Z. Li, Y. Chen, and B. Y.
Zhao. Detecting and characterizing social spam
campaigns. In IMC, 2010.
[8] C. Grier, K. Thomas, V. Paxson, and M. Zhang.
@spam: the underground on 140 characters or less. In
CCS, 2010.
[9] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and
S. Krasser. Detecting spammers with snare:
spatio-temporal network-level automatic reputation
engine. In USENIX Security, 2009.
[10] T. Jiang and M. Li. On the approximation of shortest
common supersequences and longest common
subsequences. In ICALP, 1994.
[11] C. Kanich, C. Kreibich, K. Levchenko, B. Enright,
G. M. Voelker, V. Paxson, and S. Savage.
Spamalytics: An empirical analysis of spam marketing
conversion. In CCS, 2008.
[12] C. Kreibich, C. Kanich, K. Levchenko, B. Enright,
G. M. Voelker, V. Paxson, and S. Savage. On the
spam campaign trail. In LEET, 2008.
[13] C. Kreibich, C. Kanich, K. Levchenko, B. Enright,
G. M. Voelker, V. Paxson, and S. Savage. Spamcraft:
An inside look at spam campaign orchestration. In
LEET, 2009.
[14] J. D. Laﬀerty, A. McCallum, and F. C. N. Pereira.
Conditional random ﬁelds: Probabilistic models for
segmenting and labeling sequence data. In ICML,
2001.
[15] S. Lee and J. Kim. WarningBird: Detecting suspicious
URLs in Twitter stream. In NDSS, 2012.
[16] K. Levchenko, N. Chachra, B. Enright, M. Felegyhazi,
C. Grier, T. Halvorson, C. Kanich, C. Kreibich,
H. Liu, D. McCoy, A. Pitsillidis, N. Weaver,
V. Paxson, G. M. Voelker, and S. Savage. Click
Trajectories: End-to-End Analysis of the Spam Value
Chain. In S&P, 2011.
[17] Z. Li, M. Sanghi, Y. Chen, M.-Y. Kao, and B. Chavez.
Hamsa: Fast signature generation for zero-day
polymorphicworms with provable attack resilience. In
S&P, 2006.
[18] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker.
Beyond blacklists: learning to detect malicious web
sites from suspicious urls. In KDD, 2009.
[19] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker.
Identifying suspicious urls: an application of
large-scale online learning. In ICML, 2009.
[20] N. Madnani and B. Dorr. Generating phrasal and
sentential paraphrases: A survey of data-driven
methods. Computational Linguistics, 36(3):341–387,
2010.
[21] J. Newsome, B. Karp, and D. Song. Polygraph:
Automatically generating signatures for polymorphic
worms. In S&P, 2005.
[22] A. Pitsillidis, K. Levchenko, C. Kreibich, C. Kanich,
G. Voelker, V. Paxson, N. Weaver, and S. Savage.
Botnet Judo: Fighting Spam with Itself . In NDSS,
2010.
[23] A. Ritter, S. Clark, O. Etzioni, et al. Named entity
recognition in tweets: an experimental study. In
EMNLP, 2011.
[24] J. Song, S. Lee, and J. Kim. Spam ﬁltering in twitter
using sender-receiver relationship. In RAID, 2011.
[25] G. Stringhini, C. Kruegel, and G. Vigna. Detecting
spammers on social networks. In ACSAC, 2010.
[26] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song.
Design and Evaluation of a Real-Time URL Spam
Filtering Service. In S&P, 2011.
[27] K. Thomas, C. Grier, V. Paxson, and D. Song.
Suspended Accounts In Retrospect: An Analysis of
Twitter Spam. In IMC, 2011.
[28] S. Venkataraman, A. Blum, and D. Song. Limits of
learning-based signature generation with adversaries.
In NDSS, 2008.
[29] A. H. Wang. Don’t follow me - spam detection in
twitter. In S. K. Katsikas and P. Samarati, editors,
SECRYPT, pages 142–151. SciTePress, 2010.
[30] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten,
and I. Osipkov. Spamming botnets: signatures and
characteristics. In Proc. of SIGCOMM, 2008.
[31] C. Yang, R. Harkreader, and G. Gu. Die free or live
hard? empirical evaluation and new design for ﬁghting
evolving twitter spammers. In RAID, 2011.
[32] C. Yang, R. Harkreader, J. Zhang, S. Shin, and
G. Gu. Analyzing spammers’ social networks for fun
and proﬁt: a case study of cyber criminal ecosystem
on twitter. In WWW, 2012.
[33] Q. Zhang, D. Y. Wang, and G. M. Voelker. Dspin:
Detecting automatically spun content on the web. In
NDSS, 2014.
[34] L. Zhuang, J. Dunagan, D. R. Simon, H. J. Wang, and
J. D. Tygar. Characterizing botnets from email spam
records. In LEET, 2008.
APPENDIX
A. TEMPLATE GENERATION COMPUTA-
TIONAL CHALLENGE
We prove that the template generation problem is NP-
hard. We use the following notions for ease of presentation:
1. len(S): When S is a token sequence, this operation
computes the number of tokens in S. When S is a set
or a list, this operation recursively computes the sum
of len() for all the elements in S. len(ε) is zero.
2. cat(S): This operation concatenates the elements of a
set S in arbitrary order and returns the concatenation.
3. [s1, s2, ..., sk]: An ordered list containing k elements.
Single Campaign Template Generation (SCTG): We
start with the problem to reconstruct the underlying tem-
plate given a set of spam messages instantiating the same
template.
Input: n token sequences, instantiating the same template.
Output: An ordered list L = [S1, S2, ..., Sk], where each Si
is a set of token sequences. Si may contain ε (representing
nothing). Every input token sequence can be represented
as the concatenation of one element in each Si. Meanwhile,
len(L) is minimized.
Hardness: SCTG is NP-hard. We prove this by reduc-
ing Shortest Common Supersequence Problem, a well-known
NP-hard problem, into SCTG (Table 6).
Input: A set of n token sequences M = {m1, m2, ..., mn}
Reduction:
Find L, the SCTG solution of M .
S :=“”
Foreach Si in L:
S := S + cat(Si)
End Foreach
S is the shortest common supersequence of M .
Proof: S is the shortest common supersequence of M
It is trivially true that S is a common supersequence of M .
Assume ∃S 0, such that S 0 is a common supersequence of M
and that len(S 0)  len(L0).
We thus reach a contradiction.
Hence we reject the assumption and prove that S is the
shortest common supersequence of M .
Table 6: The reduction from Shortest Common Su-
persequence Problem to SCTG.
Multiple Campaign Template Generation (MCTG):
In real-world deployment scenarios, the system is expected
to receive a mixture of spam instantiating multiple tem-
plates, and it is non-trivial to separate them. Accordingly,
the system should be able to generate multiple templates
from the input spam. Intuitively, the MCTG problem is at
least as hard as the SCTG problem, since a MCTG solver
is able to solve the SCTG problem as well.
B. CORRECTNESS OF MATRIX COLUMN
REDUCTION
In Section 3.2, we state three conditions to merge matrix
columns. Condition i) column j and column k have iden-
tical label; Condition ii) in any row at least one column is
ε; and Condition iii) if the cell at row i, column k is not
ε, all cells in row i, between column j and column k must
be ε. Under the three conditions, we prove that the super-
sequence property holds after merging by contradiction. Let
column j and column k satisfy the above three conditions,
and we assume that after merging column k into column j,
the resulting concatenation of column labels are not a super-
sequence of some input sequence i (row i). There is at least
one token in sequence i that is not covered by the resulting
concatenation of column labels. Let it be at the mth column
in the original matrix. m must be k because other columns
still perserve after merging. Hence, row i column k must
not be ε. We denote it as t. Due to condition ii), row i
column j must be ε. Due to condition iii), the subsequence
of row i between column j and column k is merely one to-
ken, t. Since column j and column k have identical token
(condition i)), after merging the label of columns between
j and k can cover t. Hence, the resulting column labels are
still a supersequence of input sequence i. We hereby reach
a contradiction, and the proof is complete.