eε
1
eε+d(cid:5)−1
eε+d(cid:5)−1
(cid:5),
(cid:2) p
(cid:5),
(cid:2) q
if a = H(v),
otherwise,
(7)
(cid:5) = eε
where y is the perturbed value sent to the central server from a
user with item v. Therefore, the overall probability parameters
(cid:5) = 1
p and q are p = p
d(cid:5) .
Aggregate: A perturbed value y = (H,h) supports an item
v ∈ [d] if v is hashed to h by H. Formally, we have S(y) =
{v|v ∈ [d] and H(v) = h}.
eε+d(cid:5)−1 and q = 1
(cid:5) +(1− 1
d(cid:5) )·q
d(cid:5) · p
2.2 Heavy Hitter Identiﬁcation
The goal of heavy hitter identiﬁcation [9, 10, 62] is to identify
the top-k items that are the most frequent among the n users.
A direct and simple solution is to ﬁrst estimate the frequency
of each item using a frequency estimation protocol and then
select the k items with the largest frequencies. However, such
method is not scalable to a large number of items. In response,
a line of works [9, 10, 62] developed protocols to identify
heavy hitters without estimating item frequencies. For ex-
ample, Bassily et al. [9] and Wang et al. [62] independently
developed a similar heavy hitter identiﬁcation protocol, which
divides users into groups and iteratively applies a frequency
estimation protocol to identify frequent preﬁxes within each
group. Next, we take the Preﬁx Extending Method (PEM) [62],
a state-of-the-art heavy hitter identiﬁcation protocol, as an
example to illustrate the process.
j· γ−(cid:6)log2 k(cid:7)
In PEM, each user encodes its item as a γ-bits binary vec-
tor. Suppose users are evenly divided into g groups. In the
jth iteration, users in the jth group use the OLH protocol
to perturb the ﬁrst λ j = (cid:6)log2 k(cid:7) +
bits of their
binary vectors and send the perturbed bits to the central server,
which uses the aggregate step of the OLH protocol to esti-
mate the frequencies of the preﬁxes that extend the previous
top-k preﬁxes. OLH instead of OUE is used because the num-
ber of items corresponding to λ j bits is 2λ j, which is often
large and incurs large communication costs for OUE. Specif-
ically, the central server uses the aggregate step of OLH to
estimate the frequencies of the λ j-bits preﬁxes in the set
R j−1 ×{0,1}λ j−λ j−1, where R j−1 is the set of top-k λ j−1-bits
preﬁxes identiﬁed in the ( j− 1)th iteration and the × symbol
denotes Cartesian product. After estimating the frequencies
of these λ j-bits preﬁxes, the central server identiﬁes the top-k
most frequent ones, which are denoted as the set R j. This pro-
cess is repeated for the g groups and the set of top-k preﬁxes
in the ﬁnal iteration are identiﬁed as the top-k heavy hitters.
(cid:3)
(cid:4)
g
2.3 Data Poisoning Attacks
Data poisoning attacks to LDP protocols: A concurrent
work [13] studied untargeted attacks to LDP protocols. In
particular, they focused on degrading the overall performance
of frequency estimation or heavy hitter identiﬁcation. For
instance, we can represent the estimated frequencies of all
items as a vector, where an entry corresponds to an item. They
studied how an attack can manipulate the Lp-norm distance
between such vectors before and after attack. In contrast,
we study targeted attacks that aim to increase the estimated
frequencies of the attacker-chosen target items or promote
them to be identiﬁed as heavy hitters. We note that the Lp-
norm distance between the item frequency vectors is different
from the increased estimated frequencies for the target items.
For instance, L1-norm distance between the item frequency
vectors is a loose upper bound of the increased estimated
frequencies for the target items.
Data poisoning attacks to machine learning: A line of
works [7, 11, 23–25, 27–30, 35–39, 41–44, 49, 50, 58, 65] stud-
ied data poisoning attacks to machine learning systems. In
particular, the attacker manipulates the training data such
that a bad model is learnt, which makes predictions as the at-
tacker desires. For instance, Biggio et al. [11] investigated data
poisoning attacks against Support Vector Machines. Jagiel-
ski et al. [29] studied data poisoning attacks to regression
models. Shafahi et al. [50] proposed poisoning attacks to
neural networks, where the learnt model makes incorrect
predictions only for target testing examples. Gu et al. [27]
and Liu et al. [36] proposed data poisoning attacks (also
called backdoor/trojan attacks) to neural networks, where
the learnt model predicts an attacker-chosen label for test-
ing examples with a certain trigger. Data poisoning attacks
were also proposed to spam ﬁlters [41], recommender sys-
tems [24,25,35,65], graph-based methods [55], etc.. Our data
poisoning attacks are different from these attacks because
how LDP protocols aggregate the users’ data to estimate fre-
quencies or identify heavy hitters is substantially different
from how a machine learning system aggregates training data
to derive a model.
3 Attacking Frequency Estimation
3.1 Threat Model
We characterize our threat model with respect to an attacker’s
capability, background knowledge, and goal.
Attacker’s capability and background knowledge: We as-
sume an attacker can inject some fake users into an LDP
protocol. These fake users can send arbitrary data in the en-
coded space to the central server. Speciﬁcally, we assume
n genuine users and the attacker injects m fake users to the
system. Therefore, the total number of users becomes n + m.
We note that it is a practical threat model to assume that an
950    30th USENIX Security Symposium
USENIX Association
attacker can inject fake users.In particular, previous measure-
ment study [54] showed that attackers can easily have access
to a large number of fake/compromised accounts in various
web services such as Twitter, Google, and Hotmail. Moreover,
an attacker can buy fake/compromised accounts for these
web services from merchants in the underground market with
cheap prices. For instance, a Hotmail account costs $0.004 –
0.03; and a phone veriﬁed Google account costs $0.03 – 0.50
depending on the merchants.
Since an LDP protocol executes the encode and perturb
steps locally on users’ side, the attacker has access to the
implementation of these steps. Therefore, the attacker knows
various parameters of the LDP protocol. In particular, the
attacker knows the domain size d, the encoded space D, and
the support set S(y) for each perturbed value y ∈ D.
Attacker’s goal: We consider the attacker’s goal is to pro-
mote some target items, i.e., increase the estimated frequen-
cies of the target items. For example, a company may be
interested in making its products more popular. Formally,
we denote by T = {t1,t2,··· ,tr} the set of r target items. To
increase the estimated frequencies of the target items, the at-
tacker carefully crafts the perturbed values sent from the fake
users to the central server. We denote by Y the set of crafted
perturbed values for the fake users, where an entry yi of Y
is the crafted perturbed value for a fake user. The perturbed
value yi could be a number (e.g., for kRR protocol), a binary
vector (e.g., for OUE), and a tuple (e.g., for OLH).
Suppose ˜ft,b and ˜ft,a are the frequencies estimated by the
LDP protocol for a target item t before and after attack, re-
spectively. We deﬁne the frequency gain Δ ˜ft for a target item
t as Δ ˜ft = ˜ft,a − ˜ft,b,∀t ∈ T . A larger frequency gain Δ ˜ft im-
plies a more successful attack. Note that an LDP protocol
perturbs the value on each genuine user randomly. Therefore,
the frequency gain Δ ˜ft is random for a given set of crafted
perturbed values Y for the fake users. Thus, we deﬁne the
attacker’s overall gain G using the sum of the expected fre-
quency gains for the target items, i.e., G(Y) = ∑t∈T E[Δ ˜ft ],
where Δ ˜ft implicitly depends on Y. Therefore, an attacker’s
goal is to craft the perturbed values Y to maximize the over-
all gain. Formally, the attacker aims to solve the following
optimization problem:
max
Y
G(Y).
(8)
We note that, to incorporate the different priorities of the
target items, an attacker could also assign different weights to
the expected frequency gains E[Δ ˜ft ] of different target items
when calculating the overall gain. Our attacks are also appli-
cable to such scenarios. However, for simplicity, we assume
the target items have the same priority.
3.2 Three Attacks
We propose three attacks: Random perturbed-value attack
(RPA), random item attack (RIA), and Maximal gain attack
(MGA). RPA selects a perturbed value from the encoded space
of the LDP protocol uniformly at random for each fake user
and sends it to the server. RPA does not consider any informa-
tion about the target items. RIA selects a target item from the
set of target items uniformly at random for each fake user and
uses the LDP protocol to encode and perturb the item. MGA
crafts the perturbed value for each fake user to maximize the
overall gain G via solving the optimization problem in Equa-
tion (8). RPA and RIA are two baseline attacks, which are
designed to better demonstrate the effectiveness of MGA.
Random perturbed-value attack (RPA): For each fake
user, RPA selects a value from the encoded space of the LDP
protocol uniformly at random and sends it to the server.
Random item attack (RIA): Unlike RPA, RIA considers in-
formation about the target items. In particular, RIA randomly
selects a target item from the set of target items for each fake
user. Then, the LDP protocol is applied to encode and perturb
the item. Finally, the perturbed value is sent to the server.
Maximal gain attack (MGA): The idea behind this attack is
to craft the perturbed values for the fake users via solving the
optimization problem in Equation (8). Speciﬁcally, according
to Equation (3), the frequency gain Δ ˜ft for a target item t is:
Δ ˜ft =
=
1
n+m
n+m∑
i=1
1S(yi)(t)− q
p− q
n+m∑
1S(yi)(t)
i=n+1
(n + m)(p− q)
n∑
i=1
1
n
n∑
i=1
−
1S(yi)(t)− q
p− q
1S(yi)(t)
− m
n(n + m)(p− q)
,
(9)
(10)
where yi is the perturbed value sent from user i to the server.
The ﬁrst term in Equation (10) only depends on fake users,
while the second term only depends on genuine users. More-
over, the expected frequency gain for a target item t is:
E[Δ ˜ft ] =
n+m∑
E[1S(yi)(t)]
i=n+1
(n + m)(p− q)
− m
n∑
E[1S(yi)(t)]
i=1
n(n + m)(p− q)
,
(11)
where we denote the second term as a constant ct for simplic-
ity. Moreover, based on Equation (4), we have:
ct = m( ft (p− q) + q)
(n + m)(p− q)
,
(12)
where ft is the true frequency of t among the n genuine users.
Furthermore, we have the overall gain as follows:
G =
∑
t∈T
− c,
E[1S(yi)(t)]
n+m∑
i=n+1
(n + m)(p− q)
where c = ∑t∈T ct = m( fT (p−q)+rq)
, where fT = ∑t∈T ft. c
(n+m)(p−q)
does not depend on the perturbed values sent from the fake
users to the central server. In RPA and RIA, the crafted per-
turbed values for the fake users are random. Therefore, the
expectation of the characteristic function E[1S(yi)(t)] and the
overall gain depend on such randomness. However, MGA
(13)
USENIX Association
30th USENIX Security Symposium    951
uses the optimal perturbed values for fake users, and the char-
acteristic function 1S(yi)(t) becomes deterministic. Therefore,
for MGA, we can drop the expectation E in Equation (13), and
then we can transform the optimization problem in Equation
(8) as follows:
n+m∑
∑
t∈T
Y∗ = argmax
Y
Y
i=n+1
1S(yi)(t),
G(Y) = argmax
(14)
where we remove the constants c and (n +m)(p−q) in the op-
timization problem. Note that the above optimization problem
only depends on the perturbed values of the fake users, and
the perturbed values yi for the fake users are independent from
each other. Therefore, we can solve the optimization prob-
lem independently for each fake user. Formally, for each fake
∗ via solving the following
user, we craft its perturbed value y
optimization problem:
∗ = argmax
y
y∈D
∑
t∈T
1S(y)(t).
(15)
We note that, for each fake user, we obtain its perturbed
value via solving the same above optimization problem. How-
ever, as we will show in the next sections, the optimization
problem has many optimal solutions. Therefore, we randomly
pick an optimal solution for a fake user.
Next, we discuss how to apply these three attacks to state-
of-the-art LDP protocols including kRR, OUE, and OLH, as
well as analyzing their overall gains.
3.3 Attacking kRR
Random perturbed-value attack (RPA): For each fake user,
RPA randomly selects a perturbed value yi from the encoded
space, i.e., [d], and sends it to the server. We can calculate the
expectation of the characteristic function for t ∈ T as follows:
(16)
(17)
E[1S(yi)(t)] = Pr(1S(yi)(t) = 1)
= Pr(t ∈ S(yi)) = Pr(yi = t)
= 1
d
rm
d(n+m)(p−q) − c.
Therefore, according to Equation (13), the overall gain is
G =
Random item attack (RIA): For each fake user, RIA ran-
domly selects an item ti from the set of target items T , per-
turbs the item following the rule in Equation (5), and sends
the perturbed item yi to the server. First, we can calculate the
expectation of the characteristic function as follows:
(18)
(19)
(20)
E[1S(yi)(t)] = Pr(yi = t)
= Pr(ti = t)Pr(yi = t|ti = t)
+ Pr(ti (cid:4)= t)Pr(yi = t|ti (cid:4)= t)