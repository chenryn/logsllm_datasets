Throughout this paper, we use λ as the security parameter. We use negl(λ) to denote
that some function is negligible in λ. Calligraphic letters are used for sets and algorithms.
A shorthand x ← X denotes that x is drawn uniformly from a set X . For algorithms and
distributions, the same notation x ← A means that the element x is sampled according
to the (output) distribution. When A is a probabilistic algorithm, we use A(x; r) to
denote running A on input x with explicate random coin r. Let A = (A1, A2) ∈ G2
and B = (B1, B2) ∈ G2 be two ElGamal ciphertexts. By A · B, we denote the direct
product (A1·B1, A2·B2); by Ax we mean (Ax
2). We use Dlogg(h) to label the discrete
logarithm of h with respect to base g.
1, Ax
2.2 Bilinear Groups and SXDH Assumptions
Let Genbp(·) be a probabilistic polynomial time (PPT) bilinear group generator that
takes as input, 1λ and outputs the group parameters, σbp := (p, G1, G2, GT , e, g1, g2),
where (i) G1, G2, GT are cyclic multiplicative groups with prime order p; (ii) g1 ∈ G1
and g2 ∈ G2 are generators of G1 and G2 respectively; (iii) e : G1 × G2 (cid:55)→ GT is a non-
degenerate bilinear pairing such that e(ga
2) = e(g1, g2)ab. We assume the decisional
Diﬃe-Hellman problem is hard in both groups, a.k.a., the symmetric external Diﬃe-
Hellman (SXDH) assumption, stated in Deﬁntion 1, holds for G1 and G2.
1 , gb
5
Deﬁnition 1 (SXDH assumption). We say SXDH assumption holds for Genbp(1λ) if
for any PPT adversary A we have that for i ∈ {1, 2}:
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Pr
 σbp ← Genbp(1λ);
a, b ← Z∗
p :
A(σbp, ga
i , gb
i , gab
i ) = 1
Advsxdh(A) :=
 − Pr
 σbp ← Genbp(1λ);
a, b, c ← Z∗
p :
A(σbp, ga
i , gb
i , gc
i ) = 1
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) = negl(λ),
where Advsxdh(A) is the distinguishing advantage of A.
2.3 Sigma Protocols
Let L be a language in NP and let RL be an eﬃciently computable binary relation
for L. For all (x, w) ∈ RL, we call x the statement and w the witness for x in L. In
a Sigma protocol, the prover P wants to convince the veriﬁer V a statement x ∈ L
in a zero knowledge fashion. More speciﬁcally, Sigma protocols are 3-move public coin
special honest-veriﬁer zero knowledge proofs of knowledge with special soundness. In the
ﬁrst step, the prover publishes a commitment message, denoted as Σ(1). In the second
step, the veriﬁer gives a challenge message, denoted as ch. In the third step, the prover
outputs a response message, denoted as Σ(2). At the end, the transcript (Σ(1), ch, Σ(2))
is publicly veriﬁable with respect to (x,L).
In this work, we employ the Schnorr’s identity protocol [Sch89] to show the knowl-
edge of discrete logarithm. For instance, Σdlog {(s) : h = gs} stands for a Sigma protocol
for the knowledge of secret s satisfying the equation h = gs. We also use the DDH
tuple proof [Cha90] to show the correctness of election parameters. In particular, by
Σddh {(x) : C = Ax ∧ D = Bx}, we mean a Sigma protocol showing the DDH tuple re-
lation of (A, B, C, D).
2.4 Non-interactive Zero Knowledge Proofs.
A non-interactive proof system Γ = (Gencrs, Simcrs, Prov, Vrfy, Sim) for group languages
consists of the following PPT algorithms:
• Gencrs(σbp) is a CRS generation algorithm that takes as input the bilinear group
parameter σbp ← Genbp(1λ) and outputs a common reference string crs.
• Simcrs(σbp) is a CRS simulator that takes as input the bilinear group parameter
σbp ← Genbp(1λ) and outputs a simulated common reference string crs∗ together
with a simulation trapdoor td.
• Prov(crs; x; w) is the prover algorithm that takes as input the common reference
string crs, the statement x and the witness w, and outputs a proof π.
• Vrfy(crs; x; π) is the veriﬁer algorithm that takes as input the common reference
string crs, the statement x and the proof π, and outputs 1 if the proof is acceptable
and 0 otherwise.
• Sim(crs∗; x; td) is the proof simulator that takes as input the simulated crs∗, the
statement x and the simulation trapdoor td, and outputs a simulated proof π∗.
Deﬁnition 2 (NIZK). We say that Γ = (Gencrs, Simcrs, Prov, Vrfy, Sim) is a non-
interactive zero knowledge (NIZK) proof system for group language L if it has com-
pleteness, soundness, and zero knowledge properties described below.
6
1. Perfect completeness:
2. Perfect soundness: for all adversaries A,
Pr
π ← Prov(crs; x; w) : Vrfy(crs; x; π) = 1 ∨ (x, w) (cid:54)∈ RL
(cid:20) σbp ← Genbp(1λ); crs ← Gencrs(σbp); (x, w) ← A(crs);
(cid:21)
(cid:20) σbp ← Genbp(1λ); crs ← Gencrs(σbp);
(x, π) ← A(crs) : Vrfy(crs; x; π) = 1 ∧ x (cid:54)∈ L
Pr
= 0
(cid:21)
= 1
3. Computational zero-knowledge: there exists a pair of probabilistic polynomial time
simulators (Simcrs, Sim) such that for all non-uniform polynomial time adversaries
A,(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Pr
 σbp ← Genbp(1λ);
crs ← Gencrs(σbp) :
AProv(crs;·;·)(crs) = 1
 − Pr
 σbp ← Genbp(1λ);
(crs∗, td) ← Simcrs(σbp) :
ASim∗(crs∗,td,·,·)(crs∗) = 1
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) = negl(λ),
where Sim∗(crs∗, td, x, w) = Sim(crs∗, x, td) for (x, w) ∈ RL and both oracles output
⊥ if (x, w) (cid:54)∈ RL.
3 E-voting Security Framework
3.1 Syntax
An e-voting system is an interactive protocol Π among an election authority EA, a
bulletin board BB, a set of voters V = {V1, . . . , Vn} (who may utilize a voter supporting
device (VSD) to vote), and a set of trustees T = {T1, . . . , Tt}. Let O = {opt1, ..., optm}
be the set of election options. We denote by U ⊆ 2O the collection of subsets of options
that the voters are allowed to choose to vote. We denote the option selection of voter
V(cid:96) as U(cid:96) ∈ U, which is a subset of the options.
Let (cid:126)U be the set of vectors of option selections of arbitrary length. Let F : (cid:126)U (cid:55)→
(Z+)m be the election evaluation function such that F (U1, . . . ,Un) is equal to an m-
vector whose i-th location is equal to the number of times opti was chosen in the option
selections U1, . . . ,Un.
Similar as [KZZ15], we consider an e-voting system Π as a quintuple of algorithms
and protocols that are denoted by (Setup, Cast, Tally, Result, Verify) as follows:
• Setup is a protocol executed among the trustees T , the election authority EA, and
the bulletin board BB. During the protocol, the election public parameters includ-
ing V,O,U are generated and published on BB. The voters’ credentials (s1, . . . , sn)
are generated and distributed to the voters. After the protocol execution, each
trustee Ti obtains a private state sti.
• Cast is a protocol executed between the voter V(cid:96) (who operates a VSD) and BB.
In the protocol, V(cid:96) posts her ballot blt(cid:96) to BB and obtains a receipt rec(cid:96).
• Tally is a protocol executed among T1, . . . , Tt, EA and BB. In the protocol, each
Ti sends her partial tally data tai to the EA, and the EA will post the received
data to BB after all Ti complete their Tally protocols.
7
The ideal election process for privacy F m,n
priv .
• Upon receiving (sid, init,O,V,U) from EA, it parses O as options {opt1, ..., optm}, V as
voters {V1, ..., Vn}, and U voting option selections U ⊆ 2O. It sets the election status to
‘vote’ and initiliazes a list records as empty. Finally, it sends (sid, vote,O,V,U) to the
adversary S.
• Upon receiving (sid, cast,U(cid:96)) from V(cid:96), if the election status is ‘vote’ and U(cid:96) ∈ U, then it
sends (sid, cast, V(cid:96)) to S.
• Upon receiving (sid, cast, V(cid:96)) from S, if the election status is ‘vote’ and (sid, cast,U(cid:96)) was
sent before by V(cid:96), it adds (V(cid:96),U(cid:96)) to records.
• Upon receiving (sid, tally) from S, if the election status is ‘vote’, it sets the election status
to ‘tally’ and computes the election result τ ← F ((cid:104)U(cid:96)(cid:105)(V(cid:96),U(cid:96))∈records). Finally, it sends τ
to S.
Figure 1: The ideal process F m,n
priv interacting with the ideal world adversary S.
• Result is an algorithm that takes as input the election transcript info on BB, and
outputs the election result or returns ⊥ in case such result is undeﬁned.
• Verify is an algorithm that takes as input the election transcript info on BB and
an auxiliary information aux, and outputs 0 or 1. aux can be either a voter’s
receipt, rec(cid:96) or a trustee’s private state sti.
3.2 Simulation-based Privacy
priv
We model privacy as indistinguishability between a real-world experiment and an ideal
world experiment.
In the ideal experiment, we consider an ideal process F m,n
priv deﬁned in Figure 1 that
captures the essential aspects of the election functionality from a privacy perspective (we
stress that this is not a full ideal functionality as it is not intended to capture correctness
or veriﬁability which we model separately). All the voters V1, . . . , Vn, are modeled as
dummy parties that simply forward the inputs they receive from the environment Z
. Note that the environment Z can schedule all the election
to the ideal process F m,n,t
entities arbitrarily. The ideal world adversary S that is active in the experiment interacts
with F m,n
priv and provides output to Z which makes a ﬁnal decision outputing a bit.
Note that the interaction between Z and S is restricted in this way (in the spirit of
[Can98]) since in our setting it is impossible to achieve stronger notions of simulation-
based security (such as universal composition, [Can01]). We denote the output of the
environment in the ideal experiment by IDEALF m,n
In the real world experiment, the entities T = T1, . . . , Tt, V = V1, . . . , Vn, EA, BB
participate in the e-voting system Π = (Setup, Cast, Tally, Result, Verify) in the
presence of an adversary A who has corrupted up to k voters and t − 1 trustees. The
voters and the trustees run the protocol on command by the environment Z. We denote
the output of the environment in the real world experiment by REALΠ,A,Z (λ). The
objective of the adversary is to obtain suﬃcient information about the honest voters’
option selection so that, in collaboration with the environment, is able to distinguish
the real from the ideal world execution.
priv ,S,Z (λ).
8
We say that the e-voting system is private if for all real-world adversaries A there is
a simulator S so that it is impossible for any environment Z to distinguish between the
real and ideal world experiment. Formally, we deﬁne it as follows.
Deﬁnition 3. Let n, m, t, k ∈ N with k ≤ n and let Π = (Setup, Cast, Tally, Result,
Verify) be an e-voting system with t trustees and n voters. We say that Π is k-private if
for every PPT adversary A controlling up to k voters and up to t−1 trustees, there is an
adversary S in the ideal world experiment, such that for every environment Z the random
variables IDEALF m,n
priv ,S,Z (λ) and REALΠ,A,Z (λ) are computationally indistinguishable.
3.3 E2E Veriﬁability
We would like to extend the E2E veriﬁability deﬁnition in [KZZ15] by adding VSD and
trustees. Similarly, we use the metric d1(·,·) derived by the 1-norm, (cid:107)·(cid:107)1 scaled to half,
i.e.,
2 ·(cid:80)n
d1 : Zm
+ −→ R
+ × Zm
(w, w(cid:48))
(cid:55)−→ d1(w, w(cid:48)) = 1
2 · (cid:107)w − w(cid:48)(cid:107)1 = 1
i=1 |wi − w(cid:48)
i|
to measure the adversarial success rate with respect to the amount of tally deviation d
and the number of voters that perform audit θ. The adversary starts by selecting the
voter, options and trustee identities for given parameters n, m, k. It also speciﬁes the
set U of the allowed ways to vote. The adversary now fully controls all the trustees and
the EA. The adversary manages the Cast protocol executions, playing the role of the
VSD. For each voter, the adversary may choose to corrupt it or to allow the challenger
to play on its behalf. In the second case, the adversary provides the option selection
that the honest voter will use in the Cast protocol. The adversary ﬁnally posts the
election transcript to the BB.
As in [KZZ15], we consider a vote extractor algorithm E (not necessarily running
in polynomial-time) that explains the election transcript from the dishonest voters’
aspect. The adversary will win the game provided that there is a subset of θ honest
voters that audit the result successfully but the deviation of the tally is bigger than d;
the adversary will also win in case the vote extractor fails to produce the option selection
of the dishonest voters but still, θ honest voters verify correctly. The attack game is
speciﬁed in detail in Figure 2.
Deﬁnition 4 (E2E-Veriﬁability). Let 0 <  < 1 and m, n, t, d, θ ∈ N with θ ≤ n and
Π an e-voting protocol with n voters and t trustees. Π achieves E2E veriﬁability with
error , w.r.t. the election function F , a number of θ honest successfull voters and tally
deviation d if there exists a (not necessarily polynomial-time) vote extractor E such that
for any PPT adversary A it holds that
A,E,d,θ