(c) AstroPh dataset
number of nodes participating in the second data collection step in
the proposed improved solution. Figure 4 depicts the upper bound
of LSG(Γ△), i.e., ϵ1λ from Phase 1 as a function of h. For each of
the datasets, for better presentation, the figure only shows three
curves for three values of ϵ1 = {0.1, 0.3, 0.5}, corresponding to the
total budget ϵ = {1, 3, 5}. The valleys represent the optimal value
of h, i.e., with the lowest ϵ1λ, while the vertical lines represent
the heuristic value of h as computed in Lines 7-10 in Algorithm 1.
The figure confirms that the heuristic values of h are close to the
optimal ones. For example, on the Facebook dataset, the optimal
and heuristic values are exactly the same for ϵ1 = 0.1 and ϵ1 = 0.3,
while in the case of ϵ1 = 0.5, the heuristic deviates by 1 from the
optimal value, which results in only 6% increase of the upper bound
compared to its optimal value. The figure also shows that the noise
scale varies across the datasets, with Facebook being the lowest
(e.g., ϵ1λ = 1443 for ϵ1 = 0.3) and HepPh being the highest (e.g.,
ϵ1λ = 1749 for ϵ1 = 0.3). This is simply because the local sensitiv-
ity depends on the dataset properties, i.e., number of nodes, node
degrees, node degree distribution.
Evaluation metric. We evaluate the accuracy of our approach
in counting subgraph patterns (triangle, 3-hop path, and k-clique)
on all the aforementioned datasets and compare it with that of
the baselines. The accuracy of each method (M) on graph (G) is
measured by the mean relative error (MRE), that is, MRE(M, G) =
|M(G) − f (G)|/f (G), where M(G) is the differential private sub-
graph pattern count in input graph G, and f (G) is the true subgraph
count in G. Each result reported is averaged over 300 repeated runs.
Triangle counts. The MRE of triangle counts of all the methods
on all the datasets are depicted on Figure 5 while the privacy bud-
get (ϵ) varies from 1 to 10. The results show that our optimized
approach achieves good accuracy over all datasets. The proposed so-
lution Mo(△) clearly outperforms all the other differential private
methods in terms of result accuracy. Note that the difference is sig-
nificant since MRE is plotted in log-scale. In the Facebook dataset,
for example, when privacy budget is relatively large, e.g., ϵ = 5, its
MRE always stays below or close to 0.49%. When ϵ decreases, the
accuracy drops but it is still smaller than 3.8% even when ϵ = 1.
The result of the first-cut solution Mc(△) is close to Mo(△) in the
case of HepPh and AstroPh datasets, with Mo(△) strictly better.
However, Mo(△) significantly enhances the accuracy compared to
Mc(△) for the Facebook dataset.
3-hop counts. Figure 6 shows the results for the 3-hop counts.
Again, the figure shows that our improved approach achieves good
accuracy over all datasets. Mo(⊔) clearly outperforms all the other
differential private methods including Mc(⊔), simply because it
injects less noise into the true results. The general trend in the
results of 3-hop counts is the same as that of triangle counts across
datasets and differential private approaches. However, we first note
that, even though the number of 3-hop counts is larger than that
of triangles, triangle counts are more accurate than those of 3-hop
counts. This is because the local sensitivity of triangle counts is
much smaller than that of 3-hop counts. Second, we note that the
difference between Mo(⊔) and Mc(⊔) is bigger than the difference
between Mo(△) and Mc(△). This is because Mo(⊔) uses a much
tighter bound for the noise scale compared to Mc(⊔), while the
noise scale in Mo(△) is not as much tight compared to Mc(△).
First cut two-Phase
Optimized three-phase
Pessimistic Laplace
LDPGen
E
R
M
100
10−1
10−2
10−3
101
100
10−1
E
R
M
E
R
M
101
100
10−1
10−2
10−3
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(a) Facebook dataset
102
101
100
10−1
10−2
E
R
M
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(b) HepPh dataset
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(c) AstroPh dataset
First cut two-Phase
Figure 6: 3-hop-path Counting
Optimized two-phase
Pessimistic Laplace
LDPGen
102
101
100
10−1
10−2
E
R
M
E
R
M
103
102
101
100
10−1
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(c) AstroPh dataset
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(b) HepPh dataset
Figure 7: 4-Clique Counting
1 2 3 4 5 6 7 8 9 10
Privacy budget ϵ
(a) Facebook dataset
Finally, we note that the drop in MRE as ϵ increases is faster in
the case of 3-hop counts compared to triangle counts for both Mo
and Mc. For example, in the Facebook dataset, the MRE of Mo(⊔)
drops from 14.7% when ϵ = 1 to 0.44% when ϵ = 5.
4-clique counts. Figure 7 shows the results for the 4-clique counts.
k-clique counting for a larger k > 4 would be expensive to evalu-
ate due to the high time complexity of counting such cliques. Our
proposed approach Mo(4C) once again achieves good accuracy
over all datasets, and consistently outperforms its competitors. The
general trend in the results of 4-clique counts is the same as that of
triangle counts across datasets and differential private approaches.
However, triangle counts are much more accurate than 4-clique
counts due to the larger scale of 4-cliques in Eq. (14) compared to tri-
angles. We also note that LDPGen is strictly better than Pessimistic
Laplace for all privacy budgets on all the datasets.
6 RELATED WORK
Differential privacy [11] has attracted widespread attention from
both academia and industry in the last decade. There are two exist-
ing models of differential privacy: centralized differential privacy
(CDP) and local differential privacy (LDP). In CDP, data from indi-
viduals are collected and maintained by a trusted centralized data
curator. The trusted curator executes a DP mechanism on the sen-
sitive data and releases outputs, e.g., to untrusted data analysts.
In LDP, there is no trusted centralized data curator. Rather, each
individual perturbs its own data using a (local) differentially private
algorithm. The data analyst collects these perturbed data, and uses
it to infer aggregate statistics of the datasets. In a broader sense,
this work falls into the category of differential privacy in the lo-
cal setting [10], and our privacy definition (i.e., DDP) generalizes
existing LDP definitions by considering extended local views.
Graph analysis with CDP. Graph analysis under the CDP setting
has been studied intensively in the literature. Two different CDP
models were defined for graph analysis: edge differential privacy
and node differential privacy. Edge differential privacy considers
two graphs as neighbors if they differ in one edge, while node
differential privacy considers two graphs as neighbors if one can be
obtained from the other by deleting a node and its adjacent edges.
Edge differentially private algorithms have focused on releasing
various types of graph statistics, including degree distributions
[19, 22, 28], cuts [3, 17, 18], degree sequences [19, 22], k-stars and k-
triangles [29], and subgraph counts [4, 21, 34, 42]. Triangle counting
queries can be answered with edge differential privacy by efficiently
computing the smooth sensitivity [30], empirical sensitivity [6],
and ladder functions [42].
Earlier works on graph analysis under node differential privacy
include [4, 6, 24]. Gehrke et al. [16] defined a generalization of
differential privacy, called zero-knowledge privacy, that enforces
node differentially privacy for bounded-degree graphs. [5, 33] fo-
cus on high-dimension graph data release with node differential
privacy. Day et al. [8] investigated graph data publishing under
node-differential privacy. Continuous release of graph statistics
(e.g., degree distributions and subgraph counts) with node differ-
ential privacy has been initiated in [36]. All these CDP solution
(for both edge and node differential privacy) require that the data
publisher has the full knowledge of the whole input graph. There-
fore, they are not applicable to our setting, where the social graph
is decentralized and no party knows the full graph.
Graph analysis with LDP. The LDP notion [23] assumes there is
no trusted centralized data curator. Randomized response [41] is
one of the simplest LDP techniques. However, directly applying
the randomized response method on the local graph information
(e.g., neighbor lists) collected from individual users may ruin the
property (e.g., sparsity) of the original graph [32]. Gao et al. [15]
transform the local graphs into neighbor lists and apply the hierar-
chical random graph (HRG) approach to add noise on the neighbor
lists. Qin et al. [32] design LDPGen, a multi-phase technique that
generates representative synthetic decentralized social graphs with
local differential privacy. The synthetic graphs can be used for vari-
ous graph analysis, such as graph modularity, clustering coefficient
and assortativity coefficient. To our best knowledge, ours is the
first work that considers subgraph counts in decentralized social
networks with differential privacy guarantees, and the first to con-
sider the case where each node possesses an extended local view
with information beyond direct connections.
LDP for other types of data analysis. Finally, beyond social
graph analysis, LDP algorithms for a variety of tasks have been
widely investigated recently. Examples include frequency estima-
tion [13, 39], heavy hitters [2, 14, 31], frequent itemsets [40], and
marginal tables [7, 43]. The LDP model has been applied to the col-
lection of various data types, including location [9] and positioning
data [25], responses from crowdsourcing workers [27, 35, 37], and
user data on mobile devices [38].
7 CONCLUSION
Given that more and more data are generated in the context of so-
cial networks and the well-spread concern of privacy, the problem
of decentralized social network analysis would become increasingly
important and relevant in practice. Our work is the one of first ef-
forts toward develop privacy-preserving techniques to address the
problem. With the proposed concept of decentralized differential
privacy, our framework could be extended in multiple directions.
For one, diverse local view models could be further considered. For
example, in some social networks, though one cannot see all his two
hop neighbors, the connections between her one-hop neighbors
would be visible. How to accurately estimate relevant graph prop-
erties with such local views under DDP would be interesting future
work. Another important direction is to integrate our framework
with specific social network applications and carry out more so-
phisticated graph analysis tasks (e.g., community discovery, social
graph recommendation).
ACKNOWLEDGMENTS
This publication was made possible by NPRP grant NPRP10-0208-
170408 from the Qatar National Research Fund (a member of Qatar
Foundation), and by the National Science Foundation (NSF), USA
under grant No. 1350324. The findings herein reflect the work, and
are solely the responsibility, of the authors. This work was also
supported by the National Research Foundation, Prime Minister's
Office, Singapore under its Strategic Capability, and by the Research
Centres Funding Initiative, Provincial Key Research and Develop-
ment Program of Zhejiang (Grant No. 2019C03133) and Major Sci-
entific Research Project of Zhejiang Lab (Grant No. 2018FD0ZX01).
REFERENCES
[1] Borja Balle and Yu-Xiang Wang. 2018. Improving the Gaussian Mechanism for
Differential Privacy: Analytical Calibration and Optimal Denoising. In Interna-
tional Conference on Machine Learning. 403–412.
[2] Raef Bassily and Adam Smith. 2015. Local, private, efficient protocols for succinct
histograms. In Proceedings of the forty-seventh annual ACM symposium on Theory
of computing. 127–135.
[3] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. 2012. The johnson-
lindenstrauss transform itself preserves differential privacy. In 2012 IEEE 53rd
Annual Symposium on Foundations of Computer Science. 410–419.
[4] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. 2013. Differentially
private data analysis of social networks via restricted sensitivity. In Proceedings
of the 4th conference on Innovations in Theoretical Computer Science. 87–96.
[5] Christian Borgs, Jennifer Chayes, and Adam Smith. 2015. Private graphon esti-
mation for sparse graphs. In Advances in Neural Information Processing Systems.
1369–1377.
[6] Shixi Chen and Shuigeng Zhou. 2013. Recursive mechanism: towards node
differential privacy and unrestricted joins. In Proceedings of the 2013 ACM SIGMOD
International Conference on Management of Data. 653–664.
[7] Graham Cormode, Tejas Kulkarni, and Divesh Srivastava. 2018. Marginal release
under local differential privacy. In Proceedings of the 2018 International Conference
on Management of Data. 131–146.
[8] Wei-Yen Day, Ninghui Li, and Min Lyu. 2016. Publishing graph degree distribution
with node differential privacy. In Proceedings of the 2016 International Conference
on Management of Data. 123–138.
[9] Rinku Dewri. 2013. Local differential perturbations: Location privacy under
approximate knowledge attackers. IEEE Transactions on Mobile Computing 12, 12
(2013), 2360–2372.
[10] John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. 2013. Local Privacy
and Statistical Minimax Rates. In 54th Annual IEEE Symposium on Foundations
of Computer Science, FOCS 2013, 26-29 October, 2013, Berkeley, CA, USA. 429–438.
https://doi.org/10.1109/FOCS.2013.53
[11] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
brating noise to sensitivity in private data analysis. In Theory of cryptography
conference. Springer, 265–284.
[12] Cynthia Dwork and Aaron Roth. 2014. The Algorithmic Foundations of Differen-
tial Privacy. Found. Trends Theor. Comput. Sci. 9, 3&#8211;4 (Aug. 2014), 211–407.
https://doi.org/10.1561/0400000042
[13] Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. 2014. Rappor: Random-
ized aggregatable privacy-preserving ordinal response. In Proceedings of the 2014
ACM SIGSAC conference on computer and communications security. 1054–1067.
[14] Giulia Fanti, Vasyl Pihur, and Úlfar Erlingsson. 2016. Building a rappor with
the unknown: Privacy-preserving learning of associations and data dictionaries.
Proceedings on Privacy Enhancing Technologies 2016, 3 (2016), 41–61.
[15] Tianchong Gao, Feng Li, Yu Chen, and XuKai Zou. 2018. Local Differential
Privately Anonymizing Online Social Networks Under HRG-Based Model. IEEE
Transactions on Computational Social Systems 5, 4 (2018), 1009–1020.
[16] Johannes Gehrke, Edward Lui, and Rafael Pass. 2011. Towards privacy for social
networks: A zero-knowledge based definition of privacy. In Theory of Cryptogra-
phy Conference. 432–449.
[17] Anupam Gupta, Aaron Roth, and Jonathan Ullman. 2012. Iterative constructions
and private data release. In Theory of cryptography conference. 339–356.
[18] Moritz Hardt and Guy N Rothblum. 2010. A multiplicative weights mechanism
for privacy-preserving data analysis. In 2010 IEEE 51st Annual Symposium on
Foundations of Computer Science. 61–70.
[19] Michael Hay, Chao Li, Gerome Miklau, and David Jensen. 2009. Accurate es-
timation of the degree distribution of private networks. In 2009 Ninth IEEE
International Conference on Data Mining. 169–178.
[20] Michael Hay, Chao Li, Gerome Miklau, and David D. Jensen. 2009. Accurate
Estimation of the Degree Distribution of Private Networks. In ICDM 2009, The
Ninth IEEE International Conference on Data Mining, Miami, Florida, USA, 6-9
December 2009. 169–178. https://doi.org/10.1109/ICDM.2009.11
[21] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev.
2011. Private analysis of graph structure. Proceedings of the VLDB Endowment 4,
11 (2011), 1146–1157.
[22] Vishesh Karwa and Aleksandra B Slavković. 2012. Differentially private graphical
degree sequences and synthetic graphs. In International Conference on Privacy in
Statistical Databases. 273–285.
[23] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova,
and Adam Smith. 2011. What can we learn privately? SIAM J. Comput. 40, 3
(2011), 793–826.
[24] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam