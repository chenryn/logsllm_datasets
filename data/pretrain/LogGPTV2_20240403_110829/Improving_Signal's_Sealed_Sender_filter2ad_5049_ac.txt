Later work also includes a theoretical bound [44], but their
model is much more general than ours, where they seek to
reveal the entire network rather than a single target user.
Theoretical attack success bound. In our attack, all users
in the system are ranked according to their chances of being
an associate of Bob after some number of target and random
epochs. We now provide bounds on the number of epochs
necessary to ensure that an arbitrary associate Alice is ranked
higher than all non-associates.
Theorem 1. Assume m total users in a messaging system. Let
Alice be an associate of the target Bob with probabilities ra, ta
of appearing in a random or target epoch respectively. Then,
under the stated assumptions above, the probability that Alice
B. Attack simulation
We cannot directly validate the effectivenesses of our
attacks in practice, as we do not have access to Signal’s
servers and there is no public sample dataset of Signal sealed
sender messages. Instead, we perform simulations based on
generalized but realistic assumptions on message patterns. We
do not claim our simulations will reveal the exact number
4Unfortunately, there appear to be at least three slightly different versions of
this bound in the published literature ([14, equation (6)]; [15, equation (9.8)];
[40, page 5]), making it difﬁcult to compare bounds.
6
Fig. 5: Left: Effect of delayed Read Receipts — The attack assumes that each epoch lasts one second, and thus the log collects all delivery
receipts that are sent within 1 second of Bob receiving a sealed sender message. A possible simple solution to this attack is to delay delivery
receipts. We tested the effectiveness of the attack with variably sized epochs and determined that if delivery receipts were delayed a full hour
(making them effectively worthless for their purpose) that with a user base of 500,000 users (each sending 50 messages a day) Bob would
need to receive 60 messages from the victim user to identify Alice as the sender.
Right: Effect of popular users in our SDA — We examined the effectiveness of our SDA variant by examining the cases where only Alice is
messaging Bob and where Bob is being messaged by Alice and 5 other users. The graph shows the rank of those messaging Bob, how many
users have received more messages than those messaging Bob. When only Alice is messaging Bob each of the attack epochs are started by
her, meaning her rank will very quickly drop. When multiple users are messaging Bob there is a range of ranks, represented by the green band
which bounds the lowest ranked user messaging Bob (on the bottom) and the highest ranked individual messaging Bob (on the top). When
epochs are begun by multiple users, an individual’s rank takes a while to drop. The graph shows that for over 45 epochs one of the users
messaging Bob has a rank of over 1000, while another user messaging Bob has dropped to a rank of 0 (meaning they have received a message
after Bob received a message the most of any user in the system). The black band considers the same situation, but with 1000 popular users
in the system which our variant accounts for.
of messages needed to deanonymize a particular user, as
that would depend on exact messaging patterns. Rather, our
simulations give a sense of the order of magnitude of messages
needed to deanonymize a user.
We simulated sequences of target and random epochs (e.g.
epochs where Bob does or does not receive a message) and
ranked users by their score. Recall that a user’s score increases
if they appear in a target epoch. We simulated 1 million active
users, with 800 messages per epoch. This corresponds to users
sending on average about 70 messages per day, with 1 second
epochs5.
Within each epoch, we select a random set of 800 message
destinations. In a target epoch, Alice (the associate) is sent
a message to represent Bob’s delivery receipt that would be
sent to her automatically. The remaining messages are chosen
randomly: 25% of messages are selected as “repeat” messages
(same sender and receiver) from prior epochs (representing one
side of a prior conversation), and another 25% are selected
as “responses” to messages in prior epochs (representing a
conversation’s response). The remaining 50% of messages are
messages from and to a random pairing of users from the
set of 1 million active users. We ﬁnd that the percent of
repeats/replies has limited impact on the number of epochs
to identify an associate until over nearly all messages are
repeats (i.e. each epoch is essentially the same small set of
senders/receivers). We choose half of the epochs to be target
5Based off our observation of round-trip delivery receipt times
epochs (where Alice messages Bob) and half as random (where
Alice does not message Bob).
Social graph signiﬁcance. We note our experiment does not
rely on a particular social graph (or rather, assumes a fully
connected one), as any user can message any other. In prelim-
inary experiments, we examined the impact of several different
graph generators that are designed to simulate social networks,
but found no noticable change in our results. Speciﬁcally, we
used the Erd¨os-R´enyi [20] model, Barab´asi-Albert [3] model,
Watts-Strogatz [52] model, and a fully connected graph, but
found they all resulted in a similar number of epochs needed to
deanonymize the associate (Alice). Given this result, we opted
to use the fully connected graph model for simplicity.
Figure 5 shows the result of several attack simulations. We
ran each attack simulation for 100 runs, and at each epoch,
report the average rank of Alice’s score based on our attack.
First, in the “Alice Only” variant, only Alice messages Bob
(and no one else). Even though there are thousands of other
users messaging randomly, Alice’s score quickly becomes the
top ranked user: within 5 messages, she is uniquely identiﬁed
as messaging Bob.
If multiple users are also messaging Bob while Alice does,
it
takes more total epochs to identify Alice (and her co-
associates messaging Bob). In this scenario, each target epoch
is selected to be either Alice or one of 5 co-associates that
messages Bob (6 total conversations with Bob).
7
0500100015002000250030003500Length of epoch (s)01020304050607080Number of messages needed to uniquely identify sender500000 Users250000 Users100000 Users50000 Users020406080100Number of Epochs02004006008001000Rank of Associates of BobAlice Only6 total conversations with Bob1000 popular users and 6 total conversations with BobIf there are popular users present (e.g. users that receive
messages in a large fraction of all epochs), then it may be
more difﬁcult to identify Alice without accounting for them.
However, since we remove users that also appear in a large
fraction of random epochs, Alice is still eventually ranked
uniquely as messaging Bob.
Finally, we combine our popular users and multiple mes-
sagers into a single simulation, which is dominated by the
multiple messagers effects.
Summary. In the worst case, it takes on the order of 60 epochs
to identify the users messaging Bob. Note that only half of
these are messages to Bob, and the other half are random
epochs. If only one person is messaging Bob, the number of
messages needed is under 5 to identify Alice as the associate
of Bob.
V. FORMALIZING SEALED SENDER CONVERSATIONS
Sealed sender messages were initially introduced in Signal
to obscure the communication graph. As we have just shown,
the current instantiation fails to accomplish this goal. Before
we present our solutions to this problem, we brieﬂy discuss
formalizations for the properties that a perfect
implemen-
tation should accomplish. We call such a system a sealed
sender conversation, because unlike sealed sender messages,
the anonymity properties must be maintained throughout the
lifetime of the conversation.
Our goal in introducing this formalization is to specify
exactly how much information a service provider can learn
when it runs a sealed sender conversation protocol. In a sealed
sender conversation between two users, the mediating service
provider should learn only the identity of the receiver of
the ﬁrst message, no matter the messaging pattern of the
users. Unlike sealed sender messages, the anonymity of the
sender must be maintained across the full conversation, not
just individual messages. As such, we require a deﬁnition that
argues about the privacy of the users at the conversation level,
rather than at the message level, as in sealed sender messag-
ing. We formalize sealed sender conversations by giving an
ideal functionality, presented in Figure 6. We note that this
deﬁnition fundamentally reasons over conversations, even if it
does this in a message-by-message way by using an internal
conversation table. Our ideal functionality captures our desired
properties by specifying the maximum permissible information
leakage for each message, depending on which member of the
conversation sent the message.
Our ideal functionality models a sealed sender conversation
and explicitly leaks certain information to the service provider.
Users are able to do three things: (1) start a conversation,
(2) send messages in an existing conversation, and (3) receive
messages. When a user starts a new conversation, the initial
receiver’s identity is leaked to the service provider, along with
a unique conversation identiﬁer cid. All subsequent messages
sent in this conversation are linked with the identiﬁer cid. If
they are being sent to the initial receiver, their destination is
leaked. Otherwise, the service provider learns that the message
is part of some known cid, but never learns the identity
of that end of the conversation. While we do not explicitly
include timestamps in our modeling, timestamps are implicitly
captured by our model because the service provider is notiﬁed
immediately whenever the ideal functionality receives a mes-
sage. This is equivalent because the absolute time at which a
message is sent is not important in our context, just the relative
time between messages.
Users receive messages via pull notiﬁcations. These pull
notiﬁcations leak no more information than the message itself
does; if the receiver is anonymous, then the pull notiﬁcation
process leaks no information about the receiver. While we
formalize this notion using pull notiﬁcations, this is compa-
bile with Signal-style push notiﬁcations, where the receiver
and the server maintain long-lived TLS connections. These
communication channels are equivalent to a continuous pull
notiﬁcation, and thus a simulator can easily translate between
the two communication paradigms. Finally, because the service
provider may arbitrarily drop messages, we give the service
provider the power to approve or deny any pull notiﬁcation
request.
While leaking the conversation identiﬁer might seem like
a relaxation of sealed sender messages, we note that our
timing attack succeeds by guessing with high likelihood the
sender of a message. As such, Signal’s sealed sender does
not meet this ideal functionality, as our timing correlation
attack in Section III shows. This is because the cid of a
message, although not explicitly sent with the ciphertext, can
be inferred with high probability by its timing. One ﬁnal note
is our deﬁnition does not prevent a service provider from
using auxiliary information about a conversation (e.g. time
zone information) to reidentify the initiator of the conversation.
Such attacks are incredibly difﬁcult
to formalize and are
beyond the scope of our work. Rather, we only require that the
protocol itself cannot be used to reidentify the participants.
A. Security Deﬁnition for One-Way Sealed Sender Conversa-
tions
We now give a formal deﬁnition for one-way sealed sender
conversations using a simulation based security deﬁnition.
We present the ideal functionality for one-way sealed sender
conversations in Figure 6. Importantly, this deﬁnition does
not rule out learning information about the sender based on
timing of sending messages, e.g. the sender’s time zone. We
model the service provider as a party Pservice that can control
delivery of messages and delivery receipts. Note that the ideal
functionality leaks the contents of the message m to the service
provider only if the receiver of that message is corrupted. This
models that if the service provider can decrypt the messages it
is relaying, it may make delivery decisions based on knowledge
of the plaintext.
We say that a protocol securely realizes this ideal function-
ality (in the stand alone model) if a corrupted service provider
and an arbitrary number of corrupted users cannot determine
if they are interacting in the real experiment or with the
ideal experiment with non-negligible probability in the security
parameter λ. In the real experiment, the adversary starts by
statically corrupting the service provider and any number of
users. Then, each honest user follows it own arbitrary strategy,
interacting with the service provider using the protocol. The
corrupt parties can follow an adversarially chosen strategy. In
the ideal experiment, the adversary again begins by statically
8
Ideal Functionality For Sealed Sender Conversation System
• P1, . . . , Pn: A set of n (possibly corrupt) users of the system
• Pservice: A single corrupt service provider that is in charge of relaying messages between users
• Active Conversation Table Cactive with entries of the form (convo-id, initiator, receiver), Delivery Pending Message
Table Mpending with entries of the form (convo-id, sender, receiver, plaintext)
Start Conversation: Upon receiving a message (StartConvo, Pj) from a user Pi, the ideal functionality generates a unique identiﬁer
cid, and performs the following:
• If Pi or Pj is corrupt, send (ApproveNewConvoCorrupt, Pi, Pj, cid) to Pservice
• If both Pi and Pj are honest, (ApproveNewConvo, Pj, cid) to Pservice
• If Pservice responds with (Disapprove), the ideal functionality halts
• If Pservice responds with (Approve), the ideal functionality sends (NewConvo, Pi, Pj, cid) to both Pi and Pj and adds (cid, Pi, Pj)
Pservice responds to either message with (Approve) or (Disapprove)
to Cactive.
Send Message: Upon receiving a message (SendMessage, cid, m) from party Pi, the ideal functionality checks the active conversations
table Cactive for an entry (cid, Pj, Pi) or (cid, Pi, Pj). If no such entry exists, the ideal functionality drops the message. The ideal
functionality generates a unique identiﬁer mid and performs the following:
• If there is an entry and Pj is corrupted, the ideal functionality sends (NotifySendMessageCorrupt, cid, mid, m, Pi, Pj) to Pservice,
• If an entry (cid, Pi, Pj) exists, send (NotifySendMessage, cid, mid, Pj,|m|) to Pservice, and add (Pi, Pj, cid, mid, m) to Mpending.
• If an entry (cid, Pj, Pi) exists, send (NotifyAnonymousSendMessage, cid, mid,|m|) to Pservice, and add (Pi, Pj, cid, mid, m) to
and add (Pi, Pj, cid, mid, m) to Mpending.
Mpending.
there is an entry (cid, Pj, Pi) in Cactive and entries (Pi, Pj, cid, mid, m) in Mpending,
Receive Message: Upon receiving a message (ReceiveMessage, cid) from party Pj, the ideal functionality checks Cactive for an entry
(cid, Pj, Pi) or (cid, Pi, Pj). If such an entry exist, it performs one of the following:
• If Pi is corrupt, the ideal functionality then sends (ApproveReceiveMessageCorrupt, cid, Pi, Pj) to Pservice, which responds with
• If
tuples of the form (cid, Pi, Pj, m). The ideal functionality then sends (Sent, Pi, Pj, cid, m) to Pj for each such tuple.
functionality sends
(ApproveAnonymousReceiveMessage, cid, mid,|m|) to Pservice for each such entry. Pservice responds to each message with either
(Approve, mid) or (Disapprove, mid). If Pservice responds with (Approve, mid), the ideal functionality sends (Sent, Pi, Pj, cid, m)
to Pj.
functionality sends
(ApproveReceiveMessage, cid, mid,|m|, Pj) to Pservice
responds to each message with either
(Approve, mid) or (Disapprove, mid). If Pservice responds with (Approve, mid), the ideal functionality sends (Sent, Pi, Pj, cid, m)
to Pj.
there is an entry (cid, Pi, Pj) in Cactive and entries (Pi, Pj, cid, mid, m) in Mpending,
for each such entry. Pservice
• If
the ideal
the ideal
Fig. 6: Ideal functionality formalizing the leakage to the service provider for a one-way sealed sender conversation.
corrupting the service provider and any number of users. Then,
the honest players follow an arbitrary strategy but interact
directly with the ideal functionality. The service provider and
corrupted users interact with a simulator Sim, which mediates
interaction between the adversary and the ideal functionality.
At the end of each experiment, a distinguisher algorithm takes
in the views of the service provider and the corrupted parties
and attempts to determine if the interaction was in the real
experiment or the ideal experiment. Note that because the
simulator may not know which parties are interacting, it cannot
leak this information to the adversary.
We denote the output of the ideal world experiment for any
ideal world adversary Sim and honest players with arbitrary
strategies PH on inputs x as IdealPH ,Sim(1λ, x). We denote
the output of the real experiment with adversary A running
protocol Π on input x as RealPH ,A,Π(1λ, x). We say that a
protocol Π securely realizes the ideal functionality described
in Figure 6 if there exists a simulator Sim such that
(cid:12)(cid:12)IdealPH ,Sim(1λ, x) − RealPH ,A,Π(1λ, x)(cid:12)(cid:12) < negl(λ)
VI. SOLUTIONS
We now present three protocols that follow the security
deﬁnition from Section V and, in particular, prevent the attacks
presented in Section III. We ﬁrst outline a one-way sealed
sender conversation in Section VI-B, in which the initiator
of the conversation remains anonymous. We prove that our
construction meets the deﬁnition presented in Section V-A. In
Section VI-C, we extend this protocol to give better privacy
to the receiver using a two-way sealed sender conversation.
Finally, in Section VI-D, we address denial of service attacks
that malicious users could launch against the server.
Overview of Solutions. Our key observation is that the attack
described in Section III is only possible because both users in
a conversation are sending messages to the other’s long-term
identity. Over time, these messages can be correlated, revealing
the identities of the users. On the other hand, if anonymous and
ephemeral identities are used instead, then user’s true identities
can remain hidden. However, anonymous identities lead to a
bootstrapping problem: how do users initiate and authenticate
a conversation if they are using fresh, pseudonyms?
9
In a one-way sealed sender conversations,
the identity
of one side of the conversation is leaked, namely the initial
message receiver, in order to solve this bootstrapping problem.
This closely models the situation of a whistle-blower, where
the informant wishes to stay anonymous, but
the reporter
receiving the information can be public. At a high level, the
initiator of the conversation begins by creating a fresh, anony-
mous identity and then sends this identity to a receiver via a