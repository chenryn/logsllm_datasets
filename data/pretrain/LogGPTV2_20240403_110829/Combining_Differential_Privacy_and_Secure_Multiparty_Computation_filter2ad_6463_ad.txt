1000000
500000
1000000
2000000
10000
20000
50000
100000
200000
500000
1000000
392
405
460
594
866
443
461
532
694
999
759
768
827
962
1184
1099
1285
1774
2625
4426
2455
822
2665
1001
3278
1556
4312
2473
4443
6359
9721 12218
19414 22608
9850 20115
19380 30657
37643 51381
1332
1737
2137
4075
5559
851
1327
2318
4620
6498
Figure 1. Benchmarking results (in milliseconds)
When comparing the non-diﬀerentially private and the global-budget version
of median, we see that the diﬀerentially private version is often the faster one.
This is due to the high variance of the running time of the selection algorithm
(for choosing the ith ranked element from a set of n elements), and we made only
one run for each of the larger input sizes. The distribution of the running time
does not depend on the actual input, which is randomly shuﬄed before running
the selection algorithm. In the diﬀerentially private version, we do need to choose
roughly (cid:96) middle-ranked elements instead of only 1 or 2 but the running time of
the selection algorithm in this case is only 1 + (cid:96)
n times higher on average, and
usually (cid:96) is much less than n.
When comparing the global-budget version of diﬀerential privacy with in-
place budgets, we see that the extra overhead depends mostly on n, not on the
aggregating function. This is because we use the same -diﬀerentially private
aggregating functions in both cases but in the latter case we also need to check
which rows have enough budget and to reduce the budgets.
Similarly, the extra overhead of the provenance-budgets version of diﬀerential
privacy compared to the in-place-budgets version depends on n and not on the
aggregating function.
We have also measured which operations take most of the running time. For
example, for correlation with provenance budgets, n = 200000, and (cid:96) = 100,
the total running time was 112300 ms, of which 58168 ms is sorting (mostly
comparisons), 32949 ms (of which 19697 ms are equality checks and 11707 ms
multiplications) is computing the frequency table and propagating values back
(Algorithms 7 and 4 but reusing the results of equality checks instead of com-
puting them twice). As discussed in Sec. 9, if the query is performed on the same
value table as the previous query then it is not necessary to redo the sorting and
the running time would be 54132 ms. If also the mask vector is the same as in
the previous query, we can also leave out Algorithms 7 and 4 and the running
time would be 21183 ms, which is 2.5 times slower than with in-place budgets
but 5.3 times faster than the full provenance-budgets version.
Now we consider correlation with in-place budgets, n = 2000000, and (cid:96) =
1000. Here the overhead compared to global budgets is about 21000 ms, of which
13237 ms are comparisons, 1943 ms are multiplications, and 4345 ms is spent on
writing the new budgets to database (a local operation). This overhead would
be almost the same for other aggregating functions instead of correlation.
Thus the most important operations for our implementation of diﬀerential
privacy are integer comparisons, followed by equality checks and multiplications.
For larger ratios of (cid:96)
n (and thus smaller n), also ﬂoating-point operations are
important.
11 Discussion
We have implemented our system on Sharemind which provides security against
a passive attacker (but also privacy against an active one [30]). We may wonder
what the overheads of diﬀerential privacy would have been on an SMC platform
that provides security also against active adversaries. One of the most eﬃcient
actively secure protocol sets is (the online phase of) SPDZ [21]. They use an ex-
pensive oﬄine preprocessing phase, which in the online phase allows multiplying
two integers with each party sending only two values to every other party (as op-
posed to ﬁve in Sharemind, which does not use preprocessing). Thus (integer)
multiplications would be faster on SPDZ but they are only a small part of our
algorithms. In the following, we discuss the expected overheads of our protocols,
if implemented on top of the online phase of SPDZ.
More important than multiplications for us are integer comparisons, which
in our tests (using 64-bit integers) took about 6.5 s per million elements. Mul-
tiplications took 0.5 s per million elements and equality tests 3 s per million
elements. As SPDZ multiplications use 2.5 times less communication, these may
take 0.2 s per million elements on our hardware. According to [21], 64-bit integer
comparisons in SPDZ are about 90 times slower than multiplications, i.e. these
may take 18 s per million elements, about 3 times slower than on Sharemind.
Equality tests are not considered in [21] but the best equality-checking protocol
in [6] makes 8 openings of secret values for 64-bit integers in the online phase
(and much more in the precomputing phase), i.e. 4 times more than multiplica-
tion. If this could be implemented on SPDZ then it may take 0.8 s per million
elements, about 4 times faster than on Sharemind. Thus we guess the that the
communication costs of the online phase of an implementation on SPDZ would
not diﬀer from our implementation by more than a couple of times.
12 Conclusion
We have presented eﬃcient algorithms for performing diﬀerentially private sta-
tistical analyses on secret-shared data. We have implemented them on the SMC
platform Sharemind. The current implementation supports the aggregation
functions count, sum, arithmetic average, median, and linear correlation co-
eﬃcent but it can easily be extended to other functions using the Sample-and-
Aggregate mechanism. We have implemented three diﬀerent kinds of budgets for
diﬀerential privacy and compared their performance. We can conclude that non-
trivial queries using various forms of diﬀerential privacy can be performed on an
SMC platform based on secret sharing, and the performance is good enough to
be usable in practice.
Bibliography
[1] G. ´Acs and C. Castelluccia. I have a dream! (diﬀerentially private smart
metering). In T. Filler, T. Pevn´y, S. Craver, and A. D. Ker, editors, In-
formation Hiding - 13th International Conference, IH 2011, Prague, Czech
Republic, May 18-20, 2011, Revised Selected Papers, volume 6958 of Lecture
Notes in Computer Science, pages 118–132. Springer, 2011.
[2] D. Beaver. Eﬃcient multiparty protocols using circuit randomization. In
J. Feigenbaum, editor, CRYPTO, volume 576 of Lecture Notes in Computer
Science, pages 420–432. Springer, 1991.
[3] D. Bogdanov, L. Kamm, S. Laur, and V. Sokk. Rmind: a tool for crypto-
graphically secure statistical analysis. Cryptology ePrint Archive, Report
2014/512, 2014. http://eprint.iacr.org/.
[4] D. Bogdanov, S. Laur, and J. Willemson. Sharemind: A framework for
fast privacy-preserving computations. In S. Jajodia and J. L´opez, editors,
ESORICS, volume 5283 of Lecture Notes in Computer Science, pages 192–
206. Springer, 2008.
[5] D. Bogdanov, M. Niitsoo, T. Toft, and J. Willemson. High-performance
secure multi-party computation for data mining applications. Int. J. Inf.
Sec., 11(6):403–418, 2012.
[6] O. Catrina and S. de Hoogh.
Improved primitives for secure multiparty
integer computation.
In J. A. Garay and R. D. Prisco, editors, Security
and Cryptography for Networks, 7th International Conference, SCN 2010,
Amalﬁ, Italy, September 13-15, 2010. Proceedings, volume 6280 of Lecture
Notes in Computer Science, pages 182–199. Springer, 2010.
[7] K. Chatzikokolakis, M. E. Andr´es, N. E. Bordenabe, and C. Palamidessi.
Broadening the scope of diﬀerential privacy using metrics. In E. D. Cristo-
faro and M. Wright, editors, Privacy Enhancing Technologies - 13th Inter-
national Symposium, PETS 2013, Bloomington, IN, USA, July 10-12, 2013.
Proceedings, volume 7981 of Lecture Notes in Computer Science, pages 82–
102. Springer, 2013.
[8] R. Cramer, I. Damg˚ard, and J. B. Nielsen. Multiparty computation
from threshold homomorphic encryption. In B. Pﬁtzmann, editor, EURO-
CRYPT, volume 2045 of Lecture Notes in Computer Science, pages 280–299.
Springer, 2001.
[9] I. Damg˚ard, S. Meldgaard, and J. B. Nielsen. Perfectly secure oblivious ram
without random oracles. In Y. Ishai, editor, TCC, volume 6597 of Lecture
Notes in Computer Science, pages 144–163. Springer, 2011.
[10] I. Damg˚ard, V. Pastro, N. P. Smart, and S. Zakarias. Multiparty compu-
tation from somewhat homomorphic encryption.
In R. Safavi-Naini and
R. Canetti, editors, CRYPTO, volume 7417 of Lecture Notes in Computer
Science, pages 643–662. Springer, 2012.
[11] C. Dwork. A ﬁrm foundation for private data analysis. Commun. ACM,
54(1):86–95, 2011.
[12] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data,
ourselves: Privacy via distributed noise generation. In S. Vaudenay, editor,
Advances in Cryptology - EUROCRYPT 2006, 25th Annual International
Conference on the Theory and Applications of Cryptographic Techniques,
St. Petersburg, Russia, May 28 - June 1, 2006, Proceedings, volume 4004
of Lecture Notes in Computer Science, pages 486–503. Springer, 2006.
[13] H. Ebadi, D. Sands, and G. Schneider. Diﬀerential privacy: Now it’s get-
ting personal. In S. K. Rajamani and D. Walker, editors, Proceedings of the
42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Pro-
gramming Languages, POPL 2015, Mumbai, India, January 15-17, 2015,
pages 69–81. ACM, 2015.
[14] F. Eigner, M. Maﬀei, I. Pryvalov, F. Pampaloni, and A. Kate. Diﬀerentially
private data aggregation with optimal utility.
In C. N. P. Jr., A. Hahn,
K. R. B. Butler, and M. Sherr, editors, Proceedings of the 30th Annual
Computer Security Applications Conference, ACSAC 2014, New Orleans,
LA, USA, December 8-12, 2014, pages 316–325. ACM, 2014.
[15] R. Gennaro, M. O. Rabin, and T. Rabin. Simpliﬁed VSS and Fast-Track
Multiparty Computations with Applications to Threshold Cryptography.
In PODC, pages 101–111, 1998.
[16] O. Goldreich, S. Micali, and A. Wigderson. How to Play any Mental Game
or A Completeness Theorem for Protocols with Honest Majority. In STOC,
pages 218–229. ACM, 1987.
[17] O. Goldreich and R. Ostrovsky. Software Protection and Simulation on
Oblivious RAMs. J. ACM, 43(3):431–473, 1996.
[18] S. Goryczka, L. Xiong, and V. S. Sunderam. Secure multiparty aggregation
with diﬀerential privacy: a comparative study. In G. Guerrini, editor, Joint
2013 EDBT/ICDT Conferences, EDBT/ICDT ’13, Genoa, Italy, March 22,
2013, Workshop Proceedings, pages 155–163. ACM, 2013.
[19] J. Hsu, M. Gaboardi, A. Haeberlen, S. Khanna, A. Narayan, B. C. Pierce,
and A. Roth. Diﬀerential privacy: An economic method for choosing ep-
silon. In IEEE 27th Computer Security Foundations Symposium, CSF 2014,
Vienna, Austria, 19-22 July, 2014, pages 398–410. IEEE, 2014.
[20] L. Kamm. Privacy-preserving statistical analysis using secure multi-party
computation. PhD thesis, University of Tartu, 2015.
[21] M. Keller, P. Scholl, and N. P. Smart. An architecture for practical ac-
tively secure MPC with dishonest majority. In A. Sadeghi, V. D. Gligor,
and M. Yung, editors, 2013 ACM SIGSAC Conference on Computer and
Communications Security, CCS’13, Berlin, Germany, November 4-8, 2013,
pages 549–560. ACM, 2013.
[22] P. Laud. Parallel Oblivious Array Access for Secure Multiparty Compu-
tation and Privacy-Preserving Minimum Spanning Trees. Proceedings on
Privacy Enhancing Technologies, 1, 2015. To appear.
[23] S. Laur, R. Talviste, and J. Willemson. From Oblivious AES to Eﬃcient and
Secure Database Join in the Multiparty Setting. In Applied Cryptography
and Network Security, volume 7954 of LNCS, pages 84–101. Springer, 2013.
[24] C. Liu, Y. Huang, E. Shi, J. Katz, and M. W. Hicks. Automating eﬃcient
ram-model secure computation. In 2014 IEEE Symposium on Security and
Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014, pages 623–638.
IEEE Computer Society, 2014.
[25] A. Machanavajjhala and D. Kifer. Designing statistical privacy for your
data. Commun. ACM, 58(3):58–67, 2015.
[26] F. McSherry. Privacy integrated queries: an extensible platform for privacy-
preserving data analysis. Commun. ACM, 53(9):89–97, 2010.
[27] F. McSherry and K. Talwar. Mechanism design via diﬀerential privacy. In
48th Annual IEEE Symposium on Foundations of Computer Science (FOCS
2007), October 20-23, 2007, Providence, RI, USA, Proceedings, pages 94–
103. IEEE Computer Society, 2007.
[28] P. Mohan, A. Thakurta, E. Shi, D. Song, and D. E. Culler. GUPT: privacy
preserving data analysis made easy. In K. S. Candan, Y. Chen, R. T. Snod-
grass, L. Gravano, and A. Fuxman, editors, Proceedings of the ACM SIG-
MOD International Conference on Management of Data, SIGMOD 2012,
Scottsdale, AZ, USA, May 20-24, 2012, pages 349–360. ACM, 2012.
[29] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth sensitivity and sam-
pling in private data analysis.
In D. S. Johnson and U. Feige, editors,
Proceedings of the 39th Annual ACM Symposium on Theory of Computing,
San Diego, California, USA, June 11-13, 2007, pages 75–84. ACM, 2007.
[30] M. Pettai and P. Laud. Automatic Proofs of Privacy of Secure Multi-
Party Computation Protocols Against Active Adversaries. In IEEE 28th
Computer Security Foundations Symposium, CSF 2015, Verona, Italy, 14-
17 July, 2015. IEEE, 2015.
[31] A. Shamir. How to share a secret. Commun. ACM, 22(11):612–613, 1979.
[32] A. Smith. Privacy-preserving statistical estimation with optimal conver-
gence rates. In L. Fortnow and S. P. Vadhan, editors, Proceedings of the
43rd ACM Symposium on Theory of Computing, STOC 2011, San Jose,
CA, USA, 6-8 June 2011, pages 813–822. ACM, 2011.
[33] A. C.-C. Yao. Protocols for secure computations (extended abstract). In
FOCS, pages 160–164. IEEE, 1982.