branch. We observed a strong correlation between the
timings of most of the instructions and the branch they belong
to. The ﬁrst 10 mov instructions in the branch turned out to
be a stronger indicator of which branch was taken, but all
the other instructions belonging to the branch showed some
correlation, albeit a weaker one.4
As in Section 3, we observed the execution time of the
ﬁrst mov in each branch to be faster or slower, depending
on the branch it belongs to, with a difference between the
slower and faster mov of around 100 cycles. This observation
allowed us to set a timing threshold with which we could,
with up to 99.9% accuracy, determine which branch was
taken, and therefore determine the secret branch condition.
We stress again that the two branches are instruction-wise
3There are 52 instructions in Figure 2, however the ﬁrst cmp and jnz get
macro-fused into one instruction which cannot be split again by interrupts.
4The timings of the initial cmp and jnz were independent of the executed
branch - only instructions within the branches were correlated with the secret.
668    30th USENIX Security Symposium
USENIX Association
Figure 4: Attack success rate depending on the alignment
of the branches. The attack success rate is the percentage
of correctly guessed branches by the attacker out of 1000
executed branches. The 10th instruction (5th mov) from
Figure 2 is used to distinguish between both branches. The
color gradient goes from darker to brighter, where darker
boxes indicate higher attack success rates (up to 100%) and
brighter ones lower success rates (down to 50%).
code in Figure 2 1000 times with uniformly random secrets.
We use the timings of the 10th instruction (5th mov) to dis-
criminate between the branches. Figure 4 presents the result
of our experiment. These results show a clear dependency
between virtual addresses and the instruction execution times.
Modulo 16 There are four main quadrants of length 16 that
are essentially identical. This hints at the fact that the behav-
ior with respect to the alignment of the two branches repeats
every 16 bytes. We veriﬁed this assumption by repeating
the experiment for every value of X and Y for which the two
branches are still contained in the same 4 kB virtual page.6
We observed the same pattern for all the quadrants of length
16 in this test. As a consequence of this observation, when
we use the term alignment, we refer to alignment modulo 16.
Observation 2.1: The attack success rate depends on
the alignment modulo 16 of the two branches.
Diagonals The attack success rate on the diagonals in each
quadrant is around 50%. In the diagonals, both branches are
aligned to the same value X = Y mod 16.
Observation 2.2: Branches and instructions with the
same alignment will show the same execution times.
6We did not cross the virtual page boundary because this would most
likely require fetching pages that are not cached, thus introducing noise that
masks the effects that we are interested in measuring.
Figure 5: Timing distribution of a mov to the stack when
executing it in a trace containing 100,000 repeated add-mov
instructions (unrolled).
Symmetry The attack success rates are symmetric with
respect to their diagonal, meaning that the success of the
attack when the “if” branch is aligned at address X and the
“else” branch at address Y is the same when the alignment
of the branches is switched.
Observation 2.3: Alignments X,Y and Y,X produce
the same attack success rate.
Shape Finally, we focus our attention on the alignments in
the heatmap in which the success rate is above 70%. These
success rates are grouped into rectangles. Within each of these
rectangles, there are three regions of decreasing intensity. The
most interesting alignments are the ones that give the higher
attack success rates, as they allow to optimize the accuracy of
the attack. The best results are concentrated on rectangles of
size 3×5. This corresponds with the length in bytes of the two
instructions within the branch in Figure 2. The add instruction
has a length of 3B, while the mov we use in Figure 2 has
a length of 5B. Unfortunately, this rule does not trivially
generalize with more complex instruction size combinations.
Note that there are only a few structures in the CPU that are
sensitive to the alignment of the instruction, and in particular,
to their alignment modulo 16. On Skylake and Coffee Lake
architectures, one of them is the instruction pre-decode and
fetch module in the frontend of the CPU, which uses a fetch
window of 16 bytes to fetch instruction from the L1 instruc-
tion cache. We cannot be entirely sure about the internal
behavior of the CPU and what leads to the timing differences
in the two branches. However, as discussed in Section 3,
the different alignment changes the way instructions are
batched by the frontend and, ultimately, the timing at which
they are delivered to the subsequent stages of the CPUs.
The experiments presented in this section strongly suggest
that these fetching differences have repercussions for the
instruction’s execution time. We will discuss potential causes
that could lead the observed variable timings in Section 7.
USENIX Association
30th USENIX Security Symposium    669
4.3 The Effects of Instruction Alignment
To study the effects of the instruction alignment we analyze
the timing distributions of a linear code sequence of 100,000
repeating add-mov. Note that this is essentially an unrolled
loop, which compared to a loop removes the noise that the
loop-control instructions would introduce. We don’t envision
any real code to have such a sequence of instructions, but by
exploring the patterns that emerge from these instructions
we can gather several insights about how the differences in
branch alignments manifest.
The timings are collected using a slightly modiﬁed version
of SGX-Step, whose changes are described in Appendix A.3.
The timing of each instruction includes the time to perform
ERESUME, the time to execute the instruction, and the time
required to perform AEX. ERESUME, and AEX prepare the CPU
for the enclave execution and clean the state when returning
to the untrusted app. These operations take thousands of
CPU cycles to complete, and this is why, despite the fact that
we are measuring a single instruction, the latencies reported
in the graphs are in the order of thousands of cycles. We use
two ﬁgures to illustrate different aspects of the timing latency
of the same run: (i) Figure 5 depicts the overall latency
distribution of all the movs, and (ii) Figure 6 the distribution
separated by particular virtual addresses.
Distribution of instruction execution times
In Figure 5
we present the distribution of the instruction execution
times, estimated from all the 100,000 executed mov. The
most evident feature of this distribution is that it consists
of a bimodal Gaussian distribution. The movs are therefore
exhibiting two different distribution modes, whose peaks are,
on average, around 100 cycles apart. We refer to the mode
with the lower average and the one with the higher average
as the fast mode and slow mode, respectively.
Observation 3.1: The timing distribution of the movs
follows a bimodal distribution. The peaks of the two
distribution modes are around 100 cycles apart.
In general, we observed similar results with other instruc-
tions that access memory, such as add to memory. We remark
here that these differences are not due to the state of the L1
data-cache. We ensure this by running the victim enclave on a
dedicated physical core in the system and by always perform-
ing the same operations while handling interrupts. We further
veriﬁed with the OFFCORE_REQUESTS_ALL_REQUESTS per-
formance counter that no extra off-core memory transactions
were being performed.
Observation 3.2: Observation 3.1 applies not only
to movs but to all memory writes.
Figure 6: Timing distribution of the movs from Figure 5
grouped by their virtual address alignment.
Instruction execution times by alignment Regarding
alignment, there is an important characteristic of the cho-
sen instruction sequence that has not been considered in our
analysis thus far. Each couple of add-mov in the sequence
has a length of 8B, which is a multiple of 16. This implies
that the movs can only be aligned modulo 16 in two different
ways. In general, by testing the sequence with different initial
offsets, we observed movs at addresses between 1 and 8 to be
predominately slow and movs at addresses 9 to 16 to be pre-
dominately fast. We highlight that the two alignments are only
predominately fast (or slow) and usually they exhibit timings
from both distribution modes. We can think of each instruc-
tion at a given alignment to have a certain intrinsic probability
p to exhibit the fast mode and probability 1− p to exhibit the
slow mode every time it executes. Different alignments have a
different value of p. Figure 6 shows this phenomenon for two
particular alignments (0x6 and 0xe). As can be seen, align-
ment 0x6 is predominately slow, but some of its timings ex-
hibit the fast mode as well. The plots for other alignments are
similar, with the only difference being the size of the smaller
peaks. We do not show them here due to space constraints.
Observation 3.3: The alignment of the memory
writes determines how their latency will distribute
between the fast and slow distribution modes.
The value of p relates to the attack success rate. Say
that one branch is aligned such that the measured mov has
p ≥ 0.9, and the other is aligned to have a p ≤ 0.1 then the
branches are easily distinguishable, and a high success rate
If one of them has 0.3 ≥ p ≤ 0.7, and
will be observed.
the other a very small or very high p, as is the case for the
distributions in Figure 6, then one bit can be distinguished
with high accuracy, but the other will contain some errors.
If the branches have a p ≈ 0.3 and say p ≈ 0.7, then both
branches will be on average guessed better than random, but
will also contain errors. And ﬁnally if both branches have
a similar p the success rate of the attacker will be negligible.
670    30th USENIX Security Symposium
USENIX Association
4.4 Requirements and Limitations
In our experiments, we only observed timing differences
in branches which contain memory writes. Thus, at least
a memory write must be present for the side-channel to
emerge. All the other conditions being equal, other memory
write instructions we tested (variations of mov to different
addresses and arithmetic instructions that write back to
memory), excluding the push instruction, exhibited the very
same behaviors as described so far. Notably, instructions that
are surrounded by other memory writes also show a timing
difference, albeit usually smaller. Furthermore, the timing
distribution of a memory write is not only determined by its
alignment in isolation, but it is also inﬂuenced by the number
and alignment of surrounding memory instructions. For
instance, the more memory writes in the branch (or even right
after it), the more distinguishable the distributions will be,
increasing the probability of success of the attack. Another
element we were able to characterize, relates to the vicinity of
the memory instructions with each other. Particularly, when
writes are executed in a loop, the attack success probability
is higher if the loop executes only a few instructions (around
10) in between writes, and the fewer, the better, for the attack.
It is worth noting that simultaneous multi-threading (SMT)
was a big source of noise in our experiments. When the
core co-located with the victim is executing a CPU-heavy
workload, we were unable to observe any signiﬁcant timing
difference. In general, the Frontal attack is more reliable
if SMT is disabled or the virtual core co-located with the
victim is idle. We speculate that this is most likely due to
how the frontend handles and fetches instructions coming
from different virtual cores, but possibly also to the resulting
lower interference in the memory subsystem.
5 Frontal Attack Exploitation
The Frontal attack exploits control-ﬂow secret dependencies.
Therefore, the ﬁrst step of the attack is to identify target code
paths in the victim binary which execute secret-dependent
branches. Several techniques have been proposed to automate
ﬁnding such code paths [32, 33]. Among these code paths,
as discussed before, the attacker should choose those that
contain at least one memory write. Until now, we mostly
focused on balanced branches, but unbalanced branches are
also distinguishable with our attack. As unbalanced branches
can be exploited with other attacks as well, we focus on more
challenging balanced branches in our example exploits below.
Balanced branches are not rare in compiled code. In fact,
we found two code patterns that commonly lead to this type
of branches: slightly different return statements, and inlined
function calls with different parameters.
In the following, we give examples of vulnerable branches
satisfying the conditions above in two libraries: the Intel IPP
Cryptography library [25], and the mbedTLS library [24].
We note that since a secret-dependent code path must be
present, branch-prediction attacks can also exploit the
binaries vulnerable to the Frontal attack. For instance, the
examples we present below, when compiled with gcc are also
vulnerable to branch-shadowing attacks [14]. However, when
compiling the mbedTLS library with the compiler from [22],
all the branches are translated to indirect unconditional jumps,
which are hitherto not vulnerable to any known BPU attack.
On the other hand, we veriﬁed that even when using [22] the
branch targets are unchanged and have in general different
alignments, thus remaining vulnerable to the Frontal attack.
The attacks described in this section were performed on an
Intel i9-9900KS CPU with the latest microcode available at
the time of writing (0xca).
Intel IPP Cryptography Library
5.1
The Intel IPP Cryptography library is a cryptographic library
optimized for Intel CPUs and advertised as constant-time [25].
However, through manual inspection we identiﬁed several
secret dependent branches in its most recent version (2.9
at the time of writing). Among these, the l9_ippsCmp_BN
function compares two big numbers represented as arrays of
integers by iterating through each element of the array. The
function then terminates when a different array entry is found.
It can take three different exit paths, depending on whether
the ﬁrst input is smaller, bigger, or equal to the second. The
smaller-than and bigger-than paths are instruction-wise
identical, while the equal path contains the same instructions
as the others but in a different order. Given that the different
order of instructions of the equal vs. unequal paths can
be inferred with other attacks, we focus on distinguishing
the smaller-than vs. bigger-than paths with the Frontal
attack. With branch-prediction mitigations in place, other
known attacks do not allow to leak this information, as all
the paths ﬁt in a single cache-line. The exit paths contain
a mov to memory, which we target in our attack. We did
not observe any timing difference on this instruction alone,
despite the fact that the paths start at different alignments,
this is expected as the memory write is executed only once.
However, by inlining the function in an enclave that performs
a loop of at least 9 memory writes after the IPP function call,
we obtained the distributions shown in Figure 7. The ﬁgure
shows two distributions that differ in their modality. The
timing distribution of the mov in the smaller-than path has a
single peak around 9400 cycles. On the other hand, the mov in
the bigger-than path exhibits two modes, a small one around
9300 cycles, and a predominant one at 9525 cycles, and is
thus usually slower to execute than the mov in the smaller-
than path. Consequently, if a measured mov timing is “slow”
it must mean that the bigger-than path was executed (3%
false positive). Overall, by using this comparison repeatedly
with a secret bitstring as input, we were able to accurately
recover 25% of the secret’s bits (with 1000 function calls).
USENIX Association
30th USENIX Security Symposium    671
Figure 7: Timing distributions of two different movs in the
IPP Cryptography library’s l9_ippsCmp_BN function (each
estimated from 3000 samples). The function executes a secret
dependent comparison, which can result in two balanced
the bigger-than or smaller-than path.
paths being taken:
Each path contains a differently-aligned mov in it, whose
distribution is shown in the ﬁgure.
5.2 Montgomery Modular Multiplication
The Montgomery modular multiplication (MM) is a fast MM
algorithm often used in cryptographic libraries due to its
efﬁciency and minimal secret dependence. There is only a
single secret-dependent branch in the algorithm: a conditional
subtraction that is done at the end of the multiplication. MM
is used to perform modular exponentiation, and knowing
whether the subtraction was done or not leaks some bits of
a secret key used in the exponentiation [34]. Some implemen-
tations, including mbedTLS as of version 2.16.6, just balance
the branches by adding an else branch with a dummy subtrac-
tion in it (cf. Listing 1). However, this naive mitigation is still
vulnerable to side-channel attacks that target control-ﬂow
secret dependencies, such as the Frontal attack. We compiled
the mbedTLS library with the gcc -O3 ﬂag and used it inside
an enclave that performs a modular exponentiation (as the
MM function is not directly exposed in the library’s API).
The O3 ﬂag inlines functions when possible, so instead of
performing two function calls, as shown in Listing 1, the
binary contains two identical copies of the mpi_sub_hlp
function. The branch condition determines which of these two
gets executed. The mpi_sub_hlp function contains a loop
with two memory writes. The loop repeats a number of times
proportional to the size of the modulus of the multiplication.
In Listing 2 in the Appendix, we give the assembly code
generated by the compiler for the loop we exploit. Since the
two loops were aligned differently, they exhibited different
timing distributions, as shown in Figure 8. While the differ-
ences were not as big as seen in our controlled tests (most
likely due to the fact that several instructions are executed
in between consecutive memory writes), they were enough to
differentiate the branches. Using Welch’s t-test, we correctly
classiﬁed 83% (511 out of 616) subtraction calls (whether
they were dummies or not) with 99.9% conﬁdence with just
16 repetitions of an exponentiation with the same inputs.
Figure 8: Comparison of the real subtraction (if branch) and