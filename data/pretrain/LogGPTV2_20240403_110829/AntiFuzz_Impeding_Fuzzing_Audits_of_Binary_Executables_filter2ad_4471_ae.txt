md5sum
AFL
Honggfuzz
QSYM
Vuzzer
zzuf
None
Coverage Crash
Speed
Symbolic Execution All
(#28)
(#48)
(#48)
(#47)
(#1)
(#14)
(#29)
(#14)
(#26)
(#1)
(#194)
(#72)
(#1926)
(#266)
(#1)
(#57)
(#34)
(#25)
-
-
(#1)
(#1)
(#1)
-
-
-
-
-
-
(#24)
(#48)
(#33)
(#1)
(#13)
(#29)
(#15)
(#1)
(#95)
(#72)
(#260)
(#1)
-
(#55)
(#22)
-
-
-
inserted. All fuzzer conﬁgurations were allowed to run for 24
hours each. Due to DWORD comparisons that AFL has difﬁ-
culty to solve, the AFL modiﬁcation LAF-INTEL was used,
which breaks comparisons (including string operations) down
to single byte comparisons to allow for more nuanced edge
generation during compilation. For blind fuzzers like ZZUF,
solving four bytes is too hard, thus one constraint was reduced
to a single bit-ﬂip for this fuzzer alone.
Results Table 4 shows our result. The # sign denotes the
number of unique crashes found (according to distinct LAVA-
M fault IDs). Again we can see the same consistent result
for all binaries: once ANTIFUZZ is turned on, it effectively
prevents fuzzers from detecting bugs. The exceptional cases
are similar to the ones we discussed in the previous section.
In summary, these results demonstrate that our anti-fuzzing
features are applicable to real-world binaries to prevent bug
ﬁnding.
6.4 Reducing Code Coverage
As a next step, we want to answer RQ 4. by demonstrating that
applying ANTIFUZZ results in far less coverage in coverage-
based fuzzers. More speciﬁcally, we evaluated AFL, HONGG-
FUZZ, VUZZER, and QSYM against eight real-world binaries
from the binutils collection (namely addr2line, ar, size,
strings, objdump, readelf, nm-new, strip-new). Every
fuzzer and every application was executed three times for
24 hours in the setting “None” (ANTIFUZZ is disabled) and
then again in the setting “All” (all ANTIFUZZ features are
enabled).
Result The results of this experiment are shown in Figure 3.
For each of the eight binutils programs, we compare the per-
formance of the four tested fuzzers (measured in the number
of branches covered) without and with protection via ANTI-
FUZZ. It is apparent that ANTIFUZZ does indeed severely
hinder fuzzers from extending code coverage. Note that in all
cases, when ANTIFUZZ was activated, even after 24 hours
the fuzzers could only reach coverage that would have been
reached in the ﬁrst few minutes without ANTIFUZZ.
We performed a statistical analysis on the resulting data, the
results are shown in Table 3. All but three out of thirty experi-
ments were statistically signiﬁcant with p < 0.05 according
to a two-tailed Mann–Whitney U test. Two of the insigniﬁ-
cant results are from VUZZER, which displayed rather low
coverage scores even without ANTIFUZZ enabled. The other
insigniﬁcant result is on ar, a target where most bug ﬁnding
tools fail due to a multi-byte comparison. Additionally, we
calculated the reduction of the amount of covered code that
resulted from enabling ANTIFUZZ. Typically (in half of the
experiments), less than 3% of the code that was tested on an
unprotected target could be covered when ANTIFUZZ was
enabled. The 95th percentile of coverage was less than 13% of
the code that the fuzzers found when targeting an unprotected
program. In the worst result, we achieved a reduction to 17%.
Therefore, we conclude that ANTIFUZZ will typically reduce
the test coverage achieved by 90% to 95%.
6.5 Performance Overhead
Lastly, to answer RQ 5. we measure the performance over-
head caused by using ANTIFUZZ on complex programs. For
this purpose, we use the SPEC CPU2006 version 1.1 INT
benchmark. This experiment consists of all benchmarks that
1942    28th USENIX Security Symposium
USENIX Association
Figure 3: Evaluation of eight binutils binaries to show the branch coverage difference between unmodiﬁed binary ("Disabled") and binary with ANTIFUZZ
("Enabled"). The dashed line at the bottom is the baseline (i.e. the number of branches covered with the seed ﬁle).
take an input ﬁle (thus only 462.libquantum was excluded).
The remaining benchmarks ran for three iterations each and
were averaged over ten runs with the geometric mean.
Result The impact of ANTIFUZZ for each benchmark was
insigniﬁcant enough to bear little to no observable overhead
(see Table 5): most applications show small negative over-
heads (with the outlier being gcc with -3.80%), but the positive
overheads also never reach 1%. The total average overhead is
-0.42%. This is expected because antifuzz_init() is only
called once when the input ﬁle is opened. Reading the ﬁle to
memory and checking if the input data is well-formed usually
happens only once in the beginning, thus it does not impact
the computationally intensive main part of the benchmarks at
all.
7 Limitations
In the following, we discuss limitations of both our proposed
approach and implementation, and also consider threats to
validity. For our current prototype implementation, a human
analyst can likely remove the protection mechanisms added by
ANTIFUZZ rather easily. However, according to our attacker
model, we regard this threat out of scope in the context of this
paper. Moreover, many other works have detailed techniques
to prevent modiﬁcation and human analysis using software
obfuscation techniques [16, 17, 21, 24, 41, 43, 53]. For a more
complete protection, we recommend to use a combination of
Table 5: SPEC CPU2006 INT benchmark.
Benchmark
400.perlbench
401.bzip2
403.gcc
429.mcf
445.gobmk
456.hmmer
458.sjeng
464.h264ref
471.omnetpp
473.astar
483.xalancbmk
Total average
Overhead
0.13%
0.11%
-3.80%
-0.36%
0.89%
0.32%
0.43%
-1.53%
-0.8%
-1.06%
0.17%
-0.42%
both ANTIFUZZ as well as traditional anti-analysis/-patching
techniques.
The delay-inducing technique should not be applied to any
kind of public-facing server software, as this would drastically
weaken the server against Denial-of-Service attacks. Instead
of sleeping or busy waiting, one should implement a similar
approach based on rate limitation.
The number of functions added as fake code results in a
ﬁxed ﬁle size increase of approximately 25MB. While this
is less relevant for large software binaries, it might pose sig-
niﬁcant code size overhead for small binaries. However, for
modern machines we deem this to be a minor obstacle.
USENIX Association
28th USENIX Security Symposium    1943
Furthermore, it is worth mentioning that one can avoid
this increase in ﬁle size by using self-modifying code. We
explicitly decided not to use self-modifying code since such
techniques have the tendency of making exploitation easier
by using memory pages with read/write/execute privileges
and potentially raising alerts in anti-virus products.
Furthermore, ANTIFUZZ in its current form requires de-
veloper involvement which is not optimal from a usability
perspective. However, most of the manual work in ANTIFUZZ
can be automated. In particular, we require the developer to
perform the following tasks: (a) ﬁnd error paths, (b) replace
constant comparisons, and (c) annotate functions which read
user input or data. It is relatively easy to automate items (b)
and (c) via a compiler pass. The reason that ﬁnding error paths
is more challenging is that there are many different ways for
handling errors. On the other hand, the responsible developer
is well aware of the error handling code. Adding a single
function call in the error handler is straightforward and does
not signiﬁcantly increase the complexity of the code base.
Additionally, it is worth mentioning that the benchmarking
suite which we used was focused on CPU intensive tasks
rather than I/O bound tasks. We assume that using our pro-
totype AES implementation to encrypt and decrypt every
input signiﬁcantly increases the overhead on I/O bound tasks.
Therefore, we recommend to replace AES by a much weaker
and faster encryption algorithm, as our goal is not to be cryp-
tographically secure, but to confuse SMT solvers.
Finally, it has to be considered that automatic program
transformations for obfuscation can always be thwarted [7].
Therefore, tools like ANTIFUZZ can never completely guar-
antee that they can defeat a motivated human analyst. Based
on this observation, the situation for anti-fuzzing mechanisms
like ANTIFUZZ is similar to obfuscation mechanisms: given
sufﬁcient interest from the attackers and defenders, a pro-
longed arms race is to be expected. This also means that as
time passes, continuing this arms race will become more and
more expensive for both sides involved. However, similar
to obfuscation, we expect only the implementation of tools
like ANTIFUZZ to become more complicated. Similarly to
modern obfuscation tools, usage of anti-fuzzing defenses will
most likely remain cheap.
As we cannot evaluate against techniques not yet invented,
some of our techniques could be attacked by smarter fuzzers.
The junk code that was inserted could be detected based on
statistical patterns or the way it interacts with the rest of the
execution. To counter this, more complex and individualized
junk code fragments could be used. For example, junk code
can change global variables that are also used in the original
code (e.g., in opaque predicates).
ing junk code that is never executed [16, 53], often hidden
behind conditional expressions that always evaluate to some
ﬁxed value [17]. The control ﬂow can be further cloaked
by creating many seemingly dissimilar paths that are picked
randomly [43] to thwart dynamic analysis based approaches.
Other common techniques include self-modifying code [41],
which increases the difﬁculty of obtaining a useful disassem-
bly and changes to the control-ﬂow [21, 24]. Similarly, there
has been some work that speciﬁcally target symbolic execu-
tion [51].
Recent research tried to address a very similar issue: To
increase the cost of the attacker, Hu et al. [35] insert a large
number of fake bugs into the target application. This approach
has the advantage that it works against many different kinds
of attack scenarios. However, they rely on the bugs being non-
exploitable as otherwise the actual security of the application
is reduced. For example, the authors state that they rely on
the exact stack layout behavior of the chosen compiler. Any
update to the compiler might render the previously "safe" bugs
exploitable. Additionally, fuzzers generally tend to ﬁnd many
hundreds to thousands of crashes for each real bug uncovered.
Adding some more crashes does not prevent the fuzzer from
ﬁnding real bugs. The large number of crashes found might
draw attention and common analysis techniques for bug triage
(such as AFLs bug exploration mode) will greatly simplify
weeding out the fake bugs.
In contrast, our approach is much more low key. Addition-
ally, since in our approach no proper test coverage is achieved,
no analysis of the produced fuzzing data will be able to un-
cover any bugs. An idea similar to our fake code insertions
was also presented in a talk by Kang et al. [38]. However, they
explicitly tried to prevent AFL in QEMU mode from ﬁnding
a speciﬁc crashing path. In our scenario, the defenders do
not know the speciﬁc crashing path, as otherwise, they would
rather ﬁx the bug. Additionally, as we demonstrated in our
evaluation, our approach is effective across different fuzzers
and does not attack a speciﬁc implementation.
Finally, a master thesis by Göransson and Edholm has in-
troduced the idea of masking crashes and actively detecting if
the program is being fuzzed, e.g., by detecting speciﬁc AFL
environment variables [30]. Similarly to the work by Kang et
al., the methods they devised are highly speciﬁc to the imple-
mentation of the only two fuzzers they considered: AFL and
HONGGFUZZ. Additionally, to reduce the execution speed
of fuzzers, they proposed to artiﬁcially decrease the overall
performance of the program under test, whereas ANTIFUZZ
only decreases the performance if the input is malformed.
9 Conclusion
8 Related Work
Obfuscating software against program understanding has been
exhaustively researched. Common techniques include inject-
In this paper, we categorized the general assumptions common
to all current bug-ﬁnding tools. Based on this analysis, we
developed techniques to systematically attack and break these
assumptions (and thus a representative sample of contempo-
1944    28th USENIX Security Symposium
USENIX Association
rary fuzzers). The evaluation demonstrated that obfuscation
on its own fails to prevent fuzzing satisfyingly. In contrast,
our techniques effectively prevent fuzzers from ﬁnding crash-
ing inputs in simple programs, even if the crash was found
in seconds in an unprotected application. Furthermore, we
demonstrated that we get the same result for real-world ap-
plications, i.e., fuzzers are unable to detect any crashes or
even achieve a signiﬁcant amount of new code coverage. Our
techniques also show no signiﬁcant overhead when evaluated