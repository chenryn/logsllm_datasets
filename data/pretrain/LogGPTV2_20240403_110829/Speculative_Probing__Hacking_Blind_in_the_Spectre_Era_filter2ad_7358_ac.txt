page with corruptiblefunction pointerunmappedpageGadgetMemoryunmappedpagecode pageptXXNo gadget needed or involvedfpKernelexample:GadgetSpectredata page with known dataXLoad known value (*V) from address (V).data pagepage with corruptiblefunction pointer and datadata pagepurposeinstruction1.mov regX,[A]2.mov regY,[regX]3.mov regZ,[B]Load address with known value (V) from A incorrupted page.Access probe target (pt=*B+*V) to induce the signal in cache.Memory*B+*VfpKernel4.mov regQ,[regZ+regY]Load array base (*B) from B in corrupted page.ptV A BAccess probe target (pt) to induce the signal in cache.page with corruptiblefunction pointer anddataunmappedpagepurposeGadgetinstruction1.mov regX,[p1]2.mov regY,[regX]Load probe target (pt) from corrupted page.Memoryfpunmappedpagedata pageptXXp1KernelLoad probe target (pt) from data-controlled page.page with corruptiblefunction pointer and datadata pagepurposeGadgetinstruction1.mov regX,[p1]2.mov regY,[regX]3.mov regZ,[regY]Load pointer to data-controlled page (p2) from corrupted page.Access probe target (pt) to induce the signal in cache.Memoryfpreadablepagedata-controlledpageptXXp2p1KernelLoad value to test (*T) from test target (T).data pagepage with corruptiblefunction pointer and datadata page data pagepurposeGadgetinstruction1.mov regX,[A]2.mov regY,[regX]3.mov regZ,[B]Load test target (T) from A in corrupted page.Access probe target (pt=*B+*T) to induce the signal in cache.Memory*TfpKernel4.mov regQ,[regZ+regY] BLoad array base (*B) from B in corrupted page.ptT AArray Bculminates in (and can be verified by) the activation of a single cache
set selected by the attacker. However, this is not a strict requirement
and more elaborate fingerprinting is possible (but unnecessary for
practical exploitation, as shown by our end-to-end exploits).
For different gadgets, the detection of such behavior may take
slightly different forms. For instance, suppose we are looking for a
traditional (B)ROP gadget such as pop reg; ret; for some register.
In that case, there is no direct reference to the target cache set by
the gadget. To detect such gadgets, the attacker can look at the
callsite for the use of the register upon successful completion of
the gadget. After all, when code dereferences the register after the
return, the appropriate cache set gets activated. In other words, it
does not matter how the code activates the selected cache set, as
long as one can infer the behavior of the target gadget from it.
Finally, it is helpful to discuss the usefulness of gadget probing in
general even if it can leak a Spectre gadget already. Given a Spectre
gadget, the attacker can probe the address space more directly.
However, while the Spectre gadget is convenient for exploitation,
as we discuss in Section 6.5, it is unable to bypass certain leakage-
resistant randomization schemes. Gadget probing is not subject to
these limitations, but the analysis of cache traces for each necessary
gadget requires additional effort on behalf of the attacker.
5.3 Data Region Probing
While the Stage 1 primitives give attackers all that is needed to
launch an exploit, solely relying on Stage 1 may not be efficient.
For instance, probing the entire address space with the Spectre
gadget is slow as each value that the gadget reads requires probing
many cache sets (some of which may be quite noisy), even when
the attackers do not care about the actual value. As an example, it
is common for exploits to require the base address of a data region
like heap/physmap, regardless of its content (see the exploits in §6).
For this scenario, Figure 1c shows how data region probing
allows an attacker to find the kernel heap efficiently. In this case,
we use a gadget that accesses memory via two chained dereferences.
The gadget uses an attacker-controlled value on the corrupted page
as a pointer to load another value from a target page. To verify that
the target page is indeed mapped as a data page, we only need to
check the cache sets at the attacker-controlled page offset. If one of
these cache sets gets activated, then we know that the probe has
succeeded in finding a mapped kernel data page.
5.4 Object Probing
Merely locating the base address of a data region is not always
sufficient. For instance, some attacks [49] require the location of
specific user objects in the physmap. Moreover, as later detailed in
Section 5.6, locating user objects in the physmap is useful to build
a f+r [98] covert channel as a better alternative to p+p [69].
To conveniently accommodate such exploitation techniques, ob-
ject probing allows attackers to scan memory for pointer signatures:
pointers to a probe target of which the attacker knows the cache
set. The procedure is shown in Figure 1d. The corrupted function
pointer targets a gadget that uses an attacker-controlled value as
a pointer to another pointer p2 that it subsequently dereferences.
By checking the cache set corresponding to pt, attackers can tell if
they found the address of the right object containing p2.
5.5 Spectre Probing
The most convenient primitive is given by a Spectre gadget that
we can use to scan the content of memory directly. The Spectre
gadget serves as a universal read primitive, as we can use it to
dump the content of any memory region. For instance, we could
use it to dump the full contents of the kernel code and data regions.
Spectre probing could act as an alternative to object probing for
locating data in physmap by leaking memory contents byte by byte
(leaking mode). However, doing so is slow as each value needs
explicit testing which requires probing a range of cache sets to see
which one was activated. Moreover, some of the cache sets may be
used a lot, leading to increased noise that slows down the attack.
For this reason, we can also efficiently use our Spectre probing
in value testing mode, as illustrated in Figure 1e. In this case, the
corrupted function pointer targets a Spectre gadget and the attacker
configures memory such that the dereference in Line 4 hits a partic-
ular cache set if and only if the value that the Spectre gadget reads
has the value that the attacker is looking for. By doing so, BlindSide
greatly reduces the number of cache sets to probe during a scan.
Note that the technique applies to both data and code pages. As we
discuss in Section 6.5, certain mitigations, however, are immune
against Spectre probing when leaking code pages. The attacker can
instead use gadget probing in those circumstances.
5.6 Optimizations
Reducing Noise. During our p+p measurements for examining
the state of the LLC, some cache sets always get accessed due to
the code executed and data accessed by the measurement itself.
These cache sets may conflict with the eviction sets that we use for
checking the probe’s signal. The eviction sets associated with the
accessed cache sets will always result in a slow probe which would
falsely imply that it has the signal (i.e., a false positive). To learn
the cache sets that are accessed by default, we collect a footprint of
the cache by performing one round, using a void probe target (i.e.,
memory address 0x0) before the actual probing starts. We avoid
these cache sets when probing our target address.
Cache attacks are noisy by nature, so once we find a signal, we
need to verify it is a true positive. For verification, we adjust the
offset in the probe target to another cache set. If that cache set also
appears to show a signal, it means the signal was a true positive
and that the probe target points to the sought element in memory.
Leveraging flush+reload. As p+p is known to be slow and sen-
sitive to noise, replacing it with the faster and more noise-resistant
flush+reload [98] attack is beneficial for the probes. f+r achieves
its speed up mainly by allowing a lower number of measurement
repetitions per probe and having a high signal confidence on a sin-
gle hit, unlike p+p which requires more hits to validate the signal.
Appendix A presents a detailed comparison between p+p and f+r
used with our primitives.
However, unlike p+p, f+r requires the attacker and victim to
share memory. Observe that the kernel heap (or physmap) is im-
plicitly “shared” between the user process and the kernel and can
be used to build an efficient f+r covert channel. Specifically, the
attacker can map a f+r buffer in user memory backed by 2 MB
huge pages and put a signature in the beginning. To locate kernel
mapping of such buffer, the attacker relies on Spectre probing to
scan the physmap for the signature at 2 MB intervals. After this step,
the attacker can use Spectre probing again to access the buffer via
its kernel mapping, but now perform f+r (instead of p+p) using the
user mapping to leak information. If huge pages are not available,
the attacker can rely on side channels to detect a 2 MB user memory
alignment [28, 47] or resort to spraying 4 KB pages with a unique
page id attached to the signature to reduce the search space.
Our results show that f+r improves the speed of the probes on
average more than 5x, which is in line with numbers reported in the
literature [93]. As we shall see next, we use f+r in two of our three
exploits after leaking the kernel heap and the user page within it.
6 EXPLOITATION
In this section, we present three proof-of-concept (PoC) exploits.
The first exploit uses our Stage 1 code region probing primitive to
bypass standard code KASLR, our Stage 2 data region probing to by-
pass heap KASLR, and finally our Stage 2 object probing primitive
to detect the location of our ROP payload. This allows us to mount
an end-to-end just-in-time code-reuse exploit and gain reliable code
execution in the kernel using a single heap buffer overflow vul-
nerability. The second exploit first uses our Stage 1 code region
probing and gadget probing to find a Stage 2 Spectre probing prim-
itive to leak arbitrary information from the victim kernel’s data
region. We use this primitive to mount an architectural end-to-end
data-only exploit using a microarchitectural speculative code-reuse
exploit, which, as an example, leaks the root password hash. The
exploit structurally bypasses fine-grained, leakage-resistant ran-
domization and other mitigations against (architectural) code reuse
such as CFI [3] which have been deployed in secure production
kernels [2]. Our last exploit shows how the Spectre probing primi-
tive can be more powerful than traditional arbitrary memory read
primitives, demonstrating how it can directly read code and enable
(architectural) just-in-time code reuse in the face of software-based
eXecute-only-Memory (XoM) for the kernel [71].
The ultimate goal of the exploits is elevating privileges by execut-
ing a ROP payload crafted with the disclosed gadgets to disable the
SMAP and SMEP protections and allow user-space code to change
the process’ credentials, or by compromising the root password.
First, we briefly discuss the vulnerability and shared initialization of
the exploits, then we go over how we used the probing primitives,
and finally we discuss how we achieve privilege escalation in the
final stage. We perform the attacks against Linux kernel version
4.8.0 compiled with gcc and all mitigations enabled on a machine
with Intel(R) Xeon(R) CPU E3-1270 v6 @ 3.80GHz and 16 GB of
RAM. We repeat all our experiments 5 times and report the median,
with marginal deviations across runs. In each experiment, we set
the number of probing repetitions and hits to the minimum number
necessary to achieve a 100% success rate (0% error rate) in our re-
peated attempts on an idle system. See Appendix A for more details
on the impact of repetitions on our probing primitives.
6.1 Vulnerability
For our exploits, we use a heap buffer overflow in the Linux kernel
(CVE-2017-7308). This bug applies to AF_PACKET sockets with a
TPACKET_V3 ring buffer. We used Konovalov’s detailed write up
on this vulnerability [56] to start off our exploits.
In the original exploit, once the vulnerable ring buffer is initial-
ized, only a fixed offset beyond the buffer can be overwritten. In
our exploits, we create two such vulnerable objects. The first object
serves to corrupt (adjust) the fixed write offset stored in the second.
This results in a non-linear out-of-bound write through the second
object with a range of up to 64 KB (due to the offset being of type
unsigned short). For details about how the out-of-bound write is
triggered, we point the interested readers to Konovalov’s write-up.
Note that BlindSide can work with any vulnerability that pro-
vides a write primitive similar to the one used here. Examples
include CVE-2017-1000112, CVE-2017-7294, and CVE-2018-5332.
6.2 Speculative Probing Initialization
For speculative probing, we exploit a conditional branch and an
indirect branch combination in the code related to sockets. We place
a socket object adjacent to the out-of-bound write primitive and
corrupt its function pointer consumed by the indirect branch for
probing. We trigger the execution of the conditional and indirect
branch combination using a sendto system call.
To ensure that the conditional branch is taken towards the indi-
rect branch by default, we prepare a non-corrupted socket object
for the purpose of training the execution of the conditional branch
towards the indirect branch. To trigger speculation, we flip the
direction of the conditional branch by simply corrupting the condi-
tional data using the out-of-bound write vulnerability. To ensure
that speculation succeeds in reaching our target indirect branch, we
spawn a thread on a separate core to constantly evict the conditional
data from the cache and maximize the speculation window.
6.3 Exploit 1: Breaking Coarse-grained KASLR
In our first exploit, we focus on applying BlindSide to the stock
Linux kernel with default mitigations including KASLR.
Locating kernel image. To discover the base of the kernel im-
age (i.e., code and adjacent data), we perform code region probing
on memory range 0xffffffff80000000 - 0xffffffffc0000000
(1 GB) with a step size of 8 MB. The kernel image size is a little over
8 MB. Once we get a hit, we lower the step size to 2 MB and restart
probing from the last unmapped page. Note that the kernel image is
mapped with huge pages and thus aligned to 2 MB. Once we know
the base of the kernel image, we know the location of all gadgets.
Results. While searching for an executable page, we measured
a probing speed of 95.4 pages per second with 14 repetitions per
cache set. On average, it takes around 0.7s to find the kernel image
base (i.e., on average located in the middle of the possible range).
Locating the kernel heap. To build the ROP payload, we need to
leak its location in memory in order to use payload pointers inside
the payload. We first use data region probing to locate the kernel
heap and then use object probing starting from the base of the heap.
We use the following gadget in both probes:
0 x146a3 : mov rax , qword ptr [ rbx + 0 x158 ]
0 x146aa : mov rax , qword ptr [ rax + 0 x138 ]
0 x146b1 : mov rax , qword ptr [ rax + 0 x78 ]
Listing 1: Gadget in uncore_pmu_event_start and at kernel
image offset 0x146a3.
For data region probing, we use the first two instructions and, for
object probing, we use all three instructions. The rbx register points
to the socket object which we corrupt for speculative probing. We
probe for the heap base in memory range 0xffff880000000000 -
0xffffa40000000000 (i.e., a 28 TB memory range which we found
empirically). Ideally we would use a 16 GB step size, but we noticed
an unmapped gap of 1GB in the heap. To avoid such gaps, we
instead use a step size of 8GB (and 1GB on the slow path).
Results. While searching for a data page, we measured a probing
speed of 36.4 pages per second with 36 repetitions per cache set. On
average, it takes around 49.2s to find the heap base (i.e., on average
located in the middle of the possible range).
Locating the ROP payload. Once we find the heap base, we use
object probing to find the ROP payload’s location. Essentially, we
search for the location where we have the out-of-bound write ca-
pabilities as we write the ROP payload at that location. We start
the probe at the discovered heap base and use a step size of 0x8000
bytes as the vulnerable buffer used for the out-of-bound write is
aligned to 0x8000. Once we observe a signal through our object
probing primitive, it means that we have disclosed the location of
the target ROP payload.
Results. While searching for the target location, we measured
a probing speed of 3,910.8 pages per second on average with 43
repetitions per cache set. On average, it takes around 67.0s to find
our target object if it is located in the middle of the heap.
6.4 Exploit 2: Speculative Data-only Attacks