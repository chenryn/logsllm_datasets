### 容错
在本章的最后一节中，让我们看一看流处理是如何容错的。我们在 [第十章](ch10.md) 中看到，批处理框架可以很容易地容错：如果 MapReduce 作业中的任务失败，可以简单地在另一台机器上再次启动，并且丢弃失败任务的输出。这种透明的重试是可能的，因为输入档案是不可变的，每个任务都将其输出写入到 HDFS 上的独立档案中，而输出仅当任务成功完成后可见。
特别是，批处理容错方法可确保批处理作业的输出与没有出错的情况相同，即使实际上某些任务失败了。看起来好像每条输入记录都被处理了恰好一次 —— 没有记录被跳过，而且没有记录被处理两次。尽管重启任务意味著实际上可能会多次处理记录，但输出中的可见效果看上去就像只处理过一次。这个原则被称为 **恰好一次语义（exactly-once semantics）**，尽管 **等效一次（effectively-once）** 可能会是一个更写实的术语【90】。
在流处理中也出现了同样的容错问题，但是处理起来没有那么直观：等待某个任务完成之后再使其输出可见并不是一个可行选项，因为你永远无法处理完一个无限的流。
#### 微批次与存档点
一个解决方案是将流分解成小块，并像微型批处理一样处理每个块。这种方法被称为 **微批次（microbatching）**，它被用于 Spark Streaming 【91】。批次的大小通常约为 1 秒，这是对效能妥协的结果：较小的批次会导致更大的排程与协调开销，而较大的批次意味著流处理器结果可见之前的延迟要更长。
微批次也隐式提供了一个与批次大小相等的滚动视窗（按处理时间而不是事件时间戳分窗）。任何需要更大视窗的作业都需要显式地将状态从一个微批次转移到下一个微批次。
Apache Flink 则使用不同的方法，它会定期生成状态的滚动存档点并将其写入持久储存【92,93】。如果流运算元崩溃，它可以从最近的存档点重启，并丢弃从最近检查点到崩溃之间的所有输出。存档点会由讯息流中的 **壁障（barrier）** 触发，类似于微批次之间的边界，但不会强制一个特定的视窗大小。
在流处理框架的范围内，微批次与存档点方法提供了与批处理一样的 **恰好一次语义**。但是，只要输出离开流处理器（例如，写入资料库，向外部讯息代理传送讯息，或传送电子邮件），框架就无法抛弃失败批次的输出了。在这种情况下，重启失败任务会导致外部副作用发生两次，只有微批次或存档点不足以阻止这一问题。
#### 原子提交再现
为了在出现故障时表现出恰好处理一次的样子，我们需要确保事件处理的所有输出和副作用 **当且仅当** 处理成功时才会生效。这些影响包括传送给下游运算元或外部讯息传递系统（包括电子邮件或推送通知）的任何讯息，任何资料库写入，对运算元状态的任何变更，以及对输入讯息的任何确认（包括在基于日志的讯息代理中将消费者偏移量前移）。
这些事情要么都原子地发生，要么都不发生，但是它们不应当失去同步。如果这种方法听起来很熟悉，那是因为我们在分散式事务和两阶段提交的上下文中讨论过它（请参阅 “[恰好一次的讯息处理](ch9.md#恰好一次的讯息处理)”）。
在 [第九章](ch9.md) 中，我们讨论了分散式事务传统实现中的问题（如 XA）。然而在限制更为严苛的环境中，也是有可能高效实现这种原子提交机制的。Google Cloud Dataflow【81,92】和 VoltDB 【94】中使用了这种方法，Apache Kafka 有计划加入类似的功能【95,96】。与 XA 不同，这些实现不会尝试跨异构技术提供事务，而是透过在流处理框架中同时管理状态变更与讯息传递来内化事务。事务协议的开销可以透过在单个事务中处理多个输入讯息来分摊。
#### 幂等性
我们的目标是丢弃任何失败任务的部分输出，以便能安全地重试，而不会生效两次。分散式事务是实现这个目标的一种方式，而另一种方式是依赖 **幂等性（idempotence）**【97】。
幂等操作是多次重复执行与单次执行效果相同的操作。例如，将键值储存中的某个键设定为某个特定值是幂等的（再次写入该值，只是用同样的值替代），而递增一个计数器不是幂等的（再次执行递增意味著该值递增两次）。
即使一个操作不是天生幂等的，往往可以透过一些额外的元资料做成幂等的。例如，在使用来自 Kafka 的讯息时，每条讯息都有一个持久的、单调递增的偏移量。将值写入外部资料库时可以将这个偏移量带上，这样你就可以判断一条更新是不是已经执行过了，因而避免重复执行。
Storm 的 Trident 基于类似的想法来处理状态【78】。依赖幂等性意味著隐含了一些假设：重启一个失败的任务必须以相同的顺序重播相同的讯息（基于日志的讯息代理能做这些事），处理必须是确定性的，没有其他节点能同时更新相同的值【98,99】。
当从一个处理节点故障切换到另一个节点时，可能需要进行 **防护**（fencing，请参阅 “[领导者和锁](ch8.md#领导者和锁)”），以防止被假死节点干扰。尽管有这么多注意事项，幂等操作是一种实现 **恰好一次语义** 的有效方式，仅需很小的额外开销。
#### 失败后重建状态
任何需要状态的流处理 —— 例如，任何视窗聚合（例如计数器，平均值和直方图）以及任何用于连线的表和索引，都必须确保在失败之后能恢复其状态。
一种选择是将状态储存在远端资料储存中，并进行复制，然而正如在 “[流表连线（流扩充）](#流表连线（流扩充）)” 中所述，每个讯息都要查询远端资料库可能会很慢。另一种方法是在流处理器本地储存状态，并定期复制。然后当流处理器从故障中恢复时，新任务可以读取状态副本，恢复处理而不丢失资料。
例如，Flink 定期捕获运算元状态的快照，并将它们写入 HDFS 等持久储存中【92,93】。Samza 和 Kafka Streams 透过将状态变更传送到具有日志压缩功能的专用 Kafka 主题来复制状态变更，这与变更资料捕获类似【84,100】。VoltDB 透过在多个节点上对每个输入讯息进行冗余处理来复制状态（请参阅 “[真的序列执行](ch7.md#真的序列执行)”）。
在某些情况下，甚至可能都不需要复制状态，因为它可以从输入流重建。例如，如果状态是从相当短的视窗中聚合而成，则简单地重播该视窗中的输入事件可能是足够快的。如果状态是透过变更资料捕获来维护的资料库的本地副本，那么也可以从日志压缩的变更流中重建资料库（请参阅 “[日志压缩](#日志压缩)”）。
然而，所有这些权衡取决于底层基础架构的效能特征：在某些系统中，网路延迟可能低于磁碟访问延迟，网路频宽也可能与磁碟频宽相当。没有针对所有情况的普适理想权衡，随著储存和网路技术的发展，本地状态与远端状态的优点也可能会互换。
## 本章小结
在本章中，我们讨论了事件流，它们所服务的目的，以及如何处理它们。在某些方面，流处理非常类似于在 [第十章](ch10.md) 中讨论的批处理，不过是在无限的（永无止境的）流而不是固定大小的输入上持续进行。从这个角度来看，讯息代理和事件日志可以视作档案系统的流式等价物。
我们花了一些时间比较两种讯息代理：
* AMQP/JMS 风格的讯息代理
  代理将单条讯息分配给消费者，消费者在成功处理单条讯息后确认讯息。讯息被确认后从代理中删除。这种方法适合作为一种非同步形式的 RPC（另请参阅 “[讯息传递中的资料流](ch4.md#讯息传递中的资料流)”），例如在任务伫列中，讯息处理的确切顺序并不重要，而且讯息在处理完之后，不需要回头重新读取旧讯息。
* 基于日志的讯息代理