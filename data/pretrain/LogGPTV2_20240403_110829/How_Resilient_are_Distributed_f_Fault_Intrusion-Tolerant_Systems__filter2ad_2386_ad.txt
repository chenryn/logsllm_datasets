of the system – it slows down some nodes and postpones
the delivery of messages between two parts of the system
(or temporally partitions the network). The reader should
notice that after this ﬁrst attack the system will exhibit a
behavior that could have occurred in any fault-free asyn-
chronous system. Therefore, this attack simply forces the
system to act in a manner convenient for ADV2, instead of
having her wait for the system to naturally behave in such
way.
Attack by adversary ADV1: ADV1 performs a mobile
virus attack against f+1 servers. However, instead of trying
to retrieve the CODEX private key share of each node, it
does a much simpler thing: it adjusts, one after the other,
the rate of each local clock. The adjustment increases the
drift rate to make the clock slower than real time. In other
words, 1 system second becomes λ real time seconds, where
λ (cid:14) 1.
APSS execution is triggered either by a local timer at
each node or by a notiﬁcation received from another node4.
This notiﬁcation is transmitted during the execution of
APSS. The mobile virus attack delays at most f + 1 nodes
from starting their own APSS execution, but it does not pre-
vent the reception of a notiﬁcation from any of the remain-
der n − (f + 1) nodes. Therefore, various APSS instances
will be run during the attack.
After slowing down the clock of f + 1 nodes, ADV1
attacks the links between these nodes and the rest of the
system. Basically, it either temporally cuts off the links or
removes all messages that could (remotely) initiate APSS.
The links are restored once ADV2 obtains the CODEX pri-
vate key, which means that messages start to be delivered
again and the fair links assumption is never violated.
The reader should notice that the interruption of commu-
nications is not absolutely necessary for the effectiveness of
the ADV2 attack. Alternatively, one could extend the mo-
bile attack to the n nodes and in this way delay APSS exe-
cution in all of them.
Attack by adversary ADV2: ADV2 starts another mo-
bile virus attack against the same f + 1 nodes that were
compromised by ADV1. Contrarily to the previous attack,
this one now has a time constraint: the APSS execution in-
terval. Remember that f + 1 shares are only useful if re-
trieved in the interval between two successive executions of
APSS. However, for all practical considerations, the time
constraint is removed, since the clocks are made as slow as
needed, by a helping accomplice – ADV1. Thus, the actual
APSS interval is much larger than expected.
Without any time constraint, it sufﬁces to implement the
mobile virus attack suggested in the CODEX paper, learn-
ing, one by one, f + 1 CODEX private key shares. The
4These triggering modes were conﬁrmed by the inspection of the
CODEX code, which is available at http://www.umiacs.umd.
edu/˜mmarsh/CODEX/.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:59 UTC from IEEE Xplore.  Restrictions apply. 
CODEX private key is disclosed using these shares. Us-
ing this key, ADV2 can decrypt the secrets stored in the
compromised nodes. Moreover, she can get all new secrets
submitted by clients through write operations.
The described attack explores one ﬂaw on the assump-
tions of CODEX. It implicitly assumes that although em-
bracing the asynchronous model, it can have access to a
clock with a bounded drift rate. But, by deﬁnition, in an
asynchronous system no such bounds exist [7, 12, 6]. Typ-
ically, a computer clock has a bounded drift rate ρ guaran-
teed by its manufacturer. However, this bound is mainly
useful in environments with accidental failures. If an ad-
versary gains access to the clock, she or he can arbitrarily
change its progress in relation to real time.
More generally, the concept of proactive recovery has
some compatibility problems with the asynchronous model.
In [21], authors brieﬂy discuss some of these problems, and
conclude that the deﬁnition of the window of vulnerabil-
ity in terms of events rather than the passage of time, can
potentially afford attackers leverage. In fact, asynchronous
systems evolve at an arbitrary pace, while proactive recov-
ery has natural timeliness requirements: proactive recov-
ery leverages the defenses of a system by periodically “re-
moving” the work of an attacker. Despite these problems,
we subscribe the discussion about APSS vs a PSS (syn-
chronous proactive secret sharing) protocol in [21]: APSS
will defend against any attack that the PSS protocol does
and will also defend against some attacks that compromise
the PSS protocol, such as attacks that invalidate PSS timing
assumptions. This goes in line with what we say in the ﬁ-
nal of Section 3.1 about the greater fragility of synchronous
systems. However, APSS is still vulnerable to time attacks
such as the one presented above. Therefore, asynchronous
systems enhanced with proactive recovery subsystems are
in fact promising but care must be taken in their design.
4.3 Combining proactive recovery and wormholes
In this section, we propose one solution to the problem
of ensuring exhaustion-safe operation of proactive recovery
systems. The solution is based on the concept of worm-
holes: subsystems capable of providing a small set of ser-
vices, with good properties that are otherwise not available
in the rest of the system [16]. For example, an asynchronous
system can be augmented with a synchronous wormhole
that offers a few and well-deﬁned timely operations. Worm-
holes must be kept small and simple to ensure the feasi-
bility of building them with the expect trustworthy behav-
ior. Moreover, their construction must be carefully planed
to guarantee that they have access to all required resources
when needed. In the past, two incarnations of distributed
wormholes have already been created, one for the secu-
rity domain [5] (the TTCB) and another for the time do-
main [17] (the TCB).
Remember that as explained in Sections 3.2 and 3.3, it is
impossible to guarantee the exhaustion-safety of an asyn-
chronous system A when Atexhaust has a bounded value
(Corollary 3.3), even with an asynchronous proactive re-
covery scheme (Corollary 3.5). The reader however should
notice that the main difﬁculty with proactive recovery is not
the concept but its implementation – this mechanism is use-
ful to artiﬁcially increase Atexhaust as long as it has time-
liness guarantees. Therefore, we probably can ﬁnd a solu-
tion to this problem by revisiting the system and the proac-
tive recovery subsystem under an architecturally hybrid dis-
tributed system model, and using a wormhole to implement
the latter.
asynchronous
synchronous
A
A’
Figure 5. A system A enhanced with a proac-
tive recovery subsystem A(cid:1). A runs asyn-
chronously, but A(cid:1) runs synchronously in the
context of a secure and timely wormhole.
We could use the TTCB Timely Execution Service to
timely execute proactive recovery protocols. The feasibil-
ity of building such a service in a real system is conﬁrmed
by the already available implementation5 of the TTCB for
the RTAI [4] operating system.
We let as future work the conception of a wormhole
speciﬁcally tailored for proactive recovery. We envisage
that this wormhole will be simpler and will require weaker
environment assumptions than the TTCB. A representation
of a system using a wormhole to execute proactive recovery
procedures is depicted in Figure 5.
Because it makes synchronous assumptions, the worm-
hole is in theory subject to the same kind of problems de-
scribed in Section 3.1. However, in practice, the worm-
hole can be a small and simple component, and thus, as
explained in [5], it can be constructed in order to depend-
ably guarantee secure and timely behavior.
5 Conclusions and future work
This paper has made a discussion about the actual re-
silience of synchronous and asynchronous systems. We
5Available
at
software/tcb/downloads.htm.
http://www.navigators.di.fc.ul.pt/
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:59 UTC from IEEE Xplore.  Restrictions apply. 
it
proposed a system model that takes in account the environ-
mental resources and their evolution along the timeline of
system execution, and introduced the predicate exhaustion-
safe, meaning freedom from exhaustion-failures.
Based on it, we predicted the extent
to which
fault/intrusion-tolerant distributed systems (synchronous
and asynchronous) can be made to work correctly. We
is possible to have exhaustion-safe f
showed that
fault/intrusion-tolerant synchronous systems as long as they
have a bounded lifetime, with the remark that timing as-
sumptions must not be violated. We also showed that
it is impossible to have exhaustion-safe f fault/intrusion-
tolerant asynchronous systems. Even proactive recovery in
asynchronous systems, though a major breakthrough in that
context, has some limitations which had not been identiﬁed
before. We explained these limitations and showed them in
practice through an attack to the CODEX system that does
not violate any of the assumptions underlying its operation.
Finally, we proposed the combined use of proactive recov-
ery and wormholes as a possible approach to circumvent
these limitations.
As future work, we intend to study in more detail the
combination of proactive recovery and wormholes. Our
goal is to deﬁne a hybrid wormhole-enhanced architecture
that guarantees the safety of the asynchronous (or syn-
chronous) payload part, despite any number of arbitrary
faults, through the wormhole-based timely execution of
proactive recovery protocols.
Acknowledgments
We would like to thank Ant´onia Lopes, and the anony-
mous referees for their valuable comments on improving
this paper.
References
[1] G. Bracha and S. Toueg. Asynchronous consensus and
broadcast protocols. Journal of the ACM, 32(4):824–840,
Oct. 1985.
[2] C. Cachin, K. Kursawe, A. Lysyanskaya, and R. Strobl.
Asynchronous veriﬁable secret sharing and proactive cryp-
tosystems. In CCS ’02: Proceedings of the 9th ACM con-
ference on Computer and communications security, pages
88–97. ACM Press, 2002.
[3] M. Castro and B. Liskov. Practical Byzantine fault toler-
ance and proactive recovery. ACM Transactions on Com-
puter Systems, 20(4):398–461, Nov. 2002.
[4] P. Cloutier, P. Mantegazza, S. Papacharalambous, I. Soanes,
S. Hughes, and K. Yaghmour. DIAPM-RTAI position paper.
In Real-Time Linux Workshop, Nov. 2000.
[5] M. Correia, P. Ver´ıssimo, and N. F. Neves. The design of a
COTS real-time distributed security kernel. In Proceedings
of the Fourth European Dependable Computing Conference,
pages 234–252, Oct. 2002.
[6] F. Cristian and C. Fetzer. The timed asynchronous system
model. In Proceedings of the 28th IEEE International Sym-
posium on Fault-Tolerant Computing, pages 140–149, 1998.
[7] M. J. Fischer, N. A. Lynch, and M. S. Paterson. Impossibility
of distributed consensus with one faulty process. Journal of
the ACM, 32(2):374–382, Apr. 1985.
[8] J. A. Garay, R. Gennaro, C. Jutla, and T. Rabin. Secure
distributed storage and retrieval. Theor. Comput. Sci., 243(1-
2):363–389, 2000.
[9] V. Hadzilacos and S. Toueg. A modular approach to fault-
tolerant broadcasts and related problems. Technical Report
TR94-1425, Cornell University, Department of Computer
Science, May 1994.
[10] A. Herzberg, M. Jakobsson, S. Jarecki, H. Krawczyk, and
M. Yung.
Proactive public key and signature systems.
In Proceedings of the 4th ACM Conference on Computer
and Communications Security, pages 100–110. ACM Press,
1997.
[11] A. Herzberg, S. Jarecki, H. Krawczyk, and M. Yung. Proac-
tive secret sharing or: How to cope with perpetual leakage.
In Proceedings of the 15th Annual International Cryptol-
ogy Conference on Advances in Cryptology, pages 339–352.
Springer-Verlag, 1995.
[12] N. Lynch. Distributed Algorithms. Morgan Kaufmann,
1996.
[13] M. A. Marsh and F. B. Schneider. CODEX: A robust and
secure secret distribution system.
IEEE Transactions on
Dependable and Secure Computing, 1(1):34–47, January–
March 2004.
[14] R. Ostrovsky and M. Yung. How to withstand mobile virus
attacks (extended abstract). In Proceedings of the tenth an-
nual ACM symposium on Principles of distributed comput-
ing, pages 51–59. ACM Press, 1991.
[15] D. P. Siewiorek and R. S. Swarz. Reliable Computer Sys-
tems: Design and Evaluation (2nd Edition). Digital Press,
1992.
[16] P. Ver´ıssimo. Uncertainty and predictability: Can they be
reconciled? In Future Directions in Distributed Computing,
volume 2584 of Lecture Notes in Computer Science, pages
108–113. Springer-Verlag, 2003.
[17] P. Ver´ıssimo and A. Casimiro. The Timely Computing
Base model and architecture. IEEE Transactions on Com-
puters, 51(8):916–930, Aug. 2002. Preliminary version as
DI/FCUL Technical Report 99–2.
[18] P. Ver´ıssimo, N. F. Neves, C. Cachin, J. A. Poritz, D. Powell,
Y. Deswarte, R. J. Stroud, and I. S. Welch. Intrusion-tolerant
middleware: the MAFTIA approach. DI/FCUL TR 04–14,
Department of Informatics, University of Lisbon, November
2004.
[19] P. Ver´ıssimo and L. Rodrigues. Distributed Systems for Sys-
tem Architects. Kluwer Academic Publishers, 2001.
[20] L. Zhou, F. Schneider, and R. van Renesse. COCA: A secure
distributed on-line certiﬁcation authority. ACM Transactions
on Computer Systems, 20(4):329–368, Nov. 2002.
[21] L. Zhou, F. B. Schneider, and R. van Renesse. Proactive
secret sharing in asynchronous systems. Technical Report
TR 2002-1877, Cornell University, New York, Oct. 2002.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:59 UTC from IEEE Xplore.  Restrictions apply.