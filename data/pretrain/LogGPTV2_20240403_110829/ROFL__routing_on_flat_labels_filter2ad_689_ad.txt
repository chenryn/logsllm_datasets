four messages times the diameter of the network since only succes-
sors need to be notiﬁed on join of a new host. Moreover, ROFL
gives the operator control over the number of messages gener-
ated for host joins. For example, ephemeral hosts can join with a
smaller number of successor pointers, and routers can keep succes-
sor groups active while host-sessions ﬂuctuate. Figure 5c shows
a CDF of the amount of time required to complete a join. This
amount of time is typically on the order of the network diameter,
because several messages in the join are sent in parallel. In prac-
tice, join overhead may be reduced further by ephemeral joins and
having the router maintain the virtual node when the host fails or
moves temporarily to another AS. Finally, we note this join over-
head is a one-time cost in the absence of churn.
Stretch: Figure 6a plots stretch, measured by routing packets be-
tween random sources and destinations, as a function of the size
of the pointer cache. Although stretch with small pointer caches
can be high, with roughly 70,000 entries (corresponding to a 9Mbit
cache of 128-bit IDs) the stretch drops to roughly 2. By compar-
ison a DNS lookup suffers a round trip to the DNS server before
sending which could incur a stretch of up to 3. Figure 6b shows
the fraction of packets that traverse a particular router. The x-axis
corresponds to the rank of the router in a list sorted by the y-value
for OSPF. That is, for a particular x value, we plot the load at the
ith most congested router in an OSPF network, and the load under
ROFL for that same router. We can see that although load varies
across routers, the difference from OSPF is fairly slight, indicating
that ROFL does not introduce a signiﬁcant increase in the number
of “hot-spots.”
Memory requirements: The intradomain pointer-cache mem-
ory requirements of ROFL is shown in Figure 6c. By comparison
CMU-ETHERNET requires from 34 to 1200 times more memory
than ROFL. ROFL’s memory requirements were reduced further
for routers near the network edge, potentially allowing non-core
routers (e.g. customer routers in access networks) to have smaller
TCAMs or to cache popular destinations and additional successors.
In addition, hosting routers must store state for resident IDs, which
requires between 1.3 Mbits for AS 3257 to 10.5 Mbits for AS 1239
assuming IDs are hosted at the Rocketfuel-visible transit routers.
Failure: Here we discuss the overhead and time to reconverge in
the presence of network level events. We found the overhead trig-
gered by host failure and mobility to be comparable to join over-
head, and link/router failures that do not trigger partitions to be
comparable to OSPF recovery times. However if a network-layer
partition occurs the ring needs to reconverge into two separate, con-
sistent namespaces. We believe partition events in ISPs are rare in
comparison to host failures given the high degree of engineering
and redundancy in these networks. Nevertheless, we investigate this
]
s
t
e
k
c
a
p
[
d
a
e
h
r
e
v
o
n
o
i
j
l
a
t
o
T
 1e+08
 1e+07
 1e+06
 100000
 10000
 1000
 100
 10
 1
ROFL-AS1221
ROFL-AS1239
ROFL-AS3257
ROFL-AS3967
 1
 10
 100
 1000  10000
IDs per AS
(a)
n
o
i
t
c
a
r
f
e
v
i
t
a
u
m
u
C
l
 1
 0.8
 0.6
 0.4
 0.2
 0
AS 1221
AS 1239
AS 3257
AS 3967
 0  5  10  15  20  25  30  35  40  45
Join overhead [packets]
(b)
n
o
i
t
c
a
r
f
e
v
i
t
l
a
u
m
u
C
 1
 0.8
 0.6
 0.4
 0.2
 0
AS 3257
AS 3967
AS 1239
AS 1221
 0  5  10  15  20  25  30  35  40  45
Join latency [ms]
(c)
Figure 5: Intradomain routing, joining: (a) Cumulative overhead to construct the network (b) CDF of overhead per node join (c) Join latency
h
c
t
e
r
t
S
 9
 8
 7
 6
 5
 4
 3
 2
 1
 0
AS1221
AS1239
AS3257
AS3967
 1
 10
 100
 1000  10000 100000 1e+06
Finger cache size [entries]
(a)
r
e
t
u
o
r
i
g
n
s
r
e
v
a
r
t
s
g
s
m
f
o
n
o
i
t
c
a
r
F
OSPF
ROFL
 0.1
 0.08
 0.06
 0.04
 0.02
 0
 0
 100
 200
Router number
(b)
]
s
e
i
r
t
n
e
[
e
g
a
s
u
y
r
o
m
e
m
r
e
t
u
o
r
.
g
v
A
 10000
 1000
 100
 10
 1
 1
ROFL-AS1221
ROFL-AS1239
ROFL-AS3257
ROFL-AS3967
 10
 100
 1000
IDs
(c)
Figure 6: Intradomain routing, data trafﬁc performance: (a) Effect of pointer cache size on stretch (b) Load balance, compared with shortest-path
routing (OSPF) (c) Memory used per router
]
s
t
e
k
c
a
p
[
n
o
i
t
i
t
r
a
p
r
e
p
d
a
e
h
r
e
v
O
 100000
 10000
 1000
 100
 10
 1
AS 1221
AS 1239
AS 3257
AS 3967
 1
 10
 100
 1000
IDs per PoP
Figure 7: Convergence overhead from Point of Presence (PoP)
failures
overhead to show performance under such extreme scenarios. Fig-
ure 7 shows the overhead to recover from a partition. We create
partitions by varying the number of IDs per PoP between 1 and
10000 (we collect PoP information from Rocketfuel [32] traces),
randomly selecting a PoP, and measuring the overhead to discon-
nect and reconnect it to the graph. We found that repair did not trig-
ger any massive spikes in overhead, which was roughly on the same
order of magnitude of rejoining all the hosts in the PoP. Finally, we
repeated this experiment for 10 million partitions and our approach
converged correctly in every case; we perform consistency checks
for misconverged rings in the simulator.
6.3 Interdomain
Join overhead: Figure 8a shows the overhead to join a single host.
On the x-axis we vary the number of IDs in the AS, and on the y-
axis we plot a moving average of the join overhead over the last 200
joins, averaged over 3 runs. We compare four joining strategies:
ephemeral, where the host joins only at its global successor, single-
homed, where the host joins only via a single path towards the core,
recursively multihomed, where the host joins via all ASes above it
in the topology, and recursively multihomed+peering (which we
call Peering), where the host also joins across all adjacent peer-
ing links. The last approach provides the strongest guarantees on
isolation, but comes at an increased join overhead. The join over-