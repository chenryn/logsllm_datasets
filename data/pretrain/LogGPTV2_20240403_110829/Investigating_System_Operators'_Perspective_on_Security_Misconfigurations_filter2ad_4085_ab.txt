Alex
Benjamin
Christian
David
Eno
Konstantin
Background
Former database administrator (DBA), now
DBA team lead, large organization, mostly
databases and Red Hat Linux
Operator focusing on networking/systems,
organization size unclear
Linux administrator with additional network-
ing tasks, medium-sized organization
Consultant, freelancer, mixed setup as used
by the customers, not administrating himself
anymore
Network operator, organization size unclear,
also active in an NGO
Network engineer,
provider
large public healthcare
Language
German
German
German
German
German
English
Table 1: Interview partners and their backgrounds
Category
Misconfiguration
Types
Impact
of Security Incidents
Misconfiguration
Facilitating Factors
Impact on
Work Environment
Detection
Possible Mitigations
Description
The technical misconfiguration and resulting security flaw
Consequences for organizations, clients, and users
Why misconfigurations occurred
How an incident impacted the work environment
Circumstances leading to misconfiguration detection
Methods, tools, and processes that would have prevented
misconfigurations
Table 2: Coding-categories that emerged from interviews
Category
Authentication
Passwords
Updates
Firewalls
Encryption
Scripting
Storage
No hardening
Authorization
Deployment
Integration
Example
Faulty or missing identity verification
Bad or publicly known (e.g., default) passwords
Missing or delayed (security-related) updates
Disabled firewalls, faulty filter settings
Unencrypted login pages, bad SSL/TLS settings
Faulty automation stalling system components
Backups on the same drive as the productive system
Not following best current practices, although it has no
direct security impact
Faulty assignment of access privileges
Publishing information like extended log files or version
information in connect banners
Insufficiently separated systems (e.g., Internet and intranet),
not adapting old configuration to new systems
Table 3: Misconfiguration types of the qualitative study
interviews, where participants may digress around questions, spe-
cific inquiries might have influenced their openness. Nonetheless,
we include general information on their background, such as rel-
ative organization size or industry sector. We carefully examined
the operators’ statements about their general work environment to
ensure that the participants did not accidentally reveal identifying
information,andtoredactsuchinformationbeforeproceedingwith
the interviews. We also inquired about the operators’ background,
for example, which kind of systems they commonly operate. Our
participants have diverse backgrounds (Table 1), spanning smaller
and larger organizations as well as different aspects of operations,
including networks, systems, and, (database) applications. Interest-
ingly, as to why misconfigurations occur, the participants described
their perceived issues in general, and regularly and explicitly noted
that their comments are independent of any specific organization.
4.2 Coding Categories
Misconfiguration Types. This category contains the cases that the
operators considered a security misconfiguration. We categorize
theminelevensub-categories(Table3),whichareintentionallytech-
nical. Although including the nature of the misconfiguration (its
root cause) could yield interesting categories, such as the usage of
defaults due to being misled by conventions, or lack of updates due
to abandoned components (e.g., if the initially responsible person
left the organization), it ultimately leads to fuzzy results as miscon-
figurations often have several contributing causes. Hence, we de-
tach the technical mistake from its cause. This approach is more
suitable to identify both misconfiguration types and the involved
components.
Impact of Security Misconfigurations. During our study, intervie-
wees were mostly vague on the impact of security misconfigura-
tions. In many cases, the impact follows directly from the type of
misconfiguration, like when an operator does not configure authen-
tication, then unauthorized parties will have access. However, if the
(potential) impact does not directly follow from the misconfigura-
tion itself, then it is often not clear whether therehas been an accom-
panying incident. Furthermore, even if an incident occurs, then the
incident may still not be attributable to a single misconfiguration.
Misconfiguration Facilitators. Identifying misconfiguration facil-
itators is one of the objectives of our study. The interviewees’ per-
ceptions on potential causes yield a multitude of unique codes in
which the operators explain what keeps them and their peers from
configuring systems correctly and securely. We encouraged the par-
ticipants to cover all aspects of potential factors, which resulted in
several mutually dependent codes. In turn, a clear distinction and
separation between them is challenging. Based on our coding, we
systematically group codes relating to misconfiguration facilitators
by the responsibility domains of the actors:
Systems
Operators
This category relates to the systems involved, for example,
complex setups, software with bad defaults, or, complex and
confusing interfaces.
This category includes personal shortcomings of the opera-
tors, such as overconfidence or insufficient knowledge.
Organizational Environment
This category relates to the operators’ organizational envi-
ronment, including management, or policy implementation.
Systems. Factors relating to the systems that the operators use
are predominantly usability issues, as Krombholz et al. also discov-
ered [9]. For instance, Alex remarks: “If you are setting up a new
system, you have to learn how it works first. But getting it working
is usually more important than figuring out which switches are there,
and which have to be flipped so the system is working and secure.”
The issues in this group have technical solutions: Pervasive usabil-
ity, better system management tools, and secure-by-default [33].
Operators. The operators are the main actors in systems’ opera-
tion, and we group factors together under the operators’ umbrella
4
Investigating System Operators’ Perspective on Security Misconfigurations
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
that relate to them personally. During our interviews, the most fre-
quentlymentionedissuesontheoperators’sidewasalackofknowl-
edge, experience, or concern, but also simple blunders, or as David
put it: “typos happen.”
Focusingonknowledgeandexperience,Enostatesthatmostnew
operators, just right out of school, are “[…] still wet behind their
ears regarding security.” Similarly, on the matter of misleading tu-
torials perpetuating insecure solutions, like chmod -Rv 0777 ./,
Christian mentions that “with enough experience you would never
do something like that. But it’s written on the Internet.” Interestingly,
Acar et al. [31] reported similar behavior among programmers.
On a self-reflective note, Konstantin reports why he misconfig-
ured a firewall, exposing countless internal hospital systems: “As
to why, well I was fairly right out of school, unexperienced, and my
education did not even prepare me for something so complex.”
Organizational Environment. In our classification, the organiza-
tional environment includes actions by the organizations’ manage-
ment team, as well as other institutional and policy-driven exter-
nal factors, like standards and regulations. Particularly important
is that personal and systemic factors can be amplified by the en-
vironment. For example, Konstantin continues his prior comment:
“I had very little training, our manager was the ‘figure it out yourself
type’. Which was common back then :)”
The participants also reported unreasonable budget constraints,
an unreflected faith in external suppliers, and consultants leading
to issues. David remarks on why automation and quality assurance
as remedies to typos and blunders are not implemented by a multi-
national network provider: “They use external consultants up to the
team-lead level. These cost 1/4 of an engineer in Germany. Why should
they care about implementing quality assurance or automation?”
Intervieweesoftentracetheseissuesbacktomanagementhaving
little to no understanding about what exactly the operators’ day-to-
day responsibilities look like. Such as when Konstantin and multi-
ple colleagues tried to communicate to their manager that a security
misconfiguration related issue in their network was in dire need to
be addressed, the manager “[…] then claimed we where just after buy-
ing fancy hardware, and overdoing [exaggerating] the severity of the
warned about issues.” This may tie in with more structural communi-
cation issues, or as David remarks: “From a manager’s point of view
all technicians are the same. Why? Because no matter to whom he
talks, he does not understand him.”
Factor Frequency. In our analysis, we find that external factors
appear more frequent than systems or personal factors. The most
common factors that we encounter are “unqualified leadership” and
“financial decisions.” Interestingly, insufficient knowledge and con-
cern are mentioned frequently, but other systemic reasons, such as
poor defaults or usability issues, are mentioned rarely.
Impact of Misconfigurations on Job Attitude. Over the course of
our interviews, we frequently encounter codes indicating that se-
curity misconfigurations lead to some positive change in job atti-
tude. Konstantin comments on actions taken after an incident: “We
adopted a clear naming standard for our firewall rules and interfaces
[…] The hospital in question started segmenting up there [their] net-
work.” Similarly, Benjamin remarks that “processes were adjusted”.
However, he also notes that “Timepressure is usually not fixed, be-
cause everything has to be fast.” Several interviewees report that
5
while actions were taken in response to an incident, they did not
include a general commitment to security, but they were incident-
driven remediation of the specific issues. More generally, the differ-
ing statements can be summarized by Christian’s remark: “Either
you are embarrassed by your mistake and learn from it, or you estab-
lish more funny processes and buy useless security stuff. In large shops
it’s usually the latter.”
Detection. Looking at how misconfigurations are discovered in
practice, we identify three principal cases: (i) detection due to an
incident, (ii) accidental detection, and (iii) detection during an au-
dit. In our interviews, Christian reports an example of (i), namely
how he encountered a misconfigured system because it was unac-
counted for, security patches were not installed, and, in turn, it was
compromised:“Oryou’rewonderingwhytherestillareworm-infested
Windows machines on your network and only then realize that the
print-server of $printing-system also uses windows. Of course not hav-
ing been updated for years.” In contrast, Benjamin explains how he
accidentally stumbled upon a misconfiguration, insufficiently pro-
tected file shares, by chance: “Chance is, if you are searching for some-
thing on a file share and suddenly stumble onto something that should
not be there.” He also reports that found misconfigurations during
security audits. However, based on the interviews, we cannot deter-
mine a clear distinction between audits as a method for detecting
misconfigurations versus them being a method to preventing them
in the first place.
Possible Mitigations. We identify four clusters from the mitiga-
tion strategy codes: (i) personal measures, (ii) non-personal mea-
sures including organizational strategies, (iii) postmortem strate-
gies, and (iv) social strategies. Generally, system operators are con-
fident that existing tools and procedures could mitigate security
misconfigurations if they were used. Furthermore, a technique that
received particular attention across operators are “blameless post-
mortems”. Blameless postmortems are important and effective be-
cause, as Benjamin puts it, “[…] they are not about figuring out who’s
guilty, but instead about finding a sustainable solution for the prob-
lem.”
Personal Measures. The operators also commonly mention per-
sonal behavior and actions to reduce the occurrence of misconfig-
urations in the first place. On the more straight-forward side, they
suggest to be mindful about one’s tasks and to pay attention. Simi-
larly, having enough time to actually be mindful, planning well be-
foremakingchanges,andhavingaclearoverview andunderstanding
of the system are aspects that operators see themselves to be respon-
sible for. To ensure some of these personal best practices, Eno aims
to make changes to systems he operates only between 8 AM and
2 PM. Furthermore, they frequently mention that it is imperative to
have enough fundamental knowledge of the task at hand, as well as
sufficient experience in system operations.
Non-personal Measures. Foreshadowed by the perceived reasons
for security misconfigurations leaning toward non-personal issues,
operatorsalsohavestrongtendenciestowardprocessdrivenmitiga-
tions. For example, operators frequently mention that they require
processes that enable them to work without making mistakes. Sim-
ilarly, operators are concerned about the lack of understanding by
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
Constanze Dietrich, Katharina Krombholz, Kevin Borgolte, and Tobias Fiebig
theirmanagersonhowdiversetheknowledgeinITisandwhattech-
nicians require in terms of environment, tools, and support to work
effectively and efficiently. In turn, they also perceive their job as be-
ing a translator between management and IT, and they indicate that
there should be more IT professionals bridging the communication
gap between IT and management. This highlights the importance
of communication, particularly across departments, which is tightly
connected to the suggested social strategies.
Postmortem and Social Strategies. It is common practice to con-
duct a postmortem analysis after any incident, with the goal of iden-
tifyingwhat wentwrongandwhy.Theoperatorsinourstudystrongly
emphasizethatapostmortem must be blameless.Inablamelesspost-
mortem,personalresponsibilityandaccountabilityisdetachedfrom
the what and why. Specifically, a blameless postmortem aims to pre-
vent operators from omitting the truth to avoid punishment for mis-
takes,whichcouldobscureorcovertheactualunderlyingcausesfor
the incident, such as a lack of automation or poor procedures that
lead to security misconfigurations.
4.3 Summary
Overall,ourqualitativestudyrevealsperceptionsonthemanyinter-
dependent facets of security misconfigurations. Our interviewees
have a broad range of experiences with security misconfigurations.
Based on our interviews, security misconfigurations appear to be a
common problemin the operations community. Although technical
mitigation strategies exist, operators still perceive mitigation strate-
gies as rarely or insufficiently implemented and they see the princi-
pal reasons for misconfigurations in the institutional and manage-
ment domain. The operators also highlight that the discovery of a se-
curity misconfiguration or an incident due to a misconfiguration it-
selfoftenhasapositiveeffectonacompany’ssecurityposture.How-
ever, this positive effect can only be temporary. Based on these ob-
servations, we focus our quantitative analysis on three core themes:
(1) Securitymisconfigurationsaremorecommonthanthe
reported security incidents indicate.
Security misconfigurations do not always lead to large-scale
security incidents. Hence, they may not have been publicly
disclosed. Based on our qualitative research, we assume that
misconfigurations are a regular occurrence and every opera-
tor has encountered them previously.
(2) Securitymisconfigurationfacilitatorsarelargelybased
in the management and institutional domain.
Most discussed misconfiguration facilitators pertain to deci-
sions by management or institutional characteristics, such as
insufficiently allotted time to complete tasks, underspecified,
missing, or overly restrictive processes, as well as unreason-
ablebudgetconstraints.Theseconditionsappeartobecaused
by a lack of understanding or trust toward the operators.
(3) Security misconfigurations that result in security inci-
dentsmakemanagementandoperations(temporarily)
more security-sensitive.
Severalintervieweesstatedthatdiscoveringsecuritymiscon-
figurations made them more cautious. Furthermore, as inci-
dents also involve management, the negative impact of mis-
configurations (eventually) will make management more ap-
preciativeofsecurityandincidentprevention,which,inturn,
increases their willingness to invest in the security measures
that prevent or reduce the impact of misconfigurations. Im-
portantly, it only increases their willingness if we expect the
cost of an incident to be higher than its preventive measures,
which has become a reasonable assumption today due to the
theft and value of private data, and governmental fines [34].
5 QUANTITATIVE METHODOLOGY
To investigate the observations from the qualitative study, we con-
ducted a broader quantitative study. We implemented our question-
naire using Google Forms [35].
5.1 Questionnaire Structure and Sections
We specifically design our questionnaire so that it allows investi-
gating the previously stated observations.1 To address multiple cat-
egories of subjects gracefully, there are multiple paths through our
questionnaire, primarily based on the subjects’ current state of em-
ployment (Figure 1). See the full questionnaire in Appendix A.
At the start of our questionnaire, we inform participants about
the purpose of our study, and we explain the applicable privacy con-
siderations. We also inform the participants that completing the sur-
vey will take between 10 and 20 minutes, depending on how many
of the qualitative questions they will answer. Participants were not
compensated for participating in our survey.
Throughout our survey and wherever an estimation within a cer-
tain range was needed, we use unipolar and bipolar five-step Likert-
typescaleswithbalancedoptionsthatwouldbeperceivedasequally
far apart from each other [36].
We focus our survey on: Occupation, Job Environment, Daily
Business, Past Misconfiguration Experience, Misconfiguration Facili-
tating Factors, Consequences, Opinions, and Demographics.
Occupation. Operators may work in different organizational se-
tups and constellations. In fact, during our qualitative study, some