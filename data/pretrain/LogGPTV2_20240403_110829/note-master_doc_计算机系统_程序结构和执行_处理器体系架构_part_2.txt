  - 系统输入
  - 某个存储单元的输出
  - 某个逻辑门的输出
- 逻辑门的输出不能连接到一起
- 网必须无环
多路复用器：
![](/assets/202339173140.png)
### 字级的组合电路和HCL整数表达式
```hcl
[
    select1:expr1;
    select2:expr2:
    ...
]
```
### 集合关系
![](/assets/202339173244.png)
### 存储器和时钟
## Y86-64的顺序实现
### 将处理组织成阶段
- 取指
- 译码
- 执行
- 访存
- 写回
- 更新PC
### SEQ硬件结构
### SEQ时序
## 流水线的通用原理
![未流水线化](/assets/202262821248.png)
![流水线化](/assets/2022628212429.png)
用来同步简单指令与复杂指令的执行时长匹配，让所有步骤需要执行的时间尽量都差不多长，可以解决性能瓶颈来自于最复杂的指令的问题
流水线带来的吞吐率提升，只是一个理想情况下的理论值。在实践的应用过程中，还需要解决指令之间的依赖问题
每一级流水线对应的输出，都要放到流水线寄存器（Pipeline Register）里面，然后在下一个时钟周期，交给下一个流水线级去处理。所以，每增加一级的流水线，就要多一级写入到流水线寄存器的操作，由于这个原因，这个流水线级数也不能无线叠加上去
### 超标量与多发射
可以让 CPU 不仅在指令执行阶段是并行的，在取指令和指令译码的时候，也是并行的
![2022629212531](/assets/2022629212531.webp)
### 冒险与预测
- 流水线所带来的问题
#### 结构冒险
CPU 在同一个时钟周期，同时在运行两条计算机指令的不同阶段。但是这两个不同的阶段，可能会用到同样的硬件电路
![结构冒险](/assets/2022629204552.webp)
对于访问内存数据和取指令的冲突，一个直观的解决方案就是把我们的内存分成两部分，让它们各有各的地址译码器。这两部分分别是存放指令的程序内存和存放数据的数据内存
现代的CPU 没有对主存做划分，而是对内部的高速缓存部分进行了区分，把高速缓存分成了指令缓存（Instruction Cache）和数据缓存（Data Cache）两部分
#### 数据冒险
同时在执行的多个指令之间，有数据依赖的情况：
1. 先写后读
```c
int main() {
  int a = 1;
  int b = 2;
  a = a + 2;
  b = a + 3;
}
```
2. 先读后写
```c
int main() {
  int a = 1;
  int b = 2;
  a = b + a;
  b = a + b;
}
```
3. 写后再写
```c
int main() {
  int a = 1;
  a = 2;
}
```
最简单的一个办法，不过也是最笨的一个办法，就是流水线停顿（Pipeline Stall），或者叫流水线冒泡（Pipeline Bubbling）
![流水线停顿](/assets/2022629204915.webp)
另外一个方法就是操作数前推：
通过在硬件层面制造一条旁路，让一条指令的计算结果，可以直接传输给下一条指令，而不再需要“指令 1 写回寄存器，指令 2 再读取寄存器“这样多此一举的操作
![操作数前推](/assets/2022629205742.webp)
对于没有依赖的指令，是完全可以乱序执行的，只需保证结果是有序的就行：
![乱序并发](/assets/202262921730.webp)
#### 控制冒险
所有的流水线停顿操作都要从指令执行阶段开始。流水线的前两个阶段，也就是取指令（IF）和指令译码（ID）的阶段，是不需要停顿的。CPU 会在流水线里面直接去取下一条指令，然后进行译码
但是如果遇到分支语句，CPU要如何决定取哪个分支的指令加入到流水线？只有等跳转指令执行完成，才能明确程序走的是哪个分支
##### 缩短分支延迟
将条件判断、地址跳转，都提前到指令译码阶段进行，这样就能更快拿到结果，知道怎么执行
##### 分支预测
仍然按照顺序，把指令往下执行。其实就是 CPU 预测，条件跳转一定不发生。这样的预测方法，其实也是一种静态预测技术，有50%的概率猜中，当然如果猜错了，就需要把执行完成或者正在执行的指令清除掉
##### 动态分支预测
根据之前条件跳转的比较结果来预测
- 一级分支预测：用一个比特，去记录当前分支的比较情况
- 双模态预测器
## 超线程
在一个物理 CPU 核心内部，会有双份的 PC 寄存器、指令寄存器乃至条件码寄存器。这样，这个 CPU 核心就可以维护两条并行的指令的状态
![2022629213015](/assets/2022629213015.webp)
超线程的目的，是在一个线程 A 的指令，在流水线里停顿的时候，让另外一个线程去执行指令。因为这个时候，CPU 的译码器和 ALU 就空出来了，那么另外一个线程 B，就可以拿来干自己需要的事情
## SIMD
是一种“数据并行”的加速方案。在处理向量计算的情况下，同一个向量的不同维度之间的计算是相互独立的，就可以并行读取数据，并行计算
![2022629213436](/assets/2022629213436.webp)
## CISC与RISC
CISC               | RISC
------------------ | --------------------
以硬件为中心的指令集设计       | 以软件为中心的指令集设计
通过硬件实现各类程序指令       | 通过编译器实现简单指令组合,完成复杂功能
更高效地使用内存和寄存器       | 需要更大的内存和寄存器，并更频繁地使用
可变的指令长度，支持更复杂的指令长度 | 简单、定长的指令
大量指令数              | 少量指令数
现代的CPU的指令集大多是 RISC 和 CISC 融合的产物
- RISC-V：一个开源的指令集
## GPU
### 图像实时渲染原理
1. 顶点处理：构成多边形建模的每一个多边形，都有多个顶点（Vertex），把这些顶点在三维空间里面的位置，转化到屏幕这个二维空间里面
![顶点处理](/assets/2022630214337.webp)
2. 图元处理：把顶点处理完成之后的各个顶点连起来，变成多边形
![2022630214428](/assets/2022630214428.webp)
3. 栅格化：把做完图元处理的多边形，转换成屏幕里面的一个个像素点
![2022630214514](/assets/2022630214514.webp)
4. 片段处理：计算每一个像素的颜色、透明度等信息，给像素点上色
![202263021464](/assets/202263021464.webp)
5. 像素操作：把不同的多边形的像素点“混合（Blending）”到一起。可能前面的多边形可能是半透明的，那么前后的颜色就要混合在一起变成一个新的颜色
![2022630214644](/assets/2022630214644.webp)
这里的1 3 4 都是可以并行操作的
### 早期的GPU
![2022630214757](/assets/2022630214757.webp)
### 现代的GPU
可编程管线：在整个的渲染管线（Graphics Pipeline）的一些特别步骤，能够自己去定义处理数据的算法或者操作
![2022630215030](/assets/2022630215030.webp)
1. 芯片瘦身：本质上CPU核心就是一个GPU核心，但是GPU并不需要CPU核心的一些功能，就可以去掉
2. 多核并行和SIMT：由于核心精简了，所以就可以塞更多的核心提升并行度，并且可以一次取多条，计算多条数据
3. 超线程：提供较多的执行上下文，同样也是为了并行度
## FPGA
- 现场可编程门阵列（Field-Programmable Gate Array）：可重复对电路进行编程
1. 用存储换功能实现组合逻辑，通过 LUT 来实现各种组合逻辑
![LUT](/assets/2022742154.webp)
2. 对于需要实现的时序逻辑电路，使用 D 触发器，作为寄存器，组合了多个 LUT 和寄存器的设备，也被叫做 CLB（Configurable Logic Block，可配置逻辑块）
3. 通过可编程逻辑布线，来连接各个不同的 CLB，最终实现我们想要实现的芯片功能
![可编程逻辑布线](/assets/20227421822.webp)
## ASIC
有专门用途的场景，单独设计一个芯片。称之为 ASIC（Application-Specific Integrated Circuit），也就是专用集成电路
矿机的芯片也是一种ASIC，专用集成电路在某些方面能效比更加出色