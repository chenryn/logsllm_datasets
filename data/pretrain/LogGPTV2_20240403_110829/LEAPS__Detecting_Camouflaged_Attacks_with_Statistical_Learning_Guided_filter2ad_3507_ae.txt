remote hacker has already controlled their machine when the
trojaned application is running.
In this case, we leverage the tools and payloads in the
Metasploit Framework [31] to generate the trojaned applica-
tion. Metasploit Framework is a widely-adopted system for
developing and executing exploit code to perform penetration
testing. Msfpayload is a command-line tool for generating
6565
types of shellcode in the Metasploit Framework.
different
We use this tool to generate a Meterpreter, a dynamically
extensible payload that uses in-memory DLL injection stagers.
The Meterpreter communicates with the remote server via a
reverse TCP connection. It enables the remote adversary to
perform all kinds of hacking operations on a victim system,
e.g., keylogging, ﬁle uploading, taking screenshots, password
hash collection, etc. The benign host application in this case
is WinSCP. We leverage Msfencode to encode the payload
with shikata_ga_nai (a polymorphic XOR additive feedback
encoder) three times and then embed it
into the WinSCP
binary.
We can see from the results that all ﬁve measurements
increase if we use the WSVM model. Take ACC and TPR
for instance, we can see from Figure 6 that these two mea-
surements based on the call graph model are 74.79% and
68.16%. ACC and TPR increase to 85.81% and 72.08% if we
use traditional non-weighted SVM. Our Weighted SVM ap-
proach shows even better classiﬁcation effectiveness compared
to the SVM method. For example, ACC and TPR increase
to 93.2% and 86.5%. These comparisons demonstrate the
superior performance of our proposed CFG guided Weighted
SVM approach.
2) Case Study II — vim_codeinject: This case is also in the
ofﬂine infection category, but the infection technique and the
payload are different. We choose the hacking tool Codeinject
[32] to inject a password dialog into a portable executable, in
this case Vim is the host application. When the user starts Vim,
a password dialog will be popped up asking for the password,
which is pre-set when the trojaned binary is generated. If the
user does not know the password, Vim exits silently.
From Figure 6, we can see that vim_codeinject increases
in all ﬁve measurements for each classiﬁcation model. For
instance, ACCs for CGraph, SVM and WSVM are 35.5%,
72.5% and 85.2%. Another measurement, NPVs for CGraph,
SVM and WSVM are 51.8%, 64.6% and 78.2%, respectively.
3) Case Study III — putty_reverse_https_online: This case
is in the online injection category. In the event that there is
some unpatched vulnerability in the target system, an adversary
may craft some shellcode and perform a remote exploitation
to run the shellcode. In order to stay persistent in the system,
after taking control of the system, the adversaries can choose
a long-running process and inject a backdoor payload into
its memory space. They ﬁrst allocate a memory slot for
the backdoor payload and then remotely create a thread to
run the code in parallel with the benign code. In this case,
the adversaries ﬁrst leverage the Metasploit Framework to
take over the target system. Then they can run the script of
post/windows/manage/payload_inject to inject the Meterpreter
payload into the memory of a running Putty. Finally they can
connect to the Meterpreter payload running within the Putty’s
process via a reverse HTTPS connection.
We can see from Figure 7 that the ACC, PPV, TPR, TNR,
and NPV for WSVM are the highest, which is consistent with
our observation in the Case Study I and II. For example,
the corresponding ACCs for the three methods are 69.22%,
78.25% and 86.86%, and their respective TPRs are 41.2%,
56.1% and 73.8%.
VI. DISCUSSION
In this section, we examine the limitations of LEAPS
and propose potential solutions to address these problems.
In addition, we discuss some future research opportunities in
the area of attack detection by bridging program analysis and
machine learning based techniques.
A. Source-level Trojaned Applications
LEAPS currently targets camouﬂaged attacks against bi-
nary applications, which indicates that
the relative offsets
of the benign code will not change. However, imagine that
the adversary has obtained the source code of this benign
application. He or she could add the source code of the
malicious payload into the original code base, recompile the
program, and deliver the trojaned application to the victim.
For closed-source software, only internal developers of the
software vendors can intentionally conduct such trojan im-
planting attacks. For software in the open-source community,
each line of the committed source code will be open to public
inspection, which makes such attacks more difﬁcult. Assuming
there exist such malicious vendors or negligent maintainers,
currently LEAPS is not able to assign correct weights in the
mixed dataset because the CFG itself has been modiﬁed.
In order to address this limitation, we need to generalize
our CFG comparison algorithm. For trojaned applications,
assuming that the adversaries do not change the functionality
of the original benign software (they just implant the payload’s
source code), the general structure of the benign subgraph in
the CFG will not change. In light of this, instead of conducting
exact matching, we could search for isomorphic subgraphs in
both benign/mixed CFGs by identifying and aligning pivotal
nodes. We consider this as our future work to improve LEAPS.
B. Future Work in Learning
LEAPS employs a Weighted SVM model to distinguish
malicious events from benign ones. As shown in the experi-
mental results, LEAPS achieves reasonably good performance
on camouﬂaged attack detection, and consistently outperforms
approaches based on system-level call graph and pure SVM.
However, LEAPS only takes the order of adjacent events into
account. But in real scenarios, there may exist some causal
relations between multiple events dispersed far away (tempo-
rally) in the log. Therefore, we plan to explore more machine
learning techniques, such as conditional random ﬁeld model
and hidden Markov model, to reveal such hidden relationships
between events.
VII. RELATED WORK
Host-based anomaly detection and malware classiﬁcation
systems are well-researched in recent years. The general proce-
dure of these approaches is to extract the execution abstraction
from a subject program, build a model, and use this model to
make decisions on future data.
Some systems are based on the assumption that source code
or binary is available for analysis, thus they are able to derive
a precise model to represent the program’s execution. Wagner
et al. [1] deﬁne a model of expected application behavior
through static analysis of its source code, and then check the
6666
system call trace for compliance at runtime. Gifﬁn et al. [2],
[3] introduce the Dyck model, based on static binary analysis,
to include program instrumentation on the binary to facilitate
efﬁcient runtime monitoring. DOME [4] ﬁrst identiﬁes the
locations of system calls within the executables using static
analysis, and then verify at runtime that each observed system
call is invoked from its legitimate call site. SMIT [33] is
a malware indexing system that
leverages an executable’s
function-call graphs to cluster malware. Kruegel et al. [34]
propose extracting CFGs from worm executables embedded
in the network stream to identify structural similarities among
polymorphic worms. In real-world scenarios, source code or
executables may not always be available for training. Fur-
thermore, obfuscated executables and complexity of binary
disassembly render static analysis difﬁcult to build accurate
models. In comparison, LEAPS does not require static analysis
or instrumentation of application source or binary code. We
model the execution of the program only by analyzing the
system event log and infer its CFG to guide statistical learning.
Some researchers also propose black-box or gray-box ap-
proaches to infer the execution model without static analysis.
For example, Sekar et al. [6] propose an approach to gener-
ate a deterministic FSA by monitoring the normal program
executions at runtime, thus avoiding static analysis on source
code. Gao et al. [7] propose a gray-box approach that builds
execution graphs based on system call sequences and does
not require static analysis. Feng et al. [8] propose extracting
return addresses from the call stack to build a model of abstract
execution path and use the model to detect exploits. LEAPS
shares the methodology of dynamically deriving the program
execution model. Yet it is among the ﬁrst efforts to leverage the
inferred execution models to reﬁne statistical learning models
by pruning noisy training datasets.
Statistical learning techniques are also widely adopted in
anomaly detection research. Such techniques have the advan-
tage of being robust in processing incomplete training data,
thus they can usually achieve better classiﬁcation results. The
input of these systems is based on the interaction between the
applications and OS (e.g., system call sequence, system state
change, and access activities). For example, Hofmeyr et al. [11]
propose to characterize normal behaviors of a program in terms
of system call sequences, thus they can detect an anomalous
execution if it produces aberrant system call sequences. Wespi
et al. [12] leverage Teiresias, an algorithm for discovering
patterns in unaligned biological sequences, to build a table of
variable-length patterns of audit events. Lee et al. [9], [10]
leverage data mining techniques to ﬁnd patterns of system
features that describe program behavior. Bailey et al. [23]
develop a classiﬁcation technique that categorizes malware
behavior in terms of system state changes, rather than from
system call patterns. Lanzi et al. [35] demonstrate that malware
detectors based on system call sequence may not be effective
in real-world scenarios and build a model based on access
activities on ﬁles and the registry.
Recently, some researchers introduce more sophisticated
machine learning models, such as HMM and SVM, to assist
classiﬁcation. Warrender et al. [13] compare four anomaly
detection models based on the system call dataset and con-
clude that HMM achieves the best accuracy on average, but
with high computational costs. Gao et al. [36] propose the
concept of behavioral distance to compare the differences of
process’ behaviors on different platforms based on system
calls invoked. In subsequent work [14], they also introduce
HMM to measure the behavior distance to better account
for system call orderings. Heller et al. [16] use a one-class
SVM to perform training on a dataset of normal registry
accesses and then detect anomalous registry behavior in the
testing data. Kolter et al. [37] use n-grams of byte codes from
benign/malicious executables as features and evaluate them
on a variety of inductive methods to train the classiﬁcation
model. Rieck et al. [15] extract behavior of malware in a
sandbox environment and use SVM to learn the classiﬁcation
model for discriminating malware types. Bayer et al. [38]
leverage locality sensitive hashing to perform unsupervised
clustering based on the malware’s behavior extracted in a
controlled environment. Khan et al. [17] present a study on
using hierarchical clustering analysis for enhancing the training
time of SVM, especially for dealing with large data sets in
intrusion detection. Eskin [39] also recognizes the existence
of noisy training datasets. His solution is to ﬁrst
learn a
distribution probability over training data and then apply a
statistical test to detect anomalies. LEAPS also adopts SVM
as the statistical learning model. However, different from these
efforts that are purely based on learning, LEAPS leverages
the inferred CFGs as guidance to prune the noisy datasets,
thus effectively boosting the accuracy of the learned model
for detecting camouﬂaged attacks.
VIII. CONCLUSION
Camouﬂaged attacks implant malicious payloads into be-
nign applications and execute concurrently under the cover of
benign processes. This causes traditional statistical learning
based detection systems to generate a misleading decision
boundary due to noisy training data. In this paper, we present
LEAPS, a new attack detection system based on a supervised
statistical learning model to classify benign and malicious
system events. Different from existing approaches, LEAPS
leverages CFGs inferred from system event logs as guidance
to automatically reﬁne noisy training data, leading to a more
accurate classiﬁcation model for camouﬂaged attack detection.
We have conducted extensive evaluation on a range of real-
world attacks with ofﬂine and online camouﬂaging strategy.
Our experimental results demonstrate that LEAPS can effec-
tively improve classiﬁcation accuracy compared to traditional
learning and system-level call graph based models.
ACKNOWLEDGMENT
This work was inspired by technical discussions with
Dr. Sukarno Mertoguno, who proposed the “Learn-2-Reason”
paradigm [19]. We also thank Brendan Saltaformaggio and the
anonymous reviewers for their constructive comments. This
research has been supported in part by ONR under Award
N000141410468, NSF under Award 1409668, and Cisco Sys-
tems under an unrestricted gift. Any opinions, ﬁndings, and
conclusions in this paper are those of the authors only and do
not necessarily reﬂect the views of our sponsors.
REFERENCES
[1] D. Wagner and D. Dean, “Intrusion detection via static analysis,” in
Proceedings of the 2001 IEEE Symposium on Security and Privacy,
6767
[2]
[3]
[4]
ser. SP ’01. Washington, DC, USA: IEEE Computer Society, 2001,
pp. 156–.
J. T. Gifﬁn, S. Jha, and B. P. Miller, “Efﬁcient context-sensitive intrusion
detection.” in NDSS, 2004.
J. T. Gifﬁn, S. Jha, and B. P. Miller, “Detecting manipulated remote
call streams,” in Proceedings of the 11th USENIX Security Symposium.
Berkeley, CA, USA: USENIX Association, 2002, pp. 61–79.
J. C. Rabek, R. I. Khazan, S. M. Lewandowski, and R. K. Cunningham,
“Detection of injected, dynamically generated, and obfuscated malicious
code,” in Proceedings of the 2003 ACM Workshop on Rapid Malcode,
ser. WORM ’03. New York, NY, USA: ACM, 2003, pp. 76–82.
[5] H. Feng, J. Gifﬁn, Y. Huang, S. Jha, W. Lee, and B. Miller, “Formalizing
sensitivity in static analysis for intrusion detection,” in Security and
Privacy, 2004. Proceedings. 2004 IEEE Symposium on, May 2004, pp.
194–208.
[6] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni, “A fast automaton-
based method for detecting anomalous program behaviors,” in Proceed-
ings of the 2001 IEEE Symposium on Security and Privacy, ser. SP ’01.
Washington, DC, USA: IEEE Computer Society, 2001, pp. 144–.
[7] D. Gao, M. K. Reiter, and D. Song, “Gray-box extraction of execution
graphs for anomaly detection,” in Proceedings of the 11th ACM Confer-
ence on Computer and Communications Security, ser. CCS ’04. New
York, NY, USA: ACM, 2004, pp. 318–329.
[8] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong,
“Anomaly detection using call stack information,” in Proceedings of
the 2003 IEEE Symposium on Security and Privacy, ser. SP ’03.
Washington, DC, USA: IEEE Computer Society, 2003, pp. 62–.
[9] W. Lee, S. J. Stolfo, and P. K. Chan, “Learning patterns from unix
process execution traces for intrusion detection,” in In AAAI Workshop
on AI Approaches to Fraud Detection and Risk Management. AAAI
Press, 1997, pp. 50–56.
[10] W. Lee and S. J. Stolfo, “Data mining approaches for intrusion
detection,” in Proceedings of the 7th Conference on USENIX Security
Symposium - Volume 7, ser. SSYM’98. Berkeley, CA, USA: USENIX
Association, 1998, pp. 6–6.
[11] S. A. Hofmeyr, S. Forrest, and A. Somayaji, “Intrusion detection using
sequences of system calls,” J. Comput. Secur., vol. 6, no. 3, pp. 151–
180, Aug. 1998.
[12] A. Wespi, M. Dacier, and H. Debar, “Intrusion detection using variable-
length audit trail patterns,” in Proceedings of the Third International
Workshop on Recent Advances in Intrusion Detection, ser. RAID ’00.
London, UK, UK: Springer-Verlag, 2000, pp. 110–129.
[13] C. Warrender, S. Forrest, and B. Pearlmutter, “Detecting intrusions using
system calls: alternative data models,” in Security and Privacy, 1999.
Proceedings of the 1999 IEEE Symposium on, 1999, pp. 133–145.
[14] D. Gao, M. K. Reiter, and D. Song, “Behavioral distance measurement
using hidden markov models,” in Proceedings of the 9th International
Conference on Recent Advances in Intrusion Detection, ser. RAID’06.
Berlin, Heidelberg: Springer-Verlag, 2006, pp. 19–40.
[15] K. Rieck, T. Holz, C. Willems, P. Düssel, and P. Laskov, “Learning
and classiﬁcation of malware behavior,” in Proceedings of the 5th
International Conference on Detection of Intrusions and Malware,
and Vulnerability Assessment, ser. DIMVA ’08. Berlin, Heidelberg:
Springer-Verlag, 2008, pp. 108–125.
[16] K. A. Heller, K. M. Svore, A. D. Keromytis, and S. J. Stolfo, “One
class support vector machines for detecting anomalous windows registry
accesses,” in In Proc. of the workshop on Data Mining for Computer
Security, 2003.
[17] L. Khan, M. Awad, and B. Thuraisingham, “A new intrusion detection
system using support vector machines and hierarchical clustering,” The
VLDB Journal, vol. 16, no. 4, pp. 507–521, Oct. 2007.
[18] S.-J. Horng, M.-Y. Su, Y.-H. Chen, T.-W. Kao, R.-J. Chen, J.-L. Lai,
and C. D. Perkasa, “A novel
intrusion detection system based on
hierarchical clustering and support vector machines,” Expert systems
with Applications, vol. 38, no. 1, pp. 306–313, 2011.
J. S. Mertoguno, “Human decision making model for autonomic cyber
systems,” International Journal on Artiﬁcial Intelligence Tools Vol. 23,
No. 6 (2014).
[19]
[20] C. H. Kim, J. Rhee, H. Zhang, N. Arora, G. Jiang, X. Zhang, and D. Xu,
“Introperf: Transparent context-sensitive multi-layer performance in-
6868
ference using system stack traces,” in The 2014 ACM International
Conference on Measurement and Modeling of Computer Systems, ser.
SIGMETRICS ’14. New York, NY, USA: ACM, 2014, pp. 235–247.
[21] T. Hastie, R. Tibshirani, and J. Friedman, The Elements of Statistical
Learning, ser. Springer Series in Statistics. Springer New York Inc.,
2001.
[22] T. Bao, J. Burket, M. Woo, R. Turner, and D. Brumley, “Byteweight:
Learning to recognize functions in binary code,” pp. 845–860, 2014.
[23] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao, F. Jahanian, and
J. Nazario, “Automated classiﬁcation and analysis of internet malware,”
in Proceedings of the 10th International Conference on Recent Ad-
vances in Intrusion Detection, ser. RAID’07.
Berlin, Heidelberg:
Springer-Verlag, 2007, pp. 178–197.
[24] C. Kolbitsch, P. M. Comparetti, C. Kruegel, E. Kirda, X. Zhou, and
X. Wang, “Effective and efﬁcient malware detection at the end host,”
in Proceedings of the 18th Conference on USENIX Security Symposium,
ser. SSYM’09. Berkeley, CA, USA: USENIX Association, 2009, pp.
351–366.
[25] C. M. Bishop, Pattern Recognition and Machine Learning (Information
Secaucus, NJ, USA: Springer-Verlag New
Science and Statistics).
York, Inc., 2006.
[26] C. Chang and C. Lin, “LIBSVM: A library for support vector ma-
chines,” ACM TIST, vol. 2, no. 3, p. 27, 2011.
[27] S. hyuk Cha, “A genetic algorithm for constructing compact binary
decision trees,” Journal of Pattern Recognition Research, 2009.
[28] B. Schölkopf, R. Herbrich, and A. J. Smola, “A generalized representer
[29]
theorem,” in COLT, 2001, pp. 416–426.
I. Buch and R. Park,
tuning with
etw,” MSDN Magazine,[Online],Avaliable
http://msdn.microsoft.com/en-us/magazine/cc163437.aspx, 2007.
“Improve debugging and performance
from:
[30] S. V. Stehman, “Selecting and interpreting measures of thematic clas-
siﬁcation accuracy,” Remote sensing of Environment, vol. 62, no. 1, pp.
77–89, 1997.
“Metasploit,” http://www.metasploit.com/.
“Portable Executable (P.E.) Code Injection:
Injecting an Entire
C Compiled Application,” http://www.codeproject.com/Articles/24417/
Portable-Executable-P-E-Code-Injection-Injecting-a.
[31]
[32]
[33] X. Hu, T.-c. Chiueh, and K. G. Shin, “Large-scale malware indexing
using function-call graphs,” in Proceedings of the 16th ACM Conference
on Computer and Communications Security, ser. CCS ’09. New York,
NY, USA: ACM, 2009, pp. 611–620.
[34] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and G. Vigna, “Poly-
morphic worm detection using structural information of executables,”
in Proceedings of the 8th International Conference on Recent Advances
in Intrusion Detection, ser. RAID’05. Berlin, Heidelberg: Springer-
Verlag, 2006, pp. 207–226.
[35] A. Lanzi, D. Balzarotti, C. Kruegel, M. Christodorescu, and E. Kirda,
“Accessminer: Using system-centric models for malware protection,” in
Proceedings of the 17th ACM Conference on Computer and Commu-
nications Security, ser. CCS ’10. New York, NY, USA: ACM, 2010,
pp. 399–412.
[36] D. Gao, M. K. Reiter, and D. Song, “Behavioral distance for intrusion
detection,” in Proceedings of the 8th International Conference on Recent
Advances in Intrusion Detection, ser. RAID’05. Berlin, Heidelberg:
Springer-Verlag, 2006, pp. 63–81.
J. Z. Kolter and M. A. Maloof, “Learning to detect and classify
malicious executables in the wild,” J. Mach. Learn. Res., vol. 7, pp.
2721–2744, Dec. 2006.
[37]
[38] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda,
“Scalable, behavior-based malware clustering.” in NDSS, vol. 9. Cite-
seer, 2009, pp. 8–11.
[39] E. Eskin, “Anomaly detection over noisy data using learned probability
distributions,” in Proceedings of the Seventeenth International Confer-
ence on Machine Learning, ser. ICML ’00. San Francisco, CA, USA:
Morgan Kaufmann Publishers Inc., 2000, pp. 255–262.