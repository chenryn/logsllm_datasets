                                {      
                                        sendFileWithContent(TABLESPACE_MAP, tblspc_map_file);      
                                        sendDir(".", 1, false, tablespaces, false);      
                                }      
                                else      
                                        sendDir(".", 1, false, tablespaces, true);      
                                /* ... and pg_control after everything else. */      
                                if (lstat(XLOG_CONTROL_FILE, &statbuf) != 0)      
                                        ereport(ERROR,      
                                                        (errcode_for_file_access(),      
                                                         errmsg("could not stat control file \"%s\": %m",      
                                                                        XLOG_CONTROL_FILE)));      
                                sendFile(XLOG_CONTROL_FILE, XLOG_CONTROL_FILE, &statbuf, false);      
                        }      
                        else      
                                sendTablespace(ti->path, false);      
```      
通过以上方法，我们备份时的检查点信息得以保存在backup_label中，因此pg_basebackup的备份集，在恢复时可以拿到正确的WAL位置进行恢复，而不需要用到控制文件的检查点位置。        
因为控制文件可能不是最初的位置。        
## zfs快照, 如何保证多个zfs文件系统的一致性      
其实从pg_basebackup的备份步骤我们就能得知，备份集需要一个最老的检查点位置。        
那我们不使用pg_basebackup，如何能保证在整个备份过程中控制文件是最老的呢？        
因此最靠谱的方法是，优先给控制文件所在的ZFS打快照，然后再给其他ZFS文件系统打快照，这样就很好的解决了需要最老的控制文件的这个问题。        
## 例子      
回到我写的《PostgreSQL 最佳实践 - 块级增量备份(ZFS篇)方案与实战》        
https://yq.aliyun.com/articles/59363          
以上案例中一个standby集群用的是一个ZFS(所有表空间, 以及$PGDATA), 当数据库集群使用多个ZFS时, 因为快照只能基于单个volume或filesystem产生, 所以当我们使用了多个zfs filesystem是要得到数据库一致的备份, 怎么办呢?        
例如 :       
1\. $PGDATA使用文件系统 zfs/pg_root      
2\. tbs1使用文件系统 zfs/tbs1      
3\. tbs2使用文件系统 zfs/tbs2      
4\. pg_xlog使用文件系统 zfs/pg_xlog      
要使用zfs snapshot来备份这个PostgreSQL, 应该怎么做?      
前面已经从代码中分析了，我们需要最老的控制文件即可。      
首选创建控制文件所在zfs的快照, 再创建其他文件系统的快照.       
pg_xlog的快照可以不创建, 而通过归档来恢复.      
那么就比较清晰了, 以上快照的步骤如下 :       
```    
STIME=`date +%F%T`      
1. zfs snapshot zp1/pg_root@$STIME      
2. zfs snapshot zp1/tbs1@$STIME      
3. zfs snapshot zp1/tbs2@$STIME      
```    
## 验证    
验证一下这种方法的有效性      
还记得我以前写过一篇使用老的控制文件来恢复一个异常的standby吗?      
某数据库的流复制standby因为主库产生的XLOG过多, 延迟后触发了recovery.conf的restore命令, 但是restore里面用了sudo 进行copy并未保持源文件的owner, 属性等特征, 使用了root owner, 导致COPY完的xlog不能被postgresql 正常读取.    
同事在处理这个事情, 因为没有了解实际情况, 上去就使用了pg_resetxlog修改standby的nextXID(resetxlog在这个场景属于扯淡的操作, 千万不要这么干), 接着大家知道的, standby无法正常完成standby的工作了.    
这个数据库有10几个T, 要重新做standby的话, 拷贝的数据量太大了, 即使使用rsync重做, 工作量也比较大(表空间过多, 目录过多).    
有没有省事的方法呢?    
首先来分析一下事件,     
    1\. xlog不能被postgresql 正常读取(这个很好修复, 修改一下restore command就可以了, 或者不要用sudo 来拷贝).    
```  
2014-11-30 10:05:54.505 CST,,,3695,,5435f48b.e6f,6,,2014-10-09 10:35:55 CST,1/0,0,LOG,00000,"restored log file ""0000000300002A9D0000004D"" from archive",,,,,,,,"RestoreArchivedFile, xlogarchive.c:254",""    
2014-11-30 10:05:54.534 CST,,,3695,,5435f48b.e6f,7,,2014-10-09 10:35:55 CST,1/0,0,PANIC,42501,"could not open file ""pg_xlog/0000000300002A9D0000004D"": Permission denied",,,,,,,,"XLogFileRead, xlog.c:2696","" ```  
    2\. pg_resetxlog对控制文件造成了持久性伤害, 没有办法修复.    
```  
     pg_resetxlog -x 90010254 -f $PGDATA    
```  
    为了快速恢复, 可以找到更早的控制文件, 刚好这套数据库的备份系统使用的是ZFS快照做的, 每天会创建一个快照, 所以可以取早些时间的快照, 拿到控制文件, 替换掉standby被人为"破坏"的控制文件, 启动standby后, 将从控制文件开始恢复需要的xlog. (只要这些xlog归档还在就可以了).    
    操作过程 :     
    1\. shutdown standby    
    2\. mount zfs snapshot old then standby crashed time.    
    3\. copy $PGDATA/global/pg_control from snapshot to standby.    
    4\. startup standby.    
    5\. umount snapshot.    
    注意, 拿到的控制文件必须是standby crash之前的控制文件, 并且控制文件至今的所有xlog归档必须都在. postgresql standby将从控制文件需要的xlog开始恢复数据块. 所以这么做是完全可以的.    
    现在standby数据库已经完全恢复了    
```  
  882 postgres  20   0 2337m  15m  14m S  0.0  0.1   0:00.10 /opt/pgsql9.3.2/bin/postgres                                               
  883 postgres  20   0  157m 1072  476 S  0.0  0.0   0:00.14 postgres: logger process                                                   
  884 postgres  20   0 2338m 2.0g 2.0g S  0.0  8.6   5:16.35 postgres: startup process   recovering 0000000300002AA50000003F            
  889 postgres  20   0 2338m 2.0g 2.0g S  0.0  8.6   0:35.69 postgres: checkpointer process                                             
  890 postgres  20   0 2338m 2.0g 2.0g S  0.0  8.6   0:34.98 postgres: writer process                                                   
  905 postgres  20   0  159m 1212  456 S  0.0  0.0   0:02.62 postgres: stats collector process                                          
 1922 postgres  20   0  105m 1632 1180 S  0.0  0.0   0:00.01 -bash                                                                      
 1959 postgres  20   0  137m 1764 1292 S  0.0  0.0   0:00.00 psql                                                                       
 1960 postgres  20   0 2340m 6780 4684 S  0.0  0.0   0:00.01 postgres: postgres postgres [local] idle                                   
 4309 postgres  20   0 2346m 7080 1748 S  0.0  0.0   0:00.67 postgres: wal receiver process   streaming 2AA5/3F0429C0     
```      
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")