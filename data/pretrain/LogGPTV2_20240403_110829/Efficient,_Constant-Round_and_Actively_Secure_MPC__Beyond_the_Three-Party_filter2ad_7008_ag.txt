[Sha49]
[Woo07]
[Yao82]
[ZSB13]
Claude E Shannon. Communication theory of secrecy systems. Bell Labs Technical Journal,
28(4):656–715, 1949.
David P. Woodruﬀ. Revisiting the eﬃciency of malicious two-party computation. In Advances
in Cryptology - EUROCRYPT 2007, 26th Annual International Conference on the Theory and
Applications of Cryptographic Techniques, Barcelona, Spain, May 20-24, 2007, Proceedings,
volume 4515 of Lecture Notes in Computer Science, pages 79–96. Springer, 2007.
Andrew Chi-Chih Yao. Protocols for secure computations (extended abstract). In FOCS, pages
160–164. IEEE, 1982.
Yihua Zhang, Aaron Steele, and Marina Blanton. Picco: a general-purpose compiler for private
distributed computation. In Proceedings of the 2013 ACM SIGSAC conference on Computer
& communications security, pages 813–826. ACM, 2013.
27
A Preliminaries (cont’d)
In this section we present complementary preliminary material, including the deﬁnition of the
cryptographic building blocks.
Deﬁnition 5. A pseudo-random function (PRF) family PRF is a family of functions PRF :
K × D → R. The setup algorithm produces (on input 1κ) a key k at random from K. Let
PRFk(·) be the function parameterized by k. The security property requires that when k is chosen
at random from K, no PPT adversary A can distinguish between PRFk(·) and a random function
(with appropriate domain and range), when given oracle access to one of the functions.
Deﬁnition 6. A collision-resistant hash function (CRHF) family H is a family of functions H :
K × D → R, where |D| < |R|. The setup algorithm produces (on input 1κ) a key k at random
from K. Let Hk(·) be the function parameterized by k. The security property requires that when k
is chosen at random from K, no PPT adversary A, given H and k, can produce x0 and x1 (with
x0 (cid:54)= x1) such that Hk(x0) = Hk(x1), except with negligible probability in κ.
Deﬁnition 7. A (non-interactive) commitment scheme (for a message space M) is a triple of
algorithms (ComGen, Com, Open) such that:
CK ← ComGen(1κ), where CK is the public commitment key;
for m ∈ M, (c, d) ← Com(m) is the commitment/decommitment pair for m. (We omit men-
tioning the public key CK when it is clear from the context.) When we wish to make explicit
the randomness used by Com(·), we write Com(m; r);
˜m ← Open(c, d), where ˜m ∈ M ∪ {⊥}, and where ⊥ is returned if c is not a valid commitment
to any message;
satisfying the following properties:
Correctness: For any m ∈ M, Open(Com(m)) = m.
Hiding: For all m0, m1 ∈ M output by any PPT adversary A, the distributions c0 and c1
are indistinguishable to A, where (cb, db) ← Com(mb) for b ∈ {0, 1}, except with negligible
probability.
Binding: No PPT adversary A can produce (c, d0, d1, m0, m1) (with m0 (cid:54)= m1) such that
Open(c, db) → mb for b ∈ {0, 1}, except with negligible probability.
Oblivious Transfer. While our protocol does not make use of the oblivious transfer primitive,
we present the primitive below for completeness (as the protocol of [BLO16b], which we modify,
does). The oblivious transfer (OT) functionality is described in Figure 8; for a description of a
protocol implementing the functionality, we refer the reader to [BLO16b].
B Proofs
Lemma 3.1 Assuming (ComGen, Com, Open) is a secure commitment scheme, protocol Π4AOT se-
curely realizes the F4AOT functionality.
Proof. (Sketch) We shall prove this considering various corruption scenarios and providing simulator
strategies for each. For any adversary A corrupting parties, we describe a simulator S interacting
with the ideal functionality F4AOT. We ﬁrst consider the case when only one party is corrupted.
P1 is the sender and P2 is the receiver.
28
Functionality FOT(P1, P2)
FOT interacts with parties P1 and P2 and the adversary S, with P1 and P2 acting as sender and receiver,
respectively.
Input.
On input message (Sender, sid , m0, m1) from P1, where each mβ ∈ M, record (m0, m1) and send
(Sender, sid ) to the adversary. Ignore further (Sender,·,·,·) messages.
On input message (Receiver, sid , b) from P2, where b ∈ {0, 1}, record b and send (Receiver, sid )
to the adversary. Ignore further (Receiver,·,·) inputs.
Output. On input message (Output, sid ) from the adversary, send (Output, sid , success, mb) to P2.
Figure 8: The Oblivious Transfer ideal functionality FOT.
0, m3
1, r4
0, r4
0, Com1
0, m3
1, r3
0, r3
0, m3
1, r3
0, r3
0, m4
1, r4
1, b3, r3
0, r3
0, Com1
1, Open1
m1
b2
1) intended for P3 and P4.
It receives two tuples from A,
P1 is corrupted: P2, P3 and P4 are honest. S runs A.
If the tuples are not equal, S
0, r4
(m3
1) and (m4
sends ⊥ to the functionality, and simulates the honest parties aborting. If the tuples are the
1 intended for P2. S veriﬁes that the commitments are correctly
same, A will send (Com1
generated using the tuple it obtained earlier. If not, it sends an Abort message to the func-
tionality; else, it submits (m3
1) as P1’s input to the functionality. This completes
the simulator’s description.
1) (cid:54)=
(m4
1), then P3 and P4 will detect this and induce an abort in Step 3b of the pro-
tocol. This abort is independent of P2’s input b and identically distributed to S’s abort. If
P3 and P4 receive two sets of values that are equal, then P3 and P4 will generate and send
(Com1
1, when P3 and P4 are honest). If
Note that in the real execution, if P3 and P4 receive two sets of values (m3
0, m4
1 = m4
1
P1 sends a diﬀerent set of commitments (Com
1) in Step 1 of the protocol, then P2 will
detect this and abort. Once again, this abort is independent of b and identically distributed to
S’s abort. Now, suppose (Com
0 and m1
1
by P1, P3 and P4 are identical), then P2 indeed receives the opening to Com1
b from P3 and P4
and hence outputs mb.
P2 is corrupted: In this case, P1, P3 and P4 are honest. S runs A. It receives two bits from
the adversary, b3, b4, intended for P3 and P4. If the two values are diﬀerent, S sends Abort to
the functionality and simulates the honest parties aborting. If the two bits are the same, it
submits b3 as P2’s input to the ideal functionality and receives m3
b3 from the functionality. It
then generates two commitments/openings (Com1
b3, and another
to a dummy value, say, 0 (permuted based on the bit b3), and sends the two commitments to
A on behalf of honest P1. It then sends decommitment for m3
b3 on behalf of honest P3. This
completes the simulation.
1) (i.e., the commitments to m1
1), one committing to m3
) to P2 (as m3
1
1) = (Com3
0 and m3
0 = m4
1
0, Com
1
0, Com
0, Com3
0, Com1
In the real execution, P2 will receive commitments (Com1
1) as well as the decommit-
b2 in Step 3a. By the hiding property of the commitment scheme, P2 will learn no
¯b2 and it can be replaced by a commitment to 0, making the real and
0, Com1
ment Open1
information about m1
simulated views indistinguishable.
P3 is corrupted: since P1, P2 are honest, S receives (m3
generates fresh randomness r3
1, r3
0, m3
of P2 to the adversary.
1 and sends (m3
0, r3
1, b3) from the functionality. It then
1) on behalf of P1 and b3 on behalf
If A sends a diﬀerent tuple intended for honest P4, S sends Abort
0, m3
0, r3
29
In the real execution, if P3 cheats by sending a diﬀerent set of (m3
to the functionality and simulates the honest P4 aborting. Else, it receives two commitments
and a decommitment from A intended for P2. If the commitments and/or decommitment are
not consistent with the tuples it sent to A earlier, S sends Abort to the functionality. This
completes the simulation.
1) values in
Step 3b, then P4 will send a ⊥ message to P2, which is what our simulator does as well. If P3
cheats by sending a diﬀerent set of commitments to P2 in Step 3a, then again P2 will detect this
as honest P4 (and P1) send honest versions of these commitments. If P3 cheats by sending a
diﬀerent opening of the commitment Com3
b3, then by the binding property of the commitment
scheme, P3 can indeed only open Com3
b2 (or
abort) which is identical to S’s behavior.
P4 is corrupted: This case is similar to when P3 is corrupted.
b2 and hence P2 will output m1
b3 = Com1
b2 to m1
1, b3, r3
0, m3
0, r3
Next, let us consider the case when two parties are corrupted: Note that our functionality in
this case does not require privacy of inputs since corrupted attesters will learn both parties’ inputs.
It only guarantees that an honest P2 will always output the right mb (or abort); hence, the only
interesting cases are when P2 is honest, i.e., P1 and P3 are corrupted, or P3 and P4 are corrupted
(other cases are symmetric).
0, r3
0, m4
1, r4
0, r4
0, m4
0, m3
0, Com1
It receives a tuple from A,
P1 and P3 are corrupted: P2 and P4 are honest. S runs A.
1, b3, r3
1) intended from P1 to P4 and another tuple (m3
(m4
1) intended from P3
to P4. If the tuples do not hold the same values, S sends Abort to the functionality. , simulating
the honest P4 aborting. If the tuples are the same, A will send (Com1
1 intended for P2.
S veriﬁes that the commitments are correctly generated using the tuple it obtained earlier. If
not, it sends Abort to the functionality, inducing P2’s abort. Else, it submits (m4
0, r4
1)
as P1’s input to the functionality. This completes the simulator’s description.
Consider the real execution. Recall that P4 is honest in this case. If P3 sends a diﬀerent
set of values in Step 3b, then P4 will send a ⊥ message, and P2 will abort the protocol. Now, if
i
P1 or P3 send maliciously generated messages (Com
1) (for i = 1, 3, in Step 1 or Step 3a,
respectively), then P2 will detect this and output ⊥ when P4 sends the correct (Com4
0, Com4
1)
to P1 in Step 3a. Similarly, if P3 sends a maliciously generated message ( ¯m3
b3, ¯rb3) (in Step
3a), then, by the binding property of the commitment scheme, ¯m3
b2. Hence, P2 always
outputs m1
It is easy to see that the aborts are identically distributed to the
simulation.
P3 and P4 are corrupted: In this case, P1 and P2 are honest and the simulation is very similar
to the case above where P3 was corrupted with the only diﬀerence that S does not simulate an
honest P4 aborting since P4 is not honest in this case.
b2 or aborts.
b3 = m1
i
0, Com
1, b4, r4
Theorem 4.1 Assuming (ComGen, Com, Open) is a secure commitment scheme, and H $← H is
a collision-resistant hash function, protocol Π5pc(C,{P1, . . . , P5}) securely realizes the functionality
sfe({P1, . . . , P5})5 in the F4AOT-hybrid model.
F C
Proof. (Sketch) To prove our 5PC protocol Π5pc(C,{P1, . . . , P5}) secure, for any adversary A in the
protocol, we describe a simulator S that interacts with the ideal functionality F C
sfe({P1, . . . , P5}).
There are two main corruption scenarios to consider: (i) When two garblers are corrupted. In this
case, without loss of generality we assume P1 and P2 are corrupted since the protocol is symmetric
5Recall that we slightly abuse notation, and mean security with abort.
30
with respect to the garblers; and (ii) when the evaluator P5 and one of the garblers is corrupted.
Similary, wlog, we assume P1 and P5 are corrupted.
P1 and P2 are corrupted. At a high level, in this case the evaluator is honest, and hence the
only guarantee we need from the distributed circuit garbling is to generate a correct garbled circuit.
We also require that the garblers’ inputs are extractable from the garbled input generation process.
These two properties combined will guarantee that we can describe a simulator that simulates any
adversary corrupting P1 and P2. More details follow.
S runs A. S receives two copies of each seed s1, s2 intended for honest parties P3 and P4 from
A. S checks whether the two copies are the same or not. If not, it sends an abort message to the
functionality. Else S generates random seeds s3 and s4 on behalf of honest P3 and P4 and sends
them to the adversary. It then generates random inputs x3, x4, x5 for P3, P4, P5 and uses them in
the rest of the simulation.
During the garbled input generation S behaves as honest P3, P4, P5 in most cases and using the
random inputs and seeds it generated above, and sends an abort to the functionality if it detects any
cheating, or if the adversary opens the commitments generated for P5’s garbled input generation to
a diﬀerent value than expected (this is indistinguishable from the real-world interaction due to the
binding property of the commitment). The aborts are independent of the honest parties’ inputs as
the inputs are always XORed with three uniformly random pads one of which is held by an honest
party. If there is no abort, for each input wire of P1, A sends Fs1(‘key’||w||0) ⊕ Fs1(‘delta’) · b(cid:48)
intended for P5. Given that S has knowledge of all seeds, it can use it to derive b(cid:48) and further
derive P1’s input b = b(cid:48) ⊕ pw. A similar strategy can be used to extract P2’s input. Denote these
inputs by x(cid:48)
In the distributed garbling stage, S behaves as honest P3 and P4 and instructs the functionality
to abort if it detects any cheating, i.e., if messages intended for P3 and P4 are not consistent. If
there is no abort, it is easy to see that the garbling function described in Figure 3 will be the output
of honest parties. If the garbled circuit sent by A intended for P5 (or its hash) is not the same as
what the honest parties would have obtained, S sends abort to the functionality.
1, x(cid:48)
2.
2 to the functionality. From the correctness of the garbling function, if there
are no aborts, the garbled circuit evaluated by P5 in the real protocol would evaluate to the same