faultlocalization,canconsumesignificantoperatorresourcesinacomplexsystem
environment. In cloud based distributed micro-services applications, localizing
(cid:2)c SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.137–149,2021.
https://doi.org/10.1007/978-3-030-76352-7_17
138 P. Aggarwal et al.
faultisachallengingtaskduetothefollowingreasons:a)heterogeneityofinfras-
tructure components, b) difficulty to trace the execution paths, c) overhead of
instrumentation,andd)lackofasynchronizedclockacrossadistributedsystem
to interpret the dependency among the components. Therefore, localizing faults
in cloud-based distributed applications using artificial intelligence is an active
area of research.
There are three types of approaches present in the literature for fault local-
ization in distributed systems: trace-based, metric-based and log-based. Trace
andmetricbasedapproachesrequireinstrumentationofcodeandmetricsrespec-
tively, thus adding extra overhead and may not always be feasible to do. On the
other hand, logs are easily available with any distributed system making log-
based approaches more practical to use as compared to trace and metric based
approaches.
Using causal inference techniques for trace and metric based approaches has
been thoroughly explored [11,15,18]. Jia et al. have used causal inference tech-
niques for log-based approaches [9], but they make the assumption that the
abnormal or the failed service is known and that the time order of the log tem-
plates within a service is maintained. However, this is not always true, making
it difficult for the approaches to generalize well. The above cited state-of-the
art approaches also don’t take into account the causality relationships across
templates of multiple services in the system.
Weaddressthelimitationsofexistinglogbasedapproachesbytakingaholis-
ticviewofcausalityminingamongthemicro-serviceslevelaswellasthetemplate
level across micro-services, capturing the fine-grained causality of the various
components involved. Also, our fault-localization approach does not assume an
abnormal or failed service. We use Golden Signal errors also known as gateway
errors [4] that the users face or observe when a system fails. These errors are
very critical and have to be handled in real time. The faults are characterized
by the PIE model [23] which states that the fault should be executed, the error
state/fault then infects the system and the errors are propagated to the output
state. We term these faults as observable operational faults. Our approach does
not depend on the time order of log templates like [9] within a micro-service to
localize the fault at the template level, since we build causality at the template
level and then use PageRank-based centrality metrics to find the most impor-
tant log template responsible for the fault. Unlike previous approaches [12,13],
we do not need data spanning days or weeks to compute causality. Our work in
this paper uses very less runtime data (in the order of minutes) to infer causal
relationships.
1.1 Main Contributions
In this paper, we propose a transactional error log based fault localization tech-
nique which has the following key characteristics:
1. Multi-variate Time Series Modeling of Logs: We transform the logs to
multivariatetimeseriesdatabycountingthenumberoferrorlogsineachtime
Localization of Operational Faults in Cloud Applications 139
bin for the impacted services. This transformation from log space to metric
space helps us in running causal dependency models directly on log data.
2. Causal dependency model which is mined from golden signals viz. error
logsinapplicationandgatewayatthelogtemplatelevel.Unlikestate-of-the-
art approaches which need weeks of training data our system can compute
causal relationship among anomalous micro-services from only a few minutes
of logs.
3. Personalized PageRankalgorithmthatusestheextractedanomaloussub-
graph from the dependency and causal graphs and the golden signal errors
to provide a ranked order of faulty nodes.
We experiment with two Granger causal based techniques: Regression and Con-
ditional Independence [7,22]. The experiments are run on a simulated micro-
service system, the TrainTicket application that contains 41 micro-services [2].
Our empirical results demonstrate the accuracy of our proposed approach in
identifying and localizing operational faults.
The rest of the paper is organized as follows. We provide a brief summary
of related works in Sect.2. Section3 describes the proposed fault localization
systemindetail.Section4givesanoverviewofthedatasetgenerationtechnique.
In Sect.5, we present our experimental results and highlight the key takeaways
fromourexperiments.Finally,weconcludeinSect.6withsomefuturedirections
of our work.
2 Related Work
Inrecentyears,differentsolutionshavebeenproposedforfaultlocalizationindis-
tributedsystems,networks,cloudsandmicro-services.Thoseproposedsolutions
typically fall into three categories, i.e. trace-based, metric-based and log-based
approaches [26].
Trace-basedapproachesneedtogatherinformationthroughcompletetracing
of the execution path, and then detect the potential faults through the outlier
analysis along the execution path [5,16,18]. These methods are able to identify
the root causes of the underlying problems with high accuracy, but they require
significant domain knowledge. These approaches also require system code logic
which might not be available.
Metric-based methods collect the metrics from both application and infras-
tructure components and construct the causality graph among components to
infertherootcausesoffaults[11,14,15,24,26].Theseapproachesoftentreatthe
applications as a black box and only collect the system metrics related to the
applications such as CPU utilization, memory usage, etc. The challenging task
in these methods is in how to build the accurate causality graph using the huge
amount of collected metrics data.
Log-based approaches [8,9,21,25,27] parse the system logs first, and then
identifythefaultycomponentsbasedonparsedlogs.Thoughlog-basedmethods
arecapableofidentifyinginformationalcauses,thedifficultiesinlogparsingand
140 P. Aggarwal et al.
abnormal information locating from large scale of logs pose great challenges in
practice. The log-based approaches can further classified in three categories, a)
machinelearningbasedapproach[27],b)domaindependent[21,25]andb)causal
inferencebasedapproach[9].Jiaetal.[9]presentafaultlocalizationsystemusing
causalinferencetechniquestobuildadependencygraphamongtheservicesfirst
and then within a service at log template level. Using causal inference on logs
from a distributed system is still in its infancy. The existing approaches suffer
from lack of benchmark data, assumptions such as failed or abnormal service
is given as well as ignoring the causality across the log templates of multiple
micro-services. We address these limitations in the proposed approach.
3 Central Idea
Our proposed fault localization technique using golden signals addresses the
problem of localizing the faults that are characterized by the PIE model [23].
There are four types of golden signals viz.Latency, Error, Traffic, and Satu-
ration [4]. These signals can help monitor the health of systems by identifying
faultsandtriagingofissues.Inthispaper,wefocusononetypeofgoldensignal
viz. Error to localize faults.
Figure1 illustrates the predictive and reactive modes of our approach. In
the predictive mode, the logs are analyzed in real time. Our fault localization
technique is triggered when the number of golden signal errors reach above a
threshold value in a given time window, indicating that there is a fault in the
system which is repeatable. To localize the fault, causal relationships among
the micro-services, emitting error signals, and the service emitting golden signal
errors are inferred after modeling the logs as multivariate time series data (time
series modeling).Weidentifytheserviceswhicharecausinggoldensignalerrors
and extract a subgraph of those services from the dependency graph.
Generally, the faulty node has high causality score with golden signal errors.
However, it is highly possible that nodes that have no relation with the golden
signal errors can also have high causal scores. To avoid such false positives, we
exploregraphcentralityindices(e.g.,PageRank)tofindthemicro-servicewhich
best characterizes the golden signal errors. The node with the highest centrality
scores is likely the faulty service. It is possible that the nature of fault is such
thattheactualfaultynodedoesnotemitanyerrorsignals.Insuchscenarios,we
analysetheerrormessagesemittedbyanodeinordertodetectfaultyservice.We
refer to this technique as Last Mile Fault Localization. We propose 3 variants of
ourapproach:(1)Allthenodescausinggoldensignalerrorareconsideredfaulty,
(2)WerunPersonalizedPageRankonthestatic/dependencygraph,and(3)We
run Personalized PageRank on causal graph.
During the reactive mode, the fault localization model is triggered whenever
the system raises an alert/alarm. In this scenario, we extract fault timing by
parsingthealertmessagesandretrievethecorrespondinglogsfromlogdatabase.
Subsequent process is same as described in the predictive mode.
Localization of Operational Faults in Cloud Applications 141
Fig.1.(Left:)Architectureofproposedfaultlocalizationapproach.(Upper Right:)
Graph showing direction of cause and depends-on relationship. (Lower Right) Time
series data - Each bar corresponds to an error signal, each color represents a micro-
service, and the height indicates the frequency of the error
Fig.2. A sample fault localization flow using causal inference and PageRank.
3.1 Fault Localization
Figure2 shows the flow of our fault localization approach. We start with the
dependency graph where nodes in the graph represent various services and the
edges indicate the requests flow direction (Fig.2a). Dependency graphs can be
inferredfromarchitecturediagrams,orcanbediscoveredfromlogs[9].Wefocus
on a subgraph extracted from the dependency graph consisting of only those
nodes which emit error signals (Fig.2b). Next, we use two Granger causality
techniques: regression based and independence testing based to infer the causal
relationship among micro-services. Causal dependencies indicate the strength of
the correlation between the errors in various micro-services. We run PageRank
based centrality index to find the faulty node (Fig.2d) among the nodes which
havecausalrelationshipwiththenodeemittinggoldensignalerrors(Fig.2c).In
the following subsections, we will describe each sub-component of our approach
in detail.
MultivariateTimeSeriesModeling.Wemodelthelogsasmultivariatetime
series data. We count the number of error logs in each time bin to obtain a time
series corresponding to each impacted micro-service for a given time window.
The resulting data representation can be viewed as a multidimensional array
142 P. Aggarwal et al.
M ∈Rn×t, where n is number of micro-services emitting error logs and t is the
number of time steps. It is possible that for some time bins, none of the micro-
services emit error logs. In such cases, we do zero padding to keep the interval
between consecutive time bins constant as shown in Fig.1.
To pinpoint the exact errorwithin the faulty service, we also model the time
series at the level of log error templates. A log template is an abstraction of
a print statement in the source code, which manifests itself in raw logs with
different pa(cid:2)rameter values in different runs [17]. It is represented as T ∈ Re×t,
n
where e = i=1xi, and xi is the number of error templates emitted by micro-
serviceni.Eachcolumnofarray,T,representsthenumberofoccurrencesofthe
error template for a particular time bin.
Causal Inference. We infer causal relationships among the error signals emit-
tedbyindividualmicro-servicesandthegoldensignalerrors,aftermodelingthe
log data as multiple time series. We assume that the anomalous behavior of a
faulty component is likely to result in error signals being emitted by neighbor-
ing components (micro-services), which are components that interact with the
faultycomponenteitherdirectlyorindirectly.Differentfromassociationandcor-
relation, causality is used to represent a direct “cause-effect” relation. Figure1
shows a sample graph where the nodes correspond to micro-services and edges
represent the cause and depends on relationship. The direction of causality is
reverse of the direction of dependency.
Mining temporal dependency structure among multiple time series has been
extensivelystudied.AsmentionedinSect.2,theGrangercausalityframework[7]
is used to infer the causal dependencies among time series data. In this paper,
weusetwotypesofGrangercausalitytechniques:(1)RegressionBasedand,(2)
Conditional Independence Testing. One of the classic approaches for a Granger
causal test is to linearly regress Bt on At−1:t−p,Bt−1:t−p for some lag p and
comparetheresiduewiththatofregressionofBt onBt−1:t−p alone[6],whereA
andB aretwotime-series.Inthispaper,werefertothisapproachasBlinear.In
ordertotrackthecausaldependenciesamongtimeseriesinstantly,[28]developed
a novel Bayesian Lasso-Granger method, BLasso, which conducts the causal
inference from the Bayesian perspective [19] in a sequential online mode. We
use BLinear and BLassoregression based methods to infer the causality graph
of micro-services. For conditional independence based causal inference, we use
the PC−Algorithm [10,20]. The algorithm starts from a complete, undirected
graph and deletes recursively the edges based on conditional independence deci-
sions.Weleverageacrossentropybasedmetric,namelyG2,totestwhethertwo
services are dependent on one another or not. The micro-services which cause
golden signal errors are identified as potential source of fault.
Personalized PageRank Algorithm. As described above, the nodes which
causegoldensignalerrorsareusefulforfindingtheactualrootcauseofthefault.
However, it is highly possible that nodes that have no relation with the golden
signalerrorscanhavehighcausalscores.Toavoidsuchfalsepositives,thenodes
(micro-services) causing golden signal errors are considered as candidate nodes.
Localization of Operational Faults in Cloud Applications 143
We experiment with both dependency and causal graphs and use the extracted
anomaloussub-graph(nodeshavingcausalscoreswithgoldensignalandtheircon-
nections) to rank the nodes using the Personalized PageRank method proposed
in[11].Weassignhigherweightstothenodeswhichcausegoldensignalerror.
TheinputstothePageRankalgorithmarethegraphs(causalanddependency),
thegoldensignalerrorsandthecausalscoreofeachnodewiththegoldensignal
errors. Let CSi define the causal score of node i with respect to the golden sig-
nalerrors.Wederivetheanomaloussub-graphfrombothdependencyandcausal
graphsbypreservingthenodesthatcausegoldensignalerrors(candidatenodes)
andtheirdirectconnections.Consideringthattherequestflowisfromnodeito
nodej,theweightofeachedgeeij isassignedtothevalueofCSj,theweightof
each added self-edge eii is assigned to the value of CSi, and the weight of each
added backward edge eji is assigned to the value of ρCSi, where ρ ∈ [0,1]. We
setρtoahighvalueifthecausalgraphrepresentsthetruedependencygraph.As
errorpropagationhappensintheoppositedirectionofrequestflow,wereversethe
directionoftheedgeswhenapplyingthePageRankalgorithm.
Fig.3. Last mile fault localization on TrainTicket system.
Last Mile Fault Localization. The output from the previous step namely,
Personalized PageRank, provides a ranked list of potential nodes (or micro-
services) which are faulty. However, this information is not sufficient to identify
the precise location of the fault. To get the precise location, we use the Last
Mile Fault Localization technique which examines the service emitting the error
as well as it’s neighbourhood to identify the correct fault location.
Let us assume that the nodes localized by PageRank are given by:
Lp =[Si], where i∈{1..n} (1)
For last mile fault localization, we inspect the following set of nodes:
Lm =[Si,Ti1,...,Tij,...Ti k], where i∈{1..n} and j ∈{1...k} (2)
Herein, {Ti1,...,Tik} are nodes which are one hop away from Si returned by
Page Rank. To detect the correct fault location, we use the application topol-
ogyobtainedusingexecutionbehaviourmodel[17]alongwithtraceinformation
144 P. Aggarwal et al.
obtained using discriminating parameters [3]. The last mile localization tech-
nique is illustrated in Fig.3 which shows the service call flow mined from exe-
cution logs. For this instance, PageRank returns the faulty service as ts-inside-
payment-service which has three directly connected edges. As such we inspect
thenodes[ts-inside-payment-service, ts-order-service, ts-inside-payment-mongo,
ts-payment-service]. With the use of discriminating parameter values in the call
flow viz. 5a590c1c-7428-408d-8da5-9ff0806df47e) and paymentservice/payment
we are able to correctly localize the fault to ts-payment-service as shown in the
figure.
4 Dataset Details
We use the TrainTicket application [2], an open-source micro-service applica-
tion, to inject faults and generate log data to evaluate the effectiveness of our
proposed approach. The application contains 41 micro-services. Service ts-ui-
dashboard acts as thegateway servicewhich records the status of each incoming
and outgoing service. The error signals emitted by this service and capturing
the failure of a request are considered as golden signals. We use Istio [1] to
inject HTTP abort fault in multiple services. In abort fault, incoming request