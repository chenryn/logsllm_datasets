print statement have the same HashCode. Based on this
observation, the Prepossessing Agent is generating a hash code
for all raw log messages. Then it puts the raw log messages that
have the same hash code in the same group by using the Equals
Fig. 2. Example 1 of raw log message and key log message. method to find matches between them. After selecting all the
matching raw log messages, the Agent removes the duplicate
The difficulty here is in identifying the log keys because we results in each group, and it gets the log keys, while their
do not know which log messages are printed by the same number is limited. Examples of log keys are shown in the third
statement print or the location of the parameters in the log block in Figure 5.
www.etasr.com Bin Lashram et al.: HCLPars: Α New Hierarchical Clustering Log Parsing Method
Engineering, Technology & Applied Science Research Vol. 13, No. 4, 2023, 11130-11138 11133
stores them as a list of sentences (line 1). The number of
WS in each log key (sentence) is calculated, and the results
are added into the LengthLogKeys list (lines 6-13). Then it
finds the smallest common number of WS from
LengthLogKeys list (line 14). For example, the third Block
in Figure 5 contains 5 log messages from the HDFS
dataset. These 5 log keys contain a different number of WS
(6, 3, 4), whereas the smallest common number of WS is 3.
The last step is generating a regular expression, where it
replaces the number of WS from the previous step with the
symbol ("\s"), for example, if the smallest common number
of WS is 3, then the regular expression will be: ([ˆ\s] +\s)
([ˆ\s] +\s) ([ˆ\s] +. *). Finally, the regular expression is
returned (line 16).
2. The second step is to use a regular expression from step 1
to separate all the log keys in groups. In this step, every log
key is transformed from sentence to columns, to find the
common parts between the log keys in all groups. The
fourth block of Figure 5 provides some examples of
separated log keys.
Algorithm 1: pseudo code for generating a
regular expression
Input: a list of log keys from step B
(LogkeysL)
Output: regular expression for common
space between all log keys
1: ListLogKeys  LogkeysL
2: LengthLogKeys  => List() (initialize
with empty list)
3: RegEx  NULL => (initialize with empty
string)
4: SmallestL  NULL => (initialize with
empty integer)
5: LLog  NULL => (initialize with empty
integer)
6: CurLog  First log in ListLogKeys
7: while (Curlog has white-space) = true
Fig. 5. Step of extracting log keys. do
8: LLog  compute a white-space in CurLog
C. Merge Groups by Log Key
9: add LLog to LengthLogKeys
Each log key contains the component (server), log event, 10: remove CurLog from ListLogKeys
and message and most groups contain log keys that share the 11: CurLog  next log in ListLogKeys
same component and log event but differ in the message. For
12: until ListLogKeys is empty
example, Figure 4 contains 4 log messages from the HDFS
13: End while
dataset. The four log keys that contain the same component are
14: SmallestL  find smallest length in
dfs.DataNode$DataXceiver, and the same log event is
LengthLogKeys
writeBlock, but differ in the message. To improve parsing
15: RegEx generation of regular
accuracy, the Prepossessing Agent clusters similar groups
expression
based on the component and their log events, through several
16: return RegEx
steps.
1. The first step is to generate a regular expression that will 3. In the final step, the Prepossessing Agent uses hierarchical
be used to separate the log by using the whitespaces (WS) clustering [22-25] to cluster similar groups based on
shared between all log keys in all groups as separators. components and their log events. The groups in the same
Algorithm 1 provides the pseudo-code of Generating cluster will be merged. This step assumes that if logs from
regular expressions. The Prepossessing Agent considers different groups have the same component and log event
every log key from the previous step as a sentence and type, then the texts of the component and the log events
www.etasr.com Bin Lashram et al.: HCLPars: Α New Hierarchical Clustering Log Parsing Method
Engineering, Technology & Applied Science Research Vol. 13, No. 4, 2023, 11130-11138 11134
that generated from these groups will be similar, so the the is responsible for allocating Spark tasks to workers in the Spark
Hamming distance [25] is calculated between the texts cluster [27]. For the Spark application, in Step 1, the
(component and log event) of two logs to assess the Prepossessing Agent uses sqlContext.read.text() to read the text
similarity between them. file (e.g. HDFS execution traces), converts every message or
line into a single row at a single string column called value
0 (cid:2)(cid:13) (cid:7)(cid:11)(cid:9) (1) (DF), and loads the DF to the Spark cluster (arrow 1). Then, it
(cid:1)(cid:2)(cid:3)(cid:4) (cid:6)(cid:7),(cid:9)(cid:10)(cid:11)(cid:1)(cid:12)(cid:13)(cid:14)
(cid:5) 1 (cid:18)(cid:4)ℎ(cid:12)(cid:20)(cid:21)(cid:2)(cid:3)(cid:12) uses withColumn() to preprocess all log messages (erasing
where a is the value of the component in the first log and b is parameters) (arrow 2). After preprocessing, it caches the
the value of the component in the other log. If a and b are preprocessed log messages as schema in off-heap memory and
equal, it returns 0, otherwise 1. For example, we have 3 returns a DF as the reference (arrow 3). In step 2, it uses
components, the first is "dfs.DataNode$DataXceiver:", the distinct() to drop duplicate rows (in the column) from the DF
second is "dfs.FSDataset:", and the third is (arrow 4) and return them (arrow 5). In step 3, it generates
"dfs.DataNode$DataXceiver:". We calculated the Hamming regular expressions for all log messages (arrows 6, 7) as
distance between these and found that the first and the third are described above. Then, the driver program separates the
classified in the same group because they are exactly equal in column (value) into many columns based on the regular
value. We used the Hamming distance because it is a very expression from the previous step and adds them into new DF
practical metric for measuring the similarity and difference (arrows 8, 9). When all the columns are separated, it runs
between data strings. Besides, the Hamming distance is hierarchical clustering on them, and then it uses groupby() to
intuitive, which makes parameter adjusting easier. After the merge log message (row) based on the clustering result (arrow
above steps, we obtained the log key set (shown in the fifth 10). Finally, the merged DF (log keys) are outputted as a CSV
block in Figure 5) from the training log messages in the file by use coalesce(1).write() (arrow 11).
training log files. The first part refers to the event (E1) and the
second part refers to the message (1). With this step, we were
able to know each component of the system, what events are
issued by it, and what message types are issued for each event.
So, this step provides the administrators with an overview of
the system and what messages are issued from it.
IV. IMPLEMENTATION
The Prepossessing Agent uses Spark to make a large-scale
analysis of records efficient [22, 26]. Spark is a platform for
quickly processing data on a large scale and can also distribute
data processing tasks across multiple computers, either alone or
in conjunction with other distributed computing tools. Apache
Spark offers three data abstractions: RDD, DF, and DS. In
HCLPars, we use the DF API for several reasons: First, the DF
resolves performance and measurement limitations that occur Fig. 6. Extracting log key steps.
while using the RDD. Second, it uses input optimization
engines, for exemplify, Catalyst optimizer, to process data V. DATA COLLECTION AND EVALUATION
efficiently. We can use the same engine for all Java, Python, R,
In this section, we present the data sets that were used in the
and Scala DataFrame API. Third, it provides a schematic view
evaluation process and the evaluation methodology. The
of the data, meaning that the data has some meaning when it is
performance of HCLPars is evaluated in terms of its accuracy,
stored, and this serves to provide a simplified view of the data
efficiency, and effectiveness and the results are compared with
for the administrators. Fourthly, DF optimally manages
those of existing log parsers.
memory, it stores data outside the heap but still inside RAM
(outside the main Java Heap), which in turn reduces garbage A. Data Collection
collection overload, while RDD stores data in memory (inside
The loghub dataset [6] were used during the training and
the main Java Heap). Lastly, it is characterized by flexibility
test phases. Loghub is a large collection of logs from 16 real-
and scalability. It supports various formats of data and can be
world systems, including operating systems, mobile phone
combined with many other big data tools.
systems, distributed systems, supercomputers, standalone
In our case, a DF can represent execution traces, where software, and server applications. All these logs are over 77 GB
each message in execution traces is a row. Each step of the in size and contain 440 million log messages. Table II provides
HCLPars requires specific tasks that are executed on every a summary of the dataset. The columns are marked with the
message. To speed up these tasks and execute them with high symbol (#), as in [29].
accuracy, we invoke Spark DF specially designed operations to
B. Evaluation
work in parallel. Figure 6 illustrates the implementation of the
The parameters of the log parsers are fine-tuned through
Prepossessing Agent on Spark. The numbered arrows represent
over 8 runs and the best results are reported to avoid the
the interactions between the Spark cluster and the main
randomization bias.
program, where the main program works at Spark driver, which
www.etasr.com Bin Lashram et al.: HCLPars: Α New Hierarchical Clustering Log Parsing Method
Engineering, Technology & Applied Science Research Vol. 13, No. 4, 2023, 11130-11138 11135
1) Evaluation Measures dataset. For ease of observation, we marked the accuracy
values greater than 0.9 in boldface, and highlighted the best
Accuracy, robustness, and efficiency were considered for
accuracy with an asterisk (*). We can observe that most of the
the evaluation of the results [29].
datasets were parsed accurately (more than 90%) by at least 2
 Accuracy is a measure of the ability of a log parser to log parsers. Totally, 12 out of the 15 log parsers provide the
distinguish between fixed and variable parts. Therefore, we best accuracy on at least 3 log datasets. To measure the overall
define the accuracy metric of parsing as the ratio of effectiveness of the log parsers, we calculated the average
properly parsed log messages to the total number of log accuracy of each log parser across different datasets, as shown
messages. A log message is parsed correctly if its event in the last row of Table III. We can observe that HCLPars is the
template matches one of the previously extracted log most accurate on average with a score of 0.9605, achieving
message templates. high accuracy (over 0.9) in 12 out of 16 datasets. It was
followed by POP, which achieved high accuracy in 10 datasets.
 Robustness of a log parser is measured by the extent of its
ability to work continuously within different datasets or
different sizes with the same efficiency.
 Efficiency is measured by the amount of time it takes the
parser to parse the data. Τhe less time spent, the higher the
efficiency.
TABLE II. SUMMARY OF THE LOGHUB DATASET
Templates
Dataset # Description # Log size #
(total) #
HDFS Hadoop distributed file system log 11,175,629 30
Spark Spark job log 33,236,604 456
Hadoop Hadoop mapreduce job log 394,308 298
ZooKeeper ZooKeeper service log 74,380 95
OpenStack OpenStack software log 207,820 51
Linux Linux system log 25,567 488
Fig. 7. Accuracy distribution of the log parsers in different types of logs.
Mac Mac OS log 117,283 2,214
Thunderbird Thunderbird supercomputer log 211,212,192 4,040 B. Robustness
BGL Blue Gene/L supercomputer log 4,747,963 619 Robustness is an important measure of the practical use of a
HPC High performance cluster log 433,489 104 log parser. In this part, we evaluate the robustness of HCLPars
Apache Apache server error log 56,481 44 and compare it with the existing log parsers from 2 aspects:
across different types and sizes of logs.
OpenSSH OpenSSH server log 655,146 62
Proxifier Proxifier software log 21,329 9 Figure 7 (boxplot diagram) indicates the accuracy
Android Android framework log 30,348,042 76,923 distribution of each log parser across the 16 log datasets. For
Health app Health app log 253,395 220 each box, the highest point of the vertical line corresponds to
the maximum accuracy values, while the lowest point
corresponds to the minimum accuracy values. In Figure 7, from
2) Evaluation Procedure
left to right, the log parsers are arranged in ascending order of
To evaluate HCLPars, we compared it with 14 log parsers average accuracy. It can be noted that HCLPars has the highest
by using 16 standard datasets. The log parser parameters were average accuracy. This means that it can efficiently parse
finely tuned through more than 8 runs, and the best results were different types of log data, as its minimum accuracy is 0.889.
recorded. Additionally, we evaluated the robustness of HCLPars on
different log sizes. We sampled 40 original real-world datasets,