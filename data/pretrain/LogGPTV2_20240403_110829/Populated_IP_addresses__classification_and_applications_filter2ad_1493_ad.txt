### Figure 6: Classification Performance
- **(a)** PIPMiner performance as a function of data length.
- **(b)** Performance of the pure history-based approach, which predicts PIP labels using all available prior reputation score records.
- **(c)** PIPMiner performance as a function of the number of PIPs used for training.
- **(d)** PIPMiner performance as a function of the amount of malicious traffic.

**Metrics:**
- **Accuracy** = (True Negatives + True Positives) / Total
- **Precision** = True Positives / (True Positives + False Positives)
- **Recall** = True Positives / (True Positives + False Negatives)

### Exponential Weighting in Time Series
In this model, the weighting factors for each older data point decrease exponentially. As shown in Figure 6(b), the baseline approach, which uses all historical information, achieves only 82% accuracy with the best smoothing factor. Unlike our machine learning-based approach, the baseline cannot be applied to PIPs without labels. The machine learning approach learns good and bad behavior patterns from many other PIPs, thus not requiring long activity histories.

### Service Scale
PIPMiner is designed to analyze PIP behaviors. A key question is whether PIPMiner is useful only for very large service providers or can it also be deployed for small-scale online services with only a few PIPs? To answer this, we conducted an experiment by randomly removing part of the source IP addresses in the Hotmail trace. As shown in Figure 6(c), PIPMiner retains high classification accuracy with only a few hundred labeled samples, which is fewer than 0.2% of the labeled PIPs in the trace. This suggests that PIPMiner is effective across a wide range of business sizes.

### Robustness to Attacks
Adversaries will naturally attempt to evade detection. The simplest method would be to use anonymized networks like Tor. However, this is not very effective due to Tor's low throughput and public IP addresses, making it easy for service providers to monitor requests from Tor IPs. Instead, attackers often use open proxies or set up their own proxies. This observation motivates our work on classifying PIPs.

Although individual features of PIPMiner may be manipulated, it is difficult for an attacker to evade the combination of these features. A malicious PIP that evades our classification (i.e., below the threshold of being classified as bad) may still receive a lower score if it fails to emulate normal user behaviors for some features. This score can be used with other detection techniques to improve confidence. Additionally, PIPMiner significantly raises the bar for attackers to evade detection. The population and time series features force attackers to reduce their attack scale to approximate real user behavior. Figure 6(d) shows that PIPMiner remains robust even when attackers reduce their attack scales.

### Validation of Unlabeled Cases
For PIPs with known labels, our classifier accurately distinguishes good and bad ones. However, it is unclear whether we can accurately classify unlabeled PIPs, which comprise 42.8% of the total. These are particularly challenging to classify as they often have little history or few activities, making reputation data ineffective.

To validate the classification of unlabeled PIPs, we combine information from user registration month and future reputation.

#### User Registration Month
Good PIPs are shared by many different normal users, leading to a diverse distribution of user registration months. Bad PIPs, generated by attacker-created accounts, likely have most accounts created in a short time window. We quantify this by placing accounts into bins based on their registration month. Figure 7 shows the CDF of the percentage of accounts in the top bin. For PIPs classified as good, only 4% have over 45% of accounts registered in the same month. For PIPs classified as bad, about 82% have at least 45% of accounts registered in the same month, suggesting accurate classification.

#### Future Reputation
Future reputation scores, reported months after our dataset's collection time, provide a better chance of recognizing previously unclassified accounts. Using the reputation score from July 2011, we found that around 62% of accounts on initially unlabeled PIPs classified as good were recognized as good after one year. For those classified as bad, about 86.1% were either deleted or marked as malicious. Many bad accounts were deleted due to malicious behavior or inactivity, demonstrating PIPMiner's accuracy.

### Applications

#### 5.1 Windows Live ID Sign-up Abuse Problem
We apply the PIP list to flag malicious sign-ups. Since there is little information at sign-up, it is challenging to distinguish malicious accounts. PIP addresses can serve as a feature or initial reputation to detect malicious users more quickly.

- **Table 7**: Comparative study of our PIP list and newly appeared "PIP-like" addresses.
- **Table 8**: User reputation distribution on different types of PIPs.

Using the 1.7 million PIP list from the Hotmail login log, we studied sign-up behavior. Table 7 shows that while both lists are associated with malicious sign-ups, the fraction from PIP-like addresses is significantly higher (78.3% vs. 41.1%). Good PIPs usually have activities across multiple services, whereas PIP-like addresses are more suspicious and likely controlled by attackers.

Blindly applying our PIP list to sign-up data, we observed a mixed user reputation. To further classify, we used PIP address properties: goodness score and the number of good users. For PIPs with low scores, only 3.9% of sign-ups remained good after 11 months. For PIPs with high scores, around 35% were potentially abused. Sign-ups from abused PIPs had much lower reputation scores. Our early-warning system flagged over 3 million bad sign-ups with 97.0% precision and 96.0% recall.

#### 5.2 Hotmail Malicious Account Detection
We applied our PIP list to the Hotmail malicious user sign-in problem. Intuitively, there should not be many good users (with high reputation scores) using bad PIPs. We used bad PIPs to perform postmortem forensic analysis to identify malicious accounts that slipped through the Hotmail reputation system.