title:SEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial
Learning based Disentangled Representation
author:Jianwei Tai and
Xiaoqi Jia and
Qingjia Huang and
Weijuan Zhang and
Haichao Du and
Shengzhi Zhang
0
2
0
2
t
c
O
5
2
]
S
A
.
s
s
e
e
[
4
v
8
0
6
2
0
.
2
1
9
1
:
v
i
X
r
a
SEEF-ALDR: A Speaker Embedding Enhancement Framework
via Adversarial Learning based Disentangled Representation
Jianwei Tai
Xiaoqi Jia‚àó
Key Laboratory of Network
Assessment Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; Beijing Key
Laboratory of Network Security and
Protection Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; School of Cyber
Security, University of Chinese
Key Laboratory of Network
Assessment Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; Beijing Key
Laboratory of Network Security and
Protection Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; School of Cyber
Security, University of Chinese
Academy of Sciences;
Beijing, China
PI:EMAIL
Weijuan Zhang‚àó
Academy of Sciences;
Beijing, China
PI:EMAIL
Haichao Du
Key Laboratory of Network
Assessment Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; Beijing Key
Laboratory of Network Security and
Protection Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; School of Cyber
Security, University of Chinese
Key Laboratory of Network
Assessment Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; Beijing Key
Laboratory of Network Security and
Protection Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; School of Cyber
Security, University of Chinese
Academy of Sciences;
Beijing, China
PI:EMAIL
Academy of Sciences;
Beijing, China
PI:EMAIL
Qingjia Huang
Key Laboratory of Network
Assessment Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; Beijing Key
Laboratory of Network Security and
Protection Technology, Institute of
Information Engineering, Chinese
Academy of Sciences; School of Cyber
Security, University of Chinese
Academy of Sciences;
Beijing, China
PI:EMAIL
Shengzhi Zhang
Department of Computer Science,
Metropolitan College, Boston
University
Boston, USA
PI:EMAIL
ABSTRACT
Speaker verification, as a biometric authentication mechanism, has
been widely used due to the pervasiveness of voice control on smart
devices. However, the task of ‚Äúin-the-wild‚Äù speaker verification is
still challenging, considering the speech samples may contain lots
of identity-unrelated information, e.g., background noise, rever-
beration, emotion, etc. Previous works focus on optimizing the
model to improve verification accuracy, without taking into ac-
count the elimination of the impact from the identity-unrelated
information. To solve the above problem, we propose SEEF-ALDR,
a novel Speaker Embedding Enhancement Framework via Adver-
sarial Learning based Disentangled Representation, to reinforce
‚àó(cid:66)Xiaoqi Jia and (cid:66)Weijuan Zhang are the corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
¬© 2020 Association for Computing Machinery.
ACM ISBN 978-1-4503-8858-0/20/12...$15.00
https://doi.org/10.1145/3427228.3427274
the performance of existing models on speaker verification. The
key idea is to retrieve as much speaker identity information as
possible from the original speech, thus minimizing the impact of
identity-unrelated information on the speaker verification task by
using adversarial learning. Experimental results demonstrate that
the proposed framework can significantly improve the performance
of speaker verification by 20.3% and 23.8% on average over 13 tested
baselines on dataset Voxceleb1 and 8 tested baselines on dataset
Voxceleb2 respectively, without adjusting the structure or hyper-
parameters of them. Furthermore, the ablation study was conducted
to evaluate the contribution of each module in SEEF-ALDR. Finally,
porting an existing model into the proposed framework is straight-
forward and cost-efficient, with very little effort from the model
owners due to the modular design of the framework.
CCS CONCEPTS
‚Ä¢ Security and privacy ‚Üí Biometrics; ‚Ä¢ Computing method-
ologies ‚Üí Artificial intelligence; ‚Ä¢ Human-centered comput-
ing ‚Üí Human computer interaction (HCI).
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
Jianwei and Xiaoqi, et al.
KEYWORDS
Biometrics, Speaker Embedding, Disentangled Representation, Ad-
versarial Learning
ACM Reference Format:
Jianwei Tai, Xiaoqi Jia, Qingjia Huang, Weijuan Zhang, Haichao Du, and Shengzhi
Zhang. 2020. SEEF-ALDR: A Speaker Embedding Enhancement Framework
via Adversarial Learning based Disentangled Representation. In Annual
Computer Security Applications Conference (ACSAC 2020), December 7‚Äì11,
2020, Austin, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.
1145/3427228.3427274
1 INTRODUCTION
Biometric authentication relies on biosensors to collect physiolog-
ical and behavioral characteristics of users and applies the bio-
statistics principle to verify users‚Äô identity. Physiological features
mainly include fingerprint, face, eyeball, iris, soundtrack, etc., and
behavioral features include handwriting, gait, etc. As the advance of
machine learning and the pervasiveness of mobile devices, biomet-
ric authentication has been widely used in everyone‚Äôs daily life, e.g.,
fingerprint matching [40], face recognition [50], iris recognition
[7] and speaker verification [6, 45, 46] are supported by various
smartphones these days. Recently, speaker verification has become
a topic of interest for its applications in authentication [5, 60], foren-
sics [8, 10], etc. For example, Barclays, a British banking company,
has deployed voice authentication for its call centers since 2013
[66]. Alipay 1 supports voice biometrics as an alternative authen-
tication for users‚Äô convenience. Smart home devices like Amazon
Echo, Apple HomePod, Google Home not only support voice con-
trol, but also integrate speaker verification to authenticate users for
sensitive operations. The above application scenarios, with a large
number of users worldwide, concern their private information as
well as personal property.
The availability of ‚Äúin-the-wild‚Äù datasets [6, 45, 46] helps speaker
verification systems to become capable of dealing with real-world
issues that require high accuracy and robustness in a variety of
complex environments, e.g., grocery store, restaurant, etc. However,
the task of ‚Äúin-the-wild‚Äù speaker verification is still quite challeng-
ing. On one hand, the human voice may vary dramatically under
different emotions and body situations, e.g., the physical condition
of the throat and nose, etc. The diverse attributes of speech informa-
tion hinder the extraction of speaker identity features. On the other
hand, various environments may introduce different background
noise and reverberation that can severely impact the speaker verifi-
cation systems. Moreover, although the speech datasets are already
large-scale compared with previous ones, they still cannot com-
pensate for the variance introduced by the above-mentioned two
factors, making it more difficult to learn uniform speaker embed-
dings.
Recently, Convolutional Neural Network (CNN) has witnessed
great success in the domain of face recognition and begins playing
an important role in the domain of speaker verification on various
speech datasets [1, 3, 4, 14, 57‚Äì59]. For instance, previous works
[4, 14, 32, 36, 68, 69] have been proposed to further improve the
performance of speaker verification. However, they directly process
the original speech, which contains lots of irrelevant features other
1Alipay is the largest mobile payment platform in the world, mainly used in China.
than the ones closely related to the speaker identity. Disentangled
representation [22, 70] is a straightforward idea to decouple the
speaker identity features from the identity unrelated ones. Recently,
disentangled representation has been explored in various computer
vision applications, e.g., exposing invariant features for face recog-
nition [62] and person re-identification [9], attribute transfer via
adversarial disentanglement [30, 37]. In the audio domain, seminal
works [2, 42, 63, 72] focus on robust identity representation by re-
ducing the environmental complexity through adversarial learning.
Nevertheless, they usually require additional and explicit supervi-
sion during the training process, which is not always feasible in
real-world situations, e.g., background noise labels. Therefore, it is
demanded that disentangled representation be effectively adopted
for speaker embeddings to reduce the interference from identity-
unrelated information.
To solve the above problem, we propose a novel speaker em-
bedding enhancement framework via adversarial learning based
disentangled representation, named SEEF-ALDR, which aims to
minimize the impact of identity-unrelated information for speaker
verification task. Inspired by recent advances in adversarial learning
[21, 30, 37], we train SEEF-ALDR based on twin networks, with one
extracting speaker identity features through a simple recognition
training scheme and the other extracting identity-unrelated features
through adversarial learning. The two sets of features obtained by
the twin networks are later joined together in the reconstruction
process that generates the reconstruction supervision signal. By
optimizing the ùêø2 distance between the reconstructed spectrogram
and the original spectrogram, we ensure the union of the decou-
pled features still preserves the same information as the original
spectrogram.
With the speaker embeddings constructed from the speaker iden-
tity features, SEEF-ALDR significantly improves the performance
of ‚Äúin-the-wild‚Äù speaker verification. It is worth noting that SEEF-
ALDR follows the modular design to ease the porting of existing
speaker verification models. Experimental results show that SEEF-
ALDR significantly improves the performance of the speaker verifi-
cation task on ‚Äúin-the-wild‚Äù datasets. The Equal Error Rate (EER)
[61] is reduced by an average of 20.6% on Voxceleb1 and 23.8% on
Voxceleb2 for all the tested baselines. To evaluate the contribution
of each individual module, we conducted a comprehensive ablation
study to learn the performance of each module introduced in the
proposed framework for the speaker verification task. The experi-
mental results show that each module in SEEF-ALDR collaborates
effectively, thus achieving better speaker verification.
The contribution of this paper is highlighted as follows:
‚Ä¢ (1) We propose a novel twin network-based speaker em-
bedding enhancement framework to disentangle identity
representation from the original speech by combining the
autoencoder-like architecture and adversarial learning.
‚Ä¢ (2) SEEF-ALDR follows the modular design to facilitate the
porting of existing speaker verification models, thus signif-
icantly improving the performance of all tested baselines
for ‚Äúin-the-wild‚Äù speaker verification without adjusting the
structure or hyper-parameters of them.
SEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial Learning based Disentangled Representation
ACSAC 2020, December 7‚Äì11, 2020, Austin, USA
‚Ä¢ (3) We only utilize speaker labels to train the eliminating en-
coder based on adversarial supervision to obtain the identity-
unrelated information without explicit or manual labels.
The rest of this paper is organized as follows. Section II provides
background and related works on speaker verification, disentangled
representation, and speech recognition. In Section III, we detail the
SEEF-ALDR approach proposed in this paper. In Section IV, we
conduct comprehensive experiments on the proposed framework
to evaluate its performance on speaker verification and present the
ablation study to demonstrate the contribution of each module in