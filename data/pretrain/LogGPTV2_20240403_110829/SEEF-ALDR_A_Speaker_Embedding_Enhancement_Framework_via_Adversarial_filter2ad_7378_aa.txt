# SEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial Learning based Disentangled Representation

## Authors
Jianwei Tai, Xiaoqi Jia, Qingjia Huang, Weijuan Zhang, Haichao Du, Shengzhi Zhang

### Affiliations
- **Jianwei Tai, Xiaoqi Jia, Qingjia Huang, Weijuan Zhang, Haichao Du**
  - Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences
  - Beijing Key Laboratory of Network Security and Protection Technology, Institute of Information Engineering, Chinese Academy of Sciences
  - School of Cyber Security, University of Chinese Academy of Sciences
  - Beijing, China
  - *Email*: [PI:EMAIL]

- **Shengzhi Zhang**
  - Department of Computer Science, Metropolitan College, Boston University
  - Boston, USA
  - *Email*: [PI:EMAIL]

### Abstract
Speaker verification, a biometric authentication mechanism, has gained widespread use due to the prevalence of voice control on smart devices. However, "in-the-wild" speaker verification remains challenging because speech samples often contain identity-unrelated information such as background noise, reverberation, and emotion. Previous works have focused on optimizing models to improve verification accuracy without addressing the impact of identity-unrelated information. To address this, we propose SEEF-ALDR, a novel Speaker Embedding Enhancement Framework via Adversarial Learning based Disentangled Representation. This framework aims to enhance existing models by extracting as much speaker identity information as possible from the original speech, thereby minimizing the impact of identity-unrelated information. Experimental results show that SEEF-ALDR significantly improves the performance of speaker verification, achieving an average improvement of 20.3% on VoxCeleb1 and 23.8% on VoxCeleb2 over tested baselines, without altering their structure or hyperparameters. Additionally, an ablation study evaluates the contribution of each module in SEEF-ALDR. The modular design of the framework makes it straightforward and cost-efficient to integrate with existing models.

### CCS Concepts
- **Security and Privacy**: Biometrics
- **Computing Methodologies**: Artificial Intelligence
- **Human-Centered Computing**: Human-Computer Interaction (HCI)

### Keywords
Biometrics, Speaker Embedding, Disentangled Representation, Adversarial Learning

### ACM Reference Format
Jianwei Tai, Xiaoqi Jia, Qingjia Huang, Weijuan Zhang, Haichao Du, and Shengzhi Zhang. 2020. SEEF-ALDR: A Speaker Embedding Enhancement Framework via Adversarial Learning based Disentangled Representation. In Annual Computer Security Applications Conference (ACSAC 2020), December 7â€“11, 2020, Austin, USA. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3427228.3427274

## 1 Introduction
Biometric authentication relies on biosensors to collect physiological and behavioral characteristics for user verification. Common physiological features include fingerprints, faces, irises, and voice, while behavioral features include handwriting and gait. With the advancement of machine learning and the ubiquity of mobile devices, biometric authentication is now widely used in daily life, such as fingerprint matching, face recognition, iris recognition, and speaker verification. Recently, speaker verification has gained attention for its applications in authentication and forensics. For example, Barclays has used voice authentication in call centers since 2013, and Alipay supports voice biometrics for user convenience. Smart home devices like Amazon Echo, Apple HomePod, and Google Home also integrate speaker verification for sensitive operations.

The availability of "in-the-wild" datasets, such as VoxCeleb, has enabled speaker verification systems to handle real-world issues with high accuracy and robustness in various environments. However, "in-the-wild" speaker verification remains challenging due to variations in human voices under different emotions and physical conditions, as well as the presence of background noise and reverberation. Although large-scale datasets exist, they do not fully compensate for these variances, making it difficult to learn uniform speaker embeddings.

Recent advancements in Convolutional Neural Networks (CNNs) have shown success in face recognition and are now being applied to speaker verification. While previous works have improved speaker verification performance, they directly process original speech, which contains irrelevant features. Disentangled representation, which decouples speaker identity features from unrelated ones, has been explored in computer vision and audio domains. However, these methods often require explicit supervision, which is not always feasible. Therefore, there is a need for effective disentangled representation in speaker embeddings to reduce interference from identity-unrelated information.

To address this, we propose SEEF-ALDR, a novel speaker embedding enhancement framework that uses adversarial learning to minimize the impact of identity-unrelated information. Inspired by recent advances in adversarial learning, SEEF-ALDR employs twin networks: one extracts speaker identity features through a simple recognition training scheme, and the other extracts identity-unrelated features through adversarial learning. The features are then combined in a reconstruction process, ensuring the reconstructed spectrogram preserves the original information. Experimental results show that SEEF-ALDR significantly improves "in-the-wild" speaker verification, reducing the Equal Error Rate (EER) by an average of 20.6% on VoxCeleb1 and 23.8% on VoxCeleb2. An ablation study further demonstrates the effectiveness of each module in SEEF-ALDR.

### Contributions
1. **Novel Framework**: We propose a twin network-based speaker embedding enhancement framework that disentangles identity representation from the original speech using an autoencoder-like architecture and adversarial learning.
2. **Modular Design**: SEEF-ALDR follows a modular design, facilitating the integration of existing speaker verification models and significantly improving their performance without adjusting their structure or hyperparameters.
3. **Adversarial Supervision**: We utilize speaker labels to train the eliminating encoder based on adversarial supervision, obtaining identity-unrelated information without explicit or manual labels.

### Organization
The rest of this paper is organized as follows. Section II provides background and related work on speaker verification, disentangled representation, and speech recognition. Section III details the SEEF-ALDR approach. Section IV presents comprehensive experiments and an ablation study to evaluate the framework's performance.