title:Effective Anomaly Detection with Scarce Training Data
author:William K. Robertson and
Federico Maggi and
Christopher Kruegel and
Giovanni Vigna
Effective Anomaly Detection with Scarce Training Data
William Robertson∗
PI:EMAIL
UC Berkeley
Federico Maggi∗
PI:EMAIL
Politecnico di Milano
Christopher Kruegel Giovanni Vigna
{chris,vigna}@cs.ucsb.edu
Computer Security Group
UC Santa Barbara
Abstract
1 Introduction
Learning-based anomaly detection has proven to be
an effective black-box technique for detecting unknown
attacks. However, the effectiveness of this technique
crucially depends upon both the quality and the com-
pleteness of the training data. Unfortunately, in most
cases, the trafﬁc to the system (e.g., a web applica-
tion or daemon process) protected by an anomaly de-
tector is not uniformly distributed. Therefore, some
components (e.g., authentication, payments, or content
publishing) might not be exercised enough to train an
anomaly detection system in a reasonable time frame.
This is of particular importance in real-world settings,
where anomaly detection systems are deployed with lit-
tle or no manual conﬁguration, and they are expected to
automatically learn the normal behavior of a system to
detect or block attacks.
In this work, we ﬁrst demonstrate that the features
utilized to train a learning-based detector can be se-
mantically grouped, and that features of the same group
tend to induce similar models. Therefore, we propose
addressing local training data deﬁciencies by exploiting
clustering techniques to construct a knowledge base of
well-trained models that can be utilized in case of un-
dertraining. Our approach, which is independent of the
particular type of anomaly detector employed, is vali-
dated using the realistic case of a learning-based system
protecting a pool of web servers running several web
applications such as blogs, forums, or Web services. We
run our experiments on a real-world data set containing
over 58 million HTTP requests to more than 36,000 dis-
tinct web application components. The results show that
by using the proposed solution, it is possible to achieve
effective attack detection even with scarce training data.
Keywords: Anomaly detection, training data, web appli-
cation.
The Internet has evolved from its humble beginnings
at CERN in 1991 into a massive network of ubiquitous
services that spans the globe and reaches an estimated
1.4 billion people [27]. The World Wide Web contains
more than 100 million sites [46] and around 1 trillion
unique URLs as indexed by Google [1]. Due to its per-
vasive nature, the Internet – and in particular the Web
– has become a predominant medium for disseminat-
ing and collecting information. In fact, web applications
have enjoyed immense popularity as an efﬁcient means
for providing services to users. For instance, Face-
book has more than 250 million active users, upload-
ing more than 1 billion photos each month, and Twit-
ter distributed more than 3 million messages per day in
March 2008 [34].
Unfortunately, applications have been found to con-
tain many security vulnerabilities, due to a combina-
tion of unsafe development tools and a historical lack
of security awareness among developers.
In addition,
the risks are magniﬁed when vulnerable software is de-
ployed in the context of the Web, since applications are
typically widely accessible and often have access to sen-
sitive information. These factors have naturally resulted
in web-related vulnerabilities receiving substantial at-
tention from the criminal underground [40]. As a con-
sequence, the incidence of data breaches, online fraud,
and other crimes resulting from the exploitation of web
application vulnerabilities continues to rise [29,33], and,
therefore, it is essential to protect applications and sys-
tems connected to the Internet against such attacks.
Anomaly detection has received much attention from
the research community as an approach to detecting and
preventing unknown attacks by monitoring a network’s
trafﬁc [20,25,26,32,43,44,47] or a host’s operating sys-
tem [3,14,21,24,28,31,38,42]. Recently, anomaly-based
techniques have also been shown to be effective against
web-based threats [5, 15, 19, 30]. Effective anomaly de-
tection systems are attractive because they consider the
protected system as a black box. As a result, they can
be deployed in live environments without any a priori
knowledge about the application.
Anomaly detection systems contain speciﬁcations, or
models, of the normal behavior of the protected system,
and consider deviations from the speciﬁcations to be ev-
idence of malicious behavior. In contrast to signature-
based systems, anomaly detectors have the desirable
property that previously unknown attacks can be iden-
tiﬁed automatically. Though anomaly detection models
can be manually speciﬁed by domain experts, this is a
tedious, labor-intensive, and error-prone process. There-
fore, most research has instead focused on applying ma-
chine learning techniques to automatically derive mod-
els of normal behavior from unlabeled training data. The
term normal behavior generally refers to a set of charac-
teristics (e.g., the distribution of the symbols of strings,
or the mean and standard deviation of the values of nu-
merical variables) extracted from data observed during
a system’s normal operation. For instance, such data
could be the payloads of network packets, or HTTP re-
quests and responses exchanged between a web server
and clients. Those characteristics are used to build mod-
els of normal behavior. Learning-based anomaly detec-
tors obviate the tedious and error-prone task of creat-
ing speciﬁcations, and, additionally, are able to adapt to
the particular characteristics of the local environment.
Therefore, anomaly detectors typically require only a
modest initial conﬁguration effort to provide effective
attack detection.
In an ideal case, a learning-based anomaly detection
system is deployed in front of a system and, in a com-
pletely automated fashion, learns the normal interaction
between the system and its users. Once enough training
data has been analyzed and the proﬁles for the moni-
tored systems have been established, the anomaly detec-
tor switches to detection mode; it is then able to detect
attacks that represent anomalies with respect to normal
usage. These types of anomaly detection systems are
extremely attractive to security ofﬁcers and site admin-
istrators, who have neither the resources nor the skills to
manually analyze applications composed of hundreds of
components. Because of this, several commercial web
application ﬁrewalls implement some form of machine
learning to support anomaly detection [4, 6, 11].
Learning-based anomaly detectors are not without
their drawbacks, however.
In fact, these systems are
known for their tendency to produce a non-negligible
amount of false positives due to the difﬁculty of accu-
rately modeling non-trivial domains. This is a limit-
ing factor for the effectiveness of such systems [2, 13].
An additional limitation is that anomaly detection sys-
tems critically rely upon the quality of the training data
used to construct their models.
In particular, training
sets must be free from attacks. Otherwise, the result-
ing models will be prone to false negatives, as attack
manifestations will have been learned as normal behav-
ior [8, 10, 17, 39].
Another limitation that is well-known in the research
community is the difﬁculty of obtaining enough high-
quality training data. Unfortunately, to our knowledge,
no proposals exist that satisfactorily address the prob-
lem. In particular, our experiments suggest that web ap-
plication component invocations are non-uniformly dis-
tributed. That is, relatively few components dominate,
and the remaining components are accessed relatively
infrequently. Thus, for those components, it is often
impossible to gather enough training data to accurately
model their normal behavior. We informally refer to
the components that receive insufﬁcient accesses as the
“long tail” of a web application. Note that, however, this
does not necessarily imply a power law distribution of
these accesses. Nevertheless, components that are infre-
quently accessed lead to poor detection capabilities due
to undertrained models (i.e., models possessing knowl-
edge limited to the low number of samples they have
been trained on).
This work addresses the problem of undertrained
models by exploiting natural similarities among the
modeled features. We demonstrate this hypothesis using
the web applications context as a real-world example.
In particular, we show that the values of the parameters
extracted from HTTP requests can generally be catego-
rized according to their type, such as an integer, date, or
string. Moreover, our experiments demonstrate that pa-
rameters of similar type induce similar models of normal
behavior. Taken together, these results can be leveraged
to effectively supplement a lack of training data for one
web application component with similar data from an-
other component that has received more requests.
In this paper, we make the following contributions:
• We introduce the problem that arises from the fact
that trafﬁc is distributed in a non-uniform fashion,
and we provide evidence that this occurs in the real
world in the case of web applications.
• We propose an approach to address the problem of
undertraining by using global knowledge built by
exploiting similarities between web application pa-
rameters of similar type.
• We evaluate our approach on a large data set of
real-world trafﬁc from many web applications, and
demonstrate how anomaly detectors can accurately
model those components that would otherwise be
associated with undertrained models.
The results of our experiments show that by using
our approach, it is possible to improve the detection rate
of undertrained models. In particular, web application
Ri =
ri,1 = /article,
ri,2 = /comments,
ri,3 = /comments/edit,
ri,4 = /account,
ri,5 = /account/password
Figure 1: Example resources comprising a web application.
components that have received only a few dozen requests
can be protected almost as effectively as those that com-
ponents have received thousands of requests.
2 Training data scarcity
To understand why the problem of undertrained mod-
els exists, we ﬁrst present a general description of an
anomaly detection system designed to protect web ap-
plications. While this description is based on the system
described in [19], we believe it represents an accurate
abstraction of web application anomaly detection. We
then use these concepts to introduce the long-tail prob-
lem and its ramiﬁcations on the feasibility of construct-
ing accurate models.
It is important to note that although there is no estab-
lished architecture for these systems, a large portion of
learning-based anomaly detectors are designed in a sim-
ilar manner. In particular, they extract some signiﬁcant
features from the captured trafﬁc, estimate the parame-
ters of a set of pre-existing models (learning phase), and
then use these models to analyze live trafﬁc and recog-
nize unexpected values of the selected features. Thus,
the description that follows can easily be generalized.
In addition, we remind the reader that a low detection
accuracy due to undertraining may affect any type of
learning-based protection system, rather than those de-
tectors speciﬁcally designed for the web domain.
2.1 Web application anomaly detection
Without loss of generality, a set of web applications
A can be organized into a set of resource paths or com-
ponents R, and named parameters P . For example,
a web application ai = blog.example.com might be
composed of the resources shown in Figure 1.
In this example, resource path ri,5 might take a set
of parameters as part of the HTTP request: Pi,5 =
{pi,5,1 = id, pi,5,2 = oldpw, pi,5,3 = newpw}.
A generic learning-based application intrusion detec-
tion system operates by observing a sequence of re-
quests Q = {q1, q2, . . .} issued by clients to the set of
monitored applications. Each request q ∈ Q is repre-
sented by the tuple "ai, ri,j, Pq#, where Pq is a set of
parameter name-value pairs such that Pq ⊆ Pi,j.
As highlighted in Figure 5, the initial training is per-
formed ofﬂine. During this phase, the anomaly detec-
tor learns the behavior of the monitored web applica-
tions in terms of models. As new web application, re-
source path, and parameter instances are observed, the
sets A, R, and P are updated. For each unique pa-
rameter pi,j,k observed in association with a particular
application ai and path ri,j, a set of models that char-
acterizes the normal behavior of various features of the
parameter is constructed. The set of models associated
with each unique parameter instance can be represented
as a tuple c(.) = "m1, m2, . . . , mu, . . . , mU#, referred
to as a proﬁle or model composition. Therefore, for
each application ai and resource path ri,j, a set Ci,j of
model compositions is constructed, one for each param-
eter pi,j,k ∈ Pi,j. The knowledge base of an anomaly
detection system trained on web application ai is de-
noted by Cai = (j Ci,j. A graphical representation of
how a knowledge base is modeled for multiple web ap-
plications is depicted in Figure 2.
To introduce and address the problem of undertrain-
ing, we leverage the set of models described in [19] as
a real-world case. According to the system described
in [19], a proﬁle for a given parameter pi,j,k is the tuple
ci,j,k = "m(tok), m(int), m(len), m(char), m(struct)#. m(tok)
models parameter values as a set of legal tokens (e.g.,
the set of of possible values for the parameter gender
observed during training). m(int) and m(len) describe
normal intervals for integers and string lengths, respec-
tively, in a distribution-independent fashion using the
Chebyshev inequality. m(char) models character strings
as a ranked frequency histogram, or Idealized Charac-
ter Distribution (ICD), that are compared using the χ2
or G tests. m(struct) models sets of character strings by
inducing a Hidden Markov Model (HMM). The HMM
encodes a probabilistic grammar that can produce a su-
perset of strings observed in a training set. Aside from
the addition of m(int), which is a straightforward gen-
eralization of m(len) to numerical ranges, the interested
reader may refer to [19] for further details.
After training, learning-based systems are typically
switched to detection mode, which is performed online.
The models trained in the previous phase are queried to
determine whether or not the new parameters observed
are anomalous. Without going into the details of a par-
ticular implementation, each parameter is compared to
all the applicable models (e.g., an integer parameter is
compared to m(int), while a string parameter is com-
pared to m(len), m(char), and m(struct)) and an aggregated
anomaly score on the interval [0, 1] is calculated by com-
posing the values returned by the individual models. If
the anomaly score is above a certain threshold, an alert
is generated.
Ca1
···
Cai
···
CaI
http : //blog.example.com,
...
http : //dav.example.com
Cr1,1
···
c(·)
cp1,1,1
m1, . . . , mU
···
···
···
···
Cr1,j
···
c(·)
···
···
c(·)
cpi,j,k
m1, . . . , mU
···
···
···
Cri,J
c(·)
···
/article,
/comments,
...
/account,
/account/password
id = 1
date = 10 − 11 − 2004
title = foo
cpi,j,K
m1, . . . , mU
Figure 2: Overview of web application model construction.
2.2 The problem of non-uniform training data
Because learning-based detectors dynamically build
speciﬁcations of normal behavior from training data, it
is clear that the quality of the detection critically relies
upon the quality of the training data. For instance, one