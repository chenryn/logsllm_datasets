Query: path(S,D,P,C).
P = f concatP ath(P1, link(Z,D,C2)),
C = C1 + C2.
Rule NR1 produces new one-hop paths from existing link
tuples as before. Rule DSR2 matches the destination (cid:12)elds of
newly computed path tuples with the source (cid:12)elds of link tu-
ples. This requires newly computed path tuples be shipped by
their destination (cid:12)elds to (cid:12)nd matching links, hence ensuring
that each source node will recursively follow the links along
all reachable paths. Here, the function f concatP ath(P; L)
returns a new path vector with L appended to P. These rules
can also be used in combination with BPR1 and BPR2 to gen-
erate the best paths. By adding two extra rules not shown
here, we can also express the logic for sending each path on
the reverse path from the destination to the source node.
5.4 Link State
To further illustrate the (cid:13)exibility of our approach, we con-
sider a link-state protocol that moves route information around
the network very di(cid:11)erently from the best-path variants. The
following Link-State query expresses the (cid:13)ooding of links to
all nodes in the network:
LS1: (cid:13)oodLink(S,S,D,C,S) :- link(S,D,C)
LS2: (cid:13)oodLink(M,S,D,C,N) :- link(N,M,C1),
.
Query: (cid:13)oodLink(M,S,D,C,N)
(cid:13)oodLink(N,S,D,C,W), M 6= W.
f loodLink(M ; S; D; C; N ) is a tuple storing information about
link(S,D,C). This tuple is (cid:13)ooded in the network starting from
source node S. During the (cid:13)ooding process, node M is the
current node it is (cid:13)ooded to, while node N is the node that
forwarded this tuple to node M.
Rule LS1 generates a f loodLink tuple for every link at each
node. Rule LS2 states that each node N that receives a
f loodLink tuple recursively forwards the tuple to all neigh-
bors M except the node W that it received the tuple from.
Datalog tables are set-valued, meaning that duplicate tuples
are not considered for computation twice. This ensures that
no similar f loodLink tuple is forwarded twice.
Once all the links are available at each node, a local version
of the Best-Path query in Section 5.1 is then executed locally
using the f loodLink tuples to generate all the best paths.
5.5 Multicast
The examples we have given so far support protocols for
unicast routing. Here, we demonstrate a more complex ex-
ample, using Datalog to construct a multicast dissemina-
tion tree from a designated root node to multiple destination
nodes that \subscribe" to the multicast group. The following
Source-Speci(cid:12)c-Multicast query sets up such a forwarding tree
rooted at a source node a for group gid:
#include(NR1,NR2,BPR1,BPR2)
M1:
.
.
M2:
.
.
M3:
Query: joinGroup(N,a,gid)
bestPath(N,M,P,C),
I = f head(P1), P = f tail(P1)
joinMessage(I,J,P,S,G) :- joinMessage(J,K,P1,S,G),
joinMessage(I,N,P,S,G) :- joinGroup(N,S,G),
I = f head(P1),P = f tail(P1),
f isEmpty(P1) = f alse.
forwardState(I,J,S,G) :- joinMessage(I,J,P,S,G).
For simplicity of exposition, this query utilizes the Best-
Path query (rules NR1, NR2, BPR1 and BPR2) to compute
the all-pairs best paths. We will discuss query optimization
techniques to reduce the communication overhead for small
multicast groups in Section 7.2.
Each destination node n joins the group gid with source a
by issuing the query joinGroup(n; a; gid). This results in the
generation of the following derived tuples:
joinMessage(nodeID, prevNodeID, pathVector, source,
gid). This tuple stores the multicast join message for group
gid. It is sent by every destination node along its best path to
the source address of the group. At each intermediate node
with address nodeID, we keep track of prevNodeID, which is
the address of the node that forwarded this tuple. pathVector
is the remaining path that this message needs to traverse in
order to reach the source node.
forwardState(nodeID, forwardNodeID, source, gid).
This tuple represents source-speci(cid:12)c state of the multicast
dissemination tree at each intermediate node with address
nodeID. If a message from source of multicast group gid is
received at nodeID, it is forwarded to forwardNodeID.
Rules M1 and M2 create the joinM essage tuple at each par-
ticipating destination node N, and forward this tuple along
the best path to the source node S. Upon receiving a
joinM essage tuple, rule M3 allows each intermediate node I
to set up the forwarding state using the f orwardState(I; J; S; G)
tuple. The predicate function f head(P ) returns the next
node in the path vector P, and f tail(P ) returns the path
vector P with the (cid:12)rst node removed. f isEmpty(P ) returns
true if P is empty.
Instead of a source-speci(cid:12)c tree, with minor modi(cid:12)cations,
we can construct core-based trees [9]. Here, each participating
node sends a join message to a designated core node to build
a shared tree rooted at the core. Messages are then unicast
to the core, which disseminates it using the shared tree.
6. SECURITY ISSUES
Security is a key concern with any extensible system [24,
11]. In the network domain, this concern is best illustrated
by Active Networks [14] which, at the extreme, allow routers
to download and execute arbitrary code.
Our approach essentially proposes Datalog as a Domain
Speci(cid:12)c Language (DSL) [27] for programming the control
plane of a network. DSLs typically provide security bene(cid:12)ts
by having restricted expressibility. Datalog is attractive in
this respect, both because of its strong theoretical founda-
tions, and its practical aspects. Queries written in the core3
Datalog language have polynomial time and space complexi-
ties in the size of the input [5]. This property provides a nat-
ural bound on the resource consumption of Datalog queries.
However, many implementations of Datalog (including our
own) augment the core language with various functions. Ex-
ample of such functions are boolean predicates, arithmetic
functions, and string or list manipulation logic (e:g:;
f concatP ath, f inP ath, f isEmpty, f head and f tail).
With the addition of arbitrary functions, the time complexity
of a Datalog program is no longer polynomial.
Fortunately, several powerful static tests have been devel-
oped to check for the termination of an augmented Data-
log query on a given input [18].
In a nutshell, these tests
identify recursive de(cid:12)nitions in the query rules, and check
whether these de(cid:12)nitions terminate. Examples of recursive
de(cid:12)nitions that terminate are ones that evaluate monoton-
ically increasing/decreasing predicates whose values are up-
per/lower bounded.
The queries that pass these checks are general enough to ex-
press a large class of routing protocols. Thus, our augmented
Datalog language o(cid:11)ers a good balance between expressive-
ness and safety. We note that all queries presented in this
paper pass such termination tests, with the exception of the
original Network-Reachability query in Section 3. This query
has a rule NR2 that recurse in(cid:12)nitely to generate path tuples
of monotonically increasing costs. However, with the addition
of the boolean function f inP ath(P2; S) = f alse to prevent
path cycles, the number of recursive calls are (cid:12)nite and hence
the query is safe.
Datalog is a side-e(cid:11)ect-free language which takes a set of
stored tables as input, and produce a set of derived tables.
In addition, the execution of the query is \sandboxed" within
the query engine. These properties prevent the query from
accessing arbitrary router state such as in-(cid:13)ight messages,
and the routerâ€™s operating system state. As a result, Datalog
eliminates many of the risks usually associated with extensi-
ble systems.
Of course, there are many other security issues beyond the
safety of the Datalog language. Two examples are denial-
of-service attacks and compromised routers. These problems
are orthogonal to network extensibility, and we do not address
them in this paper.
7. OPTIMIZATIONS
In this section, we explore connections between database
query optimization techniques and routing protocols, with a
focus on more e(cid:14)cient and realistic implementations of the
examples above. In addition, we address techniques for work-
sharing among a diverse set of queries, a new challenge that
is not well-studied in either the database or networking liter-
ature.
7.1 Pruning Unnecessary Paths
A na(cid:127)(cid:16)ve execution of queries with aggregates such as Best-
Path and Distance-Vector starts by enumerating all possible
paths, and then selects among the result. This ine(cid:14)ciency
can be avoided with a query optimization technique known
as aggregate selections [25, 22]. Space constraints prevent a
detailed discussion of this optimization, but we illustrate the
idea with an example.
In Figure 3, there are two di(cid:11)erent
paths from node a to node d, but only the shorter of the two
is required when computing shortest paths. By maintaining
a \min-so-far" aggregate value for the current shortest path
3Such a \core" language does not contain predicates constructed
using function symbols.
cost from node a to its destination nodes, we can selectively
avoid sending path tuples to neighbors if we know they can-
not be involved in the shortest path. In general, aggregate
selections are useful when the running state of a monotonic
AGG function (as in Section 5.1) can be used to prune com-
munication. In addition, aggregate selections are necessary
for the termination of some queries. For example, without ag-
gregate selections, if paths with cycles are permitted, a query
computing the shortest paths will run forever.
7.2 Subsets of Sources and Destinations
In Sections 5.2 and 5.5 we considered scenarios involving
only a subset of nodes in the network. However, our exam-
ples so far { based on the core Network Reachability query of
Section 3 { require all nodes to participate in the query plan.
This leads to an unnecessary overhead when only a subset of
nodes participate in the query as sources and/or destinations.
Next, we discuss two techniques that alleviate this problem:
magic sets rewrite and left-right recursion rewrite.
Magic Sets Rewrite: Consider the multicast construction
in Section 5.5. Even when only a small number of nodes par-
ticipate in the multicast group, the query will still compute
the best paths between all pairs. To limit query computa-
tion to the relevant portion of the network, we use a query
rewrite technique, called magic sets rewriting [10]. For ex-
ample, if nodes b and c are the only nodes issuing the path
query, the rewritten example is as follows:
MRR1: magicSources(D) :- magicSources(S), link(S,D,C).
MRR2: path(S,D,P,C) :- magicSources(S), link(S,D,C),
.
MRR3: path(S,D,P,C) :- magicSources(S), link(S,Z,C1),
.
.
MRR4: magicSources(b).
MRR5: magicSources(c).
Query: path(S,D,P,C).
path(Z,D,P2,C2), C = C1 + C2,
P = f concatP ath(link(S,Z,C1),P2).
P = f concatP ath(link(S,D,C), nil).
The changes to rules NR1 and NR2 are represented in bold.
Intuitively, the set of magicSources facts is used as a \(cid:12)lter" in
the rules de(cid:12)ning paths. After the rewrite, only nodes reach-
able from b and c participate in this query { the computation
is restricted to just the relevant nodes in the network. The
query can be further optimized by combining the common
sub-rules at the beginning of MRR1, MRR2 and MRR3.
Left-Right Recursion Rewrite: The above rewritten query
may provide little or no savings if the set of destinations is
not constrained. Consider the example in Figure 3, where
nodes b and c are the only source nodes. Even with magic
sets, the computation of paths from these sources will require
the computation of all paths sourced at all nodes reachable
from b and c. To avoid these extra computations, we can
rewrite the query using left recursion. To illustrate, the fol-
lowing Best-Path-Pairs query extends the previous query to
perform (1) left recursion, and (2) magic sets query rewrite
on both sources and destinations to generate best paths from
all magicSources to magicDsts nodes:
BPP1: path(S,D,P,C) :- magicSources(S), link(S,D,C),
.
BPP2: path(S,D,P,C) :- path(S,Z,P1,C1), link(Z,D,C2),
.
.
BPP3: pathDst(S,D,P,C) :- magicDsts(D), path(S,D,P,C).
BPP4: bestPathCost(S,D, AGG) :- pathDst(S,D,Z,C).
BPP5: bestPath(S,D,P,C) :- bestPathCost(S,D,C), path(S,D,P,C).
BPP6: magicSources(c).
BPP7: magicDsts(e).
Query: bestPath(S,D,P,C)
C = f compute(C1,C2),
P = f concatP ath(P1, link(Z,D,C2)).
P = f concatP ath(link(S,D,C), nil).
The above example computes only the required best path
starting from the source node c to e. Rules BPP1 and BPP2
are used to compute the paths using left recursion starting
from the magicSources nodes. Recall that the rules are left
recursive because the recursive term path appears to the left
of the matching link. As pointed out in Section 5, executing
the query in a left recursive fashion bears close resemblance
to dynamic source routing. Each source node computes new
path tuples by recursively following the links along all reach-
able paths4. Filtering of the required destination nodes is
done by matching magicDsts with the destination addresses
of computed paths (rule BPP3). The best paths are then
computed using rules BPP3 and BPP4, and sent back to the
source nodes. By adding two extra rules not shown here, we
can also express the logic for sending each best path on the
reverse best path from the destination to the source node.
The drawback of this approach is that it does not allow
computations along overlapping paths to be shared. For ex-
ample, if magicSources(b) is added to the query, both nodes
b and c must compute their paths to node e separately. In
contrast, in the previous right-recursive query, both nodes b
and c would be able to obtain that shared information from
node d. In the following subsection, we will discuss a sim-
ple query rewrite for (cid:12)xing this problem, yet retaining the
bene(cid:12)ts of left recursion.
7.3 Multiâ€ºQuery Sharing
As discussed in the introduction, we are interested in facil-
itating aggressive use of the routing infrastructure, in which
a diverse set of route requests queries is executed concur-
rently in our system. A key requirement for scalability is the
ability to share the query computation among a potentially
large number of queries. A challenge for the query processor
is in detecting sharing opportunities across the diverse set
of queries. Detecting overlaps between Datalog queries (or
database queries in general) is a di(cid:14)cult problem [12], and
beyond the scope of this paper. However, we can leverage
the fact that our routing queries are often simple variants of
graph transitive closure computations. We are currently ex-
ploring the use of a more concise transitive closure language
representation [6] that makes it easier to determine whether
two queries are similar.
We (cid:12)rst consider sharing among queries with identical rules,
as might occur in a single-protocol scenario. If all nodes are
running the same query, the optimal strategy is one based on
right-recursion where each node directly utilizes path infor-
mation sent by neighboring nodes. On the other hand, if only
a small subset of nodes are issuing the same query, using left-
recursion achieves lower message overhead as we will see in
Section 9. In general, one would like an optimizer to automat-
ically choose whether to use left or right recursion. This can
be achieved using a query rewrite optimization. For example,
the following Best-Path-Pairs-Share query replaces the origi-
nal left-recursion rule BPP2 from the Best-Path-Pairs query
with two rules BPPS1 and BPPS2:
#include(BPP1,BPP3,BPP4,BPP5)
BPPS1: path(S,D,P,C) :- magicDst(D3), path(S,Z,P1,C1),
.
.
.
BPPS2: path(S,D,P,C) :- magicDst(D), path(S,Z,P1,C1),
.
.
.
Query: bestPath(S,D,P,C)
link(Z,D,C2), :bestPathCache(Z,D3,P3,C3),
C = f compute(C1,C2),
P = f concatP ath(P1, link(Z,D,C2)).
bestPathCache(Z,D,P2,C2),
C = f compute(C1,C2),
P = f concatP ath(P1,P2).
Rule BPPS1 speci(cid:12)es that in the absence of any cached5
4Note that the rules speci(cid:12)es that the computed path tuples are
stored at the destination nodes instead of the source nodes as in the
previous queries. This turns out to be the optimal tuple placement
strategy that minimizes communication overhead for this query.
While the decision on where to store derived facts is currently
explicitly speci(cid:12)ed via the rules, we plan to explore letting a query
optimizer decide the optimal placement automatically.