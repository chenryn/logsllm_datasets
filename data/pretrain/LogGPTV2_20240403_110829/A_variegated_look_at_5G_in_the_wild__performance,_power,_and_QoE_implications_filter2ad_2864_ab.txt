performance. [C2] Secondly, we also have no clear visibility into
the carrier’s network/transport infrastructure and policies enforced
by them. [C3] Finally, there is significant diversity in end-device
(e.g., server or smartphone) specifications and capabilities which
can affect network performance.
Methodology. We now describe our carefully designed method-
ology for evaluating 5G network performance. Ookla’s Speedtest
service [43] is a widely used and state-of-the-art tool for testing
Internet connection bandwidth and latency. By default, Speedtest
chooses a geographically nearby server with the least round-trip
latency to measure downlink/uplink throughput. They also al-
low users to choose a server from a pool of geographically dis-
tributed servers. More importantly, both the 5G carriers studied
host servers on Ookla. For instance, Verizon hosts 48 servers while
T-Mobile hosts 47 servers. These are mainly located in major metro-
politan U.S. cities. We leverage the flexibility of server selection as
well as the carrier’s presence in Speedtest’s pool of server network
to evaluate a carrier’s network performance by conducting several
tests on carrier-hosted servers. Particularly, this strategy helps us
reduce the impact of [C1] and [C2] on our measurement tests.
The default policy of server selection from Speedtest is to choose
a server located in the same city as the UE. Our results (Fig. 24
in Appendix A.2) also further confirm that using carrier-hosted
Speedtest servers (especially if one is available in the UE’s city) usu-
ally provides best performance over non-carrier based servers. Even
when testing using carrier-hosted servers in other states and cities,
we believe this strategy helps eliminate most of the Internet side
bottleneck as the carrier would usually place Speedtest servers at
the edge of the carrier’s city-level ingress points. Speedtest service
uses TCP protocol for all its tests. Speedtest additionally also allows
us to conduct a test in one of the two connection modes: (i) us-
ing a single connection and (ii) using multiple connections that
Figure 1: Impact of UE-Server distance on RTT.
is non-configurable. The number of multiple connections varies
from one test to another, and the algorithm is not disclosed on
how Speedtest decides the number of connections to establish for
a test. To account for this limitation, we also provision VMs with
high network-throughput (in different U.S. locations) provided by
Microsoft Azure’s public cloud service. This allowed us to evaluate
the impact of different transport layer protocols and parameters.
Lastly, we take two steps to address [C3]. First, to account for UE
diversity, we use two 5G smartphones: PX5 and a more powerful
S20U (§2). Secondly, in addition to the carrier-hosted Speedtest
servers, we also use all the Speedtest servers located in the local
state of the UE. This allows to reduce the impact of geographic dis-
tance on network performance, rather allows us to understand the
impact of other potential server-side factors over 5G network per-
formance. For each unique  setting,
we repeat the test at least 10 times per connection mode. Our dataset
contains over 12,500 Speedtest measurements2. We report the 95th
percentile performance results of all Speedtest sessions repeatedly
conducted for a setting. In other words, our approach measures
the peak network performance, and should not be confused with
the user perceived network quality metrics [5]. Focusing on the
peak metrics helps us to further reduce the impact of congestion
and other Internet-side factors on our performance measurements,
and rather helps us understand the impact of UE-Server distance
and radio technology/band over network performance. Having this
information is particularly important for application and service
providers so that they can better harness 5G. Unless specified other-
wise, all mmWave-5G based experiments were conducted outdoors
and the UE was held stationary with clear LoS to the 5G tower.
Baseline. To provide the initial longitudinal insights of commercial
5G’s network performance in the US, we consider 5Gophers [39]
dataset (reportedly measured in the US as of October 2019) as the
baseline for comparing results.
3.2 Impact of UE-Server Distance
Round-Trip Time (RTT). By tapping into the 5G carriers’ nation-
wide network of Speedtest servers, we next quantify the impact of
UE-Server distance over RTT. Fig. 1 shows the latency characteris-
tics of Verizon’s mmWave 5G service for different server locations
on a geographic map. UE’s location is fixed as Minneapolis, MN.
Clearly, RTT degrades severely as the UE-Server distance increases.
The lowest observed RTT is ∼6ms when tested with a server located
closest (∼3 km) to the UE. Compared to latency observed back in
2019 [39] (i.e., during early deployment), this is a∼50% improvement
2We developed scripts for Android smartphones to completely automate the process
of conducting a test using Ookla’s Speedtest service (free version).
47846357314743283872402274687261657637861517658893845589356142563020406080100Latency(in ms)BetterSIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Arvind Narayanan∗, Xumiao Zhang∗, Ruiyang Zhu, Ahmad Hassan, Shuowei Jin, et al.
Figure 2: [Verizon] Latency.
Figure 3: [Verizon] Downlink.
Figure 4: [Verizon] Uplink.
Figure 5: [T-Mobile] Latency.
Figure 6: [T-Mobile] Downlink.
Figure 7: [T-Mobile] Uplink.
over the baseline performance. RTT gets doubled as the UE-Server
distance increases to 320 km. This trend is more clearly visible in
Fig. 23 which further signifies the importance of edge computing
for latency-sensitive apps and services. Fig. 2 also compares RTT
values of mmWave 5G against that of low-band 5G and 4G/LTE. We
find that low-band 5G suffers an additional delay of ∼6 to 8 ms over
mmWave 5G across the entire UE-Server distance range. This is
not surprising as mmWave 5G bands (n260/n261) with higher sub-
carrier spacing and shorter OFDM symbol duration lead to lower
latency when compared to low-band 5G [53, 54]. On the other hand,
due to flexible frame structure and fine-grained transmission time
interval (TTI) in 5G NR, we find both low-band and mmWave 5G
exhibit better RTT (6 to 15ms reduction) than LTE. Similar experi-
ments were also conducted over T-Mobile’s network (including SA
Low-Band 5G) and results are shown in Fig. 5. While the earlier
trend observed in Verizon’s network about the impact of UE-Server
distance over RTT also holds true for T-Mobile’s network, we do
not find any significant difference yet in RTT performance between
T-Mobile’s SA and NSA deployments of low-band 5G.
Throughput. Fig. 3 shows the impact of UE-Server distance on
Verizon mmWave 5G downlink throughput performance. With mul-
tiple TCP connections, the UE is able to achieve an impressive
downlink throughput of over 3 Gbps across all the servers in the
US. This is a ∼50-60% improvement over the baseline. We attribute
this improvement to ramping up of carrier aggregation from 4CC
to 8CC which requires improvements in carrier’s infrastructure
as well as the UE’s chipset specifications (see Appendix A.1). As
pointed out earlier, Speedtest does not allow us to control the num-
ber of TCP connections for a test. Using packet dumps, we found
that Speedtest would establish anywhere between 15 to 25 TCP
connections for the multiple connection test. The packet loss rate
was less than 1%. However, with a single TCP connection, we find
that the throughput degrades as the UE-Server distance increases
(see Fig. 3). We suspect this degradation is due to the: (1) increase
in RTT which is known to affect TCP performance, (2) packet loss
3Figures 2 to 7 shows servers located in the conterminous US region only.
Figure 8: Single conn. downlink throughput across all US-
based Azure regions under different transport layer settings.
(even at the slightest rate). The impact of both coupled with exist-
ing TCP mechanisms gets amplified at ultra-high bandwidth levels
thus degrading TCP performance. Nonetheless, compared to the
baseline, we find there is a significant improvement in the single
TCP (1-TCP) connection’s performance. 1-TCP connection (with
less overhead compared to multiple connections) can also achieve
close to 3 Gbps throughput provided the server is much closer to
the UE. This again signifies the importance of the edge especially
for bandwidth-hungry applications. Uplink throughput (see Fig. 4)
performance has also improved by a factor of 3× to 4× over the base-
line. Both single and multiple connection uplink tests can achieve a
throughput of ∼220 Mbps. On the other hand, for T-Mobile which
also has SA-based deployments for the low-band 5G, we find that
both downlink and uplink performance can achieve only half the
performance of what their low-band NSA 5G service can provide
(see Figs. 6 and 7). We believe this to be due to carrier aggregation
not yet supported for SA or that the 5G core is not fully mature to
provide the benefits envisioned by SA 5G.
Taking a Closer Look at Single-Conn. Throughput. To get
a better understanding of single-connection’s performance with
mmWave 5G (known to provide ultra-high bandwidth capacity),
we perform controlled experiments using Microsoft Azure’s public
cloud service. We provision a high-network bandwidth capacity
VM (Type: DS4_v2) at every region in the US provided by Microsoft
Azure. In order to capture packet dumps and have the ability to
change kernel parameters, we use rooted PX5 to conduct these
experiments. Unlike S20U that can achieve a throughput of more
than 3 Gbps, PX5 has a maximum observable downlink throughput
05001000150020002500UE-ServerDistance(inkm)020406080100RTT(inms)mmWaveLow-BandLTE/4GmmWaveLow-BandLTE/4G05001000150020002500UE-ServerDistance(inkm)500100015002000250030003500DownlinkThroughput(inMbps)mmWave020406080100RTTinms(invertedaxis)multipleconn.singleconn.RTT05001000150020002500UE-ServerDistance(inkm)050100150200250UplinkThroughput(inMbps)mmWavemultipleconn.singleconn.05001000150020002500UE-ServerDistance(inkm)020406080100RTT(inms)SALow-Band(T-Mobile)NSALow-Band(T-Mobile)SALow-Band(T-Mobile)NSALow-Band(T-Mobile)05001000150020002500UE-ServerDistance(inkm)050100150200DownlinkThroughput(inMbps)SALow-Band(T-Mobile)NSALow-Band(T-Mobile)Multipleconn.Singleconn.Multipleconn.Singleconn.05001000150020002500UE-ServerDistance(inkm)0255075100UplinkThroughput(inMbps)SALow-Band(T-Mobile)NSALow-Band(T-Mobile)Multipleconn.Singleconn.Multipleconn.Singleconn.CentralNorthCentralEastWestCentralEast2SouthCentralWest2West0500100015002000Throughput(inMbps)374km563km1393km1444km1539km1779km2044km2532kmUE-ServerDistanceUDPTCP-8TCP-1TunedTCP-1DefaultA Variegated Look at 5G in the Wild: Performance, Power, and QoE Implications
SIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Figure 9: [T-Mobile] Handoff frequency (while driving)
across different low-band frequency settings.
of ∼2.2 Gbps (see Appendix A.1 for details). For TCP, we use CUBIC
TCP [16] as the congestion control algorithm. The experimental
setup uses UDP performance as baseline. As shown in the results
(see Fig. 8), UDP is able to achieve peak observable throughput
across all the server locations. We observe a small yet noticeable gap
between UDP and 8-TCP performance most likely due to the proto-
col overhead of TCP. However, with default Linux kernel (v4.18.0)
parameters for TCP, we find 1-TCP connection’s throughput is
limited to no more than 500 Mbps for all servers. Upon further
investigation, increasing the maximum size of TCP write buffer
(tcp_wmem) parameter of Linux’s TCP kernel significantly improves
the UE’s downlink throughput using 1-TCP connection by a factor
of 2.1× to 3× (denoted as “1-TCP tuned” in Fig. 8). Theoretically, the
sender’s TCP buffer size (which is a per socket configuration) must
at the least be equal to the bandwidth-delay product (BDP) of the
high-throughput flow’s capacity. In other words, transport-layer
kernel parameters should be carefully tuned to meet the desired
application QoE requirements. Nonetheless, even the tuned 1-TCP
performance falls short by ∼886 Mbps on average when compared
to UDP. Similar to the impact of UE-Server distance observed ear-
lier in Fig. 3 for the single-connection performance using Ookla’s
Speedtest service, we make similar observations in performance
under controlled experimental settings using Azure servers. In that,
we again find that TCP performance (including that of 1-TCP tuned)
exacerbates as the UE-Server distance increases. These observations
highlight the inefficacies that exist in current TCP and congestion
control mechanisms over mmWave 5G networks.
3.3 Handoffs in (Low-Band) NSA & SA 5G
Previous studies on handoffs4 of NSA mmWave 5G [39] have shown
that compared to 4G/LTE, there are far more frequent handoffs.
This is mainly due to the smaller coverage footprint of mmWave
towers as well as that NSA 5G still relies on LTE for control plane
signaling. In this preliminary study, we however focus on compar-
ing T-Mobile’s SA 5G with NSA 5G that are commercially deployed.
T-Mobile is the only carrier that has deployed both NSA and SA-
based 5G for their low-band network. To obtain connectivity to
SA 5G (over n71 band), it was critical to use T-Mobile’s firmware
in S20U. We selected a 10 km driving route which traversed via
busy downtown regions and freeways with driving speeds ranging
from 0 to 100 kph. Using Samsung’s service code (*#2263#), we
selectively enable a set of radio bands to configure the UE in one of
the 5 setting: (i) enable SA-n71 band only, (ii) enable NSA-n71 and
LTE bands only, (iii) enable LTE bands only, (iv) enable SA-n71
and LTE bands only, and, (v) enables all bands (default setting). For
each configuration, while the UE was handheld by a passenger, we
4Handoff here refers to the change in tower or data transmission technology.
drove the route 2× per direction and monitored the handoff activity.
Fig. 9 shows a representative set of results. There are five horizontal
bars, one for each of the 5 band configuration settings. Within each
horizontal bar, there are several colored-segments that denoted the
active radio (blue for 4G/LTE, orange for NSA-5G, and green for
SA-5G). Ticks on these bars indicate the occurrence of a horizontal
handoff (i.e., across towers) or a vertical handoff (i.e., across radio
technologies). The most important finding here is that SA 5G has
far fewer handoffs (i.e., 13 handoffs) compared to other configura-
tions, NSA-5G + LTE (110), LTE (30), SA+LTE (38) and all bands (64).
These will have implications not just on control plane signaling
and scheduling overheads, but also over network performance. Due
to increased coverage of the low-band RF n71 band, both SA and
NSA over n71 band experience very few horizontal handoffs (13 to
20). But, in NSA, we found close to 90 vertical handoffs (e.g., 4G to
5G or vice-versa) highlighting the complexities involved in NSA.
Now that we have seen the network performance characteris-
tics of different 5G technologies, next we investigate how such
performance characteristics impact power.
4 POWER CHARACTERISTICS
In this section, we discuss the power characterization of 5G net-
work and compare with the latest 4G results. To better understand
the UE’s power consumption, we construct power models for dif-
ferent 5G networks with multiple factors including signal strength,
throughput, and frequency bands.
4.1 Methodology
RRC state inference. We first derive the built-in radio state ma-
chine which was designed for power management of mobile de-
vices, e.g., parameters of RRC states and transitions for 4G [12]
and 5G [13]. For the parameter inference, we improve a network-
based approach used in [31, 51] to build our own inference tool,
RRC-Probe, in which a server sends UDP packets to a client (UE) at
different packet intervals and the UE sends an ACK once a packet
is received. The length of RTT depends on the UE’s instant RRC
state when receiving the packet. Therefore, by measuring the RTT
for different packet intervals, we can identify different states and
calculate the timers for the transitions between states. Note that
this approach does not require root access on smartphones.
Power measurement. We use Monsoon power monitor [17] to
measure the UE’s power consumption for two purposes: First, we
aim to understand power consumption during RRC state transitions.
To measure this, the UE is left idle without any data activity for
sufficient time (20s in our experiments) thus forcing the UE to be
in RRC_IDLE state. A server then sends a packet to the UE which
subsequently triggers an RRC_IDLE → RRC_CONNECTED transition
and switch to 5G. Then the UE starts its inactivity timer and de-
motes to RRC_IDLE at the end. In this way, the power monitor can
capture full tail period5 for RRC_CONNECTED. Second, to study
the throughput-power relationship and its implications on energy
efficiency, we control the UE’s data transfer throughput while mea-
suring its power. To reduce the impact of power consumption due
to display screen and brightness, we set the screen at the maximum
5The period after Continuous Reception (i.e., when UE finishes its data transfer) and
before demoting to RRC_IDLE in which there are discontinuous reception cycles
(DRX) and the UE can reduce power consumption.
0100200300400500600Timeline(inseconds)SA-5GonlyNSA-5G+LTELTEonlySA-5G+LTEAllBandsActiveRadio4GNSA-5GSA-5GHandoﬀTypeVerticalHorizontalHandoﬀTypeVerticalHorizontalSIGCOMM ’21, August 23–28, 2021, Virtual Event, USA
Arvind Narayanan∗, Xumiao Zhang∗, Ruiyang Zhu, Ahmad Hassan, Shuowei Jin, et al.