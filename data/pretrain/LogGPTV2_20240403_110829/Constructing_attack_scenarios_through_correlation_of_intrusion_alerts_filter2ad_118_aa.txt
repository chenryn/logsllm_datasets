title:Constructing attack scenarios through correlation of intrusion alerts
author:Peng Ning and
Yun Cui and
Douglas S. Reeves
Constructing Attack Scenarios through Correlation of
Intrusion Alerts
Peng Ning
Science
Yun Cui
Science
Department of Computer
Department of Computer
NC State University
Raleigh, NC 27695-7534
PI:EMAIL
NC State University
Raleigh, NC 27695-7534
PI:EMAIL
Douglas S. Reeves
Department of Computer
Science
NC State University
Raleigh, NC 27695-7534
PI:EMAIL
ABSTRACT
Traditional intrusion detection systems (IDSs) focus on low-
level attacks or anomalies, and raise alerts independently,
though there may be logical connections between them. In
situations where there are intensive intrusions, not only will
actual alerts be mixed with false alerts, but the amount of
alerts will also become unmanageable. As a result, it is di(cid:14)-
cult for human users or intrusion response systems to under-
stand the alerts and take appropriate actions. This paper
presents a practical technique to address this issue. The
proposed approach constructs attack scenarios by correlat-
ing alerts on the basis of prerequisites and consequences of
intrusions. Intuitively, the prerequisite of an intrusion is the
necessary condition for the intrusion to be successful, while
the consequence of an intrusion is the possible outcome of
the intrusion. Based on the prerequisites and consequences
of di(cid:11)erent types of attacks, the proposed approach corre-
lates alerts by (partially) matching the consequence of some
previous alerts and the prerequisite of some later ones. The
contribution of this paper includes a formal framework for
alert correlation, the implementation of an o(cid:11)-line alert cor-
relator based on the framework, and the evaluation of our
method with the 2000 DARPA intrusion detection scenario
speci(cid:12)c datasets. Our experience and experimental results
have demonstrated the potential of the proposed method
and its advantage over alternative methods.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection|In-
vasive software (e.g., viruses, worms, Trojan horses); K.6.5
[Management of Computing and Information Sys-
tems]: Security and Protection
General Terms
Security, Performance
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’02, November 18-22, 2002, Washington, DC, USA.
Copyright 2002 ACM 1-58113-612-9/02/0011 ...$5.00.
Keywords
intrusion detection, alert correlation, attack scenarios
1.
INTRODUCTION
Traditional intrusion detection systems (IDSs) focus on
low-level attacks or anomalies, and raise alerts indepen-
dently, though there may be logical connections between
them.
In situations where there are intensive intrusions,
not only will actual alerts be mixed with false alerts, but
the amount of alerts will also become unmanageable. As a
result, it is di(cid:14)cult for human users or intrusion response
systems to understand the alerts and take appropriate ac-
tions. Therefore, it is necessary to develop techniques to
construct attack scenarios (i.e., steps that attackers use in
their attacks) from alerts and facilitate intrusion analysis.
Several alert correlation methods have been proposed to
address this problem. These methods fall into three classes.
The (cid:12)rst class (e.g., Spice [16], the probabilistic alert correla-
tion [18]) correlates alerts based on the similarities between
alert attributes. Though they are e(cid:11)ective for correlating
some alerts (e.g., alerts with the same source and destina-
tion IP addresses), they cannot fully discover the causal re-
lationships between related alerts. The second class (e.g.,
LAMBDA [5] and the data mining approach [6]) bases alert
correlation on attack scenarios speci(cid:12)ed by human users or
learned through training datasets. Obviously, these methods
are restricted to known attack scenarios. A variation in this
class uses a consequence mechanism to specify what types of
attacks may follow a given attack, partially addressing this
problem [7]. The third class (e.g., JIGSAW [17]) is based on
the preconditions and consequences of individual attacks; it
correlates alerts if the precondition of some later alerts are
satis(cid:12)ed by the consequences of some earlier alerts. Com-
pared with the (cid:12)rst two classes of methods, this class can
potentially uncover the causal relationship between alerts,
and is not restricted to known attack scenarios. (Please see
Section 5 for more related work.)
JIGSAW [17] is the only published result that falls into
the third class (when this paper was submitted)1.
It was
originally proposed to represent complex attacks, and the
authors envisaged to apply it to correlate intrusion alerts.
However, several problems make it di(cid:14)cult for JIGSAW to
1Recent work by Cuppens and Miege [4] has substantial sim-
ilarity to our work, which was done independently. The
comparison of [4] with our work can be found in Section 5.
245be a practical alert correlation technique. First, JIGSAW
requires all the preconditions (i.e., required capabilities in
[17]) of an (abstract) attack to be satis(cid:12)ed in order to con-
sider its consequences. This is theoretically okay; however,
it has a negative impact on alert correlation in practice. In
particular, if the IDS fails to detect one of the attacks that
prepare for later attacks, JIGSAW will miss the opportu-
nity to correlate the detected attacks. Moreover, JIGSAW
treats low-level attacks individually, and does not correlate
an alert if it does not prepare for (or is prepared for by) other
alerts, even if the alert is related to others. For example, if
an attacker tries several variations of the same attack in a
short period of time, JIGSAW will treat them separately,
and only correlate those that prepare for (or are prepared
for by) other alerts. In addition, JIGSAW ignores failed at-
tempts of attacks even if they belong to a sequence of well
planned attacks. Finally, no speci(cid:12)c mechanism has been
provided in JIGSAW to correlate alerts, though this has
been speculated as an application of JIGSAW in [17]. Thus,
additional work is necessary to have a practical solution for
constructing attack scenarios from alerts.
In this paper, we address the limitations of JIGSAW, and
develop a practical alert correlation technique that can be
used to construct attack scenarios for real-life intrusion anal-
ysis. Our method can be explained easily based on the fol-
lowing observation: most intrusions are not isolated, but
related as di(cid:11)erent stages of attacks, with the early stages
preparing for the later ones. For example, in Distributed
Denial of Service (DDOS) attacks, the attacker has to in-
stall the DDOS daemon programs in vulnerable hosts be-
fore he/she can instruct the daemons to launch an attack.
In other words, an attacker has to (or usually does) reach
a certain state before he/she can carry out certain attacks,
and usually reaches the state by launching some other at-
tacks.
Based on this observation, we correlate alerts using pre-
requisites and consequences of intrusions.
Intuitively, the
prerequisite of an intrusion is the necessary condition for
the intrusion to be successful, while the consequence of an
intrusion is the outcome of the intrusion if it is successful.
For example, the existence of a vulnerable service is the pre-
requisite of a remote bu(cid:11)er over(cid:13)ow attack against the ser-
vice, and as the consequence of the attack, the attacker may
gain access to the host. Accordingly, we correlate the alerts
together when the attackers launch some early attacks to
prepare for the prerequisites of some later ones. For exam-
ple, if they use a UDP port scan to discover the vulnerable
services, followed by an attack against one of the services, we
can correlate the corresponding alerts together. To address
the limitations of JIGSAW, our method allows alert aggre-
gation as well as partial satisfaction of prerequisites of an
intrusion. In addition, our formalism provides an intuitive
representation of correlated alerts and a speci(cid:12)c mechanism
for alert correlation, which leads to our implementation of
the method.
The contribution of this paper is three-fold. First, we de-
velop a framework for alert correlation by addressing the
limitations of JIGSAW. Unlike JIGSAW, our method can
deal with attack attempts and correlate alerts as long as
there are signs of connections between them, even if some re-
lated attacks fail or bypass the IDS. In addition, our method
provides an intuitive mechanism (called hyper-alert correla-
tion graph) to represent attack scenarios constructed through
alert correlation. Second, we develop an o(cid:11)-line tool that
implements our alert correlation method. Based on the in-
formation about di(cid:11)erent types of attacks, our tool processes
the alerts reported by IDSs and generates hyper-alert corre-
lation graphs as the output. As we will see in Section 4, these
hyper-alert correlation graphs reveal the structure of series
of attacks, and thus the strategy behind them. Third, we
perform a series of experiments to validate our method using
2000 DARPA intrusion detection scenario speci(cid:12)c datasets
[10]. Our results show that our method not only correlates
related alerts and uncovers the attack strategies, but also
provides a way to di(cid:11)erentiate between alerts.
The remainder of this paper is organized as follows. The
next section presents our formal framework for correlating
alerts using prerequisites and consequences of intrusions.
Section 3 describes the implementation of our method. Sec-
tion 4 reports our experiments with the 2000 DARPA intru-
sion detection scenario speci(cid:12)c datasets. Section 5 discusses
additional related work. Section 6 concludes this paper and
points out future research directions.
2. A FRAMEWORK FOR ALERT CORRE-
LATION
As discussed in the introduction, in a series of attacks
where the attackers launch earlier attacks to prepare for
later ones, there are usually strong connections between the
consequences of the earlier attacks and the prerequisites of
the later ones. If an earlier attack is to prepare for a later
attack, the consequence of the earlier attack should at least
partly satisfy the prerequisite of the later attack.
Accordingly, we propose to identify the prerequisites (e.g.,
existence of vulnerable services) and the consequences (e.g.,
discovery of vulnerable services) of each type of attack. These
are then used to correlate alerts, which are attacks detected
by IDSs, by matching the consequences of (the attacks cor-
responding to) some previous alerts and the prerequisites of
(the attacks corresponding to) some later ones. For exam-
ple, if we (cid:12)nd a Sadmind Ping followed by a bu(cid:11)er over(cid:13)ow
attack against the corresponding Sadmind service, we can
correlate them to be parts of the same series of attacks. In
other words, we model the knowledge (or state) of attackers
in terms of individual attacks, and correlate alerts if they
indicate the progress of attacks.
Note that an attacker does not have to perform early at-
tacks to prepare for a later attack, even though the later at-
tack has certain prerequisites. For example, an attacker may
launch an individual bu(cid:11)er over(cid:13)ow attack against a ser-
vice blindly, without knowing if the service exists. In other
words, the prerequisite of an attack should not be mistaken
for the necessary existence of an earlier attack. However, if
the attacker does launch attacks with earlier ones preparing
for later ones, our method can correlate them, provided that
the attacks are detected by IDSs.
In the following subsections, we adopt a formal approach
to develop our alert correlation method.
2.1 Prerequisite and Consequence of Attacks
We propose to use predicates as basic constructs to repre-
sent prerequisites and consequences of attacks. For example,
a scanning attack may discover UDP services vulnerable to
a certain bu(cid:11)er over(cid:13)ow attack. We can use the predicate
UDPVulnerableToBOF (VictimIP, VictimPort) to represent
246the attacker’s discovery. Similarly, if an attack requires a
UDP service vulnerable to the bu(cid:11)er over(cid:13)ow attack, we
can use the same predicate to represent the prerequisite.
Some attacks may require several conditions be satis(cid:12)ed
at the same time in order to be successful. To represent such
complex conditions, we use a logical combination of predi-
cates to describe the prerequisite of an attack. For example,
a network launched bu(cid:11)er over(cid:13)ow attack may require the
target host have a vulnerable UDP service accessible to the
attacker through the (cid:12)rewall. This prerequisite can be rep-
resented by UDPVulnerableToBOF (VictimIP, VictimPort)
^ UDPAccessibleViaFirewall (VictimIP, VictimPort). To
simplify the discussion, we restrict the logical operators to
^ (conjunction) and _ (disjunction).
We use a set of predicates to represent the consequence
of an attack. For example, an attack may result in com-
promise of the root privilege as well as modi(cid:12)cation of the
.rhost (cid:12)le. Thus, we may use the following to represent the
corresponding consequence: fGainRootAccess (VictimIP),
rhostModi(cid:12)ed (VictimIP)g. Note that the set of predicates
used to represent the consequence is essentially the conjunc-
tion of these predicates and can be represented by a single
logical formula. However, representing the consequence as a
set rather than a long formula is more convenient and will
be used here.
The consequence of an attack is indeed the possible result
of the attack. In other words, the attack may or may not
generate the stated consequence, depending on whether the
attack is successful or not. For example, after a bu(cid:11)er over-
(cid:13)ow attack against a service, an attacker may or may not
gain the root access, depending on if the service is vulnerable
to the attack.
We use possible consequences instead of actual consequences
due to the following reasons. First, an IDS may not have
enough information to decide if an attack is e(cid:11)ective or not.
For example, a network based IDS can detect certain bu(cid:11)er
over(cid:13)ow attacks by matching the patterns of the attacks;
however, it cannot decide whether the attempts succeed or
not without more information from the related hosts.
In
contrast, the possible consequence of a type of attack can
be analyzed and made available for IDS. Second, even if an
attack fails to prepare for the follow-up attacks, the follow-
up attacks may still occur simply because, for example, the
attacker uses a script to launch a series of attacks. Using
possible consequences of attacks will lead to better oppor-
tunity to correlate such attacks.
2.2 Hyper-alert Type and Hyper-alert
Using predicates as the basic construct, we introduce the
notion of a hyper-alert type to represent the prerequisite and
the consequence of each type of alert.
De(cid:12)nition 1 A hyper-alert type T is a triple (fact, prerequi-
site, consequence), where (1) fact is a set of attribute names,
each with an associated domain of values, (2) prerequisite is
a logical combination of predicates whose free variables are
all in fact, and (3) consequence is a set of predicates such
that all the free variables in consequence are in fact.
Each hyper-alert type encodes the knowledge about a type
of attack. The component fact of a hyper-alert type tells
what kind of information is reported along with the alert
(i.e., detected attack), prerequisite speci(cid:12)es what must be
true in order for the attack to be successful, and consequence
describes what is true if the attack indeed succeeds. For the
sake of brevity, we omit the domains associated with the
attribute names when they are clear from the context.
Example 1 Consider the bu(cid:11)er over(cid:13)ow attack against the
sadmind remote administration tool. We may have a hyper-
alert type SadmindBu(cid:11)erOver(cid:13)ow = (fVictimIP, Victim-
Portg, ExistHost(VictimIP)^VulnerableSadmind (VictimIP),
fGainRootAccess(VictimIP)g) for such attacks. Intuitively,
this hyper-alert type says that such an attack is against the
host at IP address VictimIP. (We expect the actual values
of VictimIP are reported by an IDS.) For the attack to be
successful, there must exist a host at IP address VictimIP,
and the corresponding sadmind service must be vulnerable
to bu(cid:11)er over(cid:13)ow attacks. The attacker may gain root priv-
ilege as a result of the attack.