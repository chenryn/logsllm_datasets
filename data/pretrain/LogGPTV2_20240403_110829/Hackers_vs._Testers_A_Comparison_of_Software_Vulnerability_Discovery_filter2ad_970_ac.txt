200-10K
200
60K
50
2K
2K
10-50K
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
0-3
0-3
26-50
>500
>500
51-100
>500
101-500
0-3
0-3
11-25
51-100
>500
26-50
101-500
101-500
26-50
101-500
26-50
11-25
51-100
11-25
>500
101-500
26-50
TABLE I: Participant demographics.
necessarily representative of participant skill. It may instead
depend on their specialization. For example, participants who
focused on web applications reported ﬁnding more vulnera-
bilities, but these are generally considered less complex and
therefore are less proﬁtable in bug bounties [99].
V. VULNERABILITY DISCOVERY PROCESS
Perhaps our most surprising result is that hackers and testers
described a similar exploratory process for vulnerability ﬁnding.
They ﬁrst focus on learning what the program does, then
use their intuition and experience to ﬁnd ways to perform
unintended, malicious actions. Across participants, this process
was generally broken into ﬁve phases: Information Gathering,
Program Understanding, Attack Surface, Exploration, Vulnera-
bility Recognition, and Reporting. Participants described the
second (Program Understanding) through fourth (Exploration)
phases as a loop that they iterate until a vulnerability is found.
Figure 1 shows the process our participants described, as well as
the factors that inﬂuence the process. In all the category graphs
in this paper, we represent process categories as hexagons,
inﬂuencing categories as rectangles, and items that determine
the inﬂuencing categories as ovals. Additionally, we represent
relationships between categories with arrows whose direction
indicates the direction of inﬂuence. For readability, we color
arrows from inﬂuencers to process categories to indicate the
inﬂuence category they are derived from.
In this section, we brieﬂy outline the overall vulnerability
discovery process. In the following section, we discuss in detail
378
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
and the machine code that my C++ program produces.”
Attack surface. Our participants then identify how a user
can interact with the program (T=9, H=15). Their goal is to
determine what an attacker can manipulate and how they can
inﬂuence program execution. This allows our participants to
focus only on critical components of the program. H4H explains
“I look at things that I can touch, [for example] what can I
get to from the network. . . . That’s necessary to narrow down
the target[s].” Our participants discussed looking for direct
program inputs (T=9, H=10), such as website form ﬁelds, as
well as indirect inputs (T=4, H=10), such as data pulled from
their social media page or backend communication to a server.
Exploration. Next, practitioners explore the effect of a range
of inputs to see whether it is possible to perform some
malicious action by providing data the program mishandles.
H5M described this as “enumerating all the variable[s] and all
the parameters. . . I can quickly make a bunch of accounts and
see how the user ID changes and how it associates one user
with multiple devices.” Our participants described a range
of approaches to exploring program behavior, typically a
combination of executing the program with a set of test inputs
(T=9, H=11) and code inspection (T=6, H=12).
Of the tools mentioned during our interviews, almost all
were used in this phase. Our participants reported preferring
tools that automate simple, repetitive tasks so that they can
focus on more complicated problems (T=4, H=13). Such tasks
include quickly searching through code or network captures
(T=2, H=10), providing suggestions for test cases (T=5, H=3),
or making code easier to read (e.g., callee-caller method cross-
referencing, variable renaming) (T=1, H=6). We found that
hackers were much more likely to utilize tools to automate this
phase of the process, preferring dynamic analyses (e.g., fuzzing)
(T=5, H=12) over static analyses (e.g., symbolic execution)
(T=0, H=2), which matches Haﬁz and Fang’s ﬁndings [32].
On the other hand, seven hackers mentioned speciﬁcally
focusing on doing things manually, or using tools that aided
them in doing so, because they feel
this gives them a
competitive advantage (T=0, H=7). For example, H15W says
he avoids fully automated tools because “I assume that [large
companies] already run static and dynamic analysis tools. . . so
there’s not much of a point of me doing it.”
Vulnerability recognition. Participants iterate through the
prior three phases until they eventually identify a vulnerability.
This phase can be as simple as seeing a crash that produces
a known bad behavior or getting a tool output that indicates
a problem. However, in most cases our participants described
relying on their intuition and system knowledge to recognize
where an assumption is violated or a simple crash shows a
bigger security problem (T=6, H=14).
Reporting. Finally, once the vulnerability is found, it must
be reported. In their reports, our participants focus on making
sure the information is presented in a way that is easily
understandable by developers (T=8, H=11). Speciﬁcally, they
stressed communicating the importance of ﬁxing the vulnera-
Fig. 1: Vulnerability-ﬁnding process and inﬂuencing factors.
the factors which inﬂuence the execution of each phase, and
which exhibit greater differences between our two populations.
Information gathering. In the initial phase of vulnerability
discovery, practitioners quickly collect preliminary information
about the program to develop context prior to reading any
code or executing the program (T=6, H=14). This includes
ﬁnding any previous bugs reported in the program (T=3, H=9),
determining the age of the code and update history (i.e.,
looking at change logs to identify old or recently updated
code segments) (T=5, H=9), and identifying the libraries used
(T=1, H=2). This phase’s goal is to develop an understanding
of prior efforts, as well as the technologies the program is built
on. Information Gathering is also used speciﬁcally by some
hackers to decide whether to expend additional effort or move
on to a different target (T=0, H=3).
Program understanding. Next, our participants try to de-
termine how the program operates, how it interacts with its
environment (i.e., the user, network, etc.), and how individual
components interact with each other. Initially, this step is
based on communication with developers (T=7, H=0) or on
reading documentation (T=5, H=5), when available. Through
iterations of the loop (i.e., Program Understanding, Attack
Surface, and Exploration), as they execute the program and
read code, practitioners learn about the program by its behavior
(T=6, H=11). T4G described iteratively building up an idea of
the program structure by “touching a little bit everything, and
then you are organizing that structure in your head. . . [and]
you can formalize it [with the code].” H9G tries to get into the
developer’s mindset by rewriting the code himself. He starts
by thinking about the possible “inputs from the management
or business side that [go] into the speciﬁcation,” then he writes
a version of the program himself and “look[s] for matches
between the machine code I’m seeing [the original program]
379
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
bility (T=10, H=12). T4G explained that even after you ﬁnd
a vulnerability, “you have to have the weight of someone
else to agree that [it] is a bug. . . you do have to [convince]
someone that there’s a risk. . . It’s quite timely [time consuming],
running a ticket.” This emphasis on selling the importance of the
vulnerability mirrors the ﬁndings of Haney and Lutters [100].
Exception to the process. Four hackers in our study reported
a notable exception to the order of phases described above.
These hackers stated that they, in some cases, ﬁrst recognize a
vulnerability and reverse the normal process by looking for an
execution path to the insecure code (T=0, H=4). This occurs
whenever they ﬁnd known insecure code (e.g., memcpy or
printf in a C program) using a string search or other simple
static analysis. Then they trace the execution path back through
the code manually to ﬁnd any input that triggers the vulnerable
code. While this is a different order of operations, the general
phases of the process remain the same.
VI. INFLUENCING FACTORS
While all our participants described a similar process, their
implementation of this process differed. These differences can
be loosely grouped into four inﬂuencing factors: Vulnerability
Discovery Experience, Underlying System Knowledge, Access
to the Development Process, and Motivation. We found that
both groups of practitioners expect increases in Vulnerability
Discovery Experience and Underlying System Knowledge to
improve vulnerability discovery success. Further, we found
that hackers and testers reported similar levels of underlying
system knowledge, yet the most important difference between
our hackers and testers was in their vulnerability discovery
experience. To our surprise, we did not ﬁnd a straightforward
relationship between increased access to the development
process and successful vulnerability ﬁnding. Finally, the impact
of different motivational inﬂuencing factors was likewise more
complex than expected.
A. Vulnerability discovery experience
Overall, hackers and testers agreed that prior experience
ﬁnding vulnerabilities signiﬁcantly improves their vulnerability
discovery process (T=10, H=13); the key difference is that
hackers reported notably more experience than testers.
In particular, we ﬁnd that regardless of role, experience
improves a practitioner’s ability to efﬁciently identify the attack
surface, select test cases, recognize vulnerabilities, and sell the
resulting report. Both groups reported that the best approaches
to gaining the relevant experience are real-world code analysis,
hacking exercises, learning from their community, and prior
bug reports. However, hackers were more likely than testers to
rely on hacking exercises and bug reports. Further, hackers are
exposed to a wider variety of vulnerabilities across all these
learning approaches. Figure 2 shows the effect of vulnerability
discovery experience on phases of the process and the ways
practitioners develop experience.
Fig. 2: Vulnerability Discovery Experience Category Graph.
1) How does experience affect the process? Across both
groups of practitioners, participants identiﬁed several key ways
that experience adds to vulnerability discovery success.
Helps recognize a problem quickly. Our participants fre-
quently mentioned learning to recognize patterns that indicate
a problem based on prior experience (T=6, H=14). For example,
as he explores a program for possible bugs, H10H stated that
he has a set of potential problems that he knows could occur
based on prior experience. He said “I know that if there’s a loop
[that’s] going through my input, it could be going out of bounds
on the array, could be underﬂow, overﬂow.” Relatedly, most
participants discussed maintaining a mental or physical list of
all the vulnerabilities they have seen through past experience
and checking for these whenever they test a new piece of
software (T=9, H=11).
Informs test case selection. In complex real-world systems,
it is impractical to perform a complete search of all possible
program inputs, so our participants stated that they rely on their
intuition, learned from prior experience, to triage (T=9, H=8).
For example, T3W discussed creating a list of standard test
cases “based on things we’ve found from Rapid7 [web security
scanning tool]” or after asking “one of the developers. . . if
there is other security testing we should be doing.” From her
experience, she “broadened the scope of security testing at
the time [was just SQL injection], and brought in cross-site
scripting.” H2H explained how he built a set of ﬁle formats
that he tries to open “in some random image parser, and half
the time it would [cause a crash].” He said that he created
his list based on his experience working with other security
professionals in an “apprentice”-like situation where “You
watch them, they watch you, and soon you’re doing it on your
own.”
Helps identify the attack surface. We observed that only
participants with more experience mentioned indirect inputs
as part of the attack surface (T=4, H=10). Indirect inputs
are more difﬁcult to identify because they require a complex
combination of events that may not occur frequently. Typically,
our practitioners suggested that they only know to look for
these complex interactions because they have seen something
similar previously. T3W discussed learning about indirect inputs
380
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:29:31 UTC from IEEE Xplore.  Restrictions apply. 
after incidentally ﬁnding a vulnerability in the way a program
accepted user input from a LinkedIn third-party login service,
“as soon as I found the LinkedIn problem, I made sure to test
[FB and Twitter] to make sure [they were processed correctly].
And if we did allow login with another 3rd party in the future,
I would check that too.”
Helps describe a vulnerability’s impact. Testers and hackers
leverage prior experience to explain how a vulnerability could
be used by a malicious actor when arguing its impact to
developers. T10W recalled a time where he used the story
of a denial of service attack, caused by the same type of
vulnerability, to explain the importance of ﬁxing a new problem
quickly.
Without experience, slower and more random. Without
prior experience guiding triage, our practitioners relied on
stumbling across vulnerabilities incidentally (T=5, H=4); or on
their curiosity (T=8, H=5), personal creativity (T=3, H=6), and
persistence (T=2, H=9) with ample time (T=4, H=9) to dig
through the complexity of a program. Such incidental discovery
is time consuming and haphazard, with little consistency in
results. H1H described looking for a vulnerability in a complex
program and “spent the whole summer on it and failed”, but
after reviewing bug reports for similar programs, he returned
to searching the same program and found a vulnerability after
“about a month”. Thus, prior experience provides a useful and,
in the opinion of some of our hackers, critical stimulus to the
bug ﬁnding process (T=0, H=4).
2) How is experience developed? Our participants developed
experience through hands-on practice, supplemented by support
from their peers and by reading other practitioners’ vulnerability
reports. Most notably, hackers reported a greater variety of
learning methods, and more diverse experiences within each
method, than testers; as a result, hackers developed more, and
more valuable, experience.
Gained by searching real-world programs. All of our testers
mentioned gaining experience through their job, supporting
ﬁndings from Lethbridge et al [35]. Six reported gaining
vulnerability-discovery experience by incidentally ﬁnding secu-
rity vulnerabilities while seeking out functionality bugs. Four
reported learning something from their company’s security-
training best practices, but also reported that these best practice
guides provide, at best, limited information.
The hackers in our study also develop hands-on experience
through employment, which tended to be in security-speciﬁc
roles such as full-time bug bounty participation and contracted
penetration testing (H=13). As might be expected, this security-
focused experience provides a strong advantage. Additionally,
the ad-hoc and frequently changing nature of hackers’ em-
ployment exposes them to a wider variety of programs, and
therefore types of vulnerabilities, compared to testers who