# 31丨案例：当磁盘参数导致I/O高的时候，应该怎么办？在大部分的性能项目中，当系统调优到一定程度的时候，性能的瓶颈往往会体现在两类计数器上：一个是CPU，另一个就是磁盘 I/O了。所以我们也经常会在一些性能优化的文章中看到两个分类，分别是 CPU密集型和磁盘 I/O 密集型。有人说为什么不说内存呢？内存是那么重要。不是说内存不会成为瓶颈，只不过内存的瓶颈基本上都可以转嫁给CPU 和磁盘I/O。当内存不够的时候，大不了就是清理得快一点。内存能表现出来的，就是满不满，而谁去清理呢？那就是CPU 了。清理得快就得 CPU转得快。 我们经常会听到有人说什么性能优化到最后就是"空间转时间、时间转空间的优化"。如此带有禅意的一句话，其实意思就是，CPU不够用，就扩大内存；内存不够，就让 CPU计算得更快一些。举个例子，当我们需要在内存中使用很多变量时，如果内存不够，就会导致CPU不断清理内存中没被引用的变量来释放内存，这就导致了释放内存的动作会消耗更多的CPU。而这时，我们就可以用增加内存的方式，让 CPU不那么繁忙。但这个"空间、时间转化"的论点并不会在所有的场景下成立。比如说一个应用并不需要多大内存，就是纯计算型的，那你加内存也没啥用。另外这里提到的"空间"也不是硬盘，因为如果CPU不够用，拿再多磁盘补也无济于事。所以这句话只能是做为高深谒语让初入性能的小白们仰望，实际上适用的场景非常少。而磁盘 I/O和内存有很大的区别。只要系统需要保存运行过程中留下的数据，那就必然会用到磁盘I/O。分析磁盘 I/O 的时候，相对于其他的分析环节还是要复杂一些，因为磁盘I/O 栈是比较长的。有了 Direct I/O 技术之后，磁盘 I/O栈短了一段，速度快了，但是同样也没有给性能测试分析人员带来什么福音，因为从分析的角度来说，我们看计数器并没有减少什么。在性能分析过程中，操作系统是绕不过去的一个环节。在当前的技术栈中，我们仍然要把操作系统当成一个非常重要的环节。现在对于 I/O的分析和判断，大部分还停留在磁盘百分比、队列、磁盘延时之类上。可是这样的计数器的值多了，少了，你要干什么呢？怎么解决它呢？是磁盘参数有问题，还是应用有问题？还是磁盘硬件能力就那样了？这是性能分析人员应该给出的答案,可是有很多性能测试工程师还真的给不出来这样的答案，甚至有些人连哪个线程导致的I/O高都判断不出来。至少现在的状态说明了，性能测试行业还远远不够成熟，我们还有很多的机会。现在我们所说的 I/O，基本上把 File I/O 和 Disk I/O都说进去了，所以在分析上，层级更是非常模糊。如下图所示的一个 I/O栈： ![](Images/2f24614120519958ee6182504590714b.png)savepage-src="https://static001.geekbang.org/resource/image/6f/ee/6fee04695be068f0622fbf67e55f01ee.png"}(此图来自于：https://www.thomas-krenn.com/de/wikiDE/images/b/ba/Linux-storage-stack-diagram_v4.0.pngslate-object="inline")在这个图中，我们可以明确看到磁盘 I/O栈有多长。从应用层开始，产生系统调用，再通过 visual FS Layer → FS Layer→ Block Layer这样一层一层地调用下去，最后才写到了硬件存储里。当然还有一层，我们需要关注的就是从系统的全局状态到具体的线程，这个我在操作系统那一篇的I/O 部分已经描述过。下面我们来看一个 I/O高的分析案例。案例现象在这个项目的压力测试过程当中，发现了经典的现象：1.       **TPS 上不去**        ；        2.       **硬件资源用不上**        。        应该说，性能分析要是分类比较宽泛，基本上是两种。**第一种是资源用不上，TPS上不去，响应时间随压力而增加**，如下图所示：![](Images/2fe5fd3757d98c9d2385f6db0c2ad3d6.png)savepage-src="https://static001.geekbang.org/resource/image/11/ce/1199fc4d93022aee612a2aca437278ce.png"}**第二种是资源用得上，TPS上不去，响应时间随压力而增加**。如下图所示：![](Images/229313564e1fef79636bfa3a46193af7.png)savepage-src="https://static001.geekbang.org/resource/image/72/6d/729cfa4bad0f164ea88e55ae71e8e06d.png"}这样的划分方式看似有调侃味道，却是很多人疑惑的起点。为什么这么说呢？我们在开始做性能分析的时候，经常会面对这种情况，那就是资源用不上去。也就是路不够宽，硬件资源才用不上的。我们要解决的，就是把路扩宽一些。但是，当我们面对一些客户或领导的时候，如果去汇报某资源使用率达到 100%这样高的值的时候，有可能得到的一个反馈是，能不能把资源使用率降下来，因为资源使用率高会让人有种不安全感，而TPS 反而不是关注的重点。这就让我们很疑惑：TPS上去了，资源必然用得多呀，难道让资源使用率稳定保持在 50%，而 TPS蹭蹭往上涨吗？这不现实呀。我的建议是，不用怕资源使用率高，做为专业性能分析人员，更应该怕的是资源使用率不高！在这个例子中，一开始同事跟我描述的时候，说**资源怎么也用不上去，TPS也上不去**。这样的描述很常见。还是看看压力结果，如下所示：![](Images/8589d9097a1bb8c1e788969a2449b559.png)savepage-src="https://static001.geekbang.org/resource/image/b1/33/b1486cc6adfe2d0a3ecbe3f2685f1133.png"}（场景开始时报了少量的错，不过这不是我们这个案例要分析的部分，请看官忽略。）像这种描述，基本上没办法让人分析，因为信息太少了。特别是有些人直接给一个固定线程数的压力结果，用来描述资源上不去的情况，这就更得不到有用的信息了，所以问性能问题的人一定要注意收集足够的信息，不然只能让人从头查一遍。分析过程因为没有什么具体的信息，所以我只能让同事把压力再压起来。我登录到服务器上之后，顺手执行了一个 top命令： ![](Images/75f1fa354cdc6f56bbb748d28898e160.png)savepage-src="https://static001.geekbang.org/resource/image/b1/7d/b1c1e4b1cd41d7481086388994f4997d.png"}这里给个小提醒，执行 top 的时候一定要习惯性地点一下数字1，这样可以把所有的 CPU 都列出来，因为我要看到每个 CPU的各个计数器的使用率。别看这个动作不起眼，就算是这一个小小的操作，也是工作经验的积累。果不其然，看到了一个问题，那就是上图中 CPU0 的 wa 达到了72%。像这样的问题，如果不看每个 CPU的每个计数器，是发现不了的。看到这样的东西，我们要有个基本的判断，对于一般的 Java 应用来说，I/O线程数基本上不会是 1个，除非是特别的理由，所以这种情况还是很少的。不过既然是 I/O 的问题导致了 wa CPU 使用率高，那么我来看一下 CPU的热点在哪个层面。这是我在工作中经常执行的一个动作，因为我不想在后面的分析过程中偏离方向，而看CPU 热点可以让我记得这个方向。如下图所示：![](Images/0c4c53d3dd7e85daa3c6ca8330129cc6.png)savepage-src="https://static001.geekbang.org/resource/image/e1/2e/e1080375920d5fd944d2df9dadaf8e2e.png"}有人说，即然 wa CPU 使用率已经高了，接下去直接看磁盘 I/O不就行了，看不看 CPU 热点还重要吗？我要说，当然重要！看到前面的磁盘 I/O栈了吗？那么长，怎么知道是在哪一层呢？这是定向细化分析过程中的经验之一。在 CPU 热点中我们看到了，是内核模块中的 blk_queue_bio 消耗的 CPU大。blk_queue_bio 是用来做 I/O 调度合并的，可以对 I/O请求进入后向、前向合并操作，互斥方式就是加锁。根据它我们就可以知道，这是一个有 queue的调度过程，再接着看它下面的几个函数也可以看出，都是 kernel级的调用，并没有 user 级的调用，这几个函数基本上也说明了当前系统忙于journal 写。接着执行 iotop，看是哪个进程在做这个动作。这里可以看到 jbd2，和上面CPU 热点的函数也是对应得上的。![](Images/3e0cda6fb6c1a3111ea163b894024f03.png)savepage-src="https://static001.geekbang.org/resource/image/6a/fc/6a7690bbf843e84e1eeb806093a390fc.png"}那么 jbd2 是个啥玩意呢？jbd2 英文名是这样的：Journaling Block Device2。 它是跟着 ext4格式来的，当然它也可以在其他磁盘格式下工作。这个进程的工作原理是这样的：文件系统写入数据，要提交给驱动程序，而jbd2 就是在文件系统调用驱动之前工作的。文件系统要先调用 jbd2，然后 jbd2会根据系统的设置（设置有writeback、ordered、journal），进行数据的备份，然后再让文件系统提交数据。当文件系统将数据写入了块设备之后，jbd2就会把备份的数据删除。如果文件系统写块设备时出了问题（比如说可悲的断电），那jbd2这里还有一个备份，在进行完整性检查时就会把数据补全，所以数据不会丢。jbd2就是这样保证数据的完整性的。但是！对嘛，我就喜欢说但是。jbd2保证的数据完整性也只是一个原子操作的完整性，即一个原子操作如果操作了 2M的数据，它就只能保证这 2M 的数据不会丢失。如果你一下子操作了 1T的数据，jbd2 也不能保证完整性。jbd2 有一个参数 barrier，它用来开启磁盘屏障。就是设置一个栅栏，要先把barrier 之前的数据全都写到磁盘设备之后，才会写 barrier之后的数据，也就是说它是用来保证原子操作中数据的完整性的。当然了，开启barrier的一个后果就是性能下降。了解了这些内容之后，我们就要判断一下了。这个应用有没有必要用这个功能来保证原子操作的完整性？我考虑了一下之后，觉得这个应用就是写日志而已，也没有其他什么重要的东西是要写日志的，重要的业务数据都写到数据库去了。所以，没必要保证数据写入的完整性，就算丢了一些日志数据又怎么样呢？如果真的就那么寸，应用出现大bug，恰好块设备也出问题，或者断电，那真的只有烧香拜佛了。于是我觉得这个功能不用也罢，把原理说明白之后，和架构组、开发组、运维组以及领导层们沟通了一圈，告诉了他们原理，实在是没有打开的必要。最后大家一致同意：关掉！我们再回过头来看下这个参数：    [root@主机A]
# cat /proc/mounts     /dev/mapper/data_lvm-data_lv /data ext4 rw,relatime,barrier=1,data=ordered 0 0 上面的这个barrier=1，就是我们要找的目标。想关了它，就是挂载磁盘的时候使用挂载选项-o barrier=0 或者 nobarrier。我这里是直接设置为 0的。 你也可以直接关掉 journal功能：     tune2fs -o journal_data_writeback /dev/mapper/data_lvm-data_lv tune2fs -O "^has_journal" /dev/mapper/data_lvm-data_lv e2fsck -f /dev/mapper/data_lvm-data_lv问题解决之后我们再来看下问题解决后的压力工具结果：![](Images/98bf411e6834e04da2340612ce132889.png)savepage-src="https://static001.geekbang.org/resource/image/74/3d/74a3e5ceb53b45db668e768d8b7f843d.png"}从压力结果来看，同样的压力之下，TPS增加了一倍，响应时间快了一倍。top 如下所示：![](Images/1d901d7073b6faa756a229ce547da68d.png)savepage-src="https://static001.geekbang.org/resource/image/ab/7d/ab9a6ef19d55c87f0b380f9a6dcf937d.png"}集中的 wa CPU也消失不见了，现在使用的也挺均衡的了。iotop： ![](Images/7b1d6dc8d8304897d99a7a6b7ceb9b01.png)savepage-src="https://static001.geekbang.org/resource/image/85/ac/8534cc3d96242eb3f017fbd84735b6ac.png"}在 I/O top 的结果中，也看不到 I/O 非常高的 jbd2了。 问题得到了完美地解决。总结不管是什么样的性能问题，其实从分析思路上仍然逃不开我一直提到的思路------那就是一个分析的完整链路。当你一层一层往下找问题时，只要抓住了重点，思路不断，找到根本原因就可以解决问题。在这个 I/O 的问题中，难点在于怎么能知道 jbd2的原理和参数。应该说，不管是谁，都不能保证自己的知识体系是完整的，那怎么办呢？查资料，各种学习，看源码，看逻辑。实在看不懂，那也没办法，接着修炼基础内功呗。所以说性能测试行业中，经常只测不分析，也是因为做性能分析需要的背景知识量有点大，还要不断分析各种新的知识点。不过也就是因为如此，性能测试和性能分析才真的有价值。只测不调只是做了一半工作，价值完全体现不出来。思考题最后问你两个问题吧：为什么 TPS上不去时，资源用不上才是更让人着急的问题？以及为什么要在 CPU 高时查看CPU 热点函数呢？欢迎你在评论区写下你的思考，我会和你一起交流。也欢迎你把这篇文章分享给你的朋友或者同事，一起交流一下。
# 32丨当Postgres磁盘读引起I/O高的时候，应该怎么办？在性能分析的人眼里，性能瓶颈就是性能瓶颈。无论这个性能瓶颈出现在代码层、操作系统层、数据库层还是其他层，最终的目的只有一个结果：解决掉！ 有人可能会觉得这种说法过于霸道。 事实上，我要强调的性能分析能力，是一套分析逻辑。在这一套分析逻辑中，不管是操作系统、代码还是数据库等，所涉及到的都只是基础知识。如果一个人都掌握这些内容，那确实不现实，但如果是对一个性能团队的要求，我觉得一点也不高。 在性能测试和性能分析的项目中，没有压力发起，就不会有性能瓶颈，也就谈不上性能分析了。所以每个问题的前提，都是要有压力。 但不是所有的压力场景都合理，再加上即使压力场景不合理，也能压出性能瓶颈，这就会产生一种错觉：似乎一个错误的压力场景也是有效的。 我是在介入一个项目时，首先会看场景是否有效。如果无效，我就不会下手去调了，因为即使优化好了，可能也给不出生产环境应该如何配置的结论，那工作就白做了。 所以要先调场景。 我经常会把一个性能测试项目里的工作分成两大阶段： 整理阶段在这个阶段中，要把之前项目中做错的内容纠正过来。不止有技术里的纠正，还有从上到下沟通上的纠正。 调优阶段这才真是干活的阶段。 在这个案例中，同样，我还是要表达一个分析的思路。 案例问题描述这是一个性能从业人员问的问题：为什么这个应用的 update用了这么长时间呢？他还给了我一个截图： ![](Images/2887d7a6427e170160a93332875c46b7.png)savepage-src="https://static001.geekbang.org/resource/image/fe/ac/fe83f42fd8b130b561e2a8f79c7cabac.png"}从这个图中可以看到时间在 100 毫秒左右。根据我的经验，一个 SQL 执行100ms，对实时业务来说，确实有点长了。 但是这个时间是长还是短，还不能下结论。要是业务需要必须写成这种耗时的SQL 呢？ 接着他又给我发了 TPS图。如下所示： ![](Images/4a21a28ba29dd8b3af6e2c960a9f3ce5.png)savepage-src="https://static001.geekbang.org/resource/image/ee/24/ee0ec6e2a7038611ccb30d7b5bf66824.png"}这个 TPS 图确实......有点乱！还记得前面我对 TPS的描述吧，在一个场景中，TPS是要有阶梯的。 如果你在递增的 TPS 场景中发现了问题，然后为了找到这个问题，用同样的TPS级别快速加起来压力，这种方式也是可以的。只是这个结果不做为测试报告，而是应该记录到调优报告当中。 而现在我们看到的这个 TPS 趋势，那真是哪哪都挨不上呀。如此混乱的TPS，那必然是性能有问题。 他还告诉了我两个信息。 1.       有 100 万条参数化数据；        2.       GC 正常，dump    文件也没有死锁的问题。        这两个信息应该说只能是信息，并不能起到什么作用。另外，我也不知道他说的"GC正常"是怎么个正常法，只能相信他说的。 以上就是基本的信息了。 分析过程照旧，先画个架构图出来看看。 每次做性能分析的时候，我几乎都会先干这个事情。只有看了这个图，我心里才踏实。才能明确知道要面对的系统范围有多大；才能在一个地方出问题的时候，去考虑是不是由其他地方引起的；才能跟着问题找到一条条的分析路径...... 下面是一张简单的架构图，从下面这张架构图中可以看到，这不是个复杂的应用，是个非常典型的微服务结构，只是数据库用了PostgreSQL 而已。 ![](Images/148d3e3d1015c430c2ae542ee49a5a4d.png)savepage-src="https://static001.geekbang.org/resource/image/21/3d/21e32cd936482c970abb2ef02007563d.jpg"}由于这个问题反馈的是从服务集群日志中看到的 update慢，所以后面的分析肯定是直接对着数据库去了。 这里要提醒一句，我们看到什么现象，就跟着现象去分析。这是非常正规的思路吧。但就是有一些人，明明看着数据库有问题，非要瞪着眼睛跟应用服务器较劲。 前不久就有一个人问了我一个性能问题，说是在压力过程中，发现数据库 CPU用完了，应用服务器的 CPU 还有余量，于是加了两个数据库CPU。但是加完之后，发现数据库 CPU 使用率没有用上去，反而应用服务器的 CPU用完了。我一听，觉得挺合理的呀，为什么他在纠结应用服务器用完了呢？于是我就告诉他，别纠结这个，先看时间耗在哪里。结果发现应用的时间都耗在读取数据库上了，只是数据库硬件好了一些而已。 因为这是个在数据库上的问题，所以我直接查了数据库的资源。 ![](Images/621703d9b98ad30404bdc26ddcea9f3b.png)savepage-src="https://static001.geekbang.org/resource/image/dc/78/dcacb613ed1d09dfa56d500c10307e78.png"}查看 vmstat，从这个结果来看，系统资源确实没用上。不过，请注意，这个bi 挺高，能达到 30万以上。那这个值说明了什么呢？我们来算一算。 bi是指每秒读磁盘的块数。所以要先看一下，一块有多大。     [root@7dgroup1 ~]