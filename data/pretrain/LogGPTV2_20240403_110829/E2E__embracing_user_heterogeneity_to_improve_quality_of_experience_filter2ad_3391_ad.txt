### Decision Caching and QoE Optimization

The system ensures that the same decision assignment can achieve near-optimal Quality of Experience (QoE) even if some inputs to the end-to-end (E2E) decision-making policy have slightly changed. To leverage this, E2E caches its decision assignments in a decision lookup table, which the shared-resource service can query for every new request. The keys in this table are the buckets of external delays, and the corresponding values are the decisions assigned to each bucket. The exact definition of these decisions varies depending on the use case. For example, in a distributed database, the decision for a specific external delay bucket is the probability of sending a request to each replica if the request’s external delay falls within that bucket.

The lookup table is updated only when one of the input variables has changed by a "significant amount." The policy for determining what constitutes a significant change is orthogonal and not prescribed; it could be, for instance, if the Jensen-Shannon divergence between the new and old distributions exceeds a certain threshold.

### Fault Tolerance of the E2E Controller

In E2E, a request must wait for its resource allocation decision from the E2E controller, which can become a single point of failure for the entire system. This risk can be mitigated in three ways:

1. **Caching Decisions**: If the E2E controller fails, the shared-resource service can still make QoE-aware decisions by looking up the request’s external delay in the most recently cached decision lookup table.
2. **Replication**: The E2E controller is replicated with the same input state (QoE model, external delay model, server-side delay model). When the primary controller fails, a secondary controller can take over using standard leader election mechanisms.
3. **Fallback Mechanism**: In the event of a total E2E failure, the shared-resource service can bypass E2E and revert to its default resource allocation policy.

### Use Cases

We demonstrate the practical usefulness of E2E by integrating it into two popular web infrastructure services: replica selection in a distributed database and message scheduling in a message broker. In both cases, E2E makes minimal changes to the shared-resource service and relies only on the control interface exposed by them. The overhead of E2E is evaluated in §7.3.

#### Use Case #1: Distributed Database

We chose Cassandra as the distributed database and used E2E to select the replica for each request. Specifically, we made two modifications:

1. **Replica Selection Logic**: We modified the existing replica selection logic (getReadExecutor of ReadExecutor) in the Cassandra client. Our new logic stores the decision lookup table received from the E2E controller in a local data structure. When a new request arrives, it looks up the request’s external delay in the table to get the selected replica’s IP.
2. **Client Service Callback Function**: We modified the client service callback function (in RequestHandler) to track the load (number of concurrent requests) and the observed (server-side) delay of each replica. In practice, the replication level, i.e., the number of replicas for each key, is usually much smaller than the total number of servers. A simple replication strategy, adopted by Cassandra and other databases like MongoDB, is to divide the servers into replica groups and store a copy of the entire database in each group. This strategy fits well with E2E, which now simply needs to choose a replica group for each incoming request. It also allows E2E to affect server-side delays by ensuring that some replica groups are less loaded and used to process QoE-sensitive requests.

#### Use Case #2: Message Broker

We chose RabbitMQ as the message broker (other message brokers can work similarly with E2E). RabbitMQ manages its resources using priority queues and associates each request with a priority level. High-priority requests are served before low-priority ones. Similar to the Cassandra implementation, we made two changes to integrate E2E:

1. **E2E Controller Logic**: We wrote the E2E controller logic in a Python script and passed it to RabbitMQ as the default scheduling policy (through queue_bind) when the RabbitMQ service is initialized.
2. **Per-Request Callback Function**: We modified the per-request callback function (confirm_delivery) to track each request’s progress and the queuing delay in the message broker.

### Implementation Details

E2E requires three models as input to run. Below are our realizations of these models, though other approaches are possible:

- **QoE Model**: Our E2E prototype uses QoE models derived from Microsoft traces and an MTurk user study, detailed in Appendix B. The QoE model needs to be updated only when the web service content changes substantially.
- **External Delay Model**: Our E2E prototype builds the external delay distribution from recent per-request external delay measurements. Currently, the external delays are provided by our traces and are not calculated in real-time for each request, though this is necessary in a production deployment. We use batched updates to reduce the overhead of keeping the distribution up-to-date. We found that updating the external delay distribution every 10 seconds is sufficient.
- **Server-Side Delay Model**: Our prototype builds the server-side delay model offline by measuring the service delay distributions induced by different resource allocations. For the distributed database, we measure the processing delays of one server under different input loads. For the message broker, we consider both the number of requests at each priority level and the total number of requests at higher priority levels.

### Evaluation

We evaluate E2E using a combination of trace-driven simulations and real testbed experiments. Our key findings are:

- **QoE Improvement**: Users spend 11.9% more web session time (more engagement) compared to the default resource allocation policy in our traces, accounting for 77% of the best-possible improvement if server-side delays were zero.
- **Low Overhead**: E2E incurs only 0.15% additional server-side delay and requires 4.2% more compute resources per request.
- **Robustness to Estimation Errors**: E2E can tolerate moderate estimation errors (up to 20%) on the external delays while still retaining over 90% of the QoE improvement attainable without errors.

### Methodology

Both our trace-driven simulator and our testbeds use the external delay model derived from our traces and the QoE model from Figure 3. The simulator is described in more detail in §2.3.

**Testbed Setup**: To complement our trace-driven simulations, we created two real testbeds on Emulab—one for Cassandra and one for RabbitMQ. We feed requests from our traces to each testbed in chronological order with their recorded external delays, and use the actual testbed processing time as the server-side delays. We speed up the replay by reducing the interval between two consecutive requests by a speedup ratio.

**Baselines**: We compare E2E against two baseline policies:
- **Default Policy**: Unaware of the heterogeneity of QoE sensitivity. In the simulator, it gives each request its recorded server-side delay. In RabbitMQ, it uses First-In-First-Out (FIFO) queuing. In Cassandra, it balances load perfectly across replicas.
- **Slope-Based Policy**: Aware of the heterogeneity of QoE sensitivity but suffers from the problem described in §3.2. In the simulator, it gives the shortest server-side delay to the request whose external delay has the steepest slope in the QoE model. In RabbitMQ, it gives the highest priority to the request whose external delay has the steepest slope in the QoE model.

**Metric of QoE Gain**: We measure the QoE gain of E2E (and its variants) by the relative improvement of their average QoE over that of the default policy, i.e., (QE2E − Qdefault)/(Qdefault).

### End-to-End Evaluation

**Overall QoE Gains**: Figure 14 compares the QoE gains of E2E and the slope-based policy over the existing default policy in our traces and testbeds. E2E achieves 12.6–15.4% better average QoE than the default policy, whereas the slope-based policy has only 4–8% improvement. This suggests that E2E addresses the limitation of the slope-based policy discussed in §3.2.

**Better QoE-Throughput Tradeoffs**: Figure 15 compares the QoE of E2E and the default policy under different loads. E2E strikes a better QoE-throughput tradeoff than both the default policy and the slope-based policy.

### Microbenchmarks

We examine the overheads incurred by E2E in computing cost, decision delay, and fault tolerance.

**System Overhead**: Figure 16 shows the additional overhead of E2E in CPU and RAM usage. The overhead of E2E is several orders of magnitude lower than the total overhead of running the Cassandra or RabbitMQ testbeds themselves. Moreover, the CPU and RAM overheads grow more slowly than those of the testbed service as the load increases.

**Decision Delay**: Figure 17 shows the effectiveness of our two decision delay-reduction optimizations using the Cassandra testbed. Spatial coarsening (bucketization of external delays) reduces the decision delay by four orders of magnitude, and temporal coarsening (caching E2E decisions in a lookup table) reduces the decision delay by another two orders of magnitude. The resulting per-request response delay is well below 100µs, less than 0.15% of Cassandra’s response delay.

At the same time, we see that these reductions in decision-making delay have only a marginal impact on QoE. Note that E2E does not need to make a decision on the arrival of each request due to these optimizations. Instead, decisions are made periodically and cached.