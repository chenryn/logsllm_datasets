Applying Data Mining Algorithms to Calculate the
Quality of Service of Workflow Processes
Jorge Cardoso
Department of Mathematics and Engineering
9000-390 Funchal, Portugal
PI:EMAIL
Abstract. Organizations have been aware of the importance of Quality of
Service (QoS) for competitiveness for some time. It has been widely recognized
that workflow systems are a suitable solution for managing the QoS of
processes and workflows. The correct management of the QoS of workflows
allows for organizations to increase customer satisfaction, reduce internal costs,
and increase added value services. In this paper we show a novel method,
composed of several phases, describing how organizations can apply data
mining algorithms to predict the QoS for their running workflow instances. Our
method has been validated using experimentation by applying different data
mining algorithms to predict the QoS of workflow.
Keywords: Quality of Service, Data Mining, Business Process, Workflow.
1 Introduction
The increasingly global economy requires advanced information systems. Business
Process Management Systems (BPMS) provide a fundamental infrastructure to define
and manage several types of business processes. BPMS, such as Workflow
Management Systems (WfMS), have become a serious competitive factor for many
organizations that are increasingly faced with the challenge of managing e-business
applications, workflows, Web services, and Web processes. WfMS allow
organizations to streamline and automate business processes and reengineer their
structure; in addition, they increase efficiency and reduce costs.
One important requirement for BMPS and WfMS is the ability to manage the
Quality of Service (QoS) of processes and workflows [1]. The design and
composition of processes cannot be undertaken while ignoring the importance of QoS
measurements. Appropriate control of quality leads to the creation of quality products
and services; these, in turn, fulfill customer expectations and achieve customer
satisfaction. It is not sufficient to just describe the logical or operational functionality
of activities and workflows. Rather, design of workflows must include QoS
specifications, such as response time, reliability, cost, and so forth.
One important activity, under the umbrella of QoS management, is the prediction
of the QoS of workflows. Several approaches can be identified to predict the QoS of
workflows before they are invoked or during their execution, including statistical
algorithms [1], simulation [2], and data mining based methods [3, 4].
The latter approach, which uses data mining methods to predict the QoS of
workflows, has received significant attention and has been associated with a recent
new area coined as Business Process Intelligence (BPI). In this paper, we investigate
the enhancements that can be made to previous work on BPI and business process
quality to develop more accurate prediction methods.
The methods presented in [3, 4] can be extended and refined to provide a more
flexible approach to predict the QoS of workflows. Namely, we intend to identify the
following limitations that we will be addressing in this paper with practical solutions
and empirical testing:
1. In contrast to [4], we carry out QoS prediction based on path mining and by
creating a QoS activity model for each workflow activity. This combination
increases the accuracy of workflow QoS prediction.
2. In [4], time prediction is limited since workflow instances can only be classified
to “have” or “not to have” a certain behavior. In practice, it means that it is only
possible to determine that a workflow instance will have, for example, the “last
more than 15 days” behavior or will not have that behavior. This is insufficient
since it does not give an actual estimate for the time a workflow will need for its
execution. Our method is able to deduce that a workflow wi will probably take 5
days and 35 minutes to be completed with a prediction accuracy of 78%.
3. In [4], the prediction of the QoS of a workflow is done using decision trees. We
will show that MultiBoost Naïve Bayes outperforms the use of decision trees to
predict the QoS of a workflow.
This paper is structured as follows: In Section 2, we present our method of carrying
out QoS mining based on path mining, QoS activity models, and workflow QoS
estimation. Section 3 describes the set of experiments that we have carried out to
validate the QoS mining method we propose. Section 4 presents the related work in
this area. Finally, section 5 presents our conclusions.
2 Motivation
Nowadays, a considerable number of organizations are adopting workflow
management systems to support their business processes. The current systems
available manage the execution of workflow instances without any quality of service
management on important parameters such as delivery deadlines, reliability, and cost
of service.
Let us assume that a workflow is started to deliver a particular service to a
customer. It would be helpful for the organization supplying the service to be able to
predict how long the workflow instance will take to be completed or the cost
associated with its execution. Since workflows are non-deterministic and concurrent,
the time it takes for a workflow to be completed and its cost depends not only on
which activities are invoked during the execution of the workflow instance, but also
depends on the time/cost of its activities. Predicting the QoS that a workflow instance
will exhibit at runtime is a challenge because a workflow schema w can be used to
generated n instances, and several instances w (i≤n) can invoke a different subset of
i
activities from w. Therefore, even if the time and cost associated with the execution
of activities were static, the QoS of the execution of a workflow would vary
depending on the activities invoked at runtime.
For organizations, being able to predict the QoS of workflows has several
advantages. For example, it is possible to monitor and predict the QoS of workflows
at any time. Workflows must be rigorously and constantly monitored throughout their
life cycles to assure compliance both with initial QoS requirements and targeted
objectives. If a workflow management system identifies that a running workflow will
not meet initial QoS requirements, then adaptation strategies [5] need to be triggered
to change the structure of a workflow instance. By changing the structure of a
workflow we can reduce its cost or execution time.
3 QoS Mining
In this section we focus on describing a new method that can be used by organizations
to apply data mining algorithms to historical data and predict QoS for their running
workflow instances. The method presented in this paper constitutes a major and
significant difference from the method described in [4]. The method is composed of
three distinct phases (figure 1) that will be explained in the following subsections.
Fig. 1. Phases of workflow QoS mining
In the first phase, the workflow log is analyzed and data mining algorithms are
applied to predict the path that will be followed by workflow instances at runtime.
This is called path mining. Path mining identifies which activities will most likely be
executed in the context of a workflow instance. Once we know the path, we also
know the activities that will be invoked at runtime. For each activity we construct a
QoS activity model based on historical data which describes the runtime behavior
(duration and cost) of an activity. In the last phase, we compute the QoS of the overall
workflow based on the path predicted and from the QoS activity models using a set of
reduction rules.
3.1 Path Mining
As we have stated previously, the QoS of a workflow is directly dependent on which
activities are invoked during its execution. Different sets of activities can be invoked
at runtime because workflows are non-deterministic. Path mining [6, 7] uses data
mining algorithms to predict which path will be followed when executing a workflow
instance.
Definition (Path): A path P is a continuous mapping P: [a, b] → Co, where P(a) is the
initial point, P(b) is the final point, and Co denotes the space of continuous functions.
A path on a workflow is a sequence {t , t , …, t } such that {t , t }, {t , t }, …,{t , t }
1 2 n 1 2 2 3 n-1 n
are transitions of the workflow and the t are distinct. Each t is connected to a
i i
workflow activity.
A path is composed of a set of activities invoked and executed at runtime by a
workflow. For example, when path mining is applied to the simple workflow
illustrated in figure 2, the workflow management system can predict the probability of
paths A, B, and C being followed at runtime. Paths A and B have each 6 activities,
while path C has only 4 activities. In figure 2, the symbol ⊕ represented non-
determinism (i.e., a xor-split or xor-join).
Fig. 2. Path mining
To perform path mining, current workflow logs need to be extended to store
information indicating the values and the type of the input parameters passed to
activities and the output parameters received from activities. The values of
inputs/outputs are generated at runtime during the execution of workflow instances.
Table 1 shows an extended workflow log which accommodates input/output values of
activity parameters that have been generated at runtime. Each ‘Parameter/Value’ entry
as a type, a parameter name, and a value (for example, string loan-type=”car-loan”).
Additionally, the log needs to include path information: a path describing the
activities that have been executed during the enactment of a process. This information
can easily be stored in the log. From the implementation perspective it is space
efficient to store in the log only the relative path, relative to the previous activity, not
the full path. Table 1 shows the full path approach because it is easier to understand
how paths are stored in the log.
Table 1. Extended workflow log
Workflow
log extension
… Parameter/Value Path
… int SSN=7774443333; …
string loan-type=”car-
loan”
…
… string name=PI:EMAIL; {FillLoanRequest,
… CheckLoanType,
CheckCarLoan,
ApproveCarLoan,
NotifyCarLoanClient,
ArchiveApplication}
… … …
During this phase, and compared to [3, 4], we only need to add information on paths
to the log. Once enough data is gathered in the workflow log, we can apply data
mining methods to predict the path followed by a process instance at runtime based
on instance parameters. In section 4.2, we will show how the extended workflow log
can be transformed to a set of data mining instances. Each data mining instance will
constitute the input to machine learning algorithm.
3.2 QoS activity model construction
After carrying out path mining, we know which activities a workflow instance will be
invoking in the near future. For each activity that will potentially be invoked we build
what we call a QoS activity model. The model includes information about the activity
behavior at runtime, such as its cost and the time the activity will take to execute [1].
Each QoS activity model can be constructed by carrying out activity profiling. This
technique is similar to the one used to construct operational profiles. Operational
profiles have been proposed by Musa [8, 9] to accurately predict future the reliability
of applications. The idea is to test the activity based on specific inputs. In an
operational profile, the input space is partitioned into domains, and each input is
associated with a probability of being selected during operational use. The probability
is employed in the input domain to guide input generation. The density function built
from the probabilities is called the operational profile of the activity. At runtime,
activities have a probability associated with each input. Musa [9] described a detailed
procedure for developing a practical operational profile for testing purposes. In our
case, we are interested in predicting, not the reliability, but the cost and time
associated with the execution of workflow activities.
During the graphical design of a workflow, the business analyst and domain expert
construct a QoS activity model for each activity using activity profiles and empirical
knowledge about activities. The construction of a QoS model for activities is made at
design time and re-computed at runtime, when activities are executed. Since the initial
QoS estimates may not remain valid over time, the QoS of activities is periodically re-
computed, based on the data of previous instance executions stored in the workflow
log.
The re-computation of QoS activity metrics is based on data coming from designer
specifications (i.e. the initial QoS activity model) and from the workflow log.
Depending on the workflow data available, four scenarios can occur (Table II): a) For
a specific activity a and a particular dimension Dim (i.e., time or cost), the average is
calculated based only on information introduced by the designer (Designer
Average (a)); b) the average of an activity a dimension is calculated based on all its
Dim
executions independently of the workflow that executed it (Multi-Workflow
Average (a)); c) the average of the dimension Dim is calculated based on all the
Dim
times activity a was executed in any instance from workflow w (Workflow
Average (t, w)); and d) the average of the dimension of all the times activity t was
Dim
executed in instance i of workflow w (Instance Average (t, w, i)).
Dim
Table 2. QoS dimensions computed at runtime
a) QoS (a) = Designer Average (a)
Dim Dim
b) QoS ’(a) = wi* Designer Average (a) +
Dim 1 Dim
wi* Multi-Workflow Average (a)
2 Dim
c) QoS (a, w) = wi* Designer Average (a) +
Dim 1 Dim
wi* Multi-Workflow Average (a) +
2 Dim
wi*Workflow Average (a, w)
3 Dim
d) QoS (a, w, i) wi* Designer Average (a) +
Dim 1 Dim
= wi* Multi-Workflow Average (a) +
2 Dim
wi* Workflow Average (a, w) +
3 Dim
wi* Instance Workflow Average (a,w, i)
4 Dim
Let us assume that we have an instance i of workflow w running and that we desire to
predict the QoS of activity a ∈ w. The following rules are used to choose which
formula to apply when predicting QoS. If activity a has never been executed before,
then formula a) is chosen to predict activity QoS, since there is no other data available
in the workflow log. If activity ahas been executed previously, but in the context of
workflow w , and w != w , then formula b) is chosen. In this case we can assume that
n n
the execution of a in workflow w will give a good indication of its behavior in
n
workflow w. If activity ahas been previously executed in the context of workflow w,
but not from instance i, then formula c) is chosen. Finally, if activity a has been
previously executed in the context of workflow w, and instance i, meaning that a loop
has been executed, then formula d) is used.
The workflow management system uses the formulae from Table II to predict the
QoS of activities. The weights wi are manually set. They reflect the degree of
k
correlation between the workflow under analysis and other workflows for which a set
of common activities is shared. At this end of this second phase, we already know the
activities of a workflow instance that will most likely be executed at runtime, and for
each activity we have a model of its QoS, i.e. we know the time and cost associated
with the invocation of the activity.
3.3 Workflow QoS Estimation
Once we know the path, i.e. the set of activities which will be executed by a workflow
instance, and we have a QoS activity model for each activity, we have all the elements
required to predict the QoS associated with the execution of a workflow instance.
To compute the estimated QoS of a process in execution, we use a variation of the
Stochastic Workflow Reduction (SWR) algorithm [1]. The variation of the SWR
algorithm that we use does not include probabilistic information about transitions.
The SWR is an algorithm for computing aggregate QoS properties step-by-step. At
each step a reduction rule is applied to shrink the process. At each step the time and
cost of the activities involved is computed. This is continued until only one activity is
left in the process. When this state is reached, the remaining activity contains the QoS
metrics corresponding to the workflow under analysis. For the reader interested in the
behavior of the SWR algorithm we refer to [1].
For example, if the path predicted in the first phase of our QoS mining method
includes a parallel system, as show in Figure 3, the parallel system reduction rule is
applied to a part of the original workflow (Figure 3.a) and a new section of the
workflow is created (Figure 3.b).
A system of parallel activities t , t , …, t , an and split activity t , and an and join
1 2 n a
activity t can be reduced to a sequence of three activities t , t , and t . In this
b a 1n b
reduction, the incoming transitions of t and the outgoing transition of activities t
a b
remain the same. The only outgoing transitions from activity t and the only incoming
a
transitions from activity t are the ones shown in the figure below.
b
t
1
* *
t t t t t t
a 2 b a 1n b
t
n
(a) (b)
Fig. 3. Parallel system reduction
The QoS of the new workflow is computed using the following formulae (the QoS of
tasks t and t remain unchanged):
a b
Time(t ) = Max {Time(t)} and