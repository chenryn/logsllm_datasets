title:DataGuard: Dynamic data attestation in wireless sensor networks
author:Dazhi Zhang and
Donggang Liu
DataGuard: Dynamic Data Attestation in Wireless Sensor Networks
Dazhi Zhang and Donggang Liu
PI:EMAIL,PI:EMAIL
Department of Computer Science and Engineering
The University of Texas at Arlington
Abstract
Attestation has become a promising approach for ensur-
ing software integrity in wireless sensor networks. How-
ever, current attestation either focuses on static system
properties, e.g., code integrity, or requires hardware sup-
port such as Trusted Platform Module (TPM). However,
there are attacks exploiting vulnerabilities that do not vio-
late static system properties, and sensor platforms may not
have hardware-based security support. This paper presents
a software attestation scheme for dynamic data integrity
based on data boundary integrity. It automatically trans-
forms the source code and inserts data guards to track run-
time program data. A data guard is unrecoverable once it
is corrupted by an attacker, even if the attacker fully con-
trols the system later. The corruption of any data guard at
runtime can be remotely detected. A corruption either indi-
cates a software attack or a bug in the software that needs
immediate attention. The beneﬁts of the proposed attesta-
tion scheme are as follows. First, it does not rely on any
additional hardware support, making it suitable for low-
cost sensor nodes. Second, it introduces minimal communi-
cation cost and has adjustable runtime memory overhead.
Third, it works even if sensor nodes use different hardware
platforms, as long as they run the same software. The pro-
totype implementation and the experiments on TelosB motes
show that the proposed technique is both effective and efﬁ-
cient for sensor networks.
1 Introduction
Wireless sensor nodes often lack advanced hardware
support for system integrity and are vulnerable to attacks
exploiting software ﬂaws. Additionally, it is often costly
to physically access sensor nodes and check their system
integrity after deployment. As a result, attestation, i.e., re-
motely verifying the integrity of sensor software, becomes
particularly attractive.
Software attestation is a challenge-response protocol.
The veriﬁer (e.g., base station) sends an attestation com-
Existing techniques and their limitations:
mand to the attester (the node being attested) asking for
certain state information as the evidence of its software in-
tegrity. Such state can be computed correctly only if the
attester’s system meets certain integrity requirement, e.g.,
having an authentic copy of the software. After receiving
the response, the veriﬁer compares it with the known good
state to check if the software at the attester has been cor-
rupted. If a sensor node fails to give the correct answer,
actions can be taken to revoke this node from the network.
Several
software attestation schemes have been proposed to attest
the static memory regions of the software [19, 25, 21, 18].
A static memory region is the place where the content
never changes during software execution. One example
is the code segment of a program that does not include
self-modifying code. SWATT [19] and Pioneer [18] are
software-based solutions where the challenger asks for the
hash of randomly traversed code blocks. To compute a cor-
rect hash value, the challenged device has to have an au-
thentic copy of the code, which turns out to be difﬁcult for
a malicious device with the same hardware. Similar ideas
were studied in [25, 21]. However, these solutions only at-
test the static part, e.g., code and static program conﬁgura-
tions, of the challenged system. Dynamic data, which also
play a critical role in software integrity, are ignored. In ad-
dition, these solutions only measure the software integrity at
the time of attestation; there is a large TOUTOA (time-of-
use and time-of-attestation) gap. BIND [22] narrows such
gap. However, it uses hardware support (TPM) and assumes
a secure kernel that can ensure the security of code execu-
tion. Unfortunately, we cannot promise that every sensor
node will be equipped with a TPM chip.
Recent studies have also shown that an adversary can
launch attacks without modifying the code. These attacks
defeat all existing static attestation techniques. One exam-
ple is the “return-into-libc”attack [15], where the adversary
takes advantage of existing function calls to run malicious
code. More recently, researchers have shown that it is even
possible to run malicious code without modifying the code
or using existing function calls [20, 7]. This attack takes
advantage of many gadgets in the program, each consist-
ing of a sequence of instructions that end with a “ret” and
achieve something useful to the attacker. The attack has
been demonstrated on Atmel AVR-based sensors.
ReDAS [13] was recently proposed to measure the in-
tegrity of dynamic system properties. This method attests
the structural constraints of memory objects and data in-
variants. One example is “the saved frame pointers in stack
must form a chain”. Given this property, one can monitor
program execution and record integrity violation evidence
for attestation. However, this method has a number of prob-
lems. First, it needs a training phase to run a program with
a large number of test data and use the Daikon [5] tool to
collect data invariants. Identifying these constraints and in-
variants is both time-consuming and error-prone. Second,
this method uses TPM, which is often not available at sen-
sor nodes. Third, it measures the system integrity at each
system call point, which may lead to a large TOUTOA gap.
Finally, ReDAS does not consider non-control-data attacks,
i.e., the attacks that do not modify control data such as func-
tion pointers and return addresses [23].
Our contributions: We model a program as a sequence
of statements that manipulate a set of data; its control ﬂow
and data ﬂow are determined by program logic. At source
code level, each operation on a data object usually intends
to limit its effect within this data object. In other words, the
semantics of the operation on one object should not generate
side effects to change the state of any other data object that
is not involved in the operation. For example, for statement
strcpy(buf,user_input);, the high level intended
semantics is to only copy the string speciﬁed by the second
argument user_input to the ﬁrst object buf, not to any-
where else in the memory. As a result, any object that is
physically adjacent to buf in memory should not be mod-
iﬁed by this statement. However, the problem is that such
high-level intended semantics is not enforced during pro-
gram execution, and the string user_input is just blindly
copied to buf without any boundary check. Hence, buffer
overﬂow occurs when the second argument user_input
is a string that is larger than the buffer size.
In this paper, we introduce data boundary integrity,
meaning that “any operation on a program variable should
not impact anything outside of the memory region allocated
to such variable”. In other words, the program runtime se-
mantics should be consistent with the intended source-code
level program semantics. Our idea is to add additional data
objects, called data guards, in the source code and place
them around the program data objects to track any viola-
tion of data boundary integrity. These data guards are the
boundaries of the program data objects and are semanti-
cally independent from all program data objects. In other
words, no statements in the original program should operate
(e.g., write) on them. Only the attestation code inserted by
our approach can access these data guards. As a result, the
corruption, i.e., modiﬁcation done by statements other than
our inserted attestation code, of any data guard indicates an
unintended write operation, which is either an attack or a
software bug that needs immediate attention.
Based on the above idea, we propose a new dynamic
attestation scheme, called DataGuard, for wireless sensor
network. Our approach automatically transforms the source
code and tracks unintended modiﬁcations to the runtime
program data objects, including global data, local data, and
dynamically created data objects such as heap data. The
beneﬁts of our scheme are as follows. First, it captures
a wide range of software attacks, including both control-
data and non-control-data attacks. Speciﬁcally, our tool de-
tects any software attack that starts from overﬂowing one
of the program data objects. Second, it does not rely on
additional hardware (e.g., TPM), which is not supported
by most sensor platforms. Third, it only introduces mini-
mal communication cost and has adjustable runtime mem-
ory overhead. Fourth, our scheme effectively mitigates the
TOUTOA problem. This is because once a data guard is
corrupted, the node will never be able to provide a correct
answer at any later time. We have implemented a proto-
type system to evaluate our scheme and done experiments
on TelosB motes [12] . The result shows that our scheme is
effective and efﬁcient in practice.
Organization: The rest of this paper is organized as
follows. The next section describes system assumptions and
attack models. Section 3 presents our attestation scheme in
detail. Section 4 discusses implementation issues. Section
5 presents the evaluation results. Section 6 reviews other
related work. Section 7 discusses some limitations of our
scheme. Section 8 concludes this paper.
2 Threats, Attack Models, and Assumptions
Remotely exploiting the software vulnerability at sen-
sor nodes is often more attractive than physically access-
ing them to launch an attack. First, physically accessing a
sensor node not only incurs high cost for attackers but also
physically exposes themselves in the ﬁeld. Second, sensor
applications are often written in unsafe languages such as
nesC [8] and C. Thus, vulnerabilities such as buffer over-
ﬂow are likely to appear in sensor software as well. In fact,
a number of studies have pointed out that buffer overﬂow
can be launched to compromise sensor nodes [9, 7]. Note
that many sensor platforms use the Harvard architecture
where program instructions are physically separated from
data. This will make code injection attacks difﬁcult. How-
ever, a signiﬁcant part of sensor platforms are still devel-
oped based on Von Neumann architecture [24]. In addition,
separating instructions from data does not solve the prob-
lem completely. For Harvard architecture-based sensors,
new techniques have recently been developed [7] to exploit
program vulnerabilities to execute arbitrary malicious code
without changing the code image. As a result, these attacks
cannot be detected by current static attestation techniques.
Third, the homogeneous software infrastructure in sensor
networks allows attackers to infect a large fraction of sen-
sor nodes using the same software attack. It has been shown
that worms in sensor networks are possible and can propa-
gate and compromise the whole network quickly [9, 26].
In this paper, we focus on adversaries that remotely ex-
ploit the sensor software. First, the adversary may remotely
exploit the software vulnerability to directly inject and run
malicious code.
In order to achieve this, he may (1) di-
rectly inject malicious code using buffer overﬂow attacks,
(2) launch “return-into-libc” attacks using existing function
calls [15], or (3) inject “meta-gadgets” [7]. Second, in addi-
tion to directly injecting malicious code, the adversary may
simply manipulate some security-critical data (e.g., cryp-
tographic keys) in the original program to compromise its
security. For example, if the key used to verify software
updates is overwritten by the adversary, he will be able to
directly reprogram the sensor node with malicious software.
In addition to the above capabilities, we also assume that the
adversary can attack any network link. In other words, he
can interrupt, eavesdrop, modify, forge, and replay any net-
work trafﬁc. The attacker can also launch DoS attacks (e.g.,
jamming) to disable the network for a short period of time.
We assume that there is an authenticated communication
channel between the veriﬁer and an attester. This can be
achieved by establishing a pairwise key between them us-
ing existing techniques [6, 2, 14]. We assume that the ini-
tialization of a sensor node is secure. We also assume that
the veriﬁer is trustworthy. We assume that the attestation
module has been installed on each sensor node, and the ap-
plications in every sensor node have been instrumented with
our attestation scheme discussed in Section 3 (our tool can
automatically instrument the program).
3 The Proposed Attestation Scheme
In this section, we will describe our data boundary in-
tegrity model and show how to set up, measure, and manage
the data guards in the program to achieve the desired secu-
rity requirements. In the end, we will present our attestation
scheme to stop attacks exploiting program data.
3.1 Data Boundary Integrity Model
Consider a program P that runs on a sensor node C. In-
tuitively, program P consists of a set of statements S= {S1,
S2, ..., Sm} written in a language L that manipulate a set of
data objects D = {D1, D2, ..., Dn}. The intended semantic
effect of statement Si is always conﬁned to the data objects
that are involved in this statement. In other words, other
data objects in D should not be modiﬁed by this statement.
However, such development-time intended semantics is no
longer enforced at runtime.
To detect the inconsistency between the intended seman-
tics and the runtime behavior, we introduce an additional set
of data objects B = {B1, B2, ..., Bn}, where Bi is placed
at the memory that physically surround Di at runtime. If
the intended semantics has not been violated at runtime, we
know that none of the values in B will be corrupted since
these values are semantically independent from all data ob-
jects in the original program. In other words, a corruption
of a value in B indicates a software attack or a software bug
that needs immediate attention. Thus, we can capture any
attack that overﬂow a program variable. We found that a
wide range of attacks need to overﬂow at least one program
data object. As a result, our model can handle a wide range
of software attacks against sensor nodes.
Direct overﬂow attacks: Buffer overﬂow and heap
overﬂow vulnerabilities can be exploited to launch a large
number of attacks that alter the program control ﬂow. Ex-
amples include code injection attacks, return-into-libc at-
tacks [15], and return-oriented-programming attacks [20].
For example, stack buffer overﬂow can be used to change
return addresses, and heap overﬂow can be used to mod-
ify function pointers. These data overﬂows can also be ex-
ploited to modify security-critical or decision-making vari-
ables to launch non-control-data attacks [23]. For example,
a boolean variable that is used to determine whether authen-
tication is passed or not can be ﬂipped to circumvent the
authentication. In our model, such direct overﬂow attacks
can be immediately captured because of the corruption of
the boundary integrity of the overﬂowed data object.
Indirect overﬂow attacks: Integer overﬂow and double
free vulnerabilities are often followed by buffer overﬂow or
heap overﬂow attacks to compromise the system security
[23]. For example, an integer overﬂow may cause a smaller
buffer being allocated, which leads to a buffer overﬂow at-
tack at a later stage. As another example, calling f ree()
twice on the same variable can also lead to a buffer over-
ﬂow. Our model is capable of detecting the overﬂow of any
program data object. Thus, indirect data overﬂow caused by
other vulnerabilities can be handled by our scheme as well.
From the above discussion, we believe that a wide range
of possible attacks against sensor nodes are captured by our
data boundary integrity model. To be more speciﬁc, any
software attack that starts from overﬂowing a program data
object can be captured by our model.
Due to the dynamic nature of runtime data objects, their
corresponding data guards are also dynamic. In the follow-
ing, we present the three main components of our scheme:
(1) data guard setting up, (2) runtime guarding, and (3) data
guard memory management.
3.2 Data Guard Setting Up
There are two problems that must be carefully consid-
ered: (1) how to set up the data guard for a data object and
(2) at what resolution should the data guards be set up.
We classify the data objects in D into static data and
dynamic data. The static data deﬁned here is not the same
as the static memory region we deﬁned at the beginning of
this paper. Static data here refers to the data whose memory
location is determined at the compiling time, e.g., global
variables and static variables. Dynamic data refers to the
data whose memory is allocated at runtime, i.e., its memory
location is unknown at the compiling time. For example,
in C program, data blocks allocated in heap at runtime are
dynamic data.
For static data, we notice that most compilers such as
GCC and nesC compiler organize runtime variables in a
way that is consistent with the variable declaration order in
the program. Therefore, we introduceadditional guard vari-
ables around the static data. Then after compilation, these
data guards have addresses encompassing their protected
data. For dynamic data, we wrap the memory allocation
functions such as malloc to allocate a piece of additional
memory at the end of original allocated memory for hold-
ing its data guard. Conceptually, a data object Di has two
physical boundaries in memory: the upper boundary and
the lower boundary. In practice, however, memory-write in-
structions always write the memory from lower address to
higher address. Thus, we only put data guards at the upper
boundaries. (If necessary, lower boundaries can be handled
in the same way.) From now on we use one data guard for
each program data object.
The types of data objects in D range from primitive type
to compositional type. At what resolution to set up data
guards depends on how the program treats these data ob-
jects at runtime. For example, a struct type object can be
regarded as one single object or many individual ﬁeld ob-
jects. Therefore, the data guard resolution is an essential
design choice. In our method, an object in D is either a
primitive type object or an array. For a struct object, its ﬁeld
objects are protected individually. For an array, it is pro-
tected as a single object. We believe this is a cost-effective
and feasible choice in practice.
3.3 Runtime Guarding
Since many data objects in D are dynamically created
and destroyed at runtime, their data guards are also dy-
namic. In order to monitor the data boundary integrity, the
runtime behavior of these data guards must satisfy follow-
ing three requirements. These three requirementsensure the
security of our scheme. We will explain them one by one