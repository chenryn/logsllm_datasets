title:Scalable flow-based networking with DIFANE
author:Minlan Yu and
Jennifer Rexford and
Michael J. Freedman and
Jia Wang
Scalable Flow-Based Networking with DIFANE
Minlan Yu∗ Jennifer Rexford∗ Michael J. Freedman∗ Jia Wang†
Princeton University, Princeton, NJ, USA
AT&T Labs - Research, Florham Park, NJ, USA
∗
†
ABSTRACT
Ideally, enterprise administrators could specify ﬁne-grain poli-
cies that drive how the underlying switches forward, drop,
and measure traﬃc. However, existing techniques for ﬂow-
based networking rely too heavily on centralized controller
software that installs rules reactively, based on the ﬁrst packet
of each ﬂow.
In this paper, we propose DIFANE, a scal-
able and eﬃcient solution that keeps all traﬃc in the data
plane by selectively directing packets through intermediate
switches that store the necessary rules. DIFANE relegates
the controller to the simpler task of partitioning these rules
over the switches. DIFANE can be readily implemented with
commodity switch hardware, since all data-plane functions
can be expressed in terms of wildcard rules that perform
simple actions on matching packets. Experiments with our
prototype on Click-based OpenFlow switches show that DI-
FANE scales to larger networks with richer policies.
Categories and Subject Descriptors: C.2.1[Computer
Communication Networks]: Network Architecture and De-
sign
General Terms: Algorithms, Design, Management
Keywords: Access Control, Network Architecture, Open-
Flow, Scalability
1.
INTRODUCTION
The emergence of ﬂow-based switches [1, 2] has enabled
enterprise networks that support ﬂexible policies. These
switches perform simple actions, such as dropping or for-
warding packets, based on rules that match on bits in the
packet header. Installing all of the rules in advance is not
attractive, because the rules change over time (due to pol-
icy changes and host mobility) and the switches have rel-
atively limited high-speed memory (such as TCAMs). In-
stead, current solutions rely on directing the ﬁrst packet of
each “microﬂow” to a centralized controller that reactively
installs the appropriate rules in the switches [3, 4]. In this
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’10, August 30–September 3, 2010, New Delhi, India.
Copyright 2010 ACM 978-1-4503-0201-2/10/08 ...$10.00.
Distribute 
partition 
information 
e  r u l e s
c t
d ir e
c
a
C
h
e
R
First 
Packet
Ingress
Switch
Subsequent 
Packets
Controller
Install 
authority 
rules
...
Authority
Switch
Authority
Switch
Forward
Egress
Switch
Hit cached rules and forward
Figure 1: DIFANE ﬂow management architecture.
(Dashed lines are control messages. Straight lines are
data traﬃc.)
paper, we argue that the switches themselves should collec-
tively perform this function, both to avoid a bottleneck at
the controller and to keep all traﬃc in the data plane for
better performance and scalability.
1.1 DIFANE: Doing It Fast ANd Easy
Our key challenge, then, is to determine the appropriate
“division of labor” between the controller and the underly-
ing switches, to support high-level policies in a scalable way.
Previous work has demonstrated that a logically-centralized
controller can track changes in user locations/addresses and
compute rules the switches can apply to enforce a high-level
policy [4, 5, 6]. For example, an access-control policy may
deny the engineering group access to the human-resources
database, leading to low-level rules based on the MAC or IP
addresses of the current members of the engineering team,
the IP addresses of the HR servers, and the TCP port num-
ber of the database service. Similar policies could direct
packets on customized paths, or collect detailed traﬃc statis-
tics. The controller can generate the appropriate switch
rules simply by substituting high-level names with network
addresses. The policies are represented with 30K - 8M rules
in the four diﬀerent networks we studied. This separation of
concerns between rules (in the switches) and policies (in the
controller) is the basis of several promising new approaches
to network management [3, 7, 8, 9, 10].
While we agree the controller should generate the rules, we
do not think the controller should (or needs to) be involved
in the real-time handling of data packets. Our DIFANE
(DIstributed Flow Architecture for Networked Enterprises)
architecture, illustrated in Figure 1, has the following two
main ideas:
351• The controller distributes the rules across (a subset
of) the switches, called “authority switches,” to scale
to large topologies with many rules. The controller
runs a partitioning algorithm that divides the rules
evenly and minimizes fragmentation of the rules across
multiple authority switches.
• The switches handle all packets in the data plane
(i.e., TCAM), diverting packets through authority switches
as needed to access the appropriate rules. The “rules”
for diverting packets are themselves naturally expressed
as TCAM entries.
All data-plane functionality in DIFANE is expressible in
terms of wildcard rules with simple actions, exactly the ca-
pabilities of commodity ﬂow switches. As such, a DIFANE
implementation requires only modiﬁcations to the control-
plane software of the authority switches, and no data-plane
changes in any of the switches. Experiments with our pro-
totype, built on top of the Click-based OpenFlow switch [11],
illustrate that distributed rule management in the data plane
provides lower delay, higher throughput, and better scala-
bility than directing packets through a separate controller.
Section 2 presents our main design decisions, followed by
our DIFANE architecture in Section 3. Next, Section 4 de-
scribes how we handle network dynamics, and Section 5
presents our algorithms for caching and partitioning wild-
card rules. Section 6 presents our switch implementation,
followed by the performance evaluation in Section 7. Sec-
tion 8 describes diﬀerent deployment scenarios of DIFANE.
The paper concludes in Section 9.
1.2 Comparison to Related Work
Recent work shows how to support policy-based manage-
ment using ﬂow switches [1, 2] and centralized controllers [4,
5, 6, 3]. The most closely related work is the Ethane con-
troller that reactively installs ﬂow-level rules based on the
ﬁrst packet of each TCP/UDP ﬂow [3]. The Ethane con-
troller can be duplicated [3] or distributed [12] to improve
its performance. In contrast, DIFANE distributes wildcard
rules amongst the switches, and handles all data packets in
the data plane. Other recent work capitalizes on OpenFlow
to rethink network management in enterprises and data cen-
ters [7, 8, 9, 10]; these systems could easily run as applica-
tions on top of DIFANE.
These research eﬀorts, and ours, depart from traditional
enterprise designs that use IP routers to interconnect smaller
layer-two subnets, and rely heavily on inﬂexible mechanisms
like VLANs. Today, network operators must conﬁgure Vir-
tual LANs (VLANs) to scope broadcast traﬃc and direct
traﬃc on longer paths through routers that perform access
control on IP and TCP/UDP header ﬁelds.
In addition,
an individual MAC address or wall jack is typically asso-
ciated with just one VLAN, making it diﬃcult to support
more ﬁne-grained policies that treat diﬀerent traﬃc from the
same user or oﬃce diﬀerently.
Other research designs more scalable networks by selec-
tively directing traﬃc through intermediate nodes to reduce
routing-table size [13, 14, 15]. However, hash-based redi-
rection techniques [13, 14], while useful for ﬂat keys like
IP or MAC addresses, are not appropriate for look-ups on
rules with wildcards in arbitrary bit positions. ViAggre [15]
subdivides the IP preﬁx space, and forces some traﬃc to al-
ways traverse an intermediate node, and does not consider
on-demand cache or multi-dimensional, overlapping rules.
2. DIFANE DESIGN DECISIONS
On the surface, the simplest approach to ﬂow-based man-
agement is to install all of the low-level rules in the switches
in advance. However, preinstalling the rules does not scale
well in networks with mobile hosts, since the same rules
would need to be installed in multiple locations (e.g., any
place a user might plug in his laptop). In addition, the con-
troller would need to update many switches whenever rules
change. Even in the absence of mobile devices, a network
with many rules might not have enough table space in the
switches to store all the rules, particularly as the network
grows or its policies become more complex.
Instead, the
system should install rules on demand [3].
To build a ﬂow-processing system that has high perfor-
mance and scales to large networks, DIFANE makes four
high-level design decisions that reduce the overhead of han-
dling cache misses and allow the system to scale to a large
number of hosts, rules, and switches.
2.1 Reducing Overhead of Cache Misses
Reactively caching rules in the switches could easily cause
problems such as packet delay, larger buﬀers, and switch
complexity when cache misses happen. More importantly,
misbehaving hosts could easily trigger excessive cache misses
simply by scanning a wide range of addresses or port num-
bers — overloading TCAM and introducing extra packet-
processing overhead. DIFANE handles “miss” packets eﬃ-
ciently by keeping them in the data plane and reduces the
number of “miss” packets by caching wildcard rules.
Process all packets in the data plane: Some ﬂow man-
agement architectures direct the ﬁrst packet (or ﬁrst packet
header) of each microﬂow to the controller and have the
switch buﬀer the packet awaiting further instructions [3].1
In a network with many short ﬂows , a controller that han-
dles “miss” packets can easily become a bottleneck. In ad-
dition, UDP ﬂows introduce extra overhead, since multiple
(potentially large) packets in the same ﬂow may be in ﬂight
(and need to visit the controller) at the same time. The
switches need a more complex and expensive buﬀering mech-
anism, because they must temporarily store the “miss” pack-
ets while continuing to serve other traﬃc, and then retrieve
them upon receiving the rule. Instead, DIFANE makes it
cheap and easy for switches to forward all data packets in
the data plane (i.e., hardware), by directing “miss” packets
through an intermediate switch. Transferring packets in the
data plane through a slightly longer path is much faster than
handling packets in the control plane.
Eﬃcient rule caching with wildcards: Caching a sep-
arate low-level rule for each TCP or UDP microﬂow [3],
while conceptually simple, has several disadvantages com-
pared to wildcard rules. For example, a wildcard rule that
matches on all destinations in the 123.132.8.0/22 subnet
would require up to 1024 microﬂow rules.
In addition to
consuming more data-plane memory on the switches, ﬁne-
grained rules require special handling for more packets (i.e.,
the ﬁrst packet of each microﬂow), leading to longer de-
lays and higher overhead, and more vulnerability to misbe-
having hosts. Instead, DIFANE supports wildcard rules, to
1Another solution to handle cache miss is for the switch to
encapsulate and forward the entire packet to the controller.
This is also problematic because it signiﬁcantly increases
controller load.
352have fewer rules (and fewer cache “misses”) and capitalize on
TCAMs in the switches. Caching wildcard rules introduces
several interesting technical challenges that we address in
our design and implementation.
2.2 Scaling to Large Networks and Many Rules
To scale to large networks with richer policies, DIFANE
divides the rules across the switches and handles them in a
distributed fashion. We also keep consistent topology infor-
mation among switches by leveraging link-state protocols.
Partition and distribute the ﬂow rules:
Replicat-
ing the controller seems like a natural way to scale the sys-
tem and avoid a single point of failure. However, this re-
quires each controller to maintain all the rules, and coordi-
nate with the other replicas to maintain consistency when
rules change. (Rules may change relatively often, not only
because the policy changes, but also because host mobility
triggers changes in the mapping of policies to rules.)
In-
stead, we partition the space of rules to reduce the number of
rules each component must handle and enable simpler tech-
niques for maintaining consistency. As such, DIFANE has
one primary controller (perhaps with backups) that man-
ages policies, computes the corresponding rules, and divides
these rules across the switches; each switch handles a por-
tion of the rule space and receives updates only when those
rules change. That is, while the switches reactively cache
rules in response to the data traﬃc, the DIFANE controller
proactively partitions the rules across diﬀerent switches.
Consistent topology information distribution with
the link-state protocol:
Flow-based management re-
lies on the switches having a way to communicate with
the controller and adapt to topology changes. Relying on
rules for this communication introduces circularity, where
the controller cannot communicate with the switches until
the appropriate rules have been installed. Rather than boot-
strapping communication by having the switches construct
a spanning tree [3], we advocate running a link-state pro-
tocol amongst the switches. Link-state routing enables the
switches to compute paths and learn about topology changes
and host location changes without involving the controller,
reducing overhead and also removing the controller from
the critical path of failure recovery. In addition, link-state
routing scales to large networks, enables switches to direct
packets through intermediate nodes, and reacts quickly to
switch failure [13]. As such, DIFANE runs a link-state rout-
ing protocol amongst the switches, while also supporting
ﬂow rules that allow customized forwarding of traﬃc be-
tween end hosts. The controller also participates in link-
state routing to reach the switches and learn of network
topology changes.2
3. DIFANE ARCHITECTURE
The DIFANE architecture consists of a controller that
generates the rules and allocates them to the authority switches,
as shown in Figure 1. Authority switches can be a subset
of existing switches in the network (including ingress/egress
switches), or dedicated switches that have larger memory
and processing capability.
2The links between the controller and switches are set with
high link-weights so that traﬃc between switches do not go
through the controller.
Controller
           Policies
Map
Rules
Partition
Partition
rules
Authority rules 
for Switch A
... ...
Authority rules 
for Switch D
Figure 2: Rule operations in the controller.
Upon receiving traﬃc that does not match the cached
rules, the ingress switch encapsulates and redirects the packet
to the appropriate authority switch based on the partition
information. The authority switch handles the packet in the
data plane and sends feedback to the ingress switch to cache
the relevant rule(s) locally. Subsequent packets matching
the cached rules can be encapsulated and forwarded directly
to the egress switch.
In this section, we ﬁrst discuss how the controller parti-
tions the rules and distributes the authority and partition
rules to the switches. Next, we describe how a switch directs
packets through the authority switch and caches the neces-
sary rules, using link-state routing to compute the path to
the authority switch. Finally, we show that the data-plane
functionality of DIFANE can be easily implemented on to-
day’s ﬂow-based switches using wildcard rules.
3.1 Rule Partition and Allocation
As shown in Figure 2, we use the controller to pre-compute
the low-level rules, generate partition rules that describe
which low-level rules are stored in which authority switches,
and then distribute the partition rules to all the switches.
The partition rules are represented by coarse-grained wild-
card rules on the switches.
Precompute low-level rules: The controller pre-computes
the low-level rules based on the high-level policies by sim-
ply substituting high-level names with network addresses.
Since low-level rules are pre-computed and installed in the
TCAM of switches, we can always process packets in the
fast path. Most kinds of policies can be translated to the
low-level rules in advance because the controller knows the
addresses of the hosts when the hosts ﬁrst connect to the
ingress switch, and thus can substitute the high-level names