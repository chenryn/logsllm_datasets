### States Larger than k and Inlining

States larger than \( k \) will not be inlined. To maintain accuracy, the hybrid model must transform the source program to add guards to calls of non-inlined functions, similar to the Dyck model. For instance, if the program contains a call to `f()` (and this is the 23rd call site to that function), and the NFA for `f` is larger than \( k \), the following transformation is applied:

```c
f();
```

is transformed into:

```c
pre("f", 23);
f();
post("f", 23);
```

Clearly, \( k \) has a significant impact on performance. At the extreme, if \( k \) is set to 1, the hybrid inlined automaton model (hIAM) would degenerate into an instance of the Dyck model.

### Deterministic Markers

A high degree of non-determinism results in large fan-outs for the automaton states. A larger fan-out translates to greater runtime overhead for the monitoring algorithm, which must check every successor state for matching transition symbols. Although the monitoring algorithm starts with a single current state (entry of main), non-determinism and the existence of several successor states for the same transition symbol quickly introduce ambiguity about the current state. This causes the monitoring algorithm to maintain a set of current states and check successors for each at runtime. The overhead introduced by this can be significant, especially for programs like `gnatsd`, which have a high average fan-out and a low average unique transition symbol per state (see Figure 9).

To reduce such overhead, we introduce the concept of deterministic markers. These are unique transition symbols inserted into the program text to reduce the search space (current states and successors) of the runtime monitoring algorithm. Conceptually, they are similar to the renaming and null call insertion techniques described in [3, 4, 1]. However, they are not needed for determining the calling context (inlining takes care of that) but for disambiguating the current state (program counter) and reducing the fan-out of frequently occurring high fan-out states (such as a library function call in a loop followed by severe non-determinism).

Currently, we use such markers only for `gnatsd` along the paths exercised by the workloads. Eleven sites were manually identified, and null library calls were introduced. The performance gains were substantial for the minimal effort involved in identifying instrumentation sites. It is reasonable to assume that the selection of instrumentation sites can be automated at model construction time. This can be done by detecting high fan-out and high ambiguity states in the \(\varepsilon\)-free IAM and maintaining a mapping of the model states to program points to help identify instrumentation sites in the program text. Automating the selection of instrumentation sites and evaluating its impact on model size is part of future work.

### Evaluation

Program models for on-the-fly intrusion detection can be evaluated based on two criteria: accuracy and efficiency. Greater accuracy makes these models useful by reducing false negatives, and increased efficiency makes them usable by reducing time and space overheads. The IAM model has a runtime efficiency equal to that of an NFA model, which is the most efficient model possible.

We demonstrate the efficiency of our model by testing it with the four real-world programs shown in Table 1. For comparison purposes, we have chosen programs used in the literature. Tests were run on a Sun V100 550MHz UltraSPARC II with 256MB of RAM and running Solaris 9. Table 3 shows the workloads used in testing. Table 4 shows the runtime overhead for our model. Runtime is measured using the UNIX `time` utility, and measurements are calculated over several runs. The base runtime represents the cost of library interposition, and the monitored runtime includes the cost of operating the automaton. The monitored runtime does not include the setup time needed to load the program model from the disk (except in the case of `cat`). The difference between the base runtime and the monitored runtime represents the model operation overhead. The percentages compare this overhead against the base runtime. We attribute the slight variations between expected times (because of interposition and monitoring) and actual times to measurement noise. Except for `htzipd`, the runtime overhead for the programs is negligible. We are confident that the runtime overhead for `htzipd` can be reduced by using deterministic markers. Note that our solution scales efficiently to `gnatsd`, which is a 32K line program.

Table 5 shows the memory usage of the programs. The unmonitored memory usage of the code is obtained using the `pmap` command, which displays information about the address space of a process. The percentages compare the automaton overhead against the unmonitored memory usage of the code. The automaton overhead is significant for `gnatsd` when compared to others. However, this can be reduced by as much as 72.19% by including \(\varepsilon\)-transitions and delta successor states as described in Section 5. Also, note that the same automaton can be used if multiple instances of the program are running simultaneously. Table 6 compares the runtime and memory overheads of the Dyck, VPStatic, and IAM models for common test programs. The IAM model is clearly more time and space efficient for these programs.

#### Discussion

In this paper, we demonstrated the efficiency of the IAM model by monitoring library calls instead of system calls, as done in previous work. This choice is motivated by pragmatic considerations. Analyzing the source code of C libraries is a challenging task [17] (other approaches typically analyze statically-linked binaries [3, 4, 1]). The static analysis infrastructure used in our prototype was not able to handle these libraries; we plan to address this problem in future work. However, we also believe that switching to system calls will not affect our results. Library functions provide a finer-grained program model as they are usually more frequent. Therefore, the overheads reported here are likely an upper bound on the costs of the approach. From an effectiveness perspective, monitoring the library interface alone is not sufficient for intrusion detection.

There are several approaches to handling recursion. The simplest solution is to allow imprecision at recursion points in the model, based on the assumption that the actual loss of accuracy is small. The implication of this for mimicry attacks must be considered. Recursion is only a problem if there are library calls in the unwinding phase (i.e., if a library call is reachable in the control flow graph between the recursive call site and the function's exit). If not, the attacker would gain nothing by following impossible paths. Thus, if a function `g()` is recursive and has library calls in an unwinding path, its calls can be transformed into guarded calls in the hybrid model. However, this can have an impact on performance (which is why the Dyck model does not instrument recursive calls). None of the existing approaches, including ours, demonstrate an efficient way of handling recursion. Our implementation targets C programs, and extending it to object-oriented languages with dynamic binding raises concerns for accuracy and scalability. For example, in C++, virtual methods are invoked through function pointers, so we would have to inline all possible implementations of the method at every call site. Static program analysis techniques can help. Experience with Java programs suggests that upwards from 90% of call sites can be devirtualized [15], i.e., it is possible to determine unambiguously which implementation will be invoked.

### Limitations

Existing approaches to anomaly detection address only a part of the IDS problem: accurate and efficient monitoring of system call sequences. This is the simplest yet important concern for intrusion detection because an attacker must use system calls to interact with the underlying operating system to cause harm (with the possible exception of DoS attacks). By accurately modeling the acceptable sequences of system calls, the models limit the attacker to only those expected system call sequences. However, there are several limitations that diminish the precision of these models.

- **Path Sensitivity**: All proposed models, including ours, treat branches conservatively without evaluating branch predicates, which requires more sophisticated static and dynamic program analysis. Such path-insensitive modeling can be exploited by an attacker, as illustrated in [1].
- **Granularity of Events**: The granularity of events is a troublesome issue. Ideally, an IDS would monitor every single statement executed by the target program and validate each machine instruction. Clearly, this is not possible, and existing models are approximations at different levels of granularity. The coarser the approximation, the easier it is to mount a mimicry attack. For example, restricting observable events to system calls means that library function calls are not captured in the model. Yet, library functions are common entry points for attackers due to their susceptibility to buffer overflow and format string vulnerabilities. Some vulnerable library functions, such as the string family of functions, do not make any system calls. Thus, a coarse model may not observe deviant behavior at the library interface and would have to rely on an out-of-sequence system call to detect an intrusion.
- **Library Interposition Techniques**: These techniques, such as the one used in this paper, allow monitoring the library functions called by a target program. However, an IDS based solely on library interposition will not be effective if an attacker manages to exploit a vulnerability without setting off the IDS and then evades the IDS by directly issuing system calls in the "attack code." Therefore, coupling library interposition with kernel-level system call interposition is necessary. Such a combined IDS appears feasible, requiring two supervisors that must match up: one to monitor library calls and the other to monitor system calls. A single program model can be used for both. A detailed discussion of this issue is beyond the scope of this paper.
- **Data Flow Analysis**: Data flow support is another requirement for more robust IDSs. It is well documented [17, 4] that even a naive approach that incorporates data flow by looking at arguments with constant values can dramatically improve the accuracy of models. To protect against mimicry attacks, it may be necessary to have more powerful predicates about the values of arguments. For example, if the leading part of a file name can be determined statically (even though the full name is constructed dynamically), an IDS could prevent attempts to open files outside of the intended directory. Such predicates can be obtained by program analysis but are likely to increase the runtime costs of monitoring, further reason to keep the costs of the basic program model low.

### Conclusions

We have proposed an efficient and scalable solution to the problem of constructing conservative approximations of legal program behaviors for host-based intrusion detection. Our approach, based on an inlined automaton model (IAM), is context-sensitive and does not suffer from false positives. Constructing a basic IAM is simple, and the resulting model is easy to understand. The overhead of monitoring programs based on an IAM is low, suggesting that this technique could be deployed in production environments. The IAM construction algorithm has been shown to scale to a 32K line program with a substantial space overhead. We then show how to reduce this overhead with automaton compaction techniques.

### Acknowledgments

We thank Barbara Ryder and Atanas Rountev for providing the PROLANGS Analysis Framework (PAF) used to implement our prototype and answering our questions. We also thank the authors of [1] for providing us with the `htzipd` source code and answering questions about their work. Finally, we thank the anonymous referees for their suggestions. This work was supported by sponsors of CERIAS, which is gratefully acknowledged, and in part by grant NSF TC #0209083.

### References

[1] H. Feng, J. Giffin, Y. Huang, S. Jha, W. Lee, and B. Miller. Formalizing sensitivity in static analysis for intrusion detection. In IEEE Symposium on Security and Privacy, May 2004.

[2] H. Feng, O. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection using call stack information. In IEEE Symposium on Security and Privacy, May 2003.

[3] J. Giffin, S. Jha, and B. Miller. Detecting manipulated remote call streams. In 11th USENIX Security Symposium, August 2002.

[4] J. Giffin, S. Jha, and B. Miller. Efficient context-sensitive intrusion detection. In 11th Annual Network and Distributed Systems Security Symposium, February 2004.

[5] S. A. Hofmeyr, S. Forrest, and A. Somayaji. Intrusion detection using sequences of system calls. Journal of Computer Security, 6(3):151–180, 1998.

[6] J. E. Hopcroft, R. Motwani, and J. D. Ullman. Introduction to automata theory, languages, and computation, 2nd edition. ACM Press, 2001.

[7] A. Jones and Y. Lin. Application intrusion detection using language library calls. In Proceedings of the 17th Annual Computer Security Applications Conference (ACSAC), 2001.

[8] C. Ko, G. Fink, and K. Levitt. Automated detection of vulnerabilities in privileged programs by execution monitoring. In Proceedings of the 10th Annual Computer Security Applications Conference (ACSAC), 1994.

[9] B. Kuperman and E. H. Spafford. Generation of application level audit data via library interposition. CERIAS TR 99-11, COAST Laboratory, Purdue University, Oct. 1998.

[10] T. Lane and C. E. Brodley. Temporal sequence learning and data reduction for anomaly detection. ACM Transactions on Information and System Security, 2(3):295–331, 1999.

[11] W. Lee, S. J. Stolfo, and K. W. Mok. A data mining framework for building intrusion detection models. In IEEE Symposium on Security and Privacy, 1999.

[12] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A fast automaton-based method for detecting anomalous program behaviors. In IEEE Symposium on Security and Privacy, 2001.

[13] K. Tan, K. Killourhy, and R. Maxion. Undermining an anomaly-based intrusion detection system using common exploits. In Recent Advances in Intrusion Detection (RAID), 2002.

[14] K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal to the normal and beyond. In Fifth International Workshop on Information Hiding, 2002.

[15] F. Tip and J. Palsberg. Scalable propagation-based call graph construction algorithms. In Proceedings of the Conference on Object-Oriented Programming Languages, Systems and Applications (OOPSLA), 2000.

[16] D. Wagner. Static Analysis and Computer Security: New Techniques for Software Assurance. PhD thesis, University of California, Berkeley, 2000.

[17] D. Wagner and D. Dean. Intrusion detection via static analysis. In IEEE Symposium on Security and Privacy, 2001.

[18] D. Wagner and P. Soto. Mimicry attacks on host-based intrusion detection systems. In Ninth ACM Conference on Computer and Communications Security, 2002.

[19] A. Wespi, M. Dacier, and H. Debar. Intrusion detection using variable-length audit trail patterns. In Third International Workshop on Recent Advances in Intrusion Detection (RAID), 2000.