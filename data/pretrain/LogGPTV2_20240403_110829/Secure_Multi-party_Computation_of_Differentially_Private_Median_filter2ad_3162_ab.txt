1Smooth sensitivity approximations exist that provide a factor of 2 ap-
proximation in linear-time, or an additive error of max(U)/poly(|D|) in
sublinear-time [58, Section 3.1.1]. Note that this error e is w.r.t. smooth
sensitivity s, the additive noise is even larger with Laplace((s + e)/ε).
USENIX Association
29th USENIX Security Symposium    2149
0.10.250.50510152025Avg.Abs.ErrorsSmoothSensitivityThisworkExponentialMechanism0.10.250.5024681012Avg.Abs.ErrorsSmoothSensitivityThisworkExponentialMechanism2.2 Secure Multi-party Computation
Secure multi-party computation (MPC) [36] allows a set
of three or more parties P = {P1, . . . ,Pn}, where party Pi
holds sensitive input di, to jointly compute a function y =
f (d1, . . . ,dn) while protecting their inputs. The computation
must be correct, i.e., the correct y is computed, and secret, i.e.,
only y and nothing else is revealed. There are two main imple-
mentation paradigms for MPC [32,46]: garbled circuits [68]2,
where the parties construct a (large, encrypted) circuit and
evaluate it at once, and secret sharing [12, 21, 57, 62], where
the parties interact for each circuit gate. In general, the for-
mer allows for constant number of rounds but requires larger
bandwidth (as fewer, but bigger messages are sent), and the
latter has low bandwidth (small messages per gate) and high
throughput, where the number of rounds depends on the cir-
cuit depth. We will focus on secret-sharing-based MPC as
our goal is an efﬁcient implementation in a network with
reasonable latency. Informally, a (t,n)-secret sharing scheme
splits a secret s into n shares si and at least t shares are re-
quired to reconstruct the secret. We use (cid:104)s(cid:105) = (s1, . . . ,sn) to
denote the sharing of s among n parties (for a formal deﬁni-
tion see, e.g., Evans et al. [32]). Recent works, e.g., SCALE-
MAMBA [6], BDOZ [12], SPDZ [21], improve MPC perfor-
mance by combining a computationally secure ofﬂine phase,
to exchange correlated randomness (e.g., Beaver triples [11]),
with an information-theoretic secure online phase. The former
is generally more efﬁcient since the latter requires asymmetric
cryptography [47]. MPC can be implemented in two models
with different trust assumptions: in the semi-honest model
(passive) adversaries do not deviate from the protocol but
gather everything created during the run of the protocol, in
the malicious model (active) adversaries can deviate from the
protocol (e.g., alter messages).
In this work we consider n input parties with sensitive
input, and m (e.g., m ∈ {3,6,10}) semi-honest computation
parties, i.e., non-colluding untrusted servers. The input parties
create and send shares of their input to the computation parties,
which run the secure computation on their behalf. We assume
semi-honest parties but explain how to extend our protocol
to malicious parties and implement our protocol with the
SCALE-MAMBA framework [6].
3 Secure EM for Median Selection
We implement a multi-party computation of the exponential
mechanism EM for rank-based statistics enabling distributed
parties to learn the differentially private median of their joint
data. There are two challenges for multi-party computation
of the exponential mechanism:
2Yao described a garbled circuit for two parties in an oral presentation
about secure function evaluation [68], the ﬁrst written description is from [37],
and the ﬁrst proof was given in [49].
(i) the running time complexity is linear in the size of the
data universe, |U|, as selection probabilities for all pos-
sible outputs in U are computed,
(ii) the general mechanism is too inefﬁcient for general se-
cure computation as selection probability computation
requires |U| exponentiations over ﬂoating-point numbers.
We solve these challenges by (i) recursively dividing the data
universe into subranges to achieve sublinear running time in
|U|, and (ii) focusing on utility functions which allow efﬁ-
cient selection probability computation. We call such utility
functions decomposable, which we formalize in Section 3.1,
and give example applications.
In the following, we describe an overview of our solution.
We efﬁciently compute the exponential mechanism with run-
ning time complexity sublinear in the size of the data universe
U by dividing U into k subranges. We select the best sub-
range and also split it into k subranges for the next iteration,
until the last subrange is small enough to directly select the
ﬁnal output from it. After (cid:100)logk |U|(cid:101) iterations the selected
subrange contains only one element. Each subrange selection
increases the overall privacy loss ε, and we enable users to
select a trade-off between running time, privacy loss and accu-
racy by presenting three protocols to compute unnormalized
selection probabilities, which we call weights, w.r.t. ε:
• Weightsln(2) ﬁxes ε = ln(2) to compute exp(εy) as 2y,
• Weightsln(2)/2d allows ε = ln(2)
2d
• Weights∗ supports arbitrary ε.
On a high-level, we have three phases in each iteration:
for some integer d > 0,
1. Evaluate: Each party locally computes the basis for util-
ity scores for each subrange.
2. Combine: They combine their results into a global result
and compute selection probabilities.
3. Select: Finally, they select an output based on its selec-
tion probabilities.
The results of the evaluation step are computed over sensitive
data and might also be sensitive (e.g., utility functions for
median and mode leak exact counts [48]). Therefore, we com-
bine them via MPC to preserve privacy. To ensure efﬁcient
implementation of the combination step we require utility
functions to have a certain structure as detailed next.
3.1 Decomposability & Applications
Recall, each party Pi holds a single value di (we can generalize
to data sets Di). To combine local utility scores per party
into a global score for all, we require utility functions to be
decomposable:
2150    29th USENIX Security Symposium
USENIX Association
Application
Utility
Convex optimization: ﬁnd x that minimizes
∑n
i=1 l(x,di) with convex loss function l de-
ﬁned over D; e.g., empirical risk minimization
in machine learning [10, 63], and integer parti-
tions (password frequency lists) [16]
Unlimited supply auction: ﬁnd price x max-
imizing revenue x∑i bi(x), where bidder de-
mand curve bi indicates how many goods bid-
der i will buy at price x; e.g., digital goods [52]
Frequency: select x based on its frequency in
D; e.g., mode [48]
Rank-based statistics: select x based on its
rank in sorted D; e.g., kth-ranked element [48]
−∑n
i=1 l(x,di)
x∑i bi(x)
∑n
i=1 1x=di
See
Section 3.2
Table 1: Applications with decomposable utility functions.
Deﬁnition 4 (Decomposability). We call a function u : (U n×
R ) → R decomposable w.r.t. function u(cid:48) : (U n × R ) → R if
u(D,x) = ∑n
i=1 u(cid:48)(di,x) for x ∈ R and D = {d1, . . . ,dn}.
We use decomposability to easily combine utility scores in
Weightsln(2), Weightsln(2)/2d , and to avoid secure evaluation
of the exponential function in Weights∗3. If u is decompos-
able, users can compute weights locally, and securely combine
them via multiplications:
∏
i
exp(u(cid:48)(di,x)ε) = exp(∑
i
u(cid:48)(di,x)ε) = exp(u(D,x)ε).
Decomposability is satisﬁed by a wide range of selection
problems. Counts are clearly decomposable and so are utility
functions that can be expressed as a sum of utility scores.
Applications with decomposable utility functions are listed
in Table 1. One use case for the median is a software com-
pany collecting private usage statistics, e.g., number of times a
procedure was run or the size of database tables, in a medium-
sized installed base. Reporting the median in addition to the
mean allows the collector to detect skew in the distribution.
Another example is private federated learning with network
resource constrained parties, e.g., mobile phones on cellu-
lar networks. Gradient compressed federated learning, e.g.,
signSGD [13], enables to reduce the update message size
for these parties, but uses the median instead of the mean to
aggregate the gradients. The additional communication stem-
ming from our secure median computation can be shifted to
few parties who are not network resource constrained, e.g.,
mobile phones on WiFi networks.
To be sublinear in the size of the universe we consider
decomposability w.r.t. ranges instead of elements: parties only
3Secure exponentiation is complex [5,7,20,43], requiring many interactive
rounds, and we want to avoid the expensive computational overhead.
report one utility score per range, instead of one score per
element. Decomposability for elements x ∈ U does not imply
decomposability for ranges R ⊂ U 4. However, we present a
decomposable utility function w.r.t. ranges for rank-based
statistics next.
3.2 Decomposable Median Utility Function
First, we describe the median utility function [48]. Then, we
present a reformulation more convenient for secure imple-
mentation and show that it is decomposable.
Li et al. [48, Section 2.4.3] quantify an element’s utility
via its rank relative to the median. The rank of x ∈ U in a
data set D is the number of values in D smaller than x. More
formally, rankD(x) = |{d | d ∈ D : d  µ). This observation leads us to the following
deﬁnition without iterations:
Deﬁnition 6 (Simpliﬁed Median Utility Function). The me-
µ : (U n ×U) → Z gives a utility score
dian utility function uc
for a range R = [rl,ru) of U w.r.t. D ∈ U n as
rankD(ru)− n
2 − rankD(rl)
0
2
n
uc
µ(D,R) =
if rankD(ru)  n
2
else
.
4Consider the mode, i.e., the most frequent element. E.g., for two parties
with data sets D1 = {1,1,1,2,2},D2 = {2,2,3,3,3} the mode per data set
is 1 resp. 3 but the mode for the combined data is 2.
USENIX Association
29th USENIX Security Symposium    2151
1. Set s = (cid:100)logk |U|(cid:101) and split privacy budget ε into ε1, . . . ,εs
2. Initialize S = U and repeat below steps s times:
(a) Every party p ∈ P divides S into k equal-sized subranges
{Ri = [ri
i. if ε j = ln(2)/2d in step j (with integer d ≥ 0), input
u)}k
l,ri
i=1
u)(cid:9)k
l),rankDp (ri
i=1,d
(cid:8)rankDp (ri
(cid:110)
ii. else input
l ))(cid:111)k
,ε j
i=1
eε j(rankDp (ri
u)−|Dp|/2),eε j(|Dp|/2−rankDp (ri
(b) The functionality combines the inputs (Section 3.2)
and outputs S = Ri with probability proportional to
exp(uc
µ(D,Ri)ε j)
Figure 3: Ideal functionality FEM∗ for EM∗.
In the following, we generalize from a single value per
(input) party, di, to multiple values, i.e., data set Di, as com-
putation parties operate on data sets later on. Deﬁnition 5
and 6 are equivalent as can be seen by proof by cases (see
Appendix B), and uc
µ is decomposable w.r.t.:
rankDi(ru)− |Di|
|Di|
2 − rankDi(rl)
2
0
u(cid:48)(Di,R) =
if rankD(ru)  n
2
else
,
where rankD(r) = ∑n
i=1 rankDi(r) for range endpoints r. We
will use both utility deﬁnitions interchangeably. Speciﬁcally,
we use uµ to simplify notation in our accuracy proofs (Sec-
tion 3.4), and uc
µ in our implementation (Section 4).
For implementations Weightsln(2), Weightsln(2)/2d the par-
ties input ranks for lower and upper range endpoints (as in
u(cid:48) above), which we combine (as uc
µ) to efﬁciently compute
weights. For Weights∗ we let the parties input weights, i.e.,
exp(εu(cid:48)), which we can efﬁciently combine via multiplication.
In more detail, weights for u(cid:48) are:
(cid:17)
(cid:16)
rankDi (ru)− |Di|
(cid:16) |Di|
(cid:17)
2 −rankDi (rl )
eε
1
2 ))  eε( n
else
(cid:16)