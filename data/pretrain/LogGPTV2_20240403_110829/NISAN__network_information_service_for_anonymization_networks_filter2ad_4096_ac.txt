 50
 40
 30
 20
 10
 0
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
Factor
Figure 5: Factor inﬂuence on success probability (1)
positives and the rate of found malicious nodes, when the adver-
saries make their FT contain only colluded nodes by changing en-
tries to the next colluded node where necessary. Even if the attacker
is the correct owner of the searched ID, in case his FT check fails,
his ID is thrown out resulting in a smaller fraction of malicious
nodes found than present in the system.
]
%
[
d
n
u
o
f
s
e
d
o
n
s
u
o
i
c
i
l
a
m
f
o
n
o
i
t
c
a
r
F
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5
 0
Factor influence (100,000 Peers, 20% malicious)
Without Filter
Filter with factor 4
Filter with factor 3
Filter with factor 2
 0
 5
 10
 15
 20
Finger table entries replaced
Figure 6: Factor inﬂuence on success probability (2)
In contrast to that, in Figure 6 malicious nodes detect the search
directions and intelligently replace honest nodes with colluded ones,
starting with the honest nodes closest to the searched area. This
is done in such a way that the closest malicious node to the to-
be-replaced honest node is selected for this operation. This in-
creases the plausibility of modiﬁed FTs. The other entries remain
unchanged. We can see the dependency of the attacker success rate
on both the FT tolerance factor and the number of replaced entries.
A staggering ﬁnding here is that replacing all the entries in the FT
with the closest malicious nodes does not help the adversary to sig-
niﬁcantly increase the rate of its nodes in the ﬁnal results of the
queries, even if the searcher were to believe all these FTs. Thus,
as long as the FTs look plausible, the attacker is not able to sig-
niﬁcantly bias the user selection, even if he provides the searcher
with only malicious nodes. This provides a clue into why NISAN,
or the combination of aggregated greedy search with ﬁnger table
checking, provides such strong protection against eclipse attacks:
by forcing the attacker to conform closely to the original structure
of the DHT and aggregating results, we can always correct mis-
]
%
[
n
o
i
t
c
a
r
F
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
Factor influence (1,000,000 Peers, 20% malicious)
Malicious nodes found
Honest finger tables rejected
 1
 1.5
 2
 2.5
 3
 3.5
 4
 4.5
 5
Factor
Figure 7: Malicious nodes know the FT acceptance threshold
In Figure 7 we additionally assume that the adversary knows the
FT acceptance threshold of the users. As in the previous plot the at-
tacker learns the search value. He replaces FT entries in the search
direction, but only up to the acceptance threshold, so that his FT
would be still accepted by an honest user. This is the strongest ad-
versarial behavior that we tested, because it seems hard to conceive
of an easy way for the attackers to optimize their responses beyond
this point. The optimization problems arising are hard enough to
describe, let alone solve efﬁciently. Certainly, there is ample space
for future research in this direction. Because the structure of DHTs
like Chord seems so benign to our approach, we conjecture though,
that the effect of further optimization, at least when restricted to
efﬁciently solvable problems, will be limited.
As our simulations show, bounds checking on FTs is a very
promising technique. A FT tolerance factor of 3 seems to be a
good choice for the considered setup. As Figure 7 shows, virtually
no FTs of honest users are rejected when we apply this factor. Fur-
thermore, malicious nodes are not able to increase their rate in the
system while changing more than 3 entries (see Figure 6). Know-
ing the searched ID and the acceptance threshold of the honest users
does not help malicious nodes to signiﬁcantly increase their rate in
the queries beyond their rate in the system as Figure 7 suggests.
Castro et al. [5] give a very precise statistical method for optimiz-
ing the tolerance factor when checking ﬁnal results. Their method
could easily be adapted to our FT checking. Yet, we ﬁnd that sim-
ply selecting an ad-hoc value such as 3 works pretty well in our
simulations. Further inspection of Figure 6 helps us to understand
this: We are relatively free to minimize the false positive rate by
choosing a rather high tolerance factor, because there is no need to
strictly minimize the false negatives. This is because as long as the
fraction of malicious nodes found remains below the actual attacker
rate f , it just makes no sense for an attacker to lie about its FT.
Performing the FT check test based on the mean distance only is
certainly not the only possibility. Possibly, other strategies would
yield even better results. In fact, the whole armament of statisti-
cal classiﬁcation techniques can be imagined to be brought to use.
However, the results show that even our simple strategy works well
in the considered simulations. That is why we leave improvements
146in this direction for future work. See Section 6.3 for arguments why
research in this direction might still be worthwhile. One possible
improvement might be to consider only (or to weight additionally)
those entries which are leading into the direction of search and are
considered for the top list of log2(n) best nodes seen so far. If an
adversary is able to learn the search direction, these are the ﬁrst
entries he would replace.
As the results show, our protection works well against an active
attacker. Most of the simulations provided here have been con-
ducted with 20% of malicious nodes in the system. However, we
have also conducted simulations for 1,10, and 40% of colluding
nodes, respectively. Due to the space limit and similarity of the
results we forego their presentation in this paper.
5.4 Further Improvements
We have analyzed the rate of the malicious nodes in the log2(n)
best nodes list depending on the iteration. Our initial idea was to
also accept the nodes found in the intermediate steps of a search
as onion router candidates in order to mitigate bridging and ﬁnger-
printing attacks. However, as the results in Figure 8 show, this is
not a good idea. Still, the rate of colluded nodes in the last search it-
eration corresponds to the rate of malicious nodes if we only look at
the single result of the search (cf. Figure 7). Thus, it makes sense to
consider the whole list of log2(n) closest nodes to the search value
instead of the single value only as possible routers. This increases
the uncertainty of an attacker about the nodes which are known to
honest users (as their number is signiﬁcantly increased), and thus
helps us counter passive information leakage attacks, as explained
in the following section.
Fraction of malicious peers seen/queried (1,000,000 Peers, 20% malicious)
 50
 40
 30
 20
 10
]
%
[
s
r
e
e
p
s
u
o
i
c
i
l
a
m
f
o
n
o
i
t
c
a
r
F
Fraction of malicious nodes seen overall
Fraction of malicious peers in the top log(n) list
Number of peers seen
 3000
 2400
 1800
 1200
 600
n
e
e
s
s
r
e
e
p
f
o
r
e
b
m
u
N
 0
 0
 2
 4
 6
 8
 10
 12
 14
 0
 16
Iteration
Figure 8: Fraction of malicious nodes depending on the itera-
tion
6. DISCUSSION AND ALTERNATIVES
In this section, we discuss challenges to network information
services that have rarely been seriously addressed when proposing
new methods, but have to be considered when deploying a system
in the real world. One of these is information leakage, which invites
passive attacks such as bridging and ﬁngerprinting.
The ﬁngerprinting attack relies on the fact that an adversary,
observing some tunnel through the network can associate it to a
small set of possible initiators. Bridging an honest node assumes
that, similarly as with the ﬁngerprinting, the nodes constructing the
paths only know a fraction of all routers. Thus, not all combinations
of in-/output links of a router are valid: possibly no node knows all
the routers needed to construct them. In order to deanonymize a
user, the attacker has to control (or observe) at least the exit node
involved in the user’s tunnel. Observing or controlling the middle
node can be used to further reduce the set of possible initiators.
For a full deanonymization, however, the involved combination of
nodes should be known to a single user only. In other cases this
information merely reduces the anonymity set (the set of possible
initiators), but does not necessarily give conﬁdence in the conjec-
ture.
Even though from our point of view bridging and ﬁngerprint-
ing attacks have been of rather theoretical interest so far and could
not yet be shown to signiﬁcantly compromise anonymity in open
networks like Tor, where the number of users is estimated to be in
the hundreds of thousands, we still ﬁnd it challenging to look for
defenses against these attacks. Because all approaches with par-
tial knowledge about the network known so far are susceptible to
them, we try to overcome these attacks by discussing a radically
different alternative to NISAN, namely random walk, as well as a
combination of both methods.
After evaluating these two approaches, in 6.2 we address the of-
ten overlooked question of bootstrapping. While keeping a rather
generic view, we give implementation pointers and argue why we
believe that NISAN can be bootstrapped and maintained securely
when carefully implemented. Finally, in 6.3 a more powerful adver-
sarial model is examined, as we look into NISAN’s behavior under
the assumption that the attacker is free to choose their positioning
within the ID space of the DHT.
6.1 Information Leakage and Random Walks
All known DHT-based information distribution services, includ-
ing NISAN, are endangered by passive information leakage attacks
[15, 6]. These attacks generally use the fact that searching in a DHT
entails talking to many colluded nodes in the process. The redun-
dancy typically used to prevent active attacks only makes this ex-
posure worse, so that we may even talk about a trade-off in protec-
tion against active and passive attacks [15]. Through these search
queries, the attacker learns who is searching whom, either directly
or through linking multiple queries. Measures such as recursive
routing or hiding the search goal may make this information harder
to obtain or less precise, yet in general cannot keep the adversary
from gaining signiﬁcant insight. This kind of information can then
be abused in a number of subtle ways that are out of scope in this
paper. In fact, the types of attacks possible have become a very
active research topic lately [15, 6]. Still, in all of these attacks the
worst case that can arise is the attacker gaining knowledge of the
complete routing circuit. Though this is clearly not desirable, there
is little research about the consequences in real-world systems. Ar-
guably, we are worse off if the attacker controls the routing circuit,
as is the goal of eclipse attacks. That is why so far, we have placed
emphasis on avoiding this kind of attack.
The information leakage in NISAN lies in giving away x, or,
more precisely, the link between the searching node v and x. Through
hiding the search value (cf. 5.2) and taking into consideration the
whole top list at the end of the search (cf. 5.4) we have already
introduced some uncertainty for the attacker. In general, a good
way to raise the entropy for the attacker in our choice of circuit
nodes is to simply conduct multiple searches, sequentially or in
parallel, thereby learning a greater part of the network. Moreover,
such behavior, especially when conducted by a great many nodes,
may serve to obscure the links between searchers and searched-for
nodes.
Although these measures may foil most attacks in practice, and
though it is not clear how much an attacker could proﬁt at all from
knowledge gained this way, it would obviously be preferable from a
147 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
)
g
-
2
.
1
(
/
2
.
0
 0.2
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
g
Figure 9: Theoretical lower bound to attacker success on ran-
dom walks for attacker ratio f = 0.2 and increasing attacker
ﬁnger table corruption g
theoretical point of view if we could provably avoid passive attacks
altogether. Hence we looked for an entirely different approach that
cannot give away a search goal since there is no such thing. A
random walk (RW) through the network is a relatively obvious so-
lution.
In a RW, we randomly select one of our neighbors, ask this
neighbor for its ﬁnger table, and, again, randomly select one of
its neighbors, iterating this method for a path length l. On average,
l should at least be log2(n), since this ensures that each peer in the
DHT can be reached by the RW. Intuitively, there is little informa-
tion leakage in this process, probably as little as we can reach when
routing in a DHT, since there really is no direction to the search that
might be leaked.
It is clear that this approach can be combined with our ﬁnger ta-
ble checking to keep the attacker from presenting arbitrary neigh-
bor tables and thus hijacking a path with certainty. Still, we have
to assume a different ratio g of colluding nodes in attacker ﬁn-