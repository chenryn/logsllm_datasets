    type = "S"
  }
}
terraform {
  backend "s3" {
    bucket = "provider-tfstate"
    key    = "global/s3/terraform.tfstate"
    region = "eu-west-1"
    encrypt = "true"
    dynamodb_table = "global-s3"
  }
}
```
You'll probably need to execute an `terraform apply` with the `dynamodb_table`
line commented
If you want to unforce a lock, execute:
```bash
terraform force-unlock {{ unlock_id }}
```
You get the `unlock_id` from an error trying to execute any `terraform` command
# Modules
In terraform you can put code inside of a `module` and reuse in multiple places
throughout your code.
The provider resource should be specified by the user and not in the modules
Whenever you add a module to your terraform template or modify its source
parameter you need to run a get command before you run `plan` or `apply`
```bash
terraform get
```
To extract output variables of a module to the parent tf file you should use
`${module.{{module.name}}.{{output_name}}}`
## Basics
Any set of Terraform templates in a directory is a module.
The good practice is to have a directory called `modules` in your parent project
directory. There you git clone the desired modules. and for example inside
`pro/services/bastion/main.tf` you'd call it with:
```terraform
provider "aws" {
  region = "eu-west-1"
}
module "bastion" {
  source = "../../../modules/services/bastion/"
}
```
## Outputs
Modules encapsulate their resources. A resource in one module cannot directly
depend on resources or attributes in other modules, unless those are exported
through outputs. These outputs can be referenced in other places in your
configuration, for example:
```terraform
resource "aws_instance" "client" {
  ami               = "ami-408c7f28"
  instance_type     = "t1.micro"
  availability_zone = "${module.consul.server_availability_zone}"
}
```
# Import
You can import the different parts with `terraform import
{{resource_type}}.{{resource_name}} {{ resource_id }}`
For examples see the documentation of the desired resource.
## Bulk import
But if you want to bulk import sources, I suggest using `terraforming`.
# Bad points
* Manually added resources wont be managed by terraform, therefore you can't use
  it to enforce as shown in this
  [bug](https://github.com/hashicorp/terraform/issues/4728).
* If you modify the LC of an ASG, the instances don't get rolling updated, you
  have to do it manually.
* They call the dictionaries `map`... (/ﾟДﾟ)/
* The conditionals are really ugly. You need to use `count`.
* You [can't split long strings](https://github.com/hashicorp/hcl/issues/211) xD
# Best practices
Name the resources with `_` instead of `-` so the editor's completion work :)
## VPC
Don't use the default vpc
## Security groups
Instead of using `aws_security_group` to define the ingress and egress rules,
use it only to create the empty security group and use `aws_security_group_rule`
to add the rules, otherwise you'll get into a cycle loop
The sintaxis of an egress security group must be
`egress_from_{{source}}_to_destination`. The sintaxis of an ingress security
group must be `ingress_to_{{destination}}_from_{{source}}`
Also set the order of the arguments, so they look like the name.
For ingress rule:
```terraform
security_group_id = ...
cidr_blocks = ...
```
And in egress should look like:
```terraform
security_group_id = ...
cidr_blocks = ...
```
Imagine you want to filter the traffic from A -> B, the egress rule from A to
B should go besides the ingress rule from B to A.
### Default security group
You can't manage the default security group of an vpc, therefore you have to
adopt it and set it to no rules at all with `aws_default_security_group`
resource
# IAM
You have to generate an gpg key and export it in base64
```bash
gpg --export {{ gpg_id }} | base64
```
To see the secrets you have to decrypt it
```bash
terraform output secret | base64 --decode | gpg -d
```
# [Sensitive information](https://blog.gruntwork.io/a-comprehensive-guide-to-managing-secrets-in-your-terraform-code-1d586955ace1)
One of the most common questions we get about using Terraform to manage infrastructure as code is how to handle secrets such as passwords, API keys, and other sensitive data.
Your secrets live in two places in a terraform environment:
* [The Terraform state](#sensitive-information-in-the-terraform-state)
* [The Terraform source code](#sensitive-information-in-the-terraform-source-code).
## Sensitive information in the Terraform State
Every time you deploy infrastructure with Terraform, it stores lots of data about that infrastructure, including all the parameters you passed in, in a state file. By default, this is a terraform.tfstate file that is automatically generated in the folder where you ran terraform apply. 
That means that the secrets will end up in terraform.tfstate in plain text! This has been an [open issue](https://github.com/hashicorp/terraform/issues/516) for more than 6 years now, with no clear plans for a first-class solution. There are some workarounds out there that can scrub secrets from your state files, but these are brittle and likely to break with each new Terraform release, so I don’t recommend them.
For the time being, you can:
* *Store Terraform state in a backend that supports encryption*: Instead of storing your state in a local `terraform.tfstate` file, Terraform natively supports a variety of backends, such as S3, GCS, and Azure Blob Storage. Many of these backends support encryption, so that instead of your state files being in plain text, they will always be encrypted, both in transit (e.g., via TLS) and on disk (e.g., via AES-256). Most backends also support collaboration features (e.g., automatically pushing and pulling state; locking), so using a backend is a must-have both from a security and teamwork perspective.
* *Strictly control who can access your Terraform backend*: Since Terraform state files may contain secrets, you’ll want to carefully control who has access to the backend you’re using to store your state files. For example, if you’re using S3 as a backend, you’ll want to configure an IAM policy that solely grants access to the S3 bucket for production to a small handful of trusted devs (or perhaps solely just the CI server you use to deploy to prod).
There are several approaches here.
First rely on the S3 encryption to protect the information in your state file.
Second, use [Vault
provider](https://www.terraform.io/docs/providers/vault/index.html) to protect the state file.
Third (but I won't use it) would be to use [terrahelp](https://github.com/opencredo/terrahelp)
## Sensitive information in the Terraform source code
To store secrets in your source code you can:
* [Use Secret Stores](https://blog.gruntwork.io/a-comprehensive-guide-to-managing-secrets-in-your-terraform-code-1d586955ace1#bebe)
* [Use environment variables](https://blog.gruntwork.io/a-comprehensive-guide-to-managing-secrets-in-your-terraform-code-1d586955ace1#4df5)
* [Use encrypted files](https://blog.gruntwork.io/a-comprehensive-guide-to-managing-secrets-in-your-terraform-code-1d586955ace1#3073)
Using Secret Stores is the best solution, but for that you'd need access and trust in a Secret Store provider which I don't have at the moment (if you want to follow this path check out Hashicorp Vault). Using environment variables is the worst solution because this technique helps you avoid storing secrets in plain text in your code, but it leaves the question of how to actually securely store and manage the secrets unanswered. So in a sense, this technique just kicks the can down the road, whereas the other techniques described later are more prescriptive. Although you could use a password manager such as `pass`. Using encrypted files is the solution that remains.
If you don't want to install a secret store and are used to work with GPG, you can encrypt the secrets, store the cipher text in a file, and checking that file into the version control system. To encrypt some data, such as some secrets in a file, you need an encryption key. This key is itself a secret! This creates a bit of a conundrum: how do you securely store that key? You can’t check the key into version control as plain text, as then there’s no point of encrypting anything with it. You could encrypt the key with another key, but then you then have to figure out where to store that second key. So you’re back to the “kick the can down the road problem,” as you still have to find a secure way to store your encryption key. Although you can use external solutions such as AWS KMS or GCP KMS we don't want to store that kind of information on big companies servers. A local and more beautiful way is to rely on PGP to do the encryption.
We'll use then [`sops`](https://github.com/mozilla/sops) a Mozilla tool for managing secrets that can use PGP behind the scenes. `sops` can automatically decrypt a file when you open it in your text editor, so you can edit the file in plain text, and when you go to save those files, it automatically encrypts the contents again. 
Terraform does not yet have native support for decrypting files in the format used by `sops`. One solution is to install and use the custom provider for sops, [`terraform-provider-sops`](https://github.com/carlpett/terraform-provider-sops). Another option, is to use [Terragrunt](https://terragrunt.gruntwork.io/). To avoid installing more tools, it's better to use the terraform provider.
First of all you may need to install `sops`, you can grab the latest release [from their downloads page](https://github.com/mozilla/sops/releases).
Then in your terraform code you need to [select the `sops` provider](https://github.com/carlpett/terraform-provider-sops):
```hcl
terraform {
  required_providers {
    sops = {
      source = "carlpett/sops"
      version = "~> 0.5"
    }
  }
}
```
Configure `sops` by defining the gpg keys in a `.sops.yaml` file at the top of your repository:
```yaml
---
creation_rules:
  - pgp: >-
      2829BASDFHWEGWG23WDSLKGL323534J35LKWERQS,
      2GEFDBW349YHEDOH2T0GE9RH0NEORIG342RFSLHH
```
Then create the secrets file with the command `sops secrets.enc.json` somewhere in your terraform repository. For example:
```json
{
  "password": "foo",
  "db": {"password": "bar"}
}
```
You'll be able to use these secrets in your terraform code. For example:
```hcl
data "sops_file" "secrets" {
  source_file = "secrets.enc.json"
}
output "root-value-password" {
  # Access the password variable from the map
  value = data.sops_file.secrets.data["password"]
}
output "mapped-nested-value" {
  # Access the password variable that is under db via the terraform map of data
  value = data.sops_file.secrets.data["db.password"]
}
output "nested-json-value" {
  # Access the password variable that is under db via the terraform object
  value = jsondecode(data.sops_file.secrets.raw).db.password
}
```
Sops also supports encrypting the entire file when in other formats. Such files can also be used by specifying `input_type = "raw"`:
```hcl
data "sops_file" "some-file" {
  source_file = "secret-data.txt"
  input_type = "raw"
}
output "do-something" {
  value = data.sops_file.some-file.raw
}
```
## RDS credentials
The RDS credentials are saved in plaintext both in the definition and in the
state file, see [this](https://github.com/hashicorp/terraform/issues/516) bug
for more information. The value of `password` is not compared against the value
of the password in the cloud, so as long as the string in the code and the state
file remains the same, it won't try to change it.
As a workaround, you can create the RDS with a fake password `changeme`, and
once the resource is created, run an `aws` command to change it. That way, the
value in your code and the state is not the real one, but it won't try to change
it.
Inspired in [this
gist](https://gist.github.com/mattupstate/27f2bf26d3712b6b7973) and the
[`local-exec`](https://www.terraform.io/docs/language/resources/provisioners/local-exec.html)
docs, you could do:
```hcl
resource "aws_db_instance" "main" {
    username = "postgres"
    password = "changeme"
    ...
}
resource "null_resource" "master_password" {
    triggers {
        db_host = aws_db_instance.main.address
    }
    provisioner "local-exec" {
        command = "pass generate rds_main_password; aws rds modify-db-instance --db-instance-identifier $INSTANCE --master-user-password $(pass show rds_main_password)"
        environment = {
            INSTANCE = aws_db_instance.main.identifier
        }
    }
}
```
Where the password is stored in your `pass` repository that can be shared with
the team.
If you're wondering why I added such a long line, well it's because of HCL! as
you [can't split long strings](https://github.com/hashicorp/hcl/issues/211),
marvelous isn't it? xD
# Loops
You can't use nested lists or dictionaries, see this [2015 bug](https://github.com/hashicorp/terraform/issues/2114)
## Loop over a variable
```hcl
variable "vpn_egress_tcp_ports" {
  description = "VPN egress tcp ports "
  type = "list"
  default = [50, 51, 500, 4500]
}
resource "aws_security_group_rule" "ingress_tcp_from_ops_to_vpn_instance"{
  count = "${length(var.vpn_egress_tcp_ports)}"
  type = "ingress"
  from_port   = "${element(var.vpn_egress_tcp_ports, count.index)}"
  to_port     = "${element(var.vpn_egress_tcp_ports, count.index)}"
  protocol    = "tcp"
  cidr_blocks = [ "${var.cidr}"]
  security_group_id = "${aws_security_group.pro_ins_vpn.id}"
}
```
# Refactoring
Refactoring in terraform is **ugly business**
## Refactoring in modules
If you try to refactor your terraform state into modules it will try to destroy
and recreate all the elements of the module...
## [Refactoring the state file](https://www.terraform.io/docs/commands/state/mv.html)
```bash
terraform state mv -state-out=other.tfstate module.web module.web
```
# [Google cloud integration](https://www.terraform.io/docs/providers/google/index.html)
You configure it in the terraform directory
```terraform
// Configure the Google Cloud provider
provider "google" {
  credentials = "${file("account.json")}"
  project     = "my-gce-project"
  region      = "us-central1"
}
```
To download the json go to the [Google Developers
Console](https://console.developers.google.com/). Go to `Credentials` then
`Create credentials` and finally `Service account key`.
Select `Compute engine default service account` and select `JSON` as the key
type.
# [Ignore the change of an attribute](https://www.terraform.io/docs/language/meta-arguments/lifecycle.html#syntax-and-arguments)
Sometimes you don't care whether some attributes of a resource change, if that's
the case use the `lifecycle` statement:
```hcl
resource "aws_instance" "example" {
  # ...
  lifecycle {
    ignore_changes = [
      # Ignore changes to tags, e.g. because a management agent
      # updates these based on some ruleset managed elsewhere.
      tags,
    ]
  }
}
```
# [Define the default value of an variable that contains an object as empty](https://github.com/hashicorp/terraform/issues/19898)
```hcl
variable "database" {
  type = object({
    size                 = number
    instance_type        = string
    storage_type         = string
    engine               = string
    engine_version       = string
    parameter_group_name = string
    multi_az             = bool
  })
  default     = null
```
# Conditionals
## Elif
```terraform
locals {
  test = "${ condition ? value : (elif-condition ? elif-value : else-value)}"
}
```
## [Do a conditional if a variable is not null](https://stackoverflow.com/questions/53200585/terraform-conditionals-if-variable-does-not-exist)
```hcl
resource "aws_db_instance" "instance" {
  count                = var.database == null ? 0 : 1
  ...
```
# [Debugging](https://www.terraform.io/docs/internals/debugging.html)
You can set the `TF_LOG` environmental variable to one of the log levels
`TRACE`, `DEBUG`, `INFO`, `WARN` or `ERROR` to change the verbosity of the logs.
To remove the debug traces run `unset TF_LOG`.
# Snippets
## [Create a list of resources based on a list of strings](https://developer.hashicorp.com/terraform/language/meta-arguments/count)
```hcl
variable "subnet_ids" {
  type = list(string)
}
resource "aws_instance" "server" {
  # Create one instance for each subnet
  count = length(var.subnet_ids)
  ami           = "ami-a1b2c3d4"
  instance_type = "t2.micro"
  subnet_id     = var.subnet_ids[count.index]
  tags = {
    Name = "Server ${count.index}"
  }
}
```
If you want to use this generated list on another resource extracting for example the id you can use
```hcl
aws_instance.server.*.id
```
# References
* [Docs](https://www.terraform.io/docs/index.html)
* [Modules registry](https://registry.terraform.io/)
* [terraform-aws-modules](https://github.com/terraform-aws-modules)
* [AWS providers](https://www.terraform.io/docs/providers/aws/index.html)
* [AWS examples](https://github.com/brikis98/terraform-up-and-running-code)
* [GCloud examples](https://github.com/mjuenema/Terraform-Up-and-Running-Code-Samples-Translated/)
* [Good and bad sides of terraform](https://charity.wtf/2016/02/23/two-weeks-with-terraform/)
* [Awesome Terraform](https://github.com/shuaibiyy/awesome-terraform)