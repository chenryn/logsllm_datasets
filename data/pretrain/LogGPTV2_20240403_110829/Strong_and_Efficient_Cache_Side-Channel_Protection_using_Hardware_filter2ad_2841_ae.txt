6.4 GTK keystroke example
We investigated leakage in the GTK framework, which
performs a binary search to translate raw keyboard in-
puts to platform-independent key names and key values.
Gruss et al. [24] demonstrated that this leaks signiﬁcant
information on single keys typed by a user, in an auto-
mated cache template attack. Their attack on GDK li-
brary version 3.10.8 has partially been resolved on cur-
rent Linux systems with GDK library version 3.18.9. In-
stead of multiple binary searches that leak information
we only identiﬁed one binary search that is still per-
formed upon every keystroke.
USENIX Association
26th USENIX Security Symposium    227
Cacheline0x807000x83200Key0AZCacheline0x807000x83200Key0AZcontains a predicate which is evaluated on features of the
input record. As a result, observations of unprotected
tree traversal can leak information about the tree and the
input record. In this particular case, several trees in a so-
called decision forest are traversed for each input record.
Our Cloak-enhanced implementation of the algorithm
contains three programmer-annotated functions, which
translates into three independent transactions. The most
complex of these traverses a preloaded tree for a batch of
preloaded input records. The batching of input records is
crucial here for performance, as it amortizes the cost of
preloading a tree. We give a detailed explanation and a
code sample of tree traversal with Cloak in Appendix A.
Evaluation. We compiled our
implementation for
SGX enclaves using the extended compiler and a cus-
tom SGX software stack. We used a pre-trained decision
forest for the Covertype data set from the UCI Machine
Learning Repository5. Each tree in the forest consists of
30497—32663 nodes and has a size of 426 KB–457 KB.
Each input record is a vector of 54 ﬂoating point val-
ues. We chose the Covertype data set because it pro-
duces large trees and was also used in previous work by
Ohrimenko et al. [49], which also mitigates side channel
leakage for enclave code.
We report on experiments executed on a mostly idle
system equipped with a TSX and SGX-enabled Intel
Core i7-6700 CPU and 16 GB DDR4 RAM running Win-
dows Server 2016 Datacenter. In our container library,
we reserved eight L1 cache sets for writable arrays, re-
sulting in an overall write set size of 4 KB. Figure 13
shows the cycles spent inside the enclave (including en-
tering and leaving the enclave) per input record averaged
over ten runs for differently sized input batches. These
batches were randomly drawn from the data set. The
sizes of the batches ranged from 5 to 260. For batches
larger than 260, we observed capacity aborts with high
probability. Nonetheless, seemingly random capacity
aborts could also be observed frequently even for small
batch sizes. The number of aborts also increased with
higher system load. The cost for restarting transactions
on aborts is included in Figure 13.
As baseline, we ran inside SGX the same algorithm
without special containers and preloading and without
transactions. The baseline was compiled with the un-
modiﬁed version of the Microsoft C++ compiler at the
highest optimization level. As can be seen, the number
of cycles per query greatly decreases with the batch size.
Batching is particularly important for Cloak, because
it enables the amortization of cache preloading costs.
Overall, the overhead ranges between +79% (batch size
5) and +248% (batch size 260). The overhead increases
5https://archive.ics.uci.edu/ml
Figure 13: Average number of cycles per query for deci-
sion forest batch runs of different sizes.
with the batch size, because the baseline also proﬁts from
batching (i.e., “cache warming” effects and amortization
of costs for entering/leaving the enclave), while the pro-
tected version experiences more transactional aborts for
larger batches. We also ran a similar micro-benchmark
outside SGX with more precise timings. Here, the effect
of batching was even clearer: for a batch size of 5, we
observed a very high overhead of +3078%, which grad-
ually decreased to +216% for a batch size of 260.
Even though the experimental
setting in Ohri-
menko et al. [49] is not the same as ours (for instance
they used the ofﬁcial Intel SGX SDK, an older version
of the compiler, and their input data was encrypted) and
they provide different guarantees, we believe that their
reported overhead of circa +6200% for a single query to
SGX highlights the potential efﬁciency of Cloak.
7.2 Service Contracts with the OS
Applying the basic Cloak techniques to sensitive enclave
code reduces the risk of side-channel attacks. However,
enclave code is especially vulnerable as the correspond-
ing attacker model (see Section 3) includes malicious
system software and hardware attacks. In particular, ma-
licious system software, i.e., the OS, can amplify side-
channel attacks by concurrently (A1) interrupting and re-
suming enclave threads [40], (A2) unmapping enclave
pages [61], (A3) taking control of an enclave thread’s
sibling hyper-thread (HT) [11], or (A4) repeatedly reset-
ting an enclave. A3 is of particular concern in Cloak
as TSX provides requirement R2 (see Section 4) only for
the LLC. Hence, code and data in the read set are not pro-
tected against a malicious HT which can perform attacks
over the L1 and L2 caches from outside the enclave. In
the following, we describe how Cloak-protected enclave
code can ensure that the OS is honest and does not mount
attacks A1–A4.
228    26th USENIX Security Symposium
USENIX Association
 0 500000 1x106 1.5x106 2x106 2.5x106 3x106 0 50 100 150 200 250 300 0 1 2 3 4average cycles per queryaverage overhead (Cloak / baseline)queries per batchaverage cycles per query: Cloakaverage cycles per query: baselineaverage overhead (Cloak / baseline)7.2.1 Checking the Honesty of the OS
While SGX does not provide functionality to directly
check for A1 and A2 or to prevent them, it is simple with
Cloak: our experiments showed in line with Intel’s docu-
mentation [31] that transactions abort with code OTHER
(no bits set in the abort code) in case of interrupts or ex-
ceptions. In case unexpected aborts of this type occur,
the enclave may terminate itself as a countermeasure.
Preventing A3 is more involved and requires several
steps: before executing a transaction, we demand that
(i) both HTs of a CPU core enter the enclave and (ii) re-
main there. To enforce (ii), the two threads write a unique
marker to each thread’s State Save Area (SSA) [32] in-
side the enclave. Whenever a thread leaves an enclave
asynchronously (e.g., because of an interrupt), its regis-
ters are saved in its SSA [32]. Hence, every unexpected
exception or interrupt necessarily overwrites our mark-
ers in the SSAs. By inspecting the markers, we can thus
ensure that neither of the threads was interrupted (and
potentially maliciously migrated to a different core by
the OS). One thread now enters a Cloak transaction and
veriﬁes the two markers, making them part of its read set.
Thus, as we conﬁrmed experimentally, any interruption
of the threads would overwrite an SSA marker in the read
set and cause an immediate transactional abort with code
CONFLICT (bit three set in the abort code).
Unfortunately, for (i), there is no direct way for en-
clave code to tell if two threads are indeed two corre-
sponding HTs. However, after writing the SSA markers,
before starting the SSA transaction, the enclave code can
initially conduct a series of experiments to check that,
with a certain conﬁdence, the two threads indeed share
an L1 cache. One way of doing so is to transmit a se-
cret (derived using the rdrand instruction inside the en-
clave) over a timing-less L1-based TSX covert channel:
for each bit in the secret, the receiver starts a transac-
tion and ﬁlls a certain L1 cache set with write-set cache
lines and busy-waits within the transaction for a certain
time; if the current bit is 1, the sender aborts the re-
ceiver’s transaction by touching conﬂicting cache lines of
the same cache set. Otherwise, it touches non-conﬂicting
cache lines. After the transmission, both threads com-
pare their versions of the secret. In case bit-errors are
below a certain threshold, the two threads are assumed
to be corresponding HTs. In our experiments, the covert
channel achieved a raw capacity of 1 MB/s at an error
rate of 1.6% between two HTs. For non-HTs, the er-
ror rate was close to 50% in both cases, showing that no
cross-core transmission is possible.6 While a malicious
OS could attempt to eavesdrop on the sender and replay
for the receiver to spoil the check, a range of additional
6Using the read set instead yields a timing-less cross-core covert
channel with a raw capacity of 335 KB/s at an error rate of 0.4%.
countermeasures exists that would mitigate this attack.
For example, the two threads could randomly choose a
different L1 cache set (out of the 64 available) for each
bit to transmit.
To protect against A4, the enclave may use SGX’s
trusted monotonic counters [3] or require an online con-
nection to its owner on restart.
Finally, the enclave may demand a private LLC parti-
tion, which could be provided by the OS via Intel’s re-
cent Cache Allocation Technology (CAT) feature [32] or
“cache coloring” [11,37,58]. A contract violation would
become evident to the enclave through increased num-
bers of aborts with code CONFLICT.
8 Limitations and Future Work
Cache attacks are just one of many types of side-channel
attacks and Cloak naturally does not mitigate all of them.
Especially an adversary able to measure the execution
time of a transaction might still derive secret information.
Beyond this, Cloak instantiated with Intel TSX may be
vulnerable to additional side channels that have not yet
been explored. We identiﬁed ﬁve potential side channels
that should be investigated in more detail: First, the in-
teraction of the read set and the “second level structure”
(i.e., the bloom ﬁlter) is not documented. Second, other
caches, such as translation-lookaside buffers and branch-
prediction tables, may still leak information. Third, the
Intel TSX abort codes may provide side-channel infor-
mation if accessible to an attacker. Fourth, variants of
Prime+Probe that deliberately evict read set cache lines
from L1 to the LLC but not to DRAM could potentially
obtain side-channel information without causing trans-
action aborts. Fifth, the execution time of transactions
including in particular the timings of aborts may leak in-
formation. Finally, it is important to note that Cloak is
limited by the size of the CPU’s caches, since code and
data that have secret-dependent accesses must ﬁt in the
caches. TSX runtime behavior can also be difﬁcult to
predict and control for the programmer.
9 Related Work
Using HTM for Security and Safety. The Mimosa
system [25] uses TSX to protect cryptographic keys in
the Linux kernel against different forms of memory dis-
closure attacks. Mimosa builds upon the existing TRE-
SOR system [47], which ensures that a symmetric master
key is always kept in the CPU’s debug registers. Mi-
mosa extends this protection to an arbitrary number of
(asymmetric) keys. Mimosa always only writes pro-
tected keys to memory within TSX transactions. It en-
sures that these keys are wiped before the correspond-
USENIX Association
26th USENIX Security Symposium    229
ing transaction commits. This way, the protected keys
are never written to RAM. However, Mimosa does not
prevent cache side-channel attacks.
Instead, for AES
computations it uses AES-NI, which does not leak in-
formation through the cache. However, a cache attack on
the square-and-multiply routine of RSA in the presence
of Mimosa would still be possible. To detect hardware
faults, the HAFT system [39] inserts redundant instruc-
tions into programs and compares their behavior at run-
time. HAFT uses TSX to efﬁciently roll-back state in
case a fault was encountered.
Probably closest related to Cloak is the recent T-SGX
approach [59]. It employs TSX to protect SGX enclave
code against the page-fault side channel [61], which can
be exploited by a malicious OS that unmaps an enclave’s
memory pages (cf. Section 7). At its core, T-SGX lever-
ages the property that exceptions within TSX transac-
tions cause transactional aborts and are not delivered to
the OS. T-SGX ensures that virtually all enclave code
is executed in transactions. To minimize transactional
aborts, e.g., due to cache-line evictions, T-SGX’s ex-
tension of the Clang compiler automatically splits en-
clave code into small execution blocks according to a
static over-approximation of L1 usage. At runtime, a
springboard dispatches control ﬂow between execution
blocks, wrapping each into a separate TSX transaction.
Thus, only page faults related to the springboard can be
(directly) observed from the outside. All transactional
aborts are handled by the springboard, which may termi-
nate the enclave when an attack is suspected. For T-SGX,
Shih et al. [59] reported performance overheads of 4%–
108% across a range of algorithms and, due to the strat-
egy of splitting code into small execution blocks, caused
only very low rates of transactional aborts.
The strategy employed by T-SGX cannot be generally
transferred to Cloak, as—for security—one would need
to reload the code and data of a sensitive function when-
ever a new block is executed. Hence, this strategy is not
likely to reduce cache conﬂicts, which is the main reason
for transactional aborts in Cloak, but rather increase per-
formance overhead. Like T-SGX, the recent D´ej`a Vu [8]
approach also attempts to detect page-fault side-channel
attacks from within SGX enclaves using TSX: an en-
clave thread emulates an non-interruptible clock through
busy waiting within a TSX transaction and periodically
updating a counter variable. Other enclave threads use
this counter for approximate measuring of their execu-
tion timings along certain control-ﬂow paths.
In case
these timings exceed certain thresholds, an attack is as-
sumed. Both T-SGX and D´ej`a Vu conceptually do not
protect against common cache side-channel attacks.
Prevention of Resource Sharing. One branch of de-
fenses against cache attacks tries to reduce resource shar-
ing in multi-tenant systems. This can either be imple-
mented through hardware modiﬁcations [12, 52], or by
dynamically separating resources. Shi et al. [58] and
Kim et al. [37] propose to use cache coloring to isolate
different tenants in cloud environments. Zhang et al. [68]
propose cache cleansing as a technique to remove infor-
mation leakage from time-shared caches. Godfrey et al.
[18] propose temporal isolation through scheduling and
resource isolation through cache coloring. More re-
cently Zhou et al. [69] propose a more dynamic approach
where pages are duplicated when multiple processes ac-
cess them simultaneously. Their approach can make at-
tacks signiﬁcantly more difﬁcult to mount, but not im-
possible. Liu et al. [42] propose to use Intel CAT to split
the LLC, avoiding the fundamental resource sharing that
is exploited in many attacks.
In contrast to Cloak, all
these approaches require changes on the OS level.
Detecting Cache Side-Channel Leakage. Other de-
fenses aim at detecting potential side-channel leakage
and attacks, e.g., by means of static source code analy-
sis [13] or by performing dynamic anomaly detection us-
ing CPU performance counters. Gruss et al. [23] explore
the latter approach and devise a variant of Flush+Reload
that evades it. Chiappetta et al. [9] combine performance
counter-based detection with machine learning to detect
yet unknown attacks. Zhang et al. [65] show how per-
formance counters can be used in cloud environments to
detect cross-VM side-channel attacks. In contrast, Cloak
follows the arguably stronger approach of mitigating at-
tacks before they happen. Many attacks require only a
small number of traces or even work with single mea-
surements [17, 43, 62]. Thus, Cloak can provide protec-
tion where detection mechanisms fail due to the inherent
detection delays or too coarse heuristics. Further, reliable
performance counters are not available in SGX enclaves.
10 Conclusions
We presented Cloak, a new technique that defends
against cache side-channel attacks using hardware trans-
actional memory. Cloak enables the efﬁcient retroﬁtting
of existing algorithms with strong cache side-channel
protection. We demonstrated the efﬁcacy of our ap-
proach by running state-of-the-art cache side-channel at-
tacks on existing vulnerable implementations of algo-
rithms. Cloak successfully blocked all attacks in every
attack scenario. We investigated the imperfections of In-
tel TSX and discussed the potentially remaining leakage.
Finally, we showed that one of the main limitations of
Intel SGX, the lack of side-channel protections, can be
overcome by using Cloak inside Intel SGX enclaves.
230    26th USENIX Security Symposium
USENIX Association
References
[1] ACIIC¸ MEZ, O., GUERON, S., AND SEIFERT, J.-P. New branch
prediction vulnerabilities in OpenSSL and necessary software
countermeasures. In IMA International Conference on Cryptog-
raphy and Coding (2007).
[2] ALLAN, T., BRUMLEY, B. B., FALKNER, K., VAN DE POL, J.,
AND YAROM, Y. Amplifying side channels through performance
degradation. In Anual Computer Security Applications Confer-
ence (ACSAC) (2016).
[3] ANATI, I., GUERON, S., JOHNSON, S., AND SCARLATA, V.
Innovative technology for CPU based attestation and sealing. In
International Workshop on Hardware and Architectural Support
for Security and Privacy (HASP) (2013).
[4] BERNSTEIN, D. J. Cache-timing attacks on AES. Tech. rep.,
Department of Mathematics, Statistics, and Computer Science,
University of Illinois at Chicago, 2005.
[5] BHATTACHARYA, S., AND MUKHOPADHYAY, D. Curious case
of Rowhammer: Flipping secret exponent bits using timing anal-
ysis. In Conference on Cryptographic Hardware and Embedded