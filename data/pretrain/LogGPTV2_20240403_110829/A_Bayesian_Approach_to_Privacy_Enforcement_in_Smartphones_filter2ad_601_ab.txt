values. In practice, however, assuming (i) the distance
metric d(. . .) satisﬁes d(x,y) ≤ max{|x|,|y|}, (ii) ∃c ∈
N. |[[F]]| ≤c (as with the IMEI, IMSI, location, etc.), and
(iii) [[F]] is not compared with values larger than it, we
can bound [[F]] by c. In general, any feature can be made
ﬁnite, with (at most) n+1 possible values, by introducing
a privileged “≥ n” value, which denotes that the distance
between the reference and relevant values is at least n.
3.2 Measuring Distance between Values
To compute a quantitative measure of similarity between
data values, we exploit the fact that private data often
manifests as strings of ASCII characters [4, 9, 27]. These
include e.g. device identiﬁers (like the IMEI and IMSI
numbers), GPS coordinates, inter-application communi-
cation (IPC) parameters, etc. This lets us quantify dis-
tance between values in terms of string metrics.
Many string metrics have been proposed to date [17].
Two simple and popular metrics, which we have exper-
imented with and satisfy the requirement that d(x,y) ≤
max{|x|,|y|}, are the following:
Hamming Distance This metric assumes that
the
strings are of equal length. The Hamming distance be-
tween two strings is equal to the number of positions at
which the corresponding symbols are different (as indi-
cated by the indicator function δc1(cid:23)=c2(. . .)):
ham(a,b) =Σ 0≤i<|a|δc1(cid:23)=c2 (a(i),b(i))
In another view, Hamming distance measures the num-
ber of substitutions required to change one string into the
other.
Levenshtein Distance The Levenshtein string met-
ric computes the distance between strings a and b as
leva,b(|a|,|b|) (abbreviated as lev(|a|,|b|)), where
Informally,
lev(|a|,|b|) is the minimum number of
single-character edits — either insertion or deletion or
lev(i, j) =
max(i, j)
min
lev(i− 1, j) +1
lev(i, j− 1) +1
lev(i− 1, j− 1) +δ ai(cid:23)=b j
if min(i, j) = 0
 otherwise
Data: Strings u and v
Data: Distance metric d
begin
x ←− |u| < |v| ? u : v // min
y ←− |u| ≥ |v| ? u : v // max
r ←− y
for i = 0 to |y|−|x| do
y(cid:20) ←− y[i,i +|x|−1]
if d(x,y(cid:20)) < r then
r ←− d(x,y(cid:20))
end
end
return r
end
Algorithm 1: The BAYESDROID distance measure-
ment algorithm
substitution — needed to transform one string into the
other. An efﬁcient algorithm for computing the Leven-
shtein distance is bottom-up dynamic programming [24].
The asymptotic complexity is O(|a|·|b|).
Given string metric d(x,y) and pair (u,v) of reference
value u and relevant value v, BAYESDROID computes
their distance according to the following steps:
1. BAYESDROID ensures that both u and v are String
objects by either (i) invoking toString() on refer-
ence types or (ii) converting primitive types into
Strings (via String.valueOf(. . .)), if the argument
is not already of type String.
2. To meet the conservative requirement that |x| = |y|
(i.e., x and y are of equal length), BAYESDROID ap-
plies Algorithm 1. This algorithm induces a sliding
window over the longer of the two strings, whose
width is equal to the length of the shorter string. The
shorter string is then compared to contiguous seg-
ments of the longer string that have the same length.
The output is the minimum across all comparisons.
To ensure that comparisons are still meaningful un-
der length adjustment, we decompose private values into
indivisible information units. These are components of
the private value that cannot be broken further, and so
comparing them with a shorter value mandates that the
shorter value be padded. In our speciﬁcation, the phone,
IMEI and IMSI numbers consist of only one unit of
information. The Location object is an example of a
data structure that consists of several distinct informa-
tion units. These include the integral and fractional parts
of the longitude and latitude values, etc. BAYESDROID
handles objects that decompose into multiple informa-
tion units by treating each unit as a separate object and
applying the steps above to each unit in turn. The no-
tion of information units guards BAYESDROID against
ill-founded judgments, such as treating release of a sin-
gle IMEI digit as strong evidence for leakage.
USENIX Association  
23rd USENIX Security Symposium  179
5
3.3 Estimating Probabilities
The remaining challenge, having clariﬁed what the fea-
tures are and how their values are computed, is to esti-
mate the probabilities appearing in Equation 4:
(cid:127) We need to estimate the probability of the legiti-
mate event, Pr(legitimate), where illegitimate is the
complementary event and thus Pr(illegitimate) =
1− Pr(legitimate).
(cid:127) We need to estimate the conditional probabilities
Pr(F = u|legitimate) and Pr(F = u|illegitimate) for
all features F and respective values u.
Pr(legitimate) can be approximated straightforwardly
based on available statistics on the frequency of data
leaks in the wild. For the conditional probabilities, as-
suming feature Xi is discrete valued with j distinct val-
ues (per the discussion in Section 3.1 above), we would
naively compute the estimated conditional probability
θi jk according to the following equation:
#D{Xi=xi j∧Y =yk}
#D{Y =yk}
(5)
θi jk = (cid:31)Pr(Xi = xi j|Y = yk) =
The danger, however, is that this equation would produce
estimates of zero if the data happens not to contain any
training examples satisfying the condition in the numer-
ator. To ﬁx this, we modify Equation 5 as follows:
#D{Xi=xi j∧Y =yk}+l
#D{Y =yk}+l·J
θi jk = (cid:31)Pr(Xi = xi j|Y = yk) =
(6)
where l is a factor that “smoothens” the estimate by
adding in a number of “hallucinated” examples that are
assumed to be spread evenly across the J possible values
of Xi. In Section 5.1, we provide concrete detail on the
data sets and parameter values we used for our estimates.
4 The BAYESDROID Algorithm
In this section, we describe the complete BAYESDROID
algorithm. We then discuss enhancements of the core
algorithm.
4.1 Pseudocode Description
Algorithm 2 summarizes the main steps of BAYES-
DROID. For simplicity, the description in Algorithm 2
assumes that source statements serve private data as
their return value, though the BAYESDROID implemen-
tation also supports other sources (e.g. callbacks like
onLocationChanged(. . .), where the private Location ob-
ject is passed as a parameter). We also assume that each
source maps to a unique privacy feature. Hence, when
a source is invoked (i.e., the OnSourceStatement event
ﬁres), we obtain the unique tag corresponding to its re-
spective feature via the GetFeature(. . .) function. We
Input: S // privacy specification
begin
while true do
OnSourceStatement r := src p :
// map source to feature
f ←− GetFeature src
attach tag f to r
OnNormalStatement r := nrm p :
propagate feature tags according to data ﬂow
OnSinkStatement r := snk p :
// map feat.s to param.s with resp.
tag
{ f (cid:24)→ p f} ←− ExtractTags p
foreach f → p f ∈ { f → p f} do
u ←− ref f
δ ←− min{d(u, [[p]])}p∈p f
f ←− δ ≥ c f ? “ ≥c f ”: δ
end
if IsLeakageClassification { f} then
end
Alarm snk p
end
end
Algorithm 2: Outline of the core BAYESDROID algo-
rithm
then attach the tag to the return value r. Normal data
ﬂow obeys the standard rules of tag propagation, which
are provided e.g. by Enck et al. [4]. (See Table 1 there.)
When an OnSinkStatement event is triggered, the ar-
guments ﬂowing into the sink snk are searched for pri-
vacy tags, and a mapping from features f to parameters
p f carrying the respective tag is built. The value of f is
then computed as the minimal pairwise distance between
the parameters p ∈ p f and ref f . If this value is greater
than some constant c f deﬁned for f , then the privileged
value “≥ c f ” is assigned to f . (See Section 3.1.) Finally,
the judgment IsLeakageClassification is applied over
the features whose tags have reached the sink snk. This
judgment is executed according to Equation 4.
We illustrate the BAYESDROID algorithm with ref-
erence to Figure 3, which demonstrates a real leak-
age instance in com.g6677.android.princesshs, a pop-
ular gaming application.
In this example, two differ-
ent private items ﬂow into the sink statement: both the
IMEI, read via getDeviceId(), and the Android ID, read
via getString(...).
At sink statement URL.openConnection(...), the re-
spective tags IMEI and AndroidID are extracted. Values
are assigned to these features according to the description
in Section 3, where we utilize training data, as discussed
later in Section 5.1, for Equation 6:
Pr(IMEI ≥ 5|leg) = 0.071 Pr(AndID ≥ 5|leg) = 0.047
Pr(IMEI ≥ 5|ilg) = 0.809
Pr(AndID ≥ 5|ilg) = 0.833
6
180  23rd USENIX Security Symposium 
USENIX Association
1 source : private value
TelephonyManager.getDeviceId() : 000000000000000
Settings $Secure.getString (...)
: cdf15124ea4c7ad5
2
3
4
5 sink : arguments
getSystemService(TELEPHONY SERVICE);
1 TelephonyManager tm =
2
3 String imei = tm.getDeviceId(); // source
4 String encodedIMEI = Base64Encoder.encode(imei);
5 Log.i (encodedIMEI); // sink
6 URL.openConnection(...) : app id=2aec0559c930 ... &
7
android id =cdf15124ea4c7ad5 \& udid= ... &
serial id = ... & ... &
publisher user id =000000000000000
8
9
Figure 3: True leakage detected by BAYESDROID in
com.g6677.android.princesshs
We then compute Equation 4, where the denominator
is the same for both leg and illeg, and so it sufﬁces to
evaluate the nominator (denoted with ˜Pr(...) rather than
Pr(...)):
˜Pr(leg|IMEI ≥ 5,AndID ≥ 5) =
Pr(leg)× Pr(IMEI ≥ 5|leg)× Pr(AndID ≥ 5|leg) =
˜Pr(ilg|IMEI ≥ 5,AndID ≥ 5) =
Pr(ilg)× Pr(IMEI ≥ 5|ilg)× Pr(AndID ≥ 5|ilg) =
0.66× 0.071× 0.047 = 0.002
0.33× 0.809× 0.833 = 0.222
Our estimates of 0.66 for Pr(leg) and 0.33 for Pr(ilg) are
again based on training data as explained in Section 5.1.
The obtained conditional measure of 0.222 for ilg is (far)
greater than 0.002 for leg, and so BAYESDROID resolves
the release instance in Figure 3 as a privacy threat, which
is indeed the correct judgment.
4.2 Enhancements
We conclude our description of BAYESDROID by high-
lighting two extensions of the core algorithm.
Beyond Plain Text While many instances of illegiti-
mate information release involve plain text, and can be
handled by the machinery in Section 3.1, there are also
more challenging scenarios. Two notable challenges are
(i) data transformations, whereby data is released follow-
ing an encoding, encryption or hashing transformation;
and (ii) high-volume binary data, such as camera or mi-
crophone output. We have extended BAYESDROID to
address both of these cases.
We begin with data transformations. As noted ear-
lier, in Section 1, private information is sometimes re-
leased following standard hashing/encoding transforma-
tions, such as the Base64 scheme. This situation, il-
lustrated in Figure 4, can distort feature values, thereby
Figure 4: Adaptation of the DroidBench Loop1 bench-
mark, which releases the device ID following Base64 en-
coding
leading BAYESDROID to erroneous judgments. Fortu-
nately, the transformations that commonly manifest in
leakage scenarios are all standard, and there is a small
number of such transformations [9].
To account for these transformations, BAYESDROID
applies each of them to the value obtained at a source
statement, thereby exploding the private value into mul-
tiple representations. This is done lazily, once a sink is
reached, for performance. This enhancement is speciﬁed
in pseudocode form in Algorithm 3. The main change is
the introduction of a loop that traverses the transforma-
tions τ ∈ T , where the identity transformation, λ x. x, is
included to preserve the (non-transformed) value read at
the source. The value assigned to feature f is then the
minimum with respect to all transformed values.
Binary data — originating from the microphone, cam-
era or bluetooth adapter — also requires special han-
dling because of the binary versus ASCII representation
and, more signiﬁcantly, its high volume. Our solution is
guided by the assumption that such data is largely treated
as “uninterpreted” and immutable by application code
due to its form and format. This leads to a simple yet
effective strategy for similarity measurement, whereby a
ﬁxed-length preﬁx is truncated out of the binary content.
Truncation is also applied to sink arguments consisting
of binary data.
Heuristic Detection of Relevant Values So far, our
description of the BAYESDROID algorithm has relied on
tag propagation to identify relevant values at the sink
statement. While this is a robust mechanism to drive fea-
ture computation, ﬂowing tags throughout the code also
has its costs, incurring runtime overheads of ≥ 10% and
affecting the stability of the application due to intrusive
instrumentation [4].
These weaknesses of the tainting approach have led us
to investigate an alternative method of detecting relevant
values. A straightforward relaxation of data-ﬂow track-
ing is bounded (“brute-force”) traversal of the reachable
values from the arguments to a sink statement up to some
depth bound k: All values pointed-to by a sink argument
or reachable from a sink argument via a sequence of ≤ k
ﬁeld dereferences are deemed relevant. Though in theory
USENIX Association  
23rd USENIX Security Symposium  181
7
Input: T ≡ {λ x. x,τ1, . . . ,τ n} // std.
begin
. . .
OnSinkStatement r := snk p :
transformations
{ f (cid:28)→ p f} ←− ExtractTags p
foreach f → p f ∈ { f → p f} do
foreach τ ∈ T do
u ←− τ (ref f )
δ ←− min{d(u, [[p]])}p∈p f
f ←− min{[[ f ]],δ ≥ c f ? “ ≥c f ”: δ}
end
end
. . .
end
Algorithm 3: BAYESDROID support for standard data
transformations
this might introduce both false positives (due to irrele-
vant values that are incidentally similar to the reference
value) and false negatives (if k is too small, blocking rel-
evant values from view), in practice both are unlikely, as
we conﬁrmed experimentally. (See Section 5.)
For false positives, private values are often unique, and
so incidental similarity to irrelevant values is improbable.
For false negatives, the arguments ﬂowing into privacy
sinks are typically either String objects or simple data
structures. Also, because the number of privacy sinks is
relatively small, and the number of complex data struc-
tures accepted by such sinks is even smaller, it is pos-
sible to specify relevant values manually for such data
structures. We have encountered only a handful of data
structures (e.g.
the android.content.Intent class) that
motivate a speciﬁcation.
5 Experimental Evaluation
In this section, we describe the BAYESDROID implemen-
tation, and present two sets of experiments that we have
conducted to evaluate our approach.
5.1 The BAYESDROID System
Implementation Similarly to existing tools like Taint-
Droid, BAYESDROID is implemented as an instrumented
version of the Android SDK. Speciﬁcally, we have in-
strumented version 4.1.1 r6 of the SDK, which was cho-
sen intentionally to match the most recent version of
TaintDroid.3 The experimental data we present indeed
utilizes TaintDroid for tag propagation (as required for
accurate resolution for relevant values).
3 http://appanalysis.org/download.html
Beyond the TaintDroid instrumentation scheme, the
BAYESDROID scheme speciﬁes additional behaviors for
sources and sinks within the SDK. At source points, a
hook is added to record the private value read by the
source statement (which acts as a reference value). At
sink points, a hook is installed to apply Bayesian reason-
ing regarding the legitimacy of the sink.
Analogously to TaintDroid, BAYESDROID performs
privacy monitoring over APIs for ﬁle-system access and
manipulation, inter-application and socket communica-
tion, reading the phone’s state and location, and sending
of text messages. BAYESDROID also monitors the HTTP
interface, camera, microphone, bluetooth and contacts.
As explained in Section 4.1, each of the privacy sources
monitored by BAYESDROID is mirrored by a tag/fea-
ture. The full list of features is as follows: IMEI, IMSI,
AndroidID, Location, Microphone, Bluetooth, Camera,
Contacts and FileSystem.
The BAYESDROID implementation is conﬁgurable,
enabling the user to switch between distance metrics as
well as enable/disable information-ﬂow tracking for pre-
cise/heuristic determination of relevant values. (See Sec-
tion 4.2.) In our experiments, we tried both the Leven-
shtein and the Hamming metrics, but found no observ-
able differences, and so we report the results only once.
Our reasoning for why the metrics are indistinguishable
is because we apply both to equal-length strings (see Sec-
tion 3.2), and have made sure to apply the same metric
both ofﬂine and online, and so both metrics achieve a
very similar effect in the Bayesian setting.
Training To instantiate BAYESDROID with the re-
quired estimates, as explained in Section 3.3, we ap-
plied the following methodology: First,
to estimate
Pr(legitimate), we relied on (i) an extensive study by
Hornyack et al. spanning 1,100 top-popular free Android
apps [9], as well as (ii) a similarly comprehensive study
by Enck et al. [5], which also spans a set of 1,100 free
apps. According to the data presented in these studies,
approximately one out of three release points is illegiti-
mate, and thus (cid:31)Pr(legitimate) =0.66 and complementar-
ily (cid:31)Pr(illegitimate) =1 − 0.66 ≈ 0.33.
For the conditional probabilities (cid:31)Pr(Xi = xi j|Y = yk),
we queried Google Play for the 100 most popular apps
(across all domains) in the geography of one of the au-
thors. We then selected at random 35 of these apps, and
analyzed their information-release behavior using debug
breakpoints (which we inserted via the adb tool that is
distributed as part of the Android SDK).
Illegitimate leaks that we detected ofﬂine mainly in-
volved (i) location information and (ii) device and user
identiﬁers, which is consistent with the ﬁndings reported
by past studies [9, 5]. We conﬁrmed that illegitimate
leaks are largely correlated with high similarity between
182  23rd USENIX Security Symposium 
USENIX Association
8
private data and sink arguments, and so we ﬁxed six dis-