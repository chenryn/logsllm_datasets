such that they explore states similar to the root cause. This
allows for a comparative analysis of how crashes and non-
crashes behave on the buggy path.
To efﬁciently generate such inputs, we can use the crash
exploration mode bundled with fuzzers such as AFL. As de-
scribed previously, this mode applies mutations to inputs as
long as they keep crashing. Inputs not crashing the binary
are discarded from the queue and saved to the non-crashing
set; all inputs remaining within the fuzzing queue constitute
the crashing set. In general, the more diversiﬁed inputs crash
exploration produces, the more precise the statistical analysis
becomes. Fewer inputs are produced in less time but cause
more false positives within the subsequent analysis. Once the
input sets have been created, they are passed to the analysis
component.
3.2 Monitoring Input Behavior
Given the two sets of inputs—crashing and non-crashing—we
are interested in collecting data allowing semantic insights
into an input’s behavior. To accommodate our binary-only
approach, we monitor the runtime execution of each input,
collecting the values of various expressions. For each instruc-
tion executed, we record the minimum and maximum value of
all modiﬁed registers (this includes general-purpose registers
and the ﬂag register). Similarly, we record the maximum and
minimum value stored for each memory write access. Notably
and perhaps surprisingly, we did not observe any beneﬁt in
tracing the memory addresses used; therefore, we do not ag-
gregate information on the target addresses. It seems that the
resulting information is too noisy and all relevant information
is already found in observed registers. We only trace the mini-
mum and maximum of each value to limit the amount of data
produced by loops. This loss of information is justiﬁed by the
insight that values causing a crash usually surface as either
a minimum or maximum value. Our evaluation empirically
supports this thesis. This optimization greatly increases the
performance, as the amount of information stored per instruc-
tion is constant. At the same time, it is precise enough to allow
statistical identiﬁcation of differences. Besides register and
memory values, we store information on control-ﬂow edges.
This allows us to reconstruct a coarse control-ﬂow graph for
a speciﬁc input’s execution. Control ﬂow is interesting behav-
ior, as it may reveal code that is only executed for crashing
inputs. Furthermore, we collect the address ranges of stack
and heap to test whether certain pointers are valid heap or
stack pointers.
We do not trace any code outside of the main executable,
i. e., shared libraries. This decreases overhead signiﬁcantly
while removing tracing of code that—empirically—is not
interesting for ﬁnding bugs within a given binary program.
For each input, we store this information within a trace ﬁle
that is passed on to the statistical analysis.
3.3 Explanation Synthesis
Based on the monitoring, explanation synthesis is provided
with two sets of trace ﬁles that describe intrinsic behaviors
of crashing and non-crashing inputs. Our goal is to isolate
behavior in the form of predicates that correlate to differences
between crashing and non-crashing runs. Any such predi-
cate pointing to an instruction indicates that this particular
instruction is related to a bug. Our predicates are Boolean
expressions describing concrete program behavior, e. g., “the
maximum value of rax at this position is less than 2”. A pred-
icate is a triple consisting of a semantic description (i. e., the
Boolean expression), the instruction’s address at which it is
evaluated and a score indicating the ability to differentiate
crashes from non-crashes. In other words, the score expresses
the probability that an input crashes for which the predicate
evaluates to true. Consequently, predicates with high scores
identify code locations somewhere on the path between root
cause and crashing location. In the last step, we sort these
predicates ﬁrst by score, then by the order in which they were
executed. Given this sorted list of predicates, a human analyst
can then manually analyze the bug. Since these predicates
and the calculation of the score are the core of our approach,
we present more details in the following section.
4 Predicate-based Root Cause Analysis
Given the trace information for all inputs in both sets, we
can reason about potential root cause locations and deter-
mine predicates that explain the root cause. To this end, we
construct predicates capable of discriminating crashing and
non-crashing runs, effectively pinpointing conditions within
the program that are met only when encountering the crash.
Through the means of various heuristics described in Sec-
tion 4.4, we ﬁlter the conditions and deduce a set of locations
close to the root cause of a bug, aiding a developer in the
tedious task of ﬁnding and ﬁxing the root cause. This step po-
tentially outputs a large number of predicates, each of which
partitions the two sets. In order to determine the predicate
explaining the root cause, we set conditional breakpoints that
represent the predicate semantics. We then proceed to exe-
cute the binary for each input in the crashing set, recording
the order in which predicates are triggered. As a result, we
obtain for each input the order in which the predicates were
encountered during execution. Given this information and the
predicates’ scores, we can deﬁne a ranking over all predicates.
In the following, we present this approach in detail.
The ﬁrst step is to read the results obtained by tracing the
inputs’ behavior. Given these traces, we collect all control-
ﬂow transitions observed in crashing and non-crashing inputs
and construct a joined control-ﬂow graph that is later used to
synthesize control-ﬂow predicates. Afterward, we compute
the set of instructions identiﬁed by their addresses that are rel-
evant for our predicate-based analysis. Since we are interested
USENIX Association
29th USENIX Security Symposium    239
in behavioral differences between crashes and non-crashes,
we only consider addresses that have been visited by at least
one crashing and one non-crashing input. Note that—as a
consequence—some addresses are discarded if they are vis-
ited in crashes but not in non-crashes. However, in such a
situation, we would observe control-ﬂow transitions to these
discarded addresses from addresses that are visited by inputs
from both sets. Consequently, we do not lose any precision
by removing these addresses.
Based on the trace information, we generate many predi-
cates for each address (i. e., each instruction). Then, we test
all generated predicates and store only the predicate with
the highest score. In the following, we describe the types of
predicates we use, how these predicates can be evaluated and
present our ranking algorithm. Note that by assumption a
predicate forecasts a non-crash, if it is based on an instruction
that was never executed. This is motivated by the fact that
not-executed code cannot be the cause of a crash.
4.1 Predicate Types
To capture a wide array of possible explanations of a software
fault’s root cause, we generate three different categories of
predicates, namely (1) control-ﬂow predicates, (2) register and
memory predicates, as well as (3) ﬂag predicates. In detail,
we use the following types of predicates:
Control-ﬂow Predicates. Based on the reconstructed
control-ﬂow graph, we synthesize edge predicates that eval-
uate whether crashes and non-crashes differ in execution
ﬂow. Given a control-ﬂow edge from x to y, the predicate
has_edge_to indicates that we observed at least one transi-
tion from x to y. Contrary, always_taken_to expresses that
every outgoing edge from x has been taken to y. Finally, we
evaluate predicates that check if the number of successors is
greater than or equal to n ∈ {0,1,2}.
Register and Memory Predicates. For each instruction,
we generate predicates based on various expressions: the
minimum and the maximum of all values written to a register
or memory, respectively. For each such expression (e. g., r =
max(rax)) we introduce a predicate r  0.5, p
is a good predictor for non-crashing inputs. As our goal is to
predict crashes, we use the negated predicate in these cases.
1013 + 2000
2000+412
2 ·(cid:0) 1013
(cid:1) ≈ 0.9146). The predicate score is
Example 1. Assume that we have 1,013 crashing and 2,412
non-crashing inputs. Furthermore, consider a predicate p1,
with p1 := min(rax)  0.5—we in-
vert the predicate p1. Thus, true and false positives/negatives
are switched, resulting in a large amount of true positives
(Ct = 1013) and true negatives (Nt = 2000) for the inverted
predicate: ¬p1 := min(rax) ≥ 0xff
Testing another predicate p2 for the same instruction with
ˆθ2 = 0.01, we calculate the score s2 = 2· abs(0.01− 0.5) =
0.98. Since s2 > s1, consequently we only store p2 as best
predicate for this instruction.
4.3 Synthesis of Constant Values
When computing our register and memory predicates of type
r < c, we want to derive a constant c that splits the test inputs
into crashing and non-crashing inputs based on all values
observed for r during testing. These predicates can only be
evaluated once a value for c is ﬁxed. Since c can be any 64-bit
value, it is prohibitively expensive to try all possible values.
However, c splits the inputs into exactly two sets: Those where
r is observed to be smaller than c and the rest. The only way
to change the quality of the predicate is to choose a value
of c that ﬂips the prediction of at least one value of r. All
constants c between two different observations of r perform
the exact same split of the test inputs. Consequently, the only
values that change the behavior of the predicate are exactly
the observed values of r. We exploit this fact to ﬁnd the best
value(s) for c using only O(n∗ log(n)) steps where n is the
number of test cases.
To implement this, we proceed as follows: In a preprocess-
ing step, we collect all values for an expression r at the given
instruction and sort them. Then, we test each value observed
for r as a candidate for c. We then want to evaluate our can-
didate for c on all inputs reaching the address. Naively, we
would recompute the score for each value of c; however, this
would yield a quadratic runtime. To increase the performance,
we exploit the fact that we only need Ct , Cf , Nt , Nf to calcu-
late the score. This property of our scoring scheme allows us
to update the score in constant time when checking the next
candidate value of c.
To calculate the score for any candidate value ci, we start at
the smallest candidate c0 and calculate the predicate’s score
by evaluating the predicate on all inputs and counting the
number of correctly predicted outcomes. After calculating the
score of the ith possible candidate ci, we can update the score
for the candidate ci+1 by tracking the number of correctly
predicted crashes and non-crashes. Since using ci+1 instead
of ci only ﬂips a single prediction, we can efﬁciently update
Ct , Cf , Nt , Nf in constant time. When using ci resulted in a
correctly predicted crash for the ith observation, we decrement
Ct. Likewise, if the old prediction was an incorrectly predicted
non-crash, we decrement Nf . The other cases are handled
accordingly. Afterward, we increment the number of observed
outcomes based on the results of the new predicate in the same
fashion. This allows us to track Ct , Cf , Nt , Nf while trying
all values of c to determine the value which maximizes the
score. Finally, we might have dropped some inputs that did
not reach the given instruction; thus, we then perform one
re-evaluation of the score on the whole dataset to determine
the ﬁnal score for this predicate.
Note that the predicate is constructed involving all ad-
dresses reaching that instruction. Consequently, it is perfect
with respect to the whole dataset: all data not yet evaluated
does not reach this address and thus cannot affect the syn-
thesized value. Another consequence of this fact is that our
synthesis works both for ranges and single values.
Example 2. Consider that we want to synthesize a value
c that maximizes the score of the predicate p(r) = r < c.
Assume that we have four inputs reaching the address where
the predicate is evaluated and we observed the following
data:
outcome
values of r
crash
0x08
crash
0x0f
non-crash
0x400254
non-crash
0x400274
In this example, the values are already sorted. Remember that
we are interested in locating the cutoff value, i. e., the value
of c that separates crashing and non-crashing inputs best.
Hence, we proceed to calculate the score for each candidate,
starting with the smallest c = 0x8. Since r < 0x8 is never true
USENIX Association
29th USENIX Security Symposium    241
(cid:0) 2
2+0 + 0
0+2
(cid:1) = 0.5 and, consequently, in a
for our four inputs, they are all predicted to be non-crashing.
Therefore, we obtain Cf = 2, Ct = 0, Nf = 0,Nt = 2. This
results in ˆθ = 1
2
score = 2∗abs(ˆθ−0.5) = 0, indicating that this is not a good
candidate for c. Using the next candidate c = 0x0f, we now
predict that the ﬁrst input is crashing. Since the ﬁrst input
triggered a crash, we update Cf and Ct by incrementing Ct
and decrementing Cf . Consequently, we obtain Cf = 1, Ct = 1,
Nf = 0 and Nt = 2, resulting in ˆθ = 0.75 and a ﬁnal score
of 0.5. Repeating this for the next step, we obtain a perfect
score for the next value 0x400254 as both crashing values are
smaller. This yields the ﬁnal predicate p(r) = x < 0x400254
that will be re-evaluated on the whole dataset.
We observed that if all recorded constants are either valid
stack or heap addresses (i. e., pointers), we receive a high
number of false positives since these addresses are too noisy
for statistical analysis. Accordingly, we do not synthesize
predicates other than is_heap_ptr and is_stack_ptr for
these cases.
4.4 Ranking
Once all steps of our statistical analysis are completed, we
obtain the best predicate for each instruction. A predicate’s
score indicates how well a predicate separates crashing and
non-crashing inputs. Since we synthesize one predicate for
each instruction, we obtain a large number of predicates. Note
that most of them are independent of the bug; thus, we discard
predicates with a score lower than the empirically determined
threshold of 0.9. Consequently, the remaining predicates iden-
tify locations that are related to the bug.
Still, we do not know in which order relevant predicates are
executed; therefore, we cannot distinguish whether a predicate
is related to the root cause or occurs later on the path to the
crash site. As predicates early in the program trace are more
likely to correspond to the root cause, we introduce a new
metric called the execution rank. To calculate the execution
rank, we determine the temporal order in which predicates are
executed. To do so, we add a conditional breakpoint for each
relevant predicate p. This breakpoint triggers if the predicate
evaluates to true. For each crashing input, we can execute
the program, recording the order in which breakpoints are
triggered. If some predicate p is at program position i and we
observed n predicates in total, p’s execution rank is i
n. If some
predicate is not observed for a speciﬁc run, we set its execution
rank to 2 as a penalty. Since a predicate’s execution rank may
differ for each crashing input due to different program paths
taken, we average over all executions.
However, the primary metric is still its prediction score.
Thus, we sort predicates by their prediction score and resolve
ties by sorting according to the execution rank.
Example 3. Consider three predicates p1, p2 and p3 with
their respective scores 1, 0.99 and 0.99. Furthermore, assume
that we have the crashing inputs i1 and i2. Let the observed
predicate order be (p1, p3) for i1 and (p1, p3, p2) for i2. Then,
we obtain the execution ranks:
2 ·(cid:0) 1
2 ·(cid:0)2 + 3
2 ·(cid:0) 2
2 + 1
3
3
2 + 2
3
(cid:1) ≈ 0.41
(cid:1) = 1.5
(cid:1) ≈ 0.83
p1: 1
p2: 1
p3: 1
Since we sort ﬁrst by score and then by execution rank, we
obtain the ﬁnal predicate order (p1, p3, p2).
5
Implementation