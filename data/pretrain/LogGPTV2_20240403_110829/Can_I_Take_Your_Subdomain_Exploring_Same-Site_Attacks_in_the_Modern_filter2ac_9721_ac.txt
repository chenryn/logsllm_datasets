### Vulnerable Scenarios as Described in §3.2.1

#### 1. Expired Domains
The detection of expired domains is performed through the following procedure:
- Given a resolving chain that starts with a CNAME record, our tool checks if it points to an unresolvable resource.
- The eTLD+1 (effective top-level domain plus one) of the canonical name at the end of the chain, referred to as the "apex" for brevity, is extracted.
- If the `whois` command on the apex domain does not return any match, RDScan queries GoDaddy to check if the domain can be purchased.
- If the domain can be purchased, we consider the domain of the resolving chain (i.e., the alias of the first record in the chain) as vulnerable.
- Note that we only tested domains that can be registered without special requirements, excluding domains like `.edu` and other specific eTLDs not offered by the registrar.

#### 2. Discontinued Services
The process of identifying discontinued services is summarized in Algorithm 1. RDScan traverses each resolving chain to determine if it points to one of the supported services. This step is implemented according to the documentation provided by individual services and typically involves checking for:
- An A record resolving to a specific IP address.
- The canonical name of a CNAME record matching a given host.
- The existence of an NS record pointing to the DNS server of a service.

(Sub)domains mapped to services are then checked to verify if the bindings between user accounts and (sub)domains are in place. For most services, a simple HTTP request is sufficient to expose the lack of a correct association. Other services require active probing to determine if a domain can be associated with a fresh test account created using the automated browser testing library Puppeteer with Chromium [1].

RDScan also detects DNS wildcards that might be abused. A DNS wildcard for a domain such as `test.example.com` can be detected by attempting to resolve a CNAME or A DNS record for `nonce.test.example.com`, where `nonce` is a random string unlikely to match an entry in the DNS zone of the target domain.

**Algorithm 1: Detection of Discontinued Services**
```python
Input: Set of DNS resolving chains RC, set of supported services S
Output: Set of vulnerable subdomains Vs

procedure DISCONTINUED_SERVICES(RC, S)
    Vs ← ∅
    for each chain ∈ RC do
        for each service ∈ S do
            if chain points to service then
                d ← target_domain(chain)
                if d is unclaimed at service then
                    Vs ← Vs ∪ {d}
            else if service vulnerable to wildcard issue then
                r ← generate_nonce()
                rd_chains ← compute_resolving_chains(r.d)
                for each rd_chain ∈ rd_chains do
                    if rd_chain points to service then
                        Vs ← Vs ∪ {r.d}
```

#### 3. Deprovisioned Cloud Instances
The detection of potentially deprovisioned cloud instances follows a probabilistic approach similar to [8, 33]. We did not create any virtual machines or register any services at cloud providers. Instead, we collected the IP ranges of six major providers: Amazon AWS, Google Cloud Platform, Microsoft Azure, Hetzner Cloud, Linode, and OVHcloud. Each (sub)domain in our dataset was tested to check if the pointed IP was within any of the cloud IP ranges. If the IP falls within a cloud provider's range, we ensure it does not point to a reserved resource such as a proxy or load balancer. Finally, we perform a liveness probe to determine if the IP is in use. This is done by executing a ping to the IP; if no answer is received, we use a publicly available dataset [43] comprising a scan of the full IPv4 range on 148 ports (128 TCP, 20 UDP). If no open ports are found for the given IP, we deem the resource as potentially deprovisioned.

### 4. Web Analyzer
Our web security analysis aims to quantify the number of domains hosting web applications that can be exploited by taking over the vulnerable domains discovered by RDScan. Specifically, for every apex domain with at least one vulnerable subdomain, we selected the 200 most popular related domains from the CommonCrawl dataset [19] based on the Pagerank score [10]. From the homepage of these domains, we extracted same-origin links that appear in the HTML code. For each related domain, we considered the homepage and up to five of these URLs as targets for our web analysis, accessed using the Chromium browser automated by Puppeteer. In the following sections, we present the data collection process and the security analyses conducted to identify the threats discussed in §3.3. The summary of the results is provided in §5.

#### 4.1 Analysis of Cookies
We used the Puppeteer API to collect cookies set via HTTP headers and JavaScript. Our goal is to identify cookies affected by confidentiality or integrity issues. A cookie is flagged as having confidentiality issues if there exists a vulnerable domain `d` such that:
- `d` is a subdomain of the Domain attribute of the cookie.
- By taking over `d`, the attacker can acquire the capabilities required to leak the cookie.

A cookie is marked as having integrity issues if:
- The name of the cookie does not start with `__Host-`.
- We identified a vulnerable domain that grants the capabilities required to set the cookie.

We also rely on a heuristic proposed by Bugliesi et al. [12] to statically identify potential (pre-)session cookies, i.e., cookies that may be relevant for managing user sessions. The capabilities required to perform these attacks depend on the security flags assigned to the cookie and the usage of cookie prefixes (see §3.3.2).

#### 4.2 Analysis of CSP Policies
For this analysis, we implemented a CSP evaluator according to the draft of the latest CSP version [55], which is currently supported by all major browsers. This is a complex task due to the rich expressiveness of the policy and various aspects introduced for compatibility across different CSP versions. For example, the `unsafe-inline` keyword, which whitelists arbitrary inline contents, is discarded when hashes or nonces are specified.

In our analysis, we focus on the protection offered against click-jacking and the inclusion of active content, including scripts, stylesheets, objects, and frames. For each threat, we first check if the policy is unsafe with respect to any web attacker. If the policy is safe, we classify it as exploitable by a related domain if one of the vulnerable domains detected by RDScan is whitelisted and the attacker acquires the relevant capabilities to perform the attack (see §3.3.3).

#### 4.3 Analysis of CORS
To evaluate the security of the CORS policy implemented by a website, we perform multiple requests with different Origin values and inspect the HTTP headers in the response to understand whether CORS has been enabled by the server. Inspired by the classes of CORS misconfigurations identified in [18], we test three different random origins with the following characteristics:
- The domain is a related domain of the target URL.
- The domain starts with the registrable domain of the target URL.
- The domain ends with the registrable domain of the target URL.

We report a CORS deployment as vulnerable to web attackers if either the second or third test succeeds. A page is exploitable exclusively by a related-domain attacker if only the first test succeeds and one of the vulnerable related domains discovered by RDScan grants the `js` capability to the attacker.

#### 4.4 Analysis of postMessage Handlers
PMForce [51] is an automated in-browser framework for analyzing postMessage event handlers. It combines selective force execution and taint tracking to extract constraints on message contents that lead to execution traces in which the message enters a dangerous sink. We integrated PMForce into our pipeline and modified it to generate multiple exploit messages with the same contents but different origin properties, e.g., a related-domain origin and a randomly-generated cross-site origin. A page is considered vulnerable to any web attacker if any of its handlers is exploitable from a cross-site position. A page is exploitable by a related-domain attacker if its handlers can be exploited only from a related-domain position and one of the vulnerable domains discovered by RDScan grants the `js` capability to the attacker.

#### 4.5 Analysis of Domain Relaxation
The analyzer first detects whether the `document.domain` property is set after the page is loaded. To identify cases where the page sets the property to its original value, we use Puppeteer APIs to inject a frame from a randomly generated subdomain of the page under analysis and intercept outgoing network requests. The relaxation mechanism is exploitable by a related-domain attacker if RDScan discovered a vulnerable subdomain that grants the `js` capability to the attacker. If the webpage is hosted over HTTPS, the `https` capability is also required.

### 5. Heuristics and False Positives
Our methodology minimizes false positives by testing sufficient preconditions for the reported attacks. However, the scanning pipeline uses two heuristics in the RDScan and web analyzer modules to detect potentially deprovisioned cloud instances and label security-sensitive cookies. We also identify a potential TOCTOU (Time of Check to Time of Use) issue between the two modules of the analysis pipeline.

**RDScan:**
- Automated procedures test sufficient preconditions for a takeover. Expired domains are verified by checking if the target domain can be purchased.
- For discontinued services, we created personal testing accounts on each service and used these accounts to probe the mapping between the target subdomain and the service.
- The detection of subdomains pointing to deprovisioned cloud instances relies on a heuristic that might introduce false positives. We excluded the results on deprovisioned cloud instances from the pipeline to avoid false positives in the web analyzer.

**Web Analyzer:**
- The web vulnerabilities are identified via dynamic testing and analysis of the data collected by the crawler. We manually verified samples of each detected vulnerability to ensure correctness and confirmed the absence of false positives.
- The usage of heuristics is limited to labeling cookies likely containing session identifiers, which has been proven reasonably accurate in prior work [12].

**Interplay Between Modules:**
- The modules of the pipeline were executed in sequence at different times. The DNS enumeration phase ended in June 2020, while RDScan ran during the first half of July 2020. The severity of the discovered issues motivated us to immediately report them to the affected parties, leading to a large-scale vulnerability disclosure campaign in the second half of the month.
- The web scanner was executed right after that. Since the DNS data collection ran first, RDScan might have missed new subdomains issued after the completion of the DNS enumeration, leading to a possible underestimation of threats. Subdomain takeover vulnerabilities might have been fixed prior to the web security analysis. A second run of RDScan six months later confirmed that 85% of the subdomains tested were still affected by leftover subdomain takeover vulnerabilities.

### 6. Security Evaluation
We report on the results of our security evaluation on the top 50k domains from the Tranco list. We quantify the vulnerabilities that allow an attacker to be in a related-domain position and provide a characterization of the affected websites. We also delve into the security of 31 service providers, discussing common pitfalls and the capabilities that could be abused by an attacker. Finally, we present the outcome of our web analysis, identifying practical vulnerabilities by intersecting the capabilities on vulnerable domains with the threats found on web applications hosted on their related domains.

**Table 3: Breakdown of Results by Attack Vectors and Web Threats**
- The values reported in the cells represent the number of vulnerable domains/sites compared to those deploying the corresponding web mechanism.

**5.1.1 Characterization of Vulnerable Domains**
- The likelihood of a domain being vulnerable is directly related to the breadth of its attack surface, i.e., the number of subdomains found. Around 15% of the domains with more than 50,000 subdomains are vulnerable.
- Sites in top positions on the Tranco list are more likely to have a vulnerable subdomain than those with a lower rank.
- The analyzed websites are further partitioned into categories, with special care taken for dynamic DNS services. RDScan identified vulnerable subdomains belonging to 8 domains, but 4 were listed in the PSL and excluded from our analysis.
- The second most affected category concerns education websites, with academic institutions generally having a higher number of subdomains and thus a larger attack surface.