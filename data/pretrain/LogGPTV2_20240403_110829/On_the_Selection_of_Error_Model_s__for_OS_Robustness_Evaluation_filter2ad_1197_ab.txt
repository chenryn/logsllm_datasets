### 4.3. Implementation Complexity Criteria
The complexity of implementing the fault injection (FI) campaign is a subjective and qualitative estimation of the effort required to implement the three different error models. A detailed discussion on the implementation complexity is provided in Section 7.

### 4.4. Experiment Execution Time Criteria
Experiment execution time significantly influences the usability of the chosen approach. Therefore, we track the execution time of all experiments. Failures that require manual intervention (Class 3) are assigned a standard timeout of 200 seconds. This timeout is used by the system to detect if no progress is made and a reboot is required. It is set to be sufficiently large to capture any delays incurred by an error, thereby detecting whether the system is hung or just delayed.

### 5. Target Setup
The experiments were conducted using Windows CE .Net 4.2. The hardware consists of a development board with the Intel XScale PXA255 platform, featuring 64 MB RAM and 32 MB ROM (flash). The board is connected via serial and Ethernet connections and also provides a Compact Flash (CF) slot. This setup was chosen because its structure is similar to most other operating systems and hardware, and it is small in size, making it easy to work with and control.

#### 5.1. Targeted Drivers
For comparison, we targeted three different drivers for our experiments. Table 3 summarizes the number of services targeted and the total number of injection cases for the three error models. The drivers were selected to represent three common, yet distinct, functional classes:

- **Serial Driver (cerfio_serial):** Implements the common RS232 serial interface.
- **Ethernet Driver (91C111):** Represents network interface drivers.
- **CF Driver (atadisk):** Represents filesystem drivers.

| Driver        | #Services | FZ Injection Cases | BF Injection Cases | DT Injection Cases |
|---------------|-----------|--------------------|--------------------|--------------------|
| cerfio_serial | 60        | 1410               | 2362               | 397                |
| 91C111        | 54        | 1050               | 1035               | 255                |
| atadisk       | 47        | 1658               | 1658               | 294                |

### 5.2. Benchmark Applications
The benchmark applications consist of five different processes. One application uses the driver currently targeted, thus there are test applications for serial and Ethernet communication (with the host computer) as well as testing multiple reads and writes to the CF card. The general benchmark applications target a variety of general OS services, such as process creation and synchronization, file system operations, and memory allocation/manipulation.

These applications are chosen to activate the system in a varied manner and to drive the experiments, i.e., function as a workload for the targeted driver. For a system designer, if the set of applications to be used in the target product is known, they should be used to drive the experiments. Otherwise, benchmark applications are the best choice as they usually target many common features.

For each injection, all applications are used, and their results are tracked for deviations using assertions. Each application is written specifically for testing purposes, making it possible to manually track the used services and add assertions.

### 5.3. System Pre-Profilng
To expedite the injection process, the system is first profiled to remove injections that will not lead to an error being injected. This is achieved by generating all injections for a driver and then running the benchmark applications while keeping track of which services are being used. After successful execution of the benchmark applications, the list of injections is reduced to include only services actually called during the profiling run. This typically reduces the number of test cases by half or more. The number of injections greatly influences the time required to execute the experiments. The more unnecessary cases identified, the more time is saved. Thus, the most time (in absolute numbers) is saved for the BF error model, as it requires the most injection cases in this study.

### 5.4. Experiment Setup
Information on the selected experiments to perform is stored in a file in persistent storage (flash memory) on the target computer. The file is created the first time the system boots up. The injection is configured using the registry, and the Interceptor automatically generates all test cases for the selected set of targeted services and the chosen error model.

Each experiment run (combination of error model and driver) uses a newly built OS image. Each experiment starts with a cold reboot where the OS image is read from ROM into RAM, ensuring that each injection is performed using a fresh, uncorrupted OS image. Persistence between injections is limited to the error configuration file, and for FZ errors, to the seed to the random number generator. Logs are stored on the host computer.

### 6. Experimental Results
A range of experiments were conducted for the three drivers. The following sections present the comparative results for the selected criteria. Due to the nature of the error models studied, BF uses a significantly larger set of injection cases, resulting in longer experiment times. The discussions focus on Class 3 failures, as these are relevant for robustness evaluation. Appropriate references to the other classes are clearly indicated. For FZ, we report values for fifteen injections per parameter. Section 6.4 details a discussion on the number of injections needed.

#### 6.1. Comparing Drivers
Driver Diffusion (as defined in Section 4.1) is used to compare the drivers. The probability \( P_{DS_i} \) is approximated as the ratio of failures to the number of injections. Table 4 summarizes the results, showing that DT and FZ identify the serial driver as the most vulnerable (higher Diffusion value), whereas BF pinpoints atadisk as the most vulnerable.

| Driver        | BF      | DT      | FZ      |
|---------------|---------|---------|---------|
| cerfio_serial | 1.05    | 1.50    | 1.56    |
| 91C111        | 0.98    | 0.73    | 0.69    |
| atadisk       | 1.86    | 0.63    | 0.29    |

Table 6 details the results for each driver and error type. Overall, the Class 3 ratio is below 5%, indicating that the OS is indeed able to handle most introduced perturbations. Furthermore, the error model does not significantly impact the ratios for the 91C111 and cerfio_serial drivers. For Class 3 failures, the percentage of injections varies between 3.22% and 3.97% for the serial driver and 2.35% and 4.24% for the 91C111 driver. For atadisk, the differences are larger but still within 1.26% and 3.98%, with BF identifying it as more vulnerable. The results show slight differences between the drivers and between the error models.

While Diffusion values in Table 4 for BF indicate atadisk to have the highest diffusion, the experimental results from Table 6 show that 91C111 has a higher ratio of Class 3 failures. This is due to Diffusion being a "sum of probabilities." Diffusion shows that atadisk has more services with higher propagation probability than 91C111.

For Class 2 failures, there are some distinct differences between the drivers. The 91C111 and atadisk drivers have considerably fewer Class 2 failures. This is due to differences in how the drivers function, i.e., blocking vs. non-blocking. Failed blocking services are more likely to cause hangs of the system, i.e., Class 2 failures. This suggests that there is, as expected, a difference between the tested drivers, which is exactly what the Diffusion metric captures. For Class 1 failures, we notice the same difference with the serial driver having fewer cases due to its blocking nature.

Overall, many injections, for all drivers and all error models, end up in the NF category, i.e., no observable deviation from the expected behavior could be seen. This is in line with several previous studies, e.g., [2], [9], and [12]. It is important to note that all cases reporting the errors were in fact activated, since the pre-profiling eliminated the not used services a priori. Outcomes in the NF category are either masked by the system, for instance by not being used or overwritten; or handled by built-in error detection/correction mechanisms checking incoming parameter values for correctness. Another explanation could be that the fault is dormant in the system and has not yet propagated to the OS-Application interface.

#### 6.2. Execution Time
Table 5 details the execution time for each experiment run. The BF model, with the most injections, has the longest execution time. However, the execution time also depends on the outcome of the experiments (Class 2 and 3 take longer as they typically require timeouts to be triggered) and the nature of the test applications. There are also slight variations in the boot-up time of the target system. The serial driver and the atadisk driver both take longer when failing, which also influences the execution time.

| Driver        | Error Model | Execution Time (hours:minutes) |
|---------------|-------------|--------------------------------|
| cerfio_serial | BF          | 38:5                           |
|               | DT          | 17:1                           |
|               | FZ          | 20:2                           |
| 91C111        | BF          | 14:15                          |
|               | DT          | 44:20                          |
|               | FZ          | 56:48                          |
| atadisk       | BF          | 20:7                           |
|               | DT          | 51:55                          |
|               | FZ          | 55:56                          |

#### 6.3. Comparing Error Models
Table 7 depicts services incurring Class 3 failures, showing the number of failures for each service/error model. BF clearly outperforms the other error models in terms of identifying critical failures.

#### 6.4. The Number of Injections for Fuzzing
A crucial question regarding the FZ model is how many injection cases are needed. Figure 3 shows how Diffusion changes with increasing number of injections. The X-axis shows the number of injections, and the Y-axis shows the diffusion values using x injections. Diffusion stabilizes after roughly ten injections. We have injected fifteen cases for all three drivers, and all of these are included in Tables 3-7.