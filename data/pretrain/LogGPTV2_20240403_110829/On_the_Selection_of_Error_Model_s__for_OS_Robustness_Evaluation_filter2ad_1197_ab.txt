The failure modes give rise to a partitioning of the ex-
periment outcomes. Similar to for instance [16], when an
experiment could be placed in multiple classes, e.g., when
it ﬁrst gives an application error code (class 1) and then the
system crashes (class 3) the more severe class is assigned.
4.3. Implementation Complexity Criteria
The complexity of implementing the FI campaign is a
subjective and qualitative estimation of the effort needed to
implement the three different error models. A discussion on
the implementation complexity appears in Section 7.
4.4. Experiment Execution Time Criteria
Experiment execution time signiﬁcantly inﬂuences the
usability of the chosen approach. We therefore track the ex-
ecution time of all experiments. Failures requiring manual
intervention (Class 3) are assigned 200 seconds. This is the
standard timeout used by the system to detect if no progress
is made and a reboot is required. It is set to be sufﬁciently
large to capture any delays incurred by an error, i.e., to de-
tect that the system is hung and is not just delayed.
5. Target Setup
The conducted experiments use Windows CE .Net 4.2.
The hardware is a development board, using the Intel XS-
cale PXA255 platform, with 64 MB RAM and 32 MB ROM
(ﬂash). The board is connected using serial and Ethernet
connections. The board also provides a Compact Flash (CF)
slot. We have used this setup as its structure is very simi-
lar to most other OSs and hardware. It is also small in size
making it easy to work with and control.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:38 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007From a SW perspective, the system comprises two main
components, namely the Interceptor and the Experiment
Manager (Figure 2). The Interceptor intercepts all calls
to or from a speciﬁc driver, and can then inject errors on
request. It interacts with the Experiment Manager, receiv-
ing commands and sending the results back in form of log
messages. The Experiment Manager is responsible for set-
ting up the needed infrastructure, sending injection com-
mands to the Interceptor, transmitting log messages to the
host computer and for monitoring the outcome of the exper-
iments. The Experiment Manager starts the test applications
and monitors their behavior, receives reports of triggered as-
sertions, and passes them on as log messages. It is also re-
sponsible for restarting the machine after each experiment.
(cerfio_serial) implements the common RS232 serial
interface, a well established and commonly used interface.
The Ethernet driver (91C111) represents network interface
drivers. The CF driver (atadisk) represents a different
class of interfaces altogether, namely ﬁlesystem drivers.
Driver
#Services
cerﬁo serial
91C111
atadisk
60
54
47
# Injection cases
FZ
BF
1410
2362
1722
1050
1035
1658
DT
397
255
294
Table 3. Overview of the target drivers.
5.2. Benchmark Applications
The benchmark applications consist of ﬁve different pro-
cesses. One application uses the driver that is currently tar-
geted, thus there are test applications testing serial and Eth-
ernet communication (with the host computer) as well as
testing multiple reads and writes to the CF card. The gen-
eral benchmark applications target a variety of general OS
services, such as process creation and synchronization, ﬁle
system operations and memory allocation/manipulation.
The applications are chosen to activate the system in a
varied manner and to drive the experiments, i.e., function
as workload for the targeted driver. For a system designer,
the set of applications to be used in the target product may
be known, and if so they should be used to drive the exper-
iments. If not, then benchmark applications form the best
choice, as they usually target many common features.
For each injection, all applications are used and their re-
sults tracked for deviations using assertions. Each applica-
tion is written speciﬁcally for testing purposes, therefore its
expected behavior is known a priori. This makes it possible
to manually track the used services and add assertions.
5.3. System Pre-Proﬁling
To expedite the injection process, the system is ﬁrst pro-
ﬁled to remove injections that will not lead to an error being
injected. This is achieved by ﬁrst generating all injections
for a driver and then running the benchmark applications
while keeping track of which services are being used. Af-
ter successful execution of the benchmark applications, the
list of injections is reduced to include only services actually
called during proﬁling run. This typically reduces the num-
ber of test cases by half or more. The number of injections
greatly inﬂuences the time required to execute the exper-
iments. The more unnecessary cases identiﬁed, the more
time is saved. Thus, the most time (in absolute numbers)
is saved for the BF error model, since it requires the most
injection cases in this study.
Figure 2. Experiment setup
Information on the selected experiments to perform is
stored in a ﬁle in persistent storage (ﬂash memory) on the
target computer. The ﬁle is created the ﬁrst time the system
boots up. The injection is conﬁgured using the registry and
the Interceptor automatically generates all test cases for the
selected set of targeted services and the chosen error model.
Each experiment run (combination of error model and
driver) uses a newly built OS image. Each experiment starts
with a cold reboot where the OS image is read from ROM
into RAM, ensuring that each injection is performed using
a fresh, uncorrupted, OS image. Persistence between injec-
tions is limited to the error conﬁguration ﬁle, and for FZ
errors to the seed to the random number generator. Logs are
stored on the host computer.
5.1. Targeted Drivers
For comparison, we target three different drivers for our
experiments. Table 3 shows the number of services targeted
and the total number of injection cases for the three targeted
error models. The number of services reported includes
both exported services, used by the OS, and imported OS
services that the driver uses.
The drivers were chosen to represent three common, yet
different, functional classes of drivers. The serial driver
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:38 UTC from IEEE Xplore.  Restrictions apply. 
Operating SystemDriver xDriver xTargetdriverInterceptorTestApplicationsHostComputerExperimentManager- Exp. Setup- Exp Synch.- Logging- Restarting37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 20076. Experimental Results
A range of experiments were conducted for the three
drivers. The next sections present the comparative results
for the selected criteria. Due to the nature of the error mod-
els studied, BF use a signiﬁcantly larger set of injection
cases. Consequently, the time taken to perform the exper-
iments is also signiﬁcantly longer. The discussions in the
following sections focus on class 3 failures, as these are rel-
evant for robustness evaluation. Appropriate references to
the other classes are clearly indicated. For FZ we report val-
ues for ﬁfteen injections per parameter. Section 6.4 details
a discussion on the number of injections needed.
Driver
cerﬁo serial
91C111
atadisk
BF
1.05
0.98
1.86
DT
1.50
0.73
0.63
FZ
1.56
0.69
0.29
Table 4. Driver Diffusion for class 3 failures.
6.1. Comparing Drivers
Driver Diffusion (as deﬁned in Section 4.1) is used to
compare the drivers. The probability P DSi
x.j is approxi-
mated as the ratio of failures to the number of injections.
Table 4 summarizes the results showing that DT and FZ
identify the serial driver to be the most vulnerable driver
(higher Diffusion value), whereas BF pin-points atadisk
to be the most vulnerable.
Table 6 details the results for each driver and error
type. Overall the class 3 ratio is below 5%, indicating
that the OS is indeed able to handle most introduced per-
turbations. Furthermore, we conclude that the error model
does not signiﬁcantly impact the ratios for the 91C111 and
cerfio_serial drivers. For class 3 failures the per-
centage of injections (last column) varies between 3.22%
and 3.97% for the serial driver and 2.35% and 4.24% for
91C111 driver. For atadisk the differences are larger,
but still within 1.26% and 3.98% with BF identifying it as
more vulnerable. The results show slight differences be-
tween the drivers as well as between the error models.
While Diffusion values in Table 4 for BF indicate
atadisk to have highest diffusion, the experimental re-
sults from Table 6 show that 91C111 has a higher ratio of
class 3 failures. This is due to Diffusion being a “sum of
probabilities”. Diffusion shows that atadisk has more
services with higher propagation probability than 91C111.
For class 2 failures there are some distinct differences
between the drivers. 91C111 and atadisk drivers have
considerably fewer class 2 failures. This is due to differ-
ences in how the drivers function, i.e., blocking vs. non-
blocking. Failed blocking services are more likely to cause
hangs of the system, i.e., class 2 failures. This suggests that
there is, as expected, a difference between the tested drivers,
which is exactly what the Diffusion metric captures. For
class 1 failures, we notice the same difference with the se-
rial driver having fewer cases due to its blocking nature.
Overall, many injections, for all drivers and all error
models, end up in the NF category, i.e., no observable devi-
ation from the expected behavior could be seen. This is in
line with several previous studies, e.g., [2], [9] and [12].
It is important to note that all cases reporting the errors
were in fact activated, since the pre-proﬁling eliminated the
not used services a priori. Outcomes in the NF category
are either masked by the system, for instance by not be-
ing used or overwritten; or handled by built-in error detec-
tion/correction mechanisms checking incoming parameter
values for correctness. Another explanation could be that
the fault is dormant in the system and has not yet propa-
gated to the OS-Application interface.
Driver
Error Model
Execution Time
hours minutes
cerio serial
91C111
atadisk
BF
DT
FZ
BF
DT
FZ
BF
DT
FZ
38
5
20
17
1
7
20
2
11
14
15
44
20
56
48
51
56
55
Table 5. Experiment execution times.
6.2. Execution Time
Table 5 details the execution time for each experiment
run. The BF model with the most injections, has the longest
execution time. However, the execution time also depends
on the outcome of the experiments (class 2 and 3 take longer
time as they typically require timeouts to be triggered) and
the nature of the test applications. There are also slight vari-
ations in the boot-up time of the target system. The serial
driver and the atadisk driver both take longer time when
failing, which also inﬂuences the execution time.
6.3. Comparing Error Models
Table 7 depicts services incurring class 3 failures.
It
shows the number of failures for each service/error model.
BF clearly outperforms the other error models in terms of
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:49:38 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Driver
Error Model No Failure
%
Class 1
%
Class 2
%
Class 3
%
cerﬁo serial
91111C
atadisk
BF
DT
FZ
BF
DT
FZ
BF
DT
FZ
1771
264
931
1166
181
670
1246
191
531
74.98%
66.50%
66.03%
67.71%
70.98%
63.81%
75.15%
64.97%
51.30 %
209
65
218
482
67
350
343
98
483
8.85%
16.37%
15.46%
27.99%
26.27%
33.33%
20.69%
33.33%
46.67%
306
53
205
1
1
1
3
1
7
12.96%
13.35%
14.54%
0.06%
0.39%
0.10%
0.18%
0.34%
0.67%
76
15
56
73
6
29
66
4
13
3.22%
3.78%
3.97%
4.24%
2.35%
2.76%
3.98%
1.36%
1.26%
Table 6. The number of experiments is shown for each driver, error model and failure class.
6.4. The Number of Injections for Fuzzing
A crucial question regarding the FZ model is how many
injection cases are needed. Figure 3 shows how Diffusion
changes with increasing number of injections. The X-axis
shows the number of injection and the Y-axis shows the dif-
fusion values using x injections. Diffusion stabilizes after
roughly ten injections. We have injected ﬁfteen cases for all
three drivers and all of these are included in Tables 3-7.