it can be seen as a two party protocol between the “sender”
and the server, followed by a two-party protocol between
the “receiver” and the server.
In this setting, the server needs to be involved in the com-
putation rather than being simply used for message passing.
The reason is that if the server is only used for message
passing, then it is equivalent to a two-party non-interactive
protocol. This makes the message essentially a hash of the
location, which allows a dictionary attack on the location.
The asynchronous setting allows a privacy-efﬁciency
tradeoff due to the fact that the sender and receiver can each
execute their half of the protocol with the server at arbitrary
times. Speciﬁcally, a user might conﬁgure her device to par-
ticipate in the protocol in the role of sender only when her
location changes. Similarly, she might conﬁgure her device
to participate in the role of receiver only when she explicitly
checks the proximity testing application.
The detriment to privacy comes from the fact that the
server learns when the user is moving. This is of course a
much less severe leak than leaking the location. Neverthe-
less, the server might be able to tell, for example, when
a user went home for the night.
It is important to note
that each user can control their participation schedule and
change it at any time.
2.5 Reducing proximity testing to equality testing.
Let G be a grid or a tessellation of the plane,3 and let Lu
be the location of user u expressed as the center of the grid
cell that the user is located in. For any two users u and v, the
equality testing protocol Πu,v must satisfy the following:
• if Lu = Lv then u learns Lv
3more accurately, the surface of the Earth. In Section 5 we describe
how we apply a grid to a curved surface.
Figure 1. Overlapping grid system. The squares represent
minimally separated users who are not part of the same cell
in any grid. The round dots represent maximally separated
users are in the same cell in one of the grids (the bold one).
• if Lu (cid:54)= Lv then u learns nothing about Lv except that
Lu (cid:54)= Lv
By running any such protocol Π on three hexagonal grids
G1, G2, G3 which are mutually offset in the manner shown
in Figure 1, we obtain a proximity testing protocol Π(cid:48) such
that
• if ||Xu − Xv|| ≤ δ then u learns at least one of
Lv,1, Lv,2 and Lv,3.
• if ||Xu − Xv|| ≥ γδ then u learns nothing about Xv
except that ||Xu − Xv|| > δ
where Lu,i is the quantized location of user u in grid i, δ is
half the height of each hexagonal cell, γδ is the diagonal of
the hexagons and Xu is the exact location of a user u. Π(cid:48) is
the ideal functionality for proximity testing.
Intuitively, what this means is that (i) proximity testing
only reveals quantized locations, (ii) it is guaranteed to do
so when the parties are sufﬁciently close, and (iii) guaran-
teed not to do so when they are sufﬁciently far apart.
The values δ and γδ are respectively the closest two users
can be and not be detected as nearby, and the farthest they
can be and still be detected as nearby. Note that δ is
3/2
times the side of the hexagons and γ is 4/
3 (dimension-
less).
√
√
The value of γδ is visually clear from Figure 1. To derive
the value of δ, we argue as follows (Figure 2): consider two
users not detected as nearby. If one of them (Alice) lies in
the triangle marked by the dot, the other (Bob) cannot lie
in the region marked X, and therefore the two locations are
separated by at least one of six pairs of parallel lines (one
such pair is shown in the diagram), which are a distance δ
apart.
In practice Alice will detect Bob as nearby when he is in
one of the triangles marked X, and will learn nothing about
Bob’s location when he is not in this region. There is no re-
gion of unpredictable behavior, and there is no compromise
of security.
The reason there is a gap between δ and γδ is because the
X region is not circular and not necessarily centered around
Alice’s location. This is clear when we look at Figure 3: for
a user located as at the center — considering that she can be
in any one of the six triangles incident at that point by mov-
ing an inﬁnitesimal distance — the region that is guaranteed
to be in her neighborhood is a hexagon, and the largest cir-
cle that can be inscribed in this hexagon has radius δ. Simi-
larly, the region guaranteed not to be in her neighborhood is
the complement of a bigger hexagon, and the smallest circle
that can be exscribed in this hexagon has radius γδ.
Our choice of grid is the simplest one that works, be-
cause at least three overlapping grids are required (with only
two grids, consider any point at which they intersect, then
two people arbitrarily near this point but on opposite sides
will not be detected as nearby).
The ideal functionality generally behaves as expected
when invoked repeatedly over time, i.e., no security is lost
is lost by running multiple instances. The one exception
is when a user is moving and crosses a grid boundary: a
friend who is nearby will be able to observe this, and under
assumptions about speed of movement, etc., may be able
to infer the user’s proximity to an edge, or more rarely, a
vertex. It does not appear possible to eliminate this vulner-
ability.
3 Private Equality Testing
Figure 2. Neighborhood of a point
The private equality testing problem was studied in a
number of papers [12, 32, 6, 26]. Here we describe two
concrete protocols that are especially well suited for our
purposes. They solve the following problem:
Input: Alice has value a representing her location. Bob
has value b representing his location.
Output: Alice learns if a = b and nothing else. Bob learns
nothing.
Figure 3. Circles with radii δ and γδ
We call this problem asymmetric equality testing because
Alice learns the answer but Bob does not. This sort of asym-
metry is often needed in social networks. Our ﬁrst protocol
is computationally more expensive than the second, but pro-
vides stronger security guarantees.
3.1 Protocol 1: Synchronous private equality test-
ing
In this protocol the server is used only to forward mes-
sages between the two parties, and does not perform any
computation. It is based on a mechanism of Lipmaa [26];
our contribution is a adaption for the asymmetric setting
with an efﬁciency improvement.
The protocol has the following characteristics: (1) it is
synchronous, i.e., both parties need to be online (2) each
party performs either 2 or 3 exponentiations, (3) there are
two rounds, namely Alice sends a message to Bob (through
the server) and Bob responds to Alice, (4) communication
is about 40 bytes per edge per time interval using elliptic
curves of size 160 bits (additional end-to-end encryption
introduces a negligible overhead). It is secure against ar-
bitrary collusion assuming the hardness of the standard De-
cision Difﬁe-Hellman problem. The protocol proceeds as
follows.
Global setup: Let G be a cyclic group of prime order p and
g a generator of G. We will assume that the Decision Difﬁe-
Hellman problem is hard in G. All clients in the system are
pre-conﬁgured with the same G and g. In what follows we
will use Zp to denote the set {0, . . . , p − 1}.
Client setup: When the system is ﬁrst installed on the client
it chooses a random x in Zp and computes h ← gx. Thus,
Alice has x and h; h will be used as her ElGamal pubic key.
We assume Bob already has Alice’s public key h (more on
this in Section 5.1).
Round 1: Alice computes an ElGamal encryption of her
location a encoded as ha and sends the resulting ciphertext
to Bob (through the server). More precisely, Alice chooses
a random r in Zp, computes
Ca ← (gr, ha+r)
and sends Ca to Bob.
Round 2: Bob chooses a random non-zero s in Zp and uses
his own location b and the ciphertext Ca = (g1, g2) from
Alice to construct a fresh ElGamal encryption of the mes-
sage s · (a − b). More precisely, Bob chooses a random t in
Zp and computes
Cb ←(cid:16)
gsr+t, hs(a−b)+sr+t(cid:17)
gs
1 gt, gs
(cid:16)
2 h(t−sb)(cid:17)
(cid:16)
=
gw, hs(a−b)+w(cid:17)
Observe that setting w := sr + t we have
Cb =
so that Cb is a fresh encryption of s(a − b) under the public
key h. Bob sends Cb to Alice through the server.
Obtain answer: Alice now has
Cb = (u1, u2) =(cid:0) gw, hs(a−b)+w(cid:1)
and her secret key x. She decrypts Cb, namely computes
m ← u2/ux
1 = hs(a−b). If m = 1 she concludes that a = b
and if not she concludes that a (cid:54)= b.
Security. The protocol above is an optimization of the
generic mechanism of Lipmaa who provides a proof of se-
curity [26, Theorem 4]. We brieﬂy sketch the argument:
Alice’s privacy is assured under the DDH assumption since
the only thing she sends to Bob is an ElGamal encryption of
her location. Bob’s privacy is assured unconditionally since
all Alice learns is s(a − b) which is either 0 if a = b or
random non-zero in Zp if a (cid:54)= b. When a (cid:54)= b this reveals
no other information about b.
With this protocol, it is possible for a malicious Bob
to convince Alice that he is nearby even without knowing
her location: he can simply choose a random s and send
(gs, hs). While this is not a privacy violation (Bob cannot
learn Alice’s location or vice-versa), it is still important to
keep in mind.
Performance. Since computing a product of exponents
such as gs
1gt is not much more expensive than computing
a single exponent (see [30, p. 619]) we count these as a
single exponentiation. Overall, Alice performs three expo-
nentiations and Bob does two. Two of Alice’s exponenti-
ations use a ﬁxed base which can be sped up considerably
using pre-computations. The total trafﬁc amounts to two
ElGamal ciphertexts which is about 320 bytes using 160-bit
elliptic curves.
3.2 Protocol 2: Fast asynchronous private equal-
ity test with an oblivious server
Our second private equality test, shown in Figure 4, is
novel and requires far less communication and computation,
but is only secure assuming the server does not collude with
either party. The server learns nothing at the end of the pro-
tocol. The reason for the performance improvements is that
this protocol uses three parties (Alice, Bob, and server) and
is therefore able to rely on information theoretic methods
such as secret sharing.
We describe the protocol as it would be used in our sys-
tem, namely at time t Alice is in location at and Bob is in
location bt. At certain times t Alice wants to test if at = bt,
but should learn nothing else about bt. The server and Bob
should learn nothing.
Global setup: Let p be a prime so that all possible locations
are in the range [1, p]. If location data is 32 bits then one
can set p := 232 + 15. All clients in the system are pre-
conﬁgured with the same p. As before we let Zp denote the
set {0, . . . , p − 1}.
Client setup: When Alice and Bob declare themselves as
friends they setup a shared secret key which we denote as
kab. We explain key setup in more detail in Section 5.1.
Both clients also maintain a counter ctr which is initially
set to 0 (there is a separate counter for each pair of clients).
When Alice and Bob sign up for the service we assume that
Alice
input: at
k1, k2
m + k2
?= 0
(cid:0)ctr, ma ← at + k1
(cid:1)
−−−−−−−−−−−−−−−−−−−−−−−−−−−→
←−−−−−−−−−−−−−−−−−−−−−−−−−−− r
m ← r ma − mb
Server
(cid:0)ctr, mb ← r(bt + k1) + k2
Bob
input: bt
←−−−−−−−−−−−−−−−−−−−−−−−−−−− r, k1, k2
(cid:1)
Figure 4. Asynchronous equality test with an oblivious server
they generate a secret key with the server denoted ka and kb
respectively.
The keys kab, ka, kb will be used as keys to a Pseudo
Random Function (PRF) denoted by F (k, x), where k is
the PRF key and x is the point at which the function is
evaluated.
(Our implementation uses AES as the PRF.)
All communication between Alice and the server and Bob
and the server is encrypted with an authenticated encryption
scheme.
Step 1 (Bob’s message): Bob increments ctr by one and
computes
(k1, k2) ← F (kab, ctr)
and r ← F (kb, ctr) .
Bob parses the result so that k1, k2 are elements in Zp and
r is an element in Zp \ {0} (i.e. r (cid:54)= 0). Bob computes
mb ← r(bt + k1) + k2 and sends mb and ctr to the server.
Step 2 (Alice queries server): This step consists of two
rounds: ﬁrst Alice queries the server to obtain the latest
value of ctr from Bob. If the value received is not fresh,
i.e., Alice used it before, she aborts.
Alice then computes (k1, k2) ← F (kab, ctr). Alice
parses the result so that k1, k2 are elements in Zp and sends
ma ← at + k1 and ctr to the server.
Step 3 (Server responds to Alice): The server ﬁnds a mes-
sage from Bob that has the same counter value ctr as the
It computes r ← F (kb, ctr) and
message from Alice.
parses the result as an element in Zp \{0}. It sends to Alice
the message
m ← r ma − mb
= r(at + k1) − r(bt + k1) − k2 = r(at − bt) − k2
Alice computes m + k2 = r(at − bt). If the result is 0 then
she knows at = bt and otherwise not.
Security. We show that the protocol is secure (i.e. no party
learns more than it should) as long as no two parties col-
lude. First, since F is a secure Pseudo Random Function,
the outputs k1, k2, and r at every iteration are indistinguish-
able from truly random and independent values in Zp with
r (cid:54)= 0.
Now, observe that Bob learns nothing from the protocol
since he receives no messages. The server sees ma and mb
and both are independent of the users’ inputs at and bt. To
see why, recall that ma is blinded by k1 and mb is blinded
by k2. Since k1 and k2 are independent random values in
Zp so are ma and mb. Therefore, the server’s view in this
protocol can be easily simulated by two random elements in
Zp.
Finally, Alice learns m = r(at − bt) − k2 for some at
of Alice’s choice. Consider the case at (cid:54)= bt. Since r is
uniform in Zp \ {0} and unknown to Alice this m is uni-
formly distributed in Zp \ {k2} in Alice’s view. Therefore,
when at (cid:54)= bt, Alice’s view of the server’s response can be
simulated by one random element in Zp \ {k2}.
Note that if Alice colludes with the server they easily
learn Bob’s location. Similarly, if Bob colludes with the
server they easily learn Alice’s location.
However, unlike in Protocol 1, Bob cannot trick Alice
into thinking he is nearby without correctly guessing her lo-