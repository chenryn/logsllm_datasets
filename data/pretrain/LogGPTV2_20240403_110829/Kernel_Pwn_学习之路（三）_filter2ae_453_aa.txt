# Kernel Pwn 学习之路（三）
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
## 0x01 前言
由于关于Kernel安全的文章实在过于繁杂，本文有部分内容大篇幅或全文引用了参考文献，若出现此情况的，将在相关内容的开头予以说明，部分引用参考文献的将在文件结尾的参考链接中注明。
Kernel的相关知识以及一些实例在Kernel中的利用已经在Kernel Pwn
学习之路(一)(二)给予了说明，本文主要介绍了Kernel中`slub`分配器的相关知识。
【传送门】：[Kernel Pwn 学习之路(一)](https://www.anquanke.com/post/id/201043)
【传送门】：[Kernel Pwn 学习之路(二)](https://www.anquanke.com/post/id/201454)
⚠️：本文中的所有源码分析以`Linux Kernel 4.15.15`为例。
## 0x02 buddy system (伙伴系统)
Linux内核内存管理的一项重要工作就是如何在频繁申请释放内存的情况下，避免碎片的产生。Linux采用伙伴系统解决外部碎片的问题，采用slab解决内部碎片的问题，在这里我们先讨论外部碎片问题。避免外部碎片的方法有两种：一种是之前介绍过的利用非连续内存的分配；另外一种则是用一种有效的方法来监视内存，保证在内核只要申请一小块内存的情况下，不会从大块的连续空闲内存中截取一段过来，从而保证了大块内存的连续性和完整性。显然，前者不能成为解决问题的普遍方法，一来用来映射非连续内存线性地址空间有限，二来每次映射都要改写内核的页表，进而就要刷新TLB，这使得分配的速度大打折扣，这对于要频繁申请内存的内核显然是无法忍受的。因此Linux采用后者来解决外部碎片的问题，也就是著名的伙伴系统。
伙伴系统的宗旨就是用最小的内存块来满足内核的对于内存的请求。在最初，只有一个块，也就是整个内存，假如为1M大小，而允许的最小块为64K，那么当我们申请一块200K大小的内存时，就要先将1M的块分裂成两等分，各为512K，这两分之间的关系就称为伙伴，然后再将第一个512K的内存块分裂成两等分，各位256K，将第一个256K的内存块分配给内存，这样就是一个分配的过程。
## 0x02 Kernel slub 分配器
`Linux`的物理内存管理采用了以页为单位的`buddy
system`(伙伴系统)，但是很多情况下，内核仅仅需要一个较小的对象空间，而且这些小块的空间对于不同对象又是变化的、不可预测的，所以需要一种类似用户空间堆内存的管理机制(`malloc/free`)。然而内核对对象的管理又有一定的特殊性，有些对象的访问非常频繁，需要采用缓冲机制；对象的组织需要考虑硬件`cache`的影响；需要考虑多处理器以及`NUMA`架构的影响。90年代初期，在`Solaris
2.4`操作系统中，采用了一种称为`slab`（原意是大块的混凝土）的缓冲区分配和管理方法，在相当程度上满足了内核的特殊需求。
多年以来，`SLAB`成为`linux
kernel`对象缓冲区管理的主流算法，甚至长时间没有人愿意去修改，因为它实在是非常复杂，而且在大多数情况下，它的工作完成的相当不错。
但是，随着大规模多处理器系统和 `NUMA`系统的广泛应用，`SLAB`分配器逐渐暴露出自身的严重不足：
  1. 缓存队列管理复杂；
  2. 管理数据存储开销大；
  3. 对NUMA支持复杂；
  4. 调试调优困难；
  5. 摒弃了效果不太明显的slab着色机制；
针对这些`SLAB`不足，内核开发人员`Christoph
Lameter`在`Linux`内核`2.6.22`版本中引入一种新的解决方案：`SLUB`分配器。`SLUB`分配器特点是简化设计理念，同时保留`SLAB`分配器的基本思想：每个缓冲区由多个小的`slab`组成，每个
`slab`包含固定数目的对象。`SLUB`分配器简化`kmem_cache`，`slab`等相关的管理数据结构，摒弃了`SLAB`分配器中众多的队列概念，并针对多处理器、`NUMA`系统进行优化，从而提高了性能和可扩展性并降低了内存的浪费。为了保证内核其它模块能够无缝迁移到`SLUB`分配器，`SLUB`还保留了原有`SLAB`分配器所有的接口`API`函数。
## 0x02 Kernel slub 内存管理数据结构
首先给出一张经典的结构图
可以看到，slub分配器首先会管理若干个`kmem_cache`，这些`kmem_cache`将构成一个大的 **双向循环列表**
，这个列表的头为`slab_caches`，其中`kmalloc_caches`管理着若干定长的`kmem_cache`，分别是`kmalloc-8`到`kmalloc-0x2004`，以步长为8递增。(此处事实上非常类似于`GLibc`内存管理中`Fastbin`的管理方式)
每一个固定程度的`kmem_cache`都有以下数据结构：(`/source/include/linux/slub_def.h#L82`)
    /*
     * Slab cache management.
     */
    struct kmem_cache {
        struct kmem_cache_cpu __percpu *cpu_slab;
        /* Used for retriving partial slabs etc */
        slab_flags_t flags;
        unsigned long min_partial;
        int size;        /* The size of an object including meta data */
        int object_size;    /* The size of an object without meta data */
        int offset;        /* Free pointer offset. */
    #ifdef CONFIG_SLUB_CPU_PARTIAL
        int cpu_partial;    /* Number of per cpu partial objects to keep around */
    #endif
        struct kmem_cache_order_objects oo;
        /* Allocation and freeing of slabs */
        struct kmem_cache_order_objects max;
        struct kmem_cache_order_objects min;
        gfp_t allocflags;    /* gfp flags to use on each alloc */
        int refcount;        /* Refcount for slab cache destroy */
        void (*ctor)(void *);
        int inuse;        /* Offset to metadata */
        int align;        /* Alignment */
        int reserved;        /* Reserved bytes at the end of slabs */
        int red_left_pad;    /* Left redzone padding size */
        const char *name;    /* Name (only for display!) */
        struct list_head list;    /* List of slab caches */
    #ifdef CONFIG_SYSFS
        struct kobject kobj;    /* For sysfs */
        struct work_struct kobj_remove_work;
    #endif
    #ifdef CONFIG_MEMCG
        struct memcg_cache_params memcg_params;
        int max_attr_size; /* for propagation, maximum size of a stored attr */
    #ifdef CONFIG_SYSFS
        struct kset *memcg_kset;
    #endif
    #endif
    #ifdef CONFIG_SLAB_FREELIST_HARDENED
        unsigned long random;
    #endif
    #ifdef CONFIG_NUMA
        /*
         * Defragmentation by allocating from a remote node.
         */
        int remote_node_defrag_ratio;
    #endif
    #ifdef CONFIG_SLAB_FREELIST_RANDOM
        unsigned int *random_seq;
    #endif
    #ifdef CONFIG_KASAN
        struct kasan_cache kasan_info;
    #endif
        struct kmem_cache_node *node[MAX_NUMNODES];
    };
此处我们暂且不关心其他的成员变量，首先关注`struct kmem_cache_cpu __percpu *cpu_slab;`和`struct
kmem_cache_node *node[MAX_NUMNODES];`
那么我们首先来看`struct kmem_cache_node
*node[MAX_NUMNODES];`：(`/source/mm/slab.h#L453`)
    struct kmem_cache_node {
        spinlock_t list_lock;
    #ifdef CONFIG_SLAB
        struct list_head slabs_partial;    /* partial list first, better asm code */
        struct list_head slabs_full;
        struct list_head slabs_free;
        unsigned long total_slabs;    /* length of all slab lists */
        unsigned long free_slabs;    /* length of free slab list only */
        unsigned long free_objects;
        unsigned int free_limit;
        unsigned int colour_next;    /* Per-node cache coloring */
        struct array_cache *shared;    /* shared per node */
        struct alien_cache **alien;    /* on other nodes */
        unsigned long next_reap;    /* updated without locking */
        int free_touched;        /* updated without locking */
    #endif
    #ifdef CONFIG_SLUB
        unsigned long nr_partial;
        struct list_head partial;
    #ifdef CONFIG_SLUB_DEBUG
        atomic_long_t nr_slabs;
        atomic_long_t total_objects;
        struct list_head full;
    #endif
    #endif
    };
这个结构体我们称之为节点，值得注意的是`struct
list_head`这个结构体，正如他们的名字所示，这三个结构体的成员变量分别表示部分使用的`slab`、全部使用的`slab`、全部空闲的`slab`，这个结构体的实现也很简单，就是一个前导指针和一个后向指针而已：(`/source/include/linux/types.h#L186`)
    struct list_head {
        struct list_head *next, *prev;
    };
## 0x03 slub分配器的初始化
###  `kmem_cache_init()`源码分析
`kmem_cache_init()`是`slub`分配算法的入口函数：(在`/source/include/linux/slab.c#L4172`处实现)
那么我们来看这个结构体：(“)
    void __init kmem_cache_init(void)
    {
        static __initdata struct kmem_cache boot_kmem_cache,boot_kmem_cache_node;
        if (debug_guardpage_minorder())
            slub_max_order = 0;
        kmem_cache_node = &boot_kmem_cache_node;
        kmem_cache = &boot_kmem_cache;
        // 调用 create_boot_cache 创建 kmem_cache_node 对象缓冲区
        create_boot_cache(kmem_cache_node, "kmem_cache_node",
            sizeof(struct kmem_cache_node), SLAB_HWCACHE_ALIGN);
        // 用于注册内核通知链回调
        register_hotmemory_notifier(&slab_memory_callback_nb);
        /* Able to allocate the per node structures */
        slab_state = PARTIAL;
        // 调用 create_boot_cache 创建 kmem_cache 对象缓冲区
        create_boot_cache(kmem_cache, "kmem_cache",
                offsetof(struct kmem_cache, node) +
                    nr_node_ids * sizeof(struct kmem_cache_node *),
                   SLAB_HWCACHE_ALIGN);
        // 将临时kmem_cache向最终kmem_cache迁移，并修正相关指针，使其指向最终的kmem_cache
        kmem_cache = bootstrap(&boot_kmem_cache);
        /*
         * Allocate kmem_cache_node properly from the kmem_cache slab.
         * kmem_cache_node is separately allocated so no need to
         * update any list pointers.
         */
        kmem_cache_node = bootstrap(&boot_kmem_cache_node);
        /* Now we can use the kmem_cache to allocate kmalloc slabs */
        setup_kmalloc_cache_index_table();
        create_kmalloc_caches(0);
        /* Setup random freelists for each cache */
        init_freelist_randomization();
        cpuhp_setup_state_nocalls(CPUHP_SLUB_DEAD, "slub:dead", NULL, slub_cpu_dead);
        pr_info("SLUB: HWalign=%d, Order=%d-%d, MinObjects=%d, CPUs=%u, Nodes=%dn",
            cache_line_size(),
            slub_min_order, slub_max_order, slub_min_objects,
            nr_cpu_ids, nr_node_ids);
    }
###  `create_boot_cache()`源码分析
`create_boot_cache()`用于创建分配算法缓存，主要是用于初始化`boot_kmem_cache_node`结构：(`create_boot_cache()`在`/source/mm/slab_common.c#L881`处实现)
    /* Create a cache during boot when no slab services are available yet */
    void __init create_boot_cache(struct kmem_cache *s, const char *name, size_t size,
            slab_flags_t flags)
    {
        int err;
        s->name = name;
        s->size = s->object_size = size;
        // calculate_alignment() 用于计算内存对齐值
        s->align = calculate_alignment(flags, ARCH_KMALLOC_MINALIGN, size);
        // 初始化 kmem_cache 结构的 memcg 参数
        slab_init_memcg_params(s);
        // 创建 slab 核心函数
        err = __kmem_cache_create(s, flags);
        if (err)
            panic("Creation of kmalloc slab %s size=%zu failed. Reason %dn",
                        name, size, err);
        // 暂时不合并 kmem_cache
        s->refcount = -1;    /* Exempt from merging for now */
    }
###  `bootstrap()`源码分析
`bootstrap()`用于将临时`kmem_cache`向最终`kmem_cache`迁移，并修正相关指针，使其指向最终的`kmem_cache`：(`bootstrap()`在`/source/mm/slub.c#L4141`处实现)
    /********************************************************************
     *            Basic setup of slabs
     *******************************************************************/
    /*
     * Used for early kmem_cache structures that were allocated using
     * the page allocator. Allocate them properly then fix up the pointers
     * that may be pointing to the wrong kmem_cache structure.
     */
    static struct kmem_cache * __init bootstrap(struct kmem_cache *static_cache)
    {
        int node;
        // 通过 kmem_cache_zalloc() 申请 kmem_cache 空间
        // 注意，存在以下函数调用链 kmem_cache_zalloc()->kmem_cache_alloc()->slab_alloc()
        // 其最终将会通过 create_boot_cache() 初始化创建的 kmem_cache 来申请 slub 空间来使用
        struct kmem_cache *s = kmem_cache_zalloc(kmem_cache, GFP_NOWAIT);
        struct kmem_cache_node *n;
        // 将作为参数的的 kmem_cache 结构数据通过 memcpy() 拷贝至申请的空间中
        memcpy(s, static_cache, kmem_cache->object_size);
        /*
         * This runs very early, and only the boot processor is supposed to be
         * up.  Even if it weren't true, IRQs are not up so we couldn't fire
         * IPIs around.
         */
        // 调用 __flush_cpu_slab() 刷新 cpu 的 slab 信息
        __flush_cpu_slab(s, smp_processor_id());
        // 遍历各个内存管理节点node
        for_each_kmem_cache_node(s, node, n) {
            struct page *p;
            // 遍历 partial slab ，修正每个 slab 指向 kmem_cache 的指针
            list_for_each_entry(p, &n->partial, lru)
                p->slab_cache = s;
    // 若开启CONFIG_SLUB_DEBUG
    #ifdef CONFIG_SLUB_DEBUG
            // 遍历 full slab ，修正每个 slab 指向 kmem_cache 的指针
            list_for_each_entry(p, &n->full, lru)
                p->slab_cache = s;
    #endif
        }
        slab_init_memcg_params(s);
        // 将 kmem_cache 添加到全局 slab_caches 链表中
        list_add(&s->list, &slab_caches);
        memcg_link_cache(s);
        return s;
    }
###  `create_kmalloc_caches()`源码分析
`create_kmalloc_caches()`用于创建`kmalloc`数组：(`create_kmalloc_caches()`在`/source/mm/slab_common.c#L1071`处实现)
    /*
     * Create the kmalloc array. Some of the regular kmalloc arrays
     * may already have been created because they were needed to