for the textbook implementation of the ﬂoating-point Lapla-
cian mechanism, the probability of ruling out one of two
adjacent databases is almost 40%. It eﬀectively means that
one can consume the privacy budget in arbitrary small incre-
ments, without reducing capacity of the side channel. This
ability will be exploited in the next section, where we show
that the entire database can be extracted by asking suﬃ-
ciently many adaptively chosen queries.
′
Another reason to consider the case of a large λ, is that it
) as long as they are
applies to all values of f (D) and f (D
both much smaller than λ.
Figure 3 plots two functions. The ﬁrst (smooth graph) is
∗
the probability density function of ˜f
1/λ(D) for λ = 106 and
f (D) = 100. The range of the x-axis is [−2λ, 2λ], which cov-
ers 1− exp(−2) ≈ 0.865 fraction of output values under that
distribution. The second (ragged) line is the probability,
computed over small intervals [a, a + µa], of the event that
∗
an output of ˜f
1/λ(D) in that range is outside the support of
x=1⊘πx+9·2−543⊗LN(x)3⊗LN(x+9·2−54)3⊗LN(·)......1.5˜f∗1/3(D)˜f∗1/3(D′)............1.5+3·2−521.5+2·2−52654100%
80%
60%
40%
20%
y
t
i
l
i
b
a
b
o
r
p
”
n
u
g
g
n
i
k
o
m
s
“
◦◦◦◦◦◦◦◦◦◦◦◦
••••••••••••
◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦◦
•••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••
•
maximal precision
−53
precision 2
•
◦
0%
0.0
0.4
0.8
1.2
1.6
2.0
2.4
2.8
∗
∗
1/λ(D) (solid dots) or ˜f
Figure 2: Probability that outputs from ˜f
1/λ,53(D) (hollow dots) fall outside support of
∗
′
˜f
) = 1.
)), as a function of λ. f (D) = 0 and f (D
1/λ(D
∗
) (resp., ˜f
1/λ,53(D
′
′
λ
′
[
∗
the distribution ˜f
1/λ(D
):
x /∈ supp( ˜f
∗
1/λ(D
x ∈ supp( ˜f
1/λ(D)) ∩ [a, a + µa]
∗
s(a) , Pr
))
(cid:12)(cid:12)(cid:12)
′
]
.
We use µ = 0.001 and f (D
′
) = 101.
The plot suggests that s(a) (computed over suﬃciently
small intervals) is smooth except with sharp discontinuities
at powers of 2 and certain multiples of λ. Indeed, consider an
interval [2k·u, 2k·v], when f (D
),
and 1/2 < u < v < 1. The set of doubles in this interval is
uniformly spaced and has cardinality 253(v − u).
On the other hand, the interval in the range of the uniform
distribution that is mapped to [2k · u, 2k · v] is approximately
(ignoring for a moment the contribution of f (D) ≪ 2k):
)+2k < ln 2·λ, 2k ≫ f (D
′
′
[exp(−2kv/λ), exp(−2ku/λ)],
which, for 2k < ln 2 · λ is contained in the [1/2, 1) inter-
val. The total number of doubles in that interval is 253 ·
(exp(−2ku/λ) − exp(−2kv/λ)). The ratio of the doubles in
the range and the domain of the mapping x 7→ −λ ln(x) is
thus
253 · (exp(−2ku/λ) − exp(−2kv/λ))
253(v − u)
,
which can be approximated for v ≈ u as
− exp(−2ku/λ)
′
(u) =
exp(−2ku/λ).
2k
λ
As 2k gets smaller compared to λ, the ratio quickly ap-
proaches 0. It means that for smaller values of k, the number
of doubles in the image of the mapping is much larger than
the number of doubles in its range.
Recall that the doubles output by the uniform distribu-
tion are spaced evenly. The logarithm function destroys
the arithmetic progression, resulting in a sequence that is
not translation invariant. The Laplacian mechanism on in-
puts D and D
produces two distributions shifted by 1, and
′
we may heuristically assume that a random element from
∗
the support of ˜f
1/λ(D) on [a, b] belongs to the support of
∗
˜f
) in
1/λ(D
[a, b], which we estimated earlier. It follows that
∗
) with probability close to the density of ˜f
1/λ(D
′
′
s(a) ≈ 2k
λ
exp(−a/λ),
where 2k is the smallest power of 2 larger than a. This
expression is in remarkable agreement with Figure 3, giv-
ing a tight lower bound on the ragged curve in the range
[−(ln 2)λ, (ln 2)λ]. Although some breaches of diﬀerential
privacy happen outside that range, our analysis explains al-
most 90% of all violations for this setting of the parameters.
4.7 A practical attack
To demonstrate that the vulnerability described in the
paper is more powerful than a simple breach of diﬀerential
privacy, we adapt the technique from the previous section
to extract the entire content of a database.
Consider a list of alphanumerical records and a query lan-
guage that reports counts of records sharing a particular
preﬁx. All systems considered by this paper allow this ac-
cess mechanism.
If histogram counts are protected with Laplacian noise
generated with a method vulnerable to our attack, we may
reconstruct the entire database by issuing adaptively-chosen
queries. We begin by obtaining an upper bound on number
of records in the database, then ask a histogram query on the
ﬁrst character of all records, i.e., ask the number of records
that start with ‘\0’, ‘\1’,. . . ,‘\255’. Initially, all counts up
to the upper bound are feasible, but with every query, ap-
proximately 40% of the counts not equal to the exact answer
can be excluded.
After a unique count for each ﬁrst character is identiﬁed,
we append all possible characters to preﬁxes with non-zero
support, and iterate the process until the entire dataset is
recovered. Since a single run of the attack is eﬀective even
for very large λ according to the analysis of the previous
655100%
80%
60%
40%
20%
0%
−2λ
ln 2 · λ
1/λ(D)) that x /∈ supp( ˜f
∗
∗
Figure 3: The ragged curve plots the probability for x in supp( ˜f
1/λ(D
∗
) = 101, and λ = 106. The smooth curve is pdf( ˜f
small intervals, where f (D) = 100, f (D
1/λ(D)).
− ln 2 · λ
2λ
218 219
λ 220
′
′
−220 − λ −219−218 0
)) averaged over
section, the attack can be executed within an arbitrarily
small total privacy budget.
We implemented the attack against PINQ, and veriﬁed
its eﬀectiveness. We were able to reconstruct a database
consisting of 18K records in a fewer than 1000 queries with
the total privacy budget smaller than 10
−6.
5. DEFENSE
The primary reason why the attack of the previous sec-
tion succeeds is because the standard ﬂoating-point Lapla-
cian sampling procedures (Section 4.1) result in very porous
distributions, missing out on many possible output values.
That would not be a problem if the missing values were the
same for adjacent inputs. Unfortunately, the distributions
are not translation invariant, and after being shifted by f (D)
and f (D
), they diverge signiﬁcantly.
′
These eﬀects are observable in vanishingly small scales,
bearing almost no relation on numerical accuracy or the
number of usable bits of the outputs. Even if a non-private
f (·) returns answers with many signiﬁcant digits, the Lapla-
cian mechanism degrades accuracy of the resulting mecha-
nism, introducing error with the standard deviation of ∆/ϵ.
We leverage both observations in designing the snapping
mechanism, whose ﬂoating-point implementation is proved
diﬀerentially private in Section 5.2: the set of output val-
ues is made independent of the input, and output values
are spaced approximately λ apart. Before we introduce the
snapping mechanism, we discuss two approaches that are
simple but insecure.
5.1 False starts
An appealing goal for a defense mechanism would be to
come up with a method for sampling from a “ﬂoating-point
aware” Laplacian distribution whose addition guarantees dif-
ferential privacy even when realized in ﬂoating-point arith-
metic. One beneﬁt of this strategy is its modularity—it
would be suﬃcient to prove and implement such distribu-
tion once, and use it in a variety of contexts that require
additive noise.
∗
∗
′
∗
′
2(cid:0)32 .
(λ)⌉
(λ)⌉
2(cid:0)32 and f (D
(λ) to the closest integer multiple of, say, 2
We analyze two most straightforward approaches towards
this goal, and ﬁnd them ineﬀective and possibly even more
detrimental to privacy than current implementations.
Rounding. It may appear that since gaps in the double-
precision outputs of the Laplacian sampling procedure are
only noticeable at the smallest possible scale, dropping the
least signiﬁcant bits of the Laplacian could increase security.
Consider, for example, the eﬀect of rounding the out-
−32,
put of Lap
denoted as ⌊Lap
It is easy to verify that un-
der some mild assumptions on accuracy of a ﬂoating-point
implementation of the log function and access to the uni-
form distribution on D ∩ (0, 1), the resulting distributions
) + ⌊Lap
(λ)⌉
for f (D) + ⌊Lap
∗
2(cid:0)32 will
have identical supports if f (D) = 0 and f (D
) = 1. More-
over, the mechanism conﬁned to these two output values is
going to be 1/λ-diﬀerentially private.
Recall, however, that the sensitivity of f is an upper bound
on the diﬀerence of f on adjacent inputs. Suppose f (D) −
−33, which may easily be arranged by an adver-
f (D
sarially chosen function or input. Adding a random vari-
−32 will have the eﬀect that
able rounded to a multiple of 2
the supports of two distributions of the Laplacian mecha-
nism applied to D and D
become completely disjoint, and
privacy is going to be lost after a single invocation of the
mechanism.
Smoothing. Taking the opposite approach, and trying to
smooth the additive Laplacian noise, ensuring that all dou-
bles are in its support, also fails to achieve diﬀerential pri-
vacy, albeit for a diﬀerent reason.
) =
1, and additive Lap(1) noise. With probability ≈ 20% the
random variable x = f (D) ⊕ Lap(1) belongs to the inter-