3.2 Security of CAU
Theorem 3.1 below gives a tight mu-security bound of CAU against a d-repeating adversary. We
stress that the bound σ in the theorem takes into account the block length of both the message
and the associated data of an encryption/veriﬁcation query.
Theorem 3.1 (Mu-security of CAU/GCM) Let E : {0, 1}k × {0, 1}n → {0, 1}n be a blockcipher
that we will model as an ideal cipher, with k ≥ n ≥ 128. Let H be a c-AXU hash function. Let
A be a d-repeating adversary attacking CAU[H, E] using at most p ≤ 2n−2 ideal-cipher queries, q
encryption/veriﬁcation queries of total block length at most σ, and the total number of blocks in
encryption queries of each user is at most B. Then
Advmu-ae
CAU[H,E](A) ≤ d(p + q) + n(q + σ + p)
2k
+
σ(2B + cn + 3)
2n
+
2q + 1
22n +
σ(σ + ncd) + 2pq
2k+n
.
9
Discussion. It is important to note that the bound in Theorem 3.1 does not depend explicitly on
the number of users, which can become as large as q. The only dependence on users is through the
parameter d, which can be (but generally is not) as large as q. The bound in Theorem 3.1 contains
three important factors, pd
2n that correspond to actual attacks. We discuss them here,
which will be instrumental for understanding the proof below.
2k , and σB
2k , nσ
First, for the term pd
2k , consider the following attack. The adversary picks an arbitrary nonce N ,
a long enough message M , and makes d encryption queries (1, N, A, M ), . . . (d, N, A, M ), where A is
the empty string, to get answers C1, . . . , Cd respectively. (Recall that the adversary is d-repeating,
so it cannot repeat a nonce N in encryption queries for more than d users.) By picking p distinct
candidate keys K1, . . . , Kp and comparing Ci with CAU.Enc(Kj, N, A, M ) for all 1 ≤ i ≤ d and
1 ≤ j ≤ p, the adversary can recover one key with probability about pd
2k .
For the term nσ
2k , consider the following attack. The adversary ﬁrst picks an arbitrary nonce
N and p distinct candidate keys K1, . . . , Kp, and makes 2p ideal-cipher queries (Ki, (pad(N ), +)),
(Ki, (0n, +)). The goal of the adversary is to make q veriﬁcation queries (j, N, A, T (cid:107) C), for j =
1, . . . , q for associated data A and ciphertext T (cid:107) C of (cid:96) blocks total that it will determine later. To
maximize its chance of winning, the adversary will iterate through all possible tuples (A∗, T ∗ (cid:107) C∗) of
(cid:96) blocks total and compute count(A∗, T ∗ (cid:107) C∗), the number of ideal-cipher queries (Ki, (pad(N ), +))
whose answer is HLi(A∗, C∗)⊕T ∗, where Li ← EKi(0n).
It then picks (A, T (cid:107) C) to maximize
count(A, T (cid:107) C). Then the adversary wins with advantage about E[count] · q/2k. The proof of
Theorem 3.1 shows that E[count] ≤ n(cid:96) = nσ
q with very high probability, and thus the advantage of
the adversary is at most nσ/2k.
For the term σB/2n, consider the following distinguishing attack. The adversary will target u
users, where u = (cid:98)σ/B(cid:99). Let M be an arbitrary message of B blocks. Pick an arbitrary nonce N ,
and let A be the empty string. The adversary then calls Enc(i, N, A, M ) to receive Ti (cid:107) Ci, for every
i = 1, . . . , u. If some ciphertext core Ci contains two identical blocks then the adversary outputs 0,
otherwise it outputs 1. By using appropriate data structure, one can implement this attack using
O(B) space and O(σ) time. To analyze the adversary’s advantage, we need the following technical
Lemma 3.2 and Lemma 3.3. The ﬁrst result states a well-known lower bound for the birthday
bound; see, for example, [9, Appendix A] for a proof. The second result is a useful inequality whose
proof can be found in [4].
throw 1 ≤ q ≤ √
Lemma 3.2 (Lower bound for birthday bound) Let N > 0 be an integer. Suppose that we
2N balls into N bins uniformly at random. Then the chance that there are two
balls that fall into the same bin is at least q(q−1)
4N .
Lemma 3.3 [4] Let p ≥ 1 be an integer and a ≥ 0 a real number. Assume ap ≤ 1. Then
(1 − a)p ≤ 1 − ap/2.
Back to the analysis, in the ideal world, each Ci is a truly random B−block string, and thus
. Hence in the
from Lemma 3.2, the chance that it contains two identical blocks is at least B(B−1)
4·2n
ideal world, the chance that the adversary outputs 1 is at most
(cid:16)
1 − B(B − 1)
2n+2
(cid:17)u ≤ 1 − B(B − 1)u
2n+3
≈ 1 − σB
2n+3
where the inequality is due to Lemma 3.3. In contrast, in the real world, the adversary will always
output 1. Hence the adversary wins with advantage about σB
2n+3 .
The term σB/2n also deserves some further discussion. It conveys an important message, and
namely that as B becomes smaller, the term becomes closer to σ/2n. A small B could be enforced,
10
for example, by ensuring that a session in a protocol only transfers a bounded amount of data
before a re-keying operation is issued. In other words, re-keying only improves multi-user security.
This is important, when compared to the single-user security analysis, which gives a bound of the
order σ2/2n. (Of course, if we have one single user, then B = σ.)
Proof ideas. The proof examines several cases but here we discuss two illustrative ones that
correspond to the two attacks above. First, consider the event that the adversary can query
Prim(K, (x, +)) and query Enc(i, N, A, M ) such that K = Ki and x ∈ {pad(N ), . . . , pad(N ) + (cid:96)},
where (cid:96) = |M|n. This case includes the ﬁrst attack above. Note that for any query Prim(K, (x, +)),
since the adversary is d-repeating, there are at most d queries Enc(i, N, A, M ) such that x ∈
{pad(N ), . . . , pad(N ) + (cid:96)}, where (cid:96) = |M|n, and the chance that some of these d latter queries
satisﬁes Ki = K is at most d/2k. Hence, this case happens with probability at most dp/2k.
On the other hand, in GCM, every user i derives the hash key Li via EKi(0n). Thus by querying
Prim(K, (0n, +)) for p keys K, the adversary may accidentally obtain some blockcipher key Ki and
its associated hash key Li with probability about pu/2k, where u is the number of users, and in
the worst case, u can be as large as q. This creates a problem in using the AXU-property of the
hash function H, since we can no longer treat the hash keys as independent of the queries. This
is exactly the issue in the second attack above, where the adversary adaptively picks veriﬁcation
queries after seeing the hash keys.
To make the analysis simpler, at the beginning, we will even grant the adversary all pairs
(K, EK(0n)) for every K ∈ {0, 1}k, and this can only help the adversary. However, now when
we pick Ki ←$ {0, 1}k, the corresponding key Li ← EKi(0n) is no longer uniformly random. To
understand the distribution of the key Li, we need the following balls-into-bins result of Bose,
Hoang, and Tessaro [7].
Lemma 3.4 ([7]) Fix integers n ≥ 128, (cid:96) ≥ 2, and a ≥ 1. Suppose that we throw q ≤ a · 2n
balls into 2n bins. The throws may be inter-dependent, but for each i-th throw, conditioning on the
result of the prior throws, the conditional probability that the i-th ball falls into any particular bin
is at most 21−n. Then the chance that the heaviest bin contains (cid:100)a(cid:96)n/2(cid:101) or more balls is at most
2−(3(cid:96)+2)n.
Now, view each granted pair (K, EK(0n)) as throwing a ball into bin EK(0n). Thus we throw
2k balls uniformly at random into 2n bins. Thus using Lemma 3.4 with a = 2k−n and (cid:96) = 2, with
probability at least 1−2−8n, each bin contains at most n·2k−n balls. Thus for any L ∈ {0, 1}n, there
are at most n · 2k−n keys K such that EK(0n) = L. In other words, when we pick Ki ←$ {0, 1}k,
the conditional min-entropy of Li is at least − lg(n · 2k−n/2k) = n − lg(n).
Going back to the dependency issue of the hash keys and its inputs, a particularly tough case is to
analyze the probability that the adversary can ﬁrst make a query Prim(K, (pad(N ), +)) and obtain
answer y and then query Vf(i, N, A, T (cid:107) C), and it happens that K = Ki and HLi(A, C)⊕T = y,
where Ki is the blockcipher key of user i, and Li ← EK(0n). This case includes the second attack
above. To deal with this case, we employ a trick from [7]. Speciﬁcally, consider a ﬁxed tuple
(N∗, A∗, C∗) and let (cid:96) = |A∗|n + |C∗|n. View each query Prim(K, (pad(N∗), +)) of answer y as
throwing a ball into bin HL(A∗, C∗)⊕y, where L ← EK(0n). By Lemma 3.4 above, with probability
at least 1 − 2−(3(cid:96)+2)n, each bin contains at most (cid:96)n balls. Thus for an adaptive T , the number
count∗ of matching ideal-cipher queries is at most (cid:96)n = (|A∗|n + |C∗|n)n, with probability at
least 1 − 2−(3(cid:96)+2)n. Then for any adaptive choice (N, A, T (cid:107) C), the chance that there are at most
(|A|n + |C|n) · n matching ideal-cipher queries is at least
11
∞(cid:88)
(cid:88)
(cid:96)=2
(i∗,N∗,A∗,C∗):|A∗|n+|C∗|n=(cid:96)
1 −
2−(3(cid:96)+2)n ≥ 1 −
∞(cid:88)
(cid:96)=2
22n+2(cid:96) · 2−(3(cid:96)+2)n ≥ 1 − 2
22n .
Hence, the chance that the case above happens is at most nσ/2k + 2q/22n.
Proof of Theorem 3.1 : Without loss of generality, assume that σ ≤ 2n/n; otherwise the bound
is moot. As mentioned earlier, at the beginning, we will give the adversary (K, EK(0n)) for every
K ∈ {0, 1}k, and this can only help the adversary. Because we consider computationally unbounded
adversaries, without loss of generality, assume that A is deterministic, and never repeats a prior
query. Assume that if the adversary queries Prim(K, (x, +)) to get an answer y then it will not
subsequently query Prim(K, (y,−)), since the answer would be x. Likewise, assume that if the
adversary queries Prim(K, (y,−)) to get an answer x then it will not later query Prim(K, (x, +).
Our proof is based on the H-coeﬃcient technique.
Defining bad transcripts. In the real world, after the adversary ﬁnishes querying, we will give
it the blockcipher keys Ki of all users i. In the ideal world, we instead give the adversary truly
random strings Ki ←$ {0, 1}k, independent of the transcript. Thus the transcript implicitly includes
the hash keys Li ← EKi(0n). This key revealing only helps the adversary. Thus a transcript consists
of the revealed keys, the granted ideal-cipher queries, and the following information:
• Ideal-cipher queries: For each query Prim(K, (x, +)) with answer y, we associate it with an
entry (prim, K, x, y, +). Likewise, for each query Prim(K, (y,−)) with answer x, we associate
it with an entry (prim, K, x, y,−). We stress that we do not create prim entries for the granted
ideal-cipher queries, and thus there are at most p prim entries.
• Encryption queries: For each query Enc(i, N, A, M ) with answer T (cid:107) C, let M = M1 ··· M(cid:96)
and C = C1 ··· C(cid:96), with 0 ≤ |M(cid:96)| = |C(cid:96)| < n, and |Mj| = |Cj| = n for every j < (cid:96). For
each j < (cid:96), let Vj = Mi⊕Cj. Let V0 = HLi(A, C)⊕T . If |M(cid:96)| = 0 then let V ← V0 ··· V(cid:96)−1,
otherwise let V ← V0 ··· V(cid:96), where V(cid:96) ← EKi(pad(N ) + (cid:96)) in the real world, and V(cid:96) ←
(C(cid:96)⊕M(cid:96))(cid:107) Z in the ideal world, with Z ←$ {0, 1}n−|M(cid:96)|. The string V is revealed to the
adversary when it ﬁnishes querying, which can only improve its advantage. Associate the
query above with the entry (enc, i, N, A, M, T (cid:107) C, V ).
• Veriﬁcation queries: For each query Vf(i, N, A, T (cid:107) C), associate it with the corresponding
entry (vf, i, N, A, T (cid:107) C). Note that we do not need to keep track of the answers of the veriﬁ-
cation queries, since for any valid transcript in the ideal world, the answers of all veriﬁcation
queries must be false.
We say that a transcript is bad if one of the following happens:
1. There are two entries (enc, i, N, A, M, T (cid:107) C, V ) and (enc, j, N, A(cid:48), M(cid:48), T (cid:48) (cid:107) C(cid:48), V (cid:48)) with i (cid:54)= j
but Ki = Kj. Eliminating this case removes potential inconsistency due to the nonce reuse.
2. There is an entry (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and some indices 0 ≤ s < t ≤ (cid:96) such that
Vs = Vt. Recall that in the real world, Vs and Vt are outputs of EKi on diﬀerent inputs
pad(N ) + s and pad(N ) + t. Thus in the real world, the strings Vs and Vt can’t be the same.
0 ··· V (cid:48)
u)
t . Again, in the
3. There are two entries (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and (enc, j, N(cid:48), A(cid:48), M(cid:48), T (cid:48) (cid:107) C(cid:48), V (cid:48)
with N (cid:54)= N(cid:48) and with some indices s and t such that Ki = Kj, and Vs = V (cid:48)
12
real world, Vs and V (cid:48)
Thus in the real world, the strings Vs and V (cid:48)
t are outputs of EKi on diﬀerent inputs pad(N ) + s and pad(N(cid:48)) + t.
t can’t be the same.
4. There is an entry (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and an index t such that Vt = Li. Recall
that in the real world, Li = EKi(0n) whereas Vt is the output of EKi on input pad(N )+t (cid:54)= 0n.
Thus in the real world, the strings Li and Vt must be diﬀerent.
5. There are two entries (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and (prim, K, x, y,·) such that K = Ki
and x ∈ {pad(N ), . . . , pad(N ) + (cid:96)}. Eliminating this case removes the potential inconsistency
due to the adversary’s accidental query of a correct key.
6. There are two entries (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and (prim, K, x, y,·) such that K = Ki
and y ∈ {V0, . . . , V(cid:96)}. Again, eliminating this case removes the potential inconsistency due to
the adversary’s accidental query of a correct key.
7. There are two entries (enc, i, N, A, M, T (cid:107) C, V0 ··· V(cid:96)) and (vf, j, N, A(cid:48), T (cid:48) (cid:107) C(cid:48)) such that V0 =
HLj (A(cid:48), C(cid:48))⊕T (cid:48) and Ki = Kj. This means that the adversary should have received the
answer true for this veriﬁcation query, but recall that for valid transcripts in the ideal world,
the answer must be false, leading to inconsistency.
8. There are entries (vf, i, N, A, T (cid:107) C) and (prim, K, x, y,·) such that K = Ki and HLi(A, C)⊕T =
y and x = pad(N ). This means that the adversary should have received the answer true for
this veriﬁcation query, but recall that for valid transcripts in the ideal world, the answer must
be false, leading to inconsistency.
If a transcript is not bad and is valid for the ideal system then we say that it is good.
Probability of bad transcripts. Let Tideal be the random variable for the transcript in the
ideal system. We now bound the probability that Tideal is bad. For each j ∈ {1, . . . , 8}, let Badj
be the set of transcripts that violates the j-th constraint of badness. View each granted query
(K, EK(0n)) as throwing a ball into bin EK(0n). Thus we throw 2k balls into 2n bins uniformly
at random. By applying Lemma 3.4 for a = 2k−n and (cid:96) = 2, with probability at least 1 − 2−8n,
for every string L ∈ {0, 1}n, there are at most n · 2k−n keys K such that EK(0n) = L. In other