14 use history-sniﬃng code from meaningtool.com.
Figure 5 shows the JavaScript attack code exactly as found
on youporn.com. The code creates an obfuscated list of in-
spected websites (line 1). We only show part of the list —
the actual list had 23 entries. For each site, the code decodes
the website name (line 6), creates a link to the target site on
the page (lines 11–12), reads the color of the link that was
2781:var k = { 0: "qpsoivc/dpn",
1: "sfeuvcf/dpn", ... };
2:var g = [];
3:for(var m in k) {
4: var d = k[m];
5: var a = "";
6: for(var f = 0; f < d.length; f++) {
a += String.fromCharCode(d.charCodeAt(f)-1)
}
7: var h = false;
8: for(var j in {"http://":"","http://www.":""}){
9:
10:
11:
var l = document.createElement("a");
l.href = j + a;
document.getElementById("ol").
12:
13:
14:
15:
16:
17:
18:
appendChild(l);
var e = "";
if(navigator.appName.
indexOf("Microsoft") != -1 ){
e = l.currentStyle.color
} else {
e = document.defaultView.
getComputedStyle(l, null).
getPropertyValue("color")
}
if(e == "rgb(12, 34, 56)" ||
e == "rgb(12,34,56)") { h = true }
19: }
20: if(h) { g.push(m) }
21:}
22:var b = (g instanceof Array)? g.join(",") : "";
23:var c = document.createElement("img");
24:c.src= "http://ol.youporn.com/blank.gif?id="+b;
25:document.getElementById("ol").appendChild(c)
Figure 5: Attack code as found on youporn.com
just created (lines 12–17), and ﬁnally tests the color (line
18). If the color indicates a visited link, the h variable is set
to true, which in turn causes the link to be inserted in the
list g of visited sites (line 20). This list is then ﬂattened into
a string (line 22), and an image is added to the current web
page, encoding the ﬂattened string into the src name of the
image (lines 23–25).
The ﬂow in Figure 5 from the color property e to the ar-
ray of visited sites g is actually an indirect ﬂow that passes
through two conditionals (on lines 18 and 20). Our frame-
work’s ability to track such indirect ﬂows allowed us to ﬁnd
this history-sniﬃng attack. Note however that our frame-
work found the ﬂow because the sites being tested had ac-
tually been previously visited (because we had already run
the experiments once, and so all the top 50,000 Alexa global
sites were in the history). If none of the tested sites had been
visited, the g array would have remained empty, and no vio-
lation of the policy would have been observed, even though
in fact the user’s empty history would have been leaked.
This example is precisely the implicit ﬂow limitation that
was mentioned in Section 2.3.
False-positive cases of history sniﬃng Of the 63 sites
ﬂagged by our framework, 17 are false positives in that a
manual examination of the source code and run-time behav-
ior did not allow us to conclude that they were real cases of
history sniﬃng. Out of these 17 sites, 12 contain JavaScript
code that is too complicated to understand. The remaining 5
sites contain a history sniﬃng widget from interclick.com,
but no suspicious runtime behavior was detected by monitor-
ing their network access. Our framework reported these sites
Provider Description
addtoany
infolinks
kontera
other
social
advertisement
advertisement
-
Sites
83
124
87
32
Inspected URLs
120.2
14
11.5
44.4
Table 2: Characteristics of suspicious websites de-
pending on JavaScript widget provider
either because they inspected style properties for purposes
other than history sniﬃng, or because too many irrelevant
values were tainted by our handling of indirect ﬂows.
A more stringent policy To investigate the possibility of
history hijacking further, we also looked at all the sites that
simply read the computed style of a link. This uncovered an
additional 422 websites that read style properties of links,
but did not send the properties out on the network. Un-
fortunately, because our framework does not cover all the
corner cases of information ﬂow in JavaScript (as discussed
later), we cannot immediately conclude that these sites did
not transfer the browser history. Even if we were certain
that the style information was not sent to the network, it is
still possible that the absence of sending data was used to re-
veal information about the browsing history. For example,
if a site sent the browsing history only if a link was vis-
ited, then the server could have learned about certain links’
not being visited without any information’s being transfered
from the client. Thus, to better understand the behavior of
these additional websites, we inspected them in detail, and
categorized them into two bins: suspicious websites, and
non-suspicious websites.
Suspicious sites Of the 422 sites, 326 sites exhibit what
we would categorize as suspicious behavior. In particular,
these suspicious websites inspect a large number of external
links, and some of these links are dynamically generated, or
they are located in an invisible iframe. We found that many
of them embed a JavaScript widget developed by another
website that inspects the browser history systematically.
Table 2 shows how such widgets are used on the 326 sites.
For each JavaScript widget, we give the name of its provider,
a description of its provider, the number of sites embedding
it, and the number of URLs it inspects on average over the
sites on which it is embedded. The most notable is a menu
widget developed by addtoany.com which inspects around
120 URLs on average to activate or deactivate each menu
item depending on the browser history.
Non-suspicious sites The remaining 96 sites seemed non-
suspicious. Of these, 77 simply inspect their own website
history. The remaining 19 samples have JavaScript code
that is too complicated for us to fully understand, but where
the sites seem non-suspicious.
Incompleteness Our current implementation would miss
information ﬂow induced by certain browser built-in meth-
ods. For example, consider the code:
arr.push(z); var result = arr.join(’,’)
The value z is inserted into an array and then all the el-
ements of the array are joined into a string using the the
built-in method join. Even though we have implemented
a wrapper object for arrays to track array assignments and
279reads, we have not yet implemented a complete set of wrap-
pers for all built-in methods. Thus, in the above case, even
though result should be tainted, our current engine would
not discover this.
It would be straightforward, although
time-consuming, to create precise wrappers for all built-in
methods that accurately reﬂect the propagation of taints.
Moreover, our current implementation does not track infor-
mation ﬂow through the DOM, although recent techniques
on tracking information ﬂow through dynamic tree struc-
tures [25] could be adapted to address this limitation.
Even if our implementation perfectly tracked the taints of
all values through program execution, our approach would
still miss certain history hijacking attacks. For example, the
attacking website can use a style sheet to set the font of vis-
ited links to be much larger than the size of unvisited links.
By placing an image below a link, and using JavaScript to
observe where the image is rendered, the attacker can de-
termine whether the link is visited or not. These kinds of
attacks that use layout information would currently be very
hard to capture using a taint-based information ﬂow engine.
Some attacks in fact don’t even use JavaScript. For ex-
ample, some browsers allow the style of visited links to be
customized with a background image that is speciﬁc to that
link, and this background image can be located on the at-
tacker’s server. By observing which images are requested,
the attacker can infer which links have been visited, without
using any JavaScript.
Despite all these sources of incompleteness, our JavaScript
information ﬂow framework can still be used as a diagnostic
tool to ﬁnd real cases of history sniﬃng in the wild. By
running experiments on the Alexa global top 50,000 we have
found that 46 sites really do perform history sniﬃng, and
one of these sites is in the Alexa global top 100. We have
also found several sites that have suspicious behavior, even
though our current tool does not allow us to conclude with
full certainty that these sites transfer the browser’s history.
5. EMPIRICAL STUDY OF ATTENTION
TRACKING
We have also conducted an empirical study on the preva-
lence of keyboard/mouse tracking on popular websites.
JavaScript code can install handlers for events related to the
mouse and keyboard to collect detailed information about
what a user is doing on a given website. This information
can then be transfered over the network. It is not enough
to take a naive approach of simply prohibiting information
from being transfered into the network while the event han-
dler is being executed since the gathered information can
be accumulated in a global variable, and then sent over the
network in bulk (which is what most attacks actually do).
Policies To use our information ﬂow framework for detect-
ing keyboard/mouse tracking, we use the following policies
in our framework:
at $1.isMouseOver() inject “secret”
at $1.isClick() inject “secret”
at $1.isScroll() inject “secret”
. . .
at document.send($1, $2) block “secret” on $2
front pages of the Alexa global top 1,300 websites. One of
the challenges in performing this empirical study automati-
cally is that, to observe keyboard/mouse tracking, one has
to somehow simulate keyboard and mouse activity. Instead
of actually simulating a keyboard and mouse, we instead
chose to automatically call event handlers that have been
registered for any events related to the keyboard or mouse
(click,mousemove,mouseover,mouseout,scroll,copy,select).
To this end,
in each web page we included a common
piece of JavaScript code that automatically traverses the
DOM tree of the current page and systematically triggers
each handler with an event object that is appropriately
synthesized for the handler. Another challenge is that many
of the sites that track keyboard/mouse activity accumulate
information locally, and then send the information in bulk
back to the server at regular intervals, using timer events.
These timer events are sometimes set to intervals spanning
several minutes, and waiting several minutes per site to
observe any ﬂow would drastically increase the amount of
time needed to run our test suite. Furthermore, it’s also
hard to know, a priori, how long to wait. To sidestep these
issues,
in addition to calling keyboard and mouse event
handlers, we also automatically call timer event handlers.
We successfully ran our framework on the Alexa top 1,300
websites in a total of about two hours.
Overall, we found 328 websites on which network transfers
were ﬂagged as transferring keyboard/mouse information to
the network. Of these transfers, however, many are visu-
ally obvious to the user. In particular, many websites use
mouse-over events to change the appearance of the item be-
ing moused-over. As an example, it is common for a website
to display a diﬀerent image when the mouse moves over a
thumbnail (possibly displaying a larger version of the thumb-
nail). Although these kinds of ﬂows can be used to track
mouse activity, they are less worrisome because the user
sees a change to the web page when the mouse movement
occurs, and so there is a hint that something is being sent
to the server.
Ideally, we would like to focus on covert keyboard/mouse
tracking, in which the user’s activities are being tracked
without any visual cues that this is happening (as opposed
to visible tracking where there is some visual cue).2 How-
ever, automatically detecting covert tracking is challenging
because it would require knowing if the keyboard/mouse
activity is causing visual changes to the web page.
In-
stead, we used a simple heuristic that we developed af-
ter observing a handful of sites that perform visible key-
board/mouse tracking. In particular, we observed that when
the mouse/keyboard information is sent to the server be-
cause of a visual change, the server responds with a relatively
large amount of information (for example a new image). On
the other hand, we hypothesized that in covert tracking,
the server would not respond with any substantial amount
of data (if any at all). As a result, of all the network trans-
fers found by our information ﬂow tool, we ﬁltered out those
where the response was larger than 100 bytes (with the as-
sumption that such ﬂows are likely to be visible tracking).
After this ﬁltering, we were left with only 115 websites. We
sampled the top 10 ranked websites among these 115 sites.
Real cases of covert tracking Of the 10 sites we sampled,
Benchmarks and Summary of Results We ran our
information ﬂow framework using the above policies on the
2One could view this heuristic as charging sites, in band-
width, for the privilege of exﬁltrating user attention data.
280Rank
3
11
15
19
34
53
65
Site
youtube
yahoo.co.jp
sina.com.cn
microsoft
mail.ru
soso
about
Description
contents
portal
portal
software
email
search engine
search engine
Events
click
click
click
mouseover,click
click
click
click
Table 3: Top 7 websites that perform real behavior
sniﬃng
Rank
503
548
560
622
713
910
1236
Site
thesun.co.uk
metrolyrics
perezhilton
wired
suite101
technorati
answerbag
Description
news
music
entertainment
news
blog
blog