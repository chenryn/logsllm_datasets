hardware. 
3. 
Performance Results 
techniques 
using 
Once the evaluation of  SFIO had  been  completed  and 
several key functions had been hardened, we measured the 
performance  of  the  original  and  hardened  versions  and 
compared them to each other, and to STDIO.  To measure 
the performance of the robust  SFIO functions, we used the 
benchmarks  (Table  I )  as described  by  the  authors of  the 
Table 1. Benchmark Descriptions 
52 1 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply. 
tions, but to present  platforms whose OS developers have 
divergent philosophies and goals.  Digital Unix is a propri- 
etary  operating  system  developed  to  provide  maximum 
throughput, and is optimized for a small number of  archi- 
tecturally  similar, advanced processors  with fast IO hard- 
ware.  Linux is an open source OS that runs on a very wide 
range  of  hardware  platforms,  from  Intel  x86  based 
workstations to the IBM Systed390 mainframes.  One side 
effect of  targeting such  a  wide  range of  architectures  for 
Linux is that some performance enhancements can't  be in- 
cluded in the code base due to problems with cross platform 
compatibility.  Further, it can be argued that Linux is most 
commonly  used  as a workstation  OS and as such is opti- 
mized  more  for  latency  and  less  for  raw  throughput. 
Finally, commodity PC hardware  is extremely  cost sensi- 
tive and tends to sacrifice significant bandwidth potential to 
keep costs down.  We hope that by satisfactorily showing 
that the cost of achieving a high degree of YO robustness is 
low on these diverse systems, it is likely  that similar tech- 
niques will work on other systems whose design points fall 
between these two extremes. 
The block IO benchmarks  perform  IO on  large  files  - 
1000 MB  on  the  Linux  platform  and  2000 MB  on  the 
AlphaServer.  Byte IO benchmarks use a 256 MB file and 
2000 MB on the Linux  and Alpha systems respectively. 
The  seek  benchmarks  performed  125,00O(Linux)  or 
250,00O(Alpha)  seek + read  + write  operations,  totaling 
1000 MB or 2000 MB respectively.  These  are  in  some 
cases a few orders of  magnitude greater than the original 
SFIO benchmarks published in  1990 because original sizes 
completed too quickly for accurate measurement. 
In  order to avoid  large penalties  for exception  context 
initialization  and  checking  each  time  through  a  tight  IO 
loop, we applied a variation of optimistic incremental spe- 
cialization [ 131.  We cached the most recent set of checks, 
and tested to see if  the current data set  was recently  vali- 
dated  for  a call that  was  non-destructive  to its value.  In 
such (1 case, we allowed  program execution to bypass the 
exceptional condition checks. 
Table  2  gives complete  user  and  system  level  perfor- 
mance data  for the original SFIO and the final robust SFIO 
with incremental specialization . Total process time is bro- 
ken  clown  into the  user  and  system  components  as mea- 
sured by libc function call time(). 
4.  Analysis 
It should be no surprise that the performance data clearly 
show  that the  common operations  selected for additional 
hardening  are  IO  bound.  This  is  typical  in  a  modem 
super-scalar machine where the CPU can be IO bound even 
on simple memory requests.  Although there is much work 
being done to improve this [5], it seems unlikely  that the 1 0  
speed will catch up to the speed of the processing unit in the 
near to mid-term future.  Thus, hardening of  IO functions 
can  be  accomplished  basically  for  free  on  latency-based 
computational tasks. 
In particular, although file I/O operations are state rich 
and require much error checking and handling, the latency 
added for increasing  the ability of the functions to handle 
exceptions and behave in a robust manner is mostly hidden 
by the latency of the overall operations.  Block file opera- 
File sizes 2x-8x  larger for the axp (ALPHA) system 
Elapsed Tirne 
3000  1 
2500 
2000 
d 
1500 
$ 
c 
'  500 
.- 
E 
1000 
I 
0~86-STDl0 
Clx86-0riginal SFlO 
SFlO 
O x 8 6 - R o b ~ t  
Baxp-STDIO 
,  SFlO 
SFlO 
0 
Figure 3. Benchmark Execution Time in Seconds - Programs from [9] 
522 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply. 
tions suffer an execution time penalty of only a few percent 
compared with the less robust implementations. 
Though  the elapsed time  for the benchmarks to run  to 
completion tell part of  the story, it isn't  enough to simply 
look at this data.  Elapsed time hides the intricacies of what 
is going on inside the OS and hardware that can be critical 
to the performance  of  a system.  After all, the time spent 
during IO wait can be used to perform other useful work in 
a multi-tasking system. 
Figure 4 shows the total time spent performing compu- 
tation (i.e., usr+sys time but not IO wait time) of the hard- 
ened SFIO is in some cases less than that  of  STDIO, and 
except  for  the  757  block  size  and  copy  benchmarks  is 
within  2%  of  STDIO on Linux.  Both  SFIO implementa- 
tions  used  much  less  actual  processing  time  than  did 
STDIO  on  the  Alphaserver  platform  (except  seekrw, 
copyrw,  revrd757  and  read757)  though  the  elapsed  time 
tended to be close to or slower than STDIO.  This seems to 
indicate  that  the  Digital  Unix  STDIO libraries perform  a 
fair amount of processing to optimize the disk transfers, and 
is bom out by the fact that the benchmarks spend less time 
in IO wait when using the STDIO libraries.  From this one 
can  infer that  disk  transfer scheduling  optimizations con- 
sume  far  more  CPU  cycles  than  increased  robustness 
checks. 
The processing time penalty paid by robust SFIO com- 
pared to original SFIO consists largely of occasional excep- 
tion  handling  context  setup  and  parameter  checks. 
In 
addition to this penalty, there is a mandatory penalty  that 
represents the check to determine if the validation must be 
done.  However, we expect the  processing  cost  for  such 
checks to diminish significantly in the near future. 
Of the penalties incurred, the penalty for determining if 
validation  should occur is likely  to be  almost  completely 
negated by improved hardware branch prediction that  will 
be  available  in  new  processors  soon, though  fragmenting 
block size with  a branch can still affect performance[l6]. 
Actually  achieving this  requires  creating  a  compiler  that 
can structure exception-checking code sequences in a way 
that will help the CPU predict  that exceptions will not oc- 
cur. 
Processors that use a trace cache[l6], such as the Intel 
Pentium  4 processor,  will  lessen  the  cost  of  additional 
checks by allowing the unit to fetch past branches that may 
otherwise throttle fetch bandwidth.  While more advanced 
checking  and  caching  techniques  might  degrade  perfor- 
mance in ways the trace cache can not  help (such as multi 
branch  direction traces), we anticipate techniques to solve 
such  problems  will  be  incorporated  in  processors  in  the 
near future.  These  include such techniques as completion 
time multiple branch prediction  [ 141 and block caches [2]. 
In  general  it  seems  reasonable  to  expect  that  exception 
checking branches,  which are easily predictable  as taking 
the  non-exceptional  code  path,  will  become  increasingly 
efficient as processors incorporate more predictive execu- 
tion capabilities. 
Thus, robust SFIO libraries can achieve dramatically re- 
duced robustness  vulnerabilities compared to STDIO and 
even  original  SFIO implementations.  For  latency-bound 
applications the performance impact of providing extra ro- 
bustness  is minimal.  For  throughput  bound  applications 
there can be a moderate increase in CPU time used to per- 
form extra checking for some routines, but this can be mini- 
mized by caching check results.  Furthermore, it  is likely 
that  as CPUs increase their use of concurrency  and branch 
prediction  that  any speed penalties for performing  excep- 
tion checking will decrease dramatically over time. 
Processing Time  (usr+sys) 
0x86-Robust Sfio 
DAW-STDIO 
300 
250 
200 
J  150 
100 
50 
U) 
0 
Figure 4;  Processing Time 
523 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply. 
5. 
Conclusions 
We used  the  Ballista robustness testing  tool  to find ro- 
bustness problems in the SafeEast I/O library (SFIO), and 
fou’nd that  we were  able to improve the robustness of the 
code by  an  average factor of  5.9 across the  treated  func- 
tions, despite the  fact that  SFIO already  improves. robust- 
ness over STDIO robustness by an order of magnitude. The 
achieved robuslness level, was approximately 0% to 2% ro- 
bustness failure rates, compared to 0% to 79% failure rates 
for STDIO. We have found that the remaining failures gen- 
erally  involve  incorrect  or  corrupt  data  within  otherwise 
valid data structures, but speculate that such failures might 
be dealt better with during interface design. 
Contrary to commonly  held  opinion, very  robust soft- 
ware need not  come at the price  of reduced performance. 
The data show that the performance penalty  for providing 
thorough exception handling and error handling tends to be 
low in terms of elapsed time, and similarly small in terms of 
processing  overhead.  Robust  SFIO was  only  -0%-15% 
(avg. of 2%)  slower than ordinary SFIO, while providing 
better robustness. Furthermore, near-term architectural  im- 
provements  in  processors  will  tend  to reduce the  costs of 
providing robust exception handling by exploiting the fact 
that exception checks can be readily predicted and executed 
concurrently with mainstream computations. 
6.  Acknowledgments 
This work  funded  in  part  by  DARPA under  contract 
DABT 63-96-C-0064 (the Ballista project),  and a fellow- 
ship from IBM Corporation.  Intel  based  systems used  in 
the  research  were  provided by  an  equipment grant  from 
Intel Corporation. 
7.  References 
[I] Austin, T.M.; Breach, SE.; Sohi, G.S., “Efficient detection 
of all pointer and array access errors,” Con$  on 
Programming Language Design and Implementation 
(PLDI) ACM SIGPLAN ‘94 
[2] Bryan Black, Bohuslav Rychlik and John Paul Shen, “The 
block-based trace cache,” Proceedings of the 26th annual 
Intl. Symp. on Computer Architecture 
[3] Carreira, J.; Madeira, H.; Silva, J.G., “Xception: a technique 
for the experimental evaluation of dependability in modem 
computers,” IEEE Trans. on Software Engineering, ~01.24, 
110.2 p.  125-36 
[4] Fmnsler, K.; Koopman; P., “Robustness testing of a 
distributed simulation backplane,” Proc. 10th Intl. Symp.on 
:$oftware Reliability Engineering ISRE 1999 
[5] Griffin, J.L.; Schlosser, S.W.; Ganger, G.R.; Nagle, E.F., 
“Modeling and performance of  MEMS-based storage 
devices,” Intl. Con$  on Measurement and Modeling of 
Computer Systems ACM SIGMETRICS ‘2000 
[6] Hastings, R.; Joyce, B., “Purify: fast detection of memory 
leaks and access errors,’’ Proceedings of the Winter 1992 
USENIX Con$ 
[7] Koopman, P.: DeVale, J., “Comparing the robustness of 
POSIX operating systems,” Tbventy-Ninth Annual Intl. 
.Symp.on Fault-Tolerant Computing 
[8] Koopman, P.; DeVale, J., “The exception handling 
effectiveness of POSIX operating systems,” IEEE Trans. 
,on Software Engineering, vo1.26,no.9 p. 837-48 
[9] Kom, D.G.; Vo, K.-P., “SFIO: safelfast stringlfile IO,” 
.Proceedings of the Summer 1991 USENIX Con$ 
[IO]  Kropp, N.P.; Koopman, P.J.; Siewiorek, D.P., “Automated 
robustness testing of off-the-shelf software components,” 
Twenty-Eighth Annual 1ntl.Sytnp. on Fault-Tolerant 
Computing FTCS 1998 
[I I] Lee, P.A., “Exception Handling in C Programs,” Software 
.Practice and Experience. Vol  13, 1983 
[I 21 Maxion, R.A.; Olszewski, R.T., “Improving software 
robustness with dependability cases,’’ Twenty-Eighth 
.4nnua~Intl.Symp. on Fault-Tolerant Computing 
[I31 I%,  C.; Autrey, T.; Black, A.; Consel, C.; Cowan, C.; 
[nouye, J.; Kethana, L.; Walpole, J.: Ke Zhang, “Optimistic 
incremental specialization: streamlining a commercial 
,operating system,” Proceedings of  the fifteenth ACM Symp. 
,on Operating systems principles, SIGOPS 1995 
[ 141 Ryan Rakvic, Bryan Black and John Paul Shen, 
“Completion time multiple branch prediction for enhancing 
trace cache performance,” The 27th Annual IntlSymp. on 
Computer architecture ISCA 2000 
[ 151 Isheiton, C.P.; Koopman, P.: Devale, K., “Robustness 
testing of the Microsoft Win32 API,” Proceedings of the 
Intl. Con$  on Dependable Systems and Networks. DSN 
2000 
[I61 13ric Rotenberg, Steve Bennett and James E. Smith, “Trace 
cache: a low latency approach to high bandwidth 
instruction fetching,” Proceedings ofthe 29th annual 
IEEE/ACM  1ntl.Symp. on Computer Architecture ISCA 
1996 
[17] ‘Wilken, K.D.; Kong, T., “Efficient memory access 
checking,” The Twenty-Third 1ntl.Symp. on Fault-Tolerant 
Computing  FTCS-23 
[18] ‘Wilken, K.D.: Kong, T., “Concurrent detection of software 
and hardware data-access faults,” IEEE Trans. on 
Computers, ~01.46, no.4 p. 412-24 
524 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:15 UTC from IEEE Xplore.  Restrictions apply.