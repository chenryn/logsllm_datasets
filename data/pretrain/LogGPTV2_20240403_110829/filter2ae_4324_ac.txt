我想知道我收藏的这些输入文件是从哪里来的。触发该问题的几个BPG文件就是我以前给[libbpg](https://bellard.org/bpg/)做fuzzing测试用的，因此它们是由AFL在为本地库创建BPG文件时产生的。触发另一个问题的chm文件是我在Fuzzing项目中很久之前从
[fuzzing project](https://crashes.fuzzing-project.org/chmlib-heapoverflow-_chm_skip_cword.chm)下载的一个文件。这个文件是Hanno Böck提供的，用来为
[CHMLib](https://github.com/jedwing/CHMLib)进行Fuzz测试。
至此，在没开始正式Fuzzing之前，我就已经在Apache Commons里面发现了一个未捕获的异常和Apache Tika中的两个低级别的安全问题。
为了找到引起问题的Java类，我用一个调试器和触发文件运行ApacheTika，在死循环中停止执行，并打印堆栈跟踪。但是，找到这些问题根因的最难的工作是维护人员来完成的，最重要的是Tim
Allison和ApacheTika团队。对于所有即将到来的问题也是如此。
## 使用Kelinci来Fuzzing Apache Tika
在整理出导致挂起的输入文件后，我启动了几个afl-fuzz的Fuzzing实例并等待。Kelinci
fuzzer的行为有时有点脆弱，所以我经常得到“队列满”错误信息。这意味着Fuzz不能正常运行，并且会出现超时。我不得不多次重新启动Fuzz实例，并尝试调整命令行设置以提高稳定性。然而，随着时间的推移，实例经常会重新填充队列。不过，有几个实例运行得很好，发现了几个“AFL崩溃”。记住，在这种情况下，“AFL崩溃”只是意味着未捕获的Java异常。在检查并消除问题后，我向Apache
Tika使用的库的维护人员报告了以下非安全（或非常低的严重程度、定义问题）的问题：
  * [Apache PDFBOX解析PDF文件时的两个独立栈溢出的问题](https://issues.apache.org/jira/browse/PDFBOX-4193) (文件 5_uncaught_stackoverflow_checkPagesDictionary.pdf 和 6_uncaught_stackoverflow_getInheritableAttribute.pdf)
  * [Apache common ZipFile解析解压文件中的一个数组边界越界问题](https://issues.apache.org/jira/browse/COMPRESS-447) (文件 7_uncaught_ArrayIndexOutOfBoundsException_1.zip 和 7_uncaught_ArrayIndexOutOfBoundsException_2.zip)
  * [Gagravarr VorbisJava 解析ogg文件的一个IllegalArgumentException问题](https://github.com/Gagravarr/VorbisJava/issues/27) (文件 8_uncaught_IllegalArgumentException_Skeleton.ogv 和 9_uncaught_IllegalArgumentException_ogg_page.ogv)
AFL的挂起目录没有显示任何有趣的结果。在运行ApacheTika的挂起目录中的每一个文件之后，我发现了一个PDF文件，它花费了将近一分钟的时间来处理，但是没有一个文件导致了Tika线程的全部挂起。我怀疑这两个进程的同步是fuzzer没有发现无限挂起的原因之一。
在这个阶段，我最失望的是，没有一个崩溃表明，除了指定的JavaSecurityManager策略，有其他问题被触发。因为我的Kelinci的脆弱配置，可能不是很容易找到任意文件读写问题。但最终，你往往不知道到底是什么原因导致Fuzzing不成功。
## JQF和Java中的一个bug
我还想在我的ARM Fuzz机器上使用Apache Tika进行JQF
Fuzz测试。起初这不起作用，我发现ARM上的[OpenJDK在JQF上表现得很糟糕](https://github.com/rohanpadhye/jqf/issues/20#issuecomment-369656546)，所以我切换到了Oracle
Java。另外，Apache
Tika不会与JQF一起运行。在ApacheTika修复了Tika的1.17问题之后，我认为是时候通知这些Fuzz工具的维护人员了，所以他们可以尝试自己去Fuzz
ApacheTika。Rohan（JQF维护者）[快速修复了三个独立问题，实现了JQF的测试用例/基线](https://github.com/rohanpadhye/jqf/issues/20#issuecomment-386742103)。在那之后，我可以用自己的语料库来fuzz
Tika，但由于各种原因，性能非常糟糕。其中一个原因是arm机器的性能问题。但是[JQF也不能处理超时](https://github.com/rohanpadhye/jqf/issues/26)（AFL的-t开关）。Rohan尝试了修复，但有时没有效果。Rohan也很快实现了[afl-cmin](https://github.com/rohanpadhye/jqf/issues/25),并说运行[Java安全管理器策略](https://github.com/rohanpadhye/jqf/issues/24)应该是没有问题的。但是，由于ARM机器上的性能问题，我不能正确地尝试这些特性。由于我没有心情切换fuzzing机器，我只是想让fuzzer跑起来。在削减了输入语料库和删除所有可能需要Apache
Tika花费更长时间处理的PDF文件之后，Fuzzer缓慢地跑起来了。放在那儿运行十天后，JQF在Apache Tika1.18发现另一个挂起…
…然而，在向ApacheTika提交这个bug后，他们指出这实际上是Java标准库中的一个bug，它影响Java 10 之前的版本，我重新发现了它：
  * [在RiffReader中死循环](https://bugs.openjdk.java.net/browse/JDK-8135160)(file 10_hang.riff),代码根本不会返回。不幸的是，Java/Oracle从来没有为这个问题分配过一个CVE。因此，来自ApacheTika的TimAllison要求他们分配一个，经过三个月的时间和无穷尽的没有实际内容的状态更新邮件，我们仍在等待CVE编号。由于这在Java8中没有修复，所以[Tim Allison也在Apache Tika优化了它。](https://github.com/apache/tika/commit/41bc34ca7e5c7d868755b0adaf992104cabd0c57)
该挂起文件由JQF
Fuzzer通过修改[公共ffmpeg样例中的“fart_3.qcp”](https://samples.libav.org/A-codecs/suite/QCP/fart_3.qcp)创建。因此，在没有主动地针对Java本身的情况下，我重新发现了Java的标准库中的一个bug，因为Tika使用了它。interesing。
## 添加一个x86的fuzzing 机器
同时，我也意识到这些ARM JQF
Fuzz实例卡住了。死循环的RIFF环路文件被检测为崩溃（这可能只是JQF的错误行为），所以我不知道为什么他们现在被卡住了。我试图在另一台机器上运行当前的输入文件，但是用例没有挂起。所以我不知道为什么Fuzz被卡住了，但随着罗汉指出超时处理（AFL的“挂起”）还不完美的。当已装载的代码命中死循环时，JQF将检测超时，因为它将能够计算耗费的时间。但是，如果测试文件使代码循环在未装载代码中，JQF将挂起。我删除了所有的RIFF/QCP输入文件，希望我不会再次发现RIFF死循环错误（我未切换到Java10）并重新启动Fuzz实例。
我决定另外使用一个32bit x86 VMWare fuzzing 机器,也许它会运行更稳定.我用Java8重新设置了JQF
,并且没有RIFF文件作为输入. x86虚拟机性能更好，每秒执行十个用例。所以我让这些实例运行了几天…
…当我回来的时候，两个实例都在运行七个小时后被卡住了。我再次检查是当前输入文件的原因，确实是，所以我发现了另一个bug。清理导致挂起的文件并重新运行,第二天早上发现了另一个bug.所以过了一段时间（至少五次迭代），发现了很多bug：
  * [在Junrar中的一个死循环](https://github.com/junrar/junrar/pull/8)(文件11_hang_junrar_zero_header2.rar)，在rar头大小为零的情况下，代码根本不会返回。我联系了一个维护人员，beothorn。目前已经修复，这个问题最后申请了CVE-2018-12418。
  * [ApacheTika IptcAnparser的死循环] (
  * [Apache PDFbox的adabe字体指标解析器死循环](https://mail-archives.apache.org/mod_mbox/www-announce/201806.mbox/%PI:EMAIL%3e) (文件16_570s_fontbox_OOM.afm)在循环近十分钟(在我的机器上)后导致内存不足。已经被修复，并分配了CVE-2018-8036。
  * [使用Apache Commons Compress阅读特殊构造的zip内容时的问题](https://lists.apache.org/thread.html/3f01b7315c83156875741faa56263adaf104233c6b7028092896a62c@%3Cdev.commons.apache.org%3E)(文件14_69s_tagsoup_HTMLScanner_oom.zip)导致内存异常的问题。[Apache Commons Compress中修复了](https://github.com/apache/commons-compress/commit/a41ce6892cb0590b2e658704434ac0dbcb6834c8)，分配CVE-2018-11771。另一个创建的zip文件（file 15_680s_commons_IOE_push_back_buffer_full.zip）运行了十一分钟（在我的机器上），导致IOException。并出现了一个提示：“the push back buffer is full”，可能与这个问题有关。可能是同样的问题，Tika在处理一个zip文件（文件13_48s_commons_truncated_zip_entry3.zip）时需要花费一定时间（在20秒到十一分钟之间）。最后一个问题值得注意，因为JQF正确地检测到这是一个挂起，并将它放在AFL的挂起目录。CVE-2018-11771的底层问题是，当InputStreamReader用UTF-16调用时，读操作开始返回-1和345的交替值。重现的最小代码是： 
        @Test
    public void testMarkResetLoop() throws Exception {
      InputStream is = Files.newInputStream(Paths.get("C:/14_69s_tagsoup_HTMLScanner_oom.zip"));
      ZipArchiveInputStream archive = new ZipArchiveInputStream(is);
      ZipArchiveEntry entry = archive.getNextZipEntry();
      while (entry != null) {
          if (entry.getName().contains("one*line-with-eol.txt")) {
              Reader r = new InputStreamReader(archive, StandardCharsets.UTF_16LE);
              int i = r.read();
              int cnt = 0;
              while (i != -1) {
                  if (cnt++ > 100000) {
                      throw new RuntimeException("Infinite loop detected...");
                  }
                  i = r.read();
              }
          }
          entry = archive.getNextZipEntry();
      }
    }
在所有这些修复之后，我在后来的Apache Tika 1.19上再次运行Fuzz，它在十天内没有发现任何新的问题。所以我的fuzzing
Tika的方法似乎已经凉了。与往常一样，这并不意味着其他方法不会发现新的问题。
## 总结
Java的Fuzzing之旅至此为止了。我有点失望的是，JavaSecurityManager的方法没有发现任何像SSRF之类的安全问题，并且我只发现了资源管理问题。然而，我坚信这个策略前途仍然是光明的，它可能只需要换其他的目标。正如你所看到的，到处都是坑，我正计划继续Fuzzing
Java：
  * 用其他ApacheCommons解析器使用Kelinci/JQF，如PNG
  * 编写原生代码AFL的文件或打开socket消等消毒器
  * 为基于AFL的JavaFuzz工具做一些贡献
然而，还有其他的一些个人事情要去完成。
我要感谢ApacheTika项目的TimAllison，很高兴能与他合作。非常感谢Rohan Padhye，他真的很快实现了JQF的新特性。
请确保将 
中包含的文件添加到您的输入语料库集合中，因为当我们测试一个新的库时如果有其他库的crash记录是非常棒的。