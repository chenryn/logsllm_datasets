# Community Epidemic Detection Using Time-Correlated Anomalies

## 6.2 Detection Performance
We first examine Syzygy's ability to detect epidemics for various community sizes and infected populations. Figure 12 shows the performance of Syzygy in a fixed-size community as the number of infected clients increases. The system's performance improves with the size of the infection, reaching its peak when approximately 10% of the community is infected (about 10 clients in this experiment). However, as shown in Figure 13, with a sufficiently large community, even a very small fraction of the population can be detected before the exploit spreads widely. Although both the community and the infected population are growing at the same rate, Syzygy's detection capability outpaces this growth.

## 6.3 Parameter Sensitivity
Next, we evaluate Syzygy's sensitivity to the threshold \( V \). Figure 14 illustrates the performance for different values of \( V \). As the community and infected population grow, the performance curve reaches a maximum between \( V = \mu_X \) and \( V = \mu_Y \). Increasing the multiplier tends to increase precision, decrease recall, and reduce the false positive rate, which decreases exponentially like the tail of a normal distribution. Figure 15 further visualizes this, showing that as the number of clients increases, the normal and infected distributions become more clearly separated. This increasing margin of separation suggests that the exact placement of the threshold does not significantly affect Syzygy's performance. In the limit, any threshold \( \mu_X < V < \mu_Y \) will yield perfect detection.

## 6.4 Client Variation
We expect client machines to differ in specifications and configurations, and these may change over time. To test this, we ran the same applications on a secondary system (System B) with different specifications: an Apple PowerBook G4 with a single 1.33 GHz PowerPC processor and 1.25 GB of memory running Mac OS X 10.5.4. The data from these tests are summarized in Table 3. Figure 16 compares the anomaly scores from System B against those from the primary test machine (System A) and the screenshot exploit. Although System B's average score is higher by a factor \( \Delta \) (since its model is based on another system), the programs behave similarly enough that unusual but healthy clients are not easily confused with exploits.

However, as the community grows, System B begins to look like an exploit. The variance of the healthy community score distribution, \( \sigma_H \), shrinks, causing \( V \) to move closer to \( \mu_X \) and eventually fall below System B's average anomaly score. This issue can be resolved by using a model constructed from System B's behavior or by normalizing the anomaly scores from System B as described in Section 3.2. In practice, such a situation might arise if a client upgrades the application but does not retrain the model. If a client's anomaly signal remains high for extended periods, it may indicate that the model is no longer valid. Only when many clients make such changes would we expect spurious epidemic reports. Additional results related to client variation in Section 5 suggest that heterogeneity is not a significant problem in practice.

## 6.5 Mimicry and Tainting
An exploit can avoid detection if its behavior is sufficiently similar to the application's, from the perspective of a given model [38]. There are two ways an exploit might mimic application behavior: (i) by ensuring that the distribution of anomaly scores is sufficiently similar, or (ii) by limiting the rate at which it exhibits bad behavior. Perfect mimicry, where exploit behavior is indistinguishable from application behavior, cannot be detected by any behavior-based epidemic detector. However, Syzygy is robust against a high degree of mimicry and against rate-limited attacks.

Scenario (i), mimicking the distribution, is quantified in Syzygy by the parameter \( \delta \). A lower value for \( \delta \) indicates that the two distributions are more similar. 

---

**Figures and Tables:**

- **Figure 13:** F1 measure with varying community size and constant fraction \( f = d/n \) infected, using TextEdit and prompttext.
- **Figure 14:** F1 measure with \( n = 100 \) and varying threshold multiplier using traces from Mail and the mailspam exploit.
- **Figure 15:** Anomaly signal density estimates for TextEdit and the prompttext exploit. The left plot shows no ideal position on the x-axis to set a threshold. The right plot shows that averaging scores across multiple clients yields a clearer separation.
- **Figure 16:** Similar to Figure 15, using the Adium program and providing data for both the primary system (System A) and the laptop (System B).
- **Table 3:** Data from OS X apps on a different client. The Unique column indicates the number of unique length-six sequences, and \( T_i \) is the maximum time from the beginning of one system call to the start of the next. The \( \Delta \) column shows the empirically estimated average difference between anomaly scores on Systems A and B.

---

This revised text provides a clear and professional overview of the sections, figures, and tables, ensuring that the content is well-organized and easy to understand.