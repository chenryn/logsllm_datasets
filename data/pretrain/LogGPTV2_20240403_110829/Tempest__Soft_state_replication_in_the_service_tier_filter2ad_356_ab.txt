platform configuration on a single computer and might run
several services. A service instance stores data in one or
more TempestCollections. Multiple instances of a service
execute across different servers, and invocations to a ser(cid:173)
vice are sent by first-tier front-ends to all the service in(cid:173)
stances. Figure 2 depicts a front end initiating a multicast to
the servers containing replicas of the same service instance.
The life-cycle of a Tempest invocation begins when a
client sends a request to the datacenter, which gets load bal(cid:173)
anced to a web-facing front-end node. The front-end is then
responsible for contacting a set of services and aggregat(cid:173)
ing individual service responses into a composite result that
it returns to the client. Front-ends use IP multicast (there
is a distinct IP multicast group for each replicated Tempest
service) to perform web-service invocations on service in(cid:173)
stances, allowing very rapid communication in the general
case. When multicast pac ets are dropped, gossip-based
point-to-point (typically UDP) reconciliation is used to re(cid:173)
pair gaps and errors in the TempestCollections maintained
by the different service instances of the same service.
3.1 Client Invocations
When a client request enters the datacenter at a front-end
it's tagged with a web service invocation identifier (wsiid)
consisting of a tuple containing the front-end node identifier
1-4244-2398-9/08/$20.00 ©2008 IEEE
229
DSN 2008: Marian et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:40 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
and sequence number. Front-end node identifiers are ob(cid:173)
tained by applying the SHAI consistent hash function over
the front-end's IP address and port pair. Each Tempest re(cid:173)
quest is thus uniquely identified by its wsiid.
As mentioned previously, Tempest differentiates be(cid:173)
tween updates and queries or reads. For updates, Tempest
uses IP multicast to send the operation directly to the full
set of Tempest servers that hold replicas of the service for
which the requests were intended. A hashing mechanism is
employed to determine which server instance is responsible
for replying. In the absence of message loss, the common
case, IP multicast within datacenters is reliable and ordered.
For read requests, front-ends use an adaptive querying
mechanism. Each front-end periodically multicasts a bea(cid:173)
con to each service and waits for unicast responses from
each instance. It selects the k instances that respond first (cid:173)
where k is the redundant querying parameter -
and subse(cid:173)
quently directs service read invocations to these instances.
3.2 The Tempest Gossip Mechanism
Tempest is designed under the assumption that the mul(cid:173)
ticast protocol used might not be fully reliable or might re(cid:173)
cover lost pac ets at high latencies. If some replicas miss an
update, they can become inconsistent. Tempest uses a gos(cid:173)
sip protocol to repair these inds of inconsistencies rapidly.
Servers use a custom tailored gossip protocol to reconcile
differences between the TempestCollection replicas.
Tempest eeps trac of all the operations performed at
the data structure boundary -
this is possible due to our
by-value semantics of altering the collections. When an ob(cid:173)
ject is added to a collection, it is annotated with the web
service invocation identifier of the corresponding invoca(cid:173)
tion; when an object is removed from a collection, a death
certificate for it is created and annotated with the wsiid. A
death certificate is simply a means of retaining the informa(cid:173)
tion necessary to identify which objects were removed from
a collection. In particular each TempestCollection eeps a
history of the removed objects in an internal private data
structure not exposed via the standard interface.
The anti-entropy mechanism wor s by having each
server "gossip about" the sets of web service invocation
identifiers (wsiids) that annotated objects in TempestCol(cid:173)
lections. Suppose for example that during one gossip round
we have two service replicas rl and r2 respectively engaged
in an exchange; let their sets of wsiids be denoted by w(rl)
and w(r2). If w(rl) = w(r2) no action is ta en, otherwise
some invocations were missed by one (or both) and a "rec(cid:173)
onciliation" phase is triggered:
• If w (rl ) C w (r2) then rl missed invocations and
holds a stale version of the state - as a result rl re(cid:173)
trieves from r2 the objects and death certificates an(cid:173)
notated with the wsiids from the set w (r2) \ w (rl ).
Objects referred by the death certificates are removed,
newly received objects are added; also rl's set of wsi(cid:173)
ids is updated accordingly: w(rl) ~ w(r2).
• If w(rl) ct w(r2) and Iw(rl)1 =I
Iw(r2)1 (the sets
have different cardinality) both replicas have missed
at least one update each, therefore to rna e progress
it is safe for any of the replicas to assume the other
replica's state - without violating the "eventual con(cid:173)
sistency" guarantees offered by the system. Choose
the replica that has the smaller w set -let it be rl with(cid:173)
out loss of generality; rl performs the following steps:
- For every identifier i in the set w (rl) \ w (r2),
if i annotates an object then the object is dis(cid:173)
carded, otherwise if i annotates a death certifi(cid:173)
cate the object referred by the death certificate is
"resurrected" (added bac to the collection).
- Fetch from r2 all objects and death certificates
annotated with identifiers from the set w (r2) \
w (rl ). Remove objects referred by the death
certificates, add the new objects, and update
w (rl) ~ w (r2). Here we used the heuristic of
discarding the state of the replica that received
less invocations, however one can imagine other
criteria.
• If w(rl) ct w(r2) and Iw(rl)1 = Iw(r2)1 then the ini(cid:173)
tiator of the gossip round between rl and r2 "plays the
role" of the replica with the smaller wand performs
the same operations as in the previous case.
An upcall is provided such that the service developer us(cid:173)
ing TempestCollections is notified when a gossip reconcili(cid:173)
ation was triggered.
If no new invocations are issued against the system, and
if no permanent networ partition that splits the servers
into two or more disjoint communication parties occurs the
TempestCollection replicas will eventually contain identical
elements with probability 1 [11].
During a gossip round, there can never be more than
3 messages issued per process (by protocol design). Cur(cid:173)
rently the sets of web service identifiers are monotonically
increasing as new invocations are issued, therefore gossip
messages si e increases with time. We are wor ing on a
method for garbage collecting the stale wsiids by append(cid:173)
ing an epoch number at wsiid generation time -
tempest
servers will discard wsiids that are more than 8 epochs old
for some choice of parameter 8. Another option is to use
efficient set reconciliation methods like the ones in [27, 5].
The strength of gossip protocols lies in their simplicity,
the fact that they are robust (there are exponentially many
paths information can travel in between two endpoints), and
the ease with which they can be tuned to trade speed of
1-4244-2398-9/08/$20.00 ©2008 IEEE
230
DSN 2008: Marian et at.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:40 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
delivery against resource consumption. The Tempest epi(cid:173)
demic protocols evolved out of our previous wor on sim(cid:173)
ple primitive mechanisms that enable scalable services ar(cid:173)
chitectures in the context of large-scale data-centers [26].
3.2.1 TempestCollections Update Order Sensitivity
The gossip protocol described above requires that opera(cid:173)
tions against TempestCollections be commutative, or order
insensitive - which is the expected common case for most
soft state applications [10]. The framewor cannot support
data structures that inherently depend on the order of oper(cid:173)
ations - e.g. lists, stac s or queues.
Since this is a limitation developers may find hard to
accept, we provided Tempest with a variant of the gossip
protocol that uses for each TempestCollection ordered lists
instead of sets of web service invocation identifiers. The
protocol description is roughly identical with the one pre(cid:173)
sented above with a few minor differences. Set inclusion
tests are replaced with list prefix matching, and reconcili(cid:173)
ation between replicas is more elaborate - however due to
space limitations we omit a more in depth description.
3.3 Membership and Failure Detection
In addition,
Membership in Tempest is handled by the Group Mem(cid:173)
bership Service (GMS), which maintains the mapping be(cid:173)
tween servers and service replicas.
it also
acts as a UDDI (Universal Description Discovery and In(cid:173)
tegration) registry providing appropriate WSDL (Web Ser(cid:173)
vices Description Language) descriptions for the services
deployed on Tempest servers -
consequently it provides
the appropriate mapping between a service identifier and
the corresponding IP multicast group. The GMS also fills
the administrator role for Tempest servers, monitoring the
overall stress and spawning new servers to match the load
imposed on the system. Finally, it monitors components to
detect failures and adapt the configuration.
Tempest assumes that processes fail by crashing and can
be reliably detected as faulty by timeout. Accordingly, Tem(cid:173)
pest processes monitor the peers with which they interact
using a secondary gossip-based heartbeat mechanism. Pro(cid:173)
cesses that are thought to be deceased are reported to the
GMS, which waits for f distinct suspicions before actu(cid:173)
ally declaring it deceased.
It then updates and dissemi(cid:173)
nates group membership information to all interested par(cid:173)
ties. While in our experiments the GMS is hosted on a
single high-end node, in a datacenter it could potentially
be replicated and partitioned across multiple machines for
scalability and fault-tolerance.
_n Front-ends
a~····]··.
"~•....1
r·
·1
:...... ~
~.:
Figure 3. Baseline configurations.
3.4 Node Recovery and Checkpointing
TempestCollections are automatically chec pointed. Pe(cid:173)
riodically, each Tempest server batches the items in each
TempestCollection and writes them atomically to dis us(cid:173)
ing a copy-on-write technique. When a node crashes and
reboots, upon starting the Tempest server, the services are
brought up to date with the state that was last written to dis
before the crash.
When a server is newly spawned, or when a server that
has been unavailable for a period of time missed many up(cid:173)
dates, Tempest employs a bul
transfer mechanism to bring
the server up to date. In such cases, a source server is se(cid:173)
lected and the contents of the relevant TempestCollections
are transmitted over a TCP connection. When multiple
services are collocated in a single server, the transfers are
batched and sent over a single shared TCP stream.
Newly spawned services and services that rebooted after
a crash will consequently "catch up" gracefully with the rest
of the service replicas by means of the epidemic protocols.
4 Experimental Evaluation
Tempest was implemented in Java, adding new transport
protocols to the Apache Axis Soap [36] web services stac ,
Le. SOAP over TempestTransport instead of SOAP over
HTTP. The deep cloning capability was implemented using
the Java Reflection API. The system components are built
with Java's non-bloc ing I/O primitives.
The evaluation is structured as follows: in subsection 4.1
we show that a single replicated Tempest service can pro(cid:173)
vide rapid response to large numbers of concurrent front(cid:173)
end requests.
In subsection 4.2 we show that this is true
even when services are heavily loaded. Finally, in subsec(cid:173)
tion 4.3, we show that the two nobs provided by Tempest
- number of replicas per service and number of redundant
queries -
enable rapid predictable response for "service(cid:173)
clouds" composed of many collaborating services with dif(cid:173)
fering timing characteristics.
1-4244-2398-9/08/$20.00 ©2008 IEEE
231
DSN 2008: Marian et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:40 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
4.1 Micro bechmarks
First we ran a set of micro benchmar s to compare Tem(cid:173)
pest against four multi-tier baseline scenarios. The experi(cid:173)
ments were run on the Cornell cluster - a pool of 252 ma(cid:173)
chines, each a 1.33GH Intel single CPU blade-server with
512MB of RAM and 100Mbps ethernet interfaces and 3
higher end servers each a single 2.8GH CPU with 1GB
of RAM and 3 IGbps ethernet interfaces. Nodes are con(cid:173)
nected through a mesh of 100Mbps/1Gbps switches (HP
ProCurve J4121A 4000m and J4902A 6108).
In all con(cid:173)
figurations we had the same set of front-ends interacting
with the ShoppingCart web service deployed on the high
end servers. We deployed the service on top of the Apache
Tomcat server. The service stores the data using various re(cid:173)
lational database repositories as shown in Figure 3. In one
configuration we stored the data using the Oracle TimesTen
in memory database co-located with the Tomcat server. In
the second configuration TimesTen resided on a remote
third-tier machine and lastly deployed in a primary-bac up
configuration with the primary co-located with the Tomcat
container and the bac up on the third-tier machine.
In all configurations TimesTen worked in "high per(cid:173)
formance cache-mode" for in-memory operations only,
thereby offering ACI guarantees instead of full ACID (cid:173)
without committing durably to dis . The primary-bac up
scheme provided by TimesTen that we used is called return
receipt, and it ensures that upon submitting a request to the
master the client application is bloc ed until the replication
scheme on the master received an ac nowledgment that the
update has been received by the bac up server.
We also use an ubiquitous on-dis database engine, and
for that purpose we relied on MySQL 5.0 with the InnoDB
storage engine configured for ACID compliance -
flush(cid:173)
ing the log after every transaction commit, and the under(cid:173)
lying operating system (Linux 2.6.15) with the file system
mounted in synchronous mode and with barriers enabled.
Similarly, we have deployed the ShoppingCart service on
3 replicated Tempest servers gossiping at a rate of once ev(cid:173)
ery 100 milliseconds - we did not replicate Tomcat for
load balancing since Tempest replicas were configured to
receive all updates. The Tempest ShoppingCart service
stores the data inside a TempestMap.
The wor load applied consists of multiple clients issuing
small 1024-byte requests against the ShoppingCart ser(cid:173)