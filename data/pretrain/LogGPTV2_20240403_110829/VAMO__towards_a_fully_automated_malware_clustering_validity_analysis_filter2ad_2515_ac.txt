among the shortest paths in the AV Label Graph between all paris
of labels lk, lh, with lk ∈ Li and lh ∈ Lj. This allows us to
compute an r × r distance matrix D, where r = |M| and ele-
ment D[i, j] is the distance between samples mi, mj. The ﬁnal
reference clustering is obtained by applying average-linkage hier-
archical clustering [9, 10] on the distance matrix D. The result
is not an actual partitioning of the malware dataset M. Rather,
the reference clustering is represented by a dendrogram [9], i.e.,
a tree-like data structure that expresses the “relationship” between
malware samples. Cutting this dendrogram at any particular height
would produce a partitioning of M according to the AV label-based
distances (see Section 5 for details).
Validity Analysis Let T be the reference clustering dendro-
gram output by the previous step. The Validity Analysis module
takes in input T and the set of malware clusters C output by the
third-party malware clustering system. At this point, VAMO ap-
plies the external validity indexes introduced in Section 3 to com-
pute the maximum level of agreement between C and all possible
reference clusterings obtained by cutting T at different heights. For
example, we can compute the maximum Jaccard coefﬁcient ˆJ be-
tween all possible reference clusterings and C. The higher ˆJ, the
stronger the agreement between C and the AV label-based refer-
ence clustering.
Effectively, VAMO compares the third-party clustering results C
to a reference clustering obtained by partitioning the dataset M ac-
cording to the relationships among multiple AV labels learned from
the archive malware dataset A. It is worth noting that this process
has some similarities with the majority voting-based approach used
in previous work. In fact, the effect of the majority voting approach
is to group a subset of the malware in M according to the labels as-
signed by multiple AVs to the samples in the very same M dataset.
VAMO is different because (a) it automatically learns the relation-
ships among malware family labels assigned by different AVs, and
does not require any manual (or semi-manual) mapping between
them; (b) it introduces a measure of label-based distance between
malware samples that is not limited to the cases in which a ma-
jority voting-based consensus can be achieved; (c) it enables the
computation of well known external validity indexes over the en-
tirety of malware clustering results, rather than focusing only on
“easy-to-cluster” subset of the malware dataset. In Section 6.1 we
empirically show that building a reference clustering based on the
AV Label Graph and applying the validity analysis process outlined
above outperforms the majority voting-based cluster validation ap-
proach proposed in previous work.
5. VALIDITY ANALYSIS
In this Section, we provide more details on how VAMO builds
the reference clustering by leveraging multiple AV labels, and how
the clustering validity indexes are computed to compare third-party
malware clustering results to VAMO’s reference clustering.
5.1 Building a Reference Clustering
As mentioned in Section 4, the ﬁrst step to obtaining the ref-
erence clustering is to build an AV Labels Graph. This graph ex-
presses the “relationships” between different AV labels, and auto-
matically learns the likelihood that different labels from different
AVs will be assigned to the same malware sample, based on historic
observations.
Assume M is the malware dataset used as input to a third-party
(e.g., behavior-based) malware clustering system, as shown in Fig-
A_WORM/Korgo
0 . 9 5 5
T_PE_VIRUT
0 . 6 8 2
0 . 9 5 7
A_TR/Drop
0 . 1 3
0 . 6 9 6
0 . 3 6 4
M_W32/Virut
0 . 9 5 5
0 . 8 7
0 . 9 5 5
0 . 3 4 8
T_PE_VIRUX
0 . 8 2 4
A_W32/Virut
0 . 9 4 1
0 . 9 4 1
M _ u n k n o w n 1
M _ u n k n o w n 2
Figure 2: AV Label Graph for Clust.1 (see Section 3.1)
ure 1. Also, let A be a large historic malware archive contain-
ing, for example, malware samples collected during the past several
months, and that M ⊂A (i.e., A contains all the “current” samples
collected in M, plus a large set of malware samples collected in the
past). We deﬁne an AV Label Graph learned from A as follows.
DEFINITION 1. - AV Label Graph. An AV Label Graph is an
undirected weighted graph. Given an archive of n malware sam-
ples A = {mi}i=1..n, let L = {L1 = (l1, .., lν)1, .., Ln =
(l1, .., lν)n} be a set of label vectors, where a label vector Lh =
(l1, .., lν)h is an ordered set of malware family labels assigned by
ν different AV scanners to malware mh ∈A . The AV Label Graph
G = {Vk, Ek1,k2}k=1..l is constructed by adding a node Vk for
each distinct label lk ∈L . Two nodes Vk1 and Vk2 are connected
by a weighted edge Ek1,k2 if the labels lk1 and lk2 related to the
two nodes appear at least once in the same label vector Lh ∈L
(that is, if they are both assigned to a malware sample mh). Each
edge Ek1,k2 is assigned a weight w = 1 −
max (n1,n2) , where n1
is the number of label vectors Lh ∈L that contain lk1, n2 is the
number of vectors that contain lk2, and m is equal to the number
of vectors containing both lk1 and lk2.
m
For example, assume A contains all (and only) the samples shown
in Clust. 1 (shown in Section 3). In this case, the related AV Label
Graph is shown in Figure 2. Notice that in reality A will typically
contain thousands of samples, and that the graph in Figure 2 is re-
ported simply to provide an example of how the AV Label Graph is
computed. Also, notice that the missing labels were replaced with
unique “unknown” identiﬁers.
Once the AV Label Graph is computed, we build a reference clus-
tering dendrogram as follows (notice that a dendrogram is a tree-
like data structure generated by hierarchical clustering [9]). Given
any two samples mi, mj ∈ M we ﬁrst “map” each sample onto the
graph, and then compute the distance di,j between mi, mj on the
graph, thus obtaining a distance matrix D in which D[i, j] = di,j.
A more formal deﬁnition of graph-based distance between malware
samples is given below.
DEFINITION 2. - Graph-based Distance. Let mi ∈ M be a
malware sample, and Li = (l1, .., lν)i be its label vector. By def-
inition, each label lh,i ∈ Li corresponds to a node Vh,i in the
AV Label Graph, with h = 1, ..,ν . Therefore, sample mi can be
mapped to a list Vi = (V1,i, .., Vν,i) of ν nodes in the graph.
Now, let Vi and Vj be the lists of nodes related to mi and mj,
respectively. To compute the distance di,j between mi, mj, we ﬁrst
compute the length of the shortest path pk among a pair of nodes
(Vk,i,Vk,j), for each k = 1, ..,ν . Then, we compute di,j as the
median among all pk, with k = 1, ..,ν .
After computing the distance matrix D, we apply average-linkage
hierarchical clustering, which outputs a dedrogram T that expresses
the “relationship” between the malware samples in M according to
their AV labels. Section 5.2 explains in details how the reference
clustering dendrogram T can be used to validate third-party clus-
tering results.
5.2 Computing the Validity Indexes
As mentioned above, by cutting the reference clustering dendro-
gram T at a given height h, we obtain an actual partitioning of the
dataset M into a set of reference clusters Rc = {Rc1, .., Rcw}.
Then, the level of agreement between Rc and the third-party clus-
tering results C = {C1, C2, .., Cx} can be computed using the
external validity indexes introduced in Section 3.2. Naturally, dif-
ferent values of h will produce a different set of reference clusters,
and therefore the values of these validity indexes will also differ.
Therefore, to decide where exactly to cut the dendrogram T we
proceed as follows. Let Rc(h) be the set of reference clusters ob-
tained by cutting T at height h. Also, assume I(Rc(h), C) is an
external validity index computed over the clusterings Rc(h) and
C (e.g., I(·) could be equal to the Jaccard index, or one of the
other indexes outlined in Section 3.2). We then cut T at height
h∗ = argmaxh{I(Rc(h), C)}, so that h∗ is the cut at which the
level of agreement between C and the VAMO’s reference cluster-
ing is maximum.
In summary, we perform hierarchical clustering of the malware
samples in M according to similarities in their AV labels by lever-
aging the previously learned AV Label Graph, and then we ﬁnd the
set of reference clusters Rc(h∗) that best explains (or agrees with)
the third-party clustering results C. This is useful because given
two different third-party results C1 and C2 (e.g., given by the
same behavior-based malware clustering systems conﬁgured with
different parameter values, or given by different malware cluster-
ing systems), VAMO allows us to establish which of them has the
highest level of agreement with the underlying multiple AV labels.
6. EVALUATION
6.1 VAMO v.s. Majority Voting
In this Section, we present a set of experiments performed in
a controlled setting. Our objective is to show that, when faced
with noisy AV labels, VAMO outperforms majority voting-based
approaches. Namely, in the vast majority of cases VAMO pro-
duces an AV label-based reference clustering that better explains
(or agrees with) the true malware clusters. To this end, we use the
following high-level approach. We simulate a controlled dataset of
malware samples for which we know exactly what samples should
belong to what malware cluster, and ﬁrst assume that all samples
are perfectly (i.e., correctly) labeled by multiple AVs. Then, we
gradually introduce more and more noise into the AV labels, thus
simulating the inconsistent labeling typical of real-world AVs (see
Section 3.1). For each noise increase, we apply both VAMO and
a majority voting-based approach to obtain an AV label-based ref-
erence clustering, and the obtained results show that VAMO’s ref-
erence clustering yields validity indexes that offer a higher level of
agreement with the true malware clusters, compared to using ma-
jority voting.
6.1.1 Controlled Datasets
We create a synthetic dataset to simulate a scenario in which we
have a historic archive A consisting of 3,000 distinct malware sam-
ples and the related dataset L of labels assigned by three different
AV scanners to each of these 3,000 samples. Furthermore, we cre-
ate a dataset M containing 300 distinct samples, with M ⊂A (i.e.,
M is a proper subset of A). Therefore, the label dataset LM con-
taining the AV labels for the malware samples in M can be directly
obtained from L (since M ⊂A , then LM ⊂L ). It is worth noting
that we named these datasets following the same terminology that
we used in Section 4 and in Figure 1.
At ﬁrst, we assume to have perfect knowledge (i.e., perfect ground
truth) regarding the malware family each sample belongs to. Specif-
ically, we construct the datasets so that the samples in A (and the
related malware labels in L) belong to 15 different malware fam-
ilies, with 200 samples per family, and that each of the three AVs
consistently assigns the correct malware family name to the sam-
In practice,
ples in A, and therefore also to the samples in M.
to obtain M we simply randomly (uniformly) select 300 samples
from A. Also, since we know exactly what malware belong to
what family, we can precisely partition the dataset M into a set of
15 malware clusters C = {C1, C2, ..., Cs}, with s = 15.
It is worth noting that in this idealized scenario we also assume
the AVs use the very same family names for the malware family
labels. In other words, we assume the AVs all agree on using the
same terminology or notation. This means that no manual mapping
between family names assigned by different AVs is needed, and a
majority voting-based approach can be applied directly. This typi-
cally does not hold in practice, in which case we would need to ob-
tain the name mapping before being able to apply majority voting.
On the other hand, VAMO is agnostic to differences in the termi-
nology that the AVs use to assign malware family names, because
VAMO will automatically learn the relationships between different
malware family names through the AV Label Graph construction,
as discussed in Section 4 and Section 5.
6.1.2
To simulate inconsistency in the AV labels, we proceed as fol-
lows. We start from the label dataset L described above, and we
progressively inject more and more noise into the labels. Speciﬁ-
cally we inject the following two types of noise:
Simulating Inconsistency in the AV Labels
• Label Flips Given a malware mk ∈A , and its label vector
Lk = (l1,k, l2,k, l3,k) ∈L , with probability pf we replace
label lν,k with a different label lν,k chosen among the 14
other possible malware family labels, where the probability
pf is a preset “probability of ﬂip”.
• Missing Labels Similarly, given a malware mk ∈A , and
its label vector Lk = (l1,k, l2,k, l3,k) ∈L , with probability
pm we drop label lν,k to simulate the case in which the ν-th
AV missed to detect mk, where the probability pm is a preset
“probability of missed detection”.
These two types of noise can affect, with different preselected
probabilities, either one, two, or three AVs. To better explain this,
let n = [pf , pm; p1, p2, p3] be a “noise vector” whose elements ex-
press the following probabilities: pf is the overall probability that a
malware sample m will be affected by a label ﬂip, while pm is the
overall probability that a sample will be affected by a missing label;
on the other hand, px (with x =1,2, or 3) represents the probability
S
R
1
0.8
0.6
0.4
0.2
0
0
M
F
1
0.8
0.6
0.4
0.2
0
0
200
400
600
800 1000 1200 1400
Noise Index
(a) Rand
200
400
600
800 1000 1200 1400
Noise Index
(c) FM
C
J
1
0.8
0.6
0.4
0.2
0
0
1
F
1
0.8
0.6
0.4
0.2
0
0
200
400
600
800 1000 1200 1400
Noise Index
(b) Jaccard
200
400
600
800 1000 1200 1400
Noise Index
(d) F1
Figure 3: VAMO, absolute values of cluster validity indexes.
S
R
∆
0.08
0.06
0.04
0.02
0
−0.02
0
M
F
∆
0.8
0.6
0.4
0.2
0
−0.2