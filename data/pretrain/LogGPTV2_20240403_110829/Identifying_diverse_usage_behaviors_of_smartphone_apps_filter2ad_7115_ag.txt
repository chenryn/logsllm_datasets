individual access time
-60
-40
-20
 0
 20
 40
 60
difference (%)
b. device 3 vs. device 4
Figure 16: impact of devices used.
coverage is still very dependent on the genre (e.g., weather apps are
highly used in the south-eastern U.S.), even the app’s name (e.g.,
the news app headquartered in CHICAGO), etc. Therefore, con-
tent placement according to the geographic coverage is advisable
for both national and local apps.
5.2 Context-Aware Applications
Despite very diverse usage usage patterns across different smart-
phone apps, they still have some common traits. According to our
observations, ﬁrst, apps in the same genre share similar geographic
coverage. Second, some apps share a large set of common users
due to the similarity of content and interests, e.g., social network-
ing apps strongly correlate with entertainment apps, music apps,
news apps, etc. Third, some apps share similar diurnal patterns due
to content characteristics, e.g., the peak hours of news apps and
weather apps come at early morning.
Context-aware applications can take advantage of the existing
similarity/correlation across smartphone apps. Take smartphone
apps recommendation systems as an example. Unlike normal PC
users, smartphone users depend on apps far more than browsers.
Since a smartphone apps recommendation system is the ﬁrst ap-
proach for users to explore various smartphone apps that meet their
interests, these systems can be quite important. As the bridge be-
tween app marketplace and app customers, if apps recommendation
systems can learn user interests and dependency across apps, they
can identify more appropriate apps for users, e.g., suggesting gam-
ing fans more entertainment apps and social networking apps.
Another example of context-aware application is advertisement
systems, which upon learning user’s interests in apps, can deliver
more relevant ads to users. Camera or camcorder advertisements
may target more smartphone users that use more entertainment and
game apps because photography apps are more correlated with en-
tertainment and game apps.
5.3 Network Providers
Besides content providers, cellular network providers also play
an important role in content delivery and customization. By under-
standing the access patterns of smartphone apps, network providers
can beneﬁt in allocating radio resource, setting caching policy, com-
pression policy, etc.
If a large number of smartphone apps are targeted, their trafﬁc
volume and access time roughly have linear correlation with their
number of unique subscribers. Accordingly, cellular providers can
estimate and allocate radio resources.
We observe that the several few top apps contribute the major-
ity trafﬁc. For example, the app with the largest trafﬁc volume is
accountable for 50% of the total trafﬁc volume of the smartphone
apps category, and the app with the longest network access time
takes 86% of the total network access time of the smartphone apps
category. Understanding the usage patterns of these apps, network
providers may do certain optimizations case by case.
The temporal patterns of smartphone apps help network providers
allocate radio resource. For example, the access time per IP ﬂow
helps network providers decide the timers in state promotion [20].
We observe that some smartphone apps have large usage radius,
i.e., users of certain social networking apps and games apps are
more likely to move around across several base stations. In future,
LTE networks will push the ﬁrst IP hop forward to base stations,
which increases the ﬂexibility of content placement and optimiza-
tion. However, if users frequently move around, the correspond-
ing mobility may increase the complexity to decide where to cache
content and what content to cache.
5.4 OS Vendors and Apps Designers
Since smartphones have limited resources, the OS is account-
able for resource management, e.g., the push notiﬁcation on iOS,
Android, Windows Phone. Understanding the access patterns of
apps on device, OS can add some ﬂexibility to apps and optimize
the resource usage. For example, if a user frequently resorts to a
certain sleep aid app, then OS may allocate less resource to those
apps that may interrupt the user’s sleep.
Certain genres of smartphone apps have different characteris-
tics, which may be taken advantage by apps designers. We ob-
serve that news and weather apps have distinctive diurnal patterns.
Since the content of these apps usually are very time dependent and
content fetching time is very predictable, apps designer can imple-
ment some prefetching mechanism to reduce the latency perceived
by users. Similarly, the content of social networking apps can be
prefetched before dinner time.
6. CONCLUDING REMARKS
In this study, we comprehensively investigated the diverse usage
patterns of smartphone apps via network measurements from a na-
tional level tier-1 cellular network provider in the U.S. Our study
is the ﬁrst attempt in addressing the lack of how, where and when
smartphone apps are used at the scale of the entire U.S.
We observed that a considerable fraction of popular apps (20%)
are local because their content are expected to serve local users such
as news and radio apps. This suggests that there is signiﬁcant pos-
sibility for content optimization in LTE and WiFi access networks
where the ﬂexibility of placing content is high.
We also found out that there are similarities across apps in terms
of geographic coverage, diurnal usage patterns, etc. Certain apps
340have a high likelihood of co-occurrence – that is, (i) when a user
uses one app, he is also likely to use another one; or (ii) users use
alternatives for the same type of interests, e.g., multiple news apps,
bank apps. These observations suggest that some apps should be
treated as a “bundle” when trying to optimize for their user ex-
perience. There may be opportunities for integrating these apps
together.
Diurnal patterns of smartphone apps can be remarkably differ-
ent. For instance, news apps are much more frequently used in the
early morning while sports apps are more frequently used in the
evening. These ﬁndings suggest that content providers (e.g., hosted
on cloud) can leverage distinct usage patterns in classes of apps to
maximize the utilization of their resources.
Many social networking and games apps are more frequently
used when users are moving around. Mobility affects connectiv-
ity and performance, so bandwidth sensitive content that are mo-
bile may need to consider techniques to compensate for bandwidth
variability.
We believe that our ﬁndings on the diverse usage patterns of
smartphone apps in spatial, temporal, user, device dimensions will
motivate future work in the mobile community.
7. REFERENCES
[1] Apple. Apple’s App Store Downloads Top 10 Billion.
http://www.apple.com/pr/library/2011/01/
22appstore.html.
[2] A. Balasubramanian, R. Mahajan, and A. Venkataramani.
Augmenting Mobile 3G Using WiFi: Measurement, System
Design, and Implementation. In Proc. ACM MOBISYS, 2010.
[3] X. Bao and R. Roy Choudhury. MoVi: mobile phone based
video highlights via collaborative sensing. In Proc. ACM
MOBISYS, 2010.
[4] I. Constandache, X. Bao, M. Azizyan, and R. R. Choudhury.
Did you see Bob?: human localization using mobile phones.
In Proc. ACM MOBICOM, 2010.
[5] E. Cuervo, A. Balasubramanian, D. ki Cho, A. Wolman,
S. Saroiu, R. Ch, and P. Bahl. MAUI: Making smartphones
last longer with code ofﬂoad. In Proc. ACM MOBISYS, 2010.
[6] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,
P. McDaniel, and A. N. Sheth. TaintDroid: an
information-ﬂow tracking system for realtime privacy
monitoring on smartphones. In USENIX Symposium on
Operating Systems Design and Implementation (OSDI),
2010.
[7] H. Falaki, D. Lymberopoulos, R. Mahajan, R. Govindan,
S. Kandula, and D. Estrin. Diversity in Smartphone Usage.
In Proc. ACM MOBISYS, 2010.
[8] H. Falaki, D. Lymberopoulos, R. Mahajan, S. Kandula, and
D. Estrin. A ﬁrst look at trafﬁc on smartphones. In Proc.
ACM SIGCOMM IMC, 2010.
[9] Federal Emergency Management Agency. Tornado Activity
in the United States. http://www.fema.gov/plan/
prevent/saferoom/tsfs02_torn_activity.shtm.
[10] M. Ficek, T. Pop, P. Vláˇcil, K. Dufková, L. Kencl, and
M. Tomek. Performance study of active tracking in a cellular
network using a modular signaling platform. In Proc. ACM
MOBISYS, 2010.
[11] A. Gember, A. Anand, and A. Akella. A Comparative Study
of Handheld and Non-Handheld Trafﬁc in Campus WiFi
Networks. In Proc. International Conference on Passive and
Active Network Measurement (PAM), 2011.
[12] Google. Eric Schmidt at Mobile World Congress 2011.
http://www.youtube.com/watch?v=ClkQA2Lb_iE&
feature=related.
[13] B. D. Higgins, A. Reda, T. Alperovich, J. Flinn, T. J. Giuli,
B. Noble, and D. Watson. Intentional networking:
opportunistic exploitation of mobile network diversity. In
Proc. ACM MOBICOM, 2010.
[14] J. Huang, Q. Xu, B. Tiwana, Z. M. Mao, M. Zhang, and
P. Bahl. Anatomizing Application Performance Differences
on Smartphones. In Proc. ACM MOBISYS, 2010.
[15] R. Keralapura, A. Nucci, Z.-L. Zhang, and L. Gao. Proﬁling
users in a 3g network using hourglass co-clustering. In Proc.
ACM MOBICOM, 2010.
[16] K. A. Li, T. Y. Sohn, S. Huang, and W. G. Griswold.
Peopletones: a system for the detection and notiﬁcation of
buddy proximity on mobile phones. In Proc. ACM
MOBISYS, 2008.
[17] Y. Liu, A. Rahmati, Y. Huang, H. Jang, L. Zhong, Y. Zhang,
and S. Zhang. xShare: supporting impromptu sharing of
mobile phones. In Proc. ACM MOBISYS, 2009.
[18] G. Maier, F. Schneider, and A. Feldmann. A ﬁrst look at
mobile hand-held device trafﬁc. In Proc. International
Conference on Passive and Active Network Measurement
(PAM), 2010.
[19] National Hurricane Center. National Hurricane Center.
http://www.nhc.noaa.gov/pdf/TAFB_Trifold.pdf.
[20] F. Qian, Z. Wang, A. Gerber, Z. M. Mao, S. Sen, and
O. Spatscheck. Characterizing radio resource allocation for
3G networks. In Proc. ACM SIGCOMM IMC, 2010.
[21] F. Qian, Z. Wang, A. Gerber, Z. M. Mao, S. Sen, and
O. Spatscheck. Proﬁling Resource Usage for Mobile
Applications: a Cross-layer Approach. In Proc. ACM
MOBISYS, 2010.
[22] I. Trestian, S. Ranjan, A. Kuzmanovic, and A. Nucci.
Measuring serendipity: connecting people, locations and
interests in a mobile 3G network. In Proc. ACM SIGCOMM
IMC, 2009.
[23] I. Trestian, S. Ranjan, A. Kuzmanovic, and A. Nucci.
Taming User-Generated Content in Mobile. Networks via
Drop Zones. In Proc. IEEE INFOCOM, 2009.
[24] Wikipedia. High-Speed Downlink Packet Access. http://
en.wikipedia.org/wiki/High-Speed_Downlink_
Packet_Access.
[25] Wikipedia. High-Speed Uplink Packet Access. http://en.
wikipedia.org/wiki/High-Speed_Uplink_Packet_
Access.
[26] W. Woerndl, C. Schueller, and R. Wojtech. A Hybrid
Recommender System for Context-aware Recommendations
of Mobile Applications. In Proc. IEEE ICDE, 2007.
[27] Q. Xu, A. Gerber, Z. M. Mao, and J. Pang. Acculoc:
Practical localization of peformance measurement in 3g
networks. In Proc. ACM MOBISYS, 2011.
[28] Q. Xu, J. Huang, Z. Wang, F. Qian, A. Gerber, and Z. M.
Mao. Cellular data network infrastructure characterization
and implication on mobile content placement. In Proc. ACM
SIGMETRICS, 2011.
[29] B. Yan and G. Chen. AppJoy: Personalized Mobile
Application Discovery. In Proc. ACM MOBISYS, 2011.
[30] L. Zhang, B. Tiwana, Z. Qian, Z. Wang, R. P. Dick, Z. M.
Mao, and L. Yang. Accurate online power estimation and
automatic battery behavior based power model generation for
smartphones. In Proc. IEEE/ACM/IFIP CODES+ISSS, 2010.
341Summary Review Documentation for 
“Identifying Diverse Usage Behaviors of Smartphone 
Apps” 
Authors: Q. Xu, J. Erman, A. Gerber, Z. Mao, J. Pang, S. Venkataraman 
Reviewer #1 
Strengths:  This  is  an  excellent  paper  that  I  enjoyed  much 
reading.  The  paper  is  vey  well  organized,  reads  easily  and  the 
main  results  are  backed  up  by  a  solid  methodology  as  well  as 
strong intuitions and justifications. This is the first paper that I am 
aware  of  which  goes  one  step  further 
in  understanding 
smartphone usage, i.e., they open up the space of the smartphone 
applications segment. 
Weaknesses: The strength of the paper resides in the smartphone 
apps and how they are grouped together, but little is said on how 
they are identified and grouped. I would have loved to understand 
the details on what the authors have exactly done to appreciate the 
robustness and reliability of their findings.  
Comments  to  Authors:    The  authors  mentioned  that  they  have 
used the string reported in the USER-AGENT field of the HTTP 
protocol to identify the specific application name. But, to the best 
of my knowledge, many of these applications use a default string 
that is indicative of the company releasing the specific application 
rather than the specific application in question. For example, any 
game released by Zynga is labeled with Zynga (at least from the 
packet traces I have played with in the past) and not the specific 
game.  If  a  company  may  offer  distinct  apps  for  different 
categories, 
the  application 
classification and grouping will be questionable. I would strongly 
advice  the  authors  to  add  a  paragraph  or  even  more  to  explain 
exactly  how  this  is  done  as  this  is  a  vital  aspect  of  the  entire 
paper.  Same  story  on  how  they  do  application  grouping.  Their 
explanation  is  very  short  and  surely  deserves  more  room  in  the 
paper. Not clear after reading it twice whether they are using the 
exact  method  proposed  by  Erman  et  all  in  “Network-Aware 
forward Caching” based on the filed CONTENT-TYPE or use a 
grouping like the one done in the “Profiling users in a 3g network 
using  hourglass  co-clustering”  by  Keralapura  et  all  (ACM 
Mobicom 2010). This should be explained in more details. 
Reviewer #2 
Strengths:  Uncovers  many  aspects  of  how  people  use 
smartphones.  While  none  of  the  results  are  terribly  surprising, 
these  authors  are  the  first  to  do  this  kind  of  analysis  and  the 
results  have  interesting  implications  of  network  and  content 
provisioning. 
Weaknesses: The results are mostly along expected lines. Some 
of the analysis methods are not rigorous enough to be conclusive 
(although I still think the results will hold) 
the  overall  accuracy  of 
then 
Comments  to  Authors:    Let  me  first  comment  on  the  lack  of 
rigor in the analysis. I’ll pick examples from Sections 4.4 and 4.5, 
but  a  similar  lack  of  consideration  for  random  processes  is 
missing from other sections as well. 
In  Section  4.5,  you  should  draw  confidence  intervals  for 
individual hours. This is important to reliably draw the kinds of 
conclusions  you  are  drawing,  given  that  the  curves  are  pretty 
jumpy  and  you  only  have  7  data  points  per  hour.  The  intervals 
will  show  if  the  differences  that  you  are  commenting  on  are 
statistically significant. 
In  Section  4.4,  you  need  to  compare  the  results  to  a  uniform 
random process to put them in perspective. Even if there was no 
correlation in how a user acquires applications but if instead the 
acquisition  of  each  application  was  a  uniform  random  process, 
you  would  see  dependency  ratios  higher  than  one.  How  much 
higher depends on the subscribers of the application.   
I  still  believe  that  your  findings  will  hold,  but  it  is  a  matter  of 
using the right tools and drawing correct conclusions from them. 
What is the impact of focusing analysis on only popular apps on 
your estimates of how many apps are local? The filter you apply 
is  more  likely  to  filter  out  local  apps,  because  of  their  inherent 
handicap  in  attracting  a  large  number  of  users.  What  if  you 
identified top apps by traffic volume per user (not total traffic, as 
you  appear 
local  apps  are  not 
disadvantaged? 
In  Table  3,  you  mention  news,  weather,  and  entertainment  as 
locally popular apps in the same breath. That seems like you are 
selling a pre-conceived notion, because the numbers show that its 
basically just news. The raw numbers for music are in fact higher 
than  weather.  Perhaps  you  are  basing  your  claim  based  on 
comparison with the aggregate PDF for popular apps in Table 1. 
In that case, it would be good to directly show that comparison. 
I love Figure 8! 
The travel area analysis of Section 4.3.3 is highly unsatisfying in 
the way it is done. There is not much useful I can conclude from 
it, besides some apps travel. 
I suggest dropping the Jaccard similarity index analysis in Section 
4.4.  It  does  not  add  anything  that  is  not  already  covered  by  the 
succeeding dependency ratio analysis. The latter analysis is more 
direct. (It is closer to what I was hoping for when I originally read 
the  Jaccard  analysis,  modulo  the  appropriate  normalization 
comment above.) 
in  Figure  4),  so 
to  do 
342Did  you  attempt  to  cluster  users  based  on  the  applications  they 
use  or  the  genres  of  applications  they  use?  It  will  be  very 
interesting if only a few clusters (e.g., heavy news users, games 
and music users, etc.) exist. 
In Section 4.6, were “similar” set of apps being used across the 
three devices?  
Out  of  curiosity,  how  did  you  simultaneously  guarantee  exactly 
one  anonymized 
identifier  per  distinct  device  and  non-
reversibility of anonymous identifiers? 
Reviewer #3 
Strengths:  With  3G  data  traffic  rising  faster  than  any  other 
network  traffic  and  most  of  this  being  due  to  smart-phone  apps 
the paper is right on target in terms of relevance. The dataset is 
quite impressive and the analysis sound and extensive. 
Weaknesses: The paper never goes deep in any of the topics that 
it touches. 
Comments to Authors: This paper is a nice read and I am mostly 
positive about it, but it stays way too high in its treatment of the 
problem. At no place the paper goes deep to drill on a particular 
topic and make a sound contribution that goes beyond interesting, 
but  rather  general  observation.  What  I  am  missing  here  is 
additional  work  in  some  part  of  the  results  in  order  to  make  a 
concrete connection between the measurement part and the uses 
discussed  but  not  demonstrated  at  the  end  of  the  paper.  If  the 
authors  would  have  used  the  data  and  their  analysis  to  improve 
some aspect of either the network or the devices that run smart-
apps then the paper would really be stellar.  
Given  that  the  data  are  not  made  available  nor  there  is  any  re-
usable model derived from them for others to use, I am wondering 
how  much  these  works  really  contribute  beyond  anecdotal  facts 
that do not however connect directly with some advancement in 
the field. 
In Section 4.1 you state that the top app generates 50% of the total 
traffic  volume  but  in  Fig  1a  there  does  not  seem  to  be  any 
category with 50% contribution. Something is wrong there. 
Section  4.4  (especially  at  the  end  where  it  discusses  the 
correlations  between  different  apps)  is  really  hand  wavy.  The 
paper is in general full of unsubstantiated claims and theories to 
the point that it really hurts rigor. 
Reviewer #4 
Strengths:  -  Unprecedented  scales  of  data  in  terms  of  spatial 
application usage. 
- The paper is clearly written. 
Weaknesses:  The  paper  dilutes  the  study  into  a  “one  by  one” 
dimension study, with very little derivation of a real consequence. 
All  results  are  finally  formulated  in  a  qualitative  form  that  is 
completely  expected 
immediately  explained  by 
obvious intuition on what drives traffic) and not related to some 
of  the  implications  in  a  precise  way.  It  makes  the  observations 
very weak. 
- No effort to position this paper in the area of results known on 
apps  usage,  it’s  not  clear  what  is  a  confirmation  and  what  is  a 
surprising result, even relatively. 
(generally 
Comments to Authors: I think the paper goes a bit far in stating 
that  scale  and  diversity  is  the  final  word  to  judge  empirical 
results.  Comparison  and  insights  are  also  a  primary  need.  Some 
studies  have  been  made  of  smart  usage  and,  in  addition  to  that, 
one can easily develop some intuition on how apps behave. This 
paper is a full confirmation of each using a massive collection of 
data.  It  chooses  not  to  compare  to  any  previous  study,  even 
preliminary  ones  that  had  more  limitations,  so  it  seems  like  a 
brand  new  start,  but  without  a  real  point  of  incremental 
knowledge to grasp.  
I feel it is a debate we should have in IMC to see what to do with 
such  submission.  My  personal  bias  goes  in  accepting  this  paper 
for its strengthening of our understanding and also gives priority 
to  work  that  would,  in  the  short  time  of  a  conference,  have  a 
chance to bring more important research in our community. 
The  paper  chooses  to  ignore  topics/questions  that  one  would 
expect to see addressed.  
1) First of all, a comparison of the findings with previous studies 
of popularity of websites, wired network, etc. It is not like spatial 
locality  and  access  of  data  from  different  category  happen  on  a 
network.  
2)  Second,  a  comparison  of  the  findings  with  the  “plethora  of 
study” mentioned in related work about apps usage. Truly these 
studies concluded using a much more limited set of data, still it 
would matter to understand what we know better from this point 
on. 
3) Third, how are the quantitative findings present in the data set 
turn into operational numbers? A good example is the “locality” 
of 20% of the application. Unfortunately, it seems that, although 
the  applications  were  carefully  selected 
to  avoid  obvious 
degenerate cases (very unpopular applications), it is not clear how 
much traffic this represents (especially with massive applications 
like the “social utility” responsible for huge amounts of traffic).  
Another  example  is  the  presence  of  co-occurence  and  temporal 
variation.  The  paper  states  that  this  property  can  be  exploited 
(which  is  obvious).  The  qualitative  statement  that  this  property 
exists brings little and no more work to translate them in concrete 
savings.  Note  in  particular  that  the  exploitation  of  the  temporal 
variation is quite obscure. 
4)  Statement  of  contributions  are  too  vague  to  attract  real 
attention  (“presenting  results.”  “present  aggregate  results”  is  all 
that can be found in the abstract. The introduction concludes with 
a “We believe our study makes an important step”.) 
5) The following hypothesis seems an ad-hoc simplification used 
to highlight the importance of the result: “We do not expect users 
...  as  a  function  of  their  geographical  location”:  That  would  be 
true only if looking at equivalent users. Right now, it is clear that 
obvious variations of demographics (rural, urban, access to city) 
explain  a  lot  of  spatial  variation,  even  without  any  location 
embedded in the actual application itself. 
3436)  Implications  are  narrowed  and  remained  vague  or  somewhat 
out of the blue (“if a user resort to a certain sleep aid ...”: This 
seems not at all a spatial property, but a quite customized option 
to add to a phone as an add-on to be made by the users. It is very 
unclear what the provider should be doing that from the network 
(in terms of resource location).  
Reviewer #5 
Strengths:  The  traces  analyzed  are  unique  and  large  in  scale, 
very different from what’s been in the literature.	
Weaknesses: The analyses are fairly standard. 
Comments to Authors: The paper performs extensive analysis of 
a  very  interesting  dataset.  The  analyses  include  popularity  of 
applications,  spatial  distributions,  their  joint  access  patterns, 
temporal  distribution,  difference  across platforms. Most analysis 
results are as we would expect. Certainly it is useful to confirm 
our intuition using real data. On the other hand, it would be nice 
to  also  see  some  unexpected  results  from  the  analysis,  e.g.,  are 
there  anomalies  in  any  of  these  access  patterns?  How  often  do 
you see deviation and what are possible reasons for them?  
In  Section  4.2  “Popular  smartphone  applications”:  I  found  the 
filtering  analysis  not  compelling.  Why  do  you  filter  out 
applications  just  because  it  does  not  have too many users? Will 
such filtering prevent deployment of new applications as they all 
start with a small number of users? 
It is good that the paper has a section on implications. The section 
could be strengthened by going beyond the obvious improvement. 
For example, placing content closer to the users certainly makes a 
lot  of  sense.  But  how  accurately  can  we  predict  the  user  access 
pattern to support efficient content placement? In general, if you 
could  have  some  concrete  numbers  about  the  potential  saving, 
that would be very helpful. 
Response from the Authors 
1.  We  manually  checked  more  smartphone  apps  to  validate  the 
correctness  of  querying  the  marketplace  API  with  the  USER-
AGENT to categorize smartphone apps. 
On Table 1, we manually check top 10, 20, 50, 100, 200, and 500 
apps.  We  are  confident  on  the  correctness  of  the  majority  of 
smartphone  apps.  Among  the  top  500  apps,  427  apps  are 
considered  as  correct  by  our  manual  check;  14  of  them  are 
considered as misclassified into the wrong category; and 69 of are 
considered as “unknown” because either we are uncertain on the 
correctness  or  querying  the  marketplace  API  responds  with 
empty. 
2.  We  differentiated  and  clarified  the  usage  of  “app”  and 
“application”. “app” is used in the context of individual programs 
running on smartphones, such as YouTube player, Google maps; 
while  “application”  is  more  abstract  and  general,  such  as  “push 
notification”, “content delivery service”, etc. 
3.  We  embedded  more  examples  in  the  implication  section.  We 
add more examples make our implication more concrete and more 
convincing.  For  instance,  In  Section  5.1,  we  mention  “...for 
national apps, the distribution of geographic coverage is still very 
dependent on the genre (e.g., weather apps are highly used in the 
south-eastern  U.S),  even  the  app’s  name  (e.g.,  the  news  app 
headquartered in CHICAGO), etc...” 
4. We calculated the contribution of traffic volume by local apps. 
In  our  submission,  we  mentioned  that  20%  apps  are  local; 
however, we didn’t mention the contribution of these local apps, 
i.e., whether they are significant to cellular network operators. In 
total,  these  20%  local  apps  contribute  2%  of  the  total  traffic 
volume in the smartphone apps category. 
5.  We  agree  with  these  comments  from  Reviewer  #2  on  taking 
more  consideration  on  “random  process”,  but  we  didn’t  go  that 
far. The main reason is that we didn’t consider the “correlation” 
across  apps  at  the  granularity  as  fine  as  “happen  before” 
relationship or “causality”. Given a pair of apps (A, B), we simply 
counted how many users used both A and B, and how many users 
used either A or B. 
6. We addressed these minor issues: 
-  In  Section  4.1,  “the  top  app  generates  50%  of  the  total  traffic 
volume”  is  changed  to  “the  top  app  generates  50%  of  the  total 
traffic volume of the smartphone apps category”. 
-  In  Section  4.1,  “86%  of  the  total  network  access  time”  is 
changed  to  “86%  of  the  total  network  access  time  of  the 
smartphone apps category”. 
344