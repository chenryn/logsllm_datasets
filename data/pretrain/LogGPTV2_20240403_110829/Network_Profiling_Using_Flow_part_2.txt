### Optimized Text

Outdated information can still serve as a starting point for identifying known devices and potential problem areas that may require additional validation during the profiling process. Familiarity with the organization’s network and security policies is also beneficial, as it allows the profiler to identify discrepancies between the policies and the actual findings. The output of the profiling effort may reveal compliance issues or suggest potential changes to security policies that are worth considering.

It is essential to have a clear expectation of what you will see when starting the profile, but it is equally important to recognize that not all aspects of the network are known. For example, an old File Transfer Protocol (FTP) server dedicated to internal file sharing might have been temporarily opened to external services and then forgotten. Such oversights can lead to information gaps, which in turn create vulnerabilities in network security.

If time permits, consider conducting a quick assessment or penetration test to develop a network map and a list of exposed services on various machines. Many automated tools, such as the free and open-source nmap, are available for network mapping. Most network monitoring solutions also have built-in network mapping capabilities. Ensure that you obtain permission to run active scans on the network, as initiating such scans without authorization could violate company policy or negatively impact system performance.

Once the profile is complete, update the network maps and lists of servers so that the process can be repeated in the future.

### 2.1 Sample Network Information

For the purposes of this report’s case study, we initially assumed the following about the network being profiled:
- **Size**: Thousands of users
- **Owner**: A mid-sized organization using the network for business purposes
- **CIDR**: 203.0.113.0/24 (203.0.113.0 – 203.0.113.255)

**Note**: "Nmap ('Network Mapper') is a free and open-source utility for network exploration or security auditing." Source: nmap.org

### 3. Select an Initial Data Set

Choosing the initial data set for analysis is crucial because it shapes the entire analysis. Take some time to obtain a good representative sample of data that remains a reasonable size. A data set large enough to represent typical traffic is necessary, but it should be small enough to allow for iterative query processing.

Before selecting the initial data set, understand how sensor placement and flow collection configurations affect the available flow data.

### 3.1 Sensor Placement and Configuration

The importance of sensor placement cannot be overstated. It affects what flow data is collected and which IP addresses are associated with each flow record. The following framework will help you decide the most effective sensor placement and configuration for the network you will profile.

Proper sensor placement for network profiling considers several factors: the goal of the flow collection, the network topology, and the network hardware in use. For example, some network hardware or security devices, such as proxy servers or firewalls, can make visibility into the network difficult or impossible with flow data alone. The goal of this report’s step-by-step process is to profile perimeter traffic to see what a network looks like from an external attacker's perspective. Therefore, sensors should be placed on the external, or internet-facing, side of any perimeter networking devices. Sensor placement for other goals may have different requirements and is thus out of the scope of this report.

When a network is split into intranets, it is tempting to profile each one individually. However, the goal is to profile the network from the view of an outsider, so place the sensors around the perimeter of the largest extranet that needs to be profiled. If necessary, divide the data collected by address blocks to view differences between intranets. Note that profiling anything except the entire network may leave out assets not intended to be left out.

Remote and business-to-business networks often have their own gateway into a network. Include these gateways when placing sensors at all access points to the network. Note any special access points, as traffic across these sensors may differ from typical traffic at other sensors. This same reasoning applies to business continuity links, which should be included in the profile with a note that traffic at these sensors will be different from traffic at other sensors. Table 2 contains guidelines for sensor placement.

**Table 2: Sensor Placement Guidelines**

| Configuration | Placement |
|---------------|-----------|
| Multiple exit points | Make sure all access points connecting the network to other networks are covered. |
| Network/security devices (proxies, NATs, firewalls, etc.) | Sensors should be placed on the external side of these devices. |
| Intranets/extranets | Place sensors around the largest extranet that needs to be profiled. |
| Remote networks, failover access points | Place sensors at these access points, making a note of their special purpose. |

**Figure 3: Example Sensor Placement**

While working with the data, you should see plausible amounts of traffic for expected assets. For example, if a web server has a 200 Mbps network interface card, expect to see traffic to and from that web server at a rate of less than 200 Mbps.

### 3.2 Guidelines

Guidelines for selecting a sample data set are listed in Table 3. It is not necessary to ensure that the sample data set is representative of all traffic that crosses the network boundary. Once built, the profile will be reapplied to the rest of the data set to ensure nothing is missed. Selecting a sample data set should be done after the sensors are placed and network flow has been collected.

**Table 3: Guidelines for Selecting a Data Set**

| Feature | Considerations |
|---------|----------------|
| Duration | Start with at least an hour’s worth of data. Add more data—up to a day’s worth—until the query time starts to slow down. The query time for the entire initial data set should be 15-60 seconds. |
| Timing | Select the busiest time of day to quickly carve out the most common network traffic. |
| Direction | If the traffic is bidirectional and it is necessary to further reduce the sample size to reduce the query time, start by looking at outbound traffic—traffic generated by internal equipment. |
| Sampling | Avoid starting with sampled data if possible because it may mask some important and routine behaviors. |
| Network Size | If the network is extremely large but divides into logical boundaries by IP address, consider separating the analysis into a few independent profiles and merging them after completing the analysis. |

For the sample network, we used the following command to choose a day’s worth of data from Wednesday, September 28, 2011, which is representative of a typical workday, as the sample data set.

```bash
$ rwfilter --start-date=2011/09/28:00 --end-date=2011/09/28:23 \
--type=all --protocol=0- --pass=sample.rw
```

**Note**: `rwfilter` is the main SiLK command, which allows selection and partitioning of flow records based on various fields in the record.

In the case of the sample network, there was enough processing power to query a data set of this size. No other filtering was done based on start or end times, flow duration, address space, direction, or other characteristics.

The following example shows the command we performed on the sample data set and the result that it has 10,985,967 total records and is 571 MB in size.

```bash
$ rwfileinfo sample.rw
sample.rw:
format(id) FT_RWGENERIC(0x16)
version 16
byte-order littleEndian
compression(id) none(0)
header-length 156
record-length 52
record-version 5
silk-version 2.4.2
count-records 10985967
file-size 571270440
command-lines
1 rwfilter --type=all --start-date=2011/09/28:00 \
--end-date=2011/09/28:23 --protocol=0- --pass=sample.rw
```

### 3.3 Validating the Selection

After identifying a sample data set to work with, it is worthwhile to take a few extra minutes to perform a surface analysis of the sample to confirm that it represents the network. A quick inspection of the sample will save time that could otherwise be wasted on an improperly collected or filtered data set.

The highest volume data paths should be no surprise and should be obvious in the data set. Check typical ports, protocols, and address blocks to ensure the sample contains expected data. Table 4 includes a few possible tests for validating the selection.

**Table 4: Validating the Initial Data Set**

| Expected Asset | Expected Sample Traffic | Method of Verifying the Sample |
|----------------|------------------------|--------------------------------|
| Web servers | TCP traffic with an internal source address and a source port of 80 or 443 | Using a web browser, browse to those IP addresses. |
| Web clients | TCP traffic with an internal source address and a destination port of 80 or 443 | Make sure gateways and/or proxy servers are in this list. |
| Email servers | TCP traffic with an internal destination address and a source port of 25 | These addresses should match the mail exchanger (MX) records of the network. |
| Business-to-business VPN | IP protocol 50 (ESP) and 51 (AH); UDP port 500 (IKE) or TCP port 4500 (NAT-T) | The external addresses should be business partner networks. |

### 3.3.1 Sample Network Data Set Validation

Because there was no network map or list of servers for the sample network, the sample data set was validated by inspecting for the types of traffic typically seen during a workday on a business network. Basic networking knowledge indicates that almost all of the traffic should be over TCP and UDP. This can be verified by dividing the traffic volumes for the sample network based on IP protocol number and looking at the top five protocols in use. The following command and output from the sample data show that there was also some ICMP (protocol 1) traffic, and ESP and IPv4 encapsulation protocols (50 and 4 respectively).

```bash
$ rwstats sample.rw --fields=protocol --count=5
INPUT: 10985967 Records for 7 Bins and 10985967 Total Records
OUTPUT: Top 5 Bins by Records
pro| Records| %Records| cumul_%|
6| 7302815| 66.474030| 66.474030|
17| 3605304| 32.817357| 99.291387|
1| 72762| 0.662318| 99.953705|
50| 5079| 0.046232| 99.999936|
4| 3| 0.000027| 99.999964|
```

**Figure 4: Top Five IP Protocols on the Sample Network**

**Note**: In SiLK, `rwstats` is the command that groups flows by a specific key or, in this case, protocol, and prints the top values by traffic volume percentage. Other analysis tools may show this graphically, as seen in Figure 4.

The top expected services requested by clients on a typical network are web (ports 80 and 443), DNS (port 53), and SMTP (port 25). Verify this by sorting outgoing traffic into the top five most common destination ports. The statistics that follow the SiLK command below and are represented graphically in Figure 5 show some traffic to port zero, which is SiLK’s notation for traffic on IP protocols other than TCP and UDP.

```bash
$ rwfilter sample.rw --type=out,outweb --protocol=0- --pass=stdout \
| rwstats --count=5 --fields=dport
INPUT: 5064003 Records for 64477 Bins and 5064003 Total Records
OUTPUT: Top 5 Bins by Records
dPort| Records| %Records| cumul_%|
80| 2625707| 51.850423| 51.850423|
53| 1530900| 30.231025| 82.081448|
443| 291927| 5.764748| 87.846196|
25| 13910| 0.274684| 88.120880|
0| 4000| 0.078989| 88.199869|
```

**Figure 5: Destination Ports for Outbound Traffic from the Sample Network**

The output shows that the expected services are being used. Also, servers on the network are likely to handle the same services.

Next, check the source port of outbound traffic. The SiLK command and the output from the sample network follow.

```bash
$ rwfilter sample.rw --type=out,outweb --protocol=0- --pass=stdout \
| rwstats --count=5 --fields=sport
INPUT: 5064003 Records for 64897 Bins and 5064003 Total Records
OUTPUT: Top 5 Bins by Records
sPort| Records| %Records| cumul_%|
53| 291693| 5.760127| 5.760127|
80| 129093| 2.549228| 8.309355|
25| 85331| 1.685050| 9.994406|
443| 71429| 1.410524| 11.404930|
0| 6644| 0.131201| 11.536131|
```

**Figure 6: Source Ports for Outbound Traffic from the Sample Network**

This second analysis shows that the services in use—DNS, web, and email servers—are as expected. You can safely assume at this point that the available data has been properly sampled and can proceed with the profiling process.

### 4. Identify the Monitored Address Space

Start network profiling activities by becoming familiar with the network address topology and how well the sensors can see it. Some issues involving monitored address space include whether sensors cover any private address space, what traffic is expected on failover circuits during normal operations, and whether a business unit has connected a system without administrator knowledge. This section explores some of these issues by first finding populated addresses.

The process to identify the monitored address space follows these steps:
1. Identify hosts that have active TCP connections.
2. Identify hosts that generate a nontrivial amount of traffic on protocols other than TCP.
3. Aggregate individual hosts into populated network blocks.
4. Examine additional information to confirm the list of active IP address blocks.

**Figure 7: Active Hosts**

### 4.1 TCP Talkers

For most networks, the bulk of traffic happens on TCP (IP protocol 6). Therefore, you can find most active network hosts (also referred to as “talkers”) by looking for legitimate TCP sessions. Sustained TCP conversations are relatively easy to identify in flow. However, pay careful attention to eliminate scan traffic and “ghost” traffic—attempts to connect to hosts that no longer exist. The purpose of getting rid of the ghost traffic is not because it is inconsequential, but simply because it is not helpful for identifying active internal hosts. Criteria for finding active TCP hosts are listed in Table 5.

**Table 5: Active TCP Host Criteria**

| Criteria | Explanation |
|----------|-------------|
| Outbound | Outbound traffic is generated from the internal IP block, so no unsolicited traffic or public scanning traffic should be contained in this traffic. |
| Protocol 6 | TCP traffic |
| More than four packets | To establish a TCP session, two packets must be sent in each direction. Another one or two packets are required to tear down the session. Requiring at least four packets ensures that at least some data are exchanged between the client and the server. |
| ACK flag set | This eliminates flows consisting entirely of SYN or RST packets, which could be the result of scans or ghosts. |

Use the following command to apply these filter criteria to the sample traffic and obtain a list of the source IP addresses actively using TCP.

```bash
$ rwfilter sample.rw --type=out,outweb \
--protocol=6 --packets=4- --ack-flag=1 --pass=stdout \
| rwset --sip-file=tcp_talkers.set
$ rwsetcat tcp_talkers.set --count
36
```

The command’s output shows that the sample network has 36 active TCP talkers. The addresses of these hosts were placed into a SiLK set file for future reference. Saving the list of IP addresses is an important step to eliminate redundant queries later on.

### 4.2 Other Talkers

TCP was used to identify active hosts first to eliminate as much scanning and ghost activity as possible; however, many connectionless protocols are used on networks. In addition to finding TCP talkers, it is important to find IP addresses on the network that are actively using other protocols.

You should separate web-browsing traffic (ports 80, 8080, and 443) from all other traffic if the analysis software has the capability to do so. Web-browsing traffic is not normally carried over protocols other than TCP. Leave out this traffic over non-TCP protocols for now. See the following commands as an example.

```bash
$ rwfilter sample.rw --type=out --protocol=0-5,7-255 --pass=stdout \
| rwset --sip-file=other_talkers.set
$ rwsetcat --count other_talkers.set
25
```

The output of these commands shows that the sample network has 25 active talkers on other protocols.

### 4.3 Aggregating Hosts

You should now have two lists of active addresses—TCP and non-TCP. Join the lists together and remove any duplicates. The result will be all of the active assets from the sample set, without too much extraneous traffic. If the list is large, consider dividing it into groups of smaller netblocks for separate analysis. The SiLK command for joining the TCP and non-TCP lists follows.

```bash
$ rwsettool --union tcp_talkers.set other_talkers.set \
--output-path=talkers.set
$ rwsetcat --count talkers.set
40
```

Combining the TCP and “other talkers” lists for the sample network results in 40 active talkers, as shown in the command output above.

**Note**: The SiLK set file is located at http://tools.netsa.cert.org/silk/rwset.html.