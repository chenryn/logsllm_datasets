the attacker can force the victim model to misclassify a spe-
ciﬁc input sample without signiﬁcantly damaging the overall
accuracy. However, the blind attacker gains no signiﬁcant ad-
vantage over the black-box scenario as the lack of capability
prevents the attacker from acting on the knowledge.
USENIX Association
28th USENIX Security Symposium    499
4 Single-Bit Corruptions on DNNs
In this section, we expose DNNs’ vulnerability to single bit-
ﬂips. We start with an overview of our experimental setup
and methodology. We then present our ﬁndings of DNNs’
vulnerability to single bit corruptions. For characterizing the
vulnerability, we analyze the impact of 1) the bitwise repre-
sentation of the corrupted parameter, and 2) various DNN
properties; on the resulting indiscriminate damage2. We also
discuss the broader implications of the vulnerability for both
the blind and surgical attackers. Finally, we turn our attention
to two distinct attack scenarios single bit-ﬂips lead to.
4.1 Experimental Setup and Methodology
Our vulnerability analysis framework systematically ﬂips the
bits in a model, individually, and quantiﬁes the impact using
the metrics we deﬁne. We implement the framework using
Python 3.73 and PyTorch 1.04 that supports CUDA 9.0 for
accelerating computations by using GPUs. Our experiments
run on the high performance computing cluster that has 488
nodes, where each is equipped with Intel E5-2680v2 2.8GHz
20-core processors, 180 GB of RAM, and 40 of which have 2
Nvidia Tesla K20m GPUs. We achieve a signiﬁcant amount
of speed-up by leveraging a parameter-level parallelism.
Datasets. We use three popular image classiﬁcation
datasets: MNIST [31], CIFAR10 [29], and ImageNet [47].
MNIST is a grayscale image dataset used for handwritten dig-
its (zero to nine) recognition, containing 60,000 training and
10,000 validation images of 28x28 pixels. CIFAR10 and Ima-
geNet are colored image datasets used for object recognition.
CIFAR10 includes 32x32 pixels, colored natural images of
10 classes, containing 50,000 training and 10,000 validation
images. For ImageNet, we use the ILSVRC-2012 subset [46],
resized at 224x224 pixels, composed of 1,281,167 training
and 50,000 validation images from 1,000 classes.
Models. We conduct our analysis on 19 different DNN mod-
els. For MNIST, we deﬁne a baseline architecture, Base (B),
and generate four variants with different layer conﬁgurations:
B-Wide, B-PReLU, B-Dropout, and B-DP-Norm. We also
examine well-known LeNet5 (L5) [31] and test two variants
of it: L5-Dropout and L5-D-Norm. For CIFAR10, we em-
ploy the architecture from [55] as a baseline and experiment
on its three variants: B-Slim, B-Dropout and B-D-Norm. In
the following sections, we discuss why we generate these
variants. In Appendix A, we describe the details of these
custom architectures; in Appendix C, we present the hyper-
parameters. For CIFAR10, we also employ two off-the-shelf
2We use this term to indicate the severe overall accuracy drop in the model.
3https://www.python.org
4https://pytorch.org
network architectures: AlexNet [30] and VGG16 [50]. For Im-
ageNet, we use ﬁve well-known DNNs to understand the vul-
nerability of large models: AlexNet, VGG16, ResNet50 [22],
DenseNet161 [23] and InceptionV3 [56]5.
Metrics. To quantify the indiscriminate damage of sin-
gle bit-ﬂips, we deﬁne the Relative Accuracy Drop as
RAD = (Accpristine−Acccorrupted )/Accpristine; where Accpristine and
Acccorrupted denote the classiﬁcation accuracies of the pristine
and the corrupted models, respectively. In our experiments,
we use [RAD > 0.1] as the criterion for indiscriminate dam-
age on the model. We also measure the accuracy of each class
in the validation set to analyze whether a single bit-ﬂip causes
a subset of classes to dominate the rest. In MNIST and CI-
FAR10, we simply compute the Top-1 accuracy on the test
data (as a percentage) and use the accuracy for analysis. For
ImageNet, we consider both the Top-1 and Top-5 accuracy;
however, for the sake of comparability, we report only Top-1
accuracy in Table 1. We consider a parameter as vulnerable
if it, in its bitwise representation, contains at least one bit
that triggers severe indiscriminate damage when ﬂipped. For
quantifying the vulnerability of a model, we simply count the
number of these vulnerable parameters.
Methodology. On our 8 MNIST models, we carry out a
complete analysis: we ﬂip each bit in all parameters of a
model, in both directions—(0→1) and (1→0)—and compute
the RAD over the entire validation. However, a complete anal-
ysis of the larger models requires infeasible computational
time—the VGG16 model for ImageNet with 138M parame-
ters would take ≈ 942 days on our setup. Therefore, based on
our initial results, we devise three speed-up heuristics that aid
the analysis of CIFAR10 and ImageNet models.
Speed-up techniques. The following three heuristics allow
us to feasibly and accurately estimate the vulnerability in
larger models:
• Sampled validation set (SV). After a bit-ﬂip, deciding
whether the bit-ﬂip leads to a vulnerability [RAD > 0.1]
requires testing the corrupted model on the validation set;
which might be cost prohibitive. This heuristic says that we
can still estimate the model accuracy—and the RAD—on
a sizable subset of the validation set. Thus, we randomly
sample 10% the instances from each class in the respective
validation sets, in both CIFAR10 and ImageNet experiments.
• Inspect only speciﬁc bits (SB). In Sec 2, we showed how
ﬂipping different bits of a IEEE754 ﬂoating-point number
results in vastly different outcomes. Our the initial MNIST
analysis in Sec 4.3 shows that mainly the exponent bits lead to
perturbations strong enough to cause indiscriminate damage.
5The pre-trained ImageNet models we use are available at: https://
pytorch.org/docs/stable/torchvision/models.html.
500    28th USENIX Security Symposium
USENIX Association
Dataset
Network
Base acc.
# Params
B(ase)
B-Wide
B-PReLU
B-Dropout
B-DP-Norm
L5
L5-Dropout
L5-D-Norm
B(ase)
B-Slim
B-Dropout
B-D-Norm
AlexNet
VGG16
95.71
98.46
98.13
96.86
97.97
98.81
98.72
99.05
83.74
82.19
81.18
80.17
83.96
91.34
21,840
85,670
21,843
21,840
21,962
61,706
61,706
62,598
776,394
197,726
776,394
777,806
2,506,570
14,736,727
SV








(83.74)
(82.60)
(80.70)
(80.17)
(85.00)
(91.34)
T
S
I
N
M
0
1
R
A
F
I
C
t
e
N
e
g
a
m
I
Speed-up heuristics
Vulnerablility
SB








(exp.)
(exp.)
(exp.)
(exp.)
(exp.)
(exp.)
(31st bit)
(31st bit)
(31st bit)
(31st bit)
(31st bit)
SP
# Params
Ratio














(20,000)
(20,000)
(20,000)
(20,000)
(20,000)
10,972
42,812
21,663
10,770
11,195
28,879
27,806
30,686
363,630
92,058
314,745
357,448
1,185,957
6,812,359
9,467 SP
8,414 SP
9,565 SP
9,790 SP
8,161 SP
50.24%
49.97%
99.18%
49.35%
50.97%
46.80%
45.06%
49.02%
46.84%
46.68%
40.54%
45.96%
47.31%
46.23%
47.34%
42.07%
47.82%
48.95%
40.84%
AlexNet
VGG16
ResNet50
DenseNet161
InceptionV3
56.52 / 79.07
79.52 / 90.38
76.13 / 92.86
77.13 / 93.56
69.54 / 88.65
61,100,840
138,357,544
25,610,152
28,900,936
27,197,488
(51.12 / 75.66)
(64.28 / 86.56)
(69.76 / 89.86)
(72.48 / 90.94)
(65.74 / 86.24)
SV = Sampled Validation set
SB = Speciﬁc Bits
SP = Sampled Parameters set
Table 1: Indiscriminate damages to 19 DNN models caused by single bit-ﬂips.
This observation is the basis of our SB heuristic that tells us
to examine the effects of ﬂipping only the exponent bits for