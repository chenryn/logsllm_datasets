trie level
SAIL basic algorithm
SAIL B
SAIL U SAIL B + updated oriented optimization
SAIL L
SAIL M SAIL L extension for multiple FIBs
SAIL B + lookup oriented optimization
a(i,j)
integer value of bit string of a
from i-th bit to j-th bit
a FIB has 33 levels. For each level i, we construct a bit map
array Bi[0..2i − 1] of length 2i, and the initial values are all
0s. At each level i (0 ≤ i ≤ 32), for each node v, letp (v)
denote its corresponding preﬁx and |p(v)| denote the value
of the binary string part of the preﬁx (e.g., |11 ∗ | = 3). If v
is solid, then we assign Bi[|p(v)|] = 1; otherwise, we assign
Bi[|p(v)|] = 0. Here |p(v)| indicates the horizontal position
of node v because if the trie is a complete binary tree then
v is the |p(v)|-th node on leveli . Figure 2(c) shows the bit
maps for levels 0 to 4 of the trie in 2(b). Taking bit map B3
for level 3 as an example, for the two solid nodes correspond-
ing to preﬁxes 001*/3 and 111*/3, we have B3[1] = 1 and
B3[7] = 1. Given the 33 bit maps B0, B1,··· , B32 that we
constructed from the trie for a FIB, for any given IP address
a, for i from 32 to 0, we test whether Bi[a >> (32− i)] = 1;
once we ﬁnd the ﬁrst i that Bi[a >> (32 − i)] = 1 holds,
we know that the longest matching preﬁx length is i. Here
a >> (32− i) means right shifting a by 32− i bits. For each
bit map Bi, we construct a next hop array Ni[0..2i − 1],
whose initial values are all 0s. At each level i, for each preﬁx
p of length i in the FIB, denoting the next hop of preﬁx p
by n(p), we assign Ni[|p|] = n(p). Thus, for any given IP
address a, once we ﬁnd its longest matching preﬁx length i,
then we know its next hop is Ni[a >>(32 − i)].
FIB
prefix
*/0
1*/1
01*/2
001*/3
111*/3
0011*/4
1110*/4
11100*/5
001011*/6
(a)
next-
hop
6
4
3
3
7
1
8
2
9
level 0
level 1
level 2
level 3
Trie
6
4
3
O
3
A
B
1
C
8
88
F
3
D
3
E
2
G
9
(b)
B0
B1
B2
B3
B4
N4
N3
7
H
8
Bit maps
1
0
1
0 1
0 0
0 1
0 0
0 0
0 1
0 0
1 1
0 0 (cid:3257) 
01
0 0
0 1
0 0 (cid:3257) 
00
0 3
0 0
0 0
0 7
(c)
Figure 2: Basic SAIL Algorithm.
413.2 Splitting Preﬁx Length
Based on our observation that almost all the traﬃc of
backbone routers has the longest matching preﬁx length
≤ 24, we split all preﬁxes in the given FIB into preﬁxes
of length ≤ 24, which we call short preﬁxes and preﬁxes of
length ≥ 25, which we call long preﬁxes. By this splitting,
we want to store the bit maps of preﬁxes of length ≤ 24 in
on-chip memory. However, given an IP address, because it
may match a long preﬁx, it seems that we need to search
among both short and long preﬁxes, which makes this split-
ting not much useful. In this paper, we propose a technique
called pivot pushing to address this issue. Our basic strategy
is that for a given IP address, we ﬁrst test its longest match-
ing preﬁx length is within [0, 24] or [25, 32]; thus, after this
testing, we continue to search among either short preﬁxes or
long preﬁxes, but not both. We call level 24 the pivot level.
Given a trie and a pivot level, the basic idea of pivot push-
ing is two-fold. First, for each internal solid node on the pivot
level, we push its label (i.e., the next hop) to a level below
the pivot level. Second, for each internal empty nodes on
the pivot level, we let it inherit the label of its nearest solid
ancestor node, i.e., the next hop of the ﬁrst solid node along
the path from this empty node to the root, and then push
this inherited label to a level below the pivot level. In this
paper, we assume that the root always has a label, which is
the default next hop. Thus, for any internal empty nodes on
the pivot level, it always can inherit a label.
Given a trie and an IP address a, traversing a from the
root of the trie downward, for any internal or leaf node v
that the traversal passes, we say a passes v. Based on the
above concepts, we introduce Theorem 3.1.
Theorem 3.1. Given a trie constructed from a FIB, after
pivot pushing, for any IP address a, a passes a node on the
pivot level if and only if its longest matching preﬁx is on the
pivot level or below.
Proof. Given a trie and an IP address a that passes a
node v on the pivot level, there are two cases: (1) v is a
leaf node, and (2) v is an internal node. For the ﬁrst case
where v is a leaf node, then a’s longest matching preﬁx is
p(v) (i.e., the preﬁx represented by node v) and thus a’s
longest matching preﬁx is on the pivot level. For the second
case where v is an internal node, because of pivot pushing,
a must pass a solid node on a level below the pivot level,
which means that a’s longest matching preﬁx is below the
pivot level.
Based on Theorem 3.1, we construct the bit map for the
pivot level l as follows: for any node v on level l, we assign
Bl[|p(v)|] = 1; in other words, Bl[i] = 0 if and only if there
is no node on level l that corresponds to the preﬁx denoted
by i. Thus, given an IP address a, Bl[a >>(32 − l)] = 1 if
and only if its longest matching preﬁx is on the pivot level
or below. In SAIL, we choose level 24 to be the pivot level.
By checking whether B24[a >>8] = 1, we know whether the
longest matching preﬁx length is ≤ 23 or ≥ 24, which will
guide us to search either up or down. Consider the example
in Figure 2(b), taking level 4 as the pivot level, node C on
level 4 is an internal solid node, pushing C to level 5 results
in a new leaf solid node H with the same next hop as C. Note
that after pushing node C down, node C becomes empty.
Given a pivot pushed trie, we build a bit map array and a
next hop array for each level of 0 to 24 as above. Note that for
any i (0 ≤ i ≤ 23) and any j (0 ≤ j ≤ 2i−1), Bi[j] = 1 if and
only if there is a solid node on level i that corresponds to the
preﬁx denoted by j; for level 24 and any j (0 ≤ j ≤ 224 − 1),
B24[j] = 1 if and only if there is a node, no matter solid or
empty, on level 24 that corresponds to the preﬁx denoted by
j. Note that B24[j] = 1 and N24[j] > 0 if and only if there is
a leaf node on level 24 that corresponds to the preﬁx denoted
by j, which means that the longest matching preﬁx length is
24. Note that B24[j] = 1 and N24[j] = 0 if and only if there
is an empty node on level that corresponds to the preﬁx
denoted by j, which means that the longest matching preﬁx
length is ≥ 25. Thus, given an IP address a, ifB 24[a >>
8] = 0, then we further check whether B23[a >> 9] = 1,
··· , B0[a >> 32] = 1 until we ﬁnd
B22[a >>10] = 1,
the ﬁrst 1; if B24[a >>8] = 1, then we know a’s longest
matching preﬁx length is ≥ 24 and further lookup its next
hop in oﬀ-chip memory. It is easy to compute that the on-
i=0 2i = 4M B. Consider the
chip memory usage is ﬁxed as
example in Figure 2. Given an address 001010, as the pivot
level is 4, sinceB 4[001010 >> 2] = B4[0010] = B4[2] = 1
and N4[001010 >> 2] = N4[0010] = N4[2] = 0, then we
know that the longest matching preﬁx length is longer than
4 and we will continue the search on levels below 4.
(cid:2)24
The pseudocode for the above SAIL Basic, denoted by
SAIL B, is shown in Algorithm 1.
Algorithm 1: SAIL B
Input: Bit map arrays: B0, B1,··· , B24
Input: Next hop arrays: N0, N1,··· , N24
Input: a: an IP address
Output: next hop of the longest matched preﬁx
if Bj[a >>(32 − j)]=1 then
return Nj[a >> (32 − j)]
end
end
for j = 23; j > 0; j − − do
1 if B24[a >>8]=0 then
2
3
4
5
6
7 end
8 else if N24[a >> 8]>0 then
9
return N24[a >> 8];
10 end
11 else
12
13 end
lookup on levels 25∼32;
There are multiple ways to handle preﬁxes of length ≥
25. Below we give one simple implementation using next
hop arrays. Let the number of internal nodes on level 24
be n. We can push all solid nodes on levels 25∼31 to level
32. Afterwards, the number of nodes on level 32 is 256 ∗
n because each internal node on level 24 has a complete
subtree with 256 leaf nodes, each of which is called a chunk.
As typically 256 ∗ n is much smaller than 232 based on our
experimental results on real FIBs, constructing a next hop
array of size 232 wastes too much memory; thus, we construct
a next hop array N32 of size 256 ∗ n for level 32. As we
push all solid nodes on levels from 25 to 31 to level 32,
we do not need bit maps B25, B26,··· , B32. Now consider
the nodes on level 24. For each leaf node, its corresponding
entry in bit map B24 is 1 and its corresponding entry in
42next hop array N24 is the next hop of this node. For each
internal node, its corresponding entry in bit map B24 is 1
and its corresponding entry in next hop array N24 is the
chunk ID in N32, multiplying which by 256 plus the last 8
bits of the given IP address locates the next hop in N32. To
distinguish these two cases, we let the next hop be a positive
number and the chunk ID to be a negative number whose
absolute value is the real chunk ID value. To have negative
values, chunk IDs are named starting from 1. With our pivot
pushing technique, looking up an IP address a is simple: if
B24[a >> 8] = 0, then we know the longest matching preﬁx
length is within [0, 23] and further test whether B23[a >>
8] = 1; if B24[a >> 8] = 1∧ N24[a >> 8] > 0, then we know
that the longest matching preﬁx length is 24 and the next
hop is N24[a >> 8]; if B24[a >>8] = 1 ∧ N24[a >>8] >8]|− 1)∗
256 + (a&255)].
3.3 FIB Update for SAIL Basic
We now discuss how to adjust the lookup data structures
when the given FIB changes. Note that the FIB update per-
formance for levels 25∼32 is less critical than that for levels
0∼24. As most traﬃc hits levels 0∼24, when the lookup
data structures for levels 0∼24 in on-chip memory change,
no lookup can be performed before changes are ﬁnished and
therefore may cause packet losses. For the lookup data struc-
tures in oﬀ-chip memory, one possible solution is to store
two copies of the lookup data structures in two memory
chips so that while one copy is being updated, the other
copy can be used to perform lookups. Furthermore, many
IP lookup schemes that can handle preﬁxes of length ≥ 25
can be plugged into SAIL B. Diﬀerent IP lookup schemes
have diﬀerent FIB update algorithms. Therefore, in this pa-
per, we focus on the update of data structures in on-chip
memory.
For SAIL B, updating the on-chip lookup data structures
is simple: given an update preﬁx p with length of l, whose
next hop is denoted by h where h = 0 means to withdraw
preﬁx p and h >0 means to announce preﬁx p, ifl  0) (i.e., ifh > 0, then we assign
Bl[|p|] = 1; otherwise, we assign Bl[|p|] = 0). If l = 24, for
the same update, we ﬁrst locate the node in the trie, if it
is an internal node, then B24 is kept unchanged; otherwise,
we assign B24[|p|] = (h > 0). Note that for one FIB up-
date, we may need to update both the on-chip and oﬀ-chip
lookup data structures. A router typically maintains the trie
data structure on the control plane and uses it to compute
the changes that need to be made to oﬀ-chip lookup data
structures. Because little traﬃc hits the oﬀ-chip lookup da-
ta structures for levels 25∼32, updating the oﬀ-chip lookup
data structures often can be performed in parallel with IP
lookups on the on-chip data structures.
4. SAIL OPTIMIZATION
In this section, we ﬁrst present two optimization tech-
niques of our SAIL algorithms, which favors the performance
of FIB update and IP lookup, respectively. We use SAIL U
to denote SAIL B with update oriented optimization, and
SAIL L to denote SAIL B with lookup oriented optimiza-
tion. Then, we extend SAIL L to handle multiple FIBs.
4.1 Update Oriented Optimization
Data Structures & Lookup Process: In this optimiza-
tion, by preﬁx expansion, we push all solid nodes on levels
0 ∼ 5 to level 6, all solid nodes on levels 7 ∼ 11 to level 12,
all solid nodes on levels 13 ∼ 17 to level 18, and all solid
nodes on levels 19 ∼ 23 to level 24. With this 4-level push-
ing, looking up an IP address a is the same as without this
pushing, except that if B24[a >> 8] = 0, then we further
check whether B18[a >> 14] = 1, B12[a >> 20] = 1, and
B6[a >> 26] = 1 till we get the ﬁrst 1. This 4-level push-
ing brings two beneﬁts to IP lookup. First, it reduces the
maximum number of array lookups in on-chip memory from
24 to 4. Second, it reduces the on-chip memory usage by
49.2% because we do not need to store B0 ∼ B5, B7 ∼ B11,
B13 ∼ B17, andB 19 ∼ B23.
FIB Update: While improving lookup speed and reduc-
ing on-chip memory usage, this pushing incurs no extra cost
to the update of on-chip data structures. With this pushing,
we still achieve one on-chip memory access per FIB update
because of three reasons. First, for any FIB update, it at
most aﬀects 26 = 64 bits due to the above pushing. Second,
typically by each memory access we can read/write 64 bits