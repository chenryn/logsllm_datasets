### Optimized Text

The effectiveness of a model in predicting Data-Correcting Node Unavailability (DCNU) is primarily determined by its precision. If the precision is less than a certain threshold \( y_{\text{tm}} \), the Node Unavailability Reduction Rate (NURR) becomes negative, indicating that inaccurate predictions can lead to an increase in node unavailability. Conversely, a high-precision model ensures a positive NURR, and the recall further enhances the reduction in unavailability.

Given that our problem definition differs significantly from previous studies, there are no existing methods for direct comparison. The most relevant work is on UE prediction [2], [16]. We adapt two UE predictors to our environment: CE Threshold [16] and a random forest-based UE predictor [2]. Additionally, we explore simple heuristic rules based on thresholds for faulty rows and columns. Our evaluation includes four baselines:

1. **CE Threshold**: This method triggers a DCNU alert when the CE count exceeds a certain threshold within the last 24 hours [16]. We fine-tune the threshold to achieve the best NURR.
2. **RF-based UE Predictor**: This uses a random forest to predict UEs based on basic memory error statistics [2]. We retrain the model using DCNUs instead of UEs and optimize the hyperparameters for the best NURR.
3. **Faulty-Row Threshold**: A node is predicted to be unavailable if the number of faulty rows in its history exceeds a specified threshold.
4. **Faulty-Column Threshold**: Similar to the Faulty-Row Threshold, but based on faulty columns.

For XBrainM, we evaluate the performance of its rule-based prediction (XBrainM-Rule), XGBoost-based prediction (XBrainM-XGB), and the hybrid approach that predicts a DCNU if either the rule or XGBoost predicts one.

**Table III** shows the comparison results. First, since the rules used in XBrainM can be considered a superset of the threshold-based baselines, XBrainM-Rule achieves slightly better performance (2% to 9% higher NURR) than the baselines. Second, the machine learning model in XBrainM, XBrainM-XGB, consistently outperforms the baselines across all three datasets, achieving at least 30% higher F1-score and 37% higher NURR. Finally, the hybrid approach demonstrates the best F1-score and NURR, with improvements of more than 40% over the baselines.

### VII. Experiments

#### A. Experiment Setup

**Dataset**: The dataset for offline evaluation was collected from over half a million nodes in the ECS system over one year, covering multiple CPU generations and DIMMs from various vendors, generations, and capacities. These nodes have different hardware specifications, such as varying CPU generations, DIMM vendors, and memory capacities. We processed the raw data to generate over 1TB of structured data.

**Table III: Recall / Precision / F1-Score / NURR of Different Prediction Approaches**

| Dataset  | CE Threshold        | RF-based UE Predictor | Faulty-Row Threshold | Faulty-Column Threshold | XBrainM-Rule         | XBrainM-XGB         | XBrainM-Rule+XGB    |
|----------|---------------------|-----------------------|----------------------|-------------------------|----------------------|---------------------|---------------------|
| Dataset1 | 0.24 / 0.34 / 0.28 / 0.17 | 0.50 / 0.18 / 0.26 / 0.22 | 0.41 / 0.25 / 0.31 / 0.23 | 0.48 / 0.20 / 0.28 / 0.22 | 0.30 / 0.62 / 0.41 / 0.25 | 0.75 / 0.51 / 0.61 / 0.60 | 0.77 / 0.68 / 0.72 / 0.65 |
| Dataset2 | 0.36 / 0.17 / 0.23 / 0.15 | 0.46 / 0.16 / 0.23 / 0.17 | 0.37 / 0.23 / 0.28 / 0.19 | 0.40 / 0.17 / 0.24 / 0.16 | 0.33 / 0.58 / 0.42 / 0.28 | 0.77 / 0.48 / 0.59 / 0.61 | 0.83 / 0.65 / 0.73 / 0.70 |
| Dataset3 | 0.36 / 0.17 / 0.23 / 0.15 | 0.39 / 0.22 / 0.28 / 0.21 | 0.35 / 0.18 / 0.24 / 0.14 | 0.81 / 0.15 / 0.26 / 0.26 | 0.35 / 0.60 / 0.44 / 0.29 | 0.79 / 0.49 / 0.60 / 0.63 | 0.78 / 0.67 / 0.72 / 0.66 |

**Table IV: Performance of Different ML Models in XBrainM**

| Model            | Recall  | Precision | F1      | NURR   |
|------------------|---------|-----------|---------|--------|
| XBrainM-SVM      | 55.73%  | 29.32%    | 38.86%  | 45.72% |
| XBrainM-XGB      | 79.34%  | 48.65%    | 60.31%  | 63.03% |
| XBrainM-RF       | 68.57%  | 49.26%    | 54.65%  | 57.33% |
| XBrainM-LR       | 51.30%  | 41.23%    | 38.42%  | 36.72% |

**Table V: Performance on Different Feature Combinations**

| Feature Combination | Recall  | Precision | F1      | NURR   |
|---------------------|---------|-----------|---------|--------|
| All Features        | 79.34%  | 48.65%    | 60.31%  | 63.03% |
| Excluding Static    | 70.08%  | 50.84%    | 56.29%  | 58.93% |
| Excluding Temporal  | 67.01%  | 43.01%    | 51.43%  | 52.39% |
| Excluding Spatial   | 67.35%  | 38.57%    | 49.89%  | 49.05% |
| Top-20 Only         | 72.64%  | 37.22%    | 49.22%  | 53.12% |

With simple rules and an effective learning model, XBrainM consistently achieves over 77%, 65%, 72%, and 65% in recall, precision, F1-score, and NURR, respectively.

#### C. Comparison of Various Prediction Models

We explored the use of different ML models in XBrainM and performed head-to-head comparisons among XGBoost, Random Forest (RF), Support Vector Machine (SVM), and Logistic Regression (LR). **Table IV** shows the recall, precision, F1-score, and NURR for these models. SVM and LR perform relatively well but are still inferior to RF and XGBoost. XGBoost achieves the highest F1-score and NURR, at 60.31% and 63.03%, respectively. This means that when deployed online, it can reduce node unavailability caused by DRAM faults by approximately 63.03%. Therefore, we use XGBoost as the default learning-based prediction model in XBrainM.

#### D. Feature Evaluation

**Feature Importance**: To understand the underlying causes of DCNU, we quantified the importance of each feature. **Figure 7** illustrates the top 20 important features, including 10 spatial and 10 temporal features. Both spatial and temporal features are crucial indicators of DCNU. The most important spatial features are `s single hard error b max` and `s single hard error b sum`, which represent the maximum and sum of single hard errors from the fault banks of a node. For temporal features, the events in the 3-hour window (`t mcelog ce count 3h` and `t mce killing 3h`) contribute most to the prediction, indicating that temporal error statistics in this time frame are strongly related to DCNUs.

**Effectiveness of Feature Engineering**: We also examined the importance of static, spatial, and temporal features by excluding them from the feature list. The experimental results are shown in **Table V**. As seen in the table, static features are less important, and the NURR decreases by no more than 7%. Both temporal and spatial features significantly contribute to the final results, with the NURR decreasing by over 11% and 13%, respectively, when these features are excluded.

Spatial features are the most important in prediction, indicating that DCNU occurrences are related to micro-level spatial fault characteristics [16], [21]. To evaluate whether we need so many features, we trained the XGBoost model with only the top-20 important features. **Table V** shows that the NURR decreases by roughly 10%. In a large-scale cloud, a 10% reduction in node unavailability is significant and valuable, especially considering the scale of the system.

**Figure 8** shows the parameter tuning and leading time analysis. The ROC curve in offline evaluation has an AUC of 0.927, and the leading time versus the proportion of leading time is also depicted.