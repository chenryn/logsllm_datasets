tu is always positive, precision determines DCNU
prediction is beneﬁcial or not. If precision < y tm
tu , the NURR
becomes negative, which indicates that inaccurate predictions
may even cause more nodes to be unavailable. In contrast, a
high-precision model can always achieve positive NURR, and
recall then ampliﬁes the unavailability reduction magnitude.
(2)
(3)
(4)
(5)
(6)
(7)
Since the deﬁnition of our problem is totally different from
prior studies, there is no existing methods for reference and
comparison. The most relevant work is UE prediction [2], [16].
Hence, we adapt two UE predictors in our environments to
predict DCNUs: CE Threshold [16] and UE predictor based on
random forest [2]. We also explore the use of simple heuristic
rules based on threshold of faulty rows and columns. Finally,
four baselines are included in our evaluation.
1. CE Threshold reports a DCNU alert when the CE
count reaches a certain threshold in recent 24 hours [16]. We
carefully tune the threshold and report the best NURR.
2. RF-based UE Predictor uses random forest to predict
UEs with a set of basic memory error statistics [2]. We use
DCNUs instead of UEs to train the model and carefully tune
the hyperparameters to achieve the best NURR.
3. Faulty-Row Threshold. A node will be predicted to be
unavailable if the number of faulty rows accumulated in the
history exceeds a threshold.
4. Faulty-Column Threshold. Similar
to Faulty-Row
Threshold.
As to XBrainM, we evaluate the individual performance
of its rule-based prediction (XBrainM-Rule), XGBoost-based
prediction (XBrainM-XGB), and the hybrid approach actually
used in XBrainM that predicts a DCNU if any of the rule or
XGBoost predict a DCNU.
Table III shows the comparison results. Firstly, as the rules
used in XBrainM can be considered as a superset of the
threshold-based baselines, XBrainM-Rule achieves slightly-
better performance (2%˜9% higher NURR) than the baselines.
Secondly, the ML model of XBrainM, i.e., XBrainM-XGB,
consistently outperforms the baselines in the three datasets.
With more effective features, XBrainM-XGB can achieve at
least 30% absolutely higher F1-score and 37% absolutely
higher NURR than the baselines. Last but not
the
hybrid approach demonstrates the best F1-score and NURR
that are more than 40% absolutely better than the baselines.
least,
VII. EXPERIMENTS
A. Experiment Setup
Dataset. The dataset for ofﬂine evaluation is collected from
more than half a million nodes in ECS system in one year
and covers the multiple CPU generations, and the DIMMs of
multiple vendors, generations and capacities, etc. These nodes
incorporate different hardware speciﬁcations, e.g., varying
CPU generation, DIMM vendor, memory capacity, etc. We
process the raw data and generate more than 1TB structured
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:28:25 UTC from IEEE Xplore.  Restrictions apply. 
282
TABLE III: Recall / Precision / F1-socre / NURR of different prediction approaches.
Dataset1
Dataset2
Dataset3
CE Threshold
RF-based UE Predictor
Faulty-Row Threshold
Faulty-Column Threshold
0.24 / 0.34 / 0.28 / 0.17
0.50 / 0.18 / 0.26 / 0.22
0.41 / 0.25 / 0.31 / 0.23
0.48 / 0.20 / 0.28 / 0.22
0.36 / 0.17 / 0.23 / 0.15
0.46 / 0.16 / 0.23 / 0.17
0.37 / 0.23 / 0.28 / 0.19
0.40 / 0.17 / 0.24 / 0.16
0.36 / 0.17 / 0.23 / 0.15
0.39 / 0.22 / 0.28 / 0.21
0.35 / 0.18 / 0.24 / 0.14
0.81 / 0.15 / 0.26 / 0.26
XBrainM-Rule
XBrainM-XGB
XBrainM-Rule+XGB
0.30 / 0.62 / 0.41 / 0.25
0.75 / 0.51 / 0.61 / 0.60
0.77 / 0.68 / 0.72 / 0.65
0.33 / 0.58 / 0.42 / 0.28
0.77 / 0.48 / 0.59 / 0.61
0.83 / 0.65 / 0.73 / 0.70
0.35 / 0.60 / 0.44 / 0.29
0.79 / 0.49 / 0.60 / 0.63
0.78 / 0.67 / 0.72 / 0.66
TABLE IV: Performance of different ML models in XBrainM.
Recall
79.34%
68.57%
51.30%
XBrainM-SVM 55.73%
XBrainM-XGB
XBrainM-RF
XBrainM-LR
Precision
48.65%
49.26%
41.23%
29.32%
F1
NURR
60.31% 63.03%
54.65%
57.33%
38.86%
45.72%
38.42%
36.72%
TABLE V: Performance on different feature combinations.
All Features
Excluding Static
Excluding Temporal
Excluding Spatial
Top-20 Only
Recall
79.34%
70.08%
67.01%
67.35%
72.64%
Precision
48.65%
50.84%
43.01%
38.57%
37.22%
F1
NURR
60.31% 63.03%
56.29%
58.93%
51.43%
52.39%
49.89%
49.05%
49.22%
53.12%
With the simple rules and effective learning model, XBrainM
consistently achieves over 77%, 65%, 72%, and 65% of recall,
precision, F1-score and NURR, respectively.
C. Comparison of Various Prediction Models
We then explore the use of different ML models in XBrainM
and perform head-to-head comparisons among XGBoost, RF,
SVM, and LR. Table IV shows the recall, precision, F1-score
(denoted as F1), and NURR with 4 different models. SVM
and LR perform relatively well but are still inferior to RF and
XGBoost. XGBoost achieves the highest F1-score and NURR,
which are 60.31% and 63.03%, respectively. It means when the
model is deployed online, it can roughly reduce 63.03% node
unavailability caused by DRAM faults. So, we use XGBoost
as the default learning-based prediction model in XBrainM.
D. Feature Evaluation
Feature importance. To understand the underlying causes of
DCNU, we expect to quantify the importance of each feature.
Fig. 7 illustrates the top 20 important features relevant to
DCNU, including 10 spatial (beginning with ‘s ’) and 10
temporal features respectively. It indicates that both spatial and
temporal features are important indicators of DCNU. The most
important spatial features are s single hard error b max, and
s single hard error b sum;
they are the max and sum of
single hard errors from the fault banks of a node. For temporal
features, the events in 3 hours t mcelog ce count 3h and
t mce killing 3h contribute most to the prediction. It indicates
that the temporal error statistics in the 3-hour time window are
strongly relevant to DCNUs.
Effectiveness of feature engineering. We also examine the
importance of static, spatial, and temporal1 features respec-
tively by excluding them from the feature list. The experi-
mental results are shown in Table V. As we can see from the
table, the static features are less important, and the NURR
1CE counts, kernel events, and their temporal aggregations.
s single hard error b max
t mcelog ce count sum 3h
s single hard error b sum
s singe hard error b avg 28d
t mce killing std 3h
s single hard error b max 7d
t mce killing sum 3h
t suppressed mce notify sum 3h
s error row sum 1d
s error cell b sum
t suppressed mce notify std 3h
s error colomn b sum
t mcelog ce count diff 3h
t mce killing std 3h
s error bank count
t mcelog ce count skew 3h
s single hard error b max
s ce count col max b max 1d
t kernel edac sum 3h
t suppressed mce notify std 3h
0
1000
2000
3000
Fig. 7: Feature importance of the XGBoost model.
decreases no more than 7%. Both the temporal and spatial
features contribute a lot to the ﬁnal results as the NURR
decreases over 11% and 13% respectively, without including
those features.
The spatial features are most important in prediction, and it
again indicates that DCNU occurrences are relevant to micro-
level spatial fault characteristics [16], [21]. Furthermore, to
evaluate whether we need so many features, we train the
XGBoost model with only the top-20 important features. Table
V shows that the NURR decreases roughly 10%. In such a
large-scale cloud, 10% node unavailability reduction impacts
a lot and is quite valuable, especially considering that the
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:28:25 UTC from IEEE Xplore.  Restrictions apply. 
283
1.0
0.8
0.6
0.4
0.2
e
u
l
a
v
c
i
r
t
e
M
0.0
0.0
Best F1-Score
Best NURR
Recall
Precision
F1-Score
NURR
0.2
0.4
0.6
0.8
1.0
Decision Threshold
(a) Ofﬂine evaluation, varying decision threshold.
1.0
0.8
0.6
0.4
0.2
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
0.0
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
n
o
i
t
r
o
p
o
r
P
1.0
0.8
0.6
0.4
0.2
0.0
1
(15,0.89)
1e2
10
Leading time (in minute)
1e3
1e4
1e5
(b) ROC curve in ofﬂine evaluation (AUC =
0.927).
Fig. 8: Parameter tuning and leading time.
(c) Leading time versus proportion of leading time
.
n
o
i
s
i
c
e
r
P
d
n
a
l
l
a
c
e
R
1.0
0.8
0.6
0.4
0.2
0.0
Recall
Precision
1 2 3 4 5 6 7 8 9 10 11 12
Time (in month)
e
t
a
r
U
N
C
D
e
v
i
t
a
l
e
R
1.0
0.8
0.6
0.4
0.2
0.0
1 3
6
XBrainM
Deployment
9
12 15 18 21 24
Time (in month)
e
m
i
t
U
N
C
D
l
a
t