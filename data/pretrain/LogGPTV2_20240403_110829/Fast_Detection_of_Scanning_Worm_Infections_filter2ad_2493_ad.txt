### Optimized Text

#### Forged Response Attack
After half the timeout period, Worm A can send a message to Worm B, requesting it to forge a connection response. This forged response attack prevents the system from detecting connection failures. To counter this attack for TCP connections, a worm detection system implemented on a router can modify the TCP sequence numbers of traffic as it enters and leaves the network. For example, a hash function \( h(\text{IP}_{\text{local}}, \text{IP}_{\text{remote}}, \text{salt}) \) can be added to all outgoing sequence numbers and subtracted from all incoming sequence numbers. The use of a secret salt prevents infected hosts from calculating the sequence number used to respond to a connection request they have sent but not received. By storing the correct sequence number in the FCC queue, responses can be validated by the worm detection system.

#### Known-Replier Attack
Another concern is the possibility that a worm could arrive at its target already in possession of a list of known repliers—hosts that are known to reply to connection requests at a given port. This known-replier attack could employ lists programmed into the worm at creation or accumulated as the worm spreads through the network. First-contact connections to these known repliers are very likely to succeed and can be interleaved with scans to raise the first-contact connection success rate. A one-to-one interleaving is likely to ensure that more than half of all connections succeed, enabling the scanner to bypass credit-based connection rate limiting and delay detection by Reverse Sequential Hypothesis Testing until the scanner has contacted all known repliers. Worse still, a worm could avoid detection altogether if the detection system defines a first-contact connection with respect to a fixed-size previously contacted host (PCH) set. If the PCH set tracks only the \( n \) previously visited hosts, the scanner can cycle through \( (n/2) + 1 \) known repliers, interleaved with as many new addresses, and never be detected. To prevent a worm from scanning your local network by interleaving connections to known repliers outside of your network, Weaver et al. [26] propose running one hypothesis test for local connections (i.e., those within the same IP block) and another for connections to remote hosts. If hosts in your local network are widely and randomly dispersed through a large IP space, the worm will have a low probability of finding another host to infect before being quarantined.

#### Interleaving Scanning with Benign Behavior
A worm might also avoid detection by interleaving scanning with other apparently benign behavior, such as web crawling. A subset of these benign interleaving attacks can be prevented by detecting scanners based on the destination port they target in addition to the source IP of the local host. While it is still fairly easy to create benign-looking traffic for ports such as HTTP, where one connection can lead to information about other active hosts receptive to new connections, this is not the case for ports such as those used by SSH. Running separate scan detection tests for each destination port that a local host addresses can ensure that connections to one service aren’t used to mask scans to other services.

#### Address Impersonation Attacks
Finally, if an infected host can impersonate other hosts, it could escape quarantine and cause other (benign) hosts to be quarantined. To address these address impersonation attacks, it is important that a complete system for network quarantining includes strong methods for preventing IP masquerading by its local hosts, such as switch-level egress filtering. Host quarantining should also be enforced as close to the host as possible without relying on the host to quarantine itself. If these boundaries cannot be enforced between each host, one must assume that when one machine is infected, all machines within the same boundary will also be infected.

#### Related Work
Our work was motivated by the research of Moore et al. [10], who model attempts at containing worms using quarantining. They perform theoretical simulations, many of which use parameters from the CodeRed II [4, 20] outbreak. They argue that it is impossible to prevent systems from being vulnerable to worms and that treatment cannot be performed fast enough to prevent worms from spreading, leaving containment (quarantining) as the most viable way to prevent worm outbreaks from becoming epidemics.

Early work on containment includes Staniford et al.’s GrIDS Intrusion Detection System [19], which advocates the detection of worms and viruses by tracing their paths through the departments of an organization. More recently, Staniford [16] has generalized these concepts by extending models for the spread of infinite-speed, random scanning worms through homogeneous networks divided into 'cells'. Simulating networks with \( 2^{17} \) hosts (two class B networks), Staniford limits the number of first-contact connections that a local host initiates to a given destination port to a threshold, \( T \). While he claims that for most ports, a threshold of \( T = 10 \) is achievable in practice, HTTP and KaZaA are exceptions. In comparison, reverse sequential hypothesis testing reliably identifies HTTP scanning in as few as 10 observations.

The TRAFEN [2, 3] system also observed failed connections for the purpose of identifying worms. The system was able to observe larger networks without access to endpoints by inferring connection failures from ICMP messages. One problem with acting on information at this level is that an attacker could spoof source IP addresses to cause other hosts to be quarantined.

Our use of rate limiting to buy time to observe worm behavior was inspired by the virus throttle presented by Twycross and Williamson [22], which we described in detail in Section 3. Worms can evade a throttle by scanning at rates below one connection per second, allowing epidemics to double in size as quickly as once every two seconds.

An approach similar to ours has been simultaneously developed by Weaver, Staniford, and Paxson [26]. Their approach combines the rate limiting and hypothesis testing steps by using a reverse sequential hypothesis test that (like our CBCRL algorithm) assumes that connections fail until they are proven to succeed. As with CBCRL, out-of-order processing could cause a slight increase in detection delay, as the successes of connections sent before an infection event may be processed after connections initiated after the infection event. In the context of their work, where high-performance monitoring of large networks is a key goal, the performance benefits are likely to outweigh the slight cost in detection speed.

For a history and recent trends in worm evolution, we recommend the work of Kienzle and Elder [8]. For a taxonomy of worms and a review of worm terminology, see Weaver et al. [25].

#### Future Work
As worm authors become aware of the limitations discussed in Section 6, it will be necessary to revise our algorithms to detect scanning at the resolution of the local host (source address) and targeted service (destination port), rather than looking at the source host alone. Solutions for managing the added memory requirements imposed by this approach have been explored by Weaver, Staniford, and Paxson [26].

The intrusiveness of credit-based connection rate limiting, which currently drops outgoing connection requests when credit balances reach zero, can be further reduced. Instead of halting outgoing TCP first-contact connection requests from hosts that do not maintain a positive credit balance, the requests can be sent immediately, and the responses held until a positive credit balance is achieved. This improvement reduces the delays caused by false rate limiting while ensuring that fewer connections are allowed to complete when a high-speed scanning worm issues a burst of connection requests. As a result, the remaining gap in response speed between credit-based connection rate limiting and Twycross and Williamson’s virus throttle can be closed, further decreasing the risk of acting on false positives.

Finally, we would like to employ additional indicators of infection to further reduce the number of first-contact connection observations required to detect a worm. For example, it is reasonable to conclude that, when a host is deemed to be infected, those hosts to which it has most recently initiated successful connections are themselves more likely to be infected (as was the premise behind GrIDS [19]). We propose adding an event type, the report of an infection of a host that has recently contacted the current host, to our existing hypothesis test.

#### Conclusion
When combined, credit-based connection rate limiting and reverse sequential hypothesis testing ensure that worms are quickly identified with an attractively low false alarm rate. While no system can detect all possible worms, our new approach is a significant improvement over prior methods, which detect a smaller range of scanners and unnecessarily delay network traffic. The techniques introduced in this paper lend themselves to efficient implementation, as they need only be activated to observe a small subset of network events and require little calculation for the common case that traffic is benign.

#### Acknowledgments
This paper could not have been completed without the continued support of Vern Paxson and Hari Balakrishnan. We are indebted to Dave Andersen and Noah Case for the network logs used for our analysis. We would also like to thank the anonymous reviewers as well as Nick Feamster, David Molnar, Rodrigo Miragaia Rodrigues, David Savitt, Matt Williamson, and especially Glenn Holloway for taking the time to review and comment on earlier drafts of this paper. Stuart Schechter would like to thank the National Science Foundation for support under grant CCR-0310877.

#### References
[References remain unchanged]