connection request after half the timeout period, it could send a message to
worm B asking it to forge a connection response. This forged response attack
prevents our system from detecting connection failures. To thwart this attack
for TCP connections, a worm detection system implemented on a router can
modify the TCP sequence numbers of traﬃc as it enters and leaves the network.
, IPremote, salt) may be added
For example, the result of a hash function h(IPlocal
to all sequence numbers on outgoing traﬃc and subtracted from all incoming
sequence numbers. The use of the secret salt prevents the infected hosts from
calculating the sequence number used to respond to a connection request which
they have sent, but not received. By storing the correct sequence number in the
FCC queue, responses can then be validated by the worm detection system.
Another concern is the possibility that a worm could arrive at its target al-
ready in possession of a list of known repliers – hosts that are known to reply
to connection requests at a given port. This known-replier attack could em-
ploy lists that are programmed into the worm at creation, or accumulated by
the worm as it spreads through the network. First-contact connections to these
known-repliers will be very likely to succeed and can be interleaved with scans
to raise the ﬁrst-contact connection success rate. A one to one interleaving is
likely to ensure that more than half of all connections succeed. This success rate
would enable the scanner to bypass credit-based connection rate limiting, and
delay detection by Reverse Sequential Hypothesis Testing until the scanner had
contacted all of its known-repliers. What’s worse, a worm could avoid detection
altogether if the detection system deﬁnes a ﬁrst-contact connection with respect
to a ﬁxed sized previously contact host (PCH) set. If the PCH set tracks only the n
previously visited hosts, the scanner can cycle through (n/2) + 1 known-repliers,
interleaved with as many new addresses, and never be detected4. To prevent a
worm from scanning your local network by interleaving connections to known-
4 For detecting such a worm, a random replacement policy will be superior to an LRU
replacement policy, but will still not be eﬀective enough for long known-replier lists.
76
Stuart E. Schechter, Jaeyeon Jung, and Arthur W. Berger
repliers outside of your network, Weaver et al. [26] propose that one hypothesis
test be run for local connections (i.e. those within the same IP block) and an-
other for connections to remote hosts. If hosts in your local network are widely
and randomly dispersed through a large IP space5, then a worm will have a low
probability of ﬁnding another host to infect before being quarantined.
A worm might also avoid detection by interleaving scanning with other ap-
parently benign behavior, such as Web crawling. A subset of these benign inter-
leaving attacks can be prevented by detecting scanners based on the destination
port they target in addition to the source IP of the local host. While it is still
fairly easy to create benign looking traﬃc for ports such as HTTP, for which
one connection can lead to information about other active hosts receptive to new
connections, this is not the case for ports such as those used by SSH. Running
separate scan detection tests for each destination port that a local host addresses
can ensure that connections to one service aren’t used to mask scans to other
services.
Finally, if an infected host can impersonate other hosts, the host could es-
cape quarantine and cause other (benign) hosts to be quarantined. To address
these address impersonation attacks, it is important that a complete system for
network quarantining include strong methods for preventing IP masquerading
by its local hosts, such as switch level egress ﬁltering. Host quarantining should
also be enforced as close to the host as is possible without relying on the host
to quarantine itself. If these boundaries cannot be enforced between each host,
one must assume that when one machine is infected, all of the machines within
the same boundary will also be infected.
7 Related Work
We were motivated by the work of Moore et al. [10], who model attempts at con-
taining worms using quarantining. They perform theoretical simulations, many
of which use parameters principally from the CodeRed II [4, 20] outbreak. They
argue that it is impossible to prevent systems from being vulnerable to worms
and that treatment cannot be performed fast enough to prevent worms from
spreading, leaving containment (quarantining) as the most viable way to pre-
vent worm outbreaks from becoming epidemics.
Early work on containment includes Staniford et al.’s work on the GrIDS
Intrusion Detection System [19], which advocates the detection of worms and
viruses by tracing their paths through the departments of an organization. More
recently, Staniford [16] has worked to generalize these concepts by extending
models for the spread of inﬁnite-speed, random scanning worms through ho-
mogenous networks divided up into ‘cells’. Simulating networks with 217 hosts
(two class B networks), Staniford limits the number of ﬁrst-contact connections
that a local host initiates to a given destination port to a threshold, T . While
he claims that for most ports, a threshold of T = 10 is achievable in practice,
5 Randomly dispersing local hosts through a large IP space can be achieved by using
a network address translation (NAT) switch.
Fast Detection of Scanning Worm Infections
77
HTTP and KaZaA are exceptions. In comparison, reverse sequential hypothesis
testing reliably identiﬁes HTTP scanning in as few as 10 observations.
The TRAFEN [2, 3] system also observed failed connections for the purpose
of identifying worms. The system was able to observe larger networks, without
access to end-points, by inferring connection failures from ICMP messages. One
problem with acting on information at this level is that an attacker could spoof
source IP addresses to cause other hosts to be quarantined.
Our use of rate limiting in order to buy time to observe worm behavior was
inspired by the virus throttle presented by Twycross and Williamson [22], which
we described in detail in Section 3. Worms can evade a throttle by scanning at
rates below one connection per second, allowing epidemics to double in size as
quickly as once every two seconds.
An approach quite similar to our own has been simultaneously developed by
Weaver, Staniford, and Paxson [26]. Their approach combines the rate limiting
and hypothesis testing steps by using a reverse sequential hypothesis test that
(like our CBCRL algorithm) assumes that connections fail until they are proven
to succeed. As with CBCRL, out-of-order processing could cause a slight increase
in detection delay, as the successes of connections sent before an infection event
may be processed after connections are initiated after the infection event. In the
context of their work, in which the high-performance required to monitor large
networks is a key goal, the performance beneﬁts are likely to outweigh the slight
cost in detection speed.
For a history and recent trends in worm evolution, we recommend the work
of Kienzle and Elder [8]. For a taxonomy of worms and a review of worm termi-
nology, see Weaver et al. [25].
8 Future Work
As worm authors become aware of the limitations discussed in Section 6, it will
be necessary to revise our algorithms to detect scanning at the resolution of
the local host (source address) and targeted service (destination port), rather
than looking at the source host alone. Solutions for managing the added memory
requirements imposed by this approach have been explored by Weaver, Staniford,
and Paxson [26].
The intrusiveness of credit-based connection rate limiting, which currently
drops outgoing connection requests when credit balances reach zero, can be fur-
ther reduced. Instead of halting outgoing TCP ﬁrst-contact connection requests
from hosts that do not maintain a positive credit balance, the requests can be sent
immediately and the responses held until a positive credit balance is achieved.
This improvement has the combined beneﬁts of reducing the delays caused by
false rate limiting while simultaneously ensuring that fewer connections are al-
lowed to complete when a high-speed scanning worm issues a burst of connection
requests. As a result, the remaining gap in response speed between credit-based
connection rate limiting and Twycross and Williamson’s virus throttle can be
closed while further decreasing the risk of acting on false positives.
Finally, we would like to employ additional indicators of infection to further
reduce the number of ﬁrst-contact connection observations required to detect a
78
Stuart E. Schechter, Jaeyeon Jung, and Arthur W. Berger
worm. For example, it is reasonable to conclude that, when a host is deemed
to be infected, those hosts to which it has most recently initiated successful
connections are themselves more likely to be infected (as was the premise behind
GrIDS [19]). We propose that this be accomplished by adding an event type, the
report of an infection of a host that has recently contacted the current host, to
our existing hypothesis test.
9 Conclusion
When combined, credit-based connection rate limiting and reverse sequential
hypothesis testing ensure that worms are quickly identiﬁed with an attractively
low false alarm rate. While no system can detect all possible worms, our new
approach is a signiﬁcant improvement over prior methods, which detect a smaller
range of scanners and unnecessarily delay network traﬃc. What’s more, the
techniques introduced in this paper lend themselves to eﬃcient implementation,
as they need only be activated to observe a small subset of network events and
require little calculation for the common case that traﬃc is benign.
Acknowledgments
This paper could not have been completed without the continued support of Vern
Paxson and Hari Balakrishnan. We are indebted to Dave Andersen and Noah
Case for the network logs used for our analysis. We would also like to thank the
anonymous reviewers as well as Nick Feamster, David Molnar, Rodrigo Miragaia
Rodrigues, David Savitt, Matt Williamson, and especially Glenn Holloway for
taking the time to review and comment on earlier drafts of this paper. Stuart
Schechter would like to thank the National Science Foundation for support under
grant CCR-0310877.
References
1. George Bakos and Vincent Berk. Early detection of internet worm activity by
metering ICMP destination unreachable messages. In Proceedings of the SPIE
Aerosense, 2002.
2. Vincent Berk, George Bakos, and Robert Morris. Designing a framework for ac-
tive worm detection on global networks. In Proceedings of the IEEE International
Workshop on Information Assurance, March 2003.
3. Vincent H. Berk, Robert S. Gray, and George Bakos. Using sensor networks
and data fusion for early detection of active worms. In Proceedings of the SPIE
Aerosense Conference, April 2003.
4. CERT. “Code Red II:” another worm exploiting buﬀer overﬂow in IIS indexing
service DLL. http://tinyurl.com/2lzgb.
5. F-Secure. Computer virus information pages: Lovsan. http://tinyurl.com/ojd1.
6. F-Secure. Computer virus information pages: Mimail.J. http://tinyurl.com/3ybsp.
7. Jaeyeon Jung, Vern Paxson, Arthur W. Berger, and Hari Balakrishnan. Fast
portscan detection using sequential hypothesis testing. In Proceedings of the IEEE
Symposium on Security and Privacy, May 9–12, 2004.
Fast Detection of Scanning Worm Infections
79
8. Darrell M. Kienzle and Matthew C. Elder. Recent worms: a survey and trends.
In Proceedings of the 2003 ACM Workshop on Rapid Malcode, pages 1–10. ACM
Press, October 27, 2003.
9. David Moore, Vern Paxson, Stefan Savage, Colleen Shannon, Stuart Staniford, and
Nicholas Weaver. Inside the Slammer worm. IEEE Security and Privacy, 1:33–39,
July 2003.
10. David Moore, Colleen Shannon, Geoﬀrey M. Voelker, and Stefan Savage. Internet
quarantine: Requirements for containing self-propagating code. In Proceedings of
IEEE INFOCOM, April 1–3, 2003.
11. Network Associates Inc. Security threat report for W32/MydoomMM.
http://tinyurl.com/2asgc.
12. Vern Paxson. Bro: A system for detecting network intruders in real-time.
http://www.icir.org/vern/bro-info.html.
13. Vern Paxson. Bro: a system for detecting network intruders in real-time. Computer
Networks, 31(23–24):2435–2463, 1999.
14. Stelios Sidiroglou and Angelos D. Keromytis. Countering network worms through
automatic patch generation. Technical Report CUCS-029-03, 2003.
15. Stelios Sidiroglou and Angelos D. Keromytis. A network worm vaccine architecture.
In Proceedings of the IEEE International Workshops on Enabling Technologies:
Infrastructure for Collaborative Enterprises (WETICE), Workshop on Enterprise
Security, June 2003.
16. Stuart Staniford. Containment of scanning worms in enterprise networks. Journal
of Computer Security, Forthcoming.
17. Stuart Staniford, James Hoagland, and Joseph McAlerney. Practical automated
detection of stealthy portscans. Journal of Computer Security, 10(1):105–136, 2002.
18. Stuart Staniford, Vern Paxson, and Nicholas Weaver. How to 0wn the Internet in
your spare time. In Proceedings of the 11th USENIX Security Symposium, August
7–9, 2002.
19. S. Staniford-Chen, S. Cheung, R. Crawford, M. Dilger, J. Frank, J. Hoagland,
K. Levitt, C. Wee, R. Yip, and D. Zerkle. GrIDS – A graph-based intrusion de-
tection system for large networks. In Proceedings of the 19th National Information
Systems Security Conference, volume 1, pages 361–370, October 1996.
20. Symantec. Security response – CodeRed II. http://tinyurl.com/89t0.
21. Symantec. Security response – W32.Novarg.Amm. http://tinyurl.com/2lv95.
22. Jamie Twycross and Matthew M. Williamson. Implementing and testing a virus
throttle. In Proceedings of the 12th USENIX Security Symposium, August 4–8,
2003.
23. Luis von Ahn, Manuel Blum, and John Langford. Telling humans and computers
apart (automatically) or how lazy cryptographers do AI. Technical Report CMU-
CS-02-117, February 2002.
24. Abraham Wald. Sequential Analysis. J. Wiley & Sons, New York, 1947.
25. Nicholas Weaver, Vern Paxson, Stuart Staniford, and Robert Cunningham. A tax-
onomy of computer worms. In Proceedings of the 2003 ACM Workshop on Rapid
Malcode, pages 11–18. ACM Press, October 27, 2003.
26. Nicholas Weaver, Stuart Staniford, and Vern Paxson. Very fast containment of
scanning worms. In Proceedings of the 13th USENIX Security Symposium, Au-
gust 9–13, 2004.
27. Matthew M. Williamson. Throttling viruses: Restricting propagation to defeat ma-
licious mobile code. In Proceedings of The 18th Annual Computer Security Appli-
cations Conference (ACSAC 2002), December 9–13, 2002.
80
Stuart E. Schechter, Jaeyeon Jung, and Arthur W. Berger
A Optimizing the Computation
of Repeated Reverse Sequential Hypothesis Tests
It is unnecessarily expensive to repeatedly recompute Λ in reverse sequence
each time a new ﬁrst-contact connection is observed. A signiﬁcant optimization
requires that we maintain single state variable ¯Λ, calculated iteratively in the
order in which events are observed.
(cid:6)
(cid:7)
1, ¯Λ(Yn−1)φ(Yn)
¯Λ(Y0) ≡ 1.
¯Λ(Yn) = max
(1)
We will prove that ¯Λ(Yn) > η1 if and only if a reverse sequential hypothesis
test starting backward from observation n would lead us to conclude that the
host was infected.
We ﬁrst prove the following lemma stating that if a reverse sequential hy-
pothesis test reports an infection, our optimized algorithm will also report an
infection.
Lemma 1. For η1 > 1 and for mutually independent random variables Yi,
∀m ∈ [1, n] : Λ(Yn, Yn−1, . . . , Ym) ≥ η1 ⇒ ¯Λ(Yn) ≥ η1
Proof. We begin by replacing the Λ term with its equivalent expression in terms
of φ:
(2)
(3)
(4)
η1 ≤ Λ(Yn, Yn−1, . . . , Ym)
≤ n(cid:2)
φ(Yi)
We can place a lower bound on the value of ¯Λ(Yn) by exploiting the fact
that, in any iteration, ¯Λ cannot return a value less than 1.
i=m
¯Λ(Yn) = ¯Λ(Y1, Y2, . . . , Yn)
≥ 1 · ¯Λ(Ym, Ym+1, . . . , Yn)
≥ n(cid:2)
φ(Yi) ≥ η1
i=m
where the last inequality follows the steps taken in Equations (3) and (4).
Thus, Λ(Yn, Yn−1, . . . , Ym) ≥ η1 ⇒ ¯Λ(Yn) ≥ η1.
We must also prove that our optimized algorithm will only report an infection
when a reverse sequential hypothesis test would also report an infection. Recall
that a reverse sequential hypothesis test will only report an infection if Λ exceeds
η1 before falling below η0.
Lemma 2. For thresholds η0  m:
¯Λ(Yn) =
φ(Yj)
n(cid:2)
j=m
= Λ(Yn, Yn−1, . . . , Ym)
Thus, ¯Λ(Yn) ≥ η1 ⇒ Λ(Yn, Yn−1, . . . , Ym) ≥ η1.
To prove that there exists no k in [m, n] such that Λ(Yn, Yn−1, . . . , Yk) ≤ η0,
suppose that such a k exists. It follows that:
n(cid:2)
φ(Yj) ≤ η0 < 1
j=k
Recall that we chose m to ensure that:
η1 ≤ n(cid:2)
φ(Yj)
j=m
(5)
(6)
The product on the right hand side can be separated into factors from before
and after observation k.
φ(Yj)·
(7)
We then use Equation (5) to substitute an upper bound of 1 on the latter prod-
uct.
η1 ≤ k−1(cid:2)
φ(Yj) · n(cid:2)
j=m
j=k
η1 ≤ k−1(cid:2)
φ(Yj)
η1 ≤ ¯Λ(Yk−1)
j=m
This contradicts the hypothesis that ¯Λ(Yi) < η1 for all i ∈ [1, n − 1].
If we were concerned with being notiﬁed when the test came to the ‘benign’
conclusion we could create an analogous function Λ:
Λ(Yn) = min (1, Λ(Yn−1)φ(Yn))
The lemmas required to show equivalence and proof are also analogous.