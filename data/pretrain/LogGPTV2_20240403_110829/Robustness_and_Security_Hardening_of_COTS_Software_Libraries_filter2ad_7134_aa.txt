title:Robustness and Security Hardening of COTS Software Libraries
author:Martin S&quot;ußkraut and
Christof Fetzer
Robustness and Security Hardening of COTS Software Libraries
Martin S¨ußkraut
Christof Fetzer
Department of Computer Science
Technische Universit¨at Dresden, Germany
{martin.suesskraut,christof.fetzer}@tu-dresden.de
Abstract
COTS components, like software libraries, can be used to
reduce the development effort. Unfortunately, many COTS
components have been developed without a focus on robust-
ness and security. We propose a novel approach to harden
software libraries to improve their robustness and security.
Our approach is automated, general and extensible and
consists of the following stages. First, we use a static anal-
ysis to prepare and guide the following fault injection. In
the dynamic analysis stage, fault injection experiments exe-
cute the library functions with both usual and extreme input
values. The experiments are used to derive and verify one
protection hypothesis per function (for instance, function
foo fails if argument 1 is a NULL pointer). In the hard-
ening stage, a protection wrapper is generated from these
hypothesis to reject unrobust input values of library func-
tions. We evaluate our approach by hardening a library
used by Apache (a web server).
1 Introduction
When building dependable systems, one can rarely af-
ford to built everything from scratch. This means that one
needs to build systems using software components imple-
mented by third parties. These software components might
have been designed and implemented for less critical appli-
cation domains. The use of such components without fur-
ther hardening is therefore not recommended for depend-
able systems.
Third party software components are often provided in
form of libraries. Experience with our previous library
hardening tool [8] has shown that tools like HEALERS can
help developers to harden libraries. The idea of HEALERS
was to use automated fault injection experiments to deter-
mine automatically the robust argument types of functions.
Any argument that does not belong to the given robust ar-
gument type will result in a crash of the function. The
robust argument types were computed from a ﬁxed hier-
archy of robust argument types. For example, HEALERS
was able to automatically determine that the C function
strcpy(d,s) requires s to be a string and d a writable
buffer with a length of at least strlen(s)+1 bytes.
Our experience with HEALERS showed however deﬁ-
ciencies regarding (1) the extensibility and (2) the perfor-
mance of the tool. These deﬁciencies need to be addressed
to make such hardening tools more widely applicable. Our
new tool addresses these issues by facilitating
• Extensible fault injections: new test case generators can
be added, e.g., to test new handle types more carefully.
• Extensible run-time checking: new checks for arguments
can easily be added.
• Flexible computation of robust argument types: these are
computed without a given type hierarchy and are auto-
matically extended for new run-time checks.
• Performance:
the use of static analysis can reduce the
number of fault injections dramatically.
The paper is structured as follows. Section 2 gives an
overview on our approach. Our extensible test type system
is described in Section 3 together with our proposal to re-
duce the number of fault injections. In Section 4 we present
our run-time checks before we discuss how the protection
wrapper is generated in Section 5. In Section 6 we show
that we can prevent more than 56 % of injected faults from
becoming visible as crash failures. We conclude discussion
of the related work in Section 7.
2 Approach
Our goal is to automatically increase the robustness and
security of applications. To be applicable for users without
expert knowledge, we want to minimize the required user
input. However, most programmers will want to have con-
trol over the generation of protection wrappers. Hence, we
permit programmers to verify and modify the robust argu-
ment types that our tool system derives. The tool also pro-
vides programmers with evidence (in form of truth tables)
Figure 1. Workﬂow of our tool.
Figure 2. Table base approach to generate ro-
bustness and security checks.
about why it derived certain robust argument types and that
these are reasonable for the wrapped application.
To improve the applicability of our approach, we do not
want to require access to the source code of the applications
and libraries that need to be hardened. Source code might
not always be available and dealing with source code that
was written for different compilers and even for different
programming languages is very difﬁcult and time consum-
ing to get right (e.g., see [5]). Using only fault-injections
has the potential disadvantage of huge run-time costs (see
Section 6). Since intermediate languages like MSIL [2] and
LLVM [12] become more widespread, we instead assume
that we have access to the bytecode of libraries and applica-
tions.
In this paper we focus on the interface between an appli-
cation and its dynamic linked libraries. Our approach pro-
tects the application’s libraries from unrobust and insecure
input. Figure 1 illustrates the workﬂow of our approach. In
the analysis stage, an application’s libraries are ﬁrst stat-
ically analyzed to reduce the number of test inputs used
during the dynamic analysis phase.
In the following dy-
namic analysis phase, the libraries functions are exercised
by fault injection. Based on the observed behavior of the li-
braries, protection hypotheses are generated. A hypothesis
is a boolean expression over predicates on the arguments to
a function. We refer to these predicates as checks. In the
second stage, a protection wrapper is generated. Its job is to
protect the library functions at run-time from being called
with unrobust or insecure argument values. Therefore, it
intercepts all function calls from the application into its li-
braries. The protection wrapper only forwards the current
argument values to the wrapped library function, if they sat-
isfy the protection hypotheses.
The main two contributions of this paper are a new ﬂex-
ible fault injection tool (Autocannon) and a table-based ap-
proach to generate the protection hypotheses for the protec-
check1
check2
robust?
0
1
1
1
0
0
0
1
0
0
0
1
check1 = string?(src)
check2 = buf write?(dest, strlen(src) + 1)
truth table for function
Table 1. Part of
strcpy(char* dest, const char* src).
tion wrapper. Autocannon makes use of static analysis to
perform fault injection on arbitrary functions. For each li-
brary function, a table like the one in Figure 2 is built in
the analysis stage. One row represents one fault injection
experiment with the function. The input vectors (gray) are
not part of the truth table. They only denote where the rows
come from. All test values used in the analysis stage are
classiﬁed by boolean checks. The right most column con-
tains the boolean result of the call: either robust or unro-
bust. A functions execution is robust, if the function does
not crash (e.g., by a segmentation fault). We show in Sec-
tion 3.3 how to create test values in a way that security vi-
olations (like buffer overﬂows) are converted into robust-
ness issues. We view this truth table as a boolean function
f (check1, . . . , checkn). A truth table minimizer computes
a boolean expression of f . This boolean expression is a pro-
tection hypothesis. It takes the role of the HEALERS robust
argument types but it is much more ﬂexible because it is an
arbitrary boolean expression over a set of given checks.
Table 1 sketches the truth table for the Standard C
function strcpy. The truth table is ﬁrst preprocessed
before minimizing it (e.g., removing redundant row 3).
Check check1 is true if argument src points to a string,
check2 is true,
if the ﬁrst strlen(src) + 1 byte
of the buffer pointed by dest are writeable. The re-
sulting protection hypothesis is: string?(src) AND
buf write?(dest, strlen(src) + 1). The pro-
tection wrapper will reject all inputs for which the protec-
tion hypothesis does not evaluate to true.
The protection wrapper prevents calling a function f
with unsafe arguments. Therefore, it evaluates the protec-
tion hypothesis of f on the current argument values given
by the caller of f . Only if the evaluation yields true, the
control is passed to f . Otherwise the wrapper returns with
an error code without executing f .
In order to use our approach, some knowledge about the
library functions used by an application is needed: we need
at least the return type and the types of the arguments of a
function to perform a dynamic analysis. Depending on the
target platform, this information might already be included
within the library (e.g., library given in LLVM bytecode).
Otherwise, some other form of speciﬁcation (like C header
ﬁles) is needed. In the following we will refer with pub-
lic source to ﬁles that contain that information. Note even
if this is part of the source code of the library, it must be
available at least for developers using the library. Whereas
private source is the source code of the library implementa-
tion, which is typically not available to all users.
Even though our approach is independent from the pro-
gramming language and platform of a library, we will focus
in the following on libraries implemented in the program-
ming language C.
3 Test Values
Test values are used in the analysis phase as input values
for performing fault injection experiments with the libraries
functions. For each of a function’s arguments a set of test
values is generated. The set of input vectors is the cross
product of all test value sets. These test value sets must
be large enough to exercise the function under analysis in
a way that the resulting truth table is sufﬁciently complete.
Of course, executing the function on all possible input val-
ues is in general infeasible, e.g., a function with two 32-bit
arguments has more than 1.8 · 1019 possible input vectors.
We tackle that issue but providing an extensible test type
system. Each argument type of a function is mapped to a
test type. The set of test values for an argument is the union
of the representatives of the test types of this argument. The
test type system is richer than the argument type system in
the sense that it has more semantics. For instance, the C
type char* can be a pointer, a string, a ﬁlename or a for-
mat string depending on its usage. Generic pointers, strings,
ﬁlenames and format strings are test types. Some test types
contain other test types (e.g., ﬁlenames and format string
are also plain strings, which itself are pointers). We call
ﬁle names and format strings special test types. In general,
special test types have a very clear semantics. They often
contain other more generic types with more vague seman-
tics.
Our test type system is based on Ballista’s test type sys-
tem [10, 11]. Ballista is a dependability benchmark for
POSIX implementations. Ballista’s test type system can
handle a predeﬁned ﬁxed set of argument types and func-
tions. In order to test arbitrary libraries, we extended it to
handle arbitrary argument types. We call this new test sys-
tem Autocannon. It uses argument type characteristics to
determine the test type for an argument type (e.g., its size,
if an argument type is a pointer or if it can be casted to an
integer). The argument type characteristics are extracted us-
ing static analysis on the public sources (e.g., C header ﬁles
or bytecode).
We introduce meta types, type templates, and feedback
into Autocannon. A meta type combines a set of Ballista’s
Figure 3. A part of Ballista’s test type system
with a meta type.
specialized type into one general type. A specialized test
type implements applications semantics. For instance, a
test type that represents pointers to a time data structure
time t* is a specialized test type. We do not want to rely
in Ballista’s specialized types only. That’s why we intro-
duce type templates to generate specialized test types from
type characteristics. We use them to generate test types for
handles of abstract data types and for data structures. Auto-
cannon is able to give feedback to test types to reﬁne their
test values. We use this to detect conditions for buffer over-
runs.
In the ﬁrst part of this section we brieﬂy introduce Bal-
lista’s test type system before we present Autocannons im-
provements: meta types, feedback, and type templates. The
second part explains the mapping from argument types to
test types, and how we deal we large set of input vectors.
3.1 Ballista Type System
Ballista is a test system for measuring the dependability
of POSIX implementations. It contains a ﬂexible test type
system that we have extended for our needs. Ballista’s test
type system is extensible: one can easily add new test types
to it. All test types are arranged in one type tree. Part of this
tree is shown in Figure 3. The root is the most general type,
the leafs are the most special ones. A child type is also a
parent type (e.g., a ﬁlename is also a string, which itself is
also a pointer). Each type has a set of representatives or test
values. The root’s set of test values is empty.
A child type inherits all type values of its parent. For in-
stance, a function expecting a ﬁle name, is also tested with
plain strings values and general pointer values. But a func-
tion whose argument is mapped to the plain string type is
not tested with ﬁlenames and format strings.
To test a function with usual and exceptional values a
Ballista type has more than one representatives. For ex-
ample, the Ballista type for ﬁlenames has 432 representa-
tives that result of all possible combinations for the content
(empty, non-empty), the ﬁle permissions (readable, write-
able, etc.), the ﬁle state (existing, non-existing, directory,
etc.) and the ﬁlename (local, temporary, with spaces, etc.).
3.2 Meta Types
The mapping between test types and argument types is
predeﬁned within Ballista. It is done by an expert know-
ing the functions speciﬁcation. In order to test arbitrary li-
braries, our system works without such a predeﬁned map-
ping. In Autocannon, we introduced meta types to combine
specialized Ballista types into more general types. A meta
type has more than one parent. So our type system is a di-
rected acyclic graph instead of a tree. For simplicity, meta
test types do not contribute test values. They join the test
values of their parents.
The test values of meta type meta string in Figure 3
are the union of the test values of Ballista’s test types ﬁle-
name, format string, string, and pointer. Because we do
not know the speciﬁcation of a function foo(char*), we
map an argument type char* to meta string. So foo
will be tested with ﬁlenames, format strings and its parents
test values.
We have deﬁned 4 generic meta types. Meta string com-
bines all special string types. Meta pointer combines all
specialized pointer types including meta string. Meta inte-
ger and meta short combine all integer types with width 32
bit and 16 bits, respectively. More meta types are gener-
ated to combine generated types (like instantiated type tem-
plates) with Ballista types or predeﬁned meta types.
3.3 Feedback
Autocannon uses feedback to detect conditions for buffer
overruns. This feedback loop is originally a part of HEAL-
ERS [7]. Feedback is used to convert buffer overruns into
robustness issues. Therefore, the test system gives feedback
back to certain test types, so that they can reﬁne their test
values. A feedback test type generates a buffer that is en-
closed with unaccessible memory pages. If the testing func-
tion overruns this given buffer, the OS will raise a segmenta-
tion fault exception. The test system catches this exception
and asks the test type, if the bad memory access occurred
within the enclosing memory pages. If this is the case, the
test type enlarges the buffer and the test is redone. Figure
4 illustrates the feedback loop. The feedback cycle goes
on until either the function executes without a segmentation
fault or the test type is unable to allocate more memory.
for buffer overruns.
This
Let us
The test
system itself does not detect
the con-
is done by
ditions
illustrate this with function
the checks.
strcpy(char* dest, const char *src).
test
system tests strcpy with a string (src) provided by
Ballista’s string test type and a read/write buffer of size
1 byte (dest) provided by Autocannon’s feedback test
The
Figure 4. Feedback loop: The test system
uses the addresses of illegal memory ac-
cesses to reﬁne test values.
type. Function strcpy will overrun dest and cause a
segmentation fault if the length of src’s string is larger
than 1 byte. Successively, the feedback type will enlarge
dest’s buffer until its size equals src’s string length + 1.
The check correlate the buffer’s size and the string’s length
so that
the hypothesis sizeof (dest) > strlen
(src) will be ﬁnally extracted.
We have added a test type to Autocannon that (1) ac-
cepts and responds to feedback and (2) generates different
representatives: buffers of different size (1 byte, 4 kbytes,
64 kbytes), content and protection (read only, read/write).
Beside this one feedback test type, templates are used to
generate special feedback test types for data structures.
3.4 Type Templates
We use type templates to generate specialized test types
for arbitrary argument types. Type templates are param-
eterized test types. Currently, we have two kinds of type
templates: one for Abstract Data Types and one for data
structures. The data structure type gives feedback back to
the testing environment (see Section 3.3).
Abstract Data Types Abstract Data Types (ADT) are of-
ten implemented by a set of functions operating on some
hidden state. This hidden state, the instance of the ADT, is
referenced by a handle. Examples for such handles are ﬁle
descriptor handles, socket handles, or a handle to a random
number generator.
The Ballista type system already includes a set of test
types generating handle values. But this handles refer all
to ADT implemented by the POSIX API. To test libraries
implementing arbitrary APIs, we generate a test type for
each kind of handle we identiﬁed. In this way, functions
expecting handles values are not only tested with extreme
values, but also with input values that might appear in a
non-faulty execution.