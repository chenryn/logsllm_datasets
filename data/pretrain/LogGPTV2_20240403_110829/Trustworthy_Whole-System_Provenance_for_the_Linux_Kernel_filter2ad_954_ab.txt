• Networks: Provenance metadata can also be associ-
ated with packets in order to better understand network
events in distributed systems [5, 65, 66]. Coordinating
multiple compromised hosts, an attacker may attempt
to send unauthenticated messages to avoid provenance
generation and to perform data exﬁltration.
We deﬁne a provenance trusted computing base (TCB)
to be the kernel mechanisms, provenance recorder, and
storage back-ends responsible for the collection and
management of provenance. Provenance-aware appli-
cations are not considered part of the TCB.
We make the following assumption with regards to the
TCB. In Linux, kernel modules have unrestricted access
to kernel memory, meaning that there is no mechanism
for protecting LPM from the rest of the kernel. The ker-
nel code is therefore trusted; we assume that the stock
kernel will not seek to tamper with the TCB. However,
we do consider the possibility that the kernel could be
compromised after installation through its interactions
with user space applications. To facilitate host attestation
in distributed environments, we also assume access to
a Public Key Infrastructure (PKI) for provenance-aware
hosts to publish their public signing keys.
3.3 System Goals
We set out to provide the following security assurances
in the design of of our system-layer provenance collec-
tion mechanism. McDaniel et al.
liken the needs of a
secure provenance monitor [42] to the reference monitor
guarantees laid out by Anderson [4]: complete media-
tion, tamperproofness, and veriﬁability. We deﬁne these
guarantees as follows:
G1 Complete. Complete mediation for provenance has
been discussed elsewhere in the literature in terms
of assuring completeness [32]: that the provenance
record be gapless in its description of system activ-
ity. To facilitate this, LPM must be able to observe
all information ﬂows that pass through controlled
data types.
G2 Tamperproof. As many provenance use cases in-
volve enhancing system security, LPM will be an
Prov. Aware 
Applications
IMA
TPM
user space
GZip
SQL
Neo4j
SNAP
kernel space
Provenance
Recorder
Relay
Buffer
Prov. Module
Prov. Hooks
NF Hooks
System Provenance
Integrity Measurements
Workﬂow Provenance
Figure 2: Diagram of the LPM Framework. Kernel
hooks report provenance to a recorder in userspace,
which uses one of several storage back-ends.
The
recorder is also responsible for evaluating the integrity
of workﬂow provenance prior to storing it.
adversarial target. The TCB must therefore be im-
pervious to disabling or manipulation by processes
in user space.
G3 Veriﬁable. The functionality of LPM must be
veriﬁably correct. Additionally, local and remote
users should be able to attest whether the host with
which they are communicating is running the se-
cured provenance-aware kernel.
Through surveying past work in provenance-aware
systems, we identify the following additional goals to
support whole-system provenance:
G4 Authenticated Channel.
In distributed environ-
ments, provenance-aware systems must provide a
means of assuring authenticity and integrity of
provenance as it is communicated over open net-
works [7, 42, 48, 65]. While we do not seek to
provide a complete distributed provenance solution
in LPM, we do wish to provide the required build-
ing blocks within the host for such a system to ex-
ist. LPM must therefore be able to monitor ev-
ery network message that is sent or received by the
host, and reliably explain these messages to other
provenance-aware hosts in the network.
G5 Attested Disclosure. Layered provenance, where
additional metadata is disclosed from higher opera-
tional layers, is a desirable feature in provenance-
aware systems, as applications are able to report
workﬂow semantics that are invisible to the oper-
ating system [44]. LPM must provide a gateway for
322  24th USENIX Security Symposium 
USENIX Association
4
upgrading low integrity user space disclosures be-
fore logging them in the high integrity provenance
record. This is consistent with the Clark-Wilson In-
tegrity model for upgrading or discarding low in-
tegrity inputs [17].
In order to bootstrap trust in our system, we have im-
plemented LPM as a parallel framework to Linux Secu-
rity Modules (LSM) [60, 61]. Building on these results,
we show in Section 4 that this approach allows LPM to
inherit the formal assurances that have been veriﬁed for
the LSM architecture.
3.4 Design & Implementation
An overview of the LPM architecture is shown in Fig-
ure 2. The LPM patch places a set of provenance hooks
around the kernel; a provenance module then registers
to control these hooks, and also registers several Netﬁl-
ter hooks; the module then observes system events and
transmits information via a relay buffer to a provenance
recorder in user space that interfaces with a datastore.
The recorder also accepts disclosed provenance from ap-
plications after verifying their correctness using the In-
tegrity Measurements Architecture (IMA) [52].
In designing LPM, we ﬁrst considered using an exper-
imental patch to the LSM framework that allows “stack-
ing” of LSM modules 10. However, at this time, no stan-
dard exists for handling when modules make conﬂict-
ing decisions, creating the potential unpredicted behav-
ior. We also felt that dedicated provenance hooks were
necessary; by collecting provenance after LSM autho-
rization routines, we ensure that the provenance history
is an accurate description of authorized system events. If
provenance collection occurred during authorization, as
would be the case with stacked LSMs, it would not be
possible to provide this property.
3.4.1 Provenance Hooks
The LPM patch introduces a set of hook functions in the
Linux kernel. These hooks behave similarly to the LSM
framework’s security hooks in that they facilitate mod-
ularity, and default to taking no action unless a module
is enabled. Each provenance hook is placed directly be-
neath a corresponding security hook. The return value of
the security hook is checked prior to calling the prove-
nance hook, thus assuring that the requested activity has
been authorized prior to provenance capture; we consider
the implications of this design in Section 4. A workﬂow
for the hook architecture is depicted in Figure 3. The
LPM patch places over 170 provenance hooks, one for
each of the LSM authorization hooks. In addition to the
10See https://lwn.net/Articles/518345/
user space
kernel space
Text Editor
open System Call
Look Up Inode
Error Checks
DAC Checks
LSM Module
Examine context.
Does request pass policy?
Grant or deny.
LPM Module
Examine context.
Collect provenance.
If successful, grant.
LSM Hook
"Authorized?"
Yes or No
LPM Hook
"Prov collected?"
Yes or No
Access Inode
Figure 3: Hook Architecture for the open system call.
Provenance is collected after DAC and LSM checks, en-
suring that it accurately reﬂects system activity. LPM
will only deny the operation if it fails to generate prove-
nance for the event.
hooks that correspond to existing security hooks, we also
support Pohly et al.’s Hi-Fi [48] hook that is necessary to
preserve Lamport timestamps on network messages [38].
3.4.2 Netﬁlter Hooks
LPM uses Netﬁlter hooks to implement a cryptographic
message commitment protocol.
In Hi-Fi, provenance-
aware hosts communicated by embedding a provenance
sequence number in the IP options ﬁeld [49] of each out-
bound packet [48]. This approach allowed Hi-Fi to com-
municate as normal with hosts that were not provenance-
aware, but unfortunately was not secure against a net-
work adversary. In LPM, provenance sequence numbers
are replaced with Digital Signature Algorithm (DSA)
signatures, which are space-efﬁcient enough to embed in
the IP Options ﬁeld. We have implemented full DSA
support in the Linux kernel by creating signing rou-
tines to use with the existing DSA veriﬁcation func-
tion. DSA signing and veriﬁcation occurs in the NetFil-
ter inet_local_out and inet_local_in hooks.
In inet_local_out, LPM signs over the immutable
ﬁelds of the IP header, as well as the IP payload.
In
inet_local_in, LPM checks for the presence of a
signature, then veriﬁes the signature against a conﬁg-
urable list of public keys. If the signature fails, the packet
is dropped before it reaches the recipient application,
thus ensuring that there are no breaks in the continuity of
the provenance log. The key store for provenance-aware
hosts is obtained by a PKI and transmitted to the ker-
nel during the boot process by writing to securityfs.
LPM registers the Netﬁlter hooks with the highest prior-
USENIX Association  
24th USENIX Security Symposium  323
5
ity levels, such that signing occurs just before transmis-
sion (i.e., after all other IPTables operations), and sig-
nature veriﬁcation occurs just after the packet enters the
interface (i.e., before all other IPTables operations).
3.4.3 Provenance Modules
Here, we introduce two of our own provenance modules
(Provmon, SPADE), as well as brieﬂy mention the work
of our peers (UPTEMPO):
• Provmon. Provmon is an extended port of the Hi-Fi
security module [48]. The original Hi-Fi code base
was 1,566 lines of code, requiring 723 lines to be mod-
iﬁed in the transition. Our extensions introduced 728
additional lines of code. The process of porting did
not affect the module’s functionality, although we have
subsequently extended the Hi-Fi protocol to capture
additional lineage information:
File Versioning. The original Hi-Fi protocol did not
track version information for ﬁles, leading to uncer-
tainty as to the exact contents of a ﬁle at the time it
was read. Accurately recovering this information in
user space was not possible due to race conditions be-
tween kernel events. Because versioning is necessary
to break cycles in provenance graphs [43], we have
added a version ﬁeld to the provenance context for in-
odes, which is incremented on each write.
Network Context. Hi-Fi omitted remote host address
information for network events, reasoning that source
information could be forged by a dishonest agent in the
network. These human-interpretable data points were
replaced with an assigned random identiﬁer for each
packet. We found, however, that these identiﬁers could
not be interpreted without remote address information,
and incorporated the recording of remote IP addresses
and ports into Provmon.
• SPADE. The SPADE system is an increasingly pop-
ular option for provenance auditing, but collecting
provenance in user space limits SPADE’s expressive-
ness and creates the potential for incomplete prove-
nance.
To address this limitation, we have cre-
ated a mechanism that reports LPM provenance into
SPADE’s Domain-Speciﬁc Language pipe [29]. This
permits the collection of whole-system provenance
while simultaneously leveraging SPADE’s existing
storage, remote query, and visualization utilities.
• Using Provenance to Expedite MAC Policies (UP-
TEMPO). Using LPM as a collection mechanism,
Moyer et al.
investigate provenance analysis as a
means of administrating Mandatory Access Control
(MAC) policies [54]. UPTEMPO ﬁrst observes system
execution in a sterile environment, aggregating LPM
provenance in a centralized data store. It then recov-
ers the implicit information ﬂow policy through min-
ing the provenance store to generate a MAC policy for
the distributed system, decreasing both administrator
effort and the potential for misconﬁguration.
3.4.4 Provenance Recorders
LPM provides modular support for different storage
through provenance recorders. To prevent an inﬁnite
provenance loop, recorders are ﬂagged as provenance-
opaque [48] using the security.provenance ex-
tended attribute, which is checked by LPM before creat-
ing a new event. Each recorder was designed to be as ag-
nostic to the active LPM as possible, making them easy
to adapt to new modules.
We currently provide provenance recorders that of-
fer backend storage for Gzip, PostGreSQL, Neo4j, and
SNAP. Commentary on our PostGreSQL and Neo4j re-
porters can be found in our technical report [8]. We make
use of the Gzip and SNAP recorders during our evalua-
tion in Section 6.
The Gzip recorder incurs low storage overheads and
fast insertion speeds. On our test bed, we observed
this recorder processing up to 400,000 events per sec-
ond from the Provmon provenance stream. However, be-
cause the provenance is not stored in an easily queried
form, this back-end is best suited for environments where
queries are an ofﬂine process.
To create graph storage that was efﬁcient enough for
LPM, we used the SNAP graphing library11 to design
a recorder that maintains an in-memory graph database
that is fully compliant with the W3C PROV-DM Model
[59]. We have observed insertion speeds of over 150,000
events per second using the SNAP recorder, and highly
efﬁcient querying as well. This recorder is further evalu-
ated in Section 6.
3.4.5 Workﬂow Provenance
To support layered provenance while preserving our se-
curity goals, we require a means of evaluating the in-
tegrity of user space provenance disclosures. To ac-
complish this, we extend the LPM Provenance Recorder
to use the Linux Integrity Measurement Architecture
(IMA) [35, 52]. IMA computes a cryptographic hash of
each binary before execution, extends the measurement