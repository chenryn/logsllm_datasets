Figure 2: Results of automatically analyzing the PIN integrity check with respect to multiple runs of an adaptive attacker.
We conclude that the distribution of the PINs is γ-close to the uni-
form distribution u, i.e., pY
γ
≈ u.
Consider again the PIN integrity check program P from Sec-
tion 5.1, generalized to 4 PINs, i.e., IP = {0, . . . , 9}4, FP = {0, 1},
and
P(s1 s2 s3 s4) = ^i=1...4
si ⊕ mi < 10
Theorem 3 gives the following formula to bound H(DpY |PpY ):
H(DpY |PpY ) ≤ γ · H(Du) −
1
γ
· H(Pu) + log2 γ γ +
1
γ!
We set m = FFFF, which results in the following upper bound:
H(DpY |PpY )
≤ γ · log2 104 +
+ log2 γ γ +
≈ 13.1654
1
γ
104
·  44
γ!
1
log2
44
104
+
104 − 44
104
log2
104 − 44
104
!
A lower bound of H(DpY |PpY ) ≥ 13.0664 follows along the same
lines.
The small delta between the upper and lower bounds shows that
the uniform analysis is (almost) precise for PINs generated accord-
ing to the Interbank algorithm. We conclude by comparing this
result with the result of the analysis with respect to PINs gener-
ated using decimalization tables presented in Section 5.2 where,
for 4 digit PINs, we obtained a remaining uncertainty of 12.9631
bits. The diﬀerence between the remaining uncertainties gives an
account of the security that is gained by using a better (i.e., less
skewed) PIN generation algorithm.
6. RELATED WORK
Denning is the ﬁrst to quantify information ﬂow in terms of the
reduction in uncertainty about a program variable [14]. Millen [28]
and Gray [16] use information theory to derive bounds on the trans-
mission of information between processes in multi-user systems.
Lowe [24] shows that the channel capacity of a program can be
over-approximated by the number of possible behaviors. The chan-
nel capacity corresponds to the maximal leakage w.r.t. to any input
distribution and hence is an over-approximation of the information
that is actually revealed.
Clark, Hunt, and Malacaria [10] connect equivalence relations
to quantitative information ﬂow, and propose the ﬁrst type system
for statically deriving quantitative bounds on the information that
a program leaks [11]. The analysis assumes as input (upper and
lower) bounds on the entropy of the input variables and delivers
corresponding (upper and lower) bounds for the leakage of the pro-
gram. For loops with high guards, the analysis always reports com-
plete leakage of the guard.
Malacaria [25] shows how to characterize the leakage of loops
in terms of the loop’s output and the number of iterations. Closely
related on this approach, Mu and Clark [30] propose a precise, auto-
matic QIF based on a distribution transformer semantics, which can
deal with non-uniform input distributions. Their approach relies
on an explicit representation of the probability distribution trans-
formed by the program (and hence the set of initial states), which
prevents the direct application to programs with large state spaces.
The problem is mitigated by an interval-based abstraction proposed
in [29]. The abstraction splits a totally ordered domain into inter-
vals, each of which assumed to be uniformly distributed. In our
approach, the probability distribution is represented in terms of
preimages of a generating program, which oﬀers the possibility of
a symbolic treatment of large state spaces.
Köpf and Basin [20] show how to compute partitions on the se-
cret input that represent what an attacker can learn in an adaptive
attack. Backes, Köpf, and Rybalchenko [2] show how to determine
the partitions corresponding to the information (with respect to a
non-adaptive attacker) that a program leaks by computing weakest
preconditions. Both approaches rely on counting the number and
the sizes of the preimages in order to quantify the remaining un-
certainty about the input w.r.t. uniform distributions. When used in
conjunction with these approaches, the ideas presented in this paper
can be used to weaken the requirement of a uniform distribution.
Köpf and Rybalchenko [22] propose approximation and random-
ization techniques to approximate the remaining uncertainty about
a program’s inputs for programs with unbounded loops. Their ap-
proach relies on approximating the sizes of blocks (but without
their complete enumeration) and it delivers bounds w.r.t. uniformly
distributed inputs. As we have shown, the reduction presented in
this paper can be used for extending the techniques to programs
with non-uniform input distributions.
McCamant and Ernst propose a dynamic taint analysis for quan-
tifying information ﬂow [27]. Their method does not assume a par-
ticular input distribution and provides over-approximations of the
leaked information along a particular path. However, it does not
yield guarantees for all program paths, which is important for se-
curity analysis. Newsome, McCamant, and Song [31] also use the
feasible outputs along single program paths as bounds for channel
capacity (i.e. the maximal leakage w.r.t. to all possible input dis-
tributions), and they apply a number of heuristics to approximate
upper bounds on the number of reachable states of a program.
Chatzikokolakis, Chothia, and Guha [7] use sampling to build up
a statistical system model. Based on this model, they compute the
channel capacity, i.e. the maximum leakage w.r.t. all possible input
distributions.
DiPierro, Hankin, and Wiklicky [33] consider probabilistic pro-
cesses with given input distributions and (instead of information
theory) use the distance of the produced output distributions to
quantify information ﬂow.
Clarkson, Myers, and Schneider [12] use non-uniform input dis-
tributions to model adversaries beliefs, which they update accord-
ing to the program semantics. They do not discuss techniques for
automation or abstraction.
Smith [36] proposes min-entropy as an alternative measure of
information ﬂow. Min-entropy gives bounds on the probability of
guessing a secret in one attempt, whereas Shannon-entropy gives
bounds on the average number of guesses required for determin-
ing a secret. The investigation of a reduction from non-uniform to
uniform QIF for min-entropy remains future work.
7. CONCLUSIONS AND FUTURE WORK
We have considered the problem of quantifying the information-
ﬂow in programs with respect to non-uniform input distributions.
We have made the following contributions to solve the problem.
First, we have shown how the problem of non-uniform QIF can be
reduced to the uniform case. To this end, we represented the non-
uniform input distribution as a program that receives uniform input,
and we sequentially composed it with the target program. We have
proved a connection between the information-theoretic characteris-
tics of the target program and its composition with the distribution
generator. This connection enables us to perform a precise non-
uniform analysis using existing QIF techniques for the uniform
case. Second, we have shown that the result of a QIF is robust
with respect to small variations in the input distribution. This result
shows that we can estimate the information-theoretic characteris-
tics of a program by considering an approximate input distribution.
This is useful in cases where the input distribution can only be ap-
proximated or an approximation simpliﬁes the analysis. Finally, we
have performed a case-study where we illustrated both techniques
and demonstrated their usefulness in practice.
Acknowledgments.
Boris Köpf’s research was partially done while at MPI-SWS
and is partially supported by FP7-ICT Project NESSoS (256980),
by FP7-PEOPLE-COFUND Project AMAROUT (229599), and by
Comunidad de Madrid Program PROMETIDOS-CM (S2009TIC-
1465).
8. REFERENCES
[1] American National Standards Institute. Banking - Personal
Identiﬁcation Number Management and Security - Part 1:
PIN protection principles and techniques for online PIN
veriﬁcation in ATM & POS systems. ANSI X9.8-1, 2003.
[2] M. Backes, B. Köpf, and A. Rybalchenko. Automatic
Discovery and Quantiﬁcation of Information Leaks. In Proc.
30th IEEE Symposium on Security and Privacy (S& P ’09),
pages 141–153. IEEE, 2009.
[3] T. Batu, S. Dasgupta, R. Kumar, and R. Rubinfeld. The
complexity of approximating entropy. In Proc. 34th
Symposium on the Theory of Computing (STOC ’02), pages
678–687. ACM, 2002.
[4] O. Berkman and O. M. Ostrovsky. The unbearable lightness
of pin cracking. In Financial Cryptography (FC ’07), volume
4886 of LNCS, pages 224–238. Springer, 2008.
[5] M. Bond and P. Zieli´nski. Decimalisation table attacks for
PIN cracking. Technical Report UCAM-CL-TR-560,
University of Cambridge, Computer Laboratory, Feb. 2003.
[6] C. Cachin. Entropy Measures and Unconditional Security in
Cryptography. PhD thesis, ETH Zürich, 1997.
[7] K. Chatzikokolakis, T. Chothia, and A. Guha. Statistical
Measurement of Information Leakage. In Proc. 16th Intl.
Conf. on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS ’10), LNCS 6015, pages
390–404. Springer, 2010.
[8] K. Chatzikokolakis, C. Palamidessi, and P. Panangaden.
Anonymity protocols as noisy channels. Inf. Comput.,
206(2-4):378–401, 2008.
[9] D. Clark, S. Hunt, and P. Malacaria. Quantitative Analysis of
the Leakage of Conﬁdential Data. Electr. Notes Theor.
Comput. Sci., 59(3), 2001.
[10] D. Clark, S. Hunt, and P. Malacaria. Quantitative Information
Flow, Relations and Polymorphic Types. J. Log. Comput.,
18(2):181–199, 2005.
[11] D. Clark, S. Hunt, and P. Malacaria. A static analysis for
quantifying information ﬂow in a simple imperative language.
Journal of Computer Security, 15(3):321–371, 2007.
[12] M. R. Clarkson, A. C. Myers, and F. B. Schneider. Belief in
Information Flow. In Proc. IEEE Computer Security
Foundations Workshop (CSFW ’05), pages 31–45. IEEE,
2005.
[13] J. Clulow. The Design and Analysis of Cryptographic
Application Programming Interfaces for Security Devices.
Master’s thesis, University of Natal, SA, 2003.
[14] D. E. Denning. Cryptography and Data Security.
Addison-Wesley, 1982.
[15] C. Gomez, A. Sabharwal, and B. Selman. Chapter 20: Model
counting. In Handbook of Satisﬁability: Volume 185
Frontiers in Artiﬁcial Intelligence and Applications. IOS
Press, 2009.
[16] J. W. Gray. Toward a Mathematical Foundation for
Information Flow Security. Journal of Computer Security,
1(3-4):255–294, 1992.
[17] J. Heusser and P. Malacaria. Quantifying information leaks
in software. In Proc. Annual Computer Security Applications
Conference (ACSAC ’10). ACM, 2010.
[18] IBM Corporation. Interbank pin generation algorithm.
https://publib.boulder.ibm.com/infocenter/zos/
v1r9/topic/com.ibm.zos.r9.csfb400/inbkal.htm.
[19] B. Köpf and D. Basin. Automatically Deriving
Information-theoretic Bounds for Adaptive Side-channel
Attacks. Journal of Computer Security (to appear).
[20] B. Köpf and D. Basin. An Information-Theoretic Model for
Adaptive Side-Channel Attacks. In Proc. ACM Conference
on Computer and Communications Security (CCS ’07),
pages 286–296. ACM, 2007.
[21] B. Köpf and M. Dürmuth. A Provably Secure and Eﬃcient
Countermeasure against Timing Attacks. In Proc. 22rd IEEE
Computer Security Foundations Symposium (CSF ’09), pages
324–335. IEEE, 2009.
[22] B. Köpf and A. Rybalchenko. Approximation and
Randomization for Quantitative Information-Flow Analysis.
In Proc. 23rd IEEE Computer Security Foundations
Symposium (CSF ’10), pages 3–14. IEEE, 2010.
[23] B. Köpf and G. Smith. Vulnerability Bounds and Leakage
Resilience of Blinded Cryptography under Timing Attacks.
In Proc. 23rd IEEE Computer Security Foundations
Symposium (CSF ’10), pages 44–56. IEEE, 2010.
[24] G. Lowe. Quantifying Information Flow. In Proc. IEEE
Computer Security Foundations Workshop (CSFW ’02),
pages 18–31. IEEE, 2002.
[25] P. Malacaria. Risk assessment of security threats for looping
constructs. Journal of Computer Security, 18(2):191–228,
2010.
[26] J. L. Massey. Guessing and Entropy. In Proc. IEEE
International Symposium on Information Theory (ISIT ’94),
page 204. IEEE, 1994.
[27] S. McCamant and M. D. Ernst. Quantitative information ﬂow
as network ﬂow capacity. In Proc. Conf. on Programming
Language Design and Implementation (PLDI ’08), pages
193–205. ACM, 2008.
based upon Sampling Functions. In Proc. ACM Symposium
on Principles of Programming Languages (POPL ’05), 2005.
[28] J. K. Millen. Covert Channel Capacity. In Proc. IEEE
[33] A. D. Pierro, C. Hankin, and H. Wiklicky. Approximate
Symposium on Security and Privacy (S&P ’87), pages 60–66.
IEEE, 1987.
[29] C. Mu and D. Clark. An Interval-based Abstraction for
Quantifying Information Flow. ENTCS, 253(3):119–141,
2009.
[30] C. Mu and D. Clark. Quantitative Analysis of Secure
Information Flow via Probabilistic Semantics. In Proc. 4th
International Conference on Availability, Reliability and
Security (ARES ’09), pages 49–57. IEEE, 2009.
[31] J. Newsome, S. McCamant, and D. Song. Measuring
Channel Capacity to Distinguish Undue Inﬂuence. In Proc.
4th ACM Workshop on Programming Languages and
Analysis for Security (PLAS ’09). ACM, 2009.
Non-Interference. In Proc. IEEE Computer Security
Foundations Workshop (CSFW ’02), pages 3–17. IEEE,
2002.
[34] C. E. Shannon. A Mathematical Theory of Communication.
Bell System Technical Journal, 27:379–423 and 623–656,
July and October 1948.
[35] C. E. Shannon. Communication theory of secrecy systems.
Bell System Technical Journal, 28:656–715, 1949.
[36] G. Smith. On the foundations of quantitative information
ﬂow. In Proc. Intl. Conference of Foundations of Software
Science and Computation Structures (FoSSaCS ’09), LNCS
5504, pages 288–302. Springer, 2009.
[37] G. Steel. Formal analysis of PIN block attacks. Theoretical
[32] S. Park, F. Pfenning, and S. Thrun. A Probabilistic Language
Computer Science, 367(1-2):257–270, Nov. 2006.