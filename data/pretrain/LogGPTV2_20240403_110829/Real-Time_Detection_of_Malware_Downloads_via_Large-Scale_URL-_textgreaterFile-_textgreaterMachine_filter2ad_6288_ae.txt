behavioral classiﬁers. For example, an attacker might serve
a mix of benign and malicious ﬁles from their URLs to con-
fuse our system. However, we believe this will not trouble
Mastino notably. First, considering the way we compute
the behavior-based features (Section 3.2.2), our system still
takes into consideration the aggregate of badness reputations
of all ﬁles served from the attacker’s URLs and could still
distinguish these cases. Second, even though the attacker
could mix some good ﬁles in their URLs, they cannot alter
the badness reputation and labels of machines that contact
these URLs, because we assign badness reputation to ma-
chines not only based on their network-level history, but also
according to their system-level activities. Third, this type
of evasion might have a negative impact on behavior-based
features. Intrinsic features of benign and malicious ﬁles and
URLs, however, could still steer Mastino towards correct
decisions and play an important role in improving our accu-
racy as it is shown in Section 5.4.
3
Varying between 16.5K to 16.9K, due to the eﬀect of packing.
792Similarly, to evade detection and introduce noise, attack-
ers might try to somehow utilize legitimate and popular do-
mains. For example, they might host their malware on cloud
storage services. Since the URLs of these domains are also
used to store legitimate softwares, some amount of noise
might be introduced when computing behavior-based fea-
tures for ﬁles and URLs. To reduce the amount of noise, we
try to ﬁlter out these types of domains from our whitelist
(see Section 4.1). However, due to the number of such do-
mains and services, it is diﬃcult to ﬁlter all of them out. De-
spite this, Mastino still achieves very high accuracy while
incurring very low FP rates. Again, intrinsic features assist
us signiﬁcantly in these situations as well.
Another challenge is the detection of ﬁles and URLs for
which no prior information is available in our download
graph, i.e. the test samples of Fu and Uu (see Section 5.2.1).
Mastino, however, performs remarkably well on these test
datasets by taking full advantage of all the three layers of
the download graph plus the intrinsic features. We also pro-
vided multiple case studies in Section 5.8 to further point
out how Mastino enables detection in these diﬃcult cases.
We need to compute badness reputation and assign la-
bels for nodes in all three layers of the tripartite download
graph, including machines.
In reality, machines’ true la-
bels might change during training window T . So our labels
for machines might not be completely accurate during the
whole T due to their ﬂeeting nature. For example, a ma-
chine will be labeled as vulnerable, if it downloaded enough
malwares during training window T or visited multiple mali-
cious URLs, but it is possible that after visiting those URLs
and downloading malware ﬁles and getting infected, an AV
agent disinfected the machine. However, the machine’s la-
bel will stay as vulnerable in the graph for T . Despite this,
we still believe that keeping the machine’s label as vulnera-
ble is useful, even if it is cleaned currently, due to the fact
that it had a tendency of downloading malwares and visit-
ing malicious URLs and it could likely do so again. We also
showed in Section 5.4 that machines’ reputations are helpful
in improving our accuracy.
7. RELATED WORK
Traditional approaches in malware detection involve ana-
lyzing the binaries by statically inspecting the code or eval-
uating their behavior at runtime [4, 5, 15, 20, 23, 25]. Unfor-
tunately, the time to detect malwares is quite high in these
methods and they simply cannot keep up with thousands of
new and unknown ﬁles observed daily in the wild.
A large corpus of research focus on DNS-based reputation
systems [1–3, 6], which primarily focus on detecting IP ad-
dresses and domain names associated with malicious activi-
ties, e.g. hosting C&C servers or “drop zones”. Mastino is a
diﬀerent system that not only could detect malicious URLs,
it can also provide real-time protection against malware ﬁles
and can label download events using a novel tripartite graph
mining model.
Graph mining, as a general technique to reason on data
modeled as a graph, has been successfully applied in dif-
ferent domains of system security. Polonium [8] aims to
detect malware ﬁles using graphical models. While their
graph-based approach is similar to ours, we identify the fol-
lowing fundamental diﬀerences: Polonium employs a very
expensive loopy belief propagation algorithm and adopts an
oﬄine approach, by running the algorithm on the entire
(huge) graph, which is very time consuming and costly. As
opposite, we do real-time detection and proactively detect
malware download events so that malware ﬁles can be imme-
diately quarantined (or removed) to prevent their execution
on the client machine; Polonium does not consider the URL
layer and only classiﬁes ﬁles. Our approach extends the anal-
ysis to the URL from where the ﬁle was downloaded, and
we concurrently classify ﬁles and URLs. In addition, as we
showed in our evaluation, all layers, including URL layer, are
helpful in improving the system overall performance; The
Polonium’s paper does not reveal how the reputation of ma-
chines is computed. On our side, we present and describe,
in detail, which intrinsic machine’s features are helpful in
improving the results – for example, the download history
of a machine and the downloading process.
Manadhata et al.
in [16] also introduce a system that
detects malicious domains by constructing a host-domain
graph that runs belief propagation. Relationships between
ﬁles (e.g., between binaries) have also been modeled with
graphs in [21] and [24] to detect malwares. Recently, au-
thors of [13] also proposed a system to detect malwares by
following the chains of downloads on individual hosts initi-
ated by malware droppers. Mastino is diﬀerent from these
systems as it provides simultaneous detection of malicious
ﬁles, URLs, and download events, in general.
More recently, authors in [18] build bipartite graphs from
passive DNS traﬃc collected from large ISP networks, with
the goal of representing the who is querying what relation-
ship. They run a graph-based behavioral classiﬁer that sug-
gests for domains used in C&C operations. Unlike this work,
Mastino is not limited to only detecting C&C servers and
can deal with all sort of malicious URLs.
Nazca [12] focuses on detecting malware downloads by
identifying the network infrastructure (domain, IPs, URLs)
that support malware installation campaigns (e.g., drive-by
download campaigns). Nazca is designed to be deployed at
the edge of ISP networks, and only inspects network traf-
ﬁc without performing any analysis of the ﬁle properties
or reputation of the downloading client. On the contrary,
Mastino combines information from URLs, ﬁles, and client
machines to accurately detect new malware downloads in
real time.
AMICO [22] and Google’s CAMP [19] distinguish between
benign and malicious ﬁles by reasoning on the download
behavior of client machines. However, we identify several
fundamental diﬀerences with our work. AMICO performs
on-the-ﬂy reconstruction of the download from HTTP net-
work traﬃc. This is expensive and limits its adoption to
non-encrypted traﬃc and standard protocols. AMICO, for
example, cannot detect modern ransomwere like Torrent-
Locker [14], which hosts the cash-out infrastructure in the
Tor network – i.e., a series of circuits of encrypted connec-
tions as routing relays. In the same way, CAMP only detects
ﬁles as been downloaded from the browser (i.e., Chrome).
This makes the system ineﬀectual against malware updates
(e.g., from botnets), second-stage malware (often employed
in large malware campaigns), or any ﬁle downloaded by a
generic client. In addition, as the downloaded ﬁle is inter-
cepted and reconstructed at browser-level, multi-stage infec-
tions (i.e., where the drive-by’s execution code downloads
the malware in multiple steps) might not been eﬃciently
identiﬁed by CAMP, or exploits triggering vulnerabilities in
the browser might disable the anti-malware solution.
793Our system, in addition to overcome the limitation hereby
described, aims at protecting users’ machine independently
from their networking conﬁguration. AMICO, for example,
collects download information at network level and is use-
ful in protecting machines when installed in LANs – but it
fails with protecting machines like laptops switching across
diﬀerent networks (e.g., wireless or 4G). Another important
diﬀerence in approach is the lack of system-level informa-
tion about the machine that downloaded the ﬁle, e.g. about
the client process that initiated the download and the des-
tination path where the downloaded ﬁle is stored. As we
showed in our evaluation, these features help in improving
our system. Finally, both AMICO and CAMP are only able
to detect malware ﬁles, but Mastino leverages a tripartite
download graph to enable concurrent detection of bad URLs,
malware ﬁles, and malicious download events in general.
8. CONCLUSION
In this paper, we presented Mastino a novel system that
is cable of eﬃciently detecting malware download events in
real time by passively monitoring the download events of
users. We developed a proof-of-concept prototype of the
system and evaluated it using real-world data. Our evalu-
ation results show that the system can detect malware ﬁles
and malicious URLs with high accuracy while only incur-
ring less than 0.5% FPs. We discussed the eﬃciency of the
system and the fact that it only takes a fraction of a second
to provide accurate classiﬁcation of ﬁles or URLs submit-
ted to the system. We analyzed our classiﬁcation results in
details and provided interesting case studies of Mastino’s
real-world operation.
Acknowledgments
This material is based in part upon work supported by the
National Science Foundation, under grant No. CNS-1149051.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do not
necessarily reﬂect the views of the National Science Founda-
tion. This work is also partially supported by a grant from
the Auburn University at Montgomery Research Grant-in-
Aid Program. Additional acknowledgments go to Trend Mi-
cro’s Forward-Looking Threat Research (FTR), SPN and
Machine Learning teams who supported the research in dif-
ferent forms.
9. REFERENCES
[1] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and
N. Feamster. Building a dynamic reputation system for
dns. In USENIX security symposium, pages 273–290, 2010.
[2] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou II, and
D. Dagon. Detecting malware domains at the upper dns
hierarchy. In USENIX Security Symposium, page 16, 2011.
[3] M. Antonakakis, R. Perdisci, Y. Nadji, N. Vasiloglou II,
S. Abu-Nimeh, W. Lee, and D. Dagon. From throw-away
traﬃc to bots: Detecting the rise of dga-based malware. In
USENIX Security Symposium, pages 491–506, 2012.
[4] U. Bayer, C. Kruegel, and E. Kirda. TTAnalyze: A tool for
analyzing malware. na, 2006.
[5] J. Bergeron, M. Debbabi, J. Desharnais, M. M. Erhioui,
Y. Lavoie, N. Tawbi, et al. Static detection of malicious
code in executable programs. Int. J. of Req. Eng,
2001(184-189):79, 2001.
[6] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. Exposure:
Finding malicious domains using passive dns analysis. In
NDSS, 2011.
[7] L. Breiman. Random forests. Machine learning, 45(1):5–32,
2001.
[8] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and
C. Faloutsos. Polonium: Tera-scale graph mining for
malware detection. In ACM SIGKDD Conference on
Knowledge Discovery and Data Mining, 2010.
[9] M. Felegyhazi, C. Kreibich, and V. Paxson. On the
potential of proactive domain blacklisting. In Proceedings of
the 3rd USENIX conference on Large-scale exploits and
emergent threats: botnets, spyware, worms, and more,
pages 6–6. USENIX Association, 2010.
[10] Google. Google Safe Browsing. https:
//www.google.com/transparencyreport/safebrowsing/.
[11] F. Guo, P. Ferrie, and T.-C. Chiueh. A study of the packer
problem and its solutions. In Recent Advances in Intrusion
Detection, pages 98–115. Springer, 2008.
[12] L. Invernizzi, S. Miskovic, R. Torres, S. Saha, S. Lee,
M. Mellia, C. Kruegel, and G. Vigna. Nazca: Detecting
malware distribution in large-scale networks. In Proceedings
of the Network and Distributed System Security
Symposium (NDSS), 2014.
[13] B. J. Kwon, J. Mondal, J. Jang, L. Bilge, and T. Dumitras.
The dropper eﬀect: Insights into malware distribution with
downloader graph analytics. In Proceedings of the 22nd
ACM SIGSAC Conference on Computer and
Communications Security, pages 1118–1129. ACM, 2015.
[14] K. Lab. Torrentlocker ransomware.
http://www.kaspersky.com/internet-security-center/
threats/torrentlocker-malware, 2015.
[15] W.-J. Li, K. Wang, S. J. Stolfo, and B. Herzog. Fileprints:
Identifying ﬁle types by n-gram analysis. In Information
Assurance Workshop, 2005. IAW’05. Proceedings from the
Sixth Annual IEEE SMC, pages 64–71. IEEE, 2005.
[16] P. Manadhata, S. Yadav, P. Rao, and W. Horne. Detecting
malicious domains via graph inference. In Proceedings of
the 2014 Workshop on Artiﬁcial Intelligent and Security
Workshop, pages 59–60. ACM, 2014.
[17] J. Oberheide, E. Cooke, and F. Jahanian. Cloudav:
N-version antivirus in the network cloud.
[18] B. Rahbarinia, P. Roberto, and M. Antonakakis. Segugio :
Eﬃcient Behavior-Based Tracking of Malware-Control
Domains in Large ISP Networks. DSN ’15 (45th Annual
IEEE/IFIP International Conference on Dependable
Systems and Networks), (3), 2015.
[19] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and
N. Provos. Camp: Content-agnostic malware protection. In
NDSS, 2013.
[20] N. Solutions. Norman sandbox whitepaper, 2003.
[21] A. Tamersoy, K. Roundy, and D. H. Chau. Guilt by
association: large scale malware detection by mining
ﬁle-relation graphs. In Proceedings of the 20th ACM
SIGKDD international conference on Knowledge discovery
and data mining, pages 1524–1533. ACM, 2014.
[22] P. Vadrevu, B. Rahbarinia, R. Perdisci, K. Li, and
M. Antonakakis. Measuring and detecting malware
downloads in live network traﬃc. In Computer
Security–ESORICS 2013, pages 556–573. Springer, 2013.
[23] C. Willems, T. Holz, and F. Freiling. Toward automated
dynamic malware analysis using cwsandbox. IEEE Security
& Privacy, (2):32–39, 2007.
[24] Y. Ye, T. Li, S. Zhu, W. Zhuang, E. Tas, U. Gupta, and
M. Abdulhayoglu. Combining ﬁle content and ﬁle relations
for cloud based malware detection. In Proceedings of the
17th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, KDD ’11, pages
222–230, New York, NY, USA, 2011. ACM.
[25] H. Yin, D. Song, M. Egele, C. Kruegel, and E. Kirda.
Panorama: capturing system-wide information ﬂow for
malware detection and analysis. In Proceedings of the 14th
ACM conference on Computer and communications
security, pages 116–127. ACM, 2007.
794