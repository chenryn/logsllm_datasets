and vice versa. We plot the results in Figure 2. We ﬁnd
that the range of possible overheads for WT is quite small
compared to Tamaraw. Half-duplex communication in-
duces a 30% time overhead in our experiments, so that is
the minimum value for WT. While the overhead of Tama-
raw can vary signiﬁcantly, its range of both bandwidth
USENIX Association
26th USENIX Security Symposium    1383
cause cell sequences to collide. We measure the effec-
tiveness by deﬁning a notion of Maximum Attacker Ac-
curacy (MAA). The MAA of a cell sequence is equal to:
MAA(s) =
|{s(cid:48) ∈ C(s)|Page(s(cid:48)) = Page(s)}|
|C(s)|
The MAA describes an attacker who, seeing that they
cannot distinguish between any of the cell sequences in
the collision set, decides to simply randomly guess which
page it is. On the other hand, if all cell sequences in
the collision set belong to the same page anyway, the
attacker’s guess will be exactly correct. The attacker
maximizes classiﬁcation accuracy in the sense that they
know exactly which page each cell sequence belongs to
(Page(s) is known to the attacker for all s). No classiﬁer’s
accuracy can exceed the MAA; the lower the MAA, the
more effective the defense. We thus favor the MAA as an
intuitive, attack-agnostic metric for measuring the mini-
mum effectiveness of a defense. Later, in Section 6.2,
we expand on the MAA by investigating WT in an open-
world scenario with different page visit rates; for now,
we evaluate WT on a simpler MAA.
It is easy to see that the MAA of Walkie-Talkie is 0.5.
Each cell sequence is in a collision set with exactly one
other cell sequence from a different page due to burst
molding. Furthermore, since the decoy page selection
mechanism is symmetric (Section 4.3.2), the collision set
does not reveal which cell sequence is the true cell se-
quence. However, if we increase the number of colliding
cell sequences, the MAA can lower further. We develop
this idea next.
5.4.2 Maximum Attacker Accuracy of WT
In the context of WT, the MAA is that of an attacker who
knows exactly which two pages can be the decoy page
and the real page, but not which is which. In other words,
he resorts to guessing one out of two pages. We can de-
crease his MAA by molding towards the supersequence
of several decoy cell sequences, not just one decoy cell
sequence.
The greater the number of cell sequences chosen, the
greater the overhead. We investigate the MAA of WT
and compare it with Tamaraw. We show the results in
Figure 3, plotting MAA against bandwidth overhead.
WT is generally more efﬁcient even if the user desires
a very low MAA. The time overhead of WT goes up to
45% for the values in this graph, while it increases much
more quickly for Tamaraw, from 130% to 350%.
WT has another advantage over other WF defenses:
any defended cell sequence could have come from many
different web pages. This is because any subsequence of
a defended cell sequence could have been the original un-
defended cell sequence. Not all possibilities are equally
Figure 2: Bandwidth and time overhead for Tamaraw and
WT.
and time overhead is in any case much higher than that of
WT. To reach a bandwidth overhead less than 100%, for
example, a time overhead over 150% is required, which
is a large increase in page load time.
To investigate the trade-off between overhead and ef-
fectiveness, we need a general notion of effectiveness for
all attacks, not just any given attack. We next develop
such a notion and show that WT is effective against all
WF attacks in general.
5.4 Defending against any classiﬁcation at-
tack
Observing that many older defenses have not proven ef-
fective against newer attacks, authors in the ﬁeld [4, 31]
have suggested that a defense should be designed to be
effective against all possible WF attacks. To do so, the
output cell sequences of some web pages should be ex-
actly the same as some other web pages. To be spe-
ciﬁc, the cell sequences should be the same length, and
the timing, direction, and size of all cells should be the
same.3 If this is achieved, then no attacker can distin-
guish between those web pages, independent of the clas-
siﬁcation mechanism they use.
The above is achieved in both Tamaraw and WT. We
compare Tamaraw and WT in terms of their effectiveness
against all possible WF attacks.
5.4.1 Maximum Attacker Accuracy
Borrowing terminology from the k-anonymity literature,
we say that two cell sequences s,s(cid:48) belong to the same
collision set C(s) if they become the same sequence af-
ter applying the defense. They may come from different
web pages; we denote the page a cell sequence comes
from as Page(s). An effective defense’s objective is to
3We do not need to ensure that the cells were received at the same
time including network noise; we only need to ensure that the cells were
attempted to be sent at the same time, as any timing difference then
would only indicate network noise and reveals no information about
the cells themselves.
1384    26th USENIX Security Symposium
USENIX Association
 0 50 100 150 200 250 300 0 50 100 150 200 250 300Time Overhead (%)Bandwidth Overhead (%)TamarawWT6 Extensions of Walkie-Talkie
In this section, we present several extensions of Walkie-
Talkie to defeat three WF attackers that are more ad-
vanced than that of previous work.
In Section 6.1 we
describe multi-page attackers, who understand the rela-
tionship between several pages of the same site and can
determine when the client is on the same site. In Sec-
tion 6.2 we describe attackers who know that the client
visits pages at different base rates, and can estimate this
base rate.
In Section 6.3 we investigate attackers that
can use timing information to defeat Walkie-Talkie. We
show that, with some modiﬁcations, WT can effectively
defend clients at little extra cost against all of these ad-
vanced attackers.
6.1 Defending against multi-page classiﬁ-
cation
In Section 5, we analyzed Walkie-Talkie against an at-
tacker who classiﬁes pages one at a time, independently
of any other page. A realistic attacker could leverage his
knowledge of the link structure of web sites to achieve
greater accuracy. For example, if the attacker knows a
priori that two web page accesses came from the same
site, then the attacker can more accurately identify what
site that is.
Defending against multi-page classiﬁcation critically
relies on the ability to specify which non-sensitive decoy
page to use for each sensitive page. With this feature, we
can specify non-sensitive pages from the same site as de-
coys when the client is visiting sensitive pages from the
same site. BuFLO-based defenses are unable to specify
decoy pages, while Supersequence and Glove must suf-
fer signiﬁcant overhead to do so. However, WT is able
to choose decoy pages with great efﬁciency. WT is thus
well suited as a defense against multi-page classiﬁcation.
We modify WT so that it chooses decoy pages more clev-
erly. When the client is visiting sensitive pages from the
same site, WT also mimics non-sensitive pages from the
same site, each one of which is likely to lead to the next.
With the above modiﬁcation, WT will succeed in de-
fending clients against multi-page attacks, which no pre-
vious WF defense has done. To demonstrate this, we will
evaluate its overhead and Maximum Attacker Accuracy
against multi-page attackers. We expect the overhead to
be higher than before, because the client has less freedom
of choice in page selection.
We experiment by conﬁguring our Tor Browser client
to randomly follow links on each of Alexa’s top 100 sites.
Unfortunately, we do not know the true probabilities with
which real clients visit links from Alexa’s top 100 sites,
so we choose the next link uniformly randomly from the
set of all links on the page. The client stops after 10 page
Figure 3: Bandwidth overhead and MAA for Tamaraw
and WT across a range of parameters. No WF attack can
achieve a classiﬁcation accuracy above the MAA.
Figure 4: Cumulative distribution frequency graph of
WT collision set sizes. A collision set of a defended
cell sequence is the set of undefended cell sequences that
could have generated it when the defense is applied.
likely: burst molding attempts to minimize overhead, so
from the attacker’s perspective, the true cell sequence is
not likely to be much smaller than the observed cell se-
quence. Nevertheless, this observation produces a con-
fusing effect on the attacker that has not been accounted
for in the MAA; that is, a realistic attacker’s accuracy is
likely to be lower than the MAA.
We evaluate this effect on our closed-world page set
of 100 pages and 100 instances each. For each defended
cell sequence, we calculate the number of possible unde-
fended cell sequences from other web pages that could
have generated it. We call this the collision set size. The
maximum collision set size is therefore 9900. We show
the cumulative distribution frequency graph in Figure 4.
There was only a .1% chance that the collision set size
was smaller than 10 (it was always at least 2 because of
burst molding), and a 4% chance that it was smaller than
100. The median collision set size was 860. We con-
trast this with Tamaraw, where on our data set there was
a 2% chance that the collision set size was smaller than
10 and a 13% chance it was smaller than 100; the largest
collision set size was 795. The attacker’s ability to rule
out possible web pages given a defended cell sequence is
much more limited under WT.
USENIX Association
26th USENIX Security Symposium    1385
 0 0.2 0.4 0 40 80 120 160MAABandwidth Overhead (%)TamarawWT 0 0.2 0.4 0.6 0.8 1 0 2000 4000 6000 8000 10000Number of possible cell sequencesloads. Then, we test the bandwidth and time overhead of
a client attempting to decoy random sensitive pages with
those page loads. We ﬁnd that, maintaining an MAA of
0.5, the bandwidth overhead necessary to defend against
a multi-page attacker increases from 31% to 53%, and
the time overhead increases from 34% to 42%. The in-
crease is small, and demonstrates that a client can effec-
tively defend herself against multi-page attacks as well,
with no decrease in minimal defense effectiveness.
Incorporating prior knowledge
6.2
For analytical simplicity, our experiments assumed a
client that visits all pages with the same likelihood; to
our knowledge, all other works in website ﬁngerprinting
make this assumption. Realistically, a client would visit
pages with different probabilities, and the attacker may
have prior knowledge of such a distribution. Here, we
remove the previous assumption and adopt a model for
estimating page likelihood, assuming that the attacker
knows the client’s distribution fully. We examine how
this affects Walkie-Talkie.
We obtain basic estimated page view data for Alexa’s
top 10,000 sites from StatShow, and perform least-
squared approximation on the logarithm of the number
of page views. We attempted to approximate the number
of page views with the following function
Views = a· ebx · (x + 1)c
In the above, a, b, and c are parameters, and x being the
index of the page (1 being most popular). We obtain the
parameters by performing Levenberg-Marquardt least-
squared approximation on the logarithm of the above
function, resulting in a = 36000, b = −0.000083, c =
−1.0. However, we found that the number of page views
dropped precipitously near the end of our data set, ren-
dering parameter estimation inaccurate. We believe this
is because our list of top sites was incomplete at the end
of the list. Instead of trying to ﬁt all of our data, we ﬁt the
top 5,000 sites and then extrapolate. The resultant curve
had a mean squared error of 0.0002 on the logarithm of
the number of page views.
We simulate clients that visit pages with probability
based on this curve, with no limit on the index of the
page. Our model suggests that 57% of all page views are
in the top 100 sites, and 40% of all page views are in the
next 10,000 sites. We use the former set as non-sensitive
decoy pages and the latter as monitored sensitive pages.
Considering an ambitious, powerful attacker who is al-
ways capable of identifying the potential decoy and sen-
sitive page in a WT-protected page access (but not which
is which), the attacker can achieve a precision of 41% by
simply guessing that all pages are sensitive (with a recall
of 100%). In a more realistic scenario when the attacker
Figure 5: Maximum precision/recall graph for an at-
tacker on Tor defended by WT, after incorporating page
likelihood.
is interested in much fewer than 10,000 pages, the maxi-
mum precision would be proportionally lower.
We draw the attacker’s precision/recall curve by hav-
ing him cleverly choose to identify sensitive pages in de-
creasing order of precision, and gradually increasing the
set of such pages he was willing to classify. This gives
the attacker the maximum precision at each level of re-
call. We draw the graph in Figure 5. For instance, we
ﬁnd that at 25% recall, the attacker has a maximum pre-
cision of 90%. Even with such a low recall, the attacker
frequently makes mistakes in identifying sensitive pages.
We can contrast this with kNN, which can achieve a pre-
cision of 99% with a recall of 80% on a non-defended Tor
data set [31]. The attacker’s precision does not change
even if the attacker had prior information indicating that
the client is not visiting certain monitored pages, as long
as the visit rate of other pages is unchanged.
We consider a page-view-sensitive variation of WT
where we also choose decoy pages based on the popu-
larity of the page, not just the potential overhead. This
method would come with a penalty to the overhead. We
take the value of maximum precision for at least 25%
recall, and we we plot the graph of maximum precision
to bandwidth overhead in Figure 6. (Time overhead in-
creased slowly from 34% to 42% within the range of
this graph.) The maximum precision starts at 90% and
then drops sharply to 64%.
(The minimum precision
of simply randomly guessing if each page is sensitive
is 41%.) However, as we increase the weight for page
popularity further, we see that the maximum precision
increases counter-productively. This represents the case
where the client starts choosing only the ﬁrst few most
popular pages, which limits her set of potential decoys,
weakening her defense.
Intercell timing
6.3
WT may have a subtle timing leak: the incoming cell rate
may leak information about the destination web page—
more precisely, the number of servers that are sending in-
1386    26th USENIX Security Symposium
USENIX Association
 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1Maximum PrecisionRecallFigure 6: Maximum precision/bandwidth overhead
graph for an attacker on Tor defended by a page-view-
sensitive variation of WT. The variation decreases preci-
sion further for a small increase in bandwidth overhead.
formation simultaneously, and their possible processing
times before starting to send the page data. For outgo-
ing cells, timing leaks no information for WT, because
there is only one client and half-duplex communication
ensures that the client is dumping all the requests she can
send as quickly as possible, after which she falls silent.
In this section, we ﬁrst argue with empirical evidence
why the incoming intercell timing leak of WT may not
be practically usable by any attacker. Nevertheless, we
then show how WT can be modiﬁed to cover any possi-
ble incoming intercell timing leak. Despite the lack of
empirical evidence that this timing leakage can be lever-
aged by any attacker, we provide such a modiﬁcation to
preserve the theoretical guarantees of WT against future
WF attacks that may more cleverly use intercell timing.
Is timing useful for classiﬁcation?
The results of this work have already suggested that
in Section 5.2 and Sec-
intercell timing is not useful:
tion 5.3, we allowed WT to leak intercell timing, and WT
was nevertheless able to efﬁciently defeat known attacks.
In fact, WF researchers tend to avoid the use of intercell
timing in general: out of fourteen known WF attacks we
surveyed, we found that only three attacks used intercell
timing: the two oldest WF attacks [2, 29] (both are sig-
niﬁcantly less effective than newer attacks on Tor), and
kNN [31]. We speciﬁcally saw in Table 3 that intercell
timing does not aid classiﬁcation in kNN either. We ran
a further classiﬁcation test using kNN only on extracted
intercell timing values of the top 100 pages, and achieved
a 0.5% TPR.
We suggest that this is because intercell timing is
highly inconsistent for the same site, but the distribu-
tion of timings is similar across different sites. Network
conditions ﬂuctuate rapidly as proxies need to be rotated
frequently to safeguard anonymity. We constructed ker-