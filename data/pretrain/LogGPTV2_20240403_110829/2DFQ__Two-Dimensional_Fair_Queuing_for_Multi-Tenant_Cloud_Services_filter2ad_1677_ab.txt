ants from each other. In such cases, aggressive tenants can
overload the process and gain an unfair share of resources.
In the extreme, this lack of isolation can lead to a denial-of-
service to well-behaved tenants and even system wide outages.
For example, eBay Hadoop clusters regularly su(cid:242)ered denial of
service attacks caused by heavy users overloading the shared
HDFS NameNode [z§,h(cid:13)]. HDFS users report slowdown for
a variety of reasons: poorly written jobs making many API
calls [hh]; unmanaged, aggressive background tasks making
too many concurrent requests [hz]; and computationally ex-
AAAAAAAAAAAAAAAAAAAAAA…BBBBBBBBBBBBBBBBBBBBBB…CDCDCDABABABABABABABABABABABABABABABABABABABABABABABABABAB…CDCDCD …pensive APIs [z˙]. Impala [h6] queries can fail on overloaded
Kudu [(cid:13)¸] clusters due to request timeouts and a lack of fair
sharing [h˙]. Cloudstack users can hammer the shared man-
agement server, causing performance issues for other users
or even crashes [¸(cid:13)]. Guo et al. [z6] describe examples where
a lack of resource management causes failures that cascade
into system-wide outages: a failure in Microso(cid:22)’s datacenter
where a background task spawned a large number of threads,
overloading servers; overloaded servers not responding to
heartbeats, triggering further data replication and overload.
Given the burden on application programmers, inevitably,
many systems do not provide isolation between tenants, or
only utilize ad-hoc isolation mechanisms to address individual
problems reported by users. For example, HDFS recently intro-
duced priority queueing [z(cid:146)] to address the problem that “any
poorly written MapReduce job is a potential distributed denial-
of-service attack,” but this only provides coarse-grained throt-
tling of aggressive users over long periods of time. CloudStack
addressed denial-of-service attacks in release (cid:13).¸, adding man-
ually conßgurable upper bounds for tenant request rates [¸h].
A recent HBase update [h¸] introduced rate limiting for oper-
ators to throttle aggressive users, but it relies on hard-coded
thresholds, manual partitioning of request types, and lacks
cost-based scheduling. In these examples, the developers iden-
tify multi-tenant fairness and isolation as an important, but
diıcult, and as-yet unsolved problem [¸§,h˙,(cid:13)6].
Research projects such as Retro [(cid:13)h], Pulsar [h], Pisces [(cid:254)z],
Cake [@§], IOFlow [(cid:254)(cid:13)], and more [@¸], provide isolation in
distributed systems using rate limiting or fair queueing. Rate
limiters, typically implemented as token buckets, are not de-
signed to provide fairness at short time intervals. Depending
on the token bucket rate and burst parameters, they can either
underutilize the system or concurrent bursts can overload it
without providing any further fairness guarantees. Fair queue-
ing is an appealing approach to provide fairness and isolation
because it is robust to dynamic workloads. However, as we
demonstrate in §h, in many systems, request costs can vary by
up to four orders of magnitude and are unpredictable, which
can cause head-of-line blocking for small requests and signiß-
cantly increase latencies.
Desirable Properties. In this paper, we characterize a resource
isolation mechanism that provides “so(cid:22)” guarantees by using
a fair scheduler. _e scheduler attempts to share the resources
available within a process equally or in proportion to some
weights among tenants currently sending requests to the sys-
tem. Incoming requests are sent to (logical) per-tenant queues.
_e system runs a set of worker threads, typically in the low ¸§s,
but sometimes in the ¸§§s, to process these requests. When a
worker thread is idle, it picks the next request from one of the
per-tenant queues based on a scheduling policy that seeks to
provide a fair share to each of the tenants.
We specify two desirable properties of such a scheduler.
First and foremost, the scheduler should be work conserving —
a worker thread should always process some request when it
becomes idle. _is property ensures that the scheduler max-
imizes the utilization of resources within a datacenter. _is
requirement precludes the use of ad-hoc throttling mecha-
nisms to control misbehaving tenants.
146
WFQ keeps track of the work done by each tenant over
time and makes scheduling decisions by considering the work
done so far and cost of each tenant’s next request. To track
fair share, the system maintains a virtual time which increases
by the rate at which backlogged tenants receive service, for
example, for (cid:13) tenants sharing a worker thread of capacity ¸§§
units per second, virtual time advances at a rate of z(cid:254) units per
second; for (cid:13) tenants sharing two worker threads each with
capacity ¸§§ units per second, virtual time advances at a rate
f) to denote
of (cid:254)§ units per second; and so on. We use A(r j
f)) to denote the system virtual time when
server, and v(A(r j
f) as follows:
f) and virtual ßnish time F(r j
start time S(r j
S(r j
f)+ l j
F(r j
f)), F(r j−¸
f)= S(r j
f)= max{v(A(r j
f )}
simply the ßnish time of the(j− ¸)th request, unless the tenant
where  f is the weight of tenant f and l j
f is the size of the
request. For a single tenant, the start time of the jth request is
the wallclock arrival time of the jth request of tenant f at the
the request arrived. WFQ stamps each request with a virtual
f
 f
Second, the scheduler should not be bursty when servicing
di(cid:242)erent tenants. For example, a scheduler that alternates be-
tween extended periods of servicing requests from one tenant
and then the other is unacceptable even though the two ten-
ants get their fair share in the long run. Providing fairness at
smaller time intervals ensures that tenant request latency is
more stable and predictable, and mitigates the aforementioned
challenges like denial-of-service and starvation.
Fair Queueing Background. A wide variety of packet sched-
ulers have been proposed for fairly allocating link bandwidth
among competing network (cid:6)ows. _eir goal is to approximate
the share that would be provided under Generalized Proces-
sor Sharing (GPS) [(cid:13)@], constrained in that only one packet
can be sent on the network link at a time, and that packets
must be transmitted in their entirety. Well-known algorithms
include Weighted Fair Queueing (WFQ) [(cid:13)@], Worst-case Fair
Weighted Fair Queueing (WFzQ) [@], Start-Time Fair Queue-
ing (SFQ) [zh], Deßcit Round-Robin (DRR) [(cid:254)§], and more.
We brie(cid:6)y describe WFQ.
was inactive, in which case it fast-forwards to the current
system virtual time. Each time a thread is free to process a
request, WFQ schedules the pending request with the lowest
virtual ßnish time.
Worst-case Fair Weighted Fair Queueing (WFzQ) [@] ex-
tends WFQ and is widely considered to have better fairness
bounds. _e authors identify and address a prominent cause
of bursty schedules that can occur on a single networking
link. WFzQ restricts WFQ to only schedule requests a(cid:22)er they
become eligible, with a request becoming eligible only if it
would have begun service in the corresponding GPS system,
i.e. S(r)≤ v(now).
Request scheduling across many threads is analogous to
packet scheduling across multiple aggregated links. Blanquer
and Özden previously extended WFQ to multiple aggregated
links and examined the changes to its fairness bounds, packet
delays, and work conservation [˙]. While they termed the
algorithm MSFQ, we retain the name WFQ in the interest of
familiarity, and use WFzQ to refer to the naïve work conserv-
ing extension of WFzQ to multiple aggregated links.
(a) Cost distributions for ¸§ APIs.
(b) Cost distributions for ¸z tenants.
Figure z: Measurements of Azure Storage show widely varying request costs.
Whiskers extend to ¸st and (cid:146)(cid:146)th percentiles; violins show distribution shape.
3. CHALLENGES
In this section we describe two challenges to providing fair-
ness in shared processes. _e ßrst challenge, described in §h.¸,
arises when requests with large cost variance are scheduled
across multiple threads concurrently. _e second challenge,
described in §h.z, arises when request costs are unknown and
diıcult to predict. To demonstrate the challenges we collect
statistics from (cid:254)-minute workload samples across (cid:254)§ produc-
tion machines of Azure Storage [(cid:13), (cid:146)], a large-scale system
deployed across many Microso(cid:22) datacenters.
3.1 High Request Cost Variability
We ßrst illustrate how request costs in shared services vary
widely, by up to (cid:13) orders of magnitude. For cost, we report the
CPU cycles spent to execute the request, and anonymize the
units. Other metrics we considered include wallclock execu-
tion time and dominant resource cost [z¸].
Figure za shows anonymized cost distributions for several
di(cid:242)erent APIs in Azure Storage, illustrating how some APIs
are consistently cheap (A), some vary widely (K), and some
are usually cheap but occasionally very expensive (G).
Figure zb shows cost distributions for several di(cid:242)erent ten-
ants of Azure Storage, illustrating how some tenants only make
small requests with little variation (T¸), some tenants make
large requests but also with little variation (T¸¸), and some
tenants make a mixture of small and large requests with a lot
of variation (T(cid:146)).
In aggregate across all tenants and APIs, request costs span
four orders of magnitude — a much wider range than net-
work packets, for which most scheduling algorithms were
developed, where sizes only vary by ¸.(cid:254) orders of magnitude
(between (cid:13)§ and ¸(cid:254)§§ bytes). High cost variance is not unique
to this production system and is shared by many popular open-
source systems as well: in storage and key-value stores, users
can read and write small and large objects; in databases, users
can specify operations that scan large tables; in conßguration
and metadata services, users can enumerate large lists and
directories. All of these operations can have very high cost
compared to the average operations in the system.
As illustrated in Figure ¸, both bursty and smooth schedules
are possible when there are multiple worker threads. Bursty
schedules adversely a(cid:242)ect tenants with small requests by servic-
ing them in high-throughput bursts rather than evenly paced
over time. Since realistic systems have such high cost variance,
Figure h: Le(cid:22): cost distributions of some tenants using API G, illustrating
variability across tenants. Right: scatter plot showing, for each tenant and
API, the average request cost (x-axis) and coeıcient of variation (y-axis)
for the tenant’s use of that API. Each point represents one tenant on one
API, indicated by color. Each API has tenants using it in predictable and
unpredictable ways.
tenants like T¸ will experience large service oscillations if the
scheduler lets too many expensive requests occupy the thread
pool. In §@ we verify that existing schedulers like WFQ and
WFzQ do produce bursty schedules in practice.
Our insight to generating smooth schedules is that given
the large number of available threads, we can spread requests
of di(cid:242)erent costs across di(cid:242)erent threads. In some cases it will
be preferable to prioritize small requests in order to prevent
long periods of blocking that would occur if we selected a
large request. We discuss the details of our approach in §(cid:13).
3.2 Unknown Request Costs
To motivate the second challenge we illustrate how some
tenants are dynamic, with varying and unpredictable request
costs. Figure (cid:13) shows time series for Tz, Th, and T¸§, illustrat-
ing request rates and costs for the APIs being used. Tz ((cid:13)a)
has a stable request rate, small requests, and little variation