VirusTotal [31] and a Google search. The resulting model
provided by the authors of Hidost was trained using the
randomly-sampled 5,000 malicious and 5,000 benign ﬁles. It is
reported to be robust against adversaries, where the number of
false negatives on another 5,000 random malicious ﬁles only
increased from 28 to 30 under what the authors claim is the
“strongest conceivable mimicry attack” [28].
IV. EVADING PDF MALWARE CLASSIFIERS
The proposed method could be applied to any security
classiﬁer, although its effectiveness depends on being able to
ﬁnd good genetic programming operators to search the feature
space efﬁciently and an appropriate ﬁtness function to direct
the search. In this section, we show how to instantiate our
design to ﬁnd evasive PDF malware.
A. PDF Parser and Repacker
The ﬁrst step is to parse the PDF ﬁle as a tree-like
representation. We will also need to regenerate a PDF ﬁle from
the tree representation, after it has been manipulated to produce
a new variant. For this, we use pdfrw [21], a python-based open
source library for parsing PDF ﬁles into the tree-like structure
and serializing that structure into an output PDF ﬁle.
It is important to note that pdfrw is not a perfect PDF
parser and repacker, and a number of PDF malware samples
have been malformed intentionally to bypass or confuse PDF
parsers used in malware detectors (while still being processed
by target PDF readers due to parser quirks). This means we
cannot test our method on PDF seed samples that cannot be
1The Mimicus authors were unable to locate one malicious ﬁle with the
MD5 hash 35b621f1065b7c6ebebacb9a785b6d69 in Contagio.
4
parsed by pdfrw, or that no longer exhibit malicious behavior
when they are unpacked and packed using pdfrw.
To avoid losing too many samples because of PDF parsing
issues, we modiﬁed pdfrw to loosen its grammar checking.
This signiﬁcantly increased the success rate of repacking PDF
malware samples. The modiﬁed version of pdfrw is available
at https://github.com/mzweilin/pdfrw.
instead,
In our modiﬁed pdfrw, we ignore several potentially cor-
rupted, malformed, or misleading auxiliary elements. The EOF
marks in PDF raw bytes are ignored;
the parser
reads in all bytes of a ﬁle. The cross-reference tables are
ignored; instead, it parses objects in the body directly without
any index. Stream length indicators are ignored; instead, the
parser detects the stream length with the endstream token.
The unpaired keys or values are also ignored in parsing
a dictionary. Ignoring these auxiliary elements signiﬁcantly
decreases parsing efﬁciency, thus, is only suitable for repacking
seed malware samples. All seeds are repacked with correct
auxiliary elements for efﬁcient parsing later. In addition, we
added support for parsing empty objects, which do exist in the
malware samples. The dictionary data structure was modiﬁed
to enable deep-copy in duplicating variants from seeds.
B. Genetic Operators
Since both of the classiﬁers we target employ the object
structure of the PDF ﬁle as features, we need to generate
variants by manipulating the PDF ﬁles at that level. (If we were
targeting JavaScript-based classiﬁers instead, we would instead
need to generate variants by manipulating the embedded
JavaScript code.) Due to the limited number of possible static
features, we believe it is reasonable to assume the attackers
have the knowledge of the manipulation level.
We use computational analogs of mutation in biological
evolution to generate evasive PDF malware variants. The
mutation operator changes any object in a PDF ﬁle’s tree-
like structure with low probability. An object is mutated with
probability given by the mutation rate, typically a number
smaller than 0.5. The mutation is either a deletion (the object
is removed), an insertion (another object is inserted after it), or
a replacement (this object is replaced with some other object).
We choose among these options with uniform random
probability. In the case of an insertion or replacement, a second
object is also chosen uniformly at random from a large pool
of objects segmented from benign PDFs. The external genome
helps to generate a more diverse population.
The other well-known operator, crossover, commonly used
in genetic algorithms, is not used in this work. We found it
was possible to achieve an 100% evasion rate only using the
simple mutation operations.
C. Oracle
We need an oracle to determine if a variant preserves
the seed’s malicious behavior. There is no perfectly accurate
malware detection technique that works universally (indeed, if
such a technique existed our work would not be necessary). In
this case we have one advantage that enables a highly-accurate
oracle for testing variants: we do not need an oracle that can
test for arbitrary malicious behavior, but instead only need to
Fig. 3. A PDF malware detection result given by the Cuckoo sandbox. The
left side shows the key API execution trace, the right is a screenshot captured
from the virtual machine.
verify that a particular known malicious action is performed
by the variant.
To do this, we use the Cuckoo sandbox [12]. Cuckoo
runs a submitted sample in a virtual machine installed with
a PDF reader and reports the behavior of the sample including
network APIs called and their parameters. Figure 3 shows
an example of malware detection results from Cuckoo. The
malware sample opened in a virtual machine exploited a dis-
closed buffer overﬂow vulnerability in Acrobat Readers (CVE-
2007-5659). The injected shellcode downloads four additional
pieces of malware from Internet and executes them. Since the
execution of Cuckoo was isolated from the Internet to avoid
spreading malware,
the shellcode just received malformed
executable ﬁles provided by INetSim, a network service simu-
lator [14]. However, the downloading and execution behaviors
detected by Cuckoo are enough to show that the shellcode
has been executed. By comparing the behavioral signature of
the original PDF malware and the manipulated variant, we
determine if the original malicious behavior is preserved. The
details on how we select and compare behavioral signatures
are deferred to Section V-A.
We only focus on the network behaviors of malware sam-
ples in this work. Although this setting prevents our method
from working on malware samples without network activity,
we believe it is not a real constraint in practice since malware
authors could always develop a way to verify the desired
malicious behaviors.
Cuckoo sandbox works well as an oracle, but is com-
putationally expensive. We experimented with other possible
oracles, including using Wepawet. Wepawet and similar de-
tection techniques only detect the malicious payloads, but do
not verify that the payload is actually executed in a real PDF
reader. Because many of the genetic mutations will disrupt that
execution, oracles that do not actually dynamically observe the
variant exhibiting the malicious behavior result in many false
positives (apparently evasive variants that would not actually
work as malware). Hence, it is important to use an oracle
that conﬁrms the malicious behavior is preserved through
actual execution. This limits the samples we can use in our
experiments to ones for which we can produce the malicious
behavior in our oracle’s test environment (Section V-A).
D. Fitness Function
A ﬁtness function gives the ﬁtness score of each generated
variant. Higher scores are better. Given 0 as a threshold value,
5
a variant with a positive ﬁtness score is evasive: it is classiﬁed
as benign and retains the malicious behavior.
In our case, the ﬁtness function captures both the output
of the oracle and the predicted result of the target classiﬁer.
The oracle is modeled as a binary function: oracle(x) = 1 if
x exhibits the malicious signature; otherwise, oracle(x) = 0.
In order to eliminate corrupted variants, we always assign the
lowest possible ﬁtness score to variants with oracle(x) = 0.
Based on the different scoring methods used by the target
classiﬁers, the ﬁtness functions are deﬁned separately. PDFrate,
as a random forest classiﬁer, outputs a conﬁdence value of
maliciousness from 0 to 1, typically with a threshold of 0.5.
Thus, we deﬁne its ﬁtness function as
(cid:26)0.5− pdfrate(x) oracle(x) = 1
ﬁtnesspdfrate(x) =
LOW SCORE
oracle(x) = 0
with evasive range of (0,0.5].
The SVM model of Hidost outputs negative (positive) dis-
tance of a benign (malicious) sample to hyperplane. Therefore,
for Hidost the ﬁtness function is deﬁned as
(cid:26)hidost(x)× (−1) oracle(x) = 1
ﬁtnesshidost(x) =
LOW SCORE
oracle(x) = 0
with evasive range of (0, +∞).
E. Selection
A selection process in GP can be as simple as always
selecting variants with higher ﬁtness scores in a generation.
However, it might happen that very few or even none of the
variants in a generation preserve the malicious behavior during
the evolutionary process. If the malicious behavior is lost from
the population, it is very unlikely the GP will ever ﬁnd an
evasive sample that exhibits the original malicious behavior.
In order to avoid degeneration in the population, we
designed a replacement mechanism in addition to the na¨ıve
selection process. The corrupted variants, which are judged
by the oracle as non-malicious, are assigned the lowest ﬁtness
score (LOW SCORE) and are replaced by either the original
malicious PDF,
the best variant found so far, or the best
variant found in the previous generation. We choose among
these options with uniform random probability when corrupted
variants occur, which ensures that a ﬁxed number of variants
are retained in each generation.
F. Trace Collection and Replay
The most common way to initialize a population is du-
plicating the original seed and performing a random mutation
operation on each copy. Considering the potentially common
properties across evasive variants, we accelerate the search
by reusing mutation traces that successfully led to evasive or
promising variants.
A mutation trace consists of a series of mutations deﬁned
by 3-tuple (mutation operator, target object path, ﬁle id: source
object path). For example,
(insert, /Root/Pages/Kids/1, 1: /Root/Pages/Kids/4)
6
inserts an external Page object from a benign ﬁle 1 to the
targeted PDF ﬁle. The three possible mutation operators are
deﬁned in Section IV-B. Though the target object path has
the same format as the source object path, they are paths in
different PDF ﬁles. The target object path refers to an object
in the variant, while the source object path points to an object
in an external benign ﬁle with the speciﬁed ﬁle id.
Mutation traces are added to two pools at
the end of
each GP search. If a GP search successfully generates evasive
variants, all of the corresponding mutation traces are added
to the success trace pool. Otherwise, a mutation trace that
generates the variant with the highest ﬁtness score is added to
the promising trace pool.
The traces in the two pools are replayed in the population
initialization to produce some variants for the ﬁrst generation.
If the number of usable traces is smaller than the population
size, additional variants are generated in the conventional way.
If the number is larger than the population size, the selection
process described in Section IV-E shrinks the population to the
speciﬁed size.
V. EXPERIMENT
We evaluate the effectiveness of the proposed method
by conducting experiments on the two target PDF malware
classiﬁers.
A. Dataset and Experiment Setup
We started with the 10,980 PDF malware samples in the
Contagio archive [5], from which we selected 500 suitable
samples for evaluation. These samples are veriﬁed by the
oracle as exhibiting malicious behavior, are classiﬁed by both
target classiﬁers as malicious, and can be correctly repacked
by pdfrw.
Malicious PDF Dataset. Table I summarizes the sample
selection procedure.
First, we ﬁltered out
the samples that don’t have any
network API calls by the shell code analysis of Wepawet,
leaving 9,688 out of 10,980 samples. This is not necessary
for our method, but useful since we use Wepawet to obtain
additional information about the samples.
Second, the remaining samples were tested in the Cuckoo
sandbox. According to the vulnerability information of each
sample provided by Wepawet, Adobe Acrobat Reader 8.1.1 is
the most common target PDF reader, except for CVE-2009-
9837 which targets Foxit readers. Thus, these samples were
loaded with Acrobat Reader 8.1.1. However, not all network
behaviors indicated by the static analysis on shell code can be
observed in Cuckoo even though we have selected a targeted
TABLE I.
SEED SELECTION.
Description
PDF Malware samples in Contagio
Samples with network API calls detected by Wepawet
Samples with network activities observed by Cuckoo
Unique samples correctly repacked by pdfrw
True positives of PDFrate
True positives of Hidost
Intersection of TPs in PDFrate and Hidost
Number
10,980
9,688
1,414
1,384
1,378
502
500
TABLE II.
COMPARISON OF NETWORK-BASED MALWARE SIGNATURES.
Source
API traces
API traces
Network trafﬁc
API traces
Network trafﬁc
Network trafﬁc
Description
Combination of HTTP URL requests and host
queries
Hosts queried through getaddrinfo()
Transport layer destination IP addresses
URLs requested through raw socket,
URLDownloadToFileW(), InternetOpenUrlA()
DNS queries
HTTP URL requests
Example
[http://stortfordaircadets.org.uk/ﬂash/exe.php?x=pdf,
stortfordaircadets.org.uk]
[stortfordaircadets.org.uk]
(udp: [192.168.57.2:53], tcp: [192.168.57.2:80])
[http://stortfordaircadets.org.uk/ﬂash/exe.php?x=pdf]
[stortfordaircadets.org.uk]
[http://stortfordaircadets.org.uk/ﬂash/exe.php?x=pdf]
Effective
Consistency
Average Minimum
500
497
476
473
462
460
0.95
0.95
0.85
0.95
0.93
0.93
0.50
0.50
0.10
0.50
0.10
0.10
PDF reader due to the imperfect network simulation in virtual
machines as well as the potential sandbox detection features
in malware. As a result, only 1,414 out of the 9,688 samples
were observed to have malicious network activities running on
Acrobat Reader 8.1.1 inside the Cuckoo sandbox.
Next, the 1,414 samples were repacked by the modiﬁed
pdfrw with less strict grammar checking, then re-tested by
Wepawet and Cuckoo. This resulted in 1,384 unique samples.
Eleven of the samples were corrupted during repacking and no
longer behaved maliciously in Wepawet or Cuckoo. The other
19 samples were found to be duplicates after being repacked.
This is a clear sign that malware authors have attempted to
evade detection through parsing obfuscation.
Since our goal is to evaluate the effectiveness of an evasion
attack, we need to ﬁlter out the false negative samples of
the target classiﬁers. PDFrate correctly classiﬁed 1,378 out of
the 1,384 samples as malicious, while Hidost only correctly
classiﬁed 502 of them. The intersection of the true positives
from both classiﬁers left a suitable evaluation set of 500 unique
PDF malware samples.
According to results from Wepawet, these 500 malware
samples exploit two different vulnerabilities in Acrobat Read-
ers: 333 of them exploit multiple buffer overﬂows reported in
CVE-2007-5659, the other 167 exploit a stack-based buffer
overﬂow reported by CVE-2009-0927. Both vulnerabilities
can be exploited to execute arbitrary code. In summary, the
payloads in the 500 samples access 255 different hosts to
download additional malware from the Internet.
The selection process leaves us with 500 samples from
the original 10,980 malware samples in the Contagio archive.
Although this selects less than 5% of the original samples, it
does not have implications for the success rate of a malware
author attempting to ﬁnd an evasive sample so long as the
selection criteria have no biases which would impact our
results. Many of the down-selects are due to artifacts of the
experiment, not reﬂective of what an actual malware producer
would observe. For example, the most signiﬁcant reduction
is because of the particular dynamic environment we selected
to verify the malicious behaviors. Malware authors can easily
design an oracle that veriﬁes the presence of the particular
malicious behaviors they intend to inﬂict.
Reliable Malware Signatures. Since the dynamic behavior
of malware samples may vary across executions, we need to
select a reliable malware signature from a group of candidates.
Even though the malware is executing in the same virtual
environment, its behavior may be effected by the timing of
events, service failures, and other sources of non-determinism.
Focusing on the network behaviors of malware samples, we
may extract various network behaviors reported by Cuckoo as
signatures, such as DNS queries, HTTP URL requests, and
network destinations. Cuckoo generates these reports from the
network-related API execution traces and the captured network
trafﬁc. Table II compares the effectiveness of six different types
of signatures extracted from Cuckoo reports.
We tested the 500 malware seeds in Cuckoo virtual ma-
chines, running each seed ten times. Our goal is to determine
which type of signature will have the best precision in captur-
ing observed malicious behavior, while being consistent across
multiple executions of the same sample.
If a signature extracts any relevant behavior for a seed in
any of the ten tests, we count the signature effective on the
seed. Obviously, an ideal signature would be effective on all
500 seeds. We also measure the consistency of a signature
over the 10 repeated tests. We designate the extracted behavior
observed most frequently over the ten tests as the reference
signature for a seed. The consistency on a seed is calculated
as mode
(that is, the fraction of times the reference signature
10
occurred across the 10 trials).
The average and the minimum consistency of each type of
signature over the ten executions for each of the 500 seeds are
listed in Table II. In general, the signatures extracted from API
traces are more consistent than those extracted from network
trafﬁc. We choose the union of the HTTP URL requests and