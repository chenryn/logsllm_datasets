example, the number of target graphs for GIN are 304 on COIL, 77
on IMDB, and 318 on NCI1, respectively.
Metrics. We use four metrics to evaluate the effectiveness of our
attacks: (i) Success Rate (SR), i.e., the fraction of successful adversar-
ial graphs over all the target graphs. (ii) Average Perturbation (AP),
i.e., the average number of perturbed edges across the successful
adversarial graphs. (iii) Average Queries (AQ), i.e., the average num-
ber of queries used in the whole attack. (iv) Average Time (AT), i.e.,
the average time used in the whole attack. We count queries and
time for all target graphs even if the attack fails. Note that an attack
has better attack performance if it achieves a larger SR or/and a
smaller AP, AQ and AT.
Baselines. We compare our attack with state-of-the-art RL-S2V
attack [13]. We also choose random attack as a baseline.
• RL-S2V attack. RL-S2V is a reinforcement learning based adver-
sarial attack that models the attack as a Finite Horizon Markov
Decision Process. To attack each target graph, it first decomposes
the action of choosing one perturbed edge in the target graph
into two hierarchical actions of choosing two nodes separately.
Then it uses Q-learning to learn the Markov decision process. In
the RL-S2V attack, the attacker needs to set a maximum number
of perturbed edges before the attack. Thus, in our experiments,
we first conduct our attack to obtain the perturbation rate and
then we set the perturbation rate of RL-S2V attack the same as
ours. Thus, the RL-S2V attack and our attack will have the same
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea114Table 3: AQ and AT on three datasets.
RL-S2V Random
Dataset Metric
1728
AQ
245
AT (s)
AQ
1740
7291
AT (s)
1809
AQ
AT (s)
3071
Our
1621
121
1800
109
1822
163
1621
97
1800
88
1822
104
NCI1
COIL
IMDB
APs (see Figure 7 and 8). For ease of comparison, we also tune
RL-S2V to have a close number of queries as our attack. Then,
we compare our attack with RL-S2V in terms of SR and AT.
• Random attack. The attacker first chooses a perturbation ratio
uniformly at random. Then, given a target graph, the attacker
randomly perturbs the corresponding number of edges in the
target graph. For ease of comparison, the attacker will repeat this
process and has the same number of queries as our attack, and
choose the successful adversarial graph with a minimal perturba-
tion as the final adversarial graph. Note that, the random attack
we consider is the strongest, as the attacker always chooses the
successful adversarial graph with a minimal perturbation.
Parameter setting. All the four metrics are impacted by the pre-
set budget 𝑏. Unless otherwise mentioned, we set a default 𝑏 = 0.2.
Note that we also study the impact of 𝑏 in our experiments. For
other parameters such as 𝑄 and 𝜇 in signSGD, we set 𝑄 = 100 and
𝜇 = 0.1 by default. In each experiment, we repeat the trail 10 times
and use the average results of these trails as the final results to ease
the influence of randomness.
5.2 Effectiveness of Our Attack
We conduct experiments to evaluate our hard-label black-box at-
tacks. Specifically, we study the impact of the attack budget, the
impact of our coarse-grained searching algorithm, and the impact
of query-efficient gradient computation.
Impact of the budget on the attack. Figure 5 and 6 show the
5.2.1
SR of the compared attacks with different budgets on the three
datasets and three GNN models. We sample 20 different budgets
ranging from 0.01 to 0.20 with a step of 0.01. We can observe that:
(i) Our attack outperforms the baseline attacks significantly in most
cases. For instance, with a budget 𝑏 less than 0.05, random attack
fails to work on the three datasets, while our attack achieves a SR at
least 40%; With a budget 𝑏 = 0.15, our attack against GIN achieves
a SR of 72% on IMDB, while the SR of RL-S2V is less than 40%.The
results show that our proposed optimization-based attack is far
more advantageous than the baseline methods. (ii) All methods
have a higher SR with a larger budget. This is because a larger
budget allows an attacker to perturb more edges in a graph.
We further calculate AP of successful adversarial graphs with
different budgets 𝑏, and show the results in Figure 7 and 8. Note
that, due to algorithmic issue, RL-S2V is set to have the same AP as
our attack. We have several observations. (i) The AP of our attack
is smaller for achieving a higher SR, which shows that our attack
outperforms random attack significantly, even when the considered
random attack is the strongest. For example, on the COIL dataset,
our attack can achieve a SR of 91.52% when 𝑏 = 0.20 and the
Table 4: Coarse-grained searching with different strategies.
Dataset
Strategy
COIL
IMDB
NCI1
I
II
III
I
II
III
I
II
III
SR
0.89
0.86
0.84
0.79
0.79
0.57
0.88
0.89
0.59
AP
8.88
9.15
14.46
17.27
17.22
17.62
12.57
13.42
43.09
AQ AT (s)
3.07
175
7.60
337
339
29.29
293
6.46
6.66
279
18.80
308
437
7.55
12.55
725
463
49.87
corresponding AP of adversarial graphs is 4.33. Under the same
setting, random attack has a SR of only 9.25%. (ii) AP increases
with budget 𝑏. It is obvious and reasonable because a larger budget
means that the perturbed graphs with large perturbations have
larger probabilities to generate successful adversarial graphs. (iii)
The APs of our attack on three datasets are different. The reason
is that these datasets have different average degree. Specifically,
IMDB is the most dense graph while NCI1 is the least dense. This
result demonstrates that it takes more effort to change the state of
supernodes or superlinks of graphs in the dense graph, and thus
we need to perturb more edges.
To evaluate the types of perturbations, we record the number of
added edges and removed edges for each dataset in our attack. With
the target GNN model as GIN and 𝑏 = 0.20, the averaged (added
edges, removed edges) on IMDB, COIL, and NCI1 are (8.46, 12.03),
(2.51, 1.80), and (12.84, 1.12), respectively. Thus, we can see that we
should remove more edges for denser datasets (e.g., IMDB) and add
more edges for sparser datasets (e.g., COIL and NCI1).
We also record AQ and AT of the three attack methods on the
three datasets, as shown in Table 3. Recall that the three methods
are set to have very close number of queries. We observe that RL-
S2V has far more AT than our attack and random attack. This is
because the searching space of RL-S2V is exponential to the number
of nodes of the target graph. Random attack has the smallest AT, as
it does not need to compute gradients. Our attack has similar AT
as random attack, although it needs to compute gradients.
Impact of coarse-grained searching (CGS) on the attack. In
5.2.2
this experiment, we evaluate the impact of different strategies of
CGS on the effectiveness of the attack. Specifically, we will validate
the importance of initial search in our entire attack. We use three
methods to search the initial perturbation vector Θ0: (i) Strategy-I
(i.e., our strategy): supernode + superlink + whole graph, which
means we search the space in the order of supernodes, superlinks
and the whole graph (see Section 4.3); (ii) Strategy-II: superlink +
supernode + whole graph; and (iii) Strategy-III: whole graph, which
means we do not use CGS and search the whole space defined by
the target graph directly. Note that, this strategy also means that
we start our signSGD based on a randomly chosen Θ0.
Table 4 shows the attack results with different strategies against
GIN. We have the following observations. (i) The SRs of strategy-I/-
II are very close and both are much higher than that of strategy-III.
For example, the SRs of strategy-I and -II are 0.88 and 0.89 on NCI1,
while that of strategy-III is 0.59. (ii) The APs of strategy-I/-II are
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea115(a) NCI1:GIN
(c) IMDB:GIN
Figure 5: Successful rate (SR) of our attack vs. budget 𝑏 on the three datasets against GIN.
(b) COIL:GIN
(a) NCI1:SAG
Figure 6: Successful rate (SR) of our attack vs. budget 𝑏 on IMDB and NCI1 against SAG and GUNet.
(c) NCI1:GUNet
(b) IMDB:SAG
(d) IMDB:GUNet
(a) NCI1:GIN
(b) COIL:GIN
(c) IMDB:GIN
Figure 7: Average perturbation (AP) of our attack vs. budget 𝑏 on the three datasets against GIN.
(a) NCI1:SAG
(d) IMDB:GUNet
Figure 8: Average perturbation (AP) of our attack vs. budget 𝑏 on IMDB and NCI1 against SAG and GUNet.
(c) NCI1:GUNet
(b) IMDB:SAG
much less than that of strategy-III. For instance, AP of strategy-
I on the NCI1 dataset is only 12.57, while that of strategy-III is
43.09, about 3.43 times more than the former. This result validates
that CGS can find better initial vectors with less perturbations. (iii)
Strategy-I has the least searching time and the least number of
queries among the three strategies. For instance, it only requires
3.07 seconds to find Θ0 for target graphs on COIL, while Strategy-II
requires 2x time. (iv) The benefit of our CGS algorithm (e.g., Strategy
III has a 1.94x AQ and 9.54x AT of our Strategy I on COIL) does
not reach the theoretical level as stated in Theorem 4.1 (i.e., O(2𝜅4)).
The reason is that from a practical perspective, we assume that
the attacker only has maximum number of queries as 5𝑁 , which
is exponentially much less than 2𝑆. If we traverse the entire graph
space with strategy-III as stated in Theorem 4.1, AQ and AT will be
enlarged to 2𝑆
5𝑁 times, which also explains the gap between strategy-
I/II and strategy-III. In summary, our proposed CGS algorithm can
effectively find initial perturbation vectors with higher success
rates, less perturbations, less queries, and shorter time.
Session 1B: Attacks and Robustness CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea116Figure 9: Percentage of the number of adversarial graphs
with different initial perturbation vectors found in each
component (i.e., supernode, superlink, and the whole graph)
under three searching strategies.
Table 5: Impact of query-efficient gradient computation.
Dataset QEGC
Yes
No