in P ) accordingly. We reiterate that the random character of this
process ensures the equiprobability property of k-anonymity.
i ∈ Q(cid:2)
Based on the preceding discussion, the problem of k-anonymiza-
tion is translated to a problem of determining a k-regular general-
ization graph from original to anonymized tuples, and then general-
ize the attribute values of each anonymized tuple q(cid:2)
i so as to include
the values of its k matches. We aim to ﬁnd a generalization graph
that achieves low information loss. Previous research [14, 15, 28, 7,
6] has used several variants of a Global Certainty Penalty (GCP )
as a measure of information loss. We opt for a similar metric, in
which we distinguish between numerical and categorical attributes
in a way that reﬂects the way we publish the data. For a numer-
ical attribute Aj, published as a range, we deﬁne the Normalized
Certainty Penalty, N CP , for a recast tuple q(cid:2)
i − lj
uj
U j − Lj
N CPj(q(cid:2)
i as follows:
i) =
(1)
i
i (lj
where uj
i, V(qj
i ) is the largest (smallest) value of attribute Aj in
the set of possible values of q(cid:2)
i ), (i.e., among the matches of
q(cid:2)
i), and U j (Lj) is the largest (smallest) value in the domain of
attribute Aj. The published ranges prevent the determination of an
individual’s presence in the data, while they can be used for query
processing assuming uniform distribution of values within a range
[14, 15]. On the other hand, in case Aj is a categorical attribute,
we deﬁne the N CP for a recast tuple q(cid:2)
i as follows:
N CPj(q(cid:2)
i) =
i) − 1
countj(q(cid:2)
|Aj| − 1
where countj(q(cid:2)
i) is the number of distinct values of attribute Aj
i ), and |Aj| is the cardinality of the domain of Aj. A similar
in V(qj
metric is employed in [28]. By deﬁnition, the NCP obtains values
between 0 and 1, where 0 signiﬁes no information loss and 1 sig-
niﬁes the maximum information loss for the attribute in question.
Then the GCP for a set of recast tuples Q(cid:2)
is deﬁned as:
GCP (Q(cid:2)
) =
(cid:2)
q(cid:2)
i∈Q(cid:2)
(cid:2)
d · |Q(cid:2)|
j N CPj(q(cid:2)
i)
where j is the index of any attribute Aj in Q, d is the number
of all such attributes, and |Q(cid:2)| the number of tuples in Q and Q(cid:2)
.
Our deﬁnition of GCP is the average value of N CP among all
attributes and all tuples. We aim to minimize this GCP value,
hence the problem of optimal k-anonymization calls for satisfying
the k-anonymity guarantee with a minimal reduction in the utility
of the original data:
PROBLEM 1. Given a data set D = (Q, P ), transform D to an
that satisﬁes k-anonymity, such that GCP (Q(cid:2)
)
anonymized form D(cid:2)
is minimized.
4. OPTIMAL SOLUTION
The methodology proposed in [28] and adopted in [29] creates a
ﬁxed k-regular ring generalization graphs, without taking into ac-
count the actual data values involved. The chief contribution of [28]
lies in the randomized process that extracts k disjoint assignments
from those graphs in a secure fashion, while that of [29] lies in de-
vising a total order over the records that yields good utility after the
ﬁxed graph pattern is applied on it for sparse set-valued data. How-
ever, the information loss incurred by the anonymization process
eventually depends on the exact form of graph built over the data.
Unfortunately, the problem of building a graph that minimizes in-
formation loss is not addressed in [28, 29]. As we discussed, [28]
uses a ﬁxed-form solution and [29] follows suit by adopting it.
Our contribution lies exactly on this graph construction process.
We aim to build the graph in a way that minimizes the information
lost by value generalization or achieves a near-minimal value of it;
to our knowledge, we are the ﬁrst to address this problem in such
terms. In this section, we examine the possibility for an optimal
solution that builds a k-regular generalization graph. The construc-
tion of such a graph corresponds to selecting the set of edges that
deﬁne it, out of all the available edges in the complete bipartite
graph from Q to Q(cid:2)
. Viewed in this manner, our problem is a spe-
cial case of a network ﬂow problem [3]. In network ﬂow terminol-
ogy, the characteristics of this special case are outlined as follows:
all n vertices in Q(cid:2)
• Our network is a complete bipartite graph from Q to Q(cid:2)
• All n vertices in Q are sources supplying k units of ﬂow, and
side are sinks demanding k ﬂow units.
• The ﬂow across each edge can take binary values in {0, 1}.
• The objective is to minimize our GCP function.
.
i and lj
i ). Let qj
We can formulate this problem using techniques of Mixed Inte-
ger Programming (MIP). For a numerical attribute Aj, we employ
auxiliary variables uj
i that stand for the maximum (mini-
mum) value in V(qj
i be the actual value of original tuple
qi on attribute Aj. Last, let x((cid:4), i) be a binary variable denoting
whether the edge from q(cid:2) to q(cid:2)
i is included in the generalization
graph we are building (i.e., whether the values of q(cid:2) are included in
the possible values of q(cid:2)
i). Then the relationship between original
and recast tuples can be expressed via the following constraints:
(cid:2) · x((cid:4), i) + (1− x((cid:4), i)) · qj
i
(cid:2) · x((cid:4), i) + (1− x((cid:4), i)) · qj
i
i ≥ qj
uj
i ≥ qj
uj
i ≤ qj
lj
i ≤ qj
lj
i
i
∀q(cid:2)
∀q(cid:2)
(4)
(5)
(6)
(7)
In case Aj is a categorical attribute Aj, our formulation is slightly
different. We substitute Aj by a set of |Aj| auxiliary binary at-
tributes, denoted as Bj, one for each value in the domain of Aj.
Then an original tuple qi has value 1 in one of these attributes only,
and 0 in the others, while a recast tuple q(cid:2)
i should get value 1 in
each auxiliary attribute corresponding to a value in the domain of
i, V(qj
Aj that is in the set of possible Aj values of q(cid:2)
i ). Using h as
an index for the auxiliary attributes for Aj, it now sufﬁces to em-
(cid:2)
ploy one auxiliary variable, uh
i , that stands for the maximum value
in V(qh
uh
i for a given
i ), which is either 1 or 0. The sum
tuple q(cid:2)
i and attribute Aj denotes the number of distinct values of
Aj in V(qj
i) in Equation 2. Using other
notations as before, the constraints can be expressed as:
i ), i.e., equals countj(q(cid:2)
h∈Bj
(2)
(3)
(cid:2) · x((cid:4), i) + (1− x((cid:4), i)) · qh
i
i ≥ qh
uh
i ≥ qh
uh
i
∀q(cid:2)
(8)
(9)
To the above constraints we should add the constraint represent-
ing the k-regularity of the graph:
x((cid:4), i) = k ∀(cid:4)
(cid:3)
i
(cid:3)
(cid:2)
x((cid:4), i) = k ∀i
(10)
Then, denoting the set of numerical attributes as NA and that of
categorical attributes as CA, the objective to minimize the GCP
metric translates to the minimization of the following quantity:
(cid:3)
(cid:3)
⎧⎨
⎩
i − lj
uj
U j − Lj +
i
(cid:2)
(cid:3)
i − 1
uh
h∈Bj
|Aj| − 1
⎫⎬
⎭
i
Aj∈NA
Aj∈CA
(11)
where we follow the notation in Equations (1) and (2). Our for-
mulation is a Mixed Integer Program, where the variables uj
i and
lj
i are real-valued, while the edge ﬂows x((cid:4), i) are constrained to
be binary. In Section 8 we show that this formulation can be run
by an MIP Solver for small data. Unfortunately, it is prohibitive on
sizeable data sets, as Mixed-Integer Programming is NP-hard [4].
5. THE GREEDY ALGORITHM
Given the impracticability of the optimal solution presented in
Section 4 for large data, in this section we set up to design a prac-
ticable and efﬁcient algorithm for our problem, aiming to achieve
near to optimal data utility. Our strategy starts out from the follow-
ing observation: Instead of striving to build a k-regular generaliza-
tion graph over the data at once, we can do so in a sequence of k
distinct iterations, adding a single assignment to the graph under
construction at each iteration.
Let G = (S, T, E) be a bipartite graph with the vertex set S
standing for original tuples (pre-images) and the vertex set T stand-
ing for the recast records (post-images) we aim to deﬁne, where
|S| = |T| = n. The assignment selection starts out with G being a
complete graph. Initially, the weight of each edge ei,j from Si to
Tj, wi,j is deﬁned as the GCP that will be incurred if the tuple qj
at vertex Tj is recast so as to include the tuple qi at vertex Si; for
brevity, we call this the cost of recasting qj as {qi, qj}. At each it-
eration of our algorithm, we aim to ﬁnd an assignment (i.e., a set of
n edges covering all vertices) from S to T that achieves a low total
sum of edge weights. After each iteration, the selected edges are
discarded from the graph, and the weights of remaining edges are
redeﬁned so as to reﬂect the new state of affairs. Thus, a redeﬁned
weight wi,j reﬂects the increase of GCP that will be incurred if
we extend the set of possible values of tuple qj at Tj to include
the values of tuple qi at Si (i.e., if we recast qj as {qi, qj}). In ef-
fect, at each iteration we attempt to increase the total GCP as little
as possible. After k iterations, a k-regular generalization graph is
constructed. In fact, the ﬁrst iteration is redundant, since the self-
matching assignment, having zero information loss, is chosen by
default. Thus, there are k − 1 iterations that matter.
We now discuss the details of assignment selection at each it-
eration. We sequentially process all vertices in S. For each such
Si ∈ S we select the edge ei,j, matching it to a Tj ∈ T , that has the
minimum weight wi,j. In other words, we greedily match each qi
to the qj that incurs the least GCP increase. Thereafter, we omit
Si from S and its chosen match Tj from T . This O(n2) process
terminates when all pre-image vertices in S have been matched,
and hence all post-image vertices in T have been used.
Nevertheless, the termination of the process outlined above is not
guaranteed. Given that at each iteration the degree of each vertex
is reduced by one, at the (cid:4)th iteration, our algorithm works on an
incomplete bipartite graph where each pre-image in S connects to
n−(cid:4)+1 vertices of T , and vice versa, i.e., on an (n−(cid:4)+1)-regular
bipartite graph. While it is always possible to extract an assignment
from such a graph, the process outlined above may encounter a
dead-end, in case all n−(cid:4)+1 possible matches of a certain vertex
Si have already been matched to preceding vertices of S and are
hence unavailable. To resolve this problem, when we encounter
such a dead-end, we perform a backtracking process as follows.
Algorithm 1: Greedy Algorithm Iteration
Data: A weighted bipartite graph G = (S, T, E)
Result: An assignment A with weight close to minimum
1 while S (cid:2)= (cid:3) do
2
3
4
select next vertex Si ∈ S;
if (cid:2) available vertex in T connected to Si then
ﬁnd Si−x matched to Tj such that ei,j and ei−x,m are
available;
substitute ei−x,m for ei−x,j;
select Tj such that wi,j is the minimum of all edges incident
to Si;
5
6
7
else
S = S − Si, T = T − Tj;
Add ei,j to A;
8
9
10 return A;
Assume that a dead-end is encountered when processing vertex
Si in the (cid:4)th iteration, i.e. there exists no available match between
Si and any remaining vertex of T . Then we backtrack to vertex
Si−1, which has been already matched to a vertex Tj ∈ T by edge
ei−1,j, and check whether two edges as follows are available:
1. The edge ei,j, so that Tj can be assigned as a match to Si.
2. Any edge ei−1,m between Si−1 and any vertex Tm ∈ T , so
that Si−1 can obtain another available match in T instead.
In case such available edges exist, we add edge ei,j to the con-
structed matching and substitute ei−1,j by ei−1,m (in case more
than one Tm are available, we select the one of minimum wi−1,m).
Otherwise, backtracking continues with vertex Si−2, and goes on
until it ﬁnds an eligible candidate Si−x. A pseudo-code for a single
iteration of this Greedy algorithm is shown in Algorithm 1.
The backtracking process forces a dead-end vertex Si to obtain
the ﬁrst available match Tj of a predecessor vertex Si−x. However,
while the match of Si−x has been selected as the one of minimum
edge weight, such a consideration is not taken into account during
backtracking. Therefore, we should better ensure that the vertices
in S are examined in an order such that it is likely that neighbor-
ing vertices have similar attribute values. To achieve this effect, we
ﬁrst sort the tuples in S by a lexicographic order of their attribute
values, positioning these attributes from lower to higher cardinality.
Putting attributes of lower cardinality at a higher position in this or-
der ensures that large value changes among consecutive tuples are
less frequent; for instance, the order {{a, 1},{a, 3},{b, 2},{b, 4}},
obtained by positioning the low-cardinality alphabetic attribute of
these four tuples ﬁrst, is better than {{1, a},{2, b},{3, a},{4, b}},
obtained by positioning the high-cardinality numerical attribute ﬁrst.
While backtracking offers a way out of the dead-end, we should
prove that it can efﬁciently ﬁnd an eligible substitution candidate
for practical values of k. We start out with the following lemma.
LEMMA 5.1. In the (cid:4)th iteration of our Greedy algorithm, if we
encounter a dead-end while processing the ith vertex, Si, we can
ﬁnd a previously matched vertex Sy, which can exchange its match-
ing with Si and obtain an alternative match Tm, among no more
than 2 · (cid:4) + i − n − 3 previously matched vertices.
PROOF. The status of our graph while processing the ith vertex
at the (cid:4)th iteration is visualized in the matrix of Figure 4. Rows
correspond to vertices in S and columns stand for vertices in T .
The entry in the cell (a, b) shows the status of edge ea,b. A “×”
indicates that Sa has been matched to Tb in a previous iteration.
Without loss of generality, we arrange the matrix columns so that
all post-images in T to which Si has been matched in the previous
(cid:4)−1 iterations are gathered in positions {T1, . . . , T(cid:2)−1}. The cor-
responding cells are labeled with “×” in Figure 4. We do not show
other ”×” entries as they are inconsequential for the proof, but we
keep in mind that there are exactly (cid:4)−1 “×” entries in each row and
each column, corresponding to previously deleted edges. Then, an
“(cid:9)” indicates that Sa has been matched to Tb in the current, (cid:4)th
iteration. Thus, each of rows {S1 . . . Si−1} contains exactly one
“(cid:9)”. Besides, each column contains at most one “(cid:9)”, since a
post-image in T can be matched to at most one pre-image in S in
the current iteration.
1S
iS
1(cid:16)(cid:16) x
iS (cid:16)
x
1(cid:16)iS
iS
R1 
R3 
R2 
R4 
1T
1(cid:16)lT
lT
nT
Figure 4: Matrix representation for bipartite matching
An edge from Sa to Tb will be available for matching provided
that (i) the corresponding cell is empty; and (ii) there is no “(cid:9)”
entry in the whole Tb column. Since we encounter a dead-end at
vertex Si, we deduce that each column in {T(cid:2), . . . , Tn}, for which
the cell in the Si row is empty, contains exactly one “(cid:9)” entry, as
Figure 4 shows.
Without loss of generality, we gather the rows for all x vertices
that need to be revisited by our backtracking process in the worst-
case scenario at the bottom of the matrix, from Si−x to Si−1.
Then our matrix is divided into four disjoint regions, shown by
different colors in Figure 4, such that R1 = {S1, . . . , Si−x−1}×
{T1, . . . , T(cid:2)−1}, R2 = {S1, . . . , Si−x−1}×{T(cid:2), . . . , Tn}, R3 =
{Si−x, . . . , Si−1}×{T1, . . . , T(cid:2)−1}, and R4 ={S i−x, . . . , Si−1}×
{T(cid:2), . . . , Tn}. The row of a vertex Sy, with y ∈ [i − x, i − 1], that
can exchange its match with Si should satisfy the following two
requirements, which correspond to the existence of edges ei,j and
ey,m we have seen in our discussion of backtracking:
1. Sy should have been given a match Tj ∈ {T(cid:2), . . . , Tn} in
the current iteration that it can transfer to Si; thus, the row of
Sy should have an “(cid:9)” entry in R4.