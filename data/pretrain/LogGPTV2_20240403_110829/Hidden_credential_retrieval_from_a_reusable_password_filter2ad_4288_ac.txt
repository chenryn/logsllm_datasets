viding an oﬄine password validity test that is not al-
ready implicitly present in the message Msg (whether
that is the case depends on the plaintext distribution
and is thus application-speciﬁc). In other words:
• the retrieval protocol should be blind, i.e., keep
the password invisible to the server;
• the retrieval protocol should be oblivious, i.e., not
disclose its success to either party;
• the Pwd-based encrytion of Msg into Ctx has to be
redundancy-free (and thus not carry any integrity
check), i.e., the only information-theoretic redun-
dancy in Ctx should come from Msg itself.
Under those conditions, if the plaintext Msg is intrin-
sically unrecognizable in itself, e.g., being a random
access key for a separate third-party service, then it
will be impossible even for the insider server to recover
the password (or the plaintext) in an oﬄine dictionary
attack.
We stress that the server S is only partially trusted, since
we merely ask it to maintain a private copy of the blinded
ciphertext Ctx (a “secrecy” requirement), and participate in
the retrieval protocol with anyone who asks posing as the
client Q (an “availability” requirement). We make no strong
security assumption on it, and explicitly allow it to misbe-
have.
We also stress that, by contrast, the user is ultimately
trusted, since all the data is his. Hence, it is pointless to
contemplate corruptions of either P or Q (even though im-
personations should of course be considered).
2.3 Formal Security Requirements
We formalize the preceding security requirements using
a game-based deﬁnition that captures all the properties we
need.
We actually deﬁne two games, since there are two pos-
sible (and mutually exclusive) adversaries: the ﬁrst is an
“outsider game”, pitting the user and server against and ex-
ternal attacker; the second is an “insider game”, pitting the
user against a dishonest server. As we mentioned, it is point-
less to consider a dishonest user, since all the valuable data
ultimately belongs to the user. Our two security games thus
capture the notion that the message Msg (and the password
Pwd) must remain private to the user, under passive and
active attacks by an outsider and/or by a dishonest server.
2.3.1 Quantifying the Adversary’s Work
This model presents a technical conundrum, however. Sup-
posing that the plaintext Msg contains enough redundancy
for an oﬄine attack to be possible in principle, how can we
argue that such attack must be as expensive as the task
of enumerating the entire password dictionary (or half of it
on expectation), when all the work for that enumeration is
spent internally by the adversary, out of view of the outside
world? Surely, it would be nice to show from ﬁrst principles
that the complexity of computing Msg and Pwd from Ctx
alone is exponential in the password bit-length |Pwd| (as-
suming that Msg brings enough intrinsic redundancy for the
pair (cid:104)Msg, Pwd(cid:105) to be uniquely determined by Ctx), but this
would imply a separation P (cid:54)= NP.
As our ambitions in this paper are more modest, we shall
instead consider such lower bound relative to a validity check
oracle. In this model, the attacker will not know a priori
the set M ⊆ {0, 1}k of admissible plaintexts from which
the correct message Msg is to be drawn uniformly. The
adversary will have to make a call to a test oracle f1 to
determine whether a given string belongs to M.
We cannot emphasize enough, though, that f1 is a gim-
mick that we use in our games for accounting purposes. In
reality, the adversary may very well know what M is, and
thus be able to make the same determination as f1 in a
purely oﬄine manner.
2.3.2 Modeling Online and Ofﬂine Validity Tests
In addition to f1 which lets us quantify an important as-
pect of the adversary’s oﬄine work, we also introduce a sec-
ond predicate f2 to model the process by which the adver-
sary can truly validate a candidate plaintext by performing
an expensive online check.
More precisely, the oracle f2[Msg(cid:48)] models the real-world
action of trying to use the decrypted candidate credential
Msg(cid:48) in lieu of the correct credential Msg for its intended
purpose, i.e., it models the attempt to impersonate the user
by presenting the credential Msg(cid:48) to the appropriate third
233party. Generally, this will only succeed if Msg(cid:48) = Msg, and
thus f2[Msg(cid:48)] models a very expensive but accurate test for
Msg(cid:48) ?= Msg.
The two “message validity test” oracles f1 and f2 thus
have the following semantics:
• The ﬁrst oracle, f1, captures the oﬄine recognition
of a potentially valid plaintext on the basis of its in-
trinsic redundancy: f1[Msg(cid:48)] = 1 means that Msg(cid:48) is
well-formed, i.e., it is in the set M, though it is not
necessarily correct.
• The second oracle, f2, models an expensive but per-
fectly accurate validity check, often requiring an on-
line component and the cooperation of a third party:
f2[Msg(cid:48)] = 1 indicates that Msg(cid:48) is usable in lieu of
the correct Msg with the third party, and thus typi-
cally that Msg(cid:48) is the correct Msg.
These oracles are always deﬁned relative to a speciﬁc refer-
ence ciphertext Ctx, the target of the attack, which will be
clear from context. More summarily:
f1 : {0, 1}k → {0, 1} : Msg (cid:55)→ “Is Msg well-formed?” ,
f2 : {0, 1}k → {0, 1} : Msg (cid:55)→ “Is Msg the answer?” .
This model strikes a good balance between ﬂexibility and
simplicity in our quest to characterize a plaintext’s intrinsic
redundancy and extrinsic validity that an attacker may be
able to exploit.
2.3.3 Outsider Security
We ﬁrst deﬁne the privacy model against outsider attacks.
It is based on the following game, played between an adver-
sary A and a challenger B. The challenger simulates all the
parties in the HCR protocol, i.e., Q and S (recall that P
only interacts with S over a secure channel, so we do not
consider P). The adversary is an outsider; it makes passive
requests for transcripts of legitimate executions of Retrieve
between Q and S; it can also actively impersonate Q to S,
or S to Q, by interfering with the ﬂows in concurrent but
independent protocol executions. (What the outsider adver-
sary cannot do is corrupt or read the internal state of any
of the actual players.)
The outsider attack game thus proceeds as follows:
Initialization. B privately simulates an execution of
the Store protocol between P and S, for a random
password Pwd ∈ {0, 1}n and a random message
Msg ∈ {0, 1}k.
We assume that the distribution of Msg is uni-
form over some subset M ⊆ {0, 1}k, such that
∀m ∈ {0, 1}k : m ∈ M ⇐⇒ f1[m] = 1. M is thus
the set of well-formed plaintexts, and is a param-
eter of the game but is not given to A. This is
to force A to make accountable calls to the f1-
oracle if it wants to test candidate messages for
membership to M.
(In the real world, M will
likely be public, allowing the adversary to run f1
privately.)
Eavesdropping queries. A can adaptively request
to see the transcript of a random execution be-
tween Q and S, in which Q uses the correct pass-
word Pwd(cid:48) = Pwd.
Impersonation queries. A can adaptively send mes-
sages to S or to Q; it immediately obtains the
corresponding reply if any reply is due.
Oﬄine validity tests. A can make adaptive calls to
the oﬄine predicate f1 on any string of its choice.
The response indicates whether the string belongs
in M.
Online validity tests. A can make adaptive calls to
the online predicate f2 on any string of its choice.
The response indicates whether the string is the
correct message Msg.
Message guess. A eventually outputs one guess dMsg
Adjudication. The adversary wins if dMsg = Msg.
for the value of Msg.
Definition 1. The advantage of an adversary A in a
(p, q, t1, t2)-outsider attack is deﬁned as the probability that
A wins the preceding game, when A makes a total of p pas-
sive eavesdropping queries, q active impersonation queries,
and t1 and t2 calls to f1 and f2 respectively.
Insider Security
2.3.4
We now deﬁne the privacy model against insider attacks.
Since the user embodied by P and Q is ultimately trusted,
the only potentially malicious insider is S (or any entity
that has managed to acquire Ctx from S, and which is thus
equivalent to S).
The model is based on a game played between a mali-
cious server AS and a challenger B (where the subscripted
AS is a reminder that the adversary is the server itself).
The challenger simulates the trusted user in the storage and
retrieval phases of the HCR protocol, i.e., P and Q. The
attack proceeds in two phases: the ﬁrst phase involves a
single execution of the Store protocol between P and AS ;
the second phase involves as many independent executions
of the Retrieve protocol between Q and AS as the adver-
sary desires, and in which Q will use the correct password
Pwd(cid:48) = Pwd.
(Note that if the server wishes to execute
the protocol with someone using a diﬀerent password, it can
simulate the protocol execution all by itself, so we need not
consider those.) As before the task of AS is to recover the
value of Msg.
The insider attack game proceeds as follows:
Storage interaction. B, acting on behalf of P, picks
a random password Pwd ∈ {0, 1}n and a random
message Msg ∈ M ⊆ {0, 1}k, and engages in the
Store protocol with the adversary AS .
The distribution of Msg is uniform over the sub-
set M ⊆ {0, 1}k, which as before is the cover set
of the predicate f1; it is a parameter of the game
but is not given to A. This is to force A to make
accountable calls to an f1-oracle in order to deter-
mine whether a message is well-formed. (In the
real world, the adversary would know M and be
able to run f1 oﬄine locally.)
Retrieval interactions. B, acting on behalf of Q,
initiates the Retrieve protocol with the adversary
AS , using the correct access password Pwd(cid:48) =
Pwd. This may happen multiple times, adap-
tively, at the request of AS .
234Oﬄine validity tests. A makes adaptive calls to the
oﬄine predicate f1 on any chosen string. The
response indicates whether the string is in the set
M.
Online validity tests. A makes adaptive calls to the
online predicate f2 on any chosen string. The re-
sponse indicates whether the string is the correct
Msg.
Message guess. A eventually outputs its guess dMsg
Adjudication. The adversary wins if dMsg = Msg.
for the value of Msg.
Definition 2. The advantage of an adversary A in a
(r, t1, t2)-insider attack is deﬁned as the probability that A
wins the preceding game, after a total of r initiated instances
of the Retrieve protocol, and a total of t1 and t2 oracle calls
to f1 and f2 respectively.
2.3.5 Recovery vs. Distinguishing Challenges
A peculiarity of the two preceding games is that we ask the
adversary to recover the full plaintext Msg and not merely
recognize it in a left-vs.-right distinguishing challenge, which
would correspond to the usual notion of semantic security
for encryption schemes. The reason why a distinguishing
challenge is inadequate is that, given Msg1 and Msg2 such
that one of them is the true Msg, a single call to the online
oracle f2 will immediately solve the challenge, and two calls
to the oﬄine oracle f1 are likely to solve it too (if f1 returns
0 on either plaintext, we know that the correct answer is the
other one.)
The root of the discrepancy is that in the traditional con-
text of encryption schemes, we seek to protect the plain-
text from semantic leaks caused entirely by the encryption
scheme itself.
In the envisioned applications of HCR, the
plaintext has no intrinsic semantic value; it is an arbitrary
string to be used as an authenticator to a third-party remote
service. Thus, in our case, the ultimate goal of the adver-
sary is not to compute the actual plaintext Msg, or decide
which one of Msg1 or Msg2 might have been committed to
storage, but to gain access to whatever service the owner of
the plaintext is entitled to. If the adversary knows that ei-
ther Msg1 or Msg2 will grant such access, trying them both
will not present much of a challenge, whereas recovering a
randomly chosen string Msg ∈ M still would.
For all these reasons, we contend that the preceding deﬁni-
tions provide the simplest model that captures the essential
security requirements of an HCR protocol for its intended
application.
Remark also that applications that require semantic se-
curity in the traditional sense can easily be accommodated,
using standard ampliﬁcation techniques from one-way to se-
mantic security (e.g., by hashing Msg with an appropriate
function, and invoking either the left-over hash lemma or
the random-oracle model).
3. REALIZATION
We observed when discussing related works that HCR and
protocols that subsume it may already be found in the liter-
ature, though sometimes addressing a completely diﬀerent
problem.
We already alluded to a generic transformation from unique
blind signature protocols into HCR protocols in the random-
oracle model, and indeed the three most practical examples
of constructions to date that are suitable for HCR are related
to unique blind signatures: ﬁrst is the Chaum blind signa-
ture [21], second is the Ford-Kaliski server-assisted password
generation protocol [26], and third is the Boldyreva blind
signature [9].
For the same of illustration, we focus on the Boldyreva
signature, since it is very eﬃcient and comes with a secu-
rity reduction (albeit to a non-standard assumption in the
random-oracle model). The resulting HCR scheme is di-
rectly usable in practice.
3.1 From Unique Blind Signatures
First, to ﬁx ideas, we brieﬂy explain how (suitably secure)
unique blind signatures already realize, and in fact subsume,
the HCR functionality in the random-oracle model. To do
so, we sketch how to construct the HCR protocols Store
and Retrieve using only a hash function and the signature’s
blind signing and unblinding functions (while noting that
the veriﬁcation function is not needed).
Store. The user does the following,
interacting with the
server over a secure channel:
1. Generate a random signing private key κ for the
blind signature scheme (a public veriﬁcation key
is not needed).
2. Hash the password Pwd into a string µ = H1[Pwd]
and compute its (deterministic) signature σ =
Sign[κ : µ].
3. Hash the signature into a one-time pad π = H2[σ]
and use it as a mask for Msg in γ = Msg ⊕ π.
4. Give the key κ and the string γ to the server.
The pair (cid:104)κ, γ(cid:105) acts as the HCR ciphertext Ctx,
though only κ ought to remain secret.
Retrieve. The user does the following, interacting with the
server over any channel:
1. Hash the password Pwd(cid:48) into a string µ(cid:48) = H1[Pwd(cid:48)]
2. Perform the blind signature protocol with the server
and unblind the result to obtain a signature σ(cid:48) on
µ(cid:48).
3. Also request the string γ back from the server.
Let γ(cid:48) be the received copy.
4. Hash σ(cid:48) to obtain a one-time pad π(cid:48) = H2[σ(cid:48)]
and use it to unmask γ(cid:48) to get the result Msg(cid:48) =
γ(cid:48) ⊕ π(cid:48).
3.2 A Concrete Construction
Based on the foregoing, we construct a simple HCR scheme
using the Boldyreva blind signature as a starting point.
The Boldyreva blind signature actually requires a bilinear
pairing for its implementation, but that is because the pair-
ing is needed for signature veriﬁcation. The signing function
alone is suﬃcient to construct an HCR protocol, therefore