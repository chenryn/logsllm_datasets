it is foreseeable that some may eventually (in the long term) push for strict OCSP
checks for any certiﬁcate that is not within its (short initial) guaranteed phase,
regardless of whether it is a child certiﬁcate or a regular certiﬁcate. This would
incentivize servers to both use our child-parent approach and to make sure that
they always can present an up-to-date child certiﬁcate. Ideally all servers would
eventually try to maintain up-to-date child certiﬁcates and OCSP checks would
only be needed when a server fails to do so (of legit or non-legit reasons).
5.3 Data-Driven Overhead Analysis
In this section we examine the overhead associated with diﬀerent high-level cer-
tiﬁcate management solutions.
For this analysis, we assume that the overhead is proportional to the issuance
rate of certiﬁcates that require (1) the validation of subject-key mappings and
(2) the submission of new certiﬁcates to CT logs. Both overheads are important
since the subject-key validation process can be both time consuming and costly,
and since many CT logs already contain more than a billion certiﬁcates and the
log sizes are quickly growing [73].
To illustrate the value of parent certiﬁcates, we present a simple model that
captures the relative increase in the number of certiﬁcates (parent or traditional)
that must be issued for a set of domains when the validity period is reduced.
Model: Consider the set of certiﬁcates N currently used by a large set of servers.
Let T and O denote the average validity time and overlap, respectively. Assuming
the system is in steady state, we can then use Little’s law to obtain the average
rate λ that new certiﬁcates must be generated as: λ = N/(T − O), where T > O
and N = |N|. The relative increase in the issuance rate can now be calculated
as: (Told − Oold)/(Tnew − Onew), where the subscripts capture change.
Baseline Comparisons: Figure 15 illustrates the eﬀect that certiﬁcate lifetimes
can have on the issuance rate. For this discussion, we normalize all numbers rel-
ative to two basic baselines. In particular, we show the relative increase in the
number of subject-key validations and CT submissions of when using a few diﬀer-
ent example management policies relative to the corresponding overhead when
using these two baselines, as a function of the selected validity period when
72
C. M. Bruhner et al.
Fig. 15. Relative increase in the number of subject-key validations and CT submissions
of selected management policies compared to two baselines.
Table 1. Increase in overhead for diﬀerent CAs using short-lived certiﬁcates without
the proposed technique. We show results for diﬀerent average inter-issuance intervals
Δ = Tnew − Onew, measured in days. The columns to the left are based on the CAs’
current median values for Told and Oold. The columns to the right are based on the
observed distributions of Told and Oold for each CR of a CA.
using the diﬀerent example policies. Fig. 15(a) shows the relative (multiplica-
tive) increase when we start with an average validity time of 398 days and an
average overlap of 60 days, and then reduce the lifetimes in diﬀerent manners.
Figure 15(b) shows the corresponding statistics when we start with an average
validity period of 90 days and an average overlap of 30 days. The ﬁrst default
scenario corresponds to changes relative to the most commonly used certiﬁcates
and overlaps used by Amazon and the second case corresponds to what subjects
using Let’s Encrypt usually use. In both cases, we include results for the case
when the overlap is scaled proportionally to the validity period, the cases when
a ﬁxed overlap (e.g., 1, 4, 15, or 60 days) always is used (regardless of validity
period), and for our proposed method. Here, we assume that parent certiﬁcates
are issued with a similar frequency and overlap as in the baseline systems. For
this solution, the validity time (on the x-axis) corresponds to the frequency that
child certiﬁcates are generated (by CA) and used (by servers). Again, the over-
head associated with these actions is very small compared to the overhead of
validating a subject-key pairing and submitting parent certiﬁcates to CT logs.
The ﬁrst scenario (Fig. 15(a)) illustrates that a CA reducing its validity
period from 398 days to 90 days using normal means would increase its issuance
overhead by more than a factor of four (i.e., >300%), and that further reductions
Changing of the Guards: Certiﬁcate and Public Key Management
73
to a 5-day validity period with a 1-day overlap would increase overhead by a fac-
tor of 84.5 (or 8,350%). In contrast, our parent-based solutions can be used with
even shorter guaranteed periods without increasing the number of subject-key
veriﬁcations or CT-log submissions. This clearly demonstrates the eﬀectiveness
of our approach. When comparing against the second baseline (Fig. 15(b)) of
90-day certiﬁcates (e.g., currently used by Let’s Encrypt) we still see signiﬁcant
reductions in overhead. For example, with a validity period of 5-days and a 1-day
overlap, we would see a factor 15 (or 1,400%) diﬀerence and for organizations
that would want daily certiﬁcates the overhead would be 90x (8,900%) higher
than the parent certiﬁcate approach.
Measurement-Based CA Comparisons: To put the above changes in per-
spective we ﬁrst refer back to the CDFs of the most popular CAs validity periods
and current overlaps (Fig. 6). With all CAs having a median value well above
one of these two base cases, our approach would hence consistently result in
substantial improvements in overhead compared to the na¨ıve approaches when
using short-lived certiﬁcates.
We next quantify the improvements for individual CAs. Table 1 shows the
relative overhead increases that the top-7 CAs (including the ﬁve for which
we observed key re-usage) would see when changing to use diﬀerent example
certiﬁcate update intervals (listed in the second row and measured in days).
This corresponds to Δnew = Tnew − Onew. Here, we calculate the increases in
two ways: (1) The columns to the left are based on the CAs’ current median
values for Told and Oold. (2) The columns to the right are based on the actual
distributions of Told and Oold values, as observed for CRs associated with each
CA. Note that the increase is substantial when we get down to update intervals
of less than a week. For example, with an update interval of 5 days (e.g., a 7-day
certiﬁcate with a 2-day overlap) all CAs except Google would need to submit
12–33 times as many certiﬁcates to CT logs as they do now, and if updating
certiﬁcates on a daily basis (potentially still with bigger overlap) the overhead
increase would be 61–163 times current loads. The lower overheads for Google
are due to them already using substantially shorter update intervals than the
other CAs (e.g., median of (70–39) days compared to (90–29) days for Let’s
Encrypt).
In comparison, using our approach a CA could easily use the same certiﬁcate
update interval for their parent certiﬁcates as they do now (i.e., Δ = Told−Oold),
or perhaps more likely even increase it. If they increase the update interval for
parent certiﬁcates, the improvements would be even greater with our approach
than suggested here. For example, we expect updates of parent certiﬁcates to
be signiﬁcantly less frequent than the 41 days used by Google on average at the
moment. By creating and submitting new using parent certiﬁcates less frequently,
CAs could hence easily reduce the number of CT submissions and subject-to-key
checks they perform at the same time as the lifetime of their child certiﬁcates
can be reduced substantially.
Finally, there are many validity-overlap pairings that result in the same
update intervals. The best overlap is expected to be both website dependent
74
C. M. Bruhner et al.
and depend on how strictly browsers would enforce OCSP checks (suggested as
a fallback mechanism during the probable phase). Diﬀerences are also expected
between CAs. Again, the relatively bigger overlaps used by Google compared to
Let’s Encrypt was a contributing factor to their shorter update intervals.
6 Related Work
Wide-Area Certiﬁcate Scanning: Fast internet-scale certiﬁcate measure-
ments using systems and tools such as ZMap [35] and Censys [33] have enabled
researchers to quickly scan large IP address spaces to collect and analyze
large volumes of certiﬁcates. Researchers have studied the certiﬁcates collected
using such tools (e.g., Rapid7 and Censys) and the certiﬁcates found in pub-
lic CT logs [42,50,69] to characterize the certiﬁcate landscape [78], analyze
how well CAs construct certiﬁcates [47], study the popularity of cryptographic
libraries [61], label devices [11], and a wide range of other purposes. Others have
considered the eﬀect of location [79] or discussed how to best adapt the scanning
solutions for the much larger IPv6 address space [60].
Certiﬁcate Management: Complicated issuance and certiﬁcate management
processes are believed to have slowed down the original HTTPS deployment [20].
Let’s Encrypt addressed many of these issues through the introduction of Certbot
and other automated processes [9,75]. However, there are still many issues yet
to address, including frequent errors in the CAs’ issuance processes [47]. Kumar
et al. [47] developed a certiﬁcate linter (ZLint), quantiﬁed the compliance of the
CA/Browser Forum’s baseline requirements and RFC 5280 [22]. While there has
been a drastic reduction in the fraction of certiﬁcates with errors, errors are
still frequent [47]. Acer et al. [10] used client-side reports from within Chrome
to analyze the main causes of certiﬁcate errors, and found that almost all date
errors are caused by expired certiﬁcates.
Others have proposed extensions to the ACME protocol. For example,
Borghol et al.
[23] presents a related mitigation technique to better pro-
tect against domain takeover attacks for trust-based domain-validation ser-
vices. Their solution introduces an additional issuance challenge (for trusted
re-issuance) that easily can be solved by domains that are currently in pos-
session of the private key associated with a trusted certiﬁcate that has been
previously issued for the domain.
Certiﬁcate Replacements: Most papers on certiﬁcate replacement consider
the reissuing and revoking of certiﬁcates during mass-revocation events related
to Heartbleed [34,82] or the case when invalid certiﬁcates are replaced by other
invalid certiﬁcates [29]. These studies suggested that the top sites were quicker
at revoking certiﬁcates and addressing the Heartbleed vulnerabilities than less
popular sites [34] and that sites that did not do this immediately were very
slow to do so [34,82]. None of these works considered replacement relationships
under normal circumstances, the primary focus in this paper. Mirian [58] ﬁnds
that popular websites are more likely to be proactive in their certiﬁcate renewal
Changing of the Guards: Certiﬁcate and Public Key Management
75
than less popular websites. In parallel work, Omolola et al. [64] evaluated how
reactive administrators utilizing automation for reissuing certiﬁcates were in
the event of the Let’s Encrypt mass-revocation event (Apr. 2020). They found
that 28% successfully reissued their certiﬁcates manually within a week—around
three times better than the result a week after the Heartbleed bug. They focus
on Let’s Encrypt certiﬁcates found in CT logs and do not consider key reusage
or when replacements occur on the servers.
Revocation Problems: Browsers have traditionally performed revocation
checks using the Online Certiﬁcate Status Protocol (OCSP) [39] or Certiﬁ-
cate Revocation Lists (CRLs) [22]. However, due to several security, privacy,
and performance issues many browser vendors today do not utilize these proto-
cols [28,55].
One area of broad research interest is better ways to revoke certiﬁcates.
While the goal is the same as OCSP and CRLs, the paths taken diﬀer substan-
tially between solution approaches [30,32,49,72]. Proposals include more eﬃcient
push-based protocols and compact forms to convey which certiﬁcates have been
revoked [49,72] and the caching/sharing of revocation statuses [32]. Others have
considered if the world is ready for OCSP Must-Staple and hard-fail policies [30].
Short-Lived Certiﬁcates: Other solutions to the above problem include the
use of short-lived certiﬁcates [62,71,76], proxy certiﬁcates [28,77,80], and the use
of diﬀerent delegation schemes [15,18,21,27,43,52,53]. Conceptually, the idea to
use shorter validity periods is simple. Unlike our work, previous works on short-
lived certiﬁcates did not reuse keys. As we previously noted, just shortening
the validity period would result in a big overhead for CAs and CT logs. An
interesting alternative way to obtains SCTs for the child certiﬁcates may be to
combine our idea with that of utilizing special log entries for a collection of short-
lived certiﬁcates [36]. However, such hybrid scheme may require some extra care
in how to best ensure that child certiﬁcates are not leaked ahead of time and
would still beneﬁt from key reusage and the rest of our proposal.
Both proxy certiﬁcates and delegation schemes typically are designed to allow
a third party to serve content on behalf of a domain owner without giving them
access to the private key of the domain owner. Chuat et al. [28] present a nice
survey and high-level comparison of the above approaches, in which they also
make a case for the use of short-lived proxy certiﬁcates. While proxy certiﬁ-
cates [28] and delegated credentials [15,43] (and similar approaches) help reduce
the number of servers that keep long-lived certiﬁcates, they do not address the
actual problem of speeding up revocations when revocations are needed.
7 Conclusion
This paper ﬁrst presents a novel server-side characterization of the CR relation-
ships in the wild, including the reuse of public keys. Second, it proposes and
demonstrates a simple way to combine parent-child certiﬁcate relationships and
three-phase certiﬁcate handling to reduce the reliance of revocation checks.
76
C. M. Bruhner et al.
Our data-driven CR analysis captures management biases, including the
inﬂuence that the services oﬀered by diﬀerent CAs may have on the timing
of replacements, safety margins, certiﬁcate violations (e.g., early/late usage),
and whether the public key is reused. The results highlight a lack of industry
standards for replacement policies [38]. Interestingly, the top-CAs using shorter
validity periods often also use more common (default) overlaps and their cus-
tomers achieve more consistent/predictable lifetime characteristics.
Having said that, we observe the smallest fraction of gaps and early/late
usage for the more expensive (and longer-lived) EV certiﬁcates. Another inter-
esting observation is that the three CAs (Sectigo, GlobalSign, Go Daddy) with
highest key reuse (>65%) all achieved substantially less gaps when reusing keys
than when not reusing keys. While they do not have as high key reuse, Let’s
Encrypt nicely demonstrates how key-reuse chains can help customers achieve
good key utilization.
Finally, motivated by the eﬀectiveness and potential of some of the observed
automation solutions and trends, we present a new way to address an important
revocation problem currently leaving web users highly vulnerable to man-in-the