Our discovery process begins with Session Extraction: reducing
a stream of connections to a stream of application-level sessions,
where each session comprises a sequence of connections. We ﬁrst
detail different types of session structures (including homogeneous
and mixed sessions), then describe how we extract homogeneous
sessions, and ﬁnally how we extract mixed sessions.
4.1 Types of Sessions
The simplest possible session structure is a lone connection by it-
self, which we term a singleton. Next in complexity comes sessions
consisting of consecutive invocations of the same application pro-
tocol, all with the same directionality, which we term homogeneous
sessions. Last in complexity for the types of sessions we tackle in
this work are sessions involving different connection types as well
as varying directionality, mixed sessions. (More complex still are
sessions involving multiple remote hosts. Extracting these remains
for future work, though we have some preliminary results indicat-
ing its likely feasibility [16].)
Different applications vary widely in the prevalence they exhibit
for each of these types of session structure. For example, the algo-
rithm we develop classiﬁes 11% of LDAP client sessions as single-
tons and 88% as homogeneous sessions (with 1% being mixed ses-
sions); for SSH client sessions, 80% singletons vs. 18% homoge-
neous sessions; and for Grid FTP client sessions, 58% vs. 0% (with
42% being mixed sessions). For about half of the 40+ applications
we examined in our trace, simple forms of sessions dominate, while
for the rest, sessions often involve somewhat more complex struc-
ture. In addition, for some protocols (Web surﬁng, peer-to-peer)
many sessions involve multiple remote hosts, which our present
structure abstraction does not aim to capture. Also, as our results
later show, for applications that only rarely exhibit mixed sessions,
sometimes these are sessions of particular potential interest to an
analyst.
4.2 Extracting Homogeneous Sessions
Consider an algorithm that processes a stream of connection ar-
rivals C1, . . . in an online fashion. On observing a new connection
Ci, the algorithm must decide whether: (a) Ci is part of a current
session, or (b) Ci represents the beginning of a new session.
We ﬁrst employ a simple heuristic to identify homogeneous ses-
sions that, as explained before, consist of consecutive invocations
of the same application protocol. For example, a user may in-
voke their mail client to send multiple mails in a single sitting,
leading to consecutive SMTP instantiations. The same holds for
Web browsing as reported in [24], which shows that one can cap-
ture HTTP sessions by simply considering HTTP connections less
than a time Taggreg apart as part of the same session. Their work
found Taggreg ≈ 100 secs as suitable. We generalize this aggre-
gation rule as follows. For a connection Ci, if we already have
an existing active session Sj = (C j
n) between the same
pair of hosts and involving the same protocol and direction (i.e.,
A(Sj) ≡ T (C j
1) = T (Ci)) , and for which the most recently seen
connection of Sj, C j
n, arrived less than Taggreg in the past from
Ci’s arrival, then we consider Ci part of Sj.
1, . . . , C j
4.3 Extracting Mixed Sessions
The aggregation rule does not help for connections either in-
volving different protocols, or somewhat further apart. The for-
mer are particularly interesting, as these potentially reﬂect mixed
In this case we attempt to assess possible causality,
sessions.
If Ci’s arrival is indeed part of an ongoing session
as follows.
Sk = (C k
m), then we can consider Ci as “triggered”
(caused) by the connection C k
1 represents the start of the ses-
sion Sk, and thus serves as a representative of the event that led to
the initiation of the session.
1 , . . . , C k
1 ; C k
We base our approach on the observation that if Ci is a “trig-
gered connection”, i.e., causally related to Sk, then the arrival of
Ci is likely to be “closer” to Sk, in comparison to the case where
Ci is a “normal connection” (no causal connection to Sk). We
now proceed to develop a more formal statement of this intuition
by framing the problem in terms of hypothesis testing, and then
explain a statistical detection algorithm that has a bounded false
positive rate.
Modeling Normal Trafﬁc. We can frame the problem of dis-
tinguishing between triggered and normal connections in terms of
hypothesis testing [32]. In this formulation, we use the arrival time
of a connection to choose between two hypotheses: the null hypoth-
esis that the connection is normal, versus the alternative hypothesis
that the connection is triggered.
Modeling the alternative hypothesis requires capturing the statis-
tical dependence of the arrival time of the triggered connection on
the arrival time of the triggering connection, but this may depend on
the semantics of the speciﬁc application session itself. Fortunately,
as we will show shortly, the null hypothesis is easier to model.
Therefore our abstraction algorithm discovers likely causality, and
hence sessions, by building a model for the arrival characteristics
of untriggered (normal) connections. We then identify connections
whose arrivals deviate from this model as triggered connections.
At the heart of our approach lies the empirical observation that
the arrival of user-initiated sessions is generally well-modeled as
a Poisson process, stationary over time scales of an hour [24, 29].
Here, user-initiated means sessions instigated by human activity
rather than machine activity with a correlational structure (such as
periodic daemons). Note that although the model of the arrival pro-
cess can be relaxed from a Poisson process to a renewal process,
the Poisson assumption makes the false positive analysis simpler
(as will be seen in Section 4.3).
To ﬁt within this framework, we estimate rates for each type of
session using a sliding window of duration Trate = 1 hr. Our
model for session arrivals views the activity of local hosts as inde-
pendent from that of other local hosts, and, further, independent of
sessions of other types involving the same local host. We therefore
maintain separate notions of session rates for the different types of
applications in which each host participates. Finally, our deﬁni-
tion of session type also includes directionality, accounting for the
difference in the arrival characteristics of clients and servers.
Causality Detection Algorithm. We now describe a statistical
test that identiﬁes triggered connections by using our model of nor-
mal trafﬁc.
Consider the arrival of two connections Ci, Cj with types de-
noted Ti, Tj. Assume that Ci is the connection at the start of an
ongoing session S1. Let us provisionally assume that Cj marks the
beginning of a new, separate session, S2. Denote the arrival rates of
these session types as λ1 and λ2. Let the interarrival time between
Ci and Cj be x. Now consider the alternative that Ci triggered Cj.
In this case, in general we presume to ﬁnd x signiﬁcantly lower
than the case when Ci and Cj are unrelated; we base this presump-
tion on the expectation that connections due to a common origin
will tend to come somewhat close together. Our strategy is there-
fore to estimate the probability P of observing an interarrival x for
the null hypothesis of the connections being unrelated, and to de-
duce that Ci triggered Cj, and therefore Cj belongs to S1, if P is
less than a conﬁdence threshold α.
Let T1 and T2 be two sessions whose arrivals follow indepen-
dent Poisson processes with rates λ1 and λ2 respectively. Consider
the event of an arrival of T1 followed no later than x seconds by
an arrival of T2. We denote by P [T1, T2, x], the expected number
of such events per one unit of time. Given such a formulation, our
causality detection algorithm proceeds as follows. We ﬁrst catego-
rize connections into different types; estimate rates for each of these
types; and then use these computed rates along with the threshold α
to detect triggers. More speciﬁcally, on the arrival of a connection
C (either incoming or outgoing) of type T involving a local host L,
we perform the following actions:
• Let the sessions observed at L in the previous Ttrigger sec-
onds be S1, S2, . . . , Sn, where Ttrigger is a threshold speci-
fying the maximum interval that can separate a triggered con-
nection from the most recent activity in the session. In our
study, we set Ttrigger to be 500 sec.
• If any session Si (a) has the same type as C, (b) involves the
same remote host, and (c) had a connection arrival within a
time window Taggreg of C, then we add C to the most recent
such Si, and we are done. This is the simple aggregation
heuristic discussed above.
• Estimate the rate of connection arrivals at L for each session
type within the past Trate seconds (3600 sec in our study).
We form our estimate as simply the average interarrival time
between sessions of each type, over the window size Trate.
• For 1 ≤ i ≤ n, compute P [Ti, T, xi], for xi the interval
between the arrival of Si and C. Note that at this point C
differs in type from Si.
• If P [Ti, T, xi] < α and C and Si involve the same remote
host, then add C to Si. (We conceptually defer the test for the
same remote host to this point because when expanding our
work to discover sessions involving multiple remote hosts, it
is at this point that we will modify the inference algorithm.)
Also, note that if P [Ti, T, xi] < α holds for multiple Ti,
then C is added to all such sessions Si.
• If the probability test does not identify C as belonging to any
ongoing session, then C is considered to be the ﬁrst connec-
tion of a new session Sn+1.
Naturally, the performance of the above algorithm depends crit-
ically on the parameter α. Too low a value may mean we miss
certain causal links (false negatives); too high may lead to falsely
aggregating unrelated connections (false positives). The false neg-
ative rate is difﬁcult to characterize analytically due to the lack of a
statistical model for the arrival of triggered connections, so we rely
on empirical analysis for evaluating it. Our choice for P [T1, T2, x],
however, allows us to provide a bound on false positives; see below.
False Positives. In this section, we establish an upper bound for
P [T1, T2, x], where T1 and T2 are two different types of sessions,
and then use it to upper-bound the false positive rate (i.e., the num-
ber of false positives per second) in the presence of M different
session types.
THEOREM 1. Let λ1 and λ2 be the arrival rate for sessions of
type T1 and T2. Then, P [T1, T2, x], the expected number of events
where an arrival of type T1 is followed by an arrival of type T2
within time x, is P [T1, T2, x] (cid:2) λ1λ2x.
The proof can be found in Appendix A. Note that we also ver-
iﬁed Theorem 1 using Monte Carlo simulations [16]. Next, we
consider the scenario where there are m (cid:3) 2 types of connections.
COROLLARY 1. Let there be m types of sessions and let α be
the threshold for reporting a connection pair. Then the rate of false
positives per unit time can be upper bounded as m2α.
To prove this corollary, ﬁrst note that the number of different
pairs of session types under consideration is m2 (note that a session
of a particular type can also be a “trigger” for a second session of
the same type). Thus, from Theorem 1, since α is an upper bound
on the rate of false positives for a particular ordered pair of session
types, a simple union bound gives the formula in Corollary 1.
In practice, we choose the unit of time for measuring α as an
hour and we found that α = 0.1 per hour works well. Although our
proofs of these theorems assume stationarity, our results apply even
otherwise (e.g., non-homogeneous Poisson processes), as long as
the rate estimation algorithm adapts to the changing rates. Finally,
in our experiments, we found that the number of false positives is
typically lower than the worst-case bound proved above.
4.4 Discussion
The fact that our Session Extraction approach is statistical im-
poses certain constraints on our abstraction approach. That it may
exhibit false negatives is not particularly disconcerting: since our
focus is on discovering application behavior, usually a trace will
contain several instances of a particular type of behavior, so we can
abide missing some. Our extraction need not ﬁnd all instances to
be successful. Further, our Session Extraction approach may also
have false positives: for instance, the Poisson assumption used in
our statistical test may not hold, or, it may so happen that two con-
nections occur close-by in time simply by coincidence. We would
27
7
6
4
15
13
12
5
20
17
14
9
3
0
1
8
21
18
23
2
26
24
10
19
11
25
28
22
16
Figure 1: The Exact DFA for FTP
not want our abstraction mechanism led astray into deducing ses-
sion descriptors that incorrectly incorporate elements induced by
false aggregations.
Our strategy is to choose α to obtain acceptable false nega-
tive performance, and to then design our abstraction mechanism
to explicitly accommodate the level of false positives this leads to
(for which the analysis in the previous section also gives a useful
bound). We assessed different candidate values of α by manually
assessing the false negatives for 4 applications (SMTP, FTP, two
Web services) present in our traces, which led us to select α = 0.1.
This setting incurs a false negative rate of less than 25% [16].
5. STRUCTURE ABSTRACTION
The Structure Abstraction process aims to derive succinct de-
scriptions for application sessions based on the set of session types
reported by Session Extraction. We discuss how we represent ses-
sion descriptions and then present our abstraction framework.
5.1 Representation of Session Descriptors
We ﬁrst need to resolve “representation”: what language should
we use to abstractly describe the structure of sessions? We looked
for a good balance between expressiveness and ease of generat-
ing abstractions from complex initial descriptions, which led us to
choose regular expressions.1 This choice was supported by our pre-
vious empirical experiences when we manually attempted to derive
descriptions for different types of sessions [16]. In our discussions
and ﬁgures we will often use the DFA equivalents of particular reg-
ular expressions. We also further reﬁne this representation by la-
beling state transitions with probabilities, similar to the Customer
Model Behavior Graphs used for characterizing workloads on web-
sites [20].
Thus, given a set ST of observed session types ST =
(ST1, ST2, . . . ), we can capture the full structural range using a
regular expression that explicitly matches the entire set. Figure 1
shows such as complete DFA for FTP (as derived from our larger
dataset). Here we have omitted the labeling because the point of the
ﬁgure is simply to convey the great complexity that the full struc-
tural range can manifest. In this case, the DFA is complex (with
28 states) due to the fact that it has to exactly capture several FTP
sessions varying in the number and the direction of data transfers.
Figure 2, on the other hand, shows a more “natural” (and
tractable) DFA that abstracts much of the original while preserving
some of its unintuitive features (the presence of HTTP transitions,
1We also experimented with using Hidden Markov Model infer-
ence techniques to abstract sessions, but found the results much
harder to intuitively understand, as well as requiring computation
that scales poorly with the size of the trace.
0
ftp_in
ftp_out
1
2
http_in
eph_in eph_out
eph_in eph_out
http_out
3
4
eph_in eph_out
5
http_in
eph_in
http_out
eph_out
6
http_in
7
eph_in
8
http_out
9
eph_out
Figure 2: Abstract Session Descriptor for FTP
Observed Session Types 
Exact 
DFA E
Coverage DFAs
(F1 , F2 , …)
Application
Categorization
Exact
Inference
Coverage
Phase
Generalization
Phase
Coverage Curve
DFAs (G1,G2,..)