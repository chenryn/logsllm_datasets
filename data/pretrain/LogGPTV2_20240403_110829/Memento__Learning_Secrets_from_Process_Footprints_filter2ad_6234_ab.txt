a
c
s
g
o
l
(
s
l
l
a
c
c
o
l
l
a
m
f
o
.
o
N
10-1
0
wikipedia.org
100
200
300
400
500
600
700
800
Size of allocated blocks (in kB)
106
105
104
103
102
101
100
l
)
e
a
c
s
g
o
l
(
s
l
l
a
c
c
o
l
l
a
m
f
o
.
o
N
10-1
0
cnn.com
200
400
600
800
1000
1200
Size of allocated blocks (in kB)
Figure 2. Firefox: Distribution of malloc’d block sizes.
Figure 3. Firefox: Distribution of malloc’d block sizes.
l
)
e
a
c
s
g
o
l
(
s
l
l
a
c
k
r
b
/
p
a
m
m
f
o
.
o
N
103
102
101
100
10-1
wikipedia.org
0
1000 2000 3000 4000 5000 6000 7000 8000 9000
Size of allocated blocks (in kB)
103
102
101
100
l
)
e
a
c
s
g
o
l
(
s
l
l
a
c
k
r
b
/
p
a
m
m
f
o
.
o
N
10-1
0
cnn.com
2000
4000
6000
8000 10000 12000 14000 16000
Size of allocated blocks (in kB)
Figure 4. Firefox: Distribution of mmap/brk allocation sizes.
Figure 5. Firefox: Distribution of mmap/brk allocation sizes.
the browser’s allocation and de-allocation patterns.
Fragmentation causes the allocator to issue more frequent
requests to the OS. As a consequence, the pattern of changes
in the OS-visible memory footprint varies even for the same
HTML content. This introduces noise into the attacker’s
measurements and decreases accuracy of the attack. Fortu-
nately, modern allocators aim to minimize fragmentation.
Requirements for a successful attack. Recall from Sec-
tion III that the attack process periodically measures the
target’s OS-visible memory footprint. For the attack to work,
these measurements must be diverse and stable. Diversity
means that
the sequences of changes in the monitored
process’s memory usage must vary signiﬁcantly between
different webpages. Stability means that these sequences—or
at least a signiﬁcant fraction of them—must be similar across
repeated visits to the same page.
The key decision is which process to monitor. “Mono-
lithic” browsers like Firefox run as a single process, but
in modern browsers like Chrome or OP, a separate process
is responsible for each piece of the browser’s functionality.
For example, OP has dedicated processes for the browser
kernel, user interface, cookie management, networking, and
database management. For these browsers, the attacker must
choose between monitoring a particular browser component,
with more measurements per process, or multiple compo-
nents, with fewer measurements per process.
In our experiments, we opted for more measurements
per process and monitored only the rendering process. This
process takes HTML content as input, parses it, creates
DOM trees, executes JavaScript, uncompresses images, and
generates raw bitmaps to be displayed via the user interface.
Most of these tasks are memory-intensive and memory usage
of the rendering process satisﬁes both stability and diversity.
Memory usage of other processes—for example, cookie
manager or HTML5 local storage handler—can provide
secondary channels to improve accuracy of the attack. For
example, a page setting multiple cookies will result
in
memory allocations in the cookie manager, differentiating
it from a page that does not set cookies.
Our attack exploits temporal changes in the memory
footprint caused by dynamic allocations from the heap and
mmap’d regions. Data resident size visible to the attacker
also includes stack, but we found in our experiments that
the number of pages allocated for the stack rarely changes.
Comparison with network attacks. It is well-known that
webpages can be ﬁngerprinted using the number and size of
objects on the page [5, 16], provided the attacker has access
to the user’s network packets and can thus directly observe
the sizes of objects on pages requested by the user—even if
the page is encrypted.
Fingerprinting webpages using object sizes does not work
in our setting. There is no 1-to-1 correspondence between
individual objects and memory allocation requests to the OS
(see Figs. 2 and 4). There are many allocation sites in the
browser and its libraries, and the attacker who monitors the
browser’s memory usage observes only the cumulative effect
of multiple allocations corresponding to multiple HTML ob-
jects. This information is signiﬁcantly more coarse-grained
147
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply. 
than that available to the network attacker.
Allocations caused by executing JavaScript and parsing
DOM trees are not related to the size of HTML objects on
the page. Image decompression results in bigger allocations
during rendering than the size of the image object, big ob-
jects may be written into temporary ﬁles piece by piece and
never stored in memory in their entirety, etc. Fragmentation
and the resulting nondeterminism of the allocator’s behavior
introduce further noise into our attacker’s observations.
In Chrome, the attacker can also measure the footprint of
the networking process alone. This does not enable the attack
based on individual object sizes because it processes Web
pages as blocks of bytes, without distinguishing individual
objects. Furthermore, the networking process re-uses buffers
through which it streams data to other processes, thus their
sizes are useless for identifying individual objects.
V. EXPERIMENTAL SETUP
We report experimental results for Chrome, Firefox, and
the default Android browser, but the principles of our attack
are applicable to any browser that exposes its memory usage
to other system users. Android experiments are representa-
tive of the smartphone setting, where a malicious application
may spy on the phone owner’s Web browsing. Chrome
and Firefox experiments are representative of a shared-
workstation setting, where one user may spy on another.
Chrome experiments were performed with a Chrome
13.0.782.220 browser running on an Acer laptop with an
Intel Core Duo 2 GHz processor, 2 GB of memory, and
Linux Ubuntu 10.04 operating system. By default, Chrome
uses the process-per-site-instance model and forks a separate
rendering process for each instance of a site visited by the
user.4 A site is identiﬁed by its protocol, domain, and port.
The renderer process is responsible for parsing and executing
JavaScript, building DOM trees, rendering images, etc., and
serves as the target in our experiments.
In addition to the renderer, Chrome also forks one process
per each type of plugins that are needed to display the site
instance correctly. These can be distinguished from the ren-
derer process because they have the “–type=plugin” option
in their command line, as opposed to “–type=renderer”.
Firefox experiments were performed with Firefox 3.6.23
on the same laptop. Unlike Chrome, Firefox is a monolithic
browser: a single process is responsible for most of its
functionality and serves as the target in our experiments.
Firefox plugins run in separate “plugin-container” processes.
Whereas Chrome creates a new process for each instance
of a site, Firefox uses one process for all sites visited for the
user. The attack works against Chrome unconditionally, but
against Firefox it works if the browser is fresh, i.e., it can
identify the ﬁrst page visited by the user after starting the
4http://www.chromium.org/developers/design-documents/
process-models
browser, but accuracy drops off afterwards. We used fresh
browser instances in the Firefox experiments. In Section VI,
we describe variations of the attack that work even against
a “dirty” Firefox browser.
To perform browsing measurements on a large scale,
Android experiments were done with the default browser
in Android 2.2 Froyo in the x86 simulator running in a
VirtualBox VM. We veriﬁed that the results are the same for
3.1 Honeycomb in Google’s ARM simulator, but the latter
simulator is too slow for the scale of our experiments. We
used a native attack process for better accuracy. Android pro-
vides developers with the Native Development Kit (NDK),
thus a malicious process can easily masquerade as a game
or another app that plausibly requires native functionality
for performance reasons. Memory footprints of concurrent
processes can also be measured by applications implemented
in Android SDK, but with a lower measurement rate.
In contrast to desktops, an Android user is much likelier
to open a fresh browser for each site visit. Most Android
devices are charged based on their data usage. Keeping the
browser open increases the amount of data transferred over
the cellular network, thus the user has a monetary incentive
to close the browser after viewing a page.
Furthermore, memory is a scarce resource in most An-
droid devices. Once memory usage grows high, the kernel
starts killing inactive processes, reclaiming their memory,
and storing application state—for example, the URL of the
current page in the browser. When the user switches to the
browser, the kernel starts a fresh browser instance with the
saved URL as the destination. Since the browser app has a
big memory footprint, its chances of getting killed when left
inactive and then started afresh are high.
Automating page visits. Gathering memory signatures of a
large number of pages is signiﬁcantly more time-consuming
than a simple Web crawl. Most memory allocations in the
browser happen when rendering and executing content, after
it has been fetched. Therefore, it is necessary to wait until
the browser has ﬁnished retrieving and displaying the page.
JavaScript- and Flash-heavy pages can take a long time to
load. Many of those located far from our measurement site
took as long as 30-40 seconds to fetch and render fully.
Because load times are extremely variable, we instru-
mented browsers with custom scripts that automatically
close the tab 5 seconds after an on load event. The default
Android browser does not support user scripts. We started
its instances remotely, using Google’s adb tool to execute
the am start -a android.intent.action.view
-d  command, and closed the page after 20 seconds.
Measuring browsers’ memory footprints. First, the attack
process ﬁnds out the pid of the browser process using ps or
a similar utility. It then reads the /proc//statm
ﬁle in a loop. Each time it observes a change in data
resident size, it records the new value. Because the initial
148
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply. 
allocations of most browsers do not depend on the contents
of the webpage, measurements only include values above the
browser-speciﬁc threshold: 8MB (2048 memory pages) for
Chrome and 64MB (16348 memory pages) for Firefox.5 For
the Android browser, the attack process records all values.
To read proc faster, the attack process uses the pread
system call which does not change the current offset, allow-
ing repeated reads without rewinding or closing the ﬁle. To
conceal its heavy CPU use, the attack process exploits the
well-known ﬂaw in the Linux scheduling algorithm [17].
Fig. 18 shows that
this CPU cheat has little effect on
accuracy of the attack. Its only purpose is to hide the attack
process’s activity from other users.
To scale our experiments up to 100,000 webpages, we
used a different measurement method that runs the browser
as a child of the attack process. The attack process uses
ptrace to stop the browser at every system call and
measures drs in /proc//statm. This enables up
to 6 concurrent measurement and browser processes on the
same CPU without compromising the measurement rate. For
Firefox, the attack process starts firefox-bin as its child.
For Chrome, it only measures the renderer process and starts
the browser with the “–renderer-cmd-preﬁx=tracer” option.
Chrome then starts a copy of the tracer as its renderer and the
tracer forks the original renderer as its child. We also used
the “–allow-sandbox-debugging” option to allow ptrace
to monitor the renderer as this is not allowed by default.
In the rest of the paper, we refer to measurements collected
using this method as FixSched measurements.
Obviously, only Attack measurements are available during
the actual attack. The sole purpose of FixSched is to
scale our experiments. Fig. 14 shows that the measurement
method does not signiﬁcantly affect recognizability. The vast
majority of pages that are recognizable in the FixSched
experiments remain recognizable under the actual attack.
Stability of footprints across different machines. The
memprints used in our attack are based on measurements of
the browser’s data resident size. For a given HTML content,
these values are OS- and browser-speciﬁc, but machine-
independent (except for minor variations described in Sec-
tion IV). We used Chrome and Firefox to load cached copies
of 20 random webpages on 10 machines with different
processors (from 2 to 8 cores) and amounts of memory
(from 2 to 16 GB), all running Linux Ubuntu 10.04. The
memprints for each page were identical across machines.
User-installed customizations such as plugins, add-ons,
and extensions run either in the browser’s memory context,
or as separate processes. For example, video players, PDF
readers, Chrome extensions, etc. run as separate processes
and have no effect on the memory usage of browser pro-
cesses monitored by our attack. Firefox toolbars, on the other
5Firefox generally consumes more memory than Chrome. Also, the attack
on Chrome only measures the rendering process.
hand, change the browser’s memory footprint in predictable
ways:
typically, each toolbar is associated with a small
number of possible offsets, and each measurement of the
browser’s data resident size is shifted by one of the offsets.
We conjecture that the attacker can compute a database of
offsets for common Firefox extensions and account for their
effect when matching memprints against page signatures.
Extensions that signiﬁcantly change the content rendered by
the browser for a given page—for example, block scripts or
suppress ads—result in very different memprints and thus
require a separate database of webpage signatures.
VI. EVALUATING THE BASIC ATTACK
We now show that our attack can identify many webpages
as they are being rendered by the browser. We are concerned
about two types of errors. A false negative means that the
attack fails to recognize the page visited by the victim. False
negatives can be caused by pages that signiﬁcantly change
their content depending on the visitor’s IP address, cookies,
or some other factor that varies between the attacker’s visits
when computing the signature database and the victim’s
visits. In this case, memprints observed during the attack
will not match the pre-computed signatures. A false positive
means that the victim visits page A, but the attack mistakenly
“recognizes” the resulting memprint as another page B.
First, we show that there exists a subset of distinguishable
webpages. For each such page, browser memprints are
similar across visits to this page, but dissimilar to visits to
any other page (including pages outside the distinguishable
subset). The matching threshold of Algorithm 1 can thus be
set so that any match to the signature of a distinguishable
page is correct and there are no false positives.
Second, we measure the true positive rate for distinguish-
able pages, i.e., how often a visit to each page produces a
memprint that matches that page’s signature.
Third, we measure how accuracy of inference is affected
by the measurement rate and concurrent workload, and
describe variations of the attack.
We say that a memprint m and a webpage signature p
match if their similarity (see Section III) is above a certain
threshold (see Algorithm 1). A match is correct if m was
indeed a visit to p, false otherwise. Distinguishability of a
page is the difference between the (probabilistically) worst
correct match of any memprint to this page’s signature and
the best false match. Positive distinguishability implies low
false positive rate. Recognizability of a page is the true
positive rate, i.e., the percentage of visits to this page whose
memprints are matched correctly.
Measuring distinguishability. In our experiments, we mea-
sure distinguishability with respect to ﬁxed ambiguity sets.
Intuitively, a page is distinguishable if a visit to this page
is unlikely to be confused with a visit to any page from
the ambiguity set. We cannot rule out that a page may be
confused with some page not from the ambiguity set. Our
149
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:37 UTC from IEEE Xplore.  Restrictions apply. 
reported false positive rates are thus subject to the “closed-
world” assumption (i.e., the victim only visits pages in the
ambiguity set). To ensure that our “closed world” is as big
as possible given the constraints of our experimental setup,
we use the front pages of Alexa top N websites as our
ambiguity sets, regardless of whether they are themselves
distinguishable or not. N varies between 1,000 and 100,000