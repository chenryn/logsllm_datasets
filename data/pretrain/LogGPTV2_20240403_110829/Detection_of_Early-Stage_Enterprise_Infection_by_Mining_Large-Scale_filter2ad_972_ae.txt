We thoroughly examined the domains labeled as new ma-
licious and suspicious and found several prominent and inter-
esting clusters. Among the new malicious domains, we found
5 domains hosting URLs with the same pattern /logo.gif?
later conﬁrmed by the SOC as related to Sality worm. We
also found 15 domains with the same URL pattern reported
by VirusTotal. Moreover, we identiﬁed a cluster of 10 DGA
domains with none of them reported by VirusTotal and SOC,
demonstrating our detector’s ability in capturing new mali-
cious campaigns. All the malicious domains are under the
TLD .info and their names have 4 or 5 characters (e.g.,
mgwg.info). 9 out of the 10 domains hosts URLs with
pattern /tan2.html and visiting them will be redirected to
the remaining domain 1.tv990.info.
We labeled legitimate 63 domains belonging to categories
like Ad-network, Gaming, Toolbar and Torrent Tracker, re-
sulting in a FPR of 8.63 · 10−4% over 7.3M domains. They
are captured by our detector because they exhibit suspicious
features, like automated connections or are registered recently.
Though they do not pose serious harm to the enterprise, some
of them are policy violations (e.g., Gaming, Torrent Tracker).
We did not discover any suspicious activities from examining
log data, but we believe these domains still need to be vetted.
E. Comparison and performance
We compare the results of the two modes of operation.
Only 21 domains are detected in both modes, which is a
small percentage compared to 202 and 108 domains detected
separately. When deployed by the enterprise, we suggest our
detector conﬁgured to run in both modes, in order to have
better coverage. As we have shown, starting from a seed of
known malicious domains or hosts, the algorithm in SOC hints
mode can identify suspicious domains with high accuracy.
The C&C communication detector has the unique capability
of identifying C&C domains used in new attack campaigns.
To reduce the false positive rate in the no-hint mode, we
recommend that the detected C&C domains are ﬁrst vetted
by the SOC and then belief propagation is seeded only with
conﬁrmed malicious C&C domains.
In terms of performance, our system proves scalable to
the logs generated by a large enterprise (average 662GB data
daily). The data is stored on a parallel Greenplum database
with 90TB storage and is processed on a Cisco UCS C200 M2
server with 48GB of RAM. The normalization and proﬁling
stages take around 2 hours every day (this includes the time to
query the database, create normalized representations and write
the normalized data to disk). Belief propagation is extremely
fast (taking on average 5 seconds) since we build the bipartite
graph incrementally and only add to the graph a small number
of suspicious domains and hosts in each iteration.
Both variants of our detector include conﬁgurable options
for various parameters (e.g., thresholds for domain scoring).
These parameters can be chosen by the SOC according to
the capacity of the team performing manual investigation, and
various tradeoffs between accuracy and larger coverage as
shown by our experimental evaluation.
VII. RELATED WORK
Our work focuses on detecting early-stage infections within
enterprise perimeters,
including communications related to
malware delivery and C&C. There has been a large body of
work in this area, but to the best of our knowledge, we are
the ﬁrst to exploit the relationship between malicious domains
associated with the same attack campaign, and to detect them
5454
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:58:29 UTC from IEEE Xplore.  Restrictions apply. 
by a graph-theoretic framework based on belief propagation.
We describe here related work in the literature.
Detection of C&C communication. Some of the previous
work detecting C&C domains in botnets require malware
samples as input to detect connections with similar patterns
(e.g., BotFinder[38], Jackstraws[22]). Anomaly-based botnet
detection systems (e.g., BotMiner[16], BotSniffer[18] and
TAMD [42]) typically detect clusters of multiple synchronized
hosts infected by the same malware. In contrast to these, our
approach does not require malware samples and can detect
campaigns with few hosts communicating to a C&C server.
it
in that
DISCLOSURE [7] identiﬁes C&C trafﬁc using features
extracted from NetFlow records but incorporates external in-
telligence sources to reduce false positives. Our C&C detector
is different
leverages enterprise-speciﬁc features
extracted from HTTP connections. From that perspective, Ex-
ecScent [28] is close to our work in detecting C&C communi-
cations in large enterprise network. However, ExecScent needs
malware samples to extract templates representing malicious
C&C connections. The templates are adapted to a speciﬁc
enterprise considering the popularity of different features (URL
patterns, user-agent strings, etc.). Our work complements
ExecScent in detecting new unknown malware that can be
provided as input to the template generation module.
Detection of malware delivery. Nazca [21] analyzes web
requests from ISP networks to identify trafﬁc related to mal-
ware delivery and unveils malicious distribution networks.
CAMP [33] determines reputation of binary downloads in
the browser and predicts malicious activities. BotHunter [17]
identiﬁes sequences of events during infection, as observed
from a network perimeter.
Detection of malicious domains. Domains used in malicious
activities are backed by highly resilient infrastructures to deal
with takedowns or blacklisting, and hence exhibit unique char-
acteristics distinct from benign sites. Another branch of work
detects domains involved in malicious activities by patterns
observed in DNS trafﬁc (e.g., EXPOSURE [8], Notos [4],
Kopis [5], and Antonakakis et al. [6]). Paxson et al. [31] detect
malicious communication established through DNS tunnels.
Carter et al. [9] use community detection for identifying highly
localized malicious domains in the IP space.
Anomaly detection in enterprise network. Beehive [41]
is an unsupervised system identifying general anomalies in
an enterprise setting including policy violations and malware
distribution. Our work is speciﬁcally targeting enterprise in-
fections which pose high risk and potential ﬁnancial loss.
Targeted attacks. The threats in cyberspace keep evolving and
more sophisticated attacks recently emerged. Some targeted
attacks (APT) are well-funded, carefully orchestrated and
persist in the victim environments for years before detection.
Detecting targeted attacks in general is a very challenging
task. These attacks are usually very stealthy and able to evade
existing defenses [3]. However during the automated infection
stage many campaigns (e.g., Shady RAT [20], Mirage [11],
APT1 [26]) exhibit similar infection patterns. Recent studies
have shown that even though in theory APTs could be ar-
bitrarily sophisticated, in practice goal-oriented attackers use
relatively low levels of sophistication [39], [27], [24]. We
leverage some common patterns observed during the infection
stage to build a detector tailored to an enterprise. Our detection
result on the LANL’s APT infection discovery challenge indi-
cates that our techniques have potential in detecting infections
originated from targeted attacks.
VIII. LIMITATIONS AND DISCUSSION
As reported by Mandiant, the infection patterns that we
detect are quite prevalent in many APT attacks. Nevertheless,
attackers could in principle use a number of techniques to
evade our detectors, such as:
- Attackers may attempt to communicate through protocols
other than HTTP(S) but most other communication is blocked
at an enterprise border.
- Attackers could add more randomization to the timing
of C&C communications evading our dynamic histogram
detector. In that case, communication patterns will be less
predictable to attackers orchestrating a campaign.
- Attackers could use standard user-agent strings but they
need to determine a popular UA for an enterprise (since
we measure UA popularity within the enterprise). Popular
UAs limit functionality of malware that encodes host status,
conﬁguration and other information in the UAs.
- Attackers could register domains in advance before their use.
- Attakers could communicate directly with IP addresses at an
increased risk of their infrastructure being discovered.
All
these evasion methods come at an increased cost
of operation for attacker, limiting malware functionality and
increasing the risk of campaign discovery.
Our proposed approach is meant to complement existing
tools rather than replace them. The results from §VI demon-
strate that our belief propagation algorithm in both variants
(SOC hints and no-hint) detects new suspicious activities
overlooked by deployed defense mechanisms. These include
both domains associated with existing malware campaigns
(and identiﬁed by VirusTotal), but with new presence in the
enterprise of our study, as well as entirely new malware cam-
paigns (not yet detected by anti-virus technologies). Since our
methods are focused on detecting the initial infection stages
of a campaign it is difﬁcult to determine how many of these
suspicious activities are related to more advanced attacks, and
how many are mainstream malware variants. We believe that
monitoring activity to these suspicious domains over longer
periods of time, as well as correlating with information from
other data sources will answer this question, and we leave this
as an interesting avenue for future work.
ACKNOWLEDGMENTS
We are grateful to Kevin Bowers, Michael Fikes, Robert
Grifﬁn, Christopher Harrington, Engin Kirda, Silvio La Porta,
Todd Leetham, James Lugabihl, Robin Norris, Martin Rosa,
and Ronald L. Rivest for their many useful comments and
suggestions on the system design and evaluation. We also thank
the enterprise who permitted us access to the web proxies
dataset and helped with investigation of suspicious activities.
We are grateful to LANL for releasing the anonymous DNS
5555
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:58:29 UTC from IEEE Xplore.  Restrictions apply. 
dataset and the C3E 2014 organizers for supporting the APT
infection discovery challenge. Finally, we thank our shepherd
Michel Cukier and anonymous reviewers for their feedback on
drafts of this paper.
[21] L. Invernizzi, S. Miskovic, R. Torres, S. Saha, S.-J. Lee, C. Kruegel,
and G. Vigna. Nazca: Detecting malware distribution in large-scale
networks.
In Proc. ISOC Network and Distributed System Security
Symposium (NDSS ’14).
[22] G. Jacob, R. Hund, C. Kruegel, and T. Holz.
REFERENCES
[23]
command and control connections from bot trafﬁc.
USENIX Security Symposium, 2011.
James Wyke.
//nakedsecurity.sophos.com/zeroaccess/, 2012.
The ZeroAccess rootkit — Naked Security.
http:
Jackstraws: Picking
In Proc. 20th
[24] S. Le Blond, A. Uritesc, C. Gilbert, Z. L. Chua, P. Saxena, and E. Kirda.
A look at targeted attacks through the lense of an NGO. In Proc. 23rd
USENIX Security Symposium, 2014.
J. Ma, L. K. Saul, S. Savage, and G. M. Voelker. Beyond blacklists:
Learning to detect malicious web sites from suspicious URLs. In Proc.
15th ACM International Conference on Knowledge Discovery and Data
Mining, KDD, 2009.
[25]
[26] MANDIANT. APT1: Exposing one of China’s cyber espionage units.
Report available from www.mandiant.com, 2013.
[27] W. Marczak, J. Scott-Railton, M. Marquis-Boire, and V. Paxson. When
governments hack opponents: A look at actors and technology. In Proc.
23rd USENIX Security Symposium, 2014.
[28] T. Nelms, R. Perdisci, and M. Ahamad. ExecScent: Mining for new
C&C domains in live networks with adaptive control protocol templates.
In Proc. 22nd USENIX Security Symposium, 2013.
[29] A. Oprea, Z. Li, T.-F. Yen, S. H. Chin, and S. Alrwais. Detection of
early-stage enterprise infection by mining large-scale log data. http:
//arxiv.org/abs/1411.5005, 2014.
[30] Panda Security.
Annual
report PandaLabs
- 2013 summary.
http://press.pandasecurity.com/wp-content/uploads/2010/05/
PandaLabs-Annual-Report 2013.pdf, 2014.
[31] V. Paxson, M. Christodorescu, M. Javed, J. Rao, R. Sailer, D. Schales,
M. P. Stoecklin, K. Thomas, W. Venema, and N. Weaver. Practical
comprehensive bounds on surreptitious communication over DNS. In
Proc. 22nd USENIX Security Symposium, 2013.
J. Pearl. Reverend Bayes on inference engines: A distributed hierarchi-
cal approach. In Second National Conference on Artiﬁcial Intelligence,
1982.
[32]
[33] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and N. Provos.
CAMP: content-agnostic malware protection. In Proc. ISOC Network
and Distributed System Security Symposium (NDSS ’13), 2013.
[34] U. Rivner.
Anatomy of an attack.
http://blogs.rsa.com/rivner/
anatomy-of-an-attack, 2011.
[35] RSA. Stalking the kill chain. http://www.emc.com/collateral/hardware/
solution-overview/h11154-stalking-the-kill-chain-so.pdf, 2012.
[36] Y. Rubner, C. Tomasi, and L. J. Guibas. The earth mover’s distance as
a metric for image retrieval. International Journal of Computer Vision,
40:99–121, 2000.
[37] G. Stringhini, C. Kruegel, and G. Vigna. Shady Paths: Leveraging
In Proc. 20th ACM
surﬁng crowds to detect malicious web pages.
Conference on Computer and Communications Security, CCS, 2013.
[38] F. Tegeler, X. Fu, G. Vigna, and C. Kruegel. BotFinder: Finding
bots in network trafﬁc without deep packet inspection.
In Proc. 8th
International Conference on Emerging Networking Experiments and
Technologies, CoNEXT ’12, 2012.
[39] O. Thonnard, L. Bilge, G. OGorman, S. Kiernan, , and M. Lee. Indus-
trial espionage and targeted attacks: Understanding the characteristics of
an escalating threat. In Proc. 15th International Symposium on Recent
Advances in Intrusion Detection, RAID, 2012.
[40] WebSense Security Lab. WebSense 2014 Threat Report. http://www.
websense.com/assets/reports/report-2014-threat-report-en.pdf, 2014.
[41] T.-F. Yen, A. Oprea, K. Onarlioglu, T. Leetham, W. Robertson, A. Juels,
and E. Kirda. Beehive: Large-scale log analysis for detecting suspicious
activity in enterprise networks. In Proc. 29th Annual Computer Security
Applications Conference, ACSAC ’13, pages 199–208, New York, NY,
USA, 2013. ACM.
[42] T.-F. Yen and M. K. Reiter. Trafﬁc aggregation for malware detection. In
Proc. Intl. Conf. Detection of Intrusions and Malware, and Vulnerability
Assessment, DIMVA, 2008.
[1] Hackers
months.
chinese-hackers-inﬁltrate-new-york-times-computers.html, 2013.
4
http://www.nytimes.com/2013/01/31/technology/
attacked
Times
China
The
last
for
in
[2] Target’s data breach: The commercialization of APT.
http://www.
securityweek.com/targets-data-breach-commercialization-apt, 2014.
[3] Verizon 2014 data breach investigations
verizonenterprise.com/DBIR/2014/, 2014.
report.
http://www.
[4] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.
Building a dynamic reputation system for DNS. In Proc. 19th USENIX
Security Symposium, 2010.
[5] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou, II, and D. Dagon.
Detecting malware domains at the upper DNS hierarchy. In Proc. 20th
USENIX Security Symposium, 2011.
[6] M. Antonakakis, R. Perdisci, Y. Nadji, N. Vasiloglou, S. Abu-Nimeh,
W. Lee, and D. Dagon. From throw-away trafﬁc to bots: Detecting
the rise of DGA-based malware.
In Proc. 21st USENIX Security
Symposium, 2012.
[7] L. Bilge, D. Balzarotti, W. Robertson, E. Kirda, and C. Kruegel. DIS-
CLOSURE: Detecting botnet Command-and-Control servers through
large-scale NetFlow analysis. In Proc. 28th Annual Computer Security
Applications Conference, ACSAC, 2012.
[8] L. Bilge, E. Kirda, K. Christopher, and M. Balduzzi. EXPOSURE:
Finding malicious domains using passive DNS analysis. In Proc. 18th
Symposium on Network and Distributed System Security, NDSS, 2011.
Probabilistic threat
IEEE Transactions on Information
[9] K. M. Carter, N. Idika, and W. W. Streilein.
propagation for network security.
Forensics and Security, 9, 2014.
[10] Command Five Pty Ltd. Command and control in the ﬁfth domain. http:
//www.commandﬁve.com/papers/C5 APT C2InTheFifthDomain.pdf,
2012.
[11] Dell SecureWorks. The Mirage campaign. http://www.secureworks.
com/cyber-threat-intelligence/threats/the-mirage-campaign/, 2012.
[12] Dell
SecureWorks.
of
http://www.secureworks.com/cyber-threat-intelligence/threats/
top-banking-botnets-of-2013/, 2014.
banking
botnets
Top
2013.
[13] N. Falliere, L. O. Murchu, and E. Chien. W32.Stuxnet dossier. http:
//www.symantec.com/security response/whitepapers.jsp, 2011.
[14] P. Ferrell. APT infection discovery using DNS data. C3E Chal-
lenge Problem. http://permalink.lanl.gov/object/tr?what=info:lanl-repo/
lareport/LA-UR-13-23109, 2013.
[15] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich,
K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis,
N. Provos, M. Z. Raﬁque, M. A. Rajab, C. Rossow, K. Thomas,
V. Paxson, S. Savage, and G. M. Voelke. Manufacturing compromise:
The emergence of Exploit-as-a-Service. In Proc. 19th ACM Conference
on Computer and Communications Security, CCS, 2012.
[16] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner: Clustering
analysis of network trafﬁc for protocol and structure-independent botnet
detection. In Proc. 17th USENIX Security Symposium, 2008.
[17] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee. BotHunter:
Detecting malware infection through IDS-driven dialog correlation. In
Proc. 16th USENIX Security Symposium on USENIX Security Sympo-
sium, SS’07, 2007.
[18] G. Gu, J. Zhang, and W. Lee. BotSniffer: Detecting botnet command
In Proc. 15th Network and
and control channels in network trafﬁc.
Distributed System Security Symposium, NDSS, 2008.
[19] S. Hao, N. Feamster, and R. Pandrangi. Monitoring the initial DNS
In Proc. ACM Internet Measuremnt
behavior of malicious domains.
Conference, IMC ’11, 2011.
[20] Hon Lau. The truth behind the Shady RAT. http://www.symantec.com/
connect/blogs/truth-behind-shady-rat, 2011.
5656
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:58:29 UTC from IEEE Xplore.  Restrictions apply.