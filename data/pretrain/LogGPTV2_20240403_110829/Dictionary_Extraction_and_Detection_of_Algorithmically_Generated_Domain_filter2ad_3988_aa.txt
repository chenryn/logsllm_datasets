title:Dictionary Extraction and Detection of Algorithmically Generated Domain
Names in Passive DNS Traffic
author:Mayana Pereira and
Shaun Coleman and
Bin Yu and
Martine De Cock and
Anderson C. A. Nascimento
Dictionary Extraction and Detection
of Algorithmically Generated Domain
Names in Passive DNS Traﬃc
Mayana Pereira1(B), Shaun Coleman2, Bin Yu1, Martine DeCock2,
and Anderson Nascimento2
2 Institute of Technology, University of Washington Tacoma, Tacoma, WA, USA
1 Infoblox Inc., Santa Clara, CA, USA
{mpereira,biny}@infoblox.com
{spcole,mdecock,andclay}@uw.edu
Abstract. Automatic detection of algorithmically generated domains
(AGDs) is a crucial element for ﬁghting Botnets. Modern AGD detec-
tion systems have beneﬁted from the combination of powerful advanced
machine learning algorithms and linguistic distinctions between legit-
imate domains and malicious AGDs. However, a more evolved class
of AGDs misleads the aforementioned detection systems by generat-
ing domains based on wordlists (also called dictionaries). The resulting
domains, Dictionary-AGDs, are seemingly benign to both human anal-
ysis and most of AGD detection methods that receive as input solely
the domain itself. In this paper, we design and implement method called
WordGraph for extracting dictionaries used by the Domain Generation
Algorithms (DGAs) solely DNS traﬃc. Our result immediately gives us
an eﬃcient mechanism for detecting this elusive, new type of DGA, with-
out any need for reverse engineering to extract dictionaries. Our exper-
imental results on data from known Dictionary-AGDs show that our
method can extract dictionary information that is embedded in the mal-
ware code even when the number of DGA domains is much smaller than
that of legitimate domains, or when multiple dictionaries are present in
the data. This allows our approach to detect Dictionary-AGDs in real
traﬃc more accurately than state-of-the-art methods based on human
deﬁned features or featureless deep learning approaches.
Keywords: Malicious domain name · Domain generation algorithm
Dictionary-AGD · Malware detection · Machine learning
1 Introduction
Whenever a client needs to connect to a server over the internet by using web
addresses (domains), these are ﬁrst translated into IP addresses. The Domain
Name System (DNS) is responsible for doing this translation. Requests con-
taining web addresses arrive at DNS servers that reply with corresponding IP
c(cid:2) Springer Nature Switzerland AG 2018
M. Bailey et al. (Eds.): RAID 2018, LNCS 11050, pp. 295–314, 2018.
https://doi.org/10.1007/978-3-030-00470-5_14
296
M. Pereira et al.
addresses, or with an error message in case the domain is not registered – an
NX Domain. Malicious software (malware) also uses this mechanism to com-
municate with their command and control (C&C) center. However, instead of
using a single hard-coded domain to communicate with the C&C (which could
be easily blocked), several malware families use a more sophisticated mecha-
nism known as Domain Generation Algorithms (DGAs) [15]. DGAs provide a
method for controllers of botnets to dynamically produce a large number of ran-
dom domain names and select a small subset for actual command and control
use. This approach makes blacklisting ineﬀective. Being able to detect algorith-
mically generated domains automatically becomes, thus, a vital problem.
Traditional DGA algorithms usually start from random seeds and produce
domains that are distinctly diﬀerent from common benign domains. They appear
more “random looking”, such as, for example, the domain sgxyﬁxkhuark.co.uk
generated by the malware Cryptolocker. Traditional DGAs are detected with
techniques that leverage the distribution of characters in the domain, either
through human engineered lexical features [3,11,17] or through training deep
neural networks [10,16,19,20,22,23].
Lately, a newer generation of DGA algorithms has been observed. This new
kind of DGA makes detection by the techniques mentioned above much harder,
namely by producing domains that are similar to the ones created by a human.
Dictionary-based DGAs generate domains by concatenating words from a dictio-
nary. For example, the malware Suppobox [7], a known Dictionary-based DGA,
produces domains such as: heavenshake.net, heavenshare.net and leadershare.net
[15].
Due to the challenging nature of the problem of detecting Dictionary-AGDs
based solely on the domain name string itself, one often resorts to other infor-
mation such as the IP address of the source [8], or information about the time
when the domain was sent to the DNS server [1]. This kind of information
can be expensive to acquire, or due to privacy concerns, it might just not be
available. Moreover, detecting an AGD based solely on the domain allows for
inline, real-time blocking of such domain at the DNS server level – a highly
desirable feature. Another existing approach to detect Dictionary-AGDs is to
reverse engineer the malware [4], extracting the list of words in the dictionary
and using this list to identify domains that are generated by the malware. This
process is labor-intensive and time-consuming, making it unsuitable to detect
new Dictionary-based DGA malware as soon as it emerges.
Little or no attention has been given in the literature to the problem that
we address in this paper: detecting Dictionary-based DGAs purely based on the
domain name string, and without reverse engineering the malware. A notable
recent exception is the work by Lison and Mavroeidis [10] who constructed a deep
learning-based DGA detection model that can detect Dictionary-AGDs gener-
ated from a “familiar” dictionary. Familiar in this context means that a large
number of Dictionary-AGDs stemming from the same dictionary are assumed
to be available as examples to train the model. Once trained, the model can
detect previously unseen Dictionary-AGDs provided that they originate from
Detection of Algorithmically Generated Domain Names in DNS Traﬃc
297
a dictionary that has already been seen during training time. In practice, it is
natural for hackers to change the dictionary in a Dictionary-based DGA, leaving
the problem of detecting Dictionary-AGDs largely unresolved.
Contributions.
In this paper, we study the problem of detecting
Dictionary-based DGAs. We show that a state-of-the-art DGA classiﬁer based
on human engineered lexical features that does well for traditional DGAs per-
forms very poorly when confronted with Dictionary-based DGAs. We also show
that deep neural networks, while better at detecting Dictionary-AGDs, struggle
to maintain a consistent good performance in face of changes in the dictionary.
We propose the ﬁrst eﬀective method for detecting and extracting the dictio-
nary from Dictionary-based DGAs purely by observing domain name strings in
DNS traﬃc. The intuition behind our approach is that, for known Dictionary-
based DGAs, the words from the dictionary are used repeatedly by the DGA in
diﬀerent combinations to generate domains. We leverage these repetitions and
combinations within a graph-based approach to isolate Dictionary-based DGA
domains in traﬃc.
The fact that our method is completely agnostic to the dictionary used as
generator by the DGA, and in fact learns this dictionary by itself (Sect. 4), makes
it very robust: if in the future the malware starts generating domains with new
dictionaries we still detect them, as we show in our experiments (Sect. 6). Even in
a highly imbalanced scenario, where the domain names generated by a speciﬁc
Dictionary-based DGA algorithm make up only a very small fraction of the
traﬃc, our WordGraph method is successful at isolating these domain names
and learning the underlying dictionary.
The remainder of this paper is structured as follows: after presenting an
overview of related work in Sect. 2 and recalling necessary preliminaries in Sect. 3,
we describe our WordGraph method for detection and extraction of DGA dictio-
naries in Sect. 4. Next, in Sect. 5 we provide our experimental methodology. This
section contains details about the ground truth and real life traﬃc data used in
our experiments, as well as a more detailed description of the state-of-the-art
methods that we compare our WordGraph method with, namely a random for-
est classiﬁer based on lexical features, and a convolutional neural network based
deep learning approach. In Sect. 6 we present the results of the various methods
on ground truth data as well as on real traﬃc data, showing that, unlike the
other approaches, the WordGraph approach has a consistently high true posi-
tive rate vs. an extremely low false positive rate. Furthermore, after deploying
our solution in a real network, we detected variations of known dictionaries that
have never been reported previously in the literature.
2 Related Work
Blacklists were one of the ﬁrst actions taken by the security community to
address the problem of malicious domains. These continuously updated lists
serve as databases for known malicious entities. One of the main advantages
of blacklists is that they provide the beneﬁt of lookup eﬃciency and precision.
298
M. Pereira et al.
However, after the deployment of DGAs by recent malware, domain blacklisting
became an ineﬀective technique for disrupting communications between infected
machines and C&C centers.
As a consequence, alternative methods for detecting DGA domains have been
proposed. In [21], Yadav et al. analyzed the distribution of alphanumeric char-
acters as well as bigrams in domains that map to the same set of IP-addresses.
This work is an extension of the analysis made by McGrath and Gupta [13] for
diﬀerentiating phishing/non-phishing URLs. The approach focuses on classifying
groups of URLs as algorithmically-generated or not, solely by making use of the
set of alphanumeric characters used. The authors used statistical measures such
as Kullback-Leibler divergence, Jaccard index, and Levenshtein edit distance to
measure the distance of the probability distributions of the n-grams, in order to
make a binary classiﬁcation (DGA vs. Non-DGA).
In [3], Antonakakis et al. developed a bot detection system called Pleiades
which uses a combination of lexical features and host-based features to cluster
domains. The main novelty of their work is the use of Non-Existing Domains
(NXDomain) queries to detect bots and as training data. Their insight is that
most domain queries made from a bot result in non-existent domains. Given
this observation they cluster NXDomains that have similar lexical characteristics
and are queried by overlapping sets of hosts. In a second stage, the clusters are
classiﬁed in order to identify their corresponding DGA family.
In order to achieve an overall solution, Schiavoni et al. [17] proposed Phoenix,
a mechanism that makes two diﬀerent classiﬁcations: a binary classiﬁcation that
identiﬁes DGA- and non-DGA-generated domains, using a combination of string
and IP-based features; and a multi-class classiﬁcation that characterizes the
DGA family, and ﬁnds groups of DGA-generated domains that are representative
of the respective botnets.
With the intention of building a simple DGA classiﬁer based on domain
names only, Mowbray and Hagen [14] proposed a DGA detection classiﬁer based
solely on URL length distributions. The approach allows the detection of a DGA
at the end of the ﬁrst time slot during which the ﬁrst infected machine is used
for malicious queries. However, their approach is eﬀective for only a limited set
of DGA families.
All methods described above rely on the extraction of predeﬁned, human
engineered lexical features from the domain name string. Recently, several works
have proposed DGA detection models based on deep learning techniques that
learn features automatically, thereby oﬀering the potential to bypass the human
eﬀort of feature engineering [10,16,20,22,23]. Deep learning approaches for DGA
detection based on convolutional neural networks (CNNs) and long short term
memory networks (LSTM) achieve a predictive performance that is at par with
or better than the methods based on human deﬁned lexical features, provided
that enough training data is available.
The DGA detection methods that we have described so far in this section all
use the domain name string itself, sometimes combined with some side informa-
tion like IP-based features. All these methods have been proposed and studied
Detection of Algorithmically Generated Domain Names in DNS Traﬃc
299
in the context of traditional DGA detection. Traditional DGAs produce domain
names that appear more random looking than usual benign domain names, even
to human observers. This substantial diﬀerence between the domain name strings
created by traditional DGAs vs. those created by humans is the underlying rea-
son for the success of the DGA detection methods described above. A newer
generation of DGA algorithms, the so-called Dictionary-based DGAs, attempt
to evade the traditional DGA detection methods by producing domain names
that look more similar to the ones created by humans. To this end, they con-
catenate words from a dictionary.
Since catching Dictionary-AGDs based on the domain name string itself is
challenging, it is natural to look at side information instead. An interesting app-
roach in this regard is the work of Krishnan et al. [8] who followed the insight
of Antonakakis et al. [3] that infected machines tend to generate DNS queries
that result in non-existent (NX) responses. Krishnan et al. applied sequential
hypothesis tests and focused on NX traﬃc patterns of individual hosts to iden-
tify infected machines. More recently, Abbink and Doerr [1] proposed to detect
DGAs based on sudden rises and declines of popularity of domain names in large
networks. Neither of these approaches uses information about the domain name
string itself, which sets it apart from the work in this paper.
Regarding the development of a classiﬁer that can label a given domain name
in real time as benign or malicious, solely based on the domain name string
itself, there has been some initial success with deep learning approaches for
catching Dictionary-AGDs [10]. As explained in Sect. 1, and as we also observe
in Sect. 6, this appears to work well for previously seen dictionaries, but doesn’t
oﬀer any guarantees for consistent predictive performance when the dictionary
in the malware is changed, which can be considered as an adversarial attack on
the machine learning model. We provide evidence in Sect. 6 that the WordGraph
method proposed in this paper is resilient to such kind of attack, thereby making
it the ﬁrst of its kind.
Finally, we stress that all the existing methods described above are aimed at
developing classiﬁers to distinguish between benign and malicious domain names.
The method proposed in this paper goes beyond, by learning the underlying
word patterns present in DNS traﬃc, and extracting the DGA-related words
from traﬃc. This results in the ﬁrst DGA detection method that automatically
extracts malware information from traﬃc in the form of malware dictionaries.
Once these dictionaries are known, it becomes straightforward to construct a
domain name classiﬁer based on them, as explained in Sect. 4.
3 Preliminaries
In this section we present deﬁnitions that are used throughout our method
description in Sect. 4. We refer the reader to [6,9,12] for more detailed expla-
nations of these concepts. Throughout this paper, a graph G(V, E) (or G for
brevity) is deﬁned as a set V of vertices and a set E of edges. In an undirected
graph, an edge is an unordered pair of vertices. If vertex v is one of edge e’s
300
M. Pereira et al.
endpoints, v is called incident to e. The degree of a vertex is the number of