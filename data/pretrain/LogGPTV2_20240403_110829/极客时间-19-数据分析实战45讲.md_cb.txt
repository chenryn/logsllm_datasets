# 45丨求职简历中没有相关项目经验，怎么办？上节课我讲到了如何培养数据分析思维，它是一个重要但不紧急的事。在工作求职中，你可能会遇到各种又重要又紧急的事，比如填写求职简历中的项目经验。它的重要性在于，HR一般都会依据简历中的项目经验初步筛选候选人是否符合面试要求，紧急性在于求职找工作往往就是眼前的事，但简历中的项目经验又很难临时抱佛脚。项目经验一般没有弹性，一是一，二是二，一方面要保证真实性，是自己做过的项目，另一方面又很难在短时间内积攒这些经验。如果没有项目经验，很多人就会感觉无从下手，这时候该怎么办呢？我自己面试过的技术人员少说也有上百人，我想以自己的经验做一些分享，在经验积累上和你分享以下三个需要注意的地方：1.  我们求职找工作的时候，要理解 HR 看项目经验的逻辑是什么？2.  明确要完善项目经验这个目标后，我们该如何快速定位要积累的内容，并通过实战和训练快速进行提升经验值？3.  如何在项目经验中融入自己的心得体会，让你的经验显得与众不同？
## HR 看相关项目简历，背后的逻辑是什么上篇文章中我讲到过，HR之所以要看相关的项目经验，是因为这些历史信息可以帮助他预估一个人相关的工作能力。知识不等于项目经验，即使你对知识都了解了，在实际项目过程中，还是会遇到各种问题。比如工具包安装不上、中文编码错误、画图显示不出来、算法运行过慢、数据拟合结果不好等各种问题。项目经历相当于一种训练，当你得到了更好的训练之后，数据分析的模型能力也就会越强，然后在"新公司"这个测试集中，就越有可能发挥好的效果。``{=html}做过训练和没有训练的人是完全不同的。如果你没有相关的经验，那么你现在找的这份工作就好比是训练集一样，没有一个公司会把他们的项目当做是你练手的数据集。大家都期望你是已经训练好的模型，可以马上开展新的工作，并且产生价值。所以在经验积累上，你要证明给 HR，我做过这样的项目，具备这样的能力。你可能想问，项目从哪里来呢？第一个肯定是以往类似的工作经历，第二个就是自己做过类似的项目。但是在简历中呈现数据分析的项目也是需要技巧的，简历不是流水账，你需要重点把当时的项目目标、采用的解决方案、实现的代码以及项目过程的总结体会拿给HR 看。这样，即使你没有相关的工作经历，如果你能通过专栏实战积累上面的 4 点，对HR 来说也是有说服力的，这样总比一张白纸要强得多。要知道 HR背后的逻辑是要通过简历证明你是已经被训练过的模型，可以上手工作了，而不是把新公司当成训练集。
## 如何完善简历里的项目经历现在我们需要简历中有更多的项目经验。如果你跟着专栏从头到尾完整学习了，在爬虫、数据可视化、数据清洗和集成、数据挖掘算法、图像识别等多个维度进行了实战训练，那么恭喜你，实际上你已经具有数据分析相关的工作经验了。这方面我来简单帮你总结下，梳理出一个项目简历的模板。但最根本的是，你需要自己跑一遍项目代码，完整了解项目目标和解决方案。只有这样，放到简历中的时候才会比较充实。1.  **乳腺癌检测：**采用 SVM    方法，对美国威斯康星州的乳腺癌诊断数据集进行分类，最终实现一个针对乳腺癌检测的分类器：2.  **内容抓取：**通过 Python    爬虫对豆瓣电影中的电影数据和海报等信息进行抓取：3.  **邮件数据分析**：通过 PageRank    算法分析邮件中的人物关系图谱，并针对邮件数量较大的情况筛选出重要的人物，进行绘制：4.  **微博文档分类**：采用朴素贝叶斯的方法，对微博的内容进行分类，最终实现一个简单的文档分类器：5.  **电影数据集关联规则挖掘**：采用 Apriori    算法，分析电影数据集中的导演和演员信息，从而发现导演和演员之间的频繁项集及关联规则：6.  **歌词词云可视化**：动态抓取指定明星的歌曲列表，保存歌词文件，去除歌词中的常用词，并对歌词进行词云展示，分析歌曲的作词风格：7.  **信用卡违约率分析**：针对台湾某银行信用卡的数据，构建一个分析信用卡违约率的分类器。采用    Random Forest 算法，信用卡违约率识别率在 80%    左右：8.  **信用卡欺诈分析**：针对欧洲某银行信用卡交易数据，构建一个信用卡交易欺诈识别器。采用逻辑回归算法，通过数据可视化方式对混淆矩阵进行展示，统计模型的精确率，召回率和    F1 值，F1 值为    0.712，并绘制了精确率和召回率的曲线关系：9.  **比特币走势分析**：分析 2012 年 1 月 1 日到 2018 年 10 月 31    日的比特币价格数据，并采用时间序列方法，构建自回归滑动平均模型（ARMA    模型），预测未来 8 个月比特币的价格走势。预测结果表明比特币将在 8    个月内降低到 4000 美金左右，与实际比特币价格趋势吻合（实际最低降到    4000 美金以下）：
## 不一样的项目经历和体会上面我整理了 9个项目简历的示例，如果认真学习专栏，并且坚持练习的话，那么不用愁相关的项目经验。如果你希望有不一样的项目经历，那么能融入自己的项目体会和总结的话，就会更好。比如分析比特币走势这一篇文章中，我还提供了沪市指数的历史数据（从 1990 年12 月 19 日到 2019 年 2 月 28 日），你完全可以采用 ARMA模型自己跑一遍，然后整理出相关的经历。再或者，我们对毛不易歌词进行词云分析的时候，你也可以分析其他的歌手，或者某个歌手的某张专辑的词云。模型方法是相同的，但不同的数据集出来的结果是不同的。另外你也可以在项目实战中，融入自己的心得体会。比如在预测比特币走势这个项目中，我们对原始数据进行了降维，按月为粒度进行了统计，实际预测结果与按天进行统计的结果相差并不大，但是数据量降到了1/30，大大提升了效率。在这个过程中，你应该能体会到数据降维的作用。在信用卡欺诈分析这个项目中，我们观察到数据集的分类样本是不平衡的，针对这种情况，我们到底该采用哪个评价标准呢？为什么采用准确率作为评价标准会有问题？有关这方面的经验总结你也可以简单做个说明，这样不光可以证明你具备这种项目的经验，也能证明针对这类的问题，你都找到了哪些规律。总之自己的心得体会和总结能给项目经验加分不少。
## 总结在专栏的讲解过程中，很多同学都反馈过他们正在找工作，但项目经历这块是自己的软肋。我们关键要弄明白HR招人背后的逻辑，把相关的训练经验总结下来写在简历中，最后拆解专栏的实战项目。在这个过程中你需要：1.  了解每个实战项目的目标；2.  理解每个算法的原理；3.  跑一遍项目代码，将运行结果放到 GitHub 上；4.  做项目的心得总结。当你自己把这些内容整理出来的时候，你发现自己会更有信心。简历的完善只是表象，实际上最重要的是自己的能力也得到了提升，这也是通过学习专栏，我希望你能收获的价值。我在专栏里讲解了理论知识、工具方法和实战项目，希望你把专栏作为一个工具，带你走入数据科学的大门。掌握了这个工具之后，平时遇到问题的时候，你就可以用数据的视角来分析它，使用工具来做模拟，总结结果，进一步完善你的简历。![](Images/136aa20e88d2dcaf94cf030840628601.png){savepage-src="https://static001.geekbang.org/resource/image/d4/66/d48bc67969a70475a66fba58c68b3a66.png"}\我在专栏中讲解了理论知识，工具使用和实战项目，在 Python爬虫、数据可视化和数据挖掘算法这三个部分中，除了专栏中讲解到的项目，你还做过哪些项目或者练习（采用相同的算法模型用于不同的数据集也可以），欢迎你分享一下。另外，简历是最好的工作梳理，通过专栏的学习，你是否已经开始完善你的项目简历了呢，还有哪些地方是可以完善的？欢迎你在评论区与我分享一下你的心得体会，也欢迎点击"请朋友读"，把这篇文章分享给你的朋友或者同事。![](Images/8b75105190797b2e4f7be2536b6543db.png){savepage-src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"}
# 加餐丨在社交网络上刷粉刷量，技术上是如何实现的？我们都知道很多社交网络上可以刷粉，也可以刷阅读量，这已经形成了一个"产业链"，我们也经常会看到很多记者报道过这样的灰色产业链。你也许很好奇，这些技术都是怎么实现的？首先我梳理了一下整个流程，可以分成 3 个步骤。![](Images/b495de7e5509c6b7617ee8607e1b691f.png){savepage-src="https://static001.geekbang.org/resource/image/53/08/53b4ab2c38f684cb1550f75d2dd89b08.jpg"}\在这个流程里，需要有下面三个准备。**1. 多个手机号**尽管早期注册只需要邮箱就可以，但现在账号注册都是需要绑定手机号的，所以手机号是必备的。**2. 多个 IP**因为很多社交网站都会有反垃圾的措施。共用同一个 IP，一定会被封号。**3. 模拟操作**因为我们的需求是个性化的。所以在这一步，可以封装出一些基本的操作，比如关注、发布动态、转发、阅读文章等。
## 那么多手机号从哪弄？于是问题来了，从哪里弄这么多手机号？比如说 1 万个！**虚拟手机号：被歧视的号码段**很多从事相关产业的人首先想到的，便是虚拟手机号，因为虚拟手机号不限数量，其他号码段都需要绑定身份证。不过虚拟手机号有个最大的问题，就是"会被歧视"。在社交网络里，虚拟手机号注册的账号被封的概率远超其他账号，比如说以"170"开头的手机号。**阿里小号：一个看似可行的解决方案**既然虚拟手机号容易被封，那怎样才能找到既不会被封，还便宜的号码呢？阿里小号是个选择。阿里小号的价格比较亲民，5元 / 月。可以自己选择号码段，这些号码段很多都不是 170号码段的。但是阿里小号有个问题，就是需要用身份证来绑定。``{=html}**国外号码，贵但价值明显**那有没有既不会被封，又不用绑定身份证的办法呢？国外的手机号是可以的，但最大的问题就是贵，差不多5 美金一个月，相当于一个账号就要 35 元。我调查了一下，其实国外也有类似的刷量刷粉的操作，比如刷Facebook、Twitter、YouTube等。这些网站刷粉、刷量的收费更高，所以相比之下，手机号带来的成本其实不算什么。一个手机号就相当于你雇了一个工人，在雇佣的这段期间里，你需要让它的任务"充实"起来。一般的做法都是先从高价值的网站开始刷，在完成后，再来刷国内的APP。如果有足够多的刷粉刷量的任务，这个"工人"就会 7X24小时不间断地工作。这些号码各有特点，根据实际情况，不同人手里用到的号码是不同的。我总结了一下。![](Images/897a4d35349e9c11b00e60c53f9134eb.png){savepage-src="https://static001.geekbang.org/resource/image/3c/01/3c11f84acd2e49ab9ec906d919149001.jpg"}
## 如何自动切换 IP？在解决多个手机号的情况后，那下个问题就来了，如何自动切换 IP呢？这是一个自动化运营绕不开的问题。有三种方式可以选择。1.  IP 代理。2.  飞行模式。3.  小区宽带。**IP 代理：所有人都能想到，但并不靠谱的方案**IP 代理应该是很多人首先想到的解决方案，因为在编写 Python爬虫的时候，是可以使用代理机制的。网上就有很多做 IP代理的。但这里有两个认知，你需要注意。1.  IP 代理没有你想得那么便宜。以不重复的 100 万 IP 为例，单日价格在    2700 元，相当于 1 万 IP=27    元。所以你会有这样一个疑惑：那些刷网站流量的，1    万流量只需要几元的是怎么做到的？2.  免费 IP 比你想象得要好用。实际上，有很多免费 IP    代理可以使用，它们主要的问题在于数量比较少。所以在量少的情况下，IP 代理是可以使用的。在量大的情况下，IP代理就没那么好用了，因为成本太高，并不是一个靠谱的方案。**飞行模式，一个让人飞起来的 idea！**当你发现，购买 IP代理的价格比淘宝上售卖流量的还要贵的时候，你就知道他们用的根本不是 IP代理。换个思维，有没有免费的 IP呢？这里会用到手机的飞行模式，它和路由器断开重连一样完美！这是为什么呢？当我们的手机采用飞行模式后再关闭，你会发现手机的 IP发生了变化。同样，当你断开路由器后，再进行重连，IP也自动发生了变化。这个就是动态 IP。**WIFI 和 MIFI**那么问题来了，怎样写程序来控制手机呢？这里你可以使用 MIFI 设备，MIFI其实就是 Mobile WIFI 的意思。MIFI设备最大的好处，就是脱离了手机，你不需要一台手机，而只需要一台 MIFI设备和一张 SIM 卡。MIFI 设备集成了路由器和调制解调器的功能，使用的流量还是 SIM卡的流量。所以当我们断开 MIFI 设备重连的时候，就相当于自动换了IP。当然，这个过程需要定制 MIFI设备，也就是多一个网线接口，把数据传输出来，这样就可以自动进行控制了。**MIFI 可能存在的问题**MIFI可以说是个很方便的解决方案，但是依然存在一个问题，就是当流量大的时候，手机的流量费是很高的。那这样的话，就不能采用MIFI 的方式了，可以考虑使用小区宽带。小区宽带最大的好处，就是不限流量。当然除了控制 MIFI 设备外，还需要控制交换器，才能做到自动切换IP。所以在流量较小的情况下，MIFI是个好的解决方案。流量大的情况，比如要访问视频网站，小区宽带是更好的方案。在自由切换 IP 这个部分，我整理了以下的 3种方案，一般来说手机飞行适合轻度的并发访问，而重度的流量访问方式还需要采用小区宽带的方案。![](Images/e788d8135a625f4a07502bfe53d4f299.png){savepage-src="https://static001.geekbang.org/resource/image/4d/c3/4d2bfea6ed27986abdad60d5f6f507c3.jpg"}
## 如何模拟操作，是一个技术活模拟操作，就是文章开头中，我提到的流程中的最后一步。所有的流程，如果想要实现机器自动化，就需要一个利器。这里 Python最适合不过。那么该怎么做呢？首先这里需要用到 Python的几个工具。在做自动化运营的过程中，会经常使用这些工具，我简单给你介绍下。**Selenium**：用于 Web 测试的工具，支持多种浏览器和自动化测试。**lxml**：网页解析利器，支持 HTML、XML、XPath 解析，而且解析效率很高。**Scrapy**：强大的爬虫框架，提升开发效率。**PhantomJS**：基于 WebKit 的无头浏览器，无头就是没有 UI界面的意思。同时 PhantomJS 提供了 JavaScript API 接口，可以直接与 WebKit内容交互。通过它，你可以完成无界面的自动化测试、网页截屏等。通过网页截屏，就可以帮水军做结案报告。通过结案报告，就可以看到刷量的直观数据结果。![](Images/26a41a503f2dca27742ad466e6ebec6b.png){savepage-src="https://static001.geekbang.org/resource/image/bf/7f/bf13d87259a86139a1dac9e9946d477f.jpg"}通过以上的工具，我们就可以达到实时抓取，实时刷量的目的。当然这些工具只是表象，更重要的是模块化的思维。也就是如何使用这些工具，具体都做哪些事。一般来说，我们可以把自动化运营拆解成不同的模块。下图是我以微信、微博为例，整理的自动化运营所需模块的全景图，这些模块都需要编写相应的代码来实现，从而打造整个社交网络上自动化运营的机器人团队。![](Images/61634e0bf69ce7dbe1da80e3cd89cd18.png){savepage-src="https://static001.geekbang.org/resource/image/55/f1/550a8b3472305a44c9e067db869726f1.jpg"}虽然这篇文章给你讲了这个灰色地带，但我还是想强调一下，我只想通过这篇文章让你直观地体验数据思维是什么样的以及实现的方式是什么，这样才能更好地帮助你解决工作或者生活中遇到的问题。作为技术出身的从业人员，我倡导不作恶的理念。所以我不建议你去购买这么多的手机号和MIFI 设备，我希望你把重点放到如何掌握 Python中数据分析的工具上，以及慢慢培养你的数据化思维。我是一个数据分析爱好者，总是被各种问题吸引，带着好奇心，脑海中提出各种问题，然后通过思考一步一步进行解决。所以，我希望你能在实际工作中，和我一样具有数据思维，以及数据分析的解决能力，这也是我们在《数据分析实战45 讲》这个专栏里想要讨论的内容。而我也希望你能通过这个专栏获得这样的能力。如果你觉得这篇文章有帮助，欢迎点击"请朋友读"，把它分享给你的朋友或者同事。