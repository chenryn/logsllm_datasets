σ(k), let the ordered load for coflow σ(k) on port p with re-
σ(i). Furthermore, let ˆp(k) be the port with
highest ordered load for σ(k). That is
spect to σ be:
p
i ≤k d
k
i =1
ˆp(k) ← arg max
p
d
p
σ(i)
Definition 3. Let σ be an ordering of coflows. Let A(σ) be the
class of flow scheduling algorithms for which the completion
time of each coflow σ(k) is no earlier than its ordered load at
port ˆp(k) divided by the bandwidth of port ˆp(k).
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Agarwal et al.
Central Coordinator
Running BSSI
Unordered
Coflows
Ordered
Coflows
App
App
Sincronia Daemon
Sincronia Daemon
Set Priorities
Unordered
Coflows
Ordered
Coflows
Set Priorities
Unordered
Coflows
Ordered
Coflows
Transport Layer
Transport Layer
Figure 4: Sincronia end-to-end architecture. See §4.1 for de-
scription of various components.
A(σ) is indeed a large class of flow scheduling mechanisms
— the only condition is that the last bit of coflow σ(k) is sent
no earlier than the ordered load at port ˆp(k). Let OPT(A(σ))
be the optimal average coflow completion time for the set of
coflows across all flow scheduling mechanisms in A(σ).
Theorem 2. Suppose all coflows arrive at time 0 and let
σ be an ordering of coflows. Then any flow rate allocation
scheme that is work-conserving, is pre-emptive and is σ-order-
preserving achieves average coflow completion time within 2×
of OPT(A(σ)). This bound is tight.
4 SINCRONIA IMPLEMENTATION
We now provide details on the Sincronia implementation.
We start with a description of the end-to-end system (§4.1).
The remainder of the section focuses on three important
aspects of the implementation. First, the BSSI algorithm from
§3.1 assumes that all coflows arrive at time 0. In §4.2, we
discuss how Sincronia implementation incorporates the BSSI
algorithm to efficiently handle coflows arriving at arbitrary
times. Second, we showed in §3.2 that Sincronia decouples
coflow ordering from rate allocation to and scheduling of
individual flows. In §4.3, we discuss how this result enables
Sincronia to be efficiently integrated with existing datacenter
transport mechanisms, including TCP, pHost and pFabric.
Finally, we discuss how Sincronia implementation achieves
work conservation (§4.4), enables co-existence of flows and
coflows, and resolves various other practical issues (§4.5).
4.1 End-to-end system design
We have implemented Sincronia in C++ using just 3000 lines
of code. This includes a central coordinator and at each server,
a shim layer that sits between the application and the trans-
port layers (see Figure 4).
Applications, upon arrival of a coflow, inform Sincronia
daemon about the coflow (coflow ID, flows, and correspond-
ing sources, destinations, sizes, etc.); the daemon adds this
coflow to the list of “unordered coflows” (to be used for
work conservation) and then uses the above information to
register the coflow to the coordinator. The daemons also
maintain a list of “ordered coflows”, ones that have been
assigned an ordering by the coordinator (as discussed below).
When the ongoing flow finishes, the daemon picks one flow
from the currently highest ordered coflow (if one exists) or
from list of unordered coflows (if no ordered coflow exists),
assigns the flow an appropriate priority, and sends it to the
underlying transport layer. The daemon also unregisters
the finished (co)flow from the coordinator. The priorities
assigned to both ordered and unordered coflows depend on
the underlying transport mechanism and are discussed in
more depth in §4.3.
The coordinator performs the following tasks. It divides
the time into epochs. The coordinator maintains a list of
“unordered coflows”, those that have been registered but not
yet ordered (ordering is done only at the start of each epoch).
At the start of each epoch, the coordinator selects a subset
of coflows from the unordered coflow list and uses the of-
fline algorithm to order these coflows. We discuss several
strategies for deciding the epoch size and for selecting the
subset of coflows at the starting of epoch in §4.2. Once com-
puted, the coordinator removes the ordered coflows from
the unordered coflow list, and sends the “ordered coflow”
list to all the servers that have unfinished coflows; we use
several optimizations here such that the coordinator only
informs the servers of the “delta”, changes in ordered list,
rather than resending the entire ordered list. Note that each
server is oblivious to epochs maintained at the coordinator;
hence, servers are not require to be time synchronized with
the coordinator.
As discussed in §2, there is a lower bound of Ω(√
n) on
achievable approximation for average CCT for mechanisms
that do not use coordination [8]; thus, some coordination is
necessary. However, Sincronia admits much simpler coordi-
nator that existing network designs for coflows — in contrast
to existing designs that require the central coordinator to
perform per-flow rate allocation, Sincronia requires it to just
order the coflows using its BSSI algorithm.
4.2 From Offline to Online
We now discuss how Sincronia implementation incorporates
the BSSI algorithm into a system that can efficiently handle
the online case, where coflows may arrive at arbitrary times.
An obvious way to incorporate BSSI algorithm into an online
design is to use the approach taken by prior works (e.g.,
Varys [10]) — run the offline algorithm upon each coflow
arrival. However, in datacenter networks where thousands
of coflows may arrive within each second, this may lead to
high complexity (although we do use this algorithm as a
baseline in our simulations).
Sincronia: Near-Optimal Network Design for Coflows
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Sincronia avoids this high complexity approach using a
recently proposed framework [19] along with its own BSSI
algorithm from the previous section. We provide a high-level
description of the framework to keep the paper relatively
self-contained. The framework works in three steps. First,
time horizon is divided into exponentially increasing sized
epochs. At the start of each epoch, the framework runs an
approximation algorithm to select a subset of unfinished
coflows. This approximation algorithm, introduced by Garg
et. al. [14], works as follows: formulate an integer program
with a decision variable for each coflow to indicate whether
(or not) it should be assigned to complete within that epoch;
we add constraints to enforce that the total work required
for the selected subset does not exceed the amount of data
that can be transferred within the epoch, and we aim to
maximize the total weight of the coflows assigned to this
epoch. We solve the linear programming relaxation of this
integer program, and select each coflow that is at least “half-
assigned” by this optimal solution. It is easy to understand
why this process loses a factor of 8 in the approximation
guarantee. Once the subset of coflows is selected, any α-
approximate offline algorithm can be used to order coflows
arriving over time while providing (8 +α)-competitive ratio2.
Sincronia implementation of this framework uses the BSSI
algorithm (in the last step) to order coflows arriving in an
online manner; we set smallest epoch size to be 100ms, with
every subsequent epoch being 2× larger. However, Sincro-
nia makes two modifications in its implementation of the
framework. The first modification is to incorporate a work
conservation step; we describe this in more detail in §4.4. The
second modification Sincronia implementation makes in us-
ing this framework is to avoid performance degradation due
to large epoch sizes. Indeed, if epoch sizes grow arbitrarily
large, increasingly larger number of coflows arrive within an
epoch and have to wait until the starting of the next epoch
to be scheduled (despite work conservation, as discussed in
§4.4); small coflows, in particular, observe poor performance.
Sincronia thus bounds the maximum number of epochs and
once this number is reached, it “resets the time horizon”.
Since BSSI algorithm provides 4-approximation guarantees,
using the above formula, Sincronia system achieves a com-
petitive ratio of 12 for the online case.
We emphasize that exponentially-increasing sized epochs
are needed only for polynomial-time complexity of the online
algorithm and for theoretical guarantees [19]. If these were
not the goals, Sincronia could simply use suitably chosen
fixed-sizes epochs. We evaluate this in §5 and show that
Sincronia performance with exponentially-increasing sized
epochs is very similar to that with fixed-sized epochs.
2As with all online algorithms, Sincronia guarantees for the online version
are in terms of competitive ratio.
4.3 Sincronia + Existing Transport Layers
We now discuss Sincronia implementation on top of several
existing transport layer mechanisms for flows. We already
described Sincronia coordinator and daemon functionalities
in §4.1; these remain unchanged across Sincronia implemen-
tation on top of various transport mechanisms. We focus on
the only difference across implementations — assignment
of priorities to individual flows before Sincronia daemon
offloads the flows to the underlying transport mechanism.
Sincronia + TCP. If the underlying network fabric supports
infinite priorities, implementing Sincronia on top of TCP is
straightforward — each server daemon, for any given flow,
simply assigns it a priority equal to the order of the corre-
sponding coflow, sets the priority using the priority bits in
DiffServ [6], and sends the data over TCP. However, in prac-
tice, the underlying fabric may only support a fixed number
of priorities due to hardware limitations, or due to use of
some priority levels for other purposes (e.g., fault tolerance).
With finite number p of priorities, Sincronia implementa-
tion on top of TCP (with DiffServ) approximates the ideal
Sincronia performance using a simple modification: the dae-
mon sets the priority of a given flow to be the order of the
corresponding coflow if the current order of the coflow is
less than p−1, else it assigns priority p to the flow. As the list
of active coflows is updated, the priority used for a flow is
also updated accordingly. When using unordered coflows for
work conservation, the daemon also sets priority p. While
not ideal, our experimental results over real testbeds that
support 8 priority levels (§5) show that Sincronia achieves
significant improvements in average CCT even with small
number of priority levels.
Sincronia + pHost. We now discuss Sincronia implementa-
tion on top of pHost, a receiver-driven transport layer mech-
anism. This is particularly interesting because pHost handles
incast and outcast traffic patterns efficiently, precisely a use
case for coflows. We extend the pHost implementation to
support special prioritized scheduling required for Sincro-
nia implementation (at the receiver as well as at the source
and at intermediate network elements). We assume famil-
iarity with pHost design. In our implementation, the pHost
receiver sends a token for packets in flows in order of cor-
responding coflow ordering. The server daemons, among all
the received tokens, use the one for a flow in the currently
highest ordered coflow. In-network priorities are not neces-
sary (congestion is at the edge due to per-packet scheduling
and packet spraying) but can be supported using TCP style
priority assignment. Interestingly, pHost implementation
of Sincronia converges to the greedy algorithm shown in
Algorithm 2 that, in a converged state, assigns a single flow
the full outgoing access link rate at any given point of time.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Agarwal et al.
Algorithm 2 Greedy Rate Allocation Algorithm
All access links have uniform bandwidth
C = σ is the input coflow ordering
procedure GreedyFlowScheduling(σ)
while C is not empty do
for i = 1 to |C| do
for j = 1 to |Ci.flows| do
if Ingress port of Ci.flows(j) free then
if Egress port of Ci.flows(j) free then
Allocate entire BW to Ci.flows(j)
Update flow sizes and available link bandwidth
GreedyFlowScheduling(C)
return
Sincronia + pFabric. Sincronia implementation on top of
pFabric admits an even simpler design. Since pFabric already
supports infinite priority levels, we only need a minor change
in pFabric priority assignment mechanism: each flow is now
assigned a priority equal to the ordering of its coflow, rather
than the size of the flow as in original pFabric paper [4]. A
special “minimum priority level” is assigned to unordered
coflows for work conservation purposes. Since Sincronia gen-
erates a total ordering across coflows, this implementation
results in ideal Sincronia performance.
4.4 Prioritized Work Conservation
Sincronia coordinator runs the BSSI algorithm for coflow or-
dering at the starting of each epoch. Thus, coflows that arrive
in the middle of an epoch (referred to as “orphan coflows”)
may not be assigned an ordering until the starting of the
next epoch. While our flow scheduling mechanisms from
the previous section are naturally work-conserving (because
underlying transport layer mechanisms are work conserv-
ing), our preliminary implementation highlighted a potential
performance issue. Orphan coflows, since unordered, end up
fair sharing the bandwidth. For “short” orphan coflows, such
fair sharing could lead to a long tail.