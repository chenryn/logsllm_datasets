48
42
43
48
md5sum
57
2
0
1
28
57
49
49
60
uniq
28
7
0
27
24
29
24
26
29
who
2,136
0
18
50
194
1,541
17
63
1,582
TABLE V: Bugs found by 3 fuzzers in 50 CGC binaries
Fuzzers AFL Driller NEUZZ
Bugs
31
21
25
dataset comes with a set of inputs as proof of vulnerabilities.
We evaluate NEUZZ, Driller, and AFL on 50 randomly
chosen CGC binaries. As running each test binary for each
fuzzer takes 6 hours to run on CPU/GPU and our limited
GPU resources do not allow us to execute multiple instances
in parallel, we randomly picked 50 programs to keep the total
experiment time within reasonable bounds. Similar to LAVA-M,
here we also run AFL for an hour to generate the training data
and use it to train the NN. We provide the same random seed
to all three fuzzers and let them run for six hours. NEUZZ
uses the same customized LLVM pass used for the LAVA-M
dataset to instrument magic checkings in CGC binaries.
The results (Table V) show that NEUZZ uncovers 31 buggy
binaries out of 50 binaries, while AFL and Driller ﬁnd 21 and
25, respectively. The buggy binaries found by NEUZZ include
all those found by Driller and AFL. NEUZZ further found bugs
in 6 new binaries that both AFL and Driller fail to detect.
int* more_command){
...
if(cgc_strncmp(&buffer[1], "VISUALIZE",
1 int cgc_ReceiveCommand(CommandStruct* command,
2
3
4
5
6
7
8
cgc_strlen("VISUALIZE")) == 0){
command->command = VISUALIZE;
//vulnerable code
...
Listing
CROMU_00027
1:
cgc_ReceiveCommand
function
in
We analyze an example program CROMU_00027 (shown
in Listing 1). This is an ASCII content server that takes a
query from a client and serves the corresponding ASCII code.
A null-pointer dereferencing bug is triggered after a user
tries to set command as VISUALIZE. AFL failed to detect
this bug within 6-hour time budget due to its inefﬁciency at
guessing the magic string. Although Driller tries to satisfy
such complex magic string checking by concolic execution,
in this case it fails to ﬁnd an input that satisﬁes the check.
By contrast, NEUZZ can easily use the NN gradient to locate
the critical bytes in the program input that affects the magic
comparison and ﬁnd inputs that satisfy the magic check.
(cid:25)(cid:18)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:52:15 UTC from IEEE Xplore.  Restrictions apply. 
Result 1: NEUZZ found 31 previously unknown bugs
in 6 different programs that other fuzzers could not ﬁnd.
NEUZZ also outperforms the state-of-the-art fuzzers at
ﬁnding LAVA-M and CGC bugs.
RQ2. Can NEUZZ achieve higher edge coverage than
existing fuzzers?
To investigate this question, we compare the fuzzers on
24-hour ﬁxed runtime budget. This evaluation shows not only
the total number of new edges found by fuzzers but also the
speed of new edge coverage versus time.
TABLE VI: Comparing edge coverage of NEUZZ w.r.t. other
fuzzers for 24 hours runs.
Programs
NEUZZ AFL AFLFast VUzzer KleeFL AFL-laf-intel
readelf -a
nm -C
objdump -D 2,318
size
strip
libjpeg
libxml
mupdf
zlib
harfbuzz
4,942
746
2,056 1,418
257
2,262 1,236
856
3,177
94
1,022
1,596
517
370
487
374
376
6,081 3,255
1,073
1,503
263
1,924
960
651
392
371
371
4,021
12
221
307
541
478
60
16
38
15
111
968
1,614
328
1,091
869
67
n/a†
n/a
362
n/a
1,023
1,445
221
976
1,257
2
370
142
256
2,724
†indicates cases where Klee failed to run due to external dependencies
We collect the edge coverage information from AFL’s
edge coverage report. The results are summarized in Ta-
ble VI. For all 10 real-world programs, NEUZZ signiﬁcantly
outperforms other fuzzers in terms of edge coverage. As
shown in Fig 4, NEUZZ can achieve signiﬁcantly more new
edge coverage than other fuzzers within the ﬁrst hour. On
programs strip, harfbuz and readelf, NEUZZ can
achieve more than 1, 000 new edge coverage within an
hour. For programs readelf and objdump, the number
of new edge coverage from NEUZZ’s 1 hour running even
beats the numbers of new edge coverage from all other
fuzzers’ 24 hours running. This shows the superior edge
coverage ability of NEUZZ. For all 9 out of 10 programs,
NEUZZ achieves 6×,1.5×,9×,1.8×,3.7×,1.9×,10×,1.3× and
3× edge coverage than baseline AFL, respectively, and
4.2×,1.3×,7×,1.2×,2.5×,1.5×,1.5×,1.3× and 3× edge cover-
age than the second highest number among all 6 fuzzers. For the
smallest program zlib, which has less than 2k lines of code,
NEUZZ achieves similar edge coverage with other fuzzers. We
believe it reaches a saturation point when most of the possible
edges for such a small program are already discovered after 24
hours fuzzing. The signiﬁcant outperformance shows the effec-
tiveness of NEUZZ in efﬁciently locating and mutating critical
bytes using the gradient to cover new edges. NEUZZ also scales
well in large systems. In fact, for programs with more than
10K lines (e.g., readelf, harfbuzz, mupdf and libxml),
NEUZZ achieves the highest edge coverage, where the taint-
assisted fuzzer (i.e., VUzzer) and symbolic execution assisted
fuzzer (i.e., KleeFL) either perform badly or does not scale.
The gradient-guided mutation strategy allows NEUZZ
to explore diverse edges, while other evolutionary-based
fuzzers often get stuck and repetitively check the same branch
conditions. Also, the minimal execution overhead of the NN
smoothing technique helps NEUZZ to scale well for larger
programs while other advanced evolutionary fuzzers incur high
execution overhead due to the use of heavyweight program
analysis techniques like taint-tracking or symbolic execution.
Among the evolutionary fuzzers, AFLFast, uses an
optimized seed selection strategies that focuses more on rare
edges and thus achieves higher coverage than AFL on 8
programs, especially in libjpeg, size and harfbuzz.
VUzzer, on the other hand, achieves higher coverage than
AFL, AFLFast, and AFL-laf-intel within the ﬁrst hour on small
programs (e.g., zlib, nm, objdump, size and strip),
but its lead stalls quickly and eventually is surpassed by other
fuzzers. Meanwhile, VUzzer’s performance degrades on larger
programs like readelf, harfbuzz, libxml, and mupdf.
We suspect that the imprecisions introduced by VUzzer’s taint
tracker causes it to perform poorly on large programs. KleeFL
uses additional seeds generated by the symbolic execution
engine Klee to guide AFL’s exploration. Similar to VUzzer,
for small programs (nm, objdump, and strip), KleeFL
has good performance at the beginning, but its advantage
of additional seeds from Klee fade away after several hours.
Moreover, KleeFL is based on Klee that cannot scale to large
programs with complex library code, a well-known limitation
of symbolic execution. Thus, KleeFL does not have results on
programs libxml, mupdf and harfbuzz. Unlike VUzzer
and KleeFL, NEUZZ does not rely on any heavy program
analysis techniques; NEUZZ uses the gradients computed from
NNs to generate promising mutations even for larger programs.
The efﬁcient NN gradient computation process allow NEUZZ
to scale better than VUzzer and KleeFL at identifying the
critical bytes that affect different unseen program branches,
achieving signiﬁcantly more edge coverage.
AFL-laf-intel transforms complex magic number comparison
into nested byte-comparison using an LLVM pass and then runs
AFL on the transformed binaries. It achieves second-highest
new edge coverage on program strip. However, the com-
parison transformations add additional instructions to common
comparison operations and thus cause a potential edge explo-
sion issue. The edge explosion greatly increases the rate of edge
conﬂict and hurt the performance of evolutionary fuzzing. Also,
these additional instructions cause extra execution overheads.
As a result, programs like libjpeg with frequent comparison
operations suffer signiﬁcant slowdown (e.g., libjpeg), and
AFL-laf-intel struggles to trigger new edges.
Result 2: NEUZZ can achieve signiﬁcantly higher edge
coverage compared to other gray-box fuzzers (up to 4
× better than AFL, and 2.5× better than the second-best
one for 24-hour running).
(cid:25)(cid:18)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:52:15 UTC from IEEE Xplore.  Restrictions apply. 
4000
3000
2000
1000
e
g
a
r
e
v
o
c
e
g
d
E
0
e
g
a
r
e
v
o
c
e
g
d
E
2000
1500
1000
500
0
0
2
4
6
8 10 12 14 16 18 20 22 24
Time (hour)
readelf
0
2
4
6
8 10 12 14 16 18 20 22 24
Time (hour)
nm
e
g
a
r
e
v
o
c
e
g
d
E
6000
5000
4000
3000
2000
1000
0
e
g
a
r
e
v
o
c
e
g
d
E
2000
1500
1000
500
0
0
2
4
6
8 10 12 14 16 18 20 22 24
Time (hour)
harfbuzz
e
g
a
r
e
v
o
c
e
g
d
E
1000
800
600
400
200
0
e
g
a
r
e
v
o
c
e
g
d
E
2000
1500
1000
500
0
500
400
300
200
100
0
e
g
a