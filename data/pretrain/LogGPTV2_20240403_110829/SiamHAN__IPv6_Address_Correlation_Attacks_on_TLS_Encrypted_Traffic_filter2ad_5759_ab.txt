the node stays on the same IPv6 link but may change
when the node moves from one IPv6 link to another,
which is described in RFC 7217 [14] and could be used
to correlate activities within single IPv6 link.
• Temporary IID. An IPv6 interface identiﬁer varies over
time. The IID could be generated through SLAAC pri-
vacy extension [33], or DHCPv6 [32], which could only
be tracked for the temp address lifetime.
Therefore, address-based correlation attacks are usually effec-
tive on an address with a constant or stable interface identiﬁer
while unachievable on a temporary address. Correlation tech-
niques need more meta-information to overcome dynamic
address transform.
3.3 TLS Communication
TLS [36] is an encryption protocol designed to secure Inter-
net communications. Whenever a user navigates to a website
4332    30th USENIX Security Symposium
USENIX Association
(a) Node C
(b) Nodes S and SCS meta-paths
(c) Nodes F and FCF meta-paths
(d) Nodes F and FSF meta-paths
Figure 2: The building process of the knowledge graph on one IPv6 client address.
over HTTPS, the TLS encryption of the trafﬁc payload effec-
tively protects user privacy from malicious analysis. However,
before the encrypted communications, a TLS handshake is
required to exchange several messages to establish the session
of the two communicating sides, which includes considerable
available meta-information to infer activities. For instance:
• ClientHello message. The client initiates the handshake
by sending a ClientHello message to the server. The mes-
sage includes which TLS version the client supports, the
cipher suites supported, the compression methods sup-
ported, a random string, and the extension ﬁeld. Clients
may request extended functionality from servers by send-
ing data in the extensions ﬁeld, like specifying Server
Name Identiﬁer (SNI) to prevent common name mis-
match errors.
• ServerHello message. In reply to the ClientHello mes-
sage, the server sends a ServerHello message containing
a random string, extensions, the server’s chosen TLS
version, cipher suite, and compression method.
• Certiﬁcate message. The Certiﬁcate message will al-
ways immediately follow the ServerHello message when
required certiﬁcates for authentication, which conveys
the server’s certiﬁcate chain to the client. The certiﬁcate
also contains the meta-information related to the server,
such as issuer and subject.
To help readers understand this paper, we provide the no-
tions of the TLS ﬁelds related to the paper in Table 1. Based
on the meta-information proposed from the TLS communi-
cations, a user’s communication activities could be learned
due to the exposure of client’s and server’s information in
the session. However, complex user activities and consider-
able ﬁeld information render correlation attacks infeasible in
multiple contexts. Advanced trafﬁc characteristic correlation
techniques must focus on favorable information to facilitate
effective user correlation.
Table 2: The detail of nodes in the knowledge graph.
Node Type
Client node
Server node
Client
ﬁngerprint
Server
ﬁngerprint
ClientHello
ClientHello
ServerHello
Source
IPv6 header
IPv6 header
Label Node Attribute
C
S
F1
F2
F3
F4
F5
F6
F7
F8
F9
F10
F11
F12
Date statistics
Count statistics F13
Client address
Server address
Record version
Client version
Cipher suites
Compression
SNI
Record version
Server version
Cipher suite
Algorithm ID
Issuer
Subject
First connection
Flow count
Certiﬁcate
4 Design of SIAMHAN
This section introduces our IPv6 address correlation attack
system, called SIAMHAN, which is a two-step attack, includ-
ing building knowledge graphs and learning attack models.
4.1 Knowledge Graph
When chronically intercepting network trafﬁc on the victim
router or server, the adversary could collect considerable meta-
information about the client address communication, which
could be reconstructed to help identify the user. To achieve
this goal on the IPv6 network, we construct a knowledge
graph based on TLS encrypted communication for each IPv6
client address as the adversary’s background knowledge κt.
Since the user’s complex online behavior will generate di-
verse semantic data during the adversary’s wiretapping time
t, we use a heterogeneous graph [43] to model the knowledge
USENIX Association
30th USENIX Security Symposium    4333
CClient Address2001:db8::2036:213:81:573CSSSServer Address2001:db8::b05Server Address2001:db8::681b:a554Server Address2001:db8::10:53…CSSSFFFClient FingerprintsClientHello - Client versionClient FingerprintsClientHello - CompressionClient FingerprintsClientHello - Cipher suites…FClient FingerprintsClientHello - Record versionCSSSFFFFFFFFFFFFServer FingerprintsServer FingerprintsServer Fingerprints……FFFFFFFServerHello - Cipher suiteServerHello - Server versionServerHello - Record versionClientHello - SNICertiﬁcate - Algorithm IDCertiﬁcate - IssuerCertiﬁcate - SubjectDate statistics - First connectionCount statistics - Flow countCount statistics - Flow countDate statistics - First connection ClientHello - SNICertiﬁcate - SubjectCertiﬁcate - IssuerCertiﬁcate - Algorithm IDgraph. It contains multi-type nodes and neighbor relationships
to describe the user activities behind the address accurately.
Figure 2 shows the building process of the knowledge graph.
Node and Node Attribute. Based on the adversary’s back-
ground knowledge κt, the knowledge graph of each IPv6
client address contains three types of nodes, including a client
node C, server nodes S, and ﬁngerprint nodes F, which are
shown in Table 2. Each graph node keeps an attribute to
represent the meaning of the node:
• Client node C. The client node models an IPv6 client
address that is monitored within time t, whose attribute
is the 32-digit hexadecimal IPv6 client address. Each
knowledge graph contains only one client node to denote
the meta-information related to it.
• Server node S. The server nodes are all IPv6 server
addresses that have established TLS communications
with the client address, whose attribute is the 32-digit
hexadecimal IPv6 server address.
• Fingerprint node F. The ﬁngerprint nodes include
client ﬁngerprints and server ﬁngerprints, whose at-
tributes are ﬁeld values of the ClientHello, ServerHello,
Certiﬁcate messages, and statistical characteristics in the
TLS connection established with the client address. Fol-
lowing the work of [1, 7, 30], we intend to select the
commonly used, distinguishable TLS ﬁelds for model
learning. In addition, the statistical characteristics pro-
vide a more detailed description of the user behavior.
First connection refers to the date of the ﬁrst time
the client accesses the server. Flow count records the
number of the ﬂow generated during the communication.
Because the attributes of these nodes integrate address and
trafﬁc characteristic meta-information, the adversary could
learn user activities based on the knowledge of address struc-
ture and trafﬁc characteristic correlation.
Neighbor Relationship. In a heterogeneous graph, nodes
can be connected via different semantic paths, which are
called meta-paths [44]. To denote the neighbor relationship
of different semantics, we propose three types of meta-paths
to connect three types of nodes in the knowledge graph, in-
cluding SCS meta-path, FCF meta-path, and FSF meta-path:
• SCS meta-path. The SCS meta-path connects the client
node C and multiple server nodes S, which represents
the TLS communication activities between the client and
multiple servers.
• FCF meta-path. The FCF meta-path connects the
client node C and multiple client ﬁngerprint nodes F,
which represents the browser parameters that may be
used behind the client.
• FSF meta-path. The FSF meta-path connects each
server node S and multiple server ﬁngerprint nodes F
related to the server, which denotes the service charac-
teristics behind each server.
The FCF meta-path and the FSF meta-path can be ef-
fectively exploited to learn unique client and service repre-
sentations. The SCS meta-path exposes the communication
activities between the user’s client and each service, thus fa-
cilitating correlation attacks reliable.
It is worth noting that, since the user may use multiple
browsers, the same type of client ﬁngerprint may contain
multiple nodes, e.g., two client ﬁngerprint nodes with differ-
ent Cipher suites attributes are included in one knowledge
graph. In addition, since a TLS connection may not contain all
three types of messages, a server node could lack some server
ﬁngerprints, thus leaving a smaller count of the FSF-based
neighbors.
4.2 Model Architecture
SIAMHAN is a deep learning framework shown in Figure 3,
which exploits the Heterogeneous Graph Attention Network-
based Siamese Network architecture to learn the address corre-
lation. The architecture could be divided into four objectives:
node-level attention, semantic-level attention, graph-level at-
tention, and metric learning with Siamese Network.
After constructing a knowledge graph for each client ad-
dress, the adversary could select any two knowledge graphs
to model their association and infer whether they are bound
to the same user. Each knowledge graph could extract an ad-
jacency matrix A and feature matrix X to be processed by the
GNNs, where the adjacency matrix A includes the neighbor
relationships of each node and the feature matrix X is the
attribute value of all nodes. A GNN method iteratively up-
dates a node’s features via aggregating its neighbors’ features.
SIAMHAN uses self-attention [48] with multiple levels to
update a pair of feature matrix Xi and Xj according to the adja-
cency matrix Ai and A j and obtain their network embeddings
to measure the distance of the two addresses for correlation.
Node-level Attention. For each pair of input knowledge
graphs, the node-level attention ﬁrst learns the weights of
meta-path-based neighbors and aggregates them to get the
semantic-speciﬁc node embedding. Given NΦ
u denotes the
meta-path Φ based neighbors of node u (include itself) and
node v ∈ NΦ
u , the importance of meta-path-based node pair
(cid:104)u,v(cid:105) can be formulated as follows:
eΦ
uv = σ(aT
uv = softmaxv(eΦ
αΦ
uv) =
Φ · [hu||hv]),
exp(eΦ
uv)
u exp(eΦ
uk)
∑k∈NΦ
,
(2)
where hu and hv are the features of node u and v, aΦ is the
node-level attention parametrize matrix for meta-path Φ, σ
denotes the activation function, and || denotes the concate-
nate operation. Since the attack model inputs pairwise user
4334    30th USENIX Security Symposium
USENIX Association
Figure 3: The overall architecture of SIAMHAN. SIAMHAN inputs pairwise client addresses’ knowledge graphs to learn their
correlation. The multi-level attention mechanism helps match the similar features between the two heterogeneous graphs to learn
their graph embeddings. The Siamese Network ﬁnally metric the distance of the embeddings to judge the correlation relationship.
meta-information, a larger weight coefﬁcient αΦ
uv indicates
matching similar neighbor data in a single meta-path-based
semantic in the two knowledge graph, which contributes to
the correlation task. For instance, the two client nodes in the
pairwise graph link to the same server nodes based on ΦSCS.
Then, the meta-path-based embedding of node u can be
obtained by aggregating all neighbor attributes with the corre-
sponding coefﬁcients as follows:
(cid:16)
(cid:13)(cid:13)(cid:13)K
zΦ
u =
σ
k=1
uv · hv
αΦ
∑
v∈NΦ
u
(cid:17)
,
(3)
where zΦ
u is the learned embedding of node u for the meta-
path Φ, K is the head number using the multi-head attention
mechanism [48]. Among the three types of meta-path in our
work, FCF and FSF promote learning the unique client and
server service embeddings based on the client and server
ﬁngerprints, while SCS mines the user activity representation
using the communication relationship.
Semantic-level Attention. After feeding node features
into node-level attention with the meta-path set M =
{ΦFCF ,ΦFSF ,ΦSCS}, the semantic-level attention is required
to learn the importance of three types of semantic-speciﬁc
embeddings and fuse them as a comprehensive node embed-
ding. The importance of meta-path Φi based embedding is
shown as follows:
wΦi =
1
|V| ∑
u∈V
pT · tanh(Ws · zΦi
u + bs),
βΦi = softmaxi(wΦi) =
exp(wΦi)
∑Φi∈M exp(wΦi)
,
(4)
where Ws is the weight matrix, bs is the bias vector, and p
is the semantic-level attention parametrize matrix. V is the
node-set of the input knowledge graph. Since we average the
importance of all the semantic-speciﬁc node embedding, the
weight coefﬁcient βΦi could be interpreted as the contribution
of the meta-path Φi for the correlation task.
With the learned weights of each semantic-speciﬁc embed-
ding, the comprehensive embedding su of node u could be:
su = ∑
Φi∈M
βΦi · zΦi
u .
(5)
The comprehensive embeddings are the ﬁnal representations
of nodes learned by SIAMHAN, which aggregates multiple
semantic characteristics. For instance, the client node sC ﬁ-
nally obtains the embedding with the semantics that using
speciﬁc browsers to access online services by integrating
semantic-speciﬁc embeddings zΦFCF
and zΦSCS
.
Graph-level Attention. To gain the graph embedding for
distance metric learning, graph-level attention is proposed to
aggregate the ﬁnal embeddings of all nodes in the knowledge
graph. The importance of node u could be obtained as follow:
C
C
USENIX Association
30th USENIX Security Symposium    4335
CSFFFCSFFFSFFFSemantic-level attentionGraph-level attentionNode-level attentionFCF AttentionFSF AttentionSCS AttentionNode-level attentionFCF AttentionFSF AttentionSCS AttentionBackground Knowledge Kt Graph ConstructionSiamese Heterogeneous Graph Attention NetworkAddress CorrelationDistance metricFeature matrix XiXjFeature matrix Adjacency matrix  Aj Adjacency matrix  Ai Shared parametersPaddinggu = qT · tanh(Wg · su + bg),
exp(gu)
∑u∈V (gu)
γu = softmaxu(gu) =
,
(6)
where Wg is the weight matrix, bg is the bias vector, and q
is the graph-level attention parametrize matrix. Unlike αΦ
uv
with local attention on neighbors, a larger weight coefﬁcient
γu denotes globally matching similar nodes in the two knowl-
edge graphs. Therefore, the graph embedding Z could be
formulated as follows:
Z = ∑
u∈V
γu · su
(7)
Metric Learning with Siamese Network. The goal of the
Siamese Network architecture in our work is to metric the
distance D between the knowledge graph of two arbitrary IPv6
client addresses, which could be used to judge the correlation
relationship R through a threshold η:
D = ||Z1 − Z2||2,
(8)
(cid:40)1 D < η
0 D ≥ η ,
R =
where Z1 and Z2 are the ﬁnal graph embeddings of the two
input knowledge graphs. R = 1 means the two client addresses
come from the same user, otherwise R = 0.
To train the attack model for IPv6 address correlation,
SIAMHAN requires sets of positive samples and negative
samples to learn the correlation function. The positive sam-
ples are the pairwise knowledge graphs of IPv6 client ad-
dresses bound to the same user. The negative samples are
arbitrary pairs of knowledge graphs that come from two dif-
ferent IPv6 users. With both negative and positive samples in
hand, SIAMHAN could then be optimized by minimizing the
contrastive loss L: