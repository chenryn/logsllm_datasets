archive_mode = on  
archive_command = '/bin/date'   
polar_datadir = 'file-dio:///var/polardb/backup/polar_shared_data'  
port = 5436  
polar_hostid = 200 " >> ./postgresql.conf   
echo "polar_enable_switch_wal_in_backup = on  
archive_mode = on  
archive_command = '/bin/date'   
polar_datadir = 'file-dio:///var/polardb/backup/polar_shared_data'  
port = 5436  
polar_hostid = 200 " >> ./postgresql.auto.conf   
echo "recovery_target_timeline = 'latest'  
restore_command = 'cp /var/polardb/wal_archive/%f %p' " > ./recovery.conf   
```  
5\.6、启动并进行恢复  
```  
pg_ctl start -D /var/polardb/backup/primary  
```  
5\.7、观察最后修改的数据是否正常恢复到新的PolarDB集群  
```  
postgres@docker-desktop:/var/polardb/backup/primary$ psql -p 5436  
psql (11.9)  
Type "help" for help.  
postgres=# select * from t;  
 id | info  |             ts               
----+-------+----------------------------  
  1 | test  | 2024-01-25 16:17:29.400825  
```
### 6、创建 PolarDB 实例的容灾实例  
容灾实例包含计算节点和存储2个部分, 从主实例同步WAL的完整数据进行回放. PolarDB的流复制协议会自动识别当前是不同存储实例的容灾节点还是同一存储实例下的RO节点, 如果是不同存储下的容灾节点, 流复制会发送所有的WAL信息, 如果是同一存储下的 RO节点则只发送WAL meta信息.   
6\.1、准备容灾机器, 本例子就在同一个docker容器中进行模拟测试, 所以创建一个新的实例目录即可.  
```  
cd /var/polardb    
mkdir disast    
```  
6\.2、使用`polar_basebackup`备份主实例和存储  
```  
# 通过RW (5433)进行备份    
# 本地数据写入 /var/polardb/disast/primary    
# 共享数据写入 /var/polardb/disast/polar_shared_data    
polar_basebackup -h 127.0.0.1 -p 5433 -U postgres -R -D /var/polardb/disast/primary --polardata=/var/polardb/disast/polar_shared_data  
```  
6\.3、修改容灾实例配置  
```  
cd /var/polardb/disast/primary    
echo "polar_enable_switch_wal_in_backup = on    
archive_mode = on    
archive_command = '/bin/date'     
polar_datadir = 'file-dio:///var/polardb/disast/polar_shared_data'    
port = 1921    
polar_hostid = 100 " >> ./postgresql.conf     
echo "polar_enable_switch_wal_in_backup = on    
archive_mode = on    
archive_command = '/bin/date'     
polar_datadir = 'file-dio:///var/polardb/disast/polar_shared_data'    
port = 1921    
polar_hostid = 100 " >> ./postgresql.auto.conf     
echo "recovery_target_timeline = 'latest'    
standby_mode = 'on'  
primary_conninfo = 'host=localhost port=5433 user=postgres dbname=postgres application_name=diast_primary' " > ./recovery.conf     
```  
6\.4、启动容灾实例  
```  
pg_ctl start -D /var/polardb/disast/primary    
```  
6\.5、在主实例的读写节点对数据进行修改  
```  
psql -p 5433  
create table tbl_diast(id int primary key, info text, ts timestamp);  
insert into tbl_diast select generate_series(1,10), md5(random()::text), clock_timestamp();  
```  
6\.6、观察容灾节点同步数据是否正常  
```  
psql -p 1921  
postgres=# select count(*) from tbl_diast;  
 count   
-------  
    10  
(1 row)  
```
使用lsof可以看到容灾实例打开了primary和polar_shared_data数据文件
```
sudo apt-get install -y lsof
lsof|grep disast
...
postgres  588              postgres    7u      REG              0,176     32768   27919 /var/polardb/disast/polar_shared_data/base/13123/2703
postgres  584              postgres   13w      REG              0,176         0   28920 /var/polardb/disast/primary/pg_log/postgresql-2024-01-26_202711_slow.log
```
### 7、排查 PolarDB CPU负载高     
在 PolarDB for PostgreSQL 的使用过程中，可能会出现 CPU 使用率异常升高甚至达到满载的情况。本文将介绍造成这种情况的常见原因和排查方法，以及相应的解决方案。  
7\.1、业务量上涨  
当 CPU 使用率上升时，最有可能的情况是业务量的上涨导致数据库使用的计算资源增多。所以首先需要排查目前数据库的活跃连接数是否比平时高很多。如果数据库配备了监控系统，那么活跃连接数的变化情况可以通过图表的形式观察到；否则可以直接连接到数据库，执行如下 SQL 来获取当前活跃连接数：  
```  
SELECT COUNT(*) FROM pg_stat_activity WHERE state NOT LIKE 'idle';  
```  
`pg_stat_activity` 是 PostgreSQL 的内置系统视图，该视图返回的每一行都是一个正在运行中的 PostgreSQL 进程，`state` 列表示进程当前的状态。该列可能的取值为：  
- `active`：进程正在执行查询  
- `idle`：进程空闲，正在等待新的客户端命令  
- `idle in transaction`：进程处于事务中，但目前暂未执行查询  
- `idle in transaction (aborted)`：进程处于事务中，且有一条语句发生过错误  
- `fastpath function call`：进程正在执行一个 `fast-path` 函数  
- `disabled`：进程的状态采集功能被关闭  
上述 SQL 能够查询到所有非空闲状态的进程数，即可能占用 CPU 的活跃连接数。如果活跃连接数较平时更多，则 CPU 使用率的上升是符合预期的。  
7\.2、慢查询  
如果 CPU 使用率上升，而活跃连接数的变化范围处在正常范围内，那么有可能出现了较多性能较差的慢查询。这些慢查询可能在很长一段时间里占用了较多的 CPU，导致 CPU 使用率上升。PostgreSQL 提供了慢查询日志的功能，执行时间高于 `log_min_duration_statement` 的 SQL 将会被记录到慢查询日志中。然而当 CPU 占用率接近满载时，将会导致整个系统的停滞，所有 SQL 的执行可能都会慢下来，所以慢查询日志中记录的信息可能非常多，并不容易排查。  
7\.2\.1、定位执行时间较长的慢查询  
[`pg_stat_statements`](https://www.postgresql.org/docs/current/pgstatstatements.html) 插件能够记录数据库服务器上所有 SQL 语句在优化和执行阶段的统计信息。由于该插件需要使用共享内存，因此插件名需要被配置在 `shared_preload_libraries` 参数中。  
如果没有在当前数据库中创建过 `pg_stat_statements` 插件的话，首先需要创建这个插件。该过程将会注册好插件提供的函数及视图：  
```  
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;  
```  
该插件和数据库系统本身都会不断累积统计信息。为了排查 CPU 异常升高后这段时间内的问题，需要把数据库和插件中留存的统计信息做一次清空，然后开始收集从当前时刻开始的统计信息：  
-- 清空当前数据库的统计信息  
SELECT pg_stat_reset();  
-- 清空 pg_stat_statements 插件截止目前收集的统计信息  
SELECT pg_stat_statements_reset();  
接下来需要等待一段时间（1-2 分钟），使数据库和插件充分采集这段时间内的统计信息。  
统计信息收集完毕后，参考使用如下 SQL 查询执行时间最长的 5 条 SQL：  
```  
-- = PostgreSQL 13  
SELECT * FROM pg_stat_statements ORDER BY total_exec_time DESC LIMIT 5;  
```  
7\.2\.2、定位读取 Buffer 数量较多的慢查询  
当一张表缺少索引，而对该表的查询基本上都是点查时，数据库将不得不使用全表扫描，并在内存中进行过滤条件的判断，处理掉大量的无效记录，导致 CPU 使用率大幅提升。利用 pg_stat_statements 插件的统计信息，参考如下 SQL，可以列出截止目前读取 Buffer 数量最多的 5 条 SQL：  
```  
SELECT * FROM pg_stat_statements  
ORDER BY shared_blks_hit + shared_blks_read DESC  
LIMIT 5;  
```  
借助 PostgreSQL 内置系统视图 [`pg_stat_user_tables`](https://www.postgresql.org/docs/15/monitoring-stats.html#MONITORING-PG-STAT-ALL-TABLES-VIEW) 中的统计信息，也可以统计出使用全表扫描的次数最多的表。参考如下 SQL，可以获取具备一定规模数据量（元组约为 10 万个）且使用全表扫描获取到的元组数量最多的 5 张表：  
```  
SELECT * FROM pg_stat_user_tables  
WHERE n_live_tup > 100000 AND seq_scan > 0  
ORDER BY seq_tup_read DESC  
LIMIT 5;  
```  
7\.2\.3、定位长时间执行不结束的慢查询  
通过系统内置视图 `pg_stat_activity`，可以查询出长时间执行不结束的 SQL，这些 SQL 有极大可能造成 CPU 使用率过高。参考以下 SQL 获取查询执行时间最长，且目前还未退出的 5 条 SQL：  
```  
SELECT  
    *,  
    extract(epoch FROM (NOW() - xact_start)) AS xact_stay,  
    extract(epoch FROM (NOW() - query_start)) AS query_stay  
FROM pg_stat_activity  
WHERE state NOT LIKE 'idle%'  
ORDER BY query_stay DESC  
LIMIT 5;  
```  
结合前一步中排查到的 使用全表扫描最多的表，参考如下 SQL 获取 在该表上 执行时间超过一定阈值（比如 10s）的慢查询：  
```  
SELECT * FROM pg_stat_activity  
WHERE  
    state NOT LIKE 'idle%' AND  
    query ILIKE '%表名%' AND  
    NOW() - query_start > interval '10s';  
```  
7\.2\.4、解决方法与优化思路  
对于异常占用 CPU 较高的 SQL，如果仅有个别非预期 SQL，则可以通过给后端进程发送信号的方式，先让 SQL 执行中断，使 CPU 使用率恢复正常。参考如下 SQL，以慢查询执行所使用的进程 pid（`pg_stat_activity` 视图的 `pid` 列）作为参数，中止相应的进程的执行：  
```  
SELECT pg_cancel_backend(pid);  
SELECT pg_terminate_backend(pid);  
```  
如果执行较慢的 SQL 是业务上必要的 SQL，那么需要对它进行调优。  
首先可以对 SQL 涉及到的表进行采样，更新其统计信息，使优化器能够产生更加准确的执行计划。采样需要占用一定的 CPU，最好在业务低谷期运行：  
```  
ANALYZE 表名;  
```  
对于全表扫描较多的表，可以在常用的过滤列上创建索引，以尽量使用索引扫描，减少全表扫描在内存中过滤不符合条件的记录所造成的 CPU 浪费。  
7\.3、更多的DBA常用SQL参考[digoal github](../202005/20200509_02.md)  
更多优化思路参考[digoal github](../201704/20170424_06.md)    
更多维护信息参考[PolarDB 开源官方网站](https://apsaradb.github.io/PolarDB-for-PostgreSQL/zh/).    
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")