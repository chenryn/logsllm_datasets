a pair of threads for each thread in source code; system calls
are only executed by one thread. PLR [62] targets unmodiﬁed
single-threaded binary applications by creating replicas at the
process level with Pin [63], transparently forking replicas.
Both assume a reliable OS.
Romain [64] is an OS service based on the Fiasco.OC
microkernel. It replicates user-level processes assuming the
kernel, device drivers and the replication framework to operate
correctly. Ulbrich et al. [65] hardens crtical user-mode code
with CoRed (combined redundancy), which combines TMR,
data encoding, and control-ﬂow encoding, to eliminate the
single point of failure in software-based redundancy; these
techniques for protecting user code complement our aims.
Rex [66] proposes an execute-agree-follow model to efﬁciently
replicate multithreaded applications on multicore servers. The
model allows a primary replica to handle requests concur-
rently; non-deterministic decisions are recorded in traces. After
all replicas agree on the traces by executing a consensus
protocol, secondary replicas replay the traces concurrently to
reach the same state as the primary.
Bressoud and Schneider [67] design protocols for coordi-
nating non-deterministic event delivery for a hypervisor run-
ning on HP’s PA-RISC architecture, enabling the hypervisor
to manage a primary-backup virtual machine pair for fault
tolerance. The approach relies on the PA-RISC processor’s
ability to deterministically deliver interrupts and on correct
operation of the hypervisor.
Remus [68] aims for high availability by replicating the
protected and backup virtual machines on a pair of physical
hosts using the live-migration capability of the Xen virtual
machine monitor to support ﬁne-grained checkpoints, and
relying on correct operation of Xen. The fault-tolerant feature
of VMware vSphere 4.0 [69] runs primary and backup virtual
machines in virtual lockstep on different physical machines,
where the hypervisor, assumed to be reliable, manages the
virtual CPU of the backup VM to execute the same instructions
committed by the primary VM. A logging channel is used to
transmit input data and nondeterministic events captured by
the primary VM to the backup VM, which applies the data
and replays the events deterministically. These fault-tolerant
systems based on virtual machines assume that the kernel or
hypervisor is not affected by hardware faults.
FT-Linux [70] is the only other system in the literature (al-
though predated by LC-RCoE [23]) that replicates virtually the
complete software stack without hardware support. It imple-
ments a full-stack, primary-backup, fault-tolerant Linux sys-
tem on a single machine by partitioning hardware resources,
instantiating two Linux kernels, and replicating OS services
as well as selected applications. Non-deterministic events are
logged on the primary and replayed on the secondary. Failure
detection is achieved by interchanging heartbeat messages
between the Linux kernels and also relying on hardware error-
detection features. The replicas managed by RCoE sychronise
before they observe non-deterministic events, removing the
latency of recording and replaying non-deterministic events
and thus extending the SoR.
VIII. CONCLUSIONS AND FUTURE WORK
Our results show that it is feasible to provide protection
against random hardware faults, by redundantly executing a
complete software stack on commodity multicore processors.
Without non-standard hardware support we can replicate ev-
erything except low-level device access. Speciﬁcally, replicat-
ing applications is transparent: we do not have to modify
user-mode code other than drivers and for porting to seL4.
This paper introduces CC-RCoE to overcome some limitations
of LC-RCoE, signiﬁcantly extending the range of supported
applications.
Our evaluation shows that while performance cost are
noticeable, we can trade them against the latency of error
detection, by choosing voting frequency, and deciding on how
198
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:08 UTC from IEEE Xplore.  Restrictions apply. 
much state to accumulate into the state signatures which the
kernel replicas use for voting.
Compared to other software approaches, which only protect
selected applications and rely on the kernel not being affected
by faults, we dramatically extend the sphere of replication to
include practically the complete system.
Current RCoE can only replicate a logical single-core
system. With increasing core counts in commodity processors,
it is now feasible (and desirable) to replicate multicore systems
on a single processor. Furthermore we found that a signiﬁcant
portion of errors is detected by barrier timeouts (Section V-C),
recovering from those would be beneﬁcial. Finally we would
like to investigate how we can provide real-time guarantees
with RCoE.
ACKNOWLEDGEMENT
The authors would like to thank the shepherd, Sameh
Elnikety, and anonymous reviewers for their feedback and
suggestions.
AVAILABILITY
Source code for our RCoE implementations, as well as eval-
uation rigs and complete raw data sets are available for down-
load from https://trustworthy.systems/projects/TS/cots.pml.
REFERENCES
[1] D. Bernick, B. Bruckert, P. Del Vigna, D. Garcia, R. Jardine, J. Klecka,
and J. Smullen, “NonStop advanced architecture,” in Proceedings of the
35th International Conference on Dependable Systems and Networks
(DSN), Washington, DC, US, 2005, pp. 12–21.
[2] J. Bartlett, W. Bartlett, R. Carr, D. Garcia, J. Gray, R. Horst,
R. Jardine, D. Lenoski, and D. McGuire. (1990) Fault tolerance in
Tandem computer systems. [Online]. Available: http://www.hpl.hp.com/
techreports/tandem/TR-90.5.pdf
[3] L. Spainhower and T. A. Gregg, “IBM S/390 parallel enterprise server
G5 fault tolerance: A historical perspective,” IBM Journal of Research
and Development, vol. 43, no. 5, pp. 863–873, Sep. 1999.
[4] W. Bartlett and L. Spainhower, “Commercial fault tolerance: A tale of
two systems,” IEEE Transactions on Dependable and Secure Computing,
vol. 1, pp. 87–96, Jan. 2004.
[5] M. N. Sweeting, “Modern small satellites—changing the economics of
space,” Proceedings of the IEEE, vol. 106, pp. 343–361, Mar. 2018.
[6] J. F. Ziegler and W. A. Lanford, “Effect of cosmic rays on computer
memories,” Science, vol. 206, no. 4420, pp. 776–788, 1979. [Online].
Available: http://science.sciencemag.org/content/206/4420/776
[7] R. Baumann, “Technology scaling trends and accelerated testing for
soft errors in commercial silicon devices,” in 9th IEEE On-Line Testing
Symposium, Jul. 2003, pp. 4–.
[8] ——, “Radiation-induced soft errors in advanced semiconductor tech-
nologies,” IEEE Transactions on Devices and Materials Reliability,
vol. 5, no. 3, pp. 305–316, Sep. 2005.
[9] N. Seifert, P. Slankard, M. Kirsch, B. Narasimham, V. Zia, C. Brookre-
son, A. Vo, S. Mitra, B. Gill, and J. Maiz, “Radiation-induced soft error
rates of advanced CMOS bulk devices,” in Proceedings of the 44th IEEE
International Reliability Physics Symposium, San Jose, CA, US, Mar.
2006, pp. 217–225.
[10] V. Ferlet-Cavrois, L. W. Massengill, and P. Gouker, “Single event
transients in digital CMOS – a review,” IEEE Transactions on Nuclear
Science, vol. 60, no. 3, pp. 1767–1790, Jun. 2013.
[11] G. Klein, J. Andronick, K. Elphinstone, T. Murray, T. Sewell, R. Kolan-
ski, and G. Heiser, “Comprehensive formal veriﬁcation of an OS
microkernel,” ACM Transactions on Computer Systems, vol. 32, no. 1,
pp. 2:1–2:70, Feb. 2014.
[12] H. Chen, D. Ziegler, T. Chajed, A. Chlipala, M. F. Kaashoek, and
N. Zeldovich, “Using Crash Hoare logic for certifying the FSCQ
ﬁle system,” in ACM Symposium on Operating Systems Principles,
Monterey, CA, Oct. 2015, pp. 18–37.
[13] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang,
and B. Zill, “Ironclad apps: End-to-end security via automated
full-system veriﬁcation,” in USENIX Symposium on Operating Systems
Design and Implementation, Broomﬁeld, CO, US, Oct. 2014, pp. 165–
[Online]. Available: https://www.usenix.org/conference/osdi14/
181.
technical-sessions/presentation/hawblitzel
[14] S. Chen, J. Xu, Z. Kalbarczyk, R. K. Iyer, and K. Whisnant, “Mod-
eling and evaluating the security threats of transient errors in ﬁrewall
software,” Performance Evaluation, vol. 56, no. 1–4, pp. 53–72, Mar.
2004.
[15] J. Xu, S. Chen, Z. Kalbarczyk, and R. K. Iyer, “An experimental study
of security vulnerabilities caused by errors,” in Proceedings of
the
International Conference on Dependable Systems and Networks (DSN),
2001, pp. 421–430.
[16] S. Govindavajhala and A. W. Appel, “Using memory errors to attack a
virtual machine,” in IEEE Symposium on Security and Privacy, 2003,
pp. 154–165.
[17] X. Li, K. Shen, M. C. Huang, and L. Chu, “A memory soft error
the 2007
measurement on production systems,” in Proceedings of
USENIX Annual Technical Conference, Santa Clara, CA, US, 2007.
[18] S. Z. Shazli, M. Abdul-Aziz, M. B. Tahoori, and D. R. Kaeli, “A ﬁeld
analysis of system-level effects of soft errors occurring in micropro-
cessors used in information systems,” in 2008 IEEE International Test
Conference, Oct. 2008, pp. 1–10.
[19] B. Schroeder, E. Pinheiro, and W.-D. Weber, “DRAM errors in the wild:
A large-scale ﬁeld study,” in Proceedings of the ACM Conference on
Measurement and Modeling of Computer Systems, Seattle, WA, US,
2009, pp. 193–204.
[20] E. B. Nightingale, J. R. Douceur, and V. Orgovan, “Cycles, cells
and platters: An empirical analysis of hardware failures on a million
consumer PCs,” in Proceedings of the 6th EuroSys Conference, Salzburg,
AT, Apr. 2011.
[21] V. Sridharan, J. Stearley, N. DeBardeleben, S. Blanchard, and S. Gu-
rumurthi, “Feng shui of supercomputer memory: Positional effects
in DRAM and SRAM faults,” in Proceedings of
the International
Conference on High Performance Computing, Networking, Storage and
Analysis, Denver, CO, US, 2013.
[22] V. Sridharan, N. DeBardeleben, S. Blanchard, K. B. Ferreira, J. Stearley,
J. Shalf, and S. Gurumurthi, “Memory errors in modern systems: The
good, the bad, and the ugly,” in Proceedings of the 20th International
Conference on Architectural Support for Programming Languages and
Operating Systems, Istanbul, TR, Mar. 2015, pp. 297–310.
[23] Y. Shen and K. Elphinstone, “Microkernel mechanisms for improving
the trustworthiness of commodity hardware,” in European Dependable
Computing Conference, Paris, France, Sep. 2015, p. 12.
[24] S. K. Reinhardt and S. S. Mukherjee, “Transient fault detection via
simultaneous multithreading,” in Proceedings of the 27th International
Symposium on Computer Architecture, Jun. 2000, pp. 25–36.
[25] T. C. May and M. H. Woods, “Alpha-particle-induced soft errors in
dynamic memories,” IEEE Transactions on Electron Devices, vol. 26,
no. 1, pp. 2–9, 1979.
[26] K. P. Rodbell, D. F. Heidel, H. H. K. Tang, M. S. Gordon, P. Oldiges, and
C. E. Murray, “Low-energy proton-induced single-event-upsets in 65 nm
node, silicon-on-insulator, latches and memory cells,” IEEE Transactions
on Nuclear Science, vol. 54, no. 6, pp. 2474–2479, Dec. 2007.
[27] B. D. Sierawski, M. H. Mendenhall, R. A. Reed, M. A. Clemens,
R. A. Weller, R. D. Schrimpf, E. W. Blackmore, M. Trinczek, B. Hitti,
J. A. Pellish, R. C. Baumann, S.-J. Wen, R. Wong, and N. Tam,
“Muon-induced single event upsets in deep-submicron technology,”
IEEE Transactions on Nuclear Science, vol. 57, no. 6, pp. 3273–3278,
Dec. 2010.
[28] M. P. King, R. A. Reed, R. A. Weller, M. H. Mendenhall, R. D.
Schrimpf, B. D. Sierawski, A. L. Sternberg, B. Narasimham, J. K. Wang,
E. Pitta, B. Bartz, D. Reed, C. Monzel, R. C. Baumann, X. Deng, J. A.
Pellish, M. D. Berg, C. M. Seidleck, E. C. Auden, S. L. Weeden-Wright,
N. J. Gaspard, C. X. Zhang, and D. M. Fleetwood, “Electron-induced
single-event upsets in static random access memory,” IEEE Transactions
on Nuclear Science, vol. 60, no. 6, pp. 4122–4129, Dec 2013.
[29] NEC. (2011, Mar.) Fault tolerant server white paper. [Online]. Avail-
able: http://www.nec.com/en/global/prod/express/collateral/whitepaper/
ft WhitePaper E.pdf
199
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:08 UTC from IEEE Xplore.  Restrictions apply. 
[30] C. M. Fuchs, T. P. Stefanov, N. M. Murillo, and A. Plaat, “Bringing
fault-tolerant Gigahertz-computing to space: A multi-stage software-side
fault-tolerance approach for miniaturized spacecraft,” in 2017 IEEE 26th
Asian Test Symposium (ATS), Nov. 2017.
[31] BAE.
(2018) Radiation-hardened processors products.
[Online].
https://www.baesystems.com/en/our-company/our-
Available:
businesses/electronic-systems/product-sites/space-products-and-
processing/processors
[32] D. D. Corporation.
computer
[Online]. Available: http://www.ddc-web.com/Products/
for
Microelectronics/images/documents/SCS750 rev8 r6.pdf
SCS750
(2018)
space.
single
board
[33] F. B. Schneider, “Implementing fault-tolerant services using the state
machine approach: A tutorial,” ACM Computing Surveys, vol. 22, no. 4,
pp. 299–319, Dec. 1990.
[34] J. M. Mellor-Crummey and T. J. LeBlanc, “A software instruction
counter,” in Proceedings of the 3rd International Conference on Archi-
tectural Support for Programming Languages and Operating Systems,
1989, pp. 78–86.
[35] J. G. Fletcher, “An arithmetic checksum for serial transmissions,” IEEE
Transactions on Communications, vol. 30, no. 1, pp. 247–252, Jan. 1982.
[36] V. Weaver, D. Terpstra, and S. Moore, “Non-determinism and overcount
on modern hardware performance counter implementations,” in IEEE
International Symposium on Performance Analysis of Systems and
Software, Apr. 2013.
[37] Intel 64 and IA-32 Architectures Software Developer’s Manual Vol-
Intel Corp., 2016, https://
ume 3: System Programming Guide,
software.intel.com/en-us/articles/intel-sdm.
[38] G. W. Dunlap, S. T. King, S. Cinar, M. A. Basrai, and P. M. Chen,
“Revirt: Enabling intrusion analysis through virtual-machine logging and
replay,” in Proceedings of the 5th USENIX Symposium on Operating
Systems Design and Implementation, Boston, MA, US, 2002.
[39] J. H. Slye and E. N. Elnozahy, “Supporting nondeterministic execution
the 26th International
in fault-tolerant systems,” in Proceedings of
Symposium on Fault-Tolerant Computing, Jun. 1996, pp. 250–259.
[40] Y. Shen, “Microkernel mechanisms for improving the trustworthiness of
commodity hardware,” Ph.D. dissertation, UNSW, Mar. 2019.
[41] i.MX 6Dual/6Quad Applications Processor Reference Manual,
NXP, 2015, http://www.nxp.com/assets/documents/data/en/reference-
manuals/IMX6DQRM.pdf.
[42] R. P. Weicker, “Dhrystone benchmark: Rationale for version 2 and
measurement rules,” SIGPLAN Notices, vol. 23, no. 8, pp. 49–62, Aug.
1988.
[43] R. Painter, “C converted Whetstone double precision benchmark,” http:
//www.netlib.org/benchmark/whetstone.c, 1998.
[44] Buildroot, “Buildroot,” 2018. [Online]. Available: https://buildroot.org
[45] S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta, “The
SPLASH-2 programs: Characterization and methodological considera-
tions,” in Proceedings of the 22nd International Symposium on Computer
Architecture. S. Margherita Ligure, IT: ACM, 1995, pp. 24–36.
[46] RedisLabs. (2009) Redis. [Online]. Available: https://redis.io
[47] A. Dunkels, “Minimal TCP/IP implementation with proxy support,”
SICS, Tech. Rep. T2001-20, Feb. 2001, http://www.sics.se/∼adam/
thesis.pdf.
[48] B. F. Cooper, A. Silberstein, E. Tam, R. Ramakrishnan, and R. Sears,
“Benchmarking cloud serving systems with YCSB,” in ACM Symposium
on Cloud Computing.
Indianapolis, IN, US: ACM, Jun. 2010, pp. 143–
154.
[49] BusyBox, “BusyBox: The Swiss army knife of embedded Linux,” https:
//busybox.net/, 2017.
[50] R. Rivest, “The MD5 message-digest algorithm,” Internet Requests for
Comments, Internet Engineering Task Force, RFC 1654, Apr. 1992.
[Online]. Available: https://tools.ietf.org/html/rfc1321
[51] G. Memik, M. H. Chowdhury, A. Mallik, and Y. I. Ismail, “Engineering
over-clocking: reliability-performance trade-offs for high-performance
register ﬁles,” in Proceedings of the 35th International Conference on
Dependable Systems and Networks (DSN), Jun. 2005, pp. 770–779.
[52] BAE Systems.
PowerPC
microprocessor. [Online]. Available: https://www.baesystems.com/en-
us/download-en-us/20161103152954/1434555668211.pdf
radiation-hardened
(2016) Rad750®
[53] R. W. Berger, D. Bayles, R. Brown, S. Doyle, A. Kazemzadeh,
K. Knowles, D. Moser, J. Rodgers, B. Saari, D. Stanley, and B. Grant,
“The RAD750™ - a radiation hardened PowerPC™ processor for high
performance spaceborne applications,” in 2001 IEEE Aerospace Con-
ference Proceedings (Cat. No.01TH8542), vol. 5, Mar. 2001, pp. 2263–
2272.
[54] ARM.
(2009)
line]. Available:
//www.arm.com:80/ﬁles/pdf/ARMCortexA-9Processors.pdf
The
[On-
https://web.archive.org/web/20120522214159/http:
ARM Cortex-A9
processors.
[55] (2011) SABRE Lite hardware user manual. [Online]. Available: https:
//boundarydevices.com/SABRE Lite Hardware Manual rev11.pdf
[56] R. Ginosar, “Survey of processors for space,” in Proceedings of DASIA
2012, data systems in aerospace, May 2012.
[57] BD-SL-i.MX6
development
board.
[Online]. Available:
https:
//boundarydevices.com/product/sabre-lite-imx6-sbc/
[58] G. A. Reis, J. Chang, N. Vachharajani, R. Rangan, and D. I. August,
“SWIFT: Software implemented fault tolerance,” in Proceedings of the
3rd IEEE Symposium on Code Generation and Optimization, 2005, pp.
243–254.
[59] D. Kuvaiskii, R. Faqeh, P. Bhatotia, P. Felber, and C. Fetzer, “HAFT:
Hardware-assisted fault tolerance,” in Proceedings of the 11th EuroSys
Conference, London, UK, Apr. 2016.
[60] S. Biggs, D. Lee, and G. Heiser, “The jury is in: Monolithic OS design
is ﬂawed,” in Asia-Paciﬁc Workshop on Systems (APSys). Korea: ACM
SIGOPS, Aug. 2018, Conference Paper - Refereed.
[61] C. Wang, H. S. Kim, Y. Wu, and V. Ying, “Compiler-managed software-
based redundant multi-threading for transient fault detection,” in Pro-
ceedings of the 5th International Symposium on Code Generation and
Optimization, 2007, pp. 244–258.
[62] A. Shye, J. Blomstedt, T. Moseley, V. J. Reddi, and D. A. Connors,
“PLR: A software approach to transient fault tolerance for multicore ar-
chitectures,” IEEE Transactions on Dependable and Secure Computing,
vol. 6, no. 2, pp. 135–148, Apr. 2009.
[63] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,
S. Wallace, V. J. Reddi, and K. Hazelwood, “Pin: Building customized
program analysis tools with dynamic instrumentation,” in Proceedings of
the 2005 ACM SIGPLAN Conference on Programming Language Design
and Implementation, Jun. 2005, pp. 190–200.
[64] B. D¨obel, H. H¨artig, and M. Engel, “Operating system support for
redundant multithreading,” in Proceedings of
the 12th International
Conference on Embedded Software, Tampere, SF, Oct. 2012, pp. 83–
92.
[65] P. Ulbrich, M. Hoffmann, R. Kapitza, D. Lohmann, W. Schr¨oder-
Preikschat, and R. Schmid, “Eliminating single points of failure in
software-based redundancy,” in Ninth European Dependable Computing
Conference, May 2012, pp. 49–60.
[66] Z. Guo, C. Hong, M. Yang, D. Zhou, L. Zhou, and L. Zhuang, “Rex:
the 9th
the speed of multi-core,” in Proceedings of
Replication at
EuroSys Conference, Amsterdam, NL, Jan. 2014.
[67] T. C. Bressoud and F. B. Schneider, “Hypervisor-based fault tolerance,”
ACM Transactions on Computer Systems, vol. 14, pp. 80–107, 1996.
[68] B. Cully, G. Lefebvre, D. Meyer, M. Feeley, N. Hutchinson, and
A. Warﬁeld, “Remus: High availability via asynchronous virtual machine
replication,” in Proceedings of the 5th Symposium on Networked Systems
Design and Implementation (NSDI), San Francisco, CA, US, 2008.
[69] D. J. Scales, M. Nelson, and G. Venkitachalam, “The design of a
practical system for fault-tolerant virtual machines,” ACM Operating
Systems Review, vol. 44, no. 4, pp. 30–39, Dec. 2010.
[70] G. Losa, A. Barbalace, Y. Wen, M. Sadini, H.-R. Chuang, and B. Ravin-
dran, “Transparent fault-tolerance using intra-machine full-software-
stack replication on commodity multicore hardware,” in Proceedings
of the 37th IEEE International Conference on Distributed Computing
Systems, Jun. 2017, pp. 1521–1531.
200
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:08 UTC from IEEE Xplore.  Restrictions apply.