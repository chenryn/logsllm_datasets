### C. Safety Specification

To evaluate the effectiveness of these techniques, we developed partial behavioral specifications aimed at ensuring system safety. We utilized six safety rules that assessed a combination of system robustness and functionality.

Since the feature under test is a third-party code module designed primarily as a placeholder for early system integration, no formal specification was available. Ideally, we would have derived monitoring rules from a comprehensive system specification, but this was not possible with the systems we had to test. Instead, we created a set of specification rules based on "expert" elicited common sense—properties that an experienced engineer in the automotive domain would expect to hold. These rules were developed through discussions with the system's engineers and by reviewing existing system metrics and related documentation.

While it would be preferable to derive rules directly from system documentation, this is not always feasible in industry. In such cases, the usefulness of the monitoring results heavily depends on the expertise of the engineers and the quality of the rules they choose. Although expert-derived rules may not provide a clear notion of monitoring coverage, they can be tailored to meet the direct needs of the experts. For example, while the rules we checked in this work are not exhaustive, they address high-priority issues (likely leading to vehicle collisions) for a production-quality feature.

The six rules we checked against the robustness testing traces were:

1. **Rule #0:**
   - If the `ServiceACC` signal is `true`, then `ACCEnabled` must be `false`.
   - This is a simple consistency check to ensure the feature does not attempt to control the vehicle when it knows something is wrong.

2. **Rule #1:**
   - If the actual vehicle headway time is below 1.0s, it must be recovered to greater than 1.0s within 5s elapsed time.
   - This rule is derived from an existing headway metric for another similar system.

3. **Rule #2:**
   - If `TargetRange` is less than half the desired headway, then `RequestedTorque` should not be increasing.
   - This checks for the feature trying to increase speed when it is already too close to the target vehicle.

4. **Rule #3:**
   - If `Velocity` is greater than `ACCSetSpeed` and `RequestedTorque` is still less than 0 in the next timestep, then the vehicle should not attempt to increase speed when already above the set speed.
   - This avoids tripping on control oscillations by only checking after there are no active requests.

5. **Rule #4:**
   - If `Velocity` is greater than `ACCSetSpeed`, then `RequestedTorque` must not be increasing at some point within 400ms.
   - Similar to Rule #3, if the vehicle velocity is increasing while above the set speed, it should start slowing down (or at least hold speed) within 400ms.

6. **Rule #5:**
   - If `BrakeRequested` is `true`, then `RequestedDecel` must be less than or equal to 0.
   - This checks if the value of a requested deceleration is indeed a deceleration (negative).

7. **Rule #6:**
   - If `VehicleAhead` is `true` and `TargetRange` is less than 1, then `TorqueRequest` must be `false` or `RequestedTorque` must be less than 0.
   - This checks for near collisions, assuming the feature should not request an increase in speed when the target vehicle is extremely close.

Because these rules were selected without knowledge of the internal control algorithms or design parameters, some may be too strict. This approach is likely common when applying runtime monitoring to real-world systems, which often have incomplete specifications and opaque internal operations. Our approach was to adopt these rules and relax them when false positives and uninteresting violations were found. We believe this is a reasonable method for employing runtime monitors in practice.

The issue of whether the data required to implement the monitor would be observable was straightforward, as we could create rules based on the system state available on the CAN bus. Observability would be more challenging when deriving rules from system requirements that include properties not externally observable. We discuss this further in Section V-D.

### IV. Testing Results

For each of the eight target signals, we conducted three tests: one Ballista-style injection, one bit flip test with one, two, and four bit flips injected, and one random value injection. The random and Ballista tests included eight different injection values per test, and the bit flip tests included four injections for each bit flip size (with all injections held for 20s). We also ran eight tests of 20 injection values on multiple target signals simultaneously (e.g., `TargetRange`, `VehAhead`, and `TargetRelVel` at the same time). Testing time was limited by the physical time required to run tests on real automotive hardware setups. Statistical analysis of robustness testing techniques was not a goal of this work. The number of tests was sufficient to demonstrate that monitoring detected problems under robustness fault injection and indicated a lack of problems (to the degree possible given available data) in non-faulted operation.

The robustness testing identified many specification violations, summarized in Table I. An "S" represents a rule satisfied by the given trace, while a "V" represents a violated rule. The `mBallista`, `mRandom`, and `mBitFlip` entries are tests where more than one message was targeted at once. "Range+" injected `TargetRange`, `TargetRelVel`, and `VehAhead`. "Range+Set" also included `SetSpeed`, and "All" was all 9 FSRACC inputs. Six out of the seven rules were detected as violated during testing (all except Rule #0). Many of the violations could be caused and detected by multiple test runs (i.e., different signals being targeted or different types of injections to the same signal).

All three types of robustness testing found similar robustness problems in the system under test. This is not an unreasonable outcome, as all three fault classes easily exercised out-of-range faults that caused most of the identified violations.

A major cause of problems was the lack of input checking in the feature. The `Velocity`, `TargetRange`, `TargetRelVel`, and `ACCSetSpeed` messages all have direct and strong effects on the control output but are neither bounds checked (for exceptional inputs) nor consistency checked against each other or other inputs. This makes them vulnerable to bad input values causing the control algorithm to command an unsafe output. For example, an exceptional `TargetRange` value when following a target causes the ACC feature to command the vehicle to accelerate into (and through, because the simulator doesn’t check collisions) the target vehicle.

#### Table I: Fault Injection Results

| Specification Rule | Target Signal | Velocity | TargetRange | TargetRelVel | ACCSetSpeed | ThrotPos | AccelPedPos | BrakePedPos | SelHeadway | Range+ | All |
|--------------------|---------------|----------|-------------|--------------|-------------|----------|-------------|-------------|------------|--------|-----|
| 0                  | S             | S        | S           | S            | S           | S        | S           | S           | S          | S      | S   |
| 1                  | V             | S        | V           | V            | S           | S        | S           | S           | S          | V      | V   |
| 2                  | S             | V        | S           | S            | S           | S        | S           | S           | S          | S      | S   |
| 3                  | V             | S        | S           | V            | S           | S        | S           | S           | S          | V      | V   |
| 4                  | S             | V        | S           | S            | S           | S        | S           | S           | S          | S      | S   |
| 5                  | S             | S        | S           | S            | S           | S        | S           | S           | S          | S      | S   |
| 6                  | S             | V        | S           | S            | S           | S        | S           | S           | S          | S      | S   |

- **Injection Types:**
  - Random
  - Ballista
  - Bit Flips (1, 2, 4 bits)
  - mBallista
  - mRandom (Range+, All, Range+Set)
  - mBitFlip (1, 2, 4 bits)

- **Results Summary:**
  - Many violations were detected across different injection types.
  - Most violations were caused by out-of-range faults.
  - Lack of input checking in the feature was a significant issue.