round(sum(power) / 4 / 1000, 2) AS kWh
FROM readings
GROUP BY ROLLUP (year, system_id)
ORDER BY year NULLS FIRST, system_id NULLS FIRST;
If we want to see the totals by system in all years this is quite possible, too. Instead of
falling back from ROLLUP to GROUP BY GROUPING SETS and manually adding, you can
use GROUP BY CUBE. GROUP BY CUBE will not produce subgroups but actual combinations
(2^n grouping sets). In our example (year, system_id), (year), (system) and ():
Listing 4.14 Using GROUP BY CUBE
SELECT year(read_on) AS year,
system_id,
count(*),
round(sum(power) / 4 / 1000, 2) AS kWh
FROM readings
GROUP BY CUBE (year, system_id)
ORDER BY year NULLS FIRST, system_id NULLS FIRST;
produces now:
© Manning Publications Co. To comment go to liveBook
80
┌──────┬───────────┬──────────────┬───────────┐
│ year │ system_id │ count_star() │ kWh │
├──────┼───────────┼──────────────┼───────────┤
│ │ │ 151879 │ 401723.22 │
│ │ 10 │ 47750 │ 2226.48 │
│ │ 34 │ 52057 │ 306775.25 │
│ │ 1200 │ 52072 │ 92721.48 │
│ 2019 │ │ 103621 │ 269303.39 │
│ 2019 │ 10 │ 33544 │ 1549.34 │
│ 2019 │ 34 │ 35040 │ 205741.9 │
│ 2019 │ 1200 │ 35037 │ 62012.15 │
│ 2020 │ │ 48258 │ 132419.83 │
│ 2020 │ 10 │ 14206 │ 677.14 │
│ 2020 │ 34 │ 17017 │ 101033.35 │
│ 2020 │ 1200 │ 17035 │ 30709.34 │
└──────┴───────────┴──────────────┴───────────┘
We have now a complete overview of our power production readings, in a single,
compact query instead of several queries. All the additional drill-downs that we added on
the way can be expressed with grouping sets. The minimum and maximum values have
only been omitted to keep the listing readable.
4.5 Window functions
Windows and functions applied over windows are an essential part of modern SQL and
analytics. Window functions in general let you look at other rows. Normally, an SQL
function can only see the current row at a time, unless you’re aggregating. In that case
however you reduce the number of rows.
Unlike a regular aggregate function, the use of a window function does not cause rows
to become grouped into a single output row—the rows retain their separate identities. If
you want to peek at other rows, you would use a window function. A window is
introduced by the OVER() clause, following the function you want to apply to the data
inside that window. The window itself is the definition of the rows that are worked on,
and you can think about it as a window that moves along a defined order with a defined
size of rows over your dataset. Windowing works by breaking a relation up into
independent partitions, optionally ordering those partitions, and then computing a new
column for each row as a function of the nearby values.
For looking at all rows, you can use an empty window OVER (). If you want to look at
all rows that have the same value matching another field, use a partition for that field.
And last but not least, if you want to look at nearby rows, you can use a frame.
© Manning Publications Co. To comment go to liveBook
81
The size of a window is not equal to the size of a partition, both can be defined
independently. Eventually, the contents of a window are fed to a function to compute new
values. While there are a couple of dedicated functions that work only in the context of
windows, all regular aggregate functions might be used as window functions.
This allows use cases such as
Ranking
Computing independent aggregates per window
Computing running totals per window
Computing changes by accessing preceding or following rows via lag or
lead
Let’s have a look at a concrete example. Imagine you want to retrieve the system and
every time at which the top 3 amounts of power were produced at a quarter-hour. One
naive approach would be ordering the results by power produced and limit to 3: SELECT
* FROM readings ORDER BY power DESC LIMIT 3;.
┌───────────┬─────────────────────┬───────────────┐
│ system_id │ read_on │ power │
│ int32 │ timestamp │ decimal(10,3) │
├───────────┼─────────────────────┼───────────────┤
│ 34 │ 2019-05-08 12:15:00 │ 133900.000 │
│ 34 │ 2019-05-23 10:00:00 │ 133900.000 │
│ 34 │ 2019-05-23 11:30:00 │ 133900.000 │
└───────────┴─────────────────────┴───────────────┘
While the above results present readings for system 34 at different dates, you notice
that they have the same value in the power column. This might be good enough but is
not necessarily what we have been asked for. In regard to the raw value of power
produced, it is only the top one ranking, not all readings for the top 3 power values. For
computing a proper top 3, we will use the window function dense_rank(). This function
computes the rank for a row without skipping ranks for equal rankings. dense_rank
returns the rank of the current row without gaps. That means that after 5 rows having
the rank 1, the next rank will be 2, not 6. If you need the latter, you would use rank
instead.
© Manning Publications Co. To comment go to liveBook
82
Listing 4.15 A proper top-n query
WITH ranked_readings AS (
SELECT *,
dense_rank()
OVER (ORDER BY power DESC) AS rnk -- #1
FROM readings
)
SELECT *
FROM ranked_readings
WHERE rnk <= 3;
#1 Here the window is opened over one row each, ordered by the amount of power in descending order
The result looks very different now, with 3 different, decreasing values for power as
shown in figure 4.1.
Figure 4.1 The most simple window possible over the power readings
We will revisit the statement above when we learn about the QUALIFY clause in section
Section 46.2, avoiding the somewhat odd condition in the WHERE clause that filters on the
rank.
The ORDER clause as part of the window definition inside the OVER() clause is optional
and unlike the ORDER BY clause at the end of a statement, it does not sort the query
result. When used as part of the OVER() clause, ORDER BY defines in which order window
functions are executed. If ORDER BY is omitted, the window function is executed in an
arbitrary order. In our example above it would make no sense to omit it, as an
unordered, dense rank would always be one. We will see an example in the next section
where we can safely omit ORDER BY.
© Manning Publications Co. To comment go to liveBook
83
4.5.1 Defining partitions
The ranked power values above are better, but they are not yet particularly helpful, as
the systems have production values that are orders of magnitudes different. Computing
ranks without differentiating the systems might not be what are after. What we actually
need in this case is having the top 3 readings per system, each system making up its
own partition of the data. Partitioning breaks the relation up into independent, unrelated
pieces in which the window function is applied. If we don’t define how a partition is made
up by using the PARTITION BY clause the entire relation is treated as a single partition.
Window functions cannot access values outside the partition containing the row they are
being evaluated at.
Requesting the top n measurements per system would be a partitioning task. For the
sake of readability of the results we requested only the top-two power-production values
per system.
Listing 4.16 Applying a partition to a window
WITH ranked_readings AS (
SELECT *,
dense_rank()
OVER ( -- #1
PARTITION BY system_id -- #2
ORDER BY power DESC
) AS rnk
FROM readings
)
SELECT * FROM ranked_readings WHERE rnk <= 2
ORDER BY system_id, rnk ASC;
#1 Starting the definition of the moving window
#2 Defining a partition: the window
Look closely at how the number of ranks repeat now in the result in figure 4.2. They
have now been computed individually inside the respective partitions which makes a
pretty different statement about the dataset.
© Manning Publications Co. To comment go to liveBook
84
Figure 4.2 Partitioning the data before applying a window
We see ranks 1 and 2 for all systems, sy stem 34 has 5 times a top production of
133900W and the second place twice. System 1200 has only one first place, but two
seconds. The window was partitioned by the systems and then ordered by the value of
power produced.
Of course ranking tasks are not the only things that can be applied within partitions.
Aggregate functions like avg, sum, max and min are other great candidates to be used in
a windowing context. The difference of using aggregates within a window context is the
fact that they don’t change the number of rows being produced. Let’s say you want to
select both the production on each system each day and in an additional column, the
average overall production of system. You might think of using GROUP BY ROLLUP and
you would not be wrong. That grouping set would however be quite big (GROUP BY
ROLLUP (system_id, day, kwh)) and not produce the average value in an additional
column, but produce additional rows. The value that you would be looking for (the
overall production per system) would be found in the rows that have a value for the
system and no value for the day.
One way to avoid dealing with additional rows would be a self-join, in which you select
the desired aggregate grouping by a key to join the same table again. While it does
produce the results we want, it will be hard to read and does most likely not perform well
as the whole table would be scanned twice. Using avg in a partitioned window context is
much easier to read and will perform well. The aggregate, in this case avg(kWh), is
computed over the window that follows, it does not change the number of rows and will
be present in each row. It will be computed for every system as defined by the partition:
© Manning Publications Co. To comment go to liveBook
85
SELECT *,
avg(kWh) -- #1
OVER (
PARTITION BY system_id
) AS average_per_system
FROM v_power_per_day;
#1 Computing an aggregate over a partition
And you will find the requested value in an additional column:
┌───────────┬────────────┬────────┬────────────────────┐
│ system_id │ day │ kWh │ average_per_system │
│ int32 │ date │ double │ double │
├───────────┼────────────┼────────┼────────────────────┤
│ 10 │ 2019-01-01 │ 2.19 │ 4.444051896207586 │
│ 10 │ 2019-01-04 │ 5.37 │ 4.444051896207586 │
│ · │ · │ · │ · │
│ · │ · │ · │ · │
│ · │ · │ · │ · │
│ 1200 │ 2019-07-25 │ 232.37 │ 170.75771639042347 │
│ 1200 │ 2019-04-29 │ 210.97 │ 170.75771639042347 │
├───────────┴────────────┴────────┴────────────────────┤
│ 1587 rows (4 shown) 4 columns │
└──────────────────────────────────────────────────────┘
Note that we omitted the ORDER BY inside the window definition, as it is irrelevant for the
average value in which order values are fed to the aggregate.
As a rule of the thumb you probably want to use a window function every time you
consider writing a self-join like the one above for adding aggregates to your query
without changing the row count.
4.5.2 Framing
Top-N queries are useful, for example, if you happen to have a streaming service and
want to present the Top-N charts. A more interesting question in our example is this:
"What is the moving 7-day average of energy produced system-wide?" To answer this
question we must
Aggregate the readings per 15-minutes interval into days (grouping and
summing)
Partition by day and systems
Create frames of 7 days
© Manning Publications Co. To comment go to liveBook
86
This is where framing comes into play. Framing specifies a set of rows relative to each
row where the function is evaluated. The distance from the current row is given as an
expression either preceding or following the current row. This distance can either be
specified as an integral number of rows or as a range delta expression from the value of
the ordering expression.
For the purpose of readability and to keep the following examples focused on the
window definitions, we will use the view v_power_per_day defined in chapter 3, that
returns the amount of energy produced in kWh per system and day. We could equally
express v_power_per_day as a CTE.
The following statement computes the average power over a window per system that
moves along the days and is 7 days wide (3 days before, the actual day and 3 days
ahead). The statement utilizes all options for defining a window.
Listing 4.17 Using a range partition for applying a window-function
SELECT system_id,
day,
kWh,
avg(kWh) OVER (
PARTITION BY system_id -- #1
ORDER BY day ASC -- #2
RANGE BETWEEN INTERVAL 3 Days PRECEDING -- #3
AND INTERVAL 3 Days FOLLOWING
) AS "kWh 7-day moving average"
FROM v_power_per_day
ORDER BY system_id, day;
#1 The window should move over partitions defined by the system id
#2 Ordered by day
#3 With a size of 7 days in total
The result will have as many rows as there are full days in the source readings, so we
can only show a subset as an example. Figure 4.3 demonstrates the size of the window
and how rows are included.
© Manning Publications Co. To comment go to liveBook
87
Figure 4.3 The result of framing a window
4.5.3 Named windows
Window definitions can be pretty complex as we have just learned while discussing
windows with ranges. They can include the definition of the partition, the order and the
actual range of a window. Sometimes you are interested in more than just one
aggregate over a given window. It would be a tedious task, repeating the window
definition over and over again.
For our domain—measuring power production from photovoltaic systems—we could
use quantiles to create a report that essentially takes in both the seasons and the
weather by computing the quantiles over a 7-day-window per month. Sometimes a
broad monthly average might be enough, but a chart would represent only a relatively
smooth curve changing with the months. The fluctuation of the amount of power
produced is higher throughout the changing weather in a week. Outliers and runaway
values would be better caught and represented by quantiles. The result can easily be
used to create a moving box-and-whisker plot for example.
© Manning Publications Co. To comment go to liveBook
88
We need three aggregates (min, max, and quantiles) for caching outliers and
computing the quantiles, and we don’t want to define the window each time. We basically
take the definition from listing 4.17 and add the month of the reading to the partition.
Otherwise, the window definition is the same. We move the definition after the FROM
clause and name it seven_days. It can be referenced from as many aggregates than as
necessary:
Listing 4.18 Using a named window with a complex order and partition
SELECT system_id,
day,
min(kWh) OVER seven_days AS "7-day min", -- #1
quantile(kWh, [0.25, 0.5, 0.75]) -- #2
OVER seven_days AS "kWh 7-day quartile",
max(kWh) OVER seven_days AS "7-day max",
FROM v_power_per_day
WINDOW -- #3
seven_days AS (
PARTITION BY system_id, month(day)
ORDER BY day ASC
RANGE BETWEEN INTERVAL 3 Days PRECEDING
AND INTERVAL 3 Days FOLLOWING
)
ORDER BY system_id, day;
#1 Referencing the window defined after the FROM clause
#2 The quantile function takes in the value for which the quantiles should be computed and a list of the desired quantiles
#3 The window clause has to be specified after the FROM clause and the definition of window itself follows inline windows
The result now showcases a structured column type, "kWh 7-day quartile":
© Manning Publications Co. To comment go to liveBook
89
┌──────────┬────────────┬───────────┬──────────────────────────┬──────────┐
│system_id │ day │ 7-day min │ kWh 7-day quartile │ 7-day max│