（6）改变表文件格式和组织
ALTER TABLE table_name SET FILEFORMAT file_format
ALTER TABLE table_name CLUSTERED BY（col_name, col_name，……）
[SORTED BY（col_name，……）]INTO num_buckets BUCKETS
这个命令修改了表的物理存储属性。
注意 这些命令只能修改Hive的元数据，不能重组或格式化现有的数据。用户应该确定实际数据的分布符合元数据的定义。
3.表分区操作语句
Hive在进行数据查询的时候一般会对整个表进行扫描，当表很大时将会消耗很多时间。有时候只需要对表中比较关心的一部分数据进行扫描，因此Hive引入了分区（Partition）的概念。
Hive表分区不同于一般分布式系统中常见的范围分区、哈希分区、一致性分区等概念。Hive的分区相对比较简单，是在Hive的表结构下根据分区的字段设置将数据按目录进行存放。相当于简单的索引功能。
Hive表分区需要在表创建的时候指定模式才能使用。它的字段指定的是虚拟的列，在实际的表中并不存在。在Hive表分区的模式下可以指定多级的结构，相当于对目录进行了嵌套。表模式在创建完成之后使用之前还需要通过ALTER TABLE语句添加具体的分区目录才能使用。
Hive表分区的命令主要包括创建分区、增加分区和删除分区。其中创建分区已经在CREATE语句中进行介绍，下面介绍一下为Hive表增加分区和删除分区命令。
（1）增加分区
ALTER TABLE table_name ADD partition_spec[LOCATION'location1']partition_spec[
LOCATION'location2']……
partition_spec：
：PARTITION（partition_col=partition_col_value, partition_col=partiton_col_
value，……）
用户可以用ALTER TABLE ADD PARTITION来对表增加分区。当分区名是字符串时加引号，例如：
ALTER TABLE page_view ADD
PARTITION（dt='2010-08-08'，country='us'）
location'/path/to/us/part080808'
PARTITION（dt='2010-08-09'，country='us'）
location'/path/to/us/part080809'；
（2）删除分区
ALTER TABLE table_name DROP
partition_spec, partition_spec，……
用户可以用ALTER TABLE DROP PARTITION来删除分区，分区的元数据和数据将被一并删除，例如：
ALTER TABLE page_view
DROP PARTITION（dt='2010-08-08'，country='us'）；
下面我们通过一组例子对分区命令及相关知识进行讲解。
假设我们有一组电影评分数据
[1]
 ，该数据包含以下字段：用户ID、电影ID、电影评分、影片放映城市、影片观看时间。首先，我们使用Hive命令行创建电影评分表，如代码清单11-1所示。
代码清单11-1 创建电影评分表u1_data
create table u1_data（
userid int，
movieid int，
rating int，
city string，
viewTime string）
row format delimited
fields terminated by'\t'
stored as textfile；
该表为普通用户表，字段之间通过制表符“\t”进行分割。通过Hadoop命令可以查看该表的目录结构如下所示：
hadoop fs-ls/user/hive/warehouse/u1_data；
Found 1 items
-rw-r--r--1 hadoop supergroup 2609206 2012-05-17 01：27/user/hive/warehouse/
u1_data/u.data.new
可以看到u1_data标下并没有分区。
下面我们创建带有一个分区的用户观影数据表，如代码清单11-2所示。
代码清单11-2 创建电影评分表u2_data：
create table u2_data（
userid int，
movieid int，
rating int，
city string，
viewTime string）
PARTITIONED BY（dt string）
row format delimited
fields terminated by'\t'
stored as textfile；
在该表中指定了单个表分区模式，即“dt string”，在表刚刚创建的时候我们可以查看该表的目录结构，发现其并没有通过dt对表结构进行分区，如下所示：
hadoop fs-ls/user/hive/warehouse/u2_data；
Found 1 items
drwxr-xr-x-hadoop supergroup 0 2012-05-17 01：33/user/hive/warehouse/u2_data/
下面我们使用该模式对表指定具体分区，如下所示：
alter table u2_data add partition（dt='20110801'）；
此时，无论是否加载数据，该表根目录下将存在dt=20110801分区，如下所示：
hadoop fs-ls/user/hive/warehouse/u2_data；
Found 1 items
drwxr-xr-x-hadoop supergroup 0 2012-05-17 01：33/user/hive/warehouse/u2_data/dt=20110801
这里有两点需要注意：
1）当没有声明表模式的时候不能为表指定具体的分区。若为表u2_data指定city分区，将提示以下错误：
hive＞alter table u2_data add partition（dt='20110901'，city='北京'）；
FAILED：Error in metadata：table is partitioned but partition spec is not specified
or does not fully match table partitioning：{dt=20110901，city=北京}
FAILED：Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask
2）分区名不能与表属性名重复，如下所示：
create table u2_data（
userid int，
movieid int，
rating int，
city string，
viewTime string）
PARTITIONED BY（city string）
row format delimited
fields terminated by'\t'
stored as textfile；
FAILED：Error in semantic analysis：Column repeated in partitioning columns
另外，还可以为表创建多个分区，相当于多级索引的功能。以电影评分表为例，我们创建dt string和city string两级分区，如代码清单11-3所示。
代码清单11-3 创建电影评分表u3_data：
create table u3_data（
userid int，
movieid int，
rating int）
PARTITIONED BY（dt string, city string）
row format delimited
fields terminated by'\t'
stored as textfile；
下面，我们使用模式指定一个具体的分区并查看HDFS目录，如下所示：
alter table u3_data add partition（dt='20110801'，city='北京'）；
hadoop fs-ls/user/hive/warehouse/u3_data/dt=20110801；
Found 1 items
drwxr-xr-x-hadoop supergroup 0 2012-05-17 19：27/user/hive/warehouse/
u3_data/dt=20110801/city=北京
对于数据加载操作我们将在11.3.2节数据操作（DML）中进行详细介绍，这里不再赘述。
4.删除表
DROP TABLE table_name
DROP TABLE用于删除表的元数据和数据。如果配置了Trash，那么会将数据删除到Trash/Current目录，元数据将完全丢失。当删除EXTERNAL定义的表时，表中的数据不会从文件系统中删除。
5.创建/删除视图
目前，只有Hive 0.6之后的版本才支持视图。
（1）创建表视图
CREATE VIEW[IF NOT EXISTS]view_name[（column_name[COMMENT column_comment]，……）]
[COMMENT view_comment]
AS SELECT……
CREATE VIEW，以指定的名称创建一个表视图。如果表或视图的名字已经存在，则报错，也可以使用IF NOT EXISTS忽略这个错误。
如果没有提供表名，则视图列的名字将由定义的SELECT表达式自动生成；如果SELECT包括像x+y这样的无标量的表达式，则视图列的名字将生成_C0，_C1等形式。当重命名列时，可有选择地提供列注释。注释不会从底层列自动继承。如果定义SELECT表达式的视图是无效的，那么CREATE VIEW语句将失败。
注意 没有关联存储的视图是纯粹的逻辑对象。目前在Hive中不支持物化视图。当一个查询引用一个视图时，可以评估视图的定义并为下一步查询提供记录集合。这是一种概念的描述，实际上，作为查询优化的一部分，Hive可以将视图的定义与查询的定义结合起来，例如从查询到视图使用的过滤器。
在创建视图的同时确定视图的架构，随后再改变基本表（如添加一列）将不会在视图的架构中体现。如果基本表被删除或以不兼容的方式被修改，则该无效视图的查询失败。
视图是只读的，不能用于LOAD/INSERT/ALTER的目标。
视图可能包含ORDER BY和LIMIT子句。如果一个引用了视图的查询也包含了这些子句，那么在执行这些子句时首先要查看视图语句，然后返回结果按视图中语句执行。例如，一个视图v指定返回记录LIMIT为5，执行查询语句：select*from v LIMIT 10，这个查询最多返回5行记录。
以下是创建视图的例子：
CREATE VIEW onion_referrers（url COMMENT'URL of Referring page'）
COMMENT'Referrers to The Onion website'
AS
SELECT DISTINCT referrer_url
FROM page_view
WHERE page_url='http：//www.theonion.com'；
（2）删除表视图
DROP VIEW view_name
DROP VIEW，删除指定视图的元数据。在视图中使用DROP TABLE是错误的，例如：
DROP VIEW onion_referrers；
6.创建/删除函数
（1）创建函数
CREATE TEMPORARY FUNCTION function_name AS class_name
该语句创建了一个由类名实现的函数。在Hive中可以持续使用该函数查询，也可以使用Hive类路径中的任何类。用户可以通过执行ADD FILES语句将函数类添加到类路径，可参阅用户指南CLI部分了解有关在Hive中添加/删除函数的更多信息。使用该语句注册用户定义函数。
（2）删除函数
注销用户定义函数的格式如下：
DROP TEMPORARY FUNCTION function_name
7.展示描述语句
在Hive中，该语句提供一种方法对现有的数据和元数据进行查询。
（1）显示表
SHOW TABLES identifier_with_wildcards
SHOW TABLES列出了所有基表及与给定正则表达式名字相匹配的视图。在正则表达式中，可以使用“*”来匹配任意字符，并使用“[]”或“|”来表示选择关系。例如'page_view'、'page_v*'、'*view|page*'，所有这些将匹配'page_view'表。匹配表按字母顺序排列。在元存储中，如果没有找到匹配的表，则不提示错误。