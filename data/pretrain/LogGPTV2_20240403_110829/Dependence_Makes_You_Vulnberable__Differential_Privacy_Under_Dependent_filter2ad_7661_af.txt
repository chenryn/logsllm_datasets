### Section XI: Acknowledgements

We would like to express our gratitude to the anonymous reviewers at NDSS 2016 for their valuable feedback. We are particularly thankful to Reza Shokri for his guidance and support as our shepherd. This research was partially supported by NSF awards CNS-1409415 and CNS-1423139. Additionally, this work received partial sponsorship from the U.S. Army Research Laboratory and the UK Ministry of Defense under Agreement Number W911NF-06-3-0001.

The views and conclusions presented in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory, the U.S. Government, the UK Ministry of Defense, or the UK Government. The U.S. and UK Governments are authorized to reproduce and distribute reprints for governmental purposes, notwithstanding any copyright notation hereon.

### References

[1] M. E. Andrés, N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi, "Geo-indistinguishability: Differential privacy for location-based systems," in CCS, 2013.

[2] L. Backstrom, E. Sun, and C. Marlow, "Find me if you can: Improving geographical prediction with social and spatial proximity," in WWW, 2010.

[3] I. Bilogrevic, K. Huguenin, S. Mihaila, R. Shokri, and J.-P. Hubaux, "Predicting users' motivations behind location check-ins and utility implications of privacy protection mechanisms," in NDSS, 2015.

[4] A. Blum, K. Ligett, and A. Roth, "A learning theory approach to noninteractive database privacy," Journal of the ACM, 2013.

[5] A. Campan and T. M. Truta, "Data and structural k-anonymity in social networks," in Privacy, Security, and Trust in KDD, 2009.

[6] A. Chaabane, G. Acs, M. A. Kaafar et al., "You are what you like! Information leakage through users' interests," in NDSS, 2012.

[7] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate, "Differentially private empirical risk minimization," The Journal of Machine Learning Research, 2011.

[8] R. Chen, B. C. Fung, P. S. Yu, and B. C. Desai, "Correlated network data publication via differential privacy," The International Journal on Very Large Data Bases, 2014.

[9] E. Cho, S. A. Myers, and J. Leskovec, "Friendship and mobility: User movement in location-based social networks," in SIGKDD, 2011.

[10] T. M. Cover and J. A. Thomas, Elements of Information Theory. John Wiley & Sons, 2012.

[11] I. Dinur and K. Nissim, "Revealing information while preserving privacy," in PODS, 2003.

[12] C. Dwork, "Differential privacy," in Automata, Languages and Programming, 2006.

[13] C. Dwork, "Differential privacy: A survey of results," in Theory and Applications of Models of Computation, 2008.

[14] C. Dwork, "A firm foundation for private data analysis," Communications of the ACM, 2011.

[15] C. Dwork, F. McSherry, K. Nissim, and A. Smith, "Calibrating noise to sensitivity in private data analysis," in Springer Theory of Cryptography, 2006.

[16] C. Dwork and A. Smith, "Differential privacy for statistics: What we know and what we want to learn," Journal of Privacy and Confidentiality, 2010.

[17] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart, "Privacy in pharmacogenetics: An end-to-end case study of personalized warfarin dosing," in USENIX Security, 2014.

[18] S. R. Ganta, S. P. Kasiviswanathan, and A. Smith, "Composition attacks and auxiliary information in data privacy," in SIGKDD, 2008.

[19] N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar, and D. Song, "Evolution of social-attribute networks: Measurements, modeling, and implications using Google+," in IMC, 2012.

[20] J. A. Hartigan and M. A. Wong, "Algorithm AS 136: A k-means clustering algorithm," Applied Statistics, 1979.

[21] X. He, A. Machanavajjhala, and B. Ding, "Blowfish privacy: Tuning privacy-utility trade-offs using policies," in SIGMOD, 2014.

[22] S. Ji, W. Li, M. Srivatsa, and R. Beyah, "Structural data de-anonymization: Quantification, practice, and implications," in CCS, 2014.

[23] D. Kifer and B.-R. Lin, "Towards an axiomatization of statistical privacy and utility," in PODS, 2010.

[24] D. Kifer and A. Machanavajjhala, "No free lunch in data privacy," in SIGMOD, 2011.

[25] D. Kifer and A. Machanavajjhala, "A rigorous and customizable framework for privacy," in PODS, 2012.

[26] N. Li, T. Li, and S. Venkatasubramanian, "t-closeness: Privacy beyond k-anonymity and l-diversity," in ICDE, 2007.

[27] N. Li, W. Qardaji, D. Su, Y. Wu, and W. Yang, "Membership privacy: A unifying framework for privacy definitions," in CCS, 2013.

[28] D. Liben-Nowell and J. Kleinberg, "The link-prediction problem for social networks," Journal of the American Society for Information Science and Technology, 2007.

[29] A. Machanavajjhala, D. Kifer, J. Gehrke, and M. Venkitasubramanian, "l-diversity: Privacy beyond k-anonymity," ACM Transactions on Knowledge Discovery from Data, 2007.

[30] F. D. McSherry, "Privacy integrated queries: An extensible platform for privacy-preserving data analysis," in SIGMOD, 2009.

[31] P. Mittal, C. Papamanthou, and D. Song, "Preserving link privacy in social network based systems," in NDSS, 2013.

[32] A. Narayanan and V. Shmatikov, "De-anonymizing social networks," in IEEE S&P, 2009.

[33] S. Nilizadeh, A. Kapadia, and Y.-Y. Ahn, "Community-enhanced de-anonymization of online social networks," in CCS, 2014.

[34] P. Sen and A. Deshpande, "Representing and querying correlated tuples in probabilistic databases," in ICDE, 2007.

[35] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux, "Quantifying location privacy," in IEEE S&P, 2011.

[36] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-Y. Le Boudec, "Protecting location privacy: Optimal strategy against localization attacks," in CCS, 2012.

[37] M. Srivatsa and M. Hicks, "Deanonymizing mobility traces: Using social network as a side-channel," in CCS, 2012.

[38] L. Sweeney, "k-anonymity: A model for protecting privacy," International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 2002.

[39] C. Task and C. Clifton, "A guide to differential privacy theory in social network analysis," in Proceedings of the 2012 International Conference on Advances in Social Networks Analysis and Mining, 2012.

[40] T. Zhu, P. Xiong, G. Li, and W. Zhou, "Correlated differential privacy: Hiding information in non-iid dataset," Information Forensics and Security, IEEE Transactions on, 2013.

### Appendix

#### A. Security Guarantees of DP

For \(\epsilon\)-differential privacy with \(P(D')\), we have:
\[
\sum_{D'} P(D')P(A(D) = S) \leq e^\epsilon \sum_{D'} P(D')P(A(D') = S)
\]
Integrating Eq. 1, we obtain:
\[
\sum_D P(D)P(A(D) = S) \log \frac{P(A(D)=S)}{P(A(·)=S)} \leq \epsilon
\]

#### B. Formulation for \(\rho_{ij}\) in Eq. 18

To analyze the second term of the RHS of Eq. 12, consider the dependent relationships of the tuples:
\[
\max_{d_{i1}, d_{i2}} \sum_{d_j} P(D_j = d_j | D_i = d_{i1}) \exp\left(- \frac{\| \tilde{d}_j - d_j \|_1}{\sigma(\epsilon)} \right) \leq \max_{d_{i1}, d_{i2}} \sum_{d_j} \exp\left(- \frac{\| \tilde{d}_j - d_{\min} \|_1}{\sigma(\epsilon)} \right) P(D_j = d_j | D_i = d_{i1})
\]
where \(d_{\min}\) is the value of \(d_j\) that minimizes \(\exp\left(- \frac{\| \tilde{d}_j - d_j \|_1}{\sigma(\epsilon)} \right)\). To quantify the dependence coefficient, substitute \(d_{\min}\):
\[
\exp\left( \frac{\| d_j - d^* \|_1}{\sigma(\epsilon)} \right)
\]
Thus, we obtain Eq. 18.

#### C. Proof for Sequential Composition Theorem for DDP

For any sequence \(r\) of outcomes \(r_t \in \text{Region}(A_t)\) with the same dependence relationship \(R\), the probability of output \(r\) from the sequence of \(A_t(D)\) is:
\[
P(A(D) = r) = \prod_t P(A_t(D) = r_t)
\]
Applying the definition of DDP for each \(A_t\), we have:
\[
\prod_t P(A_t(D) = r_t) \leq \prod_t P(A_t(D') = r_t) \times \exp\left( \sum_t \frac{\epsilon_t}{\sigma(\epsilon)} \right)
\]

#### D. Proof for Parallel Composition Theorem for DDP

For \(D\) and \(D'\) with the same dependence relationship \(R\), the probability of output \(r\) from the sequence of \(A_t(D)\) is:
\[
P(A(D) = r) = \prod_t P(A_t(D) = r_t)
\]
Applying the definition of DDP for each \(A_t\), we have:
\[
\prod_t P(A_t(D) = r_t) \leq \prod_t P(A_t(D') = r_t) \times \exp\left( \sum_t \frac{\epsilon_t}{\sigma(\epsilon)} \right)
\]

#### E. Dependent Sensitivity for Any Query \(Q\)

As \(\rho_{ij}\) evaluates the extent of dependence between \(D_i\) and \(D_j\), a modification of \(D_i\) implies a modification of \(D_j\). Therefore, the sensitivity is:
\[
\Delta Q_i + \rho_{ij} \Delta Q_j
\]
Thus, the global sensitivity for publishing any query function \(Q\) on a dependent dataset is:
\[
\Delta S_Q = \sum_i \Delta Q_i + \sum_{j \neq i} \rho_{ij} \Delta Q_j
\]

#### F. \((\alpha, \beta)\)-Accuracy Guarantee for DDP

\[
P\left( \max |A(D) - Q(D)| > \alpha \right) \leq \beta \implies P\left( \max | \text{Lap} \left( \frac{\Delta S_Q}{\epsilon} \right) | > \alpha \right) \leq \beta \implies P\left( \text{Lap} \left( \frac{\Delta S_Q}{\epsilon} \right) > \alpha \right) + P\left( \text{Lap} \left( \frac{\Delta S_Q}{\epsilon} \right) < -\alpha \right) \leq \beta
\]

#### G. Proof for the Transform Invariance Axiom

\[
P(B(A(D)) = O | d_{i1}) = \sum_D P(B(A(D)) = O) P(D = D | d_{i1}) = \sum_S P(B(S) = O) P(A(D) = S | d_{i1}) \leq e^\epsilon P(B(A(D)) = O | d_{i2})
\]

#### H. Proof for the Convexity Axiom

\[
P(A_p(D) = S | d_{i1}) = p P(A_1(D) = S | d_{i1}) + (1 - p) P(A_2(D) = S | d_{i1}) \leq e^\epsilon \left( p P(A_1(D) = S | d_{i1}) + (1 - p) P(A_2(D) = S | d_{i1}) \right) = e^\epsilon P(A_p(D) = S | d_{i2})
\]