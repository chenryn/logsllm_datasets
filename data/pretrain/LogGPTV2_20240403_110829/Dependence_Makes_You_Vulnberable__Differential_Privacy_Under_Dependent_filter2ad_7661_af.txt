used for providing differential privacy.
XI. ACKNOWLEDGEMENT
We would like to thank the anonymous reviewers at NDSS
2016 for helpful feedback, and we are especially grateful to
Reza Shokri for his guidance as our shepherd. This work was
supported in part by NSF awards number CNS-1409415 and
CNS-1423139. This work was also partially sponsored by US
Army Research laboratory and the UK Ministry of Defense
under Agreement Number W911NF-06-3-0001. The views and
conclusions contained in this document are those of the authors
and should not be interpreted as representing the ofﬁcial
policies, either expressed or implied, of the US Army Research
Laboratory, the U.S. Government, the UK Ministry of Defense,
or the UK Government. The US and UK Governments are
authorized to reproduce and distribute reprints for Government
purposes notwithstanding any copyright notation hereon.
REFERENCES
[1] M. E. Andr´es, N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi,
“Geo-indistinguishability: Differential privacy for location-based sys-
tems,” in CCS, 2013.
[2] L. Backstrom, E. Sun, and C. Marlow, “Find me if you can: improving
geographical prediction with social and spatial proximity,” in WWW,
2010.
I. Bilogrevic, K. Huguenin, S. Mihaila, R. Shokri, and J.-P. Hubaux,
“Predicting users” motivations behind location check-ins and utility
implications of privacy protection mechanisms,” in NDSS, 2015.
[3]
[4] A. Blum, K. Ligett, and A. Roth, “A learning theory approach to
noninteractive database privacy,” Journal of the ACM, 2013.
[5] A. Campan and T. M. Truta, “Data and structural k-anonymity in social
networks,” in Privacy, Security, and Trust in KDD, 2009.
[6] A. Chaabane, G. Acs, M. A. Kaafar et al., “You are what you like!
information leakage through users’ interests,” in NDSS, 2012.
[7] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate, “Differentially
private empirical risk minimization,” The Journal of Machine Learning
Research, 2011.
[8] R. Chen, B. C. Fung, P. S. Yu, and B. C. Desai, “Correlated network
data publication via differential privacy,” The International Journal on
Very Large Data Bases, 2014.
[9] E. Cho, S. A. Myers, and J. Leskovec, “Friendship and mobility: user
movement in location-based social networks,” in SIGKDD, 2011.
Wiley & Sons, 2012.
I. Dinur and K. Nissim, “Revealing information while preserving
privacy,” in PODS, 2003.
[10] T. M. Cover and J. A. Thomas, Elements of information theory.
John
[11]
14
[12] C. Dwork, “Differential privacy,” in Automata, languages and program-
ming, 2006.
[13] ——, “Differential privacy: A survey of results,” in Theory and Appli-
cations of Models of Computation, 2008.
[14] ——, “A ﬁrm foundation for private data analysis,” Communications of
the ACM, 2011.
[15] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to
sensitivity in private data analysis,” in Springer Theory of cryptography,
2006.
[16] C. Dwork and A. Smith, “Differential privacy for statistics: What we
know and what we want to learn,” Journal of Privacy and Conﬁden-
tiality, 2010.
[17] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart,
“Privacy in pharmacogenetics: An end-to-end case study of personalized
warfarin dosing,” in USENIX Security, 2014.
[18] S. R. Ganta, S. P. Kasiviswanathan, and A. Smith, “Composition attacks
and auxiliary information in data privacy,” in SIGKDD, 2008.
[19] N. Z. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar,
and D. Song, “Evolution of social-attribute networks: measurements,
modeling, and implications using google+,” in IMC, 2012.
J. A. Hartigan and M. A. Wong, “Algorithm as 136: A k-means
clustering algorithm,” Applied statistics, 1979.
[20]
[21] X. He, A. Machanavajjhala, and B. Ding, “Blowﬁsh privacy: Tuning
privacy-utility trade-offs using policies,” in SIGMOD, 2014.
[22] S. Ji, W. Li, M. Srivatsa, and R. Beyah, “Structural data de-
anonymization: Quantiﬁcation, practice, and implications,” in CCS,
2014.
[23] D. Kifer and B.-R. Lin, “Towards an axiomatization of statistical privacy
and utility,” in PODS, 2010.
[24] D. Kifer and A. Machanavajjhala, “No free lunch in data privacy,” in
SIGMOD, 2011.
[25] ——, “A rigorous and customizable framework for privacy,” in PODS,
2012.
[26] N. Li, T. Li, and S. Venkatasubramanian, “t-closeness: Privacy beyond
k-anonymity and l-diversity,” in ICDE, 2007.
[27] N. Li, W. Qardaji, D. Su, Y. Wu, and W. Yang, “Membership privacy:
a unifying framework for privacy deﬁnitions,” in CCS, 2013.
[28] D. Liben-Nowell and J. Kleinberg, “The link-prediction problem for
the American society for information
social networks,” Journal of
science and technology, 2007.
[29] A. Machanavajjhala, D. Kifer, J. Gehrke, and M. Venkitasubrama-
niam, “l-diversity: Privacy beyond k-anonymity,” ACM Transactions on
Knowledge Discovery from Data=, 2007.
[30] F. D. McSherry, “Privacy integrated queries: an extensible platform for
privacy-preserving data analysis,” in SIGMOD, 2009.
[31] P. Mittal, C. Papamanthou, and D. Song, “Preserving link privacy in
social network based systems,” in NDSS, 2013.
[32] A. Narayanan and V. Shmatikov, “De-anonymizing social networks,” in
IEEE S&P , 2009.
[33] S. Nilizadeh, A. Kapadia, and Y.-Y. Ahn, “Community-enhanced de-
anonymization of online social networks,” in CCS, 2014.
[34] P. Sen and A. Deshpande, “Representing and querying correlated tuples
in probabilistic databases,” in ICDE, 2007.
[35] R. Shokri, G. Theodorakopoulos, J.-Y. Le Boudec, and J.-P. Hubaux,
“Quantifying location privacy,” in IEEE S&P, 2011.
[36] R. Shokri, G. Theodorakopoulos, C. Troncoso, J.-P. Hubaux, and J.-
Y. Le Boudec, “Protecting location privacy: optimal strategy against
localization attacks,” in CCS, 2012.
[37] M. Srivatsa and M. Hicks, “Deanonymizing mobility traces: Using
social network as a side-channel,” in CCS, 2012.
[38] L. Sweeney, “k-anonymity: A model for protecting privacy,” Interna-
tional Journal of Uncertainty, Fuzziness and Knowledge-Based Systems,
2002.
[39] C. Task and C. Clifton, “A guide to differential privacy theory in social
network analysis,” in Proceedings of the 2012 International Conference
on Advances in Social Networks Analysis and Mining, 2012.
[40] T. Zhu, P. Xiong, G. Li, and W. Zhou, “Correlated differential privacy:
Hiding information in non-iid dataset,” Information Forensics and
Security, IEEE Transactions on, 2013.
XII. APPENDIX
(cid:80)
D(cid:48) P(D(cid:48))P(A(D) = S) ≤ e(cid:80)
Leaked Information =(cid:80)
A. Security Guarantees of DP
-differential privacy with P(D(cid:48)), we have
Integrating Eq. 1 for
D(cid:48) P(D(cid:48))P(A(D(cid:48)) = S),
i.e., P(A(D) = S) ≤ eP(A(·) = S). Combining with
11, we
obtain
in Eq.
the
D P (D)P (A(D) = S) log P (A(D)=S)
P (A(·)=S) } ≤ .
of Leaked
Information
deﬁnition
B. Formulation for ρij in Eq. 18
We
to
consider
analyze
general
second
the
the
term of
maxdi1
,di2
(cid:80)
(cid:80)
(cid:80)
dj
dj
P (Dj =dj|Di=di1
P (Dj =dj|Di=di2
P (Dj =dj|Di=di1
dependent
relationships
of
the RHS
) exp(− (cid:107)(cid:101)dj−dj(cid:107)1
) exp(− (cid:107)(cid:101)dj−dj(cid:107)1
) exp(− (cid:107)(cid:101)dj−dj(cid:107)1
σ()
σ()
σ()
)
)
)
of
Eq.
12
tuples
as
≤
≤
maxdi1
,di2
(cid:80)
dj
exp(− (cid:107)(cid:101)dj−dmin
(cid:107)1
P (Dj = dj|Di = di1 ) exp(
j
σ()
)
(cid:107)dj−dmin
(cid:107)1
j
is
dj
σ()
j
σ()
(cid:107)(cid:101)dj−dj(cid:107)1
(cid:107)dj−d∗
(cid:107)dj−dmin
), where dmin
maxdi1
the value of dj that minimizes exp(
dependence coefﬁcient which is applicable for any output value of (cid:101)dj, we
j
σ()
). In order to quantify the
(cid:107)1
j(cid:107)1. Substituting dmin
j , we obtain Eq. 18.
further have exp(
(cid:107)dj − d∗
C. Proof
for Sequential Composition Theorem for DDP For any
sequence r of outcomes rt ∈ Region(At) with the same dependence
relationship R, the probability of output r from the sequence of At(D)
t P r(At(D) = rt). Applying the deﬁnition of
t P r(At(D(cid:48)) =
DSQ × |D − D(cid:48)|(cid:17) ≤ P r(A(D(cid:48)) = r) × exp(cid:0)(cid:80)
(cid:16) t
is P r(A(D) = r) = (cid:81)
DDP for each At, we have (cid:81)
rt) ×(cid:81)
t P r(At(D) = rt) ≤ (cid:81)
) ≤ exp(
with d∗
), where d∗
j maximizes
(cid:1) .
t exp
j (cid:107)1
t t
σ()
j
let Dt
: D ∩ Dt and D(cid:48)
D. Proof for Parallel Composition Theorem for DDP
For D and D(cid:48),
same dependence relationship R,
rt ∈ R(At),
t = D ∩ Dt with the
At(D) is P r(A(D) = r) = (cid:81)
for any sequence r of outcomes
deﬁnition of DDP for each At, we have (cid:81)
the probability of output r from the sequence of
(cid:16) t
t|(cid:17) ≤ P r(A(D(cid:48)) =
t P r(At(Di) = rt) Applying the
(cid:81)
t) = rt) ×(cid:81)
t P r(At(D) = rt) ≤
(cid:18) max
(cid:19)
t P r(At(D(cid:48)
DSQ × |Dt − D(cid:48)
DSQ × |D − D(cid:48)|
≤ P r(A(D(cid:48)) = r) × exp
r) × exp
(cid:19)
(cid:18)
t exp
max
t
t
.
t
t
for
for Dj
any query function Q, we have
E. Dependent Sensitivity for Any Query Q
As ρij evaluates the extent of dependence between Di and Dj,
modiﬁcation of Di would imply modiﬁcation of Dj
Therefore,
the
sensitivity
Furthermore, we
DSQ
the
as ρij ∆Dj.
corresponding
prove
i = maxdi1,di2 (cid:107)Q([D1, · · · , di1, · · · ])− Q([D1, · · · , di2, · · · ])(cid:107)1 =
≤
(cid:82) di2
∆Qj + · · · ≤ ∆Qi + ρij ∆Qj = (cid:80)CiL
ρij ∆Qj.
∆Qi +
Therefore, the global sensitivity for publishing any query function Q on a
dependent dataset is DSQ = maxi DSQ
dDi + (cid:82) dmax
i =(cid:80)
dDj + · · ·
j ρij ∆Qj.
di1
∆Dj(i)
maxdi1,di2
ρij ∆Qj.
j(i)
dmin
j(i)
j=Ci1
∂Q(D)
∂Q(D)
can
∆Dj
∂Dj
∂Di
as
F. (α, β)-Accuracy Guarantee for DDP
P (max |A(D) − Q(D)| > α) ≤ β =⇒ P (max |Lap( DSQ
> α) ≤ β =⇒ P (Lap( DSQ
)|
)  α) + P (Lap( DSQ
DSQ ) ≤ β.


2(cid:82) ∞
α t exp(− t
P (B(A(D)) = O|di1) = (cid:80)
di1) = (cid:80)
e(cid:80)
(cid:80)
D
G. Proof for the Transform Invariance Axiom
D P (B(A(D)) = O)P (D = D|
S P (B(S) = O)P (A(D = S|di1) ≤
D P (B(A(D)) = O)P (D = D|di2) = eP (B(A(D)) = O|di2).
H. Proof for the Convexity Axiom
P (Ap(D) = S|di1) = pP (A1(D) = S|di1) + (1 − p)P (A2(D) =
S|di1) ≤ epP (A1(D) = S|di1) + e(1 − p)P (A2(D) = S|di1) =
eP (Ap(D) = S|di2).
15