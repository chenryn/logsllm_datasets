200
100
0
PLT
domContentLoaded
TTFP
TTFB
20
80
Redirect Time / Load Time [%]
40
60
100
(a) Nav. Timings: Redirect share of load time
Alexa 1000
Alexa 10001−11000
0
1
2
3
4
5
6
7
8
HTTP 301 or 302 before first 200
(b) HAR: Number of redirects
Fig. 3. Eﬀects of initial redirects.
Since the most commonly used workload are the Alexa Top Lists despite their
limitations [26] we also use a snapshot of the global Alexa Top 100012, and the
Alexa 10001 to 11000 for Marionette and ChromeDevTools. We then repeatedly
accessed each page 10 times with the diﬀerent frameworks. This ensures that all
experiments for a single page are done within a reasonable time window. Overall,
the experiments were executed between 18. September and 11. October 2018.
For each page, we ﬁrst initialize a new browser proﬁle with a cold browser
cache. We then fetch the page and wait for it to load13. As data sources, we
export Navigation Timings, Resource Timings, TTFP, and the HAR ﬁle using
the native HAR export of the browser via har-export-trigger 0.6.1. In parallel,
we also run a packet capture to derive our baseline. If one of the data sources
does not yield any data, we log an error and exclude the page load attempt from
the data set.
5 Results
In this section, we point out various pitfalls with Web performance metrics.
5.1 Pitfall: Redirects
As already pointed out, see Fig. 1, initial redirects can increase PLT substan-
tially, especially for short page loads. Timings excluding redirects may be more
representative of page loads by actual users due to browser optimizations, e.g.,
the user types the ﬁrst few letters and then clicks on a URL suggested by the
browser, or the browser automatically uses HTTPS due to HSTS or adds “www”
to domain names the user types14. In contrast, load times including redirects are
representative of page loads if a user types in the full URL and presses Enter.
However, a conscious choice should be made and the web workload adjusted
accordingly.
12 18. September 2018 for Alexa 1000 and 30. September 2018 for Alexa 10001–11000.
13 We instruct the browser automation tool to wait for the onLoad event.
14 See, e.g., https://support.mozilla.org/en-US/kb/search-web-address-bar.
Web Performance Pitfalls
293
Table 3. Object sizes: accuracies for unencrypted objects.
Comparison
Browser Match
Counted too many bytes Counted too few bytes
Cases [%] Cases [%] 99%q
[KB]
Max
[KB]
Cases
[%]
99%q
[KB]
Max
[KB]
Content-length Firefox
Chrome
HAR body size Firefoxa
Chrome
Res body size
Firefox
100
100
72.6
91.9
39.6
Chrome
46
0
0
13.4
0.5
0.8
0.5
0
0
0
0
66.28
2170
0
0
0
303.4
2910
276.5
0
0
14
7.6
59.6
53.5
0
0
0.13
0.3
196.6
181.5
6.8
0
852.4
2925
5092
5092
aIn HAR ﬁles, Firefox logs body size including headers, contradicting [7], see https://
dxr.mozilla.org/mozilla-central/source/devtools/server/actors/network-monitor/network-resp
onse-listener.js\#428, accessed 28.09.2018. Thus, we subtract header size from all object sizes.
To assess the impact of redirects we ﬁrst count the number of server-side
redirects15 for both the Alexa 1000 and 10000–11000, see Fig. 3b. The most
common cause for a redirect is that a page is no longer available via HTTP
and the browser is redirected to the HTTPS version. Given that many pages
have migrated to HTTPS, e.g., 75% of Web pages loaded by Firefox users in
September 2018 [27], this is not surprising. Other reasons for redirects include
pointers to subdomains, e.g., for localized versions of the content based on the
geolocation. Often both occur and lead to two redirects.
Next, we revisit page load times16. To quantify their contribution to the load
time, we show, in Fig. 3a, the relative percentage of load times of redirects for all
Web pages. Redirects account for 6.1% of PLT for 50% of the pages and for 23%
of PLT for 10% of pages. This implies that the PLT with or without redirects
diﬀers by this amount. The diﬀerence is even larger for user-centric load time
metrics as these are usually shorter. For instance, Time To First Paint (TTFP)
diﬀers by 19.1% for 50% of pages and by 47% for 10% of pages. Indeed, the time
for the redirects is about the same as the Time To First Byte after the redirect
for about 50% of pages. The reason is that most redirects, typically involve an
additional name resolution, TCP connection establishment, TLS handshake17,
and HTTP request.
In summary, we make the following observations: (1) Redirects account for
a signiﬁcant share of PLT and a substantial share of user-centric load time
metrics such as TTFP. (2) Studies should make a conscious choice on in-/exclude
redirects, see Sect. 6.
15 Server-side redirects use HTTP status 301 or 302. Client-side redirects use status
200 and contain the redirection URL in the response content, which we do not log.
16 For Navigation Timings, redirects are the time between navigationStart and fetch-
Start. For HAR ﬁles, we use the time before the ﬁrst HTTP 200 response.
17 In September and early October 2018, TLS 1.3 was still not deployed.
294
T. Enghardt et al.
5.2 Pitfall: Object Sizes
Next, we take a closer look at object sizes. In particular, we explore if diﬀerent
data sources are consistent with the baseline from the packet capture trace and
if they yield similar results.
Comparison with the Baseline for Unencrypted Objects: To validate
the object sizes recorded by the diﬀerent data sources, see Sect. 2.2, we com-
pare them against the baseline which we get via the packet capture trace. This,
unfortunately, is only possible for objects loaded over unencrypted HTTP/1.0
or HTTP/1.1. If TLS is used object sizes may be incorrect due to padding. For
computing the baseline, we extract HTTP request and response pairs from the
packet capture trace and exclude objects with missing bytes. For the remaining
object, we separate the TCP payload into the HTTP header and body, and count
bytes18. Finally, we match the object to the corresponding HAR and Resource
Timing (Res) data based on timestamp. Hereby, we exclude ambiguous cases,
i.e., where multiple HAR entries match an object from the trace.
The resulting comparison is summarized in Table 3. If the Content-Length
header is present its information is mostly consistent with the traces. None of
the other data sources is that good. Rather, we ﬁnd that the accuracy varies
widely across data sources and browsers. When manually investigating the most
signiﬁcant mismatches, we ﬁnd that Resource Timings set object size to 0 for
most cross-origin objects19. In HAR ﬁles, body size is often set to −1 if the
browser did not succeed in loading a resource. In several cases, Firefox counted
too many bytes if redirects happened. Apparently, it is returning the size of the
redirect destination instead of the actual object size.
Comparison of Data Sources for All Objects: Next, we explore the con-
sistency of the results for all objects including those that are transferred over
an encrypted connection. Figure 4, shows the object size diﬀerences for the same
object and various data source combinations, i.e., HAR ﬁle body size (HAR),
Content-Length header taken from HAR ﬁle, and Resource Timings encoded
body size (Res). Since Content-Length is a close approximation to the baseline
for unencrypted objects we use it as a baseline. Res provides the exact same
object size as Content-Length in only 42.5% of cases for Firefox and in 43.4% of
cases for Chrome. This is consistent with the results for unencrypted objects, see
Table 3. For HAR, Firefox provides an object size which matches the Content-
Length for 91.3% of cases, see Fig. 4a. Thus, we conclude that HAR’s accuracy is
better than for unencrypted objects. In contrast, Chrome provides an object size
which matches the Content-Length in only 39.4% of cases for all objects. When
investigating the diﬀerence, we ﬁnd that Chrome sets HAR body and header
size to −1 for all HTTP/2 objects20.
From this, we conclude: (1) Content-Length provides the most accurate
object size but is not always available. (2) Resource Timings are an unreliable
18 See analysis script eval/validate object sizes.py in our repository.
19 Unless the ‘Timing-Allow-Origin’ header is set, see [5].
20 In Firefox, only HTTP/2 Server Push objects lack body size and timings.
Web Performance Pitfalls
295
8
.
0
F
D
C
E
4
.
0
0
.
0
HAR − Content−Length
Res − Content−Length
Res − HAR
10 100
1000000
Absolute Difference [Bytes]
10000
8
.
0
F
D
C
E
4
.
0
0
.
0
10
HAR − Content−Length
Res − Content−Length
Res − HAR
100
Absolute Difference [Bytes]
10000
1000000
(a) Firefox
(b) Chrome
Fig. 4. Object sizes: diﬀerences due to metric for all objects.
data source for object sizes, as they do not provide sizes for cross-origin objects,
except when explicitly allowed. (3) HAR body size is inaccurate for a signiﬁcant
number of objects, due to bugs in both Firefox and Chrome (whereby Firefox is
more accurate than Chrome).
5.3 Pitfall: Object Count and ByteIndex
Amazingly, we ﬁnd that not only the object sizes diﬀer by data sources but also
the object counts (for the same page download)! For the Alexa 1000 dataset,
object counts from HAR and Res always diﬀer by at least one object and by 7
or more objects for 50% of cases. For 10% of the cases, they are oﬀ by more than
67 objects. Numbers for Alexa 10000 are similar. Among the main contributor
to this diﬀerence is that Resource Timings do not include objects loaded within
commonly embedded HTML Inline Frames (iframes)21. Rather, these objects
are recorded in the Resource Timeline for the iframe.
8
.
0
F
D
C
E
4
.
0
0
.
0
8
.
0
F
D
C
E
4
.
0
0
.
0
HAR − Content−Length
Res − Content−Length
Res − HAR
HAR − Content−Length
Res − Content−Length
Res − HAR
0
20
40
60
80
100
0
20
40
60
80
100
Relative Byte Index Difference [%]
Relative Byte Index Difference [%]
(a) Firefox
(b) Chrome
Fig. 5. Byte index: diﬀerence due to data source.
Next, we quantify the impact of object size and count diﬀerences on the
Byte Index [1], which captures page load progress, i.e., loaded bytes over time. In
21 See the examples in Sect. 4.2 of [5].
296
T. Enghardt et al.
Table 4. Missing data source: successful page loads vs. errors for Alexa 1000 run
Tools
Success
Before
onLoad
No data
No Res No
HAR
No Res
and HAR
Min Max Median Min Max Median Median Median
Firefox with Selenium
880
898
Firefox with Marionette 915
922
0
0
Chrome with DevTools
740
801
100
60