# A Throughput-Centric View of the Performance of Datacenter Topologies

**Authors:**
- Pooria Namyar, University of Southern California
- Sucha Supittayapornpong, Vidyasirimedhi Institute of Science and Technology
- Mingyang Zhang, University of Southern California
- Minlan Yu, Harvard University
- Ramesh Govindan, University of Southern California

## Abstract
Prior research has explored numerous datacenter designs, but only Clos-based and expander-based topologies are considered practical due to their scalability using commodity switching chips. These topologies have been evaluated using two metrics: bisection bandwidth and throughput. The relationship between these metrics remains unclear both theoretically and practically. By leveraging the characteristics of these topologies, we derive an upper bound on their throughput and demonstrate that this upper bound provides a more accurate estimate of worst-case throughput than previous estimators, while also scaling better. Our findings show that, for expander-based topologies, beyond a certain network size, full throughput cannot be achieved even with full bisection bandwidth. This is in contrast to Clos topologies, which can maintain full throughput. We conclude by showing that using throughput as a metric for evaluating datacenter performance, rather than bisection bandwidth, can lead to different conclusions regarding cost, manageability, and reliability.

## CCS Concepts
- **Networks:** Data center networks, Network performance modeling, Network manageability, Topology analysis and generation
- **General and Reference:** Metrics

## Keywords
Data centers, Throughput, Clos topologies, Network management

## ACM Reference Format
Pooria Namyar, Sucha Supittayapornpong, Mingyang Zhang, Minlan Yu, and Ramesh Govindan. 2021. A Throughput-Centric View of the Performance of Datacenter Topologies. In *ACM SIGCOMM 2021 Conference (SIGCOMM '21), August 23â€“28, 2021, Virtual Event, USA*. ACM, New York, NY, USA, 21 pages. https://doi.org/10.1145/3452296.3472913

## Permission Notice
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

## 1. Introduction
The success of cloud computing is significantly attributed to datacenters, which are large-scale aggregations of compute and storage resources on commodity servers. The performance of distributed applications running in datacenters, such as search, reliable storage, and social networks, is heavily influenced by the design of the datacenter network. This network consists of a topology where switches interconnect servers. Modern datacenters often feature tens of thousands of switches connecting hundreds of thousands of servers. This paper focuses on the design and evaluation of topologies for such large-scale datacenters.

### Datacenter Topology Designs
Two primary classes of topology designs have emerged: Clos-based and expander-based. Clos-based designs, including Fat-tree, VL2, Jupiter, and Facebook Fabric, are hierarchical and bi-regular, meaning each switch either connects to \(H\) servers or none at all. Expander-based designs, such as Jellyfish, Xpander, and FatClique, aim to reduce installation and management costs. These topologies are uni-regular, with every switch connecting to \(H\) servers. Both classes ensure that each server connects to exactly one switch.

### Measures of Topology Capacity
The capacity of the datacenter network is a critical factor in application performance. A topology with sufficient capacity to allow every server to send traffic at full line rate simplifies cloud application design, enabling flexible placement and robustness against correlated failures. Most prior work has used bisection bandwidth, defined as the smallest aggregate capacity of links crossing the worst-case cut dividing the topology into two halves, as a measure of capacity. A topology has full bisection bandwidth if its bisection bandwidth is at least half the total number of servers. For Clos-based designs, full bisection bandwidth allows arbitrary application instance placement.

Other research has explored throughput, defined as the highest scaling factor \(\theta(T)\) such that the topology can support the traffic matrix \(T \cdot \theta(T)\) without violating any link's capacity. A topology has full throughput if \(\theta^*\) (the worst-case throughput among all traffic matrices) is at least 1, allowing it to support any traffic demand and enable arbitrary application instance placement.

### Contributions
1. **Difference Between Full Throughput and Full Bisection Bandwidth for Uni-regular Topologies:**
   - We prove that for any uni-regular topology, there exists a size beyond which the topology cannot achieve full throughput, even if it has full bisection bandwidth. This is true even for small instances with as few as 10-15K servers. In contrast, bi-regular Clos topologies with full bisection bandwidth always have full throughput. This means that full bisection bandwidth is necessary but not sufficient for uni-regular topologies to support arbitrary traffic demand, whereas full throughput is both necessary and sufficient.

2. **A Throughput-Centric View:**
   - Prior work has primarily used bisection bandwidth to evaluate both uni-regular and bi-regular topologies. We show that using throughput can lead to different conclusions, impacting cost and management complexity. Throughput is a more appropriate metric as it better captures the capacity of both types of topologies.
   - We find that a full throughput Jellyfish, Xpander, or FatClique uses only 25% fewer switches than a full throughput Clos, compared to the 50% fewer switches claimed when using bisection bandwidth. This smaller cost differential may make uni-regular topologies less attractive relative to Clos.
   - Expanding a full throughput Jellyfish or FatClique, even slightly, while keeping the number of servers per switch constant, can result in a topology without full throughput. This suggests that maintaining full throughput after expansion may require a more complex strategy than Clos.

3. **An Efficiently-Computable, Tight, Throughput Upper Bound:**
   - We derive an upper bound on the throughput of uni-regular and bi-regular topologies and empirically show that this upper bound is tighter and scales better than existing approaches, including the throughput bound in [43], heuristics for estimating throughput in [23, 24, 51], bisection bandwidth, and sparsest cut [27].
   - This scalable throughput upper bound can be used to better assess the performance of large-scale datacenter topologies.

### Conclusion
Using throughput as a metric for evaluating datacenter performance, rather than bisection bandwidth, can lead to different conclusions about cost, manageability, and reliability. Our findings highlight the importance of considering throughput in the design and evaluation of datacenter topologies.