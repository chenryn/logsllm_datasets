multivariate sampling problem x âˆ¼ P to a univariate one, namely
ğ‘¡ âˆ¼ PMix or ğœƒ âˆ¼ PArc, plus a uniform one, ğƒ âˆ¼ Uni(Sğ‘›âˆ’2 âŠ¥ ğ). This
is normally easier, as generating univariate samples avoids the curse
of dimensionality regarding numerical precision and complexity.
2.2.2 Von Misesâ€“Fisher distribution. The (ğ‘› âˆ’ 1)-dimensional von
Misesâ€“Fisher (VMF) distribution, named after von Mises [40] and
Fisher [13], is a probability distribution on the unit hypersphere
Sğ‘›âˆ’1. Due to its popularity, it has been studied thoroughly, and
proven sampling methods have been published [27, 38, 44] (see
Section 3.4.1). Therefore, we use it as a starting point to construct a
first novel privacy mechanism for directional data in Section 3.2.
Definition 10. The VMF distribution on Sğ‘›âˆ’1 with mean direction
ğ âˆˆ Sğ‘›âˆ’1 and concentration parameter ğœ… â‰¥ 0 is given by the density
VMF(ğ, ğœ…)[x] = ğ¶VMF(ğ‘›, ğœ–) Â· exp(cid:0)ğœ… Â· ğáµ€x(cid:1) .
2 Â· ğœ‹ ğœˆ+1ğ‘€(cid:0)ğœˆ + 1
2 âˆ’ 1, the normalization factor amounts to
(2ğœ‹)ğœˆ+1ğ¼ğœˆ(ğœ…) =
Î“(ğœˆ + 1)ğ‘’ğœ…
If we set ğœˆ â‰” ğ‘›
ğ¶VMF(ğ‘›, ğœ…) =
2 , 2ğœˆ + 1, 2ğœ…(cid:1) .
ğœ…ğœˆ
Session 4D: Differential Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea1207The parameter ğœ… characterizes how strongly the random vectors
x âˆ¼ VMF(ğ, ğœ…) are concentrated about the mean ğ. If ğœ… > 0, the dis-
tribution is unimodal and the mode matches ğ. A VMF distribution
with ğœ… = 0 degenerates to the uniform distribution Uni(Sğ‘›âˆ’1).
2.2.3 Purkayastha distribution. Purkayastha [34] studied rotation-
ally symmetric distributions on Sğ‘›âˆ’1 for which the median direction
is a maximum likelihood estimate of the location parameter. He
proposed the following distribution that meets this criterion; in
Section 3.3, we use it for a second mechanism for directional data.
Definition 11. The Purkayastha distribution on Sğ‘›âˆ’1 with mean
direction ğ âˆˆ Sğ‘›âˆ’1 and concentration parameter ğœ… â‰¥ 0 has density
Pur(ğ, ğœ…)[x] = ğ¶Pur(ğ‘›, ğœ…) Â· exp(cid:0)âˆ’ğœ… Â· arccos(ğáµ€x)(cid:1).
Its normalization factor is ğ¶Pur(ğ‘›, ğœ…) = ğ‘†âˆ’1
(ğ‘›âˆ’2)!(1âˆ’ğ‘’âˆ’ğœ…ğœ‹)
(ğ‘›âˆ’2)!(1+ğ‘’âˆ’ğœ…ğœ‹)
 ğœ…(ğœ…2+22)(ğœ…2+42)Â·Â·Â·(ğœ…2+(ğ‘›âˆ’2)2)
(ğœ…2+12)(ğœ…2+32)Â·Â·Â·(ğœ…2+(ğ‘›âˆ’2)2)
ğ¹âˆ’1
ğ‘›âˆ’2,âˆ’ğœ…(ğœ‹) =
ğ‘›âˆ’2ğ¹âˆ’1
ğ‘›âˆ’2,âˆ’ğœ…(ğœ‹), where
for even ğ‘›,
for odd ğ‘›
(cf. Lemma 21). Note that ğ¹ also appears in the normalization con-
stant of the angular and mixture densities in Section 3.3.1.
3 DIRECTIONAL PRIVACY MECHANISMS
This section presents our main results. This comprises a novel
notion of privacy for directional data as well as the conforming
von Misesâ€“Fisher and Purkayastha mechanisms. We derive certain
marginal densities, expected values, and CDFs of the underlying
distributions. These are important for assessing the average er-
ror, or sampling, as we show by constructing a novel Purkayastha
sampling method. Moreover, we explain how the mechanism param-
eters depend on the desired privacy guarantees. Lastly, we describe
adaptions of common privacy mechanisms to directional data as
baselines. Proofs for this section are provided in Appendix A.3.
3.1 Directional privacy
Our goal is to define a variant of metric privacy [4] (Definition 3) for
directions. To this end, we first need a suitable metric to measure
distances between directions, i.e., angles on the sphere:
Definition 12. The surface distance between two points ğ’™, ğ’š âˆˆ
ğ‘Ÿ Sğ‘›âˆ’1 is given by the arc length ğ‘‘âˆ¡(ğ’™, ğ’š) â‰” ğ‘Ÿ arccos(ğ’™áµ€ğ’š).
On the unit sphere (ğ‘Ÿ = 1), the surface distance ğ‘‘âˆ¡ between two
points is the enclosed angle (in radians) between themâ€”together,
Sğ‘›âˆ’1 with ğ‘‘âˆ¡ becomes a metric space for angles. We thus obtain
Definition 13 (Directional privacy). Let ğœ– > 0. A mechanismM on
Sğ‘›âˆ’1 fulfills ğœ–ğ‘‘âˆ¡-privacy if for all ğ’™, ğ’™â€² âˆˆ Sğ‘›âˆ’1 and all Z âŠ‚ suppM,
M(ğ’™)[Z] â‰¤ exp(cid:0)ğœ– Â· ğ‘‘âˆ¡(ğ’™, ğ’™â€²)(cid:1) Â· M(ğ’™â€²)[Z].
Interpretation as pure DP. Following Chatzikokolakis et al. [4,
Fact 5], ğœ–ğ‘‘-privacy on a space Y implies ğœ–Î”-DP for a query function
ğ‘“ : D â†’ Y with ğ‘‘-sensitivity Î” on the universe of databases D.
We apply this fact specifically to sphere-valued functions with range
Y âŠ† Sğ‘›âˆ’1 to obtain ğœ–-DP:
Fact 14 (ğœ–ğ‘‘-privacy implies ğœ–-DP). Let ğ‘“ : D â†’ Sğ‘›âˆ’1 be a query
function, and letMğœ– be an ğœ–ğ‘‘-private mechanism on Sğ‘›âˆ’1 with metric
ğ‘‘. Then its ğ‘‘-sensitivity is Î” = Î”ğ‘‘ ğ‘“ := maxğ‘¥ âˆ¼D ğ‘¦ ğ‘‘(ğ‘“ (ğ‘¥), ğ‘“ (ğ‘¦)), and
the composition Mğœ–/Î” â—¦ ğ‘“ is ğœ–-differentially private.
3.2 Von Misesâ€“Fisher privacy mechanism
The Laplace and Gaussian distributions are often used in Euclidean
space, particularly as mechanisms to provide DP. Since the VMF
distribution can be seen as natural counterpart on the sphere, we
propose it as promising candidate to achieve DP for directional data:
Theorem 15 (ğœ–ğ‘‘2-privacy of VMF mechanism). Let ğœ– > 0 be a
privacy parameter. The VMF mechanism on Sğ‘›âˆ’1 induced by ğ’™ â†¦â†’
VMF(ğ’™, ğœ–) for ğ’™ âˆˆ Sğ‘›âˆ’1 fulfills ğœ–ğ‘‘2-privacy.
Corollary 16 (ğœ–ğ‘‘âˆ¡-privacy of VMF mechanism). For any ğ’™, ğ’š âˆˆ
Sğ‘›âˆ’1, ğ‘‘2(ğ’™, ğ’š) â‰¤ ğ‘‘âˆ¡(ğ’™, ğ’š), so the VMF mechanism fulfills ğœ–ğ‘‘âˆ¡-privacy.
By Fact 14, the VMF mechanism VMF(ğ’™, ğœ–/Î”) also provides ğœ–-
: D â†’ Sğ‘›âˆ’1 on the space of
DP for sphere-valued functions ğ‘“
databases D. Note that in this case, we can use the sensitivity Î” of
ğ‘“ with respect to either ğ‘‘âˆ¡ (by Corollary 16) or ğ‘‘2 (by Theorem 15).
3.2.1 VMF marginal distributions. By Lemma 8 and Corollary 9,
the mixture and angular densities of a VMF distribution are
where the normalization factor amounts to
2 ğ‘’ğœ…ğ‘¡ ,
VMF Â· sinğ‘›âˆ’2(ğœƒ) ğ‘’ğœ… cos(ğœƒ),
VMFMix[ğ‘¡] = ğ¶â€²
VMFArc[ğœƒ] = ğ¶â€²
VMF Â·(cid:0)1 âˆ’ ğ‘¡2(cid:1) ğ‘›âˆ’3
(cid:16) ğœ…
(cid:17)ğœˆ(cid:16)Î“(cid:0) 1
2 (cid:1)ğ¼ğœˆ(ğœ…)(cid:17)âˆ’1
2(cid:1)Î“(cid:0) ğ‘›âˆ’1
2 (cid:1) Â· ğ‘€âˆ’1(cid:0) ğ‘›âˆ’1
= ğ‘’ğœ… Â· Bâˆ’1(cid:0) 1
2 , ğ‘›âˆ’1
=
2
ğ¶â€²
VMF = ğ¶VMF Â· ğ‘†ğ‘›âˆ’2
2 ; ğ‘› âˆ’ 1; 2ğœ…(cid:1).
(3)
(4)
(5)
The mixture density is used in the rejection sampling scheme for
the VMF distribution by Ulrich [38] and Wood [44], and is based on
earlier work by Saw [36]. We use it next for the expected distance.
3.2.2 Expected Euclidean distance. To assess the error induced by
a mechanism, we can use statistical tools such as the expected
value of an error measure based on the underlying distribution.
Concretely, for a random vector x âˆ¼ VMF(ğ, ğœ…), we provide an
analytical expression for the expected L2 distance to the mode ğ:
Theorem 17. The expected Euclidean distance between a random
vector x âˆ¼ VMF(ğ, ğœ…) and the mode ğ can be expressed as expected
value over the mixture density. It evaluates to
[ğ‘‘2(x, ğ)] =
E
xâˆ¼VMF
=
E
B(cid:0) 1
B(cid:0) 1
ğ‘¡âˆ¼VMFMix
2 , ğ‘›
2 , ğ‘› âˆ’ 1
âˆš
1 âˆ’ ğ‘¡]
2
2 ; ğ‘› âˆ’ 1
[âˆš
2(cid:1) ğ‘€(cid:0) ğ‘›âˆ’1
2; 2ğœ…(cid:1)
2(cid:1)
ğ‘€(cid:0) ğ‘›âˆ’1
2 ; ğ‘› âˆ’ 1; 2ğœ…(cid:1) .
(6)
3.2.3 Mixture CDF. Kurz and Hanebeck [27] provide analytical
solutions for the CDF of the VMF angular distribution in the con-
text of sampling. While their solution is an analytical, closed-form
expression of elementary functions when ğ‘› is odd, it involves an
infinite series in terms of special functions for even ğ‘›.
In the following, we present a concise, analytic solution for
the CDF of the VMF mixture distribution in terms of confluent
hypergeometric series covering both odd and even dimensions:
Theorem 18. Setting ğ›¼ â‰” ğ‘›âˆ’1
2 , the CDF of the VMF
mixture distribution VMFMix(ğ‘›, ğœ…) at ğ‘‡ âˆˆ [âˆ’1, 1] can be written as
(7)
Î¦1(ğ›¼, 1 âˆ’ ğ›¼, 1 + ğ›¼; ğ‘¥, 2ğœ…ğ‘¥)
2 and ğ‘¥ â‰” ğ‘‡+1
VMFMix(ğ‘›, ğœ…)[ğ‘¡ â‰¤ ğ‘‡] =
.
B(ğ›¼, ğ›¼)ğ‘€(ğ›¼, 2ğ›¼, 2ğœ…)
ğ‘¥ğ›¼
ğ›¼
Session 4D: Differential Privacy CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea12083.3 Purkayastha privacy mechanism
The VMF distribution enjoys wide popularity among spherical dis-
tributions, and provides differential as well as ğ‘‘2- and ğ‘‘âˆ¡-privacy as
shown in the previous section. However, we also observe potential
shortcomings, namely the probability decreases exponentially with
the squared L2 distance from the mode, i.e., the distance is measured
as straight line through the sphere. Instead, we would rather have
it decrease exponentially with the surface distance on the sphere,
i.e., with arccos(ğáµ€ğ’™). It turns out that this is precisely the distribu-
tion in Definition 11 studied by Purkayastha [34]. We immediately
obtain a corresponding Purkayastha privacy mechanism as follows:
Theorem 19 (ğœ–ğ‘‘âˆ¡-privacy of Purkayastha mechanism). Let ğœ– > 0 be
a privacy parameter. The Purkayastha mechanism on Sğ‘›âˆ’1 induced
by ğ’™ â†¦â†’ Pur(ğ’™, ğœ–) for ğ’™ âˆˆ Sğ‘›âˆ’1 fulfills ğœ–ğ‘‘âˆ¡-privacy.
By Fact 14, the Purkayastha mechanism Pur(ğ’™, ğœ–/Î”) also pro-
: D â†’ Sğ‘›âˆ’1 with ğ‘‘âˆ¡-
vides ğœ–-DP for sphere-valued functions ğ‘“
sensitivity Î” on the space of databases D.
3.3.1 Purkayastha marginal densities. By Lemma 8 and Corollary 9,
we obtain the Purkayastha mixture and angular densities as
PurMix[ğ‘¡] = ğ¶â€²
PurArc[ğœƒ] = ğ¶â€²
with normalization factor ğ¶â€²
2 ğ‘’âˆ’ğœ… arccos(ğ‘¡),
Pur Â· sinğ‘›âˆ’2(ğœƒ) ğ‘’âˆ’ğœ…ğœƒ ,
Pur = ğ¶Pur Â· ğ‘†ğ‘›âˆ’2 = ğ¹âˆ’1
ğ‘›âˆ’2,âˆ’ğœ…(ğœ‹).
(8)
(9)
Integrating the angular density. Having derived an expression
for the angular density PurArc[ğœƒ], we are interested in statistical
properties such as its expected value to assess the average error,
or the angular CDF PurArc[ğœƒ â‰¤ ğœ—] which is fundamental for the
sampling algorithm we propose in Section 3.4.2.
The angular density is specified through a function ğ‘’ğ‘ğ‘¥ sinğ‘› ğ‘¥,
where ğ‘› âˆˆ N and ğ‘ âˆˆ R. Gradshteyn and Ryzhik [15, 2.662] provide
separate closed-form expressions for its antiderivative for even
and odd ğ‘›. We rewrite these expressions and provide the following
unified solution which allows to efficiently evaluate such integrals:
Fact 20. An antiderivative of ğ‘’ğ‘ğ‘¥ sinğ‘› ğ‘¥ with ğ‘› âˆˆ N and ğ‘ âˆˆ R is
(10)
ğ¸ğ‘›,ğ‘(ğ‘¥) â‰” ğ‘’ğ‘ğ‘¥
Pur Â·(cid:0)1 âˆ’ ğ‘¡2(cid:1)ğ‘›âˆ’3
Cğ‘˜Tğ‘˜(ğ‘¥),
ğ‘š
(cid:0)ğ‘2 + (ğ‘› âˆ’ 2â„“)2(cid:1) ,
ğ‘˜=0
1
and
where ğ‘š = âŒŠğ‘›/2âŒ‹,
Cğ‘˜ =
ğ‘›!
(ğ‘› âˆ’ 2ğ‘˜)!
ğ‘˜
â„“=0
âˆ« ğ‘Ÿ
Tğ‘˜(ğ‘¥) = sinğ‘›âˆ’2ğ‘˜âˆ’1(ğ‘¥)[ğ‘ sin(ğ‘¥) âˆ’ (ğ‘› âˆ’ 2ğ‘˜) cos(ğ‘¥)].
In particular, the definite integral over [0, ğ‘Ÿ] is given by
ğ¹ğ‘›,ğ‘(ğ‘Ÿ) â‰”
Lemma 21. The integral ğ¹ğ‘›,ğ‘(ğœ‹) =âˆ« ğœ‹
ğ‘’ğ‘ğ‘¥ sinğ‘› ğ‘¥ dğ‘¥ = ğ¸ğ‘›,ğ‘(ğ‘Ÿ) âˆ’ ğ¸ğ‘›,ğ‘(0).
Pur = ğ¹âˆ’1
(11)
ğ‘›âˆ’2,âˆ’ğœ…(ğœ‹):
0 ğ‘’ğ‘ğ‘¥ sinğ‘› ğ‘¥ dğ‘¥ evaluates to
A special case is the normalization factor ğ¶â€²
0
ğ¹ğ‘›,ğ‘(ğœ‹) =
ğ‘›!(ğ‘’ğ‘ğœ‹ âˆ’ 1)
ğ‘›!(ğ‘’ğ‘ğœ‹ + 1)
ğ‘(ğ‘2 + 22)(ğ‘2 + 42) Â· Â· Â· (ğ‘2 + ğ‘›2)
(ğ‘2 + 12)(ğ‘2 + 32) Â· Â· Â· (ğ‘2 + ğ‘›2)
for even ğ‘›,
for odd ğ‘›.
(12)
3.3.2 Expected surface distance. We provide a closed-form solution
for the expected angle of a Purkayastha random vector as follows:
Theorem 22. The expected surface distance (or angle) between a
random point x âˆ¼ Pur(ğ, ğœ…) and the mode ğ âˆˆ Sğ‘›âˆ’1 can be expressed
as expected angular density. It evaluates to
[ğ‘‘âˆ¡(x, ğ)] =
E
xâˆ¼Pur
[ğœƒ]
ğœƒâˆ¼PurArc
E
ğ‘š
ğœ‹
1 âˆ’ ğ‘’ğœ…ğœ‹ âˆ’ 1
where ğ´â„“ â‰”(cid:0)ğœ…2 + (ğ‘› âˆ’ 2â„“)2(cid:1)âˆ’1 for 1 â‰¤ â„“ â‰¤ ğ‘š â‰”(cid:4) ğ‘›
2(cid:5).
1 + ğ‘’ğœ…ğœ‹
ğ´â„“ +
= 2ğœ…
â„“=1
ğœ‹
ğœ…
if ğ‘› is even,
if ğ‘› is odd,
(13)
âˆ« ğœ—
3.3.3 Angular CDF. We provide the following expression for the
CDF of the angular distribution PurArc in terms of Eqs. (11) and (12):
Corollary 23. The CDF of the Purkayastha angular distribution
PurArc(ğ‘›, ğœ…) is
ğ¹ğ‘›âˆ’2,âˆ’ğœ…(ğœ—)
PurArc[ğœƒ â‰¤ ğœ—] = ğ¶â€²
ğ¹ğ‘›âˆ’2,âˆ’ğœ…(ğœ‹) . (14)
Note that this is a closed-form solution that can be efficiently
evaluated in terms of finite sums ğ¸ğ‘›,ğ‘(ğ‘¥) (Fact 20) and the formula
for ğ¹ğ‘›,ğ‘(ğœ‹) (Lemma 21) for both odd and even ğ‘›. This is crucial for
the Purkayastha sampling method we develop in the next section.
ğ‘’âˆ’ğœ…ğœƒ sinğ‘›âˆ’2(ğœƒ) dğœƒ =
Pur
0
3.4 Sampling algorithms
In this section, we discuss concrete algorithms for our directional
privacy mechanisms, i.e., to generate samples from the underlying
distributions. For some general intuition on sampling rotationally
symmetric distributions, we refer the reader to Section 2.2.1. Due
to its popularity, the VMF distribution has been studied extensively,
and proven sampling methods already have been published; two
of them we describe in Section 3.4.1. In contrast, no methods have
been published so far for the Purkayastha distribution. Therefore,
in Section 3.4.2, we contribute the first sampling algorithm for the
Purkayastha distribution.
3.4.1 VMF sampling methods. To generate a point x âˆ¼ VMF(ğ, ğœ…),
we can employ the existing rejection scheme by Ulrich [38] and
Wood [44]: Pursuant to Section 2.2.1, it involves two crucial steps:
âˆš
First, the tangent-normal decomposition x = ğ‘¡ ğ +
1 âˆ’ ğ‘¡2ğƒ in
Eq. (1) reduces the multivariate sampling problem to a univariate
one, namely sampling ğ‘¡ (cid:123) VMFMix(ğ‘›, ğœ…) from the mixture dis-
tribution, as well as a direction vector ğƒ (cid:123) Uni(Sğ‘›âˆ’2âŠ¥ ğ). This
avoids the curse of dimensionality since the mixture density is one-
dimensional, and uniform samples from a hypersphere are easily
created by normalizing samples from a (multivariate) standard nor-
mal distribution. Second, we need an efficient sampling algorithm
for the reduced problem. A clever way to solve this is the rejection
method [44, Algorithm VM*] for VMFMix(ğ‘›, ğœ…). Ulrich [38] showed
that the acceptance ratio is at least â‰ˆ 66% for any parameters ğ‘› and