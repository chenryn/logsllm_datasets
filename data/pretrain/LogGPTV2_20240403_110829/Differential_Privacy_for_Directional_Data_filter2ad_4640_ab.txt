multivariate sampling problem x ∼ P to a univariate one, namely
𝑡 ∼ PMix or 𝜃 ∼ PArc, plus a uniform one, 𝝃 ∼ Uni(S𝑛−2 ⊥ 𝝁). This
is normally easier, as generating univariate samples avoids the curse
of dimensionality regarding numerical precision and complexity.
2.2.2 Von Mises–Fisher distribution. The (𝑛 − 1)-dimensional von
Mises–Fisher (VMF) distribution, named after von Mises [40] and
Fisher [13], is a probability distribution on the unit hypersphere
S𝑛−1. Due to its popularity, it has been studied thoroughly, and
proven sampling methods have been published [27, 38, 44] (see
Section 3.4.1). Therefore, we use it as a starting point to construct a
first novel privacy mechanism for directional data in Section 3.2.
Definition 10. The VMF distribution on S𝑛−1 with mean direction
𝝁 ∈ S𝑛−1 and concentration parameter 𝜅 ≥ 0 is given by the density
VMF(𝝁, 𝜅)[x] = 𝐶VMF(𝑛, 𝜖) · exp(cid:0)𝜅 · 𝝁ᵀx(cid:1) .
2 · 𝜋 𝜈+1𝑀(cid:0)𝜈 + 1
2 − 1, the normalization factor amounts to
(2𝜋)𝜈+1𝐼𝜈(𝜅) =
Γ(𝜈 + 1)𝑒𝜅
If we set 𝜈 ≔ 𝑛
𝐶VMF(𝑛, 𝜅) =
2 , 2𝜈 + 1, 2𝜅(cid:1) .
𝜅𝜈
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1207The parameter 𝜅 characterizes how strongly the random vectors
x ∼ VMF(𝝁, 𝜅) are concentrated about the mean 𝝁. If 𝜅 > 0, the dis-
tribution is unimodal and the mode matches 𝝁. A VMF distribution
with 𝜅 = 0 degenerates to the uniform distribution Uni(S𝑛−1).
2.2.3 Purkayastha distribution. Purkayastha [34] studied rotation-
ally symmetric distributions on S𝑛−1 for which the median direction
is a maximum likelihood estimate of the location parameter. He
proposed the following distribution that meets this criterion; in
Section 3.3, we use it for a second mechanism for directional data.
Definition 11. The Purkayastha distribution on S𝑛−1 with mean
direction 𝝁 ∈ S𝑛−1 and concentration parameter 𝜅 ≥ 0 has density
Pur(𝝁, 𝜅)[x] = 𝐶Pur(𝑛, 𝜅) · exp(cid:0)−𝜅 · arccos(𝝁ᵀx)(cid:1).
Its normalization factor is 𝐶Pur(𝑛, 𝜅) = 𝑆−1
(𝑛−2)!(1−𝑒−𝜅𝜋)
(𝑛−2)!(1+𝑒−𝜅𝜋)
 𝜅(𝜅2+22)(𝜅2+42)···(𝜅2+(𝑛−2)2)
(𝜅2+12)(𝜅2+32)···(𝜅2+(𝑛−2)2)
𝐹−1
𝑛−2,−𝜅(𝜋) =
𝑛−2𝐹−1
𝑛−2,−𝜅(𝜋), where
for even 𝑛,
for odd 𝑛
(cf. Lemma 21). Note that 𝐹 also appears in the normalization con-
stant of the angular and mixture densities in Section 3.3.1.
3 DIRECTIONAL PRIVACY MECHANISMS
This section presents our main results. This comprises a novel
notion of privacy for directional data as well as the conforming
von Mises–Fisher and Purkayastha mechanisms. We derive certain
marginal densities, expected values, and CDFs of the underlying
distributions. These are important for assessing the average er-
ror, or sampling, as we show by constructing a novel Purkayastha
sampling method. Moreover, we explain how the mechanism param-
eters depend on the desired privacy guarantees. Lastly, we describe
adaptions of common privacy mechanisms to directional data as
baselines. Proofs for this section are provided in Appendix A.3.
3.1 Directional privacy
Our goal is to define a variant of metric privacy [4] (Definition 3) for
directions. To this end, we first need a suitable metric to measure
distances between directions, i.e., angles on the sphere:
Definition 12. The surface distance between two points 𝒙, 𝒚 ∈
𝑟 S𝑛−1 is given by the arc length 𝑑∡(𝒙, 𝒚) ≔ 𝑟 arccos(𝒙ᵀ𝒚).
On the unit sphere (𝑟 = 1), the surface distance 𝑑∡ between two
points is the enclosed angle (in radians) between them—together,
S𝑛−1 with 𝑑∡ becomes a metric space for angles. We thus obtain
Definition 13 (Directional privacy). Let 𝜖 > 0. A mechanismM on
S𝑛−1 fulfills 𝜖𝑑∡-privacy if for all 𝒙, 𝒙′ ∈ S𝑛−1 and all Z ⊂ suppM,
M(𝒙)[Z] ≤ exp(cid:0)𝜖 · 𝑑∡(𝒙, 𝒙′)(cid:1) · M(𝒙′)[Z].
Interpretation as pure DP. Following Chatzikokolakis et al. [4,
Fact 5], 𝜖𝑑-privacy on a space Y implies 𝜖Δ-DP for a query function
𝑓 : D → Y with 𝑑-sensitivity Δ on the universe of databases D.
We apply this fact specifically to sphere-valued functions with range
Y ⊆ S𝑛−1 to obtain 𝜖-DP:
Fact 14 (𝜖𝑑-privacy implies 𝜖-DP). Let 𝑓 : D → S𝑛−1 be a query
function, and letM𝜖 be an 𝜖𝑑-private mechanism on S𝑛−1 with metric
𝑑. Then its 𝑑-sensitivity is Δ = Δ𝑑 𝑓 := max𝑥 ∼D 𝑦 𝑑(𝑓 (𝑥), 𝑓 (𝑦)), and
the composition M𝜖/Δ ◦ 𝑓 is 𝜖-differentially private.
3.2 Von Mises–Fisher privacy mechanism
The Laplace and Gaussian distributions are often used in Euclidean
space, particularly as mechanisms to provide DP. Since the VMF
distribution can be seen as natural counterpart on the sphere, we
propose it as promising candidate to achieve DP for directional data:
Theorem 15 (𝜖𝑑2-privacy of VMF mechanism). Let 𝜖 > 0 be a
privacy parameter. The VMF mechanism on S𝑛−1 induced by 𝒙 ↦→
VMF(𝒙, 𝜖) for 𝒙 ∈ S𝑛−1 fulfills 𝜖𝑑2-privacy.
Corollary 16 (𝜖𝑑∡-privacy of VMF mechanism). For any 𝒙, 𝒚 ∈
S𝑛−1, 𝑑2(𝒙, 𝒚) ≤ 𝑑∡(𝒙, 𝒚), so the VMF mechanism fulfills 𝜖𝑑∡-privacy.
By Fact 14, the VMF mechanism VMF(𝒙, 𝜖/Δ) also provides 𝜖-
: D → S𝑛−1 on the space of
DP for sphere-valued functions 𝑓
databases D. Note that in this case, we can use the sensitivity Δ of
𝑓 with respect to either 𝑑∡ (by Corollary 16) or 𝑑2 (by Theorem 15).
3.2.1 VMF marginal distributions. By Lemma 8 and Corollary 9,
the mixture and angular densities of a VMF distribution are
where the normalization factor amounts to
2 𝑒𝜅𝑡 ,
VMF · sin𝑛−2(𝜃) 𝑒𝜅 cos(𝜃),
VMFMix[𝑡] = 𝐶′
VMFArc[𝜃] = 𝐶′
VMF ·(cid:0)1 − 𝑡2(cid:1) 𝑛−3
(cid:16) 𝜅
(cid:17)𝜈(cid:16)Γ(cid:0) 1
2 (cid:1)𝐼𝜈(𝜅)(cid:17)−1
2(cid:1)Γ(cid:0) 𝑛−1
2 (cid:1) · 𝑀−1(cid:0) 𝑛−1
= 𝑒𝜅 · B−1(cid:0) 1
2 , 𝑛−1
=
2
𝐶′
VMF = 𝐶VMF · 𝑆𝑛−2
2 ; 𝑛 − 1; 2𝜅(cid:1).
(3)
(4)
(5)
The mixture density is used in the rejection sampling scheme for
the VMF distribution by Ulrich [38] and Wood [44], and is based on
earlier work by Saw [36]. We use it next for the expected distance.
3.2.2 Expected Euclidean distance. To assess the error induced by
a mechanism, we can use statistical tools such as the expected
value of an error measure based on the underlying distribution.
Concretely, for a random vector x ∼ VMF(𝝁, 𝜅), we provide an
analytical expression for the expected L2 distance to the mode 𝝁:
Theorem 17. The expected Euclidean distance between a random
vector x ∼ VMF(𝝁, 𝜅) and the mode 𝝁 can be expressed as expected
value over the mixture density. It evaluates to
[𝑑2(x, 𝝁)] =
E
x∼VMF
=
E
B(cid:0) 1
B(cid:0) 1
𝑡∼VMFMix
2 , 𝑛
2 , 𝑛 − 1
√
1 − 𝑡]
2
2 ; 𝑛 − 1
[√
2(cid:1) 𝑀(cid:0) 𝑛−1
2; 2𝜅(cid:1)
2(cid:1)
𝑀(cid:0) 𝑛−1
2 ; 𝑛 − 1; 2𝜅(cid:1) .
(6)
3.2.3 Mixture CDF. Kurz and Hanebeck [27] provide analytical
solutions for the CDF of the VMF angular distribution in the con-
text of sampling. While their solution is an analytical, closed-form
expression of elementary functions when 𝑛 is odd, it involves an
infinite series in terms of special functions for even 𝑛.
In the following, we present a concise, analytic solution for
the CDF of the VMF mixture distribution in terms of confluent
hypergeometric series covering both odd and even dimensions:
Theorem 18. Setting 𝛼 ≔ 𝑛−1
2 , the CDF of the VMF
mixture distribution VMFMix(𝑛, 𝜅) at 𝑇 ∈ [−1, 1] can be written as
(7)
Φ1(𝛼, 1 − 𝛼, 1 + 𝛼; 𝑥, 2𝜅𝑥)
2 and 𝑥 ≔ 𝑇+1
VMFMix(𝑛, 𝜅)[𝑡 ≤ 𝑇] =
.
B(𝛼, 𝛼)𝑀(𝛼, 2𝛼, 2𝜅)
𝑥𝛼
𝛼
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea12083.3 Purkayastha privacy mechanism
The VMF distribution enjoys wide popularity among spherical dis-
tributions, and provides differential as well as 𝑑2- and 𝑑∡-privacy as
shown in the previous section. However, we also observe potential
shortcomings, namely the probability decreases exponentially with
the squared L2 distance from the mode, i.e., the distance is measured
as straight line through the sphere. Instead, we would rather have
it decrease exponentially with the surface distance on the sphere,
i.e., with arccos(𝝁ᵀ𝒙). It turns out that this is precisely the distribu-
tion in Definition 11 studied by Purkayastha [34]. We immediately
obtain a corresponding Purkayastha privacy mechanism as follows:
Theorem 19 (𝜖𝑑∡-privacy of Purkayastha mechanism). Let 𝜖 > 0 be
a privacy parameter. The Purkayastha mechanism on S𝑛−1 induced
by 𝒙 ↦→ Pur(𝒙, 𝜖) for 𝒙 ∈ S𝑛−1 fulfills 𝜖𝑑∡-privacy.
By Fact 14, the Purkayastha mechanism Pur(𝒙, 𝜖/Δ) also pro-
: D → S𝑛−1 with 𝑑∡-
vides 𝜖-DP for sphere-valued functions 𝑓
sensitivity Δ on the space of databases D.
3.3.1 Purkayastha marginal densities. By Lemma 8 and Corollary 9,
we obtain the Purkayastha mixture and angular densities as
PurMix[𝑡] = 𝐶′
PurArc[𝜃] = 𝐶′
with normalization factor 𝐶′
2 𝑒−𝜅 arccos(𝑡),
Pur · sin𝑛−2(𝜃) 𝑒−𝜅𝜃 ,
Pur = 𝐶Pur · 𝑆𝑛−2 = 𝐹−1
𝑛−2,−𝜅(𝜋).
(8)
(9)
Integrating the angular density. Having derived an expression
for the angular density PurArc[𝜃], we are interested in statistical
properties such as its expected value to assess the average error,
or the angular CDF PurArc[𝜃 ≤ 𝜗] which is fundamental for the
sampling algorithm we propose in Section 3.4.2.
The angular density is specified through a function 𝑒𝑎𝑥 sin𝑛 𝑥,
where 𝑛 ∈ N and 𝑎 ∈ R. Gradshteyn and Ryzhik [15, 2.662] provide
separate closed-form expressions for its antiderivative for even
and odd 𝑛. We rewrite these expressions and provide the following
unified solution which allows to efficiently evaluate such integrals:
Fact 20. An antiderivative of 𝑒𝑎𝑥 sin𝑛 𝑥 with 𝑛 ∈ N and 𝑎 ∈ R is
(10)
𝐸𝑛,𝑎(𝑥) ≔ 𝑒𝑎𝑥
Pur ·(cid:0)1 − 𝑡2(cid:1)𝑛−3
C𝑘T𝑘(𝑥),
𝑚
(cid:0)𝑎2 + (𝑛 − 2ℓ)2(cid:1) ,
𝑘=0
1
and
where 𝑚 = ⌊𝑛/2⌋,
C𝑘 =
𝑛!
(𝑛 − 2𝑘)!
𝑘
ℓ=0
∫ 𝑟
T𝑘(𝑥) = sin𝑛−2𝑘−1(𝑥)[𝑎 sin(𝑥) − (𝑛 − 2𝑘) cos(𝑥)].
In particular, the definite integral over [0, 𝑟] is given by
𝐹𝑛,𝑎(𝑟) ≔
Lemma 21. The integral 𝐹𝑛,𝑎(𝜋) =∫ 𝜋
𝑒𝑎𝑥 sin𝑛 𝑥 d𝑥 = 𝐸𝑛,𝑎(𝑟) − 𝐸𝑛,𝑎(0).
Pur = 𝐹−1
(11)
𝑛−2,−𝜅(𝜋):
0 𝑒𝑎𝑥 sin𝑛 𝑥 d𝑥 evaluates to
A special case is the normalization factor 𝐶′
0
𝐹𝑛,𝑎(𝜋) =
𝑛!(𝑒𝑎𝜋 − 1)
𝑛!(𝑒𝑎𝜋 + 1)
𝑎(𝑎2 + 22)(𝑎2 + 42) · · · (𝑎2 + 𝑛2)
(𝑎2 + 12)(𝑎2 + 32) · · · (𝑎2 + 𝑛2)
for even 𝑛,
for odd 𝑛.
(12)
3.3.2 Expected surface distance. We provide a closed-form solution
for the expected angle of a Purkayastha random vector as follows:
Theorem 22. The expected surface distance (or angle) between a
random point x ∼ Pur(𝝁, 𝜅) and the mode 𝝁 ∈ S𝑛−1 can be expressed
as expected angular density. It evaluates to
[𝑑∡(x, 𝝁)] =
E
x∼Pur
[𝜃]
𝜃∼PurArc
E
𝑚
𝜋
1 − 𝑒𝜅𝜋 − 1
where 𝐴ℓ ≔(cid:0)𝜅2 + (𝑛 − 2ℓ)2(cid:1)−1 for 1 ≤ ℓ ≤ 𝑚 ≔(cid:4) 𝑛
2(cid:5).
1 + 𝑒𝜅𝜋
𝐴ℓ +
= 2𝜅
ℓ=1
𝜋
𝜅
if 𝑛 is even,
if 𝑛 is odd,
(13)
∫ 𝜗
3.3.3 Angular CDF. We provide the following expression for the
CDF of the angular distribution PurArc in terms of Eqs. (11) and (12):
Corollary 23. The CDF of the Purkayastha angular distribution
PurArc(𝑛, 𝜅) is
𝐹𝑛−2,−𝜅(𝜗)
PurArc[𝜃 ≤ 𝜗] = 𝐶′
𝐹𝑛−2,−𝜅(𝜋) . (14)
Note that this is a closed-form solution that can be efficiently
evaluated in terms of finite sums 𝐸𝑛,𝑎(𝑥) (Fact 20) and the formula
for 𝐹𝑛,𝑎(𝜋) (Lemma 21) for both odd and even 𝑛. This is crucial for
the Purkayastha sampling method we develop in the next section.
𝑒−𝜅𝜃 sin𝑛−2(𝜃) d𝜃 =
Pur
0
3.4 Sampling algorithms
In this section, we discuss concrete algorithms for our directional
privacy mechanisms, i.e., to generate samples from the underlying
distributions. For some general intuition on sampling rotationally
symmetric distributions, we refer the reader to Section 2.2.1. Due
to its popularity, the VMF distribution has been studied extensively,
and proven sampling methods already have been published; two
of them we describe in Section 3.4.1. In contrast, no methods have
been published so far for the Purkayastha distribution. Therefore,
in Section 3.4.2, we contribute the first sampling algorithm for the
Purkayastha distribution.
3.4.1 VMF sampling methods. To generate a point x ∼ VMF(𝝁, 𝜅),
we can employ the existing rejection scheme by Ulrich [38] and
Wood [44]: Pursuant to Section 2.2.1, it involves two crucial steps:
√
First, the tangent-normal decomposition x = 𝑡 𝝁 +
1 − 𝑡2𝝃 in
Eq. (1) reduces the multivariate sampling problem to a univariate
one, namely sampling 𝑡 (cid:123) VMFMix(𝑛, 𝜅) from the mixture dis-
tribution, as well as a direction vector 𝝃 (cid:123) Uni(S𝑛−2⊥ 𝝁). This
avoids the curse of dimensionality since the mixture density is one-
dimensional, and uniform samples from a hypersphere are easily
created by normalizing samples from a (multivariate) standard nor-
mal distribution. Second, we need an efficient sampling algorithm
for the reduced problem. A clever way to solve this is the rejection
method [44, Algorithm VM*] for VMFMix(𝑛, 𝜅). Ulrich [38] showed
that the acceptance ratio is at least ≈ 66% for any parameters 𝑛 and