checks, as in SFI, to enforce these constraints simultane-
ously.
In the control-ﬂow-only use, CFI has overheads rang-
ing from 0 to 45% on a Pentium 4; the wide variation pre-
sumably results from a large overhead on indirect jumps
combined with little overhead on any other operation. By
comparison, PittSFIeld imposes a smaller overhead on
jumps, but signiﬁcant additional overheads on other op-
erations. Figure 9 compares the overheads reported in [1]
with those for PittSFIeld from Figure 4. Because a differ-
ent C compiler, library, and hardware were used, caution
should be used in directly comparing the PittSFIeld and
CFI results, but overall the average overheads of the tools
can be seen to be comparable. The benchmark labelled
“?”, 253.perlbmk, was omitted from [1] because of last-
minute implementation difﬁculties [9], and is excluded
from the CFI average.
Like PittSFIeld, CFI performs a separate veriﬁcation
to enforce proper rewriting at load time, so the compiler
and binary rewriting infrastructure need not be trusted.
The CFI authors have written a human-checked proof [2]
that a CFI-protected program will never make unsafe
jumps, even in the presence of arbitrary writes to data
memory. However, the proof is formulated in terms of a
miniature RISC architecture whose encoding is not spec-
iﬁed. This is somewhat unsatisfying, as the safety of the
real CFI technique is affected in subtle ways by the x86
instruction encoding (for instance, the possibility that the
immediate value used in the comparison at a jump site
might be itself interpreted as a safe jump target tag.)
10.4 Static C safety mechanisms
Another class of program rewriting tools (often imple-
mented as compiler modiﬁcations) are focused on en-
suring fairly narrow security policies, for instance that
the procedure return address on the stack is not mod-
iﬁed [6]. Such tools can be very effective in their in-
tended role, and tend to have low overheads, but they do
not provide protection against more esoteric subversion
attacks. They also do not provide isolation between com-
ponents, and are not intended for untrusted code. They
could, however, be used in conjunction with SFI if both
isolation and protection from subversion are desired.
10.5 Dynamic translation mechanisms
Several recent projects has borrowed techniques from
dynamic optimization to rewrite programs on the ﬂy;
such techniques allow for ﬁne control of program exe-
cution, as well as avoiding the difﬁculties of static binary
rewriting. Valgrind [22] is a powerful framework for dy-
namic rewriting of Linux/x86 programs, which is best
known for Purify-like memory checking, but can also be
222
Security ’06: 15th USENIX Security Symposium
USENIX Association
?0%10%20%30%40%50%60%PittSFIeldPittSFIeld jump onlygccperlvortexeongapcraftytwolfparservprgzipbzip2mcfG. meanCFIadapted to a number of other purposes. Valgrind’s rewrit-
ing uses a simpliﬁed intermediate language, sacriﬁcing
performance for ease of development of novel applica-
tions. A research tool with a more security-oriented fo-
cus is Scott and Davidson’s Strata [24]; it has achieved
lower overheads (averaging about 30%) while enforcing
targeted security policies such as system call intercep-
tion. A similar but even higher performance system is
Kiriansky et al.’s program shepherding [15], based on
the DynamoRIO dynamic translation system. Their work
concentrates on preventing attacks on a program’s con-
trol ﬂow, as an efﬁcient and transparent means to pre-
vent stack- and function-pointer-smashing vulnerabili-
ties from being exploited. The VX32 system described
in Section 8 also falls into this category. A disadvantage
of dynamic techniques is that they are inherently some-
what complex and difﬁcult to reason about, relative to a
comparable static translation.
10.6 Low-level type safety
Recent research on veriﬁable low-level program repre-
sentations has concentrated most strongly on static in-
variants, such as type systems. For instance, typed as-
sembly language [19] can provide quickly checkable,
ﬁne-grained safety properties for a sublanguage of x86
assembly, but requires that the original program be writ-
ten in a type-safe language. Type inference can also be
used to transform C code into a type-safe program with
a minimal set of dynamic checks, as in the CCured sys-
tem [5]. Because they can constrain writes to a occur on
speciﬁc objects, type-based safety properties are gener-
ally quite effective at preventing subversion attacks that
overwrite function pointers.
Proof-carrying code [21] represents a more general
framework for software to certify its own trustworthi-
ness. Most work on PCC has focused on type-like safety
properties, but under the banner of foundational PCC [4],
efforts have been made to place proofs on a more general
footing, using fully general proof languages that prove
safety with respect to concrete machine semantics. This
approach seems to carry the promise, not yet realized, of
allowing any safe rewriting to certify its safety proper-
ties to a code consumer. For instance, one could imagine
using the lemmas from the proof of Section 9 as part of
a foundational safety proof for a PittSFIeld-rewritten bi-
nary. It is unclear, however, if any existing foundational
PCC systems are ﬂexible enough to allow such a proof
to be used.
11 Conclusion
We have argued that software-based fault isolation can
be a practical tool in constructing secure systems. Us-
ing a novel technique of artiﬁcially enforcing alignment
for jump targets, we show how a simple sandboxing im-
plementation can be constructed for an architecture with
variable-length instructions like the x86. We give two
new optimizations, which along with previously known
ones minimize the runtime overhead of the technique,
and argue for the importance of an architecture that
includes separate veriﬁcation. We have constructed a
machine-checked soundness proof of our technique, to
further enhance our conﬁdence in its security. Finally,
we have constructed an implementation of our technique
which demonstrates separate veriﬁcation and is scalable
to large and complex applications. The performance
overhead of the technique, as measured on both standard
compute-intensive benchmarks and a realistic data com-
pression application, is relatively low. Though some re-
lated techniques have lower runtime overheads, and oth-
ers can offer additional security guarantees, SFI’s com-
bination of simplicity and performance is a good match
for many uses.
Acknowledgements
Bryan Ford provided us with the VXA infrastructure used in
the case study of Section 8, and Mihai Budiu and ´Ulfar Er-
lingsson provided results for Figure 9 and answered other ques-
tions about CFI. Members of the MIT PDOS and PAG groups,
and the Harvard programming languages and compilers groups,
provided a number of helpful suggestions. The ﬁrst author
is supported by a National Defense Science and Engineering
Graduate Fellowship.
References
[1] Mart´ın Abadi, Mihai Budiu, ´Ulfar Erlingsson, and Jay
Ligatti. Control-ﬂow integrity: Principles, implementa-
tions, and applications. In Proceedings of the 12th ACM
Conference on Computer and Communications Security
(CCS’05), pages 340–353, Alexandria, VA, November 7–
11, 2005.
[2] Mart´ın Abadi, Mihai Budiu, ´Ulfar Erlingsson, and Jay
Ligatti. A theory of secure control ﬂow. In Proceedings of
the 7th International Conference on Formal Engineering
Methods (ICFEM’05), pages 111–124, Manchester, UK,
November 1–4, 2005.
[3] Ali-Reza Adl-Tabatabai, Geoff Langdale, Steven Lucco,
and Robert Wahbe. Efﬁcient and language-independent
mobile programs.
In Proceedings of the SIGPLAN ’96
Conference on Programming Language Design and Im-
plementation, pages 127–136, Philadelphia, PA, May 21–
24, 1996.
[4] Andrew W. Appel. Foundational proof-carrying code. In
16th Annual IEEE Symposium on Logic in Computer Sci-
ence (LICS’01), page 247, June 16–19, 2001.
[5] Jeremy Condit, Mathew Harren,
Scott McPeak,
George C. Necula, and Westley Weimer. CCured in
USENIX Association
Security ’06: 15th USENIX Security Symposium
223
In Proceedings of the ACM SIGPLAN
the real world.
2003 Conference on Programming Language Design and
Implementation, pages 232–244, San Diego, CA, USA,
June 9–11, 2003.
[18] Stephen McCamant and Greg Morrisett. Efﬁcient, veriﬁ-
able binary sandboxing for a CISC architecture. Techni-
cal Report 2005-030, MIT Compter Science and Artiﬁcial
Intelligence Lab, May 2005. (also MIT LCS TR #988).
[6] Crispin Cowan, Calton Pu, Dave Maier, Heather Hin-
ton, Jonathan Walpole, Peat Bakke, Steve Beattie, Aaron
Grier, Perry Wagle, and Qian Zhang.
Stackguard:
Automatic adaptive detection and prevention of buffer-
overﬂow attacks. In Proceedings of the 7th USENIX Secu-
rity Symposium, pages 63–78, Austin, Texas, January 28–
29, 1998. USENIX Association.
[7] Peter Deutsch and Charles A. Grant. A ﬂexible measure-
ment tool for software systems. In Information Process-
ing 71: Proceedings of IFIP Congress 71, pages 320–326,
Ljubljana, Yugoslavia, August 23–28, 1971.
[8] Daniel C. DuVarney, Sandeep Bhatkar,
and V.N.
Venkatakrishnan. SELF: a transparent security extension
for ELF binaries. In Proceedings of the 2003 New Secu-
rity Paradigms Workshop, pages 29–38, Ascona, Switzer-
land, August 18–21, 2003.
´Ulfar Erlingsson. Personal communication, May 2006.
´Ulfar Erlingsson and Fred B. Schneider. SASI enforce-
ment of security policies: A retrospective. In Proceedings
of the 1999 New Security Paradigms Workshop, pages 87–
95, Caledon Hills, ON, Canada, September 22–24 1999.
[11] Bryan Ford. VXA: A virtual architecture for durable
compressed archives. In 4th USENIX Conference on File
and Storage Technologies, pages 295–308, San Francisco,
CA, December 14–16, 2005.
[9]
[10]
[12] Andreas Gal, Christian W. Probst, and Michael Franz.
A denial of service attack on the Java bytecode veriﬁer.
Technical Report 03-23, University of California, Irvine,
School of Information and Computer Science, November
2003.
[13] Matt Kaufmann and J Strother Moore. An industrial
strength theorem prover for a logic based on Com-
mon Lisp. IEEE Transactions on Software Engineering,
23(4):203–213, April 1997.
[14] Douglas Kilpatrick. Privman: A library for partitioning
applications. In Proceedings of the 2003 USENIX Annual
Technical Conference (FREENIX Track), pages 273–284,
San Antonio, TX, USA, June 12–14, 2003.
[15] Vladimir Kiriansky, Derek Bruening, and Saman P. Ama-
rasinghe. Secure execution via program shepherding. In
Proceedings of the 11th USENIX Security Symposium,
pages 191–206, San Francisco, California, August 7–9,
2002. USENIX Association.
[16] Fei Lu.
C Plus J software architecture.
Under-
graduate thesis, Shanghai Jiaotong University,
June
2000. English summary at http://www.cs.jhu.
edu/˜flu/cpj/CPJ_guide.htm.
[17] Stephen McCamant. A machine-checked safety proof
for a CISC-compatible SFI technique. Technical Report
2006-035, MIT Computer Science and Artiﬁcial Intelli-
gence Laboratory, May 2006.
[19] Greg Morrisett, Karl Crary, Neal Glew, Dan Gross-
man, Richard Samuels, Frederick Smith, David Walker,
Stephanie Weirich, and Steve Zdancewic. TALx86: A
realistic typed assembly language. In Second ACM SIG-
PLAN Workshop on Compiler Support for System Soft-
ware, pages 25–35, Atlanta, GA, USA, May 1, 1999.
[20] George C. Necula and Peter Lee. Safe kernel extensions
without run-time checking. In Proceedings of the Second
Symposium on Operating Systems Design and Implemen-
tation, pages 229–243, Seattle, Washington, October 28–
31, 1996.
[21] George C. Necula and Peter Lee. The design and im-
plementation of a certifying compiler. In Proceedings of
the ACM SIGPLAN’98 Conference on Programming Lan-
guage Design and Implementation, pages 333–344, Mon-
treal, Canada, June 17–19 1998.
[22] Nicholas Nethercote and Julian Seward. Valgrind: A pro-
gram supervision framework. In Proceedings of the Third
Workshop on Runtime Veriﬁcation (RV’03), Boulder, Col-
orado, USA, July 13, 2003.
[23] Niels Provos, Markus Friedl, and Peter Honeyman. Pre-
venting privilege escalation. In Proceedings of the 12th
USENIX Security Symposium, pages 231–242, Washing-
ton, D.C., August 6–8, 2003. USENIX Association.
[24] Kevin Scott and Jack Davidson. Safe virtual execution
using software dynamic translation.
In Proceedings of
the 2002 Annual Computer Security Application Confer-
ence, pages 209–218, Las Vegas, Nevada, December 9–
13, 2002.
[25] Christopher Small. MiSFIT: A tool for constructing safe
extensible C++ systems.
In Proceedings of the Third
USENIX Conference on Object-Oriented Technologies,
pages 174–184, Portland, OR, USA, June 16–20 1997.
[26] Michael M. Swift, Brian N. Bershad, and Henry M. Levy.
Improving the reliability of commodity operating sys-
tems. In Proceedings of the 19th ACM Symposium on Op-
erating Systems Principles, pages 207–222, Bolton Land-
ing, NY, October 20–22, 2003.
[27] Robert Wahbe, Steven Lucco, Thomas E. Anderson, and
Susan L. Graham. Efﬁcient software-based fault isola-
tion.
In Proceedings of the 14th ACM Symposium on
Operating Systems Principles, pages 203–216, Asheville,
NC, USA, December 5–8, 1993.
[28] Robert S. Wahbe and Steven E. Lucco. Methods for safe
and efﬁcient implementations of virtual machines. U.S.
Patent 5,761,477, June 1998. Assigned to Microsoft Cor-
poration.
[29] Simon Winwood and Manuel M. T. Chakravarty. Secure
untrusted binaries - provably!
In Workshop on Formal
Aspects in Security and Trust (FAST 2005), pages 171–
186, Newcastle upon Tyne, U.K., July 18–19, 2005.
224
Security ’06: 15th USENIX Security Symposium
USENIX Association