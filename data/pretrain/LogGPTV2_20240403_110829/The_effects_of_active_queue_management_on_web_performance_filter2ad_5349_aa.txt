# The Effects of Active Queue Management on Web Performance

**Authors:**
- Long Le
- Jay Aikat
- Kevin Jeffay
- F. Donelson Smith

**Department of Computer Science, University of North Carolina at Chapel Hill**
- [http://www.cs.unc.edu/Research/dirt](http://www.cs.unc.edu/Research/dirt)

## Abstract

This paper presents an empirical study of the effects of active queue management (AQM) on the distribution of response times experienced by web users. Three prominent AQM schemes were considered: the Proportional Integrator (PI) controller, the Random Exponential Marking (REM) controller, and Adaptive Random Early Detection (ARED). The study examined these AQM schemes both independently and in combination with Explicit Congestion Notification (ECN). The key findings are:

1. For offered loads up to 80% of bottleneck link capacity, no AQM scheme provides better response times than simple drop-tail FIFO queue management.
2. For loads of 90% or more of link capacity without ECN, PI results in a modest improvement over drop-tail and other AQM schemes.
3. With ECN, both PI and REM provide significant response time improvements at offered loads above 90% of link capacity. At 90% load, PI and REM with ECN achieve response times comparable to those on an unloaded network.
4. ARED, with recommended parameter settings, consistently resulted in the poorest response times, which were not improved by the addition of ECN.

We conclude that without ECN, there is little end-user performance gain from employing the AQM designs studied here. However, with ECN, response times can be significantly improved, and provider links may be operated at near saturation levels without significant degradation in user-perceived performance.

## Categories and Subject Descriptors

C.2.2 [Computer Systems Organization]: Computer Communication Networks — Network Protocols.

## General Terms

Algorithms, Measurement, Performance, Experimentation.

## Keywords

Congestion control, Active queue management, Web performance.

## 1. Introduction and Motivation

The Random Early Detection (RED) algorithm, first described a decade ago [7], inspired a new focus for congestion control research on active queue management (AQM). The common goal of all AQM designs is to maintain a small average queue size in routers, which has several desirable effects, including providing queue space to absorb bursts of packet arrivals, avoiding lock-out and bias effects from a few flows dominating queue space, and providing lower delays for interactive applications such as web browsing [3].

All AQM designs function by detecting impending queue buildup and notifying sources before the queue in a router overflows. The various designs proposed for AQM differ in the mechanisms used to detect congestion and in the type of control mechanisms used to achieve a stable operating point for the queue size. Another dimension that significantly impacts performance is how the congestion signal is delivered to the sender. In today's Internet, where the dominant transport protocol is TCP (which reacts to segment loss as an indicator of congestion), the signal is usually delivered implicitly by dropping packets at the router when the AQM algorithm detects queue buildup. An IETF proposed standard adds an explicit signaling mechanism, called Explicit Congestion Notification (ECN) [12], by allocating bits in the IP and TCP headers for this purpose. With ECN, a router can signal congestion to an end-system by "marking" a packet (setting a bit in the header).

In this work, we report the results of an empirical evaluation of three prominent AQM designs: the Proportional Integrator (PI) controller [8], the Random Exponential Marking (REM) controller [2], and a contemporary redesign of the classic RED controller, Adaptive RED [6] (here called ARED). While these designs differ in many respects, each aims to achieve a stable operating point for the size of the router queue. Thus, a user of each of these mechanisms can determine a desired operating point for the control mechanism by specifying a desired target mean queue size. Choosing the desired queue size may represent a tradeoff between link utilization and queuing delay—a short queue reduces latency at the router, but setting the target queue size too small may reduce link utilization by causing the queue to drain needlessly.

Our primary goal in this study was to compare the performance of control-theoretic AQM algorithms (PI and REM) with the more traditional randomized dropping found in RED. We chose both user-centric measures of performance, such as response times for the request-response transactions that comprise web browsing, as well as more traditional metrics like achievable link utilization and loss rates. The distribution of response times experienced by a population of web users was used to assess the user-perceived performance of the AQM schemes. Link utilization was used to assess the impact on network resources. Of particular interest was the implication of ECN support on performance. ECN requires the participation of end-systems in the AQM scheme, and it is important to quantify the performance gain at the expense of a more complex protocol stack and migration issues for the end-system.

Our experimental platform was a laboratory testbed consisting of a large collection of computers arranged to emulate a peering point between two ISPs operated at 100 Mbps (see Figure 1). We emulated the web browsing behavior of tens of thousands of users whose traffic transits the link connecting the ISPs and investigated the performance of each AQM scheme in the border-routers connecting the ISPs. Each scheme was investigated both with and without ECN support across a variety of AQM parameter settings that represented a range of target router-queue lengths. For each target queue length, we varied the offered load on the physical link connecting the ISPs to determine how (or if) AQM performance was affected by load.

Our results showed that for offered loads up to 80% of the bottleneck link capacity, no AQM scheme provided better response time performance than simple drop-tail FIFO queue management. Additionally, all schemes resulted in similar loss rates and link utilization. For offered loads above 80% of link capacity, there was an advantage to employing control-theoretic AQM. When ECN is not used, at offered loads of 90% of link capacity, PI resulted in a modest improvement over drop-tail and the other AQM schemes. Web browsing response time was improved for responses requiring more than approximately 400 milliseconds to complete, but at the cost of slightly lower achievable link utilization (compared to drop-tail). Notably, without ECN, PI outperformed REM.

Our most striking result is that with ECN, both REM and PI significantly outperform drop-tail at 90% load and provide response time performance competitive with that achieved on an unloaded network. The improved response time performance, however, comes at some loss of achievable link utilization. In light of these results, another striking finding was that the addition of ECN did not improve ARED performance. ARED consistently resulted in the poorest response time performance across all offered loads and resulted in the lowest link utilizations.

We conclude that without ECN, there is little end-user or provider performance gain to be realized by employing the AQM algorithms studied here. However, with ECN, performance can be significantly improved. Our experiments also provide evidence that provider links may be operated at near saturation levels (90% average utilization with bursty traffic sources) without significant degradation in user-perceived performance and with only very modest decreases in link utilization (when compared to drop-tail). Thus, unlike a similar earlier study [4] which was negative on the use of AQM, we view the ECN results as a significant indicator that the stated goals of AQM can be realized in practice.

While the results of this study are intriguing, the study was nonetheless limited. The design space of AQM schemes is large, with each algorithm typically characterized by a number of independent parameters. We limited our consideration of AQM algorithms to a comparison between two classes: those based on control-theoretic principles and those based on the original randomized dropping paradigm of RED. Moreover, we studied a link carrying only web-like traffic. More realistic mixes of HTTP and other TCP traffic, as well as traffic from UDP-based applications, need to be examined.

The following section reviews the salient design principles of current AQM schemes and discusses the major algorithms that have been proposed. Section 3 presents our experimental methodology and discusses the generation of synthetic web traffic. Section 4 presents our results for AQM with packet drops, and Section 5 presents our results for AQM with ECN. The results are discussed in Section 6. We conclude in Section 7 with a summary of our major results.

## 2. Background and Related Work

### 2.1 Original RED Design

The original RED design uses a weighted-average queue size as a measure of congestion. When this weighted average is below a minimum threshold (minth), no packets are marked or dropped. When the average queue length is between the minimum and maximum thresholds (maxth), the probability of marking or dropping packets varies linearly between 0 and a maximum drop probability (maxp, typically 0.10). If the average queue length exceeds maxth, all packets are marked or dropped. A modification to the original design introduced a "gentle mode" in which the mark or drop probability increases linearly between maxp and 1 as the average queue length varies between maxth and 2 x maxth. This fixes a problem in the original RED design caused by the non-linearity in drop probability (increasing from maxp to 1.0 immediately when maxth is reached).

### 2.2 Limitations of RED

A weakness of RED is that it does not consider the number of flows sharing a bottleneck link [5]. Given the TCP congestion control mechanism, a packet mark or drop reduces the offered load by a factor of (1 – 0.5n-1), where n is the number of flows sharing the bottleneck link. Thus, RED is not effective in controlling the queue length when n is large. On the other hand, RED can be too aggressive and can cause under-utilization of the link when n is small. Feng et al. concluded that RED needs to be tuned for the dynamic characteristics of the aggregate traffic on a given link [5]. They proposed a self-configuring algorithm for RED by adjusting maxp every time the average queue length falls out of the target range between minth and maxth. When the average queue length is smaller than minth, maxp is decreased multiplicatively to reduce RED’s aggressiveness in marking or dropping packets; when the queue length is larger than maxth, maxp is increased multiplicatively. Floyd et al. improved upon this original adaptive RED proposal by replacing the MIMD (multiplicative increase multiplicative decrease) approach with an AIMD (additive increase multiplicative decrease) approach [6]. They also provided guidelines for choosing minth, maxth, and the weight for computing a target average queue length. The RED version that we implemented and studied in our work (referred to herein as “ARED”) includes both the adaptive and gentle refinements to the original design. It is based on the description given in [6].

### 2.3 Control-Theoretic Approaches

In [11], Misra et al. applied control theory to develop a model for TCP and AQM dynamics and used this model to analyze RED. They pointed out two limitations in the original RED design: (1) RED is either unstable or has slow responses to changes in network traffic, and (2) RED’s use of a weighted-average queue length to detect congestion and its use of loss probability as a feedback signal to the senders are flawed. Because of this, in overload situations, flows can suffer both high delay and a high packet loss rate. Hollot et al. simplified the TCP/AQM model to a linear system and designed a Proportional Integrator (PI) controller that regulates the queue length to a target value called the “queue reference,” qref [8]. The PI controller uses instantaneous samples of the queue length taken at a constant sampling frequency as its input. The drop probability is computed as:

\[ p(kT) = a \times (q(kT) - q_{\text{ref}}) - b \times (q((k-1)T) - q_{\text{ref}}) + p((k-1)T) \]

where \( p(kT) \) is the drop probability at the kth sampling interval, \( q(kT) \) is the instantaneous sample of the queue length, and \( T \) is 1/sampling-frequency. A close examination of this equation shows that the drop probability increases in sampling intervals when the queue length is higher than its target value. Furthermore, the drop probability also increases if the queue has grown since the last sample (reflecting an increase in network traffic). Conversely, the drop probability in a PI controller is reduced when the queue length is lower than its target value or the queue length has decreased since its last sample. The sampling interval and the coefficients in the equation depend on the link capacity, the maximum RTT, and the expected number of active flows using the link.

### 2.4 Random Exponential Marking (REM)

In [2], Athuraliya et al. proposed the Random Exponential Marking (REM) AQM scheme. REM periodically updates a congestion measure called “price” that reflects any mismatch between packet arrival and departure rates at the link (i.e., the difference between the demand and the service rate) and any queue size mismatch (i.e., the difference between the actual queue length and its target value). The measure (p) is computed by:

\[ p(t) = \max(0, p(t-1) + \gamma \times (\alpha \times (q(t) - q_{\text{ref}})) + x(t) - c) \]

where \( c \) is the link capacity (in packet departures per unit time), \( p(t) \) is the congestion measure, \( q(t) \) is the queue length, and \( x(t) \) is the packet arrival rate, all determined at time \( t \). As with ARED and PI, the control target is only expressed by the queue size.

The mark/drop probability in REM is defined as \( \text{prob}(t) = 1 - \phi^{-p(t)} \), where \( \phi > 1 \) is a constant. In overload situations, the congestion price increases due to the rate mismatch and the queue mismatch. Thus, more packets are dropped or marked to signal TCP senders to reduce their transmission rate. When congestion abates, the congestion price is reduced because the mismatches are now negative. This causes REM to drop or mark fewer packets and allows the senders to potentially increase their transmission rate. It is easy to see that a positive rate mismatch over a time interval will cause the queue size to increase. Conversely, a negative rate mismatch over a time interval will drain the queue. Thus, REM is similar to PI because the rate mismatch can be detected by comparing the instantaneous queue length with its previous sampled value. Furthermore, when the drop or mark probability is small, the exponential function can be approximated by a linear function [1].

## 3. Experimental Methodology

For our experiments, we constructed a laboratory network that emulates the interconnection between two Internet service provider (ISP) networks. Specifically, we emulated one peering link that carries web traffic between sources and destinations on both sides of the peering link, with the traffic carried between the two ISP networks evenly balanced in both directions.

The laboratory network used to emulate this configuration is shown in Figure 1. All systems shown in this figure are Intel-based machines running FreeBSD 4.5. At each edge of this network are a set of 14 machines that run instances of a web request generator (described below) each of which emulates the browsing behavior of thousands of human users. Also at each edge of the network is another set of 8 machines that run instances of a web response generator (also described below) that creates the traffic flowing in response to the browsing requests. A total of 44 traffic-generating machines are in the testbed. In the remainder of this paper, we refer to the machines running the web request generator simply as the “browser machines” (or “browsers”) and the machines running the web response generator as the “server machines” (or “servers”). The browser and server machines have 100 Mbps Ethernet interfaces and are attached to switched VLANs with both 100 Mbps and 1 Gbps ports on 3Com 10/100/1000 Ethernet switches.

At the core of this network are two router machines running the ALTQ extensions to FreeBSD. ALTQ extends IP-output queuing at the network interfaces to include alternative queue-management disciplines [10]. We used the ALTQ infrastructure to implement PI, REM, and ARED. The routers are 1 GHz Pentium IIIs with over 1 GB of memory. Each router has one 1000-SX fiber Gigabit Ethernet NIC attached to one of the 3Com switches. Each router also has three additional Ethernet interfaces (a second 1000-SX fiber Gigabit Ethernet NIC and two 100 Mbps Fast Ethernet NICs) configured to create point-to-point Ethernet segments that connect the routers as shown in Figure 1. When conducting measurements to calibrate the traffic generators on an un-congested network, static routes are configured on the routers so that all traffic uses the full-duplex Gigabit Ethernet segment. When we need to create a bottleneck between the two routers, the static routes are reconfigured so that all traffic flowing in one direction uses one 100 Mbps Ethernet segment and all traffic flowing in the opposite direction uses the other 100 Mbps Ethernet segment. These configurations allow us to emulate the full-duplex behavior of a typical wide-area network link.

Another important factor in emulating this network is the effect of end-to-end latency. We use a locally-modified version of the dummynet [9] component of FreeBSD to configure outbound packet delays on browser machines to emulate different round-trip times on each TCP connection (giving per-flow delays). This is accomplished by extending the dummynet mechanisms for regulating per-flow bandwidth to include a mode for adding a randomly-chosen minimum delay to all packets from each flow. The same minimum delay is applied to all packets in a given flow (identified by IP addressing 5-tuple). The minimum delay in milliseconds assigned to each flow is sampled from a discrete uniform distribution on the range [10, 150] (a mean of 80 milliseconds). The minimum and maximum values for this distribution were chosen to approximate a typical range of Internet round-trip times within the continental U.S., and the uniform distribution ensures a large variance in the values selected over this range. We configured the dummynet delays only on the browser’s outbound packets to simplify the experimental setup. Most of the data transmitted in these experiments flow from the server to the browser, and the TCP congestion control loop at the server (the one AQM causes to react) is influenced by the total RTT, not by asymmetry in the delays relative to the receiver’s side. Because these delays at the browsers effectively delay the ACKs received by the servers, the round-trip times experienced by the TCP senders (servers) will be the combination of the flow’s minimum delay and any additional delay introduced by queues at the routers or on the end systems. (End systems are configured to ensure no resource constraints were present, hence delays there are minimal, ~1 millisecond.) A TCP window size of 16K bytes was used on all the end systems because widely used OS platforms, e.g., most versions of Windows, typically have default windows this small or smaller.

The instrumentation used to collect network data during experiments consists of two monitoring programs. One program monitors the router interface where we are examining the effects of the AQM algorithms. It creates a log of the queue size (number of packets in the queue) sampled every 10 milliseconds along with complete counts of the number of packets entering the queue and the number dropped. Additionally, a link-monitoring machine is connected to the links between the routers (through hubs on the 100 Mbps segments or fiber splitters on the Gigabit link). It collects (using a locally-modified version of the tcpdump utility) the TCP/IP headers in each frame traversing the links and processes these in real-time to generate detailed statistics.

## 4. Results for AQM with Packet Drops

[Insert detailed results and analysis for AQM with packet drops]

## 5. Results for AQM with ECN

[Insert detailed results and analysis for AQM with ECN]

## 6. Discussion

[Insert detailed discussion of the results, including comparisons and implications]

## 7. Conclusion

[Insert a summary of the major results and conclusions, and any future work or recommendations]

---

**Figure 1: Experimental Network Setup**

[Insert Figure 1 with a detailed caption explaining the setup]

---

**Acknowledgments**

[Insert acknowledgments, if any]

---

**References**

[Insert references in the appropriate format]

---

**Permissions**

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.

SIGCOMM’03, August 25–29, 2003, Karlsruhe, Germany.
Copyright 2003 ACM 1-58113-735-4/03/0008…$5.00.