on the same key. The reader client runs on the smaller t1.micro
instance with 2GHz Intel Xeon E5-2650 cores and 600MB of
memory. We set ǫ to be 100ms, δ to be 5ms, TA = 500ms
and vary TS between 0.5 and 3 seconds, taking the average
over 5 runs. We also log the time of every Put and Get and
perform an ofﬂine analysis to extract the ground truth (GT)
number of TCaelus and TS violations. We then plot the results
in Figure 5. As stated by its guarantees, Caelus detects all
TCaelus violations and some but not all TS violations. As the
TS increases, more operations are replicated by S3 in time,
resulting in fewer true and detected violations.
In Figure 6, we hold TS ﬁxed at 0.5 seconds while varying
TA between 0.5 and 3 seconds. The number of true violations
of TS stays the same, but the number of true TCaelus violations
and those detected by Caelus decreases as TA increases,
illustrating how a larger TA decreases Caelus’ ability to detect
TS violations.
Fig. 6. Percentage of Gets with consistency violations on S3 as a function
of TA.
CONSISTENCY VERIFICATION PERFORMANCE ON A PC.
TABLE I
Attest
(µs)
85.7±2.02
85.7±2.02
67.5±2.26
67.5±2.26
97.6±2.88
97.6±2.88
Presence
(µs)
399.25±11.64
402.38±26.08
392.59±12.57
410.78±8.45
307.44±16
319.03±8.15
Consistency
(µs)
86.1±13.21
9.52±2.19
17.79±2.71
18.47±6.68
595.69±50.43
2.7±1.75
Strong-Get
Strong-Put
Eventual-Get
Eventual-Put
Causal-Get
Causal-Put
B. Client veriﬁcation costs
Since Caelus veriﬁcation operations occur asynchronously,
they are not on the critical path of any Put or Get op-
erations and thus do not affect
the performance of these
operations. However, Caelus does increase CPU utilization as
both veriﬁcation and attestation contain cryptographic (2048
bit RSA with SHA256) and logical computations. We evaluate
the computational costs of the different consistency model
veriﬁcation procedures by running them against our strong
consistency prototype. The strong consistency server never
causes consistency violations and evaluates the worst case
computational costs because operations must pass all tests to
verify correctly while Caelus will not perform any further
checks on an operation once it detects that an operation
violates consistency.
We measure the time to perform veriﬁcations on both a PC
with 3.4GHz Intel i7-2600 Processor and 16GB of memory
and on a rooted stock Google Nexus 5 phone with 2.3GHz
processor and a 2300 mAh battery. We run measurements
in our lab to minimize network variability, and therefore
machines are connected to a local Caelus service also in
our lab. We run YCSB [31] with a 50/50 mix of Put and
Get operations with no delay between operations on both
machines, resulting in an applied workload of 26 ops/s. TA
CONSISTENCY VERIFICATION PERFORMANCE ON A SMARTPHONE.
TABLE II
Attest
(ms)
Presence
Consistency
(ms)
(ms)
1.49±0.06
1.49±0.06
1.40±0.12
1.40±0.12
1.75±0.13
1.75±0.13
2.24±0.33
2.15±0.14
1.91±0.11
2.22±0.11
1.79±0.13
2.18±0.09
0.05±0.03
0.01±0.01
0.74±0.22
0.03±0.01
2.53±0.39
0.022±0.01
Strong-Get
Strong-Put
Eventual-Get
Eventual-Put
Causal-Get
Causal-Put
892
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:39 UTC from IEEE Xplore.  Restrictions apply. 
BATTERY SAVINGS AND PERCENTAGE TIME SLEEPING COMPARISON
BATTERY DRAIN AND AVERAGE CPU FREQUENCY OF AN ACTIVE PHONE
BETWEEN WHEN PHONE ACTS AS AN ATTESTOR AND WHEN
WITH AND WITHOUT THE ATTESTOR ROLE.
TABLE III
TABLE IV
ATTESTOR-PARTITIONING IS USED.
Idle
Single Attestor (WiFi)
Single Attestor (LTE)
Root Attestor (WiFi)
Root Attestor (LTE)
Battery (mAh)
Sleeping (%)
20.85
90.2
90.29
22.57
22.57
98.5
0
0
98.3
97.7
is set to 1 second and we take the average over 5 runs.
The per-operation cost of the individual steps in the ver-
iﬁcation procedure are tabulated for the PC in Table I and
for the Nexus 5 in Table II. The consistency column records
the cost of all the model-speciﬁc consistency checks, which
are generally fast with the exception of Gets under causal
consistency. This check requires an iterative search through
the log to ﬁnd all operations with vector clocks between the
Get and matching Put. Cryptographic operations are main
source of overhead for Caelus. Out of the three components of
the veriﬁcation operation, the presence check component dom-
inates the overall cost because there is a public-key signature
veriﬁcation performed on each operation in the log segment.
These relative trends hold on both the PC and the Nexus 5,
except that the PC is roughly 5-18× faster at cryptographic
operations, which is to be expected. We also evaluate the
cost of performing the signing operations and attestations and
found that they are dominated by the cost of the RSA signature
operation, which takes about 11ms on the PC and 60ms on
the Nexus 5 regardless of the type of operation being signed.
Overall, the cost of Caelus operations is not high and we
ﬁnd that these operations take about 8.8-16.4% of CPU time
on our test devices. Currently, our Caelus prototype signs and
veriﬁes individual cloud operations and this makes up the bulk
of the CPU overhead. Batching signing cloud operations would
reduce both the number of signatures and veriﬁcations and thus
reduce the CPU overhead of Caelus.
C. Phone battery consumption
When regular Caelus client devices have no operations to
perform on the cloud service, they can perform a client leave
and go to sleep, so Caelus imposes no battery cost on normal
client devices. The only devices that have additional duties in
Caelus even if they have no operations to perform is the RA
and the AA. We thus measure the battery impact on the RA
when it could be otherwise idle. In addition, recall that the RA
should select an AA that is already awake, so we also measure
the battery impact of Caelus on an AA that is running other
tasks.
We used the same phone we used for veriﬁcation cost
measurement. We use battery level readings from the OS and
the percentage of time the phone spends sleeping to measure
the beneﬁts of attestor-partitioning. To get a baseline, we
ﬁrst perform measurements on an idle phone in its default
conﬁguration with basic services and applications running and
background synchronization disabled. We then compare this
Active Attestor (WiFi)
Active Attestor (LTE)
No Caelus (WiFi)
No Caelus (LTE)
Battery (mAh)
CPU (GHz)
431.01
433.87
366.17
343.66
1.66
1.52
1.64
1.61
NETWORK BANDWIDTH CONSUMED BY CAELUS OPERATIONS.
TABLE V
Operation
Read_History
Write_Attest
Read_Attest
Select
Cost (Bytes)
1411 + 1087 × |P uts| + 695 × |Gets|
756
2582 + 1087 × |P uts| + 695 × |Gets|
1421
to the battery consumption of the phone acting as a single
attestor in the basic system and Root Attestor using attestor-
partitioning. For these experiments, we have clients run a
simulated image browsing and editing workload with a mix
of random 330 Gets and 30 Puts of 1MB values every 30
minutes. TA is set to 1 second and TR is set to 5 min. We
perform measurements when the phone is on a WiFi network
and a cellular LTE network. We run each experiment for at
least 30 minutes, or longer until workload is ﬁnished, and
normalize the results to a 30 minute period in Table III. Our
battery consumption measurement tool rounds up to the near-
est percentage of battery capacity (i.e. 23 mAh). The results
show that attestor-partitioning has negligible battery use over
a completely idle phone with only a slight increase in battery
usage and a slight decrease in time spent sleeping. However,
compared to the phone acting as a single attestor, running as
an RA with attestor-partitioning reduces the additional battery
drain over an idle phone by about 40×.
In cases where a device is acting as an AA, the device is
assumed to be running some other workload that prevents it
from sleeping. To evaluate the battery impact on such a device,
we run the same image viewing workload as above on the
phone. To simulate UI events, we use the monkey tool, which
generates random UI events. We compare the battery drain
and average CPU frequency when the phone is acting as an
Active Attestor with when Caelus on the phone is completely
disabled and tabulate the results in Table IV. To isolate the
cost of Caelus components, fetching and verifying attestations
is disabled in all ”No Caelus” cases. The results show that
acting as an attestor on an active phone adds roughly a 17-
26% increase in battery consumption.
D. Network cost
On top of existing Get and Put operations, Caelus adds
operations that fetch log segments, read and write attestations,
as well as assigning the attestor role through select operation
– all of which consume network bandwidth. To measure this
cost, we measure the amount of data before it is encoded
by XML-RPC. Because XML-RPC transmits data in ASCII,
it Base64 encodes encrypted binary data, which adds about
1.5× overhead. Using a binary packet format in our prototype
893
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:39 UTC from IEEE Xplore.  Restrictions apply. 
would have avoided this unnecessary artifact. We note that this
measurement method also doesn’t take into account transport
protocol overhead, but these costs are well understood (usually
about 40-60 bytes per packet).
Table V gives the cost of various Caelus control operations.
Note that the cost of Read_History and Write_History
operations depend on the number of Put and Get opera-
tions that are attested as this affects the size of the history
log segment that is read. For the image browsing workload
in the previous section, the client uses about 1.14MB on
Read_Attest messages, the AA uses about 3.65MB on
Read_History and Write_Attest messages and the
phone uses about 8.33KB on selection messages. When
amortized over the 360MB of data transferred in the workload,
this works out to about 13KB of network bandwidth overhead
per megabyte of transferred data or about 1.3%. While these
costs are fairly small, they are actually smaller in practice
since they only exist if clients are active and using the cloud
service. If the cloud service is not being used, the clients use
no network bandwidth at all.
VIII. RELATED WORK
The most closely related works to Caelus are SUNDR [3],
BFT2F [8], and CloudProof [9]. All of these systems provide
consistency and integrity guarantees for untrusted storage
systems to clients who do not communicate directly with
each other. SUNDR only guarantees fork consistency, while
BFT2F weakens fork consistency to fork*. Other work has
also extending SUNDR’s contribution on fork-linearizability to
computations on untrusted services [32], [33]. Both fork, fork*
and fork-linearizability are weaker than any of the consistency
models that Caelus can guarantee in that they permit some
operations to be forever unknown to some clients. CloudProof
can verify strong consistency, but requires information from
clients to be assembled at an “auditor”. Because the auditor
is not always online, auditing is retroactive instead of in real
time. Caelus uses a smartphone to make auditing real-time and
distributes the auditing work to minimize the impact on the
smartphone battery.
Depot [4], SPORC [5] and Venus [6] provide consistency
guarantees using client-to-client communication. Client-to-
client communication simpliﬁes the problem because clients
may implement their own replication policy and thus enforce a
consistency model independent of the cloud service provider.
However, client-to-client communication is either inefﬁcient
for battery-powered devices, or it requires a trusted service
that can buffer and multicast messages so that clients need
not waste battery on network bandwidth or need not be
simultaneously awake to communicate. Caelus avoids these by