The read/append and create/delete biases were set to 5, and we
conﬁgured Postmark to use buffered ﬁle I/O. We ran Postmark
on the SSD since it has lower latency and less variability in
its latency than the hard disk. Each run of the experiment
performed 500,000 transactions. We ran the experiment 20
times on both the native FreeBSD kernel and the KCoFI
system. Table VIII shows the average results.
As Table VIII shows, the Postmark overheads are close to
the LMBench ﬁle creation overheads.
IX. RELATED WORK
Abadi et. al. [4] introduced the deﬁnition of control-ﬂow
integrity and proved that
their approach enforced context-
insensitive control-ﬂow integrity. Our proof for the KCoFI
design uses a similar approach but also demonstrates how
control-ﬂow integrity is preserved during OS operations that
can have complex, often unanalyzable,
impact on control
ﬂow, including context switching, MMU conﬁguration, signal
handler dispatch, and interrupts.
Zhang and Sekar’s BinCFI [10] and Zhang et. al.’s CC-
FIR [32] transform binary programs to enforce CFI. Similarly,
Strato [9] modiﬁes the LLVM compiler to instrument code
with CFI checks similar to those used by KCoFI. None of
these techniques can protect against ret2usr attacks since they
ﬁnd the targets of control-ﬂow transfers via static analysis.
KCoFI does not verify that its instrumentation is correct like
Strato does [9]. However, KCoFI can incorporate Strato’s
instrumentation veriﬁcation techniques.
RockSalt [33] is a veriﬁed veriﬁer for Google’s Native
Client [34]; the veriﬁer ensures that Native Client x86 machine
code enforces sandboxing and control-ﬂow integrity properties
and has been proven correct via formal proof. Native Client’s
CFI policy [34] only requires that the x86 segment registers be
left unmodiﬁed and that branches jump to aligned instructions;
its CFI policy is therefore less restrictive than KCoFI’s policy,
305
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:09 UTC from IEEE Xplore.  Restrictions apply. 
and it does not permit code to perform the myriad of operations
that an OS kernel must be able to perform.
The Secure Virtual Architecture [12], [5] provides strong
control-ﬂow integrity guarantees. However, it also enforces
very strong memory safety properties and sound points-to
analysis; this required the use of whole-program pointer anal-
ysis [13] which is challenging to implement. SafeDrive [35]
also enforces memory safety on commodity OS kernel code.
However, SafeDrive requires the programmer to insert annota-
tions indicating where memory object bounds information can
be located. These annotations must be updated as the code is
modiﬁed or extended.
HyperSafe [6] enforces control-ﬂow integrity on a hy-
pervisor. Like SVA [5], HyperSafe vets MMU translations
to protect the code segment and interrupt handler tables; it
also introduces a new method of performing indirect function
call checks. HyperSafe, however, does not protect the return
address in interrupted program state, so it does not fully
implement CFI guarantees and does not prevent ret2usr attacks.
Furthermore, HyperSafe only protects a hypervisor, which
lacks features such as signal handler delivery; KCoFI protects
an entire commodity operating system kernel.
kGuard [11] prevents ret2usr attacks by instrumenting
kernel code to ensure that
indirect control ﬂow transfers
move control ﬂow to a kernel virtual address; it also uses
diversiﬁcation to prevent attacks from bypassing its protection
and to frustrate control-ﬂow hijack attacks. KCoFI uses similar
bit-masking as kGuard to prevent user-space native code from
forging kernel CFI labels. kGuard also uses diversiﬁcation
to prevent their instrumentation from being bypassed, which
provides probabilistic protection against ROP attacks (with
relatively low overhead), whereas KCoFI provides a CFI
guaranty and ensures that the kernel’s code segment is not
modiﬁed.
Giuffrida et. al. [36] built a system that uses ﬁne-grained
randomization of the kernel code to protect against memory
safety errors. Their system’s security guarantees are prob-
abilistic while our system’s security guarantees are always
guaranteed. Additionally, their prototype has only been applied
to Minix while ours has been applied to a heavily used, real-
world operating system (FreeBSD).
SecVisor [37] prevents unauthorized code from executing
in kernel space but does not protect loaded code once it is
executing. Returnless kernels [38] modify the compiler used
to compile the OS kernel so that the kernel’s binary code does
not contain return instructions. Such kernels may still have
gadgets that do not utilize return instructions [26].
The seL4 [39] microkernel is written in a subset of C and
both the design and implementation are proven functionally
correct, using an automated proof assistant. The proof ensures
that the code does not have memory safety errors that alter
functionality [39]. While seL4 provides stronger security guar-
antees than KCoFI, it only provides them to the microkernel
while KCoFI provides its guarantees to a commodity OS kernel
of any size. Changes to the seL4 code must be correct and
require manual updates to the correctness proof [39] while
KCoFI can automatically reapply instrumentation after kernel
changes to protect buggy OS kernel code.
Several operating systems provide control-ﬂow integrity
by virtue of being written in a memory-safe programming
language [40], [41], [42], [43], [44]. Verve [44], the most
recent, is a kernel written in a C#-like language that sits upon
a hardware abstraction layer that has been veriﬁed to maintain
the heap properties needed for memory safety. While KCoFI
can enforce control-ﬂow integrity, its implementation is not
veriﬁed like Verve’s hardware abstraction layer.
X. FUTURE WORK
There are several plans for future work. First, we plan
to investigate improvements to KCoFI’s speed and efﬁcacy.
For example, using separate stacks for control-data and local
variables could both improve performance and enforce a more
restrictive context-sensitive CFI policy. We also plan to do
much more low-level tuning of the system’s performance than
we have done; there is room for extensive improvement.
Second, we plan to ﬁnish the control ﬂow integrity proof
in Section V so that
it proves that control ﬂow integrity
is maintained across the transitive closure of the transition
relation. Furthermore, we plan to enhance the formal model to
include more features (such as user-space application support).
Third, we plan to investigate building a veriﬁed implemen-
tation of KCoFI. Similar work has been done with operating
systems written in safe languages [44]; while an ambitious
goal, doing the same for existing commodity operating systems
could help uncover implementation bugs and would increase
conﬁdence in the system’s security.
XI. CONCLUSIONS
In this paper, we presented KCoFI: a system which pro-
vides comprehensive control ﬂow integrity to commodity oper-
ating systems. We have shown that KCoFI provides protection
to OS kernel code similar to that found for user-space code
with better overheads than previously developed techniques
for commodity OS kernels. Essentially, KCoFI uses traditional
label-based protection for programmed indirect jumps but adds
a thin run-time layer linked into the OS that protects key OS
kernel data like interrupted program state and monitors all
low-level state manipulations performed by the OS. We have
provided a partial proof that KCoFI’s design correctly enforces
CFI, adding conﬁdence in the correctness of our system.
ACKNOWLEDGMENTS
The authors would like to thank Bin Zeng, Gang Tan, and
Greg Morrisett for sharing their x86 CFI instrumentation pass
with us. The authors also thank the FreeBSD community for
providing a commodity OS that compiles with LLVM/Clang.
This material is based upon work supported by the AFOSR
under MURI award FA9550-09-1-0539. Additional support
was provided by the Ofﬁce of Naval Research under Award
No. N000141210552 and by NSF grant CNS 07-09122.
REFERENCES
[1] AlephOne, “Smashing the stack for fun and proﬁt.” [Online]. Available:
http://www.fc.net/phrack/ﬁles/p49/p49-14
[2] Solar
Designer,
http://www.securityfocus.com/archive/1/7480.
“return-to-libc
attack,”
August
1997,
306
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:09 UTC from IEEE Xplore.  Restrictions apply. 
[3] R. Roemer, E. Buchanan, H. Shacham, and S. Savage, “Return-oriented
programming: Systems, languages, and applications,” ACM Trans. Inf.
Syst. Secur., vol. 15, no. 1, pp. 2:1–2:34, Mar. 2012.
[4] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-ﬂow
integrity principles, implementations, and applications,” ACM Trans.
Inf. Syst. Secur., vol. 13, pp. 4:1–4:40, November 2009.
J. Criswell, N. Geoffray, and V. Adve, “Memory safety for low-
level software/hardware interactions,” in Proceedings of the Eighteenth
Usenix Security Symposium, August 2009.
[5]
[6] Z. Wang and X. Jiang, “Hypersafe: A lightweight approach to provide
lifetime hypervisor control-ﬂow integrity,” vol. 0. Los Alamitos, CA,
USA: IEEE Computer Society, 2010.
[7] D. P. Bovet and M. Cesati, Understanding the LINUX Kernel, 2nd ed.
Sebastopol, CA: O’Reilly, 2003.
[8] M. K. McKusick, K. Bostic, M. J. Karels, and J. S. Quarterman,
The Design and Implementation of the 4.4 BSD Operating System.
Redwood City, CA: Addison-Wesley Publishing Company, Inc., 1996.
[9] B. Zeng, G. Tan, and U. Erlingsson, “Strato: a retargetable framework
for low-level inlined-reference monitors,” in Proceedings of the 22nd
USENIX conference on Security, ser. SEC’13. Berkeley, CA, USA:
USENIX Association, 2013, pp. 369–382.
[10] M. Zhang and R. Sekar, “Control ﬂow integrity for COTS binaries,” in
Proceedings of the 22nd USENIX conference on Security, ser. SEC’13.
Berkeley, CA, USA: USENIX Association, 2013, pp. 337–352.
[11] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis, “kGuard:
lightweight kernel protection against returntouser attacks,” in Proceed-
ings of the 21st USENIX conference on Security symposium. Berkeley,
CA, USA: USENIX Association, 2012.
J. Criswell, A. Lenharth, D. Dhurjati, and V. Adve, “Secure Virtual
Architecture: A Safe Execution Environment for Commodity Operat-
ing Systems,” in Proc. ACM SIGOPS Symp. on Op. Sys. Principles,
Stevenson, WA, USA, October 2007.
[12]
[13] C. Lattner, A. D. Lenharth, and V. S. Adve, “Making context-sensitive
points-to analysis with heap cloning practical for the real world,” in
ACM SIGPLAN Conference on Programming Language Design and
Implementation, San Diego, CA, USA, June 2007, pp. 278–289.
J. Salwan and A. Wirth. [Online]. Available: http://shell-storm.org/
project/ROPgadget
[14]
[15] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-control-
data attacks are realistic threats,” in 14th USENIX Security Symposium,
August 2004, pp. 177–192.
[16] W. A. Arbaugh, D. J. Farber, and J. M. Smith, “A secure and reliable
bootstrap architecture,” in Security and Privacy, 1997. Proceedings.,
1997 IEEE Symposium on.
I. Uniﬁed EFI, “Uniﬁed extensible ﬁrmware interface speciﬁcation:
Version 2.2d,” November 2010.
IEEE, 1997, pp. 65–71.
[17]
[18] B. Zeng, G. Tan, and G. Morrisett, “Combining control-ﬂow integrity
and static analysis for efﬁcient and validated data sandboxing,” in Pro-
ceedings of the 18th ACM conference on Computer and communications
security, ser. CCS ’11. New York, NY, USA: ACM, 2011, pp. 29–40.
J. Criswell, B. Monroe, and V. Adve, “A virtual instruction set interface
for operating system kernels,” in Workshop on the Interaction between
Operating Systems and Computer Architecture, Boston, MA, USA, June
2006, pp. 26–33.
[19]
[20] C. Lattner and V. Adve, “LLVM: A compilation framework for lifelong
program analysis and transformation,” in Proc. Conf. on Code Gener-
ation and Optimization, San Jose, CA, USA, Mar 2004, pp. 75–88.
[21] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham, “Efﬁcient
software-based fault isolation,” in Proceedings of the Fourteenth ACM
Symposium on Operating Systems Principles, ser. SOSP ’93. New
York, NY, USA: ACM, 1993.
[22] The Coq Development Team, “The Coq proof assistant reference
manual (version 8.3),” 2010, http://coq.inria.fr/refman/index.html.
[23] D. A. Wheeler, “SLOCCount,” 2014.
[Online]. Available: http:
[24]
[25]
//www.dwheeler.com/sloccount/
Intel 64 and IA-32 architectures software developer’s manual.
2012, vol. 3.
J. Criswell, N. Dautenhahn, and V. Adve, “Virtual Ghost: Protecting
applications from hostile operating systems,” in Proceedings of the
Intel,
Nineteenth Internantional Conference on Architectural Support
Programming Languages and Operating Systems, March 2014.
for
[26] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,
and M. Winandy, “Return-oriented programming without returns,” in
Proceedings of the 17th ACM conference on Computer and communi-
cations security, ser. CCS ’10. New York, NY, USA: ACM, 2010.
[27] Postmark, “Email delivery for web apps,” July 2013.
Available: https://postmarkapp.com/
[Online].
ser. ATEC ’96.
[28] L. McVoy and C. Staelin, “lmbench: portable tools for performance
analysis,” in Proceedings of the 1996 annual conference on USENIX
Annual Technical Conference,
Berkeley, CA,
USA: USENIX Association, 1996, pp. 23–23. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1268299.1268322
J. Poskanze,
tiny/turbo/throttling http server,” 2000,
http://www.acme.com/software/thttpd. [Online]. Available: http://www.
acme.com/software/thttpd
“Apachebench: A complete benchmarking and regression testing suite.
http://freshmeat.net/projects/ apachebench/,” July 2003.
“thttpd -
[29]
[30]
[31] T. O. Project, “Openssh,” 2006, http://www.openssh.com. [Online].
Available: http://www.openssh.com
[32] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and randomiza-
tion for binary executables,” in Security and Privacy (SP), 2013 IEEE
Symposium on, 2013, pp. 559–573.
[33] G. Morrisett, G. Tan, J. Tassarotti, J.-B. Tristan, and E. Gan, “Rocksalt:
better, faster, stronger sﬁ for the x86,” in Proceedings of the 33rd
ACM SIGPLAN conference on Programming Language Design and
Implementation, ser. PLDI ’12. New York, NY, USA: ACM, 2012,
pp. 395–404.
[34] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,
S. Okasaka, N. Narula, and N. Fullagar, “Native client: a sandbox for
portable, untrusted x86 native code,” Commun. ACM, vol. 53, no. 1, pp.
91–99, Jan. 2010.
[35] F. Zhou, J. Condit, Z. Anderson, I. Bagrak, R. Ennals, M. Harren,
G. Necula, and E. Brewer, “Safedrive: Safe and recoverable extensions
using language-based techniques,” in USENIX Symposium on Operating
System Deisgn and Implementation, Seattle, WA, USA, November 2006,
pp. 45–60.
[36] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operat-
ing system security through efﬁcient and ﬁne-grained address space
randomization,” in Proceedings of the 21st USENIX conference on
Security symposium, ser. Security’12. Berkeley, CA, USA: USENIX
Association, 2012.
[37] A. Seshadri, M. Luk, N. Qu, and A. Perrig, “Secvisor: A tiny hypervisor
to provide lifetime kernel code integrity for commodity oses,” in
Proceedings of Twenty-ﬁrst ACM SIGOPS Symposium on Operating
Systems Principles, ser. SOSP ’07. New York, NY, USA: ACM, 2007.
J. Li, Z. Wang, X. Jiang, M. Grace, and S. Bahram, “Defeating return-
oriented rootkits with ”return-less” kernels,” in Proceedings of the 5th
European conference on Computer systems, ser. EuroSys ’10. New
York, NY, USA: ACM, 2010.
[38]
[39] G. Klein et al., “seL4: formal veriﬁcation of an OS kernel,” in Pro-
ceedings of the ACM SIGOPS 22nd symposium on Operating systems
principles, ser. SOSP ’09. New York, NY, USA: ACM, 2009.
[40] B. Bershad, S. Savage, P. Pardyak, E. G. Sirer, D. Becker, M. Fiuczyn-
ski, C. Chambers, and S. Eggers, “Extensibility, Safety and Performance
in the SPIN Operating System,” in Proc. ACM SIGOPS Symp. on Op.
Sys. Principles, Copper Mountain, CO, USA, 1995.
[41] T. Saulpaugh and C. Mirho, Inside the JavaOS Operating System.
Reading, MA, USA: Addison-Wesley, 1999.
[42] C. Hawblitzel, C.-C. Chang, G. Czajkowski, D. Hu, and T. von Eicken,
“Implementing multiple protection domains in Java,” in USENIX Annual
Technical Conference, Jun. 1998.
[43] M. Golm, M. Felser, C. Wawersich, and J. Kleinoder, “The JX Operating
System,” in Proc. USENIX Annual Technical Conference, Monterey,
CA, USA, June 2002, pp. 45–58.
J. Yang and C. Hawblitzel, “Safe to the last instruction: automated
veriﬁcation of a type-safe operating system,” in Proceedings of the
2010 ACM SIGPLAN conference on Programming language design and
implementation, ser. PLDI ’10. New York, NY, USA: ACM, 2010.
[44]
307
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:09 UTC from IEEE Xplore.  Restrictions apply.