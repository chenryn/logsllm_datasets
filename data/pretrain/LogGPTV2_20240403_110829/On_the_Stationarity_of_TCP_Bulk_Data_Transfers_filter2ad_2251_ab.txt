contains about 25% of points from the ”new” distribution (the distribution after
the change point) up to the moment when the left-size window contains about
25% of points from the ”old” distribution. In practice, a visual inspection of
some samples revealed that using such values for wmin allows to correctly detect
obvious changes in the time series. Figure 3 presents an example on one of our
TCP ﬂows time series (aggregated at a 10 seconds time scale - see next section
for details) along with the scaled binary time series output by the tool and the
change points (vertical bars). This example illustrates the ability of the test to
isolate stationary regions. Note also that the output of the binary time series
that represents the output of the K-S test for each window position (dash line
in ﬁgure 3) exhibits a noticeable consistency. This is encouraging as oscillations
in the output of the test would mean that great care should be taken in the
design of the change point criterion. As this is apparently not the case, we can
expect our simple criterion (wmin consecutive ’1’ values to detect a change) to
be eﬀective.
4.3 K-S Test in the Presence of Correlation
We want to apply the K-S change point tool described in the previous section
to detect changes in the throughput time series described in section 3. However,
we have to pay attention that, due to the close loop nature of TCP, consecutive
one-second throughputs samples are correlated2. If all samples are drawn from
2 While correlation and independence are not the same, we expect that removing cor-
relation will be suﬃcient in our context to obtain some almost independent samples.
32
G. Urvoy-Keller
800
700
600
500
400
300
200
100
s
/
s
t
i
b
k
n
i
t
u
p
h
g
u
o
r
h
T
0
0
50
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
)
0
l
(
F
100
300
Sample index (1 sample=10 seconds)
200
250
150
350
400
0
0
2
4
6
l
0
8
10
12
14
Fig. 3. Initial time series (thin line), binary
time series (dash line) and change points
(thick bars)
Fig. 4. Cumulative distri. function of l0
l0
(cid:1)n−f
i=1 ¯X(i+f) ¯X(i)
, where ¯X(t) (cid:1) X(t) − E[X] and σ2
the same underlying distribution, a simple heuristic to build an uncorrelated
time series out of a correlated time series is to (i) compute the auto-correlation
function of the initial time series, (ii) choose a lag l0 at which correlation is close
enough to zero and (iii) aggregate the initial time series over time intervals of size
l0. Speciﬁcally, let X(t)t∈{1,...n} be the initial time series. Its auto-correlation
function is AC(f) =
¯X is
the variance of ¯X. AC(f) measures the amount of correlation between samples
located at positions t and t + f. If ever the time series is i.i.d., then |AC(f)|
should be upper bounded by 2√
n for f > 1 [6]. For a correlated time series, we can
choose l0 such that ∀f > l0,|AC(f)| ≤ 2√
n. We then generate the aggregate time
series Y (t)t∈{1,...(cid:4) n
. This method is however not
applicable to our TCP time series as changes in the network conditions prevent
us from assuming the same underlying distributions over the whole duration of
a ﬂow.
(cid:5)} where Y (t) =
u=t×l0+1 X(u)
(cid:1)(t+1)×l0
nσ2
¯X
To overcome this diﬃculty and be able to use the K-S test, we aggregate each
time series at a ﬁxed value of l0 = 10. This means that we average the initial
time series over intervals of 10 seconds. As the average throughput of the ﬂows
is 444 kbits/s, an average ﬂow will send more than 400 packets (of size 1500
bytes) in a 10 second time interval, which is reasonably large enough for a TCP
connection to have lost memory of its past history (e.g. to have fully recovered
from a loss). To assess the level of correlation that persists in the time series after
aggregation at the 10 second time scale, we have computed, for each stationary
interval obtained with our tool, the autocorrelation function of the process in
this interval. We then derive the lag l0 after which the autocorrelation function
. Figure 4 represents
remains (for 95% of the cases) in the interval
the cumulative distribution function of l0. We notice that about 95% of the l0
values are below 5, which indicates that the ”remaining” correlation is of short
term kind only.
, 2√
n
− 2√
(cid:2)
(cid:1)
n
l0
On the Stationarity of TCP Bulk Data Transfers
33
Table 2. Change point detection tool performance in the presence of correlation
a w wmin % of cases with one Average number
detection in [450, 550]
of detections
0.2 40 15
0.2 40 40
0.2 80 15
0.2 80 40
0.5 40 15
0.5 40 40
0.5 80 15
0.5 80 40
0.9 40 15
0.9 40 40
0.9 80 15
0.9 80 40
100
100
100
100
100
100
100
100
100
99
89.9
90.7
2.4
1
2.4
1.2
5.6
1.1
4.5
1.9
14.6
6.5
8
5.6
Based on the result of ﬁgure 4, one could however still argue that we should
continue further the aggregation of the time series for which the correlation is
apparently too large, say for l0 ≥ 3. Note however that the choice of the time
scale at which one works directly impacts the separation ability of the K-S test.
Indeed, as we use windows of w samples, a window corresponds to a time interval
of 10 × w seconds, and we won’t be able to observe stationary periods of less
than 10×w seconds. For example, the results presented in section 5 are obtained
with w = 40, which means that we won’t be able to observe stationary periods
of less than 400 seconds (∼ 6.7 minutes). Thus, there exists a trade-oﬀ between
the correlation of the TCP throughput time series that calls for aggregating over
large time intervals and the separation ability of the test that calls for having as
much small windows as possible.
A second reason why we have chosen to aggregate at a ﬁxed 10 second time
scale value is that we expect our tool to be robust in the presence of short term
correlation. We investigate this claim in the next section, on synthetic data,
where we can tune the amount of correlation. While by no means exhaustive,
this method allows us to obtain insights on the behavior of K-S test in the
presence of correlation.
Test of the Robustness of the Tool with Synthetic Data
4.4
We consider a ﬁrst-order auto-regressive process X with X(t) = aX(t − 1) +
Z(t),∀t{1, . . . n} where Z is a purely random process with a ﬁxed distribution.
We choose two distributions for Z (leading to Z1 and Z2) to generate two samples
X1(t) and X2(t). We then form the compound vector [X1(t)X2(t)] and apply
the K-S change point test. We can vary the a parameter to tune the amount
of correlation and test how the K-S change point test behaves. Speciﬁcally, we
consider a ∈ {0.2, 0.5, 0.9} as these values roughly correspond to l0 values (as
deﬁned in the previous section) equal respectively to 2, 5 and 20. With respect
34
G. Urvoy-Keller
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0
200
400
600
800
1000
Fig. 5. Sample trajectory of [X1X2] with the detected change points (vertical bars) for
w = 40 and wmin = 15
to the results presented in ﬁgure 4, we expect the K-S test to behave properly
for a ≤ 0.5 (i.e. l0 ≤ 5). In table 2, we present results obtained when Z1(t) and
Z2(t) are derived from normal distributions with respective means and variances
(0.4, 0.3) and (1.5, 1.5) where a given sample Z1(t) (resp. Z2(t)) is obtained
by averaging 10 independent samples drawn from the normal distribution with
parameters (0.4, 0.3) (resp. (1.5, 1.5)). The main idea behind this averaging phase
is to smooth X1(t) and X2(t) in a similar fashion that the throughput samples
are smoothed at a 10 second time scale in the case of our BitTorrent dataset. As
the transition between X1(t) and X2(t) is sharp thanks to the diﬀerence in mean
between Z1 and Z2, we expect that the change point tool will correctly detect it.
Now, depending on the correlation structure, it might happen that more change
points are detected. This is reﬂected by the results presented in table 2, where for
diﬀerent values of a, w and wmin, we compute over 1000 independent trajectories,
the average number of detections made by the algorithm (without false alarm,
we should obtain 1) and the percentage of cases for which a change is detected in
the interval [450, 550] that corresponds to the border between X1(t) and X2(t)
in the compound vector [X1(t)X2(t)], each vector having a size of 500 samples.
When the latter metric falls below 100%, it indicates that the correlation is such
that our tool does not ncessarily notice the border between X1(t) and X2(t) any
more. From table 2, we note that such a situation occurs only for a = 0.9. Also,
when the amount of correlation increases, the average number of points detected
increases dramatically, as the correlation structure of the process triggers false
alarms as illustrated by the trajectory depicted in ﬁgure 5. For a given w value,
increasing the treshold wmin helps reducing the rate of false. Note that while
the results obtained here on synthetic data seem to be better for a criterion
wmin = 40, we used wmin = 15 on our dataset as it was giving visually better
results. A possible reason is the small variance of the throughput time series as
compared to the corresponding mean for our dataset. More generally, we note
that tuning w and wmin is necessary to tailor the tool to the speciﬁc needs of a
user or an application.
On the Stationarity of TCP Bulk Data Transfers
35
s
e
u
a
V
l
150
100
50
0
−50
−100
700
600
500
400
300
200
100
0
−100
s
e
u
a
V
l
Inter
Intra
Inter
Intra
Fig. 6. Boxplot representation of the inter
jump in mean (left side) and intra jump
in mean (right side)
Fig. 7. Boxplot representation of the inter
jump in standard deviation(left side) and
intra jump in standard deviation (right
side)
Empirical Validation on Real Data
4.5
For the results obtained in this section and the rest of the paper, we used w = 40
as special care must be taken when using the K-S test for smaller values [16].
Also, we consider wmin = 15 as it visually gives satisfying results on our dataset.
In addition, to obtain meaningful results, we restrict the application of the tool
to time series with at 4 × w samples (the tool will thus output at least 2 × w
results), i.e. to ﬂows that last at least 1600 seconds.
1 and µi
Our change point analysis tool can be easily validated with synthetic data.
However, we need to further check whether the results obtained on real traces