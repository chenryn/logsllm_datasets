RAID 5：：性性能能与与数数据据备备份份的的均均衡衡考考虑虑
RAID-5 至少需要三颗以上的磁盘才能够组成这种类型的磁盘阵列。这种磁盘阵列的数据写入有点类似 RAID-0 ， 不过每个循环的写入
过程中 （striping），在每颗磁盘还加入一个同位检查数据 （Parity） ，这个数据会记录其他磁盘的备份数据， 用于当有磁盘损毁时的救援。
RAID-5 读写的情况有点像下面这样：
图14.2.4、RAID-5 的磁盘写入示意图
如上图所示，每个循环写入时，都会有部分的同位检查码 （parity） 被记录起来，并且记录的同位检查码每次都记录在不同的磁盘， 因
此，任何一个磁盘损毁时都能够借由其他磁盘的检查码来重建原本磁盘内的数据喔！不过需要注意的是， 由于有同位检查码，因此 RAID 5 的
总容量会是整体磁盘数量减一颗。以上图为例， 原本的 3 颗磁盘只会剩下 （3-1）=2 颗磁盘的容量。而且当损毁的磁盘数量大于等于两颗
时，这整组 RAID 5 的数据就损毁了。 因为 RAID 5 默认仅能支持一颗磁盘的损毁情况。
在读写性能的比较上，读取的性能还不赖！与 RAID-0 有的比！不过写的性能就不见得能够增加很多！ 这是因为要写入 RAID 5 的数据
还得要经过计算同位检查码 （parity） 的关系。由于加上这个计算的动作， 所以写入的性能与系统的硬件关系较大！尤其当使用软件磁盘阵列
时，同位检查码是通过 CPU 去计算而非专职的磁盘阵列卡， 因此性能方面还需要评估。
另外，由于 RAID 5 仅能支持一颗磁盘的损毁，因此近来还有发展出另外一种等级，就是 RAID 6 ，这个 RAID 6 则使用两颗磁盘的容量
作为 parity 的储存，因此整体的磁盘容量就会少两颗，但是允许出错的磁盘数量就可以达到两颗了！ 也就是在 RAID 6 的情况下，同时两颗磁
盘损毁时，数据还是可以救回来！
Spare Disk：：预预备备磁磁盘盘的的功功能能：：
当磁盘阵列的磁盘损毁时，就得要将坏掉的磁盘拔除，然后换一颗新的磁盘。换成新磁盘并且顺利启动磁盘阵列后， 磁盘阵列就会开始
主动的重建 （rebuild） 原本坏掉的那颗磁盘数据到新的磁盘上！然后你磁盘阵列上面的数据就复原了！ 这就是磁盘阵列的优点。不过，我们
还是得要动手拔插硬盘，除非你的系统有支持热拔插，否则通常得要关机才能这么做。
为了让系统可以实时的在坏掉硬盘时主动的重建，因此就需要预备磁盘 （spare disk） 的辅助。 所谓的 spare disk 就是一颗或多颗没
有包含在原本磁盘阵列等级中的磁盘，这颗磁盘平时并不会被磁盘阵列所使用， 当磁盘阵列有任何磁盘损毁时，则这颗 spare disk 会被主动的
拉进磁盘阵列中，并将坏掉的那颗硬盘移出磁盘阵列！ 然后立即重建数据系统。如此你的系统则可以永保安康啊！若你的磁盘阵列有支持热拔
插那就更完美了！ 直接将坏掉的那颗磁盘拔除换一颗新的，再将那颗新的设置成为 spare disk ，就完成了！
举例来说，鸟哥之前所待的研究室有一个磁盘阵列可允许 16 颗磁盘的数量，不过我们只安装了 10 颗磁盘作为 RAID 5。 每颗磁盘的容
量为 250GB，我们用了一颗磁盘作为 spare disk ，并将其他的 9 颗设置为一个 RAID 5， 因此这个磁盘阵列的总容量为： （9-
1）*250G=2000G。运行了一两年后真的有一颗磁盘坏掉了，我们后来看灯号才发现！ 不过对系统没有影响呢！因为 spare disk 主动的加入支
持，坏掉的那颗拔掉换颗新的，并重新设置成为 spare 后， 系统内的数据还是完整无缺的！嘿嘿！真不错！
磁磁盘盘阵阵列列的的优优点点
说的口沫横飞，重点在哪里呢？其实你的系统如果需要磁盘阵列的话，其实重点在于：
1. 数据安全与可靠性：指的并非网络信息安全，而是当硬件 （指磁盘） 损毁时，数据是否还能够安全的救援或使用之意；
2. 读写性能：例如 RAID 0 可以加强读写性能，让你的系统 I/O 部分得以改善；
3. 容量：可以让多颗磁盘组合起来，故单一文件系统可以有相当大的容量。
尤其数据的可靠性与完整性更是使用 RAID 的考虑重点！毕竟硬件坏掉换掉就好了，软件数据损毁那可不是闹着玩的！ 所以企业界为何
需要大量的 RAID 来做为文件系统的硬件基准，现在您有点了解了吧？那依据这三个重点，我们来列表看看上面几个重要的 RAID 等级各有哪
些优点吧！假设有 n 颗磁盘组成的 RAID 设置喔！
项目 RAID0 RAID1 RAID10 RAID5 RAID6
最少磁盘数 2 2 4 3 4
最大容错磁盘数（1） 无 n-1 n/2 1 2
数据安全性（1） 完全没有 最佳 最佳 好 比 RAID5 好
理论写入性能（2） n 1 n/2  --raid-devices=N --spare-devices=N /dev/sdx /dev/hdx...
选项与参数：
--create ：为创建 RAID 的选项；
--auto=yes ：决定创建后面接的软件磁盘阵列设备，亦即 /dev/md0, /dev/md1...
--chunk=Nk ：决定这个设备的 chunk 大小，也可以当成 stripe 大小，一般是 64K 或 512K。
--raid-devices=N ：使用几个磁盘 （partition） 作为磁盘阵列的设备
--spare-devices=N ：使用几个磁盘作为备用 （spare） 设备
--level=[015] ：设置这组磁盘阵列的等级。支持很多，不过建议只要用 0, 1, 5 即可
--detail ：后面所接的那个磁盘阵列设备的详细信息
上面的语法中，最后面会接许多的设备文件名，这些设备文件名可以是整颗磁盘，例如 /dev/sdb ， 也可以是分区，例如 /dev/sdb1 之
类。不过，这些设备文件名的总数必须要等于 --raid-devices 与 --spare-devices 的个数总和才行！鸟哥利用我的测试机来创建一个 RAID 5 的
软件磁盘阵列给您瞧瞧！ 下面是鸟哥希望做成的 RAID 5 环境：
利用 4 个 partition 组成 RAID 5；
每个 partition 约为 1GB 大小，需确定每个 partition 一样大较佳；
利用 1 个 partition 设置为 spare disk
chunk 设置为 256K 这么大即可！
这个 spare disk 的大小与其他 RAID 所需 partition 一样大！
将此 RAID 5 设备挂载到 /srv/raid 目录下
最终我需要 5 个 1GB 的 partition。在鸟哥的测试机中，根据前面的章节实做下来，包括课后的情境仿真题目，目前应该还有 8GB 可供
利用！ 因此就利用这部测试机的 /dev/vda 切出 5 个 1G 的分区。实际的流程鸟哥就不一一展示了，自己通过 gdisk /dev/vda 实作一下！ 最终这
部测试机的结果应该如下所示：
[root@study ~]# gdisk -l /dev/vda
Number Start （sector） End （sector） Size Code Name
1 2048 6143 2.0 MiB EF02
2 6144 2103295 1024.0 MiB 0700
3 2103296 65026047 30.0 GiB 8E00
4 65026048 67123199 1024.0 MiB 8300 Linux filesystem
5 67123200 69220351 1024.0 MiB FD00 Linux RAID
6 69220352 71317503 1024.0 MiB FD00 Linux RAID
7 71317504 73414655 1024.0 MiB FD00 Linux RAID
8 73414656 75511807 1024.0 MiB FD00 Linux RAID
9 75511808 77608959 1024.0 MiB FD00 Linux RAID
# 上面特殊字体的部份就是我们需要的那 5 个 partition 啰！注意注意！
[root@study ~]# lsblk
NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
vda 252:0 0 40G 0 disk
|-vda1 252:1 0 2M 0 part
|-vda2 252:2 0 1G 0 part /boot
|-vda3 252:3 0 30G 0 part
| |-centos-root 253:0 0 10G 0 lvm /
| |-centos-swap 253:1 0 1G 0 lvm [SWAP]
| `-centos-home 253:2 0 5G 0 lvm /home
|-vda4 252:4 0 1G 0 part /srv/myproject
|-vda5 252:5 0 1G 0 part
|-vda6 252:6 0 1G 0 part
|-vda7 252:7 0 1G 0 part
|-vda8 252:8 0 1G 0 part
`-vda9 252:9 0 1G 0 part
以以 mdadm 创创建建 RAID
接下来就简单啦！通过 mdadm 来创建磁盘阵列先！
[root@study ~]# mdadm --create /dev/md0 --auto=yes --level=5 --chunk=256K \
> --raid-devices=4 --spare-devices=1 /dev/vda{5,6,7,8,9}
mdadm: /dev/vda5 appears to contain an ext2fs file system