has access to a training set and a test set.
(i) We select the frequent patterns from the training set,
as these are (with high probability) the frequent ones
in the test set, too,
(ii) We learn the n-gram probabilities from the training set,
(iii) We estimate probabilities for all remaining patterns
based on the Markov model,
(iv) We sort all patterns in decreasing (estimated) proba-
bility,
(v) We evaluate these guesses against the test set.
We perform 5-fold cross-validation on our dataset: we
split our dataset into K = 5 disjoint subsets S1, . . . , S5 of
(roughly) equal size; all data points were distributed at ran-
dom in one of the 5 sets. We select a testing set Si0 , and use
the union of the remaining sets as training set. We repeat
this process for every set Si as test set and average the ﬁnal
results over all 10 runs. Our samples have size around 100,
so the training sets have size around 80 and the test sets
have size about 20.
We use the training set in two diﬀerent ways: First, we
select all patterns that appear more than four times in the
training set. While our sample size is too small to guarantee
a small approximation error of the relative frequencies, it
still provides a hint that it is more frequent than the others.
As guessing a few infrequent passwords upfront does less
harm than not guessing a frequent one upfront, we use a
small threshold of 4.
(In preliminary tests we found the
results to be insensitive to reasonable parameter choices.)
In order to estimate the frequencies of the remaining pat-
terns, we learn the n-gram frequencies for the Markov model.
165Additional information vs. no information.
When collecting data we obtained what we called defen-
sive and oﬀensive datasets (c.f. Section 3.2). We choose the
training and test set as subsets of the defensive set. The of-
fensive set is presumably drawn from a weaker distribution,
so we can use the oﬀensive set as additional training data.
Two contradicting eﬀects come into play: more training data
typically means better approximation, but as the additional
data is drawn from a (presumably) diﬀerent distribution, it
might actually worsen the results. We tested a number of
sizes of the additional dataset, the results are shown in Fig-
ure 6. We can see that more data means better results, up
to the maximum size of data we have. This is interesting
because it seems to hint at the fact that the oﬀensive and
defensive patterns have very similar statistical properties.
Smoothing.
When there is not enough data to learn all n-grams, one
can use smoothing to improve the approximation of n-grams,
in particular for the rare n-grams. We tested two diﬀerent
smoothing techniques, simple Laplace smoothing (increas-
ing each count by 1) and Interpolation smoothing (weighted
average between between 2-gram and 3-gram probabilities).
We found that the smoothing had very little inﬂuence on
the success of guessing, which is shown in Figure 5.
4.4 Pattern Strength
A variety of measures for the strength of passwords has
been proposed. On a high level, we can distinguish ap-
proaches that study resistance against a speciﬁc password
cracker (either by directly attacking them, or by using math-
ematical models to estimate their eﬀectiveness), and ap-
proaches that consider the distribution of passwords. While
the former are motivated by practice and model real-world
attacks pretty well, they highly depend on the speciﬁc at-
tack and are usually not generalizable. The latter are based
on mathematical models and thus have a clear meaning and
are (in some sense) optimal; and usually still provide a rea-
sonable approximation to practical security. See the survey
by Bonneau et al. [8] for a review of a number of possible
measures.
Partial guessing entropy estimate.
Guessing entropy [12,26] is one metric that can be used to
measure the strength of a (password) distribution; it mea-
sures the average number of guesses that the optimal attack
needs in order to ﬁnd the correct password. However, an
attacker is usually satisﬁed with breaking a certain fraction
of accounts already, which guessing entropy does not take
into account. Partial guessing entropy [8] (or α-guesswork )
improves on this.
i=1 pi ≥ α} the
minimal number so that the guesses cover at least a fraction
i=1 pi the actual
fraction covered (which is greater or equal to α). With these,
partial guessing entropy is deﬁned as
For 0 ≤ α ≤ 1 let µα = min{i0 | (cid:80)i0
α of the passwords, and let λα = λµα =(cid:80)µα
µα(cid:88)
Gα(X) = (1 − λα) · µα +
i · pi
(2)
Here the ﬁrst term is contributed by those values that weren’t
guessed in the alloted time, and the second term is con-
tributed by those that were guessed.
i=1
Figure 3: Guessing entropy estimate for plain Android Un-
lock Patterns.
We use a 3-gram model with a simple Laplace smoothing,
see Section 4.3 for experiments justifying these parameter
choices. In addition, we use a ﬁxed additional set of pat-
terns which is independent from both the test set and the
training set to increase the training material.
Next, we enumerate all valid patterns (i. e., those that
fulﬁll the requirements described in Section 3.1), using a
straightforward recursive algorithm. For each pattern, we
used both the initial probabilities and the transition prob-
abilities learned before to utility by decreasing probability,
overall running time is about ﬁve seconds on a standard PC.
Finally, we match the guesses against the test set, record-
ing after how many (simulated) guesses what fraction of the
test set was covered.
4.3 Model and Parameter Selection
In this section we discuss some of the design choices we
made for the experiments, and discuss the results presented
in this section.
3-grams vs. 2-grams.
The choice of the parameter n, i. e., the length of the n-
gram, is of crucial importance. In general, longer n-grams
yield better results, provided there is a suﬃcient amount
of training data to estimate the occurring probabilities with
high enough probability. For n = 2 we need to learn (slightly
less than) 9 · 8 = 72 values, for n = 3 we need to learn
(slightly less than) 9 · 8 · 7 = 504 values. Each dataset has
about 100 patterns at an average length of 6.6. For 2-grams,
this yields about 560 data-points or 7.8 data-points per value
to learn, for 3-grams, this yields about 460 data-points or 0.9
data-points per value to learn, and for 4-grams, this drops
to about 360 data-points or 0.1 data-points per value to
learn. This gives a strong indication that we do not have
enough data to learn 4-gram probabilities, thus we concen-
trated on 2 and 3 grams. The results are shown in Figure 4,
and clearly 3-grams show better performance. In addition,
we believe that the nature of the Android Unlock Pattern
scheme suggests the use of 3-grams instead of 2-grams: we
found that many users choose points in a straight line, which
is not modeled by 2-grams.
 0 0.2 0.4 0.6 0.8 1 0 1000 2000 3000 4000 5000guessing success# guessesAndroid offensive patternsAndroid defensive patternsRandom 3 digit PINRandom 4 digit PIN166Figure 4: Android (defensive) patterns:
Guessing entropy estimate with 3-grams
and 2-grams.
Figure 5: Android (defensive) patterns:
Guessing entropy estimate for diﬀerent
smoothing.
Figure 6: Android (defensive) patterns:
Guessing entropy estimate with and
without additional information.
Table 2: Comparing partial entropy estimate of several dis-
tributions and diﬀerent values for the target fractions α.
lower. However, in order to exploit such a lower entropy in
practice one would need to ﬁnd an attack that exploits this.
Distribution
α = 0.1 α = 0.2 α = 0.5
Android Unlock Patterns (Def, Markov)
Android Unlock Patterns (Oﬀ, Markov)
8.72
7.56
Random Android Unlock Pattern (U389 112) 18.57
19.93
Random 6-digit PINs (U1 000 000)
16.61
Random 5-digit PINs (U100 000)
13.29
Random 4-digit PINs (U10 000)
9.97
Random 3-digit PINs (U1 000)
Random 2-digit PINs (U100)
6.64
9.10
7.74
18.57
19.93
16.61
13.29
9.97
6.64
10.90
8.19
18.57
19.93
16.61
13.29
9.97
6.64
We want to express this in “bits of information” to be able
to compare it with other measures more easily. This is done
as follows:
˜Gα(X) = log
− 1
+ log
1
2 − λα
(3)
(cid:18) 2 · Gα(X)
λα
(cid:19)
where the term log
is used to make the metric constant
for the uniform distribution (see [8] for a more detailed ex-
planation).
2−λα
1
We have two reasons to deviate from this approach. First,
to approximate the distribution of X (i. e., the probabilities
pi) requires a certain size of the sample set which is beyond
the data we collected; second, one can be interested in get-
ting a more comparable metric for a speciﬁc attack. We are
using a combined approach, where we replace the probabil-
ities pi that are in optimal order (as for guessing entropy),
with probabilities whose order is given by the actual attack
we are considering, i. e., pi gives the fraction of passwords
from the test set that was cracked by the i-th guess. We
will refer to this modiﬁed guessing entropy estimate simply
as entropy from here on.
Measuring entropy.
Our entropy estimates are shown in Table 2. We com-
puted (partial) entropy estimates for three levels 10%, 20%,
and 50%. We ﬁnd that these three values span a reason-
able range, where breaking half the logins is clearly bad,
and even breaking 10% of all accounts is worrisome. As
usual for non-uniform distributions, higher values for α give
higher entropy estimates. Note that these values are com-
puted on the basis of the attack outlined above, and thus
give an upper bound only and the true entropy could be
4.5 Evaluation
Results.
The results of our guessing attack is shown in Figure 3,
which shows both the success against the defensive and the
oﬀensive pattern set. For comparison, we show the respec-
tive guessing curves for (randomly-assigned) PINs of three
and four (decimal) digits. (4-digit PINs are typically used
to protect the SIM-card; user-generated PIN numbers are
known to be weaker [9]).
Typically, devices such as mobile phones try to protect
against guessing attacks by locking the devices after a num-
ber of failed attempts, often requiring a master-PIN to un-
lock the device. This implies a trade-oﬀ between security
and usability, which prevents manufacturers from picking
too small a number of guesses. With 10 guesses, our data
shows that we guess approximately 4% of the accounts cor-
rectly for the defensive patterns and approximately 7% for
the oﬀensive patterns; with 30 guesses this increases to ap-
proximately 9% for the defensive patterns and approximately
19% for the oﬀensive patterns.
Discussion.
The results of our study reveal a lot of shortcomings of the
plain Android Unlock Pattern approach. While they pro-
vide nearly 400,000 possibilities and are, from a theoretical
point of view, therefore more secure than 5-digit randomly-
assigned PINs, our evaluations shows that the collected pat-
terns only have an estimated entropy slightly lower than
3-digit randomly-assigned PINs (1.4 bit lower for α = 0.1, 1
bit higher for α = 0.5). We believe that the collected pat-
terns present an upper bound on the actual strength most
Android users lock their smartphone with. This assumption
is based on two facts: First, engineers are over-represented
in our study and the faculty has a substantial number of
students in computer security. Second, the imminent threat
of having taken his sweet away, combined with the short
timeframe for recall, might have biased the choice of a par-
ticipant towards a more secure pattern. Furthermore, our
evaluation reveals that the “oﬀensive pattern” have a sub-
stantially lower estimated entropy, close to the entropy of 2-
digit randomly-assigned PINs. We argue that patterns used
in the wild have a lower entropy than the collected “defen-
 0 0.2 0.4 0.6 0.8 1 0 1000 2000 3000 4000 5000guessing success# guesses3-grams2-grams 0 0.2 0.4 0.6 0.8 1 0 1000 2000 3000 4000 5000guessing success# guessesLaplace SmoothingNo SmoothingInterpolation Smoothing 0 0.2 0.4 0.6 0.8 1 0 1000 2000 3000 4000 5000guessing success# guesses600 additional samples300 additional samples50 additional samplesno additional samples167sive pattern” and are more like “oﬀensive pattern” because
people without a strong IT security background do not re-
gard a weak pattern as threat for their valuable data on the
smartphone. This is also in line with our initial survey on
Android Unlock Patterns “in the wild”.
5. FINDING MORE SECURE PATTERNS
User choices for the Android unlock patterns are highly
biased, yielding security roughly comparable to three digit
PINs. We evaluate the inﬂuence of several factors on the
user choices, in particular we will see that small re-arrangements
of the points can yield higher entropy estimates. Secondly,
these alternative patterns provide us with insides on the ra-
tionals behind user choices.
5.1 Bias Found in the Android Patterns
The design of the Android Unlock Patterns imposes sev-
eral biases to the patterns chosen by users, that we were
able to identify in the collected data. We identiﬁed these
sources for bias in order to systematically search for better
patterns. Here we concentrate on relatively small modiﬁ-
cations, in particular re-ordering of the points, because the
design of the Android Unlock Patterns is well-known now
and has quite good usability. As we will see, relatively small
changes are suﬃcient to substantially improve the security
of the scheme, without harming usability.
A basic and obvious weakness is a strong bias of the start-
ing point towards the top-left corner, as is shown in Figure 7.
While for a uniformly chosen pattern the probability for the
top-left corner should be 11%, it is nearly four times higher
(44%). Also, we can see a bias towards the corners and away
from the center, which is heavily under-represented with 2%
probability (less than a ﬁfth from the average). These results
are consistent with ﬁndings for the PassPoints system [16],
which also found a bias to the top-left corner, even though
the system is quite diﬀerent. A plausible explanation is that