Leader 𝐿𝑒′ = 𝐿𝑒
O𝑒′ ← 𝐻(𝑅𝑒,
O𝑒′−1, . . . , O𝑒′−𝑡)
Figure 3: Overview of RandPiper – GRandPiper. In every epoch, a
PVSS sharing of some random value is secret shared. At the same
time, a reconstruction protocol is used to reconstruct the random
value committed by the leader of this epoch, the last time it was a
leader. O𝑒′ is generated using the random value 𝑅𝑒, shared in epoch
𝑒, reconstructed in epoch 𝑒′ > 𝑒 + 𝑡, and outputs {O𝑒′−1, . . . , O𝑒′−𝑡 }
from previous epochs by using them as inputs to the random oracle
𝐻.
4We can use Merkle trees instead of 𝑞-SDH at the expense of 𝑂(log 𝑛) multiplicative
communication complexity.
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3508We use the SMR protocol (refer Figure 1) described in Section 3
as a building block. At a high-level, consider using the SMR protocol
such that the leader outputs a number chosen uniformly at random
in each epoch. The random beacon output can be a function of
the outputs of the last 𝑡 + 1 epochs, allowing for the presence of
at least one honest input (chosen uniformly at random) which is
potentially sufficient to obtain a random output. This argument
holds only if each leader chooses their input in the SMR protocol
independently of other inputs. Otherwise, if a Byzantine leader
can choose an input after knowing the outputs of the previous 𝑡
instances then it can bias the output. A separate concern with using
the SMR protocol as is, is that in an epoch with a Byzantine leader,
honest nodes may not all output the same value or output at all.
To fix both of these concerns, we require each node to send a
commitment of a random value more than 𝑡 epochs before it will
be reconstructed and used in the beacon protocol. To ensure the
secrecy of this value (for unpredictability and bias-resistance), the
values are shared with the nodes using a publicly verifiable secret
sharing (PVSS) scheme (refer to Appendix B for detailed PVSS
interface). Committing a secretly chosen value ahead of time helps
us solve both of our previous concerns. First, if the same leader is
not chosen twice in any span of 𝑡 +1 epochs, it ensures that the 𝑡 +1
values that will be used to construct the beacon protocol are chosen
independently of one another. Thus, when nodes reconstruct a
value in an epoch, it corresponds to a value committed more than
𝑡 epochs before. Moreover, the nodes can reconstruct this value
independent of the participation of the leader in this epoch. Second,
waiting for 𝑡 + 1 epochs before opening allows for the value to be
committed by the SMR protocol. Thus, all honest nodes will open
the same value in an epoch.
A graphical description of this approach is presented in Figure 3.
In epoch 𝑒, a leader 𝐿𝑒 inputs PVSS shares corresponding to a
random value 𝑅𝑒 to the SMR protocol. Conceptually, when the block
is committed, this value is added to a queue Q(𝐿𝑒) corresponding
to this leader. When the same node is chosen the next time as a
leader, say in epoch 𝑒′, the committed shares of 𝑅𝑒 is dequeued
and reconstructed by all honest nodes to obtain 𝑅𝑒. The output O𝑒′
of epoch 𝑒′ can be computed as 𝐻(𝑅𝑒, O𝑒′−1, . . . , O𝑒′−𝑡). To allow
for unpredictability in leader selection while disallowing repetition
within 𝑡 + 1 epochs, the leader for the next epoch 𝑒′ + 1 is chosen
based on O𝑒′ and by removing the leaders 𝐿𝑒′, . . . , 𝐿𝑒′−𝑡.
A remaining concern is when no values are added to the chain at
epoch 𝑒. Observe that the reconstruction in epoch 𝑒 is not affected,
since nodes reconstruct values previously committed. However,
nodes may not have shares in epoch 𝑒′ > 𝑒 + 𝑡 where 𝑒′ is the first
epoch where 𝐿𝑒 is chosen as the leader again. To fix this concern,
we ensure that such a malicious leader who does not commit in
epoch 𝑒 can be removed by all nodes by 𝑒 + 𝑡  𝑡 nodes will
reconstruct a unique secret.
Setup. We establish PVSS parameters PVSS.pp, and public keys
PVSS.pk𝑖 for every node 𝑝𝑖 ∈ P. We also buffer shares for one
random value for every node 𝑝𝑖, i.e., fill Q(𝑝𝑖) for 𝑝𝑖 ∈ P. We
start with epoch 𝑒 = 1, and use seed random values for 𝑅𝑒 and
{O𝑒−1, . . . , O𝑒−𝑡}. We also assign L𝐿𝑎𝑠𝑡 ← {𝑝𝑛, . . . , 𝑝𝑛−𝑡} and set
P𝑟 ← ∅ arbitrarily.
Leader selection. The leader for epoch 𝑒 is chosen based on the
following rule:
Definition 4.1 (Leader selection rule). Let 𝑒 be the current epoch,
L𝐿𝑎𝑠𝑡 := {𝐿𝑒−1, . . . , 𝐿𝑒−𝑡} be the leaders of the last 𝑡 epochs, P𝑟 be
the set of nodes that are removed (due to misbehavior), and L𝑒 =
(P \ L𝐿𝑎𝑠𝑡) \ P𝑟 := {𝑙0, . . . , 𝑙𝑤−1}, be a set of candidate leaders for
epoch 𝑒 ordered canonically, with 0  𝑡 shares will reconstruct a unique secret,
which implies that the degree of the polynomial cannot be more
than 𝑡. Finally, the block in our SMR protocol consists of the outputs
of the PVSS.ShGen algorithm, i.e., 𝑏ℎ := (PVSS.(cid:174)𝐸, PVSS.𝜋) ←
PVSS.ShGen(𝑅𝑒). An honest nodes acknowledges 𝐵ℎ if 𝑏ℎ meets
the validity condition PVSS.ShVrfy algorithm. Note that despite
the blocks being 𝑂(𝜅𝑛) sized, due to our usage of Deliver primitive,
we retain a communication complexity of 𝑂(𝜅𝑛2) per epoch.
Commit, reconstruct, and output beacon value. In each epoch,
nodes commit the shares sent by the leader. They also reconstruct
the last sharing sent by the leader at the start of the epoch. Note
that each node can separately maintain the last time a node was
elected as the leader, and thus, be able to appropriately invoke
Dequeue(Q(𝐿𝑒)). Moreover, since a leader does not repeat in any
consecutive 𝑡 + 1 epochs, and we ensure that the set of leaders are
consistently known to all honest nodes (as will be shown in the next
subsection), the value being reconstructed is agreed upon by all the
honest nodes. When the nodes reconstruct 𝑅𝑒, they already have
access to {O𝑒−1, . . . , O1}. Hence, they can compute a consistent
output O𝑒. Observe that since all nodes enter epoch 𝑒 within a
delay of Δ, they also output the beacon value within Δ time of each
other.
Remove misbehaving leaders. Finally, at the end of an epoch 𝑒,
if no block was committed in epoch 𝑒 − 𝑡 by 𝐿𝑒−𝑡, 𝐿𝑒−𝑡 is removed
from all future proposals. Since this operation is performed after
𝑡 + 1 epochs, all nodes will perform this action consistently.
Due to space constraints, we analyze security in Appendix B.2.
4.2 RandPiper – BRandPiper Protocol
In this section, we present a random beacon protocol using 𝑂(𝜅 𝑓 𝑛2)
bits of communication complexity where 𝑓 ≤ 𝑡 is the actual number
of faults and with 1-absolute unpredictability. Thus, in the optimistic
Session 12D: Decentralized Cryptographic Protocols CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3509All nodes 𝑝𝑖 ∈ P running the SMR protocol do the following:
• Setup. Set 𝑒 = 1. All nodes agree upon seed random values for 𝑅𝑒 and {O𝑒−1, . . . , O𝑒−𝑡 }. Set L𝐿𝑎𝑠𝑡 ← {𝑝𝑛, . . . , 𝑝𝑛−𝑡 }, P𝑟 ← ∅. Run PVSS.Setup and
agree on the public parameters PVSS.pp. Then every node generates a key pair (PVSS.sk, PVSS.pk) ← PVSS.KGen(𝜅), and all nodes agree on each others
public keys.
• Leaders. Choose leaders for an epoch 𝑒 using Definition 4.1 instead of a round-robin order.
• Blocks. The leader 𝐿𝑒 of an epoch 𝑒, creates a PVSS sharing (PVSS.(cid:174)𝑆, PVSS. (cid:174)𝐸, PVSS.𝜋) ← PVSS.ShGen(𝑅) of a random value chosen from the input
space of PVSS, and creates a block 𝐵ℎ with block contents 𝑏ℎ as 𝑏ℎ := (PVSS. (cid:174)𝐸, PVSS.𝜋) ← PVSS.ShGen(𝑅). (We drop the individual shares in PVSS.(cid:174)𝑆.)
• Update. When committing a block 𝐵ℎ sent by leader 𝐿𝑒′ for some epoch 𝑒′, Enqueue(Q(𝐿𝑒′), 𝑏ℎ). At the end of epoch 𝑒, if no block was committed for
epoch 𝑒 − 𝑡 by 𝐿𝑒−𝑡 , then remove 𝐿𝑒−𝑡 from future proposals, i.e., P𝑟 ← P𝑟 ∪ {𝐿𝑒−𝑡 } from epoch 𝑒 + 1.
• Reconstruct. When the epoch timer epoch-timer𝑒−1 for epoch 𝑒 − 1 ends, obtain the (PVSS. (cid:174)𝐸, PVSS.𝜋) corresponding to the committed block in
Dequeue(Q(𝐿𝑒)). Send 𝑠 ← PVSS.Dec(PVSS.sk, PVSS. (cid:174)𝐸𝑖) to all the nodes in the system. On receiving share 𝑠′ from another node 𝑝 𝑗 , ensure that
PVSS.Enc(PVSS.pk𝑗 , 𝑠′) = PVSS. (cid:174)𝐸 𝑗 . On receiving 𝑡 + 1 valid shares in PVSS.(cid:174)𝑆, reconstruct 𝑅𝑒 ← PVSS.Recon(PVSS.(cid:174)𝑆).
• Output. After reconstructing 𝑅𝑒 for epoch 𝑒, output the beacon value O𝑒 by computing O𝑒 ← 𝐻 (𝑅𝑒, O𝑒−1, . . . , O𝑒−𝑡)
Figure 4: RandPiper – GRandPiper beacon protocol description.
case when 𝑓 = 𝑂(1), our communication complexity is quadratic.
In order to achieve 1-absolute unpredictability, we need to ensure
that we reconstruct inputs from > 𝑡 nodes in every epoch. If we
use PVSS schemes, we need to add 𝑂(𝑡) shares in every epoch, so
that we can consume > 𝑡 combined shares in every round. A PVSS
sharing for one secret is of size 𝑂(𝑛), and therefore performing
𝑂(𝑛𝑡) sharings trivially results in a communication complexity of
𝑂(𝑛3). Therefore, we will use VSS schemes (refer to Appendix B for
detailed VSS interface) in an attempt to improve the communication
complexity for a 1-absolute unpredictable random beacon protocol.
Improved VSS. We will first describe an improved VSS (iVSS)
4.2.1
scheme that achieves better communication complexity to share 𝑛
secrets in the optimistic case which will then be used in our random
beacon protocol.
Efficient VSS (eVSS). eVSS [32] (refer Figure 5) presents the state-
of-the-art VSS scheme for synchronous network setting. The pro-
tocol is described assuming the presence of a bulletin board (or
broadcast channels) [6, 17, 20, 32] where there exists a public bul-
letin board, in which messages posted by any node are available
instantly, and the bulletin board provides a consistent view to all
the nodes. We can realize such message delivery guarantees by
invoking Byzantine Broadcast (BB) protocols.
In this protocol, a dealer 𝐿 creates a commitment VSS.C to a
random polynomial whose constant term is the secret, and posts the
commitment on the bulletin board (Step 1), while privately sending
individual shares VSS.s𝑗 along with witnesses VSS.𝜋 𝑗 to every node
𝑝 𝑗 ∈ P (Step 2). Nodes post complaints on the bulletin board in the
form of blame message if they do not receive valid shares (Step 3)
in a timely manner. The dealer then opens the secret shares on the
bulletin board corresponding to the nodes that blamed (Step 4). If
there are > 𝑡 complaints, the nodes abort (Step 5). Otherwise, the
honest nodes commit their shares (Step 5), with the guarantee that
all honest nodes will be able to reconstruct the shared secret.
Note that 𝑓 ≤ 𝑡 Byzantine nodes can always blame regardless
of the dealer being honest or not. This forces an honest dealer to
post 𝑂(𝑓 𝑛) shares on the bulletin board when secret sharing 𝑂(𝑛)
secrets. In general, the amount of information posted on the bulletin
board is 𝑂(𝜅𝑛 + 𝜅 𝑓 + 𝜅 𝑓 𝑛) corresponding to 𝑂(𝑛) commitments, 𝑓
blame messages and 𝑂(𝑓 𝑛) opened secret shares. A naïve approach
of using BB protocols (extension protocols [36] for larger inputs)
to instantiate the bulletin board involves following steps:
9
(1) Commitment and sharing. Dealer 𝐿 invokes BB to broadcast 𝑛
commitments Step 1, while privately sharing individual shares
Step 2.
(2) Blame. Nodes invoke 𝑛 parallel instances of BB to broadcast
blame messages Step 3.
(3) Open shares. Dealer 𝐿 invokes an instance of BB with secret
shares corresponding to the blames received.
We note that state-of-the-art honest majority BB protocols, with-
out threshold signatures, incur 𝑂(𝜅𝑛3) bits communication cost to
achieve consensus on a single decision [1, 23, 33]. Thus, invoking 𝑛
parallel instances of BB trivially incurs 𝑂(𝜅𝑛4) communication cost.
In addition, running BB on inputs of size 𝑂(𝑓 𝑛) incurs 𝑂(𝜅 𝑓 𝑛3)
without threshold signatures and extension techniques. Thus, the
total communication complexity is 𝑂(𝜅𝑛4) bits.
Improved eVSS (iVSS). In order to reduce the large communication
overhead, we first present an improved VSS scheme, that reduces
(i) the number of posts to the bulletin board, and (ii) the amount of
information posted on the bulletin board.
In iVSS (refer Figure 6), the dealer posts commitments on the
bulletin board, privately sends the secret shares and corresponding
witnesses similar to eVSS. However, unlike eVSS, nodes send the
blame messages to all nodes. In addition, nodes forward the received
blame messages to the dealer to request for missing shares. The
dealer privately sends missing shares to the nodes that forwarded
the blame message instead of posting on the bulletin board. If
an honest node receives missing shares for all blame messages it
forwarded, it sends an ack to the dealer. The dealer collects 𝑡 + 1
ack messages and posts the ack certificate on the bulletin board.
An honest node commits the proposed commitment if it observes
an ack certificate on the bulletin board.
The honest nodes then forward the missing shares if the dealer
sent the missing shares. A key correctness argument for our scheme
is the following: if an honest node 𝑝𝑖 ∈ P does not receive commit-
ments and secret shares, it must have sent blame messages to all
honest nodes. If some honest node 𝑝 𝑗 ∈ P sends an ack message, it