### Table 1: Maximum Number of Rounds for Finding MIS
- **Random Values in Each Round [38]**
- **Fixed Order [7]**

### Algorithm Steps
1. **Initialization:**
   - Each node \( v \) is assigned a random value \( r(v) \).

2. **Node Selection:**
   - (b) If \( r(v) \) is smaller than the values received from all neighbors of \( v \), then:
     - \( v \) inserts itself into the independent set \( I \).
     - \( v \) informs its neighbors about this.
     - \( v \) becomes inactive.
   - (c) If \( v \) hears that one of its neighbors was inserted into \( I \), then:
     - \( v \) becomes inactive.

3. **Return:**
   - Return the independent set \( I \).

### Luby’s Algorithm
Luby’s algorithm is a message-passing algorithm where each round can be implemented using two scatter/gather steps:
- **Scatter Step:** Send \( r(v) \) to \( v \)'s neighbors.
- **Gather Step:** Nodes that joined the MIS inform their neighbors to become inactive.

Implementing this algorithm in our framework requires a gather circuit to compare \( r(v) \) with the \( r \) values of its neighbors. This circuit is larger, by at least a factor of \( \log |V| \), compared to the BFS gather circuit which only computes an OR of bits.

### Blelloch et al. Variant [7]
Blelloch et al. suggested running Luby’s algorithm with a single initial assignment of random values to nodes. A recent analysis showed that this variant finds the MIS with high probability (whp) in \( O(\log n) \) rounds [18].

**Experimental Results:**
- 1,000 experiments were conducted on random graphs of various sizes.
- Using a fixed assignment of random values works almost as well as Luby’s algorithm, with the following properties:
  1. The expected size of the MIS increases by about 0.5%.
  2. The maximum number of rounds, as described in Table 1, increases by very little and is much less than \( \log n \).
- A secure implementation must run for a constant number of rounds, which we set to be 8 or 9.

### Efficient Implementation
The variant due to Blelloch et al. [7] can be more efficiently implemented in our framework:
1. **Initial Phase:**
   - Each node is assigned a random ID.
   - Edges are directed towards the node with the higher ID among their two endpoints.
2. **Initialization:**
   - Each node is assigned a MIS bit, initialized to 0.
   - Each node is assigned an "active" bit, initialized to 1.
3. **Scatter Step:**
   - Each node pushes its activity bit on all outgoing edges.
4. **Gather Step:**
   - Each active node with no incoming edges from active nodes sets its MIS bit to 1.
5. **Scatter Step:**
   - Each node in the MIS sends "inactive" on all outgoing edges.
6. **Gather Step:**
   - Each node that receives an "inactive" message becomes inactive.
7. **Iteration:**
   - Repeat from Step 3.

This algorithm allows scatter and gather operations to use OR operations instead of comparisons, resulting in more compact circuits. We implemented this functionality and report the results in Appendix A.4.

### Implementation and Evaluation
A detailed description of the implementation, optimization, and evaluation of the protocols appears in Appendix A.

### References
[1] M. Ajtai, J. Komlós, and E. Szemerédi, “An O(n log n) sorting network,” in STOC, 1983, pp. 1–9.
[2] T. Araki, A. Barak, J. Furukawa, T. Lichter, Y. Lindell, A. Nof, K. Ohara, and A. Watzman, “Optimized honest-majority mpc for malicious adversaries - breaking the 1 billion-gate per second barrier,” in IEEE Symposium on Security and Privacy, SP, 2017.
...
[7] G. E. Blelloch, J. T. Fineman, and J. Shun, “Greedy sequential maximal independent set and matching are parallel on average,” in SPAA. ACM, 2012, pp. 308–317.
...
[18] M. Fischer and A. Noever, “Tight analysis of parallel randomized greedy MIS,” in SODA. SIAM, 2018, pp. 2152–2160.
...

### Appendix A: Implementation and Evaluation

#### Testbed
- **Hardware:**
  - AWS c5.9xlarge servers.
  - Intel Xeon Platinum 8000 series (Skylake-SP) processor.
  - Sustained all-core Turbo CPU clock speed up to 3.5 GHz.
  - 32 cores, 72GB of memory.
  - Connected over a 10Gb network.

#### Optimizations
- **Parallelization and Multi-threading:**
  - Quicksort algorithm with parallel comparisons.
  - Layer \( i \) has at most \( 2^i \) partitions and pivots.
- **Vectorization:**
  - Utilize SIMD (single instruction multiple data) vectorization.
  - Intel’s AVX512 instructions for 512-bit operations.
- **Shallow Comparison Circuit:**
  - Tradeoff between deep and small circuits and shallow and large circuits.
  - Use the deep and small circuit for large numbers of comparisons.
  - Use the shallow and large circuit when the number of comparisons is small.
- **Choosing the Pivot:**
  - Sample \( s \) items and compute their median.
  - Sample size \( s = 2 \log n \) for a good approximation.
  - In our implementation, sample size is 3, 5, or 7 items.
- **Handling Small Subsets:**
  - Stop recursion when subset size is reduced to a threshold \( t \).
  - Parallel comparison of all pairs of items in the subset.
  - Use a precomputed lookup table for outputting items in sorted order.

#### Experiments
- **Performance Analysis:**
  - Separate experiments for secure shuffle and sort protocols.
  - Implemented using the MPC library described in Araki et al. [4].
  - Number of elements ranges from 1M to 50M.
  - Results are the average of five executions.
  - Detailed results in Table 2.