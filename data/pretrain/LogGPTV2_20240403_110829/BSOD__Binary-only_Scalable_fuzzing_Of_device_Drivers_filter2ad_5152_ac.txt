end if
M[prev_loc] ← 0xcc
sinдlestep ← f alse
COV ∪ rip − base ⊕ prev_loc − base
prev_loc ← rip
end if
end while
We modified the described edge coverage mode above to reduce
the amount of reoccurring interrupts that are costly to handle and
consequently lower the tracing accuracy to improve the fuzzing
throughput. Here, BSOD sets breakpoints on the offsets of control-
flow instructions and both reachable basic blocks. Whenever a
breakpoint triggers, it reports the current RIP register for coverage
feedback but omits the reinjection of the breakpoint so that it only
triggers once.
Therefore, the granularity of the coverage feedback per test
case reduces to previously unseen basic blocks, which lowers the
number of inputs considered interesting. For example, when an
input encounters a new edge whose origin and target blocks were
already reached previously, it can not be spotted as new interesting
behavior.
3.1 BSOD-AFL
We implemented an AFL++ proxy [13] that integrated AFL++ into
BSOD using libvmi. Initially, it was derived from the kernel-fuzzer-
for-xen [23] project and retargeted for KVM. Figure 3 shows the
overall system overview of the fuzzing setup. The host system runs
AFL and QEMU, while the fuzzing takes place in the guest system,
which runs the target kernel module. Based on the collected in-
formation, the analyst must create a target-specific harness that
implements the respective API functions to fuzz. Listing 2 shows
the minimal harness boilerplate code. At first, the harness allo-
cates a buffer and issues a hypercall to share the buffer’s address
and length. We implemented the hypercalls as software interrupts
with prepared register values, which are handled by BSOD accord-
ingly. The rax register contains a specific magic value that encodes
the command, and the registers rbx and rcx hold the arguments
that are the address and length, respectively. BSOD translates the
buffer’s virtual address to the physical address through page-table
lookup. After starting the harness inside the guest, it will first allo-
cate a buffer and share the address and length via a hypercall. Since
the scheduling of other processes can happen while a whole oper-
ating system is running, it could be possible that other processes
hit breakpoints during the execution of a test case. To ensure to
Toepfer and Maier
collect only the related coverage of the harness, BSOD determines
the respective PID of the current process by reading it from the
struct task_struct. Afterward, the harness enters the fuzzing
loop and issues at first in every iteration a hypercall to request
a new test case into the created buffer. Then, it calls the target
function and fills the arguments with the buffer’s content.
We create breakpoints at the basic block addresses of the Linux
kernel error handlers, such as oops_begin, panic, and kasan_
report to detect faults that we report to AFL. When the system has
to halt due to a critical fault, the VM needs to reboot and initialize
again to continue the fuzzing process.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
# include 
# include 
# define HYPERCALL_BUFFER
# define HYPERCALL_TESTCASE
# define LENGTH
int main ( int argv , char ∗ ∗ argc )
{
/ / A l l o c a t e
char ∗ b u f f e r = malloc (LENGTH) ;
memset ( b u f f e r , 0 , LENGTH) ;
i n p u t b u f f e r
0 x1337133713371338
0 x1337133713371337
0 x10000
/ / H y p e r c a l l
asm ( " i n t $3 "
s i g n a l b u f f e r a d d r e s s and l e n g t h
t o
: : " a " ( HYPERCALL_BUFFER ) ,
" b " ( b u f f e r ) ,
" c " (LENGTH) ) ;
F u z z i n g l o o p
/ /
while ( 1 )
{
/ / H y p e r c a l l
asm ( " i n t $3 "
r e q u e s t new t e s t
t o
: : " a " ( HYPERCALL_TESTCASE ) ) ;
c a s e
f u n c t i o n
/ / C a l l
t a r g e t _ f u n c t i o n ( b u f f e r ) ;
t a r g e t
}
}
Listing 2: BSOD-AFL Harness boilerplate
3.2 BSOD-Syzkaller
Syzkaller [11] is a system call kernel fuzzer, predestined in the
context of device driver fuzzing on the ioctl interface. It uses virtu-
alization, based on QEMU [2], to run one or multiple worker guests
in which the fuzzing takes place.
When the fuzzer inside the guest executes a program that reaches
new program locations, according to coverage, it gets re-executed
multiple times to verify functionality, reduce noise, and minimize
the testcase, in the so-called triage phase. The minimized program
and the coverage information are sent to the manager on the host.
The manager adds the new program to the input corpus from which
the fuzzer subsequently generates the programs through mutation
of the parameters and updates the overall reached coverage. The
reached basic block addresses are mappable to the respective source
code lines of the kernel image.
In the case of closed-source targets, the common KCOV kernel
feature can not provide coverage information for binary modules.
To overcome this hurdle, we hook up BSOD as new coverage source,
that prototypically emulates the functionality of KCOV based on
software breakpoints in a very similar way to the setup described
in subsection 3.1.
BSOD includes a tool named syz-bp-cov to run alongside the
Syzkaller manager on the host. It also relies on the introspection
capabilities of VMI to receive interrupts and to access the guest’s
memory. We modified the libvmi library and removed the libvirt de-
pendency, an extensive virtualization API, for seamless integration
in Syzkaller, since the manager unit already controls the QEMU
processes. We extended the startup routine of Syzkaller to start the
tool before it executes the fuzzer inside the guest. In the first step,
53BSOD: Binary-only Scalable fuzzing Of device Drivers
RAID ’21, October 6–8, 2021, San Sebastian, Spain
the tool connects to the introspection API of the guest VM and
replaces the target’s control-flow instructions with software break-
points those offsets also require to be extracted beforehand. In the
next step, it registers the two events BREAKPOINT and SINGLESTEP
that are used for control-flow tracing according to Figure 4 from
the first setup.
We modified the Syzkaller executor in terms of dropping out the
interactions with the KCOV interface. Instead, it allocates a cover-
age buffer and signals its memory location via a hypercall realized
as a software interrupt with prepared register values. Whenever
the CPU reaches a breakpoint during the execution of a Syzkaller
program, the basic block address is reported according to the cur-
rent RIP register value and written into the dedicated coverage
buffer at the position of the current size value that is increased
afterward. Since the module load addresses vary across reboots, the
tool rebases the reached basic block addresses into a fixed address
range per module. To avoid having to manage coverage buffers for
each thread and the corresponding mapping for each basic block
reached, the experimental setup is limited to a single fuzzer process
that runs in non-threaded mode per VM.
In BSOD-Syzkaller, reached breakpoints are not reactivated and
only trigger once, which requires some changes to the Syzkaller
logic. Since Syzkaller typically uses edge coverage that chains two
successive basic blocks together, it would likely create edges de-
pending on the state of enabled breakpoints that are not existing.
This effect influences the assessment of whether an input triggers
new behavior and is added to the corpus. To solve the problem, we
modified Syzkaller to use block coverage that lowers the accuracy
to maintain correct functionality. Consistent coverage feedback is
required to function correctly to keep the triage phase intact for
inputs that reach new program locations. Therefore, when entering
this phase, the fuzzer issues a hypercall dedicated to syz-bp-cov. It
activates all breakpoints again and continuously reactivates them
when they are triggered so that it traces the full set of reached basic
block addresses accordingly until the fuzzer leaves the triage phase
and signals it via another hypercall. Fuzzing with Syzkaller requires
the tester to provide interface descriptions for the target.
1
2
3
4
5
6
7
8
9
10
11
12
13
r e s o u r c e
o p e n a t $ n v i d i a c t l ( fd const [AT_FDCWD] ,
f d _ n v i d i a c t l [ fd ]
f l a g s
f l a g s [ o p e n _ f l a g s ] , mode const [ 0 ] )
f d _ n v i d i a c t l
ioctl$NVRM_IOCTL_CREATE ( fd f d _ n v i d i a c t l , cmd const [0 xc020462b ] , arg p t r [ inout
f i l e p t r [ in ,
s t r i n g [ " / dev / n v i d i a c t l " ] ] ,
, n v r m _ i o c t l _ c r e a t e _ t ] )
{
n v r m _ i o c t l _ c r e a t e _ t
c i d i n t 3 2 ( in )
par
i n t 3 2 ( in )
handle
c l s
i n t 3 2 ( in )
p t r p t r 6 4 [ in ,
s t a t u s
_pad
i n t 3 2
i n t 3 2 ( i n o u t )
i n t 3 2 ]
i n t 3 2 ( out )
}
Listing 3: Syzkaller ioctl system call description
Based on recovered ioctl structures, the creation of equivalent
Syzkaller descriptions is straightforward, exemplary shown in List-
ing 3. The first line defines a resource to hold the file descriptor of
the device node, which will be opened in the next line. The third
line defines an ioctl system call according to the function definition
which takes the file descriptor, the cmd parameter, and a pointer
of an expected parameter structure as arguments. The definition
of the parameter structure starts from the fifth line, and each line
between the brackets defines a field with name and type.
4 PCI DEVICE RECORD & REPLAY
Fuzzing of device drivers requires running an operating system
containing a supported hardware device so that the target driver
can initialize and operate. Unfortunately, when fuzzing with physi-
cal hardware devices via PCI passthrough, it requires one separate
device for each guest, in which the fuzzing takes place. Further-
more, the fuzzer could trigger operations that bring the device into
an unstable state or even break it. To overcome these issues, we
create a QEMU virtual device, able to replay large parts of the real
PCI devices. It enables fuzzing execution on systems that do not
include the physical device and allows scaling up using virtualiza-
tion technology to utilize all the system resources more efficiently.
Several similar attempts address this issue for different hardware
families.[6, 15, 29, 30, 41]
4.1 PANDA-based Deterministic Recordings
Analyzing any driver behavior in full-system emulation involves
challenges due to the nondeterminism of the operating system and
the hardware, due to the state differences of the OS and the physical