### 优化后的文本

```plaintext
end if
M[prev_loc] = 0xcc
singlestep = false
COV = COV ∪ (rip - base) ⊕ (prev_loc - base)
prev_loc = rip
end if
end while

我们对上述描述的边缘覆盖模式进行了修改，以减少重复中断的数量。这些中断处理成本高昂，并且会降低跟踪准确性，从而提高模糊测试的吞吐量。在这里，BSOD 在控制流指令和可到达的基本块的偏移处设置断点。每当断点触发时，它会报告当前的 RIP 寄存器值以提供覆盖率反馈，但省略了断点的重新注入，因此它只触发一次。

因此，每个测试用例的覆盖率反馈粒度降低到以前未见过的基本块，这减少了被认为有趣的输入数量。例如，当一个输入遇到一个新的边，而其源块和目标块之前已经被访问过时，它不会被视为新的有趣行为。

### 3.1 BSOD-AFL

我们实现了一个 AFL++ 代理 [13]，通过 libvmi 将 AFL++ 集成到 BSOD 中。最初，它是从 kernel-fuzzer-for-xen [23] 项目中派生出来的，并针对 KVM 进行了重新定位。图 3 显示了模糊测试设置的整体系统概览。主机系统运行 AFL 和 QEMU，而模糊测试在运行目标内核模块的客户机系统中进行。根据收集的信息，分析人员必须创建一个特定于目标的 harness，实现相应的 API 函数以进行模糊测试。清单 2 显示了最小的 harness 模板代码。首先，harness 分配一个缓冲区并通过超调用共享缓冲区的地址和长度。我们将超调用实现为带有预设寄存器值的软件中断，由 BSOD 相应地处理。rax 寄存器包含一个特定的魔数，编码命令，而 rbx 和 rcx 寄存器分别保存参数（即地址和长度）。BSOD 通过页表查找将缓冲区的虚拟地址转换为物理地址。在客户机内部启动 harness 后，它将首先分配一个缓冲区并通过超调用共享地址和长度。由于整个操作系统运行时可能会调度其他进程，因此在执行测试用例时，其他进程可能会命中断点。为了仅收集与 harness 相关的覆盖率，BSOD 通过读取 struct task_struct 来确定当前进程的 PID。然后，harness 进入模糊测试循环，在每次迭代中首先通过超调用请求新的测试用例到创建的缓冲区中，然后调用目标函数并用缓冲区内容填充参数。

我们在 Linux 内核错误处理程序（如 oops_begin、panic 和 kasan_report）的基本块地址处创建断点，以检测故障并将这些故障报告给 AFL。当系统因严重故障而停止时，虚拟机需要重启并重新初始化以继续模糊测试过程。

### 清单 2: BSOD-AFL Harness 模板代码

```c
#include <stdio.h>
#include <stdlib.h>

#define HYPERCALL_BUFFER 0x1337133713371338
#define HYPERCALL_TESTCASE 0x1337133713371337
#define LENGTH 0x10000

int main(int argc, char **argv) {
    // 分配缓冲区
    char *buffer = malloc(LENGTH);
    memset(buffer, 0, LENGTH);

    // 超调用
    asm volatile (
        "int $3"  // 信号传递缓冲区地址和长度
        : : "a" (HYPERCALL_BUFFER), "b" (buffer), "c" (LENGTH)
    );

    // 模糊测试循环
    while (1) {
        // 超调用
        asm volatile (
            "int $3"  // 请求新的测试用例
            : : "a" (HYPERCALL_TESTCASE)
        );
        
        // 调用目标函数
        target_function(buffer);
    }
}
```

### 3.2 BSOD-Syzkaller

Syzkaller [11] 是一个系统调用内核模糊器，特别适用于设备驱动程序的 ioctl 接口模糊测试。它基于 QEMU [2] 使用虚拟化技术来运行一个或多个工作客户机，模糊测试在这些客户机中进行。

当客户机中的模糊器执行一个程序并达到新的程序位置时，根据覆盖率，该程序会被多次重新执行以验证功能、减少噪声并最小化测试用例，这一阶段称为 triage 阶段。最小化的程序和覆盖率信息被发送到主机上的管理器。管理器将新程序添加到输入语料库中，模糊器随后通过参数变异生成程序并更新整体覆盖率。达到的基本块地址可以映射到内核镜像中的相应源代码行。

对于闭源目标，常见的 KCOV 内核特性无法为二进制模块提供覆盖率信息。为了克服这一障碍，我们使用 BSOD 作为新的覆盖率来源，它原型化地基于软件断点实现了 KCOV 的功能，类似于 3.1 节中描述的设置。

BSOD 包含一个名为 syz-bp-cov 的工具，与 Syzkaller 管理器一起在主机上运行。它还依赖于 VMI 的内省能力来接收中断并访问客户机的内存。我们修改了 libvmi 库并移除了 libvirt 依赖项（一种广泛的虚拟化 API），以便无缝集成到 Syzkaller 中，因为管理器单元已经控制了 QEMU 进程。我们扩展了 Syzkaller 的启动例程，以便在客户机内部执行模糊器之前启动该工具。第一步，工具连接到客户机 VM 的内省 API，并替换目标的控制流指令为软件断点，这些偏移也需要预先提取。接下来，它注册 BREAKPOINT 和 SINGLESTEP 事件，用于根据图 4 从第一个设置中进行控制流跟踪。

我们修改了 Syzkaller 执行器，使其不再与 KCOV 接口交互。相反，它分配了一个覆盖率缓冲区并通过超调用（实现为带有预设寄存器值的软件中断）来传递其内存位置。每当 CPU 在执行 Syzkaller 程序期间达到断点时，基本块地址将根据当前 RIP 寄存器值报告，并写入专用覆盖率缓冲区中当前位置的大小值之后递增。由于模块加载地址在每次重启时都会变化，该工具将到达的基本块地址重基到每个模块的固定地址范围。为了避免为每个线程管理覆盖率缓冲区及其对应的基本块映射，实验设置限制为每个 VM 只运行一个非线程模式下的模糊器进程。

在 BSOD-Syzkaller 中，到达的断点不会重新激活并且只触发一次，这要求对 Syzkaller 逻辑进行一些更改。由于 Syzkaller 通常使用边缘覆盖率将两个连续的基本块链接在一起，它很可能会根据启用的断点状态创建不存在的边缘。这种效果影响了评估输入是否触发新行为并将其添加到语料库中。为了解决这个问题，我们修改了 Syzkaller 以使用块覆盖率，虽然降低了准确性，但保持了正确功能。一致的覆盖率反馈是必要的，以确保 triage 阶段对达到新程序位置的输入保持完整。因此，在进入此阶段时，模糊器发出一个专门用于 syz-bp-cov 的超调用。它重新激活所有断点并在它们被触发时不断重新激活，直到模糊器离开 triage 阶段并通过另一个超调用发出信号。使用 Syzkaller 进行模糊测试需要测试者为目标提供接口描述。

### 清单 3: Syzkaller ioctl 系统调用描述

```c
resource openat$nvctl(fd const[AT_FDCWD], fd_nvctl[fd], flags[open_flags], mode const[0])
fd_nvctl
ioctl$NVRM_IOCTL_CREATE(fd fd_nvctl, cmd const[0xc020462b], argptr[inout fileptr[in, string["/dev/nvidia"]], nvrmi_ioctl_create_t])
{
    nvrmi_ioctl_create_t
    cid int32(in)
    par int32(in)
    handle int32(in)
    cls int32(in)
    ptrptr64[in, status]
    _pad int32
    int32(inout)
}
```

基于恢复的 ioctl 结构，创建等效的 Syzkaller 描述非常简单，如清单 3 所示。第一行定义了一个资源来保存设备节点的文件描述符，将在下一行打开。第三行根据函数定义定义了一个 ioctl 系统调用，它接受文件描述符、cmd 参数和预期参数结构的指针作为参数。参数结构的定义从第五行开始，括号之间的每一行定义一个具有名称和类型的字段。

### 4 PCI 设备记录与回放

设备驱动程序的模糊测试需要运行包含受支持硬件设备的操作系统，以便目标驱动程序可以初始化和操作。不幸的是，通过 PCI 透传使用物理硬件设备进行模糊测试时，每个客户机都需要一个单独的设备。此外，模糊器可能会触发使设备进入不稳定状态甚至损坏的操作。为了解决这些问题，我们创建了一个 QEMU 虚拟设备，能够回放大部分真实 PCI 设备的行为。这使得可以在不包含物理设备的系统上进行模糊测试，并允许利用虚拟化技术更高效地利用系统资源。已有几个类似尝试解决了不同硬件家族的这个问题。[6, 15, 29, 30, 41]

### 4.1 基于 PANDA 的确定性记录

在全系统仿真中分析任何驱动程序行为都面临挑战，由于操作系统和硬件的非确定性，以及操作系统和物理设备的状态差异。
```

希望这段优化后的文本更加清晰、连贯和专业。如果有进一步的需求或需要更多的修改，请告诉我！