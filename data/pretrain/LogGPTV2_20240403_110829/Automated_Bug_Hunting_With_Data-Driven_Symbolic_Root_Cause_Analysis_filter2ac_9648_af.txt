CVE-2004-1279
Ovf
CVE-2004-1288
Ovf
CVE-2009-2629
Ovf
CVE-2009-3896
Ovf
CVE-2009-5018
Ovf
CVE-2017-7938
CVE-2017-9167
Ovf
CVE-2018-12326 Ovf
CVE-2018-12327 Ovf
CVE-2018-18957 Ovf
CVE-2019-14267 Ovf
Ovf
EDB-15705
Ovf
EDB-46807
CVE-2017-9182
UAF
CVE-2017-11403 UAF
CVE-2017-14103 UAF
CVE-2017-12858 DF
FS
CVE-2005-0105
CVE-2012-0809
FS
# BBs
41,625,163
53,490
67,772
74,723
300,071
283,157
90,738
100,186
75,404
291,275
374,830
65,198
128,427
260,986
60,849
132,302
2,316,152
2,316,133
5,980,255
127,209
108,442
ŒîRC L
Y
247
6,319
Y
Y
26,216
Y
33,211
Y
28
Y
59
1,848
Y
Y
4,051
Y
1,828
Y
8
Y
122,740
94
Y
Y
83,123
Y
19,322
Y
335
Y
296
38
Y
Y
38
Y
51
Y
1
1
Y
P
[3]
-
-
[4]
[7]
[6]
[42]
-
-
[2]
[78]
[1]
[80]
-
-
-
[45]
[45]
[69]
[5]
[100]
M
Y
-
-
Y
Y
Y
Y
-
-
Y
Y
Y
Y
-
-
-
Y
Y
Y
Y
Y
are calculated as (ùëÉ ‚àí ùêµ)/ùêµ where ùêµ is the baseline metric and ùëÉ is
with Bunkerbuster.
Results. Figure 8 shows the metrics for the SPEC benchmark.
The average tracing overhead is 7.21% with a geometric mean of
3.83%, which is within 1% of prior systems that record full PT traces,
demonstrating that the filtering and snapshot steps performed by
Bunkerbuster incur negligible additional overhead. Similar to prior
work, the storage requirement is also large for some cases, averag-
ing 1,348 MB/min, however all tests completed in under 1 minute,
so the average final size is 110 MB per workload. We believe this
is tolerable given that the data is forwarded to a storage server
and with a 10 GB quota per end-host, dozens of executions can be
stored at a time for analysis. Recall that this storage is temporary.
Once a trace is analyzed, it can be discarded to free space. The band-
width required to transfer traces currently makes Bunkerbuster
better suited to enterprise LANs/WANs as opposed to end-hosts
distributed across the internet.
Figure 9 shows the results for our Nginx benchmark. Here the
average performance overhead is only 2% with 1.6 MB of data
generated, on average, per HTTP request. With a quota of 10 GB,
traces corresponding to thousands of requests can be buffered at a
time. Requested file size had little impact on our results.
4.6 Verifying the Root Cause Analysis
Methodology. We trace proof of compromise exploits targeting
overflow, UAF, DF, and FS vulnerabilities, for the same dataset used
in the original symbolic root cause analysis work [106]. We then
analyze the recorded traces with Bunkerbuster. In each case, we
verified that our detection modules pinpoint the concise root cause
of the vulnerability, in accordance with the prior work‚Äôs results.
Results. The results of our evaluation are summarized in Table 4,
which shows the number of basic blocks in each trace, the number
Session 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea330Figure 8: Performance and storage for tracing the SPEC CPU 2006 benchmark. The average overhead is 7.21% and the geometric
mean is 3.83%. The average trace size is 1,348 MB/min and the geometric mean is 602 MB/min.
Figure 9: Overheads for tracing Nginx. The performance
overhead is under 2% and the maximum storage is 1.6 MB
per request.
of blocks between where the bug was detected and its determined
root cause, whether the root cause was correctly located, whether a
patch exists, and if so, whether the recommended constraints match
the official patch. In total, 21 bugs were evaluated. As the table
shows, Bunkerbuster‚Äôs detection modules are able to accurately
detect and localize all 21 of the tested exploits, even when traces
are over 1,000,000 basic blocks long and contain bugs that do not
manifest into an observable corruption until over 100,000 blocks
from the root cause. This gives us confidence that our symbolic
root cause analysis is correctly designed, despite now working over
partial traces in multi-path exploration.
5 LIMITATIONS & THREATS TO VALIDITY
Scope of Target Programs. Our current prototype is evaluated
on benign, unobfuscated, Linux binaries. Further work is required
to handle malware, packing, and virtualization, which fall outside
the intended scope for this system. The current prototype also
skips dynamically generated code (e.g., JIT compilation), however
our driver is capable of recording and decoding it. Although our
prototype focuses on Linux, the analysis is implemented for VEX IR,
which is architecture independent and can be ported to other OSes
that support PT, assuming the necessary system calls are modeled.
Scope of Detected Bug Classes. Bunkerbuster currently supports
detection of overflow, UAF, DF, and FS bugs, but these are not
the only types of memory corruption that can occur in programs
written in unsafe languages like C/C++. However, all approaches
to bug detection have class limitations. For example, the systems
we compare against (AFL, QSYM) rely on crashes as indicators
of buggy behavior, and consequently cannot detect non-crashing
bugs, such as ones caught by exception handlers. Conversely, it is
possible for Bunkerbuster to miss bugs that reside in program states
that it cannot reach within the allotted time. It is also possible for
Bunkerbuster to miss overflows that cannot corrupt the program
counter. Detecting UAF, DF, and FS bugs relies on knowing which
functions manage dynamic memory and accept format specifier
strings in advance. The search strategies proposed in Section 3
are used only to prioritize certain paths and therefore do not limit
Bunkerbuster‚Äôs total detection capabilities.
Reachability of Detected Bugs. As explained in Subsection 3.2,
bugs found using snapshots taken from the program‚Äôs entry point
are inherently reachable via input arguments. Conversely, bugs
found via API snapshots may not be reachable via the analyzed
program, but may be reachable by other programs that also import
the same library. In such cases, we reported the bugs to the library
maintainers, who decided to patch in most cases.
Severity of Detected Bugs. Our prototype does not currently ana-
lyze the exploitability of uncovered bugs, however our approach
is compatible with automatic exploit generation techniques [11].
Our system has found confirmed 0-day RCE vulnerabilities, demon-
strating the security relevance of our techniques.
In one case, Bunkerbuster found a bug that the developers de-
cided not to patch, labeled ‚ÄúWill Not Fix‚Äù in Table 1. In this lone
case, the develops acknowledged the bug‚Äôs existence, but decided
that the performance cost of fixing it was too high, and instead
cautioned downstream developers to take care in validating the
inputs passed to the relevant library API.
6 PRIVACY & LEGAL CONSIDERATIONS
In the evaluation, we setup an end-host and an analysis server as
separate machines to emphasize the decoupled nature of Bunker-
buster‚Äôs design. However, it is important to point out that analyzing
control flow reveals some information about the values of data vari-
ables due to program control dependencies.
The threat of control flow leaking sensitive data has been well-
studied by the side-channel research community [19], and some
sensitive applications (e.g., cryptography) use hardened code to
mitigate, however leakage in the context of traces recorded by PT
has not been formally studied, to the best of our knowledge. Conse-
quently, we envision the end-hosts and analysis servers belonging
to the same or trusted parties where leakage is not an issue. How-
ever, it is possible for these machines to belong to different parties,
raising privacy and legal concerns (e.g., Europe‚Äôs General Data Pro-
tection Regulation, a.k.a., GDPR). Further research is required to
fully understand this risk, which is outside the scope of this work.
Notice however that there exists prior work on sanitizing artifacts
like crash dumps [35], some large corporations may already be
recording PT traces from end-users [41], and once the analysis is
distilled into a root cause report, its privacy risk diminishes, as can
be seen in the example report shown in the Appendix (Figure 10).
437.leslie3d435.gromacs473.astar445.gobmk450.soplex436.cactusADM483.xalancbmk462.libquantum459.GemsFDTD447.dealII453.povray454.calculix403.gcc464.h264ref481.wrf471.omnetpp434.zeusmp456.hmmer482.sphinx3400.perlbench458.sjeng465.tonto410.bwaves401.bzip2429.mcf416.gamess470.lbm444.namd433.milcAverageGeometric Mean0.00%20.00%05000Performance (%)Storage (MB/min)0.10.51101000.00%2.00%020Performance (%)Storage (MB/min)Session 2A: Fuzzing and Bug Finding CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea3317 RELATED WORK
Symbolic Analysis & Fuzzing. Early work in symbolic analysis
proposed treating inputs as symbols to aid in testing code [18,
29, 64]. Over time, the applications of symbolic analysis ex-
panded to include replaying protocols [75], vulnerability detec-
tion [44, 74, 88, 98], side-channel analysis [19], firmware analy-
sis [94], verifying the correctness of cryptographic methods [24, 25],
emulator testing [72], and automatic binary patching [77, 93]. Our
work distinguishes itself from prior techniques like loop-extended
symbolic execution (LESE) [88] in how it relies on novel uses of con-
crete data rather than a different type of symbolic lattice or grammar
to achieve scalability. Whereas LESE has been evaluated on small
CLI programs like Sendmail to uncover overflows, Bunkerbuster
handles large plugin-based GUI tools like GIMP and also finds in-
stances of orthogonal bug classes like UAF, DF, and FS. LESE cannot
be extended to discover these classes because exploring loops is
orthogonal to their life cycles.
An alternative approach to bug hunting is fuzzing [23, 36, 37, 43,
52, 56, 72, 85, 86, 110], which instead enumerates possible inputs
to a program or API and checks for crashes as an indicator of
buggy behavior. As mentioned in Section 1, some of the challenges
with fuzzing are acquiring good seed inputs, reaching deep APIs,
and identifying the nature of the bug when a crash does occur,
typically using additional tools like AS. Although Bunkerbuster
does not rely on fuzzing, it addresses the same usability challenges.
While we consider the ability to collect traces from production
systems with minor overhead to be a key novelty of our design,
Bunkerbuster is technically capable of collecting traces from fuzzers
as an alternative, should the user of our system not have access to
production systems to monitor.
Many practical systems focus on concolic execution, whereby real
executions are used to guide symbolic analysis without getting stuck
in loops or string parsing [61, 90, 95]. Although Bunkerbuster also
explores nearby paths with guidance from concrete data to discover
vulnerabilities [22], our design takes a unique approach to avoiding
path explosion. Namely, rather than turning to hybrid techniques
that incorporate fuzzing [17, 27, 99, 111], source code [48], or prior
crashes [82] to find more inputs (that can still lead to path explosion
during symbolic analysis), we propose ways to leverage control
flow traces. Bunkerbuster‚Äôs symbolic states enable it to detect a
wide range of vulnerabilities (overflows, UAF, DF, FS) whereas prior
taint-based tracing approaches are limited to a specific class, such
as heap overflow [59]. Also, whereas many prior concolic systems
have to operate in lockstep with the concrete environment [28,
59], Bunkerbuster‚Äôs tracing is completely decoupled from analysis,
granting low overhead.
had to be manually fixed to account for complex structures and
callbacks while a large portion of the remaining 95% required minor
manual tweaks. Bunkerbuster does not exhibit these shortcomings.
Root Cause Analysis. One of the oldest forms of root cause anal-
ysis is delta debugging [113], whereby comparisons are made be-
tween concrete program states for successful and failing inputs to
pinpoint differences. Unfortunately, this requires having an ample
number of test inputs in both classes to be effective. Alternatively,
program slicing [87] can use tainting to identify the instructions
that contribute to a failing instruction, even for a lone case, however
the result can be hard to understand, with flagged instructions being
sparsely scattered throughout the program. Conversely, Bunker-
buster‚Äôs root cause analysis leverages neighboring symbolic states,
performing comparisons to pinpoint a concise root cause (unlike
slicing), using symbolic constraints instead of concrete variables
(unlike delta debugging), requiring only a single trace. Another
approach to root cause analysis is failure sketching, however this is
typically applied to bug classes like race conditions [63], or higher
level issues in websites [8], insecure use of keys [68], and other
domains outside Bunkerbuster‚Äôs scope [110].
It is also possible to produce root cause explanations by triaging
the many crashes produced by tools like fuzzers into buckets of
related cases. Bucketing can be done symbolically [81], semantically
with program transformations [101], or statistically [16]. These lines
of research are spiritual successors to delta debugging and carry
similar limitations. Namely, they can only analyze bugs that result