dow  are averaged.  To simplify  our presentation,  we plot- 
ted only the 4-day averages here.  We can see from the fig- 
ure that intrusion datasets have much higher misclassifica- 
tion rates, in ranges clearly separated from the correspond- 
ing  normal  datasets.  For  normal  data,  models  from  the 
(more) partitioned  datasets have much better performance, 
and models from the datasets with added temporal and sta- 
tistical features also have better performance on normal test 
data. 
Note that  compared  with  the  results  from  experiments 
on sendmail data, here the relationship between conditional 
entropy  and  misclassification  rate  is  not  as  clear  because 
the  features  we  added can  only  approximate the  sequen- 
tial dependencies. We are experimenting the ‘‘place holder” 
method (see Section 2.4) to construct features that directly 
represent sequential dependencies. 
4  Discussion 
In this section, we discuss the advantages as well as lim- 
itations of our work. 
in 
As 
illustrated 
the  case  studies,  we  can  use 
information-theoretic measures to characterize regularity in 
audit data and  to  guide the model building  and evaluation 
process.  In our experiments, we exhaustively computed the 
models, for example, using different sequence lengths, only 
for the  purpose  of  showing the  relationship  between reg- 
ularity  and  detection  performance.  Once  we  understand 
this  relationship,  in  practice,  we  can  simply  compute  the 
regularity of a given dataset and determine how  to build a 
model.  Computing regularity, in general, is much more ef- 
ficient than computing a model. Therefore our approach is 
much superior than the current ad-hoc and expensive trial- 
and-error practice where there is no guideline for building a 
model and explaining its performance. 
False  alarm rate  is  a  very  important performance mea- 
sure for intrusion  detection in general and anomaly detec- 
tion  in  particular.  We  believe  that  because  of  the  proba- 
bilistic nature of anomaly detection, alarms should be post- 
processed  so that sporadic false alarms due to the inherent 
uncertainty  in  data can  be  filtered  out.  For  example,  for 
sendmail  data,  we  use  misclassification  rate  on  the  whole 
trace,  instead  of  individual  misclassification,  for detecting 
anomalies.  Likewise for network  connection data,  we can 
use misclassification  rate on a (time) segment for anomaly 
detection.  We  believe that  anomalies  within  a single con- 
nection,  e.g.,  a  “buffer  overflow”  attack  to  a  program on 
the destination  within  a telnet connection, can  be best  de- 
tected  using  models on lower  level  data,  e.g.,  system  call 
data of the target program. Regardless how alarms are post- 
processed, the model needs to have high accuracy (e.g.,  for 
normal data,  a  low  misclassification  rate).  Therefore,  we 
can  say  that regularity  in audit data (indirectly) influences 
false alarm rate. 
We have not attempted to explain or reason why certain 
regularity  exists in  a  particular dataset.  The motivation  is 
to  make  our  approach independent  of  the  assumptions  of 
the  underlying  computing environments  because after  all, 
we aim  to develop general  theories and tools for anomaly 
detection.  In practice, our approach can always be compli- 
mented by  using  expert domain knowledge to validate the 
computed regularity. 
We have shown that there is a relationship between reg- 
ularity and detection performance when the model is a clas- 
sifier. There are other probabilistic algorithms, e.g., cluster- 
ing, Bayesian modeling,  Hidden Markov Model, etc.  that 
can  be  used  for  anomaly  detection.  Can  we  use  similar 
information-theoretic measures for these algorithms?  And 
more  fundamentally,  can  we  select  the  best  algorithm  to 
build  model based  on the regularity  of  data?  These ques- 
tions are for our future work. 
Our experiments  with  regularity  measure on sequential 
dependencies,  i.e., conditional entropy, are all  on fixed se- 
quence length or time window models. Debar et al. showed 
that although a variable-length  pattern matching model for 
sendmail data is more difficult to build, it can be more ef- 
fective  [5]. Likewise,  using  variable  time  window  based 
on network traffic  load may also improve detection perfor- 
mance. Naively, from a conditional entropy plot, we can es- 
timate the performance of various sequence lengths (or time 
windows), build  multiple  models  with  different sequence 
lengths, and select an appropriate models to use in run-time 
based  on  the  relative  conditional  entropy  between the  se- 
quences in run-time and in training. A better approach is to 
build an adaptive model that can dynamically adjust to dif- 
ferent length based on run-time information. We will extend 
140 
our approach to facilitate the construction of such models. 
5  Related Work 
Anomaly detection is an important research area in intru- 
sion detection. In earlier systems, a normal profile for a user 
or program  is  usually  based  on statistical  measures of  the 
system  features, e.g., the CPU usage,  the  number of  shell 
commands used, etc [ I ,   1 1,  271.  In  several recent studies, 
learning-based  approaches  were  applied  to  build  anomaly 
detection models using  system  call data of privileged pro- 
grams [6, 7,  15, 291.  Lane et al. [I21 proposed  a learning 
algorithm for analyzing user shell command history to de- 
tect anomalies. The algorithm attempts to address the “con- 
cept  drift”  problem,  i.e.,  when  the  normal  user  behavior 
changes.  EMERALD  [25]  uses  statistical anomaly detec- 
tion modules to monitor network traffics and a “resolver” to 
correlate alarms from misuse and anomaly detectors across 
an enterprise. While these systems all have some degree of 
success, they were developed for a particular kind of envi- 
ronment.  The fundamental question  of  “how to build  and 
evaluate anomaly detection model in general” has not been 
adequately  addressed.  As  a result,  the  approaches devel- 
oped  in  these studies may  not be  applicable to other envi- 
ronments. 
Researchers  have  begun  to develop principles  and  the- 
ories  for  intrusion  detection.  Axelsson  [2]  pointed  out 
that the established field of detection and estimation theory 
bears similarities  with  the  IDS domain.  For example,  the 
subject of  an  anomaly detection  model  corresponds to the 
“signal  source”  in  detection  and estimation  theory,  audit- 
ing mechanism corresponds to “signal transmission”, audit 
data corresponds to “observation space”, and in both cases, 
the task is to derive detection rules. Therefore, results from 
detection and estimation theory, which have been found ap- 
plicable to  a wide  range of  problems,  may  be used  in  the 
IDS domain.  One of the key  findings by  Axelsson  is that 
when building  a detection model, both anomaly and  intru- 
sion  data  is  needed  to  ensure  detection  performance.  In 
previous work  [ 171, we showed that using  labeled training 
dataset with normal and intrusion connections, we can build 
highly effective classifier for intrusion detection. However, 
in  practice,  it  is  difficult  to  obtain  intrusion  data.  In  this 
work,  we  therefore  focus  on  the  problem  of  how  to  build 
anomaly detection models when only normal data is avail- 
able for training.  Another key finding by  Axelsson is that a 
detection model should be optimized for some utility  func- 
tion, not  necessarily statistical accuracy, and instead could 
be  some definition of cost.  We  are studying how  to build 
cost-sensitive IDS, i.e., an IDS that provides the best-valued 
protection [ 141. 
The most  related  work  is  by  Maxion et  al.  [22],  where 
the relationship  between  data  regularity  and  anomaly de- 
tection  performance  was  studied.  The  study  focused  on 
sequence  data,  and  hence  regularity  is  defined  as  condi- 
tional  entropy.  The key  result  from experiments  on  syn- 
thetic data is that when an anomaly detection model is tested 
on datasets with varying regularity values, the detection per- 
formance also varies. This suggests that the current practice 
of deploying  a particular anomaly detection system across 
different environments is perhaps flawed and should be re- 
considered.  Our study  here confirmed  this  finding in  that 
we showed that the expected detection performance can be 
attained only when the relative conditional entropy between 
the training and testing datasets is small. Our study is more 
extensive because  we used  real  system  and network audit 
data in our case studies, and more importantly, we defined 
more  information-theoretic  measures  and  showed  how  to 
use them to build anomaly detection models. 
6  Conclusion and Future Work 
In  this  paper,  we  proposed  to  use  some  information- 
theoretic measures for anomaly detection.  Entropy can  be 
used  to  measure  the  regularity  of  an  audit dataset  of  un- 
ordered records.  conditional entropy can  be used to mea- 
sure the regularity  on  sequential dependencies of  an  audit 
dataset of  ordered records.  Relative  (conditional) entropy 
can be used to measure the similarity between the regularity 
measures of two datasets. Information gain of  a feature de- 
scribes its power in classifying data items. Information cost 
measures the computational cost of processing audit data by 
an anomaly detection  model.  We discussed that these mea- 
sures can be used to guide the model building process and 
to explain the performance of the model. 
In  the  case  studies  on  sendnzail  system  call  data,  we 
showed that  we  can  use  conditional  entropy  to  determine 
the  appropriate  sequence  length  for  accuracy  only  or  for 
the trade-off between accuracy and cost, a problem that has 
been posed but not solved by  the community.  We showed 
that when relative conditional entropy is low, the detection 
performance on the testing dataset is comparable to that on 
the training dataset.  In the case study on  network data, we 
showed that entropy  can be used  to direct the partitioning 
of a dataset (i.e., refining the subject) and build better mod- 
els.  We also showed evidence that conditional entropy can 
be used to guide the construction of temporal and statistical 
features. 
Although our work  is still preliminary, we  are very en- 
couraged by the results thus far. We have intended to show 
that  despite  the  need  for expert  domain  knowledge when 
building  an  IDS, theoretical  understandings  and  tools  are 
not  only  necessary,  but  also possible.  Although one  may 
argue that  our results  are  obvious  (or  not  surprising),  we 
feel that it is very important to develop a formal framework, 
even just for stating and validating  the obvious, so that  the 
141 
field of  intrusion detection  can progress more  rapidly and 
rigorously. 
As  for future work, besides  conducting  more compre- 
hensive experiments and evaluations, we will study how to 
extend our information-theoretic measures to accommodate 
algorithms other  than  classification  for  building  anomaly 
detection models. We will study how to determine the best 
algorithm to use  based on  regularity  of the data.  We  will 
also study how to build model with variable sequence length 
or time window. 
Acknowledgments 
This research is supported in part by grants from DARPA 
(F30602-00- 1-0603). Roy Maxion of Carnegie Mellon Uni- 
versity has provided insightful and valuable suggestions. 
References 
[ I ]   D. Anderson, T. Frivold, and A. Valdes. Next-generation in- 
trusion detection expert system (NIDES): A summary. Tech- 
nical  Report  SRI-CSL-95-07, Computer Science  Labora- 
tory, SRI International, Menlo Park, California, May 1995. 
[2]  S. Axelsson.  A preliminary attempt to apply detection and 
estimation theory to intrusion detection.  Technical report, 
Department of Computer Engineering, Chalmers University 
of Technology, Goteborg, Sweden, 2000. 
[3]  W.  W.  Cohen.  Fast effective rule  induction. 
In  Machine 
Learning:  the  12th  International  Cotlference, Lake Taho, 
CA, 1995. Morgan Kaufmann. 
[4]  T.  M. Cover and J.  A.  Thomas.  Elements  of  IrEformarion 
Theory. Wiley, 199 1. 
[5] H. Debar, M. Dacier, M. Nassehi, and A. Wespi.  Fixed vs. 
variable-length patterns for detecting suspicious process. In 
Proceedings of the 1998 ESORICS (LNCS 1485), 1998. 
[6]  S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. 
A  sense  of  self  for  Unix  processes. 
In  Proceedings  of 
the  1996 IEEE Symposium  on Security and Privacy, pages 
120-128,  Los Alamitos, CA, 1996. IEEE Computer Society 
Press. 
[7]  A. K. Ghosh and A. Schwartzbard.  A study in using neural 
networks for anomaly and misuse detection. In Proceedings 
of the 8th USENIX Security Symposium, August 1999. 
[SI  K.  Ilgun,  R. A. Kemmerer,  and  P.  A.  Porras.  State tran- 
sition analysis:  A rule-based intrusion detection  approach. 
IEEE  Transactions on  Software  Engineering,  21 (3): 181- 
199, March 1995. 
[9]  V. Jacobson, C. Leres, and S. McCanne.  tcpdump. available 
via anonymous ftp to ftp.ee.lbl.gov, June  1989. 
[IO]  S. Kumar and E. H.  Spafford.  A software architecture to 
support misuse intrusion detection.  In  Proceedings of 
the 
18th National Information Security Conference, pages  194- 
204, 1995. 
[I I ]   L. A. N.  Laboratory.  Wisdom and sense guidebook.  Los 
Alamos National Laboratory. 
121  T. Lane and C. E. Brodley. Temporal sequence learning and 
data reduction for anomaly detection.  In Proceedings of 5th 
ACM  Conference on Computer & Communication Security, 
1998. 
131  W. Lee.  A  Data Mining  Framework for Constructing Fea- 
tures and Models for Intrusion Detection Systems. PhD the- 
sis, Columbia University, June  1999. 
[ 141  W. Lee, W. Fan, M. Miller, S. Stolfo, and E. Zadok. Toward 
cost-sensitive modeling for intrusion detection and response. 
In 1st ACM  Workshop on Intrusion Detection Systems, 2000. 
[I51  W. Lee and S. J. Stolfo.  Data mining approaches for intru- 
sion detection.  In Proceedings of the 7th USENIX Security 
Symposium, San Antonio, TX, January  1998. 
[16]  W.  Lee,  S. J.  Stolfo, and  P.  K.  Chan. 
Learning  patterns 
from Unix process execution traces for intrusion detection. 
In AAAI  Workshop: AI Approaches to Fraud Detection and 
Risk Management, pages 5Cb56. AAAI Press, July  1997. 
[ 171  W. Lee, S. J. Stolfo, and K. W. Mok.  A data mining frame- 
work for building intrusion detection models.  In Proceed- 
ings of the 1999 IEEE Symposium on Security and  Privacy, 
May 1999. 
[18]  R.  Lippmann,  D.  Fried,  I.  Graf,  J.  Haines,  K.  Kendall, 
D.  McClung,  D.  Weber,  S.  Webster,  D.  Wyschogrod, 
R. Cunninghan,  and M. Zissman.  Evaluating intrusion de- 
tection systems: The 1998 darpa off-line intrusion detection 
evaluation.  In Proceedings of  the 2000 DARPA Information 
Sitrvivability Corlference and Exposition, January 2000. 
[19]  R. Lippmann, J. Maines, D. Fried, J. Haines, J.  Korba, and 
K. Das. Analysis and results of the 1999 darpa off-line intru- 
sion detection evaluation. In Proceedings of  the 3rd Interna- 
tional Workshop on Recent Advances in Intrusion Detection 
(RAID 2000). October 2000. 
[20] T. Lunt.  Detecting intruders in computer systems.  In  Pro- 
ceedings of the 1993 Corlference on Auditing and  Compiiter 
Technology, 1993. 
[21]  T. Lunt, A. Tamaru, E Gilham, R. Jagannathan, P. Neumann, 
H. Javitz, A. Valdes, and T. Garvey. A real-time intrusion de- 
tection expert system (IDES) - final technical report. Techni- 
cal report, Computer Science Laboratory, SRI International, 
Menlo Park, California, February  1992. 
[22]  R. A. Maxion and K. M. C. Tan.  Benchmarking  anomaly- 
based  detection  systems.  In  Proceedings  of  the  1st Inter- 
national  Conference on  Dependable  Systems  &  Networks, 
2000. 
[23]  T. Mitchell. Machine Learning.  McGraw-Hill, 1997. 
[24]  V.  Paxson.  Bro:  A system for detecting network  intruders 
the  7th USENIX  Security 
in  real-time.  In  Proceedings of 
Symposium, San Antonio, TX, 1998. 
[25]  P.  A. Porras and P. G. Neumann.  EMERALD: Event mon- 
itoring enabling responses to anomalous  live disturbances. 
In Nationctl Information Systems Security  Conference, Bal- 
timore MD, October  1997. 
[26]  C. E. Shannon and W. Weaver. The Matliematical Theory of 
Communication. University of  Illinois Press, 1949. 
[27]  S. E. Smaha.  Haystack: An  intrusion detection system.  In 
Proceedings of the IEEE Foiirtli Aerospace Compiiter Secii- 
rity Applications Conference, 1988. 
[28]  SunSoft.  SL~IISHIELD Basic Secwitv  Module  Guide.  Sun- 
Soft, Mountain View, CA, 1995. 
142 
[29]  C. Warrender, S. Forrest, and B. Pearlmutter.  Detecting in- 
trusions using system calls: Altemative data models.  In Pro- 
ceedings of  the 1999 IEEE Symposium  on Security and  Pri- 
vacy, May  1999. 
[30]  A. Wespi, M. Dacier, and H. Debar.  Intrusion detection us- 
ing variable-length audit trail patterns. In Proceedings ofthe 
3rd International Workshop on Recent Advances in Intrusion 
Detection (RAID 2000), October 2000. 
143