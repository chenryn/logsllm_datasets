### 谱减法
先取一段非人声段音频，记录下噪声的频谱能量，然后从所有的音频频谱中减去这个噪声频谱能量
### 基于统计模型的实时降噪算法
利用统计的方法估算出音频频谱中每个频点所对应的噪声和语音的分量，是假设在噪声是比较平稳的情况上
### 子空间算法
针对一些已知噪声类型，量身定做一个降噪算法，把噪声和人声投影到一个高纬度的空间，让本来不容易分离的信号变成在高纬度占据一个可分的子空间，从而可分的信号
### 基于机器学习的降噪
通过数据训练的方式，训练人工神经网络来进行降噪
f(带噪音的音频) = 不带噪音的音频
一般用纯净的语音作为目标或者说标签，然后用纯净语音加入一些噪声生成含噪数据
传统降噪中，维纳滤波等方法，都是通过计算先验信噪比，然后在频域上对每一个频谱的频点都乘以一个小于等于 1 的系数来抑制噪声。这些在频域上乘的系数统称为频域掩码。而如何计算这个频域掩码就成了解决降噪问题的关键
机器学习的任务就是计算出频域掩码
## 回声消除
$$
z'(n)=f(x(n))-f'(x(n))+y(n)
$$
- z'(n)：消除了回声的声音
- x(n)：远端接收到的参考信号
- f：回声路径的传递函数
- y(n)：近端声音
回声消除算法的目的就是通过算法估计出回声路径的传递函数f
### 自适应滤波器
用实时更新的滤波器的系数来模拟真实场景的回声路径，然后结合远端信号来估计出回声信号，再从近端采集的混合信号中减去估计的回声，从而达到消除回声的目的
- 最小均方算法 LMS（Least Mean Square）
- NLMS
## 网络传输
### 编解码器
```mermaid
mindmap
  音频编解码器常见指标
    码率
    音质
    主观听感
      采样率
      采样位深
      通道数
    计算复杂度
      编码耗时
      解码耗时
    延迟
      算法延迟
      一包多帧
```
![不同编解码器的性能表现](/assets/20231128195837.webp)
- 语音编解码器：对语音的发声来建模进行编解码
- 音乐编解码器：从听得清晰的角度利用心理听觉来进行编码，人耳更敏感的频带需要多耗费一些码率来编码，不敏感的则少耗费一些码率
### 弱网对抗
- FEC（Forward Error Correction）：发送端通过信道编码和发送冗余信息，而接收端检测丢包，以更高的信道带宽作为恢复丢包的开销
- ARQ（Automatic Repeat-reQuest）：类似于 TCP 中的请求重传
NetEQ模块：主要包括两个模块：MCU（Micro Control Unit，微控制单元）和 DSP（Digital Signal Prcessing，信号处理单元），通过再 MCU 开辟一个比较大的缓冲区域，让一段时间内到来的数据包进行存储排序，再交给解码器进行解码
## 空间音频
![](/assets/20231129192647.webp)
人耳的耳廓在接收不同方向的音源时，会让声波以不同的路径传导至内耳。这样，不同方向的声波传输到内耳的时候，音色就会由于耳廓的形状而产生各向异性
![](/assets/2023112919271.webp)
如果音源在你的左侧，那么左耳会先接收到声波；相反如果音源在右侧，右耳会先收到声音。同时由于人的头部也会对声音的传播产生影响，如果音源在左侧，那么声波需要越过头部这个“障碍”才能传递到右耳，那么相对于左耳，音色和能量可能都会有所衰减
这是空间音频里常说的“双耳效应”，即依靠双耳间的音量差、时间差和音色差来判别声音方位的效应
人耳对距离的感知是相对的。比如声音播放时音量由小变大，我们会感觉声音在靠近
![不同频率的声波空气衰减曲线](/assets/20231129193112.webp)
### 空间音频的采集
- 人工头：通过仿生模型，构建人头和耳廓、耳道等部位，然后通过人工头上的人工耳中内置的麦克风来采集空间音频
- 入耳式麦克风：直接把左右耳道接收到的音频给录下来
- Ambisonics：把整个空间的声场都录下来，从而在回放的时候，你可以转动自己的头聆听任意方向的声音，那么就需要另一套叫做高保真度立体声像复制（Ambisonics）的技术
### 空间音频的播放
- 用耳机来还原空间音频相对比较准确
### HRTF
预先把空间中不同位置声源的空间传递函数都测量并记录下来，然后利用这个空间传递函数，我们只需要有一个普通的单声道音频以及这个音源和听音者所在虚拟空间中的位置信息，就可以用预先采集好的空间传递函数来渲染出左右耳的声音
## 音频特效
- 变调：变调其实就是要改变基频，而基频的本质是一个信号的循环周期的倒数，变调其实就是把这个循环周期进行扩大或者缩小
- 均衡器：一组滤波器，比如常见的高通、低通、带通、带阻等
- 混响
## 音频AI
- ASR（Automatic Speech Recognition）：将语音转为信号序列，根据特征序列推断出对应的音素序列，最后再转为文本。
  - 为了实现比较准确的 ASR 系统，需要构建两个主要的模型：声学模型（Acoustic Model）和语言模型（Language model）。然后通过语言解码器和搜索算法（Ligusitic Decoding and search algorithm），结合声学模型和语言模型的结果，综合选择出概率最大的文字序列作为识别的输出
- TTS（Text To Speech）：通过一个模型把文字转为语音的特征向量，再使用声码器（Vocoder）把语音特征转换为音频信号
- VPR（Voice Print Recognition）：把说话人的声音特点编码成固定长度的向量（SpeakerEmbeding）