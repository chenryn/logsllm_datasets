how do they notify. For example, RMs can create an issue on
the git repo to notify PMs, or alternatively, contact PMs via
email. This also includes whom do they notify. For example,
RMs can notify public victims such as PMs of the offend-
ing package and its dependents. More proactive notifications
would seek to notify Devs and publishing advisories to inform
other dependents and suggest fixes.
We manually evaluated each feature under the functional
section in Table I. For the review and remediation features
we contacted registry maintainers directly to report malicious
packages that we identified with our pipeline. Based on our
information exchange, we noted their responses such as what
they have in place to detect or flag suspicious packages,
and document them in the review and remediation section of
Table I. Moreover, we collected information from presentations
and blogs that disclosed the security practices of registries.
2) Threat Model: As highlighted in Figure 1, we consider
supply chain attacks that aim at exploiting upstream stakehold-
ers (i.e. PMs and RMs) in the package manager ecosystem, to
amplify their impacts on downstream stakeholders (i.e. Devs
and Users). We investigate existing reports of supply chain
attacks and elaborate on their attack vectors and malicious
behaviors.
Attack Vectors. Several threats subvert the package man-
agement supply chain ecosystem. We define them as follows
and annotate them with attack numbers in Figure 1. Registry
Exploitation 4 refers to exploiting a vulnerability in the
registry service that hosts all the packages and modifying or
inserting malicious code [21], [22]. Typosquatting 3 refers
to packages that have misspelled names similar to popular
packages in hope that Devs incorrectly specify their package
instead of the intended package [7], [16], [23]. This also in-
cludes squatting popular names across registries and platforms
(also called package masking [24]), in the hope that Devs
falsely assume their presence on a particular registry [25],
[26]. Publish 3 refers to directly publishing packages with-
out expectation of typos. This can be used for bot tracking
† The review features are unavailable in these registries and are
unsupported - (cid:35), optional - (cid:72)(cid:35), enforced - (cid:32)
compiled by the authors based on existing malware detection literature.
ways of installation on Devs’ system and code shipping capa-
bilities for PMs. Access refers to how registries authenticate
PMs to publish a package. We look at account security-
related features such as public-key authentication and multi-
factor authentication (MFA). Publish refers to how packages
are packaged and released to registries. We look at release
approaches such as upload by PMs and reference through
package development repository. We also look at packaging
features such as signing and naming rules such as typo guard.
Manage refers to how packages are managed and what con-
trols are allowed on packages. Controls can include removing
the package by version, deprecating the package, or adding
authorized collaborators. Select refers to rating or reputation
score that helps Devs select which packages to trust and add
as dependencies. We look at criteria related to the rating and
reputation of repositories and authors. Install refers to how
packages are installed by Devs. We look at features such
as install hooks which can run additional code, dependency
locking which can specify secure dependencies, and if the
package can contain proprietary code.
4
or malware-hosting [27]. Account Compromise 3 refers to
compromising accounts of PMs on the registry portal, allowing
the attacker to replace the package with a malicious package or
release malicious versions [4], [5], [28]–[30]. Infrastructure
Compromise 2 refers to the compromise of development,
integration and deployment infrastructure of PMs, allowing the
attacker to inject malicious code into packages [31]. Disgrun-
tled Insider 1 refers to authorized PMs that insert malicious
code or attempt to sabotage the package development [32].
Malicious Contributor 1 refers to a benign package that
receives a bug fix or an improvement that includes additional
vulnerable or malicious code [14]. Ownership Transfer 1 3
refers to packages that are abandoned and reclaimed or the
original owner transfers responsibility to new owners for future
development [13], [17]. The transfer can happen both at code
hosting sites and registries.
Malicious Behaviors.
In supply chain attacks, we consider
victims as downstream stakeholders such as Devs and Users in
Figure 1. Devs can be exploited directly to steal their creden-
tials or harm their infrastructure, and indirectly as a channel to
reach Users through their applications or services. Users can be
exploited to steal their credentials or harm their devices. We
refer to descriptions of existing malware in advisories [33]
and blogs [15] and summarize their malicious behaviors as
follows. Stealing refers to harvesting sensitive information and
sending them back to attackers. Various types of information
can be collected or stolen, ranging from less-sensitive machine
identifiers which can be used for tracking sensitive informa-
tion [34] including secret tokens [4], cryptocurrencies [14],
passwords and even credit cards which may lead to further
compromise or financial loss. Backdoor refers to leaving a
code execution backdoor on victim machines. The backdoor
can be implemented in various ways. It can be code generation
(e.g. eval) of a specific attribute (e.g. cookie) [29], a specific
payload [5], or a reverse shell that allows any command [35].
Sabotage refers to the destroying of system or resources. This
is less severe in the browser due to isolation, but critical on
developer infrastructure and end-user devices. This can be
done for profit and fun. The common thing is to destroy the
system by removing or encrypting the filesystem and ask for
money (ransomware) [27]. Cryptojacking refers to exploiting
the computing power of victim machines for crypto-mining.
The cryptojacking behavior [6] is a rising family of malware
that is also seen in browsers [36] and other platforms [35],
[37]. Virus refers to spreading malware by leveraging the fact
that a person can be Devs and PMs at the same time to
infect packages maintained by him [38]. Malvertising refers
to exploiting end-users who visit compromised websites or
use compromised apps to click ads associated to the attack-
ers’ publisher accounts, which drives revenue for them [39].
Proof-of-concept refers to packages without real harm, but
rather proof-of-concept that aims at demonstrating something
malicious can be done [38].
3) Security Gaps and Broken Trust: We further analyze
the previously enumerated threats under the supply chain
model in Figure 1. Registry exploitation is caused by the
implementation errors of RMs, but it is hard to launch and
rarely seen. Typosquatting and publish are caused by the
implicit trust in PMs by RMs to act benignly. Account com-
promise is caused by careless PMs and missing support of
TABLE II: Trust model changes for stakeholders in the pack-
age manager ecosystem.
RMs
Devs
Users
(cid:32)
(cid:32)
→
(cid:32)
(cid:32)
(cid:72)(cid:35)
SH/T
PMs
RMs
Devs
Users
→
Cs
(cid:32)
PMs
→
→
(cid:72)(cid:35)
(cid:72)(cid:35)
(cid:72)(cid:35) (cid:32)
(cid:32)
(cid:35)
no trust - (cid:35), majority trust - (cid:72)(cid:35), complete trust - (cid:32)
SH: Stakeholder, T: Trustee, Cs: Contributors
MFA and abnormal account detection by RMs. Infrastructure
compromise, disgruntled insider and malicious contributor are
caused by insufficient security mechanism of PMs and implicit
trust in PMs by RMs to secure their code and infrastructure.
Ownership transfer is caused by the implicit trust in new
owners by PMs and RMs to act benignly.
The security gaps require enhancement to the ecosystem
and are straightforward to fix. For example, as shown in Ta-
ble I, RMs can support or enforce features such as 2FA access
for account protection, reference (webhook-based) publish for
consistency between code hosting service and registries, and
typo detection on the client side for intent verification. In
addition, PMs and RMs can limit the owners who can manage
package releases, especially for popular ones, to minimize risks
for the ecosystem.
To better understand the broken trust, we listed the trust
model changes for stakeholders in Table II. RMs are central
authorities in the ecosystem, so PMs and Devs would have to
trust RMs to act benignly and responsibly. But on the contrary,
although RMs can still trust the majority of PMs and Devs
as a community, RMs should not trust all of them due to
potential attackers. PMs interact with contributors and other
PMs and should also weaken their trust to majority trust or
reputation-based trust, due to potential malicious contributors
and disgruntled insiders. Devs and Users, as downstream users
in the ecosystem, would have to trust the benign intent of
upstream stakeholders, although they may add some security
mechanisms for protection. On the other hand, Devs interact
with Users from the Internet and have no trust in them.
B. Empirical Measurement
Our qualitative analysis shows that the three registries cur-
rently have little to no review process for publishing packages
and existing supply chain attacks are mainly reported by the
community without automation. Intuitively, we expect more
unknown attacks still exist in the wild. Therefore, we apply
well-known program analysis techniques such as metadata,
static and dynamic analysis to spot new malware within
registries. It’s important to note that we are not inventing
new program analysis techniques, but rather leveraging insights
from existing attacks to compile a functional vetting pipeline
for analyzing packages and spotting potential attacks.
We present the workflow and internal components of the
vetting pipeline MALOSS in Figure 4, which consists of
four components: metadata analysis, static analysis, dynamic
analysis, and true positive verification. Packages from registries
are processed by the three analysis components to generate
intermediate reports which reveal suspicious activities. We
5
Fig. 4: The workflow and internal components of the vetting pipeline.
Fig. 5: Interactions between pack-
ages and the underlying system.
curate a list of heuristics rules from reported attacks for
package filtering and labeling, which are iteratively improved
when encountering false positives.
1 try{
2
3
var https= require (’https ’);
https.get ({’hostname ’:’pastebin .com ’,path:’/raw/ XLeVP82h
’,headers :{’User -Agent ’:’Mozilla /5.0 ( Windows NT 6.1;
rv :52.0) Gecko /20100101 Firefox /52.0 ’,Accept :’text/html
, application /xhtml+xml , application /xml;q=0.9 ,*/*;q=0.8 ’
}},(r)=>{
1) Metadata Analysis: Metadata analysis focuses on col-
lecting auxiliary information (e.g. package name, author, re-
lease, downloads, and dependencies) of packages and ag-
gregating them based on different criteria. All information
are directly retrieved from registry APIs. Metadata analysis
can flag suspicious packages, as well as identify packages
similar to known malware. For example, the edit distance
of package names can help group packages based on their
names, allowing pinpointing of typosquatting candidates of
popular packages. The author information can help group
packages based on authors, allowing identification of packages
from known malicious authors. Metadata analysis also includes
checking types of files shipped within packages, to identify
whether embedded binaries or native extensions are present.
2) Static Analysis: The static analysis focuses on analyzing
source files of the corresponding interpreted language for each
package manager and skips embedded binaries and native
extensions. The analysis consists of three components, manual
API labeling, API usage analysis, and dataflow analysis. To al-
low efficient processing given a large number of dependencies,
we perform modularized analysis using package summaries.
Manual API Labeling. As highlighted in Figure 5, we focus
on four types of runtime APIs in the static analysis, namely,
network, filesystem, process, and code generation. Network
APIs allow communication over various protocols such as
socket, HTTP, FTP, etc. They have been used to leak sensitive
information [40], fetch malicious payload [5], etc. Filesystem
APIs allow file operations such as read, write, chmod, etc.
They have been used to leak ssh private keys [40], infect other
packages [32] etc. Process APIs allow process operations such
as process creation, termination and permission change. They
have been used to spawn separate malicious processes [6].
Code generation APIs (CodeGen) allow runtime code genera-
tion and loading. This includes the infamous eval and others
like vm.runInContext in Node.js, which have been used to load
malicious payload [5], [30].
For the runtime of each registry, we manually go through
their framework APIs and check if they belong to any of the
above categories. To allow dataflow analysis, we further label
them as data sources if they can return sensitive or suspicious
data and data sinks if they can perform suspicious operations
on inputs. Note that an API can be both a source and a sink,
e.g. https.post in Node.js can both retrieve suspicious data and
send out sensitive information. Also, some sink APIs do not
have to be used with a source to perform malicious behaviors.
r. setEncoding (’utf8 ’);
r.on(’data ’,(c)=>{
eval(c);
4
5
6
7
8
9
10 }catch(e){}
});
r.on(’error ’ ,()= >{});
}).on(’error ’ ,()= >{});
Listing 1: eslint-scope [4] downloads malicious payload
via https.get and executes via eval.
try {
request ({
1 const request = require (’request ’);
2 ...
3 login(token = this.token) {
4
5
6
7
8
9
10 }
...
form: { ’token ’: token }
...
}, (err , res , body) => { if (err) {}; }); }
Listing 2: discord.js-user [41] steals discord tokens via its
dependency request.
For example, fs.rmdir in Node.js is a sink and raises a warning
if its argument comes from user input. But even without a
source, fs.rmdir can be used to sabotage user machines by
hardcoding the input path to the root folder. Hence, we need
to identify both suspicious APIs and their flows. Table V (in
Appendix) shows the manual labeling results in more detail.
API Usage Analysis. We parse source files of packages
into Abstract Syntax Trees (AST) using state-of-the-art li-
braries [42]–[45] and search for usage of manually labeled
APIs in AST. For APIs in the global namespace (e.g. eval
for Python), we match them against function calls using their
names. For APIs that are static methods of classes or exported
functions of modules (e.g. vm.runInContext for Node.js), we
identify their usage by tracking aliases of classes or modules
and matching their full names. For APIs that are instance
methods of classes, since identifying them in dynamically
typed languages is an open problem, we make a trade-off
and identify their usage in two ways: method name only and
method name with the default instance name. Although the
former can overestimate and the latter can have both false
positives and false negatives, we argue that
they are still
useful in estimating API usage. For example, by processing
the malicious code snippet of eslint-scope in Listing 1,