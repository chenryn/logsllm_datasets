title:A model and architecture for pseudo-random generation with applications
to /dev/random
author:Boaz Barak and
Shai Halevi
A Model and Architecture for Pseudo-Random Generation
and Applications to /dev/random
∗
Boaz Barak
Department of Computer Science
Princeton University
PI:EMAIL
ABSTRACT
We present a formal model and a simple architecture for
robust pseudorandom generation that ensures resilience in
the face of an observer with partial knowledge/control of
the generator’s entropy source. Our model and architecture
have the following properties:
• Resilience. The generator’s output looks random to
an observer with no knowledge of the internal state.
This holds even if that observer has complete control
over data that is used to refresh the internal state.
• Forward security. Past output of the generator looks
random to an observer, even if the observer learns the
internal state at a later time.
• Backward security/Break-in recovery. Future output
of the generator looks random, even to an observer
with knowledge of the current state, provided that the
generator is refreshed with data of suﬃcient entropy.
Architectures such as above were suggested before. This
work diﬀers from previous attempts in that we present a
formal model for robust pseudo-random generation, and pro-
vide a formal proof within this model for the security of our
architecture. To our knowledge, this is the ﬁrst attempt at
a rigorous model for this problem.
Our formal modeling advocates the separation of the en-
tropy extraction phase from the output generation phase.
We argue that the former is information-theoretic in na-
ture, and could therefore rely on combinatorial and statisti-
cal tools rather than on cryptography. On the other hand,
we show that the latter can be implemented using any stan-
dard (non-robust) cryptographic PRG.
We also discuss the applicability of our architecture for
applications such as /dev/(u)random in Linux and pseudo-
random generation on smartcards.
∗Work was done while in the Institute for Advanced Study
and partially supported by NSF grants DMS-0111298 and
CCR-0324906.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’05, November 7–11, 2005, Alexandria, Virginia, USA.
Copyright 2005 ACM 1-59593-226-7/05/0011 ...$5.00.
Shai Halevi
IBM, T.J. Watson Research Center
PI:EMAIL
Categories and Subject Descriptors: D.4.6 [Software]:
Security and Protection
General Terms: Security
Keywords: /dev/random, Entropy, Mixing functions, Pseudo-
randomness, Smart-cards, True randomness.
1.
INTRODUCTION
Randomness is a very useful resource, and nowhere more
than in cryptographic applications. Randomness is essen-
tial for secret keys, and inadequate source of randomness
can compromise the strongest cryptographic protocol (e.g.,
see [8]). However, the reality is that procedures for obtain-
ing random bits (called pseudo-random generators) are often
not designed as well as they could have been. This is unfor-
tunate since a security ﬂaw in this procedure translates into
a security ﬂaw in the whole system. Also, if this procedure
does not have a rigorous security proof then there is no hope
for such a proof for the whole system.
In this work we formalize the requirements that we believe
are needed from a robust pseudorandom generator, and de-
scribe an architecture to realize these properties. Underly-
ing our model is the view that randomness must be assessed
from the point of view of a potentially malicious observer,
and that this observer may have signiﬁcant knowledge about
inner workings of the system and the environment in which
it operates (and may even be able to inﬂuence that envi-
ronment). Our goal is to ensure (to the extent possible)
that even such observer cannot distinguish the output of
the generator from an endless string of random bits. Our
formal model clariﬁes the conditions that must be met to
achieve this goal, and our architecture demonstrates how to
realize the security goal when the necessary conditions are
met.
Below we refer to this potentially malicious observer as
the attacker. It is always assumed that the attacker knows
the code of the generator itself. Hence, knowledge of the
generator’s internal state would give the attacker the ability
to predict its output. The heart of any design for robust
pseudorandom generator is therefore devoted to preventing
an attacker from learning the internal state (past, present,
and future). This task is complicated by the fact that often
times the attacker can get at the internal state by “external
means”. (For example, by compromising the OS and read-
ing the memory content of the generator process.) Hence,
many designs incorporate a “refresh” mechanism, by which
the generator can modify its internal state using “new ran-
dom data”. The intent is that the new state be completely
unknown, even to an attacker with knowledge of the old
state. Common pseudorandom generators therefore consist
of two components:
The attacker interacts with the generator using these three
interfaces, and the main security goal can be informally
stated as follows:
• A function next() that generates the next output and
then updates the state accordingly. The goal of this
component is to ensure that if the attacker does not
know the state, then it cannot distinguish the output
(and new state) from random.
• A function refresh(x) that refreshes the current state
using some additional input x. The goal of this compo-
nent is to ensure that if the input has “high-entropy”
(from the attacker’s point of view) then the resulting
state is unknown to the attacker.
In some architectures these two components are mixed to-
gether, while in others they are separate. In this work we
advocate separating these components, and argue that they
are very diﬀerent in nature. Some architectures include also
an “entropy estimation” component, that tries to estimate
the entropy of the additional input before running the re-
fresh function, with the intent of running the refresh func-
tion only if the additional input is indeed “high-entropy”.
We believe that such component is counter-productive, since
the quantity we are trying to estimate is the entropy from
the point of view of the attacker. The attacker, however,
is an adversarial entity on which we know next to nothing,
so there is no conceivable way to actually estimate this en-
tropy.1 Therefore, at best the entropy estimator provides
a false sense of security. At worst it can be actively ma-
nipulated by an attacker, causing the generator to refresh
its state using data that is guessable by the attacker (or,
in some cases, preventing refresh even though the available
data is not guessable by the attacker). See Section 5.2 for
more discussion.
1.1 The model
The most important part of our formal model is modeling
the capabilities of an attacker. Loosely speaking, we con-
sider an attacker that has access to the system where the
generator is run, and has the following capabilities:
• Prompting the generator for output and observing this
output. Namely, the attacker has an interface next-bits()
that returns (say) the next m bits of output. (Through-
out this paper, m is ﬁxed to be some security parame-
ter of the generator.)
• Observing and even inﬂuencing some of the data that
is used to refresh the internal state of the generator.
Roughly, we model this by allowing the attacker to
specify the distribution from which the refresh data
in drawn. This capability can be thought of as an
interface refresh(D) that refreshes the internal state
using an input that is drawn from the distribution D
(although our formal model is a bit diﬀerent, see Sec-
tion 2).
• Revealing and even modifying the internal state of the
i.e, an interface set-state(s0) that
generator at will,
returns to the attacker the internal state and then
changes this state to s0.
1The designer of the generator may not even know much on
the system in which this generator is to run, let alone the
capabilities of an attacker on this system.
If the attacker calls refresh(D) with a “high en-
tropy distribution” D, then the output of the gen-
erator from that point and until the next set-state
call must look random to the attacker (even given
the internal state obtained from that set-state call).
Note that this security goal in particular implies that once a
“good” refresh occurred (i.e., a refresh with high entropy),
the output of the generator will look random to the attacker
even if all later refreshes are “bad” in the sense that they are
completely known or even controlled by the attacker.
1.2 Additional requirements
In addition to making the output look random, it is also
desirable that the generator protects the secrecy of the in-
put that was used in the refresh operation. The reason is
that the refresh data reveals things about the environment
of the generator, and some of these things may be important
to keep secret for various reasons. Consider for example a
generator that uses the user’s key-strokes for refresh data,
and imagine that the user types his/her password on the
keyboard. Surely we don’t want an attacker to learn the
user’s password by attacking the pseudorandom generator,
so the generator should be built to protect this input: Even
knowing the internal state of the generator before and after
the refresh operation the attacker should not be able to re-
cover a “high entropy” refresh data,2 and not knowing the
state before the refresh the attacker should not even be able
check if a certain guess for the refresh data is correct or not.
1.3 The construction
The construction uses two distinct elements. One is a ran-
domness extraction function extract(x) that converts a “high
entropy” input into a shorter “random” output. Namely, if
the input is taken from a “high entropy” source, then the
output is almost uniformly random. We comment that the
function extract need not be cryptographic at all. (See Sec-
tion 2 and Appendix A for details.) The other element is a
standard (non-robust) cryptographic PRG, that takes a ran-
dom seed and outputs a longer (e.g., of size twice the size of
the seed) pseudorandom output, denoted G(s). The output
length of the extraction function equals the seed length of
the cryptographic PRG (e.g., 128 bits if we use for crypto-
graphic PRG, say, AES in counter mode).
Given these two elements, the construction is very simple:
The internal state of the robust generator consists of a seed
of the cryptographic PRG, which we denote by s, and let
m = |s| be the security parameter.
In response to a call
next(), the generator runs G(s) to generate 2m pseudoran-
dom bits, outputs the ﬁrst m of them and replaces the state s
by the last m bits. On a call refresh(x), the generator xors
extract(x) into the current state, and then runs the crypto-
graphic PRG once more, setting s0 ← G(s ⊕ extract(x)).
1.4 Relation to previous work
The problem of designing pseudorandom generators satis-
fying similar notions of robustness is well known and many
2We can actually achieve the property of “entropic security”,
see [6].
designs have been suggested in the literature, some quite
similar to ours. In particular, the Fortuna architecture of
Ferguson and Schneier [7] is very similar to what we pro-
pose in this paper. (Some minor diﬀerences are discussed in
Section 5.2.) Thus the novelty of this paper is not in our
particular design of a pseudorandom generator. Rather it is
in our formal and rigorous deﬁnition for this generator and
in our proof that our design satisﬁes this deﬁnition. In par-
ticular, our formal model incorporates the attacks that were
discussed by Kelsey, Schneier, Wagner, and Hall in [13].
In general, robust pseudorandom generation can be viewed
as an extension of the notion of forward security, adding the
feature of automatic (or proactive) recovery from compro-
mise. Indeed, the construction that we describe in Section 4
is very similar to the forward-secure generator of Bellare
and Yee [2]. We also mention that the current design can
be thought of as the “stand-alone variant” of the proactive
pseudo-random generators of Canetti and Herzberg [4]. (In
that work they considered robust pseudorandom generation
is a distributed network where nodes can help each other
recover from state compromise.)
Finally, this work is concerned mostly with the algorithmic
aspects of robust pseudorandom generation. For an excel-
lent exposition of the system aspects we refer the reader to
Gutmann’s paper [11]. (However, we disagree with some of
Gutmann’s opinions regarding the algorithmic aspects. See
discussion in Section 5.2.)
1.5 Organization
In Section 2 below we formalize the interface refresh(·) of
the attacker that was sketched above. Then in Section 3
we complete our formal modeling, providing a formal def-
inition of a robust pseudorandom generator. In Section 4
we describe our architecture and proves that it indeed real-
izes a robust pseudorandom generator. Finally, in Section 5
we discuss several practical issues with the use of robust
generators and suggest a few application areas where an ar-
chitecture such as ours may be used. We mention some of
the related work on randomness extraction on Appendix A.
2. STATE REFRESH AND ENTROPY
EXTRACTION
In this section we formally model the attacker’s interfaces
to the state-refresh operation. An important feature of our
model is that it distinguishes between “normal” and “dys-
functional” conditions of the system. Roughly, this models
the fact that there are times when the system can harvest
enough entropy to recover from an exposure of the state,
and other times when it cannot (e.g., if the attacker installs
a monitor on the system to track the collected bits).
Following the common practice in cryptographic model-
ing, we let the attacker decide whether the system is in “nor-
mal” or “dysfunctional” state. Thus, the attacker in our
model is given two interfaces, good-refresh that models re-
freshing the state under “normal” conditions, and bad-refresh
that models refreshing the state under “dysfunctional” con-
ditions. In both cases the attacker speciﬁes the distribution
from which the refresh data is drawn, but in the “dysfunc-
tional” case the distribution can be arbitrary, while in the
“normal” case we require that this be a “good distribution”.
This section is mostly about formalizing what we mean by
“good distributions”.
2.1 Good distributions for the refresh data
What we need from a “good distribution” D is that draw-
ing x ←R D and using x to refresh the state will result in
future outputs of the generator looking random to the at-
tacker, even if this attacker knows the current internal state
of the generator. To illustrate the diﬃculties in formalizing
this notion, let Fs(x) be the function that returns the ﬁrst
output of the generator after refreshing the current state s
with the refresh data x. (Note that once the generator is
ﬁxed, the function Fs is a well deﬁned deterministic func-
tion for all s.)
Since we cannot say anything about the state of the gener-
ator before the refresh (for all we know it may be completely
controlled by the attacker), we would like to require that the
output of Fs(x) looks random to the attacker regardless of
what s is. Namely, to deﬁne what it means for a distribution
D to be “good” we could consider the following game:
1. The attacker picks the current state s,
2. A refresh data x is drawn from D,
3. The attacker is given Fs(x).