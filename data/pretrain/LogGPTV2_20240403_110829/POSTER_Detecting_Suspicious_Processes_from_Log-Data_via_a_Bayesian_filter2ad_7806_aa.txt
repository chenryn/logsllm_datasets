# POSTER: Detecting Suspicious Processes from Log-Data via a Bayesian Block Model

**Authors:**
- Daniel Andrade
- Yusuke Takahashi
- Daichi Hasumi

**Affiliation:**
- Data Science Research Laboratories, Security Research Laboratories, NEC
- Security Research Laboratories, NEC
- Kawasaki, 221-8666, Japan

**Contact:**
- PI: EMAIL
- PI: EMAIL
- PI: EMAIL

## ABSTRACT
Analyzing the behavior of an attacker is critical for determining the scope of damage in a cyber attack, facilitating recovery, and fixing system vulnerabilities. However, identifying all traces of an attacker from log data is a labor-intensive task, and existing machine learning methods often fall short. This work focuses on detecting all processes executed by the attacker. Standard anomaly detection methods, such as Isolation Forest, perform poorly because many processes are used by both the attacker and the legitimate user. To address this, we incorporate prior knowledge about the temporal concentration of the attacker's activity. We propose that an attacker is active only during a relatively small time window (block assumption) rather than at random times. We introduce a generative model that effectively incorporates this prior knowledge. Experiments on intrusion log data show that our method significantly outperforms a strong baseline that also uses the block assumption.

## CCS CONCEPTS
- **Security and privacy** → Intrusion detection systems
- **Computing methodologies** → Anomaly detection
- **Mathematics of computing** → Bayesian computation

## KEYWORDS
- Forensic data analysis
- Generative model
- Dataset creation
- Block anomaly detection

## ACM Reference Format:
Daniel Andrade, Yusuke Takahashi, and Daichi Hasumi. 2020. POSTER: Detecting Suspicious Processes from Log-Data via a Bayesian Block Model. In Proceedings of the 15th ACM Asia Conference on Computer and Communications Security (ASIA CCS '20), October 5–9, 2020, Taipei, Taiwan. ACM, New York, NY, USA, 3 pages. https://doi.org/10.1145/3320269.3405445

## 1 INTRODUCTION
Analyzing the behavior of an attacker is crucial for determining the extent of damage from a cyber attack, facilitating recovery, and addressing system vulnerabilities. Since real-time attack detection is not always feasible, forensic analysis of log data is essential. However, identifying all traces of an attacker from log data is often a laborious manual task [2]. Given a sequence of Windows event logs, our goal is to distinguish between user and attacker activities. Previous studies on applying machine learning techniques often assume the availability of clean training data, where data from the same client machine with and without intrusion is available [1, 4]. In a more realistic scenario, we do not know the start and end of an attacker's activity, and thus no training data is available for the same client at test time. This reflects the reality that due to limited log data storage capacity and uncertainty about the start of the intrusion, we only have mixed data.

Fully unsupervised methods like those in [6] and [5] score each activity individually, assuming that attacker activities are uniformly spread over time. This is an unrealistic assumption, as attackers are more likely to be active only during a relatively small time window, which we call the block assumption. A natural way to model temporal structure is to use state-dependent models like Long Short-Term Memory (LSTM) or Hidden Markov Models (HMMs) [2, 4]. However, these models struggle to capture global properties like the number of blocks. Other Bayesian methods for outlier detection, such as change-point-detection methods [8], are designed for continuous stochastic processes and cannot be directly applied to our setting.

We propose a Bayesian Block Model (BBM) that incorporates the block assumption and allows us to include prior knowledge from past cyber attacks. The BBM's simplicity makes it computationally feasible to calculate the posterior distribution exactly. We evaluate our approach on several user and intrusion event log data based on real incidents and compare it to Isolation Forest [7] and its extension that also exploits the block assumption.

## 2 PROPOSED METHOD
The most critical feature for distinguishing between user and attacker processes is the process name, such as "Word" or "Powershell." Similar to language models in natural language processing, we call the set of different process names the vocabulary. We model the size of the vocabulary from the user and attacker as coming from Poisson distributions with mean parameters κu and κa, respectively. If the vocabularies of the user and attacker are very different, detecting the attacker's processes is straightforward. Unfortunately, this is not the case, as our analysis of real data shows in Table 2. Nevertheless, we expect the probability mass functions of processes used by the user and the attacker to be different, denoted by θu and θa, respectively.

Our proposed model assumes that the attacker is active only during one time window [i, i + na], where i is the start of the intrusion, and na is the number of intrusion processes. In other words, processes in [i, i + na] follow a categorical distribution with probabilities θa, and otherwise with probabilities θu.

We assume discrete time events, and denote the time index set {a, a + 1, a + 2, ..., b} as [a, b], where a ≤ b. The process started at time index j ∈ [1, n] is denoted as wj. The sequence of observed process names is denoted as w = (w1, w2, ..., wn).

Our proposed generative model is summarized as follows:
- n − na + 1 ~ Categorical(1n−na+1)
- na ~ Poisson[1,nmax](λa)
- i ~ Categorical(1n−na+1)
- ka ~ Poisson[1,na](κa)
- ma ~ Binomial(ka, γnew)
- ku ~ Poisson[ka−ma, n−na](κu)
- θa ~ Dirichlet(1ka)
- θu ~ Dirichlet(1ku)
- For process j ∈ {1, ..., i − 1} ∪ {i + na, ..., n}: wj ~ Categorical(θu)
- For process j ∈ {i, ..., i + na − 1}: wj ~ Categorical(θa)

where 1c denotes the all-one vector of dimension c, and Poisson[a,b](λ) denotes the Poisson distribution with average parameter λ truncated to be in the interval [a, b]. A summary of all parameters is given in Table 1.

### 2.1 Inference
To find the probability that a process belongs to the attacker, we need to calculate the posterior distribution p(i, na|w). We have:
\[ p(i, na|w) \propto p(i, na, w) \]
\[ = \int p(w|θu, θa, i, na) \cdot p(θu|ku) \cdot p(θa|ka) \cdot p(i, na) \cdot p(ka|na) \cdot p(ma|ka) \cdot p(ku|ka, ma, na) dθu dθa \]

The integral has an analytic solution due to the conjugacy of the Dirichlet and categorical distributions. However, to determine the normalization constant, we need to sum over all combinations of na ∈ [1, nmax] and i ∈ [1, n − na + 1], which is in O(n^2), assuming nmax ∈ O(n). For our experiments, we set nmax = 0.1 · n.

**Table 1: Summary of all parameters.**

| Hyper-parameters (estimated from training data) | Description |
|---|---|
| λa | Expected number of attacker processes |
| κu | Expected number of different processes from the user |
| κa | Expected number of different processes from the attacker |
| γnew | Expected ratio of process names used only by the attacker |
| nmax | Maximal number of possible attacker processes |

| Test log file - Observed parameters | Description |
|---|---|
| n | Number of all processes |
| wj | Name of the j-th process |
| i | Index where intrusion starts |
| na | Number of processes used by the attacker |
| ku | Number of different process names of the user |
| ka | Number of different process names of the attacker |
| ma | Number of process names used only by the attacker |
| θa | Probability vector of the attacker’s process names |
| θu | Probability vector of the user’s process names |

## 3 EXPERIMENTS
For our experiments, we used Windows event log data collected from several users' client machines across a global organization.