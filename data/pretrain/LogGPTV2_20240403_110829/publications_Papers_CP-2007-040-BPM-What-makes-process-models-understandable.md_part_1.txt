### What Makes Process Models Understandable?

**Authors:**
- J. Mendling, Vienna University of Economics and Business Administration, Augasse 2-6, 1090 Vienna, Austria
- H.A. Reijers, Eindhoven University of Technology, P.O. Box 513, 5600 MB Eindhoven, The Netherlands
- J. Cardoso, University of Madeira, 9000-390 Funchal, Portugal

**Abstract:**
Despite the significant importance of both formal and informal quality aspects in business process modeling, there is limited empirical research on process model quality and its influencing factors. This paper investigates understandability as a proxy for the quality of process models, focusing on its relationship with personal and model characteristics. We used a questionnaire administered to students at three European universities and conducted exploratory data analysis to generate several novel hypotheses. Additionally, we interviewed practitioners to validate our findings. The results reveal that participants tend to overestimate the differences in model understandability, self-assessment of modeling competence is often inaccurate, and the number of arcs in models significantly influences understandability.

**1. Introduction**
Workflow and process modeling have been extensively used over the past 30 years, yet we know surprisingly little about the act of modeling and the factors that contribute to a "good" process model in terms of human understandability. This contrasts with the extensive body of knowledge available for the formal analysis and verification of desirable properties, particularly for Petri nets. To ensure a certain degree of design quality, several authors propose guidelines for modeling (e.g., [1, 2]), but these have had limited impact on actual practice. Clearly, an empirical research agenda is needed to gain new insights into the quality (cf. [3]) and usage aspects (cf. [4]) of process modeling.

A recent empirical study provides evidence that larger, real-world process models tend to have more formal flaws (such as deadlocks) than smaller models [5, 6]. One hypothesis related to this phenomenon is that human modelers may lose track of the interrelations in large and complex models due to their limited cognitive capabilities (cf. [7]), leading to errors that would not occur in smaller models. Other factors, such as the degrees of sequentiality, concurrency, or structuredness, are also believed to affect the understandability of a process model [8]. Empirically validating these relationships would not only advance our understanding of process model quality beyond verification but also provide a sound theoretical basis for defining general guidelines for process modeling.

**2. Related Work**
Research related to our work in the conceptual modeling area can be categorized into three streams: top-down quality frameworks, bottom-up metrics related to quality aspects, and empirical surveys related to modeling techniques.

**Top-Down Quality Frameworks:**
- **SEQUAL Framework [9, 10]:** Based on semiotic theory, this framework defines quality aspects based on relationships between a model, a body of knowledge, a domain, a modeling language, and the activities of learning, taking action, and modeling. Syntactic quality relates to the model and modeling language; semantic quality to the model, domain, and knowledge; and pragmatic quality to the model and its ability to enable learning and action. Although it does not provide an operational definition of how to determine the various degrees of quality, it has been found useful for business process modeling in experiments [11].
- **Guidelines of Modeling (GoM) [2]:** This alternative quality framework, inspired by general accounting principles, includes six principles: correctness, clarity, relevance, comparability, economic efficiency, and systematic design. It was operationalized for Event-Driven Process Chains (EPCs) and tested in experiments [2].
- **ISO 9126 Standard [12]:** Some authors advocate for a quality framework for conceptual modeling in compliance with the ISO 9126 standard for software quality. An adaptation to business process modeling is reported in [13].

Our experiments address partial aspects of these frameworks, focusing on the understandability of process models as an enabler of pragmatic quality (SEQUAL) and clarity (GoM). This requires not only asking about understandability but also checking whether models are interpreted correctly, aligning with the research of Gemino and Wand [14] on conclusions drawn from models.

**Bottom-Up Metrics:**
Several studies focus on metrics related to quality aspects of process models, though many are theoretical without empirical validation. For example:
- **Canfora et al. [21]:** Study the connection between count metrics (e.g., the number of tasks or splits) and maintainability of software process models.
- **Cardoso [24]:** Validates the correlation between control flow complexity and perceived complexity.
- **Mendling et al. [6, 8]:** Use metrics to predict control flow errors such as deadlocks in process models. These studies suggest that an increase in model size negatively impacts quality, which influenced the design of our questionnaire.

**Empirical Surveys:**
- **[25]:** Studies the maturation of business process modeling languages over time, but does not provide insights into individual process models.
- **[26]:** Examines the usability of UML, but not on the level of individual process models.
- **[27]:** Approaches understandability at the modeling language level, finding that EPCs seem more understandable than Petri nets. Inspired by this, we used an EPC-like notation in our questionnaire to minimize the impact of notation on understandability.

In summary, the primary confirmed relation in related research is that larger models tend to be negatively connected with quality. Our questionnaire aims to enhance this limited body of knowledge.

**3. Research Design**
Given the limited research on quality aspects of process models, we identified six research questions related to the factors that might influence the understandability of process models (cf. [27, 8, 28, 10]):
1. What personal factors (beyond general psychological and intellectual factors) have an influence?
2. Which model characteristics (e.g., number and type of splits) contribute to good understandability?
3. How does the modeling purpose (e.g., documentation versus enactment) relate to understandability?
4. How is understandability related to knowledge about the domain described in the model?
5. Which differences in understandability exist when observing semantically equivalent models described in different modeling languages?
6. What is the impact of different visual layout strategies or graph drawing algorithms on understandability?

We approached these questions with an experimental design focusing on personal and model characteristics (questions 1 and 2). We also aimed to neutralize the influence of other factors:
- **Modeling Purpose (Question 3):** We gathered a set of process models created for documentation purposes.
- **Domain Knowledge (Question 4):** Task labels were recoded to capital letters A to W to eliminate the influence of domain knowledge.
- **Modeling Language (Question 5):** We chose an EPC-like notation without events, providing participants with a short informal description of the semantics similar to [29, p.25].
- **Visual Layout (Question 6):** All models were drawn in the same top-to-bottom style with the start element at the top and the end element at the bottom.

**3.1 Phases of the Experiment**
The experiment was conducted in three phases:
1. **Model Collection and Questionnaire Development:**
   - We collected eight process models from practice, each with 25 tasks, and constructed two additional variants for each by changing the type of some routing elements.
   - A questionnaire was built to measure the following variables:
     - **Theory:** Students' self-assessment of theoretical knowledge in business process modeling on a five-point ordinal scale.
     - **Practice:** Students' self-assessment of practical experience in business process modeling on a four-point ordinal scale.
     - **Perceived Difficulty:** Students' assessment of the perceived difficulty of each model.
     - **Score:** Students answered a set of eight closed questions and one open question about the model. The score was calculated as the sum of correct answers, serving as an operationalization of understandability.
     - **Ranking:** Students ranked the variants of the same model regarding their relative perceived understandability.
   - The correct answers for the questions relating to the score were determined using EPC analysis tools [30]. Closed answers were evaluated automatically, while open answers were interpreted and matched with the errors detected by the tools.
   - A pre-test led to a reduction of the model set to 12 process models (four models in three variants each) and a reformulation of some questions to prevent fatigue.

2. **Questionnaire Administration:**
   - Six versions of the questionnaire with different randomized orders of models and variants were created to eliminate learning effects.
   - The questionnaire was filled out in class settings by 73 students from the Eindhoven University of Technology, the University of Madeira, and the Vienna University of Economics and Business Administration.
   - Participation was voluntary, and students were motivated by the competitive nature of the exercise and the fact that the questionnaire would help prepare them for exams.
   - The answers were coded and analyzed using SPSS and Statgraphics, resulting in 847 complete model evaluations.

3. **Expert Interviews:**
   - We conducted interviews with experts in business process modeling to validate our findings and contrast them with insights from practitioners.
   - This validation is crucial given the potential external validity issues of student experiments in information systems research (see [3]).

**Conclusion**
This paper presents an empirical investigation into the understandability of process models, focusing on the relationship between personal and model characteristics. The results highlight the tendency of participants to overestimate differences in model understandability, the inaccuracy of self-assessed modeling competence, and the significant influence of the number of arcs in models. Future research should further explore the identified factors and their implications for process modeling.