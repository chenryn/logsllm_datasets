Slide 1 
Note:
The following slides (and speaker notes) are in 
draft format.  Final presentation slides will be 
made available after both BlackHat and DEF CON.
The most significant changes will be in the 
Machine Learning section.  This deck includes 
results based on Nearest Neighbour (Weka’s
NNge algorithm). The final deck will change to 
take into account additional data and alternative 
models.
Slide 2 
Predicting Susceptibility to 
Social Bots on Twitter
Chris Sumner & Dr. Randall Wald
PI:EMAIL & PI:EMAIL
Welcome to ‘Predicting Susceptibility to Social 
Bots on Twitter’ . I’m Chris Sumner, 
representing the Online Privacy Foundation and 
I’m joined by Dr. Randall Wald from Florida 
Atlantic University. 
Before we begin, I want to ensure that people 
are aware of what the talk is and isn’t. 
What’s in it for you 
- Discuss some research in this area 
- Social Bots – links to code 
- Introduction to simple bots to play with 
- Human Behaviour Psychology 
- Look at what makes some people do things 
which other people think are dumb. 
- Data Mining & Machine Learning 
- How to collect & analyze data 
- Implications for security awareness training 
Slide 3 
TP
TL;DR
TP
FP
TP
TP
TP
TP
FP
Targeted
Spray & Pray
We examined the performance of a ‘Spray & 
Pray’ approach to unsolicited social interaction 
versus a Targeted approach using Machine 
Learning and the results will look a little like 
this.   
Slide 4 
Anyone know who this guy is?.... It’s Tim 
Hwang….  
Slide 5 
And back in early 2011 I’d stumbled upon this 
fascinating and amusing competition which he 
hosted with the Web Ecology Project… 
….it was described as… 
References: 
- 5 minute video overview - 
http://ignitesanfrancisco.com/83e/tim-hwang/ 
- http://aerofade.rk.net.nz/?p=152 
• Instantly go out and follow all 500 of the 
target users 
• every 2-3 hours, tweet something from a 
random list of messages. 
• constantly scan flickr for pictures of "cute 
cats" from the Cute Cats group and blog 
them to James' blog "Kitteh Fashun" - 
(which auto tweets to James' twitter 
timeline) 
• 4 secondary bots following the network of 
the 500 users and the followers of the 
targets to test for follow backs (and then 
getting James to follow those that followed 
back, once per day) - we believed that 
expanding our own network across mutual 
followers of the 500 would increase our 
likely hood of being noticed (through 
retweets or what have you from those who 
were not in the target set. 
Slide 6 
“It’s blood sport for internet social 
science/network analysis nerds.”
….‘blood sport of internet social 
science/network analysis nerds’. Tim and the 
Web Ecology team had… 
Slide 7 
500 targets
…selected 500 targets who all liked cats (the 
animals, not the musical) 
Slide 8 
Points
+1   Mutual Follows
+3   Social Response
-15  Killed by Twitter
3 teams took part and were given those same 
500 unsuspecting users to target. The teams 
gained 1 point for a follow back, 3 points for 
some response and they lost 15points if they 
got suspended. 
Slide 9 
Team Emp
701 Points
107  Mutual Follows
198  Social Response
2 weeks later…
@AeroFade  
The winning team achieved 701 points, 107 
mutual follow backs and 198 social responses.  
You can check out @AeroFade’s Twitter and his 
blog.   
Slide 10 
To date, most research has focus on how to 
identify bots, less research has looked at the 
other side of the question – detecting users 
likely to be fooled by bots, something which is 
important in helping raise awareness and seek 
solutions.…. 
http://www.satc-cybercafe.net/presenters/ 
http://www.satc-cybercafe.net/wp-
content/uploads/2012/10/NSF.jpg 
Slide 11 
…So while we were conducting our 2012 study 
into Twitter usage and the Dark Triad of 
personality, we figured we’d incorporate a side 
project to look at social bots and, as an 
organization, attempt to answer couple of 
questions…. 
Slide 12 
Are some users more naturally 
predisposed to interacting with 
strangers (in this case social 
bots)? 
i.e. Are some users more naturally predisposed 
to interacting with strangers (social bots) than 
others? (Does personality play a part?) 
Slide 13 
Is it possible to increase the 
odds of getting a response 
from a twitter user?
…and is it possible that social bot creators 
could use machine learning to better target 
users who are more likely to response.   
Slide 14 
….thereby (the thinking goes) reducing the 
chances of landing in Twitter Jail (account 
suspension). 
Slide 15 
Who Cares?
The obvious questions are….1) who cares and 
2) aren’t you giving the bad guys an idea. 3) 
what’s this got to do with privacy. .. we’ll look 
at these in greater depth, but…  
Slide 16 
“If it can be measured, 
it can be manipulated”
..we’ll look at these in greater depth, but one 
area which always attracted unscrupulous 
actors (think BlackHat SEO – search engine 
optimisation) are marketeers. Not *ALL* 
marketeers though.  Initially they wanted your 
‘likes’, but since that doesn’t necessarily 
translate to a purchase (because that was easy 
to game with social bots), they’re being 
requested to create ‘engagement’.   
Slide 17 
…and of course Propagandists. 
Slide 18 
The privacy implications are nicely described in 
this recent paper by Erhardt Graeff.  
Slide 19 
..conversely, existing social media sites are getting much 
better at detecting bots so part of an effective bot strategy 
is reducing the chances of ending up in Twitter jail. 
Slide 20 
So set to work, or rather our bots did. 
Slide 21 
Contents/Flow
• History & Current Research
• Experiment & Method
• Findings
• Conclusions
The rest of the talk flows like this. 
Slide 22 
Socialbots
“A socialbot is a piece of 
software that controls a 
user account in an online 
social network and passes 
itself of as a human” 
(Wagner et al)
Wagner et al (2012)” 
Wagner et al define these as a piece of 
software that controls a user account in an 
online social network and passes itself of as a 
human. 
The socialbot M.O. is to (1) make friends, (2) 
gain a level of trust, (3) influence 
The success of a Twitter-bomb relies on two 
factors: tar- getting users interested in the 
spam topic and relying on those users to spread 
the spam further.  
(http://journal.webscience.org/317/2/websci1
0_submission_89.pdf) 
• Sybils - The Sybil Attack (Doucer, 2002) 
• SockPuppets - an online identity used for 
purposes of deception (see also, Persona 
Management) 
Slide 23 
Bots aren’t new, Chatterbots featured in 
research around 1994. In this talk we’re really 
examining bots in social media, which for the 
sake of argument, we’ll split into 1st Generation 
and 2nd Generation bots… 
Slide 24 
Popularity
Photo Credit : http://mashable.com/2009/04/01/social-media-cartoon-the-twitter-follower-bots/  
Early bots tend to be all about making you look 
popular (with fake followers). These are still 
hugely popular and according to a recent NY 
Times article, remain a lucrative business, but 
ultimately they’re pretty dumb. 
http://bits.blogs.nytimes.com/2013/04/05/fak
e-twitter-followers-becomes-multimillion-
dollar-business/ 
Slide 25 
Spam
…then there’s good old-fashioned spam…. 
@spam: The Underground on 140 Characters 
or Less (Grier, 2010) 
http://imchris.org/research/grier_ccs2010.pdf 
Slide 26 
Keyword aware
..some bots are all about humour… 
Slide 27 
…and in the case of @AI_AGW, some respond 
to climate change deniers…  These are all 
pretty basic and remain prevalent today. 
Slide 28 
In 2008 we see the first (Publicly at least) 
manifestation of a social bot on Twitter.  
Project Realboy plays with the concept of 
creating more believable bots.  Here’s what 
they did…. 
This is around the same time that Hamiel and 
Moyer shared their talk “Satan Is On My 
Friends List” highlighting that some of your 
social media friends may be imposters.  We 
saw another example of that in the 2010 ‘Robin 
Sage’ talk at Blackhat. 
Project Realboy by Zack Coburn & Greg Marra - 
http://ca.olin.edu/2008/realboy/ 
Slide 29 
Virtual Plots, Real Revolution 
(Temmingh and Geers - 2009)
“For example, in the week before an election, 
what if both left and right-wing blogs were 
seeded with false but credible information 
about one of the candidates? It could tip the 
balance in a close race to determine the 
winner”
Things get a bit more sinister in 2009. A 2009 
paper by Temmingh and Geers (Roelof 
Temmingh of Sensepost/Paterva/Maltego 
fame) states “For example, in the week before 
an election, what if both left and right-wing 
blogs were seeded with false but credible 
information about one of the candidates? It 
could tip the balance in a close race to 
determine the winner”.   
Source: R Temmingh 
http://www.ccdcoe.org/publications/virtualbat
tlefield/21_TEMMINGH_Virtual%20Revolution
%20v2.pdf 
Slide 30 
V
1 year later…
…and in 2010 (if not earlier) we see it play out 
for real.  “Four days before the 2010 special 
election in Massachusetts to fill the Senate seat 
formerly held by Ted Kennedy, an anonymous 
source delivered a blast of political spam. The 
smear campaign launched against Democratic 
candidate Martha Coakley quickly infiltrated 
the rest of the election-related chatter on the 
social networking service Twitter. Detonating 
over just 138 minutes, the “Twitter bomb” and 
the rancorous claims it brought with it 
eventually reached tens of thousands of 
people.”….   
Source - 
http://www.sciencenews.org/view/feature/id/
345532/description/Social_Media_Sway 
Some notes  
“A single change in the decision to vote can 
affect many individuals….Because…. there are 
competing effects between the decay of 
influence and the growth in the number of 
acquaintances…….. But as people hang out with 
like minded individuals… cascades will not be 
zero sum So the decision of a single individual 
to vote has a substantially larger impact than 
what an atomized theory of individuals might 
say….. “ 
Truthy: Mapping the Spread of Astroturf in 
Microblog Streams 
Detecting and Tracking Political Abuse in Social 
Media 
“…Here we focus on a particular social media 
platform, Twitter, and on one particular type of 
abuse, namely political astroturf — political 
campaigns disguised as spontaneous 
“grassroots” behavior that are in reality carried 
out by a single person or organization. This is 
related to spam but with a more specific 
domain context, and potentially larger 
consequences.” 
Sep. 28, 2010 — Astroturfers, Twitter-bombers 
and smear campaigners need beware this 
election season as a group of leading Indiana 
University information and computer scientists 
have unleashed Truthy.indiana.edu, a 
sophisticated new Twitter-based research tool 
that combines data mining, social network 
analysis and crowdsourcing to uncover 
deceptive tactics and misinformation leading 
up to the Nov. 2 elections. 
http://www.sciencedaily.com/releases/2010/0
9/100928122612.htm 
Also - http://cs.wellesley.edu/~pmetaxas/How-
Not-To-Predict-Elections.pdf 
Slide 31 
Swift-Boating  
…this type of campaign has a name, 
Swiftboating – “The term swiftboating (also 
spelled swift-boating or swift boating) is an 
American neologism used pejoratively to 
describe an unfair or untrue political attack. 
The term is derived from the name of the 
organization "Swift Boat Veterans for Truth" 
(SBVT, later the Swift Vets and POWs for Truth) 
because of their widely publicized[1] then 
discredited campaign against 2004 US 
Presidential candidate John Kerry” (Wikipedia – 
26th March 2013) 
Slide 32 
Photo Credit : http://www.guardian.co.uk/world/2012/feb/07/hacked-emails-nashi-putin-bloggers  
and allegedly, prior to the 2012 Russian 
Presidential elections, a pro-Kremlin 
organization reportedly paid hundreds of 
thousands of $’s to network of internet users to 
help political cause by creating flattering 
coverage on Vladamir Putin. 
An article in the Economist describes the 
Russian smear campaigns as reaching “farcical 
levels”, 
http://www.economist.com/blogs/easternappr
oaches/2012/02/hackers-and-kremlin 
http://www.themoscowtimes.com/news/articl
e/campaign-mudslinging-taken-to-new-
lows/452583.html 
Source - 
http://www.guardian.co.uk/world/2012/feb/07
/hacked-emails-nashi-putin-bloggers 
Slide 33 
Astroturfing
“It could tip the balance in a close race to determine 
the winner” (Temmingh & Geers, 2009)
This is a little different to Swift-boating in that 
it’s generally not a smear 
campaign…Astroturfing - refers to political, 
advertising or public relations campaigns that 
are designed to mask the sponsors of the 
message to give the appearance of coming 
from a disinterested, grassroots participant. 
Slide 34 
…This is essentially what gave rise to Truthy, a 