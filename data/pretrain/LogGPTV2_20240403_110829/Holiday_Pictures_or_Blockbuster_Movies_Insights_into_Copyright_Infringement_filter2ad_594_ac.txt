Megaupload samples. As a corollary, the remaining ﬁle names were automati-
cally classiﬁed as unknown (in addition to those already classiﬁed as unknown
by all three researchers because of ambiguous ﬁle names). This was partially
due to Filefactory and Megaupload hosting the largest fraction of ﬁles named
in foreign languages and coming from cultural backgrounds that the researchers
were not familiar with. These OCHs also hosted the largest detected fraction
of legitimate ﬁles. In our experience, such ﬁles were generally more diﬃcult
to classify than large-scale commercial content because the situation was of-
ten more ambiguous, leading one researcher to label a ﬁle as legitimate while
Table 3. Consensus among the three labellers for the overall assessment and heuristics
Frequency of Consensus (%)
Heuristic
FF
ES
FS WU MU
UL
Overall Assessment 57 ■
I1 Warez Name
I2 Uploader Name
I3 Indexing URL
I4 Commercial
I5 Keywords
I6 Obfuscated
L1 Freeware
L2 Legit. Extension
L3 Personal
95 ■
99 ■
98 ■
73 ■
94 ■
98 ■
98 ■
97 ■
85 ■
79 ■
92 ■
98 ■
99 ■
82 ■
72 ■
96 ■
99 ■
98 ■
97 ■
77 ■
88 ■
97 ■
97 ■
75 ■
87 ■
98 ■
86 ■
81 ■
98 ■
95 ■
76 ■
78 ■
98 ■
99 ■
100 ■
93 ■
100 ■
100 ■
99 ■
56 ■
90 ■
91 ■
91 ■
72 ■
87 ■
96 ■
98 ■
98 ■
92 ■
84 ■
85 ■
94 ■
96 ■
72 ■
77 ■
99 ■
100 ■
100 ■
100 ■
382
T. Lauinger et al.
l
e
p
m
a
s
n
i
n
o
i
t
r
o
p
o
r
p
1.0
0.8
0.6
0.4
0.2
0.0
F
F
S
E
S
F
W U
OCH
M U
L
U
legitimate
legitimate if majority, else unknown
unknown
infringing if majority, else unknown
infringing
Fig. 1. The ﬁle name classiﬁcation results for the six samples. The area shaded in dark
grey corresponds to ﬁles with unknown classiﬁcation. If only a majority among the
three labellers is required for classiﬁcation, the entire hatched area above corresponds
to the proportion of legitimate ﬁles, whereas the hatched area below corresponds to
ﬁles classiﬁed as infringing. In the more conservative case requiring consensus between
the three labellers, the areas shaded in light grey become unknown. The plot shows
95 % conﬁdence intervals. The real-world ratio between infringing and legitimate ﬁles
is likely to lie in the unknown area (plus conﬁdence intervals).
the others marked it as unknown. Other OCHs exhibited a less ambiguous work-
load. The “benchmark” data set Undeadlink, for instance, was labelled with a
16.3 % dissent rate plus 4.2 % consensually unknown ﬁles, resulting in 20.5 %
unknown ﬁles for overall. Across all OCHs, pornography was frequently clas-
siﬁed as unknown, especially when the ﬁle name contained a scene number as in
my-sexy-kittens-29-scene1.mp4, because it remained unclear whether it was
an infringing copy or public advertisement material.
The situation for the individual heuristics was similar, except that all decisions
were binary and did not permit an unknown value. Obfuscated ﬁle names (I6)
were diﬃcult to classify because it was often unclear whether a ﬁle name was
random or an unrecognised (but meaningful) abbreviation. For shareware, it
was often impossible to distinguish between a cracked version and a legitimate
evaluation copy. The degree of consensus is lowest for I4 (commercial content)
because it was the heuristic where the most non-trivial decisions had to be made.
Other heuristics such as L1 (freeware) clearly did not apply to most ﬁles. The
few realistic candidates for freeware often led to disagreements, but their number
was small compared to the overall size of the data sets.
5.2 Overall File Classiﬁcation
We were able to detect signiﬁcant proportions of legitimate uploads only for
Filefactory and Megaupload. Figure 1 shows that for the remaining OCHs, even if
Insights into Copyright Infringement in User Uploads to One-Click Hosters
383
we assumed all unknown ﬁles to be legitimate, we would still estimate more than
half of all uploads to be infringing. One possible explanation for this eﬀect is that
Filefactory and Megaupload were the oldest OCHs in our data sets, which might
have allowed them to gain popularity with legitimate users. Wupload, in contrast,
had been launched just a few months before our measurement. We estimate that
at least 79 % of the ﬁles uploaded to Wupload during our measurement infringe
copyright, the highest proportion among the OCHs in our data sets. As expected
in Section 4.1, Undeadlink equally exhibits a very high level of infringing ﬁles.
The estimated lower bound of 4.3 % legitimate ﬁles on Megaupload might not
seem very high, but compared to the overall estimate of 250 million hosted
ﬁles, this still implies that the forced Megaupload shutdown resulted in at least
10.75 million legitimate ﬁles being taken oﬄine.
Because the consensus approach might be overly conservative for some of
the diﬃcult decisions, we additionally merged the classiﬁcations of the three
labellers using a majority voting algorithm: A ﬁle was labelled as legitimate
or infringing when at least two of the researchers agreed. The diﬀerence be-
tween the two approaches is shown in Figure 1 through the diﬀerent shades of
grey. The majority strategy allows to classify more ﬁles as legitimate or infring-
ing and thereby reduces the number of unknown ﬁles. However, this comes at
the cost of lower conﬁdence in the accuracy of the labels, thus we decided to
retain the more conservative consensus merging for the remainder of this pa-
per.
5.3 Heuristic Analysis
Given the overall classiﬁcation, we visualise in Table 4 the probability of each
heuristic. The heuristics for commercial content (I4) and ﬁle sharing keywords
(I5) apply frequently to the ﬁles classiﬁed as infringing, e.g. I4 applies to 80 %
of the infringing ﬁles on Undeadlink, but only very rarely to ﬁles classiﬁed as
legitimate or unknown. Similar results hold for legitimate ﬁle extensions (L2) and
personal content (L3), which apply almost exclusively to ﬁles classiﬁed as legiti-
mate. All three labellers classiﬁed .jpg as a potentially legitimate ﬁle extension,
which was fairly frequent on Filefactory. However, not all .jpg ﬁles were eventu-
ally labelled as legitimate because some of them contained the names of models,
for instance, leading to a relatively high number of unknown ﬁles with legitimate
extensions. All in all, the heuristics apply to the ﬁle classiﬁcations in a consis-
tent manner, which increases our conﬁdence that the overall classiﬁcation is
reasonable.
Among the automated heuristics, infringing ﬁles were split more frequently
than legitimate ﬁles. Even though most infringing ﬁles were uploaded multiple
times, there were non-negligible numbers of legitimate ﬁles that were duplicates
as well. Surprisingly, there was a generally low number of DMCA takedown
notices or hits in our database of infringing ﬁles for ﬁle names of all classiﬁcations.
Heuristic A3 (public links) appears to be a poor indicator for infringement as
it applies to legitimate ﬁles as much as to infringing ﬁles. This supports our
384
T. Lauinger et al.
opinion that automated classiﬁers not based on “curated” ﬁle name, checksum
or provenance blacklists are likely to suﬀer from high false positive rates.
5.4 File Extensions
We analysed the ﬁle extensions being used in the full reassembled data sets
(including incomplete ﬁles). Table 5 shows the ﬁve most frequent ﬁle extensions
and the associated ﬁle extension entropy per data set. Some OCHs exhibit a
more uniform ﬁle type workload than others, with their ﬁle extension distribution
being more heavily skewed toward .rar archives, .avi movies and .mp3 audio
ﬁles. This observation is captured by a lower ﬁle extension entropy and appears
to be correlated with a higher estimated proportion of copyright infringement
as reported in Table 4. A higher diversity in uploaded ﬁle types appears to be a
characteristic of the OCHs hosting a higher proportion of legitimate ﬁles.
the manual heuristics. Given is p(classiﬁcation)
Table 4. Manual and automated ﬁle classiﬁcation results with consensus merg-
for overall and
ing for
p(heuristic | classiﬁcation) for each heuristic, where the classiﬁcation is legiti-
mate/infringing/unknown. The results are coded in a greyscale from 0 % (■ ) to
100 % (■ ). Due to the low number of legitimate ﬁles, the conditional probabilities
p( · | legitimate) for OCHs other than FF and MU are based on too few examples to
be considered exact (e.g., L1 on WU, or A5 on ES and FS). File names labelled as in-
fringing frequently contained the name of commercial software (I4) or were duplicates
(A2); ﬁle names classiﬁed as legitimate often used a legitimate ﬁle extension (L2) or
referred to personal content (L3).
Heuristic
Overall
Conditional Heuristic % with Consensus (legit./infr./unknown)
FF
ES
FS
WU
MU
UL
14/26/60 1.6/63/35 1.4/63/36 0.1/79/21 4.3/31/65 0.1/79/21
I1 Warez Name
I2 Uploader Name
I3 Indexing URL
I4 Commercial
I5 Keywords
I6 Obfuscated
L1 Freeware
L2 Legit. Ext.
L3 Personal
A1 Split File
A2 Duplicates
A3 Public Link
A4 DMCA Notice
A5 In Infr. DB
n/a
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■
■