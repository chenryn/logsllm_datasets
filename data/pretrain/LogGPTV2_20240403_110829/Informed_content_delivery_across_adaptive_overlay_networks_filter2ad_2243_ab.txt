ing operations. In a scenario where encoding symbols are drawn
from a large, unordered universe, end-systems that hold only part
of the content must take care to arrange transmission of useful infor-
mation between each other. The digital fountain approach handles
this problem in the case where an end-system has decoded the en-
tire content of the ﬁle; once this happens, the end-system can gen-
erate new encoded content at will. It does not solve this problem
when an end-system can only forward encoding packets, since the
receiving end-system may already have obtained those packets. To
avoid redundant transmissions in such scenarios, we describe mech-
anisms for estimating and reconciling differences between working
sets and subsequently performing informed transfers.
2.4 Suitable Applications
Reliable delivery of large ﬁles leveraging erasure-resilient encod-
ings is only one representative example of content delivery sce-
narios that can beneﬁt from the approaches proposed in this paper.
More generally, any content delivery application which satisﬁes the
following conditions may stand to beneﬁt.
4
involving multiple connections per peer.
• The architecture employs a rich overlay topology potentially
• Peers may only have a portion of the content, with potentially
• Working sets of peers are drawn from a large universe of pos-
complex correlation between the working sets of peers.
sible symbols.
Another natural application which satisﬁes these criteria is video-
on-demand. This application also involves reliable delivery of a
large ﬁle, but with additional complications due to timeliness con-
straints, buffering issues, etc. Our methods for informed content
delivery can naturally be utilized in conjunction with existing ap-
proaches for video-on-demand such as [19] to move from a pure
client-server model to an overlay-based model. While the methods
of [19] also advocate the use of erasure-resilient codes, our methods
for informed content delivery for video-on-demand apply whether
or not codes are used. Similarly, informed content delivery can be
used for near real-time delivery of live streams. For this application,
where reliability is not necessarily essential, collaboration may im-
prove best-effort performance. Finally, our approach may be used
for peer-to-peer applications relying on a shared virtual environ-
ment, such as distributed interactive simulation or networked multi-
player games. For these applications, peers may only be interested
in reconstructing a small subspace of what can be a very large-scale
environment. Here, in addition to issues of scalable naming and
indexing, summarization is also essential for facilitating effective
collaboration between peers.
3 Reconciliation and Informed Delivery
The preceding sections have established expectations for informed
collaboration: an adaptive overlay architecture designed for scal-
able transmission of rich content. We abstract our solutions away
from the issues of optimizing the layout of the overlay over time
[10, 13, 2], as well as distributed naming and indexing [25, 29, 27];
our system supplements any set of solutions employed to address
these issues.
The approaches to reconciliation which we wish to address are local
in scope, and typically involve a pair or a small number of end-
systems. In the setting of wide-area content delivery, many pairs of
systems may desire to transfer content in an informed manner. For
simplicity, we will consider each such pair independently, although
we point to the potential use of our techniques to perform more
complex, non-local orchestration.
Our goal is to provide the most cost-effective reconciliation mech-
anisms, measuring cost both in computation and message com-
plexity. In the subsequent sections, we propose the following ap-
proaches:
Coarse-grained reconciliation employs working set sketches, ob-
tained by random sampling or min-wise sketches. Coarse ap-
proaches are not resource-intensive and allow us to estimate
the fraction of symbols common to the working sets of both
peers.
Speculative transfers involve a sender performing “educated
guesses” as to which symbols to generate and transfer. This
process can be ﬁne-tuned using results of coarse-grained rec-
onciliation.
50Fine-grained reconciliation employs compact, searchable work-
ing set summaries such as Bloom ﬁlters or approximate rec-
onciliation trees. Fine-grained approaches are more resource-
intensive and allow a peer to determine the symbols in the
working set of another peer with a quantiﬁable degree of cer-
tainty.
The techniques we describe provide a range of options and are
useful in different scenarios, primarily depending on the resources
available at the end-systems, the correlation between the work-
ing sets at the end-systems, and the requirements of precision.
The sketches can be thought of as an end-system’s calling card:
they provide some useful high-level information, are extremely
lightweight, can be computed efﬁciently, can be incrementally up-
dated at an end-system, and ﬁt into a single 1KB packet. Generat-
ing the searchable summaries requires a bit more effort: while they
can still be computed efﬁciently and incrementally updated, they
require a modest amount of space at the end-system and a gigabyte
of content will typically require a summary on the order of 1MB
in size. Finally, recoded content optimizes transfers by tuning, or
personalizing, the content across a particular peer-to-peer connec-
tion based on information presented in sketches. We describe these
methods and their performance tradeoffs in the following sections.
4 Estimating Working Set Similarity
In this section, we present simple and quick methods for estimat-
ing the resemblance of the working sets of pairs of nodes prior to
establishing connections. Knowledge of the resemblance allows a
receiver to determine the extent to which a prospective peer can
offer useful content. We also use the resemblance to optimize our
recoding strategy described in Section 5.4. Since it is essential that
the data to compute the resemblance be obtained as quickly as pos-
sible, our methods are designed to give accurate answers when only
a single 1KB packet of data is transferred between peers. We em-
phasize that there are different tradeoffs involved in each of the ap-
proaches we describe; the best choice may depend on speciﬁcs of
the application.
We ﬁrst establish the framework and notation. Let peers A and B
have working sets SA and SB containing symbols from an encoding
of the ﬁle.
Deﬁnition 1 (Containment) The containment of B in A is the
quantity
|SA∩SB|
.
|SB|
Deﬁnition 2 (Resemblance) The resemblance of A and B is the
quantity
|SA∩SB|
|SA∪SB| .
These deﬁnitions are due to Broder [5] and were applied to deter-
mine the similarity of documents in search engines [1]. The contain-
ment represents the fraction of elements B that are useless (already
known) to A. If this quantity is close to zero, the containment is
small, and B rates to be a useful source of information for A. We
point out that containment is not symmetric while resemblance is.
Also, given |SA| and |SB|, an estimate for one can easily be used
to calculate an estimate for the other.
We suppose that each element of a working set is identiﬁed by an
integer key; sending an element entails sending its key. We will
think of these keys as unique, although they may not be; for exam-
ple, if the elements are determined by a hash function seeded by the
key, two keys may generate the same element with small probabil-
ity. This may introduce small errors in estimating the containment,
but since we generally care only about the approximate magnitude
of the containment, this will not have a signiﬁcant impact. With 64-
bit keys, a 1KB packet can hold roughly 128 keys, which enables
reasonable estimates for the techniques we describe. Finally, we
assume that the integer keys are distributed over the key space uni-
formly at random, since the key space can always be transformed
by applying a (pseudo)random hash function.
k
|SB|
|SA∩SB|
, and hence
The ﬁrst approach we consider is straightforward random sampling:
simply select k elements of the working set at random (with re-
placement) and transport those to the peer. (We may also send the
size of the working set, although this is not essential.) Suppose
A sends B a random sample KA from SA. The probability that
|KA∩SB|
each element in KA is also in SB is
is an unbiased estimate of the containment. Random samples can
be incrementally updated upon acquisition of new elements using
reservoir sampling [31]. Random sampling suffers the drawback
that B must search for each element of KA in its own list SB.
Although such searches can be implemented quickly using stan-
dard data structures (interpolation search will take O(log log |SB|)
average time per element), they require some extra updating over-
head. One remedy, suggested in [5], is to sample only those ele-
ments whose keys are 0 modulo k for an appropriately chosen k,
yielding samples KA and KB. (Here we speciﬁcally assume that
is an unbiased esti-
the keys are random.) In this case
mate of the containment; moreover, all computations can be done
directly on the small samples, instead of on the full working sets.
However, this technique generates samples of variable size, which
can be awkward, especially when the size of the working sets varies
dramatically across peers. Another concern about both of these ran-
dom sampling methods is that they do not easily allow one peer to
check the resemblance between prospective peers. For example, if
peer A is attempting to establish connections with peers B and C,
it might be helpful to know the resemblance between the working
sets of B and C.
|KA∩KB|
|KB|
7 14
15
3 27 9 31
Working set
π  = (4x+2) mod |U|
1
62
58
30
π  = 
(17x+7) mod |U|
38
14
62
46
2
62
53
6
32
22
58 18
..
.
π  = (13x+12) mod |U|
N
39 2
43 1 31
51
15
Summary of peer A
14
6
49
5
1
= ?
14
20
6
5
1
N
Summary of peer B
Resemblance
3
5
14
6
..
.
1
Permutations
Summary
Estimation by comparison
Figure 2: Example of minwise summarization and estimation of re-
semblance (Key universe size is 64, example permutation functions
shown).
5
51Another clever sampling technique from [5] avoids the drawbacks
of the ﬁrst two approaches. This approach, which we employ, cal-
culates working set resemblance based on min-wise sketches, fol-
lowing [5, 6]; the method is depicted in Figure 2. Let πj repre-
sent a random permutation on the key universe U. For a set S =
{s1, s2, . . . , sn}, let πj(S) = {πj(s1), πj(s2), . . . , πj(sn)}, and
let min πj(S) = mink πj(sk). Then for two working sets SA and
SB containing symbols of the ﬁle F , we have x = min πj(SA) =
j (x) ∈ SA ∩ SB. That is, the min-
min πj(SB) if and only if π−1
imum element after permuting the two sets SA and SB matches
only when the inverse of that element lies in both sets. In this case,
we also have x = min πj(SA ∪ SB). If πj is a random permu-
tation, then each element in SA ∪ SB is equally likely to become
the minimum element of πj(SA ∪ SB). Hence we conclude that
|SA∩SB|
min πj(SA) = min πj(SB) with probability r =
|SA∪SB| . Note
that this probability is the resemblance of A and B. Now to es-
timate the resemblance, peer A computes min πj(SA) for some
ﬁxed number of permutations πj (as shown on Figure 2), and simi-
larly for B and SB. The peers must agree on these permutations in
advance; we assume they are ﬁxed universally off-line.
|SA∩SB|
|SA∪SB| , A sends B a vector containing A’s
For B to estimate
minima, v(A). B then compares v(A) to v(B), counts the num-
ber of positions where the two are equal, and divides by the total
number of permutations, as depicted in Figure 2. The result is an
unbiased estimate of the resemblance r since each position is equal
with probability r.
In practice, truly random permutations cannot be used, as the stor-
age requirements are impractical. Instead, we may use simple per-
(mod |U|) for randomly
mutations, such as πj(x) = ax + b
chosen a and b and when U is prime, without affecting overall per-
formance signiﬁcantly [4, 6].
The min-wise sketches above allow similarity comparisons given
any two sketches for any two peers. Moreover, these sketches can
be combined in natural ways. For example, the sketch for the union
of SA and SB is easily found by taking the coordinate-wise min-
imum of v(A) and v(B). Estimating the resemblance of a third
peer’s working set SC with the combined working set SA ∪ SB can
therefore be done with v(A), v(B), and v(C). Min-wise sketches
can also be incrementally updated upon acquisition of new content,
with constant overhead per receipt of each new element.
5 Reconciling Differences
As shown in the previous section, a single packet can allow peers to
estimate the resemblance in their working sets. If the difference is
sufﬁcient to allow useful exchange of data, the peers may then act
to determine what data to exchange. We provide methods for this
problem that generally require transmission of only a handful of
packets. There are a number of related performance considerations
that we develop below.
The problem we consider is a set difference problem. Speciﬁcally,
suppose peer A has a working set SA and peer B has a working set
SB, both sets being drawn from a universe U with |U| = u. Peer A
sends peer B some message M with the goal of peer B determining
as many elements in the set SB − SA as possible.
The set difference problem has been widely studied in communi-
cation complexity. The focus, however, has generally been on de-
6
termining the exact difference SB − SA. With encoded content, a
peer does not generally need to acquire all of the symbols in this
difference. For example, two peers may each have 3/4 of the sym-
bols necessary to reconstruct the ﬁle with no overlap between them.
Hence we do not need exact reconciliation of the set difference; ap-
proximations will sufﬁce. One of our contributions is this insight
that approximate reconciliation of the set differences is sufﬁcient
and allows us to determine a large portion of SB − SA with very
little communication overhead.
In this section, we describe how to quickly determine approximate
differences using Bloom ﬁlters [3]. We also introduce a new data
structure, which we call an approximate reconciliation tree. Ap-
proximate reconciliation trees are especially useful when the set
difference is small but still potentially worthwhile.
There are several performance considerations in designing these
data structures:
• Transmission size of the message (data structure).
• Computation time.
• Accuracy of the approximation (deﬁned below).
Deﬁnition 3 (Accuracy) A method for set reconciliation has accu-
racy a if it can identify a given discrepancy between the sets of two
peers with probability a.
Traditional approaches which we will describe brieﬂy in Section 5.1
provide perfect accuracy (i.e. accuracy equal to 1) but are pro-
hibitive in either computation time or transmission size. Bloom ﬁl-
ters and approximate reconciliation trees trade off accuracy against
transmission size and computation time and will be described in
Sections 5.2 and 5.3.
5.1 Exact Approaches
To compute differences exactly, peer A can obviously send the
entire working set SA, but this requires O(|SA| log u) bits to be
transmitted. A natural alternative is to use hashing. Suppose the
set elements are hashed using a random hash function into a uni-
verse U(cid:6)
= [0, h). Peer A then hashes each element and sends
the set of hashes instead of the actual working set SA. Now only
O(|SA| log h) bits are transmitted. Strictly speaking, this process
may not yield the exact difference: there is some probability that an
element x ∈ SB \ SA will have the same hash value as an element
y of SA, in which case peer B will mistakenly believe x ∈ SA.
The miss probability can be made inversely polynomial in |SA| by
setting h = poly(|SA|), in which case Θ(|SA| log |SA|) bits are
sent.
Another approach is to use set discrepancy methods of [22]. If the
discrepancy d = |SB − SA| + |SA − SB| is known, then peer A
can send a data collection of size only O(d log u) bits, or if hashing
is done as pre-processing, of size only O(d log h) bits. However,
if d is not known, a reasonable upper bound on d must be deter-
mined through multiple rounds of communication. In the special
case where SA ⊆ SB, this information is used to ﬁnd coefﬁcients
of a characteristic polynomial which is factored to recover the dif-
ferences. Otherwise, a rational polynomial is interpolated and fac-
tored to recover the difference. In either case, the amount of work is
52Θ(d3). This protocol was later improved in [21] to run in expected
O(d) time at the cost of requiring more rounds of communication.
For our application, multiple rounds of communication are unde-
sirable, since the duration of each round is at least one round-trip
time.
5.2 A Bloom Filter Approach
In our applications, it is sufﬁcient for peer B to be able to ﬁnd most
or even just some of the elements in |SB − SA|. We describe how
to use Bloom ﬁlters in this case.
We ﬁrst review the Bloom ﬁlter data structure [3]. More details and
other applications can be found in [12]. A Bloom ﬁlter is used to
represent a set S = {s1, s2, . . . , sn} of n elements from a universe
U of size u, and consists of an array of m bits, initially all set to 0. A
Bloom ﬁlter uses k independent random hash functions h1, . . . , hk
with range {0, . . . , m − 1}. For each element s ∈ S, the bits hi(s)
are set to 1 for 1 ≤ i ≤ k. To check if an element x is in S, we