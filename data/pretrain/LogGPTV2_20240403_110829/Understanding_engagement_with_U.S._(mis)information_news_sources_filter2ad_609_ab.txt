smaller share of total interactions or followers. (Separate plots of
list provenance for non-misinformation and misinformation pages
can be found in Figures 12a and 12b in the appendix.)
3.3 Facebook Post Data
We use Facebook’s CrowdTangle API to extract all public posts
of news publishers on their Facebook pages, covering the period
between 10 August 2020 and 11 January 2021. Metadata includes
the total engagement numbers for the post. Specifically, according
447
050100PagesNewsGuardoverlapMedia Bias/Fact CheckFar LeftLeftCenterRightFar Right050100Interactions020406080100Political leaning (%)050100Followers0.00.20.40.60.81.00.00.20.40.60.81.0News publisher list (%)Understanding Engagement with U.S. (Mis)Information News Sources on Facebook
IMC ’21, November 2–4, 2021, Virtual Event
it with our initial data set. This resulted in an additional 627,946
posts, mostly published in August 2020 and after December 24, 2020.
Second, the API sometimes returned identical posts with different
CrowdTangle IDs even though they had the same Facebook post
ID. We removed 80,895 accidentally duplicated posts. Overall, the
updated posts data set has an additional 7.86 % of posts and 7.08 %
of additional engagement. The results in this paper (except for
Section 4.4) are derived from the updated posts data set, thus they
are not affected by the bugs. We did not notice any materially
different trends between the two versions of our data set, and the
update does not seem to have introduced any strong bias based on
political leaning or (mis)information status of a publisher.
We decided not to update our secondary data set containing
video views (Section 3.3.1). Recollecting this data set would only
give us the latest view count, which is many months after the videos
were first published, in contrast to the two-week delay we use for
engagement in the remainder of the paper. Concretely, 46 k videos
(7.1 % of video posts from the updated posts data set) are not in
the video views data set, and thus excluded from our analysis in
Section 4.4. The ratios of missing videos range from 6.1 % (center
non-misinformation) to 23.0 % (far-right non-misinformation). The
second bug causing duplicated posts does not affect the video view
data. Because of the different collection method and time, and the
effects of missing videos due to the API bug, results from our two
data sets should not be compared quantitatively, only qualitatively
based on general trends.
3.3.3 Ethical Considerations. We collect our posts data set using
CrowdTangle, an official tool with API access granted to us by
Facebook. CrowdTangle contains only public posts of Facebook
pages and aggregate engagement data, but no personally identi-
fiable information. We do not have access to information about
individual news consumers, and cannot quantify the overlap of
followers across pages, for instance.
4 ANALYSIS
In this work, we are interested in news providers with a reputation
of spreading misinformation, and how much engagement they gen-
erate on Facebook, especially in comparison to content from non-
misinformation sources. Using three different metrics, we analyze
our data set from three different angles: Overall engagement with
(mis)information at the level of the news ecosystem on Facebook
in Section 4.1, the range of (mis)information publishers and how
well they engage with their primary audiences in Section 4.2, and
the performance of individual pieces of (mis)information content
across the political spectrum in Section 4.3.
4.1 Ecosystem-Wide Engagement
Our first research question aims to shed light on how much engage-
ment (mis)information from news providers generates on Facebook
overall. We compute total engagement by summing the number
of interactions of all posts across all publisher pages. During our
study period, content from the 236 misinformation sources gener-
ated 2 B total interactions, compared to 5.4 B interactions for 2,315
non-misinformation sources. Thus, misinformation providers accu-
mulated a sizeable quantity of engagement overall, but less than
448
Figure 2: Bar plot of total engagement with (mis)infor-
mation pages from Far Left to Far Right, with the number
of Facebook pages on the x axis. In absolute terms, only Far
Right misinformation pages accumulated more engagement
than their non-misinformation counterparts.
non-misinformation news sources. The picture is more nuanced,
however, when taking into account the partisanship of the source.
To do so, we segment publishers into groups based on their
political bias and (mis)information status. Figure 2 shows that the
1,527 center publishers as a group accumulate the largest amount of
interactions, around 2.6 B, over the course of our study period. We
also observe that Slightly Left-leaning news sources generate more
engagement than Slightly Right-leaning news sources, whereas the
opposite is true for the extreme end of the spectrum, where the Far
Right generates by far the most engagement outside of the Center.
The finding that Facebook users engage less with misinformation
still holds true across the political spectrum from Far Left to Slightly
Right, but not for the Far Right. There, only 109 misinformation
publishers account for over 1.2 B interactions, which is more than
twice the total engagement of the 154 non-misinformation publish-
ers of the Far Right (and more than half of the engagement of the
much larger Center non-misinformation group that includes 1,434
publishers). This suggests that relatively small numbers of misin-
formation sources can drive disproportionately large engagement,
also illustrated by the only 16 misinformation pages of the Far Left
that generate more than 60 % of the total engagement of their 171
non-misinformation counterparts, and the 11 Slightly Right misin-
formation pages that generate almost 38 % of the engagement of
their 177 non-misinformation counterparts. A counterexample in
our data set are the 7 Slightly Left misinformation pages that gener-
ate very little overall engagement, less than 0.3 % of the engagement
of Slightly Left non-misinformation sources.
In general, reactions contribute most engagement, as shown
in Table 2 (with “likes” being the most common reaction). Exact
proportions of interaction types, and the gains or losses when
comparing misinformation to non-misinformation, fluctuate across
the political spectrum.
When looking at post types in Table 3, posts with links to non-
Facebook websites are the most common contributor of engagement
with non-misinformation publishers, followed by photo posts and
17116379714349317711154109# Pages per political leaning & (mis)information0500 M1 B1.5 B2 BTotal engagement779 M473 M1.30 B3.77 M2.38 B237 M373 M141 M575 M1.23 BNon-misinformationMisinformationFar LeftLeftCenterRightFar RightIMC ’21, November 2–4, 2021, Virtual Event
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and Tobias Lauinger
page during the study period. This makes it possible to compare
small pages with only a niche following to well-established pages
with large audiences. Because the metric sums posts of a page
without accounting for the number of posts, pages do not incur
a “penalty” for low-performing posts, but they can gain a higher
score with posts that perform well relative to the size of each page’s
respective follower base.
Total
Comments (N)
(misinfo.)
Shares (N)
(misinfo.)
Reactions (N)
(misinfo.)
Far Left
9.79 %
-0.42
11.8 %
+6.16
78.4 %
-5.75
Left
14.1 %
-8.51
8.52 %
+21.3
77.4 %
-12.8
Center Right
20.6 %
18.3 %
-8.10
-11.7
12.4 %
12.4 %
-2.69
+5.71
67.0 %
69.3 %
+14.4
+2.39
Far Right
13.3 %
+3.36
14.6 %
-2.30
72.1 %
-1.06
Table 2: Interaction types: Percentage of total engagement
with non-misinformation (N) pages per political leaning,
and in alternating rows the misinformation difference in
percentage points (misinformation delta relative to non-
misinformation pages). Comments, shares and reactions
add up to 100 % in each column. Reactions are most common.
Total
Status (N)
(misinfo.)
Photo (N)
(misinfo.)
Link (N)
(misinfo.)
FB video (N)
(misinfo.)
Live video (N)
(misinfo.)
Ext. video (N)
(misinfo.)
Far Left
0.46 %
-0.08
17.6 %
+55.9
47.6 %
-32.0
33.9 %
-25.0
0.38 %
+0.99
0.12 %
+0.24
Left
0.34 %
-0.31
23.2 %
+11.4
64.1 %
-5.50
6.80 %
-0.86
3.45 %
-2.83
2.07 %
-1.92
Center Right
0.21 %
0.36 %
-0.00
-0.17
11.0 %
18.6 %
+1.28
+16.8
75.3 %
62.7 %
-13.1
-17.6
7.90 %
13.1 %
+13.3
-1.20
5.37 %
5.24 %
-2.63
-2.73
0.20 %
0.10 %
+5.66
+0.36
Far Right
0.64 %
+2.10
13.7 %
+12.3
62.9 %
-11.6
20.7 %
-8.48
1.87 %
+5.40
0.19 %
+0.23
Table 3: Post types: Percentage of total engagement with
non-misinformation (N) pages per political leaning, and in
alternating rows the misinformation difference in percent-
age points (misinformation delta relative to non-misinfor-
mation pages). Different post types add up to 100 % in each
column. Link posts contribute most engagement.
Facebook-hosted video. For misinformation publishers, the largest
gains come from photo posts. On the Far Left, for example, photo
posts contribute 73.5 % of engagement with misinformation sources,
as opposed to only 17.6 % for non-misinformation.
The total engagement metric as we have presented it in this
section can provide an overview of the Facebook news ecosystem
as a whole. However, if the underlying list of news publishers
is incomplete and missing large pages from a particular political
leaning or (mis)information group, the picture could be biased and
lead to incorrect conclusions.
4.2 Publisher/Audience Engagement
A separate question is how well individual publishers generate
engagement within their primary audiences. We utilize a per-page
metric that sums the interactions of all posts by the page during the
study period. The primary audience of pages are their followers,
since posts are primarily shown to a page’s followers. To account
for pages’ different audience sizes, we divide the per-page sum of
interactions by the largest number of followers observed for that
449
From this perspective, the median misinformation provider gen-
erates 1.46 interactions per follower, or a mean of 3.71, whereas
the median non-misinformation provider generates a higher 2.06
interactions per follower, but a lower mean of 3.15. The difference
in trend between the median and mean is likely due to the mean
being more impacted by outliers (exceptionally well-performing
misinformation providers).
The box plot in Figure 3 shows how (mis)information providers
perform across the political spectrum. On the Far Left and the
Far Right, the median misinformation page engages better with
their audience than the respective non-misinformation page of the
same political leaning, whereas the opposite is true for the less
extreme political leanings. Also worth noting is that the median
engagement of the four left-leaning groups is significantly lower
than the engagement of the corresponding right-leaning groups,
suggesting that Slightly Right and Far Right pages better mobilize
their followers, irrespective of (mis)information status.
Because of outliers, averages are considerably higher than the
medians. The median Slightly Right misinformation page, for in-
stance, generated 1.2 interactions per follower over the study period,
whereas the average was 5.8, which even outperformed the average
of Slightly Right non-misinformation (whereas the median did not).
Overall, the means indicate that misinformation providers from
the Far Left, Slightly Right, and Far Right engage better with their
audiences than the corresponding non-misinformation providers.
For Slightly Left and Center publishers, those in the misinformation
group consistently performed worse than those in the non-misinfor-
mation group, both in the median and mean. (Median and mean
values can also be found at the bottom of Table 9 in the appendix.)
To determine which of these differences in mean engagement
were statistically significant, we need to disentangle the effects of
partisanship and factualness. For that purpose, we fit a Multivariate
ANOVA model with partisanship and factualness as the indepen-
dent variables, and their interaction on the natural log-transformed
distribution of engagement per follower as the dependent variable
(Table 4; see Appendix A.1 for details about the appropriateness
of this test). In addition to the significant main effects (that are
semantically less interesting for the purpose of our analysis), the
interaction of factualness and partisanship is also significant at
the .05 level, except for Slightly Left publishers. For publishers of
all other partisanship groups, ANOVA showed significance of the
effect of factualness on mean engagement per follower (i.e., misin-
formation associated with decreased engagement for Far Left and
Center publishers, and increased engagement for Slightly Right and
Far Right publishers). We note that while the effect for the Far Left
and Slightly Right was significant, it was on the basis of only 16
and 11 misinformation pages, respectively, thus we do not have a
high degree of confidence that this result is representative of these
Understanding Engagement with U.S. (Mis)Information News Sources on Facebook
IMC ’21, November 2–4, 2021, Virtual Event
Figure 3: Box plot of engagement with (mis)information
pages from Far Left to Far Right, normalized by each page’s
number of followers. White lines represent the medians and
+ the means. Some outliers up to 82.8 not shown. Mean en-
gagement per follower is higher for misinformation pages
than non-misinformation pages in the Far Left, Slightly
Right, and Far Right.
categories of pages in general. Post-hoc testing (Appendix A.2) con-
firmed the significance of factualness in explaining differences in
engagement per follower for Center and Far Right partisanship.
The audience engagement distributions for misinformation and
non-misinformation publishers overlap. That is, even though one
group performs better than another on average or in the median,
many individual pages from the group do perform worse. There are
Far Right non-misinformation pages that engage their audiences
better than the median misinformation page, for instance, and some
center misinformation pages do better than the median center non-
misinformation page, even though most do not.
In addition to understanding how well publishers of (mis)infor-
mation engage with their primary audiences, it is also interesting to
look at how large these audiences are. To that end, Figure 4 shows
the distribution of followers per page. For the Far Right, misin-
formation and non-misinformation pages have a similar median
of around 200 k followers, whereas for all other political leanings,
misinformation pages have a considerably higher median number
of followers than the respective non-misinformation counterpart,
such as 1.1 M vs. 248 k on the Far Left, or 956 k vs. 128 k for Slightly
Right pages. These larger per-page audience sizes for misinforma-
tion pages outside of the Far Right come from comparatively few
misinformation pages. Indeed, in several political leanings, a vast
majority of misinformation pages have larger audiences than most
of the non-misinformation pages with the same partisanship. This
suggests a potential audience for new misinformation pages to enter
the market, whereas the Far Right appears to be more saturated.
The audience-normalized per-page metric we have used in this
section has a number of drawbacks. First, using a single value for
each page can cause occasional outlier posts to propagate to the
final distribution, that is, a page’s viral post could dominate its score,
even if it happened only once and is not representative of the entire
study period. Second, normalizing by the audience size can cause
Figure 4: Box plot of followers per page, from Far Left to Far
Right. White lines represent the medians and + the means.
Some outliers up to 114 M not shown. For each partisan-
ship, there are much fewer misinformation pages than non-
misinformation pages, but their median number of follow-
ers tends to be higher.
strong effects at the extremes, such as reducing the contribution of
high-engagement posts of a page with an even larger follower base,
or amplifying the contribution of moderate-engagement posts of a
page with a very small follower base. Some of these effects were
mitigated by removing pages with fewer than 100 followers and
aggregating across all posts of each page, but Figure 5 shows that
there still are cases of this kind in the distribution of normalized
per-page engagement.
A third limitation of our per-publisher metric is that it sums
post engagement without accounting for the quantity of posts. This
is done under the theory that the attention of a page’s audience
is limited, and that the metric should neither prescribe whether
a page can obtain that engagement with a single post or split it
across multiple lower-engagement posts, nor should the metric
penalize pages for no-engagement posts. However, when pages
can generate repeat engagement by publishing more frequently
(short of saturating their audience’s limited attention), differences
in posting behavior can make it hard to compare the audience en-
gagement of different pages. Figure 6 shows that Far Left and Far
Right misinformation pages indeed post more frequently than their
non-misinformation counterparts, which could explain why they
accumulate higher per-page engagement. Similarly, Slightly Left
and Center misinformation pages post less frequently than non-
misinformation pages, which could hurt their performance under
our per-page audience engagement metric. In other words, higher
audience engagement of Far Left and Far Right misinformation pub-
lishers, and lower audience engagement of Slightly Left and Center
misinformation pages speaks to the effectiveness of publishers, but
it does not imply that Far Left and Far Right audiences would be
more likely than Slightly Left or Center audiences to engage with a
post of misinformation. To explore this aspect, we consider per-post
engagement in the next section.
450
17116379714349317711154109# Pages per political leaning & (mis)information024681012Engagement per page (per follower)Non-misinformationMisinformationNon-misinformationMisinformation17116379714349317711154109# Pages per political leaning & (mis)information01 M2 M3 M4 M5 MFollowers per pageNon-misinformationMisinformationNon-misinformationMisinformationIMC ’21, November 2–4, 2021, Virtual Event
Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and Tobias Lauinger
Test (Section)
Publisher (4.2)
Post (4.3)
Video views (4.4)
Video engagement (4.4)
𝐹
15
5, 709
893
144
Far Left
𝑡 (186) = 4.30
𝑝 < 0.01
𝑡 (369 𝑘) = 112
𝑝 < 0.01
𝑡 (32.5 𝑘) = 55.9
𝑝 < 0.01
𝑡 (32.5 𝑘) = 22.3
𝑝 < 0.01
Slightly Left
𝑡 (385) = 0.50
𝑝 = 0.59
𝑡 (1.12 𝑀) = 23.8
𝑝 < 0.01
𝑡 (57.8 𝑘) = −11.0
𝑝 < 0.01
𝑡 (57.8 𝑘) = −6.50
𝑝 < 0.01
Center
𝑡 (1.53 𝑘) = −7.30
𝑝 < 0.01
𝑡 (4.60 𝑀) = 37.4
𝑝 < 0.01
𝑡 (440 𝑘) = 41.6
𝑝 < 0.01
𝑡 (440 𝑘) = 68.0
𝑝 < 0.01
Slightly Right
𝑡 (187) = 2.10
𝑝 = 0.04
𝑡 (497 𝑘) = 94.9
𝑝 < 0.01
𝑡 (37.9 𝑘) = 19.7
𝑝 < 0.01
𝑡 (37.9 𝑘) = 3.00