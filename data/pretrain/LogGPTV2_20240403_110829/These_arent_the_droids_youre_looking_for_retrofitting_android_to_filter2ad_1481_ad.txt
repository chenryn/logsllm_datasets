5.3 Fine-grained controls
We ran a second experiment to determine which resources
were causing side eﬀects when destination-agnostic privacy
controls were applied. This required us to re-run our tests,
applying privacy controls individually to each type of sensi-
tive information. However, we only had to do so for those
applications that were less functional or were broken when
privacy controls had been applied to all types of informa-
tion. For each resource (row) and privacy control (column)
in Table 6, the corresponding entry shows the number of
applications that experienced side eﬀects as a result of im-
posing the privacy control on that resource.
Our results reﬂect that data types that are rarely directly
presented to the user – device ID, location, and phone num-
ber – are best protected by shadowing. Shadowing did not
break any applications that attempted to send the device
ID or phone number to their servers. Six applications did
become less functional when the device ID was shadowed—
all were games that could still track their high scores, but
not build cross-application high-score proﬁles. In contrast,
eight applications that access the device ID broke when
overt exﬁltration blocking was imposed, and another seven
were less functional. Many of these applications send data
upon launch, then wait for a response before continuing,
and thus break when exﬁltration blocking is imposed. Oth-
ers included the device ID in login information sent over an
encrypted (SSL) socket, which we blocked. Because appli-
cations use the device ID in a way that is not directly visible
to the user, shadowing the device ID can be less disruptive
to the user experience than actively blocking the communi-
cation.
When controlling access to the user’s location, shadowing
also had slightly fewer side eﬀects than exﬁltration blocking.
646Breaks or less functional
Breaks (only)
device ID
location
contacts
history&bookmarks
phone number
SMS
calendar
Shadowing
6/43 (14%)
10/36 (28%)
4/14 (29%)
1/3 (33%)
0/43 ( 0%)
1/2 (50%)
1/4 (25%)
Exﬁltration blocking
Overt
Covert
16/43 (37%)
14/36 (39%)
2/14 (14%)
0/3 ( 0%)
3/43 ( 7%)
0/2 ( 0%)
0/4 ( 0%)
15/43 (35%)
14/36 (39%)
2/14 (14%)
0/3 ( 0%)
3/43 ( 7%)
0/2 ( 0%)
0/4 ( 0%)
Shadowing
0/43 ( 0%)
5/36 (14%)
2/14 (14%)
0/3 ( 0%)
0/43 ( 0%)
1/2 (50%)
0/4 ( 0%)
Exﬁltration blocking
Overt
Covert
9/43 (21%)
8/36 (22%)
1/14 ( 7%)
0/3 ( 0%)
3/43 ( 7%)
0/2 ( 0%)
0/4 ( 0%)
8/43 (19%)
8/36 (22%)
1/14 ( 7%)
0/3 ( 0%)
3/43 ( 7%)
0/2 ( 0%)
0/4 ( 0%)
Table 6: For each type of sensitive information, the fraction of applications that require this information that
either break or are less functional as a result of imposing a destination-agnostic privacy control (ﬁrst three
data columns), followed by the subset of only those applications that break – rather than just become less
functional – as a result of these controls (the last three data columns). Data types not represented by rows in
this table did not cause our privacy controls to induce side eﬀects.
Like the device ID, location coordinates are rarely presented
to the user directly; rather, they are usually used to down-
load information about a given location. Thus, exﬁltration
blocking will prevent any information from being retrieved,
whereas shadowing will result in data being retrieved for the
shadow location instead of the actual location. For some ap-
plications, data for the shadow location was not better than
no data at all (as with exﬁltration blocking), so these appli-
cations (14%) were classiﬁed as broken. However, the diﬀer-
ence between the number of applications that were broken
or less useful with location shadowing (28%) versus those
broken or less useful with exﬁltration blocking (39%) shows
that some applications exﬁltrated location data for purposes
(such as analytics) that did not cause user-visible side eﬀects
when the location was shadowed. For these applications
that use location data in a way that is not visible to the
user, shadowing is a more appropriate privacy control than
exﬁltration blocking.
The results demonstrate that exﬁltration blocking is best
used for data that applications display to the user or allow
the user to navigate. For example, whereas data shadowing
causes four applications that use contacts to break or become
less functional, only one of these applications is impacted by
exﬁltration blocking. Similar results are seen in Table 6 for
bookmarks, SMS messages, and calendar entries.
Shadowing and exﬁltration blocking are complementary,
and when used together can produce fewer side eﬀects than
either can alone. While 28 of the 50 applications in our
sample (56%) run side eﬀect-free with just shadowing and
merely 16 applications (32%) are side eﬀect-free with exﬁl-
tration blocking, 33 (66%) could run side eﬀect-free if the
most appropriate privacy control (i.e. as determined by an
oracle) could be applied to each application. Section 6.1 de-
scribes how we might determine appropriate privacy settings
in the future.
The beneﬁts of having two privacy controls to choose from
are also apparent from Table 7, which presents another view
of the data from our ﬁne-grained analysis. This table char-
acterizes the types of application functionality that were im-
pacted by our privacy controls, and shows which data types
led to side eﬀects for shadowing, exﬁltration blocking, or
both. Many of the rows in this table show that for partic-
ular functionalities and data types, one control exhibits the
side eﬀect but the other does not, indicating that AppFence
can avoid impacting this type of functionality if the appro-
priate privacy control is used.
Table 7 also oﬀers further insight into the behavior of the
tested applications. For example, returning to the previous
discussion of applications that use location data in ways that
are not visible to users, these applications are precisely those
listed in the rows of the table for which exﬁltration blocking
of the location data type made applications broken or less
functional while shadowing had no side eﬀects.
Finally, Table 7 provides insight into the 34% of applica-
tions that exhibit side eﬀects that were unavoidable: those
side eﬀects that occurred regardless of which privacy con-
trol was used. These are represented by the ﬁve rows in
Table 7 in which both the shadowing and exﬁltration block-
ing columns list that some side eﬀect was present. In every
instance, these side eﬀects were the result of a direct con-
ﬂict between the goal of imposing a privacy control (keeping
information from leaving the device) and the functionality
desired by the user. This functionality included sharing con-
tacts with others (FindOthers), broadcasting the user’s loca-
tion to others (GeoBroadcast), performing a query contain-
ing the user’s location on a remote server (GeoSearch), and
building a cross-application proﬁle of the user on a remote
server (GameProﬁle). All of these are features that violate
the privacy requirement by design, and represent a nearly-
unavoidable2 choice between the functionality desired and
the privacy goal. For this minority of applications, the user
cannot have her privacy and functionality too.
6. FUTURE WORK
This section discusses promising avenues to explore in or-
der to further strengthen AppFence. In particular, we dis-
cuss how to address the problems of determining which pri-
vacy controls to apply to which applications and data types,
and preventing applications from circumventing exﬁltration
blocking.
6.1 Determining privacy settings
While a user’s privacy goals can be met by choosing the
right privacy controls, the responsibility for making the cor-
rect choice must fall somewhere. To allow for more informed
choices, we envision that AppFence could report application
2Outside of rearchitecting both client and server to support
private-information retrieval protocols.
647Impacted functionality
Sh EB Data type
Applications impacted
Launch: Application can’t launch because required network transaction contains sensitive data
dilbert, yearbook
dex, docstogo, kayak, moron, yearbook
dex, docstogo, moron
Login: User can’t login because login request contains sensitive data
Query: User can’t receive response to a query because query contains sensitive data
assistant, tunewiki
wnypages, yellowpages
manga
callerid
callerid
iheartradio
⊗ Phone #
⊗ Device ID
⊗ Location
⊗ Device ID
⊗ Device ID
⊗ Location
⊗ Phone #
⊗ Contacts
(cid:127) Device ID
(cid:127) Device ID
(cid:127) Location
⊗ Location
(cid:127) Location
(cid:127) Location
(cid:127) Contacts
-
-
-
-
-
-
-
-
-
(cid:127)
-
⊗
(cid:127)
(cid:127)
(cid:127)
⊗
(cid:127)
(cid:127)
⊗
(cid:127)
GameProﬁle: Can’t access cross-application high-score proﬁle associated with device ID
GeoSearch: Can’t perform geographic search
droidjump, mario, papertoss, simon, smiley_pops, trism
papertoss
compass, dex, starbucks, wnypages, yellowpages
apartments, iheartradio, npr, yearbook
GeoBroadcast: Can’t broadcast geographic location to others
FindOthers: Can’t learn which contacts are also using this application
SelectRecipient: Can’t select contacts with whom to call, message, or share
heytell
mocospace
DeviceData: Can’t access bookmarks, SMS messages, calendar reminders, or other device data
-
-
Contacts
Contacts
callerid, heytell
quickmark
-
-
-
Bookmarks
SMS
Calendar
skyfire
sqd
tvguide
‘-’: no side eﬀect, ‘(cid:127)’: application less functional, ‘⊗’: primary application functionality breaks.
Table 7: The types of application functionality that were impacted by AppFence’s privacy controls. The
symbols in the shadowing (Sh) and exﬁltration blocking (EB) columns indicate the severity of the side eﬀects
observed when privacy controls were applied to the given data types. Applications may be listed multiple
times if they exhibited side eﬀects for multiple functionalities or for diﬀerent data types.
behaviors to a server and that users could report side ef-
fects. This data would reveal how applications use data and
whether they will exhibit side eﬀects if privacy controls are
applied. Open problems to achieve this goal include ﬁnding
ways to crowdsource the construction of application proﬁles
while respecting users’ privacy, detecting attempts by de-
velopers to compromise the integrity of this system to the
advantage of their applications, and ﬁnding the right set of
choices to present to users based on the data available.
6.2 Hampering evasion
As we discussed in Section 3.3, applications may be able
to exploit limitations of AppFence’s information ﬂow track-
ing, which only monitors data ﬂow operations, to circumvent
exﬁltration blocking.
Tracking information ﬂow through control dependencies
may broaden the set of data that is marked as tainted and
result in false positives, which would in turn result in the
unwarranted blocking of messages from an application. One
promising option is to continue information ﬂow tracking
that is less likely to overtaint, and simultaneously use a more
aggressive tracking that may overtaint. When AppFence
detects a message that is tainted only by the more aggres-
sive ﬂow tracking it would allow the message. However, it
would also report the event and the conditions that led up
to it, to our servers for further analysis. We would then
perform more comprehensive oﬄine analysis (e.g. inﬂuence
analysis [16]) to detect the cause of the diﬀerence between
more and less aggressive tainting.
Alas, we cannot prevent applications from exploiting side
channels (e.g. cache latency) to cleanse data of taint and
circumvent exﬁltration blocking. As shadowing prevents
applications from ever accessing private data, it may al-
ways be the safest way to protect data from truly mali-
cious applications. Data shadowing can be extended to oﬀer
ﬁner-granularity controls such as shadowing location with a
nearby but less private place, e.g. the city center. However,
this kind of context-dependent control would require more
conﬁguration, warranting more research to make such con-
trols practical and useful.
7. RELATED WORK
The use of shadow resources dates back at least as far
as 1979, when the chroot operation was introduced to run
648UNIX processes with a virtualized view of the ﬁle system
hierarchy. Shadow password ﬁles allow system components
that once accessed the real password ﬁles to get some of
the information in that ﬁle without exposing the password
hashes. Honeypots and Honeynets [17, 19, 21] have popu-
larized the use of shadow resources to run malware while
studying its behavior and limiting its potential to do dam-
age. The preﬁx honey is frequently used for shadow re-
sources created for the purpose of attracting an adversary
and/or monitoring the adversary’s behavior.
Felt and Evans propose a data shadowing scheme, called
privacy-by-proxy [10]. Their mechanism is similar to our
data shadowing as it provides a fake placeholder to third-
party Facebook applications rather than the user’s real in-
formation but the privacy-by-proxy is only eﬀective to ap-
plications that access the user’s information for the sole pur-
pose of displaying the exact information back to the user.
A recent paper by Beresford et al. also argues for replac-
ing sensitive user data with “mock” (shadow) information.
They apply data shadowing for a limited number of data
types to 23 applications selected from those that were previ-
ously examined by Enck et al. using TaintDroid. However,
they only tested to determine if shadowing could be applied
to applications without causing them to crash–they did not
measure user-discernable side eﬀects [5]. Zhou et al. present
a similar system that uses shadow data to provide a “privacy
mode” for untrusted applications [27].
The Privacy Blocker application [2] performs static analy-
sis of application binaries to identify and selectively replace
requests for sensitive data with hard-coded shadow data.
This binary-rewriting approach requires that each target
application be rewritten and reinstalled, whereas AppFence
performs data shadowing on unmodiﬁed applications at run-
time. AppFence’s dynamic approach also supports exﬁltra-
tion blocking, which requires the hostname or IP address
of the destination server that can only known for certain at
runtime. However, this increased control over privacy comes
at the price of deployability: AppFence requires modiﬁca-
tions to the underlying operating system, whereas Privacy
Blocker only requires the user to install an application.
There is also a wealth of prior work on the use of
information-ﬂow tracking to protect data conﬁdentiality and
integrity. Yin et al.’s Panorama uses dynamic information-
ﬂow tracking (DIFT) to perform oﬄine analysis of data
exﬁltration by malware [26]. Chow et al.’s TaintBochs [6]
uses DIFT to analyze the lifetime of security-critical data in
memory, ﬁnding vulnerabilities when applications free mem-
ory containing encryption keys without ﬁrst deleting them.
Wang et al.’s PRECIP [25] tracks sensitive data (e.g., clip-
board and user keystrokes) in Windows at the system-call
level – tainting system objects – to prevent malicious pro-