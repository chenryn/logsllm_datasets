the control group; and also much fewer insecure results (17.3% vs.
68.8%). When studying click behavior, participants in the treatment
condition visited more secure (41.0% vs. 15.4%) and secure best-
practice results (25.6% vs. 1.3% ). The control group predominantly
visited insecure results with 84.3% of made clicks.
The two tasks IV and KEY had a significant negative effect on
security (𝑝 < 0.001). This goes in line with our initial assumption
that secure solutions are more difficult to achieve for these two
tasks.
We calculated further models which included background vari-
ables, i.e., whether participants had a security background, were
professional developers, and whether developing in Java was their
primary job. None of those variables had a significant effect on se-
curity. This means that the treatment helped in improving security
independent of whether or not participants had any distinguishing
characteristics.
Functional Correctness— We again conducted our analysis for
three models MF1-MF4 and made similar observations. We present
the three best fits according to (AIC) model selection in Table 2.
MF1 shows that not searching at all had a significant negative
effect on functionality (𝑝 < 0.01) for all participants independently
from the condition. Further, MF2 shows that the average count of
secure or secure best-practice results per task has a significant pos-
itive effect on functionality (𝑝 < 0.001). Further, once more, in the
interaction of participants with the search engine, we find a robust
significant positive interaction effect on functionality (𝑝 < 0.001)
in the treatment group, as shown by MF4. The more the treatment
group used the modified search engine, the more functional solu-
tions they submitted. We calculated further models that included
background variables. None of them had a significant effect on
functionality.
Given our observations in Figure 6b, it is unsurprising that we
find a residual negative baseline effect of being in the treatment
group (Condition: Treatment) on functionality (𝑝 < 0.001), once the
positive interaction effect is filtered out.
We performed further analysis to explain this observation and
found an imbalance between conditions in the amount of partici-
pants that submitted only one functional solution (treatment: 19 vs.
control: 9). We further observed that this imbalance is resembled in
the average amount of searches performed by those participants
(treatment: 6.32 vs. control: 10.44). While participants from the
control group that submitted only one functional solution had a
similar average amount of searches as performed by all remain-
ing participants that submitted more than one functional solution
(10.02), participants from the treatment group that submitted only
one functional solution were way below average.
Figure 7: Results received and clicked
This low-effort search behavior can be caused by participants
rushing through the study, solving the tasks on their own without
searching, or side-using other sources (such as books, formal doc-
umentation, their own code repositories or other search engines).
The treatment group had more participants who searched less often
than the control group. Similar to the participants, who did not
search at all, they did less well.
Note that the bottom line is that interaction with the treatment
significantly improves security and functionality in comparison
with the control group. This means with increasing search depth
in both condition groups, the treatment group significantly and
increasingly outperforms the control in submitting secure and func-
tional solutions.
7 STACK OVERFLOW SIGNALS
We analyzed whether Stack Overflow’s voting signals were reflected
by the ranking of search results. Since we have shown that devel-
opers mostly click on one of the top three results it is important to
evaluate whether those links provide posts with relatively low or
high votes as it may influence the developer’s decisions.
In order to measure to what extent the ranking of search results
reflects Stack Overflow’s voting signals, we calculated the Norma-
tive Discounted Cumulative Gain (NDCG) of search results from
both condition groups in Study 2. NDCG is the standard metric
used to evaluate information retrieval systems and reports a value
between 0.0 and 1.0. It reveals how close a given ranking is to a
defined ideal ranking. In our case, the ideal ranking 𝑟𝑉 was created
by ordering all Stack Overflow results for each search query in
Study 2 based on the score of the top voted answer. A NDCG value
of 1.0 means that the ranking perfectly matches the voting signals
on Stack Overflow.
7.1 Reflection in Ranking
We obtained NDCG values based on the top ten results for each
search query submitted during Study 2. We calculated two average
NDCG values, one over all queries from the control group, and one
for the treatment group. However, comparison between conditions
has rather informative character since the set of queries of each
condition is different, even though participants in both treatments
solved the same tasks.
Ranking had an average NDCG of 0.89 in the control group and
0.85 in the treatment group. The obtained values reveal that the
higher the rank of a result shown to our participants, the higher
the vote of the top answer on the Stack Overflow post linked by
the result. There was a much lower chance that results that lead to
highly voted answers appeared on lower ranks.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3080We compared the ranking of the results with Google’s original
ranking and security-based re-ranking using the same set of queries.
We calculated two different NDCGs: 𝑁 𝐷𝐶𝐺𝑆 compares a given
ranking with the ideal security ranking 𝑟𝑆, while 𝑁 𝐷𝐶𝐺𝑉 compares
with ideal ranking 𝑟𝑉 (as introduced in the beginning of Section 7).
The ideal security ranking 𝑟𝑆 ranks secure best-practice results
before secure results, and insecure results are shown last.
Security-based re-ranking achieved the highest 𝑁 𝐷𝐶𝐺𝑆 with
0.89, while Google’s original ranking had by far the lowest value
with 0.45. Surprisingly, voting-based re-ranking was very close
to security-based re-ranking with 0.86. With respect to 𝑁 𝐷𝐶𝐺𝑉 ,
voting-based re-ranking was very close to Google’s original ranking
with 0.88 vs 0.89. Security-based re-ranking followed with 0.85.
The results show that voting-based re-ranking offers a security-
scalability trade-off: it up-ranks secure results and down-ranks
insecure results almost as good as security-based re-ranking and
it up-ranks highly voted results very similar to original Google
Search. Using this trade-off allows for a more scalable approach.
It sidesteps manual labeling as well as clustering of secure best
practices. Further, boosting values do not have to be customized to
individual search tasks such as KEY or IV.
8 THREATS TO VALIDITY
Since we performed our studies online and not in a laboratory
environment, we were not able to directly control side-use of other
sources (i.e., books, formal documentation, own code repositories
or different search engines).7 On the one hand, running a study
with actual developers at their place of (remote) work favorably
adds to the realism and ecological validity of our work. However,
this comes with a certain loss of control. Instead of solely using our
search engine provided on the study webpage, participants may
have opened a new browser tab and another search engine.
We were able to show that increase of interaction with our search
engine (i. e., 𝐶𝑜𝑛𝑑𝑖𝑡𝑖𝑜𝑛 × 𝑆𝑒𝑎𝑟𝑐ℎ𝑒𝑠 ) had a positive significant effect
on security and functionality in the treatment group. In addition, re-
ceiving more secure and best practice results significantly improved
outcomes for both treatment groups. Individuals in the treatment
group disproportionally benefited from this direct effect on out-
comes (see Figure 7). The question is if side-use may have effected
any of these robust statistical results.
We consider two theoretical scenarios: one where side-use was
significantly performed by only one of the condition groups and
one where side-use was similarly distributed across conditions.
Regarding the first scenario, we observed a lower average search
count for participants that submitted only one functional solution
in the treatment group. This may have been caused by side-use.
However, we do not think that the treatment itself would have
caused potential side-use, since we did not observe smaller than
average search counts for treatment participants that submitted
more than one functional solution.
In the second scenario we assume side-use is equally likely per-
formed by both groups. Here we would only expect differences if
one group used a search engine different to Google Search signif-
icantly more often. For instance, the treatment group may have
side-used Bing while the control group side-used Yahoo. However,
7Due to national and local COVID-19 restrictions, all studies were performed online.
Figure 8: Sum of votes for secure results per rank
This is an important observation. If developers would frequently
encounter lower-scored answers when clicking on top results, they
may start looking for better scored content on the Stack Overflow
site itself without using Google Search. This would subvert our
intervention of security-based re-ranking. However, this risk is
mitigated since top ranks lead to top voted content.
We further compared votes of top ranked secure and secure best-
practice results in the treatment group with the control group. We
observed that the sum of votes per rank was much higher in the
treatment group on all ranks (except rank 9) and especially in the
top three ranks as shown in Figure 8.6
We also included the voting score in regression models MS3
and MF3 (see Table 2). The interaction variable Condition × Votes
measures whether higher voting scores in search results under
treatment lead to better security or functionality outcomes. The
variable was only significant for security (𝑝 < 0.05) but with a small
effect size (0.004). As such, the effect of votes is clearly dominated
by the number of searches (Condition × Searches).
Taken together, these findings are promising because for secure
content our re-ranking intervention is compatible with Stack Over-
flow’s own content evaluation system to a large extent. Therefore,
developers can follow two signals they are used to pay attention to
—Google rank and Stack Overflow votes—while being much better
protected from inadvertently selecting insecure content.
7.2 Voting-Based Re-ranking
Similar to security-based re-ranking in Section 5, we calculated a
boosting weight based on Stack Overflow’s voting signals. This
weight only considers the security label (i. e., secure/insecure) and
the Stack Overflow score of the top voted answer. It does not know
whether the top answer provides a secure best practice example
(see Section 5.1). The advantage of voting-based re-ranking over
security-based re-ranking is that it does not require manual labeling
and clustering of secure best practices (see Section 5.3), as well as
task-dependent ranking boosts (see Section 5.5).
Boost values for secure results were mapped to a value in [0, 1]
by applying min-max normalization on the Stack Overflow score.
We did not consider the Stack Overflow scores for insecure results.
Those still obtained a fixed negative boost of −1. We created a new
search engine that applied those boosts and reapplied the search
queries obtained from Study 2.
6The sum of votes per rank averaged over the number of results showed very similar
results.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3081we find this unlikely since all participants stated in the exit survey
that they merely use Google Search to solve programming tasks.
If participants side-used Google Search, personalization may
have let to different search results for individual participants. How-
ever, this effect would have evened out over the complete set of
participants.
9 DISCUSSION AND FUTURE WORK
Our results show that Google Search ranking has a significant effect
on code security. Therefore, we argue that Web mechanics can be
leveraged in order to support developers to write secure code. It is
a new approach in the research field of usable security for software
developers and we will discuss the advantages and disadvantages
of this approach in the following.
Scalability— While security-based re-ranking showed very promis-
ing results in our study it is still an open question whether it can be
applied to a greater ecosystem consisting of different open source
websites and multiple programming languages. Especially since
our approach involves manual inspection and reliance on a pre-
annotated dataset.
However, large-scale scanning of open-source code websites is al-
ready taking place. The code analysis platform LGTM8 scans public
repositories on Bitbucket, GitHub, and GitLab. It supports popular
programming languages like C,C++, C#, Go, Java, JavaScript, and
Python. It relies on deep learning to detect a wide range of CWEs
for each of the supported programming languages. Additional in-
variant learning allows detection of zero-days.
Further, LGTM’s code analysis tools9 and results are publicly
available and could directly be used by Google Search as a signal
to update their ranking.
As we have shown in Section 7.1, Google Search’s ranking very
closely reflects the perceived relevance of results to coding problems.
As such, Google may initially keep the relative ordering of their
ranking and merely use the security label, e. g., a found CWE by
LGTM or CodeQL, to down-rank those specific results. This solution
may be “good enough” in the sense that it keeps developers away
from the most dangerous CWEs.10 As discussed in Section 7.2, this
would eliminate the necessity of manual code inspection as well as
customized ranking boosts for individual tasks (see Section 5).
Note that by re-ranking specific pages of a single prominent
website, we were already able to demonstrate significant positive
effects on code security. Therefore, we think that it is not necessary
to scan and vet each and every webpage, but rather advocate for
a smaller scale that considers hot-spots, i. e., frequently visited
webpages. Google already has the necessary data including page
rank and click logs to identify those webpages.
Transparency— Being a major player, Google already took ad-
vantage of their central position in order to successfully enforce
security standards (e.g., HTTPS, CT). These standards can be en-
forced transparently with near-zero errors. However, identifying
insecure code examples is not transparent to the user and may
be associated with a non-negligible amount of false positives. A
wrongly identified vulnerability may then unjustly down-rank a
specific webpage. Note that our approach does not penalize the
complete website domain but merely the single webpage that pro-
vides insecure code. It requires further work on how to design a
protocol between website owners and search providers to commu-
nicate found vulnerabilities, required actions with a given timeline,
and penalties. The problem is very similar to Google’s approach
on down-ranking webpages that provide misinformation. Those
webpages obtain the lowest rating by their Search Quality Rater.
However, it is unclear how accurate their ratings are.11
Human Factors— Our intervention remains completely invisi-
ble and does not require anything from the user. Developers do not
have to be aware of it in order to use it [51]. They do not need to
download, install, and learn how to use it [31]. They do not have
to pay attention to understand and follow security warnings, in-
dicators, or recommendations [29]. They do not need to evaluate
whether vulnerabilities reported by code analysis tools are false
positives. There are no disruptive effects on the main programming
task [11]. Developers do not have to cope with incomplete or un-
helpful documentation or gain advanced skills that are sometimes
required to use security tools [51]. Therefore, typical factors that
need to be addressed in the field of usable security tooling, such
as unawareness, usability, habituation, and inertia may not have
any negative effects on security in our approach. Developers can
simply perform their default code search behavior.
Incentives— In previous work we have shown that roughly 15%
of apps from Google Play contain vulnerable code due to reuse
from information sources found on the Web [17]. Fahl et al. have
shown that many pose serious privacy risks [15]. In light of Google’s