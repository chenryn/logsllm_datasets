### Control Group vs. Treatment Group: Security and Click Behavior

The treatment group exhibited a significantly lower rate of insecure results (17.3% vs. 68.8%) compared to the control group. In terms of click behavior, participants in the treatment condition were more likely to visit secure (41.0% vs. 15.4%) and secure best-practice (25.6% vs. 1.3%) results. Conversely, the control group predominantly visited insecure results, with 84.3% of their clicks leading to such pages.

### Task Difficulty and Security

Tasks IV and KEY had a significant negative impact on security (p < 0.001), aligning with our initial assumption that these tasks are more challenging to secure. We also examined background variables, such as whether participants had a security background, were professional developers, or primarily worked with Java. None of these variables significantly affected security outcomes, indicating that the treatment improved security regardless of participants' characteristics.

### Functional Correctness

We analyzed functional correctness using three models (MF1-MF4) and found similar patterns. Model MF1 showed that not searching at all had a significant negative effect on functionality (p < 0.01) for all participants, irrespective of the condition. Model MF2 indicated that the average count of secure or secure best-practice results per task had a significant positive effect on functionality (p < 0.001). Model MF4 revealed a robust, significant positive interaction effect on functionality (p < 0.001) in the treatment group, suggesting that increased use of the modified search engine led to more functional solutions. Background variables did not significantly affect functionality.

### Residual Effects and Search Behavior

Despite the positive interaction effect, we observed a residual negative baseline effect on functionality in the treatment group (p < 0.001). Further analysis revealed an imbalance in the number of participants who submitted only one functional solution (treatment: 19 vs. control: 9). These participants from the treatment group performed fewer searches on average (6.32 vs. 10.44). This low-effort search behavior could be attributed to participants rushing through the study, solving tasks independently, or using other sources like books, formal documentation, or different search engines.

### Stack Overflow Voting Signals and Ranking

We evaluated whether Stack Overflow's voting signals were reflected in the ranking of search results. Since developers typically click on one of the top three results, it is crucial to assess the quality of these links. We used the Normalized Discounted Cumulative Gain (NDCG) metric to measure the extent to which the ranking of search results aligns with Stack Overflow's voting signals. The NDCG values were 0.89 for the control group and 0.85 for the treatment group, indicating that higher-ranked results generally linked to highly voted answers.

### Security-Based Re-Ranking and Voting-Based Re-Ranking

Security-based re-ranking achieved the highest NDCG value (0.89), while Google's original ranking had the lowest (0.45). Voting-based re-ranking closely followed with an NDCG of 0.86. With respect to NDCG based on votes, voting-based re-ranking was very close to Google's original ranking (0.88 vs. 0.89), and security-based re-ranking followed with 0.85. Voting-based re-ranking offers a security-scalability trade-off by up-ranking secure results and down-ranking insecure results, without requiring manual labeling or clustering of secure best practices.

### Threats to Validity

Conducting the studies online introduced potential side-use of other sources, which we could not directly control. However, this setup enhanced the realism and ecological validity of the study. Participants may have used additional resources, but we observed that increased interaction with our search engine had a positive significant effect on security and functionality in the treatment group. Side-use, if present, did not significantly alter these robust statistical results.

### Discussion and Future Work

Our findings highlight the significant impact of Google Search ranking on code security. We argue that leveraging web mechanics can support developers in writing secure code. While security-based re-ranking showed promising results, its scalability remains an open question. Large-scale scanning platforms like LGTM, which already analyze public repositories, could provide a practical solution. By integrating security labels from such tools, Google could down-rank insecure results, potentially reducing the risk of developers encountering dangerous vulnerabilities.

### Transparency and Human Factors

Google's central position allows for the enforcement of security standards, but identifying insecure code examples is not transparent and may involve false positives. Our approach does not penalize entire websites but focuses on specific pages. Further work is needed to design protocols for communicating found vulnerabilities and required actions. Additionally, our intervention is invisible to users, eliminating the need for them to download, install, or learn new tools, thereby addressing common usability issues in security tooling.

### Incentives and Privacy Risks

Previous research has shown that a significant portion of apps on Google Play contain vulnerable code due to web-sourced information. Addressing these risks through improved search rankings could enhance overall security.