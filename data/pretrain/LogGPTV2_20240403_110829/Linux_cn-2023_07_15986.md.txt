---
author: 硬核老王
category: 硬核观察
comments_data: []
count:
  commentnum: 0
  favtimes: 0
  likes: 0
  sharetimes: 0
  viewnum: 1571
date: '2023-07-10 19:04:36'
editorchoice: false
excerpt: "OpenAI 拿出五分之一的算力来防止人工智能“叛变”\nMeta 向 Python 提议可选全局解释器锁功能\n谷歌建议为人工智能更新 robots.txt 文件"
fromurl: ''
id: 15986
islctt: false
largepic: /data/attachment/album/202307/10/190318vxnp6t2op6w765fo.jpg
permalink: /article-15986-1.html
pic: /data/attachment/album/202307/10/190318vxnp6t2op6w765fo.jpg.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: "OpenAI 拿出五分之一的算力来防止人工智能“叛变”\nMeta 向 Python 提议可选全局解释器锁功能\n谷歌建议为人工智能更新 robots.txt 文件"
tags:
- AI
- Python
thumb: false
title: '硬核观察 #1058：OpenAI 拿出五分之一的算力来防止人工智能“叛变”'
titlepic: true
translator: ''
updated: '2023-07-10 19:04:36'
---

![](/data/attachment/album/202307/10/190318vxnp6t2op6w765fo.jpg)
![](/data/attachment/album/202307/10/190337wgq6ioevz2ljwfii.jpg)

### OpenAI 拿出五分之一的算力来防止人工智能“叛变”

OpenAI 认为，能够超越人类智慧并压倒人类的计算机系统可能会在未来十年内被开发出来。然而，这种超级智能的巨大力量也可能非常危险，可能导致人类丧失能力，甚至导致人类灭绝。OpenAI 的既定目标一直是安全地开发人工通用智能（AGI），但这项技术目前还不存在。OpenAI 希望建立一个人工智能系统，在不明确依赖人类的情况下，使其他机器与人类的价值观保持一致。为此，他们计划投入 20% 的处理能力，并成立一个由其首席科学家领导的新部门，以某种方式防止未来机器危害人类。他们的目标是在四年内解决人工智能和人类行为对齐的问题。

**消息来源：[The Register](https://www.theregister.com/2023/07/07/openai_superhuman_intelligence/)**

**老王点评**：那么如何防止监管人工智能的人工智能叛变或合谋呢？从本质上来说，除非人工智能也具有自限性，就像大自然中的很多物种一样，能够与人类和其他生物形成共存条件，否则人工智能最终将是无法控制的。在这方面，我持悲观态度。

![](/data/attachment/album/202307/10/190358ddk5pgdi9g0p0qgd.jpg)

### Meta 向 Python 提议可选全局解释器锁功能

CPython 的全局解释器锁（GIL）阻止了多线程同时执行代码，这实际上阻碍了在多核 CPU 上提高 Python 代码的运行效率。Meta 正致力于推动 Python 项目采纳 PEP 703 提案，该提案将使全局解释器锁成为可选，并加入了必要的更改以确保解释器线程安全。Meta 还承诺，如果 PEP 703 提案被接受，它将在 2025 年前投入三个工程师年的人力，与核心团队合作实现 PEP 703。

**消息来源：[Solidot](https://www.solidot.org/story?sid=75464)**

**老王点评**：Python 如果想进一步发展，打破原有的一些制约是必经之路，否则就会像其他语言一样逐渐老化。比如 Perl。

![](/data/attachment/album/202307/10/190413i3ezydi7y7iiddwt.jpg)

### 谷歌建议为人工智能更新 robots.txt 文件

人工智能公司大量使用从互联网上抓取的内容进行训练，而这些内容中有很多是受版权保护的。谷歌建议网络和人工智能社区讨论改进 robots.txt 标准，以应对人工智能抓取内容的需求。robots.txt 是一个由社区开发的网络标准，诞生于近 30 年前，已被证明是网络发布者控制搜索引擎抓取其内容的一种简单而透明的方式。然而，robots.txt 并不具有法律约束力，只是一种善意的指示。

**消息来源：[Slashdot](https://tech.slashdot.org/story/23/07/08/2158211/google-suggests-robotstxt-file-updates-for-emerging-ai-use-cases)**

**老王点评**：虽然不具备法律效力，但至少为人工智能抓取制定了一个行为准则和法律底线。
---