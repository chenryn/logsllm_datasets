volunteered to host Encore. This origin page references a
ClientHTTP GET /foo.htmlHTTP GET /task.jsHTTP GET /favicon.icoHTTP GET /submit?result=failure⋯  ⋯⋯  ⋯Collectionserver4example.comOrigin server1Coordinationserver2censored.comTarget3658measurement task hosted on a coordination server; the client
downloads the measurement task, which in turn instructs the
client to attempt to load a resource (e.g., an image) from a
measurement target censored.com. This request is ﬁl-
tered, so the client informs a collection server of this ﬁltering.
The remainder of this section explains how the origin Web
server, coordination server, and collection server work to-
gether to induce and collect Web ﬁltering measurements.
5.1 Sources of measurement targets
Encore requires a set of potentially ﬁltered Web sites and
resources to test for Web ﬁltering. This list can contain either
speciﬁc URLs if Encore is testing the reachability of a speciﬁc
page; or a URL pattern denoting sets of URLs (e.g., an entire
domain name or URL preﬁx) to test the reachability of a
domain or a portion of a Web site. A small list of likely ﬁltered
targets is most useful during initial stages of deployment
when clients of only a few moderately popular Web sites will
likely be contributing measurements. As adoption increases,
a broader set of targets can increase breadth of measurements.
We explore how to obtain lists in both scenarios.
During initial deployment, Encore relies on third parties
to provide lists of URLs to test for Web ﬁltering. Several
organizations maintain such lists. Some sites rely on per-
country experts to curate URLs (e.g., GreatFire for China [19],
Filbaan for Iran [16]), while others crowdsource list creation
and let anyone contribute reports of Web censorship (e.g.,
Herdict [23]). Our evaluation in Section 6 uses a list of
several hundred “high value” URLs curated by Herdict and its
partners. Curating accurate and appropriate lists of potentially
censored URLs is beyond the scope of this paper and an active
research area.
If we deploy Encore to many geographically distributed
Web clients and build a large, accurate Web index, we could
instead use Encore clients to verify accessibility of the entire
Web index, which would avoid the need for specialized lists
of measurement targets by instead testing the entire Web.
Regardless of whether Encore curates a small list of high-
value measurement targets or simply extracts URLs from a
large Web index, these URLs and URL patterns serve as input
for Encore’s next stage.
5.2 Generating measurement tasks
Measurement task generation is a three-step procedure that
transforms URL patterns from the list of measurement targets
into a set of measurement tasks that can determine whether
the resources denoted by those URL patterns are ﬁltered for
a client. This procedure happens prior to interaction with
clients (e.g., once per day). Figure 3 summarizes the process.
First, the Pattern Expander transforms each URL pattern into
a set of URLs by searching for URLs on the Web that match
the pattern. Second, the Target Fetcher collects detailed infor-
mation about each URL by loading and rendering it in a real
Web browser and recording its behavior in an HTTP Archive
(HAR) ﬁle [22]. Finally, the Task Generator examines each
HAR ﬁle to determine which of Encore’s measurement task
types, if any, can measure each resource and generates mea-
surement tasks for that subset of resources.
The Pattern Expander searches for URLs that match each
URL pattern. This step identiﬁes a set of URLs that can all
indicate reachability of a single resource; for example, all
URLs with the preﬁx http://foo.com/ are candidates
for detecting ﬁltering of the foo.com domain. Some pat-
terns are trivial (i.e., they match a single URL) and require
no work. The rest require discovering URLs that match the
pattern. We currently expand URL patterns to a sample of up
to 50 URLs by scraping site-speciﬁc results (i.e., using the
site: search operator) from a popular search engine. In the
future, Encore could use its own Web crawler to explore each
pattern.
After expanding URL patterns into a larger set of URLs,
the Target Fetcher renders each URL in a Web browser and
records a HAR ﬁle, which documents the set of resources
that a browser downloads while rendering a URL, timing
information for each operation, and the HTTP headers of
each request and response, among other metadata. We use
the PhantomJS [39] headless browser hosted on servers at
Georgia Tech. To the best of our knowledge, Georgia Tech
does not ﬁlter Web requests, especially to the set of URLs we
consider in this paper.
Finally, the Task Generator analyzes each HAR ﬁle to de-
termine which subset of resources is suitable for measuring
using one of the types of measurement tasks from Table 1.
It examines timing and network usage of each resource to
decide whether a resource is small enough to load from an
origin server without signiﬁcantly affecting user experience,
then inspects content type and caching headers to determine
whether a resource matches one of the measurement tasks.
The Task Generator is particularly conservative when con-
sidering inline frames because loading full Web pages can
severely impact performance and user experience (e.g., by
playing music or videos). Our prototype implementation ex-
cludes pages that load ﬂash applets, videos, or any other large
objects totaling more than 100 KB, and requires manual veri-
ﬁcation of pages before deployment; a future implementation
could apply stricter controls. Refer back to Section 4 for more
information on the requirements for each type of measure-
ment task. Section 6.1 further explores network overhead of
measurement tasks.
5.3 Scheduling measurement tasks
After generating measurement tasks, the coordination server
must decide which task to schedule on each client. Task
scheduling serves two purposes. First, it enables clients to
run measurements that meet their restrictions. For example,
we should only schedule the script task type from Table 1
on clients running Chrome. In other cases, we may wish to
schedule additional tasks on clients that remain idle on an
origin Web page for a long time. Second, intelligent task
scheduling enables Encore to move beyond analyzing indi-
vidual measurements and draw conclusions by comparing
measurements between clients, countries, and ISPs. For ex-
659Measurement
target list (§5.1)
Patterns
Pattern
Expander
URLs
Target
Fetcher
HARs
Task
Generator
Tasks
Task scheduling
(§5.3)
Figure 3: Encore transforms a list of URL patterns to a set of measurement tasks in three steps. A URL pattern denotes a set of URL (e.g., all
URLs on a domain). A HAR is an HTTP Archive [22].
ample, a single client in Pakistan could report failure to access
a URL for a variety of reasons other than Web ﬁltering (e.g.,
high client system load, transient DNS failure, WiFi unre-
liability). However, if 100 clients measure the same URL
within 60 seconds of each other and the only clients that re-
port failure are 10 clients in Pakistan, then we can draw much
stronger conclusions about the presence of Web ﬁltering.
5.4 Delivering measurement tasks
After scheduling measurement tasks for execution, Encore
must deliver tasks to these clients, who subsequently run
them and issue cross-origin requests for potentially ﬁltered
Web resources. To collect a signiﬁcant number of useful
Web ﬁltering measurements, Encore requires a large client
population that is likely to experience a diversity of Web
ﬁltering. Previous censorship measurement efforts require
researchers to recruit vantage points individually and instruct
them to install custom software, which presents a signiﬁcant
deployment barrier [15, 35]. In contrast, Encore recruits a
relatively small number of webmasters and piggybacks on
their sites’ existing Web trafﬁc, instantly enlisting nearly all
of these sites’ visitors as measurement collection agents.
A webmaster can enable Encore in several ways. The
simplest method is to add a single  tag that di-
rects clients to load an external JavaScript directly from the
coordination server. The coordination server generates a mea-
surement task speciﬁc to the client on-the-ﬂy. This method
is attractive because it requires no server-side modiﬁcations,
aside from a single tag; incurs little server overhead (i.e., only
the extra time and space required to transmit that single line);
and allows the coordination server to tailor measurement tasks
to individual clients in real time. Unfortunately, this method
is also easiest for censors to ﬁngerprint and disrupt: a censor
can simply block access to the coordination server, which
inﬂicts no collateral damage. Section 8 discusses ways to
make task delivery more robust to blocking, while Section 6.3
discusses incentives for webmasters to include Encore on
their sites in the ﬁrst place.
Rather than recruit webmasters ourselves, we have ex-
plored the possibility of purchasing online advertisements
and delivering Encore measurement tasks inside them. This
idea is attractive because online advertising networks already
have established agreements with webmasters to display con-
tent (i.e., by paying webmasters to display ads.) Ad networks
even allow advertisers to target ads to speciﬁc users, which
Encore could leverage to measure censorship in speciﬁc coun-
tries. Unfortunately for us, this idea works poorly in practice
because most ad networks prevent advertisements from run-
ning custom JavaScript and loading resources from remote
origins, with good reason; only a few niche ad networks are
capable of hosting Encore. Even if more networks could
serve Encore measurement tasks, they may not take kindly
to perceived misuse of their service, especially if it leads to
network ﬁltering and subsequent loss of revenue in countries
wishing to suppress Encore’s measurements.
5.5 Collecting measurement results
After clients run a measurement task, they submit the result
of the task for analysis. Clients submit the result of task (i.e.,
whether the client could successfully load the cross-origin
resource), related timing information (i.e., how long it took
to load the resource), and the task’s measurement ID. The
process of submitting results is similar to the process that
clients use to obtain measurement tasks. In the absence of
interference from the adversary, clients submit results by
issuing an AJAX request containing the results directly to our
collection server. Section 8 discusses other ways to submit
results if the adversary ﬁlters access to the collection server.
6 Feasibility of Encore Deployment
We evaluate the feasibility of deploying Encore based on early
experience with a prototype implementation and analysis of
potential measurement targets.
6.1 Are sites amenable to Encore’s tasks?
This section investigates whether real Web sites host resources
that Encore’s measurement tasks can use to measure ﬁltering.
We evaluate the feasibility of using Encore to measure ﬁlter-
ing of both entire domain names and individual URLs. To
measure ﬁltering practices, we use a list of domains and URLs
that are “high value” for censorship measurement according
to Herdict and its partners [24]; most sites are either perceived
as likely ﬁltering targets in many countries (e.g., because they
are afﬁliated with human rights and press freedom organiza-
tions) or would cause substantial disruption if ﬁltered (e.g.,
social media like Twitter and YouTube). This list contains
over 200 URL patterns, of which only 178 were online when
we performed our feasibility analysis in February 2014.
We collect data for this set of experiments by running the
ﬁrst two stages of the pipeline in Figure 3, which uses the
Pattern Expander to generate a list of 6,548 URLs from the
178 URL patterns in our list, then collect HAR ﬁles for each
URL using the Target Fetcher. We then send these HAR
ﬁles to a modiﬁed version of the Task Generator that emits
statistics about sizes of accepted resources and pages.
Filtering of entire domains. We explore whether Encore
can measure ﬁltering of each of the 178 domains on the list
660Figure 4: Distribution of the number of images hosted by each of
the 178 domains tested, for images that are at most 1 KB, at most
5 KB, and any size. Over 60% of domains host images that could
be delivered to clients inside a single packet, and a third of domains
have hundreds of such images to choose from.
Figure 5: Distribution of page sizes, computed as the sum of sizes
of all objects loaded by a page. This indicates the network overhead
each page would incur if a measurement task loaded it in a hidden
iframe. Over half of pages load at least half a megabyte of objects.
we generated as described above. Recall from Section 4.3
that we can use either images or style sheets to observe Web
ﬁltering of an entire domain; for simplicity, this analysis only
considers images, although style sheets work similarly. We
can measure a domain using this technique if (1) it contains
images that can be embedded by an origin site and (2) those
images are small enough not to signiﬁcantly affect user ex-
perience. We explore both of these requirements for the 178
domains in our list. Because our implementation expands
URL patterns using the top 50 search results for that pattern,
we will be analyzing a sample of at most 50 URLs per do-
main. Most of these domains have more than 50 pages, so
our results are a lower bound of the amenability of Encore to
collect censorship measurements from each domain.
Figure 4 plots the distribution of the number of images
that each domain hosts. 70% of domains embed at least one
image, and almost all such images are less than 5 KB. Nearly
as many domains embed images that ﬁt within a single packet,
and a third of domains have hundreds of such images. Even if
we conservatively restrict measurement tasks to load images
less than 1 KB, Encore can measure Web ﬁltering of over half
of the domains.
Filtering of speciﬁc Web pages. We explore how often En-
core can measure ﬁltering of individual URLs by loading a
Web page in an iframe and verifying that the browser cached
embedded resources from that page. We can use this mech-
anism to measure ﬁltering of pages that (1) do not incur too
much network overhead when loading in a hidden iframe and
(2) embed cacheable images.
We ﬁrst study the expected network overhead from loading
sites in an iframe. Figure 5 plots the distribution of page sizes
for each URL, where the page size is the sum of sizes of all
resources a page loads and is a rough lower bound on the net-
work overhead that would be incurred by loading each page
in a hidden iframe (protocol negotiation and inefﬁciencies
add further overhead). Page sizes are distributed relatively
evenly between 0–2 MB with a very long tail. Our prototype
only permits measurement tasks to load pages smaller than
Figure 6: Distribution of the number of cacheable images loaded by
pages that require at most 100 KB of trafﬁc to load, pages that incur
at most 500 KB of trafﬁc, and all pages. Perhaps unsurprisingly,
smaller pages contain fewer (cacheable) images. Over 70% of all
pages cache at least one image and half of all pages cache ﬁve
or more images; these numbers drop considerably when excluding
pages greater than 100 KB.
100 KB, although future implementations might tune this
bound to a client’s performance and preferences.
We then evaluate whether these sites embed content that
can be retrieved with cross-origin requests. Figure 6 shows
the distribution of the number of cacheable images per URL
for pages that are at most 100 KB, at most 500 KB, and any
size. Nearly 70% of pages embed at least one cacheable
image and half of pages cache ﬁve or more images, but these
numbers drop signiﬁcantly when restricting page sizes. Only
30% of pages that are at most 100 KB embed at least one
cacheable image.
Encore can measure ﬁltering of upwards of 50% of do-
mains depending on the sizes of images, but fewer than 10%
of URLs when we limit pages to 100 KB. This ﬁnding sup-
ports our earlier observation in Section 4.3 that detecting the
ﬁltering of individual Web resources may be signiﬁcantly
more difﬁcult than detecting the ﬁltering of entire domains.
6.2 Who performs Encore measurements?
Encore requires clients to visit the Web sites that are hosting
Encore scripts. The demographics of clients who perform
Encore measurements is closely related those who visit a
0500100015002000Numberofimagesperdomain0.00.20.40.60.81.0CDF≤1KB≤5KBall0500100015002000Totalpagesize(KB)0.00.20.40.60.81.0CDF01020304050Cacheableimagesperpage0.00.20.40.60.81.0CDF≤100KB≤500KBall661participating Web site. To evaluate whether a typical Web
site will receive measurements from enough locations, we
examined demographic data collected by Google Analytics