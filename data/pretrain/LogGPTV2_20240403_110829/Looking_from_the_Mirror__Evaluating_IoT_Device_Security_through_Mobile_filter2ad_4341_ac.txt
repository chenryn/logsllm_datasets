### Uniqueness and Correlation of Devices

To ensure uniqueness, our approach allows for a strong correlation between different devices that use the same hardware. For instance, we discovered that two Wi-Fi modules with a known security vulnerability related to credential leakage are potentially used in 166 devices from 35 different vendors. The combined download count for these apps exceeds 278,000.

### Similar Protocol and Backend Service

A specific protocol often has its own request and response format. Similarly, a specific backend service typically exposes standard APIs. Our Cross-App Analysis Engine can detect similarities in network interfaces, allowing us to correlate devices that use the same protocol or interact with the same backend service, even if these protocols or services are undocumented. For example, we found that 39 devices from 11 vendors are very likely to use the SSDP protocol, which is known to be vulnerable to DDoS attacks. Additionally, 32 devices from 10 vendors rely on the same cloud service for device management, and this cloud service has a reported security weakness that allows attackers to gain full control of IoT devices through device ID and password enumeration.

### Future Work

There are additional dimensions in which the security evaluation of an IoT device can benefit from similarity analysis. Previous studies [16, 28] have shown that developers or sub-contractors may follow similar coding practices, leading to the same set of security vulnerabilities. Similarly, the same development toolchain (e.g., compiler) may introduce the same set of security issues [7, 52, 54]. In future work, we plan to extend our analysis to cover more dimensions of similarities to achieve a more accurate and comprehensive evaluation of smart home IoT devices.

### Device Firmware Collector

Our platform includes a component called the Device Firmware Collector, which enriches the Device Firmware Database by downloading firmware images for devices corresponding to the analyzed apps. The purpose of these firmware images is to help confirm the findings from the cross-app analysis phase. We collect device firmware in two ways:

1. **Firmware Download Links**: We utilize the firmware download links embedded in mobile companion apps. Since IoT devices are usually headless (i.e., no keyboard or screen for user interaction), they often receive firmware updates via the companion apps. These links are sometimes built into the app by the vendor and can be extracted through imprint analysis.
2. **Vendor Websites**: We follow the app pages on Google Play, which often direct to device vendors' websites, to crawl potential firmware files. Specifically, we use the Google Custom Search API to programmatically search through vendor websites for firmware image files.

For the collected files, we filter out non-firmware files by checking their format using Binwalk [2], a well-known firmware unpacking tool. Once a file is identified as firmware, we correlate the firmware version with the app version. This helps us determine at which version a particular vulnerability is fixed and whether that fix impacts the app.

It is important to note that not all device firmware can be downloaded. Even for the ones we collected, a significant number of firmware files are encrypted or obfuscated, making analysis difficult. This is a limitation that needs to be addressed in vulnerability confirmation, as discussed in Section 4.2.

### Dataset and Results

#### Dataset and Platform Statistics

- **Dataset**: Our dataset consists of 2,081 apps collected using the method described in Section 2.2. The average app size is 13MB (ranging from 23KB to 142MB). These apps are globally distributed (271 languages) and have a total download count exceeding 1.2 billion. They cover 1,345 different device vendors and approximately 4,720 different device models.
- **Testbed and App Processing**: Our app analysis platform runs on a 4-core, 3.33GHz Ubuntu 16.04 server with 16 GB RAM and a 1TB hard drive. The Android emulator is compiled from AOSP 4.4.4. The platform processed 2,081 apps in approximately 68.3 hours, with an average processing time of 118.2 seconds per app. The maximum processing time was set to 10 minutes, and most apps were successfully processed within this timeframe. However, 73 (3.5%) apps were not fully analyzed within the timeout window, and 43 (2.1%) apps could not be analyzed due to issues with the Soot tool used to build CDG and DDG. Overall, about 98% of the apps were either fully or partially analyzed.

#### Practical Concerns

- **Obfuscation**: Most (85.8%) device companion apps are produced using Proguard, which renames classes, methods, and fields. While this affects fuzzy hash analysis, it does not impact our main analysis method (network interface analysis) since it does not obfuscate network APIs, data flow, or control flow.
- **Packing**: Some developers use packers to encrypt their code, which can affect network interface analysis. However, packers are more common in malware and less so in benign apps. In our dataset, only a few apps used commercial packers, and we did not apply special processing to these apps. There is ongoing research on developing better unpacking tools (e.g., DexHunter [59] and PackerGrind [57]) that could supplement our platform.

#### Device Families

Table 2 shows the device families detected through our cross-app analysis. For example, we identified 19 distinct device families covering 122 different vendors and 139 apps that share similar software. Another example is 14 distinct device families covering 51 different vendors that use similar hardware components. These families are not mutually exclusive; a device might share software components with one family and hardware components with another. The largest family includes 31 device vendors, while the smallest includes only 2.

### Results Validation

Our platform is based on code analysis of mobile companion apps without requiring physical devices or firmware images. This enables large-scale security analysis of smart home IoT devices. However, the accuracy of the results must be validated. We validate our findings using a hybrid approach:

1. **Acquiring Real Devices**: We purchase and test real devices in a local environment (Figure 6 shows the devices we purchased for validation).
2. **Simulating or Analyzing Firmware**: If we do not have the device, we simulate or statically analyze the firmware stored in the Device Firmware Database.
3. **Online Reports**: We search through online reports, including vendor manuals, bug reporting forums, and IoT hacking communities.
4. **Vendor Collaboration**: We work with vendors to request their help in validating the results.

We primarily use the second and third methods, as the first method is expensive and the fourth method often yields no response from vendors. Upon confirming our findings, we estimate the impact by searching the online presence of the device on Shodan [4].

### Ethics

We are careful not to cross legal and ethical boundaries. For both real and simulated devices, we evaluate them in a local network that only allows outbound connections. The device is taken offline immediately after the experiment to avoid exploitation. To assess the impact of a security issue, we use existing Shodan results rather than scanning vulnerable devices directly.

### Results Overview

From the perspective of threats, we show how many smart home IoT devices are potentially impacted by given vulnerabilities or security weaknesses. We identified 324 device models from 73 vendors that are potentially vulnerable to various security issues. For the devices we could confirm or disprove, about 91% are confirmed to be vulnerable, affecting an estimated 11.1 million users.

#### Vulnerable Software

To demonstrate how software vulnerabilities propagate across devices, we analyzed five high-profile vulnerabilities (Table 3) in the GoAhead web server, which many smart home IoT devices use for web-based interfaces. These vulnerabilities range from authentication bypass to backdoor accounts to remote code execution. Starting from the mobile companion app `object.liouzx.client` of the NEO Coolcam IP Camera, which is known to be vulnerable, we identified 72 device models from 16 distinct vendors that share similar software. Despite these being relatively old vulnerabilities (reported in 2017), we still found a significant number of potentially vulnerable devices. We confirmed through online reports that 45 device models from four vendors are indeed vulnerable.

### Table 3: IoT Devices Impacted by Vulnerable Software and Device Rebranding

| CVE | Impacted Vendor | Device Models |
|-----|-----------------|---------------|
| ... | ...             | ...           |

This table provides a detailed list of the impacted vendors and device models.