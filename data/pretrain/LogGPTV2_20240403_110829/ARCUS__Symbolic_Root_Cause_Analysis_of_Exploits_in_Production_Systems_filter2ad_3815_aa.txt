title:ARCUS: Symbolic Root Cause Analysis of Exploits in Production Systems
author:Carter Yagemann and
Matthew Pruett and
Simon P. Chung and
Kennon Bittick and
Brendan Saltaformaggio and
Wenke Lee
ARCUS: Symbolic Root Cause Analysis of 
Exploits in Production Systems
Carter Yagemann, Georgia Institute of Technology; Matthew Pruett, 
Georgia Tech Research Institute; Simon P. Chung, Georgia Institute of Technology; 
Kennon Bittick, Georgia Tech Research Institute; Brendan Saltaformaggio and 
Wenke Lee, Georgia Institute of Technology
https://www.usenix.org/conference/usenixsecurity21/presentation/yagemann
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.ARCUS: Symbolic Root Cause Analysis of Exploits in Production Systems
Carter Yagemann
Georgia Institute of Technology
Simon P. Chung
Georgia Institute of Technology
Brendan Saltaformaggio
Georgia Institute of Technology
Matthew Pruett
Georgia Tech Research Institute
Kennon Bittick
Georgia Tech Research Institute
Wenke Lee
Georgia Institute of Technology
Abstract
End-host runtime monitors (e.g., CFI, system call IDS) ﬂag
processes in response to symptoms of a possible attack. Un-
fortunately, the symptom (e.g., invalid control transfer) may
occur long after the root cause (e.g., buffer overﬂow), creating
a gap whereby bug reports received by developers contain
(at best) a snapshot of the process long after it executed the
buggy instructions. To help system administrators provide de-
velopers with more concise reports, we propose ARCUS, an
automated framework that performs root cause analysis over
the execution ﬂagged by the end-host monitor. ARCUS works
by testing “what if” questions to detect vulnerable states, sys-
tematically localizing bugs to their concise root cause while
ﬁnding additional enforceable checks at the program binary
level to demonstrably block them. Using hardware-supported
processor tracing, ARCUS decouples the cost of analysis
from host performance.
We have implemented ARCUS and evaluated it on 31 vul-
nerabilities across 20 programs along with over 9,000 test
cases from the RIPE and Juliet suites. ARCUS identiﬁes the
root cause of all tested exploits — with 0 false positives or
negatives — and even ﬁnds 4 new 0-day vulnerabilities in
traces averaging 4,000,000 basic blocks. ARCUS handles
programs compiled from upwards of 810,000 lines of C/C++
code without needing concrete inputs or re-execution.
1 Introduction
End-host runtime monitors are designed to enforce secu-
rity properties like control ﬂow integrity (CFI) [1]–[10] or
detect anomalous events (system calls [11], segmentation
faults [12]–[15]). They can effectively halt attacks that rely
on binary exploits and are seeing real-world deployment [16],
[17]. However, these systems are designed to react to the
symptoms of an attack, not the root cause. A CFI monitor
responds to an invalid control ﬂow transfer, not the buggy
code that allowed the code pointer to become corrupted in the
ﬁrst place. A host-based IDS responds to an unusual sequence
of system calls, without concern for how the program was
able to deviate from the expected behavior model.
Traditionally, symptoms of an attack are easier to detect
than root causes. Namely, it is easier to detect that the current
state has violated a property than to diagnose what lead to that
violation. Unfortunately, this has led security professionals to
adopt brittle stopgaps (e.g., input ﬁlters [18]–[21] or selective
function hardening [22]), which can be incomplete or incur
side effects (e.g., heavyweight instrumentation [23]). Ideally,
the developers that maintain the vulnerable program must ﬁx
the code and release a patch, but this creates a conundrum:
where is the bug that led to the detected attack?
Unfortunately, the journey from a detected attack to a patch
is rarely easy. Typical attack artifacts, like crash dumps [24] or
logs [25]–[35], contain partial, corruptible data [36]–[42] with
only the detection point marked. Concrete inputs may repro-
duce the symptoms in the production environment, but raise
privacy concerns [24] and rarely work for developers [43],
[44]. Worse still, developers are known to undervalue a bug’s
severity [45] or prioritize other (better understood) issues [46].
Seeking a better solution, we propose a root cause analysis
that considers “what if” questions to test the impact of partic-
ular inputs on the satisﬁability of vulnerable states. The tests
are vulnerability-class-speciﬁc (e.g., buffer overﬂows) and
enable the analysis to localize vulnerabilities and recommend
new enforceable constraints to prevent them, essentially sug-
gesting a patch to developers. Analysis is conducted over the
control ﬂow trace of the program ﬂagged by the end-host mon-
itors, testing at each state “what if” any of the vulnerability
tests could be satisﬁed. Notice that this is a divergence from
the traditional mindset of replaying [47]–[49] or tainting [21],
[50]. For example, instead of tainting a string that caused a
stack overﬂow, the developers would most directly beneﬁt
from knowing which code block caused the corruption and
what additional constraints need to be enforced upon it.1
Armed with vulnerability-class-speciﬁc satisﬁability tests,
we turn our attention to efﬁciently collecting control ﬂow
1Such analysis could also merge redundant alerts stemming from the
same bug producing varying symptoms, improving alert fatigue [51]–[53].
USENIX Association
30th USENIX Security Symposium    1989
traces in production end-hosts, which is challenging due
to strict performance expectations.
Interestingly, we ﬁnd
that readily available, hardware-supported, processor trac-
ing (PT)2 offers a novel avenue towards efﬁcient recording.
Speciﬁcally, we leverage the capability of Intel® PT to design
a kernel module that can efﬁciently capture the control ﬂow of
user programs, storing and forwarding it to an analysis system
if the end-host runtime monitor ﬂags the process. Notably,
this avoids recording concrete data or attempting to re-execute
the program.
We have implemented a system called ARCUS3 — an au-
tomated framework for localizing the root cause of vulnerabil-
ities in executions ﬂagged by end-host runtime monitors. We
have evaluated our ARCUS prototype using 27 exploits target-
ing real-world vulnerabilities, covering stack and heap over-
ﬂows, integer overﬂows, allocation bugs like use after free
(UAF) and double free (DF), and format string bugs, across
20 different commodity programs. Surprisingly, ARCUS also
discovered 4 new 0-day vulnerabilities that have been issued
3 CVE IDs, demonstrating an ability to ﬁnd neighboring
programming ﬂaws.4 ARCUS demonstrates impressive scala-
bility, handling traces averaging 4,000,000 basic blocks from
complicated programs and important web services (GIMP,
Redis, Nginx, FTP, PHP), compiled from upwards of 810,000
source lines of C/C++ code. It also achieves 0 false positives
and negatives in analyzing traces taken of the over 9,000 test
cases provided by the Juliet and RIPE benchmarks for our
implemented classes. We show that tracing incurs 7.21% per-
formance overhead on the SPEC CPU 2006 benchmark with
a reasonable storage requirement. To promote future work,
we have open source ARCUS and our evaluation data.5
2 Overview
ARCUS’ analysis begins when an end-host runtime monitor
ﬂags a running process for executing some disallowed op-
eration. Three classes of such systems are widely deployed
today: CFI monitoring [1]–[10], system call/event anomaly
detection [11], and segmentation fault/crash reporting [12]–
[15]). However, ARCUS is not dependant on how or why
the process was ﬂagged, only that it was ﬂagged. Notice
that ARCUS must handle the fact that these systems detect
attacks at their symptom and not their onset or root cause. In
our evaluation, we tested alongside a CFI monitor [1] and
segmentation fault handler, both of which provide delayed
detection. ARCUS can easily be extended to accept triggers
from any end-host runtime monitor.
2Available in Intel®, AMD®, and ARM® processors.
3Analyzing Root Cause Using Symbex.
4We reported new vulnerabilities to MITRE for responsible disclosure.
5https://github.com/carter-yagemann/ARCUS
1
2
3
4
5
6
7
8
9
10
11
12
13
14
i n t o p e n h o s t ( const char *hname ,
char * cp ;
char name [ 2 5 6 ] ;
. . . ) {
( * cp == ’ [ ’ ) {
cp ++;
f or ( i = 0 ; * cp && * cp != ’ ] ’ ; cp ++ ,
/ / b u f f e r o v e r f l o w
i ++)
cp = hname ;
i f
i f
name [ i ] = * cp ;
( * cp == ’ ] ’ ) {
name [ i ] = ’ \ 0 ’ ;
hname = name ;
} e l s e return 0 ;
/ * [ . . . ] * /
Figure 1: CVE-2018-12327 in ntpq. A stack overﬂow occurs
if there is no ‘]’ within the ﬁrst 257 characters of hname.
2.1 Real-World Example
We will brieﬂy walk through how to apply our proposed solu-
tion to a real vulnerability: CVE-2018-12327. We pick this
example because the bug is concise and straightforward to
exploit. Conversely, a case study containing thousands of
intermediate function calls is presented in Section 4.5. We
will stay at a high level for this subsection and revisit the same
example in greater detail in Subsection 3.2.
CVE-2018-12327 is a stack overﬂow bug exploitable in
ntpq to achieve arbitrary code execution. The vulnerability
exists because there is no check for the length of the relevant
command line argument. We will follow the source code in
Figure 1 for simplicity, but the actual analysis is on binaries.
Assume the attacker can manipulate the arguments passed
to ntpq, allowing him to overwrite the stack with a chain
of return addresses that will start a reverse shell — a typical
example of return-oriented programming (ROP). When ntpq
starts, the ARCUS kernel module snapshots the program’s
initial state and conﬁgures PT. The malicious input triggers
the bug, and a shell is created. A runtime monitor determines
that the shell spawning is anomalous and ﬂags the program,
causing the kernel module to send the snapshot and trace for
analysis.
The analysis sequentially reconstructs a symbolic program
state for each executed basic block. All input data, including
command line arguments, are symbolized. As the states are
stepped through, a plugin for each implemented bug class
checks for memory violations (Subsection 3.3). Since the
attacker’s input is symbolic, when the buggy code corrupts
the stack, the return pointer will also become symbolic. The
return causes the program counter to become symbolic, which
is detected by the stack overﬂow module as a vulnerability.
ARCUS now switches to localizing the root cause. It iden-
tiﬁes the symbolic instruction pointer in memory and ﬁnds
the prior state that made it become symbolic (compiled from
line 9). By examining the control dependencies of this state,
ARCUS automatically identiﬁes the guardian basic block that
1990    30th USENIX Security Symposium
USENIX Association
Figure 2: ARCUS architecture. The user program executes in the end-host while the ARCUS kernel module snapshots and
traces it using Intel PT. When a runtime monitor ﬂags a violation or anomaly, the data is sent to the analysis environment where
symbolic states are reconstructed, over which the modules detect, localize, and report vulnerabilities.
decides when the relevant loop will exit (compiled from line
8). ARCUS determines the loop could have exited sooner
and checks what would happen if it did (the “what if” ques-
tion, elaborated on in Subsection 3.2). ARCUS veriﬁes that
this alternative state does not have a symbolic return pointer,
compares the resulting data constraints to those in the compro-
mised program state, and spots the contradiction — a special
delimiter character at a particular offset of an input string.
It uses this to automatically recommend a new constraint to
enforce at the guardian to ﬁx the overﬂow.
As output, the human analyst automatically receives a re-
port containing: 1) the basic block that corrupted memory, 2)
the guardian that failed to protect against the exploit, and 3) a
recommended ﬁx for the guardian.
2.2 Threat Model
We consider attacks against user programs and assume that the
kernel and hardware in the production system are trustworthy,
which is reasonable given that Intel PT is a hardware feature
that writes directly to physical memory, bypassing all CPU
caches, conﬁgurable only in the privileged CPU mode. This
is consistent with prior security work relying on Intel PT [1],
[2], [54], [55]. We do not alter user space programs in any
way. The kernel module also provides a secure way to store
and forward recorded data to an analysis system, which may
be a separate server for extra isolation.
We expect attackers to target the production system’s pro-
grams, but not have direct access to the analysis. We focus
on program binaries without assuming access to source code
or debug symbols.6 Consequently, we cannot handle all data-
only attacks (e.g., selectively corrupting a ﬂag), which may
require accurate type information. However, ARCUS can be
extended in future work to incorporate this.
3 Design
ARCUS consists of two general components, shown in Fig-
ure 2. A kernel module snapshots the initial state of the
6However, we reference source code in our explanations and ﬁgures
whenever possible for brevity and clarity.
monitored program and collects its subsequent control ﬂow
via PT (Subsection 3.4). The data is recorded to secure stor-
age reserved by the kernel module and if an alarm is raised
by a runtime monitor, it is transmitted to the analysis system,
which may reside in a separate server. ARCUS is compatible
with any end-host runtime monitor that can ﬂag a process ID.
We use an asynchronous CFI monitor [1] and a segmentation
fault handler in our evaluation for demonstration.
The analysis is facilitated using symbolic execution with
pluggable modules for different classes of bugs (Subsec-
tion 3.3). This serves to reconstruct the possible data ﬂows
for a single path, which enables the system to spot vulnera-
ble conditions (e.g., a large input integer causing a register
to overﬂow) and consider “what if” questions to automati-
cally ﬁnd contradictory constraints that prune the vulnerable
state (Subsection 3.2). ARCUS then automatically recom-
mends places in the binary to enforce these constraints so that
developers can quickly understand and patch the root cause.
3.1 Symbolic Execution Along Traced Paths
Once an alarm is raised by a monitor, ARCUS will construct
symbolic program states from the data sent by the kernel mod-
ule. Our insight is to use symbolic analysis, but with special
consideration to avoid its greatest shortcoming: state explo-
sion. Put brieﬂy, symbolic analysis treats data as a combina-
tion of concrete (one possible value) and symbolic (multiple
possible values) data. As the analysis explores different paths
in the program, it places constraints on the symbolic data,
altering their set of values. In this way, symbolic analysis
tracks the possible data values that can reach a program state.
We use symbolic analysis not to statically explore all pos-
sible paths, as is the typical use case, but to instead consider
all possible data ﬂows over one particular path. To do this,
we symbolize all input data that could be controlled by the at-
tacker (command line arguments, environment variables, ﬁles,
sockets, and other standard I/O) and only build constraints for
the path that was traced. This sidesteps the biggest problem
with performing analysis in a vacuum — state explosion —
by leveraging the execution trace leading up to the end-host
runtime monitor’s alert.
USENIX Association
30th USENIX Security Symposium    1991
Figure 3: Revisiting CVE-2018-12327 in more detail. Part of the snapshot and constraints tracked by ARCUS are shown on the
right with registers and addresses substituted with variable names for clarity. PT is on the left.
“What If” Questions
3.2
Reasoning over symbolic data also enables ARCUS to con-
sider “what if” questions, which is a key novelty in our root
cause analysis. We now revisit CVE-2018-12327 (introduced
in Subsection 2.1) to show how ARCUS uses “what if” ques-
tions in detail. In Figure 3, part of the snapshot (orange box)
and constraints tracked by ARCUS (grey boxes) are shown
on the right. We substitute registers and memory addresses
with variable names for clarity, but keep in mind that ARCUS
operates on binaries without needing debug symbols or source
code. A part of the PT trace (yellow boxes) is shown on the
left with the source code in the center. We use square brackets
to denote array contents and curly to list the possible values
for a variable. The notation si is for unconstrained symbolic
data and ci is for concrete constants. ret_ptr is the return
pointer.
ARCUS starts by replacing the attacker-controlled data
in the snapshot with symbolic variables. hname points to a
command line argument, which is why its contents become
symbolic. As ARCUS symbolically executes the program,
it follows the PT trace, which says to take the branch at line
6 and to repeat the loop 312 times. As the loop iterates, cp
increments, and name is ﬁlled with symbolic values copied
from hname. By the time line 14 is reached, the return pointer
has been overwritten with an unconstrained symbolic value.
When the function returns, the program counter becomes
symbolic, which means the attacker is capable of directly
controlling the program’s execution via crafted command
line arguments. This is a vulnerability that triggers the stack
overﬂow module in ARCUS to begin root cause analysis.
The full algorithm for this vulnerability class is presented
in Subsection 3.3, so for brevity we will focus on the “what if”
question, which comes into play after ARCUS has located the
symbolic state prior to ret_ptr being corrupted. ARCUS
revisits this state and discovers there is another possible path
where the loop exits sooner, which requires cp ≤ hname+257
and the 257th character in hname to be ‘]’.
What if this path were to be taken by the program? The
resulting constraints would contradict the ones that led to
the corrupted state, which requires ‘]’ to occur in hname
no sooner than offset 258. Thus, by solving the “what if”
question, ARCUS has automatically uncovered a ﬁx for the
vulnerability. Subsection 3.3 covers how the module then
determines where to enforce the new data constraints to make
the recommendation more concise and practical. Note that
even after applying the recommended ﬁx, line 14 of the pro-
gram is still reachable. However, because the newly enforced
constraints contradict the compromised state, the code can no
longer be executed in the context that would give rise to the