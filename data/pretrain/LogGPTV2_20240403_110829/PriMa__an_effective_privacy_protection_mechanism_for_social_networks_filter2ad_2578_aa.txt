title:PriMa: an effective privacy protection mechanism for social networks
author:Anna Cinzia Squicciarini and
Federica Paci and
Smitha Sundareswaran
PriMa: An Effective Privacy Protection Mechanism for
Social Networks
Anna Squicciarini
College of Information
Sciences and Technology
The Pennsylvania State
University, USA
PI:EMAIL
Federica Paci
Department of Information
Engineering and Computer
Science
University of Trento,
Trento,Italy
PI:EMAIL
Smitha Sundareswaran
College of Information
Sciences and Technology
The Pennsylvania State
University, USA
PI:EMAIL
ABSTRACT
In this paper, we propose PriMa (Privacy Manager), a privacy pro-
tection mechanism which supports semi-automated generation of
access rules for users’ proﬁle information. PriMa access rules are
tailored by the users’ privacy preferences for their proﬁle data, the
sensitivity of the data itself, and the objective risk of disclosing this
data to other users. The resulting rules are simple, yet powerful
speciﬁcations indicating the adequate level of protection for each
user, and are dynamically adapted to the ever changing setting of
the users’ preferences and SN conﬁguration.
1.
INTRODUCTION
Web 2.0 revolutionizes how people store and share personal data,
allowing for pervasive sharing of personal information on the web.
This change has multi-faceted implications, especially on privacy.
End users, are often unaware of the size or nature of the audience
that could potentially access their data. These issues are partic-
ularly pronounced in Social Network sites (SNs from now on),
where the false sense of intimacy amongst digital friends often
leads to potentially risky disclosures of private data.
Privacy in SNs can be compromised in several ways, by steal-
ing proﬁles’ data, observing the SN graph and by cross-correlating
distributed proﬁles that belongs to multiple sites [19, 7]. One of
the main threats to the users’ privacy stems from accidental disclo-
sures of data. For example, despite a user may choosing to protect
her actual name, another user could accidentally reveal it in a mes-
sage. Besides, a digital dossier of a user can be built by aggregating
partially obfuscated proﬁles on various SNs.
The privacy protection mechanisms currently provided by most
SNs fall short as they enforce access policies set by users. Setting
privacy preferences in these policies is a tedious and confusing task
for average users having hundreds of connections and extensive
proﬁles [1, 2]. Hence, users often end up with policies which do not
protect their personal information well. Further, the anonymization
techniques used by some sites to obfuscate users’ personal identi-
fying information (PII) may not succeed in protecting it from in-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS’10 April 13–16, 2010, Beijing, China.
Copyright 2010 ACM 978-1-60558-936-7 ...$10.00.
appropriate disclosures [19].
Hence, we need privacy protec-
tion mechanisms that guarantee SN users protection of their shared
data without any tedious policy speciﬁcation by them. An effective
solution for this problem should take into account users’ privacy
preferences on the desired level protection of their proﬁle informa-
tion, and adapt the same to the objective risks users face by taking
into account the structure of the SN graph and the level of exposure
of connected users. In this paper, we propose P riM a (Privacy
Manager), a privacy protection mechanism which automatically
generates access rules for users’ proﬁle information. P riM a ac-
cess rules are generated on the basis of users’ privacy preferences
on their proﬁle data, the sensitivity of the data with respect to the
privacy settings of the user such as his privacy preferences for his
proﬁle data and the degree to which his proﬁle data is at a risk
of being exposed to others, and the risk of disclosing such data to
other users. These access rules allow users to enforce ﬁne-grained
protection, such that the rules can be stated for different levels of
granularity ranging from single traits to an entire class of them.
Due to this ﬁne-grained control, accidental disclosures are avoided.
Hence, P riM a reduces the chance of accidental disclosures due to
outdated policies.
The rest of the paper is organized as follows. Section 2 provides
a formal representation of SNs and user proﬁles. Section 3 presents
how users’ proﬁle data are partitioned based on their sensitivity
while Section 4 presents the generation of access rules for the same.
Section 5 outlines the related works, with concluding remarks in
Section 6.
2. REPRESENTATION OF SOCIAL NETWORKS
AND USERS’ PROFILES
In this section, we present the concepts that characterize P riM a
framework, including the formal deﬁnition of SN, proﬁles, and
users’ privacy preferences.
2.1 SN Representation
A SN is a labeled graph hU, E, Φi, where U denotes the set of
nodes and E the labeled edges. Each node represents a user i, and
an edge Ei,j represents a relationship between users i and j. Edges
are labeled with the social relationship type that connects the two
users. The labeling function Φ is deﬁned as φ : U × U → R,
where U is the set of users registered to the SN and R is the set of
the possible relationships connecting the users. We assume the SN
supports a ﬁnite set of relationships R = {R1, . . . , Rm}, which
are explicit and mutually accepted by the involved users. For sim-
plicity we focus on binary user relationships, and denote a relation-
ship as i :R: j, being i and j users’ unique identiﬁers, and R the
320relationship that connects them. The set deg(i) is the set of ﬁrst
degree connected users. The cardinality of deg(i) is denoted as
#deg(i). Users can join groups within the SN, where each group
has a unique name, without any approval from other SN members.
Each user i has a web space or proﬁle denoted by profi. A proﬁle,
profi, is a collection of traits [T1(i), ...., Tw(i)] sorted by order of
appearance (i.e., the older the traits, the lower the index). Traits can
be data posted by the user i or by other users. The user i has control
over the access of the traits posted on his/her proﬁle regardless of
whether the traits have been posted by i or by the other users.
Each trait is a pair Tk(i) = (tnk(i), tvk(i)), where tnk is the
trait’s name, and tvk the trait’s value. Traits can belong to one of
the following categories: Tattr, denoting users’ attributes, Tcomm,
denoting comments and posts, Tmm, representing group member-
ship, and Trel, representing users’ relationships. 1 Depending on
their semantics, some traits have a single unique value, like ﬁrst
name and last name, whereas others, like address or telephone num-
ber could have multiple values. For simplicity we assume traits are
normalized [18]. If a trait is of type Tattr, the trait name denotes
the attribute type and the trait value denotes the value assumed by
the attribute. For example, a user John Doe has the trait (“Last-
Name”,“Doe”) of type Tattr, where the trait name tnk(i) is “Last-
Name” and the trait value tvk(i) is “Doe”. Traits of the type Tmm
model groups’ memberships. In this case, the trait name is “Group”
while the value is the given group’s name. For example, when Jane
Doe joins the group “Fashionista”, a new trait with the trait name
“Group” and the trait value “Fashionista” is added to her proﬁle.
Traits of type Trel are represented as tuples where the trait name is
equal to “Relationship” and the trait value is i : R : j. Traits of
type Tcomm represent streaming data, that is, posts, comments, and
other html content that users post over the web. They are modeled
by a tuple where the trait name is “Comment” and the trait value is
the comment or post text. Comments (or posts) can be associated
with other traits. For example, the post “How are you Jane? How
is Austin?” left on Jane’s proﬁle is associated with the traits of type
Tattr (“First Name”,“Jane”) and (“Location”, “Austin”).
2.2 Traits and User’s Privacy preferences
When a user i registers to the SN, he speciﬁes a coarse-grained
privacy preference for each of the four main trait categories Tattr,
Tcomm, Tmm and Trel, or some default settings are applied by the
SN site. These initial values are used to bootstrap P riM a with
ﬁner grained privacy preferences, denoted as α(Tk(i)) (α, when
the trait is not relevant) for each trait Tk(i) in the proﬁle of user i.
If a trait has no speciﬁc α value, P riM a derives the user’s pri-
vacy preference for that trait, by leveraging the same for other traits
that have some commonalities with the given trait, such as the value
or the name. Otherwise, if this is not possible due to lack of user
input, it calculates the α expected value based on the correspond-
ing α values speciﬁed by other users having in their proﬁle a trait
Tk(i).
P riM a dynamically evaluates whether a recently updated pri-
vacy preference α(Tk(i)) can be applied to other traits in the user’s
proﬁle. To do this, it considers the frequency of updates of the pri-
vacy preferences and infers the user’s privacy inclination.
If such
inference is not possible, due to lack of data or user’s input, P riM a
computes an expected value for α(Tk(i)) leveraging the values of
α(Tk(j)) speciﬁed by other users for traits similar to Tk(i). The
idea is to group together those users who share the same trait types,
are linked by a relationship and have displayed similar privacy pref-
erences. Such a group of users, referred to as Crowd, serves as a
1For simplicity, we do not consider images among the trait’s types.
ﬁrst indicator of user’s i privacy behavior and expectation.
DEFINITION 2.1
(CROWD). Let Uset be a subset of users in
U. Let i be a user in U. Uset is a Crowd for a trait Tk(i) =
(tnk(i), tvk(i)) of i’proﬁle and for user i if and only if the follow-
ing conditions hold:
• Given a trait value tvk(i), ∀j ∈ Uset there exists Tk(j) =
(tnk(j), tvk(j)) in profj s.t. tnk(i) = tnk(j),
• Given a not empty set of relationship types {R1, . . . , Rm}
∀ j ∈ Uset there exists a relationship i : R : j, where
R ∈ {R1, . . . , Rm}.
• for every trait Tk(i) in profi
α(Tk(i)) ≈
|Uset|
X
j=1,i6=j,j∈Uset
α(Tk(j))p(α(Tk(j))
where p(α(Tk(j)) is the p.m.f of α(Tk(i)); α(Tk(i)) is a
discrete random variable.
At ﬁrst, there may not be a speciﬁc value for α(Tk(i)). Hence,
in condition 3, we use the generic preference value speciﬁed for the
category Tk(i) belongs to.
To compute the expected value for a trait Tk(i), we adopt the Expectation-
Maximization (EM). The EM algorithm [13] is used to ﬁnd the
maximum likelihood of various parameters in probabilistic models.
The algorithm takes as input the recently updated known values of
α(Tk(j)), where j 6= i ∀ j ∈ Crowd, where Crowd is a Crowd
associated with user i. If no changes have been made for the same
trait type in i’s Crowd, no meaningful updates can be applied to the
sensitivity value, and the value of α is not changed.
3.
P RIM A TRAITS CLASSIFICATION AND
PARTITION
Once a privacy preference value is associated by P riM a to each
trait in a user proﬁle, the traits are then classiﬁed and partitioned
based on the notion of sensitivity. Then, for each partition the rules
that determine who have access to which traits are derived.
The “sensitivity score”, denoted as θ(Tk(i)) (simply referred to
as θ when no ambiguity arises) is a measure of how sensitive a trait
Tk(i) in a user’s proﬁle is with respect to the user’s privacy pref-
erences for his data and the exposure of the user’s proﬁle data to
others; the higher θ is, the higher is the sensitivity of a particular
trait. θ takes into account not only the privacy preference of the
user on Tk(i), but also objective information about the SN such as
the popularity of the proﬁle and of the trait itself. θ is calculated
combining three different metrics: the number of users that are part
of user i’s Crowd that have trait Tk in their proﬁle accessible by
i, denoted as fcr(Tk(i)); L(i), the looseness of the proﬁle; and
α(Tk(i)), the privacy preference of i for the trait Tk(i). The loose-
ness gives a measure of the popularity of a proﬁle profi, and thus
of its potential level of exposure.We omit its detailed formulation
due to lack of space.
DEFINITION 3.1. (Sensitivity Value) Let Tk(i) be a trait in the
proﬁle profi of a user i, and let cr be a Crowd related to user i
with respect to Tk(i). Let fcr(Tk(i)) be the value of f with respect
to cr, L(i) be the looseness of the proﬁle profi, and α(T (i)) the
value of the privacy preference for Tk(i). The Sensitivity score for
Tk(i) is calculated as follows:
θ(Tk(i)) =
1