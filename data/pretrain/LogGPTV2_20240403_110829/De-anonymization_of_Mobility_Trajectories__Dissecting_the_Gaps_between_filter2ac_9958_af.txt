### Precision of Using Historical Check-Ins Versus Not Using Them

Clearly, utilizing historical check-ins improves the performance of all algorithms. Intuitively, historical check-ins can significantly mitigate the sparsity issues in synchronized check-in trajectories.

### Validation Using Dianping Trajectories

Finally, we apply our algorithms to de-anonymize the ISP dataset using 45,790 app-level trajectories from Dianping as external information. This experiment serves two purposes: first, to evaluate the performance of our algorithms using Dianping’s dataset; second, to simulate a scenario where ground-truth data is not available to train the GM-B algorithm. In this case, we assume the attacker does not have access to Dianping's ground-truth data for parameter estimation. Instead, we directly apply the parameters estimated from the Weibo dataset to the Dianping experiment (empirical GM-B). As shown in Fig. 9(c), the empirical GM-B performs competitively with the best existing algorithms and the GM algorithm with parameters learned from Dianping trajectory data. This result demonstrates the robustness of our proposed algorithm.

### B. Parameter Evaluation

#### Impact of Parameters in GMM

Fig. 10 illustrates the sensitivity of GMM’s performance to different parameter settings. Fig. 10(a) shows the average hit-precision of the GM algorithm under various maximum tolerable delays \( H_u \). We use Weibo’s app-level trajectories with at least two distinct locations. As observed, the hit-precision improves slowly with increasing \( H_u \). However, as mentioned in Section VII-B, the computational complexity of the GM algorithm increases with \( H_u \). Therefore, a balance between accuracy and computational complexity must be struck in real de-anonymization attacks.

Next, we examine the impact of parameters \( \pi \) and \( \sigma \) in the GMM. For an adversary without detailed ground-truth data, these parameters cannot be estimated using the EM algorithm. Instead, we use parameters derived from empirical distribution fitting: \( \sigma(p) \) is set to 0.5 km for all \( p \), and \( \pi(p) \) follows either a power-law or exponential distribution. The performance comparison is shown in Fig. 10(b).

The results indicate that the GM algorithm using power-law empirical parameters outperforms the one using exponential empirical parameters. This finding aligns with our prior observation that Weibo’s mismatches follow a power-law distribution. Additionally, the performance of using power-law empirical parameters is very close to that of the ground-truth parameters estimated by the EM algorithm, suggesting that our algorithm is robust and does not rely heavily on accurate parameter estimation as long as the appropriate distribution model is selected.

#### Impact of Parameters in Markov Mobility Model

The key parameter in the Markov mobility model is the component. We evaluate the impact of the order of the Markov model and location context.

In Fig. 11(a), we show the impact of using 0-order or 1-order Markov models, as well as ignoring the dependency between external records. Specifically, we use "0-order (simplified)" to represent the GM algorithm with a 0-order Markov mobility model, ignoring dependencies between external records. The maximum tolerable delay \( H_u \) is set to 1 hour, and \( \pi \) and \( \sigma \) use values estimated by the EM algorithm. As shown in Fig. 11(a), there is a very small difference in hit-precision between different settings, indicating that the order of the Markov model and the dependency between external records have a minimal impact on performance. Additionally, Fig. 11(b) shows the relative performance gain for the GM algorithm with location context compared to without it. By utilizing the location context, over a 25% relative performance gain is achieved, demonstrating its effectiveness.

### Experiment Limitation

As mentioned in Section V-B, for each trajectory in the external datasets, there must exist a matched trajectory in the ISP dataset. In practice, however, the external dataset may contain users not present in the ISP dataset. Therefore, the performance of all de-anonymization algorithms, including ours, represents an upper bound. The above experiments demonstrate the advantage of our proposed algorithms based on relative comparisons with existing methods.

### Summary

We demonstrate that de-anonymization attacks can be more effective by tolerating spatial and temporal mismatches (GM algorithm) and modeling user behavior (GM-B algorithm). Specifically, the total performance gain in terms of hit-precision is more than 17% compared to existing algorithms. Further, by incorporating historical check-ins and location context, an additional 30% to 150% relative gain can be achieved. Finally, we show that the proposed algorithms are robust against model parameter settings. Even without ground-truth data for parameter estimation, our algorithms remain robust using empirical parameters.

### IX. Discussion & Conclusions

In this work, we use two large-scale ground truth mobile trajectory datasets to extensively evaluate commonly used de-anonymization methods. We identify a significant gap between the algorithms’ empirical performance and theoretical privacy bounds. Further analysis reveals that the main reasons for this gap are the underestimation of spatio-temporal mismatches in data from different sources and the significant noise in user-generated data. Our proposed algorithms, designed to address these practical factors, show promising performance, confirming our insights.

Our work has key implications for de-anonymization algorithm designers by highlighting the critical factors that matter in practice. For example, we show that temporal mismatches are more damaging than spatial mismatches. Spatial mismatches are naturally bounded by the strong locality of human movements, so having algorithms that tolerate temporal mismatches (or both) is crucial. On the other hand, to provide better location privacy protections, practical factors such as user mobility patterns and location context should be considered. Our results indicate that simple mechanisms to manipulate time and location points in original trajectories may no longer suffice. Privacy protection algorithms should consider user and location context to provide stronger privacy guarantees (e.g., using context differential privacy [12]). For future work, we plan to investigate de-anonymization attacks using other types of external information, such as social graphs [19], [20], [29], [35], or user home and work addresses, and design better privacy protection mechanisms.

### Acknowledgment

The authors thank the anonymous reviewers for their helpful comments. This work was partially supported by the NSF grant CNS-1717028.

### References

[References listed here, formatted consistently]