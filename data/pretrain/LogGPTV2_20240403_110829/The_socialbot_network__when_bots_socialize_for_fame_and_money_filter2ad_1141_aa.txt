title:The socialbot network: when bots socialize for fame and money
author:Yazan Boshmaf and
Ildar Muslukhov and
Konstantin Beznosov and
Matei Ripeanu
The Socialbot Network:
When Bots Socialize for Fame and Money
Yazan Boshmaf, Ildar Muslukhov, Konstantin Beznosov, Matei Ripeanu
{boshmaf,ildarm,beznosov,matei}@ece.ubc.ca
University of British Columbia
Vancouver, Canada
ABSTRACT
Online Social Networks (OSNs) have become an integral
part of today’s Web. Politicians, celebrities, revolutionists,
and others use OSNs as a podium to deliver their message
to millions of active web users. Unfortunately, in the wrong
hands, OSNs can be used to run astroturf campaigns to
spread misinformation and propaganda. Such campaigns
usually start oﬀ by inﬁltrating a targeted OSN on a large
scale. In this paper, we evaluate how vulnerable OSNs are
to a large-scale inﬁltration by socialbots: computer programs
that control OSN accounts and mimic real users. We adopt
a traditional web-based botnet design and built a Socialbot
Network (SbN): a group of adaptive socialbots that are or-
chestrated in a command-and-control fashion. We operated
such an SbN on Facebook—a 750 million user OSN—for
about 8 weeks. We collected data related to users’ behav-
ior in response to a large-scale inﬁltration where socialbots
were used to connect to a large number of Facebook users.
Our results show that (1) OSNs, such as Facebook, can be
inﬁltrated with a success rate of up to 80%, (2) depending
on users’ privacy settings, a successful inﬁltration can result
in privacy breaches where even more users’ data are exposed
when compared to a purely public access, and (3) in prac-
tice, OSN security defenses, such as the Facebook Immune
System, are not eﬀective enough in detecting or stopping a
large-scale inﬁltration as it occurs.
1.
INTRODUCTION
Online Social Networks (OSNs) such as Facebook1 and
Twitter2 have far exceeded the traditional networking ser-
vice of connecting people together. With millions of users
actively using their platforms, OSNs have attracted third
parties who exploit them as an eﬀective media to reach and
potentially inﬂuence a large and diverse population of web
users [21, 23]. For example, during the 2008 U.S. presiden-
tial election, social media was heavily employed by Obama’s
1http://www.facebook.com
2http://www.twitter.com
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC 11 Dec. 5-9, 2011, Orlando, Florida USA
Copyright 2011 ACM 978-1-4503-0672-0/11/12 ...$10.00.
campaign team who raised about half a billion dollars online,
introducing a new digital era in presidential fundraising [40].
Moreover, it has been argued that OSNs, as democracy-
enforcing communication platforms, were one of the key en-
ablers of the recent Arab Spring in the Middle East [35, 38].
Such a global integration of social media into everyday life is
rapidly becoming the norm, and arguably is here to stay [8].
But what if some of the content in social media—OSNs in
particular—is not written by human beings?
A new breed of computer programs called socialbots are
now online, and they can be used to inﬂuence OSN users [24].
A socialbot is an automation software that controls an ac-
count on a particular OSN, and has the ability to perform
basic activities such as posting a message and sending a
connection request. What makes a socialbot diﬀerent from
self-declared bots (e.g., Twitter bots that post up-to-date
weather forecasts) and spambots is that it is designed to be
stealthy, that is, it is able to pass itself oﬀ as a human being.
This allows the socialbot to compromise the social graph of a
targeted OSN by inﬁltrating (i.e., connecting to) its users so
as to reach an inﬂuential position. This position can be then
exploited to spread misinformation and propaganda in order
to bias the public opinion [26]. For example, Ratkiewicz et
al. [33] describe the use of Twitter bots to run astroturf and
smear campaigns during the 2010 U.S. midterm elections.
As socialbots inﬁltrate a targeted OSN, they can further
harvest private users’ data such as email addresses, phone
numbers, and other personal data that have monetary value.
To an adversary, such data are valuable and can be used
for online proﬁling and large-scale email spam and phishing
campaigns [30]. It is thus not surprising that diﬀerent kinds
of socialbots are being oﬀered for sale in the Internet black-
market for as much as $29 per bot [4].
Recently, many techniques have been proposed that aim
to automatically identify spambots in OSNs based on their
abnormal behavior [31, 16, 37]. For example, Stein et al. [36]
present the Facebook Immune System (FIS): an adversarial
learning system that performs real-time checks and classiﬁ-
cation on every read and write action on Facebook’s database,
all for the purpose of protecting its users and the social graph
from malicious activities. It is, however, not well-understood
how such defenses stand against socialbots that mimic real
users, and what the expected users’ behavior might be in
response to a large-scale inﬁltration by such bots.
In this paper, we aim to ﬁll this knowledge gap. We treat
large-scale inﬁltration in OSNs as an organized campaign
that is run by an army of socialbots to connect to either
random or targeted OSN users on a large scale. Therefore,
we decided to adopt a traditional web-based botnet design
and deﬁne what we call a Socialbot Network (SbN): a group
of re-programmable socialbots that are orchestrated by an
adversary (called a botherder) using a software controller
(called a botmaster). The botmaster is designed to exploit
the known properties of social networks, such as the triadic
closure principle [32], and use them as heuristics to deﬁne
commands, which increase the magnitude of the potential
inﬁltration in the targeted OSN.
We built a simple, yet eﬀective, SbN consisting of 102 so-
cialbots and a single botmaster. We then operated this SbN
on Facebook for 8 weeks. During that time, the socialbots
were able to send a total of 8,570 connection requests. We
recorded all data related to the anticipated inﬁltration and
the corresponding users’ behavior, along with all accessible
users’ proﬁle information. Overall, we summarize our main
ﬁndings as follows:
(1) OSNs, such as Facebook, are highly vulnerable
to a large-scale inﬁltration. From the OSN side, we show
that it is not diﬃcult to fully automate the overall operation
of an SbN, including accounts creation. From the users’ side,
we show that most OSN users are not careful enough when
accepting connection requests sent by strangers, especially
when they have mutual connections. This behavior can be
exploited to achieve a large-scale inﬁltration with a success
rate of up to 80%.
(2) Depending on users’ privacy settings, operating
an SbN can result in many privacy breaches. We show
that greater number of users’ data can be harvested after a
large-scale inﬁltration. This data include email addresses,
phone numbers, and other proﬁle information, all of which
have monetary value. Unfortunately, this also includes the
private data of users who have not been inﬁltrated, but are
connected to inﬁltrated users. Moreover, we show that a
botherder can operate an SbN conservatively, at a slow pace,
and still collect an average of 175 new chunks of publicly-
unaccessible users’ data per socialbot per day.
(3) In practice, OSN security defenses such as the
FIS are not eﬀective enough in detecting a large-
scale inﬁltration. Our results show that a successful in-
ﬁltration of an OSN user is expected to be observed within
the ﬁrst 3 days after the request has been sent by a social-
bot. This means that the social graph will rapidly change
in a relatively short time, and the socialbots will get grad-
ually integrated into the targeted online community. We
found that the FIS was able to block only 20% of the ac-
counts used by the socialbots. This, however, was a result
of feedback from users who ﬂagged these accounts as spam.
In fact, we did not observe any evidence that the FIS de-
tected what was really going on: an organized large-scale
inﬁltration campaign.
The rest of the paper is organized as follows: We ﬁrst
provide background information and deﬁne our notations in
Section 2. After that, we present the concept of a Social-
bot Network, along with its design goals and construction
details, in Section 3. Next, we demonstrate our experiments
with an SbN on Facebook in Section 4, and then we discuss
our results in Section 5. This is followed by an outline of
related works in Section 6. Finally, we conclude the paper
in Section 7.
2. PRELIMINARIES
In what follows, we present background information and
deﬁne the notations we use in the upcoming discussion.
2.1 Online Social Networks
Online Social Networks (OSNs) provide centralized web
platforms that facilitate users’ social activities. A user in
such a platform owns an account and is represented by a pro-
ﬁle that describes her social attributes such as name, gen-
der, interests and contact information. We use the terms
“account”, “proﬁle”, and “user” interchangeably. A social
connection between two users can be either undirected like
friendships in Facebook, or directed like follower-followee re-
lationships in Twitter.
An OSN can be modeled as a graph G = (V, E), where V
represents a set of users and E represents a set of social con-
nections among these users. For every user u ∈ V , the set
Γ(u) is called the neighborhood of u, and it contains all users
in V with whom u has social connections. We denote the av-
u∈V |Γ(u)|.
v∈Γ(u) Γ(v) the extended
erage neighborhood size in G by Navg = |V |−1(cid:80)
Finally, we call the set ∆(u) = (cid:83)
neighborhood of u.
2.2 Social Engineering and Socialbots
Traditionally, social engineering is deﬁned as the art of
gaining access to secure objects by exploiting human psy-
chology, rather than using hacking techniques. Social en-
gineering, however, has become more technical and com-
plex; social engineering attacks are being computerized and
fully automated, and are becoming adaptive and context-
aware [9, 5]. In fact, some of these attacks are sophisticated
and use learned or hard-coded heuristics and observations
about users’ behaviour in the targeted system so as to in-
crease the magnitude of their potential damage [5, 6, 20].
The next generation of social engineering attacks is even
more deceptive; they employ an automation software called
a socialbot that controls a proﬁle in an OSN, and has the
ability to execute basic online social activities. For example,
Realboy [10] is an experimental project that aims to design
believable Twitter bots that imitate real Twitter users.
2.3 OSN Vulnerabilities
Ineffective CAPTCHAs
We discuss four vulnerabilities found in today’s OSN which
allow an adversary to carry out a large-scale inﬁltration cam-
paign. We treat each vulnerability separately and provide
evidence to support it.
2.3.1
OSNs employ CAPTCHAs [42] to prevent automated bots
from abusing their platforms. An adversary, however, can
often circumvent this countermeasure by using diﬀerent tech-
niques such as automated analysis using optical character
recognition [6], exploiting botnets to trick infected victims
into manually solving CAPTCHAs [5, 12], reusing session
IDs of known CAPTCHAs [18], cracking MD5 hashes of
CAPTCHAs that are validated at the client side [44], and
hiring cheap human labor [27].
Let us consider the use of cheap human labor to break
CAPTCHAs; a phenomenon that is known as CAPTCHA-
breaking business. Motoyama et al. [27] show that compa-
nies involved in such a business are surprisingly eﬃcient;
they have high service quality with a success rate of up to
98%, charge $1 per 1,000 successfully-broken CAPTCHAs,
and provide software APIs to automate the whole process.
Thus, even the most sophisticated CAPTCHA technology
that only humans could solve can be eﬀectively circumvented
with a small investment from an adversary. In such a situ-
ation, the adversary acts as an economist; he would invest
in such businesses if the return on investment is consider-
ably high. This allows researchers to look at online attacks
from an economic context, and deﬁne cost metrics that mea-
sure when it is economically feasible for an adversary to
mount a large-scale attack that involves, for instance, break-
ing CAPTCHAs through employing cheap human labor [17].
2.3.2 Fake User Accounts and Proﬁles
Creating a user account on an OSN involves three tasks:
providing an active email address, creating a user proﬁle,
and sometimes solving a CAPTCHA. Each user account
maps to one proﬁle, but many user accounts can be owned
by the same person or organization using diﬀerent email ad-
dresses.
In what follows, we argue that an adversary can
fully automate the account creation process. This, however,
is not new, as similar tools are used for online marketing [2].
Fake user accounts: When creating a new user account
in an OSN, an email address is required to ﬁrst validate
and then activate the account. The OSN validates the ac-
count by associating it to the owner of the email address.
After account validation, its owner activates the account by
following an activation link that is emailed by the OSN. Ac-
cordingly, an adversary has to overcome two hurdles when
creating a new account: providing an active email address
that he owns, and account activation. To tackle the ﬁrst hur-
dle, the adversary can maintain many emails by either us-
ing “temp” email addresses that are obtained from providers
that do not require registration such as 10minutemail.com,
or by creating email addresses using email providers that do
not limit the number of created emails per browsing session
or IP address such as mail.ru. As for the second hurdle,
an adversary can write a simple script that downloads the
activation email, and then sends an HTTP request to the
activation URL that is included in the downloaded email.
Fake user proﬁles: Creating a user proﬁle is a straight-
forward task for real users; they just have to provide the
information that represents their social attributes. For an
adversary, however, the situation is a bit diﬀerent. The ob-
jective of the adversary is to create proﬁles that are “so-
cially attractive”. We consider a purely adversarial stand-
point concerning social attractiveness; the adversary aims
to exploit certain social attributes that have shown to be
eﬀective in getting users’ attention. Such attributes can be
inferred from recent social engineering attacks. Speciﬁcally,
using a proﬁle picture of a good looking woman or man has
had the greatest impact [6, 14]. Thus, an adversary can use
publicly available personal pictures for the newly created
proﬁles, with the corresponding gender and age-range. In
fact, the adversary can use already-rated personal pictures
from websites like hotornot.com, where users publicly post
their personal pictures for others to rate their “hotness”.3
It is thus possible for an adversary to automate the collec-
tion of the required proﬁle information through crawling (or
scavenging in this case) the Web.
3Such sites also provide categorization of the rated personal
pictures based on gender and age-range.
2.3.3 Crawlable Social Graphs
The social graph of an OSN is usually hidden from public
access in order to protect its users’ privacy. An adversary,
however, can reconstruct parts of the social graph by ﬁrst
logging in to the OSN platform using an account, and then
traversing through linked user proﬁles starting from a “seed”
proﬁle. In the second task, web crawling techniques can be
used to download proﬁle pages and then scrape their content.
This allows the adversary to parse the connections lists of
user proﬁles, such as the “friends list” in Facebook, along
with their proﬁle information. After that, the adversary can
gradually construct the corresponding social graph with all
accessible social attributes using a breadth-ﬁrst search [25].
The adversary can build either a customized web crawler
for this task or resort to cheap commercial crawling services