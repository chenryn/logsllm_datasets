●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
5e+08
6e+08
7e+08
9e+08
Projection on 1st PC
8e+08
1e+09
rithms. Initially, the data was clustered in an ellipse. In the
top plot, we see that both algorithms construct reasonable
estimates for the center and ﬁrst principal component for
this data. However, in the bottom plot, we see that a large
amount of poisoning dramatically perturbs some of the data
and as a result the PCA subspace is dramatically shifted to-
ward the target ﬂow’s direction (y-axis). Due to this shift,
DoS attacks along the target ﬂow will be less detectable.
Meanwhile, the subspace of PCA-GRID is noticeably less
aﬀected.
4.2 PCA-GRID
The PCA-GRID algorithm introduced by Croux et al. [6]
is a projection pursuit technique as described above.
It
ﬁnds a K-dimensional subspace that approximately maxi-
mizes S (·), a robust measure of dispersion, for the data Y as
in Eq. (4). The ﬁrst step is to specify our robust dispersion
measure. We use the Median Absolute Deviation (MAD) ro-
bust measure of dispersion, over other possible choices for
S (·). For scalars r1, . . . , rn the MAD is deﬁned as
S
MAD
(r1, . . . , rn) = ω · median {|ri − median{rj}|} ,
where the coeﬃcient ω = 1.486 ensures asymptotic consis-
tency on normal distributions.
The next step requires choosing an estimate of the data’s
central location. In PCA, this estimate is simply the mean
of the data. However, the mean is not robust, so we center
the data using the spatial median instead:
ˆc (Y) ∈ arg min
μ∈RN
(cid:3)yi − μ(cid:3)2 ,
nX
i=1
which involves a convex optimization that is eﬃciently solved
(see e.g., [11]).
Given a dispersion measure and location estimate, PCA-
GRID ﬁnds a (unit) direction v that is an approximate so-
lution to Eq. (4). The PCA-GRID algorithm uses a grid-
search for this task. Namely, suppose we want to ﬁnd the
best candidate between some pair of unit vectors a1 and
a2 (a 2D search space). The search space is the unit cir-
cle parameterized by φ as aφ = cos(φ)a1 + sin(φ)a2 with
φ ∈ [−π/2, π/2]. The grid search splits the domain of φ into
a mesh of Q + 1 candidates φk = π
, k = 0, . . . , Q.
2
Each candidate vector aφk is assessed and the one that max-
imizes S (Yaφk ) is the approximate maximizer ˆa.
”
− 1
“
2k
Q
Figure 1: Here the data has been projected into the 2D
space spanned by the 1st principal component and the
direction of the attack ﬂow #118. The eﬀect on the 1st
principal components of PCA and PCA-GRID is shown
under a globally informed attack (represented by ◦’s).
simply a technique for approximating a projection pursuit
estimator and does not itself contribute to the algorithm’s
robustness—that robustness comes from the deﬁnition of the
projection pursuit estimator in Eq. (4).
First, to better understand the eﬃcacy of a robust PCA al-
gorithm, we demonstrate the eﬀect our poisoning techniques
have on the PCA algorithm and contrast them with the ef-
fect on the PCA-GRID algorithm. In Figure 1, we see the
impact of a globally informed poisoning attack on both algo-
To search a more general N -dimensional space, the search
iteratively reﬁnes its current best candidate ˆa by performing
a grid search between ˆa and each of the unit directions ei.
With each iteration, the range of angles considered progres-
sively narrows around ˆa to better explore its neighborhood.
This procedure (outlined in Algorithm 1) approximates the
direction of maximal dispersion analogous to an eigenvector
in PCA.
i vj = δi,j}
(cid:2)
that maximizes the dispersion measure, the Grid-Search is
repeated K-times. After each repetition, the data is deﬂated
to remove the dispersion captured by the last direction from
the data. This process is detailed in Algorithm 2.
4.3 Robust Laplace Threshold
To ﬁnd the K-dimensional subspace {vi | v
In addition to the robust PCA-GRID algorithm, we also
use a robust estimate for its residual threshold in place of the
Q-statistic described in Section 2.2. Using the Q-statistic as
6Algorithm 1 Grid-Search(Y)
Require: Y is a T × N matrix
1: Let: ˆv = e1;
2: for i = 1 to C do
3:
4:
5:
for k = 0 to Q do
2k
Q
for j = 1 to N do
”
− 1
“
;
Let: φk = π
2i
Let: aφk = cos(φk)ˆa + sin(φk)ej;
if S (Yaφk ) > S (Yˆv) then
Assign: ˆv ← aφk ;
6:
7:
8:
9: Return: ˆv;
Algorithm 2 PCA-GRID(Y, K)
1: Center Y: Y ← Y − ˆc (Y);
2: for i = 1 to K do
vi ← Grid-Search(Y);
3:
4: Y ← projection of Y onto the complement of vi;
5: end for
6: Return subspace centered at ˆc (Y) with principal direc-
tions {vi}K
i=1;
a threshold was motivated by an assumption of normally dis-
tributed residuals [13]. However, we found that the residuals
for both the PCA and PCA-GRID subspaces were empiri-
cally non-normal leading us to conclude that the Q-statistic
is a poor choice for our detection threshold. Instead, to ac-
count for the outliers and heavy-tailed behavior we observed
from our method’s residuals, we choose our threshold as the
1 − β quantile of a Laplace distribution ﬁt with robust lo-
cation and scale parameters. Our solution, antidote is the
combination of the PCA-GRID algorithm and the Laplace
threshold. The non-normality of the residuals has also been
recently pointed out in [3].
As with the previous method described in Section 2.2, we
select our threshold QL,β as the 1 − β quantile of a para-
metric distribution ﬁt to the residuals in the training data.
However, instead of the normal distribution assumed by the
Q-statistic, we use the quantiles of a Laplace distribution
speciﬁed by a location parameter c and a scale parameter b.
Critically, though, instead of using the mean and standard
deviation, we robustly ﬁt the distribution’s parameters. We
estimate c and b from the residuals (cid:3)ya(t)(cid:3)2 using robust
consistent estimates of location (median) and scale (MAD)
`(cid:3)ya(t)(cid:3)2´
Histogram of PCA Residuals
Qstat
Laplace
0e+00
2e+08
4e+08
Residual Size
6e+08
8e+08
Histogram of PCA−GRID Residuals
Qstat
Laplace
y
c
n
e
u
q
e
r
F
y
c
n
e
u
q
e
r
F
0
0
2
0
5
1
0
0
1
0
5
0
0
0
2
0
5
1
0
0
1
0
5
0
0e+00
2e+08
4e+08
Residual Size
6e+08
8e+08
Figure 2: Histograms of the residuals for the original
PCA algorithm (left) and the PCA-GRID algorithm (the
largest residual is excluded as an outlier). Red and blue
vertical lines demarcate the threshold selected using the
Q-statistic and the Laplace threshold, respectively.
Empirically, the Laplace threshold also proved to be better
suited for thresholding the residuals of our models than the
Q-statistic. As can be seen in Figure 2, both the Q-statistic
and the Laplace threshold produce a reasonable threshold
on the residuals of the PCA algorithm but only the Laplace
threshold produces a reasonable threshold for the residuals
of the PCA-GRID algorithm; the Q-statistic vastly underes-
timates the spread of the residuals. As was consistently seen
throughout our experiments, the Laplace threshold proved
to be a more reliable threshold than the Q-statistic.
ˆc = median
1
√
ˆb =
2P −1(0.75)
median
˛˛¯
˘˛˛(cid:3)ya(t)(cid:3)2 − ˆc
5. METHODOLOGY
5.1 Trafﬁc Data
−1(q) is the q
th
where P
quantile of the standard Laplace
distribution. The Laplace quantile function has the form
c,b (q) = c + b· k(q) for some k(q). Thus, our threshold only
−1
P
depends linearly on the (robust) estimates ˆc and ˆb making
the threshold itself robust. This form is also shared by the
normal quantiles (diﬀering only in the function k(q)), but
because non-robust estimates for c and b are implicitly used
by the Q-statistic, it is not robust. Further, by choosing
a heavy-tailed distribution like the Laplace, the quantiles
are more appropriate for the heavy-tails we observed, but
the robustness of our threshold comes from our parameter
estimation.
We use OD ﬂow data collected from the Abilene (Inter-
net2 backbone) network to simulate attacks on PCA-based
anomaly detection. Data was collected over an almost con-
tinuous 6 month period from March 1, 2004 through Septem-
ber 10, 2004 [33]. Each week of data consists of 2016 mea-
surements across all 144 network OD ﬂows binned into 5
minute intervals. At the time of collection the network con-
sisted of 12 PoPs and 15 inter-PoP links. 54 virtual links
are present in the data corresponding to two directions for
each inter-PoP link and an ingress and egress link for each
PoP.
75.2 Validation
To evaluate the subspace method and antidote in the
face of poisoning and DoS attacks, we use two consecutive
weeks of data—the ﬁrst for training and the second for test-
ing. The poisoning occurs throughout the training phase,
while the attack occurs during the test week. An alter-
nate method (described later) is needed for the Boiling Frog
scheme where training and poisoning occur over multiple
weeks. Our performance metric for measuring the success of
the poisoning strategies is through their impact on a PCA-
based detector’s false negative rate (FNR). The FNR is the
ratio of the number of successful evasions to the total num-
ber of attacks (i.e., the attacker’s success rate is PCA’s FNR
rate). We also use Receiver Operating Characteristic (ROC)
curves to visualize a detection method’s trade-oﬀ between
detection rate (TPR) and false positive rate (FPR).
In order to compute the FNRs and FPRs, we generate
synthetic anomalies according to the method of Lakhina et