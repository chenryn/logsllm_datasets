None of the existing solutions have achieved widespread commercial adoption. In this section, we evaluate the industry’s proposed solution, USB Type-C Authentication (TCA) [121]. TCA is the first attempt by the USB 3.0 Promoter Group and USB-IF to address security issues. However, the security properties of TCA are not yet widely understood by the security community.

We begin with an overview of TCA's features and assumptions. Using the Type-C Authentication revision 1.0 specification (released on February 2, 2017), we formally model and verify the protocol using ProVerif [21], identify multiple attacks, and discuss other issues within the specification. We then evaluate TCA based on our findings. At the time of writing, the only commercial products supporting TCA are software from Siliconch [107] and a USB PD controller from Renesas [96].

### Features and Assumptions of TCA

#### 1. Certificate Verification Process
The certificate verification process can be expedited if the certificate chain has already been cached and verified.

#### 2. Certificate Read
This operation allows the host to retrieve a specific certificate chain using the `GetCertificate` request.

#### 3. Challenge
As shown in Figure 5, this operation initiates a challenge-response protocol where the host sends a `Challenge` request. The request includes a slot identifier in the request header and a 32-byte nonce. The response echoes the same slot identifier in the response header and contains:
- A 32-byte SHA256 hash of the chosen certificate chain.
- A 32-byte salt.
- A 32-byte SHA256 hash of all USB descriptors for USB devices or all zeros for PD devices.
- A 64-byte ECDSA digital signature on the challenge message and the response message, using the corresponding private key of the device.

#### 4. Secure Key Storage and Processing
To protect certificate private keys, a non-volatile secure enclave is required, as shown in Figure 6. This storage is partitioned into 8 slots, each supporting a private key. Similarly, the certificate chain region also has 8 slots, containing the corresponding certificate chain if there is a private key in the associated slot. The TCA specification does not specify whether certificate chains should also be secured.

To support the authentication protocol, a hardware cryptographic engine supporting ECDSA is also required. Presumably, this should be the only component that can access the secure storage. Other hardware components, such as a TRNG and SHA256, may be needed for both security and performance reasons.

#### 5. Security Policy
Following device authentication, the TCA specification suggests the introduction of a policy mechanism for peripheral management. The specification explains that “Policy defines the behavior of Products. It defines the capabilities a Product advertises, its Authentication requirements, and resource availability with respect to unauthenticated Products” (Page 14, Section 1.4) and “USB Type-C Authentication allows an organization to set and enforce a Policy with regard to acceptable Products.” (Page 11, Section 1). Unfortunately, beyond this description, a concrete definition for policy is not provided; all implementation details are left to the OEM.

### Formal Verification

To discover possible vulnerabilities in the design, we formally verify the TCA protocol using ProVerif [21], which has been applied to Signal [69] and TLS 1.3 Draft [19]. ProVerif uses the concept of channels to model an untrusted communication environment (e.g., the Internet) where adversaries may attack the protocol. However, because the USB communication channel does not provide confidentiality by default and is trusted in most cases, we instead model the device firmware as our channel. This accurately models attacks such as BadUSB [85], where the attacker is either a malicious USB device or a non-root hub trying to spoof the authentication protocol. In ProVerif, we define this firmware channel as `free fw:channel`.

We also need to define the security properties we wish to prove. For example, since the private keys inside USB devices should never be leaked, we seek to understand if attackers can learn the key from eavesdropping or participating in the protocol. The Type-C authentication specification clearly states (Page 11, Section 1.2) that “it permits assurance that a Product is:
1. Of a particular type from a particular manufacturer with particular characteristics.
2. Owned and controlled by a particular organization.”

This means the authentication protocol should guarantee both the original configuration and the true identity of the device. The original configuration should be the one designed by the vendor for this product (e.g., a webcam). The true identity combines the usage of certificate chains (tying to a particular organization) and private keys baked into the device to provide the ability to cryptographically verify the original configuration. We abstract these security goals in ProVerif:

```proverif
free slot_key:pri_key [private].
free slot_cert_chain:cert_chain.
free orig_conf:usbpd_config.
query attacker(slot_key).
query d:usbpd; event(goodAuth(d, true)) ==>
event(useConfig(d, orig_conf)).
query d:usbpd; event(goodAuth(d, true)) ==>
(event(useCert(d, slot_cert_chain)) &&
event(usePrivkey(d, slot_key))).
```

To simplify the abstraction, we model one private key and the corresponding certificate chain rather than implementing all 8 slots. We also make the following assumptions:
- We ignore the verification process for a certificate chain, which is critical to the security of the entire protocol but out of the scope of the protocol.
- We assume the verification process to be successful by default.

Our modeling is based on the communication between the USB host and the USB device. PD products share the same procedure via different signaling mappings. To mimic the caching behavior involved in the protocol, we use a "table" in the host side, supporting reading and writing a certificate chain: `table cert_chain_cache(cert_chain, digest)`.

### Results

Unsurprisingly, attackers cannot obtain the private key inside the USB device through protocol messages alone, as none of these messages are designed to transmit the key. However, the protocol fails to meet its goals; neither the original configuration nor the true identity of the device could be guaranteed even if the authentication protocol succeeds, due to certificate chain caching inside the USB host:

```proverif
get cert_chain_cache(chain, =dig) in known_device(config)
else new_device(config).
```

Since the certificate chains are not secret, a malicious device can compute the digest of the expected chain. This digest can be sent as a response to the `GetDigest` request and impersonate the legitimate device. Unless the configuration of the legitimate device is saved and compared with the current configuration by the host, a malicious device can claim any functionality it wants. Thus, the certificate chain cache is vulnerable to spoofing attacks.

We then remove the certificate chain cache from the host, forcing every device to go through a complete certificate request. Again, the private key is secure. Unfortunately, the authentication can still be spoofed as shown in this attacking trace:

```proverif
attacker(sign((non_1883,hash(chain_1877),sal_d_1881,
config_d_1879),prik_1876)).
```

To exploit this vulnerability, the attacker hardcodes a certificate chain and a private key in the firmware rather than using the ones in the slot and modifies the original configuration (e.g., by adding a malicious HID functionality). This means that without firmware verification to prevent BadUSB attacks, these also allow circumventing the TCA protocol, rendering it useless for its stated goals.

To demonstrate how firmware verification corrects this issue, we then assume firmware is trusted (e.g., signed by the vendor and verified by the MCU before flashing). We model this in ProVerif by marking the firmware channel as private: `free fw:channel [private]`. We assume that valid, legitimate firmware will use the certificate chains and private keys inside the slots during authentication and that the original configuration of the device does not contain malicious functionality.

Using this model, ProVerif confirms that successful authentication guarantees both the original configuration and the true identity of the device:

```proverif
RESULT event(goodAuth(d,true)) ==>
(event(useCert(d,slot_cert_chain[])) &&
event(usePrivkey(d,slot_key[]))) is true.
RESULT event(goodAuth(d_2076,true)) ==>
event(useConfig(d_2076,orig_conf[])) is true.
RESULT not attacker(slot_key[]) is true.
```

These results show that correct authentication using the TCA protocol is possible only when the firmware is verified.

### Other Issues

Our analysis of the TCA specification uncovered other serious and systemic design flaws. These flaws reflect both a lack of understanding of secure protocol design and a lack of awareness of the present state of threats to peripheral devices. Responsibility for solving the most difficult security challenges raised by Type-C, such as a USB Certificate Authority system or a rich language for expressing security policies, is delegated wholesale to the OEMs. As a result, we conclude that Type-C is based on an intrinsically broken design. Below, we catalog these issues:

1. **No Binding for Identification with Functionality**: In addition to the VID, PID, and serial number of the device, a device’s leaf certificate also carries Additional Certificate Data (ACD). ACD contains physical characteristics of PD products (e.g., peak current and voltage regulation) but no functionality (interface) information for other USB products. One explanation is that the protocol was designed to address low-quality Type-C cables that were damaging host machines [18] but was later extended to support other USB products. For PD, the specification clearly states that it does not consider alternative modes. As a result, a successful authentication does not specify the device’s original configuration (e.g., storage device, keyboard, normal charging cable).

2. **Volatile Context Hash**: As shown in Figure 5, the challenge response contains the context hash, which is all zeros for PD products but a SHA256 hash of all descriptors for USB products. This seems intended to solve the functionality binding issue for USB products mentioned above but is broken when the firmware is not trusted. However, the firmware can provide its own set of USB descriptors and feed them into the hardware ECDSA signing module to generate the challenge response, as shown in Figure 6. As a result, BadUSB attacks are still possible.

3. **Unidirectional Authentication**: For PD products, either a PD sink or a PD source can initiate an authentication challenge. The authentication between PD devices is thus mutual. However, the TCA specification only allows USB host controllers to initiate an authentication challenge for USB devices. This is unfortunate, as our survey of defensive solutions demonstrates that host authentication is an essential feature for device self-protection. As a result, the TCA specification does not provide a way for smart devices such as mobile phones to make informed trust decisions.

4. **Nebulous Policy Component**: Following device authentication, the TCA specification calls for the creation of a security policy to handle different connected products, but does not adequately describe what a policy is or how to create one. The specification does not define the security policy language, encoding, installation method, or how it interacts with the USB host controller. Policies are only described anecdotally, indicating a lack of forethought as to how TCA policy can appreciably enhance security.

5. **Impractical Key Protection Requirement**: The private keys in the slots are the most important property a product needs to protect besides the firmware. Although the specification does not detail how to secure private keys, it does list more than 10 attacks a product needs to defend against from leaking keys, including side-channel attacks, power analysis, micro-probing, etc. It is unlikely that a $10 USB product [96] could stop advanced invasive attacks, e.g., using Focused Ion Beam (Appendix C, TCA Spec), which makes certificate revocation critical when a private key is leaked.

6. **No Revocation**: The specification states that the validity time of a product certificate is ignored, suggesting that once the certificate is loaded onto the device, there is no way to revoke it. The use of certificate chain caching to accelerate the authentication process is also based on the fact that all certificates along a chain stay legitimate forever once the chain is verified.

7. **No Support for Legacy Products**: With the help of converters, Type-C can be fully compatible with legacy USB devices, and leaves it to the end user to set a security policy that blacklists devices that cannot participate in the authentication protocol. As breaking backwards compatibility is in direct conflict with the USB’s core design principle of universality, very few organizations will elect to set such a policy. As a result, TCA is likely to be trivially bypassed by applying a converter to a Type-C device.

We map TCA as a new defense primitive against all attack primitives in Table III, which shows the limitation of TCA as a complete USB security solution. Not surprisingly, TCA works best for signal injection attacks since it was designed to solve the problem of low-quality charging cables. All other limited defense effects are the results of trusting the identity and the firmware once the device passes the authentication protocols, and assuming some security policies deployed on the host machines using the identity of the device.

We then evaluate TCA using all the findings based on our systematization, as shown in Table IV. On one hand, TCA is aware of some urgent issues in USB security, taking initial steps to address them. However, the design flaws and limitations render its goals in vain.