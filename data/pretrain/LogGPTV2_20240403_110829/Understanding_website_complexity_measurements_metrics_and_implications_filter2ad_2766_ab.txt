rendering content (we call this RenderStart), and onLoad, the time
to completely render all components of the page (we call this Ren-
derEnd).3 Our main ﬁeld of interest is the array of request-response
entries. Each entry provides a timestamp of when the request was
initiated, the time it took to complete the request, the host to which
the request was sent, and the size and content type of the response.
We gathered measurements from four geographically distributed
vantage points. Three of these vantage points were Amazon EC2
Micro instances running Ubuntu Linux (version 11.04) located in
the US-East, Europe, and Asia Paciﬁc regions of EC2. To discount
any effects speciﬁc to EC2, our last vantage point is a personal
desktop at UC Riverside. We choose multiple vantage points to
3There is discussion in the web community on good load time
metrics; suggestions include “above-the-fold” time, time to ﬁrst
“paint”, time-to-ﬁrst-byte, etc. [7]. Using a full spectrum of ren-
der metrics is outside the scope of our analysis. We pick the two
standard metrics reported by the browser itself.
(a) By rank
(b) By category
Figure 2: Total number of objects loaded on the base web page
of websites across rank ranges and categories.
ensure that our choice of measurement site does not introduce any
bias.
At each vantage point, we run a measurement agent that period-
ically (every 60 seconds) selects a website at random from the list
of 2000 sites, launches a Firefox instance that loads the base URL
(i.e., www.foo.com) for the website, generates the log report in
the HAR format, and subsequently terminates the Firefox process.
We repeat this for a period of 9 weeks (between May and August
2011) and gather roughly 30 measurements per website on average.
Our primary focus is on the root or landing pages of these sites; we
present a preliminary study of non-landing pages in Section 6.
We perform the following pre-processing on our data. We dis-
card individual HAR ﬁles if they have recorded the number of bytes
fetched or the page load time as zero, specify the HTTP status code
as not 200, or are malformed. We discard measurements from all
websites for which we observe consecutive HAR ﬁles spaced less
than 60 seconds apart. These correspond to corner cases where the
Firebug add-on to Firefox had trouble exporting a HAR ﬁle for the
web page it loaded. These steps for cleaning the dataset leave us
with measurements from 1748 websites. Table 1 summarizes the
spread of the websites that remain across ﬁve rank-ranges.
For each website, we compute the median value for various fea-
tures, such as number of objects loaded or number of servers con-
tacted, across multiple measurements of the website. We use these
median values of features for most of our analysis, though we do
315Complexity metric
Key result(s)
No. of objects
MIME type
No. of servers
Non-origin contribution
Content complexity
Across all rank ranges, median web page requests over 40 objects and 20% request over 100 objects
News websites load a signiﬁcantly greater number of objects than others
Contribution of various content types is similar across rank ranges
Images dominate in fraction of objects, but to a lesser extent with respect to fraction of bytes
Kids and Teens websites have a signiﬁcantly greater fraction of Flash content than others
Service complexity
25–55% of websites load content from at least 10 servers
News websites fetch content from signiﬁcantly more servers than others
60% of websites fetch content from more than 5 non-origins
Non-origins make signiﬁcant contributions to content—30% of objects and 35% of bytes in the median case
Contribution of non-origins to page load time is low (80th percentile is 35%) due to browser optimizations
Images dominant object type served from origins, but Javascript accounts for sizeable fraction of non-origin objects
Advertising and analytics services account for most non-origin objects, but CDNs account for most bytes
Table 2: Summary of key takeaways from our analysis with respect to various web page complexity metrics.
consider variation across samples when studying how complexity
impacts variability in page load times.
4. CHARACTERIZING COMPLEXITY
Our analysis of our measurement dataset is two-pronged. First,
in this section, we analyze web pages with respect to various com-
plexity metrics. Next, in Section 5, we analyze the impact of these
metrics on performance. Note that our focus is on capturing the
complexity of web pages as visible to browsers on client devices;
we do not intend to capture the complexity of server-side infras-
tructure of websites [43].
We consider two high-level notions of web page complexity.
Content complexity metrics capture the number and size of objects
fetched to load the web page and also the different MIME types
(e.g., image, javascript, CSS, text) across which these objects are
spread. Now, loading www.foo.com may require fetching con-
tent not only from other internal servers such as images.foo.com
and news.foo.com, but also involve third-party services such as
CDNs (e.g., Akamai), analytics providers (e.g., Google analytics),
and social network plugins (e.g., Facebook). Service complexity
metrics capture the number and contributions of the various servers
and administrative origins involved in loading a web page.
We begin with the content-level metrics before moving on to
service-level metrics. In each case, we present a breakdown of the
metrics across different popularity rank ranges (e.g., top 1–1000
vs. 10000–20000) and across different categories of websites (e.g.,
Shopping vs. News). Here, we only show results for one of the
vantage points as the results are (expectedly) similar across van-
tage points. Table 2 summarizes our key ﬁndings for the various
complexity metrics.
4.1 Content complexity
Number of objects: We begin by looking, in Figure 2, at the total
number of object requests required, i.e., number of HTTP GETs
issued, to load a web page. Across all the rank ranges in Fig-
ure 2(a), loading the base web page requires more than 40 objects
to be fetched in the median case. We also see that a non-trivial
fraction (20%) of websites request more than 100–125 objects on
their landing web page, across the rank ranges. While the top 1–
400 sites load more objects, the distributions for the different rank
ranges are qualitatively and quantitatively similar; even the lower
rank websites have a large number of requests.
Next, we divide the sites by their Alexa categories. For clarity,
we only focus on the top-two-level categories from Alexa. To en-
sure that our results are statistically meaningful, we consider only
Figure 3: Median number of requests for objects of different
MIME-types across different rank ranges.
the categories that have at least 50 websites in our dataset. The
breakdown across the categories in Figure 2(b) shows a pronounced
difference between categories; the median number of objects re-
quested on News sites is nearly 3× the median for Business sites.
We suspect that this is an artifact of News sites tending to cram in
more content on their landing pages compared to other sites to give
readers quick snippets of information across different news topics.
Types of objects: Having considered the total number of object re-
quests, we next consider their breakdown by content MIME types.
For brevity, Figure 3 shows only the median number of requests
for the four most popular content types across websites of different
rank ranges. The ﬁrst order observation again is that the differ-
ent rank ranges are qualitatively similar in their distribution, with
higher ranked websites having only slightly more objects of each
type.
However, we ﬁnd several interesting patterns in the prevalence
of different types of content. While it should not come as a surprise
that many websites use these different content types, the magnitude
of these fractions is surprising. For example, we see that, across all
rank ranges, more than 50% of sites fetch at least 6 Javascript ob-
316Figure 4: Median number of requests for objects of different
MIME-types for different categories.
jects. Similarly, more than 50% of the sites have at least 2 CSS
objects. The median value for Flash is small; many websites keep
their landing pages simple and avoid rich Flash content. These
results are roughly consistent with recent independent measure-
ments [31].
Figure 4 shows the corresponding breakdown for the number
of objects requested of various content types across different cat-
egories of websites. Again, we see the News category being dom-
inant across different content types. As previously seen in Fig-
ure 2(b), News sites load a larger number of objects overall com-
pared to other site categories. Hence, a natural follow-up question
is whether News sites issue requests for a proportionately higher
number of objects across all content types. Therefore, for each
website, we normalize the number of objects of each content type
by the total number of objects for that site. The distribution of the
median values of the normalized fraction of objects of various con-
tent types (not shown) presents a slightly different picture than that
seen with absolute counts. Most categories have a very similar nor-
malized contribution from all content types in terms of the median
value. The only signiﬁcant difference we observe is in the case
of Flash objects. Figure 5 shows that Kids and Teens sites have
a signiﬁcantly greater fraction of Flash objects than sites in other
categories.
Bytes downloaded: The above results show the number of ob-
jects requested across different content types, but do not tell us
the contribution of these content types to the total number of bytes
downloaded. Again, for brevity, we summarize the full distribution
with the median values for different website categories in Figure 6.
Surprisingly, we ﬁnd that Javascript objects contribute a sizeable
fraction of the total number of bytes downloaded (the median frac-
tion of bytes is over 25% across all categories). Less surprising
is that images contribute a similar fraction as well. For websites
in the Kids and Teens category, like in the case of number of ob-
jects, the contribution of Flash is signiﬁcantly greater than in other
categories. As in the case of the number of objects, we see no sig-
niﬁcant difference across different rank ranges.
Figure 5: Fraction of objects accounted for by Flash objects,
normalized per category.
4.2 Service complexity
Anecdotal evidence suggests that the seemingly simple task of
loading a webpage today requires the client-side browser to con-
nect to multiple servers distributed across several administrative
domains. However, there is no systematic understanding of how
many different services are involved and what they contribute to
the overall task. To this end, we introduce several service complex-
ity metrics.
Number of distinct servers: Figure 7 shows the distribution across
websites of the number of distinct webservers that a client contacts
to render the base web page of each website. We identify a server
by its fully qualiﬁed domain name, e.g., bar.foo.com. Across
all ﬁve rank ranges, close to 25–55% of the websites require a client
to contact at least 10 distinct servers. Thus, even loading simple
content like the base page of websites requires a client to open
multiple HTTP/TCP connections to many distinct servers. Also,
Figure 7(b) mirrors the earlier result from Figure 2(b); News sites
have the most number of distinct servers as well.
Number of non-origin services: Not all the servers contacted in
loading a web page may be under the web page provider’s con-
trol. For example, a typical website today uses content distribution
networks (e.g., Akamai, Limelight) to distribute static content, an-
alytics services (e.g., google-analytics) to track user activity, and
advertisement services (e.g., doubleclick) to monetize visits.
Identifying non-origins, however, is slightly tricky. The subtle is-
sue at hand is that some providers use multiple origins to serve con-
tent. For example, yahoo.com also owns yimg.com and uses
both domains to serve content. Even though their top-level domains
are different, we do not want to count yimg.com as a non-origin
for yahoo.com because they are owned by the same entity. To
this end, we use the following heuristic. We start by using the two-
level domain identiﬁer to identify an origin; e.g., x.foo.com and
y.foo.com are clustered to the same logical origin foo.com.
Next, we consider all two-level domains involved in loading the
base page of www.foo.com, and identify all potential non-origin
domains (i.e., two-level domain not equal to foo.com). We then
do an additional check and mark domains as belonging to different
origins only if the authoritative name servers of the two domains do
not match [33]. Because yimg.com and yahoo.com share the
same authoritative name servers, we avoid classifying yimg.com
as having a different origin from yahoo.com.
317(a) By rank
Figure 6: Median normalized contribution of different MIME
types to total bytes downloaded.
Figure 8 shows that across the different rank ranges and cate-
gories, clients need to contact servers in at least 10 different origins
for 20–40% of websites. The presence of non-origin content is
even more pronounced on News sites; more than 40% of News sites
serve content from over 20 non-origin providers. On further in-
spection, we ﬁnd that because the landing pages of News sites have
to provide content that spans multiple user interests (e.g., sports,
weather) they provide links to non-origin afﬁliates that serve such
content as well.
Contribution of non-origin services: The previous result simply
counts the number of distinct domains contacted. Next, we quantify
the contribution of the non-origin domains along three dimensions:
fraction of objects, fraction of bytes, and fractional contribution to
total page load time.
Figure 9 shows that, in the median case, over 30% of the to-
tal number of objects and over 35% of the total number of bytes
downloaded are from non-origin services. At the same time, we
see that the distribution is pretty heavy-tailed; for 20% of websites,
non-origin services account for roughly 80% of the objects and to-
tal bytes.
The total number of objects or bytes may, however, not directly
translate into download time because modern browsers can paral-
lelize requests to multiple servers. Now, parallelization also makes
it inherently difﬁcult to exactly determine the time contribution of
non-origins. In light of this, we use three alternative ways to mea-
sure the non-origin contribution to total page load time: (1) the
“wall-clock” time where the browser is retrieving content from at
least one non-origin (labeled “Time: At Least 1 Non-Origin”), (2)
the ratio of the sum of all time spent in downloading non-origin
content to the total time spent downloading all content (labeled
“Time: Total Cycle Contribution”), and (3) emulating the act of
loading the page by disabling all non-origin content using custom
Adblock ﬁlters (labeled “Time: Block Non-Origin”). We see in
Figure 9 that in the median case, content from non-origins con-
tributes to only 15% of the page load time in terms of the At Least
1 Non-Origin and around 25% for the Total Cycle Contribution.
These results suggest that though non-origin services play a signif-
(b) By category
Figure 7: Number of distinct servers contacted to load the base
webpage for websites across different rank ranges and cate-
gories.
icant part of the web ecosystem in terms of the fraction of content
they contribute, browser optimizations (e.g., pipelining and paral-
lelizing requests to distinct servers) lower their impact on page load
times.
4.3 What do non-origins offer?
A natural question is what types of content and services do non-
origins provide. Beyond a basic curiosity of what non-origin con-
tent includes, this also has important performance implications. For
example, if most non-origin objects constitute content essential for
the user experience, then it might be difﬁcult for website providers
to directly optimize their delivery or client-side blocking of non-
origin content would adversely affect user experience. But, if most
non-origin objects are from services for displaying ads or tracking
users, they could potentially be consolidated or optimized. There-
fore, in this section, we do a more in-depth analysis of the MIME-
types of objects served by non-origins, how they differ from objects
served from origins, and also identify the class of services that these
non-origins provide.
Content type breakdown: As a ﬁrst step, we want to understand
what types of content are served by non-origins across different