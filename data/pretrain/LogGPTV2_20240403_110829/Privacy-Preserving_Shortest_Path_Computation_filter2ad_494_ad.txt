k0
nw
(k0
nw), Lunblind
k1
nw
(k1
nw).
Figure 3 (Continued): The fully-private routing protocol, as outlined in Section 4. The protocol description continues
on the next page.
12
12. The client evaluates the garbled circuit ˜C unblind. If the garbled circuit evaluation is successful and the client
obtain outputs (ˆbne, ˆbnw, ˆkne, ˆknw), then the client computes a direction dir = IndexToDirection(ˆbne, ˆbnw) ∈
{n, e, s, w} (Eq. (1)).
(a) The client computes the direction key ˆkdir = F (ˆkne, dir) ⊕ F (ˆknw, dir). Next, the client decrypts the
encrypted source key ˆκdir to obtain the source key ˆk(r+1)
src = Dec(ˆkdir, ˆκdir) for the next round of the
protocol.
(b) Let vdir be the neighbor of s in the direction given by dir (deﬁne vdir to be ⊥ if s does not have a
neighbor in the direction dir). If vdir (cid:54)= ⊥, the client outputs vdir and updates s = vdir. Otherwise, if
vdir = ⊥, the client outputs ⊥ and leaves s unchanged.
If the OT for the input wires to the garbled circuit fails, the garbled circuit evaluation fails, or the output of
the garbled circuit is ⊥, then the client outputs ⊥, but continues with the protocol: it leaves s unchanged
and sets ˆk(r+1)
r←− {0, 1}(cid:96).
src
Figure 3 (Continued): The fully-private routing protocol, as outlined in Section 4.
4.2 Security Model
In this section, we formally specify our security model. To deﬁne and argue the security of our protocol, we
compare the protocol execution in the real-world (where the parties interact according to the speciﬁcation
given in Figure 3) to an execution in an ideal world where the parties have access to a trusted party
that computes the shortest path. Following the conventions in [Can06], we view the protocol execution
as occurring in the presence of an adversary A and coordinated by an environment E = {E}λ (modeled
as a family of polynomial size circuits parameterized by a security parameter λ). The environment E is
responsible for choosing the inputs to the protocol execution and plays the role of distinguisher between
the real and ideal experiments.
As speciﬁed in Figure 3, we assume that the following quantities are public to the protocol execution:
the topology of the network G = (V, E), the number of columns d in the compressed routing matrices, a
bound on the bit-length τ of the values in the matrix products A(ne) · (B(ne))T and A(nw) · (B(nw))T , and
the total number of rounds R (i.e., the number of hops in the longest possible shortest path). We now
deﬁne the real and ideal models of execution.
Deﬁnition 4.1 (Real Model of Execution). Let π be a private navigation protocol. In the real world,
the parties interact according to the protocol speciﬁcation π. Let E be the environment and let A be an
adversary that corrupts either the client or the server. The protocol execution in the real world proceeds
as follows:
1. Inputs: The environment E chooses a source-destination pair s, t ∈ V for the client and compressed
next-hop routing matrices A(ne), B(ne), A(nw), B(nw) ∈ Zn×d for the server. The bit-length of all
entries in the matrix products A(ne) · (B(ne))T and A(nw) · (B(nw))T must be at most τ . Finally, the
environment gives the input of the corrupted party to the adversary.
2. Protocol Execution: The parties begin executing the protocol. All honest parties behave according
to the protocol speciﬁcation. The adversary A has full control over the behavior of the corrupted
party and sees all messages received by the corrupted party.
3. Output: The honest party computes and gives its output to the environment E. The adversary
computes a function of its view of the protocol execution and gives it to E.
13
At the conclusion of the protocol execution, the environment E outputs a bit b ∈ {0, 1}. Let REALπ,A,E (λ)
be the random variable corresponding to the value of this bit.
Deﬁnition 4.2 (Ideal Model of Execution). In the ideal world, the client and server have access to a
trusted party T that computes the shortest paths functionality f .
1. Inputs: Same as in the real model of execution.
2. Submission to Trusted Party: If a party is honest, it gives its input to the trusted party. If a
party is corrupt, then it can send any input of its choosing to T , as directed by the adversary A.
3. Trusted Computation: From the next-hop routing matrices, the trusted party computes the ﬁrst
R hops on the shortest path from s to t: s = v0, v1, . . . , vR. If vi = t for some i  2τ +µ+1, using larger ﬁnite ﬁelds will decrease the failure
probability, but at the expense of performance. In our experiments, R · 2−µ ≈ 2−30. We now state the
formal security guarantee, but defer its formal proof to Appendix A.2.
Theorem 4.5 (Security Against a Malicious Client). Let π be the protocol in Figure 3 instantiated with a
CPA-secure encryption scheme (Enc, Dec), a secure PRF F , and an OT scheme secure against a malicious
client. Let λ, µ be the security parameter and statistical security parameter, respectively. Let f be the ideal
shortest-paths functionality. Then, for all PPT adversaries A, there exists a PPT adversary S such that
for every polynomial-size circuit family E = {E}λ,
where negl(λ) denotes a negligible function in λ.
Adv(sec)
π,f,A,S,E (λ) ≤ negl(λ) + R · 2−µ,
In addition to security against a malicious client, we require our protocol to provide privacy against a
malicious server. In other words, while a malicious server might be able to cause the client to receive an
invalid path, it still cannot learn any information about the client’s source or destination. We formalize
this in the following theorem. We defer the formal proof to Appendix A.1.
Theorem 4.6 (Privacy Against a Malicious Server). Let π be the protocol in Figure 3 instantiated with
PIR and OT primitives that provide privacy against a malicious server. Let λ be a security parameter
and let f be the ideal shortest-paths functionality. Then, for all PPT adversaries A, there exists a PPT
adversary S such that for every polynomial-size circuit family E = {E}λ,
Adv(priv)
π,f,A,S,E (λ) ≤ negl(λ),
where negl(λ) denotes a negligible function in λ.
5 Experiments
In this section, we describe our implementation of the private routing protocol from Figure 3. Then,
we describe our procedure for preprocessing and compressing actual road networks for major cities taken
from OpenStreetMap [Ope]. Finally, we give concrete performance benchmarks for our preprocessing and
compression pipeline as well as our private routing protocol on actual road networks.
5.1 Protocol Implementation
To evaluate the performance of the protocol in Figure 3, we implemented the complete protocol in C++.
In this section, we describe the building blocks of our implementation. For each primitive, we choose the
parameters to guarantee a minimum of 80 bits of security. The complete protocol implementation contains
approximately 4000 lines of code.
15
PIR. We implemented the (recursive) PIR protocol based on additive homomorphic encryption from [KO97,
OI07]. We instantiate the additive homomorphic encryption scheme with Paillier’s cryptosystem [Pai99],
and use NTL [Sho] over GMP [Gt12] to implement the necessary modular arithmetic. We use a 1024-bit
√
RSA modulus for the plaintext space in the Paillier cryptosystem, which provides 80 bits of security. We
use two levels of recursion in the PIR protocol, so the communication scales as O( 3
n) for an n-record
database.
OT. We instantiate the OT protocol with the protocol from [HL10, §7.3] which provides security against
malicious clients and privacy against malicious servers. This protocol is a direct generalization of the Naor-
Pinkas OT protocol [NP01] based on the decisional Diﬃe-Hellman (DDH) assumption. Security against a
malicious client is enforced by having the client include a zero-knowledge proof of knowledge (speciﬁcally, a
Schnorr proof [Sch89]) with its OT request. To decrease the number of rounds of communication, we apply
the Fiat-Shamir heuristic [FS86] to transform the interactive proof of knowledge into a non-interactive
one by working in the random oracle model. We instantiate the random oracle with the hash function
SHA-256. For improved performance, we implement the Naor-Pinkas OT protocol over the 256-bit elliptic
curve group numsp256d1 from [BCLN14]. We use the MSR-ECC [BCLN14] library for the implementation
of the underlying elliptic curve operations. The 256-bit curve provides 128 bits of security.
Arithmetic and Yao’s circuits. We implement our arithmetic circuits over the ﬁnite ﬁeld Fp where
p = 261 − 1 is a Mersenne prime. Then, reductions modulo p can be performed using just two p-bit
additions. We use NTL [Sho] over GMP [Gt12] for the ﬁnite ﬁeld arithmetic.
For the garbled circuit implementation, we use JustGarble [BHKR13] with the “free XOR” [KS08]
and row-reduction optimizations [PSSW09]. We set the parameters of the garbling framework to obtain
80-bits of security. We use the optimized addition, comparison, and multiplexer circuits from [KSS09] to
implement the neighbor-computation function shown in Figure 2. For multiplication, we implement the
basic “school method.”
Record encryption and PRF. We instantiate the CPA-secure encryption scheme in Figure 3 with AES
in counter mode. We also instantiate the PRF used for deriving the neighbor keys (Step 5 in Figure 3)
with AES. We use the implementation of AES from OpenSSL [The03].
5.2 Preprocessing and Map Compression.
We extract the street maps for four major cities (San Francisco, Washington, D.C., Dallas, and Los Angeles)
from OpenStreetMap [Ope]. For each city, we take its most important roadways based on annotations in
OpenStreetMap, and construct the resulting graph G. Speciﬁcally, we introduce a node for each street
intersection in the city and an edge for each roadway. We assign edge weights based on the estimated
time needed to traverse the associated road segment (computed by taking the length of the segment and
dividing by the approximated speed limit along the segment). Using the procedure described in Section 3,
we preprocess the graph to have out-degree at most 4. We then associate each edge of G with a cardinal
direction by solving the assignment problem from Section 3. We use Stachniss’ implementation [Sta04] of
the Hungarian method [KY55] to solve this assignment problem.
Given the graph G corresponding to the road network for each city, we run Dijkstra’s algorithm [Dij59]
on each node s in G to compute the shortest path between all pairs of nodes. Then, using the all-pairs
shortest paths information, we construct the next-hop routing matrices (M (ne), M (nw)) for G. We remark
that we can substitute any all-pairs shortest path algorithm for Dijkstra’s in this step. The underlying
principle we exploit in the construction of our protocol is the fact that next-hop routing matrices for road
networks have a simple compressible structure amenable to cryptography.
16
City
San Francisco
Washington, D.C.
Dallas
Los Angeles
n
Preprocessing Time (s) Compression Time (s)
1830
2490
4993
7010
0.625
1.138
4.419
9.188
97.500
142.431
278.296
503.007
Table 1: Average time to preprocess and compress the next-hop routing matrices for diﬀerent networks. The second
column gives the number of nodes n in each city’s road network. The preprocessing time column gives the average
time needed to orient the edges, compute all-pairs shortest paths, and construct the next-hop routing matrix for the
network. The compression time column gives the average time needed to compress the ne or nw component of the
next-hop routing matrices.
Finally, we implement the optimization-based compression approach described in Section 3 to compress
the next-hop routing matrices M (ne) and M (nw). We minimize the objective function from Eq. (2) with
the loss function set to the modiﬁed Huber hinge loss from Eq. (3). Because of the highly parallelizable
nature of the objective function, we write specialized CUDA kernels to evaluate the objective function
and its derivative on the GPU. In our experiments, we use the LBFGS optimization algorithm [BLNZ95]
from the Python scientiﬁc computation libraries NumPy and SciPy [ADH+01] to solve the optimization
problem.
5.3 Experiments
Graph preprocessing and compression. We ﬁrst measure the time needed to preprocess and compress
the next-hop routing matrices for several road networks. The preprocessing time includes the time needed
to orient the edges, compute all-pairs shortest paths, and construct the next-hop routing matrix for the
network (as described in Section 5.2).
We also measure the time needed to compress the resulting next-hop routing matrices for the diﬀerent
networks. Recall that our compression method takes a matrix M ∈ {−1, 1}n×n and produces two matrices
A, B ∈ Zn×d such that sign(ABT ) is a good approximation of M . Since the modiﬁed Huber hinge loss
(Eq. 3) is an upper bound on the 0-1 loss function (cid:96)(x, t) = 1{sign(x) = t}, when the objective value
J(A, B) is less than 1 (where J(A, B) is the objective function in Eq. 2), we have sign(ABT ) = M , i.e., the
matrices A, B perfectly reconstruct M . The parameter d is the number of columns in the matrices A and
B. Because our objective function is non-convex in the variables A and B, LBFGS is neither guaranteed
to ﬁnd the globally optimal solution, nor even to converge in a reasonable number of iterations. As a
heuristic for deciding whether a candidate value of d admits a feasible solution that perfectly reconstructs
M (ne) and M (nw), we run up to 5000 iterations of LBFGS and check whether the resulting solution gives
a perfect reconstruction of M . To determine the most compact representation, we search over a range of
possible values for d, and choose the smallest value d that yields a perfect reconstruction of M .
We apply our compression method to the routing matrices for road networks from four cities of varying
size. Then, we compare the size of the original matrix M to the size of its compressed representation A, B.
The number of bits needed to represent A, B is determined by two factors: the number of columns d in
each matrix A, B and the precision ν (measured in number of bits) needed to represent each entry in A, B.
Recall that the optimization procedure outputs two real-valued matrices such that sign(ABT ) = M . To
obtain a representation over the integers (as required by the arithmetic circuits), we scale the entries of
A, B by a constant factor and round each of the resulting entries to the nearest integer. The precision ν
is the number of bits needed to represent each integer component of A, B after rescaling. We choose the
smallest scaling factor such that the rescaled matrices perfectly reconstruct the routing matrix M .
We run the preprocessing and compression experiments on a machine running Ubuntu 14.04 with
17
City
San Francisco
Washington, D.C.
Dallas
Los Angeles
n
1830
2490
4993
7010
d
12
14
19
26
ν
10
10
12
12
τ
20
19
23
24
Compression Factor