to encode distinct elements. HLL is based on two techniques.
The ﬁrst
technique is rank, which is the position of the
leftmost 1’s bit in the hash value of a distinct element. For
instance, the rank of 00001001 is 5. The other technique is
called stochastic averaging, which improves the robustness
of the counting. When encoding, all destination IPs are split
uniformly into m registers (i.e., rank array M []) using a hash
function, and each register maintains the maximum rank value
in M [i]. That is:
M [i] =max{ρ( x), M [i]}
(1)
where ρ(x) is the rank of hash value x. To estimate, HLL
calculates a normalized harmonic mean of all registers as
ˆnm = αm · m
2 · (
m(cid:2)
i=1
−M [i]
2
)
−1
,
(2)
where αm is a constant determined by m.
Multi-tenant cardinality estimation. HLL was designed to
count a single spreader on scale. However, because of the
increasing complexity of the deployment context, the multi-
tenant spreader estimation became crucial. A straightforward
solution then is to use dedicated registers for each spreader,
but that requires a massive memory. To resolve this issue,
vHLL [27] suggested maintaining a global register array for
multiple spreaders, and each spreader uses only a random
portion of the registers in the array. A register can be assigned
to spreaders repeatedly. In vHLL, the registers’ selection of
each spreader follows a random behavior (i.e., random memory
sharing). We note that the random memory sharing technique
is widely used in designing memory-efﬁcient data structures
(i.e., sketch) [2], [3], [15], [16], [28], [29]. However, the major
challenge is how to eliminate the noise caused by the memory
sharing strategy?
State-of-the-art noise handling solutions. In terms of noise
elimination, vHLL and MCSE [16] are state-of-the-art works
in multi-tenant spread estimation. The major difference be-
tween the two schemes is that vHLL is an exponential counter
that shares memory at a register level, whereas MCSE is a
linear counter sharing memory at a bit level. However, they
both maintain a global array and consider the average of global
estimation as a local noise, which will be eliminated from a
local estimation value. To explain, let M [1 . . . m] be the global
register array of vHLL, n be the summation of all spreaders’
cardinalities, and nf is the cardinality of a ﬂow f. In vHLL, all
other ﬂows n− nf is considered as noise that is distributed in
M [] following binomial distribution Bino(n − nf , 1
m ). When
each spreader uses s shared (virtual) register array that is
signiﬁcantly smaller than m (s (cid:2) m), the expectation of the
n−nf
m .
noise (random variable X) inM [i] is given as E(X) =
Then, the noise of s registers is given as E(ns − nf ) =
s · E(X) =s
ns−nf
E(ns−nf ) ) approaches zero
when s is sufﬁciently large [11], E(ns − nf ) ≈ ns − nf .
Hence ns − nf = s
m . Since V ar(
n−nf
m .
n−nf
m · s
m − s
nf =
· (
ns
s
− n
m
)
(3)
vHLL replaces ns and n with HLL’s ( ˆns, ˆn) to estimate ˆnf .
Therefore,
ˆnf = ˆns · m
m − s
− ˆn ·
s
m − s
,
(4)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:21 UTC from IEEE Xplore.  Restrictions apply. 
332
(a) Attack Trafﬁc
(b) Normal Trafﬁc
Fig. 1: Comparison of actual noise, vHLL’s noise estimation,
and our RRSE’s noise estimation using real-world normal and
attack network traces using 2Mb memory.
Fig. 2: A novel representation of cardinality estimation accu-
racy, namely rank (register) value distribution. The harmonic
mean of all rank values in the distribution is the ﬁnal esti-
mation of HLL (see Eq. (2)). Original rank distribution is a
noise-free rank value distribution. Closer distribution to the
original distribution results in more accurate estimation.
ˆn
the former is the estimated cardinality held by s registers
before eliminating a noise and the latter is the noise estimated
by vHLL. We note that ˆn is the estimated cardinality of the
global register array (M []), s is the number of registers for a
spreader, and m is the global array size. Simply put, vHLL
assumes that the per-register noise is the average cardinality of
m−s, where s (cid:2) m), and the virtual register
global registers ( ˆn
array (s) noise for a spreader can be scaled up from the per-
m−s · s (i.e., the latter term in Eq.(4)).
register noise, as
Our observations. As discussed above, vHLL’s noise estima-
tion is based on the cardinality estimation of the global register
array (i.e., ˆn) regardless of individual spreaders’ noise level.
Since the noise increment of individual spreaders has minor
effects on the overall noise estimation result, vHLL’s noise
estimation will lead to an underestimated noise, in general.
Moreover, the estimated noise in vHLL, as a universal noise
(a single value), will be subtracted from every spreader’s
estimation even though the noise varies in different spreaders.
As Fig. 1 shows, the actual noise varies for different-sized
ﬂows, whereas the noise estimated by vHLL is negligibly
small for medium and high spreaders. (1) We observed that
medium and high spreaders increase the noise level of all
spreaders due to the register sharing strategy and memory
constraint. Accordingly, the noise level increases signiﬁcantly
when a massive amount of medium and high spreaders arrive
simultaneously (i.e., attack trafﬁc) compared to the normal
TABLE I: Notation
M []
m
Ms[]
s
b
r
w
global register array
size of M []
local register array
size of Ms[]
size of a register
max rank value (=2b − 1)
r bits of Hash(f )
Cm[]
Cs[]
ˆ
Cf []
ˆnf
Hash()
R[]
ρ(w)
global rank distribution
local rank distribution
recovered Cs[]
estimated cardinality
hash function
distinct integer array
rank calculation function
trafﬁc, as shown in Fig. 1. (2) We also observed that most
of the memory was occupied by small spreaders in both
normal and attack scenarios. These two observations combined
show why vHLL gives the biased overestimation. That is, the
estimated noise of vHLL, which is a global average, is too
small for medium and high spreaders. We note that the concept
of assuming a global average as a local noise is used not only
in vHLL, but a series of multi-tenant estimation algorithms [5],
[15], [16], [28]. Compared to these algorithms, our algorithm
provides more precise noise reduction across all ranges and
more tolerant spreader estimation regarding trafﬁc distribution,
as shown in Fig. 1.
Our approach. In this work, we demonstrate a different
approach to deal with the noise caused by memory sharing.
Our method, called the Rank Distribution Recovery Function,
performs a ﬁne-grained noise estimation and elimination for
every single spreader, which is fundamentally different from
vHLL that applies a universal noise (i.e., identical value) to all
spreaders. And unlike vHLL that performs noise elimination
after estimation, we analyze the distribution of the recorded
intermediate values (i.e., tainted rank values due to memory
sharing) of a spreader, then recover them to the original ones
(i.e., clean rank values; no memory sharing). Then, we use the
cleaned intermediate data to estimate the spreader’s cardinality
without worrying about noise.
To recover the original rank distribution, we obtain a
rank distribution from the tainted rank values of a spreader
(hereafter,
local rank distribution). Then, we leverage the
global rank distribution obtained from the entire memory to
recover the local rank distribution at a ﬁne-grained rank level
(see section III.D for details). Subsequently, we can leverage
the recovered rank distribution to perform HLL estimation
without considering the noise. Fig. 2 shows an example of rank
distribution recovery. We note that the closer the recovered
rank distribution to the original rank distribution, the more
successful the rank recovery or noise elimination is. As shown
in Fig. 2, RRSE’s rank recovery results match well the original
rank distribution.
III. RANK RECOVERY-BASED SPREAD ESTIMATOR(RRSE)
In this section, we introduce RRSE, a multi-tenant car-
dinality estimation algorithm based on the rank distribution
recovery technique. We describe our data structure ﬁrst, fol-
lowed by the encoding and decoding algorithms. Next, we
present the Rank Distribution Recovery, which is our main
contribution. Finally, a theoretical analysis of our scheme, in
terms of estimation bias and variance, is given. Table I shows
the notations used in this paper.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:21 UTC from IEEE Xplore.  Restrictions apply. 
333
Algorithm 1: Encoding
1 forall srcIP, dstIP ← pktf do
x ← Hash(dstIP);
i ←2; w ←2;
idx ← Hash(srcIP ⊕ R[i]);
if M [idx]  (1/30) × 2
end
return ˆnf
Algorithm 2: Decoding
1 Function DECODING(srcIP):
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16 Function RANK DIST RECOVERY(Cs[], Cm[]):
17
18
19
20
21
/* Dynamic Programming */
Set ˆCf [0 . . . r] = 0, sumPn = 0, sum ˆCf = 0;
for i = 0to r do
sumPn = sumPn + (Cm[i] − Cs[i])/(m − s);
ˆCf [i] = (Cs[i] − Cm[i]−Cs[i]
· sum ˆCf )/sumPn;
sum ˆCf = sum ˆCf + ˆCf [i];
m−s
32 then
log(1 − ˆns/2
); [27] for details