as their universality reveals more generic or class-agnostic fea-
tures that machine learning algorithms appear to be sensitive to.
In contrast, input-speci(cid:128)c adversarial perturbations, though less
detectable in many cases, can “over(cid:128)t” and apply only to the inputs
they were designed for [79].
Current approaches, like the following, cra(cid:137) UAPs using white-
box knowledge of the model’s learned parameters. Moosavi-Dezfooli
et al. [44] use the DeepFool algorithm [45] iteratively over a set of
images. Mopuri et al. [46] use Generative Adversarial Nets (GANs)
to compute UAPs, whilst Khrulkov and Oseledets [30] propose to
use the singular vector method that maximizes the di(cid:130)erence in
activations at a targeted hidden layer between the original and the
adversarial examples.
We hypothesize that procedural noise, which exhibits pa(cid:138)erns
visually similar to those of UAPs (see Appendix A), can also act as
a UAP. Procedural noise is simple to implement, fast to compute,
and does not require the additional overhead of building, training,
or accessing a DCN to generate adversarial perturbations. (cid:140)e
parametrization of procedural noise is simpler and this results in
a reduced search space, which can enable query-e(cid:129)cient black-
box a(cid:138)acks. (cid:140)is is particularly useful in large-scale applications
like natural-image classi(cid:128)cation where existing a(cid:138)acks explore the
entire input space, which has very high dimensionality (≥ 100,000).
Procedural noise functions can be classi(cid:128)ed into three categories:
la(cid:138)ice gradient noise, sparse convolution noise, and explicit noise
[34]. La(cid:138)ice gradient noise is generated by interpolating random
values or gradients at the points of an integer la(cid:138)ice, with Perlin
noise as a representative example. Sparse convolution noise is a
sum of randomly positioned and weighted kernels,1 with Gabor
noise as a representative example. Explicit noise di(cid:130)ers from the
others in that the images are generated in advance and stored
later for retrieval. (cid:140)is induces large memory costs and limits its
applicability as an inexpensive a(cid:138)ack. We therefore do not use it
here and leave its investigation for future work.
3.2 Perlin Noise
We chose to use Perlin noise as a representative example for la(cid:138)ice
gradient noise, because of its ease of use, popularity, and simplic-
ity. Perlin noise was developed as a technique to produce natural-
looking textures for computer graphics, with its initial application
in motion pictures where it has remained a staple of the industry
[34]. Although Perlin noise may not be the most expressive noise
function, it has a simple implementation which makes it suitable
for inexpensive black-box a(cid:138)acks as it is controlled by only a few
parameters.
We summarize the formal construction of two-dimensional Per-
lin nose as described by Perlin [54–56]. (cid:140)e value at a point (x, y)
is derived as follows: let (i, j) de(cid:128)ne the four la(cid:138)ice points of the
la(cid:138)ice square where i = {|x|, |x| + 1} and j = {|y|, |y| + 1}. (cid:140)e four
gradients are given by qij = V[Q[Q[i] + j]] where precomputed
arrays Q and V contain a pseudo-random permutation and pseudo-
random unit gradient vectors respectively. (cid:140)e four linear functions
qij(x − i, y − j) are then bilinearly interpolated by s(x − |x|) and
s(y − |y|), where s(t) = 6t
3. (cid:140)e result is the Perlin
4 + 10t
noise value p(x, y) for coordinates (x, y).
(cid:140)e Perlin noise function has several parameters that determine
the visual appearance of the noise. In our implementation, the
wavelengths λx , λy and number of octaves Ω contribute the most
to the visual change. (cid:140)e noise value at point (x, y) with parameters
δper = {λx , λy , Ω} becomes
5 − 15t
Ω
n=1
Sper(x, y) =
p(x · 2n−1
λx
, y · 2n−1
λy
)
To achieve more distinct visual pa(cid:138)erns, we use a sine colour
map with an additional frequency parameter ϕsine. (cid:140)is colour map
for the noise value p is de(cid:128)ned by C(p) = sin(p · 2πϕsine). (cid:140)e
periodicity of the sine function creates distinct bands in the image
to achieve a high frequency of edges. (cid:140)e resulting noise generating
function Gper at point (x, y) is de(cid:128)ned as the composition of our
Perlin noise function and the sine colour map,
Gper(x, y) = C(Sper(x, y)) = sin((Sper(x, y) · 2πϕsine)
with combined parameters δper = {λx , λy , ϕsine, Ω}.
1A kernel in image processing refers to a matrix used for image convolution.
3
3.3 Gabor Noise
We use Gabor noise as a representative example for sparse con-
volution noise. It has more accurate spectral control than other
procedural noise functions [35], where spectral control refers to
the ability to control the appearance of noise as measured by its
energy along each frequency band. Gabor noise can be quickly
evaluated at any point in space and is characterized by only a few
parameters such as orientation, frequency, and bandwidth [35]. In
essence, Gabor noise is a convolution between sparse white noise
and a Gabor kernel ❕. (cid:140)e Gabor kernel is the product of a circular
Gaussian and a Harmonic function:
−π σ 2(x 2+y2) cos[ 2π
λ (x cos ω + y sin ω)],
❕(x, y) = e
where σ is the width of the Gaussian, λ and ω are the period and
orientation of the Harmonic function [34]. Our implementation of
the Gabor kernel uses the OpenCV library [5]. (cid:140)e value Sgab(x, y)
at point (x, y) is the sparse convolution with a Gabor kernel where
{(xi , yi)} are the random points [34]. Gabor noise is an expressive
noise function and will have a large number of dimensions if each
random point is assigned di(cid:130)erent kernel parameters. To simplify
the implementation, we use the same parameters and weights for
each random point (xi , yi). (cid:140)is results in noise pa(cid:138)erns that have
a uniform texture.
We add an additional discrete parameter ξ to control the isotropy
of the Gabor noise. Having ξ = 1 results in anisotropic noise, which
is oriented in one direction. Progressively larger ξ makes it more
uniform in all directions. Implementing these changes gives an
updated formulation
ξ

n=1
i
Sgab(x, y) = 1
ξ
ξ ).
❕(x − xi , y − yi; σ , λ, ω + nπ
To achieve high-frequency pa(cid:138)erns and remove unwanted low-
contrast oscillations, we normalize the variance spectrum of the
Gabor noise using the algorithm described by Neyret and Heitz [48].
(cid:140)is results in min-max oscillations. Note that we refer speci(cid:128)cally
to the frequency of edges, i.e. how o(cid:137)en edges appear one a(cid:137)er the
other on an image. (cid:140)is is di(cid:130)erent from the classical frequency
used in spectral analysis. For simplicity we use “low-frequency” or
“high-frequency” when referring to pa(cid:138)erns with low or high edge
frequency in the image.
We have tried applying the sine colour map to Gabor noise,
but it obscures the Gabor kernel structures. Similarly, we have
tried normalizing the variance spectrum of Perlin noise, but this
resulted in (cid:131)at images with few edges and no distinct pa(cid:138)erns. (cid:140)e
(cid:128)nal noise generating function Gper with a normalized variance
spectrum has parameters δgab = {σ , λ, ω, ξ}.
4 VULNERABILITY TO PROCEDURAL NOISE
In this section, we empirically demonstrate the vulnerability of (cid:128)ve
di(cid:130)erent DCN architectures to procedural noise for the ImageNet
classi(cid:128)cation task. We show that randomly chosen procedural noise
perturbations act as e(cid:130)ective UAPs against these classi(cid:128)ers. (cid:140)e
procedural noise UAPs greatly exceed the baseline uniform random
noise, is on average universal on more than half the dataset across
di(cid:130)erent models, and fools each model on more than 72% of the
dataset when considering input-speci(cid:128)c evasion.
4.1 Experiment Setup
(cid:140)e data used are 5,000 random images from the validation set of
the ILSVRC2012 ImageNet classi(cid:128)cation task [63]. It is a widely
used object recognition benchmark with images taken from vari-
ous search engines and manually labelled to 1,000 distinct object
categories where each image is assigned one ground truth label.
Models. We use four distinct DCN architectures pre-trained
on ImageNet: VGG-19 [67], ResNet-50 [21], Inception v3 [72], and
Inception ResNet v2 [71]. We abbreviate Inception ResNet v2 to
IRv2. Inception v3 and Inception ResNet v2 take input images with
dimensions 299 × 299 × 3 while the remaining two networks take
images with dimensions 224 × 224 × 3.
We also take an ensemble adversarially trained version of the
Inception ResNet v2 architecture: Tramer et al. [75] (cid:128)ne-tuned the
IRv2 network by applying ensemble adversarial training, making it
more robust to gradient-based a(cid:138)acks. We refer to this new model
as IRv2ens. It has the same architecture, but di(cid:130)erent weights when
compared to the (cid:128)rst IRv2. For complete details of the ensemble
adversarial training process, we refer the reader to [75].
Perturbations. (cid:140)e Perlin noise parameters λx , λy , ϕsine and
Gabor noise parameters σ , λ are positive and bounded above by
the image’s side length d. Increasing the parameters beyond this
will have no impact on the resulting image as it gets clipped by the
image dimension. (cid:140)e isotropy ξ ∈ [1, 12] and number of octaves
Ω ∈ [1, 4] are discrete, and evaluations show negligible change in
the image for ξ > 12 and Ω > 4. (cid:140)e range on the angle ω ∈ [0, 2π]
covers all directions.
We (cid:128)x the kernel size and number of random points for Gabor
noise so that the Gabor kernels always populate the entire image.
(cid:140)e parameters δgab of the Gabor noise have the greater in(cid:131)uence
on the resulting visual appearance of the noise pa(cid:138)ern.
To provide a baseline, we also test the models against uniform
random noise perturbations: sgn(r) · ε where r ∈ U(−1, 1)d×d×3, d
is the image’s side length, and ε is the (cid:96)∞-norm constraint on the
perturbation. (cid:140)is is an (cid:96)∞-optimized uniform random noise, and it
is reasonable to say that a(cid:138)acks that signi(cid:128)cantly outperform this
baseline are non-trivial.
Metrics. To measure the universality of a perturbation, we
de(cid:128)ne the universal evasion rate of a perturbation over the dataset.
Given model output f , input x ∈ X, perturbation s, and small ε > 0,
the universal evasion of s over X is
|{x ∈ X : arg max f (x + s) (cid:44) τ(x)}|
|X|
(cid:107)s(cid:107)∞ ≤ ε,
,
where τ(x) is the true class label of x. An (cid:96)∞-norm constraint on
s ensures that the perturbation is small and does not drastically
alter the visual appearance of the resulting image; this is a proxy
for the constraint τ(x) = τ(x + s). We choose the (cid:96)∞-norm as it
is straightforward to impose for procedural noise perturbations
and is o(cid:137)en used in the adversarial machine learning literature.
In this case, f is the probability output vector, but note that the
a(cid:138)acker only needs to know the output class label arg max f (x + s)
to determine if their a(cid:138)acks succeed. To measure the model’s
sensitivity against the perturbations for each input, we de(cid:128)ne the
model’s average sensitivity on an input x over perturbations s ∈ S
4
as
|{s ∈ S : arg max f (x + s) (cid:44) τ(x)}|
|S|
(cid:107)s(cid:107)∞ ≤ ε.
,
Table 1: Universal evasion (%) by percentile for random and
procedural noise perturbations on Inception v3.
,
|X|
(cid:140)is will help determine the portion of the dataset on which the
model is more vulnerable. Finally, the input-speci(cid:128)c evasion rate is
|{x ∈ X : ∃s ∈ S such that arg max f (x + s) (cid:44) τ(x)}|
(cid:107)s(cid:107)∞ ≤ ε.
(cid:140)is measures how many inputs in the dataset can be evaded with
perturbations from S.
Experiment. We evaluate our procedural noise perturbations
on 5,000 random images from the validation set. (cid:140)e perturbations
generated are from 1,000 Gabor noise, 1,000 Perlin noise, and 10,000
uniform random perturbations. 1,000 queries for the procedural
noise functions was su(cid:129)cient for our results and its search space
only has four bounded parameters. We use an (cid:96)∞-norm constraint
of ε = 16. (cid:140)e pixels of the perturbations are (cid:128)rst clipped to [−ε, ε]
and the resulting adversarial example’s pixels are clipped to the
image space [0, 255].
(cid:140)us, this is an untargeted black-box a(cid:138)ack with exactly 1,000
queries per image for procedural noise. Note that the adversary has
no knowledge of the target model and only requires the top label
from the model’s output.
4.2 Universality of Perturbations
(cid:140)e procedural noise perturbations appear to be both universal
and transferable across models. (cid:140)e results in Fig. 2 show that the
models in order from least to most robust against the perturbations
are: VGG-19, ResNet-50, Inception v3, IRv2, and then IRv2ens. (cid:140)is
is not surprising, as the generalization error for these models appear
in the same order, with larger generalization error indicating a less
robust model. (cid:140)e ensemble adversarially trained model has also
been hardened against adversarial examples, so it was expected to
be less a(cid:130)ected. However, the ensemble adversarial training did
not fully mitigate the impact of the procedural noise.
Both Gabor and Perlin noise have signi(cid:128)cantly higher universal
evasion rate than random noise. In Fig. 2a, we represent random
noise using the median (which, in this case, is very close to the
mean) of its universal evasion rate over all 10,000 perturbations, as
the variance is very small (less than 10−5) for each model.
Procedural noise functions create a distribution whose modes
have high universal evasion rates. Table 1 shows an example of this
on Inception v3, where more than half the Perlin noise perturbations
achieve evasion on more than 57% of the dataset.
Between the two procedural noises, Perlin noise is a stronger
UAP, though not by a large margin. In Fig. 2a, Gabor noise appears
bimodal, especially with the IRv2 classi(cid:128)ers. (cid:140)is bimodal aspect
shows that there are two large disjoint subsets of Gabor noise: one
with high universal evasion and another with low universal evasion.
(cid:140)is was not as prominent for Perlin noise.
Best Parameters. Given the distribution of universal evasion
rates in Fig. 2a, it is interesting to observe which parameters of
the noise functions contribute most to the evasion rate. Because
there are only four parameters for each procedural noise function,
the linear correlations between these parameters and the universal
evasion rates give a general overview of their in(cid:131)uence. (cid:140)ough
this analysis may not fully capture multi-variable relationships.
Percentile
min
25th
50th
75th