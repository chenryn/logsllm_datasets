Otherwise, it sets CRED[ 𝑗] = cred.
We define correctness, compactness, unforgeability, dependabil-
ity and anonymity as the following experiments. We assume that,
if required, the experiment honestly generates a reference string 𝜌
using Setup(1𝜆) which is an implicit argument for the remaining
algorithms.
Definition A.8 (Correctness). A core/helper anonymous creden-
tials system is correct if for all 𝜆 ∈ N, all key pairs (isk, ipk) ←$
IKGen(1𝜆), all secret key ssk ←$ CKGen(1𝜆), all attribute sets
Attr𝑠 ⊆ Attr𝑜 and all nonces nonce𝑜, nonce𝑠 ∈ {0, 1}𝜆, aid𝑜 ←$
AIDGen(Attr𝑜, nonce𝑜), aid𝑠 ←$ AIDGen(Attr𝑠, nonce𝑠), all cre-
dential requests areq ←$ HObtain(Attr𝑜, nonce𝑜, ipk, CObtain(aid𝑜,
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2019ipk, ssk)), all showings asig ←$ HShow(Attr𝑠, nonce𝑠, cred,
CShow(aid𝑠, ssk)), we have Verify(Attr, nonce, areq, ipk) = 1, where
(cred, did) ←$ Issue(Attr, nonce𝑜, asig, isk).
Definition A.9 (Compactness). A core/helper anonymous creden-
tials system is compact if for all 𝜆 ∈ N, all key pairs (isk, ipk) ←$
IKGen(1𝜆), all secret key ssk ←$ CKGen(1𝜆), all attribute sets
Attr𝑠 ⊆ Attr𝑜 and all nonces nonce𝑜, nonce𝑠 ∈ {0, 1}𝜆, aid𝑜 ←$
AIDGen(Attr𝑜, nonce𝑜), aid𝑠 ←$ AIDGen(Attr𝑠, nonce𝑠), all cre-
dential requests areq ←$ HObtain(Attr𝑜, nonce𝑜, ipk, CObtain(aid𝑜,
ipk, ssk)), all showings asig ←$ HShow(Attr𝑠, nonce𝑠, cred,
CShow(aid𝑠, ssk)), we have |asig| ≤ 𝑂(𝜆), i.e., the size of the show-
ing token asig is independent of the attribute set |Attr𝑠| and only
depends on 𝜆.
Definition A.10 (Unforgeability). For the core/helper anonymous
credential and adversary A we define the following experiment:
UNFA
CHAC(𝜆)
(isk, ipk) ←$ IKGen(1𝜆)
nonce ←$ {0, 1}𝜆
O := {OHD, OCD, Ononce, OObtIss, OIssue, OHShow}
(Attr∗, asig∗) ←$ AO (ipk, nonce)
if Verify(Attr∗, nonce, asig∗, ipk) = 1 and ∀𝑗 Attr∗ ⊈ CATTR[ 𝑗]
and (nonce) ∉ MN then return 1
else return 0
A CHAC is unforgeable if for all 𝑃𝑃𝑇 adversaries A, its advantage
in the above experiment is negligible:
AdvunfA,CHAC(𝜆) = Pr(cid:104)
CHAC(𝜆) = 1(cid:105)
UNFA
= negl(𝜆).
Definition A.11 (Dependability). For the core/helper anonymous
credential and adversary A we define the following experiment:
HD
CHAC(𝜆)
, OObtIss, Ononce, OIssue, OCShow}
DEPA
(isk, ipk) ←$ IKGen(1𝜆)
O := {O(1)
(Attr∗, nonce∗, asig∗) ←$ AO (ipk)
aid∗ ←$ AIDGen(Attr∗, nonce∗)
if (aid∗) ∈ SN then return 0
if Verify(Attr∗, nonce∗, asig∗, ipk) = 1 and
∀𝑗 Attr∗ ⊈ CATTR[ 𝑗] then
return 1
else return 0
A CHAC is dependable if for all 𝑃𝑃𝑇 adversaries A, its advantage
in the above experiment is negligible:
AdvdepA,CHAC(𝜆) = Pr(cid:104)
CHAC(𝜆) = 1(cid:105)
DEPA
= negl(𝜆).
Definition A.12 (Anonymity). For the core/helper anonymous
credential and adversary A we define the following experiment:
CHAC(𝜆)
ANONA
𝑏 ←$ {0, 1}
O := {OHD, OCD, OObtain1, OObtain2, OHShow}
( 𝑗0, 𝑗1, Attr∗, nonce∗, isk∗, ipk∗, st) ←$ AO (𝜆)
𝑖0 ←$ I2D[ 𝑗0]; 𝑖1 ←$ I2D[ 𝑗1]
if 𝑖0, 𝑖1 ∉ HD or Attr∗ ⊈ ATTR[ 𝑗0] ∩ ATTR[ 𝑗1] then return 0
aid∗ ←$ AIDGen(Attr∗, nonce∗)
apsig ←$ CShow(aid∗, ipk∗, DSK[𝑖𝑏])
asig ←$ HShow(Attr∗, nonce∗, CRED[ 𝑗𝑏], ipk∗, apsig)
𝑏∗ ←$ AO (asig, st)
return 𝑏∗ = 𝑏
A CHAC is anonymous if for all 𝑃𝑃𝑇 adversaries A, its advantage
in the above experiment is negligible:
ANONA
AdvanonA,CHAC(𝜆) = Pr(cid:104)
CHAC(𝜆) = 1(cid:105)
= negl(𝜆).
Note that the adversary returns isk∗ which means that in our def-
inition we assume an honestly generated issuer’s key. This can
be ensured using standard proof techniques, i.e. the issuer proves
knowledge of the secret key. We define anonymity this way to
simplify our construction and proofs.
B PROOFS FOR SECTION 3
B.1 Proof of Theorem 3.2
2, 𝑔𝑏
1 , 𝑔𝑎
Proof. Let (BG, 𝑔𝑎
1, 𝑔𝑏
1, 𝑔𝑑
1, 𝑔𝑐
SFPK
2, 𝑔𝑐
2, 𝑔𝑑
1, Sig∗
2, Sig∗
, 𝑚∗, pk∗
SFPK = (Sig∗
2) be an instance of the
BDDH problem. We will show that we can use any efficient adver-
sary A to solve the above problem instance. To do so, we will build
a reduction algorithm R that uses A in a black box manner.
Let 𝑞ℎ the maximal number of random oracle queries made by the
adversary A and (Sig∗
SFPK) be the forgery returned by
an adversary A, where Sig∗
3). The reduction
choose a random index 𝑖 ∈ {1, . . . , 𝑞ℎ} and aborts the experiment in
case 𝑚∗ is not the 𝑖-th query of A to the random oracle. Note that
this means that the probability that R does not abort the experiment
at any point is 1/𝑞ℎ. What is more, for the 𝑖-th random oracle query
H(𝑚∗) the reduction answers with 𝑔ℎ𝑚∗
To simulate the unforgeabilty experiment, the reduction first
prepares the common reference string 𝜌 by setting 𝑌1 = 𝑔𝑎
1, 𝑌2 = 𝑔𝑎
2.
Next R prepares the public key pkSFPK and the trapdoor 𝜏SFPK.
2 from the problem instance. It
For this it uses the values 𝑔𝑏
sets pkSFPK = (𝑔1, 𝑔𝑏
2). Moreover, the reduction
chooses 𝑘𝑢 ←$ Z∗
2) · 𝑔𝑘𝑢2 ) and shares it
1) · 𝑔𝑘𝑢1 , (𝑔𝑎
with A.
To answer A’s signing queries for message 𝑚 and randomness
𝑡 (which is equal to 1 for oracle O1), the reduction R follows the
following steps:
1 and 𝑔𝑏
𝑝, sets stpub = ((𝑔𝑎
1) and 𝜏SFPK = (𝑔𝑏
1
.
𝑔ℎ𝑚1
(1) it first chooses 𝑤𝑡 ←$ Z∗
𝑝,
(2) it programs the random oracle to output H(𝑚) = (𝑔𝑏
(3) compute 𝑤 = 𝑤𝑡 · 𝑡,
1)𝑡·𝑘𝑢 · (𝑈 𝑤
(4) it computes: Sig1
(5) set the pre-signature pSigSFPK := (Sig1
for some ℎ𝑚 ←$ Z∗
𝑝,
SFPK = (𝑔𝑏
1 )ℎ𝑚,
, 𝑤).
SFPK
1)−𝑤−1
𝑡
·
Session 6D: Authentication and Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea20201
· ((𝑔𝑏
1)−𝑤−1 · 𝑔ℎ𝑚1
1)−𝑤−1 · 𝑔ℎ𝑚1
, 𝑚∗, Sig∗
It is easy to see that this is a valid pre-signature. Note that a valid
one is of the form (𝑔𝑎·𝑏·𝑡
)𝑟 , 𝑤). In this case, the
reduction has set 𝑟 = 𝑡 · 𝑤 · (𝑎 + 𝑘𝑢) and this means that the 𝑔𝑎·𝑏·𝑡
1
cancels out and the reduction does not need to compute 𝑔𝑎·𝑏
. Note
1
that this only works because the reduction is able to program the
random oracle and does not actually know the value 𝑟. We also
assume that if A queries a message 𝑚 prior to a query to signing
queries, the reduction answers with H(𝑚) = (𝑔𝑏
and
retains (𝑤, ℎ𝑚).
Finally, the adversary outputs the forgery (pk∗
SFPK)
of A and the reduction proceeds as follows:
(1) parse Sig∗
SFPK),
, Sig3
SFPK)−ℎ𝑚∗
· H(𝑚∗)𝑟∗ · (𝑔𝑟∗
)𝑟∗ · (𝑔𝑟∗
· (𝑔ℎ𝑚1
SFPK = (𝑔𝑡∗
2).
1 , 𝑔𝑑
(4) output 1 iff 𝑒(𝑔𝑎·𝑏·𝑡∗
The probability that R successfully solves the bilinear decisional
Diffie-Hellman problem depends on the advantage of A and the
probability that R’s simulation succeeds.
[pkSFPK]R and we have pk∗
use 𝑔𝑡∗
1 ,
1 )−ℎ𝑚∗(cid:17) ,
1 )−ℎ𝑚∗(cid:17) ,
, and since for a valid forgery then pk∗
SFPK ∈
1)𝑡∗) and R can
(cid:16)𝑔𝑎·𝑏·𝑡∗
(cid:16)𝑔𝑎·𝑏·𝑡∗
SFPK · (Sig
1
1
(3) parse pk∗
2) = 𝑒(𝑔𝑡∗
, 𝑔𝑐
(2) compute
as (Sig1
𝑔𝑎·𝑏·𝑡∗
1
1 , (𝑔𝑏
, Sig2
= Sig
SFPK
SFPK
SFPK
SFPK
=
=
SFPK
2
1
1
□
ˆ𝑦∗ =𝜋 ˆ𝑦+∑︁
ˆ𝑣∗ =𝜋 ˆ𝑣+∑︁
𝑖∈[ℓ]
B.2 Proof of Lemma 3.6
Proof. We exactly follow the proof of the underlying FHS15
SPS-EQ scheme in [45] and only highlight the differences. To ease
the readability we write elements in G2 with “hat”, e.g., as ˆ𝑉 instead
of 𝑉2, and consequently the forgery is denoted as (𝑍, 𝑌, ˆ𝑌, ˆ𝑉). Now,
if the take the discrete logarithms of all available group elements in
the forgery, we get an additional ˆ𝑉 ∗ term (ˆ𝑣∗) and need to consider
the contributions of the ℎ elements (with coefficients 𝜃𝑖) and ˆ𝑣 𝑗
elements (with coefficients 𝜈 𝑗) from the 𝑞 queries. So the changes
to ˆ𝑦∗ and the additional element ˆ𝑣∗ are:
𝑖∈[𝑘]
𝜃 ˆ𝑦,𝑖ℎ𝑖+∑︁
𝜒 ˆ𝑦,𝑖𝑥𝑖+∑︁
𝜃 ˆ𝑣,𝑖ℎ𝑖+∑︁
𝜒 ˆ𝑣,𝑖𝑥𝑖+∑︁
∑︁
𝑗 ∈[𝑞]
𝜈 ˆ𝑦,𝑗 𝑣 𝑗 +∑︁
𝜈 ˆ𝑣,𝑗 𝑣 𝑗 +∑︁
𝑗 ∈[𝑞]
𝑗 ∈[𝑞]
𝜓 ˆ𝑦,𝑗
𝜓 ˆ𝑣,𝑗
1
𝑦 𝑗
1
𝑦 𝑗
𝑖∈[ℓ]
𝑖∈[𝑘]
𝑗 ∈[𝑞]
From the forgery we know that we have
𝑖 𝑥𝑖 = 𝑧∗ ˆ𝑦∗
𝑚∗
𝑦∗ = ˆ𝑦∗
ˆ𝑣∗ = 𝑦∗ ˆℎ∗
𝑖∈[ℓ]