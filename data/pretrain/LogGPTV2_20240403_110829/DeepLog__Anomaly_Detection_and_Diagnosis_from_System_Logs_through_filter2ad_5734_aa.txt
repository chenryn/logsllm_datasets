title:DeepLog: Anomaly Detection and Diagnosis from System Logs through
Deep Learning
author:Min Du and
Feifei Li and
Guineng Zheng and
Vivek Srikumar
DeepLog: Anomaly Detection and Diagnosis from System Logs
through Deep Learning
Min Du, Feifei Li, Guineng Zheng, Vivek Srikumar
School of Computing, University of Utah
{mind, lifeifei, guineng, svivek}@cs.utah.edu
ABSTRACT
Anomaly detection is a critical step towards building a secure and
trustworthy system. (cid:140)e primary purpose of a system log is to
record system states and signi(cid:128)cant events at various critical points
to help debug system failures and perform root cause analysis. Such
log data is universally available in nearly all computer systems.
Log data is an important and valuable resource for understanding
system status and performance issues; therefore, the various sys-
tem logs are naturally excellent source of information for online
monitoring and anomaly detection. We propose DeepLog, a deep
neural network model utilizing Long Short-Term Memory (LSTM),
to model a system log as a natural language sequence. (cid:140)is allows
DeepLog to automatically learn log pa(cid:138)erns from normal execution,
and detect anomalies when log pa(cid:138)erns deviate from the model
trained from log data under normal execution. In addition, we
demonstrate how to incrementally update the DeepLog model in
an online fashion so that it can adapt to new log pa(cid:138)erns over time.
Furthermore, DeepLog constructs work(cid:131)ows from the underlying
system log so that once an anomaly is detected, users can diagnose
the detected anomaly and perform root cause analysis e(cid:130)ectively.
Extensive experimental evaluations over large log data have shown
that DeepLog has outperformed other existing log-based anomaly
detection methods based on traditional data mining methodologies.
CCS CONCEPTS
•Information systems → Online analytical processing; •Security
and privacy → Intrusion/anomaly detection and malware mitiga-
tion;
KEYWORDS
Anomaly detection; deep learning; log data analysis.
1 INTRODUCTION
Anomaly detection is an essential task towards building a secure
and trustworthy computer system. As systems and applications
get increasingly more complex than ever before, they are subject
to more bugs and vulnerabilities that an adversary may exploit to
launch a(cid:138)acks. Such a(cid:138)acks are also ge(cid:138)ing increasingly more
sophisticated. As a result, anomaly detection has become more
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for pro(cid:128)t or commercial advantage and that copies bear this notice and the full citation
on the (cid:128)rst page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permi(cid:138)ed. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior speci(cid:128)c permission and/or a
fee. Request permissions from permissions@acm.org.
CCS’17, Oct. 30–Nov. 3, 2017, Dallas, TX, USA.
© 2017 ACM. ISBN 978-1-4503-4946-8/17/10...$15.00
DOI: h(cid:138)p://dx.doi.org/10.1145/3133956.3134015
challenging and many traditional anomaly detection methods based
on standard mining methodologies are no longer e(cid:130)ective.
System logs record system states and signi(cid:128)cant events at various
critical points to help debug performance issues and failures, and
perform root cause analysis. Such log data is universally available
in nearly all computer systems and is a valuable resource for un-
derstanding system status. Furthermore, since system logs record
noteworthy events as they occur from actively running processes,
they are an excellent source of information for online monitoring
and anomaly detection.
Existing approaches that leverage system log data for anomaly
detection can be broadly classi(cid:128)ed into three groups: PCA based
approaches over log message counters [39], invariant mining based
methods to capture co-occurrence pa(cid:138)erns between di(cid:130)erent log
keys [21], and work(cid:131)ow based methods to identify execution anom-
alies in program logic (cid:131)ows [42]. Even though they are successful in
certain scenarios, none of them is e(cid:130)ective as a universal anomaly
detection method that is able to guard against di(cid:130)erent a(cid:138)acks in
an online fashion.
(cid:140)is work proposes DeepLog, a data-driven approach for anom-
aly detection that leverages the large volumes of system logs. (cid:140)e
key intuition behind the design of DeepLog is from natural lan-
guage processing: we view log entries as elements of a sequence
that follows certain pa(cid:138)erns and grammar rules. Indeed, a sys-
tem log is produced by a program that follows a rigorous set of
logic and control (cid:131)ows, and is very much like a natural language
(though more structured and restricted in vocabulary). To that end,
DeepLog is a deep neural network that models this sequence of log
entries using a Long Short-Term Memory (LSTM) [18]. (cid:140)is allows
DeepLog to automatically learn a model of log pa(cid:138)erns from nor-
mal execution and (cid:131)ag deviations from normal system execution
as anomalies. Furthermore, since it is a learning-driven approach,
it is possible to incrementally update the DeepLog model so that it
can adapt to new log pa(cid:138)erns that emerge over time.
Challenges. Log data are unstructured, and their format and se-
mantics can vary signi(cid:128)cantly from system to system. It is already
challenging to diagnose a problem using unstructured logs even
a(cid:137)er knowing an error has occurred [43]; online anomaly detection
from massive log data is even more challenging. Some existing
methods use rule-based approaches to address this issue, which
requires speci(cid:128)c domain knowledge [41], e.g., using features like
“IP address” to parse a log. However, this does not work for general
purpose anomaly detection where it is almost impossible to know
a priori what are interesting features in di(cid:130)erent types of logs (and
to guard against di(cid:130)erent types of a(cid:138)acks).
Anomaly detection has to be timely in order to be useful so that
users can intervene in an ongoing a(cid:138)ack or a system performance
issue [10]. Decisions are to be made in streaming fashion. As
a result, o(cid:132)ine methods that need to make several passes over
the entire log data are not applicable in our se(cid:138)ing [22, 39]. We
would also like to be able to detect unknown types of anomalies,
rather than gearing towards speci(cid:128)c types of anomalies. (cid:140)erefore,
previous work [44] that use both normal and abnormal (for speci(cid:128)c
types of anomalies) log data entries to train a binary classi(cid:128)er for
anomaly detection is not useful in this context.
Another challenge comes from concurrency. Clearly, the or-
der of log messages in a log provides important information for
diagnosis and analysis (e.g., identify the execution path of a pro-
gram). However, in many system logs, log messages are produced
by several di(cid:130)erent threads or concurrently running tasks. Such
concurrency makes it hard to apply work(cid:131)ow based anomaly de-
tection methods [42] which use a work(cid:131)ow model for a single task
as a generative model to match against a sequence of log messages.
Lastly, each log message contains rich information such as a log
key and one or more metric values, as well as its timestamp. A
holistic approach that integrates and utilizes these di(cid:130)erent pieces
of information will be more e(cid:130)ective. Most existing methods [22,
32, 39, 41, 42, 44] analyze only one speci(cid:128)c part of a log message
(e.g., the log key) which limits the types of anomalies they can
detect.
Our contribution. A Recurrent Neural Network (RNN) is an arti-
(cid:128)cial neural network that uses a loop to forward the output of last
state to current input, thus keeping track of history for making pre-
dictions. Long Short-Term Memory (LSTM) networks [13, 18, 27]
are an instance of RNNs that have the ability to remember long-term
dependencies over sequences. LSTMs have demonstrated success
in various tasks such as machine translation [35], sentiment analy-
sis [8], and medical self-diagnosis [20].
Inspired by the observation that entries in a system log are a
sequence of events produced by the execution of structured source
code (and hence can be viewed as a structured language), we design
the DeepLog framework using a LSTM neural network for online
anomaly detection over system logs. DeepLog uses not only log
keys but also metric values in a log entry for anomaly detection,
hence, it is able to capture di(cid:130)erent types of anomalies. DeepLog
only depends on a small training data set that consists of a sequence
of “normal log entries”. A(cid:137)er the training phase, DeepLog can
recognize normal log sequences and can be used for online anomaly
detection over incoming log entries in a streaming fashion.
Intuitively, DeepLog implicitly captures the potentially non-
linear and high dimensional dependencies among log entries from
the training data that correspond to normal system execution paths.
To help users diagnose a problem once an anomaly is identi(cid:128)ed,
DeepLog also builds work(cid:131)ow models from log entries during its
training phase. DeepLog separates log entries produced by concur-
rent tasks or threads into di(cid:130)erent sequences so that a work(cid:131)ow
model can be constructed for each separate task.
Our evaluation shows that on a large HDFS log dataset explored
by previous work [22, 39], trained on only a very small fraction
(less than 1%) of log entries corresponding to normal system exe-
cution, DeepLog can achieve almost 100% detection accuracy on
the remaining 99% of log entries. Results from a large OpenStack
log convey a similar trend. Furthermore, DeepLog also provides
the ability to incrementally update its weights during the detec-
tion phase by incorporating live user feedback. More speci(cid:128)cally,
DeepLog provides a mechanism for user feedback if a normal log
entry is incorrectly classi(cid:128)ed as an anomaly. DeepLog can then use
such feedback to adjust its weights dynamically online over time
to adapt itself to new system execution (hence, new log) pa(cid:138)erns.
2 PRELIMINARIES
2.1 Log parser
We (cid:128)rst parse unstructured, free-text log entries into a structured
representation, so that we can learn a sequential model over this
structured data. As shown by several prior work [9, 22, 39, 42, 45],
an e(cid:130)ective methodology is to extract a “log key” (also known as
“message type”) from each log entry. (cid:140)e log key of a log entry e
refers to the string constant k from the print statement in the source
code which printed e during the execution of that code. For example,
the log key k for log entry e =“Took 10 seconds to build instance.” is
k =Took * seconds to build instance., which is the string constant from
the print statement printf(”Took %f seconds to build instance.”, t). Note
that the parameter(s) are abstracted as asterisk(s) in a log key. (cid:140)ese
metric values re(cid:131)ect the underlying system state and performance
status. Values of certain parameters may serve as identi(cid:128)ers for
a particular execution sequence, such as block_id in a HDFS log
and instance_id in an OpenStack log. (cid:140)ese identi(cid:128)ers can group
log entries together or untangle log entries produced by concurrent
processes to separate, single-thread sequential sequences [22, 39,
42, 45]. (cid:140)e state-of-the-art log parsing method is represented by
Spell [9], an unsupervised streaming parser that parses incoming
log entries in an online fashion based on the idea of LCS (longest
common subsequence).
Past work on log analysis [22, 39, 42, 44] have discarded times-
tamp and/or parameter values in a log entry, and only used log keys
to detect anomalies. DeepLog stores parameter values for each log
entry e, as well as the time elapsed between e and its predecessor,
into a vector −→
v e. (cid:140)is vector is used by DeepLog in addition to
the log key. An example is given in Table 1, which shows the pars-
ing results for a sequence of log entries from multiple rounds of
execution of virtual machine (VM) deletion task in OpenStack.
2.2 DeepLog architecture and overview
(cid:140)e architecture of DeepLog is shown in Figure 1 with three main
components: the log key anomaly detection model, the parame-
ter value anomaly detection model, and the work(cid:131)ow model to
diagnose detected anomalies.
Training stage. Training data for DeepLog are log entries from
normal system execution path. Each log entry is parsed to a log key
and a parameter value vector. (cid:140)e log key sequence parsed from a
training log (cid:128)le is used by DeepLog to train a log key anomaly de-
tection model, and to construct system execution work(cid:131)ow models
for diagnosis purposes. For each distinct key k, DeepLog also trains
and maintains a model for detecting system performance anomalies
as re(cid:131)ected by these metric values, trained by the parameter value
vector sequence of k.
Detection stage. A newly arrived log entry is parsed into a log
key and a parameter value vector. DeepLog (cid:128)rst uses the log key
log key
log message (log key underlined)
t1 Deletion of (cid:128)le1 complete
k1
t2 Took 0.61 seconds to deallocate network … k2
t3 VM Stopped (Lifecycle Event)
k3
…
…
parameter value vector
[t1 − t0, (cid:128)le1Id]
[t2 − t1, 0.61]
[t3 − t2]
…
Table 1: Log entries from OpenStack VM deletion task.
Figure 1: DeepLog architecture.
anomaly detection model to check whether the incoming log key is
normal. If yes, DeepLog further checks the parameter value vector
using the parameter value anomaly detection model for that log key.
(cid:140)e new entry will be labeled as an anomaly if either its log key or
its parameter value vector is predicted being abnormal. Lastly, if
it is labeled being abnormal, DeepLog’s work(cid:131)ow model provides
semantic information for users to diagnose the anomaly. Execution
pa(cid:138)erns may change over time or were not included in the original
training data. DeepLog also provides the option for collecting user
feedback. If the user reports a detected anomaly as false positive,
DeepLog could use it as a labeled record to incrementally update
its models to incorporate and adapt to the new pa(cid:138)ern.