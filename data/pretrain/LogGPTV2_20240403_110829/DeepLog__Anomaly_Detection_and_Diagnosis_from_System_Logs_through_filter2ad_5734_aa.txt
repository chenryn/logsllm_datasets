# DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning

**Authors:** Min Du, Feifei Li, Guineng Zheng, Vivek Srikumar  
**Affiliation:** School of Computing, University of Utah  
**Emails:** {mind, lifeifei, guineng, svivek}@cs.utah.edu

## Abstract
Anomaly detection is a critical step in building secure and trustworthy systems. System logs are primarily used to record system states and significant events at various critical points, aiding in the debugging of system failures and root cause analysis. Log data, which is universally available in almost all computer systems, is an essential resource for understanding system status and performance issues. Therefore, system logs are a natural source of information for online monitoring and anomaly detection.

We propose DeepLog, a deep neural network model that uses Long Short-Term Memory (LSTM) to model system logs as natural language sequences. This allows DeepLog to automatically learn log patterns from normal execution and detect anomalies when log patterns deviate from the model trained on normal log data. Additionally, we demonstrate how to incrementally update the DeepLog model in an online fashion, enabling it to adapt to new log patterns over time. Furthermore, DeepLog constructs workflows from the underlying system logs, allowing users to diagnose detected anomalies and perform effective root cause analysis. Extensive experimental evaluations on large log datasets have shown that DeepLog outperforms existing log-based anomaly detection methods based on traditional data mining methodologies.

## CCS Concepts
- **Information Systems → Online Analytical Processing**
- **Security and Privacy → Intrusion/Anomaly Detection and Malware Mitigation**

## Keywords
- Anomaly detection
- Deep learning
- Log data analysis

## 1. Introduction
Anomaly detection is essential for building secure and trustworthy computer systems. As systems and applications become increasingly complex, they are more susceptible to bugs and vulnerabilities that adversaries can exploit. These attacks are also becoming more sophisticated, making anomaly detection more challenging. Many traditional anomaly detection methods based on standard data mining techniques are no longer effective.

System logs record system states and significant events at various critical points, helping to debug performance issues and failures, and perform root cause analysis. Such log data is universally available in nearly all computer systems and is a valuable resource for understanding system status. Since system logs record noteworthy events from actively running processes, they are an excellent source of information for online monitoring and anomaly detection.

Existing approaches that leverage system log data for anomaly detection can be broadly classified into three groups:
1. PCA-based approaches over log message counters [39]
2. Invariant mining methods to capture co-occurrence patterns between different log keys [21]
3. Workflow-based methods to identify execution anomalies in program logic flows [42]

While these methods are successful in certain scenarios, none of them is effective as a universal anomaly detection method capable of guarding against different types of attacks in an online fashion.

This work proposes DeepLog, a data-driven approach for anomaly detection that leverages large volumes of system logs. The key intuition behind DeepLog is inspired by natural language processing: we view log entries as elements of a sequence that follow certain patterns and grammar rules. A system log is produced by a program that follows a rigorous set of logic and control flows, much like a natural language (though more structured and restricted in vocabulary). To this end, DeepLog is a deep neural network that models the sequence of log entries using LSTM. This allows DeepLog to automatically learn a model of log patterns from normal execution and flag deviations from normal system execution as anomalies. Since it is a learning-driven approach, it is possible to incrementally update the DeepLog model to adapt to new log patterns that emerge over time.

### Challenges
- **Unstructured Data:** Log data is unstructured, and its format and semantics can vary significantly from system to system. Diagnosing problems using unstructured logs is already challenging, and online anomaly detection from massive log data is even more so.
- **Timeliness:** Anomaly detection must be timely to allow users to intervene in ongoing attacks or system performance issues. Offline methods that require multiple passes over the entire log data are not applicable.
- **Unknown Anomalies:** We aim to detect unknown types of anomalies rather than specific types. Previous work that uses both normal and abnormal log data entries to train a binary classifier is not useful in this context.
- **Concurrency:** Log messages are often produced by several different threads or concurrently running tasks, making it hard to apply workflow-based anomaly detection methods.
- **Holistic Approach:** Each log message contains rich information such as a log key, metric values, and timestamps. A holistic approach that integrates and utilizes these different pieces of information will be more effective.

### Our Contribution
A Recurrent Neural Network (RNN) is an artificial neural network that uses a loop to forward the output of the last state to the current input, thus keeping track of history for making predictions. Long Short-Term Memory (LSTM) networks are a type of RNN that can remember long-term dependencies over sequences. LSTMs have demonstrated success in various tasks such as machine translation, sentiment analysis, and medical self-diagnosis.

Inspired by the observation that entries in a system log are a sequence of events produced by the execution of structured source code, we design the DeepLog framework using an LSTM neural network for online anomaly detection over system logs. DeepLog uses not only log keys but also metric values in a log entry for anomaly detection, enabling it to capture different types of anomalies. DeepLog depends on a small training dataset consisting of a sequence of "normal log entries." After the training phase, DeepLog can recognize normal log sequences and can be used for online anomaly detection over incoming log entries in a streaming fashion.

Intuitively, DeepLog implicitly captures the potentially nonlinear and high-dimensional dependencies among log entries from the training data that correspond to normal system execution paths. To help users diagnose a problem once an anomaly is identified, DeepLog also builds workflow models from log entries during its training phase. DeepLog separates log entries produced by concurrent tasks or threads into different sequences so that a workflow model can be constructed for each separate task.

Our evaluation shows that on a large HDFS log dataset, trained on only a very small fraction (less than 1%) of log entries corresponding to normal system execution, DeepLog can achieve almost 100% detection accuracy on the remaining 99% of log entries. Results from a large OpenStack log convey a similar trend. Furthermore, DeepLog provides the ability to incrementally update its weights during the detection phase by incorporating live user feedback. Specifically, DeepLog provides a mechanism for user feedback if a normal log entry is incorrectly classified as an anomaly. DeepLog can then use such feedback to adjust its weights dynamically online over time to adapt itself to new system execution (hence, new log) patterns.

## 2. Preliminaries

### 2.1 Log Parser
We first parse unstructured, free-text log entries into a structured representation to learn a sequential model over this structured data. Prior work has shown that an effective methodology is to extract a "log key" (also known as "message type") from each log entry. The log key of a log entry refers to the string constant from the print statement in the source code that printed the entry during execution. For example, the log key for the log entry "Took 10 seconds to build instance." is "Took * seconds to build instance.", where the parameter(s) are abstracted as asterisk(s). These metric values reflect the underlying system state and performance status. Certain parameters may serve as identifiers for a particular execution sequence, such as `block_id` in an HDFS log and `instance_id` in an OpenStack log. These identifiers can group log entries together or untangle log entries produced by concurrent processes into single-thread sequential sequences. The state-of-the-art log parsing method is represented by Spell, an unsupervised streaming parser that parses incoming log entries in an online fashion based on the idea of LCS (longest common subsequence).

Past work on log analysis has discarded timestamps and/or parameter values in a log entry, using only log keys to detect anomalies. DeepLog stores parameter values for each log entry, as well as the time elapsed between the entry and its predecessor, into a vector. This vector is used by DeepLog in addition to the log key. Table 1 shows the parsing results for a sequence of log entries from multiple rounds of execution of a virtual machine (VM) deletion task in OpenStack.

| Log Key | Log Message (Log Key Underlined) | Parameter Value Vector |
|---------|----------------------------------|------------------------|
| k1      | Deletion of file1 complete        | [t1 - t0, file1Id]     |
| k2      | Took 0.61 seconds to deallocate network... | [t2 - t1, 0.61] |
| k3      | VM Stopped (Lifecycle Event)      | [t3 - t2]              |

### 2.2 DeepLog Architecture and Overview
The architecture of DeepLog, shown in Figure 1, consists of three main components:
1. **Log Key Anomaly Detection Model:** Detects anomalies in the log keys.
2. **Parameter Value Anomaly Detection Model:** Detects anomalies in the parameter values.
3. **Workflow Model:** Provides semantic information for diagnosing detected anomalies.

#### Training Stage
Training data for DeepLog are log entries from normal system execution paths. Each log entry is parsed into a log key and a parameter value vector. The log key sequence parsed from a training log file is used to train a log key anomaly detection model and to construct system execution workflow models for diagnosis purposes. For each distinct log key, DeepLog also trains and maintains a model for detecting system performance anomalies, using the parameter value vector sequence of that key.

#### Detection Stage
A newly arrived log entry is parsed into a log key and a parameter value vector. DeepLog first uses the log key anomaly detection model to check whether the incoming log key is normal. If it is, DeepLog further checks the parameter value vector using the parameter value anomaly detection model for that log key. The new entry will be labeled as an anomaly if either its log key or its parameter value vector is predicted to be abnormal. If it is labeled as an anomaly, DeepLog’s workflow model provides semantic information for users to diagnose the anomaly. Execution patterns may change over time or were not included in the original training data. DeepLog also provides the option for collecting user feedback. If the user reports a detected anomaly as a false positive, DeepLog can use it as a labeled record to incrementally update its models to incorporate and adapt to the new pattern.

![DeepLog Architecture](figure1.png)

---

This optimized version of the text is more coherent, professional, and clearly structured, making it easier to understand and follow.