to A without blank entries. Until now, we have scored all attribute
relationships while the Attribute Graph ¯G can be reconstructed with
all attribute relationships.
4.4 Scoring Attributes using PageRank
Now we quantify each attribute’s score by using the attribute rela-
tionship scores. Our solution is based on the PageRank algorithm,
which has been implemented by Google to analyze the link rela-
tionships and rank hyperlinks using numerical values. It has the
property of ranking the important website with a higher value
while ranking a less important website with a lower value. This
property can be customized in our design to offer the attributes that
have different potentials of attracting spammer’s interest with various
scores. In particular, if an attribute has more potentials of attracting
spammer’s interest, it will be assigned with a higher value while
another attribute that has fewer potentials will be assigned with a
lower value. Here, we customize the PageRank algorithm into our
design and leverage it as the underlying algorithm to rank the at-
tributes in the Attribute Graph based on the attribute relationships.
To employ PageRank, we require to have an irreducible matrix.
The method proposed in [15] can be leveraged here to transform
the P into an irreducible matrix ˆP. That is, if there exists some rows
having all entries with zero in P, we use the uniform vector 1
eT
Na
to replace each of these rows to get a new matrix ¯P, where e is an
Na × 1 vector with all ones and Na is the total number of attributes,
respectively. Next, we transform ¯P into an irreducible matrix ˆP as
follows:
ˆP = κ ¯P + (1 − κ) eeT
Na
.
where κ is a parameter to adjust stochastic perturbation and is set
to be 0.85 as suggested in [15].
With the irreducible matrix ˆP, we can leverage the PageRank
algorithm to calculate the scores of all attributes, which are denoted
by an 1×Na vector π. The vector π is initialized as π(0) = 1
eT and
Na
the Power Iteration Method [1] is employed to iteratively update
this vector until it is converged. That is, we iteratively calculate
π(i +1) by following:
(5)
where π(i +1) will be normalized by π(i +1)e = 1 in each iteration.
Once Eqn. (5) is converged, each entry of final converged vector π is
the rank of an attribute. In our context, the rank is also considered
as the attribute’s score. Such final PageRank vector is the same as
(i) ˆP = π
(i +1)
π
,
Figure 4: Illustration of random walk method on directed
Activity graph. The selection of next node depends on the
structure of both previous node (i.e., P) and current node (i.e.,
C).
dominant left eigenvector of matrix ˆP. Note here, the convergence
speed of this method depends on the subdominant eigenvalue which
is between 0 and 1. It typically takes no more than 100 iterations.
(cid:40)

4.5 Scoring Tweets
After we quantified each attribute using a score, we can map the
score on the tweet to reflect its association to a user’s behaviors.
Here, we evaluate each tweet from most relevant user’s attributes
instead of only the one that posts this tweet, since the neighbor’s
behaviors are important factors to reflect a tweet’s attribute. The
Random Walk method is employed here to find the most relevant
users by walking l steps. We can use their attribute scores to repre-
sent each tweet as an evaluation vector. Such a vector of attribute
scores can reflect the trend of a tweet is spam or not to some extent.
We start from the users that are posting this tweet and perform
l steps on Activity Graph G to find the most relevant users. The
challenge here is how to decide which way to go at each step. We
define Pi, j as the probability of selecting the next node j from a
node i as follows:
(6)
ϕi, j
X ∈Nr (i)(ϕ(i, j)) ,
k + 1  q > z > r, to
represent the level of activity relationships of each type of link with
its neighbor 1. Notably, this graph traversal strategy can balance
the extreme search strategies of Depth-first Search and Breadth-first
Search.
After performing the Random Walk, we obtain a path for each
tweet starting from the user that posts it and ending at a destination
node. For a tweet, we assume the start and end users are i and k,
respectively. We use the attribute scores of users i and k to score this
tweet. We define an 1 by 2∗ Nb vector Sw to represent the scores of
each attribute associated to users i and k,where Nb represents the
attributes extracted from user i. Note here the column indicates the
attributes, not the attribute intervals. For user i or k, its attribute
values may fall into a specific interval, so we take the score of this
attribute interval as its attribute score. Then entries of Sw can be
calculated as follows:
S[j] =
ij + kj
,
2
S[Nb + j] = ij − kj ,
(8)
(9)
for columns j (j ≤ Nb) and Nb + j, respectively.
which reflects the rich information of the associated behaviors.
As a result, each tweet can be represented by a vector of scores,
4.6 Scoring Users’ Dependence Relationships
In addition to score attribute relationships, the random walk paths
are used to evaluate the user relationships in a network. For each
user ui, we define a high-dimensional vector variable vi ∈ RN to
represent its activities, where all elements in vector vi are indepen-
dent to each other. Such a vector is simply a mapping from a user
into a dense vector in RN . The advantage of such expansion is that
the high-dimensional vector can represent more fine-grained and
affluent features than a single value of a user [3]. We then quantify
a user’s activities with other users using a conditional probability
model. That is, the probability (denoted as p(uj|ui)) of a user ui has
some activities with another user uj can be defined as follows:
.
evjvi
k ∈U evkvi
p(uj|ui) =
(10)
The goal here is to find the optimal value v of all users that can
reflect neighboring users’ activities. Thus, we study the optimiza-
tion problem with the objective of maximizing the probability of
all users activating with their neighbors. Here, the neighboring
users represent the Random Walk results of each user in the activity
graph. Then, this problem can be formulated as follows:

log Pr(Nд(u)|u) ,
u∈U
(11)
where Nд(u) represents the set of neighborhoods (the users in the
random walk path from Section 4.5) for a user u, and Pr repre-
sents the conditional probability for a user u activating with her
1The optimal values of p, q, z and r can be identified through experimental test. Due
to the space limitation, we omit its discussion here to conserve space.
max
u∈U
max
= max
= max
= max
u∈U
u∈U
u∈U
log Pr(Nд(u)|u)
uj ∈Nд(u)
log 


uj ∈Nд(u)
uj ∈Nд(u)
p(uj|u)
log evjv − 
vjv − 
log
log 
uj ∈Nд(u)
k ∈U
uj ∈Nд(u)
uk ∈U
evkv
evkv
(13)
neighborhoods. As all elements in the high dimensional vector are
independent to each other, we have:
Pr(Nд(u)|u) = 
uj ∈Nд(u)
p(uj|u) .
(12)
Put Equations (10), (11), and (12) together, we have:

Note here, v, vj and vk are the high dimensional vectors of u, uj,
and uk, respectively.
From Eqn. (13), we see the objective can be understood as maxi-
mizing the likelihoods of all users activating with their neighbor-
hoods (first term in the right hand) while minimizing the likelihoods
of users activating with their non-neighboring users (second term
in the right hand) at the same time. Thus, Eqn (13) can be approxi-
mated and simplified by removing the in the second term, i.e.,
vkv − log 
OPT max
It is extremely expensive to solve the above optimization prob-
lem for a large sized network as we need to consider all users in
the networks. Since the neighboring users take a small portion
while non-neighboring users take a large portion, we can employ
the Negative sampling [21] by just identifying a small Negative
sample set from a user µ’s non-neighboring users. Denote Ns(µ)
as the selected Negative sample set for a user µ, then OPT can be
reformulated into the following approximate expression.
uk ∈Nд(u)
uk ∈U
evkv
u∈U
(14)
max

vkv − log 
u∈U
uk ∈Nд(u)
uk ∈Ns(u)
This optimization problem can be solved by using the Stochastic
Gradient Ascend method [23]. Then, we can obtain the optimal
solutions of the dependence relationship vectors v for all users.
4.7 Neural Network Model
Till now, we obtain the score of each tweet Sw, its sender’s depen-
dent relationship vector vs, and its receiver’s dependent feature
vector vr . These values represent a tweet’s characteristics and can
be consolidated to a new tweet score vector S.
S = concatenate(Sw, vs , vr)
(16)
These three entries provide affluent information to reflect both
users’ and attributes’ relationships associated to a tweet. After we
obtain the consolidated tweet score vectors of all tweets, we can
use a small set of collected data in D as the training dataset and
evkv
(15)
Session 5A: Web SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand385Table 1: The number of neurons at each layer in Neural Net-
work model.
Layer Type
Input
Fully Connected +ReLU