title:Analyzing and Modeling Longitudinal Security Data: Promise and Pitfalls
author:Benjamin Edwards and
Steven A. Hofmeyr and
Stephanie Forrest and
Michel van Eeten
Analyzing and Modeling Longitudinal Security Data:
Promise and Pitfalls
Benjamin Edwards
University of New Mexico
PI:EMAIL
Stephanie Forrest
University of New Mexico
PI:EMAIL
Santa Fe Institute
Steven Hofmeyr
Lawrence Berkeley National
Delft University of Technology
PI:EMAIL
Laboratory
PI:EMAIL
Michel van Eeten
ABSTRACT
Many cybersecurity problems occur on a worldwide scale, but we
lack rigorous methods for determining how best to intervene and
mitigate damage globally, both short- and long-term. Analysis of
longitudinal security data can provide insight into the effectiveness
and differential impacts of security interventions on a global level.
In this paper we consider the example of spam, studying a large
high-resolution data set of messages sent from 260 ISPs in 60
countries over the course of a decade. The statistical analysis is
designed to avoid common pitfalls that could lead to erroneous
conclusions. We show how factors such as geography, national
economics, Internet connectivity and traffic flow impact can affect
local spam concentrations. Additionally, we present a statistical
model to study temporal transitions in the dataset, and we use a
simple extension of the model to investigate the effect of historical
botnet takedowns on spam levels. We find that in aggregate most
historical takedowns are beneficial in the short-term, but few have
long-term impact. Further, even when takedowns are effective
globally, they can be detrimental in specific geographic regions or
countries. The analysis and modeling described here are based on
a single data set. However, the techniques are general and could
be adapted to other data sets to help improve decision making
about when and how to deploy security interventions.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Sys-
tems]: Security and Protection
Keywords
Spam, takedowns, statistical model
1.
INTRODUCTION
Many cybersecurity problems occur at a global scale, involving
nations, corporations, or individuals whose actions have impact
around the world. Despite these global, persistent problems,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed for
profit or commercial advantage and that copies bear this notice and the full citation on
the first page. Copyrights for components of this work owned by others than the author(s)
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Request permissions from permissions@acm.org.
ACSAC ’15, December 07 - 11, 2015, Los Angeles, CA, USA
c(cid:13) 2015 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN
978-1-4503-3682-6/15/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2818000.2818010
there is limited research on the actual effectiveness of the many
interventions that have been proposed. Most interventions are
based on deep, hands-on experience with specific attacks, and
are never evaluated systematically at a large scale. For example,
there has been little quantitative analysis of the sustained effect
of the many botnet takedowns that occurred over the past decade.
Simple qualitative observation of declines in malicious activity
following a takedown is not sufficient to determine whether the
takedown is effective or causal [19, 31, 33]. Attributing cause is
always problematic, but it is especially difficult when empirical
datasets have high variance as is often the case in security[13,
15]. Moreover, as the scope of cyber-insecurity has increased,
no one security practitioner is able to grasp all of the relevant
details associated with global problems [17]. Thus, there is a
need for more explicit and rigorous methods to determine which
interventions are effective and which are are not.
In this paper, we explore some of the opportunities and im-
pediments to analyzing longitudinal security data, by focusing
on the concrete example of spam, developing statistical models to
describe a large dataset, and using the model to assess the effect
of certain interventions. We ask whether a particular intervention
has a temporary or sustained impact and how interventions play
out geographically. A potential pitfall in longitudinal datasets,
including our dataset, is high variance, and we use careful statis-
tical methods to separate significant effects from noise. A second
issue is the retrospective nature of data-driven analyses, which
makes predicting the future a challenge. Because intervention
methods are often re-used, however, we believe that studying the
existing examples, e.g., a historical botnet takedown, can provide
insight about the likely effect of similar future interventions.
We illustrate our approach by analyzing a spam dataset, com-
prising more than 127 billion spam messages sent from over
440 million unique IP addresses, spread across 260 ISPs in 60
countries. Spam is a global problem, and countermeasures have
never eliminated it completely. Spam plays a key role in the
cyber-crime ecosystem as a vector for various activities such as
stealing login credentials through phishing, distributing malware,
making fraudulent sales, or selling illegal goods [37]. Spam can
be viewed as a proxy for estimating the numbers of infected PCs
and the extent of botnets [83, 70, 26].
To compare spam levels across countries, we study a quantity
called wickedness [25], which can be thought of as the concen-
tration of infected machines sending out spam, either in a single
Internet Service Provider (ISP) or in a geographic region. This
measure allows us to compare spam levels among different coun-
tries or different ISPs, identify how different factors contribute
to the concentration of spam sending computers, and assess what
effect interventions have across the globe.
Analysis of the data shows that spam concentrations are rela-
tively stable for ISPs from one week to the next but are punctuated
by spikes that often span several orders of magnitude. These
spikes can mask the effect of interventions. Further analysis also
reveals that: (1) Gross Domestic Product (GDP) per capita is neg-
atively correlated with wickedness, with less developed countries
experiencing higher levels; (2) an ISP’s wickedness is correlated
with that of surrounding ISPs, suggesting that there are regional
influences; and (3) an ISP’s network connectivity is correlated
with wickedness.
To further understand the impact of ISP connectivity on spam,
we construct an ISP graph that represents how ISPs are con-
nected to each other. The graph reveals that ISPs with high graph
centrality have lower wickedness, while those on the periphery
suffer higher rates of infection. Adding a simple model of spam
dynamics to the ISP graph shows that spam concentrations at
an ISP are influenced by previous levels, suggesting that spam
could is one driver in spreading infections across the Internet.
In the last decade, a number of approaches have been suggested
and implemented to help fight spam. Of these, the most famous
is the botnet takedown. But, email providers have also adopted
adaptive IP black lists [21], banks have restricted access to credit
card payment processors [29], resources have been devoted to
arresting and prosecuting cyber-criminals [51, 36, 1], and users of
infected computers have been offered free cleanup tools [4]. Some
of these interventions seem to have led to declining spam levels,
e.g., real-time filtering and credit card interventions [71, 50, 29, 68].
We show how modeling can help identify when particular in-
terventions likely began affecting spam concentrations. The best
model of our dataset identifies three distinct time periods or eras,
each corresponding to different dynamics. These eras correlate
roughly with the introduction of new intervention strategies, and
they give some idea of the overall impact of a particular strategy.
When the exact date of an intervention is known (as in the case
of botnet takedowns), we can use the model to analyze its impact
more precisely, both globally and regionally. Model analysis con-
firms the hypothesis that most botnet takedowns are effective only
in the short-term, with spam levels rebounding in the weeks after a
takedown [39]. However, we also find that a few of the takedowns
were globally effective in the long term. A closer look at their re-
gional impact, however, shows that effects vary dramatically across
different geographic areas and individual countries. Takedowns
that are successful globally can be detrimental in specific countries.
Our work uses one particular dataset to illustrate how robust
statistical techniques can be applied to study spam trends and the
effect of interventions—globally, regionally, and by individual coun-
try. Because we studied data taken from a single data source, and
focused only on email spam, our conclusions are only as good as the
data—a pitfall of any statistical analysis. The methods, however,
could readily be applied to other sources of spam and even other
security data, as they become avaiable. Additional datasets would
certainly improve our confidence in the conclusions of the analysis,
and section 2 discusses the idiosyncrasies of our particular dataset.
In summary, statistical analysis of global longitudinal data is
a promising approach to understanding the security landscape.
This paper makes the following contributions:
1. It presents a robust statistical analysis of longitudinal, global
security data, showing how to analyze high variance time se-
ries, identify correlations with external factors, and identify
the effects of interventions, both when the deployment date
is unknown (filters) and when it is known exactly (botnets).
2. It identifies statistically significant correlations between
spam concentrations and various risk factors, including
GDP, nearby spam concentrations, and ISP connectivity
in the ISP graph. Traffic dynamics on this graph influence
future wickedness, suggesting that spam is used to spread
malware infections.
3. Identification of three statistically distinct eras within the
ten-year data set. Although spam levels are highly variable
in all eras, the overall concentration of spam declines during
the last two eras. These declines may be related to historical
events that are outside the scope of our study, and they
may have caused discernible shifts in the data.
4. Analysis of the global impact of historical botnet takedowns:
only a few of the studied takedowns had lasting impact,
while most had only a transient effect, in all eras.
5. Geographic impacts of takedowns. We find that even when
a takedown is effective globally, it often results in an increase
in wickedness in particular regions or countries.
2. COLLECTING AND MAPPING SPAM DATA
TO WICKEDNESS
In this section we describe our dataset, and the wickedness
metric. We show that wickedness has interesting statistical
properties, and identify significant changes in wickedness over time.
2.1 Spam Data
Our spam dataset is based on that used by Van Eeten et al. [73]
but greatly expanded. We collected additional data, doubling the
timespan covered, and studied the data on a weekly basis. The
original study examined spam trends only on a quarterly basis.
This dataset was collected from a spam trap—an Internet domain
designed specifically to capture spam with e-mail addresses that
have never been published or used to send or receive legitimate
email. Spam traps have been used successfully to identify malware
infected hosts, and to measure the extent of botnets, because
botnets often send spam [83, 70, 26]. Over the past decade, our
spam trap received more than 127 billion spam messages, sent
from 440 million unique IP addresses.
In order to make comparisons among different ISPs and ge-
ographic regions, the ISP which owns each IP address and the
country in which that ISP operates must be identified. To do
this we used the following procedure:
1. Each IP address was linked to an ASN (Autonomous System
number) using historical BGP data.
2. Each ASN was then manually linked an administrating
entity using historical WHOIS records.
3. Industry reports and news media were consulted to connect
the administrating entities to the main ISPs in 60 countries,
as identified in Telegeography’s GlobalComms database.
The database also provides us with accurate subscriber
numbers for each ISP.
4. Each (part of an) ASN was mapped onto a country using
MaxMind’s GeoIP database [47].
The manual mapping of ASNs to ISPs prevented us from iden-
tifying all possible ISPs which sent spam to our trap. However,
we were able to map 659 ASNs to 260 ISPs in 60 countries. These
ISPs account for over 80% of the major broadband markets in
those countries. These countries also compose the entirety of the
Organisation for Economic Co-operate and Development(OECD)
and European Union, along with several other major spam sending
nations.
This procedure produced two time series for each ISP: a count
spam messages and the number of unique IP addresses that sent
spam per day. Some ISPs provide dynamic IP addresses with
short lease times to their customers. This could potentially cause
a single spam-emitting host to be associated with multiple IP
addresses over short periods. To help correct for this potential
source of overcounting, we use average daily counts of IP addresses
over the course of a week to obtain an estimate of the number of
(a)
(b)
Figure 1: Two views of global spam. (a) uses a logged vertical axis to show the high variance in the spam data. The black points
indicate global wickedness, and the shaded area shows the range of values for individual ISPs. (b) uses a linear vertical axis to show
the qualitative changes in wickedness between different eras.
infected machines associated with an ISP in a given week. This
produces slightly coarser granularity data but removes some of
the churn caused by dynamic addresses.
Our data was collected from a single spam trap and is only
a sample of all the spam sent globally, and it is possible that
our data is only capturing the activity of a few unsophisticated
spam gangs. It is difficult to exactly compare our data to other
publicly available spam reports because most reports rely on
relative measures such as fraction of total email that was classified
as spam or percentages relative to a peak. However we were
able to make some qualitative comparisons to other sources. A
subset of the data from 2006 and 2009 was previously found to
correspond with industry reports, both in terms of spam volume
trends and geographical distribution of sources [73].
Comparing post 2010 trends to longitudinal data available
from Spamhaus [66], our data on global wickedness qualitatively
matches theirs until mid-2012. After that, however, Spamhaus
shows a brief rise in spam, though not to previous levels, while
our data show a continued downward trend (Figure 1). Symantec
reports a small overall decline in annual average spam in 2013 [69],
and Kaspersky also reported a small decline the percentage of
spam email compared to legitimate email in 2013 [23]. Our
data also shows declines in these two years. The discrepancies
between our data and Spamhaus likely reflect changes in tactics
of spammers over time that are not captured by our spam trap.
However, in this paper we emphasize the procedure used to analyze
the data over the exact conclusions drawn from the analysis, which
in future work could be verified by analyzing other datasets.
2.2 Estimating Wickedness From Spam Data
We calculate wickedness in terms of IP addresses sending spam.
The two time series establish the total number of spam sending
hosts within an ISP, but they do not account for the total number
of IP addresses actively used by each ISP (i.e. the number of cus-
tomers). We focus on wickedness rather than the absolute number
of spam sending hosts so that we can make valid comparisons be-
tween ISPs, countries, and regions in the world. We use data from
TeleGeography’s Globalcomm database to establish the number of
subscribers for each ISP. These data, available quarterly, allowed
us to compute the concentration of malicious hosts per customer
(the wickedness) and the number of spam messages sent per cus-
tomer.1 Using linear interpolation, we inferred the number of cus-
tomers each week to match the time granularity of the data for ma-
licious hosts. We calculate the wickedness of an ISP i at time t as:
Wi(t)=
Ai(t)
Ci(t)
.
(1)
where Ai(t) refers to the number of spam-sending IP addresses
and Ci(t) refers to the number of customers for ISP i at time
t. The global wickedness is defined over all ISPs, i.e. W (t) =
iCi(t). Figure 1 shows the global wickedness over
(cid:80)
iAi(t)/(cid:80)
time calculated from our dataset.
In these data, which capture a sample of the total population
of spam-emitting hosts worldwide, between 0.00091% and 0.33%
of hosts are sending spam at any given time. However, individual
ISP infection rates vary widely as shown by the shaded area in