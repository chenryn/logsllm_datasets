### Table II: AUC of LINKTELLER Compared to Two Baselines (LSA2-post, LSA2-attr)

Each column corresponds to one dataset. Groups of rows represent sampled nodes of different degrees.

| Degree | Method       | ENGB         | PPI          | PTBR         | Flickr       |
|--------|--------------|--------------|--------------|--------------|--------------|
| Low    | Ours         | 1.00 ± 0.00  | 0.58 ± 0.04  | 0.72 ± 0.03  | 1.00 ± 0.00  |
|        | LSA2-post    | 1.00 ± 0.00  | 0.58 ± 0.09  | 0.77 ± 0.08  | 1.00 ± 0.00  |
|        | LSA2-attr    | 1.00 ± 0.00  | 0.67 ± 0.06  | 0.82 ± 0.02  | 0.99 ± 0.00  |
| Unconstrained | Ours     | 1.00 ± 0.00  | 0.56 ± 0.02  | 0.62 ± 0.05  | 1.00 ± 0.00  |
|        | LSA2-post    | 1.00 ± 0.00  | 0.59 ± 0.01  | 0.74 ± 0.00  | 1.00 ± 0.00  |
|        | LSA2-attr    | 1.00 ± 0.00  | 0.70 ± 0.05  | 0.48 ± 0.08  | 1.00 ± 0.00  |
| High   | Ours         | 1.00 ± 0.00  | 0.65 ± 0.09  | 0.62 ± 0.14  | 1.00 ± 0.00  |
|        | LSA2-post    | 1.00 ± 0.00  | 0.70 ± 0.08  | 0.65 ± 0.09  | 0.97 ± 0.00  |
|        | LSA2-attr    | 1.00 ± 0.00  | 0.64 ± 0.00  | 0.48 ± 0.02  | 1.00 ± 0.00  |

### Table III: Attack Performance (Precision and Recall) of LINKTELLER on GAT

| \(\hat{k}\) | Method       | Precision                | Recall                   |
|-------------|--------------|--------------------------|--------------------------|
| \(k/4\)     | Ours         | 83.3 ± 23.6              | 26.1 ± 5.5               |
|             | LSA2-post    | 63.9 ± 10.4              | 38.3 ± 10.3              |
|             | LSA2-attr    | 51.0 ± 7.0               | 53.3 ± 4.7               |
| \(k/2\)     | Ours         | 63.9 ± 30.7              | 18.4 ± 9.0               |
|             | LSA2-post    | 60.0 ± 22.5              | 29.7 ± 11.7              |
|             | LSA2-attr    | 33.8 ± 13.3              | 32.1 ± 13.3              |
| \(k\)       | Ours         | 14.9 ± 3.8               | 3.8 ± 1.3                |
|             | LSA2-post    | 19.6 ± 2.8               | 9.9 ± 1.9                |
|             | LSA2-attr    | 18.2 ± 4.5               | 18.5 ± 6.1               |
| \(2k\)      | Ours         | 13.3 ± 1.7               | 26.8 ± 5.6               |
|             | LSA2-post    | 19.6 ± 2.8               | 9.9 ± 1.9                |
|             | LSA2-attr    | 18.2 ± 4.5               | 18.5 ± 6.1               |
| \(4k\)      | Ours         | 9.2 ± 0.8                | 37.3 ± 7.1               |
|             | LSA2-post    | 19.6 ± 2.8               | 9.9 ± 1.9                |
|             | LSA2-attr    | 18.2 ± 4.5               | 18.5 ± 6.1               |

### Observations and Discussion

When the estimated degree \(\hat{k}\) is larger (\(\hat{k} = 2k\)), almost all recall values are above 90% except for the Flickr dataset. Even under extremely inaccurate estimations such as \(\hat{k} = k/4\) or \(\hat{k} = 4k\), the precision values (or recall values) are mostly higher than 95%. This observation demonstrates the generality and robustness of LINKTELLER.

We notice that LINKTELLER's performance on the Flickr dataset is slightly poorer than on other datasets. This may be due to the highly sparse structure of the Flickr dataset, which results in the trained GCN not achieving good performance. Consequently, the parameters of the trained network on Flickr may not capture the graph structure very well, negatively influencing the attack performance.

### Beyond GCNs: LINKTELLER on GATs

In this section, we aim to study the effectiveness of LINKTELLER on other Graph Neural Networks (GNNs). Since the rule of information propagation holds almost ubiquitously in GNNs, we hypothesize that our influence analysis-based LINKTELLER can also successfully attack other types of GNNs. We directly apply Algorithm 1 on another classical model—Graph Attention Networks (GATs)—to investigate the transferability of our influence analysis-based attack from GCNs.

We evaluate the attack on the two large datasets, PPI and Flickr, introduced in Table IV. For both datasets, we train a 3-layer GAT. Details of the architecture and hyperparameters are provided in Appendix F6. The results are reported in Table III. Although LINKTELLER still significantly outperforms the baselines, it is less effective on GATs compared to GCNs. This is mainly due to the different structures of GCNs and GATs, which lead to different influence calculations (one related to graph convolution and the other to the attention mechanism). Further discussion on adapting LINKTELLER to other architectures is provided in Appendix E4.

### Evaluation of Differentially Private GCN

In this section, we aim to understand the capability of the LINKTELLER attack by experimenting with potential ways to defend against it. Specifically, we examine whether it is possible to weaken the effectiveness of LINKTELLER by ensuring the \(\epsilon\)-edge Differential Privacy (DP) guarantee of the GCN model. We further investigate the utility of the DP GCN models. In the end, we demonstrate the tradeoff between privacy and utility, which may be of interest to practitioners who wish to use DP GCNs to defend against LINKTELLER.

We aim to evaluate the attack effectiveness of LINKTELLER and the model utility on four types of models: DP GCN models derived using DP mechanisms EDGERAND.