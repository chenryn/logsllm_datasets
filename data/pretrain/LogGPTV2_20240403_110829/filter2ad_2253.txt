title:ALICE@home: Distributed Framework for Detecting Malicious Sites
author:Ikpeme Erete and
Vinod Yegneswaran and
Phillip A. Porras
ALICE@home: Distributed Framework for
Detecting Malicious Sites
Ikpeme Erete1, Vinod Yegneswaran2, and Phillip Porras3
1 Georgia Institute of Technology
PI:EMAIL
2 SRI International
PI:EMAIL
3 SRI International
PI:EMAIL
Abstract. Malware silently infects millions of systems every year
through drive-by downloads,
i.e., client-side exploits against web
browsers or browser helper objects that are triggered when unsuspecting
users visit a page containing malicious content. Identifying and blacklist-
ing websites that distribute malicious content or redirect to a distributing
page is an important part of our defense strategy against such attacks.
However, building such lists is fraught with challenges of scale, timeli-
ness and deception due to evasive strategies employed by adversaries. In
this work, we describe alice@home, a distributed approach to overcoming
these challenges and actively identifying malware distribution sites.
The growing prevalence of browser exploits and client-side attacks demands bet-
ter surveillance strategies to actively blacklist malicious sites and to detect new
and zero-day exploits. An approach that has been suggested is actively patrolling
the Internet for sites that surreptitiously install malicious software [6]. However,
scanning the Internet for miscreant sites is fraught with challenges of both scale
and evasion. First, modern search engines track over a trillion web links [4] and
using a virtual machine to assess the forensic impact of visiting each link requires
minutes of processing time. Second, adversaries use javascript obfuscators, IP
address tracking and website cloaking to evade patrolling systems. Third, most
search engines do not index javascript content and simply searching on exploit
features is insuﬃcient to discover malicious sites. To address these challenges,
we need to devise an intelligent and Internet-scale approach to the malicious site
discovery problem.
In this paper, we present the case for a distributed architecture alice@home for
tracking malicious websites. Much like, other @home projects [5], this distributed
approach utilizes the idle processing cycles of desktops to crawl the web for
infected sites. This enables alice@home to scale to tens of millions of pages
per day assuming 1000-node network and avoid IP-tracking strategies employed
by distribution sites. The incentive for participation in this network would be
tangible, i.e., the ability to receive a real-time feed of malicious sites to blacklist
from other paticipants.
E. Kirda, S. Jha, and D. Balzarotti (Eds.): RAID 2009, LNCS 5758, pp. 362–364, 2009.
c(cid:2) Springer-Verlag Berlin Heidelberg 2009
ALICE@home: Distributed Framework for Detecting Malicious Sites
363
1 ALICE: Virtual Honey-Client
A key component of alice@home is ALICE (A Low-Interaction Crawler and Em-
ulator), a drive-by download discovery and analysis tool that is lightweight, scal-
able, self-learning, easily deployable, precise, and resilient to evasion. Locating
malicious scripts embedded in a page is a challenging task due to complexities
such as redirects, obfuscation, multiple layers of frames and iframes, and self-
modifying script code. Static analysis of these scripts are diﬃcult since attackers
typically obfuscate scripts or use string operations to conceal script contents.
Therefore, we use dynamic analysis to generate and output execution traces
of the script. ALICE, strips away the need to have a forensic tool or a VM
running a vulnerable OS and browser by using a lightweight browser emulator
able to execute script in a safe way. Scripts typically manipulate the Document
Object Model (DOM) of a web page in a browser. Therefore, we emulate the
DOM hierarchy by implementing a light weight browser. This browser provides
the necessary support script functions, DOM hierarchal structure, safe execu-
tion environment and exposes the execution path of the script. Then we use
spidermonkey (Mozilla’s C implementation of a javascript engine) to execute all
javascripts. Our analysis engine post-processes the output of these scripts and
compares them with a dictionary of known exploits to decide malicious scripts.
Its lightweight design allows a single instance of ALICE to process over 12 URLs
per minute.
2 Preliminary Results
We are able to determine the malware distribution sites in the case of MDAC
vulnerabilities or the type of BHO vulnerabilities that is exploited by an attacker.
In the case of MDAC vulnerabilities, the location of malware distribution site
is often diﬀerent from the landing site, i.e., sites typically visited by users. To
evade detection, these distribution sites often incorporate techniques such as non-
determinism, IP tracking and fast ﬂux to rapidly change binding IP addresses
of domain names.
Processing rate. We evaluated the processing rate of ALICE relative to [2,6,1].
In the worst case ALICE is atleast 300% faster than Wang et al and in the best
case it is 17% faster than Moshchuk et al ’s approach with optimization. Un-
fortunately, the technique by [2] aﬀects the detection capability of their system
given that some of the steps used by distribution sites to evade detection. One
of the distinguishing features of ALICE versus PhoneyC [3], a similar virtual
honeyclient, is that PhoneyC takes an average of 2.1 hours to process URL.
Detection. In our initial testing of 35,000 urls, we detected 1294 drive-by down-
load sites. Our initial focus was on attacks that exploit MDAC vulnerabilities.
These sites linked to 33 unique distribution sites hosting malicious binaries. All
33 distribution sites infrequently infected a host by using IP tracking. Nonethe-
less, we were able to detect these sites.
364
I. Erete, V. Yegneswaran, and P. Porras
References
1. Moshchuk, A., Bragin, T., Deville, D., Gribble, S.D., Levy, H.M.: Spyproxy:
Execution-based detection of malicious web content. In: 16th USENIX Security
Symposium (August 2007)
2. Moshchuk, A., Bragin, T., Gribble, S.D., Levy, H.M.: A crawler-based study of spy-
ware on the web. In: Network and Distributed System Security Symposium (Febru-
ary 2006)
3. Nazario, J.: Phoneyc: A virtual client honeypot. In: 2nd USENIX Workshop on
Large-Scale and Emergent Threats, Boston, MA (April 2009)
4. Provos, N., Mavrommatis, P., Rajab, M.A., Monrose, F.: All your iframes point to
us. In: 17th USENIX Security Symposium (2008)
5. Anagnostakis, K.G., Antonatos, S., Markatos, E.P.: Honey@home: A new approach
to large-scale threat monitor. In: 5th ACM Workshop on Recurring Malcode (2007)
6. Wang, Y.-M., Beck, D., Jiang, X., Roussev, R., Verbowski, C., Chen, S., King, S.:
Automated web patrol with strider honeymonkeys: Finding web sites that exploit
browser vulnerabilities. In: Network and Distributed System Security Symposium
(NDSS), San Diego, CA (2006)