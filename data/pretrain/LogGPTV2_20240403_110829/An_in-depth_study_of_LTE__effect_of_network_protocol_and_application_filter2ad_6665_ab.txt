In contrast, public IP addresses observed by servers may change
rapidly [4]. Private IPs can also be reused. We take this into ac-
count by using a timing gap threshold of one hour in our analysis.
If a private IP has not been seen for one hour, we assume its cor-
responding user session has terminated. This potentially overesti-
mates the user base, but its impact on our subsequent analyses is
expected to be small since changing this threshold to 30 minutes
or 2 hours does not qualitatively affect the measurement results
in §4, §6, and §7. In total, we observe about 379K anonymized
client IPs and 719K server IPs.
Flow Extraction. From the data set, we extract ﬂows based on
a 5-tuple of src/dst IP, src/dst port numbers, and protocol (TCP or
UDP). We conservatively use a threshold of 1 hour to determine
that a ﬂow has terminated if no ﬂow termination packets are ob-
served. We ﬁnd that similar to the idle period threshold for sub-
scriber identiﬁcation, the impact of this value on subsequent anal-
ysis results is negligible. Overall, 47.1 million ﬂows are extracted
from the trace.
We emphasize here that no customer private information is used
in our analysis and all customer identities are anonymized before
any analysis is conducted. Similarly, to adhere to the conﬁdential-
ity under which we had access to the data, in subsequent sections,
we present normalized views of our results while retaining the sci-
entiﬁcally relevant bits.
3.2 Controlled Local Experiments
We also set up a measurement testbed in our lab for controlled
experiments. The UE used is a fairly new smartphone model —
Samsung Galaxy S III (SGH-I747) running Android 4.0.4 (Ice-
Cream Sandwich, Linux kernel version 3.0.8) connecting to an LTE
network. We tested on two large commercial LTE carriers referred
to as Carrier A and Carrier B, using two Samsung Galaxy S III
phones purchased from the two carriers. We conﬁgure a server
with 2GB memory and 2.40GHz Intel Core 2 CPU, running Ubuntu
12.04 with 3.2.0-36-generic Linux kernel. Both the UE and
the server use TCP CUBIC as their TCP implementation.
Note that the purpose of using local experiments from a poten-
tially different LTE carrier at locations that may not match where
our studied data set comes from is to provide a different perspective
and also evaluate whether observations from analyzing the data set
can be empirically observed.
When measuring TCP throughput and RTT (Figures 11,20, and 19),
the UE establishes a TCP connection to the server, which then
transfers randomized data without any interruption. For throughput
measurement, we ignore the ﬁrst 10 seconds of the TCP connection
(skip the slow start phase), and calculate the throughput every 500
ms from the continuously transferred data. The RTT is measured
by computing the gap between timestamps of transmitting a data
packet and receiving the corresponding ACK from the sender-side
trace collected by the tcpdump tool.
4. LTE NETWORKS CHARACTERISTICS
We study LTE trafﬁc characteristics using the aforementioned
packet traces collected from the studied commercial LTE network.
We also compare our results with two previous measurement stud-
ies of cellular and WiFi performance on mobile devices (§4.4).
4.1 Flow Size, Duration, Rate, Concurrency
We begin by showing the protocol breakdown of the data set. For
the transport-layer protocol, TCP dominates the data set (95.3%
ﬂow-wise and 97.2% byte-wise), with majority of the remaining
trafﬁc in UDP. Within TCP, as the dominant application-layer pro-
tocol, HTTP (port 80/8080) contributes 76.6% and 50.1% of all
TCP bytes and TCP ﬂows, respectively. We also notice the popu-
larity of HTTPS (port 443), which account for 14.8% and 42.1%
of TCP bytes and ﬂows, respectively. We present a more detailed
app-layer content analysis and compare the ﬁndings with those for
3G networks in §7.1.
Following previous measurement studies of wired and WiFi net-
works [36, 22, 6], we are interested in three characteristics of LTE
TCP ﬂows: size, duration, and rate. Size is the total number of
payload bytes within the ﬂow (excluding IP/transport layer head-
ers). Duration is the time span between the ﬁrst and last packet of
a ﬂow. Flow rate is calculated by dividing ﬂow size by ﬂow dura-
tion. Understanding these characteristics is vital to many aspects
in cellular networks such as eNB scheduling, usage-based billing
policy, and RAN resource balancing and optimization. Our focus
is TCP since its accounts for the vast majority of the trafﬁc (95.3%
of ﬂows and 97.2% of bytes).
TCP Flow Size. Figure 2 plots the CDF of uplink and downlink
payload sizes, both exhibiting strong heavy-tail distributions. Most
ﬂows are small: 90% of ﬂows have less than 2.9 KB uplink payload
and 90% of ﬂows carry no more than 35.9 KB downlink payload.
In particular, 11.3% (10.9%) of ﬂows do not have any downlink
365Figure 4: An example of delayed FIN packet and its impact on
radio resource management.
Figure 2: Distribution of TCP ﬂow sizes.
Figure 3: Distribution of ﬂow duration and the duration be-
tween the last payload byte to the end of the ﬂow.
(uplink) payload as they only contain complete or incomplete TCP
handshakes. On the other hand, a very small fraction of large ﬂows,
which are known as “heavy-hitter” ﬂows [22], contribute to the ma-
jority of the trafﬁc volume. For downlink, the top 0.6% of ﬂows
ranked by payload sizes, each with over 1 MB of downlink pay-
load, account for 61.7% of the total downlink bytes. For uplink,
the top 0.1% of ﬂows, each with over 100 KB of uplink payload,
consist of 63.9% of the overall uplink bytes. Such a distribution is
as skewed as that in wired networks [22].
We next examined the top 5% of downlink ﬂows ranked by their
downlink payload sizes. Each of them contains at least 85.9KB of
downlink payload data and 80.3% of them use HTTP. By examin-
ing the HTTP headers (if exist) of the top 5% downlink ﬂows, we
found that 74.4% of their contents (in bytes) are video or audio.
Regarding to the top 5% uplink ﬂows, 73.6% of their bytes are im-
ages. Most of such trafﬁc corresponds to users uploading photos to
social networks such as Instagram.
TCP Flow Duration. Figure 3 shows the distribution of TCP
ﬂow duration (the solid line), deﬁned to be the time span between
the ﬁrst and the last packets of a ﬂow. Most ﬂows are short: 48.1%
are less than 5 seconds. 8.5% of the TCP ﬂows are not even estab-
lished successfully and they only consist of SYN packets. For the
long-tailed part, 6.8% of the ﬂows last at least 3 minutes and 2.8%
are longer than 10 minutes.
The dotted curve in Figure 3 denotes the timing gap between the
packet carrying the last payload byte and the last packet of a ﬂow.
Note that most ﬂows in the data set are properly terminated by ei-
ther FIN (86.2% of ﬂows) or RESET (5.4%), and the remaining
ﬂows consist of only one or more SYN packets (8.5%). One ex-
ample of the cause of the aforementioned timing gap is persistent
HTTP that tries to reuse the same TCP connection for transferring
multiple web objects so there is a timeout before the connection is
closed. This does not cause any issue in wired or WiFi networks.
However, in LTE networks, there exists a timeout for shutting down
Figure 5: Distributions of normalized TCP ﬂow rates.
the radio interface after a data transfer. Such a timeout, which is
called tail time, saves energy by taking the device to the idle state
once it ﬁnishes, and prevents frequent radio state switches [13].
We measured the timeout (i.e., the tail time) to be 10 seconds for
the studied LTE network. A delayed FIN or RESET packet will
incur additional radio-on time and one additional off-on switch if
the delay is longer than 10 seconds, leading to waste of device en-
ergy [26]. Figure 4 shows one such example, which is found to
be prevalent: delaying FIN or RESET for longer than 10 seconds
occurs in 23.1% of the ﬂows in our data set as shown in Figure 3.
TCP Flow Rate. Figure 5 measures the ﬂow rate. We observe a
huge disparity between uplink and downlink rates, due to (i) mobile
devices usually do not perform bulk data uploading (e.g., FTP and
P2P upload), and (ii) cellular uplink channel is signiﬁcantly slower
than the downlink channel, even in LTE networks [29]. The four
downlink throughput distributions for ﬂows with different sizes in
Figure 5 indicate that larger ﬂows tend to be faster. Previous mea-
surements for wired networks also suggest that for Internet ﬂows,
there exist correlations among their size, duration, and rate [36, 22].
We quantitatively conﬁrm that similar behaviors also hold for LTE
ﬂows. Let S, D, and R be downlink ﬂow size, duration, and rate,
respectively, and (X, Y ) be the correlation coefﬁcient between X
and Y . We calculate the values of (logS, logD), (logD, logR),
and (logR, logS) to be 0.196, -0.885, and 0.392, respectively. For
uplink ﬂows, the values of (logS, logD), (logD, logR), and
(logR, logS) are 0.030, -0.986, and 0.445, respectively. We found
the ﬂow duration and the rate are much more negatively correlated,
compared with Internet ﬂows studied in [22], whose correlation co-
efﬁcients are between -0.60 and -0.69 for Internet backbone, VPN,
and DSL ﬂows. This is worth further investigation to conﬁrm if the
sessions are terminated early due to bad performance.
Concurrent TCP Flows. We explore the concurrency of TCP
ﬂows per user in the LTE data set, as shown in Figure 6. Speciﬁ-
cally, we use 1 second as a threshold to determine the concurrency,
i.e., for the sampled time point, we count the number of TCP ﬂows
that have the downlink data transfers within the last 1 second. We
observe that for 72.1% of the time, there is only one TCP ﬂow ac-
tively downloading data, and this percentage might be even larger
for smartphone users, considering that our data set also consists of
a small share of users that uses LTE data cards on their laptops,
which may have high TCP ﬂow concurrency.
 0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10 100 1000 10000CDFPayload (KB)Downlink payloadUplink payload 0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10 100 1000CDFTime (second)LTE tail timeTCP flow durationLast payload byte to flow endRadioPacketONONt=1s11s13s23st=1s: last payload packett=11s: radio turns off (Tail=10s)t=13s: TCP FIN, radio turns ont=23s: radio turns offTime 0 0.2 0.4 0.6 0.8 1 1e-05 0.0001 0.001 0.01 0.1 1CDFNormalized TCP rateDownlink (all)Downlink (flows=10MB)Uplink (all)366Figure 6: Concurrency for TCP ﬂows per user uniformly sam-
pled by time.
Figure 8: Distribution of the radio between uplink and down-
link RTT (for non-PEP trafﬁc).
Figure 7: Distributions of normalized handshake RTT and
DNS lookup time.
4.2 Network Latency
Figure 7 measures distributions of TCP handshake RTT. “C”,
“M”, “P”, and “S” correspond to the client (UE), monitor (the data
collection point), PEP, and remote server, respectively. Since the
monitor lies in the LTE core network, we can break down the over-
the downstream RTT between a
all RTT into two components:
client and the monitor (“C-M”, for all trafﬁc), and the upstream
RTT between either the monitor and the PEP (“M-P”, for TCP port
80/8080 trafﬁc) or server (“M-S”, for other trafﬁc). The down-
stream RTT is an estimation of the latency in the RAN (Figure 1).
In a TCP three-way handshake, let the monitor’s reception time of
SYN (uplink), SYNACK (downlink), and ACK (uplink) be t1, t2,
and t3, respectively. Then the upstream RTT is computed as t2−t1,
and the downstream RTT is t3−t2. The “C-S” curve combines both
the “C-M” and the “M-S” components (for non-PEP trafﬁc only).
It is well known that in 2G/3G data networks, usually the RAN
latency dominates the overall end-to-end delay [35]. This is no
longer the case in LTE networks. Figure 7 shows that the up-
stream RTT to a remote server (“M-S”) has a higher variance, and
is usually larger than the downstream RTT (“C-M”). This is fur-
ther conﬁrmed by Figure 8, which plots the distribution of ratios
between the upstream RTT and the downstream RTT for non-PEP
(“C-S”) ﬂows. For 55% of the non-PEP ﬂows, their upstream RTTs
are larger than the corresponding downstream RTT, whose reduc-
tion (i.e., the reduction of the RAN latency) is mostly attributed
to the ﬂattened network topology in the LTE RAN. For example,
the two-layered RAN architecture (NodeB and the Radio Network
Controller, RNC) in 3G UMTS/HSPA networks is replaced by the
single-layered eNB architecture in LTE, helping signiﬁcantly re-
ducing the RAN latency [29] (See §4.4 for quantitative compar-
isons). Further, the “M-P” curve in Figure 7 indicates the latency
between the monitor and the PEP is very small.
LTE Promotion Delay. In cellular networks, the end-to-end la-
tency of a packet that triggers a UE’s radio interface to turn on is
signiﬁcantly long. Such a packet incurs a radio resource control
(RRC) promotion delay during which multiple control messages
Figure 9: Estimating the promotion delay.
are exchanged between a UE and the RAN for resource alloca-
tion. The promotion delay can be as long as 2 seconds in 3G net-
works [25], and it also exists in LTE networks [13]. The promotion
delay is not included in either the upstream RTT or the downstream
RTT in Figure 7, since the promotion (if any) has already ﬁnished
when the monitor observes a SYN packet, as illustrated in Figure 9.
However, we are able to infer the promotion delay using the TCP
timestamp embedded into a TCP packet when the packet is about to
leave the UE. In a three-way handshake, let the TCP timestamp of
the SYN and the ACK packet be T Sb and T Sa, respectively. Then
the round-trip time (including the promotion delay) experienced by
the UE is G(T Sb − T Sa) where G is the inverse of the ticking
frequency of UE’s clock generating the TCP timestamp. Note that
the TCP timestamps are not wall-clock times. Their units depend
on the ticking frequency of the UE. We detail how to compute G
in §6.1. Finally the promotion delay (if exists) could be derived by
subtracting the RTT between the UE and the server/PEP (estimated
in Figure 7) from G(T Sb − T Sa), as shown in Figure 9.
We calculated promotion delays using the aforementioned method,
by examining TCP handshakes with the following property:
the
user does not send or receive a packet within the time window
(t−T, t) where t is the reception time of SYN and T is the window
size. We conservatively choose T = 13 seconds which is larger
than the 10-second timeout of the studied LTE network. This re-
striction ensures the UE is in the idle state when the handshake is
initiated. Therefore, the SYN packet must trigger a state promo-
tion. The 25%, 50%, and 75% percentiles of the promotion delay
are 319 ms, 435 ms, and 558 ms, respectively. We found these are
signiﬁcantly shorter than the 3G promotion delays (around 2 sec-
onds from idle to high-power state, and around 1.5 seconds from
low-power to high-power state [25]), possibly due to the simpliﬁed
signaling protocol in LTE networks [29].
DNS Lookup. The “DNS” curve in Figure 7 measures the DNS
lookup delay, computed as the delta between the reception time of a
DNS request and its response at the monitor. Note this is the latency
between monitor and the DNS server, and we are not able to mea-
sure the downstream latency since DNS messages are transferred
 0 0.2 0.4 0.6 0.8 1 0 2 4 6 8 10CDFTCP concurrency 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CDFNormalized RTTC-MM-PM-SC-SDNS lookup time 0 0.2 0.4 0.6 0.8 1 0 0.5 1 1.5 2 2.5 3 3.5 4CDFRatio of RTT(M-S) / RTT(C-M)UERANMonitorServer/PEPSYNSYNACKACKTSbTSaG(TSb-TSa)PromoDelayRTT367Figure 10: Downlink bytes in ﬂight vs. downstream RTT.
Figure 12: Downlink bytes in ﬂight vs. downstream RTT (con-
trolled lab experiments with LTE Carrier B).
Figure 11: Downlink bytes in ﬂight vs. downstream RTT (con-
trolled lab experiments with LTE Carrier A).
over UDP. We found that the upstream latency is usually very short
i.e., less than 10 ms for 87.3% of request-response pairs. Since
the studied LTE network (Figure 1) has its own DNS server, the
short lookup delay indicates the desired effectiveness of the DNS
server, which caches most DNS responses so their domain names
are effectively resolved locally within the LTE core network.
4.3 Queuing Delay and Retransmission Rate
§4.2 focuses on the RTT of TCP connection establishment dur-
ing which the small TCP handshake packets are usually unlikely to
be buffered by the network. During the data transfer phase, a TCP
sender will increase its congestion window, allowing the number
of unacknowledged packets to grow. Such “in-ﬂight” packets can
potentially be buffered by routers and middleboxes on their net-
work paths, incurring queueing delays. In LTE networks, buffers
are extensively used to accommodate the varying cellular network
conditions and to conceal packet losses [29].
Figure 10 shows the relationship between the downstream RTT