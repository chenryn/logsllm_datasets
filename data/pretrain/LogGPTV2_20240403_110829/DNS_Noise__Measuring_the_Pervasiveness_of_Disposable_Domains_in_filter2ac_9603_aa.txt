# Title: DNS Noise: Measuring the Pervasiveness of Disposable Domains in Modern DNS Traffic

## Authors:
- Yizheng Chen, College of Computing, Georgia Institute of Technology, yizheng.chen@cc.gatech.edu
- Manos Antonakakis, School of Electrical and Computer Engineering, Georgia Institute of Technology, manos.antonakakis@ece.gatech.edu
- Roberto Perdisci, Department of Computer Science, University of Georgia, roberto.perdisci@uga.edu
- Yacin Nadji, College of Computing, Georgia Institute of Technology, yacin.nadji@cc.gatech.edu
- David Dagon, College of Computing, Georgia Institute of Technology, david.dagon@cc.gatech.edu
- Wenke Lee, College of Computing, Georgia Institute of Technology, wenke.lee@cc.gatech.edu

## Conference:
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks

## Abstract
In this paper, we present an analysis of a new class of domain names: disposable domains. We observe that popular web applications and other Internet services systematically use these automatically generated, one-time-use domain names, which appear to be used for signaling via DNS queries. To understand the pervasiveness of disposable domains, we study 24 days of live DNS traffic observed at a large Internet Service Provider over a year. Our findings indicate that disposable domains increased from 23.1% to 27.6% of all queried domains and from 27.6% to 37.2% of all resolved domains daily. While this creative use of DNS may enable new applications, it may also have unanticipated negative consequences on DNS caching infrastructure, DNSSEC validating resolvers, and passive DNS data collection systems.

**Keywords:** Disposable Domain Name, Internet Measurement

## I. Introduction
The Domain Name System (DNS) is a critical component of the Internet, mapping human-readable names to machine-level IP addresses. As the Internet has evolved, service providers have increasingly used DNS in ways not originally intended, aiming to make their network operations more agile and scalable. Examples include content delivery networks (CDNs), NXDOMAIN rewriting, and URL auto-completion and prefetching.

This paper introduces a new class of DNS misuse called disposable domains. Recently, several service providers, such as popular search engines, social networks, and security companies, have begun using automatically generated domain names to convey "one-time signals" to their servers. These disposable domains are often created on demand in large volumes and belong to common parent DNS zones. They exhibit unique cache hit rate distributions that distinguish them from non-disposable domains.

While these innovative uses of DNS can enable new applications and performance improvements, the increasing use of disposable domains may have unintended and potentially negative impacts on DNS operations for large Internet Service Providers (ISPs). For instance, disposable domain names are typically queried only a few times by a small number of clients. However, when a large number of disposable domains are generated, they can fill up the cache of local DNS resolvers, causing premature evictions of non-disposable domains and degrading DNS service within the ISP network. This can also increase the traffic between DNS resolvers and authoritative name servers, leading to extra cryptographic operations for DNSSEC-enabled resolvers. Additionally, the prevalence of disposable domains in modern DNS traffic can significantly increase the storage costs for passive DNS databases, which are essential for domain reputation systems and forensic analysis of network security incidents.

Therefore, it is crucial for the research and operational communities to monitor and analyze the evolution of DNS usage in today's Internet. In this paper, we design a system to automatically discover DNS zones that use disposable domains and present detailed measurements on their usage by large service providers. Specifically, our contributions include:

- A study of large-scale DNS traffic traces collected at a major North American ISP (Comcast), serving millions of end users. Our measurements show that a significant percentage (25% of all queried domain names, 33% of all resolved domain names, and 60% of all distinct resource records observed daily) are disposable.
- A novel algorithm to automatically find DNS zones containing disposable domains. Our algorithm accurately discovers disposable domains by passively monitoring DNS traffic, with 97% true positive and 1% false positive rates. Over 11 months, we discovered 14,488 new disposable zones.
- A discussion of the potential negative implications of the growth of disposable domains on DNS caching infrastructure, DNSSEC-validating resolvers, and passive DNS data collection systems.

The rest of the paper is organized as follows. In Section II, we provide background on DNS and discuss related work. In Section III, we describe our data collection process and provide an overview of the characteristics of modern DNS traffic observed in our dataset. In Section IV, we define disposable domains and examine their key properties. In Section V, we provide details of our disposable domain miner. In Section VI, we discuss the negative impacts of disposable domains on DNS cache, DNSSEC, and passive DNS databases. We conclude the paper in Section VII.

## II. Related Work
### A. DNS Concepts and Terminology
Establishing an Internet connection from a client to a server typically begins with a DNS resolution that maps a domain name (e.g., www.example.com) to an IP address (e.g., 192.0.12.0). The client (stub resolver) first issues a query to the Recursive DNS server (RDNS). If the resolution request is not in the cache, the RDNS performs an iterative query, starting at the root server and working its way down through the top-level domain (TLD) server and the name server of example.com until the RDNS receives the current DNS answer for the original clientâ€™s request. Finally, the RDNS replies to the client with the answer received from the name server of example.com.

### B. Related Work
1. **Passive DNS and DNS Traffic Aggregation:**
   - Weimer [13] was the first to propose passive DNS replication for forensic analysis and network measurement. The implementation, dnstop, passively collects DNS data from a production network to keep historic DNS information.
   - Plonka et al. [14] built treetop to collect and analyze passive DNS traces, categorizing traffic into canonical, overloaded, and unwanted. They showed that spikes in DNS traffic are typically unwanted or overloaded. Unwanted DNS traffic comprises all unsuccessful DNS resolutions (NXDOMAINs), while overloaded DNS traffic includes purposes beyond domain-to-IP mapping, such as blacklisting.
   - Disposable domains are more general than the overloaded class, as they are used for various services beyond blacklisting.

2. **DNS Traffic Analysis:**
   - CDNs traditionally use dynamic request routing via resolution management [1]. Many Internet services use "domain sharding" to allow parallel client queries to web content [15].
   - Vixie [16] pointed out numerous problems with DNS-based load balancing, noting potential decreases in caching effectiveness. His work focused on DNS policy, such as "NXDOMAIN Remapping" for commercial gains, rather than the cache consumption caused by disposable domains.
   - Yadav et al. [17] detected algorithmically-generated malicious domain names. Disposable domains, while generated algorithmically, have low cache hit rates and are not necessarily malicious.
   - Berger et al. [18] studied the dynamics of DNS and proposed stability metrics to classify dynamic and stable domain names. Our definition of disposable domains is a distinct category.
   - Paxson et al. [19] built a practical system for detecting DNS covert channels, enforcing a 4kB/day information bound after lossless compression for enterprise environments. Disposable domains can be stealthy and stay under this threshold but can be identified collectively from the entire disposable zone.

3. **DNS Cache Modeling:**
   - Jung et al. [20] presented a trace-driven simulation to measure cache hit rates. Later, they [21] proposed a cache hit rate model based on inter-query arrival times and TTL values in DNS cache records. Their assumptions, however, do not hold in our ISP Recursive DNS Server monitoring scenario, so we take a black-box analysis approach by evaluating the performance of a server cluster with multiple independent caches.

## III. Data Collection
### A. Traffic Collection and Datasets
We have visibility of all DNS traffic to and from the recursive DNS (RDNS) servers of a large ISP in the Midwestern US. For quality of service reasons, such as load balancing and fault tolerance, DNS queries from ISP customers are served by a cluster of RDNS servers. We can monitor traffic "above" and "below" the RDNS servers, observing DNS responses from the RDNS servers to the client and from the authoritative name servers to the RDNS servers.

We use two types of DNS datasets: a full passive DNS (fpDNS) dataset and a reduced passive DNS (rpDNS) dataset. The fpDNS dataset includes all DNS traffic observed at the monitoring point, with each entry containing the timestamp, anonymized client ID, queried domain name, DNS query type, TTL, and resolution data (RDATA). The rpDNS dataset includes distinct (no duplicates) resource records (RRs) from all successful DNS resolutions, excluding requests with no valid response (e.g., NXDOMAIN).

The size of the compressed fpDNS dataset is around 60GB per day in February and 145GB per day in December 2011. We built the fpDNS dataset using data collected over 24 days, totaling 2.67TB. The rpDNS dataset, which contains deduplicated RRs, is smaller, with a size of seven to nine GBs per day, covering the period from 11/28/2011 to 12/10/2011.

### B. Notation
A domain name \( d \) consists of a set of labels separated by periods. The effective rightmost label is the top-level domain (TLD), capturing the delegation aspects of the zone. The second-level domain (2LD) represents the two rightmost child labels, and the third-level domain (3LD) consists of the three rightmost labels. In general, the \( N \)-th level domain (NLD) refers to the \( N \) rightmost labels. For example, given the domain name \( d = a.example.com \), \( TLD(d) = com \), \( 2LD(d) = example.com \), and \( 3LD(d) = a.example.com \).

### C. Full Passive DNS Database
Before introducing the notion of "disposable" domain names, we provide insights from analyzing the fpDNS dataset. From a high-level view, the most interesting properties are the traffic volumes above and below the RDNS servers, caching properties, and deduplicated resource record volumes. These analyses will provide tell-tale signs for disposable domain names, which the DNS community has not thoroughly defined nor studied.

In February, there were 4.2 billion RRs observed below the RDNS servers and 500 million RRs above them. In December, the volume increased to 10 to 11 billion RRs below the RDNS servers and 800 million RRs above them. Additionally, in December, we observed approximately 30 million unique domain names every day, with 20 million successfully resolved.

1. **DNS Traffic Volume:**
   - We examine the DNS resource record (RR) volumes above and below the recursive DNS servers. There is an order of magnitude less traffic above the recursive servers due to caching. We also observe the human-driven diurnal effect on DNS traffic, with traffic volume dropping after midnight and rising at 10 AM local time.

To put these observations into perspective, we selected two of the most...