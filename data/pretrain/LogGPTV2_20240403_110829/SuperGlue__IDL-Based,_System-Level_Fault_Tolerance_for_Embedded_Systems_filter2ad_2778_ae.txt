case performance is a priority. This web server, which makes
use of all system-level components, enables us to determine
the impact of the recovery infrastructure on best-effort tasks,
whereas prior work [7] has demonstrated the real-time prop-
erties of interface-driven recovery. We evaluate a custom
web server implemented in COMPOSITE, COMPOSITE with
SuperGlue and COMPOSITE with C3 under normal condition
and under the presence of injected faults. We also compare
performance with the Apache HTTP server of version 2.2.14,
which is running on Linux 3.2.6 on a machine with Intel i7-
2760QM at 2.4 Ghz. Performance is measured by how many
requests per second are handled by each web server with ab,
the Apache HTTP server benchmarking tool of version 2.3.
During each test, ab sends 50000 requests with a maximum
of 10 requests concurrently to the server for benchmarking.
Figure 7 shows the performance in throughput (HTTP
requests per second) of all four variations when running for
one minute, which is repeated 20 times with measurements
taken for each, and we report
the average and standard
deviation. Apache achieves around 17600 requests per second,
and the COMPOSITE base web server achieves about 16200
requests per second. COMPOSITE with SuperGlue achieves
average 14281 requests per second (11.84% slowdown), while
COMPOSITE with C3 achieves average 14500 requests per
second (10.5% slowdown).
We evaluated recovery using COMPOSITE with SuperGlue
and COMPOSITE with C3 by injecting faults into one system-
level component every 10 seconds. We observe that recovery
proceeds in parallel to continued web server operations, and
after recovery the web server achieves similar throughput as
236
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:10 UTC from IEEE Xplore.  Restrictions apply. 
before the fault occurred. For example, when the fault occurs
in the scheduler, the web server throughput is only disturbed
temporarily for less than 2 seconds and continues serving
clients, without dropping the network throughput down to
zero. These results indicate that SuperGlue can improve
system reliability with minor performance degradation.
Web server throughput comparison
)
c
e
s
/
s
t
s
e
u
q
e
r
(
t
u
p
h
g
u
o
r
h
T
19000
18000
17000
16000
15000
14000
13000
12000
11000
10000

	





	



0
10
20
30
Time (seconds)
40
50
60
Apache HTTP Server
C3 Web Server w/o fault
SuperGlue Web Server w/o fault
Composite Web Server
C3 Web Server w/ fault
SuperGlue Web Server w/ fault
Fig. 7: Web Server Throughput. Requests/Second for Apache,
COMPOSITE, COMPOSITE with C3 without faults, COMPOS-
ITE with C3 COMPOSITE with SuperGlue without faults, and
COMPOSITE with SuperGlue with one crash injected every 10
seconds, as indicated by red crosses, into a different system-
level component.
VI. RELATED WORK
There has been considerable work on improving OS relia-
bility. Two well-known approaches are TMR and checkpoint-
restore, both of which incur heavy overhead. TMR achieves
reliability through redundancy, which comes at the cost of
more than tripling SWaP costs. Checkpoint-restore, for exam-
ple in EROS [31], Otherworld [32] and Tardigrade [33], takes
a snapshot of the OS services and rolls back to a previous state
when a fault occurs. In addition to the storage and time spent
creating checkpoints, checkpointing client (user-space) state
incurs extra overhead for consistency. Another drawback of
restoring a checkpoint, aside from the overhead, is that com-
putation and communication since the last saved checkpoint
can be lost and the current physical system state and the state
expected by the control system from checkpointed information
could mismatch [7]. Additionally, process level [34] replica-
tion can be made to improve system reliability by using a set
of redundant processes per original application process and
compares their output to ensure correct execution.
A. Dependability in OS
Nooks [1] improves Linux reliability by moving device
drivers into a light-weight protection domain with limited ac-
cess to the kernel‚Äôs memory space. A shadow driver, designed
with the same interface as the original driver, monitors the
transfer of data during normal execution. Device drivers and
their shadow drivers run in privileged mode. When a fault
happens, the shadow driver becomes active instead of the
original driver so it can be recovered with previously saved
state.
Minix [35] is a microkernel OS, in which a special iso-
lated component, the reincarnation server, can restart faulty
components by recreating a fresh copy. Minix does not track
client state however, and therefore the recovery mechanisms
only work well for stateless servers such as device drivers.
In other words, the reincarnation server is not applicable
for OS services that use client state. Additionally, system-
level services in Minix such as memory management are still
implemented in the kernel space, which makes building a
reliable OS tolerant of system-level faults challenging.
CuriOS [36] is a microkernel OS in which a Server State
Region (SSR) stores each server‚Äôs client-related information
that is protected from both the server and client. All SSRs
are managed by a single separate component (SSRManager)
and requests that cause crashes are isolated by restricting
write from clients. A SSR can be created and deleted when
a client accesses a server and returns. When a fault occurs in
a server, a recovery routine in the restarted server is invoked
to enumerate all associated SSRs for recreating the internal
state of the restarted server. However, SSRManager is a single
point of failure and not desirable for a reliable OS when faults
can occur in system-level services. In contrast, COMPOSITE
with C3 [7] as we have discussed in SectionII, focuses on
the fault tolerance mechanism for system-level services and
C‚ÄôMON [28] allows predictable detection of latent faults in
system-level services in component-based OS.
Instead, SuperGlue aims at building reliable OS while
reducing programming effort. SuperGlue makes constructing
reliable OS a much less error-prone process. It achieves this by
mapping a high-level abstract system model (see SectionIII) to
the low-level interface-driven recovery mechanisms, and im-
proves the reliability for system-level services in a component-
based OS with only a small performance degradation. Al-
though the system model and fault recovery mechanisms
could be further integrated with formal speciÔ¨Åcation tech-
niques [37] [38] to achieve greater system assurance, we have
focused on using a model that enables a concise deÔ¨Ånition of
system behavior to evaluate SuperGlue‚Äôs effectiveness.
B. Interface Synthesis
To support software design, automatic code generation
with interface description language (IDL) have been studied
extensively in the past for different purposes. Flick [39] aims
to build a highly Ô¨Çexible IDL compiler which can be used
with various IDL types as well as generate code for different
communication platforms. For example, Flick supports IDLs
such as CORBA IDL at the frontend, and L4 at the backend.
Flick achieves this modularity through a series of programmer-
visible intermediate languages which can be operated on
independently.
Jinn [30] is a dynamic analysis framework for Java Native
Interface (JNI) and can be used to synthesize runtime checks
to detect
language interface violations. Jinn deÔ¨Ånes three
categories of rules that can be expressed using eleven Ô¨Ånite
state machines. Based on these FSMs, Jinn enforces these
237
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:10 UTC from IEEE Xplore.  Restrictions apply. 
rules by dynamically injecting checks into user code with
language interposition at the JNI interfaces for uncovering
software bugs.
In contrast, SuperGlue IDL aiming at system reliability,
allows declarative high-level description about a component-
based OS based on a resource-descriptor relation model and a
descriptor state machine, and enables SuperGlue compiler to
generate the fault recovery code for system-level services and
enhance component-based embedded system dependability.
VII. CONCLUSION
Faults in system-level services usually necessitate rebooting
the system, thus disrupting all applications. In real-time and
embedded systems, this means violating the temporal guaran-
tees of applications, thus violating system correctness. This
paper presents SuperGlue, an infrastructure built on top of
the predictable recovery mechanisms of C3 to improve the
programmability of those mechanisms. We introduce a model
of component and interface semantics that enables the IDL-
based, declarative speciÔ¨Åcation of the salient properties that
the SuperGlue compiler uses to generate recovery code. The
average SuperGlue IDL Ô¨Åle replaces C header Ô¨Åles and is 37
lines of code, an order of magnitude improvement over C3
which required manually written, error-prone recovery code.
We demonstrate that the SuperGlue infrastructure causes a
non-prohibitive slowdown of 11.84% in a throughput-oriented
application (a web-server). Even with injected faults,
the
slowdown is only 13.6%.
REFERENCES
[1] Michael M. Swift, Brian N. Bershad, and Henry M. Levy. Improving
the reliability of commodity operating systems. In SOSP, 2003.
[2] Pedro Mej¬¥ƒ±a-Alvarez and Daniel Moss¬¥e. A responsiveness approach for
scheduling fault recovery in real-time systems. In RTAS, 1999.
[3] A. Burns, S. Punnekkat, L. Strigini, and D. R. Wright. Probabilistic
In DCCA,
scheduling guarantees for fault-tolerant real-time systems.
1999.
[4] S. Punnekkat and A. Burns. Analysis of checkpointing for schedulability
of real-time systems. In RTCSA Workshop, 1997.
[5] Man-Lap Li, Pradeep Ramachandran, Swarup Kumar Sahoo, Vikram S.
Adve, and Yuanyuan Zhou. Understanding the propagation of hard
errors to software and implications for resilient system design.
In
ASPLOS, 2008.
[6] R. Barbosa, J. Karlsson, Qiu Yu, and Xiaozhen Mao. Toward depend-
ability benchmarking of partitioning operating systems. In DSN, 2011.
[7] Jiguo Song, John Wittrock, and Gabriel Parmer. Predictable, efÔ¨Åcient
system-level fault tolerance in C3. In RTSS, 2013.
[8] Gabriel Parmer and Richard West. Mutable protection domains:
Adapting system fault isolation for reliability and efÔ¨Åciency. In ACM
Transactions on Software Engineering (TSE), July/August 2012.
[9] P. Chevochot, I. Puaut, and Projet Solidor. Experimental evaluation of
the fail-silent behavior of a distributed real-time run-time support built
from cots components. 2000.
[10] S. Chandra and P. M. Chen. How fail-stop are faulty programs? In
FTCS, 1998.
[11] Shekhar Borkar. Designing reliable systems from unreliable compo-
IEEE
nents: The challenges of transistor variability and degradation.
Micro, 2005.
[12] Shubu Mukherjee.
Architecture Design for Soft Errors. Morgan
Kaufmann Publishers Inc., San Francisco, CA, USA, 2008.
[13] Qi Wang, Yuxin Ren, Matt Scaperoth, and Gabriel Parmer. Speck: A
kernel for scalable predictability. In Proceedings of the 21st IEEE Real-
Time and Embedded Technology and Applications Symposium (RTAS),
2015.
[14] Gabriel Parmer. The case for thread migration: Predictable IPC in a
customizable and reliable OS. In OSPERT, 2010.
[15] Bryan Ford and Jay Lepreau. Evolving Mach 3.0 to a migrating
In Proceedings of the Winter 1994 USENIX Technical
thread model.
Conference and Exhibition, 1994.
[16] J. Liedtke. On micro-kernel construction. In Proceedings of the 15th
ACM Symposium on Operating System Principles. ACM, December
1995.
[17] Yuxin Ren, Gabriel Parmer, Gedare Bloom, and Teo Georgiev. Cbufs:
EfÔ¨Åcient, system-wide memory management and sharing. In Proceed-
ings of the 2016 International Symposium on Memory Management,
2016.
[18] Kevin Elphinstone and Gernot Heiser. From L3 to seL4 what have we
learnt in 20 years of L4 microkernels? In SOSP, 2013.
[19] G. Candea, S. Kawamoto, Y. Fujiki, G. Friedman, and A. Fox.
Microreboot‚Äìa technique for cheap recovery. In OSDI, 2004.
[20] Giacinto P. Saggese, Nicholas J. Wang, Zbigniew T. Kalbarczyk, San-
jay J. Patel, and Ravishankar K. Iyer. An experimental study of soft
errors in microprocessors. IEEE Micro, 2005.
[21] M. Nicolaidis. Time redundancy based soft-error tolerance to rescue
nanometer technologies. In VLSI Test Symposium, 1999.
[22] A. Wood A. Dixit, R. Heald. Trends from ten years of soft error
experimentation. In SELSE, 2009.
[23] Jonathan Chang, George A. Reis, and David I. August. Automatic
instruction-level software-only recovery methods. In DSN, 2006.
[24] Nicholas J. Wang, Justin Quek, Todd M. Rafacz, and Sanjay J. Patel.
Characterizing the effects of transient faults on a high-performance
processor pipeline. In DSN, 2004.
[25] M. Rebaudengo, M.S. Reorda, and M. Violante. An accurate analysis of
the effects of soft errors in the instruction and data caches of a pipelined
microprocessor. In DATE, 2003.
[26] George A. Reis, Jonathan Chang, Neil Vachharajani, Ram Rangan, and
David I. August. Swift: Software implemented fault tolerance. In CGO,
2005.
[27] N.J. Wang and S.J. Patel. Restore: Symptom based soft error detection
in microprocessors. In DSN, 2005.
[28] Jiguo Song and Gabriel Parmer. C‚ÄôMON: a predictable monitoring
In
infrastructure for system-level latent fault detection and recovery.
RTSS, 2013.
[29] Manuel F¬®ahndrich, Mark Aiken, Chris Hawblitzel, Orion Hodson,
Galen C. Hunt, James R. Larus, and Steven Levi. Language support
for fast and reliable message-based communication in Singularity OS.
In EuroSys, 2006.
[30] Byeongcheol Lee, Ben Wiedermann, Martin Hirzel, Robert Grimm, and
Jinn: synthesizing dynamic bug detectors for
Kathryn S. McKinley.
foreign language interfaces. In PLDI, 2010.
[31] Jonathan S. Shapiro, Jonathan M. Smith, and David J. Farber. Eros: A
fast capability system. In SOSP, 1999.
[32] Alex Depoutovitch and Michael Stumm. Otherworld: giving applica-
tions a chance to survive OS kernel crashes. In Proceedings of the 5th
European conference on Computer systems, pages 181‚Äì194, New York,
NY, USA, 2010. ACM.
[33] Jacob R. Lorch, Andrew Baumann, Lisa Glendenning, Dutch T. Meyer,
and Andrew WarÔ¨Åeld.
Tardigrade: Leveraging lightweight virtual
machines to easily and efÔ¨Åciently construct fault-tolerant services. In
NSDI, 2015.
[34] A. Shye, J. Blomstedt, T. Moseley, V.J. Reddi, and D.A. Connors. Plr: A
software approach to transient fault tolerance for multicore architectures.
TDSC, 2009.
[35] Jorrit N. Herder, Herbert Bos, Ben Gras, Philip Homburg, and An-
drew S. Tanenbaum. Reorganizing unix for reliability. In ACSAC, 2006.
[36] Francis M. David, Ellick M. Chan, Jeffrey C. Carlyle, and Roy H.
Campbell. Curios: Improving reliability through operating system
structure. In OSDI‚Äô08.
[37] M. Rodriguez, J. C. Fabre, and J. Arlat. Formal speciÔ¨Åcation for building
robust real-time microkernels. In RTSS, 2000.
[38] Jean Arlat, Jean-Charles Fabre, Manuel Rodr¬¥ƒ±guez, and Fr¬¥ed¬¥eric Salles.
IEEE Transactions
Dependability of cots microkernel-based systems.
on Computers, 2002.
[39] Eric Eide, Kevin Frei, Bryan Ford, Jay Lepreau, and Gary Lindstrom.
Flick: a Ô¨Çexible, optimizing idl compiler. In PLDI, 1997.
238
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:19:10 UTC from IEEE Xplore.  Restrictions apply.