### Department of Mathematics and Engineering at the University of Madeira (Portugal)

#### Subject Selection
Nineteen subjects were selected, most of whom had industrial experience in various areas but no prior experience with business process management systems. By the time the experiment was conducted, all students had completed a 50-hour course on Business Process Management (BPM), gaining experience in the design and development of business processes.

#### Research Review
In [5], we introduced the CFC metric to analyze the complexity of business processes. With the increasing importance of complexity analysis due to the inherent complexity of processes spanning both within and between enterprises [16], methods are needed to support the design, improvement, and redesign of processes to reduce their complexity. The CFC metric can be used to analyze the complexity of business, workflow, and web processes.

#### Experiment Design
The objects to be rated were business processes graphically designed using the language of the METEOR workflow management system [17]. An example of the processes analyzed and rated by the subjects is illustrated in Figure 4. The independent variable was measured using the CFC metric presented in section 3, while the dependent variable was based on the subjects' ratings. All tests were completed by the same group of subjects.

#### Hypotheses Formulation
An essential aspect of experiments is clearly stating what we intend to evaluate. We present two hypotheses: an abstract and a concrete hypothesis. The abstract hypothesis posits the existence of a correlation between the independent and dependent variables.

#### External Validity
One threat to external validity is subject selection, which may limit the generalizability of the results. The subjects were Master's students who had recently taken a 50-hour BPM course, gaining in-depth experience in designing and developing business processes. To generalize the findings, the experiment should be replicated with a more diverse group of subjects, including practitioners and designers with varying levels of experience.

#### Material Preparation
We prepared 22 professionally-designed, error-free processes (objects) related to bank loan applications. Subjects were instructed on how to conduct the experiment, which they carried out individually in class, with unlimited time. We collected all data, including subjects' ratings and measurements automatically calculated using the CFC metric. All tests were considered valid as all subjects had at least medium experience in designing and analyzing business processes.

#### Data Analysis and Presentation
Two main approaches for data presentation and analysis are quantitative and qualitative. Given that subjects rated processes on a numerical scale from 0 to 100, we chose quantitative analysis. Qualitative analysis was also conducted in conjunction with statistical analysis.

Our goal is to determine if any correlation exists between subjects' ratings and the CFC metric proposed in [5] and briefly described in section 3. Since the data is distribution-free, the Spearman Rank-Difference Correlation Coefficient [18], \( r_S \), was used to determine the correlation. The null hypothesis was:
\[ H_0: \text{“There is no correlation between the CFC metric and the subjects' rating of control-flow complexity.”} \]

The probability of erroneously rejecting the null hypothesis was controlled with two confidence levels: \( \alpha_1 = 0.005 \) and \( \alpha_2 = 0.05 \). The decision rules for rejecting the null hypothesis were:
- For \( \alpha_1 \): reject \( H_0 \) if \( r_S \geq 0.586 \)
- For \( \alpha_2 \): reject \( H_0 \) if \( r_S \geq 0.425 \)

#### Threats to Validity
**Construct Validity:** All measurements of the dependent variable were subjective and based on the subjects' perceptions. Given the subjects' medium experience in BPM design, their ratings are considered significant. The independent variable, measuring control-flow complexity, is constructively valid from a complexity theory perspective, as a complex system is composed of many different types of elements.

**Internal Validity:** We considered aspects that could threaten internal validity, such as differences among subjects, precision of ratings, learning effects, fatigue effects, and subject incentives. Subjects were knowledgeable about the evaluation issues, and the results empirically show the validity of the experiment.

#### Results
The analysis of the collected data led to interesting results. Table 1 shows the Spearman rank-difference correlation coefficients between subjects' ratings and the values given by the CFC metric. For each subject, the correlation coefficient \( r_S \) is provided.

| Subject | \( r_S \) | Decision at \( \alpha_1 \) | Decision at \( \alpha_2 \) |
|---------|-----------|-----------------------------|-----------------------------|
| 1       | 0.741     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 2       | 0.576     | Accept \( H_0 \)            | Reject \( H_0 \)            |
| 3       | 0.487     | Accept \( H_0 \)            | Reject \( H_0 \)            |
| 4       | 0.974     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 5       | 0.732     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 6       | 0.693     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 7       | 0.733     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 8       | 0.848     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 9       | 0.620     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 10      | 0.638     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 11      | 0.720     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 12      | 0.677     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 13      | 0.833     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 14      | 0.487     | Accept \( H_0 \)            | Reject \( H_0 \)            |
| 15      | 0.767     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 16      | 0.704     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 17      | 0.835     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 18      | 0.899     | Reject \( H_0 \)            | Reject \( H_0 \)            |
| 19      | 0.664     | Reject \( H_0 \)            | Reject \( H_0 \)            |

Based on the data from Table 1, for \( \alpha_1 \), the values of \( r_S \) are greater than 0.586 for 84% of the subjects, leading us to reject the null hypothesis. For \( \alpha_2 \), all values of \( r_S \) are greater than 0.425, also leading to the rejection of the null hypothesis. Our confidence levels are 95% for \( \alpha_1 \) and 99.5% for \( \alpha_2 \).

After analyzing the data, we concluded that there is a high correlation between the CFC metric and the subjects' rating of control-flow complexity. This supports our original goal of demonstrating that the CFC metric serves its intended purpose of measuring the control-flow complexity of processes. The results are credible, and no external factors influenced the outcomes. We plan to publish our findings and develop a web-based system to allow other researchers to replicate our experiment.

#### Conclusions
The complexity of processes is intuitively connected to factors such as readability, effort, testability, reliability, and maintainability. Therefore, it is important to develop metrics to identify and reengineer complex processes. In our previous research, we proposed the Control-Flow Complexity (CFC) metric to evaluate the difficulty of producing a business process, web process, or workflow before actual implementation. When process control-flow complexity analysis is part of the development cycle, it significantly influences the design phase, leading to less complex processes.

To demonstrate the effectiveness of the CFC metric, we conducted an empirical validation through a controlled experiment involving 19 graduate students in Computer Science. We tested whether the control-flow complexity of 22 business processes could be predicted using the CFC metric. Statistical analysis confirmed a high correlation between the CFC metric and the control-flow complexity of processes. This metric can be used by business process analysts and designers to create simpler processes.

#### Acknowledgements
We would like to thank the Computer Science graduate students from the University of Madeira, class of 2004-05, for their contribution to this study.

#### References
[1] Harrington, H., Process Breakthrough: Business Process Improvement. Journal of Cost Management (Fall), 1993: p. 30-43.
[2] Wastell, D., P. White, and P. Kawalek, A methodology for business process re-design: experiences and issues. Journal of Strategic Information Systems, 1994. 3(1): p. 23-40.
[3] Ould, M.A., Business Processes: Modelling and analysis for re-engineering and improvement. 1995, Chichester, England: John Wiley & Sons. 224.
[4] Zuse, H., A Framework of Software Measurement. 1997, Berlin: Walter de Gruyter Inc.
[5] Cardoso, J., Evaluating Workflows and Web Process Complexity, in Workflow Handbook 2005, L. Fischer, Editor. 2005, Future Strategies Inc.: Lighthouse Point, FL, USA. p. 284-290.
[6] Fenton, N. and M. Neil, Software metrics: successes, failures and new directions. Journal Systems Software, 1999. 47(2-3): p. 149-157.
[7] Zelkowitz, M.V. and D.R. Wallace, Experimental Models for Validating Technology. IEEE Computer, 1998. 31(5): p. 23-31.
[8] Curtis, B., Measurement and Experimentation in Software Engineering. Proceedings of the IEEE, 1980. 68(9): p. 1144-1157.
[9] Card, D. and W. Agresti, Measuring Software Design Complexity. Journal of Systems and Software, 1988. 8: p. 185-197.
[10] Fenton, N., Software Metrics: A Rigorous Approach. 1991, London: Chapman & Hall.
[11] IEEE, IEEE 610, Standard Glossary of Software Engineering Terminology. 1992, New York: Institute of Electrical and Electronic Engineers.
[12] Borning, A., Computer System Reliability and Nuclear War, in Communications of the ACM. 1987. p. 112-131.
[13] McCabe, T., A Complexity Measure. IEEE Transactions of Software Engineering, 1976. SE-2(4): p. 308-320.
[14] Miller, G., The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information. The Psychological Review, 1956.
[15] Perry, D.E., A.A. Porter, and L.G. Votta, Empirical Studies of Software Engineering: A Roadmap, in The Future of Software Engineering, A. Finkelstein, Editor. 2000, ACM Press. ISBN 1-58113-253-0.
[16] Sheth, A.P., W.v.d. Aalst, and I.B. Arpinar, Processes Driving the Networked Economy. IEEE Concurrency, 1999. 7(3): p. 18-31.
[17] Kochut, K.J., METEOR Model version 3. 1999, Large Scale Distributed Information Systems Lab, Department of Computer Science, University of Georgia: Athens, GA.
[18] Siegel, S. and J. N. John Castellan, Nonparametric Statistics for The Behavioral Sciences. 1988: McGraw-Hill. 399.