the Department of Mathematics and Engineering at the Nineteen subjects were selected. Most of the students
University of Madeira (Portugal). had industrial experience in several areas, but none had
experience with business process management systems
Research Review. In [5] we have presented the CFC and methodologies. By the time the experiment was
metric to analyze the degree of complexity of business done, all the students had taken a 50 hours course on
processes. Nowadays, complexity analysis has an Business Process Management (BPM) and, therefore,
increased importance since the emergence of processes gained experience in the design and development of
that span both between and within enterprises [16] have business processes.
an inherent complexity. Therefore, methods should be
used to support the design, improvement, and redesign Experiment design. The objects to be rated were
of processes to reduce their complexity. The CFC can business processes graphically designed with the
be used to analyze the complexity of business process language used by METEOR workflow
processes, as well as workflow and Web processes. management system [17]. An example of the processes
analyzed and rated by the subjects is illustrated in
4.2. Hypotheses formulation Figure 4. The independent variable was measured using
the CFC metric presented in section 3. The dependent
An important aspect of experiments is to know and variable was measured according to subject’s ratings.
to state in a clear and formal way what we intend to All the tests were solved by the same group of subjects.
evaluate. Hypotheses are essential as they state the
research questions we are asking. We present two
hypotheses: an abstract and a concrete hypothesis.
existence of a correlation between the independent and
the dependent variable.
External validity. One threat to external validity has
been identified: subject selection. This threat can limit
the ability to generalize the results to settings outside
the study. The subjects were Master students that had
recently taken a 50 hours course on BPM gaining an in-
depth experience in the design and development of
business processes. In order to extract a final
conclusion that can be generalized, it is necessary to
Figure 4. Example of an object rated by the replicate this experiment with a more diversified
subjects number of subjects, including practitioners and
designers with less experience.
We prepared the material we had to give to the
subjects. The material consisted of 22 professionally-
4.5. Data Analysis and Presentation
designed, error-free, processes (objects) of the same
universe of discourse, related to bank loan applications.
Two main approaches to presenting and analyzing
The subjects were told how to carry out the experiment.
data can be chosen: quantitative and qualitative
Each subject carried out the experiment alone, in class,
analysis. Since our subjects rated processes using a
and could use unlimited time to solve it. We collected
numerical scale from 0 to 100, we have selected
all the data, including subjects’ rating and the
quantitative analysis to draw conclusions from our
measurements automatically calculated by means of the
data. The qualitative analysis was done in conjunction
CFC metric. All tests were considered valid because all
with a statistical analysis.
of the subjects had at least medium experience in
As we have said previously, our goal is to determine
designing and analyzing business processes.
if any correlation exists between subjects’ ratings and
the CFC metric proposed in [5] and briefly described in
4.4. Threats to Validity
section 3. Since the data collected in the experiment is
distribution free, the Spearman Rank-Difference
Threats to validity are influences that may limit our
Correlation Coefficient [18], r , was used to determine
S
ability to interpret or draw conclusions from the study’s
the correlation of the data collected in the experiment.
data. We will discuss the empirical study’s various
The Spearman r is a non-parametric statistic used to
S
threats to validity (construct, internal, and external
show the relationship between two variables which are
validity) and the way we attempted to alleviate them.
expressed as ranks (the ordinal level of measurement).
The correlation coefficient is a measure of the ability of
Construct validity. All the measurements of the
one variable to predict the value of another variable.
dependent variable were subjective and based on the
Using Spearman’s correlation coefficient, the CFC
perception of the subjects. As the subjects involved in
metric was correlated separately to the different
this experiment had medium experience in BPM design
subject’s rates of control-flow complexity. In our
we think their ratings can be considered significant.
experiment the null hypothesis was:
The independent variable that measures the control-
flow complexity of processes can also be considered
H : “there is no correlation between the CFC metric
0
constructively valid because from a complexity theory
and the subject’s rating of control-flow complexity”.
point of view, a system is called complex if it is
composed of many different types of elements.
The probability that the null hypothesis would be
erroneously rejected was controlled with two
Internal validity. We have considered the different confidence levels: α =0.005 and α =0.05. The decision
1 2
aspects that could threaten the internal validity of the
rules for rejecting the null hypothesis were:
study, such as differences among subjects, precision of
subject’ ratings, learning effects, fatigue effects, and For α : reject H if r >= 0.586; For α : reject H if
subject incentive. Subjects were knowledgeable 1 0 S 2 0
r >= 0.425
concerning the evaluation issues. Analyzing the results S
of the experiment we can empirically observe the
5. Results based system to allow other researcher to replicate our
experiment.
The analysis performed on the collected data led to Our results recommend the use of the CFC metric to
some interesting results. Table 1 shows summary create less complex processes, thus reducing the time
statistics describing the Spearman rank-difference spent reading and understanding processes in order to
correlation coefficient between subjects’ ratings and remove faults or adapt the processes to changed
the values given by the CFC metric. For each subject, requirements. The complexity measurement enables
the correlation coefficient, r , is given. process managers and administrators to calculate the
S
complexity of processes generated by others. Process
designers can analyze the complexity of a particular
Table 1. Correlation coefficients process in development. Process consultants can
contribute with new process components, needing
rs α 1 α 2 methods to analyze the complexity of the proposed
1 0,741 Reject H0 Reject H0 solutions. End-users can inquire about the complexity
2 0,576 Accept H0 Reject H0 of processes before starting process instances.
3 0,487 Accept H0 Reject H0
4 0,974 Reject H0 Reject H0
6. Conclusions
5 0,732 Reject H0 Reject H0
6 0,693 Reject H0 Reject H0
7 0,733 Reject H0 Reject H0 The complexity of processes is intuitively connected
8 0,848 Reject H0 Reject H0 to effects such as readability, effort, testability,
9 0,620 Reject H0 Reject H0 reliability, and maintainability. Therefore, it is tcejbuS
10 0,638 Reject H0 Reject H0
important to develop metrics to identify complex
11 0,720 Reject H0 Reject H0
processes. Afterwards, these processes can be
12 0,677 Reject H0 Reject H0
13 0,833 Reject H0 Reject H0 reengineered, improved, or redesigned to reduce their
14 0,487 Accept H0 Reject H0 complexity.
15 0,767 Reject H0 Reject H0 In our previous research we have proposed the
16 0,704 Reject H0 Reject H0 Control-Flow Complexity (CFC) metric to be applied
17 0,835 Reject H0 Reject H0
to processes. The CFC is a design-time metric that can
18 0,899 Reject H0 Reject H0
19 0,664 Reject H0 Reject H0 be used to evaluate the difficulty of producing a
business process, a Web process, or a workflow before
an actual implementation exists. When process control-
Based on the data from Table 1 and taking in flow complexity analysis becomes part of the process
consideration α , the values of r are greater than 0.586 development cycle, it has a considerable influence in
1 S
the design phase, leading to less complex processes.
for 84% of the subjects; therefore we reject the null
hypothesis. Taking in consideration α , all the values of In order to demonstrate that our CFC metric serves
2
the purpose it was defined for, we have carried out an
r are greater than 0.425, therefore we also reject the
S
null hypothesis. For α , our confidence level is 95%, empirical validation by means of a controlled
1 experiment. Our experiment has involved 19 graduate
and for α our confidence level is 99.5%.
2 students in Computer Science, as part of a research
After analyzing the data we gathered, we concluded
project, and tested if the control-flow complexity of a
that the obtained results reveal that there exists a high
set of 22 business processes could be predicted using
correlation between the CFC metric and the subject’s
the CFC metric. Analyzing the collected data using
rating of control-flow complexity. This leads us back to
statistical methods we have concluded that the CFC
our original goal which was to demonstrate that the
metric is highly correlated with the control-flow
CFC metric serves the purpose it was defined for,
complexity of processes. This metric can, therefore, be
measure the control-flow complexity of processes. The
used by business process analysts and process
results obtained are believable and there are no
designers to analyze the complexity of processes and, if
ambiguities in our interpretation. We also believe that
possible, develop simpler processes.
no external elements have influenced our results. The
diffusion of the experimental results and the way they
are presented are relevant so that they are really put
into use. Therefore, we published our findings in this
paper and we are also planning to develop a Web-
6. Acknowledgements [14].Miller, G., The Magical Number Seven, Plus or
Minus Two: Some Limits on Our Capacity for
We would like to thank the Computer Science Processing Information. The Psychological Review,
graduate students from the University of Madeira of 1956.
class 2004-05 for their contribution in this study.
[15].Perry, D.E., A.A. Porter, and L.G. Votta,
Empirical Studies of Software Engineering: A
7. References
Roadmap, in The Future of Software Engineering, A.
Finkelstein, Editor. 2000, ACM Press. ISBN 1-58113-
[1].Harrington, H., Process Breakthrough: Business 253-0.
Process Improvement. Journal of Cost Management
[16].Sheth, A.P., W.v.d. Aalst, and I.B. Arpinar,
(Fall), 1993: p. 30-43.
Processes Driving the Networked Economy. IEEE
[2].Wastell, D., P. White, and P. Kawalek, A Concurrency, 1999. 7(3): p. 18-31.
methodology for business process re-design:
[17].Kochut, K.J., METEOR Model version 3. 1999,
experiences and issues. Journal of Strategic
Large Scale Distributed Information Systems Lab,
Information Systems, 1994. 3(1): p. 23-40.
Department of Computer Science, University of
[3].Ould, M.A., Business Processes: Modelling and Georgia: Athens, GA.
analysis for re-engineering and improvement. 1995,
[18].Siegel, S. and J. N. John Castellan, Nonparametric
Chichester, England: John Wiley & Sons. 224.
Statistics for The Behavioral Sciences. 1988: McGraw-
[4].Zuse, H., A Framework of Software Measurement. Hill. 399.
1997, Berlin: Walter de Gruyter Inc.
[5].Cardoso, J., Evaluating Workflows and Web
Process Complexity, in Workflow Handbook 2005, L.
Fischer, Editor. 2005, Future Strategies Inc.:
Lighthouse Point, FL, USA. p. 284-290.
[6].Fenton, N. and M. Neil, Software metrics:
successes, failures and new directions. Journal Systems
Software, 1999. 47(2-3): p. 149-157.
[7].Zelkowitz, M.V. and D.R. Wallace, Experimental
Models for Validating Technology. IEEE Computer,
1998. 31(5): p. 23-31.
[8].Curtis, B., Measurement and Experimentation in
Software Engineering. Proceedings of the IEEE, 1980.
68(9): p. 1144-1157.
[9].Card, D. and W. Agresti, Measuring Software
Design Complexity. Journal of Systems and Software,
1988. 8: p. 185-197.
[10].Fenton, N., Software Metrics: A Rigorous
Approach. 1991, London: Chapman & Hall.
[11].IEEE, IEEE 610, Standard Glossary of Software
Engineering Terminology. 1992, New York: Institute
of Electrical and Electronic Engineers.
[12].Borning, A., Computer System Reliability and
Nuclear War, in Communications of the ACM. 1987. p.
112-131.
[13].McCabe, T., A Complexity Measure. IEEE
Transactions of Software Engineering, 1976. SE-2(4):
p. 308-320.