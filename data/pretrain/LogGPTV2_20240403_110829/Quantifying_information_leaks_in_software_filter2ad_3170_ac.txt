memcpy(uaddr, &sat, sizeof(sat));
return 0;
}
Program 5: Function introducing the leak for CVE-2009-
3002.
of type sockaddr_at. The driver uses as parameter eq_t the
library function memcmp to compare memories.
The model checker found a counterexample for a 6 bit
policy within 1 hour and 39 minutes. Once the oﬃcial patch
was applied of setting the sat structure to 0 with memset, our
driver successfully veriﬁed the policy in about the same time
with unwinding assertions, thus it proved that the patch
stops the leak.
tcf ﬁll node. This information leak happens in the net-
link subsystem of the kernel. The function tcf_fill_node
prepares a struct tcmsg to be sent back to the user. How-
ever, the programmer made a typing mistake and ﬁlled a
ﬁeld tcm__pad1 twice instead of the second time for tcm__pad2.
struct tcmsg *tcm;
...
nlh=NLMSG_NEW(skb, pid, seq, event, sizeof(*tcm), flags);
tcm=NLMSG_DATA(nlh);
tcm->tcm_family = AF_UNSPEC;
tcm->tcm__pad1 = 0;
tcm->tcm__pad1 = 0; // typo, should be tcm__pad2 instead.
Program 6: Function excerpt introducing the leak for
CVE-2009-3612.
This leaks kernel memory from tcm__pad2 back to user-
space. Here, we again modelled kernel memory implicitly by
the memory allocated for tcm through the function NLMSG_DATA,
which initialised the ﬁelds of the struct with nondetermin-
istic values. The observation is the ﬁlled out variable tcm,
the low user input is a simple integer variable not mentioned
here for brevity.
The oﬃcial patch which was applied to ﬁx the leak is
simply changing the last line above to tcm->tcm__pad2=0.
We were again able to prove that this patch successfully
ﬁxes the security hole and otherwise the program violates a
leakage policy of 6 bits.
Without the patch, a counterexample is found within 3
minutes and 34 seconds; with the patch, the program is
veriﬁed within about the same time.
sigaltstack. The leakage for this vulnerability is intric-
ate and only manifests itself on 64-bit processors. On such
a system, the struct stack_t, as shown in Program 7, will
be padded to a multiple of 8 bytes because on 64-bit sys-
tems void* and size_t are both 8 bytes (instead of 4 bytes
for 32-bit systems), while an integer type remains 4 bytes.
Thus, the size of stack_t is padded to 24 bytes, while on a
32-bit system it remains unpadded at 12 bytes.
typedef struct sigaltstack {
void __user *ss_sp;
int ss_flags; // 4 bytes padding on 64-bit
size_t ss_size;
} stack_t;
Program 7: Structure with padding depending on archi-
tecture.
The syscall do_sigaltstack in kernel/signal.c copies
such a structure back to userland via the copy function
copy_to_user, however it does not clear the padding bytes,
thus those are leaked to the user on a 64-bit system. In the
function visible in Program 8, the high input is the structure
oss and the low output is the argument uoss.
int do_sigaltstack (const stack_t __user *uss,
stack_t __user *uoss, unsigned long sp) {
stack_t oss;
... // oss fields get filled
if (copy_to_user(uoss, &oss, sizeof(oss)))
goto out; ....
Program 8: Leakage through copying whole structures in-
cluding padding.
CBMC supports modelling of 64-bit widths however that
is not enough to automatically measure the padding bytes.
This is because the sizeof operator in CBMC returns only
the sum of all sizes without eventual bit alignments. This is
solved in our approach by providing a model of the copy_to_-
user function, just like e.g. an implementation of memcpy
is provided, which checks if the length parameter is aligned
according to the architecture (4 bytes for 32 and 8 bytes
for 64). If there are padding alignments then these will be
chosen to be ﬁlled with nondeterministic integer values mod-
ulo the number of padding bytes.
In Program 8, this would translate to the following: size-
of(oss) counts 20 bytes as the size of the structure. How-
ever, this does not account for the padding bytes, and our
copy_to_user model does the following calculation:
pad = ALIGN - (sizeof(oss) % ALIGN);
if(pad == ALIGN)
padding = 0;
else
padding = ((unsigned int) nondet_int()) %
(1 buf at oﬀset *ppos. Because of
if (*ppos + nbytes > ctr->bufsz)
nbytes = ctr->bufsz - *ppos;
if (copy_to_user(buf, ctr->buf + *ppos, nbytes))
return -EFAULT;
the underﬂow, nbytes and *ppos access memory way out of
the actual buﬀer and thus disclose kernel memory. However
our analysis of this vulnerability requires at the moment too
much manual intervention to model memory access outside
of the allowed bound ( i.e. ctr->buf + *ppos).
One elegant way of addressing this problem would be by
modifying CBMC itself; CBMC could for example return
nondeterministic values for such out-of-bound memory ac-
cesses which would implicitly model the access to conﬁden-
tial data.
5.2 Authentication Checks
We analysed parts of the authentication routines of the
secure remote password suite (SRP) and the Unix passwd-
authentication of Cyrus’ Internet Message Support Protocol
daemon (IMSPD).
SRP. To demonstrate that conﬁdential variables and ob-
servations can be used ﬂexibly, we checked that there is no
leakage in the password request function in libsrp/t_get-
pass.c.
The conﬁdential input is the password entered by the user
when being prompted at the login; the observations are the
echos of the terminal of typed characters. Whether the ter-
minal echos the typed characters or not depends on which
mode the console is in. The environment modelling the con-
sole and its modes had to be provided to check this program.
In Program 9, the function t_getpass ﬁrst gets the cur-
rent mode of the console by the function GetConsoleMode;
then it sets a new console mode by inverting the bit
ENABLE_ECHO_INPUT in the mode through the function
SetConsoleMode which clearly disables the echo of input
_TYPE( int ) t_getpass (char* buf, unsigned maxlen,
const char* prompt) {
DWORD mode;
GetConsoleMode( handle, &mode );
SetConsoleMode( handle, mode & ~ENABLE_ECHO_INPUT );
if(fputs(prompt, stdout) == EOF ||
fgets(buf, maxlen, stdin) == NULL) {
SetConsoleMode(handle,mode);
return -1;
} ....
Program 9: Side-eﬀect of mode decides on echo output of
fgets
read from standard input. The function GetConsoleMode is
modelled by nondeterministically setting the mode to any in-
teger value, the function SetConsoleMode sets a global mode
variable to its second argument. The function fgets, which
reads a number of bytes from stdin, is modelled to return
its ﬁrst argument buf completely if the mode is set to echo
the input and return a constant value otherwise.
With this setup CBMC proves through our driver that
starting from any initial mode, the program will always end
up with log2(| (cid:39)P |) = 0, i.e. that there is no leakage. We
can also successfully check that if the line which disables the
echo is removed then the policy is violated.
IMSPD. The function checked in this test is login_plain-
text in imsp/login_unix.c as shown in Program 10.
int login_plaintext(char *user, char* pass,
char** reply) {
...
struct passwd* pwd = getpwnam(user);
if (!pwd) return 1;
if (strcmp(pwd->pw_passwd,
crypt(pass, pwd->pw_passwd)) != 0) {
*reply = "wrong password";
return 1;
}
return 0;
Program 10: Login function of IMSPD.
The program ﬁrst tries to receive the stored password con-
text of a user using the function getpwnam.
If successful,
it will compare the stored with the entered password using
strcmp. If this fails it will set the string reply to “wrong
password”. If authentication is successful it returns 0.
Clearly, this function has three distinguishable observa-
tions: (1) it returns 1 (2) it returns 1 and sets *reply (3) it
returns 0. We modelled the three parameters to the function
as low user input and the stored password as conﬁdential
variable. With this setup, we are able to verify that this
program conforms to a policy which only leaks 3 observa-
tions, within 9 seconds.
6. RELATED WORK
There have been several attempts in recent years to build
a quantitative analysis of leakage, starting with the static
analysis in [4].
The most relevant works for this paper are [1] by M.
Backes, B. K¨opf and A. Rybalchenko and [8] by J. Heusser
and P. Malacaria where veriﬁcation techniques are used to
compute leakage of programs. Those works are both in-
spired by the important previous theoretical work on self
composition by G. Barthe, P. D’Argenio, and T. Rezk [2]
and T. Terauchi and A. Aiken [18]. However as already
noted, those approaches attempt primarily to answer ques-
tions about how much a program leak and seem unable to
scale to real code in terms of line of code, state space and
language constructs. In particular, they have not, as far as
we are aware, been used to analyse independently existing
vulnerabilities in independently existing programs.
On the theoretical side, the complexity of QIF analysis
has recently been thoroughly investigated by H. Yasuoka
and T. Terauchi [19] who, amongst other aspects, explored
the relation to veriﬁcation and k-safety properties.
Approaches that do scale to large programs are by S. Mc-
Camant, M. D. Ernst [14] and J. Newsome, S. McCamant,
D. Song [15]. They released an impressive tool, FlowCheck,
which is able to analyse very large programs. There are how-
ever signiﬁcant diﬀerences between the approaches in that
FlowCheck is a security testing tool based on the Valgrind
dynamic instrumentation framework whereas our approach
is based on veriﬁcation and static analysis techniques. Thus,
our work comes with stronger theoretical guarantees (for ex-
ample veriﬁcation of the oﬃcial patches) and does not re-
quire to “run” the code.
D. Kroening’s CBMC [5] has been used for many practical
applications. A good overview over the applied ﬁelds can be
found under the following link [6].
7. CONCLUSION
In this paper we combined state of the art model check-
ing with theoretical work on Quantitative Information Flow,
to provide a powerful tool for the analysis of leakage of in-
formation. We demonstrated not only that CVE reported
vulnerabilities such as for the Linux kernel can be analysed
with a level of scalability and precision able to ﬁnd real
security vulnerabilities, but that it is also possible to prove
whether the oﬃcial patches ﬁx the problem. We argued that
leaks are not synonymous of a security breach and hence a
quantitative framework is better equipped than a qualitat-
ive one to determine when an information leak represents a
security threat.
We see this work as a signiﬁcant step in the application of
academic research on information ﬂow analysis to real-world
problems in systems software.
Acknowledgment We thank Peter O’Hearn for help-
ful comments on the paper. This research was funded by
EPSRC, grant EP/F023766/1, with title “Model Checking
and Program Analysis for Quantifying Interference”.
8. REFERENCES
[1] Michael Backes and Boris K¨opf and Andrey
Rybalchenko: Automatic Discovery and
Quantiﬁcation of Information Leaks. Proc. 30th
IEEE Symposium on Security and Privacy (S&P ’09)
[2] Barthe, Gilles and D’Argenio, Pedro R. and Rezk,
Tamara: Secure Information Flow by
Self-Composition. CSFW ’04: Proceedings of the
17th IEEE workshop on Computer Security
Foundations.
[4] David Clark, Sebastian Hunt, and Pasquale
Malacaria: Quantitative information ﬂow, relations
and polymorphic types. Journal of Logic and
Computation, Special Issue on Lambda-calculus, type
theory and natural language, 18(2):181-199, 2005.
[5] Clarke, Edmund, and Kroening, Daniel, and Lerda,
Flavio: A Tool for Checking ANSI-C Programs.
Tools and Algorithms for the Construction and
Analysis of Systems (TACAS 2004). Springer,
168–176, Volume 2988
[6] http://www.cprover.org/cbmc/applications.shtml –
Checked 17 June 2010.
[7] Joseph A. Goguen, Jose Meseguer: Security Policies
and Security Models. IEEE Symposium on Security
and Privacy 1982: 11-20
[8] Jonathan Heusser and Pasquale Malacaria: Applied
Quantitative Information Flow and Statistical
Databases. Formal Aspects in Security and Trust
2009: 96-110
[9] Boris K¨opf and Andrey Rybalchenko: Approximation
and randomization for quantitative information-ﬂow
analysis. In Proceedings CST 2010
[10] Landauer, J., and Redmond, T.: A Lattice of
Information. In Proc. of the IEEE Computer Security
Foundations Workshop. IEEE Computer Society
Press, 1993.
[11] Pasquale Malacaria: Assessing security threats of
looping constructs. Proc. ACM Symposium on
Principles of Programming Language, 2007.
[12] Pasquale Malacaria, Han Chen: Lagrange multipliers
and maximum information leakage in diﬀerent
observational models. PLAS 2008: 135-146
[13] Pasquale Malacaria and Jonathan Heusser:
Information Theory and Security: Quantitative
Information Flow. In Formal Methods for
Quantitative Aspects of Programming Languages,
LNCS, Springer Verlag, 2010
[14] Stephen McCamant, Michael D. Ernst: Quantitative
information ﬂow as network ﬂow capacity. PLDI
2008: 193-205 MIT Department of Electrical
Engineering and Computer Science, Ph.D.,
Cambridge, MA, 2008.
[15] James Newsome, Stephen McCamant, Dawn Song:
Measuring channel capacity to distinguish undue
inﬂuence. PLAS 2009: 73-85
[16] Benjamin Schwarz, Hao Chen, David Wagner,
Jeremy Lin, Wei Tu, Geoﬀ Morrison, Jacob West:
Model Checking An Entire Linux Distribution for
Security Violations. ACSAC 2005: 13-22
[17] Pasareanu, Corina S. and Dwyer, Matthew B. and
Huth, Michael: Assume-Guarantee Model Checking
of Software: A Comparative Case Study. Proceedings
of the 5th and 6th International SPIN Workshops on
Theoretical and Practical Aspects of SPIN Model
Checking,1999
[18] T. Terauchi and A. Aiken. Secure information ﬂow as
a safety problem: In SAS, volume 3672 of LNCS,
pages 352–367, 2005.
[3] David Clark, Sebastian Hunt, Pasquale Malacaria: A
[19] Hirotoshi Yasuoka and Tachio Terauchi Quantitative
static analysis for quantifying information ﬂow in a
simple imperative language. Journal of Computer
Security, Volume 15, Number 3 / 2007.
information ﬂow - veriﬁcation hardness and
possibilities. In Proceedings CSF 2010.
View publication stats
View publication stats