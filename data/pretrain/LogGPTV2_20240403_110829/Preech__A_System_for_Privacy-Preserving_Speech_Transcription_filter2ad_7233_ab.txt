for the second speaker in Carpenter, the cloned samples were
successfully identiﬁed as the true speakers.
3.2 Text Analysis
CSPs possess natural language processing (NLP) capabili-
ties that enable automated statistical analyses on large sets
of documents. Those analyses fall into two broad categories.
The ﬁrst type involves identifying speciﬁc words from the
transcript that correspond to sensitive information such as an
address, name, and SSN using named-entity extraction [14].
The other type of analysis involves statistically analyzing the
entire transcript on the whole to extract some semantic or
user-identifying information. This analysis uses two types of
information: the set of words (i.e., bag-of-words representa-
tion of the transcript) and their order of appearance (to capture
the context).
Bag-of-Words Analysis: One of the most commonplace anal-
ysis that treats a document as a bag-of-words is topic mod-
eling [37, 43]. Topic modeling is an unsupervised machine
learning technique that identiﬁes clusters of words that best
characterize a set of documents. Another popular technique
is stylometry analysis, which aims at attributing authorship
(in our case, the speaker) of a document based on its literary
style. It is based on computing a set of stylistic features like
mean word length, words histogram, special character count,
and punctuation count from the disputed document [30].
USENIX Association
29th USENIX Security Symposium    2705
Context-based Analysis: An example of context-based anal-
ysis is sentiment analysis (understanding the overall attitude
in a block of text). Text categorization is another example; it
refers to classifying a document according to a set of prede-
termined labels.
4 Prεεch
Our discussion in the previous sections highlights a trade-off
between privacy and utility. The OSP provides perfect privacy
at the cost of higher error rates, especially for non-standard
speech datasets. On the other hand, clear privacy violations
accompany revealing the speech recording to the CSP. Moti-
vated by this trade-off, we present Prεεch, a practical system
that lies at an intermediate point along the utility-privacy
spectrum of speech transcription.
4.1 System and Threat Models
We consider the scenario where users have audio recordings
of private conversations that require high transcription accu-
racy. For example, a journalist with recordings of conﬁdential
interviews is a paradigmatic user for Prεεch. Other exam-
ples include a therapist with recordings of patient therapy
sessions or a course instructor with oral examination records
of students. Prεεch, however, does not target real-time tran-
scription applications. For example, voice assistants and on-
line transcription (e.g. a live-streaming press conference) are
out-of-scope. Thus, for our target use cases, the latency of
transcription is not a critical concern.
The adversary is the CSP or any other entity having direct
or indirect access to the stored speech at the CSPs. This adver-
sary is capable of the aforementioned voice- and text-based
analysis.
4.2 Prεεch Overview
Prεεch provides an end-to-end tunable system which aims at
satisfying the following design goals:
1. protect the users’ privacy along the acoustic and textual
dimensions;
2. improve on the transcription accuracy compared to ofﬂine
models; and
3. provide the users with control knobs to customize Prεεch’s
functionality according to their desired level of utility, us-
ability, and privacy.
4.2.1 Preserving Textual Privacy
Prεεch protects the privacy of the textual content of an input
speech ﬁle S through the following three operations:
Segmentation and shufﬂing: Prεεch breaks S into a se-
quence of segments, denoted by S. This is followed by shuf-
ﬂing the segments to remove all ordering information. Thus,
segmenting and shufﬂing S transform its textual content into
a bag-of-words representation.
Sensitive word scrubbing (SWS): First, Prεεch applies the
OSP to identify the list of sensitive keywords that contain
numbers, proper nouns, or any other user-speciﬁed words.
Next, Prεεch applies keyword spotting, KWS, (identify por-
tions of the speech that correspond to a keyword) to each of
the segments in S. Only the segments that do not contain a
keyword pass to the CSP for transcription.
Dummy word injection to ensure differential privacy:
The bag-of-words representation of a transcript corresponds
to its word histogram (Sec. 4.5). As discussed in Sec. 3.2,
several statistical analyses can be built on the word histogram
of the transcript T CSP
such as topic modeling or stylometry
analysis. Thus, protecting the privacy of this word histogram
is a primary focus of Prεεch, and the privacy guarantee we
choose is that of differential privacy. To this end, Prεεch en-
sures DP by adding a suitable amount of dummy words to S
before sending it to the CSP. This way, the CSP is allowed
only a differentially private view of the word histogram and
any subsequent statistical model built over it (by Thm. 4.1 in
Sec. 4.5).
S
S
The main challenge in this setting is that the dummy words
must be added in the speech domain, which Prεεch addresses
as follows. First, Prεεch estimates the general domain of
the text for S (speciﬁcally its vocabulary, details in Sec. 4.5)
from T OSP
. Next, it generates dummy text segments using a
state-of-the-art NLP language model. Finally, Prεεch applies
text-to-speech (TTS) transforms to these dummy segments
and adds them to S. However, leaving it just at this would be
insufﬁcient as the CSP can potentially distinguish between
the two different sources of speech (TTS generated dummy
segments and segments in S) based on their acoustic features.
Therefore, Prεεch provides the user with multiple options to
synthesize indistinguishable dummy segments, namely (1)
voice cloning [20], and (2) voice conversion [21, 44]. These
options offer different trade-offs between utility, usability,
and privacy (Secs. 4.5.2 and 4.6). As stated in Sec. 3.2, text-
based attacks exploit individual sensitive words or the order
of the words or the word histogram. Thus, from the above
discussion, Prεεch protects privacy along all three dimensions
(evaluation results in Sec. 7).
To this end, Prεεch applies a series of privacy-preserving
operations to the input speech ﬁle before sending it to the
CSP. Fig. 1 shows the high-level overview of Prεεch. Below,
we brieﬂy describe Prεεch’s privacy-preserving operations.
4.2.2 Preserving Voice Privacy
Voice conversion, VC, is a standard speech processing tech-
nique that transforms the voice of a source speaker of a speech
2706    29th USENIX Security Symposium
USENIX Association
Figure 1: High-level overview of Prεεch, showing the knobs where a user can tune the associated trade-offs.
utterance to that of another speaker. Prεεch applies voice con-
version to fulﬁll a two-fold agenda. First, it obfuscates the
sensitive voice biometric features in S. Second, VC ensures
that the dummy segments (noise added to ensure differential
privacy) are acoustically indistinguishable from the original
speech ﬁle segments. There are two main categories in voice
conversion: one-to-one VC, and many-to-one VC ( Sec. 4.6).
4.2.3 End-to-End System Description
Fig. 1 depicts the workﬂow of Prεεch. Given a speech ﬁle S,
the ﬁrst step (1) is to break S into a sequence of disjoint and
short speech segments, S. This is followed by (2) sensitive
word scrubbing where speech segments containing numbers,
proper nouns, and user-speciﬁed keywords are removed from
S. Next, (3) given the domain of S’s textual content (its vocab-
ulary), Prεεch generates a set of text segments (as is suitable
for satisfying the DP guarantee as discussed in Sec. 4.5), and
subjects it to TTS transformation (4). At this point, Prεεch
has audio segments for the input speech, S, as well as the
dummy segments, Sd. If the user also wants to hide the voice
biometric information in S, Prεεch applies (5) voice conver-
sion over all the segments in S(cid:83)Sd to convert them to the
same target speaker. This process hides the acoustic features
of S and ensures that the segments in S and Sd are indistin-
guishable. This is followed by Prεεch partitioning S across
N > 0 non-colluding CSPs (Sec. 4.5). This partitioning re-
duces the number of dummy segments that are required to
achieve the DP guarantee (Sec. 4.5). Next, Prεεch adds a suit-
able amount of dummy segments from Sd to each partition
Si,i ∈ [N] and shufﬂes them. Additionally, Prεεch keeps track
of time-stamps of the dummy segments, T Si and order of
shufﬂing, Orderi for each such partition (6). After obtaining
the transcript (7) for each partition from the N CSPs, Prεεch
removes Sd’s transcripts and de-shufﬂes the remaining por-
tion of the transcript using T Si and Orderi, and outputs the
ﬁnal transcript to the user (8).
In what follows, we elaborate on the key components of
Prεεch, namely segmentation, sensitive word scrubbing, DP
word histogram release, and voice conversion.
Figure 2: An illustration of Prεεch’s segmentation algorithm.
The coarse segments in light gray. The absence of pitch infor-
mation indicate non-speech instances, which further breaks
down the coarse segments into ﬁner segments.
4.3 Segmentation Algorithm
A key component of Prεεch is breaking the textual context
by segmenting S. We represent S as a sequence of segments
S, where each segment can contain multiple words. Prεεch
applies a hierarchical segmentation approach that starts with
a stage of silence detection based on the energy level, fol-
lowed by pitch detection to detect speech activity for ﬁner
segmentation. The mechanism is illustrated in Fig. 2.
We deﬁne a period of silence as the time duration when
the RMS power of the speech signal drops below -35 dB
for at least 500ms. The initial segmentation stage detects
such silence periods from S resulting in coarse segments. A
human speech signal can be viewed as a modulated periodic
signal where the signal period is referred to as the glottal
cycle [27]. In the second stage, Prεεch uses the existence of
glottal cycles [7] to detect human voice, which breaks down
the coarse segments into ﬁner ones. A time duration of at least
20 ms without the presence of glottal cycles is regarded as
non-speech.
As some segments might be abrupt or too short to allow for
correct speech recognition, Prεεch performs two additional
optimization steps. First, it merges nearby ﬁne segments to
ensure a minimum length per segment. Second, it does not
partition segments at the boundaries of the identiﬁed human
speech and allows 40 ms of non-speech to be included at the
beginning and the end of each segment.
USENIX Association
29th USENIX Security Symposium    2707
Control Knob: Segmenting S presents with a trade-off –
smaller segments result in better privacy guarantee at the
expense of deteriorated transcription accuracy due to semantic
context loss. Prεεch allows the user to tune the minimum
length of the segments as a means to control this trade-off.
4.4 Sensitive Word Scrubbing
S
S
Prεεch performs sensitive word scrubbing (SWS) as follows.
First, it obtains the ofﬂine transcript of S, T OSP
. Next, it ap-
plies named entity recognition (NER) on T OSP
. NER is an
NLP technique that seeks to locate and classify named entities
in text into pre-deﬁned categories such as the names of per-
sons, organizations, locations, expressions of times, monetary
values, etc. Prεεch also gives the option for users to specify
some keywords of their choice. This allows customization of
the sensitive keyword list as users have subjective ideas of
what they might consider sensitive.
S
After the list of sensitive words is ﬁnalized, Prεεch applies
keyword spotting (KWS) on the segments. KWS is needed for
the following three reasons. First, KWS is used to spot the user-
deﬁned keywords which cannot be identiﬁed by NER. Second,
the initial T OSP
is generated on S without segmentation to
achieve the highest estimation accuracy. However, for Prεεch,
we need to identify the segments containing the keywords.
Finally, the OSP might not transcribe the named-entities cor-
rectly at all locations. For example, the name “Carpenter”
might be repeated 20 times in S, while the OSP transcribes
it accurately only ﬁve times. KWS has higher accuracy in
spotting keywords than the OSP’s transcription accuracy.
Control Knob: KWS takes the list of keywords and matches
them phonetically to a speech ﬁle based on a sensitivity score.
This sensitivity score sets a threshold for the phonetic similar-
ity required for a keyword to be spotted. A low score results in
false positives by ﬂagging phonetically similar words as key-
words which degrades the utility by transcribing non-sensitive
segments using the OSP. Conversely, a high score could re-
sult in some keywords being missed and revealed to the CSP.
Hence, the sensitivity score is a trade-off parameter between
privacy and utility (Sec. 7.3.1).
4.5 Differentially Private Word Histogram
We deﬁne vocabulary,V , to be the domain of non-stop and
stemmed words from which T g
S is constructed. Let ci denote
the frequency of the word wi ∈ V in T g
S . As is typical in
the NLP literature, we model the transcription as a bag of
words: BoW = {wi : ci|wi ∈ V }. Additionally, let H represent
[ci] – the count vector of BoW . In other words, the bag of
words model represents a histogram on the vocabulary, i.e., a
mapping from V to N|V |.
4.5.1 Privacy Deﬁnition
As discussed in Sec. 3.2, the aforementioned word histogram
is sensitive and can only be released to the CSP in a privacy-
preserving manner. Our privacy guarantee of choice is DP
which is the de-facto standard for achieving data privacy
[11, 13, 15]. DP provides provable privacy guarantees and
is typically achieved by adding noise to the sensitive data.
Deﬁnition 4.1 ((ε,δ)-differentially private d-distant his-
togram release). A randomized mechanism A : N|V | → N|V |,
which maps the original histogram into a noisy one, satisﬁes
(ε,δ)-DP if for any pair of histograms H1 and H2 such that
||H1 − H2||1 = d and any set O ⊆ N|V |,
Pr[A(H1) ∈ O] ≤ eε · Pr[A(H2) ∈ O] + δ.
(1)
In our context, the DP guarantee informally means that
from the CSP’s perspective, the observed noisy histogram,
˜H, could have been generated from any histogram within a
distance d from the original histogram, H. We deﬁne the set
of all such histograms to be the ε-indistinguishability neigh-
borhood for H. In other words, from ˜H the CSP will not be
able to distinguish between T CSP
and any other transcript that
differs from T CSP
in d words from V .
An important result for differential privacy is that any post-
processing computation performed on the output of a differ-
entially private algorithm does not cause any loss in privacy.
Theorem 4.1. (Post-Processing) Let A : X (cid:55)→ R be a ran-
domized algorithm that is (ε,δ)-DP. Let f : R (cid:55)→ R(cid:48) be an
arbitrary randomized mapping. Then f ◦A : X (cid:55)→ R(cid:48) is (ε,δ)-
DP.
S
S
Another result is that the privacy of DP-mechanism can be
ampliﬁed if it is preceded by a sampling step.
Theorem 4.2. Let A be an (ε,δ)-DP algorithm and D is an
input dataset. Let A(cid:48) be another algorithm that runs A on a
random subset of D obtained by sampling it with probability
β. Algorithm A(cid:48) will satisfy (ε(cid:48),δ(cid:48))-DP where ε(cid:48) = ln(1 +
β(eε − 1)) and δ(cid:48) < βδ.
Additionally, we deﬁne a DP mechanism namely the trun-
cated Laplace mechanism [6] which is used in Prεεch.
Deﬁnition 4.2 (Truncated Laplace mechanism for his-
togram). Given a histogram H, the truncated Laplace mech-
anism, Lp(ε,δ,d), adds a non-negative integer noise vector
[max(η,0)]|V | to H, where η follows a distribution, denoted
by L(ε,δ,d) with a p.d.f Pr[η = x] = p· e−(ε/d)|x−η0|, where
p = eε/d−1
eε/d +1 and η0 = − d·ln((eε/d +1)δ)
+ d.
ε
Theorem 4.3. The truncated Laplace mechanism satisﬁes
(ε,δ)-DP for d-distant histogram releases [6].
2708    29th USENIX Security Symposium
USENIX Association
(a) Original
(b) ε=1, δ=0.05, and d=2
(c) ε=1, δ=0.05, and d=5
(d) ε=1, δ=0.05, and d=10
Figure 3: The word cloud of the Facebook dataset visualizing the histogram as it changes after adding different levels of noise.
Fig. 3 visualizes the histogram of the Facebook dataset
as a word cloud for different noise levels. As evident from
the original word cloud, the histogram emphasizes few im-
portant words such as Facebook, people, information, and
users. With increased value of d, the resulting histogram has
a roughly uniform distribution of the included words.