### Extracting Per-Boot Randomness from DRAM

#### Temperature Dependence
Previous studies have demonstrated that the decay of DRAM cells is temperature-dependent. To compensate for this, many systems increase the refresh frequency as the temperature rises. This is primarily due to the increased leakage in DRAM cells at higher temperatures. To understand the effect of temperature on the probability of decay, we designed an experimental setup to control the DRAM temperature. By submerging the DRAM in non-conductive isopropyl alcohol within a refrigerator and using an aquarium heater, we were able to maintain the DRAM temperature within ±1°C. For temperatures above 35°C, we used a laboratory oven.

Our results, shown in Figure 16, indicate that at low temperatures, only a few bits consistently decay (i.e., the same bits always decay). Around 20°C, we begin to see bits that sometimes decay. At room temperature (approximately 23°C), we observe an exponential rise in bit decay.

#### DRAM Temperature Modification
To generate more randomness, we can increase the temperature of the DRAM chip. We achieved this by writing a simple "power virus" that maximizes DRAM power consumption and heat dissipation. The virus initializes a region of DRAM and then repeatedly reads from different addresses. The initial data and addresses are chosen to maximize the toggling frequency on the DRAM pins.

We found that by running our power virus, we could heat the DRAM from 26°C to 29°C within one minute. We ran the power virus while waiting for bits to decay.

#### Variability
In addition to the randomness in bit decay between boots, we observed two types of variability between individual boards:
1. **Decay Probability Variability**: The variability in the probability that different bits will decay.
2. **Cold State Variability**: The variability in the initial contents of DRAM after a cold boot.

This variability is due to manufacturing variations that cause DRAM cells to leak at different rates, leading to the decay probability variability we observe. Process variations in the sense amplifiers, which convert the analog values from the DRAM bits into logical "0"s and "1"s, also contribute to this variability.

The variation in the DRAM's contents from a cold boot (measured after the device was powered off for three days) can provide a unique fingerprint for each board. For instance, at 25-28°C with a delay of 7 seconds, one BeagleBoard had 10 bits that always decayed, while another had only 6 such bits. The two sets are disjoint; the bits that decay on one board do not decay on the other.

Under the assumption that, due to process variation, the placement of these "leaky" bits is independent between different DRAM modules, the locations of leaky bits act as a fingerprint for a particular BeagleBoard. Verifying this assumption about the distribution of leaky bits would require access to more systems than we have, and we leave it for future work.

#### Estimating Entropy
The location of leaky bits cannot, by itself, be the basis for random number generation. An attacker with physical access or who can run software on the device will be able to locate the leaky bits. Therefore, we must examine the bits that sometimes decay and sometimes do not.

We now provide a rough estimate of the amount of entropy available in the decay of these bits. Our analysis assumes that bits decay independently of each other. This is a strong assumption, and there is evidence that it is at least partially false. Accordingly, the entropy estimates below are overestimates, and we hope future work can provide a better measure of available entropy.

We estimate Pr[decay] for each bit based on our experiments and use this probability to compute the information-theoretic entropy content for each bit:

\[ E(p) = -p \cdot \log_2(p) - (1 - p) \cdot \log_2(1 - p) \]

Under the assumption that bits decay independently, we can sum this distribution entropy over every bit we observed to decay.

For a BeagleBoard xM at 25-27°C with a decay time of 7 seconds, we obtain a total boot-time entropy estimate of 4.9 bits, largely due to the fact that only 19 memory decays ever happen, and 16 of these happen with \( p > 0.9 \) or \( p < 0.1 \).

For a decay time of 14 seconds, we see 511 bits decay, and summing their entropy contributions gives an entropy estimate of 209.1 bits. For a delay of 28 seconds, 9,943 bits decay, resulting in an estimated entropy of 8,415.6 bits. For 56 seconds, we see 427,062 decays, resulting in an estimated entropy of 98,611.85 bits.

A delay of even 14 seconds on the first boot is unacceptable in many applications. Moreover, because DRAM decay depends on temperature, this approach may not provide security in very cold conditions, such as phones used on a ski slope.

### PLL Lock Latency
Phase-Locked Loops (PLLs) that produce on-chip clocks in modern processors are complex, analog devices. When they start up (or the chip reconfigures them), they take a variable amount of time to "lock" onto the new output frequency. This variation in lock time is due to factors such as power supply stability, oscillator accuracy and jitter, temperature, and manufacturing process variation. Repeatedly reconfiguring an on-chip PLL and measuring how long it takes to lock will result in random variations.

SoCs typically contain several PLLs used to derive clocks for the processor, memory, and peripherals. On the BeagleBoard xM, the DM3730 contains five DPLLs (Digital Phase-Locked Loops). Each DPLL can be reconfigured and toggled via a software register, and a status flag and interrupt will signal when a DPLL is locked. To measure the time it takes to acquire a lock, we instrumented code to disable the DPLL for the USB peripheral clock on the BeagleBoard xM. Using the hardware performance counter, we measured the number of cycles it took for the DPLL to reacquire a lock (Figure 17).

We obtain about 4.7 bits of entropy every time we re-lock the DPLL, and it takes at most approximately 9,000 cycles (9 µs) for the DPLL to re-lock. Using the DPLL lock latency, we can obtain about 522 KiB of pure entropy per second.

DPLL lock latency can be easily polled for entropy during early boot when the SoC first sets up the clocks and PLLs in the system. Since the DPLL is affected by analog conditions such as temperature, a determined attacker may be able to induce bias in the lock time.

### Conclusion
Randomness is a fundamental system service. A system cannot be said to have successfully booted unless it is ready to provide high-entropy randomness to applications.

We have presented three techniques for gathering entropy early in the boot process. These techniques provide different tradeoffs along three metrics: bitrate, specificity to a particular system, and the extent to which they are explained by unpredictable physical processes.

1. **Timing Kernel Code Blocks**: Provides a moderate amount of entropy and is easily applied to every system, but we can only give a partial account for the source of the entropy it gathers.
2. **DRAM Decay**: Provides a large amount of entropy but presents a heavy performance penalty and is tricky to deploy, relying on details of the memory controller. Its advantage is a physical justification for the observed randomness.
3. **Timing PLL Locking**: Promises the highest bitrate and is well supported by physical processes, but its implementation requires intimate knowledge of the individual SoC.

We implemented and characterized these techniques on a broad spectrum of embedded devices featuring a variety of popular SoCs and hardware, from resource-rich mobile phone hardware to devices that are little more than an Ethernet port and a SoC. While these techniques can be applied to traditional desktop systems and more powerful embedded devices, our focus is on adequately protecting headless, resource-poor embedded devices, which must acquire strong entropy on their very first boot, before they can even export network connectivity.

Our work leaves many questions open. We are able to give only a partial explanation for the entropy we observed in our first technique and only a partial characterization of the DRAM decay effects in our second technique. We hope that future work can shed more light on the situation. More work is also necessary to understand how much the gathered entropy depends on environmental factors that might be under adversarial control.

The three techniques we present exploit just a few of the many potential architectural sources of randomness available in modern systems. Other possible sources of entropy, which we hope will be explored in future work, include voltage scaling latency, GPIO pin voltage, flash memory corruption patterns, and power supply stabilization latency.

Our three techniques are ultimately workarounds for the lack of dedicated hardware random number generators in embedded architectures. What will spur the adoption of such hardware by both hardware and software developers? What is the right way to specify such hardware for the ARM architecture, where a high-level core description is licensed to many processor manufacturers? Furthermore, is it possible to verify that such a unit is functioning correctly and free of backdoors?

### Acknowledgments
We thank Daniel J. Bernstein, J. Alex Halderman, Nadia Heninger, and Eric Rescorla for their comments and suggestions. We would like to thank Xilinx for donating hardware. This material is based upon work supported by the National Science Foundation under Grants No. CNS-0831532, CNS-0964702, DGE-1144086, and by the MURI program under AFOSR Grant No. FA9550-08-1-0352.

### References
[1] E. Barker and J. Kelsey, “Recommendation for random number generation using deterministic random bit generators,” NIST Special Publication 800-90A, Jan. 2012, online: http://csrc.nist.gov/publications/nistpubs/800-90A/SP800-90A.pdf.
[2] M. Bellare, Z. Brakerski, M. Naor, T. Ristenpart, G. Segev, H. Shacham, and S. Yilek, “Hedged public-key encryption: How to protect against bad randomness,” in Asiacrypt 2009. Springer, Dec. 2009.
[3] J. Bouda, J. Krhovjak, V. Matyas, and P. Svenda, “Towards true random number generation in mobile environments,” in NordSec 2009. Springer, Oct. 2009.
[4] E. Brickell, “Recent advances and existing research questions in platform security,” Invited talk at Crypto 2012, Aug. 2012.
[5] J.-L. Danger, S. Guilley, and P. Hoogvorst, “High speed true random number generator based on open loop structures in FPGAs,” Microelectronics Journal, vol. 40, no. 11, Nov. 2009.
[6] D. Davis, R. Ihaka, and P. Fenstermacher, “Cryptographic randomness from air turbulence in disk drives,” in Crypto 1994. Springer, Aug. 1994.
[7] L. Dorrendorf, Z. Gutterman, and B. Pinkas, “Cryptanalysis of the random number generator of the Windows operating system,” ACM Trans. Info. & System Security, vol. 13, no. 1, Oct. 2009.
[8] D. Eastlake 3rd, S. Crocker, and J. Schiller, “Randomness Recommendations for Security,” RFC 1750 (Informational), Internet Engineering Task Force, Dec. 1994, obsoleted by RFC 4086. [Online]. Available: http://www.ietf.org/rfc/rfc1750.txt
[9] V. Fischer and M. Drutarovský, “True random number generator embedded in reconfigurable hardware,” in CHES 2002. Springer, 2003.
[10] I. Goldberg and D. Wagner, “Randomness and the Netscape browser,” Dr. Dobb’s Journal, Jan. 1996.
[11] P. Gutmann, “Software generation of practically strong random numbers,” in USENIX Security 1998. USENIX, Jan. 1998.
[12] Z. Gutterman, B. Pinkas, and T. Reinman, “Analysis of the Linux random number generator,” in IEEE Security and Privacy (“Oakland”) 2006. IEEE Computer Society, May 2006.
[13] J. A. Halderman, S. D. Schoen, N. Heninger, W. Clarkson, W. Paul, J. A. Calandrino, A. J. Feldman, J. Appelbaum, and E. W. Felten, “Lest we remember: Cold boot attacks on encryption keys,” in USENIX Security 2008. USENIX, Jul. 2008.
[14] M. Hamburg, P. Kocher, and M. E. Marson, “Analysis of Intel’s Ivy Bridge digital random number generator,” Online: http://www.cryptography.com/public/pdf/Intel_TRNG_Report_20120312.pdf, Mar. 2012.
[15] R. Heald and P. Wang, “Variability in sub-100 nm SRAM designs,” in ICCAD 2004. IEEE Computer Society, Nov. 2004.
[16] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman, “Mining your Ps and Qs: Detection of widespread weak keys in network devices,” in USENIX Security 2012. USENIX, Aug. 2012.
[17] P. Heydari, “Analysis of the PLL jitter due to power/ground and substrate noise,” IEEE Trans. Circuits and Systems I, vol. 51, no. 12, Dec. 2004.
[18] D. E. Holcomb, W. P. Burleson, and K. Fu, “Power-up SRAM state as an identifying fingerprint and source of true random numbers,” IEEE Trans. Computers, vol. 58, no. 9, Sep. 2009.
[19] A. Hubert and R. van Mook, “Measures for Making DNS More Resilient against Forged Answers,” RFC 5452 (Proposed Standard), Internet Engineering Task Force, Jan. 2009. [Online]. Available: http://www.ietf.org/rfc/rfc5452.txt
[20] M. Jakobsson, E. Shriver, B. K. Hillyer, and A. Juels, “A practical secure physical random bit generator,” in CCS 1998. ACM, Nov. 1998.
[21] DDR3 SDRAM Standard JESD79-3F, JEDEC Committee JC-42.3, Jul. 2012, online: www.jedec.org/sites/default/files/docs/JESD79-3F.pdf.
[22] D. Kaminsky, “Black ops 2008: It’s the end of the cache as we know it,” Black Hat 2008, Aug. 2008, presentation. Slides: https://www.blackhat.com/presentations/bh-jp-08/bh-jp-08-Kaminsky/BlackHat-Japan-08-Kaminsky-DNS08-BlackOps.pdf.
[23] J. Kelsey, B. Schneier, D. Wagner, and C. Hall, “Cryptanalytic attacks on pseudorandom number generators,” in FSE 1998. Springer, Mar. 1998.
[24] J. Kelsey, B. Schneier, and N. Ferguson, “Yarrow-160: Notes on the design and analysis of the Yarrow cryptographic pseudorandom number generator,” in SAC 1999. Springer, 2000.
[25] P. Kohlbrenner and K. Gaj, “An embedded true random number generator for FPGAs,” in FPGA 2004. ACM, Feb. 2004.
[26] P. Lacharme, A. Röck, V. Strubel, and M. Videau, “The Linux pseudorandom number generator revisited,” Cryptology ePrint Archive, Report 2012/251, 2012, http://eprint.iacr.org/.
[27] N. McGuire, P. O. Okech, and Q. Zhou, “Analysis of inherent randomness of the Linux kernel,” in RTLW 2009. OSADL, Sep. 2009, online: http://lwn.net/images/conf/rtlws11/random-hardware.pdf.
[28] T. Mytkowicz, A. Diwan, and E. Bradley, “Computer systems are dynamical systems,” Chaos, vol. 19, no. 3, Sep. 2009.
[29] N. Nisan and A. Ta-Shma, “Extracting randomness: A survey and new constructions,” J. Computer and System Sciences, vol. 58, no. 1, Feb. 1999.
[30] C. Pyo, S. Pae, and G. Lee, “DRAM as source of randomness,” Electronics Letters, vol. 45, no. 1, 2009.
[31] T. Ristenpart and S. Yilek, “When good randomness goes bad: Virtual machine reset vulnerabilities and hedging deployed cryptography,” in NDSS 2003. Internet Society, Feb. 2003.
[32] A. Rukhin, J. Soto, J. Nechvatal, M. Smid, E. Barker, S. Leigh, M. Levenson, M. Vangel, D. Banks, A. Heckert, J. Dray, and S. Vo, “A statistical test suite for random and pseudorandom number generators for cryptographic applications,” NIST Special Publication 800-22, Revision 1a, Apr. 2010, online: http://csrc.nist.gov/groups/ST/toolkit/rng/documents/SP800-22rev1a.pdf.
[33] A. Seznec and N. Sendrier, “HAVEGE: A user-level software heuristic for generating empirically strong random numbers,” ACM Trans. Modeling & Computer Simulation, vol. 13, no. 4, Oct. 2003.
[34] B. Sunar, W. J. Martin, and D. R. Stinson, “A provably secure true random number generator with built-in tolerance to active attacks,” IEEE Trans. Computers, vol. 56, no. 1, Jan. 2007.
[35] M. Technology, MT41J256M4 DDR3 SDRAM Datasheet, Rev. I, Feb. 2010, online: http://download.micron.com/pdf/datasheets/dram/ddr3/1Gb_DDR3_SDRAM.pdf.
[36] AM/DM37x Multimedia Device Silicon Revision 1.x Version R Technical Reference Manual, Texas Instruments, Sep. 2012, online: http://www.ti.com/lit/ug/sprugn4r/sprugn4r.pdf.
[37] The Debian Project, “openssl – predictable random number generator,” DSA-1571-1, May 2008, http://www.debian.org/security/2008/dsa-1571.
[38] J. Voris, N. Saxena, and T. Halevi, “Accelerometers and randomness: Perfect together,” in WiSec 2011. ACM, Jun. 2011.
[39] Zynq-7000 All Programmable SoC Technical Reference Manual, Version 1.3, Xilinx, Oct. 2012, online: http://www.xilinx.com/support/documentation/user_guides/ug585-Zynq-7000-TRM.pdf.
[40] S. Yilek, “Resettable public-key encryption: How to encrypt on a virtual machine,” in CT-RSA 2010. Springer, Mar. 2010.
[41] S. Yilek, E. Rescorla, H. Shacham, B. Enright, and S. Savage, “When private keys are public: Results from the 2008 Debian OpenSSL vulnerability,” in IMC 2009. ACM, Nov. 2009.