### 1. Introduction to Data Pollution and Its Impact

Even a small percentage (e.g., 1%) of polluted emails in the training set can cause a Bayesian classifier, such as SpamBayes, to misclassify an email with a 90% probability. Beyond the Bayes classifier, Biggio et al. [9] have also targeted support vector machines (SVMs) and studied corresponding pollution tactics. Fumera et al. [24] evaluated pattern classification systems in general and concluded that all of them are vulnerable to data pollution attacks. Wang et al. [45] demonstrated that crafted training samples can mislead machine learning classifiers used for detecting malicious crowdsourcing workers.

These causative attacks, or data pollutions, serve as a strong motivation for the development of KARMA. For instance, the pollution technique proposed by Nelson et al. [33] was used in our evaluation.

### 2. Exploratory Attacks

Exploratory attacks, which are out of the scope of KARMA, are still worth mentioning for completeness. In adversarial machine learning, exploratory attacks can be further classified into two sub-categories: model inversion [12, 23], where an attacker infers training data samples based on the learning model, and data evasion [7, 13, 29, 44, 45], where an attacker crafts samples to evade the learning model. Model inversion is within the scope of the machine unlearning proposed by Cao et al. However, because the samples to unlearn are known in this scenario, it is not necessary to apply KARMA. Data evasion is also beyond the scope of the machine unlearning paper.

### 3. Defense Against Data Pollution

In this section, we introduce prior works that defend against data pollution. These works can be divided into two categories: filtering polluted samples before training and training a robust learning model.

- **Filtering Polluted Samples**: Both Brodley et al. [10] and Cretu et al. [17] introduced an additional filtering layer to remove polluted samples. Brodley et al. used majority consensus among different techniques, while Cretu et al. adopted sanitization with micro-models in a voting scheme. Similarly, Newsome et al. [34] clustered samples beforehand to filter out outliers, such as polluted samples.
  
- **Training Robust Models**: Dekel et al. [19] minimized the damage that an attacker could make by formulating the learning as a linear program and using an online-to-batch conversion. Bruckner et al. [11] modeled the learner and the attacker as a game with Nash equilibrium.

Techniques that filter polluted samples before training or make the learning model robust are orthogonal to and can be combined with KARMA. If polluted samples bypass these approaches, as evident from new pollution attacks [19, 35], KARMA serves as a remedy approach that repairs polluted learning models and brings them back to a healthy state.

### 4. Other Similar Techniques

**Machine Unlearning** is a technique proposed by Cao et al. [14] that makes learning systems forget what they have learned before. Cao et al. converted a learning algorithm to a special form in statistical query learning [28], which consists of a small number of summations. The learning algorithm only depends on these summations, which are the sum of some efficiently computable transformations of the training data samples. Therefore, to unlearn a training sample, one just needs to subtract the transformations of that sample from all the summations and then update the learning model.

Machine unlearning only removes specified samples from a learning model, whereas KARMA tries to find what data to remove. As discussed in Section 4.1, KARMA utilizes the machine unlearning technique by Cao et al. but is compatible with other incremental or decremental machine learning methods [15, 20, 22, 37, 42, 43]. The reason for using machine unlearning is its generality, which makes KARMA general as well.

**BoostClean** [31] detects and repairs domain value violations, i.e., attribute values outside their value domain, using statistical boosting. While BoostClean corrects the prediction results of a machine learning model, KARMA corrects the machine learning model itself.

Koh et al. [30] proposed using influence functions to estimate the influence of training samples on prediction results. This approach can prioritize the administrator’s efforts in inspecting the training set without removing any samples and observing causality. In comparison, KARMA is more accurate and reduces the administrator’s efforts by directly unlearning samples. According to Koh et al., the administrator needs to inspect 30% of the training data if 10% is polluted. KARMA improves efficiency by avoiding the need to retrain models from scratch.

### 5. Conclusions

In this paper, we present a new technique called causal unlearning, which actively searches the training set for the misclassification cause in an iterative manner and then removes the cause to repair a polluted machine learning system.

We implemented a prototype of KARMA for causal unlearning and evaluated it using SpamBayes, another SVM-based spam filter, and a JavaScript malware detection engine. Our evaluation results show that KARMA can successfully identify the misclassification cause, i.e., polluted samples, with true positive rates ranging between 98.0% and 99.97% and true negative rates ranging between 85.5% and 94.3%. Furthermore, KARMA can repair polluted learning models and restore the learning model’s accuracy to the original value with less than 1% difference.

### 6. Acknowledgements

We would like to thank Nicolas Papernot (our shepherd), Alex Yang, and anonymous reviewers for their helpful comments and feedback. This work was supported in part by National Science Foundation (NSF) grants CNS-15-63843 and CNS-15-64055. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of NSF.

### 7. References

[References listed as in the original text]

### 8. Appendices

#### A. Another Divergence Score

In the appendix, we define another divergence score between a cluster and a sample called D2. To calculate D2, we maintain two lists: (1) all the features in the cluster, and (2) the number of occurrences of each feature in the cluster. We then obtain the common feature list between the cluster and the sample. The divergence score between the cluster and the sample is defined in Equation 3.

\[ \text{D2} = \sum_{j \in \text{common\_features}} \left( \frac{1}{N_k^1 + 1} + \frac{1}{N_k^2 + 1} + \ldots \right) \]

If the cluster contains only one sample, the divergence score between two samples is half of the divergence score defined in D1. This new divergence score introduces the concept of frequency. When a feature occurs more frequently in the cluster, its contribution to the divergence score is smaller. Conversely, when a feature occurs less frequently, its contribution is larger. During clustering, the active unlearning algorithm tends to include samples with more high-frequency features and fewer low-frequency ones in the current cluster.

#### B. Evaluation on a Bayes-Based JavaScript Malware Detector

In this section, we integrate KARMA with Zozzle [18], a JavaScript malware detection engine using Naïve Bayes. The purpose of the experiment is to show that KARMA works with not only spam detectors but also malware detectors. Because Zozzle is closed-source, we reimplemented a Java version by following their paper and obtained an implementation from Cao et al. [14] where they implemented machine unlearning and evaluated its effectiveness. Their Zozzle implementation is based on Java, and we used Jython [27] to integrate our Python implementation of KARMA with their Zozzle.

The dataset used contains 142,350 real-world JavaScript malware samples from Huawei, JavaScript from the top 10,000 Alexa web sites, and 15,520 polluted JavaScript. All other setups are similar to the setup of our previous experiment, dividing unpolluted samples into 10 equal parts: nine parts plus the polluted samples for training, and the rest equally divided for the oracle and the testing dataset.

The results show that KARMA can successfully identify 98.9% of polluted JavaScripts and restore the detection accuracy against the testing dataset to the original value with less than 0.9% difference.