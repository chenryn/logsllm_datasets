Increment(DBVerVector, WS)
For Each Replica R Do:
1: MasterPreCommit(PageSet[] PS):
2:
3:
4:
5:
6:
7: Return DBVerVector
SendUpdate(R, WS, DBVerVector)
WaitForAcknowledgment(R)
Figure 2. Master node pre-commit actions.
memory modiﬁcations performed by the MySQL storage
manager. Since MySQL heap tables are not transactional
we add an undo and a redo log. The unit of transactional
concurrency control is the memory page. The redo log con-
tains a list of per-page modiﬁcation encodings. Figure 2
shows the pseudo-code for pre-committing a transaction on
the master node. The parameter PS (from Page Set) is a
data structure maintaining all the pages that the transaction
modiﬁed.At pre-commit, the master generates the write-set
message with the modiﬁcationsfor each modiﬁedpage. It
then increments the database version and sends the write-
set and the version that it would turn the database into to
all other replicas. The increment of DBVersion vector on
line 3 is implemented as an atomic operation to ensure that
each committed transaction obtains a unique version vec-
tor. After the pre-commit step completes, the master node
reports back to the scheduler that the transaction has suc-
cessfully committed and piggybacks the new DBVersion on
the reply. Finally, all page locks are released and the master
commits the transaction locally. The scheduler records the
new version vector and uses it to tag subsequent read-only
transactions with the appropriate versions they need to read.
4. Fault Tolerance and Data Availability
In this section, we ﬁrstdescribe our reconﬁgurationtech-
niques in case of master, slave or scheduler node failures.
Second, we describe our mechanisms for data persistence
and availability of storage in the on-disk back-end database
tier. We assume a fail-stop failure model where failures of
any individual node are detected through missed heartbeat
messages or broken connections.
4.1. Scheduler Failure
The scheduler node is minimal in functionality, which
permits extremely fast reconﬁguration in the case of sin-
gle node fail-stop failure scenarios. Since the scheduler’s
state consists of only the current database version vector,
this data can easily be replicated across multiple peer sched-
ulers, which work in parallel. If one scheduler fails and mul-
tiple schedulers are already present, one of the peers takes
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:31:27 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007over. Otherwise, a new scheduler is elected from the re-
maining nodes.
The new scheduler sends a message to the master
databases asking them to abort all uncommitted transactions
that were active at the time of failure. This may not be nec-
essary for databases that automatically abort a transaction
due to broken connections with their client. After the mas-
ters execute the abort request, they reply back with the high-
est database version number they produced. Then, the new
scheduler broadcasts a message to all the other nodes in the
system, informing them of the new topology.
4.2. Master Failure
Upon detecting a master failure, one of the schedulers
takes charge of recovery. It asks all databases to discard
their modiﬁcationlog records, which have version numbers
higher than the last version number it has seen from the
master. This takes care of cleaning up transactions whose
pre-commit modiﬁcationlog ﬂush message may have par-
tially completed at a subset of the replicas but the master
has not acknowledged the commit of the transaction before
failure.
For all other failure cases, reconﬁgurationis trivial. The
replication scheme guarantees that the effects of committed
transactions will be available on all the slaves in the system.
Hence, reconﬁgurationsimply entails electing a new master
from the slave replicas to replaces the failed master replica.
Thereafter, the system continues to service requests. In the
case of master failure during a transaction’s execution, the
effects of the transaction are automatically discarded since
all transaction modiﬁcationsare internal to the master node
up to the commit point.
4.3. Slave Failure
The failure of any particular slave node is detected by all
schedulers. Each scheduler examines its log of outstand-
ing queries, and for those sent to the failed slave, the cor-
responding transaction is aborted and an error message is
returned to the client/application server. The failed slave is
then simply removed from the scheduler tables and a new
topology is generated.
4.4. Data Migration for Integrating Stale
Nodes
In this section, we present the data migration algorithm
for integrating recovering or other stale replicas. New repli-
cas are always integrated as slave nodes of the system, re-
gardless of their rank prior to failure.
The reintegrating node (Sjoin) initially contacts one of
the schedulers and obtains the identities of the current mas-
ters and an arbitrary slave node. We refer to this slave node
as the support slave.
In the next step, Sjoin subscribes to the replication
list of the masters, obtains the current database version
vector DBV ersion and starts receiving modiﬁcation log
records. The node stores these new modiﬁcations into its
local queues, as any other active slave node without apply-
ing these modiﬁcationsto pages. It then requests page up-
dates from its support node indicating the current version
it has for each page and the version number that it needs
to attain, according to DBV ersion, as obtained from the
master replicas upon joining. The support node then selec-
tively transmits only the pages that changed after the joining
node’s version to Sjoin.
In order to minimize integration time, all nodes im-
plement a simple fuzzy checkpoint algorithm [8], modi-
ﬁed to suit our in-memory database. At regular intervals,
each slave starts a checkpointing thread, which iterates the
database pages and persists their current contents together
with their current version onto local stable storage. A ﬂush
of a page and its version number is atomic. Dirty pages,
which have been written to but not committed, are not in-
cluded in the ﬂush. However, our checkpointing scheme is
ﬂe xible and efﬁcient,because it does not require the system
to be quiescent during checkpoints. Since our in-memory
database normally works with its data pages having differ-
ent versions at the same time, a checkpoint does not have to
be synchronous either across replicas or across the pages
checkpointed at each replica. Furthermore, a stale node
only receives the changed pages since its last checkpointed
version of each page. These pages might have collapsed
long chains of modiﬁcations to database rows registering
high update activity. Hence, our scheme allows for poten-
tially faster reintegration of stale nodes into the computation
compared to replaying a log of update transactions.
4.5. Fail-Over Recon(cid:12)guration Using Spare
Backups
Database fail-over time consists of two phases: data mi-
gration for bringing the node up to date and the new node’s
buffer cache warmup. An additional phase occurs only
in the case of master failure due to the need to abort unac-
knowledged and partially propagated updates, as described
in the master failure scenario above.
The data migration phase proceeds as in the algorithm
for stale node integration described in the previous section.
In the buffer cache warmup phase, the backup database
needs to warm up its buffer cache and other internal data
structures until the state of these in-memory data struc-
tures approximates their corresponding state on the failed
database replica. The backup database has its in-memory
buffer cache only partially warmed up, if at all, because it is
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:31:27 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007normally not executing any reads for the workload.
In order to shorten or eliminate the buffer cache warmup
phase, a set of warm spare backups are maintained for a
particular workload for overﬂo w in case of failures (or po-
tentially overload of active replicas). These nodes may be
either idle e.g., previously failed nodes that have just recov-
ered or intentionally maintained relatively unused e.g., for
power savings or because they may be actively running a
different workload. The spare backups subscribe to and re-
ceive the regular modiﬁcation broadcasts from the master
replicas just like active slave replicas. In addition, we use
two alternative techniques for warming up the spare backup
buffer caches during normal operation.
In the ﬁrsttechnique, spare backups are assigned a num-
ber of read-only transactions with the sole purpose of keep-
ing their buffer caches warm. The number of periodic read-
only requests serviced by spare backups is kept at a mini-
mum.
In the second technique, a spare backup does not receive
any requests for the workload. Instead, one or more desig-
nated slave nodes collect statistics about the access pattern
of their resident data set and send the set of page identiﬁers
for pages in their buffer cache to the backup periodically.
The backup simply touches the pages so that they are kept
swapped into main memory. In this way, the backup’s valu-
able CPU resource can be used to service a different work-
load. For spare backups running a different workload, care
must be taken to avoid interference [21] in the database’s
buffer cache for the two workloads. This aspect is, how-
ever, beyond the scope of this paper.
4.6. Data Persistence and Availability in
the Storage Database Tier
We use a back-end on-disk database tier for data persis-
tence in the unlikely case that all in-memory replicas fail.
Upon each commit returned by the in-memory master
database for an update transaction, the scheduler logs the
update queries corresponding to this transaction and, at the
same time, sends these as a batch to be executed on one or
more on-disk back-end databases. Replication in the case of
the on-disk databases is for data persistence and availabil-
ity of data and not for CPU scaling; only a few (e.g., two)
on-disk replicas are needed. Once the update queries have
been successfully logged, the scheduler can return the com-
mit response to the application server without waiting for
responses from all the on-disk databases. The query log-
ging is performed as a lightweight database insert of the
corresponding query strings into a database table [21]. In
case of failure, any on-disk database can be brought up to
date by replaying the log of missing updates.
5. Evaluation
5.1. TPC-W Benchmark
We evaluate our solution using the TPC-W benchmark
from the Transaction Processing Council (TPC) [22], that
simulates an on-line bookstore.
The database contains eight tables: customer, address,
orders, order line, credit info, item, author, and country.
We implemented the fourteen different interactions speci-
ﬁedin the TPC-W benchmark speciﬁcation.The most com-
plex read-only interactions are BestSellers, NewProducts
and Search by Subject which contain complex joins.
We use the standard size with 288K customers and 100K
books, which results in a database size of about 610MB.
The memory-resident set of the workload is about 360MB
and it consists of the most-frequently accessed sections of
the database.
We use the three workload mixes of the TPC-W bench-
mark: browsing, shopping and ordering. These workloads
are characterized by increasing fraction of writes from the
browsing mix (5%) to the most commonly used workload,
the shopping mix (20%) to the ordering mix (50%).
5.2. Experimental Setup
We run our experiments on a cluster of 19 dual AMD
Athlons with 512MB of RAM and 1.9GHz CPU, running
the RedHat Fedora Linux operating system. We run the
scheduler and each of nine database replicas on separate
machines. We use 10 machines to operate the Apache
1.3.31 web-server, which runs a PHP implementation of the
business logic of the TPC-W benchmark and use a client
emulator, which emulates client interactions as speciﬁedin
the TPC-W document.
To determine the peak throughput for each cluster con-
ﬁguration we run a step-function workload, whereby we
gradually increase the number of clients from 100 to 1000.
We then report the peak throughput in web interactions per
second, the standard TPC-W metric, for each conﬁguration.
At the beginning of each experiment, the master and the
slave databases mmap an on-disk database. Although per-
sistence is ensured through an InnoDB database, our pro-
totype currently requires a translation of the database from
the InnoDB table format into the MySQL heap table for-
mat before initial mmap-ing. We run each experiment for a
sufﬁcienttime such that the benchmark’s operating data set
becomes memory resident and we exclude the initial cache
warm-up time from the measurements. Our experiments fo-
cus on demonstrating the system scalability, resiliency and
efﬁciency of failover.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:31:27 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007)
S
P
W
I
(
t
u
p
h
g
u
o
r
h
T
350
300
250
200
150
100
50
0
317
311
Master fails here
Reintegrated as slave
186188
148
124
208
116
25
55
17
153
74
37
20
)
S
P
W
I
(
t
u
p
h
g
u
o
r
h
T
300
250
200
150
100
50
0
1800
1600
1400
1200
1000
800
600
400
200
0
)
s
d
n
o
c
e
s
i
l
l
i
m
(
y
c
n
e
t
a
L
Ordering, M + 4S
Ordering, M + 2S
Ordering, M + 1S
Ordering, M + 8S
Ordering, InnoD B
Bro wsing, InnoD B
Bro wsing, M + 4S
Bro wsing, M + 2S
Bro wsing, M + 1S
Bro wsing, M + 8S
Figure 3. Comparison against InnoDB.
Shopping, InnoD B
Shopping, M + 4S
Shopping, M + 2S
Shopping, M + 1S
Shopping, M + 8S
6. Experimental Results
In our experimental evaluation, we ﬁrstshow the perfor-
mance beneﬁtsbrought about by our fast in-memory trans-
actional layer, compared to a stand-alone on-disk InnoDB
database, in Section 6.1. Then, we demonstrate fast re-
conﬁguration under failures in our in-memory tier versus
a stand-alone InnoDB replicated tier in Section 6.2.
6.1. Performance Experiments
Figure 3 shows the throughput scaling we obtained over
the ﬁne-tunedsingle InnoDB on-disk database back-end. In
the experiment InnoDB was conﬁguredfor serializable con-
currency control. We performed experiments with 1, 2, 4
and 8 slave replicas respectively. Overall, we improve per-
formance over stand-alone InnoDB by factors of 6.5, 17.6