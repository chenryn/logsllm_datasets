### Master Node Pre-Commit Actions

**Pseudo-Code:**
```plaintext
Increment(DBVerVector, WS)
For Each Replica R Do:
1. MasterPreCommit(PageSet[] PS):
2. ...
3. Increment DBVersion vector (atomic operation)
4. ...
5. Return DBVerVector
6. SendUpdate(R, WS, DBVerVector)
7. WaitForAcknowledgment(R)
```
**Figure 2.** Pseudo-code for pre-committing a transaction on the master node.

**Explanation:**
The `MasterPreCommit` function handles the pre-commit actions for a transaction. The `PageSet` (PS) parameter is a data structure that maintains all the pages modified by the transaction. During the pre-commit phase, the master generates a write-set message containing the modifications for each page. It then increments the database version and sends the write-set along with the new version to all replicas. The increment of the `DBVersion` vector is performed atomically to ensure each committed transaction gets a unique version vector. After the pre-commit step, the master reports back to the scheduler that the transaction has successfully committed and includes the new `DBVersion` in the reply. Finally, all page locks are released, and the master commits the transaction locally. The scheduler records the new version vector and uses it to tag subsequent read-only transactions with the appropriate versions they need to read.

### Memory Modifications and Transactional Concurrency Control

Memory modifications are managed by the MySQL storage manager. Since MySQL heap tables are not transactional, we add an undo and a redo log. The unit of transactional concurrency control is the memory page. The redo log contains a list of per-page modification encodings. This ensures that all changes are recorded and can be replayed if necessary.

### Fault Tolerance and Data Availability

#### 4.1 Scheduler Failure

The scheduler node is designed with minimal functionality, allowing for fast reconfiguration in case of failure. The scheduler's state consists only of the current database version vector, which can be easily replicated across multiple peer schedulers. If one scheduler fails, another peer takes over. If no peers are available, a new scheduler is elected from the remaining nodes.

Upon taking over, the new scheduler sends a message to the master databases to abort all uncommitted transactions active at the time of failure. The masters then reply with the highest database version number they produced. The new scheduler broadcasts a message to all nodes, informing them of the new topology.

#### 4.2 Master Failure

When a master failure is detected, a scheduler takes charge of recovery. It instructs all databases to discard modification log records with version numbers higher than the last seen from the master. This cleans up transactions whose pre-commit logs may have partially completed but were not acknowledged before the failure.

For other failure cases, reconfiguration is straightforward. The replication scheme ensures that the effects of committed transactions are available on all slaves. A new master is elected from the slave replicas to replace the failed master, and the system continues to service requests. In the case of a master failure during a transaction, the transaction's effects are discarded as all modifications are internal to the master until the commit point.

#### 4.3 Slave Failure

A slave failure is detected by all schedulers. Each scheduler examines its log of outstanding queries and aborts transactions sent to the failed slave, returning an error message to the client/application server. The failed slave is removed from the scheduler tables, and a new topology is generated.

#### 4.4 Data Migration for Integrating Stale Nodes

To integrate recovering or stale replicas, the reintegrating node (Sjoin) contacts a scheduler to obtain the identities of the current masters and an arbitrary slave node (support slave). Sjoin subscribes to the masters' replication list, obtains the current database version vector (`DBVersion`), and starts receiving modification log records. These new modifications are stored in local queues without being applied to pages. Sjoin then requests page updates from the support node, indicating the current version for each page and the version number it needs to attain. The support node selectively transmits only the pages that changed after Sjoin's version.

To minimize integration time, all nodes implement a simple fuzzy checkpoint algorithm. At regular intervals, each slave checkpoints the database pages and persists their current contents and version onto local stable storage. Dirty pages (written but not committed) are not included in the flush. This checkpointing scheme is flexible and efficient, as it does not require the system to be quiescent during checkpoints.

#### 4.5 Fail-Over Reconfiguration Using Spare Backups

Database fail-over time consists of two phases: data migration and buffer cache warmup. An additional phase occurs in the case of master failure to abort unacknowledged and partially propagated updates.

Data migration proceeds as described in the stale node integration algorithm. For buffer cache warmup, a set of warm spare backups is maintained. These nodes subscribe to and receive regular modification broadcasts from the master replicas. Two techniques are used to warm up the spare backup buffer caches:

1. **Periodic Read-Only Transactions:** Spare backups are assigned a minimal number of read-only transactions to keep their buffer caches warm.
2. **Access Pattern Statistics:** Designated slave nodes collect access pattern statistics and send the set of page identifiers to the backup, which touches these pages to keep them in main memory.

#### 4.6 Data Persistence and Availability in the Storage Database Tier

We use a back-end on-disk database tier for data persistence in case all in-memory replicas fail. Upon each commit returned by the in-memory master, the scheduler logs the update queries and sends them as a batch to one or more on-disk back-end databases. Replication in the on-disk databases is for data persistence and availability, not CPU scaling. Once the update queries are logged, the scheduler returns the commit response to the application server. In case of failure, any on-disk database can be brought up to date by replaying the log of missing updates.

### Evaluation

#### 5.1 TPC-W Benchmark

We evaluate our solution using the TPC-W benchmark, which simulates an online bookstore. The database contains eight tables: customer, address, orders, order line, credit info, item, author, and country. We implemented the fourteen different interactions specified in the TPC-W benchmark, including complex joins for BestSellers, NewProducts, and Search by Subject.

We use the standard size with 288K customers and 100K books, resulting in a database size of about 610MB. The memory-resident set of the workload is about 360MB, consisting of the most frequently accessed sections of the database. We use the three workload mixes: browsing (5% writes), shopping (20% writes), and ordering (50% writes).

#### 5.2 Experimental Setup

Experiments are run on a cluster of 19 dual AMD Athlons with 512MB of RAM and 1.9GHz CPU, running RedHat Fedora Linux. The scheduler and nine database replicas are run on separate machines. Ten machines operate the Apache 1.3.31 web-server, running a PHP implementation of the TPC-W business logic. A client emulator emulates client interactions as specified in the TPC-W document.

To determine peak throughput, we gradually increase the number of clients from 100 to 1000 and report the peak throughput in web interactions per second. At the beginning of each experiment, the master and slave databases mmap an on-disk database. Our prototype requires a translation of the database from the InnoDB table format into the MySQL heap table format before initial mmap-ing. Experiments focus on demonstrating system scalability, resiliency, and failover efficiency.

### Experimental Results

#### 6.1 Performance Experiments

Figure 3 shows the throughput scaling compared to a fine-tuned single InnoDB on-disk database back-end. InnoDB was configured for serializable concurrency control. Experiments were performed with 1, 2, 4, and 8 slave replicas. Overall, we improve performance over stand-alone InnoDB by factors of 6.5, 17.6, and so on.

#### 6.2 Fast Reconfiguration Under Failures

We demonstrate fast reconfiguration under failures in our in-memory tier versus a stand-alone InnoDB replicated tier. The results show significant improvements in both performance and fault tolerance.