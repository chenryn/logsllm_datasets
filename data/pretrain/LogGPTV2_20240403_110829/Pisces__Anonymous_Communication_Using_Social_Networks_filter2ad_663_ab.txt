In this paper, we present a complete design
for a decentralized anonymity system based on the recip-
rocal neighbor policy. Since our design is not limited to
constant degree topologies, we explore the advantages that
come from applying the technique to unstructured social
network graphs. We also present the ﬁrst fully decentralized
protocols for achieving these policies and present analysis,
simulation, and experimentation results demonstrating the
security and performance properties of the Pisces approach.
3 Pisces Protocol
In this section, we ﬁrst describe our design goals, threat
model, and system model. We then outline the core problem
of securing random walks and describe the role of the recip-
rocal neighbor policy in solving the problem in the context
of social networks. Finally, we explain how Pisces securely
implements this policy.
3.1 Design goals
We now present our key design goals for our system.
1. Trustworthy anonymity: we target an architecture that is
able to leverage a user’s social trust relationships to improve
the security of anonymous communication. Current mecha-
nisms for incorporating social trust are either centralized or
are limited in applicability to an honest-but-curious attacker
model.
2. Decentralized design: the design should not have any
central entities. Central entities are attractive targets for at-
tackers, in addition to being a single point of failure for the
entire system. The design should also mitigate route capture
and information leak attacks.
3. Scalable anonymity: the design should be able to scale
to millions of users and relays with low communication
overhead. Since anonymity is deﬁned as the state of being
unidentiﬁable in a group [47], architectures that can support
millions of users provide the additional beneﬁt of increasing
the overall anonymity of users.
3.2 Threat model
In this work, we consider a colluding adversary who
can launch Byzantine attacks against the anonymity system.
The adversary can perform passive attacks such as logging
information for end-to-end timing analysis [31], as well as
active attacks such as deviating from the protocol and se-
lectively denying service to some circuits [6]. We assume
the existence of effective mechanisms to defend against the
Sybil attack, such as those based on social networks [12,67].
Existing Sybil defense mechanisms are not perfect and al-
low the insertion of a bounded number of Sybil identities in
the system. They also require the number of attack edges
log h ), where h is the number
to be bounded by g = O( h
of honest nodes in the system. We use this as our primary
threat model. For comparative analysis, we also evaluate
our system under an ideal Sybil defense that does not allow
the insertion of any Sybil identities.
3.3 System Model and Assumptions
Pisces is a fully decentralized protocol and does not as-
sume any PKI infrastructure. Each node generates a local
public-private key pair. An identity in the system is rep-
resented by its public key. We assume that the ability to
whitewash identities—i.e., rejoin the network with a new
public key in order to avoid blacklisting—is bounded. This
can be enforced by limiting how frequently the social graph
is updated. Several existing Sybil defenses, such as Sybil-
Infer and SybilLimit, already process social graph updates
in batches, and allow a bounded number of Sybil identities
in each batch. By setting the update period to, e.g., one day,
the ability to whitewash identities can be kept low while
maintaining the overall usability of the system. We also
note that a high churn rate for neighbors of a node may in
itself be indicative of a Sybil attack, so future work that in-
corporates this indicator into a Sybil defense may be able to
reduce whitewashing ability even more. A perfect Sybil de-
fense would require an attacker to establish new social ties
in order to whitewash an identity. We assume loose time
synchronization amongst nodes. Existing services such as
NTP [35] can provide time synchronization on the order of
hundreds of milliseconds in wide area networks [21].
Finally,
in this work, we will leverage mechanisms
for building efﬁcient communication structures over un-
structured social networks, such as Whanau [29] and X-
Vine [40]. These mechanisms embed a structure into so-
cial network topologies to provide a distributed hash ta-
ble for efﬁcient communication [50, 54]. In particular, we
use Whanau, since it provides the best security guarantees
amongst the current state of art. Whanau guarantees that,
with high probability, it is possible to securely look up any
object present in the DHT. It is important to point out that
Whanau only provides availability, but not integrity [29].
This means that if a user performs redundant lookups for
a single key, multiple conﬂicting results may be returned;
Whanau guarantees that the correct result will be included
in the returned set, but leaves the problem of identifying
which result is correct to the application layer. Therefore,
Whanau cannot be used in conjunction with current pro-
tocols that provide anonymous communication using struc-
tured topologies [38], since these protocols require integrity
guarantees from the DHT layer itself. We emphasize that
the only property we assume from Whanau is secure rout-
ing; in particular, we do not assume any privacy or anony-
mity properties in its lookup mechanisms [37, 64].
3.4 Problem Overview
Random walks are an integral part of many distributed
anonymity systems, from Tor [14] to ShadowWalker [38].
In a random walk based circuit construction, an initiator I
of the random walk ﬁrst selects a random node A from its
neighbors in some topology (in our case, the social network
graph). The initiator sets up a single-hop circuit with node
A and uses the circuit to download a list of node A’s neigh-
bors (containing the IP addresses and public keys of neigh-
bors). Node I can then select a random node B from the
downloaded list of node A’s neighbors and extend the cir-
cuit through A onto node B. This process can be repeated
to set up a circuit of length l.
Random walks are vulnerable to active route capture at-
tacks in which an adversary biases the peer discovery pro-
cess towards colluding malicious nodes. First, malicious
nodes can exclude honest nodes from their neighbor list to
bias the peer discovery process. Second, malicious nodes
can modify the public keys of honest nodes in their neigh-
bor list. When a initiator of the random walk extends a cir-
cuit from a malicious node to a neighboring honest node,
the malicious node can simply emulate the honest neigh-
bor. The malicious node can repeat this process for further
circuit extensions as well. Finally, the malicious nodes can
add more edges between each other in the social network
topology to increase the percentage of malicious nodes in
their neighbor lists. To secure the random walk process,
we use a reciprocal neighbor policy that limits the beneﬁt
to the attacker of attempting to bias the random walks. We
propose a protocol that securely realizes this policy through
detection of violations.
3.5 Reciprocal Neighbor Policy
We now discuss the key primitive we leverage for se-
curing random walks, the reciprocal neighbor policy. The
main idea of this policy is to consider undirected versions
of structured or unstructured topologies and then entangle
the routing tables of neighboring nodes with each other. In
other words, if a malicious node X does not correctly ad-
vertise an honest node Y in its neighbor list, then Y also
excludes X from its neighbor list in a tit-for-tat manner.
The reciprocal neighbor policy ensures that route capture
attacks based on incorrect advertisement of honest nodes
during random walks serves to partially isolate malicious
nodes behind a small cut in the topology, reducing the prob-
ability that they will be selected in a random walk. In par-
ticular, this policy mitigates the ﬁrst two types of route cap-
ture attacks described above, namely the exclusion of hon-
est nodes and the modiﬁcation of honest nodes’ public keys.
However, the adversary can still bias the peer discovery pro-
cess by simply inserting a large number of malicious nodes
to its routing tables. Thus, the reciprocal neighbor policy
described so far would only be effective for topologies in
which node degrees are bounded and homogeneous, such
as structured peer-to-peer topologies like Chord [54] and
Pastry [50]. However, node degrees in unstructured social
network topologies are highly heterogeneous, presenting an
avenue for attack.
Handling the node degree attack: Addition of edges
amongst colluding malicious nodes in a topology increases
the probability that a malicious node is selected in a random
walk. To prevent this node degree attack, we propose to per-
form random walks using the Metropolis-Hastings modiﬁ-
cation [20, 34] — the transition matrix used for our random
walks is as follows:
8><>:min( 1
1 (cid:0)P
0
)
; 1
di
dj
k6=i Pik
Pij =
if i ! j is an edge in G
if j = i
otherwise
(1)
where di denotes the degree of vertex i in G. Since the
transition probabilities to neighbors may not always sum
to one, nodes add a self loop to the transition probabilities
to address this. The Metropolis-Hastings modiﬁcation en-
sures that attempts to add malicious nodes in the neighbor
table decreases the probability of malicious nodes being se-
lected in a random walk. We will show that the Metropolis-
Hastings modiﬁcation along with reciprocal neighbor pol-
icy is surprisingly effective at mitigating active attacks on
random walks. A malicious node’s attempts to bias the ran-
dom walk process by launching route capture attacks reduce
its own probability of getting selected as an intermediate
node in future random walks, nullifying the effect of the
attack.
3.6 Securing Reciprocal Neighbor Policy
We now present our protocol for securely implementing
the reciprocal neighbor policy.
Intuition: Our key idea is to have neighbors periodically
check each other’s neighbor lists. Suppose that node X and
node Y are neighbors. If node X’s neighbor list doesn’t in-
clude node Y , then the periodic check will reveal this and
enable node Y to implement the tit-for-tat removal of node
X from its routing table. Additionally, the neighbor lists
can be signed by each node so that a dishonest node can be
caught with two different, signed lists and blacklisted. To
handle churn, we propose that all nodes keep their neigh-
bor lists static for the duration of a regular interval (t) and
update the list with joins and leaves only between intervals.
Here we rely on our assumption of loose time synchroniza-
tion. The use of static neighbor lists ensures that we can
identify conﬂicting neighbor lists from a node for the same
time interval, which would be a clear indication of mali-
cious behavior. The duration of the time interval for which
the lists remain static determines the trade-off between the
communication overhead for securing the reciprocal neigh-
borhood policy and the unreliability of circuit construction
due to churn.
Setting up static neighbor list certiﬁcates: A short
time prior to the beginning of a new time interval, each node
sets up a new neighbor list that it will use in the next time
interval:
1. Liveness check:
In the ﬁrst round, nodes exchange
messages with their trusted neighbors to check for live-
ness and reciprocal trust. A reciprocal exchange of
messages ensures that both neighbors are interested in
advertising each other in the next time interval (and
are not in each other’s local blacklists). Nodes wait
for a time duration to receive these messages from all
neighbors, and after the timeout, construct a prelim-
inary version of their next neighbor list, comprising
node identities of all nodes that responded in the ﬁrst
communication round.
2. Degree exchange: Next, the nodes broadcast the length
of their preliminary neighbor list to all the neighbors.
This step is important since Metropolis-Hastings ran-
dom walks require node degrees of neighboring nodes
to determine their transition probabilities.
3. Final list: After receiving these broadcasts from all the
neighbors, a node creates a ﬁnal neighbor list and digi-
tally signs it with its private key. The ﬁnal list includes
the IP address, public key, and node degree of each
neighbor, as well as the time interval for the validity of
the list. Note that a neighbor may go ofﬂine between
the ﬁrst and second step, before the node has a chance
to learn its node degree, in which case it can simply be
omitted from the ﬁnal list.
4. Local integrity checks: At the beginning of every new
time interval, each node queries all its neighbors and
downloads their signed neighbor lists. When a node A
receives a neighbor list from B, it performs local in-
tegrity checks, verifying that B’s neighbor entry for A
contains the correct IP address, public key, and node
degree. Additionally, it veriﬁes that the length of the
neighbor list is at most as long as was broadcast in
Phase 2. (Note that intentionally broadcasting a higher
node degree is disadvantageous to a B, as it will re-
duce the transition probability of it being chosen by a
random walk).
If any local integrity checks fails, A
places B in its permanent local blacklist, severing its
social trust relationship with B and refusing all fur-
ther communication.
If all the checks succeed, then
these neighbor lists serve as a cryptographic commit-
ment from these nodes–the presence of any conﬂicting
neighbor lists for the same time interval issued by the
same node is clear evidence of misbehavior.
If B’s neighbor list omits A entirely, or if B simply
refuses to send its neighbor list to A, B is placed on a
temporary blacklist, and A will refuse further commu-
nication with B for the duration of the current time pe-
riod, preventing any circuits from being extended from
A to B. (Effectively, A performs a selective denial-of-
service against B; see Section 4.3 for more discussion
of this.) The blacklist only lasts for the duration of the
current round, since the omission could have resulted
from a temporary communication failure.
Duplicate detection: Next, we need to ensure that B
uses the same neighbor list during random walks as it pre-
sented to its neighbors. Our approach is to use the Whanau
DHT to check for the presence of several conﬂicting neigh-
bor lists signed by the same node for the same time period.
After performing the local checks, A will store a copy of
B’s signed neighbor list in the Whanau, using B’s identity
(namely, its public key) as the DHT key. Then, when an-
other node C performs a random walk that passes through
B, it will receive a signed neighbor list from B. It will then
perform a lookup in the DHT for any stored neighbor lists
under B’s key. If it discovers a different list for the same
period with a valid signature, then it can notify B’s neigh-
bors about the misbehavior, causing them to immediately
blacklist B.
One challenge is that the Whanau lookups are not anony-
mous and may reveal to external observers the fact that C
is performing a random walk through B. This information
leak, linking C and B, can then be used to break C’s an-
onymity [37, 64]. To address this problem, we introduce
the concept of testing random walks that are not actually
used for anonymous communication but are otherwise in-
distinguishable from regular random walks. The indistin-
guishability of testing random walks from regular random
walks forces the adversary to have the same attack strat-
egy for both processes. Thus it sufﬁces to check for misbe-
havior in the testing random walks only; Whanau lookups
to check for misbehavior are performed for testing random
walks only. The key advantage of this strategy is that infor-
mation leaks during Whanau lookups do not reveal private
information about the user. The lookups are performed after
the random walk to ensure that testing walks and the regu-
lar walks cannot be distinguished. If each node performs
a small number of testing walks within a each time period,
any misbehavior will be detected with high probability.
Blacklisting: When C detects a conﬂicting neighbor list
issued by B, it immediately notiﬁes all of B’s neighbors
(as listed in the neighbor list stored in the DHT), presenting
the two lists as evidence of misbehavior. B’s neighbors will
thereafter terminate their social relationships with B, black-
listing it. Note, however, that the two conﬂicting lists form
incontrovertible evidence that B was behaving maliciously,
since honest nodes never issue two neighbor lists in a sin-
gle time interval. This evidence can be broadcast globally
to ensure that all nodes blacklist B, as any node can verify
the signatures on the two lists, and thus B will not be able
to form connections with any honest nodes in the system.
Moreover, honest nodes will know not to select B in any
random walk, effectively removing it from the social graph
entirely.
Proactive vs. reactive security: Our system relies on
detecting malicious behavior and blacklisting nodes. Thus,
as described so far, Pisces provides reactive security. To fur-
ther strengthen random walk security in the scenario when
the adversary is performing route capture for the ﬁrst time,
we propose an extension to Pisces that aims to provide
proactive security. We propose a discover but wait strat-
egy, in which users build circuits for anonymous commu-
nication, but impose a delay between building a circuit and
actually using it for anonymous communication. If misbe-
havior is detected by a testing random walk within the de-
lay period, the circuit will be terminated as B’s neighbors
blacklist it; otherwise, if a circuit survives some timeout du-
ration, then it can be used for anonymous communication.