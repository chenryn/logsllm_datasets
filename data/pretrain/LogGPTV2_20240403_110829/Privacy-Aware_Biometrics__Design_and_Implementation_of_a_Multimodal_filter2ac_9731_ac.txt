input biometric readings). Figure 4 shows the layout of the
described compositions.
The parallel composition (Figure 4(A)) offers a simple
method to exploit different biometric traits to create the ID.
This way, the level of multi-modality implemented is higher
than in the basic approach since more than two biometric
traits are in use. Given a certain number of biometric traits,
the corresponding binary strings Ji are obtained from the
digital representations of the traits. The two inputs I1 and
I2 to the enrollment module described in Section 4.2 are
obtained through the concatenation of strings Ji.
In par-
ticular, I1 is obtained from {J1, J2, . . . , Jk} and I2 from
{Jk+1, Jk+2, . . . , JN} where N is the number of differ-
ent biometrics. Analogously to what required for the basic
module, it should be possible to measure the error rates ei
for all the feature extraction algorithms that generated Ji
124134
I1’I2'{s, x}{P, δ}IDPδYes/NoRBiometricmatchingI2RecExtsFuzzy Extractor ReproductionxVerification SubmoduleI1I1’I2'{s, x}{P, δ}IDPδYes/NoRBiometricmatchingI2RecExtsFuzzy Extractor ReproductionxVerification SubmoduleI1Figure 4. Examples of the enrollment and veriﬁcation modules in a parallel composition (A)-(B) and
in a hierarchical composition(C)-(D).
with i ∈ [1, k]. However, the global error rate e in the com-
posed input I1 needs particular scrutiny as each biometric
method differently contributes to the overall error rate. No-
tice with respect to Figure 4(B) that in the veriﬁcation phase
the biometric matching module is truly multimodal, that is,
it receives in input a composition of N − k biometric read-
ings (Jk+1, Jk+2, . . . , JN ) to be matched against the ones
collected at enrollment.
The basic modules can be composed also in hierarchi-
cal structures. Figures 4(C) and 4(D) show an example of
a two-level hierarchical composition. Biometric inputs I1
and I2 are used to create ID1 by means of a basic enroll-
ment module. Then, ID1 is used in place of the second bio-
metric trait in a cascaded basic enrollment module together
with a third biometric input I3. The binary string ID2 is
ﬁnally associated with the user. In the veriﬁcation phase,
ID2 and a binary string I(cid:48)
3 obtained from a fresh biometric
reading are processed through a ﬁrst veriﬁcation submod-
ule (substantially a fuzzy extractor; see Figure (3)) and ID1
is recovered. Finally, a basic veriﬁcation module receives
ID1, I(cid:48)
1 as input and completes the authentication
process.
2, and I(cid:48)
It is worth noticing that it is possible to build more com-
plex systems by using each method of composition (parallel
and hierarchical) recursively or by combining the methods
iteratively.
4.4. Analysis of the method
To foolish the authentication system, an adversary can:
i) obtain the digital representations of the biometric traits
of a genuine user through covert means; ii) or recover Ii
from what is publicly available and associated with the en-
rolled person (the identiﬁer). In the ﬁrst case, to attack the
system, the adversary should steal at least two biometric
samples and compute Ii to complete successfully the au-
thentication phase. As described in Section 4.3, a higher
number of biometrics can be taken into account in the setup
of the authentication system to increase the overall security
of the application and prevent such kind of attacks. In the
second case, the method should ensure that the adversary
cannot take advantage from the knowledge of the identiﬁers
or from tampering with the enrollment and veriﬁcation pro-
cedures. Indeed, our approach builds on the fuzzy commit-
ment scheme presented by Juels and Wattenberg and recast
as secure sketch in [1, 7]. Differently from Juels’s approach,
in our scheme, we make use of a fuzzy extractor [8, 1] that
guarantees both uniformity and error tolerance in recon-
structing the biometric inputs I1 and I2. The assumption
when using a fuzzy extractor is that the public information
P must be sufﬁciently separate from the extracted secret R,
so that P does not leak information on the biometric input I.
Indeed, as shown in [10, 9], the mutual information between
P and w = I1 must be non trivial, that is, P must leak some
125135
J1J2IDEnrollmentModule{…}{…}JKJK+1JK+2JN……VerificationSubmoduleMultimodalBiometricMatching(A)(C)IDYes/NoVerification ModuleI1I2ID1EnrollmentModuleI3EnrollmentModuleID2ID1Yes/NoI’2I’1Biometricmatching(B)(D)VerificationSubmoduleI’3ID2VerificationSubmoduleVerification ModuleJ’1J’2{…}J’K…{…}J’K+1J’K+2J’N…J1J2IDEnrollmentModule{…}{…}JKJK+1JK+2JN……VerificationSubmoduleMultimodalBiometricMatching(A)(C)IDYes/NoVerification ModuleI1I2ID1EnrollmentModuleI3EnrollmentModuleID2ID1Yes/NoI’2I’1Biometricmatching(B)(D)VerificationSubmoduleI’3ID2VerificationSubmoduleVerification ModuleJ’1J’2{…}J’K…{…}J’K+1J’K+2J’N…information about the biometric input I1 in order to correct
errors in inputs similar to I1, even if the input distribution
is uniform. In this case, it is possible to use a weaker notion
of security and to deﬁne entropically secure fuzzy extrac-
tors, that is, fuzzy extractors for which the knowledge of
(R, P ) does not help in predicting the value f(I1) for any
predeﬁned function f(w). An equivalent deﬁnition is the
one of uniform fuzzy extractor, that is, when the probability
density function of R and P might be considered close to
uniform. If the adversary has the capability to tamper the
public string P returned by the fuzzy extractor, another ab-
straction robust fuzzy extractors can be considered. For this
kind of extractors the retrieve procedure recovers the secret
string R only if the original public string P is given as input;
otherwise, a special symbol is produced. By using a robust
uniform fuzzy extractor, the proposed scheme ensures both
the randomness of R and the protection from adversarial at-
tempts to use the information in P to recover the original
biometric input readings.
In our scheme the second biometric reading is xor-ed
with the resulting bit-string obtained after processing the
ﬁrst biometric reading, which is then used as a key. From
the previous discussion, the randomness of the key is en-
sured by the fuzzy cryptographic primitive used in the en-
rollment phase. To have strong security guarantees,
it
should be also ensured that the biometric features extracted
from the reading are not too much biased, avoiding that the
adversary can collect information on the string used as key
in the xor-ing. For this reason, the second biometric input
should ensure a sufﬁciently large and uniform entropy.
5. Implementation and Experimental Results
Privacy-aware biometric systems while theoretically
conceivable are often difﬁcult to apply to real biometrics.
For this reason, the implementation described in this sec-
tion not only shows that the method described in Section
4 is practically feasible, but also casts light on the method
itself.
Our implementation is based on two biometric traits: iris
and ﬁngerprint. Since the work of Daugman [6], binary
strings (often called iriscodes) are obtained from pictures of
the eye by using banks of Gabor’s ﬁlters. Genuine subjects
and impostors are then discriminated using the Hamming
metric on such strings. Following the terminology used in
this paper, iris codes correspond to binary input I1 and the
feature extraction algorithm employed to generate them cor-
respond to F1. By using the code presented in [22], we
were able to compute 9600 bits wide iris codes (radial reso-
lution: 20). The code displays an error rate e1 of about 40%.
Fingerprints templates (I2) were instead computed by using
the NIST NBIS code mindtct [28] (feature extraction al-
gorithm F2); the 34 best quality minutia were selected and
then serialized in a ANSI INCITS 378-2004 record (1920
bits). The biometric match between ﬁngerprint templates
was veriﬁed by using the NIST NBIS matcher bozorth3.
The matcher returns a similarity value between the two
minutia sets; to obtain a Hamming distance, as suggested
in the best practice of the literature of multimodal biomet-
rics, the bozorth3 score was subtracted from a large value
(500) and then normalized in the range [0, 1].
5.1. Construction of the fuzzy extractor
We have implemented the Gen procedure of the fuzzy
extractor as follows. First, a 128 bit random number x
was drawn and used as key in the HMAC-SHA1 algorithm
(strong extractor Ext), as provided by the standard Java
JDK, that processed I1 to obtain the pseudo-random secret
R. Since the number of bits in R must match the size of the
biometric input I2, which is a string of 1920-bit, we applied
repeatedly (12 times) the HMAC-SHA1 algorithm (HMAC-
SHA1 returns a string which is 160 bits long). Then, we
selected a shortened Reed-Solomon [9600, 1920, 7681]214
random codeword c [17]. The string s = ˜I1⊕ c is computed
as the binary shift necessary to obtain c from ˜I1, where ˜I1 is
the 9600 bit iris code preliminary mapped with a [14, 1, 1]2
naive code. The mapping might be rationalized as follow.
The codeword c is built with symbols that are 14 bits long.
Each of the 9600 bits of the iris code is turned into a 14-
bits symbol simply padding it with zeros, which is what the
coding we selected does. Such a coding ensures that at most
one bit in each symbols of c might be corrupted. One might
wonder why we did not simply packed the bits together to
form a series of m bits symbols as in common industrial
application. The reason is that we want to correct at most
a certain number of errors and not at least, as usual. The
selection of a proper error correction code is critical and not
trivial (see Appendix A for further discussion on this issue).
Finally, x was concatenated with s to obtain the string P ,
which can be made public without impairing the security of
the scheme.
Analogously, the reproduction function Rep was simi-
larly built. In practice, one decomposes P into x and s and
then applies the shift s to I(cid:48)
1 to obtain a corrupted version of
c. If the number of bits that differ from I1 and I(cid:48)
1 is smaller
than t = 3840, the error correction capability of the Reed-
Solomon code, the codeword can be decoded. The code-
word c is obtained as c = RSenc(RSdec(s ⊕ I(cid:48)
1)), where
RSend and RSdec are a pair of Reed-Solomon encoding
and decoding algorithms. Then, I1 = s ⊕ c furnished at
enrollment is recovered. Analogously to what done in the
Gen phase, I1 is set as input to the strong extractor Ext with
randomness x (HMAC-SHA1) to obtain R.
126136
Figure 5. Frequency distributions and ROC curves for a practical implementation of the multimodal
biometric authentication system (panels (C) and (D)). As a reference, in panel (A) and (B) we reported
the frequency distributions of the single-trait biometric systems on which our implementation built
(dashed-line: impostor). Correspondent ROC curves are included in panel (D).
5.2. Experimental Results
We made the assumption that the enrolling agency de-
sires to collect only biometrics of sufﬁcient quality and that
more than one sample could be required for each subject
to ensure such a quality. We further supposed that three
different iris pictures and ﬁngerprint scans should sufﬁce;
among the three iris codes computed we retained the one
with the smallest number of masking bits1 (I1). For each
ﬁngerprint’s minutia, mindtct offered a quality estimate;
the ﬁngerprints template with the highest average quality
was further processed (I2). We performed our experiments
by coupling eyes images from the CASIA iris database [5]
to ﬁngerprints scans extracted from the FVC2000 dataset.
In particular, we synthetically created a dataset of 108 indi-
viduals. For each individual, we had three eye and ﬁnger-
print images to be used in the enrollment phase, and four
eye images and ﬁve ﬁngerprint images for the veriﬁcation
phase [21].
At enrollment, I1 was processed through the Gen phase
of the fuzzy extractor to obtain R and P . Then, the offset
δ = R ⊕ I2 was concatenated with P to form the ID. The
procedure was repeated for each of the 108 individuals.
For the veriﬁcation phase, we quantiﬁed both the FNMR,
by applying the basic veriﬁcation module to biometric in-
puts collected from the same subject, and the FMR, by try-
ing to validate the ID against all the other subjects. First, the
1For each bit of the iris code, there is a correspondent masking bit that
denotes its quality; a one masking bit means that the iris code in that posi-
tion is affected by errors occurred in the segmentation procedure.
ID was split into δ and P . The Gen phase of the fuzzy ex-
tractor ensures that as long as a second iris code I(cid:48)
1 is close
enough to the iris code collected at enrollment, the secret
R might be obtained only from the knowledge of P . Obvi-
ously this condition should fail for an impostor. Therefore,
when the decoding operation RSdec(s ⊕ I(cid:48)
1) failed using
each of the four available iris codes in the validation set, the
Hamming distance between the two subjects being veriﬁed
was set to 1. Otherwise, with R and δ at hand, the ﬁn-
gerprint template might be retrieved, by computing R ⊕ δ.
Then, once acquired a second ﬁngerprint sample a biomet-
ric match could be performed, and its result determined the
success (or not) of the veriﬁcation procedure. The biomet-
ric match was performed with each of the ﬁve ﬁngerprint
images available.
We selected as references for a comparison the per-
formances of the two biometric systems based only on
iris or ﬁngerprint, respectively. Such performances were
evaluated on the same dataset and using an identical ap-
proach for enrollment and veriﬁcation (best-of-three in en-
rollment; best-of-four in veriﬁcation for the iris system and