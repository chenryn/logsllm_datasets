---
author: Greg Pittman
category: 软件开发
comments_data: []
count:
  commentnum: 0
  favtimes: 2
  likes: 0
  sharetimes: 0
  viewnum: 7884
date: '2018-03-27 11:19:10'
editorchoice: false
excerpt: 用一些简单的脚本，可以很容易地清理文档和其它大量的 HTML 文件。但是首先你需要解析它们。
fromurl: https://opensource.com/article/18/1/parsing-html-python
id: 9485
islctt: true
largepic: /data/attachment/album/201803/27/111914vfz045ksfbbdxuk0.png
permalink: /article-9485-1.html
pic: /data/attachment/album/201803/27/111914vfz045ksfbbdxuk0.png.thumb.jpg
related: []
reviewer: ''
selector: ''
summary: 用一些简单的脚本，可以很容易地清理文档和其它大量的 HTML 文件。但是首先你需要解析它们。
tags:
- HTML
- Python
thumb: false
title: 如何用 Python 解析 HTML
titlepic: true
translator: Flowsnow
updated: '2018-03-27 11:19:10'
---
> 
> 用一些简单的脚本，可以很容易地清理文档和其它大量的 HTML 文件。但是首先你需要解析它们。
> 
> 
> 
![](/data/attachment/album/201803/27/111914vfz045ksfbbdxuk0.png)
作为 Scribus 文档团队的长期成员，我要随时了解最新的源代码更新，以便对文档进行更新和补充。 我最近在刚升级到 Fedora 27 系统的计算机上使用 Subversion 进行检出操作时，对于下载该文档所需要的时间我感到很惊讶，文档由 HTML 页面和相关图像组成。 我恐怕该项目的文档看起来比项目本身大得多，并且怀疑其中的一些内容是“僵尸”文档——不再使用的 HTML 文件以及 HTML 中无法访问到的图像。
我决定为自己创建一个项目来解决这个问题。 一种方法是搜索未使用的现有图像文件。 如果我可以扫描所有 HTML 文件中的图像引用，然后将该列表与实际图像文件进行比较，那么我可能会看到不匹配的文件。
这是一个典型的图像标签：
```
```
我对 `src=` 之后的第一组引号之间的部分很感兴趣。 在寻找了一些解决方案后，我找到一个名为 [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) 的 Python 模块。 脚本的核心部分如下所示：
```
soup = BeautifulSoup(all_text, 'html.parser')
match = soup.findAll("img")
if len(match) > 0:
    for m in match:
        imagelist.append(str(m))
```
我们可以使用这个 `findAll` 方法来挖出图片标签。 这是一小部分输出：
```
```
到现在为止还挺好。我原以为下一步就可以搞定了，但是当我在脚本中尝试了一些字符串方法时，它返回了有关标记的错误而不是字符串的错误。 我将输出保存到一个文件中，并在 [KWrite](https://www.kde.org/applications/utilities/kwrite/) 中进行编辑。 KWrite 的一个好处是你可以使用正则表达式（regex）来做“查找和替换”操作，所以我可以用 `\n', all_text)
if len(match)>0:
    for m in match:
        imagelist.append(m)
```
它的一小部分输出如下所示：
```
images/cmcanvas.png" title="Context Menu for the document canvas" alt="Context Menu for the document canvas" />`，这被称为*贪婪*，意味着它不一定停止在遇到 `/>` 的第一个实例。我应该补充一点，我也尝试过 `src="(.*)"`，这真的没有什么更好的效果，我不是一个正则表达式专家（只是做了这个），找了各种方法来改进这一点但是并没什么用。
做了一系列的事情之后，甚至尝试了 Perl 的 `HTML::Parser` 模块，最终我试图将这与我为 Scribus 编写的一些脚本进行比较，这些脚本逐个字符的分析文本内容，然后采取一些行动。 为了最终目的，我终于想出了所有这些方法，并且完全不需要正则表达式或 HTML 解析器。 让我们回到展示的那个 `img` 标签的例子。
```
```
我决定回到 `src=` 这一块。 一种方法是等待 `s` 出现，然后看下一个字符是否是 `r`，下一个是 `c`，下一个是否 `=`。 如果是这样，那就匹配上了！ 那么两个双引号之间的内容就是我所需要的。 这种方法的问题在于需要连续识别上面这样的结构。 一种查看代表一行 HTML 文本的字符串的方法是：
```
for c in all_text:
```
但是这个逻辑太乱了，以至于不能持续匹配到前面的 `c`，还有之前的字符，更之前的字符，更更之前的字符。
最后，我决定专注于 `=` 并使用索引方法，以便我可以轻松地引用字符串中的任何先前或将来的字符。 这里是搜索部分：
```
    index = 3
    while index  '/tmp/actual_images.txt'
```
然后我需要在该文件上运行 `sortlist.py`，因为 `ls` 方法的排序与 Python 不同。 我原本可以在这些文件上运行比较脚本，但我更愿意以可视方式进行操作。 最后，我成功找到了 42 个图像，这些图像没有来自文档的 HTML 引用。
这是我的完整解析脚本：
```
#!/usr/bin/env python
# -*- coding: utf-8  -*-
# parseimg4.py
import os
def imagefound(all_text, imagelist, index):
    end = 0
    index += 2
    newimage = ''
    while end == 0:
        if (all_text[index] != '"'):
            newimage = newimage + all_text[index]
            index += 1
        else:
            newimage = newimage + '\n'
            imagelist.append(newimage)
            end = 1
            return
htmlnames = []
imagelist = []
tempstring = ''
filenames = os.listdir('/home/gregp/development/Scribus15x/doc/en/')
for name in filenames:
    if name.endswith('.html'):
        htmlnames.append(name)
#print htmlnames
for htmlfile in htmlnames:
    all_text = open('/home/gregp/development/Scribus15x/doc/en/' + htmlfile).read()
    linelength = len(all_text)
    index = 3
    while index 
作者：[Greg Pittman](https://opensource.com/users/greg-p) 译者：[Flowsnow](https://github.com/Flowsnow) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出