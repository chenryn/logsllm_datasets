W in §5). For a certain client and AP a, denote the (sorted, mono-
tonically non-decreasing) sequence of La ESNR readings in this
window by
(cid:2)
e1(a), . . . eLa
(a)(cid:3)
.
E(a) =
After sorting, we select the AP a∗
reading in the E(a) window:
(cid:4)
a∗ = arg max
a
e(cid:3)La/2(cid:4)(a)(cid:5)
with the maximal median ESNR
AP3
AP2
AP1
23
13
17
21
16
12 11
median
18
19
9
9
13
13
14
9
Sliding window (10 ms)
23
13
18
15
7
.
23
12
17
20
14
Time
Figure 6: WGTT AP selection: Choosing between three
nearby APs, Wi-Fi Goes to Town examines the median ESNR
reading from each, selecting in this case AP3 with the great-
est median SNR.
3.1.2 AP Queue Management. To rapidly switch between APs,
the WGTT controller forwards each downlink packet to all APs
within communication range of the client,1 while allowing just one
at a time (as determined by the AP selection algorithm) to transmit
packets to the client. Each other AP buffers downlink packets in
stop pkt
start pkt
User level
Switching
control
(cid:258)
(cid:258)
8
2k
8
0 1
2
567
3
4
567
Tail
Packet
transmission
(cid:258)
(cid:258)
8
2k
8
0 1
2
567
3
45
67
(cid:258)(cid:258)
Tail
Head
Queueing
Kernel level
mac80211
Driver
NIC
stop ioctl
ieee80211_ops.tx()
Head
mac80211
queue
Tx cyclic
queue
NIC internal
queue
Figure 7: Packet queueing in the WGTT AP.
the cyclic queue shown in Figure 7, which also summarizes all
other locations in the WGTT AP where packets are buffered. Both
packet switching and queue management require an index number
to identify each data packet. In WGTT, we define an m-bit index
number for each data packet, which increments by one for each
packet destined to a certain client. We set m = 12 to guarantee the
uniqueness of each index number in each client’s cyclic buffer.
When the controller switches from one AP to the next (e.g., AP1
to AP2), there are roughly 1,600 (at 50 Mbit/s UDP offered load)
to 2,000 packets (at 90 Mbit/s UDP offered load) backlogged in
AP1’s queues, at various layers of the networking stack as shown
in the figure 7. Unless dequeued, AP1 will attempt to deliver these
backlogged packets to the client, likely failing, thus sacrificing
channel capacity and disrupting any ongoing TCP flows to that
client.
WGTT’s switching protocol. When the controller determines
that the client should be switched from AP1 to AP2, it instructs AP1
to tell AP2 which packets are backlogged in its queues. Since these
backlogged packets are already buffered in AP2’s cyclic queues even
before the switch, AP2 can then deliver them to the client almost
immediately. This switching protocol consists of the following three
steps:
(1) The controller sends a stop(c) control packet to AP1, instructing
it to cease sending to the client c. The stop packet contains the
layer-2 addresses of c and AP2.
(2) After receiving stop(c), AP1 ceases sending to c, and sends to
AP2 a start control packet containing c and the index k of the
first unsent packet destined to c: start(c, k).
(3) After receiving start(c, k), AP2 sends an ack control packet back
to the controller, and begins transmitting packets from its cyclic
queue at index k to the client.2
After the switch, AP2 continues delivering new downlink packets
received from the controller to c. In the absence of control packet
loss, the switch will be accomplished after these three steps. How-
ever, both the control packet and the ack packet may be lost, and
so we set a timeout for the control packet retransmission. If the
controller does not receive the ack within 30 ms, it retransmits the
1Those APs that have received a packet from the client within the AP selection window
W .
2The controller will not issue another switch until the current issued switch is
acknowledged.
325
Wi-Fi Goes to Town: Rapid Picocell Switching for Wireless Transit Networks
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
stop packet. On the other hand, since the control and ack pack-
ets manage the downlink packet switching, these packets should
be processed promptly for switching delay minimization. In the
WGTT AP, incoming control packets are prioritized, bypassing the
cyclic queue. Control packets are thus given higher priority, so that
they are always been processed ahead of data packets and thereby
minimizing switching delay.
Table 1: Measuring the running time of the switching proto-
col in different data rate settings.
Data rate (Mb/s)
Mean execution time (ms)
Standard deviation (ms)
50
17
3
60
19
5
70
21
4
80
19
5
90
17
3
Running the switching protocol takes over 17 ms on average (as
shown in Table 1), During the time that the switch is happening, we
allow AP1 to send the backlogged packets buffered in its hardware
NIC queue. These packets take 6 ms to deliver, thus although they
are sent over AP1’s inferior link, the capacity loss is minimal.3
Implementing the switch. We modify the ieee80211_ops_tx()
function in the Linux kernel to keep track of the index of the last
packet destined to each client just before it enters the NIC’s hard-
ware queue. When AP1 receives a stop(c) packet from the controller,
it queries the index number for c in the kernel through an ioctl
system call: this is the first unsent packet destined to c (index num-
ber k). The ieee80211_ops_tx() function replies and then monitors
the backlogged packets that flow out of the driver’s transmit cyclic
queue and filters out packets destined to c. Upon receiving the
packet index from the kernel, AP1 sends start(c, k) to AP2.
3.1.3 Packet addressing and tunneling. In the controller, both
the layer-2 and layer-3 headers of the downlink packet have the
destination set to the addresses of the clients. We cannot change
them to the AP’s addresses, otherwise the AP cannot decide which
client the packet should be delivered to, so we tunnel downlink
packets in an IP packet with the AP’s IP address in the destination
field.
3.2 Uplink packet flow
On the uplink, WGTT introduces a new technique, block acknowl-
edgement forwarding, that integrates with frame aggregation to
make block acknowledgements more reliable, reducing retransmis-
sions on the downlink.
3.2.1 Block acknowledgement forwarding. The Wi-Fi block ac-
knowledgement mechanism (first introduced in the 802.11e stan-
dard) improves channel efficiency by aggregating multiple packet
acknowledgements into one frame. The block acknowledgement
(Block ACK) contains a bitmap to selectively acknowledge indi-
vidual frames in a window of packets. When the client moves at
vehicular speed, its Block ACK is prone to loss due to the construc-
tive and destructive wireless multipath fading, especially near the
edges of an individual AP’s coverage. In this case, the AP retrans-
mits all packets that should be acknowledged in the lost Block ACK,
3We intend to further optimize switching time with kernel-level Click cyclic queue
implementations in future work.
hurting throughput and channel utilization. In WGTT, we exploit
path diversity, designing a link-layer protocol to allow APs not
currently talking to the client to forward an overheard Block ACK
to the client’s current AP over the Ethernet backhaul.
AP2 (adjacent)
User level
Kernel
AP1 (currently associated)
User level
Kernel
ath_tx_complete_aggr ()
enabled
Interface 2
Interfaff ce 2
Interface 1
AP mode
Monitor mode
UDP
ath_tx_complete_aggr ()
disabled
Interface 2
Interface 1
AP mode
Monitor mode
Atheros NIC
Atheros NIC
Figure 8: WGTT’s Block ACK forwarding design.
Specifically, we create two virtual NIC interfaces for each AP,
with one working in AP mode to handle normal uplink/downlink
packet flows, and another working in monitor mode to overhear
packets and captures block ACKs. The monitor mode interface is
disabled in the AP that the client currently associated with. As
shown in Figure 8, upon receiving a block ACK, AP2 extracts the
layer-2 source address (client’s address), the sequence number of
the first packet that should be acknowledged in this Block ACK, and
the Block ACK bitmap, encapsulating them into a UDP packet, and
forwarding this UDP packet to AP1. Upon receiving the information,
AP1 first checks whether this Block ACK has been received before
(from its own NIC or from other APs). If so, AP1 drops the forwarded
block ACK. Otherwise, it updates the ath_tx_status data structure
using the received information, and inputs this data structure to
the function ath_tx_complete_aggr()4, where the newly updated
block ACK bitmap is examined. The result is that the effective block
ACK loss rate will decrease.
3.2.2 Packet addressing and tunneling. Uplink packets sent from
a client are received by one or more APs, which encapsulate the
packet in an UDP/IP and 802.3 header, putting the source layer-2
and layer-3 address as the received AP, and the destination host
as the controller. Consequently, the controller can record from
which AP the received packet is sent. The controller then strips
the tunneling header of the packet and de-duplicate packets by
checking the source IP address and the IP sequence number of
incoming packets. To speed up the de-duplication process, we use a
hashset and compose a 48-bit key unique to a specific packet using
the source IP address and the IP identification field of this packet.5
3.2.3 Packet de-duplication. As all APs in the network are suc-
cessfully associated with the client, they all forward uplink packets
heard from the client to the controller, resulting in packet dupli-
cation, which can lead to spurious TCP retransmissions, harming
throughput. Hence the controller needs to de-duplicate uplink pack-
ets before forwarding them to the Internet.
4While all ath functions are specific to the Atheros driver, similar functions can be
found in other drivers due to the generic interface of Linux OS.
5Not all packets have IP header: for those without an IP header, we only consider ARP
packets, where we don’t need de-duplication.
326
SIGCOMM ’17, August 21-25, 2017, Los Angeles, CA, USA
Zhenyu Song, Longfei Shangguan, and Kyle Jamieson
78
6
5
34
2
1
d
r
i
v
i
n
g
Figure 9: Experiment setup: we deploy eight WGTT APs on
the third floor of an office building overlooking a side road
with speed limit 25 mph. The radio coverage overlaps be-
tween adjacent APs.
Figure 10: Effective SNR heatmap measured at each AP. In
each heatmap the x-axis refers to distance along the road, y-
axis refers to distance across the road. The AP radio coverage
overlaps by between 6 m and 10 m.
4 IMPLEMENTATION
We implement the WGTT AP and controller logic on commodity
routers and laptops using the Click modular router [9], and deploy
a testbed on the third floor of an office building overlooking a
side road with speed limit 25 mph (as shown in Figure 9). The
testbed is composed of eight WGTT APs interconnected with each
other through the Ethernet backhaul. The controller connects to
the routers through Ethernet backhaul as well. The router works on
the channel 11 of the 2.4 GHz frequency band, without modification
of the default rate control algorithm. WGTT’s small cell limits the
delay spread to a value similar to an indoor environment. So the
length of the standard Wi-Fi cyclic prefix is sufficient. Figure 10
shows the ESNR heatmap of the road we measured at each AP.
We can see the ESNR distribution is coherent with the location
distribution of eight APs deployed along the roadside.
4.1 Controller
Hardware. The WGTT controller is a Lenovo Thinkpad T430
laptop[45], equipped with a Intel Core i5-3320M CPU, 8 GB DDR3
RAM, and a 160 GB Solid State Drive (SSD). We install two USB
ethernet adaptors on it, one for LAN packet processing and another
327
(a)
(b)
(c)
Figure 11: The WGTT AP is composed of (a) a directional
antenna that connected to three ports of TP-Link AP via a
splitter (b). (c): the AP is deployed in front of a window.
for the WAN.
Implementation. The controller runs Ubuntu Linux v14.04 LTS.
We write click elements for our control logic and install rules block-
ing the Linux kernel from receiving any packets received from the
NIC, so Click is the only application with access to the NIC.
4.2 Access Point
Hardware. We build the WGTT AP using a TP-Link N750 AP [46]
equipped with an Atheros AR9344 NIC, which measures the CSI of
each incoming frame and forwards it to the controller for process-
ing. We detach the default omnidirectional antennas of this router
and connect it to a 14 dBi, 21-degree beamwidth Laird directional
antenna [26] using a Mini-Circuits ZN3PD-622W-S+ RF splitter-
combiner (as shown in Figure 11).6 Notice that since the WGTT
software design is hardware-agnostic, it is possible to replace the
directional antenna with small-cell omni-directional antenna.
Implementation. The TP-Link router runs openwrt Chaos Calmer
v15.05.1 [35]. We write click elements for AP control logic and a
click configuration ap.click on it to (i) manage the packet queue and
(ii) encapsulate uplink packets and forward them to the controller.
The Atheros NIC on the TP-Link router computes the CSI of each
uplink packet (using the CSI tool [18]), encapsulating the CSI and
client information into a UDP packet, and delivering this packet to
the controller through the Ethernet.
4.3 Client Association
Like other wireless local area network designs that utilize “thin APs”
coupled with a centralized controller, WGTT APs all share the same
802.11 basic service set identifier (BSSID), and so appear as one AP
to the client. When a client associates with the first AP (e.g. AP1),
WGTT synchronizes the association with all APs in the network. To
achieve this goal, we modify hostapd in the user space of the Linux
wireless system, letting AP1 send the client information (layer-2
address, authorization state etc.) to other APs through the Ethernet
backhaul. Specifically, at the end of the client association with AP1,
the hostapd of this AP will receive an association callback, signal-
ing that hostapd’s association confirmation to the client has been
received. AP1 then moves the client information sta_info struct to a
6As all cables to the splitter-combiner are short and of equal length, this results in one