# Decision-Support for Certification by Calculating the Evidential Volume of a Product

**Authors: Silke Kuball and Gordon Hughes**

**Affiliation:**
Safety Systems Research Centre  
Faculty of Engineering  
University of Bristol  
Woodland Road, Bristol BS8 1UB, UK  
Email: [PI:EMAIL], [PI:EMAIL]

## Abstract
In this paper, we present an approach to quantify the degree of compliance of a product with an industry standard, such as the international standard for functional safety of E/E/PE systems, IEC 61508. We term this measure the "evidential volume" of an assessment scenario. The evidential volume is calculated by compiling observed evidence according to assigned weighting factors, which reflect the relative importance of each piece of evidence. This measure can be used as an indicator to compare different assessment scenarios, potentially improving consistency in assessments. We propose a model to relate the evidential volume to the probability of achieving a product with the required safety integrity. This relationship can serve as a decision-aid for acceptance or rejection, or to determine if additional evidence, such as statistical testing, is needed to meet the target safety integrity. Our model is based on the Success Likelihood Index Model (SLIM) and represents an initial step towards decision-support for assessments. The proposed model is applicable to any standard, with IEC 61508 serving as an example.

## 1. Introduction
Systems containing software and/or programmable electronic systems are increasingly used in safety-critical applications, such as nuclear protection systems and avionics. This trend has heightened the need for guidance on the development and assessment of safety-related systems. Industry standards and guidelines, such as DO-178B (avionics), IEEE/EIA 12207 (defense), IEC 61508 (all industry sectors), and PES Guidelines (nuclear), support the development and maintenance of safe and reliable systems. Although adherence to these standards does not guarantee reliability, it helps implement techniques that form the basis of safe and reliable products. Compliance with a standard can be part of a safety case, complementing more quantitative methods like statistical testing (ST), which estimate reliability figures but do not directly scrutinize the design and development process.

Our long-term goal is to combine both assessment routes: standards/certification and ST. Specifically, we aim to answer the following questions: "Can we integrate the evidence from certification and ST into a single reliability measure?" and "Does the groundwork performed in design and development justify the effort of ST?" This could be achieved by using certification evidence as prior input for ST, requiring the expression of certification evidence as a prior distribution for the system's probability of failure on demand (pfd). To advance this complex topic, we start by formulating an approach to measure the degree of compliance of a product with a standard. This measure has two uses: 1) direct use as decision-support in assessments, and 2) transformation into a statement of confidence on the pfd target, which can be translated into a prior distribution for the pfd. We suggest methods for both uses, but these are initial ideas that require feedback from a broader audience.

The measure introduced in Sections 3 and 4 of this paper will express the "overall picture" of evidence available with respect to a standard, providing a consistent and repeatable measure of the total volume of related evidence. Initially, it can be used alongside expert judgment to aid in deciding on the acceptance or rejection of a system. Due to our focus on the industry, we will primarily refer to IEC 61508 and the PES Guidelines, but the methodologies proposed are applicable to any standard.

## 2. Motivation
The international functional safety standard IEC 61508 (Functional Safety of E/E/PE Safety-Related Systems) provides guidance on the development and assessment of safe and reliable systems consisting of hardware, software, or a combination of both. It describes the overall safety lifecycle of a system or component, consisting of 16 phases, and provides generic guidance for all safety lifecycle activities. The achievement of functional safety is supported through a wide range of measures, techniques, and principles related to both the process and the product.

The PES Guidelines are a smaller, more accessible document tailored to the use of programmable electronic systems (PES) in nuclear safety-related applications. They describe eight main phases, including Specification of Safety Requirements, Design for Safety, and Validation. These guidelines also provide guidance on the use of standards such as IEC 61508.

Both documents make claims on the pfd of a system and its components. According to IEC 61508, starting with a hazard and risk analysis, safety requirements are identified for each safety function and then translated into claims on the pfd for the components implementing the function. These claims are expressed through Safety Integrity Levels (SILs) in IEC 61508 and Integrity Targets (ITs) in the PES Guidelines. SILs represent bands in which the system pfd should lie, while ITs are upper bounds on the pfd, coinciding with the left boundary of the SIL bands.

Throughout this paper, we refer to the techniques and principles listed in a standard as requirements. The set of requirements recommended in IEC 61508 becomes more stringent for higher SILs. Standards thus link a set of procedures (the requirements) described in the document to the target pfd of a safety-related system or component. This link is not derived through any quantitative method, but it is assumed that following the standard conscientiously makes achieving the pfd target value reasonably probable.

Our work began by trying to assess, through expert elicitation, what "reasonably probable" might mean. We offered intervals of pfd values and aimed to assess where expert belief would place the most confidence and how the confidence would be spread. We observed that experts familiar with probabilities were more inclined to express their beliefs in this way, while those not used to working with probabilities preferred binary statements such as "the target is met or not." Probabilities may not be a straightforward way for experts in software development, testing, and management to model their experience. Therefore, we decided to adjust our strategy and aim for an alternative formulation of the "rating" of a product based on compliance with a standard. We developed a model that requires deterministic input from experts, such as "accept/reject" statements and rankings of the importance of different pieces of evidence. This approach aims to use language that relates more to the practice of these experts, enabling us to tap into their expertise more authentically.

The quantification of assessment outcomes has been tackled differently by Gran et al. in [3], where prior belief distributions on the system pfd are elicited from experts conditioned on the evidence accumulated during assessment. However, this approach requires some accumulated evidence or history, which was not the case in our work. Before introducing our approach to measure compliance with a standard in Sections 3 and 4, we will introduce the structure of evidence encountered in the example of IEC 61508.

### 2.1 Structure of Evidence
IEC 61508 depicts the overall safety lifecycle as consisting of 16 phases. Figure 1 provides a sketch of the structure of IEC 61508. The output generated during one phase typically serves as input to succeeding phases. The structure in Figure 1 is laid out over four sections. Section 1 lists the main phases, which may be split into sub-phases (Section 2). These sub-phases may again be split into further sub-phases (Section 3) before a set of requirements is listed (Section 4).

Phases and sub-phases generally refer to different parts of the safety lifecycle, while the requirements listed for a phase or sub-phase represent diverse sources of evidence contributing to the same lifecycle task. For example, the phase "Software Realisation" in Section 1 contains sub-phases such as "Safety Requirements Allocation" and "Design and Development." We call "Software Realisation" the parent phase of "Safety Req. Allocation." Sub-phase "Design and Development" in Section 2 includes a series of sub-phases, such as "Architecture," "Code Implementation," or "Module Testing." For "Code Implementation," a set of example requirements is listed under Section 4 in Figure 1. Figure 1 does not replicate the entire safety lifecycle as described in [1] but shows an excerpt for illustrative purposes.

The question we aim to address in the next section is: "How does the evidence collected during assessment influence the confidence in having achieved a system of target integrity?" In some way, the degree to which the requirements listed for a sub-phase have been followed will be an indicator of the quality of that phase, influencing the quality achieved with its parent phase, and ultimately, the product's overall ability to comply with the safety claim. If important evidence is missing, this will impact the confidence in the system's safety integrity.