title:Decision-Support for Certification by Calculating the Evidential Volume
of a Product
author:Silke Kuball and
Gordon Hughes
Decision-Support for Certiﬁcation by Calculating the
Evidential Volume of a Product
Silke Kuball, Gordon Hughes
Safety Systems Research Centre
Faculty of Engineering
University of Bristol
Woodland Road, Bristol BS8 1UB, UK
PI:EMAIL, PI:EMAIL
Abstract
In this paper we describe an approach to capture the de-
gree of compliance of a product with an industry standard
such as the international standard for functional safety of
E/E/PE systems, IEC 61508. We call this the evidential vol-
ume of an assessment scenario. It is based on compiling
observed evidence according to assigned weighting factors,
which describe the relative importance of each piece of evi-
dence. The evidential volume can by itself be used as an
indicator to compare different assessment scenarios. This
could form the basis for improved consistency in assess-
ment. We suggest a model to relate the evidential volume
to the probability of having achieved a product of required
safety integrity. Developing such a relationship can lead to
a decision-aid on acceptance or rejection or can be used
to decide whether additional evidence, such as statistical
testing could be used to achieve target safety integrity. The
model we suggest is based on the Success Likelihood Index
Model (SLIM) and it poses an initial step towards decision-
support for assessment. The model developed can be used
for any standard, IEC 61508 is used as an example only.
1
Introduction
Systems cointaining software and/or programmable
electronic systems are increasingly used within safety-
critical applications such as nuclear protection systems or
avionics. This results in an increased need for guidance
on the development and assessment of safety-related sys-
tems. One of the routes that support the development and
maintenance of safe and reliable systems is the use of indus-
try standards and guidelines such as for example DO-178B
(avionics), IEEE/EIA 12207 (defense), IEC 61508 (all in-
dustry sectors), PES Guidelines (nuclear). Even though the
use of standards and guidelines itself does not guarantee
reliability, it helps to implement techniques that are con-
sidered to be the basis of safe and reliable products. Com-
pliance with a standard can form part of a safety case. It can
be seen as a technique complementary to more quantitative
methods such as statistical testing (ST), which estimate a re-
liability ﬁgure but do not directly scrutinize the process of
design and development. Our long-term goal is the combi-
nation of both routes of assessment: standards/certiﬁcation
and ST. On the long-term, we want to answer the follow-
ing questions: “Can we combine the evidence seen dur-
ing certiﬁcation and during ST into one reliability mea-
sure?” “Does the groundwork performed in design and de-
velopment for any particular component look sound enough
to justify launching into the effort of ST?” This could be
achieved by considering the information provided through
certiﬁcation evidence as prior input to ST. This requires to
express the message of the certiﬁcation evidence in the form
of a prior distribution for the system probability of failure
on demand (pfd). To advance on this complex topic, we
start in this paper by formulating an approach, which mea-
sures the degree of compliance of a product with a standard.
For this measure there are then two uses. 1) The direct use
of the calculated ﬁgure as decision-support in assessment.
2) The transformation of the ﬁgure into a statement of con-
ﬁdence on the pfd target. This statement can in principle be
translated into a simple prior distribution for the pfd. We
suggest methods to cover 1) and 2). However, these are ini-
tial ideas and they require feedback from a wider audience
before being developed further.
The measure introduced in sections 3 and 4 of this paper
will express the “overall picture” of evidence available with
respect to a standard, a measure for the total volume of
related evidence. This measure is repeatable and provides a
high degree of consistency between assessment scenarios.
In the ﬁrst instance,
it could be used alongside expert
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
judgement and aid in deciding on acceptance or rejection
of a system.
Due to the requirements of the industry we work
with, our focus in this paper is on IEC 61508 [1] and the
PES (Programmable Electronic Systems) Guidelines [2],
and we shall refer to these two documents throughout
the paper. However, it should be noted that any other
standard/guideline could be inserted,
the methodologies
proposed would remain the same.
2 Motivation
The international functional safety standard IEC 61508
(Functional safety of E/E/PE safety-related systems) [1]
aims at providing guidance on the development and assess-
ment of safe and reliable systems consisting of hardware,
software or a combination of both. It describes the overall
safety lifecycle of a system or component as consisting
of 16 phases and provides generic guidance for all safety
lifecycle activities. The achievement of functional safety
is supported through a wide rande of measures, techniques
and principles relating both to the process and the product.
The PES Guidelines [2] are a smaller, more accessible
document
tailored to the use of PES (Programmable
Electronic Systems) in nuclear safety-related applications.
They describe 8 main phases including Speciﬁcation of
Safety Requirements, Design for Safety, Validation etc.
Among the purposes of [2] is to provide guidance on the
use of standards such as IEC 61508.
Both documents operate with claims on the pfd of a sys-
tem and its components. According to IEC 61508, start-
ing with a hazard and risk analysis, safety requirements
are to be identiﬁed for each safety function and then trans-
lated into claims on the pfd for the components implemen-
ting the function. These claims are expressed in IEC 61508
through the concept of Safety Integrity Levels (SILs) and in
the PES Guidelines through the notion of Integrity Targets
(ITs). SILs represent bands in which the system probability
of failure on demand (pfd) should lie. Examples are:
, 10−2[, SIL3 : pf d ∈ [10−4
SIL2 : pf d ∈ [10−3
, 10−3[.
(1)
Integrity Targets are upper bounds on the pfd, such as
IT 10−3, IT 10−4. They coincide with the left boundary of
the SIL bands. Throughout this paper, we refer to the tech-
niques and principles listed in a standard as requirements.
The set of requirements recommended in [1] becomes more
stringent for higher SILs. Standards thus contain a link be-
tween a set of procedures (the requirements) described in
the document and the target pfd of a safety-related system
or component. This link is not derived through any quan-
titative method. In spite of this, one has to assume that the
expertise poured into the compilation of a standard is such
that by following the standard conscientiously, achievement
of the pfd target value becomes reasonably probable. Our
work on this topic started off by trying to assess through
expert elicitation what “reasonably probable” might mean:
99%?, 75%? We offered intervals of pfd values and aimed
at assessing where expert belief would put most conﬁdence
and how the conﬁdence would be spread. We observed that
an expert who is used to working with the notion of pro-
babilities is more inclined towards expressing their belief
in this way. An expert who is not used to working with
probabilities in this context, on the other hand, was inclined
more towards using binary statements such as “the target
is met or not”. Probabilities are not necessarily a straight-
forward way for experts in the areas software development,
-testing and -management to model their experience with.
Thus, the information elicited through probabilities may not
serve to convey an authentic picture of these experts’ be-
liefs or experience. We thus decided to adjust our strate-
gy and to aim at an alternative formulation of the “rating”
of a product based on compliance with a standard. First
of all, we wanted to capture the assessment outcome in a
way that requires mostly deterministic input from experts
rather than probability values or tables. Thus we developed
a model that requires as input from assessors or engineers
“accept/reject” statements as well as rankings of importance
of different pieces of evidence. Thus, we try to use language
that relates more to the practice of these experts. We believe
that this enables us to tap into the available expertise in a
more authentic way. Of course, this is just one approach to
tackle the issue, however, since it developed in the course
of this project through discussions with and feedback from
industrial collaborators, we believe that other parties might
beneﬁt from it as well. The approach introduced in this pa-
per can be easily applied to any standard.
The quantiﬁcation of assessment outcomes has been
tackled in a different way by Gran et al. in [3]. Here, prior
belief distributions on the system probability of failure on
demand (pfd) are elicited from experts conditioned on the
evidence that was accumulated during assessment. Such
prior belief distributions can often be conveniently com-
bined with the results of statistical testing and thus a com-
bined reliability measure can be derived. However probabil-
ity tables can only be reasonably derived if there is some ac-
cumulated evidence or history present that allows the inter-
viewed person to at least put a rough estimate on the prob-
ability based on their experience and in the context of our
work this was not the case. Before introducing an approach
to measure compliance with a standard in sections 3 and 4,
we will introduce the structure of evidence encountered in
the example of IEC 61508.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
Section 1
Section 2
Section 3
Section 4
Concept
Hazard & Risk 
Analysis
Safety Requirements
Allocation
Software
Realisation
S/w safety req.
allocation
Requirements:
Determine hazards and
hazardous events
Likelihoods of hazardous
events
Evaluate EUC risk
Etc.
S/w Design and
development
Architecture
Support tools & PLs
Module design
Code Implementation
Module tests etc
S/w safety 
validation
planning
S/w safety
validation
Requirements:
PL unambiguously def.
Coding Standards
No dynamic objects
Limited use of pointers
Etc.
Figure 1. Excerpt from safety lifecycle as described in
IEC 61508.
2.1 Structure of evidence
IEC 61508 depicts the overall safety lifecycle as consis-
ting of 16 phases. Fig. 1 depicts a sketch of the structure of
IEC 61508. Mostly the output generated during one phase
serves as input to succeeding phases. The structure in Fig.
1 is laid out over 4 Sections. In Section 1 the main phases
are listed. These may be split into sub-phases, which are
shown under Section 2. These sub-phases may again be
split into sub-phases (shown under Section 3) before ﬁnally
a set of requirements is listed, shown under Section 4.
Mostly phases and sub-phases refer to different parts of
the safety lifecycle, whereas the requirements listed for a
phase or sub-phase represent diverse sources of evidence
contributing to the same lifecycle task. For example, the
phase Software Realisation in Section 1 contains among
others the sub-phases Safety Requirements Allocation and
Design and Development. We call Software Realisation
the parent phase of Safety Req. Allocation. Sub-phase
Design and Development in section 2 contains a series of
sub-phases building on each other such as Architecture,
CodeImplementation or ModuleTesting. For CodeImple-
mentation, a set of example requirements is listed under
Section 4 in Fig. 1. Fig. 1 does not attempt to replicate the
entire safety lifecycle as described in [1], it only shows an
excerpt for illustrative purposes.
The question we want to tackle in the next section is:
“How does the evidence collected during assessment inﬂu-
ence the conﬁdence in having achieved a system of target
integrity?” In some way, the degree to which the require-
ments listed for a sub-phase have been followed will be an
indicator towards quality of that phase; this will inﬂuence
the quality achieved with its parent phase, and ﬁnally this
will be indicative of the product’s overall ability to comply
with the safety claim. If important evidence is missing, this