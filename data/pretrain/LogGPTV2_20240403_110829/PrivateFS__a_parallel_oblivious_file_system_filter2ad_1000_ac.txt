n round trips per
75 ms. Single clients, incurring log2
query, are tightly bound by the round trip time. Adding
more parallel clients increases this throughput linearly,
up to the point where bandwidth limits from the query
log traﬃc take over.
To ﬁnd the optimal number of clients c for a given conﬁg-
uration the lower of these upper bounds needs to be maxi-
mized. This relationship is plotted in Figure 3 for a repre-
sentative setting.
1To disseminate this information in a more network-eﬃcient
manner, e.g., by only requesting the log entry the client
is interested in (instead of the entire log) a PIR protocol
may be deployed. This results in a tradeoﬀ between server
bandwidth and server CPU time. This tradeoﬀ is mostly
unfavorable [15], yet recent results [10] indicate that it may
become feasible in the near future.
After c queries execute, the query log is converted into the
ORAM top level. Queries are thus applied to the database,
in the ORAM-sense (Figure 4). This is where the require-
ment of a “period-based” Instance is necessary.
Remote ID Log Remote Results Log
q
read
x1 Contents
x2 Contents
x3 Contents
x4 Contents
x1
x2 write
read
x3
x4
read
q+1
q+2
q+c
Shuffler
Top Level
For each block, take
the last write or first read
unique blocks and fakes
Figure 4: Reconciliation of the query log into the new
top level. After a period of c queries, the query log is
shuﬄed and becomes the top level. Regarding the query
log hosted set of ids, consider that a block can only be
read once from the ORAM during this period. Thus, the
correct value for a given block is either the last write of
this period, if there is one, or otherwise the ﬁrst read.
In the process, the shuﬄer consolidates the query log.
A single block may be accessed multiple times by diﬀer-
ent queries, but is placed only once back into the database.
The value chosen for a given block is the last write, if there
is one, or otherwise the ﬁrst read. Recall that subsequent
reads are associated with fake results.
Properties.
optimality and query privacy.
It is time to informally deﬁne two properties:
Theorem 1. In any model in which the server can as-
sociate all visible read/write data accesses corresponding to
a given query, hiding access patterns in a “non-simultaneous
ORAM” requires waiting for the results of all previous queries
(“wait-optimality”).
Proof. Take any “non-simultaneous” ORAM that requires
serial execution of queries for the same underlying block. In
such an ORAM, repeating the query before the previous
query has completed would result in overlap between visi-
ble data accesses, and would allow an adversary to correlate
these queries.
Thus, instead of attempting to repeat a previous query,
clients must obtain the result from it once that query has
ﬁnished executing.
To make all query sequences indistinguishable to the server,
even in a parallel ORAM, clients still need to wait for the
prior queries, as if their query depended on each of the pre-
vious queries (lest they reveal which query they are waiting
for, if any).
Theorem 2 shows that running parallel queries in this
model is safe. The intuition is as follows.
In the parallel
case, client behavior from the perspective of the server is
identical for each new query instance regardless of whether
and how often the same equivalent query appears earlier in
the log. For every query, the server only sees a semantically
secure encrypted append operation to the query log, a query
to the underlying ORAM, and a scan of the results log up
to that point.
982The only diﬀerence now is that transcripts of the diﬀerent
queries are interleaved, but otherwise contain the same ac-
cesses as when executed in a traditional ORAM. This is so
because in the parallel case, if a client queries for a block that
is already queried for by a simultaneously ongoing query, the
client’s ORAM Instance will instead issue a fake query—
which is what it would have done anyway in the traditional
ORAM had it found the query result at the top level. Thus,
from the server’s point of view, the transcripts contain the
same (random looking) accesses.
Further, query transcripts are independent of their query
and, without knowledge of the secret ORAM key, indistin-
guishable from random, as required by Deﬁnition 18 of tra-
ditional ORAM [2]. Then, an advantage at distinguishing
the new transcripts translates into an equivalent advantage
at distinguishing the underlying ORAMs if parallelism were
not enabled.
Theorem 2. Existence of an adversary with non-negligible
advantage at violating query privacy (as in Deﬁnition 18 [2])
in a parallel ORAM implies existence of an adversary with
non-negligible advantage at violating the privacy of the un-
derlying single-client ORAM (“query privacy inheritance”).
Proof. Take an adversary A with advantage  at corre-
lating queries in a parallel ORAM based on an underlying
ORAM O. We now construct an adversary B with equiva-
lent advantage at correlating queries in O.
B simulates adversary A on every query. Since the in-
terleaving information is publicly known, it includes this in-
formation in the transcripts it uses to simulate A.
It ap-
pends random information to the query log contents for A.
These query log contents give A no additional non-negligible
advantage; otherwise a distinguisher could be built distin-
guishing the semantically secure encryption function output
from random.
B then outputs the guesses and requests provided by A,
and obtains the same advantage as A.
5.3 De-amortization abstraction / construction
Definition 2. A level-based amortized ORAM In-
stance is an ORAM that searches levels recursively, append-
ing the result back to the ﬁrst level. Privacy results from the
property than an item is sought at a particular level no more
than once between two consecutive shuﬄes of that level.
De-amortization techniques need to deal eﬃciently with
the level constructions resulting from overﬂow of the top
levels. Their goal is to arrange the levels such that they can
be queried while the items are simultaneously being inserted
and re-shuﬄed into new levels. That is, instead of suspend-
ing querying to wait for shuﬄing to proceed, a new level
must be available as soon as it is needed.
The main idea is to provide pre-emptive shuﬄing. Rather
than waiting for querying to complete before shuﬄing a
level, its transformation into a new level begins as soon as a
level is constructed, and right as its querying begins.
To allow this, we duplicate a level into two copies: a read-
only variant that is used in the querying process, and a
writable variant which is dynamically updated into the new
generation of this level. The read-only copy is discarded at
the end of the period.
Level De-amortization. Consider the de-amortization
of a single level. In a traditional ORAM, a level is recon-
structed by combining into it the above level that has ﬁlled
up and now overﬂows (Section 2.1). This necessarily stops
the query process for its duration.
To de-amortize this, when beginning its construction, in-
stead of pausing queries and waiting for the construction
to ﬁnish, querying can continue via the read-only level copy
while a new generation is produced into the writable variant.
Critically, during this process, existing levels can overﬂow
into a fresh, empty, replacement for this level. (Figure 5).
Original 
database
Intermediate
database
Resulting 
database
New empty level
Read-only
New copy of
bottom level, 
undergoing shuffle
Delete log
Figure 5: Background construction of a single level. The
top section represents the initial database state; the mid-
dle section shows the database state during the process
of constructing the new bottom level; the bottom sec-
tion shows the resulting database state. In this scenario,
the third level is full, so it needs to be combined with
the fourth level. Read-only copies of those two levels
are made, and can be queried while the combination is
occurring. Simultaneously, overﬂows from the top level
are placed into the a replacement third level. All ﬁve
levels are accessed during queries at this time. Once the
construction of the bottom level is complete, querying
resumes with this new bottom level replacing the two
read-only levels (which contain the same items).
Delete Log. The second change is to delay level updates
until the end of the shuﬄe. Some ORAMs avoid the com-
plexity of reconciling multiple versions of an item (and in the
process, reduce storage overheads) by deleting blocks from
the levels where they are found. In the de-amortized con-
struction, this is not possible, since the queried level copies
are now read-only.
Instead, these changes are appended
to an update log.
Items marked for deletion in this log
are now deleted by the server before the next shuﬄe of the
level. Not all ORAMs modify the pyramid structure during
queries; some [2] do not need such modiﬁcation. This de-
amortization protocol requires that those changes that are
made can be applied after the level has been reconstructed.
Details. A level at height i, containing m = c2i items, is
queried m times. At the end of the mth query, the shuﬄe
983will have completed, and the remaining items from this level
are now in a new level.
Each level is a data set, completely speciﬁed by its height
i, the sequentially increasing “generation” j at that height,
and a one-bit marker for the odd generations. The two levels
at an even generation j, denoted by i.j and i.j.∗, are com-
bined to produce a level at the next height i + 1, generation
j/2. Those levels at a height i with an odd generation j are
reshuﬄed to produce level i.j + 1.∗.
The levels currently reshuﬄed are the ones queried – at
any one time there are either one or two active levels (queried
and being shuﬄed) at each given height, for i ≤ log2 n.
The above construction allows de-amortization of the con-
struction of all the levels except the top level. De-amortization
of the top level appears to be possible using a rotating query
log, but is left as future work (since its impact is minimal as
the top level is very small).
If based on an underlying stateless period-based amortized
ORAM, the result is a stateless period-based de-amortized
ORAM, suitable for parallelization.
Theorem 3. A polynomially bounded adversary has no
non-negligible advantage at guessing the access pattern based
on observing the transcripts of a de-amortized ORAM.
Proof. For simplicity, the proof is given for BF ORAMs
(Section 5.4) but property should hold for any secure under-
lying level-based ORAM. The output of the underlying BF
ORAM level construction process is shown in previous work
to be a randomly ordered set of stores (ID,value pairs). Both
the ID and value are opaque; that is, the server cannot dis-
tinguish them from random. The only other time the server
sees this opaque ID is when the ID is retrieved later on. The
same opaque ID is never retrieved twice. BF locations are
also accessed in a manner uncorrelable to the access pattern,
as the locations corresponding to any ID are chosen with a
pseudo-random number generator.
Theorem 4. If the underlying level-based ORAM destroys
inter-item correlations on shuﬄe, then existence of an ad-
versary with non-negligible advantage at violating query pri-
vacy in a de-amortized ORAM implies existence of an adver-
sary with non-negligible advantage at violating the privacy of
this underlying level-based ORAM (“privacy inheritance”).
Proof. A de-amortized ORAM operates equivalently to
the underlying ORAM, with two diﬀerences. First, the level
access structure is diﬀerent—there are up to twice as many
levels—but the privacy-preserving property that no item is
requested twice under the same (opaque) identiﬁer is the
same. Second, items are not deleted until after the shuﬄe
(instead of before), but this provides no additional informa-
tion as long as the level construction process is also opaque.
This is the only new information given to the adversary.
Privacy is shown by reducing to a property of ideal permuta-
tions: uncovering a portion of a permutation does not reveal
anything about the remaining portion. Since the underlying
level-based ORAM selects the level permutation according
to an ideal secret permutation, this follows trivially: all ar-
rangements of the elements in the “still secret” portion are
equally likely. It constitutes a secret permutation in itself.
This results in an ordering and labeling indistinguishable
from random.
shuﬄe the next larger level, i + 1, de-amortization requires
an extra factor of client storage upper-bound by log2 n (since
all log2 n levels are being shuﬄed at once).
Communication overhead. This construction requires
querying up to twice as many levels simultaneously. How-
ever, since it is known in advance that the item won’t show
up in both levels, this querying can be done in the same
number of round trips.
Shuﬄing overhead. The amount of work performed
per query is roughly similar. Additional overhead may stem
from shuﬄing being done before level items are removed.
But since only half of the items would be removed anyway,
for ORAMs where the level i construction cost is sm log2 m
for constant s and m = 2i, this keeps the new overhead for
shuﬄing within a factor of
s(2m log2 2m)
s(m log2 m) = 2 + 1
log2 m < 3.
5.4 BF ORAM with logarithmic memory
We now detail the ﬁnal piece of the construction: the un-
derlying base ORAM mechanism. For illustration we take
our ORAM [19] that separated each ORAM pyramid level
into two data structures: a hash table of items, indexed by
unique random IDs, and an encrypted BF to check whether
an item is stored at a given level. Querying this ORAM pro-
ceeds analogously to the standard pyramidal ORAM model—
starting at the top, searching downward until the item is
found, querying randomly from then forward. However, in-
stead of scanning a bucket sized O(log n) at each level, the
encrypted BF is checked, requiring only a single item re-
trieval from each level.
At reshuﬄe time, in [19], BFs for each level were built
securely by the client using a somewhat complex procedure
based on an oblivious scramble of a list representation of
positions to set, followed by bucket sort. This allowed costs
under O(log2 n), requiring k
√
n ln n client storage.
We now introduce a technique resulting in an O(log2 n)
BF-based ORAM and requiring only logarithmic client stor-
√
age. Instead of using the “bucket sort” method that builds
n-sized chunks of the encrypted BF, we construct, then
sort, a server-stored list of the BF segments and indexes:
First, in a single pass over the encrypted items of the
level undergoing construction:
that need to be set in the encrypted BF
• build an encrypted, server-stored, list of the positions
• divide the BF into segments of size O(log n)
• append one encrypted segment identiﬁer for each pos-
sible segment to this list, padded so the server cannot
distinguish segment identiﬁers from BF positions.
Second, obliviously sort this entire list [5, 19], with seg-
ments distributed among the positions, directly following
the positions they belong in.
Third, in a single pass over this sorted list:
• output one BF segment for every list element: for each
segment identiﬁer, output an encrypted segment, with
the appropriate positions set. Recall that these posi-
tions immediately preceded this segment identiﬁer in
the sorted list.
• for each position encountered in this list, output a
dummy empty segment.
Storage overhead. Since the client storage required to
shuﬄe level i is less than or equal to the space required to
Fourth, obliviously sort the resulting list by segment iden-
tiﬁer, with the dummy segments at the end.
984Fifth, truncate oﬀ the dummy segments from this list.
The result is the encrypted BF.
The advantage of this approach over [19] is that using
a logarithmic-space O(m log m) oblivious sort [5] provides
a logarithmic-space construction still running in O(log2 n)
time. As discussed, employing this as a de-amortized ORAM
brings the client storage requirement to O(log2 n).
This construction process is secure, provided (a) the obliv-
ious sort is private, (b) the server cannot distinguish an en-
crypted dummy segment from an encrypted BF segment,
and (c) the server cannot distinguish an encrypted segment
identiﬁer from an encrypted BF position. If these three con-
ditions are satisﬁed, then every run of this process over a set
of m items appears identical to the server, regardless of the
positions in the BF being set.
√
The PD-ORAM implementation assumes k
n ln n client
storage to employ the Oblivious Merge Sort instead of the
disk-seek intensive less eﬃcient randomized shell sort. Nev-