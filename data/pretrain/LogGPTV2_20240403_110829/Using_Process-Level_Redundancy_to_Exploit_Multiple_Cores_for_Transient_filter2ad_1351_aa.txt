title:Using Process-Level Redundancy to Exploit Multiple Cores for Transient
Fault Tolerance
author:Alex Shye and
Tipp Moseley and
Vijay Janapa Reddi and
Joseph Blomstedt and
Daniel A. Connors
Using Process-Level Redundancy to Exploit Multiple Cores for
Transient Fault Tolerance
Alex Shye Tipp Moseley† Vijay Janapa Reddi‡
Joseph Blomstedt Daniel A. Connors
Dept. of Electrical and
Computer Engineering
U. of Colorado at Boulder
{shye, blomsted, dconnors}@colorado.edu
†Dept. of Computer Science
U. of Colorado at Boulder
PI:EMAIL
‡Dept. of Elect. Eng.
and Computer Science
Harvard University
PI:EMAIL
Abstract
Transient faults are emerging as a critical concern in the
reliability of general-purpose microprocessors. As archi-
tectural trends point towards multi-threaded multi-core de-
signs, there is substantial interest in adapting such parallel
hardware resources for transient fault tolerance. This paper
proposes a software-based multi-core alternative for tran-
sient fault tolerance using process-level redundancy (PLR).
PLR creates a set of redundant processes per application
process and systematically compares the processes to guar-
antee correct execution. Redundancy at the process level
allows the operating system to freely schedule the processes
across all available hardware resources. PLR’s software-
centric approach to transient fault tolerance shifts the fo-
cus from ensuring correct hardware execution to ensuring
correct software execution. As a result, PLR ignores many
benign faults that do not propagate to affect program cor-
rectness. A real PLR prototype for running single-threaded
applications is presented and evaluated for fault coverage
and performance. On a 4-way SMP machine, PLR provides
improved performance over existing software transient fault
tolerance techniques with 16.9% overhead for fault detec-
tion on a set of optimized SPEC2000 binaries.
1
Introduction
Transient faults, also known as soft errors, are emerg-
ing as a critical concern in the reliability of computer sys-
tems [4, 21]. A transient fault occurs when an event (e.g.
cosmic particle strikes, power supply noise, device cou-
pling) causes the deposit or removal of enough charge to
invert the state of a transistor. The inverted value may prop-
agate to cause an error in program execution.
Current trends in process technology indicate that the fu-
ture error rate of a single transistor will remain relatively
constant [13, 18]. As the number of available transistors
per chip continues to grow exponentially, the error rate
of for an entire chip is expected to increase dramatically.
These trends indicate that to ensure correct operation of
systems, all general-purpose microprocessors and memo-
ries must employ reliability techniques.
Transient faults have historically been a design con-
cern in speciﬁc computing environments (e.g. spacecrafts,
high-availability server machines) in which the key system
characteristics are reliability, dependability, and availabil-
ity. While memory is easily protected with error-correcting
code (ECC) and parity, protecting the complex logic within
a high-performance microprocessor presents a signiﬁcant
challenge. Custom hardware designs have added 20-30%
additional logic to add redundancy to mainframe proces-
sors and cover upwards of 200,000 latches [32, 2]. Other
approaches include specialized machines with custom hard-
ware and software redundancy [16, 39].
However, the same customized techniques can not be di-
rectly adopted for the general-purpose computing domain.
Compared to the ultra-reliable computing environments,
general-purpose systems are driven by a different, and of-
ten conﬂicting, set of factors. These factors include:
Application Speciﬁc Constraints: In ultra-reliable en-
vironments, such as spacecraft systems, the result of an
transient error can be the difference between life or death.
For general-purpose computing, the consequences of faulty
execution are often less severe. For instance, in audio de-
code and playback, a fault results in a mere glitch which
may not even be noticed. Thus, the focus for reliability
shifts from providing a bullet-proof system to improving re-
liability to meet user expectations of failure rates.
Design Time and Cost Constraints: In the general-
purpose computing market, low cost and a quick time to
market are paramount. The design and veriﬁcation of new
redundant hardware is costly and may not be feasible in
cost-sensitive markets. In addition, the inclusion of redun-
dant design elements may negatively impact the design and
product cycles of systems.
Post-Design Environment Techniques: A system’s
susceptibility to transient faults is often unplanned for and
appears after the design and fabrication processes. For ex-
ample, the scientists at the Los Alamos National Laboratory
documented a surprisingly high incidence of single-node
failures due to transient faults during the deployment of the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:16 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007ASC Q supercomputer [21]. Likewise, environmental con-
ditions of a system such as altitude, temperature, and age
can cause higher fault rates [40]. In these cases, reliability
techniques must be augmented after the design and devel-
opment phase without the addition of new hardware.
With such pressures driving general-purpose computing
hardware, software reliability techniques are an attractive
solution for improving reliability in the face of transient
faults. While software techniques cannot provide a level of
reliability comparable to hardware techniques, they signiﬁ-
cantly lower costs (zero hardware design cost), and are very
ﬂexible in deployment. Existing software transient fault tol-
erant approaches use the compiler to insert redundant in-
structions for checking computation [26], control ﬂow [25],
or both [29]. The compiler-based software techniques suffer
from a few limitations. First, the execution of the inserted
instructions and assertions decreases performance (∼1.4x
slowdown [29]). Second, a compiler approach requires re-
compilation of all applications. Not only is it inconvenient
to recompile all applications and libraries, but the source
code for legacy programs is often unavailable.
This paper presents process-level redundancy (PLR), a
software reliability technique leverages multiple processor
cores for transient fault tolerance. PLR creates a set of
redundant processes per original application process and
compares their output to ensure correct execution. PLR
scales with the architectural trend towards large many-
core machines and leverages available hardware parallelism
to improve performance without any additional redundant
hardware structures or modiﬁcations to the system. In com-
puting environments which are not throughput-constrained,
PLR provides an alternate method of leveraging the hard-
ware resources for transient fault tolerance.
In addition,
PLR can be easily deployed without recompilation or mod-
iﬁcations to the underlying operating system.
This paper makes the following contributions:
• PLR implies a software-centric paradigm in transient
fault tolerance which views the system as software lay-
ers which must execute correctly. In contrast, the typ-
ical hardware-centric paradigm views the system as
a collection of hardware that must be protected. We
differentiate between software-centric and hardware-
centric views using the commonly accepted sphere of
inﬂuence concept.
• Demonstrates the beneﬁts of a software-centric ap-
proach.
In particular, we show how register errors
propagate through software. We show that many of the
errors result in benign faults and many detected faults
propagate through hundreds or thousands of instruc-
tions. By using a software-centric approach, PLR is
able to ignore many benign faults.
• Presents a software-only transient fault tolerance tech-
nique for leveraging multiple cores on a general-
purpose microprocessor for transient fault tolerance.
We describe a real prototype system designed for
single-threaded applications and evaluate the fault cov-
erage and performance of PLR. Overall, the PLR pro-
totype runs a set of the SPEC2000 benchmark suite
with only a 16.9% overhead on a 4-way SMP system.
The rest of this paper is organized as follows. Section 2
provides background on transient fault tolerance. Section 3
describes PLR. Section 4 shows initial results from the dy-
namic PLR prototype. Section 5 discusses related work.
Section 6 concludes the paper.
2 Background
In general, a fault can be classiﬁed by its effect on system
execution into the following categories [37]:
Benign Fault: A transient fault which does not propa-
gate to affect the correctness of an application is considered
a benign fault. A benign fault can occur for a number of rea-
sons. Examples include a fault to an idle functional unit, a
fault to a performance-enhancing instruction (i.e. a prefetch
instruction), data masking, and Y-branches [36].
Silent Data Corruption (SDC): An undetected fault
which propagates to corrupt system output is an SDC. This
is the worst case scenario where a system appears to execute
correctly but silently produces incorrect output.
Detected Unrecoverable Error (DUE): A fault which
is detected without possibility of recovery is considered a
DUE. DUEs can be split into two categories. A true DUE
occurs when a fault which would propagate to incorrect exe-
cution is detected. A false DUE occurs when a benign fault
is detected as a fault.
A transient fault in a system without transient fault tol-
erance will result in a benign fault, SDC, or true DUE (e.g.
error detected by core dump). A system with only detection
attempts to detect all of the true DUEs and SDCs. However,
the system may inadvertently convert some of the benign
faults into false DUEs and unnecessarily halt execution. Fi-
nally, a system with both detection and recovery will detect
and recover from all faults without SDCs or any form of
DUE. In this case, faults which would be false DUEs may
cause unwarranted invocations to the recovery mechanism.
3 Approach
3.1 Software-centric Fault Detection
The sphere of replication (SoR) [28] is a commonly ac-
cepted concept for describing a technique’s logical domain
of redundancy and specifying the boundary for fault detec-
tion and containment. Any data which enters the SoR is
replicated and all execution within the SoR is redundant in
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:16 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007only faults which affect correctness are detected. Benign
faults are safely ignored. A software-centric system with
only detection is able to reduce the incidence of false DUEs.
A software-centric system with both detection and recovery
will not need to invoke the recovery mechanism for faults
which do not affect correctness.
Figure 1(b) shows an example software-centric SoR
which is placed around the user space application and li-
braries (as used by PLR). A software-centric SoR acts ex-
actly the same as the hardware-centric SoR except that it
acts on the software instead of the hardware. Again, all in-
put is replicated, execution within the SoR is redundant, and
data leaving the SoR is compared.
By operating at the software level, the software-centric
model caters to the strengths of a software-implemented
technique. While software has limited visibility into hard-
ware, it is able to view a fault at a broader scope and de-
termine its effect on software execution. Thus, software-
implemented approaches which are hardware-centric are ig-
noring the potential strengths of a software approach.
3.2 Process-Level Redundancy
Process-level redundancy (PLR) is a technique which
uses the software-centric model of transient fault detec-
tion. As shown in Figure 1(b), PLR places its SoR around
the user address space by providing redundancy at the pro-
cess level. PLR replicates the application and library code,
global data, heap, stack, ﬁle descriptor table, etc. Every-
thing outside of the SoR, namely the OS, must be protected
by other means. Any data which enters the SoR via the
system call interface must be replicated and all output data
must be compared to verify correctness.
Providing redundancy at the process level is natural as
it is the most basic abstraction of any OS. The OS views
any hardware thread or core as a logical processor and
then schedules processes to the available logical proces-
sors. PLR leverages the OS to schedule the redundant pro-
cesses to take advantage of hardware resources. With mas-
sive multi-core architectures on the horizon, there will be a
tremendous amount of hardware parallelism available in fu-
ture general-purpose machines. In computing environments
where throughput is not the primary concern, PLR provides
a way of utilizing the extra hardware resources for transient
fault tolerance.
A high level overview of PLR is shown in Figure 2 with
three redundant processes, which is the minimum number
of processes necessary for both transient fault detection and
recovery. PLR intercepts the beginning of application exe-
cution and replicates the original process to create other re-
dundant processes. One of the processes is logically labeled
the master process and the others are labeled the slave pro-
cesses. At each system call, the system call emulation unit
is invoked. The emulation unit performs the input replica-
Figure 1. Hardware-centric and software-
centric transient fault detection models.
some form. Before leaving the SoR, all output data is com-
pared to ensure correctness. All execution outside of the
SoR is not covered by the particular transient fault tech-
niques and must be protected by other means. Faults are
contained within the SoR boundaries and detected in any
data leaving the SoR.
Most previous work in fault
tolerance is hardware-
centric and uses a hardware-centric SoR. A hardware-
centric model views the system as a collection of hardware
components which must be protected from transient faults.
In this model, a hardware-centric SoR is placed around spe-
ciﬁc hardware units. All inputs are replicated, execution is
redundant, and output is compared.
While the hardware-centric model is appropriate for
hardware-implemented techniques, it is awkward to apply
the same approach to software. Software naturally oper-
ates at a different level and does not have full visibility into
the hardware. Nevertheless, previous compiler-based ap-
proaches attempt to imitate a hardware-centric SoR. For ex-
ample, SWIFT [29] places its SoR around the processor as
shown in Figure 1(a). Without the ability to control du-
plication of hardware, SWIFT duplicates at the instruction
level. Each load is performed twice for input replication
and all computation is performed twice on the replicated in-
puts. Output comparison is accomplished by checking the
data of each store instruction prior to executing the store in-
struction. This particular approach works because it is pos-
sible to emulate processor redundancy with redundant in-
structions. However, other hardware-centric SoRs would be
impossible to emulate with software. For example, software
alone cannot implement an SoR around hardware caches.
Software-centric fault detection is a paradigm in which
the system is viewed as the software layers which must exe-
cute correctly. A software-centric model uses a software-
centric SoR which is placed around software layers, in-
stead of hardware components. The key insight to software-
centric fault detection is this: although faults occur at the
hardware level, the only faults which matter are the faults
which affect software correctness. By changing the bound-
aries of output comparison to software, a software-centric
model shifts the focus from ensuring correct hardware exe-
cution to ensuring correct software execution. As a result,
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:16 UTC from IEEE Xplore.  Restrictions apply. 
PLR SoRProcessorCacheDevicesMemoryApplicationLibrariesOperating System(a) Hardware−centric(b) Software−centricProcessor SoR37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 20073.2.2 Output Comparison