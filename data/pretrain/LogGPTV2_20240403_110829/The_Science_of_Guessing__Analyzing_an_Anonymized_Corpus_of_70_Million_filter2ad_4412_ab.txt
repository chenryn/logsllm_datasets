4The proof of this is a straightforward consequence of Shannon’s source
← X can be encoded using a Huffman
coding theorem [26]. Symbols X
code with average bit length ≤ H1(X ) + 1, of which the adversary can
learn one bit at a time with subset membership queries.
5H1 has further been claimed to correlate poorly with password cracking
difﬁculty [8], [23], though the estimates of H1 used cannot be relied upon.
R
541
(cid:33)
(cid:32) N(cid:88)
i=1
B. R´enyi entropy and its variants
R´enyi entropy Hn is a generalization of Shannon en-
tropy [31] parametrized by a real number n ≥ 0:6
Hn(X ) =
1
1 − n
lg
pn
i
(2)
In the limit as n → 1, R´enyi entropy converges to Shannon
entropy, which explains why Shannon entropy is denoted
H1. Note that Hn is a monotonically decreasing function of
n. We are most interested in two special cases:
1) Hartley entropy H0: For n = 0, R´enyi entropy is:
H0 = lg N
(3)
Introduced prior to Shannon entropy [32], H0 measures
only the size of a distribution and ignores the probabilities.
2) Min-entropy H∞: As n → ∞, R´enyi entropy is:
H∞ = − lg p1
(4)
This metric is only inﬂuenced by the probability of the
most likely symbol in the distribution, hence the name.
This is a useful worst-case security metric for human-chosen
distributions, demonstrating security against an attacker who
only guesses the most likely password before giving up. H∞
is a lower bound for all other R´enyi entropies and indeed
all of the metrics we will deﬁne.
C. Guesswork
A more applicable metric is the expected number of
guesses required to ﬁnd X if the attacker proceeds in optimal
order, known as guesswork or guessing entropy [27], [30]:
(cid:104)
(cid:105)
N(cid:88)
i=1
G(X ) = E
#guesses(X
R
← X )
=
pi · i
(5)
Because G includes all probabilities in X , it models an
attacker who will exhaustively guess even exceedingly un-
likely events which can produce absurd results. For example,
in the RockYou data set over twenty users (more than 1
in 221) appear to use 128-bit pseudorandom hexadecimal
strings as passwords. These passwords alone ensure that
G(RockYou) ≥ 2106. Thus G provides little insight into
practical attacks and furthermore is difﬁcult to estimate from
sampled data (see Section V).
D. Partial guessing metrics
Guesswork and entropy metrics fail to model the tendency
of real-world attackers to cease guessing against the most
difﬁcult accounts. As discussed in Section II, cracking
evaluations typically report the fraction of accounts broken
by a given attack and explicitly look for weak subspaces of
passwords to attack. Having many accounts to attack is an
6R´enyi entropy is traditionally denoted Hα; we use Hn to avoid
confusion with our primary use of α as a desired success rate.
important resource for a real attacker, as it enables a partial
guessing attack which trades a lower proportion of accounts
broken for increased guessing efﬁciency.
Formally, if Eve must sequentially guess each of k pass-
words drawn from X , she will need ∼ k · G(X ) guesses on
average. However, a second guesser Mallory willing to break
only (cid:96) < k of the passwords can do much better with the
optimal strategy of ﬁrst guessing the most likely password
for all k accounts, then the second-most likely value and
so on. As (cid:96) decreases, Mallory’s efﬁciency increases further
as the attack can omit progressively more low-probability
passwords. For large values of k and (cid:96), Mallory will only
need to guess the most popular β passwords such that
k . There are several possible
(cid:80)β
i=1 pi ≥ α, where α = (cid:96)
1) β-success-rate: A very simple metric, ﬁrst formally
deﬁned by Boztas¸ [29], measures the expected success for
an attacker limited to β guesses per account:
metrics for measuring guessing in this model:
λβ(X ) =
pi
(6)
2) α-work-factor: A related metric, ﬁrst formalized by
Pliam [28], evaluates the ﬁxed number of guesses per
account needed to break a desired proportion α of accounts.
(cid:41)
µα(X ) = min
j
pi ≥ α
(7)
If µα(X ) = n, this tells us that an attacker must use an
optimal dictionary of n entries to have a probability α of
breaking an individual account, or equivalently to break an
expected fraction α of many accounts.
3) α-guesswork: While λβ and µα are closer to mea-
suring real guessing attacks, both ignore the fact that a
real attacker can stop early after successful guesses. While
making up to µα guesses per account will enable breaking
a fraction α of accounts, some will require fewer than µα
guesses. We introduce a new metric to reﬂect the expected
number of guesses per account to achieve a success rate α:
β(cid:88)
i=1
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) j(cid:88)
i=1
(cid:40)
µα(cid:88)
i=1
Gα(X ) = (1 − λµα ) · µα +
pi · i
(8)
We use λµα in place of α to round up to the proportion
of passwords actually covered by µα guesses. Note that the
traditional guesswork metric G is a special case G1 of this
metric with α = 1. We could equivalently deﬁne Gβ for an
attacker limited to β guesses, but this is less useful as for
small β the effect of stopping early is negligible.
E. Effective key-length metrics
While λβ, µα and Gα are not measures of entropy, it is
convenient to convert them into units of bits. This enables
direct comparison of all metrics as a logarithmically scaled
attacker workload which is intuitive to programmers and
542
cryptographers. This can be thought of as an “effective
key-length” as it represents the size of a randomly chosen
cryptographic key which would give equivalent security.7
We convert each metric by calculating the logarithmic size
N for all
of a discrete uniform distribution UN with pi = 1
1 ≤ i ≤ N which has the same value of the guessing metric.
For β-success-rate, since we have λβ (UN ) = β
N we say
that another distribution X is equivalent with respect to λβ
to a uniform distribution of size N = β
λβ (X ). We take the
logarithm of this size to produce our effective key-length
metric ˜λβ, using a tilde to denote the conversion to bits:
(cid:19)
(cid:19)
(cid:18) β
(cid:18) µα(X )
λβ(X )
λµα
˜λβ(X ) = lg
˜µα(X ) = lg
(9)
(10)
The conversion formula for α-work-factor is related:
(11)
Again, we use λµα in place of α in the denominator
because µα increases as a step function as α increases.
Without this correction, ˜µα would decrease over each range
of α where µα is constant, giving a misleading over-estimate
of security. Using λµα effectively rounds up to the next
value of α which would require additional guesses to cover,
ensuring that ˜µα is monotonically increasing.
To convert Gα, we consider that an attacker desiring to
break a proportion α of accounts will average Gα guesses
per account, or one successful guess per Gα
α guesses. Against
the uniform distribution UN , an attacker will break an
account every N +1
2
guesses, giving us the formula:
2 · Gα(X )
1
− 1] + lg
λµα
2 − λµα
˜Gα(X ) = lg[
using the same correction for α as we did for ˜µα to achieve
to make
monotonicity, and the correction factor lg
the metric constant for a uniform distribution.
2−λµα
1
F. Relationship between metrics
We enumerate a few useful relationships between differ-
ent metrics in Table II. Note that for a discrete uniform
distribution UN , all of the metrics Hn, ˜Gα, ˜λβ and ˜µα are
equivalent. This validates the deﬁnitions and demonstrates
why more complicated guessing metrics have rarely come
up in cryptographic literature, as they provide no additional
information for uniform distributions.
Massey proved that ˜G1 ≥ H1−1 [30], which is sometimes
used to justify H1 as a guessing metric. However, several
negative results show that neither H1 nor ˜G1 can provide
any lower bound on partial guessing. Theorems proved by
Pliam [28], Boztas¸ [29], and Bonneau [34] demonstrate an
unbounded gap: for any desired success rate α < 1, it is
possible to construct a distribution X such that ˜µα(X ) +
7Boztas¸ introduced the term effective key-length speciﬁcally to refer to
˜µ0.5 [29]. We extend the notion here to all of our metrics.
(a) µα, Gα (number of guesses)
(b) µα, Gα (effective key-length)
Figure 2. Two ways of comparing the guessing difﬁculty of user-chosen 4-digit PINs [33] against uniform distributions of size 10,000 and 1,000 (U104
and U103 , respectively). Fig. 2a plots the dictionary size µα needed to have a chance of success α as well as the expected number of guesses per account
Gα. Fig. 2b converts both metrics into an effective key-length, enabling visual comparison across the entire range of α. Traditional single-point metrics
H0, H1, H2, H∞ and ˜G are also marked for comparison. Note that ˜µα and ˜Gα are horizontal lines for uniform distributions; an attacker gains no
efﬁciency advantage from lowering his desired success rate α.
m ≤ H1(X ) and ˜µα(X ) + m ≤ ˜G1(X ) for any separation
parameter m. Furthermore, for any α1 < α2 a distribution
X can be found with ˜µα1 (X ) + m ≤ ˜µα2(X ) for any m.
These results easily extend to ˜Gα using the bounds listed in
Table II and related results can be proved for ˜λβ(X ).
equivalences
∀n Hn(UN ) = lg N
˜λβ (UN ) = lg N
∀β
∀α ˜µα(UN ) = lg N
˜Gα(UN ) = lg N
∀α
H0 = ˜µ1 = ˜λN = lg N
H∞ = ˜µα≤p1 = ˜λ1 = − lg p1
bounds
all metrics equal for U
all metrics equal for U
all metrics equal for U
all metrics equal for U
metrics depending only on N
metrics depending only on p1
˜Gα ≤ ˜µα
H∞ ≤ ˜Gα, ˜µα, ˜λβ
˜Gα, ˜µα, ˜λβ ≤ H0
˜Gα − ˜µα ≤ lg(1 − α)
H∞ ≤ . . . ≤ H1 ≤ H0
˜λβ ≤ ˜λβ+
˜µα ≤ ˜µα+
˜Gα ≤ ˜Gα+
monotonicity
H∞ is abs. lower bound
H0 is abs. upper bound
straightforward proof
straightforward proof
Hn decreasing with n
˜λβ increasing with β
˜µα increasing with α
˜Gα increasing with α
RELATIONS BETWEEN GUESSING METRICS
Table II
G. Application in practical security evaluation
For an online attacker we can use ˜λβ with β equal to the
guessing limits imposed by the system. There is no standard
for β, with 10 guesses recommended by usability stud-
ies [35], 3 by FIPS guidelines [20], and a variety of values
(often ∞) seen in practice [36]. Sophisticated rate-limiting
schemes may allow a probabilistic number of guesses [37].
543
We consider ˜λ10 a reasonable benchmark for resistance to
online guessing, though ˜λ1 = H∞ is a conservative choice
as a lower bound for all metrics proposed.
The separation results of Section III-F mean that for brute-
force attacks we can’t rely on any single value of α; each
value provides information about a fundamentally different
attack scenario. For a complete picture, we can consider ˜µα
or ˜Gα across all values of α. We can plot this as the guessing
curve for a distribution, as seen in Figure 2.
For ofﬂine attacks, where an adversary is limited only by
time and computing power, we might consider ˜µα or ˜Gα for
a standard value such as 0.5 as a benchmark (˜µ0.5 was orig-
inally suggested by [29]). While ˜Gα more directly measures
the efﬁciency of a guessing attack, ˜µα can be advantageous
in practice because it is simpler to compute. In particular, it
can be computed using previously published cracking results
reported as “a dictionary of size µ compromised a fraction α
of available accounts,” as plotted in Figure 1b. Furthermore,
the difference between the metrics is only signiﬁcant for
higher values of α; for α ≤ 0.5 the two will never differ by
more than 1 bit (from the bound in Table II).
IV. PRIVACY-PRESERVING EXPERIMENTAL SETUP
By using statistical guessing metrics to evaluate pass-
words, we are freed from the need to access passwords
in their original form. Users may be willing to provide
passwords to researchers with ethics oversight [4], [23]
but this approach does not scale and the validity of the
collected passwords is questionable. In contrast, leaked data
sets provide unquestionably valid data but there are ethical
questions with using stolen password data and its availability
shouldn’t be relied on [38]. There is also no control over
0.00.20.40.60.81.0successrateα0200040006000800010000numberofguessesµα(U104)/Gα(U104)µα(U103)/Gα(U103)µα(PIN)Gα(PIN)0.00.20.40.60.81.0successrateα02468101214bits-H∞˜G&H0&H1→H2→˜µα(U104)/˜Gα(U104)˜µα(U103)/˜Gα(U103)˜µα(PIN)˜Gα(PIN)0.00.51.01.52.02.53.03.54.0ditsthe size or composition of leaked data sets. Thus far, for
example, no leaked sources have included demographic data.
We addressed both problems with a novel experimental
setup and explicit cooperation from Yahoo!, which maintains
a single password system to authenticate users for its diverse
suite of online services. Our experimental data collection
was performed by a proxy server situated in front of live
login servers. This is required as long-term password storage
should include account-speciﬁc salting and iterated hashing
which prevent constructing a histogram of common choices,
just as they mitigate pre-computed dictionary attacks [39].
Our proxy server sees a stream of pairs (u, passwordu)
for each user u logging in to any Yahoo! service. Our
goal is to approximate distinct password distributions Xfi
for a series of demographic predicates fi. Each predicate,
such as “does this user have a webmail account?”, will
typically require a database query based on u. A simplistic
solution would be for the proxy to emit a stream of tuples
(H(passwordu), f1(u), f2(u), . . . ), removing user identiﬁers
u to prevent trivial access to real accounts and using a cryp-
tographic hash function H to mask the values of individual
passwords.8 There are two major problems to address:
A. Preventing password cracking
If a user u can be re-identiﬁed by the uniqueness of
then the value
his or her demographic predicates [40],
H(passwordu) could be used as an oracle to perform an
ofﬂine dictionary attack. Such a re-identiﬁcation attack was
demonstrated on a data set of movie reviews superﬁcially
anonymized for research purposes [41] and would almost
certainly be possible for most users given the number and
detail of predicates we would like to study.
This risk can be effectively mitigated by prepending the
same cryptographically random nonce r to each password
prior to hashing. The proxy server must generate r at the
beginning of the study and destroy it prior to making data
available to researchers. By choosing r sufﬁciently long
to prevent brute-force (128 bits is a conservative choice)
and ensuring it is destroyed, H(r||passwordu) is useless
for an attacker attempting to recover passwordu but the
distribution of hash values will remain exactly isomorphic
to the underlying distribution of passwords seen.
B. Preventing cross-account compromise
While including a nonce prevents ofﬂine search, an at-
tacker performing large-scale re-identiﬁcation can still iden-
tify sets of users which have a password in common. This
decreases security for all users in a group which share a
password, as an attacker may then gain access to all accounts
in the group by recovering just one user’s password by
auxiliary means such as phishing, malware, or compromise
of an external website for which the password was re-used.
8Note that H cannot incorporate any user-speciﬁc salt—doing so would
occlude the frequency of repeated passwords.
544
Figure 3. Changing estimates of guessing metrics with increasing sample
size M. Estimates for H∞ and ˜λ10 converge very quickly; estimates for
˜µ0.25 converge around M = 222 (marked ×) as predicted in Section V-A.
Estimates for H0, H1, and ˜G are not close to converging.
Solving this problem requires preventing re-identiﬁcation by
not emitting vectors of predicates for each user.
Instead,
the proxy server maintains a histogram Hi
of observed hash values
for each predicate fi. For
each pair (u, passwordu) observed, the proxy server adds
H(r||passwordu) to each histogram Hi for which fi(u) is
true. An additional list is stored of all previously seen hashed
usernames H(r||u) to prevent double-counting users.
C. Deployment details
The collection code, consisting of a few dozens lines of
Perl, was audited and r generated using a seed provided