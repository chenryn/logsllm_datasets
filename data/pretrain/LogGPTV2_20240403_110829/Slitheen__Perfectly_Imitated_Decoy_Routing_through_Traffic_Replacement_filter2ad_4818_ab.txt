the completion of the initial GET request to the overt site. As such,
the overt site will continue to receive upstream data from the client
without complaint, thereby eliminating the need for ﬂow blocking.
The station fulﬁlls the client’s requests for censored content, issu-
ing encrypted responses on behalf of the overt site. As the only
downstream data from the server are the original TLS handshake
messages (which are not needed by the TapDance station), and
the TCP ACK messages following extra data from the incomplete
header, the station does not need to witness this downstream trafﬁc,
making the scheme amenable to asymmetric ﬂows.
Although TapDance solves two major challenges to deployment,
it also exempliﬁes the trade-off between deployability and security.
By leaving the connection between the client and overt destination
open but abandoned, TapDance becomes vulnerable to active at-
tacks by an adversarial censor. The station sends HTTP responses
in place of the overt server, resulting in a discrepancy between the
TCP state of the overt site and the TCP state witnessed by the cen-
Figure 1: An overview of the Telex [26] architecture. A client ﬁrst
initiates a TLS handshake with the overt destination, tagging the
ClientHello message (1). The relay station recognizes the tag, and
then continues to passively monitor the TLS handshake (2). Upon
receipt of the TLS Finished messages from both sides, the station
decrypts and veriﬁes the Finished messages with the session’s TLS
master secret, computed from the client’s tag. Finally, the station
will sever the connection to the overt site (3), and assume its role
as a proxy to the censored, covert site (4). Slitheen is very similar,
except that in step (3), the connection between the client and the
overt destination is maintained and actively used.
their services. The proxy only has to subscribe and pay for band-
width (shown to be between $0.10 and $0.20 USD per GB [10]) in
order for their service to be accessible from an overt edge server.
After establishing a connection to the overt destination, the client
can issue HTTP requests to the Meek proxy. Packets are redirected
to the proxy by the overt destination according to the host ﬁeld
of the HTTP header. The client’s Tor trafﬁc is then tunneled over
HTTP to the proxy and sent to a Tor guard. In this way, the proxy
to Tor “hides” behind the cloud service. To block all trafﬁc to the
Meek proxy, the censor would have to block all trafﬁc to the front
service, causing collateral damage.
Domain fronting relies on the deterrence of collateral damage. If
the censor knows the existence of the domain fronted proxy, they
may block it only by blocking the entire front service. This may be
prohibitively expensive in terms of collateral damage for large web
services and therefore unappealing to the censor.
2.2 Decoy Routing
The ﬁrst generation of decoy routers surfaced in 2011, proposed
by three independent research groups. Telex [26], Cirripede [12],
and Curveball [14] all use the same basic technique in which the
client steganographically expresses a desire to access censored con-
tent covertly by tagging the setup messages in a seemingly benign
connection to an overt destination, sometimes referred to as a de-
coy server. These tags are recognized by a friendly ISP with a
deployed relay station on the path between the client and the overt
destination, but are provably invisible to a censoring ISP without
the relay station’s private key. After the tag has been recognized,
the station facilitates the ﬂow of information between the client and
a censored website via a man-in-the-middle proxy. The details of
the tagging process and proxy setup vary; Figure 1 shows the gen-
eral architecture of Telex, which is most similar to our system.
In Telex, the tag is placed in the random nonce of the Clien-
tHello message that initiates a TLS handshake with the overt site.
From this tag and the station’s private key, the station can compute
the client’s Difﬁe-Hellman (DH) exponent, allowing it to compute
the session’s TLS master secret and man-in-the-middle the connec-
tion between the client and the overt destination. Upon the receipt,
decryption, and veriﬁcation of both TLS Finished messages, the
station severs the connection to the overt destination and assumes
its role as a proxy, preserving the server-side TCP and TLS state.
sor. A passive censor would not notice this discrepancy, as the overt
site will ignore client packets with an acknowledgement number
higher than the overt site’s TCP SND.NXT value. An active at-
tacker, however, may determine the actual TCP state of the overt
site by replaying a TCP ACK packet with a stale sequence number,
prompting the server to reveal its current TCP state, and incrimi-
nating the client.
Rebound, proposed by Ellard et al. [7], is the most recent decoy
routing system and aims to solve the trade-off mentioned above,
providing an asymmetric solution that defends against an active ad-
versary. Clients tag Rebound ﬂows in a manner similar to Telex, by
inserting a tag in the ClientHello message of a TLS handshake, en-
abling the Rebound station to compute the master secret of the TLS
connection between the client and the overt site. They achieve an
asymmetric version of the tagging procedure by leaking the val-
ues of the server random nonce and the ciphersuite to the Rebound
station by embedding them in the ciphertext of initial HTTP GET
requests from the client to the overt site. Once the Rebound station
is able to man-in-the-middle the TLS connection, the client begins
issuing requests for censored content embedded in invalid HTTP
GET requests to the overt site. The relay station fetches the cen-
sored content and stores it in a queue. When the next invalid GET
request is received by the Rebound station, the station replaces the
URL ﬁeld of the request with content from the censored site. This
information is forwarded to the overt site, which “rebounds” the
encrypted content, inside an HTTP error response.
Rebound maintains the connection between the client and the
overt site, making it resistant to the TCP replay attack mentioned
above. The TCP state of the overt site will report the TCP sequence
and acknowledgement numbers expected by the censor. Further-
more, by rebounding content off of the overt site in the form of
error messages, Rebound delivers downstream data from the proxy
to the client even if the underlying network routes are asymmet-
ric. There are two major barriers to the adoption of Rebound as
a censorship resistance technique. The ﬁrst barrier is that a client
must send upstream data in an equal amount to the downstream
data they receive to avoid mismatched TCP sequence numbers up-
stream, alerting the censor of a decoy session. In typical Internet
usage, the ratio between upstream data sent and downstream data
received by the client is very low; this trend is reﬂected in the band-
width provided by most ISPs. The second barrier to adoption is the
ﬂood of bad HTTP GET requests that the client sends to the overt
site. The frequency and size of these requests are reminiscent of
HTTP ﬂooding, a class of Denial of Service attacks, and will likely
be blocked by the overt site.
The two most recent decoy routing systems have addressed the
shortcomings of ﬁrst generation systems, notably those of deploy-
ability in the case of TapDance, and security against some active
(but not all passive) attacks in the case of Rebound. However, all
existing systems are vulnerable to the timing analysis attacks in-
troduced by Schuchard et al. [18]. They showed that differences
in latency due to fetching content from a possibly distant censored
server through the decoy routing proxy is enough to not only detect
the usage of a decoy routing system, but also ﬁngerprint the cen-
sored webpage accessed. Although Rebound’s stored queue of cen-
sored content reduces the latency that stems from proxying trafﬁc
between the client the covert destination, it does not account for the
latency introduced by the relay station in replacing the contents of
the HTTP GET request. Furthermore, all previous systems are vul-
nerable to traditional website ﬁngerprinting techniques, in which
the censor can compare packet sizes, timings, and directionality to
differentiate between decoy and regular trafﬁc while ﬁngerprinting
the censored site.
We designed Slitheen to defend against latency analysis and web-
site ﬁngerprinting attacks. We present a system that perfectly mim-
ics the expected packet sequences from the overt site and tech-
niques for reducing the latency introduced by the Slitheen station.
Our system also provides strong defenses against active and routing-
based attacks, including the TCP replay attack mentioned above.
We give the details of our system and provide a security analysis
and comparison to previous systems in Section 3 and Section 4,
respectively.
3. SLITHEEN SYSTEM DETAILS
Slitheen defends against passive latency analysis and website ﬁn-
gerprinting attacks by perfectly imitating a typical access to an al-
lowed, overt destination. We accomplish this by maintaining the
connection to the overt site after the completion of the tagging pro-
tocol in the TLS handshake. At this point, the relay station is able to
man-in-the-middle the TLS connection to the overt site and monitor
or modify both upstream and downstream data. The station extracts
upstream data to the covert destination from specialized headers in
valid HTTP GET requests to the overt site, and replaces image or
video resources from the overt site with downstream data from the
covert destination. In this section, we give a high-level overview
of the Slitheen architecture and follow with a detailed discussion
of the replacement protocol. We show an overview of the Slitheen
architecture in Figure 2.
3.1 Architecture Overview
A typical access to content on the web consists of a collection of
TCP connections, over which ﬂow HTTP requests and responses.
The ﬁrst connection to the overt destination typically requests an
HTML document, which in turn prompts the client’s browser to
issue several more requests to HTTP servers (the same or different)
to collect various resources such as cascading style sheets (CSS),
JavaScript, images, and videos. Certain types of resources, such as
CSS or Javascript, may in turn require additional resources to be
fetched by the client’s browser. Others, such as images or videos,
are “leaf” content types in that they never contain a request for an
additional resource.
In Slitheen, we have the client access the overt site exactly as
a regular user would, fetching both the original HTML page from
the overt site as well as all additional resources necessary to com-
pletely load the page. When a client initiates a Slitheen session
with the desire to proxy information to a censored, blocked site,
they ﬁrst randomly generate a 32-byte Slitheen identiﬁcation num-
ber. They then proceed to access the overt site through the use of an
overt user simulator (OUS) running on the client’s machine (as part
of the Slitheen client code). The OUS is a headless browser that
requests a page from an overt destination over a tagged TLS con-
nection. When the OUS receives a resource that contains a request
for additional resources, it issues these requests over tagged TLS
connections to the servers that host them. Although the OUS must
also realistically simulate the client’s usual browsing habits and add
“think time” between different overt page accesses, we leave this as
future, and largely orthogonal, work.
The tagging procedure of Slitheen is identical to that of Telex,
though in principle we could use something different, as the tagging
procedure is not the contribution of Slitheen. The client’s OUS ini-
tiates a tagged ﬂow with a decoy routing station by inserting a Telex
tag into the random nonce of the ClientHello message at the begin-
ning of the TLS handshake with the overt site. If the path between
the client and the overt site crosses into the territory of a friendly
ISP with a deployed Slitheen station, the tag is recognized and the
Figure 2: After the establishment of a TLS session between the client’s Overt User Simulator (OUS) and the overt site, the Slitheen station
may monitor the encrypted trafﬁc (shaded) in both directions. The station receives upstream proxy data from the client in an X-Slitheen
header of a valid HTTP GET request to the overt site. Once the station has relayed the upstream data to the censored site, it stores the
downstream responses in a queue. When the station receives responses from the overt site, it replaces leaf content types such as images with
the queued data. This data is then forwarded by the OUS to the SOCKS frontend and ﬁnally received by the client’s browser. The censor
sees only the TLS handshake and encrypted trafﬁc to and from the overt site.
station continues to passively observe the TLS handshake, allowing
it to compute the shared master secret for the TLS connection.
After the TLS session has been established and the tagging pro-
cedure is complete, the Slitheen protocol deviates from Telex. Ra-
ther than terminating the connection to the overt site on behalf of
the client or leaving it stale, the station continues to passively mon-
itor the session as the OUS proceeds to request content from the
overt site in the usual manner. When the OUS issues a valid HTTP
GET request for a resource to the overt site, the Slitheen station
inspects the headers of this request for an X-Slitheen header con-
taining the Slitheen identiﬁcation number of the client, and any up-
stream data meant for a covert destination. The station now asso-
ciates the tagged ﬂow with the given Slitheen ID, replaces the con-
tents of this header with garbage bytes, and allows it to continue
to the overt site. If the X-Slitheen header contained upstream data
to be proxied to a covert destination, the station simultaneously re-
lays this data, and stores any responses in a queue of content for
the Slitheen ID, to later replace leaf content from overt sites to the
client associated with the given ID. If the overt site has a large
amount of images or a video stream, a large amount of content can
be delivered to the client quickly, allowing them to browse latency-
sensitive covert sites. To keep the size of HTTP requests consis-
tent with the addition of the X-Slitheen header and data, the client
may replace only non-essential headers or compress existing head-
ers to be later decompressed by the relay station before they are
forwarded to the overt site. If the existing headers are compressed,
the X-Slitheen header is simply removed by the relay station.
When the Slitheen station receives downstream trafﬁc from an
overt site, it ﬁrst decrypts the TLS record and inspects the HTML
response for the content type of the resource. If the content type is
not a leaf type, the station will re-encrypt the record and let the
resource pass unaltered to the client.
If the resource has a leaf
content type, the station will replace the response body with data
from the downstream queue pertaining to the Slitheen ID of the
ﬂow and change the content type of the resource to “slitheen”. It
then re-encrypts the modiﬁed record, recomputes the TCP check-
sum, and sends the packet on its way.
If there is a shortage of
downstream data, the station will replace the resource with garbage
bytes, padding the response body to the expected length. When the
OUS receives the resource, it sends all resources of the “slitheen”
content type to be processed and sent to the client’s (real, not OUS)
browser. All other resources, it processes in the usual manner. Note
that the usage of a Slitheen ID allows covert data for a single client
to split across multiple tagged ﬂows.
By replacing the leaf resources of valid HTTP requests, Slith-
een perfectly imitates an access to an overt site. Regardless of ad-
vances in website ﬁngerprinting techniques, a censor will be un-
able to distinguish between a Slitheen decoy routing session and
a regular access to the overt site based on packet sequence pat-
terns such as packet lengths, directionalities, and timings. As in
Rebound, we completely eliminate one form of latency identiﬁed
by Schuchard et al. by not waiting for responses from possibly dis-
tant covert destinations; unlike Rebound, however, we instead im-
mediately replace leaf responses with content that is available in
the saved downstream queue. The key insight of Slitheen is that
whenever a packet arrives at the relay station from the overt desti-
nation, the relay station will immediately forward a packet toward
the client with the same size and TCP state; only the (encrypted)
contents of the packet will be possibly replaced with (again en-
crypted) censored content, and only when the replaced content is a
leaf type. We show that this replacement process introduces a mini-
mal amount of latency, leaving the censor unable to detect the usage
of a decoy routing system, and give the results of timing analysis in
Section 6.
Not only does our system design defend against passive attacks,
but also against known active attacks on decoy routing schemes.
Slitheen defends against TCP replay attacks by actively maintain-
ing the connection between the client and the overt site. Since our
replacements match the sizes of requests and responses exactly, the
TCP state between the client and the overt site as seen by the censor
is the true TCP state. Furthermore, Slitheen eliminates the ability
of the censor to identify its use through TCP/IP protocol ﬁnger-
printing. The station modiﬁes only application-level data, which is
unidentiﬁable by the censor as ciphertext. We do not need to mimic