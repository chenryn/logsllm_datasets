Actual URL: http://www.xn--rczniki-98a.pl/r%C4%99cznik?model=Ja%B6#Złóż_zamówienie
Label converted Path converted Query string Literal UTF-8
to Punycode to UTF-8 converted to
ISO 8859-2
Of all the URL-based encoding approaches, IDNA soon proved to be the
most problematic. In essence, the domain name in the URL shown in the
browser’s address bar is one of the most important security indicators on the
Web, as it allows users to quickly differentiate sites they trust and have done
business with from the rest of the Internet. When the hostname shown by the
browser consists of 38 familiar and distinctive characters, only fairly careless
victims will be tricked into thinking that their favorite example.com domain
and an impostor examp1e.com site are the same thing. But IDNA casually and
indiscriminately extended these 38 characters to some 100,000 glyphs sup-
ported by Unicode, many of which look exactly alike and are separated from
each other based on functional differences alone.
34 Chapter 2
How bad is it? Let’s consider Cyrillic, for example. This alphabet has a
number of homoglyphs that look practically identical to their Latin counter-
parts but that have completely different Unicode values and resolve to com-
pletely different Punycode DNS names:
Latin a c e i j o p s x y
U+0061 U+0063 U+0065 U+0069 U+006A U+006F U+0070 U+0073 U+0078 U+0079
Cyrillic a c e i j o p s x y
U+0430 U+0441 U+0435 U+0456 U+0458 U+043E U+0440 U+0455 U+0445 U+0443
When IDNA was proposed and first implemented in browsers, nobody
seriously considered the consequences of this issue. Browser vendors appar-
ently assumed that DNS registrars would prevent people from registering
look-alike names, and registrars figured it was the browser vendors’ problem
to have unambiguous visuals in the address bar.
In 2002 the significance of the problem was finally recognized by all
parties involved. That year, Evgeniy Gabrilovich and Alex Gontmakher pub-
lished “The Homograph Attack,”11 a paper exploring the vulnerability in
great detail. They noted that any registrar-level work-arounds, even if imple-
mented, would have a fatal flaw. An attacker could always purchase a whole-
some top-level domain and then, on his own name server, set up a subdomain
record that, with the IDNA transformation applied, would decode to a string
visually identical to example.com/ (the last character being merely a nonfunc-
tional look-alike of the actual ASCII slash). The result would be:
http://example.com/.wholesome-domain.com/
This only looks like a real slash.
There is nothing that a registrar can do to prevent this attack, and the
ball is in the browser vendors’ court. But what options do they have, exactly?
As it turns out, there aren’t many. We now realize that the poorly envi-
sioned IDNA standard cannot be fixed in a simple and painless way. Browser
developers have responded to this risk by reverting to incomprehensible
Punycode when a user’s locale does not match the script seen in a particular
DNS label (which causes problems when browsing foreign sites or when using
imported or simply misconfigured computers); permitting IDNA only in cer-
tain country-specific, top-level domains (ruling out the use of international-
ized domain names in .com and other high-profile TLDs); and blacklisting
certain “bad” characters that resemble slashes, periods, white spaces, and
soforth (a fool’s errand, given the number of typefaces used around the
world).
These measures are drastic enough to severely hinder the adoption of
internationalized domain names, probably to a point where the standard’s
lingering presence causes more security problems than it brings real usability
benefits to non-English users.
It Starts with a URL 35
Common URL Schemes and Their Function
Let’s leave the bizarre world of URL parsing behind us and go back to the
basics. Earlier in this chapter, we implied that certain schemes may have
unexpected security consequences and that because of this, any web applica-
tion handling user-supplied URLs must be cautious. To explain this point a
bit better, it is useful to review all the URL schemes commonly supported in
a typical browser environment. These can be combined into four basic groups.
Browser-Supported, Document-Fetching Protocols
These schemes, handled internally by the browser, offer a way to retrieve
arbitrary content using a particular transport protocol and then display it
using common, browser-level rendering logic. This is the most rudimentary
and the most expected function of a URL.
The list of commonly supported schemes in this category is surprisingly
short: http: (RFC 2616), the primary transport mode used on the Web and
the focus of the next chapter of this book; https:, an encrypted version of HTTP
(RFC 281812); and ftp:, an older file transfer protocol (RFC 95913). All brows-
ers also support file: (previously also known as local:), a system-specific method
for accessing the local filesystem or NFS and SMB shares. (This last scheme is
usually not directly accessible through Internet-originating pages, though.)
Two additional, obscure cases also deserve a brief mention: built-in
support for the gopher: scheme, one of the failed predecessors of the Web
(RFC 143614), which is still present in Firefox, and shttp:, an alternative,
failed take on HTTPS (RFC 266015), still recognized in Internet Explorer
(but today, simply aliased to HTTP).
Protocols Claimed by Third-Party Applications and Plug-ins
For these schemes, matching URLs are simply dispatched to external, spe-
cialized applications that implement functionality such as media playback,
document viewing, or IP telephony. At this point, the involvement of the
browser (mostly) ends.
Scores of external protocol handlers exist today, and it would take another
thick book to cover them all. Some of the most common examples include
the acrobat: scheme, predictably routed to Adobe Acrobat Reader; callto: and
sip: schemes claimed by all sorts of instant messengers and telephony soft-
ware; daap:, itpc:, and itms: schemes used by Apple iTunes; mailto:, news:, and
nntp: protocols claimed by mail and Usenet clients; mmst:, mmsu:, msbd:, and
rtsp: protocols for streaming media players; and so on. Browsers are some-
times also included on the list. The previously mentioned firefoxurl: scheme
launches Firefox from within another browser, while cf: gives access to Chrome
from Internet Explorer.
For the most part, when these schemes appear in URLs, they usually
have no impact on the security of the web applications that allow them to
gothrough (although this is not guaranteed, especially in the case of plug-
in–supported content). It is worth noting that third-party protocol handlers
tend to be notoriously buggy and are sometimes abused to compromise the
36 Chapter 2
operating system. Therefore, restricting the ability to navigate to mystery pro-
tocols is a common courtesy to the user of any reasonably trustworthy website.
Nonencapsulating Pseudo-Protocols
An array of protocols is reserved to provide convenient access to the
browser’s scripting engine and other internal functions, without actually
retrieving any remote content and perhaps without establishing an isolated
document context to display the result. Many of these pseudo-protocols are
highly browser-specific and are either not directly accessible from the Inter-
net or are incapable of doing harm. However, there are several important
exceptions to this rule.
Perhaps the best-known exception is the javascript: scheme (in earlier
years, also available under aliases such as livescript: or mocha: in Netscape brows-
ers). This scheme gives access to the JavaScript-programming engine in the
context of the currently viewed website. In Internet Explorer, vbscript: offers
similar capabilities through the proprietary Visual Basic interface.
Another important case is the data: protocol (RFC 239716), which
permits short, inline documents to be created without any extra network
requests and sometimes inherits much of their operating context from the
referring page. An example of a data: URL is:
data:text/plain,Why,%20hello%20there!
These externally accessible pseudo-URLs are of acute significance to site
security. When navigated to, their payload may execute in the context of the
originating domain, possibly stealing sensitive data or altering the appear-
ance of the page for the affected user. We’ll discuss the specific capabilities
of browser scripting languages in Chapter 6, but as you might expect, they
are substantial. (URL context inheritance rules, on the other hand, are the
focus of Chapter 10.)
Encapsulating Pseudo-Protocols
This special class of pseudo-protocols may be used to prefix any other URL
in order to force a special decoding or rendering mode for the retrieved
resource. Perhaps the best-known example is the view-source: scheme sup-
ported by Firefox and Chrome, used to display the pretty-printed source of
an HTML page. This scheme is used in the following way:
view-source:http://www.example.com/
Other protocols that function similarly include jar:, which allows content
to be extracted from ZIP files on the fly in Firefox; wyciwyg: and view-cache:,
which give access to cached pages in Firefox and Chrome respectively; an
oddball feed: scheme, which is meant to access news feeds in Safari;17 and a
host of poorly documented protocols associated with the Windows help sub-
system and other components of Microsoft Windows (hcp:, its:, mhtml:, mk:,
ms-help:, ms-its:, and ms-itss:).
It Starts with a URL 37
The common property of many encapsulating protocols is that they allow
the attacker to hide the actual URL that will be ultimately interpreted by the
browser from naïve filters: view-source:javascript: (or even view-source:view-
source:javascript:) followed by malicious code is a simple way to accomplish
this. Some security restrictions may be present to limit such trickery, but they
should not be relied upon. Another significant problem, recurring especially
with Microsoft’s mhtml:, is that using the protocol may ignore some of the
content directives provided by the server on HTTP level, possibly leading
towidespread misery.18
Closing Note on Scheme Detection
The sheer number of pseudo-protocols is the primary reason why web appli-
cations need to carefully screen user-supplied URLs. The wonky and browser-
specific URL-parsing patterns, coupled with the open-ended nature of the
list of supported schemes, means that it is unsafe to simply blacklist known
bad schemes; for example, a check for javascript: may be circumvented if this
keyword is spliced with a tab or a newline, replaced with vbscript:, or prefixed
with another encapsulating scheme.
Resolution of Relative URLs
Relative URLs have been mentioned on several occasions earlier in the chap-
ter, and they deserve some additional attention at this point, too. The reason
for their existence is that on almost every web page on the Internet, a consid-
erable number of URLs will reference resources hosted on that same server,
perhaps in the same directory. It would be inconvenient and wasteful to require
a fully qualified URL to appear in the document every time such a reference
is needed, so short, relative URLs (such as ../other_file.txt) are used instead.
The missing details are inferred from the URL of the referring document.
Because relative URLs are allowed to appear in exactly the same scenar-
ios in which any absolute URL may appear, a method to distinguish between
the two is necessary within the browser. Web applications also benefit from the
ability to make the distinction, because most types of URL filters may want to
scrutinize absolute URLs only and allow local references through as is.
The specification may make this task seem very simple: If the URL string
does not begin with a valid scheme name followed by a semicolon and, pref-
erably, a valid “//” sequence, it should be interpreted as a relative reference.
And if no context for parsing such a relative URL exists, it should be rejected.
Everything else is a safe relative link, right?
Predictably, it’s not as easy as it seems. First, as outlined in previous sec-
tions, the accepted set of characters in a valid scheme name, and the patterns
accepted in lieu of “//”, vary from one implementation to another. Perhaps
more interestingly, it is a common misconception that relative links can
point only to resources on the same server; quite a few other, less-obvious
variants of relative URLs exist.
38 Chapter 2
Let’s have a quick peek at the known classes of relative URLs to better
illustrate this possibility.
Scheme, but no authority present (http:foo.txt)
This infamous loophole is hinted at in RFC 3986 and attributed to an
oversight in one of the earlier specs. While said specs descriptively clas-
sified such URLs as (invalid) absolute references, they also provided a
promiscuous reference-parsing algorithm keen on interpreting them
incorrectly.
In the latter interpretation, these URLs would set a new protocol
and path, query, or fragment ID but have the authority section copied
over from the referring location. This syntax is accepted by several
browsers, but inconsistently. For example, in some cases, http:foo.txt
maybe treated as a relative reference, while https:example.com may be
parsed as an absolute one!
No scheme, but authority present (//example.com)
This is another notoriously confusing but at least well-documented quirk.
While /example.com is areference to a local resource on the current server,
the standard compels browsers to treat //example.com as a very different
case: a reference toa different authority over the current protocol. In
this scenario, the scheme will be copied over from the referring location,
and all other URL details will be derived from the relative URL.
No scheme, no authority, but path present (../notes.txt)
This is the most common variant of a relative link. Protocol and author-
ity information is copied over from the referring URL. If the relative
URL does not start with a slash, the path will also be copied over up to
the rightmost “/”. For example, if the base URL is http://www.example
.com/files/, the path isthe same, but in http://www.example.com/files/index
.html, the filename is truncated. The new path is then appended, and
standard path normalization follows on the concatenated value. The
query string and fragment ID are derived only from the relative URL.
No scheme, no authority, no path, but query string present (?search=bunnies)
In this scenario, protocol, authority, and path information are copied
verbatim from the referring URL. The query string and fragment ID
arederived from the relative URL.
Only fragment ID present (#bunnies)
All information except for the fragment ID is copied verbatim from the
referring URL; only the fragment ID is substituted. Following this type of
relative URL does not cause the page to be reloaded under normal cir-
cumstances, as noted earlier.
Because of the risk of potential misunderstandings between application-
level URL filters and the browser when handling these types of relative refer-
ences, it is a good design practice never to output user-supplied relative URLs
verbatim. Where feasible, they should be explicitly rewritten to absolute ref-
erences, and all security checks should be carried out against the resulting
fully qualified address instead.
It Starts with a URL 39
Security Engineering Cheat Sheet
When Constructing Brand-New URLs Based on User Input
 If you allow user-supplied data in path, query, or fragment ID: If one of the section
delimiters manages to get through without proper escaping, the URL may have a differ-
ent effect from what you intended (for example, linking one of the user-visible HTML
buttons to the wrong server-side action). It is okay to err on the side of caution: When
inserting an attacker-controlled field value, you can simply percent-escape everything
butalphanumerics.
 If you allow user-supplied scheme name or authority section: This is a major code injec-
tion and phishing risk! Apply the relevant input-validation rules outlined below.
When Designing URL Input Filters
 Relative URLs: Disallow or explicitly rewrite them to absolute references to avoid trouble.
Anything else is very likely unsafe.
 Scheme name: Permit only known prefixes, such as http://, https://, or ftp://. Do not use
blacklisting instead; it is extremely unsafe.
 Authority section: Hostname should contain only alphanumerics, “-”, and “.” and can only
be followed by “/”, “?”, “#”, or end-of-string. Allowing anything else will backfire. If you
need to examine the hostname, make sure to make a proper right-hand substring match.
In rare cases, you might need to account for IDNA, IPv6 bracket notation, port num-
bers, or HTTP credentials in the URL. If so, you must fully parse the URL, validate all sec-
tions and reject anomalous values, and reserialize them into a nonambiguous, canonical,
well-escaped representation.
When Decoding Parameters Received Through URLs
 Do not assume that any particular character will be escaped just because the standard says
so or because your browser does it. Before echoing back any URL-derived values or put-
ting them inside database queries, new URLs, and so on, scrub them carefully for danger-
ous characters.
40 Chapter 2
H Y P E R T E X T T R A N S F E R
P R O T O C O L
The next essential concept we need to discuss is the
Hypertext Transfer Protocol (HTTP): the core trans-
fer mechanism of the Web and the preferred method
for exchanging URL-referenced documents between
servers and clients. Despite having hypertext in its
name, HTTP and the actual hypertext content (the
HTML language) often exist independent of each
other. That said, they are intertwined in sometimes
surprising ways.
The history of HTTP offers interesting insight into its authors’ ambitions
and the growing relevance of the Internet. Tim Berners-Lee’s earliest 1991
draft of the protocol (HTTP/0.91) was barely one and a half pages long, and
it failed to account for even the most intuitive future needs, such as extensi-
bility needed to transmit non-HTML data.
Five years and several iterations of the specification later, the first
officialHTTP/1.0 standard (RFC 19452) tried to rectify many of these short-
comings in about 50 densely packed pages of text. Fast-forward to 1999, and
in HTTP/1.1 (RFC 26163), the seven credited authors attempted to antici-
pate almost every possible use of the protocol, creating an opus over 150
pages long. That’s not all: As of this writing, the current work on HTTPbis,4
essentially a replacement for the HTTP/1.1 specification, comes to 360 pages
or so. While much of the gradually accumulated content is irrelevant to the
modern Web, this progression makes it clear that the desire to tack on new
features far outweighs the desire to prune failed ones.
Today, all clients and servers support a not-entirely-accurate superset of
HTTP/1.0, and most can speak a reasonably complete dialect of HTTP/1.1,
with a couple of extensions bolted on. Despite the fact that there is no practi-
cal need to do so, several web servers, and all common browsers, also main-
tain backward compatibility with HTTP/0.9.
Basic Syntax of HTTP Traffic
At a glance, HTTP is a fairly simple, text-based protocol built on top of
TCP/IP.* Every HTTP session is initiated by establishing a TCP connection
to the server, typically to port 80, and then issuing a request that outlines the