61
user, so Pileus conﬁnes cloud services to a vendor label. The sec-
ond category involves operations that operate over multiple users’
data at the same time (e.g., delete all VMs on a node). In this case,
Pileus conﬁnes cloud services using group label, which combines
authorities of multiple users that are involved in the operation.
Endorsers and Declassiﬁers. A cloud operation would involve
DIFC-aware cloud services only if it will cause data to ﬂow across
user boundaries (i.e., resource sharing). In our study, we found that
only two kinds of resources, volume and image, might be shared
across users. Although 13 cloud operations involve volume or im-
age sharing, the types of declassiﬁcation and endorsement are lim-
ited, as shown below.
User → Public declassiﬁcation allows a user to safely release a
private resource to public. For images, the declassiﬁer is motivated
by the problem studied in Amazonia [8], where a careless user may
publish her images with sensitive data such as API keys remained.
We thus implemented the countermeasures suggested in Amazonia
which parses the image and scans for any sensitive data. The im-
age declassiﬁer achieves the following security guarantee: without
proper declassiﬁcation, user images will not be released to public
either intentionally or by mistake.
For volumes, declassiﬁcation to public means removing any data
residue. So, to implement a volume declassiﬁer, we factored out
the function in OpenStack volume service that zeros out all data on
a volume. The difference is that in OpenStack, vulnerabilities [12,
13] can cause this function to be omitted. But on Pileus, the volume
declassiﬁer must be run to return an used volume.
Public → User endorsement allows a user to safely use a public
resource. For images, the problem is motivated by vulnerabilities
such as [41]. We provided two reference implementations. One
endorses image by performing a checksum against a white list and
another scans the image for malware.
User → User data ﬂow allows a user to selectively share a re-
source with another user (e.g., Alice shares her volume with Bob).
In this case, the owner of the resource needs to declassify the data
(i.e., run a declassiﬁer), and the receiver needs to endorse the data
(i.e., run an endorser). To implement a declassifer for the owner
is different from declassifying to the public, since in this case the
resource may contain private data that the owner wants only the re-
ceiver (e.g., Bob, not public) to be able to access. The general idea
is that declassiﬁer will still run with the owner’s ownership, as it
is trusted by the owner to declassify data, but it will create a new
intermediate secrecy tag, say n, to label the resource and transfer
the ownership of n to the receiver. Then using the ownership of n,
the receiver, and only the receiver, will be able to access the data.
The receiver may endorse the resource using the same endorsers as
if the resource is from public.
Latency(s)
OpenStack
Pileus
Percentage
delete
1.72
1.74
resize
boot
4.07
3.92
4.16
4.01
2.3% 0.8% 2.2%
snapshot migrate
2.83
2.91
2.8%
4.11
4.20
2.2%
Table 5: Latency for cloud operations.
6.5 Performance
Our testbed consists of six cloud nodes:
three running nova-
compute, one running Glance services, one running Cinder services
and the last one running the rest. Cloud nodes are identical blades
with 2.4Ghz Intel E5-2609 CPU and 64GB memory, installed with
Ubuntu 14.04.
Pileus Kernel. Table 4 shows micro-benchmark results for some
system calls. The process under test has secrecy and integrity label
with both 20 tags. For most system calls, Pileus kernel adds a la-
tency of a factor of 1.1-5 with relative to native Linux. Since Pileus
runs the DIFC mechanism in kernel, the performance is better than
Flume [21]. It also appears to be slightly better than FlowK [48],
another kernel DIFC module developed contemporarily.
Pileus Daemon. We evaluate the throughput of Pileus daemon by
stressing it with large volume of events.
In original OpenStack,
the throughput for cloud service is 1,200 req/sec whereas in Pileus
it is 950 req/sec (20.8% slowdown). The reason is that cloud ser-
vices spawn green threads but Pileus Daemon spawns processes,
in order to isolate them using user labels. To improve the perfor-
mance, a possible solution is to build new OS abstractions that can
be as lightweight as threads but have the same level of isolation as
processes, such as the event process abstraction proposed in As-
bestos [15]. But this may require intrusive kernel modiﬁcation.
Ownership Registry. We evaluate the scalability of the OR by
stressing it with high frequency of spawn request. Results show
that the OR can handle up to ∼3000 req/sec. Most of the overhead
comes from two sources: (1) the spawn scheduling algorithm and
(2) the OR signing the authority token during spawn. One way
to optimize it is to separate the spawn scheduling algorithm into a
separate service. This service needs not to be trusted, but the OR
must be able to check the output of the service to ensure that the
global cloud policy is met (e.g., CoI is not violated).
Overall Latency. Table 5 shows the latency perceived by cloud
users. While Pileus adds latency in its network protocol (due to
the added round of communication with the OR during spawn),
the latency is amortized by the time spent on actually processing
the events. As a result, we noticed less than 3% additional latency
when performing various cloud operations in Pileus.
7. RELATED WORK
There has been much work on improving data security in cloud,
including data encryption [31], data sealing [34], protection against
compromised hypervisor and privileged domain [53, 9, 6, 46] and
leakage detection [30]. These works aim to protect data from par-
ties in cloud that should not have access. Pileus addresses a differ-
ent concern: if a cloud service has legitimate access to data, how
to prevent them from being leveraged as confused deputies due to
cloud service vulnerabilities.
Another line of research focuses on security of cloud infrastruc-
ture. The CV framework [35] allows cloud users to reason about in-
tegrity of cloud nodes. CloudArmor [44] protects cloud operations
performed on benign cloud nodes from compromised ones by en-
forcing a cloud operation model. These works are complementary
to Pileus. SOS [45] addresses the concern of compromised com-
pute services, but it requires other cloud services to be trustworthy.
In contrast, Pileus can systematically run and conﬁne any type of
cloud services. Pileus is motivated by the SCOS [43], which advo-
cates the development of a secure cloud operating system in order
to conﬁne vulnerable cloud services.
Pileus takes advantage of a number of well-established mecha-
nisms in decentralized information ﬂow control (DIFC) systems. In
particular, Pileus adopts its label and ownership from Flume [21]
and its event handler abstraction from Asbestos [15]. The DIFC
model was proposed by Myers and Liskov [24], then it was incor-
porated into programming languages such as Jif [25] and systems
such as Asbestos [15], HiStar [51], Flume [21], Laminar [33] and
Aeolus [11]. These systems often assume a fully trusted reference
monitor (or several mutually trusted reference monitors) that can
track information ﬂows on the system. Pileus, on the other hand,
assumes cloud nodes are mutually distrustful.
Similar to DStar [52], Fabric [23] and Mobile-fabric [4], Pileus
assumes reference monitor on a single node may be compromised
and therefore cloud nodes are mutually distrustful. However, Pileus
differs from these systems in its ability to control authority distribu-
tion. In Pileus, the ownership registry (OR) ensures that authority
propagation across cloud nodes will not violate the cloud policy
and it enables timely authority revocation from nodes. In addition,
Pileus developed a systematic approach for cloud users to delegate
their authorities to event handlers that they trust, without the fear
the such trust might be misused to run other code.
Researchers have shown that DIFC is an useful model in protect-
ing distributed web applications deployed on PaaS clouds [29, 5].
These systems focus on protecting cloud hosted applications and
rely on a trustworthy cloud platform, including underlying cloud
services and nodes. Pileus can be used to secure this foundation.
The ownership authorization in Pileus is motivated by capability-
based systems [37, 47, 16]. A security issue with traditional capa-
bility systems is that they cannot enforce the ⋆-property [49]. To
address this concern, multiple designs [20, 18, 16] were proposed
that combined capability with authority check to limit who may ex-
ercise the capability. Pileus adopts a similar design idea that uses
ownership authorization to securely delegate the ownerships to par-
ticular event handlers that cloud users trust.
Cloud vendors have started developing some countermeasures
to address the security issue reported in this paper. For example,
an OpenStack blueprint [28] proposes to encrypt the message be-
tween cloud services, preventing a malicious cloud node from sniff-
ing the channel. As another example, OpenStack supports scoped
tokens [2] which could reduce the token privilege down a single
project. However, much of these efforts are still ongoing, and they
cannot address the vulnerabilities in cloud services.
8. CONCLUSION
Pileus is a model and system for securing cloud platforms by en-
forcing decentralized information ﬂow control (DIFC) over cloud
services. On Pileus, cloud services are ephemeral, and are conﬁned
to users’ security labels, enabling least privilege. Pileus tracks and
protects users’ data as it ﬂows through the cloud platform there-
fore mitigating both cloud service vulnerabilities and compromised
cloud nodes. We ported OpenStack, a widely used cloud platform,
to Pileus and show that Pileus can greatly improve the security of
OpenStack for less than 3% overhead on user operation latency.
9. ACKNOWLEDGMENTS
The authors thank Danfeng Zhang, Susanta Nanda and the
anonymous reviewers for their comments on drafts of this paper.
This work was supported by NSF under grant No. CNS-1117692.
62
10. REFERENCES
[1] CVE-2012-3360. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-3360.
[2] Openstack keystone token. http:
//docs.openstack.org/admin-guide/keystone_tokens.html.
[3] Amazon EC2. http://aws.amazon.com/ec2.
[4] O. Arden, M. D. George, J. Liu, K. Vikram, A. Askarov, and
A. C. Myers. Sharing mobile code securely with information
ﬂow control. In Proc. 2012 IEEE Security and Privacy, 2012.
[5] J. Bacon, D. Eyers, T. Pasquier, J. Singh, I. Papagiannis, and
P. Pietzuch. Information Flow Control for Secure Cloud
Computing. IEEE Transactions on Network and System
Management, SI Cloud Service Management, 11(1):76–89,
2014.
[6] A. Baumann, M. Peinado, and G. Hunt. Shielding
applications from an untrusted cloud with haven. In Proc.
11th USENIX OSDI, 2014.
[7] W. E. Boebert and R. Y. Kain. A practical alternative to
hierarchical integrity policies. In Proceedings of the 8th
National Computer Security Conference, 1985.
[8] S. Bugiel, S. Nürnberger, T. Pöppelmann, A. Sadeghi, and
T. Schneider. AmazonIA: When elasticity snaps back. In
Proc. ACM CCS’11.
[9] S. Butt, H. A. Lagar-Cavilla, A. Srivastava, and
V. Ganapathy. Self-service cloud computing. In Proc. ACM
CCS’12.
[10] CVE-2012-0030. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-0030.
[11] W. Cheng, D. R. K. Ports, D. A. Schultz, V. Popic,
A. Blankstein, J. A. Cowling, D. Curtis, L. Shrira, and
B. Liskov. Abstractions for usable information ﬂow control
in aeolus. In USENIX ATC’12.
[12] CVE-2012-5625. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-5625.
[13] CVE-2013-4183. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2013-4184.
[14] D. E. Denning. A lattice model of secure information ﬂow.
Communications of the ACM, 19(5):236–243, 1976.
[15] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey,
D. Ziegler, E. Kohler, D. Mazières, F. Kaashoek, and
R. Morris. Labels and event processes in the asbestos
operating system. In Proc. ACM SOSP’05.
[16] L. Gong. A secure identity-based capability system. In Proc.
IEEE Security and Privacy, 1989.
[17] N. Hardy. The confused deputy. Operating Systems Review,
22(4):36–38, Oct. 1988.
[18] P. A. Karger. Limiting the damage potential of discretionary
trojan horses. In Proc. IEEE Security and Privacy, 1987.
[19] P. A. Karger and A. J. Herbert. An augmented capability
architecture to support lattice security and traceability of
access. In Proceedings of the 1984 IEEE Symposium on
Security and Privacy, pages 2–12, 1984.
[20] P. A. Karger and A. J. Herbert. An augmented capability
architecture to support lattice security and traceability of
access. In Proc. IEEE Security and Privacy, 1984.
[21] M. N. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F.
Kaashoek, E. Kohler, and R. Morris. Information ﬂow
control for standard OS abstractions. In Proc. ACM SOSP’07.
[22] libselinux. http://www.rpmﬁnd.net//linux/RPM/fedora/devel/
rawhide/armhfp/l/libselinux-2.4-5.fc24.armv7hl.html.
[23] J. Liu, M. D. George, K. Vikram, X. Qi, L. Waye, and A. C.
63
Myers. Fabric: A platform for secure distributed
computation and storage. In Proc. ACM SOSP’09.
[24] A. C. Myers and B. Liskov. A decentralized model for
information ﬂow control. In Proc. 16th ACM SOSP, 1997.
[25] A. C. Myers and B. Liskov. Protecting privacy using the
decentralized label model. ACM TOCS, 9(4):410–442, Oct.
2000.
[26] Security-enhanced linux. http://www.nsa.gov/selinux.
[27] OpenStack Open Source Cloud Computing Software.
http://www.openstack.org//, 2008.
[28] OpenStack Message Security.
https://wiki.openstack.org/wiki/MessageSecurity/.
[29] T. Pasquier, J. Singh, D. Eyers, and J. Bacon. CamFlow:
Managed Data-Sharing for Cloud Services. IEEE
Transactions on Cloud Computing, 2015.
[30] C. Priebe, D. Muthukumaran, D. O’ Keeffe, D. Eyers,
B. Shand, R. Kapitza, and P. Pietzuch. Cloudsafetynet:
Detecting data leakage between cloud tenants. In Proc. ACM
CCSW’14.
[31] K. P. N. Puttaswamy, C. Kruegel, and B. Y. Zhao. Silverline:
Toward data conﬁdentiality in storage-intensive cloud
applications. In Proc. 2nd ACM SOCC, 2011.
[32] Rackspace Cloud Servers. http://www.rackspace.com/cloud/.
[33] I. Roy, D. E. Porter, M. D. Bond, K. S. McKinley, and
E. Witchel. Laminar: Practical ﬁne-grained decentralized
information ﬂow control. In Proc. ACM PLDI, 2009.
[34] N. Santos, R. Rodrigues, K. P. Gummadi, and S. Saroiu.
Policy-sealed data: A new abstraction for building trusted
cloud services. In Proc. 21st USENIX Security, 2012.
[35] J. Schiffman, Y. Sun, H. Vijayakumar, and T. Jaeger. Cloud
veriﬁer: Veriﬁable auditing service for IaaS clouds. In Proc.
IEEE SERVICE’13.
[36] The SEPostgreSQL Project.
https://wiki.postgresql.org/wiki/Main_Page.
[37] J. S. Shapiro, J. M. Smith, and D. J. Farber. Eros: A fast
capability system. In Proc. ACM SOSP’99.
[38] J. S. Shapiro and S. Weber. Verifying the EROS conﬁnement
mechanism. In Proceedings of the 2000 IEEE Symposium on
Security and Privacy, pages 166–176, 2000.
[39] CVE-2012-4573. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-4573.
[40] CVE-2012-5482. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2012-5482.
[41] CVE-2013-4354. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2013-4354.
[42] CVE-2015-3221. http://cve.mitre.org/cgi-bin/cvename.cgi?
name=CVE-2015-3221.
[43] Y. Sun, G. Petracca, and T. Jaeger. Inevitable failure: The
ﬂawed trust assumption in the cloud. In Proc. ACM
CCSW’14.
[44] Y. Sun, G. Petracca, T. Jaeger, H. Vijayakumar, and
J. Schiffman. Cloudarmor: Protecting cloud commands from
compromised cloud services. In Proc. IEEE CLOUD’15.
[45] W.-K. Sze, A. Srivastava, and R. Sekar. Hardening
OpenStack Cloud Platforms against Compute Node
Compromises. Technical report, ASIACCS 2016, May 2016.
[46] R. Ta-Min, L. Litty, and D. Lie. Splitting interfaces: making
trust between applications and operating systems
conﬁgurable. In Proc. USENIX OSDI’07.
[47] A. S. Tanenbaum, S. J. Mullender, and R. van Renesse.
Using sparse capabilities in a distributed operating system. In
Proc. ICDCS’86.
[48] D. M. E. Thomas F. J.-M. Pasquier, Jean Bacon. Flowk:
Information ﬂow control for the cloud. In Proc. IEEE
CloudCom’14.
[49] W.E.Boebert. On the inability of an unmodiﬁed capability
machine to enforce the *-property. In Proc. 7th DoD/NBS
Computer Security Conference, 1984.
[50] C. Wright, C. Cowan, J. Morris, S. Smalley, and
G. Kroah-Hartman. Linux security module framework. In
Ottawa Linux Symposium, volume 8032, page 6, 2002.
[51] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazières.
Making information ﬂow explicit in HiStar. In Proc.
USENIX OSDI’06.
[52] N. Zeldovich, S. Boyd-Wickizer, and D. Mazières. Securing
distributed systems with information ﬂow control. In Proc.
USENIX NSDI’08.
[53] F. Zhang, J. Chen, H. Chen, and B. Zang. Cloudvisor:
retroﬁtting protection of virtual machines in multi-tenant
cloud with nested virtualization. In Proc. ACM SOSP’11.
64