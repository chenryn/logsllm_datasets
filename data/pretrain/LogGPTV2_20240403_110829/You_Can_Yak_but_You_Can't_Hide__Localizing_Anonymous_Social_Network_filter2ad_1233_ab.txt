features from n to just four by deﬁning xE to be the number of
probes that observe the message from east. If there are p probes
in each line, then xE can take values in {0, 1, . . . , p}. Similarly
we can deﬁne xW , xN , xS from respective directions, each taking
values in {0, 1, . . . , p}. In this case, the labeled data collapses to
S ⌘, for all i = 1, . . . , m. We mention that
⇣y(i), x(i)
if the service were to apply an obfuscation technique (such as ran-
domly choosing messages to display for each click), then we would
not collapse the features and instead use the extended feature vec-
tor.
3.2 Learning the Locations
After having collected the label data, we use supervised machine
E , x(i)
W , x(i)
N , x(i)
Figure 2: A honeycomb layout
Figure 3: A sparse probe layout (four lines of probes)
27learning regression to predict the locations of non-labeled mes-
sages. Many penalization techniques have been proposed, support
vector regression [23], ridge regression [9], and the Lasso (Least
Absolute Shrinkage and Selection Operator) [22]. For example,
ridge regression minimizes the residual sum of squares subject to
a bound on the L2-norm of the coefﬁcients and the Lasso is im-
posing an L1-penalty on the regression coefﬁcients. Owing to the
nature of the L1-penalty, the Lasso does both continuous shrinkage
and automatic variable selection simultaneously. Fu [8] compared
the prediction performance of the Lasso, ridge, and bridge regres-
sion [7] and found that none of them uniformly dominates the other
two. For simplicity, owing to its sparse representation, we ﬁnally
select the Lasso regularized linear regression model as our predic-
tive model. Each data point is then labeled with a latitude and a
Lat, y(i)
Lon⌘, for all i = 1, . . . , m.
longitude y =⇣y(i)
We also consider a heuristic that does not require any training
data, so no artiﬁcial messages need to be introduced into the sys-
tem. The heuristic is as follows. For any given target message for
which we would like to determine the location, we take the probe
readings and obtain the measurements xE, xW , xN , xS. Let x0E
and x0W denote the corresponding longitudes for xE and xW . Sim-
ilarly, let x0N and x0S denote the corresponding latitudes for xN and
xS. Then we simply use (x0E + x0W )/2 to predict the longitude
of the message, and (x0N + x0S)/2 to predict the latitude of the
message. We refer to this location inference heuristic as Centroid
Prediction. We will see that it provides very good results, although
not quite as accurate as supervised machine learning.
4. REAL-WORLD EXPERIMENTS
In this section, we show how the methodology can predict the lo-
cations from where yaks originate with a high-degree of accuracy.
We carry out three experiments.
In the ﬁrst experiment, we use
a honeycomb layout with 2,880 probes covering the University of
Montana campus in Missoula, Montana. The goal is to gain some
basic insight into Yik Yak’s service. In the second experiment, we
use our experimental setup to post 50 messages scattered through-
out the University of California Santa Cruz (UCSC) campus, and
then collect data about these messages by using 160 virtual probes
in a sparse layout. We use both the machine learning methodol-
ogy and the centroid heuristic to predict the locations of the 50
messages, and then compare the predictions with the ground-truth
location values. In the third experiment, again on the UCSC cam-
pus, we post the yaks from each of the dorm colleges on the UCSC
campus, and then attempt to predict from which dorm college each
yak was posted. We choose these campuses as they are large, con-
tiguous, and mostly isolated from non-university activity. Our en-
vironment to run the experiments was located at NYU Shanghai, in
Shanghai, China.
4.1 Preliminary Experiment
We conduct our ﬁrst experiment on the University of Montana,
in August 2015. In this experiment, we post ﬁve yaks at random
locations on the University of Montana campus. We cover the city
of Missoula with a honeycomb layout, using 2,880 probes, with
adjacent probes separated by 200 meters. We partition the virtual
probes across six computers, and have the six computers probing in
parallel. At each location, our environment took screenshots of all
the yaks seen. Each probe reading took anywhere from 30 seconds
to 2 minutes to record all the yaks made available by Yik Yak.
Figure 4 shows the results for all the probes in the honeycomb
for one of our ﬁve yaks. Green (resp. red) indicates presence (resp.
no presence) of the yak at the probe. Strikingly, for each of the
Figure 4: Probe results for one yak at the University of Mon-
tana. Green (resp. red) indicates presence (resp. no presence)
of the yak at the probe.
messages, the shape of the set of green probes is square like [15].
Oddly, there are also small ears attached to the square, vaguely
resembling the Yik Yak logo! (There are some points within the
shape that are red, which are due to the low recognition rates of
the OCR software we were using at the time.). The other four yaks
give rise to the same shape, but shifted so that the shape is roughly
centered on the message.
From this preliminary experiment, we make the following ob-
servations. First, Yik Yak does not use a static geographic region
for limiting all messages to the University of Montana (or to any
other region); if it did, then the shape of the ﬁgure would not shift
for different yaks. Instead, Yik Yak indeed employs user-centric
proximity, showing the user messages that are in proximity to that
speciﬁc user. Second, the proximity region has a deﬁnite shape, but
surprisingly it is not a circle.
4.1.1 Learning the Locations Using Lasso
Figure 5: Ground-truth, machine learning prediction, and cen-
troid prediction. A black dot represents the true location, the
corresponding blue dot is our machine learning inference, and
the corresponding red dot is the centroid prediction.
28We now apply to Yik Yak the sparse-layout and machine-
learning methodology, as described in Section 3. In this second ex-
periment, we make predictions (again from Shanghai) for the Uni-
versity of California Santa Cruz (UCSC) in mid-December 2015.
We use the sparse east, south, west, north linear layout, with probes
spaced by 100 m, as described in Section 3. Each line has 20
probes. To reduce the impact of probing error, we use two parallel
lines of probes for each direction, giving a total of 160 probes. If
two parallel probes give inconsistent results, we use the inner-most
probe that has seen the message for deﬁning the corresponding fea-
ture value. (Due to an improved OCR tool, inconsistencies were
very rare, and the additional lines of probes were probably unnec-
essary.)
To generate labeled data, we post 50 messages from random lo-
cations on the UCSC campus. As described in Section 3.2, we use
Lasso regression over our trained data set to make predictions. We
use the mean absolute errors (MAE) and the coefﬁcient of determi-
nation R2 [3] to measure the performance of the predictions. MAE
measures how close predictions are to the ground-truth values. We
apply leave-one-out cross validation to determine the parameters
for Lasso and the weights for each feature. In order to make the
weight regularization work properly, each feature is scaled within
the range [0, 1].
Figure 5 shows the locations of the 50 messages (black dots)
and the corresponding machine-learning predicted locations (blue
dots). We can see the predictions are always in the vicinity of the
actual message locations. However, the machine-learning predic-
tions have errors. As shown in Table 1, the MAE is 105.9 meters
and the coefﬁcient of determination R2 is 0.966, which indicates
that the given four features can explain 96.6% of the outcome vari-
ance. These estimates are remarkably accurate – accurate enough
to predict the dorm college from which the yak was made, as we’ll
soon discuss.
The MAE error can potentially be reduced by collecting more la-
beled data and/or reducing the spacing between the probes. (With
the current 100 m spacing, we would minimally expect an average
of 50 m errors in both the east-west and north-south directions.) Ta-
ble 1 also shows the root of mean squared error (RMSE); compared
with MAE, RMSE penalizes more the large errors.
4.1.2 Centroid Heuristic
Recall from Section 3.2 that our centroid heuristic does not re-
quire training; instead it simply takes the averages of the longitude
and latitude of the inner most probes having the presence of the tar-
get message. Figure 5 also shows the centroid predictions for our
50 yaks. A black dot represents the true location while the corre-
sponding red dot represents our centroid prediction. As shown in
Table 1, the MAE is 118.2 meters.
Table 1: Estimation accuracy (absolute distance er-
rors in units of meters)
Lasso Regression Inference
Centroid Prediction
MAE
RMSE
Minimum
Maximum
SD
105.9
117.8
14.4
217.8
51.2
118.2
125.8
30.3
220.4
43.6
out-performs the centroid heuristic. Machine learning can poten-
tially do better with a larger number of training examples. On the
other hand, the centroid heuristic does not require any training. The
errors for both approaches can potentially be reduced by reducing
the spacing between the probes.
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
200
150
100
50
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
n
o
i
t
c
i
d
e
r
P
d
o
r
t
n
e
C
i
50
Machine Learning Inference
100
150
200
Figure 6: Scatter plot of ﬁfty yaks scattered throughout the
UCSC campus
Figure 6 shows a scatter diagram where, for each of the 50 mes-
sages, the machine learning errors are plotted along the x-axis and
the centroid-heuristic predictions are plotted along the y-axis. We
see from this ﬁgure that there is a strong correlation between the
machine-learning error and the centroid error: when the machine-
learning error is small, the centroid error is typically small; and
when the machine-learning error is large, the centroid error is also
typically large. We also see from Figure 6 and Figure 7 that for
small errors (under 100 m with machine learning), the machine-
learning predictions typically out-perform the centroid predictions;
however, for large errors, neither seems to be signiﬁcantly better
than the other.
y
t
i
l
i
b
a
b
o