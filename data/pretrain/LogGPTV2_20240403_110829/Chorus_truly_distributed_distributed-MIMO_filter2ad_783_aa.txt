title:Chorus: truly distributed distributed-MIMO
author:Ezzeldin Hamed and
Hariharan Rahul and
Bahar Partov
Chorus: Truly Distributed Distributed-MIMO
Ezzeldin Hamed
Microsoft
PI:EMAIL
Hariharan Rahul
MIT CSAIL
PI:EMAIL
Bahar Partov
Wavelite
PI:EMAIL
ABSTRACT
Distributed MIMO has long been known theoretically to bring
large throughput gains to wireless networks. Recent years have
seen signiﬁcant interest and progress in developing practical
distributed MIMO systems. However, these systems only dis-
tribute the transmission function across the multiple nodes.
The control fabric that synchronizes the nodes to a common
reference phase still fundamentally requires a single leader that
all nodes in the network are capable of hearing.
This paper presents Chorus, a truly distributed distributed-
MIMO system. Chorus is leaderless – all nodes are peers, and
jointly transmit the synchronization signal used by other nodes
to synchronize to a common reference phase. The participation
of all nodes in the network in the synchronization signal en-
ables Chorus to scale to large networks, while being resilient to
node failures or changes in network connectivity, and without
imposing onerous management burdens on network adminis-
trators. We implement and evaluate Chorus and demonstrate
that it can synchronize effectively without the need for a single
leader, scale to large networks where no leader node can be
heard by all others, and provide 2.7× throughput improvement
over traditional leader-based systems.
CCS CONCEPTS
• Networks → Network protocols; Wireless access points,
base stations and infrastructure; • Hardware → Digital sig-
nal processing;
KEYWORDS
Wireless Networks, Multi-user MIMO, Distributed MIMO,
LTE, Synchronization
ACM Reference Format:
Ezzeldin Hamed, Hariharan Rahul, and Bahar Partov. 2018. Chorus:
Truly Distributed Distributed-MIMO . In SIGCOMM ’18: ACM SIG-
COMM 2018 Conference, August 20–25, 2018, Budapest, Hungary.
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made
or distributed for proﬁt or commercial advantage and that copies bear this
notice and the full citation on the ﬁrst page. Copyrights for components of this
work owned by others than ACM must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute
to lists, requires prior speciﬁc permission and/or a fee. Request permissions
from permissions@acm.org.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5567-4/18/08. . . $15.00
https://doi.org/10.1145/3230543.3230578
ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3230
543.3230578
1 INTRODUCTION
Distributed-MIMO can eliminate interference and deliver dra-
matic throughput improvements in wireless networks [2, 31, 40,
45]. It does so by synchronizing the oscillators on independent
nodes, allowing a network of transmitters to act as if they were
one huge MIMO transmitter. The theory underlying distributed
MIMO has been around for several decades [48]. Recent years
however have seen signiﬁcant advances in moving distributed-
MIMO from theory to practice [1, 5, 23, 33, 36, 46]. Multiple
systems have developed coordination protocols to synchronize
the phase of distributed oscillators, thereby allowing them to
transmit together without interference.
Yet, existing systems only focus on enabling the transmis-
sion functionality of signals to be distributed. The control plane
itself, which coordinates the transmitters, is still fairly central-
ized [1, 5, 23, 33, 36, 49]. Speciﬁcally, in past systems, the
transmitters are typically organized around an architecture con-
sisting of clusters, each with a single leader and multiple slaves.
All the slaves listen to the leader signal and synchronize the
phase of their signals to match that of the leader. Such an archi-
tecture prevents distributed MIMO networks from enjoying key
desirable features expected in network protocols: scalability,
resilience, and ease of management. First, they do not easily
scale to large networks where the transmitters cannot all hear
one node. Second, they are not resilient - they fail if the leader
fails or any of the slaves becomes disconnected from the leader.
Third, they are difﬁcult to deploy and manage. The network ad-
ministrator has to pick the nodes’ positions carefully to ensure
they all hear the leader. The administrator cannot simply add
or remove nodes, and has to monitor the system to ensure that
the connectivity constraints always hold.
Bringing scalability, resilience, and manageability to dis-
tributed MIMO is particularly important for 5G small cell
networks. All major cellular equipment manufacturers and op-
erators expect massive deployment of small cells in 5G in order
to meet capacity requirements, especially in dense urban set-
tings, such as Manhattan, downtown Tokyo etc. [10, 21, 44].
Such dense small cell deployment will naturally increase the
interference between transmitting nodes, and emphasize the
need for distributed MIMO, which both eliminates interference
and increases throughput. Further, such small cell networks
will naturally span large geographic scale (e.g., Manhattan),
and hence will need a distributed architecture that does not
461
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
E. Hamed et al.
assume the presence of one node that can be heard by all oth-
ers. Finally, small cells are typically deployed in third-party
premises with limited access and control for the operators of
the network. This will make management a nightmare with ex-
isting Distributed-MIMO solutions, as nodes cannot be easily
replaced and changes to the wireless environment are often out
of operator control, making it very hard to ensure that all slaves
always hear the leader.
In this paper, we introduce Chorus, a system that removes
these limitations and builds a truly distributed Distributed-
MIMO network. In Chorus, there are no special roles, i.e., no
leader and slaves. All Chorus nodes transmit a synchronization
signal, and all synchronize their oscillator phases by listening
to the synchronization signals transmitted by other nodes in
their vicinity. This makes the design resilient to node failure,
addition and removal. There are also no special constraints on
topology or connectivity. Thus, the coordination protocol is
easy to manage and naturally scales to large networks with
transmitters that are no longer in hearing range of each other.
Chorus is different from standard distributed consensus pro-
tocols (e.g., Paxos or Raft [25, 26, 30]). In those protocols,
the state of the system advances or rolls back only based on
interactions between the nodes in the system, and is controlled
only by the protocol. In contrast, Chorus’s distributed protocol
tracks an underlying analog state of the world (speciﬁcally, a
reference oscillator phase) that advances independently of the
protocol. This analog state cannot be controlled or rolled back
by the distributed protocol, instead the role of the protocol is
to ensure that all nodes in the system accurately track the state
of the reference oscillator to within tens of nanoseconds.
The design of Chorus has the following three components
that together deliver a fully distributed phase synchronization
protocol for distributed-MIMO.
(a) Self-Organizing Tree Architecture: As described earlier,
each Chorus node transmits a synchronization signal and syn-
chronizes with the composite synchronization signal that it
hears. Naively applying this design leads to synchronization
loops –e.g., a node may be synchronizing with a second node,
that is synchronizing with a third node, which is synchronizing
with the ﬁrst node in the loop. Such loops are destabilizing, i.e.,
they prevent the system from converging [29]. To prevent loops,
Chorus has a distributed protocol to organize the nodes in the
form of a tree (speciﬁcally a fat tree). Nodes at the same depth
of the tree transmit the synchronization signal in the same fre-
quency, and this composite synchronization signal is used by
nodes at the next lower depth to synchronize themselves. In
addition to this resilient fat tree architecture, Chorus also has a
special acyclic structure at the root to make the synchronization
tree resilient to failures of the root. We describe the details of
our protocol and resilient architecture in §5.
(b) Robust Phase Update Algorithm: In past work on dis-
tributed MIMO, each transmitter listens to the leader’s signal,
computes the difference between its phase and that of the leader,
and adds the difference to its own phase [1, 5, 23, 33, 36, 49].
This simple algorithm however does not work for Chorus. In
Chorus, the synchronization signal is no longer a clean trans-
mission from one leader – it is a composition of synchroniza-
tion signals from multiple nodes. Thus, there is more phase
variability due to potential misalignment between the transmit-
ters of the composite signal. Furthermore, in past systems, the
phase difference can be computed at the time of transmission
and applied immediately. In contrast, in Chorus, the synchro-
nization signal can be sent only sporadically due to the frame
structure of LTE. As a result, the measured phase difference
can be outdated. To deal with multiple transmitters, as well as
its more stringent synchronization requirements, Chorus uses
tools from signal processing and control theory. Speciﬁcally,
instead of using a known synchronization signal, Chorus ran-
domizes the synchronization signal sent by each transmitter in
order to ensure resilience to channel conditions. Additionally,
Chorus explicitly models measurement variability and delays,
and incorporates its model within the framework of robust con-
trol, which is known to account for these uncertainties. In §6,
we describe our controller formulation.
(c) LTE Compatibility: We would like Chorus to be directly
applicable to small cells without having to change the LTE
protocol or user devices. To do so, we leverage that LTE’s
OFDM modulation divides the frequency band into subcarriers,
which themselves get divided into timeslots called resource
elements. Chorus allocates some of these resource elements for
transmitting synchronization signals. Chorus also schedules the
resource elements used for synchronization so that they look
to user devices as if they were yet another user in the system.
Only small cells participating in Chorus need to interpret the
synchronization signal.
We implement Chorus in a hardware platform composed of
an FPGA connected to a high speed ARM core. We use the
srsLTE open source LTE stack implementation [42] and aug-
ment the eNodeB with Chorus. Our implementation therefore
provides an LTE small cell that is capable of synchronized
operation and distributed joint transmission. We perform our
experiments in the white space frequency bands (680 MHz),
which is very close to the 700-800 MHz where major US opera-
tors such as Verizon and AT&T run their networks. Our results
show:
• Chorus’s distributed synchronization is scalable, and syn-
chronizes small cells that are not within range of each other.
Speciﬁcally, the median phase variance between two such
small cells is less than 0.004 radians 2.
• Chorus is resilient to the loss of any single node by enabling
multiple nodes to simultaneously transmit the synchroniza-
tion signal. Speciﬁcally, Chorus achieves synchronization
within a phase variance of 0.002 radians 2 even when 10
independent small cells jointly transmit the synchronization
462
Chorus: Truly Distributed Distributed-MIMO
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
signal. This means that the interference between concurrent
transmissions from our distributed MIMO nodes is less than
0.5 dB.
• Chorus’s controller is resilient to variations in synchroniza-
tion signal SNR. Speciﬁcally, it delivers accurate synchro-
nization even when synchronization SNR is as low as 6 dB.
The resilience to loss of any single node, as well as variation
in synchronization SNR, ensure that Chorus’s deployments
are easy to manage.
• We evaluate Chorus in a 20 node testbed deployment, and
compare its performance with MegaMIMO [23, 33], a state-
of-the-art leader-based distributed MIMO system.1 Chorus
delivers 2.7× higher throughput than MegaMIMO in our
testbed. This gain is the result of Chorus’s ability to build
a large distributed MIMO system across nodes that cannot
hear a single leader, and allow all these nodes to transmit
together. In contrast, MegaMIMO must divide the network
into multiple distributed MIMO clusters, each within range
of a single leader. These clusters have to transmit in different
time slots to avoid mutual interference, and as a result misses
out on large throughput gains.
• We evaluate the scaling performance of Chorus in a larger ge-
ographic setting using simulation. Speciﬁcally, we consider
an example deployment of 25600 small cells in an 8 × 8 sq.
km. area, which is slightly larger than the size of Manhattan.
We show that Chorus can synchronize cells within a median
radius of 5 km to within a phase variance of 0.004 radians 2.
Nodes outside this range show higher phase variance. These
differences however are irrelevant, because these nodes are
much more distant from each other than the range at which
nodes interfere in the network.
2 RELATED WORK
Related work falls in ﬁve categories:
(a) Distributed MIMO Schemes for Wi-Fi and LTE: The
typical design of distributed MIMO systems assume a leader/
coordinator that plays a special role in synchronizing the os-
cillators of the nodes. Such a design is used in distributed
MIMO schemes proposed for both Wi-Fi and LTE, such as
MegaMIMO [23, 33], AirSync [5], AirShare [1] for Wi-Fi, as
well as Co-ordinated Multi Point (CoMP) for LTE, which is
implemented in example systems such as PCell [22, 32] and a
demonstration by Ericsson [13]. In particular, MegaMIMO and
AirSync are organized around a single leader that all slaves
must be able to hear. AirShare [1] transmits the synchronization
signal over a separate out-of-band channel, using a network of
lead emitter and slave emitters. The CoMP schemes assume a
shared clock, distributed either via GPS or a wire, and a dedi-
cated central server that creates the signals for all participating
1MegaMIMO is designed for a Wi-Fi network with one leader, but we adapt it
to larger small cell networks as we describe in §11.4.
base stations, and delivers them to all antennas using a dedi-
cated ﬁber backhaul infrastructure with very high throughput
and carefully controlled latencies. As such, these systems do
not deliver the beneﬁts of a truly distributed design. They do
not scale to a large network of small cells, they are not resilient
to network faults, and are complicated to manage.
There are some previous schemes that have considered scal-
ing beyond a single leader. For example, NEMOx [49] consid-
ers multiple clusters each having its own leader AP. The leader
APs coordinate with each other to limit interference across
clusters. However, such a system still is not resilient to the loss
of the leader within a cluster, or changes in network topology
that prevent adjacent leaders from coordinating, and is difﬁcult
to manage since it requires operators to determine the partition-
ing of the network into clusters and the corresponding leader
assignment. An extension to Airsync [35] proposes a hierarchi-
cal leader scheme that faces the same problems of scalability
and resilience, and further, that system has only been proposed
in theory and not evaluated empirically. Vidyut [46] avoids the
need for a single leader by allowing the Wi-Fi access points
to synchronize their transmissions over the power lines, even
if they are not within the same coverage area. Such a scheme
applies to nodes within the same home or building, but does
not scale to a larger network and does not apply to small cells
where nodes are geographically dispersed and connected to
different power systems.
(b) Distributed Coordination Protocols: There is a signiﬁ-
cant literature on a variety of coordination, consistency, and
consensus protocols in the distributed systems literature, such
as Dynamo, Paxos, Spanner, and Raft [11, 25, 26, 30]. These
systems are typically used to determine a leader among a set
of servers in a distributed system, and agree in a distributed
manner on states of a state machine. These systems are how-
ever fundamentally different in scope, and timescales, from
Chorus. Speciﬁcally, in these distributed protocols, the state
of the system is determined only by interactions between the
servers in the distributed system, and advances or rolls back
based on messages exchanged between them. In contrast, the
goal of Chorus is to track an analog state, speciﬁcally, the
phase of a reference oscillator, which is constantly changing
independent of the interaction between the nodes in the system.
As a result, the role of the protocol is to ensure that all nodes
in the system track this reference oscillator accurately within
tens of nanoseconds.
(c) Massive MIMO: A popular recent trend in LTE is massive
MIMO [24, 28, 38, 39]. For instance, systems such as Argos
have demonstrated designs where a large number of MIMO
antennas are packed densely on a single node. Chorus is com-