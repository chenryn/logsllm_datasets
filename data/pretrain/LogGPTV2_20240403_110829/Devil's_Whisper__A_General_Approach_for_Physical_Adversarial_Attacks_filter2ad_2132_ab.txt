on the selected FM radio channel, those who run smartphone
navigation while listening to the corresponding FM channel
will be impacted. Actually, our experimental results show that
“Okay Google, navigate to my home” can stealthily command
Google Assistant on smartphones through music and none
of the participants in our user study were able to identify the
hidden command even after listening to the AE twice. This
attack, if successful, will put both drivers and passengers to
serious danger. Given the pervasiveness of the commercial
IVC systems, it is important to understand whether such an
attack is indeed realistic, particularly when the adversary has
little information about how such systems work. Our research,
therefore, aims at ﬁnding the answer.
To hack the commercial IVC devices in the real world
successfully, there are generally two requirements for the
attacks: (R1) effectiveness (towards device) and (R2) conceal-
ing (towards human). Both of the two requirements emphasize
the practical aspects of such attacks, that is, to deceive those
devices successfully but uninterpretable by human. Unfortu-
nately, most of existing adversarial attacks fail either (R1) [20]
or (R2) [19] in some extents. Hence, we concentrate on the
research question “whether it is possible to hack those com-
mercial IVC devices (mostly black-box based) in the real
world with both (R1) and (R2) satisﬁed” in this paper.
3.2 Threat Model
Since our target is the commercial IVC devices, they are black-
box to us by default. Speciﬁcally, we have no knowledge of
the internals of the speech recognition systems, e.g., model
parameters or hyperparameters. Instead, we assume the corre-
sponding online Speech-to-Text API services, i.e., providing
real time decoding results from input audio, are open to public.
This assumption is valid for most of the popular IVC devices
available on the market, e.g., Google Cloud Speech-to-Text
API, Microsoft Bing Speech Service API, etc4. Either free
4However, as the paper is written, we could not ﬁnd such API service
from Apple yet. Communication with Apple Siri developers conﬁrmed that
Apple has not released their speech API service to the public. In this work,
we proposed an alternative approach to hack such IVC devices without
corresponding API service available, like Apple Siri, in Section 6.3.
or pay as you go, such services are accessible to third party
developers. We further assume that for the same platform, the
ASR system used to provide online speech API service and
that used for the IVC devices are the same or similar5, e.g.,
Microsoft Bing Speech Service API and Microsoft Cortana.
Once the attack audio is generated, we assume it will be
played by speakers (either dedicated speakers or speakers on
radio, TV, smartphone, computer, etc.), which is placed not
quite far away (e.g., 5~200 centimeters) from the target IVC
devices. For example, the methods proposed in [39] can be
used to remotely control the contents played by the radio.
Furthermore, we do not have the knowledge of the speakers,
or the microphones of the target devices. Once the attack is
successful, an indicator could be observed. For instance, the
attack audio with the command of “Echo, turn off the light”
is successful by observing the corresponding light off.
3.3 Technical Challenges
Currently there are several methods to attack black-box mod-
els. First, attackers can probe the black-box model by con-
tinuously querying it with different inputs, analyzing the cor-
responding outputs, and adjusting the inputs by adding per-
turbations to craft the workable AEs. However, such method
normally suffers from the problems of uncertainty in terms of
probing process and timing cost, especially for a commercial
IVC device whose models are quite complex for approxi-
mation. Another method is “transferability” based, i.e., AEs
generated on a known Model A are used to attack the tar-
get Model B, as long as those two models are similar in the
aspects of algorithm, training data and model structure. If
Model A is hard to ﬁnd, a local model can be trained based
on the algorithm and training data to approximate the target
Model B, to implement the “transferability”. However, since
the target Model B is black-box, the similarity is hard to de-
termine and the algorithm as well as the training data may not
be available.
4 Approaches
In this section, we present our approach of AE based attacks
against the commercial black-box IVC devices. Figure 1 gives
the details of our approach. We start by transferability based
approach (Step 1(cid:13) in Figure 1), via an enhancement over the
existing state-of-the-art work generating AEs against ASR
systems. Then we describe the novel approach of “Alternate
Models based Generation” (Step 2(cid:13), 3(cid:13), and 4(cid:13) in Figure 1).
4.1 Transferability Based Approach
For the black-box AE based attacks, the knowledge about the
internal model is not known, so a straightforward method is
to generate AEs based on a white-box model and transfer the
AEs to the black-box model. The success of the transferability
5Based on our experiments, Amazon seems like an exception, which will
be discussed in Section 6.2.
2670    29th USENIX Security Symposium
USENIX Association
Figure 1: Architecture of general adversarial attack against ASR API service and IVC devices.
based attacks depends on the similarity between the inter-
nal structure and parameters of the white-box and black-box
models. Recent research demonstrates that the transferability
could work on heterogeneous models through the improve-
ment of AE generation algorithm [32].
Initial try. To implement the transferability-based approach,
we start by adopting Kaldi ASpIRE Chain Model as the white-
box model, and refer to the idea of “pdf-id matching algorithm”
proposed in CommanderSong [40] to generate AEs. We make
such choices because (i) CommanderSong is the state-of-
the-art AE generation work based on white-box model as
this paper is written; (ii) the AEs generated in Commander-
Song demonstrates transferability to iFLYTEK application—
a black-box ASR system—running on smartphone, when
played over-the-air; and (iii) the white-box model used in
CommanderSong is accessible and popular.
We tested the AEs generated using the above approach
on our target black-box ASR systems such as the Google
Cloud Speech-to-text API, and ﬁnd that only few AEs can be
partially recognized as “Google”, “Hey Google”, “phone”, etc.
The success rate of the transferability on Amazon Transcribe,
the API service offered by Amazon, is even lower. This is
not surprising, since CommanderSong was not designed to
transfer across different systems.
Enhancement. We analyzed the approach proposed in Com-
manderSong and enhanced it by applying the Momentum
based Iterative Fast Gradient Method (MI-FGM) to improve
the transferability of the AEs. The momentum method was
introduced in [23], which can accumulate a velocity vector
in the gradient direction during iterations. In each iteration,
the gradient will be saved, and then combined using a decay
factor with the previously saved gradients. The work [23] also
demonstrated that by combining these gradients together, the
gradient direction will be much more stabilized and the trans-
ferability of AEs could be enhanced. Furthermore, we added
random noise into the samples in each iteration to improve the
robustness of the AEs, similar as in CommanderSong [40].
Speciﬁcally, let gt+1 be the gradient in the (t + 1)th iter-
ation, and g0 be start gradient 0. Let x∗
t denote the AE gen-
erated in the (t)th iteration, and x∗
0 be original audio. Clipε
is a function clipping the values exceeding the pre-deﬁned
maximum and works in each iteration. Therefore, x∗
t+1 within
the ε vicinity can be obtained based on MI-FGM as below:
gt+1 = µ· gt +
J(x∗
t ,y)
(cid:107)(cid:53)xJ(x∗
t ,y)(cid:107)1
t + Clipε (α· gt+1)
x∗
t+1 = x∗
(1)
(2)
where y is the probability value of the target pdf-id sequence
of x∗
t , µ is the decay factor for the momentum, α is the step fac-
tor6, J(x∗
t ,y) is the loss function. Intuitively, MI-FGM uses the
gradient of the loss function to determine the direction, along
which the loss function itself can be minimized. Compared
with normal FGM, MI-FGM replaces the current gradient
with the accumulated gradients of all previous steps.
Based on our evaluation, the enhanced approach helps to
generate a few AEs attacking black-box ASR API services
(e.g., Google Cloud Speech-to-Text API) with low success
rate and works even poorer on IVC devices (see Section 6.2).
The main reason is that the approach to generate AEs mainly
depends on the sample’s transferability to other black-box
systems. Thus, we consider the transferability based approach
has one major limitation: the crafted AEs are generated more
towards the white-box model. However, the decision bound-
aries may vary between the white-box model used to generate
the AEs and the target black-box model.
4.2 Alternate Models based Generation
Approach overview. First, we propose to build our carefully
augmented corpus to train a local model approximating the
target black-box model on the desired commands. As the AEs
generated from Kaldi ASpIRE Chain Model can be trans-
ferred to the target black-box model in some extent, we take
it as the large base model, and use it to enhance the small
substitute model to generate the AEs. Therefore, the large
base model can generate most of the acoustic features of the
desired command (Step 1(cid:13) in Figure 1). Furthermore, the last
generated AE of the base model will be fed into the substitute
6Dong et al. evaluated the success rate of AEs for different decay factors
and found 1.0 is the optimal value [23]. Carlini et al. used Adam optimizer
to minimize the loss function where the default step factor α is set as 100 [5].
In this paper, we set those two factors based on the above two works.
USENIX Association
29th USENIX Security Symposium    2671
BaseModelAEsSubstituteModelAEsOnlineSpeech APIServiceTargetIVC DevicesSuccessfulAEsFailedAEsOriginal Audio③③①①②②④④⑦⑦Alternate Modelsbased GenerationTest on Black-box Platformsthe last generated AEthe last generated AEQueryReduction⑥⑥⑤⑤model (Step 2(cid:13) in Figure 1). Thus, the unique features of
the desired command on the target model can be adjusted
in a ﬁne-grained manner by the substitute model (Step 3(cid:13) in
Figure 1), since it was trained based on an augmented corpus
(details in Section 4.2.1) that can be well recognized by the
black-box model. During the AE generation process under
each model, we use a small subset of AEs to query the target
ASR API service according to our query reduction method
(Step 5(cid:13) and Step 6(cid:13) in Figure 1). If none of these AEs works,
the last crafted audio (an unsuccessful AE) from the substi-
tute model will be fed to the base model as the input for the
next epoch (Step 4(cid:13) in Figure 1). Finally, we select the effec-
tive AEs to compromise the target IVC devices (Step 7(cid:13) in
Figure 1). Below we detail such approach.
4.2.1 Local Model Approximation
Training set with limited number of phrases. Generally,
the commercial black-box models are trained with signiﬁ-
cantly large proprietary dataset, and the structure of the neural
network can be quite complicated. Therefore, it is extremely
difﬁcult to obtain the corpus or even infer the details about
neural network. In other words, training a local substitute
model completely approximating the target commercial black-
box system is almost unpractical. However, since our ultimate
goal is to hack the commercial IVC devices and in turn lever-
age it to compromise the victim’s digital life, we are only
interested in a limited number of selected phrases such as
“open my door”, “clear notiﬁcation”, etc. A side product of
selecting those phrases is that, based on our experiences, the
IVC devices are trained to be quite robust to those phrases,
e.g., “open my door” on Amazon Echo, “what is the weather”
and “play music” on Microsoft Cortana and Google Assistant.
Hence, we just need to train a local model partially approxi-
mating the target system on the most frequently used phrases,
also the ones we are highly interested in, on IVC devices. We
use Text-to-Speech services to generate TTS audio clips for
our desired phrases (details in Section 5.3) as the training set
for local model approximation.
Training set augment. The above observation inspired us the
idea of the local partial approximation. However, the training
set has two problems: the number of phrases in the training
set is too limited for training; and the robustness of an IVC
device to a phrase is unknown. To solve these problems, we
augment the training set by tuning the TTS audio clips, i.e.,
either changing the speech rate of and adding noises to them.
Based on our experience, the changing of the speech rate and
the noise amplitude is quite unique to different ASR systems,
e.g., a speciﬁcally tuned audio might be decoded correctly
with high conﬁdence by one ASR system, but incorrectly by
the other. Hence, we believe that those tuned but still cor-
rectly decoded audio clips can help to uniquely characterize
different ASR systems, and that training an ASR system with
plenty of such audio clips will guide it towards the target ASR
system on the desired phrases in the audio clips.
Obviously, not all the tuned audios can still be decoded
correctly by the target black-box system. In our research, we
assume that the speech recognition mechanisms of the IVC
devices are similar to that of the API service provided by the
same company7. Hence, we query the corresponding online
speech API service on them, and ﬁlter out those either not cor-
rectly decoded, or decoded correctly but with low conﬁdence
values. The magnitude of the corpus augmented in this way
is not very big, usually 3~6 hours for ten selected phrases,
which can be ﬁnished in about 1500 queries on the target
speech API service.
4.2.2 AE Generation
Generating AEs with base model and substitute model.
After the local substitute model is trained based on the aug-
mented dataset, we ensemble it with the large base model for
the alternate models generation summarized in Algorithm 1.
Speciﬁcally, Line 3 and Line 4 are for the AE generation on
the large base model and the small substitute model respec-
tively. The AE generation is the same for two models and
deﬁned as the function “AEGENERATION” in Line 8~24.
interval = Tinterval
Algorithm 1 Alternate Models Generation Algorithm
Require: The original audio x0, the target label y, ftarget is the func-
tion to get output from black-box model, the black-box query
interval times Tinterval, the maximum allowed epoch E pochMax.
Ensure: A set of adversarial example collection X∗, all with label
y under classiﬁer ftarget.
1: x∗
0 = x0 ; g0 = 0 ; CurrentE poch = 0 ; T∗
2: while CurrentE poch < E pochMax do
AEgeneration (Base Model Settings);
3:
AEgeneration (Substitute Model Settings);
4:
CurrentE poch + +;
5:
6: end while
7: return X∗
8: function AEGENERATION(Model Settings)
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
end if
21:
22:
0 = x∗
T ;
23:
24: end function
Take x∗
Update gt+1 by Eq. 1;
Update x∗
t+1 by Eq. 2;
if t mod T∗
interval = 0 then
Input x∗
t+1 to ftarget and get ftarget (x∗
if ftarget (x∗
t+1) match y then
Put x∗
t+1 into X∗;
Update T∗
Reset T∗
interval = Tinterval;
for each t ∈ [0,T − 1] do
t for current model f and get the gradient;
t+1);
interval by Eq. 3;
else
end if
end for
Set x∗
7Although previous studies [29, 42] show that it is possible to recover
Speech-to-Text functionality from some IVC devices like Echo, their ap-
proaches cannot obtain the conﬁdence values for the decoded results, which
are required in our approach.
2672    29th USENIX Security Symposium
USENIX Association
In each iteration of the f or loop starting at Line 10, the
gradient is updated in line 12 based on Eq. 1 and the audio
sample is crafted in line 13 based on Eq. 2. To successfully
attack the target black-box model, we need to query the target
speech API service and validate whether the decoded result
of the crafted audio sample is as expected or not. An intuitive
way is to submit the sample generated in each iteration, so
any potential effective AE will not be ignored. However, such
method will incur a signiﬁcant amount of queries sent to the
API service, which could be costly and at the same time suspi-
cious. Therefore, we implement the query reduction algorithm
(will be detailed at the end of this subsection), which aims to
reduces the number of queries to the target black-box system.
At Line 1, we set the Tinterval as the number of iterations be-
tween two consecutive queries to the target black-box system,
and then at Line 19, it is updated based on Eq. 3, according
to the recognition results from the target black-box system.
If after T iterations, effective AE is still not generated (i.e.,
Line 16 always returns false), we assume the transferability
based attack does not work well towards the target black-box
system. We will use the output x∗ from the last iteration as the
input to the local substitute model, then use the same gradient
algorithm to craft the adversarial sample under the substitute
mode settings. If after we reach the T iterations and the lo-