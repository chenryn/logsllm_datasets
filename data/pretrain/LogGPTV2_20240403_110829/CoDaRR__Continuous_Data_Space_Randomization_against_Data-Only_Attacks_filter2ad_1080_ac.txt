sufficient information to accurately locate and update en-
crypted values on the heap and in global data as well as DR
keys in registers and on the stack.
After compiling the protected application, we launch it
along with our runtime monitoring and rerandomization com-
ponent (see Section 4.6). Figure 3 illustrates the operation of
the monitor at run time. The run-time monitor component
runs as a separate process and is therefore fully isolated from
the target application. This separation protects randomiza-
tion secrets and metadata from disclosure by an attacker
from the protected process and partially addresses challenge
C-2. The runtime component pauses the execution of the
protected program whenever (i) the program triggers dy-
namic rerandomization or (ii) the periodic refresh interval
expires (Step 1 ). The monitor is aware of the instrumented
code locations that encrypt and decrypt masked values and
has fine-grained control over the paused program. The moni-
tor, when pausing the program, can check if there are any
in-flight, encrypted values in registers. This can occur in two
such cases: either (i) the store instruction following an en-
cryption operation or (ii) the decryption instruction following
a load from memory has not yet been executed. The monitor
can step forward the execution of the paused program until
the pending operation is completed.
When dynamic rerandomization is triggered eventually the
monitor refreshes the keys and patches the necessary memory
locations and references to use the new keys. It begins by
unmapping the old code from memory and mapping in its
place a fresh code section with new embedded keys (Step 2 ).
This allows us to minimize the time required to update the
code, thus partially addressing challenge C-3, while gener-
ically supporting fine-grained code rerandomization at the
same time. Since the new code may have a different layout,
the monitor fixes up all code pointers referring to the old
code as detailed in Sections 5.1.1 and 5.1.2. Next, in Step 3
the monitor must update mask values currently stored in
registers and on the stack (see Section 4.6.2). Finally, the
monitor updates the encrypted data (Steps 4 and 5 ). Using
the aforementioned metadata, it locates each memory value
that needs to be updated and re-encrypts the value with its
new mask.
4.3 Compile-time Analysis and
Instrumentation
As our first step in preparing a program for data rerandom-
ization, we run Lattner et al.’s [33] Data Structure Analysis
(DSA) on the program. DSA is a Steensgaard-style pointer
analysis that generates points-to sets for the whole program.
We perform context-insensitive analysis using DSA and the
equivalence classes our tool computes should therefore be iden-
tical to those constructed by Bhatkar and Sekar’s DSR [8, 11],
which we use as a baseline for comparison.
We then generate a random, word-sized mask value (i.e., 64-
bit keys on x86 64 platforms) for each equivalence class and
instrument the program at the compiler IR level. We add an
XOR operation before all memory stores and after all memory
loads with the mask for the corresponding equivalence class.
We apply the encryption uniformly to the whole program, and
therefore do not exclude “safe” equivalence classes, contrary
to prior DSR schemes [8, 11], since these values may still
be corrupted by other, unsafe writes.1 Similar to prior DSR
schemes [7], we only use word-sized keys and use bitwise key
shifting to handle unaligned memory accesses.
Note, that our rerandomization mechanism is agnostic to
the details of the analysis and instrumentation passes. Co-
DaRR could easily support other pointer analyses or stronger
forms of encryption.
4.4 Mask Table and Tracking Live Masks
After adding the DSR instrumentation, we generate a new
metadata section, the Mask Table, containing all of the masks
we use in the program, laid out in a contiguous array. The
run-time monitor uses this Mask Table as a lookup table
1Using an attack similar to that described in Section 3.2, an attacker
with arbitrary read and write primitives can derive the mask used for
the arbitrary write operation in a straightforward manner.
DSA (Field + Context)DSR-KeysEQ-ClassesAdversarySourcesDataclass-1class-2CodeMem-OpsCompilerBinary InstrumentationLoadsStoresDebugBinaryDataclass-1class-2CodeMem-OpsCoDaRRTrackingDebugSuspend / ResumeRefresh Keys & FixupRuntimeMonitorProcessExecute BinaryFigure 3: CoDaRR run-time rerandomization process.
(see Section 4.6), but it is never loaded into memory by the
application itself. The metadata that tracks each value’s mask
refers to masks by indices in this table to avoid exposing the
mask themselves to an attacker.
Mask constants must be loaded into a CPU register before
they can be used to encrypt or decrypt data in memory. As in
prior work [7, 8, 11], our compiler instrumentation does not
prevent mask constants from spilling to the stack, although
one could do so, potentially with additional performance and
code size overhead. To support rerandomization, CoDaRR
therefore needs to keep track of which registers and stack
slots currently store masks at the time of rerandomization.
One of the challenges to achieving this is to differentiate
between actual program values and the keys. To allow for
rerandomization at any point of time during program exe-
cution, the monitor must know exactly where these masks
reside (i.e., in which registers or stack slots) at any given
time during the execution of the program.
Instrumentation to dynamically track all mask locations
at run time would be slow, since the program must load a
mask into a register every encrypted memory operation. To
address this problem, we instead emit static metadata that
allows the monitor to compute which registers and stack slots
contain keys at each program execution point. Specifically,
we create an artificial local variable in debug information
for every mask constant introduced by DSR, named so that
it corresponds to the mask’s index in the Mask Table. We
then associate each encryption/decryption operation that
uses a mask constant with the mask’s artificial variable in
the program’s debug metadata.
The compiler emits DWARF information for mask con-
stants by treating them as local variables, which we force even
when compiling at the highest optimization level and with
symbol table stripping enabled. This DWARF information
contains the symbol name (which references an index in the
Mask Table), and describes the location of the associated
value throughout the execution of the function.
Note, that the artificial local variables we introduce do not
change the runtime behavior or logic of the program in any
way, but only affect the debug information generated by the
compiler.
As is the case for the Mask Table, the compiler writes the
DWARF mask metadata into a file section which is never
loaded into memory by the program itself. We only load
this section into the runtime monitor’s address space. Our
DWARF mask metadata is therefore not accessible to an
attacker.
4.5 Value Mask Mappings
To rerandomize the data representation at run time, CoDaRR
must be able to decrypt and re-encrypt all masked data. This
requires three steps: locating all masked values, looking up
the masks for each value, and re-encrypting all locations with
an updated masking key. To support the first two steps, we
generate static metadata for global and static local variables,
which we call the Static Mask Mapping, and maintain run-
time variable metadata for dynamic allocations on the heap
and stack (the Dynamic Mask Mapping). These mappings
specify the size, location, and mask of each global variable
and heap object, with the mask encoded as an index into the
Mask Table.
We generate the Static Mask Mapping at compile time,
after we apply the DSR instrumentation and generate the
Mask Table. To generate the run-time metadata for dynamic
allocations, we hook all memory allocation sites with a small
run-time library we embed into the program. Our alloca-
tion hook stores the location, size, and mask index of the
newly allocated object in the Dynamic Mask Mapping. Our
deallocation hook invalidates the metadata.
Pause process execution1Replace code with new variant2Unwind stack & update masks3Update masked globals4Update dynamic masked allocations (stack and heap) 5RegistersMonitor processProtected processStackProtected binary (old/new)CodeDWARF mask metadataStatic Mask MappingCodeGlobalsDynamic MaskMappingHeapMemoryDiskMASK20MASK10V ^ MASK10Mask tableMask tableMASK10MASK201020MASK10MASK201020&V10&VX ^ MASK20&X&S30S ^ MASK30&S……The Static Mask Mapping is only on located disk and
is never loaded into the protected program’s address space.
The Dynamic Mask Mapping is stored in a shadow memory
region in the program’s address space, and could therefore be
a target for an attacker. However, since the metadata only
refers to masks by their index in the Mask Table, disclosure
does not reveal the mask values themselves. We refer to
Section 7.2 for an in-depth discussion on the security of the
Dynamic Mask Mapping.
4.6 Run-time Monitor
As depicted in Figure 3, our run-time monitor is a stan-
dalone application that attaches to the protected process and
rerandomizes its masks periodically or on demand. When
rerandomization is triggered, the monitor first suspends all
threads in the program, then updates all masks in the code,
in registers, and on the stack. Next, it decrypts all encrypted
variables with the old masks and re-encrypts them with the
new masks. Finally, it resumes all program threads and re-
peats this process on set intervals. The protected program
can also trigger rerandomization at strategic points during
execution.
4.6.1 Updating Code. (Step 2 )
To replace masks in the binary code, we replace all code
segments in the program with entirely new code segments.
Before rerandomization we compile one or more additional
variant binaries with different random masks. During reran-
domization, we remove the executable code segment of the
original binary from memory and map in the executable code
segment from a new binary. This approach ensures that we
update all masks correctly, without having to mark their
locations in the code and minimizes the time required to
update the masks for large programs. We do, however, have
to account for differences in the code layouts between the
original binary and the new binary we mapped in. We do
this by updating all code pointers using a strategy laid out
in Section 5.1.
We could instead use a binary rewriter component to patch
the code in-place as some of the existing code rerandomization
tools do. Our approach, in our view, is the most generic
strategy for DR key replacement as it allows us to use either
pre-compiled variants or variants generated at run time by
a separate binary rewriter. We discuss this design choice
further in Section 7.1.
4.6.2 Updating Masks In Registers and Stack. (Step 3 )
After replacing the code segment and updating code point-
ers, we generate call stack information for all threads in the
program and identify all active stack frames. Next, we consult
the DWARF mask metadata (see Section 4.4) to identify all
registers and stack slots that currently hold masks. For each
mask, we look up its index in the Mask Table of the new
variant, and we replace the mask value with the new mask.
4.6.3 Re-Encrypting Global, Stack and Heap Data. (Steps 4
& 5 )
Next, we iterate through all global variables marked in
the Static Mask Mapping (see Section 4.5), look up their
location, size, and masks, and re-encrypt them with the
corresponding mask in the new binary. Also included in the
Static Mask Mapping are static local variables, which are
actually allocated in the global data section, so we re-encrypt
these allocations along with the globals.
Finally, we re-encrypt heap objects and dynamically allo-
cated stack objects by consulting the Dynamic Mask Mapping
in the program’s shadow memory region.
5 IMPLEMENTATION DETAILS
We implemented our compile-time analysis and instrumen-
tation passes on top of Clang/LLVM v3.8. We based our
static DSR instrumentation on an existing implementation of
DSR [42], and modified the instrumentation passes to gener-
ate the necessary mask metadata (see Section 4.4) and to add
calls to our run-time heap metadata management functions
(see Section 4.5). However, our proposed data rerandomiza-
tion techniques are not tied to a particular implementation
of DSR. We can extend support to other implementations by
making similar changes to the compile-time instrumentation
passes.
We developed the run-time monitor as a Linux applica-
tion that attaches to the protected process with the ptrace
API. In our current implementation, the monitor waits in
the background until the rerandomization interval has ex-
pired, at which point we attach the monitor to the program
and start the rerandomization process. The monitor can also
be initiated with chosen rerandomization points (program
counter values) in the program to trigger rerandomization
strategically. This latter approach works by setting break-
points on specific code paths. By hitting a breakpoint, the
program generates an exception, which the monitor catches.
5.1 Code Pointer Fixups
To minimize the rerandomization overhead and support fine-
grained code layout randomization, CoDaRR rerandomizes
masks by replacing the entire code segment of the program
with code from a different binary. This means we have to
adjust some code pointers after applying rerandomization.
Our current implementation does not dynamically track the
location of code pointers. We instead use heuristics to find
and update a part of the relevant pointers. While these
heuristics do not guarantee correctness, similar ones were
used in prior work [35], and we found them to be sufficient
for the programs we tested with. Prior work [15, 50, 51] has
proposed mechanisms to allow more precise updates of code
pointers, any of which could we could add to CoDaRR.
5.1.1 Updating Return Addresses. After mapping in the new
code segments, we start by updating all return addresses to
reflect the new code layout. We use the following heuristic to
calculate the updated return addresses: first, we disassemble
the original binary and variant binaries with new DSR masks
using capstone. We construct a ReturnAddressMap for the
original program binary and all variants using Algorithm 1.
Function CollectReturnAddresses(Binary) is
declare ReturnAddressMap;
foreach Function in Binary do
PreviousIns = nullptr;
CallNumber=0;
foreach Ins in Function do
if IsCallInstruction(PreviousIns) then
ReturnAddress = Ins.Address;
ReturnAddressMap.insert(Function,
CallNumber++, ReturnAddress);
end
PreviousIns=Ins;
end
return ReturnAddressMap
end
Algorithm 1: Collecting possible return addresses from
a disassembled binary.
Identifying a corresponding return address in the new
variants for a given return address in the process becomes
trivial once we have ReturnAddressMaps for all variants. We
prepare this data ahead of time before we attach the monitor
to the program for rerandomization. During rerandomization,
we unwind the program stack using libunwind and update
the return addresses in the stack with new return addresses.
This process assumes that equivalent call instructions always
appear in the same order in all variant binaries, which holds
true even when we apply a software diversity transformation
such as function reordering [32]. Basic-block level reordering