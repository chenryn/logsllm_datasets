momorphically implementable in this encryption scheme with the
corresponding indexes. The last hypothesis ensure that f would be
typable if applied on the decrypted ciphertext. The label (cid:96)y in the
typing of ke, y, and (cid:126)z records the ﬂow from ke and (cid:126)z to y.
Our typing rule ensures that if an homomorphic function types,
its equivalent non-homomorphic version would also type, as illus-
trated in Example 7.
PRE-ENCRYPT
Γ(y) = Enc τ Kq((cid:96)y)
(cid:96) e : τ
τ ≤C y
(cid:96) ke : Ke E K((cid:96)y)
τ ∈ E
(cid:96) y := P(e, ke) : (cid:96)y
BLIND
(Ge,B,D) is CPA
Γ(y) = Enc τ Kq((cid:96)y)
(cid:96) z : Enc τ
Kq(L(τ ))
(cid:96) ke : Ke E K((cid:96)y)
ke ≤I α or τ ≤C α
(cid:48)
(cid:48) ≤ τ
τ
(cid:48) ∈ E
τ, τ
(cid:96) y := B(z, ke) : (cid:96)y
(cid:48)
HOM-FUN
FK (f ) = fK : (cid:126)q → q
Γ(y) = Enc τ Kq
((cid:96)y)
(cid:96) zi : Enc τi Kqi((cid:96)y)
(cid:96) ke : Ke E K((cid:96)y)
Γ, x : τ (cid:116) (cid:96)y, (cid:126)x : (cid:126)τ (cid:116) (cid:96)y (cid:96) x := f ((cid:126)x) : L(τ ) (cid:116) (cid:96)y
for zi ∈ (cid:126)z
(cid:126)τ , τ ∈ E
(cid:48)
(cid:96) y := fK ((cid:126)z, ke) : (cid:96)y
Figure 4: Additional typing rules for pre-encryption, blinding, and encryption homomorphisms with policy Γ.
commands J, B0, B1, T containing no cryptographic variables,
such that wv(Bb)∩ V = ∅ and rv(T ) ⊆ V , (cid:126)A α-adversaries such
that P [ (cid:126)A] is a polynomial command, g /∈ v(J, B0, B1, P, (cid:126)A), and
some variable b /∈ v(J, B0, B1, P, (cid:126)A, T ) in the command
if we have Pr[CNI;(cid:86)
CNI
·
= b := {0, 1}; J; if b = 0 then B0 else B1; P [ (cid:126)A]
x∈rv(T ) x (cid:54)= ⊥] = 1, then the advantage
2| is negligible.
| Pr[CNI; T ; b =0 g] − 1
In the game, the command J; if b = 0 then B0 else B1 probabilis-
tically initializes the memory, depending on b. Deﬁnition 7, then
runs the command context applied to adversaries P [ (cid:126)A]. Finally, T
attempts to guess the value of b and set g accordingly. T cannot
read cryptographic variables, which are not an observable outcome
x∈rv(T ) x (cid:54)= ⊥ rules out com-
mands T that may read uninitialized memory. Hence, the property
states that the two memory distributions for b = 0 and b = 1 after
running CNI cannot be separated by an adversary that reads V .
of the program. The condition(cid:86)
Besides the cryptographic assumptions, we state additional safety
Examples The examples below use Paillier encryption, which en-
ables us to add plaintexts by multiplying their ciphertexts. Thus,
we use f = + and fK = ∗, and for F(+) = ∗ : 0 (cid:55)→ 0 we obtain
a single instance of rule HOM-FUN:
HOM-PAILLIER
Γ(y) = Enc (Data ((cid:96))) K ((cid:96)y)
(cid:96) zi : Enc (Data ((cid:96)i)) K ((cid:96)y) for i = 0, 1
(cid:96) ke : Ke E K((cid:96)y)
(cid:96)0 (cid:116) (cid:96)1 (cid:116) (cid:96)y ≤ (cid:96) (cid:116) (cid:96)y
(cid:96) y := z0 ∗ z1 : (cid:96)y
Data ((cid:96)), Data ((cid:96)0), Data ((cid:96)1) ∈ E
EXAMPLE 7. To illustrate our typing rule, we compare two pro-
grams that perform the same addition, on plaintexts (on the left)
and homomorphically (on the right):
P (cid:48)
P
·
= ke, kd := Ge();
z1 := E(x1, ke);
1 := D(z1, kd)
x(cid:48)
1 + x(cid:48)
x := x(cid:48)
1;
y := E(x, ke);
r := D(y, kd);
·
= ke, kd := Ge();
z1 := E(x1, ke);
y := z1 ∗ z1;
r := D(y, kd);
conditions for soundness.
Suppose that we type P with a policy Γ, then, relying on the plain-
text-typing assumption in rule HOM-FUN, we can also type P (cid:48) with
the same policy.
EXAMPLE 8. We show how to homomorphically multiply an
encrypted value by a small integer factor.
ke, kd := Ge(); yLH := E(xHH, ke); zSH := E(0, ke);
for iSH := 1 to nSH do zSH := zSH ∗ yLH;
zLH := B(zSH, ke); _; xHH := D(zLH, kd)
By typing, we have that an honest-but-curious adversary (α = SH)
does not learn xHH, and that a network adversary (α = LH) learns
neither xHH nor nSH. The latter guarantee crucially relies on blind-
ing the result at the end of the loop, since otherwise the adversary
may also iterate multiplications of yLH and compare them to the
result to guess nSH.
Another classic example of homomorphic scheme is the ElGa-
mal encryption, which enables us to multiply plaintexts by mul-
tiplying their ciphertexts; we omit similar, typable programming
examples.
6. COMPUTATIONAL SOUNDNESS
We deﬁne security properties for probabilistic command con-
texts as computational variants of noninterference, expressed as
games [9].
DEFINITION 7
(COMPUTATIONAL NON-INTERFERENCE).
Let Γ be a policy, α an adversary level, and P a command context.
P is computationally non-interferent against α-adversaries
α , and for all polynomial
when, for both V = V C
α and V = V I
DEFINITION 8. Let α ∈ L be security label. A command con-
text P is safe against α-adversaries when Γ (cid:96) P and
1. Each key label is used in at most one key generation.
2. Each key variable read in P is ﬁrst initialized by P .
3. There is no dependency cycle between key labels.
We rely on these conditions to apply cryptographic games in the
proof of type soundness, for instance to guarantee the integrity of
decrypted values. They can be enforced by static analysis, for in-
stance by collecting all relevant static occurrences of variables and
forbidding encryption-key generation within loops.
Condition 1 prevents decryption-key mismatches. Condition 2
recalls our assumption on uninitialized variables for keys. Condi-
tion 3 prevents leaks with low integrity ciphertext when using CPA.
We also assume that each static key label is associated to a ﬁxed
scheme for encryption that meets Deﬁnitions 1, 5, or 6 and we im-
pose constraints on the length of ciphertexts in order to prevent
information leakage via the length of encrypted messages (see ap-
pendix for a formal deﬁnition).
Relying on these conditions, we obtain our main security theo-
rem: well-typed programs are computationally non-interferent.
THEOREM 2. Let α ∈ L be a security label. Let Γ be a pol-
icy. Let P be a polynomial-time command context, safe against
α-adversaries. P satisﬁes computational non-interference against
α-adversaries.
The proof relies on a series of typability-preserving program
transformations that match the structure of the games used in the
cryptographic security assumptions (Deﬁnition 2). These transfor-
mations replace, one static key label at a time, couples of encryp-
tions and decryption algorithms by an ideal implementation that
maintains a global table for all values encrypted so far and encrypts
0s instead of the actual plaintexts.
7. PRIVATE SEARCH ON DATA STREAMS
We illustrate the use of Paillier encryption on a simpliﬁed ver-
sion of a practical protocol developed by Ostrovsky and Skeith III
[21] for privately searching for keywords in data streams (without
the Bloom ﬁlter). The protocol has two roles: an agency P and
a service S. Assume that the service issues, or processes, conﬁ-
dential documents such as mail orders or airline tickets, and that
the agency wishes to retrieve any such document whose content
matches some keywords on a secret black list. The two roles com-
municate using a public network. The black list is too sensitive to
be given to the service. Conversely, the service may be processing
a large number of documents, possibly at many different sites, and
may be unwilling to pass all those documents to the agency.
We formally assume that the agency is more trusted than the ser-
vice. We suppose that the documents are arrays of words, and that
all words (including the keywords on the black list) appear in a
public, trusted dictionary. We model the public network using vari-
ables shared between P and S. We rely on the additive property
of Paillier encryption, detailed in Section 5. We code the protocol
using three commands, explained below.
Initially, the agency generates a keypair and encodes the list of
keywords as an array (mask) of encryptions indexed by the public
dictionary that contains, for each word, either an encryption of 1 if
the word appears in the black list or an encryption of 0 otherwise.
The agency can distribute this array to the service without revealing
the black list.
P0
·
= ke, kd := Ge();
for i := 0 to size(words) − 1 do
if words[i] ∈ keywords then wb := 1 else wb := 0;
mask[i] := E(wb, ke)
Then, for each document d, the service homomorphically com-
putes the number of matching keywords, as the sum of the 0 and
1s encrypted in mask for all indexes of the words (d[j]) present
in the document, by multiplying those encryptions in e. Moreover,
the service homomorphically multiplies e and the value of the doc-
ument d (seen as a large integer) in z—the loop computes ed, and
may be efﬁciently replaced with a fast exponentiation. In particular,
if they were no matches, z is just an encryption of 0. Finally, the
serviceblinds both e and z before sending them to the agency—this
step is necessary to declassify these encryptions without leaking
information on the document.
S
·
= e := 1;
for j := 0 to size(d) − 1 do
e := e ∗ mask[words−1(d[j])];
e(cid:48) := B(e, ke); z := 1;
for j := 0 to d − 1 do z := z ∗ e;
z(cid:48) := B(z, ke)
Last, for each pair e(cid:48) and z(cid:48), the agency decrypts the value con-
taining the number of matches (in n) and, if n is different from 0,
retrieves the value of the document by decrypting the product and
dividing by n.
·
= n := D(e(cid:48), kd);
P
if n > 0 then
nd := D(z(cid:48), kd); log := log + (nd/n)
Adding an outer loop for the documents processed by the service,
the whole protocol is modelled as the command
·
= P0;
Q
for l := 0 to nb_docs do
d := docs[l]; S; P ; _
As discussed by Ostrovsky and Skeith III, this algorithm is reason-
ably efﬁcient for the service, as it requires just a multiplication and
a table lookup for each word in each document. Relying on Bloom
ﬁlters, the authors of the protocol and Danezis and Diaz [6] develop
more advanced variants, requiring less bandwidth and guaranteeing
additional privacy properties for the service, but the overall struc-
ture of the protocol remains unchanged.
We now specify the security of the protocol as a policy Γ that
maps the variable of Q to labels. We distinguish three levels of
integrity: H for the agency, S for the service, and L for untrusted
data, with H <I S <I L. ke and keywords have high integrity
(H); all other variables have service integrity (S).
We also distinguish four levels of conﬁdentiality: H and P for
the agency, S for the service, and L for public data. With L <C
P <C H and L <C S <C H.
• words, mask, e(cid:48), z(cid:48), i, nb_docs, ke are public ( at level L);
• docs, d, e, z, j, l are readable by the service (S) and the
agency;
• keywords, kd, bw are readable only by the agency (P );
• log, n, nd are also readable by the agency, but they depend
on low-integrity decryptions, and thus should not ﬂow to any
further encryption with key ke (H).
We prove the security properties of the protocol as instances
of computational non-interference, established by typing our code
with different choices of adversary level α.
THEOREM 3. Γ (cid:96) Q when α ranges over SH, SS, and LS,
hence Q is computationally non interferent against these adver-
saries.
The case α = SH corresponds to a powerful adversary that en-
tirely controls the service but still learns nothing about the black-
list: it cannot distinguish between any two runs of the protocol with
different values of keywords. If the service is honest but curious
(α = SS), the protocol also completes with the correct result. If
the adversary controls only the network (α = LS), it learns nothing
either about the documents contents (docs).
8. BOOTSTRAPPING HOMOMORPHIC
ENCRYPTIONS
Gentry [11] proposes a ﬁrst fully homomorphic encryption
(FHE) scheme, that is, a scheme that supports arbitrary compu-
tations on encrypted data, thereby solving a long-standing crypto-
graphic problem [13]. Others, e.g. Smart and Vercauteren [23],
develop more efﬁcient constructions towards practical schemes.
These constructions are based on bootstrappable encryption
schemes, equipped with homomorphic functions for the scheme’s