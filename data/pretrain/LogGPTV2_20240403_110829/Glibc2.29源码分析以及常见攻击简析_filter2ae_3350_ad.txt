              /*  If a false alarm (empty bin), clear the bit. */
              if (victim == bin)    //如果largebin不为空
                {
                  av->binmap[block] = map &= ~bit; /* Write through */
                  bin = next_bin (bin);
                  bit = (unsigned long) (nb));
                  remainder_size = size - nb;
                  /* unlink */
                  unlink_chunk (av, victim);
                  /* Exhaust */
                  if (remainder_size fd;
              if (__glibc_unlikely (fwd->bk != bck))
                malloc_printerr ("malloc(): corrupted unsorted chunks 2");
                      remainder->bk = bck;
                      remainder->fd = fwd;
                      bck->fd = remainder;
                      fwd->bk = remainder;
                      /* advertise as last remainder */
                      if (in_smallbin_range (nb))
                        av->last_remainder = remainder;
                      if (!in_smallbin_range (remainder_size))
                        {
                          remainder->fd_nextsize = NULL;
                          remainder->bk_nextsize = NULL;
                        }
                      set_head (victim, nb | PREV_INUSE |
                                (av != &main_arena ? NON_MAIN_ARENA : 0));
                      set_head (remainder, remainder_size | PREV_INUSE);
                      set_foot (remainder, remainder_size);
                    }
                  check_malloced_chunk (av, victim, nb);
                  void *p = chunk2mem (victim);
                  alloc_perturb (p, bytes);
                  return p;
                }
            }
        use_top:
          /*
             If large enough, split off the chunk bordering the end of memory
             (held in av->top). Note that this is in accord with the best-fit
             search rule.  In effect, av->top is treated as larger (and thus
             less well fitting) than any other available chunk since it can
             be extended to be as large as necessary (up to system
             limitations).
             We require that av->top always exists (i.e., has size >=
             MINSIZE) after initialization, so if it would otherwise be
             exhausted by current request, it is replenished. (The main
             reason for ensuring it exists is that we may need MINSIZE space
             to put in fenceposts in sysmalloc.)
           */
                    //如果在所有的bin中都没有找到合适的chunk，就去top chunk中取
          victim = av->top;      //获取top地址
          size = chunksize (victim);   //获取top的size，top没有prev_size
          if (__glibc_unlikely (size > av->system_mem))   //检查top chunk的合法性，这里导致了house of force不可用了，因为force需要改top size为一个很大的数(常用的是-1)，而-1在计算机中表示是(64位下)FFFFFFFFFFFFFFFF，明显大于system_mem
            malloc_printerr ("malloc(): corrupted top size");
          if ((unsigned long) (size) >= (unsigned long) (nb + MINSIZE))  //如果top chunk的size大于等于nb+0x10,则切割
            {
              remainder_size = size - nb;
              remainder = chunk_at_offset (victim, nb);
              av->top = remainder;
              set_head (victim, nb | PREV_INUSE |
                        (av != &main_arena ? NON_MAIN_ARENA : 0));
              set_head (remainder, remainder_size | PREV_INUSE);
              check_malloced_chunk (av, victim, nb);
              void *p = chunk2mem (victim);
              alloc_perturb (p, bytes);
              return p;
            }
          /* When we are using atomic ops to free fast chunks we can get
             here for all block sizes.  */
          else if (atomic_load_relaxed (&av->have_fastchunks))  //如果top chunk size不够大，则合并fastbin到smallbin或者largebin中
            {
              malloc_consolidate (av);
              /* restore original bin index */
              if (in_smallbin_range (nb))
                idx = smallbin_index (nb);
              else
                idx = largebin_index (nb);
            }
          /*
             Otherwise, relay to handle system-dependent cases
           */
          else    //如果没有fastbin，直接用sysmalloc进行分配空间
            {
              void *p = sysmalloc (nb, av);
              if (p != NULL)
                alloc_perturb (p, bytes);
              return p;
            }
        }
    }
###  3.__libc_free
    void
    __libc_free (void *mem)
    {
      mstate ar_ptr;
      mchunkptr p;                          /* chunk corresponding to mem */
      void (*hook) (void *, const void *)
        = atomic_forced_read (__free_hook);  //与malloc_hook同理
      if (__builtin_expect (hook != NULL, 0))
        {
          (*hook)(mem, RETURN_ADDRESS (0));
          return;
        }
      if (mem == 0)                              /* free(0) has no effect */
        return;
      p = mem2chunk (mem);
      if (chunk_is_mmapped (p))          ////判断chunk是否由mmap分配             
        {
          /* See if the dynamic brk/mmap threshold needs adjusting.
         Dumped fake mmapped chunks do not affect the threshold.  */
          if (!mp_.no_dyn_threshold            //如果是mmap，则首先更新mmap分配和收缩阈值
              && chunksize_nomask (p) > mp_.mmap_threshold
              && chunksize_nomask (p)  (uintptr_t) -size, 0)
          || __builtin_expect (misaligned_chunk (p), 0))
        malloc_printerr ("free(): invalid pointer");
      /* We know that each chunk is at least MINSIZE bytes in size or a
         multiple of MALLOC_ALIGNMENT.  */
      if (__glibc_unlikely (size  chance), so verify it's not an unlikely
           coincidence before aborting.  */
        if (__glibc_unlikely (e->key == tcache))   
          {
            tcache_entry *tmp;
            LIBC_PROBE (memory_tcache_double_free, 2, e, tc_idx);
            for (tmp = tcache->entries[tc_idx];
             tmp;
             tmp = tmp->next)   //遍历同大小的tcache
              if (tmp == e)    //增加了double free的检测，不能向2.26那样无限free同一个chunk喽
            malloc_printerr ("free(): double free detected in tcache 2");
            /* If we get here, it was a coincidence.  We've wasted a
               few cycles, but don't abort.  */
          }
        if (tcache->counts[tc_idx] top)   //并且下一个chunk不是top chunk
    #endif
          ) {
        if (__builtin_expect (chunksize_nomask (chunk_at_offset (p, size))  //检查下一个chunk的size是否合法    
                  = av->system_mem, 0))
          {
        bool fail = true;
        /* We might not have a lock at this point and concurrent modifications
           of system_mem might result in a false positive.  Redo the test after
           getting the lock.  */ 
        if (!have_lock)
          {
            __libc_lock_lock (av->mutex);
            fail = (chunksize_nomask (chunk_at_offset (p, size)) = av->system_mem);
            __libc_lock_unlock (av->mutex);
          }
        if (fail)
          malloc_printerr ("free(): invalid next size (fast)");  
          }
        free_perturb (chunk2mem(p), size - 2 * SIZE_SZ);
        atomic_store_relaxed (&av->have_fastchunks, true);
        unsigned int idx = fastbin_index(size);
        fb = &fastbin (av, idx);  //获得下标为idx的存储fastbin的地址 比如chunk:0x602010，获得的就是存储0x602010的栈地址
        /* Atomically link P to its fastbin: P->FD = *FB; *FB = P;  */
        mchunkptr old = *fb, old2;
        if (SINGLE_THREAD_P)
          {
        /* Check that the top of the bin is not the record we are going to
           add (i.e., double free).  */
        if (__builtin_expect (old == p, 0))  //这里没有遍历fastbin，所以依旧可以用free(a),free(b),free(a)的方式来绕过检测
          malloc_printerr ("double free or corruption (fasttop)");  
        p->fd = old;
        *fb = p;   //插入p并且更新fb的值
          }
        else
          do   
        {
          /* Check that the top of the bin is not the record we are going to
             add (i.e., double free).  */
          if (__builtin_expect (old == p, 0))  //如果重复释放的话，报错退出
            malloc_printerr ("double free or corruption (fasttop)");
          p->fd = old2 = old;   //将要被释放的chunk放入fastbin头部，修改其fd 指针指向Old
        }
          while ((old = catomic_compare_and_exchange_val_rel (fb, p, old2))
             != old2);
        /* Check that size of fastbin chunk at the top is the same as
           size of the chunk that we are adding.  We can dereference OLD
           only if we have the lock, otherwise it might have already been