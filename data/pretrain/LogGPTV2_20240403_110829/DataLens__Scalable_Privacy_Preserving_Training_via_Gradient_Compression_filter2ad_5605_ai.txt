𝜀 = 4.00
𝜀 = 8.00
𝜀 = ∞
TopAgg. For each dataset, each privacy budget 𝜀, and each NormTopK
parameter 𝑘, we perform an extensive grid search for the combi-
nation of hyper-parameters (including gradient clipping norm 𝐶,
noise scale 𝜎, batch size 𝐵, and learning rate 𝑙𝑟) for all methods for
fair comparison. We then use the best hyper-parameters to start 10
runs with different random seeds for noise generation and report
the averaged results for each method. For models trained under
baseline frameworks, we follow the same parameter search protocol
and parameter grid to obtain the reported results.
A.2.2 Experimental Results.
We compare TopAgg (with 𝑘 ∈ {0.7, 0.8, 1.0}) with two baselines
(GM-DP and DPDL) on DP SGD training under a wide variety of
privacy constraints, as shown in Figure 3. For clarity of presentation,
we leave the complete set of results in Table 8. For MNIST, we mainly
evaluate small privacy budgets (𝜀 ≤ 1.0), since the performance gap
of private and non-private models on MNIST is negligible for large
𝜀. For CIFAR-10, specifically, we examine the regions of both small
𝜀 and large 𝜀 respectively in a more comprehensive manner.
We first note that GM-DP is a special case of our TopAgg when
𝑘 = 1.0. In this case, the complete gradient is preserved after the
Top-K step, and therefore the performance of TopAgg is equivalent
to GM-DP. Still, we provide both results as a sanity check in Figure 3.
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2161(a) MNIST
(b) CIFAR-10 (under small 𝜀)
(c) CIFAR-10 (under full range of 𝜀)
Figure 3: The performance of DataLens applied to SGD training on two datasets: (a) MNIST and (b-c) CIFAR-10. We run DataLens with a
range of 𝑘 ∈ {0.7, 0.8, 1.0} and compare its performance with two baselines GM-DP and DPDL on a wide range of privacy budget 𝜀.
Table 9: Model utility for applying norm-based TopAgg and dimension-based TopAgg in DP SGD training on MNIST dataset. 𝜀 is the privacy
budget and 𝑘 is the top-𝑘 parameter in TopAgg. In all cases, 𝛿 = 10−5.
TopAgg (norm-based)
𝑘 = 0.6
73.87 ± 4.77
85.67 ± 1.48
89.84 ± 0.64
𝑘 = 0.7
75.81 ± 3.59
86.12 ± 1.39
90.25 ± 0.40
𝑘 = 0.8
77.15 ± 2.89
85.88 ± 1.97
90.80 ± 1.04
TopAgg (dim-based)
𝑘 = 0.2
74.25 ± 3.25
83.65 ± 0.73
89.10 ± 1.22
𝑘 = 0.4
78.45 ± 2.89
85.59 ± 1.39
90.48 ± 0.73
𝑘 = 0.6
73.55 ± 1.97
86.41 ± 0.70
89.30 ± 0.74
GM-DP
78.40 ± 4.00
84.55 ± 0.98
91.17 ± 0.37
𝜀 = 0.05
𝜀 = 0.10
𝜀 = 0.20
We observe that the results of TopAgg (𝑘 = 1.0) and GM-DP are
indeed close in almost all scenarios regardless of the randomness
of the algorithm (the green and red lines are generally overlapped).
In Figure 3 (a) for MNIST, different curves are intertwined, in-
dicating that choosing different 𝑘 values can only influence the
model performance by a little margin. Thus, it does not hurt to
adopt TopAgg with different 𝑘. The main reason is that, on MNIST,
the model utility gap before and after adding DP noise is small,
which does not provide space for smaller gradient compression
ratios to improve the performance.
Moreover, for CIFAR-10 whose dimensionality is around 4 times
larger than MNIST, we observe consistent performance improve-
ments under the limited privacy budget 𝜀 in Figure 3 (b), which is
also aligned with our observation in TopAgg for generative mod-
els, where our methods demonstrate a large margin over baselines
under limited privacy budgets. Specifically, In Table 8 (b) under
𝜀 = 0.025, we observe that TopAgg with 𝑘 = 0.8 can achieve the
model accuracy of 45.87%, which is more than 4% higher than the
baseline. This again verifies our theoretical analysis that TopAgg
can help save the privacy budget consumption by compressing the
gradient, and therefore substantially help the model convergence
and improve the utility of the model.
With larger privacy budgets, Figure 3 (c) shows that TopAgg with
very small 𝑘 tends to have worse performance. It indicates that given
small 𝑘, the bias introduced by top-𝑘 compression outweighs the
bias introduced by low differential privacy noise. Without DP noise
(𝜀 = ∞), we observe that TopAgg with 𝑘 < 1 has slightly worse
performance than the GM-DP baseline, which is because without
DP noise there is no longer the benefits of lower DP noise brought
by top-𝑘, while the bias introduced by gradient compression starts
to hurt the performance moderately.
We further point out that DPDL has the worst performance
among all as shown in Figure 3. This phenomenon is well under-
stood given that the privacy analysis is looser in Abadi et al. [2]
compared with the privacy analysis based on Rényi Differential
Privacy [42] adopted in both our TopAgg and GM-DP here.
In addition, we empirically examine the hyper-parameters and
the impact of gradient compression and noise injection in TopAgg
on MNIST. We omit the detailed results in Appendix A. We observe
that the bias induced by the DP noise is indeed larger than the
gradient compression, which confirms our theoretical analysis of
the convergence for TopAgg.
A.3 Ablation Studies on Hyper-parameters
DP-SGD algorithms (GM-DP and DPDL) contains several key pa-
rameters: the noise multiplier 𝜎 of the injected Gaussian noise,
gradient clipping constant 𝑐, batch size that will affect the sampling
rate 𝑞, and learning rate. TopAgg adds another important param-
eter 𝑘 for NormTopK on top of the GM-DP framework. To search
for the optimal hyper-parameters, we conduct comprehensive grid
search. We list the optimal hyper-parameters under several different
privacy budgets 𝜀 in Table 11 for MNIST and CIFAR-10.
A.4 Tradeoff between Gradient Compression
and Noise Injection
In essence, TopAgg differs from the standard DP SGD training
scheme and moment accountant method adopted in GM-DP [39]
mainly in the introduction of the gradient compression parameter
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2162Table 10: Results of the control experiments to explore the impact
of gradient compression and noise injection.
(a) Experimental setup. Each cell is one experimental scenario.
noise ∼ N(0, 𝜎2𝐶2I)
noise ∼ N(0, 𝑘𝜎2𝐶2I)
NormTopK
no compression
TopK-GM-DP
GM-DP [39]
TopAgg
–
no noise
TopK-SGD
clipped SGD
(b) Experimental results on MNIST dataset under small and big pri-
vacy budgets. (above) 𝜀 = 0.1 and 𝑘 = 0.8; (below) 𝜀 = 1.0 and 𝑘 = 0.8.
noise ∼ N(0, 𝜎2𝐶2I)
83.86 ± 1.49
85.05 ± 1.85
noise ∼ N(0, 𝜎2𝐶2I)
94.95 ± 0.25
95.56 ± 0.17
NormTopK
no compression
NormTopK
no compression
noise ∼ N(0, 𝑘𝜎2𝐶2I)
85.88 ± 1.97
noise ∼ N(0, 𝑘𝜎2𝐶2I)
95.42 ± 0.20
–
–
no noise
91.96 ± 0.61
94.26 ± 0.43
no noise
98.03 ± 0.09
98.94 ± 0.04
𝑘. On the one hand, using a smaller 𝑘 to compress the gradients
leads to more biased results in the returned gradients, which can
cause performance degradation. On the other hand, the gradient
norm becomes smaller after TopAgg based training which enables
the introduction of less noise to achieve the same level of privacy
guarantee, and therefore less distortion to the prediction. Noticing
the tradeoff, we ask, is there a sweet spot where the performance
increase caused by the injection of less noise surpasses the model
utility degradation induced by the bias in gradient compression?
To this end, we design a set of control experiments to analyze
the impact of the two factors: 1) compression parameter of gradi-
ents and 2) amount of injected DP noise. We provide the setup of
the control experiments in Table 10a. Concretely, we investigate
3 levels of noise injection corresponding to the requirement of 3
algorithms (non-private SGD [26], GM-DP [39], and our TopAgg),
and 2 scenarios of gradient compression (no compression and our
NormTopK compression). Note that only GM-DP and TopAgg satisfy
the intended privacy requirements. We do not report the results for
the combination of no compression and reduced noise, since it is
blatantly non-private and does not offer additional insights. Rather,
we investigate the combination of NormTopK and full noise which
we title TopK-GM-DP, in a hope to build the bridge between GM-DP
and TopAgg. We additionally examine TopK-SGD (the combination
of NormTopK and no noise) to get the sense of an upper-bound of
the performance after gradient compression. For the purpose of
controlling variables, we control the clipping norm 𝐶 and noise
scale 𝜎 to be the same for all the scenarios, and train the non-private
algorithms using the same number of iterations as the private ones,
which is determined by the corresponding privacy budget.
The results of the control experiments on different privacy bud-
gets are provided in Table 10 (b). We summarize our observations
as follows. First, along each row or each column of Table 10 (b), the
performance of the training schemes will experience an increase.
Naturally, the non-private SGD training will give the best perfor-
mance of all (despite norm clipping). This means that less noise and
no compression will generally yield better results. Second, noise
injection has a larger impact on the performance than gradient com-
pression in both cases of small and big 𝜀. Third, the reduction in the
Figure 4: Visualization of generated images from DataLens
scale of injected noise will compensate the performance decrease
caused by gradient compression, therefore resulting in a similar
or slightly better performance of TopAgg when compared with
GM-DP. Given these observations, we conclude that the impact of
gradient compression is negligible compared with noise injection,
and that it is beneficial to exploit gradient compression to trade
for the reduction in injected noise to achieve a potentially better
performance.
B VISUALIZATION OF IMAGE QUALITY
We visualize the private synthetic images for MNIST, Fashion-
MNIST and CelebA, as shown in Figure 4. As expected the image
has a lot of noise, since our goal is to generate data which can pro-
tect privacy and ensure high data utility in terms of training high
performance models. It is interesting to see that these generated
images are enough to train useful models, which lead to interesting
future direction on what ML models actually learn from data.
C EXPERIMENTAL DETAILS
C.1 Visual Quality Evaluation
We evaluate both Inception Score and Frechet Inception Distance
for DataLens and baselines over four datasets. We present the
evaluation results in Table 12.
For Inception Score, in our experiments, we follow GS-WGAN
and use the implementation7 for Inception Score calculation with
pretrained classifiers trained on real datasets (with test accuracy
equal to 99%, 93%, 97% on MNIST, Fashion-MNIST, and CelebA-
Gender).
For FID, we observe it is not necessarily consistent with Inception
Score (e.g., for MNIST 𝜀 = 1, DataLens has better IS than G-PATE,
7https://github.com/ChunyuanLI/MNIST_Inception_Score
ε=10ε=1(a) MNISTε=10ε=1(b) Fashion-MNISTFemaleMale(c) CelebA-Gender (ε=1)FemaleMale(d) CelebA-Gender (ε=10)Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2163Table 11: Optimal hyper-parameters for TopAgg and GM-DP baseline on MNIST and CIFAR-10 with different privacy parameter 𝜀 and
TopAgg parameter 𝑘. In all cases, 𝛿 = 10−5.
(a) MNIST (𝜀 = 0.05)
(b) MNIST (𝜀 = 0.2)
(c) MNIST (𝜀 = 1.0)
TopAgg
𝑘 = 0.7
𝑘 = 0.8
GM-DP
𝑘 = 0.6
10.0
5.8
128
0.01
𝑐
𝜎
batch size
learning rate
5.0
6.6
128
0.01
5.0
7.4
128
0.01
(d) CIFAR-10 (𝜀 = 0.025)
3.0
8.2
128
0.01
𝑐
𝜎
batch size
learning rate
TopAgg
𝑘 = 0.7
10.0
3.6
512
0.1
𝑘 = 0.6
12.0
3.6
512
0.1
𝑘 = 0.8
10.0
3.6
512
0.1
(e) CIFAR-10 (𝜀 = 0.4)
GM-DP
10.0
3.4
512
0.08
𝑐
𝜎
batch size