title:A numerical optimization-based methodology for application robustification:
Transforming applications for error tolerance
author:Joseph Sloan and
David Kesler and
Rakesh Kumar and
Ali Rahimi
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
A Numerical Optimization-based 
Methodology for 
Application 
Robustification: 
Transforming 
Applications 
for Error Tolerance 
Joseph Sloan, David Kesler, Rakesh Kumar 
University 
of Illinois 
Urbana-Champaign 
Ali Rahimi 
Intel Labs 
Berkeley 
jsloan,dkesler2,PI:EMAIL 
PI:EMAIL 
ABSTRACT 
vari­
level. 
we explore 
and handle them in 
of an approach 
at correcting 
to converting 
take up valuable 
the feasibility 
form by recasting 
level [10,271. These ap­
die area and power on the chip. 
process 
and masking these er­
at the algorithmic 
approach 
In this paper, we present 
applications 
these applications 
into an error 
as numerical 
which can then be solved reliably 
There have been several attempts 
ation induced errors by identifying 
rors at the circuit 
and architecture 
proaches 
As an alternative, 
that allows these errors to occur freely, 
software, 
a general 
tolerant 
optimization 
via stochastic 
bustness 
ing an FPGA-based 
point unit (FPU) of a Leon3 processor 
[111. 
in the floating 
of applications 
have the 
We show that stochastic  versions 
potential 
in the face of tim­
ing errors under certain  assumptions. 
for both intrinsically 
good quality 
ro­
bust algorithms 
applications 
assumptions. 
We evaluate 
of the proposed 
that emulates 
problems, 
optimization. 
are possible 
as well as fragile 
to produce good quality  outputs 
approach 
timing errors 
and energy benefits 
We also show that 
the potential 
framework 
under these 
results 
ro­
us­
1. INTRODUCTION 
Power has been, for some time now, a first order design 
for microprocessors  11 
J. In fact, performance, 
constraint 
yield, and functionality 
considerations 
today 117, 24J. 
are routinely 
sacrificed 
for power 
reason why modern microprocessors 
conditions 
An important 
are guardbanded) 
under the worst-case 
con­
amount of power is that they are often de­
to allow cor­
sume a significant 
signed conservatively  (i.e., 
rect operation 
vironmental 
design is high and is only increasing 
cess variation 
nologies. 
a power reduction 
voltage  scaling  reduces 
be limited 
line worst-case 
pro­
CMOS and post-CMOS 
tech­
technique 
such as 
to 
nature of the base­
by the inherently 
conservative 
in the current 
design [291. 
Applying 
manufacturing 
and en­
with increasing 
l7J. The power cost of conservative 
power, but the benefits  continue 
Processors 
conditions. 
Some recent proposal 
reducing 
pro­
guardbands 
have advocated 
design-level 
s II 0 J 
cessor power by eliminating 
worst-case 
bands consume lower power than their counterparts 
for the worst-case. 
liable 
once the voltage 
Unreliability 
duced by process 
such processors 
below a certain 
against 
design-level 
designed 
is due to the possibility 
and environmental 
of timing errors in­
is reduced 
However, 
may be unre­
without 
guard­
threshold. 
fluctuations. 
with reduced guardbands. 
Previous 
proposals 
variation 
largely 
anisms to detect and correct 
cessors 
rely on temporal 
rect the errors. 
correct 
and power costs. 
face of drastic 
or spatial 
Hardware-based 
timing errors 
variation-induced 
employ hardware-based 
variation-induced 
often 
mech­
in pro­
These mechanisms 
to detect and cor­
to detect and 
redundancy 
mechanisms 
errors 
Costs may be especially 
the supply voltage 
reduction in 
[10,251-
have associated 
prohibitive 
area 
in the 
In this paper, we explore 
the feasibility 
of an approach 
mechanisms 
and handle them in 
computation 
applications 
would allow us to elim­
to detect and correct 
longer to complete. 
at the algorithmic 
for error correction 
level. (Figure I) An algorith­
the area and power cost of lower-level 
problems. 
and numerical 
errors by 
with one that may take 
in this 
of reformulating 
In the last thirty 
optimization 
The approach presented 
as stochastic 
the machine 
that allows these errors to occur freely, 
software, 
mic approach 
inate or minimize 
hardware-based 
replacing 
the original 
slightly 
paper consists 
optimization 
learning 
duced and analyzed 
tion procedures 
large-scale learning problems 
We propose an entirely  different  application 
tic optimization: 
plications 
rors. Unlike the traditional  setting 
descent, 
rection 
the processor 
our approach 
the gradient 
from a random subset of a dataset, 
here 
is the source of stochasticity. 
We call 
ap­
er­
for stochastic 
because 
di­
is computed 
itself 
application 
a generic 
on processors 
for surveys). 
for stochas­
that produce variation-induced 
engine for building robust 
where stochasticity 
and online learning 
robustijication. 
(see [21,8,261 
algorithms 
community 
for solving 
gradient 
years, 
arises 
has pro­
many successful  stochastic  optimiza­
978-1-4244-7501-8/101$26.00 
©20 I 0 IEEE 
161 
DSN 2010: Sloan et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:54:08 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
Conventional 
Software 
GuardBanding 
 Hardware 
Robustified 
Software 
 Hardware 
Figure 1: The traditional 
hardware uncertainties 
allow  hardware  errors 
is robustified 
approach to dealing with 
is through guradbanding. 
to be exposed to software which 
to tolerate these errors. 
We 
in  a graph can also be cast into variational 
distances, 
As a specific 
instance 
of the proposed approach, 
assumptions, 
we show 
to 
optimistic 
common applications 
on a stochastically 
correct 
[19, 3, 20, 41, we express 
mechanically 
Least 
many combina­
problems 
under certain 
(stochastic 
a large class of important, 
For example, 
or finding eigenvalues 
processor) 
optimization 
these to an unconstrained 
timing errors that occur in the numerical 
units of 
solving 
overscaled processors. 
problems 
of a matrix can be 
form. Similarly 
cast in a variational 
an array of numbers, 
find­
such as sorting 
that it is possible, 
robustify 
against 
voltage 
Squares 
readily 
torial 
ing a minimum cut, a maximum flow, shortest 
or a matching 
form. To solve such problems 
processor 
them as constrained 
convert 
then solve them using stochastic 
jugate gradient 
ity in the processor 
sults on the convergence 
tic gradient 
optimization 
This approach 
which is P-complete, 
we present 
sumptions 
are typically 
etc., as well as the ones for which small errors 
are typically 
e.g., IIRfilters, 
etc. 
problems, 
exact penalty 
descent 
examples 
for both applications 
can be implemented 
of robustification 
rate and robustness 
form, and 
and con­
carryover directly 
is stochastic, 
for which precise 
is quite generic, 
algorithms. 
(fragile 
existing 
required 
gradient 
theoretical 
re­
of stochas­
to this setting. 
as­
under optimistic 
outputs 
sorting, 
applications), e.g., 
in the output 
When the source of unreliabil­
acceptable (intrinsically 
robust applications), 
only the potential 
simplifying 
upside 
assumptions 
6 and throughout 
in Section 
Future work will continue 
to evaluate 
and miti­
approach. 
Note that this paper explores 
Several 
of the proposed 
have been made (as discussed 
the paper). 
gate the costs. 
• We present 
Our contributions 
a general 
in this paper are as follows: 
approach 
for converting 
appli­
into a form that may be robust to variation­
optimistic 
assumptions, 
cations 
induced errors. Our approach 
certain 
can be mapped into a stochastic 
lem. To the best of our knowledge, 
work on a generic 
tion code for error tolerance 
fragile 
and intrinsically 
methodology 
is applicable, 
under 
that 
to all applications 
optimization 
prob­
this is the first 
to transform 
applica­
that may work for both 
robust applications. 
since linear programming, 
this way. In fact, 
2. RELATED WORK 
proposed 
Recently 
• We develop 
for evaluating 
an FPGA-based framework 
of the proposed 
point unit (FPU) of a Leon3 [Ill 
benefits 
framework 
ap­
emulates 
We show through 
robustness 
Our FPGA-based 
the potential 
proach. 
errors in the floating 
processor. 
tic versions 
outputs 
tions. 
sible for both intrinsically 
as fragile 
of applications 
applications. 
We also show that good quality 
in the face of errors under certain 
results 
assump­
are pos­
robust algorithms 
as well 
our experiments 
can produce good quality 
timing 
that stochas­
• We demonstrate 
that there is a real need to develop 
code transformation 
methodologies 
Writing 
the processor 
stochastic 
optimization-based 
that address 
ticity. 
become a necessity 
computing 
work will evaluate 
posed approach. 
due to increasing 
and mitigate 
as a new source of stochas­
versions 
of applications 
may 
for future CMOS and post-CMOS 
Our future 
variation. 
the costs of the pro­
The rest of the paper is organized 
as follows. 
Section 
2 
work. Section 
of stochastic 
gradient 
for implementing 
3 summarizes 
known prop­
and illustrates 
solvers 
robust applications 
using mod­
of 
a generic 
descent. 
Section 
an application 
4 presents 
into its robust, 
related 
presents 
erties 
framework 
ified gradient 
converting 
Section 
discusses 
future work. Section 
5 presents 
four examples 
stochastic 
form. 
Section 
methodology 
and 
6 
our methodology 
and results. 
the limitations 
of the proposed 
7 concludes. 
by allowing hardware 
to produce errors even 
stochastic 
processor 
designs 
the software 
119, 3, 
/ hard­
re-think 
20, 41 aim to fundamentally 
ware interface 
during nominal 
niques presented 
in stochastic 
dressing errors 
the application 
level. 
The numerical 
in this paper represent 
processors 
operation. 
algorithmic 
tech­
one method of ad­
by handling 
them at 
characteristics 
noise  tolerance 
error tolerance 
function 
and knowledge 
overscaling 
and input/output 
r51 target probabilistic 
Some past works have also addressed 
at 
[141 is 
is em­
of the 
are 
errors that occur. Error resilient 
level. Algorithmic 
the algorithmic 
a technique 
for DSPs in which voltage 
ployed to reduce power consumption 
DSP's transfer 
used to tolerate 
architectures 
large pool of unreliable, 
as the main workhorse, 
sources 
tations 
addresses 
data with supplemental 
to produce the encoding 
encoded data to detect and correct 
is used to deal with errors and ensure that compu­
fault tolerance 
are completed. 
r161 
level by encoding 
input 
errors at the algorithmic 
checksums, 
for the output data, and using the 
In 
power-efficient 
while a smaller 
algorithms 
and use a 
computing 
Algorithm-based 
modifying 
set of reliable 
system 
re­
errors when possible. 
algorithms 
resources 
978-1-4244-7501-8/10/$26.00 
©2010 IEEE 
162 
DSN 2010: Sloan et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:54:08 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEE/IFIP 
International 
Conference 
on Dependable 
Systems & Networks (DSN) 
Non-Robust 
Application 
f(x) x* 
involves convert­
optimization 
to the output 
Robustification 
Figure 2: Application 
ing an application 
to an unconstrained 
problem, where the minimum corresponds 
of the original non-robust application. 
contrast 
application-specific 
in this paper for application-level 
and can potentially 
tions on stochastic 
error tolerance 
drive a large class of important 
processors. 
to the above approaches 
the methodology 
that are limited 
nature, 
that we present 
is generic 
applica­
by their 
3. PROPOSED APPROACH 
Our goal is to recast a given problem into an equivalent 
problem that can tolerate 
encodes the solution 
numerical 
whose solution 
lem. Let the vector x* denote the (unknown) 
To devise a robust algorithm, 
our problem. 
f whose minimum is attained 
a cost function 
ing the problem then amounts to minimizing 
challenges, 
noise in the FPU, and 
to the equivalent 
prob­
to 
solution 
we construct 
at x*. Solv­
f. The main 
as illustrated 
• How to construct 
• How to choose an optimization 
of x* a priori? 
in Figure 2: 
f without 
knowing the actual value 
engine that converges 
quickly 
and tolerates 
CPU noise? 
Since the selection 
of the minimization 
function 
can of­
ten depend on the optimization 
choice of our optimization 
engine. 
engine, 
we first detail 
the 
3.1 Stochastic 
Solvers for Constrained 
Opti­
mization 
Under mild conditions, 
as long as step sizes are chosen 
converges 
to a local optimum of 
even when the gradient 
descent 
gradient 
For this reason, 
carefully, 
the cost function 
proximately. 
as the primary optimization 
that tolerate 
mize a cost function 
ates a sequence 
noise in the CPU's numerical 
f : R d --+ R, gradient 
is known only ap­
we rely on gradient 
units. To mini­
descent 
gener­
descent 
engine to construct 
algorithms 
of steps xl ... Xi E  Rd via the iteration 
Xi +--xi-l + )...i\lf(xi-l), 
iterate 
of f at Xi-I, and the positive 
xO E  Rd. The vector 
(1) 
with a given initial 
starting 
\l f(xi-l) is a subgradient 
scalar)'" i is a step 
tion. The goal is for the sequence 
x* , of f. 
a local optimizer, 
size that may vary from iteration 
to 
to itera­
to converge 
of iterates 
The bulk of the computation 
in gradient 
descent 
is in 
by \l f(xi-\ e), with e denoting 
of xi-I. The remaining 
the step size, updating 
\l f. There may be variation-induced 
\l f. We denote the resulting 
noisy 
a random vari­
operations, 