network over a protocol by selecting hitListPerc percentage of these servers (for
the corresponding protocol) at random to form HitList. The attacker (or rather,
his bots) then contacts each element of HitList to generate the log ﬁle attk.
|HitList|
|bots|
More precisely, we allow the attacker to use multiple bots in the attack; let bots
denote the bots used by the attacker. bots do not appear in the log ctrlπ, so as to
decrease chances of triggering condition (2). Each bot boti ∈ bots is assigned a hit
list HitListi consisting of a random
fraction of HitList. Each bot’s hit list is
drawn randomly from HitList, but hit lists do not intersect. That is,
i HitListi =
HitList and for i (cid:10)= j, HitListi ∩ HitListj = ∅. By employing hit lists that do
not intersect, we again decrease the chances of triggering condition (2). attk is
generated by creating synthetic attack records from each boti to all members of
HitListi. In our simulations, members of HitListi do not participate in the attack
after being contacted by boti; i.e., each λ ∈ attk is initiated by a member of
bots. That said, this restriction is largely irrelevant to our results, since neither
|V (Λπ)| nor |C(Λπ)| is sensitive to whether a member of HitListi is contacted by
another member of HitListi (after it is “infected”) or by boti itself.
(cid:7)
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
287
5.3 True Alarms
Table 3 shows the eﬀectiveness of the detection mechanism as a function of
dur for diﬀerent hitListPerc values. hitListPerc varies between 25% and 100%.
The value in each cell is the percentage of attacks that were detected by the
system.
Table 3 sheds light on the eﬀectiveness of our approach. The most aggressive
worms we considered, namely those that contacted hitListPerc ≥ 75% of known
servers (see Table 2) within dur = 30s, were easily detected: our tests detected
these worms more than 90% of the time for all protocols and all numbers of
|bots|, and at least 95% of the time except in one case.
The table also sheds light on approaches an adversary might take to make his
worm more stealthy. First, the adversary might decrease hitListPerc. While this
does impact detection, our detection capability is still useful: e.g., as hitListPerc
is decreased to 50% in dur = 30s, the true detection rates drop, but remain 80%
or higher for all protocols except SMTP. Second, the adversary might increase
dur. If the adversary keeps hitListPerc ≥ 75%, then increasing dur from 30s to
60s appears to have no detrimental eﬀect on the true alarm rate of the detector
for HTTP, Oracle or FTP, and it remains at 60% or higher for SMTP, as well.
Third, the adversary might increase |bots|. Note that whereas the previous
two attempts to evade detection necessarily slow the worm propagation, increas-
ing |bots| while keeping hitListPerc and dur ﬁxed need not—though it obviously
requires the adversary to have compromised more hosts prior to launching his
hit-list worm. Intuitively, increasing |bots| might decrease the likelihood of de-
tection by our technique by reducing the probability that one boti will merge
components of the graph and thereby trigger condition (2). (Recall that bots’ in-
dividual hit lists do not intersect.) However, Table 3 suggests that in many cases
this is ineﬀective unless the adversary simultaneously decreases hitListPerc: with
hitListPerc ≥ 75%, all true detection rates with |bots| = 5 remain above 92% with
the exception of SMTP (at 60% for dur = 60s). The eﬀects of increasing |bots|
may become more pronounced with larger numbers, though if |bots| approaches
t σ(V dur
Π ) then the attacker risks being detected by condition (1) immediately.
Table 3. True alarm percentages for combined detector (conditions (1) and (2))
HTTP
SMTP
Oracle
FTP
hitListPerc =
hitListPerc = hitListPerc = hitListPerc =
dur |bots| 25 50 75 100 25 50 75 100 25 50 75 100 25 50 75 100
73 80 95 100 28 74 100 100 100 100 100 100 100 100 100 100
72 80 95 100 25 50 97 100 33 95 100 100 100 100 100 100
60 80 92 100 23 45 98 100 16 87 99 100 100 100 100 100
68 80 100 100 20 50 70 80 100 100 100 100 100 100 100 100
28 100 100 100 100 100 100 100
65 68 100 100 10 35 65 70
65 63 100 100 5 30 60 55
12 100 100 100 100 100 100 100
30s
60s
1
3
5
1
3
5
288
M.P. Collins and M.K. Reiter
Fig. 4. Contributions of conditions (1) and (2) to true alarms in Table 3. For clarity,
only true alarms where
≤ 20 are plotted.
|V (Λπ)|−μ(Vdur
Π )
|C(Λπ)|−μ(Cdur
Π )
≤ 20 or
σ(Vdur
Π )
σ(Cdur
Π )
Π ))/σ(Cdur
Π ))/σ(Cdur
Π ))/σ(V dur
Π ))/σ(V dur
Figure 4 compares the eﬀectiveness of conditions (1) and (2) for each of the
test protocols. Each plot in this ﬁgure is a scatter plot comparing the deviation
of |C(Λπ)| against the deviation of |V (Λπ)| during attacks. Speciﬁcally, values
on the horizontal axis are (|V (Λπ)|− μ(V dur
Π ), and values on the vertical
axis are (|C(Λπ)| − μ(Cdur
Π ), for Π ⊇ π. The points on the scatter plot
represent the true alarms summarized in Table 3, though for presentational
convenience only those true alarms where (|V (Λπ)| − μ(V dur
Π ) ≤ 20
or (|C(Λπ)| − μ(Cdur
Π ) ≤ 20 are shown. Each plot has reference lines at
t = 3.5 on the horizontal and vertical axes to indicate the trigger point for each
detection mechanism. That is, a “•” above the horizontal t = 3.5 line indicates a
test in which condition (2) was met, and a “•” to the right of the vertical t = 3.5
line indicates a test in which condition (1) was met.
We would expect that if both conditions were eﬀectively equivalent, then every
“•” would be in the upper right “quadrant” of each graph. HTTP (Figure 4(a))
shows this behavior, owing to the fact that in HTTP, the largest component
size and graph size are nearly the same in average and in standard deviation;
see Table 1. As such, each bot contacts only the largest component with high
probability, and so adds to the largest component all nodes that it also adds
to the graph. A similar phenomenon occurs with SMTP (Figure 4(b)), though
with diﬀerent scales in am and pm, yielding the two distinct patterns shown
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
289
there. However, the other graphs demonstrate diﬀerent behaviors. Figure 4(c)
and (d) shows that the growth of |C(Λπ)| is an eﬀective mechanism for detecting
disruptions in both Oracle and FTP networks. The only protocol where graph
inﬂation appears to be a more potent indicator than component inﬂation is
SMTP. From this, we conclude that component inﬂation (condition (2)) is a
more potent detector than graph inﬂation (condition (1)) when the protocol’s
graph structure is disjoint, but that each test has a role to play in detecting
attacks.
6 Bot Identiﬁcation
Once an attack is detected, individual attackers (bots) are identiﬁable by how
they deform the protocol graph. As discussed in Section 5.1, we expect a bot to
impact the graph’s structure by connecting otherwise disjoint components. We
therefore expect that removing a bot from a graph G(Λ) will separate compo-
nents and so the number of connected components will increase.
To test this hypothesis, we consider the eﬀect of removing all records λ in-
volving an individual IP address from Λ. Speciﬁcally, for a log ﬁle Λ and an IP
address v, deﬁne:
¬v = {λ ∈ Λ : λ.sip (cid:10)= v ∧ λ.dip (cid:10)= v}
Λ
¬v) in that the latter includes neither v nor any
As such, G(Λ) diﬀers from G(Λ
(cid:4) ∈ V (Λ) of degree one that is adjacent only to v in G(Λ).
v
In order to detect a bot, we are primarily interested in comparing G(Λ) and
¬v) for vertices v of high degree in G(Λ), based on the intuition that bots
G(Λ
should have high degree. Figure 5 examines the impact of eliminating each of
the ten highest-degree vertices v in G(Λ) from each log ﬁle Λ for FTP discussed
in Section 5 that resulted in a true alarm. Speciﬁcally:
– Figure 5(a) represents |V (Λ
¬v)| − |V (Λ)|, i.e., the diﬀerence in the number
of vertices due to eliminating v and all isolated neighbors, which will be
negative;
¬v)|−|C(Λ)|, i.e., the diﬀerence in the size of the
largest connected component due to eliminating v and all isolated neighbors,
which can be negative or zero; and
¬v)| − |K(Λ)|, i.e., the diﬀerence in the number
of connected components due to eliminating v and all isolated neighbors,
which can be positive, zero, or −1 if eliminating v and its isolated neighbors
eliminates an entire connected component.
– Figure 5(b) represents |C(Λ
– Figure 5(c) represents |K(Λ
Each boxplot separates the cases in which v is a bot (right) or is not a bot
(left). In each case, ﬁve horizontal lines from bottom to top mark the mini-
mum, ﬁrst quartile, median, third quartile and maximum values, with the lines
for the ﬁrst and third quartiles making a “box” that includes the median line.
The ﬁve horizontal lines and the box are evident, e.g., in the “bot” boxplot in
290
M.P. Collins and M.K. Reiter
Fig. 5. Eﬀects of eliminating high degree vertices v from FTP attack traﬃc logs Λ
Figure 5(c). However, because some horizontal lines are on top of one another
in other boxplots, the ﬁve lines or the box is not evident in all cases.
This ﬁgure shows a strong dichotomy between the two graph parameters used
for detection (graph size and largest component size) and the number of com-
ponents. As shown in Figures 5(a) and 5(b), the impact of eliminating bots and
the impact of eliminating other vertices largely overlap, for either graph size or
largest component size. In comparison, eliminating bots has a radically diﬀerent
eﬀect on the number of components, as shown in Figure 5(c): when a non-bot
vertex is eliminated, the number of components increases a small amount, or
sometimes decreases. In contrast, when a bot is eliminated, the number of com-
ponents increases strongly.
Also of note is that the change in the total number of components (Figure 5(c))
is relatively small, and small enough to add little power for attack detection. For
example, if we were to deﬁne a random variable Kdur
pm and
Cdur
pm , and then formulate a worm detection rule analogous to (1) and (2) for
component count—i.e., raise an alarm for log ﬁle Λπ where π ∈ pm had duration
dur, if |K(Λπ)| > μ(Kdur
pm )—then roughly 80% of our hit-list attacks
within FTP would go undetected by this check. This is because of the large
standard deviation of this measure: σ(K60s
pm analogous to V dur
pm) + t σ(Kdur
pm ) ≈ 12.5.
Despite the fact that the number of components does not oﬀer additional
power for attack detection, Figure 5(c) suggests that removing a high-degree
vertex v from a graph G(Λ) on which an alarm has been raised, and checking
the number of connected components that result, can provide an eﬀective test
to determine whether v is a bot. More speciﬁcally, we deﬁne the following bot
identiﬁcation test:
(cid:8)
isbotΛ,θ(v) =
1 if |K(Λ
0 otherwise
¬v)| − |K(Λ)| > θ
(4)
We characterize the quality of this test using ROC curves. Each curve in
Figure 6 is a plot of true positive (i.e., bot identiﬁcation) rate versus false positive
rate for one of the protocols we consider and for the simulated hit-list worm
attacks discussed in Section 5 that yielded a true alarm with |bots| = 5 (the
hardest case in which to ﬁnd the bots) and hitListPerc ∈ {25%, 50%, 75%}. Each
Hit-List Worm Detection and Bot Identiﬁcation in Large Networks
291
75%
50%
25%
 15
 10
 5
 40
False positive rate (percentage)
 20
 25
 30
 35
 45
 50
PTTH)a(
75%
50%
25%
 0
t
)
e
g
a
n
e
c
r
e
p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
)
e
g
a
t
n
e
c
r
e
p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5
 0
 0  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90  95 100
False positive rate (percentage)
t
)
e
g
a
n
e
c
r
e
p
(
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 100
 95
 90
 85
 80
 75
 70
 65
 60
 55
 50
)
e
g
a
t
n
e
c
r
e