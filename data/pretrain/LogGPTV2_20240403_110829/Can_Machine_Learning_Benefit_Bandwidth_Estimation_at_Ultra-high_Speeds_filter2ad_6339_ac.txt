### Impact of Interrupt Coalescence Parameters on Training and Testing

In our experiments, we have primarily utilized the default configuration on NIC1, which typically results in an interrupt delay of about 120 µs. 

#### Figure 10: Impact of ICparams in the Training Set
Different ICparams (Interrupt Coalescence parameters) lead to distinct "spike-dip" patterns in the receive gaps, characterized by the heights of the spikes and the distances between neighboring spikes. We investigate the impact of varying ICparams in the training versus testing data sets. A model trained with one parameter may perform poorly when applied to data streams with different parameters.

We first apply a previously learned machine learning (ML) model (trained with ICparam=default) to test scenarios where `rx-usecs` is set to specific values ranging from 2 µs to 300 µs. Figure 10 compares the estimation accuracy of BASS and the ML model. The box plots represent the 10%–90% relative error, while the extended bars show the 5%–95% error range.

Our findings indicate that BASS significantly overestimates available bandwidth (AB) when the interrupt delay is substantial (i.e., `rx-usecs ≥ 200 µs`), whereas the ML model provides better accuracy. This underscores the importance of carefully studying the impact of ICparams, a factor that was not considered in the BASS evaluations in [10]. Additionally, the ML model consistently underestimates AB when `rx-usecs = 300 µs`.

To ensure that the training set is representative of the conditions encountered during testing, we create a new training set, denoted as "ALL-set," which includes 5000 pstream samples for each ICparam. As shown in Figure 10, the model trained on "ALL-set" reduces the error to within 10% for most pstreams, even those with extreme `rx-usecs` values.

In practice, it may not be feasible to know all possible configurations of ICparams at a receiver NIC. We then explore whether a model trained with a limited set of ICparams can still be effective. To this end, we minimize the training set to include only two extreme values (2 µs and 300 µs) along with the default setting, referred to as "3sets." Figure 10 shows that "3sets" is sufficient to train an accurate ML model, providing similar accuracy to "ALL-set."

### Robustness and Portability Across NICs

Different NIC platforms may interpret and implement interrupt coalescence differently. For instance, NIC-2 relies on adaptive interrupt behavior, even though it allows specifying `rx-usecs` and `rx-frames`. Figure 11 illustrates the distribution of the number of frames coalesced per interrupt on NIC-2. We find that `rx-frames` has no effect when `rx-usecs ≤ 12 µs`, and `rx-usecs` is not respected once it exceeds 12 µs; the distribution mainly depends on `rx-frames`. This unpredictability contrasts with what we observed on NIC1.

#### Figure 11: Interrupting Behavior on NIC2
We repeat the experiments from Section 5.3 using NIC2 instead of NIC1 for both training and testing data. We consider the following ICparams for NIC-2: `rx-usecs` from 2 to 10 µs, and `rx-frames` from 2 to 20 (with `rx-usecs=100`). Models are trained using different combinations of ICparams, namely "Default," "All-set," and "3sets" (default, `rx-frames=2`, and `rx-frames=20`). Figure 12 plots the estimation errors for these three environments.

Compared to Figure 10, the estimation error is generally higher on NIC-2 than on NIC-1, likely due to greater unpredictability in its interrupt behavior. As before, the "3sets" on NIC-2 outperforms BASS significantly and provides comparable accuracy to "All-set," consistent with our observations on NIC-1.

#### Figure 12: Impact of ICparams on NIC-2
**Cross-NIC Validation:**
To investigate the portability of a learned model across NICs, we perform cross-NIC validation. The model trained with data from one NIC is tested on data from a different NIC. Using only ICparam="3sets," we plot the results in Figures 13(a) and (b). Generally, we find that the cross-NIC models provide comparable accuracy to models trained on the NIC itself. Notable exceptions occur for extreme values of ICparams, such as `rx-usecs=300 µs` on NIC1 and `rx-frames=20` on NIC2.

#### Figure 13: Cross-NIC Evaluation

### Implementation Overhead

The benefits of our ML framework come with some overhead during the testing phase. The entire model must be loaded into memory, increasing memory usage, and the estimation time increases with model complexity. Table 2 lists the memory and CPU costs for different models trained with ICparam="3sets" for generating a single estimate. The memory usage is shown as a relative increment compared to BASS.

| Model | Memory (KB) | CPU Time (s) |
|-------|-------------|--------------|
| GradientBoost (Single-rate, N=48) | 248 | 7.7e-6 |
| AdaBoost (Multi-rate, N=48) | 3.3 MB | 8.1e-6 |
| Random Forest (Multi-rate, N=48) | 3.8 MB | 2.5e-5 |

Although the numbers are implementation-specific, it is important to understand the implementation complexity. In our evaluations, the offline-learned GradientBoost model consists of 100 base estimators, each with a decision tree height less than 3. The memory cost of maintaining 100 small trees and the time complexity in tree-search (upper-bounded by 300 comparisons) are both manageable in modern end-systems, in both user and kernel space.

Network operators can use any preferred ML library to program the training process and store the learned model. The stored model contains parameters that fully define the model structure, making it easily portable to other development platforms. Even a Linux kernel module, such as those used in bandwidth-estimation-based congestion control, can load the model during initialization and reconstruct it to estimate AB.

### Conclusion

In this paper, we apply machine learning techniques to estimate bandwidth in ultra-high-speed networks and evaluate our approach in a 10 Gbps testbed. We find that supervised learning improves estimation accuracy for both single-rate and multi-rate probing frameworks, enabling shorter pstreams than the state-of-the-art methods. Further experiments show that:
1. A model trained with more bursty cross-traffic is robust to traffic burstiness.
2. The ML approach is robust to interrupt coalescence parameters if default and extreme configurations are included in training.
3. The ML framework is portable across different NIC platforms.

In future work, we intend to conduct evaluations with more NICs from different vendors and investigate practical issues related to generating training traffic in various networks.

### References
[References listed as provided in the original text]