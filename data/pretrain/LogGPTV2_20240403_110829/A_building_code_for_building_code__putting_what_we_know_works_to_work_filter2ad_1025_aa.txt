title:A building code for building code: putting what we know works to work
author:Carl E. Landwehr
A Building Code for Building Code 
Putting What We Know Works to Work
Carl E. Landwehr 
George Washington University 
1923 Kenbar Ct. 
McLean, VA 22101 
ABSTRACT 
Systems  of  programs  control  more  and  more  of  our  critical 
infrastructures.  Forty  years  of  system  development  and  research 
have  taught  us  many  lessons  in  how  to  build  software  that  is 
reliable, relatively free of vulnerabilities, and can enforce security 
policies.  Those  years  of  experience  seem  not  to  have  taught  us 
how to get these lessons put into practice, particularly with respect 
to security, except in a few specialized places. This essay suggests 
an approach to capturing what we know in a way that can make a 
difference in systems on which we all rely. 
Categories and Subject Descriptors 
1998  CR  classification:  D.2.0  SOFTWARE  ENGINEERING 
General  (Protection  Mechanisms,  Standards)  K.4  COMPUTERS 
AND SOCIETY K.4.1 Public Policy Issues (Regulation)  
General Terms 
Security, Standardization, Management 
Keywords 
Security policy, critical infrastructure software, building code 
1.  INTRODUCTION 
In  The  Mythical  Man-Month  Fred  Brooks  writes,  under  the 
heading “The Joys of the Craft”: 
"...  The  programmer,  like  the  poet,  works  only  slightly 
removed from pure thought-stuff. He builds his castles in the 
air  from  air,  creating  by  exertion  of  the  imagination.  Few 
media  of  creation  are  so  flexible,  so  easy  to  polish  and 
rework,  so  readily  capable  of  realizing  grand  conceptual 
structures. ... 
"Yet the program construct, unlike the poet's words, is 
real in the sense that it moves and works, producing visible 
outputs  separate  from  the  construct  itself.  It  prints  results, 
draws pictures, produces sounds, moves arms. The magic of 
Permission to make digital or hard copies of all or part of this work for 
personal or classroom use is granted without fee provided that copies are 
not  made  or  distributed  for  profit  or  commercial  advantage  and  that 
copies bear this notice and the full citation on the first page. Copyrights 
for  components  of  this  work  owned  by  others  than  ACM  must  be 
honored.  Abstracting  with  credit  is  permitted.  To  copy  otherwise,  or 
republish,  to  post  on  servers  or  to  redistribute  to  lists,  requires  prior 
specific 
permissions 
from Permissions@acm.org.  
ACSAC '13, December 09 - 13 2013, New Orleans, LA, USA 
Copyright 2013 ACM 978-1-4503-2015-3/13/12…$15.00.  
http://dx.doi.org/10.1145/2523649.2530278  
fee.  Request 
a 
permission 
and/or 
myth  and  legend  has  come  true  in  our  time.  One  types  the 
correct  incantation  on  a  keyboard,  and  a  display  screen 
comes to life, showing things that never were nor could be. 
     "Programming  then  is  fun  because  it  gratifies  creative 
longings  built  deep  within  us  and  delights  sensibilities  we 
have in common with all.” [1, p.7] 
Though I won’t claim any software I ever wrote rose to the level 
of  poetry,  I  quote  these  lines  in  part  because  they  capture  what 
first drew me into computing and computer science.  
These  lines  also  remind  us  that  although  the  execution  of  a 
program  by  a  computer  can  have  very  concrete  effects,  the 
program  itself  is  a  relatively  abstract  creation  –  “only  slightly 
removed  from  pure  thought-stuff.”    But  unlike  the  poet,  whose 
language  communicates  directly  to  readers,  the  programmer’s 
creation is visible to most people only through its physical effects. 
Metaphor is a figure of speech in which two otherwise unrelated 
objects are asserted to be the same on some point of comparison 
(without  using  “like”  or  “as”,  which  would  convert  metaphor  to 
simile). To think about ethereal things, or things they don’t fully 
understand, people often resort to metaphors – things in the real 
world that they do understand and that they can use to talk about 
and think about those things made of "pure thought stuff". 
This  kind  of  thinking  can  be  wonderfully  helpful.  A  good 
metaphor  can  provoke  insights  about  the  problem  domain  that 
might be difficult or impossible to achieve through direct analysis. 
But  there  is  a  risk  that  in  embracing  the  metaphor,  we  will  lose 
sight of the places where metaphor and reality depart.  Based on 
the metaphor, we may believe things about the program that are 
not necessarily true. 
The balance of this essay proposes the adoption of the metaphor 
of a building code as a framework to capture what we know about 
how to build software that can weather attacks and as a vehicle to 
put  that  knowledge  into  practice  where  it  counts.  But  first,  it 
considers briefly the merits of some metaphors currently in wide 
use for software and computing systems. 
2.  METAPHORS IN USE TODAY 
If we think of a metaphor as a sort of mapping from a domain we 
know something about – a source domain – to another domain we 
are less certain of – the target domain, the metaphor may help us 
understand  the  target  domain  if  (1)  the  relationship  captures  an 
essential aspect of the target, (2) it hides irrelevant details of the 
target, and (3) reasoning in the source domain yields results in the 
target domain that remain valid. 
The well-known story of the six blind men examining the elephant 
exemplifies metaphors that fail the second and third of these tests. 
Each  of  the  examiners  creates  his  own  metaphor  for  the  beast 
based on the particular part of the animal he is exposed to: the one 
at the tail thinks the elephant is a rope, the one at the trunk thinks 
139
it is a snake, the one at the tusk thinks the elephant is a spear and 
so on.  
Metaphors  have  been  used  to  explain  computer  and  information 
security  problems  to  people  for  a  long  time.  We  assess  several  
commonly used ones below. 
2.1  Trojan Horse 
Perhaps  the  oldest  metaphor  in  computer  security  is  the  Trojan 
horse. The story originates in Homer’s Iliad, in which the Greeks 
appear to admit defeat and abandon the field, leaving behind what 
seems to be a trophy to the Trojans: a large wooden replica of a 
horse. The Trojans move the horse inside the city walls. But the 
Greeks have concealed a few men inside it who then escape the 
following  night  and  open  the  city’s  gates,  allowing  the  Greek 
army to invade and slaughter the inhabitants.  
In the computer security context, the earliest use I have found of 
this  metaphor  is  in  the  Anderson  Report  in  1972,  where  the 
identification of this kind of attack is attributed to Dan Edwards of 
the NSA [2, p.62]. In the computing context, the Trojan horse is a 
program that provides a function appealing enough that a user (or 
administrator)  is  willing  to  install  it  even  though  its  internal 
details are not known.  Once activated in the victim’s computing 
context,  the  Trojan  horse  program  takes  advantage  of  the 
privileges of that context to perform whatever functions its author 
built into it, possibly including downloading additional malicious 
software, for example. 
This  metaphor  seems  to  work  pretty  well.  The  story  is  widely 
understood, the metaphor captures an essential aspect of the target 
domain  –  installing  a  dangerous  component  inside  a  security 
perimeter, and reasoning about what the Trojans might have done 
to  avoid  disaster  carries  over  reasonably  well  to  the  computing 
domain. 
2.2  Worm 
The  original  use  of  “worm”  in  a  computing  context  apparently 
comes  from  the  novel  Shockwave  Rider,  published  by  John 
Brunner in 1975 [3].  As used in that story, the worm is a (virtual) 
tapeworm and thus a parasite. In 1982, John Shoch and Jon Hupp 
implemented a worm at Xerox PARC to take advantage of unused 
computing cycles on a distributed set of machines [4]. 
The term is now defined in Internet RFC 1135 [5] as follows:  
A  "worm"  is  a  program  that  can  run  independently,  will 
consume  the  resources  of  its  host  from  within  in  order  to 
maintain  itself,  and  can  propagate  a  complete  working 
version of itself on to other machines. 
Again,  the  notion  of  biological  worms,  including  tapeworms,  is 
widely  understood.    Biological  parasitic  worms  may  require 
alternate hosts to propagate, and computational worms may also 
reflect that aspect. So it seems the metaphor does capture essential 
aspects of the target domain. It definitely hides many inessential 
details, and reasoning about biological parasitic worms seems to 
carry  over  reasonably  well  in  the  computational  domain:  worms 
consume host resources, can propagate to other systems, and can 
be difficult to eradicate. 
2.3  Virus 
The precise origins of the virus metaphor for a particular kind of 
software  (today  malware)  are  a  but  murky.  David  Gerrold’s 
science  fiction  novel,  When  HARLIE  Was  One  [6],  published  in 
1972, is said to include “one of the first fictional representations 
of  a  computer  virus”[7].    The  earliest  use  of  the  term  in  the 
technical literature is a paper by Fred Cohen in 1984 [8]. Again 
drawing on RFC 1135: 
A  "virus"  is  a  piece  of  code  that  inserts  itself  into  a  host, 
including  operating  systems,  to  propagate.    It  cannot  run 
independently.    It  requires  that  its  host  program  be  run  to 
activate it.  
Viruses  are  a  widely  understood  biological  phenomenon,  and  as 
the definition above indicates, the computational version displays 
the ability to infect and modify the behavior of the host system but 
depends  on  mechanisms  in  the  host  for  replication,  as  the 
biological  version  does.  As  biological  viruses  sometimes  mutate 
to form strains that resist prior treatments, computational viruses 
have developed (albeit with human assistance) means of resisting 
computational countermeasures.  A new strain of virus, biological 
or  computational,  may  require  new  detection  mechanisms  and 
new cures. So this metaphor seems apt. 
2.4  Firewall 
Physical  firewalls  are  designed  to  prevent,  or  at  least  delay,  the 
propagation  of  a  fire  between  parts  of  a  building.  The 
International Building Code includes the following definition:  
FIRE  WALL:  A  fire-resistance-rated  wall  having 
protected openings, which restricts the spread of fire and  
extends continuously from the foundation to or through 
the  roof,  with  sufficient  structural  stability  under  fire 
conditions to allow collapse of the construction on either 
side without collapse of the wall.  
The Anderson report [2] actually used “firewall” as a description 
for  the  barriers  an  operating  system  should  provide  between 
different user domains in a time-sharing system in 1972, but the 
term gained its modern meaning with the advent of internet packet 
filters in the late 1980s and early 1990s. By the time Bellovin and 
Cheswick’s classic book [9] appeared in 1994, it was in wide use.  
Unfortunately this metaphor has some serious problems. As noted 
above,  conventional  firewalls  are  there  to  stop  pretty  much 
anything,  particularly  fire,  from  penetrating  them.    Internet 
firewalls aim to stop only the traffic they can detect as evil and to 
let everything else pass through – so their fundamental purpose is 
to provide communication, not to stop it. Indeed, firewalls barely 
slow  down  a  capable  attacker,  and  this  has  been  true  for  a  long 
time.    So  this  seems  to  be  a  case  where  the  metaphor,  though 
widely used, has fooled many people into thinking this component 
provides a much greater degree of protection than it can achieve 
in  fact.    A  propped-open  firedoor,  perhaps  manned  by  a  sleepy 
attendant, might be a better visualization of the operation of these 
components. 
2.5  Public Health 
Cybersecurity  is  frequently  described  using  the  terms  of  public 
health.  This  metaphor  fits  well  with  the  virus  and  worm 
metaphors.      For  example,users  and  system  administrators  are 
admonished  to  observe  proper  “hygiene.”.  Systems  hosting 
malware  are  “infected.”    Large  clusters  of  machines  should  be 
“immunized”  so  they  will  display  “herd  immunity,”  and  if  they 
are  identically  configured  they  may  represented  a  vulnerable 
“monoculture.”    There  have  even  been  calls  for  creating  a 
cybersecurity  version  of  the  US  Center  for  Disease  Control  to 
monitor malware outbreaks and provide immunizations.    
In general, this metaphor works well according to the criteria we 
have been using. Everyone understands public health and a good 
deal  of  the  reasoning  one  might  follow  in  the  public  health 