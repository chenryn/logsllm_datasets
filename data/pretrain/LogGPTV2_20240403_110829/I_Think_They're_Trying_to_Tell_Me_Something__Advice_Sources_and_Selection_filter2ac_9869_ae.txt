We also found that participants rely on IT professionals,
particularly those from their workplaces, as a source of
credible digital-security advice, even for personal technology.
Given that many IT professionals are already overloaded with
requests, we suggest organizations plan to provide them with
extra support and training for this potentially critical but under-
acknowledged role. Training IT professionals to distribute a
small set of valuable advice as an explicit part of their job
duties could have a strong positive impact on users’ security
behavior. Investigating the feasibility and efﬁcacy of this
approach is a rich topic for future work.
VI. SUMMARY
Users must sift through a multitude of security advice to
determine which security behaviors to implement and which
to reject. This process of evaluating security tactics based on
the advice of others is multi-faceted and complex. In an effort
to understand users’ choices, we conducted a semi-structured
interview study of 25 participants with varied demographics
and security sensitivities. We asked questions about users’
security behaviors, how they learned these behaviors, and why
they accepted or rejected different behaviors and pieces of
advice. Our analysis of these interviews resulted in three key
ﬁndings.
First, our ﬁndings indicate that users believe they lack the
skills to evaluate the content of digital-security advice and
must instead rely on their evaluation of the trustworthiness
of the advice source when determining whether to accept the
advice. Sources they trust include their workplace, providers
of their digital services, IT professionals, family members, and
friends. Our participants also relied upon media as a source
of advice, but only if it passed an heuristic credibility test.
Second, we found that users reject security advice for a
number of somewhat surprising reasons, including containing
too much marketing information and threatening users’ sense
of privacy. Further, a majority of participants believed that
someone or something else was responsible for their security
in at least one digital domain (e.g., online banking).
Third, we found evidence that vignettes of negative ex-
periences in TV shows or movies may be able to change
behavior in a similar manager to negative experiences that are
directly experienced. Thus, through further research testing
the efﬁcacy of ﬁctional negative-event vignettes in security-
behavior change, we may be able to develop a novel, highly-
effective intervention.
ACKNOWLEDGMENTS
Our thanks to Lujo Bauer, Yla Tausczik, Bethany Tiernan,
and Bruce Webster, Jr. for their input and assistance. This
material
is based upon work supported by the Maryland
Procurement Ofﬁce under contract no. H98230-14-C-0137.
REFERENCES
[1] “Us-cert:tips.” [Online]. Available: https://www.us-cert.gov/ncas/tips
[2] S. Das, T. H. Kim, L. Dabbish, and J. Hong, “The effect of social
inﬂuence on security sensitivity,” in Tenth Symposium on Usable Privacy
and Security. USENIX Association, 2014. [Online]. Available: https:
//www.usenix.org/conference/soups2014/proceedings/presentation/das
[3] E. Rader, R. Wash, and B. Brooks, “Stories as informal lessons about
security,” in Eighth Symposium on Usable Privacy and Security. ACM,
2012. [Online]. Available: http://doi.acm.org/10.1145/2335356.2335364
283283
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:08 UTC from IEEE Xplore.  Restrictions apply. 
[4] L. Rainie, S. Kiesler, R. Kang, and M. Madden, “Anonymity,
privacy and security online,” Pew Research Center, 2013. [Online].
Available: http://www.pewinternet.org/2013/09/05/anonymity-privacy-
and-security-online/
[5] A. E. Howe,
I. Ray, M. Roberts, M. Urbanska, and Z. Byrne,
the home computer user.” in
“The psychology of
IEEE Symposium on Security and Privacy.
IEEE Computer
Society, 2012. [Online]. Available: http://dblp.uni-trier.de/db/conf/sp/
sp2012.html#HoweRRUB12
security for
[6] C. Herley, “So long, and no thanks for the externalities: The rational
rejection of security advice by users,” in New Security Paradigms
[Online]. Available: http://doi.acm.org/
Workshop.
ACM, 2009.
10.1145/1719030.1719050
[7] A. Beautement, M. A. Sasse, and M. Wonham, “The compliance
budget: managing security behaviour
in organisations,” in 2008
workshop on New security paradigms. ACM, 2009. [Online]. Avail-
http://portal.acm.org/citation.cfm?id=1595676.1595684&coll=
able:
DL&dl=ACM&CFID=595658384&CFTOKEN=19488999
““...no
non-expert
hack my mind”: Comparing
practices,”
Security. USENIX Association, 2015.
//www.usenix.org/conference/soups2015/proceedings/presentation/ion
can
security
and
[Online]. Available: https:
Symposium On Usable Privacy
S. Consolvo,
and
Ion, R. Reeder,
in Eleventh
expert
[8] I.
[9] S. Das, A. D. Kramer, L. A. Dabbish,
I. Hong,
“Increasing security sensitivity with social proof: A large-scale
experimental conﬁrmation,” in SIGSAC Conference on Computer
and Communications Security. ACM, 2014.
[Online]. Available:
http://doi.acm.org/10.1145/2660267.2660271
and J.
and
one
[10] R. Wash, “Folk models of home computer security,” in Sixth Symposium
on Usable Privacy and Security. ACM, 2010. [Online]. Available:
http://cups.cs.cmu.edu/soups/2010/proceedings/a11 Walsh.pdf
[11] E. Rader and R. Wash, “Identifying patterns in informal sources
of security information,” Journal of Cybersecurity, 2015. [Online].
Available: http://cybersecurity.oxfordjournals.org/content/early/2015/12/
01/cybsec.tyv008
[12] C. Herley, “More is not
the answer,” IEEE Security and Privacy
[Online]. Available: http://research.microsoft.com/
magazine, 2014.
apps/pubs/default.aspx?id=208503
[18] E. M. Rogers, Diffusion of innovations. New York: Free Press, 2003.
[19] R. E. Rice and K. E. Pearce, “Divide and diffuse: Comparing digital
divide and diffusion of innovations perspectives on mobile phone
adoption,” 2015.
[20] P. J. A. van Dijk, “The evolution of
the
digital divide turns to inequality of skills and usage,” in Digital
Enlightenment Yearbook 2012, J. Bus, M. Crompton, M. Hildebrandt,
and G. Metakides, Eds. Amsterdam: IOS Press, 2012. [Online].
Available: http://doc.utwente.nl/83918/
the digital divide -
[21] S. Sheng, B. Magnien, P. Kumaraguru, A. Acquisti, L. F. Cranor,
J. Hong, and E. Nunge, “Anti-phishing phil: The design and evaluation
of a game that teaches people not to fall for phish,” in Third Symposium
on Usable Privacy and Security. ACM, 2007. [Online]. Available:
http://doi.acm.org/10.1145/1280680.1280692
[22] N. A. G. Arachchilage and S. Love, “A game design framework
for avoiding phishing attacks,” Comput. Hum. Behav., 2013. [Online].
Available: http://dx.doi.org/10.1016/j.chb.2012.12.018
Eleventh
“Too much
[13] R. Wash
and E. Rader,
Symposium On Usable
knowledge?
among united states
and protective behaviors
in
security
internet
beliefs
users,”
and
Security. USENIX Association, 2015.
[Online]. Available: https:
//www.usenix.org/conference/soups2015/proceedings/presentation/wash
[14] T. Halevi, J. Lewis, and N. Memon, “A pilot study of cyber
security and privacy related behavior and personality traits,” in 22nd
International Conference on World Wide Web.
International World
Wide Web Conferences Steering Committee, 2013. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2487788.2488034
Privacy
[15] S. Sheng, M. Holbrook, P. Kumaraguru, L. F. Cranor, and J. Downs,
“Who falls for phish?: A demographic analysis of phishing susceptibility
and effectiveness of interventions,” in SIGCHI Conference on Human
Factors in Computing Systems. ACM, 2010. [Online]. Available:
http://doi.acm.org/10.1145/1753326.1753383
[16] “Microsoft safety and security center.” [Online]. Available: http:
//www.microsoft.com/security/default.aspx
[17] “Mcafee
security
advice
center.”
[Online]. Available:
http:
//home.mcafee.com/advicecenter/
[23] V. Garg, L. J. Camp, K. Connelly, and L. Lorenzen-Huber, “Risk
communication design: Video vs.
in Privacy Enhancing
Technologies: 12th International Symposium, PETS 2012, Vigo, Spain,
Springer Berlin Heidelberg, 2012.
[Online].
July 11-13, 2012.
Available: http://dx.doi.org/10.1007/978-3-642-31680-7 15
text,”
[24] S. A. Robila and J. W. Ragucci, “Don’t be a phish: Steps
in user education,” in Proceedings of
the 11th Annual SIGCSE
Conference on Innovation and Technology in Computer Science
Education. New York, NY, USA: ACM, 2006. [Online]. Available:
http://doi.acm.org/10.1145/1140124.1140187
[25] E. Lin, S. Greenberg, E. Trotter, D. Ma, and J. Aycock, “Does domain
highlighting help people identify phishing sites?” in Proceedings
of
in Computing
Systems. New York, NY, USA: ACM, 2011. [Online]. Available:
http://doi.acm.org/10.1145/1978942.1979244
the SIGCHI Conference on Human Factors
[26] S. Egelman, L. F. Cranor, and J. Hong, “You’ve been warned: An
empirical study of the effectiveness of web browser phishing warnings,”
in SIGCHI Conference on Human Factors in Computing Systems. ACM,
2008. [Online]. Available: http://doi.acm.org/10.1145/1357054.1357219
[27] D. Akhawe and A. P. Felt, “Alice in warningland: A large-
security warning effectiveness,” in
Berkeley, CA, USA:
[Online]. Available: http://dl.acm.org/
scale ﬁeld study of browser
22nd USENIX Conference on Security.
USENIX Association, 2013.
citation.cfm?id=2534766.2534789
Sunshine,
F. Cranor,
S. Egelman, H. Almuhimedi, N. Atri,
of
and
[28] J.
L.
ssl
warning effectiveness,” in 18th Conference on USENIX Security
Symposium.
[Online]. Available:
http://dl.acm.org/citation.cfm?id=1855768.1855793
USENIX Association,
“Crying wolf: An
empirical
2009.
study
[29] M. Wu, R. C. Miller, and S. L. Garﬁnkel, “Do security toolbars
actually prevent phishing attacks?” in SIGCHI Conference on Human
Factors in Computing Systems. ACM, 2006. [Online]. Available:
http://doi.acm.org/10.1145/1124772.1124863
[30] S. E. Schechter, R. Dhamija, A. Ozment, and I. Fischer, “The Emperor’s
New Security Indicators,” IEEE Symposium on Security and Privacy,
2007. [Online]. Available: http://dl.acm.org/citation.cfm?id=1264196
[31] C. Bravo-Lillo, S. Komanduri, L. F. Cranor, R. W. Reeder, M. Sleeper,
J. Downs, and S. Schechter, “Your attention please: Designing
security-decision uis to make genuine risks harder to ignore,” in Ninth
Symposium on Usable Privacy and Security. ACM, 2013. [Online].
Available: http://doi.acm.org/10.1145/2501604.2501610
[32] B. Ur, P. G. Kelley, S. Komanduri, J. Lee, M. Maass, M. L.
Mazurek, T. Passaro, R. Shay, T. Vidas, L. Bauer, N. Christin,
and L. F. Cranor, “How does your password measure up? the
effect of strength meters on password creation,” in 21st USENIX
conference on Security symposium. USENIX Association, 2012.
https://www.usenix.org/system/ﬁles/conference/
[Online]. Available:
usenixsecurity12/sec12-ﬁnal209.pdf
[33] M. Ciampa, “A comparison of password feedback mechanisms and their
impact on password entropy,” Information Management & Computer
Security, 2013. [Online]. Available: http://dx.doi.org/10.1108/IMCS-
12-2012-0072
[34] M. Fujita, M. Yamada, S. Arimura, Y. Ikeya, and M. Nishigaki, “An at-
tempt to memorize strong passwords while playing games,” in Network-
Based Information Systems (NBiS), 2015 18th International Conference
on, September 2015.
[35] S. Schechter
and J. Bonneau,
for
unlocking mobile devices,” in Eleventh Symposium On Usable
USENIX Association,
Privacy
[Online]. Available: https://www.usenix.org/conference/
July 2015.
soups2015/proceedings/presentation/schechter
“Learning assigned secrets
(SOUPS
Security
2015).
and
[36] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and D. Wagner,
“Android permissions: user attention, comprehension, and behavior,”
in Eighth Symposium on Usable Privacy and Security. ACM, 2012.
[Online]. Available: http://cups.cs.cmu.edu/soups/2012/proceedings/a3
Felt.pdf
[37] P. G. Kelley, L. F. Cranor, and N. Sadeh, “Privacy as part of
the app decision-making process,” in SIGCHI Conference on Human
Factors in Computing Systems. ACM, 2013. [Online]. Available:
http://patrickgagekelley.com/papers/android-decision.pdf
[38] C. S. Gates, J. Chen, N. Li, and R. W. Proctor, “Effective risk
communication for android apps,” IEEE Transactions on Dependable
and Secure Computing, May 2014.
284284
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:08 UTC from IEEE Xplore.  Restrictions apply. 
[44] D. G. Freelon, “Recal: Intercoder reliability calculation as a web
[69] D. Laibson, “Golden eggs and hyperbolic discounting,” Quarterly Jour-
of how audience involvement, message processing, and message
design inﬂuence health information recall,”
Journal of Health
Communication, 2013. [Online]. Available: http://dx.doi.org/10.1080/
10810730.2012.688244
“Computer help at home: Methods
[65] E. S. Poole, M. Chetty, T. Morgan, R. E. Grinter, and W. K.
and motivations
Edwards,
for
the SIGCHI
Conference on Human Factors in Computing Systems, ser. CHI
’09. New York, NY, USA: ACM, 2009.
[Online]. Available:
http://doi.acm.org/10.1145/1518701.1518816
support,” in Proceedings of
technical
informal
[66] M. B. Twidale, “Over the shoulder learning: Supporting brief informal
learning,” Comput. Supported Coop. Work, December 2005. [Online].
Available: http://dx.doi.org/10.1007/s10606-005-9007-7
[67] X. Hu, “Assessing source credibility on social media— an electronic
word-of-mouth communication perspective,” Ph.D. dissertation, Bowling
Green State University, 2015.
[68] M. Kang, “Measuring social media credibility: A study on a measure
of blog credibility,” Institute for Public Relations, 2009.
nal of Economics, 1997.
VII. APPENDIX
A. Questions
Employment
• Could you tell me a little bit about what you do?
• Do you handle sensitive or private data as part of your
job?
– Could you tell me a little bit more about that data?
Digital Security
Device Protection
• How many devices do you use to access the internet for
personal use?
– Do you have a smartphone? Tablet? Multiple com-
puters?
– What type or brand of smartphone or computer (e.g.
Windows/Mac/Linux) do you use?
• Can you show me how you access your devices?
– When was the last time you changed this password?
• Are there any other tactics you use to protect your
devices?
• Do you use antivirus software?
– How often do you run the software?
– Did you install it or did it come with your computer?
– Why do you use it?
• Why do you use these strategies for protecting your
[phone/computer/devices]? For each strategy, ask:
– When did you start using this strategy?
– How do you feel that this strategy works to protect
[39] E. K. Choe, J. Jung, B. Lee, and K. Fisher, “Nudging people
away from privacy-invasive mobile apps through visual framing,” in
Human-Computer Interaction INTERACT 2013, Part III, P. Kotz´e,
G. Marsden, G. Lindgaard, J. Wesson, and M. Winckler, Eds., 2013.
[Online]. Available: http://dx.doi.org/10.1007/978-3-642-40477-1 5
[40] K. Charmaz, Constructing grounded theory : a practical guide through
qualitative analysis. London; Thousand Oaks, Calif.: Sage Publications,
http://www.amazon.com/Constructing-
2006.
Grounded-Theory-Qualitative-Introducing/dp/0761973532
[Online]. Available:
[41] G. Guest, A. Bunce, and L. Johnson, “How many interviews are
enough?: An experiment with data saturation and variability,” Field
Methods, 2006.
[42] M. C. Harrell and M. A. Bradley, “Data collection methods. Semi-
structured interviews and focus groups,” DTIC Document, Tech. Rep.,
2009. [Online]. Available: http://www.rand.org/content/dam/rand/pubs/
technical reports/2009/RAND TR718.pdf
[43] A. Strauss and J. Corbin, Basics of qualitative research: Procedures and
techniques for developing grounded theory, 1998.
service,” International Journal of Internet Science, 2010.
[45] M. Lombard, J. Snyder-Duch, and C. C. Bracken, “Content Analysis in
Intercoder
[Online].
Mass Communication: Assessment and Reporting of