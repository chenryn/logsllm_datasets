(1) interface.c receives a fork request from AFL.
(2) One of the forked interface.c processes loads the provided
input file, the other keeps running the fork server.
(3) The former interface.c process sends the provided input
file over a TCP connection to the Kelinci server.
(4) The Kelinci server receives the incoming request and en-
queues it.
(5) The Kelinci server processes the request by writing the
incoming input file to disk, starting a new thread in which
the main method of the target application is called on the
provided input and monitoring it. If the thread throws an ex-
ception that escapes main, it is considered a bug. If the thread
does not terminate within a given time-out, it is considered
a hang.
(6) The Kelinci server communicates the results back to the
C side. The shared memory bitmap is sent over the TCP
connection, as well as the status (OK, ERROR or TIMEOUT).
(7) On the C side, the received bitmap is written to shared mem-
ory. Depending on the received status, the program exits
normally, aborts or keeps looping until AFL hits its time-out.
To use the tool, the user first runs the Instrumentor on the tar-
get application. Next, the user starts the Kelinci server in the instru-
mented program. Finally, the user executes AFL on interface.c.
The fuzzer is unaware that it is actually analyzing a Java program.
3 EVALUATION
To evaluate Kelinci we ran it on a JPEG parser. We chose Apache
Commons Imaging because it is written completely in Java and
the Apache Commons libraries are well-known. The version we
analyzed is release candidate 7 (“commons-imaging-1.0-RC7”). We
compare this against a run of AFL on the djpeg utility that comes
with the IJG jpeg library[12].
The first notable observation is that the behavior of Kelinci on
Apache Commons Imaging is similar to the behavior of AFL on
djpeg: it quickly finds that if the first byte is 0xFF, new behavior
is triggered. Using this second-generation test-case, Kelinci finds
after approximately 20 minutes that if the next byte is 0xD8, many
new behaviors are triggered. In fact, as AFL on djpeg also showed,
the two bytes 0xFF 0xD8 that Kelinci finds are the correct mark-
ers for the start of a JPEG image. As inputs that cause previously
unexplored program behaviors are prioritized by AFL, the fuzzer
will get incrementally closer to valid JPEG inputs.
After running Kelinci on our case study for 32 minutes, it found
a bug: the value of segment length bytes is not properly validated.
Each JPEG segment starts with a two-byte unsigned integer spec-
ifying the segment size. As the specified size includes these two
bytes, the program subtracts 2 from the size before it is used. It
then attempts to allocate a buffer for the segment, which fails (with
a NegativeArraySizeException) if the specified size is 0 or 1. If
this exception is not properly caught by a (server) application using
AFLfork()interface.cfork()fork()fork()fork()fork()...TCPServerInstrumentedtarget appInstrumentorTarget appFuzzer / C sideJAVA sideKelinci overviewPOSTER: AFL-based Fuzzing for Java with Kelinci
CCS ’17, October 30-November 3, 2017, Dallas, TX, USA
5 CONCLUSIONS
We have presented Kelinci, which, to the best of our knowledge, is
the only currently viable option to apply AFL-style fuzzing to Java
programs. It does not require modifications to the fuzzer, is highly
parallelizable and has discovered a real bug in the popular image
processing library, Apache Commons Imaging.
AFL has proved to be exceptionally successful at discovering se-
curity vulnerabilities. Compared to available tools for Java fuzzing,
such as EvoSuite and Randoop, AFL operates at the system level
while the other tools generate unit tests and is specifically tar-
geted to security vulnerabilities. Kelinci opens up the possibility
of testing Java based applications using this powerful technique.
Future Work. We intend to enable connecting the fuzzer side to
an array of servers running Kelinci instrumented applications. This
would enable running as many instances as desired in parallel in
the cloud (the Java side can already accept requests from multiple
fuzzer clients). It is expected that such parallelization creates a
near-linear increase in performance.
We intend to use Kelinci as a platform for finding time/time
vulnerabilities (notably Denial-of-Service). This research direction
would comprise adding a cost dimension to AFL’s logic for priori-
tizing inputs to fuzz, e.g., inputs that yield long computation times
are more likely to be fuzzed.
Analogous to the work on Mayhem [2] and Driller [9], we
also intend to combine Kelinci with symbolic execution, using
Symbolic PathFinder [8].
REFERENCES
[1] ASM. 2017. http://asm.ow2.org/. (2017). Accessed August 11, 2017.
[2] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley. 2012. Unleashing Mayhem on
Binary Code. In 2012 IEEE Symposium on Security and Privacy. 380–394. https:
//doi.org/10.1109/SP.2012.31
[3] Gordon Fraser and Andrea Arcuri. 2011. Evosuite: automatic test suite generation
for object-oriented software. In Proceedings of the 19th ACM SIGSOFT symposium
and the 13th European conference on Foundations of software engineering. ACM,
416–419.
[4] GCJ – GCC Wiki. 2017. https://gcc.gnu.org/wiki/GCJ. (2017). Accessed August
11, 2017.
[5] Patrice Godefroid, Michael Y. Levin, and David Molnar. 2012. SAGE: Whitebox
Fuzzing for Security Testing. Queue 10, 1, Article 20 (Jan. 2012), 8 pages. https:
//doi.org/10.1145/2090147.2094081
[6] Barton P. Miller, Louis Fredriksen, and Bryan So. 1990. An Empirical Study
of the Reliability of UNIX Utilities. Commun. ACM 33, 12 (Dec. 1990), 32–44.
https://doi.org/10.1145/96267.96279
[7] C. Pacheco, S.K. Lahiri, M.D. Ernst, and T. Ball. 2007. Feedback-directed Ran-
dom Test Generation. In Proceedings of the International Conference on Software
Engineering (ICSE). 75–84. https://doi.org/10.1109/ICSE.2007.37
[8] Corina S. Pasareanu, Willem Visser, David H. Bushnell, Jaco Geldenhuys, Peter C.
Mehlitz, and Neha Rungta. 2013. Symbolic PathFinder: integrating symbolic
execution with model checking for Java bytecode analysis. Autom. Softw. Eng. 20
(2013), 391–425.
[9] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
2016. Driller: Augmenting Fuzzing Through Selective Symbolic Execution.. In
NDSS, Vol. 16. 1–16.
[10] Michael Sutton, Adam Greene, and Pedram Amini. 2007. Fuzzing: brute force
vulnerability discovery. Pearson Education.
[11] Michal Zalewski. 2017. American Fuzzy Lop (AFL). http://lcamtuf.coredump.cx/
afl/. (2017). Accessed August 11, 2017.
[12] Michal Zalewski. 2017. Pulling JPEGs out of thin air. https://lcamtuf.blogspot.
com/2014/11/pulling-jpegs-out-of-thin-air.html. (2017). Accessed August 11,
2017.
Imaging. The
Figure 2: Snapshot of the AFL interface while fuzzing
Apache Commons
fuzzer has been
running for 35 minutes,
in which the target appli-
cation was executed on 20400 different inputs. A to-
tal of 30 program behaviors have been explored, of
which 3 result
in a crash. While the paths leading
to these 3 crashes are different, the cause is the same
(NegativeArraySizeException in the readBytes() method in
org.apache.commons.imaging.common.BinaryFunctions).
the library, a malicious user could cause a crash by sending a faulty
JPEG2.
A snapshot of the AFL interface after running Kelinci on Apache
Commons Imaging for 35 minutes, presenting the results obtained
so far, is shown in Fig. 2.
4 DISCUSSION
The design of the tool with a TCP connection and file IO adds
overhead; furthermore running Java programs is much slower that
running native programs. For example, on Apache Commons Imag-
ing, Kelinci is approximately a factor 500 slower than AFL on C.
Despite this, Kelinci is still useful in practice as evidenced by our
findings which were obtained on a single machine. In addition, the
autonomy of the tool—separating the fuzzer from the application be-
ing fuzzed—enables Kelinci to leverage a distributed infrastructure
that would make it possible to perform scalable, parallel fuzzing; a
powerful advantage of Kelinci. We intend to extend interface.c
to connect to an array of servers, to enable this distributed approach.
Another limitation of Kelinci is that different runs are executed
within the same Java Virtual Machine (JVM) in new threads. This
assumes that the different runs are independent, i.e. they cannot
influence each other. This is not true in general, as, for instance,
different threads could access the same static locations. Even with
only a single executor thread, static locations might not be properly
reset. A more precise implementation would be to create a new
JVM for each run, or to fork the entire JVM before starting the host
program. Analogous to many design decisions in AFL, we take a
best effort approach, where precision is traded against efficiency or,
in this case, simplicity.
2See https://issues.apache.org/jira/browse/IMAGING-203 for the bug report.