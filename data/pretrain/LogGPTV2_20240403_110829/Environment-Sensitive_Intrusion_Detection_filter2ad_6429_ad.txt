gzip
mailx (receive)
Dyck Model
Prior Data-Flow Analysis
New Data-Flow Analysis
Environment-Sensitive
cat
Fig. 10. Precision of program models with increasing sensitivity to data-ﬂows and the environ-
ment. The y-axis indicates precision using the average reachability measure: the average number
of reachable and potentially malicious system calls. Lower numbers indicate greater precision
and less opportunity for attack. All programs have 4 bars; bars that do not show on the graph
have value less than 0.01.
202
J.T. Gifﬁn et al.
puted here by the average reachability measure are not comparable to average branch-
ing factor numbers previously reported for the Dyck model. Our current results may be
compared with previous average branching factor numbers for non-stack-based mod-
els [9, 20].
Second, we added system-call argument constraints to the Dyck model when the con-
straints could have been recovered by a previously reported analysis technique
[9, 10, 20]. Arguments values are recovered only when a value is recovered along all
execution paths reaching a system call. If the value from one execution path cannot be
identiﬁed statically, then the entire argument value is unknown. Furthermore, any data-
ﬂows that cross between a shared object and the program are considered unknown. This
limited data-ﬂow analysis improved model precision from 0% to 20%.
Last, we enabled all static data-ﬂow analyses described in Sect. 4. Our new argument
analysis improved precision from 61% to 100%.
7.3 Effects of Environment Sensitivity
We then made the models environment sensitive. For each program, we manually iden-
tiﬁed execution characteristics that depended upon environment properties. Stated more
formally, we deﬁned the functions f of Deﬁnition 4 that describe data-ﬂows from an en-
vironment property to a program variable used as a system-call argument or as a branch
condition. Table 2 lists the dependencies added to the Dyck model for each program.
The system-call argument dependencies augmented values recovered using the static
data-ﬂow analyses presented in Sect. 4. Immediately before execution, the monitor in-
stantiates the model in the current environment by resolving the dependencies.
Figure 10 reports the average reachability measure for each program’s execution
when monitored using these environment-sensitive models. Model precision has im-
proved from 76% (procmail) to 100% (gzip and cat). Both gzip and cat had
Table 2. Environment dependencies in our test programs. We manually identiﬁed the dependen-
cies via inspection of source code and object code.
mailx
Environment dependencies
Program
procmail • Program branching depends upon “–d” command-line argument.
• Program branching depends upon “–r” command-line argument.
• Filename opened depends upon user’s home directory.
• Program branching depends upon “–T” command-line argument.
• Program branching depends upon “–u” command-line argument.
• Program branching depends upon “–n” command-line argument.
• Filename created depends upon the parameter to the “–T” command-line argument.
• Filename opened depends upon the TMP environment variable.
• Filename opened depends upon the user’s home directory.
• Filename unlinked depends upon the TMP environment variable.
• Argument to chown depends upon the ﬁlename on the command line.
• Argument to chmod depends upon the ﬁlename on the command line.
• Filename unlinked depends upon the ﬁlename on the command line.
• Filename opened depends upon the ﬁlename on the command-line.
gzip
cat
Environment-Sensitive Intrusion Detection
203
d
e
n
i
a
r
t
s
n
o
C
t
n
e
c
r
e
P
100
80
60
40
20
0
procmail
Dyck Model
Prior Data-Flow Analysis
New Data-Flow Analysis
Environment-Sensitive
cat
mailx (send)
gzip
mailx (receive)
Fig. 11. Percentage of potentially malicious system calls identiﬁed by the average reachability
measure made safe by constraints upon their arguments. The Dyck model with no data-ﬂow
analysis constrained no arguments.
average reachability measures of zero, indicating that an adversary had no opportu-
nity to undetectably insert a malicious system call at any point in either process’
execution.
Successful argument recovery constrains system calls so that an attacker can no
longer use the calls in a malicious manner. We evaluated the ability of our techniques
to constrain system calls. Figure 11 shows the percentage of potentially malicious
system calls discovered during computation of the average reachability measure that
were restricted because of system call argument analysis and environment-sensitivity.
In this ﬁgure, higher bars represent the improved constraints upon system calls that pro-
duced the correspondingly lower bars previously shown in Fig. 10. For three programs,
mailx, gzip, and cat, environment-sensitive models constrained 99–100% of the
potentially dangerous calls.
We expect environment-sensitive program models to affect the performance of run-
time execution monitoring. The monitor must both update the program model at load
time to remove paths unreachable in the current environment and enforce context-
sensitive argument restrictions at every system call. Table 3 shows the execution time
overhead arising from the model update and the more precise enforcement. These over-
heads are modest: about one-half second for the short-lived processes procmail and
mailx and two seconds for the longer-running cat. Although the overheads for
proc- mail and mailx are high when viewed as a percentage of the original run-
time, this occurs due to the short lifetime of these processes and the monitor’s upfront
ﬁxed cost of pruning unreachable paths. Longer-lived processes such as cat give a
better indication of relative cost: here, 2.8%.
Further, improved argument recovery may increase the size of program models as the
model must contain the additional constraints. For all programs, environment-sensitive
models required 16 KB (2 pages) more memory than a Dyck model with no argument
recovery or environment-sensitivity.
We believe that these results strongly endorse our proposed environment-sensitive
intrusion detection. The precision measurements demonstrate that with the right analy-
sis tools, program execution can be safely constrained to the point that attackers have
little ability to undetectably execute attacks against the operating system via a vulner-
able program. We certainly do not constrain all execution: for example, our models do
204
J.T. Gifﬁn et al.
Table 3. Performance overheads due to execution enforcement using environment-sensitive mod-
els. Model update is the one-time cost of pruning from the model execution paths not allowed in
the current environment. The enforcement times include both program execution and veriﬁcation
of each system call executed against the program’s model.
Program
procmail
mailx (send)
mailx (receive)
gzip
cat
No model update
No enforcement Model update Enforcement
0.67 s
0.16 s
0.14 s
6.11 s
58.06 s
0.55 s
0.08 s
0.07 s
6.26 s
56.47 s
Environment-sensitive
0.41 s
0.38 s
0.38 s
0.00 s
0.00 s
Total
1.08 s
0.54 s
0.52 s
6.11 s
58.06 s
Overhead
0.53 s
0.46 s
0.45 s
0.00 s
1.59 s
not enforce iteration counts on loops or verify data read or written to ﬁles. However,
we strongly limit process execution that can adversely affect the underlying operating
system or other processes executing simultaneously.
7.4 Evasion Attacks
Intrusion detection systems that are not environment-sensitive are susceptible to evasion
attacks. These attacks mimic correct process execution for some environment [21, 18],
just not the current environment. To demonstrate the effectiveness of environment sen-
sitivity in defense against such attacks, we designed an attack against mailx that
overwrites command-line arguments stored in the process’ address space to change
the process’ execution. Although the original command line passed to the program di-
rected it to check for new mail and exit, our attack changes the environment data so that
mailx instead reads sensitive information and sends unwanted email.
Our attack makes use of a buffer overrun vulnerability when mailx unsafely copies
the string value of the HOME environment variable. We assume that the attacker can
alter the HOME variable, possibly before the monitor resolves environment dependen-
cies. The attacker changes the variable HOME to contain the code they wish to
inject into mailx. The exploit follows the typical “nop sled + payload + address”
pattern [12].
1. The ﬁrst part consists of a sequence of nops (a “sled”) that exceeds the static buffer
size, followed by an instruction sequence to obtain the current address on the stack.
2. The payload then rewrites the command-line arguments in memory. The change
to the command-line arguments alters execution so that the process will perform a
different operation, here sending spam and leaking information.
3. The return address at the end of the payload is selected to reenter getopt so that
the new command-line arguments update appropriate state variables. If necessary,
an evasive exploit can alter its reentry point so that no additional system calls or
stack frames occur between the overﬂow and the resumed ﬂow. In our attack, reen-
tering at getopt was sufﬁcient.
We implemented the mailx exploit, loaded it via HOME, and caused the program
to read arbitrary ﬁles and send unwanted email. Since the exploit did not introduce
Environment-Sensitive Intrusion Detection
205
additional system calls and reentered the original execution path, the attack perfectly
mimicked normal execution for some environment, with one exception caused by the
register windows used by the SPARC architecture. To effectively manipulate the return
address, exploit code must return from a callee function after corrupting the stack [12].
This “double return” makes exploit detection slightly easier on SPARC machines, be-
cause an exploit that attempts to reenter a function alters return addresses in a de-
tectable way. This attack limitation is not present on the more common x86
architecture.
Environment-sensitive models can detect these evasion attacks. The monitor resolves
environment dependencies before process execution begins, and hence before the attack
alters the environment data. In this example, the execution paths that mailx followed
subsequent to the attack, reading sensitive ﬁles and sending email, do not match the
expected paths given the command-line input.
8 Conclusions
Program models used for model-based intrusion detection can beneﬁt from our new
analyses. Our static argument recovery reduces attack opportunities signiﬁcantly further
than prior argument analysis approaches. Adding environment sensitivity continues to
strengthen program models by adding environment features to the models. The useful-
ness of these model-construction techniques is shown in the results, where the models
could severely constrain several test programs’ execution.
Acknowledgments
We thank the anonymous reviewers and the members of the WiSA project at Wisconsin
for their helpful comments that improved the quality of the paper.
Jonathon T. Gifﬁn was partially supported by a Cisco Systems Distinguished Gradu-
ate Fellowship. Somesh Jha was partially supported by NSF Career grant CNS-0448476.
This work was supported in part by Ofﬁce of Naval Research grant N00014-01-1-0708
and NSF grant CCR-0133629. The U.S. Government is authorized to reproduce and
distribute reprints for governmental purposes, notwithstanding any copyright notices
afﬁxed hereon. The views and conclusions contained herein are those of the authors
and should not be interpreted as necessarily representing the ofﬁcial policies or en-
dorsements, either expressed or implied, of the above government agencies or the U.S.
Government.
References
1. R. Chinchani, A. Iyer, B. Jayaraman, and S. Upadhyaya. ARCHERR: Runtime environment
In 9th European Symposium on Research in Computer Security,
driven program safety.
Sophia Antipolis, France, Sept. 2004.
2. E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction
reﬁnement. In Computer Aided Veriﬁcation, Chicago, IL, July 2000.
206
J.T. Gifﬁn et al.
3. H. Debar, M. Dacier, and A. Wespi. Towards a taxonomy of intrusion-detection systems.
Computer Networks, 31:805–822, 1999.
4. J. Esparza, D. Hansel, P. Rossmanith, and S. Schwoon. Efﬁcient algorithms for model check-
ing pushdown systems. In Computer Aided Veriﬁcation, Chicago, IL, July 2000.
5. H. H. Feng, J. T. Gifﬁn, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity in
static analysis for intrusion detection. In IEEE Symposium on Security and Privacy, Oakland,
CA, May 2004.
6. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection using call
stack information. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2003.
7. L. Fix and F. B. Schneider. Reasoning about programs by exploiting the environment. In 21st
International Colloquium on Automata, Languages, and Programming, Jerusalem, Israel,
July 1994.
8. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly detection.
In 13th USENIX Security Symposium, San Diego, CA, Aug. 2004.
9. J. T. Gifﬁn, S. Jha, and B. P. Miller. Detecting manipulated remote call streams. In 11th
USENIX Security Symposium, San Francisco, CA, Aug. 2002.
10. J. T. Gifﬁn, S. Jha, and B. P. Miller. Efﬁcient context-sensitive intrusion detection. In 11th
Network and Distributed Systems Security Symposium, San Diego, CA, Feb. 2004.
11. httpd. Solaris manual pages, chapter 8, Feb. 1997.
12. J. Koziol, D. Litchﬁeld, D. Aitel, C. Anley, S. Eren, N. Mehta, and R. Hassell. The Shell-
coder’s Handbook: Discovering and Exploiting Security Holes. Wiley, 2003.
13. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous system call
arguments. In 8th European Symposium on Research in Computer Security, pages 326–343,
Gjøvik, Norway, Oct. 2003.
14. L.-c. Lam and T.-c. Chiueh. Automatic extraction of accurate application-speciﬁc sandbox-
ing policy. In Recent Advances in Intrusion Detection, Sophia Antipolis, France, Sept. 2004.
15. S. S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann Pub-
lishers, San Francisco, CA, 1997.
16. R. Sekar, V. N. Venkatakrishnan, S. Basu, S. Bhatkar, and D. C. DuVarney. Model-carrying
code: A practical approach for safe execution of untrusted applications. In ACM Symposium
on Operating System Principles, Bolton Landing, NY, Oct. 2003.
17. M. Sharir and A. Pnueli. Two approaches to interprocedural data ﬂow analysis.
In S. S.
Muchnick and N. D. Jones, editors, Program Flow Analysis: Theory and Applications, chap-
ter 7, pages 189–233. Prentice-Hall, 1981.
18. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal to the nor-
mal and beyond. In 5th International Workshop on Information Hiding, Noordwijkerhout,
Netherlands, October 2002.
19. U.S. Department of Energy Computer Incident Advisory Capability. M-026: OpenSSH use-
login privilege elevation vulnerability, Dec. 2001.
20. D. Wagner and D. Dean.
Intrusion detection via static analysis.
In IEEE Symposium on
Security and Privacy, Oakland, CA, May 2001.
21. D. Wagner and P. Soto. Mimicry attacks on host based intrusion detection systems. In 9th
ACM Conference on Computer and Communications Security, Washington, DC, Nov. 2002.
22. D. A. Wagner. Static Analysis and Computer Security: New Techniques for Software Assur-
ance. PhD dissertation, University of California at Berkeley, Fall 2000.
23. M. Yannakakis. Graph-theoretic methods in database theory. In ACM Symposium on Princi-
ples of Database Systems, Nashville, TN, Apr. 1990.