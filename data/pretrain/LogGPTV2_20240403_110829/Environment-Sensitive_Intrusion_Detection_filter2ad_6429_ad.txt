### 1. Introduction

This section evaluates the precision and performance of our environment-sensitive intrusion detection system. We use the Dyck model as a baseline and compare it with prior data-flow analysis, new data-flow analysis, and environment-sensitive models. The precision is measured using the average reachability measure, which indicates the number of potentially malicious system calls that an adversary could insert undetected.

### 2. Precision of Program Models

**Figure 10** shows the precision of different program models for `gzip`, `mailx (receive)`, `Dyck Model`, `Prior Data-Flow Analysis`, `New Data-Flow Analysis`, and `Environment-Sensitive` models. The y-axis represents the average reachability measure, indicating the number of reachable and potentially malicious system calls. Lower values on the y-axis indicate higher precision and fewer opportunities for attacks.

![Precision of program models](fig_10.png)

All programs have four bars, and any bars not visible on the graph have a value less than 0.01. For example, `gzip` and `cat` show zero reachability, indicating that no potentially malicious system calls can be inserted undetected.

### 3. Comparison with Previous Results

The results computed here using the average reachability measure are not directly comparable to the average branching factor numbers previously reported for the Dyck model. Our current results can be compared with previous average branching factor numbers for non-stack-based models [9, 20].

### 4. System-Call Argument Constraints

We enhanced the Dyck model by adding system-call argument constraints. These constraints were added when the values could be recovered by previously reported analysis techniques [9, 10, 20]. Argument values are considered known only if they are recovered along all execution paths reaching a system call. If the value from any path cannot be identified statically, the entire argument value is marked as unknown. Additionally, data flows between shared objects and the program are also considered unknown. This limited data-flow analysis improved model precision from 0% to 20%.

### 5. Enhanced Data-Flow Analysis

By enabling all static data-flow analyses described in Section 4, our new argument analysis further improved precision from 61% to 100%.

### 6. Environment Sensitivity

To make the models environment-sensitive, we manually identified execution characteristics that depend on environment properties. Specifically, we defined functions that describe data flows from an environment property to a program variable used as a system-call argument or a branch condition. **Table 2** lists the dependencies added to the Dyck model for each program.

| Program | Environment Dependencies |
|---------|--------------------------|
| mailx   | - Program branching depends on command-line arguments: “–d”, “–r”, “–T”, “–u”, “–n”<br> - Filenames opened/created/unlinked depend on user’s home directory, TMP environment variable, and command-line parameters. |
| procmail | - Program branching depends on command-line arguments: “–d”, “–r”, “–T”, “–u”, “–n”<br> - Filenames opened/created/unlinked depend on user’s home directory, TMP environment variable, and command-line parameters. |

Immediately before execution, the monitor instantiates the model in the current environment by resolving these dependencies.

**Figure 10** reports the average reachability measure for each program's execution when monitored using these environment-sensitive models. Model precision has improved significantly, with `gzip` and `cat` showing 100% precision.

### 7. Argument Recovery and System Call Constraints

Successful argument recovery constrains system calls, preventing attackers from using them maliciously. **Figure 11** shows the percentage of potentially malicious system calls that were constrained due to system call argument analysis and environment sensitivity.

![Percentage of constrained system calls](fig_11.png)

For `mailx`, `gzip`, and `cat`, environment-sensitive models constrained 99–100% of the potentially dangerous calls.

### 8. Performance Overheads

Environment-sensitive program models affect the performance of runtime execution monitoring. The monitor must update the program model at load time and enforce context-sensitive argument restrictions at every system call. **Table 3** shows the execution time overheads for these operations.

| Program | No Model Update | No Enforcement | Model Update | Enforcement | Total | Overhead |
|---------|-----------------|-----------------|--------------|-------------|-------|----------|
| procmail | 0.67 s          | 0.16 s         | 0.14 s       | 6.11 s      | 1.08 s | 0.53 s   |
| mailx (send) | 0.55 s        | 0.08 s         | 0.07 s       | 6.26 s      | 0.54 s | 0.46 s   |
| mailx (receive) | 0.41 s     | 0.38 s         | 0.38 s       | 0.00 s      | 0.52 s | 0.45 s   |
| gzip    | 0.00 s          | 0.00 s         | 0.00 s       | 0.00 s      | 0.00 s | 0.00 s   |
| cat     | 0.00 s          | 0.00 s         | 0.00 s       | 0.00 s      | 1.59 s | 1.59 s   |

The overheads are modest, with longer-lived processes like `cat` showing a relative cost of 2.8%.

### 9. Memory Usage

Improved argument recovery may increase the size of program models. For all programs, environment-sensitive models required 16 KB (2 pages) more memory than a Dyck model with no argument recovery or environment sensitivity.

### 10. Evasion Attacks

Intrusion detection systems that are not environment-sensitive are susceptible to evasion attacks, where an attacker mimics correct process execution for some environment but not the current one. To demonstrate the effectiveness of environment sensitivity, we designed an attack against `mailx` that overwrites command-line arguments stored in the process' address space, changing the process' execution.

Our attack exploits a buffer overrun vulnerability in `mailx` when it unsafely copies the string value of the `HOME` environment variable. The attack follows the typical "nop sled + payload + address" pattern:

1. A sequence of nops (a "sled") exceeds the static buffer size, followed by an instruction sequence to obtain the current address on the stack.
2. The payload rewrites the command-line arguments in memory, altering execution to perform different operations, such as sending spam and leaking information.
3. The return address at the end of the payload reenters `getopt`, updating state variables.

We implemented this exploit and caused `mailx` to read arbitrary files and send unwanted email. Since the exploit did not introduce additional system calls and reentered the original execution path, the attack perfectly mimicked normal execution for some environment, except for a detectable change in return addresses on SPARC architecture.

Environment-sensitive models can detect these evasion attacks because the monitor resolves environment dependencies before process execution begins, preventing the attack from altering the environment data. In this example, the execution paths followed by `mailx` after the attack, such as reading sensitive files and sending email, do not match the expected paths given the command-line input.

### 11. Conclusions

Our new analyses for constructing program models for intrusion detection significantly reduce attack opportunities. Adding environment sensitivity further strengthens these models by incorporating environment features. The results show that these models can severely constrain the execution of several test programs, demonstrating the usefulness of our model-construction techniques.

### 12. Acknowledgments

We thank the anonymous reviewers and the members of the WiSA project at Wisconsin for their helpful comments. Jonathon T. Giffin was partially supported by a Cisco Systems Distinguished Graduate Fellowship. Somesh Jha was partially supported by NSF Career grant CNS-0448476. This work was supported in part by Office of Naval Research grant N00014-01-1-0708 and NSF grant CCR-0133629.

### 13. References

1. R. Chinchani, A. Iyer, B. Jayaraman, and S. Upadhyaya. ARCHERR: Runtime environment driven program safety. In 9th European Symposium on Research in Computer Security, Sophia Antipolis, France, Sept. 2004.
2. E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction refinement. In Computer Aided Verification, Chicago, IL, July 2000.
3. H. Debar, M. Dacier, and A. Wespi. Towards a taxonomy of intrusion-detection systems. Computer Networks, 31:805–822, 1999.
4. J. Esparza, D. Hansel, P. Rossmanith, and S. Schwoon. Efficient algorithms for model checking pushdown systems. In Computer Aided Verification, Chicago, IL, July 2000.
5. H. H. Feng, J. T. Giffin, Y. Huang, S. Jha, W. Lee, and B. P. Miller. Formalizing sensitivity in static analysis for intrusion detection. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2004.
6. H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and W. Gong. Anomaly detection using call stack information. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2003.
7. L. Fix and F. B. Schneider. Reasoning about programs by exploiting the environment. In 21st International Colloquium on Automata, Languages, and Programming, Jerusalem, Israel, July 1994.
8. D. Gao, M. K. Reiter, and D. Song. On gray-box program tracking for anomaly detection. In 13th USENIX Security Symposium, San Diego, CA, Aug. 2004.
9. J. T. Giffin, S. Jha, and B. P. Miller. Detecting manipulated remote call streams. In 11th USENIX Security Symposium, San Francisco, CA, Aug. 2002.
10. J. T. Giffin, S. Jha, and B. P. Miller. Efficient context-sensitive intrusion detection. In 11th Network and Distributed Systems Security Symposium, San Diego, CA, Feb. 2004.
11. httpd. Solaris manual pages, chapter 8, Feb. 1997.
12. J. Koziol, D. Litchfield, D. Aitel, C. Anley, S. Eren, N. Mehta, and R. Hassell. The Shellcoder’s Handbook: Discovering and Exploiting Security Holes. Wiley, 2003.
13. C. Kruegel, D. Mutz, F. Valeur, and G. Vigna. On the detection of anomalous system call arguments. In 8th European Symposium on Research in Computer Security, pages 326–343, Gjøvik, Norway, Oct. 2003.
14. L.-c. Lam and T.-c. Chiueh. Automatic extraction of accurate application-specific sandboxing policy. In Recent Advances in Intrusion Detection, Sophia Antipolis, France, Sept. 2004.
15. S. S. Muchnick. Advanced Compiler Design and Implementation. Morgan Kaufmann Publishers, San Francisco, CA, 1997.
16. R. Sekar, V. N. Venkatakrishnan, S. Basu, S. Bhatkar, and D. C. DuVarney. Model-carrying code: A practical approach for safe execution of untrusted applications. In ACM Symposium on Operating System Principles, Bolton Landing, NY, Oct. 2003.
17. M. Sharir and A. Pnueli. Two approaches to interprocedural data flow analysis. In S. S. Muchnick and N. D. Jones, editors, Program Flow Analysis: Theory and Applications, chapter 7, pages 189–233. Prentice-Hall, 1981.
18. K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions: From the abnormal to the normal and beyond. In 5th International Workshop on Information Hiding, Noordwijkerhout, Netherlands, October 2002.
19. U.S. Department of Energy Computer Incident Advisory Capability. M-026: OpenSSH use-login privilege elevation vulnerability, Dec. 2001.
20. D. Wagner and D. Dean. Intrusion detection via static analysis. In IEEE Symposium on Security and Privacy, Oakland, CA, May 2001.
21. D. Wagner and P. Soto. Mimicry attacks on host based intrusion detection systems. In 9th ACM Conference on Computer and Communications Security, Washington, DC, Nov. 2002.
22. D. A. Wagner. Static Analysis and Computer Security: New Techniques for Software Assurance. PhD dissertation, University of California at Berkeley, Fall 2000.
23. M. Yannakakis. Graph-theoretic methods in database theory. In ACM Symposium on Principles of Database Systems, Nashville, TN, Apr. 1990.