### User Profile-Based Anomaly Detection: Fighting Malicious Insider Threats in Office 365

**Lei He**  
Principal Engineering Manager, Microsoft Corporation  
May 30, 2019

#### Context: Office 365 Security Requirements
- **Customer Lockbox Onboarding**: Mandatory for enterprise services accessing customer data.
- **Access Control**: Corporate identities cannot be used for deployment or access. Two-factor authentication (2FA) is required for access.
- **Operational Clearance Expectations (OCEs)**: Must meet clearance requirements.
- **Isolation**: Separate capacity and control planes.
- **Zero Standing Access and Least Privilege Access**: Ensure minimal access rights.
- **Customer Lockbox & Bring Your Own Key (BYOK)**: Enhanced security features.
- **Event Tracing for Windows (ETW)-based Telemetry**: Detailed raw telemetry with the ability to add new telemetry within one day.
- **Centralized Processing**: Alerts raised within 15 minutes for security issues.
- **Simulated Attacks**: At least one attack per day to validate monitoring and response.
- **Security Response Workflows**: Triggered within 15 minutes, with the ability to implement new workflows within one day.
- **Secrets Management**: All secrets must be stored in a secure container, never leave the boundary, and be rolled immediately upon exposure.
- **Data Trustee Control**: Full control of secrets in a sovereign environment.
- **Daily Scans**: All production endpoints are scanned daily.
- **Vulnerability Patching**: Medium and higher-rated vulnerabilities should be patched or exempted.
- **Web App Scans**: Conducted monthly.
- **Central Reporting and Tracking**: Centralized system for reporting and tracking.

#### Overview
- **Problem**: Compromised or disgruntled malicious insiders remain a top threat. Supervised machine learning (ML) detections are trained to detect known patterns but need coverage for unknown patterns.
- **Solution**: User profile-based detection to flag abnormal activities. For Office 365 Data Center security, users are primarily DevOps personnel. This approach can be generalized to other entity profiles.

#### O365 Data Center Monitoring
- **Automated Near Real-Time Multi-Tier Detection and Response**: Evaluates up to 100,000 machines and 1,000 users, with near real-time (NRT) multi-tier processing on Spark, generating alerts within 15 minutes.
- **Analyst Tools and Dashboards**: Interactive tools for viewing results in near real-time.
- **Alerting and Automation**: 24/7 paging alerting and automated response.

#### Model Feature Selection
- **Observation**: DevOps activities exhibit specific patterns.
  - **Logon Activities**:
    - Login location
    - Login time
    - Login target
  - **Just-In-Time Elevations**:
    - Elevation role requested
    - Approval status
  - **Actions**:
    - Workflow performed
    - Processes started
    - Detections triggered
- **Features**:
  - Machines logged into
  - Machine roles
  - Capacity unit scope
  - IPs logged from
  - IPs connected to
  - Other atomic detections triggered
  - Roles elevated to
  - Elevation purpose
  - Approver
  - Time of day
  - Processes and workflows run

#### The Model
1. **Historical Profile Computation**: Compute a complete historical profile for every user, where each feature is a list of {Value: Occurrence}.
2. **Real-Time Evaluation**: Every 2 minutes, evaluate activities from the past 6-hour user sessions.
3. **Session Comparison**: Compare each current session with the user’s historical profile.
   - **Feature Similarity Score**: Calculated based on the occurrence of values in the session. Higher historical occurrences indicate more normal activity.
   - **Session Anomaly Score**: Generated from the similarity scores of multiple features.
4. **Test Dataset Curation**: Curate a test dataset from historical positive events to evaluate model performance.
5. **Alert Threshold Setting**: Set a session score threshold for alerting, with an alert tolerance of 5 per week.

#### Model Tuning Workflow
- **Malicious ≠ Anomalous**: Differentiate between malicious and anomalous activities.
- **Tuning Process**:
  - **Corroboration**: Verify if the alert was corroborated.
  - **User Notification**: Email the user in the alert.
  - **False Positive Labeling**: Improve the model by labeling false positives.
  - **Abnormal Activity Verification**: Label true positives.
- **Model Tuning Patterns**:
  - **New Team Member**: Set a minimum threshold for the volume of activities.
  - **Sparse Features**: Set a minimum threshold of valid features.
  - **Double Counting**: Remove auto-generated activities.
  - **Changing Teams**: Use team profiles.
  - **Renamed Commands**: Case-insensitive comparison.
  - **High Entropy Features**: Replace target machine names or IPs with {Capacity Unit, Capacity Type}. Downgrade the weight of user source IP and free text features (e.g., elevation reason).

#### Model Performance
- **Success Metrics**:
  - **Paging Volume**: Average of ~5 paging alerts per week since late 2018.
  - **Precision**: ~90% true positives (Last Month: 16/18).
- **Types of True Positives**:
  - Penetration testing
  - One-off incidents (e.g., "Break Glass" or audit)
  - Operational process violations
  - DevOps poor practices
  - DevOps one-off testing or experimenting

#### Call to Action
- **Apply Profile-Based Anomaly Detection for Defense in Depth**:
  - Start with quality data.
  - Identify true positives.
  - Conduct offline analysis before online implementation.
  - Continuously tune the model through a feedback loop.
  - Ensure the model is explainable.
  - Generate actionable alerts.

#### Q & A
- **Contact Information**: [www.linkedin.com/in/lei-he-security](https://www.linkedin.com/in/lei-he-security)
- **Email**: Lei He

This optimized version of your text is more structured, clear, and professional, making it easier to read and understand.