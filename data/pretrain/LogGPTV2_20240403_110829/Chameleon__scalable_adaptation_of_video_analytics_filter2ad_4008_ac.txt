two cameras can share the set of best configurations, but
not with the third camera. We will describe our data-driven
approach for automatically grouping similar cameras in §5.3.
4.3 Independence of configuration knobs
To further reduce the cost of searching the exponential con-
figuration space, we observe that, typically, individual knobs
have independent impact on accuracy. For example, consider
a pipeline with the resolution and frame rate knobs, taking
values (480p,720p,960p) and (1, 10, 30), respectively. Recall
from §3 that we measure the accuracy of configurations rel-
ative to a golden configuration, which in this case is (960p,
30). We observe empirically that in most cases the accuracy
 0 0.2 0.4 0.6 0.8 1 100 1000 10000CDFPersistence (frames)30 fps, 800p, ResNet10130 fps, 1200p, ResNet50Chameleon: Scalable Adaptation of Video Analytics
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Figure 8: Spatially similar cameras tend to have similar
resource-accuracy profiles. By varying frame rate, Camera
#1 and Camera #2 share a similar resource-accuracy profile,
which is different to Camera #3.
of configuration (480p, 30) relative to (960p, 30) is similar in
value to the accuracy of (480p, 10) relative to (960p, 10).
This has two important implications. First, it lets us tune
the resolution knob independent of the frame rate; this prunes
a large part of the configuration space. Second, it lets us
estimate a configuration’s accuracy by combining its per-
knob accuracies; in particular, we can do this without running
the expensive golden configuration.
Further, the relative ordering between the configurations
on their resource demand will be unaltered between using
frame rates 30 and 10. That is, if the resource demand of
(480p, 30) is less than that of (720p, 30), then this ordering will
continue to be true with the resource demand of (480p, 10)
being less than (720p, 10). In our setting, the configuration
knobs have monotonic impact on cost, i.e., increasing the
value of a knob while holding the other knobs fixed increases
the resource demand of the configuration.
Since our objective is to pick the cheapest configuration
that meets the desired accuracy threshold, the above obser-
vations allow us to significantly reduce the profiling costs.
5 CHAMELEON TECHNIQUES
We build upon the insights in §4 to present the techniques in
our solution, Chameleon, to reduce the cost of profiling for
online adaptation of configurations. It should be noted that
Chameleon only represents one instance of a concrete design
inspired by the insights in §4, which are of independent value.
5.1 Overview
Chameleon’s solution relies on periodically re-profiling the
video pipeline. Video workloads are typically non-stationary,
in that both the characteristics of the video as well as the
pipeline tend to change over time. This makes traditional ap-
proaches (e.g., Bayesian optimization, multi-armed bandits)
either too expensive for real-time adaptation or unsuited
because they assume a stationary environment (despite their
successful use in recent systems [12, 19, 31]).
Chameleon uses a solution inspired by greedy hill climbing
that exploits the independence of NN configuration knobs
to reduce the search space from exponential to linear (§5.4).
Using this profiling method, it leverages the temporal per-
sistence of configurations to learn their properties over time
Figure 9: The horizontal lines represent video feeds generated
by three cameras over time (one leader, two followers). The solid
vertical lines delineate profiling windows and the dashed lines
delineate segments. The blue circles represent profiling (§5.4);
bigger dark circles represent full profiling of the configuration
space, which yields the top-k most promising configurations
from the leader. The red arrows show the propagation of the
top-k configs both temporally (to segments on the same camera,
§5.2), and spatially (to segments on the follower cameras, §5.3).
(§5.2), and amortizes the cost of profiling across multiple
cameras by leveraging cross-video similarities (§5.3).
Figure 9 illustrates how different Chameleon techniques
work together. A “leader” video is profiled at the start of a
“profiling window” and a set of good (top-k) configurations
is found. This set is shared among “follower” videos who
are similar to the leader. Both the leader and followers then
restrict their search to this top-k set when choosing configu-
rations over time, until the start of the next profiling window
(when a new top-k set will be obtained from the leader). All
of these terms are defined in the subsequent sections.
5.2 Temporal incremental updates
Chameleon periodically and profiles the video pipeline using
an interval we refer to as the profiling window. Each profiling
window is split into w smaller segments, each of which is a
contiguous set of frames spanning a T -second interval (by
default, T = 4). We leverage temporal persistence (§4.1) by
not profiling all the segments in a profiling window. Instead,
we re-profile the configuration space on only the first seg-
ment of the profiling window (see §5.4 for details). We use
the results from this first segment to obtain a short ranked
list of the top-k most promising configurations (i.e., the least
expensive k configurations that meet the accuracy thresh-
old), and then profile only the top-k configurations on the
remaining segments to find the best one. When profiling a
configuration on a segment, we do not evaluate every frame
of the segment. Instead, we profile the first t seconds (by de-
fault, t = 1) and use the best configuration for the remaining
T − t seconds.
Algorithm 1 lists the steps taken in each profiling win-
dow given a video stream i. For the ith video, we use Si, j
to denote the jth segment and Wi,l to denote the lth pro-
filing window, which is a list of w consecutive segments
(Si,wl , . . . , Si,w(l +1)−1). Line 3 in the algorithm picks the top-
k configurations from the first segment, and lines 5-7 use
the top-k set to profile the remaining segments. Both these
steps use the Profile method, which we will cover in §5.4.
 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.6 0.7 0.8 0.9 1Avg GPU time per frame (sec)Accruacy (F1 Score)Camera #1Camera #2Camera #3leaderfollower 1follower 2profiling window top-kconfigssegments 1 -4……SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
J. Jiang et al.
Input: Wi,l: the lth profiling window of the ith video,
which consist of w segments Si,wl , . . . , Si,wl +l−1;
C: set of all configs under consideration
Output: A map from each segment Si, j in the profiling
window to the chosen config ˆci, j.
3
[0])
promisinд
l
promisinд
l
promisinд
l
return Result
← Profile(Si,wl , C, k)
1 Function UpdateWindowT(Wi,l , C):
2
ˆci, j ←Profile (Si, j , C
Result[si, j] ← ˆci, j
Result ← ∅
C
Result .add(ˆci,wl , C
foreach j = wl + 1, . . . , wl + w − 1 do
, 1)[0]
4
5
6
7
8
Algorithm 1: Temporal updates take promising configu-
rations from the first segment of a profiling window and
apply them to subsequent segments in the window.
We have also observed in practice that it is beneficial to
include not only the current set of top-k configurations but
also those from the past few profiling windows. So we can
sample from ∪l ∈W C
to obtain the k configurations,
where W is the set of profiling windows in the past. This
extension is currently not used in our experiments.
5.3 Cross-video inference
The ability to take good configurations profiled on one video
stream and apply them to other video streams offers more
potential savings (§4.2).
Cross-video profiling: In each profiling window, Chameleon
leverages spatial similarities in NN performance to amor-
tize the cost of profiling across multiple video feeds. Let
P be the cost of profiling a video segment on the full con-
figuration space (C), p ≪ P the cost of profiling only the
top-k most promising configurations from a reference video
(Cpromisinд), and suppose there are V videos in total. If the
videos need to be profiled separately, the cost of profiling is
P · V in every profiling window. On the other hand, if the
videos show spatial similarity, the cost reduces to P +p(V −1),
a savings that grows with the number of videos V .
promisinд
l
Algorithm 2 takes a group of related video streams G as
input, and only profiles the first video (referred to as the
“leader”) on the full configuration space (lines 3-5). We dis-
cuss how we group the set of related videos shortly. The call
to UpdateWindowT assigns a configuration to each segment
of the window using the temporal update technique from
§5.2. For all remaining videos (the “followers”), the call to
UpdateWindowT only receives the most promising configura-
tions from the first video as input (line 7), thus significantly
reducing the search space.
Grouping related videos: We group video feeds by exploit-
ing the correlation between configurations on the accuracy
of their output on different feeds; these accuracy values are
Input: G: a list of related video feeds, C: set of configs
under consideration
Output: Configuration ˆci, j for each segment Si, j.
1 Function UpdateWindowS(l, G, C):
2
3
4
Result ← ∅
leader ← G[0]
Result .add(UpdateWindowT(Wi,l , C))
C
foreach i ∈ G \ {leader} do
promisinд
l
← (returned by Profile in line 4)
promisinд
l
return Result
Result .add(UpdateWindowT(Wi,l , C
5
6
7
8
Algorithm 2: Spatial updates take promising configura-
tions profiled from one video and apply them to all other
videos in the same related group.
comparable across feeds since they are running the same
pipeline. The grouping of video feeds is offline and done
relatively infrequently (e.g., once every few hours).
))
We use the following simple grouping algorithm. The al-
gorithm starts with a randomly chosen configuration and
profiles all videos on it, then uses the accuracy results to
create an initial grouping using a simplified version of k-
means—essentially, sort the accuracy values and bound the
deviation from the minimum of a group. We repeat this pro-
cess by using another randomly chosen configuration to
subdivide the groups created by the previous round, and so
on. This greedy refinement stops when enough configura-
tions have been tested or the groups become too small.
While the above grouping algorithm works well in our
evaluations, we realize that it represents a very simple, first
stab at the problem, and there could be value in adding more
sophistication. For example, the algorithm could be aug-
mented with information on camera specifications and object
density. We defer these and other improvements to future
work, while currently choosing to focus on the feasibility
and potential savings of grouping videos.
5.4 Profiling a video segment
Algorithm 1 reduces the profiling cost from once per video
segment per video feed to once per profiling window per
video feed. Algorithm 2 further reduces the profiling cost
from once per profiling window per video feed to once per
profiling window per video group. Although these savings
are substantial, even profiling once can be very costly. This
is because the configuration space is multi-dimensional, con-
sisting of several knobs each taking one of several values,
yielding exponentially many possible configurations. Assum-
ing m knobs and (for simplicity) n values for each knob, an
exhaustive search would involve O(nm) configurations. In-
stead, Chameleon leverages the empirically-driven assump-
tion from §4.3 that the knobs of our NN configurations can
be treated independently. This allow us to use a variant of
Chameleon: Scalable Adaptation of Video Analytics
Input: S: a segment; C: set of configs under
consideration, k: # of top configs to output.
Output: A list of the top-k best configurations in
descending order.
1 Function Profile(S, C, k):
KnobV alueToScore ← ∅
2
/* Profile one knob at a time
foreach Knob r do
foreach vr ∈ Vr do
3
4
*/
1, . . . , v∗
comparing c(vr) against c∗
/* Set knob r to vr while setting others
to the golden value v∗
*/
r
c(vr) ← (v∗
n)
1, . . . , vr , . . . , v∗
/* c∗ is Golden config
c∗ ← (v∗
n)
r , . . . , v∗
/* Calculate F1 metric of c(vr) by
f ← Eval_F1(S, c(vr), c∗))
KnobV alueToScore[vr] ← f
r KnobV alueToScore[vr] ≥ α′}
Sort AccurateCon f iдs by c’s resource consumption
AccurateCon f iдs ← top k elements in
AccurateCon f iдs
return AccurateCon f iдs
AccurateCon f iдs ← {c ∈
C|
*/
*/
5