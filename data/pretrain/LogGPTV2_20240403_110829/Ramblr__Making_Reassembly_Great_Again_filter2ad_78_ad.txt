Conceptually, a pointer is a reference to a memory location.
At some point in the life of the program, it will be dereferenced
so that value located at the memory location it references
is retrieved, or used as a jump target. If a pointer is never
dereferenced or used as a jump target anywhere in the binary,
it is the same as an integer. For the purpose of reassembling,
Listing 9: The assembly manifest of Listing 8, compiled by
gcc with -O1.
The instruction at offset 0x8048557 increments the dword
[0x8049f30+ebx×4] by 1, where ebx holds the option letter
(either “A” or “B”) from user input. Due to optimizations, the
pointer 0x8049f30 comes from address of the counters
array (0x804a034), minus 4× 0x41, where 0x41 is the ASCII
9
code of character “A”. Since the integer value of this pointer
does not fall into any memory region deﬁned in this binary, it
will be viewed as non-symbolizable by the original approach,
and consequently the reassembled binary is functionally bro-
ken. The problem can be even worse: a symbolizable integer
having, due to optimizations, a value inside the .rodata
section might actually be pointing to the .bss section when
being dereferenced. Such cases, which cause extremely hard-
to-detect symbolization mis-classiﬁcations, are not rare in
binaries compiled with optimization enabled.
To tackle this problem, we adopt a different approach.
Instead of checking if the integer falls into any predeﬁned
memory regions of the binary, we enlarge each memory region
by some amount, both in the beginning and the end, and check
if the integer falls into any of the enlarged memory regions.
This is used as a pre-ﬁlter to identify potential cases of mis-
classiﬁcation due to constant folding. Empirically, we enlarge
each memory region by 4KB.
this point, since the pointer must be valid when it
For each symbolizable integer that matches our pre-ﬁlter,
a forward slice is computed in the intra-function data depen-
dence graph, until a dereferencing site of any value depending
on the integer is reached. Then value-set analysis is performed
on the slice, from the beginning to the dereferencing site, and
an address (expressed as a value-set in VSA) is obtained.
At
is
dereferenced, we can reasonably infer that the original sym-
bolizable integer must point to the same memory region as this
address belongs to. This approach not only makes it possible
for Ramblr to correctly handle the example we described
above (where the value of the pointer no longer falls within
the bounds of the binary), but also ﬁnds and ﬁxes cases where
a base pointer points to one memory region, but in fact it
should be pointing to another memory region in the binary.
B. Data Consumer Check
After previous steps, all immediates and constant values
should be categorized into two groups: symbolizables and non-
symbolizables. Ramblr is normally guaranteed to be correct
as long as the above categorization is perfect. However, there
are certain scenarios where categorization fails. Such scenarios
are rarely seen in normal binaries, but arise when a binary
implements unusual behavior, such as pointer decryption,
custom pointer construction (e.g., adding two integers together,
then converting the result to a pointer and dereferencing it),
etc. We developed a data consumer check analysis that detects
these scenarios in two ways:
1) For each non-symbolizable integer, data consumer check
performs an intra-function data dependence analysis to
determine if it is used as a pointer or a jump target later
without involving any symbolizable integer. Speciﬁcally,
the requirement to avoid involvement of any symboliz-
able integers excludes the pointer offset case from the
pointer construction case. The former is already handled
by making the base pointer properly symbolizable. The
latter, on the other hand, results in a symbolization mis-
classiﬁcation and a broken binary. Intuitively, building
a pointer out of integers, although acceptable,
is an
uncommon behavior, and we have found no way for
it to be safely handled, in the general case, by binary
reassembling.
2) For each symbolizable integer, the data consumer check
performs an intra-function data dependence analysis on
it and examines if any “unusual” operation is applied on
it. Unusual operations include operations besides add and
subtract (which are used for pointer offsetting and can
be supported by reassembling). If hard-coded pointers
undergo such operations, we assume that the binary is
doing something unusual that reassembly cannot handle.
Reassembling immediately terminates when any of the
cases above are found, as the reassembled binary would
otherwise likely to be broken.
An example of pointer encryption is shown in Listing 10.
A pointer in the binary is encrypted before use by XORing
with a static number 0xdead1337. It is loaded into register
eax and decrypted before being used as a call target. Data
consumer check recovers a data dependence graph with respect
to the integer 0xdeed1137 loaded at instruction 0x400100.
This analysis detects that two non-symbolizable integers are
XORed, and then used as a jump target. Data consumer check
deems this binary to be unsafe for reassembling, and terminates
reassembling right away.
It
is important
techniques,
Ramblr is able to detect these cases and avoid producing
a broken reassembled binary.
to note that, unlike prior
.text
400100
400105
40010a
.data
600010
mov
xor
call
eax, DWORD PTR [0x600010]
eax, 0xdead1337
eax
; calling address 0x400200
0xdeed1137
Listing 10: An example of pointer decryption using a static
key.
VIII. FAST WORKAROUNDS
The systematic approach described in previous sections
uses data dependence analysis and value-set analysis to offer
a level of functionality guarantee for the reassembled binary.
However, those analyses, along with the CFG recovery re-
quirement, are still inevitably time-consuming on real-world
binaries. In certain cases, where abundant
test cases exist
for the original binary and checking the functionality of the
reassembled binary by running those test cases can be done
quickly, some ad-hoc alternatives can be applied instead of
the Content Classiﬁcation and Symbolization steps of our
systematic approach. This allows binary reassembling be done
almost instantly, at the cost of some functionality guarantee.
This set of what we term “fast workarounds”, along with a
discussion of their compromises on the functionality guaran-
tees of the reassembled binary, are presented and discussed
in this section. We measure the resulting correctness and
the runtime of both the systematic approach and the fast
workarounds in Section X.
A. Fast Data Type Recognition
In order to identify data types, especially to get the sizes
of arrays, our systematic approach leverages localized static
10
analysis, which is accurate but heavyweight. An alternative
approach is to guess data types based solely on the values
of those data, which is way faster, and still maintains an
acceptable accuracy for reassembling.
We implement a series of fast data type guessing strategies
in Ramblr:
Floating point numbers. Our
type guessing strategy for
ﬂoating point numbers does a scan of the disassembly
to identify obvious cases of data being used as ﬂoating
points.
Pointer arrays. One or more consecutive integers of machine
bit-width that points to any pre-deﬁned memory region.
We still apply a fast version of base pointer reattribu-
tion on pointer arrays, allowing for the identiﬁcation of
pointers that are, ostensibly, not pointing to any memory
region due to compiler optimization. We treat individual
pointers as a single-element pointer array.
Null-terminated Unicode strings. Any fully-printable con-
secutive sequence of valid Unicode characters, ending
with two null bytes (by Unicode spec), is recognized as
a null-terminated Unicode string. The minimal length is
four characters.
Null-terminated ASCII strings. Any fully-printable consec-
utive byte sequence ending with a null byte is recognized
as a null-terminated ASCII string. The minimal length is
four bytes.
Sequences. Any arithmetic progression of bytes, shorts, or ints
is recognized as a sequence. The minimal length is ﬁve
elements.
Integers. We identify remaining “lone” integers by detecting
integer-sized gaps in the remaining disassembly. This has
no effect on the functionality of the reassembled binary,
but it makes the disassembly more readable.
Unknown data. A linear sweep is performed on the entire
non-executable memory region, and all gaps (bytes not
belonging to any recognized data blocks) are identiﬁed
as unknown data blocks.
Note that the order of applying these guessing strategies
matters. For example, we cannot apply the “unknown data”
identiﬁcation strategy before other strategies are applied, oth-
erwise all bytes will be identiﬁed as unknown. We apply these
strategies in the order listed above.
Ramblr’s data guessing is easily extensible: users can add
more type guessing strategies with respect to the nature of
binaries to be reassembled, which will beneﬁt the symbol-
ization procedure by lowering potential misidentiﬁcation of
symbolizable immediates. If a binary embeds, for example, a
PDF as a resource, a “PDF ﬁle” identiﬁcation strategy can be
easily added.
B. Fast Base Pointer Reattribution
As discussed previously in this paper, one issue that occurs
during symbolization is that an immediate holding a value
belonging to one memory region (or even outside any memory
region) actually points to another memory region when deref-
erenced. This is generally caused by compiler optimizations.
The issue is addressed by our base pointer reattribution in the
systematic approach, involving intra-function data dependence
11
tracking and value-set analysis. These analyses are both expen-
sive. Given that an immediate being used as a pointer must be
valid (i.e., must point to the appropriate memory region at
dereferencing time), we perform a forced concrete execution
on any path starting from the source of the immediate and
ending at the dereferencing site that depends on the immediate
value. Then, we symbolize the immediate value as an offset to
the beginning of the memory region that the ﬁnal dereference
was targeting. For the sake of performance, we only process
immediate values that are not trivially identiﬁable as belonging
to any memory region.
The fast base pointer reattribution allows us to avoid sym-
bolization false negatives by correctly detecting immediates as
symbols in cases where they would otherwise be ignored.
IX. REASSEMBLY
The reassembling procedure is straightforward. Taking re-
sults from symbolization, we ﬁrst assign labels for every sym-
bol reference we recovered, and then replace all symbolizable
immediate values in each instruction and each data region with
corresponding labels. The resulting reassembled disassembly
is output into a single assembly ﬁle, to which the user can
apply their own patches as needed. Finally, an off-the-shelf
assembler is used to assemble the resulting assembly into a
reassembled binary.
Theoretically, the assembly syntax can be either Intel or
AT&T. Ramblr supports emitting either syntax, however, we
ﬁnd that Clang (from version 4.4 to the latest version 4.8)
cannot support certain Intel-style instructions. Neither GCC
nor Clang has issues supporting assembly in AT&T syntax.
Therefore, Ramblr defaults to AT&T syntax. For the purpose
of transparently supporting user patches written in a different
syntax than the target outputting syntax, we also implement a
syntax converter from Intel to AT&T style.
X.
IMPLEMENTATION AND EVALUATION
This section covers the implementation of our prototype,
Ramblr, describes the datasets that we use, and presents its
evaluation. We evaluate the correctness of Ramblr against
ground truth produced during original compilation of the
binaries, compare it against Uroboros on two datasets, and
discuss analysis time and execution overhead in the resulting
binaries.
A. Implementation Overview
We use angr, an open-source binary analysis framework,
as the platform for reassembling. Ramblr is implemented
in Python as an angr analysis, and utilizes other publicly-
available analyses routines in angr. All of our CFG re-
covery improvements are done on top of angr’s CFGFast
analysis. Capstone is used for performing the disassembly
of instructions [17]. Our prototype works on x86 and x86-
64 ELF binaries. However, as angr is platform-independent,
there are no fundamental limitations preventing an extension
of Ramblr to other architectures. All of our evaluations are
performed under PyPy 5.3.1 in Ubuntu Server 16.04 LTS.
The entire Ramblr toolchain, including Ramblr itself
and our assembly syntax converters, is open sourced. Ramblr
Dataset
Total # of binaries
Optimization level
# of binaries
Coreutils
106
CGC
143
O0
O1
O2
O3
Ofast
Os
O0
O1
O2
O3
Ofast
Os
106
106
106
106
106
106
141
117
116
116
116
119
TABLE II: Number of binaries of each dataset.
is included in angr, while other parts of the toolchain are
included in a binary patching platform called Patcherex,
which was used by the third-place winning team in the DARPA
Cyber Grand Challenge [20].
B. Dataset
We use two sets of binaries for the evaluation. The ﬁrst set
is Coreutils 8.25.55-ff217, which includes 106 different
binaries that form much of the base of a Linux system. Accord-
ing to [25], Coreutils is one of the binaries collections used
to evaluate Uroboros, and allows us to compare our approach to
Uroboros. To test the relative versatility of the two approaches
in the presence of advanced binary constructs, we compile each
program in x86 and x64, with six different optimization levels,
including O0, O1, O2, O3, Ofast, and Os, with GCC 5.4.1
in our testing environment.
The second dataset is a collection of 143 binaries from
the Qualiﬁcation Event (CQE) and the run-up to the Final
Event (CFE) of the DARPA Cyber Grand Challenge (CGC),
representing all CGC binaries released before August 2016.
CGC binaries are stripped, self-contained x86 binaries that
do not rely on any dynamically-linked libraries. We compile
each program with six different optimization levels, including
O0, O1, O2, O3, Ofast, and Os, with Clang 4.4 (the only
supported compiler for CGC) in the DECREE VM provided
by DARPA.
Note that some binaries in both datasets simply do not
work (crashing with segmentation faults, failing test cases, etc.)
when compiled with certain optimization levels. Those binaries
are removed from each dataset. We also remove all multi-CB
binaries from the CGC dataset as it is difﬁcult to tell exactly
which one of the full set of binaries is the culprit when a
test case fails. The ﬁnal count of binaries our datasets across
different compilation ﬂags is shown in Table II. The entire
dataset is available upon inquiry.
Test Cases. Both Coreutils and CGC binaries come with
abundant test cases, making them well-suited for evaluating
the functionality of reassembled binaries. We run test cases on
every reassembled binary, and mark a binary as broken if any
test case fails.
C. Pre-evaluation
The authors of Uroboros [25] open-sourced their prototype
implementation to the community [19]. We used their code
for evaluating their approach in our comparative evaluation.
However, we had to make several augmentations and bug ﬁxes
ID
1
2
3
4
5
6
Changes
Add around 20 unsupported instruction opcodes
Remove duplicated labels in generated assembly ﬁle 6
Change input parsing logic to support output from newer readelf
Fix a bug in function alignments ﬁltering
Add “-ocamlopt opt” to build script
Make some changes to support statically-linked binaries
TABLE III: Changes we made to Uroboros prototype
to perform a comparative evaluation on the Coreutils dataset
and on CGC binaries. To the best of our knowledge, these
changes and bug ﬁxes, as listed in Table III, do not change the
behavior and expected output of Uroboros. We will push these
improvements upstream to the original Uroboros repository on
GitHub.
Uroboros allows for the deactivation of some of its assump-
tions, which, as discussed previously, are overly restrictive for
real-world cases. As we discussed previously in Section III-A,
assumption 2 would prevent any modiﬁcation of data sections.
Therefore during evaluation, we enable assumptions 1 and 3
and disable assumption 2 (by specifying arguments -a 3) in
order to obtain a comparative result.
For Uroboros, we use non-stripped binaries as input, as
they rely on symbols in non-stripped binaries for function
identiﬁcation. Ramblr directly takes stripped binaries as input
and carries out its own analyses to recover the necessary data.
D. Symbolization Correctness
First, we evaluate the correctness of Ramblr’s symboliza-
tion step on our dataset, with and without the use of its Fast
Workarounds (implemented in Ramblr Fast). To do this,
we collect the ground truth of mappings between labels and
addresses from the linker ld during the original compilation
of the binary, and compare this ground truth against
the
immediate values Ramblr symbolizes. It is important to note
that Ramblr does not utilize the ground truth during its
operation – it is only used for evaluation purposes. As we
are interested in the potential damage to reassembled binaries,
binaries that the tools opted out of reassembling were not
included in this evaluation.
The mis-classiﬁcations represented by these results are
roughly a measure of how likely the approach is to break
the binary, as each mis-classiﬁcation could result in a broken
reference. When there are no mis-classiﬁcations in a given
binary, the reassembled binary is guaranteed to work, except
for in the scenarios described in Section VII-B. We could not
make this evaluation comparative to Uroboros, as we were
unable to extract this information from the Uroboros prototype.
The results are shown in Table IV. While both Ramblr and