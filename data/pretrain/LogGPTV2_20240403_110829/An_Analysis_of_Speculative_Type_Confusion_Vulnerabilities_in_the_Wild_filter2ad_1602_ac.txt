L1:
Ln−1:
Ln:
Listing 4: Branch slide
in the listing.) Execution of the branch slide puts the GHR
into the same state both when the shadow is trained and when
the victim executes.
To control address-based indexing, we need the address of
the shadow gadget branches to map to the same PHT entries as
the victim eBPF program’s branches. We cannot create such
a PHT collision directly, by controlling the shadow gadget’s
address, since we do not know the victim’s address or the
hash function used by the branch predictor. We can, however,
perform a “brute force” search to ﬁnd a collision, as prior
work has shown that the PHT on Intel processors has 214
entries [26]. We describe our collision search algorithm later,
since it relies on our mechanism for leaking data.
Cache line ﬂushing We need the ability to ﬂush a memory
location out of the victim’s cache, for two reasons. First, we
need to cause the read of the value checked by the branches
to miss in the cache, so that the resulting speculation win-
dow is large enough to read and leak the secret data. Sec-
ond, one of the simplest ways of leaking the data is via a
FLUSH+RELOAD cache covert channel [92], wherein the tran-
sient execution brings a previously ﬂushed secret-dependent
line into the cache. Line 6 in Listing 2a shows an example,
which leaks over an eBPF array map, M. Notice that we mask
the secret value to obtain a valid offset into the array, to satisfy
the eBPF veriﬁer. As a result, this example leaks a single bit.
Unfortunately, eBPF programs cannot issue a clflush
instruction to ﬂush a cache line. This problem can be
sidestepped in a number of ways. We use a clever technique
due to Horn [35]. The basic idea is to perform the required
cache line ﬂushes by having another eBPF program, running
on a different core, write to these cache lines, which reside in
a shared eBPF array map. These writes invalidate the relevant
2404    30th USENIX Security Symposium
USENIX Association
cache lines in the victim’s cache, resulting in a cache miss the
next time the victim accesses the lines. After mounting the
attack, the attacker runs a third eBPF program on the victim’s
core to perform the timing measurements that deduce which
line the transient execution accessed, and thereby the secret:
r0 = CALL ktime_get_ns()
r1 = M[b] // b is 0*512 or 1*512
r2 = CALL ktime_get_ns()
return r2 - r0 // if small -> secret is b
This approach leverages the fact that eBPF programs can
perform ﬁne-grained timing measurements by invoking the
ktime_get_ns() kernel helper. This is not fundamental for
the attack’s success, however. Similarly to what has been
shown for JavaScript [71], we could implement a ﬁne-grained
“clock” by invoking eBPF code on another core to continu-
ously increment a counter located in a shared eBPF map.
Finding address-based PHT collisions To place our
shadow branches into addresses that get mapped to the same
PHT entries as the victim’s branches (whose address is un-
known), we perform the following search algorithm.
We allocate a 2 MB buffer and then, for each byte in the
buffer, we copy the shadow gadget to that location and check
for a collision by trying the attack. We ﬁrst mistrain the branch
predictor by repeatedly executing the shadow gadget (whose
branches’ PHT entries are hoped to collide with the victim’s).
We then invoke the in-kernel victim gadget, conﬁgured (by
setting the array entry read into r0) so that its correct execu-
tion does not leak (i.e., does not execute line 6 in Listing 2a).
If no leak occurs—i.e., both timing measurements of M[b]
indicate a cache miss—we do not have a collision. If a leak
occurs, we may still not have a collision: the victim may have
leaked its own stack variable by executing line 5, either due
to the initial BPU state or if we only have a PHT collision
with the second branch. To rule these possibilities out, we try
the attack again, this time with the relevant bit ﬂipped in that
stack variable (which is done by invoking the victim with a
different argument). If the leaked bit ﬂips too, then we do not
have a collision; otherwise, we do. Once found, a collision
can be reused to repeat attacks against the victim. If the search
fails, the attacker can re-load the victim and retry the search.
4.3.1 Evaluation
We use a quad-core Intel i7-8650U (Kaby Lake) CPU. The
system runs Ubuntu 18.04.4 LTS with Linux 5.4.11 in a work-
station conﬁguration, with applications such as Chrome, TeXs-
tudio, and Spotify running concurrently to the experiments.
PHT collisions We perform 50 experiments, each of which
searches for a shadow gadget location that results in PHT
collisions with a freshly loaded victim. Successful searches
take 9.5 minutes on average and occur with 92% probability
found collision?
success (46/50)
failure (4/50)
average
9.5 min.
min.
20 sec.
max.
45 min.
≈ 53 min
median
8.5 min.
Table 1: Times to ﬁnd PHT collision with victim (50 experiments).
retries
1
2
10
100
success rate
transmission rate
99.9%
98.7%
100%
100%
55,416 bps
28,712 bps
5,881 bps
584 bps
Table 2: Accuracy and capacity of the eBPF covert channel.
(Table 1). Our search algorithm can be optimized, e.g., by
considering only certain addresses (related to BPU proper-
ties and/or kernel buffer alignment). The search, however, is
not a bottleneck for an attack, since once a location for the
shadow gadget is found, it can be reused for multiple leaks.
We therefore do not invest in optimizing the search step.
Covert channel quality We attempt to leak the contents of
one page (4096 bytes) of kernel memory, which is pre-ﬁlled
with random bytes. We leak this page one bit at a time, as
described above. The only difference from Listing 2a is that
our victim eBPF program receives an argument specifying
which bit to leak in the read value, instead of always leaking
the least signiﬁcant bit. To leak a bit, we retry the attack k
times, and output the majority value leaked over the k retries.
Table 2 shows the resulting accuracy (percentage of bits
leaked correctly) and throughput (bits/second) of the overall
attack, as a function of the number of retries. Since all steps
are carried out using the same shadow gadget location, we
do not account for the initial search time. The attack reads
from arbitrary memory locations at a rate of 6.7 KB/sec with
99% accuracy, and 735 bytes/sec with 100% accuracy. (The
success rate with 2 retries is lower due to an implementation
artifact in our majority-taking computation.)
5 Compiler-introduced speculative type con-
fusion
In principle, compiler optimizations can create speculative
type confusion gadgets in the emitted code (Listing 1b shows
a hypothetical example). Here, we ﬁrst show that this is not a
theoretical concern: deployed compilers can generate specu-
lative type confusion gadgets, and certain Spectre compiler
mitigations do not identify or block such gadgets (§ 5.1).
Motivated by this ﬁnding, we perform a binary analysis on
Linux and ﬁnd that it contains potential compiler-introduced
vulnerabilities (§ 5.2).
5.1 Compilers emit gadgets
We test different versions of several compilers: GCC, Clang,
Intel ICC (from Intel Parallel Studio), and Microsoft Visual
USENIX Association
30th USENIX Security Symposium    2405
Studio (MSVC). We ﬁnd that all of them can compile C
code into x86 code that contains a speculative type confusion
gadget. Table 3 summarizes the results.
Listing 5 shows an example for GCC; the other compilers
produce similar results for similar code. Here, the code in the
ﬁrst if block overwrites the rdi register (argument p) with the
rsi register (attacker-controlled argument x). The compiler
performs this overwrite because it enables using the same
instruction for the assignment to foo at the end of the function.
The compiler also reasons that the write to *q might modify
predicate (if q points to predicate), and thus predicate
should be re-checked after the ﬁrst if block. The compiler’s
analysis does not understand that in a correct execution, the
ﬁrst if block executing implies that the second if block
does not execute, even if q points to predicate. However,
if the attacker mistrains the branches such that both predict
“not taken,” the resulting transient execution dereferences the
attacker-controlled value x and leaks its value. Using the
mistraining technique of § 4.3, we verify that this is possible.
Spectre mitigations efﬁcacy We test whether each com-
piler’s Spectre mitigations apply protection in our example.
Clang/LLVM: Implements a generic mitigation called
speculative load hardening (SLH) [21]. SLH inserts branch-
less code that creates a data dependency between each load’s
address and all prior conditional branch predicates. SLH thus
successfully protects the gadget in our example, but at a high
performance cost (§ 7).
MSVC: Supports several mitigation levels. The most ag-
gressive mitigation (/Qspectre-load) inserts an lfence
speculation barrier after every load instruction. This mit-
igation applies in our example. However, its documenta-
tion warns that “the performance impact is high” [59].
In contrast, MSVC’s recommended Spectre v1 mitigation,
/Qspectre [58], targets bounds check bypass attacks and
does not insert any speculation barriers in our example.
ICC: Similarly to MSVC, ICC supports several mitiga-
tion levels [38]. It offers two full mitigation options, based
on speculation barriers (all-fix) or SLH (all-fix-cmov),
with the former documented as having “the most run-time
performance cost” [38]. Both options apply in our example.
ICC also offers a “vulnerable code pattern” mitigation, which
does not insert speculation barriers in our example.
GCC: Does not support a whole-program mitigation. It
offers a compiler intrinsic for safely accessing values in the
face of possible misspeculation. However, programmer who
equate Spectre v1 with bounds check bypass have no reason
to use this intrinsic in our example, so we consider GCC’s
mitigation inapplicable in our case.
5.2 Finding compiler-introduced gadgets
To ﬁnd potential compiler-introduced speculative type con-
fusion vulnerabilities in the wild, we perform a binary-level
static analysis of Linux 5.4.11, compiled with different GCC
compiler
Clang/LLVM (v3.5,
v6, v7.01, v10.0.1)
MSVC (v16)
ICC (v19.1.1.217)
GCC (v4.8.2, v7.5.0)
emits gadget?
mitigates gadget?
yes
yes
yes
yes
yes
suggested: no; full: yes
lightweight: no; full: yes
N/A
Table 3: Compilers introducing speculative type confusion.
volatile char A[256*512];
bool predicate;
char* foo;
# args: p in %rdi
#
#
x in %rsi
q in %rdx
void victim(char *p,
uint64_t x ,
char *q) {
unsigned char v;
if (predicate) {
p = (char *) x ;
*q |= 1;
}
if (!predicate) {
v = A[(*p) * 512];
}
foo = p;
}
# first "if":
cmpb
$0x0,(predicate)
L1 # skip 2nd if
B1:je
%rsi ,%rdi
# assignment to p:
mov
# assignment to q:
orb
# second "if":
cmpb
B2:jne
$0x0,(predicate)
L2
$0x1,(%rdx)
# deref p & leak
L1:movsbl (%rdi),%eax
$0x9,%eax
shl
cltq
movzbl A(%rax),%eax
L2:mov
retq
%rdi,(foo)
(a) C code
(b) Emitted x86 code.
Listing 5: Example of C code compiled into a speculative type confu-
sion gadget (GCC 4.8.2, -O1). Argument x is attacker-controlled.
versions and optimization ﬂags.
Goal & methodology We set to ﬁnd out if the kernel can
be maneuvered (via transient execution) to dereference a user-
supplied address, which is the core of the attack. We explicitly
do not consider if or how the result of the dereference can
be leaked, for the following reasons. Once a secret enters the
pipeline, it can be leaked in many ways, not necessarily over
a cache covert channel (e.g., port contention [14] or execu-
tion unit timings [72]). It is beyond our scope to exhaustively
evaluate all possible leaks to determine if a “confused” deref-
erence can be exploited. Also, dereferences that appear unex-
ploitable on our test setup may be exploitable with a different
combination of kernel, compiler, and ﬂags. Finally, today’s
unexploitable dereferences may become exploitable in the
future, due to (1) discovery of new microarchitectural covert
channels, (2) secrets reaching more instructions on future
processors with deeper speculation windows, or (3) kernel
code changes. Overall, the point is: the architectural contract
gets breached when the kernel dereferences a user-supplied
address. We thus focus on detecting these breaches.