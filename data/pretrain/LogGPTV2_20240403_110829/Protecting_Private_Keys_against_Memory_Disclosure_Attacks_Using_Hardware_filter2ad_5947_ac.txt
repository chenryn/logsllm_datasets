int _xbegin(void){
int ret = _XBEGIN_STARTED;
asm volatile(".byte 0xC7,0xF8; .long 0" :
return ret;
}
"+a" (ret) :: "memory");
The default return value is set to _XBEGIN_STARTED,
which denotes that the transactional execution starts success-
fully. Next, the transaction starts when XBEGIN is executed
(“.byte 0xC7,0xF8”). The operand “.long 0” sets
the relative offset of the fallback function address to 0, i.e.,
the next instruction “return ret”. If the transaction starts
successfully, the return value is unchanged and returned to
callers. Then, the program continues transactional execution
until commits successfully. If the transaction is aborted, the
program goes to the fallback address (i.e., “return ret”),
with the micro-architectural state restored, except that the
execution is no longer in transaction and the return value
(i.e. the abort status in the EAX register) is set properly.
Program can decide whether to retry transactional execution
again based on the abort status returned in ret.
B. The Na¨ıve Implementation
We adopt PolarSSL v1.2.10 as the base of our AES
and RSA modules. PolarSSL is a modular and efﬁcient
cryptographic library with a very small memory footprint,
which is the feature we expect. A smaller work-set means
adequate cache resources to complete the transaction. Mean-
while, PolarSSL speeds up the RSA algorithm by employing
Chinese remainder theorem (CRT), Montgomery modular
exponentiation, and sliding-window exponentiation tech-
niques. It has been adopted by many projects (e.g., LinkSYS,
NGINX and OpenVPN) and governmental agencies (e.g.,
Government of the Netherlands). The AES module is a
conventional S-box-based implementation, but we improve
88
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:11 UTC from IEEE Xplore.  Restrictions apply. 
it with the AES-NI extension [41].2 This has three beneﬁts.
First, memory footprint is reduced without S-box. Second,
performance is boosted with hardware acceleration. More
importantly, timing and cache-based [1, 8, 13] side channels
of AES implementations are eliminated by running in data-
independent time.
In the long-integer module of PolarSSL, a piece of assem-
bly code uses MMX registers to accelerate the computation.
It is explicitly marked as unfriendly instructions with Intel
TSX [40]. Our solution is to replace MMX registers with XMM
registers. This needs only a little modiﬁcation because both
operands are supported in the SSE2 extension.
We implement the steps from PrCmpt.1 to PrCmpt.5
described in Section III-B, as a C-language function
mimosa_protected_compute(keyid, in, out).
It appears to be straightforward to integrate the code in
transactional region using the RTM interface: put it after
_xbegin(), and commit the transaction using _xend()
that simply invokes XEND. As aborts may occur, we invoke
_xbegin() in an inﬁnite loop, and the execution makes
progress if and only if the transaction commits successfully.
while (1){
int status;
status = _xbegin();
if (status == _XBEGIN_STARTED)
break;
}
mimosa_protected_compute(keyid, in, out);
_xend();
As mentioned in Section III-B, PrCmpt.5 erases all
sensitive data carefully before committing the transaction,
i.e., in mimosa_protected_compute(). The sensitive
data appear in the following places:
• Allocation buffer: The long-integer module requires
dynamically allocated memory.
• Stack of mimosa_protected_compute(): The
AES round keys and decrypted private keys are stored
in the stack of mimosa_protected_compute().
• Register: General purpose registers are involved in
computations, and XMM registers are used in AES and
long-integer modules.
When we test this na¨ıve implementation, the execution
never commits successfully. It is somewhat expected: there
are so many restrictions on the execution environment for
Intel TSX. In the following, we will demonstrate various
causes that lead to aborts and our optimizations. We used
the perf proﬁling tool [67] and Intel Software Develop-
ment Emulator (SDE) version 6.12 [3] for the purpose of
discovering abort reasons and performance tuning.
The perf proﬁling tool works with the Intel perfor-
mance monitoring facility. It supports the precise-event-
based sampling (PEBS) function that records the processor
2Newer versions of PolarSSL also support AES-NI. We develop it
independently to avoid using shared memories.
99
state once a particular event happens. In particular, we
use the RTM_RETIRED.ABORTED event to capture TSX
aborts. This event occurs every time a RTM execution is
aborted. Based on the dumped processor state, we are able
to locate the abort reason and the eventing IP that causes
the abort. SDE is the Intel ofﬁcial software emulator for
new instruction set extensions. It detects the instructions
that are requested to be emulated, and then skips over those
instructions and branches to the emulation routines.
C. Performance Tuning
Avoiding Data Conﬂicts. Both perf and SDE reported
plenty of data conﬂicts at ﬁrst. We found that the modular
exponentiation in the na¨ıve implementation used the OS-
provided memory allocation library which shares maintained
meta data (e.g., free list) for all the threads. As a result,
plenty of data conﬂicts happen when many threads request
for new memory simultaneously in multiple cores.
Our solution is that each Mimosa thread monopolizes its
own allocation context when in the transactional region. We
reserve a static memory buffer as this context for each core.
When a Mimosa thread enters the transactional region, it
uses the designated context for that core.
We deﬁne a global array of allocation contexts. A context
is deﬁned for each core as follows:
typedef struct{
unsigned char buffer[MAX_ALLOCATION_SIZE]
__attribute__((aligned(64)));
size_t len;
size_t current_alloc_size;
memory_header *first_free;
...
/* other meta data */
} ALLOCATION_CONTEXT;
In the transaction, when the memory allocation function
is called, the thread ﬁrst gets its core ID and uses it to
locate its allocation context. Then it performs actual memory
allocation in this context as follows.
void *mimosa_malloc(size_t len){
ALLOCATION_CONTEXT *context;
int id;
id = smp_processor_id();
context = allocation_context + id;
...
/* Actual allocation in the context */
}
The ﬁrst member in ALLOCATION_CONTEXT is aligned
on a 64-byte boundary (cache line size), which is the gran-
ularity to track the read/write-set addresses. This prevents
false sharing between continuous contexts. False sharing
happens when two threads access their distinct memory
locations in the same cache line, thus would cause data
conﬂict unexpectedly.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:11 UTC from IEEE Xplore.  Restrictions apply. 
With this tuning, Mimosa can work very well on SDE.3
We conﬁgured the CPU parameters in SDE so that the cache
size is identical to Intel Core i7 4770S (our target CPU),
and 8 Mimosa threads run without abort during extensive
experiments on SDE. This proves that our implementation
is fully compatible with the Intel TSX speciﬁcation and no
data conﬂict is caused by Mimosa itself.
Disabling Interrupts and Preemption. However, SDE does
not simulate real-time interrupts to support multi-tasking.
The private key computation is time-consuming. Therefore,
it is very likely that transactional execution is interrupted by
task scheduling on real hardware, which deﬁnitely causes
aborts. Other interrupts may also cause aborts. To give
Mimosa enough time to complete computations, interrupts
and kernel preemption are temporarily disabled when in
transactional region. All CPU-bound encryptions including
TRESOR [56], PRIME [29] and Copker [30], require dis-
abling interrupts to ensure atomicity, while Mimosa requires
it for efﬁciency because Intel TSX itself ensures atomicity
already.
Delay after Continuous Aborts. At this point, the abort
cycle ratio4 is relatively high, resulting in bad performance.
The perf proﬁling tool
is unable to provide obvious
information about abort reasons. The eventing IPs recorded
by PEBS spread across the transactional region. Meanwhile,
most of reported reason codes are ABORTED_MISC5, which
has a very ambiguous description by Intel. We list the abort
reason descriptions as follows.
• ABORTED_MISC1: Memory events, e.g., read/write
capacity and conﬂicts.
• ABORTED_MISC2: Uncommon conditions.
• ABORTED_MISC3: Unfriendly instructions.
• ABORTED_MISC4: Incompatible memory type.
• ABORTED_MISC5: Others, none of the previous four
categories, e.g., interrupts.
At ﬁrst, we suspect that the aborts would be caused by
non-maskable interrupt (NMI); however, this explanation is
immediately ruled out after examining the NMI counter
through the /proc/interrupts interface. We have con-
tacted Intel for support.5 As stated before, Intel provides
no guarantees as to whether transactional execution will
successfully commit and there are numerous implementation
speciﬁc reasons that may cause aborts [40].
We notice that Intel recommends a delay before retrying
if the abort was caused by data conﬂict [39]. Although
we encounter a different cause, we still modify Mimosa to
force a short delay after several failed transactions. As a
result, the success rate is signiﬁcantly improved. The number
3Mimosa is modiﬁed slightly to conform to SDE that runs in the user
space.
4The number of CPU cycles in the aborted transactions divided by the
total number of CPU cycles in all transactions.
5Until the submission of this manuscript, we have not received any reply.
while(!success){
int times = 0;
/* Disable interrupts and preemption */
get_cpu();
local_irq_save(flags);
#ifdef TSX_ENABLE /* Switch of Mimosa_NO_TSX */
while(1){
int status;
if(++times == MAX_TRIES)
goto delay;
status = _xbegin();
if(status == _XBEGIN_STARTED)
break;
}
#endif
mimosa_protected_compute(keyid, in, out);
success = 1;
#ifdef TSX_ENABLE
_xend();
#endif
delay:
/* Enable interrupts and preemption */
local_irq_restore(flags);
put_cpu();
if(!success){
/* Delay after several aborts */
set_current_state(TASK_INTERRUPTIBLE);
schedule_timeout(10);
}
}
Figure 2: Code Snippet in Mimosa
of tries before a delay is 5, which is an empirical value
suggested in [84] and also veriﬁed in our experiments. After
extensive experiments balancing the throughput under the
single-threaded and the multi-threaded scenarios, we have
identiﬁed 10 clock ticks as an optimized value for this
delay.6
After these tunings, almost all the remaining aborts occur
at the very beginning of the transactions. Therefore, although
we are unable to identify the exact reason(s) of the remaining
aborts, or to avoid all aborts, they only waste a very small
number of CPU cycles. The abort cycle ratio is low, as
more than 95% of the CPU cycles are used in successful
transactions. Figure 2 shows the ﬁnal code snippet.
is the result of all
We would like to point out that the signiﬁcant perfor-
mance improvement
the tuning ap-
proaches. It might appear that the abort issue is solved by
the last attempt (i.e., adding delays); however, it wouldn’t
be successful if we skip any of the previous steps. Our
perception is that we may not be able to completely avoid all
the aborts eventually: (1) the simulation results have shown
that our implementation is correct; (2) the Intel ofﬁcial tools
6For the HTM feature in zEC12 systems, IBM also suggests a random
delay before retrying a transaction on aborts [45]; and the optimal delay
depends on the particular abort reason, the CPU design and conﬁguration.
1010
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:11 UTC from IEEE Xplore.  Restrictions apply. 
are unable to identify or provide the details of the aborts;
and (3) Intel TSX and the speculative nature of transactional
memory do not guarantee all correctly implemented transac-
tions to commit, e.g., cache coherence trafﬁc may at times
appear as conﬂicting requests and may cause aborts.
D. Utility Issues
Based on the design described in Section III, Mimosa
needs an off-line machine to securely generate an encrypted
RSA private key ﬁle, and a to-be-protected machine that
runs the Mimosa service. The preparation utility in the off-
line machine generates RSA key pairs and encrypts them by
an AES master key derived from the same user password.
The encrypted key ﬁle is then copied to the to-be-protected
machine.
Mimosa provides private-key computation services to
user space through the ioctl system call. Based on the
command code and key ID, Mimosa outputs the pub-
lic key of
the corresponding key pair, or performs a
private-key operation on the input data and outputs the
result. In addition,
the ioctl interface is encapsulated
into an OpenSSL engine. A RSA key is selected via
ENGINE_load_private_key() and then can be used
in an OpenSSL-compatible way. We use this API to integrate
Mimosa into the Apache HTTPS server in the evaluation.
E. Applicability
Although the Mimosa prototype is implemented on Intel
Haswell CPUs using the RTM interface of TSX,7 our
solution is applicable to other platforms. Firstly,
it can
be implemented using the HLE interface. In particular, if
the protected computing is executed as a transaction using
HLE, XTEST will be used to determine whether it is in
transactional execution or not. If it is in normal execution
(i.e., the transaction aborts for some reasons), the protected
computing will not continue and the transactional execution
will be retried.
Most HTM solutions share a similar programming inter-
face. We will show that, in other HTM implementations,
the counterparts of the Intel TSX XBEGIN and XEND
instructions can be easily identiﬁed, and the abort process-
ing conforms to the Mimosa design. For example, in the
HTM facility of IBM zEC12 systems [45], transactions are
deﬁned by the instructions TBEGIN and TEND. On abort,
the PC register is restored to the instruction immediately
after TBEGIN, and a condition code is set to a non-zero
value. Typically, a program tests the condition code after
TBEGIN to either start the transaction execution if CC=0
or branch to the program-speciﬁed fallback function (i.e.,
7In August 2014, Intel announced a bug in the released TSX implemen-
tation, and suggested disabling TSX on the affected CPUs via a microcode
update [42]. During our experiments, the Mimosa prototype works well as
described in Section V. Note that TSX is still supported in newer CPUs,
e.g., Intel Core M-5Y71 CPU launched in Q4 2014 [43].
PolarSSL Mimosa_No_TSX Mimosa
Copker
d
n
o
c
e
s
r
e
p
s
n
o
i
t
p
y
r
c
e
d
A
S
R
700
600
500
400
300