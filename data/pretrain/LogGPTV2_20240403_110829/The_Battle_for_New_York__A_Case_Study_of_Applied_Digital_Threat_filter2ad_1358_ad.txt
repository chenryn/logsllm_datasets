USENIX Association
to implement periodic, mandatory readiness tests across
all NYC networks.
Securing accounts. Several participants identiﬁed user
account permissions – a fundamental security control in
any networked environment – as insufﬁciently well man-
aged. Three participants stated that it is common for em-
ployees to migrate across the organization and retain per-
missions to data shares and assets they no longer need.
NYC3 now directs monthly audits and re-certiﬁcation
of user access to narrow the impact of insider threats
or stolen credentials. Seven participants recommended
implementing multi-factor authentication. As a proof of
concept, NYC3 implemented multi-factor authentication
for 80 user accounts within a monitored subdomain.
Protecting physical network assets. Seven participants
determined that if control measures restricting physi-
cal access to networking infrastructure were weak, it
would create critical vulnerabilities. All expressed con-
cern with insider threats causing damage or stealing
data, but they all indicated that the most likely threat
stems from accidental damage. Three participants dis-
cussed concerns with inadvertent, wide-scale power out-
ages or power surges to networking infrastructure that
could cause some issues to persist for an extended dura-
tion. These three participants recommended security es-
corts for all personnel, in addition to multi-factor access
control near all networking infrastructure. Since the per-
formance evaluation sessions, NYC3 has been working
with federal, state, and private-sector entities on issues
related to this topic.
Crowdsourcing assessments. Two participants reported
that automated vulnerability assessment tools might not
detect all vulnerabilities and that manual
testing is
needed for identifying more complex issues. Thus, P21
recommended that NYC establish a bug bounty program
for public-facing services to beneﬁt from the collective
security community. Because of his recommendation,
NYC3 partnered with a bug bounty service provider to
conduct a 24-hour proof-of-concept assessment against
one of its web services.
Sensor coverage. Ten participants acknowledged that
the NYC environment is far too vast for manual monitor-
ing and that automated sensors play a critical role in de-
fense. In this situation, a gap in sensor coverage can lead
to unprotected systems or the successful exploitation of
known vulnerabilities. Four participants recommended
deploying additional EDRs on systems in speciﬁc subdo-
mains within which NYC3 had limited visibility. Within
30 days after the threat modeling training, NYC3 techni-
cians deployed 1331 new EDR sensors within these sub-
domains.
Protecting legacy systems. Three participants stated
that legacy systems signiﬁcantly impact their ability to
Figure 5: NYC3 developed an “urgent priorities” task
tracker to address problems identiﬁed in this study.
Their board facilitates two-week action periods and im-
proves how the organization communicates the impact of
their progress to senior leaders. NYC3 leaders have since
formalized this board using project management soft-
ware and other practices such as “demo days” to demon-
strate the viability of their defensive efforts.
4.5 Observations after 120 days
Observing NYC3’s environment 120 days after our
study concluded allows us to understand the longer-term
impact of threat modeling within live work environ-
ments. In total, we ﬁnd that NYC3 implemented eight
new categories of controls directly based on the ADPs
developed by participants in this study. Additionally,
NYC3 provided us with access to server logs, their alert
dashboard, and vulnerability reports so that we could
measure the actual efﬁcacy of three of these new con-
trols.
4.5.1 Actual adoption
Below we provide a sample set of ADPs that partici-
pants derived using threat modeling. NYC3 leaders mon-
itored the implementation of these ADPs using their pri-
orities board, and all mitigation strategies persist within
the NYC environment 120 days after the study. We only
provide high-level details about the ADPs below to avoid
placing NYC3 systems at risk.
Testing readiness. Nine participants cited resilient sys-
tems as critical requirements within their environment,
and two identiﬁed untested disaster recovery plans as
critical vulnerabilities. To dampen the impact of a cyber
attack, natural disaster, or terrorist attack, they recom-
mended frequently using multiple “fail-over” sites to val-
idate functionality. Accordingly, NYC3 has begun test-
ing fail-over servers within their local domain and plans
USENIX Association
27th USENIX Security Symposium    631
secure systems; some were installed ﬁve decades ago and
were never intended to be networked. Thus, they rec-
ommended segmenting non-critical legacy systems un-
til they are replaced/upgraded. NYC3 is now working
closely with partners to protect segmented systems and
those that must remain online.
Protecting against data corruption. Participants P02
and P17 identiﬁed data corruption as risks to NYC3 sys-
tems. NYC3 technicians now verify the integrity of each
software and indicator of compromise (IOC) update pro-
vided by third-party vendors to prevent the exploitation
of update mechanisms, as seen in the 2017 NotPetya mal-
ware outbreak [56].
Reducing human error. Human error was another com-
mon theme across the threat landscape. Six participants
stated that a simple typo in a conﬁguration script, like
the one that caused the 2017 Amazon S3 outage [2],
could have signiﬁcant impacts across multiple systems
or networks. Three defenders recommended two-person
change control when updating conﬁguration ﬁles on ﬁre-
walls and EDR systems. Such controls require one per-
son to propose a change and another to review and im-
plement the change to reduce the likelihood of human
error. NYC3 now enforces two-person change control
on all modiﬁcations to access control lists.
4.5.2 Actual efﬁcacy
Quantitative metrics captured in the 120 days after
threat modeling training empirically support the efﬁ-
cacy of threat modeling. A NYC3 security analyst ver-
iﬁed every intrusion, incident, and vulnerability within
these data records. To protect the operational security of
NYC3, we do not report on speciﬁc threats that would
enable a malicious actor to re-target their systems.
Securing accounts. User account logs allow us to ana-
lyze account hijacking attempts based on the geographic
origin of attempts, time frequency between attempts, and
why the attempt failed (e.g., wrong password or invalid
token). Over 120 days, NYC3 recorded 3749 failed login
attempts; based on frequency and subsequent success-
ful logins, we associate 3731 of these attempts with em-
ployees forgetting their password. Among the remaining
failed logins, NYC3 successfully blocked hijacking at-
tempts that originated from a foreign nation against seven
privileged user accounts. Of these seven accounts, the
attacker failed at the multi-factor login step for ﬁve ac-
counts and failed due to password lockout on the other
two accounts. Prior to this study, this subdomain did not
have multi-factor veriﬁcation enabled; these ﬁve priv-
ileged accounts were protected by mechanisms imple-
mented solely because of the introduction of threat mod-
eling.
Crowdsourcing assessments. The 24-hour bug-bounty
trial program yielded immediate results. Overall, 17 se-
curity researchers participated in the trial program and
disclosed three previously unknown vulnerabilities in a
public webserver protected by NYC3, veriﬁed through
proof-of-concept examples. NYC3 validated these vul-
nerabilities and patched the production systems in accor-
dance with policy and service-level objectives. After the
success of this trial, NYC3 has authorized an enduring
public program that will focus on improving the secu-
rity posture of web applications under NYC3’s purview.
Such a program is a ﬁrst for the City of New York and
NYC3, created as a direct result of introducing threat
modeling.
Sensor coverage. EDR reports allow us to uniquely
identify which IOCs appeared in which systems, their
severity level, and frequency of attempts. NYC3 de-
ployed 1331 new sensors to endpoints that were previ-
ously unmonitored and were able to verify and respond
to 541 unique intrusion attempts identiﬁed by these new
sensors. Of these 541 intrusion attempts, 59 were labeled
critical and 135 were labeled high severity; NYC3’s part-
nered vendor security service manually validated each
of these intrusions and veriﬁed their severity levels as
true positives. One important aspect to note: if any sys-
tems had been infected prior to sensor deployment, our
study would have captured both new intrusion attempts
and any re-infection attempts that occurred after NYC3
deployed the sensors for the ﬁrst time. According to the
lead NYC3 EDR engineer, all 541 of these events could
have led to successful attacks or loss of system availabil-
ity if technicians had not deployed the sensors to areas
identiﬁed during threat modeling.4
5 Discussion and conclusions
We provide the ﬁrst structured evaluation of introducing
threat modeling to a large-scale enterprise environment.
Overall, our ﬁndings suggest that threat modeling, in this
case the CoG framework, was an effective and efﬁcient
mechanism for developing actionable defense plans for
the NYC3 enterprise. Defense plans created using CoG
led to measurable, positive results. These results sug-
gest that even a relatively small amount of focused threat
modeling performed by IT personnel with no previous
threat-modeling experience can quickly produce useful
improvements.
Immediately after completing the performance evalu-
ation sessions, 23 participants reported that they found
the framework useful; after 30 days of use, 24 partici-
pants reported ﬁnding the framework useful and 20 par-
ticipants reported regularly using concepts from threat
modeling in their daily processes. In less than 37 minutes
on average, our 25 participants developed 147 unique
mitigation strategies for threats to their organization.
NYC3 adopted many of these recommendations, im-
proving their security posture in eight key areas. After
632    27th USENIX Security Symposium
USENIX Association
120 days, participant-designed ADPs blocked account
hijackings of ﬁve privileged user accounts, blocked 541
unique intrusion attempts, and discovered (and reme-
died) three vulnerabilities in public-facing web servers,
all of which support that introducing threat modeling
made NYC3 more secure.
We note that many of the ADPs that NYC3 em-
ployees developed and implemented (Section 4.5) con-
tain straightforward recommendations, such as applying
multi-factor authentication. We believe that this in it-
self constitutes an important ﬁnding: despite adhering to
applicable federal, state, and local compliance standards
and “best practices,” these measures were not already in
use. Threat modeling offered our participants the agility
to identify and implement defensive measures not (yet)
prescribed in these standards. In this case, threat model-
ing helped the organization gain new perspective on their
security gaps and proactively mitigate issues.
Many organizations are currently making signiﬁcant
investments in digital-security tools and capabilities [10].
Our case study of threat modeling, in contrast, shows
promising results that can be achieved by leveraging ex-
isting resources, without the need for new technologies
or personnel. Further, our approach included only two
hours of employee training, which we expect would be
palatable for many organizations.
5.1 Lessons learned
Based on our case study, we make several observations
about the process of adopting threat modeling in a large
organization.
Hands-on learning. Our participants indicated that our
hands-on approach to teaching threat modeling worked
well. After the performance evaluation sessions, without
prompting, 24 of 25 participants said that the personal-
ized, hands-on application allowed them to understand
the framework better than the educational intervention
classes alone. Our logistic regression analysis on par-
ticipants’ CoG accuracy revealed a relatively level un-
derstanding of the framework across educational back-
grounds, experience levels, and work roles. This sug-
gests that many different practitioners can potentially
beneﬁt from this hands-on approach, supporting ﬁndings
from Kolb & Kolb [31] and Bandura [6].
Mentoring and peer partnering. Multiple participants
mentioned a desire for social and organizational support
to facilitate the adoption of threat modeling. In their 30-
day follow-up surveys, P18 and P24 stated that NYC3
would need organizational programs in place to aid wide-
scale adoption of threat modeling, such as pairing ju-
nior personnel with mentors and facilitating peer-to-peer
partnerships. During their performance evaluation ses-
sions, P09 and P19 both mentioned that threat modeling
would also be useful for integrating new personnel into
NYC3. We hypothesize that pairing experienced em-
ployees with junior personnel could permit mentors to
orient their mentee to the environment and provide con-
text to ongoing defensive initiatives, all while reinforcing
their own understanding of threat modeling.
After
Further, the NYC3 leadership panel results indicated
that 9 of 25 actionable defense plans were insufﬁciently
detailed for immediate implementation. Peering would
allow small teams to challenge one another and elicit
details until results are adequately robust. This ac-
cords with prior studies of threat-modeling techniques,
as well as peer partnering examples from other do-
mains, that demonstrate the beneﬁts of peer collabora-
tion [9, 14, 15, 20, 24, 25, 28, 34, 35, 37, 38, 42, 46, 53].
Communication with leadership.
threat-
modeling training, participants reported that they were
better able to communicate the importance of various
threats to NYC3 leadership. This was reﬂected in the
immediate deployment of mitigation strategies, as dis-
cussed in Section 4.5. We hypothesize that use of a sin-
gle threat modeling framework — in this case CoG —
across administrative boundaries may help to facilitate
a shared language within the organization for commu-
nicating about threats. It would be particularly interest-
ing to explicitly evaluate whether training executive-level
leadership along with on-the-ground practitioners might
yield useful communication beneﬁts.
Shortcomings. Knowledge retention results show that
participants struggled with framework-speciﬁc terminol-
ogy; only 17 of 25 participants correctly identiﬁed crit-
ical requirements after 30 days. When institutionalizing
threat modeling, it may be helpful to provide learners
with quick-reference guides containing relatable exam-
ples to help clarify essential terminology.
5.2 Future work
In this work we took advantage of a unique coop-
erative opportunity to evaluate the introduction of an
exemplar threat-modeling approach into an enterprise
environment.
In future work, comparative evaluation
— ideally also in real-world environments — is neces-
sary to understand the relative effectiveness of different
threat-modeling approaches and may also help to clar-
ify in what situations and environments different threat-
modeling approaches are likely to be most effective.
To this end, we suggest that threat modeling should be
tested in multiple environments, to understand when and
why these frameworks should be applied. Future evalua-
tions may be able to consider how organization size, ex-
perience level and typical workload of staff members, or-
ganizational culture, and existing threat-modeling and/or
security-analysis processes affect the efﬁcacy of threat
modeling. Future work should also explore less tangible
organizational characteristics, such as employees’ under-
USENIX Association
27th USENIX Security Symposium    633
standing of organizational objectives, hierarchical struc-
ture, lines of communication within and across groups,
and the empowerment given to mid-level leaders.
In summary, our results indicate that introducing threat
modeling — in this case, CoG — was useful for helping
a large enterprise organization utilize existing resources
more effectively to mitigate security threats. These ﬁnd-
ings underscore the importance of future evaluations ex-
ploring when and why this result generalizes to other
real-world environments.
Notes
1 NYC3 was formerly known as the Department of Information
Technology & Telecommunications Citywide Cybersecurity Division,
which was subsumed by NYC3 midway through this study [13]. For
convenience, we only refer to the organization as NYC3.
2 Due to operational security risks, we do not name speciﬁc vendor
solutions.
3 Endpoint Detection and Response (EDR) describes a suite of tools
focused on detecting and investigating suspicious activities, intrusions,
and other problems on endpoint systems.
4 NYC3 deployed additional defensive capabilities based on ADPs
that also assisted with detection, but are not described here in order to
protect operational security concerns.
References
[1] AKAIKE, H. A new look at the statistical model identiﬁcation.
IEEE transactions on automatic control 19, 6 (1974), 716–723.
[2] AMAZON. Summary of the Amazon S3 Service Disruption in the
Northern Virginia (US-EAST-1) Region.
[3] ATKINSON, J. W. Motivational determinants of risk-taking be-
havior. Psychological review 64, 6p1 (1957), 359.
[4] BANDURA, A. Perceived self-efﬁcacy in cognitive development
and functioning. Educational psychologist 28, 2 (1993), 117–
148.
[5] BANDURA, A. Guide for constructing self-efﬁcacy scales. Self-
efﬁcacy beliefs of adolescents 5, 307-337 (2006).
[6] BANDURA, A., AND WALTERS, R. H. Social learning theory.
Prentice-Hall Englewood Cliffs, NJ, 1977.
[7] CHUVAKIN, A. Named: Endpoint Threat Detection & Response,
2013.
[8] CLEARY, C. DEF CON 19: Operational Use of Offensive Cyber.
[9] CLELAND-HUANG, J. How well do you know your personae
non gratae? IEEE software 31, 4 (2014), 28–31.
[10] COLWILL, C. Human factors in information security: The in-
sider threat–who can you trust these days? Information security
technical report 14, 4 (2009), 186–196.
[11] CONTI, G., AND RAYMOND, D. On Cyber: Towards an Opera-
tional Art for Cyber Conﬂict. Kopidion Press, 2017.
[12] DAVIS, F. D. Perceived usefulness, perceived ease of use, and
user acceptance of information technology. MIS quarterly (1989),
319–340.
[13] DE BLASIO, B. Executive Order 28: New York City Cyber Com-
mand, 2017.
[14] DENNING, T., FRIEDMAN, B., AND KOHNO, T. The Security
Cards: A Security Threat Brainstorming Toolkit.
[16] EDWARDS, A. L. The social desirability variable in personality
assessment and research.
[17] EIKMEIER, D. C. Center of gravity analysis. Military Review
84, 4 (2004), 2–5.