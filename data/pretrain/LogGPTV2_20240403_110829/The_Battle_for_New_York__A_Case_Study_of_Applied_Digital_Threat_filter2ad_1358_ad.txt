### USENIX Association

#### Implementing Periodic, Mandatory Readiness Tests Across All NYC Networks
NYC3 has implemented periodic, mandatory readiness tests across all networks to ensure continuous operational preparedness.

#### Securing Accounts
Several participants identified user account permissions as a critical but often poorly managed security control. It is common for employees to retain unnecessary permissions after changing roles within the organization. To address this, NYC3 now conducts monthly audits and re-certification of user access to minimize the risk of insider threats or stolen credentials. Additionally, seven participants recommended implementing multi-factor authentication (MFA). As a proof of concept, NYC3 successfully deployed MFA for 80 user accounts within a monitored subdomain.

#### Protecting Physical Network Assets
Seven participants highlighted that weak physical access controls to networking infrastructure could create significant vulnerabilities. While insider threats are a concern, accidental damage was identified as the most likely threat. Three participants specifically mentioned the risks of power outages or surges, which could cause prolonged issues. They recommended security escorts and multi-factor access control near all networking infrastructure. Since the performance evaluation sessions, NYC3 has been collaborating with federal, state, and private-sector entities to enhance physical security measures.

#### Crowdsourcing Assessments
Two participants noted that automated vulnerability assessment tools may not detect all vulnerabilities, emphasizing the need for manual testing. Consequently, P21 recommended establishing a bug bounty program for public-facing services to leverage the collective expertise of the security community. Following this recommendation, NYC3 partnered with a bug bounty service provider to conduct a 24-hour proof-of-concept assessment on one of its web services.

#### Sensor Coverage
Ten participants acknowledged the vastness of the NYC environment, making manual monitoring impractical. Automated sensors play a crucial role in defense, and gaps in sensor coverage can lead to unprotected systems. Four participants suggested deploying additional Endpoint Detection and Response (EDR) sensors in specific subdomains with limited visibility. Within 30 days after the threat modeling training, NYC3 technicians deployed 1331 new EDR sensors.

#### Protecting Legacy Systems
Three participants stated that legacy systems significantly impact their ability to secure the network. Some of these systems, installed decades ago, were never intended to be networked. They recommended segmenting non-critical legacy systems until they can be replaced or upgraded. NYC3 is now working closely with partners to protect these segmented systems and those that must remain online.

#### Testing Readiness
Nine participants emphasized the importance of resilient systems and identified untested disaster recovery plans as a critical vulnerability. To mitigate the impact of cyber attacks, natural disasters, or terrorist attacks, they recommended frequent testing of multiple "fail-over" sites to validate functionality. NYC3 has begun testing fail-over servers within their local domain and plans to expand this practice.

#### Data Corruption Protection
Participants P02 and P17 identified data corruption as a significant risk. NYC3 technicians now verify the integrity of each software and indicator of compromise (IOC) update provided by third-party vendors to prevent exploitation, as seen in the 2017 NotPetya malware outbreak.

#### Reducing Human Error
Human error was a common theme in the threat landscape. Six participants noted that simple typos in configuration scripts, like the one that caused the 2017 Amazon S3 outage, could have significant impacts. Three defenders recommended two-person change control for updating configuration files on firewalls and EDR systems. This process requires one person to propose a change and another to review and implement it, reducing the likelihood of human error. NYC3 now enforces two-person change control on all modifications to access control lists.

### Observations After 120 Days
Observing NYC3’s environment 120 days after the study concluded provides insight into the longer-term impact of threat modeling. NYC3 implemented eight new categories of controls based on the Actionable Defense Plans (ADPs) developed by participants. NYC3 also provided access to server logs, alert dashboards, and vulnerability reports to measure the efficacy of three of these new controls.

#### Actual Adoption
NYC3 leaders monitored the implementation of ADPs using a priorities board, and all mitigation strategies remained in place 120 days after the study. Below are high-level details about some of the ADPs to avoid compromising NYC3 systems:

- **Testing Readiness**: NYC3 has begun testing fail-over servers and plans to expand this practice.
- **Securing Accounts**: Multi-factor authentication and regular audits have been implemented.
- **Crowdsourcing Assessments**: A successful 24-hour bug bounty trial program led to the discovery and patching of three previously unknown vulnerabilities.
- **Sensor Coverage**: The deployment of 1331 new EDR sensors has enabled the detection and response to 541 unique intrusion attempts.
- **Protecting Legacy Systems**: Segmentation and protection of non-critical legacy systems are ongoing.
- **Data Corruption Protection**: Verification of software and IOC updates is now standard.
- **Reducing Human Error**: Two-person change control is enforced for all critical modifications.

#### Actual Efficacy
Quantitative metrics from the 120 days post-training support the efficacy of threat modeling. For example:
- **Securing Accounts**: NYC3 recorded 3749 failed login attempts, with 3731 attributed to employees forgetting their passwords. Seven privileged user accounts were protected from hijacking attempts due to multi-factor authentication and password lockout mechanisms.
- **Crowdsourcing Assessments**: The bug bounty trial program resulted in the discovery and remediation of three vulnerabilities in a public web server.
- **Sensor Coverage**: The new EDR sensors detected 541 unique intrusion attempts, with 59 labeled critical and 135 high severity. These events could have led to successful attacks if not for the new sensors.

### Discussion and Conclusions
This study provides the first structured evaluation of introducing threat modeling to a large-scale enterprise environment. The findings suggest that threat modeling, particularly the CoG framework, was an effective and efficient mechanism for developing actionable defense plans. Even a small amount of focused threat modeling by IT personnel with no prior experience produced measurable, positive results.

#### Lessons Learned
- **Hands-on Learning**: Participants found the hands-on approach to teaching threat modeling highly effective.
- **Mentoring and Peer Partnering**: Social and organizational support, such as mentoring and peer partnerships, can facilitate the adoption of threat modeling.
- **Communication with Leadership**: Threat modeling helped participants better communicate the importance of various threats to leadership, leading to the immediate deployment of mitigation strategies.
- **Shortcomings**: Knowledge retention of framework-specific terminology was a challenge, suggesting the need for quick-reference guides.

#### Future Work
Future work should include comparative evaluations in real-world environments to understand the relative effectiveness of different threat-modeling approaches. Evaluations should consider factors such as organization size, experience level, workload, culture, and existing security processes. Additionally, less tangible organizational characteristics, such as hierarchical structure and lines of communication, should be explored.

In summary, introducing threat modeling, specifically the CoG framework, was useful for helping a large enterprise organization utilize existing resources more effectively to mitigate security threats. These findings underscore the importance of future evaluations to explore the generalizability of these results in other real-world environments.

### Notes
1. NYC3 was formerly known as the Department of Information Technology & Telecommunications Citywide Cybersecurity Division, which was subsumed by NYC3 midway through this study [13].
2. Specific vendor solutions are not named due to operational security risks.
3. EDR describes a suite of tools focused on detecting and investigating suspicious activities, intrusions, and other problems on endpoint systems.
4. Additional defensive capabilities based on ADPs, not described here, were also deployed to protect operational security concerns.

### References
[1] AKAIKE, H. A new look at the statistical model identification. IEEE transactions on automatic control 19, 6 (1974), 716–723.
[2] AMAZON. Summary of the Amazon S3 Service Disruption in the Northern Virginia (US-EAST-1) Region.
[3] ATKINSON, J. W. Motivational determinants of risk-taking behavior. Psychological review 64, 6p1 (1957), 359.
[4] BANDURA, A. Perceived self-efficacy in cognitive development and functioning. Educational psychologist 28, 2 (1993), 117–148.
[5] BANDURA, A. Guide for constructing self-efficacy scales. Self-efficacy beliefs of adolescents 5, 307-337 (2006).
[6] BANDURA, A., AND WALTERS, R. H. Social learning theory. Prentice-Hall Englewood Cliffs, NJ, 1977.
[7] CHUVAKIN, A. Named: Endpoint Threat Detection & Response, 2013.
[8] CLEARY, C. DEF CON 19: Operational Use of Offensive Cyber.
[9] CLELAND-HUANG, J. How well do you know your personae non gratae? IEEE software 31, 4 (2014), 28–31.
[10] COLWILL, C. Human factors in information security: The insider threat–who can you trust these days? Information security technical report 14, 4 (2009), 186–196.
[11] CONTI, G., AND RAYMOND, D. On Cyber: Towards an Operational Art for Cyber Conflict. Kopidion Press, 2017.
[12] DAVIS, F. D. Perceived usefulness, perceived ease of use, and user acceptance of information technology. MIS quarterly (1989), 319–340.
[13] DE BLASIO, B. Executive Order 28: New York City Cyber Command, 2017.
[14] DENNING, T., FRIEDMAN, B., AND KOHNO, T. The Security Cards: A Security Threat Brainstorming Toolkit.
[16] EDWARDS, A. L. The social desirability variable in personality assessment and research.
[17] EIKMEIER, D. C. Center of gravity analysis. Military Review 84, 4 (2004), 2–5.