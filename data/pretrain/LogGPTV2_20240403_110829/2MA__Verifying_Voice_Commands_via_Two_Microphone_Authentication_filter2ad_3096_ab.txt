Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor
Figure 4: Any audio source in a room can broadcast malicious commands to the victim’s home assistant. 2MA is designed
to detect such commands by locating its source and only accepting the command if the source is closer to the user’s mobile
device.
case of audio, small changes (e.g., background noise) would com-
pute two vastly different hash values for two audio samples even
if they heard the same command. To determine if both recorded
commands are the same, we use Robust Sound Hash (RSH): a digest
function that is capable of summarizing the content of an audio
signal [29]. Unlike cryptographic hashes that change drastically in
response to minor variance in the input, RSH is designed to change
slightly as noise is added. In other words, RSH will produce a similar
speech digest2 value for a signal even if the signal has been altered
by background noises. This allows RSH to capture unique features of
the input; in our case, semantics of a sentence or the words spoken.
We use the Jiao et al. RSH construction [29] for our system, which
is described at a high level in Figure 2. To make an RSH hash, an
audio sample is first divided into one second intervals. These audio
intervals are then passed to a function (alongside a secret key) to
output a probabilistic 512-bit digest for each second in the input.
The whole speech digest would be the concatenation of all the one
second digests in the audio sample. To compare two different audio
samples, the hamming distance between the two speech digests
needs to be computed. This hamming distance would establish the
bit error rate (BER) between both samples. A lower BER rate would
mean that the two audio samples are similar to each other while
a higher BER would mean the inverse. In Figure 3, we show that
speech digests are robust in regards to two speakers speaking the
same sentence. However, if the same speaker speaks different sen-
tences, the speech digest error will be much higher. In our case, to
2To avoid confusion with cryptographic hashes, RSH will be called “speech digest” for
the rest of the paper.
determine the threshold of acceptable dissimilarity between two
audio sample, we will use the same parameters derived by Reaves
et al. [40] since they evaluated RSH in an adversarial setting.
We note that applying RSH in an adversarial environment is not a
simple matter. Accordingly, properly parameterizing this algorithm
to this specific context is a contribution of this work.
4 SECURITY MODEL
We now define our security model and adversarial abilities.
Assumptions: 2MA assumes that the user is in constant possession
of their mobile device. This allows us to identify the user by the po-
sition of their mobile device. 2MA also needs a confidential channel
during an initialization phase but does not assume a confidential
channel while commands are being heard by the voice operated
device. This simulates actual operating conditions (i.e., voice com-
mands to such devices are said in the clear). Lastly, we also assume
that the mobile device, voice controlled device, and cloud system
are not compromised. Any other device (e.g., IoT systems) may
be compromised. These assumption are similar to traditional 2FA
models.
Adversaries: The goal of the adversary is to inject a malicious com-
mand to the voice operated device owned by the user. The em-
bodiment of the adversary can vary from a friend or neighbor to
a compromised device capable of emiting audio or a TV [3, 9].
Commands injected by the adversary can exercise the full range
of commands available to authorized users, including but not lim-
ited to adding items to a shopping list, setting alarms, or make
unauthorized purchase using the user’s credentials that are stored
Session 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea922MA: Verifying Voice Commands via
Two Microphone Authentication
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
to authenticate the command to the user and to determine if the
command recorded at the home assistant is similar to the command
heard on the mobile device. We make use of an audio channel and
a network channel to communicate between both devices.
Our protocol consist of two phases: During the first phase, the
mobile device and the home assistant perform a one-time initializa-
tion where they derive a shared secret K. There are multiple means
by which K can be derived; we point the reader to the literature on
authenticated key exchange for more information as this is not a
contribution of this work.
Phase Two occurs when the user speaks a command. At this
time (denoted by Step 1), both the mobile device and home assistant
locally compute a speech digest (RSHp and RSHh, respectively). The
mobile device then computes HMAC(K, RSHp||Tp ), where RSHp is
the speech digest at the mobile device, Tp is the time when the
mobile device first receives the audio command, and K is the shared
secret between the two devices. Note that both the mobile device
and home assistant have tightly synchronized clocks via that mech-
anisms discussed earlier in the paper. In compliance to NIST stan-
dards [37], the mobile device then truncates the HMAC to 32-bits
and uses this value to create a tone that will be sent to the home
assistant via the audio channel.3 This truncated value is necessary
because the audio channel has limited bandwidth for robust acous-
tic signaling [40]. In parallel, the mobile device also constructs a
string of form RSHp||Tp||HMAC(K, RSHp||Tp ) and sends it to the
home assistant via the network channel.
In Step 2, the home assistant first validates if the string received
from the mobile device is authentic by parsing out the values RSHp
and Tp and recomputing the HMAC as above. Validating the HMAC
tells the home assistant that the string is authentic to the mobile
device of the user and that it was received at time Tp. However,
this does not tell the home assistant whether or not the command
heard at the mobile device is the same as the command heard
locally. Thus, to authenticate the command, the home assistant
passes the locally recorded audio and the speech digest RSHp from
the mobile device through an audio similarity filter (we give more
details on its construction in Section 6.2) that will determine if
both commands are similar. Once the filter outputs a result, the
home assistant will then send through the network a string of form
RSHh||Th||M||HMAC(K, RSHh||Th||M ) where RSHh is the speech di-
gest of the command heard at the mobile device, Th is the time
when the command was first recognized, and M indicates if the
commands were a match with each other. If so, the home assistant
will execute the actual command and output the results through
the audio channel. Otherwise, the home assistant will alert the user
of the failed command. Alerting the mobile device of this operation
allows it to log all commands executed by the home assistant under
its authorization.
6 SYSTEM ARCHITECTURE
We designed and constructed this emboddiment of a 2MA system
based on two main mechanisms; Command Location Bounding
3NIST 800-107, an HMAC of a strong algorithm can securely be truncated as needed
by applications. This standard specifically identifies truncation to as short as 32-bits
for audio applications because the real-time nature of audio makes it unlikely that
an adversary can successfully attack such a system. Accordingly, our approach is
compliant with best-practices.
Figure 5: 2MA uses the audio and network channel to au-
thenticate commands.
in the voice controlled device [3]. Moreover, voice commands can
be both understandable to a nearby user or outside of the range
of normal human comprehension [20, 44, 45]. As an example, an
adversary outside the target environment may leverage the lack
of authentication to inject commands that physically gain access
to the home (e.g., unlock the front door). We show the possible
adversaries in a home environment in Figure 4.
The above scenario assumes that the voice controlled device is
in a location where the user has permanent control, such as a home.
However, the voice controlled device could also be located in a
contested space where the user only has temporary ownership of the
device. Contested spaces include hotel rooms, rental cars, and public
spaces. An adversary will have the same capabilities in both settings;
however, contested spaces add new challenges to voice controlled
devices. For example, a user may temporarily assume ownership
of a built-in voice control device while staying in a hotel room.
Here, the previous tenant of the room is considered an adversary
as he/she could have left a wireless speaker in order to inject future
malicious commands to the voice controlled device. Additionally,
at the time of departure from the hotel, the voice controlled device
is left unattended and may still contain user’s credentials. In this
case, the next tenant may inject malicious commands to the voice
controlled device using the credentials left behind by the user. The
problem in either case is that the user is only in possession of the
voice controlled device for a limited time. Because users will not
stay such environments for a long time, solutions such as biometrics
are not appropriate (and remain vulnerable to replay attacks).
Security Goals: Given the above assumptions and adversaries, the
goal of any 2MA system is to tie the source of a voice command to
the holder of a mobile device, thereby stopping the above adver-
saries from being able to inject malicious commands. Legitimate
commands should not be replayable, nor should hidden/inaudible
commands be accepted.
5 AUDIO AUTHENTICATION PROTOCOL
Figure 5 details our audio authentication protocol. While 2MA may
be more broadly embodied, this specific protocol is designed to be
used between a mobile device and a voice operated home assistant
(e.g., Amazon Echo/Google Home). The goal of the protocol is
Trunc(HMAC(K,RSHp||Tp))RSHh||Th||M||HMAC(K,RSHh||Th||M)RSHp||Tp||HMAC(K,RSHp||Tp)Initialization(KeyEstablishment)Mobile DeviceVoice Operated Device1. 0. 2. [“Nothing”/“RepeatCommand”]Network ChannelAudio ChannelOne Time ProcessContinuos ProcessAudio CommandSession 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea93ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
Logan Blue, Hadi Abdullah, Luis Vargas, and Patrick Traynor
Figure 6: Our command filter first ensures that the audio heard in the mobile device is similar to that of the voice operated
device. Then, to stop hidden commands, the filter generates a new audio from the extracted command heard at the voice
operated device and compares this audio to the original for similarity.
and Audio Similarity Filtering. Command Location Bounding is
used to define an area from which non-malicious commands should
originate from. Audio Similarity Filtering ensures that the audio
detected at both the mobile device and the home assistant share
similar characteristic to avoid inaudible/malicious command injec-
tion. Through the protocl described in the previous section and its
instantiation as a system in this section, we achieve the security
goals established in Section 4.
6.1 Command Location Bounding
Home assistants execute all commands that they hear. By accepting
all commands, home assistants rely solely on their physical security
to prevent malicious command injection. Since not all potential
deployment locations for home assistants are physically secure,
we need a more robust security measure. This technique attests
to the authenticity of a command by colocating the source of the
audio and the user’s mobile device. By forcing this constraint onto
a command, we limit the physical area from which an attack could
originate.
We calculate the DOA of the audio command as our location
metric. Although DOA is not able to derive the exact location of
either the mobile device or the command’s origin, DOA can be used
to derive the direction from and bounds for the origin of a sound.
By using directionality, we can remove the majority of the physi-
cal locations in a region. While highly precise distance bounding
protocols would provide greater localization [18, 19, 28, 38, 39], the
specialized radios necessary to implement such protocols are not
available on any mass-marketed smartphone or home assistant. In-
stead, we select components that are already widely deployed on all
systems and could be activated via software update. The inclusion
of such radios could be used as part of another embodiment of a
2MA system, and we leave that exercise to future work.
We construct the chirp emitted by the mobile device as described
in Step 1 of our protocol from Section 4. The chirp is generated in
the 20 KHz range to make it inaudible to human hearing (thereby
minimizing any negative impact on user experience). We use this
chirp to calculate DOAP (DOA of the mobile device), and then add
the system tolerance for deviation from that direction. If DOAV
(DOA of the voice) falls within that tolerance, it is passed on to the
next phase of processing.
We note that an adversary operating in the absence of a user
would not be able to execute an attack. Specifically, if the user’s
mobile device is not in the room, the command will be rejected
because no chrip (yet alone a correct one) will be generated.
6.2 Audio Similarity Filter
Location bounding allows us to eliminate commands (audible to
the user or otherwise) that originate outside of the directional
cone. However, an adversary within the cone may still be able
to inject commands. All systems allow a present user to verbally
cancel commands they can hear; accordingly, we need to ensure
that inaudible commands [20, 44, 45] originating within the cone
can not activate the home assistant.
The first goal of our filter is to ensure that the same command is
heard at both the mobile device and the home assistant. Without such
a protection, an adversary may attempt a relay attack or to inject
garbled (but audible) audio [44]. Figure 6 shows the construction of
our audio similarity filter. As inputs, we get the audio recorded at
the home assistant and the speech digest RSHp that was extracted
from the string sent by the mobile device. The home assistant then
computes the speech digest RSHh of the locally stored audio and
the hamming distance between RSHp and RSHh. We use a simple
majority rule to determine if RSHp and RSHh are similar to each other.
We set our BER threshold for this comparison at 0.384, which was
Voice Operated Device AudioSimilar?Speech Digest: Mobile DeviceSpeech Digest: Voice Operated DeviceSpeech to Text (STT)Text to Speech (TTS)Similar?Speech Digest: TTSSpeech Digest: Voice Operated DevicePass/FailResample and remove silenceSession 3: AuthenticationASIACCS’18, June 4–8, 2018, Incheon, Republic of Korea942MA: Verifying Voice Commands via
Two Microphone Authentication
previously derived by Reaves et al., [40]; however, we independently
validated this setting.
However, the home assistant is still vulnerable to hidden com-
mands, or commands that are unintelligible to human hearing but
still register as an actual command to the home assistant [20, 45].
To stop this, our system uses the audio recorded at the home assis-
tant and passes it through a speech to text (STT) module4. If the
module does not transcribe the audio sample, the input is rejected.
The home assistant then passes correctly transcribed commands
through a text to speech (TTS) module. We can then compare this
new audio sample to the original audio using RSH.
The new audio signal may not have the same characteristics
or duration as the original audio. This is a common occurrence
because the original audio may contain silence at the beginning
or end of the audio or during long pauses between words, as is
common in a normal conversation. Additionally, the original audio
may have been sampled at a different rate than the new audio. To
fix these problems, we first trim silence. We then resample the new
audio for the same duration as the original audio. We do this so that
words heard in each audio match as close a possible with each other
in regards to when the command was said. We then recompute the
RSH value of trimmed original audio and compute the RSH value of
the new audio.
Second, since we are actively changing the speaker of the new
audio by using the TTS module (i.e., the speaker is no longer the
user), comparing the newly generated digests would have a higher
probability of failing if we were to use the original BER threshold of
0.384. As such, we used the TIMIT corpus [2]5 to derive a new BER
that would be receptive to the subtle changes of speakers (i.e., the
user and a machine generated voice command). We used the corpus
to represent audio that would be recorded on the home assistant
and the text file in the corpus to derive new audio by passing it
through our TTS module. In total we used 2, 310 different audio
clips that contain 7, 453 seconds of sample date. We calculated an
average BER of 0.4105 with a median of 0.4238. From those, we used
0.4105 as our new BER for our second speech digest comparison in
our audio filter. These parameters allow us to accurately determine
if the audio heard matches the command that was derived.
Finally, with our new threshold rate of 0.4105, we now compare
the speech digests of the trimmed original file and the new audio
generated by the TTS module to determine if both are similar. In
the case of a benign command, the second comparison would pass.
However, in the case of a hidden command, the distorted audio
input would not.
7 EXPERIMENTS
We perform a number of experiments to characterize our system
and design choices. Our first three experiments find minimum au-
dio levels and test seemingly equivalent (but flawed) alternative
designs. We perform these tests using a Music Angel JH-MD5BT
Bluetooth speaker [1] and 2 Huawei Nexus 6Ps, 2 Google Pixels,
and 2 Samsung Galaxy S8s as our mobile devices. We then focus
on our proposed design and measure the accuracy of the DOA and
4We treat the speech to text module as a black box and make no assumption on the
underlying algorithms.
5The TIMIT Audio Corpus is viewed as the “gold standard” for audio testing and is
therefore the most appropriate audio for calibration and testing.
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
RSH. Through these experiments, we demonstrate that our pro-