```
{
  "builders": [
    {
      "ami_description": "Cluster Node Image",
      "ami_name": "cluster-node",
      "associate_public_ip_address": true,
      "force_delete_snapshot": true,
      "force_deregister": true,
      "instance_type": "m3.medium",
      "region": "us-west-1",
      "source_ami": "ami-1c1d217c",
      "ssh_username": "ubuntu",
      "type": "amazon-ebs"
    }
  ],
  "provisioners": [
    {
      "inline": "sudo apt-get update && sudo apt-get install -y ansible",
      "type": "shell"
    },
    {
      "playbook_dir": ".",
      "playbook_file": "swarm_node.yml",
      "type": "ansible-local"
    }
  ]
}
```
如果不明显，我们在这个配置文件中有`provisioners`和`builders`部分，它们通常分别对应于 Packer 输入和输出。在前面的示例中，我们首先通过`shell`资源调配器安装 Ansible，因为下一步需要它，然后在基本 AMI 上使用`ansible-local`资源调配器从当前目录运行`main.yml`剧本。应用所有更改后，我们将结果保存为新的**弹性块存储** ( **EBS** )优化的 AMI 映像。
AWS **Elastic Block Store** (**EBS**) is a service that provides block device storage to EC2 instances (these instances are basically just VMs). To the machine, these look like regular hard disks and can be formatted to whatever filesystem you want and are used to persist data in a permanent manner in the Amazon Cloud. They have configurable size and levels of performance; however, as you might expect, the price goes up as those two settings increase. The only other thing to keep in mind is that while you can move the drive around EC2 instances just like you would move a physical disk, you cannot move an EBS volume across availability zones. A simple workaround is to copy the data over. "AMI image" phrase expands into "Amazon Machine Image image", which is a really quirky way to phrase things, but just like the sister phrase "PIN number", it flows much better when used that way and will be intentionally referred to in that way in this section. If you're curious about this particularity of the English language, you should peruse the Wiki page for RAS syndrome at [https://en.wikipedia.org/wiki/RAS_syndrome](https://en.wikipedia.org/wiki/RAS_syndrome).
对于构建器部分，更详细地解释一些参数将会有所帮助，因为它们在阅读 JSON 文件时可能并不明显:
```
- type: What type of image are we building (EBS-optimized one in our case).
- region: What region will this AMI build in.
- source_ami: What is our base AMI? See section below for more info on this.
- instance_type: Type of instance to use when building the AMI - bigger machine == faster builds.
- ami_name: Name of the AMI that will appear in the UI.
- ami_description: Description for the AMI.
- ssh_username: What username to use to connect to base AMI. For Ubuntu, this is usually "ubuntu".
- associate_public_ip_address: Do we want this builder to have an external IP. Usually this needs to be true.
- force_delete_snapshot: Do we want to delete the old block device snapshot if same AMI is rebuilt?
- force_deregister: Do we want to replace the old AMI when rebuilding?
```
You can find more information on this particular builder type and its available options at [https://www.packer.io/docs/builders/amazon-ebs.html](https://www.packer.io/docs/builders/amazon-ebs.html).
# 选择正确的急性心肌梗死基础映像
与我们在前面章节中介绍的选择基本 Docker 映像进行扩展不同，选择正确的 AMI 来使用 Packer 并不是一件简单的事情。有些发行版会定期更新，所以标识会改变。每个 AWS 区域的标识也是唯一的，您可能需要硬件或半虚拟化(`HVM` vs `PV`)。除此之外，在撰写本书时，您还必须根据您的存储需求选择合适的存储设备(`instance-store`、`ebs`和`ebs-ssd`，从而创建一个绝对不直观的选项矩阵。
如果您没有使用过亚马逊**弹性计算云** ( **EC2** )和 EBS，存储选项对新手来说有点混乱，但它们的含义如下:
*   `instance-store`:这种类型的存储对于正在运行的 EC2 虚拟机来说是本地的，其空间因虚拟机类型而异(尽管通常很少)，并且在虚拟机终止时被完全丢弃(尽管停止或重新启动的虚拟机保持其状态)。实例存储非常适合不需要保留任何状态的节点，但不应用于希望保留数据的计算机；但是，如果您希望拥有持久存储并利用无状态存储，您可以将单独的 EBS 驱动器独立装载到实例存储虚拟机。
*   `ebs`:这种存储类型会在 EC2 实例使用此特定映像启动时，创建并关联一个 EBS 卷，该卷由较旧的磁旋转硬盘(相对较慢的固态硬盘)支持，因此数据始终保留在周围。如果您想保留数据或者`instance-store`卷不够大，这个选项是很好的。然而，从今天开始，这个选项被积极地否决了，所以它很可能会在未来消失。
*   `ebs-ssd`:该选项与前面的选项基本相同，但使用速度更快但每千兆字节分配成本更高的**固态设备**(固态硬盘)作为后备存储。
我们需要选择的另一件事是虚拟化类型:
*   半虚拟化/ `pv`:这种类型的虚拟化比较老，使用软件来链式加载您的映像，因此它能够在更加多样化的硬件上运行。虽然很久以前速度更快，但现在通常比硬件虚拟化慢。
*   硬件虚拟化/ `hvm`:这种类型的虚拟化使用 CPU 级指令在完全隔离的环境中运行您的映像，类似于直接在裸机硬件上运行映像。虽然它取决于特定的英特尔虚拟处理器技术实施，但它的性能通常比`pv`虚拟化好得多，因此在大多数情况下，您可能应该将其用于其他选项，尤其是在您不确定选择哪一个的情况下。
随着我们对可用选项的新了解，我们现在可以找出我们将使用什么映像作为基础。对于我们指定的操作系统版本(Ubuntu LTS)，您可以使用位于[https://cloud-images.ubuntu.com/locator/ec2/](https://cloud-images.ubuntu.com/locator/ec2/)的助手页面来找到正确的版本:
![](img/f511a6d3-c407-4306-9ed9-96b2001ee9e9.png)
对于我们的测试构建，我们将使用`us-west-1`区域、Ubuntu 16.04 LTS 版本(`xenial`)、64 位架构(`amd64`)、`hvm`虚拟化和`ebs-ssd`存储，因此我们可以使用页面底部的过滤器来缩小范围:
![](img/eec87b2e-beb9-4914-8734-b2fa6cb52c4c.png)
如您所见，列表折叠成一个选项，在我们的`packer.json`中，我们将使用`ami-1c1d217c`。
Since this list is updated with AMIs that have newer security patches, it is very likely that by the time you are reading this section the AMI ID will be something else on your end. Because of that, do not be alarmed if you see discrepancies between values we have found here and what you have available to you while reading of this chapter.
# 构建 AMI
WARNING! Running this Packer build will for sure incur some (albeit barely a couple of US dollars at the time of writing this book) charges on your AWS account due to usage of non-free instance type, snapshot use, and AMI use, some possibly recurring. Refer to the pricing documentation of AWS for those services to estimate the amount that you will be charged. As an additional note, it is also good practice to clean up everything either from the console or CLI after you finish working with AWS objects that will not be kept around since it will ensure that you do not get additional charges after working with this code. With the `packer.json` in place, we can now do a build of our image. We will first install the pre-requisites (`python-boto` and `awscli`), then check the access, and finally build our AMI:
```
$ # Install python-boto as it is a prerequisite for Amazon builders
$ # Also get awscli to check if credentials have been set correctly
$ sudo apt-get update && sudo apt-get install -y python-boto awscli
$ # Check that AWS API credentials are properly set. 
$ # If you see errors, consult the previous section on how to do this
$ aws ec2 describe-volumes 
{
 "Volumes": [
 ]
}
$ # Go to the proper directory if we are not in it
$ cd ~/ansible_deployment
$ # Build our AMI and use standardized output format
$ packer build -machine-readable packer.json 
1509439711,,ui,say,==> amazon-ebs: Provisioning with shell script: /tmp/packer-shell105349087
1509439739,,ui,message, amazon-ebs: Setting up ansible (2.0.0.2-2ubuntu1) ...
1509439741,,ui,message, amazon-ebs: Setting up python-selinux (2.4-3build2) ...
1509439744,,ui,say,==> amazon-ebs: Provisioning with Ansible...
1509439744,,ui,message, amazon-ebs: Uploading Playbook directory to Ansible staging directory...
1509439836,,ui,message, amazon-ebs: TASK [swarm_node : Installing Docker] ******************************************
1509439855,,ui,message, amazon-ebs: [0;33mchanged: [127.0.0.1][0m
1509439855,,ui,message, amazon-ebs:
1509439855,,ui,message, amazon-ebs: PLAY RECAP *********************************************************************
1509439855,,ui,message, amazon-ebs: [0;33m127.0.0.1[0m : [0;32mok[0m[0;32m=[0m[0;32m10[0m [0;33mchanged[0m[0;33m=[0m[0;33m9[0m unreachable=0 failed=0
1509439855,,ui,message, amazon-ebs:
1509439855,,ui,say,==> amazon-ebs: Stopping the source instance...
1509439970,,ui,say,Build 'amazon-ebs' finished.
1509439970,,ui,say,--> amazon-ebs: AMIs were created:\nus-west-1: ami-a694a8c6\n
```
成功！有了这个新的映像 ID，你可以在输出的最后看到(`ami-a694a8c6`)，我们现在可以用这个 AMI 在 EC2 中启动实例，它们将拥有我们已经应用的所有调整以及预安装的 Docker！
# 部署到 aws
由于只有裸映像，没有虚拟机运行它们，我们之前的 Packer 工作还没有让我们完全进入自动化工作状态。为了真正做到这一点，我们现在需要用更多的粘合剂将所有东西绑在一起，以完成部署。不同阶段的封装层次结构在概念上应该如下所示:
![](img/fb5786d9-1667-4f2e-ad80-13b41a517013.png)
从图中可以看出，我们将采用分层的部署方法:
*   在最内层，我们有 Ansible 脚本将一台裸机、虚拟机或一个 AMI 带到我们希望它处于的配置状态。
*   Packer 封装了这一过程，并生成静态的 AMI 映像，这些映像可在亚马逊 EC2 云产品上进一步使用。
*   Ansible 最后通过用那些静态的、Packer 创建的映像部署机器来封装前面提到的一切。
# 自动化基础架构部署之路
既然我们知道自己想要什么，我们该怎么做？对我们来说幸运的是，正如前面列表中所暗示的，Ansible 可以为我们完成这一部分；我们只需要编写几个配置文件。但是 AWS 在这里非常复杂，所以它不会像仅仅启动一个实例那么简单，因为我们想要一个隔离的 VPC 环境。然而，由于我们将只管理一台服务器，我们并不真正关心 VPC 内部的网络，所以这将使事情变得简单一点。
我们首先需要考虑需要采取的所有步骤。其中一些对大多数人来说是非常陌生的，因为 AWS 非常复杂，大多数开发人员通常不会在网络上工作，但它们是在不破坏您的帐户默认设置的情况下获得孤立的 VPC 的最基本的必要步骤:
*   为特定的虚拟网络设置 VPC。
*   创建并绑定一个子网。没有这个，我们的机器将无法在上面使用网络。
*   设置一个虚拟互联网网关，并将其连接到 VPC，以查找带有路由表的无法解析的地址。如果我们不这样做，机器将无法使用互联网。
*   设置一个安全组(防火墙)白名单的端口，我们希望能够访问我们的服务器(SSH 和 HTTP 端口)。默认情况下，所有端口都被阻止，这样可以确保启动的实例是可访问的。
*   最后，使用为网络配置的 VPC 配置虚拟机实例。
为了推倒一切，我们需要做同样的事情，但只是反过来。
首先，我们需要一些将在部署和拆卸行动手册中共享的变量。在与本章中我们一直在研究的大型 Ansible 示例相同的目录中创建一个`group_vars/all`文件:
```
# Region that will accompany all AWS-related module usages
aws_region: us-west-1
# ID of our Packer-built AMI
cluster_node_ami: ami-a694a8c6
# Key name that will be used to manage the instances. Do not
# worry about what this is right now - we will create it in a bit
ssh_key_name: swarm_key
# Define the internal IP network for the VPC
swarm_vpc_cidr: "172.31.0.0/16"
```
现在我们可以在`packer.json`所在的同一个目录中编写`deploy.yml`，使用其中的一些变量:
The difficulties of this deployment is starting to scale up significantly from our previous examples and there is no good way to cover all the information that is spread between dozens of AWS, networking, and Ansible topics to describe it in a concise way, but here are some links to the modules we will use that, if possible, you should read before proceeding:
- [https://docs.ansible.com/ansible/latest/ec2_vpc_net_module.html](https://docs.ansible.com/ansible/latest/ec2_vpc_net_module.html)
- [https://docs.ansible.com/ansible/latest/set_fact_module.html](https://docs.ansible.com/ansible/latest/set_fact_module.html)
- [https://docs.ansible.com/ansible/latest/ec2_vpc_subnet_module.html](https://docs.ansible.com/ansible/latest/ec2_vpc_subnet_module.html)
- [https://docs.ansible.com/ansible/latest/ec2_vpc_igw_module.html](https://docs.ansible.com/ansible/latest/ec2_vpc_igw_module.html)
- [https://docs.ansible.com/ansible/latest/ec2_vpc_route_table_module.html](https://docs.ansible.com/ansible/latest/ec2_vpc_route_table_module.html)
- [https://docs.ansible.com/ansible/latest/ec2_group_module.html](https://docs.ansible.com/ansible/latest/ec2_group_module.html)
- [https://docs.ansible.com/ansible/latest/ec2_module.html](https://docs.ansible.com/ansible/latest/ec2_module.html)
```
- hosts: localhost
 connection: local
 gather_facts: False
 tasks:
 - name: Setting up VPC
 ec2_vpc_net:
 region: "{{ aws_region }}"
 name: "Swarm VPC"
 cidr_block: "{{ swarm_vpc_cidr }}"
 register: swarm_vpc
 - set_fact:
 vpc: "{{ swarm_vpc.vpc }}"
 - name: Setting up the subnet tied to the VPC
 ec2_vpc_subnet:
 region: "{{ aws_region }}"
 vpc_id: "{{ vpc.id }}"
 cidr: "{{ swarm_vpc_cidr }}"
 resource_tags:
 Name: "Swarm subnet"
 register: swarm_subnet
 - name: Setting up the gateway for the VPC