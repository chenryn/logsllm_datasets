Encountering a MemoryError when creating a large sparse random matrix.  
The matrix is created with scipy.sparse.rand, and even if the density is low
enough that only a few elements in the whole matrix should be nonzero (or even
none at all), it still tries to allocate a large integer array.
I'm not sure if this really is a bug, or I'm just using the function wrong. I
know it's possible to create an empty sparse matrix and fill it with random
values manually. But I thought it a bit strange that it would try to allocate
that much.
#### Reproducing code example:
    from scipy.sparse import rand
    rand(10**5, 10**5, density=0) 
#### Error message:
    ---------------------------------------------------------------------------
    MemoryError                               Traceback (most recent call last)
     in 
    ----> 1 rand(10**5, 10**5, density=0)
    ~/anaconda3/lib/python3.7/site-packages/scipy/sparse/construct.py in rand(m, n, density, format, dtype, random_state)
        840 
        841     """
    --> 842     return random(m, n, density, format, dtype, random_state)
    ~/anaconda3/lib/python3.7/site-packages/scipy/sparse/construct.py in random(m, n, density, format, dtype, random_state, data_rvs)
        786             data_rvs = random_state.rand
        787 
    --> 788     ind = random_state.choice(mn, size=k, replace=False)
        789 
        790     j = np.floor(ind * 1. / m).astype(tp, copy=False)
    mtrand.pyx in numpy.random.mtrand.RandomState.choice()
    mtrand.pyx in numpy.random.mtrand.RandomState.permutation()
    MemoryError: Unable to allocate 74.5 GiB for an array with shape (10000000000,) and data type int64
#### Scipy/Numpy/Python version information:
    1.4.1 1.18.1 sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)