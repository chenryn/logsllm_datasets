...done.
你会注意到自己将rabbit@ip-10-170-30-18设置成了磁盘节点，同时也将
RabbitMQ节点名从rabbit更改成了rabbit_1，就像我们对开发机器集群上第二
个节点做的那样。在隔离的物理系统中，第一个RabbitMQ节点总是叫作rabbit。
只有当同一系统上有多个Rabbit节点时，节点名字才会命名为rabbit_1、
rabbit_2等。当设置完第二个节点后，让我们添加第三个节点ip-10-170-29-88：
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl stop_app
...done.
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl reset
Resetting node 'rabbit@ip-10-170-29-88' ...
...done.
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl cluster-
rabbit@ip-10-170-29-145\
rabbit@ip-10-170-30-18
['rabbit@ip-10-170-29-145',
'rabbit@ip-10-170-30-18']..
---
## Page 135
5.4将节点分布到更多的机器上
113
...done.
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl start_app
...done.
如果在任何一个节点上运行 sudorabbitmqctlcluster_status，你会看
到现在自己有了三个节点的集群了：
Cluster statusof node rabbit@ip-10-170-29-88...
[{nodes,[{disc,['rabbit@ip-10-170-30-18','rabbit@ip-10-170-29-145']},
{ram,['rabbit@ip-10-170-29-88']1]},
(running_nodes,['rabbit@ip-10-170-29-145','rabbit@ip-10-170-30-18',
'rabbit@ip-10-170-29-88']}]
...done.
到目前为止，你已经搭建了两种不同的RabbitMQ集群了：一种分布在不同的
服务器上，另一种则在单台机器上。不过有一件事我们还没有介绍，那就是如何将
节点从集群中移除。如果你想要让集群规模更小，或者用更好的硬件来替换一个节
点的时候，该怎么做呢？针对这两种情况，你需要做的是让节点离开集群。和加入
集群的操作类似，只是不需要rabbitmqctlcluster这一步了。让我们将ip-
10-170-29-88从集群中移除，并将其转回独立节点：
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl stop_app
..: :88-67-041-01-dt071qq51, apou butddoss
...done.
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl reset
...done.
ubuntu@ip-10-170-29-88:~$ sudo rabbitmqctl start_app
...done.
这里关键的命令是rabbitmqctlreset。我们之前说过reset命令将清空节
点的状态，并将其恢复到空白状态。这没错，只不过当重设的节点是集群的一部分时，
该命令也会和集群中的磁盘节点进行通信，告诉它们该节点正在离开集群。这很重
要；不然，集群会认为该节点出了故障，并期望其最终能恢复回来。当离开的节点
是磁盘节点时，正式离开集群就显得格外重要。回忆之前提到的，对于每次元数据
变更来说，磁盘节点是必需的；但是对于节点加入或是离开集群来说，所有磁盘节
点都是必需的。所以如果是非正式移除磁盘节点的话，集群会认为该节点发生故障，
并等待其恢复后才允许新节点的加入。因此，简单地把磁盘节点从集群中猛拉出来
而非正式移除的话，会导致集群永久性无法进行变更。所以当从集群中移除节点时，
---
## Page 136
114
第5章集群并处理失败
请始终小心重设节点状态。
如果从移除的节点上检查集群的状态，你会发现它现在是独立节点。
Cluster status of node rabbit@ip-10-170-29-88 ...
[{nodes,[{disc,['rabbit@ip-10-170-29-88']}]},
[running_nodes,['rabbit@ip-10-170-29-88']}]
...done.
同样地，如果你从集群中其他剩余节点上来检查集群状态的话，你会看到它们
已不再将ip-10-170-29-88视为集群的一部分了：
Cluster statusof node rabbit@ip-10-170-30-18...
[{nodes,[{disc,['rabbit@ip-10-170-30-18','rabbit@ip-10-170-29-145']}]},
{running_nodes,['rabbit@ip-10-170-29-145','rabbit@ip-10-170-30-18']}]
...done.
在掌握了分布式集群以及如何正式地移除节点后，让我们讨论如何将集群升级
到RabbitMQ新版本。
5.5升级集群节点
通常来讲，在独立系统中升级到新版本RabbitMQ很容易。你只需解压新版
本，然后运行即可°。旧的数据会被保留，而你将运行最新、最棒的RabbitMQ版
本。但是升级集群并非如此简单。集群的升级是半自动化的。如果简单地将新版
本RabbitMQ在集群节点上解压并重启的话，这样会抹去集群上的所有配置和数据。
如果集群上的一切都能被重新创建的话，那就不会是什么问题。如果不是的话，那
么升级着实是个复杂的过程。
首先你需要通过RabbitMQManagement插件使用第6章讲到的指令来备份
当前配置。然后关闭所有生产者并等待消费者消费完队列中的所有消息（使用
压新版本RabbitMQ到现有的安装目录。这时，选择其中一个磁盘节点作为升级节点。
6由于RabbitMQ存储格式分别在1.x和2.0以及2.1.0和2.1.1有所更改，因此升级早于2.1.0的版本将会是
一个手动升级的过程。如果你在更新的RabbitMQ版本之间拥有互不兼容的存储格式的话，RabbitMQ
会自动将旧的存储文件复制到备份地址，并创建新的空白文件。
7在RabbitMQ2.6.0之后的新版本中，排空队列不是必需的，因为服务器会自动升级。不过这仍然是一
个保障安全的好方法，以免在升级的时候出错。
---
## Page 137
5.6镜像队列和保留消息
115
当它启动的时候，该节点会将持久化的集群数据升级到新版本。然后你就能启动其
他集群磁盘节点了，它们会获取升级后的集群数据。最后，启动集群内存节点，这
样你就让集群上运行着闪亮的RabbitMQ新版本，而且所有的元数据和配置信息都
会被保留。
在学习了升级和传统集群的操作后，现在是时候让我们看看如何对集群进行扩
展了，以便能在节点失败时保留队列内容。
5.6镜像队列和保留消息
在一开始讨论集群的时候，你也许会记得我们曾经说过默认情况下队列只存活
于集群中的一个节点上。这仍然是对的，而且如果你使用的是RabbitMQ2.6.0之前
的任何一个版本的话，这也是唯一的选择。但是在2.6.0版本的时候，Rabbit团队给
我们带来了内建的双活允余选项：镜像队列。像普通队列那样，镜像队列的主拷贝
仅存在于一个节点（主队列，master）上，但与普通队列不同的是，镜像节点在集
群中的其他节点上拥有从队列（slave）拷贝。一旦队列主节点不可用，最老的从队
列将被选举为新的主队列。这听起来不就是在探索集群时我们一直寻找的高可用性
“灵丹妙药”吗？不过有些注意事项你需要清楚。在我们深人探讨这些注意事项前，
先看看如何编写消费者应用，对镜像队列加以利用。
5.6.1声明并使用镜像队列
就如AMQP的许多方面一样，你的应用程序并不使用rabbitmqct1来定义
镜像（mirrored）队列。声明镜像队列就像声明普通队列一样；你传人一个额外的
x-ha-policy参数到queue.declare调用中。为了看看真实代码会是什么样子，
让我们更新第2章写的那个HelloWorld消费者程序，让它声明镜像队列来替代普通
的队列。将普通队列声明更改成镜像队列声明非常简单，只需将 channel.queue_
declare（queue="hello-queue")更改如卜：
queue_args = {"x-ha-policy":"all"}
channel.queue_declare(queue="hello-queue", arguments=queue_args)
queue_args 是简单的字典（或者哈希），包含了额外的队列声明参数。在该示
例中，添加的参数为x-ha-policy，并被设置为all。当设置成all时，x-ha-
---
## Page 138
116
第5章集群并处理失败
policy告诉Rabbit你想让队列被镜像到集群中所有的节点上。这意味着如果在该
队列声明之后，集群又新增节点的话，那么该节点就会自动托管一份队列的从拷
贝。为了测试新的镜像队列消费者，我们从终端运行它，然后在另一个终端使用
rabbitmqctl看看队列是否真的镜像厂：
(terminal l)> python hello_world_mirrored_queue_consumer.py
(terminal 2)> rabbitmqctl list_queues name pid slave_pids
Listing queues..
hello-queue
[ python hello_world_mirrored_queue_consumer.py
(terminal 2)> rabbitmqctl list_queues name pid slave_pids
Listing queues ..
hello-queue
[]
...done.
正如预期的那样，hello-queue 只有主拷贝而没有从拷贝（即便集群上有两
个节点）。如果此时为队列添加新的从节点会怎样呢？新增的从拷贝只会包含那些
在其添加进来之后从镜像队列发来的消息。RabbitMQ不会（2.7.0版本以前）将镜
像队列现存的内容和新添加的从拷贝进行同步。理论上说消息是从现存的主拷贝和
从拷贝上进行消费的，那些新增从拷贝不知道的所有旧消息会被移除，并且新增从
拷贝最终会和现存的队列拷贝拥有相同的状态。但是如果在旧消息消费掉以前，你
将所有包含现存的主拷贝和从拷贝的节点移除的话，那么新进的从拷贝会被推选为
主拷贝，你会丢失那些旧消息。因此，直到RabbitMQ提供镜像队列现存内容到新
从拷贝的同步机制前，分辨是否所有从拷贝都拥有相同的内容是很重要的。为了检
测镜像队列的同步状态，在使用rabbitmqctl列出队列时添加synchronised
slave_pids 即:
> rabbitmqctl list_queues name pid slave_pids synchronised_slave_pids
Listing queues ...
hello-queue
[】）
是一模一样的话，那么所有的slave队列就都同步了。但是如果在第一个括号内的
任何一个PID没有出现在第二个列表中的话，那就意味着缺失的从PID和稍早的从
拷贝拥有不同的内容。如果是这种情况的话，那么你需要等到这两个括号中的列表
内容完全相同之后，才能从集群中移除节点。这能确保只存在于你想要删除的节点
---
## Page 140
118
第5章集群并处理失败
上的任何消息都不会丢失。这就是我们介绍镜像队列时提到的注意事项之一。为了
更好地理解镜像队列的工作机制（以及剩下几项注意事项），让我们一起揭开镜像
队列的神秘“面纱”。
到目前为止，你已经学习了集群的工作机制（包括镜像队列），而且不仅学会
了如何在单台开发机器上部署，也学会了通过本地局域网络部署分布式集群。你甚
至明白如何升级集群而永远不会丢失所有的配置。现在还差的是，在集群环境下如
何编写代码以处理集群故障并自动重连到其他节点。
5.6.2镜像队列工作原理
在非镜像队列的Rabbit集群中，信道负责将消息路由到合适的队列。当加人镜
像队列后，信道仍然做着同样的事情。除了将消息按照路由绑定规则投递到合适的
队列之外，它也要将消息投递到镜像队列的从拷贝（如图5.5所示）。在某种程度上，
你可以将镜像队列视为拥有一个隐藏的fanout交换器，它指示着信道将消息分发到
队列的从拷贝上。
生产者
消息
主拷贝
从拷贝
Q2
Q2
（镜像）
（镜像）
RabbitMQ
RabbitMQ
RabbitMQ
节点
节点
节点
消费者
消费者
图5.5镜像队列行为
对于信道负责将消息并行地发布到镜像队列的主从拷贝上这一点的理解，有助
于你理解镜像队列是如何影响事务和发送方确认模式的。当处理那些非镜像队列时，
在信道根据匹配的绑定规则将消息路由到所有特定的队列之后，你只是收到一个发
---
## Page 141
5.6镜像队列和保留消息
1119
送方确认消息（publisherconfirm；或者一个成功的事务）而已。当切换到使用镜像
队列时，Rabbit使用相同的概念，只不过将概念拓展到了队列的从拷贝。所以如果
你想要确认消息没有丢失的话，就可以对消息使用发送方确认模式，Rabbit会在所
有队列和队列的从拷贝安全地接收到消息时通知你。但是如果消息在路由到从拷贝
前，镜像队列的主拷贝发生故障，并且该从拷贝变成了主拷贝的话，那么发送方确
认消息永远不会到达，于是你就知道消息可能已经去失了。不过，这只是关于发布
方是如何处理镜像队列主节点故障的。那么附加在故障的主拷贝上的消费者会怎样
呢？
如果镜像队列失去了一个从节点的话，则附加在镜像队列的任何消费者都不会
注意到这一点。这是因为从技术上来讲，它们是附加在队列主拷贝上的。但是如果
托管主拷贝的节点发生故障的话，那么所有该队列的消费者需要重新附加并监听新