two facts pose signiﬁcant challenges to existing com-
puter vision methods, which typically assume reason-
ably consistent appearance and visually distinctive fore-
grounds [52]. Nevertheless, our user study showed that
people had little trouble solving these captchas. This
bodes well for emergent captchas—per today’s attacks.
Looking towards the future, greater robustness would
result if MIOR captchas required automated attacks to
perform classiﬁcation, categorization of classes with
large inner class variance, or to identify higher level se-
mantics to understand the presented challenge. Consider,
for example, the case where the user is presented with
two objects (a person and a truck) at the same scale, and
asked to identify which one is larger. To succeed, the
automated attack would need to determine the objects
(without prior knowledge of what the objects are of) and
then understand the relationship. Humans can perform
this task because of the inherent priors learned in daily
life, but this feat remains a daunting problem in com-
puter vision. Therefore, this combination seems to of-
fer the right balance and underscores the ideas put forth
by Naor [34] and von Ahn et al. [1]—i.e., it is prudent
to employ hard (and useful) underlying AI problems in
captchas since it leads to a win-win situation: either the
captcha is not broken and there is a way to distinguish
between humans and computers, or it is broken and a
useful problem is solved.
Acknowledgments
The authors thank Pierre Georgel, Joseph Tighe, and Avi
Rubin for insightful discussions about this work, and for
valuable feedback on an earlier draft of this manuscript.
We are also especially grateful to Fletcher Fairey (of the
Ofﬁce of University Counsel at Chapel Hill), and Cindy
Cohn and Marcia Hofmann (of the Electronic Frontier
Foundation) for their guidance and assistance in making
our ﬁndings available to NuCaptcha in a timely manner.
Sonia Chiasson holds a Canada Research Chair in Hu-
man Oriented Computer Security and Paul Van Oorschot
holds a Canada Research Chair in Authentication and
Computer Security; both acknowledge the Natural Sci-
ences and Engineering Research Council of Canada
(NSERC) for funding the Chairs and Discovery Grants,
as well as funding from NSERC ISSNet. This work
is also supported by the National Science Foundation
(NSF) under award number 1148895.
Notes
1In the case where the foreground characters have varying appear-
ance, we simply use multiple modes.
2Readers can view videos of the Emerging Images concept [31]
at http://graphics.stanford.edu/~niloy/research/
emergence/emergence_image_siga_09.html.
3See
the Security Features discussed at http://www.
nucaptcha.com/features/security-features, 2012.
4One participant opted to view only six challenges in each of the
Extended and Emerging variants. We count the remaining four as skips.
References
[1] L. V. Ahn, M. Blum, N. J. Hopper, and J. Langford. CAPTCHA:
using hard AI problems for security. In Eurocrypt, pages 294–
311, 2003.
[15] M. Egele, L. Bilge, E. Kirda, and C. Kruegel. Captcha smug-
gling: hijacking web browsing sessions to create captcha farms.
In Proceedings of the ACM Symposium on Applied Computing,
pages 1865–1870, 2010.
[16] J. Elson, J. R. Douceur, J. Howell, and J. Saul. Asirra: a
CAPTCHA that exploits interest-aligned manual image catego-
In Proceedings of the ACM Conference on Computer
rization.
and Communications Security, pages 366–374, 2007.
[2] A. Basso and F. Bergadano. Anti-bot strategies based on hu-
man interactive proofs. In P. Stavroulakis and M. Stamp, editors,
Handbook of Information and Communication Security, pages
273–291. Springer, 2010.
[17] M. Fischler and R. Bolles. Random sample consensus: A
paradigm for model ﬁtting with applications to image analysis
and automated cartography. Comm. of the ACM, 24(6):381–395,
1981.
[3] E. Bursztein. How we broke the NuCaptcha video scheme
See http://elie.im/
and what we proposed to ﬁx it.
blog/security/how-we-broke-the-nucaptcha\
-video-scheme-and-what-we-propose-to-fix-it/,
Accessed March, 2012.
[4] E. Bursztein and S. Bethard. DeCAPTCHA: breaking 75% of
In Proceedings of the 3rd USENIX
ebay audio CAPTCHAs.
Workshop on Offensive Technologies, 2009.
[5] E. Bursztein, S. Bethard, C. Fabry, J. C. Mitchell, and D. Juraf-
sky. How good are humans at solving CAPTCHAs? a large scale
evaluation. In IEEE Symposium on Security and Privacy, pages
399–413, 2010.
[6] E. Bursztein, R. Beauxis, H. Paskov, D. Perito, C. Fabry, and
J. C. Mitchell. The failure of noise-based non-continuous audio
CAPTCHAs. In IEEE Symposium on Security and Privacy, pages
19–31, 2011.
[7] E. Bursztein, M. Martin, and J. Mitchell. Text-based CAPTCHA
strengths and weaknesses. In Proceedings of the 18th ACM con-
ference on Computer and communications security, pages 125–
138, 2011.
[8] K. Chellapilla, K. Larson, P. Y. Simard, and M. Czerwinski. De-
signing human friendly human interaction proofs (hips). In ACM
Conference on Human Factors in Computing Systems, pages
711–720, 2005.
[9] K. Chellapilla, K. Larson, P. Y. Simard, and M. Czerwinski.
Building segmentation based human-friendly human interaction
proofs (hips). In Human Interactive Proofs, Second International
Workshop, pages 1–26, 2005.
[10] J. Cui, W. Zhang, Y. Peng, Y. Liang, B. Xiao, J. Mei, D. Zhang,
and X. Wang. A 3-layer Dynamic CAPTCHA Implementation.
In Workshop on Education Technology and Computer Science,
volume 1, pages 23–26, march 2010.
[11] J.-S. Cui, J.-T. Mei, X. Wang, D. Zhang, and W.-Z. Zhang. A
CAPTCHA Implementation Based on 3D Animation. In Inter-
national Conference on Multimedia Information Networking and
Security, volume 2, pages 179 –182, nov. 2009.
[12] J.-S. Cui, J.-T. Mei, W.-Z. Zhang, X. Wang, and D. Zhang. A
CAPTCHA Implementation Based on Moving Objects Recogni-
In International Conference on E-Business and
tion Problem.
E-Government, pages 1277–1280, may 2010.
[13] J. J. DiCarlo and D. D. Cox. Untangling invariant object recog-
nition. Trends in Cognitive Sciences, 11:333–341, 2007.
[18] N. Friedman and S. Russell.
Image segmentation in video se-
quences: A probabilistic approach. University of California,
Berkeley, 94720, 1776.
[19] P. Golle. Machine learning attacks against the Asirra CAPTCHA.
In Proceedings of the ACM Conference on Computer and Com-
munications Security, pages 535–542, 2008.
[20] K. Grill-Spector and N. Kanwisher. Visual recognition: as soon
as you know it is there, you know what it is. Psychological Sci-
ence, 16(2):152–160, 2005.
[21] C. Harris and M. Stephens. A combined corner and edge de-
tection. In Proceedings of The Fourth Alvey Vision Conference,
volume 15, pages 147–151, 1988.
[22] J. M. G. Hidalgo and G. Alvarez. CAPTCHAs: An Artiﬁcial In-
telligence Application to Web Security. Advances in Computers,
83:109–181, 2011.
[23] A. Jain, M. Murty, and P. Flynn. Data clustering: a review. ACM
computing Surveys, 31(3):264–323, 1999.
[24] K. A. Kluever and R. Zanibbi. Balancing usability and security
in a video CAPTCHA. In Proceedings of the 5th Symposium on
Usable Privacy and Security, pages 1–14, 2009.
[25] J. Lazar, J. H. Feng, and H. Hochheiser. Research Methods in
Human-Computer Interaction. John Wiley and Sons, 2010.
[26] W.-H. Liao and C.-C. Chang. Embedding information within dy-
namic visual patterns. In Multimedia and Expo, IEEE Interna-
tional Conference on, volume 2, pages 895–898, june 2004.
[27] R. Lowry. Concepts and Applications of Inferential Statistics.
Vassar College, http://faculty.vassar.edu/lowry/
webtext.html, 1998.
[28] B. Lucas and T. Kanade. An iterative image registration technique
with an application to stereo vision. In International Joint Con-
ference on Artiﬁcial Intelligence (IJCAI), pages 674–679, 1981.
[29] D. Marr. Vision: a computational investigation into the human
representation and processing of visual information. W. H. Free-
man, San Francisco, 1982.
[30] D. Marr and T. Poggio. A computational theory of human stereo
vision. Proceedings of the Royal Society of London. Series B,
Biological Sciences, 204(1156):301–328, 1979.
[31] N. J. Mitra, H.-K. Chu, T.-Y. Lee, L. Wolf, H. Yeshurun, and
D. Cohen-Or. Emerging images. ACM Transactions on Graphics,
28(5), 2009.
[14] J. Driver and G. Baylis. Edge-assignment and ﬁgure-ground seg-
mentation in short-term visual matching. Cognitive Psychology,
31:248–306, 1996.
[32] G. Mori and J. Malik. Recognizing objects in adversarial clutter:
breaking a visual CAPTCHA. In Computer Vision and Pattern
Recognition, volume 1, pages 134 –141, june 2003.
[33] M. Motoyama, K. Levchenko, C. Kanich, D. McCoy, G. M.
Voelker, and S. Savage.
Re: CAPTCHAs-understanding
CAPTCHA-solving services in an economic context. In USENIX
Security Symposium, pages 435–462, 2010.
[34] M. Naor. Veriﬁcation of a human in the loop or identiﬁcation via
the Turing test, 1996.
[35] NuCaptcha. Whitepaper: NuCaptcha & Traditional Captcha,
2011. http://nucaptcha.com.
[36] A. Oliva and A. Torralba. The role of context in object recogni-
tion. Trends in Cognitive Sciences, 11(12):520 – 527, 2007.
[37] S. Ray and R. Turi. Determination of number of clusters in k-
means clustering and application in colour image segmentation.
In Proceedings of the International conference on advances in
pattern recognition and digital techniques, pages 137–143, 1999.
[38] M. Shirali-Shahreza
Motion
CAPTCHA. In Conference on Human System Interactions, pages
1042–1044, May 2008.
and S. Shirali-Shahreza.
[39] P. Simard, D. Steinkraus, and J. Platt. Best practices for convo-
lutional neural networks applied to visual document analysis. In
Proceedings of the Seventh International Conference on Docu-
ment Analysis and Recognition, volume 2, pages 958–962, 2003.
[40] Y. Soupionis and D. Gritzalis. Audio CAPTCHA: Existing so-
lutions assessment and a new implementation for voip telephony.
Computers & Security, 29(5):603–618, 2010.
[41] S. Thorpe, D. Fize, and C. Marlot. Speed of processing in the
human visual system. Nature, 381(6582):520–522, 1996.
[42] S. Ullman. Computational studies in the interpretation of struc-
ture and motion: Summary and extension. In Human and Ma-
chine Vision. Academic Press, 1983.
[43] S. Ullman. High-Level Vision: Object Recognition and Visual
Cognition. The MIT Press, 1 edition, July 2000.
[52] A. Yilmaz, O. Javed, and M. Shah. Object tracking: A survey.
ACM Comput. Surv., 38, December 2006.
[53] B. B. Zhu, J. Yan, Q. Li, C. Yang, J. Liu, N. Xu, M. Yi, and
K. Cai. Attacks and design of image recognition CAPTCHAs.
In ACM Conference on Computer and Communications Security,
pages 187–200, 2010.
A Parameters for video generation
Similar to NuCaptcha’s videos, our sequences have letters that move
across a background scene with constant velocity in the horizontal di-
rection, and move up and down harmonically (i.e., y(t) = A∗ sin(ωt +
ψ), y is the vertical position of the letter, t is the frame id, and A,ω,ψ
are adjustable parameters). The horizontal distance between two letters
is a function of their average width. If their widths are width1,width2,
the distance between their centers are set to be α ∗ width1+width2
, where
α is an adjustable parameter that indicates how much two letters over-
lap. Our letters also rotate and loop around. The angleθ to which a
letter rotates is also decided by a sin function θ = θ0 ∗ sin(ωθ t + ψθ ),
where θ0,ωθ ,ψθ are adjustable parameters. For the standard case, we
set the parameters the same as in NuCaptcha’s videos. We adjust these
parameters based on the type of defenses we explore (in Section 5.2).
2
B Comments from User Study
Table 2 highlights some of the free-form responses written on the ques-
tionnaire used in our study.
Variant
Standard
Extended
Comments
- User friendly
- It was too easy
- Much easier than traditional captchas
- My mother would not be able to solve these
- Giant Pain in the Butt! Sheer mass of text was
overwhelming and I got lost many times
- Too long! I would prefer a shorter text
- It was very time consuming, and is very prone to
mistakes
- Letters too bunched – several loops needed to de-
cipher
- Takes longer because I had to wait for the letter to
move a bit so I can see more of it
- Still had a dizzying affect. Not pleasant
- Some characters were only partially revealed, ‘Y’
looked like a ‘V’
- Tree background is unreadable, any non-solid
background creates too much interference
- With some backgrounds I almost didn’t realize
there were red letters
- It was almost faded and very time consuming. I
think I made more mistakes in this mechanism
- Not that complicated
- I’d feel dizzy after staring at it for more than 1 min
- It was hideous! Like an early 2000s website. But
it did do the job. It made my eyes feel ‘fuzzy’ after
a while
- It was good, better than the challenges with line
through letters
Table 2: Sample participant comments for each variant
[44] A. Vedaldi and B. Fulkerson. Vlfeat: An open and portable li-
brary of computer vision algorithms. In Proceedings of the inter-
national conference on Multimedia, pages 1469–1472, 2010.
Overlapping
[45] P. A. Viola and M. J. Jones. Rapid object detection using a
boosted cascade of simple features. In Computer Vision and Pat-
tern Recognition, 2001.
[46] L. von Ahn, M. Blum, and J. Langford. Telling humans and com-
puters apart automatically. Commun. ACM, 47:56–60, February
2004.
Semi-
Transparent
[47] J. Yan and A. S. E. Ahmad. Breaking visual CAPTCHAs with
naive pattern recognition algorithms. In ACSAC, pages 279–291,
2007.
Emerging
[48] J. Yan and A. S. E. Ahmad. A low-cost attack on a microsoft
CAPTCHA. In ACM Conference on Computer and Communica-
tions Security, pages 543–554, 2008.
[49] J. Yan and A. S. E. Ahmad. Usability of CAPTCHAs or usability
issues in CAPTCHA design. In SOUPS, pages 44–52, 2008.
[50] J. Yan and A. El Ahmad. CAPTCHA robustness: A security
engineering perspective. Computer, 44(2):54 –60, feb. 2011.
[51] J. Yan and M. Pollefeys. Articulated motion segmentation using
RANSAC with priors. Dynamical Vision, pages 75–85, 2007.