among others.
Notice that each of these applications requires certain
levels of trust for which social ties are best suited as a
trust bootstrapping and enabling tool. Especially, reasoning
about the behavior of systems and expected outcomes
(in a computing system in particular) would be well-served
by this trust model. We notice that this social trust has been
previously used as an enabler for privacy in file-sharing
systems [32], anonymity in communications systems [33],
and collaboration in sybil defenses [23], [26], among others. In
this work, we use the same insight to propose a computing
paradigm that relies on such trust and volunteered resources,
in the form of shared computing time. With that in mind,
in the following section we elaborate on the attacker used in
our system and trust models provided by our design, thus
highlight its advantage and distancing our work from prior
works in the literature.
3.4 Attacker Model
In this paper, as it is the case in many other systems built on
top of social networks [23], [26], we assume that the attacker
is restricted in many aspects. For example, the attacker has a
limited capability of creating arbitrarily many edges between
himself and other nodes in the social graph.
While this restriction may contradict some recent results
in the literature [34]Vwhere it is shown that some social
networks are prone to infiltration, it can be relaxed to
achieve the intended trust and attack model by considering
an overlay of subset of friends of each users. This overlay
expresses the trust value of the social graph well and
eliminates the influence introduced by the attacker who
infiltrated the social graph [26]. For example, since each
user decides to which node among neighbors to outsource
computations to, each user is aware of other users he
knows well and those who are just social encounters that
could be potential attackers. Accordingly, the user himself
decides whether to include a given node in his overlay or
not, thus minimizing or eliminating harm and achieving
the required trust and attack model.
The description of the above attacker model might be at
odds with the rest of the paper, especially that we use some
online social networks that do not reflect characteristics of
trust required in our paradigm. However, such networks
are used in our demonstration for two reasons. First, to
derive insight on the potential of such social networks, and
others that share similar topological characteristics, for
performing computational tasks according to the method
devised in this paper. Second, we use them to illustrate
that some of these social networks might be less effective
than the trust-possessing social graphs, which we strongly
advocate for our computing paradigm.
The restrictions of
the adversary model are used
when demonstrating the trust-based scheduling described
in Section 4.3. In that context, we limit the adversary
in the number of edges he can create with honest nodes in
the social graph, thus limiting the similarity graph used for
characterizing trust as a similarity. When using interactions
as an indicator of trust, the adversary is also limited by the
336
IEEE TRANSACTIONS ON SERVICES COMPUTING, VOL. 7, NO. 3,
JULY-SEPTEMBER 2014
Fig. 1. Depiction of the main SocialCloud paradigm as viewed by an
outsourcer of computations. The different nodes in the social network act
as workers for their friends, who act as potential jobs/tasks outsourcers.
The links between social nodes are ideally governed by a strong trust
relationship, which is the main source of
for the constructed
computing overlay. Both job outsourcers and workers have their own,
and potentially different, schedulers.
trust
number of interactions he can create with honest nodes.
Notice that our experimental settings avoid discussing or
considering the compromise of social identify and other
attacks since addressing them is orthogonal to our work.
Furthermore, simple fixes can be deployed to address that
issue. For example, identify compromise can be confirmed
in an offline manner, or by testing the adversary against
the correctness of the returned computation resultsVby
replicating computations on other hosts in case of suspecting
such compromise, among other techniques.
3.4.1 Comparison with Trust in Grid Computing Systems
While there has been a lot of research on characterizing and
improving trust in the conventional grid computing paradigm
[35], [36]Vwhich is the closest paradigm to compare to
ours, trust guarantees in such paradigm are less strict than
what is expressed by social trust. For that, it is easy to see
that some nodes in the grid computing paradigm may act
maliciously by, for example, giving wrong computations,
or refusing to collaborate; which is even easier to detect and
tolerate, as opposed to acting maliciously [37].
4 THE DESIGN OF SOCIALCLOUD
The main design of SocialCloud is very simple, where
complexities are hidden in design choices and options. In
SocialCloud, the computing overlay is bootstrapped by the
underlying social structure. Accordingly, nodes in the social
graph act as workers to their adjacent nodes (i.e., nodes which
are one hop away from the outsourcer of computations). An
illustration of this design is depicted in Fig. 1. In this design,
nodes in the social graph, and those in the SocialCloud overlay,
use their neighbors to outsource computational tasks to
them. For that purpose, they utilize local information to
decide on the way they schedule the amount of computations
they want each and every one of their neighbors to take care
of. Accordingly, each node has a scheduler which she uses
for deciding the proportion of tasks that a node wants to
outsource to any given worker among her neighbors. Once a
task is outsourced to the given worker, and assuming that
both data and code for processing the task are transferred to
the worker, the worker is left to decide how to schedule the
task locally to compute it. Upon completion of a task, the
worker sends back the computations result to the outsourcer.
4.1 Design Options: A Scheduling Entity
In SocialCloud two schedulers are used. The first scheduler
is used for determining the proportion of task outsourced
to each worker and the second scheduler is used at each
worker to determine how tasks outsourced by outsourcers are
computed and in which order. While the latter scheduler can
be easily implemented locally without impacting the system
complexity, the decision used for whether to centralize or
decentralize the former scheduler impacts the complexity
and operation of the entire system. In the following, we
elaborate on both design decisions, their characteristics,
and compare them.
4.1.1 Decentralized Scheduler
In our paradigm, we limit selection of workers to 1-hop
from the outsourcer. This makes it possible, and perhaps
plausible, to incorporate scheduling of outsourcing tasks at
the side of the outsourcer in a decentralized mannerVthus
each node takes care of scheduling its tasks. On the one hand,
this could reduce the complexity of the design by eliminating
the scheduling server in a centralized alternative. However,
on the other hand, this could increase the complexity of
the used protocols and the cost associated with them for
exchanging statesVsuch as availability of resources, online
and offline time, among others. All of such states are
exchanged between workers and outsourcers in our para-
digm. These states are essential for building basic primitives
in any distributed computing system to improve efficiency
(see below for further details). An illustration of this design
option is shown in Fig. 1. In this scenario, each outsourcer, as
well as worker, has its own separate scheduling component.
4.1.2 Centralized Scheduler
Despite the fact that nodes may only require their neighbors
to perform the computational tasks on behalf of them and
that may require only local informationVwhich could be
available to these nodes in advance, the use of a centralized
scheduler might be necessitated to reduce communication
overhead at the protocol level. For example, to decide upon
the best set of nodes to which to outsource computations, a
node needs to know which of its neighbors are available,
among other statistics. For that purpose, and given that
the underlying communication network topology may not
necessarily have the same proximity of the social network
topology, the protocol among nodes needs to incur back
and forth communication cost. One possible solution to the
problem is to use a centralized server that maintains states.
Instead of communicating directly with neighbor nodes,
an outsourcer would request the best set of candidates
among its neighbors to the centralized scheduling server.
In response, the server will produce a set of candidates,
based on the locally stored states. Such candidates would
typically be those that would have the most available
resources to handle outsourced computation tasks.
An illustration of this design option is shown in Fig. 2.
In this design, each node in SocialCloud would periodically
send states to a centralized server. When needed, an out-
sourcer node contacts the centralized server to return to it
the best set of candidates for outsourcing computations,
which the server would return based on the states of these
candidates. Notice that only states are returned to the
outsourcer, upon which the outsourcer would send tasks to
these nodes on its ownVThus, the server involvement is
limited to the control protocol.
MOHAISEN ET AL.: TRUSTWORTHY DISTRIBUTED COMPUTING ON SOCIAL NETWORKS
337
Comparison between the Centralized and Decentralized
TABLE 1
Schedulers. Compared Features are Failure, Communication
Overhead, Required Additional Hardware, and Required
Additional Trust
paradigms. See Section 6 for details on limitations of this
approach and possible extensions in the future work.
Trust-Based Scheduling
4.3
Both of the scheduling components at the worker and the
outsourcer we discussed so far have considered only the
availability of a host for performing computations. How-
ever, one interesting feature of social networks that can be
used to bias the way according to which scheduling is done is
the underlying differential trust. Oftentimes, strength of ties
between nodes in the social network varies, and that strength
can be measured using various ways. In a more realistic
context of social network-based computing systems, nodes
would capitalize on this differential trust in assigning com-
putations to other nodes. In principle, biasing the sched-
uling according to the method above is similar to the
‘‘Weighted Differential Scheduler’’, where weights of sched-
uling (at the outsourcer) are assigned on pre-computed trust
value.
4.3.1 Defining Trust-Based Scheduling
There are several ways used in the literature for computing
the strength of ties between social nodes [26]. Two widely
used notions for the strength of ties are characterized in
the following:
.
Similarity-based: the similarity-based metric for es-
timating the strength of ties between two nodes
captures the number of common nodes between
then. Formally, for two nodes vi, and vj, with their
neighbors being NðviÞ and NðvjÞ respectively, the
similarity between node vi and vj
is defined as
Sðvi; vjÞ ¼ jNðviÞ\NðvjÞj
jNðviÞ[NðvjÞj (where j  j means the cardinality
of the resulting set ðÞ). Every node vx in the social
graph computes its similarity with the neighboring
nodes in the social graph and assigns a trust value to
those nodes according to the resulting similarity. Fur-
thermore, when scheduling tasks to be computed on
those neighboring nodes, each node uses the similarity
value with those neighbors for weighting the distrib-
uted portions of tasks.
Social Graphs Used in Our Experiments
TABLE 2
The communication overhead of this design option to
transfer states between a set of d nodes is 2d, where d
messages are required to deliver all nodes’ states and d
messages are required to deliver states of all other nodes to
each node in the set. On the other hand, dðd   1Þ messages
are required in the decentralized option (which requires
pairwise communication of states update). When outsourc-
ing of computations is possible among all nodes in the
graph, this translates into OðnÞ for the centralized versus
Oðn2Þ communication overhead for the decentralized
optionVnotice that the communication overhead in the
decentralized design would be in reality OðmÞ, where
m  n2 (for an illustration, see Table 2). To sum up, Table 1
shows a comparison between both options. In the rest
of this paper and through the simulation, we use the
decentralized setting, accounting for the communication
overhead but not requiring trust by depending on any
additional entity in the paradigm, not requiring additional
hardware, and not suffering from a single point of failure.
Tasks Scheduling Policy
4.2
While using distributed or centralized scheduler resolves
scheduling at the outsourcer, two decisions remain untackled:
how much computation to outsource to each worker, and
how much time a worker should spend on a given task for a
certain outsourcer. We address these two issues separately.
Any off-the-shelf scheduling algorithm can be used to
schedule tasks at the outsourcer’s side, which can be further
improved by incorporating trust models for weighted job
scheduling [26]. On the other hand, we consider several
scheduling algorithms for workers scheduling, as follows.
1) Round Robin (RR) Scheduling Policy This is the simplest
policy to implement, in which a worker spends an equal
share of time on each outsourced task in a round robin
fashion among all tasks he has. 2) Shortest First (SF)
Scheduling Policy The worker performs shortest
task
first. 3) Longest First (LF) Scheduling Policy The worker
performs longest task first.
Notice that we omit a lot of details about the underlying
computing infrastructure, and abstract such infrastructure
to ‘‘time sharing machines’’, which further simplifies much
of the analysis in this work. However, in a working version
of this paradigm, all of these aspects are addressed in a
similar manner is in other distributed systems and
Fig. 2. Centralized versus decentralized model of task scheduling in
SocialCloud. In the centralized model, an additional centralized entity is
used for coordinating to which worker tasks are to be outsourced,
whereas the decentralized model does not require this entity and rely on
rounds of communication between the outsourcer and workers to
coordinate outsourcing of computations.
338
IEEE TRANSACTIONS ON SERVICES COMPUTING, VOL. 7, NO. 3,
JULY-SEPTEMBER 2014
We study that as well as the straightforward implication
of the time-to-complete evaluation metric (in Section 6.1)
without an adversary, but rather with the modified graph
according to the trust policies defined above.