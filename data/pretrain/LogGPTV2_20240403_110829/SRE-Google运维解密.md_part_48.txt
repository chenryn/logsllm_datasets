图21-1显示了在不同的情况下，每个后端接收到的请求的重试次数分布。这些数据是根
返回“过载；无须重试”的错误，而不是标准的“任务过载”错误信息。
明大部分请求都有重试（意味着其他后端任务也可能处于过载状态），那么后端会直接
使用这个直方图信息来评判其他后端任务也处于过载的可能性。如果这些直方图信息表
该请求。客户端会将近期信息记录为一个直方图。当某个后端需要拒绝请求时，它可以
试时以0值开始，每次重试时加1，直到计数器为2时，请求重试限制会导致不再重试
第三个方法是客户端在请求元数据中加入一个重试计数。例如，这个计数器在第一次尝
的1.1倍。这样的改进是很显著的。
重试的限制（10%重试比例），实际上我们将重试请求限制在大多数情况下仅增加为原来
然是很多的，尤其是当拒绝请求的成本不能忽略的时候。然而，通过加人一个按客户端
个请求会被重试3次）。虽然我们在这里限制了重试导致的请求数量，3倍的请求增长仍
速率。由于大部分请求会被重试，这里请求的数量将会增长得非常快，接近3X（由于每
请求，
用一个实际例子来说（一个很糟糕的情况），我们假设一个数据中心正在接受一小部分
，而大部分请求都被拒绝了。这里用X代表客户端逻辑向这个数据中心发出请求的
所有求
无过载
10
10%的流量
任务正在拒绝
1%的后端
轻微过载
0
正在拒绝50%
5%的后端任务
1000
中等过载
0
1
15
处理过载错误
重度过载
1
219
256
---
## Page 262
2>连接造成的负载
220
闲一段可配置的时间后，客户端放弃TCP连接，转为UDP健康检查。不幸的是，这种
正如之前所说，我们的RPC协议需要不活跃的客户端定期执行健康检查。当某个连接空
型系统中可以忽略不计，但是在大型RPC系统中很快就会造成问题。
维护一个大型连接池的CPU和内存成本，或者是连接快速变动的成本。
所造成的负载（这也是用QPS来建模负载的一个问题），然而却忽略了其他因素。比如
连接造成的负载是最后一个值得一提的因素。有时候我们仅仅考虑后端处理接收的请求
上层处。如果多层都要进行重试，会造成批量重试爆炸情况。
这里的关键点是，数据库前端拒绝的请求应该仅仅在后端任务B处重试一
图21-2：某个依赖栈
前端（DBFrontend）目前正处于过载状态，拒绝请求。在这里：
我们来看图21-2中所示的例子（实际上我们的系统栈要比这个复杂得多）。假设数据库
·后端任务A会根据它收到的回复进行处理。
·后端任务B会根据前述的规则重试请求。
）然而当后端任务B确定数据库前端无法处理该请求时（例如，请求已经重试3次），
后端任务B需要给后端任务A返回一个“过载；无须重试”错误，或者某个降
第21章应对过载
DBStorage
Backend B
Backend A
Frontend
BackendC
。这样的问题在小
一在它的直接
---
## Page 263
统都必须考虑的关键点（更多知识参见第22章）。
会造成整个系统（或者是显著的大部分）失败。这种层级传递的失败是每个大型部署系
子系统的问题（如某一个后端的一个任务）可能会造成其他系统组件的失败，也有可能
进行GC）、延迟上升、请求被忽略并且任务互相竞争资源。如果不解决这个问题，某个
糟糕的表现。随着工作堆积，任务最终导致内存超标而崩溃（或者基本上花费所有CPU
这里的关键是严肃对待降级情况。当这些降级情况被忽略时，很多系统都会显示出非常
统会崩溃的情况，但是应该将该阈值提升到某种很难发生的程度。
围内得到满足—有可能是两倍的配置流量，甚至10倍。我们可以接受超出某阈值时系
质量。并且由此得出，后端任务不应该在过载情况下崩溃。这些要求应该在一定流量范
被配置为服务一定程度的流量，不管多少额外流量被指向这个任务，它都应该保证服务
所以，我们认为保护某个具体任务，防止过载是非常重要的。简单地说：一个后端任务
些困难。
状态传递机制。虽然大部分情况下都表现良好，但是在真实情况下，某些应用遇到了
用户配额等）更平均地将负载分散到数据中心中。然而这些手段都依赖于在分布式下的
本章和第20章讨论了如何利用不同的技术手段（确定性算法、加权轮询、客户端侧的节流、
小结
端的过载。在我们的经验里，以下策略可以帮助消除这些问题：
任务会在短时间内建立大量的客户端。协商和维护这些超大数量的连接可以造成整个后
处理突发性的新连接请求是另外一个（相关的）问题。我们观察到，超大规模的批处理
化这些场景。
通过仔细调节连接参数（如，大幅降低健康检查频率）或者动态创建和销毁连接可以优
行为会对大量请求率很低的客户端造成问题：健康检查需要比实际处理请求更多的资源。
·将负载传递给跨数据中心负载均衡算法（如，使用资源利用率进行负载均衡，而
效率（例如，代理任务可以使用更大的子集数量，同时可以更好地进行负载均衡）。
个使用代理方式的优势是，我们可以减少后端连接的数量，同时提高负载均衡的
的高优先级客户端）。这里，批处理代理任务实际充当了保险丝的角色。另外一
只有批处理代理任务会受到影响，而保护了真正的后端任务（也随之保护了其他
处理客户端→批处理代理→后端”。在这种情况下，当大型的批处理任务执行时，
求，同时将回复转发给客户端。于是，请求路线从“批处理客户端→后端”变为“批
强制要求批处理任务使用某些特定的批处理代理后端任务，这些代理仅仅转发请
不仅仅是请求数量）。在这种情况下，过载请求会被转移到其他数据中心。
小结
221
258
---
## Page 264
222
术是根据Google内部很多系统的需求变化而产生的，可能会随着系统的变化而再次演进。
药：要进行负载均衡经常需要深人了解一个系统和它的请求处理语义。本章所描述的技
虽然我们有很多工具可以用来实现良好的负载均衡和过载保护机制，但是这里没有万能
持，应该仅仅接受它能处理的请求，而优雅地拒绝其他请求。
然后在有可用资源时才处理。某个设计良好的后端程序，基于可靠的负载均衡策略的支
是与可靠的负载均衡目标相违背的。我们实际上希望客户端可以尽可能地继续接受请求，
一个常见的错误是认为过载后端应该拒绝和停止接受所有请求。然而，这个假设实际上
第21章应对过载
---
## Page 265
注 1见 Wikipedia,“Positive feedback”,https:e.wikipedia.org/wiki/Positive_feedback。
境配置如图22-1所示。
本章会通篇使用前文提到的莎士比亚搜索服务（见第2章）作为例子。该服务的生产环
实例像多米诺骨牌一样一个一个全部出现故障。
例如，某个服务的一个实例由于过载出现故障，
障可能由于整个系统的一小部分出现故障而引发，进而导致系统其他部分也出现故障。
连锁故障是由于正反馈循环（positive feedback）导致的不断扩大规模的故障。注1连锁故
为什么人们总是忘记增加一点点抖动因素呢？
如果请求没有成功，以指数型延迟重试。
，导致其他实例负载升高，从而导致这些
-AdeOshineye,Google开发者布道师
-Dan Sandler，Google软件工程师
处理连锁故障
作者：Mike Ulrich
第22章
<259
---
## Page 266
260
224
图22-2：正常的服务器负载在集群A/B之间的分布
假设前端服务器在集群A中正在处理1000QPS的请求，如图22-2所示。
务器过载导致，要么是间接由于服务器过载引发的其他问题导致。
最常见的连锁故障触发原因是服务器过载。这里讨论的多数连锁故障要么是直接由于服
服务器过载
发生。
一个设计良好的系统应该考虑到几个典型的连锁故障产生场景，从而在设计上避免它们
连锁故障产生的原因和如何从设计上避免
图22-1：莎士比亚搜索服务的生产环境配置图
第22章
处理连锁故障
Cluster
ClusterB
GFE
Cluster
←
---
## Page 267
系列的副作用，包括如下几项。
如果CPU资源不足以应对请求负载，
CPU
不同种类的资源耗尽会对软件服务器产生不同的影响。
群请求处理成功率的下降，甚至使整个集群或者整个服务进入连锁故障模式。
效率运行，甚至崩溃。负载均衡系统进而将请求转发给其他服务器，有可能导致整个集
取决于究竞哪种资源最终耗尽，和软件服务器的构建方法，该情况可能会导致系统以低
资源耗尽时应该出现的情况：在负载不断上升到过载时，服务器不可能一直保持完全正
某一种资源的耗尽可以导致高延迟、高错误率，或者低质量回复的发生。这些的确是在
资源耗尽
速度可能非常快（可能在分钟级范围），因为负载均衡器和任务编排系统的响应速度通
其他集群，使那些集群的实例过载，从而造成整个服务过载故障。这些事件连锁发生的
如，某个集群内部的过载可能会导致该服务实例崩溃；这时负载均衡器会将请求发送给
这种成功处理请求能力的下降可能会扩展到其他的集群中，甚至可能造成全球故障。例
图22-3：集群B出现故障，所有请求都发往集群A。
他异常情况。结果，集群A成功处理的请求远低于之前的1000QPS。
的前端服务器无法处理这么多请求，由于资源不够等原因导致崩溃、超时，或者出现其
如果集群B出现故障，如图22-3所示，发往集群A的请求上升至1200QPS。集群A中
常
常非常快。
一般来说所有的请求都会变慢。这个场景会造成一
000
连锁故障产生的原因和如何从设计上避免
GFE
225
262
<261
---
## Page 268