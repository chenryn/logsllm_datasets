Our next task is to compactly represent this set of false
positives. To this end, we construct another, second-level
5In practice, a ﬁlter cascade could be made up of any compact ﬁlter with
false positives, such as cuckoo [26], quotient [5], or Golomb [59] ﬁlters.
Exploring their trade-offs in CRLite is an interesting area of future work.
543
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:56 UTC from IEEE Xplore.  Restrictions apply. 
(cid:2)
ꍌ,QVHUW
(cid:1)(cid:4)(cid:7)(cid:10)(cid:5)
(cid:9)(cid:8)(cid:10)(cid:6)(cid:11)(cid:6)(cid:12)(cid:5)(cid:10)
ꍎ,QVHUW
ꍏ6HDUFK
(cid:1)(cid:4)(cid:7)(cid:10)(cid:5)
(cid:9)(cid:8)(cid:10)(cid:6)(cid:11)(cid:6)(cid:12)(cid:5)(cid:10)
ꍐ,QVHUW
(cid:6)(cid:12)(cid:1)(cid:9)(cid:7)(cid:11)(cid:14)(cid:8)
(cid:13)(cid:12)(cid:14)(cid:10)(cid:15)(cid:10)(cid:16)(cid:8)(cid:14)
ꍑ6HDUFK
(cid:3)
ꍍ6HDUFK
(cid:5)(cid:8)(cid:16)(cid:8)(cid:11)(cid:1)(cid:2)
(cid:5)(cid:8)(cid:16)(cid:8)(cid:11)(cid:1)(cid:3)
(cid:5)(cid:8)(cid:16)(cid:8)(cid:11)(cid:1)(cid:4)
(cid:2)(cid:11)(cid:10)(cid:13)(cid:7)(cid:9)(cid:10)(cid:12)(cid:1)
(cid:6)(cid:8)(cid:12)
(cid:2)(cid:11)(cid:10)(cid:13)(cid:7)(cid:9)(cid:10)(cid:12)(cid:1)
(cid:6)(cid:8)(cid:12)
(cid:6)(cid:8)(cid:12)
(cid:4)
(cid:2)(cid:11)(cid:10)(cid:13)(cid:7)(cid:9)(cid:10)(cid:12)(cid:1)
(cid:3)(cid:11)
(cid:3)(cid:11)
(cid:3)(cid:11)
(cid:5)
(cid:4)
(cid:5)
Fig. 1: Inserting into a ﬁlter cascade. Dashed arrows represent
searches; solid arrows insertions.
Fig. 2: Lookups in a ﬁlter cascade. All lookup queries return
deﬁnitively.
Bloom ﬁlter (BF2) and insert each element of FP1. The idea is
that BF2 in essence serves as a “blacklist” to BF1: it contains
the items that should not have been in BF1. Thus, if a data
item u is in BF1 but is not in BF2, then it is deﬁnitively in
R. However, BF2 can also have false positives. The set of
second-level false positives (FP2) contains the elements of R
that appear in BF2, and is in expectation of size p · |R|.
These are our two base cases; we show one more inductive
step. If FP2 is nonempty, then we construct a third-level Bloom
ﬁlter (BF3) in which we insert each element of FP2. If an
element is in BF1 and BF2 but is not in BF3, then it is
deﬁnitively not in R. That is, like with BF1, BF3 serves as
a “whitelist”: elements of this ﬁlter represent elements of R
(and therefore the elements ideally would not have been in
BF2). However, unlike BF1, the false positives at this level
(FP3) do not come from the entire set S, but rather only the
members of S that have not already been ruled out by higher-
level ﬁlters, i.e., the members of S that are also in BF1, which
is precisely FP1. In expectation, |FP3| = p · |FP1| = p2 · |S|.
This process continues: so long as FPi is nonempty, then we
construct a Bloom ﬁlter BFi+1 and insert into it all elements
of FPi−1 for i ≥ 2. Odd-numbered levels represent whitelists
(elements that are in R) and even-numbered levels represent
blacklists (elements that are not). Figure 1 shows an example
with three layers.
Lookup queries in a ﬁlter cascade are constrained to U and
take the form: “is u ∈ U in set R?” We emphasize that clients
issuing such queries need not know all elements of the set U;
it must only be the case that whoever constructed the ﬁlter
cascade was aware of all possible values u ∈ U for which it
would subsequently be queried.
Lookup queries take a top-down approach similar to inser-
tions. Recall that Bloom ﬁlters provide deﬁnitive answers only
for items not stored in the ﬁlter, and potentially false positives
otherwise. With ﬁlter cascades, we can also provide deﬁnitive
answers in the positive when we know that there are no false
positives from the set U.
Putting this together, lookups in a ﬁlter cascade begin at
level i = 1 and continue until the ﬁrst BFi is found where
u (cid:8)∈ BFi. At this point, the “is u ∈ U in set R?” can be
answered as follows:
• If i is odd, then u is deﬁnitively not in R.
• If i is even, then u is deﬁnitively in R.
If no such BFi is found (i.e., if u is in all BFi), then the total
number of levels l in the ﬁlter cascade determines the answer:
• If l is odd, then u is deﬁnitively in R.
• If l is even, then u is deﬁnitively not in R.
Figure 2 shows an example of lookups in a three-layer ﬁlter
cascade. Note that each level offers deﬁnitive answers when
a data item is not in that level, and the ﬁnal level is always
deﬁnitive.
C. Minimizing Filter Cascade Size
We seek to minimize the size of a ﬁlter cascade, so as to
consume as little bandwidth as necessary to keep browsers up-
to-date with revocation data. To this end, we formally analyze
the ﬁlter cascade’s size and number of levels, and use our
ﬁndings to develop a strategy for setting false positive rates
in a way that minimizes the overall size. To the best of our
knowledge, this is the ﬁrst size-minimizing analysis done on
ﬁlter cascades, and we believe it to have applications beyond
that of certiﬁcate revocation.
False Positives and Size.
An oft-cited bound on the false
positive probability p for a Bloom ﬁlter in which r items are
(cid:2)
inserted into a bit-array of size m using k hash functions is
(cid:3)k
p ≤
1 − e−rk/m
This bound is “proved” by making the slightly untrue assump-
tion that whether one bit is set in the Bloom ﬁlter is indepen-
dent of whether any other bits are set, and approximating 1− 1
m
544
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:56 UTC from IEEE Xplore.  Restrictions apply. 
√
√
by e−1/m. But for large values of r and m, it is very close to
a rigorous bound proved by Goel and Gupta [30], which we
will turn to later. The number of hash functions, k, must be
integral, as must m and n. Putting aside the issue of integrality
for the moment, for a given p, the size of the Bloom ﬁlter is
minimized by setting k = m ln 2
1
p in which case the
size is given by
r = log2
m =
r ln 1
p
(ln 2)2
≈ 1.44r log2
1
p
This formula is accurate provided that m and r are large and
(most importantly) log2(1/p) is close to integral.
Normally, when using a Bloom ﬁlter, one chooses p as
it represents a trade-off between the
a design constraint:
uncertainty the system can accommodate and the cost
in
space it can afford. However, in ﬁlter cascades, there is no
uncertainty: there will ultimately be no false positives, and
thus p only affects the overall size and number of levels.
What, then, is the correct strategy for setting false positive
n
e
n
r
(cid:4)
(cid:4)
1
2
n
e
n
log2
2πn
e
2π
r log2
√
n
n
n − r +
n
rs + log2
rates in a ﬁlter cascade to minimize the overall size?
Lower Bounds.
Before answering this question, we pause
to examine a lower bound. Let r = |R|, s = |S|, and
(cid:4)
(cid:5)
n = r + s. The number of bits needed to communicate R
(cid:5)
(cid:5) ≤ n! ≤ e
√
. Applying Sterling’s approximation for n!
is at least log2
(
), this gives us a lower bound of
r + (n − r) log2
(1)
When r (cid:12) n, the second term approaches r/ ln 2 ≈ 1.44r
and the third term approaches −(1/2) log2 r. The fourth term
is about −1.2, so that the dominant terms in Eq. (1) are
n
r and 1.44r. The lower bound can be met if both parties
r log2
share an ordered list of all n certiﬁcates. Unfortunately, when
representing real certiﬁcates, we cannot assume a globally
known ordered list. However, as we show next, with the right
choice of false positive rates, ﬁlter cascades can be constructed
using 1.44r log n
False Positive Strategy.
As the following analysis shows,
a strategy of using one false positive probability, p1, at the
ﬁrst level, and a second false positive probability, p, at all
subsequent
levels produces a ﬁlter cascade whose size is
competitive with the lower bound6. The simplicity of the
strategy makes it straightforward to implement and analyze.
Observe that the size of a Bloom ﬁlter at the ﬁrst level
is a function of r and the desired false positive probability,
but does not depend on s. Thus, if r is less than s we have
some leverage, as we can reduce the number of elements in
S using a Bloom ﬁlter whose size is based on the smaller
value r. We set the false positive probability at the ﬁrst level
to bring the expected number of elements in S down to about
r. In particular, we choose p1 = r
p/s, so that the expected
number of false positives among the s non-revoked certiﬁcates
r + 4.2r bits (or perhaps even less).
√
6Note that prior work on ﬁlter cascades assumes a single false positive rate
for all levels [74], [64], and thus has slightly worse space utilization.
545
p. The
p factor is included in the formula for p1 so
is r
that at all subsequent levels, the ratio between the expected
number of elements inserted to the number that are not inserted
is always the same,
√
p, which simpliﬁes the analysis.
√
As a running example, for all levels after the ﬁrst let p =
√
1/2 and k = 1, so that p1 = r/
2s and the expected number
√
of false positives at the ﬁrst level is r/
2. The size of the
ﬁrst level is 1.44r log2(s/r
p), which, for p = 1/2, is at
n
r + .72r. The ﬁrst level is the only one that
most 1.44r log2
requires Ω(r log(n/r)) bits and the leading constant of 1.44
√
is small. After the ﬁrst level, the expected number of elements
remaining in R∪S is O(r) (i.e., (1+1/
2)r in our example),
so only O(r) additional bits will needed.
We now analyze the size of all the levels after the ﬁrst. The
achieved false positive rate at each level is a random variable
that depends on the random hash function chosen at that level.
These variables are independent, so the expectation of their
product is equal to the product of their expectations. Hence,
√
at level i + 1, the expected number of items to be inserted into
p)i, and the expected number of items
the Bloom ﬁlter is r(
√
not to be inserted but for which false positives might occur is
p)i−1. The total expected size over all levels after the ﬁrst
r(
is then given by
∞(cid:6)
1.44r
p log2
1
p
√
p)
i
1.44r(
log2
1
p =
√
1 − √
p
(2)
i=1
For p = 1/2, the sum comes to 3.48r. Hence, in our example
n
r + 4.2r.
the expected total cost over all levels is 1.44r log2
Although we have not paid particular attention to integrality
constraints, by choosing p = 1/2 and k = 1 in our example
we have taken care of the most important such constraint.
Simulations.
We close this section by empirically eval-
uating the size and lookup times of ﬁlter cascades using
simulation. For a variety of values of r and s, we conduct
a systematic search through the possible values of p1 and p
to try to minimize the total side of the ﬁlter cascade. In this
empirical analysis we insist that m, n, r, s, and the number of
hash functions at each level be integral. To calculate expected
Bloom ﬁlter size, we use the following bound due to Goel and
Gupta [30], which holds for m > 1 and is derived rigorously,
making no independence assumptions or approximations:
(cid:2)
1 − e−(r+ 1
p ≤
2 )k/(m−1)
(cid:3)k
We ﬁnd that, in practice, the optimal p tends to be very nearly
1/2 when r (cid:12) s. In estimating the expected number of levels,
we apply the bound derived in Appendix A.
Figure 3a shows that the overall size of a ﬁlter cascade is
determined primarily by the number of elements in R. This
is because, as discussed above, the size of the ﬁlter cascade
is dominated by the size of the ﬁrst Bloom ﬁlter, into which
each element of R must be inserted.
Figures 3b and 3c show the expected number of hash func-
tions that need to be computed when looking up an element
of R or S, respectively. We make two key observations: First,