0
Snapshot
Sampled
Snapshot
Sampled
)
%
(
F
D
C
C
100
80
60
40
20
0
0
5
10
15
Degree
20
25
30
0
250
1250
Session Length (minutes)
1000
750
500
)
%
(
F
D
C
C
100
80
60
40
20
0
0
Figure 3: The sampled and expected distributions are visually indistinguishable.
Snapshot
Sampled
150
300
450
600
750
900
Query Latency (RTT—ms)
f
o
r
o
r
r
E
g
n
i
l
p
m
a
S
)
D
(
e
e
r
g
e
D
Pareto α = 1.9
Pareto α = 2.1
Weibull
Exponential
0.1
0.08
0.06
0.04
0.02
0
0.1
100
Median Session Length (minutes)
10
1
)
f
o
D
(
r
o
r
r
E
g
n
h
t
g
n
e
L
i
l
p
m
a
S
n
o
i
s
s
e
S
Pareto α = 1.9
Pareto α = 2.1
Weibull
Exponential
0.1
0.08
0.06
0.04
0.02
0
0.1
100
Median Session Length (minutes)
10
1
)
f
o
D
r
o
r
r
E
g
n
i
l
p
m
a
S
(
y
c
n
e
t
a
L
y
r
e
u
Q
Pareto α = 1.9
Pareto α = 2.1
Weibull
Exponential
0.1
0.08
0.06
0.04
0.02
0
0.1
100
Median Session Length (minutes)
10
1
Figure 4: Sampling error of the three fundamental properties as a function of session-length distribution. Exceptionally heavy churn (median < 1min)
introduces error into the sampling process.
tribution function from the perfect snapshot, the KS statis-
tic is:
D = max (|S(x) − E(x)|)
In other words, if we plot the sampled and expected CDFs,
D is the maximum vertical distance between them and has
a possible range of [0, 1]. For Figures 3a, 3b, and 3c, the
values of D were 0.0019, 0.0023, and 0.0037, respectively.
For comparison, at the p = 0.05 signiﬁcance level, D is
0.0061, for the two-sample KS statistic with 100,000 data
points each. However, in practice we do not expect most re-
searchers to gather hundreds of thousands of samples. After
all, the initial motivation for sampling is to gather reason-
ably accurate data at relatively low cost. As a rough rule
of thumb, a value of D ≥ 0.1 is quite bad, corresponding to
at least a 10 percentage point diﬀerence on a CDF. A value
of D ≤ 0.01 is excellent for most purposes when studying a
peer property, corresponding to no more than a 1 percentage
point diﬀerence on a CDF.
5.4 Exploring diﬀerent dynamics
In this section, we examine how the amount of bias changes
as we vary the type and rate of dynamics in the system.
We examine diﬀerent settings of the simulation parameters
that aﬀect dynamics, while continuing to use the topologi-
cal characteristics from our base case (Table 2). We would
expect that as the rate of peer dynamics increases, the sam-
pling error also increases. The key question is: How fast
can the churn rate be before it causes signiﬁcant error, and
is that likely to occur in practice?
In this subsection, we present the results of simulations
with a wide variety of rates using three diﬀerent models for
session length, as follows:
Exponential: The exponential distribution is a one-parameter
distribution (rate λ) that features sessions relatively
close together in length.
It has been used in many
prior simulation and analysis studies of peer-to-peer
systems [24, 25, 31].
Pareto: The Pareto (or power-law) distribution is a two-
parameter distribution (shape α,
location xm) that
features many short sessions coupled with a few very
long sessions. Some prior measurement studies of peer-
to-peer systems have suggested that session lengths
follow a Pareto distribution [6, 12, 34]. One diﬃculty
with this model is that xm is a lower-bound on the
session length, and ﬁts of xm to empirical data are
often unreasonably high (i.e., placing a lower bound
signiﬁcantly higher than the median session length re-
ported by other measurement studies).
In their in-
sightful analytical study of churn in peer-to-peer sys-
tems, Leonard, Rai, and Loguinov [22] instead suggest
using a shifted Pareto distribution (shape α, scale β)
with α ≈ 2. We use this shifted Pareto distribution,
holding α ﬁxed and varying the scale parameter β. We
examine two diﬀerent α values: α = 1.9 (inﬁnite vari-
ance) and α = 2.1 (ﬁnite variance).
Weibull: Our own empirical observations [39] suggest the
Weibull distribution (shape k, scale λ) provides a good
model of peer session lengths, representing a compro-
mise between the exponential and Pareto distributions.
We ﬁx k = 0.59 (based on our empirical data) and vary
the scale parameter λ.
Figure 4 presents the amount of sampling error (D) as a
function of median session length, for the three fundamen-
tal properties, with a logarithmic x-axis scale. The ﬁgure
shows that error is low over a wide range of session lengths
but begins to become signiﬁcant when the median session
length drops below 2 minutes, and exceeds D = 0.1 when
f
o
r
o
r
r
E
g
n
i
l
p
m
a
S
)
D
(
e
e
r
g
e
D
0.1
0.08
0.06
0.04
0.02
0
0
Random Oracle
FIFO
Soft State
History
Random Oracle
FIFO
Soft State
History
0.1
0.08
0.06
0.04
0.02
Random Oracle
FIFO
Soft State
History
0.1
0.08
0.06
0.04
0.02
)
f
o
D
r
o
r
r
E
g
n
i
l
p
m
a
S
(
y
c
n
e
t
a
L
y
r
e
u
Q
)
f
o
D
(
h
t
g
n
e
L
r
o
r
r
E
g
n
i
l
p
m
a
S
n
o
i
s
s
e
S
10
5
Target Peer Degree
20
15
25
30
0
0
10
5
Target Peer Degree
15
20
25
30
0
0
10
5
Target Peer Degree
15
20
25
30
Figure 5: Sampling error of the three fundamental properties as a function of the number of connections each peer actively attempts to maintain. Low target
degree (≤ 2) introduces signiﬁcant sampling error.
the median drops below 30 seconds. The type of distribution
varies the threshold slightly, but overall does not appear to
have a signiﬁcant impact. To investigate whether the critical
threshold is a function of the length of the walk, we ran some
simulations using walks of 10,000 hops (which take around
one simulated hour to complete). Despite the long dura-
tion of these walks, they remained unbiased with D < 0.003
for each of the three fundamental properties. This suggests
that the accuracy of MRWB is aﬀected primarily by the rate
of local variation in the ratio degree(x)
degree(y) relative to the time
required to query peers, rather than the speed of global vari-
ations relative to the length of the walk.
While the median session length reported by measurement
studies varies considerably (see [31] for a summary), none
report a median below 1 minute and two studies report a