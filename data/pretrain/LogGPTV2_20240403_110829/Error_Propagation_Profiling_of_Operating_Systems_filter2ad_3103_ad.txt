### Table 6: OS Service Error Exposure

| OS Service | connect | closesocket | shutdown | getaddrinfo | getnameinfo | getpeername | memset | select | sendto | socket | strcpy | WSACleanup | WSAStartup |
|------------|---------|-------------|----------|-------------|-------------|--------------|--------|--------|--------|--------|--------|------------|-------------|
| Failure Class | NF (274) | NF (274) | NF (274) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) | NF (414) |
| Ej | 0.066 | 0.066 | 0.066 | 0.066 | 0.066 | 0.066 | 0.066 | 0 | 0 | 0 | 0 | 0 | 0 |

### Table 7: OS Service Error Exposure

| OS Service | cerfio serial.Dll. | 91C111.Dll. |
|------------|-------------------|-------------|
| connect | 85 | 85 |
| closesocket | 85 | 85 |
| shutdown | 85 | 85 |
| getaddrinfo | 0 | 0 |
| getnameinfo | 0 | 0 |
| getpeername | 0 | 0 |
| memset | 0 | 0 |
| select | 0 | 0 |
| sendto | 0 | 0 |
| socket | 0 | 0 |
| strcpy | 0 | 0 |
| WSACleanup | 0 | 0 |
| WSAStartup | 0 | 0 |
| Ej | 0.205 | 0.205 |

### Table 8: Results of Injection Experiments

| Driver | cerfio serial.Dll | 91C111.Dll |
|--------|------------------|------------|
| C1 Dk | 0.007 | 0.022 |
| C2 Dk | 0.460 | 0.002 |
| C3 Dk | 0.616 | 0.601 |
| Total | 0.482 | 0.625 |

## 7. Discussion

### Identification of Vulnerabilities

The primary goal of our proposed profiling methodology is to identify potential vulnerabilities in the system. We focus on two distinct interfaces: the OS-application interface and the OS-driver interface. The key findings from this study are:

- **OS-Driver Interface**: Specific services for one driver (Ethernet driver) are susceptible to errors leading to severe failures, such as `FreeLibrary` and `LoadLibrary` (Table 5).
- **OS-Application Interface**: A set of services at the OS-application interface is also susceptible to errors (Tables 6 and 7). A clustering effect is observed, revealing dependencies across services, as well as unexpected lack thereof.
- **Driver Error Diffusion**: The network driver (`91C111.Dll`) is more likely to spread errors (0.625 > 0.482 in Table 8) than the serial port driver.
- **No Correlation Across Drivers**: No shared propagation paths between the drivers were observed.

It is important to note that the identified vulnerabilities may not correspond to bugs in the OS. The term "vulnerability" is used to signify a potential weakness in the system. An exposed propagation path only indicates the presence of potential vulnerabilities; whether these paths will be exploited in the operational mode of the system is not guaranteed. To better understand this, we intend to extend the model to include applications.

The Driver Error Diffusion values are calculated based on the entire set of experiments. Therefore, the values depend on the number of experiments; the higher the number of experiments, the lower the values. If the number of experiments is disregarded, the number of errors should be compared. Assuming that the potential sources for vulnerabilities increase with the number of functions, the first method becomes useful for comparing drivers. The Driver Error Diffusion then indicates the likelihood of actual vulnerabilities being present, given the size of the interface. For impact analysis, the number of failures might be more important, and here focusing on each error case, starting with Class 3, is a relevant approach.

### Application Profile

The operational profile of an application, i.e., how it uses and depends on the OS, significantly impacts the robustness of the system. The subset of services used and their exposure to errors affect the system-wide exposure to errors. In this case study, four applications were used, which both loaded the system during the experiments and measured the propagation of errors. For propagation profiling to be truly useful, real application profiles must be used. The operational profile of real applications must influence the interpretations of the exposure and diffusion measures.

An application profile should consider:
- The services used by the application.
- The impact of errors in these services on the application.
- The frequency at which they are used.
- The relative criticality of the application.

When profiles exist for the applications in the system, they can be composed with the exposure profile to get a system-wide profile, which ranks the applications (and the services they depend upon) according to their susceptibility to propagating errors. The definition and implementation of such application profiling are part of our future work.

### Experiments

A crucial aspect of our methodology is its repeatability. Our experiments are repeatable, as no randomness is involved in choosing the error type or location. However, there is a risk that the state of the system is not the same for every injection. We mitigate this problem by rebooting the system before each injection and have found no deviation so far for multiple runs of the same experiment set.

We acknowledge that our current method is not complete. A concern when using any fault injection (FI) technique is the choice of error model. Without a valid error model, the conclusions derived might be misleading or even false. We have chosen a simple but realistic error model for our experiments, meaning that the errors we inject are possible in real systems and are not caught by the compiler. We believe that the errors we use are representative of real errors. Extending and including more error models to study their respective properties, such as exposing coverage, cost in terms of implementation effort, and execution time, is part of our future work.

Another concern for any FI experiment is to minimize intrusiveness on the target system to avoid influencing the results. In our setup, the Manager and Interceptor run on the target system. To minimize their impact, we designed them to be as small as possible, with the number of messages kept to a minimum. Most communication takes place before the system has booted up, i.e., before an error is injected.

### Wrapper Placement & Design

For effective use of wrappers, the actual wrapper composition is crucial. The measures presented above help in this regard. Careful inspection of the failure of `LoadLibrary` (Table 5) reveals that it occurs during boot-up of the system, meaning that no application, however well-designed, can cope with this error. This suggests that a wrapper for this error must be placed at the OS-driver interface level, filtering parameters to prevent this type of error from passing. With code access, this information can be used to verify that this vulnerability is not used/activated from a driver. For other failures of lesser impact, like `CreateFile` in Table 6, wrappers can be defined at the OS-application level, implementing, for instance, a restart functionality to handle transient errors. The development of wrappers and studying their usefulness for enhancing the robustness of the system is an important part of our future work.

### Future Work

Our ongoing and future work includes extending the current prototype in several directions. We intend to use a larger set of targets, both drivers and OSs (e.g., Windows CE .Net 5.0, Windows XP, and Linux). We also plan to investigate error models of varying levels of detail to analyze the effectiveness of different error models.

## 8. Conclusions

Overall, the contributions of this paper lie in developing measures to aid in the quantification of OS error flow. The relevance of these measures and the associated methodology is demonstrated by the OS case study, where the experiments exposed several potential vulnerabilities. This information can be used either to place wrappers in the system or as feedback to OS or driver designers. We believe this shows the utility of the proposed measures and methodology. Studying exposure and impact of errors tells the designer not only where many errors may pass but also, more importantly, where occurring errors may have severe consequences. Without this profiling, this information would not be available. As demonstrated, the potential vulnerabilities can lead to system failure, regardless of how the applications on the system are designed (and verified). We also find it significant that the observed vulnerabilities were identified using limited black-box information.

### Acknowledgments

We express our appreciation for the help and insights from Martin Hiller, Falk Fraikin, the DEEDS group, and the funding support from Microsoft Research.

### References

[1] A. Albinet et al. Characterization of the Impact of Faulty Drivers on the Robustness of the Linux Kernel. Proc. of DSN, pp. 807–816, 2004.
[2] J. Dur˜aes, H. Madeira. Multidimensional Characterization of the Impact of Faulty Drivers on the OS Behavior. IEICE Trans., E86-D(12):2563–2570, Dec. 2003.
[3] J. Arlat et al. Dependability of COTS Microkernel-Based Systems. IEEE Trans. on Computers, 51(2):138–163, Feb. 2002.
[4] T. Ball, S. Rajamani. The SLAM project: Debugging System Software via Static Analysis. Proc. of POPL, pp. 1–3, 2002.
[5] A. Chou et al. An Empirical Study of Operating System Errors. Proc. of SOSP, pp. 73–88, 2001.
[6] J. DeVale, P. Koopman. Performance Evaluation of Exception Handling in I/O Libraries. Proc. of DSN, pp. 519–524, 2001.
[7] J.-C. Fabre et al. Building Dependable COTS Microkernel-Based Systems Using Mafalda. Proc. of PRDC, pp. 85–92, 2000.
[8] C. Fetzer, Z. Xiao. An Automated Approach to Increasing the Robustness of C Libraries. Proc. of DSN, pp. 155–164, 2002.
[9] T. Fraser et al. Hardening COTS SW With Generic SW Wrappers. Proc. of OASIS, pp. 399–413, 2003.
[10] W. Gu et al. Characterization of Linux Kernel Behavior Under Errors. Proc. of DSN, pp. 459 – 468, 2003.
[11] M. Hiller, A. Jhumka, N. Suri. PROPANE: An Environment for Examining the Propagation of Errors in Software. Proc. of ISSTA, pp. 81–85, 2002.
[12] M. Hiller, A. Jhumka, N. Suri. EPIC: Profiling the Propagation and Effect of Data Errors in Software. IEEE Trans. on Computers, 53(5):512–530, May 2004.
[13] A. Johansson et al. On Enhancing the Robustness of Commercial OS’s. Proc. of ISAS, pp. 174–185, 2004.
[14] P. Koopman, J. DeVale. Comparing the Robustness of POSIX OS’s. Proc. of FTCS, pp. 30–37, 1999.
[15] T. Mitchem et al. Linux Kernel Loadable Wrappers. Proc. of DARPA Information Survivability Conf., vol. 2, pp. 296–307, 2000.
[16] B. Murphy, B. Levidow. Windows 2000 Dependability. Proc. of the Workshop on Dependable Networks and OS, pp. D20–28, 2000.
[17] J. Pan et al. Robustness Testing and Hardening of CORBA Orb Implementations. Proc. of DSN, pp. 141–150, 2001.
[18] L. R´eveill`ere, G. Muller. Improving Driver Robustness: an Evaluation of the Devil Approach. Proc. of DSN, pp. 131–140, 2001.
[19] M. M. Swift et al. Improving the Reliability of Commodity OS’s. Proc. of SOSP, pp. 207–222, 2003.
[20] T. Tsai, N. Singh. Reliability Testing of Applications on Windows NT. Proc. of DSN, pp. 427–436, 2000.

---

**Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05)**
**0-7695-2282-3/05 $20.00 © 2005 IEEE**