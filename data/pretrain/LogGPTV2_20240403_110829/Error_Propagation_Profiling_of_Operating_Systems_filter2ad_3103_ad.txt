9
9
9
9
9
3
0
0
0
0
0
0
0
0
0
0
0
(cid:0)
Ej
0.066
0.066
0.066
0.066
0.066
0.066
0.066
0
0
0
0
Table 6. OS Service Error Exposure
cerfio serial.Dll.
for
OS Service
connect
closesocket
shutdown
getaddrinfo
getnameinfo
getpeername
memset
select
sendto
socket
strcpy
WSACleanup
WSAStartup
Failure Class
NF
274
274
274
414
414
414
414
414
414
414
414
414
414
1
85
85
85
0
0
0
0
0
0
0
0
0
0
2
1
1
1
1
1
1
1
1
1
1
1
1
1
3
3
3
3
3
3
3
3
3
3
3
3
3
3
(cid:0)
Ej
0.205
0.205
0.205
0
0
0
0
0
0
0
0
0
0
Table 7. OS Service Error Exposure
91C111.Dll.
for
2 and so on. Table 8 shows that taking error impact into
consideration, the network driver has the more severe errors,
whereas the serial driver has more Class 2 failures. Thus
these two classes of failures should be the focus of the ﬁrst
round of wrapping. The network driver has overall more
failures but mainly of lesser impact, however these are still
candidates for wrapping.
Driver
cerﬁo serial.Dll
91C111.Dll
Failure Class Diffusion
Dk
C2 Dk
C3
0
C1 Dk
0.007
0.460
0.616
0.022
0.002
Total
0.482
0.625
Table 8. Results of injection experiments.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
7. Discussion
Identiﬁcation of Vulnerabilities: The purpose of our
proposed proﬁling methodology is to identify potential vul-
nerabilities in the system. We target two distinct interfaces;
the OS-application interface and the OS-driver interface.
The main results of this study can be summarized as:
- Studying services at the OS-driver interface re-
veals speciﬁc services for one driver (Ethernet
driver) to be susceptible to errors leading to severe
failures, i.e., FreeLibrary and LoadLibrary (Table 5).
- A set of services at the OS-application interface is
susceptible to errors (Tables 6 and 7). A clustering
effect is observed which reveals dependencies across
services, as well as unexpected lack thereof.
- Comparing Driver Error Diffusion values, we con-
clude that the network driver (91C111.Dll) is
more likely to spread errors (0.625 > 0.482 in Table
8) than the serial port driver.
- No correlation across drivers was observed, i.e.,
no “shared” propagation paths between the drivers.
It is important to note that the vulnerabilities identiﬁed
may not correspond to “bugs” in the OS. We have chosen
to use the word “vulnerability” to signify that this is only a
potential weakness in the system. An exposed propagation
path only indicates that there are potential vulnerabilities
in the system. Whether this path will actually be used in
the operational mode of the system is not assured. To bet-
ter consider this relation we intend to extend the model to
include applications as well.
The Driver Error Diffusion values are calculated using
the whole set of experiments. Thus the values depend on
the number of experiments, i.e., the higher the number of
experiments, the lower the values.
If one disregards the
number of experiments, the number of errors is to be com-
pared. Assuming that the potential sources for vulnerabili-
ties increase with the number of functions, the ﬁrst method
becomes useful to compare drivers. The Driver Error Dif-
fusion then indicates the likelihood of actual vulnerabilities
being present, given the size of the interface. For impact
analysis, the number of failures might be of more impor-
tance, and here focusing on each error case, starting with
Class 3 is a relevant approach.
Application Proﬁle: The operational proﬁle of an ap-
plication, i.e., the way an application in the system uses
and depends on the OS, has a high impact on the robust-
ness of the system. The subset of services used and their
exposure to errors affect the system wide exposure to er-
rors. For this case study four applications were used, that
both load the system for the duration of the experiments and
measure the propagation of errors. For propagation proﬁl-
ing to be truly useful, real application proﬁles must be used.
The operational proﬁle of real applications, must inﬂuence
the interpretations of the exposure and diffusion measures.
An application proﬁle must consider a) the services used by
an application, b) the impact errors in these services have
on the application, c) the frequency at which they are used,
and c) the relative criticality of the application. When the
proﬁles exist for the applications in the system, they can be
composed with the exposure proﬁle to get a system-wide
proﬁle, which ranks the applications (and the services they
depend upon) according to their susceptibility to propagat-
ing errors. The deﬁnition and implementation of such ap-
plication proﬁling is part of our future work.
Experiments: An important aspect of our methodology
is for it to be repeatable. Our experiments are repeatable
in the sense that no randomness is involved in choosing the
error type or location. However, there is a risk that the state
of the system is not the same for every injection. We limit
this problem by rebooting the system before each injection
and we have found no deviation so far for multiple runs of
the same experiment set.
Naturally we acknowledge that our current method is
not complete. A concern when using any FI technique is
the choice of error model. Without a valid error model the
conclusions derived might be misleading or even false. We
have chosen a simple, but yet realistic, error model for our
experiments. This means that the errors we inject are possi-
ble in real systems; they are for instance not caught by the
compiler. We believe that the errors we use are represen-
tative of real errors. However, it is part of our future work
to extend and include more error models, to study their re-
spective properties such as exposing coverage (the number
of vulnerabilities exposed and their type), cost in terms of
implementation effort and the execution time.
Another concern for any FI experiment is to use a min-
imum of intrusiveness on the target system, in order for
the experiments not to be inﬂuenced by the setup. For our
setup, the Manager and Interceptor run on the target system,
see Figure 2. To minimize their impact on the results, we
have designed them to be as small as possible. The num-
ber of messages being sent is kept to the bare minimum.
Most of the communication takes place before the system
has booted up, i.e, before an error is injected.
Wrapper Placement & Design: For effective use of
wrappers, the actual wrapper composition is of importance.
The measures presented above also help for this purpose.
Careful inspection of the failure of LoadLibrary (Table 5)
reveals that it occurs during boot-up of the system. This
means that no application, however well designed, can cope
with this error. This suggests that a wrapper for this er-
ror must be placed at the OS-driver interface level, ﬁlter-
ing the parameters, to not allow this type of error to pass.
With code access this information can be used to verify that
this vulnerability is not used/activated from a driver. For
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
some other failures of lesser impact, like CreateFile in Ta-
ble 6, wrappers can be deﬁned at the OS-application level,
implementing for instance a restart functionality handling
transient errors. The development of wrappers and study of
their usefulness for enhancing the robustness of the system
is an important part of our future work.
Future Work: Our ongoing and future work includes
extending the current prototype in several directions. We
intend to use a larger set of targets, both drivers and OS’s
(e.g., Windows CE .Net 5.0, Windows XP and Linux). We
also intend to investigate error models of varied level of de-
tail, to analyze the effectiveness of different error models.
8. Conclusions
Overall, the contributions of this paper lie in develop-
ing measures to aid quantiﬁcation of OS error ﬂow. The
relevance of the measures and associated methodology is
demonstrated by the OS case study where the experiments
exposed a number of potential vulnerabilities. This infor-
mation can be used either to place wrappers in the system
or as feedback to OS or driver designers. We believe that
this shows the utility of the proposed measures and method-
ology. Studying exposure and impact of errors tells the de-
signer not only where many errors may pass but also more
importantly where occurring errors may have severe conse-
quences. Without this proﬁling, this information would not
have been available. As demonstrated, the potential vul-
nerabilities can lead to system failure, no matter how the
applications on the system are designed (and veriﬁed). We
also ﬁnd it signiﬁcant that the observed vulnerabilities were
identiﬁed using limited black-box information.
Acknowledgments: We express our appreciation for
help and insights from Martin Hiller, Falk Fraikin, the
DEEDS group and the funding support from Microsoft Re-
search.
References
[1] A. Albinet et al. Characterization of the Impact of
Faulty Drivers on the Robustness of the Linux Kernel.
Proc. of DSN, pp. 807–816, 2004.
[2] J. Dur˜aes, H. Madeira. Multidimensional Characteriza-
tion of the Impact of Faulty Drivers on the OS Behavior.
IEICE Trans., E86-D(12):2563–2570, Dec. 2003.
[3] J. Arlat et al. Dependability of COTS Microkernel-
Based Systems. IEEE Trans. on Computers, 51(2):138–
163, Feb. 2002.
[4] T. Ball, S. Rajamani. The SLAM project: Debugging
System Software via Static Analysis. Proc. of POPL, pp.
1–3, 2002.
[5] A. Chou et al. An Empirical Study of Operating System
Errors. Proc. of SOSP, pp. 73–88, 2001.
[6] J. DeVale, P. Koopman. Performance Evaluation of Ex-
ception Handling in I/O Libraries. Proc. of DSN, pp.
519–524, 2001.
[7] J.-C. Fabre et al.
Building Dependable COTS
Microkernel-Based Systems Using Mafalda. Proc. of
PRDC, pp. 85–92, 2000.
[8] C. Fetzer, Z. Xiao. An Automated Approach to Increas-
ing the Robustness of C Libraries. Proc. of DSN, pp.
155–164, 2002.
[9] T. Fraser et al. Hardening COTS SW With Generic SW
Wrappers. Proc. of OASIS, pp. 399–413, 2003.
[10] W. Gu et al. Characterization of Linux Kernel Behav-
ior Under Errors. Proc. of DSN, pp. 459 – 468, 2003.
[11] M. Hiller, A. Jhumka, N. Suri. PROPANE: An En-
vironment for Examining the Propagation of Errors in
Software. Proc. of ISSTA, pp. 81–85, 2002.
[12] M. Hiller, A. Jhumka, N. Suri. EPIC: Proﬁling the
Propagation and Effect of Data Errors in Software. IEEE
Trans. on Computers, 53(5):512–530, May 2004.
[13] A. Johansson et al. On Enhancing the Robustness of
Commercial OS’s. Proc. of ISAS, pp. 174–185, 2004.
[14] P. Koopman, J. DeVale. Comparing the Robustness of
POSIX OS’s. Proc. of FTCS, pp. 30–37, 1999.
[15] T. Mitchem et al. Linux Kernel Loadable Wrappers.
Proc. of DARPA Information Survivability Conf., vol. 2,
pp. 296–307, 2000.
[16] B. Murphy, B. Levidow. Windows 2000 Dependabil-
ity. Proc. of the Workshop on Dependable Networks and
OS, pp. D20–28, 2000.
[17] J. Pan et al. Robustness Testing and Hardening of
CORBA Orb Implementations. Proc. of DSN, pp. 141–
150, 2001.
[18] L. R´eveill`ere, G. Muller.
Improving Driver Robust-
ness: an Evaluation of the Devil Approach. Proc. of
DSN, pp. 131–140, 2001.
[19] M. M. Swift et al. Improving the Reliability of Com-
modity OS’s. Proc. of SOSP, pp. 207–222, 2003.
[20] T. Tsai, N. Singh. Reliability Testing of Applications
on Windows NT. Proc. of DSN, pp. 427–436, 2000.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE