as top-symbol. For instance, the P -representation of the
‘usual’ term p(p(e(a, k), e(b, k(cid:48))), e(c, k(cid:48)(cid:48))) is:
P11,12,2(e(a, k), e(b, k(cid:48)), e(c, k(cid:48)(cid:48))).
And the E-representation of the usual term e(e(a, k1), k2)
is E(a, k1, k2). But only ‘legal’ bit string sequences v can
lead to meaningful terms with p on top. Such sequences are
deﬁned, inductively, as follows2:
· The empty string  is a legal bit string sequence (it is of
length 0).
· If v = a1, ..., an and w = b1, ..., bm are legal sequences of re-
spective lengths n, m, then 1.v, 2.w = 1a1, ..., 1an, 2b1, ..., 2bm
is a legal sequence, of length n + m.
We now deﬁne formally the P - and E-representations of
a term:
(P): Deﬁne a position q in a term t to be a pure p-position
in t iﬀ epos(q, t) = . We say that q is a maximal pure p-
position in t iﬀ q is a pure p-position in t, and q is not a
proper preﬁx of any pure p position in t.
For instance, let t = p(p(a, b), e(p(c, d), k)), then the pure
p-positions in t are the positions where the subterms t, p(a, b),
a, b and e(p(c, d), k) occur. And the maximal pure p-positions
in t are the positions of the subterms a, b and e(p(c, d), k).
The P -representation of a term t is then Pq1,··· ,qn (t1,··· , tn)
where {q1,··· , qn} is the lexicographically ordered set of
maximal pure p-positions in t, and for all i, t|qi = ti.
(E): Deﬁne a position q in term t to be a pure e-position in
t if ppos(q, t) = . If q is a pure e-position in t, and q either
contains no 2 at all or contains 2 only as the last element
of the sequence, then q is said to be a penuk-position in t.
(penuk abbreviates ‘pure e-position not under a key’.) We
say that q is a maximal penuk-position in t if q is a penuk-
position in t, and q is not a proper preﬁx of any penuk-
position in t.
For instance, if t = e(e(a, b), e(c, d)), then every position
in t is a pure e-position in t. Every position in t is a penuk-
position except for 21 and 22 where c and d occur. The
maximal penuk positions are the positions where a, b and
e(c, d) occur. (The reader can now see why the name penuk:
the terms c and d are inside the key e(c, d) that encrypts the
message e(a, b).)
The E-representation of a term t is then E(t1,··· , tn)
where {q1,··· , qn} is the set of all maximal penuk-positions
in t written in lexicographic order, and for all i, t|qi = ti.
Remark: The P -representation (resp. E-representation) of
a usual term t normalizes to its usual representation, under
the rewrite rules P (resp. E) below :
(P): P(t) → t
P1.v,2.w(t1, . . . , tn+m)
→ p(Pv(t1, . . . , tn), Pw(tn+1, . . . , tn+m))
if v (resp. w) is a legal bit string sequence of length n
(resp. m).
2These bit strings correspond to leaf positions on binary
trees
(E): E(t) → t
E(t, k1, . . . , kn−1, kn) → e(E(t, k1, . . . , kn−1), kn)
We may now formulate the Homomorphic Pattern rules.
• (Shaping)
Γ (cid:116) {Pv(t1, . . . , E(x, km, . . . , kn), . . . , tl)
1, . . . , k(cid:48)
= E(s, k(cid:48)
⇒
n)}
Γ ∪ {Pv(t1, . . . , E(x(cid:48), k(cid:48)
1, . . . , k(cid:48)
m−1, km, . . . , kn), . . . , tl)
= E(s, k(cid:48)
1, . . . , k(cid:48)
n)} ∪ {x = E(x(cid:48), k(cid:48)
1, . . . , k(cid:48)
m−1)}
where x(cid:48) is a fresh variable, v is a (legal) bit string
sequence, and n ≥ m > 1.
• (Failure)
(i) Γ (cid:116) {s = t} ⇒ F ail
if s, t are out of phase on some variable at a non-key
position (i.e., with epos containing only 1’s). 3
(ii) Γ (cid:116) {Pv(t1, . . . , E(ti, k1, . . . , km), . . . , tl)
= E(s, k(cid:48)
1, . . . , k(cid:48)
n)} ⇒ F ail
where v is a (legal) bit string sequence, ti not a vari-
able, and m < n.
• (Parsing)
Γ (cid:116) {Pv(E(t1, k11, . . . , k1m1 ), . . . , E(tl, kl1, . . . , klml ))
= E(s, k1, . . . , km)}
⇒
Γ(cid:116){Pv(E(t1, k11, . . . , k1m1−1), . . . , E(tl, kl1, . . . , klml−1))
= E(s, k1, . . . , km−1)}
∪ {k1m1 = k2m2 = ··· = klml = km}
where v is a (legal) bit string sequence.
The Homomorphic Pattern rules are to be performed en
bloc together with the Variable Substitution rule given above,
by which we mean: whenever one of these ‘Homomorphic
Pattern’ rules or the ‘Variable Substitution’ rule applies,
none among the remaining rules shall be applied. The ‘Shap-
ing’ rule helps make the terms being uniﬁed to be ‘well-
structured’. The ‘Parsing’ rule takes a pair of ‘well-structured’
terms, and solves for them with a macro inference, based
on the above mentioned principle of ‘encryption distributes
over pairs’. The ‘Failure’ rule tries to detect failure as early
as possible, and is always applied the most eagerly among
all rules. Failure rule (i) is sound by Lemma 1, while Fail-
ure rule (ii) corresponds to the case where the two terms
considered have diﬀerent numbers of keys, but Shaping is
inapplicable.
A simple example of Failure (i) rule is for p(x, y) = e(x, k).
The x in p(x, y) is considered as an encryption with zero
keys. The x in e(x, k) is in an encryption with 1 key. By
the footnote of Failure (i) we fail because 0 < 1. Note also
that p(x, y) and e(x, k) are out of phase on x.
The Eh-Unifn procedure is deﬁned by all the above rules
and the rules for syntactic uniﬁcation. We explicitly make
3As we will see in the Completeness proof, we only need to
check if s is of the form Pv(. . . , E(x, ki1, . . . , kimi ), . . . ), t is
of the form E(x, k1, . . . , km) and mi < m. That is the only
‘out of phase’ condition that is necessary for completeness.
the following assumption:
the equations of our problems
are given in Eh-normal form, and any new equation derived
under the inferences is kept in Eh-normal form.
A solved form for Eh-Unifn is a set of Eh-equalities {x1 =
t1,··· , xn = tn}, where each xi is a solved variable, each
ti is a usual term. (Note: a variable x, in a set of equality
constraints, is said to be solved iﬀ x appears only once, and
as the lhs of an equation of the form x = t with t a term.)
A solved form for s = t is denoted as nf (s = t). We shall be
showing below that two terms s and t are uniﬁable modulo
Eh if and only if there exists a solved form for s = t.
For any given set of Eh-uniﬁcation problems Γ, let uvars(Γ)
be the number of distinct unsolved variables in Γ. For any
equality S appearing in Γ, let T erms(S) be the multiset
{s| s appears in S}; and let U nif ns(T erms(Γ)) be the mul-
tiset {T erms(S)| S ∈ Γ}. We then deﬁne a measure M (Γ)
for the cap uniﬁcation problem Γ as the lexicographic pair
(uvars(Γ), U nif ns(T erms(Γ))).
Lemma 3. Let Γ be any set of Eh-uniﬁcation problems.
All the above inference rules for Uniﬁcation modulo Eh re-
duce M (Γ).
Proof. We show that the Homomorphic Pattern rules
reduce M (Γ); it is straightforward that all the other rules
reduce the measure.
No rule in Homomorphic Pattern increases the number
of unsolved variables. We show that, if any of the above
rules increases U nif ns(T erms(Γ)), then it must decrease
uvars(Γ).
Among the inference rules, Shaping is the only one that
can increase U nif ns(T erms(Γ)), since a variable x gets then
replaced by E(x(cid:48), k1, . . . , km), where x(cid:48) a new variable.
To show this, we ﬁrst observe that the Shaping rule cannot
be applied if s = x, where s and x are as in the Shaping Rule:
indeed, in that case, let q1 be the position of x in the entire
term on the LHS, say T1, and q2 the position of s in the term
on the RHS, say T2. Then ppos(q2, T2) = , so ppos(q2, T2)
is a preﬁx of ppos(q1, T1). Also, epos(q1, T1) < epos(q2, T2).
Therefore, T1 and T2 are out of phase on x, so we would
have failed.
Therefore, we will assume that s (cid:54)= x when the Shaping
rule is applied. This means that the Shaping rule can be
applied only ﬁnitely many times before some Parsing rule
is triggered. This is because any application of the Shaping
rule gives rise to at least one of the t(cid:48)
is having at least n
encryption keys (n as in the formulation of the Shaping rule),
so the Parsing rule will eventually become applicable.
Consider then the application of the Parsing Rule, where
s is now as in the formulation of the Parsing Rule. By
deﬁnition of E, we require that the top symbol of s is not
e. Since the terms are in normal form, the top symbol of s
cannot be p. Therefore s must be a variable or a constant.
If s is a variable, then Variable Substitution is immediately
applied, reducing the number of unsolved variables. If s is
a constant c, then suppose that Shaping has added a new
variable x(cid:48). So the result of shaping will either be of the
form p(r1, r2) = c, in which case we will fail, or it will be of
the form x(cid:48) = c, in which case Variable Substitution will be
applied, and the number of unsolved variables will decrease.
(Note that Shaping will have to be applied en bloc with
Parsing, by assumption.)
The next two lemmas show that Eh-Unifn is sound and
complete. As usual, we write Γ ⇒ Γ(cid:48) if the problem Γ(cid:48) is
derived from the problem Γ by applying one of the infer-
ences.
Lemma 4. Let σ be any term substitution. If Γ1 ⇒ Γ2
and σ is a solution for Γ2, then σ is also a solution for Γ1.
Proof. We show the soundness of Homomorphic Pattern
rules, the soundness of all the other rules being straightfor-
ward. Speciﬁcally we show that the Parsing rule of Homo-
morphic Pattern is sound.
Now, according to the homomorphic encryption theory,
p(e(t1, k1), e(t2, k2)) = e(s, k) if and only if s = p(t1, t2),
and k1 = k, k2 = k. This can be generalized without dif-
ﬁculty to Pv(E(t1, k11, . . . , k1m), . . . , E(tn, kn1, . . . , knm)) =
E(s, k1, . . . , km) if and only if s = Pv(t1, . . . , tn), k11 = ··· =
kn1 = k1, . . . , k1m = ··· = knm = km, where v is any legal
bit string sequence.
Lemma 5. Let Γ1 be a set of uniﬁcation problems that
is not in solved form, and σ a term substitution. If σ is a
solution of Γ1, then there exists a Γ2 such that Γ1 ⇒ Γ2 and
σ can be extended to a solution of Γ2.
Proof. Consider any unsolved uniﬁcation problem c in
Γ1, of the form s = t. If s or t is a variable, Variable Substi-
tution applies. If neither of them is a variable and they have
the same function symbols on top, then Std Decomposition
applies.
So we assume they have diﬀerent function symbols on top;
then Homomorphic Pattern rules apply. Suppose then the
equation s = t is of the form:
= E(s(cid:48), k1, . . . , km).
Pv(E(t1, k11, . . . , k1m1 ), . . . , E(tl, kl1, . . . , klml ))
Case 1): Suppose there is an i, 1 ≤ i ≤ l, with mi < m.
Case 1.a) Case where ti is a variable:
Case 1.a.i): Suppose ti = s(cid:48). Then s and t are out of
(cid:54)= s(cid:48). Then Shaping applies.
Clearly, any solution to Γ2 can be extended to a solution
of Γ1.
phase on the variable ti. So, the Failure Rule (i) applies.
Case 1.a.ii): Suppose ti
Case 1.b) Case where ti is not a variable: Then Failure
Rule (ii) applies. The term ti cannot be a p-term, because
s is in normal form modulo Eh. So ti must be a constant.
Let q2 be the position of s(cid:48) in t. No instance of s can have
a term at position q2 by Lemma 2, thus the equation s = t
has no solution.
Case 2): For all i, mi ≥ m. In this case, Parsing applies,
and the solution to Γ2 is a solution of Γ1, because the equa-
tion Eh implies that E(Pv(x1, . . . , xn), z1, . . . , zm)
= Pv(E(x1, z1, . . . , zm),··· , E(xn, z1, . . . , zm)).
Lemma 6. Let Γ be a set of uniﬁcation problems, σ any
substitution solution for Γ modulo Eh. Then there is a solved
form σ(cid:48) for Γ, produced by Eh-Unifn, that generalizes σ, and
σ(cid:48) only contains variables in Γ.
Proof. By Lemma 5, the inference steps of Eh-Unifn pre-
serve solutions. Lemma 3 shows that Eh-Unifn terminates.
Only the Shaping rule introduces new variables. By the
argumentation of Lemma 3, the Shaping rule always trig-
gers the Parsing rule, which gets rid of the introduced vari-
ables.
We close this section with an example, which shows why
we need to keep the equations of our problems in Eh-normal
form:
Example: Consider the following Eh-uniﬁcation problem:
e(p(x, y), k) = e(e(w, k), k).
Its term to the right (with 2 keys) is in normal form; and the
term to the left, with one key, is not in normal form. Shaping
appears inapplicable, but Failure rule (ii) is. However, the
equation in Eh-normal form actually reads:
p(e(x, k), e(y, k)) = e(e(w, k), k),
to which neither of the Failure rules applies, but Shaping
does apply. After some Shaping inferences, followed by Vari-
able Substitution, the problem becomes: