The results are organized in three parts: (1) the basic ini-
tialization costs including the cloud storage and the data
contributors’ costs on encoding and submitting the vectors,
and (2) the related costs for the cloud and the data owner
running the AHE- and SHE-based Lanczos methods. Since
the Nystr¨om methods are mainly designed for sparse data,
they will be discussed later.
4.3.1 Setup Costs
The setup costs include the contributors’ cost and the cloud
storage cost. In our framework, we assume each distributed
1. sites.google.com/site/privategraphdemo/
11
data contributor submits a row (or a few rows) of the matrix
E(A). Examples may include a social network user who
submits their interactions with others; or a customer that
submits ratings/preferences on products. They will down-
load the public key from the data owner, encrypt their share
of rows with the selected encryption scheme, and transmit
to the cloud. Two costs involved here are the encryption cost
and the transmission cost that is represented by the amount
of encrypted data. As shown in Table 4, data contributor’s
TABLE 4: Contributor’s costs for dense submission
Scheme
Paillier
RLWE-P
Encrypt Ai (seconds)
GPlus
173.6
4.1
Twitter
129.6
3.1
FB
6.7
0.2
Upload E(Ai) (MB)
FB
1.0
3.4
Twitter
18.6
58.3
GPlus
24.9
77.9
encryption costs are the lowest for the RLWE-P method,
thanks to the packing technique. However, RLWE-P’s com-
munication cost is several times higher than Paillier’s.
Table 5 lists the basic cloud-side storage costs for the
datasets with different encryption methods. Clearly, the
dense form of matrix is really expensive. For data of this
scale, only cloud infrastructures can handle the storage.
TABLE 5: Cloud Storage Costs for Dense Submissions
Dataset
Paillier
RLWE-P
Facebook
3.7GB
12.9GB
Twitter
1.4TB
4.3TB
Gplus
2.5TB
7.8TB
4.3.2 Privacy Preserving Lanczos Algorithms
We compare the costs of SHE- and AHE-based Lanczos
algorithms to see which one has the cost advantage. For the
AHE-based algorithm, there is an additional setup cost for
data contributors to compute and submit E(Aib0), which is
the same as the cost of initial data submission as shown in
Table 4 and thus skipped in the report. In the following, we
show the accumulated costs of all rounds to have a clearer
comparison.
4
3
2
)
s
d
n
o
c
e
s
(
0
1
g
o
l
Paillier
RLWE-P
Paillier
RLWE-P
)
B
M
(
0
1
g
o
l
3
2
Facebook
Twitter
GPlus
Facebook
Twitter
GPlus
(a) Accumulated encryption
and decryption costs
(b) Accumulated communica-
tion costs.
Fig. 4: Data owner’s costs for privacy-preserving Lanczos
methods.
Data owner’s costs. Figure 4(a) shows the accumulated
encryption (only RLWE has) and decryption costs for all it-
erations of the Lanczos method. For the AHE-based method,
this also includes the setup cost for the masking matrix
(h = 80). Figure 4(b) shows the total communication costs.
The Paillier-based method takes much less communication
costs, but its computational time is signiﬁcantly higher.
Table 6 shows detailed data owner’s costs for the most
expensive Gplus dataset. Note that in the AHE-based al-
gorithm, the data owner has no encryption cost. It is clear
that the high decryption time is the major shortcoming of
1041-4347 (c) 2018 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.
This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TKDE.2018.2847662, IEEE
Transactions on Knowledge and Data Engineering
Lan-AHE, among which about 80% is used for setting up
the masking matrix. This can be partially addressed by
multi-core computers. Overall, the RLWE-P based method
spends about two times of the Paillier-based method, while
the computational time is much lower. Cloud-side com-
TABLE 6: Data owner’s accumulated costs on the Gplus
dataset. h: hours; GB: Gigabytes
Schemes
Enc.(h)
Dec.(h)
Upload.(GB)
Dwnld.(GB)
Paillier(Lan-AHE)
RLWE-P(Lan-SHE)
-
0.04
5.0
0.16
0.05
2.3
2.7
2.3
putation. The cloud-side computation can be easily paral-
lelized. The computation of E(Abi) can be decomposed to
dot-products between a matrix row and bi, which can be
directly mapped to a MapReduce program. With sufﬁcient
resources, the computation cost is proportional to the cost
of per dot-product. Figure 5 (a) shows the cost of per dot-
product for the datasets. Pseudo homomorphic multipli-
cation with Paillier has much lower costs than RLWE-P’s.
Figure 5 (b) shows the nice scalability of the MapReduce
implementation for the Paillier-based matrix-vector multi-
plication, where most work is done in the Map phase and
thus the overall cost is proportional to the number of Map
rounds, which implies excellent scalability.
Paillier
RLWE-P
2
1
0
)
s
d
n
o
c
e
s
(
0
1
g
o
l
Facebook
Twitter
GPlus
400
300
200
100
)
s
d
n
o
c
e
S
(
i
e
m
T
n
o
i
t
a
t
u
p
m
o
C
0
0
Computation Time
Map Rounds
10
8
6
4
2
s
d
n
u
o
R
p
a
M
10
20
30
40
Matrix Dimension (×103)
0
50
(a) Cost of vector dot-product.
(b) MapReduce scalability.
Fig. 5: Cloud-side processing.
4.4 Sparse Submission and Nystr ¨om Algorithms
In this section, we focus on the cost savings of the differen-
tially private sparse matrices and the Nystr¨om algorithms
working on the sparse matrices. In the sparse format, the
element will be encoded in the sparse format (i, j, E(.)),
where E(.) is the encrypted non-zero or zero items. The total
number of submitted elements depends on the personalized
privacy parameter ǫ, as described in Section 3.4. We select
the number of bins so that the number of nodes in each
bin is in [50, 100] to provide sufﬁcient indistinguishability
within the bin. With ǫ = 1.0, we have the results in Table
7. The numbers in the column “|E| pert.” are the average
of 10 runs. Apparently, the size of increased edges are quite
manageable.
We have shown that for the same number of elements,
the pairing scheme has about the same ciphertext size as
the Paillier’s and the RLWE has about four times of the
Paillier’s. In the following we show only the Paillier cost
difference between dense and sparse representations if the
vector/matrix is the same for different encryption methods.
Data Contributors’ Costs. Table 8 shows the average
contributors’ costs for sparse submission with different en-
cryption methods. The actual costs for each data contributor
TABLE 7: The perturbation parameters and results. “orig.
|E|”: the number of original edges. “pert. |E|”: the number
of edges after perturbation. “%inc.”: percentage of increase.
12
Dataset
Facebook
Twitter
GPlus
nbins
100
1000
2000
nodes/bin
40
76
52
orig. |E|
84243
1242390
12113501
pert. |E|
99965
1527286
13228599
% inc.
18.66
22.93
9.21
should vary according to their original node degree. The
ciphertext packing of RLWE cannot be used for sparse
encoding anymore. Comparing it with the dense submission
costs in Table 4, we can see that sparse encoding for the
Paillier-based method can dramatically reduce the contribu-
tor’s costs, while the RLWE’s costs are about the same with
the RLWE-P’s costs for dense submission.
TABLE 8: Contributor’s Average Cost for sparse submission.
Method
Encrypt Ai (seconds)
Upload E(Ai) (MB)
Paillier
RLWE
FB
0.04
0.64
Twitter
0.03
0.51
GPlus
0.22
3.28
FB
0.006
12.1
Twitter
0.005
9.6
GPlus
0.032
61.9
Cloud-side Costs The cloud side storage cost is the sum
of all data contributors’ submitted data. Table 9 summarizes
these costs. The costs are about 100-1000 times less than
the dense-matrix ones for Paillier, while RLWE without
ciphertext packing has slightly less costs than the dense
matrix with packing.
TABLE 9: The cloud storage costs with sparse submission.
(MB: megabytes, GB: gigabytes, TB: terabytes)
Format
Paillier
RLWE
Facebook
24.4MB
47.8GB
Twitter
372.9MB
729.8GB
GPlus