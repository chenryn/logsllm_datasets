### Table 5: CNN Parameter Exploration
Final selection highlighted in **bold**.

| Max Pooling | Training Accuracy (%) | Validation Accuracy (%) | Training Loss | Dropout Rate | Kernel Size | Dense Layer Size | Dropout |
|-------------|-----------------------|-------------------------|---------------|--------------|-------------|------------------|---------|
| **2**       | **0.7342**            | **82.68**               | **0.2568**    | **0.1**      | **3**       | **50**           | **0.1** |
| 2           | 0.7092                | 83.04                   | 0.2085        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7127                | 82.75                   | 0.2554        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7307                | 82.78                   | 0.2666        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.8038                | 80.56                   | 0.2790        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6910                | 82.38                   | 0.5443        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7057                | 82.29                   | 0.3821        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6436                | 84.40                   | 0.4513        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6510                | 84.18                   | 0.2581        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7638                | 80.93                   | 0.3725        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7355                | 81.46                   | 0.6743        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6440                | 84.55                   | 0.4495        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6609                | 84.09                   | 0.2564        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6984                | 81.25                   | 0.3345        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6436                | 84.40                   | 0.3259        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7467                | 82.45                   | 0.2581        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7160                | 81.54                   | 0.4823        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6436                | 84.80                   | 0.5642        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6783                | 83.34                   | 0.2581        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6928                | 82.86                   | 0.2756        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.7293                | 81.43                   | 0.2894        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6583                | 83.45                   | 0.3184        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6314                | 85.21                   | 0.4068        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6794                | 84.82                   | 0.3686        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6915                | 83.87                   | 0.3079        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6836                | 83.07                   | 0.3283        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6456                | 83.57                   | 0.3387        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6218                | 85.76                   | 0.3208        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6424                | 83.38                   | 0.3104        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6592                | 82.51                   | 0.3487        | 0.1          | 3           | 50               | 0.1     |
| 2           | 0.6834                | 82.15                   | 0.3562        | 0.1          | 3           | 50               | 0.1     |

### Notes:
- The final selected parameters are highlighted in **bold**.
- The table includes the following parameters: max pooling, training accuracy, validation accuracy, training loss, dropout rate, kernel size, dense layer size, and dropout.
- The best performance is achieved with a max pooling of 2, training accuracy of 0.7342, validation accuracy of 82.68%, and a training loss of 0.2568.

---

**Session 3B: Learning and Authentication**
- **Conference**: AsiaCCS '19
- **Dates**: July 9â€“12, 2019
- **Location**: Auckland, New Zealand

For further details, refer to the conference proceedings or related documentation.