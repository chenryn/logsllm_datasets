miss rate in performance mode (because different instruc-
tions may need to be fetched from the I-cache in the two dif-
ferent modes). The average IPC-overhead decreases from
16.1% for a 1K-entry backlog buffer, to 13.9% for a 4K-
entry backlog buffer. A backlog buffer of 2K entries pro-
vides a good trade-off between IPC overhead (14.5%) and
hardware overhead. Therefore, we chose 2K entries as the
default size of the backlog buffer throughout our experi-
ments.
5.3. Storage Cost of the MBI Mechanism
The additional hardware required for the MBI mecha-
nism includes the backlog buffer, the extra register ﬁle (IS-
PEC ARF) and combinational logic such as mux and com-
parators. In this section, we estimate the storage cost of the
MBI mechanism. A straightforward, unoptimized imple-
mentation of the backlog buffer is to store the full instruc-
tion results in the backlog buffer entry. We assume that each
result value stored in the backlog buffer takes eight bytes.
Table 2 calculates the storage cost of the MBI mechanism
in terms of Register Bit Equivalents (RBE’s).
Table 2. Storage Cost of the MBI Mechanism.
ARF contains: 32 INT Regs
32 FP Regs
2 CNTL Regs
1 PC
Size of ARF
Backlog buffer contains
Size of each backlog buffer entry
Size of backlog buffer
Total storage cost of MBI
32*8B=256B
32*8B=256B
2*8B= 16B
1*8B= 8B
536B
2000 entries
8 B
2000*8B= 16000B
16536B
The storage cost of 16KB is fairly small, especially con-
sidering that the baseline contains a 1MB cache. This cost
can further be reduced by using compression schemes and
taking advantage of result values that require fewer than
8 bytes. It should be noted that the above calculations do
not quantify the cost of control logic for the backlog buffer
(such as ECC bits) and the cost of glue logic (such as selec-
tion mux and comparator). The hardware cost of the control
logic is fairly small in comparison to the storage cost tabu-
lated in Table 2. However, quantifying the exact cost of the
control logic is beyond the scope of this paper.
5.4. Reasons for Entering Introspection Mode
The processor enters introspection mode either because
of a long-latency cache miss (normal-introspection) or be-
cause it is forced to enter introspection mode (forced-
introspection). An episode of normal-introspection does
not cause a signiﬁcant reduction in performance because it
uses idle processing bandwidth for redundant execution. On
the other hand, an episode of forced-introspection reduces
the performance of the processor because the processor is
forced to perform redundant execution at the expense of
normal execution. In this section, we present results on the
distribution of introspection episodes. Figure 5.4(A) shows
the breakdown of the introspection episodes into normal-
introspection and forced-introspection for a subset of the
studied benchmarks.
For mcf, art, twolf, and vpr, more than 96% of the in-
trospection episodes occur because of normal-introspection.
These benchmarks are memory intensive and frequently
experience long-latency cache misses. For apsi, approxi-
mately half of the introspection episodes occur because of
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:11 UTC from IEEE Xplore.  Restrictions apply. 
forced-introspection
normal-introspection
forced-introspection
normal-introspection
s
e
d
o
s
i
p
e
n
o
i
t
c
e
p
s
o
r
t
n
i
l
l
a
f
o
%
100
90
80
70
60
50
40
30
20
10
0
mcf
art
twolf
apsi
vpr
galgel
gcc
 (A)
bzip2
vortex
perlbm k
gzip
eon
)
%
(
.
t
s
n
i
d
e
r
i
t
e
r
l
l
a
r
o
f
e
g
a
r
e
v
o
C
100
90
80
70
60
50
40
30
20
10
0
mcf
art
twolf
apsi
vpr
galgel
gcc
(B)
bzip2
vortex
perlbm k
gzip
eon
(A) Breakdown of
Figure 6.
introspection episodes into
normal-introspection and forced-introspection.
(B) Redun-
dant execution coverage of normal-introspection and forced-
introspection.
forced-introspection. Although apsi generates a significant
number of long-latency cache misses, these misses tend to
be clustered. For perlbmk, gzip, and eon almost all the
introspection episodes occur because the backlog buffer is
full. These benchmarks do not have a substantial number
of long-latency cache misses and therefore require forced-
introspection.
When the processor is forced to enter introspection mode
because the backlog buffer is full, the processor always per-
forms redundant execution until the backlog buffer becomes
empty.
In contrast, during normal-introspection, the pro-
cessor performs redundant execution either until the long-
latency cache miss gets serviced or until the backlog buffer
becomes empty, whichever is earlier. Thus, a typical forced-
introspection episode results in the execution of many more
instructions than a typical normal-introspection episode.
Figure 5.4(B) shows the redundant-execution coverage of
the instruction stream provided by normal-introspection and
forced-introspection.
For mcf, 12% of the instructions go through their redun-
dant execution due to forced-introspection. However, this
costs only 1.4% in terms of IPC because the benchmark
is memory bound. For twolf and vpr, less than 10% of
the instructions go through their redundant execution due
to forced-introspection. This translates to an IPC reduc-
tion of only 3% for these benchmarks. In contrast, for apsi,
galgel, and gcc almost 80% of the instructions go through
their redundant execution due to forced-introspection. Con-
sequently, these benchmarks incur an IPC overhead of more
than 20% (refer to Figure 4). Although these benchmarks
have a lot of CPI-L2 (theoretically enough to re-execute the
program without any performance loss), this idle process-
ing bandwidth comes in bursts and the MBI technique is
not able to exploit it.
5.5. Error Detection Latency
A redundant execution mechanism can have a delay be-
tween the first execution and the redundant execution of an
instruction. If there is an error in the first execution of an
instruction, then this error will not be detected until the in-
struction completes its redundant execution. The delay be-
tween the first execution and the redundant execution de-
termines the error detection latency of the fault tolerance
mechanism. MBI has a variable error detection latency.
Table 3 shows, for each benchmark, the average and worst-
case error detection latency of MBI.
Table 3. Error Detection Latency (in cycles).
HIGH-MEM Benchmarks
LOW-MEM Benchmarks
Name
mcf
art
lucas
ammp
twolf
wupwise
apsi
vpr
facerec
swim
galgel
gcc
bzip2
Avg
465
304
307
500
481
457
1143
487
475
807
790
902
680
Overall: Average = 692, Worst-Case = 36183
Worst-Case
6976
3552
7066
7829
10785
7711
36183
5043
9279
16546
8372
20075
4793
Name
vortex
mgrid
parser
applu
equake
mesa
gap
sixtrack
crafty
perlbmk
gzip
eon
fma3d
Avg
467
514
957
680
795
646
744
770
1190
832
1106
877
615
Worst-Case
18157
17401
8593
25941
5366
11449
12187
20978
19480
14330
7339
17954
10936
For all benchmarks except apsi, crafty, and gzip, the av-
erage error detection latency is less than 1000 cycles. Over
the entire SPEC CPU2000 suite, the average error detection
latency is 692 cycles, and the worst-case error detection la-
tency is 36183 cycles. The impact of the error detection
latency on the system operation is dependent on the fault
handling policy. For example, if the fault handling policy is
to terminate the faulting application, then the average error
detection latency of 692 cycles is clearly acceptable. How-
ever, if the fault-handling policy is to correct the error, then
the time it takes to correct the error may increase with the
error detection latency. The next section discusses error
handling policies.
6. Handling Errors
A fault in the processor can be detected only during in-
trospection mode. When a fault is detected, the faulting
instruction is re-executed one more time to ensure that the
fault was indeed during the ﬁrst execution of that instruc-
tion. If the result produced during this re-execution matches
the result in the backlog buffer, then the fault is ignored.
However, if the result of the re-execution does not match
the result in the backlog buffer, then the fault is considered
an error and is dealt with in accordance with the error han-
dling policy. We discuss some of the error handling policies
that can be combined with MBI.
6.1. Fail-Safe Operation
The simplest error handling mechanism is to terminate
the error-causing application and generate a machine check
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:10:11 UTC from IEEE Xplore.  Restrictions apply. 
exception. This mechanism avoids any correction but al-
lows the processor to fail in a safe manner.
6.2. Restore a Checkpointed State
Another error handling mechanism, also known as Back-
ward Error Recovery (BER), is based on the concept of
checkpointing. Both memory state and processor state are
checkpointed at pre-determined intervals. When an error is
detected, the system is restored to the most-recent, error-
free checkpointed state. The BER scheme provides fast re-