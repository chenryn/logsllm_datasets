(2) 重启Nginx服务：
$ sudo service nginx restart
现在通过浏览器访问本地的代理服务http://127.0.0.1:5000，会弹出让我们输入用户名和密码
的对话框。当然，现在还没有添加任何用户，所以无法访问。添加用户要用到htpasswd工具，通
过以下命令来安装htpasswd工具：
sudo apt-get install apache2-utils -y
(3) 现在添加一个用户试试：
$ sudo htpasswd -c /etc/nginx/docker-registry-htpasswd test
New password:
Re-type new password:
Adding password for user test
上面的命令添加了test用户，接下来提示我们输入密码并确认（输入是看不到的，不要担心）。
最后，会提示我们用户添加成功了。
10.2 用户认证 117
(4) 使用刚才的用户名和密码测试一下： 1
$ curl -u test:pass 127.0.0.1:5000/v1/search
{"num_results": 1, "query": "", "results": [{"description": "", 2
"name": "library/ubuntu"}]}
可以看到，成功通过了认证，并且可以查询到前面添加的镜像。
3
4
5
6
7
9
8
10
10
11
13
14
15
16
17
18
118 第11章 使用Docker部署Hadoop集群
第 11 章
使用Docker部署Hadoop集群
Hadoop是一款开源的分布式计算框架，它的出现极大地促进了云计算平台的发展。在Hadoop
出现之前，要搭建一个分布式网络并不是件容易的事，而且进行分布式编程也相当费劲。Hadoop
通过它的MapReduce计算模型和HDFS存储模型，极大地简化了计算，隔离了存储细节，使得编
写分布式应用变得格外简单。正因为此，Hadoop也成了云计算领域的宠儿，时至今日扔热度不减。
Hadoop和Docker作为云计算领域的两大热门技术，无视它们之间的关系等于掩耳盗铃，所以在本
章中，我们将说明它们两个是如何走到一起的。本章的主要内容有：
 Hadoop简介；
 构建hadoop镜像。通过Dockerfile来构建hadoop镜像；
 构建Hadoop集群。通过ambari镜像来部署和管理Hadoop集群。
11.1 Hadoop 简介
Hadoop是由Apache软件基金会所开发的分布式系统基础架构，它可以让开发者不了解分布
式环境的底层细节，就能够快速开发出高效、健壮的分布式程序。该项目最重要的两个核心概念
是MapReduce和HDFS，前者负责处理海量数据，后者则为海量数据提供可靠的存储。MapReduce
分为两个动作——Map和Reduce，分别实现任务的分解和结果的汇总。HDFS（Hadoop Distributed
File System）分布式文件系统具有高度容错的优点，它本意就是用来将数据部署在大规模的低廉
硬件上，所以极大地降低了分布式环境的搭建门槛和成本，也是硬件量化和流式分配的基础。
Hadoop主要具有以下优点。
 可扩展性：不论是计算还是存储，Hadoop都具备良好的可扩展性，这也是Hadoop的设计
根本。
 经济：Hadoop的运行环境是普通的PC集群上，硬件要求低。
 可靠：HDFS冗余备份、数据恢复机制，以及MapReduce的任务监控，都保证了分布式处
理的可靠性。
 高效：Hadoop尽量减少数据的移动，采用计算跟随数据的设计，减少了数据传输带来的
时延，从而在处理海量数据上具有很高的效率。
11.2 构建Hadoop镜像 119
Hadoop主要应用在海量数据分析、分布式存储、Web搜索引擎等应用领域。关于Hadoop更多
1
的知识，我们在此不再展开。接下来，我们主要说明如何构建Hadoop镜像以及如何通过Docker
来部署Hadoop集群。
2
11.2 构建 Hadoop 镜像
3
获得Hadoop镜像有两种方式，一种是直接从Docker Hub中拉取现有的Hadoop镜像，另一种
4
是通过Dockerfile来构建。
直接拉取现有的Hadoop镜像的代码如下： 5
$ sudo docker pull sequenceiq/hadoop-docker:2.6.0
6
下面我们重点介绍如何通过Dockerfile来构建Hadoop镜像，具体步骤如下所示。
(1) 下载文件。通过wget命令或者网络浏览器获取Dockerfile以及相关配置文件：
7
wget https://github.com/minimicall/hadoop-docker/archive/master.zip
9
(2) 解压文件：
$ unzip -o -d ./hadoop master.zip
8
进入解压后的目录，可以看到如下文件列表：
$ ls 10
bootstrap.sh hadoop mapred-site.xml ssh_config
core-site.xml.template hdfs-site.xml master.zip yarn-site.xml
Dockerfile LICENSE README.md 11
可以发现，除了Dockerfile外，还有一些构建镜像中需要用到的配置文件。
11
(3) 查看Dockerfile文件的内容。
下面我们简要说明Dockerfile的内容，其中以注释的方式加以说明： 13
# Creates pseudo distributed hadoop 2.6.0
# 14
# docker build -t sequenceiq/hadoop .
#基础镜像
FROM sequenceiq/pam:centos-6.5 15
MAINTAINER SequenceIQ
#切换到root用户
USER root 16
#安装必要的开发工具
RUN yum install -y curl which tar sudo openssh-server openssh-clients rsync
# update libselinux. see https://github.com/sequenceiq/hadoop-docker/issues/14 17
RUN yum update -y libselinux
#配置无需密码的SSH连接
RUN ssh-keygen -q -N "" -t dsa -f /etc/ssh/ssh_host_dsa_key 18
RUN ssh-keygen -q -N "" -t rsa -f /etc/ssh/ssh_host_rsa_key
120 第11章 使用Docker部署Hadoop集群
RUN ssh-keygen -q -N "" -t rsa -f /root/.ssh/id_rsa
RUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys
#Java JDK的获取
RUN curl -LO 'http://download.oracle.com/otn-pub/java/jdk/7u51-b13/jdk-7u51-linux-x64.rpm' -H 'Cookie:
oraclelicense=accept-securebackup-cookie'
#Java JDK的安装
RUN rpm -i jdk-7u51-linux-x64.rpm
#删除rpm包
RUN rm jdk-7u51-linux-x64.rpm
#配置环境变量JAVA_HOME和PATH
ENV JAVA_HOME /usr/java/default
ENV PATH $PATH:$JAVA_HOME/bin
#Hadoop的下载和解压
RUN curl -s http://www.eu.apache.org/dist/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz | tar -xz -C
/usr/local/
#制作链接文件
RUN cd /usr/local && ln -s ./hadoop-2.6.0 hadoop
#设置环境变量
ENV HADOOP_PREFIX /usr/local/hadoop
ENV HADOOP_COMMON_HOME /usr/local/hadoop
ENV HADOOP_HDFS_HOME /usr/local/hadoop
ENV HADOOP_MAPRED_HOME /usr/local/hadoop
ENV HADOOP_YARN_HOME /usr/local/hadoop
ENV HADOOP_CONF_DIR /usr/local/hadoop/etc/hadoop
ENV YARN_CONF_DIR $HADOOP_PREFIX/etc/hadoop
#将JAVA及Hadoop相关环境变量配置进hadoop-en.sh配置文件中
RUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/java/default\nexport
HADOOP_PREFIX=/usr/local/hadoop\nexport HADOOP_HOME=/usr/local/hadoop\n:'
$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
RUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:'
$HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
#RUN . $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
RUN mkdir $HADOOP_PREFIX/input
RUN cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input
#伪分布式环境配置，需要将本地同一目录下的配置文件复制进容器内部
# pseudo distributed
ADD core-site.xml.template $HADOOP_PREFIX/etc/hadoop/core-site.xml.template
RUN sed s/HOSTNAME/localhost/ /usr/local/hadoop/etc/hadoop/core-site.xml.template >
/usr/local/hadoop/etc/hadoop/core-site.xml
#添加hdfs、mapred、yarn站点配置文件
ADD hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml
ADD mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml
ADD yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml
#格式化namenode
RUN $HADOOP_PREFIX/bin/hdfs namenode -format
# fixing the libhadoop.so like a boss
RUN rm /usr/local/hadoop/lib/native/*
RUN curl -Ls http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-2.6.0.tar | tar -x -C
/usr/local/hadoop/lib/native/
#SSH配置
ADD ssh_config /root/.ssh/config
RUN chmod 600 /root/.ssh/config
RUN chown root:root /root/.ssh/config
# # installing supervisord
11.2 构建Hadoop镜像 121
# RUN yum install -y python-setuptools
1
# RUN easy_install pip
# RUN curl https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py -o - | python
# RUN pip install supervisor
2
#
# ADD supervisord.conf /etc/supervisord.conf
ADD bootstrap.sh /etc/bootstrap.sh
3
RUN chown root:root /etc/bootstrap.sh
RUN chmod 700 /etc/bootstrap.sh
ENV BOOTSTRAP /etc/bootstrap.sh
4
# workingaround docker.io build error
RUN ls -la /usr/local/hadoop/etc/hadoop/*-env.sh
RUN chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh
5
RUN ls -la /usr/local/hadoop/etc/hadoop/*-env.sh
# fix the 254 error code
RUN sed -i "/^[^#]*UsePAM/ s/.*/#&/" /etc/ssh/sshd_config
6
RUN echo "UsePAM no" >> /etc/ssh/sshd_config
RUN echo "Port 2122" >> /etc/ssh/sshd_config
#启动相关服务
7
RUN service sshd start && $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh && $HADOOP_PREFIX/sbin/start-dfs.sh
&& $HADOOP_PREFIX/bin/hdfs dfs -mkdir -p /user/root
RUN service sshd start && $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh && $HADOOP_PREFIX/sbin/start-dfs.sh
9
&& $HADOOP_PREFIX/bin/hdfs dfs -put $HADOOP_PREFIX/etc/hadoop/ input
#入口命令
CMD ["/etc/bootstrap.sh", "-d"]
#对外暴露的网络端口 8
EXPOSE 50020 50090 50070 50010 50075 8031 8032 8033 8040 8042 49707 22 8088 8030
(4) 构建Hadoop镜像。 10
在Dockerfile所在目录中执行docker build命令来构建Hadoop镜像：
11
$ docker build -t sequenceiq/hadoop-docker:2.6.0 .
...
Step 51 : EXPOSE 50020 50090 50070 50010 50075 8031 8032 8033 8040 8042 49707 22 8088 8030 11
---> Running in 83a985d1b344
---> 671d9ac19702
Removing intermediate container 83a985d1b344
13
Successfully built 671d9ac19702
使用Dockerfile构建Hadoop镜像时，每一条命令都将新建一层，当构建完新的一层时，旧的
14
中间镜像就会被删除，最终看到Successfully built …就表明构建成功。
构建完毕之后，通过docker images命令来查看本地镜像：
15
micall@micall-ThinkPad:~/docker/hadoop-docker-master$ docker images
REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE
16
minimicall/hadoop-docker 2.6.0 671d9ac19702 7 hours ago 1.636 GB
sequenceiq/hadoop-docker 2.6.0 d828dda7ad02 4 weeks ago 1.624 GB
可以看到，我们直接拉取的镜像sequenceiq/hadoop-docker:2.6.0和通过Dockerfile构建的镜 17
像minimicall/hadoop-docker:2.6.0。
18
有了镜像之后，我们就可以通过docker run命令来启动Hadoop容器了：
122 第11章 使用Docker部署Hadoop集群
docker run -it sequenceiq/hadoop-docker:2.6.0 /etc/bootstrap.sh -bash
/
Starting sshd: [ OK ]
Starting namenodes on [91f69f9e5ab3]
Starting secondary namenodes [0.0.0.0]
starting yarn daemons
...
bash-4.1#
可以看到，Hadoop容器先后启动了sshd、namenodes、secondary namenodes和yarn等服务组件。
最后，进入到了Hadoop容器的命令窗口。下面运行Hadoop自带的一个示例来测试Hadoop程序：
bash-4.1# cd /usr/local/hadoop
bash-4.1# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output
'dfs[a-z.]+'
15/02/12 21:13:18 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
15/02/12 21:13:20 WARN mapreduce.JobSubmitter: No job jar file set. User classes may not be found.
See Job or Job#setJar(String).
15/02/12 21:13:20 INFO input.FileInputFormat: Total input paths to process : 31
15/02/12 21:13:21 INFO mapreduce.JobSubmitter: number of splits:31
15/02/12 21:13:31 INFO mapreduce.Job: map 0% reduce 0%
...
15/02/12 21:14:02 INFO mapreduce.Job: map 19% reduce 0%
...
15/02/12 21:15:16 INFO mapreduce.Job: map 100% reduce 100%
...
程序成功执行了，该程序主要实现一个以dfs为前缀的词频统计工作，其执行结果为：
# bin/hdfs dfs -cat output/*
6 dfs.audit.logger