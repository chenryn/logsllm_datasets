### 2. 重启Nginx服务

执行以下命令以重启Nginx服务：
```bash
$ sudo service nginx restart
```

现在，通过浏览器访问本地代理服务 `http://127.0.0.1:5000`，会弹出一个要求输入用户名和密码的对话框。由于尚未添加任何用户，因此当前无法访问该服务。

#### 安装htpasswd工具

使用以下命令安装htpasswd工具：
```bash
sudo apt-get install apache2-utils -y
```

### 3. 添加用户

接下来，我们尝试添加一个用户：

```bash
$ sudo htpasswd -c /etc/nginx/docker-registry-htpasswd test
New password:
Re-type new password:
Adding password for user test
```

上述命令将添加一个名为 `test` 的用户，并提示您输入并确认密码（输入时不会显示字符）。最后，系统会提示用户已成功添加。

### 4. 测试用户认证

使用刚才创建的用户名和密码进行测试：

```bash
$ curl -u test:pass http://127.0.0.1:5000/v1/search
{
  "num_results": 1,
  "query": "",
  "results": [
    {
      "description": "",
      "name": "library/ubuntu"
    }
  ]
}
```

可以看到，认证成功并通过查询返回了前面添加的镜像信息。

---

## 第11章 使用Docker部署Hadoop集群

### 11.1 Hadoop简介

Hadoop是由Apache软件基金会开发的一个分布式系统基础架构，它允许开发者在不了解底层细节的情况下快速开发高效、健壮的分布式程序。Hadoop的两个核心组件是MapReduce和HDFS，前者用于处理大规模数据，后者则为这些数据提供可靠的存储。

- **可扩展性**：无论是计算还是存储，Hadoop都具有良好的扩展性。
- **经济性**：Hadoop运行在普通PC集群上，硬件要求较低。
- **可靠性**：HDFS的冗余备份和数据恢复机制以及MapReduce的任务监控确保了系统的可靠性。
- **高效性**：Hadoop通过减少数据移动，采用“计算跟随数据”的设计，提高了处理海量数据的效率。

Hadoop广泛应用于数据分析、分布式存储和Web搜索引擎等领域。

### 11.2 构建Hadoop镜像

获取Hadoop镜像有两种方法：从Docker Hub直接拉取现有镜像或通过Dockerfile构建自定义镜像。

#### 直接拉取现有镜像

```bash
$ sudo docker pull sequenceiq/hadoop-docker:2.6.0
```

#### 通过Dockerfile构建Hadoop镜像

以下是通过Dockerfile构建Hadoop镜像的步骤：

1. **下载文件**
   ```bash
   wget https://github.com/minimicall/hadoop-docker/archive/master.zip
   ```

2. **解压文件**
   ```bash
   $ unzip -o -d ./hadoop master.zip
   ```

3. **查看文件列表**
   ```bash
   $ ls
   bootstrap.sh  hadoop  mapred-site.xml  ssh_config
   core-site.xml.template  hdfs-site.xml  master.zip  yarn-site.xml
   Dockerfile  LICENSE  README.md
   ```

4. **查看Dockerfile内容**

   下面是Dockerfile的主要内容及其注释：

   ```dockerfile
   # 创建伪分布式Hadoop 2.6.0
   FROM sequenceiq/pam:centos-6.5
   MAINTAINER SequenceIQ
   USER root

   # 安装必要的开发工具
   RUN yum install -y curl which tar sudo openssh-server openssh-clients rsync
   RUN yum update -y libselinux

   # 配置无需密码的SSH连接
   RUN ssh-keygen -q -N "" -t dsa -f /etc/ssh/ssh_host_dsa_key
   RUN ssh-keygen -q -N "" -t rsa -f /etc/ssh/ssh_host_rsa_key
   RUN ssh-keygen -q -N "" -t rsa -f /root/.ssh/id_rsa
   RUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys

   # 获取并安装Java JDK
   RUN curl -LO 'http://download.oracle.com/otn-pub/java/jdk/7u51-b13/jdk-7u51-linux-x64.rpm' -H 'Cookie: oraclelicense=accept-securebackup-cookie'
   RUN rpm -i jdk-7u51-linux-x64.rpm
   RUN rm jdk-7u51-linux-x64.rpm
   ENV JAVA_HOME /usr/java/default
   ENV PATH $PATH:$JAVA_HOME/bin

   # 下载并解压Hadoop
   RUN curl -s http://www.eu.apache.org/dist/hadoop/common/hadoop-2.6.0/hadoop-2.6.0.tar.gz | tar -xz -C /usr/local/
   RUN cd /usr/local && ln -s ./hadoop-2.6.0 hadoop

   # 设置环境变量
   ENV HADOOP_PREFIX /usr/local/hadoop
   ENV HADOOP_COMMON_HOME /usr/local/hadoop
   ENV HADOOP_HDFS_HOME /usr/local/hadoop
   ENV HADOOP_MAPRED_HOME /usr/local/hadoop
   ENV HADOOP_YARN_HOME /usr/local/hadoop
   ENV HADOOP_CONF_DIR /usr/local/hadoop/etc/hadoop
   ENV YARN_CONF_DIR $HADOOP_PREFIX/etc/hadoop

   # 配置Hadoop环境变量
   RUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/java/default\nexport HADOOP_PREFIX=/usr/local/hadoop\nexport HADOOP_HOME=/usr/local/hadoop\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh
   RUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh

   # 伪分布式配置
   ADD core-site.xml.template $HADOOP_PREFIX/etc/hadoop/core-site.xml.template
   RUN sed s/HOSTNAME/localhost/ /usr/local/hadoop/etc/hadoop/core-site.xml.template > /usr/local/hadoop/etc/hadoop/core-site.xml
   ADD hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml
   ADD mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml
   ADD yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml

   # 格式化namenode
   RUN $HADOOP_PREFIX/bin/hdfs namenode -format

   # SSH配置
   ADD ssh_config /root/.ssh/config
   RUN chmod 600 /root/.ssh/config
   RUN chown root:root /root/.ssh/config

   # 启动相关服务
   RUN service sshd start && $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh && $HADOOP_PREFIX/sbin/start-dfs.sh && $HADOOP_PREFIX/bin/hdfs dfs -mkdir -p /user/root
   RUN service sshd start && $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh && $HADOOP_PREFIX/sbin/start-dfs.sh && $HADOOP_PREFIX/bin/hdfs dfs -put $HADOOP_PREFIX/etc/hadoop/ input

   # 入口命令
   CMD ["/etc/bootstrap.sh", "-d"]

   # 对外暴露的网络端口
   EXPOSE 50020 50090 50070 50010 50075 8031 8032 8033 8040 8042 49707 22 8088 8030
   ```

5. **构建Hadoop镜像**

   在Dockerfile所在目录中执行以下命令来构建Hadoop镜像：
   ```bash
   $ docker build -t sequenceiq/hadoop-docker:2.6.0 .
   ```

   构建完成后，使用以下命令查看本地镜像：
   ```bash
   $ docker images
   REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
   minimicall/hadoop-docker 2.6.0               671d9ac19702        7 hours ago         1.636 GB
   sequenceiq/hadoop-docker 2.6.0               d828dda7ad02        4 weeks ago         1.624 GB
   ```

6. **启动Hadoop容器**

   使用以下命令启动Hadoop容器：
   ```bash
   $ docker run -it sequenceiq/hadoop-docker:2.6.0 /etc/bootstrap.sh -bash
   ```

   启动后，Hadoop容器将依次启动sshd、namenodes、secondary namenodes和yarn等服务组件，并进入Hadoop容器的命令行界面。

7. **测试Hadoop程序**

   运行Hadoop自带的一个示例程序来测试：
   ```bash
   bash-4.1# cd /usr/local/hadoop
   bash-4.1# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output 'dfs[a-z.]+'
   ```

   程序成功执行后，将输出以 `dfs` 为前缀的词频统计结果：
   ```bash
   # bin/hdfs dfs -cat output/*
   6 dfs.audit.logger
   ```

这样就完成了Hadoop镜像的构建和基本测试。