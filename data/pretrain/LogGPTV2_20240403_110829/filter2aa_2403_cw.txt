        add      ebx, [edi+ecx*4] 
        mov      [eax+ecx*4], ebx 
        inc      ecx 
        cmp      ecx, edx 
        jb       short loc_14D 
loc_15B: ; CODE XREF: f(int,int *,int *,int *)+A 
           ; f(int,int *,int *,int *)+129 ... 
        xor      eax, eax 
        pop      ecx 
        pop      ebx 
异步社区会员 dearfuture(15918834820) 专享 尊重版权
第 25 章 SIMD 
377 
        pop      esi 
        pop      edi 
        retn 
loc_162: ; CODE XREF: f(int,int *,int *,int *)+8C 
           ; f(int,int *,int *,int *)+9F 
        xor      ecx, ecx 
        jmp      short loc_127 
?f@@YAHHPAH00@Z endp 
其中，与 SSE2 有关的指令有： 
 MOVDQU（Move Unaligned Double Quadword）是从内存加载16 字节数据，并复制到XMM 寄存器的指令。 
 PADDD（Add Packed Integers）是对 4 对 32 位数进行加法运算，并把运算结果存储到第一个操作符的
指令。此外，该指令不会设置任何标志位，在溢出时只保留运算结果的低 32 位，也不会报错。如果
PADDD的某个操作数是内存中的某个值，那么这个值的地址必须与 16 字节边界对齐，否则将报错。
①
GCC 
 MOVDQA（Move Aligned Double Quadword）的功能 MOVDQU 相同，只是要求存储操作数的内
存地址必须向 16 字节边界对齐，否则报错。除了这点区别之外，两个指令完全相同。此外，
MOVDQA 的运行速度要比 MOVDQU 快。 
所以上述 SSE2 指令的运行条件有 2 个：需要进行加法处理的操作数至少有 4 对；指针 ar3 的地址已经
向 16 字节边界对齐。 
而且，如果 ar2 的地址也向 16 字节边界对齐，则会执行下述指令： 
movdqu  xmm0, xmmword ptr [ebx+edi*4] ; ar1+i*4 
paddd   xmm0, xmmword ptr [esi+edi*4] ; ar2+i*4 
movdqa  xmmword ptr [eax+edi*4], xmm0 ; ar3+i*4 
另外，MOVDQU 指令会把 ar2 的值加载到 XMM0 寄存器。虽然这条指令不要求指针地址对齐，但是
性能略微慢些： 
movdqu  xmm1, xmmword ptr [ebx+edi*4] ; ar1+i*4 
movdqu  xmm0, xmmword ptr [esi+edi*4] ; ar2+i*4 is not 16-byte aligned, so load it to xmm0 
paddd   xmm1, xmm0 
movdqa  xmmword ptr [eax+edi*4], xmm1 ; ar3+i*4 
其他代码没有涉及与 SSE2 有关的指令。 
在指定-O3 选项并且启用SSE2 支持（-msse2 选项）的情况下，GCC编译器也能够进行简单的矢量化智
能处理。
②
① 有关地址对齐的详细信息，请参见：http://en.wikipedia.org/wiki/Data_structure_alignment。 
② https://gcc.gnu.org/projects/tree-ssa/vectorization.html。 
我们使用 GCC 4.4.1 编译上述程序，可得到： 
; f(int, int *, int *, int *) 
               public _Z1fiPiS_S_ 
_Z1fiPiS_S_ proc near 
var_18   
 = dword ptr -18h 
var_14   
 = dword ptr -14h 
var_10   
 = dword ptr -10h 
arg_0  
 = dword ptr  8 
arg_4  
 = dword ptr  0Ch 
arg_8  
 = dword ptr  10h 
arg_C  
 = dword ptr  14h 
 push    ebp 
 mov      ebp, esp 
异步社区会员 dearfuture(15918834820) 专享 尊重版权
378 
逆向工程权威指南（上册） 
 push     edi 
 push     esi 
 push     ebx 
 sub      esp, 0Ch 
 mov      ecx, [ebp+arg_0] 
 mov      esi, [ebp+arg_4] 
 mov      edi, [ebp+arg_8] 
 mov      ebx, [ebp+arg_C] 
 test     ecx, ecx 
 jle      short loc_80484D8 
 cmp      ecx, 6 
 lea      eax, [ebx+10h] 
 ja       short loc_80484E8 
loc_80484C1: ; CODE XREF: f(int,int *,int *,int *)+4B 
                ; f(int,int *,int *,int *)+61 ... 
 xor      eax, eax 
 nop 
 lea      esi, [esi+0] 
loc_80484C8: ; CODE XREF: f(int,int *,int *,int *)+36 
             mov      edx, [edi+eax*4] 
 add      edx, [esi+eax*4] 
 mov      [ebx+eax*4], edx 
 add      eax, 1 
 cmp      eax, ecx 
 jnz      short loc_80484C8 
loc_80484D8: ; CODE XREF: f(int,int *,int *,int *)+17 
                ; f(int,int *,int *,int *)+A5 
 add      esp, 0Ch 
             xor      eax, eax 
 pop      ebx 
 pop      esi 
 pop      edi 
 pop      ebp 
 retn 
 align8 
loc_80484E8: ; CODE XREF: f(int,int *,int *,int *)+1F 
             test     bl, 0Fh 
 jnz      short loc_80484C1 
 lea      edx, [esi+10h] 
 cmp      ebx, edx 
 jbe      loc_8048578 
loc_80484F8: ; CODE XREF: f(int,int *,int *,int *)+E0 
 lea      edx, [edi+10h] 
 cmp      ebx, edx 
 ja       short loc_8048503 
 cmp      edi, eax 
 jbe      short loc_80484C1 
loc_8048503: ; CODE XREF: f(int,int *,int *,int *)+5D 
 mov      eax, ecx 
 shr      eax, 2 
 mov      [ebp+var_14], eax 
 shl      eax, 2 
 test     eax, eax 
 mov      [ebp+var_10], eax 
 jz       short loc_8048547 
 mov      [ebp+var_18], ecx 
 mov      ecx, [ebp+var_14] 
 xor      eax, eax 
异步社区会员 dearfuture(15918834820) 专享 尊重版权
第 25 章 SIMD 
379 
 xor      edx, edx 
 nop 
loc_8048520: ; CODE XREF: f(int,int *,int *,int *)+9B 
 movdqu  xmm1, xmmword ptr [edi+eax] 
 movdqu  xmm0, xmmword ptr [esi+eax] 
 add      edx, 1 
 paddd   xmm0, xmm1 
 movdqa  xmmword ptr [ebx+eax], xmm0 
 add      eax, 10h 
 cmp      edx, ecx 
 jb       short loc_8048520 
 mov      ecx, [ebp+var_18] 
 mov      eax, [ebp+var_10] 
 cmp      ecx, eax 
 jz       short loc_80484D8 
loc_8048547: ; CODE XREF: f(int,int *,int *,int *)+73 
 lea      edx, ds:0[eax*4] 
             add      esi, edx 
             add      edi, edx 
             add      ebx, edx 
 lea      esi, [esi+0] 
loc_8048558: ; CODE XREF: f(int,int *,int *,int *)+CC 
 mov      edx, [edi] 
 add      eax, 1 
 add      edi, 4 
 add      edx, [esi] 
 add      esi, 4 
 mov      [ebx], edx 
 add      ebx, 4 
 cmp      ecx, eax 
 jg       short loc_8048558 
 add      esp, 0Ch 
 xor      eax, eax 
 pop      ebx 
 pop      esi 
 pop      edi 
 pop      ebp 
 retn 
loc_8048578: ; CODE XREF: f(int,int *,int *,int *)+52 
 cmp      eax, esi 
 jnb      loc_80484C1 
 jmp      loc_80484F8 
_Z1fiPiS_S_ endp 
GCC 生成的代码和 Intel C++十分相似，只是严谨性略差。 
25.1.2  用于内存复制 
我们回顾一下本书 14.2 节的 memcpy()函数： 
#include  
void my_memcpy (unsigned char* dst, unsigned char* src, size_t cnt) 
{ 
 size_t i; 
 for (i=0; i<cnt; i++) 
    dst[i]=src[i]; 
}; 
用 GCC 4.9.1 进行优化编译，可得到如下所示的代码。 
异步社区会员 dearfuture(15918834820) 专享 尊重版权
380 
逆向工程权威指南（上册） 
指令清单 25.1  Optimizing GCC 4.9.1 x64 
my_memcpy: 
; RDI = destination address 
; RSI = source address 
; RDX = size of block 
         test    rdx, rdx 
         je       .L41 
         lea      rax, [rdi+16] 
         cmp      rsi, rax 
         lea      rax, [rsi+16] 
         setae    cl 
         cmp      rdi, rax 
         setae    al 
         or       cl, al 
         je       .L13 
         cmp      rdx, 22 
         jbe      .L13 
         mov      rcx, rsi 
         push     rbp 
         push     rbx 
         neg      rcx 
         and      ecx, 15 
         cmp      rcx, rdx 
         cmova    rcx, rdx 
         xor      eax, eax 
         test     rcx, rcx 
         je       .L4 
         movzx    eax, BYTE PTR [rsi] 
         cmp      rcx, 1 
         mov      BYTE PTR [rdi], al 
         je       .L15 
         movzx    eax, BYTE PTR [rsi+1] 
         cmp      rcx, 2 
         mov      BYTE PTR [rdi+1], al 
         je       .L16 
         movzx    eax, BYTE PTR [rsi+2] 
         cmp      rcx, 3 
         mov      BYTE PTR [rdi+2], al 
         je       .L17 
         movzx    eax, BYTE PTR [rsi+3] 
         cmp      rcx, 4 
         mov      BYTE PTR [rdi+3], al 
         je       .L18 
         movzx    eax, BYTE PTR [rsi+4] 
         cmp      rcx, 5 
         mov      BYTE PTR [rdi+4], al 
         je       .L19 
         movzx    eax, BYTE PTR [rsi+5] 
         cmp      rcx, 6 
         mov      BYTE PTR [rdi+5], al 
         je       .L20 
         movzx    eax, BYTE PTR [rsi+6] 
         cmp      rcx, 7 
         mov      BYTE PTR [rdi+6], al  
         je       .L21 
         movzx    eax, BYTE PTR [rsi7+] 
         cmp      rcx, 8 
         mov      BYTE PTR [rdi+7], al  
         je       .L22 
         movzx    eax, BYTE PTR [rsi+8] 
         cmp      rcx, 9 
         mov      BYTE PTR [rdi+8], al  
         je       .L23 
         movzx    eax, BYTE PTR [rsi+9] 
         cmp      rcx, 10 
异步社区会员 dearfuture(15918834820) 专享 尊重版权
第 25 章 SIMD 
381 
         mov      BYTE PTR [rdi+9], al  
         je       .L24 
         movzx    eax, BYTE PTR [rsi+10] 
         cmp      rcx, 11 
         mov      BYTE PTR [rdi+10], al  
         je       .L25 
         movzx    eax, BYTE PTR [rsi+11] 
         cmp      rcx, 12 
         mov      BYTE PTR [rdi+11], al  
         je       .L26 
         movzx    eax, BYTE PTR [rsi+12] 
         cmp      rcx, 13 
         mov      BYTE PTR [rdi+12], al  
         je       .L27 
         movzx    eax, BYTE PTR [rsi+13] 
         cmp      rcx, 15 
         mov      BYTE PTR [rdi+13], al  
         jne      .L28 
         movzx    eax, BYTE PTR [rsi+14] 
         mov      BYTE PTR [rdi+14], al 
         mov      eax, 15 
.L4: 
         mov      r10, rdx 
         lea      r9, [rdx-1] 
         sub      r10, rcx 
         lea      r8, [r10-16] 
         sub      r9, rcx 
         shr      r8, 4 
         add      r8, 1 
         mov      r11, r8 
         sal      r11, 4 
         cmp      r9,14 
         jbe      .L6 
         lea      rbp, [rsi+rcx] 
         xor      r9d, r9d 
         add      rcx, rdi 
         xor      ebx, ebx 
.L7: 
         movdqa   xmm0, XMMWORD PTR [rbp+0+r9] 
         add      rbx, 1 
         movups   XMMWORD PTR [rcx+r9], xmm0 
         add      r9, 16 
         cmp      rbx, r8 
         jb       .L7 
         add      rax, r11 
         cmp      r10, r11 
         je       .L1 
.L6: 
         movzx    ecx, BYTE PTR [rsi+rax] 
         mov      BYTE PTR [rdi+rax], cl 
         lea      rcx, [rax+1] 
         cmp      rdx, rcx 
         jbe      .L1 
         movzx    ecx, BYTE PTR [rsi+1+rax] 
         mov      BYTE PTR [rdi+1+rax], cl 
         lea      rcx, [rax+2] 
         cmp      rdx, rcx 
         jbe      .L1 
         movzx    ecx, BYTE PTR [rsi+2+rax] 
         mov      BYTE PTR [rdi+2+rax], cl 
         lea      rcx, [rax+3] 