A. RQ4: Controller Selection Guideline
Inspired by our observations, we provide general guidelines
to aid operators in selecting controllers. Our guidelines focus
on completeness, functionality, and SDN use cases. We ob-
serve that most problems in FAUCET are due to missing logic
(speciﬁcally 52.5% of bugs), which makes it the least stable of
the controllers that we analyzed. Although, CORD and ONOS
are based on the same fundamental codebase, we observed
that CORD is susceptible to signiﬁcantly more load-related
problems – 30% of bugs in CORD versus 16% in ONOS.
In Table VI, we show two critical use cases that SDN has
enabled and the symptoms that affect the core functionality
of these use cases. Building on the above observations, we
recommend ONOS as the most stable and performant among
the analyzed controllers. Unlike CORD, moving towards
ONOS will require developers to ﬁnd appropriate or develop
applications due to a lack of rich applications. Moreover, we
observed that FAUCET is specialized for a speciﬁc use-case,
e.g., network slicing [131], [132]. Due to slicing’s inherent
Figure 12: CDF of Bug Category Correlation.
Figure 13: Trigger Distribution among the Whole Dataset. A:
Conﬁguration, B: System Calls, C: Third Party Calls, D: Network
Events, E: Application Calls. B, C and E belong to External Calls.
isolation, we note that using it outside of this narrow use case
will often yield missing functionality and logic errors.
B. RQ4: Automating Operators Diagnosis
In the absence of a tool for holistically diagnosing and re-
solving bugs, we conclude this section by providing guidelines
for expediating root-cause diagnosis and resolution. We do this
by analyzing the correlations between the bugs and categories
(in Table I) and exploring the uniqueness of the keywords
(AKA labels) in the bug descriptions.
Correlation Analysis: Figure 12 shows the CDF of cor-
relations between all possible bug and category pairs. The
curve illustrates that while most bug-category pairs (93.72%
of bug) are fairly correlated, there is a long tail indicating
strong-correlated bug categories (6.28% of bugs). For example,
we observed that memory bugs are highly deterministic in
nature. More interestingly, the bugs triggered by third-party
service calls are highly correlated to the ﬁx “add compatibil-
ity”, which ﬁts with the observations that these bugs could
be caused by argument mismatch between library versions.
Surprisingly, unlike bugs in the core controller, these third-
party bugs are correlated with the outcomes “Error message”
and “Byzantine”.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:22:53 UTC from IEEE Xplore.  Restrictions apply. 
109
Bug Trigger
Network Event
[116], [119]
External calls
[120]
Hardware Reboots
[121], [122]
Deterministic
No
Yes
[116]
[117]
Conﬁguration
[118]
LegoSDN [48]
Ravana [13]
SCL [14]
RoseMary [123]
SCOUT [124]
JURY [125]
DPQoAP [126]
Table V: Effectiveness of Existing Recovery Techniques. C: Conﬁguration, N: Network Event, E: External calls, and H: Hardware Reboots.
Symptoms
EM
F
[60]
[127]
P
[71]
B
[56]
SDN use case
Logically Centralized
( [128], [129], [130] )
Network Slicing
( [131], [132] )
Table VI: Symptoms of the bugs affecting SDN use case net-
work operation drastically. EM: Error Message B: Byzantine
F: Fails-stop P: Performance.
Figure 14: Unique Topic Percentage. A: Deterministic, B: Byzantine,
C: Add Synchronization, D: Third Party Calls.
Keyword Analysis: To further understand these correla-
tions, we analyzed the topics extracted by the NLP techniques.
We hypothesize that these correlations reﬂect that speciﬁc
classes of bugs have unique topics or keywords in the bug
description. For example, memory bugs often have a null
pointer and other similar exceptions in the bug description.
In Figure 14, we listed the top bug categories based on topic
uniqueness. We observe that these bug categories are the exact
bug categories that have a high correlation discussed earlier.
We observe that the uniqueness in topics spreads over all bug
classiﬁcations. Speciﬁcally, bugs with Byzantine symptoms
introduce signiﬁcantly different topics and keywords in the
bug description. Similarly, some bug types, e.g., deterministic
bugs, have remarkably unique topics.
We also apply our NLP model, which is trained with the
manually labeled dataset, onto the whole dataset of critical
bugs we get from Jira to demonstrate NLP techniques’ poten-
tial further. This large dataset contains ∼5X bugs compared to
our manually labeled dataset. Figure 13 is the distribution of
predicted trigger from the whole dataset. The result indicates
that conﬁguration error is the major trigger of SDN controller
bugs, and when troubleshooting an SDN controller, the op-
erator should pay more attention to potential conﬁguration
glitches. Compared to conﬁguration, the bugs triggered by
OpenFlow events only contribute a small part. Given the
complexity of capturing, replaying the network events to
reproduce a previous scenario, it is more clever to examine
the network events after ensuring other more critical potential
triggers. We also summarized the results for other aspects,
such as the deterministic bug is the dominant bug type. Due
to the limit of space, we skip the details in this paper.
Takeaway. These correlations and keyword analysis imply
that for a non-trivial amount of bugs, being able to identify
outcomes, symptoms, and extract keywords from the bug will
allow developers and operators to narrow down the potential
root causes and ﬁxes. As part of future work, we anticipate that
a decision tree can be developed to help restrict and narrow
the developer and operator efforts in diagnosis.
C. RQ5: Selecting Recovery Frameworks
In Table V, we present a survey of existing fault tolerance
techniques for SDNs. A key observation here is that no
one technique can recover from bugs across all root causes
effectively. Unsurprisingly, most techniques [13], [14], [48],
[123]–[125] are able to recover from events triggered by
OpenFlow messages which is the main focus of most SDN
research. Yet, there are very few existing works within the
SDN domain for interactions with conﬁguration and external
calls. We note that while non-SDN techniques, e.g., Lock-in-
Pop [133], can address external events or conﬁguration, these
techniques need to be modiﬁed to address domain-speciﬁc
issues.
We observe that most existing systems can easily recover
from non-deterministic issues. However, there is very little for
deterministic issues that account for most of the problems (as
shown in Section III).
Symptoms
Category
Fail-stop
Performance
Error Message
Byzantine
SDN
20%
4%
14.7%
61.33%
Cloud [19]
59%
14%
NA
25%
BGP [35]
39%
NA
NA
58%
Table VII: Analysis of Bug Symptoms Accross Related Work.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:22:53 UTC from IEEE Xplore.  Restrictions apply. 
110
Takeaway. Although we showed a plethora of systems
that can diagnose or recover from different types of bugs, in
practice, it is not trivial to combine these systems together to
form a holistic system for the following reasons:
• Simply layering the systems on each other may introduce
inefﬁciencies or impact accuracy. For example, while
SPHINX [134] requires that all input OpenFlow messages
to update a “ﬂow graph”-based model, Bouncer [135]
proactively ﬁlters out some input which may lead to an
inconsistent ﬂow graph and, thus, impacts accuracy 3.
• Additionally, their expected inputs and system models
are often fundamentally different; thus, integration is a
non-trivial task. For example, while SOFT [136] analyzes
output generated by different vendor implementations
and CHIMP [137] analyzes output from different SDN
applications, it is unclear how to compose the results
from SOFT and CHIMP to provide a holistic, cross-layer
approach to fault detection.
VIII. THREATS TO VALIDITY AND DISCUSSIONS
Generalizability. While limited, we believe that our
analysis generalizes to future controllers because related
work has shown that controllers follow a limited set of
design principles that are well represented in the controllers
that we studied. Speciﬁcally, the three controllers that we
analyzed provide coverage over the following design choices:
speciﬁcally, specialized (CORD) versus generalized (ONOS,
FAUCET); monolithic (FAUCET) versus modular (ONOS,
CORD); and distributed (ONOS, CORD) versus centralized
(FAUCET).
Automated SE Analysis. Our automated code analysis is
limited by the constraints of existing software engineering
analysis tools, which only support speciﬁc languages (JAVA)
or speciﬁc build systems (maven, gradle). For example, we
could not perform smell analysis for FAUCET because it
is written in Python, and the smell analysis codebase only
supports JAVA-based software. Unfortunately, this limitation
limits our ability to perform this analysis on a broader set of
controllers.
Different bug management systems. The controllers use
different bug management systems, e.g., GitHub (FAUCET),
JIRA (ONOS, CORD), which could lead to variation in the
type of information available. For example, JIRA provides
Gerrit reviews, bug status,
timestamps, etc while GitHub
provides a different subset of data. These subtle differences
impact
tools, and analysis that we
could apply. For example, we could not analyze FAUCET’s
resolution times because their GitHub repository does not
provide this information.
the set of techniques,
3The whole point for ﬂow graph is performing anomaly detection, which
requires all inputs including the bad ones.
Manual Classiﬁcation. Our work involves both manual and
automated analysis. While the automated analysis is suscepti-
ble to noise and bias, we note that we only use the automated
analysis to support our manual analysis. In fact, most of our
takeaways are based on manual analysis, thus minimizing
the impact of learning-based noise on our observations. Our
manual analysis’s validity is predicated on the fact that the
bugs are accurately described and reported.
IX. RELATED WORKS
System-Research.
In general, bug studies
spanning
across various domains [18], [19], [35], [138]–[141] lay the
foundation for systems research. While prior studies have
focused on distributed systems, we lack similar in-depth and
comprehensive studies for SDN controllers. Unsurprisingly,
we observed that, despite using a similar classiﬁcation as prior
work [18], [19], bugs in SDN controllers differ signiﬁcantly in
their distributions, motivating the need for studies such as ours.
SDN Bug Studies. Prior work on SDN bugs [11], [12],
[142]–[145] analyze a smaller spectrum of bugs compared
with our study, which provides a holistic and in-depth
analysis of ‘critical’ SDN bugs. While our work focuses on
understanding bugs and their implications, others [143]–[145]
have developed stochastic models to help quantify the
reliability of existing controllers.
X. CONCLUSION
Bugs are a crucial aspect of any software ecosystem, yet
within the software-deﬁned networking (SDN) community, we
have a poor understanding of our bugs. Without a thorough
understanding of these bugs, it is challenging to: (1) under-
stand the efﬁcacy of existing SDN fault tolerance techniques,
(2) design representative fault injectors, or (3) identity key
areas that are ripe for research. In this paper, our goal is
to provide the knowledge required to ﬁll this crucial gap
in the community’s understanding of the SDN ecosystem by
performing, to date, the largest bug study over three popular
controller platforms.
XI. ACKNOWLEDGEMENTS
We thank the anonymous reviewers and our shepherd,
Marco Vieira, for their helpful comments. This work was
supported by NSF award CNS-1749785.
REFERENCES
[1] “At&t sdwan details retrieved from,” https://www.business.att.com/
products/sd-wan.html, 2019, accessed: 10-6-2019.
[2] “Vodafone sdn details retrieved from,” https://www.vodafone.co.uk/
business/sdn, 2019, accessed: 13-11-2019.
managing
simpliﬁes
sdn
[3] “How
digital
experiences,”
https://www.orange-business.com/en/blogs/connecting-technology/
networks/how-sdn-simpliﬁes-managing-digital-experiences,
accessed: 13-11-2019.
2019,
[4] “Nsx data center details retrieved from,” https://www.vmware.com/in/
products/nsx.html, 2019, accessed: 10-6-2019.
[5] “The andromeda cloud platform details retrieved from,” 2019, https:
//www.ngcsoftware.com/landing/ngcandromedacloudplatform/.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:22:53 UTC from IEEE Xplore.  Restrictions apply. 
111
[6] J. Son and R. Buyya, “A taxonomy of software-deﬁned networking
(sdn)-enabled cloud computing,” ACM Comput. Surv., vol. 51,
no. 3, pp. 59:1–59:36, May 2018.
[Online]. Available: http:
//doi.acm.org/10.1145/3190617
[7] R. Govindan, I. Minei, M. Kallahalla, B. Koley, and A. Vahdat,
“Evolve or Die: High-Availability Design Principles Drawn from
Googles Network Infrastructure,” in Proceedings of
the 2016
ACM SIGCOMM Conference, ser. SIGCOMM ’16. New York,
NY, USA: ACM, 2016, pp. 58–72.
[Online]. Available: http:
//doi.acm.org/10.1145/2934872.2934891
[8] S. Jain, A. Kumar, S. Mandal, J. Ong, L. Poutievski, A. Singh,
S. Venkata, J. Wanderer, J. Zhou, M. Zhu, J. Zolla, U. H¨olzle,
S. Stuart, and A. Vahdat, “B4: Experience with a globally-deployed
software deﬁned wan,” in Proceedings of the ACM SIGCOMM
2013 Conference on SIGCOMM,
ser. SIGCOMM ’13. New
York, NY, USA: ACM, 2013, pp. 3–14.
[Online]. Available:
http://doi.acm.org/10.1145/2486001.2486019
[9] T. Lei, Z. Lu, X. Wen, X. Zhao, and L. Wang, “Swan: An sdn based
campus wlan framework,” in 2014 4th International Conference on
Wireless Communications, Vehicular Technology, Information Theory
and Aerospace Electronic Systems (VITAE), May 2014, pp. 1–5.
[10] S. Choi, B. Burkov, A. Eckert, T. Fang, S. Kazemkhani, R. Sherwood,
Y. Zhang, and H. Zeng, “Fboss: Building switch software at scale,”
in Proceedings of the 2018 Conference of the ACM Special Interest
Group on Data Communication, ser. SIGCOMM ’18. New York,
NY, USA: Association for Computing Machinery, 2018, p. 342–356.
[Online]. Available: https://doi.org/10.1145/3230543.3230546
[11] M. Canini, D. Venzano, P. Pereˇs´ıni, D. Kosti´c, and J. Rexford, “A
NICE way to test openﬂow applications,” in NSDI. San Jose, CA:
USENIX, 2012, pp. 127–140. [Online]. Available: https://www.usenix.
org/conference/nsdi12/technical-sessions/presentation/canini
[12] C. Scott, A. Wundsam, B. Raghavan, A. Panda, A. Or, J. Lai,
E. Huang, Z. Liu, A. El-Hassany, S. Whitlock, H. Acharya, K. Zari-
ﬁs, and S. Shenker, “Troubleshooting Blackbox SDN Control Soft-
ware with Minimal Causal Sequences,” ACM SIGCOMM Computer
Communication Review, vol. 44, 08 2014.
[13] N. Katta, H. Zhang, M. Freedman, and J. Rexford, “Ravana: Controller
Fault-tolerance in Software-deﬁned Networking,” in Proceedings of the
1st ACM SIGCOMM Symposium on Software Deﬁned Networking