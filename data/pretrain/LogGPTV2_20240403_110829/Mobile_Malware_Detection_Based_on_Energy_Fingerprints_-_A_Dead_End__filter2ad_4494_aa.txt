title:Mobile Malware Detection Based on Energy Fingerprints - A Dead End?
author:Johannes Hoffmann and
Stephan Neumann and
Thorsten Holz
Mobile Malware Detection Based on
Energy Fingerprints — A Dead End?
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
Horst G¨ortz Institute (HGI), Ruhr-University Bochum, Germany
{firstname.lastname}@rub.de
Abstract. With the ever rising amount and quality of malicious software for mo-
bile phones, multiple ways to detect such threats are desirable. Next to classical
approaches such as dynamic and static analysis, the idea of detecting malicious
activities based on the energy consumption introduced by them was recently pro-
posed by several researchers. The key idea behind this kind of detection is the
fact that each activity performed on a battery powered device drains a certain
amount of energy from it. This implies that measuring the energy consumption
may reveal unwanted and possibly malicious software running next to genuine
applications on such a device: if the normal energy consumption is known for a
device, additional used up energy should be detectable.
In this paper, we evaluate whether such an approach is indeed feasible for modern
smartphones and argue that results presented in prior work are not applicable to
such devices. By studying the typical energy consumption of different aspects of
common Android phones, we show that it varies quite a lot in practice. Further-
more, empirical tests with both artiﬁcial and real-world malware indicate that the
additional power consumed by such apps is too small to be detectable with the
mean error rates of state-of-the art measurement tools.
1
Introduction
In the last years, smartphone sales began to rise signiﬁcantly [3] and also the number
of malicious software for these devices grew [4,21]. As a result, several techniques to
analyze smartphone applications emerged with the goal to detect and warn users of un-
wanted software. Most solutions are based on classic techniques known from the PC
area, such as dynamic and static analyses (e. g., [8,7,10,22]). Based on the fact that mo-
bile phones are powered by a battery and the insight that every performed action drains a
speciﬁc amount of energy from that battery, the idea came up to measure the consumed
energy and to deduce from that data whether any unwanted (malicious) activities oc-
curred, possibly hidden from the user [12,13]. The developed tools use the system API
or additional external devices to obtain information about the battery status, running
applications, actions performed by the user (if any), and calculate the normal amount
of energy a clean device should consume under such circumstances. This model is then
used in the detection phase to compare live measurement data against it in order to de-
tect additional activities. Such a method could—at least in theory—detect software that
was loaded onto the device or applications that suddenly behave in a different way.
The proposed prototypes [12,13] were implemented and tested on feature phones
with a limited amount of additional installable (third party) applications compared to
2
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
the “application markets” of today’s smartphones. Furthermore, the devices themselves
were equipped with considerably less features and sensors, such as an accelerometer,
GPS, WiFi, large touchscreens, or a full-blown browser. Compared to a modern smart-
phone, these feature phones offer less possibilities to a user.
Throughout this paper, we attempt to verify or disprove the possibility to detect
malware on modern smartphones based on their energy consumption. We use a spe-
cialized tool named PowerTutor [20] to measure the energy consumption of several
potentially malicious activities in both short and long time test scenarios. We evaluate
the energy consumption for each action and the energy consumption for the complete
device based on the reports provided by PowerTutor. Our short time tests aim to get an
idea of the measurement possibilities for a short time duration (5 minutes) and the long
time tests (1 hour) evaluate what is possible in scenarios that can be found on smart-
phones used every day. We measure the impact of classic malicious activities such as
stealing personal data or abusing the short message service (SMS) next to artiﬁcial ones
like draining the battery as fast as possible in order to commit some kind of denial-of-
service attack. We implement our own proof-of-concept malware that accomplishes our
malicious tasks and we validate our ﬁndings with two real-world malware samples.
Our main contribution is the evaluation of a method to detect malicious software
that was conducted in the ﬁrst place on “old” feature phones rather than on modern
smartphones. We argue that the proposed methods do not hold in practice anymore and
study in detail how a modern Android phone consumes power. We show that the energy
needed to perform relevant malicious activities, such as stealing private data, is too
small to be detectable with the mean error rates of state-of-the art measurement tools.
2 Related Work
Since we want to (dis)prove that malware detection is possible on a modern smartphone
by measuring its power consumption, we ﬁrst discuss related work in this ﬁeld.
Kim et al. introduced the idea of detecting malicious software based on its power
consumption [12]. They built a prototype for phones running Windows Mobile 5.0 that
works with power signatures. These signatures are based on the power consumption of
a program rather than its code or exhibited behavior. In order to be useful to the enduser,
a signature database has to be available. This circumstance does not allow the detection
of new and unknown malware, as no signature is available.
Another tool for Symbian based phones was proposed by Liu et al. [13]. Their
tool, called VirusMeter, works without any signatures but on heuristics. In a ﬁrst step,
the user’s behavior and the corresponding power consumption on a clean system is
proﬁled. Then, in a second step, the actual used energy is compared against the learned
proﬁle and if a certain threshold is reached, the systems alerts the user that additional
(maybe malicious) activities have been performed on the phone. Throughout this paper,
we perform similar tests not on features phones but on modern Android smartphones
and evaluate to what extend malicious activities can be detected (if any).
Work by Dixon et al. shows that the location has a huge impact on the user’s ac-
tivities [5]. Leveraging this information, the average power consumption for different
locations can be computed that could then be used to detect anomalies in the power
Mobile Malware Detection Based on Energy Fingerprints — A Dead End?
3
signature for these locations if, e. g., malware performs additional operations next to
the expected power consumption introduced by a user. A study performed by Balasub-
ramanian et al. [2] analyzed the tail energy overhead introduced by transfers over the
wireless connections offered by smartphones. Although they measured the used energy
for different connection types, they focused on the amount of energy that can be saved
if a special protocol is used by applications that make use of wireless connections.
Dong et al. propose Sesame, a tool that is able to generate a power model for smart-
phones and notebooks and the underlying hardware, battery, usage etc. by itself without
external tools [6]. They argue that factory-built models are unlikely to provide accurate
values for different scenarios, such as different hardware or usage patterns.
Since all such tools need to measure the used energy in one or another way, work
related to this task is also relevant for us. The ﬁrst tool, called PowerTutor [20], was
designed to provide a precise report of energy spent on a smartphone. This report in-
cludes the power consumption of sole devices such as the NIC or the display. In order
to provide a very detailed power model for an analyzed application, a power model for
the used mobile device has to be calculated in the ﬁrst place. This model was generated
with the help of specialized hardware that precisely measured the power consumption
of the device under certain circumstances. Since these models are bound to the device,
accurate results with a claimed long-term error rate of less than 2.5% for an applica-
tion’s lifespan can only be provided if PowerTutor runs on such a “calibrated” device.
PowerTutor runs on Android, requires no changes to the operating system and the An-
droid framework, and its source code is freely available.
Next to PowerTutor, a tool called eprof was introduced to measure the power con-
sumption of a given app on Windows Mobile and Android smartphones [16]. It is also
able to provide a breakdown of the power consumption of sole methods inside applica-
tions. This is possible because eprof works on the system call level: all I/O operations
that consume energy from internal devices are realized through system calls performed
by the application, e. g., sending a packet over the mobile Internet connection through
the GPS modem. This enables a precise measurement of the energy spent for an appli-
cation in question. This measurement method is different compared to the utilization-
based one performed by PowerTutor. The authors of eprof claim an error rate of under
6% for all tested applications in contrast to an error rate of 3–50% for utilization-based
methods. Furthermore, eprof can be used to measure which application components use
what amount of energy [15]. The tool is not available and the authors describe changes
to the OS kernel, the OS/Android framework, and the analyzed application itself.
Yoon et al. recently proposed another tool named AppScope [19] to measure the
energy consumption on Android smartphones. Their monitoring software is able to es-
timate the energy consumption on a per app basis in a similar way as PowerTutor by
making use of a kernel module that hooks and reports certain events on the syscall level
and by using a linear power model. The error rate ranges from 0.9–7.5% depending
on the tested software as long as no GPU intense tasks are performed. For games like
Angry Birds it raises up to 14.7%.
All three tools can interfere the current power consumption of an app at whole or
access to some component in detail from some previously generated power model. The
subsystems itself, e. g., the WiFi device or its driver, do not provide such information.
4
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
3 Measurement Setup
To measure accurate power consumption traces for several use cases on a modern smart-
phone, we ﬁrst have to chose a stable setup under which all studies are performed. Fur-
thermore, we need some way to actually generate accurate power measurements and
we need a tool that performs deﬁned actions that consume power.
Our tool of choice to measure the power consumption is PowerTutor [20], which
was already introduced in the last section. Having access to PowerTutor’s sources, we
modiﬁed it slightly such that it generates verbose log ﬁles which we used for our cal-
culations throughout this paper. Since we want to verify if a software-based detection
mechanism is capable of detecting additionally installed malware on a smartphone, we
cannot make use of any hardware-assisted measurement mechanisms. Such additional
devices (note that the phone itself is not capable of doing this with the exception of
reporting an approximate battery charge level and voltage) would severely reduce the
user acceptance to perform such measurements at all. Since end users are the target of
such a software as they shall be protected from malicious software, it should be a purely
software based solution as one would expect from traditional AV software products. We
chose PowerTutor over eprof because we have access to the tool, the mean error rate
is comparable, and we are able to generate good measurement results despite using a
utilization-based measurement method since we have control over the test system (i. e.,
we can control how much parallel interaction occur, see Section 4 for more details).
We now describe our software which we used for our test cases and explain the
choice of our used smartphones.
3.1 Android Application
We now describe how we perform the power consumption measurements of different
smartphone features. Since the main contribution of this paper is to (dis)prove the pos-
sibility to detect malicious software due to it’s power consumption, we wrote a software
that is able to run artiﬁcial tests of relevant functions that actual Android malware ex-
hibits. While our test malware performs these actions, the power consumption is mea-
sured by PowerTutor.
Our proof-of-concept malware is able to perform the following functions in order
to evaluate what features or combinations of features are detectable. It can send and
receive SMS; make use of the location API; access content providers, e. g., contacts and
SMS database; send arbitrary (encrypted) data over the network; access serial numbers,
e. g., the IMEI; record audio; set Android wake locks to control the power states of the
CPU and the screen; and run in an endless loop to put a heavy burden on the CPU.
These features are typically (more or less) used by malicious applications once they
are installed, with the exception of the last one. Nevertheless, a malware that aims to
disrupt operational time of the smartphone is easily imaginable. The measurement re-
sults for these functions or a combination thereof are later evaluated in order to see
whether such activities are detectable by the amount of consumed power, similar to the
malware tests conducted by VirusMeter [13].
Our software is written in Java and is installed like any other Android application. To
be able to perform the described actions, all required Android permissions are requested
Mobile Malware Detection Based on Energy Fingerprints — A Dead End?
5
in the application’s Manifest ﬁle. It basically consists of a control program that initiates
an action over the network and a service which performs it. Actions can be run once,
repeated in an interval, delayed and so on. This scheduling is performed with the help
of the Android AlarmManager. All actions are performed by the service and are there-
fore performed without any GUI elements. This is crucial for the measurement step, as
PowerTutor accounts the power consumption of GUI elements to the appropriate app.
They inﬂuence the displays power consumption for OLED displays and, additionally,
foreground processes have a higher priority than background processes within Android.
The power consumption of this test malware will be referred as “MW” in all tables.
3.2 Test Devices
We performed most tests with a HTC Nexus One smartphone. The reason for this is that
this phone was explicitly tested and used by the PowerTutor developers, saving us from
calculating our own power model for the smartphone. They used three different phones,
but the Nexus One is the newest one and is upgradeable to a recent Android version
(Android 2.3.6). Having a rooted phone also enables PowerTutor to calculate a more
precise power consumption for the built-in OLED display which depends on the visible
pixel colors. By using this phone we believe we get the most accurate measurements
out of PowerTutor. All tests are performed by this phone unless stated otherwise.
We additionally performed some tests with a Samsung Galaxy Nexus phone in order
to validate our results. This is the latest Android developer phone by the time of writing
and runs Android version 4.0. The phone is also equipped with an OLED display, albeit
with a newer version being called “HD Super AMOLED”, next to some additional sen-
sors and it is used for validation purposes (although PowerTutor measurements might
be less accurate due to a missing calibration). The phone’s remaining battery capacity
and its runtime can still be used to compare the results with those of the Nexus One.
Both phones have been equipped with new and formerly unused batteries in order to
ensure maximum battery lifetimes. Note that our setup suffers from the same problems
all such systems have, e. g., the reported battery capacity and voltage may change a lot
due to different parameters [14].
4 Short Time Tests
In order to determine whether malicious software is detectable on a phone with the
help of power signatures, we ﬁrst need to know the power requirements of several soft-
and hardware components. To obtain an overview, we ﬁrst conducted short time tests
to measure which features consume what amount of battery capacity for later compar-
isons. First, all tests were run with the same basic settings. The hardware GPS module
is activated, but not used. The display brightness is set to a ﬁxed value of 130/255 and
it switches off after 30 seconds of inactivity. The standard live wallpaper is active on
the home screen but no synchronization, background data, mail fetching, or widgets
are active. Internet connectivity is either provided by WiFi or by 3G, depending on the
test. Additionally, the OS is freshly installed and only a few additional applications are
installed: PowerTutor to be able to perform our measurements; MyPhoneExplorer to
6
Johannes Hoffmann, Stephan Neumann, Thorsten Holz
easily access logged data from a PC; K-9 Mail for email fetching; and our own proof-
of-concept malware for our evaluations. All tests are repeated six times in a row for
5 minutes from which the arithmetic median of the consumed energy is calculated.
During this time, no additional interaction with the phone occurs. Note that such mea-
surements do not represent a valid usage pattern in any case, but they enable us to
determine the power consumption of basic phone features.
For all following tests, the same usage pattern is used. When the phone is fully
charged and set to an initial state, PowerTutor is started and directly put in the back-
ground such that the home screen with the live wallpaper and the launcher is visible. No
further input will occur in the next 5 minutes which causes the screen to be turned off
after 30 seconds. As long as nothing is noted, a test does not deviate from this pattern.
In the following, we calculate the amount of used energy in mW and its coefﬁ-
cient of variation (CV) for several power consumers or the whole system, respectively.
First, the CV is calculated for an idling phone (see next paragraph) and this deﬁnes
the average percentage of deviating consumed energy during a given time interval. In
other words, the CV for an idling phone describes the average amount of noise that is
introduced by all components. If any action consumes less energy than the noise rate
(i. e.., amount of energy described by the CV for an idling phone), it is not measurable
with a single measurement. We could of course measure the power demands of such
consumers if we would perform many measurements of the same consumer and would
calculate the noise out of the results. A detection engine that works with power sig-
natures does not have this kind of luxury, as it has to pinpoint malicious behavior as
soon as possible. If many measurements must occur in the ﬁrst place, a malicious soft-
ware could already have easily performed its payload undetected. If the additionally
consumed power of some activity is given in later tests in a table (referred as “Rise”
in the corresponding column), it will be shown in bold letters if its value is above the
CV of an idling phone (WiFi or 3G), meaning the measured action has a higher energy
consumption than the average noise ratio of an idling phone. Such a component could
be detected by a power signature.
Tables with measurement results will also often contain a column labeled “Total
Cons.” that depicts the total consumed energy during the test as reported by PowerTu-
tor. Unexpected Framework and OS activities triggered during a test might introduce
additional noise, which can be seen in this column. The impact is of course higher for
the conducted short time test. If this value is higher than the total consumption of the
initial tests (see next paragraph) plus the noise ratio (CV value), it will also be written in
bold letters. This value does not related to the “Rise” column but describes unexpected
introduced noise in addition to any used energy throughout the test. Note that if the
value is written in bold letters, it does not imply that it can be detected in a reliable way.
It’s value must be signiﬁcant higher than the CV value, which describes the average
noise. False positives are possible here, one must carefully check the size of the value.
Higher differences to the initial total consumption mean potentially less false positives.
Since PowerTutor is unable to measure the power consumption of the GSM modem,
we cannot provide any measurement about it’s usage. Still, we performed a test that in-
cludes the sending of short messages in Section 5.5. In order to overcome the drawbacks
of the utilization-based measurement method of PowerTutor, we strictly control all ad-
Mobile Malware Detection Based on Energy Fingerprints — A Dead End?
7
ditionally running applications (next to the running OS applications) and their access to
any device. Doing this mitigates the problem of accounting the used energy to programs
running in parallel.
4.1
Initial Tests
We start our evaluation with tests in which we measure the power consumption of sev-
eral components such as the display as well as the inﬂuence of running software. These
initial tests deﬁne a basis for later tests which are compared with the initial ones. Know-
ing the minimum amount of energy a smartphone requires in certain circumstances is
crucial for the detection of additional malicious activities.
Data Connectivity. This test evaluates the differences between a WiFi and a 3G connec-
tion on an otherwise idling phone. Table 1 shows how much power their usage consumes
if the connection is only established, but no data is actually transferred.
Table 1. Short time initial tests for a 5
minute period. Average power consump-
tion for wireless connections.
Consumption
CV
Connection
WiFi (always on)
51.17 mW 0.87%
WiFi (if screen is on) 51.26 mW 1.14%
68.47 mW 9.49%
3G
The WiFi connection can automatically be
turned off if the smartphone’s screen blanks in
order to safe energy. Using this feature saves