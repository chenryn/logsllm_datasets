additional features (e.g., non-volatile monotonic counters, demand
paging) and additional guarantees against sophisticated attackers
(e.g., timing attacks). It provides an extensible verification methodol-
ogy that enables rigorous reasoning about the security properties of
future enclave platforms. It is also an extensible model for reasoning
about enclave programs.
7.1 Implications for Enclave Platforms
The TAP can be beneficial to implementers of enclave platforms
in the following ways. First, the TAP can be used as a top-down
specification for what operations an enclave platform must support.
Implementers can use refinement checks to ensure that the TAP’s
security guarantees apply to the implementation as well. A impor-
tant implementation challenge is that security is not compositional:
addition of operations to a secure platform can make it insecure. The
insecurity of SGX to Adversary MCP [69, 83] stems from demand
paging, using which the OS observes the state of enclave’s page
tables; this feature is not present in the current implementation of
Sanctum. Suppose that the next version of Sanctum supports de-
mand paging through the use of oblivious RAM to maintain TAP’s
confidentiality guarantee. Reasoning about these more complex
12
enclave platforms is infeasible without a verification methodology
and TAP-like specification of the platform’s primitives.
Second, the TAP can also be used bottom-up, as this paper does,
to reason about the security properties of existing platforms. Such
analysis exposes differences between various platforms, e.g., leak-
age through the cache and page tables for SGX. The refinement
methodology described in this paper can be used to show that imple-
mentations of enclave platforms (e.g., the Sanctum implementation)
are refinements of corresponding models (e.g., Sanctum model).
Since we have shown that the Sanctum model is a refinement of
the TAP, this proof would mean that the security properties of the
TAP also hold for the Sanctum implementation.
7.2 Implications for Enclave Software
While techniques for verifying security properties of enclave pro-
grams [70, 71] have been developed, they rely on models of the
underlying enclave platform. We argue that such reasoning is bet-
ter done using TAP’s clean abstraction, which is simpler than the
instruction-level model of SGX and API-level model of Sanctum.
This simplification makes automated verification more scalable, yet
retains soundness because of the refinement checks. It is also a step
towards enabling portability among different enclave platforms.
Most importantly, this paper provides a common language for
research into security properties of enclaves. While side-channel
defenses have been proposed for SGX enclaves [55, 68, 69], the lack
of formalization of the enclave’s execution, attacker’s operations
and observations, and the desired confidentiality property makes it
infeasible to systematically compare two defenses.
7.3 Limitations
7.3.1 Limitations of the TAP. The TAP does not model the full
space of systems for which enclaves are relevant. Instead, it focuses
on enclave platforms that provide memory-based isolation. The
TAP’s current adversary model assumes platform memory (DRAM)
is trusted: memory can only be modified via software. Extending
the adversary model beyond this to include, for example, memory
probing/DMA attacks would require augmenting the TAP’s mem-
ory operations (fetch/load/store) with encryption and integrity
protection. The TAP also does not support demand paging as a naïve
implementation is vulnerable to the pigeonhole attack [69, 83]. One
path towards confidentiality-preserving demand paging in the TAP
would be to use an oblivious-RAM protocol.
The TAP model and proofs are currently limited to concurrent
execution on a single-threaded single-core processor. A fully gen-
eral proof showing that the TAP ensures SRE on multicore sys-
tems would require parameterized verification of these proper-
ties for an unbounded number of cores, using for example, the
CMP method [18]. We would also need to show linearizability of
operations in the Sanctum/SGX models [31]. In this context, lin-
earizability means that each operation appears to be atomic and
there exists an ordering of operations across all cores that is consis-
tent with their sequential orders of completion in individual cores.
Linearizability of a model of SGX was shown by Leslie-Hurd et
al. [39]. Extending the TAP to model security of simultaneously
multithreaded (SMT) processors would require modeling many
more side channels (e.g., branch predictors, shared resources such
as instruction queues and function units) and the development of
architectural mechanisms that prevent leakage through these side
channels.
Finally, the TAP does not model the cryptography in the attesta-
tion operation. Instead, we model the hash function using uninter-
preted functions and assume the properties of collision resistance
and second pre-image resistance.
7.3.2 Limitations of the Sanctum/SGX Models. Our SGX model
does not include demand paging, memory encryption or memory
integrity protection and assumes correctness of SGX measurement.
Unlike the TAP, the Sanctum implementation’s measurement is not
computed on a single snapshot of state, but is instead updated in-
crementally during enclave creation. A proof that this incremental
measurement is identical to the TAP’s measurement is ongoing.
Like the TAP, our Sanctum model also uses uninterpreted functions
to model the cryptography in the measurement operation.
8 RELATED WORK
Secure Processors: There have been several commercial deploy-
ments of secure processors. ARM TrustZone [2] implements a se-
cure and normal mode of execution to effectively create a single
privileged enclave in an isolated address space. TPM+TXT [29] en-
ables attestation of the platform’s state, but includes all privileged
software layers in the trusted computing base. Most recently, Intel
SGX [3, 20, 32, 47] implements unprivileged enclaves protecting
the integrity of memory and enclave state against software adver-
saries and certain physical access attacks. Academic work seeking
to improve the security of aspects of conventional processors is
also abundant [25, 43, 44].
Several clean-slate academic projects have been seeking to build
a trusted system. The XOM [42] architecture introduced the concept
of isolated software containers managed by untrusted host software,
and employed encryption and HMAC to protect DRAM. Aegis [76]
showed how a security kernel could measure and sign enclaves,
and employed counter-mode memory encryption and a Merkle tree
to guarantee freshness of data in DRAM. Bastion [16] encrypts
and HMACs DRAM and employs a trusted (and authenticated as
part of remote attestation) hypervisor which is invoked at each
TLB miss to check address translation against a policy. Fides [74]
uses a small trusted hypervisor to provide security guarantees for
so-called protected modules; protected modules offer very similar
programming abstractions and security guarantees as enclaves.
Sancus [54] builds upon Fides, and proposes hardware extensions
that ensure security of protected modules in the context of resource-
constrained embedded processors. Ascend [27] and Phantom [46]
ensure privacy and integrity of all CPU memory accesses through
a hardware ORAM primitive.
Attacks on Secure Processors: Secure systems often expose com-
plex threat models in practice, leading to vulnerabilities in the
application layers. Side channel observations, such as attacks ob-
serving cache timing, are known to compromise cryptographic keys
used by numerous cryptosystems [11, 14, 15, 37]. Attacks exploiting
other shared resources exist as well, such as those observing a core’s
branch history buffers [38]. These attacks are viable at any privilege,
separated by arbitrary protection boundaries [34, 45, 56]. Similar
13
attacks apply on trusted hardware, as shown on SGX with attacks
observing shared caches [12, 49, 66], and shared page tables [69, 83].
Formal Models/Verification of Enclave Platforms: A formal
cryptographic model of SGX’s anonymous attestation scheme is
presented in [58]. Barbosa et al. [6] present a formal analysis of
cryptographic protocols for secure outsourced computation using
enclave platforms. In contrast to these efforts, which reason about
cryptographic protocols in the context of enclaves, our work for-
malizes the security guarantees of enclave platforms themselves.
Patrignani et al. [60, 61] develop abstract trace semantics for low-
level code (not including side-channels) on protected module archi-
tectures – Fides [74] and Sancus [54] – in order to build secure com-
pilers for these platforms [59]. This is complementary to our work
which focuses on formalizing the security guarantees of enclave
platforms in presence of a precisely modelled adversary (including
side-channel observations).
While our work analyzes models of enclave platforms, verify-
ing actual implementations remains an important challenge. One
aspect of this was studied by Leslie-Hurd et al. [39]. They verified
linearizability of concurrent updates to shared SGX data structures.
Non-Interference and Hyperproperties: The security proper-
ties of secure measurement, integrity, and confidentiality are for-
mulated as 2-safety observational determinism properties [48, 62],
which is a restricted class of hyperproperties [19]. SRE relates
closely to the notion of non-interference introduced by Goguen and
Meseguer [28], and separability proposed by Rushby [63]. Our con-
fidentiality definition is an adaptation of standard non-interference
to the enclave execution model. Separability provides isolation from
other programs on the system, but it is too strict for practical appli-
cations as it forbids communication between programs and assumes
the absence of covert channels; it also does not consider privileged
software adversaries as the formalism assumes a safe underlying
hardware-software system.
Security Type Systems: A large body of work has studied type sys-
tems that enforce information-flow security [17, 22, 65, 73, 80]. Re-
cent examples for hardware design are [40, 41, 85]. SecVerilog [85]
extends the Verilog hardware description language with dependent
type annotations that define a security policy statically verified by
the SecVerilog compiler. One could conceivably implement SGX
or Sanctum processors using SecVerilog, thus guaranteeing the
implementation does not have unsafe information flow. However,
these techniques reason about the security policy at the level of
individual signals in the hardware. A higher level of abstraction
(like TAP) is needed for reasoning about enclave software. Soft-
ware fault isolation prevents an untrusted software module from
arbitrarily tampering the system’s state, and instead restrict all com-
munication to occur via a narrow interface. RockSalt [50] uses Coq
to reason about an x86 processor model and guarantee software
fault isolation of an untrusted module.
Machine-Checked Proofs of Systems: We perform machine-
checked proofs in this work, and similar efforts have verified other
classes of systems. The seL4 project [36, 51] proves isolation and
information flow enforcement in the seL4 microkernel using the
Isabelle/HOL proof assistant [53]. The Ironclad project [30] built a
fully verified software stack (including an OS, device drivers, and
cryptographic libraries) from the ground-up. The miTLS project [10]
is building a verified reference implementation of TLS which com-
plements our work nicely — enclaves indubitably require TLS
channels to communicate with other enclaves and clients. Vija-
yaraghavan et al. [79] used the Coq proof assistant [9] to verify
correctness of a multiprocessor directory-based cache coherence
protocol. While our Boogie [7, 24] proofs do involve manual effort,
we contend that they are more automated than their hypothetical
counterparts in systems such as Isabelle and Coq.
9 CONCLUSION
This paper introduced a framework and methodology to reason
about the security guarantees provided by enclave platforms. We
introduced the Trusted Abstract Platform (TAP), and performed
proofs demonstrating that TAP satisfies the three properties re-
quired for secure remote execution (SRE): secure measurement,
integrity and confidentiality. We then presented machine-checked
proofs stating that models of Intel SGX and Sanctum are refine-
ments of TAP under certain adversarial conditions. Therefore, these
platforms also satisfy the properties required for SRE. Overall, this
paper took a step towards a unified, extensible framework for rea-
soning about enclave programs and platforms.
ACKNOWLEDGMENTS
Funding for this research was partially provided by the National Sci-
ence Foundation under grants CNS-1413920 and CNS-1528108, by
the Intel ADEPT Center, by Delta Electronics, and by TerraSwarm,
one of six centers of STARnet, a Semiconductor Research Corpora-
tion program sponsored by MARCO and DARPA.
REFERENCES
[1] Lenovo ThinkPad System Management Mode Arbitrary Code Execution 0day
Exploit. Available at https://github.com/Cr4sh/ThinkPwn.git.
[2] T. Alves and D. Felton. TrustZone: Integrated Hardware and Software Security.
Information Quarterly, 3(4):18–24, 2004.
[3] I. Anati, S. Gueron, S. P. Johnson, and V. R. Scarlata. Innovative Technology
for CPU Based Attestation and Sealing. In Proceedings of the 2nd International
Workshop on Hardware and Architectural Support for Security and Privacy, HASP,
volume 13, 2013.
[4] K. Asanovic, R. Avizienis, J. Bachrach, S. Beamer, D. Biancolin, C. Celio, H. Cook,
D. Dabbelt, J. Hauser, A. Izraelevitz, et al. The Rocket Chip Generator. EECS
Department, University of California, Berkeley, Tech. Rep. UCB/EECS-2016-17, 2016.
[5] K. Asanović and D. A. Patterson. Instruction Sets Should Be Free: The Case For
RISC-V. EECS Department, University of California, Berkeley, Tech. Rep. UCB/EECS-
2014-146, 2014.
[6] M. Barbosa, B. Portela, G. Scerri, and B. Warinschi. Foundations of Hardware-
Based Attested Computation and Application to SGX. In IEEE European Sympo-
sium on Security and Privacy, EuroS&P 2016, Saarbrücken, Germany, March 21-24,
2016, pages 245–260, 2016.
[7] M. Barnett, B. E. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A
Modular Reusable Verifier for Object-Oriented Programs. In FMCO ’05, LNCS
4111, pages 364–387, 2005.
[8] G. Barthe, P. R. D’Argenio, and T. Rezk. Secure information flow by self-
composition. Mathematical Structures in Computer Science, 21(6):1207–1252,
2011.
[9] Y. Bertot and P. Castéran. Interactive Theorem Proving and Program Development:
Coq’Art: The Calculus of Inductive Constructions. Springer Science & Business
Media, 2013.
[10] K. Bhargavan, C. Fournet, and M. Kohlweiss. miTLS: Verifying Protocol Imple-
mentations against Real-World Attacks. IEEE Security & Privacy, 14(6):18–25,
2016.
[11] J. Bonneau and I. Mironov. Cache-Collision Timing Attacks Against AES, pages
[12] F. Brasser, U. Müller, A. Dmitrienko, K. Kostiainen, S. Capkun, and A. Sadeghi. Soft-
ware Grand Exposure: SGX Cache Attacks Are Practical. CoRR, abs/1702.07521,
2017.
201–215. Springer Berlin Heidelberg, Berlin, Heidelberg, 2006.
14
[13] M. C. Browne, E. M. Clarke, and O. Grumberg. Characterizing Finite Kripke
Structures in Propositional Temporal Logic. Theoretical Computer Science, 59:115–
131, 1988.
[14] B. B. Brumley and N. Tuveri. Remote Timing Attacks Are Still Practical. In
Proceedings of the 16th European Conference on Research in Computer Security,
ESORICS’11, pages 355–371, Berlin, Heidelberg, 2011. Springer-Verlag.
[15] D. Brumley and D. Boneh. Remote Timing Attacks Are Practical. In Proceedings of
the 12th Conference on USENIX Security Symposium - Volume 12, SSYM’03, pages
1–1, Berkeley, CA, USA, 2003. USENIX Association.
[16] D. Champagne and R. B. Lee. Scalable architectural support for trusted software.
In High Performance Computer Architecture (HPCA), 2010 IEEE 16th International
Symposium on, pages 1–12. IEEE, 2010.
[17] A. Chaudhuri. Language-based security on Android. In Proceedings of the 2009
Workshop on Programming Languages and Analysis for Security, PLAS 2009, Dublin,
Ireland, 15-21 June, 2009, pages 1–7, 2009.
[18] C.-T. Chou, P. K. Mannava, and S. Park. A simple method for parameterized
verification of cache coherence protocols. In A. J. Hu and A. K. Martin, editors,
Proceedings of the 5th International Conference on Formal Methods in Computer-
Aided Design, pages 382–398, Berlin, Heidelberg, 2004. Springer Berlin Heidelberg.
[19] M. R. Clarkson and F. B. Schneider. Hyperproperties. Journal of Computer Security,
18(6):1157–1210, Sept. 2010.
[20] V. Costan and S. Devadas. Intel SGX Explained. Cryptology ePrint Archive,
Report 2016/086, 2016. http://eprint.iacr.org/2016/086.
Press, 2009.
[21] V. Costan, I. Lebedev, and S. Devadas. Sanctum: Minimal Hardware Extensions
In 25th USENIX Security Symposium (USENIX
for Strong Software Isolation.
Security 16), pages 857–874, Austin, TX, 2016. USENIX Association.
[22] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A Logic of Secure Systems and
Its Application to Trusted Computing.
In Proceedings of the 2009 30th IEEE
Symposium on Security and Privacy, SP ’09, pages 221–236, Washington, DC, USA,
2009. IEEE Computer Society.
[23] L. de Moura and N. Bjørner. Z3: An Efficient SMT Solver. In TACAS ’08, pages
[24] R. DeLine and K. R. M. Leino. BoogiePL: A typed procedural language for checking
object-oriented programs. Technical Report MSR-TR-2005-70, Microsoft Research,
2005.
337–340, 2008.
[25] L. Domnitser, A. Jaleel, J. Loew, N. Abu-Ghazaleh, and D. Ponomarev. Non-
monopolizable caches: Low-complexity mitigation of cache side channel attacks.
Transactions on Architecture and Code Optimization (TACO), 2012.