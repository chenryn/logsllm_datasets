title:Membership Inference Attacks Against Recommender Systems
author:Minxing Zhang and
Zhaochun Ren and
Zihan Wang and
Pengjie Ren and
Zhumin Chen and
Pengfei Hu and
Yang Zhang
Membership Inference Attacks Against Recommender Systems
Minxing Zhang1,2∗ Zhaochun Ren1∗† Zihan Wang1∗ Pengjie Ren1
Zhumin Chen1 Pengfei Hu1 Yang Zhang2†
1Shandong University 2CISPA Helmholtz Center for Information Security
ABSTRACT
Recently, recommender systems have achieved promising perfor-
mances and become one of the most widely used web applications.
However, recommender systems are often trained on highly sen-
sitive user data, thus potential data leakage from recommender
systems may lead to severe privacy problems.
In this paper, we make the first attempt on quantifying the pri-
vacy leakage of recommender systems through the lens of member-
ship inference. In contrast with traditional membership inference
against machine learning classifiers, our attack faces two main dif-
ferences. First, our attack is on the user-level but not on the data
sample-level. Second, the adversary can only observe the ordered
recommended items from a recommender system instead of pre-
diction results in the form of posterior probabilities. To address
the above challenges, we propose a novel method by representing
users from relevant items. Moreover, a shadow recommender is
established to derive the labeled training data for training the at-
tack model. Extensive experimental results show that our attack
framework achieves a strong performance. In addition, we design a
defense mechanism to effectively mitigate the membership infer-
ence threat of recommender systems.1
CCS CONCEPTS
• Information systems → Recommender systems; • Security
and privacy;
KEYWORDS
membership inference attack, recommender system, membership
leakage
ACM Reference Format:
Minxing Zhang, Zhaochun Ren, Zihan Wang, Pengjie Ren, Zhunmin Chen,
Pengfei Hu, Yang Zhang. 2021. Membership Inference Attacks Against
Recommender Systems. In Proceedings of the 2021 ACM SIGSAC Conference
on Computer and Communications Security (CCS ’21), November 15–19, 2021,
Virtual Event, Republic of Korea. ACM, New York, NY, USA, 16 pages. https:
//doi.org/10.1145/3460120.3484770
∗These authors contributed equally to this work.
†Corresponding author.
1Our code is available at https://github.com/minxingzhang/MIARS.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.
© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484770
Figure 1: An example of recommender systems.
1 INTRODUCTION
As one of the most prevalent services in current web applications,
recommender systems have been applied in various scenarios, such
as online shopping, video sharing, location recommendation, etc. A
recommender system is essentially an information filtering system,
relying on machine learning algorithms to predict user preferences
for items. One mainstream method in this space is collaborative
filtering, which is based on traditional methods such as matrix
factorization and latent factor model, predicting a user’s prefer-
ence from their historical behaviors combined with other users’
similar decisions [19, 41]. Another is the content-based recom-
mendation [35, 51]. This approach aims to distinguish users’ likes
from dislikes based on their metadata (such as descriptions of the
items and profiles of the users’ preferences). Recent advancement
of deep learning techniques further boosts the performance of rec-
ommender systems [16].
The success of recommender systems lies in the large-scale user
data. However, the data in many cases contains sensitive informa-
tion of individuals, such as shopping preference, social relation-
ship [1], and location information [44]. Recently, various research
has shown that machine learning models, represented by machine
learning classifiers, are prone to privacy attacks [6, 8, 10, 18, 22, 28–
32, 34, 37, 39, 43, 45]. However, the privacy risks stemming from
recommender systems have been left largely unexplored.
1.1 Our Contributions
In this paper, we take the first step quantifying the privacy risks
of recommender systems through the lens of membership infer-
ence. Compared to previous membership inference attacks against
machine learning classifiers [39, 43], our attack faces two main
differences. First, the goal of our attack is to determine whether
a user’s data is used by the target recommender. This indicates
our attack is on the user-level while most of the previous attacks
focus on the sample-level [39, 43]. Unlike sample-level membership
inference, user-level membership inference has a broader scope
as mentioned in previous works [45], and it can help us gain a
comprehensive understanding of recommender systems’ privacy
risks. Second, from the adversary’s perspective, only ranking lists
RecommenderSystemPosterior ProbabilityBlack BoxRecommendationsHistoricalBehaviorsObservableUserSession 3C: Inference Attacks CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea864of items are available from the target recommender which raises
several technical challenges:
• In our attack, as Figure 1 depicts, the adversary can only
observe lists of items, even though recommender systems
have already calculated posterior probabilities before mak-
ing decisions. This setting is prevalent in the real world, such
as the service provided by Amazon or Netflix. Besides, ex-
posing less information can protect the intellectual property
of recommendation service providers [39]. On the contrary,
in classical membership inference attacks against classifiers,
posterior probabilities used for decisions can be accessed by
the adversary [31, 37, 39, 43].
• Several recent membership inference attacks against classi-
fiers focus on the decision-only (i.e., label-only) scenario [10,
28]. However, these studies either rely on the target model to
label a shadow dataset [28] or use adversarial examples [10,
28], which are not practical when targeting recommender
systems in the real world. Therefore, we aim for a new
method to extract information from decision results for the
attack model.
• Unlike classical classifiers, the outputs of recommender sys-
tems are ranking lists of items other than unordered labels.
In that case, the order information plays an important role,
and can substantially facilitate user preference predictions.
Therefore, it is necessary for our attack model to capture
order information from recommended items, which is still
ignored by previous membership inference attack methods.
Threat Model. The goal of the adversary is to conduct a mem-
bership inference attack against the target recommender system,
inferring whether a target user’s data is used to train the target
recommender or not. However, such attacks can lead to severe se-
curity and privacy risks. Specifically, when a recommender system
is trained with data from people with certain sensitive information,
such as health status, knowing a user’s data being part of the rec-
ommender’s training data directly leaks their private information.
Moreover, membership inference also gains the adversary infor-
mation about the target recommender’s training data, which may
jeopardize the recommender’s intellectual property, since collecting
high-quality data often requires a large amount of efforts [18, 27].
From a different angle, a user can also use membership inference as
a tool to audit whether their data is used by the target recommender.
We assume the adversary has black-box access to the target rec-
ommender, the most difficult setting for the adversary [43]. Instead
of posterior probabilities for recommendations, only relevant items
for users are available, such as rating or purchase and recommended
items. Due to the knowledge, a shadow recommender is established
to derive labeled training data, for the attack model better inferring
membership status in the target recommender.
Attack Method. For user-level membership inference, we need
to summarize each user’s feature vector, based on interactions be-
tween the target recommender and them, as the input to the attack
model. However, compared to the previous work of membership
inference against classifiers, the adversary can only observe the
recommended items from a recommender system instead of poste-
rior probabilities as prediction results. Thus, in the first step, the
adversary constructs a user-item matrix for ratings with a dataset
used to generate feature vectors. Then, they factorize this matrix
into two low-dimensional matrices, namely user matrix and item
matrix. Each item’s feature vector can be represented by the corre-
sponding row vector in the item matrix. For each user, the adversary
extracts two sets of items (one set contains items the user is rec-
ommended and the other contains the items the user interacted
with) and calculates these two sets’ center vectors, respectively. The
difference between these two center vectors for each user describes
how accurate the recommender is for this user. In that case, lower
difference indicates a user’s data is more likely to be used to train
the recommender. Therefore, we use this difference as the input to
the attack model, i.e., user feature vector. The adversary generates
all the labeled training dataset for their attack model with the help
of the shadow recommender. To launch the attack, the adversary
generates the target user’s feature vector following the same steps
and obtains the prediction from the attack model.
Evaluation. To evaluate our attack, the adversary is assumed
to have a shadow dataset that comes from the same distribution
as the target recommender’s training data, and know the target
recommender’s algorithm. These assumptions are gradually relaxed
based on our empirical evaluation.
Our experiments are performed on three benchmark recommen-
dation datasets, i.e., the Amazon Digital Music (ADM) [15], Lastfm-
2k (lf-2k) [4], and Movielens-1m (ml-1m) [13]. The recommendation
algorithms we focus on include Item-Based Collaborative Filtering
(Item), Latent Factor Model (LFM), and Neural Collaborative Filter-
ing (NCF). Evaluation results demonstrate that our attack is able to
achieve an excellent performance.
• In general, when the adversary knows the distribution of
the target dataset and the target recommender’s algorithm,
the attack performance is extremely strong. For instance,
when the target recommender uses NCF on the ADM dataset,
our attack achieves an AUC of 0.987. Also, when the target
algorithm is Item or NCF, our attack achieves better perfor-
mances.
• When the adversary is not aware of the target recommender’s
algorithm, attack performances are reduced but still strong.
For instance, on the lf-2k dataset, when the target recom-
mender uses Item and the shadow recommender uses NCF,
the attack performance decreases from an AUC of 0.929 to
an AUC of 0.827. On the other hand, in some cases, the at-
tack performances even increase. For instance, on the ml-1m
dataset, when the target recommender uses Item and the
shadow recommender uses LFM, the attack’s AUC increases
from 0.871 to 0.931.
• We further relax the assumption of the shadow dataset. Eval-
uation shows that even under such a scenario, our attack still
achieves good performances in general. Note that, in some
cases, when the adversary knows less about the target recom-
mender, the attack even performs better. This demonstrates
the good generalization ability of our attack.
In conclusion, the experimental results show the effectiveness of our
attack, indicating that recommender systems are indeed vulnerable
to privacy attacks.
Session 3C: Inference Attacks CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea865Defense. To mitigate the recommender’s privacy risk, we propose
a defense mechanism, namely Popularity Randomization. Popu-
larity Randomization is deployed when the target recommender
recommends items to its non-member users. The normal strategy
in such case is to provide non-member users with the most popular
items. However, to defend the attack, we enlarge the set of popular
items, and randomly select a subset of them for recommendation.
Intuitively, while preserving the recommendation performance for
non-member users, this approach enriches the randomness of the
recommendation.
Experimental results show that Popularity Randomization can
effectively mitigate membership inference. For instance, Popularity
Randomization (with a 0.1 ratio of recommendations to candidates)
decreases the attack performances by more than 12%, 33%, and
41% when the target algorithm is Item, LFM or NCF respectively.
Through analyses, we observe that Popularity Randomization has
the greatest impact on the attack targeting on NCF.
2 METHOD
In this section, we first present some necessary definitions in Sec-
tion 2.1, and then introduce the threat model for the membership
inference attack against recommender systems in Section 2.2. Next,
we give overviews for recommender systems in Section 2.3 and
our attack model in Section 2.4. Finally, we detail the proposed
membership inference attack methods in Section 2.5.
2.1 Definitions
We present the following definitions for the attack process:
the recommender system attacked by the adversary.
• Target Recommender, trained on the Target Dataset, is
• Shadow Recommender, trained on the Shadow Dataset,
is a recommender system built to infer the membership status
of the target recommender and generate training data for
the attack model.
• Members are the users whose data is used to train the rec-
ommender, while Non-Members are the ones whose data
is not used.
• Personalized Recommendation Algorithms learn mem-
bers’ preferences from historical behaviors (such as pur-
chases or ratings), which are also called Interactions. Non-
Personalized Recommendation Algorithms are based
on the predetermined rule, such as selecting the most popu-
lar or highest-rated items. According to different recommen-
dation methods, members and non-members are provided
with recommended items, which are also called Recommen-
dations.
• Feature Vectors show the latent features, indicating item
• Attack Model is used to infer whether the target user is
a member, and trained on the dataset generated from the
shadow recommender.
attributes or user preferences.
their private information. Besides, knowing a user being part of the
dataset can also allow the adversary to gain extra information of the
target recommender’s dataset. This directly violates the intellectual
property of the target recommender, since it is very expensive
to collect high-quality training data. Alternatively, membership
inference can also be used as an auditing tool by a user to find out