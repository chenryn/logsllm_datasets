但是，重要的是要注意，你可以（并且应该）进一步考虑单词在单个训练数据实例之外的情形，这称为   词频    term frequency （TF）。你还应该考虑输入数据在所有训练实例中的单词计数，通常，出现在所有文档中的低频词更重要，这被称为   逆文本频率指数    inverse document frequency （IDF）。这些指标一定会在本主题系列的其他文章和软件包中提及，因此了解它们会有所帮助。
词袋在许多文档分类应用程序中很有用。然而，在情感分析中，当缺乏情境意识的问题被利用时，事情就可以解决。考虑以下句子：
* 我们不喜欢这场战争。
* 我讨厌下雨天，好事是今天是晴天。
* 这不是生死攸关的问题。
这些短语的情感对于人类口译员来说是有难度的，而且通过严格关注单个词汇的实例，对于机器翻译来说也是困难的。
在 NLP 中也可以使用称为 “n-grams” 的单词分组。一个二元组考虑两个相邻单词组成的组而不是（或除了）单个词袋。这应该可以缓解诸如上述“不喜欢”之类的情况，但由于缺乏语境意思，它仍然是个问题。此外，在上面的第二句中，下半句的情感语境可以被理解为否定前半部分。因此，这种方法中也会丢失上下文线索的空间局部性。从实用角度来看，使问题复杂化的是从给定输入文本中提取的特征的稀疏性。对于一个完整的大型词汇表，每个单词都有一个计数，可以将其视为一个整数向量。大多数文档的向量中都有大量的零计数向量，这给操作增加了不必要的空间和时间复杂度。虽然已经提出了许多用于降低这种复杂性的简便方法，但它仍然是一个问题。
### 词嵌入
 词嵌入   Word embedding 是一种分布式表示，它允许具有相似含义的单词具有相似的表示。这是基于使用实值向量来与它们周围相关联。重点在于使用单词的方式，而不仅仅是它们的存在与否。此外，词嵌入的一个巨大实用优势是它们关注于密集向量。通过摆脱具有相应数量的零值向量元素的单词计数模型，词嵌入在时间和存储方面提供了一个更有效的计算范例。
以下是两个优秀的词嵌入方法。
#### Word2vec
第一个是 [Word2vec](https://en.wikipedia.org/wiki/Word2vec)，它是由 Google 开发的。随着你对 NLP 和情绪分析研究的深入，你可能会看到这种嵌入方法。它要么使用一个 连续的词袋   continuous bag of words （CBOW），要么使用一个连续 skip-gram 模型。在 CBOW 中，一个单词的上下文是在训练中根据围绕它的单词来学习的。连续 skip-gram 学习倾向于围绕给定的单词学习单词。虽然这可能超出了你需要解决的问题，但是如果你曾经面对必须生成自己的词嵌入情况，那么 Word2vec 的作者就提倡使用 CBOW 方法来提高速度并评估频繁的单词，而 skip-gram 方法更适合嵌入稀有单词更重要的嵌入。
#### GloVe
第二个是   用于词表示的全局向量    Global Vectors for Word Representation （GloVe），它是斯坦福大学开发的。它是 Word2vec 方法的扩展，试图通过将经典的全局文本统计特征提取获得的信息与 Word2vec 确定的本地上下文信息相结合。实际上，在一些应用程序中，GloVe 性能优于 Word2vec，而在另一些应用程序中则不如 Word2vec。最终，用于词嵌入的目标数据集将决定哪种方法最优。因此，最好了解它们的存在性和高级机制，因为你很可能会遇到它们。
#### 创建和使用词嵌入
最后，知道如何获得词嵌入是有用的。在第 2 部分中，你将看到我们通过利用社区中其他人的实质性工作，站到了巨人的肩膀上。这是获取词嵌入的一种方法：即使用现有的经过训练和验证的模型。实际上，有无数的模型适用于英语和其他语言，一定会有一种模型可以满足你的应用程序，让你开箱即用！
如果没有的话，就开发工作而言，另一个极端是培训你自己的独立模型，而不考虑你的应用程序。实质上，你将获得大量标记的训练数据，并可能使用上述方法之一来训练模型。即使这样，你仍然只是在理解你输入文本数据。然后，你需要为你应用程序开发一个特定的模型（例如，分析软件版本控制消息中的情感价值），这反过来又需要自己的时间和精力。
你还可以对针对你的应用程序的数据训练一个词嵌入，虽然这可以减少时间和精力，但这个词嵌入将是特定于应用程序的，这将会降低它的可重用性。
### 可用的工具选项
考虑到所需的大量时间和计算能力，你可能想知道如何才能找到解决问题的方法。的确，开发可靠模型的复杂性可能令人望而生畏。但是，有一个好消息：已经有许多经过验证的模型、工具和软件库可以为我们提供所需的大部分内容。我们将重点关注 [Python](https://www.python.org/)，因为它为这些应用程序提供了大量方便的工具。
#### SpaCy
[SpaCy](https://pypi.org/project/spacy/) 提供了许多用于解析输入文本数据和提取特征的语言模型。它经过了高度优化，并被誉为同类中最快的库。最棒的是，它是开源的！SpaCy 会执行标识化、词性分类和依赖项注释。它包含了用于执行此功能的词嵌入模型，还有用于为超过 46 种语言的其他特征提取操作。在本系列的第二篇文章中，你将看到它如何用于文本分析和特征提取。
#### vaderSentiment
[vaderSentiment](https://pypi.org/project/vaderSentiment/) 包提供了积极、消极和中性情绪的衡量标准。正如 [原论文](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) 的标题（《VADER：一个基于规则的社交媒体文本情感分析模型》）所示，这些模型是专门为社交媒体文本数据开发和调整的。VADER 接受了一组完整的人类标记过的数据的训练，包括常见的表情符号、UTF-8 编码的表情符号以及口语术语和缩写（例如 meh、lol、sux）。
对于给定的输入文本数据，vaderSentiment 返回一个极性分数百分比的三元组。它还提供了一个单个的评分标准，称为 *vaderSentiment 复合指标*。这是一个在 `[-1, 1]` 范围内的实值，其中对于分值大于 `0.05` 的情绪被认为是积极的，对于分值小于 `-0.05` 的被认为是消极的，否则为中性。
在[第 2 部分](https://opensource.com/article/19/4/social-media-sentiment-analysis-python-part-2)中，你将学习如何使用这些工具为你的设计添加情感分析功能。
---
via: 
作者：[Michael McCune](https://opensource.com/users/elmiko/users/jschlessman)  选题：[lujun9972](https://github.com/lujun9972) 译者：[MjSeven](https://github.com/MjSeven) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出