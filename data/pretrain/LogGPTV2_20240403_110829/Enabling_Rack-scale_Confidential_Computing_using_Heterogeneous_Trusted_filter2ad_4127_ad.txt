(cid:348)   USERcert, SIGUSERPrivAK(Ga,Gb), 
MACSMKm(USERcert)
Verify MACSMKm(USERcert)
Verify User
Fig. 4. Remote Attestation and Symmetric Key Negotiation Protocol.
(Each HETEE platform includes two sets of public key pairs,
an Endorsement Key (EK) and an Attestation Key (AK) (see
Sec. III-E). The SCcert contains the SC measurement and is
signed using the EK private key. The enclave measurement
is signed with the AK private key. The trust of AK and EK
is derived from the certificate chain generated from the
HETEE vendor’s root key and can be verified by the user.
EM: enclave measurement; KDF: Key Derivation Function;
MAC: Message Authentication Code; mSalt and sSalt are
cryptographic random numbers; Ga, Gb and Gab are used for
the Diffie-Hellman key exchange. USERcert is the user’s
public key certificate.)
The HETEE attestation protocol is shown in Fig. 4. Mes-
sage x and message y implement Difﬁe-Hellman key ex-
change. Message y is used by the HETEE platform to send
its certiﬁcates and report measurements to the remote user
for identiﬁcation and authentication. It also carries a message
authentication code MACSMKm(SCcert) for the remote user to
check its integrity. Similarly, message z is for the remote
user to send her certiﬁcate to the HETEE platform, which
also includes MACSMKm(USERcert) for integrity check.
Similar to other TEE techniques (such as Privacy CA
of TCG [103], [115], Sanctum [65], [66], Graviton [15],
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:57:53 UTC from IEEE Xplore.  Restrictions apply. 
1456
SecTEE [117] and Keystone [64], [114]), the proposed attes-
tation protocol requires trusted CA for secure certiﬁcate dis-
tribution. Intel SGX adopts Enhanced Privacy ID (EPID) [93],
an enhancement of the Direct Anonymous Attestation (DAA)
algorithm [116], which does not need trusted CA but still relies
on a trusted party (i.e., Intel) as the Issuer for key distribution.
Our current design assumes that certiﬁcate distribution of
the attestation protocol is secure. Prior research shows that
both CA-based and EPID-based protocols are vulnerable to
the Cuckoo attack [118] in which the adversary relays the
attestation messages to a TEE under his physical control.
The attestation of the HETEE box is implemented on SC,
which is included in our TCB and protected from physical
attacks for controlling the box (see Sec.VII). Also, solutions
have been proposed for mitigating the threat of the Cuckoo
attack [119], [120], which could be incorporated into our
attestation protocol.
E. Key Management in SC
Endorsement Key (EK) and Attestation Key (AK) for
each HETEE platform. Each HETEE platform includes two
sets of public key pairs, an Endorsement Key (EK) and an
Attestation Key (AK). These keys are the basis to authenticate
the platform, and will never leave the FPGA chip at any time.
The private key of EK and the EK certiﬁcate are encoded by
the vendor into the encrypted FPGA bitstream. The EK is only
used by a dedicated signing logic to sign the AK and the SC
measurement for creating an AK certiﬁcate. The AK is derived
from the random number generator module on the FPGA each
time it is powered up, and the private key of the AK and the
AK certiﬁcate can only be accessed by a dedicated attestation
logic module which is speciﬁcally used to sign Difﬁe-Hellman
parameters and enclave measurements, for remote attestation
and authentication. The EK is only used when generating the
AK certiﬁcate, and all credentials for remote attestation are
generated using the AK. This certiﬁcate chain design limits
the usage of the EK, thereby reducing the risk of its exposure,
since the key is the root of trust for the platform.
Two sets of symmetric keys for each User. SMKm and
SMKs are generated during remote attestation. The SMKm is
used for integrity check with MAC (message authentication
code) during remote attestation. The SMKs is used to build
the secure channel between the user and the HETEE box.
Symmetric key for hard disk. The SMKdisk is used for
data protection inside the HETEE box. That is to say, all the
data on the internal disks of the HETEE box are encrypted.
The (de)encryption engine locates in the disk controller. Note
that commercial SSD controllers usually have such an engine
for line-speed data protection. The SC FPGA generates the
SMKdisk and sends it to the disk controller. The key is not
stored on the disk by the disk controller, and instead is thrown
away when the system is power off for data protection.
F. Sealing, Management and Maintenance of HETEE Box
Sealing. The chassis of the HETEE box is designed to be
tamper-resistant, based upon the techniques used by proven
products [97], [104], [105], [108], which can meet the NIST
FIPS 140-2 security Level 3 or 4 [106], [107]. A typical imple-
mentation includes a microcontroller (MCU) system and a set
of sensors (e.g., pressure, vibration and temperature etc) for
access control management and intrusion detection/response.
The HETEE box provides a USB interface for authentication
based on the USB key. When the chassis is opened without
authorization, the pressure sensor notiﬁes the MCU. Then the
MCU actively empties the bitstream located in the FPGA-
connected ﬂash chip and power down the entire system.
When powered up again, the FPGA’s security boot mechanism
detects such exception through veriﬁcation, even when the
attacker replaces the bitstream. In this case, the FPGA module
will stop booting. The attacker cannot get sensitive content
from the volatile memory, and nor can he touch the content of
the encrypted data on the disk since the disk key is destroyed.
The HETEE box can be sealed by the system vendor, just
like HSM devices, when the data center is not trusted with
the data it processes. Alternatively, this can be done by the
authorized party in the data center, to prevent the access from
unauthorized members and mitigate insider risks.
Maintenance. If the HETEE box has a hardware failure
or needs to upgrade its software (e.g., ﬁrmware on SC, AI
runtime and Linux on proxy node, as well as GPU ﬁrmware),
an authorized administrator can open the chassis properly for
maintenance using the USB key. Here the administrator can be
the vendor of the HETEE box, or the third party such as the
authorized member in a data center who is allowed to access
the protected data. Anyone else even the cloud provider is not
permitted to open the chassis.
Cooling. The HETEE box uses a standard server blade chassis
enhanced with protection against unauthorized access (as de-
scribed before), which supports high-performance server level
cooling mechanisms, such as air channel design, front/rear
thermal vent, fans with speed control, air or water cooling,
which are common to the server system. This enables the
HETEE box to be easily deployed in data center.
IV. HETEE PROTOTYPE SYSTEM
PEX9797 
Chips
GTX TITAN X GPUs
(a) PCIe ExpressFabric backplane
(b) HETEE Box 
Fig. 5. HETEE prototype system.
X86 CPU board
FPGA co-processor
(C) Security Controller
Node 1
Node 0
(d) Proxy Nodes
HETEE BOX
HETEE API
HETEE A
Dog & Cat
Dog & Cat
Node 
Server
SC
Dog 
& 
Cat
AI runtime(Infer & Train Engine)
)
TensorFlow/Pytorch/MXNet...
CUDA
GPU Driver
Proxy Node
Proxy Node
GPU
Fig. 6. Conﬁdential AI service provided by HETEE system.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:57:53 UTC from IEEE Xplore.  Restrictions apply. 
1457
The HETEE prototype is shown in Fig. 5. The HETEE box
(Fig. 5(b)) uses two Broadcom PEX9797 chips to build the
PCIe ExpressFabric backplane shown in Fig. 5(a), which has
15 PCIe slots. As an industry-leading ExpressFabric platform,
the PEX9700 series switch chips provide high performance,
low latency, and scalable and cost-effective connections based
on the PCIe Gen3 protocol. They also provide the ability to
share I/Os, and to enable multiple hosts on a single PCIe-based
network using standard PCIe enumerations. PEX9797 has the
top I/O capabilities in its series [25].
The current HETEE box includes 1 SC node, 4 proxy
nodes, and 4 Nvidia GTX TITAN X GPUs. Both the SC and
the proxy nodes are implemented as custom boards shown
in Fig. 5(c)(d), each of which is an independent system. These
boards and GPU cards are plugged into the PCIe slots of the
PCIe Fabric backplane. These nodes can communicate through
either Tunneling Window Connection (TWC) or ethernet-like
DMA as standard hosts and/or end-points.
TABLE I
HETEE PROTOTYPE SYSTEM.
Hardware
Software
Component
Security
Controller
Intel Xeon-E3 1220V6
DDR4 16GB 2400MHz
Xilinx Zynq FPGA
Tailored coreboot 4.10
with security management
code, binary size is < 300KB
Proxy
Node
Intel Xeon-E3 1220V6
DDR4 16GB 2400MHz
GPU
PCIe Fabric
Nvidia GTX TITAN
PEX9797
TensorFlow 1.11.0
CUDA 9.0
Nvidia Driver 396.54
CentOS 7.2
Table I describes the major components of the SC and the
proxy nodes. The SC includes an Intel Xeon-E3 CPU,
which runs the security management functions (conﬁgure PCIe
expressfabric chip) on the customitzed open-source ﬁrmware
(coreboot [87]) and an Xilinx Zynq FPGA card, which is
in charge of the remote attestation and (de)encryption. The
proxy node integrates an Intel Xeon-E3 CPU and runs a
complete GPU software stack and Tensorﬂow 1.11.0.
To accommodate the standard Nvidia GPU acceleration
card (3U height),
the HETEE box is currently a 4U and
half-length chassis. The height and length of the chassis
could be expanded to integrate more accelerators with more
PEX9797 switching chips. This prototype system does not
include tamper resistance functionality as we use it mainly
for performance evaluation in this study.
V. CONFIDENTIAL AI COMPUTING SERVICE
The HETEE system enables conﬁdentiality for applications
requiring privacy. Without losing generality, this paper shows
a case of safeguarding conﬁdential AI models for AI services
running on top of a pool of GPU resources as shown in
Fig. 6. We used the popular ONNX open format [35] to
describe AI models. With ONNX, AI developers can easily
move models from one state-of-the-art tool to another and
choose the combination that is best for a target application.
AI inference. For an inference task, the remote user ﬁrst
authenticates and exchanges keys with the HETEE box, estab-
lishing a trusted relationship and obtaining a shared symmetric
key for secure communication. The remote user encrypts the
AI model with the shared symmetric key and sends it to the
HETEE box. Upon receiving the encrypted AI model, the SC
decrypts it and sends it to the AI runtime (TensorFlow in
our prototype system) on the proxy node. The AI runtime
parses the model and starts the corresponding inference engine.
The remote user then can begin to send encrypted data to the
HETEE box in batches. The inference engine gets the data
from the SC which performs data decryption, and invokes the
corresponding GPU kernel to process the received data.
AI training. Similarly for a training task, after the user
authenticates and exchanges keys with the HETEE box it sends
in the initial neural network structure and also provides addi-
tional training-related conﬁgurations such as hyper-parameters
(such as learning rate, epoch, batch size, etc.) and selected
optimization algorithms (such as SGD, ADAM, etc.). After
receiving the message, the SC starts the AI runtime to build
the training engine. The remote user then begins to move a
stream of encrypted data to the HETEE box. The training
engine on the proxy node performs the forward pass, the
backward pass, and so on for each batch of received data, and
returns the current loss and part of the intermediate network
state to the remote user in the encrypted form. The return
values are evaluated by the remote user to determine the
convergence of the network. The training process continues
until the network converges or diverges. The remote user then
sends out a termination command to inform the training engine
that the training task is ﬁnished.
VI. EVALUATION
A. Methodology
AI workloads. We trained 5 classical neural networks on
ImageNet 2012 [53], which contains millions of images in
1000 categories. We used 138 GiB training images of Ima-
geNet 2012 as our training dataset, while 6 GiB of images
were used as validation dataset. Besides, the test data set for
inference included 13 GiB of images. The number of layers of
the tested networks ranged from 16 to 152, with the number
of parameters between 5 million and 138 million. Our choice
covered typical neural networks from small scale ones to large
ones, with 5 different batch sizes selected as network inputs for
each network. Table II summarizes the details of each model.
We ran the inference and training workloads on our HETEE
prototype described in Sec. IV.
Since the HETEE system only affects the communication
path and software stack partition,
it does not change the
existing algorithms. Therefore, the HETEE system does not
have any impact on the classiﬁcation accuracy,
thus our
experiments mainly focus on evaluation of the throughput and
latency, as well as the overhead of hardware modules such as
data encryption and decryption.
B. Performance analysis
Compared to a standard GPU server (X86 CPU + GPU),
the HETEE system provides conﬁdential computing services
while inducing longer message transfer paths, additional data
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:57:53 UTC from IEEE Xplore.  Restrictions apply. 
1458
TABLE II
AI WORKLOADS.
Model
VGG16 [54]
GoogLeNet [55]
ResNet50 [56]
ResNet101 [56]
ResNet152 [56]
Model
size
500 MiB
28 MiB
100 MiB
150 MiB
200 MiB
Para-
meters
138 M
5 M
25 M
44 M
60 M
Layers
16
22
50