Similarly, let V be a cred-based voting scheme that has the piecewise
tally property and non-malleable credentials. If V is private against a
dishonest board with careful voters, then V is individually verifiable
against a dishonest board with careful voters.
6 COMPARING PRIVACY
We compare different notions of privacy, with and without an
honest ballot box, on four standard protocols (Helios, Belenios,
Civitas, and Neuchâtel) as well as on our simple protocol, sketched
in introduction.
To our knowledge, the only other definition of privacy with a
dishonest ballot box is the privacy notion introduced by Bernhard
and Smyth [9]. We first start by discussing this definition.
6.1 PrivacyBS
The privacy notion introduced by Bernhard and Smyth [9] is re-
called in Figure 10 (PrivacyBS). The adversary may request a voter
id to vote for v0 or v1 (depending on the bit β) through the oracle
vote(id, v0, v1). He produces an arbitrary ballot box BB and the
Obs
tally will be performed provided that, looking at honest ballots that
appear in BB, counting the corresponding left and right votes yields
the same result.
The main interest of [9] is to highlight the fact that previous def-
initions implicitly assume an honest ballot box. The first attempt at
11
defining privacy w.r.t. a dishonest ballot box (PrivacyBS) has several
limitations. First, it strongly assumes that the ballots that appear in
the ballot box are exactly the same than the cast ballots. This is not
the case for example of the ThreeBallots protocol [28] where the
ballot box only contains two shares (out of three) of the original
ballot. It is not applicable either to a protocol like BeleniosRF [12]
where ballots are re-randomised before their publication. Second, it
requires ballots to be non-malleable [9]. This means that, as soon as
a ballot includes a malleable part (for example the voter’s id like in
Helios, or a timestamp), privacy cannot be satisfied. This severely
restricts the class of protocols that can be considered. Third, Pri-
vacyBS does not account for a revote policy. As soon as revote is
allowed (for example in Helios), then PrivacyBS is broken since
some ballots may not be counted. Indeed, an attacker may call
vote(id1, 0, 1), obtaining ballots b1, b′
Obs
vote(id1, 1, 0), followed by Obs
1,
and return the board BB = [b1, b′
1]. The equality condition on the
number of ballots in BB produced by Obs
holds, since for v = 0, 1:
vote
′) ∈ L}| = |{b ∈ BB|∃v
|{b ∈ BB|∃v
′
, v) ∈ L}| = 1
where L = [(b1, 1, 0),(b′
1, 0, 1)]. Hence the tally is computed. Ac-
cording to the revote policy, only b′
1 is counted, and the result is β,
which lets the attacker win ExpBS.
. (b, v, v
′
. (b, v
′
6.2 Protocols
We consider four standard protocols (Helios, Belenios, Civitas, and
Neuchâtel) as well as our simple protocol, presented in introduction.
We briefly explain each of them in this section. In what follows
E = (gen, enc, dec) denotes an encryption algorithm.
Simple. We detail the simple protocol sketched in introduction.
Recall that voters simply send their encrypted votes to the ballot
box, and, at the end of the voting phase, the tally computes and
publishes the result of the election. No revote is allowed, and the
voters do not have any means of verifying that their vote is taken
into account. Identities and credentials are not used in this protocol.
The corresponding algorithms of this protocol are:
• Vote(id, cred, pk, v) = enc(pk, v)
• VerifVoter(id, cred, L, BB) = true (voters do not make any
checks)
• Tally(BB, sk, U) checks that all the ballots in BB are distinct,
and returns ⊥ if not. The tally performs a random permu-
tation of the ballots, decrypts all of them and returns the
multiset of the votes they contain.
• Valid(id, b, BB, pk) checks that b does not already occur in BB.
Helios [4] is similar to Simple, except that revote is allowed, and
the last vote cast by each id is counted. To make this revote policy
possible, the ballots contain the id of the voter: Vote(id, cred, pk, v) =
(id, enc(pk, v)). enc(pk, v) here also includes a proof that v is a valid
vote. Credentials are unused. The tally computes the result of the
election similarly to Simple except that it also features an homomor-
phic mode, where the tally homomorphically computes the sum of
the ballots in BB, decrypts the resulting ciphertext and returns the
result. Moreover, the tally returns a proof of correct decryption. In
addition, the board which will be tallied is made public, allowing
the voters to check that their last ballot is indeed the last ballot
12
with their id on the board:
VerifVoter(id, cred, Lid, BB) =
the last element in Lid is the last ballot
registered for id in BB.
Similarly to Simple, the Valid function checks that there is no dupli-
cated ciphertext and also checks that the ballot is submitted under
the right id.
Valid(id,(id′
, c), BB, pk) = (id = id′) ∧ c does not occur in BB
This models an authenticated channel between the ballot box and
each voter: a voter id may not cast a vote in the name of id′.
Belenios [15] is similar to Helios, except that voters sign their
encrypted vote thanks to their credential:
Vote(id, k, pk, v) = (id, signElGamal(v, pk, k))
where signElGamal(·,·,·) denotes the combination of the (ElGamal)
encryption and the signature. As for Helios, it also includes a proof
that v is a valid vote. Tally checks that there exists a bijection
between the ids and the credentials in the final board, i.e. that the
same id is always associated with the same signature, and vice
versa. The revote policy counts the last ballot corresponding to a
given credential. Voters can verify that their last ballot is indeed
the last one signed by their key on the board.
Civitas [14]. In Civitas, voters privately receive a credential,
that is published encrypted on the bulletin board. To cast a vote, a
voter encrypts her vote, also encrypts her credential, and produces
a proof π of well-formedness that links the two ciphertexts together.
The corresponding ballot is of the form
Vote(id, cred, pk, v) = (enc(pk, cred), enc(pk, v), π).
The voters can verify that their vote will be taken into account by
checking that it is present on the board that will be tallied.
VerifVoter(id, cred, Lid, BB) = b ∈ BB
where b is the ballot in Lid. In theory, revote is allowed. However,
we unveil a small discrepancy in how revote should be performed.
Assume for example that the last ballot should be counted. Since
an adversary may recast old ballots generated by an honest voter, a
voter should memorise all the ballots he generated and check that
they appear in the right order on the ballot box. Such a check seems
highly cumbersome for an average voter and we could not find its
description in [14]. Therefore, we simply assume here that honest
voters do not revote.
Neuchâtel [22]. Voters privately receive a code sheet, where
each candidate is associated to a (short) code. To cast a vote, voters
send their encrypted votes to the ballot box, similarly to Simple or
Helios. The ballot box then provides a return code allowing the voter
to check that the ballot has been received and that it encrypts their
candidate, as intended. This offers a protection against a dishonest
voting client (e.g. if the voter’s computer is corrupted). No revote
is allowed. Since the bulletin board is not published, voters cannot
check that their ballots really belong to the final board (used for
tally), which we model by VerifVoter(id, cred, L, BB) = true . Voters
have to trust the voting server (or other internal components) on
this aspect.
Protocol
Simple (no revote)
Helios
Belenios
Civitas (no revote)
Neuchâtel (no revote)
Honest board [6]
PrivDis-Naive
PrivacyBS [9]
Priv-careful
✓
✓
✓
✓
✓
✗
✗
✗
✗
✗
✓
✗
✗
✓
✓
✗
✗
✓
✓
✗
Figure 11: Comparison of several privacy definitions
(✓: the protocol is private, ✗: there exists an attack on privacy)
6.3 Attacks
Simple. As described in introduction, a dishonest ballot box may
break ballot privacy of any voter by simply replacing the other
votes by votes of its choice. In other words, even if the ballot box
does not detain any decryption key, it can learn how Alice’s voted.
Neuchâtel. Exactly like the Simple protocol, a dishonest ballot
box may break ballot privacy of any voter by simply replacing the
other votes. This is due to the fact that voters have no control over
the ballots that are actually tallied. Note that the Neuchâtel protocol
actually includes internal mechanisms that render such an attack
difficult. However, from the point of view of a voter, if the ballot
box is compromised, her privacy is no longer guaranteed.
Helios. Helios is also vulnerable to an attack when the ballot box
is compromised. This attack is due to P. Roenne [29]. It involves
two honest voters id1, id2, and a dishonest voter id3. The attacker
may call Op,c
vote(id2, 1, 0) once, obtaining
vote(id1, 0, 1) twice and Op,c
ballots (id1, b1), (id1, b′
1), (id2, b2). The adversary then returns the
board [(id1, b′
1),(id2, b2),(id3, b1)]. All ballots are different, hence
no weeding is needed. The result of the tally is then ρ({|0, 1, 0|}) if
β = 0 and ρ({|1, 0, 1|}) if β = 1. The attacker can therefore observe
the difference in the result, which breaks privacy.
Belenios and Civitas remain private against a dishonest board as
long as voters perform their verification checks. We formally prove
privacy according to our definition Priv-careful.
6.4 Comparison
We summarise our findings in Figure 11. As explained in Section 5,
the naive extension of the privacy definition to a dishonest board
(PrivDis-Naive) is immediately false for any protocol.
All of our five protocols satisfy privacy against an honest ballot
box. We rely here on previous results of the literature, except for
Civitas (and of course the Simple protocol). Indeed, Civitas has been
proved to be coercion-resistant [14] in a rather different setting.
Therefore we show here that it satisfies the Benaloh definition.
PrivacyBS fails to detect the attack on the Neuchâtel protocol
and the Simple protocol since it requires that the tally of the hon-
est ballots present on the final board does not leak information.
Conversely, it cannot prove Belenios private as it does not properly
handle revoting as explained in Section 6.1.
7 CONCLUSION
We show a subtle relation between privacy and verifiability, namely
that privacy implies individual verifiability, which is rather counter-
intuitive. Our result holds in a cryptographic as well as a symbolic
setting, for various trust assumptions. In contrast, privacy does
not seem to imply universal verifiability nor eligibility verifiability.
To show that there is indeed no implication, we plan to exhibit
counter-examples, as simple as possible.
Our result assumes counting functions that have the partial tally
property. Our proof technique does not extend immediately to
more complex counting functions such as STV or Condorcet. We
plan to study how privacy and individual verifiability are related
in this context. Also, our results implicitly discard anonymous
channels: computational models do not account for anonymous
channels while our election determinism assumption discards at
least some use of anonymous channels. Intuitively, in presence of
anonymous channels, an attacker may be able to modify a ballot
without being able to tell which one, hence breaking verifiability
without breaking privacy. It would be interesting to identify which
kind of anonymous channels and more generally, which form of
non determinism, can still be tolerated.
Our findings also highlight a crucial need for a ballot privacy
definition in the context of a dishonest ballot box, in a cryptographic
setting. So far, privacy has only been proved assuming an honest
ballot box, which forms a very strong trust assumption that was
probably never made clear to voters nor election authorities.
We propose a first attempt at modelling privacy against a dis-
honest board, assuming that honest voters checks their ballots as
expected by the voting protocol. We do not see our definition as fi-
nal. In particular, assuming that all voters check their vote is highly
unrealistic. In a realistic setting, it is more likely that a (small) frac-
tion of honest voters perform the required tests while the others
stop after casting their vote. We plan to explore how to adapt our
definition to a quantitative setting, in the lines of [27].
ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers as well
as the shepherd, whose helpful comments and suggestions greatly
contributed to clarify the notions presented in the paper.
This work has been partially supported by the European Re-
search Council (ERC) under the European Union’s Horizon 2020
research (grant agreement No 645865-SPOOC).
REFERENCES
[1] 2010. Délibération n° 2010-371 du 21 octobre 2010 portant adoption d’une recom-
French
mandation relative à la sécurité des systèmes de vote électronique.
13