(d) pair-wise marginal
(e) range query
Colorado
(f) classiﬁcation
Figure 4: End-to-end Comparison of different dataset generation methods. PrivSyn is our proposed method.
step. For PrivBayes, PGM and DualQuery, we use the open-
sourced code [2] by the author of PGM to run the experiments.
Results. Figure 4 illustrates the performance of different
methods. We do not show the classiﬁcation performance
of DualQuery since the misclassiﬁcation rate is larger than
Majority and the variance is large. The experimental results
show that PrivSyn consistently outperforms other methods
for all datasets and all data analysis tasks.
For the pair-wise marginal task, the performance of PGM
and PrivBayes is quite close to PrivSyn, meaning these two
methods can effectively capture low-dimensional correlation.
However, the performance of range query task and classiﬁ-
cation task are much worse than PrivSyn, since range query
and classiﬁcation tasks require higher dimensional correlation.
PrivSyn can effectively preserve both low-dimensional and
high-dimensional correlation.
The performance of DualQuery is signiﬁcantly worse than
other methods. The reason is that generating each record con-
sumes a portion of privacy budget, which limits the number
of records generated by DualQuery. In our experiments, the
number of generated records by DualQuery is less than 300
in all settings. When the privacy budget is low, e.g., ε = 0.2,
the number of generated records is less than 50. Insufﬁcient
number of records would lead to bad performance for all three
data analysis tasks.
6.3 Comparison of Marginal Selection
Methods
Setup. We use Weighted Gaussian method for noise addi-
tion, and use GUM for data synthesis. For each marginal se-
lection method, we compare their performance in both pri-
vate and non-private settings. In the non-private setting, the
marginal selection step do not consume privacy budget. This
can serve as a baseline to illustrate the robustness of different
marginal selection methods.
Results. Figure 5 illustrates the performance of differ-
ent marginal selection methods. For all datasets and all
data analysis tasks, our proposed DenseMarg method con-
sistently outperforms PrivBayes(InDif). In the range query
task, DenseMarg reduces the (cid:96)1 error by about 50%, which
is much signiﬁcant than that in pair-wise marginal release
task. This is because our range queries contain 3 attributes,
which requires higher dimensional correlation information
than pair-wise marginal (contain 2 attributes). DenseMarg
preserves more higher dimensional correlation by selecting
more marginals than PrivBayes(InDif).
In all settings, the performance of DenseMarg in private
setting and non-private setting are very close. The reason
is that DenseMarg tends to select the set of marginals with
high InDif, and adding moderate level of noise is unlikely to
signiﬁcantly change this set of marginals. In our experiments,
the overlapping ratio of the selected marginals between private
setting and non-private setting is larger than 85% in most
cases. This indicates that DenseMarg is very robust to noise.
6.4 Comparison of Noise Addition Methods
Setup. We compare our proposed Weighted Gaussian
method with Equal Laplace and Equal Gaussian methods.
Both Gaussian methods use zCDP for composition. The
Laplace mechanism uses the naive composition, i.e., evenly
allocate ε for all marginals. All methods use DenseMarg for
marginal selection and GUM for data synthesis.
USENIX Association
30th USENIX Security Symposium    939
1.651.701.750.20.40.60.81.01.21.41.61.82.00.050.100.150.200.25l1 error0.0680.0700.0720.20.40.60.81.01.21.41.61.82.00.0000.0020.0040.0060.0080.010l1 error0.20.40.60.81.01.21.41.61.82.00.320.330.340.350.36misclassification rate1.461.481.501.520.20.40.60.81.01.21.41.61.82.00.060.080.100.120.140.160.180.20l1 error0.1220.1240.20.40.60.81.01.21.41.61.82.00.0040.0060.0080.0100.012l1 error0.20.40.60.81.01.21.41.61.82.00.200.250.300.350.400.450.50misclassification ratePrivSynPrivBayesPGMPGM(Manual)DualQueryMajorityNonPriv(a) pair-wise marginal
(b) range query
US Accident
(c) classiﬁcation
(d) pair-wise marginal
(e) range query
Colorado
(f) classiﬁcation
Figure 5: Comparison of different marginal selection methods. DenseMarg is our proposed method. Non-private in the parenthese
indicates that the marginal selection step do not consume privacy budget.
Results. Figure 6 demonstrates the performance of different
noise addition methods. For all datasets and all data analy-
sis tasks, our proposed Weighted Gaussian method consis-
tently outperforms the other two methods. The advantage of
Weighted Gaussian increases when ε is larger.
In
our experiment, both Weighted Gaussian
and
Equal Gaussian methods use zCDP to calculate the
noise variance to each marginal, the main difference is that
Weighted Gaussian allocates privacy budget according to
the number of cells, while Equal Gaussian evenly allocate
privacy budget to all marginals. The experimental results
validate our analysis in Section 4.2 that Weighted Gaussian
is the optimal privacy budget allocation strategy.
6.5 Comparison of Synthesis Methods
To better understand the performance of different synthesis
methods, we select marginals in a non-private setting and
purely compare the performance of different synthesis meth-
ods. This is different from the end-to-end evaluation in Sec-
tion 6.2 that makes all steps private. Other settings are the
same as Section 6.2. We do not compare with DualQuery
in this experiment since Section 6.2 has illustrated that its
performance is much worse than other methods.
Results. Figure 7 shows the performance of different
data synthesis methods. Both MCF and GUM exploit dense
marginals selected by DenseMarg, while the performance of
MCF is even worse than the PGM method and the PrivBayes
method that using spare marginals. The reason is that, in each
iteration, MCF enforces the synthetic dataset Ds to fully match
the marginal. This would severely destroy the correlation es-
tablished by other marginals. While GUM preserves the cor-
relation of other marginals by gradually updating marginals
in each iteration and using duplication technique.
Comparing Figure 4 and Figure 7, we observe that the
experimental results in the private and non-private settings are
similar, showing the robustness of PrivSyn. This is consistent
with the results in Section 6.3.
7 Related Work
Differential privacy (DP) has been the de facto notion for
protecting privacy. Many DP algorithms have been proposed
(see [25,48] for theoretical treatments and [37] in a more prac-
tical perspective). Most of the algorithms are proposed for
speciﬁc tasks. In this paper, we study the general task of gen-
erating a synthetic dataset with DP. Compared to the ad-hoc
methods, this approach may not achieve the optimal utility
for the speciﬁc task. But this approach is general in that given
the synthetic dataset, any task can be performed, and there
is no need to modify existing non-private algorithms. There
are a number of previous studies focus on generating syn-
thetic dataset in a differentially private manner. We classify
them into three categoreis: graphical model based methods,
game based methods and deep generative model based meth-
ods. There are also some theoretical studies that discuss the
hardness of differentially private data synthesis.
Graphical Model Based Methods. The main idea is to
estimate a graphical model that approximates the distribu-
940    30th USENIX Security Symposium
USENIX Association
0.20.40.60.81.01.21.41.61.82.00.080.100.120.140.16l1 error0.20.40.60.81.01.21.41.61.82.00.0010.0020.0030.0040.0050.0060.007l1 error0.20.40.60.81.01.21.41.61.82.00.320.330.340.350.36misclassification rate0.20.40.60.81.01.21.41.61.82.00.060.080.100.120.140.160.18l1 error0.20.40.60.81.01.21.41.61.82.00.0040.0050.0060.0070.0080.0090.010l1 error0.20.40.60.81.01.21.41.61.82.00.200.250.300.350.400.450.50misclassification rateDenseMarg (Non-private)DenseMarg (Private)PrivBayes(InDif) (Non-private)PrivBayes(InDif) (Private)ManualMajorityNonPriv(a) pair-wise marginal
(b) range query
US Accident
(c) classiﬁcation
(d) pair-wise marginal
(e) range query
Colorado
(f) classiﬁcation
Figure 6: Comparison of different noise addition methods. Weighted Gaussian is our proposed method.
(a) pair-wise marginal
(b) range query
US Accident
(c) classiﬁcation
(d) pair-wise marginal
(e) range query
Colorado
(f) classiﬁcation
Figure 7: Comparison of different synthesis methods. GUM is our proposed method.
tion of the original dataset in a differentially private way.
PrivBayes [53] and BSG (the initials of the authors’ last
names) [12] approximate the data distribution using Bayesian
Network. These methods, however, need to call Exponential
Mechanism [53] or Laplace Mechanism [12] many times,
making the network structure inaccurate when the privacy
budget is limited; and the overall utility is sensitive to the
quality of the initial selected node.
PGM [41] and JTree [15] utilize Markov Random Field
to approximate the data distribution. PGM takes as input a
set of predeﬁned low-dimensional marginals, and estimates
a Markov Random Field that best matches these marginals.
JTree ﬁrst estimates a dependency graph by setting a thresh-
old to the mutual information of pairwise attributes, and then
obtains the Markov Random Field by transforming the de-
pendency graph into a junction tree. PGM do not provide
marginal selection method in the paper [41]. JTree proposes
to use SVT to select marginals; however, Lyu et al. [39]
point out that JTree utilizes SVT in a problematic way. The
main limitation of graphical model based methods is that they
cannot handle dense marginals that capture more correlation
information.
USENIX Association
30th USENIX Security Symposium    941
0.20.40.60.81.01.21.41.61.82.00.070.080.090.100.110.120.130.140.15l1 error0.20.40.60.81.01.21.41.61.82.00.00150.00200.00250.00300.00350.00400.00450.0050l1 error0.20.40.60.81.01.21.41.61.82.00.310.320.330.340.350.36misclassification rate0.20.40.60.81.01.21.41.61.82.00.060.080.100.120.140.160.18l1 error0.20.40.60.81.01.21.41.61.82.00.0040.0050.0060.0070.0080.009l1 error0.20.40.60.81.01.21.41.61.82.00.200.250.300.350.400.450.50misclassification rateWeighted GaussianEqual GaussianEqual LaplaceMajorityNonPriv0.20.40.60.81.01.21.41.61.82.00.0750.1000.1250.1500.1750.2000.225l1 error0.20.40.60.81.01.21.41.61.82.00.0020.0040.0060.0080.0100.012l1 error0.20.40.60.81.01.21.41.61.82.00.320.330.340.350.36misclassification rate0.20.40.60.81.01.21.41.61.82.00.060.080.100.120.140.160.18l1 error0.20.40.60.81.01.21.41.61.82.00.0040.0060.0080.0100.0120.0140.016l1 error0.20.40.60.81.01.21.41.61.82.00.200.250.300.350.400.450.50misclassification rateGUMMCFPGMPGM(Manual)PrivBayesMajorityNonPrivGame Based Methods. There are works that formulate the
dataset synthesis problem as a zero-sum game [28, 29, 49].
Assume there are two players, data player and query player.
MWEM [29] method solves the game by having the data
player use a no-regret learning algorithm, and the query player
repeatedly best responds. Dual Query [28] switches the role
of the two players. Concretely, the data player in MWEM
maintains a distribution over the whole data domain, and
query player repeatedly use exponential mechanism to select
a query that have the worse performance from a workload
of queries to update data player’s distribution. The main lim-
itation of MWEM is that when the dataset domain is large
(from 3· 1039 to 5· 10162 in our experiments), maintaining the
full distribution is infeasible. Thus, we do not compare with
MWEM in our experiments.
In contrast, the query player in Dual Query maintains a
distribution over all queries. The query player each time sam-
ples a set of queries from the workload, and the data player
generates a record that minimizes the error of these queries.
The shortcoming is that generating each record would con-
sume a portion of privacy budget; thus one cannot generate
sufﬁcient records as discussed in Section 6. Moreover, both
methods require a workload of queries in advance, and the
generated dataset is guaranteed to be similar to the original
dataset with respect to the query class. This makes MWEM
and Dual Query incapable of handling arbitrary kinds of tasks
with satisﬁed accuracy. The authors of [49] improve both
MWEM and DualQuery by replacing their core components;
however, this work follows the same framework with MWEM
and QualQuery and do not address the main limitation of
them.
Deep Generative Model Based Methods. Another ap-
proach is to train a deep generative model satisfying differen-
tial privacy, and use the deep generative model to generate a
synthetic dataset. The most commonly used deep generative
model is the Generative Adversarial Network (GAN), and
there are multiple studies focus on training GAN in a differen-
tially private way [4,11,27,46,54]. The main idea is to utilize
the DP-SGD framework [3] to add noise in the optimiza-
tion procedure (i.e., stochastic gradient descent). However,
the preliminary application of GAN is to generate images.
Thus, the objective of GAN is to generate data records that
look authentic, instead of approximating the original distribu-
tion, applying the GAN model to the current problem cannot
generate a synthetic dataset with enough variations. In the
NIST challenge [43], there are two teams adapting the GAN-
based method to synthesize high-dimensional data, while their
scores are much lower than PGM and PrivBayes. Thus, we
do not compare this line of methods in our experiments.
In addition to GAN, there are also studies based on Re-
stricted Boltzmann Machine (RBM) [26] and Variational
Auto-Encoder (VAE) [6]. These methods are not as effec-
tive as GAN.
Theoretical Results. There are a series of negative the-
oretical results concerning DP in the non-interactive set-
ting [17,18,20,22–24,47]. These results have been interpreted
“to mean that one cannot answer a linear, in the database size,
number of queries with small noise while preserving privacy”
and to motivate “an interactive approach to private data anal-
ysis where the number of queries is limited to be small –
sub-linear in the size n of the dataset” [18].
We point out that, theoretical negative results notwithstand-
ing, non-interactive publishing can serve an important role in
private data publishing. The negative results essentially say
that when the set of queries is sufﬁciently broad, one cannot
guarantee that all of them are answered accurately. These
results are all based on query sets that are broader than the
natural set of queries in which one is interested. For example,
suppose the dataset is one-dimensional where each value is an
integer number in domain [m] = {1,2 . . . ,m}. These results
√
say that one cannot answer counting queries for arbitrary sub-
sets of [m] with error less than Θ(
n), where n is the size
of the dataset. However, range queries, which are likely to
be what one is interested in, can be answered with less error.
Moreover, these results are all asymptotic and do not rule
out useful algorithms in practice. When one plugs in actual
parameters, the numbers that come out often have no bearing
on practice.
8 Discussion and Limitations
In this section, we discuss the application scope and limita-
tions of PrivSyn.
Only Applicable to Tabular Data. PrivSyn focuses on the
tabular data and cannot handle other types of data such as
image or streaming data. Note that other existing methods
(PrivBayes, PGM and DualQuery) also have this limitation.
We defer the application of PrivSyn to image dataset and
sequential dataset to future work.
Miss Some Higher Dimensional Correlation. PrivSyn
only considers low-degree marginals that may not capture
some high-dimensional correlation information. Notice that
other marginal selection methods such as PrivBayes and
BSG also use low-degree marginals to approximate the high-
dimensional datasets and also have this limitation. To capture
higher dimensional correlation, one possibility is to consider
all triple-wise marginals or higher-dimensional marginals;
however, doing this may introduce too much noise for each
of the marginal, resulting in inaccurate selection. In practice,
low-dimensional marginals are sufﬁcient to capture enough
correlation information, as illustrated on the four real-world
datasets used in our experiments.
9 Conclusion
In this paper, we present PrivSyn for publishing a synthetic
dataset under differential privacy. We identify the core steps
942    30th USENIX Security Symposium
USENIX Association
in the process and summarize previous studies for each step.
PrivSyn achieves the state-of-the-art by proposing novel meth-
ods for all steps. We extensively evaluate different methods
on multiple real-world datasets to demonstrate the superiority
of PrivSyn.
Acknowledgments
We thank the anonymous reviewers for their constructive feed-
back. This work is partially funded by NSFC under grant No.
61731004, U1911401, Alibaba-Zhejiang University Joint Re-
search Institute of Frontier Technologies, the Helmholtz As-
sociation within the project “Trustworthy Federated Data An-
alytics” (TFDA) (funding number ZT-I-OO1 4), and United
States NSF under grant No. 1931443.
References
[1] http://cs231n.github.io/neural-networks-3/#anneal.
[2] https://github.com/ryan112358/private-pgm.
[3] Martín Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya
Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential
In Proceedings of the 2016 ACM SIGSAC Conference on