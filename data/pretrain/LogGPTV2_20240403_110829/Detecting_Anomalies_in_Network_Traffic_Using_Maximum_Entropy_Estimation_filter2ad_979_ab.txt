Maximum Entropy estimation locates a set of parameters
Λ = {λi} in (3) for {fi} that minimizes the K-L diver-
gence of ˜P with respect to P :
Λ = arg min
Λ
˜P (ω) log
˜P (ω)
P (ω) .
(7)
X
ω∈Ω
There are a number of numerical methods that can be
exploited.
In our work, we use the L-BFGS Maximum
Entropy estimation algorithm ”tao lmvm” implemented by
Malouf in [8].
4.3 Model construction
Figure 1 shows the model construction algorithm. The
model is built by iterating the above two steps until some
stopping criterion is met. This stopping criterion can be ei-
ther that the K-L divergence of P with respect to ˜P is less
than some threshold value, or that the gain of adding a new
feature function is too small to improve the model.
The feature functions are selected from a set of candi-
date feature functions. Since the domain Ω in our work
consists of packet classes different in the protocols and the
destination port numbers, our candidate feature function set
comprises of three sets of indicator functions. The ﬁrst set
of indicator functions checks the packet’s protocol infor-
mation, the second set of indicator functions classify the
• Initial Data:
• Iterated steps:
(0) Set n = 0
(1) Feature selection
A set of training data with empirical distribution ˜P ,
a set of candidate feature functions F,
and an initial density model P0, P0(ω) = 1
Z , Z = |Ω|
For each feature function g ∈ F, g /∈ {fi}, compute
the gain GPn (g)
Let fn+1 be the feature function with the largest gain
(2) Parameter Estimation
Update all the parameters and set Pn+1 to be the up-
dated model
(3) Check the iteration stopping criterion
If the iteration stopping criterion is not met, set n =
n + 1, goto (1). Otherwise, return the learned
model Pn+1.
Figure 1: Model construction algorithm
packet’s destination port number, and the third set checks
both the packet’s protocol information and the destination
port number.
The training data used are pre-labeled by humans and
the packets related to the labeled anomalies are not used
in computing the empirical distribution ˜P .
In this way,
we treat the packet classes distribution deﬁned by the log-
linear model in (3) from Maximum Entropy estimation as
the baseline distribution, and are now able to compute the
relative entropy of any given network trafﬁc.
5 Detecting network trafﬁc anomalies
The relative entropy shows the difference between the dis-
tribution of the packet classes in the current network trafﬁc
and the baseline distribution. If this difference is too large,
it indicates that a portion of some packet classes that rarely
appear in the training data increases signiﬁcantly, or that
appear regularly decreases signiﬁcantly.
In other words,
this serves as an indication of the presence of an anomaly
in the network trafﬁc. Our current work only considers the
anomalies where anomaly trafﬁc increases.
We divide time into slots of ﬁxed length δ. Suppose
the trafﬁc in a time slot contains the packet sequences
{x1, . . . , xn}, the empirical distribution ˜P of the packet
classes in this time slot is
˜P (ω) = P 11(xi ∈ ω)
n
,
(8)
348
Internet Measurement Conference 2005 
USENIX Association
For each packet class, we deﬁne
D ˜PkP (ω) = ˜P (ω) log
˜P (ω)
P (ω) ,
(9)
where P is the baseline distribution obtained from Max-
imum Entropy estimation. This produces a quantitative
value that describes the distortion of the distribution for
each packet class ω from that of the baseline distribution,
and this is used as an indication of anomalies.
We then use a ’sliding window’ detection approach. In
each time slot, we record packet classes that have their di-
vergences larger than a threshold d. If for a certain packet
class ω, D ˜PkP (ω) > d for more than h times in a window
of W time slots, an alarm is raised together with the packet
class information ω, which reveals the corresponding pro-
tocol and port number.
6 Experimental results
In this section, we present initial experimental results.
The data are collected at the UMASS Internet gateway
router using DAG cards made by Endace [3]. They con-
sist of seven hours’ trafﬁc trace collected from 9:30am to
10:30am in the morning for a week from July 16th to July
22nd, 2004. All of these data are labeled by human inspec-
tion. In particular, we select a set of high volume ﬂows, a
set of nodes with high incoming or outgoing trafﬁc, and a
set of port numbers that have high volume of trafﬁc. We
then examine each of them to see whether there are anoma-
lies. For more details of the trace collected, please refer
to [4].
We use the data taken on July 20th as the training data
set. The Maximum Entropy estimation algorithm is used
to generate the baseline distribution of the packet classes
from the training data. We set the stopping criterion for the
construction algorithm to be whether the K-L difference of
P with respect to ˜P is less than 0.01. By this criterion, the
algorithm ended with a set of 362 feature functions.
As an example, we ﬁrst show two cases of port scans
that manifest themselves by increasing the D ˜PkP (ω) value.
The parameters used are set as δ = 1 second, d = 0.01,
W = 60 and h = 30. On July 19th, 2004, from 9:30am,
when we began our data collection, to 9:37am, a host
outside of the UMASS campus network performed a port
scan at port 4899 by sending many SYN packets to dif-
ferent hosts in the UMASS campus network. Then from
9:46am to 9:51am, another host outside of the UMASS
campus network performed another port scan at the same
port. During these two time periods, the relative entropy
of the packet class that represents SYN packets targeting at
ports from 4824 to 4923 increased considerably, as shown
in Figure 2. These two port scans were successfully de-
tected by our relative entropy detection algorithm.
y
p
o
r
t
n
E
e
v
i
t
a
e
R
l
 0.4
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0
UMASS OIT Trace
protocol SYN ports [4824-4923]
 500
 1000
 1500
 2000
 2500
 3000
 3500
Time (s)
Figure 2: Relative entropy for packets of type SYN and
destination port number from 4824 to 4923
We test the performance of the algorithm by running it
over the remaining six human labeled data sets. The detec-
tion algorithm provides results at every time slot δ. If an
anomaly is detected by the algorithm and there is a corre-
sponding anomaly detected by human labeling, it is a pos-
itive. All anomalies detected by the algorithm correspond-
ing to the same anomaly labeled by human are treated as
a single positive.
If there is no human labeled anomaly
corresponding to the anomaly reported by the algorithm, it
is called a false positive. Consecutive false positives are
treated as a single false positive. Anomalies labeled by hu-
man but missed by the algorithm are called false negatives.
In each case, the algorithm detects most of the anomalies
located by human labeling. However, the algorithm also
reports many ’false positives’. These ’false positives’ are
either ’ﬂash crowds’ phenomenons, high rate trafﬁc that
communicates with port numbers rarely seen in the train-
ing data, or trafﬁc that we cannot tell what they are given
the limited packet header information. For more details,
please refer to [4].
In spite of the ambiguous situation concerning all the
anomalies generated by the algorithm, we found that the
experimental results regarding SYN packets give good re-
sults. Table 1 summarizes the algorithm performance in the
experiments described above. The table also summarizes
the performance of the algorithm in terms of precision, re-
call and F1. Let a be the number of positives, b the number
of false positives, and c the number of false negatives, pre-
cision is deﬁned as a/(a + b), recall is deﬁned as a/(a + c)
and F1 is deﬁned as 2a/(2a + b + c). The table shows that
the Maximum Entropy method detects most of the anoma-
lies detected by human labeling with few false negatives
and few false positives.
7 Implementation and practical issues
We are currently implementing the detection algorithm
using an Intel IXP 1200 packet processing engine for
USENIX Association
Internet Measurement Conference 2005  
349
Date
July 16
July 17
July 18
July 19
July 21
July 22
Humanly labeled
Positive
False negative
False positive
Precision
Recall
10
11
14
16
15
9
10
10
14
14
15
8
0
1
0
2
0
1
1
0
0
0
0
0
0.91
1
1
1
1
1
1
0.91
1
0.88
1
0.89
F1
0.95
0.95
1
0.93
1
0.94
Table 1: Algorithm performance
[2] BRUTLAG, J. D. Aberrant behavior detection in time series for
network service monitoring. In Proceeding of the 14th Systems Ad-
ministration Conference (2000), pp. 139–146.
[3] ENDACE. http://www.endace.com.
[4] GU, Y., MCCALLUM, A., AND TOWSLEY, D. Detecting anomalies
in network trafﬁc using maximum entropy. Tech. rep., Department
of Computer Science, UMASS, Amherst, 2005.
[5] INTEL CORP. Intel ixp 1200 network processor, 2000.
[6] INTERNET
NUMBERS
http://www.iana.org/assignments/port-numbers.
ASSIGNED
AUTHORITY.
[7] LEE, W., AND XIANG, D.
Information-theoretic measures for
anomaly detection. In Proceedings of the IEEE Symposium on Se-
curity and Privacy (2001), IEEE Computer Society, p. 130.
[8] MALOUF, R. A comparison of algorithms for maximum entropy pa-
rameter estimation. In Proceedings of the 6th Conference on Natural
Language Learning (2002).
[9] MCCALLUM, A. Efﬁciently inducing features of conditional ran-
In Nineteenth Conference on Uncertainty in Artiﬁcial
dom ﬁelds.
Intelligence (UAI03) (2003).
[10] PAXSON, V. Bro: A system for detecting network intruders in real-
time.
[11] PIETRA, S. D., PIETRA, V. D., AND LAFFERTY, J. Inducing fea-
tures of random ﬁelds. IEEE Transactions on Pattern Analysis and
Machine Intelligence 19, 4 (1997), 380–393.
[12] SNORT: THE OPEN SOURCE NETWORK INTRUSION DETECTION
SYSTEM”. http://www.snort.org/.
[13] STANIFORD, S., HOAGLAND, J., AND MCALERNEY, J. M. Practi-
cal automated detection of stealthy portscans. In Proceedings of the
IDS Workshop of the 7th Computer and Communications Security
Conference (2000).
[14] THOTTAN, M., AND JI, C. Anomaly detection in ip networks. IEEE
Trans. Signal Processing 51 (2003).
[15] WANG, H., ZHANG, D., AND SHIN, K. G. Detecting syn ﬂooding
attacks. In Proceedings of IEEE INFOCOM (2002).
routers [5], which has six processing engines, one control
processor, and works at 200-MHz clock rate. The empiri-
cal distribution of the packet classes in the network trafﬁc is
read from the processing engine and compared to the base-
line distribution every second. The baseline distribution is
estimated ofﬂine. In practice, when the trafﬁc is expected
to experience certain changes, i.e. due to diurnal effects or
planned network reconﬁguration, the baseline distribution
should be updated or retrained. How to do this is a topic of
future research.
8 Conclusion
In this paper, we introduce our approach to detect anoma-
lies in the network trafﬁc using Maximum Entropy esti-
mation and relative entropy. The packet distribution of
the benign trafﬁc is estimated using the Maximum Entropy
framework and used as a baseline to detect the anomalies.
The method is able to detect anomalies by inspecting only
the current trafﬁc instead of a change point detection ap-
proach. The experimental results show that it effectively
detects anomalies in the network trafﬁc including different
kinds of SYN attacks and port scans. This anomaly detec-
tion method identiﬁes the type of the anomaly detected and
comes with low false positives. The method requires a con-
stant memory and a computation time proportional to the
trafﬁc rate. Many interesting aspects of this approach still
remain to be explored, and comparison with other methods
such as Holt-Winter, when possible, will be useful.
Acknowledgements
We wish to thank Professor Paul Barford for useful com-
ments and suggestions. Feedback from anonymous review-
ers also helped to improve the work. This research is sup-
ported by NSF and DARPA under grants CNS-0085848
and F30602-00-2-0554. The data collection equipment was
puchased under NSF grant EIA-0080119.
References
[1] BARFORD, P., KLINE, J., PLONKA, D., AND RON, A. A signal
analysis of network trafﬁc anomalies. In Proceedings of ACM SIG-
COMM Internet Measurement Workshop (2002).
350
Internet Measurement Conference 2005 
USENIX Association