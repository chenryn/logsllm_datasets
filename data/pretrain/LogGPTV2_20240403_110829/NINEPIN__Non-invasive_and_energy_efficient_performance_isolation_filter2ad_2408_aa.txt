title:NINEPIN: Non-invasive and energy efficient performance isolation
in virtualized servers
author:Palden Lama and
Xiaobo Zhou
NINEPIN: Non-Invasive and Energy Efﬁcient
Performance Isolation in Virtualized Servers
Palden Lama and Xiaobo Zhou
Department of Computer Science
University of Colorado at Colorado Springs, CO 80918, USA
{plama, xzhou}@uccs.edu
Abstract—A virtualized data center faces important but chal-
lenging issue of performance isolation among heterogeneous cus-
tomer applications. Performance interference resulting from the
contention of shared resources among co-located virtual servers
has signiﬁcant impact on the dependability of application QoS.
We propose and develop NINEPIN, a non-invasive and energy
efﬁcient performance isolation mechanism that mitigates per-
formance interference among heterogeneous applications hosted
in virtualized servers. It is capable of increasing data center
utility. Its novel hierarchical control framework aligns perfor-
mance isolation goals with the incentive to regulate the system
towards optimal operating conditions. The framework combines
machine learning based self-adaptive modeling of performance
interference and energy consumption, utility optimization based
performance targeting and a robust model predictive control
based target tracking. We implement NINEPIN on a virtualized
HP ProLiant blade server hosting SPEC CPU2006 and RUBiS
benchmark applications. Experimental results demonstrate that
NINEPIN outperforms a representative performance isolation
approach, Q-Clouds, improving the overall system utility and
reducing energy consumption.
Keywords: Performance Isolation, Non-invasiveness, Virtualized
Servers, Energy Efﬁciency, Robustness, Fuzzy MIMO Control
I. INTRODUCTION
A modern data center utilizes virtualization technology to
consolidate multiple customer applications onto high density
servers for improving server utilization and reducing energy
consumption costs [5], [9], [23], [27]. It also aims to satisfy
the Quality of Service (QoS) needs of hosted applications
for increasing data center utility. However, QoS experienced
by these applications may be signiﬁcantly impacted by the
performance interference between virtual machines (VMs) that
are co-located in the underlying multi-core servers [11], [21].
It is mainly due to the contention of resources such as the
last level cache, memory bandwidth, etc, which are shared by
VMs residing on a multi-core processor. For instance, VMs
running on adjacent CPU cores may experience signiﬁcantly
reduced performance due to an increased miss rate in the
last level cache [3], [31]. Performance isolation is essential to
dependable virtualized servers shared by various applications.
In this paper, we propose to design and develop a non-
invasive and energy efﬁcient performance isolation mechanism
that increases the overall utility of a virtualized server system
hosting heterogeneous customer applications. It is important
but challenging to achieve performance isolation between
Internet applications running on virtualized servers.
978-1-4673-1625-5/12/$31.00 ©2012 IEEE
Fig. 1. NINEPIN: non-invasive performance isolation in virtualized servers.
There are invasive techniques based on hardware and soft-
ware resource partitioning, which require instrumentation and
modiﬁcation of the guest operating system or the virtualization
management layer to avoid performance interference between
co-located VMs [2], [24], [29], [30]. However, resource par-
titioning can be difﬁcult and costly to implement and even
if accomplished may result in inefﬁcient resource utilization
indeed [28]. Due to portability and transparency needs, non-
invasive performance isolation is desirable in the context of
modern data centers provisioning cloud computing services,
which host third-party customer applications and often use
virtualization software from third-party vendors.
From a data center’s economic perspective, performance
isolation should be aligned with the incentive to maximize the
overall system utility, which includes the service-level utility
of customer applications and the utility of server energy con-
sumption. A service-level utility function speciﬁes the business
value of providing various levels of service to the users of an
application in terms of revenue or penalty [26]. The utility
of energy consumption is determined by the electricity costs
as well as the carbon footprint associated with it. However,
existing performance isolation techniques are utility-agnostic.
A naive approach that disregards the economic perspective
may achieve performance isolation by allocating additional
resources to compensate the effect of performance interference
among co-located VMs. Recently an important non-invasive
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:50:15 UTC from IEEE Xplore.  Restrictions apply. 
     Guest OS      App1    Guest OS  (VM 1) NINEPINCPU 1CacheMemoryCPU n   App n  (VM n)       VMMperformance isolation approach, Q-Clouds [21] was proposed
to ensure that the performance experienced by applications
is the same as they would have achieved if there was no
performance interference. However, such an approach does not
guarantee optimal operating conditions with respect to energy
efﬁciency of underlying servers and the service-level utility of
hosted applications.
Furthermore, there are practical issues in achieving robust
performance isolation among heterogeneous applications co-
located in the same physical server. These applications may
have different performance metrics as well as workload dy-
namics. For instance the performance of compute intensive
jobs is measured in terms of how fast a job is completed
whereas interactive web applications with multi-tier architec-
ture are concerned with end-to-end response time of requests.
Furthermore an interactive web application shows dynamic
workload variations at small
time scales [13], [16], [25].
As a result, co-located VMs experience frequently changing
performance interference effects and even resource saturation.
Moreover, energy consumption characteristic of VMs may also
depend on the workload intensity. Hence, it is very challenging
to achieve performance isolation and energy efﬁciency at the
same time in a heterogeneous application environment.
In this paper, we propose and develop NINEPIN, a non-
invasive and energy efﬁcient performance isolation mechanism
that mitigates the performance interference between heteroge-
neous customer applications hosted in virtualized servers. As
shown in Figure 1, NINEPIN interacts with the virtualization
management layer of a multi-core server and the co-located
VMs at the application layer. Its core is a novel two-level
control structure. The ﬁrst level performs a steady-state utility
optimization that aims to maximize the overall system utility.
It determines the economically optimal performance targets
for each application and sends these targets to the second
level, the model predictive controller. The controller regulates
the system’s dynamic behavior towards the optimal targets
by adjusting the allocation of resources among co-located
applications. The utility optimization and control are based
on system models that capture the performance interference
relationship between co-located applications and the total
energy consumption of the underlying physical server for
various resource allocations.
NINEPIN constructs fuzzy multiple-input multiple-output
(MIMO) models for estimating the performance interference
and energy usage in a virtualized server when different CPU
usage limits are enforced on the co-located VMs. A key
strength of fuzzy MIMO model is its ability to accurately
represent the inherently non-linear relationship of performance
and energy with CPU usage. NINEPIN applies subtractive
clustering and artiﬁcial neural network based machine learn-
ing techniques to construct the performance interference and
energy usage models. In order to achieve system robustness
against dynamic workload variation and application hetero-
geneity, it adapts the models online by use of a fast learning
algorithm, weighted Recursive Least Squares (wRLS), when-
ever a signiﬁcant error in prediction of energy usage and
2
performance is detected. Then, it re-computes the optimal per-
formance targets using the updated performance interference
and energy models. The model predictive controller uses a
dynamic model that is derived by linearizing the fuzzy MIMO
model at the current operating state.
We implement NINEPIN on a testbed of HP ProLiant
BL460C G6 blade server hosting SPEC CPU2006 benchmark
applications and an e-commerce benchmark application RU-
BiS. The testbed uses VMware virtual machines. Due to its
non-intrusiveness, NINEPIN is applicable to any virtualization
software given that the mechanisms to adjust VM resources are
available. Experimental results demonstrate the effectiveness
and energy efﬁciency of NINEPIN in achieving performance
isolation among multiple heterogeneous customer applications.
For performance comparison, we also implement
the rep-
resentative non-invasive performance isolation approach, Q-
Clouds [21] at the same testbed. Q-Clouds uses a closed loop
controller to compensate the effect of performance interference
between co-located VMs by allocating additional resources.
However, such an approach does not guarantee optimal oper-
ating conditions with respect to energy efﬁciency of underlying
servers and the overall system utility. It also does not consider
heterogeneous application support.
Compared to Q-Clouds, NINEPIN achieves better system
utility and signiﬁcantly reduces energy consumption. We have
observed that the advantage of NINEPIN approach is even
more signiﬁcant in case of heterogeneous applications with
dynamic workload variations. NINEPIN is able to re-compute
and assure optimal performance targets in response to the
dynamic environment in agile and robust manner.
To our knowledge, NINEPIN is the ﬁrst non-invasive per-
formance isolation mechanism that drives a virtualized server
system towards optimal operating conditions with respect
to both energy efﬁciency and service-level utility of hosted
applications. The main contributions of NINEPIN are:
1) It provides effective performance isolation between co-
located applications in virtualized servers while maxi-
mizing the overall system utility. It increases data center
utility by aligning performance isolation goals with a
data center’s economic optimization objective.
2) It is energy efﬁcient. It reduces the energy consumption
of virtualized servers while trading off performance
objectives in a ﬂexible manner. The tradeoff between
inherently conﬂicting objectives of energy efﬁciency and
performance guarantee can be speciﬁed by a data center
administrator.
3) It is robust against application heterogeneity and dy-
namic workload variations.
4) It provides desirable non-invasive performance isolation
for a data center hosting third-party customer applica-
tions and using virtualization software from third-party
vendors.
NINEPIN combines the strengths of machine learning based
self-adaptive system modeling, utility based performance tar-
geting and a model predictive control based target tracking.
The two-level structure of NINEPIN integrates utility com-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:50:15 UTC from IEEE Xplore.  Restrictions apply. 
puting paradigm with control theoretical approach. Together
with the strength of fuzzy logic, our novel hierarchical control
framework achieves this complex integration while avoiding
highly complex system modeling and computationally expen-
sive control. Hence, NINEPIN is practical for real virtualized
server systems. We demonstrate the merits of NINEPIN with
implementation on a testbed of virtualized servers.
In the following, Section II discusses related work. Sec-
tions III-B through V present NINEPIN architecture and
hierarchical control design. Section VI presents the testbed
implementation. Section VII provides the experimental results
and analysis. Section VIII concludes the paper.
II. RELATED WORK
Performance isolation of customer applications in a virtual-
ized data center is an important research topic. Despite several
advantages such as security isolation, fault
isolation, and
environment isolation, prevalent virtualization techniques do
not provide effective performance isolation between VMs [11],
[21]. The behavior of one VM can affect the performance of
another adversely due to the shared use of resources in the
system. VMs running on the underlying multi-core servers of
a virtualized data center mainly suffer from the performance
interference caused by the contention of last
level cache
and memory bandwidth. The performance impact of shared
resource contention in multi-core servers has been well studied
in the studies [7], [11], [21].
Several research efforts have focused on hardware and
software resource partitioning based techniques for perfor-
mance isolation of applications running on a multi-core server.
Hardware-based cache partitioning schemes are mainly in-
volved with modiﬁcation of cache replacement policies [30]
with various partition granularity such as cache ways and
cache blocks. On the other hand, software partitioning tech-
nique based on static and dynamic page coloring addresses
cache contention between competing applications, without
requiring any hardware level support [2], [24], [29]. Page
coloring reserves a portion of the cache for each application,
and allocates the physical memory such that the application’s
cache lines map only into the reserved portion. However, such
approaches in virtualized servers require invasive instrumen-
tation and modiﬁcation of the guest operating system or the
virtualization management layer.
Some prior studies investigated the design of cache-aware
scheduling algorithms that achieves performance isolation
among competing applications by minimizing resource con-
tention [3], [10], [31]. For instance, Fedorova et. al designed
a cache-aware scheduler that compensates threads that were
hurt by cache contention by giving them extra CPU time [3].
Knauerhase et. al [10] proposed to reduce cache interference
by spreading the cache intensive applications apart and co-
scheduling them with non-intensive applications. A common
drawback of cache-aware scheduling and resource partitioning
based performance isolation mechanism is that they only focus
on a single source of performance interference. However, in
3
practice there are several dimensions of performance interfer-
ence such as shared I/O and memory bandwidths [11].
Recently, Nathuji al. proposed an interesting non-invasive
performance isolation approach for virtualized servers, Q-
Clouds [21]. Q-Clouds builds MIMO models that capture
interference relationships between co-located VMs and applies
a closed loop controller to achieve speciﬁed performance levels
for each VM. Due to its non-invasive nature, the approach does
not need to determine the underlying sources of interference.
However, it disregards the economic objective of a data center,
which is deﬁned by the service-level utility of customer ap-
plications. Furthermore, it does not consider energy efﬁciency
and heterogeneous application support.
Energy consumption costs and the impact of carbon foot-
print on the environment have become critical
issues for
data centers today [4], [19]. There are recent studies that
aim to guarantee ﬁxed performance targets of data center
applications while minimizing the power consumption [1], [8],
[12], [15], [17], [18]. However, they do not consider the impact
of performance interference between co-located VMs on the
energy efﬁciency and the system utility.
III. NINEPIN ARCHITECTURE AND DESIGN
A. Design Goals and Motivations
NINEPIN provides an attractive and practical non-invasive
and energy efﬁcient performance isolation mechanism for
virtualized servers that host heterogeneous applications. It
maximizes the overall system utility. The key design issues
of NINEPIN are as follows:
1) Non-invasiveness with utility optimization: An intuitive
approach of non-invasive performance isolation among
co-located applications is to allocate additional resources
to achieve the performance that customers would have
realized if they were running in isolation. However, such
approaches are inherently utility-agnostic. Integration of
non-invasive performance isolation with utility optimiza-
tion would require highly complex system modeling and
computationally expensive control. NINEPIN addresses
the challenge by using a novel hierarchical control
framework.
2) Energy efﬁciency: A common technique to reducing
server energy consumption is to dynamically transition
the hardware components from high power states to
low-power states. However, it is not applicable in case
of virtualized servers since changing the power state
of a processor will affect the performance of multiple
VMs running different applications. NINEPIN achieves
energy efﬁciency by controlling the CPU usage limits
on each VM, based on an accurate energy model. It
allows a data center administrator to ﬂexibly trade-
off energy consumption with the service-level utility of
hosted applications.
3) Robust performance isolation: The robustness of per-
formance isolation against application heterogeneity and
dynamic workload variations requires a self-adaptive ap-
proach that responds to the changes in the performance
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:50:15 UTC from IEEE Xplore.  Restrictions apply. 
4
2) Level-1 Control: At level-1, the utility optimizer calcu-
lates the optimal performance targets for each VM in order to
maximize the overall system utility and sends the calculated
targets to the level-2 controller. The optimization is based on
fuzzy MIMO models that capture the performance interference
relationship between co-located VMs and the energy con-
sumption property of the underlying server for various CPU
resource allocations. These models are constructed ofﬂine
by applying machine learning techniques on various data
collected from the system as described in Section IV-A2.
It periodically collects the values of power consumption
from the power monitor, average performance of running
applications from the performance monitor and the CPU usage
limits on various VMs from server logs. Then, it calculates
the corresponding energy usage due to various applications
running in the virtualized server. The total energy usage is a
product of the average power consumption and the average
completion time of the longest running application.
The measured values are compared with the values of
energy usage and performance predicted by the fuzzy MIMO
models. If there are signiﬁcant prediction errors, the fuzzy
MIMO models are updated based on the new observations
and the optimal performance targets are re-calculated. Such
prediction errors can occur due change in workload.
3) Level-2 Control: At level-2, the model predictive con-
troller computes the CPU usage limits to be enforced on each
VM in order to track the optimal performance targets set by
the utility optimizer. For this purpose, it uses a linear state-
space performance interference model, which is obtained by
linearizing the fuzzy MIMO model at each operating point.
Linearization reduces the computational complexity of the
control problem. It is designed to achieve the performance
targets while maintaining system stability in spite of the
inevitable uncertainties and disturbances in the system.
The CPU resource allocator is the actuator for this control
system. It performs the control actions by enforcing the
computed CPU usage limits on the co-located VMs in order
to regulate the system towards the optimal targets. Applying
CPU usage limits affects a VM’s performance as well as
power consumption. It is due to the idle power management
of modern processors, which can achieve substantive energy
savings when a processor is idle compared to it is active.
IV. LEVEL-1 CONTROLLER DESIGN
Level-1 control computes the optimal service levels of
customer applications co-located in a single virtualized server
and sends these values as the performance targets to the level-
2 controller. It performs utility optimization based on the
current system models. The performance interference model
is for non-invasive performance isolation with heterogeneous
application support and the energy usage model is for energy