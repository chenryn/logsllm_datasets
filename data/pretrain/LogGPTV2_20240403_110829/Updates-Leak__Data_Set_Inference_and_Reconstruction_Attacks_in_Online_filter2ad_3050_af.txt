Deep Learning.
SIGSAC Conference on Computer and Communications
Security (CCS), pages 1310–1321. ACM, 2015. 12
USENIX Association
29th USENIX Security Symposium    1305
[40] Reza Shokri, Marco Stronati, Congzheng Song, and Vi-
taly Shmatikov. Membership Inference Attacks Against
Machine Learning Models. In Proceedings of the 2017
IEEE Symposium on Security and Privacy (S&P), pages
3–18. IEEE, 2017. 2, 3, 13
[41] Congzheng Song, Thomas Ristenpart, and Vitaly
Shmatikov. Machine Learning Models that Remember
Too Much. In Proceedings of the 2017 ACM SIGSAC
Conference on Computer and Communications Security
(CCS), pages 587–601. ACM, 2017. 13
[42] Congzheng Song and Vitaly Shmatikov. The Natural
Auditor: How To Tell If Someone Used Your Words To
Train Their Model. CoRR abs/1811.00513, 2018. 13
[43] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever,
Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing Properties of Neural Networks. CoRR
abs/1312.6199, 2013. 13
[44] Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian
Goodfellow, Dan Boneh, and Patrick McDaniel. En-
semble Adversarial Training: Attacks and Defenses. In
Proceedings of the 2017 International Conference on
Learning Representations (ICLR), 2017. 13
[45] Florian Tramér, Fan Zhang, Ari Juels, Michael K. Reiter,
and Thomas Ristenpart. Stealing Machine Learning
Models via Prediction APIs. In Proceedings of the 2016
USENIX Security Symposium (USENIX Security), pages
601–618. USENIX, 2016. 13
[46] Yevgeniy Vorobeychik and Bo Li. Optimal Randomized
Classiﬁcation in Adversarial Settings. In Proceedings
of the 2014 International Conference on Autonomous
Agents and Multi-agent Systems (AAMAS), pages 485–
492, 2014. 13
[47] Binghui Wang and Neil Zhenqiang Gong. Stealing
Hyperparameters in Machine Learning. In Proceedings
of the 2018 IEEE Symposium on Security and Privacy
(S&P). IEEE, 2018. 3, 13
[48] Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao
Zheng, and Ben Y. Zhao. With Great Training Comes
Great Vulnerability: Practical Attacks against Transfer
Learning. In Proceedings of the 2018 USENIX Secu-
rity Symposium (USENIX Security), pages 1281–1297.
USENIX, 2018. 13
[49] Weilin Xu, David Evans, and Yanjun Qi. Feature Squeez-
ing: Detecting Adversarial Examples in Deep Neural
Networks. In Proceedings of the 2018 Network and Dis-
tributed System Security Symposium (NDSS). Internet
Society, 2018. 13
[50] Mohammad Yaghini, Bogdan Kulynych, and Carmela
Troncoso. Disparate Vulnerability: on the Unfairness
of Privacy Attacks Against Machine Learning. CoRR
abs/1906.00389, 2019. 13
[51] Dingdong Yang, Seunghoon Hong, Yunseok Jang,
Tianchen Zhao, and Honglak Lee. Diversity-Sensitive
Conditional Generative Adversarial Networks. In Pro-
ceedings of the 2019 International Conference on Learn-
ing Representations (ICLR), 2019. 8
[52] Yuanshun Yao, Bimal Viswanath, Jenna Cryan, Haitao
Zheng, and Ben Y. Zhao. Automated Crowdturﬁng
Attacks and Defenses in Online Review Systems. In
Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security (CCS), pages
1143–1158. ACM, 2017. 13
[53] Samuel Yeom, Irene Giacomelli, Matt Fredrikson, and
Somesh Jha. Privacy Risk in Machine Learning: Analyz-
ing the Connection to Overﬁtting. In Proceedings of the
2018 IEEE Computer Security Foundations Symposium
(CSF). IEEE, 2018. 13
[54] Xiao Zhang and David Evans. Cost-Sensitive Robust-
ness against Adversarial Examples. In Proceedings of
the 2019 International Conference on Learning Repre-
sentations (ICLR), 2019. 13
[55] Yang Zhang, Mathias Humbert, Tahleen Rahman,
Cheng-Te Li, Jun Pang, and Michael Backes. Tagvisor:
A Privacy Advisor for Sharing Hashtags. In Proceedings
of the 2018 Web Conference (WWW), pages 287–296.
ACM, 2018. 13
[56] Yang Zhang, Mathias Humbert, Bartlomiej Surma,
Praveen Manoharan, Jilles Vreeken, and Michael
Backes. Towards Plausible Graph Anonymization. In
Proceedings of the 2020 Network and Distributed Sys-
tem Security Symposium (NDSS). Internet Society, 2020.
13
Appendices
A Target Models Architecture
MNIST model:
Sample → conv2d(5, 10)
max(2)
conv2d(5, 20)
max(2)
FullyConnected(50)
FullyConnected(10)
Softmax → (cid:96)
1306    29th USENIX Security Symposium
USENIX Association
CIFAR-10 model:
Sample → conv2d(5, 6)
max(2)
conv2d(5, 16)
max(2)
FullyConnected(120)
FullyConnected(84)
FullyConnected(10)
Softmax → (cid:96)
Insta-NY Model:
Sample → FullyConnected(32)
FullyConnected(16)
FullyConnected(9)
Softmax → (cid:96)
Here, max(2) denotes a max-pooling layer with a 2×2 kernel,
FullyConnected(x) denotes a fully connected layer with x
hidden units, Conv2d(k’,s’) denotes a 2-dimension convo-
lution layer with kernel size k(cid:48)×k(cid:48) and s(cid:48) ﬁlters, and Softmax
denotes the Softmax function. We adopt ReLU as the acti-
vation function for all layers for the MNIST, CIFAR-10 and
Location models.
B Encoder Architecture
Encoder architecture:
δ → FullyConnected(128)
FullyConnected(64) → µ
Here, µ denotes the latent vector which serves as the input
for our decoder. Furthermore, we use LeakyReLU as our
encoder’s activation function and apply dropout on both layers
for regularization.
C Single-sample Label Inference Attack’s De-
coder Architecture
ALI’s decoder architecture:
µ → FullyConnected(n)
Softmax → (cid:96)
Here, n is equal to the size of (cid:96), i.e., n = |(cid:96)|.
D Single-sample Reconstruction Attack
D.1 AE’s Encoder Architecture
AE’s encoder architecture for MNIST and CIFAR-10:
Sample → conv2d(k1, s1)
max(2)
conv2d(k2, s2)
max(2)
FullyConnected( f1)
FullyConnected( f2) → µAE
AE’s encoder architecture for Insta-NY:
Sample → FullyConnected(64)
FullyConnected(32)
FullyConnected(16)
FullyConnected(16) → µAE
Here, µAE is the latent vector output of the encoder. Moreover,
ki, si, and fi represent the kernel size, number of ﬁlters, and
number of units in the ith layer. The concrete values of these
hyperparameters depend on the target dataset, we present our
used values in Table 2. We adopt ReLU as the activation func-
tion for all layers for the MNIST and CIFAR-10 encoders. For
the Insta-NY decoder, we use ELU as the activation function
for all layers except for the last one. Finally, we apply dropout
after the ﬁrst fully connected layer for MNIST and CIFAR-10.
For Insta-NY, we apply dropout and batch normalization for
the ﬁrst three fully connected layers.
D.2 AE’s Decoder Architecture
Autoencoder’s decoder architecture for MNIST and CIFAR-
10:
µAE → FullyConnected( f (cid:48)1)
FullyConnected( f (cid:48)2)
ConvTranspose2d(k(cid:48)1, s(cid:48)1)
ConvTranspose2d(k(cid:48)2, s(cid:48)2)
ConvTranspose2d(k(cid:48)3, s(cid:48)3) → Sample
Autoencoder’s decoder architecture for Insta-NY:
µAE → FullyConnected(16)
FullyConnected(32)
FullyConnected(64)
FullyConnected(168) → Sample
Here, ConvTranspose2d(k’,s’) denotes a 2-dimension
transposed convolution layer with kernel size k(cid:48) × k(cid:48) and s(cid:48)
USENIX Association
29th USENIX Security Symposium    1307
Table 2: Hyperparameters for AE’s encoder and decoder.
CBM-GAN’s generator architecture for CIFAR-10:
Variable MNIST CIFAR-10
k1
s1
k2
s2
f1
f2
f (cid:48)1
f (cid:48)2
k(cid:48)1
s(cid:48)1
k(cid:48)2
s(cid:48)2
k(cid:48)3
s(cid:48)3
3
16
3
8
15
10
15
32
3
16
5
8
2
1
3
32
3
16
50
30
50
64
3
32
5
16
4
3
ﬁlters, and f (cid:48)i speciﬁes the number of units in the ith fully con-
nected layer. The concrete values of these hyperparameters
are presented in Table 2. For MNIST and CIFAR-10 decoders,
we again use ReLU as the activation function for all layers
except for the last one where we adopt tanh. For the Insta-NY
decoder, we adopt ELU for all layers except for the last one.
We also apply dropout after the last fully connected layer for
regularization for MNIST and CIFAR-10, and dropout and
batch normalization on the ﬁrst three fully connected layers
for Insta-NY.
E Multi-sample Reconstruction Attack’s De-
coder Architecture
CBM-GAN’s generator architecture for MNIST:
µ,z → FullyConnected(2048)
FullyConnected(2048)
FullyConnected(2048)
FullyConnected(784) → Sample
CBM-GAN’s discriminator architecture for MNIST:
µ,z → FullyConnected(1024)
FullyConnected(512)
FullyConnected(256)
FullyConnected(1)
Sigmoid →{1,0}
µ,z → conv2d(2, 512)
conv2d(4, 256)
conv2d(4, 128)
conv2d(4, 64)
conv2d(4, 3) → Sample
CBM-GAN’s discriminator architecture for CIFAR-10:
µ,z → conv2d(2, 64)
conv2d(4, 128)
conv2d(4, 256)
conv2d(4, 512)
conv2d(4, 1)
Sigmoid →{1,0}
CBM-GAN’s generator architecture for Insta-NY:
µ,z → FullyConnected(512)
FullyConnected(512)
FullyConnected(256)
FullyConnected(168) → Sample
CBM-GAN’s discriminator architecture for Insta-NY:
µ,z → FullyConnected(512)
FullyConnected(256)
FullyConnected(128)
FullyConnected(1)
Sigmoid →{1,0}
Here, for both generators and discriminators, Sigmoid is the
Sigmoid function, batch normalization is applied on the output
of each layer except the last layer, and LeakyReLU is used
as the activation function for all layers except the last one,
which uses tanh.
1308    29th USENIX Security Symposium
USENIX Association