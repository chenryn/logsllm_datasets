title:Monte Carlo Strength Evaluation: Fast and Reliable Password Checking
author:Matteo Dell'Amico and
Maurizio Filippone
Monte Carlo Strength Evaluation:
Fast and Reliable Password Checking
Matteo Dell’Amico
Symantec Research Labs, France
PI:EMAIL
∗
Maurizio Filippone
University of Glasgow, UK
maurizio.ﬁPI:EMAIL
ABSTRACT
Modern password guessing attacks adopt sophisticated prob-
abilistic techniques that allow for orders of magnitude less
guesses to succeed compared to brute force. Unfortunately,
best practices and password strength evaluators failed to
keep up: they are generally based on heuristic rules designed
to defend against obsolete brute force attacks.
Many passwords can only be guessed with signiﬁcant ef-
fort, and motivated attackers may be willing to invest re-
sources to obtain valuable passwords. However, it is em-
inently impractical for the defender to simulate expensive
attacks against each user to accurately characterize their
password strength. This paper proposes a novel method to
estimate the number of guesses needed to ﬁnd a password
using modern attacks. The proposed method requires little
resources, applies to a wide set of probabilistic models, and
is characterised by highly desirable convergence properties.
The experiments demonstrate the scalability and general-
ity of the proposal. In particular, the experimental analysis
reports evaluations on a wide range of password strengths,
and of state-of-the-art attacks on very large datasets, includ-
ing attacks that would have been prohibitively expensive to
handle with existing simulation-based approaches.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information
Systems]: Security and Protection—Authentication; G.3
[Mathematics of Computing]: Probability and Statis-
tics—Probabilistic algorithms (including Monte Carlo)
General Terms
Algorithms, Security, Theory
Keywords
Passwords, strength, Monte Carlo
∗M. Filippone is now with EURECOM, France.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org//10.1145/2810103.2813631 .
1.
INTRODUCTION
After years spent on unsuccessful attempts to overcome
password-based authentication, researchers have come to ac-
cept that, in the foreseeable future, passwords will still be
used in a large class of scenarios [12]. The recent pub-
lic leaks of very large password datasets (the latest one
in February 2015 involved ten million passwords along with
usernames [3]) can only exacerbate the well-known security
problems of password authentication.
Often, attackers can perform guessing attacks, i.e., at-
tempt to guess a password by trying a large number of can-
didates. Examples include cases where an attacker wants
to ﬁnd the password that protects a wireless network or the
master password that unlocks a password manager, or cases
where the attacker has access to a list of hashed passwords
or to a laptop where data is password-encrypted. Advanced
probabilistic guessing schemes [18, 19, 21, 28, 30] use leaked
password lists as training sets, improving their capability to
guess even passwords that have not been leaked.
While passwords remain a key part of security infrastruc-
tures and attacks become more and more eﬃcient, solutions
designed to help users choose better passwords are still un-
satisfactory. “Best practices,” such as mixing uppercase and
lowercase letters with digits, were conceived to defend users
from brute-force attacks that have progressively become ob-
solete. Against current attacks, these practices strike bad
trade-oﬀs between usability and security [10, 11, 29].
A promising direction that motivates this work is repre-
sented by password meters. Evidence shows that users are
inﬂuenced in their password choice when informed about
their “strength” [9, 27]. Although password meters encour-
age users to choose better passwords, their output is often
questionable as it is not a reliable assessment of the eﬀort
that attackers need to break a password [6].
These considerations suggest what the objective of pass-
word meters should actually be, and yield the following
widely accepted deﬁnition of password strength [1, 7, 15, 18,
19,28,29]: password strength is deﬁned as the number of at-
tempts that an attacker would need in order to guess it. The
deﬁnition underlies a guessing strategy, and indicates that
it is possible to compute password strength by emulating it;
however, such an approach is very expensive and – even after
considerable computational eﬀorts – the strength of a sub-
stantial fraction of unguessed passwords remains unknown.
For this reason, as we discuss in Section 2, existing litera-
ture does not provide a satisfactory solution to the problem
of eﬃciently evaluating password strength.
The best known guessing attacks adopt probabilistic ap-
158proaches [18, 19, 21, 28, 30], which model ways users choose
passwords, resulting in an assignment of a probability to any
password. These probabilities are then used by guessing at-
tacks to determine in what sequence passwords should be
tried. Based on the above deﬁnition of password strength,
this paper proposes a novel way to eﬃciently and accurately
evaluate the strength of any password against a given prob-
abilistic attack. Our method, described in Section 3, esti-
mates password strength by sampling from the model, i.e.,
generating random passwords according to the probabilities
assigned by the model. The appealing properties of our pro-
posal are computational eﬃciency and accuracy. Computa-
tional eﬃciency stems from the fact that the sampling step is
cheap and can be precomputed; once this is done, computing
password strength is as cheap as an array lookup through bi-
nary search. Accuracy can be rigorously characterized using
the theory of Monte Carlo sampling, and a key result of the
√
paper is that our estimate of password strength converges
n), n
to the correct value with a convergence rate of O (1/
being the number of passwords in the sample.
We evaluate our method by considering very large datasets
of leaked passwords, and state-of-the-art attacks such as the
n-grams proposed by Narayanan and Shmatikov [21], the
probabilistic context free grammars by Weir et al. [30], and
the “backoﬀ” model proposed by Ma et al. [19] (for which
we propose an improvement). Details on the evaluation are
available in Section 4.
In Section 5, we use our method in an extensive empirical
evaluation. In its ﬁrst part, we empirically analyze the pre-
cision of our method: we ﬁnd that sample sizes as small as
100-1,000 are suﬃcient to obtain strength estimates in the
right order of magnitude, which is suitable for the imple-
mentation of a strength meter. More accurate results can
simply be obtained by increasing the sample size, yielding a
relative error around 1% when the sample size is 100,000.
In the second part of Section 5, we use our method to
compare the performance of attack models, overcoming the
limitations of existing studies, as discussed in Section 2.2.
We study passwords that are extremely diﬃcult to guess (re-
quiring up to 280 attempts), and we ﬁnd that no approach is
a clear winner. Depending on the number of guesses that an
attacker can aﬀord, diﬀerent approaches become preferable.
In the third part of Section 5, we analyze the importance
of training sets with respect to attack eﬀectiveness; we show
that larger training sets improve attacks against “average”
passwords, whereas not much is gained for passwords that
are either particularly easy or hard to guess.
We conclude Section 5 by assesssing the impact of tra-
ditional restrictions (i.e., limitations on length or classes of
character composing the password) by evaluating the im-
provements in password strength that such restrictions can
obtain:
the results suggest that length requirements are
more advisable than those about character composition.
Contributions. Our main contributions are:
1. A sound method to compute password strength, ac-
cording to the consensus deﬁnition of robustness against
guessing attacks. The method is lightweight and easy
to implement, and we provide theorems to prove its
correctness and approximation level.
2. An empirical evaluation of the accuracy of our method,
including the trade-oﬀ between computation cost and
precision. We show that accurate estimations can be
obtained at a low computational cost.
3. An extensive empirical evaluation comparing state-of-
the-art attack models, impact of training set and of
restrictions in password choice. Our method allows
performing this analysis while overcoming the limita-
tions of previous research discussed in Section 2.2.
2. RELATED WORK
We ﬁrst outline the state of the art in terms of password
guessing in general (Section 2.1); we then focus on studies
that gauge password strength, highlighting the limitations
this work improves on (Section 2.2).
2.1 Password Guessing
The ﬁrst studies on password guessing attacks date back
to 1979, when Morris and Thompson [20] reported that it
was already possible for computers to guess “a substantial
fraction” of the passwords that were used in Unix systems
through brute force and dictionary attacks; similar stud-
ies after more than two decades show that not much has
changed in the meanwhile [16, 26].
Rainbow chains [22] are a technique that allows to eﬃ-
ciently memorize a very large set of pre-computed password
hashes and ﬁnd passwords that appear in them. They are
defeated by the technique of salting, i.e. appending a ran-
dom string of bits to passwords before computing their hash.
More recently, probabilistic attacks have been proposed to
drastically reduce the number of guesses for passwords that
are long and/or do not appear in dictionaries: notable exam-
ples are attacks based on n-gram models [21] and probabilis-
tic context-free grammars (PCFGs) [30]. These approaches
build a model through a training set of passwords in clear-
text; password creation is then seen as a stochastic process
where each password has a given probability of being cho-
sen. To minimize the number of needed guesses, probabilis-
tic attacks enumerate the guesses by descending probability.
Recent improvements to these attacks include the proposal
of a backoﬀ technique to improve n-gram models [19] and
amending PCFGs to include semantic patterns [28] and to
better suit Chinese passwords [18]. In this work, we imple-
mented the n-grams, PCFGs and backoﬀ models; they are
described in detail in Section 4. In Section 5.2, we provide
extensive experimental results to compare them.
A key defense technique against guessing attacks is pass-
word strengthening, or stretching, which amounts to hash-
ing passwords using computationally expensive functions,
resulting in a slowing down of guessing attacks. The de-
sign of strengthening techniques that are resilient to at-
tacks that use parallelization is an active topic of research
[23, 25]. Strengthening is a tool that essentially multiplies
the strength of a password by a constant factor, and this
beneﬁt is counterbalanced by the inconvenience of addi-
tional computation whenever a legitimate user’s password
is checked: better knowledge of password strength allows to
better choose a desirable point in this trade-oﬀ.
2.2 Password Strength Evaluation
The ubiquity of password authentication makes it obvi-
ously important to evaluate password strength,
i.e., how
diﬃcult it is to guess them. Traditionally, simple strate-
gies based on the number of characters and the presence
159of special characters such as uppercase characters, digits
and symbols have been used [4]; however, these approaches
have been found to be inadequate to quantify the resistence
against modern attacks [29]. Indeed, recent studies evalu-
ate password strength as the number of attempts an attack
would need to guess it. With this metric, a password of
strength 2x can be considered as strong as a symmetric en-
cryption key of x bits, since an attacker can guess either
with the same eﬀort.
Dell’Amico et al. [7] adopted an approximation technique
to evaluate the number of attempts needed to guess pass-
words when using n-gram models. Besides being limited to
n-grams, this technique has scalability issues with the large
state space produced by state-of-the art attacks with n ≥ 3
and datasets having millions of passwords. Our proposal re-
quires a fraction of the resources and is applicable in general
to any probabilistic password model.
Bonneau [1] considered the ideal case of probabilistic at-
tacks based on inﬁnitely large training sets, which model
perfectly the probability with which users choose passwords.
An analysis based on 80 million passwords allowed charac-
terizing the strength of passwords appearing multiple times
in the dataset, but the complete probability distribution re-
mains unknown: Kolmogorov-Smirnov tests rejected the in-
terpolation to a power-law distribution with high conﬁdence.
Unfortunately, this implies that the behavior of ideal prob-
abilistic models is still uncertain for the less frequent (and
hence stronger) passwords that most users choose.
Kelley et al. [15] measured the strength of passwords against
Brute Force Markov (BFM) and PCFGs. BFM is a hybrid
between brute force cracking and n-gram models for which
computing exactly the number of guesses needed is easy;
unfortunately, BFM performs deﬁnitely worse than n-gram
models that are actually used by attackers, ﬁnding very few
passwords within the ﬁrst 240 − 245 attempts. For PCFGs,
Kelley et al. employed a 64-node Hadoop cluster for several
days to emulate an attack of around 245 guesses; our ap-
proximated approach, instead, returns an accurate account
of password strength in a fraction of a second even for pass-
words that require around 280 attempts to be found.
Ma et al. [19] studied probabilistic password models such
as n-grams and PCFGs, and proposed a new “backoﬀ” model
that we consider in the evaluation section of this paper.
Rather than attempting to simulate very expensive attacks,
Ma et al. resorted to analyzing the distribution of prob-
abilities that existing models associate to large password
datasets. As the authors themselves acknowledge, this tech-
nique is useful in “type-1” research where passwords in dif-
ferent datasets are compared against the same attack model,
but it can give misleading results in “type-2” research where
diﬀerent attack models are compared against the same pass-
word dataset, because two passwords that are assigned the
same probability by two diﬀerent attack models may be
guessed after a diﬀerent number of attempts in the two at-
tacks: for example, a password with probability 2−15 could
be the very ﬁrst guess in a model and the thousandth one in a
diﬀerent one. Ma et al. still performed “type-2” comparisons,
based on the conjecture of a roughly linear relationship be-
tween probability and password strength. In Section 5.1, we
show that this conjecture does not hold true for a variety of
datasets and attack models; this motivates the importance
of our proposal that aims at computing password strength
in terms of number of guesses rather than probabilities.
Password strength is typically presented to users through
“strength meters”. Studies show that users put in practice
the suggestions given by strength meters in order to generate
stronger passwords [9,27]; unfortunately, strength meters are
generally based on heuristic methods that do not necessarily
reﬂect the resistance of passwords to guessing attacks [6].