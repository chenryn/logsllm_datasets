In practice, passive trac-
Limitations of passive tracing.
ing alone may not provide enough information for network
troubleshooting. Fig 1(a) shows a scenario where a packet p
is last seen at switch S1 but not at the next hop switch S2.
Although this situation indicates that p is dropped at S2, one
cannot determine whether the problem is transient (which
could be ignored) or persistent (which requires attention).
1Packet History [14] proposed techniques to reduce the
bandwidth overhead. But these techniques require heavy
modiﬁcations to both switching ASIC and the host network-
ing stack and are thus hard to deploy in current networks.
One possible solution is to correlate multiple traces with
dropped packet at S2. However, there may not be enough
traces available for such correlation because: i) the victim
ﬂows may have very few packets; ii) only a small fraction of
packets are traced due to sampling. Even if we could know it
is a persistent drop event, we will still have difﬁculty in ﬁg-
uring out whether this is a random drop (e.g., due to a faulty
cable) or a blackhole that only drops the packets of certain
5-tuples.
Fig 2(a) shows another scenario where a packet p traverses
switches S1 and S2 and the two traced packets are sent to an
analyzer A. To avoid the clock synchronization problem on
S1 and S2, we try to calculate the latency of link (S1, S2)
using the timestamps of the two traced packets on A. How-
ever, this cannot be done because the path S1 → A can be
quite different from the path S2 → A.
3.2 Key ideas
Everﬂow addresses these challenges with four key ideas.
The ﬁrst three tackle the scalability challenge while the last
one overcomes the limitations of passive tracing.
Match and mirror on switch. Commodity DCN switches
can match based on pre-deﬁned rules and then execute cer-
tain actions (e.g., mirror and encapsulate), which do not change
original packet forwarding behavior. Everﬂow leverages this
capability to reduce tracing overhead. Speciﬁcally, we de-
sign three types of matching rules to handle common DCN
faults (§2). This rule set is by no means exhaustive and can
be expanded to other types of faults.
First, we design matching rules to capture every ﬂow in
DCNs. The most straightforward rule is to randomly trace
1 out of n packets,2 which is heavily biased towards large
ﬂows. In a DCN where the ﬂow size distribution is highly
skewed, this approach will miss many small ﬂows. Yet these
small ﬂows are often associated with customer-facing, in-
teractive services with strict performance requirements. To
cover small ﬂows, we conﬁgure a new set of rules that match
based on the TCP SYN, FIN and RST ﬁelds in packets.
Since DCN trafﬁc is typically dominated by TCP [21], these
rules allow us to trace every TCP ﬂow in DCNs.
Second, we conﬁgure additional matching rules to enable
ﬂexible tracing. Basic TCP matching may not catch every
type of fault, e.g., the packet drops in the middle of a TCP
ﬂow. In fact, the exact set of traced packets that are needed
depends on the nature of the fault. For instance, we may
want to trace the packets of a particular application, with
a speciﬁc port number, or between certain pairs of servers.
To support such ﬂexible tracing, we allow the packets to be
marked by a special “debug” bit in the header. The marking
criteria can be deﬁned in any manner, as long as the total
tracing overhead stays below a threshold. In the switches,
we install a rule to trace any packet with the “debug” bit
2This differs from the random sampling in sFlow [29] –
Everﬂow ensures the same set of packets will be sam-
pled and traced across all switches while in sFlow different
switches may sample a different set of packets. That is one
of the reasons why we cannot use sFlow for tracing in our
system.
481(a) Passive tracing is insufﬁcient
(a) Encapsulation breaks the packet trace
(a) Extracting link latency from passive
tracing is hard
(b) Guided probing conﬁrms the
problem
Figure 1: Debugging packet
drops
(b) Guided probing can accurately mea-
sure link latency
Figure 2: Measuring link latency
(b) Obtaining the complete packet trace by
matching on inner header
Figure 3: Handling packet encapsula-
tion
set, which is similar to how a software developer sets the
debug ﬂag during compilation to enable ﬁne-grained tracing
in their code. As a result, Everﬂow can efﬁciently trace any
subset of regular data packets.
Finally, our tracing coverage goes beyond data packets. A
DCN has a small amount of trafﬁc associated with network
protocols such as BGP, PFC, and RDMA. We call it protocol
trafﬁc to distinguish from regular data trafﬁc. Although the
absolute volume of the protocol trafﬁc is small, it is critical
for the overall DCN health and performance. Thus, Everﬂow
has rules to trace all the protocol trafﬁc.
Scalable trace analyzers. Although matching rules limit
tracing overhead, the total amount of tracing trafﬁc can still
be huge because of the sheer scale of the DCN. To reduce
analysis overhead, we observe that at any time only a tiny
fraction of the traced packets ( 1 Tbps). This is at least 100
times faster than a server with a 10 Gbps NIC, and dramat-
ically cuts down the cost of reshufﬂing. We can further in-
crease reshufﬂing capacity by conﬁguring multiple HMuxes
with the same VIP [12].
We need to pay special attention to encapsulated packets.
(For now, let us ignore traced packets that are also encap-
sulated. We explain how to handle them in §6.1.) Packet
encapsulation is often used in DCNs for load balancing [28]
and network virtualization [24]. Fig 3(a) shows an example
of how a SLB (Software Load Balancer) Mux may break the
trace analysis. The original destination IP of a packet p is a
VIP (Virtual IP). A Mux will encapsulate p with a new DIP
(Direct IP) as the destination. Because of this, the traced
packets of the original p and the encapsulated p are sent to
two different analyzers, and are processed separately. To ad-
dress this problem, we install a rule that matches on the inner
header of an encapsulated packet, and conﬁgure HMuxes to
hash based on inner header ﬁelds. This allows us to trace p’s
complete path from source to DIP (see Fig 3(b)).
As mentioned earlier, a packet drop
Guided Probing.
could happen due to multiple reasons. Sometimes, passive
tracing alone may be insufﬁcient to disambiguate between
these possibilities. This ambiguity leads to the following
question: what if we could arbitrarily replay a packet trace?
More speciﬁcally, what if we could inject any desired packet
into any desired switch and trace the behavior of the injected
packet (by setting its debug bit)? We call this guided probing
and will describe it in more detail in §6.2.
One immediate use of guided probing is to recover the lost
482tracing information due to trace sampling or aggregation. To
recover the trace of any packet p, we simply need to inject p
into the ﬁrst hop switch (with its debug bit set).
Further, guided probing is useful in overcoming the lim-
itations of passive tracing. In the example of Fig 1(b), we
can inject multiple copies of p into switch S2 to see whether
p is dropped persistently or not. In addition, we can craft
probe packets with different patterns (e.g., 5-tuples) to see
if the drops are random or speciﬁc to certain 5-tuples. Such
probing cannot debug transient faults because they may dis-
appear before probing is initiated. We consider this limita-
tion acceptable because persistent faults usually have a more
severe impact than transient ones.
We extend guided probing such that it can not only inject
a packet into a desired switch but also cause a packet to tra-
verse a desired sequence of hops (similar to source routing).
This extension allows us to measure the roundtrip latency of
any link in the network, as illustrated in Fig 2(b). A probe
packet p is instructed to traverse S1 → S2 → S1. Because
p traverses S1 twice, S1 will generate two traced packets
of p at time t1 and t2 separately, and t2 − t1 equals to the
roundtrip latency of link (S1, S2).
Since many commodity switches today do not provide the
timestamping function, we cannot obtain t1 and t2 directly.
However, observer that the two traced packets of p are close
in time (e.g., within 1 ms) and take exactly the same path
from S1 to the analyzer. Thus we can use the difference in
their arrival time at the analyzer to approximate t2 − t1.
4. TRACE COLLECTION AND ANALYSIS
We now present the trace collection and analysis pipeline
of Everﬂow. As shown in Fig 4, it consists of four key
components: the controller, analyzer, storage and reshuf-
ﬂer. On top of that, there are a variety of applications that
use the packet-level information provided by Everﬂow to
debug network faults. The controller coordinates the other
components and interacts with the applications. During ini-
tialization, it conﬁgures the rules on switches. Packets that
match these rules will be mirrored to the reshufﬂers and the
directed to the analyzers which output the analysis results
into storage. The controller also provides APIs which allow
Everﬂow applications to query analysis results, customize
counters on the analyzers, inject guided probes, and mark
the debug bit on hosts. We describe the analyzer and con-
troller in this section and the reshufﬂer and storage in §6.
4.1 Analyzers
The analyzers are distributed set of servers, each of which
processes a portion of tracing trafﬁc. The reshufﬂers will
balance the loads among the analyzers and ensure that the
traced packets of the same 5-tuple are sent to the same ana-
lyzer (§3.2). Each analyzer keeps two type of states: packet
trace and counter.
Packet trace. The analyzer keeps a table of packet traces
where each trace is a chain of the mirrored instances of the
same original packet. A trace is uniquely identiﬁed by the
5-tuple and the IPID of the original packet. It has one copy
Figure 4: Everﬂow architecture
of the full packet content and a set of per-hop information,
including the IP address of the switch where the packet is
mirrored, timestamp, TTL, source MAC address (to identify
the previous hop), and DSCP/ECN. A trace is considered
complete when no new packet arrives for 1 second (which is
much smaller than the end-to-end latency inside a DCN).
For each complete packet trace, the analyzer checks for
two types of problems: loop and drop. A loop exhibits as
the same device appearing multiple times in the trace. A
drop is detected when the last hop of the trace is different
from the expected last hop(s) which can be computed using
the DCN topology and routing policy. For example, the ex-
pected last hop of a packet destined to an internal IP address
of the DCN is the ToR switch directly connected to the IP
address. The expected last hops of a packet destined to an
external IP address are the border switches of the DCN.
To correctly handle packet encapsulation due to SLB (see
Fig 3(a)), we merge the traces of an original packet po and an
encapsulated packet pe if the 5-tuple and IPID of pe’s inner
IP header match those of po’s IP header.
Despite of the use of match and mirror, the amount of
packet traces can still be huge. To further reduce the storage
overhead, each analyzer will only write to storage the traces
that exhibit abnormal behaviors (e.g., loop or drop), have the
debug bit set (e.g., guided probes), or correspond to the pro-
tocol trafﬁc (e.g., PFC and BGP). For the other traces (which
represent a vast majority of all traces), each analyzer will ag-
gregate them into the types of counters listed below and then
periodically (e.g., once every 10 seconds) write these coun-
ters into the storage. In the end, the controller combines the
counters from individual analyzers into the ﬁnal ones.
Link load counters. For each link, the analyzer will com-
pute the aggregate load (e.g., number of packets, bytes and
ﬂows) from the packet traces. Besides that, it may also com-
pute more ﬁne-grained load counters, e.g., the load gener-
ated by certain preﬁxes or by intra-DC trafﬁc. These ﬁne-
grained load counters can be dynamically added or removed
by Everﬂow applications via the controller.
Latency counters. The analyzer will compute the latency
of each link from the traces of guided probes (see §6.2).
For any packet trace that traverses a SLB Mux, it will also
483headers. For example, it allows ﬁltering based on whether
the traces contain a drop or a loop, or have a SLB Mux la-
tency larger than 1 ms (if the traces traverse a Mux).
GetCounter(Name, StartTime, EndTime) is used to re-
trieve the counter values between StartT ime and EndT ime.
Each counter is identiﬁed by a descriptive N ame, such as
“SwitchX_PortY_TCP”.
AddCounter(Name, Filter) & RemoveCounter(Name) are
used to dynamically add or remove ﬁne-grained load coun-
ters. The F ilter parameter is the same as above.
Probe(Format, Interval, Count) is used to launch guided
probes. The probing results can later be retrieved via GetT race()
and GetCounter(). The Interval and Count parameters
specify the frequency and total number of probes to send.
The F ormat parameter speciﬁes the format of the probe
packets, including the L3 and L4 headers. It is similar to
the F ilter parameter described above, with a minor change
to support packet encapsulation. For example, “ip.src ==
SIP1,SIP2 && ip.dst == DIP1,DIP2 && ip.proto == 6” de-
ﬁnes an IP-in-IP encapsulated TCP probe, whose outer source
IP is SIP1, outer destination IP is DIP1, inner source IP is
SIP2 and inner destination IP is DIP2.
EnableDbg(Servers, Filter) & DisableDbg(Servers, Fil-
ter) are used to mark or unmark packets with the debug bit on
certain servers. The F ilter parameter is the same as above.