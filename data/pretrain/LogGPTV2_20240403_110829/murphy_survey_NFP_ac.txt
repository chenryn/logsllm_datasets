FIGURE 1: Approximated behaviour of an RTTF prediction. The predicted RTTF will show more uncertainty and variance the further away from complete failure, and (ideally) the closer in time we are to the failure, the closer the predicted RTTF will align with the real RTTF. Then a cutoff threshold can be determined where the predicted RTTF is trustworthy enough compared to the cost of intervention, to make the decision to intervene.FIGURE 2: Generic failure prediction. A prediction decision is made at time T for the time interval of [T+X;T+X+Z] of duration Z. Decision thresholds, X and Z to be determined, depending on necessary prediction performance for the context.
Once those parameters are set and a prediction decision is taken based on a threshold value, we can try to evaluate the performance of the model.2) Measuring Prediction Performance
|  |  | Actual | Actual |
|---|---|---|---|
|  | |Positive |Negative |
| Predicted |Positive |True Positive |False Positive |
| Predicted |Negative |False Negative |True Negative |
TABLE 1: Classification of prediction results.
Usually when considering performance for network fault prediction (in the categorical mode), precision, recall, and
4 	VOLUME 4, 20224 	VOLUME 4, 2022
Murphy et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS
false positive rates are considered. Accuracy or F1-score can also be measured sometimes.
In order to calculate these prediction metrics, we compare the prediction results to the ground truth (actual values) and classify them accordingly following Table 1. We then use the number of elements of each class to calculate the following metrics.Precision is defined as the proportion of cases where the model predicted the positive class accurately (True Pos-itives), relative to the number of cases where the model predicted a data point as part of the positive class, irrespective of its correctness (True Positives + False Positives).
| Precision = | TP |
|---|---|
|  |TP + FP |
	where TP=Number of True Positives and FP=Number of False Positives.Recall is defined as the proportion of cases where the model predicted the positive class accurately (TP), relative to the total number of elements of the actual positive class (True Positives + False Negatives).
| eal  | TP |
|---|---|
| eal  |TP + FN |
where FN=Number of False Negatives.where FN=Number of False Negatives.
False Positive Rate (FPR), is defined as the proportion of cases where the model incorrectly predicted a member of the negative class as part of the positive class (False Positives), relative to the number of elements of the negative class (False Positives + True Negatives).
| FPR  | FP |
|---|---|
| FPR  |FP + TN |
where TN=Number of True Negativeswhere TN=Number of True Negatives
F1-score is a composite metrics based on Precision and Recall. The F1-score can only be high if both Precision and Recall scores are high, as can be seen in the formula below. Therefore it is often used. Another perspective is that maximizing the F1-score of a predictor minimizes both the number of False Positives and False Negatives.
F1 − score = 2 ∗Precision ∗ RecallF1 − score = 2 ∗Precision ∗ Recall
Accuracy represents the proportion of correct predictions (positive or negative) relative to all predictions made. This can be a good metric in cases where the classes are balanced.
| Acrcy= | TP + TN |
|---|---|
| Acrcy= |TP + TN + FP + FN |
III. EXPECTATIONS OF AN INDUSTRIALOne of the practical applications of Network Fault Predic-tion is for Internet Service Providers (ISPs) or Network and Systems Integrators (NSIs) that propose maintenance in operational condition services to predict incoming failures to enhance their failure response performance. Also, ISPs need to maintain their own network infrastructure in operational condition in order to provide their services to their clients and ensure the best QoS.In this case, the ability to predict the occurrence of network failure could procure a competitive edge in the maintenance of the network, to reduce operating costs and increase client satisfaction. In this section, we describe the necessary per-formance constraints that would be required of an NFP system, in order to be maximally useful for NSIs to maintain network operation. Technical input that was collected from an industrial actor in the field was used as a reference.NSIs respond to their clients’ network needs and integrate the best solution for them. Depending on the contracts, they are often also in charge of maintaining the clients’infrastructure in operational condition. The Service Level Agreement (SLA) that they sign with each client determines the conditions they must abide by in order to maintain contracted network performance. In case they do not respect these conditions, they expose themselves to penalties that can be very costly in certain cases (for example in critical infrastructure).The following information is gathered from a survey of professionals within SPIE ICS, an NSI. We present this information with the objective of giving a grounded practical view of NFP, but naturally the values vary depending on the context and the company and clients involved.Most contracts have different priorities for different net-work services and/or equipment, usually separated into three levels of priorities P1, P2, P3, from highest to lowest. The SLA stipulates the Maximum Time To Intervene (MTTI), and Maximum Time To Restore (MTTR) for network failures that the integrator must respect, and penalties to be paid when they do not respect the agreed-upon delays. The penalties are usually proportional to the excess time taken in restoring the network and they have a severe impact on the maintenance contract margin. Additionally not respecting the SLA delay has a large impact on customer satisfaction.These delay specifications depend on the priorities, and usually in SLAs, P1 equipments have an MTTI of around 20 minutes, meaning that the integrator must have someone starting to work on the failure 20 minutes after it is first detected (if the detection of the failures is incumbent on the operator) or after the client first declares it. The MTTR is usually about 4 hours for P1 failures, meaning the integrator must restore the failing service/equipments in less than four hours after detection/declaration of the incident (with the possibility of allowing for distinction between different types of working hours such as day-shift, night-shift, weekends, etc).Therefore, system integrators have a vested interest in
VOLUME 4, 2022 	5
Murphy et al.: Preparation of Papers for IEEE TRANSACTIONS and JOURNALSusing fault prediction models, as an effective and reliable prediction would enable them to gain more time to respond by taking a decision for early fault resolution. This would allow the NSI to be more competitive on the SLA terms offered, retain more margin by eliminating cases that exceed contractual MTTR, possibly preventing some types of failure from occurring and reducing maintenance costs. As the so-lutions improve, they could potentially also offer zero-failure network services with a network architecture that does not have excessive redundancy.Based on the previous information and insight into the needs and logistics involved in resolving network failures, a few criteria have been derived in order to measure usability of the different proposed models, in the environment of a maintained heterogeneous network. These elements are illustrated in Fig 3.
• Tad : Does the prediction allow enough time to run automatic preemptive diagnostics and mitigation on the networks ?• Tmd : Does the prediction allow enough time to run 	manual preemptive diagnostics on the networks ?
• Tmm : Does the prediction allow enough time to enact 	preemptive mitigative measures on the networks ?
• TL : Does the prediction allow enough time to de-ploy necessary logistics to replace the equipment before failure occurs ? Logistics constraints may vary greatly depending on time of day, geographical location of the failure and the NSI actor.The necessary time to run these diagnostics and actions depends on the state of the network and the weight of the operations that are run. However based on the professional experience of SPIE ICS, the following approximations can be given :
	• Tad ≈ 5 min
	• Tmd ≈ 30 min