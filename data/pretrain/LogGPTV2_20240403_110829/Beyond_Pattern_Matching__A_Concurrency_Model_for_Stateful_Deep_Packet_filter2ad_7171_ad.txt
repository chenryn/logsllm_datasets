6. EVALUATION
Experimental highlights. The goal of this section is to evaluate the
effectiveness of scope-based scheduling in light of the following
questions:
1. Is our concurrency model effective in exploiting the paral-
lelism present in network trafﬁc?
§6.3 shows that our approach is effective in distributing load
across multiple CPU cores. Throughput improvements are
signiﬁcant and only limited by the amount of parallelism
present in the trafﬁc.
2. Can scheduling functions be automatically determined via
static analysis?
The characterization presented in §6.4 shows that our anal-
ysis returns scheduling functions that are correct, perform
only simple stateless operations, and are close to minimal.
3. Does our approach bring improvements over traditional mul-
tiprogramming techniques?
Qualitative analysis in §6.5 suggests that our concurrency
model simpliﬁes writing and running efﬁcient IDS analyses,
as it transparently provides data isolation.
6.1 Benchmarks and Traces
To perform the evaluation we selected six “intrusion detection
kernels”, inspired either by existing literature or by discussions
with domain experts. Table 1 summarizes them.
These programs represent various classes of operations that IDSs
commonly perform; our goal is to evaluate how our technique works
on detectors of varying complexity and heterogeneous scopes. In
particular, Flowbytes and Httpvol model measurement scripts that
(a) Full trace
(b) Filtered trace
Figure 6: Thread load for full and ﬁltered trace
compute common trafﬁc statistics. Scandetect is an example of
cross-layer analysis. Multistep and Dnstunnel implement analy-
ses that correlate multiple events/ﬂows to detect suspicious activ-
ity. Finally, Sidejack is an example of a complex detection heuristic
whose scope is deﬁned inside the application layer (HTTP cookie).
We base our evaluation on a packet trace captured at the border
In order to obtain a real-
gateway of the UC Berkeley campus.
istic, diverse workload we recorded and merged the trafﬁc ﬂow-
ing through the campus IDS cluster—26 backend systems behind a
front-end load-balancer that splits up the total trafﬁc on a per-ﬂow
basis [40]—limiting it to the protocols of interest for our applica-
tions (HTTP, FTP, SSH, DNS, IRC). The resulting trace comprises
326GB in total volume, includes 349M packets, and covers a times-
pan of 15 min.
6.2 Analysis/Simulation Framework
One of the design goals of our approach is to be as architecture-
and platform-independent as possible. We therefore chose to im-
plement our benchmark in HILTI [38], an assembly-like language
designed to be a domain-speciﬁc yet abstract representation of traf-
ﬁc analysis tasks. HILTI provides a mix of basic instructions and
common high-level primitives (regexp matching, associative con-
tainers, etc.), and supports multithreading via lightweight virtual
threads. Code generation and execution are achieved using a LLVM-
based compiler and a dedicated runtime. In order to carry out our
slicing algorithms (§4), we augmented the HILTI toolchain with a
simple program analysis infrastructure.
The IDS pipeline outlined in Figure 2 consists of three stages:
low-level trafﬁc parsing, event scheduling, and high-level event
processing. Currently the HILTI runtime implements all the lan-
guage features (including multithreading), but lacks trafﬁc parsing
and event scheduling functionality. To sidestep this limitation, we
emulate the IDS pipeline by implementing the stages separately.
Each stage generates intermediate output on disk, which is then fed
to the next stage.
In more detail, we ﬁrst manually generate high-level events by
pre-processing the raw network trace with Bro. This distills our
network trace into an event trace which includes 298M high-level
events. Second, we generate scheduling functions by running our
algorithm on the HILTI implementation of our benchmarks. This
enables us to verify the correctness and quality of autogenerated
scheduling functions (results are discussed in §6.4). Furthermore,
we use the scheduling functions to partition the high-level event
trace from Stage 1 into sub-traces.
In the third stage, we instantiate a pool of HILTI analysis threads,
and we use a trace loader to feed each event sub-trace to a different
thread. Each thread performs all the analyses described in Table 1.
This setup faithfully reproduces how events would be distributed
among threads in a full system, and allows us to evaluate the perfor-
mance of multiple threads running within our concurrency model.
Results are discussed in §6.3. We run all of our experiments on a
64-bit Linux system with two quad-core Intel Xeon 5570 CPUs and
24GB of RAM.
6.3 Parallelism in Network Trafﬁc
This part of our evaluation addresses the issue of whether our
approach effectively exploits parallelism present in network trafﬁc.
In this experiment, we analyzed load balancing and throughput of
the system when running with 1 to 8 hardware threads. We used the
approach outlined above, partitioning the Bro event trace across the
analysis threads.
i = T N
i
T 1
1
Load balancing: For each run, we compute the load of each thread,
deﬁned as follows. Let N be the number of threads and T N
the pro-
i
cessing time for the i-th thread in the N-thread setting. The load
. In other words,
for the same thread is deﬁned as LN
“load” describes the processing time for a given thread in N-thread
setting, normalized to the processing time in the single-threaded
setting.
In an ideal situation where work is perfectly distributed
i = 1/N. In
among threads, the load for each thread i would be LN
practice, load deviates from the ideal, for two reasons. The ﬁrst is
that work is never perfectly distributed, resulting in threads whose
load is above or below the ideal (i.e., they perform either less or
more than their “fair share” of work). The second is that adding
more threads increases resource contention, imposing a certain ar-
chitectural overhead. Architectural overhead results in the average
thread load being greater than 1/N; the gap is expected to increase
as N increases (i.e., the overhead becomes more signiﬁcant as more
threads are added).
Figure 6(a) shows the maximum, minimum and average load
(relative to the single-threaded case) among all threads for each run.
We veriﬁed that all threads remain CPU-bound throughout the test.
First, we observe that the average load remains close to the ideal for
all the measurements. This shows that the architectural overhead
imposed by running multiple threads in parallel is limited (average
thread load is within 3% of the ideal). The ﬁgure however also
shows some imbalance in the distribution of load among threads.
12345678#Threads0.00.20.40.60.81.0Load (normalized to 1-thread case)Max loadAvg loadMin loadIdeal load12345678#Threads0.00.20.40.60.81.0Load (normalized to 1-thread case)Max loadAvg loadMin loadIdeal loadEffectiveness: Figure 8 presents simpliﬁed, high-level versions of
event handlers and respective scheduling functions from three of
our benchmarks for illustration. For most applications, scheduling
functions are minimal and perform simple struct ﬁeld extractions/-
concatenations. A few cases present opportunities for further op-
timization apparent to a human expert. For example, the function
returned for multistep’s ProtocolConﬁrmation (Figure 8b) performs
several checks that are not relevant, since the return value can be
determined purely by observing the protocol detected (proto).
Overall, results in this section suggest that our approach is effec-
tive in producing correct and compact scheduling functions.
Figure 7: Throughput increase as a function of #CPU cores
Such imbalance can limit the overall throughput, with some threads
being overloaded while other ones are not running at full capacity.
To explain this result, we investigated the composition of trafﬁc
in our trace. Similarly to previous studies [16], we found that the
distribution of data among hosts is asymmetric in nature, with the
25 busiest host pairs (of approximately 1M) accounting for 20%
of the data. Note that in a system with 8 cores each should carry
approximately 12.5% of the trafﬁc processing load to achieve per-
fect balancing. In our context, even a minor asymmetry in the load
distribution can have a signiﬁcant impact. In order to quantify this
impact, we repeated the experiment for the 1-, 2-, 4- and 8-thread
cases after ﬁltering out the top 25 host pairs. Results are reported
in Figure 6(b). As can be seen, variations in per-thread load are
signiﬁcantly more conﬁned around the average, leading to a more
evenly balanced workload. This supports our hypothesis that load
asymmetry is chieﬂy caused by a limited number of “fat ﬂows”.
We further discuss the issue in §7.
1
max(LN
i )
Throughput: For each experiment, we also computed the through-
put increase, deﬁned as I N =
. I N quantiﬁes the de-
crease in load (compared to the single-threaded case) for the busiest
thread in the N-thread setting. This deﬁnition, albeit simple, has
the advantage of allowing to estimate throughput without making
assumptions on how the system is implemented. In fact, in absence
of buffering and other optimizations, the busiest thread determines
the overall throughput. Results, depicted in Figure 7, reﬂect the
conclusion discussed in the context of load balancing. Through-
put improvement is signiﬁcant, although sensitive to asymmetries
in load distribution.
6.4 Characterization of Scheduling Functions
We implemented both the ﬂow-insensitive and ﬂow-sensitive al-
gorithms described in §4. They generate the same scheduling func-
tions for all benchmarks, except for multistep and sidejack, whose
slices contain conditional constructs—in this case, the ﬂow-sensitive
algorithm produces more precise results. Therefore, in this section
we only present results for the ﬂow-sensitive algorithm.
Correctness: To ensure correctness of our benchmark implementa-
tions, we initially run them sequentially on sample synthetic traces
and manually veriﬁed their output. The next step was to ensure that
the benchmarks keep working correctly when parallelized using the
scheduling functions generated by our algorithm. To do so we com-
pared the output of the parallelized and the sequential version on a
variety of test traces, verifying their equivalence.
6.5 Characterization of Concurrency Model
A relevant question is how our concurrency model fares—in terms
of ease of use and efﬁciency—compared to traditional multipro-
gramming techniques that make use of inter-thread synchroniza-
tion. In order to perform a qualitative comparison, we created an
alternative implementation of our benchmarks that relies on locks
to provide data isolation between threads. In this version, a sched-
uler distributes events randomly among threads, and analyses use
global locks to guard accesses to shared data structures.
When developing the benchmarks for our lock-free concurrency
model we were able to develop code in a single-threaded setting,
and directly reuse it in a parallel scenario. Conversely, implement-
ing the lock-based version required some modiﬁcations to ensure
critical sections were properly guarded. In terms of performance, as
expected the intensive use of locks led to little observable through-
put improvement as more threads were added (limited to 6% on
our traces). While switching to lock-free data structures is certainly
possible, this would add further complexity to the application and
runtime design. Moreover, each handler must at the very least hold
logical locks on the individual table element(s) while they are being
updated. Conversely, our approach guarantees ordering and mini-
mizes inter-thread synchronization by design, which proves to be a
natural ﬁt for programming IDS analyses.
7. DISCUSSION
Scheduler throughput: Scheduling functions are stateless and con-
sist mainly of short, straight-line code sequences, enabling high
scheduling throughput. Still, on a large system the scheduler could
potentially become a bottleneck, as it executes scheduling functions
on all incoming events. We note that many analyses tend to slice
trafﬁc using simple scopes, such as per-host or per-connection. The
IDS runtime can therefore provide highly optimized, “hardcoded”
versions of such scheduling functions. Another solutions to scale
further would be to parallelize the scheduler itself [30]. This can
however introduce ordering issues, which we discuss in the follow-
ing. We also note that not all events require scheduling decisions.
In particular, timed events—such as state expirations—are implic-
itly associated with the thread that generated the timer.
Event ordering: If low-level trafﬁc parsing and/or event schedul-
ing are parallelized at the connection level, events generated by dif-
ferent ﬂows may not reach the analyzer in order, as low-level pro-
cessing of different ﬂows may be performed by different threads.
This could affect high-level heuristics whose scope includes multi-
ple connections. A possible solution is to associate each event with
a timestamp, and to then use the timestamps to sort the threads’
input queues, as in [49]. Another approach is to make the detec-
tor agnostic to order, i.e., events are correlated as long as they are
received within a certain time interval.
12345678#Threads12345678Throughput increaseFull traceTrace w/o top-25 flowsIdeal speedupFigure 8: Examples of scheduling functions
Sharing data structures between applications: in our discussion
of the scheduling problem, we assumed that each application main-
tains its private data structures. In practice, separate trafﬁc analyses
may collaborate by sharing state. If their scopes are compatible, the
analyses can be treated as a single entity for scheduling purposes.
If this is not possible, the functionality of one of the analyses could
be replicated within the other. The resulting overhead may be ac-
ceptable if it allows the analyses to be independent.
Load-balancing: in §6.3 we showed that imperfect load-balancing
can limit throughput. We pinpointed the issue to a few high-bandwidth
ﬂows accounting for a signiﬁcant percentage of the total packet
stream. We note that this is an intrinsic limitation of hash-based ap-
proaches, determined by the amount of parallelism available in the
trace. Such trafﬁc would cause load imbalance even for IDSs that
perform per-ﬂow pattern matching, since each high-bandwidth ﬂow
would still be processed by a single thread. This limitation may be
acceptable; indeed hash-based approaches are currently used in de-
ployed systems, such as the NIDS cluster [40]. It should also be
noted that often a detector only needs to parse the ﬁrst few packets
of a ﬂow [29]. Therefore, processing of large ﬂows could be halted
after a certain byte threshold, preventing imbalance. An alternative
solution is to allow ﬂows to be remapped across cores, as in [36].
Customization: The goal of our work is to provide automatic and
transparent parallelization of IDS workloads. However, in certain
cases the user could want to further optimize the behavior of the
system by deﬁning the scheduling functions herself. Enabling this
is a matter of the API. In this scenario, our scheduling function
generator could be used as a programming aid, providing an initial
version of the function that the user could further reﬁne.
8. RELATED WORK
The challenge of IDS parallelization has been examined previ-