#### 自然语言推理问题（QNLI）  
QNLI 任务涉及确定给定问题是否可以通过所提供文档中的信息来回答。如果可以在文档中找到答案，则分配的标签是“符合”。相反，如果在文档中找不到答案，则分配的标签是“非蕴含”。  
如果您想使用 QNLI 模型，可以在  Hugging Face 模型中心找到它们。寻找带有“qnli”的型号。  
```  
SELECT pgml.transform(  
    inputs => ARRAY[  
        'Where is the capital of France?, Paris is the capital of France.'  
    ],  
    task => '{"task": "text-classification",   
              "model": "cross-encoder/qnli-electra-base"  
             }'::JSONB  
) AS qnli;  
```  
结果  
```  
[  
    {"label": "LABEL_0", "score": 0.9978110194206238}  
]  
```  
#### Quora 问题对 (QQP)  
Quora 问题对模型旨在评估两个给定问题是否是彼此的释义。该模型接受两个问题并分配一个二进制值作为输出。LABEL_0 表示问题是彼此的释义，LABEL_1 表示问题不是释义。用于此任务的基准数据集是 GLUE 基准中的 Quora Question Pairs 数据集，其中包含问题对及其相应标签的集合。  
如果你想使用 QQP 模型，你可以在 Hugging Face 模型中心找到它们。寻找带有qqp.  
```  
SELECT pgml.transform(  
    inputs => ARRAY[  
        'Which city is the capital of France?, Where is the capital of France?'  
    ],  
    task => '{"task": "text-classification",   
              "model": "textattack/bert-base-uncased-QQP"  
             }'::JSONB  
) AS qqp;  
```  
结果  
```  
[  
    {"label": "LABEL_0", "score": 0.9988721013069152}  
]  
```  
#### 语法正确性 (是否胡说八道, 逻辑是否正确.)  
语言可接受性是一项涉及评估句子语法正确性的任务。用于此任务的模型将两个类别之一分配给句子，“可接受”或“不可接受”。LABEL_0 表示可接受，LABEL_1 表示不可接受。用于训练和评估此任务模型的基准数据集是语言可接受性语料库 (CoLA)，它由文本及其相应标签的集合组成。  
如果您想使用语法正确性模型，可以在  Hugging Face 模型中心找到它们。寻找带有cola.  
```  
SELECT pgml.transform(  
    inputs => ARRAY[  
        'I will walk to home when I went through the bus.'  
    ],  
    task => '{"task": "text-classification",   
              "model": "textattack/distilbert-base-uncased-CoLA"  
             }'::JSONB  
) AS grammatical_correctness;  
```  
结果  
```  
[  
    {"label": "LABEL_1", "score": 0.9576480388641356}  
]  
```  
### 零样本分类  
零样本分类是一项模型预测在训练阶段未见过的类的任务。该任务利用预先训练的语言模型，是一种迁移学习。迁移学习涉及使用最初针对不同应用程序中的一项任务进行训练的模型。当手头的特定任务缺乏可用的标记数据时，零样本分类特别有用。  
在下面提供的示例中，我们将演示如何将给定句子分类为模型以前未遇到过的类。为了实现这一点，我们在 SQL 查询中使用它args，它允许我们提供candidate_labels. 您可以自定义这些标签以适合您的任务上下文。我们将使用facebook/bart-large-mnli模型。  
在  Hugging Face 模型中心寻找mnli使用零样本分类模型的模型。  
```  
SELECT pgml.transform(  
    inputs => ARRAY[  
        'I have a problem with my iphone that needs to be resolved asap!!'  
    ],  
    task => '{  
                "task": "zero-shot-classification",   
                "model": "facebook/bart-large-mnli"  
             }'::JSONB,  
    args => '{  
                "candidate_labels": ["urgent", "not urgent", "phone", "tablet", "computer"]  
             }'::JSONB  
) AS zero_shot;  
```  
结果  
```  
[  
    {  
        "labels": ["urgent", "phone", "computer", "not urgent", "tablet"],   
        "scores": [0.503635, 0.47879, 0.012600, 0.002655, 0.002308],   
        "sequence": "I have a problem with my iphone that needs to be resolved asap!!"  
    }  
]  
```  
### 标记分类  
标记分类是自然语言理解中的一项任务，其中标签被分配给文本中的某些标记。标记分类的一些流行子任务包括命名实体识别 (NER) 和词性 (PoS) 标记。可以训练 NER 模型来识别文本中的特定实体，例如个人、地点和日期。另一方面，PoS 标记用于识别文本中的不同词性，例如名词、动词和标点符号。  
#### 命名实体识别  
命名实体识别 (NER) 是一项涉及识别文本中的命名实体的任务。这些实体可以包括人名、位置或组织的名称。该任务是通过为每个命名实体标记每个标记的类以及为不包含任何实体的标记标记“0”的类来完成的。在此任务中，输入是文本，输出是带有命名实体的注释文本。  
识别出位置、人名等.  
```  
SELECT pgml.transform(  
    inputs => ARRAY[  
        'I am Omar and I live in New York City.'  
    ],  
    task => 'token-classification'  
) as ner;  
```  
结果  
```  
[[  
    {"end": 9,  "word": "Omar", "index": 3,  "score": 0.997110, "start": 5,  "entity": "I-PER"},   
    {"end": 27, "word": "New",  "index": 8,  "score": 0.999372, "start": 24, "entity": "I-LOC"},   
    {"end": 32, "word": "York", "index": 9,  "score": 0.999355, "start": 28, "entity": "I-LOC"},   
    {"end": 37, "word": "City", "index": 10, "score": 0.999431, "start": 33, "entity": "I-LOC"}  
]]  
```  
#### 词性 (PoS) 标记  
PoS 标记是一项涉及识别给定文本中词性的任务，例如名词、代词、形容词或动词。在此任务中，模型用特定词性标记每个单词。  
在  Hugging Face 模型中心寻找pos使用零样本分类模型的模型。  
```  
select pgml.transform(  
	inputs => array [  
  	'I live in Amsterdam.'  
	],  
	task => '{"task": "token-classification",   
              "model": "vblagoje/bert-english-uncased-finetuned-pos"  
    }'::JSONB  
) as pos;  
```  
结果  
```  
[[  
    {"end": 1,  "word": "i",         "index": 1, "score": 0.999, "start": 0,  "entity": "PRON"},  
    {"end": 6,  "word": "live",      "index": 2, "score": 0.998, "start": 2,  "entity": "VERB"},  
    {"end": 9,  "word": "in",        "index": 3, "score": 0.999, "start": 7,  "entity": "ADP"},  
    {"end": 19, "word": "amsterdam", "index": 4, "score": 0.998, "start": 10, "entity": "PROPN"},   
    {"end": 20, "word": ".",         "index": 5, "score": 0.999, "start": 19, "entity": "PUNCT"}  
]]  
```  
### 翻译  
翻译是将一种语言编写的文本转换为另一种语言的任务。  
您可以从 Hugging Face中心的 2000 多个模型中进行选择进行翻译。  
```  
select pgml.transform(  
    inputs => array[  
            	'How are you?'  
    ],  
	task => '{"task": "translation",   
              "model": "Helsinki-NLP/opus-mt-en-fr"  
    }'::JSONB	  
);  
```  
结果  
```  
[  
    {"translation_text": "Comment allez-vous ?"}  
]  
```  
### 摘要总结文本中心思想  
摘要涉及创建文档的精简版本，其中包含重要信息，同时减少其长度。可以使用不同的模型来完成此任务，一些模型从原始文档中提取最相关的文本，而其他模型则生成捕获原始内容本质的全新文本。  
```  
select pgml.transform(  
	task => '{"task": "summarization",   
              "model": "sshleifer/distilbart-cnn-12-6"  
    }'::JSONB,  
	inputs => array[  
	'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of Île-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.'  
	]  
);  
```  
结果  
```  
[  
    {"summary_text": " Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018 . The city is the centre and seat of government of the region and province of Île-de-France, or Paris Region . Paris Region has an estimated 18 percent of the population of France as of 2017 ."}  
]  
```  
min_length您可以通过将和max_length作为参数传递给SQL 查询来控制summary_text 的长度。  
```  
select pgml.transform(  
	task => '{"task": "summarization",   
              "model": "sshleifer/distilbart-cnn-12-6"  
    }'::JSONB,  
	inputs => array[  
	'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018, in an area of more than 105 square kilometres (41 square miles). The City of Paris is the centre and seat of government of the region and province of Île-de-France, or Paris Region, which has an estimated population of 12,174,880, or about 18 percent of the population of France as of 2017.'  
	],  
	args => '{  
            "min_length" : 20,  
            "max_length" : 70  
	}'::JSONB  
);  
[  
    {"summary_text": " Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018 . City of Paris is centre and seat of government of the region and province of Île-de-France, or Paris Region, which has an estimated 12,174,880, or about 18 percent"  
    }    
]  
```  
### 阅读理解: 通过给出的一段内容的信息中, 回答问题.   
问答模型旨在从给定文本中检索问题的答案，这对于在文档中搜索信息特别有用。值得注意的是，一些问答模型即使没有任何上下文信息也能够生成答案。  
```  
SELECT pgml.transform(  
    'question-answering',  
    inputs => ARRAY[  
        '{  
            "question": "Where do I live?",  
            "context": "My name is Merve and I live in İstanbul."  
        }'  
    ]  
) AS answer;  
```  
结果  
```  
{  
    "end"   :  39,   
    "score" :  0.9538117051124572,   
    "start" :  31,   
    "answer": "İstanbul"  
}  
```  
### 文本生成: 讲故事  
文本生成是生成新文本的任务，例如填充不完整的句子或解释现有文本。它有各种用例，包括代码生成和故事生成。完成生成模型可以预测文本序列中的下一个单词，而文本到文本生成模型则经过训练以学习文本对之间的映射，例如在语言之间进行翻译。流行的文本生成模型包括基于 GPT 的模型、T5、T0 和 BART。这些模型可以经过训练来完成广泛的任务，包括文本分类、摘要和翻译。  
```  
SELECT pgml.transform(  
    task => 'text-generation',  
    inputs => ARRAY[  
        'Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone'  
    ]  
) AS answer;  
```  
结果  
```  
[  
    [  
        {"generated_text": "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone, and eight for the Dragon-lords in their halls of blood.\n\nEach of the guild-building systems is one-man"}  
    ]  
]  
```  
要使用  模型中心中的特定模型，请在任务中传递模型名称和任务名称。  
```  
SELECT pgml.transform(  
    task => '{  
        "task" : "text-generation",  
        "model" : "gpt2-medium"  
    }'::JSONB,  
    inputs => ARRAY[  
        'Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone'  
    ]  
) AS answer;  
```  
结果  
```  
[  
    [{"generated_text": "Three Rings for the Elven-kings under the sky, Seven for the Dwarf-lords in their halls of stone.\n\nThis place has a deep connection to the lore of ancient Elven civilization. It is home to the most ancient of artifacts,"}]  
]  
```  
要使生成的文本更长，您可以包含参数max_length并指定所需的文本最大长度。  
```  
SELECT pgml.transform(  
    task => '{  
        "task" : "text-generation",  
        "model" : "gpt2-medium"  
    }'::JSONB,  
    inputs => ARRAY[  