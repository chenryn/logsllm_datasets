12
25
5
97
3
2
1
0
−1
−2
−3
201
02−12−04
75
4
85
338
−1.5
−1
−0.5
0
0.5
1
1.5
2
2.5
3
−4
−3
−2
−1
0
1
2
3
4
5
−3
−2
−1
0
1
2
3
Fig. 11. Intrusion detection by Seurat: Seurat identiﬁed a new cluster of three hosts on Feb 11,
2004, when we manually launched the Lion worm.
File ID. File name
File ID. File name
1
2
3
4
5
6
7
8
9
10
11
/sbin/asp
/dev/.lib
/dev/.lib/star.sh
/var/spool/mail/root
/dev/.lib/bind
/etc/hosts.deny
/dev/.lib/randb
/sbin
/var/log
/dev/.lib/bindname.log
/dev/.lib/index.htm
12
13
14
15
16
17
18
19
20
21
22
/var/spool/mail
/dev/.lib/bindx.sh
/tmp/ramen.tgz
/dev/.lib/scan.sh
/dev/.lib/pscan
/var/spool/mqueue
/dev/.lib/hack.sh
/dev/.lib/.hack
/dev/.lib/index.html
/dev/.lib/asp62
/var/log/sendmail.st
Fig. 12. Suspicious ﬁles for the new cluster on Feb 11, 2004.
well as the list of suspicious ﬁles can be marked for future detection. If, in the following
days, there are more hosts that are clustered together with the already infected machines,
or experience the same ﬁle updates, then we may conclude they are infected by the same
attack.
5 Discussion
5.1 Vulnerabilities and Limitations
By identifying parallel occurrences of coincident events, Seurat will be most successful
in detecting virus or worm propagations that result in ﬁle modiﬁcations at multiple
hosts. Certain attacks (e.g., password guessing attacks) that succeed only once or a few
times in a network system may evade Seurat detection. The current prototype of Seurat
also has limited detection capability to the following types of attacks.
Stealthy attack. Attackers may try to evade detection by slowing attack propagation. If
an attacker is patient enough to infect only one host a day in the monitored network
system, Seurat will not notice the intrusion with the current one-day detection window
because Seurat focuses only on anomalous ﬁle changes common across multiple hosts.
Seurat: A Pointillist Approach to Anomaly Detection
253
A larger detection window such as a couple of days or a week can help to catch slow,
stealthy attacks. Note, however, that Seurat notices the attacks only after multiple hosts
in the network system are compromised. In other words, if an attack propagates slowly,
Seurat may not recognize the attack for the ﬁrst few days after the initial successful
compromise. There is thus a tradeoff between detection rate and detection latency.
Mimicry attack. An attacker can carefully design his attack to cause ﬁle updates that
look similar to regular ﬁle changes, and mount a successful mimicry attack [21]. There
are two ways to achieve a mimicry attack against the current prototype. First, an at-
tacker may try to fool Seurat’s feature selection process by camouﬂaging all intrusion
ﬁles as frequently, regularly updated ﬁles. Those concealed ﬁles, even when they are
modiﬁed in an unexpected way (e.g., entries removed from append-only log ﬁles), will
not be selected as feature vector dimensions because of current use of the binary feature
representation. Note that Seurat’s data collection tool provides additional information
on ﬁle system changes, such as ﬁle size, ﬁle content digest, and permissions. By in-
corporating the extra information in representing host state transition, Seurat can make
such mimicry attacks harder. Second, an attacker may ﬁnd a way to cloak abnormal ﬁle
updates with many normal but irregular changes during Seurat’s clustering process. For
example, in Section 4.2, we observed that the false negative rate of detecting the Kork
worm was relatively higher due to the interference of irregular system reconﬁguration.
We leave it as future work to quantify this type of mimicry attack and the effectiveness
of possible counter measures.
Random-ﬁle-access attack. Seurat correlates ﬁle updates based on their complete path
names. Thus attackers can try to evade Seurat by installing attack ﬁles under different
directories at different hosts, or replacing randomly chosen existing ﬁles with attack
ﬁles. Many recent email viruses already change the virus ﬁle names when they propa-
gate to a new host; we envision similar techniques could be employed by other types of
attacks soon. Note, however, that even the random-ﬁle-access attack may need a few an-
chor ﬁles at ﬁxed places, where Seurat still has the opportunity to detect such attacks. A
more robust representation of a ﬁle, for example, an MD5 checksum, could help Seurat
detect random-ﬁle-access attacks.
Memory-resident attack. Memory-resident and BIOS-resident only attacks make no ﬁle
system updates. Thus Seurat will not be able to detect memory resident attacks by
examining host ﬁle updates, nor those attacks that erase disk evidence before the Seurat
data collection tool performs the scheduled disk scan.
Kernel/Seurat modiﬁcation attack. The effectiveness of Seurat relies on the correctness
of reports from the data collecting tools running on distributed hosts. So the host ker-
nels and the Seurat data collection tools should run on machines protected by trusted
computing platforms [22]. An alternative solution is to monitor ﬁle system changes in
real time (will be discussed further in Section 5.2) and to protect ﬁle update logs using
secure audit logging [23].
5.2 Future Work
Real-time anomaly detection. The current prototype periodically scans and reports ﬁle
system updates with a 1-day cycle, which may be slow to detect fast propagating at-
254
Yinglian Xie et al.
tacks. To shorten detection latency, we are enhancing the Seurat data collection module
to monitor system calls related with ﬁle updates, and report the changes immediately to
the correlation module. The reported ﬁle updates will be instantly reﬂected by setting
the corresponding bits in the feature vectors at the Seurat correlation module, which
continuously performs clustering of the new feature vectors for real time anomaly de-
tection.
Distributed correlation module. Currently, Seurat moves the daily reports from dis-
tributed data collection tools to a centralized server, where the correlation module com-
putes and clusters the host vectors. Despite the simplicity of centralized deployment, the
centralized approach exposes Seurat to problems in scalability and reliability. First, the
amount of report data to be transferred to and stored at the centralized server is large. In
our experience, a host generates a ﬁle update report of 3K-140KBytes daily in a com-
pressed format, so the aggregate report size from hundreds or thousands of hosts with a
long comparison window will be large. The report size will be larger when Seurat’s data
collection tool reports the host state changes in real time. Second, the monitored hosts
could be in different administrative domains (i.e., hosts managed by different academic
departments or labs) and it is often impractical to transfer the detailed reports from all
the hosts to one centralized server due to privacy and conﬁdentiality issues. Third, the
centralized server can be a single point-of-failure. It is important for Seurat to work
even when one correlation server is broken or a part of network is partitioned. A dis-
tributed correlation module will cope with those issues. We are now investigating meth-
ods to correlate ﬁle update events in a distributed architecture such as EMERALD [1],
AAFID [24], and Mingle [25].
Other applications. The approach of clustering coincident host state changes can be
generalized to other types of applications such as detecting the propagation of spyware,
illegal ﬁle sharing events, or erroneous software conﬁguration changes. We are currently
deploying Seurat on Planetlab [26] hosts for detecting software conﬁguration errors by
identifying host state vectors that do not fall into an expected cluster.
6 Related Work
Seurat uses ﬁle system updates to represent a host state change. File system updates
have been known to be useful information for intrusion detection. Tripwire [4], AIDE
[8], Samhain [27] are well-known intrusion detection systems that use ﬁle system up-
dates to ﬁnd intrusions. Recently proposed systems such as the storage-based intrusion
detection systems [7] and some commercial tools [28] support real-time integrity check-
ing. All of them rely on a pre-deﬁned rule set to detect anomalous integrity violation,
while Seurat diagnoses the anomaly using learning and correlation across time and
space.
Leveraging the information gathered from distributed multiple measurement points
is not a new approach. Many researchers have noticed the potential of the collective
approaches for intrusion detection or anomaly detection. Graph-based Intrusion De-
tection System (GrIDS) [29] detects intrusions by building a graph representation of
network activity based on the report from all the hosts in a network. Different from
Seurat, GrIDS uses the TCP/IP network activity between hosts in the network to infer
Seurat: A Pointillist Approach to Anomaly Detection
255
patterns of intrusive or hostile activities based on pre-deﬁned rules. Other systems, such
as Cooperative Security Managers (CSM) [30], Distributed Intrusion Detection System
(DIDS) [31], also take advantage of a collective approach to intrusion detection. They
orchestrate multiple monitors watching multiple network links and track user activity
across multiple machines.
EMERALD (Event Monitoring Enabling Responses to Anomalous Live Distur-
bances) [1] and Autonomous Agents For Intrusion Detection (AAFID) [24] have in-
dependently proposed distributed architectures for intrusion detection and response ca-
pability. Both of them use local monitors or agents to collect interesting events and
anomaly reports (from a variety of sources; audit data, network packet traces, SNMP
trafﬁc, application logs, etc.). The architectures provide the communication methods to
exchange the locally detected information and an easy way to manage components of
the systems. AAFID performs statistical proﬁle-based anomaly detection and EMER-
ALD supports a signature-based misuse analysis in addition to the proﬁle-based
anomaly detection. Note that Seurat starts with similar motivation. But Seurat focuses
more on the technique for correlating the collective reports for anomaly detection, and
infers interesting information on the system state from learning, rather than relying on a
pre-deﬁned set of events or rules. We envision Seurat as a complementary technique, not
as a replacement of the existing architectures that provide global observation sharing.
Correlating different types of audit logs and measurement reports is another active
area in security research. Many researchers have proposed to correlate multiple het-
erogeneous sensors to improve the accuracy of alarms [3, 32, 33, 2, 34]. In this work,
we attempt to correlate information gathered by homogeneous monitors (especially, the
ﬁle system change monitors) but we may enhance our work to include different type of
measurement data to represent individual host status.
Wang et al. [35] also have noticed the value of spatial correlation of multiple sys-
tem conﬁgurations and applied a collective approach to tackle misconﬁguration trouble
shooting problems. In their system, a malfunctioning machine can diagnose its problem
by collecting system conﬁguration information from other similar and friendly hosts
connected via a peer-to-peer network. The work does not target automatic detection of
the anomaly, but rather it aims at ﬁguring out the cause of a detected problem.
7 Conclusions
In this paper, we presented a new “pointillist” approach for detecting aggregated anoma-
lous events by correlating information about host ﬁle updates across both space and
time. Our approach explores the temporal and spatial locality of system state changes
through learning and correlation. It requires neither prior knowledge about normal host
activities, nor system speciﬁc rules.
A prototype implementation, called Seurat, suggests that the approach is effective in
detecting rapidly propagating attacks that modify host ﬁle systems. The detection rate
degrades as the stealthiness of attacks increases. By trading off detection latency, we
are also able to identify hosts that are compromised by slowly propagating attacks. For
each alarm, Seurat identiﬁes suspicious ﬁles and hosts for further investigation, greatly
facilitating root cause diagnosis and false alarm suppression.
256
Yinglian Xie et al.
References
1. Porras, P.A., Neumann, P.G.: EMERALD: Event Monitoring Enabling Responses to Anoma-
lous Live Disturbances. In: Proceedings of the 20th National Information Systems Security
Conference. (1997)
2. Abad, C., Taylor, J., Sengul, C., Zhou, Y., Yurcik, W., Rowe, K.: Log Correlation for Intru-
sion Detection: A Proof of Concept. In: Proceedings of the 19th Annual Computer Security
Applications Conference, Las Vegas, Nevada, USA (2003)
3. Kruegel, C., Toth, T., Kerer, C.: Decentralized Event Correlation for Intrusion Detection. In:
International Conference on Information Security and Cryptology (ICISC). (2001)
4. Tripwire, Inc.: Tripwire. (http://www.tripwire.com)
5. CERT Coordination Center: Overview of Attack Trends. http://www.cert.org/
archive/pdf/attack_trends.pdf (2002)
6. Moore, D., Paxson, V., Savage, S., Shannon, C., Staniford, S., Weaver, N.: Inside the Slam-
mer Worm. IEEE Security and Privacy 1 (2003) 33–39
7. Pennington, A., Strunk, J., Grifﬁn, J., Soules, C., Goodson, G., Ganger, G.: Storage-based
intrusion detection: Watching storage activity for suspicious behavior. In: Proceedings of
12th USENIX Security Symposium, Washington, DC (2003)
8. Lehti, R., Virolainen, P.: AIDE - Advanced Intrusion Detection Environment. (http://
www.cs.tut.fi/˜rammer/aide.html)
9. Berry, M.W., Drmac, Z., Jessup, E.R.: Matrices, vector spaces, and information retrieval.
SIAM Review 41 (1999)
10. Kamber, M.: Data mining: Concepts and techniques. Morgan Kaufmann Publishers (2000)
11. Zhang, J., Tsui, F., Wagner, M.M., Hogan, W.R.: Detection of Outbreaks from Time Series
Data Using Wavelet Transform. In: AMIA Fall Symp., Omni Press CD (2003) 748–752
12. Jolliffe, I.T.: Principle component analysis. Spring-Verlag, New York (1986)
13. Forgy, E.: Cluster analysis of multivariante data: Efﬁciency vs. Interpretability of classiﬁca-
tions. Biometrics 21 (1965)
14. Gersho, A., Gray, R.: Vector Quantization and Signal Compresssion. Kluwer Academic Pub-
lishers (1992)
15. Moore, A.: K-means and Hierarchical Clustering. http://www.cs.cmu.edu/˜awm/
tutorials/kmeans09.pdf (available upon request) (2001)
16. Symantec: Symantec Security Response. (http://securityresponse.symantec.
com)
17. F-Secure: F-Secure Security Information Center.
(http://www.f-secure.com/
virus-info)
18. Whitehats, Inc.: Whitehats Network Security Resource. (http://www.whitehats.
com)
19. PacketStorm: Packet Storm. (http://www.packetstormsecurity.org)
20. SANS Institute: Lion Worm. http://www.sans.org/y2k/lion.htm (2001)
21. Wagner, D., Dean, D.: Mimicry Attacks on Host-Based Intrusion Detection Systems. In:
Proceedings of ACM Conference on Computer and Communications Security (CCS). (2002)
22. Trusted Computing Platform Alliance: Trusted Computing Platform Alliance. (http://
www.trustedcomputing.org)
23. Schneier, B., Kelsey, J.: Cryptographic Support for Secure Logs on Untrusted Machines. In:
The Seventh USENIX Security Symposium. (1998)
24. Balasubramaniyan, J.S., Garcia-Fernandez, J.O., Isacoff, D., Spafford, E., Zamboni, D.: An
architecture for intrusion detection using autonomous agents. In: Proceedings of the 14th
IEEE Computer Security Applications Conference. (1998)
Seurat: A Pointillist Approach to Anomaly Detection
257
25. Xie, Y., O’Hallaron, D.R., Reiter, M.K.: A Secure Distributed Search System. In: Proceed-
ings of the 11th IEEE International Symposium on High Performance Distributed Comput-
ing. (2002)
26. Planetlab: PlanetLab. (http://www.planet-lab.org)
27. Samhain Labs: Samhain. (http://la-samhna.de/samhain)
28. Pedestal Software: INTACTTM.
(http://www.pedestalsoftware.com/products/intact)
29. Cheung, S., Crawford, R., Dilger, M., Frank, J., Hoagland, J., Levitt, K., Rowe, J., Staniford-
Chen, S., Yip, R., Zerkle, D.: The Design of GrIDS: A Graph-Based Intrusion Detection
System. Technical Report CSE-99-2, U.C. Davis Computer Science Department (1999)
30. White, G., Fisch, E., Pooch, U.: Cooperating security managers: A peer-based intrusion de-
tection system. IEEE Network 10 (1994)
31. Snapp, S.R., Smaha, S.E., Teal, D.M., Grance, T.: The DIDS (distributed intrusion detec-
tion system) prototype. In: the Summer USENIX Conference, San Antonio, Texas, USENIX
Association (1992) 227–233
32. Valdes, A., Skinner, K.: Probabilistic Alert Correlation. In: Recent Advances in Intrusion
Detection, Volume 2212 of Lecture Notes in Computer Science, Springer-Verlag (2001)
33. Andersson, D., Fong, M., Valdes, A.: Heterogeneous Sensor Correlation: A Case Study of
Live Trafﬁc Analysis. Presented at IEEE Information Assurance Workshop (2002)
34. Ning, P., Cui, Y., Reeves, D.S.: Analyzing Intensive Intrusion Alerts Via Correlation. In: Re-
cent Advances in Intrusion Detection, Volume 2516 of Lecture Notes in Computer Science,
Springer-Verlag (2002)
35. Wang, H., Hu, Y., Yuan, C., Zhang, Z.: Friends Troubleshooting Network: Towards Privacy-
Preserving, Automatic Troubleshooting. In: Proceedings of the 3rd International Workshop
on Peer-to-Peer Systems (IPTPS). (2004)