title:Network discovery from passive measurements
author:Brian Eriksson and
Paul Barford and
Robert D. Nowak
Network Discovery from Passive Measurements
Brian Eriksson
UW-Madison
PI:EMAIL
Paul Barford
UW-Madison
PI:EMAIL
Robert Nowak
UW-Madison
PI:EMAIL
ABSTRACT
Understanding the Internet’s structure through empirical
measurements is important in the development of new topol-
ogy generators, new protocols, traﬃc engineering, and trou-
bleshooting, among other things. While prior studies of In-
ternet topology have been based on active (traceroute-like)
measurements, passive measurements of packet traﬃc oﬀer
the possibility of a greatly expanded perspective of Internet
structure with much lower impact and management over-
head. In this paper we describe a methodology for inferring
network structure from passive measurements of IP packet
traﬃc. We describe algorithms that enable 1) traﬃc sources
that share network paths to be clustered accurately without
relying on IP address or autonomous system information,
2) topological structure to be inferred accurately with only
a small number of active measurements, 3) missing infor-
mation to be recovered, which is a serious challenge in the
use of passive packet measurements. We demonstrate our
techniques using a series of simulated topologies and empir-
ical data sets. Our experiments show that the clusters es-
tablished by our method closely correspond to sources that
actually share paths. We also show the trade-oﬀs between
selectively applied active probes and the accuracy of the in-
ferred topology between sources. Finally, we characterize
the degree to which missing information can be recovered
from passive measurements, which further enhances the ac-
curacy of the inferred topologies.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network
Operations—Network Monitoring
Keywords
Topology, Embedding, Measurement, Inference, Imputation
General Terms
Measurement, Algorithms
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’08, August 17–22, 2008, Seattle, Washington, USA.
Copyright 2008 ACM 978-1-60558-175-0/08/08 ...$5.00.
1.
INTRODUCTION
Discovering and characterizing Internet structure and
topology through empirical measurements has been an ac-
tive research area for some time (e.g., [2, 15, 17, 22, 31]).
These studies have helped to shed light on the huge size,
intricate interconnection characteristics and complicated in-
terplay between underlying physical topology and the traﬃc
that ﬂows over the infrastructure. Most prior work on mea-
suring the Internet’s structure has been based on active mea-
surement techniques that use traceroute-like tools or tomo-
graphic probing, and there are several large on-going topol-
ogy discovery projects based on active probe-based tools
(e.g., [5, 29, 21]).
There are three important limitations in the use of active
probe-based tools for Internet topology discovery. First, the
vast size of the Internet means that a set of measurement
hosts M and target hosts N where N (cid:192) M must be estab-
lished in order for the resultant measurements to capture
the diverse features of the infrastructure (especially on the
edges of the network [4]). Second, active probes sent from
monitors to the large set of target hosts result in a signif-
icant traﬃc load and complex management issues. Third,
service providers frequently attempt to thwart structure dis-
covery by e.g., ﬁltering ICMP packets, which renders stan-
dard topology discovery tools like traceroute ineﬀective.
In this paper we investigate the problem of Internet-
wide structure and topology discovery from passive measure-
ments. Our objective is to develop techniques for inferring
meaningful structural characteristics such as client groups
and shared paths using only very simple passive measure-
ments – speciﬁcally the source IP address and TTL ﬁelds
from IP packet headers. We argue that these simple mea-
surements can be widely collected without signiﬁcant man-
agement overhead, and oﬀer an opportunity to greatly ex-
pand the perspective of Internet structure due to the diver-
sity of traﬃc observed in passive monitors [9, 10].
There are signiﬁcant challenges in using passive packet
measurements for discovering Internet structure. First, and
most importantly, the individual measurements themselves
would seem to convey almost no information about network
structure. Second, source IP addresses are often considered
sensitive and are typically subject to privacy constraints.
We address the latter, to an extent, by only using source
IP addresses as unique identiﬁers of hosts (i.e., source IP
addresses could be anonymized, as long as anonymization
is consistent across measurements and monitors). Unfortu-
nately, this further complicates the structure discovery prob-
lem. Despite these severe limitations, we demonstrate two
surprising capabilities in this paper:
1. Internet sources1 can be automatically and accurately
clustered into meaningful groups corresponding to
shared network topology;
2. Network topology can be accurately recovered from
large volumes of passive data when coupled with a very
small number of additional active measurements.
Our methodology for inferring network structure from
passive measurements begins by using a standard technique
to determine the hop-count distance between sending hosts
and passive monitors [18]. It is not uncommon to observe
packets from an individual source in several of the passive
monitors, resulting in a hop-count distance vector for that
source. These vectors provide an indication of the topologi-
cal location of the source relative to the monitors. Consid-
ering all such sources and hop-count vectors places a large
number of constraints on the underlying topology relating
sources and monitors.
Sources can then be clustered by examining similarities
in hop-count vectors. Sources within a client group [20] or
(stub) autonomous systems will have similar hop-count vec-
tors. Thus, two sources with identical hop-count vectors
are likely to be topologically close together. We also ob-
serve that sources from a common topological location may
have hop-count vectors that diﬀer only by a constant oﬀ-
set, owing to the fact that they may have diﬀerent paths
to network egress points, but then share routes to passive
monitors. These oﬀsets can be eliminated by removing the
average value of each hop-count vector, resulting in what we
call a hop-count contrast. The hop-count contrasts of two
sources from the same area of the Internet should be nearly
identical. Slight variations will, of course, persist due to ﬁner
scale routing variations. The resulting hop-count contrasts
will therefore tend to be clustered about nominal values as-
sociated with local areas of the Internet. We use a set of
simulated topologies [24] to show that clustering methods
applied to the hop-counts reliably reveal such structure.
Next, we develop a lightweight method for discovering the
network topology connecting sources and monitors by aug-
menting the passively collected data with a very small num-
ber of active measurements. Roughly speaking, the clus-
tering process described above enables topology discovery
from a number of active measurements proportional to the
number of discovered clusters (i.e., we need only make O(1)
traceroute measurements from each cluster to each passive
monitor site). Since the number of clusters is expected to be
drastically smaller than the number of sources, the burden
of active measurements is almost inconsequential. The ac-
tive measurements provide ground-truth assessments of the
number of shared hops between pairs of sources and a passive
monitor or pairs of monitors and a source. This knowledge
of shared hops, coupled with the clustering inferred from
the passive data, suﬃces to reconstruct the logical network
topology. We use simulated topologies and Skitter data [5]
to show the trade-oﬀs between active probe budget and ac-
curacy for our approach.
1In this paper, we equate source IP addresses with individual
hosts (which we refer to as “sources”), understanding that
this could introduce some error in the accuracy of topology
estimation.
Source clustering and topology discovery both depend on
the quality of the hop-count data. Due to the passive na-
ture of the data collection process, typically packets from
a source will only be observed at a (small) subset of the
passive monitors. The resulting hop-count vector will be
incomplete, with missing entries corresponding to the mon-
itors that did not observe packets from the source. The
missing data greatly confounds the clustering process and
subsequent topology discovery. To cope with this serious
issue, we adopt a probabilistic model for the hop-count con-
trasts. Since we expect the contrasts to cluster, a mixture of
Gaussian densities is used to approximate the distribution
of contrasts. Each component of the mixture is intended to
represent one of the clusters. The parameters of the mix-
ture density can be ﬁtted to the (incomplete) hop-count data
using a clever iterative procedure due to Ghahramani and
Jordan [13]. Moreover, the resulting mixture density then
provides a principled mechanism for imputing the missing
data and accurately clustering sources. We use simulated
and empirical data to show the relationship between the ac-
curacy of our method and the quantity of missing data.
The remainder of this paper is organized as follows. In
Section 2, we review prior work related to our study.
In
Section 3 we describe the data sets used in our experiments.
In Section 4, we describe our source clustering algorithm.
In Section 5, we show how a very modest number of ac-
tive measurements provides enough additional information
to recover the topology relating sources and passive moni-
tors. In Section 6 we tackle the issue of missing data and
demonstrate that accurate clustering is still possible even
when the passive data are highly incomplete. We conclude
and describe future work in Section 7.
2. RELATED WORK
Internet structure can be considered in a number of
ways including connectivity (e.g., between autonomous sys-
tems, between IP addresses, between routers or between
POP’s [32]), distance related properties (e.g., geography [16,
19], packet latency [11, 12]), or behavioral characteristics
(e.g., social network membership). The focus of our work
is on identifying Internet structure in terms of clusters of
clients [20] and shared paths [6] toward the goal of full
router-level connectivity identiﬁcation [15]. Our work diﬀers
from prior studies of client clusters in that we do not rely on
IP address details. Prior studies of shared paths and router
topologies have used active probe-based measurements ex-
clusively while our work is focused on using primarily pas-
sive measurements. While passive measurements of rout-
ing updates can be used to establish intra-domain network
maps [26], our goal is to discovery Internet-wide structure
with much more simple measures.
A related perspective is aﬀorded by coordinate systems,
which have been proposed as a means for estimating latency
between arbitrary hosts in the Internet [25, 33, 7]. Coor-
dinate systems rely on latency measurements between a set
of landmark nodes to create an embedding in a high dimen-
sional space. Hosts can then use estimates of their latency to
points in the coordinate space to predict the latency to hosts
in the Internet. The challenges in creating coordinate sys-
tems are in making them scalable, robust and accurate. One
of our topology discovery techniques is based on the idea of
establishing a topology framework via active measurements,
which is similar to landmarks. Another study that bears
some similarity to ours is by Shavitt and Tankel who de-
velop the idea of a hyperbolic embedding which includes the
idea of Internet structure in distance estimation [30].
Passive measurements of packet traﬃc can be gathered
by deploying specialized hardware on TAP’ed links (e.g., [9,
10]). While measurements from TAP’ed links could be
used in our work, publicly available data sets almost always
anonymize source IP addresses making it impossible to re-
late measurements from multiple sites. An alternative form
of passive packet measurements are those collected in net-
work honeypots [1, 3, 28, 34]). Honeypots monitor routed
but otherwise unused address space, so all traﬃc directed
to these monitors is unwanted and almost always malicious.
Honeypots do not solicit traﬃc, however low interaction sen-
sors will respond to incoming connection requests in order to
distinguish spoofed addresses. In this way they are not com-
pletely passive. However, monitors of large address segments
can receive millions of connections per day from systems all
over the world and therefore oﬀer an incredibly unique and
valuable perspective [27]. The unsolicited nature of hon-
eynet traﬃc coupled with the volume and wide deployment
of monitors make it an attractive source of data for our work.
Finally, we proposed the idea of using passive measure-
ments as the basis for network discovery and present initial
results on imputing missing data in an extended abstract
in [8]. We expand and generalize that work by developing
an algorithm for client clustering, by developing methods to
infer topology and shared paths that use a small number of
active probes, and evaluate our algorithms with simulated
and empirically derived maps of the Internet.
3. PASSIVE HOP-COUNT
MEASUREMENTS
DISTANCE
We use three diﬀerent data sets to evaluate the algorithms
that are described in this paper. The ﬁrst are a set of topolo-
gies generated by Orbis [24]. Orbis is one of the latest and
most realistic network topology generators. It creates graphs
that have properties that are consistent with many of those
observed in the Internet. The Orbis-generated synthetic net-
works enable us to analyze the capabilities of methods with
full ground truth and over a range of sizes.
The second data set that we use in this paper is an router-
level connectivity map of the Internet based on data col-
lected by Skitter [5]. Measurements in Skitter are based
on traceroute-like active probes sent from a set of 24 moni-
tors to a set of nearly 1M target hosts distributed through-
out the Internet. We use the openly available router-level
map create from data collected between April 21 and May
8, 2003. This map consists of 192,224 unique nodes and
609,066 undirected links. It is important to note that the
goal of the Skitter target host list is to have one respond-
ing node in each /24 preﬁx. Thus, the characteristics of the
Skitter graph with respect to destination subnets is diﬀerent
from Orbis generated topologies, which reﬂect collections of
nodes in subnets.
The third data set used in our study was collected over
a 24 hour period starting at 00:00 on December 22, 2006
from 15 topologically diverse honeypot sensors. These sen-
sors are located in 11 distinct /8 preﬁxes that are managed
by 10 diﬀerent organizations. The segments of IP address
space monitored by the honeypots varied from /25 to /21
plus one /16. Over 37,000,000 total packets were collected
Table 2: Counts of occurrences of common source
IP addresses in multiple honeypots
Num. Honeypots Num. Sources
2
3
4
5
6
7
8
9
10
8680
4051
2816
2156
1570
1583
1574
55
4
and evaluated in our study. The packets do not contain
spoofed source IP addresses since they were the responses
to SYN/ACKs from the honeynet [3]. Details of the data set
can be found in Table 1. In order to preserve the integrity
of the honeypots, we cannot disclose their locations in IPv4
address space.
Of particular interest and importance in our evaluation
are the occurrences of the same source IP address in multiple
honeypots. We found that 93.5% of the unique IP addresses
in our data set appear in only one of the honeypots. This is
most likely due to the diverse locations of the sensors cou-
pled with the fact that diﬀerent instances of malware limit
their scans to smaller segments of address space. Neverthe-