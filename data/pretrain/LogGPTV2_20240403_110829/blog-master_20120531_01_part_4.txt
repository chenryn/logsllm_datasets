  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/consumer.py", line 286, in _launch_process_batch  
    self.process_batch(db, batch_id, list)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/cascade/consumer.py", line 172, in process_batch  
    self.process_remote_batch(src_db, tick_id, event_list, dst_db)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 368, in process_remote_batch  
    CascadedWorker.process_remote_batch(self, src_db, tick_id, ev_list, dst_db)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/cascade/worker.py", line 155, in process_remote_batch  
    self.process_remote_event(src_curs, dst_curs, ev)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 597, in process_remote_event  
    self.handle_execute_event(ev, dst_curs)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 669, in handle_execute_event  
    dst_curs.execute(stmt)  
  File "/opt/python2.7.3/lib/python2.7/site-packages/psycopg2/extras.py", line 123, in execute  
    return _cursor.execute(self, query, vars)  
ProgrammingError: schema "digoal_01" does not exist  
```  
手工执行  
```  
pg92@db-172-16-3-33-> psql digoal_02 digoal_02  
psql (9.2beta1)  
Type "help" for help.  
digoal_02=> begin;  
BEGIN  
digoal_02=> alter table digoal_02.user_info1 add column c1 int;  
ALTER TABLE  
digoal_02=> alter table digoal_02.user_session1 add column c1 int;  
ALTER TABLE  
digoal_02=> end;  
COMMIT  
```  
这里还要注意, 手工执行完后, 目标库2的consumer上, 还会不停的去执行刚才队列里面的SQL, 通过状态我们可以看出.  
```  
postgres@db5-> londiste3 /home/postgres/londiste3/dst2_digoal_02.ini status  
Queue: replika   Local node: dst2_digoal_02  
src_digoal_01 (root)  
  |                           Tables: 4/0/0  
  |                           Lag: 18s, Tick: 2238  
  +--dst1_digoal_01 (leaf)  
  |                           Tables: 4/0/0  
  |                           Lag: 18s, Tick: 2238  
  +--dst2_digoal_02 (leaf)  
                              Tables: 2/0/2  
                              Lag: 2h10m42s, Tick: 2021  
                              ERR: dst2_digoal_02: schema "digoal_01" does not exist  
```  
日志的错误也一直会有, 而且后面发生的更改, 目标库2在解决这些异常前都不能执行下去.  
```  
2012-05-31 12:28:44,500 32303 INFO Executing: add_column.sql  
2012-05-31 12:28:44,507 32303 ERROR Job dst2_digoal_02 got error on connection 'db': schema "digoal_01" does not exist.   Query: alt  
er table digoal_01.user_info add column c1 int;  
Traceback (most recent call last):  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/skytools/scripting.py", line 565, in run_func_safely  
    return func()  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/cascade/consumer.py", line 199, in work  
    return Consumer.work(self)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/consumer.py", line 257, in work  
    self._launch_process_batch(db, batch_id, ev_list)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/consumer.py", line 286, in _launch_process_batch  
    self.process_batch(db, batch_id, list)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/cascade/consumer.py", line 172, in process_batch  
    self.process_remote_batch(src_db, tick_id, event_list, dst_db)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 368, in process_remote_batch  
    CascadedWorker.process_remote_batch(self, src_db, tick_id, ev_list, dst_db)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/pgq/cascade/worker.py", line 155, in process_remote_batch  
    self.process_remote_event(src_curs, dst_curs, ev)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 597, in process_remote_event  
    self.handle_execute_event(ev, dst_curs)  
  File "/opt/skytools3.0.2/lib/python2.7/site-packages/londiste/playback.py", line 669, in handle_execute_event  
    dst_curs.execute(stmt)  
  File "/opt/python2.7.3/lib/python2.7/site-packages/psycopg2/extras.py", line 123, in execute  
    return _cursor.execute(self, query, vars)  
ProgrammingError: schema "digoal_01" does not exist  
```  
那么怎么解决呢, 一种办法是跳过这个ticker_id, 让目标库2跳过这些SQL.  
另一种办法是在目标库2上新建digoal_01 schema以及user_info和user_session表, 让这个ticker可以在目标库2上执行下去. 通过之后再删掉这个临时用的schema.  
```  
pg92@db-172-16-3-33-> psql digoal_02 digoal_02  
psql (9.2beta1)  
Type "help" for help.  
digoal_02=> create schema digoal_01;  
CREATE SCHEMA  
digoal_02=> create table digoal_01.user_info(id int);  
CREATE TABLE  
digoal_02=> create table digoal_01.user_session(id int);  
CREATE TABLE  
```  
等会在看看状态, 正常后删除这个schema .  
```  
postgres@db5-> londiste3 /home/postgres/londiste3/dst2_digoal_02.ini status  
Queue: replika   Local node: dst2_digoal_02  
src_digoal_01 (root)  
  |                           Tables: 4/0/0  
  |                           Lag: 19s, Tick: 2266  
  +--dst1_digoal_01 (leaf)  
  |                           Tables: 4/0/0  
  |                           Lag: 19s, Tick: 2266  
  +--dst2_digoal_02 (leaf)  
                              Tables: 2/0/2  
                              Lag: 19s, Tick: 2266  
```  
删除临时schema  
```  
digoal_02=> select * from digoal_01.user_info ;  
 id | c1   
----+----  
(0 rows)  
digoal_02=> select * from digoal_01.user_session ;  
 id | c1   
----+----  
(0 rows)  
digoal_02=> drop schema digoal_01 cascade;  
NOTICE:  drop cascades to 2 other objects  
DETAIL:  drop cascades to table digoal_01.user_info  
drop cascades to table digoal_01.user_session  
DROP SCHEMA  
```  
一定要注意londiste的健康, 有异常要火速解决, 否则queue会越来越大, 没有处理的tick也会堆积.  
## 参考  
《Can session_replication_role used like MySQL's BlackHole Engine?》  
http://blog.163.com/digoal@126/blog/static/163877040201119111234570/  
[《Londiste 3 replicate case - 1 上节》](../201205/20120530_01.md)    
[《Londiste3 Install》](../201205/20120529_01.md)    
[《PostgreSQL性能优化综合案例讲解 - 1》](../201203/20120313_01.md)    
[《PostgreSQL性能优化综合案例讲解 - 2》](../201203/20120313_02.md)    
http://skytools.projects.postgresql.org/skytools-3.0/  
```  
postgres@db5-> londiste3 --ini  
[londiste3]  
## Parameters for Londiste ##  
# target database  
db = dbname=somedb host=127.0.0.1  
# how many tables can be copied in parallel  
#parallel_copies = 1  
# accept only events for locally present tables  
#local_only = true  
## compare/repair  
# max amount of time table can be locked  
#lock_timeout = 10  
# compare: sql to use  
#compare_sql = select count(1) as cnt, sum(hashtext(t.*::text)) as chksum from only _TABLE_ t  
#compare_fmt = %(cnt)d rows, checksum=%(chksum)s  
## Parameters for pgq.CascadedWorker ##  
# how often the root node should push wm downstream (seconds)  
#global_wm_publish_period = 300  
# how often the nodes should report their wm upstream (seconds)  
#local_wm_publish_period = 300  
## Parameters for pgq.Consumer ##  
# queue name to read from  
queue_name =  
# override consumer name  
#consumer_name = %(job_name)s  
# whether to use cursor to fetch events (0 disables)  
#pgq_lazy_fetch = 300  
# whether to read from source size in autocommmit mode  
# not compatible with pgq_lazy_fetch  
# the actual user script on top of pgq.Consumer must also support it  
#pgq_autocommit = 0  
# whether to wait for specified number of events, before  
# assigning a batch (0 disables)  
#pgq_batch_collect_events = 0  
# whether to wait specified amount of time,  
# before assigning a batch (postgres interval)  
#pgq_batch_collect_interval =  
# whether to stay behind queue top (postgres interval)  
#pgq_keep_lag =  
## Parameters for skytools.DBScript ##  
# default lifetime for database connections (in seconds)  
#connection_lifetime = 1200  
## Parameters for skytools.DBScript ##  
# how many seconds to sleep between work loops  