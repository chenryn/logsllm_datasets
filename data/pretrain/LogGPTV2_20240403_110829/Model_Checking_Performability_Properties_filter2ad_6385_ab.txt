 under consideration. For atomic propositions (the leaves
in the parse tree) this set is directly obtained from the la-
belling of the states; Sat ^ 	 is obtained by comput-
ing Sat and Sat	 recursively, and then intersecting
these sets; Sat: is obtained by taking the complement
of the entire state space with respect to Sat. The algo-
rithm for the temporal operators is more complicated and
involves several numerical computations. For instance, for
SatEX  we ﬁrst compute the set Sat, then com-
pute for each state the probability to move to one of these
states (in one step), and compare this probability with 
according to E.
Model-checking until-formulas is even more involved.
We discuss this procedure on the basis of the example
properties presented before. Properties of the form P0
are checked on the basis of the procedure in [13], which
amounts to recursively computing the sets Sat and
Sat	 followed by solving a linear system of equations
(with  = fgreeng and 	 = fredg). The number of equa-
tions equals the number of states of the MRM. An efﬁ-
cient scheme for model-checking P1-properties has been
proposed in [3]. First, the sets Sat and Sat	are com-
puted. All states in Sat	 and all states that are neither in
Sat nor Sat	 are made absorbing. A transient analy-
sis (for time instant ) on the resulting Markov chain then
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:10:37 UTC from IEEE Xplore.  Restrictions apply. 
sufﬁces to decide the validity of the formula: the proba-
bility bound  is compared with the probability mass ac-
cumulated in Sat	 at time . Properties `a la P2 need
some additional preprocessing. By swapping the reward
bound into a time bound inside  (turning each U6 into
U 6), we can resort to the procedure for P1, provided that
the MRM  under consideration is a priori transformed
into MRM . Intuitively, a residence of  time-units in
state  of  corresponds to earning a reward  in state 
of  (and vice versa). Details of this transformation can
be found in [4, Theorem 1], together with a general duality
result on which the transformation is based.
Unfortunately, the above transformation does not help
for properties of type P3. The reason is that the role
of time and rewards in  and  are truly dual, and
hence the transformation does not provide us with a
simpler – or better studied – algorithmic problem if both
time and rewards are measured. As a consequence, a
computational procedure for properties of the form P3 has
not been devised so far.
In the next section we discuss
three different approaches to verify P3-type properties,
all of which address a more speciﬁc problem, namely
reward-bounded instant-of-time reachability, expressed by
path operator [;]
6 . The following observation states that
this is enough to decide properties of the form P3.
Theorem 1
Given the CSRL state formulas  and 	, and MRM
, let 0 be the MRM obtained from  by making all
	-states and all : ^	-states absorbing and assigning
reward 0 to these absorbing states. Then, state  in 
satisﬁes E U 6
6 	 if and only if  in 0 satisﬁes
E[;]
6 	.
The intuitive justiﬁcation for the above theorem is as fol-
lows. Once a path reaches a :  ^ 	-state, there is no
way in which it can satisfy a  U 	-formula. We can thus
safely make these states absorbing, as the rest of the path
is not of interest anymore. Moreover, once a path reaches
a 	-state at time 0  0 the value of Y increases con-
tinuously with rate (cid:26)X. Hence, the discrete states of
the original CTMC become “columns” of which the height
models the accumulated reward. To take into account the
reward bound ((cid:20) ), we introduce an absorbing barrier in
the process whenever Y reaches the level . Actually, we
are interested in
fY 6 ; X 2 S0g;
i.e., the probability of being in a certain subset S0 of states
at time , having accumulated a reward smaller than . For
our purposes, S0 shall be chosen to be the set Sat	 of
states satisfying 	 and we start the process in state  under
consideration.
Theorem 2
Given CSRL state formula 	, let MRM 0 be deﬁned
as in Theorem 1, with (cid:11)0 = 1 for some state 0 in
0.
if and only if
fY 6 ; X 2 Sat	g E .
Then 0 satisﬁes E[;]
6 	
formulas via numerical
Together with Theorem 1 the above theorem allows us
to decide the satisfaction of time- and reward-bounded
until
recipes for calculating
fY 6 ; X 2 S0g on the two dimensional stochastic
process X; Y. It is worth to remark that similar pro-
cesses (with mixed discrete-continuous state spaces) also
emerge in the analysis of non-Markovian stochastic Petri
nets (when using the supplementary variable approach,
cf. [10]), Markov-regenerative stochastic Petri nets [5],
and in ﬂuid-stochastic Petri nets [16]. We do not ad-
dress the algorithms presented in these papers here, since
they are either not directly applicable, or suffer from yet-
unresolved numerical problems (e.g., related to Laplace
back-transformations). In future work, we will investigate
them in more detail.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:10:37 UTC from IEEE Xplore.  Restrictions apply. 
”
n
o
i
s
n
e
m
i
d
d
r
a
w
e
r
d
e
t
a
l
u
m
u
c
c
a
”
absorbing barrier
rate (cid:26)2
rate (cid:26)1
1
2
green
3
"CTMC dimension"
height 
5
red
green nor red
4
Figure 1. Two-dimensional stochastic process X; Y;  (cid:21) 0 for model checking CSRL property P3.
4.2. A pseudo-Erlang approximation
Our ﬁrst approach to compute fY 6 ; X 2 S0g is
to approximate the ﬁxed reward bound  by a reward bound
that is Erlang-k distributed with mean . One may view
this as some kind of discretisation of the continuous re-
ward dimension into k steps. The main advantage of this
approach is that the resulting model is both discrete-space
and completely Markovian, and hence, standard techniques
and tools developed for P2-like properties can be used
to approximate the probabilities required by Theorem 2;
reaching the reward bound in the original model corre-
sponds to reaching a particular set of states in the approxi-
mated model. As a disadvantage we mention that an appro-
priate value for k – the number of phases in the Erlangian
approximation – is not known a priori. Furthermore, when
CSRL expressions are nested, it is yet unclear how the error
in the approximation propagates. Furthermore, the result-
ing CTMC becomes substantially larger, especially if k is
large. On the other hand, the resulting CTMC can be de-
scribed in terms of a special tensor structure which can be
exploited in the solution procedure (as far as the storage of
the generator matrix is concerned).
Further considerations concern the effectiveness of the
Erlangian approximation. Since the computation of P2-
type property-bounds requires the transient analysis of the
CTMC under study, one typically employs uniformisation,
a generic method to analyse CTMCs via an underlying
discrete-time Markov chain [12, 17]. As is well-known,
the speed of uniformisation depends on the largest diag-
onal entry in the generator matrix (in absolute sense). In
the context of the suggested Erlang-k approximation where
the reward upper bound is , the maximum diagonal en-
try is increased (additively) with k
 ^(cid:26), with ^(cid:26) the largest re-
ward rate assigned to any state. This might considerably
slow down the uniformisation procedure. For a given error
bound " > 0 one can determine the number of steps "
in the uniformised Markov chain needed to reach the given
accuracy (see also the discussion in Section 4.4). The the-
oretical time complexity then becomes "  jSj  k2.
Due to sparseness of the generator matrix the algorithm ac-
tually takes less time.
4.3. Discretisation
Recently, Tijms and Veldman [24] proposed a discreti-
sation method for computing the transient distribution of
the accumulated reward in an MRM. Their algorithm is
a generalisation of an earlier algorithm by Goyal and
Tantawi [11] for MRMs with only 0- and 1-rewards. The
basic idea is to discretise both the time and the accumu-
lated reward as multiples of the same step size d, where d
is chosen such that the probability of more than one tran-
sition in the MRM in an interval of length d is negligible.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:10:37 UTC from IEEE Xplore.  Restrictions apply. 
The algorithm allows only natural number rewards, but this
is no severe restriction since rational rewards can be scaled
to yield natural numbers.
Let F ; k be the function that discretises the joint
probability density of being in state  at time d while
having earned an accumulated reward kd. According
to [24], we have:
fY 6 ; X 2 S0g (cid:25) X2S 0
Xk=1
F T ; kd
R
where R =

d
and T =

d
:
Note that R and T are integers, as  and  are both multiples
of d. Matrix F T ; k is computed in an iterative manner
where
F 1; k = (cid:26) 1=d;
0;
if ; k = 0; (cid:26)0
otherwise
(recall that 0 is the initial state of the MRM). For the sub-
sequent iterations, the following recursive scheme2 is used:
F j1; k = F j; k (cid:26)1   Ed 
F j0; k (cid:26)0R0; d;
X02S
where k (cid:26) is set to 0 if (cid:26) > k. This expression can
be explained as follows. At the j1-st time instant, ei-
ther the MRM was in state  at the j-th time instant and re-
mained there for d time-units (the ﬁrst summand), or it has
moved from a state 0 to state  during that period (the sec-
ond summand). Given that the accumulated (discretised)
reward is k, the accumulated reward at the j-th instant is
approximated by k (cid:26) and k (cid:26)0, respectively.
In total, =d iterations are needed to obtain the de-
sired result. Due to the state-dependent displacements, i.e.,
k (cid:26), both matrices F j and F j1 need to be stored,
thus occupying 2jSjR ﬂoating point numbers. The time