that inﬂuence speciﬁc SSCs, is tantamount to crafting test
vectors with high SSC coverage. Fortunately, Bomberman
provides veriﬁcation engineers with two channels of infor-
mation to aid in this process: 1) the circuit DFG (Fig. 11
in Appendix C) illustrates the control-path that exercises a
speciﬁc SSC, and 2) the SSC Classiﬁcation output indicates
the extent suspicious SSCs have/have-not been exercised. To-
gether, these Bomberman insights guide veriﬁcation engineers
in creating test vectors that achieve high coverage, with respect
to Bomberman invariants (Properties 1 and 2 in §IV-A),
therefore minimizing false positives. For example, in §VI-B,
when analyzing the OR1200 processor, we noticed designer-
provided test vectors [49] did not exercise several CSRs.
By referencing Bomberman’s output, we located the (non-)
suspicious SSCs and crafted test vectors to exercise them.
2) Latches: For Bomberman to locate TTTs in a hardware
design, it ﬁrst locates all SSCs by identifying signals in the
design’s HDL that are inferred as ﬂip-ﬂops during synthesis
(§V-A). However, ﬂip-ﬂops are not the only circuit compo-
nents that store state. SSCs can also be implemented with
latches. However, it is typically considered bad practice to
include latches in sequential hardware designs as they often
Fig. 9. Distributions of Logic Depths per Pipeline Stage. The length of
combinational logic chains between any two sequential components in most
hardware designs is bounded to optimize for performance, power, and/or area.
High performance designs have the shortest depths (less than 8 [53]), while
even the ﬂattened and obfuscated logic model of the lowest-performance
Arm processor available [52] (worst case scenario) has a depth <25. Even in
the worst case, Bomberman’s run time (overlaid for each core), is <11 min.
on a commodity laptop.
1) SSC Enumeration: During the SSC Enumeration stage,
Bomberman locates signals that are the direct outputs of coa-
lesced SSCs, and signals that form distributed SSCs (§V-A).
For a circuit DFG with n nodes (each node representing a
signal), a maximum fan-in of f for signal nodes, a maximum
logic depth per pipeline stage4 of d,
the asymptotic time
complexity for enumerating SSCs is O(nf d). Since most
hardware designs are optimized for either power, performance
(clock speed), and/or area, the maximum logic depth, d, is
usually small and bounded. Therefore, the time complexity is
polynomial. To show this, we plot (Fig. 9) the distributions of
logic depths within pipeline stages—and the corresponding
Bomberman run time—across the four designs we study,
representing both mid-to-high performance and mid-to-large
designs. Additionally, to stress-test Bomberman, we measure
its run time in the worst-case scenario: analyzing the
ﬂattened and obfuscated functionally-equivalent logic model
of the most low-performant and low-power Arm processor
available [52]. For all designs, the logic depths were less
than 25 across all pipeline stages.5 Additionally, the maximum
fan-in for a signal node is often small—less than 10—and
bounded [8], further reducing the time complexity to O(n).
By extension, the asymptotic space complexity reduces from
O(n + nf ) to O(n), to store the DFG.
is important
While Bomberman’s SSC Enumeration time complexity
is bounded by conventional circuit size and performance
constraints, from a security perspective it
to
understand how an attacker might manipulate these bounds.
Fortunately, while an attacker can control the maximum logic
depth in a pipeline stage, d, and the maximum fan-in of a
signal node, f, choosing large values for either in hopes of ren-
dering Bomberman analyses computationally infeasible would
reveal them: the victim design would be rendered unusable—
either too large or too slow—by its intended customers and
the tools would direct the designer to inspect the Trojan logic.
4The logic depth in a pipeline stage is the number of stages of combinational
logic between layers of sequential logic.
5If we could plot the logic depths within commercial x86 processors in
Fig. 9, we would expect them to be smaller than the OR1200, RISC-V, and
Arm designs, as the maximum depth of logic per pipeline stage of GHz
processors must be less than eight [53].
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
981
induce unwanted timing errors. As a result, HDL compilers in
synthesis CAD tools issue warnings when they infer latches
in a design—highlighting the TTT. Nonetheless, to support
such (bad) design practices, we design Bomberman’s data-ﬂow
graph generation compiler back-end to also recognize latches.
3) TTT Identiﬁcation in Physical Layouts: Bomberman
is designed as an extension into existing front-end veriﬁcation
tool-chains that process hardware designs (Fig. 2). Under a
different threat model—one encapsulating untrusted back-end
designers—it may be necessary to analyze physical layouts for
the presence of TTTs. Bomberman can analyze physical lay-
outs for TTTs, provided the layout (GDSII) ﬁle is ﬁrst reverse-
engineered into a gate-level netlist. As noted by Yang et
al. [28], there are several reverse-engineering tools for carrying
out this task. Bomberman also requires HDL device models
for all devices in the netlist (e.g., NAND gate). This informs
Bomberman of a device’s input and output signals, which is
required to create a DFG. Fortunately, HDL device models
are typically provided as a part of the process technology IP
portfolio purchased by front-end designers.
4) Memories: Bomberman is designed to handle memories,
or large arrays of SSCs, in the same fashion that it handles
ﬂip-ﬂop-based SSCs. Namely, Bomberman creates a DFG
of the addressable words within a memory block to curb
state-explosion when locating distributed SSCs. For memories
that mandate word-aligned accesses, Bomberman generates
a coalesced SSC for every word. For memories that allow
unaligned accesses—which represent a minority,
i.e., part
of two adjacent words could be addressed simultaneously,
Bomberman generates a coalesced SSC for every word, and
multiple word-sized distributed SSCs created by sliding a
word-sized window across every adjacent memory word pair.
In either case, Bomberman’s DFG ﬁltering mechanism greatly
reduces the overall set of potentially suspicious SSCs.
5) Limitations: Bomberman is capable of detecting all
TTTs with zero false negatives, within the constraints of
our deﬁnition (§IV-A). However,
these constraints impose
limitations. First, if an attacker knows Bomberman is in use,
they may alter their Trojan to repeat a value to avoid detection.
There are two ways they may do this: 1) add an extra state bit
to the SSC(s) that does not repeat a value, or 2) add additional
logic that resets the SSC(s) upon recognizing speciﬁc circuit
behavior. The ﬁrst design would be detected by Bomberman
since, by deﬁnition, describes a distributed SSC. However, the
second scenario describes a Trojan that, by deﬁnition, is a data-
based (cheat code) Trojan [13] not a TTT. Therefore, it would
not be detected by Bomberman. Data-based Trojans [13]
are better addressed by techniques that
target rarely used
activation signals [9], [10] or comparator inputs [8] (Tab. I).
Second, Bomberman is incapable of detecting TTTs that use
analog SSCs, like the A2 Trojan [28], as there is no notion of
analog SSCs in front-end designs.6 Detecting Trojans like A2
6While the non-deterministic (sporadic) TTTs proposed by Imeson et
al. [22] do use non-simulatable analog behavior (i.e., phase noise) as an
entropy source for the increment event, they do not use analog SSCs. Thus,
they are detectable by Bomberman.
require knowledge of the physical layout of the circuit, and
are best addressed during circuit layout [54].
VIII. RELATED WORK
The implantation, detection, and prevention of hardware
Trojans across hardware design phases have been widely
studied. Attacks range from design-time attacks [7], [22], [27],
[55], to layout-level modiﬁcations at fabrication time [28]–
[30]. On the defensive side, most work focuses on post-
fabrication Trojan detection [37]–[43], [54], [56], [57], given
that most hardware design houses are fab-less, and therefore
must outsource their designs for fabrication. However, as
hardware complexity increases, reliance on 3rd-party IP [3]
brings the trustworthiness of the design process into question.
Thus, there is active work in both detection [8]–[10], [35],
[36] and preventation [11], [13] of design-time Trojans.
On the attack side, King et al. [7] demonstrate embedding
hardware Trojans in a processor for the purpose of planting
footholds for high-level exploitation in software. They demon-
strate how small perturbations in a microprocessor’s hardware
can be exploited to mount wide varieties of software-level
attacks. Lin et al. [27] propose a different class of hardware
Trojans, designed to expose a side-channel for leaking infor-
mation. Speciﬁcally, they add ﬂip-ﬂops to an AES core to cre-
ate a power side channel large enough to exﬁltrate key bytes,
but small enough that it resides below the device’s power noise
margin. While both attacks demonstrate different payloads,
they both require triggering mechanisms to remain dormant
during veriﬁcation and post-fabrication testing. Thankfully, our
defense is payload-agnostic and trigger-speciﬁc. We focus on
detecting hardware Trojans by their trigger. As a byproduct,
we can identify any payloads by inspecting portions of the
design that the trigger output inﬂuences.
Wang et al. [21] propose the ﬁrst variant of sporadic TTTs,
called Asynchronous Counter Trojans. Asynchronous Counter
Trojans increment pseudo-randomly from a non-periodic in-
ternal event signal (e.g., Fig. 4C and D). Similarly, Imeson
et al. [22] propose non-deterministic TTTs. Non-deterministic
TTTs are also sporadic, but they differ from pseudo-random
TTTs in that their event signals are not a function of the
state of the victim device, rather, they are a function of a
true source of entropy. Unlike, Waksman et al.’s power reset
defense [13], this nuance is irrelevant to Bomberman, who
identiﬁes TTTs by the values expressed by their SSCs, not
the source or predictability of their event signals.
On the defensive side, both design- and run-time approaches
have been proposed. At design-time, Hicks et al. [10] propose
a dynamic analysis technique for Unused Circuit Identiﬁca-
tion (UCI) to locate potential trigger logic. After veriﬁcation
testing,
they replace all unused logic with logic to raise
exceptions at run-time to be handled in software. Similarly,
Zhang et al. [9] propose VeriTrust, a dynamic analysis tech-
nique focused on the behavioral functionality, rather than
implementation, of the hardware. Conversely, Waksman et
al. [8] propose FANCI, a static analysis technique for locating
rarely used logic based on computing control values between
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
982
inputs and outputs. Lastly, Li and Subramanyan et al. [35],
[36] propose WordRev, a different static analysis approach,
whereby they search for counters in a gate-level netlist by iden-
tifying groups of latches that toggle when low order bits are 1
(up-counter), or low order bits are 0 (down-counter). As static
analysis approaches, FANCI and WordRev have the advantage
of not requiring veriﬁcation simulation results. In §VI-C2
we leverage prior work on defeating such defenses [14]–
[16] to construct a TTT that bypasses these defenses—but
Bomberman detects. At run-time, Waksman et al. [13] thwart
TTTs, using intermittent power resets. As shown in §VI-C1,
power-resets are also incapable of thwarting all TTT variants.
IX. CONCLUSION
Bomberman is an effective example of a threat-speciﬁc
defense against TTTs. Unlike prior work, we do not attempt to
provide a panacea against all design-time Trojans. Instead, we
deﬁne the behavioral characteristics of a speciﬁc but important
threat, TTTs, and develop a complete defense capable of
identifying all TTT variants as we deﬁne them. Across four
open-source hardware designs, Bomberman detects all six TTT
variants, with less than 1.2% false positives.
Bomberman demonstrates the power of threat-speciﬁc ver-
iﬁcation, and seeks to inspire future threat-speciﬁc defenses
against hardware Trojans and common hardware bugs. We be-
lieve that no one defense will ever provide the level of security
achievable by defense-in-depth strategies. Thus, by combining
Bomberman with existing design-time Trojan defenses [8]–
[10], [13], along with future threat-speciﬁc defenses, we aim
to create an insurmountable barrier for design-time attackers.
ACKNOWLEDGMENTS
We thank the anonymous reviewers and our shepherd, Ste-
fan Katzenbeisser, for their thoughtful feedback that enhanced
the quality of this paper.
DISTRIBUTION STATEMENT A. Approved for public
release. Distribution is unlimited. This material is based upon
work supported by the Under Secretary of Defense for Re-
search and Engineering under Air Force Contract No. FA8702-
15-D-0001. Additionally, the work reported in this paper was
supported in part by the US National Science Foundation
under Grant CNS-1646130 and Graduate Research Fellowship
Program under Grant DGE 1256260, as well as the US
Army Research Ofﬁce under Grant W911NF-21-1-0057. Any
opinions, ﬁndings, conclusions or recommendations expressed
in this paper are those of the authors and do not necessarily
reﬂect the views of the funding agencies.
REFERENCES
versus
“10nm
[1] M.
Lapedus,
7nm,”
April
2016,
https://semiengineering.com/10nm-versus-7nm/.
[2] P. Gupta, “7nm power
issues and solutions,” November 2016,
https://semiengineering.com/7nm-power-issues-and-solutions/.
[3] J. Blyler, “Trends driving ip reuse through 2020,” November 2017,
http://jbsystech.com/trends-driving-ip-reuse-2020/.
[4] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn,
S. Mangard, P. Kocher, D. Genkin et al., “Meltdown: Reading kernel
memory from user space,” in USENIX Security Symposium, 2018.
[5] P. Kocher, J. Horn, A. Fogh, , D. Genkin, D. Gruss, W. Haas, M. Ham-
burg, M. Lipp, S. Mangard, T. Prescher, M. Schwarz, and Y. Yarom,
“Spectre attacks: Exploiting speculative execution,” in IEEE Symposium
on Security and Privacy (S&P), 2019.
[6] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens,
M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx, “Foreshadow:
Extracting the keys to the intel SGX kingdom with transient out-of-order
execution,” in USENIX Security Symposium, 2018.
[7] S. T. King, J. Tucek, A. Cozzie, C. Grier, W. Jiang, and Y. Zhou, “De-
signing and implementing malicious hardware,” in USENIX Workshop
on Large-Scale Exploits and Emergent Threats (LEET), 2008.
[8] A. Waksman, M. Suozzo, and S. Sethumadhavan, “FANCI: identiﬁcation
of stealthy malicious logic using boolean functional analysis,” in ACM
SIGSAC Conference on Computer & Communications Security (CCS),
2013.
[9] J. Zhang, F. Yuan, L. Wei, Y. Liu, and Q. Xu, “VeriTrust: Veriﬁcation
for hardware trust,” IEEE Transactions on Computer-Aided Design of
Integrated Circuits and Systems, 2015.
[10] M. Hicks, M. Finnicum, S. T. King, M. M. K. Martin, and J. M. Smith,
“Overcoming an untrusted computing base: Detecting and removing
malicious hardware automatically,” in IEEE Symposium on Security and
Privacy (S&P), 2010.
[11] A. Waksman and S. Sethumadhavan, “Tamper evident microprocessors,”
in IEEE Symposium on Security and Privacy (S&P), 2010.
[12] M. Hicks, C. Sturton, S. T. King, and J. M. Smith, “Specs: A lightweight
runtime mechanism for protecting software from security-critical pro-
cessor bugs,” in International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS), 2015.
[13] A. Waksman and S. Sethumadhavan, “Silencing hardware backdoors,”
in IEEE Symposium on Security and Privacy (S&P), 2011.
[14] C. Sturton, M. Hicks, D. Wagner, and S. T. King, “Defeating UCI:
Building stealthy and malicious hardware,” in IEEE Symposium on
Security and Privacy (S&P), 2011.
[15] J. Zhang, F. Yuan, and Q. Xu, “DeTrust: Defeating hardware trust
veriﬁcation with stealthy implicitly-triggered hardware trojans,” in ACM
SIGSAC Conference on Computer & Communications Security (CCS),
2014.
[16] A. Waksman, J. Rajendran, M. Suozzo, and S. Sethumadhavan, “A red
team/blue team assessment of functional analysis methods for malicious
circuit identiﬁcation,” in ACM/EDAC/IEEE Design Automation Confer-
ence (DAC), 2014.
[17] V. Patankar, A. Jain, and R. Bryant, “Formal veriﬁcation of an ARM
processor,” in International Conference on VLSI Design (VLSID), 1999.
[18] C. Wolf, “Picorv32,” https://github.com/cliffordwolf/picorv3#cycles-per-
instruction-performance.
[19] OpenCores.org,
“Openrisc
https://github.com/openrisc/or1200.
or1200
processor,”
[20] H. Salmani, M. Tehranipoor, and R. Karri, “On design vulnerability
analysis and trust benchmarks development,” in IEEE International
Conference on Computer Design (ICCD), 2013.
[21] X. Wang, S. Narasimhan, A. Krishna, T. Mal-Sarkar, and S. Bhunia,
“Sequential hardware trojan: Side-channel aware design and placement,”
in IEEE International Conference on Computer Design (ICCD), 2011.
[22] F. Imeson, S. Nejati, S. Garg, and M. Tripunitara, “Non-deterministic
timers for hardware trojan activation (or how a little randomness can
go the wrong way),” in USENIX Workshop on Offensive Technologies
(WOOT), 2016.
[23] T.
Trippel,
“Bomberman,”
December
2020,
https://github.com/timothytrippel/bomberman.
[24] J. Cross, “Inside apple’s A13 bionic system-on-chip,” October 2019,
https://www.macworld.com/article/3442716/inside-apples-a13-bionic-
system-on-chip.html.
[25] R. Karri, J. Rajendran, K. Rosenfeld, and M. Tehranipoor, “Trustworthy
hardware: Identifying and classifying hardware trojans,” Computer,
2010.
[26] M. Tehranipoor and F. Koushanfar, “A survey of hardware trojan
taxonomy and detection,” IEEE Design & Test of Computers, 2010.
[27] L. Lin, M. Kasper, T. G¨uneysu, C. Paar, and W. Burleson, “Trojan
side-channels: Lightweight hardware trojans through side-channel en-
gineering.” in International Workshop on Cryptographic Hardware and
Embedded Systems (CHES), 2009.
[28] K. Yang, M. Hicks, Q. Dong, T. Austin, and D. Sylvester, “A2: Analog
malicious hardware,” in IEEE Symposium on Security and Privacy
(S&P), 2016.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:30:57 UTC from IEEE Xplore.  Restrictions apply. 
983
[29] R. Kumar, P. Jovanovic, W. Burleson, and I. Polian, “Parametric trojans
for fault-injection attacks on cryptographic hardware,” in Workshop on
Fault Diagnosis and Tolerance in Cryptography (FDTC), 2014.
[30] G. T. Becker, F. Regazzoni, C. Paar, and W. P. Burleson, “Stealthy
dopant-level hardware trojans,” in International Workshop on Crypto-
graphic Hardware and Embedded Systems (CHES), 2013.
[31] S. Ghosh, A. Basak, and S. Bhunia, “How secure are printed circuit
boards against trojan attacks?” IEEE Design & Test, 2014.
[32] R. S. Chakraborty, S. Narasimhan, and S. Bhunia, “Hardware trojan:
Threats and emerging solutions,” in IEEE International High Level
Design Validation and Test Workshop (HLDVT).
IEEE, 2009.
[33] Y. Jin and Y. Makris, “Hardware trojan detection using path delay
ﬁngerprint,” in IEEE International Workshop on Hardware-Oriented
Security and Trust (HOST), 2008.
[34] F. Wolff, C. Papachristou, S. Bhunia, and R. S. Chakraborty, “Towards
trojan-free trusted ics: Problem analysis and detection scheme,” in ACM
Conference on Design, Automation and Test in Europe (DATE), 2008.
[35] W. Li, A. Gascon, P. Subramanyan, W. Y. Tan, A. Tiwari, S. Malik,
N. Shankar, and S. Seshia, “WordRev: Finding word-level structures in
a sea of bit-level gates,” in IEEE International Workshop on Hardware-
Oriented Security and Trust (HOST), 2013.
[36] P. Subramanyan, N. Tsiskaridze, K. Pasricha, D. Reisman, A. Susnea,
and S. Malik, “Reverse engineering digital circuits using functional
analysis,” in ACM Conference on Design, Automation and Test in Europe
(DATE), 2013.
[37] D. Agrawal, S. Baktir, D. Karakoyunlu, P. Rohatgi, and B. Sunar, “Trojan
detection using IC ﬁngerprinting,” in IEEE Symposium on Security and
Privacy (S&P), 2007.
[38] M. Potkonjak, A. Nahapetian, M. Nelson, and T. Massey, “Hardware
trojan horse detection using gate-level characterization,” in ACM/IEEE
Design Automation Conference (DAC), 2009.
[39] S. Narasimhan, X. Wang, D. Du, R. S. Chakraborty, and S. Bhunia,
“Tesr: A robust temporal self-referencing approach for hardware trojan
detection,” in IEEE International Symposium on Hardware-Oriented
Security and Trust (HOST), 2011.
[40] J. Balasch, B. Gierlichs, and I. Verbauwhede, “Electromagnetic circuit
ﬁngerprints for hardware trojan detection,” in IEEE International Sym-
posium on Electromagnetic Compatibility (EMC), 2015.
[41] J. Li and J. Lach, “At-speed delay characterization for ic authentica-
tion and trojan horse detection,” in IEEE International Workshop on
Hardware-Oriented Security and Trust (HOST), 2008.
[42] D. Forte, C. Bao, and A. Srivastava, “Temperature tracking: An inno-
vative run-time approach for hardware trojan detection,” in IEEE/ACM