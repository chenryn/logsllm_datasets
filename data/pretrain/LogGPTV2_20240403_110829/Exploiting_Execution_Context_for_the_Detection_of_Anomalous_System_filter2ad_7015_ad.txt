Proprietary setuid Application. An experiment was conducted on a setuid
root application installed on the 10 audit hosts used in this study. The program
in question is a proprietary setuid root application written to allow students to
submit homework assignments to a class account for grading. While this program
is not a daemon or periodic job, an analysis of its binary revealed an exploitable
stack overﬂow vulnerability in a request logging function. This vulnerability
was used to test the detection capability of our system. The attack on this
program required circumventing the exec-shield, stack randomization, and heap
randomization protection mechanisms deployed on the monitored hosts. The
attack involved overwriting two stack variables: the current function’s return
address and the frame pointer. This caused the program to jump to an indirect
jump instruction through the modiﬁed frame pointer, transferring control to an
exploit payload previously injected in a buﬀer on the heap. This was necessary
in order to overcome the exec-shield and randomization protection mechanisms.
The results and analysis of the context-sensitive detection system’s sensitivity
to exploit payloads is discussed below.
Rootshell Exploit. The ﬁrst exploit payload executed against the vulnerable
program was a simple shell execution with root privileges. Because the execve
system call was invoked from a context not previously observed during the train-
ing period, the context-sensitive detection system was able to distinguish the
system call invocation as anomalous and report an alert. The detection system
conﬁgured in context-insensitive mode, however, did not detect the execve call
as anomalous. This stems from the fact that both a ﬁle archiving utility and a
compression utility are spawned during the normal execution of the assignment
submission program, and thus the context-insensitive argument models on their
own were not sensitive enough to detect an anomaly based on the execve target
alone. A ﬁnal observation of this scenario is that a sequence-based system call
IDS would have detected a deviation from the normal sequence of system calls,
and would have raised an alert.
Data Modiﬁcation Exploit. The second exploit payload executed against the
assignment submission program was a variation of a data modiﬁcation attack.
The objective of this exploit was to manipulate the logging of an assignment
submission such that the submitter and timestamp could be subverted with
attacker-supplied values. To accomplish this, the exploit payload ﬁrst called
mprotect from a legitimate, in-sequence context to mark the code segments
of the process read/write. Since the stack was modiﬁed to hold a legitimate
16
D. Mutz et al.
sequence of return addresses prior to calling mprotect, the program continued
executing native application code upon returning. In order to regain control for
the second part of the attack, a system library function pointer was overwritten
in the procedure linkage table (PLT). This type of attack is described in detail
in [10]. Changing the memory protection bits on the code segment of the pro-
gram allowed the statically deﬁned format string that is used in the invocation
to fprintf to be overwritten. In this way, the attacker’s format string was used
in place of the legitimate one when the transaction was logged by the program.
A sequence-based system call IDS would not have detected an anomaly, as no
invalid or out-of-sequence system calls were invoked. In addition, the context-
insensitive argument models were not tight enough to detect an aberration in the
parameters to the system call mprotect. The context-sensitive detection system,
however, was able to detect the anomalous argument due to the more precise
argument modeling that included system call context.
Detecting Attacks Against OpenSSL. The ﬁnal demonstration of the attack
detection capability of the system involved testing an oﬀ-the-shelf exploit for the
Apache web server running with a vulnerable version of OpenSSL, which is a
popular implementation of the Secure Sockets Layer (SSL) and Transport Layer
Security (TLS) protocols. This version of OpenSSL is vulnerable to a remote
client master key overﬂow, allowing an attacker to potentially execute arbitrary
code in any network service that utilizes the library.
As before, context-sensitive and context-insensitive model
instances were
trained against traces of normal HTTP client behavior. The models were then
applied to a trace of an attack against OpenSSL. As before, the stack speciﬁc
models correctly identiﬁed the attack, in this case from an anomalous execve of
“/bin/sh.” The context-insensitive models, however, did not consider this system
call to be suﬃciently anomalous to raise an alarm. We speculate that since the
training data included benign invocations of CGI scripts, which necessarily in-
volve issuing an execve for an external script execution, the context-insensitive
models were not able to diﬀerentiate between benign and malicious invocations
of the system call. This is because only one proﬁle was constructed from the
training set for execve, which supports our claim that the detection capability
of argument models is measurably enhanced by instantiating models speciﬁc to
each call stack context.
4.4 Performance Overhead of Stack Unwinding
To evaluate the performance overhead of unwinding the call stacks of user
processes, we constructed a benchmark application. The benchmark invokes a
system call after creating a parameterized number of frames on the callstack. In
each run of the benchmark, 100 groups of 100 such invocations are made and the
average time to complete 100 invocations is returned. In Figure 2 we compare
the benchmark running times of an identical system in three conﬁgurations: no
auditing whatsoever, simple system call auditing (no stack unwinding), and sys-
tem call auditing with stack unwinding. The benchmark execution time is given
for a variety of stack depths.
Exploiting Execution Context for the Detection of Anomalous System Calls
17
Auditing with stack unwind
Auditing, no stack unwind
No auditing, no stack unwind
 0.02
 0.015
 0.01
 0.005
)
s
c
e
s
(
e
m
i
t
n
o
i
t
u
c
e
x
e
e
g
a
r
e
v
A
 0
 0
 20
 40
 60
 80
 100
 120
 140
 160
Stack depth
Fig. 2. Comparison of average execution time of system call invocation benchmark
The ﬁgure shows that there is signiﬁcant overhead associated with unwinding
user call stacks while auditing. However, the overheads are roughly similar to
simple auditing for stack depths less than 40 (i.e., within a factor of two). We also
note that the benchmark is designed to expose diﬀerences in the audit times, and
diﬀers from normal applications in that it does essentially no other processing
aside from rapidly invoking system calls.
5 Related Work
Research on model-based detection using system call invocation models origi-
nated with [4], which analyzes ﬁxed-length sequences of system calls, without
considering arguments or return values. The model of legitimate program behav-
ior is built by observing normal system call sequences in attack-free application
runs. Alternative data models for the characterization of system call sequences
were proposed in [25] and [26].
These detection techniques could be easily evaded by mimicry attacks, in which
an exploit is crafted to produce a legitimate sequence of system calls while perform-
ing malicious actions [24]. The introduction of gray-box and white-box approaches,
which use additional information such as the stack context and information derived
through static analysis techniques, have considerably raised the bar for this kind
of attack [18,3,5]. Nevertheless, these approaches do not provide eﬀective model-
ing of system call arguments, giving the attacker a considerable amount of freedom
in crafting an exploit that evades detection. Therefore, black-box, learning-based
models that take into account the arguments of system calls were introduced to
further limit the ability of an attacker to perform mimicry attacks [12,15].
18
D. Mutz et al.
The system call automaton proposed in [18] was further extended to include
the analysis of system call arguments in [19]. The authors motivate this extension
by saying that “clearly, it is not enough to know that something is being written
by a program – we need to identify the object being modiﬁed by the write
[operation].” The diﬀerence with respect to our approach is that we perform
more sophisticated argument modeling and include the complete function call
history instead of only the program counter of the system call. Therefore, we are
able to detect data modiﬁcation attacks as well as deviations from established
site-speciﬁc behaviors that cannot be statically derived.
A further class of proposals extracts models directly from the program’s source
code or binary representations using static analysis methods [23,7,8,3,27]. These
systems use static analysis to derive the system call automaton, which is then
extended with call stack information to remove impossible paths and increase
the precision of the detection process.
6 Conclusions and Future Work
In this paper, we presented a novel approach to the detection of anomalous sys-
tem calls. Diﬀerent from previous approaches, our solution combines dynamic
stack context analysis with the characterization of system call arguments. The
resulting context-sensitive system call model is eﬀective against data modiﬁ-
cation attacks, which do not modify the sequence of system calls executed by
vulnerable applications. It also improves upon the false positive rates of models
that only operate on argument values and ignore context information.
We have also introduced a metric that quantiﬁes the degree to which system
call arguments are unique to particular execution contexts. Applying this metric
to a number of programs deployed in a production setting showed that the set
of argument values is optimally or nearly optimally partitioned by the argument
sets associated with individual stack conﬁgurations. Future work will explore the
utility of applying this metric to other intrusion detection domains.
The use of system call argument modeling is orthogonal with respect to analy-
sis techniques that characterize system call sequences. In future work, we will
explore how the two approaches can be composed to achieve even more precise
detection and better resilience to mimicry attacks2.
References
1. Ammons, G., Ball, T., Larus, J.R.: Exploiting hardware performance counters
with ﬂow and context sensitive proﬁling. In: Proceedings of the Conference on
Programming Language Design and Implementation (PLDI’97) (1997)
2. Feng, H., Giﬃn, J., Huang, Y., Jha, S., Lee, W., Miller, B.: Formalizing sensitivity
in static analysis for intrusion detection. In: Proceedings of the IEEE Symposium
on Security and Privacy, May 2004, IEEE Computer Society Press, Los Alamitos
(2004)
2 This research was supported by the Army Research Oﬃce, under agreement
DAAD19-01-1-0484, and by the National Science Foundation, under grants CCR-
0238492 and CCR-0524853.
Exploiting Execution Context for the Detection of Anomalous System Calls
19
3. Feng, H., Kolesnikov, O., Fogla, P., Lee, W., Gong, W.: Anomaly detection using
call stack information. In: Proceedings of the IEEE Symposium on Security and
Privacy, May 2003, IEEE Computer Society Press, Los Alamitos (2003)
4. Forrest, S.: A Sense of Self for UNIX Processes. In: Proceedings of the IEEE Sym-
posium on Security and Privacy, Oakland, CA, May 1996, pp. 120–128. IEEE
Computer Society Press, Los Alamitos (1996)
5. Gao, D., Reiter, M., Song, D.: Gray-Box Extraction of Execution Graphs for Anom-
aly Detection. In: Proceedings of ACM CCS, Washington, DC, USA, October 2004,
pp. 318–329. ACM Press, New York (2004)
6. Gao, D., Reiter, M., Song, D.: On Gray-Box Program Tracking for Anomaly De-
tection. In: Proceedings of the 13th USENIX Security Symposium, San Diego, CA,
USA (August 2004)
7. Giﬃn, J., Jha, S., Miller, B.: Detecting Manipulated Remote Call Streams. In:
Proceedings of the 11th USENIX Security Symposium, pp. 61–79 (2002)
8. Giﬃn, J., Jha, S., Miller, B.: Eﬃcient context-sensitive intrusion detection. In:
Proceedings of the 11th Network and Distributed System Security Symposium,
San Diego, California (February 2004)
9. Hind, M., Burke, M., Carini, P., Choi, J.-D.: Interprocedural pointer alias analysis.
ACM Transactions on Programming Languages 21(4) (July 1999)
10. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Automating mimicry
attacks using static binary analysis. In: Proceedings of the 14th USENIX Security
Symposium (July 2005)
11. Kruegel, C., Mutz, D., Robertson, W., Valeur, F.: Bayesian Event Classiﬁcation for
Intrusion Detection. In: Omondi, A.R., Sedukhin, S. (eds.) ACSAC 2003. LNCS,
vol. 2823, Springer, Heidelberg (2003)
12. Kruegel, C., Mutz, D., Valeur, F., Vigna, G.: On the Detection of Anomalous
System Call Arguments. In: Snekkenes, E., Gollmann, D. (eds.) ESORICS 2003.
LNCS, vol. 2808, pp. 326–343. Springer, Heidelberg (2003)
13. Lee, S., Low, W., Wong, P.: Learning Fingerprints for a Database Intrusion Detec-
tion System. In: Gollmann, D., Karjoth, G., Waidner, M. (eds.) ESORICS 2002.
LNCS, vol. 2502, Springer, Heidelberg (2002)
14. Mutz, D.: Context-sensitive Multi-model Anomaly Detection. Ph.d. thesis, UCSB
(June 2006)
15. Mutz, D., Valeur, F., Kruegel, C., Vigna, G.: Anomalous System Call Detection.
ACM Transactions on Information and System Security 9(1), 61–93 (2006)
16. Nystrom, E., Kim, H., Hwu, W.: Importance of heap specialization in pointer
analysis. In: Proceedings of Program Analysis for Software Tools and Engineering
(2004)
17. Robertson, W., Vigna, G., Kruegel, C., Kemmerer, R.: Using Generalization and
Characterization Techniques in the Anomaly-based Detection of Web Attacks. In:
Proceeding of NDSS, San Diego, CA (February 2006)
18. Sekar, R., Bendre, M., Dhurjati, D., Bollineni, P.: A fast automaton-based method
for detecting anomalous program behaviors. In: Proceedings of the IEEE Sym-
posium on Security and Privacy, May 2001, IEEE Computer Society Press, Los
Alamitos (2001)
19. Sekar, R., Venkatakrishnan, V., Basu, S., Du Varney, B.S.D.: Model-carrying code:
A practical approach for safe execution of untrusted applications. In: Proceedings
of the 19th ACM Symposium on Operating Systems Principles, ACM Press, New
York (2003)
20. SNARE - System iNtrusion Analysis and Reporting Environment,
http://www.intersectalliance.com/projects/Snare
20
D. Mutz et al.
21. Stolcke, A., Omohundro, S.: Hidden Markov Model Induction by Bayesian Model
Merging. Advances in Neural Information Processing Systems (1993)
22. Stolcke, A., Omohundro, S.: Inducing probabilistic grammars by bayesian model
merging. In: Proceedings of the International Conference on Grammatical Inference
(1994)
23. Wagner, D., Dean, D.: Intrusion Detection via Static Analysis. In: Proceedings of
the IEEE Symposium on Security and Privacy, Oakland, CA, May 2001, IEEE
Press, Los Alamitos (2001)
24. Wagner, D., Soto, P.: Mimicry Attacks on Host-Based Intrusion Detection Systems.
In: Proceedings of ACM CCS, Washington DC, USA, November 2002, ACM Press,
New York (2002)
25. Warrender, C., Forrest, S., Pearlmutter, B.: Detecting intrusions using system calls:
Alternative data models. In: Proceedings of the IEEE Symposium on Security and
Privacy, pp. 133–145. IEEE Computer Society Press, Los Alamitos (1999)
26. Wespi, A., Dacier, M., Debar, H.: Intrusion Detection Using Variable-Length Audit
Trail Patterns. In: Debar, H., M´e, L., Wu, S.F. (eds.) RAID 2000. LNCS, vol. 1907,
Springer, Heidelberg (2000)
27. Xu, H., Du, W., Chapin, S.: Context Sensitive Anomaly Monitoring of Process
Control Flow to Detect Mimicry Attacks and Impossible Paths. In: Jonsson, E.,
Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, Springer, Heidelberg
(2004)