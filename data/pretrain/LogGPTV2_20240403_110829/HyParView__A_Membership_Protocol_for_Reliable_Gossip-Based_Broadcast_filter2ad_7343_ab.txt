### Cost-Effective Gossip Protocols

#### 2. High Failure Rates and Their Impact on Partial Views
High failure rates can significantly degrade the quality of partial views in gossip protocols. Even if a membership protocol has self-healing properties, the reliability of message broadcasts after heavy failures may be severely affected. Therefore, gossip protocols would greatly benefit from membership protocols with fast healing properties. This can be achieved by incorporating TCP as a failure detector.

In the following sections, we will illustrate these points with some figures.

### 3. Fanout Value Analysis

#### 3.1. On the Fanout Value
The first two plots in Figure 1 show simulation results for the reliability of a gossip protocol delivering 50 messages using Cyclon or Scamp as the underlying membership protocol. The simulations were conducted on a network of 10,000 nodes (details of our simulation model are provided in Section 5).

- **Cyclon**:
  - To achieve a reliability above 99%, a fanout of 5 is required.
  - A fanout of 6 is needed to reach near 99.9% reliability.

- **Scamp**:
  - A fanout of 6 is required to achieve a reliability above 99%.

In this scenario, a fanout of 6 results in approximately 20,000 extra messages compared to a fanout of 4. According to [4], a fanout of 4 should ensure a reliability between 98% and 99%. More than 99% of these 20,000 extra messages are redundant, meaning fewer than 200 of these messages actually contribute to the delivery. We will later demonstrate that our approach allows for higher reliability with a fanout value close to log(n).

### 4. Effect of Failures

#### 3.2. Effect of Failures
The last plot in Figure 1 shows the reliability of 100 messages exchanged after a 50% node failure in a network of 10,000 nodes using Cyclon and Scamp. These messages are sent before Cyclon has the opportunity to execute a cycle of shuffling (noting that the Cyclon period is typically long enough to exchange several thousand messages) or before the lease time of Scamp expires.

- **Reliability Loss**:
  - No message is delivered to more than 85% of the nodes.
  - Many messages are delivered to a much smaller number of nodes.

This prolonged period of instability may be unacceptable in applications requiring high reliability and throughput.

### 4. The HyParView Protocol

#### 4.1. Overview
The HyParView protocol maintains two distinct views at each node:

- **Active View**: A small view of size fanout+1, ensuring symmetric links and avoiding relaying messages back to the sender.
- **Passive View**: A larger view that ensures connectivity despite a large number of faults and must be larger than log(n). The overhead of the passive view is minimal as no connections are kept open.

The active views of all nodes create an overlay used for message dissemination. Links in the overlay are symmetric, meaning if node q is in the active view of node p, then node p is also in the active view of node q. Nodes use TCP to broadcast messages in the overlay, keeping an open TCP connection to every other node in their active view. When a node receives a message for the first time, it broadcasts the message to all nodes in its active view (excluding the sender). The gossip target selection is deterministic in the overlay, but the overlay itself is created randomly using the gossip membership protocol.

A reactive strategy is used to maintain the active view. Nodes can be added to the active view when they join the system and removed when they fail. Each node tests its entire active view every time it forwards a message, allowing for very fast failure detection.

In addition to the active view, each node maintains a larger passive view, which is not used for message dissemination. Instead, the passive view maintains a list of nodes that can replace failed members of the active view. The passive view is maintained using a cyclic strategy, where each node periodically performs a shuffle operation with one random node to update its passive view.

One interesting aspect of the shuffle mechanism is that the identifiers exchanged in a shuffle operation include not only those from the passive view but also the node's own identifier and some nodes from its active view. This increases the probability of having active nodes in the passive views and ensures that failed nodes are eventually removed from all passive views.

#### 4.2. Join Mechanism
Algorithm 1 depicts the pseudo-code for the join operation. When a new node n wishes to join the overlay, it must know another node c that already belongs to the overlay (the contact node). There are several ways to learn about the contact node, such as through well-known servers.

- **Join Process**:
  - The new node n establishes a TCP connection to the contact node c and sends a JOIN request.
  - The contact node c adds the new node to its active view, even if it has to drop a random node from it.
  - A DISCONNECT notification is sent to the node that has been dropped from the active view.
  - The contact node c then sends a FORWARDJOIN request to all other nodes in its active view, containing the new node's identifier.
  - The FORWARDJOIN request is propagated in the overlay using a random walk, with two configuration parameters: Active Random Walk Length (ARWL) and Passive Random Walk Length (PRWL).
  - The FORWARDJOIN request carries a "time to live" field initially set to ARWL and decremented at every hop.

When a node p receives a FORWARDJOIN request, it performs the following steps:

1. If the time to live is zero or the number of nodes in p’s active view is one, it adds the new node to its active view.
2. If the time to live is equal to PRWL, p inserts the new node into its passive view.
3. The time to live field is decremented.
4. If the new node has not been inserted into p’s active view, p forwards the request to a random node in its active view (different from the one from which the request was received).

#### 4.3. Active View Management
The active view is managed using a reactive strategy. When a node p suspects that a node in its active view has failed, it selects a random node q from its passive view and attempts to establish a TCP connection with q. If the connection fails, node q is considered failed and removed from p’s passive view; another node q0 is selected at random, and a new attempt is made. This process is repeated until a connection is established successfully.

- **Connection Establishment**:
  - When the connection is established, p sends a NEIGHBOR request to q with its own identifier and a priority level.
  - The priority level can be high (if p has no elements in its active view) or low (otherwise).

- **Handling NEIGHBOR Requests**:
  - A node q receiving a high-priority NEIGHBOR request always accepts it, even if it has to drop a random member from its active view.
  - A node q receiving a low-priority NEIGHBOR request only accepts it if it has a free slot in its active view.

If the node q accepts the NEIGHBOR request, p removes q’s identifier from its passive view and adds it to the active view. If q rejects the NEIGHBOR request, p selects another node from its passive view and repeats the procedure.

#### 4.4. Passive View Management
The passive view is maintained using a cyclic strategy. Periodically, each node performs a shuffle operation with one of its peers at random. The purpose of the shuffle operation is to update the passive views of the nodes involved in the exchange.

- **Shuffle Operation**:
  - The initiating node p creates an exchange list with its own identifier, ka nodes from its active view, and kp nodes from its passive view.
  - It sends the list in a SHUFFLE request to a random neighbor of its active view.
  - SHUFFLE requests are propagated using a random walk and have an associated "time to live".

- **Handling SHUFFLE Requests**:
  - A node q receiving a SHUFFLE request decreases its time to live.
  - If the time to live is greater than zero and the number of nodes in q’s active view is greater than one, q forwards the SHUFFLE request to a random node in its active view.
  - Otherwise, q accepts the SHUFFLE request and sends a SHUFFLEREPLY message with a number of nodes selected at random from its passive view.

Both nodes integrate the elements they received in the SHUFFLE/SHUFFLEREPLY message into their passive views, excluding their own identifier and nodes that are part of the active or passive views. If the passive view gets full, some identifiers are removed to make space for new ones.

#### 4.5. View Update Procedures
Algorithm 1 also shows basic manipulation primitives used to change the contents of the passive and active views. Nodes can move from the passive view to the active view to fill the active view (e.g., in reaction to node failures). Nodes can be moved from the active view to the passive view whenever a correct node has to be removed from the active view. Since links are symmetric, removing a node p from the active view of node q creates a "free slot" in p’s active view. Adding p to its passive view increases the probability of shuffling q with other nodes, potentially helping p to refill its view.

### 5. Evaluation

We conducted simulations using the PeerSim Simulator [11]. We implemented HyParView, Cyclon, and Scamp in this simulator to obtain comparative figures. To validate our implementation of Cyclon and Scamp, we compared the results of our simulator with published results for these systems (these simulations are omitted from the paper as they do not contribute to the assessment of our approach).

We also implemented a version of Cyclon, called CyclonAcked, which adds a failure detection system based on the exchange of explicit acknowledgments during message dissemination. CyclonAcked can detect and remove failed nodes, increasing the accuracy of partial views.

Finally, we implemented a gossip broadcast protocol on PeerSim that can use any of the above protocols as a peer sampling service. In this protocol, a node forwards a message when it receives it for the first time (therefore, there is no a priori bound on the number of gossip rounds).

### 5.1. Experimental Setting
All experiments were conducted on a network of 10,000 nodes, with results aggregated from multiple runs of each experiment. The membership protocols were configured as follows:

- **HyParView**:
  - Active membership size: 5
  - Passive membership size: 30
  - Active Random Walk Length (ARWL): 6
  - Passive Random Walk Length (PRWL): 3
  - Shuffle message: 8 elements (including the node's own identifier)

- **Cyclon**:
  - Partial views: 35 elements
  - Shuffle message length: 14
  - Time to live of random walks: 5

- **Scamp**:
  - Parameter c (related to fault-tolerance): 4
  - Partial views: around 34 elements

These configurations provide the best results for each protocol. HyParView achieves similar results with either method (we used the same procedure as Cyclon).