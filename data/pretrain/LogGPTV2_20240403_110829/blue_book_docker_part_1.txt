---
title: Docker
date: 20210216
author: Lyz
---
[Docker](https://en.wikipedia.org/wiki/Docker_%28software%29) is a set of
platform as a service (PaaS) products that use OS-level virtualization to
deliver software in packages called containers. Containers are isolated from
one another and bundle their own software, libraries and configuration files;
they can communicate with each other through well-defined channels. Because
all of the containers share the services of a single operating system kernel,
they use fewer resources than virtual machines.
# Installation
Follow [these instructions](https://docs.docker.com/engine/install/debian/)
If that doesn't install the version of `docker-compose` that you want use [the next snippet](https://stackoverflow.com/questions/49839028/how-to-upgrade-docker-compose-to-latest-version):
```bash
VERSION=$(curl --silent https://api.github.com/repos/docker/compose/releases/latest | grep -Po '"tag_name": "\K.*\d')
DESTINATION=/usr/local/bin/docker-compose
sudo curl -L https://github.com/docker/compose/releases/download/${VERSION}/docker-compose-$(uname -s)-$(uname -m) -o $DESTINATION
sudo chmod 755 $DESTINATION
```
If you don't want the latest version set the `VERSION` variable.
## Configure log aggregation
To centralize the logs you can either use journald or loki directly.
### [Send logs to journald](https://docs.docker.com/config/containers/logging/journald/)
The `journald` logging driver sends container logs to the systemd journal. Log entries can be retrieved using the `journalctl` command, through use of the journal API, or using the docker logs command.
In addition to the text of the log message itself, the `journald` log driver stores the following metadata in the journal with each message:
| Field |	Description |
| ---   |  ----  |
| CONTAINER_ID |	The container ID truncated to 12 characters. |
| CONTAINER_ID_FULL |	The full 64-character container ID. |
| CONTAINER_NAME |	The container name at the time it was started. If you use docker rename to rename a container, the new name isn't reflected in the journal entries. |
| CONTAINER_TAG, | SYSLOG_IDENTIFIER	The container tag ( log tag option documentation). |
| CONTAINER_PARTIAL_MESSAGE |	A field that flags log integrity. Improve logging of long log lines. |
To use the journald driver as the default logging driver, set the log-driver and log-opts keys to appropriate values in the `daemon.json` file, which is located in `/etc/docker/`.
```json
{
  "log-driver": "journald"
}
```
Restart Docker for the changes to take effect.
### [Send the logs to loki](https://grafana.com/docs/loki/latest/send-data/docker-driver/configuration/)
There are many ways to send logs to loki
- Using the docker plugin
- Using the journald driver and sending them to loki with promtail with the journald driver
- Using the json driver and sending them to loki with promtail with the docker driver
#### Using the json driver
#### Using journald 
This has worked for me but the labels extracted are not that great.
#### Using the docker plugin
Grafana Loki officially supports a Docker plugin that will read logs from Docker containers and ship them to Loki.
I would not recommend to use this path because there is a known issue that deadlocks the docker daemon :S. The driver keeps all logs in memory and will drop log entries if Loki is not reachable and if the quantity of `max_retries` has been exceeded. To avoid the dropping of log entries, setting `max_retries` to zero allows unlimited retries; the driver will continue trying forever until Loki is again reachable. Trying forever may have undesired consequences, because the Docker daemon will wait for the Loki driver to process all logs of a container, until the container is removed. Thus, the Docker daemon might wait forever if the container is stuck.
The wait time can be lowered by setting `loki-retries=2`, `loki-max-backoff_800ms`, `loki-timeout=1s` and `keep-file=true`. This way the daemon will be locked only for a short time and the logs will be persisted locally when the Loki client is unable to re-connect.
To avoid this issue, use the Promtail Docker service discovery.
#### Install the Docker driver client
The Docker plugin must be installed on each Docker host that will be running containers you want to collect logs from.
Run the following command to install the plugin, updating the release version if needed:
bash
```bash
docker plugin install grafana/loki-docker-driver:2.9.1 --alias loki --grant-all-permissions
```
To check installed plugins, use the `docker plugin ls` command. Plugins that have started successfully are listed as enabled:
```bash
$ docker plugin ls
ID                  NAME         DESCRIPTION           ENABLED
ac720b8fcfdb        loki         Loki Logging Driver   true
```
Once you have successfully installed the plugin you can configure it.
#### Upgrade the Docker driver client
The upgrade process involves disabling the existing plugin, upgrading, then re-enabling and restarting Docker:
```bash
docker plugin disable loki --force
docker plugin upgrade loki grafana/loki-docker-driver:2.9.1 --grant-all-permissions
docker plugin enable loki
systemctl restart docker
```
# How to keep containers updated
## [With Renovate](renovate.md)
[Renovate](renovate.md) is a program that does automated
dependency updates. Multi-platform and multi-language.
## With Watchtower
With [watchtower](https://containrrr.dev/watchtower/) you can update the running
version of your containerized app simply by pushing a new image to the Docker
Hub or your own image registry. Watchtower will pull down your new image,
gracefully shut down your existing container and restart it with the same
options that were used when it was deployed initially.
Run the watchtower container with the next command:
```bash
docker run -d \
--name watchtower \
-v /var/run/docker.sock:/var/run/docker.sock \
-v /etc/localtime:/etc/localtime:ro \
-e WATCHTOWER_NOTIFICATIONS=email \
-e WATCHTOWER_NOTIFICATION_EMAIL_FROM={{ email.from }} \
-e WATCHTOWER_NOTIFICATION_EMAIL_TO={{ email.to }} \\
-e WATCHTOWER_NOTIFICATION_EMAIL_SERVER=mail.riseup.net \
-e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587 \
-e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER={{ email.user }} \
-e WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD={{ email.password }} \
-e WATCHTOWER_NOTIFICATION_EMAIL_DELAY=2 \
containrrr/watchtower:latest --no-restart --no-startup-message
```
Use the `--no-restart` flag if you use systemd to manage the dockers, and
`--no-startup-message` if you don't want watchtower to send you an email each
time it starts the update process.
Keep in mind that if the containers don't have good migration scripts, upgrading
may break the service. To enable this feature, make sure you have frequent
backups and a tested rollback process. If you're not sure one of the containers
is going to behave well, you can only monitor it or disable it by using docker
labels.
The first check will be done by default in the next 24 hours, to
check that everything works use the `--run-once` flag.
Another alternative is [Diun](https://github.com/crazy-max/diun), which is a CLI
application written in Go and delivered as a single executable (and a Docker
image) to receive notifications when a Docker image is updated on a Docker
registry.
They don't [yet support Prometheus
metrics](https://github.com/crazy-max/diun/issues/201) but it surely looks
promising.
## [Logging in automatically](https://docs.docker.com/engine/reference/commandline/login/#provide-a-password-using-stdin)
To log in automatically without entering the password, you need to have the
password stored in your *personal password store* (not in root's!), imagine it's
in the `dockerhub` entry. Then you can use:
```bash
pass show dockerhub | docker login --username foo --password-stdin
```
## [Override entrypoint](https://phoenixnap.com/kb/docker-run-override-entrypoint)
```bash
sudo docker run -it --entrypoint /bin/bash [docker_image]
```
# Snippets
## [Add healthcheck to your dockers](https://www.howtogeek.com/devops/how-and-why-to-add-health-checks-to-your-docker-containers/)
Health checks allow a container to expose its workload’s availability. This stands apart from whether the container is running. If your database goes down, your API server won’t be able to handle requests, even though its Docker container is still running.
This makes for unhelpful experiences during troubleshooting. A simple `docker ps` would report the container as available. Adding a health check extends the `docker ps` output to include the container’s true state.
You configure container health checks in your Dockerfile. This accepts a command which the Docker daemon will execute every 30 seconds. Docker uses the command’s exit code to determine your container’s healthiness:
- `0`: The container is healthy and working normally.
- `1`: The container is unhealthy; the workload may not be functioning.
Healthiness isn’t checked straightaway when containers are created. The status will show as starting before the first check runs. This gives the container time to execute any startup tasks. A container with a passing health check will show as healthy; an unhealthy container displays unhealthy.
In docker-compose you can write the healthchecks like the next snippet:
```yaml
---
version: '3.4'
services:
  jellyfin:
    image: linuxserver/jellyfin:latest
    container_name: jellyfin
    restart: unless-stopped
    healthcheck:
      test: curl http://localhost:8096/health || exit 1
      interval: 10s
      retries: 5
      start_period: 5s
      timeout: 10s
```
## [List the dockers of a registry](https://stackoverflow.com/questions/31251356/how-to-get-a-list-of-images-on-docker-registry-v2)
List all repositories (effectively images):
```bash
$: curl -X GET https://myregistry:5000/v2/_catalog
> {"repositories":["redis","ubuntu"]}
```
List all tags for a repository:
```bash
$: curl -X GET https://myregistry:5000/v2/ubuntu/tags/list
> {"name":"ubuntu","tags":["14.04"]}
```
If the registry needs authentication you have to specify username and password in the curl command
```bash
curl -X GET -u : https://myregistry:5000/v2/_catalog
curl -X GET -u : https://myregistry:5000/v2/ubuntu/tags/list
```
## Attach a docker to many networks
You can't do it through the `docker run` command, there you can only specify one
network. However, you can attach a docker to a network with the command:
```bash
docker network attach network-name docker-name
```
## [Get the output of `docker ps` as a json](https://stackoverflow.com/questions/61586686/golang-template-to-format-docker-ps-output-as-json)
To get the complete json for reference.
```bash
docker ps -a --format "{{json .}}" | jq -s
```
To get only the required columns in the output with tab separated version
```bash
docker ps -a --format "{{json .}}" | jq -r -c '[.ID, .State, .Names, .Image]'
```
To get [also the image's ID](https://stackoverflow.com/questions/54075456/docker-ps-show-image-id-instead-of-name) you can use:
```bash
docker inspect --format='{{json .}}' $(docker ps -aq) | jq -r -c '[.Id, .Name, .Config.Image, .Image]'
```
## [Connect multiple docker compose files](https://tjtelan.com/blog/how-to-link-multiple-docker-compose-via-network/)
You can connect services defined across multiple docker-compose.yml files.
In order to do this you’ll need to: