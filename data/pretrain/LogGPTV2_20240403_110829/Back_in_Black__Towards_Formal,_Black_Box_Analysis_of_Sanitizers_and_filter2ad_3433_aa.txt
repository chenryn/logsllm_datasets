title:Back in Black: Towards Formal, Black Box Analysis of Sanitizers and
Filters
author:George Argyros and
Ioannis Stais and
Aggelos Kiayias and
Angelos D. Keromytis
2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy
Back in Black: Towards Formal, Black Box Analysis
of Sanitizers and Filters
George Argyros
Columbia University
PI:EMAIL
Ioannis Stais
University of Athens
PI:EMAIL
Aggelos Kiayias
University of Athens
PI:EMAIL
Angelos D. Keromytis
Columbia University
PI:EMAIL
Abstract—We tackle the problem of analyzing ﬁlter and
sanitizer programs remotely, i.e. given only the ability to query
the targeted program and observe the output. We focus on two
important and widely used program classes: regular expression
(RE) ﬁlters and string sanitizers. We demonstrate that existing
tools from machine learning that are available for analyzing
RE ﬁlters, namely automata learning algorithms, require a very
large number of queries in order to infer real life RE ﬁlters.
Motivated by this, we develop the ﬁrst algorithm that infers
symbolic representations of automata in the standard mem-
bership/equivalence query model. We show that our algorithm
provides an improvement of x15 times in the number of queries
required to learn real life XSS and SQL ﬁlters of popular web
application ﬁrewall systems such as mod-security and PHPIDS.
Active learning algorithms require the usage of an equivalence
oracle, i.e. an oracle that tests the equivalence of a hypothesis
with the target machine. We show that when the goal is to audit a
target ﬁlter with respect to a set of attack strings from a context
free grammar, i.e. ﬁnd an attack or infer that none exists, we
can use the attack grammar to implement the equivalence oracle
with a single query to the ﬁlter. Our construction ﬁnds on average
90% of the target ﬁlter states when no attack exists and is very
effective in ﬁnding attacks when they are present.
For the case of string sanitizers, we show that existing
algorithms for inferring sanitizers modelled as Mealy Machines
are not only inefﬁcient, but lack the expressive power to be able
to infer real life sanitizers. We design two novel extensions to
existing algorithms that allow one to infer sanitizers represented
as single-valued transducers. Our algorithms are able to infer
many common sanitizer functions such as HTML encoders and
decoders. Furthermore, we design an algorithm to convert the
inferred models into BEK programs, which allows for further
applications such as cross checking different sanitizer implemen-
tations and cross compiling sanitizers into different languages
supported by the BEK backend. We showcase the power of
our techniques by utilizing our black-box inference algorithms
to perform an equivalence checking between different HTML
encoders including the encoders from Twitter, Facebook and
Microsoft Outlook email, for which no implementation is publicly
available.
I.
INTRODUCTION
Since the introduction and popularization of code injection
vulnerabilities as major threats for computer systems, saniti-
zation and ﬁltering of unsafe user input is paramount to the
design and implementation of a secure system. Unfortunately
correctly implementing such functionalities is a very challeng-
ing task. There is a large literature on attacks and bypasses in
implementations both of ﬁlter and sanitizer functions [1]–[3].
The importance of sanitizers and ﬁlters motivated the
development of a number of algorithms and tools [4]–[7] to
analyze such programs. More recently, the BEK language [8]
was introduced. BEK is a Domain Speciﬁc Language(DSL)
which allows developers to write string manipulating functions
in a language which can then be compiled into symbolic ﬁ-
nite state transducers(SFTs). This compilation enables various
analysis algorithms for checking properties like commutativity,
idempotence and reversibility. Moreover, one can efﬁciently
check whether two BEK programs are equal and,
in the
opposite case to obtain a string in which the two programs
differ.
The BEK language offers a promising direction for the
future development of sanitizers where the programs developed
for sanitization will be formally analyzed in order to verify
that certain desired properties are present. However, the vast
majority of code is still written in languages like PHP/Java and
others. In order to convert the sanitizers from these languages
to BEK programs a signiﬁcant amount of manual effort is
required. Even worst, BEK is completely unable to reason for
sanitizers whose source code is not available. This signiﬁcantly
restricts the possibilities for applying BEK to ﬁnd real life
problems in deployed sanitizers.
In this paper we tackle the problem of black-box analysis
of sanitizers and ﬁlters. We focus our analysis on regular
expression ﬁlters and string sanitizers which are modelled as
ﬁnite state transducers. Although regular expression ﬁlters are
considered suboptimal choices for building robust ﬁlters [9],
their simplicity and efﬁciency makes them a very popular
option especially for the industry.
Our analysis is black-box, that is, without access to any sort
of implementation or source code. We only assume the ability
to query a ﬁlter/sanitizer and obtain the result. Performing a
black-box analysis presents a number of advantages; ﬁrstly,
our analysis is generic, i.e. indepedent of any programming
language or system. Therefore, our system can be readily ap-
plied to any software, without the need for a large engineering
effort to adjust the algorithms and implementation into a new
programming language. This is especially important since in
today’s world, the number of programming languages used
varies signiﬁcantly. To give an example, there are over 15
different programming languages used in the backend of the
15 most popular websites [10].
The second advantage of performing a black-box analysis
comes out of necessity rather than convience. Many times,
access to the source code of the program to be analyzed is
unavailable. There are multiple reasons this may happen; for
one, the service might be reluctant to share the source code
2375-1207/16 $31.00 © 2016 IEEE
© 2016, George Argyros. Under license to IEEE.
DOI 10.1109/SP.2016.14
DOI 10.1109/SP.2016.14
91
91
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
of its product website even with a trusted auditor. This is
the reason, that a large percentage of penetration tests are
performed in a black-box manner. Furthermore, websites such
as the ones encountered in the deep web, for example TOR
hidden services, are designed to remain as hidden as possible.
Finally, software running in hardware systems such as smart
cards is also predominately analyzed in a black-box manner.
Our algorithms come with a formal analysis; for every
algorithm we develop, we provide a precise description of the
conditions and assumptions under which the algorithm will
work within a given time bound and provide a correct model
of the target ﬁlter or sanitizer.
Our goal is to build algorithms that will make it easier
for an auditor to understand the functionality of a ﬁlter or
sanitizer program without access to its source code. We begin
by evaluating the most common machine learning algorithms
which can be used for this task. We ﬁnd that these algorithms
are not ﬁt for learning ﬁlters and sanitizers for different
reasons: The main problem in inferring regular expressions
with classical automata inference algorithms is the explosion in
the number of queries caused by the large alphabets over which
the regular expressions are deﬁned. This problem also occurs in
the analysis of regular expressions in program analysis appli-
cations (whitebox analysis), which motivated the development
of the class of symbolic ﬁnite automata which effectively
handles these cases [11]. Motivated by these advances, we
design the ﬁrst algorithm that infers symbolic ﬁnite automata
(SFA) in the standard active learning model of membership and
equivalence queries. We evaluate our algorithm in 15 real life
regular expression ﬁlters and show that our algorithm utilizes
on average 15 times less queries than the traditional DFA
learning algorithm in order to infer the target ﬁlter.
The astute reader will counter that an equivalence oracle
(i.e., an oracle that one submits a hypothesized model and a
counterexample is returned if there exists one) is not available
in remote testing and thus it has to be simulated at potentially
great cost in terms of number of queries. In order to address
this we develop a structured approach to equivalence oracle
simulation that is based on a given context free grammar G.
Our learning algorithm will simulate equivalence queries by
drawing a single random string w from L(G) \ L(H) where
L(H) is the language of the hypothesis. If w belongs to the
target we have our counterexample, while if not, we have found
a string w that is not recognized by the target. In our setting
strings that are not recognized by the target ﬁlter can be very
valuable: we set G to be a grammar of attack strings and we
turn the failure of our equivalence oracle simulation to the
discovery of a ﬁlter bypass! This also gives rise to what we
call Grammar Oriented Filter Auditing (GOFA): our learning
algorithm, equipped with a grammar of attack strings, can be
used by a remote auditor of a ﬁlter to either ﬁnd a vulnerability
or obtain a model of the ﬁlter (in the form of an SFA) that
can be used for further (whitebox) testing and analysis.
Turning our attention to sanitizers, we observe that in-
ferring ﬁnite state transducers suffers from even more fun-
damental problems. Current learning algorithms infer models
as Mealy machines, i.e. automata where at each transition one
input symbol is consumed and one output symbol is produced.
However, this model is very weak in capturing the behavior of
real life sanitizers where for each symbol consumed multiple,
or none, symbols are produced. Even worse, many modern
sanitizers employ a “lookahead”, i.e. they read many symbols
from the input before producing an output symbol. In order
to model such behavior the inferred transducers must be
non deterministic. To cope with these problems we make
three contributions: First, we show how to improve the query
complexity of the Shabaz-Groz algorithm [12] exponentially.
Second, we design an extension of the Shabaz-Groz algorithm
which is able to handle transducers which output multiple
or no symbols in each transition. Finally, we develop a new
algorithm, based on our previous extension, which is able to
infer sanitizers that employ a lookahead, i.e., base their current
output by reading ahead more than one symbol.
To enable more ﬁne grained analysis of our inferred
models we develop an algorithm to convert (symbolic) ﬁnite
transducers with bounded lookahead into BEK programs. This
algorithm enables an interesting application: In the original
BEK paper [8] the authors manually converted different HTML
encoder implementations into BEK programs and then used the
BEK infrastructure to check equivalence and other properties.
Our algorithms enable these experiments to be performed
automatically, i.e. without manually converting each imple-
mentation to a BEK program and more importantly, being ag-
nostic of the implementation details. In fact, we checked seven
HTML encode implementations: three PHP implementations,
one implementation from the AntiXSS library in .NET and we
also included models infered from the HTML encoders used
by the websites of Twitter and Facebook and by the Microsoft
Outlook email service. We detected differences between many
implementations and found that Twitter and Facebook’s HTML
encoders match the htmlspecialcharacters function of
PHP although the Outlook service encoder does not match the
MS AntiXSS implementation in .NET. Moreover, we found
that only one of these implementations is idempotent.
Finally, we point out
that although our algorithms are
focused on the analysis of sanitizers and ﬁlters they are general
enough to potentially being applied in a number of different
domains. For example, in appendix D, we show how one
can use an SFA to model decision trees over the reals. In
another application, Doupe et al. [13] create a state aware
vulnerability scanner, where they model the different states
of the application using a Mealy machine. In their paper
they mention they considered utilizing inference techniques
for Mealy machines but that this was infeasible, due to the
large number of transitions. However, our symbolic learning
algorithms are able to handle efﬁciently exactly those cases
and thus, we believe several projects will be able to beneﬁt
from our techniques.
A. Limitations
Since the analysis we perform is black-box, all of our
techniques are necessarily incomplete. Speciﬁcally, there might
be some aspect of the target program that our algorithms will
fail to discover. Our algorithms are not designed to ﬁnd, for
example, backdoors in ﬁlters and sanitizers where a “magic
string” is causing the program to enter a hidden state. Such
programs will necessarily require an exponential number of
queries in the worst case in order to analyze completely.
Moreover, our algorithms are not geared towards discovering
new attacks for certain vulnerability classes. We assume that
9292
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:23 UTC from IEEE Xplore.  Restrictions apply. 
the description of the attack strings for a certain vulnerability
class, for example XSS, is given in the form of a context free
grammar.
B. Contributions
To summarize, our paper makes the following contribu-
tions:
Learning Algorithms: We present the ﬁrst, to the best of
our knowledge, algorithm that learns symbolic ﬁnite automata
in the standard membership and equivalence query model.
Furthermore, we improve the query complexity of the Shabaz-
Groz algorithm [12], a popular Mealy machine learning al-
gorithm and present an extension of the algorithm capable
of handling Mealy Machines with ε-input transitions. Finally,
we present a novel algorithm which is able to infer ﬁnite
transducers with bounded lookahead. Our transducer learning
algorithms can also be easily extended in the symbolic setting
by expanding our SFA algorithm.
Equivalence Query Implementation: We present the Gram-
mar Oriented Filter Auditing (GOFA) algorithm which imple-
ments an equivalence oracle with a single membership query
for each equivalence query and demonstrate that it is capable
to either detect a vulnerability in the ﬁlter if one is present or,
if no vulnerability is present, to recover a good approximation
of the target ﬁlter.
Conversion to BEK programs: We present, in appendix C
an algorithm to convert our inferred models of sanitizers into
BEK programs which can then be analyzed using the BEK
infrastructure enabling further applications.
Applications/Evaluation: We showcase the wide applicability
of our algorithms with a number of applications. Speciﬁcally,
we perform a thorough evaluation of our SFA learning al-
gorithm and demonstrate that it achieves a big performance
increase on the total number of queries performed. We also
evaluate our GOFA algorithm and demonstrate that it is able
to either detect attacks when they are present or give a good
approximation of the target ﬁlter. To showcase our transducer
learning algorithms we infer models of several HTML en-
coders, convert them to BEK program and check them for
equivalence.
We point out that, due to lack of space all proofs have been
moved into the appendix.
II. PRELIMINARIES
A. Background in Automata Theory
If M is a deterministic ﬁnite automaton (DFA) deﬁned over
alphabet Σ, we denote by |M| the number of states of M and
by L(M ) the language that is accepted by M. For any k we
denote by [k] the set {1, . . . , k}. We denote the set of states
of M by QM . A certain subset F of QM is identiﬁed as the
set of ﬁnal states. We denote by l : QM → {0, 1} a function
which identiﬁes a state as ﬁnal or non ﬁnal. The program of
the ﬁnite automaton M is determined by a transition function
δ over QM × Σ → QM . For an automaton M we denote by
¬M the automaton M with the ﬁnal states inverted.
A push-down automaton (PDA) M extends a ﬁnite au-
tomaton with a stack. The stack accepts symbols over an
alphabet Γ. The transition function is able to read the top of the
stack. The transition function is over QM × Σ × (Γ ∪ {ε}) →
QM × (Γ∪{ε}). A context-free grammar (CFG) G comprises
a set of rules of the form A → w where A ∈ V and
w ∈ (Σ ∪ V )
∗ where V is a set of non-terminal symbols.
The language deﬁned by a CFG G is denoted by L(G).
A transducer T extends a ﬁnite automaton with an output
tape. The automaton is capable of producing output in each
transition that belongs to an alphabet Γ. The transition function
is deﬁned over QM × (Σ ∪ {ε}) → QM × (Γ ∪ {ε}). A
Mealy Machine M is a deterministic transducer without ε
transitions where,
in addition, all states are ﬁnal. A non-
deterministic transducer has a transition function which is a
relation δ ⊆ QM × (Σ ∪ {ε}) × QM × (Γ ∪ {ε}). For general
transducers (deterministic or not), following [8], we extend
∗. A
the deﬁnition of a transducer to produce output over Γ
non-deterministic transducer is single-valued if it holds that
∗ there exists at most one γ ∈ Γ
for any w ∈ Σ
∗ such
that T on w outputs γ. A single-valued transducer T has
the bounded lookahead property if there is a k such that
any sequence of transitions involves at most k consecutive
non-accepting states. We call such a sequence a lookahead
path or lookahead transition. In a single valued transducer
with bounded lookahead we will call the paths that start and
ﬁnish in accepting states and involve only non-accepting states
as lookahead paths. The path in its course consumes some
input w ∈ Σ
∗. The bounded