horizon over which they are carried out. Most studies on
the PCA-subspace method use a one week training period,
so we assume that PCA is retrained each week. Thus the
PCs used in any week m are those learned during week m−1
with any detected anomalies removed. Thus for our poison-
ing attacks, the adversary inserts chaﬀ along the target OD
ﬂow throughout the one week training period. We also con-
sider a long-term attack in which the adversary slowly, but
increasingly, poisons the principal components over several
weeks, by adding small amounts of chaﬀ, in gradually in-
creasing quantities. We call this the Boiling Frog poisoning
method after the folk tale that one can boil a frog by slowly
increasing the water temperature over time1.
We assume the adversary does not have control over exist-
ing traﬃc (i.e., he cannot delay or discard traﬃc). Similarly,
the adversary cannot submit false SNMP reports to PCA.
Such approaches are more conspicuous because the incon-
sistencies in SNMP reporting from neighboring PoPs could
expose the compromised router.
This paper focuses on non-distributed poisoning of DoS
detectors. Distributed poisoning that aims to evade a DoS
detector is also possible; our globally-informed poisoning
strategy is an example, as the adversary has control over
all network links. We focus on DoS for a two reasons. In
our ﬁrst study on this topic, we aim to solve the basic prob-
lem ﬁrst before tackling a distributed version. Second, we
point out that results on evasion via non-distributed poi-
soning are stronger than distributed poisoning results: the
DDoS attacker can monitor and inﬂuence many more links
than the DoS attacker. Hence a DoS poisoning scenario is
usually stealthier than a DDoS one.
For each of these scenarios of diﬀerent information avail-
able to the adversary, we now outline speciﬁc poisoning
schemes. In each scheme, the adversary decides on the quan-
tity of ct chaﬀ to add to the target ﬂow time series at a time
t. Each strategy has an attack parameter θ, which controls
the intensity of the attack. For each scenario, we present
only one speciﬁc poisoning scheme. We have studied others,
but those included here are representative.
3.2 Uninformed Chaff Selection
At each time t, the adversary decides whether or not to
inject chaﬀ according to a Bernoulli random variable. If he
decides to inject chaﬀ, the amount of chaﬀ added is of size
θ, i.e., ct = θ. This method is independent of the network
traﬃc since our attacker is uninformed. We call this the
Random scheme.
3.3 Locally-Informed Chaff Selection
The attacker’s goal is to increase traﬃc variance, on which
the PCA detector’s model is based. In the locally-informed
scenario, the attacker knows the volume of traﬃc in the
ingress link he controls, yS(t). Hence this scheme elects to
only add chaﬀ when the existing traﬃc is already reasonably
large. In particular, we add chaﬀ when the traﬃc volume on
the link exceeds a parameter α (we typically use the mean).
The amount of chaﬀ added is ct = (max {0, yS(t) − α}})
θ
.
In other words, we take the diﬀerence between the link traf-
ﬁc and a parameter α and raise it to θ.
In this scheme
(called Add-More-If-Bigger ), the further the traﬃc is from
the average load, the larger the deviation of chaﬀ inserted.
3.4 Globally-Informed Chaff Selection
The globally-informed scheme captures an omnipotent ad-
versary with full knowledge of Y, A, and the future mea-
surements ˜yt, and who is capable of injecting chaﬀ into any
network ﬂow during training. This latter point is important.
In previous poisoning schemes the adversary can only inject
chaﬀ along their compromised link, whereas in this scenario,
the adversary can inject chaﬀ on any link. We formalize
the problem of selecting a link n to poison, and selecting
an amount of chaﬀ Ctn as an optimization problem that
the adversary solves to maximally increase his chances of
evasion. Although these globally-informed capabilities are
unrealistic, we include a globally-informed poisoning strat-
egy in order to understand the limits of variance injection
methods.
The PCA Evasion Problem considers an adversary wish-
ing to launch an undetected DoS attack of volume δ along
ﬂow f at time t. If the vector of link volumes at future time
t is ˜yt, where the tilde distinguishes this future measurement
from past training data ¯Y, then the vectors of anomalous
t = ˜yt + δ ∗ Af . Denote by C
(cid:4)
DoS volumes are given by ˜y
the matrix of link traﬃc injected into the network by the
adversary during training. Then the PCA-based anomaly
detector is trained on altered link traﬃc matrix ¯Y + C to
produce the mean traﬃc vector μ, the top K eigenvectors
V1:K, and the squared prediction error threshold Qβ. The
adversary’s objective is to enable as large a DoS attack as
possible (maximizing δ) by designing C. The PCA Evasion
Problem corresponds to solving the following:
max
δ∈R, C∈RT ×F
s.t.
δ
‚‚‚V
(μ, V, Qβ) = PCA(Y + C)
≤ Qβ
t − μ)
(cid:4)
(cid:2)
K+1:N (˜y
‚‚‚
(cid:3)C(cid:3)1 ≤ θ
2
∀t, n Ctn ≥ 0 ,
1Note that there is nothing inherent in the choice of a one-
week poisoning period. For a general SML algorithm, our
strategies would correspond to poisoning over one training
period (whatever its length) or multiple training periods.
where θ is a constant constraining total chaﬀ. The second
constraint guarantees evasion by requiring that the contam-
inated link volumes at time t are classiﬁed innocuous (cf.
Eq. 2). The remaining constraints upper-bound the total
chaﬀ volume by θ and constrain the chaﬀ to be non-negative.
4Unfortunately, this optimization is diﬃcult to solve an-
alytically. Thus we construct a relaxed approximation to
obtain a tractable analytic solution. We make a few as-
sumptions and derivations2, and show that the above objec-
tive seeks to maximize the attack direction Af ’s projected
length in the normal subspace maxC∈RT ×F
2.
Next, we restrict our focus to traﬃc processes that gener-
ate spherical k-rank link traﬃc covariance matrices3. This
property implies that the eigen-spectrum consists of K ones
followed by all zeroes. Such an eigen-spectrum allows us
to approximate the top eigenvectors V1:K in the objective,
with the matrix of all eigenvectors weighted by their corre-
sponding eigenvalues ΣV. We can thus convert the PCA
evasion problem into the following optimization:
‚‚V
(cid:2)
1:K Af
‚‚
max
C∈RT ×F
s.t.
(cid:3)C(cid:3)1 ≤ θ
∀t, n Ctn ≥ 0 .
‚‚( ¯Y + C)Af
‚‚
2
(3)
Solutions to this optimization are obtained by a standard
Projection Pursuit method from optimization:
iteratively
take a step in the direction of the objective’s gradient and
then project onto the feasible set.
These solutions yield an interesting insight. Recall that
our adversary is capable of injecting chaﬀ along any ﬂow.
One could imagine that it might be useful to inject chaﬀ
along an OD ﬂow whose traﬃc dominates the choice of prin-
cipal components (i.e., an elephant ﬂow), and then send the
DoS traﬃc along a diﬀerent ﬂow (that possibly shares a
subset of links with the poisoned OD ﬂow). However the
solutions of Eq. (3) indicates that the best strategy to evade
detection is to inject chaﬀ only along the links Af associated
with the target ﬂow f . This follows from the form of the ini-
tializer C(0) ∝ ¯YAf A
(cid:2)
f (obtained from an L2 relaxation)
as well as the form of the projection and gradient steps. In
particular, all these objects preserve the property that the
solution only injects chaﬀ along the target ﬂow. In fact, the
only diﬀerence between this globally-informed solution and
the locally-informed scheme is that the former uses infor-
mation about the entire traﬃc matrix Y to determine chaﬀ
allocation along the ﬂow whereas the latter use only local
information.
3.5 Boiling Frog Attacks
Boiling Frog poisoning can use any of the preceding chaﬀ
schemes to select ct. The duration of poisoning is increased
as follows. We initially set the attack parameter θ to a small
value and then increase it slowly over time. In the ﬁrst week
of the attack, the target ﬂow is injected with chaﬀ generated
using parameter θ1. At the week’s end, PCA is retrained on
that week’s data. Any anomalies detected by PCA during
that week are excluded from future training data. This pro-
cess continues with θt > θt−1 used for week t. Even though
PCA is retrained from scratch each week, the training data
includes events not caught by the previous detector. Thus,
each successive week will contain additional malicious train-
ing data, with the process continuing until the week of the
DoS attack, when the adversary stops injecting chaﬀ.
4. ANTIDOTE: A ROBUST DEFENSE
For defenses against our attacks on PCA-based anom-
aly detection we explore techniques from Robust Statistics.
Such methods are less sensitive to outliers, and as such are
ideal defenses against variance injection schemes that per-
turb data to increase variance along the target ﬂow. There
have been two approaches to make PCA robust: the ﬁrst
computes the principal components as the eigenspectrum of
a robust estimate of the covariance matrix [9], while the
second approach searches for directions that maximize a ro-
bust scale estimate of the data projection. We propose one
of the latter methods as a defense against our poisoning.
After describing the method, we propose a new threshold
statistic that can be used for any PCA-based method includ-
ing robust PCA. Robust PCA and the new robust Laplace
threshold together form a new network-wide traﬃc anomaly
detection method, antidote, that is less sensitive to our
poisoning attacks.
4.1 Intuition
Fundamentally, to mitigate the eﬀect of poisoning attacks,
we need a learning algorithm that is stable in spite of data
contamination; i.e., a small amount of data contamination
should not dramatically change the model produced by our
algorithm. This concept of stability has been studied in the
ﬁeld of Robust Statistics in which robust is the formal term
used to qualify this notion of stability. In particular, there
have been several approaches to developing robust PCA al-
gorithms that construct a low dimensional subspace that
captures most of the data’s dispersion 4 and are stable un-
der data contamination [6, 7, 9, 19, 23].
(4)
S (Ya) .
”1/2
Pn
i=1 ri − ¯r
The robust PCA algorithms we considered search for a
unit direction v whose projections maximize some univariate
dispersion measure S (·); that is,
v ∈ arg max
(cid:3)a(cid:3)2=1
“
The standard deviation is the dispersion measure used by
PCA; i.e., SSD (r1, r2, . . . , rn) =
. How-
ever, the standard deviation is sensitive to outliers making
PCA non-robust to contamination. Robust PCA algorithms
instead use measures of dispersion based on the concept of
robust projection pursuit (RPP) estimators [19]. As is shown
by Li & Chen, RPP estimators achieve the same breakdown
points as their dispersion measure (the breakdown point is
the (asymptotic) fraction of the data an adversary must con-
trol in order to arbitrarily change an estimator, and as such
is a common measure of statistical robustness) as well as
being qualitatively robust; i.e., the estimators are stable.
1
n−1
However, unlike the eigenvector solutions that arise in
PCA, there is generally no eﬃciently computable solution
for robust dispersion measures and so these must be approx-
imated. Below, we describe the PCA-GRID algorithm, a
successful method for approximating robust PCA subspaces
developed by Croux et al. [6]. Among the projection pur-
suit techniques we tried [7, 23], PCA-GRID proved to be
most resilient to our poisoning attacks. It is worth empha-
sizing that the procedure described in the next section is
2The full proof is ommitted due to space constraints.
3While the spherical assumption does not hold in practice,
the assumption of low-rank traﬃc matrices is met by pub-
lished datasets [16].
4Dispersion is an alternative term for variation since the
later is often associated with statistical variation. By a dis-
persion measure we mean a statistic that measures the vari-
ability or spread of a variable.
5w
o
F
l
t
e
g
r
a
T
o
n
o
t
n
o
t
i
c
e
o
r
P
j
w
o
F
l
t
e
g
r
a
T
o
t
n
o
n
o
t
i
c
e
o
r
P
j
8
0
+
e
1
7
0
+
e
8
7
0
+
e
6
7
0
+
e
4
7
0
+
e
2
0
0
+
e
0
8
0
+
e
1
7
0
+
e
8
7
0
+
e
6
7
0
+
e
4
7
0
+
e
2
0
0
+
e
0
Subspaces with no Poisoning
Initial PCA
Initial ANTIDOTE
5e+08
6e+08
7e+08
9e+08
Projection on 1st PC
8e+08
Subspaces with 35 % Poisoning
●
●
●
●
●
●
●
●
●
●
1e+09
●
●
●
Initial PCA
Initial ANTIDOTE
Poisoned PCA
Poisoned ANTIDOTE
●
●
●