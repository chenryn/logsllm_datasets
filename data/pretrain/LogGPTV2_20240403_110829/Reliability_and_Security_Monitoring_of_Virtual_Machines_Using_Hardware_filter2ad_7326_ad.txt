
+3


.+3
-+3

/+3

	
0+3
,++3

!

$



!





!

$



!

!










"








"










"








"



&
(,
(-
 %
%
&
(,
(-
 %
%
&
(,
(-
 %
%
&
(,
(-
 %
%
Fig. 4: Guest OS Hang Detection coverage

			


			






























Fig. 5: Guest OS Hang Detection latency. The blue line (with
triangle markers) reﬂects the latency of detecting the ﬁrst hang
of a two vCPU VM. The red dashed line (with circle markers)
reﬂects the latency of partial hangs.
• Not Detected: A fault was injected, the VM was non-
responsive but GOSHD did not report a vCPU hang.
• Not Activated: A fault was injected, but the workload
did not execute the code that contained the fault.
• Partial Hang: At least one vCPU was still operational
after 10 minutes (roughly twice the longest failure-free
execution of the workloads) from the time a hang was
detected on another vCPU.
• Full Hang: All vCPUs hung within 10 minutes after hang
was detected on the ﬁrst vCPU.
3) Detection Coverage Results: Fig. 4 summarizes the
detection coverage and percentages of partial and full hangs
detected by GOSHD. About 82% of injected faults manifested
as hangs. Overall, GOSHD missed 24 failures across all exper-
iments, which resulted in 14,720 failures (17,952 injections ×
0.82 manifested faults) or a hang detection coverage of 99.8%.
Further analysis of the misclassiﬁed failures indicates that
the failures were caused by a fault location that was repeatedly
activated by the guest SSH server, which was used by our
external probe to check for false alarms by GOSHD. As a
result, although the SSH probe reported hangs, the kernel and
other processes on the VM still executed normally.
On average, 18% to 26% of faults caused partial hangs
on the non-preemptible and preemptible kernels, respectively.
Those signiﬁcant numbers emphasize the importance of partial
hang detection. In many partial hang cases,
the VM was
21212121
still accessible from outside (e.g., via SSH connections). That
demonstrates the ineffectiveness of hang detection methods
such as heartbeats, as the process/thread responsible for gener-
ating a heartbeat can still be fully operational and will continue
to report that the system is as well.
Transient faults caused slightly more partial hangs than per-
manent faults did in single-task workloads (Hanoi Tower and
make -j1), but signiﬁcantly more partial hangs in concurrent
multi-tasking workloads (make -j2 and HTTP server), because
persistent faults can be reactivated and cause more independent
hanging threads.
Kernel preemption does not appear to help prevent a hang
due to spinlocks, as most critical sections in the kernel are non-
preemptible. However, preemption does reduce the number of
full hangs. For example, consider two tasks T1 and T2 sharing
a user-level lock lu. While holding lu, task T1 hangs because
of our injection into a kernel spinlock. Task T1 cannot be
preempted because it is executing in a non-preemptible critical
section (causing a partial hang). Now let us assume that task
T2 attempts to acquire lu. In the non-preemptible kernel, task
T2 will hang as well, thus causing a full hang. But in the
preemptible kernel, task T2 can be preempted, and therefore
the kernel remains in a partial hang.
4) Detection Latency Results: Detection latency measures
how quickly a detector can identify a problem. GOSHD
raises an alarm when it ﬁnds that the guest OS scheduler
has not scheduled processes for a predeﬁned time. Therefore,
GOSHD’s minimal detection latency is that threshold (four
seconds in our experiments). Speciﬁcally, detection latency
represents the time between fault activation and the moment
GOSHD raises an alarm. Note that
the guest OS is not
necessarily hung at the moment the fault is injected. Fig. 5
shows the detection latency of GOSHD for the same set of
experiments described previously. Fig. 5 demonstrates how
partial hang detection helps reduce full hang detection latency.
The blue line (triangles) shows that GOSHD can detect more
than 90% of hangs after four seconds and all hangs within
32 seconds. Meanwhile, the red line (circles) shows that only
54% of hangs result in a full hang after four seconds. Many
full hangs can be detected tens of seconds ahead through the
use of partial hang detection.
B. Hidden Rootkit Detection
1) HRKD Coverage: We tested HRKD on a variety of
OSes and HRKD detected the presence of malware against all
tested real-world rootkits.5 On Windows, the tested rootkits
included FU, HideProc, AFX, HideToolz, HE4Hook, and
BH. HRKD’s process counting technique showed additional
processes beyond those reported by the Task Manager. On
Linux, HRKD was able to discover all tested kernel-level
rootkits: Ivyl’s, Enyelkm 1.2, SucKIT, and PhalanX. Table II
summarizes the results.
Since HRKD’s process counting technique relies only on
architectural invariants, it worked properly for all tested OSes,
5We modiﬁed some rootkits’ source code so they could work properly on our tested
OS versions.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:30:24 UTC from IEEE Xplore.  Restrictions apply. 















	







Fig. 6: Top: Transient attack, the attacker attacks when a
passive monitor is not logging. Bottom: Spamming attack, the
attacker causes an attack to go undetected by creating extra
work for both the logger and auditor.
namely Windows XP, Vista, 7, and Server 2008, and various
distributions of Linux kernel 2.6, without any adjustment. In
addition, the detection capability of that technique was not
affected by the implementation or strategy used by rootkits.
In fact, the rootkits we evaluated employed a variety of hiding
techniques, ranging from DKOM to system call hijacking (see
Table II). Thus, HRKD will be able to detect future hidden
rootkits, even if they use novel hiding mechanisms.
C. The Three Ninjas
1) Illustrating Attacks on Ninja: Here, we intend to use
Ninja only to demonstrate the limitations of passive monitor-
ing, and are not criticizing its checking rules. We evaluated two
passive-monitoring versions of Ninja: an original in-OS ver-
sion (O-Ninja) and our modiﬁed version (H-Ninja), which was
implemented at the hypervisor-level using traditional VMI.
Later on, we will compare those two implementations against
our active monitoring HT-Ninja. But ﬁrst, we demonstrate four
attacks that can bypass passive monitoring mechanisms:
Transient attacks: We used two real privilege escalation
exploits, namely a glibc vulnerability (CVE-2010-3847) [35]
and a kernel out-of-bounds error (CVE-2013-1763) [36] to
obtain a terminal with root privileges. Ninja can easily detect
the privilege escalated terminal if it remains in the system.
However, when we terminated a process right after it ﬁnished
an operation (e.g., copying sensitive data), both Ninja versions
were unaware of the existence of the terminal, as its lifetime
was short. See the top of Fig. 6 for an illustration.
Side channel attacks: We exploited the Linux /proc ﬁle
system as a side channel [37] to determine Ninja’s monitoring
interval and when each check would be performed. Specif-
ically, the ﬁle /proc/PID/stat allowed us to determine
the current state of a process (e.g., Sleep or Running) and the
current instruction pointer (EIP). By observing Ninja’s process
TABLE II: Real-world rootkits evaluated with HRKD (All
were detected).
Rootkit
FU
HideProc
AFX
HideToolz
HE4Hook
BH-Rookit-NT Win XP, Vista
Linux >2.6.29
Ivyl’s Rootkit
Linux 2.6
Enyelkm 1.2
Linux 2.6
SucKIT
PhalanX
Linux 2.6
Hiding Technique(s)
DKOM
DKOM
Hijack system calls
Hijack system calls
Hijack system calls
Hijack system calls
Hijack system calls
kmem, Hijack system calls
kmem, DKOM
kmem, DKOM
Target OS
Win XP, Vista
Win XP, Vista
Win XP, Vista
Win XP, Vista, 7
Win XP
TABLE III: Predicting Ninja’s monitoring interval (seconds)
Ninja’s Interval
Predicted Mean Min
1
2
4
8
1.00039
2.00023
4.00025
8.00025
1.00006
1.99998
3.99986
7.99951
Max
1.00367
2.00164
4.00189
8.00126
SD
0.00071
0.00038
0.00040
0.00035
state, we could accurately measure the monitoring inteval, i.e.,