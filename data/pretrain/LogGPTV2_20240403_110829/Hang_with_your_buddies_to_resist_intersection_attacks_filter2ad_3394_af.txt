evaluations on the additional delay added by Buddies. We
constructed a network of 8 server machines, 64 client ma-
chines, and from 8 to 512 clients (running up to 8 clients
on each client machine). Clients have a 50 millisecond delay
Figure 8: The overhead of using Buddies in Dissent.
and aggregate 100 M/bit connection to servers, while servers
have a 10 millisecond delay to other servers, but each has
a dedicated 100 M/bit connection to every other server. To
focus on the overheads Buddies incurs, we avoided sending
anonymous plaintexts across Dissent, The results, shown in
Figure 8, indicate that Buddies imposes negligible overhead
over Dissent—within measurement error—because perfor-
mance costs are dominated by the expensive asymmetric
cryptography used in signing and verifying messages.
6. RELATED WORK
The utility of pseudonyms has been well-recognized since
Chaum’s seminal paper on mix networks [8]. Pseudonymity
has motivated much work in anonymous authentication [36]
and signature schemes [24,35]. One way to protect distributed
 1 2 3 5 10 20 30 50 100 200 300 500 10001sec1min1hour1day1weekAnonymity Set SizeTime since pseudonym’s first activity12864161 1 2 3 5 10 20 30 50 100 200 300 500 10001sec1min1hour1day1weekAnonymity Set SizeTime since pseudonym’s first activityPossinimityLikelihoodBuddy set 1 2 3 5 10 20 30 50 100 200 300 500 10001hour1day1weekAnonymity Set SizeTime since pseudonym’s first activity12864161 1 2 3 5 10 20 30 50 100 200 300 500 10001hour1day1weekAnonymity Set SizeTime since pseudonym’s first activityPossinimityLikelihoodBuddy set 1 2 3 5 10 20 30 50 100 200 300 500 10001day1weekAnonymity Set SizeTime since pseudonym’s first activity12864161 1 2 3 5 10 20 30 50 100 200 300 500 10001day1weekAnonymity Set SizeTime since pseudonym’s first activityPossinimityLikelihoodBuddy set 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11sec1min1hour1day1weekPercent of PseudonymsUsable Pseudonym LifetimeNominal2163264 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11sec1min1hour1day1weekPercent of PseudonymsUsable Pseudonym LifetimeOracleDynamic 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11hour1day1weekPercent of PseudonymsUsable Pseudonym LifetimeNominal2163264 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11hour1day1weekPercent of PseudonymsUsable Pseudonym LifetimeOracleDynamic 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11day1weekPercent of PseudonymsUsable Pseudonym LifetimeNominal2163264 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11day1weekPercent of PseudonymsUsable Pseudonym LifetimeOracleDynamic 0.27 0.28 0.29 0.3 0.31 0.32 0.33 0.34 10 100Round Time in SecondsTotal Clientsbaseproactivereactive1164(a) 1-second rounds
(b) 1-hour rounds
(c) 1-day rounds
Figure 7: CDFs showing distributions of delays imposed on successfully transmitted messages under Buddies.
systems from Sybil attacks [19] is to build online pseudonyms
atop “real-world” identities [22]. None of these approaches
protect a pseudonym’s owner from being traced via network
monitoring, however. We concur with recent proposals to
integrate pseudonymity into network architecture [29], al-
though this gateway-based proposal unfortunately has the
same “single point of failure” weakness as a conventional
single-hop proxy or commercial VPN service [1].
Multi-hop mix networks [15] and onion routing systems [18]
address this single point of failure, but remain vulnerable to
many traﬃc analysis attacks. Pseudonymous communica-
tion is by now well-known to be highly vulnerable to long-
term intersection attacks [31,42], later strengthened into sta-
tistical disclosure attacks [16, 37, 53]. Padding communica-
tions to a constant rate with dummy traﬃc [4, 6, 14, 23] can
slow—but not stop—passive intersection attacks [37].
Padding may not even slow active attacks, however, where
an attacker deliberately perturbs performance to trace a cir-
cuit [20, 38, 45]. Active attacks are eminently realistic, being
already widely used for Internet censorship [26, 49], for ex-
ample. Buddies is the only architecture we are aware of that
addresses both passive and active intersection attacks, by
“collectivizing” the anonymizer’s control plane logic into a
Policy Oracle component that cannot see—and thus can-
not leak—sensitive information (Section 2), even when repli-
cated for accountability (Section 4.3). This architecture en-
sures that Buddies’ attack mitigation policies apply regard-
less of whether clients churn “normally,” or are forced to slow
or go oﬄine due to deliberate denial-of-service.
The Java Anonymous Proxy [3] incorporates an “Anonym-
O-Meter” [21], to give users an indication of their current
anonymity level. This meter does not address intersection
attacks, but serves as a precedent for Buddies’ computation
and reporting of possinymity and indinymity metrics.
Prior systems also protect anonymity within well-deﬁned
groups. Tarzan [23] organizes an overlay of mimics, where
each user maintains constant cover traﬃc with k other mim-
ics to mitigate traﬃc analysis attacks. Systems based on
DC-nets [9], such as Herbivore [46] and earlier versions of
Dissent [11, 13, 52], achieve provable traﬃc analysis resis-
tance for unlinkable messages in a single communication
round. Since every group member typically knows the on-
line status of every other, however, linkable transmissions
using pseudonyms can make such systems more vulnerable
to intersection attack than “amorphous” systems such as Tor.
Buddies addresses this risk by using linkable ring signatures
to authenticate and “tag” users (Section 4.3).
Hopper and Vasserman [30] establish anonymity among
sets of k members in a mix, similar to buddy sets, and ex-
plore the resistance of these k-anonymity sets to statistical
disclosure attacks. Buddies builds on this approach to of-
fer users dynamic anonymity monitoring and active controls
over tradeoﬀs between anonymity and performance. Aqua [6]
uses padded, multipath onion routing to achieve eﬃciency
and reduce vulnerability to traﬃc analysis. We expect Bud-
dies be synergistic with designs like Aqua’s, by providing a
stronger and more controllable notion of intersection attack
resistance than currently provided by Aqua’s k-sets.
7. CONCLUSION
Buddies oﬀers the ﬁrst systematic architecture address-
ing long-term intersection attacks in anonymity systems, by
oﬀering passive metrics of vulnerability and active control
policies. While only a ﬁrst step leaving many open ques-
tions, our trace-based simulations and working prototype
suggest that Buddies may point to practical ways of further
protecting anonymity-sensitive users of online forums.
Acknowledgments
We would like to thank Joan Feigenbaum, Aaron Johnson,
Peter Druschel, our shepherd Clay Shields, and the anonym-
ous reviewers for their helpful feedback on this paper. This
material is based upon work supported by the Defense Ad-
vanced Research Agency (DARPA) and SPAWAR Systems
Center Paciﬁc, Contract No. N66001-11-C-4018.
8. REFERENCES
[1] Anonymizer, September 2012. http://anonymizer.com/.
[2] K. Bauer et al. Bitblender: light-weight anonymity for
BitTorrent. In AIPACa, 2008.
[3] O. Berthold, H. Federrath, and M. K¨ohntopp. Project
“anonymity and unobservability in the internet”. In CFP,
April 2000.
[4] O. Berthold and H. Langos. Dummy traﬃc against long
term intersection attacks. In 2nd PET, 2002.
[5] O. Berthold, A. Pﬁtzmann, and R. Standtke. The
disadvantages of free MIX routes and how to overcome
them. In Workshop on Design Issues in Anonymity and
Unobservability, pages 30–45, July 2000.
[6] S. L. Blond, D. Choﬀnes, W. Zhou, P. Druschel, H. Ballani,
and P. Francis. Towards eﬃcient traﬃc-analysis resistant
anonymity networks. In SIGCOMM, August 2013.
[7] J. Brickell and V. Shmatikov. Eﬃcient
anonymity-preserving data collection. In 12th KDD, pages
76–85, Aug. 2006.
 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11s1min1hr1day1weekPercent of MessagesExperienced Delays6432162 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11s1min1hr1day1weekPercent of MessagesExperienced DelaysOracleDynamic 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11hr1day1weekPercent of MessagesExperienced Delays6432162 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11hr1day1weekPercent of MessagesExperienced DelaysOracleDynamic 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11day1weekPercent of MessagesExperienced Delays6432162 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 11day1weekPercent of MessagesExperienced DelaysOracleDynamic1165[8] D. Chaum. Untraceable electronic mail, return addresses,
and digital pseudonyms. Communications of the ACM,
Feb. 1981.
[9] D. Chaum. The dining cryptographers problem:
Unconditional sender and recipient untraceability. Journal
of Cryptology, pages 65–75, Jan. 1988.
[33] D. J. Kelly. A taxonomy for and analysis of anonymous
communications networks. PhD thesis, Wright Patterson
AFB, OH, USA, 2009. AAI3351544.
[34] B. Levine, M. Reiter, C. Wang, and M. Wright. Timing
attacks in low-latency mix systems. In Financial
Cryptography, pages 251–265. 2004.
[10] D. Chaum, A. Fiat, and M. Naor. Untraceable electronic
[35] J. K. Liu, V. K. Wei, and D. S. Wong. Linkable
cash. In CRYPTO, Aug. 1988.
[11] H. Corrigan-Gibbs and B. Ford. Dissent: accountable
anonymous group messaging. In 17th CCS, Oct. 2010.
[12] H. Corrigan-Gibbs and B. Ford. Scavenging for anonymity
with BlogDrop (abstract). In Provable Privacy Workshop,
July 2012.
[13] H. Corrigan-Gibbs, D. I. Wolinsky, and B. Ford.
Proactively accountable anonymous messaging in Verdict.
In 22nd USENIX Security, Aug. 2013.
[14] W. Dai. PipeNet 1.1, Aug. 1996. UseNet post.
http://www.weidai.com/pipenet.txt.
[15] G. Danezis, R. Dingledine, and N. Mathewson. Mixminion:
Design of a Type III anonymous remailer protocol. In IEEE
SP, pages 2–15, May 2003.
[16] G. Danezis and A. Serjantov. Statistical disclosure or
intersection attacks on anonymity systems. In Information
Hiding Workshop, May 2004.
[17] C. D´ıaz, S. Seys, J. Claessens, and B. Preneel. Towards
measuring anonymity. In Proceedings of the 2nd
international conference on Privacy enhancing
technologies, PET’02, 2003.
[18] R. Dingledine, N. Mathewson, and P. Syverson. Tor: the
second-generation onion router. In 12th USENIX Security,
Aug. 2004.
[19] J. R. Douceur. The Sybil attack. In 1st International
Workshop on Peer-to-Peer Systems, pages 251–260, Mar.
2002.
[20] N. S. Evans, R. Dingledine, and C. Grothoﬀ. A practical
congestion attack on Tor using long paths. In 18th
USENIX Security, Aug. 2009.
[21] H. Federrath. The Anonym-O-Meter.
http://anon.inf.tu-dresden.de/help/jap_help/en/help/
jap.JAPNewView_anonymometer.html, July 2013.
[22] B. Ford and J. Strauss. An oﬄine foundation for online
accountable pseudonyms. In 1st International Workshop on
Social Network Systems (SocialNets), 2008.
[23] M. J. Freedman and R. Morris. Tarzan: A peer-to-peer
anonymizing network layer. In 9th CCS, pages 193–206,
2002.
[24] E. Fujisaki and K. Suzuki. Traceable ring signature. In 10th
PKC, pages 181–200, Apr. 2007.
[25] J. Furukawa and K. Sako. An eﬃcient scheme for proving a
shuﬄe. In CRYPTO, pages 368–387, Aug. 2001.
[26] P. Gill et al. Characterizing censorship of Web content
worldwide, 2013. http://www.cs.stonybrook.edu/
~phillipa/papers/GCDG_May8.pdf.
[27] P. Golle and A. Juels. Dining cryptographers revisited.
Eurocrypt, pages 456–473, May 2004.
[28] A. Haeberlen, P. Kouznetsov, and P. Druschel. PeerReview:
Practical accountability for distributed systems. In 21st
SOSP, Oct. 2007.
[29] S. Han et al. Expressive privacy control with pseudonyms.
In SIGCOMM, Aug. 2013.
[30] N. Hopper and E. Y. Vasserman. On the eﬀectiveness of
k-anonymity against traﬃc analysis and surveillance. In
WPES, Oct. 2006.
[31] D. Kedogan, D. Agrawal, and S. Penz. Limits of anonymity
in open environments. In 5th International Workshop on
Information Hiding, pages 53–69, Oct. 2002.
[32] D. Kelly, R. Raines, R. Baldwin, B. Mullins, and
M. Grimaila. Towards mathematically modeling the
anonymity reasoning ability of an adversary. In IPCCC,
pages 524–531. IEEE, 2008.
spontaneous anonymous group signature for ad hoc groups.
In Australian Conference on Information Security and
Privacy, pages 614–623, July 2004.
[36] A. Lysyanskaya, R. L. Rivest, A. Sahai, and S. Wolf.
Pseudonym systems. In Selected Areas in Cryptography,
pages 184–199. Springer, 2000.
[37] N. Mathewson and R. Dingledine. Practical traﬃc analysis:
extending and resisting statistical disclosure. In PET, May
2004.
[38] S. J. Murdoch and G. Danezis. Low-cost traﬃc analysis of
Tor. In IEEE Security and Privacy, pages 183–195, May
2005.
[39] C. A. Neﬀ. A veriﬁable secret shuﬄe and its application to
e-voting. In CCS, pages 116–125, Nov. 2001.
[40] A. Pﬁtzmann and M. Hansen. A terminology for talking
about privacy by data minimization: Anonymity,
unlinkability, undetectability, unobservability,
pseudonymity, and identity management, Aug. 2010.
[41] A. Pﬁtzmann, B. Pﬁtzmann, and M. Waidner. ISDN-mixes:
Untraceable communication with very small bandwidth
overhead. In GI/ITG Conference on Communication in
Distributed Systems, February 1991.
[42] J.-F. Raymond. Traﬃc analysis: Protocols, attacks, design
issues and open problems. In Workshop on Design Issues
in Anonymity and Unobservability, pages 10–29, 2000.
[43] A. Serjantov and G. Danezis. Towards an information
theoretic metric for anonymity. In Proceedings of the 2nd
international conference on Privacy enhancing
technologies, PET’02, 2003.
[44] V. Shmatikov and M.-H. Wang. Measuring relationship
anonymity in mix networks. In WPES, Oct. 2006.
[45] V. Shmatikov and M.-H. Wang. Timing analysis in
low-latency mix networks: Attacks and defenses. In
Computer Security–ESORICS 2006. Springer, 2006.
[46] E. G. Sirer, S. Goel, M. Robson, and D. Engin. Eluding
carnivores: File sharing with strong anonymity. In
SIGOPS EW, Sept. 2004.
[47] C. Soghoian. Surveillance and security lessons from the
Petraeus scandal. 12 2012.
[48] N. Tran, B. Min, J. Li, and L. Submaranian. Sybil-resilient
online content voting. In 6th NSDI, pages 15–28, Apr. 2009.
[49] J.-P. Verkamp and M. Gupta. Inferring mechanics of Web
censorship around the world. In 2nd FOCI, Aug. 2012.
[50] M. Waidner and B. Pﬁtzmann. The dining cryptographers
in the disco: Unconditional sender and recipient
untraceability with computationally secure serviceability. In
Eurocrypt, pages 302–319, Apr. 1989.
[51] D. I. Wolinsky, H. Corrigan-Gibbs, B. Ford, and
A. Johnson. Scalable anonymous group communication in
the anytrust model. In EuroSec, Apr. 2012.
[52] D. I. Wolinsky, H. Corrigan-Gibbs, A. Johnson, and
B. Ford. Dissent in numbers: Making strong anonymity
scale. In 10th OSDI, pages 179–192, Oct. 2012.
[53] M. K. Wright, M. Adler, B. N. Levine, and C. Shields.
Passive-logging attacks against anonymous communications
systems. TISSEC, May 2008.
[54] H. Yu, P. B. Gibbons, M. Kaminsky, and F. Xiao.
SybilLimit: A near-optimal social network defense against
sybil attacks. In IEEE Symposium on Security and
Privacy, pages 3–17, May 2008.
1166