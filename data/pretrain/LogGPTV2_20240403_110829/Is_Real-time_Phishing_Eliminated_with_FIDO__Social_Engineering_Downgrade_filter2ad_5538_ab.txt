We obtained the domain two-step.online as our phishing
domain, got a Let’s Encrypt certiﬁcate for the domain, and
placed our phishing pages inside a google.com directory on
our server. We intentionally opted for a domain with valid
words in a non-traditional TLD such as .online for two
reasons: (1) we could get a TLS certiﬁcate without being
ﬂagged as suspicious [72], and (2) users that do not understand
how URLs work but might have a look at it would not be
alerted as google.com is present [81, 92]. Our index.html
page would get periodically blocklisted every few days, and
so we hid it such that it is only accessible through a randomly
generated alpha-numeric string. The page would thus only
be reachable by a link, which would be emailed to potential
victims. While on the phishing website, the browser’s URL
bar would have a green padlock icon with the URL:
https://login.two-step.online/google.com/index.php?acc=8[..]b
Corresponding PHP code at the start of index.php reads:
echo " T h i s
i s
I nd ex . php ! " ;
where acc is the variable containing the random string.
When implementing our phishing pages, shown in Fig. 3,
we did not borrow content from Google’s website; we neither
pre-downloaded content from Google to upload to our pages,
nor linked to Google content from our pages. The former is
not quite straightforward because Google employs code ob-
fuscation techniques on its webpages (e.g., to thwart phishing
attacks); the latter was avoided to evade potential phishing
detection through analyzing our server’s requests to Google’s
web-content [67]. The only object we downloaded and up-
loaded onto our server was Google’s logo (image). Note that
creating our phishing page would be feasible for any attacker
with moderate web programming experience. Our implemen-
tation of Google’s pages resulted in fewer than 2K lines of
combined PHP/JavaScript/HTML/CSS code.
Recall from Sec. 2, the authentic FIDO prompt is typ-
ically displayed outside of the attacker-controlled area of
the browser to prevent attackers from replicating the prompt
within the content pane; note, e.g., for Chrome, the top tip
of the box overlapping the URL bar (see Fig. 2a). Recall
also that browsers capture the domain from the URL bar
and display it to the user within the FIDO-prompt box. It is
thus helpful (to the attacker) to use API functions that do
not display this box to the user, yet gets the browser to no-
tify the webserver that a dongle was inserted. For Step 10
(Fig. 1), we used the u2f.register function, which does
not display browser-generated prompts. With this function,
communications with the user are left to the website devel-
(a) FIDO prompt generated by the browser.
(b) Google Authenticator prompt
Figure 2: Screenshots of the Google’s login page.
curs in Step 10, where the user will be prompted for another
authentication factor after using the FIDO token. We believe
that seeing three login steps (password + FIDO + OTP) likely
sends a false signal to the user that this login trial is even more
secure than with two factors (password + FIDO). Google’s
OTP page (see Fig. 2), for example, has the sentence “This
extra step shows that it’s really you trying to sign in”. When
an attacker displays that page after its fake FIDO-prompt,
the user would interpret it as an “extra” beyond password +
FIDO, but it is intended (by the legitimate site) as extra to
only the password. In our implementation, we constructed
this (phishing) page with the statement as-is. The “extra step”
here enables our attack, as it helps attackers downgrade FIDO
to other methods.
Variations to Step 10. Depending on the design of the
legitimate website, variations other than presenting a page
with an alternative authentication (Step 10) immediately af-
ter the FIDO prompt may be more effective in tricking the
user. For example, similar to approaches discussed in previ-
ous research [77], the attacker may display: “due to technical
error, we are unable to process your FIDO token at this time”,
or “our FIDO-handling service is currently down, please use
another method”. The latter avoids the use of FIDO APIs al-
together, so alert messages familiar to the user in the browser-
displayed FIDO-prompt box (where attackers have no control
over the message within) are avoided.
4.1 Attack Implementation
In preparation for running a user study to test the effective-
ness of this attack, we implemented a phishing website that
behaves in the manner explained above. The website targets
3814    30th USENIX Security Symposium
USENIX Association
5.1 Design Decisions
We considered several study designs before ultimately de-
veloping our methodology, including carefully considering
legal concerns [44, 45] and ethical issues as summarized by
Finn & Jakobsson [26]. While it does add realism, we dis-
missed the idea of using participants’ real credentials in a ﬁeld
study without a priori consent because previous work [44]
has shown that it can lead to participants feeling violated even
after learning that no personal data was compromised. A vari-
ation of this approach [45], where a clever study design has
participants entering their real credentials to a legitimate site
rather than a researcher-controlled site was technically not
viable for our particular attack.
Another line of phishing studies [19, 46, 56, 71] ask par-
ticipants to classify pages as phishing or legitimate without
submitting any credential, usually to measure the effective-
ness of security indicators. This approach did not align with
our intended goal of measuring the effectiveness of FIDO
protocol against our phishing attack, thus was not a viable
study design. Yet another approach [67,86] to studying phish-
ing is to analyze logs from service providers to investigate
the occurrence of real phishing attacks. To the best of our
knowledge the downgrade attack presented in this paper is
novel and there are no reports that it has been exploited in the
wild, thus logs would be unhelpful. Focusing on user perspec-
tives instead, qualitative studies [16, 46] aim to understand
users’ attitudes and reasoning regarding phishing, but these
subjective accounts do not provide objective measures of the
effectiveness of particular attacks.
We next considered phishing studies based on role playing.
Such studies typically use ﬁctitious scenarios to simulate
the experience of a user that receives legitimate and unsafe
emails. The tasks are typically easy and can be performed
by an average user, thus participants do not need the proper
experience for the role. Prior studies have used various roles: a
university worker (who receives 6 phishing emails out of 14 in
total) [78], a political campaign volunteer (3 malicious emails
out of 8) [28], a company employee (5 malicious emails out
of 19) [53], or a user doing online shopping (gets a phishing
email after each online purchase) [22]. Such studies have
limitations because participants may behave less securely with
mock credentials [77]. However, role playing experiments do
not raise ethical concerns and they would allow us to perform
a realistic downgrade attack during experiments.
After careful consideration of the technical requirements
of our attack, and the ethical and legal implications of exploit-
ing participants’ personal credentials, we decided to design a
role playing experiment followed by a semi-structured inter-
view. We believed that the combination of the two methods
would minimize the limitations of either individual method
by providing an opportunity for cross-checking our data.
(a) Attacker’s FIDO prompt.
(b) Attacker’s Google Authenticator
prompt.
Figure 3: Screenshots of the phishing page.
oper (i.e., through standard HTML and JavaScript).3 As an
attacker, we do not control the legitimate displayed message;
it is browser-generated. So we implemented a mimicry of the
Chrome-generated FIDO prompt as a gif image that looks
like Chrome’s box,4 with a message identical to the authen-
tic one: “Use your security key with google.com” (Fig. 3a).
The gif had an animated indeterminate progress bar, almost
similar (visually) to Chrome’s authentic one (Fig. 2a). Since
it was an image, it was fully contained within the browser’s
content pane, located vertically at pixel 0 (top-most point).
Finally, since our aim is only to test the effect of our attack
on participants in Sec. 5 (i.e., we do not want to actually steal
credentials), we did not implement back-end communication
between our phishing website and Google.
5 Evaluation Methodology
We designed a user study to test the effectiveness of the above
social engineering tactics. In comparison to studies that test
the usability of systems, designing a user study to test attack
effectiveness is often challenging. The study must be ethi-
cal. It should reﬂect a user’s true keenness in protecting their
assets. Moreover, the explanation of the study tasks to partic-
ipants should not (1) artiﬁcially lead participants to fall for
the attacks in question, and (2) artiﬁcially alert participants
so they detect/avoid the attacks.
3Note that even if a browser-generated box was used, users may already
be oblivious to the messages displayed within that box.
4An adversary can generate similar prompts for other browsers.
USENIX Association
30th USENIX Security Symposium    3815
5.2 Study Design
5.2.1 Study Scenario
We recruited participants using ﬂyers, university mailing lists,
and social media posts. Participants visited a webpage de-
scribing the study, its duration, and the compensation before
scheduling the interview. The study advertisement generically
explained that the purpose of the study was to evaluate and
improve the usability of email clients. To eliminate any later
doubt by participants about the safety of their legitimate cre-
dentials, participants did not use their own email accounts.
We provided user accounts and credentials (with a randomly-
generated strong password) created speciﬁcally for this study.
However, to maintain ecological validity, we designed a study
scenario that indirectly encouraged participants to think about
the security of these accounts.
We ran the study in-person concurrently in two interna-
tional cities near the end of 2019, one in North America (Ot-
tawa, Canada), below sufﬁxed with -N, and one in Europe
(Zürich, Switzerland), -E. To maintain consistency in both
cities, we carefully documented the study protocol and had
the two researchers running study sessions follow this com-
mon protocol. Participants were monetarily compensated for
their time, receiving CHF20 in Zürich, and $10 in Ottawa.
Participants ﬁrst completed a demographics questionnaire
then they went through the study scenario, during which they
were asked to think-aloud (i.e., to describe their thought pro-
cess out loud). We next gathered feedback from participants
through a semi-structured interview.5 We designed the inter-
view questions to indirectly gauge participants’ awareness
of the phishing attempts. Following previously established
notions of determining participants’ thoughts [29], we asked:
“If we told you that 50% of our participants access fake
websites during their study sessions, do you think you are
one of them? Why/Why not?”
We did not ask participants about each email, one-by-one,
whether it was a phishing attempt to avoid making them overly
vigilant, and potentially biased to answer “yes”. However, we
still allowed participants to go back to the emails and check
them during the interview, should they ask to do so.
At the session’s end, the researcher provided participants
with a debrieﬁng form, explaining the true purpose of the
study and answered any questions they had. Each session
lasted approximately an hour, throughout which the researcher
took notes to provide insight into participants’ thought pro-
cesses (e.g., if participants hesitated when opening links
(phishing or legitimate), if they hovered over the links to view
the URL, and any comments they had on the emails). Study
sessions were audio-recorded, and the interview portion was
transcribed for analysis, and the researchers referred back
to the audio recordings for more context when needed. The
study received IRB approval in both cities.
5The interview script is detailed in [83, Appendix E].
Participants were asked to role play Jordan Hart, a new em-
ployee in a technology company on her/his ﬁrst day of work.
They were provided with their company gear: a laptop, smart-
phone, and a security key (the FIDO dongle). Participants
were asked to read and sign the employee on-boarding in-
formation sheet (Appendix A), a common practice in indus-
try. This sheet outlined the company policy with respect to
safeguarding company information and avoiding scams and
phishing attacks, as well as explaining FIDO keys and their as-
sociated security beneﬁts in language adapted from Google’s
Security and identity products pages [33]. The sheet listed
Microsoft Outlook as the company’s primary email provider,
included Jordan’s Outlook account credentials (username and
password), and provided their Google services credentials.
We created real Microsoft and Google accounts. The sheet
also included the names and email addresses of Jordan’s man-
ager, IT manager, and HR person, from whom Jordan would
receive emails. We created real Microsoft email accounts for
each of them. To make sure participants were comfortable
using the FIDO key, the researcher–acting as the IT manager–
asked participants to login to their email with the key as a
second factor, and explained how to use the Google Authen-
ticator app (pre-installed on Jordan’s smartphone) in case of
technical difﬁculties (Appendix A).
Jordan’s Microsoft email inbox contained 15 emails [83,
Appendix F], divided into 5 folders, one for each day of the
week [83, Fig. 7]. Participants were asked to assume that they
login to their Outlook account daily, handle emails received
that day (as tagged), logout and shutdown their laptop before
going home, and come back the next day to do the same steps.
The researcher simulated shutting down the laptop when in-
dicated by the participant by logging-out of their email and
clearing the browser cache after ﬁnishing each day’s emails.
Participants used Google Chrome.
5.2.2 Emails
Four of the 15 emails were phishing, containing a link to our
phishing website (Sec. 4.1). Such emails were spearphishing
(targeted). We chose to have such a high number of phishing
emails in the ﬁrst week of employment to give participants a
higher-than-normal chance to recognize our phishing attack.
In Sec. 6.2, we explain how detecting a single phishing email
sufﬁces for us to count the participant amongst those who did
not fall for our attack.
We used PHP’s mail function to send out the phishing
emails using a spoofed source email address. To ensure real-
ism, these emails included errors like grammatical mistakes
and typos, mimicking typical phishing emails. Non-phishing
emails were sent from the authentic email accounts of the
company’s employees (Jordan’s manager, IT manager, and
HR person) through the email web client. All emails were
sent at once before we started recruiting participants, and sim-
3816    30th USENIX Security Symposium
USENIX Association
ply marked as unread before the next participant. When we
initially sent them, we manually moved those that were placed
into Jordan’s Spam folder (legitimate or phishing) into the In-
box folder (see [83, Fig. 8] for an example of a legitimate and
a phishing email, both appearing to be from the IT manager).
Note that, as in real-life, when visiting our phishing pages,
participants will see the fake login form even when they are al-
ready logged-in to Jordan’s Google account. This has alerted
vigilant participant, P2-N, to our phishing attempts.
Some emails, legitimate and phishing, included links to doc-
uments. We created actual documents for every such email,
and stored them on Google drive. Legitimate documents were
only accessible through Jordan’s Google drive account. We
(attacker) set the other documents on Google drive as accessi-
ble with a link, and redirected to them after the user ﬁnished
logging-in to our phishing website. This way, the browser’s
URL bar would display an authentic Google domain after the
participant’s persona credentials were phished.
5.3 Participants
We recruited 51 participants for this study: 25 in city-E and
26 in city-N. Our dataset (available in [83, Appendix D])
is balanced in terms of gender: 26 participants identiﬁed as
female, 24 as male, and one chose “Other or prefer not to
answer”. Our participants were between 18 and 64 years old
(µ = 29.9,Med = 27). The vast majority of participants had