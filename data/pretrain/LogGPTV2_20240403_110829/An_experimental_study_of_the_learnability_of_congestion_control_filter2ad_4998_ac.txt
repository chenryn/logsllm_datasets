15 Mbps
15 Mbps
On avg.
1 sec
1 sec
1 sec
1 sec
1 sec
Off avg. min-
RTT
150 ms
150 ms
150 ms
150 ms
150 ms
1 sec
1 sec
1 sec
1 sec
1 sec
#
senders
2
10
20
50
100
(a) Tao protocols designed for breadth in multiplexing
Link
speeds
15 Mbps
On avg.
1 sec
Off avg. min-
RTT
150 ms
1 sec
#
senders
1–100
Buffer
5 BDP,
no drop
(b) Testing scenarios to explore breadth in multiplexing
Table 3: Scenarios for “knowledge of the degree of multiplexing”
experiment
such low-degree protocols are tested outside their training range.
Conversely, a protocol trained for a wide range in the degree of
multiplexing is unduly conservative at lower degrees of multiplex-
ing leading to lost throughput and a degradation in the objective
function.
4.3 Knowledge of propagation delays
Today, some specialized congestion-control protocols are tai-
lored for networks with either large propagation delays (e.g., the
Aspera [1] ﬁle transfer protocol over long-distance links) or short
delays (such as DCTCP [3] within the data center). Here, we ask
whether it is possible to design a single congestion-control protocol
with good performance without making strong assumptions about
the propagation delay a priori.
We designed four Tao protocols for varying ranges of the mini-
mum round trip time of the network as shown in Table 4a and tested
it on the scenarios shown in Table 4b. Figure 4 shows that training
for exactly one minimum RTT (150 ms) results in a protocol with
good performance over the 50–250 ms range, but its performance
degrades drastically below 50 ms.
Tao
rtt-150
rtt-145–155
rtt-140–160
rtt-50–250
Link
speeds
33 Mbps
33 Mbps
33 Mbps
33 Mbps
On
avg.
1 sec
1 sec
1 sec
1 sec
Off
avg.
1 sec
1 sec
1 sec
1 sec
min-RTT
150 ms
145–155 ms
140–160 ms
50–250 ms
#
senders
2
2
2
2
(a) Tao protocols designed for breadth in propagation delay.
Link
speeds
33 Mbps
On avg.
Off avg. min-RTT
1 sec
1 sec
1, 2, 3 . . . 300 ms
#
senders
2
(b) Testing scenarios to explore breadth in propagation delay.
Table 4: Scenarios for “knowledge of propagation delay” experi-
ment
On the other hand, adding a little diversity to the training — by
looking at minimum RTTs from 145 to 155 ms instead — results in
performance over the 1–300 ms range that is commensurate with a
protocol trained for the much broader range of 50 to 250 ms.
Figure 2: Evidence of a weak tradeoff between operating range in
link speed of a congestion-control protocol and performance. The
Tao protocols designed with more speciﬁc network models (Tao-
2x and Tao-10x) performed modestly better—within their design
ranges—than protocols designed for a broader range of networks
(Tao-100x and Tao-1000x), at a cost of deterioration when the ac-
tual network did not fall within the training scenarios. The four Tao
protocols outperformed Cubic and Cubic-over-sfqCoDel over their
design ranges.
(including the Tao-1000x) outperformed existing algorithms over
its full design range.
4.2 Knowledge of the degree of multiplexing
Congestion-control protocols have to cope with uncertainty in the
degree of multiplexing from one use to the next even when running
on a network with a ﬁxed and known topology. The number of
users on the network could change as could the number of ﬂows
generated by these users. Here, we evaluate whether it is possible
to learn a protocol that is robust to such uncertainty.
Speciﬁcally, we designed ﬁve Tao protocols, each for a ﬁxed
dumbbell topology, but with increasing degrees of multiplexing as
described in Table 3a. We then test all ﬁve protocols on the testing
scenarios in Table 3b. Figure 3 shows the results for two cases: one
with a buffer size of ﬁve times the bandwidth-delay product and
an extreme case where the link doesn’t drop any packet. In both
cases, we see that it is possible to train a protocol to perform well
across a wide range of multiplexing, but at the cost of diminished
performance at very low degrees of multiplexing. On the ﬂip side,
designing for a much smaller range in the degree of multiplexing
degrades performance dramatically outside that range.
Put differently, there is a tradeoff between good performance at
high and low degrees of multiplexing. A high degree of multiplex-
ing requires a protocol to be conservative in grabbing spare band-
width and good performance at low degrees of multiplexing needs
a protocol to quickly grab spare bandwidth. As a result, protocols
trained for low degrees of multiplexing are too aggressive at higher
degrees, causing either large queuing delays, when the buffer never
drops a packet, or diminished throughput, when the buffer drops
packets and causes more retransmissions than transmissions2. In ei-
ther case, the result is a degradation in the objective function when
2This is similar to the congestion collapse that triggered the devel-
opment of TCP congestion control [15].
-2-1.5-1-0.501101001000log( normalized throughput ) - log( delay )Link rate (Mbps)Link speed (Mbps)OmniscientCubicCubic-over-sfqCoDel2x rangeTao-2x10x rangeTao-10xTao-100xTao-1000x100x range1000x range484Figure 3: Tao protocols perform well across a wide range of multiplexing, but at the cost of diminished performance when there are very few
senders. However, training to accommodate lower degrees of multiplexing degrades performance at higher degrees of multiplexing.
is to learn a congestion-control protocol for a more-complicated
network, given a simpliﬁed model of that network’s structure.
In ns-2, we simulated a network with two bottlenecks in a
“parking-lot” topology, shown in Figure 5. Flow 1 crosses both
links and encounters both bottlenecks. It contends with Flow 2 for
access to the bottleneck queue at node A, and contends with Flow
3 for access to the bottleneck queue at node B.
Figure 5: Parking-lot topology used to measure the consequences
of imperfect knowledge of the network’s structure.
Tao
one-bottleneck
full two-bottleneck
Links modeled
one, 150 ms delay
two, 75 ms delay each
Num. senders
2
3
Table 5: Training scenarios used to measure the consequences of
imperfect knowledge of the network structure. Both protocols were
designed for link speeds distributed log-uniformly between 10 and
100 Mbps, and for ﬂows with mean “on” and “off” time of 1 second.
The results for Flow 1 (the ﬂow that crosses both links) are shown
in Figure 6.3 The experiment sweeps the rate of each of the two
links between 10 and 100 Mbps, and the shaded area in the ﬁg-
ure shows the full locus of throughputs seen by Flow 1. For each
pair of rates (for link 1 and link 2), we also calculate the ideal pro-
portionally fair throughput allocation, and plot the locus of these
allocations as the throughput achievable by the omniscient proto-
col.
The results suggest that a congestion-control protocol designed
for a simpliﬁed model of the network’s structure will experience
3Results for Flow 2 and Flow 3 (ﬂows crossing only a single link)
were nearly identical between the schemes.
Figure 4: Training for a little diversity in propagation delays re-
sults in good performance over a much wider range of propagation
delays.
These results suggest that prior knowledge of the propagation de-
lay of a target network may not be particularly necessary or valuable
to the protocol designer.
4.4 Structural knowledge
We evaluated the difﬁculty of designing a congestion-control
protocol, subject to imperfect knowledge of the network’s structure
or topology.
It is an understatement to say that the Internet is a vast network
whose full structure is known to nobody and which no model can
accurately capture. Nonetheless, researchers regularly develop new
distributed protocols for the Internet, which are deployed based on
tests in example network paths that imperfectly capture the Inter-
net’s true complexity.
In practice, protocol designers expect that they can reason about
the performance of a distributed network algorithm by modeling
the network as something simpler than it is. We worked to capture
that intuition rigorously by studying quantitatively how difﬁcult it
020406080100Numberofsenders−1.4−1.2−1.0−0.8−0.6−0.4−0.20.0NormalizedobjectivefunctionBuffersize5xBDP020406080100Numberofsenders−5−4−3−2−10NormalizedobjectivefunctionNopacketdropsTao1-100Tao1-50Cubic-over-sfqCoDelCubicTao1-20Tao1-10Tao1-2OmniscientTao1-100Tao1-50Cubic-over-sfqCoDelCubicTao1-20Tao1-10Tao1-2Omniscient050100150200250300RTTinms−2.0−1.5−1.0−0.50.0NormalizedobjectivefunctionOmniscientTao150msexactlyTao145-155msTao50-250msTao140-160msCubic-over-sfqCoDelCubicLink 1 / 75 msLink 2 / 75 msABCQueueQueue10--100 Mbits/s10--100 Mbits/sFlow 3Flow 2Flow 1485Tao
TCP-
aware
TCP-
naive
Link
rates
9–
11 Mbps
9–
11 Mbps
RTT
Senders
ON/OFF time
100 ms
2 Tao
1 Tao, 1 AIMD
100 ms
2 Tao
5 sec ON/OFF
5 sec ON, 10 ms OFF
5 sec ON/OFF
5 sec ON, 10 ms OFF
(a) Tao protocols with and without TCP awareness, dumbbell network with
buffer size 2 BDP
RTT
Link
rates
10 Mbps 100 ms
10 Mbps 100 ms
10 Mbps 100 ms
10 Mbps 100 ms
10 Mbps 100 ms
Senders
ON/OFF time
2 TCP-aware
2 TCP-naive
TCP-aware, AIMD
TCP-naive, AIMD
2 AIMD
5 sec ON, 10 ms OFF
5 sec ON, 10 ms OFF
5 sec ON, 10 ms OFF
5 sec ON, 10 ms OFF
5 sec ON, 10 ms OFF
(b) Testing scenarios for “knowledge about incumbent endpoints” experi-
ment, dumbbell network with buffer size 2 BDP
Table 6: Scenarios for “knowledge about incumbent endpoints” ex-
periment
We studied this by designing two Tao protocols, TCP-Naive and
TCP-Aware, for a simple network—one whose model speciﬁed that
the cross-trafﬁc would be from the same protocol, and one whose
model included a training scenario where the cross-trafﬁc was from
traditional TCP half the time (Table 6a). Remy uses an AIMD pro-
tocol similar to TCP NewReno to simulate TCP cross-trafﬁc.
The results are shown in Figure 7. In the left panel, protocols
compete only with cross-trafﬁc from the same protocol. In this ho-
mogeneous setting, adding TCP-awareness to a Tao protocol builds
up standing queues, more than doubling the queueing delay without
affecting throughput.
But in a mixed setting (Figure 7, right panel) where a Tao com-
petes against TCP NewReno, the TCP-naive Tao is squeezed out
and does not get its fair share of the link.
In the shaded region
showing the results when NewReno competes with the TCP-aware
Tao, TCP-awareness allows the Tao to claim its fair share of the link
and reduces the queueing delay experienced both by itself and by
TCP NewReno.
To further understand the differing performance of TCP-naive
and TCP-aware Tao protocols, we inspect their transmissions in
the time domain, when contending with a contrived model of TCP
cross-trafﬁc (Figure 8) that turns on exactly at time t=5 seconds
and turns off exactly at t=10 seconds. The results show that TCP-
awareness is a complicated phenomenon, which yields higher de-
lays in isolation but smaller delays when contending with TCP. It
is not simply a question of “more aggressive” or “less aggressive”
congestion-control.
The results suggest that new delay-minded protocols can avoid
being squeezed out by traditional loss-triggered TCP, but building
in this behavior comes at a cost to performance in the absence of
TCP cross-trafﬁc.
4.6 The price of sender diversity
We further generalize the notion of TCP-awareness by asking
whether it is possible to design multiple new congestion-control