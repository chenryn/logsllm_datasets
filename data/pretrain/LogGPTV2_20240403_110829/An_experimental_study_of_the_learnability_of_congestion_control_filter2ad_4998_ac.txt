### 4.2 知识的多路复用程度

拥塞控制协议需要应对从一次使用到下一次使用的多路复用程度的不确定性，即使在网络拓扑固定且已知的情况下也是如此。网络上的用户数量可能会变化，这些用户生成的流数量也可能会变化。在这里，我们评估是否可以学习一种对这种不确定性具有鲁棒性的协议。

具体来说，我们设计了五个Tao协议，每个协议针对一个固定的哑铃拓扑，但具有不同的多路复用程度，如表3a所示。然后我们在表3b所示的测试场景中测试这五个协议。图3展示了两种情况的结果：一种是缓冲区大小为带宽延迟积的五倍的情况，另一种是链路不丢弃任何数据包的极端情况。在这两种情况下，我们发现可以训练一个协议在广泛的多路复用范围内表现良好，但代价是在非常低的多路复用度下性能下降。另一方面，设计用于较小范围内的多路复用程度会导致超出该范围时性能显著下降。

换句话说，在高和低多路复用度下的良好性能之间存在权衡。高多路复用度要求协议在获取空闲带宽时保守，而在低多路复用度下良好性能需要协议快速抓住空闲带宽。因此，为低多路复用度训练的协议在高多路复用度下过于激进，导致要么排队延迟大（当缓冲区不丢弃数据包时），要么吞吐量降低（当缓冲区丢弃数据包并导致更多重传时）。无论哪种情况，结果都是目标函数的退化。

#### 表3: “多路复用知识”实验场景

| 链路速度 | 平均在线时间 | 平均离线时间 | 最小RTT | 发送者数量 |
| --- | --- | --- | --- | --- |
| 15 Mbps | 1秒 | 1秒 | 150 ms | 2, 10, 20, 50, 100 |

(a) 为广泛多路复用设计的Tao协议

| 链路速度 | 平均在线时间 | 平均离线时间 | 最小RTT | 发送者数量 | 缓冲区大小 |
| --- | --- | --- | --- | --- | --- |
| 15 Mbps | 1秒 | 1秒 | 150 ms | 1-100 | 5 BDP, 不丢包 |

(b) 测试场景以探索多路复用的广度

### 4.3 传播延迟的知识

目前，一些专门的拥塞控制协议针对长距离链路的大传播延迟（例如Aspera文件传输协议）或数据中心内的短延迟（如DCTCP）进行了优化。在这里，我们探讨是否可以在不事先假设传播延迟的情况下设计出具有良好性能的单一拥塞控制协议。

我们为不同范围的最小往返时间设计了四个Tao协议，如表4a所示，并在表4b所示的场景中进行了测试。图4显示，仅针对一个最小RTT（150 ms）进行训练的协议在50-250 ms范围内表现出良好的性能，但在低于50 ms时性能急剧下降。

#### 表4: “传播延迟知识”实验场景

| 协议 | 链路速度 | 平均在线时间 | 平均离线时间 | 最小RTT | 发送者数量 |
| --- | --- | --- | --- | --- | --- |
| Tao rtt-150 | 33 Mbps | 1秒 | 1秒 | 150 ms | 2 |
| Tao rtt-145–155 | 33 Mbps | 1秒 | 1秒 | 145-155 ms | 2 |
| Tao rtt-140–160 | 33 Mbps | 1秒 | 1秒 | 140-160 ms | 2 |
| Tao rtt-50–250 | 33 Mbps | 1秒 | 1秒 | 50-250 ms | 2 |

(a) 为广泛传播延迟设计的Tao协议

| 链路速度 | 平均在线时间 | 平均离线时间 | 最小RTT | 发送者数量 |
| --- | --- | --- | --- | --- |
| 33 Mbps | 1秒 | 1秒 | 1, 2, 3 ... 300 ms | 2 |

(b) 测试场景以探索传播延迟的广度

另一方面，通过考虑从145到155 ms的最小RTT来增加训练多样性，可以获得与训练范围为50到250 ms的协议相当的1-300 ms范围内的性能。

图4显示，少量的传播延迟多样性训练可以显著提高协议在更广泛传播延迟范围内的性能。

### 4.4 结构知识

我们评估了在不完全了解网络结构或拓扑的情况下设计拥塞控制协议的难度。

互联网是一个庞大的网络，其完整结构无人知晓，也没有模型能够准确捕捉。尽管如此，研究人员仍然基于不完全反映互联网真实复杂性的示例网络路径测试开发新的分布式协议。

实际上，协议设计者期望可以通过将网络建模为比实际简单的方式来推理分布式网络算法的性能。我们通过定量研究这种建模的难度来严格捕捉这种直觉。

#### 图5: 停车场拓扑结构

在ns-2中，我们模拟了一个具有两个瓶颈的“停车场”拓扑结构。流1跨越两个链路并遇到两个瓶颈。它与流2竞争节点A处的瓶颈队列访问，与流3竞争节点B处的瓶颈队列访问。

#### 表5: 用于测量网络结构知识不足后果的训练场景

| 协议 | 模拟链路 | 发送者数量 |
| --- | --- | --- |
| Tao one-bottleneck | 一条链路，150 ms延迟 | 2 |
| Tao full two-bottleneck | 两条链路，每条75 ms延迟 | 3 |

对于流1（跨越两个链路的流）的结果如图6所示。实验扫描了两个链路之间的速率，阴影区域显示了流1看到的所有吞吐量。对于每一对速率（链路1和链路2），我们还计算了理想的比例公平吞吐量分配，并绘制了全知协议可达到的吞吐量轨迹。

结果显示，为简化网络结构模型设计的拥塞控制协议会经历显著的性能下降。

### 4.5 关于现有端点的知识

我们通过设计两个Tao协议（TCP-Naive和TCP-Aware）来研究这一点，一个简单的网络模型指定了交叉流量来自相同的协议，另一个模型包括一半时间交叉流量来自传统TCP的训练场景（表6a）。Remy使用类似于TCP NewReno的AIMD协议来模拟TCP交叉流量。

结果如图7所示。在左侧面板中，协议仅与来自相同协议的交叉流量竞争。在这种同质设置中，向Tao协议添加TCP意识会建立持久队列，使排队延迟增加一倍以上，而不会影响吞吐量。

但在混合设置（图7右侧面板）中，当Tao与TCP NewReno竞争时，TCP-naive的Tao被挤出，无法获得其公平份额的链路。

在显示NewReno与TCP-aware Tao竞争结果的阴影区域中，TCP意识使Tao能够获得其公平份额的链路，并减少自身和TCP NewReno所经历的排队延迟。

为了进一步理解TCP-naive和TCP-aware Tao协议的不同性能，我们检查了它们在时间域中的传输，当与构造的TCP交叉流量（图8）竞争时，该流量在t=5秒时精确开启，在t=10秒时精确关闭。结果表明，TCP意识是一种复杂的现象，在隔离状态下会导致更高的延迟，但在与TCP竞争时会减少延迟。这不仅仅是“更激进”或“更保守”的拥塞控制的问题。

结果表明，新的延迟敏感协议可以避免被传统的基于丢包的TCP挤压出去，但构建这种行为会在没有TCP交叉流量的情况下付出性能代价。

#### 表6: “关于现有端点的知识”实验场景

| 协议 | 链路速率 | RTT | 发送者 | ON/OFF 时间 |
| --- | --- | --- | --- | --- |
| TCP-aware | 9-11 Mbps | 100 ms | 2 Tao | 5秒ON, 10 ms OFF |
| TCP-naive | 9-11 Mbps | 100 ms | 1 Tao, 1 AIMD | 5秒ON, 10 ms OFF |

(a) 具有和不具有TCP意识的Tao协议，哑铃网络缓冲区大小为2 BDP

| RTT | 链路速率 | 发送者 | ON/OFF 时间 |
| --- | --- | --- | --- |
| 100 ms | 10 Mbps | 2 TCP-aware | 5秒ON, 10 ms OFF |
| 100 ms | 10 Mbps | 2 TCP-naive | 5秒ON, 10 ms OFF |
| 100 ms | 10 Mbps | TCP-aware, AIMD | 5秒ON, 10 ms OFF |
| 100 ms | 10 Mbps | TCP-naive, AIMD | 5秒ON, 10 ms OFF |
| 100 ms | 10 Mbps | 2 AIMD | 5秒ON, 10 ms OFF |

(b) “关于现有端点的知识”实验的测试场景，哑铃网络缓冲区大小为2 BDP

### 4.6 发送者多样性的代价

我们通过询问是否可以设计多个新的拥塞控制协议来进一步推广TCP意识的概念，这些协议可以处理多种类型的现有流量。