R3: Response Latency. A privacy-preserving RecRes should
achieve similar response latency to that of a regular RecRes.
R4: Scalability. A privacy-preserving RecRes should process a
realistic volume of queries generated by a realistic number
of clients.
Note: query privacy guarantees provided by PDoT rely on the
forward-looking assumption that communication between RecRes
and respective NS-s is also protected by DNS-over-TLS. The DNS
Privacy (DPrive) Working Group is working towards a standard for
encryption and authentication of DNS resolver-to-ANS communi-
cation [6], using essentially the same mechanism as DNS-over-TLS.
We expect an increasing number of NS-s to begin supporting this
standard in the near future. Once PDoT is enabled at the RecRes,
it can provide incremental query privacy for queries served from
a DNS-over-TLS NS. As discussed in Section 5, with small design
modifications, PDoT can be adapted for use in NS-s.
4 SYSTEM MODEL & DESIGN CHALLENGES
4.1 PDoT System Model
Figure 1 shows an overview of PDoT. It includes four types of enti-
ties: client, RecRes, TEE, NS-s. We now summarize PDoT operation,
reflected in the figure: (1) After initial start-up, TEE creates an at-
testation report. (2) When client initiates a secure TLS connection,
the attestation report is sent from RecRes to the client alongside all
other information required to setup a secure connection. (3) Client
authenticates and attests RecRes by verifying the attestation report.
It checks whether RecRes is running inside a genuine TEE and
running trusted code. (4) Client proceeds with the rest of the TLS
handshake procedure only if verification succeeds. (5) Client sends
a DNS query to RecRes through the secure TLS channel it has just
set up. (6) RecRes receives a DNS query from client, decrypts it into
TEE memory, and learns the domain name that the client wants to
resolve. (7) RecRes sets up a secure TLS channel to the appropriate
NS in order to resolve the query. (8) RecRes sends a DNS query to
NS over that channel. If NS’s reply includes an IP address of the
next NS, RecRes sets up another TLS channel to that NS. This is
done repeatedly, until RecRes successfully resolves the name to an
IP address. (9) Once RecRes obtains the final answer, it sends this
to client over the secure channel. Client can reuse the TLS channel
for future queries.
Note that we assume RecRes is not under the control of the
user. In some cases, users could run their own RecRes-s, which
would side-step the concerns about query privacy. For example,
Figure 1: Overview of the proposed system.
modern home routers are sufficiently powerful to run an in-house
RecRes. However, this approach cannot be used in public networks
(e.g., airports or coffee shop WiFi networks), which are the target
scenarios for PDoT.
4.2 Design Challenges
The following key challenges were encountered in the process of
PDoT’s design:
C1: TEE Limited Functionality. In order to satisfy their secu-
rity requirements, TEE-s often limit the functionality avail-
able to code that runs within them. One example is the in-
ability to fork within the TEE. Forking a process running
inside the TEE forces the child process to run outside the
TEE, breaking RecRes security guarantees. Another example
is that system calls, such as socket communication, cannot
be made from within the TEE.
C2: TEE Memory Limitations. A typical TEE has a relatively
small amount of memory. Although an SGX enclave can
theoretically have a large amount of in-enclave memory,
this will require page swapping of EPC pages. The pages
to be swapped must be encrypted and integrity protected
in order to meet the security requirements of SGX. There-
fore, page swapping places a heavy burden on performance.
To avoid page swapping, enclave size should be less than
the size of the EPC – typically, 128MB. Since RecRes is a
performance-critical application, its size should ideally not
exceed 128MB. This limit negatively impacts RecRes through-
put, as it bounds the number of threads that can be spawned
in a TEE.
C3: TEE Call-in/Call-out Overhead. Applications requiring
functionality that is not available within the TEE must switch
to the non-TEE side. This introduces additional overhead,
both from the switching itself, and from the need to flush and
reload CPU caches. Identifying and minimizing the number
of times RecRes switches back and forth (whilst keeping
RecRes functionality correct) is a substantial challenge.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Yoshimichi Nakatsuka, Andrew Paverd, and Gene Tsudik
Figure 2: Overview of PDoT implementation.
5 IMPLEMENTATION
Figure 2 shows an overview of the PDoT design. Since our design is
architecture-independent, it can be implemented on any TEE archi-
tecture that provides the features outlined in Section 2.2. We chose
the off-the-shelf Intel SGX as the platform for the proof-of-concept
PDoT implementation in order to conduct an accurate performance
evaluation on real hardware. (See Section 6). Therefore, our imple-
mentation is subject to performance and memory constraints in the
current version of Intel SGX, and is thus best suited for small-scale
networks, e.g., the public WiFi network provided of a typical coffee
shop. However, as TEE technology advances, we expect that our
design will scale to larger networks.
5.1 PDoT
PDoT consists of two parts: (1) trusted part residing in TEE enclaves,
and (2) untrusted part that operates in the non-TEE region. The
former is responsible for resolving DNS queries, and the latter –
for accepting incoming connections, assigning file descriptors to
sockets, and sending/receiving data received from the trusted part.
Enclave Startup Process. When the application enclave starts,
it generates a new public-private key-pair within the enclave. It
then creates a report that summarizes enclave and platform state.
The report includes a SHA256 hash of the entire code that is sup-
posed to run in the enclave (called MRENCLAVE value) and other
attributes of the target enclave. PDoT also includes a SHA256 hash
of the previously generated public key in the report. The report
is then passed on to the SGX quoting enclave to receive a quote.
The quoting enclave signs the report and thus generates a quote,
which cryptographically binds the public key to the application
enclave. The quoting enclave sends the quote to the application
enclave, which forwards it to the Intel Attestation Service (IAS)
to obtain an attestation verification report. It can be used in the
future by clients to verify the link between the public key and the
MRENCLAVE value. After receiving the attestation verification re-
port from IAS, the application enclave prepares a self-signed X.509
certificate required for the TLS handshake. In addition to the public
key, the certificate includes: (1) attestation verification report, (2)
attestation verification report signature, and (3) attestation report
signing certificate, extracted from (1). MRENCLAVE value and hash
of public key are enclosed in the attestation verification report.
TLS Handshake Process.1 Once the application enclave is cre-
ated, PDoT can create TLS connections and accept DNS queries
from clients. The client initiates a TLS handshake process by send-
ing a message to PDoT. This message is captured by untrusted part
of PDoT and triggers the following events.2 First, untrusted part
of PDoT tells the application enclave to create a new TLS object
within the enclave for this incoming connection. This forces the
TLS endpoint to reside inside the enclave. The TLS object is then
connected to the socket where the client is waiting to be served.
RecRes then exchanges several messages with the client, including
the self-signed certificate that was created in the previous section.
Having received the certificate from RecRes, the client authenti-
cates RecRes and validates the certificate. (For more detail, see
Section 5.2). Only if the authentication and validation succeed, the
client resumes the handshake process.
DNS Query Resolving Process. The client sends a DNS query
over the TLS channel established above. Upon receiving the query,
RecRes decrypts it within the application enclave and obtains the
target domain name. RecRes begins to resolve the name starting
from root NS, by doing the following repeatedly: 1) set up a TLS
channel with NS, 2) send DNS queries and receive replies via that
channel. Once RecRes receives the answer from NS, RecRes returns
it to the client over the original TLS channel.
Figure 3 illustrates how PDoT divides DNS query resolution
process into three threads: (1) receiving DNS query – ClientReader,
1In implementing this process, we heavily relied on SGX RA TLS [20] whitepaper.
2Since we consider a malicious RecRes operator, it has an option not to trigger these
events. However, clients will notice that their queries are not being answered and can
switch to a different RecRes.
PDoT: Private DNS-over-TLS with TEE Support
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
it is implemented, caching at the RecRes causes potential privacy
leaks, e.g., timings can reveal whether a certain domain record was
already in the cache. This is an orthogonal challenge, discussed in
Section 7.2.
To explore caching in a privacy-preserving resolver, we imple-
mented a simple in-enclave cache for PDoT. It uses a red-black tree
data structure and stores all records associated with the clients’
queries, indexed by the queried domain. This results in O(loд2(N))
access times with N entries in the cache. In practice, PDoT could
also use current techniques to mitigate against side-channel attacks
on cache’s memory access patterns, e.g., [10, 31, 34]. During remote
attestation, clients can ascertain whether the resolver has enabled
caching, and which mitigations it uses.
PDoT ANS with TEE support. With minor design changes,
PDoT RecRes design can be modified for use as an ANS. Similar to
the caching mechanism described above, an PDoT ANS can look up
the answers to queries in an internal database, rather than contact
external NS-s. The same way that clients authenticate PDoT RecRes,
the RecRes can authenticate the PDoT ANS. Clients can thus estab-
lish trust in both RecRes and ANS using transitive attestation [2].
5.2 Client with PDoT Support
We took the Stubby client stub from the getdns project [22] which
offers DNS-over-TLS support and modified it to perform remote
attestation during the TLS handshake. We now describe how the
client verifies its RecRes, decides whether the RecRes is trusted,
and emits the DNS request packet.
RecRes Verification. After receiving a DNS request from an
application, the client first checks whether there is an existing TLS
connection to its RecRes. If so, the client reuses it. If not, it attempts
to establish a new connection. During the handshake, the client
receives a certificate from RecRes, from which it extracts: 1) attesta-
tion verification report, 2) attestation verification report signature,
and 3) attestation report signing certificate. This certificate is self-
signed by IAS and we assume that the client trusts it. From (3), the
client first retrieves the IAS public key and, using it, verifies (2).
Then, the client extracts the SHA256 hash of RecRes’s public key
from (1) and verifies it against a copy from (3). This way, the client
is assured that RecRes is indeed running in a genuine SGX enclave
and uses this public key for the TLS connection.
Trust Decision. The client also extracts the MRENCLAVE value
from (1), which it compares against the list of acceptable MREN-
CLAVE values. If the MRENCLAVE value is not listed or one of the
verification steps fail, the client stub aborts the handshake, moves
on to the next RecRes, and re-starts the process. Note that the trust
decision process is different from the normal TLS trust decision
process. Normally, a TLS server-side certificate binds the public key
to one or more URLs and organization names. However, by binding
the MRENCLAVE value with the public key, the clients can trust
RecRes based on its behavior, and not its organization (recall that
the MRENCLAVE value is a hash of RecRes code). There several op-
tions for deciding which MRENCLAVE values are trustworthy. For
example, vendors could publish lists of expected MRENCLAVE val-
ues for their resolvers. For open-source resolvers like PDoT, anyone
can re-compute the expected MRENCLAVE value by recompiling
the software, assuming a reproducible build process. This would
Figure 3: Overview of PDoT threading model.
(2) resolving it – QueryHandler, and (3) returning the answer –
ClientWriter.
ClientReader and ClientWriter threads are spawned anew upon
each query. Dividing receiving and sending processes and giving
them a dedicated thread is helpful because many clients send mul-
tiple DNS queries within a short timespan without waiting for the
answer to the previous query.3 When ClientReader thread receives
a DNS query from the client, it stores the query and a client ID in a
FIFO queue, called inQueryList.
QueryHandler threads are spawned when PDoT starts up. The
number of QueryHandler threads is configured by RecRes operator.
QueryHandler threads are shared among all current ClientReader
and ClientWriter threads. When a QueryHandler thread detects an
entry in the inQueryList, it removes this entry and retrieves the
query and the client ID. QueryHandler first checks whether this
client is still accepting answers from RecRes. If not, QueryHandler
simply ignores this query and moves on to the next one. If the client
is still accepting answers, QueryHandler resolves the query and
puts the answer into a FIFO queue (called outQueryList) dedicated
to that specific client.
In some cases, NS response might be too slow. When that hap-
pens, QueryHandler thread gives up on resolving that particular
query and moves on to the next query, since it is very likely that
the request was dropped. This also prevents resources (such as
mutex) from being locked up by this QueryHandler thread. In our
implementation, this timeout was set to be the same as the client’s
timeout, since there is no point in sending the answer to the client
after that.
Once an answer is added to outQueryList dedicated to its client,
ClientWriter uses that answer to compose a DNS reply packet and
sends it to the client. The reason we have N outQueryLists for N
clients is to improve performance. With only one outQueryList,
ClientWriter threads must search through the queue to find the
answer for the connected client. This takes O(M × N) time, where
N is the number of clients and M is the number of queries each
client sends. Instead, with N outQueryLists, we reduce complexity
to O(1) because ClientWriter thread merely selects the query at the
head of the list.
Caching. Some DNS recursive resolvers can cache query results.
Caching is beneficial from the client’s perspective, since, in case
of a cache hit, the RecRes can answer immediately, thus reducing
query latency. The RecRes also benefits from not having to estab-
lish connections to external NS-s. However, irrespective of how
3For example, a client has received a webpage that includes images and advertisements
that are served from servers located at different domains. This triggers multiple DNS
queries at the same time.
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Yoshimichi Nakatsuka, Andrew Paverd, and Gene Tsudik
allow trusted third parties (e.g., auditors) to inspect the source code,
ascertain that it upholds required privacy guarantees, and publish
their own lists of trusted MRENCLAVE values.
Sending DNS request. Once the TLS connection is established,
the client sends the DNS query to RecRes over the TLS tunnel. If
it does not receive a response from RecRes within the specified
timeout, it assumes that there is a problem with RecRes and sends a
DNS reply message to the application with an error code SERVFAIL.
5.3 Overcoming Technical Challenges
As discussed in Section 4.2, PDoT faced three main challenges,
which we addressed as follows:
Limited TEE Functionality. The inability to use sockets within