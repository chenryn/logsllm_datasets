4Throughout this paper, we refer to the back-end as working with “con-
straints”. Another name for the same formalism is “arithmetic circuits with
non-deterministic inputs” [19, 62].
3
generate, and encode, a query. Online, for each new (x, y) pair,
the prover responds to the encoded query with a certificate; the
verifier checks the certificate, and accepts or rejects it. GGPR
has the following properties:
• Completeness: If there is a satisfying assignment to C, a
correct prover causes the verifier’s checks to accept.
• Proof of knowledge: If the prover does not have access to
a satisfying assignment z, then—except with very small
probability—the prover’s purported certificate causes the
verifier to reject. One can use this property and the prior one,
Completeness, to show that the full system (front-end plus
back-end) meets the End-to-end Completeness and Sound-
ness properties stated earlier [28, Apdx. A].
• Zero-knowledge: The protocol provides no information to
the verifier—beyond what the verifier can deduce itself—
about the values in z. In particular, the protocol reveals no
information to the verifier about any input supplied by the
prover, provided that input cannot be easily guessed. (As
with prior work [16, 19, 62], our evaluated examples (§5)
do not have private prover input. However, Buffet supports
the property, and example applications of it are evaluated
elsewhere [14, 28, 37].)
• Efficiency: We detail costs in Section 2.4. For now, we note
that the verifier’s check is fast and the prover’s response is
short. The principal costs are the setup work and the prover’s
work to generate the certificate.
2.2 Pantry
Step 1: Compile, produce constraints. The programmer ex-
presses a computation Ψ in a subset of C. This subset [28,
62, 70] contains loops (with static bounds), functions, structs,
typedefs, preprocessor definitions, if-else statements, explicit
type conversion, and standard integer and bitwise operations.
In addition, Pantry includes a RAM abstraction.
Using a compiler [27, 55, 62, 70, 72], V and P transform Ψ
into a set of constraints C over (X, Y, Z), where X and Y are
vectors of variables that represent the inputs and outputs; we
call the variables in Z intermediate variables. Let C(X=x, Y=y)
mean C with X bound to x (V’s requested input) and Y bound
to y (the purported output). Note that C(X=x, Y=y) is a set of
constraints over Z. C is constructed so that for any x and y, we
have: y = Ψ(x) if and only if C(X=x, Y=y) is satisfiable (by
some Z=z). Step 3 (§2.1) then works over C(X=x, Y=y).
A basic example [27, 28] is the computation add-1, whose
corresponding constraints are C = {Z−X = 0, Z +1−Y = 0}:
for all pairs (x, y), there is a Z=z that satisfies C(X=x, Y=y) if
and only if y = x + 1.
Some technical points: The domain of all variables is a large
finite field, Fp (the integers mod a prime p); p typically has
at least 128 bits. Also, each constraint has degree 2 and is
of a particular form, described elsewhere [62, 70]. Constraint
variables are represented by upper-case letters (X, Y, Z, . . .);
concrete values taken by those variables are represented by
lower-case letters (x, y, z, . . .).
if (Z1 == 1) {
Z2 = 10;
} else if (Z1 == 2) {
Z2 = 20;
} else {
Z2 = 100;
}
{ 0 = M0(Z1 − 1),
0 = M0(Z2 − 10),
0 = (1 − M0)(M2(Z1 − 1) − 1),
0 = (1 − M0)(M1(Z1 − 2)),
0 = (1 − M0)(M1(Z2 − 20)),
0 = (1 − M0)((1 − M1)(M3(Z1 − 2) − 1)),
0 = (1 − M0)((1 − M1)(Z2 − 100)) }
(a) Source.
(b) Constraints.
FIGURE 1—A conditional statement and corresponding constraints,
under Pantry. For clarity, constraints with degree greater than two are
not expanded.
Compilation process. Given a program, the compiler un-
rolls loops (each iteration gets its own variables) and con-
verts the code to static single assignment (details are described
in [27]). The compiler then transforms each line into one or
more constraints. Arithmetic operations compile concisely. For
example, the line of code z3=z1+z2; compiles to Z3 = Z1 +Z2.
As in all of the works that use large finite fields to represent
computations [16, 27, 62, 70, 72], inequality comparisons and
bitwise operations cost ≈w constraints, where w is the bit width
of the variables in question.
Conditional branches include constraints for both branches.
As an example, Figure 1 illustrates a simple if-else statement
and the corresponding constraints.
RAM. Pantry includes primitives for verifiable remote state,
called GetBlock and PutBlock. Each of these primitives com-
piles into constraints that represent the operation of a collision-
resistant hash function, H(·). One way to use GetBlock is for
V to supply as part of the input to Ψ a hash (or digest) d of
a remote input b that Ψ is supposed to work over (though V
does not know b). Then, satisfying the constraints that represent
GetBlock requires P to set the variables B so that H(B) = d.
Applying well-known techniques [24, 38, 53, 57], Pantry
uses GetBlock and PutBlock to create a RAM abstraction. Con-
cretely, each Load and Store compiles into multiple GetBlock
and PutBlock calls—and thus multiple invocations of H(·).
Step 2: Solve. To produce a satisfying assignment, P proceeds
constraint-by-constraint. In cases when the solution is not im-
mediate, a constraint has a compiler-produced annotation that
tells P how to solve it. As an example, if Z1 and Z2 are already
determined, then the solution to Z3 = Z2 + Z1 is immediate.
But in the constraints that correspond to the if-else statement
of Figure 1, the annotations tell P how to set M0, . . . , M3. Sim-
ilarly, to satisfy the constraints that represent GetBlock (and in
response to a PutBlock), the annotations instruct P to interact
with a backing store. We refer to such annotations and actions
as being exogenous to the constraint formalism (the theoretical
term is “non-deterministic input”).
2.3 BCTV
As in Pantry, BCTV’s constraints are over the finite field Fp,
and the constraints have input variables X, output variables Y,
and intermediate variables Z.
4
ProcessorState states[t]
state[0].pc = state[0].flag = 0
state[0].regs[0] = ... = state[0].regs[NUM_REGS-1] = 0
for S in [0, t-1):
state[S].instruction = LOAD(state[S].pc)
decode(state[S].instruction, &opcode, &target, &arg1, &arg2)
next_flag = state[S].flag
for i in [0, NUM_REGS):
if (i != target):
state[S+1].regs[i] = state[S].regs[i]
switch (opcode):
case OP_ADD:
state[S+1].regs[target] = arg1 + arg2
next_flag = (arg1 + arg2) > REGISTER_MAX
break
case OP_CJMP:
if (state[S].flag)
state[S+1].pc = arg1
break
case OP_LOAD:
state[S+1].regs[target] = LOAD(arg1)
break
...
state[S+1].flag = next_flag
if (opcode != OP_CJMP && opcode != OP_CNJMP
&& opcode != OP_JMP):
state[S+1].pc = state[S].pc + 1
state[t-1].instruction = LOAD(state[t-1].pc)
decode(state[t-1].instruction, &opcode, &target, &arg1, &arg2)
assert opcode == OP_ANSWER
return arg1 // expands to Y = arg1
FIGURE 2—Pseudocode for Ccpu, the constraints that represent
TinyRAM’s execution [17]. In the constraints, the for loop is un-
rolled: the constraints contain t repeated blocks, one for each iteration.
Step 1: Compile, produce constraints. The programmer ex-
presses a computation Ψ in standard C, and then runs a compiler
to transform Ψ to an assembly program for a simulated MIPS-
like CPU called TinyRAM [16, 17, 19]; we notate this program
text xΨ. The programmer must statically bound t, the number
of machine steps required to execute xΨ on the simulated CPU.
The constraints themselves are produced by V and P in a sep-
arate, offline step that is parameterized by t. The constraints
decompose into three subsets, described below.
CPU execution. The first set of constraints, Ccpu, represents
the simulated CPU’s execution, for t steps, purportedly starting
with memory that contains xΨ and x and producing output y
(this will be enforced below). The constraints have t repeated
blocks; each has variables for the CPU’s state (registers, flag,
program counter, and instruction) and represents one fetch-
decode-execute cycle, the logic for which is shown in Figure 2.
Any assignment (satisfying or otherwise) to Ccpu corresponds
to a purported execution-ordered transcript of the CPU: a list
of its state at each step in the execution. In any satisfying as-
signment to Ccpu, the variable settings correspond to the correct
operation of the CPU, under the assumption that the results
of LOAD operations are correct; that is, Ccpu leaves LOAD target
variables unconstrained. These variables are restricted by the
next two sets of constraints.
Memory operations. Define an address-ordered transcript
as a sort of the execution-ordered transcript by memory address,
with ties broken by execution order. Observe that in an address-
ordered transcript, each LOAD is preceded either by its corre-
sponding STORE or by another LOAD at the same address. Thus,
one can establish the correctness of an address-ordered tran-
script by checking that sequential entries are coherent, meaning
that a load from a memory cell returns the most recently stored
value to that cell.
Leveraging these observations, the remaining constraints
include variables that represent an address-ordered transcript,
T ; these constraints are satisfiable if and only if T is a sort
of the execution-ordered transcript that is pairwise coherent.
Specifically, the constraints are divided into two groups, Cperm
and Cck-sort. Cperm is satisfiable if and only if T is at least a per-
mutation (but not necessarily a sort) of the execution-ordered
transcript. Cck-sort is satisfiable if and only if this permutation is
indeed sorted and pairwise coherent.
In more detail, Cperm represents the logic of a permutation
network [13, 20]. The inputs to this network are variables from
the execution-ordered transcript, specifically two tuples (time-
stamp, op code, address, data) per machine cycle. One tuple
represents the instruction fetch; the other, whatever the instruc-
tion requested (LOAD, STORE, or no RAM operation). Cperm also
has variables that represent switch settings of the permutation
network. By construction, Cperm is satisfiable if and only if its
outputs are assigned to a permutation of its inputs. Note that
although we have referred to “inputs” and “outputs,” all vari-
ables are intermediate; the prover must obtain values (in its
assignment z) for all of them.
Cck-sort works over the output variables in Cperm, and is sat-
isfiable if and only if the assigned values respect the pairwise
relation establishing ordering and coherence.
Putting the pieces together. Where do the inputs and out-
puts (xΨ, x, y) appear? A BCTV execution begins with a “boot”
phase that stores xΨ into the beginning of memory and x into a
well-known memory location that Ψ expects. Concretely, the
memory transcript that feeds into Cperm includes tuples for xΨ
and x; for example, (j, STORE, j, xΨ[j]), j ∈ {0, . . . ,|xΨ| − 1},
where |xΨ| is the length of the program text. Notice that the
relevant values are assigned by the verifier (that is, they are
not part of the assignment z) and thus tether the execution to
the verifier’s request. For the output y, our description assumes
that the output of Ψ is a single machine word that is returned
at the end of the execution.5 Concretely, the final constraint in
Ccpu is y − Z∗ = 0, where Z∗ here is the constraint variable that
represents the final setting of the register arg1 (Fig. 2).
To recap, any satisfying assignment to Ccpu corresponds to an
execution-ordered transcript that (1) correctly represents non-
5A more general way to handle outputs is to supply y as auxiliary input [15, 19],
and to write Ψ so that, after computing its output, it accepts iff that output
equals y. This alternative is supported by our BCTV implementation and
matches the original description of BCTV.
5
288 bytes
|C| · 180µs
6 ms + (|x| + |y|) · 3 µs
|C| · 60 µs + |C| log|C| · 0.9 µs
certificate length
V setup
V per-instance
P per-instance
x, y ∈ Fp: inputs and outputs of C
FIGURE 3—End-to-end costs of any system (including BCTV [19],
Pantry [28], and Buffet) built on the optimized libsnark implemen-
tation [3, 19] of the Pinocchio back-end [62] with 128-bit security,
applied to constraints C. The cost of steps 1–2 is captured in the
number of constraints, |C|. We extracted parameters for this model
from microbenchmarks and experimental data (§5.4). The model as-
sumes that |C| equals the number of intermediate variables (|Z|) and
that the average constraint acts on only a few intermediate variables;
these assumptions hold in our benchmark applications (§5.2) and else-
where [28]. BCTV’s setup costs amortize better than Pantry’s (§2.4).
RAM operations (ALU, control flow, etc.), and (2) ends with
the purported output, y. For Cperm and Cck-sort to be satisfiable,
the values LOADed in the execution-ordered transcript must
be correct and, in particular, consistent with program text xΨ
and program input x. Thus, the three sets of constraints as a
whole are satisfiable if and only if y is the correct output of the
simulated CPU, given program Ψ and input x.
Step 2: Solve. To produce the satisfying assignment z to the
constraint variables, the prover, given xΨ and x, runs a rou-
tine on its native CPU that simulates the execution of xΨ. This
routine produces an execution-ordered transcript, yielding a
satisfying assignment to the variables of Ccpu.6 This routine fur-
ther selects the switch settings and determines the assignment
to the address-ordered transcript variables, in Cperm.
2.4 Costs, amortization, and accounting
The end-to-end costs of BCTV and Pantry (and Buffet) are sum-
marized in Figure 3. There are several things to note here. Most
importantly, the principal costs—setup costs and P’s work for
each protocol run—scale with the number of constraints (|C|).
Thus, there will be an impetus, in the sections ahead, to translate
program structures into economical constraint representations.
Second, we are charging setup costs to V, even though our
evaluation uses the public verifier variant [40] of the back-
end (§5.3); we explain this choice at the end of the section.
Third, setup costs are incurred for each new set of constraints,
yielding different amortization. Under Pantry, these costs are in-
curred for each computation Ψ and amortize over all instances
(input-output pairs) that the verifier invokes. In BCTV, all com-