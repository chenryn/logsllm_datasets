是提高消息吞吐量重要的方式，Producer 端可以在内存中合并多条消息后，以一次请求的方式发
送了批量的消息给 broker，从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响
了消息的实时性，相当于以时延代价，换取更好的吞吐量。
12.1.3.3. 压缩（GZIP或Snappy）
Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在
Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大
数据处理上，瓶颈往往体现在网络上而不是CPU（压缩和解压会耗掉部分CPU资源）。
12.1.1. 消费者设计
13/04/2018 Page 177 of 283
12.1.1.1. Consumer Group
同一 Consumer Group 中的多个 Consumer 实例，不同时消费同一个 partition，等效于队列模
式。partition内消息是有序的，Consumer通过pull方式消费消息。Kafka不删除已消费的消息
对于partition，顺序读写磁盘数据，以时间复杂度O(1)方式提供消息持久化能力。
13/04/2018 Page 178 of 283
13. RabbitMQ
13.1.1. 概念
RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。
AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为
面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言
等条件的限制。
RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可
用性等方面表现不俗。具体特点包括：
1. 可靠性（Reliability）：RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布
确认。
2. 灵活的路由（Flexible Routing）：在消息进入队列之前，通过 Exchange 来路由消息的。对
于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路
由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。
3. 消息集群（Clustering）：多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。
4. 高可用（Highly Available Queues）：队列可以在集群中的机器上进行镜像，使得在部分节
点出问题的情况下队列仍然可用。
5. 多种协议（Multi-protocol）：RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT
等等。
6. 多语言客户端（Many Clients）：RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、
Ruby 等等。
7. 管理界面（Management UI）:RabbitMQ 提供了一个易用的用户界面，使得用户可以监控
和管理消息 Broker 的许多方面。
8. 跟踪机制（Tracing）:如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生
了什么。
9. 插件机制（Plugin System）:RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编
写自己的插件。
13.1.2. RabbitMQ架构
13/04/2018 Page 179 of 283
13.1.2.1. Message
消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系
列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其他消息的优
先权）、delivery-mode（指出该消息可能需要持久性存储）等。
13.1.2.2. Publisher
1. 消息的生产者，也是一个向交换器发布消息的客户端应用程序。
13.1.2.3. Exchange（将消息路由给队列 ）
2. 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
13.1.2.4. Binding（消息队列和交换器之间的关联）
3. 绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连
接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。
13.1.2.5. Queue
4. 消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息
可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。
13.1.2.6. Connection
5. 网络连接，比如一个TCP连接。
13.1.2.7. Channel
6. 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的 TCP 连接内地虚
拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这
些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所
以引入了信道的概念，以复用一条 TCP 连接。
13.1.2.8. Consumer
7. 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。
13.1.2.9. Virtual Host
8. 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密
环境的独立服务器域。
13/04/2018 Page 180 of 283
13.1.2.10. Broker
9. 表示消息队列服务器实体。
13.1.3. Exchange 类型
Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、
topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和
direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型：
13.1.3.1. Direct键（routing key）分布：
1. Direct：消息中的路由键（routing key）如果和 Binding 中的 binding key 一致，
交换器就将消息发到对应的队列中。它是完全匹配、单播的模式。
13.1.3.2. Fanout（广播分发）
2. Fanout：每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。很像子
网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快
的。
13/04/2018 Page 181 of 283
13.1.3.3. topic 交换器（模式匹配）
3. topic 交换器：topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模
式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成
单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号
“”。#匹配0个或多个单词，匹配不多不少一个单词。
13/04/2018 Page 182 of 283
14. Hbase
14.1.1. 概念
base是分布式、面向列的开源数据库（其实准确的说是面向列族）。HDFS为Hbase提供可靠的
底层数据存储服务，MapReduce 为 Hbase 提供高性能的计算能力，Zookeeper 为 Hbase 提供
稳定服务和 Failover 机制，因此我们说 Hbase 是一个通过大量廉价的机器解决海量数据的高速存
储和读取的分布式数据库解决方案。
14.1.2. 列式存储
列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因此整个数据库
是自动索引化的。
这里的列式存储其实说的是列族存储，Hbase 是根据列族来存储数据的。列族下面可以有非常多
的列，列族在创建表的时候就必须指定。为了加深对 Hbase 列族的理解，下面是一个简单的关系
型数据库的表和Hbase数据库的表：
13/04/2018 Page 183 of 283
14.1.3. Hbase核心概念
14.1.3.1. Column Family列族
Column Family 又叫列族，Hbase 通过列族划分数据的存储，列族下面可以包含任意多的列，实
现灵活的数据存取。Hbase 表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须
指定具体的列是一样的。Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于3。我
们使用的场景一般是1个列族。
14.1.3.2. Rowkey（Rowkey查询，Rowkey范围扫描，全表扫描）
Rowkey 的概念和mysql中的主键是完全一样的，Hbase 使用 Rowkey 来唯一的区分某一行的数
据。Hbase只支持3中查询方式：基于 Rowkey的单行查询，基于 Rowkey的范围扫描，全表扫
描。
14.1.3.3. Region分区
 Region：Region 的概念和关系型数据库的分区或者分片差不多。Hbase 会将一个大表的数
据基于Rowkey的不同范围分配到不通的Region中，每个Region负责一定范围的数据访问
和存储。这样即使是一张巨大的表，由于被切割到不通的region，访问起来的时延也很低。
14.1.3.4. TimeStamp多版本
 TimeStamp是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同
rowkey行对应的不通版本的数据。在写入数据的时候，如果用户没有指定对应的
timestamp，Hbase会自动添加一个timestamp，timestamp和服务器时间保持一致。在
Hbase中，相同rowkey的数据按照timestamp倒序排列。默认查询的是最新的版本，用户
可同指定timestamp的值来读取旧版本的数据。
14.1.4. Hbase核心架构
Hbase是由Client、Zookeeper、Master、HRegionServer、HDFS等几个组建组成。
13/04/2018 Page 184 of 283
14.1.4.1. Client：
 Client包含了访问Hbase的接口，另外Client还维护了对应的cache来加速Hbase的
访问，比如cache的.META.元数据的信息。
14.1.4.2. Zookeeper：
 Hbase通过Zookeeper来做master的高可用、RegionServer的监控、元数据的入口
以及集群配置的维护等工作。具体工作如下：
1. 通过Zoopkeeper来保证集群中只有1个master在运行，如果master异
常，会通过竞争机制产生新的master提供服务
2. 通过Zoopkeeper来监控RegionServer的状态，当RegionSevrer有异常的
时候，通过回调的形式通知Master RegionServer上下限的信息
3. 通过Zoopkeeper存储元数据的统一入口地址。
14.1.4.3. Hmaster
 master节点的主要职责如下：
1. 为RegionServer分配Region
2. 维护整个集群的负载均衡
3. 维护集群的元数据信息发现失效的Region，并将失效的Region分配到正常
RegionServer上当RegionSever失效的时候，协调对应Hlog的拆分
14.1.4.4. HregionServer
 HregionServer直接对接用户的读写请求，是真正的“干活”的节点。它的功能概括如
下：
1. 管理master为其分配的Region
13/04/2018 Page 185 of 283
2. 处理来自客户端的读写请求
3. 负责和底层HDFS的交互，存储数据到HDFS
4. 负责Region变大以后的拆分
5. 负责Storefile的合并工作
14.1.4.5. Region寻址方式（通过zookeeper .META）
第1步：Client请求ZK获取.META.所在的RegionServer的地址。
第2步：Client请求.META.所在的RegionServer获取访问数据所在的RegionServer地
址，client会将.META.的相关信息cache下来，以便下一次快速访问。
第3步：Client请求数据所在的RegionServer，获取所需要的数据。
14.1.4.6. HDFS
 HDFS为Hbase提供最终的底层数据存储服务，同时为Hbase提供高可用（Hlog存储在
HDFS）的支持。
13/04/2018 Page 186 of 283
14.1.5. Hbase的写逻辑
14.1.5.1. Hbase的写入流程
从上图可以看出氛围3步骤：
获取RegionServer
第1步：Client获取数据写入的Region所在的RegionServer
请求写Hlog
第2步：请求写Hlog, Hlog存储在HDFS，当RegionServer出现异常，需要使用Hlog来
恢复数据。
请求写MemStore
第3步：请求写MemStore,只有当写Hlog和写MemStore都成功了才算请求写入完成。
MemStore后续会逐渐刷到HDFS中。
14.1.5.2. MemStore刷盘
为了提高Hbase的写入性能，当写请求写入MemStore后，不会立即刷盘。而是会等到一
定的时候进行刷盘的操作。具体是哪些场景会触发刷盘的操作呢？总结成如下的几个场景：
13/04/2018 Page 187 of 283
全局内存控制
1. 这个全局的参数是控制内存整体的使用情况，当所有memstore占整个heap的最大比