## network block device(nbd) 共享网络块设备 - 用于测试RAC和PolarDB for PG共享存储版     
### 作者  
digoal  
### 日期  
2021-10-15   
### 标签  
PostgreSQL , nbd , network block device , 网络块设备     
----  
## 背景  
视频回放: https://www.bilibili.com/video/BV14P4y1t7zB/  
网络块设备nbd是一种廉价的共享存储解决方案. nbd也可以作为轻量化的共享存储测试方案, 用于部署学习Oracle RAC, PolarDB for PostgreSQL等.   
nbd除了支持tcp协议, 还支持sdp(rdma)协议, 也能测出高性能.   
PolarDB for PostgreSQL 开源地址如下:  https://github.com/ApsaraDB     
![pic1](https://github.com/ApsaraDB/PolarDB-for-PostgreSQL/blob/main/doc/PolarDB-CN/pic/3_HTAP_architecture.png)  
![pic2](https://www.fi.muni.cz/~kripac/orac-nbd/img/nbd.gif)    
使用nbd构建Oracle-RAC :   
http://www.fi.muni.cz/~kripac/orac-nbd/  
需要注意的问题, 例如操作系统层缓存, 当从nbd-server切换到另一个nbd-server时, 如果有缓存为写入镜像文件的话, 会导致数据丢失. 这个问题可以通过nbd-server sync export模式解决.   
## 一、部署环境  
1台server(2块100G云盘vdb, vdc), 2台client. centos 7.9环境.   
```  
yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm        
yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm        
yum install -y centos-release-scl  
yum install -y postgresql14*      
```  
### 内核参数        
```        
vi /etc/sysctl.conf            
# add by digoal.zhou                
fs.aio-max-nr = 1048576                
fs.file-max = 76724600                
# 可选：kernel.core_pattern = /data01/corefiles/core_%e_%u_%t_%s.%p                         
# /data01/corefiles 事先建好，权限777，如果是软链接，对应的目录修改为777                
kernel.sem = 4096 2147483647 2147483646 512000                    
# 信号量, ipcs -l 或 -u 查看，每16个进程一组，每组信号量需要17个信号量。                
kernel.shmall = 107374182                      
# 所有共享内存段相加大小限制 (建议内存的80%)，单位为页。                
kernel.shmmax = 274877906944                   
# 最大单个共享内存段大小 (建议为内存一半), >9.2的版本已大幅降低共享内存的使用，单位为字节。                
kernel.shmmni = 819200                         
# 一共能生成多少共享内存段，每个PG数据库集群至少2个共享内存段                
net.core.netdev_max_backlog = 10000                
net.core.rmem_default = 262144                       
# The default setting of the socket receive buffer in bytes.                
net.core.rmem_max = 4194304                          
# The maximum receive socket buffer size in bytes                
net.core.wmem_default = 262144                       
# The default setting (in bytes) of the socket send buffer.                
net.core.wmem_max = 4194304                          
# The maximum send socket buffer size in bytes.                
net.core.somaxconn = 4096                
net.ipv4.tcp_max_syn_backlog = 4096                
net.ipv4.tcp_keepalive_intvl = 20                
net.ipv4.tcp_keepalive_probes = 3                
net.ipv4.tcp_keepalive_time = 60                
net.ipv4.tcp_mem = 8388608 12582912 16777216                
net.ipv4.tcp_fin_timeout = 5                
net.ipv4.tcp_synack_retries = 2                
net.ipv4.tcp_syncookies = 1                    
# 开启SYN Cookies。当出现SYN等待队列溢出时，启用cookie来处理，可防范少量的SYN攻击                
net.ipv4.tcp_timestamps = 1                    
# 减少time_wait                
net.ipv4.tcp_tw_recycle = 0                    
# 如果=1则开启TCP连接中TIME-WAIT套接字的快速回收，但是NAT环境可能导致连接失败，建议服务端关闭它                
net.ipv4.tcp_tw_reuse = 1                      
# 开启重用。允许将TIME-WAIT套接字重新用于新的TCP连接                
net.ipv4.tcp_max_tw_buckets = 262144                
net.ipv4.tcp_rmem = 8192 87380 16777216                
net.ipv4.tcp_wmem = 8192 65536 16777216                
net.nf_conntrack_max = 1200000                
net.netfilter.nf_conntrack_max = 1200000                
vm.dirty_background_bytes = 409600000                       
#  系统脏页到达这个值，系统后台刷脏页调度进程 pdflush（或其他） 自动将(dirty_expire_centisecs/100）秒前的脏页刷到磁盘                
#  默认为10%，大内存机器建议调整为直接指定多少字节                
vm.dirty_expire_centisecs = 3000                             
#  比这个值老的脏页，将被刷到磁盘。3000表示30秒。                
vm.dirty_ratio = 95                                          
#  如果系统进程刷脏页太慢，使得系统脏页超过内存 95 % 时，则用户进程如果有写磁盘的操作（如fsync, fdatasync等调用），则需要主动把系统脏页刷出。                
#  有效防止用户进程刷脏页，在单机多实例，并且使用CGROUP限制单实例IOPS的情况下非常有效。                  
vm.dirty_writeback_centisecs = 100                            
#  pdflush（或其他）后台刷脏页进程的唤醒间隔， 100表示1秒。                
vm.swappiness = 0                
#  不使用交换分区                
vm.mmap_min_addr = 65536                
vm.overcommit_memory = 0                     
#  在分配内存时，允许少量over malloc, 如果设置为 1, 则认为总是有足够的内存，内存较少的测试环境可以使用 1 .                  
vm.overcommit_ratio = 90                     
#  当overcommit_memory = 2 时，用于参与计算允许指派的内存大小。                
vm.swappiness = 0                            
#  关闭交换分区                
vm.zone_reclaim_mode = 0                     
# 禁用 numa, 或者在vmlinux中禁止.                 
net.ipv4.ip_local_port_range = 40000 65535                    
# 本地自动分配的TCP, UDP端口号范围                
fs.nr_open=20480000                
# 单个进程允许打开的文件句柄上限                
# 以下参数请注意                
# vm.extra_free_kbytes = 4096000                
# vm.min_free_kbytes = 6291456  # vm.min_free_kbytes 建议每32G内存分配1G vm.min_free_kbytes               
# 如果是小内存机器，以上两个值不建议设置                
# vm.nr_hugepages = 66536                    
#  建议shared buffer设置超过64GB时 使用大页，页大小 /proc/meminfo Hugepagesize                
# vm.lowmem_reserve_ratio = 1 1 1                
# 对于内存大于64G时，建议设置，否则建议默认值 256 256 32            
# 生效        
# sysctl -p        
```        
### 配置限制        
```        
vi /etc/security/limits.conf            
# nofile超过1048576的话，一定要先将sysctl的fs.nr_open设置为更大的值，并生效后才能继续设置nofile.                
# 注释其他行 ， 添加如下        
* soft    nofile  1024000                
* hard    nofile  1024000                
* soft    nproc   unlimited                
* hard    nproc   unlimited                
* soft    core    unlimited                
* hard    core    unlimited                
* soft    memlock unlimited                
* hard    memlock unlimited            
```        
同时修改(若有)        
```        
/etc/security/limits.d/20-nproc.conf        
```        
### 关闭透明大页（可选）        
```        
echo never > /sys/kernel/mm/transparent_hugepage/enabled         
```        
配置永久生效        
```        
chmod +x /etc/rc.d/rc.local      
vi /etc/rc.local            
touch /var/lock/subsys/local            
if test -f /sys/kernel/mm/transparent_hugepage/enabled; then                
   echo never > /sys/kernel/mm/transparent_hugepage/enabled                
fi              
```        
### 修改时钟（可选）      
```      
vi /etc/rc.local      
touch /var/lock/subsys/local      
if test -f /sys/kernel/mm/transparent_hugepage/enabled; then      
   echo never > /sys/kernel/mm/transparent_hugepage/enabled      
fi      
echo tsc > /sys/devices/system/clocksource/clocksource0/current_clocksource         
```      
支持的时钟：        
```        
cat /sys/devices/system/clocksource/clocksource0/available_clocksource         
kvm-clock tsc acpi_pm         
```        
修改时钟：        
```        
echo tsc > /sys/devices/system/clocksource/clocksource0/current_clocksource         
```     
## 二、部署nbd  
服务端可以直接使用nbd包, 客户端需要编译一下内核(可能centos 7的内核没有默认把nbd模块带进去).    
```  
yum install -y nbd  
```  
### 服务端  
```  
[root@iZbp1eo3op9s5gxnvc7aokZ ~]# ifconfig  
eth0: flags=4163  mtu 1500  
        inet 172.17.164.66  netmask 255.255.240.0  broadcast 172.17.175.255  
        inet6 fe80::216:3eff:fe00:851f  prefixlen 64  scopeid 0x20  
        ether 00:16:3e:00:85:1f  txqueuelen 1000  (Ethernet)  
        RX packets 159932  bytes 229863288 (219.2 MiB)  
        RX errors 0  dropped 0  overruns 0  frame 0  
        TX packets 30124  bytes 3706650 (3.5 MiB)  
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0  
```  
```  
[root@iZbp1eo3op9s5gxnvc7aokZ ~]# lsblk  
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT  
vda    253:0    0  100G  0 disk   
└─vda1 253:1    0  100G  0 part /  
vdb    253:16   0  100G  0 disk   
vdc    253:32   0  100G  0 disk   
```  
编写nbd-server配置文件, 详见man 5 nbd-server  
注意每行配置末尾不能有空格, 解析有问题   
```  
vi /root/nbd.conf  
# This is a comment  
[generic]
    # The [generic] section is required, even if nothing is specified  
    # there.  
    # When either of these options are specified, nbd-server drops  
    # privileges to the given user and group after opening ports, but  
    # _before_ opening files.  
    # user = nbd  
    # group = nbd  
    listenaddr = 0.0.0.0
    port = 1921
[export1]
    exportname = /dev/vdb
    readonly = false
    multifile = false
    copyonwrite = false
    flush = true
    fua = true
    sync = true
[export2]
    exportname = /dev/vdc
    readonly = false
    multifile = false
    copyonwrite = false
    flush = true
    fua = true
    sync = true
```  
启动nbd-server  
```  
[root@iZbp1eo3op9s5gxnvc7aokZ ~]# nbd-server -C /root/nbd.conf   
```  
### 客户端  
需要额外编译nbd模块到内核中, 编译参考:  
https://www.jianshu.com/p/d7813321e0ee  
https://blog.csdn.net/mshxuyi/article/details/100610074  
https://blog.csdn.net/wendowswd/article/details/79067935  
```  
yum install -y kernel-devel kernel-headers elfutils-libelf-devel gcc+ gcc-c++  
[root@iZbp1eo3op9s5gxnvc7aolZ ~]# uname -r  
3.10.0-1160.42.2.el7.x86_64  
```  
理论上42.2小版本也要一致, 但是没找到rpm包. 3.10.0-1160.el7好像也能用.  
PS: 后来在 https://vault.centos.org/7.9.2009/updates/Source/SPackages/ 找到了更新小版本的src.   
```  
curl https://vault.centos.org/7.9.2009/os/Source/SPackages/kernel-3.10.0-1160.el7.src.rpm -o ./kernel-3.10.0-1160.el7.src.rpm  
修改为:
curl https://vault.centos.org/7.9.2009/updates/Source/SPackages/kernel-3.10.0-1160.42.2.el7.src.rpm -o ./kernel-3.10.0-1160.42.2.el7.src.rpm  
rpm -ivh kernel-3.10.0-1160.el7.src.rpm   
修改为:
rpm -ivh kernel-3.10.0-1160.42.2.el7.src.rpm
cd rpmbuild/SOURCES/  
tar xvf linux-3.10.0-1160.el7.tar.xz -C /usr/src/kernels/  
修改为:
tar xvf linux-3.10.0-1160.42.2.el7.tar.xz -C /usr/src/kernels/  
cd /usr/src/kernels/linux-3.10.0-1160.el7  
修改为:
cd /usr/src/kernels/linux-3.10.0-1160.42.2.el7  
make mrproper  
cp /usr/src/kernels/3.10.0-1160.42.2.el7.x86_64/Module.symvers ./  
cp /boot/config-3.10.0-1160.el7.x86_64 ./.config  
修改为:
cp /boot/config-3.10.0-1160.42.2.el7.x86_64 ./.config  
make oldconfig  
make prepare  
make scripts  
```  
下面是修复编译错误的一段(因为没有include blkdev.h头文件, 缺少变量定义而报错):    
```  