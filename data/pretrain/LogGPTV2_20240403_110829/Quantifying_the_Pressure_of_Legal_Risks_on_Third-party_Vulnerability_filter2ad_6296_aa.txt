title:Quantifying the Pressure of Legal Risks on Third-party Vulnerability
Research
author:Alexander Gamero-Garrido and
Stefan Savage and
Kirill Levchenko and
Alex C. Snoeren
Quantifying the Pressure of Legal Risks
on Third-party Vulnerability Research
Alexander Gamero-Garrido, Stefan Savage, Kirill Levchenko, and Alex C. Snoeren
University of California, San Diego
thus can be extremely challenging to find. Thus, even while a range
of development practices (e.g., Microsoft SDL) are thought to re-
duce their prevalence, it is widely understood that all software
ships with security vulnerabilities present. Indeed, much of modern
operational security practice today revolves around managing the
problems created when these flaws are identified after a product
has been deployed.
ABSTRACT
Product vendors and vulnerability researchers work with the same
underlying artifacts, but can be motivated by goals that are distinct
and, at times, disjoint. This potential for conflict, coupled with the
legal instruments available to product vendors (e.g., EULAs, DMCA,
CFAA, etc.) drive a broad concern that there are “chilling effects”
that dissuade vulnerability researchers from vigorously evaluating
product security. Indeed, there are well-known examples of legal
action taken against individual researchers. However, these are
inherently anecdotal in nature and skeptics of the chilling-effects
hypothesis argue that there is no systematic evidence to justify
such concerns. This paper is motivated by precisely this tussle. We
present some of the first work to address this issue on a quantitative
and empirical footing, illuminating the sentiments of both product
vendors and vulnerability researchers. First, we canvas a range
of product companies for explicit permission to conduct security
assessments and thus characterize the degree to which the broad
software vendor community is supportive of vulnerability research
activities and how this varies based on the nature of the researcher.
Second, we conduct an online sentiment survey of vulnerability
researchers to understand the extent to which they have abstract
concerns or concrete experience with legal threats and the extent
to which this mindset shapes their choices.
KEYWORDS
vulnerability; public policy; copyright
1 INTRODUCTION
Software of any complexity is invariably imperfect, riddled with
design flaws or deviations from the designers’ intent that are ca-
pable of producing unexpected side-effects. While most of these
bugs are benign, a subset is of particular concern because they
allow an adversary to violate key security properties that would
otherwise be assured. Unfortunately, such security vulnerabilities
rarely manifest in the absence of specific adversarial inputs and
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’17, October 30–November 3, 2017, Dallas, TX, USA
© 2017 Copyright held by the owner/author(s). Publication rights licensed to Associa-
tion for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10...$15.00
https://doi.org/10.1145/3133956.3134047
How security vulnerabilities are discovered is a key aspect of
this situation. While many such vulnerabilities are found by the
developer, or groups under contract to them, even cursory anal-
ysis of empirical vulnerability data shows that the vast majority
of critical vulnerabilities are identified by third-party vulnerabil-
ity researchers who audit software of their own accord and for a
variety of reasons. Indeed, this is not surprising as there are far
more such independent vulnerability researchers than any one soft-
ware developer can possibly employ. However, the role of such
researchers occupies a conflicted policy space. On the one hand, it
is clear that this set of independent research communities is key to
both identifying significant flaws in deployed software and creat-
ing an incentive for developers to fix them. At the same time, the
costs of such discoveries (particularly when uncoordinated with
the software developer), in both labor and brand damage, has the
potential to create an adversarial relationship between developers
and the research community.
Moreover, under existing U.S. law, software developers have a
range of legal theories under which they may challenge third-party
security research. These include violations of explicit contractual
terms in so-called shrink/click-wrap contracts (e.g., it is increas-
ingly common for such documents to explicitly forbid reverse-
engineering), violations of the Computer Fraud and Abuse Act
(CFAA) covering unauthorized access to computer systems (of par-
ticular concern for products with components hosted on third-party
services or products which are leased as a service and not purchased
outright), violations of electronic communications privacy laws
(e.g., the Wiretap Act, Pen/Trap Statute and the Electronic Commu-
nications Privacy Act (ECPA) as they apply to research methods that
involve intercepting messages sent from a product), as well as more
generic claims of libel, trade secret misappropriation, copyright
infringement, etc.
Perhaps the best-known example of these tensions arises due
to the Digital Millennium Copyright Act (DMCA) whose anti-
circumvention requirements were originally designed to protect
media publishers against unauthorized copyright violations, but
have been read to encompass a range of software protection mecha-
nisms typically encountered when performing security audits. The
DMCA provides a private course of action for copyright holders
to litigate both injunctive relief and monetary damages against
violators.1 Threats under the DMCA have been documented for
several high-profile vulnerability research efforts, most famously in
2000 against a group of Princeton researchers forced to withdraw
an accepted paper from publication [31].
During periodic rule-making adjustments mandated by the
DMCA statute, a variety of industry groups have resisted efforts
to create additional safe harbors for security researchers from
this legal recourse [34]. This in turn has led to a claim that the
DMCA [13, 17], and the threat of its use, has a “chilling effect” on
security research. Advocates of reform argue that that the ultimate
harm is to consumers who are denied an independent security
assessment and the resulting improvements in software security.
Opponents of reforming the anti-circumvention clause point out
that this claim is only documented via anecdote and not by any
systematic assessment.
Two key results stand out from our study:
• While some product manufacturers have embraced the role
of third-party vulnerability research and provide explicit or
implicit consent to conduct such work (either unrestricted
or with time-limited coordinated disclosure policy), most are
loathe to surrender legal recourse and either are unwilling
1The Librarian of Congress, who has statutory authority to grant certain exceptions
to the DMCA anti-circumvention clause, has recently granted a limited exemption to
the “prohibition against circumvention of technological measures controlling access
to copyrighted works” [27] for particular security uses.
This narrative is not unique to the DMCA, and variants of the
“chilling-effects” hypothesis have been proposed across the range of
potential legal risks encountered by security researchers, with op-
posing voices arguing that there is no compelling data to justify any
change in policy. Indeed, to date we are unaware of any grounded
attempt to quantify the legal risks faced by security researchers that
would place the role played by such forces on an evidence-based
footing. Within this milieu, there are two related key questions.
First, the extent to which modern product companies reserve or
assert their legal rights to limit, control or dissuade vulnerabil-
ity researchers from independently assessing the security of their
products. And second, the extent to which vulnerability researchers
factor the possibility of adverse legal action when deciding whether
to analyze a particular product.
Our work provides a first step to place these questions on an em-
pirical, quantifiable basis. To elucidate the legal posture of product
companies we conducted an empirical study of 75 companies (span-
ning a range of company sizes and product categories) in which
each were contacted by security researchers seeking prior approval
for independent security assessments of their products. By varying
the nature of the request (e.g., whether or not the DMCA is ex-
plicitly mentioned) and pedigree of researcher making the request
(e.g., academic vs. independent researchers) we sought to tease
apart dependent factors that we hypothesized might impact their
responses. To understand the role played by researcher experience
and perception, we surveyed over 100 vulnerability researchers and
evaluated their predisposition to view legal concerns as a key factor
in pursuing a given research target and the extent to which this
sentiment was driven purely by abstract concerns or whether they
had experienced concrete legal threats in practice.
to engage on questions of permission or impose significant
restrictions on doing so. Moreover, we find a significant
difference in the responsiveness afforded to academic vs.
independent security researchers.
• Legal concerns are a significant concern for many vulnera-
bility researchers and almost a quarter report having experi-
enced legal threats or action in the course of their research.
The remainder of the paper presents the methodology, data and
analysis for both of our measurement instruments, and discussion
regarding potential implications of our findings.
2 STUDY METHODOLOGY
One of the ways researchers can protect themselves from the threat
of legal action is to secure the consent of the companies whose
products they plan to investigate. Although consent does not elimi-
nate litigation risk, it puts a researcher in a dramatically stronger
position should a company take legal action. However, anecdotally
few researchers seem to take advantage of this potential safe har-
bor – perhaps fearing that a negative response to such a request
could jeopardize their research. Thus, it is not well-understood if
companies are amenable to working with researchers in this way
or if they prefer to reserve their legal options (i.e., and thus insist
on researchers absorbing all such risk). To explore this question
empirically, we worked with four security researchers to request
explicit authorization from 75 different companies to conduct secu-
rity evaluations on their products. 2 The remainder of this section
describes our methodology followed by an analysis of the responses
in Section 3.
2.1 Researcher selection
We hypothesized that the reputation and affiliation of the researcher
making the request might influence a company’s willingness to
grant permission. To test our hypothesis, we approached four
security-vulnerability experts: two academics and two indepen-
dent researchers. This experimental was based on our anecdotal
understanding that academic researchers benefit from the impri-
matur of their host university, and the associated public “optics”
associated with their public mission (in addition to the significant
resources of a dedicated university counsel).
By contrast, individual independent security researchers may
have little or no institutional support and may be far more fragile
to legal threats as a result. Further, different researchers have es-
tablished reputations for how they manage vulnerability disclosure
and this may in turn modulate the apprehension potentially felt by
companies whose products are being scrutinized. To this end, our
group of academic researchers includes one senior faculty member
(with tenure), and one junior (tenure-track) faculty member at a dif-
ferent institution. We also recruited two independent researchers:
one based in the United States, and another based in the European
Union.
2We submitted our protocol to our institutional review board (IRB) in advance of
this study and they declared it to not be human subjects research because, among
other reasons, it focused on organizational responses and not on individuals. However,
we were still careful to minimize the overhead on the organizations being evaluated
– limiting interactions to written responses and we have chosen not to name the
individual companies to avoid any reputational harm.
Recruiting researchers proved to be challenging. We approached
two academics and one independent researcher that were initially
willing to engage with this project, but then later decided to with-
draw from it. Two of the researchers feared company retribution,
given that they personally or their staff interact with product man-
ufacturers frequently, and some of their projects receives private
funding from such companies. Further, participation in this study
offered limited value to them, while potentially endangering their
prospects to do actual vulnerability research on some of these prod-
ucts, should the company reject their request in this study.
Both of the academic researchers who ultimately assisted with
our study were well-known security faculty with over 150 pub-
lished papers and 35,000 citations between them. However, the
two varied in seniority; one received their Ph.D. roughly a decade
before the other. The senior faculty member was also involved in
a pilot round of the study (using the same methodology) thus ac-
counting for a disparity in the number of companies assigned to
each. The two participating independent researchers also came with
well-established track records. The U.S.-based researcher has been
involved in security research “on behalf of Fortune 500 enterprise
security teams,” and the E.U. researcher has had their work featured
in the New York Times and Ars Technica. Both have been speakers
in major independent security conferences (e.g. BlackHat).
2.2 Company selection
We chose the consumer electronics and software industry as a start-
ing point since companies there are likely to have set procedures
for dealing with random contacts about security vulnerabilities.
Additionally, consumer products are particularly salient in policy
disputes surrounding the DMCA anti-circumvention provision [13].
To that end, we excluded non-profits and companies that sell primar-
ily to enterprise customers. However, there are fewer manufacturers
of consumer-facing products sold in the U.S. fitting our criteria than
one might surmise and we only were able to identify roughly 120
such companies using the methodology described below.
We used five sources to identify candidate companies and pruned
this set to find those manufacturing consumer-focused products
sold in the U.S.
Fortune 1000. Our first source, aimed at tallying large companies,
was the extended list of one thousand firms compiled by Fortune
magazine [6], typically referred to as the Fortune 500. The authors
rank companies by “total revenues for their respective fiscal years.
Included in the survey are companies that are incorporated in the
U.S. and operate in the U.S. and file financial statements with a
government agency.” These firms are by any metric some of the
largest corporations in the nation. Consistent with our industry
focus, we contacted companies from the following categories, as de-
fined by Fortune: Computer Software, Computers, Office Equipment,
Computer Peripherals, Electronics, Electrical Equipment, Network
and Other Communication Equipment, Semiconductors and Other
Electronic Components
Large retailers. We looked for manufacturers featured on the
“Electronics” section of two of the largest U.S. online retailers: Tar-
get.com and Amazon.com. There, we gathered the products listed
on the first page of each subcategory, and filtered for those meeting
devices, and tablets.
• MIT Technology Review: Computers and accessories,
multimedia devices, smart home devices, and wearable
electronic devices.
• PCMag.com: Drones, multimedia devices, networking devices,
printers, and smart home devices.
• TopTenReviews.com: Computers and accessories, consumer
software, multimedia devices, networking devices, and smart
home devices.
• The Wall Street Journal: Multimedia devices, networking
our criteria. Note that we did not use these products directly, but
rather compiled a list of companies and then followed our product-
selection protocol described in Section 2.3.
Stock indices. Our sample of large consumer-technology com-
panies includes components of two stock-related lists: an index
compiled by S&P Dow Jones Indices (U.S. Technology Index [2])
and an exchange-traded fund by BlackRock (iShares U.S. Technol-
ogy ETF [8]), the world’s largest investment firm [24].
Press lists. Contrary to our intuition, many popular consumer
products are not manufactured by very large companies, but rather
by mid-sized firms specializing in a technological niche. In order
to expand our sample to include them, we looked at popular press
publications and columns specializing in consumer technology. To
protect the anonymity of the companies studied we do not share
the URLs of the lists we used, but instead we aggregate them by
publication and product category below:
• cnet.com: Automotive GPS devices, computers and accessories,
smart home devices, and multimedia devices.
• Fast Company: Computers and accessories, smart home
devices, and smart home devices.
• All others3: Computers and accessories, multimedia devices,
networking devices, and smart home devices.
Y Combinator. In order to find early-stage startups with credible
prospects, we consulted the list of companies launched by well-
known incubator Y Combinator, whose alumni “companies have a
combined valuation of over $80 billion.” [19]
Among this group, a secondary goal was to diversify the size and
age of companies contacted-from very large and established firms
to startups-in the hope of obtaining a more accurate representation
of vulnerability-related policies for a wider range of products. We
hypothesized that very large companies who manage third-party
vulnerability disclosure on a regular basis may tend to understand
the complexities of the problem well and have clean processes for
handling such questions. Indeed, many such companies employ
third-party organizations (e.g., HackerOne) to operate bug bounty
programs precisely to harness this third-party labor in a controlled
setting. By contrast, smaller companies may have little experience
with independent security research and, we hypothesized, may
therefore have a tendency to act more adversarial. Our final sample
includes companies with vastly different revenues; $250 thousand
to $75 million, $75 million to $3 billion, and $3 billion to $250 billion,
3One company each from articles on NetworkWorld.com, ConsumerReports.org,
LaptopMag.com,