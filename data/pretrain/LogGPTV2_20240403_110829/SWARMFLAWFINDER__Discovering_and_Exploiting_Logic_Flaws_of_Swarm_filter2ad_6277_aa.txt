title:SWARMFLAWFINDER: Discovering and Exploiting Logic Flaws of Swarm
Algorithms
author:Chijung Jung and
Ali Ahad and
Yuseok Jeon and
Yonghwi Kwon
2022 IEEE Symposium on Security and Privacy (SP)
SWARMFLAWFINDER: Discovering and Exploiting
Logic Flaws of Swarm Algorithms
Chijung Jung∗, Ali Ahad∗, Yuseok Jeon†, and Yonghwi Kwon∗
∗Department of Computer Science, University of Virginia, Charlottesville, VA, USA
†Department of Computer Science and Engineering, UNIST, Ulsan, South Korea
∗{cj5kd, aa5rn, yongkwon}@virginia.edu
†PI:EMAIL
5
8
6
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
Abstract—Inspired by swarms in nature, swarm robotics have
been developed to conduct various challenging tasks such as
environmental monitoring, disaster recovery, logistics, and even
military operations. Despite the signiﬁcant potential impact of the
swarm on society, relatively little attention is given to adversarial
scenarios against swarm robotics.
In this paper, we explore a systematic approach to ﬁnd logical
ﬂaws of the swarm robotics algorithms that adversaries can
exploit. Speciﬁcally, we develop an automated testing system,
SWARMFLAWFINDER, for swarm algorithms. We identify and
overcome various challenges in understanding and reasoning
about the swarm algorithm execution. In particular, we propose
a novel abstraction of robotics behavior, which we call the degree
of causal contribution (DCC), based on the idea of counterfac-
tual causality. Then, we build a feedback guided greybox fuzz
testing system called SWARMFLAWFINDER, leveraging DCC as
a feedback metric. We evaluate SWARMFLAWFINDER with four
swarm algorithms conducting navigating, searching, and rescuing
missions. SWARMFLAWFINDER discovers 42 logic ﬂaws (and
all of them have been acknowledged by the developers) in the
swarm algorithms. Our analysis of the ﬂaws reveals that the
swarm algorithms have critical logic errors/bugs or suffer from
incomplete implementations that can be exploited by adversaries.
I. INTRODUCTION
Swarm robotics revolutionizes how robots can function and
what they can accomplish. It has attracted attention for a
variety of vital missions, such as search and rescue, that are
typically challenging for individual drones to complete. A
swarm is more than just a set of drones performing the same
operations. Robots in a swarm cooperate with others (e.g.,
sharing and distributing intelligence) to accomplish tasks.
A swarm operation is controlled by a swarm algorithm,
which coordinates the actions of multiple robots. The swarm
algorithm’s efﬁcacy determines a swarm operation’s effective-
ness. Logic ﬂaws (i.e., logic bugs or weaknesses) in a swarm
algorithm can result in various failures. Consider a swarm
searching algorithm that coordinates multiple groups of robots,
with robots in the same group sharing information discovered
during the mission. The efﬁciency of the swarm algorithm
depends on the number of robots in a group. In such a case,
an adversary, who is capable of breaking existing groups into
smaller groups, can lead the swarm to undesirable states,
signiﬁcantly slowing down the searching. Such undesirable
swarm operations may lead to severe consequences in the wild.
For instance, failures in searching/rescuing missions can result
in casualties. Failure to search/deliver in military missions
can lead to losing a battle. Signiﬁcantly slowed-down swarm
missions in commercial businesses can cause ﬁnancial loss.
This paper explores a systematic approach for detecting
logic ﬂaws in swarm algorithms, particularly in drone swarms.
Speciﬁcally, we develop a greybox fuzz testing technique for
swarm robotics, called SWARMFLAWFINDER, that overcomes
unique challenges in effectively testing drone swarm algo-
rithms. Given a target swarm algorithm and a swarm mission
deﬁnition (e.g., the number of drones and mission objectives),
SWARMFLAWFINDER introduces attack drones to disrupt the
swarm operation. The attack drones aim to interfere with the
swarm, attempting to expose logical weaknesses that lead to
mission failure, rather than launching naive and overt attacks
(e.g., directly crashing into victim drones). A key component
in developing SWARMFLAWFINDER is to design an efﬁcient
metric that abstracts a given test’s effectiveness. Unfortunately,
unlike testing traditional software [1]–[3], coverage-based
metrics (e.g., basic block, branch/edge, or path coverage)
are ineffective in determining a test case’s effectiveness and
guiding the test generation for swarm robotics because robotics
systems are designed to have a relatively less-diverse control
ﬂow but signiﬁcantly more-diverse data variances at runtime.
To this end, a major challenge in SWARMFLAWFINDER is
to develop a metric for the guided fuzzing process. Inspired
by the idea of counterfactual causality, we propose a new
metric the degree of
the causal contribution (or DCC) to
abstract the causal impact of attack drones on the target swarm.
Speciﬁcally, SWARMFLAWFINDER creates multiple perturbed
executions (i.e., counterfactual executions) to infer the causal-
ity between attack drones and victim drones’ behaviors. Based
on the inferred causality, we build the DCC to reﬂect the attack
drones’ impact on the victim swarm and use DCC to direct
the fuzzing process to accelerate the creation of test cases
covering unexercised swarm behaviors. We evaluate SWARM-
FLAWFINDER using four swarm algorithms [4]–[7], ﬁnding 42
logic ﬂaws that are all conﬁrmed by the algorithm developers.
Our major contributions are summarized as follows:
• We explore the possibility of exploiting swarm algorithms’
logic ﬂaws to cause swarm mission failures, solving various
technical challenges.
• We propose a concept of the degree of the causal contribu-
tion (or DCC), based on the idea of counterfactual causality,
to abstract the impact of attack drones on a swarm operation.
• We develop a greybox fuzz testing system for drone swarm
© 2022, Chijung Jung. Under license to IEEE.
DOI 10.1109/SP46214.2022.00084
1808
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
algorithms called SWARMFLAWFINDER to systematically
discover logic ﬂaws in swarm algorithms. It uses DCC as
a feedback metric for fuzz testing to mutate the test cases.
• SWARMFLAWFINDER identiﬁed 42 previously unknown
logic ﬂaws (all conﬁrmed by the developers) in the four
swarm algorithms, and present analysis results including root
causes and ﬁxes (34 out of 42 ﬁxes are conﬁrmed).
• We publicly release all the developed tools, data, and results,
including SWARMFLAWFINDER, for the community [8].
II. BACKGROUND AND THREAT MODEL
Deﬁnition of Swarm Mission and Algorithm. A swarm
mission requires the following deﬁnitions: (1) the number of
drones in a swarm and (2) the objectives of a swarm mission
(e.g., the destination or goal). Such deﬁnitions can be typically
found in conﬁguration ﬁles, swarm algorithm’s code (i.e.,
hardcoded), or the algorithms’ descriptions (e.g., academic
papers or manuals). A swarm algorithm essentially coordinates
individual drones to conduct the mission’s objectives. In this
paper, we consider the swarm algorithms to include logic for
both individual drones and the swarm’s cooperative behaviors.
Challenges in Testing Swarm Algorithms. A swarm is highly
dynamic. During a swarm mission, even a slight impact in
one of those inputs (caused by the environment or attack
drones) can lead to signiﬁcantly different swarm behaviors. For
instance, assume a moving object is approaching one of the
drones in a swarm. The swarm’s reaction can be signiﬁcantly
different depending on the approaching angle of the object.
Hence, to test swarms effectively, it is desirable to run tests
under diverse scenarios to cover various swarm behaviors.
However, the swarm’s input space (e.g., angles and coordinates
of objects) is often too large to cover them exhaustively in
practice. To mitigate the large input space, one may try to
identify inputs that may exercise a similar swarm behavior
(i.e., an equivalent class of the behavior) and prune out those,
to improve the testing performance. However, it is challenging
to know which inputs exercise a similar swarm behavior.
In typical software testing, coverage-guided fuzzing [9]–
[11] solves a similar challenge by using various code coverage
metrics (e.g., block or edge). It prioritizes the same class of
test inputs that have increased the coverage, aiming to exercise
diverse program behaviors (i.e., covering diverse execution
paths). However, they are not effective in testing robotics
systems because their execution is highly iterative. Even with
a few tests, majority of the code and branches in robotics
systems are quickly covered, while the tests do not cover
diverse behaviors. Unlike testing traditional software systems,
predicate conditions are not the critical challenges in swarm
algorithm testing. Instead, different behaviors are often caused
by different values of inputs and internal states of drones.
Greybox Fuzz Testing Approach. SWARMFLAWFINDER
chooses to use a greybox fuzz testing approach because
other alternatives, whitebox and blackbox approaches, are
not as effective as the greybox approach for testing swarm
algorithms. Speciﬁcally, whitebox approaches [12], [13] often
require expensive analyses (e.g., symbolic analysis) on the
swarm algorithm. Blackbox approaches [14] do not analyze
complex internals of the systems. They rely on correlations
between the inputs and observed outputs which are often too
coarse grained, to decide the test case mutation strategy.
SWARMFLAWFINDER takes the greybox approach, which
monitors an execution (focusing on the poses of drones) to
obtain ﬁner-grained information than the blackbox approaches,
while not requiring expensive analyses.
Efforts in Dependable Swarm Robotics. There is a line
of research on making swarm robotics dependable [15]–[19],
where most of them focus on the modeling of swarms, and
their discussions are at a high level. Speciﬁcally, Winﬁeld et
al. [15] deﬁne two properties of the swarm systems: liveness
(i.e., exhibiting desirable behaviors) and safety (not exhibiting
undesirable behaviors such as crashes). They present theoret-
ical models to prove the two properties, leveraging Lyapunov
theorems [20]. They also discuss difﬁculty in testing such as
the large input space. Higgins et al. [17] present various se-
curity threats to swarm robotics including intrusion of foreign
drones to a swarm, which is the same threat model of us (i.e.,
introducing attack drones to disrupt a swarm). Sargeant and
Tomlinson [16] present models of malicious swarms aiming
to make a victim swarm operation inefﬁcient.
their models are not concrete. For example,
Compared to the above work [15]–[17], we aim to identify
concrete logical ﬂaws from real algorithms via testing. In the
context of [15], SWARMFLAWFINDER can ﬁnd ﬂaws delaying
mission completion and crashing drones in a swarm that can
be considered ‘liveness’ and ‘safety’ violations, respectively.
To the best of our knowledge, SWARMFLAWFINDER advances
state-of-the-art swarm testing, especially in testing efﬁciency
and quality, mitigating the incompleteness of the testing dis-
cussed in [15]. Note that while [17] presents malicious swarm
models,
they
describe high-level classes of threats such as ‘mobility’ and
‘controllability’ issues. Instead, we ﬁnd concrete logic ﬂaws
with root causes. In other words, while some logic ﬂaws we
ﬁnd can relate to [17]’s deﬁnitions (In Table III, C1-5 and
C2-4 can be classiﬁed as mobility and controllability issues,
respectively), all the logic ﬂaws we ﬁnd are previously un-
known, meaning that they are newly discovered. Similarly, [16]
presents an example swarm threat scenario called landmine,
which has a similar objective (i.e., conducting a search) to two
swarm algorithms we evaluate (A2 and A3). We also ﬁnd logic
ﬂaws that slow down a swarm’s progress (See C2-3, C2-4,
C3-1, and C3-2 in Table III). However, [16]’s discussions are
conceptual and all the discovered ﬂaws we ﬁnd are new. Note
that the models in [15]–[17] can be used to deﬁne additional
mission failure criteria for our testing.
Besides, there are groups of researchers conducting in-depth
analysis in designing and modeling swarm algorithms. Taylor
et al. [18] discuss the effectiveness of adding collision avoid-
ance algorithms to existing swarm algorithms. It concludes that
it is recommended to design swarm algorithms with collision
avoidance in mind, rather than adding the collision avoidance
algorithm later. In our paper, all the four evaluated algorithms
are designed with collision avoidance in mind (i.e., we do
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:51 UTC from IEEE Xplore.  Restrictions apply. 
21809
not observe a clear separation of the collision avoidance logic
from swarm algorithms). Hamann et al. [19] model swarm
robotics using statistical physics, showing that their models are
effective. Our work focuses on ﬁnding concrete logic ﬂaws in
a concrete implementation of an algorithm, which is difﬁcult
to achieve with the modeling approach.
Threat Model. We assume an adversary knows the target
swarm mission and its swarm algorithm and can launch
external attack drones to thwart the target swarm operation.
However, the adversary does not have access to the target
drone’s device, hence cannot compromise the drone’s soft-
ware/hardware. The adversary prefers subtle attacks that do not
make physical contact (e.g., crashing into the victim drones)
due to its economic beneﬁt and subtleness. Note that a naive
crashing attack is not practical and scalable for a large-scale
swarm mission since crashed attack drones are not reusable
by the adversary, limiting the attack capability.
We target autonomous swarm algorithms and do not target
human-controlled swarms. If a swarm is a mixture of human
and autonomous control, we target the part of the swarm
with autonomous control. In practice, autonomous control is
required in many cases, such as conducting a long-distance
mission covering areas without communication infrastructure
(e.g., military mission) or a large-scale swarm mission (e.g., a