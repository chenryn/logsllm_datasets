# The Hacker Pimps and The Hexagon Security Group

## Creating Unreliable Systems
**"Attacking the Systems that Attack You"**
- **Presenters:** Sysmin Sys73m47ic & Marklar

### Document Versioning
- For a copy of this presentation, visit: [www.hackerpimps.com/docs.html](http://www.hackerpimps.com/docs.html)

### Important Notice
- **Warning:** Some of the techniques discussed in this presentation can be hazardous to your personal freedoms, particularly in terms of avoiding legal consequences. 
- **Disclaimer:** Everything discussed in this presentation is strictly theoretical.

## Why Create Unreliable Systems?
- **Question:** Isn't creating unreliable systems the opposite of what we are supposed to do? Don't people get paid to make systems reliable?
- **Answer:** Unreliable systems cannot be counted on, which can serve specific purposes in certain contexts.

## Technology Changes Everything
- We face new technology, not new problems.
- There is a tendency to accept the loss of privacy for convenience.
- Companies and governments are finding increasingly sophisticated ways to collect information.

## Presumptive Right to Privacy
- **Question:** Why not presume the right/need for privacy?
- **Common Excuse:** "I've got nothing to hide!"
- This attitude often comes from those who are not marginalized.

### Who Needs Privacy?
- People in great pain and unable to manage it legally.
- LGBTQ+ individuals in the military.
- Those needing to express unpopular views that could risk their safety.
- Whistleblowers.
- Security researchers.

## Who is Watching?
- **Statement:** "I don't care that X is watching me. I'm not doing anything wrong!"
- **Considerations:** Who might X be?
  - The Executive Branch
  - The Other Executive Branch
  - The Imaginary Judicial Branch
  - The Other Imaginary Judicial Branch
  - The No Such Branch (The Branch Which Must-Not-Be-Named)
  - Your Bad Neighbor
  - Your Nosy Neighbor
  - Your Good Neighbor

## Targeting Information Gathering Systems
- **Question:** What Information Gathering System provides the most comprehensive aggregate of what you are thinking about?
- **Example:** Web Search

### Web Search Privacy
- **Information Collected:**
  - IP Address
  - Cookies
  - Sessions
  - Browser Add-ons/Components
  - Flash/Java/JavaScript, etc. (The Interactive Web!)

### Dilemma
- The features that make the web useful are often potentially invasive.

### Proposed Architecture for Web Search Privacy
1. **Existing Solution: Tor + TorButton**
   - Summary: Hide your IP Address
2. **Proposed “Quiet” Button**
   - Turn off automatic search completion (automatic with Tor)
   - Block access to cookies: use/keep cookies but make them inaccessible on demand
   - Alternatively, use the imilly.com Google cookie anonymizer (but consider other search engines)
3. **Proposed Plugin: P2P Web Search Identity Diffusion**
   - On demand, hide in a crowd
   - A Nifty, Helpful, Insufficient Idea

#### P2P Identity Diffusion
- When you do a web search:
  1. N (e.g., 30) instances of the query terms are put on P2P.
  2. The plugin downloads N queries from P2P.
  3. Both steps are executed through Tor, hiding your IP address.
  4. The N searches are executed in the background.
  5. The original search is executed after a random number of P2P queries are executed.
  6. User-Agent is modified to indicate P2P Search.
- **Summary:** The origin of an individual query will still diffuse among N browsers.

### Why Insufficient?
- **Aggregates and Standing Out:**
  - Aggregated data can still reveal patterns.
  - Changing models can affect how data is interpreted.
- **Google Analytics Examples:**
  - Sheep Sex
  - Goatse
  - Stocks
  - Terror, Terrorists, and Terrorism

### The Point
1. **Wake Up!** It's not like they say on the news.
2. **Diffusing a Query Source:**
   - Is insufficient until N is sufficiently large to smooth your graph down into the aggregate picture.

### Privacy and Changing Models
- **Keywords:**
  - Privacy
  - Bill of Rights
  - Strict Constructionists
  - The Eighth Amendment

### Google and Changing Models
- **A Change of Focus:**
  - We spend a lot of time worrying about people knowing who we are or where we connect from.
  - The larger problem is people knowing what we are, which is the ultimate goal of collection technologies.

### Who You Are
- **Identity and Associated Items:**
  - Name
  - Address
  - SSN
  - Phone Number
  - Etc.

### What You Are
- **Personal Characteristics:**
  - Gender
  - Race
  - Religious Beliefs
  - Sexual Orientation
  - Medical Conditions
  - Mental Health
  - Veteran Status
  - Behavioral Patterns (e.g., Porn Addiction, Compulsive Behaviors)

### Who and What
- Combining both "who" and "what" can create a detailed and potentially dangerous profile.

### Collected Data
- **Dangers:**
  - Can be sold.
  - Can be misused (e.g., government files).
  - Incorrect assumptions can be made.
  - Inaccuracies may be impossible to correct.
- **Sources:**
  - Aggregates
  - Inference

### Aggregated Data
- **Definition:** Data collected from multiple sources to obtain a more complete picture.
- **Example:** Shopping habits (Credit Card, Grocery Rewards, Mailing Lists).

### Inferred Data
- **Definition:** An inference made from collected data.
- **Accuracy:** Often less accurate than aggregated data.
- **Examples:**
  - Buying Sudafed and being assumed to cook Meth.
  - Driving through bad parts of town and being assumed to buy drugs.

### A Step Further
- **Profile Creation:**
  - Profiles based on collected and inferred data can lead to incorrect and harmful assumptions.
  - **Example:** Statistics showing increased likelihood of violence or domestic abuse based on behavior and health conditions.

### Eating Your Own Cake
- **Sharing Information:**
  - Freely sharing information on social networks, blogs, public resumes, and CVs can compromise privacy.
  - Even using an alias can be risky.
- **Recommendation:** Decide what you want people to know and make it public.

### Recognition Technologies
- **Traditional Biometrics:**
  - Linguistics and web habits.
  - Microsoft is working on technology to identify you through web habits.
- **Impact:** Widespread use could make it difficult to correct inaccuracies.

### Scary S#!7
- **Future Concerns:**
  - Personal information is big business.
  - Computers need to learn to forget (Viktor Mayer-Schönberger, *Useful Void: The Art of Forgetting in the Age of Ubiquitous Computing*).
  - Freedom of speech is also affected.

### Future Connected Technologies
- **Connected Homes:**
  - Future homes will likely become a hotbed for embedded spyware.
  - Connected devices and appliances will collect information.
- **User Agreements:**
  - We freely give away our rights when we agree to user agreements.
  - Refusing to use these items or viewing them as researchers can help protect our information.

### System Models
- **Basic Model:**
  - Input – Processing – Output
- **Expanded Model:**
  - Method
  - Storage
  - Who does the output go to

### Analyzing These Systems
- **First Step:** Analysis is the first step to mitigating the effects of these systems.