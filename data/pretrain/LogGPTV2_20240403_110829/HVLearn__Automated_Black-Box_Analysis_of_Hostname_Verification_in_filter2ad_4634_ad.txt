### HttpClient with PublicSuffixMatcher
For RFC Violation: 
-  = OK
-  = RFC violate
- – = libs/apps do not support

For Discrepancies:
-  = Accept
-  = Reject

### Number of Unique Differences Between Automata Inferred from Different SSL/TLS Implementations
**Table III**

| SSL/TLS Implementation | Unique Differences |
|------------------------|--------------------|
| OpenSSL                | 95                 |
| GnuTLS                 | 6                  |
| MbedTLS                | 38, 44             |
| MatrixSSL              | 25, 69             |
| JSSE                   | 127, 97, 37        |
| CPython                | 214, 220, 58, 177, 108 |
| HttpClient             | 56, 50, 94, 110, 54, 414 |

### Code Coverage Comparison
**Figure 4.** Comparison of code coverage achieved by HVLearn, gray-box fuzzing, and black-box fuzzing for OpenSSL hostname verification.

- **HVLearn**: 11.21% increase in code coverage on average compared to black/gray-box fuzzing techniques.
- **Code Coverage Calculation**:
  - \( \text{Coverage} = \frac{\sum_{i=1}^{m} \text{LE}(f_i)}{\sum_{i=1}^{m} L(f_i)} \)
  - Where \( f_1, f_2, \ldots, f_m \) are the functions relevant to hostname verification.

### Automata Learning Performance

#### RQ.2: How does the alphabet size affect HVLearn’s performance in practice?
**Figure 5.** Number of queries required to learn an automaton with different alphabet sizes (with Wp-method depth=1 and equivalence query optimization).

- **Experiment Setup**:
  - Default configuration with all optimizations enabled.
  - Wp-method depth set to 1.
  - CPython's SSL implementation used for hostname verification.
- **Results**:
  - Starting from an alphabet size of 9, each additional character increases the number of queries by at least 10%.
  - Increasing the alphabet size from 2 to 5 results in a 7x increase in running time.

**Result 2**: Adding just one symbol in the alphabet set incurs at least a 10% increase in the number of queries. Thus, the succinct alphabet set utilized by HVLearn is crucial for the system’s performance.

#### RQ.3: Does membership cache improve the performance of HVLearn?
**Table IV.** Number of queries required to infer a model for the certificate template with common name “*.aaa.aaa” with and without utilizing a membership query cache over different alphabet sizes.

| Alphabet Size | Without Cache | With Cache | Improvement |
|---------------|---------------|------------|-------------|
| 2             | 883           | 90         | 89.8%       |
| 5             | 3,049         | 1,146      | 62.4%       |
| 7             | 5,163         | 2,520      | 51.2%       |
| 10            | 9,339         | 5,586      | 40.2%       |
| 15            | 18,979        | 13,376     | 29.5%       |

- **Average Time (sec)**:
  - Without Cache: 3.10, 21.61, 42.24, 86.92, 196.35
  - With Cache: 90, 1,146, 2,520, 5,586, 13,376

**Result 3**: Membership cache offers, on average, a 42% decrease in the number of membership queries made by the learning algorithm.

#### RQ.4: How does Wp-method’s depth parameter affect HVLearn’s performance and accuracy?
**Figure 6.** The number of queries needed to learn the DFA model of CPython certificate verification for different Wp-method depth values (without equivalence query optimization).

- **Experiment Setup**:
  - Evaluated the impact of the Wp-method depth parameter.
- **Results**:
  - The number of queries performed by the Wp-method is exponential on the customizable depth parameter.
  - The cache consistently helps to reduce the number of membership queries required to infer a model.

**Result 4**: The Wp-method depth parameter significantly affects the number of queries and the overall performance of HVLearn.