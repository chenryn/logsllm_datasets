







































HttpClient*: HttpClient with PublicSuffixMatcher
For RFC Violation: = OK, = RFC violate, – = libs/apps do not support • For Discrepancies: = Accept, = Reject
NUMBER OF UNIQUE DIFFERENCES BETWEEN AUTOMATA INFERRED FROM
DIFFERENT SSL/TLS IMPLEMENTATIONS
TABLE III
L
S
S
n
e
p
O
–
–
–
–
–
–
–
–
S
L
T
u
n
G
95
–
–
–
–
–
–
–
S
L
T
d
e
b
M
98
6
–
–
–
–
–
–
L
S
S
x
i
r
t
a
M
99
38
44
–
–
–
–
–
n
o
h
t
y
P
C
92
34
28
25
69
–
–
–
E
S
S
J
282
127
97
37
–
–
–
–
t
n
e
i
l
C
p
t
t
H
482
214
220
58
177
108
–
–
l
r
u
C
187
56
50
94
110
54
414
–
OpenSSL
GnuTLS
MbedTLS
MatrixSSL
JSSE
CPython
HttpClient
Curl
e
g
a
r
e
v
o
c
e
n
i
l
f
o
%
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
HVLearn
Coverage-guided gray-box fuzzing
Blackbox fuzzing
 0
 10000  20000  30000  40000  50000
Number of queries
Fig. 4. Comparison of code coverage achieved by HVLearn, gray-box fuzzing,
and black-box fuzzing for OpenSSL hostname veriﬁcation.
functions SSL/TLS implementations. Note that we keep the
test certiﬁcate template ﬁxed during the entire test.
We use the percentage of lines executed, which are extracted
by Gcov [51], as the indicator for the code coverage. Consider-
ing that hostname veriﬁcation is a small part of an SSL/TLS
implementation, we do not compute the percentage of lines
covered with respect to the total number of lines. Instead, we
calculate the percentage of line coverage within each function
and only take into account the functions that are related to
hostname veriﬁcation.
Result 1: HVLearn achieves 11.21% increase in code
coverage on average when comparing to the black/gray-
box fuzzing techniques.
Therefore, let LE(f) be the number of lines executed of
function f in the SI and L(f) be the total number of lines
of f, the code coverage can be deﬁned in the following equa-
530
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:25 UTC from IEEE Xplore.  Restrictions apply. 
(cid:2)m
(cid:2)m
i=1 LE(fi)
i=1 L(fi) , where f1, f2,··· , fm are the
tion: coverage =
functions that are relevant to hostname veriﬁcation. Figure 4
illustrates the code coverage comparison, which shows that
HVLearn achieves signiﬁcantly better code coverage compared
to the black/gray-box fuzzing techniques.
E. Automata learning performance
HVLearn is largely based on the KV algorithm and the
Wp-method in order to perform its analysis. It is therefore
crucial to thoroughly evaluate the different parameters of these
algorithms and their impact on the performance of HVLearn.
We will now evaluate the effect of each different parameter
of the learning algorithms in the overall performance of
HVLearn.
RQ.2: How does the alphabet size affect HVLearn’s perfor-
mance in practice?
s
e
i
r
e
u
q
f
o
r
e
b
m
u
N
 35000
 30000
 25000
 20000
 15000
 10000
 5000
*.google.com
twitter.com
9
10
11
12
13
14
Alphabet size
Fig. 5. Number of queries required to learn an automaton with different
alphabet sizes (with Wp-method depth=1 and equivalence query optimization).
HVLEARN PERFORMANCE FOR COMMON NAME *.A A A.A A A WITH
WP-METHOD DEPTH=1 (CPYTHON SSL IMPLEMENTATION)
TABLE IV
As discussed in Section III-C, the alphabet size impacts
the performance of our system. In theory, the performance of
both the KV algorithm and the Wp-method, depends on the
size of the input alphabet. We perform two experiments for
evaluating the extent to which the alphabet size affects the
performance of our learning algorithm component in practice.
In the ﬁrst experiment, we evaluate the effect of increasing
the size of the alphabet in real world DNS names. For this
experiment, we used our system in the default conﬁguration
with all optimizations (e.g., query cache and EQ optimizations)
enabled and we set the Wp-method depth to 1. We used the
CPython’s SSL implementation as the hostname veriﬁcation
function for these experiments.
Figure 5 shows the results of our experiment. Notice that,
starting from an alphabet size of 9, each additional character
we include in the alphabet will cause the learning algorithm
to perform at least 10% more queries in order to produce a
model, for both DNS names, while this percentage is only
increasing when in larger alphabet sizes.
We also measure the effect of increasing the alphabet size
on the overall running time of our system. To perform this
experiment we used the same setup as our previous experiment
and evaluated the performance of HVLearn with a certiﬁcate
containing the common name “*.aaa.aaa”. Table IV shows
the results of this experiment. We notice that the increase
in the membership queries directly translates in an increased
running time. Speciﬁcally, by adding 5 additional characters
in the alphabet (from 2 to 5), we notice that the running time
increases 7 times. Similar results can be observed when we
add more characters in the alphabet set.
Result 2: Adding just one symbol in the alphabet set
incurs at least 10% increase in the number of queries.
Thus, the succinct alphabet set utilized by HVLearn is
crucial for the system’s performance.
RQ.3: Does membership cache improve the performance of
HVLearn?
Table IV presents the number of queries required to infer
a model for the certiﬁcate template with common name
531
Alphabet
Size
2
5
7
10
15
W/o Cache
#Queries
Total
883
3,049
5,163
9,339
18,979
Total Membership
226
1,582
3,156
6,522
14,812
136
436
636
936
1,436
2
2
2
2
2
With Cache
#Queries
Equivalence
Counterexample Membership
Average
Time
(sec)
3.10
21.61
42.24
86.92
196.35
90
1,146
2,520
5,586
13,376
s
e
i
r
e
u
q
f
o
r
e
b
m
u
N
 120000
 100000
 80000
 60000
 40000
 20000
 0
(n): n inferred states
(11)
(11)
(11)
(1)
(1)
(1)
(1)
(1)
(1)
(1)
 1
 2
 3
 4
 5
 6
 7
 8
 9  10
WP-method depth
Fig. 6. The number of queries needed to learn the DFA model of CPython
certiﬁcate veriﬁcation for different Wp-method depth values (without equiv-
alence query optimization).
“*.aaa.aaa” with and without utilizing a membership query
cache over different alphabet sizes. We notice that the cache
is consistently helping to reduce the number of membership
queries required to infer a model. Overall,
the cache is
reducing the number of queries by 42%, thus signiﬁcantly
improving the efﬁciency of our system. Therefore, for the rest
of the experiments in this section, we utilize our system with
the membership query cache enabled.
Result 3: Membership cache is offering, on average,
a 42% decrease on the number of membership queries
made by the learning algorithm.
RQ.4: How does Wp-method’s depth parameter affect
HVLearn’s performance and accuracy?
As discussed in Section IV-D, the number of queries per-
formed by the Wp-method is exponential on the customizable
depth parameter. We evaluated how this exponential term is
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:25 UTC from IEEE Xplore.  Restrictions apply. 
affecting the number of queries in practice and moreover, what