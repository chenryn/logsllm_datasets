# A Method for Identifying and Confirming the Use of URL Filtering Products for Censorship

## Authors
Jakub Dalek, Bennett Haselton, Helmi Noman, Adam Senft, Masashi Crete-Nishihata, Phillipa Gill, Ronald J. Deibert

### Affiliations
- The Citizen Lab, University of Toronto
- Dept. of Computer Science, Stony Brook University

## Abstract
URL filtering products, designed to manage network traffic and restrict access to web content, are dual-use technologies. While they aim to enhance performance and protect users from inappropriate content, these products are also employed by authoritarian regimes for web censorship. This dual use has prompted Western governments to impose export restrictions on such technologies.

Our research introduces methods to identify and confirm the use of URL filtering products for censorship. We present a methodology to detect externally visible installations of URL filtering products in ISPs globally. Additionally, we leverage the fact that many of these products accept user-submitted sites for blocking to verify their use for censorship. Using this approach, we confirmed the use of McAfee SmartFilter in Saudi Arabia and the United Arab Emirates (UAE) and Netsweeper in Qatar, the UAE, and Yemen. Our findings indicate that these products are used to block a variety of content, including oppositional political speech, religious discussions, and LGBTQ+ material, which are generally protected under international human rights norms.

**Categories and Subject Descriptors:**
- C.2.2 [Computer-Communication Networks]: Network Protocols

**General Terms:**
- Measurement

**Keywords:**
- Censorship, Network Measurement, URL Filtering

## 1. Introduction
URL filtering products, widely used for managing web traffic and restricting content access, are common in corporate, educational, and ISP networks worldwide. These technologies, designed to improve performance and filter inappropriate content, represent a dual-use technology. Reports have documented instances where URL filtering products, produced by Western companies, are sold to countries with poor human rights records and used for censorship and surveillance. This raises significant legal and ethical concerns.

In recent years, the United States, Europe, and Israel have taken steps to limit the export of these technologies to sanctioned countries like Syria and Iran. As part of the OpenNet Initiative (ONI), we have documented numerous cases over the past decade where Western-developed products are used to restrict online freedom of speech and potentially for surveillance.

Given the high stakes, it is crucial to develop techniques for monitoring the use of specific technologies for censorship. These tools can inform policymakers and vendors, who may be unaware of the misuse of their technology. For example, Websense withdrew software update support after ONI informed them that their technology was being used for censorship in Yemen.

### Challenges in Measuring URL Filtering Deployments
Measuring URL filtering products is challenging due to the difficulty of observing censorship without vantage points within the country of interest. Through ONI, we have gained access to measurements from many countries with restrictive filtering regimes. However, client-based measurements in some countries (e.g., Cuba, North Korea) are too risky, limiting our global coverage. Identifying specific URL filtering product installations requires understanding distinct properties and careful validation to avoid false positives. Even if a product is installed, it does not necessarily mean it is used for censorship or surveillance.

### Our Contribution
We developed a simple, repeatable methodology to identify and confirm the use of URL filtering products for censorship. Our method for identifying URL filter installations (Section 3) helps locate installations where we can apply our confirmation methodology (Section 4). The identification method relies on the observation that some URL filter installations are visible on the global Internet, likely due to inexperienced network administrators. We developed methodologies to locate these externally visible IPs and verify that they host the suspected product and are used for censorship.

Our study highlights the human rights implications of these products and provides ground truth for web proxy fingerprinting. We observe the use of these products in multiple North American ISPs, raising issues about global monitoring. We also highlight the challenges in characterizing their use, such as inconsistent blocking and the use of multiple products. Finally, we demonstrate our method by confirming the use of Netsweeper and McAfee SmartFilter for censoring content in Qatar, Saudi Arabia, the UAE, and Yemen.

### Limitations
Our methodology for identifying URL filtering product installations requires that these installations be visible on the global Internet, suggesting that they are not maintained by technically sophisticated administrators. Additionally, our method is not robust to products that attempt to evade profiling. Therefore, our results should be considered a high-confidence subset of URL filter deployments. We discuss these limitations in Section 6.

## 2. Background

### 2.1 URL Filtering Products
URL filtering systems typically include a database of pre-categorized URLs, allowing network operators to configure which categories to block. They may also include custom category creation and subscription components for updating the database. Depending on the functionality, these products can be sold as software or as standalone middleboxes. Table 1 summarizes the products we consider.

### 2.2 Prior Work by the OpenNet Initiative
The OpenNet Initiative has studied internet censorship for the past decade, documenting the use of Western-developed products for censorship by repressive regimes. Initially, we identified products through manual analysis of block pages and HTTP headers. Over time, vendors have obscured their product use, leading us to develop novel techniques for confirmation. This paper expands on these efforts by describing how we identify networks containing URL filter installations and confirm their use for censorship.

### Policy Impacts
Our efforts have had mixed policy impacts. In 2009, our identification of Websense in Yemen led to the vendor discontinuing support. Conversely, Netsweeper stated that aiding foreign governments in implementing internet censorship is not against their policies. Blue Coat has withdrawn update support from Syria due to legal sanctions but continues to play a role in internet censorship globally. Our goal is to present a repeatable methodology for identifying and confirming the use of these products for censorship to inform future discussions with vendors and policymakers.

## 3. Identifying URL Filters
We present a methodology to identify installations of URL filtering products. Previously, we relied on user reports, but as vendors remove branding, non-technical users find it harder to identify these products. Our new method does not depend on user reports and is more scalable, examining HTTP headers and web directory structures for evidence of filtering installations.

### 3.1 Methodology
Our methodology leverages the observation that URL filtering products are sometimes configured to be visible on the global Internet. We use the Shodan search engine to locate IP addresses and manually analyze results to identify commonly appearing keywords and headers for the products (Table 2). We search for these keywords, combined with two-letter country-code top-level domains, to maximize results from Shodan.

#### Validating URL Filter Installations
When locating IP addresses, we use the WhatWeb tool to confirm that the identified host indeed runs the suspected product. This step ensures the accuracy of our findings.

## 4. Confirming the Use of URL Filters for Censorship
To confirm the use of URL filters for censorship, we leverage the fact that many products accept user-submitted sites for blocking. By submitting test sites and checking if they are blocked, we can verify the product's use for censorship. This method has been effective in confirming the use of specific products in various countries.

## 5. Case Studies
We applied our methodology to confirm the use of Netsweeper and McAfee SmartFilter for censorship in Qatar, Saudi Arabia, the UAE, and Yemen. Our findings show that these products are used to block a range of content, including oppositional political speech, religious discussions, and LGBTQ+ material, which are generally protected under international human rights norms.

## 6. Limitations and Future Work
Our methodology has limitations, primarily that it requires installations to be visible on the global Internet and is not robust to products that attempt to evade profiling. Future work will focus on improving the robustness and scalability of our methods to provide a more comprehensive view of URL filtering product deployments.

## Conclusion
Our research presents a repeatable and scalable methodology for identifying and confirming the use of URL filtering products for censorship. This work highlights the human rights implications of these products and provides valuable insights for policymakers and vendors.