### Describe the workflow you want to enable
SimpleImputer.strategy = 'random' will randomly choose a non-NaN value.
### Describe your proposed solution
Find a list of non-NaN indices. Randomly pick one index for each NaN.
### Describe alternatives you've considered, if relevant
Pandas:
    # Impute missing NaN values by randomly selecting a non-NaN value
    for column in df.columns:
        nan_indexes = df[df[column].isna()].index
        non_nan_values = df[column].dropna().tolist()
        imputed_values = [random.choice(non_nan_values) for _ in range(len(nan_indexes))]
        df.loc[nan_indexes, column] = imputed_values
### Additional context
Let's say you're in the following setting:
GOAL: Iteratively tighten a hyperparameter grid.
  * You have a broad hyperparameter grid
  * Some hyperparameter choices disable (i.e. make NaN) other hyperparameter choices.
  * You do random selection of grid points and get the loss.
  * You make _isnan a value, true or false, for params that can be NaN.
  * You impute the missing values for NaNs.
  * You use decision tree regression to figure out what hyperparameter choices are best.  
You tighten your grid iteratively using the above.
However, one downside is that some of the splits will be misleading, if they
involved imputed NaNs. (The split on this hyperparameter value could suggest a
particular threshold OR that the governing hyperparameter that created this
NaN is important.) A way to reduce this confusion is using random choice when
imputing.