We can make use of this command by running it before our task that loads the data. We can
ignore any errors from the command, and instead register them in a variable. We use this to
conditionally run the data load, loading it only if an error occurred (this is the instance
where the database does not exist, and so it is safe to load the data).
The copy task remains the same, but the tail end of the tasks now looks like this:
- name: Check to see if the database exists
shell: "mysqlshow -u root --password={{ mariadb_root_password }}
employees"
ignore_errors: true
register: dbexists
- name: Load sample data into database
shell: "mysql -u root --password={{ mariadb_root_password }} 
{{ db_filename }}"
3. The fetch module is then used to retrieve the data for archiving—fetch works
just like the copy module that we used earlier in this section, except that it copies
data in the reverse direction (that is, from the inventory host to the Ansible
server). Run the following code:
- name: Copy the backed up data for archival
fetch:
src: "{{ db_filename }}"
dest: "/backup"
[ 316 ]
Database Management Chapter 11
4. Running this in the usual manner results in a complete backup of the database,
with the resulting file being copied to our Ansible server, as the following
screenshot shows:
This example could also be achieved using the mysql_db module, just as we did
before—the set_fact and fetch tasks remain exactly the same, while the shell task is
replaced with the following code:
- name: Back up the database
mysql_db:
state: dump
name: all
target: "{{ db_filename }}"
login_user: root
login_password: "{{ mariadb_root_password }}"
Thus, Ansible can assist you both with loading data into your databases and backing it up.
As we have discussed previously, it is generally better to use the native Ansible modules
(such as mysql_db) where they are available, but, provided you apply the correct logic to
it, the shell module can assist you, if native modules don't exist or provide the
functionality you need.
Now that we have considered the process of creating databases and loading data into them,
we will proceed in the next section to demonstrate how to build on this work, to perform
routine database maintenance with Ansible.
[ 317 ]
Database Management Chapter 11
Performing routine maintenance
Loading schemas and/or data is not the only task you would perform with Ansible on a
database. Sometimes, manual intervention is required in a database. For example,
PostgreSQL requires VACUUM operations from time to time, to free up unused space in
the database. MariaDB has a maintenance tool called mysqlcheck that can be used to
verify the integrity of tables and perform optimization. Each platform will have its own
specific tools for maintenance operations, and it is up to you to establish the best practices
for database maintenance on your chosen platform. Furthermore, sometimes it is necessary
to make simple changes to a database. For example, it might be necessary to delete (or
update) a row from a table, to clear an error situation that has occurred in an application.
Of course, all these activities could be performed manually—however, this (as always)
brings about the risk of losing track of what happened, who ran a task, and how they ran it
(for example, which options were provided). If we move this example into the world of
Ansible and AWX, suddenly we have a complete audit trail of activities, and we know
exactly what was run and how it was run. Furthermore, if special options are required for a
task, these will be stored within the playbooks, and thus the self-documentation that Ansible
provides is available here too.
As our examples thus far have been very MariaDB-centric, let's take a look at how you
might run a full vacuum on a table in PostgreSQL, with Ansible.
Routine maintenance on PostgreSQL with
Ansible
PostgreSQL is something of a special case on Ansible, as it has more native modules to
support database activities than most other databases. Let's consider an example case:
performing a vacuum on the sales.creditcard table in the publicly available
AdventureWorks sample database (available here: https:/​/​github.​com/​lorint/
AdventureWorks-​for-​Postgres).
Vacuuming is a PostgreSQL-specific maintenance process and one that
you might want to consider running on a regular basis, especially if your
tables have a lot of deletes or modifications. Although a full discussion of
this is beyond the scope of this book, it is important to consider that tables
that are subject to these activities can become bloated in size and queries
can become slow over time, and vacuuming is a way to release unused
space and speed up queries again.
[ 318 ]
Database Management Chapter 11
Now, to perform a vacuum on this table by hand, you would log in to the psql client utility
with appropriate credentials, and then run the following commands to connect to the
database and perform the task:
postgres=# \c AdventureWorks
AdventureWorks=# vacuum full sales.creditcard;
In a real enterprise, this would be a task that encompasses many more tables, and even
databases, but here, we will once again keep the example simple, to demonstrate the
principles involved. Scaling this up is then left as a task for you to perform. Let's automate
this, first of all using the shell module in Ansible. This is a useful example, as this
technique will work with most major databases—simply, you must establish the command
needed for your particular maintenance operation, and then run it.
A simple role to perform this task would look like this:
---
- name: Perform a VACUUM on the sales.credit_card table
shell: psql -c "VACUUM FULL sales.creditcard" AdventureWorks
become: yes
become_user: postgres
Note—as before—very simple use of the shell module with the appropriate command,
except that, this time, we are using the become_user parameter to switch to the postgres
user account, which has superuser rights on the database on the host to which we connect.
Let's see what happens when we run this, as follows:
[ 319 ]
Database Management Chapter 11
Naturally, this could be scaled to just about any other database—for example, you could
use the mysql client tool on a MariaDB database, or even run the mysqlcheck tool, as
discussed earlier. The limit really is on what you can script for the shell module to run,
and because Ansible runs the command over SSH on the database server itself, you don't
need to worry about opening up your database for access across the network—it can
remain tightly locked down.
In addition to using the shell module, Ansible offers us the option to actually run queries
directly from a module called postgresql_query. This is unique, though such support
could be added for any other database if someone was willing to write the module and
submit it.
Unfortunately for Ansible versions prior to 2.9, it was not possible to extend our VACUUM
example to this as the postgresql_query module runs transactions inside a block, and it
is not possible to run a VACUUM inside a transaction block. If you are running version 2.9
or later, you can now run a VACUUM using example code, as shown here:
---
- name: Perform a VACUUM on the sales.credit_card table
postgresql_query:
db: AdventureWorks
query: VACUUM sales.creditcard
autocommit: yes
become_user: postgres
become: yes
By way of another simple example, we could also use the postgresql_query module to
directly manipulate the database.
Suppose that a bug in the application using this database has occurred, and an operator
must manually insert a credit card number into the database. The SQL code to perform this
might look something like this:
INSERT INTO sales.creditcard ( creditcardid, cardtype, cardnumber,
expmonth, expyear ) VALUES ( 0, 'Visa', '0000000000000000', '11', '2019' );
[ 320 ]
Database Management Chapter 11
We could achieve the same end result in Ansible, using a role that looks like the following:
---
- name: Manually insert data into the creditcard table
postgresql_query:
db: AdventureWorks
query: INSERT INTO sales.creditcard ( creditcardid, cardtype,
cardnumber, expmonth, expyear ) VALUES ( 0, 'Visa', '0000000000000000',
'11', '2019' );
become_user: postgres
become: yes
Naturally, you would use variables for the data values, and sensitive data like this should
always be stored in a vault (or, perhaps, entered by hand when the role is run).
AWX has a feature called Surveys, which presents the user with a series
of predefined questions to answer before a playbook is run. The answers
to these questions are stored in Ansible variables— thus, a role such as the
preceding one could be parameterized, and run from AWX with all the
values entered into a Survey, negating the need for a vault and concerns
over sensitive customer data being stored in Ansible.
As you can see here, when we run this role, we actually get a changed status when the
INSERT operation is successful—very useful for monitoring such tasks and ensuring they
have run as desired. The following screenshot shows this role being run, and the changed
status, denoting the successful insertion of data into the sales.creditcard table:
[ 321 ]
Database Management Chapter 11
The world really is your oyster when it comes to database management with Ansible, and,
regardless of the task required, it is desirable that all database tasks be handled in a
standardized, repeatable, and auditable manner, just like the rest of your Enterprise Linux
estate. It is hoped that this chapter has gone some way in showing you how to achieve this.
Summary
Databases are a core part of the application stack in most enterprises, and there is a
multitude of databases available on the Linux platform. Although many databases have
their own management tools, Ansible is well suited to assist with a wide array of database
management tasks, from the installation of database services and loading of initial data or
schemas (or even restoring from backups) to handling day-to-day maintenance tasks.
Combining Ansible's error handling and secure automation, there is virtually no limit to the
types of database management tasks you can perform with Ansible.
In this chapter, you learned how to use Ansible to install database servers in a consistent
and repeatable manner. You then learned how to import initial data and schemas, and how
to extend this to automate backup tasks. Finally, you gained hands-on knowledge of some
routine database maintenance tasks with Ansible.
In the next chapter, we will look at how Ansible can assist with the task of routine
maintenance on your Linux servers.
Questions
1. Why is it prudent to install and manage your database platform with Ansible?
2. What are the best practices for database configuration file management with
Ansible?
3. How can Ansible help you keep your database secure on the network?
4. When would you use the shell module instead of a native database module in
Ansible?
5. Why would you want to perform routine maintenance with Ansible?
6. How would you perform a PostgreSQL database backup with Ansible?
7. Which module would you use to manipulate the users on a MariaDB database?
8. How is PostgreSQL support unique in Ansible at the present time?
[ 322 ]