title:Automating the debugging of datacenter applications with ADDA
author:Cristian Zamfir and
Gautam Altekar and
Ion Stoica
Automating the Debugging of Datacenter Applications with ADDA
Cristian Zamﬁr∗
∗ School of Computer and Communication Sciences
· Gautam Altekar† · Ion Stoica† ·
École Polytechnique Fédérale de Lausanne (EPFL), Switzerland
Email: cristian.zamﬁr@epﬂ.ch
† University of California, Berkeley
Email: {galtekar, istoica}@eecs.berkeley.edu
Abstract—Debugging data-intensive distributed appli-
cations running in datacenters is complex and time-
consuming because developers do not have practical ways
of deterministically replaying failed executions. The reason
why building such tools is hard is that non-determinism
that may be tolerable on a single node is exacerbated in
large clusters of interacting nodes, and datacenter appli-
cations produce terabytes of intermediate data exchanged
by nodes, thus making full input recording infeasible.
We present ADDA, a replay-debugging system for
datacenters that has lower recording and storage overhead
than existing systems. ADDA is based on two tech-
niques: First, ADDA provides control plane determinism,
leveraging our observation that many typical datacenter
applications consist of a separate “control plane” and
“data plane”, and most bugs reside in the former. Second,
ADDA does not record “data plane” inputs, instead it
synthesizes them during replay, starting from the appli-
cation’s external inputs, which are typically persisted in
append-only storage for reasons unrelated to debugging.
We evaluate ADDA and show that it deterministically
replays real-world failures in Hypertable and Memcached.
Keywords—debugging; record-replay; reliability; data-
center; storage;
I.
INTRODUCTION
More and more applications that we use on a daily
basis, such as Web search, e-mail, social networks, and
video sharing are hosted in the cloud. Furthermore,
many businesses either use cloud-based services such
as Salesforce and Google Docs, or deploy their applica-
tions in private clouds. These services often use cluster
computing frameworks such as MapReduce, BigTable,
and Memcached that run on commodity hardware clus-
ters consisting of as many as thousands of machines.
As users are growing more dependent on these hosted
services, the frameworks and applications employed by
the services need to be highly robust and available. To
maintain high availability, it is critical to diagnose the
failures and quickly debug these applications.
Unfortunately, debugging datacenter applications is
hard. When an application failure occurs, the causality
chain of the failure is often difﬁcult to trace, as it may
span many nodes. Moreover, such applications typically
operate on many terabytes of data daily and are required
to maintain high throughput, which makes it hard to
record for potential later debugging what they do.
A cluster-wide replay-based solution is the natural
option for debugging, as it offers developers the global
view of the application: by deterministically replaying
a previously-encountered failure, one can use a debug-
ger to zoom in on various parts of the system and
understand why the failure occurred. If a cluster-wide
replay is not possible, the developer has to reason about
global (i.e., distributed) invariants, which in turn can
only be correctly evaluated at consistent snapshots in the
distributed execution. Getting such consistent snapshots
requires either a global clock (which does not exist in
clusters of commodity hardware) or complex algorithms
to capture consistent snapshots ([1]).
Developing an automated record-replay debugger is
harder for datacenter applications than for a single node,
due to the inherent recording overheads. First, these
applications are typically data-intensive, and the volume
of data they process increases proportionally with the
size of the system, the power of individual nodes (e.g.,
more CPUs means more data ﬂowing through), and
ultimately with the success of the business. Record-
ing to persistent storage such large volumes of data
is impractical. A second reason is the abundance of
sources of non-determinism. Coordinating cluster nodes
to perform a faithful replay of a failed execution requires
having captured all critical causal dependencies between
control messages exchanged during execution. Knowing
a priori which dependencies matter is undecidable. A
third challenge is that, at large scale, the runtime over-
head of a record-replay system has important ﬁnancial
consequences: making up for a 50% throughput drop
requires doubling the size of the datacenter. When
operating large datacenters it becomes cheaper to hire
more engineers to do manual debugging than to increase
the size of the datacenter to tolerate the overhead of an
automated record-replay system.
Existing work in distributed system debugging does
not offer solutions to these challenges. Systems like
Friday [2] address distributed replay, but have high
overhead for data-intensive datacenter applications.
To address these challenges, we developed ADDA,
an automated replay-based debugging system for dat-
978-1-4799-0181-4/13/$31.00 ©2013 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
acenter applications. Three ideas make ADDA more
efﬁcient than existing systems. First, a large class of
datacenter applications are split into a control plane and
a data plane, and most bugs reside in the former [3],
so focusing on deterministically replaying the control
plane enables the debugging of most problems. Second,
there is a class of datacenter applications for which
external inputs are anyway persisted in append-only
storage (e.g., for compliance, fault tolerance) and thus
are available when debugging. When combined with the
ability to replay the control plane, this property allows
ADDA to do record-replay by recording just a small
subset of all inputs. Third, with suitable recording, it
is possible to deterministically synthesize (regenerate)
all intermediate data sets during debugging, thus elim-
inating the need to record intermediate data.
In this paper, we make three contributions:
• A technique for recording the behavior of dat-
acenter applications with lower overhead than
existing systems;
• A technique for synthesizing intermediate data
to enable replay-based debugging, in a way that
is not affected by nondeterminism;
• A technique called reduced-scale replay, which
allows replaying a failed execution that oc-
curred in the production cluster on a smaller
cluster or on a subset of the original cluster.
In the rest of the paper, we give an overview (§II),
present ADDA’s design (§III) and prototype (§IV), we
evaluate ADDA (§V), discuss related work (§VI), and
end with a discussion (§VII) and conclusions (§VIII).
II. OVERVIEW
Many replay debugging systems have been built over
the years, and experience indicates that they are invalu-
able in reasoning about nondeterministic failures [2],
[4], [5], [6], [7], [8], [9], [10], [11]. However, we believe
no existing system meets the demands of the datacenter
environment. We discuss these requirements next.
A. Design Requirements
a) Whole-System Replay: The system should be
able to replay the behavior of all nodes in the distributed
system, if desired. Every layer of the stack has to be
replayed—for instance, merely using network snifﬁng
tools like tcpdump and tcpreplay is insufﬁcient to con-
struct the global view that is required to understand what
occurred at the system level.
b) Low Recording Overhead: Large datacenters
consist of hundreds or thousands of machines. In such
large systems, even a moderate recording overhead can
translate into signiﬁcant operation and capital costs.
Thus, low recording overhead should be a major goal
when replay-debugging datacenter applications.
c) Decoupled Debugging / Availability Concerns:
Improving the “debuggability” of applications should
not hurt service availability, especially for 24×7 ser-
vices. This means that, upon failure, the operator’s main
concern should be to bring the system back up, not to
keep the system in a state that will enable developers
to debug the problem.
d) Minimal Setup Assumptions: A replay-
debugging system should record and replay user-level
applications with no administrator or developer effort.
It should not require special hardware, languages, or
source-code analysis, and no modiﬁcations to the appli-
cations themselves. Datacenters may have components
that must be treated as black boxes (e.g., if source code
is not available), but still need to be replayable. Special
languages and source-code modiﬁcations (e.g., custom
APIs and annotations, as used in R2 [12]) are cum-
bersome to learn, maintain, and retroﬁt onto existing
datacenter applications. Source-code analysis is often
not possible, since some components may be closed-
source. Finally, datacenter applications operate in a
“mixed world”: while the nodes running the application
can be assumed to be recorded, other nodes (e.g., those
running DNS servers) may not be.
e) Debug Determinism: To be useful, a replay-
debugging system must reproduce a production failure
and its root cause [13] for most failures, but it need
not reproduce absolutely all failures to be considered
useful (e.g., faithful reproduction of control plane logic
is often sufﬁcient for datacenter systems [3]).
B. Ideas Enabling Our Solution
1) Control-Plane Determinism Sufﬁces: The key
idea is that, for debugging datacenter applications, we
do not need a precise replica of the original run. Rather,
it typically sufﬁces to reproduce some run that exhibits
the same control plane behavior as the original.
The control plane of a datacenter application is the
code that manages data ﬂow and implements operations
like locating a particular block in a distributed ﬁlesys-
tem, maintains replica consistency in a meta-data server,
or updates the routing table of a software router. Control
plane operations tend to be complicated: they account
for over 99% of the bugs in datacenter applications [3].
On the other hand, the control plane accounts for less
than 1% of all datacenter network trafﬁc [3].
In contrast, datacenter application debugging rarely
requires reproducing the same data plane behavior [3].
The data plane is the code that processes the data (e.g.,
that computes checksums of an HDFS ﬁlesystem block
or searches for a string as part of a MapReduce job). In
contrast with the control plane, data plane operations are
simple: they account for under 1% of the code in a dat-
acenter application [3] and are often part of well-tested
libraries. Yet, the data plane generates and processes
over 99% of datacenter trafﬁc [3]. Thus, unless the root
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
Record
ProducƟon node
App
Record
Linux/x86
Data plane
inputs
Replay
Analysis Plugins
Distributed Replay
Engine (DRE)
Control plane I/O
Data plane inputs
Control
plane I/O
Hadoop Distributed Filesystem (HDFS)
Fig. 1: ADDA’s architecture. It uses the recorded control
plane inputs and the persistently stored data plane inputs
to generate, in a best effort fashion, a control-plane
deterministic run.
cause is in the data plane code, reproducing the same
data plane behavior is not necessary.
We observed that the separation between control
plane and data plane holds for a representative class
of datacenter applications, such as CloudStore [14],
MapReduce/Hadoop [15], Memcached [16], Cassan-
dra [17], and Hypertable [18]. However, for many other
datacenter applications, the 1%-99% separation may not
hold, therefore ADDA does not achieve low runtime
overhead for these applications.
Our hypothesis is that by deterministically replaying
the control plane, ADDA can reproduce most bugs with
low-overhead recording. We veriﬁed this hypothesis for
the bugs in our evaluation.
2) Data Plane Inputs Are Persistently Stored: The
data that enters the system from outside is often stored
persistently in append-only ﬁle systems, such as HDFS.
Thus, we can assume that these external inputs are
available during debugging. Thus, ADDA does not need
to record these external inputs. This is a crucial property
of a large number of popular datacenter applications, as
it obviates ADDA from recording prohibitive amounts of
data. ADDA mainly targets such applications.
III. DESIGN
Having described the main insights behind our ap-
proach, we now describe ADDA’s design.
A. Approach
The complex yet low data-rate nature of the control-
plane motivates ADDA’s approach of relaxing its deter-
minism guarantees. Speciﬁcally, ADDA aims for control
plane determinism—a guarantee that replayed runs will
exhibit identical control plane behavior to that of the
original run. Control plane determinism makes data-
center replay practical because it circumvents the need
to record data plane communications (which have high
data-rates), thereby allowing ADDA to efﬁciently record
the execution on all nodes in the system.
ADDA’s architecture is given in Fig. 1. It operates in
two phases: record mode and replay mode.
1) Record Mode:
a) What ADDA records: All ADDA-enabled nodes
record control plane nondeterministic events, by which
we mean the ordering and content of control plane
inputs and outputs (I/O). We consider thread schedul-
ing order and asynchronous control-ﬂow changes (e.g.,
signals and preemptions) to be part of the control
plane, thus they are also recorded. Control plane non-
determinism is recorded by all nodes regardless of
whether the control plane I/O originated externally (i.e.,
from an untraced node) or internally (i.e., from an
ADDA-traced node).
b) What ADDA does not record: ADDA-enabled
nodes do not record data plane I/O, regardless of
whether the data plane I/O is external or internal. ADDA
assumes that external data plane I/O is stored persis-
tently and is available during replay. ADDA does not
assume that internal data plane I/O is stored persistently.
Instead, it attempts to regenerate it during replay.
c) The recording log: ADDA stores the recording
in a local log ﬁle on each node and asynchronously
transfers the logs to a distributed ﬁle system such as
HDFS (see Fig. 1). If the datacenter application supports
consistent snapshots, the logs can be truncated, such that
replay can start from the latest snapshot instead of the
beginning of the recording.
2) Replay Mode: ADDA’s Distributed Replay En-
gine (DRE) uses the recorded control plane I/O and
the persistently-stored data plane input to generate a
control-plane deterministic run. The replay is best effort:
DRE guarantees replay of control plane nodes (the most
complex and bug-prone components), but it may not be
able to replay multi-processor intensive data plane nodes
(the least complex and relatively bug-free component).
Toward ADDA’s goal of best-effort replay, the DRE was
designed using the following principles:
a) Synthesize missing non-deterministic inputs
when possible: While recording control plane non-
determinism is sufﬁcient for replaying control plane
nodes in a distributed application, mixed control/data
plane nodes (e.g., a Hypertable range server) require
recording data plane nondeterminism to determinis-
tically replay even their control plane components.
The DRE attempts to recompute this unrecorded non-
determinism in a best-effort fashion using Data Plane
Synthesis (§III-C).
b) Provide a platform for automated debugging:
Going beyond replay, the DRE also serves as a platform
for writing powerful replay-mode analysis plugins for
sophisticated distributed analyses, such as distributed
data ﬂow and global invariant checking (§III-D).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
B. Recording Control Plane Non-determinism
To record control plane non-determinism, ADDA
must ﬁrst identify it. In the general case of an arbitrary
application, manually identifying is hard – it usually
requires a deep understanding of program semantics,
and, in particular, whether or not the nondeterminism
emanates from control plane code.
The key observation behind ADDA is that, in its
target domain of datacenter applications, the control
plane can often be manually identiﬁed with ease, and,
if not, automatic methods can be successfully applied.
Thus, ADDA semi-automatically classiﬁes control plane
nondeterminism and then interposes on communication
channels (§III-B1) to record the ordering and the values
of the inputs only for channels classiﬁed as control
plane (§III-B2).
1) Interposing on Channels: ADDA interposes on
commonly used inter-CPU communication channels,
regardless of whether these channels connect CPUs on
the same node or on different nodes.
Socket, pipe, tty, and ﬁle channels can be easily in-
terposed efﬁciently, as they operate through well-deﬁned
interfaces (system calls). Interposition is a matter of in-
tercepting these system calls, keying the channel on the
ﬁle-descriptor used in the system call (e.g., as speciﬁed
in sys_read() and sys_write()), and observing
channel behavior via system call return values. Other
sources of non-determinism (e.g., local time and random
number generators) are recorded similarly.
Shared memory channels are harder to interpose
efﬁciently because this requires detecting sharing (i.e.,
when a value written by one CPU is later read by an-
other CPU). A naive approach would be to maintain per-
memory-location meta-data about CPU accesses. This
is expensive, since it requires intercepting all memory
accesses.
To efﬁciently detect inter-CPU sharing, ADDA em-
ploys the page-based Concurrent-Read Exclusive-Write
(CREW) memory sharing protocol, ﬁrst suggested in the
context of deterministic replay by Instant Replay [19]
and later implemented and reﬁned by SMP-ReVirt [7].
Page-based CREW leverages page-protection hardware
found in modern MMUs to detect concurrent accesses to
shared pages. When CREW detects concurrent accesses
on a shared page,
it serializes the accesses to the
page. Details of our CREW implementation are given
in §IV-B1.
If
the application does not have internal non-
determinism caused by data races, ADDA can just record
the order of synchronization operations, with substan-
tially lower overhead. However, the applications we
evaluated ( §V) do have data races.
2) Classifying Channels: Two observations underly