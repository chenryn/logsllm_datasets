tended with .€  and Ssz is a possible digraph when the language is extended 
with  and 1. 
We  found that  library  code taxed  the  limits of our tool 
more thoroughly than  most  applications,  and a dispropor- 
tionate  amount of  our effort was  spent on  the  C  libraries. 
For instance,  the  GNU  stdio implementation  uses  func- 
tion pointers extensively to emulate an object-oriented pro- 
gramming  style;  with  our  naive  pointer  analysis,  the  in- 
ferred models were  too  imprecise, so we replaced  our au- 
tomated analysis results with hand-crafted models.  In con- 
trast, the database library l i b d b  also uses function pointers 
extensively to parametrize database implementations, but in 
this case  we were  willing  to accept the  imprecision.  As a 
third example,  the GNU ELF libraries make heavy  use of 
both  setjmp0 and function pointers to implement excep- 
tion handling, so we resorted to refining the inferred model 
by hand in some places to improve its precision. 
There are many disadvantages to hand-built models: they 
are  time-consuming to  construct;  they  are  difficult to  get 
right (and thus unsoundness and false alarms are a risk); and 
they make it unpleasant to keep up with changes to the code. 
Ideally, we would have preferred a more precise automatic 
analysis so that we could avoid these disadvantages, but in 
practice even our crude techniques were generally sufficient 
to get the job done without compromising our primary goals 
in the few cases where manual analysis was necessary. 
Dynamic linking  Dynamically linked  libraries  pose  an- 
other challenge, because they  force us to update the model 
at  runtime.  In  our implementation,  we predict  in  advance 
the set of libraries which might be linked in and build mod- 
els  for all  of  them  from  source.  This can  introduce  false 
alarms if  our prediction becomes out of date (when, e.g., a 
new version of the library becomes available), which means 
that  everything must be  updated  whenever  the  underlying 
libraries  are.  This is not  a  fundamental  limitation,  and  a 
more satisfying solution would be to build a model  at run- 
time from object code, but we have not explored this direc- 
tion because it has not been necessary in our experience. In 
any case, binding applications to libraries statically has sub- 
stantial security benefits, because it prevents introduction of 
Trojan horses via dynamic linking attacks. 
Threads  Threads pose yet another challenge, because the 
context-switching operation introduces another type of im- 
plicit  control  flow.  If  it  were  possible  to  reliably  receive 
‘thread context-switch’ events  (see  Principle  l),  handling 
threads  would  be  straightforward;  this  is  no problem  for 
kernel threads, but unfortunately, user threads pose a thorny 
challenge, and we know of no good general solution. A sec- 
ond issue is that threaded code may contain security vulner- 
abilities due to synchronization bugs  that we do not  know 
how to detect. Because of these challenges, and because no 
security-critical application we examined used threads, our 
prototype implementation does not support threaded code. 
163 
5.3. Optimizations 
Irrelevant system calls  Up to now we have described an 
intrusion detection system that monitors all system calls the 
application  invokes, and we  originally  expected this  to  be 
optimal.  However, we found that ignoring, e.g., the b r k o  
system  call  can  greatly  improve performance by  reducing 
the  size  and  ambiguity  of  the  model:  in  many programs, 
memory allocation can occurjust about anywhere, so seeing 
a b r k 0  system call gives us very little contextual informa- 
tion.  This may  cause us to miss denial-of-service attacks, 
but those are beyond the scope of this paper. 
In some cases, ignoring certain system calls can even im- 
prove the precision of the model.  It may sound paradoxical 
that throwing away information can improve precision, but 
consider  the digraph  model:  excluding  very common sys- 
tem calls gives more context. It is useful to be able to enable 
this optimization on a per-application  basis. 
System call arguments  The most important optimization 
is based on the observation that we can gain quite a bit of ex- 
tra information about the application behavior by examining 
the arguments to each system call. Since we can often stat- 
ically predict some system call arguments with little effort, 
we might as well check them at runtime. We recognize lex- 
ically constant system call arguments in our prototype and 
found that even this extremely crude technique provides no- 
ticeable improvements to both precision and performance; 
see the measurements in the next section. 
6. Evaluation 
In this section we measure the performance of our three 
approaches  (the  abstract  stack,  callgraph,  and  digraph 
models)  on  a  number of  typical  security-critical  applica- 
tions that one might want to monitor for intrusions. For each 
model,  we measure two  variants:  a basic  implementation 
that  ignores  system  call arguments,  and then  an  improved 
implementation that  checks all system call  arguments that 
can  be statically  predicted.  In each case, we  focus on two 
key metrics:  runtime overhead (pe@ormance), and robust- 
ness  of  detection  against  targeted  attack  (precision).  As 
will become clear, our results indicate that there is a strong 
tradeoff between performance and precision. 
Performance 
In Figure 3, we show the runtime overhead 
incurred by  our system when applied to four representative 
applications  with  known  security  vulnerabilities,  finger, 
qpopper, procmail, and  sendmail. Of  these,  finger 
is  the  smallest  (at  1K lines of code,  excluding comments, 
blank lines, and libraries), and sendmail is the largest (at 
32K lines);  the other two are in the middle.  The height of 
each bar in Figure 3 indicates the performance overhead of 
each model, measured in seconds of extra computation per 
transaction’. 
The figures use  shading to show the effect of checking 
system call arguments.  One might expect that checking ar- 
guments could improve performance by reducing ambiguity 
in the model and thus reducing the number of possible paths 
through the model that we need to explore at runtime.  The 
measurements confirm this hypothesis, showing that-even 
though we implemented only an extremely crude data-flow 
analysis-the  performance benefits are substantial. 
We initially expected that, due to its complexity, the ab- 
stract  stack  model  would  be  consistently  slower  than  the 
callgraph model.  This is partially confirmed by  our experi- 
ments, but we were surprised to find many exceptions. For 
instance, in  the case of procmail, it  appears that the  im- 
proved precision provided by the abstract stack model more 
than makes up for the complexity of this model. In general, 
moving to more precise models may reduce the degree of 
non-determinism and thereby reduce the  number of possi- 
ble paths explored at runtime. 
Note that there is a wide variation in running times. The 
digraph  models  are  consistently  extremely  fast  (the  over- 
head  is  too  small  to  measure),  but  the  other models  are 
sometimes vastly slower.  For sendmail, the callgraph and 
abstract stack models were so slow that  we forcibly termi- 
nated  the experiment after an hour of computation.  Since 
our goal is for real-time intrusion detection, imposing more 
than a few seconds of latency onto any interactive applica- 
tion  is  absolutely  unacceptable;  an  hour is clearly  several 
orders of magnitude too much. Consequently, for some ap- 
plications, only the digraph model is fast enough; for oth- 
ers, the more sophisticated callgraph or abstract stack mod- 
els are also workable. We conclude that, in all cases, at least 
one of the approaches provides acceptable performance, but 
the type of model must be chosen on a per-application basis. 
Our prototype implementation has known problems that 
make its performance sub-optimal. See Section 7. 
Mimicry attacks  To motivate the need for precise  mod- 
els,  we  introduce  a  new  class of  attacks  against  intrusion 
detection  systems,  the  mimicry  attack.  Recall  that  one of 
our  primary  design  goals  is  to detect  not  only  the  attacks 
that are common today, but also to detect the attacks of the 
future.  Furthermore,  our model  of  the  application  proba- 
bly cannot be kept secret from attackers. Consequently, our 
models need  to be  precise enough that  there  is no way  for 
an  attacker  to  cause  any harm  without  deviating  from the 
’We  use the word transaction  to denote a single interactive event, such 
as delivery  of  a piece of  email.  For interactive  applications  that  are  not 
compute-intensive, WK believe  the main goal  is to avoid introducing  niore 
than a few seconds of latency per transaction, and so WK measure absolute 
rather than relative overheads.  All measurements were performed on a450 
MHz Pentium I1 running Java. using IBM’s JIT for Linux. 
164 
42 min 
> 1  hour 
__________ 
‘.Stack  - 
,B Callgraph 
i m Digraphs 
~ 
n 
finger 
qpopper 
procmail 
sendmail 
finger 
qpopper 
procmail 
sendmail 
Figure 3.  Overhead imposed by the  run- 
time  monitor for  four  representative ap- 
plications, measured in seconds of  extra 
computation per transaction. 
Figure 4. Precision of each of the models, 
as characterized by the average branching 
factor (defined later in Section 6).  Small 
numbers represent better precision. 
Notes on  both figures:  For each  application, we  show measurements for three models using a cluster of  three vertical bars:  the abstract 
stack model  (leftmost bar), the callgraph model  (middle), and the digraph  model  (rightmost). Each vertical bar  uses shading to represent 
two  measurements:  the  shorter, solid-colored segment represents the  case  where  arguments  are  checked;  the  total  height  of  the  bar 
(including both the solid-colored and lightly-shaded regions) shows the case when arguments are ignored. 
model, even when  the  attacker can predict  what model  we 
are using.  Otherwise, attackers will be free to develop ma- 
licious exploit code that mimics the operation of the appli- 
cation, staying within the confines of the model and thereby 
evading detection by our system despite its harmful effects. 
In  general,  if  the  attacker  somehow obtains  control  of 
the application  when our intrusion detection automata is in 
the  state s, and if some insecure state s’  is reachable  from 
s  through any  path  in  the  automata,  then  the  attacker  will 
be able to bring the system to an insecure state without risk 
of detection  by  synthesizing the system calls that make up 
the path s  + . . . + s’. We  call this a mimicry attack, and 
we expect that, as intrusion detection becomes more widely 
deployed, mimicry attacks are unavoidable [26]. 
Note  that  imprecise  models  contain  impossible  paths, 
which  introduces a vulncrability  to mimicry  attacks if  any 
of those paths can  reach  an  insecure state.  Consequently, 
the primary  defense  against  mimicry  attacks lies  in  high- 
precision models. 
Precision  Unfortunately, we do not  know the right way8 
to quantify an intrusion detection system’s degree of robust- 
ness against mimicry attacks, so we do not have a complete 
*In practice,  it  may  often  be  difficult even  to  identify just  the  set  of 
insecure states of the system. 
characterization of  the precision of our models.  Nonethe- 
less,  we  will  attempt to  give  some intuition  for the preci- 
sion of our models by applying the following metric. Imag- 
ine freezing the intrusion detection system in the middle of 
some application  execution  trace.  There is  some set S  of 
system  calls  that  would  be  allowed  to  come  next  without 
setting off  any  alarms.  We define  the brunching fuctor  to 
be the size  of S. A  small branching factor means that the 
intruder has few choices about what to do next if she wishes 
to evade detection, and so we can expect that small branch- 
ing factors leave the intruder most constrained and least able 
to cause harm.  Finally, because  we cannot predict  at  what 
point during execution the attacker might obtain control of 
the application, we suggest to measure the average brunch- 
ing factor over all normal execution traces.  We  stress that 
this metric is insufficient on its own, but it seems to yield a 
useful first approximation. 
Figure  4  shows  the  precision  of  our  models  on  our 
four sample applications, under the average branching fac- 
tor  metric.  We  can  see  that  checking  system  call  ar- 
guments provides substantial  precision  improvements, be- 
cause it  reduces the  number of possible  paths  through  the 
model, and because  some system calls  are harmless  when 
their  arguments  are  fixed  in  advance.  For  instance,  an 
open(”/etc/motdl’, 0-RDONLY) call  is  harmless  when 
165 
its arguments are statically known, but otherwise could po- 
tentially be exploited by attackers to overwrite arbitrary files 
on the system. Our experience is that unchecked system call 
arguments greatly increase our exposure to mimicry attacks. 
Since checking arguments improves both  performance and 
precision, we conclude that it should always be enabled. 
We  can  also  see  that,  when  system call  arguments are 
checked, the abstract stack model is much more precise than 
the  callgraph model, which  is itself  more precise  than  the 
digraph model. 