still represented as a memset in the ﬁnal post-optimization
bitcode, both with and without our customised optimizations.
Note that
these may still be converted into stores during
code generation, and that although the optimizer often fails to
remove initializations entirely, it can still obtain performance
beneﬁts due to transforming, moving or shortening them. The
table also provides the (stripped) binary size; in many cases,
the impact of the initialization makes no difference to the ﬁnal
binary size whatsoever, and in the worst case it is minimal.
When our optimizer is enabled without hardening, only a
minimal performance improvement of around 0.3% is seen, as
shown in Figure 15. The highest overhead is for h264ref; the
impact of this overhead can also be seen in Figure 12 above.
We do not believe the regressions seen here are fundamental,
but in any case, our other overhead ﬁgures include the effect of
any small regressions. If necessary in practice, any problematic
individual optimizations could be adjusted or simply disabled
when compiling without hardening.
The mean overhead when using our optimizer as the
baseline is 3.8%;
the primary contributors to this differ-
ence are small performance regressions of perlbench and
xalancbmk, and a reduced performance improvement for
omnetpp. The latter has a >1.5% performance improvement
against both baselines in any case, thanks to the combination
of our optimizations and improved cache behavior.
Figure 13 presents the performance overhead of our frame
initialization pass, combined with our hardened allocator.
10
8
6
4
2
0
−2
perlbench
bzip2 gcc
mcf
gobmk
hm mer
libquantum
sjeng
h264ref
omnetpp
astar
xalancbmk
Fig. 13. SPEC CINT2006, runtime overhead (%) of frame initialization
example, zero is propagated from heap allocation sites, rather
than undef.
A. SPEC CPU2006
We built all C/C++ benchmarks in SPEC CPU2006 us-
ing LTO and -O3, except the specrand test benchmark. We
present overhead ﬁgures for the median of 3 runs, using the
reference dataset. The runtime overhead of applying SafeInit
to CINT2006 is shown in Figure 12.
SafeInit incurs a low performance cost for many bench-
marks, even without our optimizer; these are generally CPU-
bound and/or make their allocations only at startup. For exam-
ple, mcf already uses calloc for allocating heap memory,
and does not make signiﬁcant use of the stack. However,
other benchmarks experience signiﬁcant runtime overhead; the
(geometric) mean of the runtime overhead is 8%, when applied
without our optimizer.
Applying our optimizer reduces the overhead for the re-
maining benchmarks signiﬁcantly, as expected, resulting in
average overhead for CINT2006 of 3.5% compared to our
9
TABLE I.
SPEC CINT2006 DETAILS. #INITS IS THE NUMBER OF LARGE INITIALIZATIONS LEFT AFTER EXISTING COMPILER OPTIMIZATIONS AND OUR
OPTIMIZER HAVE RUN, RESPECTIVELY. SIZE IS THE (STRIPPED) BINARY SIZE.
Benchmark
astar
bzip2
gcc
gobmk
h264ref
hmmer
libquantum
mcf
omnetpp
perlbench
sjeng
xalancbmk
#allocas
790
679
31551
17039
4229
3333
567
184
7638
12327
770
92396
#inits (naive)
7
23
650
325
122
19
3
1
110
175
61
1701
#inits (opt)
4
20
596
300
122
18
2
1
110
167
48
1302
size (baseline)
43736
80488
4108712
3554640
630664
189592
31336
19040
806712
1272584
133976
3871528
size (naive)
43736 (0%)
84584 (5.1%)
4133288 (0.6%)
3566928 (0.3%)
638856 (1.3%)
189592 (0%)
31336 (0%)
19040 (0%)
810808 (0.5%)
1284872 (1%)
133976 (0%)
3908392 (1%)
size (optimizer)
43736 (0%)
84584 (5.1%)
4120992 (0.3%)
3566928 (0.3%)
638856 (1.3%)
189592 (0%)
31336 (0%)
19040 (0%)
814904 (1%)
1280792 (1%)
133976 (0%)
3892008 (0.5%)
naive SafeInit
SafeInit
6
5
4
3
2
1
0
6
5
4
3
2
1
0
naive SafeInit
SafeInit
sendﬁle-4K
sendﬁle-64K
sendﬁle-1M B
writev-4K
writev-64K
writev-1M B
4K
64K
1M B
sendﬁle-4K
sendﬁle-64K
sendﬁle-1M B
Fig. 16.
requests/sec overhead (%) for hardening lighttpd
Fig. 17.
requests/sec overhead (%) for hardening nginx
Given the average overhead of 13.5%, it is clear that such
frame-based initialization without the beneﬁt of compiler op-
timizations is too slow. Despite this simpler approach offering
considerably less safety, only bzip2 gains signiﬁcant perfor-
mance beneﬁt from these reduced guarantees.
We also investigated another approach for weakening guar-
antees to improve performance, by increasing the lifetimes of
variables inside loops so they would only be initialized once,
before the loop. The impact of this on stack coloring and
register allocation resulted in worse performance for almost all
benchmarks (and average overhead for CINT2006 of >5%).
B. Servers
by
using
for
We
evaluated
of SafeInit
overhead
tasks
less
the
computationally-intensive
two modern
high-performance web servers, nginx (1.10.1) and lighttpd
(1.4.41). We built the web servers using LTO and -O3. Since
they are I/O bound when used on our 1gbps network interface,
we benchmarked them using the loopback interface. This is
an extreme scenario; in practice, the overhead of SafeInit is
insigniﬁcant for these servers.
We used apachebench to repeatedly download 4Kb, 64Kb
and 1MB ﬁles, for a period of 30 seconds. We enabled
pipelining, used 8 concurrent workers, and used CPU afﬁnity
to reserve a CPU core for apachebench. We measured the
overhead for the median number of requests per second, across
10 runs; we did not see signiﬁcant amounts of variance.
lighttpd: We attempted to conﬁgure lighttpd to optimize
throughput, allowing 100 requests per pipelined connection,
and evaluated both the sendfile (default) and writev
network backends. The results are shown in Figure 16.
10
Average overhead is minimal when sending the large
(1MB) ﬁle. In the extreme case of the small 4Kb ﬁle, where
we process almost 70,000 requests per second, overhead is
still less than 3%; the majority of execution time here is spent
parsing incoming requests and maintaining internal structures.
Much of lighttpd’s overhead for these tiny requests is
caused by small heap allocations for strings in the chunk
queue; only the ﬁrst byte of these is initialized by the caller, but
our hardened allocator clears the entire allocation for safety.
The remaining overhead for both situations is due to lighttpd’s
writev code, used by both backends for writing these al-
locations to the network, uses a ﬁxed-size stack buffer. Our
current optimizer fails to optimize away the unused portion of
the buffer, but improved optimizations or minor changes to the
code could reduce the overhead further. In fact, older versions
of lighttpd used a larger buffer in this code, but recently a
“sane limit” was imposed on the buffer size; such modiﬁcations
demonstrate how general code improvements can also reduce
the overhead imposed by SafeInit.
nginx: We tested nginx both with a default conﬁguration
(which is similar to the one we used for lighttpd) and with
sendﬁle enabled (which signiﬁcantly increases performance for
serving the 64Kb and 1MB ﬁles). All logging was disabled;
our overhead is slightly reduced when logs are enabled. The
results are shown in Figure 17.
Overhead of full SafeInit, including our optimizer, is not-
icably higher with the 64Kb ﬁles; however, the overhead of
SafeInit remains below 5% in all circumstances.
nginx makes use of a custom pool-based memory allo-
cator, which makes it difﬁcult for our optimizer to analyse
code. However, we manually veriﬁed that memory is not (by
TABLE II.
PHP 7.0.9 MICRO-BENCHMARK RESULTS (IN SECONDS)
baseline
new optimizer
naive SafeInit
SafeInit
bench.php
1.029
1.007 (-2.1%)
1.004 (-2.5%)
0.999 (-3%)
micro_bench.php
3.983
3.879 (-2.6%)
3.994 (0.3%)
3.897 (-2.8%)
TABLE III.
LMBENCH RESULTS. TIME IN MICROSECONDS, PLUS %
OVERHEAD ABOVE BASELINE.
Sub-benchmark
syscall null
syscall stat
syscall fstat
syscall open
syscall read
syscall write
select tcp
sig install
sig catch
sig prot
proc fork
proc exec
pipe
tcp
bw pipe (MB/s)
bw tcp (MB/s)
Baseline
0.0402
0.2519
0.0739
0.7049
0.0817
0.0981
4.5882
0.0964
0.6534
0.2220
65.5904
208.8846
3.3500
6.7489
4988.09
8269.34
w/Optimizer
0.0402 (0%)
0.2369 (-5.9%)