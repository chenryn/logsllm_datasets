·
l
d − 1
,
Pr(yu = 1)
f jq(p− q) + β
1−β ·
· ( l−1
l
d−2
d−1
fu p + (1− fu)q + β
1−β ·
l
d−1
− q)
.
= q +
(34)
(35)
(36)
(37)
(38)
(39)
Suppose both t and u are among the top-N items with the
largest estimated frequencies. The true frequency ft for the
target item t is small, since our attack aims to promote an
unpopular item. We have Pr(y j = 1|yt = 1)  0.001 and r ≥ 3. The countermeasures
are ineffective when β or r is small (e.g., β ≤ 0.001 or r ≤ 2).
This is because the detection method relies on that the target
itemset is frequent and abnormal, but the target itemset is not
frequent when β is small and is not abnormal among the users’
perturbed values when r is small.
Second, for OLH, detecting fake users and the combined
countermeasure can effectively defend against the MGA at-
tacks only when r is not too small nor large, e.g., 3 ≤ r ≤ 5
in our experiments. Recall that, to attack OLH, our MGA
randomly samples 1,000 hash functions and uses the one that
hashes the largest number of target items to the same value
for each fake user. When r ≤ 5, our MGA can ﬁnd a hash
function that hashes all target items to the same value. There-
fore, the target itemset is frequent among the users’ perturbed
values. Moreover, when r ≥ 3, the frequent target itemset is
also abnormal. As a result, the detection method can detect
MGA when 3 ≤ r ≤ 5. When r ≥ 6, our MGA can only ﬁnd
a hash function among the 1,000 random ones that hashes a
subset of the target items to the same value for each fake user.
In other words, each fake user essentially randomly picks a
subset of the target items and promotes them. Therefore, the
entire target itemset is not frequent enough and MGA evades
detection. Our MGA evades detection for all the explored β
in Figure 7b because r = 10 in these experiments.
Adaptive MGA to OUE:
Inspired by the evasiveness of
MGA to OLH, we can also adapt MGA to OUE that evades
detection. Speciﬁcally, for each fake user, instead of using a
perturbed value that supports all r target items, we randomly
(cid:5) of the r target items and ﬁnd a perturbed value that
select r
USENIX Association
30th USENIX Security Symposium    959
(a) OUE
(b) OLH
(c) OUE
(d) OLH
(e) Adaptive MGA
Figure 7: (a)-(b) Impact of β on the countermeasures against MGA when r = 10. (c)-(d) Impact of r on the countermea-
sures against MGA when β = 0.05. (e) Impact of r
(cid:5) on the adaptive MGA (MGA-A) to OUE when r = 10.
than that for OUE, e.g., ˆfu = 0.18 for OLH and ˆfu = 0.26 for
OUE when ft = f j = 0.01. Figure 8b shows the impact of β
on the detection rate, where we explore N = 1 to 20 to ﬁnd
the N that achieves the highest detection rate for each given
β. We observe that the detection rate increases as β increases,
which implies that the MGA attack with r = 1 is easier to
detect when there are more fake users. Once the target item
is detected, the server can compute the sum of the estimated
frequencies of all non-target items as ˜fU = ∑u(cid:4)=t ˜fu and set the
estimated frequency of the target item as ˜ft = 1− ˜fU, which
can reduce the overall gain of MGA. For instance, the overall
gain decreases from 2.37 to 0.095 for OLH when β = 0.1.
6.4.2 Heavy Hitter Identiﬁcation
Normalization is ineffective for heavy hitter identiﬁcation
because normalization does not impact the ranking of the
items’ estimated frequencies. Moreover, the conditional prob-
ability based detection is only applicable to one target item.
Therefore, we perform experiments on detecting fake users
for heavy hitter identiﬁcation. Moreover, we focus on MGA
because RIA and RPA are ineffective even without detecting
fake users (see Figures 4). We observe that detecting fake
users is effective in some scenarios but not in others. For
instance, when r = 5, detecting fake users can reduce the
success rate of MGA from 1 to 0, as all fake users can be
detected. However, when r = 10, our MGA can still achieve
a success rate of 1.
6.5 Other Countermeasures
Detecting fake users is related to Sybil detection in dis-
tributed systems and social networks. Many methods have
been proposed to mitigate Sybil attacks. For instance, meth-
ods [12, 16, 26, 52, 56, 57, 67, 68] that leverage content, be-
havior, and social graphs are developed to detect fake users
in social networks. Our detection method can be viewed as
a content-based method. Speciﬁcally, our detection method
analyzes the statistical patterns of the user-generated content
(i.e., perturbed values sent to the central server) to detect fake
users. However, our detection method is different from the
content-based methods to detect fake users in social networks,
as the user-generated content and their statistical patterns dif-
(a) N
(b) β
(cid:5)
(cid:6)
Figure 8: Impact of N and β on the detection rate of the
conditional probability based method for r = 1.
r
r(cid:5)
(cid:5) selected target items. The adaptive attack splits
supports the r
itemsets
the frequency of the target itemset with size r to
(cid:5), which becomes much harder to detect. We call
with size r
such adaptive attacks MGA-A. Figure 7e shows the impact
(cid:5) on MGA-A to OUE when r = 10. We observe that our
of r
(cid:5) becomes
adaptive MGA achieves smaller overall gains as r
smaller when no countermeasures are deployed. However,
(cid:5)  1, the RIA variant uses a fake
user to promote only one target item. However, MGA uses
a fake user to simultaneously promote multiple target items,
which means that its overall gain is multiple times of the RIA
variant’s overall gain. Moreover, it may be easy for the central
server to detect the RIA variant for OUE. Speciﬁcally, the
server can count the number of 1’s in a vector from a user. If
there is only one entry that is 1, then it is likely that the vector
is from a fake user as the probability that a genuine vector
contains a single 1 is fairly small.
Defending OLH by restricting the hash functions: Since
MGA to OLH relies on searching a hash function that maps
target items to the same hash value, the server could restrict
the space of seeds of the hash function or select the hash
function by itself to defend OLH against MGA. However, the
defense may break the privacy guarantees. In particular, an
untrusted server could carefully select a space of seeds or a
hash function that does not have collisions in the item domain.
For instance, a hash value h corresponds to a unique item.
When receiving a hash value h from a user, the server knows
the user’s item, which breaks the LDP guarantee.
8 Conclusion
In this work, we perform the ﬁrst systematic study on data
poisoning attacks to LDP protocols. Our results show that
an attacker can inject fake users to an LDP protocol and
send carefully crafted data to the server such that the target
items are estimated to have high frequencies or promoted as
heavy hitters. We show that we can formulate such an attack
as an optimization problem, solving which an attacker can
maximize its attack effectiveness. We theoretically and/or
empirically show the effectiveness of our attacks. Moreover,
we explore three countermeasures against our attacks. Our
empirical results show that these countermeasures have lim-
ited effectiveness in some scenarios, highlighting the needs
for new defenses against our attacks.
Interesting future work includes generalizing our attacks
to other LDP protocols, e.g., LDP protocols for itemset min-