from the TLS to each newly created stack frame, to modify
the canary upon a fork system call we must modify both
the canary in the TLS, as well as the canaries in the stack
frames that the forked process inherited.
However, this is not feasible in current canary-based pro-
tectors, as hardened programs do not store any information
regarding where (in their address space) their canaries are
stored. Thus, once a child process is forked, there is no way
for it to access the canaries in the frames it inherited from
its parent process, as it cannot diﬀerentiate canaries from
random data that may be residing in the stack. As a result,
under the current design of the stack canary mechanism, the
only value that can be updated at runtime upon a fork is
that of the canary in the TLS. However, this partial update
will result in an abort if execution reaches the frames inher-
ited from the parent process, as the canary cookies in these
frames still hold their old values.
To demonstrate this point, let us consider the example
shown in Fig. 1, where a process has two canary-protected
frames (a and b) in its call stack the moment it invokes
fork.
Initially, all frames have the same canary value,
copied from the TLS into the stack at the creation of each
frame (Fig. 1a). Once the child process is forked, it inherits
its parent’s frames in their exact state, as expected by the
process creation mechanism (Fig. 1b). In the child process’
context, before the process starts executing, we modify the
canary cookie in the TLS, thus the newly created frames in
the child now have a diﬀerent canary value, as is the case
for frame c (Fig. 1c).
The canary checks for the newly created frames will suc-
ceed, since the canaries in each frame have the same value
with the (new) canary stored in the TLS. Thus, frame c
will be successfully destroyed both for the parent and the
child process. However, once execution reaches one of the
inherited frames in the child process (Fig. 1d), the canary
in the TLS will have a new value and the canaries in the
stack will still have their old value, causing the child process
to terminate. In addition, the stack smashing check in the
function epilogue may similarly fail if, at some point, dur-
ing the execution of the child process, either an exception is
triggered or setjmp/longjmp is invoked, forcing the stack
to unwind.
}}......}ab......TLScanarypreviousframes}}......}TLSabParent ProcessTLSab}}......}Child Process}}}......}TLSabcParent ProcessTLSabc}}}......}Child Processab}}}......}TLSabcParent ProcessTLSabc}}}......}Child Process=?=?Successfully updating the canary in child process after a
fork would require modifying the current implementations
to incorporate a bookkeeping mechanism that allows for a
runtime update of the inherited stack canaries. However, in-
corporating such a mechanism to production systems proves
to be a challenging task. First, new protections should be
made modular so as to be compatible with third-party soft-
ware. Therefore, a solution that requires a custom version
of system or third-party libraries (e.g., glibc) would not be
easy to deploy at a large scale. Similarly, the incremental
performance overhead of any new canary protection design
should be within acceptable limits for production systems
and respect existing micro-architectural hardware optimiza-
tions (e.g., hardware prediction schemes), without requiring
major changes to current implementations.
To the best of our knowledge, a robust and readily deploy-
able mechanism for armoring canary-based defenses against
brute-force attacks has not yet been proposed. As a result,
attacks like those described in Section 2 are still present,
exploiting a limitation in a widely deployed defense. The
variety of applications and OSes that are protected with
some form of stack canaries is a major obstacle towards the
adoption of new countermeasures, as backward compatibil-
ity and testing of new designs is not trivial. In the following
sections, we discuss how DynaGuard solves the problems
discussed above while preserving application correctness.
4. DESIGN
At a high level, DynaGuard operates as follows: after a
fork system call, and right before any instruction has ex-
ecuted in the child process, DynaGuard must update the
canaries in both the TLS and all inherited stack frames in
the child process. Once the canaries have been updated, it
can resume the execution of the child. This runtime update
renders byte-by-byte brute-force attacks infeasible, since ev-
ery forked process has a fresh canary.
As we discussed in Section 3, current stack canary pro-
tectors do not keep any information regarding where the
canaries are located within the stack of each thread. There-
fore, DynaGuard’s design should allow each running process
to access and modify all of its stack canaries at runtime. To
achieve this goal, DynaGuard performs a per-thread runtime
bookkeeping of all the canaries that are pushed in the stack
during execution, using a lightweight buﬀer allocated dy-
namically upon each thread’s creation (this buﬀer is stored
in the heap). Figure 2 illustrates this scheme in more detail.
DynaGuard’s canary address buﬀer (CAB; Fig. 2a) holds
references to all the canaries stored in the stack of the run-
ning process. When a child process is forked, the CAB of the
parent process is copied to the child process (Fig. 2b). Before
execution starts in the child context, DynaGuard modiﬁes
the canary value in the TLS, as well as in all the stack ad-
dresses referenced by the entries in the thread’s CAB. Like-
wise, whenever a canary-protected frame is pushed onto the
stack, the address of the canary is stored in CAB (Fig. 2c)
and, once a canary-protected function returns, the respec-
tive address is removed (Fig. 2d).
The aforementioned design allows DynaGuard to success-
fully modify the canary values for newly-created processes,
without facing any of the limitations described in Section 3.
Speciﬁcally, it allows for a seamless integration with third-
party software and with libraries that only support the ex-
isting stack protection mechanisms.
In addition, the pro-
posed architecture allows for the eﬀective handling of stack
unwinding,
irrespectively of whether the latter occurs in
the context of an exception, due to a signal, or because
of setjmp/longjmp: as the stack always grows towards
lower addresses, the addresses that were last saved in CAB
must always be lower than the current value of the stack
pointer. Thus, DynaGuard can hook any stack unwinding
operation and modify the canary address buﬀer accordingly,
so that the latter is always consistent with the program
stack. In this manner, and contrary to recently proposed so-
lutions [25], application correctness is preserved even when
all frames are canary-protected.
Apart from ensuring correctness, the proposed design has
the added beneﬁt of not breaking compatibility with legacy
software or current canary protections. Compilers only need
to add this bookkeeping mechanism on top of their current
stack canary implementations, without altering the well-
established conventions on the format of the canary check
or a function’s prologue and epilogue. Finally, due to the
small number of canary-protected frames that (on average)
are active at runtime, and since DynaGuard only needs to
store one address per protected frame, this design is very
eﬃcient with respect to memory and CPU pressure.
IMPLEMENTATION
5.
5.1 Compiler-based DynaGuard
The compiler-based version of DynaGuard consists of a
plugin for the GNU Compiler Collection (GCC) and a position-
independent (PIC) dynamic shared library that gets linked
with the running application via LD_PRELOAD. Combined,
they consist of ∼1250 lines of C++ code.
Several requirements must be accomplished to implement-
ing DynaGuard at the compiler level, while at the same
time maintaining compatibility with third-party software:
(a.) DynaGuard must instrument all the canary push/pop
events and perform its bookkeeping on a per-thread basis;
(b.) DynaGuard must hook each fork system call and up-
date the canaries in the child process as described in Sec-
tion 4; (c.) DynaGuard must intercept all calls related to
stack unwinding and ensure that the CAB gets updated ac-
cordingly. The ﬁrst requirement is handled by DynaGuard’s
GCC plugin. All other requirements are handled by Dy-
naGuard’s dynamic shared library (runtime), which ensures
the proper management of the CAB for every thread.
5.1.1 GCC Plugin Implementation
Beginning with v4.5.1, GCC added support for extending
the compilation pipeline via plugins that operate on top of
the various intermediate languages (ILs) used throughout
the translation process. The GCC pipeline consists of three
distinct components, namely the front-end, middle-end, and
back-end, which transform the input into the GENERIC,
GIMPLE, and RTL ILs [43]. DynaGuard is registered as
an RTL optimization pass and loaded by GCC right after
the vartrack pass. The ﬁrst reason for placing Dyna-
Guard late in the RTL optimization pipeline is to ensure
that most of the important optimizations have already been
performed, and, as a result, DynaGuard’s instrumentation is
never added to irrelevant code. In addition, in this manner,
we ensure that all injected instructions, which perform the
necessary bookkeeping, will remain at their proper locations
and will not be optimized by later passes.
(a) Parent before fork: the canary address buﬀer (CAB) contains
the addresses of all canaries in the process’ stack frames.
(b) After forking, the canary address buﬀer of the parent is copied
to the child. All canary addresses are now accessible by the child.
(c) The per-thread CAB is updated upon frame creation/destruc-
tion, to be kept consistent with the stack.
(d) Epilogue checks work as expected since all stack canaries are
consistent with the canary in the TLS.
Figure 2: The design of DynaGuard allows for a complete update of all canaries in the child process.
Apart from inserting all stack canary addresses to CAB,
the DynaGuard GCC plugin must also modify the canary
setup and check inside each canary-protected frame, to pre-
vent the DynaGuard-protected application from using the
standard (g)libc canaries. This is necessary to allow the
modiﬁcation of the canary at runtime without aﬀecting any
checks in libraries that are not compiled with DynaGuard.
The canary initialization that occurs during the creation of
threads and processes is exactly the same in DynaGuard
and in glibc, with the only diﬀerence being that the Dy-
naGuard canary is stored at a diﬀerent location in the TLS
area. Therefore, the entropy of canaries is not aﬀected, but
now the TLS holds two diﬀerent types of canaries: the stan-
dard glibc canary and the DynaGuard canary. Upon a
fork, all DynaGuard canaries get updated without aﬀect-
ing any checks in modules or libraries that use the legacy
glibc canaries.
DynaGuard stores the starting address of CAB, its total
size, and its current size, in the TLS, together with the Dy-
naGuard canary. To ensure compatibility with current ver-
sions of glibc, we reserve 4 out of the 8 free __padding
elements of the tcbhead_t data structure for that purpose.
In x86-64, the reserved TLS oﬀsets range from 0x2a0 to
0x2b8. In particular, %fs:0x2a0 holds the base address of
CAB, %fs:0x2a8 keeps the current index in the CAB (i.e.,
how many canary addresses are stored), %fs:0x2b0 holds
the total size of the buﬀer, and ﬁnally, %fs:0x2b8 stores
the DynaGuard canary.
Figure 3: Assembly excerpt for a binary compiled with
-fstack-protector, with and without DynaGuard. The
canary bookkeeping code added by the DynaGuard plugin
is shown on the right (highlighted).
Figure 3 shows the bookkeeping instructions inserted by
the DynaGuard GCC plugin. Right after the function pro-
logue, before the canary gets pushed to the stack, the ad-
dress in which the canary will be stored must be saved in the
CAB. Initially, the address is loaded in the clobbered register
used for the canary stack placement (2). Subsequently, Dy-
naGuard retrieves the address of the CAB from the TLS (3)
}}......}ab......TLScanarypreviousframescanaryaddressbu(cid:31)ercanarypushcanaryreferencecanarycheck&(canary a)&(canary b)......=?&(can. a)&(can. b)......}}......}TLSabParent Process}}......}TLSabChild Processcanaryaddressbu(cid:31)er&(can. a)&(can. b)......canaryaddressbu(cid:31)er&(can. a)&(can. b)......canaryaddressbu(cid:31)er&(can. c)&(can. a)&(can. b)......canaryaddressbu(cid:31)er&(can. c)}}}......}TLSabcParent ProcessTLSabc}}}......}Child Process&(can. a)&(can. b)......canaryaddressbu(cid:31)er&(can. c)&(can. a)&(can. b)......canaryaddressbu(cid:31)er&(can. c)abc}}}......}TLSabcParent ProcessTLSabc}}}......}Child Process=?=?;function prologuepush   %rbpmov    %rsp,%rbpsub    $0x40,%rsp;canary stack placementmov    %fs:0x28,%raxmov    %rax,-0x8(%rbp)xor    %eax,%eax      ...;canary checkmov    -0x8(%rbp),%rcxxor    %fs:0x28,%rcxje     callq  Originalpush   %rbpmov    %rsp,%rbpsub    $0x40,%rsppush   %r14              (1)push   %r15lea    -0x8(%rbp),%rax    (2)mov    %fs:0x2a0,%r14    (3)mov    %fs:0x2a8,%r15    (4)mov    %rax,(%r14,%r15,8)  (5)incq   %fs:0x2a8    (6)pop    %r15    (7)pop     %r14   mov    %fs:0x2b8,%rax   (8)mov    %rax,-0x8(%rbp)xor    %eax,%eax    ...decq   %fs:0x2a8    (9)mov    -0x8(%rbp),%rcxxor    %fs:0x2b8,%rcx  (10)je     callq  DynaGuardand the index of the next element to be written (4). Next,
it stores the canary address in the CAB (5) and increments
the buﬀer index (6). Finally, the canary is fetched from the
TLS (8) and saved onto the stack. For this purpose, if no
registers are free, DynaGuard needs to spill two registers for
its bookkeeping ((1), (7)).1 Likewise, the canary check in
the function epilogue is modiﬁed to decrease the index in
CAB (9), and check against the DynaGuard canary instead
of the glibc canary (10).
5.1.2 Runtime Implementation
The code added by the DynaGuard GCC plugin assumes
that the respective entries in the TLS are properly initial-
ized, and that a canary address buﬀer with available space
exists. The logic for the CAB setup and update, as well as
the hooking of fork system calls and stack unwinding rou-
tines, is handled by DynaGuard’s runtime environment. The
library (PIC module) implementing that runtime is loaded
via the LD_PRELOAD mechanism into the address space of
the running application.
The CAB is allocated in the heap for each thread of the
running program. In order to allocate the CAB before the
main thread starts executing, we register—in the Dyna-
Guard runtime—a constructor routine to be called before
the main function of the application. This routine performs
the CAB allocation and sets the appropriate values in the
main thread’s TLS. For all other threads that get created,
DynaGuard hooks the pthread_create call and sets the
respective TLS entries prior to calling the start_routine
of each thread. Finally, a routine to free the allocated CAB
for each thread that ﬁnishes execution is registered via the
pthread_cleanup_push(/pop) mechanism.
To ensure that the CAB of each thread is never full, Dy-
naGuard marks the ﬁnal page in the CAB as read-only and
registers a signal handler for the SIGSEGV signal.