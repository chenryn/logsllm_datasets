# Browsing Unicity: On the Limits of Anonymizing Web Tracking Data

**Authors:**
- Clemens Deußer, Chair of Privacy and Security, TU Dresden, Germany
- Steffen Passmann, INFOnline GmbH, Berlin, Germany
- Thorsten Strufe, Karlsruhe Institute of Technology, Centre for Tactile Internet, TU Dresden

**Conference:**
2020 IEEE Symposium on Security and Privacy

## Abstract
Cross-domain tracking has become ubiquitous, with scripts collecting behavioral data from visitors across multiple sites. These collections form comprehensive profiles of browsing patterns, often containing personal and sensitive information. This data can easily be linked back to the tracked individuals, most of whom are likely unaware of its existence, storage, and processing. In response to public pressure, major tracking companies like Google, Facebook, and Baidu claim to anonymize their datasets, thereby limiting or eliminating the possibility of linking the data back to individuals.

In collaboration with Europe's largest audience measurement association, we assess both the identifiability and the feasibility of anonymizing browsing data using a comprehensive tracking dataset. Our results show that generalization techniques do not sufficiently protect anonymity. To reduce the unicity of browsing data to negligible levels, it would be necessary to remove all client and web domain information, as well as click timings. In realistic adversary scenarios, supposedly anonymized datasets are highly vulnerable to dataset enrichment and shoulder surfing adversaries, with almost half of all browsing sessions being identified by just two observations. We conclude that while it may be possible to store single coarsened clicks anonymously, any collection of higher complexity will contain large amounts of pseudonymous data.

## 1. Introduction
Behavioral tracking has become pervasive on the Web. More than four out of five websites employ some form of tracking, with the average page access being tracked by eight different scripts [1], [2]. While some sites use local tracking to optimize user experience, others use legitimate scripts for reliable audience and reach measurements. However, the majority of trackers are used to improve targeted advertising [3], [4].

The sensitivity of such data is well-known, with the request to clear one’s browser history in case of emergency having become part of contemporary folklore. A broad industry has been establishing increasingly comprehensive overviews of users' browsing histories across the entire Web. Upon visiting web pages, tracking scripts identify the browser across websites and store entire browsing profiles or sequences of observed visits as so-called click traces in vast tracking databases [5].

The usual response to inquiries about privacy is that the data has been anonymized, typically through generalization (e.g., truncation or "coarsening") of stored attributes such as IP addresses [6] or through differential privacy techniques. While differential privacy is a powerful tool that provides provable privacy guarantees, past implementations have often been misused or have led to severely restricted utility [7], [8].

In this paper, we focus on examining generalization techniques. Previous research by Narayanan et al. and others has shown that generalized data can still be de-anonymized [9], [10], [11]. Despite these findings, generalization techniques continue to be widely used in an industry that plays an increasingly ubiquitous role in modern society. Modern privacy regulations, such as the European GDPR, specifically enforce restrictions on the collection and processing of pseudonymous data, requiring informed consent. Storing a client browsing session as a sequence of website visits with very general page and client information, as audience measurement providers often do, appears to avoid these restrictions.

We argue that a combination of attributes and sequential information can be uniquely identifying, constituting an implicit pseudonym. Once enough elements of a browsing sequence have been observed, the entire session can be linked back to the data subject. Shoulder surfing—physically or through digital dossier aggregations—and the trading of supposedly anonymized data between tracking companies are examples where this fact can be exploited. This allows buyers to match unique partial traces to their own data, gaining access to the browsing history of data subjects they did not track themselves, thus evading consent and data protection rules.

In this paper, we aim to show how easily such pseudonyms can manifest and investigate whether the techniques applied by industry can prevent the emergence of pseudonyms in tracking databases. Specifically, we ask:
1. How frequently do pseudonyms emerge in anonymized tracking data?
2. How easily can tracking data be linked to secondary sources?

We analyze an obfuscated sample of data from the largest technical provider for German Audit Bureaus of Circulation, one of Europe's largest providers for audience measurement services. The analyzed sample contains 65.2 million clients and over 2.3 billion page impressions. We adhere to industry standards for data treatment to generate a database of click traces. Following the rationale of IP address truncation, we successively reduce click trace length and the level of detail of the available information per click, including visited page, timestamp, and browser-collected data.

We then calculate the unicity, the fraction of unique click traces, as a measure of how pseudonymous the data is. We argue that a unique browsing session is, by itself, a pseudonym and thus cannot be anonymous. To test anonymity in a more practical vein, we also act as an adversary in the two scenarios mentioned above—shoulder surfing and data exchange enrichment.

Given the highly sensitive and private nature of the data, we take our responsibility seriously. The data was accessed solely through scripts run locally on the database servers, directly generating the results presented here. As a result, we do not have direct access to the data and cannot provide it. Verification of our results can still be facilitated through the same method, at the discretion of the database owner.

## 2. Background
Web browsing behavior is processed for various reasons. Web developers parse web server access log files and use local, per-domain tracking scripts like Matomo (formerly Piwik) to optimize the browsing experience on their websites. Site analytics and cross-domain tracking (Google, Facebook, Yandex Metrica, etc.) provide similar functionality but collect browsing behavior across several sites, mainly to improve advertisement accuracy and enable features like retargeting. Some of these trackers are present in the vast majority of popular websites [2]. Smaller tracking companies extend their data by trading with competitors, and user data exchanges provide markets where buyers can bid for specific user profiles [12].

Another reason for tracking is audience measurement [13]. Publishers and advertisers require independent third parties, such as Audit Bureaus of Circulation (ABCs), to verify the popularity of sites and their claimed number of visits. ABCs measure the performance of advertising media to provide indicators of the relevance of different outlets.

### 2.1. Internet Audience Measurement
Audience measurement is traditionally conducted through panels or full evaluations. For this paper, we focus on the latter, which implements a census measurement similar to web tracking. Technically, this is achieved by injecting JavaScript snippets ("tags") into the code of a web page. When the page is rendered on the client system, the script collects and sends information to the tracker.

The requirement for cross-market data leads to the implementation of a third-party approach, using both third-party JavaScript and third-party cookies. When integrating the script into the website, the publisher provides an identifier for the website as a whole (website-identifier) and an identifier for the specific, visited page (code).

The transmitted dataset is received by a web server of the measuring system. It is then enriched and stored as a tuple of the client ID (extracted from a cookie), the geolocation of the client (queried based on its IP address, to an accuracy of the federal state level), and a timestamp. The user agent is converted to an estimated "device type" using a corresponding database.

Publishers provide further information, including the categorization of all pages according to the standards of the International Federation of ABCs (IFABC). For each unique combination of website-identifier and code, the publisher provides features such as the category of the content (news, social, sports, politics), the creator (editorial content, user-provided), the language, whether it is paid content, whether it is the entry-page, and for which device the exact page was optimized (desktop, mobile).

ABCs publish essential results of activity on measured sites, usually the number of page impressions, visits, and clients. The IFABC defines a page impression as "every user-induced action (e.g., a click) that leads to a significant change in the view." Visits are defined as sessions of consecutive page impressions with an inter-arrival time of 1800 seconds (30 minutes) or less. Clients represent unique, returning visitors. Several visits can correspond to the same client, and since client IDs change (e.g., when cookies are deleted or various devices are used), a multitude of measured clients can correspond to the same individual.

Tracking databases essentially contain sequences of action entries, each consisting of extensive client and page information, such as IP address, unique ID (cookie), user agent, visited URL, page category, timestamp, and more. IP addresses are now truncated due to privacy regulations prohibiting the processing of explicit identifying information without consent.

### 2.2. Pseudonymity and Threats
Browsing data is highly sensitive, especially for cross-domain tracking. The same trackers from a few large companies are found in the majority of websites offering medical advice, information on planned parenthood, opinion formation, political discussion, even pornographic content, and web search and social networking [2]. Activities across these sites are linked by their client ID to sessions in the tracking databases. Some entries may contain plaintext pseudonyms or even names as parameters of stored URLs.

Tracking companies contest concerns about identifiability, maintaining that they anonymize their databases. However, even when measures such as IP address truncation and removal of URL parameters and other directly identifying information are correctly and faithfully applied, the data may not be truly anonymized. The stored data pertaining to an individual remains pseudonymous as long as the connection to the data subject is unique. As long as this pseudonym exists, it can, in principle, be linked back to the individual identity. More sophisticated techniques and larger databases in the future could potentially retroactively expose pseudonyms in today's databases. Privacy regulations, such as the GDPR, impose severe restrictions on the use of data that is not strictly anonymous. The GDPR inversely defines "anonymous" as "the data subject is no longer identifiable," requiring that data subjects can no longer be linked to the data, which precludes the existence of pseudonyms.

In this paper, we follow the interpretation of the GDPR and consider any information that implicitly identifies an individual a pseudonym. The stored client ID that ties the clicks of sessions together represents such a pseudonym. However, being assigned randomly, it may not be easy to link it back to individuals. The behavior encoded in the click trace, on the other hand, may also represent a pseudonym. This holds for all unique click traces, which must be considered pseudonyms in themselves. Furthermore, we expect that external information exists in abundance that can be used to link these pseudonyms back to individuals.