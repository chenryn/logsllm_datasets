title:Browsing Unicity: On the Limits of Anonymizing Web Tracking Data
author:Clemens Deußer and
Steffen Passmann and
Thorsten Strufe
2020 IEEE Symposium on Security and Privacy
Browsing Unicity: On the Limits of
Anonymizing Web Tracking Data
Clemens Deußer
Chair of Privacy and Security
TU Dresden, Germany
Steffen Passmann
INFOnline GmbH
Berlin, Germany
Thorsten Strufe
Karlsruhe Institute of Technology
Centre for Tactile Internet, TU Dresden
Email: PI:EMAIL
Email: PI:EMAIL
Email: PI:EMAIL
Abstract—Cross domain tracking has become the rule, rather
than the exception, and scripts that collect behavioral data from
visitors across sites have become ubiquitous on the Web. The
collections form comprehensive proﬁles of browsing patterns and
contain personal, sensitive information. This data can easily be
linked back to the tracked individuals, most of whom are likely
unaware of this information’s mere existence, let alone its per-
petual storage and processing. As public pressure has increased,
tracking companies like Google, Facebook, or Baidu now claim
to anonymize their datasets, thus limiting or eliminating the
possibility of linking it back to data subjects.
In cooperation with Europe’s largest audience measurement
association we use access to a comprehensive tracking dataset
to assess both identiﬁability and the possibility of convincingly
anonymizing browsing data. Our results show that anonymization
through generalization does not sufﬁciently protect anonymity.
Reducing unicity of browsing data to negligible levels would
necessitate removal of all client and web domain information as
well as click timings. In tangible adversary scenarios, supposedly
anonymized datasets are highly vulnerable to dataset enrichment
and shoulder surﬁng adversaries, with almost half of all browsing
sessions being identiﬁed by just two observations. We conclude
that while it may be possible to store single coarsened clicks
anonymously, any collection of higher complexity will contain
large amounts of pseudonymous data.
I. INTRODUCTION
Tracking has become pervasive on the Web. More than
four out of ﬁve sites employ behavioral tracking, some on
a large scale, with dozens of different scripts tracking their
users at the same time [1], [2]. The average page access
on the Web is tracked by eight scripts, today1. Some sites
employ local tracking to optimize their user experience, others
use legitimate scripts to perform reliable audience and reach
measurements. The majority of trackers, however, is used to
presumably improve targeted advertisement [3], [4].
While the request to clear one’s browser history in case of
emergency has made it into contemporary folklore due to how
sensitive such data is, a broad industry has been establishing
increasingly comprehensive overviews of browsing histories
of users across essentially the entire Web. Upon visits to Web
pages, tracking scripts identify the browser across websites
This work has in parts been supported by the German Research Foundation
DFG, the Cluster of Excellence EXC 2050/1 ”Centre for Tactile Internet”
(CeTI) as part of Germany’s Excellence Strategy, and INFOnline GmbH.
1https://www.whotracks.me
and store entire browsing proﬁles or sequences of observed
visits as so called click traces in vast tracking databases [5].
The usual reﬂex to inquiry is the statement that this data
was anonymized, usually through generalization (truncation,
or “coarsening”) of stored attributes, such as IP addresses [6]
or through differential privacy techniques. Differential privacy
is a powerful tool which delivers provable privacy guarantees.
In this paper we will not examine practical implementations
of differential privacy, but in the past they have often been
either misused (eg. through lack of a properly enforced privacy
budget) or have lead to severely restricted utility [7], [8].
Instead we will focus on examining generalization techniques.
Whether and how generalized data can be de-anonymized
has been extensively researched by Narayanan et al. and
others in the past [9], [10], [11]. Nevertheless, anonymization
through generalization techniques not only continue to be
used, but the industry in which they are applied plays an
increasingly ubiquitous role in modern society. Their position
is that
these results are not universally valid and do not
apply to other methods of generalization on different kinds
of data. In this work we will attempt to close that gap as it
relates to web tracking data. More speciﬁcally, both structural
information, such as position in a social graph, as well as
pseudonyms in general have been shown to be highly identi-
fying. In recognition of this fact, modern privacy regulations
like the European GDPR speciﬁcally enforce restrictions such
as obtaining informed consent before allowing collection and
processing of pseudonymous data. Storing a client browsing
session as a sequence of website visits with very general page
and client information, as audience measurement providers
often do, appears to avoid these restrictions.
We argue that a combination of attributes and sequential
information can be uniquely identifying as well and thus
constitutes an implicit pseudonym. Once enough elements of a
browsing sequence have been observed, the entire session can
be linked back to the data subject. Shoulder surﬁng - physically
or through digital dossier aggregations - is one example where
this fact can be exploited. Another is the trading of suppos-
edly anonymized data between tracking companies, where the
buyer can match unique partial traces to their own data. In that
way they gain access to the browsing history of data subjects
they did not track themselves, evading the obtaining of consent
and data protection rules.
© 2020, Clemens Deußer. Under license to IEEE.
DOI 10.1109/SP40000.2020.00018
777
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:30 UTC from IEEE Xplore.  Restrictions apply. 
In this paper we will not only attempt to show how easily
such pseudonyms can manifest, but we will also investigate
whether the techniques applied by industry can prevent the
emergence of pseudonyms in tracking databases at all. More
speciﬁcally, we ask ourselves the following two questions:
(1) How frequently do pseudonyms emerge in anonymized
tracking data? and (2) How easily can tracking data be linked
to secondary sources? In this course we aim to understand to
which extent coarsening the available data can actually help
to reduce identiﬁability.
We analyze an obfuscated sample of the data of the largest
technical provider for German Audit Bureaus of Circulation,
one of Europe’s largest providers for audience measurement
services. The analyzed sample contains 65.2 million clients
and over 2.3 billion page impressions. We adhere to industry
standards for data treatment to generate a database of click
traces. Following the rationale of IP address truncation, we
then successively reduce click trace length as well as the
level of detail of the available information per click; including
information about the visited page, the timestamp, and data
collected from the browser.
We then calculate the unicity, the fraction of unique click
traces, as a measure of how pseudonymous the data is. We
argue that a unique browsing session is by itself a pseudonym
and thus cannot be anonymous. To test anonymity in a more
practical vein we also act as an adversary in the two scenarios
mentioned above - shoulder surﬁng and data exchange enrich-
ment.
As we have already acknowledged, the data we analyze
is highly sensitive and private. We take the responsibility
of working with such data very seriously. The data was
accessed solely through scripts run locally on the database
servers, directly generating the results we present here. As
a consequence we do not have direct access to said data
and cannot provide it. Veriﬁcation of our results can still be
facilitated through the same method we used, at the discretion
of the database owner.
II. BACKGROUND
Web browsing behavior is processed for different reasons.
To optimize the browsing experience on their website, web
developers have long parsed web server access log ﬁles, and
later turned to entirely local, per domain tracking scripts, like
Matomo (formerly Piwik)2.
Site analytics and cross domain tracking (Google, Face-
book, Yandex Metrica, etc.) provide web developers with sim-
ilar functionality. Their business model is based on collecting
browsing behavior across several sites, mainly to improve
advertisement accuracy and allow extended features like retar-
geting. Their reach varies. Some have managed to be present
in the vast majority of the popular Web [2]. Smaller tracking
companies started to extend their data by trading tracking data
with competitors. User data exchanges provide such markets,
buyers can even bid for the proﬁles of speciﬁc users [12]. This
2https://matomo.org
market has grown to dozens of providers. So meta tools have
emerged that manage the combination of trackers that are used
for speciﬁc page calls, based on chosen policies3.
Another reason is audience measurement [13]. The market
of publishers and advertisers on the Web requires independent
third parties. These ABCs (Audit Bureau of Circulation)
verify the popularity of sites, and their claimed number of
visits. They measure the performance of advertising media,
to provide the advertisement market with indicators of the
relevance of the different outlets.
A. Internet Audience Measurement
Audience measurement is traditionally conducted with pan-
els or full evaluations. For this paper, we focus on the latter,
as it implements a census measurement similar to Web track-
ing. Technically, this is implemented by injecting JavaScript
snippets (“tags”) into the code of a Web page. It collects and
sends information to the tracker when the page is rendered on
the client system.
The requirement for cross-market data leads to the imple-
mentation of a third-party approach. Hence, both third-party
JavaScript and third-party cookies are used4. When integrating
the script into the website, the publisher provides two essential
pieces of information in the html-tag. An identiﬁer for the
website as a whole (website-identiﬁer) and an identiﬁer for
the speciﬁc, visited page, called “code”.
The transmitted dataset is received by a web server of the
measuring system. It is then enriched and stored as a tuple
of the client ID (extracted from a cookie), the geolocation of
the client (as queried based on its IP address, to an accuracy
of the federal state level), and a timestamp. Similarly, the
user agent is converted to an estimated “device type” using
a corresponding database.
The publisher provides further information. This includes
the categorization of all pages contained in their site, according
to the standards of the International Federation of ABCs
(IFABC).For each unique combination of website-identiﬁer
and code, the publisher provides a number of features. These
include the category of the content (news, social, sports,
politics5),
the creator
(editorial content, user-provided), the language, whether it is
paid content, whether it is the entry-page (i.e. index.html)
and for which device the exact page was optimized (desktop,
mobile).
the media (image and text, video),
ABCs then publish the essential results of activity on the
measured sites, which is usually the number of page impres-
sions, visits, and clients. The IFABC deﬁnes a page impression
as ”[...] every user-induced action (e.g. a click) that leads to
a signiﬁcant change in the view [...]”. This deﬁnition includes
scrolling pages with progressive loading. Visits are deﬁned as
3https://marketingplatform.google.com/about/tag-manager/
4Browser developers have recently started to prevent 3rd-party cookies, so
many large trackers now turn to integrating 1st party content to the pages,
thus being able to also set 1st-party cookies, or to exploit session resumption
of TLS [14].
5https://support.aerserv.com/hc/en-us/articles/207148516-List-of-IAB-
Categories
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:12:30 UTC from IEEE Xplore.  Restrictions apply. 
778
sessions of consecutive page impressions with an inter-arrival
time of 1800 seconds (30 minutes) or less. Clients represent
unique, returning visitors. Several visits can correspond to the
same client, and since client IDs change (e.g. when cookies
are deleted or various devices used), a multitude of measured
clients can correspond to the same individual.
Tracking databases essentially contain sequences of action
entries. Each entry traditionally consists of extensive client
and page information, such as IP address, unique ID (cookie),
user agent, visited URL, page category (topical), timestamp
and many more6. IP addresses nowadays are truncated as
privacy regulations prohibit processing of explicit identifying
information without consent.
B. Pseudonymity and Threats
Browsing data is highly sensitive. This is especially true
for cross domain tracking: the same trackers from very few,
large companies are found in the majority of websites offering
medical advice, information on planned parenthood, opinion
formation, political discussion, even pornographic content,
and also web search and social networking [2]. Activities
across these sites are linked by their client ID to sessions
in the tracking databases. Some entries may contain plaintext
pseudonyms or even names as parameters of stored URLs.
to identify individuals, and that
Tracking companies contest such concerns, maintaining that
they do not attempt
they
anonymize their databases. However, even when measures
such as IP address truncation and removal of URL parameters
and other directly identifying information are correctly and
faithfully applied, they may not actually anonymize the data.
This is because the stored data pertaining to an individual
remains pseudonymous as long as the connection to the data
subject is unique. Meaning there is no other individual exhibit-
ing the exact same data signature. As long as this pseudonym
exists, it can in principle be linked back to the individual
identity. While we will present tangible scenarios as to how
this can happen even today, it is clear that more sophisticated
techniques and more massive databases will be available in
the future and potentially retroactively expose pseudonyms in
today’s databases. Privacy regulations therefore impose severe
restrictions on the use of data that is not strictly anonymous.
The GDPR for instance inversely deﬁnes “anonymous” as “the
data subject is no longer identiﬁable”. It thus requires that data
subjects can no longer be linked against the data, which also
precludes the existence of pseudonyms.
In this paper, we follow the interpretation of the GDPR and
consider any information that implicitly identiﬁes an individual
a pseudonym. The stored client ID that ties the clicks of
sessions together of course represents such a pseudonym.
However, being assigned randomly, it may not be easy to link
it back to individuals. The behavior as encoded in the click
trace on the other hand may also represent a pseudonym. This
clearly holds for all unique click traces, which therefore have
6Overviews are at https://developer.matomo.org/api-reference/tracking-api
or https://developers.google.com/analytics/devguides/collection/protocol/v1/
parameters.
to be considered pseudonyms in themselves. Furthermore,
we expect that external information exists in abundance that