nm
objcopy
objdump
readelf
func-
func
5.2%
4.0% (-1.2%)
8.2%
7.5% (-0.7%)
7.5%
7.3% (-0.2%)
18.9% 15.8% (-3.1%)
TortoiseFuzz-Bin
bb-
bb
5.2%
4.8% (-0.4%)
8.3%
7.4% (-0.9%)
7.3%
7.3% (-0.0%)
18.4% 15.7% (-2.7%)
loop-
loop
5.3%
4.5% (-0.8%)
8.5%
7.0% (-1.5%)
7.5%
7.5% (-0.0%)
18.7% 15.50% (-3.2%)
Code coverage
AFL-Qemu
aﬂ-
aﬂ
3.9% (-1.4%)
5.3%
6.2% (-2.6%)
8.8%
7.4% (-0.4%)
7.8%
20.5% 12.6% (-7.9%)
B. The Threshold for Security-sensitivity
We currently set a uniﬁed threshold for deciding security-
sensitive edges: an edge is security-sensitive if one of the
three metrics’ value is above 0. Ideally, the threshold should
be speciﬁc to programs. Future work would be to design
approaches to automatically generate the threshold for each
program through static analysis or during the fuzzing execu-
tion.
C. LAVA-M vs. Real-world Data Set
In our experiment, we observed that the LAVA-M test
suite is different from the real-world program test suite in two
aspects. First, LAVA-M has more test cases involving magic
words, which makes the test suite biased in testing exploit
generation tools. Second, the base binaries for LAVA-M are
not as complex as the real-world programs we tested. We
acknowledge the value of the data set; yet a future direction
is to systematically compare the inserted bugs in LAVA-M
against a large number of real-world programs, understand the
difference and the limitation of the current test suite, and build
a test suite that is more comprehensive and more representative
to real-world situations.
D. Statistical Signiﬁcance of #Vulnerabilities per Program
In our evaluation, we did not report the statistical sig-
niﬁcance between TortoiseFuzz and other fuzzers in terms
of the number of vulnerabilities found per program. On the
contrary to the per-program p-value in code coverage shown in
Table VI and represented in REDQUEEN [4], vulnerabilities
are very sparse in one vulnerabilities. Therefore, it is hard
to tell
the effectiveness difference among fuzzers from a
single program. For example, for the flvmeta program, the
statistical signiﬁcance among all tools are inconclusive, since
all tools found 2 vulnerabilities across all runs. Therefore, we
report the p-value of the total number of vulnerabilities found
from all target programs. This also indicates the necessity of
having a comprehensive data suite with a sufﬁcient number
of vulnerabilities.
VIII. RELATED WORK
Plenty of techniques have been presented to improve
fuzzing in different aspects since the concept of fuzzing was
developed in 1990s [38]. In this section, we introduce some of
the presented fuzzing techniques. For a more comprehensive
study on fuzzing techniques, please refer to recent surveys
such as Chen et al. [10], Li et al. [32], and Manès et al [37].
Fuzzing speciﬁc program types. Some fuzzing techniques
focus on speciﬁc types of programs, based on which they
propose more effective fuzzing techniques. These studies
include fuzzing on protocol [5, 14], ﬁrmware [11, 17, 39],
and OS kernel [13, 45, 51, 57].
Hardware-assisted fuzzing. Previous work proposes various
approaches to increase the efﬁciency of the fuzzing process.
Xu et al. [56] designs three new operating primitives to remove
execution redundancy and improve the performance of AFL
in running testing inputs. Hardware-based fuzzing, such as
kAFL [45] and PTfuzz [61], leverages hardware features such
as Intel Processor Trace [25] to guide fuzzing without the
overhead caused by instrumentation. These techniques de-
creases the time spent on program execution and information
extraction, so that fuzzers can explore more inputs within a
given amount of time.
Generational fuzzing. Besides mutation fuzzing, generational
fuzzers also play an important role to test programs and ﬁnd
security vulnerabilities. Fuzzers such as Peach [16], Sulley [3],
and SPIKE [2], generate samples based on a pre-deﬁned
conﬁguration which speciﬁes the input format. As generational
fuzzers requires a format conﬁguration which typically is
generated manually, these fuzzers are less generic and depend
on human efforts.
14
Machine learning-assisted fuzzing. Recent works, such as
Skyﬁre [52], Learn&fuzz [22], and NEUZZ [48], combines
fuzzing with machine learning and artiﬁcial intelligence. They
learn the input formats or the relationships between input and
program execution, and use the learned result to guide the
generation of testing inputs. Such fuzzers, though, usually
cause high overhead, because of the involvement of machine
learning processing.
Static analysis and its assistance on fuzzing. Dowser [24]
performs static analysis at compile time to ﬁnd vulnerable
code like loops and pointers, so as QTEP [54]. Sparks et
al. [49] extracts the control ﬂow graphs from the target to
help input generation. Steelix [33] and VUzzer [43] analyze
magic values, immediate values, and strings that can affect
control ﬂow.
Dynamic analysis and its assistance on fuzzing. Dynamic
analysis including symbolic execution and taint analysis help
enhance fuzzing. Taint analysis is capable of showing the rela-
tionship between input and program execution. BuzzFuzz [19],
TaintScope [55], and VUzzer [43] use this technique to ﬁnd
relevant bytes and reduce the mutation space. Symbolic exe-
cution helps exploring program states. KLEE [8], SAGE [21],
MoWF [42], and Driller [50] use this technique to execute
into deeper logic. To solve the problems such as path explo-
sion and constraint complexity, SYMFUZZ [9] reduces the
symbolized input bytes by taint analysis, while Angora [12]
performs a search inspired by gradient descent algorithm
during constraint solving. Another problem is that program
analysis will cause extra overhead. REDQUEEN [4] leverages
a lightweighted taint tracking and symbolic execution method
for optimization.
IX. CONCLUSION
In this paper, we propose TortoiseFuzz, an advanced
coverage-guided fuzzer with a novel technique called coverage
accounting for input prioritization. Based on the insight that
the security impact on memory corruption vulnerabilities can
be represented with memory operations, and that memory op-
erations can be abstracted at different levels, we evaluate edges
based on three levels, function call, loop, and basic block. We
combine the evaluation with coverage information for input
prioritization. In our experiments, we tested TortoiseFuzz with
6 greybox and hybrid fuzzers on 30 real-world programs,
and the results showed that TortoiseFuzz outperformed all but
one hybrid fuzzers, yet spent only 2% of memory resources.
Our experiments also showed that coverage accounting was
able to defend against current anti-fuzzing techniques. In
addition, TortoiseFuzz identiﬁed 20 zero-day vulnerabilities,
15 of which have been conﬁrmed and released with CVE IDs.
ACKNOWLEDGEMENT
We thank the anonymous reviewers of this work for
their helpful feedback. We also thank Peng Chen, Xiaoning
Du, Jinho Jung, Cornelius Aschermann and other authors of
Angora, LEAPORD, Fuzziﬁcation and Redqueen for their
help with experiments. This research is supported, in part,
by National Natural Science Foundation of China (Grant No.
U1736209), Peng Cheng Laboratory Project of Guangdong
Province PCL2018KP004. Dinghao Wu’s research was sup-
ported in part by the PNC Technologies Career Development
15
Professorship. All opinions expressed in this paper are solely
those of the authors.
REFERENCES
[1] A. V. Aho, R. Sethi, and J. D. Ullman, “Compilers:
Principles, techniques, and tools,” Addison wesley, 1986.
[2] D. Aitel, “An introduction to spike, the fuzzer creation
kit,” presentation slides, Aug, 2002.
[3] P. Amini and A. Portnoy, “Sulley fuzzing framework,”
http://www.fuzzing.org/wp-content/SulleyManual.pdf,
[2019-6-1].
[4] C. Aschermann, S. Schumilo, T. Blazytko, R. Gawlik,
and T. Holz, “REDQUEEN: Fuzzing with input-to-state
correspondence,” in Proceedings of
the Network and
Distributed System Security Symposium, 2019.
[5] G. Banks, M. Cova, V. Felmetsger, K. Almeroth,
R. Kemmerer, and G. Vigna, “SNOOZE: Toward a
stateful network protocol fuzzer,” in Proceedings of the
9th International Conference on Information Security.
Springer-Verlag, 2006.
[6] M. Böhme, V.-T. Pham, M.-D. Nguyen, and A. Roy-
choudhury, “Directed greybox fuzzing,” in Proceedings
of the 2017 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2017.
[7] M. Böhme, V.-T. Pham,
and A. Roychoudhury,
“Coverage-based greybox fuzzing as Markov chain,” in
Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2016.
[8] C. Cadar, D. Dunbar, D. R. Engler et al., “KLEE:
Unassisted and automatic generation of high-coverage
tests for complex systems programs,” in Proceedings
of the 8th USENIX Conference on Operating Systems
Design and Implementation.
USENIX Association,
2008.
[9] S. K. Cha, M. Woo, and D. Brumley, “Program-adaptive
mutational fuzzing,” in Proceedings of the 2015 IEEE
Symposium on Security and Privacy.
IEEE, 2015.
[10] C. Chen, B. Cui, J. Ma, R. Wu, J. Guo, and W. Liu, “A
systematic review of fuzzing techniques,” Computers &
Security, 2018.
[11] J. Chen, W. Diao, Q. Zhao, C. Zuo, Z. Lin, X. Wang,
W. C. Lau, M. Sun, R. Yang, and K. Zhang, “IoTFuzzer:
Discovering memory corruptions in IoT through app-
based fuzzing,” in NDSS, 2018.
[12] P. Chen and H. Chen, “Angora: Efﬁcient fuzzing by
principled search,” in Proceedings of the 2018 IEEE
Symposium on Security and Privacy.
IEEE Computer
Society, 2018.
[13] J. Corina, A. Machiry, C. Salls, Y. Shoshitaishvili,
S. Hao, C. Kruegel, and G. Vigna, “DIFUZE: Interface
aware fuzzing for kernel drivers,” in Proceedings of
the 2017 ACM SIGSAC Conference on Computer and
Communications Security. ACM, 2017.
[14] J. De Ruiter and E. Poll, “Protocol state fuzzing of TLS
implementations,” in Proceedings of the 24th USENIX
Conference on Security Symposium. USENIX Associ-
ation, 2015.
[15] X. Du, B. Chen, Y. Li, J. Guo, Y. Zhou, Y. Liu,
and Y. Jiang, “Leopard: Identifying vulnerable code for
vulnerability assessment through program metrics,” in
Proceedings of
Software Engineering.
the 41st International Conference on
IEEE Press, 2019.
[16] M. Eddington,
“Peach fuzzing platform,” https://
www.peach.tech/products/peach-fuzzer/peach-platform/,
[2019-6-1].
[17] Q. Feng, R. Zhou, C. Xu, Y. Cheng, B. Testa, and H. Yin,
“Scalable graph-based bug search for ﬁrmware images,”
in Proceedings of the 2016 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2016.
[18] S. Gan, C. Zhang, X. Qin, X. Tu, K. Li, Z. Pei, and
Z. Chen, “Collaﬂ: Path sensitive fuzzing,” in Proceedings
of the 2018 IEEE Symposium on Security and Privacy.
IEEE, 2018.
[19] V. Ganesh, T. Leek, and M. Rinard, “Taint-based directed
the 31st Inter-
IEEE
whitebox fuzzing,” in Proceedings of
national Conference on Software Engineering.
Computer Society, 2009.
test
[20] gcov,
program,”
coverage
“a
https://gcc.gnu.org/onlinedocs/gcc/Gcov.html#Gcov,
fetched 2020.
[21] P. Godefroid, M. Y. Levin, and D. Molnar, “SAGE:
Whitebox fuzzing for security testing,” Queue, 2012.
[22] P. Godefroid, H. Peleg, and R. Singh, “Learn&#38;Fuzz:
Machine learning for input fuzzing,” in Proceedings
of
the 32Nd IEEE/ACM International Conference on
Automated Software Engineering. Piscataway, NJ, USA:
IEEE Press, 2017.
[23] E. Güler, C. Aschermann, A. Abbasi, and T. Holz, “An-
tiFuzz: Impeding fuzzing audits of binary executables,”
in Proceedings of the 28th USENIX Security Symposium,
2019.
[24] I. Haller, A. Slowinska, M. Neugschwandtner, and
H. Bos, “Dowsing for overﬂows: A guided fuzzer to ﬁnd
buffer boundary violations,” in Proceedings of the 22Nd
USENIX Conference on Security. USENIX Association,
2013.
[25] Intel, “Processor Tracing,” https://software.intel.com/en-
us/blogs/2013/09/18/processor-tracing, 2013.
[26] V. Jain, S. Rawat, C. Giuffrida, and H. Bos, “TIFF: Using
input type inference to improve fuzzing,” in Proceedings
of the 34th Annual Computer Security Applications Con-
ference. ACM, 2018.
[27] X. Jia, C. Zhang, P. Su, Y. Yang, H. Huang, and
D. Feng, “Towards efﬁcient heap overﬂow discovery,” in
Proceedings of the 26th USENIX Security Symposium.
USENIX Association, 2017.
[28] J. Jung, H. Hu, D. Solodukhin, D. Pagan, K. H. Lee,
and T. Kim, “Fuzziﬁcation: Anti-fuzzing techniques,” in
Proceedings of the 28th USENIX Security Symposium,
2019.
[29] G. Klees, A. Ruef, B. Cooper, S. Wei, and M. Hicks,
“Evaluating fuzz testing,” in Proceedings of the 2018
ACM SIGSAC Conference on Computer and Communi-
cations Security. ACM, 2018.
[30] C. Lattner and V. Adve, “LLVM: A compilation frame-
work for lifelong program analysis & transformation,”
in Proceedings of the international symposium on Code
generation and optimization: feedback-directed and run-
time optimization.
IEEE Computer Society, 2004.
[31] C. Lemieux and K. Sen, “FairFuzz: a targeted mutation
strategy for increasing greybox fuzz testing coverage,”
in Proceedings of
the 33rd ACM/IEEE International
16
Conference on Automated Software Engineering, 2018.
[32] J. Li, B. Zhao, and C. Zhang, “Fuzzing: A survey,”
Cybersecurity, 2018.
[33] Y. Li, B. Chen, M. Chandramohan, S.-W. Lin, Y. Liu, and
A. Tiu, “Steelix: program-state based binary fuzzing,” in
Proceedings of the 2017 11th Joint Meeting on Founda-
tions of Software Engineering. ACM, 2017.
[34] Z. Li, D. Zou, S. Xu, H. Jin, H. Qi, and J. Hu,
“VulPecker: An automated vulnerability detection sys-
tem based on code similarity analysis,” in Proceedings
of the 32nd Annual Conference on Computer Security
Applications, 2016.
[35] Z. Li, D. Zou, S. Xu, X. Ou, H. Jin, S. Wang, Z. Deng,
and Y. Zhong, “Vuldeepecker: A deep learning-based
system for vulnerability detection,” in 25th Annual Net-
work and Distributed System Security Symposium, NDSS
2018, San Diego, California, USA, February 18-21,
2018, 2018.
[36] C. Lyu, S. Ji, C. Zhang, Y. Li, W.-H. Lee, Y. Song, and
R. Beyah, “MOPT: Optimized mutation scheduling for
fuzzers,” in Proceedings of the 28th USENIX Security
Symposium. USENIX Association, 2019.
[37] V. J. M. Manès, H. Han, C. Han, S. K. Cha, M. Egele,
E. J. Schwartz, and M. Woo, “Fuzzing: Art, science, and
engineering,” CoRR, 2018.
[38] B. P. Miller, L. Fredriksen, and B. So, “An empirical
study of the reliability of UNIX utilities,” Comm. ACM,
1990.
[39] M. Muench, J. Stijohann, F. Kargl, A. Francillon, and
D. Balzarotti, “What you corrupt is not what you crash:
Challenges in fuzzing embedded devices,” in Proceed-
ings of the Network and Distributed System Security
Symposium (NDSS), 2018.
[40] S. Neuhaus, T. Zimmermann, C. Holler, and A. Zeller,
“Predicting vulnerable software components,” in Pro-
ceedings of the 14th ACM Conference on Computer and
Communications Security, 2007.
[41] H. Perl, S. Dechand, M. Smith, D. Arp, F. Yamaguchi,
K. Rieck, S. Fahl, and Y. Acar, “Vccﬁnder: Finding
potential vulnerabilities in open-source projects to assist
code audits,” in Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security,
2015.
[42] V.-T. Pham, M. Böhme, and A. Roychoudhury, “Model-
based whitebox fuzzing for program binaries,” in Pro-
ceedings of the 31st IEEE/ACM International Conference
on Automated Software Engineering. ACM, 2016.
[43] S. Rawat, V. Jain, A. Kumar, L. Cojocar, C. Giuffrida,
and H. Bos, “VUzzer: Application-aware evolutionary
fuzzing,” in Proceedings of the 24th Network and Dis-
tributed System Security Symposium.
The Internet
Society, 2017.
[44] R. Scandariato, J. Walden, A. Hovsepyan, and W. Joosen,
“Predicting vulnerable software components via text
mining,” IEEE Transactions on Software Engineering,
2014.
[45] S. Schumilo, C. Aschermann, R. Gawlik, S. Schinzel,
and T. Holz, “kAFL: Hardware-assisted feedback fuzzing
for OS kernels,” in 26th USENIX Security Symposium
(USENIX Security 17). USENIX Association, 2017.
[46] K. Serebryany, D. Bruening, A. Potapenko,
and
D. Vyukov, “AddressSanitizer: A fast address sanity
checker,” in Usenix Conference on Technical Conference,
2012.
[47] K. Serebryany, “Continuous fuzzing with libfuzzer and
addresssanitizer,” IEEE, 2016.
[48] D. She, K. Pei, D. Epstein, J. Yang, B. Ray, and
S. Jana, “NEUZZ: Efﬁcient fuzzing with neural program
smoothing,” in Proceedings of the 2018 IEEE Symposium
on Security and Privacy.
IEEE, 2018.
[49] S. Sparks, S. Embleton, R. Cunningham, and C. Zou,
“Automated vulnerability analysis: Leveraging control
ﬂow for evolutionary input crafting,” in Twenty-Third
Annual Computer Security Applications Conference (AC-
SAC 2007), 2007.
[50] N. Stephens, J. Grosen, C. Salls, A. Dutcher, R. Wang,
J. Corbetta, Y. Shoshitaishvili, C. Kruegel, and G. Vigna,
“Driller: Augmenting fuzzing through selective symbolic
execution,” in Proceedings of
the 23rd Network and
Distributed Systems Security Symposium. The Internet
Society, 2016.
[51] D. Vyukov,
https://github.com/google/
“syzkaller,”
syzkaller, fetched 2020.
[52] J. Wang, B. Chen, L. Wei, and Y. Liu, “Skyﬁre: Data-
driven seed generation for fuzzing,” in 2017 IEEE Sym-
posium on Security and Privacy (SP), 2017.
[53] J. Wang, Y. Duan, W. Song, H. Yin, and C. Song,
“Be sensitive and collaborative: Analyzing impact of
coverage metrics in greybox fuzzing,” in 22nd Interna-
tional Symposium on Research in Attacks, Intrusions and
Defenses (RAID 2019). USENIX Association, 2019.
[54] S. Wang, J. Nam, and L. Tan, “QTEP: Quality-aware
test case prioritization,” in Proceedings of the 2017 11th
Joint Meeting on Foundations of Software Engineering.
ACM, 2017.
[55] T. Wang, T. Wei, G. Gu, and W. Zou, “TaintScope:
A checksum-aware directed fuzzing tool for automatic
software vulnerability detection,” in Proceedings of the
2010 IEEE Symposium on Security and Privacy.
IEEE
Computer Society, 2010.
[56] W. Xu, S. Kashyap, C. Min, and T. Kim, “Designing new
operating primitives to improve fuzzing performance,” in
Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security. ACM, 2017.
[57] W. Xu, H. Moon, S. Kashyap, P.-N. Tseng, and T. Kim,
“Fuzzing ﬁle systems via two-dimensional input space
exploration,” in IEEE Symposium on Security and Pri-
vacy, 2019.
[58] W. You, X. Wang, S. Ma, J. Huang, X. Zhang, X. Wang,
and B. Liang, “Profuzzer: On-the-ﬂy input type prob-
ing for better zero-day vulnerability discovery,” in Pro-
Fuzzer: On-the-ﬂy Input Type Probing for Better Zero-
Day Vulnerability Discovery.
IEEE, 2019.
[59] I. Yun, S. Lee, M. Xu, Y. Jang, and T. Kim, “QSYM:
A practical concolic execution engine tailored for hybrid
fuzzing,” in Proceedings of the 27th USENIX Security
Symposium. USENIX Association, 2018.
[60] M. Zalewski, “American fuzzy lop (AFL) fuzzer,” http:
//lcamtuf.coredump.cx/aﬂ/technical_details.t, 2013.
[61] G. Zhang, X. Zhou, Y. Luo, X. Wu, and E. Min, “PTfuzz:
Guided fuzzing with processor trace feedback,” IEEE
Access, 2018.
17