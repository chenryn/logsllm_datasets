ing on specific logic or functionalities. Although SNAP considers
fuzzing a first-class citizen, it is designed with versatility in mind for
all use cases that demand rich information about program execution
states. We provide further discussion in §6.
Name
BitmapBase
Base address of coverage bitmap
BitmapSize
Size of coverage bitmap
TraceEn
Switch to enable HW tracing
TraceStartAddr
Start address of traced code region
TraceEndAddr
End address of traced code region
LbqAddr[0-31]
Target addresses of last 32 branches
LbqStatus
Prediction result of last 32 branches
PrevHash
Hash of the last branch target inst.
Table 2: New control and status registers (CSRs) in SNAP.
Permission Description
Read/Write
Read/Write
Read/Write
Read/Write
Read/Write
Read Only
Read Only
Read/Write
4.1 Overview of Hardware Primitives
SNAP provides hardware primitives to transparently trace program
execution and maintain fuzzing metadata (e.g., coverage bitmap),
avoiding the overhead of existing software-based techniques.2 Fig-
ure 3b shows an overview of the proposed hardware platform,
highlighting the three new primitives blended into the processor
pipeline: 1 trace decision logic at the Fetch Stage to identify and tag
instructions that need to be traced (§4.2.1), 2 bitmap update queue
(BUQ) to manage coverage bitmap updates based on the tagged
instructions passing Execute Stage (§4.2.2), and 3 last branch queue
(LBQ) to collect information about the last-executed branches from
the Branch Unit for additional contextual feedback (§4.2.3). We
elaborate on each of the hardware units in §4.2.
SNAP also introduces new control and status registers (CSRs)
as configuration interfaces between the hardware and the OS.
Table 2 contains the list of the new CSRs, each of 8 bytes in
size, and their access permissions. BitmapBase and BitmapSize are
used to set the base address and size of the coverage bitmap. The
tracing in hardware is enabled by TraceEn. TraceStartAddr and
TraceEndAddr serve to define region-specific feedback when needed.
LbqAddr[0-31] and LbqStatus store the branch target addresses and
prediction results of the last 32 branches by default. Note that these
two CSRs are read-only, as the kernel is not required to modify
2All of our hardware primitives use information originated from the existing CPU
pipeline – e.g., the Program Counter and the raw bytes of an instruction available in the
Fetch Stage, the branch-target address and branch-prediction results from the Branch
Unit in the Execute Stage, etc.
UserOSFuzzerBranchPredictorExecutionUnitCPUCorpusMemFeedbackSyscallDevice DriverBranch RecordsCov. Bitmapmmap()hwtrace()LBQexe.HWBUQb0b1b2...✓...✗✓b0b1b2...✓...✗✓FetchControllerL1 I-CacheBranchPredictorBranchUnit⋅⋅⋅Fetch BufferLDQ1STQ2BUQFetch StageExecution StageMemory StageIssueRegReadTraceDecisionLogic{uses_buq, uses_lbq, inst_bytes}Fetched inst.L1 D-CacheBranch PredictionFront-endOpportunisticBitmap UpdateBranch Resolution InfoAggregationtarget address, prediction resultDecodeRenameDispatchLBQfrom dispatch stage,allocate new entries.❶❷❸❹❺ALU❻❼1LDQ (Load Queue)2STQ (Store Queue)Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2218Figure 4: Bitmap update operation in the Bitmap Update Queue.
their contents. Finally, PrevHash stores the hash of the last branch
target instruction to index the coverage bitmap, as described in §4.4.
During a context switch, the OS saves and restores this value to
ensure the correctness of the first bitmap update after the switch.
4.2 Implementation of Hardware Primitives
We design and implement SNAP based on the out-of-order BOOM
core [6], one of the most sophisticated open-source RISC-V pro-
cessors to match commercial ones with modern performance opti-
mizations. Figure 3b highlights the lightweight modifications on
key hardware components in SNAP.
4.2.1 Trace Decision Logic. In the front-end of the BOOM core (Fig-
ure 3b), instructions are fetched from the instruction cache (I-cache),
enqueued to the Fetch Buffer, and then sent onward for further exe-
cution at every cycle. We extend the Fetch Controller by adding the
Trace Decision Logic ( 1 ), which determines whether an instruc-
tion inserted into the Fetch Buffer needs to be traced by SNAP. The
trace decision results in tagging two types of instructions within
the code region to be traced (i.e., between TraceStartAddr and
TraceEndAddr) using two reserved bits, uses_buq and uses_lbq. The
uses_buq bit is used to tag the target instruction of every control-
flow instruction (i.e., a branch or a jump) to help enqueue bitmap
update operations into the BUQ. Note that we choose to trace the
target instruction instead of the control-flow instruction itself for
the bitmap update due to our newly devised trace-encoding algo-
rithm (described later in §4.4). The control-flow instruction itself is
also tagged with the uses_lbq bit to help enqueue the correspond-
ing branch resolution information (i.e., the target address and the
prediction result) into the LBQ for additional contextual semantics
(described later in §4.5). Overall, the trace decision logic conducts
lightweight comparisons within a single CPU cycle in parallel to
the existing fetch controller logic and thus does not delay processor
execution or stall pipeline stages.
4.2.2 Bitmap Update Queue. The BUQ ( 2 ) is a circular queue re-
sponsible for bitmap updates invoked by the instructions following
control-flow instructions. A new entry in the BUQ is allocated when
such an instruction tagged with uses_buq is dispatched during the
Execute Stage ( 4 ). Each entry stores the metadata for a single
bitmap update operation ( 5 ) and performs the update sequentially
through four states:
(1) s_init: The entry is first initialized with the bitmap location
to be updated, which is calculated using our trace encoding
algorithm described in §4.4.
(2) s_load: Subsequently, the current edge count at the bitmap
location is read from the appropriate memory address.
(3) s_store: Then, the edge count is incremented by one and
written to the same bitmap location stored in the entry.
(4) s_done: Once the entry reaches this state, it is deallocated
when it becomes the head of the BUQ.
Figure 4 depicts the bitmap update operation in the BUQ designed
in a manner that imposes minimal overhead. Since the bitmap itself
is stored in user-accessible memory, its contents can be read and
written via load and store operations with the base address of the
bitmap and specific offsets. To ensure the bitmap update opera-
tion does not stall the CPU pipeline, the load part of the update
operation is allowed to proceed speculatively in advance of the
store operation, which is only executed when the corresponding in-
struction is committed. However, in case there are store operations
pending for the same bitmap location from older instructions, such
speculative loads are delayed until the previous store completes to
prevent reading stale bitmap values. Moreover, each bitmap load
and store is routed through the cache hierarchy, which does not
incur the slow access latency of the main memory. Note that the
cache coherence and consistency of the bitmap updates can be en-
sured by the hardware in a manner similar to that for regular loads
and stores in the shared memory. Last, a full BUQ can result in back
pressure to the Execution Stage and cause pipeline stalls. To avoid
this, we sufficiently increase the BUQ; our 24-entry BUQ ensures
that such stalls are infrequent and incur negligible overhead.
Last Branch Queue. The LBQ ( 3 ) is a circular queue record-
4.2.3
ing the information of the last 32 branches as context-specific feed-
back used by a fuzzer, as we describe in §4.5. Specifically, each
entry of the LBQ stores the target address and the prediction result
for a branch (i.e., what was the branch direction and whether the
predicted direction from the branch-predictor was correct or not).
Such information is retrieved through the branch resolution path
from the branch unit ( 7 ), where branch prediction is resolved. To
interface with the LBQ, we utilize the CSRs described in Table 2.
Each LBQ entry is wired to a defined CSR and can be accessible from
software after each fuzzing execution using a CSR read instruction.
4.3 Micro-architectural Optimizations
Since the BUQ generates additional memory requests for bitmap
updates, it may increase cache port contention and cause non-trivial
performance overhead. To minimize the performance impact, we
rely on the fact that the bitmap update operation is not on the
critical path of program execution, independent of a program’s
correctness. Hence, the bitmap update can be opportunistically per-
formed during the lifetime of a process and also aggregated with
subsequent updates to the same location. Based on the observations,
we develop two micro-architectural optimizations.
Opportunistic bitmap update. At the Memory Stage in Figure 3b,
memory requests are scheduled and sent to the cache based on the
priority policy of the cache controller. To prevent normal memory
requests from being delayed, we assign the lowest priority to bitmap
update requests and send them to the cache only when unused cache
bandwidth is observed or when BUQ is full. Combined with the
capability of the out-of-order BOOM core in issuing speculative
bitmap loads for the bitmap updates, this approach allows us to
effectively utilize the free cache bandwidth while also minimizing
the performance impact caused by additional memory accesses.
State⋅⋅⋅Addrtail às_init⋅⋅⋅-s_load⋅⋅⋅Cs_load⋅⋅⋅Bs_load⋅⋅⋅Ahead às_store⋅⋅⋅A-Load can be speculatively executed.-Stalls until the dependent olderentry finishes its store.-Store is executed in program order.Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2219Algorithm 2: Edge encoding by SNAP
: BBsr c → BBdst , pr evLoc
Input
1 p = Addr ess(BBdst)
2 inst_bytes = Inst Bytes(BBdst)
3 cur Loc = p ˆ inst_bytes[15 : 0] ˆ inst_bytes[31 : 16]
4 bitmap[cur Loc ˆ pr evLoc] += 1
5 pr evLoc = cur Loc ≫ 1
Output:pr evLoc – hash value for the next branch
Memory request aggregation. A memory request aggregation
scheme ( 6 ) is also deployed to reduce the number of additional
memory accesses. When the head entry of the BUQ issues a write
to update its bitmap location, it also examines the other existing
entries, which might share the same influencing address for subse-
quent updates. If found, the head entry updates the bitmap on behalf
of all the matched ones with the influence carried over, while the
represented entries are marked finished and deallocated without
further intervention. This is effective, especially for loop statements,
where the branch instruction repeatedly jumps to the same target
address across iterations. The BUQ can thus aggregate the bitmap
update operations aggressively with fewer memory accesses.
4.4 Edge Encoding
Algorithm 1 describes how AFL [61] measures edge coverage, where
an edge is represented in the coverage bitmap as the hash of a pair
of randomly generated basic block IDs inserted during compile time.
To avoid colliding edges, the randomness of basic block IDs plays
an important role to ensure the uniform distribution of hashing
outputs. Rather than utilizing a more sophisticated hashing algo-
rithm or a bigger bitmap size to trade efficiency for accuracy, AFL
chooses to keep the current edge-encoding mechanism, as its practi-
cality is well backed by the large number of bugs found. Meanwhile,
software instrumentation for coverage tracing requires excessive
engineering effort and can be error-prone, especially in the case of
complex COTS binaries without source code. Since it is non-trivial
to instrument every basic block with a randomly generated ID, one
viable approach is to borrow the memory address of a basic block
as its ID, which has proved effective in huge codebase [22]. Such
an approach works well on the x86 architecture where instructions
have variable lengths, usually ranging from 1 to 15 bytes, to pro-
duce a decent amount of entropy for instruction addresses to serve
as random IDs. In the case of the RISC-V architecture, however,
instructions are defined with fixed lengths. Standard RISC-V in-
structions are 32-bit long, while 16-bit instructions are also possible
only if the ISA compression extension (RVC) is enabled [54]. As a
result, RISC-V instructions are well-aligned in the program address
space. Reusing their addresses directly as basic block IDs for edge
encoding lacks enough entropy to avoid collisions.
To match the quality of edge encoding in AFL, we devise a
new mechanism (Algorithm 2) for SNAP that produces a sufficient
amount of entropy with no extra overhead compared to the naive
employment of memory addresses. Specifically, SNAP takes both
the memory address and the instruction byte sequence inside a ba-
sic block to construct its ID. A pair of such basic block IDs are then
hashed to represent the corresponding edge in the coverage bitmap.
By sitting at the hardware level, SNAP is able to directly observe
Figure 5: An example of encoding a basic block ID.
and leverage the instruction bytes as a source of entropy without
overhead to compensate the lack of randomness due to the RISC-V
instruction alignment. To be compatible with both 16- and 32-bit
long RISC-V instructions, SNAP always fetches two consecutive
16-bit sequences starting at the instruction address and performs
bitwise XOR twice to produce a basic bock ID (line 3 in Algorithm 2,
also in Figure 5). Therefore, each ID contains the entropy from vari-
ous data fields, including opcode, registers, and immediates, of either
an entire instruction or two compressed ones. In addition, SNAP
chooses to operate on the destination instruction of a branching op-
eration to construct a basic block ID, as it provides a larger variety
of instruction types (i.e., more entropy) than the branch instruction
itself. Similar to that of AFL, the encoding overhead of SNAP is
considered minimal, as the operation can be completed within one
CPU cycle. Note that Algorithm 2 can be easily converted to trace
basic block coverage by discarding prevLoc (line 5), which tracks
control transfers (i.e., edges), and performing bitmap update (line
4) solely based on curLoc (line 3).
4.5 Richer Coverage Feedback
As discussed in §2.2, edge coverage alone can be coarse-grained
and does not represent execution states accurately. Meanwhile, col-
lecting additional execution semantics via software-based solutions
always incurs major performance overhead. SNAP aims to solve
this dilemma from a hardware perspective. With various types of
micro-architectural state information available at the hardware
level, SNAP helps fuzzers to generate more meaningful feedback
that incorporates the immediate control flow context and approxi-
mated data flow of a program run without extra overhead.
Capturing immediate control-flow context. Tracking long
control-flow traces can be infeasible due to noise from overly sen-
sitive feedback and the performance overhead from comparing
long traces. Therefore, SNAP records only the last 32 executed
branches of a program run in the circular LBQ by default. Note that
SNAP provides the flexibility of configuring branch entry number
and address filters through software interfaces so that the hosted
fuzzer can decide to track the execution trace of an arbitrary pro-
gram space, ranging from a loop to a cross-function code region. A
unique pattern of the 32 branch target addresses recorded in LBQ
captures the immediate control-flow context of a program execution,
such as the most recent sequence of executed parsing options inside
string manipulation loops. When the immediate control-flow con-
text is included in coverage feedback, a fuzzer is inspired to further
mutate the inputs that share identical edge coverage but trigger
unseen branch sequences within the loop (Figure 1 line 4-11) that
will otherwise be discarded. As a result, the fuzzer is more likely to
generate the input that can reach the specific last-executed branch
sequence (i.e., SLLTS) for the buggy constraint (line 13).
lia5, 60bgea5, a4, 106ccde ad c7 b7106cc:luia5, 0xdeadc…0x106cc0xdead0xc7b70x11fd6=+Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2220address range to be traced. Overall, SNAP is designed to be flexible
for various use cases.
Process management. Besides the software interface that allows
user programs to configure hardware through system calls, the
kernel also manages the tracing information of each traced process.
Specifically, we add new fields to the process representation in the
Linux kernel (i.e., task_struct), including the address and the size
of the coverage bitmap, the address and the size of the branch queue,
the tracing address range, and the previous hash value. Those fields
are initialized with zeros upon process creation and later assigned
accordingly by the system calls mentioned before. During a context
switch, if the currently executing process is being traced, the kernel
disables the tracing and saves the hash value and branch records
in the hardware queue. In another case, if the next process is to be
traced, the SNAP CSRs will be set based on the saved field values to
resume the last execution. Note that when fuzzing a multi-threaded
application, existing fuzzers typically do not distinguish code paths
from different threads but record them into one coverage bitmap
to test the application as a whole. Although maintaining unique
bitmaps is supported, SNAP enables the kernel to copy all the SNAP-
related fields of a parent process, except the address of the branch
queue, into its newly spawned child process by default. In addition,
when a target process exits, either with or without error, SNAP
relies on the kernel to clean up the corresponding fields during the
exit routine of the process. However, the memory of the coverage
information and the branch queue will not be released immediately,
as it is shared with the designated user programs (i.e., fuzzers) to
construct the tracing information. Instead, the memory will be freed
on demand once the data have been consumed in the userspace.
Memory sharing. To share the memory created for the coverage
bitmap and the branch queue with the userspace program, SNAP
extends the kernel with two corresponding device drivers. In gen-
eral, the device drivers enable three file operations: open(), mmap(),
and close(). A user program can create a kernel memory region
designated for either of the devices by opening the device accord-
ingly. The created memory will be maintained in a kernel array
until it is released by the close operation. Moreover, the kernel can
remap the memory to userspace if necessary. The overall design is
similar to that of kcov [37], which exposes kernel code coverage
for fuzzing.
tracing on SNAP? (§5.2)