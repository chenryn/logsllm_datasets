the hostvisor can then call VM ENTER to execute the VM. In
other words, the hostvisor stores VM images and loads them
to memory, avoiding implementing this complex procedure
in the corevisor. The corevisor veriﬁes the cryptographic
signatures of VM images using public key cryptography,
avoiding any shared secret between the user and HypSec.
Both the public keys and VM image signatures are stored
in TEE secure storage prior to any attack, as shown in Figure 1.
If the VM kernel binary is detached and can be mapped
separately to memory, the hostvisor calls the corevisor to
verify the image.
If the VM kernel binary is in the VM
disk image’s boot partition, HypSec-aware virtual ﬁrmware
bootstraps the VM. The ﬁrmware is signed and veriﬁed like
VM boot images. The ﬁrmware then loads the signed kernel
binary or a signed bootloader such as GRUB from the cleartext
VM disk partition. The ﬁrmware then calls the corevisor to
verify the VM kernel binary or bootloader. In the latter case,
the bootloader veriﬁes VM kernel binaries using the signatures
on the virtual disk; GRUB already supports this. GRUB can
also use public keys in the signed GRUB binary. The corevisor
ensures only images it veriﬁed, either a kernel binary, virtual
ﬁrmware, or a bootloader binary, can be mapped to VM
memory. Finally, the corevisor sets the VM program counter
to the entry point of the VM image to securely boot the VM.
As discussed in Section 3.5, HypSec expects that VM disk
images are encrypted as part of an end-to-end encryption
approach. HypSec ensures that any password or secret used to
decrypt the VM disk is not exposed to the hostvisor. Common
encrypted disk formats [6, 57] use user-provided passwords
to protect the decryption keys. HypSec can store the encrypted
key ﬁles locally or remotely using a cloud provider’s key
management service (KMS) [5, 58]. The KMS maintains a
secret key which is preloaded by administrators into hosts’
TEE secure storage. The corevisor decrypts the encrypted key
ﬁle using the secret key, and maps the resulting password to
VM memory, allowing VMs to obtain the password without
exposing it to the hostvisor. The same key scheme is used for
VM migration; HypSec encrypts and decrypts the VM state
using the secret key from the KMS.
3.2 CPU
Hypervisors provide CPU virtualization by performing four
main functions: handling traps from the VM; emulating
privileged CPU instructions executed by the guest OS to
ensure the hypervisor retains control of CPU hardware; saving
and restoring VM CPU state, including GPRs and system
registers such as page table base registers, as needed when
switching among VMs and between a VM and the hypervisor;
and scheduling VCPUs on physical CPUs. Hypervisors
typically have full access to VM CPU state when performing
any of these four functions, which can pose a problem for VM
security if the hypervisor is compromised.
HypSec protects VM CPU state from the hostvisor while
keeping its TCB small by restricting access to VM CPU state
to the corevisor while delegating complex CPU functions that
can be done without access to VM CPU state to the hostvisor.
This is done by having the corevisor handle all traps from the
VM, instruction emulation, and world switches between VMs
and the hostvisor, all of which require access to VM CPU state.
VCPU scheduling is delegated to the hostvisor as it can be done
without access to VM CPU state.
The corevisor conﬁgures the hardware to route all traps
from the VM, as well as interrupts as discussed in Section 3.4,
to go to the corevisor, ensuring that it retains full hardware
control. It also deprivileges the hostvisor to ensure that the
hostvisor has no access to corevisor state. Since all traps
from the VM go to the corevisor, the corevisor can trap and
emulate CPU instructions on behalf of the VM. The corevisor
multiplexes the CPU execution context between the hostvisor
and VMs on the hardware. The corevisor maintains VCPU
execution context in the VCPU state in-memory data structure
allocated on VM CREATE, and maintains the hostvisor’s CPU
context in a similar Host state data structure; both states are
only accessible to the corevisor. On VM exits, the corevisor
ﬁrst saves the VM execution context from CPU hardware
registers to VCPU state, then restores the hostvisor’s execution
context from Host state to the CPU hardware registers. When
the hostvisor calls to the corevisor to re-enter the VM, the
corevisor ﬁrst saves its execution context to Host state, then
restores the VM execution context from VCPU state to the
hardware. All saving and restoring of VM CPU state is done
by the corevisor, and only the corevisor can run a VM.
The hostvisor handles VCPU scheduling, which can
involve complex scheduling mechanisms especially for
multiprocessors. For example, the Linux scheduler code alone
is over 20K LOC, excluding kernel function dependencies
and data structures shared with the rest of the kernel. VCPU
scheduling requires no access to VM CPU state, as it simply
involves mapping VCPUs to physical CPUs. The hostvisor
schedules a VCPU to a physical CPU and calls to the corevisor
to run the VCPU. The corevisor then loads the VCPU state
to the hardware.
HypSec by default ensures that the hostvisor has no access to
any VM CPU state, but sometimes a VM may execute instruc-
tions that requiring sharing values with the hostvisor that may
be stored in general purpose registers (GPRs). For example, if
the VM executes a hypercall that includes some parameters and
1360    28th USENIX Security Symposium
USENIX Association
the hypercall is handled by the hostvisor, it will be necessary to
pass the parameters to the hostvisor, and those parameters may
be stored in GPRs. In these cases, the instruction will trap to the
corevisor. The corevisor will identify the values that need to be
passed to the hostvisor, then copy the values from the GPRs to
an in-memory per VCPU intermediate VM state structure that
is accessible to the hostvisor. Similarly, hostvisor updates to the
intermediate VM state structure can be copied back to GPRs by
the corevisor to pass values back to the VM. Only values from
the GPRs explicitly identiﬁed by the corevisor for parameter
passing are copied to and from intermediate VM state; values
in other CPU registers are not accessible to the hostvisor.
The corevisor determines if and when to copy values from
GPRs, and the GPRs from which to copy, based on the speciﬁc
CPU instructions executed. The set of instructions are those
used to execute hypercalls and special instructions provided by
the architecture to access virtual hardware via model-speciﬁc
registers (MSRs), control registers in the x86 instruction set, or
memory-mapped I/O (MMIO). There are typically only a few
speciﬁc CPU instructions that involve parameter passing to
the hostvisor via GPRs, but the speciﬁc cases are architecture
dependent.
For example, on ARM, HypSec copies selected GPRs
to and from intermediate VM state for power management
hypercalls to the virtual ﬁrmware interface and selected
MMIO accesses to virtual hardware. For power management
hypercalls, the guest kernel passes input parameters in GPRs,
and the corevisor copies only those GPRs to intermediate VM
state to make the parameters available to the hostvisor. Upon
returning to the VM, the hostvisor provides output data as
return values to the power management hypercalls, which the
corevisor copies from intermediate VM state back to GPRs to
make them available to the VM. As discussed in Sections 3.4
and 3.5, values stored and loaded in GPRs on MMIO accesses
to the virtual interrupt controller interface or I/O devices are
also copied between the selected GPRs and the intermediate
VM state to make them available to the hostvisor.
3.3 Memory
Hypervisors provide memory virtualization by performing
three main functions: memory protection to ensure VMs can-
not access unauthorized physical memory, memory allocation
to provide physical memory to VMs, and memory reclamation
to reclaim physical memory from VMs. Other advanced
memory management features may also be performed that
build on these functions. All of these functions rely on NPTs.
A guest OS manages the traditional page tables to map guest
virtual memory addresses (gVA) to guest physical memory
addresses (gPA). The hypervisor manages the NPTs to map
from gPAs to host physical memory addresses (hPA) so it can
virtualize and restrict a VM’s access to physical memory. The
hypervisor has full access to physical memory so it can manage
VM memory either directly [11] or via a host OS kernel’s [23]
Figure 2: HypSec Memory Virtualization
memory management APIs. A compromised hypervisor or
host OS kernel thus has unfettered access to VM memory and
can read and write any data stored by VMs in memory.
HypSec protects VM memory from the hostvisor while
keeping its TCB small by restricting access to VM memory
to the corevisor while delegating complex memory manage-
ment functions that can be done without access to actual VM
data in memory to the hostvisor. The corevisor is responsible
for memory protection, including conﬁguring NPT hardware,
while memory allocation and reclamation is largely delegated
to the hostvisor. HypSec memory protection imposes an addi-
tional requirement, which is to also protect corevisor and VM
memory from the hostvisor.
Memory Protection. The corevisor uses the NPT hardware
in the same way as modern hypervisors to virtualize and restrict
a VM’s access to physical memory, but in addition leverages
NPTs to isolate hostvisor memory access. The corevisor conﬁg-
ures NPT hardware as shown in Figure 2. The hostvisor is only
allowed to manage its own page tables (Host PT) and can only
translate from host virtual memory addresses (hVAs) to what
we call virtualized host physical memory addresses (vhPAs).
vhPAs are then in turn translated to hPAs by the Host Nested
Page Table (hNPT) maintained by the corevisor. The corevisor
adopts a ﬂat address space mapping; each vhPA is mapped to an
identical hPA. The hostvisor, if granted access, is given essen-
tially the same view of physical memory as the corevisor. The
corevisor prevents the hostvisor from accessing corevisor and
VM memory by simply unmapping the memory from the hNPT
to make the physical memory inaccessible to the hostvisor. Any
hostvisor accesses to corevisor or VM memory will trap to the
corevisor, enabling the corevisor to intercept unauthorized ac-
cesses. Physical memory is statically partitioned between the
hostvisor and corevisor, but dynamically allocated between the
hostvisor and VMs as discussed below. The corevisor allocates
NPTs from its own memory pool which is not accessible to the
hostvisor. All VCPU state is also stored in corevisor memory.
The corevisor also protects corevisor and VM memory
against DMA attacks [75] by retaining control of the IOMMU.
The corevisor allocates IOMMU page tables from its memory
and exports the IOMMU OPS API to device drivers in the
USENIX Association
28th USENIX Security Symposium    1361
gVAgPAHostvisorVMCorevisorsNPTVM PThPAhVAvhPAhNPTHost PThPAvNPTNPT Base RegisterShadow①②③④⑤⑥hostvisor to update page table mappings. The corevisor
validates requests and ensures that attackers cannot control
the IOMMU to access memory owned by itself or the VMs.
Memory Allocation. Memory allocation for VMs is
largely done by the hostvisor, which can reuse memory
allocation functions available in an integrated host OS kernel
to dynamically allocate memory from its memory pool to
VMs. Traditional hypervisors simply manage one NPT
per VM. However, HypSec’s memory model disallows the
hostvisor from managing VM memory and therefore NPTs.
The hostvisor instead manages an analogous Virtual NPT
(vNPT) for each VM, and HypSec introduces a Shadow
Nested Page Table (sNPT) managed by the corevisor for each
VM as shown in Figure 2. The sNPT is used to manage the
hardware by shadowing the vNPT. The corevisor multiplexes
the hardware NPT Base Register between hNPT and sNPT
when switching between the hostvisor and a VM.
Figure 2 also depicts the steps in HypSec’s memory
virtualization strategy. When a guest OS tries to map a gVA
to an unmapped gPA, a nested page fault occurs which traps to
the corevisor (step 1). If the corevisor ﬁnds that the faulted gPA
falls within a valid VM memory region, it then points the NPT
Base Register to hNPT (step 2) and switches to the hostvisor
to allocate a physical page for the gPA (step 3). The hostvisor
allocates a virtualized physical page identiﬁed by a vhPA and
updates the entry in its vNPT corresponding to the faulting gPA
with the allocated vhPA. Because the vhPA is mapped to an
identical hPA, the hostvisor is able to implicitly manage host
physical memory. The hostvisor then traps to the corevisor
(step 4), which determines the faulting gPA and identiﬁes the
updates made by the hostvisor to the vNPT. The corevisor
veriﬁes the resulting vhPA is not owned by itself or other VMs,
the latter by tracking ownership of physical memory using a
unique VM identiﬁer (VMID), and copies those updates to
its sNPT. The corevisor unmaps the vhPA from the hNPT, so
that the hostvisor no longer has access to the memory being
allocated to the VM. The corevisor updates the NPT Base
Register to point to the sNPT (step 5) and returns to the VM
(step 6) so that the VM has access to the allocated memory
identiﬁed by the hPA that is identical to the vhPA. Although
possible, HypSec does not scrub pages allocated to VMs by the
hostvisor. Guest OSes already scrub memory allocated from
their free list before use for security reasons, so the hostvisor
cannot allocate pages that contain malicious content to VMs.
HypSec’s use of shadow page tables differs signiﬁcantly
from previous applications of it to collapse multi-level
page tables down into what is supported by hardware
[2, 11, 16, 52, 82].
In contrast, HypSec uses shadowing
to protect hardware page tables, not virtualize them. The
corevisor does not shadow guest OS updates in its page tables;
it only shadows hostvisor updates to the vNPT. HypSec
does not introduce additional traps from the VM for page
table synchronization. Overshadow [16] maintains multiple
shadow page tables for a given VM that provide different
views (plaintext/encrypted) of physical memory to protect
applications from an untrusted guest OS. In contrast, HypSec
manages one shadow page table for each VM that provides
a plaintext view of gPA to hPA. The shadowing mechanism in
HypSec is also orthogonal to recent work [19] that uses shadow
page tables to isolate kernel space memory from user space.
Memory Reclamation. HypSec supports VM memory
reclamation in the hostvisor while preserving the privacy and
integrity of VM data in memory in the corevisor. When a VM
voluntarily releases memory pages, such as on VM termina-
tion, the corevisor returns the pages to the hostvisor by ﬁrst
scrubbing them to ensure the reclaimed memory does not leak
VM data, then mapping them back to the hNPT so they are
accessible to the hostvisor. To allow the hostvisor to reclaim
VM memory pages without accessing VM data in memory,
HypSec takes advantage of ballooning [82]. Ballooning is
widely supported in common hypervisors, so only modest ef-
fort is required in HypSec to support this approach. A paravir-
tual “balloon” device is installed in the VM. When the host is
low on free memory, the hostvisor requests the balloon device
to inﬂate. The balloon driver inﬂates by getting pages from the
free list, thereby increasing the VM’s memory pressure. The
guest OS may therefore start to reclaim pages or swap its pages
to the virtual disk. The balloon driver notiﬁes the corevisor
about the pages in its balloon that are ready to be reclaimed.
The corevisor then unmaps these pages from the VM’s sNPT,
scrubs the reclaimed pages to ensure they do not leak VM data,
and assigns the pages to the hostvisor, which can then treat
them as free memory. Deﬂating the balloon releases memory
pressure in the guest, allowing the guest to reclaim pages.
HypSec also safely allows the hostvisor to swap VM
memory to disk when it feels memory pressure. The hostvisor
uses GET VM STATE to get access to the encrypted VM page
before swapping it out. Later, when the VM page is swapped
in, the corevisor unmaps the swapped-in page from hNPT,
decrypts the page, and maps it back to the VM’s sNPT.
Advanced VM Memory Management. HypSec by
default ensures that the hostvisor has no access to any VM
memory, but sometimes a VM may want to share its memory,
after encrypting it, with the hostvisor. HypSec provides the
GRANT_MEM and REVOKE_MEM hypercalls which can be explic-
itly used by a guest OS to share its memory with the hostvisor.
As described in Section 3.5, this can be used to support paravir-
tualized I/O of encrypted data in which a memory region owned
by the VM has to be shared between the VM and hostvisor
for communication and efﬁcient data copying. The VM passes
the start of a guest physical frame number (GFN), the size of
the memory region, and the speciﬁed access permission to the
corevisor via the two hypercalls. The corevisor enforces the
access control policy by controlling the memory region’s map-
ping in hNPT. Only VMs can use these two hypercalls, so the
hostvisor cannot use it to request access to arbitrary VM pages.