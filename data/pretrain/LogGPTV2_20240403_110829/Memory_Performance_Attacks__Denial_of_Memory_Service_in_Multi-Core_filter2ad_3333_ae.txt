g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
)
e
n
o
l
a
i
g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
3.0
2.5
2.0
1.5
1.0
0.5
0.0
9.0
8.5
8.0
7.5
7.0
6.5
6.0
5.5
5.0
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
rdarray
art
baseline (FR-FCFS)
FairMem
stream
health
baseline (FR-FCFS)
FairMem
)
e
n
o
l
a
i
g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
)
e
n
o
l
a
i
g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
3.0
2.5
2.0
1.5
1.0
0.5
0.0
9.0
8.5
8.0
7.5
7.0
6.5
6.0
5.5
5.0
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
health
vpr
baseline (FR-FCFS)
FairMem
stream
mcf
baseline (FR-FCFS)
FairMem
)
e
n
o
l
a
i
g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
)
e
n
o
l
a
i
g
n
n
n
u
r
:
e
s
a
b
(
i
e
m
T
n
o
i
t
u
c
e
x
E
d
e
z
i
l
a
m
r
o
N
3.0
2.5
2.0
1.5
1.0
0.5
0.0
9.0
8.5
8.0
7.5
7.0
6.5
6.0
5.5
5.0
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
art
health
baseline (FR-FCFS)
FairMem
stream
art
baseline (FR-FCFS)
FairMem
Figure 8: Slowdown of different application combinations using FR-FCFS and our FairMem algorithm
Baseline (FR-FCFS)
Throughput Unfairness Throughput Unfairness
FairMem
Throughput
improvement
24.8
401.4
463.8
179.3
65.9
38.0
87.2
63.1
51.2
2.00
2.23
1.56
1.62
2.24
8.14
8.73
5.17
4.06
22.5
513.0
508.4
178.5
97.1
72.5
390.6
117.1
98.6
1.06
1.00
1.09
1.15
1.06
1.18
1.11
1.08
1.06
0.91X
1.28X
1.10X
0.99X
1.47X
1.91X
4.48X
1.86X
1.93X
Combination
stream-rdarray
art-vpr
health-vpr
art-health
rdarray-art
stream-health
stream-vpr
stream-mcf
stream-art
Fairness
improvement
1.89X
2.23X
1.43X
1.41X
2.11X
6.90X
7.86X
4.79X
3.83X
Table 3: Effect of FairMem on overall throughput (in terms of instructions per 1000 cycles) and unfairness
6.2.2 Effect of Row-buffer Size
From the above discussions, it is clear that the exploita-
tion of row-buffer locality by the DRAM memory con-
troller makes the multi-core memory system vulnerable
to DoS attacks. The extent to which this vulnerability can
be exploited is determined by the size of the row-buffer.
In this section, we examine the impact of row-buffer size
on the effectiveness of our algorithm. For these sensitiv-
ity experiments we use two real applications, art and vpr,
where art behaves as an MPH against vpr.
Figure 9 shows the mutual impact of art and vpr on
machines with different row-buffer sizes. Additional
statistics are presented in Table 4. As row-buffer size in-
creases, the extent to which art becomes a memory per-
formance hog for vpr increases when FR-FCFS schedul-
ing algorithm is used. In a system with very small, 512-
byte row-buffers, vpr experiences a slowdown of 1.65X
(versus art’s 1.05X). In a system with very large, 64 KB
row-buffers, vpr experiences a slowdown of 5.50X (ver-
sus art’s 1.03X). Because art has very high row-buffer
locality, a large buffer size allows its accesses to occupy
a bank much longer than a small buffer size does. Hence,
art’s ability to deny bank service to vpr increases with
row-buffer size. FairMem effectively contains this denial
of service and results in similar slowdowns for both art
and vpr (1.32X to 1.41X). It is commonly assumed that
row-buffer sizes will increase in the future to allow better
throughput for streaming applications [41]. As our re-
sults show, this implies that memory-related DoS attacks
will become a larger problem and algorithms to prevent
them will become more important.12
6.2.3 Effect of Number of Banks
The number of DRAM banks is another important pa-
rameter that affects how much two threads can interfere
with each others’ memory accesses. Figure 10 shows
the impact of art and vpr on each other on machines
with different number of DRAM banks. As the num-
ber of banks increases, the available parallelism in the
12Note that reducing the row-buffer size may at ﬁrst seem like one
way of reducing the impact of memory-related DoS attacks. However,
this solution is not desirable because reducing the row-buffer size sig-
niﬁcantly reduces the memory bandwidth (hence performance) for ap-
plications with good row-buffer locality even when they are running
alone or when they are not interfering with other applications.
270
16th USENIX Security Symposium
USENIX Association
i
e
m
T
n