There were some inconsistencies between these self-reports;
for example, the risky behaviors involving passwords, e.g.,
used a password found in a dictionary (24%) and used a
password that contains personal information (24%), seem to
conﬂict with the high percentage reporting usage of strong
passwords. The differences may indicate that participants did
not understand what constitutes a strong password.
The policy capturing study of [15] also assessed intention
to avoid risky actions by asking after each vignette “If you
were to get the message again, how likely are you to click on
the link in the email message?” They found that the presence
of all four threats lowered respondents’ intention to click on
the link and that women’s intention to click on an embedded
link offering a coupon was rated higher than men even when
they had been presented with a description of threats that
could occur from such action. Also, older adults weighed
conﬁdentiality threats less than younger adults. Participants
reporting higher levels of basic computer knowledge gave
unwitting accomplice threats less attention.
Intention to a particular behavior does not necessarily
translate into the particular action. Davinson and Sillence
216
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
[36] conducted a four stage study of 64 participants recruited
from the Psychology Division at Northumbria University.
They examined two factors on intended and actual behavior
involving avoidance of fraud on the Internet:
informing
someone that they have a high or low level of risk and having
them play (or not) a game-based educational program. The
ﬁrst stage involved participants taking an online survey
that asked about age, gender, Internet use, experience with
online ﬁnancial transactions and experience of fraud. 11
fraud avoiding behaviors were included, such as “I only
use websites with the secure padlock icon when shopping
online”, and were assessed as a 7-point scale from 1=Al-
ways to 7=Never. Two susceptibility items asked about
how susceptible he or she was and how susceptible others
were. Then each participant was assigned a “risk score” that
supposedly was calculated from their survey responses, but
actually was randomly assigned as either “20% at risk” or
“80% at risk of becoming a victim of fraud due to the way
you use the Internet”. The risk score was accompanied by
an information sheet derived from recommendations on the
getsafeonline.org and the APACS websites. In the second
stage, participants were given a paper survey of their inten-
tions to behave securely over the next 10 days, including the
same behaviors as in the ﬁrst survey. In the third stage, half
the participants were asked to complete an interactive game-
based training program called “Anti-Phishing Phil” which
was developed at Carnegie Mellon University. For the fourth
stage, seven days later, the participants were sent email with
a survey asking how they had behaved over the previous
week.
The safety of participants’ behavior was calculated as a
summed score over the 11 behaviors, where lower is safer.
Interestingly, the results showed a statistically signiﬁcant
drop in the behavior measure between the ﬁrst stage and
subsequent stages independent of whether they had been
told they had been placed in the low or high risk category
at the end of the ﬁrst stage. However, the behavior measure
increased signiﬁcantly from the second stage to the fourth
stage, indicating that although they did exhibit safer behavior
than reported in the ﬁrst stage survey, their intentions did not
match what they actually did. The results also showed no
effect due to the training. Finally, analysis of the susceptibil-
ity reports showed that, at each stage, participants perceived
that others were at more risk than was the individual.
Ng and Rahim developed a model of home computer
users’ intention to practice speciﬁc security actions [37].
Their model was based upon prior extensions to TPB that
further divided the three factors inﬂuencing Intention as
follows. Attitude was decomposed as:
• Perceived Usefulness was how much a user believes
certain actions will help (advantages and disadvan-
tages).
• Ease of Use was how simple the user views the action.
• Compatability was how well the action ﬁts in with the
user’s values, experiences and needs.
Subjective Norm was decomposed as:
• Peer Inﬂuence was how much a user takes action based
on peer expectations.
• Superior’s Inﬂuence was how much a user takes action
based on expectations from superiors.
Perceived Behavioral Control was decomposed as:
• Self-Efﬁcacy was the user’s conﬁdence in his/her ability
to take the actions.
• Resource Facilitating Conditions encompassed the re-
quirements in time and money.
• Technology Facilitating Conditions identiﬁed techno-
logical barriers (compatibility, complexity) that con-
strain action.
These extensions (called the “Decomposed Theory of
Planned Behavior”) were developed to explain IT usage [38].
To reﬂect the switch to security in the home, Ng and
Rahim’s model did not include Ease of Use, Compatability,
Peer Inﬂuence, Superior’s Inﬂuence, Resource Facilitating
Conditions and Technology Facilitating Conditions and sub-
stituted the following security speciﬁc factors:
• Family and Peer Inﬂuence, as a factor inﬂuencing
Subjective Norm, was pressure from family and friends
to take security actions and reﬂects the shift from an
organization/work environment to the home.
• Mass Media Inﬂuence, as a second factor inﬂuencing
Subjective Norm, was whether information gleaned
from news outlets, Internet, television, etc. inclines the
user to take security actions.
• Facilitating Conditions, as the second factor inﬂuencing
Perceived Behavioral Control, captured the inﬂuence of
external factors such as time, money and compatibility
on whether the user takes the action.
To assess their model, they surveyed 233 undergraduates
who were home computer users and asked 75 questions per-
taining to three security actions and the factors listed above.
The security actions were derived from recommendations
made by the United States Computer Emergency Response
Team Coordination Center and were:
1) update anti-virus software regularly,
2) back up critical data,
3) use a ﬁrewall.
Generally, analysis of the results of the survey supported
the model with a few exceptions. Perceived Behavioral
Control only exerted a signiﬁcant effect on Intention for
the ﬁrewall action; the authors posited that updating soft-
ware and backing up data are not inﬂuenced by Perceived
Behavioral Control because the users think they control
these actions and because the actions can be set up to be
done automatically. Similarly, Facilitating Conditions did not
appear to exert a signiﬁcant effect on Perceived Behavioral
that either factors such as
Control;
the authors suggest
217
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
from “very likely” to “very unlikely” to be carried out
within the next month. Respondents were also asked about
threat susceptibility, threat seriousness coping self-efﬁcacy,
response efﬁcacy and outcome expectations. Statistical anal-
yses showed that only about half of the expected relation-
ships were signiﬁcant. Safe online behavior intentions were
unrelated to perceived threat susceptibility and to seriousness
of threats. However, coping self-efﬁcacy beliefs, perceived
efﬁcacy of actions and perceived beneﬁts of safety behaviors
were positively related to intentions to practice safe online
behaviors. Perceived costs of safe behaviors were unrelated
to intentions, while perceived beneﬁts of unsafe behaviors
were positively related to intention, which may indicate that
users still want the beneﬁts of their unsafe behavior and look
for ways to mitigate it through other safe behaviors.
The researchers also looked at some social and personality
factors. Outcomes that were perceived as enhancing the
status of an individual also improved safe behavior inten-
tions. Not surprisingly, users who viewed safety as their
responsibility were more likely to engage in safe behaviors
and those with a reckless self-concept were less likely.
Another factor was whether the users had a regular routine
(habit) of following the safe behaviors.
Lu et al. [39] developed and evaluated a model to predict
continued use of an online antivirus application (OLA).
Their model extended the Technology Acceptance Model
(TAM), which predicts users’ intention to use technology by
characterizing their perception of usefulness (PU) and ease
of use (PE), by incorporating perceptions of risk from the
technology. In the TAM model, PU directly affects intention
to use and PE both directly and indirectly (through PU) af-
fects intention. In the Lu et al. model, perceived risk directly
inﬂuences intention to use as well as indirectly affecting it
through PE; they composed perceived risk from a weighted
sum of seven belief variables: physical risk (threat to safety),
functional risk (failure of product to perform), social risk
(opinion of others), time-loss risk (whether it is a waste of
time), ﬁnancial risk (not worth the cost), opportunity cost
risk (selected inferior software) and information risk (not
enough knowledge of how to use the software).
Behavior
Update security patches for OS
Scan with an anti-spyware program
Use a pop-up blocker
Use a spam ﬁlter
Use a ﬁrewall
Erase cookies
Update virus protection software
Update security patches for Internet browser
Scan computer with a browser hijack eraser
Carefully read license agreement before soft-
ware download
Verify identity of a website
Carefully read website privacy policies be-
fore ﬁlling in online forms
Verify a website privacy seal
Change passwords
Set up my IM to only accept connections
from my buddies
Back up ﬁles regularly
Increase privacy settings in browser
Send credit card number over an unsecure
connection
Open an email attachment I am not expecting
Send a nasty reply to spam
Click inside a pop-up window that opens
unexpectedly in browser
Switch to a different OS
Supply personal information to register at a
website
SOB
.8
.8
.8
.7
.7
.7
.7
.7
.7
PPB
UOB
.8
.8
.7
.7
.7
.6
.6
.6
.8
.8
.8
.8
.6
.6
SIGNIFICANT ONLINE BEHAVIORS IDENTIFIED FROM TABLE 1 IN [24].
RIGHTMOST COLUMNS SHOW THE HIGHEST WEIGHT FOR A CATEGORY
Table I
OF BEHAVIOR FOUND THROUGH PRINCIPAL COMPONENTS FACTOR
ANALYSIS WITH VARIMAX ROTATION.
time and money do not matter as much as ability or that
Facilitating Conditions may directly inﬂuence Intention. The
authors concluded that usefulness of the actions should be
stressed in education and mass media should be leveraged
to inform users and their peers.
Another study [24] examined intention to perform a
variety of self-protective security behaviors. Their model
was based on PMT and captured relationships between
seven protection motivation variables and speciﬁc online
safety behaviors. The protection motivation variables were:
perceived threat susceptibility, perceived threat seriousness,
coping efﬁcacy, response efﬁcacy, perceived beneﬁts of safe
behavior, perceived costs of safe behavior and perceived
beneﬁts of unsafe behavior. The last two were thought to be
negatively related to safe practices; the rest were positively
related. Through principal components factor analysis, 23
online behaviors were most closely associated with one of
three types of behaviors: Safe Online Behaviors (SOB), Pri-
vacy Protection Behavior (PPB) and Unsafe Online Behavior
(UOB) (see Table I).
To assess their model, LaRose et al. recruited 576 under-
graduates from classes in telecommunications and advertis-
ing by offering them extra credit for ﬁlling out a survey.
Each behavior was presented on a seven point scale ranging
To evaluate the extended TAM model, Lu et al. surveyed
1,259 registered users of a trial of Trend Micro OLA
(solicited via email and offered an opportunity to participate
in a drawing) and asked questions to determine the values of
the belief variables. 714 participants indicated that they used
only the trial and 107 indicated they used the OLA more
than ﬁve times subsequently. In examining the differences
in the two groups, they found that PU exerted a much more
signiﬁcant inﬂuence on attitude/intention than perceived risk
for the trial-and-leave group; although PU still exerted a
stronger effect than risk for the continuous-use group, the
effect was not as signiﬁcant as for the trial-and-leave-group
and perception of risk was found to be an important factor
in predicting subsequent use of the OLA. Given that the
218
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:49:21 UTC from IEEE Xplore.  Restrictions apply. 
participants had already judged that they should try anti-
virus software, it seems likely that they were aware of the
risk and were instead focusing on the utility of the product.
Undergraduates can exhibit inconsistent behavior between
what they know about security and what they actually do
to prevent problems [6]. On password security, only 22%
report that they never share their passwords, 51% report that
they never or rarely change their passwords. On email, 24%
report opening email attachments from unknown sources
without checking for viruses and 56% report doing so when
the source looked to be known. Frequent backups are done
by 38%. Interestingly, there was low correlation between
taking these actions, suggesting that the group did not divide
into cautious and careless, but rather a few pairings that