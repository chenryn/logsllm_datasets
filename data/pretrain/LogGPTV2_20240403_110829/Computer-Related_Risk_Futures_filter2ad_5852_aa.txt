title:Computer-Related Risk Futures
author:Peter G. Neumann
2009 Annual Computer Security Applications Conference
Computer-Related Risk Futures
Peter G. Neumann∗
Abstract: This paper reﬂects on many risks in the
development and use of computer-related systems.
It considers past and future alternatives, suggests
some remedial approaches, and oﬀers a few broad
conclusions.
Various long-touted common-sense
approaches that are holistic and proactive are more
urgently needed now than ever before.
Keywords: Risks, trustworthiness, security
1 Introduction
The word futures in the title of this paper is inten-
tionally ambiguous. On one hand, we might imag-
ine many strategies for alternative visions of future
times in which risks could be controlled, managed,
dramatically reduced, or even in some cases eﬀec-
tively eliminated, perhaps by various means consid-
ered here. On the other hand, futures suggests some
reactive business-as-usual interpretations. For ex-
ample, you might think of an exchange marketplace
that could trade in expectations relating to risks—
perhaps using actuarial tables on past and expected
losses to issue, buy, and sell insurance policies against
computer-related disasters, or speculating by short-
selling stocks in anticipation of (or prior to intention-
ally causing) malware exploitations and other serious
cyberattacks. Further derivative activities might also
come to mind, such as trading within caps on liabil-
ities, somewhat akin to using carbon-cap trading in
an attempt to address climate control.
Oversimplifying somewhat, proactive strategies
should constructively appeal to enlightened people in
R&D and operational communities. Reactive strate-
gies might rather destructively appeal primarily to
speculators in ﬁnancial markets and short-term proﬁt
seekers. Of course, the former approach is recom-
mended here, and the latter approach is mentioned
only as a dead-horse straw herring that needs to be
whipped in the bud (and nipped in the budget).
∗Computer Science Laboratory, SRI International, Menlo
Park CA 94025-3493, PI:EMAIL
This author [8, 10] and colleagues (such as Bob
Boyer, Fernando Corbat´o, Peter Denning, Edsger Di-
jkstra, Virgil Gligor, Tony Hoare, Nancy Leveson,
J Moore, David Parnas, John Rushby, and Jerry
Saltzer, to name just a few) have long advocated
principled approaches whose adoption could seriously
reduce many of the risks. Unfortunately, during
roughly the past 40 years much of that shared wis-
dom (e.g., [4] from 1968 and [8] from 1969) has been
largely ignored in practice. This wisdom certainly
bears respecting in the persistent hope that it might
eventually gain greater traction, particularly in de-
veloping greater awareness of the risks of inaction.
2 Historical Perspective
Many application areas such as critical infrastruc-
tures, real-time control, and computer-aided elec-
tions require trustworthy computer systems sat-
isfying requirements such as predictable security
and reliability, as well as enterprise survivability
and manageability in the face of a wide range of
threats—including hardware malfunctions, penetra-
tions, denial-of-service attacks, insider misuse, mal-
ware, and improper human behavior. However, many
existing systems are inadequately trustworthy for
such applications. Further, overcoming a pervasive
absence of meaningfully trustworthy systems is only
part of the problem, because many of the problems
have serious nontechnological aspects. Overall, the
risks continue to be problematic, with rampant op-
portunities for harmful consequences—as the variety
of uses expands, demands for automation increase,
technological complexity grows, and capabilities of
would-be adversaries outpace those of defenders.
Characteristically, risks continue to recur that vio-
late trustworthiness requirements such as those noted
above. They tend to repeat themselves in one form
or another, suggesting a lack of foresight. For ex-
ample, see 33 years of ACM SIGSOFT’s Software
Engineering Notes (www.sigsoft.org/SEN/), 24-plus
years of the ACM Risks Forum (see www.risks.org
1063-9527/09 $26.00 © 2009 IEEE
DOI 10.1109/ACSAC.2009.13
35
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:09:52 UTC from IEEE Xplore.  Restrictions apply. 
for archives and how to subscribe), and Computer-
Related Risks [9], for copious examples, along with an
annotated index to many past cases [15]. The series
of Inside Risks columns in the Communications of
the ACM succinctly summarizes many of these risks
(www.csl.sri.com/neumann/insiderisks.html).
A
sample set of problems from that source material ap-
pears in my 2006 ACSAC paper [12] on the risks of
untrustworthiness, which considers just a few pro-
totypical problem areas—notably, unreliable backup,
nonrobust networking, and systems that are unsafe,
unsecure, or both.
Reﬂection on the RISKS archives leads to sev-
eral observations. The very ﬁrst issue (volume 1,
number 1) on August 1, 1985 noted that hot top-
ics included the relationship of computer systems to
money, privacy, and elections, and anticipated risks
in defense systems, human safety, consumer protec-
tion, and health care. That ﬁrst issue had items
on the Strategic Defense Initiative—the anti-missile
missile system euphemistically known as Starwars—
including a summary of Dave Parnas’s analysis of why
that approach was very unlikely to succeed, and an
item on Dave’s resignation from the advisory panel.
It also noted prior events including two serious auto-
mobile recalls due to program bugs (the El Dorado
brake computer and the Mark VII computerized air
suspension) and at least two heart pacemaker prob-
lems (one of which resulted in a death).
In crafting some expectations for the future in that
ﬁrst issue, I reported on a variety of money losses,
security problems, and a string of potential misuses
and undetectable mishaps in elections that suggested
opportunities for Trojan Horses and fraud. On the
subject of elections, I cited an article by David Burn-
ham that appeared on July 29, 1985 in The New York
Times, on vulnerabilities in various computerized
voting systems. Burnham noted that about 60% of
the votes were then being counted by computer pro-
grams, with over a third of those votes being counted
by one program (or variants thereof) written by what
was then Computer Election Systems of Berkeley CA
(subsequently merged into Business Records Corp.,
with legacy ties to today’s ES&S—which is now seek-
ing to acquire Diebold’s voting subsidiary). That sys-
tem reportedly could be undetectably manipulated to
modify election results. Burnham wrote, “The allega-
tions that vote tallies calculated with [that program]
may have been secretly altered have raised concern
among election oﬃcials and computer experts. ... In
Indiana and West Virginia, the company has been
accused of helping to rig elections.” At the time, I
wrote, “This topic is just warming up.” Twenty-four
years later, it remains very hot.
For two historically separated datapoints on the
history of that topic, see Ronnie Dugger’s article in
the November 7, 1988 issue of The New Yorker and
his later reprise in the August 16/23, 2004 issue of
The Nation. The lack of fundamental progress re-
ﬂected during the 16-year interval between those two
articles (both of which are on my website) and the
continuing lack of integrity in the use of all-electronic
(paperless) voting systems are very troubling.
Volume 1 of RISKS is replete with thoughtful items
with considerable foresight on risks that needed to
be addressed. Later volumes considered more of the
same risks, sometimes in new manifestations—and
particularly problems relating to security and privacy,
reliability and safety (for example,
in transporta-
tion, medical applications, and control systems), and
human well-being. Further, numerous cases have
been recorded in the RISKS archives that involve ex-
tremely bad system development and software engi-
neering practice, poorly designed human interfaces,
human errors, and malicious misuse by both insiders
and outsiders. Looking back, very few topics of con-
cern today were unanticipated, at least conceptually.
Not surprisingly, all of the above topics are still be-
ing discussed in RISKS, including the continued and
much-spirited controversy over election systems. New
incarnations of anti-missile missile systems keep ap-
pearing, although the technology and software engi-
neering assumed to someday exist still seem far away.
Widely propagating electrical power outages have oc-
curred surprisingly frequently since 1965. Safety risks
in aviation, railroads, process control systems, nu-
clear power, health care, and many other applica-
tion areas are threaded through the entire RISKS
archives, along with myriad security and privacy
problems. The 1980s saw considerable attention de-
voted to multilevel-secure systems, which still seem
like a pipe-dream with respect to the likelihood of
high-assurance commercially available products. The
1990s and 2000s were marked by beliefs in some cir-
cles that oﬀ-the-shelf products would eventually be
suﬃciently trustworthy, with considerable empirical
evidence to the contrary along the way.
What seems to have changed somewhat over the
years? Local security and privacy problems are in-
creasingly arising more globally in new contexts, such
as health care, distributed systems, Web servers and
browsers, cloud computing, and Internet-connected,
36
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:09:52 UTC from IEEE Xplore.  Restrictions apply. 
previously isolated systems as in national infrastruc-
tures that are inadequately prepared to meet the
increased risks. We have widespread cases of mal-
ware,
identity fraud, spam, phishing attacks, and
distributed denial-of-service attacks. There is also
increasing awareness that cryptographic algorithms
are by themselves inadequate to solve security prob-
lems, and ultimately must rely on being embedded in
trustworthy hardware and software.
Various common themes have emerged over the
years. For example, many usability problems have
resulted from poorly conceived human interfaces that
place inordinate demands on timely human interven-
tion. However, blame for serious risks is typically
placed on system operators, pilots, and users, not on
the designers and implementers of systems with inad-
equately speciﬁed requirements, badly conceived ar-
chitectures and human interfaces, poor development
methodologies, sloppy software engineering, inappro-
priate programming languages, and so on.
Further, short-sighted local optimization often re-
sults in risks that could have been avoided with even
a smidgen of long-term planning and globally moti-
vated considerations. Badly chosen tradeoﬀs may ac-
tually result in reducing trustworthiness. Many issues
are all too often ignored, such as long-term enterprise
survival and privacy.
Many of the risks discussed in my 1995 book
(Computer-Related Risks [9]) are still recurring in
one guise or another, and many of its recommenda-
tions remain relevant but unheeded. We continually
tilt at the same windmills, and the windmills seem
to be winning.
It is clear that some far-reaching
proactive measures are urgently needed—although
this is not a new conclusion.
Indeed, we are in
some ways merely reiterating certain previous ﬁnd-
ings and recommendations, such as those found in
reports of the National Research Council relating to
trustworthiness—from 1983 (Multilevel Data Man-
agement Security [21]), 1990 (Computers at Risk [3]),
1998 (Trust in Cyberspace [22]), to 2007 (Toward a
Safer and More Secure Cyberspace [5]).
3 Some Pressing Problems
Consider just a few representative pandemic problem
areas that encompass a variety of application scopes,
complexities, and potential risks.
• Critical Infrastructures. The November 1965
Northeast power blackout has been followed by nu-
37
merous similar events. Testimony before the Clinton-
era President’s Commission on Critical Infrastruc-
ture Protection repeatedly suggested that all of the
critical infrastructures were vulnerable to attacks on
the survivability, integrity, and security of their in-
formation infrastructures.
In 2009, vulnerabilities
in power distribution and other national critical in-
frastructures have been reported in public forums
as being widespread and relatively easy to exploit,
and computer systems controlling power grids have
been victimized by inserted trap doors and Trojan
horses. Further, the ability to detect, diagnose, and
respond to attacks and outages is inadequate. The
risks abound.
• Malware. Perhaps the most pervasive risks in-
volve the continued lack of trustworthiness within
critical information system and network infrastruc-
tures. For example, various generations of the Con-
ﬁcker malware suite [17] emerged during 2009, ini-
tially exploiting unpatched operating systems. Con-
ﬁcker represents some of the most sophisticated mal-
ware seen thus far, morphing in stages into succes-
sively more devious functionality. And yet, the po-
tential for much more serious consequences is almost
untapped, including ﬁnancial ruin, corporate demise,
clandestine surveillance, phishing attacks, massive
identity fraud, and so on. This is a problem that has
long been recognized and typically neglected. For ex-
ample, the 1988 Internet Worm provided a harbinger
of possible malware that has progressively led to
viruses, worms, and other malicious code. But ﬂaws
such as buﬀer overﬂows, overly permissive .rhosts
ﬁles, and easily compromised reusable passwords are
still rampant two decades later.
• Electronic Voting. Although elections are one
of our most critical infrastructures in maintaining
democracy, irregularities in elections are perhaps as
old as elections themselves. Serious vulnerabilities
exist in election processes today, and risks in the in-
formation system infrastructures are only one area of
problems. The frenzy after the 2000 U.S. national
election resulted in an aggressive move toward all-
electronic systems. However, all proprietary paper-
less electronic systems that emerged have pervasive
security vulnerabilities (e.g., see the California Secre-
tary of State’s 2007 Top-to-Bottom Review,
www.sos.ca.gov/elections/elections vsr.html),
almost no meaningful accountability, and inadequate
oversight and governance. These systems have se-
riously exacerbated the overall lack of election in-
tegrity, accompanied by inequities in voter registra-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:09:52 UTC from IEEE Xplore.  Restrictions apply. 
tion, sloppy management of registration databases,
and politicization of election processes. A recent ex-
ample involves the 2009 indictments of ﬁve people in
Kentucky for conspiracy to commit vote fraud, extor-
tion, and tampering with grand jury witnesses in a