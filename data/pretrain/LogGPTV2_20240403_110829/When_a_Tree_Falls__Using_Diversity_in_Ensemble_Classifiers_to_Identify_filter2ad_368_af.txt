space will be given classiﬁcations considered uncertain by the
classiﬁer. In some instances in our evaluation, the quality of
the training set was shown to be important to detection of
evasion attacks. For example, the superior PDFrate University
classiﬁer had considerably fewer evasions than the Contagio
classiﬁer for the Reverse Mimicry attacks. For the Drebin
evaluation, Family R represented strong evasion due to weak
features, but Family Q was detectable if it was included
in the training set. Therefore,
the effectiveness of mutual
agreement analysis is also dependent upon adequate coverage
in the training set. However, the effectiveness of the training
set is directly dependent upon the strength of the features.
A weak feature set will require a more expansive training
set than a feature set that more closely models fundamental
malicious attributes. Operators should ensure that features used
for malware detection are not only resistant to spooﬁng but that
they are based on artifacts caused by malware and not merely
coincidental with current attacks.
As was shown in Section V-B, keeping the training set
of a classiﬁer secret helps improves resiliency against targeted
evasion attempts. It might be advisable for operational systems
to hide the exact scores returned from their classiﬁers as these
scores assist attackers in knowing if changes they make hurt
or help their evasion attempts. This information could weaken
the beneﬁt provided by a secret training set [18].
The GD-KDE attacks of Mimicus demonstrate that some
classiﬁers can make machine learning based detectors sus-
ceptible to evasion attacks. Stochastically generated ensemble
classiﬁers have not been shown to be vulnerable to similar
attacks, but new approaches might be found. The ability to
measure mutual agreement in ensemble classiﬁers comes at
little cost, but provides for detection of practical classiﬁer
evasion. This capability is a strong reason to use ensembles
in situations where classiﬁer evasion is a concern, such as in
malware detectors. If mutual agreement is used to optimize
classiﬁer training, then an attacker may have more knowledge
of additions to the training set than if random selection is
used. However, it is not obvious how this knowledge could
be exploited by an attacker. Any effective attacks that use
knowledge of mutual agreement based training optimization
to poison the classiﬁer would be important.
Some advocate the use of simple, monolithic classiﬁers,
because the result
is perceived as easier to interpret. For
example, the ability of Drebin to identify the features that
contribute to the classiﬁcation is lauded. It
is not clear,
however, if this information is really useful to end users. Users
are already given the opportunity to review permissions and
often choose incorrectly when prompted. Given that URLs
and API calls can be socially engineered and that users are
generally not aware of these elements, it is not likely that
providing these items as context to a user will help them
make a correct decision. For security professionals, ensemble
classiﬁers provide mechanisms that aid in analysis such as
similarity to existing known malicious or benign samples. Most
importantly, the feature set will be useful to a trained analyst.
Mutual agreement analysis gives operators greater con-
ﬁdence in the accuracy of the classiﬁer and the ability to
prioritize response to alerts. Some operators will use ensemble
classiﬁer introspection simply to adjust the voting threshold.
Environments that seek to avoid false negatives (evasion at-
tacks) will use a low threshold and increase the number of
false positives. On the other hand, some environments might
use a higher than normal voting threshold to achieve a low
false positive but potentially higher false negative rate, such
as that achieved by antivirus engines.
The operator gets the most beneﬁt from mutual agreement
analysis when uncertain observations are subjected to focused
analysis. These samples must necessarily be subjected to
different and complementary analysis or detections. Since the
number of uncertain observations is low for a well performing
classiﬁer,
this second opinion can be relatively expensive,
possibly manually driven or involving dynamic analysis. En-
semble diversity based conﬁdence estimates are useful for
organizations that desire to identify novel attacks to perform
additional analysis. While possibly unconventional for the
machine learning ﬁeld, the addition of the uncertain outcome
is intuitive for the security ﬁeld where many systems provide
only adjudications for known observations, whether benign
or malicious. For example, it is common for SPAM ﬁlters
to utilize a quarantine for samples that cannot be classiﬁed
reliably. Very often, high ﬁdelity alerts are preferred over a
response for every observation.
Mutual agreement analysis is very effective at identifying
those samples which are not similar to the already known
samples in the training set. Since adding uncertain samples
to the classiﬁer dramatically improves the classiﬁer accuracy,
analysis of uncertain observations is likely to motivate rather
than desensitize operators. Operators are empowered to im-
prove the classiﬁer in a manner much more effective than
random additions to the training set.
13
Evaluation of machine learning based detectors might be
improved though application of mutual agreement analysis. A
concise metric is the Uncertain Rate, or portion of observations
for which a classiﬁer is poorly suited to provide a prediction.
The effectiveness of classiﬁer evaluation using the mutual
agreement score distribution and variance could be a topic
of future studies. The classiﬁer score distributions shown in
Figure 12 and Figure 13 seem to indicate that regression could
be used to predict the amount of successful evasions. The
difﬁculty in this type of analysis, however, is separating the
arcs for the benign and malicious data when external ground
truth is not provided.
Most importantly, monitoring mutual agreement in ensem-
ble classiﬁers raises the bar for evasion, for both previously
unseen attacks and targeted mimicry attacks. Contemporary
evasion attacks, which have called into question the resiliency
of learning based detectors, are shown to be weaker than
previously supposed. Merely obfuscating attacks such that they
no longer appear as known attacks is not enough. Successful
mimicries must very closely mirror benign samples. Of course,
future research into the degree to which mutual agreement
analysis can improve attack quality seems worthwhile.
IX. CONCLUSIONS
We introduce a new technique to detect malware classiﬁer
performance degradation on individual observations. Mutual
agreement analysis relies on diversity in ensemble classiﬁers
to produce an estimate of classiﬁer conﬁdence. We evaluate
our approach using over 100,000 PDF documents and 100,000
Android applications. Applying PDFrate to documents taken
from a real network, we ﬁnd that the number of uncertain
outcomes is small–only 0.2%. If these uncertain examples are
excluded, the true positive rate rises from 95% to 100% and
the false positive rate drops from 0.053% to 0.0050%. Fur-
thermore, mutual agreement analysis is effective at identifying
the samples to be added to the training set, resulting in con-
siderably more rapid improvements in classiﬁer performance
than random sampling. In the direct evasion attacks against
PDFrate and novel attacks against Drebin, the majority of the
observations are assigned the outcome of uncertain, notifying
the operator of the detector failure. While evasion attacks are
still possible, they require more complete mimicry across the
whole feature set.
We believe that mutual agreement analysis can be applied
generally to ensemble classiﬁers. We ﬁnd that feature bagging
is critical to diversity based evasion detection. The GD-KDE
attack, employed with great success against Support Vector
Machines, can be foiled by an SVM ensemble. Ensemble clas-
siﬁer mutual agreement analysis provides a critical mechanism
to evaluate the accuracy of machine learning based detectors
without using external validation.
ACKNOWLEDGMENTS
The authors would like to thank all of the reviewers
for their valuable comments and suggestions. This work is
supported by the National Science Foundation Grant No. CNS
1421747 and II-NEW 1205453. Opinions, ﬁndings, conclu-
sions, and recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the views
of the NSF or US Government.
REFERENCES
“Mimicus,” http://github.com/srndic/mimicus.
“R Project,” http://www.r-project.org/.
[1]
[2]
[3] M. Arnao, C. Smutz, A. Zollman, A. Richardson, and E. Hutchins,
“Laika BOSS: Scalable File-Centric Malware Analysis and Intrusion
Detection System,” https://github.com/lmco/laikaboss, Jul. 2015.
[4] D. Arp, M. Spreitzenbarth, M. H¨ubner, H. Gascon, and K. Rieck,
“Drebin: Effective and explainable detection of android malware in
your pocket,” in 21th Annual Network and Distributed System Security
Symposium (NDSS), Feb. 2014.
[5] D. Barbara, C. Domeniconi, and J. P. Rogers, “Detecting outliers using
transduction and statistical testing,” in Proceedings of the 12th ACM
SIGKDD international conference on Knowledge discovery and data
mining, ser. KDD ’06. New York, NY, USA: ACM, 2006, pp. 55–64.
[6] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar,
“Can Machine Learning Be Secure?” in Proceedings of the 2006 ACM
Symposium on Information, Computer and Communications Security,
ser. ASIACCS ’06. New York, NY, USA: ACM, 2006, pp. 16–25.
[7] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kruegel, and E. Kirda,
“Scalable, Behavior-Based Malware Clustering,” in Network and
Distributed System Security Symposium (NDSS) 2009, 2009.
[8] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Srndic, P. Laskov,
G. Giacinto, and F. Roli, “Evasion Attacks against Machine Learning
at Test Time,” in Machine Learning and Knowledge Discovery in
Databases, ser. Lecture Notes in Computer Science, H. Blockeel,
K. Kersting, S. Nijssen, and F.
Springer Berlin
Heidelberg, 2013, no. 8190, pp. 387–402.
ˇZelezn´y, Eds.
[9] B. Biggio and P. Laskov, “Poisoning attacks against Support Vector Ma-
chines,” in In International Conference on Machine Learning (ICML)
2012, 2012.
[10] C.-C. Chang and C.-J. Lin, “LIBSVM: A Library for Support Vector
Machines,” http://www.csie.ntu.edu.tw/˜cjlin/libsvm/, May 2011.
[11] D. Chinavle, P. Kolari, T. Oates, and T. Finin, “Ensembles in
Adversarial Classiﬁcation for Spam,” in Proceedings of the 18th ACM
Conference on Information and Knowledge Management, ser. CIKM
’09. New York, NY, USA: ACM, 2009, pp. 2015–2018.
[12] M. Cova, C. Kruegel, and G. Vigna, “Detection and Analysis
of Drive-by-download Attacks and Malicious JavaScript Code,” in
Proceedings of the 19th International Conference on World Wide Web,
ser. WWW ’10. New York, NY, USA: ACM, 2010, pp. 281–290.
[13] G. Cretu, A. Stavrou, M. Locasto, S. Stolfo, and A. Keromytis,
“Casting out Demons: Sanitizing Training Data for Anomaly Sensors,”
in Security and Privacy, 2008. SP 2008. IEEE Symposium on, 2008,
pp. 81–95.
[14] M. Egele, G. Stringhini, C. Kruegel, and G. Vigna, “COMPA: Detecting
Compromised Accounts on Social Networks.” in NDSS, 2013, 2013.
[15] P. Fogla and W. Lee, “Evading network anomaly detection systems:
the
formal reasoning and practical
13th ACM conference on Computer and communications security.
Alexandria, Virginia, USA: ACM, 2006, pp. 59–68.
techniques,” in Proceedings of
[16] M. Handley, V. Paxson, and C. Kreibich, “Network Intrusion Detection:
Evasion, Trafﬁc Normalization, and End-to-End Protocol Semantics.” in
2001 USENIX Security Symposium, 2001, pp. 115–131.
[17] M. Heiderich, M. Niemietz, F. Schuster, T. Holz, and J. Schwenk,
“Scriptless Attacks: Stealing the Pie Without Touching the Sill,”
in Proceedings of
the 2012 ACM Conference on Computer and
Communications Security, ser. CCS ’12. New York, NY, USA: ACM,
2012, pp. 760–771.
[18] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D.
Tygar, “Adversarial machine learning,” in Proceedings of the 4th ACM
workshop on Security and artiﬁcial intelligence, ser. AISec ’11. New
York, NY, USA: ACM, 2011, pp. 43–58.
[19] S. Jana and V. Shmatikov, “Abusing File Processing in Malware
Detectors for Fun and Proﬁt,” in 2012 IEEE Symposium on Security
and Privacy (SP), May 2012, pp. 80–94.
J. Jang, D. Brumley, and S. Venkataraman, “BitShred: feature hashing
malware for scalable triage and semantic analysis,” in Proceedings of
the 18th ACM conference on Computer and communications security,
ser. CCS ’11. New York, NY, USA: ACM, 2011, pp. 309–320.
[20]
14
[21] G. Kakavelakis, R. Beverly, and J. Young, “Auto-learning of
SMTP TCP Transport-Layer Features for Spam and Abusive Message
Detection,” in LISA 2011, 25th Large Installation System Administration
Conference. Boston, MA, USA: USENIX Association, Dec. 2011.
[22] L. I. Kuncheva and C. J. Whitaker, “Measures of Diversity in Classiﬁer
Ensembles and Their Relationship with the Ensemble Accuracy,” in
Machine Learning, vol. 51, May 2003, pp. 181–207.
[23] P. Laskov and R. Lippmann, “Machine learning in adversarial
environments,” in Machine Learning, vol. 81, Aug. 2010, pp. 115–119.
[24] P. Laskov and N. Srndic, “Static detection of malicious JavaScript-
bearing PDF documents,” in Proceedings of the 27th Annual Computer
Security Applications Conference, ser. ACSAC ’11. New York, NY,
USA: ACM, 2011, pp. 373–382.
[25] W.-J. Li, S. Stolfo, A. Stavrou, E. Androulaki, and A. D. Keromytis,
“A Study of Malcode-Bearing Documents,” in Detection of Intrusions
and Malware, and Vulnerability Assessment 2007, B. H¨ammerli and
R. Sommer, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg,
2007, vol. 4579, pp. 231–250.
[26] D. Maiorca, D. Ariu, I. Corona, and G. Giacinto, “A Structural and
Content-Based Approach for a Precise and Robust Detection of Mali-
cious PDF Files,” in Proceedings of the 1st International Conference on
Information Systems Security and Privacy. ScitePress Digital Library,
2015, pp. 27–36.
[27] D. Maiorca, I. Corona, and G. Giacinto, “Looking at
the bag is
not enough to ﬁnd the bomb: an evasion of structural methods for
malicious PDF ﬁles detection,” in Proceedings of the 8th ACM SIGSAC
symposium on Information, computer and communications security,
ser. ASIA CCS ’13. New York, NY, USA: ACM, 2013, pp. 119–130.
J. Mason, S. Small, F. Monrose, and G. MacManus, “English
Shellcode,” in Proceedings of the 16th ACM Conference on Computer
and Communications Security, ser. CCS ’09. New York, NY, USA:
ACM, 2009, pp. 524–533.
[28]
[29] E. Menahem, A. Shabtai, L. Rokach, and Y. Elovici, “Improving
in
malware
Computational Statistics & Data Analysis, vol. 53, Feb. 2009,
pp. 1483–1494.
applying multi-inducer
ensemble,”
detection
by
and Vulnerability Assessment, ser. DIMVA ’08. Berlin, Heidelberg:
Springer-Verlag, 2008, pp. 88–107.
[40] C. Smutz and A. Stavrou, “Malicious PDF Detection Using Metadata
and Structural Features,” in Proceedings of the 28th Annual Computer
Security Applications Conference, ser. ACSAC ’12. New York, NY,
USA: ACM, 2012, pp. 239–248.
[41] R. Sommer and V. Paxson, “Outside the Closed World: On Using
Machine Learning for Network Intrusion Detection,” in Security and
Privacy (SP), 2010 IEEE Symposium on, May 2010, pp. 305 –316.
[42] Y. Song, M. E. Locasto, A. Stavrou, A. D. Keromytis, and S. J.
Stolfo, “On the Infeasibility of Modeling Polymorphic Shellcode,”
in Proceedings of
the 14th ACM Conference on Computer and
Communications Security, ser. CCS ’07. New York, NY, USA: ACM,
2007, pp. 541–551.
[43] N. Srndic and P. Laskov, “Practical Evasion of a Learning-Based
Classiﬁer: A Case Study,” in Proceedings of the 2014 IEEE Symposium
on Security and Privacy, ser. SP ’14. Washington, DC, USA: IEEE
Computer Society, 2014, pp. 197–211.
[44] G. Stringhini, C. Kruegel, and G. Vigna, “Shady Paths: Leveraging
Surﬁng Crowds to Detect Malicious Web Pages,” in Proceedings of
the 2013 ACM SIGSAC Conference on Computer & Communications
Security, ser. CCS ’13. New York, NY, USA: ACM, 2013, pp.
133–144.
[45] G. Varghese, J. A. Fingerhut, and F. Bonomi, “Detecting evasion
attacks at high speeds without reassembly,” in Proceedings of the 2006
conference on Applications, technologies, architectures, and protocols
for computer communications. Pisa, Italy: ACM, 2006, pp. 327–338.
[46] B. Waske, S. van der Linden, J. Benediktsson, A. Rabe, and P. Hostert,
“Sensitivity of Support Vector Machines to Random Feature Selection
in Classiﬁcation of Hyperspectral Data,” in IEEE Transactions on
Geoscience and Remote Sensing, vol. 48, Jul. 2010, pp. 2880–2889.
[47] Y. Ye, L. Chen, D. Wang, T. Li, Q. Jiang, and M. Zhao, “SBMDS:
an interpretable string based malware detection system using SVM
ensemble with bagging,” in Journal in Computer Virology, vol. 5, Nov.
2008, pp. 283–293.
[30] B. Nelson, M. Barreno, F. J. Chi, A. D. Joseph, B. I. P. Rubinstein,
U. Saini, C. Sutton, J. D. Tygar, and K. Xia, “Exploiting machine
learning to subvert your spam ﬁlter,” in Proceedings of
the 1st
Usenix Workshop on Large-Scale Exploits and Emergent Threats 2008.
Berkeley, CA, USA: USENIX Association, 2008, pp. 7:1–7:9.
J. Neyman, “Outline of a Theory of Statistical Estimation Based on
the Classical Theory of Probability,” Philosophical Transactions of
the Royal Society of London. Series A, Mathematical and Physical
Sciences, vol. 236, no. 767, pp. 333–380, 1937.
Malicious
testing
archive
http://contagiodump.blogspot.com/2010/08/malicious-documents-
archive-for.html, Apr. 2011.
-
research,”
“11,355+
signature
Parkour,
for
documents
and
[31]
[32] M.
[33] R. Perdisci, D. Dagon, W. Lee, P. Fogla, and M. Sharif, “Misleading
worm signature generators using deliberate noise injection,” in Security
and Privacy, 2006 IEEE Symposium on, 2006, pp. 15 pp.–31.
[34] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and N. Provos,
“CAMP: Content-Agnostic Malware Protection.” in NDSS 2013, 2013.
[35] M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz, “A Bayesian
Approach to Filtering Junk E-Mail,” in AAAI 98 Workshop on Text
Categorization, Jul. 1998.
J. Schlumberger, C. Kruegel, and G. Vigna, “Jarhead analysis and
detection of malicious Java applets,” in Proceedings of the 28th Annual
Computer Security Applications Conference, ser. ACSAC ’12. New
York, NY, USA: ACM, 2012, pp. 249–257.
[36]
[37] H. Shacham, “The Geometry of Innocent Flesh on the Bone: Return-
into-libc Without Function Calls (on the x86),” in Proceedings of the
14th ACM Conference on Computer and Communications Security,
ser. CCS ’07. New York, NY, USA: ACM, 2007, pp. 552–561.
[38] G. Shafer and V. Vovk, “A Tutorial on Conformal Prediction,” Journal
of Machine Learning Research, vol. 9, pp. 371–421, Jun. 2008.
[39] M. Z. Shaﬁq, S. A. Khayam, and M. Farooq, “Embedded Malware
Detection Using Markov n-Grams,” in Proceedings of
the 5th
international conference on Detection of Intrusions and Malware,
15