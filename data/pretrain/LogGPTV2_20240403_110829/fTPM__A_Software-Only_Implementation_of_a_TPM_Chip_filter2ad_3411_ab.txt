products based on this work shipped.
• No Trusted Storage: Surprisingly, the ARM Trust-
Zone speciﬁcation offers no guidelines on how to imple-
ment secure storage for TrustZone. The lack of secure
storage drastically reduces the effectiveness of Trust-
Zone as trusted computing hardware.
Naively, one might think that code in TrustZone could
encrypt its persistent state and store it on untrusted stor-
age. However, encryption alone is not sufﬁcient because
(1) one needs a way to store the encryption keys securely,
and (2) encryption cannot prevent rollback attacks.
• Lack of Secure Entropy and Persistent Counters:
Most trusted systems make use of cryptography. How-
ever, the TrustZone speciﬁcation is silent on offering a
secure entropy source or a monotonically increasing per-
sistent counter. As a result, most SoCs lack an entropy
pool that can only be read from the secure world, and
a counter that can persist across reboots and cannot be
incremented by the normal world.
• Lack of virtualization: Sharing the processor across
two different worlds in a stable manner can be done using
virtualization techniques. Although ARM offers virtual-
ization extensions [2], the ARM TrustZone speciﬁcation
844  25th USENIX Security Symposium 
USENIX Association
4
does not mandate them. As a result, many ARM-based
SoCs used in mobile devices today lack virtualization
support. Virtualizing commodity operating systems on
an ARM platform lacking hardware-assistance for virtu-
alization is challenging.
• Lack of secure clock and other peripherals: Secure
systems often require a secure clock. While TrustZone
can protect memory, interrupts, and certain system buses
on the SoC, this protection does extend to the ARM pe-
ripheral bus. It is hard to reason about the security guar-
antees of a peripheral if its controller can be programmed
by the normal world, even when its interrupts and mem-
ory region are mapped into the secure world. Malicious
code could program the peripheral in a way that could
make it insecure. For example, some peripherals could
be put in “debug mode” to generate arbitrary readings
that do not correspond to the ground truth.
• Lack of access: Most SoC hardware vendors do not
provide access to their ﬁrmware. As a result, many de-
velopers and researchers are unable to ﬁnd ways to de-
ploy their systems or prototypes to TrustZone.
In our
experience, this has seriously impeded the adoption of
TrustZone as a trusted computing mechanism.
SoC vendors are reluctant to give access to their
ﬁrmware. They argue that their platforms should be
“locked down” to reduce the likelihood of “hard-to-
remove” rootkits.
Informally, SoC vendors also per-
ceive ﬁrmware access as a threat to their competitiveness.
They often incorporate proprietary algorithms and code
into their ﬁrmware that takes advantage of the vendor-
speciﬁc features offered by the SoC. Opening ﬁrmware
to third parties could expose more details about these fea-
tures to their competitors.
4 High-Level Architecture
Leveraging ARM TrustZone, we implement a trusted ex-
ecution environment (TEE) that acts as a basic operat-
ing system for the secure world. Figure 1 illustrates our
architecture, and our system’s trusted computing base
(TCB) is shown in the shaded boxes.
At a high-level, the TEE consists of a monitor, a dis-
patcher, and a runtime where one or more trusted ser-
vices (such as the fTPM) can run one at a time. The TEE
exposes a single trusted service interface to the normal
world using shared memory. Our system’s TCB com-
prises the ARM SoC hardware, the TEE layers, and the
fTPM service.
By leveraging the isolation properties of ARM Trust-
Zone,
the TEE provides shielded execution, a term
coined by previous work [5]. With shielded execution,
the TEE offers two security guarantees:
Normal World
Commodity OS
Linux/Windows
fTPM
Secure World
Other secure services
TEE Runtime
TEE Dispatcher
TEE Monitor
ARM SoC Hardware
Figure 1: The architecture of the fTPM. This diagram
is not to scale.
• Conﬁdentiality: The whole execution of the fTPM
(including its secrets and execution state) is hidden from
the rest of the system. Only the fTPM’s inputs and out-
puts, but no intermediate states, are observable.
• Integrity: The operating system cannot affect the be-
havior of the fTPM, except by choosing to refuse exe-
cution or to prevent access to system’s resources (DoS
attacks). The fTPM’s commands are always executed
correctly according to the TPM 2.0 speciﬁcation.
4.1 Threat Model and Assumptions
A primary assumption is that the commodity OS running
in the Normal World is untrusted and potentially com-
promised. This OS could mount various attacks to code
running in TrustZone, such as making invalid calls to
TrustZone (or setting invalid parameters), not respond-
ing to requests coming from TrustZone, or responding
incorrectly. In handling these attacks, it is important to
distinguish between two cases: (1) not handling or an-
swering TrustZone’s requests, or (2) acting maliciously.
The ﬁrst class of attacks corresponds to refusing ser-
vice, a form of Denial-of-Service attacks. DoS attacks
are out of scope according to the TPM 2.0 speciﬁca-
tion. These attacks cannot be prevented as long as an un-
trusted commodity OS has access to platform resources,
such as storage or network. For example, a compromised
OS could mount various DoS attacks, such as erasing all
storage, resetting the network card, or refusing to call the
smc instruction. Although our fTPM will remain secure
(e.g., preserves conﬁdentiality and integrity of its data) in
the face of these attacks, the malicious OS could starve
the fTPM leaving it inaccessible.
However, the fTPM must behave correctly when the
untrusted OS makes incorrect requests, returns unusual
values (or fails to return at all), corrupts data stored on
stable storage, injects spurious exceptions, or sets the
platform clock to an arbitrary value.
At the hardware level, we assume that the ARM SoC
(including ARM TrustZone) itself is implemented cor-
rectly, and is not compromised. An attacker cannot
USENIX Association  
25th USENIX Security Symposium  845
5
mount hardware attacks to inspect the contents of the
ARM SoC, nor the contents of RAM memory on the plat-
form. However, the adversary has full control beyond the
physical boundaries of the processor and memory. They
may read the ﬂash storage and arbitrarily alter I/O includ-
ing network trafﬁc or any sensors found on the mobile
device. In other work, we address the issue of physical
attacks on the memory of a mobile device [10].
We defend against side-channel attacks that can be
mounted by malicious software. Cache collision attacks
are prevented because all caches are ﬂushed when the
processor context switches to and from the Secure World.
Our fTPM implementation’s cryptography library uses
constant time cryptography and several other timing at-
tack preventions, such as RSA blinding [27]. However,
we do not defend against power analysis or other side-
channel attacks that require physical access to hardware
or hardware modiﬁcations.
We turn our focus on the approaches taken to over-
come TrustZone’s shortcomings in the fTPM.
5 Overcoming TrustZone Shortcomings
We used three approaches to overcome the shortcomings
of ARM TrustZone’s technology.
• Approach #1: Hardware Requirements. Providing
secure storage to TEE was a serious concern. One option
was to store the TEE’s secure state in the cloud. We dis-
missed this alternative as not viable because of its drastic
impact on device usability. TPMs are used to measure
the boot software (including the ﬁrmware) on a device.
A mobile device would then require cloud connectivity
at boot time in order to download the fTPM’s state and
start measuring the boot software.
Instead, we imposed additional hardware require-
ments on device manufacturers to ensure a minimum
level of hardware support for the fTPM. Many mobile
devices already come equipped with an embedded Multi-
Media Controller (eMMC) storage controller that has an
(off-SoC) replay-protected memory block (RPMB). The
RPMB’s presence, combined with encryption, ensures
that TEE can offer storage that meets the needs of all the
fTPM’s security properties. Thus, our ﬁrst hardware re-
quirement for TEE is an eMMC controller with support
for RPMB.
Second, we require the presence of hardware fuses ac-
cessible only from the secure world. A hardware fuse
provides write-once storage. At provisioning time (be-
fore being released to a retail store), manufacturers pro-
vision our mobile devices by setting the secure hardware
fuses with a secure key unique per device. We also re-
quire an entropy source accessible from the secure world.
The TEE uses both the secure key and the entropy source
to generate cryptographic keys at boot time.
Section 6 provides in-depth details of these three hard-
ware requirements.
• Approach #2: Design Compromises. Another big
concern was long-running TEE commands. Running in-
side TrustZone for a long time could jeopardize the sta-
bility of the commodity OS. Generally, sharing the pro-
cessor across two different worlds in a stable manner
should be done using virtualization techniques. Unfor-
tunately, many of the targeted ARM platforms lack vir-
tualization support. Speaking to the hardware vendors,
we learned that it is unlikely virtualization will be added
to their platforms any time soon.
Instead, we compromised and require that no TEE
code path can execute for long periods of time. This
translates into an fTPM requirement – no TPM 2.0 com-
mand can be long running. Our measurements of TPM
commands revealed that only one TPM 2.0 command is
long running: generating RSA keys. Section 7 presents
the compromise made in the fTPM design when an RSA
key generation command is issued.
• Approach #3: Modifying the TPM 2.0 Semantics.
Lastly, we do not require the presence of a secure clock
from the hardware vendors. Instead, the platform only
has a secure timer that ticks at a pre-determined rate.
We thus determined that the fTPM cannot offer any TPM
commands that require a clock for their security. Fortu-
nately, we discovered that some (but not all) TPM com-
mands can still be offered by relying on a secure timer
albeit with slightly altered semantics. Section 8 will de-
scribe all these changes in more depth.
6 Hardware Requirements
eMMC with RPMB
6.1
eMMC stands for embedded Multi-Media Controller,
and refers to a package consisting of both ﬂash memory
and a ﬂash memory controller integrated on the same sil-
icon die [11]. eMMC consists of the MMC (multimedia
card) interface, the ﬂash memory, and the ﬂash memory
controller. Later versions of the eMMC standard offer
a replay-protected memory block (RPMB) partition. As
the name suggests, RPMB is a mechanism for storing
data in an authenticated and replay-protected manner.
RPMB’s replay protection utilizes three mechanisms:
an authentication key, a write counter, and a nonce.
RPMB Authentication Key: A 32-byte one-time pro-
grammable authentication key register. Once written,
this register cannot be over-written, erased, or even read.
The eMMC controller uses this authentication key to
compute HMACs (SHA-256) to protect data integrity.
846  25th USENIX Security Symposium 
USENIX Association
6
Programming the RPMB authentication key is done by
issuing a specially formatted dataframe. Next, a result
read request dataframe must be also issued to check that
the programming step succeeded. Access to the RPMB
is prevented unless the authentication key has been pro-
grammed. Any write/read requests will return a special
error code indicating that the authentication key has yet
to be programmed.
RPMB Write Counter: The RPMB partition also
maintains a counter for the number of authenticated write
requests made to RPMB. This is a 32-bit counter ini-
tially set to 0. Once it reaches its maximum value, the
counter will no longer be incremented and a special bit
will be turned on in all dataframes to indicate that the
write counter has expired. The correct counter value
must be included in each dataframe written to the con-
troller.
Nonce: RPMB allows a caller to label its read re-
quests with 16-byte nonces that are reﬂected in the read
responses. These nonces ensure that reads are fresh.
6.1.1 Protection against replay attacks
To protect writes from replay attacks, each write includes
a write counter value whose integrity is protected by
an authentication key (the RPMB authentication key), a
shared secret provisioned into both the secure world and
the eMMC controller. The read request dataframe that
veriﬁes a write operation returns the incremented counter
value, whose integrity is protected by the RPMB authen-
tication key. This ensures that the write request has been
successful.
The role of nonces in read operations protects them
against replay attacks. To ensure freshness, whenever a
read operation is issued, the request includes a nonce and
the read response includes the nonce signed with RPMB
authentication key.
6.2 Secure World Hardware Fuses
We required a set of hardware fuses that can be read from
the secure world only. These fuses are provisioned with
a hard-to-guess, unique-per-device number. This number
is used as a seed in deriving additional secret keys used
by the fTPM. Section 9 will describe in-depth how the
seed is used in deriving secret fTPM keys, such as the
secure storage key (SSK).
6.3 Secure Entropy Source
The TPM speciﬁcation requires a true random number
generator (RNG). A true RNG is constructed by having
an entropy pool whose entropy is supplied by a hardware
oscillator. The secure world must manage this pool be-
cause the TEE must read from it periodically.
Generating entropy is often done via some physical
process (e.g., a noise generator). Furthermore, an en-
tropy generator has a rate of entropy that speciﬁes how
many bits of entropy are generated per second. When the
platform is ﬁrst started, it can take some time until it has
gathered “enough” bits of entropy for a seed.
We require the platform manufacturer to provision an
entropy source that has two properties: (1) it can be man-
aged by the secure world, and (2) its speciﬁcation lists a
conservative bound on its rate of entropy; this bound is
provided as a conﬁguration variable to the fTPM. Upon
a platform start, the fTPM waits to initialize until suf-
ﬁcient bits of entropy are generated. For example, the
fTPM would need to wait at least 25 seconds to initialize
if it requires 500 bits of true entropy bits from a source
whose a rate is 20 bits/second.
Alerted to this issue, the TPM 2.0 speciﬁcation has
added the ability to save and restore any accumulated but
unused entropy across reboots. This can help the fTPM
reduce the wait time for accumulating entropy.
7 Design Compromises
7.1 Background on Creating RSA Keys
Creating an RSA key is a resource-intensive operation
for two reasons. First, it requires searching for two large
prime numbers, and such a search is theoretically un-
bounded. Although many optimizations exist on how
to search RSA keys efﬁciently [40], searching for keys
is still a lengthy operation. Second, the search must
be seeded with a random number, otherwise an attacker
could attempt to guess the primes the search produced.
Thus the TPM cannot create an RSA key unless the en-
tropy source has produced enough entropy to seed the
search.
The TPM can be initialized with a primary storage
root key (SRK). The SRK’s private portion never leaves
the TPM and is used in many TPM commands (such as
TPM seal and unseal). Upon TPM initialization, our
fTPM waits to accumulate the entropy required to seed
the search for large prime numbers. The fTPM also cre-
ates RSA keys upon receiving a create RSA keys com-
mand1.
TPM 2.0 checks whether a number is prime using the
Miller-Rabin probabilistic primality test [40]. If the test
fails, the candidate number is not a prime. However,
upon passing, the test offers a probabilistic guarantee
– the candidate is likely a prime with high probability.
The TPM repeats this test a couple of times to increase
1This corresponds to the TPM 2.0 TPM2 Create command.
USENIX Association  
25th USENIX Security Symposium  847
7
the likelihood the candidate is prime. Choosing a com-
posite number during RSA key creation has catastrophic
security consequences because it allows an attacker to
recover secrets protected by that key. TPM 2.0 repeats
the primality test ﬁve times for RSA-1024 keys and four
times for all RSA versions with longer keys. This re-
duces the likelihood of choosing a false prime to a prob-
ability lower than 2−100.
7.2 Cooperative Checkpointing
Our fTPM targets several different ARM platforms (from
smartphones to tablets) that lack virtualization support,
and the minimal OS in our TEE lacks a preemptive
scheduler. Therefore, we impose a requirement on ser-
vices running in the TEE that the transitions to TEE and
back must be short to ensure that the commodity OS re-
mains stable. Unfortunately, creating an RSA key is a
very long process, often taking in excess of 10 seconds
on our early hardware tablets.
Faced with this challenge, we added cooperative
checkpointing to the fTPM. Whenever a TPM command
takes too long, the fTPM checkpoints its state in mem-
ory, and returns a special error code to the commodity
OS running in the Normal World.
Once the OS resumes running in the Normal World,
the OS is free to call back the TPM command and in-
struct the fTPM to resume its execution. These “resume”
commands continue processing until the command com-
pletes or the next checkpoint occurs. Additionally, the
fTPM also allows all commands to be cancelled. The
commodity OS can cancel any TPM command even
when in the command is in a checkpointed state. Cooper-
ative checkpointing lets us bypass the lack of virtualiza-
tion support in ARM, yet continue to offer long-running
TPM commands, such as creating RSA keys.
8 Modifying TPM 2.0 Semantics
8.1 Secure Clock
TPMs use secure clocks for two reasons. The ﬁrst use is
to measure lockout durations. Lockouts are time periods
when the TPM refuses service. Lockout are very impor-
tant to authorizations (e.g., checking a password). If a
password is incorrectly entered more than k times (for a
small k), the TPM enters lockout and refuses service for
a pre-determined period of time. This thwarts dictionary
attacks – guessing a password incorrectly more than k
times puts the TPM in lockout mode.
The second use of a secure clock in TPMs is for time-
bound authorizations, such as the issuing an authoriza-
tion valid for a pre-speciﬁed period of time. For exam-
ple, the TPM can create a key valid for an hour only. At
TEE increments
volatile clock
+
If (volatile_clock-persisted_clock) > 4ms
persist volatile_clock
Normal World
Secure World
Figure 2: fTPM clock update.
the end of an hour, the key becomes unusable.
8.1.1 Requirements of the TPM 2.0 Speciﬁcation
A TPM 2.0 requirement is the presence of a clock with
millisecond granularity. The TPM uses this clock only to
measure intervals of time for time-bound authorizations
and lockouts. The volatile clock value must be persisted