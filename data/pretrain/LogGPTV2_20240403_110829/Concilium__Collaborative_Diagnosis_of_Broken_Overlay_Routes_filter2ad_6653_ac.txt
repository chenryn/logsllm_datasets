other’s votes, they will eventually determine that B makes a
poor peer and treat it accordingly.
Note that standalone reputation systems cannot replace
Concilium’s full accusation protocol. Reputation systems al-
low a node to make a direct accusation against the next hop
in a route, but they provide no structured way to propagate
accusations against nodes that are farther downstream. Using
recursive stewardship of messages and recursive revision of
accusations, Concilium provides such a capability. Concil-
ium also provides self-validating accusations which can be
conﬁrmed by arbitrary third parties.
3.7 Implementation Options
Up to now, we have assumed that each node performs
its own tomographic probing. However, hosts which trust
each other and reside in the same stub network can consol-
idate probing responsibility. For example, hosts could take
turns issuing the probes for the multi-forest induced by their
collective routing state. Alternatively, all hosts could de-
fer probing responsibility to a shared administrative machine
such as a RON gateway [1]. Either solution would make
heavyweight probing less onerous, since the bandwidth cost
for probing shared links could be amortized across multiple
nodes.
As described in Section 3.4, a fault judgment is based on
the acknowledgment of an individual message reception. If
two peers exchange many packets, it may be useful for a sin-
gle acknowledgment to cover multiple messages. The ac-
knowledgment could indicate loss rates in several ways [15],
e.g., through simple counters indicating how many pack-
ets arrived, or packet hashes identifying the speciﬁc packets
which were received.
Concilium’s goal is to ﬁnd misbehaving overlay hosts and
broken IP links, but it is agnostic about the response to its
fault identiﬁcations. Broken IP links are often discovered
quickly by the responsible ISP, so an overlay may simply
avoid certain overlay paths until the fault is ﬁxed [1]. With
respect to faulty overlay hosts, Concilium allows each sys-
tem to set an appropriate sanctioning policy. For example,
accused hosts may not be trusted to forward sensitive mes-
sages.
If the overlay is used as a substrate for a higher level ser-
vice such as a DHT, then honest nodes must not make local
decisions to evict accused nodes from leaf sets. Otherwise,
inconsistent routing [6] will arise and the higher level service
may break. A network can mandate that a node be univer-
sally blacklisted if it receives accusations at a certain rate.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Figure 1. Modeling jump table occupancy
(a) False positive probability.
In such an environment, nodes would check the accusation
repository before agreeing to peer with a new host. If the
prospective peer was discovered to be faulty, it would not be
added to the local routing table.
4 Evaluation
In this section, we use extensive simulations to evaluate
the accuracy of our jump table check, the coverage proper-
ties of our collaborative tomography, and the error rate of
our accusation algorithm. We also investigate the bandwidth
overhead of the Concilium protocol.
4.1 Jump Table Validation
Peers exchange their routing state so that Concilium can
determine the IP-level tomographic data needed to make
fault accusations at the overlay level.
If peers can adver-
tise incorrect routing tables without detection, innocent peers
may be accused and faulty peers may go unpunished. Thus,
the success of Concilium hinges on its ability to detect fraud-
ulent routing advertisements.
In this section, we analyze
Concilium’s jump table tests; we defer an analysis of leaf
set checks to Castro’s work [7].
Our jump table test uses the cdf φ(µφ, σφ) to model the
distribution of occupancy fractions. Figure 1 compares the
occupancy levels predicted by the analytic model with the
occupancy levels seen in Monte Carlo simulations of table
occupancy (y-bars indicate standard deviations). We see that
the φ(µφ, σφ) distribution accurately approximates real oc-
cupancy levels.
Our density test declares that a jump table is faulty if
γdpeer < dlocal. The test can produce both false positives
and false negatives. A false positive occurs if a non-faulty
peer has a legitimately sparse jump table but is deemed faulty
anyways. The likelihood of a false positive is equivalent to
P r(γdpeer < dlocal) =
P r(di)P r(d <
(cid:183)
(cid:88)
(cid:183)
(cid:88)
=
0≤di≤‘v
0≤di≤‘v
(φ(di +
(b) False negative probability.
(c) Overall misclassiﬁcation rate when γ is chosen to minimize
the sum of the two error probabilities.
Figure 2. Error rates (no suppression attacks)
Figure 2(a) depicts the false positive rate as a function of γ
and the fraction c of colluding malicious nodes. This graph
assumes that malicious nodes may drop messages, but they
may not try to go ofﬂine in a concerted attempt to skew local
density estimates [7]. Thus, the false positive rate is indepen-
dent of the fraction of malicious peers. Later in this section,
we will revisit this graph in the context of suppression at-
tacks.
The likelihood of a false negative is
P r(γdpeer ≥ dlocal) =
[P r(di)P r(d < γdi)]
(cid:88)
0≤di≤‘v
(cid:184)
(cid:183)
(cid:88)
=
0≤di≤‘v
(cid:184)
di
γ
)
(cid:184)
)
1
2
) − φ(di − 1
2
))φ( di
γ
(φ(di +
1
2
) − φ(di − 1
2
))φ(γdi)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
405060708010,00025,00050,000100,000250,000500,0001,000,000Total Number of Overlay HostsAverage Number of Occupied Jump Table SlotsSimulationAnalytic Prediction 1 1.05 1.1 1.15 1.2 1.25 1.3 0 0.1 0.2 0.3 0.4 0.5 0 0.2 0.4 0.6 0.8 1Pr(false positive)gcPr(false positive) 1 1.05 1.1 1.15 1.2 1.25 1.3 0 0.1 0.2 0.3 0.4 0.5 0 0.2 0.4 0.6 0.8 1Pr(false negative)gcPr(false negative)0%20%40%60%80%100%2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.0%27.5%30.0%32.5%Colluding, Malicious Host FractionError RateFalse Positive RateFalse Negative Rate37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007(a) False positive probability.
(b) False negative probability.
(c) Overall misclassiﬁcation rate when γ is chosen to minimize
the sum of the two error probabilities.
Figure 3. Error rates (suppression attacks)
A false negative occurs when a peer advertises a jump ta-
ble that only contains attacker-controlled nodes and the table
passes the density test. Figure 2(b) shows the false negative
probability in the absence of suppression attacks. Due to the
properties of secure routing tables, an attacker is expected to
control only c percent of all nodes in a jump table. Thus, the
density of the attacker’s fraudulent table is modeled as that
of a legitimate table in an overlay with N c total hosts. In the
previous equation, when we calculate P r(di), i.e., the prob-
ability that the advertised jump table contains di nodes, we
use Equation 1 but set the number of nodes to N c.
Using Figures 2(a) and (b), we can choose the γ which
minimizes some error metric. For example, Figure 2(c)
shows the misclassiﬁcation rate when γ is chosen to mini-
mize the sum of the false positive probability and the false
Figure 4. Trees Sampled vs. Forest Coverage
negative probability. If 30% of all peers are malicious and
colluding, the false positive rate is 8.5% and the false nega-
tive rate is 14.8%. If 20% of hosts collude, the false negative
rate decreases to 3.5%.
Figure 3 shows misclassiﬁcation rates when adversaries
can launch suppression attacks. We model these attacks by
supplying our false positive/negative equations with the ap-
propriately skewed versions of N as we did above. Like Cas-
tro’s density tests for leaf sets [7], our jump table checks are
not very reliable if more than 20% of hosts are malicious and
colluding. For example, with a c of 20%, the false positive
rate is 10.1% but the false negative rate is already 21.1%.
Devising effective defenses against suppression attacks is an
important area for future research. However, we note that c
represents the largest set of colluding malicious nodes. The
total number of malicious nodes may be much larger, but
their power is limited by the extent to which they can coor-
dinate the suppression of their identiﬁers.
4.2 Link Coverage
To test the coverage of tomographic probing and the accu-
racy of Concilium’s accusation algorithm, we used a discrete
event network simulator. The simulator modeled link fail-
ure, tomographic probing, the collaborative dissemination of
probe results, and three types of message events (message
sent, message acknowledged, message not acknowledged).
The simulator placed a Pastry overlay atop an IP topology
gathered by the SCAN project [11]. The topology con-
tained peering information for 112,969 routers connected by
181,639 links. Following the methodology of Chen et al [9],
we deﬁned end hosts as routers with only one link and ran-
domly selected 3% of these machines to be Pastry nodes. The
resulting overlay possessed 1,131 nodes.
In the simulations, 5% of links were bad at any moment.
Average link downtime was 15 minutes with a standard devi-
ation of 7.5 minutes; this accords with empirical observations
of high loss incidents lasting for a few tens of minutes [14].
Failures were biased towards links at the edge of the net-
work [14]. To select a new link for failure, we randomly
picked an overlay host and a random peer in that host’s rout-
ing state. We then used a beta distribution with α=0.9 and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:21:03 UTC from IEEE Xplore.  Restrictions apply. 
 1 1.05 1.1 1.15 1.2 1.25 1.3 0 0.1 0.2 0.3 0.4 0.5 0 0.2 0.4 0.6 0.8 1Pr(false positive)gcPr(false positive) 1 1.05 1.1 1.15 1.2 1.25 1.3 0 0.1 0.2 0.3 0.4 0.5 0 0.2 0.4 0.6 0.8 1Pr(false negative)gcPr(false negative)0%20%40%60%80%100%2.5%5.0%7.5%10.0%12.5%15.0%17.5%20.0%22.5%25.0%27.5%30.0%32.5%Colluding, Malicious Host FractionError RateFalse Positive RateFalse Negative Rate0%20%40%60%80%100%0510152025303540Number of Included Peer TreesPercentage of Forest Links Covered00.511.522.53# of Vouching Peers per Link% of Forest LinksCovered# of VouchingPeers37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007β=0.6 to select the depth of the link that would fail. Simu-
lations lasted for two virtual hours. We did not model ﬂuc-
tuating machine availability since we wanted to focus on the
fundamental properties of our fault inference algorithm.
Figure 4 shows the average percentage of IP links in FH
that are covered when H includes a given number of peer
trees. If a node probes only its own tree, it can gather to-
mographic data for 25% of its forest links. Increasing the
number of included peer trees results in large initial gains,
but the improvement in coverage diminishes as more trees
are included. This is because only a few trees are needed
to cover highly shared links in the center of the Internet, but
many trees are needed to cover all of the last-mile links that
are only used by a few hosts.
As shown in Figure 4, gathering probe results from more
peers increases the average number of hosts that test a given
link and can potentially vouch for the status of that link at an
arbitrary time. By increasing the number of vouching peers
for a link, we improve the quality of tomographic inferences
for that link. Greater link coverage also reduces the ability of
malicious nodes to taint the diagnostic process by submitting
bad tomographic data.
4.3 Accuracy of Fault Accusations
Accurate fault accusation requires accurate tomography.
Dufﬁeld et al reported high levels of accuracy for striped
unicast probing, with inferred link loss rates within 1% of
the actual ones [10]. High accuracy rates have also been re-
ported for other tomographic techniques [14]. In this section,
we assume that hosts can identify whether a link was up or
down with 90% accuracy.
Given the probe accuracy, we are interested in the amount
of blame assigned to a forwarding peer when a message is
dropped. Figure 5 depicts the probability distribution func-
tions for the blame that Concilium assigns to faulty and non-
faulty nodes. We generated the pdf by taking each triple of
hosts (A, B, C) 2 and picking ten random times within the
simulation period for A to route a message through B → C.
By comparing the actual link state along B → C to the to-
mographic information available to A at that time, we deter-
mined the amount of blame that A would assign to B if A did
not receive an acknowledgment from the message recipient.
B was a faulty node if it dropped a message despite B → C
being good; it was non-faulty if at least one link in B → C
was bad. Due to space constraints, we do not show results
for the recursive revision of accusations; thus, the simulator
ensured that a message was dropped either by B or a network
link along B → C, not by another peer or link further down
the overlay route to the destination host.
Figure 5(a) depicts the blame pdf when all peers faith-
fully reported their probe results. Figure 5(b) depicts the
blame pdf when 20% of peers colluded to maliciously ﬂip
2This selection was constrained by the routing tables of each node, i.e.,