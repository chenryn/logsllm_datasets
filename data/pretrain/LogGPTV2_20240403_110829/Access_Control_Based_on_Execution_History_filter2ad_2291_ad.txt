by adding another set of SIDs to the security token,
which further restricts the process.
• There is no counterpart for the explicit ampliﬁcation
of rights. Restricted tokens correspond to permis-
sions that cannot be acquired via explicit modiﬁca-
tions (see Section 3.2). Thus, restricted tokens pro-
vide strong guarantees (a process will never obtain
a right once the right is denied) at the cost of ex-
pressiveness (sensitive operations must instead be re-
quested using inter-process communication).
Beyond the reuse of well-known security concepts, a
mapping from current rights to security tokens has con-
crete advantages. Crucially, system calls can be per-
formed with the appropriate privileges. Also, SIDs can
be shared across machines within the same domain.
In
contrast, at present, code-based security policies and per-
missions in the CLR are relative to the local host machine
(for example, dealing with permissions for all ﬁles on the
local drive C:\).
When handling calls on services of an underlying op-
erating system (or calls to execution environments on re-
mote machines), it is particularly attractive to avoid com-
plicated translations of rights, as those translations can be
expensive and inaccurate. Such translations are easy to
avoid if the current rights are exactly those of one particu-
lar user of the underlying operating system. In that special
case, the user id can be employed as the representation for
those rights. We can generalize from this special case by
keeping track of rights partly in terms of code origins, as
discussed in Section 3.
8 Related Work
The security literature contains much related work.
Some of it is mentioned above, for example the use of
information-ﬂow control (e.g., [4, 14]).
History-based access control may be viewed as a prag-
matic approximation to information-ﬂow control
that
keeps track of code execution but not data dependencies.
Going further back, there is related work in the classic lit-
erature on operating systems, expressed in terms of pro-
tection rings [18, 16]. These rings might be seen as a
very simple, ﬁxed hierarchy of sets of static rights, with
an automatic update mechanism for current rights, and
with hardware support. In the remainder of this section we
focus on recent related work, particularly on work about
stack inspection.
Stack-based mechanisms for access control are widely
documented for JVMs [9] and the CLR [5, 12].
In the
research literature, many works treat the analysis and op-
timization of permissions (see for instance [11, 15]). Oth-
ers deal with interesting, non-trivial implementations of
stack inspection, for instance with inlined reference moni-
tors [7] or in security-passing style [21]. These implemen-
tations suggest that an eager computation of current rights
can be made as efﬁcient as a lazy computation by stack in-
spection. (The operations performed by these implemen-
tations to simulate a stack-based semantics are similar but
generally more complex than the operations for comput-
ing history-based rights described in Section 3.2.)
At a more semantic level, Wallach et al. explicate stack
inspection in terms of a logic of access control (ABLP
logic) [21]. They model security contexts and decisions
in terms of logical statements. The powerful idea of re-
lating stack inspection to logic should also apply, mutatis
mutandi, to our history-based technique. We discuss this
point only in order to highlight differences with stack in-
spection, so we avoid formal details. Basically, Wallach
et al. associate a set of logical statements EF with each
stack frame F . They map operations to logical statements:
Ok(T ) means that it is ok to perform operation T . The ac-
cess control problem consists in deciding whether a frame
can perform an operation T , and is reduced to deciding
whether EF logically implies Ok(T ). When a frame F
calls a frame G, for each of F ’s statements s, one adds
F says s to G’s statements. Signiﬁcantly, there is no cor-
responding modiﬁcation when G returns. In contrast, with
history-based rights, the current rights are affected when-
ever there is any transfer of control—whether the transfer
corresponds to a method call or return, and also for exam-
ple if it results from exception handling.
Fournet and Gordon also consider an abstract model of
stack inspection mechanisms [8], based on that of Pottier
et al. [15]. In a simple functional setting (a lambda cal-
culus), they discuss limitations of stack inspection. Using
formal operational semantics, they also explore several al-
ternatives to stack inspection with stronger properties by
reﬁning the reduction rule that discards a security frame
after an evaluation. The present paper can roughly be
seen as an elaboration of one of these alternatives, focused
on control transfers (rather than more general ﬂows of in-
formation), and targeted at a full-ﬂedged runtime system
(quite different from the lambda calculus).
Execution history also plays a role in Schneider’s secu-
rity automata [17] and in the Deeds system of Edjlali et
al. [6]. However, those works focus on collecting a selec-
tive history of sensitive access requests and use this infor-
mation to constrain further access requests: for instance,
network access may be explicitly forbidden after reading
certain ﬁles. In contrast, our approach considers the his-
tory of control transfers, rather than a history of sensitive
requests.
9 Conclusions
From a functional perspective, history-based rights
computation is largely compatible with existing security
machinery and libraries, although it requires runtime mod-
iﬁcations and suggests optimizations and language exten-
sions. From a security perspective, we believe that the
beneﬁts of access control based on execution history are
substantial. It provides a simpler alternative to stack in-
spection, and supports a safer, wiser posture with respect
to security checks.
Acknowledgments We are grateful
to Praerit Garg,
Andy Gordon, Tony Hoare, Brian LaMacchia, Butler
Lampson, Paul Leach, and Erik Meijer for discussions
on the subject of this paper, to Mike Burrows for help
with the title, and to Dan Wallach and anonymous re-
viewers for help with the presentation. Most of Mart´ın
Abadi’s work was done at Microsoft Research, Silicon
Valley, with Microsoft’s support. Mart´ın Abadi’s work
was also partly supported by the National Science Foun-
dation under Grants CCR-0204162 and CCR-0208800.
References
[1] B. N. Bershad, S. Savage, P. Pardyak, E. G. Sirer, M. E.
Fiuczynski, D. Becker, C. Chambers, and S. J. Eggers. Ex-
tensibility, safety and performance in the SPIN operating
system. In Proceedings of the 15th ACM Symposium on
Operating System Principles, pages 267–284, 1995.
[2] D. Box. Essential .NET Volume I: The Common Language
Runtime. Addison Wesley, 2002. To appear.
[3] D. F. C. Brewer and M. J. Nash. The chinese wall security
policy. In Proceedings of the 1989 IEEE Symposium on
Security and Privacy, pages 206–214, 1989.
[4] D. Denning. Cryptography and Data Security. Addison
Wesley, 1982.
[5] ECMA. Standard ECMA-335: Common Language In-
frastructure, Dec. 2001. Available from http://msdn.
microsoft.com/net/ecma/.
[6] G. Edjlali, A. Acharya, and V. Chaudhary. History-based
access control for mobile code.
In ACM Conference on
Computer and Communications Security, pages 38–48,
1998.
´U. Erlingsson and F. Schneider. IRM enforcement of Java
stack inspection. In Proceedings of the 2000 IEEE Sympo-
sium on Security and Privacy, pages 246–255. IEEE Com-
puter Society Press, 2000.
[7]
[8] C. Fournet and A. D. Gordon. Stack inspection: The-
ory and variants. In 29th ACM Symposium on Principles
of Programming Languages (POPL’02), pages 307–318,
Jan. 2002.
[9] L. Gong.
Inside JavaTM 2 Platform Security. Addison
Wesley, 1999.
[10] N. Hardy. The confused deputy. ACM Operating Systems
Review, 22(4):36–38, Oct. 1988. Available from
http://www.cis.upenn.edu/˜KeyKOS/
ConfusedDeputy.html.
[11] T. Jensen, D. L. Metayer, and T. Thorn. Veriﬁcation of
control ﬂow based security properties. In Proceedings of
the 1999 IEEE Symposium on Security and Privacy, pages
89–103. IEEE Computer Society Press, 1999.
[12] S. Lange, B. LaMacchia, M. Lyons, R. Martin, B. Pratt,
.NET Framework Security. Addison
and G. Singleton.
Wesley, 2002.
[13] T. Lindholm and F. Yellin. The JavaTM Virtual Machine
Speciﬁcation. Addison Wesley, 1997.
[14] A. C. Myers.
JFlow: Practical, mostly-static informa-
tion ﬂow control. In 26th ACM Symposium on Principles
of Programming Languages (POPL’99), pages 228–241,
1999.
[15] F. Pottier, C. Skalka, and S. Smith. A systematic approach
to access control.
In Programming Languages and Sys-
tems (ESOP 2001), volume 2028 of LNCS, pages 30–45.
Springer, 2001.
[16] J. H. Saltzer. Protection and the control of information
sharing in multics. Communications of the ACM, 17(7),
July 1974.
[17] F. B. Schneider. Enforceable security policies. ACM
Transactions on Information and System Security, 3(1):
30–50, Feb. 2000.
[18] M. D. Schroeder and J. H. Saltzer. A hardware architecture
for implementing protection rings. Communications of the
ACM, 15(3):157– 170, 1972.
[19] D. A. Solomon and M. E. Russinovich. Inside Microsoft
Windows 2000. Microsoft Press, third edition, 2000.
[20] D. Stutz. The Microsoft shared source CLI implementa-
tion. Mar. 2002. Available from
http://msdn.microsoft.com/library/en-
us/Dndotnet/html/mssharsourcecli.asp.
[21] D. S. Wallach, A. W. Appel, and E. W. Felten. SAFKASI:
A security mechanism for language-based systems. ACM
Transactions on Software Engineering and Methodology,
9(4):341–378, 2000.
public class Permissions
{
// Static permissions attributed to the immediate caller :
public static Permissions Static ;
// Dynamic permissions at
private static Permissions now;
// Automatically updated whenever some code runs ,
// with an implicit : now = now. Intersect ( Static ).
this stage
// Dynamic permissions can be read and updated:
public static Permissions Current {
get { return now; }
set {
if ( value . IsSubsetOf ( Static )) now = value ;
else throw new SecurityException (” Ampliﬁcation not permitted .” );
}
}
// Imperative actions on permissions ( same interface as in the CLR):
public void Demand() {
if ( this . IsSubsetOf (Current )) return;
else throw new SecurityException (”Operation not permitted .” );
}
{ Current = now.Union(this ); }
public void Assert ()
{ now = now. SetDifference ( this ); }
public void Deny()
public void PermitOnly () { now = now. Intersect ( this ); }
// Data methods (same methods as in the CLR):
public Permissions Union(Permissions p) {}
public Permissions SetDifference ( Permissions p) {}
public Permissions
public bool IsSubsetOf ( Permissions p) {}
}
Intersect ( Permissions p) {}
}
Figure 1. The class Permissions.
Appendix:
A Partial Implementation in C]
In this appendix, we provide a modiﬁed interface to per-
missions and its partial implementation, in the context of
C] and the CLR. Two essential aspects of an implemen-
tation are omitted here: the automatic update mechanism
for the current rights (represented as the public property
Permissions .Current), and an access mechanism to the
static rights associated with a given piece of code (repre-
sented as local variables Permissions . Static).
First, in Figure 1, we deﬁne a class Permissions, used
below, that provides the base interface to history-based
permissions—speciﬁc permission classes would be repre-
sented as subclasses of Permissions. Whenever possible,
we use the same method names as in the existing (stack-
based) system class CodeAccessSecurityPermission in the
CLR.
Next, we illustrate in some detail our two ampliﬁcation
patterns, “Grant” and “Accept” (Figures 2 and 3). For
each pattern, we ﬁrst rely on the high-level syntax de-
ﬁned in Section 5, then we implement the same behav-
ior in terms of lower-level operations on the current rights
(deﬁned in the class Permissions in Figure 1).
public class GrantExample
{
// Static permissions attributed to this class by the security policy :
static Permissions Static ;
// Handpicked sets of permissions ( application −speciﬁc ):
static Permissions prior ;
static Permissions extra ;
//
// extra rights of a privileged callee .
rights of a minimally−trusted valid caller .
// GRANT is a controlled form of privilege
//
public void LibraryGate () {
that
temporarily gives extra permissions to a speciﬁc block .
elevation
// usually checks preconditions
// such as the presence of some permissions :
prior .Demand();
this block of code:
// elevates permissions for
Grant ( extra ) {
/∗ run sensitive code requesting elevated privileges ∗/
}
/∗ continue with ordinary code ∗/
}
// idem, using lower−level operations on Permissions . Current .
public void ImplementLibraryGate () {
prior .Demand();
Permissions before = Permissions .Current;
try {
elevation
// privilege
extra . Assert ();
/∗ run sensitive code requesting elevated privileges ∗/
}
ﬁnally {
before .PermitOnly ();
}
/∗ continue with ordinary code ∗/
// cancels privilege
elevation
}
}
Figure 2. “Grant”.
delegate int IntCode ();
// some basic interface to untrusted code
public class AcceptExample
{
// Static permissions attributed to this class by the security policy
static Permissions Static ;
// Handpicked sets of permissions ( application −speciﬁc ):
static Permissions saved ;
restored after untrusted calls
rights
//
that
elevation
restores some or all permissions possibly lost
// ACCEPT is a controlled form of privilege
//
// a speciﬁc block ( for the beneﬁt of any following code ).
private static int LibraryProxy(IntCode badCode) {
int i ;
Accept ( saved ) {
in
// Runs code that may interact with less
i = badCode();
// usually checks post−conditions;
// by design , unhandled exceptions won’t restore permissions .
if ( i<0) throw new InvalidOperationException (”bad integer ” );
trusted code;
}
return i ;
// From the caller ’s viewpoint , the resulting permissions are
//
this method had produced i
the same as if
}
// idem, using lower−level operations on Permissions . Current :
private static int ImplementLibraryProxy(IntCode badCode) {
itself .
int i ;
Permissions before = Permissions .Current;
i = badCode();
if ( i<0) throw new InvalidOperationException(”bad integer ” );
before . Intersect (saved ). Assert ();
return i ;
}
}
Figure 3. “Accept”.