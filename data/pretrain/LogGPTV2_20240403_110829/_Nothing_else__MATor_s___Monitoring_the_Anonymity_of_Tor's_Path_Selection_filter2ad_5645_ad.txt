(cid:48) for any q.
5 Anonymity Monitors
In this section, we estimate these anonymity bounds of Tor for a given snapshot of the Tor network computed
from a given consensus document. We devise anonymity monitors that a client can run along with the Tor client
to estimate sound anonymity bounds for the PSTOR algorithm. First, we present the anonymity monitor for
sender anonymity that gives a bound for the probability that a malicious server manages to deanonymize the user.
Second, we present the anonymity monitor for recipient anonymity that bounds the probability that the user’s
ISP can determine the recipient of a communication. Third, we present the anonymity monitor for relationship
anonymity that bounds the probability that an observer can relate trafﬁc to a sender and a recipient.
The output of these three monitors provides a bound of the maximal success probability of a worst-case
adversary to deanonymize a Tor user at a given point in time. The success probability is calculated for an individual
circuit creation, i.e., whenever a new circuit is created the adversary may deanonymize the user for this circuit with
the success probability.
Adversary model. For our monitors, we consider a worst-case adversary that statically compromises a given
number k of Tor nodes of its choice. It may use any auxiliary information it possesses; however, we assume that
it is has no prior knowledge of the entry guards a user will choose or has chosen. In practice the adversary can
gather its k nodes by attacking the existing nodes or (rather easily) by adding new nodes to the Tor network.
5.1 Modeling MATor in AnoA
In MATOR we analyze the anonymity of a real Tor user depending on her preferences pf and connections conn
and the veriﬁed Tor consensus ﬁle and the latest server descriptors.
Technically, we instantiate MATOR in ANOA by deﬁning an adversary class for the user that restricts the
ANOA adversary as follows. As we are interested in the anonymity of a speciﬁc user, we overwrite the adversary’s
choice of preferences for the challenge users with the ones from the real user. The adversary may still choose the
preferences of other users in the network
Deﬁnition 4 (MATOR proﬁle). For a set of user preferences pf and two sets of ports ports1, ports2 the proﬁle
MATOR(pf ,ports1,ports2) replaces all messages of the form
(challenge,(S1,⊥, (initialize, , ), sid1),
(S2,⊥, (initialize, , ), sid1), Ψ)
with (challenge,(S1,⊥, (initialize, pf , ports1), sid1),
(S2,⊥, (initialize, pf , ports2), sid2), Ψ)
and by blocking all challenge messages in which only one user sends initialize. Consequently, only the preferences
pf and ports ports1 and ports2 that are speciﬁed for the proﬁle can be used for challenges.
In our monitors’ implementations, we prepare the anonymity analysis as follows.
Monitor—Preparing the scenario. The monitor ﬁrst prepares the scenario, consisting of user preferences pf , a
list of connections conn that describes to which servers (particularly over which ports) the user wants to connect,
and information about the current consensus ﬁle and the respective server descriptors. The monitor then uses a
simulation of the PSTOR algorithm to compute the weights of all nodes for these connections, each depending on
the possible position of the node within the circuit (entry, middle, exit) and depending on the node-speciﬁc data
from the consensus ﬁle (e.g., its tags, bandwidth and IP address).
The details of how these weights are computed heavily depend on the path selection that is to be used. A
short deﬁnition of how the path selection algorithm for Tor computes the probability of a given exit node is given
in Figure 4, where scEx() weights a node depending on its bandwidth, its tags, and the weights given in the
consensus.
5.2 Computing Sender Anonymity Bounds
Sender anonymity considers an adversary that wants to deanonymize a Tor user communicating to a given server
that is under adversarial control.
13
for en ∈ N do
if ps.allows(en, ex , pf ) then
SAMonitor(N , pf , ps)
1: for ex ∈ N do
2:
3:
4:
5:
6: sort all nodes in N by their δ(·) value in a list sorted
7: for node ∈ sorted and 1 ≤ i ≤ k do
8:
9: return δ
exitP := ps.exP(ex ); entryP = ps.enP(en, ex )
δ(en)+=exitP · entryP
δ += δ(node); i := i + 1
Figure 5: Sender Anonymity Monitor
A long history of prior work on trafﬁc correlation attacks shows that whenever an adversary controls the entry
and the exit node of a circuit, or the entry node and the server, it may deanonymize the user [9, 12, 17, 20, 21,
24–26]. Directly following the analysis from [6] we notice that a (local) adversary with control over the server
can deanonymize the user only if it manages to compromise the entry node of a circuit. Our monitor thus checks
the probability that an entry node is compromised, which depends on the user’s preferences and connections as
well as on the active nodes. We give guarantees even against a worst-case adversary that compromises the k most
probable entry nodes.
Figure 5 depicts the pseudocode for computing the bounds for sender anonymity. Here, the adversary compro-
mises the k most likely entry nodes for the given connection. Since the probability that an entry node is chosen is
independent of the user (for a ﬁxed connection), the sender anonymity bound is the sum that any of these nodes is
chosen. Thus, the bounds computed by the sender anonymity monitor are the worst case bounds.
Theorem 2 (Sender Anonymity Monitor). Given a consensus and a corresponding set of server descriptors,
let N be a set of nodes with bandwidth weights, the preferences pf of the user, the ports ports to which the
user wants to connect, and a path selection algorithm ps that uses these informations. Then for the output δ
(cid:48) satisﬁes
of the algorithm SAMonitor(N , pf , ps) the following holds: against passive local adversaries ΠOR
(1, 0, δ) − αSSA-IND-CDPMATOR(pf ,ports,∅), where αSSA-IND-CDPMATOR(pf ,ports,∅) denotes session sender anonymity
(see Section 3) with the MATOR proﬁle as in Deﬁnition 4.
Proof. By Theorem 1 and Lemma 22 from the full version of the AnoA framework [7, Lemma 22], we know that
it sufﬁces to show that (1, 0, δ) − αSSA-IND-CDPMATOR(pf ,ports,∅) holds for the ideal functionality FOR
(cid:48) sends handles over the network instead of onions (i.e. ciphertexts) for
Recall that the ideal functionality FOR
(cid:48) reveals which handles belong together, and if all nodes of the circuit
honest nodes. For compromised nodes, FOR
to the exit node are compromised, FOR
Let Ab denote the event that A in the game b correctly guesses the bit b and A1−b denote the event that A in the
game 1− b wrongly guesses the bit b, and let Cb denote the event that the circuit C is chosen by the path selection
in the game b. Since only the user differs in a sender anonymity scenario, i.e., the preferences and the connections
are the same, by the construction of Tor’s path selection algorithm (see Figure ) the distribution of selected path is
the same for both user connections:
(cid:48) additionally reveals the message along with the handle.
(cid:48).
Pr[Cb] = Pr[C1−b]
Hence, we omit the subscript b for Cb in the following.
Since the sender is the same in both scenarios and since the same messages are sent over the circuit, the view
of the adversary is the same once the circuit is ﬁxed and the adversary did not compromise the circuits entry
node. We say that a circuit is honest, written as HC, if for the circuit C = (n1, n2, n3) the entry node n1 is not
compromised. Hence, for all circuits C, the following holds
(1)
Observe that the events C and HC are independent since the adversary ﬁrst chooses which nodes to compromise,
and the path selection does not know which nodes are compromised.
Pr[Ab | C ∧ HC] = Pr[A1−b | C ∧ HC]
(cid:88)
14
Observe that
P r[Ab] =
C∈nodes3
Pr[Ab | C] · Pr[C]
(2)
Moreover, observe that
P r[Ab | C]
= Pr[Ab | C ∧ HC] · Pr[HC]
+ Pr[Ab | C ∧ ¬HC]
· Pr[¬HC]
(cid:124)
(cid:125)
(cid:123)(cid:122)
=1
(1)
= Pr[A1−b | C ∧ HC] · Pr[HC] + Pr[¬HC]
= Pr[A1−b | C ∧ HC] · Pr[HC]
+
=Pr[A1−b|C∧¬HC ]
· Pr[¬HC] + Pr[¬HC]
0(cid:124)(cid:123)(cid:122)(cid:125)
Thus, we have the following:
= Pr[A1−b | C ∧ HC] · Pr[HC]
+ Pr[A1−b | C ∧ ¬HC] · Pr[¬HC] + Pr[¬HC]
Pr[Ab]
= P r[A1−b | C] + Pr[¬HC]
(cid:88)
(cid:88)
(cid:88)
Pr[Ab | C] · Pr[C]
C∈nodes3
C∈nodes3
(2)
=
(3)
=
=
C∈nodes3
= Pr[A1−b] +
(Pr[A1−b | C] + Pr[¬HC]) · Pr[C]
(cid:88)
Pr[A1−b | C] · Pr[C] + Pr[¬HC] · Pr[C]
(cid:124)
Pr[¬HC] · Pr[C]
C∈nodes3
(cid:123)(cid:122)
(cid:125)
=:δA
(3)
Let A be the adversary that compromises the entry nodes with the k-highest weights for the set of ports ports.
Claim 1 (A is the most successful adversary). For each adversary A(cid:48) that compromises at most k nodes the
following holds: δA(cid:48) ≤ δA.
Proof of Claim 1. Recall that in a sender anonymity scenario the connections and the preferences are the same
in both games. Hence, all entry nodes have the same weights in both games. By the construction of Tor’s path
selection, the weight of an entry node equals the overall probability with which the node is chosen as an entry
node. In other words:
entryW (n) =
(n2,n3)∈unrelatedN odes2
ps.enP (n, n3) · ps.miP (n2, n, n3) · ps.exP (n3)
As a consequence, A compromises those entry node n such that the sum
(cid:88)
(cid:88)
Pr[(n, n2, n3)]
(n2,n3)∈N 2
(cid:88)
(cid:88)
C∈nodes3
δA(cid:48) =
≤
(n2,n3)∈nodes2
n∈K
Pr[¬HC] · Pr[C]
15
is k-maximal, i.e., is among the k highest sums. Let K be the k entry nodes with these highest sums.
Then, for any other adversary A(cid:48) we have the following:
Pr[(n, n2, n3)] = δA
(cid:5)
The sender anonymity monitor and the guard mechanism. The sender anonymity monitor outputs a bound on
the probability that the adversary might deanonymize a user’s communication using Tor. This deanonymization is
heavily based on the probability of compromising the user’s entry node, and thus, sender anonymity only changes
whenever a fresh entry node is chosen. If the user makes use of the guard mechanism [27, 34] she will not choose
a fresh entry node for every communication, but only choose from a small set of entry nodes that is kept for a long
time.
The guard mechanism modiﬁes the adversaries possibilities to deanonymize the user as follows: As the user
rarely choses a fresh entry node it is less likely that the adversary manages to compromise the entry node, even if
the user builds many circuits. However, if it manages to compromise a user’s guard, it will be able to deanonymize
this user very often and consistently until she changes her guards again.
5.3 Computing Recipient Anonymity Bounds
Recipient anonymity considers the setting with a malicious ISP of the user that wants to ﬁnd out which web pages
a user visits and additionally controls some Tor nodes. As presented earlier, in AnoA recipient anonymity is
formalized by comparing two challenge settings in which the user is the same but the recipients differ.
For this analysis we exclude website ﬁngerprinting attacks, as those attacks are attacks on the content of
messages and present an orthogonal attack vector that is not related to the communication protocol. A malicious
ISP could always additionally host ﬁngerprinting attacks, independent of the protocol we analyze. Technically,
we assume that the adversary cannot learn information from the answers to challenge messages.2 Recently, some
provably secure defenses have been developed against these ﬁngerprinting attacks [33].
For computing the recipient anonymity bound, the probability of three scenarios has to be considered. The
ﬁrst and most relevant scenario encompasses compromising the exit node in the user’s circuit, where recipient
anonymity is immediately broken. The second scenario considers a compromised middle node: in this case, the
adversary knows the circuit’s exit node and can check whether this exit node does not offer a port that is requested
in one of the settings. The third scenario considers a compromised entry node: even in this case, the adversary
can learn which middle node is chosen in the circuit and thereby check whether this middle node is more probable
in one of the settings, e.g., because the middle node is related to a heavy-weighted (i.e., very probable) exit node
that does not offer one of the ports in one of the two challenge settings. Additionally, the adversary might learn
something by seeing the entry node that has been chosen, e.g., it might be less probable to choose an entry node
that is related to a very heavy-weighted exit node.
A precise estimation of the recipient anonymity bounds has to take into account how much an adversary could
learn from any given node and then add these values up for the k most advantageous nodes. For each node
and each of the three positions (entry, middle, and exit), the increase in the distinguishing probability has to be
computed. For the exit position, the adversary can immediately distinguish the challenge settings by compromising
the exit node; hence this increase δEx is the probability that the node n is chosen as an exit node: δEx(node) :=
node.bw/((cid:80)
node(cid:48)∈bSi
node
.bw).
(cid:48)
For the entry position, the adversary can not directly learn which setting is chosen, but it can gain evidence
that one of the settings is chosen, e.g., because some entry nodes are more probable to be chosen as entry nodes
in the ﬁrst setting since in the other settings these entry nodes are in the family of a heavy-weighted exit node that
is only in the best support of the second setting. Hence, this increase can be characterized by the difference in the
probabilities for every triple of nodes.
δEn(node) =
(cid:88)
(cid:88)
node 1∈bS1
node,node 1
unrelated
node 2∈N
unrelated
node,node 1,node 2
node,node 1,node 2