type)
the gate.
receives a boost.
Gate 
(signaling 
type)
Thread signals 
the type.
First waiting thread is released.
Keyed 
event
Thread sets 
event with a 
key.
Thread that’s waiting for the key and 
which is of the same process as the 
signaler is released.
Semaphore
Semaphore 
count drops by 
1.
One thread is released.
Timer 
(notificatio
n type)
Set time arrives 
or time interval 
expires.
All are released.
Timer 
(synchroni
zation 
type)
Set time arrives 
or time interval 
expires.
One thread is released.
Mutex
Thread releases 
the mutex.
One thread is released and takes 
ownership of the mutex.
Queue
Item is placed 
on queue.
One thread is released.
Two other types of executive synchronization mechanisms worth noting
are the executive resource and the pushlock. These mechanisms provide
exclusive access (like a mutex) as well as shared read access (multiple
readers sharing read-only access to a structure). However, they’re available
only to kernel-mode code and thus are not accessible from the Windows API.
They’re also not true objects—they have an API exposed through raw
pointers and Ex APIs, and the Object Manager and its handle system are not
involved. The remaining subsections describe the implementation details of
waiting for dispatcher objects.
Waiting for dispatcher objects
The traditional way that a thread can synchronize with a dispatcher object is
by waiting for the object’s handle, or, for certain types of objects, directly
waiting on the object’s pointer. The NtWaitForXxx class of APIs (which is
also what’s exposed to user mode) works with handles, whereas the
KeWaitForXxx APIs deal directly with the dispatcher object.
Because the Nt API communicates with the Object Manager
(ObWaitForXxx class of functions), it goes through the abstractions that were
explained in the section on object types earlier in this chapter. For example,
the Nt API allows passing in a handle to a File Object, because the Object
Manager uses the information in the object type to redirect the wait to the
Event field inside of FILE_OBJECT. The Ke API, on the other hand, only
works with true dispatcher objects—that is to say, those that begin with a
DISPATCHER_HEADER structure. Regardless of the approach taken, these
calls ultimately cause the kernel to put the thread in a wait state.
A completely different, and more modern, approach to waiting on
dispatcher objects is to rely on asynchronous waiting. This approach
leverages the existing I/O completion port infrastructure to associate a
dispatcher object with the kernel queue backing the I/O completion port, by
going through an intermediate object called a wait completion packet. Thanks
to this mechanism, a thread essentially registers a wait but does not directly
block on the dispatcher object and does not enter a wait state. Instead, when
the wait is satisfied, the I/O completion port will have the wait completion
packet inserted, acting as a notification for anyone who is pulling items from,
or waiting on, the I/O completion port. This allows one or more threads to
register wait indications on various objects, which a separate thread (or pool
of threads) can essentially wait on. As you’ve probably guessed, this
mechanism is the linchpin of the Thread Pool API’s functionality supporting
wait callbacks, in APIs such as CreateThreadPoolWait and
SetThreadPoolWait.
Finally, an extension of the asynchronous waiting mechanism was built
into more recent builds of Windows 10, through the DPC Wait Event
functionality that is currently reserved for Hyper-V (although the API is
exported, it is not yet documented). This introduces a final approach to
dispatcher waits, reserved for kernel-mode drivers, in which a deferred
procedure call (DPC, explained earlier in this chapter) can be associated with
a dispatcher object, instead of a thread or I/O completion port. Similar to the
mechanism described earlier, the DPC is registered with the object, and
when the wait is satisfied, the DPC is then queued into the current
processor’s queue (as if the driver had now just called KeInsertQueueDpc).
When the dispatcher lock is dropped and the IRQL returns below
DISPATCH_LEVEL, the DPC executes on the current processor, which is the
driver-supplied callback that can now react to the signal state of the object.
Irrespective of the waiting mechanism, the synchronization object(s) being
waited on can be in one of two states: signaled state or nonsignaled state. A
thread can’t resume its execution until its wait is satisfied, a condition that
occurs when the dispatcher object whose handle the thread is waiting for also
undergoes a state change, from the nonsignaled state to the signaled state
(when another thread sets an event object, for example).
To synchronize with an object, a thread calls one of the wait system
services that the Object Manager supplies, passing a handle to the object it
wants to synchronize with. The thread can wait for one or several objects and
can also specify that its wait should be canceled if it hasn’t ended within a
certain amount of time. Whenever the kernel sets an object to the signaled
state, one of the kernel’s signal routines checks to see whether any threads
are waiting for the object and not also waiting for other objects to become
signaled. If there are, the kernel releases one or more of the threads from
their waiting state so that they can continue executing.
To be asynchronously notified of an object becoming signaled, a thread
creates an I/O completion port, and then calls
NtCreateWaitCompletionPacket to create a wait completion packet object
and receive a handle back to it. Then, it calls
NtAssociateWaitCompletionPacket, passing in both the handle to the I/O
completion port as well as the handle to the wait completion packet it just
created, combined with a handle to the object it wants to be notified about.
Whenever the kernel sets an object to the signaled state, the signal routines
realize that no thread is currently waiting on the object, and instead check
whether an I/O completion port has been associated with the wait. If so, it
signals the queue object associated with the port, which causes any threads
currently waiting on it to wake up and consume the wait completion packet
(or, alternatively, the queue simply becomes signaled until a thread comes in
and attempts to wait on it). Alternatively, if no I/O completion port has been
associated with the wait, then a check is made to see whether a DPC is
associated instead, in which case it will be queued on the current processor.
This part handles the kernel-only DPC Wait Event mechanism described
earlier.
The following example of setting an event illustrates how synchronization
interacts with thread dispatching:
■    A user-mode thread waits for an event object’s handle.
■    The kernel changes the thread’s scheduling state to waiting and then
adds the thread to a list of threads waiting for the event.
■    Another thread sets the event.
■    The kernel marches down the list of threads waiting for the event. If a
thread’s conditions for waiting are satisfied (see the following note),
the kernel takes the thread out of the waiting state. If it is a variable-
priority thread, the kernel might also boost its execution priority. (For
details on thread scheduling, see Chapter 4 of Part 1.)
 Note
Some threads might be waiting for more than one object, so they continue
waiting, unless they specified a WaitAny wait, which will wake them up
as soon as one object (instead of all) is signaled.
What signals an object?
The signaled state is defined differently for different objects. A thread object
is in the nonsignaled state during its lifetime and is set to the signaled state by
the kernel when the thread terminates. Similarly, the kernel sets a process
object to the signaled state when the process’s last thread terminates. In
contrast, the timer object, like an alarm, is set to “go off” at a certain time.
When its time expires, the kernel sets the timer object to the signaled state.
When choosing a synchronization mechanism, a programmer must take
into account the rules governing the behavior of different synchronization
objects. Whether a thread’s wait ends when an object is set to the signaled
state varies with the type of object the thread is waiting for, as Table 8-27
illustrates.
When an object is set to the signaled state, waiting threads are generally
released from their wait states immediately.
For example, a notification event object (called a manual reset event in the
Windows API) is used to announce the occurrence of some event. When the
event object is set to the signaled state, all threads waiting for the event are
released. The exception is any thread that is waiting for more than one object
at a time; such a thread might be required to continue waiting until additional
objects reach the signaled state.
In contrast to an event object, a mutex object has ownership associated
with it (unless it was acquired during a DPC). It is used to gain mutually
exclusive access to a resource, and only one thread at a time can hold the
mutex. When the mutex object becomes free, the kernel sets it to the signaled
state and then selects one waiting thread to execute, while also inheriting any
priority boost that had been applied. (See Chapter 4 of Part 1 for more
information on priority boosting.) The thread selected by the kernel acquires
the mutex object, and all other threads continue waiting.
A mutex object can also be abandoned, something that occurs when the
thread currently owning it becomes terminated. When a thread terminates,
the kernel enumerates all mutexes owned by the thread and sets them to the
abandoned state, which, in terms of signaling logic, is treated as a signaled
state in that ownership of the mutex is transferred to a waiting thread.
This brief discussion wasn’t meant to enumerate all the reasons and
applications for using the various executive objects but rather to list their
basic functionality and synchronization behavior. For information on how to
put these objects to use in Windows programs, see the Windows reference
documentation on synchronization objects or Jeffrey Richter and Christophe
Nasarre’s book Windows via C/C++ from Microsoft Press.
Object-less waiting (thread alerts)
While the ability to wait for, or be notified about, an object becoming
signaled is extremely powerful, and the wide variety of dispatcher objects at
programmers’ disposal is rich, sometimes a much simpler approach is
needed. One thread wants to wait for a specific condition to occur, and
another thread needs to signal the occurrence of the condition. Although this
can be achieved by tying an event to the condition, this requires resources
(memory and handles, to name a couple), and acquisition and creation of
resources can fail while also taking time and being complex. The Windows
kernel provides two mechanisms for synchronization that are not tied to
dispatcher objects:
■    Thread alerts
■    Thread alert by ID
Although their names are similar, the two mechanisms work in different
ways. Let’s look at how thread alerts work. First, the thread wishing to
synchronize enters an alertable sleep by using SleepEx (ultimately resulting
in NtDelayExecutionThread). A kernel thread could also choose to use
KeDelayExecutionThread. We previously explained the concept of
alertability earlier in the section on software interrupts and APCs. In this
case, the thread can either specify a timeout value or make the sleep infinite.
Secondly, the other side uses the NtAlertThread (or KeAlertThread) API to
alert the thread, which causes the sleep to abort, returning the status code
STATUS_ALERTED. For the sake of completeness, it’s also worth noting that
a thread can choose not to enter an alertable sleep state, but instead, at a later
time of its choosing, call the NtTestAlert (or KeTestAlertThread) API.
Finally, a thread could also avoid entering an alertable wait state by
suspending itself instead (NtSuspendThread or KeSuspendThread). In this
case, the other side can use NtAlertResumeThread to both alert the thread and
then resume it.
Although this mechanism is elegant and simple, it does suffer from a few
issues, beginning with the fact that there is no way to identify whether the
alert was the one related to the wait—in other words, any other thread
could’ve also alerted the waiting thread, which has no way of distinguishing
between the alerts. Second, the alert API is not officially documented—
meaning that while internal kernel and user services can leverage this
mechanism, third-party developers are not meant to use alerts. Third, once a
thread becomes alerted, any pending queued APCs also begin executing—
such as user-mode APCs if these alert APIs are used by applications. And
finally, NtAlertThread still requires opening a handle to the target thread—an
operation that technically counts as acquiring a resource, an operation which
can fail. Callers could theoretically open their handles ahead of time,
guaranteeing that the alert will succeed, but that still does add the cost of a
handle in the whole mechanism.
To respond to these issues, the Windows kernel received a more modern
mechanism starting with Windows 8, which is the alert by ID. Although the
system calls behind this mechanism—NtAlertThreadByThreadId and
NtWaitForAlertByThreadId—are not documented, the Win32 user-mode
wait API that we describe later is. These system calls are extremely simple
and require zero resources, using only the Thread ID as input. Of course,
since without a handle, this could be a security issue, the one disadvantage to
these APIs is that they can only be used to synchronize with threads within
the current process.
Explaining the behavior of this mechanism is fairly obvious: first, the
thread blocks with the NtWaitForAlertByThreadId API, passing in an
optional timeout. This makes the thread enter a real wait, without alertability
being a concern. In fact, in spite of the name, this type of wait is non-
alertable, by design. Next, the other thread calls the
NtAlertThreadByThreadId API, which causes the kernel to look up the
Thread ID, make sure it belongs to the calling process, and then check
whether the thread is indeed blocking on a call to
NtWaitForAlertByThreadId. If the thread is in this state, it’s simply woken
up. This simple, elegant mechanism is the heart of a number of user-mode
synchronization primitives later in this chapter and can be used to implement
anything from barriers to more complex synchronization methods.
Data structures
Three data structures are key to tracking who is waiting, how they are
waiting, what they are waiting for, and which state the entire wait operation is
at. These three structures are the dispatcher header, the wait block, and the
wait status register. The former two structures are publicly defined in the
WDK include file Wdm.h, whereas the latter is not documented but is visible
in public symbols with the type KWAIT_STATUS_REGISTER (and the Flags
field corresponds to the KWAIT_STATE enumeration).
The dispatcher header is a packed structure because it needs to hold a lot
of information in a fixed-size structure. (See the upcoming “EXPERIMENT:
Looking at wait queues” section to see the definition of the dispatcher header
data structure.) One of the main techniques used in its definition is to store
mutually exclusive flags at the same memory location (offset) in the
structure, which is called a union in programming theory. By using the Type
field, the kernel knows which of these fields is relevant. For example, a
mutex can be Abandoned, but a timer can be Relative. Similarly, a timer can
be Inserted into the timer list, but debugging can only be Active for a process.
Outside of these specific fields, the dispatcher header also contains
information that’s meaningful regardless of the dispatcher object: the
Signaled state and the Wait List Head for the wait blocks associated with the
object.
These wait blocks are what represents that a thread (or, in the case of
asynchronous waiting, an I/O completion port) is tied to an object. Each
thread that is in a wait state has an array of up to 64 wait blocks that
represent the object(s) the thread is waiting for (including, potentially, a wait
block pointing to the internal thread timer that’s used to satisfy a timeout that
the caller may have specified). Alternatively, if the alert-by-ID primitives are
used, there is a single block with a special indication that this is not a
dispatcher-based wait. The Object field is replaced by a Hint that is specified
by the caller of NtWaitForAlertByThreadId. This array is maintained for two
main purposes:
■    When a thread terminates, all objects that it was waiting on must be
dereferenced, and the wait blocks deleted and disconnected from the
object(s).
■    When a thread is awakened by one of the objects it’s waiting on (that
is, by becoming signaled and satisfying the wait), all the other objects
it may have been waiting on must be dereferenced and the wait blocks
deleted and disconnected.
Just like a thread has this array of all the objects it’s waiting on, as we
mentioned just a bit earlier, each dispatcher object also has a linked list of
wait blocks tied to it. This list is kept so that when a dispatcher object is
signaled, the kernel can quickly determine who is waiting on (or which I/O
completion port is tied to) that object and apply the wait satisfaction logic we
explain shortly.
Finally, because the balance set manager thread running on each CPU (see
Chapter 5 of Part 1 for more information about the balance set manager)
needs to analyze the time that each thread has been waiting for (to decide
whether to page out the kernel stack), each PRCB has a list of eligible
waiting threads that last ran on that processor. This reuses the Ready List
field of the KTHREAD structure because a thread can’t both be ready and
waiting at the same time. Eligible threads must satisfy the following three
conditions:
■    The wait must have been issued with a wait mode of UserMode
(KernelMode waits are assumed to be time-sensitive and not worth
the cost of stack swapping).
■    The thread must have the EnableStackSwap flag set (kernel drivers
can disable this with the KeSetKernelStackSwapEnable API).
■    The thread’s priority must be at or below the Win32 real-time priority
range start (24—the default for a normal thread in the “real-time”
process priority class).
The structure of a wait block is always fixed, but some of its fields are
used in different ways depending on the type of wait. For example, typically,
the wait block has a pointer to the object being waited on, but as we pointed
out earlier, for an alert-by-ID wait, there is no object involved, so this
represents the Hint that was specified by the caller. Similarly, while a wait
block usually points back to the thread waiting on the object, it can also point
to the queue of an I/O completion port, in the case where a wait completion
packet was associated with the object as part of an asynchronous wait.
Two fields that are always maintained, however, are the wait type and the
wait block state, and, depending on the type, a wait key can also be present.
The wait type is very important during wait satisfaction because it determines
which of the five possible types of satisfaction regimes to use: for a wait any,
the kernel does not care about the state of any other object because at least
one of them (the current one!) is now signaled. On the other hand, for a wait
all, the kernel can only wake the thread if all the other objects are also in a
signaled state at the same time, which requires iterating over the wait blocks
and their associated objects.
Alternatively, a wait dequeue is a specialized case for situations where the
dispatcher object is actually a queue (I/O completion port), and there is a
thread waiting on it to have completion packets available (by calling
KeRemoveQueue(Ex) or (Nt)IoRemoveIoCompletion). Wait blocks attached
to queues function in a LIFO wake order (instead of FIFO like other
dispatcher objects), so when a queue is signaled, this allows the correct
actions to be taken (keep in mind that a thread could be waiting on multiple
objects, so it could have other wait blocks, in a wait any or wait all state, that
must still be handled regularly).
For a wait notification, the kernel knows that no thread is associated with
the object at all and that this is an asynchronous wait with an associated I/O
completion port whose queue will be signaled. (Because a queue is itself a
dispatcher object, this causes a second order wait satisfaction for the queue
and any threads potentially waiting on it.)
Finally, a wait DPC, which is the newest wait type introduced, lets the
kernel know that there is no thread nor I/O completion port associated with
this wait, but a DPC object instead. In this case, the pointer is to an initialized
KDPC structure, which the kernel queues on the current processor for nearly
immediate execution once the dispatcher lock is dropped.
The wait block also contains a volatile wait block state
(KWAIT_BLOCK_STATE) that defines the current state of this wait block in
the transactional wait operation it is currently engaged in. The different
states, their meaning, and their effects in the wait logic code are explained in
Table 8-28.
Table 8-28 Wait block states
St
at
e
Meaning
Effect
W
ait
Bl
oc
kA
cti