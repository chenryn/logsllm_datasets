Hunk*TroubleshooFng*
Troubleshooting Main Points 
1.Hunk UI shows errors 
2.Search.log to debug Hunk / Hadoop 	client issues 
3.Hadoop logs to debug Hadoop Server 	issues 
4.Job -> Inspect Job to debug many 	performance issues19* Do*not*distribute*
Troubleshooting – Enable Debugging 
Each log line in the file that involves Hunk ERP operations is annotated with ERP.… and contains links for spawned MR job(s). You may need to follow these links to troubleshoot MR issues. 
To enable more detailed logging and monitoring flow modes, edit the following parameters in the provider setting:By*default,*Hunk*makes*the*best*effort*to*prune*unnecessary*columns/fields*to*improve*search*performance.* For*debugging,*you*can*turn*this*off*and*have*ERP*return*all*columns*to*Hunk*to*do*the*filtering*and*final*processing*at* the*search*head.*
By*seÅng*to*1,*search.log*will*have*DEBUG*level* 
logging*events.*
By*default,*Hunk*searches*run*in*mixed*mode.* 
To*disable,*set*the*value*to*0.*To*disable,*set*the*value*to*0.*
20* 	Do*not*distribute*
|  |
|---|
|   |
|  |
21*
TroubleshooFng*–*No*Map*Reduce*Job*
To*check*if*a*MapReduce*job*is*working,*you*can*
append*a*reporFng*search*job.*
22*
Find*search.log*
1* 2*
In*this*example,*a*search*returns*some*results*but*it* seems*like*it*is*stuck*aQer*the*iniFal*streaming* 
results.*Just*the*fact*that*it*has*returned*some*result*indicates*that*Hunk*can*access*data*in*HDFS.**
If*you*encounter*an*error*while*running*a*basic* search,*you*can*find*a*complete*search*job*detail*in* the*job*inspector.*
If*you*encounter*issues*while*building*your*reports,* 
search.log*is*the*place*to*look.*You*can*access* 
the*file*via*the*job*inspector.*
3*
23*
In*Search.log*–*Pinpoint*the*error*In*Search.log*–*Pinpoint*the*error*
Hunk*log*lines*are*denoted*with*ERP.*followed*by*a* provider*name.*In*this*example,*a*job*was* 
submized*and*Hunk*is*contacFng* 
ResourceManager*(YARN).*
In*Search.log*–*Pinpoint*the*error*
| However,*it*looks*like*Hunk*cannot* connect*to*the*ResourceManager.* |  |
|---|---|
|  | |
25*
Error*will*be*display*in*UI*and*search.log*
Eventually*repeated*azempts*failed*Eventually*repeated*azempts*failed* 
and*the*ERP*throws*an*excepFon.*
And*the*error*message*is*shown*on*the* 
parFal*results*page*indicaFng*that*the* 
MapReduce*job*was*unable*to*start.* 
You*suspect*that*maybe*the* 
ResourceManger*node*is*down*and*so* 
you*contact*the*Hadoop*administrator.*
26*
Troubleshoot*Hadoop*Server*issues**
A*Hadoop*administrator*checks*the* 
ResourceManager*and*finds*that*the*ResourceManager*and*finds*that*the* 
node*is*running*and*no*job*from*Hunk* 
has*been*queued.* 
With*that*informaFon,*you*can*narrow*
down*the*issue*to*a*network* 
connecFon*or*a*Hunk*configuraFon* error.* In*this*example,*the*culprit*was*misconfigured*address*to*the*ResourceManager.* AQer*fixing*the*address,*the*job*was*able*to*complete*successfully.* 
For*more*examples*of*error*message,*check:*hzp://docs.splunk.com/DocumentaFon/Hunk/latest/Hunk/TroubleshootHunk* *
27*
| Example*#*2,*Real*World*N*Bad*Performance* |
|---|
|  |
28*
No*MapReduce*Job*=*Not*a*Good*start*
Steam.bytes*=*Splunk*generate*results*
Yes,*MapReduce*Job*=*Bezer*
report.bytes*=*Hadoop*generate*results* 
MR.SPLK*=*Leverage*Hadoop*
Examine*HDFS*Storage*
Hadoop.dirs*/*files*.listed*=*How*many*directories*Splunk*need*to*scan*
VIX*with*Timestamp*on*the*files*=*Not*great*
Scan*8,760*files*–*filter*out*8,688*=*Only*72*files*used*for*search* RecommendaFon*is*to*build*Timestamp*on*Directories*
NoNSplizable*Very*Large*File*=*Bad*
1*MR*Job*for*very*large*file*is*not*ideal*
YesNSplizable*Very*Large*File*=*Good*
MulFple*Jobs*means*we*leverage*Hadoop*parallel*system*
Report*AcceleraFon*=*Great*Report*AcceleraFon*=*Great*
cache.bytes*=*HDFS*results*(No*need*for*MR)*
Summary*
Summary*N*Performance*
1.Run MR Jobs 
2.HDFS Storage 
3.VIX with Timestamp / indexes.conf 4.File Format 
5.Compression types / File size 
6.Event breaking / Props.conf 
7.Report Acceleration 
8.Hardware 
9.Search Head Clustering 
10.Many Other Flags (Threads, Splits) 
37* Do*not*distribute*
Summary*N*TroubleshooFng*Summary*N*TroubleshooFng*
1.Hunk UI shows errors 
2.Search.log to debug Hunk / Hadoop client 	issues 
3.Hadoop logs to debug Hadoop Server 
	issues 
4.Job -> Inspect Job to debug many 
	performance issues 
38* Do*not*distribute*
THANK*YOU*
Common*Issues*We*See*
|  | Clue5for5Issue5 | PotenVal5SoluVon5 |
|---|---|---|
|  |Job*takes*a*long*Fme* |Most*likely*customer*is*not*running*MR*Jobs* ||  |Job*takes*a*long*Fme* |Change*to*index*=*xyz*|*stats*count*by*xyz*+*smart*mode* |
|  |No*Error!*Job*is*just*hanging*..* |Lower*vix.mapred.job.map.memory.mb*=*1024* |
|  |No*Error!*Job*is*just*hanging*..* |OR* |
|  |No*Error!*Job*is*just*hanging*..* |Increase*the*memory*on*the*Hadoop*side* |
|  |In*the*search.log*you*will*see*“operaFon* |vix.splunk.heartbeat*=*0* |
|  |took*longer*than*the*heartbeat*interval”* |* || Timestamp*/*Fields* | |vix.input.[N].required.fields*=*Timestamp* |
| ExtracFon*in*Smart* | |Or* |
| Mode* | |Props.conf* |
| Hive*Jars*missing*or*Hive* | |Add*Jars*to*vix.env.HUNK_THIRDPARTY_JARS* |
| issues* |thread*"main"*java.lang.NoSuchFieldError*** |Or* |
| issues* |thread*"main"*java.lang.NoSuchFieldError*** |Look*in*answers*for*Hive** |
| Data*nodes*/tmp* | |Change*vix.splunk.home.hdfs* || directory*will*not*install* |will*see*permission*or*issues*wriFng*to*/ |Or* |
| SplunkD* |tmp/splunk** |Fix*permission*/*size* |
40*