title:Narrowing the Gap Between QoS Metrics and Web QoE Using Above-the-fold
Metrics
author:Diego Neves da Hora and
Alemnew Sheferaw Asrese and
Vassilis Christophides and
Renata Teixeira and
Dario Rossi
Narrowing the Gap Between QoS
Metrics and Web QoE
Using Above-the-fold Metrics
Diego Neves da Hora1(B)
Vassilis Christophides2, Renata Teixeira2, and Dario Rossi1
, Alemnew Sheferaw Asrese3,
1 Telecom Paristech, Paris, France
{diego.nevesdahora,dario.rossi}@telecom-paristech.fr
{vassilis.christophides,renata.teixeira}@inria.fr
2 Inria, Paris, France
3 Aalto University, Espo, Finland
PI:EMAIL
Abstract. Page load time (PLT) is still the most common application
Quality of Service (QoS) metric to estimate the Quality of Experience
(QoE) of Web users . Yet, recent literature abounds with proposals for
alternative metrics (e.g., Above The Fold, SpeedIndex and their variants)
that aim at better estimating user QoE. The main purpose of this work
is thus to thoroughly investigate a mapping between established and
recently proposed objective metrics and user QoE. We obtain ground
truth QoE via user experiments where we collect and analyze 3,400 Web
accesses annotated with QoS metrics and explicit user ratings in a scale
of 1 to 5, which we make available to the community. In particular, we
contrast domain expert models (such as ITU-T and IQX) fed with a sin-
gle QoS metric, to models trained using our ground-truth dataset over
multiple QoS metrics as features. Results of our experiments show that,
albeit very simple, expert models have a comparable accuracy to machine
learning approaches. Furthermore, the model accuracy improves consid-
erably when building per-page QoE models, which may raise scalability
concerns as we discuss.
1 Introduction
The Web remains one of the dominant applications in the Internet. Originally
designed to deliver static contents such as text and images, it evolved to serve
very dynamic and complex content: it is not uncommon for modern pages to
include hundreds of objects and dozens of scripts, placed at diﬀerent servers
hosted in diﬀerent domains [11]. Given this complexity, the Web architecture
and protocol landscape evolved as well, aiming at more eﬃcient operation and
to enhance the end user QoE: the introduction of Content Delivery Network
(CDN) and diﬀerent protocols such as HTTP2 [7], SPDY [16], QUIC [19] are
some of the eﬀorts in this regard.
c(cid:2) Springer International Publishing AG, part of Springer Nature 2018
R. Beverly et al. (Eds.): PAM 2018, LNCS 10771, pp. 31–43, 2018.
https://doi.org/10.1007/978-3-319-76481-8_3
32
D. N. da Hora et al.
Measuring the impact of diﬀerent network and Web browsing conﬁgurations
on Web browsing performance is essential to enhance user satisfaction. The met-
ric most commonly used to measure the performance of Web browsing has been
the Page Load Time (PLT), which holds true for both research [13,21,25–27]
and industry [1,2,4]. Recent studies [3,8,10,15,18,24], however, started to ques-
tion the relevance of using PLT to measure quality of user experience. The main
skepticism is that whereas PLT measures the precise time at which the page
ﬁnishes loading, the experience of the user depends on the whole process up to
that time and the rendering time at the browser. As such, a number of alter-
native metrics, which we review in Sect. 2.1, such as the Above-the-Fold (ATF)
time [10], SpeedIndex [3], Object/ByteIndex [8] and PerceptualSpeedIndex [15]
have been proposed to bridge this gap.
The approach adopted by the measurement community for computing met-
rics like ATF time and SpeedIndex requires taking a series of screenshots of the
Webpage loading progress and post-processing the captured frames. Unfortu-
nately, this approach is computationally intensive, which makes these metrics
complex to measure [15]. Our ﬁrst contribution (presented in Sect. 3) is to pro-
pose a tractable method to estimate the ATF metric, and oﬀer an
open-source implementation as a Chrome extension [5].
Still, to date the relationship between this class of objective metrics and
the user subjective feedback (e.g., via explicit ratings summarized with Mean
Opinion Score (MOS)) remains to be elucidated. Indeed, while models mapping
PLT to an estimated MOS do exist [14,17] (see Sect. 2.2), to the best of our
knowledge, extensions of these models to leverage these new metrics are still
lacking. Recently, Gao et al. [15] evaluated machine learning models that use
these new metrics as features to forecast A/B test results, where users are asked
to compare two Webpages loading side-by-side and identify which one loads
faster. Although Gao et al.’s work [15] represents an important step in the right
direction, A/B tests are a special case: i.e., we still miss an answer to the more
general question of how to estimate QoE of a single page a given user visits.
In this paper, we thoroughly investigate a mapping f(·) between user QoE,
expressed in terms of subjective MOS, and some QoS factor x that represents
objective measured properties of the browsing activity. In particular, we are
interested in cases where x can be any combination of the above objective metrics
and where the mapping f(·) is either deﬁned by a domain expert (e.g., according
to popular models like ITU-T [17] or IQX [14]) or data-driven models learned
using classic machine learning algorithms (e.g., SVR regression, CART trees).
The other main contribution of this paper (presented in Sect. 4) is to per-
form a thorough assessment of expert models (ITU-T [17], IQX [14],
etc.) and contrast them to models learned from the data using dif-
ferent machine learning algorithms, which our investigation ﬁnds to have
surprisingly comparable accuracy performance. Our analysis relies on a dataset
with 3,400 Web browsing sessions where users explicitly rated the quality of the
session. This dataset extends our previous eﬀort [9] and we make available to
the community [28]. We conclude that expert models for Web QoE can easily
Narrowing the Gap Between QoS Metrics and Web QoE
33
accommodate new time-related metrics beyond PLT, and that their accuracy is
comparable to that of data-driven models. Still, we gather that there is room for
improvement, as a single expert model is hardly accurate for the wide variety
of Web pages. At the same time, while we ﬁnd that per-page models have supe-
rior forecast performance, the approach is clearly not scalable, which opens new
interesting research questions for the community to address, which we discuss
in Sect. 4.4. We conclude in Sect. 5.
2 Background and Related Work
This section ﬁrst discusses the existing metrics that aim to capture Web QoS,
which we build on to deﬁne a practical method to infer the ATF time in Sect. 3.
Then, it presents the existing models to estimate Web QoE from these QoS
metrics, which we evaluate in Sect. 4.
2.1 Web QoS Metrics
The Web browsing process is complex with the request, download, and rendering
of all objects making up a Webpage. Hence, measuring when the page has ﬁnished
loading from the user’s perspective is challenging. The literature introduces two
classes of objective QoS metrics, which we exemplify with the help of Fig. 1.
Time Instants. The time to load a Web page has a number of components,
such as the time at which the ﬁrst byte is received (TTFB), the time at which
the ﬁrst object is painted (TTFP) by the browser, the parsing of the Document
Object Model (DOM), to the complete download (PLT, that we measure using
the onLoad browser event) or the rendering of the full page (VisualComplete).
We notice that whereas network-related time-instant metrics (e.g. TTFB, DOM,
PLT) are easy to measure, rendering-related metrics (e.g. TTFP, VisualCom-
plete) are harder to deﬁne across browsers [20]. An interesting metric proposed
by Google in this class is represented by the ATF time [10], deﬁned as the time
at which the content shown in the visible part of the Webpage is completely ren-
dered. Albeit interesting, the ATF metric is neither available in Webpagetest1,
Fig. 1. Illustration of time-instant (x-axis labels) and time-integral metrics (shaded
surface). The time horizon of the time-integral metrics can be limited to, e.g., (a) PLT
or (b) Above-the-Fold time instants.
1 https://www.webpagetest.org/.
34
D. N. da Hora et al.
nor deﬁned in W3C’s navigation timing speciﬁcations.2 This omission is possibly
due to the fact that the ATF time is signiﬁcantly more complex to measure, as it
requires taking screenshots during the rendering process and a post-processing
stage of the captured frames. One of our contributions is to propose a practical
way to approximate the ATF time, as well as provide an open source implemen-
tation.
Time Integrals. Another class of metrics recognizes that a single time instant
hardly captures all the complexity of interactions between the user and the
rendering process of the page. Instead, this class integrates the loading time over
all events of a given type throughout the evolution of a page progress. Following
Google’s original SpeedIndex (SI) [3] deﬁnition, a number of generalizations have
been proposed in the literature [8,15]. Metrics in this class ﬁt the general form:
(cid:2) tend
X end =
(1 − x(t))dt
(1)
0
where X end is the value of the metric, tend indicates an event considered as
time horizon and x(t) ∈ [0, 1] is the completion rate at time t. In particular,
SpeedIndex (SI) [3] measures x(t) as the visual progress using mean pixel his-
togram diﬀerence computed until the VisualComplete time. ObjectIndex (OI)
and ByteIndex (BI) [8] use the percentage of objects (and bytes) downloaded
until the PLT. Finally, PerceptualSpeedIndex (PSI) [15] uses Structural Simi-
larity to measure the visual progress x(t) and cut the time horizon at either the
PLT, or at an arbitrary time earlier than PLT.
One interesting question is how to select tend. A previous A/B study [15]
showed two pages rendering processes side by side, and asked users to click on
the page that completed faster: the best predictor uses the Time to Click as
tend, which considerably improves PSI accuracy in estimating user QoE [15].
Our experiments show that setting tend with the ATF time is a good option,
and our method to compute the ATF time enables measuring it during normal
user browsing (i.e., without requiring user intervention).
2.2 Web QoE Models
The metrics introduced in the previous section are measurable automatically
from the browser (even though those involving rendering are fairly complex to
compute). These metrics, however, may not directly capture the user experience
(or QoE), which is often measured explicitly by an opinion score and summarized
with the MOS. There are two main approaches for mapping of QoS metrics into
MOS: expert models, where domain experts specify a closed form function and