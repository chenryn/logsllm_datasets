### Machine Infection Detection

Syzygy is capable of accurately detecting each attack once a sufficiently large number of clients are infected. For the third (iii) content spoof attack, the behavior is so anomalous that even a single client's data is enough for our simple response time model to detect it. This is not the case for most other attacks, where the community's data is crucial.

Despite our behavior model being incomplete and noisy, we achieved high detection rates. Figure 4 illustrates part of the distribution of anomaly scores reported by individual healthy clients. These values ranged as high as 0.8, but the graph has been truncated for readability. In contrast, the healthy community scores remained within a very small range, indicated by the dashed red line, which represents a narrow Gaussian distribution. The epidemic threshold \( V \) is shown as the dotted line to the right of the cluster of community scores. The stability of the community scores enables Syzygy to provide a low false positive rate and to be sensitive to minor, but not isolated, changes in client behavior.

### Subsequent Sections

In the following sections, we will discuss the benefits of distributed training, the effects of heterogeneous hardware and user behavior, performance and overhead in a real network deployment, predicting and setting the false positive rate, performance in communities with thousands of clients, and Syzygy’s robustness against tainted training data and advanced exploit behavior (such as mimicry).

### Deployment Experiments

For practical use, our method assumes that (i) a real deployment can scale to large numbers of clients across a realistic network topology and (ii) despite minor client variations, such as hardware and configuration differences, healthy anomaly score distributions are similar across clients. We verified these assumptions by deploying Syzygy on several dozen Linux workstations on a university campus. Most of these machines were 3.0 GHz Intel Core2 Duos with 2 GB RAM and the CentOS 5 operating system; exceptions include two laptops and, briefly, the Syzygy server itself. Syzygy monitored the Firefox web browser via `strace` on Linux. Over the course of two weeks, Syzygy reported no false positives.

#### 5.1 Model

In the next two sections, we use a model of client behavior that employs short sequences of a program’s system calls. This information can be gathered with low overhead and has been shown to be useful [9, 14]. We use sequences of six system calls, consistent with previous work [7, 14, 22], but instead of using existing algorithms like stide or t-stide [33], the model uses an information-theoretic approach with several modifications.

During training, Syzygy computes a frequency distribution of system call sequences of length six and the maximum observed time between consecutive system call invocations. The computations are similar to those in Section 4.1, but use system call sequences as measurements instead of request response times.

Whenever a system call is invoked, the model concatenates the name of the call onto a sequence consisting of the previous five and increments the counter associated with that sequence. For example, on Mac OS X, while executing the command `echo hi`, we generate the following period-delimited sequence: `s = sigaction.writev.read.select.select.exit.`

Even when idle, many applications continue to invoke system calls (e.g., polling for new work or user input). This behavior acts as a kind of heartbeat for the program, and its absence indicates unusual behavior just as much as the presence of unusual system call sequences. For example, during one execution of `echo hi`, the maximum time between system call invocations, according to `dtrace`, was 375 μs.

Using this information about call sequences and timing, we construct a model analogous to the one for request response times in Section 4.1. The only differences are that the tables used to construct \( S_i \) and \( R_i \) are indexed by sequences and the recent window \( W_i \) has units of sequences. The anomaly signal is computed as described in Section 4.1.

#### 5.2 Distributed Training

Over a period of roughly two weeks, we collected normal usage traces from 35 active clients. During the day, a median of 8 clients were active at a time. The first week of these traces served as our training data and contained more than 2.2 billion sequences, of which approximately 180,000 were unique. As shown in Figure 5, most of the sequences were seen quickly (90% within the first 25% of the trace). The fact that training speeds up with community size is consistent with previous work [21]; Syzygy’s distinctive use of the community occurs during the monitoring phase (Section 5.3).

During this training period, while the clients were reporting both complete sequences and timestamps at an average of 100 KB/s, the average bandwidth usage at the server was 1160 KB/s (with a peak of 3240 KB/s). The clients required less than 1% CPU each for the `strace` process and Syzygy script. With all 35 clients active, the server-side script used 13% of the processor on average, with peaks as high as 32%.

Even though the training data includes machines that are unlike most of the cluster, such as two laptops, the distribution of community anomaly scores within the training community converges toward a tight normal distribution. Figure 6 shows the standard deviation of the community score for increasing numbers of clients; in the figure, the clients "join" the community in reverse order of average anomaly score (so \( n = 1 \) represents the client with the highest average anomaly score). To evaluate the impact of heterogeneity, we also plot four hypothetical communities: "Outliers Removed," where the two laptops and the Syzygy server were replaced with the client with the lowest standard deviation, "High SD Removed," where the five clients with the highest standard deviations were replaced with five clones of the machine with the lowest standard deviation, and "Homogeneous" and "Homogeneous (High SD)," which are communities of \( n \) clones of the client with the lowest average anomaly score and highest standard deviation, respectively. The results show that variance in the community score comes not from client heterogeneity (the client in "Homogeneous (High SD)" was a normal cluster machine) but from client variance. The results also show that a larger community can compensate for client variance.

Section 3.3 explains how to compute the threshold \( V \), given a desired false positive rate and the training data. These analytical results correspond well with what we observe experimentally. Using the data from our deployment, Figure 7 plots the appropriate choice of \( V \) for a desired false positive rate (note the log scale) and community size (\( n \)). The units of the false positive rate, for this deployment, are expected false positives per five seconds. The vertical line is a hypothetical target rate: \( 1 \times 10^{-5} \) (about six days). The y-value at which this line intercepts each community size line is the threshold for that value of \( n \).

#### 5.3 Distributed Monitoring

After training is complete, Syzygy switches to monitoring mode. For these experiments, we set \( T_i = \infty \) to prevent hiatons from being introduced. (We omit the exploration of \( T_i \) values for space reasons.) Over the course of a week, we collected just under 10 billion anomaly scores from the community. Five clients seen during training were not heard from again, while four new ones appeared. There were no epidemics or other coordinated events during the monitoring period; the machines are part of the campus computing infrastructure, so we could not obtain permission to stage an epidemic.

The `strace` process on the client requires an average of 1–2% CPU overhead, and the Syzygy client script requires another 2–3% to calculate the anomaly scores and send them to the server. The server-side Syzygy process uses less than 1% of the CPU for a single client; our experiments suggest a server could easily handle more than a hundred clients (see Section 7).

Syzygy can either send one packet per anomaly score or buffer some number before reporting them. At an average rate of 2000 system calls per second, sending one packet per call would be inefficient. Buffering 100 scores with a short timeout to ensure freshness, for example, reduces the bandwidth requirements to 20 packets per second at 1.5 KB per packet (∼ 30 KB/s), including the overhead of transmitting timestamps along with the anomaly scores, which we did for experimental purposes. Communicating the scores alone would require less than half this bandwidth.

Section 3.3 notes that achieving the target false positive rate requires that \( \mu_X \) and \( \sigma_X \) accurately describe the future distribution of anomaly scores. Figure 8 quantifies that statement using the deployment data collected while Syzygy was in monitoring mode (data not used to build the model). The diagonal red line indicates perfect agreement. Even at very low false positive rates and small community sizes, the modeling data was sufficient to allow good prediction of the false positive rate on real monitoring data.

### Controlled Experiments

In this section, we test Syzygy in a controlled environment under various adverse conditions, using trace data from commodity applications and exploits capable of sophisticated behaviors.

An experiment is a binary classification problem in which Syzygy is given a sequence of anomaly scores for \( n \) clients and must decide whether 0 of them are infected (healthy) or whether \( d \geq 1 \) of them have been exploited (infected). Thus, an example is a set of \( n \) score vectors of length \( W_i \). Ideally, Syzygy should report an epidemic if and only if one or more of the score vectors was produced by an infected client. We use standard metrics to evaluate performance on this classification problem: false positive rate (FP), false negative rate (FN), true positive rate (TP), true negative rate (TN), and F1 Measure \( \left(\frac{2TP}{2TP + FP + FN}\right) \), which combines precision and recall, weighting each equally.

For example, say we are measuring Syzygy’s performance on a community of size \( n = 100 \) and an epidemic of size \( d = 5 \). We produce an example of an infected community as follows. Say that we have already constructed models for all \( n \) clients and have the associated system call traces. To construct each of the \( n - d \) healthy score vectors, we pick a window from the application trace, uniformly at random, and compute the anomaly scores as described in Section 4.1. (The sample window determines \( R_i \).) Using exploit traces, we construct \( d \) infected score vectors. Syzygy then takes the \( n \) vectors of anomaly scores and computes the elementwise averages. If \( C > V \) for any element \( C \) of the resulting community score vector, then Syzygy classifies the example as infected; otherwise, it classifies it as healthy. Using data described in Section 6.1, we plot the community scores for a pair of examples in Figure 9; a healthy example is on the left and an infected example on the right. In other words, in the plot, the first 1000 scores are from a healthy community, while the next 1000 are from an infected community—Syzygy correctly identifies the infection point.

Healthy                                            Infected
Threshold (V)
Infection Point
)
C
(
e
r
o
c
S
y
t
i
n
u
m
m
o
C
2
.
2
0
.
2
8
.
1
6
1
.
4
.
1
y
t
i
s
n
e
D
0
1
8
6
4
2
0
Adium (mean= 2.5976 , sd= 1.3218 )
Camino (mean= 1.5645 , sd= 1.9471 )
Mail (mean= 1.3196 , sd= 1.9982 )
TextEdit (mean= 1.9679 , sd= 1.3489 
0
500
1000
1500
2000
Score Index
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Anomaly Score
Fig. 9. A pair of examples, using Camino and the showpages exploit with \( n = 100 \) and \( d = 5 \), showing a TN and a TP
Fig. 10. Healthy anomaly distributions, plotted with a kernel density estimator. The bump at around 2.75 suggests Adium’s model is imperfect.