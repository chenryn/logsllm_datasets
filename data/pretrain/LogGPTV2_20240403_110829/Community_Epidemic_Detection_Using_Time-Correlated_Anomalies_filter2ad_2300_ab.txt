machines are infected (low d), Syzygy is able to correctly detect each attack once
a suﬃciently large number of clients are infected. In the case of the third (iii)
content spoof attack, the behavior is anomalous enough on even a single client
for our simple response time model to detect it; this is not true for most of the
other attacks, meaning the community was crucial.
We achieved these high detection rates despite the fact that our behav-
ior model was incomplete and noisy. Figure 4 shows part of the distribution
of anomaly scores reported by individual healthy clients. In fact, these values
ranged as high as 0.8 but we have truncated the graph for readability. In con-
trast, however, note that the healthy community scores stayed within a very
small range (the dashed red line is actually a very slim Gaussian). The epidemic
threshold V is the dotted line to the right of the cluster of community scores.
Because the community scores are such a stable signal, they enable Syzygy both
to reliably provide a low false positive rate and to be sensitive to minor—but
not isolated—changes in client behavior.
In the subsequent sections, we discuss the beneﬁts of distributed training, the
eﬀects of heterogenous hardware and user behavior, performance and overhead
on a real network deployment, predicting and setting the false positive rate,
performance in communities with thousands of clients, and Syzygy’s robustness
against tainted training data and advanced exploit behavior (like mimicry).
370
A.J. Oliner, A.V. Kulkarni, and A. Aiken
5 Deployment Experiments
For practical use, our method assumes that (i) a real deployment can scale to
large numbers of clients across a realistic network topology and (ii) despite mi-
nor client variations, such as hardware and conﬁguration diﬀerences, healthy
anomaly score distributions are similar across clients. We verify that these as-
sumptions hold in practice by deploying Syzygy on several dozen Linux work-
stations on a university campus. Most of these machines were 3.0 GHz Intel
Core2 Duos with 2 GB RAM and the CentOS 5 operating system; exceptions
include two laptops and (brieﬂy) the Syzygy server, itself. Syzygy monitored the
Firefox web browser via strace on Linux. Over the course of these two weeks
of experiments, Syzygy reported no false positives.
5.1 Model
In the next two sections, we use a model of client behavior (diﬀerent from Sec-
tion 4) that uses short sequences of a program’s system calls. This information
can be gathered with low overhead and has been shown to be useful [9, 14]. We
use sequences of six system calls to be consistent with previous work [7, 14, 22],
but instead of using one of the existing stide or t-stide algorithms [33], the
model uses an information theoretic approach with several additional modiﬁca-
tions. During training, Syzygy computes a frequency distribution of system call
sequences of length six and the maximum observed time between consecutive sys-
tem call invocations. The computations are extremely similar to Section 4.1, but
use system call sequences as measurements, instead of request response times.
Whenever a system call is invoked, the model concatenates the name of the
call onto a sequence consisting of the previous ﬁve and increments the counter
associated with that sequence. For example, on Mac OS X, while executing the
command echo hi, we generate the following period-delimited sequence:
s = sigaction.writev.read.select.select.exit.
Even when idle, many applications will continue to invoke system calls (e.g.,
polling for new work or user input). This behavior acts as a kind of heartbeat
for the program, and its absence indicates unusual behavior just as much as
the presence of, say, unusual system call sequences. For example, during one
such execution of echo hi, the maximum time between system call invocations,
according to dtrace, was 375 μs.
Using this kind of information about call sequences and timing, we construct
a model analogous to the one for request response times in Section 4.1. The
only diﬀerences are that the tables used to construct Si and Ri are indexed by
sequences and the recent window Wi has units of sequences. The anomaly signal
is computed as described in Section 4.1.
5.2 Distributed Training
Over a period of roughly two weeks, we collected normal usage traces from 35
active clients. During the day, a median of 8 clients were active at a time. The
Community Epidemic Detection Using Time-Correlated Anomalies
371
s
e
c
n
e
u
q
e
S
e
u
q
n
U
i
f
o
n
o
i
t
c
a
r
F
0
.
1
8
.
0
6
.
0
4
.
0
2
.
0
0
.
0
)
)
C
(
d
s
(
n
o
i
t
i
a
v
e
D
d
r
a
d
n
a
S
t
0
.
3
0
.
2
0
1
.
0
0
.
Community Makeup:
Actual
Outliers Removed
High SD Removed
Homogeneous
Homogeneous (High SD)
0.0
0.2
0.4
0.6
0.8
1.0
0
5
10
15
20
25
30
35
Fraction of Training Set
Community Size (n)
Fig. 5. Distributed training happens
quickly: 25% of the data exhibits 90% of
the unique sequences. Retraining a model
(e.g., after a software upgrade) is eﬃcient
Fig. 6. Community scores converge in
real data; variance comes from client vari-
ance, not system conﬁguration or work-
load heterogeneity
ﬁrst week of these traces is our training data and contains more than 2.2 billion
sequences, of which approximately 180,000 are unique. As shown in Figure 5,
most of the sequences were seen quickly (90% within the ﬁrst 25% of the trace).
The fact that training speeds up with community size is consistent with pre-
vious work [21]; Syzygy’s distinctive use of the community occurs during the
monitoring phase (Section 5.3).
During this training period, while the clients were reporting both the complete
sequences and timestamps at an average of 100 KB/s, the average bandwidth
usage at the server was 1160 KB/s (the peak was 3240 KB/s). The clients re-
quired less than 1% CPU each for the strace process and Syzygy script. With
all 35 clients active, the server-side script was using 13% of the processor, on
average, with peaks as high as 32%.
Even though the training data includes machines that are unlike most of the
cluster, such as two laptops, we still ﬁnd that the distribution of community
anomaly scores within the training community converges toward a tight normal
distribution. Figure 6 shows the standard deviation of the community score for
increasing numbers of clients; in the ﬁgure, the clients “join” the community
in reverse order of average anomaly score (so n = 1 represents the client with
the highest average anomaly score). To evaluate the impact of heterogeneity,
we also plot four hypothetical communities: “Outliers Removed,” where the two
laptops and the Syzygy server were replaced with the client with the lowest
standard deviation, “High SD Removed,” where the ﬁve clients with the high-
est standard deviations were replaced with ﬁve clones of the machine with the
lowest standard deviation, and “Homogeneous” and “Homogeneous (High SD),”
which are communities of n clones of the client with the lowest average anomaly
score and highest standard deviation, respectively. The results show that vari-
ance in the community score comes not from client heterogeneity (the client in
“Homogeneous (High SD)” was a normal cluster machine) but from client vari-
ance. The results also show that a larger community can compensate for client
variance.
Section 3.3 shows how to compute the threshold V , given a desired false
positive rate and the training data; these analytical results correspond well with
what we observe experimentally. Using the data from our deployment, Figure 7
plots the appropriate choice of V for a desired false positive rate (note the log
scale) and community size (n). The units of the false positive rate, for this
372
A.J. Oliner, A.V. Kulkarni, and A. Aiken
)
V
l
(
d
o
h
s
e
r
h
T
5
4
3
2
1
0
n=
1
2
4
8
16
35
e
t
a
R
P
F
l
a
u
t
c
A
n=
30
31
32
33
34
4
0
−
e
8
4
0
−
e
4
0
0
+
e
0
1e−06
1e−04
1e−02
0e+00
2e−04
4e−04
6e−04
8e−04
1e−03
False Positive Rate (log scale)
Predicted FP Rate
Fig. 7. For a given false positive rate
and community size, we can compute the
threshold V . The vertical red line, for
instance, corresponds to about one false
positive per six days.
Fig. 8. The training data is a good pre-
dictor of the false positive rates seen in
monitoring data. The threshold V can be
set as high as necessary to achieve an ac-
ceptable rate of false positives.
deployment, are expected false positives per ﬁve seconds. The vertical line is a
hypothetical target rate: 1 × 10−5 (about six days). The y-value at which this
line intercepts each community size line is the threshold for that value of n.
5.3 Distributed Monitoring
After training is complete, Syzygy switches to monitoring mode. For these ex-
periments, we set Ti = ∞ to prevent hiatons from being introduced. (We omit
the exploration of Ti values for space reasons.) Over the course of a week, we
collected just under 10 billion anomaly scores from the community. Five clients
seen during training were not heard from again, while four new ones appeared.
There were no epidemics nor other coordinated events during the monitoring
period; the machines are part of the campus computing infrastructure, so we
could not obtain permission to stage an epidemic.
The strace process on the client requires an average of 1–2% CPU overhead,
and the Syzygy client script requires another 2–3% to calculate the anomaly
scores and send them to the server. The server-side Syzygy process uses less
than 1% of the CPU for a single client; our experiments suggest a server could
easily handle more than a hundred clients (see Section 7).
Syzygy can either send one packet per anomaly score or buﬀer some number
before reporting them. At an average rate of 2000 system calls per second, send-
ing one packet per call would be ineﬃcient. Buﬀering 100 scores with a short
timeout to ensure freshness, for example, reduces the bandwidth requirements
to 20 packets per second at 1.5 KB per packet (∼ 30 KB/s), including the over-
head of transmitting timestamps along with the anomaly scores, which we did
for experimental purposes. Communicating the scores alone would require less
than half this bandwidth.
Section 3.3 notes that achieving the target false positive rate requires that μX
and σX accurately describe the future distribution of anomaly scores. Figure 8
quantiﬁes that statement using the deployment data collected while Syzygy
was in monitoring mode (data not used to build the model). The diagonal red
line indicates perfect agreement. Even at very low false positive rates and small
Community Epidemic Detection Using Time-Correlated Anomalies
373
community sizes, the modeling data was suﬃcient to allow good prediction of
the false positive rate on real monitoring data.
6 Controlled Experiments
In this section, we test Syzygy in a controlled environment under various adverse
conditions, using trace data from commodity applications and exploits capable
of sophisticated behaviors.
An experiment is a binary classiﬁcation problem in which Syzygy is given a
sequence of anomaly scores for n clients and must decide whether 0 of them are
infected (healthy) or whether d ≥ 1 of them have been exploited (infected). Thus,
an example is a set of n score vectors of length Wi. Ideally, Syzygy should report
an epidemic iﬀ one or more of the score vectors was produced by an infected
client. We use standard metrics to evaluate performance on this classiﬁcation
problem: false positive rate (FP), false negative rate (FN), true positive rate
2T P +F P +F N ), which combines
(TP), true negative rate (TN), and F1 Measure (
precision and recall, weighting each equally.
2T P
For example, say we are measuring Syzygy’s performance on a community of
size n = 100 and epidemic of size d = 5. We produce an example of an in-
fected community as follows. Say that we have already constructed models for all
n clients and have the associated system call traces. To construct each of the n− d
healthy score vectors, we pick a window from the application trace, uniformly at
random, and compute the anomaly scores as described in Section 4.1. (The sam-
ple window determines Ri.) Using exploit traces, we construct d infected score
vectors. Syzygy then takes the n vectors of anomaly scores and computes the ele-
mentwise averages. If C > V for any element C of the resulting community score
vector, then Syzygy classiﬁes the example as infected; otherwise, it classiﬁes it as
healthy. Using data described in Section 6.1, we plot the community scores for
a pair of examples in Figure 9; a healthy example is on the left and an infected
example on the right. In other words, in the plot, the ﬁrst 1000 scores are from a
healthy community, while the next 1000 are from an infected community—Syzygy
Healthy                                            Infected
Threshold (V)
Infection Point
)
C
(
e
r
o
c
S
y
t
i
n
u
m
m
o
C
2
.
2
0
.
2
8
.
1
6
1
.
4
.
1
y
t
i
s
n
e
D
0
1
8
6
4
2
0
Adium (mean= 2.5976 , sd= 1.3218 )
Camino (mean= 1.5645 , sd= 1.9471 )
Mail (mean= 1.3196 , sd= 1.9982 )
TextEdit (mean= 1.9679 , sd= 1.3489 
0
500
1000
1500
2000
Score Index
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Anomaly Score
Fig. 9. A pair of examples, using Camino
and the showpages exploit with n = 100
and d = 5, showing a TN and a TP
Fig. 10. Healthy anomaly distributions,
plotted with a kernel density estima-
tor. The bump at around 2.75 suggests
Adium’s model is imperfect.
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●