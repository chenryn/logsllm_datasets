当应用运行时，我可以再次执行`docker compose up`，指定原始合成文件和`db-upgrade`覆盖文件:
```
> docker-compose `
   -f docker-compose.yml `
   -f docker-compose-db-upgrade.yml `
  up -d 
ch06-docker-compose_reverse-proxy_1 is up-to-date
ch06-docker-compose_nerd-dinner-homepage_1 is up-to-date
ch06-docker-compose_elasticsearch_1 is up-to-date
ch06-docker-compose_message-queue_1 is up-to-date
ch06-docker-compose_kibana_1 is up-to-date
Recreating ch06-docker-compose_nerd-dinner-db_1 ... done
Recreating ch06-docker-compose_nerd-dinner-web_1          ... done
Recreating ch06-docker-compose_nerd-dinner-save-handler_1 ... done
Recreating ch06-docker-compose_nerd-dinner-api_1          ... done
```
该命令使用`db-upgrade`文件作为主`docker-compose.yml`文件的替代。Docker Compose 将两者合并，因此最终的服务定义包含原始文件中的所有值，除了来自覆盖的映像规范。新的服务定义与 Docker 中运行的不匹配，因此 Compose 会重新创建数据库服务。
Docker Compose 使用新的映像规范，通过移除旧容器并启动新容器来重新创建服务。不依赖于数据库的服务保持原样，并带有日志条目`up-to-date`，一旦新的数据库容器运行，任何依赖于数据库的服务也将被重新创建。
我的数据库容器使用了我在 [第 3 章](03.html)*中描述的模式.NET 框架和.NET Core Applications，*具有存储数据的卷和在容器被替换时可以升级数据库模式的脚本。在合成文件中，我使用了名为`db-data`的卷的默认定义，因此 Docker Compose 为我创建了它。就像 Compose 创建的容器一样，卷是标准的 Docker 资源，可以使用 Docker CLI 进行管理。`docker volume ls`列出了主机上的所有卷:
```
> docker volume ls
DRIVER  VOLUME NAME
local   ch06-docker-compose_db-data
local   ch06-docker-compose_es-data
```
我有两个卷用于我的网络部署。它们都使用本地驱动程序，这意味着数据存储在本地磁盘上。我可以检查 SQL Server 卷以查看数据在主机上的物理存储位置(在`Mountpoint`属性中)，然后检查内容以查看数据库文件:
```
> docker volume inspect -f '{{ .Mountpoint }}' ch06-docker-compose_db-data
C:\ProgramData\docker\volumes\ch06-docker-compose_db-data\_data
> ls C:\ProgramData\docker\volumes\ch06-docker-compose_db-data\_data
    Directory: C:\ProgramData\docker\volumes\ch06-docker-compose_db-data\_data
Mode                LastWriteTime         Length Name
----                -------------         ------ ----
-a----       12/02/2019     13:47        8388608 NerdDinner_Primary.ldf
-a----       12/02/2019     13:47        8388608 NerdDinner_Primary.mdf
```
该卷存储在容器之外，因此当 Docker Compose 删除旧的容器数据库时，所有数据都会被保留。新的数据库映像捆绑了一个 Dacpac，并被配置为对现有数据文件进行模式升级，方式与从[第 3 章](03.html)、*开发 Dockerized 的 SQL Server 数据库相同.NET 框架和。网络核心应用*。
新容器启动后，我可以检查日志，看到新容器附加了卷中的数据库文件，然后修改了“晚餐”表以添加新的审核列:
```
> docker container logs ch06-docker-compose_nerd-dinner-db_1
VERBOSE: Starting SQL Server
VERBOSE: Changing SA login credentials
VERBOSE: Data files exist - will attach and upgrade database
Generating publish script for database 'NerdDinner' on server '.\SQLEXPRESS'.
Successfully generated script to file C:\init\deploy.sql.
VERBOSE: Changed database context to 'NerdDinner'.
VERBOSE: Altering [dbo].[Dinners]...
VERBOSE: Update complete.
VERBOSE: Deployed NerdDinner database, data files at: C:\data
```
新的审核列在更新行时添加了时间戳，所以现在当我通过 web UI 创建一个晚餐时，我可以看到该行上次在数据库中更新的时间。在我的开发环境中，我还没有发布用于客户端连接的 SQL Server 端口，但是我可以运行`docker container inspect`来获取容器的本地 IP 地址。然后，我可以将我的 SQL 客户端直接连接到容器，并运行查询来查看新的审核时间戳:
![](img/eb36d243-f04d-4ed7-a10c-cad9ea1d5188.png)
Docker Compose 查找资源及其定义之间的任何差异，而不仅仅是 Docker 映像的名称。如果您更改环境变量、端口映射、卷设置或任何其他配置，Docker Compose 将删除或创建资源，以使正在运行的应用达到所需的状态。
You need to be careful with modifying Compose files to run applications. If you remove the definition for a running service from the file, Docker Compose won't recognize that the existing service containers are part of the application, so they won't be included in the difference checks. You can end up with orphaned service containers.
# 监控应用容器
将一个分布式应用作为一个单元来处理，可以更容易地监控和跟踪问题。Docker Compose 提供了自己的`top`和`logs`命令，它们对应用服务中的所有容器进行操作，并显示收集到的结果。
要检查所有组件的内存和 CPU 使用情况，请运行`docker-compose top`:
```
> docker-compose top
ch06-docker-compose_elasticsearch_1
Name          PID     CPU            Private Working Set
---------------------------------------------------------
smss.exe      21380   00:00:00.046   368.6kB
csrss.exe     11232   00:00:00.359   1.118MB
wininit.exe   16328   00:00:00.093   1.196MB
services.exe  15180   00:00:00.359   1.831MB
lsass.exe     12368   00:00:01.156   3.965MB
svchost.exe   18424   00:00:00.156   1.626MB
...
```
容器按名称的字母顺序列出，每个容器中的进程没有特定的顺序。没有办法改变顺序，所以不能先在最努力的容器中显示最密集的进程，但是结果是纯文本的，所以可以在 PowerShell 中进行操作。
要查看所有容器的日志条目，运行`docker-compose logs`:
```
> docker-compose logs
Attaching to ch06-docker-compose_nerd-dinner-web_1, ch06-docker-compose_nerd-dinner-save-handler_1, ch06-docker-compose_nerd-dinner-api_1, ch06-docker-compose_nerd-dinner-db_1, ch06-docker-compose_kibana_1, ch06-docker-compose_nerd-dinner-index-handler_1, ch06-docker-compose_reverse-proxy_1, ch06-docker-compose_elasticsearch_1, ch06-docker-compose_nerd-dinner-homepage_1, ch06-docker-compose_message-queue_1
nerd-dinner-web_1   | 2019-02-12 13:47:11 W3SVC1002144328 127.0.0.1 GET / - 80 - 127.0.0.1 Mozilla/5.0+(Windows+NT;+Windows+NT+10.0;+en-US)+WindowsPowerShell/5.1.17763.134 - 200 0 0 7473
nerd-dinner-web_1   | 2019-02-12 13:47:14 W3SVC1002144328 ::1 GET / - 80 - ::1 Mozilla/5.0+(Windows+NT;+Windows+NT+10.0;+en-US)+WindowsPowerShell/5.1.17763.134 - 200 0 0 9718
...
```
在屏幕上，容器名称是彩色编码的，因此您可以很容易地从不同的组件中区分条目。通过 Docker Compose 读取日志的一个优点是，它显示所有容器的输出，即使组件显示错误并且容器停止。这些错误消息在上下文中很有用—您可能会看到一个组件在另一个组件记录它已经启动之前抛出了连接错误，这可能会突出显示撰写文件中缺少的依赖项。
Docker Compose 显示了所有服务容器的所有日志条目，因此输出会很大。您可以使用`--tail`选项对此进行限制，将输出限制为每个容器的指定数量的最新日志条目。
当您在开发中或在一个小规模项目中运行时，这些命令非常有用，因为单个服务器运行少量容器。它不适用于在多种主机上的多个容器上运行的大型项目。对于这些，您需要以容器为中心的管理和监控，我将在[第 8 章](08.html)、*管理和监控文档化解决方案*中演示。
# 管理应用映像
Docker Compose 可以管理 Docker 映像以及容器。在合成文件中，您可以包含告诉 Docker Compose 如何构建映像的属性。您可以指定要发送到 Docker 服务的构建上下文的位置，这是所有应用内容的根文件夹，以及 Docker 文件的位置。
上下文路径相对于撰写文件的位置，而 Dockerfile 路径相对于上下文。这对于复杂的源树非常有用，例如本书的演示源，其中每个映像的上下文都在不同的文件夹中。在`ch06-docker-compose-build`文件夹中，我有一个完整的包含应用规范的合成文件，并带有指定的构建属性。
这是如何为我的映像指定构建细节的:
```
nerd-dinner-db:
  image: dockeronwindows/ch06-nerd-dinner-db:2e
 build:
    context: ../ch06-nerd-dinner-db
    dockerfile: ./Dockerfile
...
nerd-dinner-save-handler:
  image: dockeronwindows/ch05-nerd-dinner-save-handler:2e
  build:
    context: ../../ch05
    dockerfile: ./ch05-nerd-dinner-save-handler/Dockerfile
```
当您运行`docker-compose build`时，任何具有指定`build`属性的服务都将被构建并使用`image`属性中的名称进行标记。构建过程使用普通的 Docker API，因此仍然使用映像层缓存，仅重建已更改的层。向合成文件中添加构建细节是构建所有应用映像的一种非常有效的方式，也是捕获映像构建方式的一个中心位置。
Docker Compose 的另一个有用特性是管理整组映像的能力。本章的撰写文件使用的映像都是 Docker Hub 上公开的，所以你可以用`docker-compose up`运行完整的应用——但是第一次运行时，所有的映像都会被下载，这需要一段时间。您可以在使用`docker-compose pull`之前预加载映像，这会拉取所有映像:
```
> docker-compose pull
Pulling message-queue             ... done
Pulling elasticsearch             ... done
Pulling reverse-proxy             ... done
Pulling kibana                    ... done
Pulling nerd-dinner-db            ... done
Pulling nerd-dinner-save-handler  ... done
Pulling nerd-dinner-index-handler ... done
Pulling nerd-dinner-api           ... done
Pulling nerd-dinner-homepage      ... done
Pulling nerd-dinner-web           ... done
```
同样，您可以使用`docker-compose push`将映像上传到远程存储库。对于这两个命令，Docker Compose 使用来自最近的`docker login`命令的经过认证的用户。如果您的合成文件包含您无权推送的映像，这些推送将会失败。对于您被授权写入的任何存储库，无论是在 Docker Hub 还是私有注册表中，这些映像都将被推送。
# 配置应用环境
当您在 Docker Compose 中定义应用时，您有一个单一的工件，它描述了应用的所有组件以及它们之间的集成点。这通常被称为**应用清单**—列出应用所有部分的文档。与 Dockerfile 明确定义安装和配置一个软件的步骤一样，Docker Compose 文件明确定义部署整个解决方案的步骤。
Docker Compose 还允许您捕获可以部署到不同环境的应用定义，因此您的 Compose 文件可以在整个部署管道中使用。通常，环境之间存在差异，无论是基础架构设置还是应用设置。Docker Compose 为您提供了两个选项来管理这些环境差异—使用外部资源或使用覆盖文件。
生产和非生产环境之间的基础架构通常不同，这影响了 Docker 应用中的卷和网络。在开发笔记本电脑上，您的数据库卷可能会映射到本地磁盘上的一个已知位置，您会定期清理该位置。在生产中，您可以为共享存储硬件设备提供卷插件。同样，对于网络，生产环境可能需要明确子网范围，这在开发中并不重要。
Docker Compose 允许您将资源指定为在 Compose 文件外部，因此应用将使用已经存在的资源。这些资源需要提前创建，但这意味着每个环境可以进行不同的配置，并且仍然使用相同的合成文件。
撰写还支持另一种方法，即在不同的撰写文件中显式捕获每个环境的资源配置，并在运行应用时使用多个撰写文件。我将演示这两种选择。与其他设计决策一样，Docker 不会强加特定的实践，您可以使用最适合您的流程的实践。
# 指定外部资源
合成文件中的卷和网络定义遵循与服务定义相同的模式—每个资源都被命名，并且可以使用相关`docker ... create`命令中提供的相同选项进行配置。在撰写文件中有一个指向现有资源的额外选项。
要为我的 SQL Server 和 Elasticsearch 数据使用现有卷，我需要指定`external`属性，并可选地指定资源的名称。在`ch06-docker-compose-external`目录中，我的 Docker Compose 文件包含以下卷定义:
```