title:Aion: Enabling Open Systems through Strong Availability Guarantees
for Enclaves
author:Fritz Alder and
Jo Van Bulck and
Frank Piessens and
Jan Tobias M&quot;uhlberg
Aion: Enabling Open Systems through Strong Availability
Guarantees for Enclaves
Fritz Alder
PI:EMAIL
imec-DistriNet, KU Leuven
Leuven, Belgium
Frank Piessens
PI:EMAIL
imec-DistriNet, KU Leuven
Leuven, Belgium
Jo Van Bulck
PI:EMAIL
imec-DistriNet, KU Leuven
Leuven, Belgium
Jan Tobias Mühlberg
PI:EMAIL
imec-DistriNet, KU Leuven
Leuven, Belgium
ABSTRACT
Embedded Trusted Execution Environments (TEEs) can provide
strong security for software in the IoT or in critical control systems.
Approaches to combine this security with real-time and availability
guarantees are currently missing. In this paper we present Aion, a
configurable security architecture that provides a notion of guar-
anteed real-time execution for dynamically loaded enclaves. We
implement preemptive multitasking and restricted atomicity on
top of strong enclave software isolation and attestation. Our ap-
proach allows the hardware to enforce confidentiality and integrity
protections, while a decoupled small enclaved scheduler software
component can enforce availability and guarantee strict deadlines
of a bounded number of protected applications, without necessar-
ily introducing a notion of priorities amongst these applications.
We implement a prototype on a light-weight TEE processor and
provide a case study. Our implementation can guarantee that pro-
tected applications can handle interrupts and make progress with
deterministic activation latencies, even in the presence of a strong
adversary with arbitrary code execution capabilities.
CCS CONCEPTS
• Security and privacy → Trusted computing; Operating sys-
tems security; Embedded systems security; • Computer systems
organization → Real-time systems; Availability.
KEYWORDS
trusted computing, availability, open systems, resource sharing
ACM Reference Format:
Fritz Alder, Jo Van Bulck, Frank Piessens, and Jan Tobias Mühlberg. 2021.
Aion: Enabling Open Systems through Strong Availability Guarantees for
Enclaves. In Proceedings of the 2021 ACM SIGSAC Conference on Computer
and Communications Security (CCS ’21), November 15–19, 2021, Virtual Event,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea
© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484782
Republic of Korea. ACM, New York, NY, USA, 16 pages. https://doi.org/10.
1145/3460120.3484782
1 INTRODUCTION
With the increased connectivity of devices all across the computing
spectrum comes an increasing demand for systems that are not
locked down but are more dynamic and open to changes after they
are deployed in the real world. An open system runs software com-
ponents (tasks, processes, ...) from several stakeholders that do not
necessarily trust each other. The resources of such system, includ-
ing memory, devices, and the CPU, must be shared among these
software components without introducing security vulnerabilities
that would allow a malicious component to violate the security
expectations of another component. Traditionally, Operating Sys-
tem (OS) kernels have the responsibility of enforcing appropriate
isolation between components, and, hence, the OS kernel has been
part of the Trusted Computing Base (TCB).
However, experience has shown that operating system kernels
can have vulnerabilities too, and several approaches have been
explored to reduce the amount of trust in the OS kernel:
First, there is a long line of work in reducing the size of kernels
(e.g., move to microkernels), or relying on simpler hypervisors or
security monitors for enforcing isolation [6, 23, 36]. The key idea
is that the trusted layer of software gets smaller, but all software
components still need to fully trust the system software for any of
their security properties.
Second, formal verification of system software has been proposed
as a mechanism to reduce the likelihood of vulnerabilities, and,
hence, to better justify the level of trust in system software[17, 19].
Third, work in the trusted computing research area has devel-
oped the idea of Trusted Execution Environments (TEEs) or en-
claves [1, 5, 7, 20, 21, 26, 30]. These approaches make it possible to
remove most (if not all) system software from the TCB, but they
cannot guarantee all desired security properties. More specifically,
while integrity and confidentiality of enclaves can be guaranteed
with a TCB consisting of just the enclave software itself and the
hardware, no availability guarantees can be provided. More gen-
erally, these systems can provide strong guarantees for resources
(like memory) that are spatially shared, but not for resources (like
CPU time) that are temporally shared. In the best case (for instance,
in Intel SGX), the operating system kernel can preempt temporally
shared resources from misbehaving enclaves, at the cost of having
Session 5A: Control System Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1357to trust the kernel for availability properties. In other cases, there
are no availability guarantees in the presence of malicious enclaves.
The objective of this paper is to improve the state-of-the-art in
this third approach. We propose a hardware/software co-design
that supports classic enclave-like isolation of software components
in an open system, and that improves on that classic isolation by
also providing availability guarantees. Our system supports the
secure temporal sharing of resources (including CPU and I/O de-
vices) among mutually distrusting software components with a
small TCB. More specifically, a given enclave software component
needs to trust: (i) its own code and the hardware for confidential-
ity and integrity properties, and (ii) its own code, the hardware,
the drivers of the shared devices it requires access to, and a small,
trusted scheduler enclave for availability properties. Crucially, since
the scheduler is only trusted for availability, our design protects
the confidentiality and integrity of vital enclave applications even
against a misbehaving scheduler. Furthermore, when the scheduler
is well-behaved, our design can provide strong availability guaran-
tees (including real-time guarantees) to software components in
the presence of arbitrary malicious software on the platform out-
side the TCB (including malicious enclaves, malicious drivers for
devices not used by this specific component, and system software
besides the trusted scheduler).
Our design targets small embedded systems (specifically, our
prototype is based on a TI MSP430 16-bit processor running the
RIOT OS), both because these can benefit most from availability
and real-time guarantees, and because this allows us to focus on
the essence of our design: building on preemption combined with
a safe bounded atomicity primitive. Extensions to larger systems,
such as for instance Intel SGX-scale processors, are not in the scope
of this paper, and are left for future work.
In summary, the contributions of this paper are:
• a novel hardware-software co-design of a security archi-
tecture for open systems that extends the strong security
properties of modern hardware TEEs with strong guarantees
on enclave availability, even in the presence of powerful
software adversaries on the same platform.
• a prototype implementation built by extending an existing
TI MSP430-based TEE and by extending the existing RIOT
IoT operating system.
• a case-study driven evaluation of the security and availability
provisions and the costs of the design.
2 PROBLEM AND ASSUMPTIONS
To illustrate the problem and our platform requirements, we first
discuss the base platform that we use as a starting point for our
work. We then describe a simple application scenario with specific
security and availability needs that cannot be realized with classic
TEE implementations. Finally we generalize this to derive platform
requirements and discuss these in the context of related work.
In general, we aim to support open systems, which are systems
that allow multiple distrusting stakeholders to dynamically load
arbitrary applications at runtime. While it is obviously possible to
combine an open system with priority-based scheduling, the inter-
esting and most difficult case is dealing with mutually distrusting
stakeholders executing code with the same priority. Only in this
case resources have to be divided fairly.
2.1 Generalized Base Platform
The base platform we start from is an embedded TEE that provides
an enclave-like isolation mechanism. This base platform supports
the creation of enclaves that offer the following security guaran-
tees. First, the software in an enclave is isolated from all other
software on the same platform, including system software such as
the operating system. Second, enclaves support (local and remote)
attestation: they can provide cryptographic evidence about their
identity (characterized by a cryptographic hash of the binary code
of the enclave). These security guarantees rely on a small trusted
computing base, sometimes even only the hardware.
More specifically, in terms of isolation, the base platform guar-
antees that: (i) the data section of an enclave is only accessible
while executing code from the code section of that same enclave,
and (ii) the code section can only be entered through one or more
designated entry points. These isolation guarantees are simple, but
they have been shown to be strong enough and useful to enforce
confidentiality and integrity properties of enclaved applications or
modules. For instance, Patrignani et al. [32] show how encapsu-
lation mechanisms from Java-like object-oriented languages can
be securely compiled to a platform that supports enclaves. This
implies that confidentiality and integrity properties of the enclave
can be guaranteed in an open system: an enclave developer only
needs to trust (or verify) the code of their own enclave (and pos-
sibly other enclaves that the enclave depends on, such as device
driver enclaves). As a consequence, mutually distrusting enclaves
can co-exist on the platform, and neither one needs to trust the
other to maintain its own security, which is limited to confidential-
ity and integrity. The construction and the benefits of such a base
platform is well understood, and Maene et al. [24] provide a survey
of existing platforms.
However, these platforms lack any kind of availability guarantee.
On some platforms [13, 30, 31] enclaves can protect themselves
from being interrupted (and, hence, get atomicity guarantees) for
security purposes, but as a consequence a misbehaving enclave
can abuse such atomicity guarantees to disrupt the system and
make it unavailable to other enclaves. On systems [7, 20, 21, 26]
where enclaves are interruptible, on the other hand, enclaves do
not get any guarantees on progress. For instance, enclaves might
never get scheduled, or when they are scheduled they can get
interrupted again without having made any progress. Also, enclaves
may need to acquire resources other than memory or CPU, e.g.,
access to I/O devices like sensors or communication channels, and
no guarantees can be provided that the enclave can acquire these
within a bounded time span. Note that some Memory-Mapped I/O
(MMIO) devices may only use a specific memory region to interact
with the applications. This means that this memory region needs
to be temporally shared between applications as a spatial sharing
may not be possible for certain control or status bits. Finally, some
platforms handle security violations in such a way that a security
violation from one enclave can impede the progress of another
one. For instance, a security violation might lead to a platform
reset [13, 30, 31].
Session 5A: Control System Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1358these platforms do not provide the required availability guarantees.
This includes the temporal sharing of MMIO devices. Specifically,
the requirements of A and B to run periodically, make progress,
and get a guaranteed opportunity to send out the alert cannot be
realized with existing TEE platforms. Especially not considering
that in our example, no application trusts any other application
on the device, for example considering them as compromised by a
strong software adversary.
2.3 Security & Availability Guarantees
We follow the established attacker model in TEE research (cf. Maene
et al. [24]), where all software that is not explicitly part of an applica-
tion’s TCB is considered to be under the control of the attacker. We
consider hardware-level attacks to be out of scope for our prototype.
In particular, an attacker cannot physically disconnect components
or control peripherals.
Under this model, the platform should provide the same guaran-
tees as the described generalized base platform above, i.e., confiden-
tiality and integrity of mutually distrusting applications combined
with the possibility to attest applications to remote parties. As a
generalization of the availability requirements of the running exam-
ple, the platform has to provide the following additional availability
guarantees for a bounded number of protected applications:
• Bounded activation latency: the platform guarantees a specific
finite bound on the maximal time that can elapse between
an event (in the example case, a timer interrupt) and the
execution of the first instruction of an enclave that wants to
act on the event.
• Guaranteed progress: the platform guarantees that within a
specific time interval 𝑇 (e.g. a second), at least 𝑥 percent of
the CPU cycles goes to the monitoring application (where 𝑇
and 𝑥 can be configurable, but an application can securely
attest these values to a remote stakeholder).
• Guaranteed device access: device drivers can be programmed
to provide assurance to an application that it can acquire
access to all devices it needs within a specific finite time 𝑇 .
Obviously, the temperature monitoring application needs to
trust (or verify) the code of the sensor driver and communi-
cation channel driver, and use it appropriately to get these
guarantees. But an important point is that no other applica-
tions competing for the same resources need to be trusted.
• Safety independence: faults in the executions of other appli-
cations do not impact the availability of the temperature
monitoring application. Only the application itself (includ-
ing dependent code) must be trusted (or verified) not to have
faults (including security faults) to preserve availability.
• No trust hierarchy: the same guarantees can be given to
multiple mutually distrusting applications. Two independent
applications can perform monitoring tasks and compete for
the communication channel to send out alerts, and both
of them will get the availability guarantees we discussed,
without either having to trust the other. It is in this sense
that our platform is truly an open system: progress and real-
time guarantees can be offered to a number of protected
applications that run at the same priority.
Figure 1: Simple example of two applications periodically
accessing the same shared resources.
This set of shortcomings leads us to the problem we set out to
solve in this paper: how can an enclave platform provide availability
guarantees, while maintaining the desired strong confidentiality
and integrity guarantees, i.e., in particular that only the hardware
plus the enclave itself and any dependent enclaves need to be trusted
or verified. By doing so, the platform we design is the first enclave
platform to provide a strong notion of availability for mutually
distrusting enclaves, where neither one needs to trust the other to
maintain its own security, which includes confidentiality, integrity,
and availability properties.
2.2 A Running Example
Figure 1 depicts a scenario with two applications A and B that
execute periodically, monitoring the same temperature sensor. Each
application will trigger an alert if the temperature exceeds a pro-
grammed threshold. These alerts are communicated over the same,
shared communication interface. We assume an open system where
all system resources, including the CPU, the sensor and the com-
munication interface, may be used by multiple applications. The de-
ploying stakeholders of A and B are neither aware of each other’s
applications, nor would they trust each other’s applications to be-
have collaboratively. However, both stakeholders consider their
applications to be critical as harm may be caused if the alarms are
not triggered within strict time bounds. The stakeholders do trust
the execution platform to uphold a notion of spatial and temporal
isolation for their respective applications, and they may rely on
primitives such as remote attestation to be ensured of their ap-
plication execution on the intended platform. In regards to input
and output from the temperature sensor and to the communica-
tion interface, the applications trust the utilized peripherals and an
attacker controlling one of the peripherals themselves or a failed
sensor are out of scope of their attacker model. This means that the
platform aims to provide guarantees only up to the device bound-
aries and tamper-resistant sensors or resilience against network
denial-of-service attackers are left to orthogonal research. At the
same time, peripheral drivers on the system and their communica-
tion with attached devices are in scope of the guarantees as long as
the attached peripheral is responsive.
While the spatial isolation properties required by our running
example are generally well understood in existing TEE platforms,