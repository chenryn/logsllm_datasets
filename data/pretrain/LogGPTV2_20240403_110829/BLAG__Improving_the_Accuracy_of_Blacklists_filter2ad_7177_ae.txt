greatly improves performance, it can only work with what it
has – existing public blacklist data. For all malicious datasets,
blacklists cover addresses in only 10.7–71.7% of /24 address
spaces and BLAG’s recall cannot go beyond this (shown by
the red horizontal line in Figure 6). Overall BLAG manages
to identify 6.4–69.7% of attackers and drop similar amounts
of attack trafﬁc. While this is far from perfect, dropping more
than half of the attack trafﬁc may be very helpful in emergency
scenarios. If BLAG were used to aggregate for-pay blacklists,
which list many more malicious sources [78],
its attacker
coverage would likely be better. We emphasize, however, that
BLAG manages to greatly improve the performance of public
blacklists while limiting collateral damage to legitimate trafﬁc.
10
 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)RecallMax recall 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)RecallMax recall 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalPRESTA+LBLAG No ExpBLAG(%)RecallMax recall 0 5 10 15 20 5 10 15 20 25 30% of BLAG IPsdaysEmail bestDDoSUniv bestDDoSDNS bestEmail historicalDDoSUniv historicalDDoSDNS historicalEmail PRESTADDoSUniv PRESTADDoSDNS PRESTA(a) Email
(b) DDoSUniv
(c) DDoSDNS
Figure 8: Speciﬁcity and recall of BLAG and four competing approaches with expansion.
(a) Email
(b) DDoSUniv
(c) DDoSDNS
Figure 9: Evaluating BGP and AS expansion techniques.
expansion vs 84.8% of PRESTA+L), making BLAG the best
performing approach, among the ones we tested. Similar trends
hold for other scenarios we tested.
BLAG outperforms best-expanded and historical-expanded
blacklists. We investigate if a similar expansion approach to
BLAG’s could improve the performance of the best blacklist
and the historical blacklist. Instead of selective expansion here,
which uses BLAG’s information, we use naïve expansion,
where each candidate address is expanded into its /24 preﬁx
if there are no overlaps with the known-legitimate source
(Ttr) dataset. Figure 8 shows that BLAG still outperforms
competing approaches, due to its selection of only high-quality
information to aggregate, before expansion. For the Email sce-
nario, the best blacklist with expansion has 99.8% speciﬁcity
vs 95% of BLAG. But, BLAG has 69.7% recall, while the
best blacklist with expansion has only 14.4%. The historical
blacklist with expansion has a comparable recall to that of
BLAG (69.7% vs 70.4% respectively). However, BLAG has
95% speciﬁcity while the historical blacklist with expansion
has 83.8%. We observe similar trends in the DDoSUniv and
DDoSDNS scenarios. In the DDoSDNS scenario, the historical
blacklist with expansion achieves 98.9% speciﬁcity (vs 99.5%
of BLAG) and 7.9% recall (vs 6.4% of BLAG) so they perform
roughly equal.
BLAG’s expansion approach using BGP preﬁx and AS
level. We investigate how BLAG’s performance would change
if we expanded IP addresses into their full BGP preﬁxes or
entire autonomous systems, as suggested in [75]. Expanding
some IP addresses into large preﬁxes is not advisable, as this
can potentially have large collateral damage, but we investigate
it as a hypothetical scenario. We apply /24-preﬁx, BGP-preﬁx
and AS-level aggregation to the master blacklist candidates,
produced by BLAG for the three datasets. We then apply the
selective expansion technique, but instead of using /24 preﬁx
in deciding whether to expand, use the encompassing BGP
preﬁx and the entire AS. We show the speciﬁcity and recall of
BLAG with these expansion approaches in Figure 9. Overall,
expanding IP addresses to AS or BGP preﬁx has a higher recall
than /24 expansion (7.9–23.4% higher). However, speciﬁcity
varies across different deployment scenarios. For the Email
scenario, /24 expansion has a little better speciﬁcity than AS
and BGP preﬁx expansion (2.5–3.7% better). For the DDoSUniv
scenario, /24 expansion has better speciﬁcity than AS and BGP
preﬁx hijacking (3.4–17.4%). For the DNS scenario, speciﬁcity
is about the same across the three expansion approaches.
B. Contribution of recommendation system
Figure 10(a) shows the contribution of the recommendation
system in the aggregation and selective expansion phase over
11
 0 20 40 60 80 100BestHistoricalBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalBLAG(%)Recall 0 20 40 60 80 100BestHistoricalBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalBLAG(%)Recall 0 20 40 60 80 100BestHistoricalBLAG(%)Specifcity 0 20 40 60 80 100BestHistoricalBLAG(%)Recall 0 20 40 60 80 100ASNBGP/24(%)Specifcity 0 20 40 60 80 100ASNBGP/24(%)Recall 0 20 40 60 80 100ASNBGP/24(%)Specifcity 0 20 40 60 80 100ASNBGP/24(%)Recall 0 20 40 60 80 100ASNBGP/24(%)Specifcity 0 20 40 60 80 100ASNBGP/24(%)Recall(a) BLAG’s recommendation system contribu-
tion to speciﬁcity.
(b) BLAG’s recommendation system contribu-
tion to recall.
(c) Contribution of blacklists by size.
Figure 10: Evaluating impact on speciﬁcty/recall due to various components in BLAG and contribution of blacklist size to BLAG.
our three scenarios. During the aggregation phase (top of
Figure 10(a)), BLAG’s recommendation system can prune out
misclassiﬁcations and improve speciﬁcity from 89–99% to 98–
99.6%. BLAG is even more effective in increasing speciﬁcity
during the selective expansion phase. BLAG’s recommenda-
tion system (shown as check1 in bottom half of Figure 10(a)),
improves speciﬁcity from 24.5–69.7% to 86.9–95.6% over
naïve expansion of all IP addresses. Also, BLAG’s complete
selective expansion phase (shown as check2), further improves
speciﬁcity to 95–99.5%.
On the other hand, BLAG’s recall depends on the cover-
age of blacklist, aggregation and selective expansion phases.
Figure 10(b) shows the impact of BLAG on recall. BLAG’s
aggregation phase (top of Figure 10(b)) uses a threshold to
prune out false positives and this can also prune out malicious
addresses. This phase reduces recall from 0.18–19.4% to 0.15–
19.35%. BLAG’s selective expansion (bottom of Figure 10(b))
also reduces the recall. During check1 phase of selective
expansion, recall further from 10.7–71.9% to 9–70.2% and
during the check2 phase of selective expansion, the recall
further reduces to 6.4–69.7%.
C. Contribution of Individual Blacklists
We ran BLAG on n largest blacklists for the Email sce-
nario, and varied n from 1 to 157 as shown in Figure 10(c).
There is a 15.7% gain in recall for the ﬁrst 106 blacklists.
After this, there is a sharp increase in recall for the remaining
blacklists. The next 20 largest blacklists double the recall to
32% and the next 14 largest blacklists push the recall past the
50% mark. When including all blacklists, the recall reaches
69.7%. Speciﬁcity stays at 100% for the ﬁrst 41 blacklists
and then drops slightly from 100% to 99.1% for the ﬁrst
100 blacklists. The speciﬁcity drops to 95.5% for the next
40 blacklists and ﬁnally, by adding the remaining blacklists,
the speciﬁcity comes down to 95%. Because we see a steady
improvement in recall and a steady, slow decline in speciﬁcity,
it is hard to tell how many blacklists would be enough. Instead,
BLAG could let a customer choose different numbers of
blacklists to aggregate and could produce speciﬁcity estimates
(e.g., by using a validation set Lv) for every choice.
12
D. Contribution of known-legitimate sources (Ltr):
We ran BLAG by varying the duration of the (Ltr) available
to BLAG– 0, 1, 3, 5 and 7 days for Email dataset as shown
in Figure 11(a). As the number of days is increased,
the
speciﬁcity improves with small reduction in recall. With only
1 day of legitimate data available, the speciﬁcity improves by
36.7% with a loss of 2% of recall. As we increase the number
of days the gain in speciﬁcity increases. By including all the
days for training dataset, the speciﬁcity only improves by 4.5%
and the recall reduces by 4.7%.
VII. PARAMETER TUNING
In this section, we discuss a methodology used to determine
the parameters l, α and K4.
Parameter l for Historical Decay.
In Section III-A, l
roughly controls the length of historical data (in days) that
may be included in the BLAG master blacklist. Using the
validation dataset (Lv + Mv), we determine the impact of l
for three values (10, 30 and 50) shown in Figure 11(b). For
the two scenarios, l = 30 has the highest recall. About 1.5–
8.9% and 4.3–36.4% higher recall for Email and DDoSUniv
scenarios respectively. For l = 30, the speciﬁcity is uniformly
high, ranging from from 95–97.9%. Therefore, l = 30 strikes
the right balance, which increases recall with minimal loss
in speciﬁcity. During our evaluation, we use l = 30 for
the DDoSDNS dataset. This agrees with our observations in
Section II-B, where 91% of blacklisted addresses that re-
offend, do so within 30 days.
Parameter α for choosing Master Blacklist candidates. The
parameter α controls the set of IP addresses, which should be
considered for the expansion phase in BLAG. We show the
performance in the validation dataset (Lv + Mv). Figure 11(c)
shows that for each scenario parameter α trades accuracy of
BLAG with higher coverage. For various thresholds, we plot
the speciﬁcity, recall and F1-score5. Network operators could
4Scripts to generate l, α and K can be found at https://steel.isi.edu/Projects/
BLAG/
5F1-score is the harmonic mean of precision (fraction of IP addresses, which
are listed and are indeed malicious sources) and recall
 0 20 40 60 80 100EmailDDoSUnivDDoSDNSAggregationspecifcity (%)Naive aggregationBLAG aggregation 0 20 40 60 80 100EmailDDoSUnivDDoSDNSExpansionspecifcity (%)Raw expansionCheck 1Check 2 0 20 40 60 80 100EmailDDoSUnivDDoSDNSAggregationrecall (%)Naive aggregationBLAG aggregation 0 20 40 60 80 100EmailDDoSUnivDDoSDNSExpansionrecall (%)Raw expansionCheck 1Check 2 0 10 20 30 40 50 60 70 80 90 100 0 20 40 60 80 100 120 140 160specifcity/recall (%)# of blacklistsspecifcityrecall(a) Contribution of known-legitimate sources
dataset.
(b) Evaluating parameter l.
(c) Threshold α.
Figure 11: Sensitivity analysis
use the F1-score as a metric to determine the appropriate
threshold. We see that for the Email scenario, after a threshold
of 0.8, the F1-score plateaus at 43%. For higher thresholds, the
speciﬁcity drops from 95% to 85.9%. Similarly for DDoSUniv
scenario, the F1-score plateaus after a threshold of 0.6 at 33%.
For higher thresholds, the speciﬁcity again drops from 97.9%
to 90.4%. Therefore, we set a threshold of 0.8 for Email and
0.6 for the DDoSUniv. Relevance scores for misclassiﬁcations
would typically be high since all misclassiﬁcations are allo-
cated a score of 1 in the misclassiﬁcation blacklist. Therefore,
for DDoSDNS scenario, we set a threshold of 0.8 to prune out
misclassiﬁcations.
Parameter K for Matrix Factorization. Parameter K is used
in non-negative matrix factorization (NMF), and denotes the
number of latent features. An ideal K will have the minimum
error between the matrix R(M xN ) and R(cid:48) (Section III-B).
Brunet et al. [53] suggested using the smallest K, after which
the cophenetic correlation coefﬁcient starts decreasing. For
the validation datasets, we evaluate different values of K and
ﬁnd that the cophenetic correlation coefﬁcient starts decreasing
after K is 5. BLAG is pre-conﬁgured to run gradient descent
with K = 5 until the root mean squared error (RMSE) between
the original matrix R and matrix R(cid:48) fell below 1% or the
number of iterations exceeded 1,000.
VIII. RELATED WORK
In this section, we survey work related to blacklist analysis,
blacklist improvement and aggregation.
Analysis of Blacklists. Kührer et al. evaluated the effec-
tiveness of ﬁfteen publicly available malware blacklists by
measuring accuracy and completeness on datasets consisting
of parked domains, sinkholed IP addresses, and active malware
domains [60]. Pitsillidis et al. evaluated ten different blacklists
on purity, coverage, proportionality, and timing [70]. Purity
was measured by comparing feeds to Alexa top websites and
Open directory listing, whereas coverage, proportionality, and
timing were obtained by comparing feeds to one another. Both
Kührer et al. and Pitsillidis et al. work support our ﬁndings
that blacklists are not accurate. Zhang et al. evaluated nine
blacklists using trafﬁc logs from a regional ISP [80]. They
analyzed overlapping IP addresses between trafﬁc logs and
blacklists. But
they were unable to measure the accuracy
of blacklists, as the trafﬁc in the logs was not labeled as
malicious or legitimate. Vector et al. [63] analyzed 47 distinct
IP address threat
intelligence sources and evaluated them
for volume, differential contribution, exclusive contribution,
latency, coverage, and accuracy. They used Alexa top 10 K
websites as ground truth for legitimate sources and scanners
captured by CAIDA darknet as ground truth for malicious
sources. Vector et al. support our ﬁnding that blacklists or
threat intelligence feeds have low recall ( 80%)
and very low misclassiﬁcations (< 2%). PRESTA’s technique
helps to uncover 18% more spammers while keeping misclassi-
ﬁcations low. In our evaluation, too, PRESTA helped improve
recall but at much higher misclassiﬁcation cost (Section V).
This may be because we use public blacklists, which may not
as accurate as pay-for blacklists.
Highly Predictive Blacklisting [79] (HPB) creates blacklists
customized to a given network by a page ranking algorithm.
Soldo et al. [76] extended HPB to use historical data about
attack sources and destinations and used a recommendation
system to predict possible attackers for each victim. In contrast,
BLAG uses a recommendation system to remove misclassiﬁ-
cations while aggregating blacklists. Sinha et al. [75] present a
new spam blacklisting technique, by monitoring email servers
and spam traps to curate a spam blacklist. BLAG, on the
other hand, works with existing blacklists to improve their
performance and is applicable to different types of attacks.
13
 0 20 40 60 80 1000 days1 days3 days5 days7 days(%)Specifcity 0 20 40 60 80 1000 days1 days3 days5 days7 days(%)Recall 0 20 40 60 80 100EmailDDoSUnivSpecifcity(%)BLAG10 BLAG30 BLAG50 0 20 40 60 80 100EmailDDoSUnivRecall(%)BLAG10 BLAG30 BLAG50 80 85 90 95 100 0 0.2 0.4 0.6 0.8 1Specifcity (%)EmailDDoSUniv 0 15 30 45 60 0 0.2 0.4 0.6 0.8 1Recall (%)EmailDDoSUniv 0 10 20 30 40 50 0 0.2 0.4 0.6 0.8 1F1 score (%)thresholdEmailDDoSUnivIX. DISCUSSION
We discuss possible attacks on BLAG. BLAG has no
way, other than the recommendation system, to differentiate
between low-quality and high-quality information. Thus, if
an attacker could produce a blacklist that is very similar to
some reputable blacklist, which does not have much overlap
with MB (e.g., by copying it) and if they included a few
public servers in it, BLAG could conceivably propagate this
information into its master blacklist. This could then lead
to legitimate trafﬁc from these public servers being dropped.
Current blacklists could also be polluted by the same approach.
Networks today choose carefully which blacklists to use, based
on their reputation in the operator community. We assume