reflection), representing 
pad (i.e., 
cause, after having selected 
movements 
they are the second longest 
other on the keypad. Putting 
193-7761. 
strings 
there are different 
cies based on these 
number in its entirety. 
(412) and random ones (776), we can see whether 
or discrimination 
all this together, 
since the number consists 
from one key to an­
we get 412-
of familiar 
accura­
to the phone 
spans, in addition 
movements 
different 
practice 
Finally, 
effects 
by the square wave via a 
matrix was triggered 
of 3.8 volts peak-to-peak, 
were: frequency of one Hertz, am­
duty cycle of 50%, DC 
whose characteristics 
plitude 
offset of 2 volts, and rise time of 20 nanoseconds. 
keyboard 
simple TTL logic tri-state 
input tied to the clock line (the output of the function 
ator). 
and 
one key-release 
error, 
milliseconds). 
200 microseconds. 
gener­
events (one key-press 
81.3% had zero 
and 18.7% had an error of 200 microseconds 
(or 0.2 
of 
per event) were triggered. 
At worst, timing is accurate 
Three thousand 
keystroke 
output latch, with the "enable" 
to a precision 
The 
Other digit strings 
may meet these criteria; 
our string 
4.4 Instructions 
to subjects 
in the end, the passcode 
in­
may not be unique. However, 
cludes all but two keys on the square portion 
(5 and 8 are never typed; 0 is outside 
cludes nine different 
seem characteristic 
of keying patterns. 
or horizontal 
vertical 
the square), 
and it in­
movements 
that 
of the keypad 
4.3 Apparatus 
Our experience 
suggests 
that the particulars 
of apparatus 
considerable 
detail 
are of significant 
used in experiments 
we provide 
may wish to replicate 
iments were run, or to determine 
not our tests were biased by experimental 
under which our exper­
whether or 
apparatus. 
the conditions 
for themselves 
importance, 
and so 
for the benefit of others who 
Computer and environment. 
All experiments 
were run 
keyboard 
computer 
X60s notebook 
(type-model 
system was 
Pack 2). We used an 
-the Apple M9034LLI A 
with 1.5 Gb RAM. The operating 
keyboard 
external 
on an IBM ThinkPad 
1702-4EU) 
Windows XP  Professional  (Service 
external 
typical 
mouse or other cursor-movement 
external 
UltraSharp 
pixel resolution. 
turned off, and there was no load on the machine other than 
the keystroke-logging 
No 
An 
was used for better visibility; 
Both wired and wireless 
used with Apple machines. 
flat panel LCD with 1280x1024 
device was available. 
application 
1907FP 19-inch 
networking 
USB; this is the 
it was a Dell 
itself. 
display 
was 
(412-193-7761) 
or en­
teller. 
Subjects 
Subjects 
passcode 
requiring 
a telephone 
were asked to type 
when prompted 
Any error in typing 
hand), as if dialing 
were instructed 
to use only the external 
by the pre­
to 
software to do so. Subjects 
key­
board, and they were advised that no mouse would be 
needed or would be available. 
50 repetitions 
of the experiment 
into a text box on the screen, 
sentation 
were instructed 
type with only the index finger of the right hand (irrespec­
tive of the dominant 
tering a PIN at an automated 
caused the text box to reset, 
the entire passcode 
Subjects 
passcodes 
needed a break or needed to stretch 
they were to do so after they had typed a full passcode, 
cluding 
artifi­
times and inter-key 
cially 
the middle of a passcode.  Subjects 
by looking 
showed how many passcodes 
yet remained. 
task, as if they were logging 
to avoid distractions, 
while the task was in progress. 
to type 
again. In this way, 50 perfectly 
typed 
were told that if they 
their hands or fingers, 
had been typed and how many 
to focus on the 
into their own account, 
and 
latencies 
could gauge progress 
in­
to prevent 
in 
the Return key. This was intended 
at the bottom of the screen which 
were admonished 
were obtained. 
such as talking 
at a counter 
anomalous 
the subject 
Subjects 
key-hold 
with the experimenter, 
4.5 Procedure 
and logging software. A presentation 
the pass code to the user in a full-screen 
pro­
win­
the user to type it into a 
and directed 
box within the user interface. 
The presentation 
Presentation 
gram displayed 
dow on the display, 
text-entry 
program has two components: 
The Logger is a DLL, written 
down and key-up event to 
VB.NET, is the graphic 
tion (instructions, 
resolution 
a Logger and a Prompter. 
in C++, that logs each key­
in 
a file. The Prompter, 
written 
informa­
user interface 
that displays 
input text box, etc.) to the user.  Timing 
was 100 microseconds 
via a specialized 
clock. 
Calibration. 
Keystroke timing 
accuracy 
was calibrated 
the keyboard 
by pulsing 
used a Hewlett Packard model 33120A, 15 MHz function 
and arbitrary 
matrix with a known signal; 
We used a square wave 
generator. 
waveform 
we 
carried 
out 
enough repetitions 
typed 200 error-free 
using only their right index finger (irrespective 
hand). The  200 repetitions 
were accumulated 
repetitions 
of the same 10-
at a time, in each of four sessions 
days. This provided 
Subjects 
digit string, 
of dominant 
50 repetitions 
over four alternating 
to reach a level of comfort with the string, 
used to a new password. 
as when getting 
comfort" 
described 
automaticity 
the mind with the low-level 
the result 
for a review). 
is reached 
task itself 
to do things without 
required. 
and practice 
repetition, 
regression 
can be more formally 
of learning, 
-the ability 
Nonlinear 
details 
after 80-100 repetitions. 
takes less than five minutes within a session. 
or 
as habituation 
occupying 
It is usually 
(see [29, 30] 
shows that full practice 
On average, 
the typing 
just the same 
This "level of 
978-1-4244-7501-8/10/$26.00 
©201O IEEE 
205 
DSN 2010: Maxion & Killourhy 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 13:58:09 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEEIIFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
5  Classifier, 
features and training 
This section 
explains 
the classifier 
that we used, the fea­
tures it employed, 
tical programming 
used for analyses. 
and its training 
environment 
and testing. 
(version 
2.10.0) 
[26] was 
The R statis­
5.1 Classifier 
-random  forest 
We used the random forest classifier, 
introduced 
by 
are an ensemble 
Breiman [6]. Random forests 
based on the generation 
one data set. Each tree is obtained 
strap sample from the data set. Each tree classifies 
and a majority 
of many classification 
a separate 
boot­
vote among the trees provides 
through 
trees from 
method 
the data, 
the final result. 
Although 
support 
vector machines 
are often considered 
random forests 
available, 
outperforming 
because it is robust against 
currently 
frequently 
to be the best classifiers 
are strong competitors, 
[8, 21]. The random forest classifier 
performer 
its tree-classification 
natures 
selection). 
lection, 
tributed 
SVMs 
is generally 
a good 
noise, and because 
rules enable it to find informative 
feature 
and can perform poorly when the classes 
in a large number of different 
of the data (i.e., 
SVMs do not perform variable 
sig­
automatic 
se­
in small subsets 
In contrast, 
but simple ways. 
are dis­
5.2 Features used in the classifier 
During typing, 
all key-press 
(key-down) 
and key-release 
(1) hold time (time elapsed 
From 
from the key-down of a character 
(key-up 
latencies 
classifier 
and recorded. 
can be derived: 
used in the random­
to key-down 
passcode, 
of the next character); 
and (3) 
between di­
events were timestamped 
each of the three features 
(key-up) 
these events, 
forest 
from key-down to key-up of a single key); (2) digram la­
tency (time elapsed 
be­
ing typed to the key-down 
digram interval 
grams). For a ten-digit 
(including 
cies, and 10 key-up to key-down 
gether form a 31-dimensional 
passcode 
they form a superset 
researchers. 
dependent, 
est, because 
part of its training, 
pendencies 
this is not a concern when using a random for­
as 
the random forest 
any linear de­
All three features 
ofthe features 
feature 
accommodating 
the return key), 10 key-down to 
some of these features 
among features. 
repetition. 
intervals, 
Although 
performs 
thereby 
there are 11 hold times 
vector that represents 
commonly used by other 
each 
were used, because 
selection 
are linearly 
key-down laten­
which taken to­
5.3 Training and testing procedures 
In this section 
we show how the random-forest 
classifier 
and tested. 
As a reminder, 
was trained 
typed the passcode 
tions each. Half of the data were selected 
the detector; 
For the training 
phase, we 
the other half were used to test the detector. 
drew 100 passcodes 
from each 
200 times, in four sessions 
of 50 repeti­
to use in training 
variation 
of 50. 
equal 
while controlling 
-25 from each of a subject's 
four sessions 
set would contain 
within-subject 
sampling 
for 
(Al­
between sessions. 
would be 
subject 
This was done so that the training 
amounts of data from each subject, 
potential 
though such stringent 
impractical 
how well the detector 
count for this additional 
within-session 
changes 
were drawn randomly 
taking the first 25, we took a randomly-selected 
each session). 
the 25 passcodes 
(e.g., rather than 
25 from 
in typing behavior, 
from each session 
could perform before having to ac­
in a real-world 
across sessions 
challenge.) 
to control 
for 
setting, 
Finally, 
we wanted to establish 
data, a random-forest 
was built to pre­
ID number) had 
timing fea­
of features). 
(denoted 
on the basis of the passcode's 
5.2 for description 
data were composed of the half of the data 
data were drawn. Using 
after the training 
classifier 
as the subject's 
The testing 
that remained 
the training 
dict which subject 
typed a passcode 
tures (see Section 
the implementation 
that is part of the randomForest R package (version 
34) by Liaw and Weiner [19]. 
using it to predict 
the test sample, 
actual subject 
con­
fusion matrix in which the element in row i, column j is a 
count of the number of times the subject 
predicted 
4.5-
by 
in 
IDs to the 
the subject 
comparing 
to have ID j by the random forest. 
We evaluated 
the classifier 
ID of each of the passcodes 
of the random forest 
IDs. We created 
the predicted 
with true ID i was 
training 
subject 
We used 
algorithm 
a 26-by-26-dimension 
Since we used a random sample to divide the data into 
for the 
and testing 
we repeated 
data set. This yielded 
the above procedure 
of this randomness, 
sets, and we wanted to account 
training 
effect 
draw 
selected 
five times, each time with an independently 
from the entire 
five confusion 
matri­
ces, only one of which was chosen for use in this paper -
that was the one with the median misclassification 
rate. The 
rates across all five draws had 
variation 
Hence the choice of 
a range of only 0.6 percentage 
which of the five matrices 
is of small import. 
of misclassification 
points. 
to explore 
6 Analysis and results 
Performance 
was measured 
in terms of classification er­
the instances 
user (mistak­
in 
him as if he were a legitimate 
an impostor 
user). 
ror, by which we mean the percentage of 
which the system misclassified 
a legitimate 
enly calling 
(mistakenly 
In classical 
called, 
alarm or false positive 
(miss or false negative 
him an impostor) 
admitting 
signal-detection 
respectively, 
Type I error (variously 
terminology, 
or misclassified 
or false rejection) 
[31]. 
or false acceptance) 
in terms of the 
report performance 