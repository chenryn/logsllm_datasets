identical resources, we use Spark’s existing task-level scheduling.
4 Overview and Design Challenges
Decima represents the scheduler as an agent that uses a neural network
to make decisions, henceforth referred to as the policy network. On
scheduling events — e.g., a stage completion (which frees up execu-
tors), or a job arrival (which adds a DAG) — the agent takes as input
the current state of the cluster and outputs a scheduling action. At a
high level, the state captures the status of the DAGs in the scheduler’s
queue and the executors, while the actions determine which DAG
stages executors work on at any given time.
Decima trains its neural network using RL through a large number
of offline (simulated) experiments. In these experiments, Decima
attempts to schedule a workload, observes the outcome, and provides
the agent with a reward after each action. The reward is set based
on Decima’s high-level scheduling objective (e.g., minimize average
Figure 2: TPC-H queries scale differently with parallelism: Q9 on a 100 GB
input sees speedups up to 40 parallel tasks, while Q2 stops gaining at 20 tasks;
Q9 on a 2 GB input needs only 5 tasks. Picking “sweet spots” on these curves
for a mixed workload is difficult.
Figure 2 illustrates this with the job runtime of two TPC-H [73]
queries running on Spark as they are given additional resources to run
more parallel tasks. Even when both process 100 GB of input, Q2 and
Q9 exhibit widely different scalability: Q9 sees significant speedup
up to 40 parallel tasks, while Q2 only obtains marginal returns beyond
20 tasks. When Q9 runs on a smaller input of 2 GB, however, it needs
no more than ten parallel tasks. For all jobs, assigning additional par-
allel tasks beyond a “sweet spot” in the curve adds only diminishing
gains. Hence, the scheduler should reason about which job will see
the largest marginal gain from extra resources and accordingly pick
the sweet spot for each job.
Existing schedulers largely side-step this problem. Most burden
the user with the choice of how many parallel tasks to use [68, §5], or
rely on a separate “auto-scaling” component based on coarse heuris-
tics [9, 28]. Indeed, many fair schedulers [31, 43] divide resources
without paying attention to their decisions’ efficiency: sometimes, an
“unfair” schedule results in a more efficient overall execution.
2.3 An illustrative example on Spark
The aspects described are just two examples of how schedulers can
exploit knowledge of the workload. To achieve the best performance,
schedulers must also respect other considerations, such as the exe-
cution order (e.g., favoring short jobs) and avoiding resource frag-
mentation [34, 77]. Considering all these dimensions together — as
Decima does — makes a substantial difference. We illustrate this by
running a mix of ten randomly chosen TPC-H [73] queries with input
sizes drawn from a long-tailed distribution on a Spark cluster with
50 parallel task slots.4 Figure 3 visualizes the schedules imposed
by (a) Spark’s default FIFO scheduling; (b) a shortest-job-first (SJF)
policy that strictly prioritizes short jobs; (c) a more realistic, fair
scheduler that dynamically divides task slots between jobs; and (d)
a scheduling policy learned by Decima. We measure average job
completion time (JCT) over the ten jobs. Having access to the graph
structure helps Decima improve average JCT by 45% over the naive
FIFO scheduler, and by 19% over the fair scheduler. It achieves this
speedup by completing short jobs quickly, as five jobs finish in the
first 40 seconds; and by maximizing parallel-processing efficiency.
SJF dedicates all task slots to the next-smallest job in order to finish
it early (but inefficiently); by contrast, Decima runs jobs near their
parallelism sweet spot. By controlling parallelism, Decima reduces
4See §7 for details of the workload and our cluster setup.
272
0102030405060708090100Degreeofparallelism0100200300Jobruntime[sec]Q9,2GBQ9,100GBQ2,100GBSIGCOMM ’19, August 19-23, 2019, Beijing, China
H. Mao et al.
(a) FIFO scheduling.
(b) SJF scheduling.
(c) Fair scheduling.
(d) Decima.
Figure 3: Decima improves average JCT of 10 random TPC-H queries by 45% over Spark’s FIFO scheduler, and by 19% over a fair scheduler on a cluster with
50 task slots (executors). Different queries in different colors; vertical red lines are job completions; purple means idle.
JCT). The RL algorithm uses this reward signal to gradually improve
the scheduling policy. Appendix B provides a brief primer on RL.
Decima’s RL framework (Figure 4) is general and it can be applied
to a variety of systems and objectives. In §5, we describe the design for
scheduling DAGs on a set of identical executors to minimize average
JCT. Our results in §7 will show how to apply the same design to
schedule multiple resources (e.g., CPU and memory), optimize for
other objectives like makespan [65], and learn qualitatively different
polices depending on the underlying system (e.g., with different
overheads for moving jobs across machines).
Challenges. Decima’s design tackles three key challenges:
(1) Scalable state information processing. The scheduler must con-
sider a large amount of dynamic information to make scheduling
decisions: hundreds of job DAGs, each with dozens of stages,
and executors that may each be in a different state (e.g., assigned
to different jobs). Processing all of this information via neural
networks is challenging, particularly because neural networks
usually require fixed-sized vectors as inputs.
(2) Huge space of scheduling decisions. The scheduler must map
potentially thousands of runnable stages to available executors.
The exponentially large space of mappings poses a challenge for
RL algorithms, which must “explore” the action space in training
to learn a good policy.
(3) Training for continuous stochastic job arrivals. It is important
to train the scheduler to handle continuous randomly-arriving
jobs over time. However, training with a continuous job arrival
process is non-trivial because RL algorithms typically require
training “episodes” with a finite time horizon. Further, we find
that randomness in the job arrival process creates difficulties for
RL training due to the variance and noise it adds to the reward.
5 Design
This section describes Decima’s design, structured according to how
it addresses the three aforementioned challenges: scalable processing
of the state information (§5.1), efficiently encoding scheduling deci-
sions as actions (§5.2), and RL training with continuous stochastic
job arrivals (§5.3).
5.1 Scalable state information processing
On each state observation, Decima must convert the state information
(job DAGs and executor status) into features to pass to its policy
network. One option is to create a flat feature vector containing all the
state information. However, this approach cannot scale to arbitrary
number of DAGs of arbitrary sizes and shapes. Further, even with
273
Figure 4: In Decima’s RL framework, a scheduling agent observes the cluster
state to decide a scheduling action on the cluster environment, and receives a
reward based on a high-level objective. The agent uses a graph neural network
to turn job DAGs into vectors for the policy network, which outputs actions.
entity
job
stage (DAG node)
node v’s children
symbol
i
v
ξ(v)
job i’s DAG Gi
job i’s parallelism li
non-linear functions
f ,д,q,w
entity
per-node feature vector
per-node embedding
per-job embedding
global embedding
node score
symbol
xi
v
ei
v
yi
z
qi
v
parallelism score w i
l
Table 1: Notation used throughout §5.
a hard limit on the number of jobs and stages, processing a high-
dimensional feature vector would require a large policy network that
would be difficult to train.
Decima achieves scalability using a graph neural network, which
encodes or “embeds” the state information (e.g., attributes of job
stages, DAG dependency structure, etc.) in a set of embedding vectors.
Our method is based on graph convolutional neural networks [12, 23,
46] but customized for scheduling. Table 1 defines our notation.
The graph embedding takes as input the job DAGs whose nodes
carry a set of stage attributes (e.g., the number of remaining tasks,
expected task duration, etc.), and it outputs three different types of
embeddings:
(1) per-node embeddings, which capture information about the node
and its children (containing, e.g., aggregated work along the crit-
ical path starting from the node);
(2) per-job embeddings, which aggregate information across an entire
job DAG (containing, e.g., the total work in the job); and
(3) a global embedding, which combines information from all per-job
embeddings into a cluster-level summary (containing, e.g., the
number of jobs and the cluster load).
Importantly, what information to store in these embeddings is not
hard-coded — Decima automatically learns what is statistically im-
portant and how to compute it from the input DAGs through end-
to-end training. In other words, the embeddings can be thought of
as feature vectors that the graph neural network learns to compute
Task slotsFIFO, avg.job duration 111.4 secTime (seconds)020010015050Task slotsSJF, avg.job duration 81.7 secTime (seconds)020010015050Task slotsFair, avg. job duration 74.9 sec020010015050Time (seconds)Task slotsDecima, avg. job duration 61.1 sec020010015050Time (seconds)StateJob DAG 1Job DAG nExecutor 1Executor mScheduling Agentp[Policy Network(§5.2)GraphNeuralNetwork(§5.1)EnvironmentSchedulable NodesObjectiveRewardObservation of jobs and cluster statusLearning Scheduling Algorithms for Data Processing Clusters
SIGCOMM ’19, August 19-23, 2019, Beijing, China
(a) Per-node embedding.
(b) Per-job and global embeddings.
Figure 5: A graph neural network transforms the raw information on each
DAG node into a vector representation. This example shows two steps of local
message passing and two levels of summarizations.
without manual feature engineering. Decima’s graph neural network
is scalable because it reuses a common set of operations as building
blocks to compute the above embeddings. These building blocks are
themselves implemented as small neural networks that operate on
relatively low-dimensional input vectors.
Per-node embeddings. Given the vectors xi
v of stage attributes cor-
responding to the nodes in DAG Gi , Decima builds a per-node em-
bedding (Gi ,xi
v is a vector (e.g., in R16) that
captures information from all nodes reachable from v (i.e., v’s child
nodes, their children, etc.). To compute these vectors, Decima prop-
agates information from children to parent nodes in a sequence of
message passing steps, starting from the leaves of the DAG (Figure 5a).
In each message passing step, a node v whose children have aggre-
gated messages from all of their children (shaded nodes in Figure 5a’s
examples) computes its own embedding as:
v . The result ei
v)(cid:55)−→ ei

 +xi
v ,
ei
v =д
u∈ξ(v)
f (ei
u)
(1)
where f (·) and д(·) are non-linear transformations over vector inputs,
implemented as (small) neural networks, and ξ(v) denotes the set
of v’s children. The first term is a general, non-linear aggregation
operation that summarizes the embeddings of v’s children; adding
this summary term to v’s feature vector (xv ) yields the embedding for
v. Decima reuses the same non-linear transformations f (·) and д(·)
at all nodes, and in all message passing steps.
aggregation operations of the form ev =
Most existing graph neural network architectures [23, 24, 46] use
u∈ξ(v) f (eu) to compute
node embeddings. However, we found that adding a second non-linear
transformation д(·) in Eq. (1) is critical for learning strong scheduling
policies. The reason is that without д(·), the graph neural network
cannot compute certain useful features for scheduling. For example,
it cannot compute the critical path [44] of a DAG, which requires a
max operation across the children of a node during message passing.5
Combining two non-linear transforms f (·) and д(·) enables Decima
to express a wide variety of aggregation functions. For example, if
f and д are identity transformations, the aggregation sums the child
node embeddings; if f ∼ log(·/n), д ∼ exp(n × ·), and n → ∞, the
aggregation computes the max of the child node embeddings. We
show an empirical study of this embedding in Appendix E.
5The critical path from node v can be computed as: cp(v) =maxu∈ξ (v)cp(u)+work(v),
where work(·) is the total work on node v.
v ,ei
Per-job and global embeddings. The graph neural network also
computes a summary of all node embeddings for each DAG Gi ,
{(xi
v),v ∈ Gi} (cid:55)−→ yi ; and a global summary across all DAGs,
{y1, y2, ...} (cid:55)−→ z. To compute these embeddings, Decima adds a
summary node to each DAG, which has all the nodes in the DAG as
children (the squares in Figure 5b). These DAG-level summary nodes
are in turn children of a single global summary node (the triangle
in Figure 5b). The embeddings for these summary nodes are also
computed using Eq. (1). Each level of summarization has its own
non-linear transformations f and д; in other words, the graph neural
network uses six non-linear transformations in total, two for each
level of summarization.
5.2 Encoding scheduling decisions as actions
The key challenge for encoding scheduling decisions lies in the learn-
ing and computational complexities of dealing with large action
spaces. As a naive approach, consider a solution, that given the embed-
dings from §5.1, returns the assignment for all executors to job stages
in one shot. This approach has to choose actions from an exponentially
large set of combinations. On the other extreme, consider a solution
that invokes the scheduling agent to pick one stage every time an
executor becomes available. This approach has a much smaller action
space (O(# stages)), but it requires long sequences of actions to sched-
ule a given set of jobs. In RL, both large action spaces and long action
sequences increase sample complexity and slow down training [7, 72].