Furthermore, the communication complexity decreases, since
only 1 proof rather than |S| needs to be broadcast. Thus,
AMT VSS can also use batch proofs and maintain the same
performance as eVSS during the complaint round. (However,
in Table I, we do not assume this optimization.)
3) Efﬁcient reconstruction: In some cases, we can reduce
the number of pairings computed during AMT VSS’s re-
construction phase. In this phase, the reconstructor is given
anywhere from t to n shares and their AMT proofs. His task
is to ﬁnd a subset of t valid shares and interpolate the secret.
Let us ﬁrst consider the best case, where all submitted shares
are valid. In this case, if the reconstructor naively veriﬁes any
t AMT proofs, he spends Θ(t log t) time. But he would be
computing the same quotient-accumulator pairings multiple
times (as in Equation (3)), since proofs with intersecting
paths will share quotient commitments. By memoizing these
computations, the reconstructor can verify the t proofs in Θ(t)
time. Alternatively, this can be sped up by exposing a gs public
key during dealing (as in DKG protocols; see §III-D3).
Now let us consider the worst case, where n − t shares
are invalid and t shares are valid. The reconstructor wants to
ﬁnd the t valid shares as fast as possible. Once again, he can
memoize the quotient-accumulator pairings that are part of
successfully validated proofs. This way, for the t valid proofs,
only Θ(t) pairings need to be computed. Thus, at most Θ((n−
t) log t) pairings could possibly be computed for the invalid
proofs. The worst-case reconstruction time remains Θ(n log t)
but, in practice, the number of pairings is reduced signiﬁcantly
by the memoization.
4) Public parameters: The AMT VSS dealer needs (t− 1)-
SDH public parameters, just like in eVSS. This is because
committing to accumulator polynomials of degree ≥ t is not
necessary, as discussed in §III-B4. In fact, adding more public
parameters for committing to degree ≥ t polynomials would
break the correctness of eVSS and thus of AMT VSS [14].
Speciﬁcally, if the dealer commits to a degree ≥ t polynomial
φ, then different secrets could be reconstructed, depending
on the subset of players whose shares are used. This is
why the (t − 1)-polyDH assumption (see Deﬁnition A.3) is
needed in both protocols. Finally, AMT VSS players (and the
reconstructor) need Θ(log t) public parameters to verify AMT
proofs, an increase from eVSS’ Θ(1) (i.e., gτ ).
D. Scalable Distributed Key Generation
In this section, we scale (t, n) DKG protocols to large n
in the difﬁcult case when t > n/2. We start from eJF-DKG,
where each player acts as an eVSS dealer (see Algorithm 2),
taking Θ(nt) time to compute n KZG evaluation proofs
and Θ(t) time to compute one KZG proof for gfi(0) (see
Algorithm 2). We simply replace eVSS with AMT VSS in
eJF-DKG, obtaining a new protocol we call AMT DKG with
smaller Θ(n log t) per-player dealing time. Importantly, we
keep the same KZG proof for gfi(0).
Compared to eJF-DKG, AMT DKG has slightly larger
communication (see §IV-C5), larger proof veriﬁcation times
and a slower complaint round (see Table I). Fortunately, when
using KZG batch proofs (see §III-C2), the complaint round
can be made more efﬁcient in both eJF-DKG and AMT DKG.
Furthermore, we show AMT DKG players can verify their
shares much faster under certain conditions (see §III-D2).
Finally, in §IV-C, we show that our smaller dealing time more
than makes up for these increases.
1) Homomorphic AMT proofs: At the end of eJF-DKG’s
sharing phase, each player must aggregate all his shares,
commitments and KZG proofs from the set of qualiﬁed players
into a ﬁnal share, commitment and proof (see Algorithm 2).
But for this to work in AMT DKG, AMT proofs must be
homomorphic: ∀a ∈ Fp, a proof for f1(a) and a proof for
f2(a) must be aggregated into a proof for (f1 + f2)(a).
The key observation is that “adding up” the multipoint
evaluation trees of two polynomials φ and ρ at the same points
(i.e., at X = {ωj−1
N }j∈[n]) results in a multipoint evaluation
tree of their sum φ + ρ (also at X). In more detail, let qw,[ψ]
denote the quotient polynomial at node w in ψ’s multipoint
evaluation tree (at X). Then, one can show that qw,[φ+ρ] =
qw,[φ] + qw,[ρ] and that gqw,[φ+ρ](τ ) = gqw,[φ](τ )+qw,[ρ](τ ) =
gqw,[φ](τ )gqw,[ρ](τ ). In other words, given an AMT for φ and
an AMT for ρ, we can obtain an AMT for φ+ρ by multiplying
quotient commitments at each node. It follows that a proof for
f1(a) and one for f2(a) can be aggregated into a proof for
(f1 + f2)(a) by multiplying commitments at each node.
2) Fast-track veriﬁcation round: During the veriﬁcation
round, each player j must receive and verify shares from
all players i ∈ [n],
including himself (see Algorithm 2).
Speciﬁcally, each player i gives j: (1) a KZG commitment
ci of i’s polynomial fi, (2) a share si,j = fi(ωj−1
N ) with an
AMT proof πi,j and (3) gfi(0) with a NIZKPoK and KZG
proof. Next, player j must verify each si,j and gfi(0) against
their ci. With naive veriﬁcation, this takes Θ(n log t) pairings
for all si,j’s (since πi,j’s are AMT proofs), and Θ(n) pairings
for the gfi(0)’s. We show how batch veriﬁcation can do this
faster, with anywhere from Θ(log t) to Θ(n log t) pairings,
depending on the number of valid shares. (We will not address
the Θ(n) work required to verify all NIZKPoKs.)
share sj = (cid:80)n
call = (cid:81)n
First, consider the best case when all si,j’s are valid.
The key idea is player j will verify just one aggregated
i=1 si,j against an aggregated commitment
i=1 ci and aggregated proof πj from all πi,j’s (as
(cid:80)n
explained in §III-D1). (We ignore the gfi(0)’s for now.) This
takes Θ(n log t) aggregation work but only takes Θ(log t)
pairings. If successful, j has a valid share sj on fall =
i=1 fi. The same aggregation can be done on the gfi(0)’s
and their KZG proofs. This way, the number of pairings is
reduced signiﬁcantly to Θ(log t) for the shares and Θ(1) for
the gfi(0)’s. (Again, j still does Θ(n) work to verify the
NIZKPoKs individually, which we will not address.)
Since players can be malicious, let us consider an average
case when a small number of b shares are bad. In this case,
j can identify the b shares faster via batch veriﬁcation [10].
Speciﬁcally, j starts with the shares, proofs and commitments
as leaves of a binary tree, where every node aggregates its
subtree’s shares, proofs and commitments. As a result, the
root will contain (call, sj, πj). If veriﬁcation of the root fails, j
proceeds recursively down the tree. Whenever a node veriﬁes,
shares in its subtree will no longer be checked individually,
saving work for j. In this fashion, j only computes Θ(b log t)
pairings if ≤ b shares are bad.
Unfortunately, in the worst case (i.e., t − 1 bad shares),
batch veriﬁcation computes ≈ (2n − 1) log t pairings, which
is slower than the ≈ n log t pairings when done naively. Thus,
as pointed out by previous work [70], j should abort and verify
naively after too many nodes fail veriﬁcation. To summarize, j
can compute fewer pairings by batch-verifying optimistically
to see if he is in the best or average case and downgrading
to naive veriﬁcation otherwise. We stress that j still does
Θ(n log t) work to build the tree and Θ(n) work to verify
all NIZKPoKs, but fewer (expensive) pairings are computed.
3) Optimistic reconstruction: DKG protocols have the ad-
vantage that gs must be exposed to all players and the recon-
structor. Thus, the reconstructor can optimistically interpolate
s from any t shares (without verifying them) and check
the result against gs. In the best case, when all or most
shares are valid, this will recover the correct s very fast (see
§IV-C3). (Note that AMT VSS and eVSS do not expose gs
but they could be easily modiﬁed to do so and speed up the
reconstruction in the best case, at a very small increase in
dealing time.) In the worst case, AMT DKG’s reconstruction
time is the same as AMT VSS’s (see §III-C3).
IV. EVALUATION
In this section, we demonstrate the scalability of our pro-
posed cryptosystems. Our experiments focus on the difﬁcult
case when t > n/2, speciﬁcally t = f +1 and n = 2f +1. We
benchmark TSS, VSS and DKG cryptosystems for thresholds
t ∈ {21, 22, 23, . . . , 220}. Although we did not benchmark
other thresholds, similar performance gains would have been
observed for other sufﬁciently large values of t (e.g., t = f +1
and n = 3f + 1). However, we acknowledge that, for
sufﬁciently small t, eVSS’s and eJF-DKG’s Θ(nt) dealing
would outperform ours. Similarly, in this small t setting, naive
Lagrange interpolation would outperform fast Lagrange. Our
experiments show that:
• Our BLS TSS scales to n ≈ 2 million signers and outper-
forms the naive scheme as early as n = 511 (see Figure 2a).
• AMT VSS scales to hundreds of thousands of participants,
and outperforms eVSS as early as n = 255 (see Figure 2f).
• AMT DKG scales to n ≈ 65,000 players and outperforms
eJF-DKG at n = 1023 (see Figure 2i).
Importantly, our VSS and DKG speed-ups come at the price
of a modest increase in communication (see Figure 2c). For
example, for n ≈ 65,000, a DKG player’s communication
during dealing increases by 4.11× from 18 MiB in eJF-DKG
to 74 MiB in AMT DKG. However, since the worst-case end-
to-end time decreases by 32× from 16.76 hrs in eJF-DKG to
30.83 mins in AMT DKG, the extra communication should be
worth it in many applications.
For prohibitively-slow experiments with large t, we repeat
them fewer times than experiments with smaller t. For brevity,
we specify the amount of times we repeat an experiment for
each threshold via a measurement conﬁguration. For example,
the measurement conﬁguration of our efﬁcient BLS threshold
scheme is (cid:104)7 × 100, 13 × 10(cid:105). This means that for the ﬁrst
7 thresholds t ∈ {21, 22, . . . , 27} we ran the experiment 100
times while for the last 13 thresholds we ran it 10 times.
1) Codebase and experimental setup: We implemented (1)
our BLS threshold signature scheme from §III-A, (2) eJF-
DKG [17] and AMT DKG and (3) eVSS [14] and AMT VSS
in 5700 lines of C++. We used a 254-bit Barretto-Naehrig
curve with a Type III pairing [71] from Zcash’s libff [72]
elliptic curve library. We used libfqfft [73] to multiply
polynomials fast using FFT. All experiments were run on an
Intel Core i7 CPU 980X @ 3.33GHz with 12 cores and 20
GB of RAM, running Ubuntu 16.04.6 LTS (64-bit version).
Since all benchmarked schemes would beneﬁt equally from
multi-threading, we did not implement it.
2) Limitations: Our DKG and VSS evaluations do not
account for network delays. This is an important limitation.
Our focus was on the computational bottlenecks of these
protocols. Nonetheless, scaling and evaluating the broadcast
channel of VSS and DKG protocols is necessary, interesting
future work. In particular,
ideas from scalable consensus
protocols [4] could be used for this. Finally, our VSS and DKG
“worst case” evaluations do not fully account for malicious
behavior. Speciﬁcally, they do not account for the additional
communication and computational cost associated with com-
plaint broadcasting. We leave this to future work (see §V-2).
A. BLS Threshold Signature Experiments
i (0) w.r.t. points xi = ωi−1
ﬁnal threshold signature σ = (cid:81)
First, we sample a random subset of t signers T with
valid signature shares {σi}i∈T . Second, we compute Lagrange
coefﬁcients LT
(see §II-4) us-
ing both fast and naive Lagrange. Third, we compute the
using a multi-
exponentiation. The measurement conﬁguration for fast La-
grange is (cid:104)7 × 100, 13 × 10(cid:105) while for naive Lagrange is
(cid:104)8 × 100, 6 × 10, 8, 4, 2, 1, 1, 1(cid:105). We plot the average aggrega-
tion time in Figure 2a and observe that our scheme beats the
naive scheme as early as n = 511. We do not measure the time
to identify valid signature shares via batch veriﬁcation [10],
which our techniques leaves unchanged.
N
LT
i (0)
i
i∈T σ
(a) Threshold signature aggregation time
(b) VSS & DKG deal time
(c) DKG dealing communication (per player)
(d) VSS verify time (per-player)
(e) VSS reconstruction time
(f) VSS end-to-end time
(g) DKG verify time (per-player)
(h) DKG reconstruction time
(i) DKG end-to-end time
Fig. 2. All benchmarked threshold cryptosystems have threshold t = f + 1 out of n = 2f + 1. The x-axis always indicates log2 t. The y-axis is in seconds,
except in Figure 2c it is in MB and in Figure 2d it is in milliseconds.
Our results show that our fast Lagrange interpolation drasti-
cally reduces the time to aggregate when t ≈ n/2. Speciﬁcally,
for n ≈ 221, we aggregate a signature in 46.26 secs, instead of
1.59 days if aggregated via naive Lagrange (2964× faster). The
beneﬁts are not as drastic for smaller thresholds, but remain
signiﬁcant. For example, for n ≈ 215, we reduce the time by
41× from 29.74 secs to 719.65 ms. For n = 4095, we see a
6.6× speed-up from 636.6 ms to 96.17 ms. For n = 2047, we
see a 3× speed-up from 155.62 ms to 50.74 ms.
B. Veriﬁable Secret Sharing Experiments
In this section, we benchmark eVSS and AMT VSS. We do
not benchmark the complaint round since, when implemented
with KZG batch proofs, it remains the same (see §III-C2).
1) VSS dealing: For eVSS dealing, the measurement con-
ﬁguration is (cid:104)10 × 10, 3, 2, 2, 1, 1, 0, 0, 0, 0, 0(cid:105). For large t ≥
216, eVSS dealing is too slow, so we extrapolate it from
the previous dealing time (i.e., we multiply by 3.5). For
AMT VSS dealing, the measurement conﬁguration is (cid:104)12 ×
100, 50, 22, 10, 5, 3, 2, 1, 1(cid:105). In eVSS, we compute the shares
si “for free” as remainders of the φ(x)/(x − i) divisions. We
plot the average dealing time in AMT VSS and eVSS as a
function of n in Figure 2b. Our results show that AMT VSS’s
Θ(n log t) dealing scales much better than eVSS’s Θ(nt)
dealing. For example, for n ≈ 65, 000, eVSS takes 15.1 hrs
while AMT VSS takes 1.24 mins. For very large n ≈ 221,
eVSS takes a prohibitive 330 days while AMT VSS takes 42
mins. We ﬁnd that AMT VSS’s dealing outperforms eVSS’s
as early as n = 31.
In Figure 2d, we plot
2) VSS veriﬁcation round: