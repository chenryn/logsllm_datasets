ran a subset of our benchmarks on in-order machines:
In-Order vs. Out-of-Order CPUs
Figure 2: SPEC2000 SFI Performance Overhead for x86-64.
SFI performance is compared to the faster of -m32 and -m64
compilation.
x86-64
4.2
Our x86-64 comparisons are based on GCC 4.4.3. The
selection of a performance baseline is not straightfor-
ward. The available compilation modes for x86 are ei-
ther 32-bit (ILP32, -m32) or 64-bit (LP64, -m64). Each
represents a performance tradeoff, as demonstrated pre-
viously [15, 25].
In particular, the 32-bit compilation
model’s use of ILP32 base types means a smaller data
working set compared to standard 64-bit compilation in
GCC. On the other hand, use of the 64-bit instruction set
offers additional registers and a more efﬁcient register-
based calling convention compared to standard 32-bit
compilation. Ideally we would compare our SFI com-
piler to a version of GCC that uses ILP32 and the 64-bit
instruction set, but without our SFI implementation. In
the absence of such a compiler, we consider a hypothet-
ical compiler that uses an oracle to automatically select
the faster of -m32 and -m64 compilation. Unless other-
wise noted all GCC compiles used the -O2 optimization
level.
Figure 2 and Table 2 provide x86-64 results, where
average SFI overhead is about 5% compared to -m32,
7% compared to -m64 and 15% compared to the ora-
cle compiler. Across the benchmarks, the distribution
is roughly bi-modal. For parser and gap, SFI per-
formance is better than either -m32 or -m64 binaries
(Table 4). These are also cases where -m64 execution
is slower than -m32, indicative of data-cache pressure,
leading us to believe that the beneﬁcial impact additional
registers dominates SFI overhead. Three other bench-
marks (vpr, mcf and twolf) show SFI impact is less
than 2%. We believe these are memory-bound and do not
beneﬁt signiﬁcantly from the additional registers.
At
the other end of the range, four benchmarks,
gcc, crafty, perlbmk and vortex show perfor-
mance overhead greater than 25%. All run as fast or
faster for -m64 than -m32, suggesting that data-cache
pressure does not dominate their performance. Gcc,
perlbmk and vortex have large text, and we sus-
-5%0%5%10%15%20%25%30%35%40%45%gzipvprgccmcfcraftyparserperlbmkgapvortexbzip2twolfa hazard that would cause a pipeline stall. Second, we
suggest that the Cortex-A9, as the ﬁrst widely-available
out-of-order ARM chip, might not match the maturity
and sophistication of the Core 2 Quad.
5 Discussion
Given our initial goal to impact execution time by less
than 10%, we believe these SFI designs are promising.
At this level of performance, most developers targeting
our system would do better to tune their own code rather
than worry about SFI overhead. At the same time, the
geometric mean commonly used to report SPEC results
does a poor job of capturing the system’s performance
characteristics; nobody should expect to get “average”
performance. As such we will continue our efforts to
reduce the impact of SFI for the cases with the largest
slowdowns.
Our work fulﬁlls a prediction that the costs of SFI
would become lower over time [28]. While thoughtful
design has certainly helped minimize SFI performance
impact, our experiments also suggest how SFI has bene-
ﬁted from trends in microarchitecture. Out-of-order ex-
ecution, multi-issue architectures, and the effective gap
between memory speed and CPU speed all contribute
to reduce the impact of the register-register instructions
used by our sandboxing schemes.
We were surprised by the low overhead of the ARM
sandbox, and that the x86-64 sandbox overhead should
be so much larger by comparison. Clever ARM in-
struction encodings deﬁnitely contributed. Our design
directly beneﬁts from the ARM’s powerful bit-clear in-
struction and from predication on stores. It usually re-
quires one instruction per sandboxed ARM operation,
whereas the x86-64 sandbox frequently requires extra in-
structions for address calculations and adds a preﬁx byte
to many instructions. The regularity of the ARM instruc-
tion set and smaller bundles (16 vs. 32 bytes) also means
that less padding is required for the ARM, hence less
instruction cache pressure. The x86-64 design also in-
duces branch misprediction through our omission of the
ret instruction. By comparison the ARM design uses
the normal return idiom hence minimal impact on branch
prediction. We also note that the x86-64 systems are gen-
erally clocked at a much higher rate than the ARM sys-
tems, making the relative distance to memory a possible
factor. Unfortunately we do not have data to explore this
question thoroughly at this time.
We were initially troubled by the result that our system
improves performance for so many benchmarks com-
pared to the common -m32 compilation mode. This
clearly results from the ability of our system to leverage
features of the 64-bit instruction set. There is a sense in
which the comparison is unfair, as running a 32-bit bi-
nary on a 64-bit machine leaves a lot of resources idle.
Figure 3: Additional SPEC2000 SFI overhead on in-order mi-
croarchitectures.
164.gzip
181.mcf
186.crafty
197.parser
254.gap
256.bzip2
geomean
Core 2 Atom 330
25.1
-34.4
51.2
-11.5
42.3
25.9
18.5
16.0
-42.6
29.3
-20.3
-5.09
21.6
6.89
A9
4.4
-0.2
4.2
3.2
3.4
2.9
3.0
A8
2.6
-1.0
6.3
0.6
7.7
2.0
3.0
Table 6: Comparison of SPEC2000 overhead (percent) for in-
order vs. out-of-order microarchitecture.
• A 1.6GHz Intel Atom 330 with 2GB of RAM, run-
ning Ubuntu Linux 9.10.
• A 500MHz Cortex-A8
OMAP3540) with 256MB of RAM,
˚Angstr¨om Linux.
(Texas
Instruments
running
The results are shown in Figure 3 and Table 6. For
our x86-64 SFI scheme, the incremental overhead can be
signiﬁcantly higher on the Atom 330 compared to a Core
2 Duo. This suggests out-of-order execution can help
hide the overhead of SFI, although other factors may also
contribute, including much smaller caches on the Atom
part and the fact that GCC’s 64-bit code generation may
be biased towards the Core 2 microarchitecture. These
results should be considered preliminary, as there are a
number of optimizations for Atom that are not yet avail-
able in our compiler, including Atom-speciﬁc instruction
scheduling and better selection of no-ops. Generation of
efﬁcient SFI code for in-order x86-64 systems is an area
of continuing work.
The story on ARM is different. While some bench-
marks (notably gap) have higher overhead, some (such
as parser) have equally reduced overhead. We were
surprised by this result, and suggest two factors to ac-
count for it. First, microarchitectural evaluation of the
Cortex-A8 [3] suggests that the instruction sequences
produced by our SFI can be issued without encountering
-10%0%10%20%30%40%50%60%gzipmcfcraftyparsergapbzip2Additional SFI OverheadAtom 330 v. Core 2Cortex-A8 v. Cortex-A9Our results demonstrate in part the beneﬁt of exploiting
those additional resources.
We were also surprised by the magnitude of the posi-
tive impact of ILP32 primitive types for a 64-bit binary.
For now our x86-64 design beneﬁts from this as yet un-
exploited opportunity, although based on our experience
the community might do well to consider making ILP32
a standard option for x86-64 execution.
In our continuing work we are pursuing opportuni-
ties to reduce SFI overhead of our x86-64 system, which
we do not consider satisfactory. Our current alignment
implementation is conservative, and we have identiﬁed
a number of opportunities to reduce related padding.
We will be moving to GCC version 4.5 which has
instruction-scheduling improvements for in-order Atom
systems. In the fullness of time we look forward to devel-
oping an infrastructure for proﬁle-guided optimization,
which should provide opportunities for both instruction
cache and branch optimizations.
6 Related Work
Our work draws directly on Native Client, a previous
system for sandboxing 32-bit x86 modules [30]. Our
scheme for optimizing stack references was informed
by an earlier system described by McCamant and Mor-
risett [18]. We were heavily inﬂuenced by the original
software fault isolation work by Wahbe, Lucco, Ander-
son and Graham [28].
Although there is a large body of published research
on software fault isolation, we are aware of no publica-
tions that speciﬁcally explore SFI for ARM or for the
64-bit extensions of the x86 instruction set. SFI for
SPARC may be the most thoroughly studied, being the
subject of the original SFI paper by Wahbe et al. [28]
and numerous subsequent studies by collaborators of
Wahbe and Lucco [2, 16, 11] and independent investi-
gators [4, 5, 8, 9, 10, 14, 22, 29]. As this work matured,
much of the community’s attention turned to a more vir-
tual machine-oriented approach to isolation, incorporat-
ing a trusted compiler or interpreter into the trusted core
of the system.
The ubiquity of the 32-bit x86 instruction set has cat-
alyzed development of a number of additional sandbox-
ing schemes. MiSFIT [23] contemplated use of software
fault isolation to constrain untrusted kernel modules [24].
Unlike our system, they relied on a trusted compiler
rather than a validator. SystemTAP and XFI [21, 7] fur-
ther contemplate x86 sandboxing schemes for kernel ex-
tension modules. McCamant and Morrisett [18, 19] stud-
ied x86 SFI towards the goals of system security and re-
ducing the performance impact of SFI.
Compared to our sandboxing schemes, CFI [1] pro-
vides ﬁner-grained control ﬂow integrity. Whereas our
systems only guarantee indirect control ﬂow will target
an aligned address in the text segment, CFI can restrict
a speciﬁc control transfer to a fairly arbitrary subset of
known targets. While this more precise control is useful
in some scenarios, such as ensuring integrity of transla-
tions from higher-level languages, our use of alignment
constraints helps simplify our design and implementa-
tion. CFI also has somewhat higher average overhead
(15% on SPEC2000), not surprising since its instrumen-
tation sequences are longer than ours. XFI [7] adds
to CFI further integrity constraints such as on memory
and the stack, with additional overhead. More recently,
BGI [6] considers an innovative scheme for constrain-
ing the memory activity of device drivers, using a large
bitmap to track memory accessibility at very ﬁne gran-
ularity. None of these projects considered the problem
of operating system portability, a key requirement of our
systems.
The Nooks system [26] enhances operating system
kernel reliability by isolating trusted kernel code from
untrusted device driver modules using a transparent OS
layer called the Nooks Isolation Manager (NIM). Like
Native Client, NIM uses memory protection to isolate
untrusted modules. As the NIM operates in the kernel,
x86 segments are not available. The NIM instead uses a
private page table for each extension module. To change
protection domains, the NIM updates the x86 page ta-
ble base address, an operation that has the side effect
of ﬂushing the x86 Translation Lookaside Buffer (TLB).
In this way, NIM’s use of page tables suggests an alter-
native to segment protection as used by NaCl-x86-32.
While a performance analysis of these two approaches
would likely expose interesting differences, the compar-
ison is moot on the x86 as one mechanism is available
only within the kernel and the other only outside the ker-
nel. A critical distinction between Nooks and our sand-
boxing schemes is that Nooks is designed only to pro-
tect against unintentional bugs, not abuse. In contrast,
our sandboxing schemes must be resistant to attempted
deliberate abuse, mandating our mechanisms for reliable
x86 disassembly and control ﬂow integrity. These mech-
anisms have no analog in Nooks.
Our system uses a static validator rather than a trusted
compiler, similar to validators described for other sys-
tems [7, 18, 19, 21], applying the concept of proof-
carrying code [20]. This has the beneﬁt of greatly re-
ducing the size of the trusted computing base [27], and
obviates the need for cryptographic signatures from the
compiler. Apart from simplifying the security implemen-
tation, this has the further beneﬁt of opening our system
to 3rd-party tool chains.
7 Conclusion
This paper has presented practical software fault isola-
tion systems for ARM and for 64-bit x86. We believe
these systems demonstrate that the performance over-
head of SFI on modern CPU implementations is small
enough to make it a practical option for general purpose
use when executing untrusted native code. Our experi-
ence indicates that SFI beneﬁts from trends in microar-
chitecture, such as out-of-order and multi-issue CPU
cores, although further optimization may be required to
avoid penalties on some recent low power in-order cores.
We further found that for data-bound workloads, mem-
ory latency can hide the impact of SFI.
Source code for Google Native Client can be found at:
http://code.google.com/p/nativeclient/.
References
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Lig-
atti. Control-ﬂow integrity: Principles, implemen-
In Proceedings of the
tations, and applications.
12th ACM Conference on Computer and Commu-
nications Security, November 2005.
[2] A. Adl-Tabatabai, G. Langdale, S. Lucco, and
R. Wahbe. Efﬁcient and language-independent mo-
SIGPLAN Not., 31(5):127–136,
bile programs.
1996.
[3] ARM Limited. Cortex A8 technical reference
http://infocenter.arm.com/
manual.
help/index.jsp?topic=com.arm.doc.
ddi0344/index.html, 2006.
[4] P. Barham, B. Dragovic, K. Fraser, S. Hand, A. Ho,
R. Neugebauer, I. Pratt, and A. Warﬁeld. Xen and
the art of virtualization. In 19th ACM Symposium
on Operating Systems Principles, pages 164–177,
2003.
[5] E. Bugnion, S. Devine, K. Govil, and M. Rosen-
blum. Disco: Running commodity operating sys-
tems on scalable multiprocessors. ACM Trans-
actions on Computer Systems, 15(4):412–447,
November 1997.
[6] M. Castro, M. Costa, J. Martin, M. Peinado,
P. Akritidis, A. Donnelly, P. Barham, and R. Black.
Fast byte-granularity software fault isolation.
In
2009 Symposium on Operating System Principles,
pages 45–58, October 2009.
[7] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and
G. Necula. XFI: Software guards for system ad-
dress spaces. In OSDI ’06: 7th Symposium on Op-
erating Systems Design And Implementation, pages
75–88, November 2006.
[8] B. Ford. VXA: A virtual architecture for durable
compressed archives. In USENIX File and Storage
Technologies, December 2005.
[9] B. Ford and R. Cox. Vx32: Lightweight user-level
sandboxing on the x86. In 2008 USENIX Annual
Technical Conference, June 2008.
[10] J. Gosling, B. Joy, G. Steele, and G. Bracha. The
Java Language Speciﬁcation. Addison-Wesley,
2000.
[11] S. Graham, S. Lucco, and R. Wahbe. Adaptable bi-
nary programs. In Proceedings of the 1995 USENIX
Technical Conference, 1995.
[12] J. L. Henning. SPEC CPU2000: Measuring CPU
performance in the new millennium. Computer,
33(7):28–35, 2000.
[13] C. Lattner. LLVM: An infrastructure for multi-
stage optimization. Masters Thesis, Computer Sci-
ence Department, University of Illinois, 2003.
[14] T. Lindholm and F. Yellin. The Java Virtual Ma-
chine Speciﬁcation. Prentice Hall, 1999.
[15] J. Liu and Y. Wu. Performance characterization
of the 64-bit x86 architecture from compiler opti-
In Proceedings of the In-
mizations’ perspective.
ternational Conference on Compiler Construction,
CC’06, 2006.
[16] S. Lucco, O. Sharp, and R. Wahbe. Omniware: A
universal substrate for web programming. In Fourth
International World Wide Web Conference, 1995.
[17] C.-K. Luk, R. Muth, H. Patil, R. Weiss, P. G.
Lowney, and R. Cohn.
Proﬁle-guided post-
In Proceedings of the
link stride prefetching.
ACM International Conference on Supercomput-
ing, ICS’02, 2002.
[18] S. McCamant and G. Morrisett. Efﬁcient, veri-
ﬁable binary sandboxing for a CISC architecture.
Technical Report MIT-CSAIL-TR-2005-030, MIT
Computer Science and Artiﬁcial Intelligence Labo-
ratory, 2005.
[19] S. McCamant and G. Morrisett. Evaluating SFI for
a CISC architecture. In 15th USENIX Security Sym-
posium, August 2006.
[20] G. Necula. Proof carrying code. In Principles of
Programming Languages, 1997.
[21] V. Prasad, W. Cohen, F. Eigler, M. Hunt, J. Kenis-
ton, and J. Chen. Locating system problems using
In 2005 Ottawa Linux
dynamic instrumentation.
Symposium, pages 49–64, July 2005.
[22] J. Richter. CLR via C#, Second Edition. Microsoft
Press, 2006.
[23] C. Small. MiSFIT: A tool for constructing safe ex-
tensible C++ systems. In Proceedings of the Third
USENIX Conference on Object-Oriented Technolo-
gies, June 1997.
[24] C. Small and M. Seltzer. VINO: An integrated
platform for operating systems and database re-
search. Technical Report TR-30-94, Harvard Uni-
versity, Division of Engineering and Applied Sci-
ences, Cambridge, MA, 1994.
[25] Sun Microsystems.
the HotSpot JVM.
com/display/HotSpotInternals/
CompressedOops.
Compressed OOPs
in
http://wikis.sun.
[26] M. Swift, M. Annamalai, B. Bershad, and H. Levy.
Recovering device drivers. In 6th USENIX Sympo-
sium on Operating Systems Design and Implemen-
tation, December 2004.
[27] U. S. Department of Defense, Computer Security
Center. Trusted computer system evaluation crite-
ria, December 1985.
[28] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Gra-
ham. Efﬁcient software-based fault isolation. ACM
SIGOPS Operating Systems Review, 27(5):203–
216, December 1993.
[29] C. Waldspurger. Memory resource management in
VMware ESX Server. In 5th Symposium on Oper-
ating Systems Design and Implementation, Decem-
ber 2002.
[30] B. Yee, D. Sehr, G. Dardyk, B. Chen, R. Muth,
T. Ormandy, S. Okasaka, N. Narula, and N. Ful-
lagar. Native client: A sandbox for portable, un-
trusted x86 native code. In Proceedings of the 2009
IEEE Symposium on Security and Privacy, 2009.