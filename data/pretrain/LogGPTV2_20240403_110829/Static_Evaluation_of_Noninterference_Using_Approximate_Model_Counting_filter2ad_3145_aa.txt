title:Static Evaluation of Noninterference Using Approximate Model Counting
author:Ziqiao Zhou and
Zhiyun Qian and
Michael K. Reiter and
Yinqian Zhang
2018 IEEE Symposium on Security and Privacy
Static Evaluation of Noninterference using
Approximate Model Counting
Ziqiao Zhou
Zhiyun Qian
Michael K. Reiter
Yinqian Zhang
University of North Carolina
University of California
University of North Carolina
The Ohio State University
Chapel Hill, NC, USA
PI:EMAIL
Riverside, CA, USA
PI:EMAIL
Chapel Hill, NC, USA
Columbia, OH, USA
PI:EMAIL
PI:EMAIL
Abstract—Noninterference is a deﬁnition of security for secret
values provided to a procedure, which informally is met when
attacker-observable outputs are insensitive to the value of the
secret inputs or, in other words, the secret inputs do not “inter-
fere” with those outputs. This paper describes a static analysis
method to measure interference in software. In this approach,
interference is assessed using the extent to which different secret
inputs are consistent with different attacker-controlled inputs
and attacker-observable outputs, which can be measured using
a technique called model counting. Leveraging this insight, we
develop a ﬂexible interference assessment technique for which the
assessment accuracy quantiﬁably grows with the computational
effort invested in the analysis. This paper demonstrates the
effectiveness of this technique through application to several
case studies, including leakage of: search-engine queries through
auto-complete response sizes; secrets subjected to compression
together with attacker-controlled inputs; and TCP sequence
numbers from shared counters.
Index Terms—information ﬂow; noninterference; approximate
model counting
I. INTRODUCTION
Information leakage about secrets in software is a core
concern for computer security, and has been for decades
(e.g., [1]). Leakage can in principle be detected by tracking
information ﬂow from secret objects to attacker-observable
ones, and considerable progress has been made on static-
analysis tools for detecting leakage vulnerabilities in software
(see Sec. II for a discussion of related work). Still, however,
assessing the signiﬁcance of detected leaks continues to be
a difﬁculty that plagues static-analysis tools, particularly for
ones that track implicit information ﬂows (e.g., [2]).
In this paper we propose a static-analysis method to assess
leakage vulnerabilities, even those that leverage implicit ﬂows.
The intuition of our design draws from noninterference [3],
which informally is achieved when the attacker-controlled
inputs and attacker-observable outputs are unchanged by the
value of a secret input that should not “interfere” with what the
attacker can observe. In practice, noninterference is extremely
unlikely to hold for most real-world programs, since a degree
of leakage is often necessary. As such, a more quantitative
measurement of (non)interference should be more useful in
assessing leakage. In principle, if all possible pairs of attacker-
controlled inputs and attacker-observable outputs could be
enumerated for any given value of the secret
then
differences in the pairs possible for different secrets would
input,
reveal interference between the secret value and the pairs that
remain possible, and hence an estimate for potential leakage.
Unfortunately, enumerating these pairs for all possible secret
values is often impractical for complex procedures, and so
previous explorations based on similar principles have been
limited (again, see Sec. II).
Within this framework, we explore the assessment of leak-
age vulnerabilities by randomly sampling a space of secret
values and then limiting our search for pairs of attacker-
controlled inputs and attacker-observable outputs to only those
that are consistent with some secret in that space. By leverag-
ing techniques from approximate model counting [4], we show
how to scalably estimate the number of such pairs to a desired
accuracy and conﬁdence and—perhaps more to the point—the
number of such pairs that are consistent with one or both of
two disjoint spaces of secret values. Finding two spaces of
secret values for which these counts suggest pairs consistent
with one but not both then reveals interference. Moreover, we
will demonstrate the need to examine samples of secrets of
varying sizes, and show how small samples can provide a more
reliable indication of the number of secret values about which
information leaks, while larger samples provide more insight
into the amount of leakage of secret values. In doing so, we
develop a powerful framework for interference detection and
assessment with the following strengths:
• The error in our assessment of a reported interference can
be reduced, arbitrarily close to zero in the limit, through
greater computational investment. Speciﬁcally, by increasing
the accuracy and conﬁdence with which the number of
pairs of attacker-controlled inputs and attacker-observable
outputs consistent with sampled secrets are estimated, and
by increasing the number and variety of samples tested, the
interference assessment quantiﬁably improves.
• Our framework supports the derivation of values from its
estimates that can separately provide insight into the number
of secret values about which information leaks, and the
amount of leakage about those secrets. Within the context of
particular applications, one type of leakage might be more
important than the other.
• Even for nondeterministic applications, our framework pro-
vides a robust assessment of noninterference, by accounting
for the nondeterministic factors (e.g., procedure inputs other
than the secrets or attacker-controlled values).
© 2018, Ziqiao Zhou. Under license to IEEE.
DOI 10.1109/SP.2018.00052
514
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:23 UTC from IEEE Xplore.  Restrictions apply. 
We detail our approach and its implementation in a tool. Our
tool takes as input a procedure; a speciﬁcation of which of its
inputs are attacker-controlled, which are secrets, and which
outputs are attacker-observable; and parameters to drive the
secret-sampling strategy to reach a desired conﬁdence in its
leakage assessment.
We demonstrate our tool through its application in numerous
scenarios. We ﬁrst apply it to selected, artiﬁcially small ex-
amples (microbenchmarks) to demonstrate its features. Then,
we apply it to assess leakage in several real-world examples.
• We apply our tool to detect leakage of web search query
strings submitted to the Sphinx web server on the basis
of auto-complete response sizes returned to the client (i.e.,
even if the query and response contents themselves are en-
crypted) [5]. We also leverage our tool to evaluate the impact
of various mitigation strategies on this leak, e.g., showing
that based on the contents of the searchable database, some
seemingly stronger defenses offer little additional protection
over seemingly weaker ones.
• We use our tool to demonstrate the vulnerability leveraged
in CRIME attacks [6], speciﬁcally that adaptive compression
algorithms provide opportunities for an attacker to test
guesses about secrets that he cannot observe, if he can
instead observe the length of compressed strings containing
both the secret and his guess. This case study demonstrates
the ability of our technique to effectively account for
attacker-controlled inputs, in contrast to many prior tech-
niques (see Sec. II). Speciﬁcally, we apply our tool to both
Gzip and the ﬁxed-dictionary compression library Smaz
to illustrate that they both leak information about secrets to
the adversary, but that Gzip leaks more information as the
number of adversary-controlled executions grows.
• We apply our tool to illustrate the tendency of Linux to leak
TCP-session sequence numbers to an off-path attacker [7],
[8]. This is perhaps the most complex of the examples
we consider, and again illustrates the power of accounting
for attacker-controlled variables. Moreover, we evaluate two
plausible defenses against this attack, one a hypothetical
patch to Linux that we propose, and another being simply
to disable use of information that is central to the leak.
This paper is structured as follows. We discuss related work
in Sec. II and then present our methodology for interference
measurement in Sec. III. The implementation of our tool is
described in Sec. IV. We use microbenchmarks in Sec. V to
demonstrate features of our approach, and then apply our tool
to real-world codebases in Sec. VI. Some limitations of our
approach are discussed in Sec. VII. We conclude in Sec. VIII.
II. RELATED WORK
Our work can be viewed as a form of static information-
ﬂow analysis, an area with a long history of prior work (e.g.,
see [9]–[13] and the references therein). A central challenge
(e.g., [2]) in this space is how to assess detected leaks, as some
might be insufﬁciently consequential to warrant attention. One
strategy that is often adopted is to simply ignore implicit ﬂows
(e.g., [14]). In contrast, our analysis encompasses both implicit
and explicit ﬂows.
A second approach to assess leaks, often termed quantitative
information ﬂow (QIF, e.g., [15]–[22]), is to compute the
amount of information leaked about the secret (e.g., in terms
of some type of entropy), conditioned on the output values
observable by the attacker. In the context of static analysis,
QIF has already been used to estimate leakage for cache side-
channel attacks based on an abstract cache model (e.g., [23],
[24]) and leakage from network trafﬁc of web applications
(e.g., [5], [25]–[27]), for example. To our knowledge, our
work improves on prior work in QIF along one or more
of the following dimensions. First, computing the measures
in these works often involves computing outputs induced by
possible secret values, which sometimes leverages application-
speciﬁc restrictions to be tractable (e.g., [25]). Our frame-
work, in contrast, does not require such application-speciﬁc
restrictions. Second, exploiting leakage vulnerabilities often
requires attackers not only to observe outputs but also to inject
inputs, and many applications incorporate other inputs, as
well. These QIF calculations are not possible without knowing
the distributions from which these values are drawn (e.g.,
[28]), and so some works (e.g., [29], [30]) heuristically assign
speciﬁc values to these unknown inputs, potentially hiding
the leakage from other assignments. Our analysis computes
conditionals in a different “direction,” i.e., counting possi-
ble combinations of attacker-controlled inputs, other inputs,
and attacker-observable outputs conditioned on sets of secret
values. In doing so, our technique accommodates attacker-
controlled inputs but does not presume knowledge of the
attacker’s strategy or the distributions of these or other inputs.
Third, some QIF frameworks work only for deterministic
procedures (e.g., [31], [32]), whereas ours accommodates
nondeterministic ones, as well.
The tractability of our design derives in part from results in
model counting (or #SAT) [33]. Previous QIF-related works
leveraging model counting either support only convex con-
straints (e.g., [31], [34]) and so therefore do not capture
all constraints of realistic applications, or use exact counts
(e.g., [27]) and so cannot scale to complex applications. In
contrast, we leverage principled sampling-based methods for
approximate model counting, which we show can be used to
expose leaks in real codebases. Our work also demonstrates a
new approach for using model counting to estimate informa-
tion leakage, again deriving from our strategy of counting pairs
of attacker-controlled inputs and attacker-observable outputs
conditioned on secret-value sets of different sizes.
More distantly related to our work are several that sim-
ply detect interference (or interference meeting certain con-
straints), versus measure it (e.g., [35]–[41]). With few ex-
ceptions (e.g., [41]), most such works are applied on an
abstract model of a program, rather than working from off-
the-shelf programs used in practice, as we do. Moreover, only
detecting interference is arguably less useful when interference
is necessitated by the program’s goals but extraneous leakage
should be otherwise measured and minimized.
515
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:39:23 UTC from IEEE Xplore.  Restrictions apply. 
III. INTERFERENCE ASSESSMENT
Our technique seeks to measure information leakage from a
procedure proc. The set VarsO is the set of attacker-observable
formal output parameters of proc; after completion, proc
outputs a value O(ovar ) for each formal output parameter
ovar ∈ VarsO . Outputs from proc that the attacker cannot
observe are not modeled. The formal input parameters to proc
are divided into three disjoint sets, namely VarsC , VarsI , and
VarsS , having the following properties.
• Each formal parameter cvar ∈ VarsC takes on a value
C(cvar ) controlled by the attacker.
• Each formal parameter ivar ∈ VarsI
takes on a value
I(ivar ) that is not controlled by the attacker.
• Each formal parameter svar ∈ VarsS takes on a value
S(svar ) that is not controlled by the attacker and moreover,
represents a secret for which we are speciﬁcally concerned
with detecting leakage via the outputs O.
So, for our purposes, we consider proc to be of the form
(By convention, J(S, S(cid:2)) = 0 if YS = YS (cid:2) = ∅.) On the
one hand, J(S, S(cid:2)) = 0 implies that YS = YS (cid:2) or, in other
words, that an attacker cannot distinguish whether the secret
S(‘secret’) is in S or S(cid:2)
. On the other hand, J(S, S(cid:2)) > 0
implies there is some (cid:4)C, O(cid:5) ∈ (YS \ YS (cid:2)) ∪ (YS (cid:2) \ YS), and so
the attacker can potentially distinguish between ‘secret’ having
a value in S and the case in which it has a value in S(cid:2)
.
Unfortunately, it is generally infeasible to compute J(S, S(cid:2))
for every disjoint pair S, S(cid:2) ⊆ S, or even when S, S(cid:2)
are
restricted to being singleton sets. We can, however, estimate
Jn =
avg
S, S (cid:2) :|S| =
(cid:2)(cid:2)S (cid:2)
(cid:2)(cid:2) = n
∧ S ∩ S (cid:2) = ∅
J(S, S(cid:2)
)
(2)
to a high level of conﬁdence by sampling disjoint sets S, S(cid:2)
of
size n (or of expected size n, as we will discuss in Sec. IV-A)
at random and computing J(S, S(cid:2)) for each.
O ← proc(C, I, S)
A. The need to vary n
with O, C, I, and S assigning values to the formal parameters
of proc as described above.
Execution of proc ensures a logical postcondition Πproc that
constrains how the variables represented in O, C, I, and S
relate to one another. We denote this predicate instantiated
with particular input and output values by Πproc(C, O, I, S),
which is either true or false.
To simplify discussion, we assume in this paper that there
is only one secret formal parameter ‘secret’ (i.e., VarsS =
{‘secret’}), though our framework naturally extends to more.
We assume that the value of ‘secret’ is chosen from a set
S, which the attacker knows. To measure the leakage about
‘secret’ from O, under the adversary’s chosen C, we consider
the set Ys of pairs (cid:4)C, O(cid:5) that are consistent with S(‘secret’):
(cid:2)
(cid:3)(cid:3)
(cid:4)C, O, I(cid:5)
Xs =
Ys = {(cid:4)C, O(cid:5) | ∃I : (cid:4)C, O, I(cid:5) ∈ Xs }
Πproc(C, O, I, S) ∧ S(‘secret’) = s
(cid:4)
In these deﬁnitions, the sets VarsC , VarsI , and VarsO (and
VarsS ) are assumed to be ﬁxed. For example, if (cid:4)C, O(cid:5) ∈
Ys and (cid:4)C(cid:2), O(cid:2)(cid:5) ∈ Ys, then while C and C(cid:2)
(respectively, O
and O(cid:2)
) can differ in the values they assign to variables (e.g.,
C(cvar ) (cid:8)= C(cid:2)(cvar ) for some cvar ), they cannot differ on
the variables to which they assign values.
The reason for considering Ys is that it is an indicator of how
s inﬂuences the possible view of the adversary, in terms of the
variables it controls (C) and the variables it observes (O). For
example, if O is independent of ‘secret’ and so leaks nothing
about the value of ‘secret’, regardless of how the adversary
chooses C, then Ys = Ys(cid:2) for any s, s(cid:2) ∈ S. To generalize from
this example, let YS =
s∈S Ys and then consider the Jaccard
distance of YS and YS (cid:2) for any two disjoint sets S, S(cid:2) ⊆ S:
(cid:3)(cid:3)(YS \ YS (cid:2)) ∪ (YS (cid:2) \ YS )
(cid:3)(cid:3)
(cid:5)
(cid:3)(cid:3)YS ∪ YS (cid:2)
(cid:3)(cid:3)
(cid:3)(cid:3)YS ∩ YS (cid:2)
(cid:3)(cid:3)YS ∪ YS (cid:2)
(cid:3)(cid:3)
(cid:3)(cid:3)
J(S, S(cid:2)
) =
= 1 −
(1)
516
i=1
(cid:5)c
Consider an idealized situation in which a procedure leaks
the equivalence class into which S(‘secret’) falls, among a
set of c “small” equivalence classes C1, . . . Cc of equal size
Ci, then the remaining elements C0 = S \
w. If C =
C form another, “large” equivalence class (w < |C0|). Let
S ⊆ {C1, . . . , Cc} denote the small equivalence classes of
C sm
S ⊆ {C0} indicate whether
which S contains elements and C lg
S = {C0})
S contains representatives of C0 (in which case C lg
S = {}). For simplicity, we assume
or not (in which case C lg
below that |YCi
| is the same for each i ∈ {0, 1, . . . , c}.
For the rest of this discussion, we treat the selection of s ∈ S
as the selection, with replacement, of Ci (cid:13) s.1
1 −
1 − w
|S|
,2 and so