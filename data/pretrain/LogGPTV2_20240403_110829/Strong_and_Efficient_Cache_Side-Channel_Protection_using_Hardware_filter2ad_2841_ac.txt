e
P
P
100
80
60
40
20
0
0
200
Flush-Delay
400
600
800
10000
100
80
60
40
20
0
1000
800
600
400
200
Reload-Delay
Figure 4: Cache hits observed by a Flush+Reload at-
tacker with the ability to overlap the attack with differ-
ent segments of the victim’s transaction. Cache hits can
be observed both in the region where the victim tries to
prepare its transactional memory, as well as in a small
window around a secret access. The Z axis represents
the success rate of the attacker observing a cache hit.
sults for all forms of preloading (reading, writing, exe-
cuting) and all forms of secret accesses (reading, writing,
executing).
To exploit the leakage we found, the attacker has to
be able to determine whether the CPU reloaded a secret-
dependent memory location. This is only possible if the
attacker shares the memory location with the victim, i.e.,
only in local attacks but not in other scenarios. Further-
more, it is necessary to align execution between attacker
and victim to trigger the eviction in exactly the right cy-
cle range in the transaction. While these properties might
be met in a Flush+Reload attack with fast eviction using
clflush and shared memory, it is rather unlikely that
an attack is possible using Prime+Probe, due to the low
frequency of the attack [22] and the cache replacement
policy. Thus, we conclude that requirements R3 and R4
are likely fulﬁlled in all scenarios where the attacker can
only perform Prime+Probe, but not Flush+Reload, i.e.,
cloud and SGX scenarios. Furthermore, requirements R3
and R4 are likely to be fulﬁlled in scenarios where an at-
tacker can perform Flush+Reload, but not align with a
victim on a cycle base nor measure the exact execution
time of a TSX transaction, i.e., the local scenario.
5.2 Memory Preloading
As discussed, exclusively using the write set for preload-
ing has the beneﬁt that sensitive data is guaranteed to
stay within the small L1 cache, which is the most secure
option. To extend the working set beyond L1, sensitive
read-only data can also be kept in the LLC as described
in Section 5.1.1. However, when doing so, special care
has to be taken. For example, na¨ıvely preloading a large
(> 32 KB) sequential read set after the write set leads
to assured abortion during preloading, as some write set
cache-lines are inevitably evicted from L1. Reversing
the preloading order, i.e., read set before write set, partly
alleviates this problem, but, depending on the concrete
read set access patterns, one is still likely to suffer from
aborts during execution caused by read/write set conﬂicts
in the L1 cache.
In the worst case, such self-eviction
aborts may leak information.
To prevent such conﬂicts, in Cloak, we reserve cer-
tain cache sets in L1 entirely for the write set. This is
possible as the L1 cache-set index only depends on the
virtual address, which is known at runtime. For exam-
ple, reserving the L1 cache sets with indexes 0 and 1
gives a conﬂict-free write set of size 2· 8· 64B = 1KB.
For this allocation, it needs to be ensured that the same
64 B cache lines of any 4 KB page are not part of the
read set (see Figure 5 for an illustration). Conversely, the
write set is placed in the same 64 B cache lines in up to
eight different 4 KB pages. (Recall that an L1 cache set
comprises eight ways.) Each reserved L1 cache set thus
blocks 1/64th of the entire virtual memory from being
used in the read set.
While this allocation strategy plays out nicely in
theory, we observed that apparently the CPU’s data
prefetcher [30] often optimistically pulled-in unwanted
cache lines that were conﬂicting with our write set. This
can be mitigated by ensuring that sequentially accessed
read cache lines are separated by a page boundary from
write cache lines and by adding “safety margins” be-
tween read and write cache lines on the same page.
In general, we observed beneﬁts from performing
preloading similar to recent Prime+Probe attacks [22,
45], where a target address is accessed multiple times
and interleaved with accesses to other addresses. Fur-
ther, we observed that periodic “refreshing” of the write
set, e.g., using the prefetchw instruction, reduced the
chances of write set evictions in longer transactions.
Using right the memory preloading strategy is crucial
for the effectiveness of Cloak when instantiated on top
of TSX. In the following, we describe preloading tech-
niques for various scenarios. The different behavior for
read-only data, writable data, and code, makes it neces-
sary to preload these memory types differently.
5.2.2 Code Preloading
As described in Section 5.1.2, we preload code into the
read set and optionally into the L1 instruction cache. To
preload it into the read set, we use the same approach as
for data. However, to preload the code into the L1 in-
struction cache we cannot simply execute the function,
USENIX Association
26th USENIX Security Symposium    223
the target array, the working set for each individual trans-
action is reduced and chances for transactional aborts de-
crease. Ideally, the splitting would be done in an auto-
mated manner by a compiler. In a context similar to ours
though not directly applicable to Cloak, Shih et al. [59]
report on an extension of the Clang compiler that auto-
matically splits transactions into smaller units with TSX-
compatible working sets. Their approach is discussed in
more detail in Section 9.
5.3 Toolset
We implemented the read-set preloading strategy from
Section 5.2.1 in a small C++ container template library.
The library provides generic read-only and writable ar-
rays, which are allocated in “read” or “write” cache lines
respectively. The programmer is responsible for arrang-
ing data in the specialized containers before invoking a
Cloak-protected function. Further, the programmer de-
cides which containers to preload. Most local variables
and input and output data should reside in the containers.
Further, all sub-function calls should be inlined, because
each call instruction performs an implicit write of a re-
turn address. Avoiding this is important for large read
sets, as even a single unexpected cache line in the write
set can greatly increase the chances for aborts.
We also extended the Microsoft C++ compiler ver-
sion 19.00. For programmer-annotated functions on
Windows, the compiler adds code for starting and end-
ing transactions, ensures that all code cache lines are
preloaded (via read or execution according to Sec-
tion 5.2.2) and, to not pollute the write set, refrains
from unnecessarily spilling registers onto the stack af-
ter preloading. Both library and compiler are used in the
SGX experiments in Section 7.1.
6 Retroﬁtting Leaky Algorithms
To evaluate Cloak, we apply it to existing weak im-
plementations of different algorithms. We demonstrate
that in all cases, in the local setting (Flush+Reload) as
well as the cloud setting (Prime+Probe), Cloak is a prac-
tical countermeasure to prevent state-of-the-art attacks.
All experiments in this section were performed on a
mostly idle system equipped with a Intel i7-6700K CPU
with 16 GB DDR4 RAM, running a default-conﬁgured
Ubuntu Linux 16.10. The applications were run as regu-
lar user programs, not pinned to CPU cores, but sharing
CPU cores with other threads in the system.
6.1 OpenSSL AES T-Tables
As a ﬁrst application of Cloak, we use the AES T-table
implementation of OpenSSL which is known to be sus-
Figure 5: Allocation of read and write sets in memory to
avoid conﬂicts in the L1 data cache
retq
=
0f 1f c3 41 57 41 56 45 31 c9 41 55 41 54 ba 07 00 00 00
0f 1f c3
push mov
0xc
0xe
push
0x5
push
0xa
xor
0x7
nop
0x0
push
0x3
55
push
0x13
53
push
0x14
31 ff
xor
0x15
41 b8 ff ff ff ff b9 22 00 00 00 be 08 00 00 40
mov mov mov
0x17
0x22
0x1d
48 83 ec 18
e8 a3 f4 ff ff
48 89 c2
49 89 c7
48 c1 e2 3c
48 c1 ea 3f
48 85 d2
sub
0x27
callq mov mov
0x2b
0x33
0x30
shl
0x36
shr
0x3a
test
0x3e
Figure 6: Cache lines are augmented with a multi-byte
nop instruction. The nop contains a byte c3 which is the
opcode of retq. By jumping directly to the retq byte,
we preload each cache line into the L1 instruction cache.
as this would have unwanted side effects. Instead, we in-
sert a multi-byte nop instruction into every cache line, as
shown in Figure 6. This nop instruction does not change
the behavior of the code during actual function execution
and only has a negligible effect on execution time. How-
ever, the multi-byte nop instruction allows us to incorpo-
rate a byte c3 which is the opcode of retq. Cloak jumps
to this return instruction, loading the cache line into the
instruction L1 cache but not executing the actual func-
tion. In the preloading phase, we perform a call to each
such retq instruction in order to load the correspond-
ing cache lines into the L1 instruction cache. The retq
instruction immediately returns to the preloading func-
tion. Instead of retq instructions, equivalent jmp reg
instructions can be inserted to avoid touching the stack.
5.2.3 Splitting Transactions
In case a sensitive function has greater capacity require-
ments than those provided by TSX, the function needs
to be split into a series of smaller transactional units.
To prevent leakage, the control ﬂow between these units
and their respective working sets needs to be input-
independent. For example, consider a function f() that
iterates over a ﬁxed-size array, e.g., in order to update
certain elements. By reducing the number of loop itera-
tions in f() and invoking it separately on ﬁxed parts of
224    26th USENIX Security Symposium
USENIX Association
……4KB memory pagesCL 0CL 1CL 2CL 63Cache set 1Cache set 2Cache set 63L1 data cache (32KB)•Write setin 2 out of 64 cache sets:2 x 8 x 64 bytes = 1024 bytes•Read setin rest of memory:Constrained by LLC …CL 0CL 1CL 2CL 63…Way 7Way 0Way 1Cache set 0…Way 7Way 0Way 1…Way 7Way 0Way 1…Way 7Way 0Way 1…Plaintext byte
40
80
c0 f8
Plaintext byte
40
80
c0 f8
00
0
4
e
n
i
l
8
e
h
c
a
C
12
15
00
0
4
e
n
i
l
8
e
h
c
a
C
12
15
Figure 7: Color matrix showing cache hits on an AES
T-table. Darker means more cache hits. Measurement
performed over roughly 2 billion encryptions. Prime+
Probe depicted on the left, Flush+Reload on the right.
Plaintext byte
40
80
c0 f8
Plaintext byte
40
80
c0 f8
00
0
4
e
n
i
l
8
e
h
c
a
C
12
15
00
0
4
e
n
i
l
8
e
h
c
a
C
12
15
Figure 8: Color matrix showing cache hits on an AES T-
table. The implementation is protected by Cloak. Darker
means more cache hits. Measurement performed over
roughly 3 billion transactions (500 million encryptions)
for Prime+Probe (left) and 4.9 billion transactions (1.5
million encryptions) for Flush+Reload (right). The side-
channel leakage is not visible in both cases.