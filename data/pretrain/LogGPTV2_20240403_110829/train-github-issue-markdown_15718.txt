I recently upgraded my Airflow version from 1.10.10 to 2.0.0, and noticed the
scheduler are failing and exiting after upgrade. After checking the log, it's
suggest the duplicated entry for records in `dag_run` table. It tries to
insert dag runs already executed before the upgrade.  
After some digging, I found it related to how the scheduler calculate the next
execution_date: it picks the last dag_run with `run_type` of scheduled,
however the new `DagRunType.SCHEDULED` is not the same as "scheduled" as
previously was. as `DagRunType` is an enum type, `DagRunType.SCHEDULED` is
actually converted to "DagRunType.SCHEDULED" not "scheduled".  
It looks like not an intended design but a mistake. change of
`DagRunType.SCHEDULED` to `DagRunType.SCHEDULED.value` will simply solve this
issue.
airflow/airflow/jobs/scheduler_job.py
Lines 1559 to 1568 in ab5f770
|  dag.create_dagrun(  
---|---  
|  run_type=DagRunType.SCHEDULED,  
|  execution_date=dag_model.next_dagrun,  
|  start_date=timezone.utcnow(),  
|  state=State.RUNNING,  
|  external_trigger=False,  
|  session=session,  
|  dag_hash=dag_hash,  
|  creating_job_id=self.id,  
|  )