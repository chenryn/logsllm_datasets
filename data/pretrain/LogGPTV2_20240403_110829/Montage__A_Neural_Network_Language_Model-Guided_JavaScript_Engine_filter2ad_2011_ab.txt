corresponds to Line 3. The bottom of the ﬁgure presents
fragments from this subtree.
We also divided each PoC that triggers a CVE into frag-
ments and then counted how many fragments existed in the
regression test suites. Figure 3 depicts the number of PoC ﬁles
whose common fragment percentage is over each percentage
threshold. We found that all the fragments (100%) from 10
PoC exploits already existed in the regression test ﬁles. More
than 96% of the fragments in the 42 PoC exploits and 90% of
the fragments in the 63 PoC exploits existed in the regression
test as well. On average, 95.9% of the fragments from the
PoC exploits were found in the regression test ﬁles.
Observation 2. More than 95% of the fragments syntac-
tically overlap between the regression tests and the PoC
exploits.
Both observations imply that it is likely to trigger a new
security vulnerability by assembling code fragments from
existing regression test suites, which is the primary motivation
for this study, as we describe in §4.
4 Overview
We present Montage, an NNLM-driven fuzzer, which auto-
matically ﬁnds bugs in JS engines. Recall that the overall
design of Montage is driven by two observations: (1) secu-
rity bugs often arise from ﬁles that were previously patched
for different causes, and (2) the JS test code that triggers
Figure 3: The number of all PoC ﬁles whose common frag-
ment percentages are greater than varying percentages.
security-related bugs heavily reuses AST fragments found in
the existing regression test sets.
We propose a novel fuzzing technique that captures these
observations. We train an NNLM to capture the syntactic and
semantic relationships among fragments from the regression
test sets. When generating a new JS test, Montage mutates the
AST of a given JS regression test. It replaces a subtree of the
AST with a new subtree, using the trained NNLM. Thus, each
generated test stems from a given regression test that checks
previously patched or buggy logic, thereby, capturing the ﬁrst
observation. At the same time, it invokes functionalities in
different execution contexts by assembling existing fragments
under the guidance of the NNLM, which addresses the second
observation.
Figure 4 shows the overall workﬂow of Montage. Phase
I prepares the training instances from given regression test
suites. Each training instance is a sequence of AST unit sub-
trees, called fragments. Phase II trains an NNLM that learns
compositional relationships among fragments. These two
phases are one-time setup procedures. Phase III generates
JS tests by leveraging the trained model.
Figure 4: Overview of Montage.
Phase I begins with a given training set of JS regression
test ﬁles. It parses each JS ﬁle into an AST and normalizes
identiﬁers that appeared in the AST to deduplicate function
and variable names. Figure 1 shows a normalized JS ﬁle
example. Each appeared variable name is changed into a
common name, such as v0 or v1. From a normalized AST tree,
Phase I then extracts multiple unit subtrees, each of which
is called a fragment. For each node in the AST, Montage
recursively slices a unit subtree of depth one. Each of the
sliced subtrees becomes a fragment of the AST. It then emits
the sequence of these fragments, produced by the pre-order
traversal of their root nodes in the normalized AST tree.
2616    29th USENIX Security Symposium
USENIX Association
IdentiﬁerMemberExprrightoperatorobjectv0name=AssignExprpropertyv1Identiﬁerleftnamenamev1Identiﬁerrightoperator+BinaryExprleftvalue5Literalacbdefgcbaedbdefcgfg,,,,,,67666358494226100204060708090100Common Fragments Percentage (%)# of PoC FilesJS’JS,,,Phase IBuilding training dataPhase IITraining LSTM modelPhase IIIGenerating JS testsPhase II trains the NNLM given a set of fragment se-
quences. From a given fragment sequence of an arbitrary
length, we design the NNLM to suggest the next fragments,
which are likely to appear after this fragment sequence. This
framing is a key contribution of this paper. Note that it is not
straightforward to model the inherent structural relationships
of an AST in such a way that a language model can learn.
By leveraging the fragments encapsulating the structural re-
lationships of ASTs, we encode a given AST into fragment
sequences. Considering that a vast volume of natural language
NNLMs have been trained upon word sequences, this frag-
ment sequencing eases the application of existing prevailing
NNLMs for generating JS tests.
Here, the objective is to train the NNLM to learn com-
positional relationships among fragments so that the JS test
code generated from the trained model reﬂects the syntax and
semantics of the given training set, which is the regression
testing set of JS engines.
Phase III generates a new JS test by leveraging the trained
model and the AST of a regression test. Given a set of ASTs
from regression test suites, it randomly picks a seed AST.
Then, it randomly selects a subtree for Montage to replace.
When generating a new subtree, Montage considers a con-
text, the sequence of all fragments that precedes the selected
subtree. Montage iteratively appends fragments from the root
node of the selected subtree while considering its context.
Because the current AST is assembled from fragments, it
is expected that some variables and function identiﬁers in the
AST nodes are used without proper declarations. Montage,
thus, resolves possible reference errors by renaming them
with the declared identiﬁers. Finally, Montage checks the
generated test and reports a bug if the code crashes the target
JS engine.
Other model guided approaches. Previous studies pre-
sented language models, which can predict the lexical code
tokens in source code. Such framing of language models
has been vastly studied while addressing code completion
problems [40, 53]. However, the generation of an executable
test is more challenging than the code completion problem
that predicts a limited number of semantically correct lex-
ical tokens. To our knowledge, the PDF fuzzer proposed
by Singh et al. [16] is the ﬁrst system that employs a
character-level RNN model to generate PDF tests. We eval-
uated whether our fragment-based approach performs better
than the character-level RNN model approach in ﬁnding JS
engine bugs (see §7.5).
5 Design
The design goal of Montage is to generate JS test inputs
that can trigger security vulnerabilities in JS engines, which
(1) reﬂect the syntactic and semantic patterns of a given JS
training set, and (2) trigger no reference errors.
It is a technical challenge to frame the problem of teach-
ing a language model the semantic and syntactic patterns of
training code. We address this challenge by abstracting the
hierarchical structure by AST subtrees, which we refer to as
fragments. We then enable the language model to learn the
compositional relationships between fragments.
We propose a novel code generation algorithm that lever-
ages a trained language model. We harness an existing JS
code that is already designed to trigger JS engine defects.
Montage alters this existing JS code by replacing one of its
AST subtrees with a new subtree that the trained language
model generates. Thus, Montage is capable of generating a
new JS test, semantically similar to the regression test case
that triggers a previously reported bug. We expect that this
new JS test triggers a new bug in a different execution context.
5.1 Phase I: Building Training Data of Frag-
ment Sequences
Phase I prepares training instances using a given training set.
It conducts parsing and fragmentation.
5.1.1 Parsing and Normalizing
Phase I builds an AST by parsing each JS ﬁle in a training
set and normalizes the parsed AST. Because the training set
includes a variety of JS ﬁles from various developers, iden-
tiﬁer naming practices are not necessarily consistent. Thus,
it is natural that the training ﬁles have diverse variable and
function names across different JS ﬁles. Consider two JS ﬁles
that contain a JS statement var b = a + 1 and var c =
d + 1, respectively. Both have the same AST structure and
semantics, but different identiﬁers.
This pattern increases the size of unnecessary vocabulary
for a language model to learn, rendering the model evaluation
expensive as it requires more training instances. To have
concise ASTs with consistent identiﬁer names, we rename all
the variable and function identiﬁers in the ASTs.
Speciﬁcally, for each declared variable identiﬁer, we as-
sign a sequential number in the order of their appearance in
a given AST. We then replace each variable name with a
new name that combines a common preﬁx and its sequential
number, such as v0 and v1. We also apply the same proce-
dure to function identiﬁers, e.g., f0 and f1. We deliberately
exclude language-speciﬁc built-in functions and engine ob-
jects from the normalization step as normalizing them affects
the semantics of the original AST. For an eval function that
dynamically evaluates a given string as the JS code, we ﬁrst
extract the argument string of the eval function and strip it
out as the JS code when the argument is a constant string.
Subsequently, we normalize identiﬁers in the JS code stripped
out from the eval argument.
As our training set is derived from regression tests of JS
engines, JS ﬁles in the set make heavy use of predeﬁned
USENIX Association
29th USENIX Security Symposium    2617
functions for testing purposes. Therefore, we manually identi-
ﬁed such vendor-provided testing functions and ignore them
during the normalization step. That is, we treated common
testing functions provided by each JS engine vendor as a
built-in function and excluded them from normalization.
5.1.2 Fragmentation
Montage slices each normalized AST into a set of subtrees
while ensuring that the depth of each subtree is one. We call
such a unit subtree as a fragment.
We represent an AST T with a triple (N,E,n0), where N
is the set of nodes in T , E is the set of edges in T , and n0 is
the root node of T . We denote the immediate children of a
given AST node ni by C (ni), where ni is a node in N. Then,
we deﬁne a subtree of T where the root node of the subtree is
ni. When there is such a subtree with a depth of one, we call
it a fragment. We now formally deﬁne it as follows.
Deﬁnition 1 (Fragment). A fragment of T = (N,E,n0) is a
subtree Ti = (Ni,Ei,ni), where
• ni ∈ N s.t. C (ni) (cid:54)= /0.
• Ni = {ni}(cid:83)C(ni).
• Ei = {(ni,n(cid:48)) | n(cid:48) = C(ni)}.
Intuitively, a fragment whose root node is ni contains its
children and their tree edges. Note that each fragment in-
herently captures an exercised production rule of the JS lan-
guage grammar employed to parse the AST. We also de-
ﬁne the type of a fragment as the non-terminal symbol of
its root node ni. For instance, the ﬁrst fragment at the bot-
tom side of Figure 2 corresponds to the assignment expres-
sion statement in Line 3 of Figure 1. The fragment possesses
four nodes whose root node is the non-terminal symbol of
an AssignmentExpression, which becomes the type of this
fragment.
Montage then generates a sequence of fragments by per-
forming the pre-order traversal on the AST. When visiting
each node in the AST, it emits the fragment whose root is the
visited node. The purpose of the pre-order sequencing is to
sort fragments by the order of their appearance in the original
AST. For example, the bottom side of Figure 2 shows the
sequence of seven fragments obtained from the AST subtree
in the ﬁgure.
We model the compositional relationships between frag-
ments as a pre-order sequencing of fragments so that an
NNLM can predict the next fragment to use based on the
fragments appearing syntactically ahead. In summary, Phase
I outputs the list of fragment sequences from the training set
of normalized ASTs.
Figure 5: Architecture of Montage LSTM model. ⊕ in the
ﬁgure denotes a concatenation.
5.2 Phase II: Training an LSTM Model
All distinct fragments become our vocabulary for the NNLM
to be trained. Before training, we label the fragments whose
frequency is less than ﬁve in the training set as out-of-
vocabulary (OoV). This is a standard procedure for building
a language model to prune insigniﬁcant words [22, 40, 43].
Each fragment sequence represents a JS ﬁle in the training
set. This sequence becomes a training instance. We build
a statistical language model from training instances so that
the model can predict the next fragment based on all of its
preceding fragments, which is considered as a context. This
way, the model considers each fragment as a lexicon, and
thereby, suggests the next probable fragments based on the
current context.
Training objectives. The overall objective is to model a
function f : X → Y such that y ∈ Y is a probability distribu-
tion for the next fragment f rt+1, given a fragment sequence
x = [ f r0, f r1, ..., f rt ] ∈ X, where f ri denotes each fragment
at time step i. Given x, the model is trained to (1) predict the
correct next fragment with the largest probability output and
(2) prioritize fragments that share the same type with the true
fragment over other types of fragments. Note that this training
objective accords with our code generation algorithm in that
Montage randomly selects the next fragment of a given type
from the top k suggestions (see §5.3).
LSTM. To implement such a statistical language model, we
take advantage of the LSTM model [23]. Figure 5 depicts the
architecture of Montage LSTM model. Our model consists
of one projection, one LSTM, and one output layers. The
projection layer is an embedding layer for the vocabulary
where each fragment has a dimension size of 32. When f rt
is passed into the model, it is converted into a vector, called
embedding, after passing the projection layer.
Then, the embedding vector becomes one of the inputs for
the LSTM layer with a hidden state size of 32. At each time
step, the LSTM cell takes three inputs: (1) a hidden state ht−1
and (2) a cell state ct−1 from the previous time step; and (3)
the embedding of a new input fragment. This architecture
enables the model to predict the next fragment based on the
cumulative history of preceding fragments. In other words,
the LSTM model is not limited to considering a ﬁxed number
of preceding fragments, which is an advantage of using an
RNN model.
The output of the LSTM layer ht is then concatenated with
2618    29th USENIX Security Symposium
USENIX Association
LSTMhtfr1LSTMh1LSTMfr0h0…Tt+1f(x)frtLSTMPt+1two other vectors: (1) the type embedding Tt+1 of the next
fragment, and (2) the fragment embedding Pt+1 of the parent
fragment of the next fragment in its AST. The concatenated
vector is now fed into the ﬁnal output layer and it outputs a
vector f (x) of vocabulary size to predict the next fragment.
Loss function. To address our training objectives, we deﬁned
a new loss function that rewards the model to locate type-
relevant fragments in its top suggestions. The LSTM model
is trained to minimize the following empirical loss over the
training set (x,y) ∈ D.
g(x) = softmax( f (x))
LD( f ) =
1
|D| ∑
(x,y)∈D
l1(g(x),y) + l2(g(x),y)
(1)
As shown in Equation 1, the loss function has two terms: l1
and l2. Note that these terms are designed to achieve our two
training objectives, respectively.
l1(g(x),y) = − N
∑
i=1
l2(g(x),y) = ∑
i∈top(n)
yi logg(x)i
g(x)i − ∑
j∈type(y)
(2)
g(x) j,
Equation 2 describes each term in detail. In the equation, n
denotes the number of fragments whose types are same as that
of the true fragment. top(n) and type(y) indicate functions
that return the indices of top n fragments and fragments of
the true type, respectively.
l1 is a cross entropy loss function, which has been used for
common natural language models [29, 34]. l2 is employed for
rewarding the model to prioritize fragments that have the same
type as the true fragment. We formally deﬁne l2 as a type
error. It is a gap between two values: the sum of the model
output probabilities corresponding to (1) top n fragments and
(2) fragments of the true type.
By reducing the sum of l1 and l2 while training, the model
achieves our training objectives. Intuitively, the LSTM model
is trained not only to predict the correct fragment for a given
context, but also to locate fragments whose types are same as
the correct fragment in its top suggestions.
The fundamental difference of Montage from previous ap-
proaches that use probabilistic language models [41,56] lies in
the use of fragments. To generate JS code, TreeFuzz [41] and
SkyFire [56] use a PCFG and PCSG to choose the next AST
production rule from a given AST node, respectively. SkyFire
deﬁnes its context to be sibling and parent nodes from a given
AST. It picks an AST production rule that is less frequent in
the training set. In contrast, Montage selects a fragment based
on the list of fragments, not AST nodes. Therefore, Montage
is capable of capturing the global composition relationships
among code fragments to select the next code fragment. Fur-
thermore, Montage preserves the semantics in the training