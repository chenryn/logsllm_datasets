title:28 Blinks Later: Tackling Practical Challenges of Eye Movement Biometrics
author:Simon Eberz and
Giulio Lovisotto and
Kasper Bonne Rasmussen and
Vincent Lenders and
Ivan Martinovic
28 Blinks Later: Tackling Practical Challenges of
Eye Movement Biometrics
Simon Eberz
PI:EMAIL
University of Oxford
Giulio Lovisotto
PI:EMAIL
University of Oxford
Kasper B. Rasmussen
PI:EMAIL
University of Oxford
Vincent Lenders
PI:EMAIL
armasuisse
Ivan Martinovic
PI:EMAIL
University of Oxford
ABSTRACT
In this work we address three overlooked practical challenges of
continuous authentication systems based on eye movement biomet-
rics: (i) changes in lighting conditions, (ii) task dependent features
and the (iii) need for an accurate calibration phase. We collect eye
movement data from 22 participants. To measure the effect of the
three challenges, we collect data while varying the experimental
conditions: users perform four different tasks, lighting conditions
change over the course of the session and we collect data related to
both accurate (user-specific) and inaccurate (generic) calibrations.
To address changing lighting conditions, we identify the two
main sources of light, i.e., screen brightness and ambient light,
and we propose a pupil diameter correction mechanism based on
these. We find that such mechanism can accurately adjust for the
pupil shrinking or expanding in relation to the varying amount
of light reaching the eye. To account for inaccurate calibrations,
we augment the previously known feature set with new features
based on binocular tracking, where the left and the right eye are
tracked separately. We show that these features can be extremely
distinctive even when using a generic calibration. We further apply
a cross-task mapping function based on population data which
systematically accounts for the dependency of features to tasks
(e.g., reading a text and browsing a website lead to different eye
movement dynamics).
Using these enhancements, even while relaxing assumptions
about the experimental conditions, we show that our system achieves
significantly lower error rates compared to previous work. For intra-
task authentication, without user-specific calibration and in variable
screen brightness and ambient lighting, we achieve an equal error
rate of 3.93% with only two minutes of training data. For the same
setup but with constant screen brightness (e.g., as for a reading
task) we can achieve equal error rates as low as of 1.88%.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3354233
CCS CONCEPTS
• Security and privacy → Biometrics;
KEYWORDS
authentication, biometrics, eye movements
ACM Reference Format:
Simon Eberz, Giulio Lovisotto, Kasper B. Rasmussen, Vincent Lenders,
and Ivan Martinovic. 2019. 28 Blinks Later: Tackling Practical Challenges
of Eye Movement Biometrics. In 2019 ACM SIGSAC Conference on Com-
puter and Communications Security (CCS ’19), November 11–15, 2019, London,
United Kingdom. ACM, New York, NY, USA, 13 pages. https://doi.org/10.
1145/3319535.3354233
1 INTRODUCTION
Authentication based on various biometric modalities has become
increasingly popular in recent years. This surge has been mostly
driven by the integration of biometric sensors in smartphones,
with fingerprint scanning and face recognition being nowadays
available in most devices. With the increasing use of deep models,
both fingerprint and face recognition can now offer low error rates
and convenient recognition times.
While such physiological biometrics offer accurate and fast recog-
nition, they are easily observable: both fingerprints and faces can
be easily obtained and forged by adversaries. While there have
been extensive efforts to detect spoofed samples (e.g., fake fingers),
this often unfolds into an arms race with attackers improving their
artifact to circumvent liveness detection. In comparison, behav-
ioral biometrics rely on distinctive behaviour rather than physical
characteristics. As such, behavioral traits are inherently less observ-
able compared to physiological ones. Different behaviour-based
modalities have been proposed by the academic community, in-
cluding keystroke dynamics [19], touchscreen input dynamics [16],
gait [5, 24], mouse movements [38], electrocardiography (ECG) [14]
and mobile device pickups (MDP) [15]. These systems may com-
bine both behavioural and physiological components, e.g., touch
dynamics make use of touch pressure, which partially depends on
the size of the user’s finger.
Eye movements have recently gained interest as a behavioural
biometric with a strong physiological component [3, 11, 12, 17,
20, 21, 31, 32, 35]. With advances in technology, video-based eye
trackers are increasingly cheap and integrated in consumer devices.
Eye movement biometrics (not to be confused with iris recognition)
combine the steadiness of gaze, rapid short-term movements, the
shape and duration of visual fixations and the (changes in) size
Session 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1187of the person’s pupil. While eye movements has been shown to
achieve relatively low error rates, there are three major practical
challenges of using eye movements in realistic settings: (i) the need
for a precise calibration, (ii) the eye movements’ task-dependency
and (iii) the pupil light-sensitivity.
A precise calibration is required in order to obtain good eye track-
ing accuracy and subsequently accurate eye movements features.
While calibration itself may be relatively quick (<10 seconds), it is
highly sensitive to changes in the user’s interaction (e.g., posture,
distance between eyes and screen, head movements), leading to
poor stability over time. Additionally, previous work has shown
that eye movements are highly task-dependant, and that authen-
tication across different tasks (i.e., enrolling the user on one task
and authenticating on another) leads to significant increases in
error rates. Finally, given the importance of pupil-based features,
changes in pupil diameter caused by changing lighting environment
(e.g., ambient light, screen brightness) compromise the stability and
accuracy of the recognition.
In this paper, we propose new methods to address the three
challenges of using eye movements biometrics in realistic settings
and combine them to develop an authentication system. We collect
data from 22 participants recruited from the general public, across
two different sessions. For each partipant, we collect eye movement
data across different tasks, different lighting conditions (including
both screen brightness and ambient light) and different calibrations
accuracies. We augment the eye movements feature set used in
previous work to include binocular features based on the difference
of tracking between left and right eye. We show that the full set
of features can successfully discriminate users without requiring
user-specific calibrations. We propose a pupil diameter correction
mechanism that accounts for the screen brightness and level of
ambient light in order to refine the pupil diameter measurement
coming from the sensor. We further show that using a population
based cross-task mapping function, we can automatically adjust for
the task-dependent changes in feature distributions, improving the
accuracy of authentication across tasks.
The contributions of this paper can be summarized as follows:
• We develop a new eye movements recognition pipeline which
accounts for imprecise calibrations, changes in lighting en-
vironment and cross-task authentication.
• We test the system on 22 participants recruited from the
general public, across two separate sessions. We test a set
of different lighting conditions (i.e., screen brightness and
ambient light), tasks and calibration quality.
• We make our dataset and the code used for the experiments
available online1.
The remainder of the paper is organised as follows: Section 2
outlines background and related work on eye movement biometrics.
Section 3 and 4 describe our experimental design and methods. In
Section 5 we present our results. We discuss the security of our
approach in Section 6 and conclude the paper in Section 7.
2 RELATED WORK
In this section, we provide an overview of the medical foundation
of eye movements, eye tracking technology and eye movement
authentication systems.
2.1 Eye movement background
The human eye moves within six degrees of freedom with six mus-
cles responsible for the movement of the eyeball. The main types of
eye movements can be categorized into saccades and fixations, while
the neural signs controlling these movements can be categorized as
voluntary, involuntary and reflexive. Saccades are rapid stepwise
movements of both eyes in the same direction that typically last
10-100 ms, depending on the distance covered [8] and are used to
shift the gaze to another location. In contrast to saccades, fixations
are relatively focused, low-velocity eye movements with a typical
duration of 100-400 ms and are used to stabilize the retina over a
stationary object of interest. Yet, eyes are never perfectly still and
exhibit involuntary movements even during visual fixations. The
main reason for such movements is to counteract retinal fatigue
and to prevent visual fading. One type of such movements are mi-
crosaccades, characterized by high velocity and acceleration often
away from the fixation centre [29].
Besides the eye movements, the pupil diameter is also an distinc-
tive feature which can be included in the analysis of eye behaviour.
The range for this feature in an individual is largely determined
by eye physiology, gender and ethnicity and is relatively constant
during adulthood [28]. Nevertheless, multiple causes that affect the
pupil diameter have been found, including memory and cognitive
workload [25], lighting conditions [36] and drug consumption [23].
The pupil size also shrinks as a person ages, an effect which is
particularly pronounced in low lighting conditions [37].
2.2 Eye tracking technology
Eye tracking is the process of tracking the position and movements
of a person’s eye. When these movements are calibrated with re-
gard to an external screen (i.e., the system determines gaze points),
the process is called gaze tracking. There are two main approaches
to eye tracking: electrooculography (EOG) and video-based track-
ing. EOG is a tracking technique that measures electrical potential
between two adhesive electrodes which are placed around the eyes.
This approach is popular in the medical field, as it enables accurate
recordings of eye movements even while the eyes are closed (e.g.,
during blinks or while the subject is sleeping). However, this is
a rather invasive technique which is unlikely to be acceptable to
users outside medical and research trials.
On the other hand, video-based eye tracking involves the record-
ing of the user’s eyes through cameras with high frame rates. While
tracking is possible with conventional RGB cameras, accuracy is
usually enhanced by using an infrared camera and an additional
infrared light source. The users retinas reflect the light source allow-
ing for a more accurate tracking of the eye’s positions. As infrared
light is invisible to the human eye, the tracking itself is completely
non-invasive and not noticeable to the user. In order to determine
the user’s gaze point on a screen, the system has to be calibrated.
The calibration process requires the user to look at a sequence of
1https://simonizor.github.io/28blinkslater
Session 6A: Biometrics SecurityCCS ’19, November 11–15, 2019, London, United Kingdom1188Cross-task Calibration optional
Pupil correction EER [%]
Feature types
Fixation density map
Stimulus
Movie trailer
Human faces Distribution of area of interest
Human faces Graph matching
Human faces
Moving dot
Study Mode
Login
[32]
Login
[17]
[31]
Login
Login
[3]
Login
[35]
Continuous Various tasks
[12]
[11]
Continuous Moving dot
Continuous Reading
[20]
[21]
Continuous Reading
Table 1: Summary of biometric eye movement authentication. Cross-task indicates whether the study measures cross-task
authentication accuracy. Pupil correction indicates whether the study corrects for the effect of light on the pupil diameter.
Scan paths
Fixation and saccade shape
Fixation and pupil features
Fixation and pupil features
Scan paths
Fixation and saccade shape
14
36.1
30
25
6.3
0.04 - 4.9
3.98
23
16.5
✗
✗
✗
✗
✗
✓
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✗
✓
✗
✗
✗
points shown on the screen and is sensitive to posture, including
the distance to the screen. Video-based eye tracking is increas-
ingly available in consumer devices, laptops in particular, but even
integrated in virtual or agumented reality headsets.
2.3 Eye movement authentication
The body of work on eye movement biometrics can be divided
into three parts: Eye movements as an input channel, continuous