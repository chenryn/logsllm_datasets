› Usability versus Security. We consider the FRR of a
biometric system as a measure of the system’s usability,
and its FAR as a measure of its security. With a higher
false reject rate, the veriﬁcation system deduces more fre-
quently (but incorrectly) that the system is under attack and
reacts by freezing or delaying the currently logged-in user’s
processes. This would unnecessarily delay the user’s time-
to-completion of ordinary tasks and may make the system
frustrating to use. There is evidence that system response
time is correlated to user productivity [7].
False rejects can be reduced by adjusting the decision
threshold T of a biometric Veriﬁer, but with a concomitant
increase in the false accept rate. This could be disastrous
from a security perspective. A usable system must balance
its FAR against its FRR. Using at least one biometric with
high accuracy can sharply distinguish a valid user from an
imposter and can strike a good balance between the two
choices. Higher accuracy can also be achieved at the cost
of more samples but that increases the computational over-
head, which impacts usability.
ﬁ Choice of biometrics. For our
design objective we need biomet-
rics that are both passive and ac-
curate. Passive biometrics do not
require active participation by the
user, (as opposed to active ones,
such as those that use speech) and
therefore do not intrude into the
normal activity of the user by re-
quiring them to periodically per-
form biometric related tasks that
are not part of their normal activ-
ity. Such a requirement can be
distracting and result in low system usability. Recently
available computer peripherals such as the Secugen mouse
[15] incorporates an optical ﬁngerprint scanner at the place
Figure 3. Sec-
ureGen mou-
se.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:12:41 UTC from IEEE Xplore.  Restrictions apply. 
Face
C
I
R
T
E
M
O
I
B
Fingerprint
a
d
b
e
c
g
f
P(system is safe | biometric observ.)
Fingerprint
score
Integrator
Face score
Fingerprint
verifier
Fingerprint 
image
Face
verifier
Face 
image
Other 
modality
t1
t2
t3
time
t4
Figure 5. Integration scheme
Figure 4. Combining multiple biometric
modalities.
where a user would normally place their thumb (Figure 3).
This device effectively turns ﬁngerprint, a normally active
biometric, into a passive one. Our other passive biometric is
the face image, which can be acquired at a distance without
the user’s active cooperation.
ﬂ Using multiple modalities. There is general agreement
in the biometric research community, also supported by the-
ory, see for example [13], that using multiple types (modal-
ities) of biometrics (with an appropriate combination rule)
can yield a higher classiﬁcation accuracy than using only a
single modality. In the context of our work here, combining
face and ﬁngerprint modalities is useful because there are
frequent situations in which one modality is missing, e.g.
when the user is looking away from the camera, or when the
user is not using the mouse. Finally, attempting to thwart a
multi-modal system is a much harder task than fooling a
single-modality system.
There are two general ways of combining biometric data
samples that are coming from different biometric modalities
at different times [1]:
1. (Time-ﬁrst) Combining samples of each modality ﬁrst
across time, and then combining them across modal-
ities.
In Figure 4, this scheme would ﬁrst combine
samples a; b; c (= u) for face, and d; e; f; g (= v) for
ﬁngerprint, then combineu and v.
2. (Modality-ﬁrst) Combinining across modality ﬁrst,
then across time. This would ﬁrst combine samples
in the order a; d at the end of t1, b; e at the end of t2
etc., and then combine across the different times.
Recently we proposed a technique that combines the two
approaches in whatever order the biometric data is made
available [19]. This paper presents performance results us-
ing that technique of multi-modal fusion. The technique is
based on Bayesian probability (see Section 3.3) and models
the computer system as being in one of two states: Safe or
Attacked. A Safe state implies that the logged-in user is still
present at the computer console, while Attacked means that
an imposter has taken over control.4 The result of the fusion
is the calculation of Psafe, the probability that the system is
still in the Safe state. This value can then be compared to a
pre-deﬁned thresholdTsafe set by the security administrator,
below which appropriate action may be taken. A key fea-
ture of our method is that we can compute Psafe at any point
in time, whether or not there are biometric observations. In
the absence of observations, there is a built-in mechanism
to decay Psafe reﬂecting the increasing uncertainty that the
system is still Safe.
In the following section we describe our use of face and
ﬁngerprint biometrics in detail, as well as our technique for
combining them.
3. Multimodal Biometrics
We use two modalities of observations: ﬁngerprint and face
images. The challenge is to integrate these observations
across modality and over time. To do this, we devised the
integration scheme shown in Figure 5. Our system currently
uses the face veriﬁer and a ﬁngerprint veriﬁer; other modal-
ities are possible in the future. Each veriﬁer computes a
score from its input biometric data (ﬁngerprint or face im-
ages), which is then integrated (fused) by the Integrator. In
the following sections, we describe in turn how we com-
pute the score for each modality and how we fuse them into
a single estimate.
3.1. Fingerprint Veriﬁer
images using the SecureGenTM
We acquire ﬁngerprint
mouse (Figure 3). The mouse comes with a software de-
velopment kit (SDK) that matches ﬁngerprints, i.e., given
two images, it computes a similarity score between 0 (very
4There is a possible Absent state, to model the situation in which the
user has left the console but has not logged out. Because we are assuming
a high-risk environment, it is justiﬁable to makeAbsent (cid:17) Attacked.
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:12:41 UTC from IEEE Xplore.  Restrictions apply. 
dissimilar) and 199 (identical). Unfortunately, the matching
algorithm is proprietary and is not disclosed by the vendor.
Nevertheless, we’ve obtained good results using the score
generated by this algorithm.
First we collect 1000 training ﬁngerprint images from
each of four users. Then, for each user we divide the train-
ing images into two sets: those belonging to the user (intra-
class images), and those belonging to others (inter-class im-
ages). For each set, we calculate the pairwise image sim-
ilarity using the proprietary algorithm, and determine the
histogram of the resulting scores. That is, for each user,
we compute two probability density functions (pdf) – the
intra-class and inter-class pdfs (represented by histograms).
Figure 6(a) shows the pairwise pdfs for a typical user. If we
denote the similarity score by s, the intra-class set by (cid:10)U ,
and the inter-class set by (cid:10)I, then these pdfs are P (s j (cid:10)U )
and P (s j (cid:10)I ). Note that the pdfs do not overlap much,
indicating that ﬁngerprint veriﬁcation is reliable (high veri-
ﬁcation accuracy).
Given a new ﬁngerprint image and a claimed identity,
the image is matched against the claimed identity’s tem-
plate (captured at enrollment time) to produce a score s.
From this we compute P (s j (cid:10)U ) and P (s j (cid:10)I ). These
values are then used by the Integrator to arrive at the overall
decision. Section 3.3 has more details.
3.2. Face Veriﬁcation
To train the face Veriﬁer, we ﬁrst capture500 images of
each of the four users under different head poses using a
Canon VCC4 video camera and applying the Viola-Jones
face detector on the image [18]. About 1200 face images
are also collected of sundry students on campus to model as
imposters. For each user, we construct training images from
two sets: those belonging to the user, and those belonging
to the imposter. All face images are resized to 28 (cid:2) 35 pix-
els. For each set we calculate the pairwise image distance
using the Lp norm (described below). This constitutes the
biometric feature that we extract from the image and is sim-
ilar to the ARENA method [14]. If we denote the similarity
score by s, the set of legitimate users by (cid:10)U , and the set
of imposters by (cid:10)I, then these pdfs are P (s j (cid:10)U ) and
P (s j (cid:10)I ). We can now determine the histogram of the
resulting scores. Figure 6(b) shows a pair of pdfs for one
user.
1
The Lp norm is deﬁned asLp(a) (cid:17) (P jaijp)
p , where
the sum is taken over all pixels of the image a. Thus the dis-
tance between images u and v is Lp(u(cid:0) v). As in ARENA,
we found that p = 0:5 works better than p = 2 (Euclidean).
Given a new face image and a claimed identity, we compute
the smallest Lp distance between the image and the intra-
class set of the claimed identity. This distance is then used
as a score s to compute P (s j (cid:10)U ) and P (s j (cid:10)I ), which in
State:
Observ.:
X1
Z1
X2
Z2
Time
X3
Z3
X4
Z4
face fingerprint face
p
Safe
(a)
1-p
0
(b)
1
Attacked
Figure 7. Holistic integration:
Markov Model; (b) State transition model.
(a) Hidden
turn is used in the holistic fusion step.
3.3. Holistic Fusion
The heart of our technique is in the integration of biometric
observations across modalities and time. This is done using
a Hidden Markov Model (HMM) (Figure 7 (a)), which is
a sequence of states xt that “emit” observations zt (face or
ﬁngerprint), for timet = 1; 2; : : :Each state can assume one
of two values: fSafe, Attackedg. The goal is now to infer
the state from the observations.
Let Zt = fz1; : : : ; ztg denote the history of obser-
vations up to time t. From a Bayesian perspective, we
want to determine the state xt that maximizes the poste-
rior probability P (xt j Zt). Our decision is the greater of
P (xt = Saf e j Zt) and P (xt = Attacked j Zt). Using a
little algebra, we may write:
P (xtjZt) / P (ztjxt; Zt(cid:0)1) (cid:1) P (xtjZt(cid:0)1)
(1)
and
P (xtjZt(cid:0)1) = Xxt(cid:0)1
P (xtjxt(cid:0)1; Zt(cid:0)1)(cid:1)P (xt(cid:0)1jZt(cid:0)1) (2)
This is a recursive formulation that leads to efﬁcient com-
putation. The base case is P (x0 = Safe) = 1, because
we know that the system is Safe immediately upon suc-
cessful login. Observe that the state variable xt has the ef-
fect of summarizing all previous observations. Because of
our Markov assumptions, we note that P (zt j xt; Zt(cid:0)1) =
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 12:12:41 UTC from IEEE Xplore.  Restrictions apply. 
Intra class
Inter calss
250
200
150
100
50
y
c
n
e
u
q
e
r
F
0
1000
2000
3000
4000