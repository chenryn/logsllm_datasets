Benenson et. al. [7]
Dhamija et. al. [20]
Halevi et. al. [30]
Our Study
Reasoning
×
✓
✓∗
×
✓∗
Spear
✓∗
×
×
×
✓∗
Facade
×
✓∗
×
×
✓∗
×
×
×
✓∗
✓
∗ shows significant effect on participants’ performance
task to differentiate between a genuine email and a bogus one. Their
focus is on content, not mimicking the scaffolding to deceive.
Strategies used is an important aspect of behavior. Authors in
[21] show that users can manage risks that they are aware of, but
they do not perform well in cases of unfamiliar risks. We can con-
clude that scaffolding can be successful since most of the people
believe that messages in a professional social network like LinkedIn
are legitimate. Our experiment is similar to this work but they
created their own phishing emails by putting some fake signals
together, whereas we used a combination of existing company rep-
resentative fraud email and crafted ones. Researchers in [2] used
cognitive map [27] to analyze and model human decision-making
process in the context of cybersecurity. They created cognitive
maps based on participants’ responses to free text questions. Un-
fortunately, they failed to make any conclusion out of the created
model, and how it can help reduce users’ vulnerability. The rela-
tion between habitual use of social network and the probability
of getting deceived was also studied in [57]. Their study shows
that both habitual and “inhabitual” users accept the friend requests,
but habitual users are more susceptible to providing information
to the phisher. Researchers in [3] find that it is possible to predict
the susceptibility of Facebook users to phishing attacks based on
their demographics, anonymity, social capital, and risk perception.
They used a questionnaire to test their hypotheses which is not an
accurate method since people do not have explicit knowledge of
their strategies. In other words, either people are not aware of the
strategies they use, or they do not explicitly mention some of them
when they receive a suspicious email.
In this study, we analyze the strategies that participants used
and the correlation between the demographics and their perfor-
mance. We also investigated the effect of background knowledge,
experience, occupation, personality, and the platform that they
use (mobile and PC) on their performance. Table 7 compares our
study with the most relevant literature based on different variables
they studied. It also shows which variables significantly affected
participants’ performance.
9 CONCLUSION
This study showed how a well-known attack (company represen-
tative fraud) can still deceive people. Participants were asked to
label four representative offers (with different parameters) as legiti-
mate and fraudulent, and only 26% of participants labeled all four
offers correctly. Our results also showed that Recursive Transition
Network as a language generation technique can be used to gener-
ate fraudulent emails without users noticing their difference from
human written emails. We also studied the effect of a very basic
form of targeted phishing attacks by including recipients’ name
and adding some basic information about the sender. Including this
information increased the success rate of the attack by 10%.
Analyzing participants’ reasoning also revealed a significant cor-
relation between the clues that users pay attention to and their
performance on detecting attacks. With the growing rate of phish-
ing and social engineering attacks, more focus is required on in-
creasing users’ knowledge about cyber threats. Periodic training
programs and drawing users’ attention to the clues by showing
them warnings are two common approaches of decreasing users’
susceptibility. Based on our observations, training programs should:
1) focus more on younger adults and mobile users (as they are more
vulnerable) and 2) adapt their training material to spear phishing
attacks (as users are worse in detecting them). Customizing these
approaches based on users’ behavior and habitual patterns can also
increase their effectiveness.
ACKNOWLEDGMENTS
This research was supported by NSF grants DUE 1356705, DGE
1433817 and CNS 1319212 and US ARO grant W911NF-16-1-0422.
The authors would like to thank Arjun Mukherjee for his helpful
suggestions on Natural Language Generation techniques.
REFERENCES
[1] Ayman El Aassal, Shahryar Baki, Avisha Das, and Rakesh M. Verma. 2020. An In-
Depth Benchmarking and Evaluation of Phishing Detection Research for Security
Needs. IEEE Access 8 (2020), 22170–22192.
[2] Tahani Albalawi, Kambiz Ghazinour, and Austin Melton. 2019. That’s how I feel:
A Study of User’s Security Mental Model. In Proc. of the Int’l Conf. on Security
and Management (SAM). The Steering Committee of The World Congress in
Computer Science, Computer, Springer, Las Vegas, USA, 115–122.
[3] Zafer Alqarni, Abdullah Algarni, and Yue Xu. 2016. Toward Predicting Sus-
ceptibility to Phishing Victimization on Facebook. In 2016 IEEE International
Conference on Services Computing (SCC). IEEE, San Francisco, CA, USA, 419–426.
[4] Leila Bahri, Barbara Carminati, and Elena Ferrari. 2016. Coip–continuous,
operable, impartial, and privacy-aware identity validity estimation for osn
profiles. ACM Trans. Web 10, 4, Article 23 (Dec. 2016), 41 pages.
https:
//doi.org/10.1145/3014338
[5] Shahryar Baki, Rakesh Verma, Arjun Mukherjee, and Omprakash Gnawali. 2017.
Scaling and Effectiveness of Email Masquerade Attacks: Exploiting Natural Lan-
guage Generation. In Proceedings of the 2017 ACM on Asia CCS. ACM, New York,
NY, USA, 469–482.
[6] Shahryar Baki, Rakesh M. Verma, Arjun Mukherjee, and Omprakash Gnawali.
2020. Less is More: Exploiting Social Trust to Increase the Effectiveness of a
Deception Attack. arXiv:cs.CR/2006.13499
[7] Zinaida Benenson, Freya Gassmann, and Robert Landwirth. 2017. Unpack-
ing Spear Phishing Susceptibility. In Financial Cryptography and Data Secu-
rity, Michael Brenner, Kurt Rohloff, Joseph Bonneau, Andrew Miller, Peter Y.A.
Session 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan246Ryan, Vanessa Teague, Andrea Bracciali, Massimiliano Sala, Federico Pintore,
and Markus Jakobsson (Eds.). Springer International Publishing, Cham, 610–627.
[8] Zinaida Benenson, Anna Girard, Nadina Hintz, and Andreas Luder. 2014. Suscepti-
bility to URL-based Internet attacks: Facebook vs. email. In 2014 IEEE Int’l Conf. on
Pervasive Computing & Communication Workshops (PERCOM WORKSHOPS). IEEE,
Budapest, Hungary, 604–609. https://doi.org/10.1109/PerComW.2014.6815275
[9] Leyla Bilge, Thorsten Strufe, Davide Balzarotti, and Engin Kirda. 2009. All Your
Contacts Are Belong to Us: Automated Identity Theft Attacks on Social Networks.
In Proceedings of the 18th International Conference on World Wide Web (WWW ’09).
ACM, New York, NY, USA, 551–560. https://doi.org/10.1145/1526709.1526784
[10] Andrew C Bulhak. 1996. On the simulation of postmodernism and mental debility
using recursive transition networks. Technical Report. Monash University.
[11] Andrew C Bulhak. 2000. The Dada engine. dev.null.org/dadaengine/
[12] Better Business Bureau. 2019. Scam Alert: Employment Scams Target Col-
lege Students. https://www.bbb.org/article/news-releases/20710-scam-alert-
employment-scams-target-college-students
[13] Marcus Butavicius, Kathryn Parsons, Malcolm Pattinson, and Agata McCormac.
2016. Breaching the Human Firewall: Social engineering in Phishing and Spear-
Phishing Emails. arXiv:cs.CY/1606.00887
[14] Casey Inez Canfield, Baruch Fischhoff, and Alex Davis. 2019. Better beware:
comparing metacognition for phishing and legitimate emails. Metacognition and
Learning 14, 3 (2019), 343–362. https://doi.org/10.1007/s11409-019-09197-5
[15] Jin-Hee Cho, Hasan Cam, and Alessandro Oltramari. 2016. Effect of personality
traits on trust and risk to phishing vulnerability: Modeling and analysis. In 2016
IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation
Awareness and Decision Support (CogSIMA). IEEE, San Diego, CA, USA, 7–13.
[16] Morshed U Chowdhury, Jemal H Abawajy, Andrei V Kelarev, and T Hochin. 2017.
Multilayer hybrid strategy for phishing email zero-day filtering. Concurrency
and Computation: Practice and Experience 29, 23 (2017), e3929.
[17] A. Das, S. Baki, A. El Aassal, R. Verma, and A. Dunbar. 2020. SoK: A Comprehen-
sive Reexamination of Phishing Research From the Security Perspective. IEEE
Communications Surveys Tutorials 22, 1 (2020), 671–708.
[18] Avisha Das and Rakesh Verma. 2019. Automated email Generation for Targeted
Attacks using Natural Language. arXiv:1908.06893
[19] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT:
Pre-training of deep bidirectional transformers for language understanding.
arXiv:cs.CL/1810.04805
[20] Rachna Dhamija, J. D. Tygar, and Marti Hearst. 2006. Why Phishing Works. In
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI
’06). ACM, New York, NY, USA, 581–590. https://doi.org/10.1145/1124772.1124861
[21] Julie S. Downs, Mandy B. Holbrook, and Lorrie Faith Cranor. 2006. Decision
Strategies and Susceptibility to Phishing. In Proceedings of the Second Symposium
on Usable Privacy and Security (SOUPS ’06). ACM, New York, NY, USA, 79–90.
[22] Yvonne D Eaves. 2001. A synthesis technique for grounded theory data analysis.
Journal of advanced nursing 35, 5 (2001), 654–663.
[23] G. Egozi and R. Verma. 2018. Phishing Email Detection Using Robust NLP
Techniques. In 2018 IEEE International Conference on Data Mining Workshops
(ICDMW). IEEE, Singapore, 7–12.
[24] Ayman El Aassal and Rakesh Verma. 2019. Spears Against Shields: Are Defenders
Winning the Phishing War?. In Proc. 5th ACM International Workshop on Security
and Privacy Analytics (IWSPA). ACM, Richardson, Texas, USA, 15–24.
[25] Yong Fang, Cheng Zhang, Cheng Huang, Liang Liu, and Yue Yang. 2019. Phish-
ing email detection using improved RCNN model with multilevel vectors and
attention mechanism. IEEE Access 7 (2019), 56329–56340.
[26] Shane Frederick. 2005. Cognitive reflection and decision making. Journal of
Economic perspectives 19, 4 (2005), 25–42.
[28] Robert Greszki, Marco Meyer, and Harald Schoen. 2014.
[27] Jack Jen Gieseking. 2013. Where we go from here: the mental sketch mapping
method and its analytic components. Qualitative Inquiry 19, 9 (2013), 712–724.
The im-
pact of speeding on data quality in nonprobability and freshly recruited
John Wiley & Sons, Ltd, Chichester,
probability-based online panels.
UK, Chapter 11, 238–262.
https://doi.org/10.1002/9781118763520.ch11
arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118763520.ch11
[29] Anti-Phishing Working Group. 2019. Phishing activity trends reports. https:
//apwg.org/trendsreports/
[30] Tzipora Halevi, James Lewis, and Nasir Memon. 2013. A pilot study of cyber
security and privacy related behavior and personality traits. In Proc. of 22nd
WWW Conf. (WWW ’13 Companion). ACM, New York, NY, USA, 737–744.
[31] Tzipora Halevi, Nasir Memon, and Oded Nov. 2015. Spear-phishing in the wild:
A real-world study of personality, phishing self-efficacy and vulnerability to
spear-phishing attacks. Phishing Self-Efficacy and Vulnerability to Spear-Phishing
Attacks (January 2, 2015) (2015).
[32] Bing-Zhe He, Chien-Ming Chen, Yi-Ping Su, and Hung-Min Sun. 2014. A defence
scheme against identity theft attack based on multiple social networks. Expert
Systems with Applications 41, 5 (2014), 2345–2352.
[33] Amir Herzberg. 2009. Combining authentication, reputation and classification
to make phishing unprofitable. In Emerging Challenges for Security, Privacy and
Trust, Dimitris Gritzalis and Javier Lopez (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 13–24.
[34] Markus Huber, Martin Mulazzani, Edgar Weippl, Gerhard Kitzler, and Sigrun
Goluch. 2011. Friend-in-the-middle attacks: Exploiting social networking sites
for spam. IEEE Internet Computing 15, 3 (2011), 28–34.
[35] Danesh Irani, Marco Balduzzi, Davide Balzarotti, Engin Kirda, and Calton Pu.
2011. Reverse social engineering attacks in online social networks. In Detection of
Intrusions and Malware, and Vulnerability Assessment, Thorsten Holz and Herbert
Bos (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 55–74.
[36] Lei Jin, Hassan Takabi, and James B.D. Joshi. 2011. Towards active detection of
identity clone attacks on online social networks. In Proceedings of the First ACM
CODASPY. ACM, New York, NY, USA, 27–38.
[37] Oliver P John and Sanjay Srivastava. 1999. The Big Five trait taxonomy: History,
measurement, and theoretical perspectives. Handbook of personality: Theory and
research 2, 1999 (1999), 102–138.
[38] A Karakasiliotis, SM Furnell, and M Papadaki. 2006. Assessing end-user awareness
of social engineering and phishing. In Australian Information Warfare and Security
Conference. School of Computer and Information Science, Edith Cowan University,
Perth, Western Australia, Perth, Western Australia.
[39] Eleftherios Karavaras, Emmanouil Magkos, and Aggeliki Tsohou. 2016. Low
use awareness against social malware: an empirical study and design of a secu-
rity awareness application. In 13th European Mediterranean and Middle Eastern
Conference on Information Systems, Vol. 13. Cracow, Poland, 1–10.
[40] Paul J Lavrakas. 2008. Encyclopedia of survey research methods. Sage Publications,
Los Angeles, London, New Delhi, Singapore, Washington DC.
[41] Tian Lin, Daniel E. Capecci, Donovan M. Ellis, Harold A. Rocha, Sandeep Dom-
maraju, Daniela S. Oliveira, and Natalie C. Ebner. 2019. Susceptibility to spear-
phishing emails: Effects of internet user demographics and email content. ACM
Trans. Comput.-Hum. Interact. 26, 5, Article 32 (July 2019), 28 pages.
[42] Shah Mahmood and Yvo Desmedt. 2012. Your facebook deactivated friend or
a cloaked spy. In Pervasive Computing and Communications Workshops (PER-
COM Workshops), 2012 IEEE International Conference on. IEEE, IEEE, Lugano,
Switzerland, 367–373.
[43] KC Meijdam, W Pieters, and J van den Berg. 2015. Phishing as a service: Designing
an ethical way of mimicking targeted phishing attacks to train employees. TU
Delft, TU Delft.
[44] María M Moreno-Fernández, Fernando Blanco, Pablo Garaizar, and Helena Matute.
2017. Fishing for phishers. Improving Internet users’ sensitivity to visual decep-
tion cues to prevent electronic fraud. Computers in Human Behavior 69 (2017),
421–436.
[45] Ajaya Neupane, Md. Lutfor Rahman, Nitesh Saxena, and Leanne Hirshfield. 2015.
A multi-modal neuro-physiological study of phishing detection and malware
warnings. In Proc. of the 22nd CCS. ACM, New York, NY, USA, 479–491.
[46] Information Security Office. 2019. FBI Alert: Employment Scam Targeting Stu-
dents. https://informationsecurity.princeton.edu/news/fbi-alert-employment-
scam-targeting-students
[47] Information Security Office. 2019. PHISH BOWL/PHISHING SCAMS. https:
//www.it.ucla.edu/security/alerts/phishing-scams
https://info.
[48] PhishLabs. 2017. Q2 2017 Phishing Trends & Intelligence Report. https://info.
phishlabs.com/q2_2017_phishing_trends_and_-intelligence_report
[49] PhishLabs. 2018. 2018 Phishing Trends & Intelligence Report.
phishlabs.com/2018_phishing_trends_and_-intelligence_report-0
[50] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI
Blog 1, 8 (2019).
[51] L. Schipper. 1969. Human information processing and decision-making. In 1969
IEEE Symposium on Adaptive Processes (8th) Decision and Control. IEEE, University
Park, PA, USA, USA, 25–25. https://doi.org/10.1109/SAP.1969.269909
[52] Steve Sheng, Mandy Holbrook, Ponnurangam Kumaraguru, Lorrie Faith Cranor,
and Julie Downs. 2010. Who falls for phish?: A demographic analysis of phishing
susceptibility and effectiveness of interventions. In Proceedings of the CHI’10.
ACM, New York, NY, USA, 373–382.
[53] Cong Tang, Keith Ross, Nitesh Saxena, and Ruichuan Chen. 2011. What’s in a
name: A study of names, gender inference, and gender behavior in Facebook. In
Database Systems for Adanced Applications, Jianliang Xu, Ge Yu, Shuigeng Zhou,
and Rainer Unland (Eds.). Springer, Berlin, Heidelberg, 344–356.
[54] Radicati Team. 2019. Email Statistics Report, 2019-2023. https://www.radicati.
com/?p=15792
[55] Rakesh M. Verma and David J. Marchette. 2019. Cybersecurity analytics. CRC
Press LLC, Boca Raton, FL. https://books.google.com/books?id=zez3xwEACAAJ
[56] Arun Vishwanath. 2015. Diffusion of deception in social media: Social contagion
effects and its antecedents. Information Systems Frontiers 17, 6 (2015), 1353–1367.
[57] Arun Vishwanath. 2015. Habitual Facebook use and its impact on getting deceived
on social media. J. of Computer-Mediated Communication 20, 1 (2015), 83–98.
[58] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov,
and Quoc V. Le. 2019. XLNet: Generalized autoregressive pretraining for language
understanding. arXiv:cs.CL/1906.08237
[59] Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, and Yafei Dai.
2014. Uncovering social network sybils in the wild. ACM TKDD) 8, 1 (2014), 2.
Session 5: Usable Security & Privacy ASIA CCS '20, October 5–9, 2020, Taipei, Taiwan247