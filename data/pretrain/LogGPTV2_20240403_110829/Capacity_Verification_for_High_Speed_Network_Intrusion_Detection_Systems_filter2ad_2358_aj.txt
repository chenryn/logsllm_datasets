### References

1. Aim Recovery. <http://www.dark-e.com/des/software/aim/index.shtml>
2. Back Orifice. <http://www.cultdeadcow.com/tools/bo.html>
3. BackDoor.XTCP. <http://www.ntsecurity.new/Panda/Index.cfm?FuseAction=Virus&VirusID=659>, <http://home.swipenet.se/~w-65048/hacks.htm>
4. BrowseList. <http://e4gle.org/files/nttools/>, <http://binaries.faq.net.pl/security_tools>
5. Happy 99. <http://www.symantec.com/qvcenter/venc/data/happy99.worm.html>
6. IPCrack. <http://www.geocities.com/SiliconValley/Garage/3755/toolicq.html>
7. L0pht Crack. <http://www.atstake.com/research/lc>
8. Setup Trojan. <http://www.nwinternet.com/~pchelp/bo/setuptrojan.txt>
9. V. Barnett and T. Lewis. *Outliers in Statistical Data*. John Wiley and Sons, 1994.
10. Fred Cohen. *A Short Course on Computer Viruses*. ASP Press, Pittsburgh, PA, 1990.
11. M. H. DeGroot. *Optimal Statistical Decisions*. McGraw-Hill, New York, 1970.
12. D. E. Denning. An intrusion detection model. *IEEE Transactions on Software Engineering*, SE-13:222–232, 1987.
13. Eleazar Eskin. Anomaly detection over noisy data using learned probability distributions. In *Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000)*, 2000.
14. Eleazar Eskin. Probabilistic anomaly detection over discrete records using inconsistency checks. Technical report, Columbia University Computer Science Technical Report, 2002.
15. Stephanie Forrest, S. A. Hofmeyr, A. Somayaji, and T. A. Longstaff. A sense of self for UNIX processes. Pages 120–128. IEEE Computer Society, 1996.
16. N. Friedman and Y. Singer. Efficient Bayesian parameter estimation in large discrete domains, 1999.
17. S. A. Hofmeyr, Stephanie Forrest, and A. Somayaji. Intrusion detection using sequences of system calls. *Journal of Computer Security*, 6:151–180, 1998.
18. Andrew Honig, Andrew Howard, Eleazar Eskin, and Salvatore Stolfo. Adaptive model generation: An architecture for the deployment of data mining-based intrusion detection systems. In *Data Mining for Security Applications*. Kluwer, 2002.
19. Internet Engineering Task Force. Intrusion detection exchange format. <http://www.ietf.org/html.charters/idwg-charter.html>, 2000.
20. H. S. Javitz and A. Valdes. The NIDES statistical component: Description and justification. Technical report, SRI International, 1993.
21. W. Lee, S. J. Stolfo, and P. K. Chan. Learning patterns from UNIX processes execution traces for intrusion detection. Pages 50–56. AAAI Press, 1997.
22. W. Lee, S. J. Stolfo, and K. Mok. Data mining in workflow environments: Experiences in intrusion detection. In *Proceedings of the 1999 Conference on Knowledge Discovery and Data Mining (KDD-99)*, 1999.
23. Wenke Lee, Sal Stolfo, and Kui Mok. A data mining framework for building intrusion detection models. 1999.
24. McAfee. Homepage: mcafee.com. Online publication, 2000. <http://www.mcafee.com>
25. M. Mahoney and P. Chan. Detecting novel attacks by identifying anomalous network packet headers. Technical Report CS-2001-2, Florida Institute of Technology, Melbourne, FL, 2001.
26. B. Schölkopf, J. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. Williamson. Estimating the support of a high-dimensional distribution. Technical Report 99–87, Microsoft Research, 1999. To appear in *Neural Computation*, 2001.
27. SysInternals. Regmon for Windows NT/9x. Online publication, 2000. <http://www.sysinternals.com/ntw2k/source/regmon.shtml>
28. Christina Warrender, Stephanie Forrest, and Barak Pearlmutter. Detecting intrusions using system calls: alternative data models. Pages 133–145. IEEE Computer Society, 1999.
29. Steve R. White. Open problems in computer virus research. In *Virus Bulletin Conference*, 1998.

### Abstract

Over the past decade, numerous anomaly-detection techniques have been proposed and deployed to provide early warnings of cyber-attacks, particularly those involving masqueraders and novel methods. However, there appears to be no systematic study identifying methods that could be used by an attacker to undermine an anomaly-based intrusion detection system. This paper demonstrates how an adversary can craft an offensive mechanism that renders an anomaly-based intrusion detector blind to ongoing, common attacks. It presents a method to identify the weaknesses of an anomaly-based intrusion detector and shows how an attacker can manipulate common attacks to exploit these weaknesses. The paper explores the implications of this threat and suggests possible improvements for existing and future anomaly-based intrusion detection systems.

### 1. Introduction

In recent years, a vast array of tools and techniques has been developed to address the problem of ensuring the availability, integrity, and confidentiality of electronic information systems. These security measures are often accompanied by equally sophisticated "shadow" arsenals aimed at subverting the security schemes. While shadow arsenals pose a significant threat, they also provide valuable insights into the weaknesses of current security tools, facilitating their improvement.

A key part of the security arsenal is the anomaly-based intrusion-detection system (IDS). These systems aim to protect electronic information systems by detecting deviations from normal behavior, which may indicate an intrusion or attack. Anomaly detection, one of two fundamental approaches in automated intrusion detection, is particularly effective in detecting novel attacks and abuse-of-privilege attacks such as masquerading and insider misuse.

The promise of anomaly detection and its incorporation into various automated IDSs underscores the importance of understanding how attackers might counteract these systems. This paper outlines a method to undermine a well-known anomaly-based IDS called stide. By first identifying the weaknesses of stide's anomaly-detection algorithm, it shows how an attacker can manipulate common attacks to exploit these weaknesses, effectively hiding the attacks from the detector.

To undermine an anomaly-based IDS, an attacker needs to know three elements:
1. Detection coverage (specifically, blind spots) of the anomaly detector.
2. How and where an attack manifests in sensor data.
3. How to shift the manifestation from a covered spot to a blind one.

### 2. Approaches to Undermining Anomaly Detectors

There are two primary approaches to undermining an anomaly-based IDS:
- Modify the normal behavior to look like the attack, incorporating attack manifestations into the model of normal behavior.
- Modify the attack to make it appear as normal behavior.

The most cited way to undermine an anomaly-based IDS is to incorporate intrusive behavior into the training data, thereby falsely representing "normal" behavior. This can be done by exploiting the fact that behavior changes over time, requiring periodic retraining. If the system undergoes attacks during retraining, the IDS may inadvertently incorporate undesired attack behavior into its model of normal behavior.

However, this method is imprecise and abstract, requiring significant time, patience, and system privileges. Moreover, it does not guarantee that the IDS will be completely blind to the attack when it is deployed. The attacker lacks knowledge of how the IDS perceives the attack and the conditions that may affect its detection capabilities.

### 3. Detection Coverage of an Anomaly Detector

Current evaluation techniques assess the detection coverage of an anomaly-based IDS with respect to its ability to detect attacks, but without determining if the detected anomalies are attributable to the attack. The anomaly-based evaluation technique described here establishes the detection coverage of stide with respect to the types of anomalous manifestations it can detect.

#### 3.1 Brief Description of the Stide Anomaly Detector

Stide operates on fixed-length sequences of categorical data. It acquires a model of normal behavior by sliding a detector window of size DW over the training data, storing each DW-sized sequence in a "normal database." The degree of similarity between test data and the model of normal behavior is based on the number of identical matches between sequences from the test data and the normal database. The anomaly signal involves a user-defined parameter, the "locality frame," which determines the size of a temporally local region over which the number of mismatches is summed up. The number of mismatches within a locality frame is used to determine the extent to which the test data are anomalous.

#### 3.2 Evaluation Strategy for Anomaly Detectors

Stide detects foreign sequences—sequences that do not exist in the normal database. However, this alone does not fully explain its performance. Two significant issues must be considered:
- How foreign sequences manifest in categorical data.
- How the interaction between foreign sequences and the anomaly detection algorithm affects overall performance.

A framework was established to focus on the architecture and characteristics of anomalous sequences, defining how they are constructed and composed. This framework allowed for the evaluation of stide's detection efficacy on synthetic data with clearly defined anomalous sequences, revealing its detection capabilities and how the interaction with the anomaly-detection algorithm affects performance.

#### 3.3 Stide’s Performance Results

The most significant result from the anomaly-based evaluation of stide was the identification of conditions that caused the detector to be completely blind to minimal foreign sequences, which are abundant in real-world data. A minimal foreign sequence is a foreign sequence whose proper subsequences all exist in the normal data, meaning it contains no smaller foreign sequences.

### 4. Implications and Improvements

The findings highlight the need for more robust anomaly-based IDSs. Possible improvements include:
- Enhancing the detection algorithm to handle minimal foreign sequences.
- Implementing additional layers of security to detect and mitigate attacks that exploit the identified weaknesses.
- Continuously updating and refining the model of normal behavior to adapt to evolving threats.

By understanding and addressing these weaknesses, future anomaly-based IDSs can be made more resilient to sophisticated attacks.