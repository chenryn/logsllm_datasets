is able to handle dynamically linked applications by support-
ing multiple instruction sets per process (i.e., instructions
randomized with diﬀerent keys).
3.
IMPLEMENTATION
We implemented ISR in software on 32-bit Linux for dy-
namically and statically linked ELF executables and libraries.
This section describes the components of our implementa-
tion. It should be noted that while the current implementa-
tion works on Linux, it can be easily ported to other plat-
forms also supported by the runtime.
3.1 Randomization of Binaries
ELF (the executable and linking format) is a very common
and standard ﬁle format used for executables and shared li-
braries in many Unix type systems like Linux, BSD, Solaris,
etc. Despite the fact that it is most commonly found on
Unix systems, it is very ﬂexible and it is not bound to any
particular architecture or OS. Also, the ELF format com-
pletely separates code and data, including control data such
as the procedure linkage table (PLT), making it an ideal
format for applying binary randomization.
We modiﬁed the objcopy utility, which is part of the GNU
binutils package to add support for randomizing ELF exe-
cutables and libraries. objcopy can be used to perform cer-
tain transformations (e.g., strip debugging symbols) on an
object ﬁle, or simply copy it to another. Thus, it is able
to parse the ELF headers of an executable or library and
access its code. We modiﬁed objcopy to randomize a ﬁle’s
code using XOR and a 16-bit key. We also extended objcopy
to randomize shared libraries in ELF format. Randomizing
using XOR does not require that the target binary is aligned,
so it does not increase its size or modify its layout.
While our current implementation is currently able to ran-
domize only ELF binaries, support for other binaries can be
easily added. For instance, we plan to extend objcopy to
also randomize Portable Executable (PE) binaries for Win-
dows operating systems [28].
3.2 Shared Libraries
Most executables in modern OSs are dynamically linked
to one or more shared libraries. Shared libraries are pre-
ferred because they accommodate code reuse and minimize
memory consumption, as their code can be concurrently
mapped and used by multiple applications. As a result, mix-
ing shared libraries with ISR has proven to be problematic
in past work. Our implementation of ISR supports multi-
ple instruction sets (i.e., multiple randomization keys) for
the same process, enabling us to use plain shared libraries
with a randomized executable. Furthermore, it enables us
to randomize each library with its own key, and share it
amongst all processes running under ISR like an ordinary
shared library.
We create a randomized copy of all libraries that are needed,
and store them in a shadow folder (e.g., “/usr/rand lib”).
For stronger security, each library is encoded using a dif-
ferent key, while we can also periodically re-randomize all
the libraries using new keys. When an application is loaded
in the runtime environment, we modify its environment so
it ﬁrst looks for shared libraries in a shadow folder.
If a
randomized version of a library is not found, it proceeds to
look for a plain version in the usual system locations (e.g.,
“/usr/lib” and “/lib” on Linux, and “c:\windows\system32”
for Windows). Of course, a process can be forced to only
use randomized code if that is required. Moreover, multiple
shadow folders can be used concurrently. For instance, if a
process crashes (e.g., a crash could be triggered by a failed
exploitation attempt), we may re-encode all shared libraries
to thwart key guessing attacks.
3.3 Key Management
Supporting multiple instruction sets for every process no-
tably increases the number of keys that are active in the
system at any given time. Thus, key management becomes
an important aspect of the system, and specially because
shared libraries can be randomized with their own key, and
multiple versions of the libraries may co-exist in the system.
Previous work proposed to store keys within the ELF ﬁles,
which removes the need for separate storage for the keys.
While this approach is robust, it leaves keys vulnerable to
exposure if an application leaks data because of a bug or an
error.
In the past information leakage has been exploited
to bypass address space layout randomization (ASLR) [19].
Additionally, storing the key within the executable might
not be feasible when using binary formats other than ELF.
Instead, we store the keys for executables and libraries
in a database, using the sqlite database system. Sqlite is a
software library that implements a self-contained, serverless
SQL database engine. The entire database is stored in a
single ﬁle, and it is accessed directly by our tool (using the
sqlite library) without the need to run additional processes.
The keys are indexed using the library’s full path, and the
operation of retrieving a key from the DB is fast. As it is
an operation that it is only performed when an application
is launched or a dynamic library is loaded, its performance
is not critical for the system.
3.4 PIN Execution Environment
We implemented the de-randomizing execution environ-
ment using Intel’s dynamic binary instrumentation tool PIN.
PIN [26] is an extremely versatile tool that operates entirely
in user-space, and supports multiple architectures (x86, 64-
bit x86, ARM) and operating systems (Linux, Windows,
MacOS). It operates by just-in-time (JIT) compiling the tar-
get’s instructions combined with any instrumentation into
new code, which is placed into a code cache, and executed
from there. It also oﬀers a rich API to inspect and modify
an application’s original instructions.
We make use of the supplied API to implement our ISR
runtime framework. First, we install a callback that inter-
cepts the loading of all ﬁle images. This provides us with
the names of all the shared libraries being used, as well as
the memory ranges where they have been loaded in the ad-
dress space. We use the path and name of the library to
lookup its key in the database and load it. We save the li-
brary’s key and memory address range in a hash table-like
data structure that allows us to quickly lookup a key using
a memory address. The existence of a key in the database
also indicates that the library is encoded, so no special han-
dling is required to load system libraries (i.e., not encoded
libraries).
The actual de-randomization is performed by installing
a callback that replaces PIN’s default function for fetching
code from the target process. This second callback reads
instructions from memory, and uses the memory address
to lookup the key to use for decoding.
If the instruction
fetched is within the memory range of a shared library we
use its key for decoding, or assume no decoding is necessary
if no key is present. All instructions not associated with
a library are considered to be part of the executable and
are decoded using its key. To avoid performing a lookup for
every instruction fetched, we cache the last used key. During
our evaluation this simple single entry cache achieved high
hit ratios, so we did not explore other caching mechanisms.
3.5 Memory Protection (MP)
When executing an application within PIN, they both op-
erate on the same address space. This means that in theory
an application can access and modify the data used by PIN
and consequently ISR. Such illegal accesses may occur due
to a program error, and could potentially be exploited by an
attacker. For instance, an attacker could attempt to over-
write a function pointer or return address in PIN, so that
control is diverted directly into the attacker’s code in the
application. Such a control transfer would circumvent ISR
enabling the attacker to successfully execute his code. To
defend against such attacks we need to protect PIN’s mem-
ory from being written by the application.
When PIN loads and before the target application and its
libraries gets loaded, we scan the address space to identify all
memory pages used by PIN. We mark these memory pages
by asserting a ﬂag in an array (page-map), which holds one
byte for every addressable page. For instance, in a 32-bit
Linux system, processes can typically access 3 out of the 4
GBytes that are directly addressable. For a page size of 4
KBytes, this corresponds to 786432 pages, so we allocate 768
KBytes to store the ﬂags for the entire address space. At
runtime, when additional memory is used by PIN, we update
the ﬂags for the newly used pages in the page-map. Memory
protection is actually enforced by instrumenting all memory
write operations performed by the application, and checking
that the page being accessed is valid according to the page-
map. If the application attempts to write to a page “owned”
by PIN, the instrumentation causes a page-fault that will
terminate it.
Introducing memory protection further hardens the system
against code-injection attacks, but incurs a substantial over-
head. However, forcing an attacker to exploit a vulnerability
in this fashion is already hardening the system considerably,
as he would have to somehow discover one of the few mem-
ory locations which can be used to divert PIN’s control ﬂow.
Alternatively, we can use address space layout randomiza-
tion to decrease the probability of an attacker successfully
guessing the location of PIN’s control data.
3.6
ISR Exceptions
While all instructions in the application are encoded, there
are cases where certain external and unencoded instructions
need to be executed in the context of the process. For in-
stance, some systems inject code within the stack of a pro-
cess when a signal is delivered. These signal trampolines are
used to set up and clean up the context of a signal handler.
The instructions are a type of legitimate code-injection per-
formed by the system, and need special handling or their
execution will lead to a crash. Fortunately, signal trampo-
lines are very small (approximately 5-7 instructions long),
and the instructions used are ﬁxed on every system (i.e.,
the same instructions are used for all signals in the system).
When a signal is delivered to a process, we scan the code
being executed to identify trampolines, and execute them
without applying the decoding function.
Moreover, modern Linux systems frequently include a read-
only virtual shared object (VDSO) in every running process.
This object is used to export certain kernel functions to user
space. For instance, it is used to perform system calls, re-
placing the older software interrupt mechanism (INT 0x80).
This object needs to be treated in the same manner as plain
shared libraries, allowing the execution of non-randomized
code. Since this is a read-only object, we can safely do so.
3.7 Startup Procedure
When a dynamically linked application is executed, the
loader looks for shared libraries in certain predeﬁned lo-
cations (e.g., “/usr/lib”, “/lib”, etc.), as well as locations
speciﬁed in the environment (i.e., the environment variable
LD_LIBRARY_PATH). To enable the loading of the randomized
versions of shared libraries, we need to add the shadow folder
in the search path. We cannot do so by adding the folder in
the system’s library search path, as that would cause these
libraries to be used instead of the originals for all running
applications.
Instead, we use LD_LIBRARY_PATH. Unfortu-
nately, as PIN itself is dynamically linked we cannot set the
variable directly. We employ a wrapper program that we
launch using PIN. The wrapper adds the shadow folder in
the library search path, and launches the target application,
which then looks for libraries in the shadow folder ﬁrst.
4. PERFORMANCE
Dynamic instrumentation tools usually incur signiﬁcant
slowdowns on target applications. While this is also true
for PIN, we show that the overhead is not prohibitive. We
conducted the measurements presented in this section on a
DELL Precision T5500 workstation with a dual 4-core Xeon
CPU and 24GB of RAM running Linux.
Figure 1 shows the mean execution time and standard
deviation when running several commonly used Linux util-
ities. We draw the execution time for running ls on a di-
rectory with approximately 3400 ﬁles, and running cp, cat,
and bunzip2 with a 64MB ﬁle. We tested four execution sce-
narios: native execution, execution with PIN and no instru-
mentation (PIN’s minimal overhead), our implementation of
ISR without memory protection (MP), and lastly with MP
enabled (ISR-MP). The ﬁgure shows that short-lived tasks
suﬀer more, because the time needed to encode the binary
and initialize PIN is relatively large when compared with the
task’s lifetime. In opposition, when executing a longer-lived
task, such as bunzip2, execution under ISR only takes about
10% more time to complete.
For all four utilities, when employing memory protection
to protect PIN’s memory from interference, execution takes
signiﬁcantly longer, with bunzip2 being the worst case re-
quiring almost 4 times more time to complete. That is be-
cause memory protection introduces additional instructions
at runtime to check the validity of all memory write op-
erations. Another interesting observation is that running
bunzip2 under ISR is slightly faster from just using PIN.
We attribute this to the various optimizations that PIN in-
troduces when actual instrumentation is introduced.
We also evaluate our implementation using two of the
most popular open-source servers: the Apache web server,
and the MySQL database server. For Apache, we measure
the eﬀect that PIN and ISR have on the maximum through-
Figure 1: Execution time of basic Linux utilities.
The ﬁgure draws the mean execution time and stan-
dard deviation when running four commonly used
Linux utilities.
put of a static web page, using Apache’s own benchmarking
tool ab over a dedicated 1 Gb/s network link. To avoid high
ﬂuctuations in performance due to Apache forking extra pro-
cesses to handle the incoming requests in the beginning of
the experiment, we conﬁgured it to pre-fork all worker pro-
cesses (pre-forking is a standard multi-processing Apache
module), and left all other options to their default setting.
Figure 2 shows the mean throughput and standard devi-
ation of Apache for the same four scenarios used in our ﬁrst
experiment. The graph shows that Apache’s throughput
is more limited by available network bandwidth than CPU
power. Running the server over PIN has no eﬀect on the at-
tainable throughput, while applying ISR, even with memory
protection enabled, does not aﬀect server throughput either.
Finally, we benchmarked a MySQL database server using
its own test-insert benchmark, which creates a table, ﬁlls
it with data, and selects the data. Figure 3 shows the time
needed to complete this benchmark for the same four scenar-
ios. PIN introduces a 75% overhead compared with native
execution, while our ISR implementation incurs no observ-
able slowdown. Unlike Apache, enabling memory protection
for MySQL is 57.5% slower that just using ISR (175% from
native). As with Apache, the benchmark was run at a re-
mote client over a 1 Gb/s network link to avoid interference
with the server.
5. RELATED WORK
Instruction-set randomization was initially proposed as a
general approach against code-injection attacks by Gaurav
et al. [25]. They propose a low-overhead implementation of
ISR in hardware, and evaluate it using the Bochs x86 emula-
tor. They also demonstrate the applicability of the approach
Execution Time (sec)05101520lscpcatbunzip2657075NativePINISRISR−MPFigure 2: Apache web server throughput. The ﬁgure