    ```javascript
    export default {
      data: () => ({
        inbox_retry: undefined
      }),
      methods: {
        retryGetInbox() {
          this.inbox_retry = setInterval(() => {
            if (this.showError) {
              console.log('Retrying the fetch of the inbox')
              // Add your code here.
            } else {
              clearInterval(this.inbox_retry)
            }
          }, 30000)
        }
      },
    ```
    You can call `this.retryGetInbox()` whenever you want to start running the
    function periodically. Once `this.showError` is `false`, we stop running the
    function with `clearInterval(this.inbox_retry)`.
* New: [Set variable if it's undefined.](javascript_snippets.md#set-variable-if-it's-undefined)
    ```javascript
    var x = (x === undefined) ? your_default_value : x;
    ```
* New: [Supporting pre-releases.](pdm.md#supporting-pre-releases)
    To help package maintainers, you can allow pre-releases to be validate
    candidates, that way you'll get the issues sooner. It will mean more time to
    maintain the broken CIs if you update your packages daily (as you should!), but
    it's the least you can do to help your downstream library maintainers
    By default, `pdm`'s dependency resolver will ignore prereleases unless there are
    no stable versions for the given version range of a dependency. This behavior
    can be changed by setting allow_prereleases to true in `[tool.pdm]` table:
    ```toml
    [tool.pdm]
    allow_prereleases = true
    ```
* New: [Solve circular dependencies.](pdm.md#solve-circular-dependencies)
    Sometimes `pdm` is not able to [locate the best package combination](https://github.com/pdm-project/pdm/issues/1354), or it does too
    many loops, so to help it you can update your version constrains so that it has
    the minimum number of candidates.
    To solve circular dependencies we first need to locate what are the conflicting
    packages, [`pdm` doesn't make it easy to detect them](https://github.com/pdm-project/pdm/issues/1354). Locate all the outdated
    packages by doing `pdm show` on each package until [this issue is solved](https://github.com/pdm-project/pdm/issues/1356) and run `pdm update {package} --unconstrained` for each of them. If you're already on the latest
    version, update your `pyproject.toml` to match the latest state.
    Once you have everything to the latest compatible version, you can try to
    upgrade the rest of the packages one by one to the latest with
    `--unconstrained`.
    In the process of doing these steps you'll see some conflicts in the
    dependencies that can be manually solved by preventing those versions to be
    installed or maybe changing the `python-requires`.
* New: Suggest to use Asyncer.
    [Asyncer](https://asyncer.tiangolo.com/tutorial/) looks very useful
* Correction: [Solve circular dependencies by manual constraining.](pdm.md#solve-circular-dependencies)
    It also helps to run `pdm update` with the `-v` flag, that way you see which are
    the candidates that are rejected, and you can put the constrain you want. For
    example, I was seeing the next traceback:
    ```
    pdm.termui: Conflicts detected:
      pyflakes>=3.0.0 (from )
      pyflakes=2.4.0 (from )
    ```
    So I added a new dependency to pin it:
    ```
    [tool.pdm.dev-dependencies]
    dependencies = [
        # Until flakeheaven supports flake8 5.x
        # https://github.com/flakeheaven/flakeheaven/issues/132
        "flake8>=4.0.1,=3.10"
    ```
* New: Suggest to use pydeps.
    If you get lost in understanding your dependencies, you can try using
    [`pydeps`](https://github.com/thebjorn/pydeps) to get your head around it.
### [Libraries](beautifulsoup.md)
* New: Introduce BeautifulSoup and how to use it.
    [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) is a Python
    library for pulling data out of HTML and XML files. It works with your favorite
    parser to provide idiomatic ways of navigating, searching, and modifying the
    parse tree.
* New: [Modifying the tree.](beautifulsoup.md#modifying-the-tree)
    `PageElement.replace_with()` removes a tag or string from the tree, and replaces
    it with the tag or string of your choice:
    ```python
    markup = 'I linked to example.com'
    soup = BeautifulSoup(markup)
    a_tag = soup.a
    new_tag = soup.new_tag("b")
    new_tag.string = "example.net"
    a_tag.i.replace_with(new_tag)
    a_tag
    ```
    Sometimes it doesn't work. If it doesn't use:
    ```python
    +a_tag.clear()
    a_tag.append(new_tag)
    ```
* New: Introduce python gnupg.
    [python-gnupg](https://github.com/vsajip/python-gnupg) is a Python library to
    interact with `gpg` taking care of the internal details and allows its users to
    generate and manage keys, encrypt and decrypt data, and sign and verify
    messages.
    [Installation](https://github.com/vsajip/python-gnupg#installing-from-pypi):
    ```bash
    pip install python-gnupg
    ```
    [Usage](https://gnupg.readthedocs.io/en/latest/#getting-started):
    ```python
    gpg = gnupg.GPG(gnupghome="/path/to/home/directory")
    gpg.decrypt("path/to/file")
    public_keys = gpg.list_keys()
    private_keys = gpg.list_keys(True)
* Correction: Use `decrypt_file` instead of `decrypt` for files.
    ```python
    gpg.decrypt_file("path/to/file")
    ```
    Note: You can't pass `Path` arguments to `decrypt_file`.
### [Configure Docker to host the application](type_hints.md)
* New: [Usage of ellipsis on `Tuple` type hints.](type_hints.md#usage-of-ellipsis-on-tuple-type-hints)
    The ellipsis is used to specify an arbitrary-length homogeneous tuples, for
    example `Tuple[int, ...]`.
* New: [List the files of a bucket.](boto3.md#list-the-files-of-a-bucket)
* New: Suggest to use `Sequence` over `List`.
    Because using `List` could lead to some unexpected errors when combined with type inference. For example:
    ```python
    class A: ...
    class B(A): ...
    lst = [A(), A()]  # Inferred type is List[A]
    new_lst = [B(), B()]  # inferred type is List[B]
    lst = new_lst  # mypy will complain about this, because List is invariant
    ```
    Possible strategies in such situations are:
    * Use an explicit type annotation:
        ```python
        new_lst: List[A] = [B(), B()]
        lst = new_lst  # OK
        ```
    * Make a copy of the right hand side:
        ```python
        lst = list(new_lst) # Also OK
        ```
    * Use immutable collections as annotations whenever possible:
        ```python
        def f_bad(x: List[A]) -> A:
            return x[0]
        f_bad(new_lst) # Fails
        def f_good(x: Sequence[A]) -> A:
            return x[0]
        f_good(new_lst) # OK
        ```
* New: [Overloading the methods.](type_hints.md#overloading-the-methods)
    Sometimes the types of several variables are related, such as “if x is type A,
    y is type B, else y is type C”. Basic type hints cannot describe such
    relationships, making type checking cumbersome or inaccurate. We can instead use
    `@typing.overload` to represent type relationships properly.
    ```python
    from __future__ import annotations
    from collections.abc import Sequence
    from typing import overload
    @overload
    def double(input_: int) -> int:
        ...
    @overload
    def double(input_: Sequence[int]) -> list[int]:
        ...
    def double(input_: int | Sequence[int]) -> int | list[int]:
        if isinstance(input_, Sequence):
            return [i * 2 for i in input_]
        return input_ * 2
    ```
    This looks a bit weird at first glance—we are defining double three times! Let’s
    take it apart.
    The first two `@overload` definitions exist only for their type hints. Each
    definition represents an allowed combination of types. These definitions never
    run, so their bodies could contain anything, but it’s idiomatic to use Python’s
    `...` (ellipsis) literal.
    The third definition is the actual implementation. In this case, we need to
    provide type hints that union all the possible types for each variable. Without
    such hints, Mypy will skip type checking the function body.
    When Mypy checks the file, it collects the `@overload` definitions as type
    hints. It then uses the first non-`@overload` definition as the implementation.
    All `@overload` definitions must come before the implementation, and multiple
    implementations are not allowed.
    When Python imports the file, the `@overload` definitions create temporary
    double functions, but each is overridden by the next definition. After
    importing, only the implementation exists. As a protection against accidentally
    missing implementations, attempting to call an `@overload` definition will raise
    a `NotImplementedError`.
    `@overload` can represent arbitrarily complex scenarios. For a couple more examples, see the function overloading section of the [Mypy docs](https://mypy.readthedocs.io/en/stable/more_types.html#function-overloading).
* Correction: [Debug the Start request repeated too quickly error.](docker.md#start-request-repeated-too-quickly)
    Use `journalctl -eu docker` to debug
* Correction: Update TypeVars nomenclature.
    Using `UserT` is [not supported by pylint](https://github.com/PyCQA/pylint/issues/6003), use `UserT` instead.
* New: [Add common ec2 functions.](boto3.md#ec2)
    * [Get instance types](boto3.md#get-instance-types)
    * [Get instance prices](boto3.md#get-instance-prices)
* New: [Using `typing.cast`.](type_hints.md#using-`typing.cast`)
    Sometimes the type hints of your program don't work as you expect, if you've
    given up on fixing the issue you can `# type: ignore` it, but if you know what
    type you want to enforce, you can use
    [`typing.cast()`](https://docs.python.org/3/library/typing.html#typing.cast)
    explicitly or implicitly from `Any` with type hints. With casting we can force
    the type checker to treat a variable as a given type.
    The main case to reach for `cast()` are when the type hints for a module are
    either missing, incomplete, or incorrect. This may be the case for third party
    packages, or occasionally for things in the standard library.
    Take this example:
    ```python
    import datetime as dt
    from typing import cast
    from third_party import get_data
    data = get_data()
    last_import_time = cast(dt.datetime, data["last_import_time"])
    ```
    Imagine `get_data()` has a return type of `dict[str, Any]`, rather than using
    stricter per-key types with a `TypedDict`. From reading the documentation or
    source we might find that the `last_import_time` key always contains
    a `datetime` object. Therefore, when we access it, we can wrap it in a `cast()`,
    to tell our type checker the real type rather than continuing with `Any`.
    When we encounter missing, incomplete, or incorrect type hints, we can
    contribute back a fix. This may be in the package itself, its related stubs
    package, or separate stubs in Python’s typeshed. But until such a fix is
    released, we will need to use `cast()` to make our code pass type checking.
* New: [Update dockers with Renovate.](docker.md#with-renovate)
    [Renovate](renovate.md) is a program that does automated
    dependency updates. Multi-platform and multi-language.
* New: [Connect multiple docker compose files.](docker.md#connect-multiple-docker-compose-files)
    You can connect services defined across multiple docker-compose.yml files.
    In order to do this you’ll need to:
    * Create an external network with `docker network create `
    * In each of your `docker-compose.yml` configure the default network to use your
        externally created network with the networks top-level key.
    * You can use either the service name or container name to connect between containers.
* New: [Attach a docker to many networks.](docker.md#attach-a-docker-to-many-networks)
    You can't do it through the `docker run` command, there you can only specify one
    network. However, you can attach a docker to a network with the command:
    ```bash
    docker network attach network-name docker-name
    ```
### [Click](click.md)
* New: [File System Isolation.](click.md#file-system-isolation)
    For basic command line tools with file system operations, the
    `CliRunner.isolated_filesystem()` method is useful for setting the current
    working directory to a new, empty folder.
    ```python
    from click.testing import CliRunner
    from cat import cat
    def test_cat():
        runner = CliRunner()
        with runner.isolated_filesystem():
            with open("hello.txt", "w") as f:
                f.write("Hello World!")
            result = runner.invoke(cat, ["hello.txt"])
            assert result.exit_code == 0
            assert result.output == "Hello World!\n"
    ```
    Pass `temp_dir` to control where the temporary directory is created. The
    directory will not be removed by Click in this case. This is useful to integrate
    with a framework like Pytest that manages temporary files.
    ```python
    def test_keep_dir(tmp_path):
        runner = CliRunner()
        with runner.isolated_filesystem(temp_dir=tmp_path) as td:
            ...
    ```
### [Dash](pydantic_factories.md)
* Correction: Correct the type hints of the factory.
    Use `Any`
    ```python
    class PersonFactory(ModelFactory[Any]):
        ...
    ```
* New: [Track issue when using with.](pydantic_factories.md#issues)
* New: [Creating your custom factories.](pydantic_factories.md#creating-your-custom-factories)
    If your model has an attribute that is not supported by `pydantic-factories` and
    it depends on third party libraries, you can create your custom extension
    subclassing the `ModelFactory`, and overriding the `get_mock_value` method to
    add your logic.
    ```
    from pydantic_factories import ModelFactory