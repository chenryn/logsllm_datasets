# 12 \| 容器文件Quota：容器为什么把宿主机的磁盘写满了？你好，我是程远。今天我们聊一聊容器文件Quota。 上一讲，我们学习了容器文件系统 OverlayFS，这个 OverlayFS有两层，分别是 lowerdir 和 upperdir。lowerdir里是容器镜像中的文件，对于容器来说是只读的；upperdir存放的是容器对文件系统里的所有改动，它是可读写的。从宿主机的角度看，upperdir就是一个目录，如果容器不断往容器文件系统中写入数据，实际上就是往宿主机的磁盘上写数据，这些数据也就存在于宿主机的磁盘目录中。当然对于容器来说，如果有大量的写操作是不建议写入容器文件系统的，一般是需要给容器挂载一个volume，用来满足大量的文件读写。但是不能避免的是，用户在容器中运行的程序有错误，或者进行了错误的配置。比如说，我们把 log 写在了容器文件系统上，并且没有做 logrotation，那么时间一久，就会导致宿主机上的磁盘被写满。这样影响的就不止是容器本身了，而是整个宿主机了。那对于这样的问题，我们该怎么解决呢？问题再现我们可以自己先启动一个容器，一起试试不断地往容器文件系统中写入数据，看看是一个什么样的情况。用 Docker 启动一个容器后，我们看到容器的根目录 (/) 也就是容器文件系统OverlayFS，它的大小是 160G，已经使用了100G。其实这个大小也是宿主机上的磁盘空间和使用情况。![](Images/c36825d1aae0c7e12b1eb100ce7f094c.png)savepage-src="https://static001.geekbang.org/resource/image/d3/3e/d32c83e404a81b301fbf8bdfd7a9c23e.png"}这时候，我们可以回到宿主机上验证一下，就会发现宿主机的根目录 (/)的大小也是 160G，同样是使用了100G。 ![](Images/a6a4a5c0798f91344ef826318bd6f9da.png)savepage-src="https://static001.geekbang.org/resource/image/b5/0b/b54deb08e46ff1155303581e9d1c8f0b.png"}好，那现在我们再往容器的根目录里写入 10GB的数据。 这里我们可以看到容器的根目录使用的大小增加了，从刚才的 100G变成现在的 110G。而多写入的 10G 大小的数据，对应的是 test.log这个文件。 ![](Images/74e171ca360426c75d9c0b4015161638.png)savepage-src="https://static001.geekbang.org/resource/image/c0/46/c04dcff3aa4773302495113dd2a8d546.png"}接下来，我们再回到宿主机上，可以看到宿主机上的根目录 (/)里使用的大小也是 110G 了。![](Images/530804c975c857204835090517d06374.png)savepage-src="https://static001.geekbang.org/resource/image/15/9d/155d30bc20b72c0678d1948f25cbe29d.png"}我们还是继续看宿主机，看看 OverlayFS 里 upperdir目录中有什么文件？这里我们仍然可以通过 /proc/mounts 这个路径，找到容器 OverlayFS 对应的lowerdir 和 upperdir。因为写入的数据都在 upperdir 里，我们就只要看upperdir 对应的那个目录就行了。果然，里面存放着容器写入的文件test.log，它的大小是 10GB。![](Images/136d90bc2fb6771e11966b29b9d52892.png)savepage-src="https://static001.geekbang.org/resource/image/4d/7d/4d32334dc0f1ba69881c686037f6577d.png"}通过这个例子，我们已经验证了在容器中对于 OverlayFS中写入数据，**其实就是往宿主机的一个目录（upperdir）里写数据。**我们现在已经写了 10GB的数据，如果继续在容器中写入数据，结果估计你也知道了，就是会写满宿主机的磁盘。那遇到这种情况，我们该怎么办呢？知识详解容器写自己的 OverlayFS根目录，结果把宿主机的磁盘写满了。发生这个问题，我们首先就会想到需要对容器做限制，限制它写入自己OverlayFS 的数据量，比如只允许一个容器写 100MB的数据。 不过我们实际查看 OverlayFS文件系统的特性，就会发现没有直接限制文件写入量的特性。别担心，在没有现成工具的情况下，我们只要搞懂了原理，就能想出解决办法。所以我们再来分析一下 OverlayFS，它是通过 lowerdir 和 upperdir两层目录联合挂载来实现的，lowerdir 是只读的，数据只会写在 upperdir中。 那我们是不是可以通过限制 upperdir 目录容量的方式，来限制一个容器OverlayFS根目录的写入数据量呢？沿着这个思路继续往下想，因为 upperdir在宿主机上也是一个普通的目录，这样就要看**宿主机上的文件系统是否可以支持对一个目录限制容量了。**对于 Linux 上最常用的两个文件系统 XFS 和 ext4，它们有一个特性Quota，那我们就以 XFS 文件系统为例，学习一下这个 Quota概念，然后看看这个特性能不能限制一个目录的使用量。XFS Quota在 Linux 系统里的 XFS 文件系统缺省都有 Quota 的特性，这个特性可以为Linux系统里的一个用户（user），一个用户组（group）或者一个项目（project）来限制它们使用文件系统的额度（quota），也就是限制它们可以写入文件系统的文件总量。因为我们的目标是要限制一个目录中总体的写入文件数据量，那么显然给用户和用户组限制文件系统的写入数据量的模式，并不适合我们的这个需求。因为同一个用户或者用户组可以操作多个目录，多个用户或者用户组也可以操作同一个目录，这样对一个用户或者用户组的限制，就很难用来限制一个目录。那排除了限制用户或用户组的模式，我们再来看看 Project 模式。Project模式是怎么工作的呢？我举一个例子你会更好理解，对 Linux熟悉的同学可以一边操作，一边体会一下它的工作方式。不熟悉的同学也没关系，可以重点关注我后面的讲解思路。首先我们要使用 XFS Quota 特性，必须在文件系统挂载的时候加上对应的Quota 选项，比如我们目前需要配置 ProjectQuota，那么这个挂载参数就是\"pquota\"。对于根目录来说，**这个参数必须作为一个内核启动的参数\"rootflags=pquota\"，这样设置就可以保证根目录在启动挂载的时候，带上XFS Quota 的特性并且支持 Project模式。** 我们可以从 /proc/mounts信息里，看看根目录是不是带\"prjquota\"字段。如果里面有这个字段，就可以确保文件系统已经带上了支持project 模式的 XFS quota 特性。![](Images/e837543f64590c99417091854b0cc546.png)savepage-src="https://static001.geekbang.org/resource/image/72/3d/72d653f67717fe047c98fce37156da3d.png"}下一步，我们还需要给一个指定的目录打上一个 ProjectID。这个步骤我们可以使用 XFS 文件系统自带的工具xfs_quota来完成，然后执行下面的这个命令就可以了。执行命令之前，我先对下面的命令和输出做两点解释，让你理解这个命令的含义。第一点，新建的目录 /tmp/xfs_prjquota，我们想对它做 Quota限制。所以在这里要对它打上一个 ProjectID。 第二点，通过 xfs_quota 这条命令，我们给 /tmp/xfs_prjquota 打上Project ID 值 101，这个 101 是我随便选的一个数字，就是个 ID标识，你先有个印象。在后面针对 Project 进行 Quota限制的时候，我们还会用到这个ID。     
# mkdir -p  /tmp/xfs_prjquota    
# xfs_quota -x -c 'project -s -p /tmp/xfs_prjquota 101' /    Setting up project 101 (path /tmp/xfs_prjquota)...    Processed 1 (/etc/projects and cmdline) paths for project 101 with recursion depth infinite (-1).最后，我们还是使用 xfs_quota 命令，对 101（我们刚才建立的这个 ProjectID）做 Quota 限制。你可以执行下面这条命令，里面的\"-p bhard=10m 101\"就代表限制 101 这个project ID，限制它的数据块写入量不能超过10MB。     
# xfs_quota -x -c 'limit -p bhard=10m 101' /做好限制之后，我们可以尝试往 /tmp/xfs_prjquota写数据，看看是否可以超过 10MB。比如说，我们尝试写入 20MB 的数据到/tmp/xfs_prjquota 里。我们可以看到，执行 dd 写入命令，就会有个出错返回信息\"No space leftondevice\"。这表示已经不能再往这个目录下写入数据了，而最后写入数据的文件test.file 大小也停留在了 10MB。    
# dd if=/dev/zero of=/tmp/xfs_prjquota/test.file bs=1024 count=20000    dd: error writing '/tmp/xfs_prjquota/test.file': No space left on device    10241+0 records in    10240+0 records out    10485760 bytes (10 MB, 10 MiB) copied, 0.0357122 s, 294 MB/s    
# ls -l /tmp/xfs_prjquota/test.file    -rw-r--r-- 1 root root 10485760 Oct 31 10:00 /tmp/xfs_prjquota/test.file好了，做到这里，我们发现使用 XFS Quota 的 Project模式，确实可以限制一个目录里的写入数据量，它实现的方式其实也不难，就是下面这两步。第一步，给目标目录打上一个 Project ID，这个 ID 最终是写到目录对应的inode 上。 这里我解释一下，inode是文件系统中用来描述一个文件或者一个目录的元数据，里面包含文件大小，数据块的位置，文件所属用户/组，文件读写属性以及其他一些属性。那么一旦目录打上这个 ID之后，在这个目录下的新建的文件和目录也都会继承这个ID。 第二步，在 XFS 文件系统中，我们需要给这个 project ID设置一个写入数据块的限制。有了 ID 和限制值之后，文件系统就可以统计所有带这个 ID文件的数据块大小总和，并且与限制值进行比较。一旦所有文件大小的总和达到限制值，文件系统就不再允许更多的数据写入了。用一句话概括，XFS Quota就是通过前面这两步限制了一个目录里写入的数据量。解决问题我们理解了 XFS Quota对目录限流的机制之后，再回到我们最开始的问题，如何确保容器不会写满宿主机上的磁盘。你应该已经想到了，方法就是**对 OverlayFS 的 upperdir 目录做 XFS Quota的限流**，没错，就是这个解决办法！其实 Docker 也已经实现了限流功能，也就是用 XFS Quota 来限制容器的OverlayFS 大小。我们在用 `docker run` 启动容器的时候，加上一个参数`--storage-opt size= ` ，就能限制住容器 OverlayFS文件系统可写入的最大数据量了。我们可以一起试一下，这里我们限制的 size 是10MB。 进入容器之后，先运行 `df -h` 命令，这时候你可以看到根目录 (/)overlayfs文件系统的大小就 10MB，而不是我们之前看到的 160GB的大小了。这样容器在它的根目录下，最多只能写 10MB数据，就不会把宿主机的磁盘给写满了。![](Images/d6c65e47d669fbd3c05a583384cb7373.png)savepage-src="https://static001.geekbang.org/resource/image/a7/8a/a7906f56d9d107f0a290e610b8cd6f8a.png"}完成了上面这个小试验之后，我们可以再看一下 Docker的代码，看看它的实现是不是和我们想的一样。Docker 里SetQuota()函数就是用来实现 XFS Quota限制的，我们可以看到它里面最重要的两步，分别是 `setProjectID`和 `setProjectQuota`。 其实，这两步做的就是我们在基本概念中提到的那两步：第一步，给目标目录打上一个 Project ID；第二步，为这个 Project ID 在XFS文件系统中，设置一个写入数据块的限制。    // SetQuota - assign a unique project id to directory and set the quota limits    // for that project id    func (q *Control) SetQuota(targetPath string, quota Quota) error {            q.RLock()            projectID, ok := q.quotas[targetPath            q.RUnlock()            if !ok {                    q.Lock()                    projectID = q.nextProjectID                    //                    // assign project id to new container directory                    //                    err := setProjectID(targetPath, projectID)                    if err != nil {                            q.Unlock()                            return err                    }                    q.quotas[targetPath] = projectID                    q.nextProjectID++                    q.Unlock()            }                 //            // set the quota limit for the container's project id            //            logrus.Debugf("SetQuota(%s, %d): projectID=%d", targetPath, quota.Size, projectID)            return setProjectQuota(q.backingFsBlockDev, projectID, quota)    }那  `setProjectID`和 `setProjectQuota`是如何实现的呢？你可以进入到这两个函数里看一下，**它们分别调用了 ioctl() 和 quotactl()这两个系统调用来修改内核中 XFS 的数据结构，从而完成 project ID 的设置和Quota 值的设置。**具体的细节，我不在这里展开了，如果你有兴趣，可以继续去查看内核中对应的代码。好了，Docker 里 XFS Quota操作的步骤完全和我们先前设想的一样，那么还有最后一个问题要解决，XFSQuota 限制的目录是哪一个？这个我们可以根据 /proc/mounts 中容器的 OverlayFS Mount 信息，再结合Docker 的代码slate-object="inline"，就可以知道限制的目录是\"/var/lib/docker/overlay2/\\"。那这个目录下有什么呢？果然upperdir目录中有对应的\"diff\"目录，就在里面！![](Images/f61912de258cc687227613627b5f61e5.png)savepage-src="https://static001.geekbang.org/resource/image/4d/9f/4d4d995f052c9a8e3ff3e413c0e1199f.png"}讲到这里，我想你已经清楚了对于使用 OverlayFS的容器，我们应该如何去防止它把宿主机的磁盘给写满了吧？**方法就是对 OverlayFS 的 upperdir 目录做 XFS Quota的限流。** 重点总结我们这一讲的问题是，容器写了大量数据到 OverlayFS文件系统的根目录，在这个情况下，就会把宿主机的磁盘写满。由于 OverlayFS自己没有专门的特性，可以限制文件数据写入量。这时我们通过实际试验找到了解决思路：依靠底层文件系统的Quota 特性来限制 OverlayFS 的 upperdir目录的大小，这样就能实现限制容器写磁盘的目的。底层文件系统 XFS Quota 的 Project模式，能够限制一个目录的文件写入量，这个功能具体是通过这两个步骤实现：第一步，给目标目录打上一个 ProjectID。 第二步，给这个 Project ID 在 XFS文件系统中设置一个写入数据块的限制。Docker正是使用了这个方法，也就是**用 XFS Quota 来限制 OverlayFS 的 upperdir目录**，通过这个方式控制容器 OverlayFS的根目录大小。当我们理解了这个方法后，对于不是用 Docker 启动的容器，比如直接由containerd 启动起来的容器，也可以自己实现 XFS Quota 限制 upperdir目录。这样就能有效控制容器对 OverlayFS的写数据操作，避免宿主机的磁盘被写满。思考题在正文知识详解的部分，我们使用\"xfs_quota\"给目录打了 project ID并且限制了文件写入的数据量。那在做完这样的限制之后，我们是否能用xfs_quota 命令，查询到被限制目录的 project ID和限制的数据量呢？欢迎你在留言区分享你的思考或疑问。如果这篇文章让你有所收获，也欢迎转发给你的同事、朋友，一起交流和学习。
# 13 \| 容器磁盘限速：我的容器里磁盘读写为什么不稳定?你好，我是程远。今天我们聊一聊磁盘读写不稳定的问题。上一讲，我给你讲了如何通过 XFS Quota来限制容器文件系统的大小，这是静态容量大小的一个限制。你也许会马上想到，磁盘除了容量的划分，还有一个读写性能的问题。具体来说，就是如果多个容器同时读写节点上的同一块磁盘，那么它们的磁盘读写相互之间影响吗？如果容器之间读写磁盘相互影响，我们有什么办法解决呢？接下来，我们就带着问题一起学习今天的内容。场景再现我们先用这里的代码，运行一下 `make image`来做一个带 fio 的容器镜像，fio在我们之前的课程里提到过，它是用来测试磁盘文件系统读写性能的工具。有了这个带 fio 的镜像，我们可以用它启动一个容器，在容器中运行fio，就可以得到只有一个容器读写磁盘时的性能数据。    mkdir -p /tmp/test1    docker stop fio_test1;docker rm fio_test1    docker run --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test1.log上面的这个 Docker命令，我给你简单地解释一下：在这里我们第一次用到了\"\--volume\"这个参数。之前我们讲过容器文件系统，比如OverlayFS。 不过容器文件系统并不适合频繁地读写。对于频繁读写的数据，容器需要把他们到放到\"volume\"中。这里的volume可以是一个本地的磁盘，也可以是一个网络磁盘。在这个例子里我们就使用了宿主机本地磁盘，把磁盘上的 /tmp/test1目录作为 volume 挂载到容器的 /tmp目录下。 然后在启动容器之后，我们直接运行 fio的命令，这里的参数和我们第 11 讲slate-object="inline"最开始的例子差不多，只是这次我们运行的是write，也就是写磁盘的操作，而写的目标盘就是挂载到 /tmp 目录的volume。 可以看到，fio 的运行结果如下图所示，IOPS 是 18K，带宽 (BW) 是 70MB/s左右。 ![](Images/23db24d7da44d9dcf00f4020b9056b2e.png)savepage-src="https://static001.geekbang.org/resource/image/a8/54/a8a156d4a543bc02133751a14ba5a354.png"}好了，刚才我们模拟了一个容器写磁盘的性能。那么如果这时候有两个容器，都在往同一个磁盘上写数据又是什么情况呢？我们可以再用下面的这个脚本试一下：    mkdir -p /tmp/test1    mkdir -p /tmp/test2    docker stop fio_test1;docker rm fio_test1    docker stop fio_test2;docker rm fio_test2    docker run --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test1.log &    docker run --name fio_test2 --volume /tmp/test2:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test2.log &这时候，我们看到的结果，在容器 fio_test1 里，IOPS 是 15K 左右，带宽是59MB/s了，比之前单独运行的时候性能下降了不少。![](Images/f45312b8153cf4f2e4206cfaf6e302cc.png)savepage-src="https://static001.geekbang.org/resource/image/cb/64/cb2f19b2da651b03521804e22f14b864.png"}显然从这个例子中，我们可以看到多个容器同时写一块磁盘的时候，它的性能受到了干扰。那么有什么办法可以保证每个容器的磁盘读写性能呢？之前，我们讨论过用 Cgroups 来保证容器的 CPU 使用率，以及控制 Memroy的可用大小。那么你肯定想到了，我们是不是也可以用 Cgroups来保证每个容器的磁盘读写性能？没错，在 Cgroup v1 中有 blkio 子系统，它可以来限制磁盘的 I/O。不过blkio 子系统对于磁盘 I/O 的限制，并不像 CPU，Memory那么直接，下面我会详细讲解。知识详解Blkio Cgroup在讲解 blkio Cgroup前，我们先简单了解一下衡量磁盘性能的**两个常见的指标 IOPS和吞吐量（Throughput）**是什么意思，后面讲 Blkio Cgroup的参数配置时会用到。IOPS 是 Input/Output Operations Per Second的简称，也就是每秒钟磁盘读写的次数，这个数值越大，当然也就表示性能越好。吞吐量（Throughput）是指每秒钟磁盘中数据的读取量，一般以 MB/s为单位。这个读取量可以叫作吞吐量，有时候也被称为带宽（Bandwidth）。刚才我们用到的fio 显示结果就体现了带宽。IOPS 和吞吐量之间是有关联的，在 IOPS固定的情况下，如果读写的每一个数据块越大，那么吞吐量也越大，它们的关系大概是这样的：吞吐量= 数据块大小 \*IOPS。好，那么我们再回到 blkio Cgroup 这个概念上，blkio Cgroup 也是 Cgroups里的一个子系统。 在 Cgroups v1 里，blkio Cgroup的虚拟文件系统挂载点一般在\"/sys/fs/cgroup/blkio/\"。和我之前讲过的 CPU，memory Cgroup一样，我们在这个\"/sys/fs/cgroup/blkio/\"目录下创建子目录作为控制组，再把需要做I/O 限制的进程 pid 写到控制组的 cgroup.procs参数中就可以了。在 blkio Cgroup 中，有四个最主要的参数，它们可以用来限制磁盘 I/O性能，我列在了下面。    blkio.throttle.read_iops_device    blkio.throttle.read_bps_device    blkio.throttle.write_iops_device    blkio.throttle.write_bps_device前面我们刚说了磁盘 I/O 的两个主要性能指标 IOPS和吞吐量，在这里，根据这四个参数的名字，估计你已经大概猜到它们的意思了。没错，它们分别表示：磁盘读取 IOPS 限制，磁盘读取吞吐量限制，磁盘写入IOPS 限制，磁盘写入吞吐量限制。对于每个参数写入值的格式，你可以参考内核blkio 的文档slate-object="inline"。为了让你更好地理解，在这里我给你举个例子。如果我们要对一个控制组做限制，限制它对磁盘 /dev/vdb的写入吞吐量不超过 10MB/s，那么我们对 blkio.throttle.write_bps_device参数的配置就是下面这个命令。    echo "252:16 10485760" > $CGROUP_CONTAINER_PATH/blkio.throttle.write_bps_device在这个命令中，\"252:16\"是 /dev/vdb 的主次设备号，你可以通过 `ls -l /dev/vdb`看到这两个值，而后面的\"10485760\"就是 10MB的每秒钟带宽限制。    
# ls -l /dev/vdb -l    brw-rw---- 1 root disk 252, 16 Nov  2 08:02 /dev/vdb了解了 blkio Cgroup的参数配置，我们再运行下面的这个例子，限制一个容器 blkio的读写磁盘吞吐量，然后在这个容器里运行一下fio，看看结果是什么。    mkdir -p /tmp/test1    rm -f /tmp/test1/*    docker stop fio_test1;docker rm fio_test1    docker run -d --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 sleep 3600    sleep 2    CONTAINER_ID=$(sudo docker ps --format "{{.ID}}\t{{.Names}}" | grep -i fio_test1 | awk '{print $1}')    echo $CONTAINER_ID    CGROUP_CONTAINER_PATH=$(find /sys/fs/cgroup/blkio/ -name "*$CONTAINER_ID*")    echo $CGROUP_CONTAINER_PATH    
# To get the device major and minor id from /dev for the device that /tmp/test1 is on.    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH/blkio.throttle.read_bps_device    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH/blkio.throttle.write_bps_device    docker exec fio_test1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log    docker exec fio_test1 fio -direct=1 -rw=read -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log在这里，我的机器上 /tmp/test1所在磁盘主次设备号是"253:0"，你在自己运行这组命令的时候，需要把主次设备号改成你自己磁盘的对应值。还有一点我要提醒一下，不同数据块大小，在性能测试中可以适用于不同的测试目的。但因为这里不是我们要讲的重点，所以为了方便你理解概念，这里就用固定值。在我们后面的例子里，fio 读写的数据块都固定在4KB。所以对于磁盘的性能限制，我们在 blkio Cgroup里就只设置吞吐量限制了。在加了 blkio Cgroup 限制 10MB/s 后，从 fio运行后的输出结果里，我们可以看到这个容器对磁盘无论是读还是写，它的最大值就不会再超过10MB/s 了。 ![](Images/40bd4d165d174a6a4563651e6ac77322.png)savepage-src="https://static001.geekbang.org/resource/image/e2/b3/e26118e821a4b936521eacac924c7db3.png"}![](Images/d20f09f220d19ec82ce7203e788ad950.png)savepage-src="https://static001.geekbang.org/resource/image/0a/f5/0ae074c568161d24e57d37d185a47af5.png"}在给每个容器都加了 blkio Cgroup 限制，限制为 10MB/s后，即使两个容器同时在一个磁盘上写入文件，那么每个容器的写入磁盘的最大吞吐量，也不会互相干扰了。我们可以用下面的这个脚本来验证一下。    #!/bin/bash    mkdir -p /tmp/test1    rm -f /tmp/test1/*    docker stop fio_test1;docker rm fio_test1    mkdir -p /tmp/test2    rm -f /tmp/test2/*    docker stop fio_test2;docker rm fio_test2    docker run -d --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 sleep 3600    docker run -d --name fio_test2 --volume /tmp/test2:/tmp  registery/fio:v1 sleep 3600    sleep 2    CONTAINER_ID1=$(sudo docker ps --format "{{.ID}}\t{{.Names}}" | grep -i fio_test1 | awk '{print $1}')    echo $CONTAINER_ID1    CGROUP_CONTAINER_PATH1=$(find /sys/fs/cgroup/blkio/ -name "*$CONTAINER_ID1*")    echo $CGROUP_CONTAINER_PATH1    
# To get the device major and minor id from /dev for the device that /tmp/test1 is on.    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH1/blkio.throttle.read_bps_device    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH1/blkio.throttle.write_bps_device    CONTAINER_ID2=$(sudo docker ps --format "{{.ID}}\t{{.Names}}" | grep -i fio_test2 | awk '{print $1}')    echo $CONTAINER_ID2    CGROUP_CONTAINER_PATH2=$(find /sys/fs/cgroup/blkio/ -name "*$CONTAINER_ID2*")    echo $CGROUP_CONTAINER_PATH2    
# To get the device major and minor id from /dev for the device that /tmp/test1 is on.    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH2/blkio.throttle.read_bps_device    echo "253:0 10485760" > $CGROUP_CONTAINER_PATH2/blkio.throttle.write_bps_device    docker exec fio_test1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log &    docker exec fio_test2 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test2.log &我们还是看看 fio 运行输出的结果，这时候，fio_test1 和 fio_test2两个容器里执行的结果都是 10MB/s了。 ![](Images/d9ca21124a285b8f75323060089c6630.png)savepage-src="https://static001.geekbang.org/resource/image/67/a9/6719cc30a8e2933dae1ba6f96235e4a9.png"}![](Images/d91cbb027126df5608329a3e44bacf07.png)savepage-src="https://static001.geekbang.org/resource/image/de/c8/de4be66c72ff9e4cdc5007fe71f848c8.png"}那么做到了这一步，我们是不是就可以认为，blkio Cgroup 可以完美地对磁盘I/O 做限制了呢？你先别急，我们可以再做个试验，把前面脚本里 fio 命令中的 "-direct=1"给去掉，也就是不让 fio 运行在 Direct I/O 模式了，而是用 Buffered I/O模式再运行一次，看看 fio执行的输出。同时我们也可以运行 iostat命令，查看实际的磁盘写入速度。这时候你会发现，即使我们设置了 blkioCgroup，也根本不能限制磁盘的吞吐量了。Direct I/O 和 Buffered I/O为什么会这样的呢？这就要提到 Linux 的两种文件 I/O 模式了：Direct I/O和 Buffered I/O。Direct I/O 模式，用户进程如果要写磁盘文件，就会通过 Linux内核的文件系统层 (filesystem) -\> 块设备层 (block layer) -\> 磁盘驱动-\>磁盘硬件，这样一路下去写入磁盘。而如果是 Buffered I/O模式，那么用户进程只是把文件数据写到内存中（Page Cache）就返回了，而Linux内核自己有线程会把内存中的数据再写入到磁盘中。**在 Linux 里，由于考虑到性能问题，绝大多数的应用都会使用Buffered I/O 模式。**![](Images/a0f67ebbbbc5557dcdaf5c99c82a566b.png)savepage-src="https://static001.geekbang.org/resource/image/10/46/1021f5f7ec700f3c7c66cbf8e07b1a46.jpeg"}我们通过前面的测试，发现 Direct I/O 可以通过 blkio Cgroup 来限制磁盘I/O，但是 Buffered I/O不能被限制。那通过上面的两种 I/O模式的解释，你是不是可以想到原因呢？是的，原因就是被 Cgroups v1的架构限制了。我们已经学习过了 v1 的 CPU Cgroup，memory Cgroup 和 blkioCgroup，那么 Cgroup v1的一个整体结构，你应该已经很熟悉了。它的每一个子系统都是独立的，资源的限制只能在子系统中发生。就像下面图里的进程 pid_y，它可以分别属于 memory Cgroup 和 blkioCgroup。但是在 blkio Cgroup 对进程 pid_y 做磁盘 I/O 做限制的时候，blkio子系统是不会去关心 pid_y 用了哪些内存，哪些内存是不是属于 PageCache，而这些 Page Cache 的页面在刷入磁盘的时候，产生的 I/O也不会被计算到进程 pid_y 上面。就是这个原因，导致了 blkio 在 Cgroups v1 里不能限制 BufferedI/O。 ![](Images/e6a89d666b2420293d69509554ec3785.png)savepage-src="https://static001.geekbang.org/resource/image/32/ba/32c69a6f69c4ce7f11c842450fe7d9ba.jpeg"}这个 Buffered I/O 限速的问题，在 Cgroup V2里得到了解决，其实这个问题也是促使 Linux 开发者重新设计 Cgroup V2的原因之一。Cgroup V2Cgroup v2 相比 Cgroup v1做的最大的变动就是一个进程属于一个控制组，而每个控制组里可以定义自己需要的多个子系统。比如下面的 Cgroup V2 示意图里，进程 pid_y 属于控制组 group2，而在group2 里同时打开了 io 和 memory 子系统 （Cgroup V2 里的 io子系统就等同于 Cgroup v1 里的 blkio子系统）。 那么，Cgroup 对进程 pid_y 的磁盘 I/O 做限制的时候，就可以考虑到进程pid_y 写入到 Page Cache 内存的页面了，这样 buffered I/O的磁盘限速就实现了。![](Images/9e335f68ae8d9872080b733e04b33038.png)savepage-src="https://static001.geekbang.org/resource/image/8a/46/8ae3f3282b9f19720b764c696959bf46.jpeg"}下面我们在 Cgroup v2 里，尝试一下设置了 blkio Cgroup+Memory Cgroup之后，是否可以对 Buffered I/O进行磁盘限速。我们要做的第一步，就是在 Linux 系统里打开 Cgroup v2的功能。因为目前即使最新版本的 Ubuntu Linux 或者 CentosLinux，仍然在使用 Cgroup v1 作为缺省的Cgroup。 打开方法就是配置一个 kernel参数\"cgroup_no_v1=blkio,memory\"，这表示把 Cgroup v1 的 blkio 和 Memory两个子系统给禁止，这样 Cgroup v2 的 io 和 Memory这两个子系统就打开了。我们可以把这个参数配置到 grub 中，然后我们重启 Linux 机器，这时Cgroup v2 的 io 还有 Memory这两个子系统，它们的功能就打开了。系统重启后，我们会看到 Cgroup v2 的虚拟文件系统被挂载到了/sys/fs/cgroup/unified 目录下。然后，我们用下面的这个脚本做 Cgroup v2 io 的限速配置，并且运行fio，看看 buffered I/O是否可以被限速。    