### 基于机器学习与大数据的智能运维平台

#### 表一：项目基本情况表
#### 表二：项目完成情况表
2020年9月28日 星期一

---

## 证券期货科学技术奖励推荐书

### 表1：项目基本情况表

#### 一、项目基本情况
- **项目名称**：
  - 中文：基于机器学习与大数据的智能运维平台
  - 英文：AIOps Platform based on Machine Learning and Big Data
- **主题词**：AIOps；机器学习；大数据；搜索存储引擎
- **成果类别**：技术推广应用
- **任务来源**：自选项目
- **计划(基金)名称和编号**：无
- **项目起止时间**：2017年12月5日至2018年8月23日

#### 二、项目简介
1. **项目名称**：基于机器学习与大数据的智能运维平台
2. **项目所属科学技术领域**：AIOps、机器学习、大数据、搜索存储引擎
3. **主要内容简介**：
   - 2016年，Gartner提出AIOps概念，通过AI和大数据提升运维水平。我们与多家券商、银行及互联网机构交流后发现，尽管互联网行业已有多个AIOps实践案例，但在证券行业仍处于探索阶段。
   - 2017年，我们完成了统一监控平台、大数据平台和云平台的优化建设，为实施AIOps提供了必要条件。同年，启动了智能运维平台建设项目，旨在通过对运行和运维数据的深度挖掘，提升现有运维水平，并探索智能运维在证券行业的实施路径。
   - 针对证券行业系统高可用性和连续性的要求，我们选择了实时异常监测、故障定位及原因分析作为建设方向。通过与顶尖高校和一流数据处理厂商合作，成功上线了智能运维平台。
   - 该平台以应用为视角，通过深度挖掘业务数据、运行数据和工单数据，形成关键运行指标和系统画像，结合无监督智能算法进行实时监测。在发现异常后，自动触发多指标异常定位和日志异常分析，整个过程可在分钟级别完成，有效帮助运维人员及时发现并修复问题，提高系统可用性和RTO水平。
   - 平台的核心技术包括数据处理、搜索存储和智能运维算法，在国内外同类产品和技术中处于领先地位。
   - 2018年，我们的智能运维平台参与了上海证券交易所“基于大数据与机器学习的证券行业智能运维体系建设”研究课题，并在同类课题中评分排名第一，被评为优秀课题，为AIOps在证券行业的落地提供了重要参考。

（纸面不敷，可另增页）

#### 三、项目详细内容

##### 1. 立项背景
- 券商作为最早实现电子化的金融机构之一，积累了大量稳态业务系统的软硬件基础架构运维数据和经验。随着市场竞争加剧，要求券商快速响应业务迭代发展，在双态IT运维环境中，如何持续保证业务系统的安全稳定高效运行，成为一大挑战。
- 2016年，Gartner提出的AIOps概念为提升运维水平提供了新思路。然而，金融行业在AIOps方面仍处于探索阶段，主要原因是基础平台建设和算法研究不足。
- 我司在2017年完成了云平台、监控平台和大数据平台的优化升级，具备实施AIOps的必要条件。我们开始研究相关算法在指标异常检测和容量预测方面的应用，并取得了一些成效。同年，我们引入了国内顶级高校和一流数据处理厂商作为合作伙伴，共同推进智能运维平台的建设。

##### 2. 详细科学技术内容
- **AIOps智能运维全景化应用**
  - **基于无监督学习技术的单指标异常检测技术**：通过对业务日志统计数据、抓包统计数据或机器指标数据的采集，检测具有时序特征或周期特征的时间数据。利用变分自编码器、渐进梯度回归树和差分指数滑动平均等算法，对不同特征的指标进行训练并形成模型。
  - **海量机器指标智能异常定位技术**：通过PageRank算法，快速定位大面积业务系统故障中的根因系统，并按根因疑似率排序，帮助运维人员快速排查故障。
  - **基于自然语言处理技术的日志聚类和日志异常定位技术**：构建频繁项前缀树结构，从日志消息中提取事件，支持增量式学习，高效映射日志模板，应对日志规模巨大、设备变更和日志结构复杂的问题。通过日志异常检测机制，准确解析和检测数据中心各种型号设备或应用的异常日志，提高数据中心稳定性。
  - **智能运维知识图谱**：基于指标异常检测和定位技术，构建运维领域的知识图谱，通过CMDB技术和机器学习抽象化故障领域内的知识，实现不同系统和层级之间的数据调度、算法编排和模型管理，增强系统平台性和扩展性。

- **运维数据工厂**
  - **海量全种类运维数据集中收集与存储**：采用高可用、高可靠的分布式架构，支持各类数据发送方的定制，满足数据的真实性、安全性和完整性要求。提供数据采集、处理、存储等功能，支持多种数据格式。
  - **数据接入**：根据数据来源的不同，采用有代理和无代理方式采集数据，实现采集策略的定制下发、采集代理的管理和采集延迟、补采的处理。
  - **数据总线层**：提供数据缓存与处理，通过Kafka等消息总线进行ETL处理，过滤、切分、扩展等操作，处理后的数据进入流式计算。
  - **数据计算层**：实现实时计算（如指标异常、日志关键字告警）和离线计算（如数据基线、预测），定期进行跑批训练数据模型。
  - **数据存储层**：根据应用场景和数据类型选择不同的存储方式，如日志数据存储到Beaver，性能数据存储到InfluxDB，关系数据存储到MySQL，图形数据存储到Neo4j，历史数据存储到HDFS，计算模型存储到MongoDB等。

基于每个模块都可横向扩展的架构设计，整体吞吐量和性能随节点增多而线性提升。

（纸面不敷，可另增页）

---

希望以上优化后的文本更加清晰、连贯和专业。如果有进一步的需求或修改，请随时告知。