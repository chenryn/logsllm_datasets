use as the axioms φi the Horn clauses that result from the
translation of AIF and as the conjecture φ we use simply
attack . When SPASS returns “proof found”, we know that
there is indeed an attack (against the abstract model), as
that can be derived from the Horn clauses in any interpreta-
tion of the symbols, including the free algebra interpretation.
When SPASS however returns “completion found”, then for
at least one interpretation, attack cannot be derived. Of
course this means, that the attack cannot be derived in the
free algebra interpretation (because if it can be derived in
the free algebra interpretation, then it can be derived in any
interpretation). Thus if SPASS ﬁnds a completion, we know
the given protocol is secure in the abstract model with the
free algebra interpretation [21] and by the soundness also in
the concrete model.
The translation to ProVerif is similar, where we may ex-
ploit domain-speciﬁc optimizations, such as treatment of
the intruder-knowledge fact.
In general it turns out that
ProVerif is faster than SPASS in ﬁnding results, see Table 1,
which is not surprising as ProVerif is a dedicated, specialized
tool. (The exception where ProVerif times out is discussed
below.) We have noted the number of agents that were used
in each example, and it can be seen that this has a major
inﬂuence on the run-time. This is of course due to the fact
that with the number of agents, also the number N of sets in
our model increases and the number of equivalence classes
underlying the abstraction is 2N .
358Problem
Agents
Result
Key-server example
SEVECOM (one key)
(both keys)
ASW
TLS (simpliﬁed)
NSL (w. conf. ch.)
NSPK (w. conf. ch.)
a, i, s
a, b, c, i, s
hsm, auth, i
hsm, auth, i
a, i, s
a, i
a, b, i
a, b, i
a, b, i
safe
safe
safe
unsafe
safe
safe
safe
safe
unsafe
SPASS ProVerif
Time
1s
37s
12s
0s
3hrs
1s
75s
17s
0s
Time
0s
0s
0s
timeout
6min
0s
13s
0s
0s
Table 1: Experimental results using SPASS and ProVerif
As the ﬁrst concrete example, we have considered our key-
server example, albeit with several honest and dishonest
participants. The second example analyzes part of a sys-
tem for secure vehicle communication from the SEVECOM
project [18]. Here, each car has a hardware security module
HSM that, amongst others, stores two public root keys of
an authority (for verifying messages sent by the authority).
The reason for using two root key pairs is that even if one
private key is leaked, the authority can still safely update it
using the other. We have found some new attacks that were
missed in the analysis of [19], because that model does not
include the authority (and thus no legal update messages).
The attacks are practically limited as they require either
several updates within a short period of time or that there
is a confusion about which key has been leaked (i.e. the in-
truder knows one key and the authority updates the other).
We have veriﬁed the system under the following simple re-
striction (see [17] for other suggestions to avoid the attacks):
we assume that one of the two private keys is never leaked
and thus never needs an update, while the other key may
be leaked and updated any number of times. Under this
restriction, we can verify the following goals: the intruder
never ﬁnds out private keys (except for ones we give him
deliberately), he cannot insert into the HSM any keys he
generated himself, and he cannot re-insert old keys. Finally,
if we give the intruder both keys, the resulting trivial attack
is found by SPASS immediately while ProVerif times out.
The reason seems to be that ProVerif dives into the more
complicated derivations enabled by the additional intruder
knowledge before ﬁnding the attack. We will investigate
this behavior further as it occurred several times during our
experimentation with this example set.
The largest example, and in fact one of the original moti-
vations for this work, is the contract signing protocol ASW
based on optimistic fair-exchange [2]. Again, we restrict
our discussion to a short summary of ASW and highlighting
some key issues of the formalization in AIF, more details are
found in [17]. The idea is that two parties can sign a con-
tract in a fair way, i.e. such that ﬁnally either both parties
or no party has a valid contract. This requires in general a
trusted third party TTP, which for ASW is only needed for
resolving disputes. The TTP maintains a database of con-
tracts that it has processed so far, which are either aborted
or resolved. A resolve means that the TTP issues a valid
contract. Whenever an agent asks the TTP for an abort or
resolve, the TTP checks whether the contract in question is
already registered as aborted or resolved. If this is not the
case, then the request to abort or resolve is granted, other-
wise the agent gets the abort token or replacement contract
stored in the database.
The protocol is based on nonces to which the exchange is
bound. Therefore each agent including the TTP maintains
a database of nonces. The database stores for each nonce
to which parties it relates, to which contractual text, and
the status of the respective transaction. For the TTP, the
status is just aborted or revoked, for honest agents the sta-
tus is the stage in the protocol execution (there are several
rounds and exceptions). One of the major diﬃculties of this
case study is that the fair exchange relies on the assump-
tion of resilient channels between agents and the TTP, i.e.
the intruder (which may be a dishonest contractual partner)
cannot block the communication forever. For this, we use a
model where the request from the user and the answer from
the TTP happen in a single transition. Roughly speaking,
we have three cases for each party asking for an abort (and
three similar for resolve requests):
• The party is in a stage of the protocol execution where
it can ask for an abort, and the TTP has not previously
seen the nonce contained in the abort request, i.e.
it
was not involved in a resolve or an abort. Then we can
go to a state where both the party and the TTP have
noted the nonce as aborted.
• The other two rules are similar but for the case that
the TTP has already noted the nonce as aborted or as
resolved and this result is communicated to the agent.
While in general, the handling of resilient channels cannot
be done by such a contraction of several steps into a single
one, the model in this case covers all real executions if we
assume that no honest party sends several requests at a time
and that the TTP processes requests sequentially.
Another challenge are the goals of fair exchange itself,
namely when one party has a valid contract, then the other
one can eventually obtain one. This is in fact a liveness
property and cannot directly be expressed. We use here the
fact that every agent who does not obtain a contract will
eventually contact the trusted third party and get either an
abort or resolve. Thus, it is suﬃcient to check that we never
come to a state where one party has a valid contract and
the other one has an abort for that contract; this is a safety
property.
Finally, we have also considered some “normal” protocols
that do not rely on databases, namely a simpliﬁed version
of TLS, the famous ﬂawed NSPK and the ﬁxed variant by
Lowe (NSL). The reason is that these protocols are standard
examples. Also this demonstrates that we can use databases
359of nonces or keys as an alternative way to describe the rel-
evant state-information of agents. For NSPK and NSL we
use conﬁdential channels instead of public-key encryption.
The experimental results demonstrate that our abstrac-
tion approach is feasible for a variety of veriﬁcation problems
of security protocols and web services.
8. CONCLUSIONS
The abstraction and over-approximation of protocols and
web services by a set of Horn clauses is a very successful
method in practice [7, 11, 10, 21, 6]. In contrast to classical
model-checking approaches, this kind of over-approximation
does not suﬀer from the usual interleaving problems and can
verify protocols for an unbounded number of sessions. The
technique has however limitations for protocols and web ser-
vices that are based on databases of keys, contracts, or even
access rights, where revocation is possible, so that the set of
true facts does not monotonically grow with the transitions.
We present a new way of abstraction in the spirit of the
Horn clauses approach that can handle such databases and
thus broadens the scope of this abstraction method. The
abstraction of data we propose is based on the membership
of the data in the databases. The updating of the databases
requires also an update of the abstraction of the data which
we can declaratively express with a new form of rule we have
introduced, the term implication rule. We show how to en-
code this rule into standard Horn clauses. As a consequence
we can use with ProVerif an existing tool from the abstrac-
tion community, and even the general purpose ﬁrst-order
theorem prover SPASS. The SEVECOM and ASW exam-
ples show that our method is feasible for modeling complex
real-world systems with databases and APIs that, for rea-
sons of their non-monotonic behavior, were previously out of
the scope of the standard abstraction-based methods. While
the AIF-library is still small, this suggest that our method
is practically feasible to tackle exactly what is missing for
the veriﬁcation of more complex cryptographic systems.
[20] considers an abstraction of keys in an API by at-
tributes; this has some similarity with our set-membership
abstraction. However, the attributes in [20] are static (i.e.
set memberships cannot change).
Our new language AIF gives a convenient way of writing
speciﬁcations in an un-abstracted form. Still, AIF is too low-
level to be used by a protocol or web service designer. We
thus plan as part of future work to connect more high-level
languages. Also we plan to build a tool with native support
for the term-implication rules and for other improvements
speciﬁc to our approach. Further, the approach is currently
limited to a ﬁxed number N of sets; we plan to investigate
how we can avoid this limitation. Another interesting ques-
tion we want to consider is the relation of our approach to
two quite diﬀerent approaches, namely static analysis [9] and
type-based analysis [5], which, besides all diﬀerences, show
some similarities with our approach.
9. REFERENCES
[1] A. Armando, L. Compagna. SAT-based
Model-Checking for Security Protocols Analysis. Int.
J. of Information Security, 6(1):3–32, 2007.
[2] N. Asokan, V. Shoup, M. Waidner. Asynchronous
protocols for optimistic fair exchange. In IEEE
Symposium on Research in Security and Privacy,
86–99. 1998.
[3] AVISPA. Deliverable 2.3: The Intermediate Format,
2003. Available at
www.avispa-project.org/publications.html.
[4] D. Basin, S. M¨odersheim, L. Vigan`o. OFMC: A
symbolic model checker for security protocols. Int. J.
of Information Security, 4(3):181–208, 2005.
[5] J. Bengtson, K. Bhargavan, C. Fournet, A. D.
Gordon, S. Maﬀeis. Reﬁnement types for secure
implementations. In CSF, 17–32. 2008.
[6] K. Bhargavan, C. Fournet, A. D. Gordon, R. Pucella.
Tulafale: A security tool for web services. In FMCO,
197–222. 2003.
[7] B. Blanchet. An eﬃcient cryptographic protocol
veriﬁer based on prolog rules. In CSFW’01, 82–96.
IEEE Computer Society Press, 2001.
[8] B. Blanchet. Automatic veriﬁcation of
correspondences for security protocols. Journal of
Computer Security, 17(4):363–434, 2009.
[9] C. Bodei, M. Buchholtz, P. Degano, F. Nielson, H. R.
Nielson. Static validation of security protocols.
Journal of Computer Security, 13(3):347–390, 2005.
[10] Y. Boichut, P.-C. H´eam, O. Kouchnarenko, F. Oehl.
Improvements on the Genet and Klay technique to
automatically verify security protocols. In AVIS’04,
1–11. 2004.
[11] L. Bozga, Y. Lakhnech, M. Perin. Hermes: An
automatic tool for the veriﬁcation of secrecy in
security protocols. In CAV’03, LNCS 2725, 219–222.
Springer-Verlag, 2003.
[12] N. Durgin, P. Lincoln, J. Mitchell, A. Scedrov.
Undecidability of bounded security protocols. In
Formal methods and security Protocols. 1999.
[13] S. Even, O. Goldreich. On the security of multi-party
ping-pong protocols. In FOCS, 34–39. 1983.
[14] J. Heather, G. Lowe, S. Schneider. How to prevent
type ﬂaw attacks on security protocols. In CSFW’00.
IEEE Computer Society Press, 2000.
[15] G. Lowe. Casper: a Compiler for the Analysis of
Security Protocols. Journal of Computer Security,
6(1):53–84, 1998.
[16] S. M¨odersheim. On the Relationships between Models
in Protocol Veriﬁcation. J. of Information and
Computation, 206(2–4):291–311, 2008.
[17] S. M¨odersheim. Veriﬁcation based on set-abstraction
using the AIF framework. Tech. Rep. IMM-Technical
report-2010-09, DTU/IMM, 2010. Available at
www.imm.dtu.dk/~samo.
[18] SEVECOM. Deliverable 2.1-App.A: Baseline Security
Speciﬁcations, 2009. Available at www.sevecom.org.
[19] G. Steel. Towards a formal security analysis of the
Sevecom API. In ESCAR. 2009.
[20] G. Steel. Abstractions for Verifying Key Management
APIs. In SecReT. 2010.
[21] C. Weidenbach. Towards an automatic analysis of
security protocols. In CADE, LNCS 1632, 378–382.
Berlin, 1999.
[22] C. Weidenbach, R. A. Schmidt, T. Hillenbrand,
R. Rusev, D. Topic. System description: Spass version
3.0. In CADE, 514–520. 2007.
360