cryptographic algorithms, including AES, ECDSA and RSA, and
the evaluation suggests that the performance overhead due to the
protection is very small to the Apache HTTPS servers.
Acknowledgments. This research was supported in part by NSF
grants 1566444, 1750809, 1526493, 1618493, CNS-1527141 and ARO
W911NF1610127.
REFERENCES
[1] Gorka Irazoqui Apecechea, Mehmet Sinan Inci, Thomas Eisenbarth, and Berk
Sunar. 2014. Fine grain Cross-VM attacks on Xen and VMware are possible!. In
Cryptology ePrint Archive.
[2] Daniel J. Bernstein. 2005. Cache-timing attacks on AES. Technical Report.
[3] Joseph Bonneau and Ilya Mironov. 2006. Cache-Collision timing attacks against
AES. In Proceedings of Cryptographic Hardware and Embedded Systems (CHES’06).
[4] Intel Corporation. 2014. Intel 64 and IA-32 Architectures Software Developer’s
Manual, Combined Volumes: 1, 2A, 2B, 2C, 3A, 3B and 3C. (2014).
[5] Stephen Crane, Andrei Homescu, Stefan Brunthaler, Per Larsen, and Michael
Franz. 2015. Thwarting cache side-channel attacks through dynamic software
diversity. In ISOC Network and Distributed System Security Symposium.
[6] The Apache Software Foundation. 2017. ApacheBench: Apache HTTP server
benchmarking tool. (2017).
[7] Daniel Gruss, Julian Lettner, Felix Schuster, Olya Ohrimenko, Istvan Haller, and
Manuel Costa. 2017. Strong and Efficient Cache Side-Channel Protection using
Hardware Transactional Memory. In 26th USENIX Security Symposium.
[8] David Gullasch, Endre Bangerter, and Stephan Krenn. 2011. Cache games –
bringing access-based cache attacks on AES to practice. In 32nd IEEE Symposium
on Security and Privacy.
[9] Gorka Irazoqui, Thomas Eisenbarth, and Berk Sunar. 2015. S$A: A shared cache
attack that works across cores and defies VM sandboxing—and its application to
AES. In 36th IEEE Symposium on Security and Privacy.
[10] Taesoo Kim, Marcus Peinado, and Gloria Mainar-Ruiz. 2012. STEALTHMEM:
System-level protection against cache-based side channel attacks in the cloud. In
21st USENIX Security Symposium.
[11] Fangfei Liu, Qian Ge, Yuval Yarom, Frank Mckeen, Carlos Rozas, Gernot Heiser,
and Ruby B. Lee. 2016. CATalyst: Defeating last-level cache side channel attacks
in cloud computing. In 22nd IEEE Symposium on High Performance Computer
Architecture.
[12] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B. Lee. 2015. Last-
level cache side-channel attacks are practical. In 36th IEEE Symposium on Security
and Privacy.
[13] Yutao Liu, Yubin Xia, Haibing Guan, Binyu Zang, and Haibo Chen. 2014. Concur-
rent and consistent virtual machine introspection with hardware transactional
memory. In 20th International Symposium on High Performance Computer Archi-
tecture.
[14] David Molnar, Matt Piotrowski, David Schultz, and David Wagner. 2005. The
program counter security model: Automatic detection and removal of control-
flow side channel attacks. In 8th International Conference on Information Security
and Cryptology.
[15] David Mosberger and Tai Jin. 1998. Httperf – A tool for measuring web server
performance. ACM SIGMETRICS Performance Evaluation Review (1998).
[16] Michael Neve and Jean-Pierre Seifert. 2007. Advances on access-driven cache
attacks on AES. In 13th International Conference on Selected Areas in Cryptography.
[17] Dag Arne Osvik, Adi Shamir, and Eran Tromer. 2006. Cache attacks and counter-
measures: the case of AES. In 6th Cryptographers’ Track at the RSA Conference on
Topics in Cryptology.
[18] Colin Percival. 2005. Cache missing for fun and profit. In 2005 BSDCan.
[19] Himanshu Raj, Ripal Nathuji, Abhishek Singh, and Paul England. 2009. Resource
management for isolation enhanced cloud services. In ACM Cloud Computing
Security Workshop.
[20] Michael Schwarz, Samuel Weiser, Daniel Gruss, ClÃľmentine Maurice, and Stefan
Mangard. 2017. Malware Guard Extension: Using SGX to conceal cache attacks.
arXiv:1702.08719. (2017). https://arxiv.org/abs/1702.08719.
[21] Eran Tromer, Dag Arne Osvik, and Adi Shamir. 2010. Efficient cache attacks on
AES, and countermeasures. Journal of Cryptology 23, 2 (Jan. 2010).
[22] Zhenghong Wang and Ruby B. Lee. 2008. A novel cache architecture with
enhanced performance and security. In 41st Annual IEEE/ACM International
Symposium on Microarchitecture.
[23] Yuval Yarom and Naomi Benger. 2014. Recovering OpenSSL ECDSA nonces using
the FLUSH+RELOAD cache side-channel attack. In Cryptology ePrint Archive.
[24] Yuval Yarom and Katrina Falkner. 2014. FLUSH+RELOAD: A high resolution,
low noise, L3 cache side-channel attack. In 23rd USENIX Security Symposium.
[25] Yinqian Zhang, Ari Juels, Alina Oprea, and Michael K. Reiter. 2011. HomeAlone:
Co-residency detection in the cloud via side-channel analysis. In 32nd IEEE
Symposium on Security and Privacy.
[26] Yinqian Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart. 2012. Cross-
VM side channels and their use to extract private keys. In 19th ACM Conference
on Computer and Communications Security.
[27] Yinqian Zhang, Ari Juels, Michael K. Reiter, and Thomas Ristenpart. 2014. Cross-
tenant side-channel attacks in PaaS clouds. In ACM Conference on Computer &
Communications Security.
[28] Yinqian Zhang and Michael K. Reiter. 2013. Düppel: Retrofitting commodity
operating systems to mitigate cache side channels in the cloud. In 20th ACM
Conference on Computer and Communications Security.
[29] Ziqiao Zhou, Michael K. Reiter, and Yinqian Zhang. 2016. A software approach to
defeating side channels in last-level caches. In 23rd ACM Conference on Computer
and Communications Security.
(a) Tracking the read set.
(b) Tracking the write set.
(c) Detecting L1 data cache eviction.
(d) Detecting data eviction in LLC.
(e) Detecting eviction of instruction in LLC.
(f) Detecting context switch.
Figure 3: Empirical evaluation of Intel TSX.
Appendices
A DETECTING CACHE EVICTIONS USING
INTEL TSX
Our empirical study on the implementation of Intel TSX is con-
ducted on a dual-core (4-threads with Intel HyperThreading) 2.3GHz
Intel Haswell Core i5 5300U processor, which is equipped with sep-
arate 8-way 32KB L1 data and instruction caches and unified 256KB
L2 caches private to each core, and a 12-way 3MB LLC shared by
both cores. Our empirically assessment of TSX implementation
aims to answer the following questions:
How are read set and write set tracked? We first study the size
of the read set and write set in TSX, respectively. To do that, we
sequentially read (or write) a buffer (of the size that is a parameter
of the experiments) within a transaction using the RTM program-
ming interface. This is repeated for 100,000 times and we count the
number of cases that the transaction aborts. We expect that abort
rate will increase drastically when the size of the buffer becomes
larger than the read (or write) set. Fig. 3a and Fig. 3b shows the
abort rate for reading and writing buffer of different sizes. We find
that the size of the write set is slightly less than the size of the L1
data cache (32 KB), while the size of the read set is similar to the
size of the LLC (3 MB). This means that the write set of Intel TSX is
tracked in the L1 data cache and the read set is tracked in the LLC.
Can TSX detect L1 data cache evictions? In this experiment, we
run two programs concurrently. The first program, P1, runs in a
loop that is encapsulated in a transaction and accesses a specific
memory location, M, in each loop. The loop iterates 20 times before
it terminates. The other program, P2, tries to evict that cache line
(where M is stored) of P1, by repeatedly reading a tunable number
of memory blocks, which map to the same cache set as M in the L1
cache. We measured the transaction abort rate encountered by P1
while varying the number of memory blocks P2 accessed.
We pin P1 and P2 on different hardware threads of the same core
(with hyperthreading enabled), hence they share the same L1 data
cache. Fig. 3c shows the results when P1 access M by reading or
writing, respectively. Since the associativity of the L1 data cache is
8, when the number of memory blocks accessed by P2 is increased
to 8, P2 can evict the whole cache set by its own data. We find that
the transaction will not abort if the data read by a transaction is
evicted out of the L1 data cache, but it will cause the transaction to
abort with very high probability if the data written by a transaction
is evicted out of the L1 data cache.
Can TSX detect data eviction in the LLC? We conducted an
experiment that is similar to the one above. The difference is that
we pin P1 and P2 on different cores so that they only share the LLC
and the memory blocks accessed by P2 maps to the same cache
set as M in the LLC. The results are shown in Fig. 3d. Since the
associativity of the LLC is 12, P2 can evict the whole cache set when
it accesses 12 or more memory blocks. We find that the eviction of
data accessed by a transaction out of the LLC, no matter read or
write, always results in transaction aborts.
010002000300040005000Buffer Size (KB)0.20.00.20.40.60.81.01.2Abort Rate05101520253035Buffer Size (KB)0.20.00.20.40.60.81.01.2Abort Rate05678NumberofCacheLines0.00.20.40.60.81.01.2AbortRateConﬂictL1ReadAbortRateConﬂictL1WriteAbortRate0101112NumberofCacheLines0.00.20.40.60.81.01.2AbortRateConﬂictL3ReadAbortRateConﬂictL3WriteAbortRate09101112NumberofCacheLines0.00.20.40.60.81.01.2AbortRate500050000100000500000PreemptionPeriod(cycles)0.00.20.40.60.81.01.2AbortRateCan TSX detect eviction of instructions? Ideally, HTM only
needs to handle memory accesses made by the load/store instruc-
tions within a transaction. In practice, many HTM designs adopt a
paradigm called implicit transactions, which means that all mem-
ory accesses within the transaction boundaries are transactional,
including instruction fetches. Therefore, we hypothesize that with
implicit transaction, the read set also includes locations executed by
the transaction, which means that we can also detect the evictions
of instructions (from the LLC), similar to the data. To validate this,
we conduct the following experiment: we run two programs P1
and P2 concurrently on different cores. P1 repeatedly executes a
transaction that calls a dummy function located at at address M
for 20 times, with a small delay in between two invocations. The
dummy function does nothing but returns to the caller immediately.
P2 repeatedly reads a tunable number of memory blocks, which
map to the same LLC cache set as M, to evict the cache line of M.
Fig. 3e shows that when instructions are evicted out of the LLC,
the transaction will also abort.
Will transactions abort upon context switches? In this exper-
iment, we developed two programs running on the same core, with
HyperThreading turned off. Program P1 run in the transaction and
repeatedly reads from a memory location M. Program P2 spawns
10 threads, each of which runs for a very short period of time to
access 8 memory blocks that map to the same L1 data cache set as
M and then sleeps. Each thread programs a software timer to wake
up the next thread after certain time interval, t, which represents
the period that P1 is preempted [8]. In each of the experiments,
we varied the preemption period, t. The result is shown in Fig. 3f.
Although, as shown in the previous experiments, the eviction of
data read by a transaction out of the L1 data cache does not abort
the transaction, high-frequency preemption would yield high abort
rate when P2 is on the same core as P1. It suggests that a transaction
will abort upon context switches.
B SECURITY-CRITICAL REGION CODE
REFACTORING EXAMPLES
Due to space constraints, we put Listing 2, Listing 3, Listing 4
here. In Listing 2, because both Madd() and Mdouble() calls a large
number of functions internally, we refactored the code in Listing 3
to keep security-critical region small. In Listing 4, we refactored
square-and-multiply algorithm so that it performs multiplication
operation regardless of the bit value.
Listing 2: Pseudo code for Montgomery ladder.
for(; i >= 0; i--) {
word = scalar->d[i];
while(mask) {
// security-critical region
if(word & mask) {
Madd(group, &point->X, x1, z1, x2, z2, ctx);
Mdouble(group, x2, z2, ctx);
}
else {
Madd(group, &point->X, x2, z2, x1, z1, ctx);
Mdouble(group, x1, z1, ctx);
}
mask >>= 1;
}
mask = BN_TBIT;
}
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
for(; i >= 0; i--) {
while(retry d[i];
while(mask) {
Listing 3: Pseudo code for Montgomery ladder after refac-
toring.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
}
if(retry == THRESHOLD) failure_handler();s
Madd(group, &point->X, a, b, c, d, ctx);
Mdouble(group, c, d, ctx);
mask >>= 1;
// security-critical region
if(word & mask) {a=x1;b=z1;c=x2;d=z2;}
else {a=x2;b=z2;c=x1;d=z1;}
_xend();
break;
}
else retry++;
}
mask = BN_TBIT;
}
if(_xbegin() == _XBEGIN_STARTED) {
Listing 4: Pseudo code for Square-and-Multiply after
refactoring.
TX = DUMMY;
1
while(retry < THRESHOLD) {
2
3
4
5
6
7
8
9
10
11
12
}
if(retry == THRESHOLD) failure_handler();
Mult(TX);
// security-critical region
if( bit == 1 ) TX = X;
_xend();
break;
}
else retry++;