the samples and search for previously created IOCs that capture
activities observed in previous samples. P12 states that they "use
things like yara rules or create signatures so that [they] can submit it
through [their] sandbox [and] ... figure out what [malware family it
belongs to]." If a sample does not match any indicators, it remains in
the analyst’s queue for further analysis. Lastly, 10 of our participants
assign a higher priority to newer malware samples. As P2 said,
"When I come in on any given day, or anytime to research malware,
I’m really only concerned about the new stuff because malware dies
really quickly. It dies within, oftentimes hours, or at most days."
During this process, some analysts may need to examine the mal-
ware’s code or strings. However, malware samples are frequently
encrypted to prevent this type of analysis. Therefore, an important
task in the malware analysis workflow is reversing this encryption,
commonly referred to as "unpacking." 7 participants utilize dynamic
analysis to unpack samples. For example, P14 says "if the malware
is packed or obfuscated, you’re either gonna spend time reversing
the encryption or obfuscation functions and that’s a pain. I hate
doing that. It’s much easier to run it and let it decrypt itself." 2
participants utilize external, automated unpacking services such
as UnpacMe [19] to get the unpacked sample. As P10 describes
“Another service that I use is called UnpacMe, which is an up and
coming malware unpacking service, and it’s really awesome. A lot
Figure 2: Tier 1 Participant Workflow; P3
of times, it will get you to the lowest stage executable really quickly
that can be really helpful”. Lastly, 3 participants also utilize a hybrid
approach by debugging the sample mainly with ollydbg [12].
5.3 Main Analysis Process
When an analyst decides to analyze a malware sample in detail,
they follow a specific workflow that allows them to reach their
objective. To identify the analysis processes of our participants,
we studied the overall workflow described in the interviews. Next,
we identified commonalities between the workflows of different
participants. These commonalities allowed us to merge similar
workflows. Finally, we selected the five most common workflows
of the participants, shown in Figures 1-35, where the blue boxes
display the participants’ main objective. The rest of this section
describes these workflows, including the analysis steps and the
thought processes of the participants.
The first workflow is shown in Figure 2. This workflow starts
with either a potentially malicious executable or document. P3
analyzes executables by statically extracting strings. This process
can be accomplished by running the strings command or opening
the sample in a disassembler such as IDA. These strings are then
used to blacklist the sample. P3 said he "will block it in our network
and we will make sure that domain and hash will be blocked in
our local firewall." When analyzing a document, P3 opts to perform
dynamic analysis on the sample and monitor the results, looking
for IOCs such as IPs and domains. These IOCs are put into firewall
blacklists to detect previously seen samples.
The second workflow, shown in Figure 3a, is used by partici-
pants who utilize some static analysis within their workflow, but
emphasize dynamic analysis. During dynamic analysis, participants
monitor the environment to identify what actions the sample takes.
As P15 mentions, “process tree, file access rewrites, registry, injects
creation are the minimum." There are a number of tools that are
able to collect this information. One example is P2, who is "always
going to run ProcMon and process explorer because I want to know
if other processes were created on the fly. I’m always going to run
Wireshark because I want to know if network traffic is going to be
done, snapshot of my box because I want to know what changes
have been made, and when I’m done I run Clonezilla to revert."
This information is used to create behavioral signatures, which P10
explains are "able to match on what the malware does like what
files that it writes or registry keys that it creates, sets or modifies.
5P5 and P21 did not follow any of the five most common workflows and, as such, are
not listed in the figures.
Static StringsDynamicExecutionBlacklist IOCSession 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3058(a) Tier 2A Workflow; P1, P2, P8, P10, P11, P15, P16, P17
(a) 3A workflow; P9, P12, P13
(b) Tier 2B Workflow; P4, P6, P20
Figure 3: Tier 2 Participant Workflows. The dashed boxes
represent optional steps in the workflow process.
[...] The most promising [tool] is called sigma and they let us write
behavioral indicators and also write signatures on log files." One of
the benefits of behavioral signatures is that they "encompass more
than one [sample] that I load" as P2 discusses.
If analysts following this workflow are not able to get the mal-
ware to reveal its malicious behavior with dynamic analysis, they
will often resort to static analysis. P1 explains his process: "first
you run it in a dynamic environment and you see: Does it output
anything? Does it look like it’s running as you think it should?
[...] To understand it better, run it on bare metal to see if there is
anything in that dynamic environment that it’s detecting. [...] If
you still can’t get anything there, the next step is reverse engineer-
ing. So, doing manual analysis with IDA pro and unpacking and
disassembling to try and understand what’s going on. That is the
tiered approach."
The third workflow, shown in Figure 3b, also utilizes a combina-
tion of static and dynamic analysis, but emphasizes static analysis.
Static analysis is used by these participants to conduct a more in-
depth analysis of the tools used by the attackers. P20 starts with "an
API scout over it; meaning I extract all of the statically referenced
window API functions and basically do a similarity of them because
the spectrum of the API functions that I use is quite static for fami-
lies because it basically relates to the semantics that are encoded
by the programmer." This type of analysis allows participants to
label samples with their malware family and understand the tools,
which improves the detection of different variations of the sample.
In this workflow, static analysis is also used to identify capabili-
ties of the sample and write different reports about it. P4 mentions
that "some people want to know all the capabilities like what can
[the malware] do; Can it log keystrokes? Can it respond to back-
doors? Can it take screenshots?" These insights are compiled to
write reports about the malware, both for internal use by other
teams, such as threat intelligence, and to respond to external re-
quests from customers. As previously mentioned, participants in
this workflow occasionally utilize dynamic analysis. P6 provided
an example of when he would use dynamic analysis, "I had some
samples ... they were packed in a certain way that I couldn’t see. In
that case, I put it in a VM and ran it and saw that it’s definitely that
family. That’s an example of when I would do dynamic."
(b) 3B workflow; P7, P14, P18, P19
Figure 4: Tier 3 Participant Workflows. The dashed boxes
represent optional steps in the workflow process.
The fourth workflow, shown in Figure 4a, is used to analyze
multiple steps of a malware attack. Attackers can combine mul-
tiple stages into a complete attack. This workflow identifies the
connections between these stages. Participants who use this work-
flow want to identify the TTPs used throughout the attack, which
requires dynamic analysis with behavioral monitoring. For exam-
ple, P13 said, "we’ve got a couple different dynamic analysis tools.
I’ll run through those if it’s an executable [...] makes it easier to
triage and get what I want out of the document." However, if the
malware evades the analysis or does not show it’s complete mali-
cious behavior, static analysis is used to figure out what triggers
are required for the malware to download and execute the second
or third payload. As P12 explains, “a lot of times the second stage
requires the downloader to actually load it and do something to get
it to run. So, if you’re running a sandbox that can collect and can
detect the second stage but it runs it separately, that may not work.
You may just get a file that doesn’t execute. So, you need it to do
one stream where it downloads each stage and is able to put that in
the same VM and memory so that the other components run." The
identified attack techniques are often sent to threat intelligence
teams who model threat actors. P12 says these teams "pull a lot of
the information and figure out the different aspects of what they
do when they model it. They use a graph database to model and
look for trends. [...] As they model, they start tying the different
techniques and building the bigger picture and they might see that
different activities are related or are from the same campaign and
threat actor."
The final workflow in Figure 4b provides another method for
extracting TTPs over a longer period of time by emulating the
malware. As P7 explains, emulating the malware involves “reversing
the C2 protocols and then using that reversed C2 protocol to harvest
information from live C2s, whether that is payloads or targets,
whatever I want to get from the C2s.” This analysis can reveal how
a group’s malware moves through different infrastructure while it
is developed, obfuscated, and eventually deployed during attacks.
This valuable knowledge allows security specialists to understand
the threats they are likely to face in the near future and prepare
appropriate defenses to stop such threats before they can damage
their organization. By adopting this approach, organizations can
reduce the number of cyber attacks that they fall victim to and
improve their security posture.
Static StringsDynamicExecutionStatic AnalysisGenerateBehavioralSignaturesStatic StringsStatic AnalysisDynamicExecutionGenerate ReportDynamicExecutionStatic AnalysisTrack TTPsStatic StringsDynamicExecutionStatic AnalysisEmulatingMalware Track TTPsSession 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea30595.4 Factors that Lead to Differences in
Workflows
The detailed findings from this section reinforce our conclusion
in section 4 that the primary factors that affect the workflows are
the main objectives and the extracted IOCs. Additionally, we found
two additional influencing factors. First, we found that the type
of malware sample being analyzed affects the workflow. When
samples are classified as variants, the participants’ workflow is less
extensive than the analysis of novel malware because the analysts
already have an understanding of the malware family. While work-
flow 3a and 3b begin to explore the steps required to conduct a
more in depth analysis, we leave a more detailed investigation for
future work. The second additional influencing factor is the obfus-
cation mechanisms used by the sample. When analyzing malware
with more sophisticated obfuscation, 4 of our participants prefer to
use dynamic analysis to deobfuscate the sample. In contrast, when
analyzing malware samples that utilize known obfuscation tech-
niques, 2 participants prefer to skip dynamic analysis and analyze
the sample statically.
6 DYNAMIC ANALYSIS SYSTEM SETUP
In section 5, we learned that all of the common malware analysis
workflows involve dynamic analysis. Due to this widespread use,
we investigated how different participants configure their dynamic
analysis system. During the interviews, we asked participants to
walk us through their configuration process. From the responses,
we learned that one of the most important factors in performing
quality dynamic analysis is the careful setup and configuration of
the analysis system. Specifically, we identified five main steps that
analysts complete when they set up their dynamic analysis system
and their reasoning behind how they complete each step.
6.1 Virtualization Vs. Bare Metal
When performing dynamic malware analysis, an analyst must de-
cide whether to run samples in a virtual environment or directly
on a bare metal machine. All of the participants use virtual envi-
ronments for dynamic analysis. One of the main reasons for this
is that bare metal analysis requires more physical resources, As
P1 mentioned, "It’s costly to run things on bare metal" (previous
work has also discussed this limitation [54]). Also, 5 participants
emphasized the fact that bare metal analysis does not scale well to
a large number of malware samples. This is especially true for the
participant in tier 1 because he frequently needs to analyze many
samples. However, if malware does not show its expected behavior
in a virtual environment, 4 participants re-analyze the sample on
a bare metal system. As P1 mentioned, the only time he uses bare
metal is for "unique cases; you can’t run everything."
6.2 Open-Source Vs. Commercial Dynamic
Analysis Tools Vs. Custom Virtual
Machines
The three types of virtual dynamic analysis platforms that analysts
use are commercial sandboxes, open-source sandboxes, and per-
sonal analysis environments that are generally built with virtual
machines (VMs). When participants decide to analyze malware in
a virtual environment, they have to decide which platform to use.
From our interviews, we discovered that the more in-depth the
analysis becomes, the less likely it will be done with commercial
tools, primarily because of their lack of configurability.
Specifically, 3 of our more experienced participants noted that
they want the ability to set many different parameters of the envi-
ronment and add additional features. For example, P19 said that if
he "cannot put personal signatures into the sandbox, that can be
a problem." Some of the other features that our participants want
in their sandboxes include the flexibility of running samples with
either a 32 or 64 bit architecture (P19), adding custom sensors to
collect activity from different malware types such as JavaScript or
Visual Basic (P19), and adding custom code when they develop their
own features (P16). Unlike commercial sandboxes, open-source so-
lutions allow analysts to personalize their setup and are free to use.
Although participants appreciate the flexibility of open-source sand-
boxes, one of their main critiques is that they require a significant
amount of effort to set up correctly. Also, 3 participants mentioned
that the setup process requires a deep technical understanding of
how sandboxes function.
In contrast to open-source sandboxes, 4 participants say that
commercial sandboxes are easier to use. Although we emphasize the
importance and challenges of setting up dynamic analysis systems,
some commercial sandboxes provide a preconfigured environment.
As P12 stated, security companies "have done a lot of research to
figure out what products should go in that and how to configure it
to get it to run optimally." The malware analysts at these companies
also provide constant feedback to the sandbox engineering team
to address new evasion techniques and incorporate new detection
signatures. However, the decision about what new features are
added to the sandbox is made by its developers, not the malware
analysts who use it. Therefore, it can be challenging for users to
get additional features added to the sandbox because this may not
be the main driving force of the developers.
Due to the previously mentioned disadvantages of both com-
mercial and open-source sandboxes, 9 participants set up personal
analysis environments. Generally, these environments are com-
posed of VMs with analysis tools installed. As P12 mentioned, "I
like to do my own dynamic analysis. I will run it in my VM and run
different tools that collect information." We were surprised when
P21 said that he had "never done anything with cloud sandboxing
like Cuckoo. I’m not terribly informed on what they do. I’ve just
done things with VM because they are easy to set up."
6.3 Setting Up Environment Targeted by
Malware
One of the key decisions an analyst has to make is how to set up the
execution environment, including selecting the operating system,
time zone, programs installed, and files present, such that malware
samples will try to attack it. Table 3 and Table 4 show the features
that participants change when configuring a general or specific
environment, respectively. To provide the most accurate results, we
only include participants who responded to our follow-up survey to
prevent inaccuracies due to a participant not mentioning a feature
they do configure during their interview.
Session 11C: Software Development and Analysis CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3060ID
P9
Windows &
Linux
Windows
P10
P16 Windows 7, 8.1,
10 & Android
P18 Windows 7, 10,
or XP
P20
Windows
OS
Microsoft
Office
Web
Browser
Adobe
Acrobat
Libraries Timezone Language Usernames
File
Names
Browsing
History
Populate
Files
Other
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
!
Shared drives
Admin vs.