rithm, derived from linear scan [32]. The resulting allocation is
flow-insensitive: within a given function, a variable is always al-
located to the same register. To compensate for this limitation, a
dedicated pass renames variables according to their liveness ranges,
using an SSA-like form. Once again, the constant propagation pass
is applied to eliminate instructions that have no effect.
The stack allocation pass puts all local (stack) variables into a
single memory region that is allocated on function entry and freed
on function exit. It also takes care of the remaining arrays: each
access to a stack array is thus translated as a corresponding memory
operation. At the end of this pass, all arrays have been removed
from the program.
The previous pass marks the end of the middle-end transform-
ing the structured intermediate representation of Jasmin. The lin-
earization pass, transforms the program into an unstructured list
of instructions with named labels and gotos. This representation
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1816is then straightforwardly translated into assembly. The assembly
generation pass enforces the architectural constraints (two address
instructions, forced registers). In this respect, it acts as a validation
of the earlier register allocation pass. Finally, this assembly repre-
sentation can be pretty-printed into usual syntax to be used by an
off-the-shelf assembler or inlined into programs written in other
languages (e.g., C, Rust).
5.2 Compiler correctness
The main correctness theorem of the Jasmin compiler is stated
as follows. For each source program, if the compilation succeeds
and produces a target program, then every execution of the source
corresponds to an execution of the target. Here, execution means
terminating and without errors. Formally, we have the following
statement.
Theorem 5.1 (Jasmin compiler correctness).
∀ p p
′
′
) →
, compile(p) = ok(p
∀ f , f ∈ exports(p) →
∀ va m vr m
f , va, m ⇓p
call vr , m
′
, enough-stack-space( f , p
′ → f , va, m ⇓p′
′
, m) →
′
call vr , m
In this statement, exports(p) refers to the exported entry points
of program p: non-exported functions do not appear in the target
program; all calls to these functions have been inlined. Stack vari-
ables are allocated to the memory during the compilation: therefore,
the compiler only preserves the semantics from initial memories in
which there is enough free stack space to execute the compiled pro-
gram. This property is captured by the enough-stack-space(f , p′, m)
predicate. Since target programs do not call functions, this predi-
cates only states that the stack variables of the function f in the
compiled program can be allocated in the initial memory m.
The conclusion of the theorem refers to the semantics of the
target assembly language (x64). It is formally defined in Coq, with
an accurate bit-level definition of all the instructions involved in
our benchmarks.
Notice that the memories and input and output values are the
same for both source and target levels: the semantics of all interme-
diate language share the same definitions of values and the same
memory model.
Since the target language (assembly) is deterministic, for safe
source programs, this theorem implies that every execution of the
target corresponds to an execution of the source.
This theorem also implies that safe source programs are compiled
to safe target programs, with the caveat that compiled programs
may consume more stack space than the source programs. More
precisely, given a source program that is safe under some precon-
dition, the compiled program, for any initial state satisfying the
precondition, will either run without run-time error, or fail by lack
of stack space.
5.3 Proof methodology
The Jasmin compiler is written in OCaml and in Coq. The Coq
part is formally verified, i.e., its correctness is stated and proved
once and for all. The OCaml part is two-fold. On the one hand,
the impure interface with the outer world (source code parsing,
assembly pretty printing) is trusted.7 On the other hand, some
compilation passes call an external oracle: this oracle is written in
OCaml but is not trusted; its result is validated on every run by a
Coq routine that is itself verified. This lightweight proof technique,
known as translation validation [29], is applied to many passes.
Moreover, all the validated passes only use two checkers: one
is dedicated to the stack-allocation pass; the other deals with the
register-allocation passes.
The checker for stack-allocation ensures that enough memory
is allocated for all the local variables and that each stack access
(including array accesses) is properly translated to the correspond-
ing memory access. Its soundness relies on the safety of the source
program: the fact that all array accesses are in bounds ensures that
all variables can be allocated to a single memory region.
The other validator checks that the two programs (before and
after the transformation) precisely have the same structure up
to some renaming. This validator is parameterized by the class
of renaming that is allowed, so that it can be used in multiple
passes: changes in variable names after unrolling, stack sharing
and register allocation, and transformation of array indexings into
variable accesses after register-array expansion.
The structure of the correctness proof follows the structure of the
compiler itself: each pass is proved correct and the main theorem
is a composition of these lemmas. The correctness of a compilation
pass is proved through a simulation relation, which is a relational
invariant of the simultaneous executions of the source and target
programs.
5.4 Constant-time preservation
In addition to functional behaviour and safety, the compiler pre-
serves constant-time security of programs. As for Jasmin programs,
one can define an instrumented semantics of assembly programs,
where leakage traces record the sequence of addresses accessed and
program point visited during execution. One then shows that the
compiler preserves constant-time: if a Jasmin program is safe and
constant-time, then the generated assembly program is constant-
time. Therefore, it is legitimate to prove that Jasmin programs are
constant-time, using the methodology and automated tool from
Section 4.
The proof of constant-time preservation for the compiler is de-
composed into proving that every individual pass preserves the
constant-time property. Moreover, the proof for each individual
pass has a similar structure. We use a stronger statement of semantic
preservation, in particular making explicit the simulation relation
for this pass, and consider how this pass transforms memory ac-
cesses and branches and argue that it does so in a constant-time
preserving fashion. This involves considering two executions of the
target program, and distinguishing between leakages that are in-
herited from a similarly leaky instruction of the source program (in
this case we use the hypothesis that the source program is constant-
time) or are constant memory accesses (in this case no information
is leaked). More formally, we rely on several crucial facts: first,
compilation does not introduce branching instructions. In particu-
lar, conditional moves are compiled into CMOV instructions, and
7The size of the trusted code base of Jasmin could be reduced; for instance, there are
techniques for validating parsers [25]. We leave this as further work.
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1817therefore have no impact on the leakage trace. Second, it is always
correct to (unconditionally) remove leaks through memory accesses
and branches, as they are similarly removed from all traces. This is
used, e.g. to justify constant propagation and loop unrolling, which
may remove (constant) branches. Third, in some cases, compilation
may introduce leaky instructions. When arrays and local variables
are allocated to the stack, the accesses to these variables become
observable in the leakage trace; but said leakage cannot depend on
secrets.
Remark. We stress that preservation of the constant-time prop-
erty can be affected by aggressive compilers, which may use opti-
mizations to tabulate expensive functions and transform constant-
time computations into memory loads; or to introduce case anal-
ysis on (secret) values that are known to have a small range and
transform constant-time computations into branches. By design,
such optimizations are not supported by the Jasmin compiler. In
any case, one could argue that constant-time verification should
be performed at assembly-level, eliminating the need to impose
restrictions on the compiler. However, we argue that our current
approach provides a reasonable compromise, with the added benefit
to simplify interface with state-of-the-art verification technology.
As a final note, we observe that it would be desirable to prove
preservation of constant-time using the Coq proof assistant. We
leave this for future work.
5.5 Statistics
The compiler comprises about 25k lines of Coq files (not including
third-party libraries), which produces about 25k lines of extracted
OCaml. This certified code is complemented with 5k lines of trusted
hand-written OCaml, and a few thousands lines of untrusted hand-
written OCaml.
6 EVALUATION
We have evaluated the performance of compiled Jasmin programs
using supercop (System for Unified Performance Evaluation Re-
lated to Cryptographic Operations and Primitives), a toolkit for
measuring the performance of cryptographic software. In this work
we looked at version 20170105 of the toolkit and we selected a
representative set of implementations that have been hand-crafted
using the qhasm language. These implementations are given as as-
sembly programs, but they include the corresponding qhasm input
program as annotations. We developed an automatic translator that
starts from such assembly implementations, extracts the original
qhasm code, and then automatically generates functionally equiv-
alent Jasmin programs–for the overwhelming majority of qhasm
instructions the translation is one-to-one.
Benchmarking procedure. A supercop release contains all the ma-
chinery required to carry out performance evaluation on a specific
computer; any computer can be used as a representative for a par-
ticular architecture and collected data can be submitted to a central
repository of collected benchmarks. In our work we have focused
on execution time and we have adapted the evaluation scripts to
consider specific implementations of our interest and collect high-
precision clock-cycle counts. This means, in particular, that all of
the implementations produced by the Jasmin compiler needed to be
Table 1: Comparison of Jasmin-generated assembly and
qhasm-generated assembly. Numbers shown correspond to
supercop clock-cycle counts.
Implementation
X25519-4limb-base
X25519-4limb
X25519-4limb-jasmin
X25519-5limb-base
X25519-5limb
ed25519-5limb-keypair
ed25519-5limb-sign
ed25519-5limb-open
salsa20
salsa20-xor
148 354
148 572
55 364
83 430
182 520
12 322
12 208
qhasm Jasmin Ratio
1.012
147 084
147 890
1.006
148 914
148 922
143 982
147 200
147 090
56 594
85 038
188 180
12 460
12 252
0.992
0.990
1.022
1.019
1.031
1.011
1.004
compliant with calling conventions imposed by gcc version 5.4.0.
The machine we used is equipped with an Intel Core i7-6500U pro-
cessor, clocked at 2.50 GHz, with 16 GB of RAM, running Ubuntu
version 16.04. Turbo boost was disabled in all measurements. To
collect clock-cycle measurements we configured supercop to use
gcc -O3. (The optimization level is irrelevant for assembly imple-
mentations, and it affects equally implementations that mix C code
with assembly implementations compiled from Jasmin or qhasm.)
Each implementation is executed 10 000 times and the median of
clock-cycle counts is taken as final result.
Benchmarking results. Table 1 displays results we collected by
first measuring the speed of the original assembly implementations
generated from qhasm programs, and then measuring the assem-
bly implementations compiled from the translated Jasmin code.
Concretely, we looked at two implementations of Curve25519, for
different representations of the underlying field, at the Ed25519
signature scheme [14], and at the salsa20 stream cipher. super-
cop testing procedures were used to ensure that both the original
implementation and the new implementation are functionally cor-
rect. Our results show that, for all implementations that we have
obtained using this procedure, the Jasmin toolchain essentially
preserves the performance of the original implementation.
High-efficiency Jasmin. To further demonstrate that high-level
programming in Jasmin is not opposite of high-efficiency, we have
manually optimized the Jasmin Montgomery ladder implementa-
tion depicted in Figure 3, by carefully reordering instructions, max-
imizing the use of registries, and directly using the #x86_MOV(0)
instruction for some variable assignments. A more detailed descrip-
tion of this optimized implementation is given in Appendix B. In
fact, our optimized X25519-4limb-jasmin implementation8 drops
below 144k clock-cycles and beats the equivalent qhasm implemen-
tation in supercop. We believe that the same optimizations could be
also performed in qhasm, but in a less modular and more expensive
way, and without a proof of semantics preservation.
8Benchmarked using the -nolea flag to disable load effective address instructions.
Session H4:  Formal VerificationCCS’17, October 30-November 3, 2017, Dallas, TX, USA1818Benchmarking verification. All the benchmarked implementa-
tions were proved safe and constant-time at the source level using
the tool presented in Section 4, and hence are guaranteed to re-
tain these properties at the machine-level, as per the discussion
in Section 5. The vast majority of qhasm-translated programs are
written in a straight-line style and were automatically proven, given
a two-line top-level specification of valid memory regions (safety)
and public inputs (constant-time). Verification is more effective for
Jasmin-style code with high-level control flow structures, especially
loops, but may require suitable programmer-supplied annotations
typical of high-level functional correctness proofs. This is the case of
some salsa20 fragments containing loops that manipulate memory
regions, and our X25519-4limb-jasmin implementation (Figure 5).
7 RELATED WORK
Verification of Curve25519. There have been several efforts to
reason formally about the functional correctness of Curve25519.
Chen et al. [19] prove functional correctness of a qhasm imple-
mentation of scalar multiplication. In their approach, functional
correctness is captured by a post-condition stating that the program
computes its intended result. Moreover, the verification process re-
quires the programmer to annotate the qhasm code with assertions
that establish relations between relevant intermediate values in the
code. For instance, applying their approach to modular multiplica-
tion requires the programmer to insert an assertion at the program
point where multiplication was completed, and insert subsequent
assertions referring to the intermediate value at various points in
the modular reduction step. Starting from a qhasm program with
sufficiently many annotations, their approach generates a set of
proof goals, which are automatically translated to the Boolector
SMT solver [30] that attempts to discharge them automatically.
When the SMT solver is not powerful enough to complete the proof
that these intermediate results suffice to imply the post-condition,