4.2 Signing Passports
The contents and origin of passports must be crypto-
graphically veriﬁable. There are numerous approaches for
such veriﬁability, ranging from crowd-sourced approaches
like Perspectives [43] and Convergence [25] to social-based
approaches like PGP [44]. While the certiﬁcate authority
(CA) model for the Web has known limitations [9], because
of its (current) wide acceptance, we choose to build on the
CA model for world-driven access control. However, we
stress that the underlying mechanism is interchangeable.
Building on the CA model, we introduce a policy authority
(PA), which is trusted to (1) verify that the entity requesting
a passport for an object or location is the real owner (i.e.,
has the authority to provide the policy), and (2) sign and
issue the requested passport. Thus, object or location own-
ers wishing to post policies must submit them to be signed
by one of these trusted authorities. For this approach to
be eﬀective, it must be diﬃcult for an attacker to obtain a
legitimately signed policy for an object or location for which
he or she cannot demonstrate ownership.
4.3 Describing Objects via Passports
In addition to containing a policy speciﬁcation, each signed
passport contains a description of the associated object or
location. For a ﬁxed location (e.g., on a corporate campus),
the description may specify GPS coordinates bounding the
targeted area. For a mobile object, the description should
be as uniquely-identifying as possible (e.g., containing the
license plate of the associated car). Thus, after verifying
a passport’s signature, the system also veriﬁes that the en-
closed description matches the associated object or location.
Having a description in the passport helps prevent an at-
tacker from moving a legitimately signed passport from one
object or location to another. Preventing such an attack
may be diﬃcult to achieve in general, as it depends on the
false positive rates of the object recognition algorithm and
what is actually captured by the device’s sensors (e.g., the
car’s license plate may not be in view). The key point is that
passports give object owners control over the description, so
an object owner can pick the best available description.
We observe that object descriptions may create privacy
risks for objects if not designed carefully. We return to the
tension between description clarity and privacy in Section 7.
We further support active object descriptions contained
in the passport. Rather than being simply static (e.g., “car
with license plate 123456”), the object description may con-
sist of code (or of a pointer to code) that directly extends the
system’s recognizers (e.g., with a car recognizer). Beyond
aiding policy veriﬁcation, active descriptions can extend the
system’s basic object recognition abilities without requiring
changes to the system itself. Certiﬁcates including code and
policy are similar in spirit to the permission objects in .NET
Code Access Security [28], the delegation authorization code
in Active Certiﬁcates [6], the self-describing packets in Ac-
tive Networks [40], or objects in Active DHTs [13], but we
are not aware of previous approaches that dynamically add
object recognition algorithms. In our initial design, the ac-
tive object descriptions are trusted by virtue of the PA’s
signature, and could be further sandboxed to limit their ca-
pabilities (as in Active DHTs [13]).
If the description contained in the passport does not match
the associated object, the passport is ignored — i.e., the sys-
tem applies a sensible default. For a real-world travel pass-
port, the default is to deny access; in our case, requiring
explicit allow-access policies on all objects would likely re-
quire an unacceptable infrastructure and adoption overhead.
Thus, in practice, the system’s default may depend on the
current context (e.g., a public or private setting), the type
of object, or the type of recognizer. For example, a default
may deny face recognition but allow QR code events.
We believe the idea of active object descriptions is of in-
terest independent from world-driven policies. By allowing
real-world objects to specify their own descriptions, the sys-
tem’s object recognition capabilities can be easily extended
in a distributed, bottom-up manner.
4.4 Monitoring Passports
Passport signatures and objects descriptions help prevent
attackers from forging or moving passports. We must also
consider the threat of removing passports entirely. Again,
because a deny-access default may create high adoption over-
head, a missing passport allows access in the common case.
As an initial approach, we suggest mitigating this threat
by monitoring passports. In particular, a policy owner can
monitor a passport directly — by installing a device to ac-
tively monitor the policy, e.g., to ensure that the expected
QR code or ultrasound signal is still present — or can in-
clude in the policy itself a request that devices occasionally
report back policy observations. While an attacker may also
try to manipulate the monitoring device, its presence raises
the bar for an attack: disabling the monitor will alert the
policy owner, and fooling it while simultaneously removing
the policy from the environment may be diﬃcult for some
policy communication technologies (e.g., WiFi).
Stepping back, we have explored the problem space for pol-
icy passports. The proposed designs are an initial approach,
and we welcome future work on alternative approaches sup-
porting our core concept that real-world objects can specify
Microsoft Research Tech Report MSR-TR-2014-67
their own policies and prove their authenticity.
5.
IMPLEMENTATION
While world-driven access control may intuitively appear
straightforward, it is not obvious that it can actually work
in practice. We explore the challenges — and methods for
overcoming them — in more detail with our implementation
and evaluation. Our prototype runs on a Windows lap-
top or tablet and relies on sensors including the Kinect’s
RGB/depth cameras and its microphone, the built-in WiFi
adapter, and a Bluetooth low energy (BLE) sensor. Though
this platform is more powerful than some early-generation
continuous sensing devices, we expect these devices to im-
prove, such as with specialized computer vision hardware [10,
30]. Some continuous sensing platforms — such as Xbox
with Kinect — are already powerful enough today.
Sensor input is processed by recognizers [18], many of
which simply wrap the raw sensor data. We also imple-
mented a QR code recognizer using an existing barcode li-
brary [1], a speech keyword recognizer using the Microsoft
Speech Platform, a WiFi access point recognizer, and one
that computes the dominant audio frequency.
5.1 Policy Module
As described in Section 3.4, the policy module subscribes
to events from all of the system’s recognizers and uses them
to detect and enforce policies. Before dispatching an event to
an application, the system calls the policy module’s Filter-
Event() method, which blocks or modiﬁes the event based
on currently active policies. To modify an event, it uses
recently buﬀered events from other recognizers if necessary.
Recall from Section 3.4 the policy accuracy versus perfor-
mance tradeoﬀ: policies can be detected and applied more
accurately if all relevant events have arrived, but waiting too
long impacts event dispatch latency. In our implementation
we favor performance: to avoid delays in event dispatch,
we do not match up events precisely using frame numbers
or timestamps, but simply use the most recent events, at
the possible expense of policy accuracy. Alternatively, this
choice could be made per application or by user preference.
We quantify the eﬀects of this tradeoﬀ in Section 6.
5.2 Passports
In addition to static policies (e.g., a simple QR code that
activates a pre-installed “block RGB events” policy), our
prototype supports passports by transforming certain recog-
nizer events into passport lookups. The system appends the
text in a QR code or a Bluetooth MAC address to the base
URL at www.wdac-passport-authority.com/passportlookup/. If
a corresponding passport exists, the server provides its URL.
The passport contains a policy DLL that implements our
policy interface (Figure 4). The system downloads, veriﬁes,
and installs the new policy (if not previously installed).
The process of loading a passport could be optimized by
caching server responses. If the system cannot make a net-
work connection, it misses the passport; a future implemen-
tation could buﬀer the network request until connectivity
is available, in case the policy is still applicable then. Note
that the system does not need a network connection to parse
static (non-passport) policies; passports communicated via
certain communication technologies (e.g., Bluetooth) could
also encode their policy code directly rather than pointing
to a server. As noted in Section 4, code in a passport could
be signed by a policy authority and sandboxed. Since signa-
ture and sandboxing approaches have been well studied else-
where, we do not include them in our prototype but rather
focus on world-driven access control functionality.
5.3 Prototype Policies
Block RGB in sensitive area. We implemented several
policies blocking RGB events in sensitive areas, based on
QR codes, BLE, WiFi, and audio. For example, a QR code
on a bathroom door can specify a policy that blocks RGB
until the corresponding “end policy” QR code is detected.
We can similarly use a BLE emitter to specify such a policy;
BLE has a range of roughly 50 meters, making it suitable
for detecting a sensitive area like a bathroom. Similarly, we
use the access point (AP) name of our oﬃce’s WiFi network
to trigger a policy that blocks RGB events. (Future APs
might broadcast more complete, authenticated policies.)
We also use our audio frequency recognizer to block RGB
events: if a trigger frequency is heard three 32 ms timeslots
in a row, the corresponding policy is engaged (and disen-
gaged when the trigger has not been heard for three consec-
utive timeslots). In our experiments, we used a frequency
of 900 Hz; in a real setting, ultrasound may be preferable.
Ultrasound is already used in real settings to communicate
with smartphones [42]. More complex audio communication
is also possible, e.g., encoding a policy in the signal [33].
Remove person from RGB. We support several policies
to remove bystanders from RGB frames. First, we support
bystanders wearing opt-out QR codes — though our imple-
mentation could easily support an opt-in instead — and ﬁlter
RGB events to remove the pixels associated with the person
nearest such a QR code’s bounding box. To do so, we use
the per-pixel playerIndex feature of Kinect depth frames.
Figure 2 shows a modiﬁed RGB frame based on this policy.
As a simpler, more eﬃcient policy to remove people from
RGB frames, and inspired by practices at AdaCamp, we also
implemented a color-based policy, using a certain shirt color
to indicate an opt-out. This policy (1) detects a 10x10 pixel
square of the target color, (2) calculates its average depth,
and (3) removes RGB pixels near that depth. Thus, this
policy applies to anything displaying the target color, and
it avoids the latency of the Kinect’s player detection. Using
a hybrid approach, we also implemented a BLE policy to
bootstrap the color policy (discussed more in Section 6).
Block sensitive audio. We implemented a policy that
blocks sensitive audio based on our speech keyword recog-
nizer. We use a hard-coded grammar that includes words
that may signal a sensitive conversation, such as project
codenames like “Natal,” as well as explicit user commands
such as “stop audio.” The policy blocks audio events once
such a keyword is detected, and resumes audio events upon
command (i.e., when the user explicitly says “begin audio”).
6. EVALUATION
We evaluate along two axes:
(1) Policy Expressiveness and Implementation Eﬀort. We
show that our architecture can incorporate a wide variety
of policies desired by users and proposed in prior work with
low developer eﬀort (Section 6.1).
(2) Policy Eﬀectiveness. We explore the eﬀectiveness of
policy communication technologies and world-driven policies
implemented in our prototype (Section 6.2).
Microsoft Research Tech Report MSR-TR-2014-67
Name
Detection
Enforcement
Lines of Code (C#)
Respectful Cameras [36] Visual indicator Blur faces
Brassil [7]
Blur faces
Bluetooth
Blur faces
TagMeNot [8]
QR Code
Ultrasound
Iceberg Systems [20]
Disable camera
Parachuri et al. [31]
Visual indicator Remove person
84 (QR code) – 104 (color)
69 (remove person)
84 (remove person)
35 (audible sound)
84
Figure 5: Policies in Prior Work. Our architecture generalizes policies from prior work; this table details those we implemented.
6.1 Policy Expressiveness & Effort
We validate that our policy interface (Figure 4) is expres-
sive enough to capture realistic policies. We implemented
a representatives set of policies proposed in prior work rele-
vant to continuous sensing [7, 8, 20, 31, 36], summarized in
Figure 5. In some cases, we implemented a slightly diﬀer-
ent enforcement than the one speciﬁed in prior work (e.g.,
removing people from the frame instead of blurring faces),
and we note these diﬀerences where applicable. Each policy
could be implemented in our prototype with only a modest
number of lines of C# code (between 35 and 104, measured
using Visual Studio’s Code Metrics), indicating that our ar-
chitecture supports new and diverse policies with modest
additional developer eﬀort.
Other policies exist in prior work, such as a policy to en-
crypt recordings with a shared key derived with a distributed
prototol [16]. We determined that our system could support
this policy, but for our purposes here we chose not to spend
eﬀort reimplementing its protocol. Our prototype can also
handle existing real-world policies (Appendix A).
We conclude that our architecture’s policy abstraction is
suﬃciently expressive and that policies can be implemented
with modest developer eﬀort.
6.2 Policy Effectiveness
We evaluate policy eﬀectiveness in representative scenar-
ios. We aim not to maximize eﬀectiveness but to explore
policy communication technologies and demonstrate the fea-
sibility of world-driven access control. We also view our
evaluation methodology itself as a contribution for others
studying access control for continuous sensing.
6.2.1 Evaluation Methodology
We designed and evaluated representative scenarios, each
with one or more environmental policy triggers (Figure 7).
For example, in the Bathroom scenario, we aﬃxed QR codes
on and near the bathroom door, and we placed a BLE emit-
ter and a smartphone producing a 900 Hz tone inside. In the
Person scenario, a person carried a BLE emitter and wore a
QR code and a red color.
We used our prototype to record a trace of raw recognizer
events for each scenario. We constructed scenarios so that
a policy was applicable in one continuous segment (e.g., a
person is only seen once in the Person trace) and that the
trace was realistic (e.g., we turned on a faucet in the bath-
room). We then replayed every trace once for each policy
present. Pre-recorded traces let us compare multiple policies
on the same trace. Since our goal is to evaluate feasibility,
we consider only one representative trace of each scenario.
We then annotated each trace with ground truth for each
policy of interest: whether the ideal enforcement of that
policy would modify or block each event. We compared
the results of the replay for each policy with our ground
truth annotations. In particular, we introduce the follow-
Figure 6: Example Policy Evaluation. We evaluate start
lag (false negatives before a policy is correctly applied), ﬁnish
lag (false positives after a policy should have been stopped), and
additional false positives and negatives outside of these lags.
ing methodology for evaluating the eﬀectiveness of a policy.
Considering only those events that may be aﬀected by the
given policy, such as RGB in the Bathroom trace or audio
in the Speech trace, we evaluate the policy as follows.
Speciﬁcally, we consider four values: (1) start lag (false
negatives before the policy is correctly applied), (2) ﬁnish
lag (false positives before the policy is correctly removed),
(3) additional false positives, and (4) additional false nega-
tives. Conceptually, start and ﬁnish lag measure the time