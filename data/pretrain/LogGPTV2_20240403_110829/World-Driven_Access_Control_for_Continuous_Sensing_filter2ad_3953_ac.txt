### 4.2 Signing Passports
The contents and origin of passports must be cryptographically verifiable. Various approaches can achieve this, ranging from crowd-sourced methods like Perspectives [43] and Convergence [25] to social-based methods like PGP [44]. Although the certificate authority (CA) model for the web has known limitations [9], it is widely accepted, and we have chosen to build on this model for world-driven access control. However, we emphasize that the underlying mechanism is interchangeable.

Building on the CA model, we introduce a policy authority (PA), which is trusted to:
1. Verify that the entity requesting a passport for an object or location is the legitimate owner (i.e., has the authority to provide the policy).
2. Sign and issue the requested passport.

Thus, owners of objects or locations who wish to post policies must submit them to be signed by one of these trusted authorities. For this approach to be effective, it must be difficult for an attacker to obtain a legitimately signed policy for an object or location they do not own.

### 4.3 Describing Objects via Passports
Each signed passport contains both a policy specification and a description of the associated object or location. For a fixed location (e.g., on a corporate campus), the description may include GPS coordinates bounding the area. For a mobile object, the description should be as uniquely identifying as possible (e.g., including the license plate of a car). After verifying a passport’s signature, the system also checks that the enclosed description matches the associated object or location.

Including a description in the passport helps prevent an attacker from transferring a legitimately signed passport from one object or location to another. Preventing such an attack can be challenging, as it depends on the false positive rates of the object recognition algorithm and what is actually captured by the device’s sensors (e.g., the car's license plate may not be visible). The key advantage is that passports give object owners control over the description, allowing them to choose the best available description.

We note that object descriptions may create privacy risks if not designed carefully. We will return to the tension between description clarity and privacy in Section 7.

We further support active object descriptions within the passport. Instead of being static (e.g., “car with license plate 123456”), the object description can consist of code (or a pointer to code) that directly extends the system’s recognizers (e.g., with a car recognizer). Active descriptions not only aid policy verification but can also extend the system’s basic object recognition capabilities without requiring changes to the system itself. Certificates including code and policy are similar in spirit to permission objects in .NET Code Access Security [28], delegation authorization code in Active Certificates [6], self-describing packets in Active Networks [40], or objects in Active DHTs [13]. However, to our knowledge, no previous approaches dynamically add object recognition algorithms. In our initial design, active object descriptions are trusted due to the PA’s signature and could be further sandboxed to limit their capabilities (as in Active DHTs [13]).

If the description in the passport does not match the associated object, the passport is ignored, and the system applies a sensible default. For a real-world travel passport, the default is to deny access. In our case, requiring explicit allow-access policies on all objects would likely impose an unacceptable infrastructure and adoption overhead. Therefore, the system’s default may depend on the current context (e.g., public or private setting), the type of object, or the type of recognizer. For example, a default may deny face recognition but allow QR code events.

We believe the concept of active object descriptions is of interest independent of world-driven policies. By allowing real-world objects to specify their own descriptions, the system’s object recognition capabilities can be easily extended in a distributed, bottom-up manner.

### 4.4 Monitoring Passports
Passport signatures and object descriptions help prevent attackers from forging or moving passports. We must also consider the threat of removing passports. A deny-access default may create high adoption overhead, so a missing passport allows access in common cases. To mitigate this threat, we suggest monitoring passports. A policy owner can monitor a passport directly by installing a device to actively monitor the policy (e.g., ensuring the expected QR code or ultrasound signal is present) or can include in the policy a request for devices to occasionally report back policy observations. While an attacker may try to manipulate the monitoring device, its presence raises the bar for an attack: disabling the monitor will alert the policy owner, and fooling it while simultaneously removing the policy from the environment may be difficult for some policy communication technologies (e.g., WiFi).

In summary, we have explored the problem space for policy passports. The proposed designs are an initial approach, and we welcome future work on alternative methods supporting our core concept that real-world objects can specify their own policies and prove their authenticity.

### 5. Implementation
While world-driven access control may seem straightforward, it is not obvious that it can work in practice. We explore the challenges and methods for overcoming them through our implementation and evaluation. Our prototype runs on a Windows laptop or tablet and relies on sensors including the Kinect’s RGB/depth cameras and microphone, the built-in WiFi adapter, and a Bluetooth low energy (BLE) sensor. Though this platform is more powerful than some early-generation continuous sensing devices, we expect these devices to improve, such as with specialized computer vision hardware [10, 30]. Some continuous sensing platforms, such as Xbox with Kinect, are already powerful enough today.

Sensor input is processed by recognizers [18], many of which simply wrap the raw sensor data. We also implemented a QR code recognizer using an existing barcode library [1], a speech keyword recognizer using the Microsoft Speech Platform, a WiFi access point recognizer, and one that computes the dominant audio frequency.

#### 5.1 Policy Module
As described in Section 3.4, the policy module subscribes to events from all of the system’s recognizers and uses them to detect and enforce policies. Before dispatching an event to an application, the system calls the policy module’s `FilterEvent()` method, which blocks or modifies the event based on currently active policies. To modify an event, it uses recently buffered events from other recognizers if necessary.

Recall from Section 3.4 the tradeoff between policy accuracy and performance: policies can be detected and applied more accurately if all relevant events have arrived, but waiting too long impacts event dispatch latency. In our implementation, we favor performance: to avoid delays in event dispatch, we do not match up events precisely using frame numbers or timestamps but use the most recent events, at the possible expense of policy accuracy. This choice could be made per application or by user preference. We quantify the effects of this tradeoff in Section 6.

#### 5.2 Passports
In addition to static policies (e.g., a simple QR code that activates a pre-installed “block RGB events” policy), our prototype supports passports by transforming certain recognizer events into passport lookups. The system appends the text in a QR code or a Bluetooth MAC address to the base URL at `www.wdac-passport-authority.com/passportlookup/`. If a corresponding passport exists, the server provides its URL. The passport contains a policy DLL that implements our policy interface (Figure 4). The system downloads, verifies, and installs the new policy (if not previously installed).

The process of loading a passport could be optimized by caching server responses. If the system cannot make a network connection, it misses the passport; a future implementation could buffer the network request until connectivity is available, in case the policy is still applicable then. Note that the system does not need a network connection to parse static (non-passport) policies; passports communicated via certain communication technologies (e.g., Bluetooth) could also encode their policy code directly rather than pointing to a server. As noted in Section 4, code in a passport could be signed by a policy authority and sandboxed. Since signature and sandboxing approaches have been well studied elsewhere, we do not include them in our prototype but focus on world-driven access control functionality.

#### 5.3 Prototype Policies
- **Block RGB in Sensitive Area:** We implemented several policies blocking RGB events in sensitive areas, based on QR codes, BLE, WiFi, and audio. For example, a QR code on a bathroom door can specify a policy that blocks RGB until the corresponding “end policy” QR code is detected. Similarly, a BLE emitter can specify such a policy; BLE has a range of roughly 50 meters, making it suitable for detecting a sensitive area like a bathroom. We also use the access point (AP) name of our office’s WiFi network to trigger a policy that blocks RGB events. Additionally, we use our audio frequency recognizer to block RGB events: if a trigger frequency is heard three 32 ms timeslots in a row, the corresponding policy is engaged (and disengaged when the trigger has not been heard for three consecutive timeslots). In our experiments, we used a frequency of 900 Hz; in a real setting, ultrasound may be preferable. Ultrasound is already used in real settings to communicate with smartphones [42]. More complex audio communication is also possible, e.g., encoding a policy in the signal [33].
- **Remove Person from RGB:** We support several policies to remove bystanders from RGB frames. First, we support bystanders wearing opt-out QR codes, though our implementation could easily support an opt-in instead, and filter RGB events to remove the pixels associated with the person nearest such a QR code’s bounding box. We use the per-pixel playerIndex feature of Kinect depth frames. Figure 2 shows a modified RGB frame based on this policy. As a simpler, more efficient policy to remove people from RGB frames, inspired by practices at AdaCamp, we also implemented a color-based policy, using a certain shirt color to indicate an opt-out. This policy (1) detects a 10x10 pixel square of the target color, (2) calculates its average depth, and (3) removes RGB pixels near that depth. Thus, this policy applies to anything displaying the target color and avoids the latency of the Kinect’s player detection. Using a hybrid approach, we also implemented a BLE policy to bootstrap the color policy (discussed more in Section 6).
- **Block Sensitive Audio:** We implemented a policy that blocks sensitive audio based on our speech keyword recognizer. We use a hard-coded grammar that includes words that may signal a sensitive conversation, such as project codenames like “Natal,” as well as explicit user commands such as “stop audio.” The policy blocks audio events once such a keyword is detected and resumes audio events upon command (i.e., when the user explicitly says “begin audio”).

### 6. Evaluation
We evaluate along two axes:
1. **Policy Expressiveness and Implementation Effort:** We show that our architecture can incorporate a wide variety of policies desired by users and proposed in prior work with low developer effort (Section 6.1).
2. **Policy Effectiveness:** We explore the effectiveness of policy communication technologies and world-driven policies implemented in our prototype (Section 6.2).

#### 6.1 Policy Expressiveness & Effort
We validate that our policy interface (Figure 4) is expressive enough to capture realistic policies. We implemented a representative set of policies proposed in prior work relevant to continuous sensing [7, 8, 20, 31, 36], summarized in Figure 5. In some cases, we implemented slightly different enforcement than specified in prior work (e.g., removing people from the frame instead of blurring faces), and we note these differences where applicable. Each policy could be implemented in our prototype with only a modest number of lines of C# code (between 35 and 104, measured using Visual Studio’s Code Metrics), indicating that our architecture supports new and diverse policies with modest additional developer effort.

Other policies exist in prior work, such as a policy to encrypt recordings with a shared key derived with a distributed protocol [16]. We determined that our system could support this policy, but for our purposes here, we chose not to spend effort reimplementing its protocol. Our prototype can also handle existing real-world policies (Appendix A).

We conclude that our architecture’s policy abstraction is sufficiently expressive and that policies can be implemented with modest developer effort.

#### 6.2 Policy Effectiveness
We evaluate policy effectiveness in representative scenarios. Our goal is not to maximize effectiveness but to explore policy communication technologies and demonstrate the feasibility of world-driven access control. We also view our evaluation methodology itself as a contribution for others studying access control for continuous sensing.

##### 6.2.1 Evaluation Methodology
We designed and evaluated representative scenarios, each with one or more environmental policy triggers (Figure 7). For example, in the Bathroom scenario, we affixed QR codes on and near the bathroom door and placed a BLE emitter and a smartphone producing a 900 Hz tone inside. In the Person scenario, a person carried a BLE emitter and wore a QR code and a red color.

We used our prototype to record a trace of raw recognizer events for each scenario. We constructed scenarios so that a policy was applicable in one continuous segment (e.g., a person is only seen once in the Person trace) and that the trace was realistic (e.g., we turned on a faucet in the bathroom). We then replayed every trace once for each policy present. Pre-recorded traces allowed us to compare multiple policies on the same trace. Since our goal is to evaluate feasibility, we considered only one representative trace of each scenario.

We then annotated each trace with ground truth for each policy of interest: whether the ideal enforcement of that policy would modify or block each event. We compared the results of the replay for each policy with our ground truth annotations. Specifically, we introduced the following methodology for evaluating the effectiveness of a policy. Considering only those events that may be affected by the given policy, such as RGB in the Bathroom trace or audio in the Speech trace, we evaluate the policy as follows:

- **Start Lag (False Negatives):** Time before the policy is correctly applied.
- **Finish Lag (False Positives):** Time after the policy should have been stopped.
- **Additional False Positives:** Events incorrectly allowed outside of the lags.
- **Additional False Negatives:** Events incorrectly blocked outside of the lags.

Conceptually, start and finish lag measure the time taken for the policy to take effect and be removed, respectively.