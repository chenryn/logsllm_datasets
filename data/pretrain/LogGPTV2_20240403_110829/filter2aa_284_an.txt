rect and is used mostly during phishing attacks.
Verifies that the protection attribute on the system.web.authentication.forms protection is 
set to All which specifies that the application use both data validation and encryption to help 
protect the authentication cookie.
Verifies that the requireSSL attribute on the system.web.authentication.forms configuration 
element is set to True which forces the authentication cookie to specify the secure attribute. 
This directs the browser to only provide the cookie over SSL.
Verifies that no credentials are specified under the form authentication configuration.
Verifies that the CustomErrors section is configured to have a default URL for redirecting uses 
in case of error.
Verifies that debug compilation is turned off. This eliminates potential performance and se-
curity issues related to debug code enabled and additional extensive error messages being 
returned.
Table 17: FxCop Flags
HttpCookiesRequireSSLShouldBeTrue
TraceShouldBeDisabled
Verifies that the system.web.httpCookies requireSSL configuration is set to True which forces 
all cookies to be sent with the secure attribute. This indicates the browser to only provide the 
cookie over SSL.
Verifies that the system.web.trace enabled setting is set to false which disables tracing. It is 
recommended to disable tracing on production servers to make sure that an attacker cannot 
gain information from the trace about your application. Trace information can help an attack-
er probe and compromise your application.
FormAuthenticationSlidingExpirationShouldBeFalse
HttpCookiesHttpOnlyCookiesShouldBeTrue
Verifies that system.web.authentication.forms slidingExpiration is set to false when the site 
is being served over HTTP. This will force the authentication cookie to have a fixed timeout 
value instead of being refreshed by each request. Since the cookie will traverse over clear text 
network and could potentially be intercepted, having a fixed timeout value on the cookie 
will limit the amount of time the cookie can be replayed. If the cookie is being sent only over 
HTTPS, it is less likely to be intercepted and having the slidingExpiration setting to True will 
cause the timeout to be refreshed after each request which gives a better user experience.
Verifies that the system.web.httpCookies httpOnlyCookies configuration setting is set to True 
which forces all cookies to be sent with the HttpOnly attribute.
A5 - Security Misconfiguration
116
Rule
Description
AnonymousAccessIsEnabled
PagesEnableViewStateMacShouldBeTrue
PagesValidateRequestShouldBeEnabled
PagesViewStateEncryptionModeShouldBeAlways
CustomErrorsModeShouldBeOn
MarkVerbHandlersWithValidateAntiforgeryToken
PagesEnableEventValidationMustBeTrue
RoleManagerCookieProtectionShouldBeAll
RoleManagerCookieRequireSSLShouldBeTrue
RoleManagerCookieSlidingExpirationShouldBeTrue
HttpRuntimeEnableHeaderCheckingShouldBeTrue
Looks in the web.config file to see if the authorization section allows anonymous access.
Verifies that the viewstate mac is enabled.
Verify that validateRequest is enabled.
Verifies that the viewstate encryption mode is not configured to never encrypt.
Verifies that the system.web.customErrors mode is set to On or RemoteOnly. This disable de-
tailed error message returned by ASP.NET to remote users.
ValidateAntiforgeryTokenAttribute is used to protect against potential CSRF attacks against 
ASP.NET MVC applications.
Verifies that event validation is enabled.
Verifies that the system.web.rolemanager cookieProtection is set to All which enforces the 
cookie to be both encrypted and validated by the server.
Verifies that the system.web.rolemanager cookieRequireSSL attribute is set to True which 
forces the role manager cookie to specify the secure attribute. This directs the browser to only 
provide the cookie over SSL.
Verifies that the system.web.rolemanager cookieSlidingExpiration is set to false when the site 
is being served over HTTP. This will force the authentication cookie to have a fixed timeout 
value instead of being refreshed by each request. Since the cookie will traverse over clear text 
network and could potentially be intercepted, having a fixed timeout value on the cookie 
will limit the amount of time the cookie can be replayed. If the cookie is being sent only over 
HTTPS, it is less likely to be intercepted and having the slidingExpiration setting to True will 
cause the timeout to be refreshed after each request which gives a better user experience.
Verifies that the system.web.httpRuntime enableHeaderChecking attribute is set to true. The 
setting indicates whether ASP.NET should check the request header for potential injection 
attacks. If an attack is detected, ASP.NET responds with an error. This forces ASP.NET to apply 
the ValidateRequest protection to headers sent by the client. If an attack is detected the ap-
plication throws HttpRequestValidationException.
A5 - Security Misconfiguration
117
A6
118
A6 - Sensitive Data Exposure
SENSITIVE DATA EXPOSURE
A6
Many web applications do not properly protect sensitive data, such as credit cards, tax IDs, and authentication 
credentials. Attackers may steal or modify such weakly protected data to conduct credit card fraud, identity 
theft, or other crimes. Sensitive data deserves extra protection such as encryption at rest or in transit, as well 
as special precautions when exchanged with the browser.
12.1 Cryptographic Controls
Software developers, architects and designers are at the forefront of deciding which category a particular 
application resides in. Cryptography provides for security of data at rest (via encryption), enforcement of data 
integrity (via hashing/digesting), and non-repudiation of data (via signing). To ensure this cryptographic code 
adequately protections the data, all source code must use a standard (secure) algorithms with strong key sizes.
Common flaws when implementing cryptographic code includes the use of non-standard cryptographic algo-
rithms, custom implementation of cryptography (standard & non-standard) algorithms, use of standard algo-
rithms which are cryptographically insecure (e.g. DES), and the implementation of insecure keys can weaken 
the overall security posture of any application. Implementation of the aforementioned flaws enable attackers 
to use cryptanalytic tools and techniques to decrypt sensitive data.
12.2 Description
Many companies handle sensitive information for their customers, for instance medical details or credit card numbers, 
and industry regulations dictate this sensitive information must be encrypted to protect the customers’ information. 
In the medical industry the HIPAA regulations advise businesses what protections must be applied to medical data, 
in the financial industry many regulations cover PII (personally identifiable information) controls.  
Regardless of the financial impact of regulatory penalties, there are many business reasons to protect (though en-
cryption or hashing) the information processed by an application, including privacy and fraud detection/protection.
All sensitive data that the application handles should be identified and encryption should be enforced.  Simi-
larly a decision should be made as to whether sensitive data must be encrypted in transit (i.e. being sent from 
one computer to another) and/or at rest (i.e. stored in a DB, file, keychain, etc.):
1) Protection in transit; this typically means using the SSL/TLS layer to encrypt data travelling on the HTTP 
protocol, although it can also include FTPS, or even SSL on TCP.  Frameworks such as IIS and Apache Struts 
come with SSL/TLS functionality included, and thus the developer will not be coding the actual TLS encryp-
tion, but instead will be configuring a framework to provide TLS security.  
However the decisions made here, even at an architectural level, need to be well informed, and a discussion on 
TLS design decisions is covered in section 1.3.
2) Protection at rest; this can include encryption of credit cards in the database, hashing of passwords, 
producing message authentication codes (MACs) to ensure a message has not been modified between com-
puters.  Where TLS code will come with a framework, code to encrypt or hash data to be stored will typically 
need to use APIs provided by cryptographic libraries.  
The developer will not be writing code to implement the AES algorithm (OpenSSL or CryptoAPI will do that), the 
developer will be writing modules to use an AES implantation in the correct way.  Again the correct decisions need to 
be made regarding up-to-date algorithms, key storage, and other design decisions, which are covered in section 1.4.
119
A6 - Sensitive Data Exposure
Cryptography Definitions
Before diving into discussions on encrypting traffic and data, some terminology used in the realm of cryptog-
raphy is defined in table 18. 
12.3 What to Review: Protection in Transit
The terms Secure Socket Layer (SSL) and Transport Layer Security (TLS) are often used interchangeably. In 
fact, SSL v3.1 is equivalent to TLS v1.0. However, different versions of SSL and TLS are supported by modern 
web browsers and by most modern web frameworks and platforms.  Note that since developments in attacks 
against the SSL protocol have shown it to be weaker against attacks, this guide will use the term TLS to refer to 
transport layer security over the HTTP or TCP protocols.
The primary benefit of transport layer security is the protection of web application data from unauthorized 
disclosure and modification when it is transmitted between clients (web browsers) and the web application 
server, and between the web application server and back end and other non-browser based enterprise com-
ponents.
In theory, the decision to use TLS to protect computer to computer communication should be based on the 
nature of the traffic or functionality available over the interface.  If sensitive information is passing over the 
Hashing
Entropy
Encoding
Salt
Encryption
Symmetric Encryption
Public-Key Encryption 
(PKI)
Certificate
Non-reversible transformation of data into what is called a ‘fingerprint’ or ‘hashvalue’.  Input of any size can be taken 
and always results in the same size of output (for the algorithm).  The aim is not to convert the fingerprint back into the 
source data at a later time, but to run the hash algorithm over two sets of data to determine if they produce the same 
fingerprint.  This would show that data has not been tampered with.
Essentially this is randomness.  Cryptographic functions will need to work with some form of randomness to allow the 
source data to be encrypted in such a way that an attacker cannot reverse the encryption without the necessary key.  
Having a good source of entropy is essential to any cryptographic algorithm.
Transforming data from one form into another, typically with the aim of making the data easier to work with. For ex-
ample encoding binary data (which could not be printed to a screen into printable ASCII format which can be copy/
pasted.  Note that encoding does not aim to hide the data, the method to return the encoded data back to its original 
form will be publically known.
A non-secret value that can be added to a hashing algorithm to modify the fingerprint result.  One attack against 
hashing algorithms is a ‘rainbow table attack’ where all source values are pre-computed and a table produced.  The 
attacker can then take a fingerprint, look it up in the table, and correspond it to the original data.  Using a unique salt 
value for each data to be hashed protects against rainbow tables, as a rainbow table for each salt value would need to 
be created, which would greatly extend the time taken by an attacker.  The salt is not a secret and can be stored or sent 
with the fingerprint.
Transformation of source data into an encrypted form that can be reversed back to the original source.  Typically the 
algorithms used to encrypt are publically known, but rely on a secret ‘key’ to guide the transformation.  An attacker 
without the key should not be able to transform the data back into the original source.
A form of encryption where the same key is known to both the sender and the receiver.  This is a fast form of encryption, 
however requires a secure, out-of-band method to pass the symmetric key between the sender and receiver.
A form of encryption using two keys, one to encrypt the data, and one to decrypt the data back to its original form.  This 
is a slower method of encryption however one of the keys can be publically known (referred to as a ‘public key’).  The 
other key is called a ‘private key’ and is kept secret.  Any data encrypted with the public key can be decrypted back into 
its original form using the private key.  Similarly any data encrypted with the private key can be decrypted back to its 
original form using the public key.
An association between an entity (e.g. person, company) and a public key.  Typically this forms part of a public-key 
infrastructure where certain trusted entities (e.g. Certificate Authorities in internet TLS) perform validation of an entitles 
credentials and assert (using their own certificate) that a declared public key belongs to the entity.
Term
Description
Table 18: Cryptographic Definitions
120
interface, TLS will prevent eavesdroppers from being able to view or modify the data.  Likewise if the interface 
allows money to be transferred, or sensitive functions to be initiated, then TLS will protect the associated login 
or session information authorizing the user to perform those functions.  However with the price of certificates 
dropping, and TLS configuration within frameworks becoming easier, TLS protection of an interface is not a 
large endeavor and many web sites are using TLS protections for their entire site (i.e. there are only HTTPS 
pages, no HTTP pages are available).
The server validation component of TLS provides authentication of the server to the client. If configured to re-
quire client side certificates, TLS can also play a role in client authentication to the server. However, in practice 
client side certificates are not often used in lieu of username and password based authentication models for 
clients.
Using Validated Implementations
The US government provides a list of software that has been validated to provide a strong and secure imple-
mentation of various cryptographic functions, including those used in TLS.  This list is referred to as the FIPS 
140-2 validated cryptomodules.
A cryptomodule, whether it is a software library or a hardware device, implements cryptographic algorithms 
(symmetric and asymmetric algorithms, hash algorithms, random number generator algorithms, and message 
authentication code algorithms). The security of a cryptomodule and its services (and the web applications 
that call the cryptomodule) depend on the correct implementation and integration of each of these three 
parts. In addition, the cryptomodule must be used and accessed securely.  In order to leverage the benefits of 
TLS it is important to use a TLS service (e.g. library, web framework, web application server) which has been 
FIPS 140-2 validated. In addition, the cryptomodule must be installed, configured and operated in either an 
approved or an allowed mode to provide a high degree of certainty that the FIPS 140-2 validated cryptomod-
ule is providing the expected security services in the expected manner.
When reviewing designs or code that is handling TLS encryption, items to look out for include:
• Use TLS for the login pages and any authenticated pages.  Failure to utilize TLS for the login landing page 
allows an attacker to modify the login form action, causing the user’s credentials to be posted to an arbitrary 
location. Failure to utilize TLS for authenticated pages after the login enables an attacker to view the unen-
crypted session ID and compromise the user’s authenticated session.
• Use TLS internally when transmitting sensitive data or exposing authenticated functionality.  All networks,
both external and internal, which transmit sensitive data must utilize TLS or an equivalent transport layer se-
curity mechanism. It is not sufficient to claim that access to the internal network is “restricted to employees”. 
Numerous recent data compromises have shown that the internal network can be breached by attackers. In 
these attacks, sniffers have been installed to access unencrypted sensitive data sent on the internal network.
• Prefer all interfaces (or pages) being accessible only over HTTPS.  All pages which are available over TLS must
not be available over a non-TLS connection. A user may inadvertently bookmark or manually type a URL to a 
HTTP page (e.g. http://example.com/myaccount) within the authenticated portion of the application.
• Use the “secure” and “http-only” cookie flags for authentication cookies.  Failure to use the “secure” flag 
enables an attacker to access the session cookie by tricking the user’s browser into submitting a request to an 
unencrypted page on the site.  The “http-only” flag denies JavaScript functions access to the cookies contents.
• Do not put sensitive data in the URL.  TLS will protect the contents of the traffic on the wire, including the URL
when transported, however remember that URL’s are visible in browser history settings, and typically written 
A6 - Sensitive Data Exposure
121
to server logs.
• Prevent the caching of sensitive data.  The TLS protocol provides confidentiality only for data in transit but it 
does not help with potential data leakage issues at the client or intermediary proxies.
• Use HTTP Strict Transport Security (HSTS) for high risk interfaces.  HSTS will prevent any web clients from 
attempting to connect to your web site over a non-TLS protocol.  From a server-side point of view this may 
seem irrelevant if no non-TLS pages are provided, however a web site setting up HSTS does protect clients 
from other attacks (e.g. DNS cache poisioning).
• Use 2048 key lengths (and above) and SHA-256 (and above).  The private key used to generate the cipher key
must be sufficiently strong for the anticipated lifetime of the private key and corresponding certificate. The 
current best practice is to select a key size of at least 2048 bits.  Note that attacks against SHA-1 have shown 
weakness and the current best practice is to use at least SHA-256 or equivalent.
• Only use specified, fully qualified domain names in your certificates.  Do not use wildcard certificates, or RFC
1918 addresses (e.g. 10.* or 192.168.*).  If you need to support multiple domain names use Subject Alternate 
Names (SANs) which provide a specific listing of multiple names where the certificate is valid. For example the 
certificate could list the subject’s CN as example.com, and list two SANs: abc.example.com and xyz.example.
com. These certificates are sometimes referred to as “multiple domain certificates”.
• Always provide all certificates in the chain.  When a user receives a server or host’s certificate, the certificate 
must be validated back to a trusted root certification authority. This is known as path validation.  There can 
be one or more intermediate certificates in between the end-entity (server or host) certificate and root certif-
icate. In addition to validating both endpoints, the client software will also have to validate all intermediate 
certificates, which can cause failures if the client does not have the certificates.  This occurs in many mobile 
platforms.
12.4 What to Review: Protection at Rest
As a general recommendation, companies should not create their own custom cryptographic libraries and al-
gorithms. There is a huge distinction between groups, organizations, and individuals developing cryptograph-
ic algorithms and those that implement cryptography either in software or in hardware.  Using an established 
cryptographic library that has been developed by experts and tested by the industry is the safest way to im-
plement cryptographic functions in a company’s code.  Some common examples of libraries used in various 
languages and environments are covered in the below table.
Discussion
Language
C# .NET
Libraries
Class libraries 
within ‘Sys-
tem.Security.
Cryptogra-
phy’
For applications coded in C#.NET there are class libraries and implementations within the ‘System.Security.Cryptog-
raphy’ that should be used.  This namespace within .NET aims to provide a number of warppers that do not require 
proficient knowledge of cryptography in order to use it.
Table 19: Popular Cryptographic implementations according to environment
C/C++ 
(Win32)
CryptoAPI 
and DPAPI
For C/C++ code running on Win32 platforms, the CreyptoAPI and DPAPI are recommended.
C/C++ 
(Linux)
OpenSSL, 
NSS, boringssl
For C/C++ on Linux/Unix operating systems, us OpenSSL, NSS, or one of the many forks of these libraries.
A6 - Sensitive Data Exposure
122
A secure way to implement robust encryption mechanisms within source code is by using FIPS [7] compliant algo-
rithms with the use of the Microsoft Data Protection API (DPAPI) [4] or the Java Cryptography Extension (JCE) [5]. 
A company should identify minimum standards for the following when establishing your cryptographic code 
strategy:
• Which standard algorithms are to be used by applications
• Minimum key sizes to be supported
• What types of data must be encrypted
When reviewing code handling cryptography look out for:
• Is strong enough encryption algorithms being used, and is the implementation of those algorithms FIPS-140 com-
plaint.
• Is the right type of cryptographic algorithm being used, is data being hashed that should be encrypted with a 
symmetric key?  If there is no way to safely transfer the symmetric key to the other party, is public key cryptographic 
algorithms being employed?
• In any cryptographic system the protection of the key is the most important aspect.  Exposure of the symmetric or 
private key means the encrypted data is no longer private.  Tightly control who has access to enter or view the keys, 
and how the keys are used within applications.
• Any code implementing cryptographic processes and algorithms should be reviewed and audited against a set of 
company or regulatory specifications. High level decisions need to be made (and continually revisited) as to what an 
organization considers ‘strong encryption’ to be, and all implementation instances should adhere to this standard.
• Cryptographic modules must be tested under high load with multithreaded implementations, and each piece of 
encrypted data should be checked to ensure it was encrypted and decrypted correctly.
• In .Net check for examples of cryptography in the MSDN Library Security Practices: .NET Framework 2.0 Security 
Practices at a Glance
o Check that the Data Protection API (DPAPI) is being used.
o Verify no proprietary algorithms are being used.
o Check that RNGCryptoServiceProvider is used for PRNG.
o Verify key length is at least 128 bits.
• In ASP perform all of these checks on the COM wrapper as ASP does not have direct access to cryptographic functions
o Check that the Data Protection API (DPAPI) or CryptoAPI is being used into COM object
ASP
Java
CryptoAPI 
and DPAPI
Java Cryp-
tography 
Extension, 
BouncyCas-
tle, Spring 
Security
Classis ASP pages do not have direct access to cryptographic functions, so the only way is to create COM wrappers in 
Visual C++ or Visual Basic, implementing calls to CryptoAPI or DPAPI.  Then call them from ASP pages using the Server.
CreateObject method.
JCE is a standard API that any cryptographic library can implement to provide cryptographic functions to the developer. 
Oracle provide a list of companies that act as Cryptographic Service Providers and/or offer clean room implementations 
of the JCE.  BouncyCastle is on of the more popular implementations.  Spring Secuirty is also popular in application 
where Spring is already being utilized.
A6 - Sensitive Data Exposure
• P122 - b
slightly incorrect 