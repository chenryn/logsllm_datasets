320
384
448
512
Left Bound
Fig. 9: Error of each range query in WR using strategy In
with n = 512,  = 1, and β = 0.05
to use the other queries strategies more efﬁciently we would
need transformations similar to the ones used in the matrix
mechanism.
√
Figure 9 exposes the error of answering each range query
(i.e., each row) in WR with strategy In and n = 512. While
we use the same kind of plot, this error cannot be directly
compared with the one shown in Figure 7 of [30], since we use
a different error metrics: (α,β)-accuracy vs MSE. Nonetheless,
we share the tendency of having lower error on small ranges and
signiﬁcant error on large ranges. Now, since the noisy values
that will be added (using the function add) are statistically
independent, we can use the Chernoff bound to show that the
error is approximately O(
√
n) for each range query, and a
maximum error of O(
n log n) for answering any query in
WR. If we compare our maximum error O(
n log n) with
the one of the matrix mechanism based on the identity strategy
O(n/2), it becomes evident how Chernoff bound is useful to
provide tighter accuracy bounds. Unfortunately, as previously
stated, the error of strategies Hn and Yn in DPella is not better
than the one of the strategy In, so we cannot reach the same
accuracy the matrix mechanism achieves with these strategies
(see Figure 7 of [30]). This limitation can be addressed by
leveraging the fact that DPella is a programming framerwork
that could be extended by adding the matrix mechanism—and
some other features—as black-box primitives.
√
VI. LIMITATIONS & EXTENSIONS
We have discussed so far the use of DPella as an API
allowing a programmer to implement her own data analyses.
However, we foreseen DPella to also serve as a ”glue” which
enables a programmer to integrate arbitrary DP-algorithms, as
(black-box) building blocks while reasoning about accuracy. In
this light, our design supports the introduction of new primitives
when some analyses cannot be directly implemented because
either (i) the static analysis for accuracy provided by DPella
is too conservative, or (ii) DPella’s API building blocks are
not enough to express the desired analysis. Below, we describe
several possible such extensions.
The matrix mechanism (MM): As we discussed in the
previous section, in some situations DPella allows to answer
in an accurate way multiple counting queries in a way that is
similar to the MM. As an example, DPella estimates accuracy
better then MM for the strategy I—recall Section V. However,
To do this, we have implemented several strategies to answer
an speciﬁc workload WR: the set of all range queries over
a domain. Figure 8 illustrates the workload that would be
answer for a frequency count of four ranges. Having the
identity I4, hierarchical H4 and wavelet Y4 strategies to
compute the noisy count of each range, binary hierarchy of
sums, and the Haar wavelet, respectively. Our implementation
generates noisy counts and any possible combination of them
will yield (at least) the same error as using strategy I4. In
other words, the more accurate answer for WR will be yield
by the identity strategy. This is not unexpected, since in order
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
421
for other workloads and other strategies the accuracy provided
by DPella is too conservative. To consider other workloads
and strategies, the MM can be incorporated into DPella as a
primitive for answering counting queries. The requirements for
this are that the return values are tainted, and that we have an
iCDFs for it—this can be calculated as in [18]. In general, it
is sound to add new primitives which permit a more precise
accuracy analysis as long as the return values are tainted, and
an accuracy information is provided—thus effectively allowing
to further compose the primitive with other analyses by means
of the union bound.
Primitives with non-compositional privacy analyses: Several
DP-algorithms have a privacy analysis which does not follow
directly by composition. Some well-known examples are report-
noisy-max, the exponential mechanism, and the sparse-vector
technique—see [20] and [43] for more details. In their natural
implementations, these algorithms branch on the result of
some noised query’s result, and the privacy analyses use
some properties of the noise distributions that are not directly
expressible in terms of composition of differentially private
components. Because DPella’s API does not allow to branch
on the results of noised queries, and because the privacy
analyses that DPella support are based on composition, we
cannot implement these analyses directly using the DPella API.
However, we can provide them as (black-box) primitives. We
already discussed how to integrate report-noisy-max through a
primitive dpMax (Figure 3). The exponential mechanism (EM)
can be incorporated into DPella in a similar way. One subtleties
that one has to consider is the fact that the privacy guarantee of
EM depends on a bound of the sensitivity of the score function.
We handle this by requiring the score function’s output to be
bound between 0 and 1, bounding the sensitivity to be at most
1. As with dpMax, the output of EM is tainted. The EM is an
important mechanism which allows to implement many other
techniques. In particular, we can use EM to implement the
ofﬂine version of the sparse vector technique, as discussed
in [20]. These components allow DPella to support automated
reasoning about accuracy for complex algorithms such as the
ofﬂine version of the MWEM algorithm [44] following an
analysis similar to the one discussed in [22].
Online adaptive algorithms: Several DP-algorithms have
different implementations depending if they work ofﬂine—
where all the decision are taken upfront before running the
program—or online—where some of the decision are taken
while running the program. Online algorithms usually have a
more involved control ﬂow which depend on information that
are available at runtime. As an example, the online version
of the sparse vector technique uses the result of a DP query
to decide whether to stop or not the computation (or whether
to stop or not giving meaningful answers). These kind of
algorithms usually are based on some re-use of a noised result
which correspond to a taint value in DPella. So, the current
design of DPella cannot support them. We plan to explore as
future how to integrate these algorithms in DPella.
Improving accuracy through post-processing: Several works
have explored the use of post-processing techniques to improve
on accuracy, e.g. [31, 45, 46]. Most of these works use accuracy
measure that differ from the one we consider here, and use
some speciﬁc properties of the particular problem at hand. As
an example, the work by Hay et al. [31] describes how to
boost accuracy in terms of Mean Squared Error (MSE) for DP
hierarchical queries by post-processing the DP results by means
of some relatively simple optimization. This improvement in
accuracy relies among other things on the impact that the
optimization has on the MSE, which does not directly apply
to the α-β notion of accuracy we use here. We expect that,
also for the notion of α-β accuracy we use, it is possible to
use post-processing for improve accuracy. However, we leave
this for future works. Moreover, the reason for us to chose
α-β accuracy as the principal notion of accuracy in DPella is
because of its compositional nature expressible through the use
of probability bounds. It is an interesting future direction to
design a similar compositional theory also for other accuracy
notions such as MSE. We expect DPella to be extensible to
incorporate such a theory, once it is available.
VII. RELATED WORK
Programming frameworks for DP: PINQ [2] uses dynamic
tracking and sensitivity information to guarantee privacy
of computations. Among the frameworks and tools sharing
features with PINQ we highlight: Airavat [3] ; wPINQ [47];
DJoin [38]; Ektelo [12]; Flex [40]; and PrivateSQL [48].
In
contrast to DPella, none of these works keeps track of accuracy,
nor static analysis for privacy or accuracy. As discussed in
Section III, DPella supports a limited form of joins, and it is still
able to provide accuracy estimates. We leave as future work to
support more general join operations through techniques similar
to the ones proposed in Flex and PrivateSQL. While several
of the components from the frameworks discussed above are
not supported in the current implementation of DPella, these
can be added as black-box primitives, as we discussed in
Section VI. All the programming frameworks discussed above
support reasoning about privacy for complex data analyses
while neglecting accuracy, whereas DPella supports accuracy,
but restricts the programming framework to rule out certain
analysis (e.g., adaptive ones) for which we do not have a
general compositional theory, yet.
Tools for DP: In a way similar to DPella, there exist tools
which support reasoning about accuracy and restrict the kind of
data analyses they support. GUPT [15] is a tool based on the
sample-and-aggregate framework for differential privacy [49].
GUPT allows analysts to specify the target accuracy of the
output, and compute privacy from it—or vice versa. This
approach has inspired several of the subsequent works and
also our design. The limitations of GUPT are that it supports
only analyses that ﬁt in the sample-and-aggregate framework,
and it supports only conﬁdence intervals estimates expressed
at the level of individual queries. In contrast, DPella supports
analyses of a more general class, such as the ones we discussed
in Section II and Section V, and it also allows to reason about
the accuracy of combined queries, rather that just about the
individual ones. PSI [17] offers to the data analyst an interface
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
422
for selecting either the level of accuracy that she wants to
reach, or the level of privacy she wants to impose. The error
estimates that PSI provides are similar to the ones that are
supported in DPella. However, similarly to GUPT, PSI supports
only a limited set of transformations and primitives, it supports
only conﬁdence intervals at the level of individual queries, and
in its current form it does not allow analysts to submit their
own (programmed) queries.
APEx [18] has similar goals as DPella and it allows data
analysts to write queries as SQL-like statements. However, the
model that APEx uses is different from DPella’s. It supports
three kind of queries: WCQ (counting queries), ICQ (iceberg
counting queries), and TCQ (top-k counting queries). To answer
WCQ queries, APEx uses the matrix mechanism (recall Section
V) and applies a Monte Carlo simulations to achieve accuracy
bounds in terms of α and β, and to determine the least privacy
parameter () that ﬁts those bounds. We have shown how DPella
can be used to answer queries based on the identity strategies
using partition and concentration bounds. To answer effectively
different workloads and strategies as well as ICQ and TCQ
queries, we would need to extend DPella with the matrix
mechanism as a black-box (recall Section VI). While APEx
supports advanced query strategies, it does not provide means
to reason about combinations of analyses, e.g., it does not
support reasoning about the accuracy of a query using results
from WCQs queries to perform TCQs ones. DPella instead
has been designed speciﬁcally to support the combination of
different queries. As we discussed in Section VI, DPella can
be seen as a programming environment that could be combined
with some of the analyses supported by tools similar to PSI,
GUPT or APEx in order to reason about the accuracy of the
combined queries.
Formal Calculi for DP: There are several works on enforcing
differential privacy relying on different models and techniques.
Within this group are Fuzz [4]—a programming language
which enforces (pure) differential privacy of computations
using a linear type system which keeps track of program
sensitivity—and its derivatives DFuzz [6], Adaptive Fuzz [10],
Fuzzi [13], and Duet [50]. Hoare2 [7], a programming language
which enforces (pure or approximate) differential privacy using
program veriﬁcation, together with its extension PrivInfer [8]
supporting differentially private Bayesian programming; and
other systems using similar ideas [43, 51, 9, 52].
reasoning. This choice makes aHL very expressive but difﬁcult
to automate. DPella instead favors automation over expressivity.
As discussed before, the use of DPella to derive accuracy bound
is transparent to a programmer thanks to its automation. On
the other hand, there are mechanisms that can be analyzed
using aHL and cannot be analyzed using DPella, e.g. adaptive
online algorithms. Second, aHL supports only reasoning about
accuracy but it does not support reasoning about privacy. This
makes it difﬁcult to use aHL for reasoning about the privacy-
accuracy trade-offs. Finally, aHL supports only reasoning using
the union bound and it does not support reasoning based
on the Chernoff bound. This makes DPella more precise
on the algorithms that can be analyzed using the Chernoff
Bound. Barthe et al [53] use aHL, in combination with a logic
supporting reasoning by coupling, to verify differentially private
algorithms whose privacy guarantee depends on the accuracy
guarantee of some sub-component. We leave exploring this
direction for future works. More recently, Smith et al. [27]
propose an automated approach for computing accuracy bounds
of probabilistic imperative programs. This work shares some
similarities with our. However, it does not support reasoning
about privacy, and it only uses the Union Bound and do not
attempt to reason about probabilistic independence to obtain
tighter bounds.
Other works: In a recent work, Ligett et al. [54] propose
a framework for developing differentially private algorithms
under accuracy constraints. This allows one to chose a given
level of accuracy ﬁrst, and then ﬁnding the private algorithm
meeting this accuracy. This framework is so far limited to
empirical risk minimization problems and it is not supported
by a system, yet.
VIII. CONCLUSIONS
DPella is a programming framework for reasoning about
privacy, accuracy, and their trade-offs. DPella uses taint analysis
to detect probabilistic independence and derive tighter accuracy
bounds using Chernoff bounds. We believe the principles behind
DPella, i.e., the use of concentration bounds guided by taint
analysis, could generalize for more notions of privacy such
as Renyi-DP [55], concentrated differential privacy [56], zero
concentrated differential privacy [57], or truncated concentrated
differential privacy [58] (as done with (, δ)-DP). As future
work, we envision lifting the restriction that programs should
not branch on query outputs.
ACKNOWLEDGMENT
We thank the anonymous reviewers for constructive feedback
on an earlier version of this work. We would like to thank
Gilles Barthe for early feedback on the development of DPella.
This work was initiated by a STINT Initiation grant (IB 2017-
77023) and supported by the Swedish Foundation for Strategic
Research (SSF) under the project Octopi (Ref. RIT17-0023)
and WebSec (Ref. RIT17-0011) as well as the Swedish research
agency Vetenskapsr˚adet. Marco Gaboardi’s work was partially
funded by the National Science Foundation under Grants No.
1718220 and 1845803.
Barthe et al. [29] devise a method for proving differential
privacy using Hoare logic. Their method uses accuracy bounds
for the Laplace Mechanism for proving privacy bounds of the
Propose-Test-Release Mechanism, but cannot be used to prove
accuracy bounds of arbitrary computations. Later, Barthe et
al. [22] develop a Hoare-style logic, named aHL, internalizing
the use of the union bound for reasoning about probabilistic
imperative programs. The authors show how to use aHL for
reasoning in a mechanized way about accuracy bounds of
several basic techniques such as report-noisy-max, sparse vector
and MWEM. This work has largely inspired our design of
DPella but with several differences. First, aHL mixes the
reasoning about accuracy with the more classical Hoare-style
Authorized licensed use limited to: Carleton University. Downloaded on August 06,2020 at 17:57:38 UTC from IEEE Xplore.  Restrictions apply. 
423
REFERENCES
[1] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating
noise to sensitivity in private data analysis,” in Proceedings of
the Third Conference on Theory of Cryptography, ser. TCC’06,
2006, pp. 265–284.
[2] F. D. McSherry, “Privacy integrated queries: an extensible
platform for privacy-preserving data analysis,” in SIGMOD.
ACM, 2009.
[3] I. Roy, S. T. V. Setty, A. Kilzer, V. Shmatikov, and E. Witchel,
“Airavat: Security and privacy for MapReduce,” in Proc. USENIX
Symposium on Networked Systems Design and Implementation,
NSDI, 2010.
[4] J. Reed and B. C. Pierce, “Distance makes the types grow
stronger: a calculus for differential privacy,” in Proc. ACM
SIGPLAN International Conference on Functional Programming,
2010.
[5] A. Haeberlen, B. C. Pierce, and A. Narayan, “Differential privacy
under ﬁre,” in Proc. of USENIX Security Symposium, 2011.
[6] M. Gaboardi, A. Haeberlen, J. Hsu, A. Narayan, and B. C. Pierce,
“Linear dependent types for differential privacy,” in Proc. ACM
SIGPLAN-SIGACT Symposium on Principles of Programming
Languages, 2013.
[7] G. Barthe, M. Gaboardi, E. J. Gallego Arias, J. Hsu, A. Roth,
and P.-Y. Strub, “Higher-order approximate relational reﬁne-
ment types for mechanism design and differential privacy,” in
POPL’15. ACM, 2015.
[8] G. Barthe, G. P. Farina, M. Gaboardi, E. J. G. Arias, A. Gordon,
J. Hsu, and P. Strub, “Differentially private bayesian program-
ming,” in Proc. ACM SIGSAC Conference on Computer and
Communications Security, 2016.
[9] D. Zhang and D. Kifer, “LightDP: towards automating differen-
tial privacy proofs,” in Proc. ACM SIGPLAN Symp. on Principles
of Programming Languages, 2017.
[10] D. Winograd-Cort, A. Haeberlen, A. Roth, and B. C. Pierce, “A
framework for adaptive differential privacy,” PACMPL, vol. 1,
no. ICFP, 2017.
[11] N. M. Johnson, J. P. Near, and D. Song, “Towards practical