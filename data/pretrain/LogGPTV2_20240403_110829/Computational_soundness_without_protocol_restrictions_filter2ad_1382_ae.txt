to only after the hybrid execution we ask the simulator to
decide what terms these variables stand for.
In our case, we change the simulator such that when pars-
ing a ciphertext c (corresponding to a key not picked by the
simulator), the simulator just outputs τ (c) := xc.
(Here
we assume an inﬁnite set of variables x indexed by cipher-
texts.) And in the end, when the hybrid execution ﬁnished,
the simulator outputs a “ﬁnal substitution” ϕ that maps xc
to either enc(N e, τ (m), N c) if by the end of the execution
the simulator has learned the corresponding decryption key
and can compute the plaintext m, or to garbageEnc(N e, N c)
if the decryption key was not received or decryption fails.
Unfortunately, to make this go through, the simulator gets
an additional tasks. In the original hybrid execution, terms
sent to the protocol do not contain variables, and whenever
we reach a computation node in the protocol, we can ap-
ply the constructor or destructor to the arguments of that
node and compute the resulting new term. This is not pos-
sible any more. For example, what would be the output a
dec-node with plaintext argument xc? Thus, the hybrid ex-
ecution will in this case just maintain a “destructor term”, in
which the destructors are not evaluated. (E.g., a node might
then store the term dec(dk (N e), xc).) That leaves the fol-
lowing problem: A computation node branches to its yes- or
no-successor depending on whether constructor/destructor
application succeeds or fails. But in the hybrid execution,
the constructor/destructor application is not evaluated, we
do not know whether it succeeds or fails. This leads to an
additional requirement for the simulator: After each compu-
tation node in the hybrid execution, the simulator is asked
a “question”. This question consists of the destructor term
that is computed at the current node, and the simulator
has to answer yes or no, indicating whether the application
should be considered to have succeeded or failed. (And then
the yes- or no-successor of the current node is taken accord-
ingly.)
In our case, to answer these questions, the simulator will
just reduce the term as much as possible (by evaluating de-
707structors), replace variables xc by enc- or garbageEnc-terms
wherever we already know the necessary keys, and make the
“right” choices when destructors are applied to xc. If all de-
structors succeed, the simulator answers yes. A large part of
the full proof is dedicated to showing that this can be done
in a consistent fashion.
In [5], it is shown that if a lazy simulator with the fol-
lowing four properties (sketched below) exists, then we have
computational soundness:
• Indistinguishability: The hybrid and the computa-
tional execution are indistinguishable (in terms of the
nodes passed through in execution).
• DY-ness: Let ϕ be the ﬁnal substitution (output by
the simulator at the end of the execution). Then in
any step of the execution it holds that Sϕ ⊢ tϕ where
t is the term sent by the simulator to the protocol, and
S is the set of the terms received by the protocol (note
that although S, t may be destructor terms, Sϕ and tϕ
do not contain variables any more and thus reduce to
regular terms without destructors).
• Consistency: For any question Q that was asked from
the simulator, we have that the simulator answered yes
iﬀ evaluating Qϕ (which contains destructors but no
variables) does not return ⊥.
• Abort-freeness: The simulator does not abort.
In the proof we construct such a simulator and show all the
properties above. (Indistinguishability is relatively similar
to the case without lazy parsing, but needs some additional
care because the invariants need to be formulated with re-
spect to unevaluated destructor terms. DY-ness follows the
same lines but becomes considerably more complicated.)
In the proof of DY-ness, it does, however, turn out that
lazy sampling does not fully solve the problem of receiving
decryption keys. In fact, PROG-KDM security alone is not
suﬃcient to guarantee computational soundness in this case
(and neither is IND-CCA2). We illustrate the problem by
an example protocol:
Alice picks a key ek (N ), a nonce M and sends a cipher-
text c := enc(ek (N ), M, R) over the network (i.e., to the
adversary). Then Alice expects a ciphertext c∗. Then Alice
sends dk (N ). Then Alice expects a secret key sk ∗. Finally,
Alice tests whether dec(sk ∗, c∗) = (M, M ).
It is easy to see that in the symbolic model, this test will
always fail. But in the computational setting, it is possible
to construct encryption schemes with respect to which the
adversary can produce c∗, sk ∗ such that this test succeeds:
Start with a secure encryption scheme (KeyGen′, Enc′, Dec′).
Then let KeyGen := KeyGen′, and Enc := Enc′, but mod-
ify Dec′ as follows: Given a secret key of the form sk =
(special, m), and a ciphertext c = (special), Dec(sk , c)
outputs m. On other inputs, Dec behaves like Dec′. Now the
adversary can break the above protocol by sending sk ∗ :=
(special, (M, M )). Notice that if (KeyGen′, Enc′, Dec′) was
PROG-KDM (or IND-CCA2), then (KeyGen, Enc, Dec) is
still PROG-KDM (or IND-CCA2): Both deﬁnitions say
nothing about the behavior of the encryption scheme for
dishonestly generated keys.
Of course, the above encryption scheme can easily be ex-
cluded by adding simple conditions on encryption schemes:
Encryption keys should uniquely determine decryption keys
and vice versa, any valid decryption key should successfully
decrypt any ciphertext that was honestly generated using
the corresponding encryption key, ciphertexts should deter-
mine their encryption key.
But even then a more complex construction works: Let
C be some class of circuits such that for each C ∈ C,
there exists at most one x, y such that C(x, y) = 1. Let
KeyGen := KeyGen′. Modify Enc′ as follows: Upon input
ek = (special, ek ′, C), Enc(ek , m) runs Enc′(ek ′, m). For
other inputs, Enc behaves like Enc′. And Dec′
is modi-
ﬁed as follows: Upon input dk = (special, dk ′, C, x, y) and
c = (special, ek ′, C) with C(x, y) = 1, Dec(dk , c) returns x.
Upon dk = (special, dk ′, C, x, y) with C(x, y) = 1 and dif-
ferent c, Dec(dk , c) returns Dec′(dk ′, c). And upon all other
inputs, Dec′ behaves like Dec. Again, this construction does
not loose PROG-KDM or IND-CCA2 security.
The adversary can break our toy protocol by choosing
C as the class of circuits Cc deﬁned by Cc((M, M ), sk ) =
1 if Dec(sk , c) = M and Cc(x, y) = 0 in all other
cases.
the adversary chooses
(ek ′, dk ′) ← KeyGen′, c∗ := (special , ek ′, Cc) and after re-
ceiving a decryption key dk from Alice, he chooses dk ∗ :=
(special , dk ′, Cc, (M, M ), dk ).
Then after getting c,
Notice that this example can be generalized to many dif-
ferent protocols where some m is uniquely determined by
the messages sent by Alice, and the adversary learns m only
after producing c but before sending the corresponding de-
cryption key: Simply choose a diﬀerent class C of circuits
such that C(m, x) = 1 is a proof that m is the message
encoded by Alice.
Clearly, the above example shows that PROG-KDM alone
does not imply computational soundness. To understand
what condition we need,
let us ﬁrst understand where
the mismatch between the symbolic and the computational
model is.
In the symbolic model, the adversary can only
produce an encryption of some message if he knows the un-
derlying plaintext.
In the computational model, however,
even if we require unique decryption keys, it is suﬃcient
that the underlying plaintext is ﬁxed, it is not necessary
that the adversary actually knows it.
Thus, to get computational soundness, we need to ensure
that the adversary actually knows the plaintext of any mes-
sage he produces. A common way for modeling knowledge is
to require that we can extract the plaintext from the adver-
sary. Since we work in the random oracle model anyway (as
PROG-KDM only makes sense there), we use the following
random-oracle based deﬁnition:12
call
an
Definition 9. We
scheme
encryption
for any
(KeyGen, Enc, Dec) malicious-key extractable if
polynomial-time (A1, A2),
there exists a polynomial-time
algorithm MKE (the malicious-key-extractorsuch that the
following probability is negligible:
Pr(cid:2)DecO(d, c) 6= ⊥ ∧ DecO(d, c) /∈ M : (z, c) ← AO
M ← MKE O(1η, c, queries), d ← AO
1 (1η),
2 (1η, z)(cid:3)
Here O is a random oracle. And queries is the list of all
random oracle queries performed by A1. And M is a list of
messages (of polynomial length).
This deﬁnition guarantees that when the adversary pro-
12This is closely related to the notion of plaintext-awareness
[16], except that plaintext-awareness applies only to the case
of honestly generated keys.
708duces a decryption key d that decrypts c to some message
m, then he must already have known m while producing c.
Notice that malicious-key extractability is easy to achieve:
Given a PROG-KDM secure encryption scheme, we mod-
ify it so that instead of encrypting m, we always encrypt
(m, H(m)) where H is a random hash oracle (and decryp-
tion checks the correctness of that hash value). The re-
sulting scheme does not loose PROG-KDM security and is
malicious-key extractable.
In Deﬁnition 9, we only require that the extractor can
output a list of plaintexts, one of which should be the cor-
rect one. We could strengthen the requirement and require
the extractor to output only a single plaintext. This deﬁni-
tion would considerably simplify our proof (essentially, we
could get rid of lazy sampling since we can decrypt all ad-
versary generated ciphertexts). However, that stronger def-
inition would, for example, not be satisﬁed by the scheme
that simply encrypts (m, H(m)). Since we strive for mini-
mal assumptions, we opt for the weaker deﬁnition and the
more complex proof instead.
How is malicious-key extractability used in the proof of
computational soundness? We extend the simulator to call
the extractor on all ciphertexts he sees (Sim 3). In the origi-
nal proof, a simulator that is not DY implied that a term t
with Sϕ 0 tϕ is produced by τ in some step i. This means
that tϕ has a “bad” subterm tbad . This, however, does not
immediately lead to a contradiction, because tbad could be
a subterm not of t, but of ϕ(xc) for some variable xc in
t. Since ϕ(xc) is produced at some later point, we cannot
arrive at a contradiction (because the bitstring mbad which
is supposed to be unguessable in step i, might already have
been sent in step j). But if the simulator runs the malicious-
key extractor in step i, we can conclude that the bitstring
mbad corresponding to the subterm tbad of ϕ(xc) has already
been seen during step i. This then leads to a contradiction
as before.
6. THE MAIN RESULT
We are now ready to state the main result of this paper.
First, we state the conditions a symbolic protocol should
satisfy.
Definition 10. A CoSP protocol is randomness-safe if it
satisﬁes the following conditions:
1. The argument of every ek -, dk -, vk -, and sk -
computation node and the third argument of every E-
and sig-computation node is an N -computation node
with N ∈ NP . (Here and in the following, we call the
nodes referenced by a protocol node its arguments.) We
call these N -computation nodes randomness nodes.
Any two randomness nodes on the same path are an-
notated with diﬀerent nonces.
2. Every computation node that is the argument of an
ek -computation node or of a dk -computation node on
some path p occurs only as argument to ek - and dk -
computation nodes on that path p.
3. Every computation node that is the argument of a vk -
computation node or of an sk -computation node on
some path p occurs only as argument to vk - and sk -
computation nodes on that path p.
4. Every computation node that is the third argument of
an E-computation node or of a sig-computation node
on some path p occurs exactly once as an argument in
that path p.
5. There are no computation nodes with the constructors
garbage , garbageEnc, garbageSig , or N ∈ NE.
In contrast to [4], we do not put any restrictions on the
use of keys any more. The requirements above translate to
simple syntactic restrictions on the protocols that require
us to use each randomness nonce only once. For example,
in the applied π-calculus, this would mean that whenever
we create a term enc(e, p, r), we require that r is under a
restriction νr and used only here.
In addition to randomness-safe protocols, we put a num-
ber of conditions on the computational implementation. The
cryptographically relevant conditions are PROG-KDM se-
curity and malicious-key extractability of the encryption
scheme, and strong existential unforgeability of the signature
scheme. In addition, we have a large number of additional
conditions of syntactic nature, e.g., that the pair-constructor
works as expected, that from a ciphertext one can eﬃciently
compute the corresponding encryption key, or that an en-
cryption key uniquely determines its decryption key. These
requirements are either natural or can be easily achieved by
suitable tagging (e.g., by tagging ciphertexts with their en-
cryption keys). The full list of implementation conditions is
given in Appendix A.
Theorem 1. The implementation A (satisfying the im-
plementation conditions from Appendix A) is a computa-
tionally sound implementation of the symbolic model from
Section 2 for the class of randomness-safe protocols. (Note
that our deﬁnition of computational soundness covers trace
properties, not equivalence properties.)
The full proof of this theorem is given in [7]. From this
result, we get, e.g., immediately computational soundness
in the applied π-calculus (see [4]) without the restrictions
on keys imposed there.
Acknowledgments. Dominique Unruh was supported by
the Cluster of Excellence “Multimodal Computing and Inter-
action”, by the European Social Fund’s Doctoral Studies and