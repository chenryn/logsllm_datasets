### Hooking Operations and Invoking the VMwall Kernel Module

Based on coarse-grained rules, we intercept the operation and invoke the VMwall kernel module for additional application-level checks. We modified `ebtables` to implement this hook, which passes a reference to the packet to VMwall.

`Ebtables` does not natively support packet queuing. If this feature were present, it would enable filters within the kernel to store packets for future processing and reinjection into the network. To allow the VMwall kernel module to queue packets currently under inspection by the user agent, we extended `ebtables` to include packet queuing and reinjection capabilities.

### Accessing DomU Kernel Memory

VMwall utilizes the XenAccess introspection library [31] to access domU kernel memory from dom0. It maps domU memory pages containing kernel data structures into the virtual memory space of the user agent running in the trusted VM. XenAccess provides APIs that map domU kernel memory pages, identified either by explicit kernel virtual addresses or by exported kernel symbols. In Linux, these exported symbols are stored in the `System.map` file. VMwall uses specific domU data structures that are exported by the kernel and thus mapped using kernel symbols. Other data structures reachable via pointers from known structures are mapped using kernel virtual addresses.

Figure 4 illustrates the internal mechanism involved in mapping the memory page that contains the desired kernel data structure in the domU virtual machine.

### Parsing Kernel Data Structures

To identify processes using the network, VMwall must parse high-level kernel data structures from the raw memory pages provided by XenAccess. Extracting these data structures is non-trivial. For example, Linux maintains a doubly-linked list of all running processes, with the head pointer stored in the exported kernel symbol `init_task`. To extract the list of processes running inside domU, VMwall maps the memory page containing the `init_task` symbol. However, VMwall must traverse the entire linked list, requiring the offset to the next member in the process structure. This information is extracted offline directly from the kernel source code and used in the user agent. While this method is not optimal due to changes in offset values across kernel versions, there are automatic methods to extract this information from the kernel binary if it was compiled with a debug option [18].

This approach provides VMwall with the necessary information to traverse kernel data structures. Using known field offsets, VMwall extracts virtual addresses of pointer fields from the mapped memory pages and recursively maps domU memory pages until it traverses the data structures needed to extract the process name corresponding to the source or destination port of a network communication. Figure 5 shows the kernel data structures traversed by the user agent to correlate TCP packet and process information. First, it attempts to obtain a reference to the socket bound to the port number specified in the packet. After acquiring this reference, it iterates over the list of processes to find the process owning the socket.

### Policy Design and Rules

VMwall identifies legitimate connections through a whitelist-based policy listing processes allowed to send or receive data. Each process that needs to communicate over the network must be specified in the whitelist a priori. The whitelist resides in dom0 and can only be updated by administrators, similar to traditional application-level firewalls. The whitelist-based design introduces usability issues because all applications that should be allowed to make network connections must be specified in the list. This limitation is inherent to whitelist-based products and solutions [6, 12].

VMwall’s kernel module maintains a rule table containing rules dynamically generated by the user agent after performing introspection. A rule includes source and destination port and IP address information, an action, and a timeout value used by the kernel module to expire and purge old rules for UDP connections. For TCP connections, the kernel module automatically purges rules when it processes a packet with the TCP `FIN` or `RST` flag set. In case of abnormal termination, VMwall uses the timeout mechanism to purge the rules.

### Evaluation

The primary requirement of an application-level firewall is to block connections to or from malicious software and allow connections to or from benign applications. We evaluated VMwall's ability to filter out packets made by various types of attacks while allowing packets from known processes to pass unimpeded. We tested VMwall against Linux-based backdoors, worms, and bots attempting to use the network for malicious activity.

#### 6.1 Illegitimate Connections

We first tested attacks that receive inbound connections from remote attackers. These attacks are rootkits that install backdoor programs, which run as user processes, listen for connections on a known port, and execute requests sent by the attacker. We used the following backdoors:
- **Blackhole**: Runs a TCP server on port 12345 [22].
- **Gummo**: Runs a TCP server on port 31337 [22].
- **Bdoor**: Runs a backdoor daemon on port 8080 [22].
- **Ovas0n**: Runs a TCP server on port 29369 [22].
- **Cheetah**: Runs a TCP server on a port specified by the attacker [22].

Once installed on a vulnerable system, attacks such as worms and bots may attempt to make outbound connections without prompting from a remote attacker. We tested VMwall with the following malware that generates outbound traffic:
- **Apache-ssl**: A variant of the Slapper worm that self-propagates by opening TCP connections for port scanning [23].
- **Apache-linux**: A worm that exploits vulnerable Apache servers and spawns a shell on port 30464 [23].
- **BackDoor-Rev.b**: A tool used by a worm to make network connections to arbitrary Internet addresses and ports [20].
- **Q8**: An IRC-based bot that opens TCP connections to contact an IRC server to receive commands from the botmaster [14].
- **Kaiten**: A bot that opens TCP connections to contact an IRC server [24].
- **Coromputer Dunno**: An IRC-based bot providing basic functionalities such as port scanning [13].

VMwall successfully blocked all illegitimate connections attempted by malware instances. In all cases, both sending and receiving, VMwall intercepted the first SYN packet of each connection and passed it to the userspace component. Since these malicious processes were not in the whitelist, the VMwall userspace component informed the VMwall kernel component to block these connections. As VMwall was used in packet queuing mode, no malicious packets were ever passed through.

#### 6.2 Legitimate Connections

We also evaluated VMwall’s ability to allow legitimate connections made by processes running inside domU. We selected several network applications and added their names to VMwall’s whitelist. We then ran these applications inside domU. Table 1 shows the list of processes tested, the type of connections used, and the effect of VMwall on those connections. All connections should be allowed to be correct.

VMwall allowed all connections made by these applications. The `yum` application, a package manager for Fedora Core Linux, had interesting runtime behavior. During our test, we updated domU with the `yum update` command. During the package update, `yum` created many child processes with the same name, and these child processes made network connections. VMwall successfully validated all the connections via introspection and allowed their network connections.

#### 6.3 Performance Evaluation

A firewall verifying all packets traversing a network may impact the performance of applications relying on timely delivery. We investigated the performance impact of VMwall on network applications running inside the untrusted virtual machine. Experiments were conducted with and without VMwall running inside dom0 on a machine with an Intel Core 2 Duo T7500 processor at 2.20 GHz with 2 GB RAM. Both dom0 and domU virtual machines ran 32-bit Fedora Core 5 Linux. DomU had 512 MB of physical memory, and dom0 had the remaining 1.5 GB. The versions of Xen and XenAccess were 3.0.4 and 0.3, respectively. Experiments were performed using both TCP and UDP connections, and all results show the median time taken from five measurements. Microbenchmarks were measured with the Linux `gettimeofday` system call, and longer executions with the `time` command-line utility.

VMwall’s performance depends on the introspection time taken by the user component. Since network packets are queued during introspection, the introspection time is critical for the system's performance. We measured the introspection time for incoming and outgoing connections to and from domU. Table 2 shows the results of experiments measuring introspection time.

It is evident that the introspection time for incoming TCP connections is very small. Strangely, the introspection time for outgoing TCP connections is notably higher. This difference is due to how the Linux kernel stores information for TCP connections. It maintains TCP connection information for listening and established connections in two different tables. Listening TCP sockets reside in a table of size 32, whereas established sockets are stored in a table of size 65536. Since newly established TCP sockets can be placed at any index, the introspection routine must search half of the table on average.

We also measured the introspection time for UDP data streams. Table 2 shows the results for inbound and outbound UDP packets. In this case, the introspection time for inbound and outbound data varies little. The Linux kernel keeps information for UDP streams in a single table of size 128, which explains the similar introspection times.

To measure VMwall’s performance overhead on network applications running inside domU, we performed experiments with two different metrics for both inbound and outbound connections. In the first experiment, we measured VMwall’s impact on network I/O by transferring a 175 MB video file over the virtual network via `wget`. Our second experiment measured the time necessary to establish a TCP connection or transfer UDP data round-trip as perceived by software in domU.

We transferred the video file from dom0 to domU and back again with VMwall running inside dom0. Table 3 shows the results of our experiments.