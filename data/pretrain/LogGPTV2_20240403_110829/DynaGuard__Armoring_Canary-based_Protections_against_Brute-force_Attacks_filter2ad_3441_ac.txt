Inside
the signal handler, DynaGuard detects whether the fault is
due to DynaGuard’s instrumentation (i.e., when DynaGuard
tries to push an address for a canary in the read-only page
of the CAB) and allocates additional memory for the CAB
if necessary.
As there may be multiple running threads, and the ex-
ception handler may execute in the context of a diﬀerent
thread than the one that generated the SIGSEGV, Dyna-
Guard maintains a hashmap of all the running threads and
their TLS entries.
Inside the signal handler, DynaGuard
iterates through all the threads in the hashmap and exam-
ines whether the memory location that caused the fault falls
within an allocated CAB.2
Since registering a signal handler may overwrite exist-
ing handlers of the application, DynaGuard also hooks all
signal and sigaction calls. If the signal is diﬀerent than
SIGSEGV, DynaGuard does not alter the application han-
dler. Otherwise, DynaGuard saves the application’s handler
and then overwrites it with its own handler.
If the fault
did not occur due to a write into one of the protected pages
1Def-use analysis, as well as checks for leaf functions that
will never call another protected function can be used to
further improve the performance of DynaGuard. However,
in our measurements, we considered the worst-case scenario
and always spilled registers.
2The memory address that caused the fault is accessible
through the si_addr ﬁeld of the siginfo_t data structure
that is passed to DynaGuard’s signal handler.
of the allocated CABs, DynaGuard passes the signal to the
saved application handler.
Lastly, in order to ensure that the CAB contains canary
addresses only for active frames, DynaGuard checks for any
stack unwinding and removes the entries corresponding to
destroyed frames from the CAB. This is based on the simple
observation that, at any point during execution, since the
stack always grows towards lower addresses, all addresses
stored in a CAB should be higher than the current stack
pointer. DynaGuard hooks the following calls that result in
stack unwinding: __cxxabiv1::__cxa_end_catch and
(sig)longjmp.
In the case of __cxa_end_catch, the
stack pointer has already been updated to its new value and
DynaGuard can check if the CAB is consistent with the un-
wound stack. In the cases of siglongjmp and longjmp,
the new value of the stack pointer is retrieved from the
contents of the __jmpbuf entry of the jump buﬀer that is
passed to the calls, and the check is performed accordingly.
Once all the components for ensuring the correctness of
the canary bookkeeping are in place, DynaGuard registers a
hook for the fork system call. Once fork is executed, in
the context of the child process, and before fork returns,
DynaGuard sets a new canary in the process’ TLS and up-
dates all the canaries inherited by the parent process.
5.2 DBI-based DynaGuard
If source code is not available, or when re-compiling a pro-
gram is not an option, we can still protect security-critical
binaries using the DBI-based ﬂavor of DynaGuard, imple-
mented over Intel’s Pin [24] dynamic binary instrumenta-
tion framework. Whenever a binary is instrumented with
Pin, execution occurs within three distinct contexts: the
context of the instrumented application, the context of the
pintool which guides the instrumentation process, and ﬁ-
nally, within the context of Pin itself, which controls the
context-switching between the pintool and the application.
From the perspective of the underlying OS, only one process
is running. In reality though, glibc and other libraries are
loaded multiple times, and the executing code is either code
of the native application, instrumentation code inserted by
the pintool, or code belonging to Pin itself.
Before executing any application code, during the instru-
mentation phase, Pin instruments the native binary with
new code, or analysis code as it is colloquially known, spec-
iﬁed by the pintool in use. DynaGuard’s instrumentation
routines deﬁne where in the binary the analysis code will be
inserted (e.g., before or after a particular instruction, system
call, or library load), which routines will be called when the
new code is triggered, and what arguments will be passed
to them. Note that instrumentation happens only once.
To minimize DynaGuard’s runtime performance overhead,
our goal is to minimize the instrumentation code, and more
importantly, to optimize the analyses routines, as it is the
analysis code that dominates the performance overhead. Due
to the DynaGuard pintool’s model of execution, updating
the canary in the TLS of the instrumented process with a
system call like prctl, would result in a TLS update within
the context of Pin, instead of that of the instrumented ap-
plication, since libraries like glibc are duplicated and the
execution of prctl occurs under Pin. For this reason, Pin
exposes an API call for getting the base address of the TLS
area of the instrumented program. DynaGuard registers a
callback routine to be executed in the child process when-
calls, as we did in the GCC implementation; instead, Dy-
naGuard checks for changes in the stack pointer value and
then updates the CAB accordingly.
6. DISCUSSION
In this section we discuss alternative DynaGuard designs
and elaborate on their drawbacks and beneﬁts. Subsequently,
we describe how the proposed architecture can serve as the
basis for resolving other security problems arising from the
(current) OS process creation mechanism.
As an alternative design for DynaGuard, one could con-
sider implementing a stack frame chain, using a mechanism
similar to the one used by exception handlers. In such a de-
sign, all canary-protected frames would be chained together,
with each protected frame holding a pointer to the previous
frame that is canary-protected. This eliminates the need for
a CAB, as the linked list would allow for “unwinding” the
stack and updating all canaries directly at runtime.
Unfortunately, this approach has several drawbacks, which
arise mainly from the fact that the pointer to the previous
frame that is canary-protected should itself be protected (by
a canary), to prevent it from being modiﬁable—otherwise,
an attacker could tamper with the stack unwinding process.
This would require the modiﬁcation of current implementa-
tions in a non-transparent manner, and would break com-
patibility with legacy software and third-party libraries. On
the contrary, our proposed design can be transparently ap-
plied to production systems.
More importantly, DynaGuard’s architecture oﬀers the
foundation for a compiler-level solution to several other prob-
lems arising from the current OS process creation model. For
instance, the current process creation mechanism may aﬀect
the trustworthiness of cryptographic Pseudo-Random Num-
ber Generators (PRNGs), as was the case with OpenSSL [5,
32] and LibreSSL [2]. The PRNGs of these libraries pro-
duced the same random number chain in parent and child
processes. Modern compilers could adopt DynaGuard’s de-
sign to support per-process data bookkeeping that would
enable entropy gathering and transparent updating of the
state of PRNGs, similarly to previously-proposed compiler
schemes that extract entropy from the OS at boot time [37].
7. EVALUATION
In this section we evaluate the performance overhead of
DynaGuard and its eﬀectiveness in protecting against byte-
by-byte canary brute-force attacks. For our measurements
we use the SPEC CPU2006 benchmark suite [17], as well as
a series of popular (open-source) server applications. Over-
all, our GCC-based implementation of DynaGuard incurs
an overhead ranging from 0.03% to 5.4%, with an average
of 1.2%. The Pin-based version of DynaGuard incurs an av-
erage overhead of 170.66%. However, this overhead is domi-
nated by the native DBI framework (Pin), with DynaGuard
adding only 2.92% on top of that, on average.
7.1 Effectiveness
We conﬁrmed that DynaGuard defends against a set of
publicly-available exploits [4, 27] targeting the Nginx web
server, which rely on brute-forcing stack canaries using the
technique outlined in Section 2. To verify that DynaGuard
does not aﬀect software correctness, we evaluated it over the
SPEC CPU2006 benchmark suite, and also applied it to a
Figure 4: Pinpointing the canary push operation inside the
function prologue. The instrumentation code selects instruc-
tion (1) and inserts the analysis routine push_canary be-
tween instructions (1) and (2).
ever a fork system call executes; this callback calculates
the base address of the TLS segment and is responsible for
the canary update (both in the TLS and in all active stack
frames).
To compute the new canary value, DynaGuard utilizes the
kernel’s random number generator (/dev/urandom) and, if
such a device is not available, falls back to arc4random.
5.2.1 Canary Bookkeeping
DynaGuard utilizes a lightweight CAB implementation in-
spired by libdft [21]. In particular, DynaGuard allocates
a per-thread CAB in the process’ heap, and then uses one
of Pin’s scratch registers as a pointer to this buﬀer. This
optimization has the beneﬁt of minimizing the instrumen-
tation code and eliminating the unnecessary locking logic
of the built-in trace buﬀer [19].
In order to correctly up-
date the canary on each newly-forked process, CAB holds
the address of every stack canary in the active frames, as
described in Section 4. CAB is updated upon the follow-
ing events: (a) canary push (function prologue), (b) canary
pop (function epilogue), and (c) stack unwinding (because
of exception handling or setjmp/longjmp).
In the following, we examine how DynaGuard handles
each of the previous scenarios. As mentioned in Section 2,
the canary is originally stored in the TLS. Upon a canary
push from the TLS to a stack frame, the address at which
the canary is stored is saved in the CAB, as illustrated in
Fig. 4: DynaGuard inserts a call to push_canary before
mov rax,−0x8(%rbp) executes. The arguments to this
analysis function are the thread context (holding a refer-
ence to the process’ CAB through Pin’s scratch register), as
well as the address in which the canary will be stored in the
stack (which is known at runtime as instruction (2) is about
to execute).
All the analysis routine needs to perform at this point
is to store the canary address into the CAB and increment
the buﬀer index. In addition, since the number of canary ad-
dresses that are present in the CAB at any given time equals
the number of canary-protected frames that are present in
the process’ stack, DynaGuard will be able to successfully
update all canaries upon a fork.
Likewise, whenever a protected frame is destroyed, the re-
spective canary address is removed from the CAB. In order
to provision for stack unwinding, the DynaGuard pintool ex-
amines whether there is any modiﬁcation of the stack pointer
during runtime. As dynamic binary instrumentation enables
the monitoring of all executed instructions, we do not need
to perform any hooking of longjmp or exception handling
   Instrumentation Pseudocode if((instruction has segment prefix)  && (prefix is one of fs/gs)             && (offset from fs/gs is 0x28/0x14)        && (instr. is a ‘mov’ from mem to reg)     && (next instr. is a `mov’ from reg to mem)&& (dest. operand(register) of current instr.   is the source operand of next instr.)) {  insert_analysis_call(            before_next_instr,   push_canary(thread_context,   canary_address))}push   rbpmov    rsp,%rbpsub    $0x40,rspmov    fs:0x28,%rax  (1)mov    rax,-0x8(%rbp)(2)Sample Function Prologue(a) GCC-based version.
(b) Pin-based version.
Figure 5: The runtime overhead of DynaGuard (normalized over native execution).
variety of popular forking applications, such as the Apache
and Nginx web servers, and the PostreSQL, MySQL, and
SQLite database servers. We observed no incompatibilities
or any altered program functionality.
As a ﬁnal step of our correctness evaluation, we manually
stress-tested DynaGuard over a series of scenarios that in-
cluded combinations of multi-threaded and forking programs
that executed setjmp/longjmp and triggered exceptions.
In all cases we veriﬁed that DynaGuard successfully ran-
domized the stack canaries for all newly-created processes
without causing any unwanted behavior.
7.2 Performance
To obtain an estimate of DynaGuard’s overhead on CPU-
intensive applications, we utilized the SPEC CPU2006 bench-
mark suite, whereas in order to examine how it performs on
I/O-bound programs, we used a series of popular web and
database servers: Apache, Nginx, PostgreSQL, MySQL, and
SQLite. For all the server applications, except MySQL, we
used the Phoronix [39] benchmark suite and maintained its
default conﬁguration, modifying only the compilation stage.
For benchmarking MySQL we used the SysBench bench-
mark tool [33]. Note that in all cases, applications were
compiled with the -fstack-protector option enabled.
All experiments were performed on a system running De-
bian GNU/Linux v8, equipped with two 2.40GHz six-core
Intel Xeon E5645 CPUs and 48GB of RAM.
Figure 5a summarizes the performance overhead of our
GCC-based implementation of DynaGuard. All binaries
were compiled with the DynaGuard plugin and had the
-fno-omitframe-pointer compiler option asserted. Dy-
naGuard incurs an average slowdown of 1.5% on the SPEC
CPU2006 benchmarks, and 0.46% on the server applications.
In all cases, the overhead of the GCC implementation of Dy-
naGuard is below 5.4% for the SPEC CPU2006 benchmarks
and below 1.5% for the I/O-bound applications, with the
overhead being negligible (< 0.5%) for the Apache and Ng-
inx web servers.
Figure 5b shows the performance overhead of the Pin-
based version of DynaGuard. Speciﬁcally, the incremental
overhead over the native DBI framework is less than 2.92%
for all the tested applications. The overall slowdown over
the native binary ranges from 0.4% to 3.2x. In particular,