bit) is composed of XOR and AND gates, which X-HE does
not support, we adapt the computation by emulating the truth
table with integer operations. (We provide more details in our
technical report [19].)
After
the x-server computes an encrypted indicator
(d[v is a neighbor]), it computes the integer multiplication between
the encrypted indicator (d[v is a neighbor]) and encrypted simi-
larity (τ (u, v)), which is denoted as the encrypted threshold
similarity φ(u, v). By Equation 2, if d[v is a neighbor] = 1, then
φ(u, v) (cid:6)= 0 and hence v’s proﬁle contributes to the predicted
ratings of user u; i.e., v is a neighbor of u.
Fig. 2: The x-server and the TP collaboratively perform
the encrypted comparison: x > 0. MSB denotes the most
signiﬁcant bit.
B. X-NN Security
Recall
that X-NN is used for performing comparison
operations. X-NN is secure and provides system-level privacy
if it is indistinguishable from the ideal comparison operation
to the x-server and to the TP respectively. Here, the ideal
comparison operation takes as input an encrypted integer from
the x-server, nothing from the TP, and outputs the encrypted
bit decomposition of that integer to the x-server, nothing to
the TP.
Theorem 2: X-NN is secure given that X-HE is semanti-
cally secure.
Proof sketch: Recall
that all parties are honest-but-
curious. We show that the messages to the TP are random
ciphertexts, and the messages to the x-server are compu-
tationally indistinguishable from random ciphertexts. In this
protocol, the TP only sees a random value encrypted under
the TP’s key; the messages are indeed random ciphertexts
to the TP. In this protocol, the x-server is given an integer
encrypted under the master key, and then the x-server obtains
encrypted bit decomposition under the master key. Given that
X-HE is semantically secure (Theorem 1), the x-server obtains
messages which are computationally indistinguishable from
encryptions of random messages. (The full proof is in [19].)
V. RECOMMENDATION AND PRIVACY
A. Recommendation
The recommendation procedure of X-REC involves four
crucial phases: x-client processing, x-server computation, TP
switching and x-client decryption.
X-client processing. Each x-client xcu caches locally a ran-
dom subset of items (rated or unrated). These items are cached
for the purpose of item sampling. Whenever user u behind xcu
rates some item i, then xcu creates three vectors (each of length
L) 12: the normalized vector (Pu), the difference vector (Qu)
and the binary vector 13 (Cu). The normalized vector is used in
the similarity computation (Equation 5) whereas the difference
(in Equation 6) and the binary (in Equation 7) vectors are used
for the predictions. These vectors correspond to the current
item rated by u along with some additional randomly sampled
distinct L − 1 items which might not have been rated by u
previously. The encrypted corresponding proﬁles are updated
on the x-server with the corresponding vectors sent by the
client.
(cid:8)(cid:4)(cid:3)
As X-HE applies only to integer values, we ﬁrst scale the
normalized and difference vectors with a value V and then
round them to the nearest integer values. The value of V is
set to 10 in our evaluation (§ VI). We denote the normalized
value for the rated element with item-id i (in the vector
Pu) as Pu,i and compute it as: Pu,i = (cid:3)(ru,i − ¯ru) · Cu,i ·
i∈Iu(ru,i − ¯ru)2(cid:4). For any sampled item j (not rated
V
by u), Pu,j is set to 0. Similarly, we compute the elements of
the vector Qu with item-id i as: Qu,i = (cid:3)(ru,i − ¯ru)· Cu,i · V (cid:4)
where Cu,i is set to 1 if u (user behind xcu) rated item i and
0 if u did not rate item i.
Then, xcu encrypts these three vectors using SG, key-
switches using MSG→SM , and then sends the encrypted vectors
([Pu]SM , [Qu]SM , [Cu]SM ) to the x-server.
X-server computation. The x-server hosts an encrypted
database (X-DB) which stores the encrypted proﬁles of the
users. The x-server receives the encrypted vectors ([Pu]SM ,
[Qu]SM , [Cu]SM ) from the x-client and updates u’s proﬁle in
X-DB. Then, the x-server proceeds to the encrypted similarity
computation, which is done periodically ofﬂine (as in Net-
ﬂix [28]), to compute the threshold-based neighbors. Recall
that X-REC leverages a random user sampling technique to
guarantee user-level privacy besides performance improve-
ment. The x-server randomly samples a fraction F of the total
users, denoted F-Sample, and then computes the predictions
from the similar users in that sample. We now present the
encrypted similarity ([τ ]SM ) computation on the x-server. Let
[Pu]SM denote the encrypted proﬁle of u stored in X-DB
on the x-server. We compute the encrypted adjusted cosine
12Each vector consists of the item-id along with the actual value.
13This vector represents the binary proﬁle of a user.
444
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:11 UTC from IEEE Xplore.  Restrictions apply. 
similarity as follows 14:
[τ ]SM =
(cid:2)
i∈Iu∩Iv
[Pu,i]SM .[Pv,i]SM
(5)
Note that the decryption of this similarity value would be
V 2-times the actual similarity value. Next, we compare the
similarities of users in F-Sample, for the current user, with a
threshold value. We leverage X-NN to compute the threshold-
based neighbors for user u.
Neighbor selection. The x-server encrypts the threshold (T )
under SG and uses the public transformation matrix MSG→SM
to transform T into an encryption under SM : [T ]SM . Next,
[T ]SM - [τ ]SM =
X-REC uses X-NN with the input as:
[T − τ ]SM . If τ ≥ T , then we get [1]SM else we get [0]SM .
The encrypted comparison is computed periodically with a
collaboration between the x-server and the TP as shown in
Figure 2. We denote this encrypted output as [d[τ (u,v)>T ]]SM
for threshold-based similarity comparison between users u and
v where d[ ] denotes the Iverson bracket indicator. FSample
denotes the set of sampled users. The formula for prediction
computation in Algorithm 1 (Step 14) involves two terms 14:
(6)
(cid:7)
τ (u, v) · (rv,i − ¯rv) · Cv,i · d[τ (u,v)>T ]
(cid:7)
Eu,i =
|τ (u, v)| · Cu,i · d[τ (u,v)>T ]
(7)
v∈FSample
Du,i =
v∈FSample
j=B·K
To compute the absolute value of similarity (τ (u, v)), we
use an approximation to avoid another round of interaction
with the TP through X-NN. We compute an approximate value
of Du,i as follows. We consider M users in the FSample. We
divide the users into { M
K } blocks, denoted as B, where each
K −1(cid:7)
block consists of K users.
(cid:10)(cid:11)(cid:11)(cid:12)K · B·K+K−1(cid:7)
K −1(cid:7)
(cid:9)
M
M
λ(a, vj, i)
Du,i,B =
Du,i =
B=0
B=0
X-REC computes [Eu,i]SM and [Du,i,B]SM , in the en-
crypted domain, using the equations mentioned above. To
prevent
the collusion between TP and any arbitrary user
(system-level privacy), the x-server adds the TP obfuscator
where λ(u, vj, i) = τ (u, vj)2 · Cvj ,i · d[τ (u,vj )>T ].
(cid:13)ru,i = ¯ru + Eu,i/Du,i.
The formula assumes K divides M and can easily be
generalized. The formula for predicted rating computation is:
Ru to Eu,i (i.e., (cid:13)Eu,i = Eu,i + Ru) and also to each block
Du,i,B (i.e., (cid:13)Du,i,B = Du,i,B + Ru) in the ciphertext domain.
(cid:13)Du,i,B]SM ) are forwarded to the TP
Ru is encrypted under SG, switched to encryption under SM
and then added to the ciphertexts using an (X-HE) addition
operation. The x-server stores Ru which is then sent to the x-
client in the next iteration (update) for user u. The encrypted
results ([
which stores them locally and forwards them to the x-client
for u in the next iteration. Hence, the x-client does not need
to wait for the duration of the x-server computation as well as
the TP key-switching operations and will receive it in the next
update (log-in session) from the x-server. The x-client receives
the encrypted results from the previous iteration (update) in the
current recommendation step.
TP switching. The TP uses the key-switching matrices
(cid:13)Eu,i]SM and [
14 The plaintext operations “.” and “+” are overloaded with the respective
X-HE operators in the encrypted domain.
445
MSM→SG to transform encryptions with master key SM to en-
cryptions with guard key SG. It receives the encrypted [
and [
and [
(Table I). Finally, the encryptions [
updated locally to be sent to the x-client in the next iteration
(log-in session).
X-client decryption. When the x-client receives [
(cid:13)Eu]SM
(cid:13)Du]SM from the x-server. Then, the TP computes [
(cid:13)Eu]SG
(cid:13)Du]SG by using the key-switching matrix MSM→SG
(cid:13)Du]SG are
(cid:13)Eu]SG and [
(cid:13)Eu]SG and
[(cid:13)Du]SG from the TP, they are encrypted with the guard key.
(cid:13)Eu,i]SG )− Ru
(cid:13)Du,i,B]SG)−Ru. The predicted rating
is ﬁnally computed at the x-client:(cid:13)ru,i = ¯ru + Eu,i/(Du,i · V )
(cid:9)
The x-client also receives the TP obfuscator (R) from the
x-server (Figure 1). The x-client uses the guard key SG to
decrypt the encrypted results: Eu,i = Dec(SG, [
and Du,i,B = Dec(SG, [
where Du,i = ΣB=0,1,.., M
Du,i,B.
K
The x-client computes the ﬁnal predictions, sorts the items
based on the new predictions, and stores the sorted predictions
locally. For every (rating) click by the end-user u, the x-client
displays the top-N items, not yet rated by u, leveraging the
most recent predictions stored locally.
B. Privacy Analysis
This subsection summarizes the privacy analysis of X-
REC. We provide the detailed proofs of system-level privacy,
user-level privacy, and their interpretations in our companion
technical report [19].
System-level privacy. Recall that system-level privacy means
that X-REC is indistinguishable to the x-server (as well as
to users who collude with the x-server) from the ideal rec-
ommender where each user inputs a user proﬁle and receives
predicted ratings as an output whereas the x-server inputs noth-
ing and receives users’ encrypted proﬁles only. As we show
in this section, the TP is also involved in the recommendation.
Therefore, X-REC should also be indistinguishable to the TP
(as well as to the users who collude with the TP) from the ideal
recommender. The ideal recommender takes nothing from the
TP as an input and outputs nothing to the TP.
Theorem 3: X-REC ensures system-level privacy given
that X-HE is semantically secure.
Proof sketch: Recall that X-NN is secure given that X-
HE is semantically secure (Theorem 2); therefore, we substi-
tute the ideal comparison for X-NN in the recommendation.
Recall that all parties are honest-but-curious. Since all parties
are honest-but-curious, we only need to show that (1) any
x-client (or any user) receives messages that depend on the
prediction, (2) the x-server receives messages that depend on
the encrypted proﬁles, and (3) the TP receives messages that
are random ciphertexts.
First, we consider the case where there is no collusion. In
the protocol, any x-client receives the obfuscator R as well
as the obfuscated prediction encrypted under key SG. As the
prediction is the output of the protocol, any x-client’s message
depends on the prediction. In the protocol, the x-server receives
the user proﬁles encrypted under key SM , which can be
easily simulated 15 by random ciphertexts given that X-HE
is semantically secure. In the protocol, the TP receives an
15Here simulating a message m means that the receiver R of m is able to
self-construct a message ˆm, given the output of R in the protocol, such that
ˆm and m are computationally indistinguishable.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:37:11 UTC from IEEE Xplore.  Restrictions apply. 
encryption of the obfuscated prediction and therefore can also
be simulated by a random ciphertext.
Second, we consider the case where the x-server colludes
with some users, and the case where the TP colludes with
some users. When the x-server colludes with some users,
the x-server receives the predictions of the corrupted users.
Since the prediction is the output of the protocol for any
corrupted user and the x-server is honest-but-curious, we can
easily simulate the encryption of the obfuscated prediction
for any corrupted user, while for any non-corrupted user, we
still simulate their encrypted proﬁles by random ciphertexts.
When the TP colludes with some users,
the TP receives
the obfuscated prediction encrypted under key SM and the
obfuscator R for any corrupted user. Since the prediction is
the output of the protocol for any corrupted user and the TP
is honest-but-curious, we can easily simulate the encryption
of the obfuscated prediction for any corrupted user, while for
any non-corrupted user, we still simulate their encryption of
obfuscated prediction by random ciphertexts.
We note that due to the use of different obfuscators R for
different users, even if the TP colludes with some users, the
TP is unable to see the predicted ratings of any non-corrupted
user (which can not be simulated).
Thus, we reduce the system-level privacy of X-REC, along
with the security of X-NN, to the semantic security of X-HE.
User-level privacy. Recall that the goal of user-level privacy is
to ensure that the predicted rating of a user is indistinguishable
from an ideal prediction where another user is not even present
in X-REC.
Theorem 4: The predicted rating of a user is (ln 1
1−F , F )-
indistinguishable from an “ideal” prediction that excludes
another user (which could be any other user) where F denotes
the fraction of sampled users.
Proof sketch:
In this setting, we assume that only one
user u is corrupted as well as honest-but-curious. Consider
that u continually queries for predictions and the prediction
Bu, provided to u, is a random variable that follows some
distribution. Let v be a new user that joins the system while the
other users of the system remain unchanged. Then, u receives
a prediction which is another random variable Bu(v).
We only need to show that Bu and Bu(v) are (ln 1
1−F , F )-
indistinguishable (even if we do not have any prior knowledge
regarding the exact distribution of Bu and Bu(v)): i.e., ∀T
where T is an arbitrary set of predicted values. By symmetry,
we only sketch the proof for the ﬁrst inequality. Given a
sampling fraction F to sample among N users, if we pick
F N users uniformly at random, then we have
possi-
ble choices and given a certain choice, Bu is determined.
For N + 1 users (including v), we have
possible
choices and Bu(v) is determined for a certain choice. Thus,
instead of enumerating the possible values of Bu (or Bu(v)),
we focus on the possible choices and compare the choices
N
between Bu and Bu(v). Clearly, we have
F N
additional choices in the case of Bu(v). In the extreme case,
these
choices all contribute to just one set
(cid:15)
(cid:15) −(cid:14)
(cid:15) −(cid:14)
(cid:14)
(cid:14)
F (N +1)
F (N +1)
N
F N
(cid:15)
(cid:14)
(cid:15)
N +1
F (N +1)
N
F N
N +1
N +1
P r(Bu ∈ T ) ≤ 1
1 − F
P r(Bu(v) ∈ T ) ≤ 1
1 − F
· P r(Bu(v) ∈ T ) + F
· P r(Bu ∈ T ) + F
(cid:14)
(cid:15)
(T ), and thus the probability of T increases immediately by