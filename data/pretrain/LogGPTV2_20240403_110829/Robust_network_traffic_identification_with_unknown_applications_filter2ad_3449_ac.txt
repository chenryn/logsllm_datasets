12:
end if
13:
14: end for
end if
accordingly. This means the classiﬁcation system is able to
learn new classes. The updated system can deal with more
applications and achieve further ﬁne-grained classiﬁcation.
Frequent system update is not necessary according to pre-
vious research [35]. If the classiﬁed zero-day trafﬁc indicates
any signiﬁcant change to the applications, the system update
will be triggered to retrain the RTC classiﬁer. Some discussions
on classiﬁer retraining are provided in Section VI-B.
In the above-mentioned procedure, training samples for new
classes may include noise because trafﬁc clusters are not 100%
pure. This issue may affect the classiﬁcation accuracy of known
classes. To tackle this issue, we propose the application of a
two-level classiﬁcation strategy.
In the ﬁrst level, the
-classes classiﬁer obtained be-
fore the system update can be utilized to perform trafﬁc classi-
ﬁcation. Ideally, zero-day trafﬁc will be classiﬁed into a generic
unknown class. In the second level, training samples for new
classes obtained during a system update can be used to train
a new classiﬁer, and this classiﬁes trafﬁc in the generic un-
known class into ﬁne-grained new classes. The advantage of the
two-level classiﬁcation strategy is the performance of known
classes will not be affected. In this sense, the robustness of the
trafﬁc classiﬁcation system can be improved.
IV. PARAMETER OPTIMIZATION
The setting of a parameter is a signiﬁcant challenge for
a trafﬁc classiﬁcation method that applies machine learning
techniques. We observe the performance of the proposed RTC
scheme relies on the effectiveness of unknown discovery. In
unknown discovery, there are two parameters:
determining
the number of clusters produced by -means, and
indicating
the size of an unlabeled training set. Fig. 2 reports the true
positive rate (TPR) and the false positive rate (FPR) of zero-day
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
6
IEEE/ACM TRANSACTIONS ON NETWORKING
Fig. 2.
Impact of parameters to unknown discovery. (a) TPR and FPR for various number of clusters
. (b) TPR and FPR for various unlabeled training sizes.
and various
sample detection produced by unknown discovery. The experi-
ment setup we used here is consistent with the one we used in
Section V-B. TPR is the rate of the sum of correctly detected
zero-day trafﬁc to the sum of all actual zero-day trafﬁc. FPR
is the rate of the sum of the trafﬁc inaccurately detected as
zero-day to the sum of trafﬁc of known applications. Fig. 2(a)
shows the results with a ﬁxed
. It
is clear that while the FPR produced in the ﬁrst step was low,
the corresponding TPR was not high either. The second step
signiﬁcantly improved TPR and further reduced FPR. TPR of
unknown discovery changed from about 28% to 99% when
increased from 100 to 4000. Meanwhile, its FPR increased
from 0% to 20%. The ﬁnal classiﬁcation performance will have
a big difference if
changes dramatically. It is necessary to
select a good
to balance TPR and FPR in order to achieve
high classiﬁcation accuracy. By ﬁxing
to 1000 and varying
from 3000 to 30 000, we obtain Fig. 2(b). This ﬁgure shows
that increasing
can slightly affect TPR and FPR. Compared
to the ﬁrst step, the second step can effectively improve TPR
by about 20%. If we consider
is out of control in practical
applications, our parameter setting focuses on .
We propose a new optimization method combining a 10-fold
cross validation and binary search to ﬁnd an optimal
. The ad-
vantage of the optimization method is twofold: accuracy and
speed. This method is applied in the proposed RTC scheme
for performance evaluation, as mentioned in Section V-B. In
10-fold cross validation, the original training set, including la-
beled and unlabeled trafﬁc ﬂows, is randomly partitioned into
10 equal-size subsets. Of the 10 subsets, a single subset is re-
tained as validation data for testing the model of unknown dis-
covery. The remaining nine subsets are used as training data.
The cross-validation process is then repeated 10 times, with
each of the 10 subsets used exactly once as the validation data.
The 10 results from the folds are then averaged to produce a
single estimation.
A new problem of which metric can be used to evaluate the
results of unknown discovery in cross validation is critical to
the optimization accuracy. Accuracy is a single value common
for measuring the overall performance of trafﬁc classiﬁcation.
However, accuracy calculated using the labeled training data
for known classes cannot measure the performance of zero-day
trafﬁc detection. Based on the empirical results as shown in
Fig. 2(a), we ﬁnd FPR is a good measure for cross valida-
tion. From a theoretical point of view, our original idea is the
following:
•
to search for a maximum that does not produce false
positives.
This refers to our ability to detect as many accurate zero-day
samples as possible without introducing any errors. However,
experimental results show the TPR obtained using this idea is
low. An observation from Fig. 2(a) is that TPR dramatically
increases if FPR slightly increases from 0. Practically, the
threshold of the false positive for parameter optimization can
be set to a small value. Based on our experiments, we ﬁnd that
3% is a good value for FPR.
Another problem is that searching for an optimal
is time-
consuming. For example, if the training set has 10 000 ﬂows,
may change from 1 to 10 000. Fortunately, we ﬁnd FPR is mono-
tone and increases as
increases. Therefore, a binary search is
helpful to quickly ﬁnd , and the corresponding FPR is closest
to 3%. Algorithm 4 describes the procedure of automatic pa-
rameter selection. A binary search of
takes logarithmic time,
which is very efﬁcient. Fig. 3 shows the results of this intelligent
method for different
can severely af-
fect classiﬁcation accuracy. This optimization method can suc-
cessfully ﬁnd an optimized
and produce excellent trafﬁc clas-
siﬁcation accuracy. The trafﬁc dataset used in this section also
refers to Section V.
. It is clear that a bad
V. PERFORMANCE EVALUATION
A large number of experiments were carried out on real-world
trafﬁc datasets to compare the RTC scheme with four state-of-
the-art trafﬁc classiﬁcation methods. This section reports the
experiments and results.
A. Dataset
In this paper, four Internet trafﬁc traces are used for our exper-
imental study, as shown in Table I. They are captured from three
Internet positions located around the world, so the sampling
points are heterogeneous in terms of link type and capacity.
The collection time ranges from 2006 to 2010, covering ﬁve re-
cent years in which the Internet has grown and evolved rapidly.
Since either partial or full packet payload is preserved in these
trafﬁc traces, we build the ground truth (i.e., the actual classes of
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
ZHANG et al.: ROBUST NETWORK TRAFFIC CLASSIFICATION
7
TABLE I
TRAFFIC TRACES
passive probe at a 100-Mb/s Ethernet edge link from an Internet
service provider located in Australia. Full packet payloads are
preserved in the collection without any ﬁltering or packet loss.
The trace is 7 days long and began on November 27, 2010.
Following the signiﬁcant work of [3], [8], and [35], we
focus exclusively on the vast majority of trafﬁc (up to 95%)
in the observed networks: TCP trafﬁc. Note the proposed
RTC scheme is independent to the transport-layer protocol.
In consideration of practical uses, we adopt a 900-s idle
timeout for ﬂows terminated without a proper teardown.
To establish the ground truth in datasets, we develop a DPI
tool matching regular expression patterns against payloads.
Two distinct sets of application signatures are developed
based on previous experience and some well-known tools,
such as the l7-ﬁlter (http://l7-ﬁlter.sourceforge.net) and Tstat
(http://tstat.tlc.polito.it). The ﬁrst set
is designed to match
against the full ﬂow payload (for the ISP trace). For the re-
maining traces, in which only 40 B of payload are available
for each packet, we tune the second set of signatures to match
early message keywords. Some efforts of manual inspection
were also made to investigate the encrypted and emerging
applications.
We create a combined dataset to study the impact of var-
ious factors on trafﬁc classiﬁcation performance. Merging mul-
tiple real-world traces into one for evaluation can minimize the
effects of data bias [3]. The combined dataset contains more
classes than individual datasets, which is helpful in challenging
the classiﬁcation methods. Since we merged the trafﬁc captured
at various locations and time periods, the target applications dis-
play strong and different behaviors, which cannot be observed
in individual trafﬁc traces. Our work focuses on dealing with
zero-day applications. To reduce the impact of class imbalance
on experiments, four trafﬁc traces were merged together to form
the experiment dataset. Then, for the classes that contain more
than 100 000 ﬂows, we randomly sampled 100 000 ﬂows of each
class; for the classes that contains less than 100 000 ﬂows, we
included all ﬂows of these classes in the experiment dataset. Un-
recognized trafﬁc of the DPI tool is excluded from the combined
dataset. Finally, the combined dataset was constituted by over
638 000 trafﬁc ﬂows from 10 major trafﬁc classes and 16 small
trafﬁc classes. Fig. 4 shows distribution of trafﬁc classes.
In experiments, 20 unidirectional ﬂow statistical features,
as listed in Table II, were extracted to represent trafﬁc ﬂows.
We applied feature selection to further remove irrelevant and
redundant features from the feature set [46]. The process of
feature selection yields nine features. These are client-to-server
number of packets, client-to-server maximum packet bytes,
client-to-server minimum packet bytes, client-to-server av-
erage packet bytes, the standard deviation of client-to-server
packet bytes, client-to-server minimum interpacket
time,
Fig. 3. Automatic selection of
.
Algorithm 4: Parameter optimization
Require: the module of unknown discovery with cross
; the size of mixed training data,
;
validation,
FPR threshold
Ensure: an optimal
{default setting to stop searching}
{searching range}
and
do
then
then
if
1:
2:
3:
4: while
5:
6:
7:
8:
9:
10:
11:
end if
12:
13: end while
else if
else
break
trafﬁc ﬂows) with high conﬁdence. The KEIO and WIDE traces
are provided by the public trafﬁc data repository, maintained by
the MAWI working group (http://mawi.wide.ad.jp/mawi/). The
KEIO trace is captured at a 1-Gb/s Ethernet link in Keio Uni-
versity’s Shonan-Fujisawa campus in Japan and was collected
in August 2006. The WIDE-08 and WIDE-09 traces are taken
from a US–Japan trans-Paciﬁc backbone line (a 150-Mb.s Eth-
ernet link) that carries commodity trafﬁc for WIDE organiza-
tions. The original traces were collected as part of the “A Day
in the Life of the Internet” project, which lasted 72 h from March
18 to 20, 2008, and 96 h from March 30 to April 4, 2009. Forty
bytes of application-layer payload were kept for each packet,
while all IP addresses were anonymized in KEIO and WIDE
traces. In addition, the ISP data set is a trace we captured using a
This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination.
8
IEEE/ACM TRANSACTIONS ON NETWORKING
Fig. 4. Class distribution of the combined dataset. (a) Flow. (b) Byte.
TABLE II
UNIDIRECTIONAL STATISTICAL FEATURES
server-to-client number of packets, server-to-client maximum
packet bytes, and server-to-client minimum packet bytes.
During experiments, we simulated the problem of zero-day
applications. On the combined dataset, we manually set a few
major classes and all small classes to “unknown.” In the ex-
periments, the dataset was divided into four disjointed parts: a
prelabeled set, an unlabeled set, and two testing sets. For known
classes, a small percentage of ﬂows were randomly selected to
form a labeled training set. It is important to note that no samples
of unknown classes were available for the classiﬁcation system.
Some ﬂows were randomly selected from the unlabeled set and
used in the RTC scheme and Erman’s semi-supervised method.
Two testing sets were used to evaluate the RTC scheme with or
without a system update.
Furthermore, we also performed a number of experiments on
individual datasets of ISP and WIDE-09, in which the trafﬁc
unrecognized by DPI were considered zero-day trafﬁc. In these
experiments, the unknown classes were not manually selected,
which is different to the combined dataset.
B. Evaluation With Synthetic Zero-Day Trafﬁc
1) Experiments and Goals: For performance evaluation, a
large number of experiments were conducted on the combined
dataset. We present the average performance of over 100 runs
and also provide the error bars to show how the results were
stable.
We compare the proposed RTC scheme with four state-of-
the-art trafﬁc classiﬁcation methods: random forest [47], the
BoF-based method [4], the semi-supervised method [35], and
one-class SVM [8]. Note that features used in experiments were
different to those in [35]. However, to be fair, all comparison
methods/schemes used the nine selected features.
The proposed RTC scheme without system update was eval-
uated in experiments. We take random forest as a representa-
tive of conventional supervised trafﬁc classiﬁcation methods.
In our empirical study, random forest displays superior perfor-
mance over other supervised algorithms, such as -NN and sup-
port vector machine. The BoF-based method [4] was able to ef-
fectively incorporate ﬂow correlation into supervised classiﬁca-
tion. Our previous work shows the BoF-based method outper-
forms conventional supervised methods. We implemented the
BoF-based method by employing the random forest algorithm
and majority vote rule. In addition, we test Erman’s semi-super-
vised method [35], which has the capability of unknown identi-
ﬁcation. Theoretically speaking, one-class SVM can avoid the
problem of zero-day applications because it can train an SVM
classiﬁer for each known class. Ideally, the trafﬁc rejected by
all known classes is generated by unknown applications. There-
fore, the modiﬁed one-class SVM [8] is also selected for our
comparison study.
The proposed RTC scheme and Erman’s semi-supervised
method share two parameters:
the number of clusters in
-means and the number of unlabeled training ﬂows. In the
empirical study, we used 30 000 unlabeled ﬂows in the training
set. According to our experimental results, we set
for
Erman’s semi-supervised method in order to achieve its highest
classiﬁcation accuracy.