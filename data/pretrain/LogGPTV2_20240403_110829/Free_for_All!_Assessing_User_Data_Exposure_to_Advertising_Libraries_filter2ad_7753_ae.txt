disambiguation layer for user attributes and our droidLESK
metric for user interests. We found that setting the LCH
threshold to 2.8 and the droidLESK threshold to 0.4 provides
the best performance. To tune the thresholds, we parameterized
them and ran Pluto multiple times on the L1 dataset. A similar
approach can be used to tune the thresholds on any available -
ideally larger - dataset 16, and data point set. In all experiments,
all Miners were enabled unless otherwise stated. The MMiner
mined in manifest ﬁles, the DBMiner in runtime-generated
database ﬁles, the XMLMiner in runtime-generated XML ﬁles
and the GMiner in String resource ﬁles and layout ﬁles. We
compared Pluto to the level-1 and level-2 ground truth we
manually constructed as described in Section IV.
In-app exposure estimation: We ran Pluto on the set of
262 apps (Pluto L1) and the full set of 2535 apps (Pluto FD).
Figure 3 plots the distribution of apps with respect to data
points found within those apps. We saw that the number of
data points found in apps remains consistent as we increased
the number of apps. We repeated the experiment for the level-1
dataset that consists of 35 apps. Figure 4. depicts Pluto’s data
point discovery. We compared Pluto’s data point prediction
with the respective level-1 and level-2 manual analysis IV.
Evidently, Pluto is optimistic in estimating in-app data
points. In other words, Pluto’s in-app discovery component
can ﬂag apps as potentially exposing data points, even though
these are not actually there. A large number of Pluto’s false
16Note that it requires little effort to get Android app packages.
positives stem from parsing the String constants ﬁle. Parsing
these ﬁles increases coverage by complementing our dynamic
analysis challenge in generating ﬁles that host apps created
after the user logged in. It also addresses the layer-2 aggressive
libraries can read from the user input. However, this results in
considering a lot of extra keywords that might match a data
point or its synonyms. Their location in the Strings.xml makes
it harder for Pluto to disambiguate the context for certain data
point classes. In this work, we make the ﬁrst attempt towards
mitigating this pathology by proposing droidLESK.
Pluto is designed to ﬁnd user attributes, user interests, and
data points stemming from the host app’s granted permissions.
We next present the performance of Pluto’s prototype imple-
mentation with respect to the above categories.
Finding user-attributes: Figure 5 depicts the performance
of Pluto in ﬁnding the data point gender when compared to
the level-1 and level-2 datasets and Figure 6 shows the same
for the user attribute age. Gender had absolute support of 13
in the level-1 dataset and 18 in the level-2 and age had 12
and 9 respectively. We observe that Pluto is doing better in
discovering data points available to the more aggressive libraries.
For example, the word age, was found in a lot of layout ﬁles and
Strings.xml ﬁles while the same was not present in the runtime
generated ﬁles. Comparing age with the level-1 ground truth,
results in a high number of false positives, since the analyst
has constructed the ground truth for a level-1 aggressive library.
When Pluto is compared with the ground truth for a level-2
aggressive library, its performance is signiﬁcantly improved.
Finding interests: Next, we evaluated Pluto’s performance
in discovering user interests. Figure 7 illustrates the user interest
workout when Pluto is compared against the level-1 ground
truth and the level-2 ground truth. Workout had absolute support
of 5 in the level-1 dataset and 6 in the level-2. Again, Pluto
does much better in the latter case for the same reasons stated
before.
Preliminary results for droidLESK: In our experiments
we used droidLESK as the most appropriate similarity metric
on Pluto’s context disambiguation layer for user interests.
We compared that with an implementation of Pluto with no
disambiguation layer and an implementation that uses the LESK
metric. droidLESK achieved an astonishing 103.3% increase
in Pluto’s precision whereas LESK achieved an improvement of
11.37%. This is a good indication that droidLESK is a promising
way of introducing domain knowledge when comparing the
similarity between words in the Android app context. We plan
to further explore droidLESK’s potential in future work.
Finding data point exposure through permission inher-
itance: Pluto’s MMiner scrapes through application manifest
11
1"
0.9"
0.8"
0.7"
0.6"
0.5"
0.4"
0.3"
0.2"
0.1"
0"
L1"
L2"
PRECISION"
RECALL"
1"
0.9"
0.8"
0.7"
0.6"
0.5"
0.4"
0.3"
0.2"
0.1"
0"
L1"
L2"
PRECISION"
RECALL"
Fig. 5: gender prediction performance given the L1 and L2
ground truth.
Fig. 7: workout prediction performance given the L1 and L2
ground truth.
1"
0.9"
0.8"
0.7"
0.6"
0.5"
0.4"
0.3"
0.2"
0.1"
0"
L1"
L2"
PRECISION"
RECALL"
1"
0.9"
0.8"
0.7"
0.6"
0.5"
0.4"
0.3"
0.2"
0.1"
0"
L1"
L1:MMiner"
L2"
L2:Mminer"
PRECISION"
RECALL"
Fig. 6: age prediction performance given the L1 and L2 ground
truth.
Fig. 8: address prediction performance in different conﬁgura-
tions, given the L1 and L2 ground truth.
ﬁles to look for permissions that would allow a level-1 or
level-2 aggressive library to get access to user attributes or
interests. We compared Pluto’s performance in two different
conﬁgurations. In conﬁguration 1 (L1 or L2), Pluto is set to look
for a data point using all of its Miners whilst in conﬁguration
2 (L1:MMiner and L2:MMiner) Pluto is set to look for a data
point only using the MMiner, if the data point can be derived
from the host app permissions. We performed the experiment
on the larger level-1 dataset, providing as input the mapping
between the permissions ACCESS COARSE LOCATION and
ACCESS FINE LOCATION with the data point address.
Figure 8 depicts Pluto’s performance in predicting the presence
of address given the above two conﬁgurations for both the
L1 and L2 datasets and ground truths. As expected, Pluto’s
prediction is much more accurate when only the MMiner is
used. It is clear that in the cases where an data point can be
derived through a permission, the best way to predict that data
point exposure would be to merely look through the target
app’s manifest ﬁle.
The main reason for the false negatives we observed in all
previous experiments was because some data points that the
analyst has discovered were in runtime ﬁles generated after
the user has logged in the app, or after a speciﬁc input was
provided. Pluto’s DAM implementation cannot automatically
log in the app. We leave this challenge open for future work.
B. Evaluation of Pluto’s out-app exposure discovery
Next, we wanted to evaluate Pluto’s ability to construct
co-installation patterns and predict user attributes and interests
based on information that can be collected through the out-app
channel. We ran Pluto’s CIP module and classiﬁers on the ABD
dataset we collect from real users (see Section V).
Mining application co-installation patterns: Our imple-
mentation of Pluto’s CIP module uses FPGrowth [20], the state
of the art frequent pattern matching (FPM) algorithm for ﬁnding
association rules. We chose FPGrowth because it is signiﬁcantly
faster than its competitor Apriori [3]. We applied Pluto’s CIP
module on the app bundles we collected through our survey.
We set FPGrowth to ﬁnd co-installation patterns in the form
1:N and prune events with support less than 10%. Table V
lists the 5 strongest—in terms of confidence—association
rules that CIP found when run on the survey dataset.
We observe that Facebook is likely to be installed
together with the Facebook Messenger app. This is likely
because Facebook asks their users to install the Facebook
Messenger app when using the Facebook app. Our survey
dataset reﬂects this as well. The strong relationship between the
Facebook app and Facebook Messenger app revealed by FPM
illustrates its effectiveness for this application. Such rules are
critical for Pluto to estimate co-installation patterns between
the input application and other applications. Pluto leverages
such patterns to provide an estimation of what user attributes
can be potentially derived from the app bundles of users that
have the input app. Co-installation patterns can also be used to
reduce redundancy when combining the in-app data exposure of
multiple applications. For example, one might want to estimate
what are the in-app data points exposed by app A and app B.
However, if these applications are installed on the same device,
then the total amount of information the adversarial library will
get will be the union of both removing duplicates.
Performance of Pluto’s classiﬁers: Pluto’s classiﬁers can
be used to estimate user attributes derived from CIP app bundles
or real-time app bundles from user proﬁles. We evaluated
the performance of Pluto’s classiﬁers on real app bundles
we collected from our survey (see Section V). We used the
users’ answers to the questionnaire in the survey as the ground
truth to evaluate the classiﬁcation results. To justify our use
of dimension reduction technique, we evaluated the classiﬁer
on both dataset before dimension reduction and dataset after
dimension reduction. The results on representative attributes
are shown in Table VI and Table VII respectively.
Based on the results shown in both tables, Random Forest
performs best across all prediction tasks. The superiority of
Random Forest in our evaluation agrees with the existing knowl-
edge [15]. Speciﬁcally, because our dataset has a relatively
smaller number of instances, the pattern variance is more likely
TABLE V: The strongest co-installation patterns found by the
CIP module when run on the survey app bundles.
Precedent
com.facebook.katana
com.lenovo.anyshare.gps
com.viber.voip
com.skype.raider
com.skype.raider
Consequence
com.facebook.orca
com.facebook.orca
com.facebook.orca
com.facebook.orca
com.viber.voip
Conf
0.79
0.75
0.74
0.71
0.70
Lift
2.10
2.01
1.98
1.88
2.32
12
TABLE VI: Performance of classiﬁers before dimension
reduction
Age
Marital Status
Classiﬁer
R(%)
P(%)
83.6
89.8
Random Forest
82.1
89.0
SVM
KNN
86.3
77.7
P = Weighted Precision, R = Weighted Recall
R(%)
66.3
63.6
60.0
P(%)
64.1
65.5
62.7
Sex
R(%)
89.6
83.1
74.8
P(%)
91.5
87.4
83.4
TABLE VII: Performance of classiﬁers after dimension reduc-
tion
Age
Marital Status
Classiﬁer
P(%)
R(%)
93.8
95.0
Random Forest
50.5
66.9
SVM
KNN
92.5
91.2
P = Weighted Precision, R = Weighted Recall
R(%)
88.6
35.4
83.6
P(%)
88.6
44.8
85.7
Sex
R(%)
92.9
70.1
89.9
P(%)
93.8
80.9
91.6
to be high. The ensemble technique (voting by many different
trees) employed by Random Forest could reduce such variance
in its prediction and thus achieve a better performance.
Comparison of Table VI and Table VII show dimension
reduction can effectively improve the performance of Random
Forest and KNN. However, the performance of SVM becomes
poorer after dimension reduction. One possible reason is that
SVM can handle high-dimension data such as our original
dataset. The model complexity of SVM is determined by the
number of support vectors instead of dimensions.
VIII. DISCUSSION
Utility of Pluto: In this work, we propose an approach that
can be leveraged to assess potential data exposure through
in-app and out-app channels to a third-party library. We
note that even though we use ad libraries in free apps as
a motivating example, our approach can be adapted to assess
data exposure by any app to any third-party library. We chose
ad libraries because they are quintessential examples of third-
party libraries with strong business incentives for aggressive
data harvesting. Motivated by rising privacy concerns related
to mobile advertising, users can exert pressure on markets
to integrate data exposure assessment into their system and
present the results in a usable way to users when downloading
an app. In light of this information, users would be able to make
more informed decisions when choosing an app. Furthermore,
government agencies, such as the Food and Drug Administration
(FDA), could beneﬁt from this approach to facilitate their efforts
in regulating mobile medical device apps [1] and the Federal
Trade Commission (FTC) could leverage Pluto to discover apps
that potentially violate user privacy.
We describe a simple way for markets (and in extend other
interested parties) to utilize Pluto’s results and rank apps based
on their data exposure. Intuitively, the harder it is for an
adversary to get a data point of a user, the more valuable