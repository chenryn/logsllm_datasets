### Generic Constraints for System Security

Generic constraints are developed based on well-established security policies and computer system design principles, historical system behavior, known attacks, and vulnerability models [16, 17]. For example, well-studied integrity and availability policies such as the Clark-Wilson model [12], the Biba integrity model [13], and the Type Enforcement model [14] can be applied. Additionally, established design principles like least privilege, least common mechanisms, and fail-safe defaults [15] are considered. These policies and principles have been used in the modeling, design, and implementation of secure systems to restrict operations and achieve security goals. However, existing systems often do not fully adhere to these principles. Our approach is to monitor these constraints for violations, allowing for corrective actions to prevent security failures. By developing constraints based on more than just known attacks, we can detect new and unseen threats.

### Example Constraints and Implementation

In this section, we describe several constraints developed using our constraint model and their implementation. These constraints aim to restrict the behavior of various components in a computer system, including programs, protocols, and critical data. To be effective, it is essential to identify the key components that need to be constrained, which depends on the policy to enforce and the security goal to achieve. In this research, we focus initially on components with special privileges (e.g., root in Unix) and entities closely related to these privileged components (e.g., protocols used by them). The goal is to protect the system from malicious normal users.

#### Host-Based Constraints: Privileged Programs and Data

We have developed various types of constraints for privileged programs. One useful type is access constraints, which restrict the files a program can access. These constraints can be defined based on the program's functionality, usage, and the system's security policy [5, 7]. For instance, the following access constraints for FTP should detect the attack mentioned in Section 2.1, regardless of how the attacker manipulates the message:

1. Read only world-readable files.
2. Write only files owned by the user.
3. Execute only specific commands: `/bin/ls`, `/bin/gzip`, `/bin/tar`, `/bin/compress`.
4. Do not change file permissions or ownership.

We are developing access constraints for all setuid root programs and root servers/daemons in a standard Linux system. Many examples of access constraints have been created [5, 7], and we will not discuss them in detail here.

Other interesting constraints for privileged programs include:

- **Privilege Discard Constraint (C1):** A privileged process should discard all its privileges and capabilities before giving control to a user, such as executing a shell-type program or a user-created program.
- **Temporary File Constraint (C2):** The temporary file for a program should be accessible only by the program execution and should be removed when the program exits.

In Unix, the first constraint requires a privileged process to reset the real and effective user and group IDs to those of the user and close any file descriptors on files the user has no authority to access. This can detect attacks that attempt to exploit leftover capabilities, such as a file descriptor for reading the shadow password file [18]. The second constraint can detect attackers tampering with temporary files used by privileged programs.

Additionally, we have developed data constraints for security-critical data. For example, the following constraint for the password file should alert on any modification that creates a root account with no password:

- **Password File Constraint (C3):** The password file `/etc/passwd` should be in the correct form, and each user defined in the file should have a password.

We have implemented an access constraint compiler that translates access constraints expressed in PE-Grammar [6] into a C++ object that analyzes audit data for violations. The Generic Software Wrapper [11] provides audit data for monitoring host-level activity. The kernel-resident Generic Software Wrapper efficiently collects audit data, which is crucial for checking whether a privileged program violates constraint C1.

#### Network-Based Constraints: Address Resolution Protocol (ARP)

We have developed two constraints for the ARP protocol. One can develop operational constraints to restrict message exchanges and data constraints to confine data values in messages.

- **Data Constraint:** The Ethernet-to-IP address mapping in any ARP message must be correct, agreeing with an authoritative database. However, maintaining this database is challenging and contradicts ARP's goal of providing automatic support for dynamic address mapping. This constraint works in static environments but not in dynamic ones.
- **Operational Constraint:** Figure 3 specifies the correct operational behavior of the ARP protocol using a state transition diagram. From the initial state, an ARP request moves the system to the "Reply wait" state. Additional requests have no effect, and after the response, the system moves to the "Cached" state. After a timeout, the system returns to the initial state.

We have implemented a simple network monitor to check the ARP operational constraint, using it as a pre-processor to the SNORT open source IDS. The monitor tracks valid IP to MAC address mappings and can detect variants of ARP cache poisoning attacks described in Section 2.3. False alarms due to DHCP automatic allocation of IP addresses are being addressed by developing a DHCP specification.

#### Application Constraints

This subsection describes an application constraint motivated by the following example:

- **Application Constraint (C4):** An application should read only configuration files owned by the user under which it is running.

For instance, the text editor Joe loads a hidden configuration file `.joerc` if it exists in the current working directory. A malicious user can create a carefully crafted `.joerc` file in a world-writable directory, causing the instructions in the file to be executed with the permissions of the person editing the file. Constraint C4 can detect such misuse.

### Conclusions and Future Work

In this paper, we present an approach to real-time security monitoring of a distributed system using a hierarchy of constraints. This approach confines the behavior of system components at various levels of abstraction to increase detection coverage. We discuss the constraint model and provide several example constraints for privileged programs, critical data, and the ARP protocol. The constraints are implemented as a host-based analyzer that examines audit data generated by wrappers or as a pre-processor to the SNORT open source IDS.

The constraints developed using this methodology are highly effective in detecting intrusions. The development process considers not only existing attacks and vulnerabilities but also knowledge of the system, its functionality, and historical behavior. We believe that the best rules for distinguishing intrusions from legitimate activity must take all these aspects into account.

Future work will include developing different types of constraints for more components and evaluating their effectiveness. It is also important to measure or estimate the effectiveness and cost of monitoring constraints. A methodology for tailoring constraints to specific environments and a unified language for specifying constraints would be beneficial. Finally, a formal methodology for reasoning about the constraints would help understand the overall policy achieved by the constraints.

### References

1. K. Ilgun, R. Kemmerer, and P. Porras, “State Transition Analysis: A Rule-based Intrusion Detection Approach,” IEEE Transactions of Software Engineering, 2(13):181-199, March 1995.
2. U. Lindqvist and P. Porras, “Detecting Computer and Network Misuse Through the Production-Based Expert System Toolset (P-BEST),” In Proceedings of the 1999 Symposium on Security and Privacy, May 1999.
3. H. Javitz and A. Valdes, “The NIDES Statistical Component Description and Justification,” Technical Report, Computer Science Laboratory, SRI International, Menlo Park, CA, Mar 1994.
4. R. Lippmann et al., “Evaluating Intrusion Detection Systems: The 1998 DARPA Off-Line Intrusion Detection Evaluation,” DISCEX 2000 - DARPA Information Survivability Conference and Exposition, Hilton Head, SC, 2000.
5. C. Ko, G. Fink, and K. Levitt, “Automated Detection of Vulnerabilities in Privileged Programs by Execution Monitoring,” In Proceedings of the 10th Computer Security Application Conference, Orlando, Dec 1994.
6. C. Ko, M. Ruschitzka, and K. Levitt, “Execution Monitoring of Security-Critical Programs in Distributed Systems: A Specification-based Approach,” In Proceedings of the 1997 Symposium on Security and Privacy, May 1997.
7. R. Sekar, T. Bowen, and M. Segal, “On Preventing Intrusions by Process Behavior Monitoring,” Workshop on Intrusion Detection and Network Monitoring Proceedings, Berkeley, CA, USENIX, pages 29-40.
8. CERT Advisory CA-1999013 Multiple Vulnerabilities in WU-FTPD, CERT CC, available at http://www.cert.org/advisories/CA-1999-13.html, Nov 1999.
9. M. Roesch, “Snort - Lightweight Intrusion Detection for Networks,” USENIX LISA ’99 conference, Nov 1999. Also available at http://www.snort.org.
10. L. Miras, “Advanced Evasion of IDS buffer overflow detection,” power point presentation, available at http://www.newhackcity.net/~jeru.
11. T. Fraser, L. Badger, M. Feldman, “Hardening COTS Software Using Generic Software Wrappers,” IEEE Symposium on Security and Privacy, May 1999.
12. D. Clark and D. Wilson, “A Comparison of Commercial and Military Computer Security Policies,” In Proceedings of the 1987 IEEE Symposium on Security and Privacy, May 1987.
13. K.J. Biba, “Integrity Considerations for Secure Computer Systems,” Technical Report ESD-TR-76-372, USAF Electronic Systems Division, Bedford, MA, 1977.
14. W. Boebert and R. Kain, “A Practical Alternative to Hierarchical Integrity Policies,” Proceedings of the 8th National Computer Security Conference, Gaithersburg, MD, 1985.
15. J. Saltzer and M. Schroeder, “The Protection of Information in Computer Systems,” In Proceedings of the IEEE, Vol. 63, No. 9, pages 1278-1308, March 1975.
16. C. Landwehr et al., “A Taxonomy of Computer Program Security Flaws,” ACM Computing Surveys, Vol. 26, No. 3, September 1994.
17. I. Krsul, “Software Vulnerability Analysis,” Department of Computer Science, Purdue University, Ph.D. Thesis, Coast TR-98-09, 1998.
18. M. Bishop, “Writing Safe Privileged Programs,” Network Security 1997, New Orleans, LA, 1997.