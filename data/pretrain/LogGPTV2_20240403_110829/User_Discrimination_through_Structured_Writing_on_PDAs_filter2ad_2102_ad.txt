within imposter transactions involving the same victim
identity. Otherwise, instances were selected at random.
For the genuine transactions within a round, 52 chal-
lenge strings were evaluated using 3 (or 11) repetitions,
reusing no letter instances. Errors were counted, and av-
eraged over the repetitions to produce an average false
non-match rate (FNMR). In the High-quality Data and
Reduced Data experiments, 156 (or 52×3) genuine trans-
actions were carried out per round, while the All Data
experiment had 572 (or 52×11).
For the imposter transactions within a round, 52 sub-
jects each masqueraded as 51 other users. Given a ﬁxed
victim, the letters from 51 different imposters were called
up to satisfy the victim’s challenge string; multiple rep-
etitions (3 or 11) of this arrangement did not reuse let-
ter instances. Errors were counted, and averaged over
the repetitions to produce an average false-match rate
(FMR). In the High-quality Data and Reduced Data ex-
periments, 7,956 (or 52×51×3) imposter transactions
were performed per round, while the All Data experiment
had 29,172 (or 52×51×11).
In biometric applications providing positive or neg-
ative identiﬁcation [24], special evaluation procedures
should be followed for imposter transactions, whenever
dependent templates are present [13]. Templates are de-
pendent whenever the enrollment of a new user affects
other templates in the system; otherwise, they are in-
2Any extra letters padded SVM-train, such that 50% (or slightly
more) of the data were assigned to SVM-train, and 25% (or slightly
less) were assigned to SVM-test and to Evaluate-test, respectively.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Table 6. Average error rates (in %) for chal-
lenge strings, high-quality data
Letters
1–2
2–4
3–6
4–8
5–10
6–12
FMR
0.35
0.04
0
0
0
0
FNMR
11.54
0.64
0.64
0
0.64
0
Letters
7–14
8–16
9–18
10–20
11–22
FMR
0.01
0
0
0
0
FNMR
0
0
0
0
0
dependent. Our SVM method employs pairwise binary
classiﬁers, and thus the templates are dependent. How-
ever, because our target task is insider detection and it as-
sumes no outsiders, our use of dependent templates with-
out special evaluation provisions is reasonable.
8. Results
Table 6 shows the results of the challenge-string
evaluation for High-quality Data; these data most closely
reﬂect actual user handwriting. The number of units, u,
was varied from 1 to 11, because the subject whose let-
ter list contained the fewest units had only 11. Each unit
contains one or two letters, so the number of letters used
in a round varies from u to 2u, depending on the subject.
Average false-match rates (FMR) and average false non-
match rates (FNMR) both decreased eventually to 0%,
as the number of units increased. With only 2–4 letters,
FMR=0.04% while FNMR=0.64%. When 8–16 letters
were used (or even more), FMR=FNMR=0%.
The results for the Reduced Data and All Data exper-
iments were very similar to the High-quality Data ones.
It appears that neither increasing the data quality (while
holding quantity constant), nor increasing the data quan-
tity (while holding quality constant), has a clear bene-
ﬁt. Due to the long running time of the evaluations, we
were unable to repeat each experiment several times us-
ing different random samples, thus preventing estimates
of variance and tests of statistical signiﬁcance. Neverthe-
less, to probe the stability of the results heuristically, we
replicated the High-quality Data experiment once; these
results very closely resembled those of the original ex-
periment, as well as those of the Reduced Data and All
Data experiments. Note that in the Reduced Data exper-
iment, the subject having the fewest units in his or her
letter list had 9; for the All Data experiment it was 8;
and for the replication of the High-quality Data experi-
ment, it was 10. The three experiments and the one repli-
cation all achieved consistently perfect results when at
least 8–16 letters were used. Excepting one chance event
(in the seventh round of the High-quality Data experi-
ment), this also happened with only 6–12 letters. The All
Data experiment used the most transaction repetitions,
and should have the most stable results; it achieved con-
sistently perfect results with only 5–10 letters.
9. Discussion
Although error rates in Table 6 do not decrease
monotonically as the number of units increases, devia-
tions from the trend are slight and short-lived. Possi-
ble explanations for these small deviations are (1) lim-
ited data quantities (or rare atypical instances) in SVM-
test and/or Evaluate-test, and (2) sub-optimal challenge
strings (because the algorithm for creating letter lists was
greedy and heuristic). It just so happened that the trends
of the other experiments were more consistent. In gen-
eral, it appears that adding units to a challenge string
should not be harmful. Also, since results under the three
different conditions of data quality and quantity did not
differ greatly, it seems that (a) data-capture anomalies
were not calamitous, and (b) similar performance might
be achieved using even less data.
One may ask how it was that such promising results
were achieved. Because data from potential attackers was
available, template ageing was absent, and ample training
data was used, our results may be slightly optimistic. De-
spite such factors, we feel that system success hailed from
the selective grouping of letters into challenge strings.
The SVM classiﬁer results were unexceptional (recall Ta-
ble 2), but combining classiﬁer outputs on letters tailored
to each user brought greater success. Some theory sup-
ports this rationale; our method is reminiscent of machine
learning techniques such as boosting [8] and co-training
[1] that conjoin several medium-quality classiﬁers to pro-
duce a very good one.
10. Summary
The aim of this work was to determine whether per-
sonalized challenge strings might discriminate enrolled
users writing on PDAs. A secondary aim was to deter-
mine what approximate length a challenge string must be.
Our work suggests that using approximately password-
length challenge strings (of at least 5-10 characters, de-
pending on the user) results in a very low equal-error rate,
approaching 0%. Employing even longer strings seems
to bring consistently perfect results, so asking for a few
more seconds of user time (a letter stroke takes less than
0.5 seconds to write, on average) could translate into a
very high level of security. These results are a ﬁrst step
towards exploring the promise of structured writing on
PDAs to deliver biometric access control.
11. Future work
There are several ways to develop the technology
of this work. Using the same data corpus, one could
try new features, different splits of training and testing
data, other classiﬁers, new ways to combine classiﬁer
outputs, and alternative algorithms to create challenge
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007strings. Variant challenge strings could be generated non-
deterministically, to discourage replay attacks. Effects of
writing experience on accuracy could be studied. Other
biometric tasks could be attempted, such as positive or
negative identiﬁcation [24], possibly using independent
templates [13]. Moreover, causes of system failure could
be elicited; multiple replications of experiments could be
conducted, to estimate the variance of the results. If new
data is collected, its quality should be tested to ensure
that it closely represents user handwriting. Higher data
granularity, accuracy, and reliability (in time, space, and
pressure if available) could be beneﬁcial. Template age-
ing [13] could be introduced to make the task more difﬁ-
cult. Larger numbers of subjects could be recruited, and
the relationship between the size of the user pool and sys-
tem accuracy could be explored. Finally, one could study
and test hypotheses about which kinds of structured let-
ters discriminate writers most effectively.
12. Acknowledgements
The authors are grateful for helpful comments from
Patricia Loring and from anonymous reviewers. Mar-
cus Louie implemented the stimulus generator. Sebas-
tian Scherer implemented the data-capture program on
the Palm m105. This work was supported by National
Science Foundation grant number CNS-0430474 and by
the Pennsylvania Infrastructure Technology Alliance.
References
[1] A. Blum and T. Mitchell. Combining labeled and un-
labeled data with co-training.
In Proceedings of the
Eleventh Annual Conference on Computational Learning
Theory, pages 92–100, New York, 1998. ACM Press.
[2] G. E. P. Box and D. R. Cox. An analysis of transforma-
tions. Journal of the Royal Statistical Society: Series B
(Methodological), 26(2):211–243, 1964.
[3] R. R. Bradford and R. B. Bradford. Introduction to Hand-
writing Examination and Identification. Nelson-Hall Pub-
lishers, Chicago, 1992.
[4] C. J. C. Burges. A tutorial on support vector machines for
pattern recognition. Data Mining and Knowledge Discov-
ery, 2(2):121–167, 1998.
[5] C.-C. Chang and C.-J. Lin.
LIBSVM: A li-
brary for support vector machines, 2001.
Soft-
ware available at .
[6] N. Cristianini and J. Shawe-Taylor. An Introduction to
Support Vector Machines and Other Kernel-based Learn-
ing Methods. Cambridge Univ. Press, Cambridge, 2000.
[7] E. Dimitriadou, K. Hornik, F. Leisch, D. Meyer, and
A. Weingessel. The e1071 package, 2005. Software avail-
at .
[8] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of
Statistical Learning: Data Mining, Inference, and Predic-
tion. Springer, New York, 2001.
[9] C.-W. Hsu, C.-C. Chang, and C.-J. Lin. A practical guide
to support vector classification. Technical report, Depart-
ment of Computer Science and Information Engineering,
National Taiwan University, Taipei, Taiwan, 2003.
[10] C.-W. Hsu and C.-J. Lin. A comparison of methods for
IEEE Transactions
multiclass support vector machines.
on Neural Networks, 13(2):415–425, March 2002.
[11] IJPRAI. Special issue on automatic signature verification.
International Journal of Pattern Recognition and Ar-
tificial Intelligence, 8(3), June 1994.
[12] F. Leclerc and R. Plamondon. Automatic signature
verification: The state of the art, 1989–1993.
Interna-
tional Journal of Pattern Recognition and Artificial Intel-
ligence, 8(3):643–660, June 1994.
[13] A. J. Mansfield and J. L. Wayman. Best practices in test-
ing and reporting performance of biometric devices (ver-
sion 2.01). Technical report, Centre for Mathematics and
Scientific Computing, National Physical Laboratory, Ted-
dington, Middlesex, UK, August 2002.
[14] L. O’Gorman. Comparing passwords, tokens, and bio-
metrics for user authentication. Proceedings of the IEEE,
91(12):2021–2040, December 2003.
[15] Palm Inc. Graffiti Alphabet, 2007. Available at .
[16] P. J. Phillips, A. Martin, C. L. Wilson, and M. Przybocki.
An introduction to evaluating biometric systems. Com-
puter, 33(2):56–63, February 2000.
[17] R. Plamondon and G. Lorette. Automatic signature
verification and writer identification—the state of the art.
Pattern Recognition, 22(2):107–131, 1989.
[18] R. Plamondon and S. N. Srihari. On-line and off-line
handwriting recognition: A comprehensive survey. IEEE
Transactions on Pattern Analysis and Machine Intelli-
gence, 22(1):63–84, January 2000.
[19] R Development Core Team. R: A Language and Environ-
ment for Statistical Computing. R Foundation for Statisti-
cal Computing, Vienna, 2006.
[20] R. Sabourin, R. Plamondon, and G. Lorette. Off-line iden-
tification with handwritten signature images: Survey and
perspectives. In H. S. Baird, H. Bunke, and K. Yamamoto,
editors, Structured Document Image Analysis, pages 219–
234. Springer, Berlin, 1992.
[21] E. Shaw, K. G. Ruby, and J. M. Post. The insider threat
to information systems: The psychology of the danger-
ous insider. Security Awareness Bulletin, 2–98, Septem-
ber 1998. Department of Defense Security Institute, Rich-
mond, Virginia, USA.
[22] V. N. Vapnik. The Nature of Statistical Learning Theory.
Springer, New York, 2nd edition, 2000.
[23] C. Vielhauer. Biometric User Authentication for IT Secu-
rity: From Fundamentals to Handwriting. Springer, New
York, 2006.
[24] J. Wayman, A. Jain, D. Maltoni, and D. Maio. An intro-
duction to biometric authentication systems.
In J. Way-
man, A. Jain, D. Maltoni, and D. Maio, editors, Biometric
Systems: Technology, Design and Performance Evalua-
tion, chapter 1, pages 1–20. Springer, London, 2005.
[25] D.-Y. Yeung, H. Chang, Y. Xiong, S. George, R. Kashi,
T. Matsumoto, and G. Rigoll. SVC2004: First interna-
tional signature verification competition. In D. Zhang and
A. K. Jain, editors, Biometric Authentication: Proceed-
ings of the First International Conference, ICBA 2004
(LNCS 3072), pages 16–22, Berlin, 2004. Springer.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:28 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007