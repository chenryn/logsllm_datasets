title:Determining Fault Tolerance of XOR-Based Erasure Codes Efficiently
author:Jay J. Wylie and
Ram Swaminathan
Determining fault tolerance of XOR-based erasure codes efﬁciently
Jay J. Wylie and Ram Swaminathan
Hewlett-Packard Labs
PI:EMAIL, PI:EMAIL
Abstract
We propose a new fault tolerance metric for XOR-based
erasure codes: the minimal erasures list (MEL). A mini-
mal erasure is a set of erasures that leads to irrecoverable
data loss and in which every erasure is necessary and suf-
ﬁcient for this to be so. The MEL is the enumeration of
all minimal erasures. An XOR-based erasure code has an
irregular structure that may permit it to tolerate faults at
and beyond its Hamming distance. The MEL completely de-
scribes the fault tolerance of an XOR-based erasure code
at and beyond its Hamming distance; it is therefore a use-
ful metric for comparing the fault tolerance of such codes.
We also propose an algorithm that efﬁciently determines the
MEL of an erasure code. This algorithm uses the structure
of the erasure code to efﬁciently determine the MEL. We
show that, in practice, the number of minimal erasures for
a given code is much less than the total number of sets of
erasures that lead to data loss: in our empirical results for
one corpus of codes, there were over 80 times fewer mini-
mal erasures. We use the proposed algorithm to identify the
most fault tolerant XOR-based erasure code for all possible
systematic erasure codes with up to seven data symbols and
up to seven parity symbols.
1. Introduction
Storage systems must be fault tolerant. Traditionally, tol-
erating a single disk failure via simple replication or RAID 5
has provided sufﬁcient reliability. In storage arrays, ever
increasing disk capacity leads to ever increasing recovery
times which leads to sector or second disk failures being en-
countered during recovery [2]. Cluster-based and grid stor-
age systems are built with commodity components and rely
on network-attached components; the former have lower re-
liability and the latter lower availability than the compo-
nents traditionally employed in storage arrays. The trends
in storage arrays, cluster-based storage, and grid storage de-
mand that storage schemes with higher degrees of fault tol-
erance be developed and be well understood.
Erasure codes are the means by which storage systems
are typically made fault tolerant (i.e., tolerant of disk fail-
ures). There are many types of erasure codes, such as repli-
cation, RAID 5, and Reed-Solomon codes, each of which
trades off between computation (encode & decode) costs,
fault tolerance, and space efﬁciency. Reed-Solomon codes
provide the best tradeoff between fault tolerance and space
efﬁciency, but are computationally the most demanding
type of erasure code. Erasure codes that rely solely on
XOR operations to generate redundancy are computationally
cheap. However, such codes offer a non-uniform tradeoff
between space efﬁciency and fault tolerance. In practice,
the exact degree of fault tolerance such codes provide in
storage systems is not yet well understood, although there
is much recent activity towards this end [14, 13, 6, 4, 5, 7].
To completely understand the fault tolerance of an XOR-
based erasure code, we must enumerate every set of erasures
that leads to data loss. This is necessary because of the ir-
regular structure of such codes. For example, if the smallest
erasure pattern—set of erasures that leads to data loss—
for a given code is of size 3, then the Hamming distance of
the code is 4. However, the code may tolerate many era-
sures of size 4. The enumeration of all erasure patterns thus
completely describes the fault tolerance of an XOR-based
erasure code. Unfortunately, there are exponentially many
such erasure patterns.
In this paper, we propose enumerating every minimal
erasure to characterize the fault tolerance of a code. A min-
imal erasure is a set of erasures that leads to irrecoverable
data loss and in which every erasure is necessary and suf-
ﬁcient for this to be so. We call the enumeration of min-
imal erasures, the minimal erasures list (MEL). The mini-
mal erasures list contains all of the fault tolerance informa-
tion as the list of erasure patterns, but can be much smaller
in size. There are also an exponential number of minimal
erasures, but our results suggest that, in practice, for most
codes, there are many fewer minimal erasures than erasure
patterns.
We introduce the Minimal Erasures (ME) Algorithm for
efﬁciently determining the MEL of an XOR-based erasure
code. The efﬁciency of the ME Algorithm is premised
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:52 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007on there being few minimal erasures relative to the overall
number of erasure patterns, and on using the structure of the
XOR-based erasure code to identify the minimal erasures.
We have used our implementation of the ME Algorithm
to analyze many XOR-based codes. Our empirical results
demonstrate that there can be almost two orders of mag-
nitude fewer minimal erasures than erasure patterns (and
likely a bigger reduction as k and m increase). We use the
MEL to compare different small XOR-based erasure codes of
similar size and report the most fault tolerant codes. These
results demonstrate both the efﬁcacy and utility of the ME
Algorithm for determining the fault tolerance of XOR-based
erasure codes.
The outline of the paper is as follows. In §2, we introduce
terminology and review some related work. We present
the ME Algorithm and prove its correctness in §3. In §4,
we describe our implementation of the ME Algorithm, our
method of validating the correctness of our implementation,
empirical results that demonstrate the efﬁciency of the ME
Algorithm, and identify the most fault tolerant systematic
XOR-based erasure codes with up to seven data symbols and
up to seven parity symbols. We discuss the ME Algorithm
in relation to speciﬁc other recent work in §5 and then con-
clude in §6.
2. Background
Table 1 lists some symbols and acronyms used in this pa-
per. An XOR-based erasure code consists of n symbols, k
of which are data symbols, and m of which are parity sym-
bols (redundant symbols). We refer to redundant symbols as
parity symbols because our focus is on XOR-based erasure
codes. We only consider systematic erasure codes: codes
that store the data and parity symbols. In storage systems,
data symbols are called “stripes.” The use of systematic
erasure codes in storage systems is generally considered a
necessity to ensure good common case performance.
A set of erasures f is a set of erased symbols; it may
contain either data symbols or parity symbols and it may or
may not be possible to recover these symbols. An erasure
pattern ˆf is a set of erasures that result in at least one data
symbol being irrecoverable (i.e., impossible to recover via
any decoding method). The erasures list EL for an erasure
code is the list of all its erasure patterns. A minimal erasure
˜f is an erasure pattern in which every erasure is necessary
for it to be an erasure pattern; if any erasure is removed
from ˜f , then it is no longer an erasure pattern. The mini-
mal erasures list MEL for an erasure code is the list of all
its minimal erasures. A more compact representation of the
EL and MEL are respectively the erasures vector EV, and the
minimal erasures vector MEV. An erasures vector is a vec-
tor of length m in which the ith element is the total number
of erasure patterns of size i in the EL; the minimal erasures
Symbol Deﬁnition
n
k
m
f
ˆf
˜f
EL
MEL
EV
MEV
Total number of symbols in the erasure code.
Number of data symbols in the code.
Number of parity symbols in the code.
A set of erasures.
An erasure pattern.
A minimal erasure.
The erasures list: a list of ˆf .
The minimal erasures list: a list of ˜f .
The erasures vector for the EL.
The minimal erasures vector for the MEL.
Table 1. Terminology
vector is deﬁned similarly with regard to the MEL. The EV
and MEV vectors only need m entries because all erasure
sets greater than m in length are necessarily erasure pat-
terns.
2.1. Erasure codes
Plank’s tutorial on erasure codes is a great introduction
to erasure codes in general, and their applicability in storage
systems in particular [12]. A Reed-Solomon erasure code
uses m redundant symbols to tolerates all erasures of size
m or less; it is therefore perfectly space efﬁcient. Unfortu-
nately, Reed-Solomon encode and decode require k opera-
tions to generate each redundant symbol, or to decode any
data symbols using redundant symbols. The operations re-
quired by Reed-Solomon codes are based on arithmetic op-
erations in Galois Fields (GF), and such operations are com-
putationally more demanding than simple XOR operations.
Cauchy Reed-Solomon codes implement Galois Field op-
erations only using XOR operations, but require many XOR
operations per Galois Field operation. XOR-based erasure
codes are appealing because of the computational efﬁciency
of encode and decode.
Two well known sub-classes of XOR-based erasure codes
are low-density parity-check (LDPC) codes and array codes.
LDPC codes trade imperfect space efﬁciency for improved
performance. Luby et al. [8] identiﬁed methods of con-
structing LDPC codes, and efﬁciently encoding and decod-
ing them; such codes were originally identiﬁed by Gal-
lager [3]. Plank has brieﬂy surveyed LDPC code construc-
tions for their applicability to storage systems [14].
An LDPC code can be represented as a Tanner graph:
a bipartite graph with k constraint nodes on one side and
k + m data and parity symbols on the other. The efﬁciency
of LDPC codes hinges on bounding the degree of the nodes
in the Tanner graph and consequently on iterative decod-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:52 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007ing. The efﬁcacy of iterative decoding is signiﬁcantly af-
fected by stopping sets: erasure patterns that prevent itera-
tive decoding from recovering symbols (e.g., see the work
of Schwartz and Vardy [17]). We note that every minimal
erasure is a stopping set but that the converse is not true.
Stopping sets are deﬁned with regard to iterative decoding;
minimal erasures are deﬁned with regard to decodability,
i.e., without regard to any particular decoding method.
Array codes are specialized erasure codes for storage ar-
rays (e.g., RAID 5 is an array code). Two well known dou-
ble disk fault tolerant array codes are EVENODD by Blaum
et al. [1] and Row-Diagonal Parity (RDP) by Corbett et al.
[2]. Hafner has generalized the concept of XOR-based array
codes to HoVer codes: codes with parity symbols in both
Horizontal and Vertical dimensions of the array [5]. He has
also proposed Weaver codes, an XOR-based erasure code
construction that chains parity symbols among a subset of
servers in a redundancy group [4]. The ME Algorithm can
be applied to any XOR-based erasure code, for example, to
LDPC codes, Weaver codes, or array codes.
2.2. Evaluating erasure codes
The seminal RAID analysis by Patterson et al. [11] pro-
vides the framework that most storage system reliability
analyses follow:
identify an appropriate Markov model,
plug in failure and recovery rates, and determine mean time
to data loss (MTTDL). Saito et al. [16] and Rao et al. [15]
both applied such a framework to analyze the reliability of
erasure codes. The former considered Reed-Solomon era-
sure codes and the latter array codes.
Plank et al. analyzed the read overhead of moderate-
sized LDPC codes using Monte Carlo methods [14] and of
small-sized LDPC codes using deterministic methods [13].
Read overhead is a performance measure of a client random
read policy; it measures the number of symbols beyond k
that must be read, on average, to decode all data symbols.
Recent work, done concurrently to our work, by Hafner
and Rao investigates the reliability of XOR-based erasure
codes [7]. The MEL and MEV output by the ME Algorithm
are “threshold” measures of fault tolerance. A reliability
measure requires additional assumptions about component
failure and recovery rates. We discuss the ME Algorithm in
the context of both of the above bodies of work in §5.
(i.e., the XOR operation). The Generator matrix consists of
a k×k identity matrix (the data submatrix) with m columns
of dimension k×1 appended (the parity submatrix). Each of
the k columns in the data submatrix corresponds to a stored
data symbol. Each of the m columns in the parity subma-
trix corresponds to a stored parity symbol. Parity column p
has a one in row i if, and only if, data symbol si is XOR’ed
to determine p. For example, if p = s2 ⊕ s4, then parity
column p has a one in rows 2 and 4, and a zero in all other
rows. We refer to the erasure pattern induced by the ones
in the ith row of the Generator matrix as the ith base era-
sure ˜fi . (We show in §3.3 that a base erasure is a minimal
erasure.) The structure of an erasure code is also captured
by its Tanner graph T . Since we exclusively consider sys-
tematic erasure codes—erasure codes that store the k data
symbols and m parity symbols—we use a simpliﬁed Tan-
ner graph representation. In the representation we use, we
collapse the k data symbols from the one side into the con-
straint nodes on the other. In doing so, we end up with what
we call a systematic Tanner graph: a bipartite graph that
has k data symbols on one side and m parity symbols on
the other.
At a high level, the ME Algorithm operates as follows.
It begins by identifying the k base erasures (one for each
data symbol) and adding them to the MEL. The ME Al-
gorithm then proceeds, in an iterative fashion. For every
minimal erasure it ﬁnds, it generates child erasure patterns.
A minimal erasure has a child erasure pattern for every ad-
jacent data symbol. Adjacency is deﬁned with regard to the
systematic Tanner graph. A data symbol is adjacent to a
minimal erasure if it is connected to a parity symbol in the
minimal erasure. To generate a child erasure pattern, the
base erasure from the Generator matrix that corresponds to
the adjacent data symbol is XOR’ed with the parent minimal
erasure. A child erasure pattern is either a minimal erasure
not yet in the MEL, a minimal erasure already in the MEL, or
an erasure pattern that can be partitioned into minimal era-
sures that are already in the MEL. We refer to the last case
as a composite erasure and discuss it in the next section.
The algorithm recurses upon child erasure patterns until all
minimal erasures in the MEL have no more children that are
minimal erasures (not in the MEL), or have no adjacent data
symbols (i.e., the minimal erasure contains all of the data
symbols from some component of the Tanner graph).
3. The Minimal Erasures (ME) Algorithm
3.1. ME Algorithm Pseudo-code
The ME Algorithm uses the structure of an erasure code
to efﬁciently generate the MEL. We rely on two representa-
tions of the XOR-based erasure code: the Generator matrix
and the systematic Tanner graph. The Generator matrix of
a (k , m)-code is a k ×(k +m) matrix in GF(2). Addition of
rows and columns in the Generator matrix is done modulo 2
The pseudo-code for the ME Algorithm is given in Fig-
ure 1. Variables used in the pseudo-code are listed on
lines 100–107. The function me search enumerates the
minimal erasures and stores them in the minimal erasures
data structure M , which it returns. This function has two
phases: in the ﬁrst phase, the base erasures are enumerated
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:52 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007/∗ Initialize data structures. ∗/
contains all parities connected to s(cid:1)
˜f ← Q.dequeue()
(M , M , Q) ← me children(T , M , M , Q, ˜f )
/∗ Get next erasure pattern to process. ∗/
/∗ Data symbol s; Set of data symbols S . ∗/
/∗ Parity symbol p; Set of parity symbols P. ∗/
/∗ Edge e is a data/parity pair (e = sp); Set of edges E . ∗/
/∗ Tanner graph. Has structure T .(S , P , E ). ∗/
/∗ A minimal erasure. Has structure ˜f .(S , P ). ∗/
/∗ Minimal erasures data structure: a set of ˜f . ∗/
/∗ Erasure patterns cache: a set of ˆf . ∗/
/∗ Erasures queue: a FIFO queue of ˆf . ∗/
100: s, S
101: p, P
102: e, E
103: T
104: ˜f
105: M
106: M
107: Q
/∗ Search systematic Tanner graph T for minimal erasures. ∗/
me search(T ) :
200: M ← ∅, M ← ∅, Q ← ∅
201: /∗ Generate the k base erasures. ∗/
202: for all (s(cid:1) ∈ T .S ) do
/∗ P(cid:1)
. ∗/
203:
P(cid:1) ← {∀p ∈ T .P ,∃e ∈ T .E : e = s(cid:1)p}
204:
˜f ← ({s(cid:1)}, P(cid:1))
/∗ A base erasure. ∗/
205:
/∗ Enqueue ˜f to process its children. ∗/
206: Q.enqueue(˜f )
207: M ← M ∪ {˜f } /∗ Add ˜f to minimal erasures data structure. ∗/
208: end for
209: /∗ Process children of enqueued erasure patterns. ∗/
210: /∗ Repeat until no more erasure patterns are enqueued. ∗/
211: while (Q.length() > 0) do
212:
213:
214: end while
215: return (M )
/∗ Generate children of ˜f and enqueue them in Q. ∗/
me children(T , M , M , Q, ˜f )
300: /∗ S(cid:1)
301: S(cid:1) ← {∀s ∈ T .S ,∃p ∈ ˜f .P ,∃e ∈ T .E : e = sp} \ ˜f .S
302: for all (s(cid:1) ∈ S(cid:1)) do
303:
304:
305:
306:
307:
308:
309:
310: M ← M ∪ {˜f (cid:1)}
311: Q.enqueue(˜f (cid:1))
312:
313:
314:
315:
316: M ← M ∪ {˜f (cid:1)}