parallelism in Nim should remain the same, and what you’ll learn in this chapter will
be applicable to other programming languages as well.
 In addition to showing you Nim’s parallelism features, this chapter will lead you
through the implementation of a simple parser, which will show you different meth-
ods for creating parsers. Toward the end of the chapter, you’ll optimize the parser so
it’s concurrent and can be run in parallel on multiple CPU cores.
6.1
Concurrency vs. parallelism
Nowadays, almost all OSs support multitasking, the ability to perform multiple tasks
over a certain period of time. A task is usually known as a process, which is an instance of
a computer program being executed. Each CPU executes only a single process at a time,
but multitasking allows the OS to change the process that’s currently being executed on
the CPU without having to wait for the process to finish its execution. Figure 6.1 shows
how two processes are executed concurrently on a multitasking OS.
 Because CPUs are extremely fast, process A can be executed for 1 nanosecond, fol-
lowed by process B for 2 nanoseconds, followed by process A for another nanosec-
ond.1 This gives the impression of multiple processes being executed at the same
time, even though a CPU can only execute a single instruction at a time. This apparent
simultaneous execution of multiple processes is called concurrency.
1 For simplicity, I’ll ignore the time taken for a context switch here.
Process A
Time (in nanoseconds) 
0
1
2
3
4
Process B 
...
Process A is
executed ﬁrst
for 1 ns.  
Execution of
process A is
paused.
Process B is
executed for
2 ns.
Execution of
process B is
paused.
Execution of
process A is
resumed.
Figure 6.1
Concurrent execution of two processes
Licensed to   
152
CHAPTER 6
Parallelism
In recent years, multicore CPUs have become popular. This kind of CPU consists of
two or more independent units that can run multiple instructions simultaneously.
This allows a multitasking OS to run two or more processes at the same time in parallel.
Figure 6.2 shows how two processes are executed in parallel on a dual-core CPU.
 Unlike a single-core CPU, a dual-core CPU can actually execute two processes at the
same time. This type of execution is called parallelism, and it can only be achieved on
multiple physical CPUs or via a simultaneous multithreading (SMT) technology such
as Intel’s Hyper-Threading (HT) Technology. Remember that despite the apparent
similarities between concurrency and parallelism, the two are not the same.
 In addition to processes, the OS also manages the execution of threads. A thread is
a component of a process, and more than one can exist within the same process. It
can be executed concurrently or in parallel, just like a process, although unlike pro-
cesses, threads share resources such as memory among each other.
 To make use of the full power of a multicore CPU, CPU-intensive computations must
be parallelized. This can be done by using multiple processes, although threads are
more appropriate for computations that require a large amount of data to be shared.
 The asynchronous await that you saw used in chapter 3 is strictly concurrent.
Because the asynchronous code always runs on a single thread, it isn’t parallel, which
means that it can’t currently use the full power of multicore CPUs.
PARALLEL ASYNC AWAIT
It’s very likely that a future version of Nim will
include an asynchronous await that’s parallel.
Unlike asynchronous await, spawn is parallel and has been designed specifically for
CPU-intensive computations that can benefit from being executed on multicore CPUs.
PARALLELISM IN OTHER PROGRAMMING LANGUAGES
Some programming lan-
guages, such as Python and Ruby, don’t support thread-level parallelism due
to a global interpreter lock in their interpreter. This prevents applications
that use threads from using the full power of multicore CPUs. There are ways
around this limitation, but they require the use of processes that aren’t as
flexible as threads. 
Process A 
Time/nanoseconds 
0
1
2
3
4
Process B 
...
...
Core #1: 
Core #2: 
Process A and Process B being
executed at the same time, in parallel
on two different CPU cores.
Figure 6.2
Parallel execution of two processes
Licensed to   
153
Using threads in Nim
6.2
Using threads in Nim
Now that you’ve learned the difference between concurrency and parallelism, you’re
ready to learn how to use threads in Nim.
 In Nim, there are two modules for working with threads. The threads module
(http://nim-lang.org/docs/threads.html) exposes the ability to create threads manu-
ally. Threads created this way immediately execute a specified procedure and run for
the duration of that procedure’s runtime. There’s also the threadpool module
(http://nim-lang.org/docs/threadpool.html), which implements a thread pool. It
exposes spawn, which adds a specified procedure to the thread pool’s task queue. The
act of spawning a procedure doesn’t mean it will be running in a separate thread
immediately, though. The creation of threads is managed entirely by the thread pool.
 The sections that follow will explain all about the two different threading modules,
so don’t feel overwhelmed by the new terms I just introduced.
6.2.1
The threads module and GC safety
In this section, we’ll look at the threads module. But before we start, I should explain
how threads work in Nim. In particular, you need to know what garbage collector safety
(GC safety) is in Nim. There’s a very important distinction between the way threads
work in Nim and in most other programming languages. Each of Nim’s threads has its
own isolated memory heap. Sharing of memory between threads is restricted, which
helps to prevent race conditions and improves efficiency.
 Efficiency is also improved by each thread having its own garbage collector. Other
implementations of threads that share memory need to pause all threads while the gar-
bage collector does its business. This can add problematic pauses to the application.
 Let’s look at how this threading model works in practice. The following listing
shows a code sample that doesn’t compile.
var data = "Hello World"
proc showData() {.thread.} =
echo(data)
var thread: Thread[void]
createThread[void](thread, showData)
joinThread(thread)
Listing 6.1
Mutating a global variable using a Thread
Defines a new mutable global 
variable named data and assigns 
the text "Hello World" to it
Defines a new procedure that will 
be executed in a new thread. The 
{.thread.} pragma must be used 
to signify this.
Attempts to display the 
value of the data variable
Defines a variable to store the new thread. 
The generic parameter signifies the type of 
parameter that the thread procedure 
takes. In this case, the void means that the 
procedure takes no parameters.
The createThread procedure 
executes the specified 
procedure in a new thread.
Waits for the thread to finish
Licensed to   
154
CHAPTER 6
Parallelism
THE THREADS MODULE
The threads module is a part of the implicitly
imported system module, so you don’t need to import it explicitly.
This example illustrates what’s disallowed by the GC safety mechanism in Nim, and
you’ll see later on how to fix this example so that it compiles.
 Save the code in listing 6.1 as listing01.nim, and then execute nim c --threads:on
listing01.nim to compile it. The --threads:on flag is necessary to enable thread
support. You should see an error similar to this:
listing01.nim(3, 6) Error: 'showData' is not GC-safe as it accesses
➥ 'data' which is a global using GC'ed memory
This error describes the problem fairly well. The global variable data has been cre-
ated in the main thread, so it belongs to the main thread’s memory. The showData
thread can’t access another thread’s memory, and if it attempts to, it’s not considered
GC safe by the compiler. The compiler refuses to execute threads that aren’t GC safe.
 A procedure is considered GC safe by the compiler as long as it doesn’t access any
global variables that contain garbage-collected memory. An assignment or any sort of
mutation also counts as an access and is disallowed. Garbage-collected memory
includes the following types of variables:
string
seq[T]
ref T
 Closure iterators and procedures, as well as types that include them
There are other ways of sharing memory between threads that are GC safe. You may,
for example, pass the contents of data as one of the parameters to showData. The fol-
lowing listing shows how to pass data as a parameter to a thread; the differences
between listings 6.2 and 6.1 are shown in bold.
var data = "Hello World"
proc showData(param: string) {.thread.} =
echo(param)
var thread: Thread[string]
createThread[string](thread, showData, data)
joinThread(thread)
Save the code in listing 6.2 as listing2.nim, and then compile it using nim c
--threads:on listing2.nim. The compilation should be successful, and running the
program should display "Hello World".
Listing 6.2
Passing data to a thread safely
A parameter of type string is 
specified in the procedure definition.
The procedure argument is 
passed to echo instead of the 
global variable data.
The void has been replaced 
by string to signify the type 
of parameter that the 
showData procedure takes.
The data global variable is passed
to the createThread procedure,
which will pass it on to showData.
Licensed to   
155
Using threads in Nim
 The createThread procedure can only pass one variable to the thread that it’s cre-
ating. In order to pass multiple separate pieces of data to the thread, you must define
a new type to hold the data. The following listing shows how this can be done.
type
ThreadData = tuple[param: string, param2: int]
var data = "Hello World"
proc showData(data: ThreadData) {.thread.} =
echo(data.param, data.param2)
var thread: Thread[ThreadData]
createThread[ThreadData](thread, showData, (param: data, param2: 10))
joinThread(thread)
EXECUTING THREADS
The threads created in the previous listings don’t do very much. Let’s examine the
execution of these threads and see what happens when two threads are created at the
same time and are instructed to display a few lines of text. In the following examples,
two series of integers are displayed.
var data = "Hello World"
proc countData(param: string) {.thread.} =
for i in 0 .. 
156
CHAPTER 6
Parallelism
012345678910
012345678910
The execution of the threads depends entirely on the OS and computer used. On my
machine, the output in listing 6.5 likely happens as a result of the two threads running
in parallel on two CPU cores, whereas the output in listing 6.6 is a result of the first
thread finishing before the second thread even starts. Your system may show different
results. Figure 6.3 shows what the execution for both the first and second sets of
results looks like.
The threads created using the threads module are considerably resource intensive.
They consume a lot of memory, so creating large numbers of them is inefficient.
They’re useful if you need full control over the threads that your application is using,
but for most use cases the threadpool module is superior. Let’s take a look at how the
threadpool module works. 
6.2.2
Using thread pools
The main purpose of using multiple threads is to parallelize your code. CPU-intensive
computations should make use of as much CPU power as possible, which includes
using the power of all the cores in a multicore CPU.
 A single thread can use the power of a single CPU core. To use the power of all the
cores, you could simply create one thread per core. The biggest problem then is mak-
ing sure that those threads are all busy. You might have 100 tasks that don’t all take the
same amount of time to complete, and distributing them across the threads isn’t a triv-
ial job.
Listing 6.6
Second possible output when the code in listing 6.4 is executed
Thread #1 
0 
0
1
1
Thread #2 
2
2
For output: 001122334455667788991010  
00
3
3
...
...
11
22
33
...
Thread #1 
0 
0
1
1
Thread #2 
For output: 012345678910 
          012345678910 
0
...
...
1
...
0
...
Finish
1
Finish
Figure 6.3
The two possible executions of listing 6.4
Licensed to   
157
Using threads in Nim
 Alternatively, one thread per task could be created. But this creates problems of its
own, in part because thread creation is very expensive. A large number of threads will
consume a lot of memory due to OS overhead.
WHAT IS A THREAD POOL?
The threadpool module implements an abstraction that manages the distribution of
tasks over a number of threads. The threads themselves are also managed by the
thread pool.
 The spawn command allows tasks, in the form of procedure invocations, to be
added to the thread pool, which then executes the tasks in one of the threads it man-
ages. The thread pool ensures that the tasks keep all the threads busy so that the CPU’s
power is utilized in the best way possible. Figure 6.4 shows how the thread pool man-
ages tasks under the hood.   
USING SPAWN
The spawn procedure accepts an expression, which in most cases is a procedure call.
spawn returns a value of the type FlowVar[T] that holds the return value of the proce-
dure that was called. This is an advantage in comparison to the threads module,
where threads can’t return any values.
 The following listing shows the spawn equivalent of the code in listing 6.4.
import threadpool
var data = "Hello World"
proc countData(param: string) =
for i in 0 .. 
158
CHAPTER 6
Parallelism
Save the code in listing 6.7 as listing4.nim, and then compile and run it. Keep in mind
that the --threads:on flag still needs to be specified. The output should be mostly
the same as the output shown in listings 6.5 and 6.6.
 Procedures executed using spawn also have to be GC safe. 
RETRIEVING RETURN VALUES FROM THE FLOWVAR TYPE
Let’s look at an example that shows how to retrieve the return values from a spawned
procedure. This involves dealing with the FlowVar[T] type.
 FlowVar[T] can be thought of as a container similar to the Future[T] type, which
you used in chapter 3. At first, the container has nothing inside it. When the spawned
procedure is executed in a separate thread, it returns a value sometime in the future.
When that happens, the returned value is put into the FlowVar container.
 The following listing shows the readLine procedure from chapter 3, which uses a
while loop to read text from the terminal without blocking.
import threadpool, os
let lineFlowVar = spawn stdin.readLine()
while not lineFlowVar.isReady:
echo("No input received.")
echo("Will check again in 3 seconds.")
sleep(3000)
echo("Input received: ", ^lineFlowVar)
Save listing 6.8 as listing5.nim, and then compile and run it. The application will wait
until you enter some input into the terminal. It will check for input every 3 seconds.
 Using the FlowVar type is straightforward. You can read the value inside it with the
^ operator, but this operator will block the thread it’s used in until the FlowVar it’s
called on contains a value. You can check whether a FlowVar contains a value by using
the isReady procedure. Listing 6.8 checks whether the lineFlowVar variable contains
a value periodically, every 3 seconds.
 Keep in mind that listing 6.8 is meant to demonstrate how the FlowVar[T] works.
It’s not meant to be very practical, because the program will only check for input every
3 seconds.
 In this example, you could just as well call readLine on the main thread, since
there’s nothing else running on it. A more realistic example might replace the
Listing 6.8
Reading input from the terminal with spawn
The threadpool module is necessary 
for spawn. The os module defines the 
sleep procedure.
Adds the readLine procedure to the 
thread pool. spawn will return a 
FlowVar[string] type that will be 
assigned to the lineFlowVar variable.
Loops until lineFlowVar 
contains the string value 
returned by readLine
Displays some status 
messages about what the 