in the graph. We a(cid:138)empted this a(cid:138)ack under many conditions,
adding anywhere from 10 to 100 edges, and selecting the events
to which we connected the incident according to both black-box
policies (random selection of secondary indicators) and white-box
policies (a(cid:138)acker has knowledge of event con(cid:128)dence and relevance
rankings), and both on the con(cid:128)dence-weighted and uniformly-
weighted graphs.
(cid:140)e counter-intuitive result to our experiments was that adding
noise to security incidents has the unintended e(cid:130)ect of increasing
its overall ranking, regardless of the graph’s weighting scheme.
(cid:140)e result of one such adversarial experiment is shown in Figure
9, wherein we assumed adversaries that a(cid:138)ach their incident to
100 security events, selected at random from the 10% least relevant
events in the con(cid:128)dence-weighted graph. (cid:140)is (cid:128)gure contrasts the
results of doing so on Smoke Detector’s classi(cid:128)cation accuracy, (cid:128)nd-
ing that adding edges results only increases performance relative
to the non-adversarial se(cid:138)ing. Our experiments have shown that
this e(cid:130)ect is not due to the fact that multiple nodes are a(cid:138)acked at
once in this evaluation, as adding edges to a single incident also
increases its rank relative to other machine-windows.
(cid:140)e reason for which the noise-based a(cid:138)ack fails is that adding
edges to a machine-window node increases its number of its incom-
ing edges, along which event nodes communicate their relevance
to the machine-window. (cid:140)is has a net positive e(cid:130)ect on the node’s
ranking as there is no normalization amongst a machine-window’s
incoming edges, yielding a net positive e(cid:130)ect on the machine’s
relevance even if these additional edges come from events that
have low, but positive relevance.2 (cid:140)is consideration more than
2(cid:140)ere is a path between each security event and at least one incident in the graph,
hence all the events receive a positive relevance.
208as this would raise an incident that would increase the relevance of
events s1 and s2. (cid:140)e broad class of a(cid:138)acks that includes this one
has several limitations:
First, Smoke Detector treats a single instance of an event in a
machine-window no di(cid:130)erently than millions of instances of the
same event in that window, so successful a(cid:138)acks require the control
of many machines on multiple networks over a long period of time,
which is costly and increases the probability of detection.
Second, model inversion a(cid:138)acks depend upon feedback from the
model, but this risk can be mitigated by providing limited precision
in the con(cid:128)dence scores that Smoke Detector shares with customers
[8], and by sorting events alphabetically by name rather than by
rank when they have tied limited-precision score.
(cid:140)ird, an e(cid:130)ective training-set a(cid:138)acks on Smoke Detector would
have to reduce the score of highly indicative events by triggering
them many times without raising a security incident, which is
di(cid:129)cult and could culminate in the blacklisting or lost control of
a(cid:138)acker-controlled machines.
Lastly, the adversary is more likely to have control of external
machines than enterprise-owned machines in su(cid:129)cient numbers for
an a(cid:138)ack, yet only internal machines can trigger events produced
by endpoint-protection products, rendering training-set a(cid:138)acks on
anti-virus events, for instance, di(cid:129)cult to carry out.
In summary, while these a(cid:138)acks are surely not comprehensive
of all possibilities, Smoke Detector has important properties that
render it a di(cid:129)cult target for an adversary, such as its ability to
capture high-order relationships, the relative inaccessibility of its
model to concerted model inversion a(cid:138)empts, and its basis in big
data, which forces a(cid:138)ackers to perform large-scale a(cid:138)acks.
Figure 9: Smoke Detector’s detection rates in an adversarial
setting where the attacker adds noise to the incidents in the
con(cid:128)dence-weighted graph. (cid:135)e attack fails as new edges
further increase the relevance of the incidents.
counterbalances the diminished outgoing relevance of the machine-
window to high-value events, as the relevance of these events is
supported by other machine-windows that are not a(cid:138)acked.
Attack 3: Altering the graph and its weights. We now con-
sider adversaries that control at least one machine in addition to
the machine-window on which they hope to evade detection. (cid:140)at
is, they seek to modify Smoke Detector’s training data, which is
a daunting task given that MSSPs use big data systems compris-
ing trillions of event instances across tens of millions of machine
windows, each protected by its own sensor net of security devices.
A(cid:138)acks are most likely to try to cause the rank of the primary
a(cid:138)ack’s machine-window to drop into a range that has many false
positives by lowering the relevance of the events connected to
the primary a(cid:138)ack’s machine-window. Consider a primary a(cid:138)ack
consisting of events s1 and s2. (cid:140)e adversary divides controlled
machines into two pools, one of which triggers event s1, the other
triggering s2, to avoid triggering both events from a single machine
9 RELATED WORK
Much of the prior art in intrusion analyzes large collections of sim-
ilar events to alert on a subset of malicious instances. By contrast,
Smoke Detector consumes raw event data that is intermixed with
the alerts generated by the prior art, and therefore treats events of
di(cid:130)erent types as distinct entities of varying reliability. (cid:140)e prior
art we discuss in this section includes techniques for event scor-
ing, alert fusion, alert correlation, and root-cause analysis, among
others.
M-Correlator [23] assigns priority scores to security events based
on context, such as the importance and vulnerability of targeted
assets. When such data is available it should be used and would
enable an approach based on M-Correlator to prioritize Smoke De-
tector incidents, whose event scores represent infection con(cid:128)dence
rather than severity.
Beehive [34] provides important techniques for normalizing and
correlating the events provided by diverse collections of security
products (which are central challenges for MSSPs and SIEMs) so
that metadata is not lost, allowing anomaly detection algorithms
and blacklists to be applied e(cid:130)ectively. Smoke Detector makes no
a(cid:138)empt to identify anomalies in event types that would otherwise
not a(cid:138)ract a(cid:138)ention, as Beehive does, and would instead consume
Beehive’s detected anomalies as separate events.
Alert correlation and alert clustering techniques bear similar-
ity to Smoke Detector in their study of the relationships between
di(cid:130)erent types of alerts. However, many of these methods strive
0.00.20.40.60.81.0FP Rate0.00.20.40.60.81.0TP RateAttacker adds noise to incidentsOriginal graphAttacked graph0.0000.0020.0040.0060.0080.010FP Rate0.00.20.40.60.81.0TP RateZoomed-in version of figure aboveOriginal graphAttacked graph209to promote understanding and root-cause analysis for existing in-
cidents [22, 24, 31] rather than detect new incidents. Julisch [14]
summarizes large volumes of event data for human consumption,
so that anomalous events stand out to an analyst. Viinika et al. [33]
and Valdes and Skinner [29] reduce alerts into aggregate “meta-
alerts” for ease of consumption. (cid:140)ese technique are valuable but
are not designed for a SIEM or MSSP se(cid:138)ing, where events vary
widely di(cid:130)erent nature and quality.
Alert Fusion refers to the problem of determining whether to
output an alert based on the result of multiple IDS models trained
over a common data set of event logs [2, 10, 25, 26], such as the
Darpa 2000 dataset [17]. (cid:140)ese techniques are not designed for
underlying datasets that are as diverse as those of SIEMs and MSSPs.
Many expert systems for intrusion-detection build on P-BEST’s
seminal algorithm [18], which provides an inference language to
detect misuse and anomalies through production rules. While sim-
ilar techniques are deployed by SIEMs and MSSPs today, these
techniques are costly to maintain because of constant changes to
the underlying events that are being collected and monitored. In
Section 7 we evaluate Smoke Detector against an MSSP of this
type. Buckzak and Guven [3] describe many applications of Ma-
chine Learning and Data Mining to intrusion detection, from which
Smoke Detector di(cid:130)ers in its use of a graphical model, which mod-
els relationships between known incidents, events and candidate
incidents.
10 CONCLUSION
We presented Smoke Detector, an intrusion detection system de-
signed for the challenges confronted by MSSPs and SIEMs, including
huge data volumes, diverse event types of greatly varying quality,
and continual event churn. We showed that Smoke Detector in-
creases the volume of detected critical incidents by 19% at a 1.3%
False Positive rate. Its con(cid:128)dence scores provide intuition and a
tuning mechanism for Random Walk with Restart (RWR). Our im-
plementation of the RWR algorithm scales linearly with the size of
the data and works well in a distributed system on commodity hard-
ware. To the best of our knowledge, our use of the RWR represents
the (cid:128)rst use of this algorithm for computer security applications
other than in the context of security for social networks [37].
11 ACKNOWLEDGMENTS
(cid:140)anks to Lenore Zuck and Zhongkai Wen for helpful discussions
on improving this paper. (cid:140)anks to Daniel Whalen for provide
feedback on the Smoke Detector algorithm and its detections.
REFERENCES
[1] Amazon. 2017. Amazon S3. h(cid:138)ps://aws.amazon.com/s3/. (2017). Accessed:
2017-06-08.
[2] Tim Bass. 2000.
Intrusion Detection Systems and Multisensor Data Fusion.
Commun. ACM 43, 4 (April 2000), 95–105.
[3] A. L. Buczak and E. Guven. 2016. A Survey of Data Mining and Machine Learning
Methods for Cyber Security Intrusion Detection. IEEE Communications Surveys
Tutorials 18, 2 (Secondquarter 2016), 1153–1176. DOI:h(cid:138)p://dx.doi.org/10.1109/
COMST.2015.2494502
[4] George Casella. 1985. An Introduction to Empirical Bayes Data Analysis. (cid:138)e
American Statistician 39, 2 (May 1985), 83–87.
[5] Paul Cichonski, Tom Millar, Tim Grance, and Karen Scarfone. 2012. Computer
Security Incident Handling Guide. NIST Special Publication 800-61 Rev 2 (August
2012).
Stanford.
[6] Dan Claudiu Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and
J¨urgen Schmidhuber. 2011. Flexible, high performance convolutional neural
networks for image classi(cid:128)cation. In International Joint Conference on Arti(cid:128)cial
Intelligence (IJCAI).
[7] Dumitru Erhan, Christian Szegedy, Alexander Toshev, and Dragomir Anguelov.
2014. Scalable object detection using deep neural networks. In IEEE Conference
on Computer Vision and Pa(cid:136)ern Recognition (CVPR). 2147–2154.
[8] Ma(cid:138)hew Fredrikson, Somesh Jha, and (cid:140)omas Ristenpart. 2015. Model Inversion
A(cid:138)acks that Exploit Con(cid:128)dence Information and Basic Countermeasures. In
ACM Conference on Computer and Communications Security (CCS). Tokyo, Japan.
[9] Leo Grady. 2006. Random walks for image segmentation. IEEE transactions on
pa(cid:136)ern analysis and machine intelligence 28, 11 (2006), 1768–1783.
[10] Guofei Gu, Alvaro A. Cardenas, and Wenke Lee. 2008. Principled Reasoning and
Practical Applications of Alert Fusion in Intrusion Detection Systems. In ACM
Symposium on InformAction, Computer and Communications Security (ASIACCS).
Tokyo, Japan.
[11] Taher Haveliwala. 1999. E(cid:129)cient computation of PageRank. Technical Report.
[12] Fred Hohman, Nathan Hodas, and Duen Horng Chau. 2017. ShapeShop: Towards
Understanding Deep Learning Representations via Interactive Experimentation.
In 2017 CHI Conference Extended Abstracts on Human Factors in Computing
Systems. ACM, 1694–1699.
[13] Forrest N Iandola, Ma(cid:138)hew W Moskewicz, Khalid Ashraf, and Kurt Keutzer.
2016. FireCa(cid:130)e: near-linear acceleration of deep neural network training on
compute clusters. In IEEE Conference on Computer Vision and Pa(cid:136)ern Recognition
(CVPR). 2592–2600.
[14] Klaus Julisch. 2003. Clustering Intrusion Detection Alarms to Support Root
Cause Analysis. ACM Transactions on Information Systems Security 6, 4 (Nov.
2003), 443–471. DOI:h(cid:138)p://dx.doi.org/10.1145/950191.950192
[15] Minsuk Kahng, Pierre Andrews, Aditya Kalro, and Duen Horng Chau. 2017.
ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models.
arXiv preprint arXiv:1704.01942 (2017).
DDoS A(cid:138)acks. IT Security Risks Special Report Series (September 2015), 7.
Data Sets. h(cid:138)ps://www.ll.mit.edu/ideval/data/2000data.html. (2000).
[16] Kaspersky Lab. 2015. Denial of Service: How Businesses Evaluate the (cid:140)reat of
[17] MIT Lincoln Laboratory. 2000. DARPA Intrusion Detection Scenario Speci(cid:128)c
[21]
[18] Ulf Lindqvist and Phillip A. Porras. 1999. Detecting Computer and Network
Misuse (cid:140)rough the Production-Based Expert System Toolset (P-BEST). In Inter-
national Symposium on Security and Privacy (SP). Oakland, CA.
[19] David Miller, Shon Harris, Allen Harper, Stephen VanDyke, and Chris Blask.
2010. Security Information and Event Management (SIEM) Implementation (1st
ed.). McGraw Hill Education.
[20] P. O’Kane, S. Sezer, and K. McLaughlin. 2011. Obfuscation: (cid:140)e Hidden Malware.
(May 2011), 41–47.
Jia-Yu Pan, Hyung-Jeong Yang, Christos Faloutsos, and Pinar Duygulu. 2004.
Automatic multimedia cross-modal correlation discovery. In ACM SIGKDD in-
ternational conference on Knowledge Discovery and Data Mining (KDD). ACM,
653–658.
[22] Roberto Perdisci, Giorgio Giacinto, and Fabio Roli. 2006. Alarm Clustering
for Intrusion Detection Systems in Computer Networks. Engineering Applied
Arti(cid:128)cial Intelligence 19, 4 (June 2006), 429–438. DOI:h(cid:138)p://dx.doi.org/10.1016/j.
engappai.2006.01.003
[23] Phillip A. Porras, Martin W. Fong, and Alfonso Valdes. 2002. A Mission-Impact-
Based Approach to INFOSEC Alarm Correlation. In International Symposium on
Recent Advances in Intrusion Detection (RAID). Zurich, Switzerland, 95–114.
[24] Alireza Sadighian, Jos´e M. Fernandez, Antoine Lemay, and Saman T. Zargar. 2014.
ONTIDS: A Highly Flexible Context-Aware and Ontology-Based Alert Correlation
Framework. Springer International Publishing, Cham, 161–177. DOI:h(cid:138)p://dx.
doi.org/10.1007/978-3-319-05302-8 10
[25] A. Sadighian, S. T. Zargar, J. M. Fernandez, and A. Lemay. 2013. Semantic-based
context-aware alert fusion for distributed Intrusion Detection Systems. In 2013
International Conference on Risks and Security of Internet and Systems (CRiSIS).
1–6. DOI:h(cid:138)p://dx.doi.org/10.1109/CRiSIS.2013.6766352
[26] Mallikarjun Shankar, Nageswara Rao, and Stephen Batsell. 2003. Fusing Intru-
sion Data for Detection and Containment. In IEEE Military Communications
Conference (MILCOM). Ontario, Canada.
Jimeng Sun, Huiming (cid:139), Deepayan Chakrabarti, and Christos Faloutsos. 2005.
Relevance search and anomaly detection in bipartite graphs. ACM SIGKDD
Explorations Newsle(cid:136)er 7, 2 (2005), 48–55.
[28] Hanghang Tong, Christos Faloutsos, and Jia-Yu Pan. 2006. Fast Random Walk
with Restart and Its Applications. In International Conference on Data Mining
(ICDM). IEEE Computer Society, Washington, DC, USA, 613–622. DOI:h(cid:138)p:
//dx.doi.org/10.1109/ICDM.2006.70
[29] Alfonso Valdes and Keith Skinner. 2001. Probabilistic Alert Correlation. In
International Symposium on Recent Advances in Intrusion Detection (RAID). Davis,
CA.
[30] Fredrik Valeur, Giovanni Vigna, Christopher Kruegel, and Richard A. Kemmerer.
2004. A Comprehensive Approach to Intrusion Detection Alert Correlation. IEEE
[27]
210[33]
[32] Vincent Vanhoucke, Andrew Senior, and Mark Z Mao. 2011.
Transactions on Dependable Secure Computing 1, 3 (July 2004), 146–169. DOI:
h(cid:138)p://dx.doi.org/10.1109/TDSC.2004.21
[31] Fredrik Valeur, Giovanni Vigna, Christopher Kruegel, and Richard A. Kemmerer.
2004. A Comprehensive Approach to Intrusion Detection Alert Correlation. IEEE
Transactions on Dependable Secure Computing 1, 3 (July 2004), 146–169. DOI:
h(cid:138)p://dx.doi.org/10.1109/TDSC.2004.21
Improving the
speed of neural networks on CPUs. In NIPS Workshop on Deep Learning and
Unsupervised Feature Learning, Vol. 1. 4.
Jouni Viinikka, Herv´e Debar, Ludovic M´e, and Renaud S´eguier. 2006. Time
Series Modeling for IDS Alert Management. In ACM Symposium on Information,
Computer and Communications Security (ASIACCS). ACM, New York, NY, USA,
102–113. DOI:h(cid:138)p://dx.doi.org/10.1145/1128817.1128835
[34] Ting-Fang Yen, Alina Oprea, Kaan Onarlioglu, Todd Leetham, William Robertson,
Ari Juels, and Engin Kirda. Beehive: Large-Scale Log Analysis for Detecting
Suspicious Activity in Enterprise Networks. In Annual Computer Security Appli-
cations Conference (ACSAC).
[35] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das, Ankur Dave, Justin Ma,
Murphy McCauley, Michael J Franklin, Sco(cid:138) Shenker, and Ion Stoica. Resilient
distributed datasets: A fault-tolerant abstraction for in-memory cluster com-
puting. In USENIX conference on Networked Systems Design and Implementation
(NSDI).
[36] Chao Zhang, Shan Jiang, Yucheng Chen, Yidan Sun, and Jiawei Han. 2015. Fast
inbound top-k query for random walk with restart. In Joint European Confer-
ence on Machine Learning and Knowledge Discovery in Databases (ECML PKDD).
Springer, 608–624.
[37] Ziming Zhao, Gail-Joon Ahn, Hongxin Hu, and Deepinder Mahi. 2012. So-
cialImpact: Systematic Analysis of Underground Social Dynamics. In European
Symposium on Research in Computer Security (ESORICS).
211