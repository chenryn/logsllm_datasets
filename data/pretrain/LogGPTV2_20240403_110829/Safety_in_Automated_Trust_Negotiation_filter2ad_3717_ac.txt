361
For sensitive attribute t, Ack[t] is called the ack policy of t (in G). Ack can
associate an ack policy with an attribute whether K possesses the attribute
or not.
r AC : Resource (cid:3)→ Policy is a partial function mapping a ﬁnite subset of
resources to policies. Resources in the preimage of AC are resources the par-
ticipant has.
Example 3. Consider the scenario described in Examples 1 and 2.
Bob’s conﬁguration is G B =(cid:4)K B, EB, AckB, ACB(cid:5),
in which K B is Bob’s
public key, EB contains one credential that proves K B has IRS.
low-
Income, and AckB (IRS.lowIncome)=IRS.nonproﬁt. Alice’s conﬁguration is
G A =(cid:4)K A, E A, AckA, ACA(cid:5),
in which E A =∅ and AckA (IRS. lowIncome) =
IRS.nonproﬁt.
While we assume that each principal (public key) is controlled by, at most, one
entity, it is possible that one entity controls several principals. The reader may
wonder why in that case our notion of conﬁguration includes just one principal.
Why not let a negotiator use several principals in a negotiation? The reason we
do not is that it makes it difﬁcult to ensure that the principals all correspond
to a single entity, so it opens the door to colluding entities obtaining resources
they should not have. This is prevented in our model.
Before a trust negotiation process starts, the two negotiators establish a
secure connection and authenticate the principals they each control. In addi-
tion to ensuring that sensitive information is not disclosed to any third parties
who may be monitoring the communications, this also ensures that one can be
conﬁdent that credentials revealed by the other participant indeed belong to
the participant. One way to achieve this is for the two parties to establish a
TLS/SSL connection using self-signed certiﬁcates.
A negotiation process starts when one participant (called the requester) sends
a request to another participant (called the access mediator) requesting access
to some resource. The access mediator identiﬁes the policy protecting that re-
source and then starts the negotiation process. The negotiation process is mod-
eled formally as a pair of sequences of message, each sequence being deﬁned
by one negotiator. The negotiation proceeds by two negotiators taking turns
extending these sequences, thus modeling message exchange. Each negotiator
maintains a local state during the negotiation process. Internal structure of
the messages and local states are opaque in the abstract framework described
in the current section. However we assume there are two distinguished states:
success, and failure. A negotiation process fails when one of the two negotiators
enters into the failure state. (In practice, a negotiator might send a message no-
tifying the opponent about the failure; for technical convenience, we choose not
to include such a message in the model here.) A negotiation process succeeds
when the access mediator enters into the success state. A negotiation process
stops when it succeeds or when it fails.
A negotiation strategy determines the structure of states and what actions a
negotiator takes in a negotiation process. More speciﬁcally, a negotiation strat-
egy is a 5-tuple strat = (cid:4)Q, M, rstart, start, reply(cid:5) whose elements satisfy the
following:
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
362
•
W. H. Winsborough and N. Li
r Q is a countable set of states. We use q (possibly with superscripts and
subscripts) to denote a state.
r M is a countable set of messages. We use m and a for messages, possibly
with subscripts.
r The function rstart : Conﬁguration × K → Q deﬁnes the initial state of the
requester, given his conﬁguration G and the requester principal K O. This
state is rstart(G, K O) = q, in which q (cid:10)∈ {success, failure}.
r The function start : Conﬁguration × Resource × K → Q × M deﬁnes how
an access mediator starts a negotiation, given his conﬁguration G, the re-
source requested ρ, and the requester principal K O. It yields start(G, ρ, K O) =
(cid:4)q, m(cid:5). The access mediator uses q as its initial local state and, when
q (cid:10)∈ {success, failure}, sends the message m to the requester to start the
negotiation.
r The function reply : Q × M → Q × M deﬁnes each action taken by a nego-
tiator, given the negotiator’s conﬁguration G, its current state q, and the last
message m from the opponent. It yields reply(q, m) = (cid:4)q(cid:3), m(cid:3)(cid:5). The negotiator
(cid:10)∈ {success, failure}) sends m(cid:3) to the other
changes state to q(cid:3) and (when q(cid:3)
negotiator.
3.2 Safety of Ack-Policy Enforcement
We now deﬁne what it means when we say a negotiation strategy is safe. Intu-
itively, a strategy is safe if the ack policies are correctly enforced when using
the strategy. What does it mean to say that a negotiator N’s ack policies are
correctly enforced? The deﬁnition we will present uses the following intuition:
no adversary M , using observations it can make in negotiation processes with
N, can make any inference about credentials proving the attributes of N it is
not entitled to know (i.e., attributes whose ack policies are not satisﬁed by M ).
To make the above intuition precise, we ﬁrst model the ability of adversaries.
An adversary is given by a set of principals it controls and a set of credentials for
each of the principals. This models the ability of entities controlling different
principals to collude. (We want a notion of safety that precludes colluding prin-
cipals from inferring information that none of them is authorized for by pooling
their observations about how the negotiator behaves with each of them.) We
assume each such set contains all credentials potentially available to the prin-
cipal for use in trust negotiation. (If an adversary controls a principal that is an
attribute authority of an attribute t, then credentials about t are available to
the adversary.) We assume that an adversary only interacts with a participant
N through trust negotiation. We allow the adversary M to initiate negotiation
with N, by sending N a request, as well as to wait for N to initiate a negotiation
process by sending a request to M . An adversary is limited by the credentials
available to it, which determine the attributes possessed by the principals it
controls. We assume that it is infeasible to forge signatures without knowing
the private keys.
The next deﬁnition introduces several concepts in a top-town fashion. It be-
gins by giving the main deﬁnition of indistinguishability of conﬁgurations and
then gives deﬁnitions for terms used in the main deﬁnition. The deﬁnition
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•
363
formalizes the observations an adversary M can make by engaging in negoti-
ations with a negotiator that uses a given strategy. We capture this in terms
of M ’s ability to determine that the negotiator’s actual conﬁguration G is not
some other conﬁguration G(cid:3). When M cannot do this, G and G(cid:3) are said to be
indistinguishable. The deﬁnition then formalizes the actions that an attacker
can take and the response it induces in a negotiator that has a certain conﬁg-
uration and uses a certain strategy. The goal of the deﬁnition is to enable us
to articulate the intuition that if an adversary cannot distinguish between two
conﬁgurations, one of which has an attribute and the other of which does not,
then the adversary cannot infer whether the negotiator has the attribute or
not. This will be made precise below.
Deﬁnition 3.1. Indistinguishability, Attack Sequence, Induced Reaction Se-
quence. Given an adversary M , a negotiation strategy strat, and two con-
ﬁgurations G and G(cid:3), G and G(cid:3) are indistinguishable under strat by M if
for every attack sequence seq that is feasible for M , the reaction sequence
induced by seq from G is the same as the reaction sequence induced by
seq from G(cid:3).
In the following, we deﬁne feasible attack sequences and the reaction se-
quences they induce. There are two forms of attack sequence, requester and
responder. A requester attack sequence has the form [K A, ρ, a1, a2, . . . , ak], in
which K A is a principal, ρ is a resource, and a1, a2, . . . , ak are messages.
This corresponds to the case in which the adversary uses K A, a principal it
controls, to request access to resource ρ, and then sends a1, a2, . . . , ak one
by one in the negotiation. Given a conﬁguration G and a strategy strat =
(cid:4)Q, q0, start, reply(cid:5), the reaction sequence induced by a requester attack sequence
[K A, ρ, a1, a2, . . . , ak] is the sequence of messages: [m1, m2, . . . , m(cid:5)] such that
there exists a sequence of states [q1, q2, . . . , q(cid:5)] that satisﬁes the following
conditions:
1. (cid:4)q1, m1(cid:5) = start(G, ρ, K A)
2. For all i ∈ [2, (cid:5)], (cid:4)qi, mi(cid:5) = reply(qi−1, ai−1)
3. For all i ∈ [1, (cid:5) − 1], qi (cid:10)∈ {success, failure}
4. Either (cid:5) = k + 1 or both 1 ≤ (cid:5) ≤ k and q(cid:5) ∈ {success, failure} (in the
latter case, the negotiation ends before the complete attack sequence is
used)
A responder attack sequence has the form [K A, a1, a2, . . . , ak], in which K A is
a principal and a1, a2, . . . , ak are messages. This corresponds to the case that the
negotiator sends a resource request to the adversary, who responds by sending
the messages of the attack sequence. Given a conﬁguration G and a strategy
strat = (cid:4)Q, rstart, start, reply(cid:5), a reaction sequence induced by a responder attack
sequence [K A, a1, a2, . . . , ak] is the sequence of messages [m1, m2, . . . , m(cid:5)] such
that there exists a sequence of states [q0, q1, . . . , q(cid:5)] that satisﬁes the following
conditions:
1. q0 = rstart(G, K A)
2. For all i ∈ [1, (cid:5)], (cid:4)qi, mi(cid:5) = reply(qi−1, ai)
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
•
W. H. Winsborough and N. Li
364
3. For all i ∈ [1, (cid:5) − 1], qi (cid:10)∈ {success, failure}
4. Either (cid:5) = k + 1 or both 1 ≤ (cid:5) ≤ k and q(cid:5) ∈ {success, failure}
Observe that an attack sequence may induce different reaction sequences
when interacting with different strategies. In particular, these reaction se-
quences may be of different lengths and some may be shorter than the attack
sequence. To simplify presentation, we choose to deﬁne an attack sequence as
an object that exists independently of the possible reaction sequences it induces.
Given an adversary M , an attack sequence seq is feasible for M if K A is
controlled by M and the only credentials included in seq are those in credentials
available to M . Feasibility formalizes the notion that M cannot forge signatures
as part of computing seq.
The notion of indistinguishability given in Deﬁnition 3.1 is suitable only for
deterministic negotiation strategies. Furthermore, the way a feasible attack
sequence is deﬁned limits strategies that can be considered to those that verify
possession of a credential by seeing the digital signature in the credential and
verifying that the signature is valid. These limitations do not affect the devel-
opment of this paper, as the strategies that we analyze in this paper all satisfy
the above requirements.
A more general way of deﬁning indistinguishability is to follow the deﬁni-
tion of indistinguishability in the cryptographic literature, see, e.g. Goldreich
[2001]. In this approach, each negotiation strategy is modeled as a Probabilistic
Polynomial-time Interactive Turing Machine (PPITM), which takes a conﬁgura-
tion as its private input. A negotiation process is modeled as a joint computation
between two PPITMs. Given an adversary M , a distinguisher A based on M is
a PPITM that takes M as private input, interacts with a negotiation strategy,
and outputs either 0 or 1. We use the notation A(M )[S(G)] to denote the output
of A when given M as private input and interacting with the strategy S, which
is given G as its private input. We say that two conﬁgurations G and G(cid:3) are
indistinguishable under a strategy S if for any distinguisher A based on M :
(cid:3)(cid:3)
(cid:3)(cid:3) Pr[A(M )[S(G)] = 1] − Pr[A(M )[S(G
(cid:3)
)] = 1]
is negligible in the security parameter, where the security parameter can be
taken as the minimal length of public keys used by the attribute authorities,
and the probability is taken over the coin choices of A and S.
Observe that indistinguishability under Deﬁnition 3.1 implies the above
cryptographic notion of indistinguishability, assuming that the signature
schemes used in the credential are secure. If G and G(cid:3) are indistinguishable
under strat in the sense of Deﬁnition 3.1, then the only way to observe any
difference at all between interacting with G and G(cid:3) is by forging a credential
the adversary does not have, which can be successfully carried out only with
negligible probability.
Deﬁnition 3.2. Unacknowledgeable Attribute Set. Given a conﬁguration
G and an adversary M , we say that an attribute t is unacknowledgeable to M
if no principal controlled by M possesses attributes that satisfy AckG (t). We
deﬁne UnAcks(G, M ) to be the set of attributes that are unacknowledgeable
to M .
ACM Transactions on Information and System Security, Vol. 9, No. 3, August 2006.
Safety in Automated Trust Negotiation
•
365
Intuitively, ATN should not enable an adversary M to learn any information
about UnAcks(G, M ) that M would not otherwise be able to learn. Given such a
set of unacknowledgeable attributes, the negotiator’s credentials can be divided
into those that can be released to M and those that cannot.
Deﬁnition 3.3. Releasable and Unreleasable Credentials. Given a set of cre-
dentials E and a set of unacknowledgeable attributes U , the set of unreleasable
credentials consists of those that deﬁne unacknowledgeable attributes, and is
given by unreleaseable(E, U ) = {e ∈ E | T (e)∩U (cid:10)= ∅}. The remaining elements
of E are releasable credentials: releaseable(E, U ) = E − unreleaseable(E, U ) =
{e ∈ E | T (e) ∩ U = ∅}.
Equipped with this terminology, we can now state that if U is the set of
attributes that must not be acknowledged to M and if two negotiators using
the same strategy have the same set of releasable credentials with respect to
U , then they should behave the same from the point of view of M . To put it
another way, a strategy is credential–combination–hiding if conﬁgurations that
differ only in unreleasable credentials are indistinguishable. We now formalize
this intuition in the central deﬁnition of the paper, which requires that an ATN
strategy hide all information about credentials representing unacknowledge-