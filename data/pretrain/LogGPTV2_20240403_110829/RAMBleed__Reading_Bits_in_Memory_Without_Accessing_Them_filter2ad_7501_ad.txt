Next, for double-
sided hammering, we need to locate addresses in three con-
secutive rows within the same bank. As some of the physical
address bits of the 2 MiB block are used for determining the
banks of individual 4 KiB pages, we must somehow obtain
these addressing bits for every 4 KiB page in our block.
Since 2 MiB= 221 bytes, and our 2 MiB block is physically
sequential, obtaining the low 21 bits of the physical addresses
amounts to Ô¨Ånding the block‚Äôs offset from being 2 MiB aligned
(where the low 21 bits are 0). In older Linux kernels, an
attacker could use the pagemap interface to translate virtual
addresses to physical addresses. However, in the current Linux
kernel, the interface requires root privileges due to security
concerns [55]. Instead of using the pagemap interface, we
exploit the row-buffer timing channel of Pessl et al. [49] to
recover the block offset.
Computing Offsets. To Ô¨Ånd a block‚Äôs offset from a 2 MiB
aligned address, we take advantage of the fact that our 2 MiB
block is physically contiguous and that the set of distances
between co-banked addresses uniquely deÔ¨Ånes the block‚Äôs
offset. Figure 4 illustrates this concept. The blue block is a
2 MiB aligned block originally found in the fragmented order
10 block, while the red, 2 MiB unaligned block is the region
we have obtained from our attack on the allocator. The colored
vertical stripes are 4 KiB pages, where two pages of the same
color indicate that they reside in the same bank.
The distances di, i ‚àà {0, 1, 2, . . . , n} are the differences
between the addresses of the i-th page in our block and the
very next address located in the same bank. Together, the set
{d0, d1, d2, . . . , dn} forms a distance pattern for our block.
There are 512 possible offsets for a 4 KiB page within a 2 MiB
block; simulations of DRAM addressing conÔ¨Årm that these
patterns uniquely identify the block‚Äôs offset.
Recovering Distance Patterns. We can now use Pessl et
al.‚Äôs [49] row-buffer timing side channel to Ô¨Ånd the distances
{d0,¬∑¬∑¬∑ , dn} between pages located in the same bank. Once
we have uncovered enough of the distance pattern to uniquely
identify a single offset, we have succeeded in computing the
offset of our 2 MiB block. This typically occurs after Ô¨Ånding
fewer than ten distances.
We compute a distance di by alternating read accesses
between pi and pj for j ‚àà {i+1, i+2, . . . , i+2n‚àí2, i+2n‚àí1},
where pi is the page at the i-th offset within the block, and
1The more naive strategy of Ô¨Årst exhausting all smaller blocks and then
using one larger request in the hope that it is served from a single large
block tends not to work in practice. Any block of order 0 released during the
exhaustion phase will be recycled before splitting the large block and will
result in a non-consecutive allocation.

		




	








Fig. 4: The blue block is the 2 MiB aligned block that was
originally found in the fragmented order 10 block, while the
red, 2 MiB unaligned block is the block we have obtained from
our attack on the allocator. We compute the offset by Ô¨Ånding
the distances between co-banked pages di, i ‚àà {0, 1, 2, .., n},
which uniquely identify the offset.
n is the number of pages with the same row index. We then
time how long it takes to access both addresses, and average
the results over 8,000 trials; the page that corresponds to the
greatest read time is identiÔ¨Åed as residing in the same bank as
pi. The distance di is then equal to the difference in the page
offset between the two.
The reason we search over the next two rows of any bank
(i.e., 512 KiB), and not just the next, is that the nature of
the DRAM addressing scheme means that the two co-banked
pages in consecutive rows can potentially lie anywhere within
the memory range with the same row index. When we compute
the distances, we make use of Schwarz‚Äôs [54] optimizations
for confusing the memory controller to obtain accurate timing
measurements. We empirically Ô¨Ånd over many trials that this
method works with a 100% success rate.
Recovering Bit 21.
So far, we have uncovered bits 0‚Äì20
of the physical address. As Pessl et al. [49] show, however,
DRAM addressing on our system depends on bits 0‚Äì21. The
naive solution is to simply adjust our attack on the memory
allocator to obtain a physically contiguous 4 MiB block. This
solution, however, is infeasible as the buddy allocator does not
track 8 MiB blocks, and thus cannot split an 8 MiB block into
two contiguous 4 MiB blocks. Another solution is to simply
guess the value of bit 21, doubling the attack‚Äôs running time.
We can, however, overcome this through an insight into the
DRAM addressing scheme. On our system (a Haswell machine
with two DIMMs on a single channel) there are three bank
addressing bits used to select between the eight banks within
a single rank. As speciÔ¨Åed by [49], bit 21 is only used for
computing the third bank addressing bit by XORing bits 17
and 21 of the physical address. Thus, to Ô¨Ånd two physical
addresses a0, a1 located in the same bank in consecutive 8 KiB
rows, we need to ensure that
17 ‚äï a0
a0
17 ‚äï a1
21 = a1
21
where ai
j is the j-th least signiÔ¨Åcant bit in the i-th physical
addresses (a0, a1). Then, given a physical address a0 in the
2 MiB block, when we want to Ô¨Ånd another physical address
a1 in the same bank, but located in the row above. First we set
a1 to be a0 plus the size until the next row index. Then, we
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:39:51 UTC from IEEE Xplore.  Restrictions apply. 
702
21 nor a1
adjust a1
17 to preserve the above equation. Even though we do
not know a0
21, we can examine bits 0 till 20 in a0 to
see if the addition of the size of row index done for computing
a1 had resulted in a carry for bit 21. If so, we compensate by
Ô¨Çipping a1
17 in order to preserve the above equation.
B. Memory Templating
After obtaining blocks of contiguous memory, we proceed
to search them for bits that can be Ô¨Çipped via Rowhammer.
We refer to this as the templating phase, which is performed
as follows. We Ô¨Årst use our technique to obtain 2 MiB blocks
of physically contiguous memory. Then, we locate addresses
that belong to the same bank using the method described
above. Next, we perform double-sided hammering with both
1-0-1 and 0-1-0 striped conÔ¨Ågurations. Finally, we record the
locations of these Ô¨Çips for later use with RAMBleed.
C. Placing Secrets Near Flippable Bits
After templating memory, we exploit the determinism of the
Linux physical memory allocator to place the victim‚Äôs page in
the desired physical locations as outlined in Figure 3. While a
similar task was achieved in [61] on Android‚Äôs ION allocator
by exhausting most of the available memory to control the
placement of the victim, we achieve the same result on Linux‚Äôs
buddy allocator without memory exhaustion. Following the
convention of [61][51][58], we call this technique ‚ÄúFrame
Feng Shui‚Äù, as we are coercing the allocator into placing select
pages into a frame of our choosing.
Exploiting Linux‚Äôs Buddy Allocator. The buddy allocator
stores blocks of equal order in a Ô¨Årst-in-last-out (FILO) stack-
like data structure, and upon receipt of a request of order n,
the allocator returns the most recently freed block from the
n-th order‚Äôs bucket. Thus, if we assume that the victim, after
being triggered, allocates a predictable number of pages before
allocating the secret-containing page, we can force Linux‚Äôs
memory allocator to place the victim‚Äôs secret containing page
in a page frame of our choice by the following:
‚Ä¢ Step 1: Dummy Allocations.
The attacker allocates n
4 KiB pages by calling mmap with the MAP POPULATE
Ô¨Çag, where n is the number of pages that the victim will
allocate before allocating its secret containing page.
‚Ä¢ Step 2: Deallocation.
The attacker inspects her own
address space and chooses the target page frame for the
victim‚Äôs secret to land on (one that neighbors the Ô¨Çippable
the attacker calls munmap and deallocates
bits). Next,
the selected frame. The attacker then immediately unmaps
all the pages mapped during Step 1. After doing so, the
allocator‚Äôs stack-like data structure for the 0th order blocks
will have the n pages on top, followed by the target page.
After Steps 1 and
2,
the attacker immediately triggers the victim process,
letting it perform its memory allocations. In Section VII,
we accomplish this by initiating an SSH connection, which
is served by the SSH daemon. After being triggered, the
victim allocates n pages, which then land in the frames
vacated by the pages mapped in Step 1. Finally, the victim
‚Ä¢ Step 3: Triggering the Victim.
allocates its secret-containing page, which then lands in the
desired frame, as it will be located on top of the allocator‚Äôs
stack-like data structure for 0th order blocks at this point.
D. Putting It All Together
With the above techniques in place, we can now describe
our end-to-end attack. which consists of two phases.
OfÔ¨Çine.
The attack starts by allocating 2 MiB blocks and
dividing them into physically consecutive pages as described
in Section V-A. The attacker then templates her blocks and
locates Rowhammer induced bit Ô¨Çips using the methodology
described in Section V-B. Notice that this phase is done ofÔ¨Çine,
entirely within the attacker‚Äôs address space, and without any
interaction with the victim. Finally, after the attacker obtains
enough Rowhammer induced bit Ô¨Çips to read the victim‚Äôs
secret, the attacker begins the online phase described below.
Online.
In this step, the attacker uses Frame Feng Shui to get
the victim to place his secret in the physical memory locations
desired by the attacker (e.g., using the layout in Figure 3).
The attacker then performs the RAMBleed attack described in
Section IV-C to exploit the data-dependency with the victim‚Äôs
bits, and subsequently deduces some of their values. Finally,
the attacker repeats the online phase step until a sufÔ¨Åcient
number of secret bits where leaked from the victim (e.g.,
around 66% percent of the victim‚Äôs RSA secret key, which
is sufÔ¨Åcient to mathematically recover of the remaining bits).
VI. EXPERIMENTAL EVALUATION
To measure RAMBleed‚Äôs capacity as a read side channel,
we measure the rate and accuracy of RAMBleed‚Äôs ability
to extract bits across process boundaries and address spaces
under ideal conditions and predictable victim behavior.
Next, after evaluating both double-sided and single-sided
RAMBleed, in Section VII we evaluate RAMBleed against
an OpenSSH 7.9 server (which is a popular SSH server),
extracting the server‚Äôs secret RSA signing keys.
The Victim Process.
In the proof-of-concept victim code,
the victim waits for an incoming TCP connection, and then
copies the secret key into a freshly allocated page (using an
anonymous mmap) upon each TCP connection request. This
behavior is akin to a server that runs a decryption routine every
time the attacker makes a request, thereby using its secret key.
The Attacker Process. The attacking process uses the tech-
niques described in Section V-A to obtain 2 MiB physically
consecutive blocks, and subsequently templates memory for
Ô¨Çippable cells using the methods outlined in Section V-B.
Finally, the attacker uses Frame Feng Shui to place the secret-
containing page above and below a Ô¨Çippable bit (for single-
sided, we only place it above). Concretely, we accomplish this
by unmapping the target location and then initiating a TCP
connection with the victim. Since n = 0 in this case, meaning
that the secret is the Ô¨Årst allocation upon context switching,
the secret-containing page should land in the recently vacated
frame. The attacker then hammers the surrounding rows and
leaks the secret bits by reading out the Ô¨Çips from its own page.
We run both processes as taskset with the same CPU afÔ¨Ånity.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:39:51 UTC from IEEE Xplore.  Restrictions apply. 
703
Type
Double-sided
Single-sided
Overall
90%
74%
Read Accuracy Percents
False Positive
False Negative
5%
19%
15%
29%
TABLE I: ‚Äúfalse positive‚Äù events, where a uniform conÔ¨Ågu-
ration still Ô¨Çips are more rare than ‚Äúfalse negative‚Äù events, in
which a striped conÔ¨Åguration refuses to Ô¨Çip.
Hardware. We use an HP Prodesk 600 desktop running
Ubuntu 18.04, featuring an i5-4570 CPU and two Axiom
DDR3 4 GiB 1333 MHz non-ECC DIMMs, model number
51264Y3D3N13811, in a single-channel conÔ¨Åguration.
Experimental Results. While [13] report that bit Ô¨Çips are
deterministic with regards to the surrounding bits (i.e. a bit
Ô¨Çips if and only if it is in a striped conÔ¨Åguration), on our
systems we observe the more general case where the bit Ô¨Çips
are probabilistic. Next, the probability of a bit Ô¨Çip highly
depends on the type of conÔ¨Åguration (striped or uniform). This
uncertainty adds noise to our read-channel, which we handle
with a variant of the Heninger-Shacham technique [24].
Memory Templating. The time required to template memory
and Ô¨Ånd the needed Ô¨Çips is entirely dependent upon how easily
the underlying DIMMs yield bit Ô¨Çips. While [37] and [21]
report Ô¨Ånding thousands of Ô¨Çips within minutes, we found
Ô¨Çips at a more modest rate of 41 Ô¨Çips per minute.
Reading Secret Bits.
After templating the memory with
a striped 0-1-0 pattern, our experimental code can read out
the victim‚Äôs secret at a rate of 3‚Äì4 bits/second. As we can
see from the results in Table I, this works with 90% accuracy
overall, and 95% accuracy when it comes to identifying 1-bits.
This is because ‚Äúfalse positive‚Äù events, that is, when a 1-1-
1 uniform conÔ¨Åguration still results in the center bit Ô¨Çipping
from one to zero, are much rarer than ‚Äúfalse negative‚Äù events,