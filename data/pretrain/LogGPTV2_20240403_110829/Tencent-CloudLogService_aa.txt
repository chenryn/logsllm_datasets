TencentCLS: The Cloud Log Service with High Query Performances
| Muzhi Yu 
Peking University 
Beijing, China 
PI:EMAIL | Zhaoxiang Lin 
Tencent Cloud Computing (Beijing) Co., Ltd.
Beijing, China 
PI:EMAIL | Jinan Sun 
Peking University 
Beijing, China 
PI:EMAIL |
|---|---|---|PI:EMAIL |
|---|---|---|
| Runyun Zhou  Tencent Cloud Computing (Beijing) Co., Ltd. Beijing, China  PI:EMAIL |Guoqiang Jiang  Tencent Cloud Computing (Beijing) Co., Ltd. Beijing, China  PI:EMAIL |Hua Huang  Tencent Cloud Computing (Beijing) Co., Ltd. Beijing, China  PI:EMAIL |
Shikun Zhang 
Peking University 
Beijing, China 
zhangsk@pku.edu.cnBeijing, China 
PI:EMAIL
ABSTRACT
With the trend of cloud computing, cloud log service is becoming increasingly important, as it plays a critical role in tasks such as root cause analysis, service monitoring and security audition. Cloud Log Service at Tencent (TencentCLS) is a one-stop solution for log collection, storage, analysis and dumping. It currently hosts more than a million tenants and the top tenant can generate up to PB-level logs per day.The most important challenge that TencentCLS faces is to sup-port both low-latency and resource-efficient queries on such large quantities of log data. To address that challenge, we propose a novel search engine based upon Lucene. The system features a novel pro-cedure for querying logs within a time range, an indexing technique for the time field, as well as optimized query algorithms dedicated to multiple critical and common query types.As a result, the search engine at TencentCLS gains significant performance improvements with regard to Lucene. It gains 20x performance increase with standard queries, and 10x performance increase with histogram queries in massive log query scenarios. In addition, TencentCLS also supports storing and querying with microsecond-level time precision, as well as the microsecond-level time order preservation capability.PVLDB Reference Format: 
Muzhi Yu, Zhaoxiang Lin, Jinan Sun, Runyun Zhou, Guoqiang Jiang, Hua Huang, and Shikun Zhang. TencentCLS: The Cloud Log Service with High Query Performances. PVLDB, 14(1): XXX-XXX, 2020.
This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visitto view a copy of this license. Fin permission by emailing Copyright is held by the owner/author(s). Publication rights licensed dowment.Proceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.
PVLDB Artifact Availability: 
The source code, data, and/or other artifacts have been made available at
URL_TO_YOUR_ARTIFACTS.
1 	INTRODUCTION
With the trend of cloud computing, cloud log service has become in-creasingly popular. Log services significantly simplify the collection and analysis of logs, and provide an one-stop solution for scenar-ios such as root cause analysis, service monitoring and security audition.Cloud log service also has a huge business value and therefore attracts many companies. Not only there have been commercially successful enterprises dedicated in log services, such as Splunk [9] and Elastic [6], but also many cloud vendors have launched their own log service product [1, 4, 5].Tencent Cloud Log Services (TencentCLS) [? ] is the log service product provided at the Tencent Cloud, and it has experienced rapid growth in the past year (500% anual growth). In this paper, we describe some characteristics and challenges of the business scenarios faced by TencentCLS, and explain the architecture and the techniques employed within TencentCLS. We also provide ex-perimental evaluations with regard to some major techniques, in order to show the benefits of those designs.The TencentCLS business scenarios have the following charac-teristics and challenges.
	Heavy and Skewed Log Writes 
	The logs stored in TencentCLS are of large and skewed quantity. Currently, TencentCLS has millions of log topics, about only 10% percent of which are monthly active.
The logs collected per day for the active topics are highly skewed. Concretely, the top topic has more than 100 billion logs collected per day while 90% of the active topics generate less than 10 million logs per day each.Heavy and Skewed Log Queries
Figure 1: The latency distribution of different types of queries
Not only the quantity of logs has a skewed distribution but also the query latency. As is shown in Figure 1, although the average latency of queries is below 1 second, there is a long-tail effect, and some of the queries take up to 30 seconds or even timeout.To be more precise, suppose that we use Lucene [12] as the search engine of TencentCLS, the index of the timestamp field of 10 billion logs would have the size of around 30 GB. Even loading the index from a disk drive that has the speed of 150 MB/s takes up a total of 200 seconds.According to the online data, around 95% of the queries ask for the latest daily logs. In order for those queries to be answered in less than 30 seconds, the number of the logs written on each drive per day is limited to 1.5 billion. Therefore, for the top topic that generates 100 billion logs per day, a total of at least 67 disks (with a speed of 150 MB/s) are required, which is very costly.Histogram Queries are Common 
	In addition, for each query, TencentCLS shows the distribution of logs in time that meets the conditions. We call the queries that support such visualization histogram queries, which collect the counts of hits in different time segments. Histogram queries are extremely common, but also resource demanding.The above challenges can be worse if we use higher precision for timestamps, because the index of the timestamp will grow larger as the precision increases, and ultimately slowing down the query processes.
Therefore, it is a both necessary and challenging task to design a system that supports low-latency queries on these large-quantity, highly-skewed log data.Our solution is a novel log search engine featuring time series index. It is based on Lucene and is optimized especially for log data. Compared with Lucene, it differs mainly in the following aspects.
(1) We keep the documents sorted according to their times-	tamps.
(2) We design an time series index dedicated for the time field. (3) We design a search algorithm dedicated for tail queries 	(queries that are expected to return the last few hits).(4) We optimize the histogram queries (queries that are ex-pected to return the distribution of number of logs in time).
Thanks to the design, TencentCLS significantly lowers the query latency, and supports microsecond-level precision for timestamps with little cost. In the scenario described above, we only need 3 disks instead of 67 to achieve the same query latency.
2
Figure 2: The TencentCLS ArchitectureFigure 2: The TencentCLS Architecture
• Scalability: ES supports discovering and joining new nodes and horizontal auto scaling. Node failures do not affect the 	cluster.
	Due to its many advantages and rapid development, Elastic-Search now enjoys a great community, and has many well-known enterprises users as well as a large number of startup companies. 	After comparative analyses, we have finally decided to use Lucene / ElasticSearch as the basis of our distributed log storage and dis-tributed full-text search solution.2.2 	Weaknesses of Lucene
Lucene’s support for range query was not provided at the begin-ning, and when it was finally introduced, it has performance issues. In practice, the search can be very slow when there are many oc-currences of terms in a single document. Although Lucene is often regarded as an efficient full-text search engine, its high performance is mostly limited to boolean queries.Starting with Lucene version 6.0, a new index data structure BKD-Tree [19] for numeric datatype was introduced to optimize the performance of range queries in Lucene.
The complexity of the BKD algorithm is linearly correlated with the index cardinality, and the number of hits. Therefore, the orig-inal BKD algorithm is not suitable for massive log query, whose timestamps are of high cardinality.3 	ARCHITECTURE
The architecture for TencentCLS is shown in Figure 2. The entire system is deployed on Tencent Cloud, using cloud services such as Elastic Compute Service, Cloud Object Storage, etc. Its components are described as follows.
3
indexes [14], SkipList [17] indexes and BKDTree [19] indexes. Also, column-oriented storage is adopted to support efficient analyses.
3.7 	Object Storage Layer3.7 	Object Storage Layer
The object storage layer takes care of the data persistence. It also supports demands such as re-indexing from objects in the event of an exception.
4 	A SEARCH ENGINE OPTIMIZED FOR LOG 	QUERY
This section describes the search engine used in TencentCLS. The search engine is built upon Lucene and is highly optimized for log queries.We begin with some basic examples of queries, and then we briefly describe the indexing and searching of Lucene. Next, we demonstrate the characteristics of log queries and explain why the default indexing and searching functionalities provided by native Lucene is not satisfactory. Finally, we propose our design, and elaborate on its differences from the Lucene search engine.4.1 	An Example Log Document and Log Query
A typical log document consists of a timestamp, text, and properties. Below is an example.
[2021 −09 −28 T10 : 1 0 : 3 9 . 1 2 3 4 ] 	[ ip = 1 9 2 . 1 6 8 . 1 . 1 ] XXXXXXXX
	Normally, to accelerate log query, the system will create indexes for the timestamp, text and properties respectively.
	A typical log query specify a few conditions, and a time range. Below is an example.SELECT ∗ FROM xxxx_index 
WHERE ip = 	1 9 2 . 1 6 8 . 1 . 1 
	and timestmap >= 2021 −09 −28 T00 : 0 0 : 0 0 	and timestamp < 2021 −09 −29 T00 : 0 0 : 0 0
4.2 	Indexing and Searching in Lucene
In Lucene, every log document will be assigned a unique number called docid. When creating an index, an inverted index storing a mapping from contents to sets of docids will be created.For example, with the timestamp field, Lucene will create a post-ings list that maintains a mapping from all possible timestamps to sets of docids. Based on that, Lucene can quickly response to the queries that search for a given timestamp. The algorithm com-possible timestamps. plexity for the query is 𝑂(𝑙𝑜𝑔(𝑛)), where 𝑛 is the number of the
4.3 	Characteristics and Challenges with Log 	QueriesAlthough Lucene is known to be good at full text queries thanks to the design of the inverted index R, its performance drops dramat-ically when searching numeric fields [15]. The performance gets even worse when searching high-cardinality numeric fields R. Un-fortunately, the timestamp field of log data is a high-cardinality nu-meric field. In fact, a maximum of 24*60*60*1000 = 86400000 unique values can be generated every day, when using millisecond-level4
Figure 3: Range query with unordered documents. It requires visiting every timestamp index within that range in order to collect the documents.
Figure 4: Range query with ordered documents. It requires visiting only two timestamp and the documents can be cal-culated based on the first docid and the last docid.
• The support for timestamps of higher precision becomes feasible.Theoretically, keeping the documents sorted would reduce the complexity of each query from 𝑂(𝑛) to 𝑂(𝑙𝑜𝑔(𝑛)), where 𝑛 is the number of the hit documents.
4.4.2 	Implementation of the Sorting Mechanism. The function that keeps the documents sorted is implemented using the existing index-sorting R in Lucene. The native Index-sorting has two functionalities. First the specified field is kept sorted. Second early-terminate is applied to increase the performance. The early-terminate feature is explained as follows.By default, a search request in Lucene must visit every document that matches the query in order to return the top documents sorted by a defined sort. When the index and search sorts are the same, it is feasible to limit the number of documents that must be viewed per segment in order to obtain the top N documents globally. With early-terminate, Lucene will only compare the first N documents per segment if it detects that the top docs of each segment are already sorted in the index. The remaining documents that fit the query are gathered in order to count the overall number of results and create aggregations.Therefore, for example, when we want the latest 10 log data, if the index-sorting is not enabled, we have to sort all the log data
5
Figure 6: Binary search for timestamp endpoints with sec-ondary index
Figure 7: Head query and tail query
4.5.2 	Optimization 2. Reverse Binary Search Algorithm for Tail Queries. We find that the queries can be divided into two groups: head queries and tail queries, and the latter can be optimized.We define the head queries as the queries that are to search the last few entries that satisfy the given conditions, and the tail queries as the queries that are to search the first few entries, as is shown in Figure 7. Given that the log data are sorted in ascending order by time, head queries are to search the oldest logs that meets the conditions while the tail queries are to search the newest logs. We also provide an example of the tail query below.SELECT ∗ FROM xxx_index 
WHERE 	. . .
ORDER BY timestamp 
DESC LIMIT 	1 0 ;