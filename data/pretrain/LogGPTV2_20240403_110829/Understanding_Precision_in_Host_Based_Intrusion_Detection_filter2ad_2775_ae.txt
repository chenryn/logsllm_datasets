instructions with static jump instructions, we remove the necessity of exposing these
control transfers to the monitor. In order to reduce code space explosion, we apply a hot
code optimization that ﬁrst identiﬁes function calls executed at a high rate at run-time
and then performs this transformation. The monitor uses DynInst to alter the code of
the monitored process during execution. We ensure that the memory region where the
inlined copy resides is write-protected by invoking necessary kernel services.
6.2 Attack Detection
Our approach has the same precision as inlined CFI. We evaluated the attack detection
ability of our system after ﬁrst ensuring the static analyzer and our implementation
introduced no false positives for our test programs on normal workloads. We conducted
two types of experiments: detection of real attacks against standard Linux programs
and detection of various arbitrary code execution attacks against a vulnerable synthetic
program.
Our ﬁrst test evaluated the ability of the external monitor in detecting actual attacks
against Linux programs with published vulnerabilities and exploits (Table 1). We en-
sured that the exploits successfully worked on the vulnerable programs. We then con-
structed models for each program and used our system to monitor the execution of each
program. As expected, the IDS successfully detected every attack before arbitrary code
was executed.
Second, we tested the ability of the control-ﬂow based model to detect a collection
of injected code and existing code attacks against a synthetic program. The program
contains a vulnerability that allows an attacker to write anywhere in data. We created
synthetic exploits that modify various code pointers inside the applications’ memory:
return addresses on the stack, global offset table (GOT) entries used for locating shared
library functions, and function pointers. We tested each control-ﬂow modiﬁcation with
three different classes of targets: injected code, code in the middle of a function, and
Table 1. Detection capability of external control-ﬂow IDS on real applications
Application Vulnerability type
imapd 10.234 Stack buffer overﬂow
thttpd 2.21
Stack buffer overﬂow
indent 2.2.9 Heap overﬂow
GnuPG 1.0.5 Format string vulnerability
[3]
[4]
[1]
[2]
Exploit code URL Detected
√
√
√
√
38
M. Sharif et al.
Table 2. Detection of synthetic tests for various kinds of arbitrary code execution
Injected Existing (inside function) Existing (function start)
Attack Step
Change return address
Modify GOT
Modify function pointer
√
√
√
√
√
√
√
√
×
the entry point of a libc function. Table 2 contains the results of our synthetic attack
detection tests.
In all but one synthetic test, our IDS successfully detected the attacks when execution
was about to be diverted before the code executed. For the failed test, our IDS missed
the attack due to the imprecision introduced in the statically-recovered CFG of the
binary code at indirect calls. The target address was a valid function entry point and
was thus classiﬁed as a normal control-ﬂow transfer by our model. This imprecision
demonstrates a shortcoming of static binary analysis that may not be present in static
source code analysis or in dynamic analysis.
6.3 Performance Impact of External Control-Flow Monitoring
We evaluated the performance overhead on several real-world applications by measur-
ing the execution-time overhead on programs representing both I/O-bound and
CPU-bound applications. Table 3 summarizes the results. All timing values represent an
average over 5 executions. We ﬁrst measured each application’s average unmonitored
runtime, shown in the results as “Base time”. To determine the time cost of external
monitoring of control ﬂow, we then ran the programs with our external monitor. “Mon-
itored time” indicates monitored program execution time. We additionally show the
percentage increase in execution time and the percentage increase in program code size
due to function body replication during the hot code optimization.
These results show that an external monitor can efﬁciently detect attacks at the ﬁne-
grained control-ﬂow level. Our hot code optimization inlining functions called at high
rates effectively balanced the need for fast execution veriﬁcation with the need to use
extra memory responsibly. For example, the I/O-bound applications such as httpd
and cat incurred a low monitoring overhead and therefore no inlining of code was
performed. On the other hand, inlining was crucial for the CPU-bound and function-
call-bound program gzip for which the crippling performance loss of over 4,000%
was brought down to only a 23.1% degradation in speed for an 11.3% increase in space.
For comparison, the Dyck model [17] produced a 3% overhead for cat for which our
system incurs a 1.2% overhead. The earlier model, however, had a 0% overhead for
gzip, which has a main loop that repeatedly calls functions to compress or decompress
data, making only a few system calls. The Dyck model hence can be efﬁcient for this
Table 3. Performance results for various applications. Time values are in real-time units.
Application Base time (sec) Monitored time (sec) Time overhead Inlining space overhead
thttpd
SQLite
gzip
cat
20.40
55.44
11.03
10.06
21.23
66.04
13.59
10.18
4.0%
19.1%
23.1%
1.2%
0.0%
8.8%
11.3%
0.0%
Understanding Precision in Host Based Intrusion Detection
39
program. Our model instead adds overhead due to the initial control-ﬂow checks and
the run-time program transformation needed to optimize away the function calls.
Our control-ﬂow model requires considerably less memory than system call based
models such as VPStatic [9] or PAID [23] because it is similar to a single-state PDA. In
summary, our IDS ties the power of precise control-ﬂow checks with the convenience
of external system call monitoring while keeping performance comparable to previous
system-call based approaches.
7 Conclusion
We presented a formal framework for understanding and comparing the attack detection
capability of anomaly detection approaches that characterize normal program execution
behavior by modeling and monitoring a set of program generated events. In our prin-
cipal contribution, we showed that for any system call sequence based approach, there
always exists a more precise control-ﬂow based approach. In order to derive more efﬁ-
cient and simpliﬁed models, we provided the theory behind selecting essential control-
ﬂow events that require exposure. In addition, we proved that control-ﬂow models are
more precise even in the case of incomplete analysis, showing that hybrid approaches
that include system calls provide only redundant detection. Finally, we used the ideas
of reducing essential control-ﬂow events in the program with appropriate transforma-
tions in order to make external monitoring at the control-ﬂow level feasible. Our static
analysis based approach provides better precision while having performance overhead
comparable to previous system-call based approaches.
Acknowledgments
This material is based upon work supported by the National Science Foundation under
Grant No. 0133629. Any opinions, ﬁndings, and conclusions or recommendations ex-
pressed in this material are those of the authors and do not necessarily reﬂect the views
of the National Science Foundation. We would like to thank Paul Royal for his help in
this research.
References
1. GNU Indent Local Heap Overﬂow Vulnerability,
http://www.securityfocus.com/bid/9297/
2. GnuPG Format String Vulnerability,
http://www.securityfocus.com/bid/2797/
3. imapd Buffer Overﬂow Vulnerability,
http://www.securityfocus.com/bid/130/
4. thttpd defang Buffer Overﬂow Vulnerability,
http://www.securityfocus.com/bid/8906/
5. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: Control-Flow Integrity: Principles, Im-
plementations, and Applications. In: Proceedings of ACM Computer and Communications
Security (CCS), Alexandria, Virginia, November 2005, ACM Press, New York (2005)
6. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: A theory of secure control ﬂow. In: Lau,
K.-K., Banach, R. (eds.) ICFEM 2005. LNCS, vol. 3785, Springer, Heidelberg (2005)
40
M. Sharif et al.
7. Bhatkar, S., Chaturvedi, A., Sekar, R.: Dataﬂow anomaly detection. In: IEEE Symposium
on Security and Privacy, Oakland, California, May 2006, IEEE Computer Society Press, Los
Alamitos (2006)
8. Chen, H., Wagner, D.: MOPS: An infrastructure for examining security properties of soft-
ware. In: ACM Conference on Computer and Communications Security (CCS), Washington,
DC, November 2002, ACM Press, New York (2002)
9. Feng, H., Gifﬁn, J., Huang, Y., Jha, S., Lee, W., Miller, B.: Formalizing sensitivity in static
analysis for intrusion detection. In: Proceedings of the IEEE Symposium on Security and
Privacy, Oakland, California, May 2004, IEEE Computer Society Press, Los Alamitos (2004)
10. Feng, H., Kolesnikov, O., Fogla, P., Lee, W., Gong, W.: Anomaly detection using call stack
information. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland,
California, May 2003, IEEE Computer Society Press, Los Alamitos (2003)
11. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaff, T.A.: A sense of self for unix processes.
In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May
1996, IEEE Computer Society Press, Los Alamitos (1996)
12. Gao, D., Reiter, M., Song, D.: Gray-box extraction of execution graphs for anomaly de-
tection. In: Proceedings of the 11th ACM Conference on Computer and Communications
Security (CCS), Washington, DC, October 2003, ACM Press, New York (2003)
13. Gao, D., Reiter, M.K., Song, D.: On gray-box program tracking for anomaly detection. In:
USENIX Security Symposium, San Diego, California (August 2004)
14. Garvey, T., Lunt, T.: Model-based intrusion detection. In: Proceedings of the 14th National
Computer Security Conf. (NCSC), Baltimore, Maryland (June 1991)
15. Ghosh, A., Schwartzbard, A., Schatz, M.: Learning program behavior proﬁles for intrusion
detection. In: Proceedings of the 1st USENIX Workshop on Intrusion Detection and Network
Monitoring, Santa Clara, California (April 1999)
16. Gifﬁn, J., Jha, S., Miller, B.: Detecting manipulated remote call streams. In: Proceedings of
the 11th USENIX Security Symposium, San Francisco, California, August 2002 (2002)
17. Gifﬁn, J., Jha, S., Miller, B.: Efﬁcient context-sensitive intrusion detection. In: Proceedings
of the 11th Annual Network and Distributed Systems Security Symposium (NDSS), San
Diego, California, February 2004 (2004)
18. Gifﬁn, J.T., Jha, S., Miller, B.P.: Automated discovery of mimicry attacks. In: Zamboni, D.,
Kruegel, C. (eds.) RAID 2006. LNCS, vol. 4219, Springer, Heidelberg (2006)
19. Hollingsworth, J.K., Miller, B.P., Cargille, J.: Dynamic program instrumentation for scalable
performance tools. In: Proceedings of the Scalable High Performance Computing Confer-
ence, Knoxville, Tennessee (May 1994)
20. Ko, C., Fink, G., Levitt, K.: Automated detection of vulnerabilities in privileged programs by
execution monitoring. In: Proceedings of the 10th Annual Computer Security Applications
Conference (ACSAC), Orlando, Florida (December 1994)
21. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Automating mimicry attacks
using static binary analysis. In: Proceedings of the USENIX Security Symposium, Baltimore,
Maryland (August 2005)
22. Kruegel, C., Mutz, D., Valeur, F., Vigna, G.: On the detection of anomalous system call argu-
ments. In: Snekkenes, E., Gollmann, D. (eds.) ESORICS 2003. LNCS, vol. 2808, Springer,
Heidelberg (2003)
23. Lam, L., Chiueh, T.: Automatic extraction of accurate application-speciﬁc sandboxing pol-
icy. In: Recent Advances in Intrusion Detection, Sophia Antipolis, France, September 2004
(2004)
24. Lam, L., Li, W., Chiueh, T.: Accurate and automated system call policy-based intrusion pre-
vention. In: The International Conference on Dependable Systems and Networks (DSN),
Philadelphia, PA, USA (June 2006)
25. Landi, W.: Undecidability of static analysis. ACM Letters on Programming Languages and
Systems (LOPLAS) 1(4), 323–337 (1992)
Understanding Precision in Host Based Intrusion Detection
41
26. Lee, W., Stolfo, S., Mok, K.: A data mining framework for building intrusion detection mod-
els. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California,
May 1999, IEEE Computer Society Press, Los Alamitos (1999)
27. Sekar, R., Bendre, M., Bollineni, P., Dhurjati, D.: A fast automaton-based method for de-
tecting anomalous program behaviors. In: Proceedings of the IEEE Symposium on Security
and Privacy, Oakland, California, May 2001, IEEE Computer Society Press, Los Alamitos
(2001)
28. Tan, K., Killourhy, K.S., Maxion, R.A.: Undermining an anomaly-based intrusion detection
system using common exploits. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS,
vol. 2516, Springer, Heidelberg (2002)
29. Vigna, G., Kruegel, C.: Handbook of Information Security. ch. Host-based Intrusion Detec-
tion Systems. Wiley, Chichester (December 2005)
30. Wagner, D.: Static Analysis and Computer Security: New Techniques for Software Assur-
ance. Ph.D. dissertation, University of California at Berkeley (2000)
31. Wagner, D., Dean, D.: Intrusion detection via static analysis. In: Proceedings of the IEEE
Symposium on Security and Privacy, Oakland, California, May 2001, IEEE Computer Soci-
ety Press, Los Alamitos (2001)
32. Wagner, D., Soto, P.: Mimicry attacks on host based intrusion detection systems. In: Pro-
ceedings of the Ninth ACM Conference on Computer and Communications Security (CCS),
Washington, DC, November 2002, ACM Press, New York (2002)
33. Xu, H., Du, W., Chapin, S.J.: Context sensitive anomaly monitoring of process control ﬂow
to detect mimicry attacks and impossible paths. In: Jonsson, E., Valdes, A., Almgren, M.
(eds.) RAID 2004. LNCS, vol. 3224, Springer, Heidelberg (2004)
34. Zhang, T., Zhuang, X., Lee, W., Pande, S.: Anomalous path detection with hardware support.
In: Proceedings of the International Conference on Compilers, Architectures and Synthesis
of Embedded Systems (CASES), San Francisco, CA (July 2005)