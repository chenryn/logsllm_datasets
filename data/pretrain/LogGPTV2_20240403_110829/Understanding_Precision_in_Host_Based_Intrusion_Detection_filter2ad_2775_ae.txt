### 6.2 Attack Detection

Our approach achieves the same precision as inlined Control-Flow Integrity (CFI). To evaluate the attack detection capability of our system, we first ensured that the static analyzer and our implementation did not introduce any false positives for our test programs under normal workloads. We conducted two types of experiments: detection of real attacks against standard Linux programs and detection of various arbitrary code execution attacks against a vulnerable synthetic program.

#### Real Attacks on Standard Linux Programs
In our first test, we evaluated the external monitor's ability to detect actual attacks against Linux programs with known vulnerabilities and exploits (Table 1). We verified that the exploits successfully worked on the vulnerable programs. We then constructed models for each program and used our system to monitor their execution. As expected, the Intrusion Detection System (IDS) successfully detected every attack before any arbitrary code was executed.

| **Application** | **Vulnerability Type** | **Exploit Code URL** | **Detected** |
|-----------------|------------------------|----------------------|--------------|
| imapd 10.234    | Stack buffer overflow  | [3]                  | √            |
| thttpd 2.21     | Stack buffer overflow  | [4]                  | √            |
| indent 2.2.9    | Heap overflow          | [1]                  | √            |
| GnuPG 1.0.5     | Format string vulnerability | [2] | √ |

#### Synthetic Attacks on a Vulnerable Program
In our second test, we evaluated the control-flow-based model's ability to detect a collection of injected code and existing code attacks against a synthetic program. The program contains a vulnerability that allows an attacker to write anywhere in data. We created synthetic exploits that modify various code pointers within the application's memory, including return addresses on the stack, Global Offset Table (GOT) entries used for locating shared library functions, and function pointers. We tested each control-flow modification with three different classes of targets: injected code, code in the middle of a function, and the entry point of a libc function. Table 2 summarizes the results of our synthetic attack detection tests.

| **Attack Step** | **Injected** | **Existing (inside function)** | **Existing (function start)** |
|-----------------|--------------|--------------------------------|------------------------------|
| Change return address | √ | √ | × |
| Modify GOT | √ | √ | √ |
| Modify function pointer | √ | √ | √ |

In all but one synthetic test, our IDS successfully detected the attacks before the execution was diverted. For the failed test, the IDS missed the attack due to imprecision in the statically-recovered Control-Flow Graph (CFG) at indirect calls. The target address was a valid function entry point and was thus classified as a normal control-flow transfer by our model. This imprecision highlights a limitation of static binary analysis, which may not be present in static source code analysis or dynamic analysis.

### 6.3 Performance Impact of External Control-Flow Monitoring

We evaluated the performance overhead of our external control-flow monitoring on several real-world applications by measuring the execution-time overhead on both I/O-bound and CPU-bound applications. Table 3 summarizes the results. All timing values represent an average over five executions. We first measured each application's average unmonitored runtime, shown as "Base time." To determine the time cost of external monitoring, we ran the programs with our external monitor, and the results are shown as "Monitored time." We also report the percentage increase in execution time and the percentage increase in program code size due to function body replication during the hot code optimization.

| **Application** | **Base time (sec)** | **Monitored time (sec)** | **Time overhead (%)** | **Inlining space overhead (%)** |
|-----------------|--------------------|--------------------------|-----------------------|---------------------------------|
| thttpd          | 20.40              | 21.23                    | 4.0%                  | 0.0%                            |
| SQLite          | 55.44              | 66.04                    | 19.1%                 | 8.8%                            |
| gzip            | 11.03              | 13.59                    | 23.1%                 | 11.3%                           |
| cat             | 10.06              | 10.18                    | 1.2%                  | 0.0%                            |

These results demonstrate that an external monitor can efficiently detect attacks at the fine-grained control-flow level. Our hot code optimization, which inlines functions called at high rates, effectively balances the need for fast execution verification with the need to use extra memory responsibly. For example, I/O-bound applications like `httpd` and `cat` incurred low monitoring overhead, so no inlining was performed. In contrast, inlining was crucial for the CPU-bound and function-call-bound program `gzip`, reducing the crippling performance loss from over 4,000% to only a 23.1% degradation in speed for an 11.3% increase in space.

For comparison, the Dyck model [17] produced a 3% overhead for `cat`, while our system incurs a 1.2% overhead. However, the Dyck model had a 0% overhead for `gzip`, which has a main loop that repeatedly calls functions to compress or decompress data, making only a few system calls. Thus, the Dyck model is efficient for this program, whereas our model adds overhead due to initial control-flow checks and run-time program transformations needed to optimize away function calls.

Our control-flow model requires considerably less memory than system call-based models such as VPStatic [9] or PAID [23] because it is similar to a single-state Pushdown Automaton (PDA). In summary, our IDS combines the power of precise control-flow checks with the convenience of external system call monitoring, while maintaining performance comparable to previous system-call-based approaches.

### 7 Conclusion

We presented a formal framework for understanding and comparing the attack detection capabilities of anomaly detection approaches that characterize normal program execution behavior by modeling and monitoring a set of program-generated events. Our principal contribution shows that for any system call sequence-based approach, there always exists a more precise control-flow-based approach. To derive more efficient and simplified models, we provided the theory behind selecting essential control-flow events that require exposure. Additionally, we proved that control-flow models are more precise even in the case of incomplete analysis, showing that hybrid approaches that include system calls provide only redundant detection. Finally, we used the ideas of reducing essential control-flow events in the program with appropriate transformations to make external monitoring at the control-flow level feasible. Our static analysis-based approach provides better precision while having performance overhead comparable to previous system-call-based approaches.

### Acknowledgments

This material is based upon work supported by the National Science Foundation under Grant No. 0133629. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. We would like to thank Paul Royal for his help in this research.

### References

1. GNU Indent Local Heap Overflow Vulnerability, <http://www.securityfocus.com/bid/9297/>
2. GnuPG Format String Vulnerability, <http://www.securityfocus.com/bid/2797/>
3. imapd Buffer Overflow Vulnerability, <http://www.securityfocus.com/bid/130/>
4. thttpd defang Buffer Overflow Vulnerability, <http://www.securityfocus.com/bid/8906/>
5. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: Control-Flow Integrity: Principles, Implementations, and Applications. In: Proceedings of ACM Computer and Communications Security (CCS), Alexandria, Virginia, November 2005, ACM Press, New York (2005)
6. Abadi, M., Budiu, M., Erlingsson, U., Ligatti, J.: A theory of secure control flow. In: Lau, K.-K., Banach, R. (eds.) ICFEM 2005. LNCS, vol. 3785, Springer, Heidelberg (2005)
7. Bhatkar, S., Chaturvedi, A., Sekar, R.: Dataflow anomaly detection. In: IEEE Symposium on Security and Privacy, Oakland, California, May 2006, IEEE Computer Society Press, Los Alamitos (2006)
8. Chen, H., Wagner, D.: MOPS: An infrastructure for examining security properties of software. In: ACM Conference on Computer and Communications Security (CCS), Washington, DC, November 2002, ACM Press, New York (2002)
9. Feng, H., Griffin, J., Huang, Y., Jha, S., Lee, W., Miller, B.: Formalizing sensitivity in static analysis for intrusion detection. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 2004, IEEE Computer Society Press, Los Alamitos (2004)
10. Feng, H., Kolesnikov, O., Fogla, P., Lee, W., Gong, W.: Anomaly detection using call stack information. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 2003, IEEE Computer Society Press, Los Alamitos (2003)
11. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaff, T.A.: A sense of self for Unix processes. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 1996, IEEE Computer Society Press, Los Alamitos (1996)
12. Gao, D., Reiter, M., Song, D.: Gray-box extraction of execution graphs for anomaly detection. In: Proceedings of the 11th ACM Conference on Computer and Communications Security (CCS), Washington, DC, October 2003, ACM Press, New York (2003)
13. Gao, D., Reiter, M.K., Song, D.: On gray-box program tracking for anomaly detection. In: USENIX Security Symposium, San Diego, California (August 2004)
14. Garvey, T., Lunt, T.: Model-based intrusion detection. In: Proceedings of the 14th National Computer Security Conference (NCSC), Baltimore, Maryland (June 1991)
15. Ghosh, A., Schwartzbard, A., Schatz, M.: Learning program behavior profiles for intrusion detection. In: Proceedings of the 1st USENIX Workshop on Intrusion Detection and Network Monitoring, Santa Clara, California (April 1999)
16. Griffin, J., Jha, S., Miller, B.: Detecting manipulated remote call streams. In: Proceedings of the 11th USENIX Security Symposium, San Francisco, California, August 2002 (2002)
17. Griffin, J., Jha, S., Miller, B.: Efficient context-sensitive intrusion detection. In: Proceedings of the 11th Annual Network and Distributed Systems Security Symposium (NDSS), San Diego, California, February 2004 (2004)
18. Griffin, J.T., Jha, S., Miller, B.P.: Automated discovery of mimicry attacks. In: Zamboni, D., Kruegel, C. (eds.) RAID 2006. LNCS, vol. 4219, Springer, Heidelberg (2006)
19. Hollingsworth, J.K., Miller, B.P., Cargille, J.: Dynamic program instrumentation for scalable performance tools. In: Proceedings of the Scalable High Performance Computing Conference, Knoxville, Tennessee (May 1994)
20. Ko, C., Fink, G., Levitt, K.: Automated detection of vulnerabilities in privileged programs by execution monitoring. In: Proceedings of the 10th Annual Computer Security Applications Conference (ACSAC), Orlando, Florida (December 1994)
21. Kruegel, C., Kirda, E., Mutz, D., Robertson, W., Vigna, G.: Automating mimicry attacks using static binary analysis. In: Proceedings of the USENIX Security Symposium, Baltimore, Maryland (August 2005)
22. Kruegel, C., Mutz, D., Valeur, F., Vigna, G.: On the detection of anomalous system call arguments. In: Snekkenes, E., Gollmann, D. (eds.) ESORICS 2003. LNCS, vol. 2808, Springer, Heidelberg (2003)
23. Lam, L., Chiueh, T.: Automatic extraction of accurate application-specific sandboxing policy. In: Recent Advances in Intrusion Detection, Sophia Antipolis, France, September 2004 (2004)
24. Lam, L., Li, W., Chiueh, T.: Accurate and automated system call policy-based intrusion prevention. In: The International Conference on Dependable Systems and Networks (DSN), Philadelphia, PA, USA (June 2006)
25. Landi, W.: Undecidability of static analysis. ACM Letters on Programming Languages and Systems (LOPLAS) 1(4), 323–337 (1992)
26. Lee, W., Stolfo, S., Mok, K.: A data mining framework for building intrusion detection models. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 1999, IEEE Computer Society Press, Los Alamitos (1999)
27. Sekar, R., Bendre, M., Bollineni, P., Dhurjati, D.: A fast automaton-based method for detecting anomalous program behaviors. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 2001, IEEE Computer Society Press, Los Alamitos (2001)
28. Tan, K., Killourhy, K.S., Maxion, R.A.: Undermining an anomaly-based intrusion detection system using common exploits. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, Springer, Heidelberg (2002)
29. Vigna, G., Kruegel, C.: Handbook of Information Security. ch. Host-based Intrusion Detection Systems. Wiley, Chichester (December 2005)
30. Wagner, D.: Static Analysis and Computer Security: New Techniques for Software Assurance. Ph.D. dissertation, University of California at Berkeley (2000)
31. Wagner, D., Dean, D.: Intrusion detection via static analysis. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, California, May 2001, IEEE Computer Society Press, Los Alamitos (2001)
32. Wagner, D., Soto, P.: Mimicry attacks on host-based intrusion detection systems. In: Proceedings of the Ninth ACM Conference on Computer and Communications Security (CCS), Washington, DC, November 2002, ACM Press, New York (2002)
33. Xu, H., Du, W., Chapin, S.J.: Context sensitive anomaly monitoring of process control flow to detect mimicry attacks and impossible paths. In: Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, Springer, Heidelberg (2004)
34. Zhang, T., Zhuang, X., Lee, W., Pande, S.: Anomalous path detection with hardware support. In: Proceedings of the International Conference on Compilers, Architectures and Synthesis of Embedded Systems (CASES), San Francisco, CA (July 2005)

---

This revised version aims to improve clarity, coherence, and professionalism, ensuring that the content is well-structured and easy to follow.