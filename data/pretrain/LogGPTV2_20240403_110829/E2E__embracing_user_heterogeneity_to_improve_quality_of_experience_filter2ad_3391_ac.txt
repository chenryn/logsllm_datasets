across requests. E2E provides a resource allocation policy for the
shared service that makes a decision for each request, e.g., telling it
which replica to route the request to in a distributed database, or
what priority to assign the request in a message broker. Figure 9
depicts only one shared-resource service, but in general E2E can
serve multiple services (or multiple applications within a service)
simultaneously, provided these services do not interact on the same
request. We discuss interrelated services, such as those used to
aggregate results for a high-level web request, in §9.
E2E takes as input three variables: an offline-profiled QoE model
(such as the ones in Figure 3), an external delay model from the
frontend web servers, and a server-side delay model from the shared-
resource service. The external delay model provides the distribution
of external delays across requests and an estimate of the current
request’s external delay. This external delay is then tagged as an
additional field on the request and on any associated sub-requests
(similar to [21]). The server-side delay model provides an estimate
of the server-side delay of a request based on the decision and the
current workload. Based on these inputs, E2E returns a decision
per request for how to allocate resources to it. We discuss how
server-side delays and external delays are estimated in §6.
Figure 10 gives two illustrative examples of how E2E might affect
resource allocation policies, for a distributed database and a message
broker. In particular, E2E can improve the requests’ QoE in two
ways. First, E2E can assign more QoE-sensitive requests to decisions
that have lower server-side delays, e.g., a less loaded replica in a
distributed database. Second, E2E can allocate resources to affect the
server-side delays, in order to reduce the delays for QoE-sensitive
requests. Even if E2E cannot predict server-side delays exactly, it
can still create a discrepancy between the delays experienced by
requests of different QoE sensitivities. For instance, as illustrated
in Figure 10(a), E2E can assign uneven loads across the replicas of
a distributed database, so that less loaded replicas are available to
process QoE-sensitive requests with faster response times.
.4.5.6.7 0.6 0.7 0.8 0.9 1QoE (Normalized)Throughput (Normalized)Reshuffled delayCurrent Policy.1.3.5.71234567Server-sidedelay (sec.)External delay (sec.)0.2.4.6.81 0 0.5 1 1.5 2CDFStdev over mean of server-side delayPage Type 1Page Type 2Page Type 3E2E controllerResource allocation policyRequests…Server-side delay modelQoEmodelExternal delay modelShared-resource service(distributed database/  message broker)Frontend web serverDecisions(replica/priority)SIGCOMM ’19, August 19–23, 2019, Beijing, China
X. Zhang et al.
Term Brief description
ri; R
ci; C
si; S
Q(·)
zi; Z
G(·)
request; vector of requests
external delay of ri; vector of external delays
server-side delay of ri; vector of server-side delays
QoE model; Q(d) returns the QoE of total delay d
allocation decision of ri; vector of decisions
server-side delay model; G(Z) returns the server-side delay
vector of decision vector Z
Table 2: Summary of terminology
This property makes it challenging to design a scalable decision-
making policy. In particular, the circular dependence between server-
side delays and resource allocation decisions makes the problem
algorithmically expensive; and the need to account for other re-
quest’s external delays adds processing overheads.
The above makes E2E conceptually different from many other
request scheduling problems where each request has an innate
property that indicates its urgency, such as subscription type (e.g.,
premium vs regular users) or the application’s delay sensitivity
(e.g., video streaming vs. web pages). Notably, Timecard [41] and
DQBarge [21], two closely related systems to ours, use the external
delay to directly determine the processing deadline of each request
in isolation, without considering other requests or the global impact
on available resources (see §8).
4 E2E: DECISION POLICY
This section describes E2E’s decision-making policy for allocating
resources to requests.
4.1 Problem formulation
We start by formulating the problem of E2E. Table 2 summarizes
th request, its ex-
our terminology. We use ri , ci , si , zi to denote the i
ternal delay, server-side delay, and allocation decision, respectively.
Given n concurrent requests r1,..., rn whose external delays ci..., cn
are provided by the external delay model, E2E finds the decision
vector Z=(z1,..., zn) that maximizes
where Q(d) is the QoE of a request with total delay d, as estimated
by the QoE model; and G(z, Z) is the server-side delay of a request
assigned to decision z given that the complete decision vector is
Z, as estimated by the server-side delay model. We assume that
the QoE, external delay, and server-side delay models are known
and provided as input; we discuss their implementation in §6. For
now we assume the server-side delay model G(·) returns precise
(noise-free) estimates; we relax this assumption at the end of §4.3.
Unfortunately, solving this problem is computationally hard,
because it has to take two dependencies into account:
1. The amount of resource allocated by zi to a request i depends on
how much impact the resource would have on the request’s QoE.
But this impact is not linear: as more resources are given to the
request, the improvement to its QoE may increase or diminish
(since Q is non-linear with respect to server-side delay G(zi)).
2. The resource allocation among a set requests depends on the
server-side delay distribution, which is itself a function of the
resource allocation.
n
i =1
1
n
Q(ci + G(zi , Z)),
Figure 10: Examples of how E2E may allocate resources differently
in (a) a distributed database and (b) a message broker.
Figure 11: Illustration of how allocating resources based solely on
requests’ external delays can lead to suboptimal QoE. Scenarios 1 and 2
have the same pair of requests but different server-side delays. We use
the assignment of server-side delays to represent resource allocation.
In scenario 1, assigning the shorter server-side delay (s2) to B and
the longer one (s1) to A leads to better overall QoE. But in scenario 2,
giving the shorter delay (s′
2) to A leads to worse overall QoE.
The next two sections present E2E’s resource allocation policy
and control interface, using the distributed database and message
broker as two concrete examples of a shared-resource service. In
general, E2E makes very few assumptions about how a shared
service processes requests or physically shares its resources; it
only requires the service to expose an API for controlling decisions
(e.g., the replica to select, the priority of a request, etc.). Also, our
work places less emphasis on the prediction of external/server-side
delays, or the implementation of a control plane on which E2E’s
resource allocation policy may run. Existing work already addresses
and provides general solutions for these aspects (e.g., [20, 21, 41]).
3.2 Key challenge
The key challenge behind E2E is that the optimal decision for a
request cannot be determined from the request alone. Instead, the
decision depends on the external delay distribution of other requests
as well as the server-side delay distribution, which itself is a function
of these decisions. Figure 11 illustrates a simple example where
prioritizing requests purely based on external delay can lead to a
bad decision, and shows how to improve it by taking the server-side
delays and other requests’ external delays into account. The key
observation is that the non-convexity of the QoE-delay curve may
cause the sensitivity of a request’s QoE to flip depending on the
external delay and the magnitude of the server-side delay.
Requests sensitive to server-side delayRequests insensitive to server-side delayDefault policy(Load balanced)New policy(AwareofQoEsensitivity)(a) Replica selection in distributed databaseDefault policy (FIFO)New policy(AwareofQoEsensitivity)(b) Scheduling in message brokerQoEDelay𝑠"𝑠#QoEDelay𝑠"𝑠#QoEDelay𝑠#′𝑠"′QoEDelay𝑠#′𝑠"′(a) Scenario 1: 𝑄𝑜𝐸𝑠"⇒𝐴+𝑄𝑜𝐸𝑠#⇒𝐵>𝑄𝑜𝐸𝑠#⇒𝐴+𝑄𝑜𝐸𝑠"⇒𝐵ABABABAB(b) Scenario 2: 𝑄𝑜𝐸𝑠"′⇒𝐴+𝑄𝑜𝐸𝑠#′⇒𝐵 Q then
i, Z′)) → q′
3 

5
6
7
8
Z′ → Z, q′ → q
*/
*/
*/
to the slot it is linked to. In this example the final decisions are:
c2 → x, c3 → x, c1 → y.
The key insight is to cast the problem of maximizing the QoE of a
request-decision mapping to that of maximizing a matching in a
bipartite graph, for which polynomial-time algorithms exist [24, 30].
The polynomial is cubic in the number of requests, so care must be
taken to ensure an efficient implementation; this is addressed in §5.
In practice, the server-side delay model G(·) estimates a distri-
bution of the server-side delay, not an exact value, so the request-
decision mapping algorithm (Figure 12) needs to be modified as
follows. Instead of labeling each slot with a fixed value in Fig-
ure 12(a) (e.g., sx ), we label it with a probability distribution fx(s)
(provided by G(·)), and label the edge in Figure 12(b) between re-
quest ri and the slot with the expected QoE over this distribution,
i.e.,∫ ∞
0 Q(ci + s)fx(s)ds.
5 E2E: DECISION OVERHEAD
E2E’s has to make a resource allocation decision for each request,
and this decision might change if one or more of the input variables
(QoE model, external delay model, server-side delay model) changes.
This overhead can quickly become unscalable if left unchecked.
Our idea for reducing the decision-making overhead is to coarsen
the granularity of decisions along two dimensions: (1) spatially
grouping requests with similar characteristics, and (2) temporally
caching decisions that are updated only when a significant change
ReplicasRequestsSlots𝑐1𝑐2𝑐3𝑠𝑥𝑠𝑥𝑠𝑦𝑄𝑐2+𝑠𝑥RequestsSlots𝑐1𝑐2𝑐3𝑠𝑥𝑠𝑥𝑠𝑦𝑠𝑥𝑠𝑥𝑠𝑦xy(a) Obtain server-side delays of the decision allocation from G()(c) Find a maximum bipartite matching(b) Construct a bipartite graph between requests and decisions(d) Translate bipartite matching into replica selection decisionsRequests𝑐1𝑐2𝑐3xyReplicasSlotsSIGCOMM ’19, August 19–23, 2019, Beijing, China
X. Zhang et al.
occurs in the input variables. Although these are heuristics with
no formal guarantees, we find that they work well in practice (§7).
Coarsening spatial granularity: We coarsen decisions spatially
by grouping requests into a constant number of buckets based on
their external delays. Specifically, we split the range of external
delays into k intervals, and all requests whose external delays fall
in the same interval are grouped in the same bucket. We then run
E2E’s decision-making policy over the buckets rather than indi-
vidual requests, and assign the same final decision to all requests
in a bucket. This coarsening ensures that the running time of the
decision-making process is always constant, rather than growing
with the cube of the number of requests (the fastest bipartite match-
ing algorithm [24, 30]). To minimize the amount of QoE degradation
caused by making decisions at the bucket level, the external delay
intervals satisfy two criteria: (1) they evenly split the request popu-
lation, and (2) the span of any interval does not exceed a predefined
threshold δ. Our evaluation shows these criteria are effective.
Coarsening temporal granularity: We have empirically ob-