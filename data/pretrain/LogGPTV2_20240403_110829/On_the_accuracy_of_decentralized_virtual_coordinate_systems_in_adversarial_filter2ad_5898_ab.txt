a single victim node is displaced from its correct position,
this has an epidemic, detrimental eﬀect on many of the nodes
in the system as the victim node will push/pull nodes away
from their correct coordinates by reporting its now incorrect
coordinates. That is because a correct node that computed
its coordinates based on incorrect information may serve as
a reference set for other nodes in the system, thus negatively
inﬂuencing their coordinate computation. Besides degrad-
ing the accuracy of the coordinate system, the attacks will
also adversely impact any application using the coordinate
system to estimate network measurements. In addition, as
the attacks exploit the semantics of the information con-
tained on the packet, they do not add a noticeable change
in traﬃc load and thus are diﬃcult to detect by traditional
mechanisms.
3. LEVERAGING OUTLIER DETECTION
TO ADD ROBUSTNESS TO VIRTUAL
COORDINATE SYSTEMS
In this section, we discuss how techniques used in net-
work security can be used in the context of virtual coor-
dinate systems to make them more robust to attacks from
compromised nodes. As such systems were proposed with
the intention to decrease the communication cost involved
in active monitoring, our goal is to propose mitigation tech-
niques that do not add any communication to the system.
We propose to prevent incorrect coordinate updates by de-
tecting and ﬁltering out outliers in the metrics reported by
queried nodes. Our method evaluates temporal and spatial
correlations among data in the system. Below, we provide
an overview of outlier detection and describe how we apply
it to virtual coordinate systems.
3.1 Overview of Outlier Detection
The usability of a data set and the quality of statistical
measures derived from it are integrally related to the number
of outliers present. Outliers are data points which deviate
so much from the rest of the data set as to arouse suspicion
that they were generated by a diﬀerent mechanism [7, 19].
The identiﬁcation of outliers can lead to discovering impor-
tant trends and information, such as the presence of mali-
cious activities. Outlier detection, also known as anomaly
or deviation detection, has been used in a variety of diﬀerent
ﬁelds including intrusion detection [14, 38], fraud detection
[15], medical analysis [41], and business trend analysis [23].
Many of the techniques for outlier detection utilize a sta-
tistical - based or distance-based approach in which an out-
lier is any point which lies beyond a speciﬁed distance thresh-
old. The Euclidean, Manhattan, Minkowski, and Maha-
lanobis distance functions are the most commonly used func-
tions in determining distance [41, 8], each having its own
beneﬁts given the type of analysis being performed.
Malicious activity can lead to spatial and temporal incon-
sistencies. Spatial outlier detection identiﬁes observations
which are inconsistent with their surrounding neighbors,
while temporal outlier detection identiﬁes inconsistencies in
the metrics of the observation space of a system over time.
The use of both temporal and spatial outlier detection al-
lows for the identiﬁcation of multiple types of attacks with
better accuracy than either alone.
3.2 Applying Outlier Detection in Virtual
Coordinate Systems
We leverage techniques from outlier detection to identify
malicious behavior and take defensive actions to mitigate its
eﬀects. Instead of allowing malicious coordinate mappings
to occur and then trying to detect them, we focus on reduc-
ing the likelihood of a node computing incorrect coordinates
through the use of statistical outlier detection. Since the ev-
idence of malicious activity is distributed across space and
time, we propose to detect them using both temporal and
spatial correlations among metrics in the system.
Each node independently performs outlier detection be-
fore changing its coordinates in order to identify and ﬁlter
out outliers in the received metrics. Spatial outlier detec-
tion compares the recently received metrics from each of the
queried nodes in a node’s reference set and forces a node
to report metrics consistent with what other reference peers
are currently reporting. Temporal outlier detection exam-
ines the consistency of the metrics received from an indi-
vidual queried node over time and forces a node to report
metrics consistent with what it has reported in the past.
To avoid adding communication cost, we use metrics al-
ready reported by the nodes in the reference set. We use
the 3-tuple of (cid:104)remote error, change in remote coordinates,
latency(cid:105) to generate the spatial outlier statistics and the
5-tuple of (cid:104)remote error, local error, latency, change in re-
mote coordinates, change in local coordinates(cid:105) to generate
the temporal outlier statistics. The metrics were chosen
on the basis that while each of them represents a diﬀerent
measure of system performance, changes in one measure will
result in a correlated change in other metrics. For example,
as the system stabilizes to low overall error, the local er-
ror reported by each node and correlated magnitude of the
change in coordinates will both change less. An attacker
must therefore report a high error with greatly changing co-
ordinates in order to not be identiﬁed as malicious. Our
solution also forces an attacker to lie consistently with other
peers. This is diﬃcult to achieve as an attacker does not
have perfect knowledge of the observation space, must ac-
curately predict the random subset of reference nodes that
will be queried, and only has a ﬁnite amount of time to
coordinate with other attackers.
Our approach uses the Mahalanobis [45] distance to de-
tect outliers. We selected this distance function because it
has been shown eﬀective at detecting outliers with multiple
attributes [30], scales each variable based on its standard
deviation and covariance, and takes into account how the
measured attributes change in relation to each other [44].
Spatial outlier detection
3.2.1
We use spatial outlier detection to examine the consis-
tency of recently received metrics from queried nodes. A
node queries a random node from its reference set and re-
ceives an observation tuple which consists of (cid:104)remote error,
change in remote coordinates, latency(cid:105). The node records
this response and tracks the most recent u updates in a
queue-like fashion, where the oldest responses are replaced
by newer ones and u is equal to the size of the reference set.
Unlike more message-intensive distributed systems where a
new set of responses from all nodes queried (in this case
nodes in the reference set) are collected in response to one
query [11], virtual coordinate systems collect these responses
sequentially. Our approach requires a node to perform out-
lier detection every time it receives a new tuple, considering
the most recent u updates. We highlight that this technique
is an instance of spatial outlier detection since we examine
metrics across various system nodes and not time.
Once a node receives an observation tuple, the node ﬁrst
computes the centroid of the data set consisting of obser-
vation tuples from the stored u updates. The node then
computes the Mahalanobis distance between the received
observation tuple and the centroid as follows [45]:
d((cid:126)x, (cid:126)y) =
(((cid:126)x − (cid:126)y)T C−1((cid:126)x − (cid:126)y))
(1)
(cid:112)
where (cid:126)x and (cid:126)y are the feature vectors consisting of error,
latency, and distance from the last virtual coordinate. (cid:126)x is
the value from the query response and (cid:126)y is the average value
that was calculated. C−1 is the inverse covariance matrix
computed from the stored observation tuples. Finally, this
distance is compared against a spatial threshold. We discuss
spatial threshold selection in Sec. 4.3.
3.2.2 Temporal outlier detection
We use temporal correlations to detect inconsistencies in
the metrics reported over time by a reference set node. We
use the tuple consisting of (cid:104)remote error, local error, latency,
change in remote coordinates, change in local coordinates(cid:105).
Using incremental learning, we compute a temporal centroid
for each of the members of a node’s reference set. We as-
sume each of the reported metrics is statistically indepen-
dent, necessitating the storage of just the mean, standard
deviation, and sample count computed from the received
query responses over time. The stored values for a reference
set member are incrementally updated with the metrics re-
ceived from that member’s query response, similar to [45],
using the technique described in [24]. In order to compare
newly received values with the temporal centroid, we use the
“simpliﬁed Mahalanobis distance” presented in [45]:
d(x, ¯y) =
(|xi − ¯yi|/( ¯σi + α))
(2)
i=0
where n is the number of metrics, ﬁve in our case (remote
error, local error, latency, change in remote coordinates, and
change in local coordinates), ¯σi is the standard deviation,
and α is a smoothing factor empirically set to .001 to help
to avoid over-ﬁtting and reduce false positives [45]. Once
a query response is received, the latest observation tuple is
compared with the corresponding temporal centroid using
the simpliﬁed Mahalanobis distance, based on a temporal
threshold that decides if the tuple is an outlier or not. We
discuss temporal threshold selection in Sec. 4.3.
n−1(cid:88)
Spatio-temporal outlier detection
3.2.3
We combine the two outlier detection mechanisms de-
scribed above by using a codebook technique similar to [18].
Each reference set node response that is not a spatial or
temporal outlier is utilized in updating the receiver node’s
coordinates.
If the reference node is found to be an out-
lier, the query response will not be used in future temporal
centroid calculations since it will not be incorporated into
the temporal mean, temporal standard deviation, or sample
count. Also, it will not be used in future spatial centroid
calculations since it will be dropped from the most recent u
updates.
4. EXPERIMENTAL RESULTS
In this section, we demonstrate the impact of attacks
against virtual coordinate systems through simulations us-
ing actual Internet topologies. In addition, we demonstrate
that our proposed mechanisms enhance the robustness of de-
centralized virtual coordinate systems to such attacks. We
examine their eﬀect on a representative decentralized vir-
tual coordinate system, Vivaldi [13], which is simulated in
the p2psim simulator [3]. We selected Vivaldi to demon-
strate the attacks and defense mechanisms because it is a
mature system, conceptually easy to understand and visu-
alize, and has been shown to produce low error embeddings
[13].
4.1 Evaluation Methodology
We use three diﬀerent RTT data sets collected from real-
life Internet topologies. Table 1 and Fig. 1 summarize the
characteristics of each data set. The data sets are:
• King: The King data set contains the pair-wise RTT
of 1740 nodes measured using the King method [17].
• Meridian: The Meridian data set, obtained from the
Cornell Meridian project [48], contains the pair-wise
RTT of 2500 nodes measured using the King method
[17].
• AMP: The AMP data set, collected from the NLANR
Active Measurement Project [2] on March 1, 2007,
contains complete information for 90 high-speed nodes
contained mostly in North America.
Table 1: Data Sets Characteristics
Data Set # Nodes
Std. Dev.
King
Meridian
AMP
1740
2500
90
Avg.
RTT
180ms
80ms
70ms
Max.
RTT
800ms
1000ms
453ms
RTT
66ms
69ms
51ms
We selected the King and Meridian data sets because they
are representative of larger scale peer-to-peer systems, and
were used in validating many virtual coordinate systems.
They have very diﬀerent data characteristics. The King
data set contains a variety of link latencies, allowing nodes in
the virtual coordinate system to form a structure in which
nodes with small RTTs between them converge into clus-
ters, as seen in Fig. 1(a). The average RTT of Meridian
is approximately half that of King since it contains many
nodes a short distance from one another, as seen in Fig. 1(b)
where the system forms fewer, but larger clusters. The ﬁ-
nal data set, AMP, was used since it represents a smaller,
high speed system, such as a corporate network. In AMP,
100ms or less links account for nearly 90% of all links, re-
sulting in one main cluster, as seen in Fig. 1(c). We did not
consider synthetic topologies since they do not capture im-
portant network properties such as violations of the triangle
inequality.
(a) King
(b) Meridian
(c) AMP
Figure 1: Node placement chosen by Vivaldi for var-
ious data sets
In order to quantitatively compare the eﬀect of attacks on
the accuracy of the system, we evaluate two error metrics:
System prediction error is deﬁned as
Errorpred = |ActRT T − EstRT T|
(3)
where the ActRT T is the actual measured RTT and EstRT T
is the predicted RTT by the virtual coordinate system. This
metric provides an intuition of how the overall system is
performing. The lower the system prediction error is, the
more accurate the predicted RTTs are.
Relative error is deﬁned as
Errorrel =
Errorattack
Errorno attack
(4)
where Errorattack is the system prediction error measured
in the presence of malicious nodes and Errorno attack is the
system prediction error without malicious nodes. This met-
ric captures the impact an attacker has on the coordinate
system. A relative error greater than one indicates a degra-
dation in accuracy and a value less than one indicates a
better estimation accuracy than the baseline.
For each of the error measures, the 5th, 50th, and 95th
percentile error are analyzed. These values are obtained
by selecting the corresponding entries from a sorted array
of prediction error and are averaged over multiple simula-
tion runs. Intuitively, the 5th percentile represents low error
nodes, the 50th percentile corresponds to average or median
error nodes, and the 95th percentile represents high error
nodes.
We ran one million tick long simulations, using the King
data set as our default topology unless otherwise noted. The
nodes join in a ﬂash-crowd scenario in which all nodes join
simultaneously and are each initially placed at the origin of
the logical coordinate space. Each node proceeds indepen-
dently of other nodes in the network and chooses a reference
set of 64 nodes using the Vivaldi method where half of the
nodes are selected as the closest nodes based on network la-
tency and the rest are selected at random. All other Vivaldi
parameters were initialized to the optimal values discussed
in [13]. Each of the experiments utilizes a two-dimensional
coordinate space {(x, y)|x, y ∈ [−300000, 300000]}. Every
simulation was run ten times with the reported metrics av-
eraged over all of the simulation.
(a) 5th Percentile Prediction Error
(b) 50th Percentile Prediction Error
(c) 95th Percentile Prediction Error
Figure 2: System prediction error under diﬀerent percentages of attackers (King)
(a) 5th Percentile Relative Error
(b) 50th Percentile Relative Error
(c) 95th Percentile Relative Error
Figure 3: Relative error under diﬀerent percentages of attackers (King)
4.2 Attacks Against Distributed Virtual