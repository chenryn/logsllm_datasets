αk
1
if τ ≥ k,
if τ  min{d1} + min{d2}.
Therefore, if, in a set of packet pair samples, min{d1 +
d2} > min{d1}+min{d2}, then we can deduce the following:
• If the delay of the ﬁrst (or the second) packet in the
minimum delay sum sample is greater than min{d1}
(or min{d2}), we conclude that this packet suﬀered
some queuing delay.
• In either case, the minimum delay sum is clearly greater
than the no-queuing delay sum and thus, the disper-
sion obtained from the minimum delay sum could have
been a distorted one.
In this way, the additional information relating individ-
ual minimum delays with the minimum delay sum helps in
weeding out incorrect minimum delay samples. We refer to
this relation as the minimum delay sum condition.
6.1 How much does this extra information
improve detection of convergence?
The probability of a single packet going through without
queuing is much higher than the probability of a packet pair
suﬀering the same fate. Thus, by comparing the delay of the
ﬁrst (second) packet in the minimum delay sample with the
minimum delay of the ﬁrst (second) packet, we can identify
incorrect minimum delays sums with the same probability
as that of the ﬁrst (second) packet not being queued in the
network.
We evaluated by simulations the probability of a packet
pair as well as a single packet going through without being
queued under diﬀerent conditions. A 6-hop linear topology,
similar to the one used in earlier sections, was used for the
simulations. Cross-traﬃc was LRD. The cross-traﬃc pack-
ets were a mix of three packet sizes as described in previous
sections. The probing packets had a size of 500 bytes.
Figure 13: Percentage increase in probability of un-
queued sample when using single packets instead of
packet pairs.
Figure 14: Number of samples required to satisfy
minimum delay sum condition.
Simulations were performed for both path-persistent and
non-persistent cross-traﬃc sources. Figure 12 shows the
probability of obtaining a sample which does not suﬀer any
queuing in the case of packet pairs and single packets, for dif-
ferent values of narrow link traﬃc load. Figure 13 shows the
percentage increase in the probability of obtaining a sample
which does not suﬀer any queuing when using single pack-
ets compared to using packet pairs. The increase is clearly
very large when the traﬃc load increases. Also, for non-
persistent traﬃc, the increase is larger than when traﬃc is
path-persistent. The more than 10 times increase for highly
loaded non-persistent traﬃc is very signiﬁcant.
6.2 More on Minimum Delay Sum
In order to show the eﬀect of using the minimum delay
sum condition with CapProbe, we show some simulation
results. The simulation parameters are similar to the ones
used in Section 6.1, except for that the size of probe packets
was varied. Figure 14 shows the number of samples required
to satisfy the minimum delay sum condition. The index in
Figure 14 shows diﬀerent probing packet sizes.
For low loads, the minimum delay condition is satisﬁed
after a small number of samples, while higher loads require
a larger number of samples. Also, packet pairs using smaller
packets satisfy this condition much faster than those using
larger packets.
To avoid situations where the minimum delay sum is equal
to the sum of the minimum delays but these minimum delays
are not the no-queuing delays (this can easily happen, for
instance, in the ﬁrst few samples, either of the packets of the
pair may not have gone through without queuing), we con-
tinue sending a few samples even after the minimum delay
sum is equal to the sum of the minimum delays. Thus, the
minimum delay sum condition is said to be satisﬁed when
the minimum delay sum is equal1 to the sum of the mini-
mum delays for the n previous samples and the minimum
delay sum and minimum delays have not changed during
these n samples. Through experiments, we found 40 to be
a good value for n.
6.3 Algorithm
Based on the observations in the last two sections, we
outline an algorithm to detect and speed-up convergence.
We again bring to the attention of the readers our result of
Section 5 that for a 6-hop path with up to 80% traﬃc load, a
sample not aﬀected by queuing could be obtained within 100
samples. This value of 100 is used as the number of packet
pair samples in each phase of the algorithm described below.
We also found while conducting experiments that when
the packet size was very small such that the operating sys-
tem could not measure the dispersion accurately, the band-
width obtained from the dispersion of samples varied quite a
lot. In our algorithm outlined below, we need to determine
whether the variance in bandwidth estimated from packet
pair samples is caused due to operating system not being
able to measure dispersion accurately. We used a simple
test: if the ratio of maximum to minimum bandwidth esti-
mated by samples > 50, it is likely to be due to measurement
errors. The value of 50 was obtained solely through experi-
mentation.
In the algorithm, each “run” is deﬁned to consist of packet
pair samples, all having the same packet size. The “run”
stops either if the minimum delay sum condition is satis-
ﬁed or 100 samples have been sent.
In the beginning, we
select two initial values of packet sizes, p1 = 700 bytes and
p2 = 900 bytes. These initial values are chosen since they
lie between very small values which cause problems in mea-
surement and large values (such as 1500 bytes, which is the
typical MTU value) which have a higher chance of suﬀer-
ing expansion. These are also values suggested by previous
authors [4].
1. The ﬁrst run uses p1 as the packet size. If the minimum
delay sum condition is not satisﬁed in this run, then:
(a) If the bandwidth estimated varies a lot across
samples (if the ratio of maximum to minimum
bandwidth estimated by packet pair samples is
greater than 50), it is an indication that the op-
erating system clock is unable to measure disper-
sion accurately. Thus, the packet sizes p1 and p2
are increased by 20% and the algorithm goes back
to Step 1. The upper bound on p1 and p2 is 1500
bytes, which is the largest packet that does not
suﬀer fragmentation.
(b) If the bandwidth estimated does not vary signiﬁ-
cantly across samples, it is an indication that no
ample could go through without queuing. Since
decreasing packet size leads to a higher chance of
obtaining an unqueued sample, the packet sizes p1
and p2 are decreased by 20% and the algorithm
goes back to Step 1.
2. If the minimum delay sum condition is satisﬁed in the
previous run with packet size p1, another run with
packet size p2 is employed.
1Since operating system measurements can have some error,
we say that the minimum delay sum is equal to the sum of
minimum delays when their diﬀerence is less than 1%.
Figure 15: (a) Minimum delay sums and (b) fre-
quency of occurrence when cross-traﬃc is TCP and
packet size of probes is 200 bytes.
(a) If the minimum delay sum condition is not satis-
ﬁed in this run, then packet sizes p1 and p2 are
decreased or increased according to the rules in
1(a) and 1(b) and the algorithm goes back to Step
1.
(b) If the minimum delay condition is satisﬁed
i. If the capacities resulting from the two runs
are within 5%, the algorithm stops, yielding
the average of the two runs as the capacity.
ii. Else, the algorithm goes back to Step 1.
Thus, the CapProbe algorithm continues to run till ca-
pacities obtained from two consecutive runs (using diﬀerent
packet sizes) are similar and the minimum delay sum con-
dition is satisﬁed in each of these runs.
7. RESULTS
In this section, we present results of simulations and In-
ternet measurements to evaluate the performance of Cap-
Probe. We compared CapProbe with two previously pro-
posed well-known capacity estimation schemes, pathchar [8]
and pathrate [4] (for a brief description, see Section 8).
We ﬁrst show results of simulations experiments to test
CapProbe. The network topology is the same 6-hop linear
path used in previous sections. The capacity is measured at
the destination. The cross-traﬃc on the path can be either
persistent (Figure 4(a)) or non-persistent (Figure 4(b)). The
diﬀerent traﬃc types we used for the cross-traﬃc were TCP,
CBR and LRD. In each set of experiments, we increased the
rate of the cross-traﬃc from 1Mbps to 4Mbps, which is the
capacity of the narrow link. The simulation time was 100
sec. The size of cross-traﬃc packets was 500 bytes. We
study below the packet pair delay sum statistics, in particu-
lar, the minima of such delays and corresponding bandwidth
estimate distributions obtained for various bandwidth esti-
mates. We show some of the results from these simulations.
Figure 15(a) shows the minimum packet pair delay sums
when packet size of probes is 200 bytes and cross-traﬃc is
path-persistent. The index in the ﬁgures shows maximum
cross-traﬃc rates2. Figure 15(b) shows the frequency distri-
bution of bandwidth estimates from packet dispersion.
We make the following observations from the graphs: the