title:Iodine: Fast Dynamic Taint Tracking Using Rollback-free Optimistic
Hybrid Analysis
author:Subarno Banerjee and
David Devecsery and
Peter M. Chen and
Satish Narayanasamy
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
Iodine: Fast Dynamic Taint Tracking Using
Rollback-free Optimistic Hybrid Analysis
Subarno Banerjee
∗
†
, David Devecsery
University of Michigan
∗
{subarno, pmchen, nsatish}@umich.edu
∗
, Peter M. Chen
∗
and Satish Narayanasamy
†
Georgia Institute of Technology
PI:EMAIL
Abstract—Dynamic information-ﬂow tracking (DIFT) is useful
for enforcing security policies, but rarely used in practice, as
it can slow down a program by an order of magnitude. Static
program analyses can be used to prove safe execution states
and elide unnecessary DIFT monitors, but the performance
improvement from these analyses is limited by their need to
maintain soundness.
In this paper, we present a novel optimistic hybrid analysis
(OHA) to signiﬁcantly reduce DIFT overhead while still guaran-
teeing sound results. It consists of a predicated whole-program
static taint analysis, which assumes likely invariants gathered
from proﬁles to dramatically improve precision. The optimized
DIFT is sound for executions in which those invariants hold true,
and recovers to a conservative DIFT for executions in which
those invariants are false. We show how to overcome the main
problem with using OHA to optimize live executions, which is
the possibility of unbounded rollbacks. We eliminate the need for
any rollback during recovery by tailoring our predicated static
analysis to eliminate only safe elisions of noop monitors. Our
tool, Iodine, reduces the overhead of DIFT for enforcing security
policies to 9%, which is 4.4× lower than that with traditional
hybrid analysis, while still being able to be run on live systems.
I.
INTRODUCTION
Dynamic information-ﬂow tracking (DIFT) [1], also re-
ferred to as taint-tracking, is a powerful method for enforcing
a security or privacy policy. It tags source data (e.g., sensitive
user input) as tainted, propagates taints through data and/or
control ﬂow, and checks if tainted data reaches sinks (e.g.,
network output). DIFT can help detect a wide range of security
attacks [2]–[8] such as SQL injection, cross-site scripting,
overwrite attacks, etc. It is also used to enforce information-
ﬂow policies that prevent sensitive information from leaking
through untrusted channels [9]–[11].
In spite of its established beneﬁts, DIFT is rarely used in
practice today, due to its prohibitive performance overhead.
For most use cases, the slowdown can be up to one to two
orders of magnitude [12]. The reason is that, in a pure dynamic
taint-tracking [12], every instruction has to be monitored to
propagate taints to the destination operand based on the source
operands’ taints. There have been several attempts to reduce
this cost by reducing tainted sources [13], by coarsening the
granularity of objects [12] and/or code-regions [4] at which
taints are tracked. But
these approaches can compromise
accuracy, and even so the overheads remain prohibitive for
production use [14]. While parallelizing DIFT can help reduce
the latency overhead [15],
it may increase the throughput
overhead due to additional parallelization costs. Recent work
[16], [17], that decouples taint tracking from the program
Iodine is used as a dye to track blood ﬂow in X-ray angiography.
Our tool tracks information ﬂow through program executions.
execution by performing symbolic taint analysis in parallel
and periodically resolving concrete taint values with control-
ﬂow information, introduces imprecision due to the symbolic
analysis. Moreover, the application might often need to wait
for the outcome of the taint analysis before it can perform
security-critical operations like releasing output.
In this paper we present a new approach to signiﬁcantly
reduce DIFT overhead using Optimistic hybrid analysis [18]
(OHA). For rigorously tested production software, execution
paths that violate an information-ﬂow policy are almost cer-
tainly either rare or impossible. For such programs, pure
dynamic taint analyses fundamentally do more work than nec-
essary. A static taint analysis can identify instructions which
cannot propagate taints to a sink [19], and DIFT monitors
for these instructions can be elided. We show that OHA can
dramatically improve the precision and scalability of static
taint analysis, and thereby reduce DIFT overhead, by assuming
program properties that are almost always true but hard to
prove statically (e.g., likely callee-set of a function pointer).
A fundamental problem with OHA is that, if its assump-
tions (likely invariants) fail during an execution,
then the
soundness of dynamic analysis for that execution is compro-
mised. To ensure soundness, prior work [18], which used OHA
for data-race detection and slicing, checked the likely invari-
ants at runtime, and when they fail, the program execution
is replayed from the beginning and analyzed with a conser-
vatively optimized dynamic analysis. While this unbounded
rollback-recovery strategy is acceptable for retrospective anal-
yses, it is not feasible for online security analysis of live
executions.
We present a novel OHA that enables efﬁcient and sound
DIFT for live executions. We address the availability problem
by completely eliminating the need for roll-back and enabling
forward recovery on a likely invariant failure. The fundamental
cause of rollbacks in an optimistic hybrid analysis is the
runtime dependence between the current monitor being elided,
and any potential future invariant violations that may affect
the soundness of that elision. We observe that in order to
construct rollback-free OHA, we must break this dependence.
In other words, any monitor elided during a program execution,
before an invariant failure, has to be proven to be unnecessary
to ensure soundness of the dynamic analysis for the entire
execution. We refer to eliding monitors satisfying this property
as safe elisions.
Our key idea is to constrain predicated static analysis, such
that it prunes a runtime monitor only if it can prove that it is a
safe elision. Given this, when a likely invariant fails at runtime,
it is sufﬁcient to simply switch to a conservatively optimized
analysis, and continue forward with the execution.
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:52)(cid:86)(cid:67)(cid:66)(cid:83)(cid:79)(cid:80)(cid:1)(cid:35)(cid:66)(cid:79)(cid:70)(cid:83)(cid:75)(cid:70)(cid:70)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:21)(cid:20)
(cid:21)(cid:26)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:28 UTC from IEEE Xplore.  Restrictions apply. 
To restrict a predicated static analysis to safe elisions, we
further observe that many analyses, particularly bug ﬁnding
and security analyses such as DIFT, often have many monitors
that do not modify any analysis’ metadata state when executed.
We call such monitors noop monitors. By constructing a
predicated static analysis that identiﬁes and elides only noop
monitors, we guarantee that any elision done by our predicated
static analysis will not have any effect on dynamic analysis
state until an invariant failure. Consequently, the soundness of
these elisions cannot depend on any potential future invariant
violations, because eliding a noop has the same effect as
executing a noop, making the noop elisions safe elisions,
and enabling forward recovery.
We construct such a predicated static analysis for DIFT that
optimizes only safe elisions as follows. We use a predicated
static forward data-ﬂow may-analysis that prunes a runtime
DIFT monitor for an instruction by proving that its source
operands are never tainted. In this forward data-ﬂow analysis,
all optimization decisions are induced from the invariant as-
sumptions using forward reasoning. Therefore, so long as the
likely invariants hold true in a program execution, it is guar-
anteed that any elided monitor for an instruction is effectively
a noop, as that instruction’s source operands are guaranteed
to be untainted. This in turn guarantees that the taint set (or
meta-data) at any program instance matches exactly that of an
unoptimized DIFT. When a program execution violates a likely
invariant, it must be detected immediately. This is trivial for
all the likely invariants we use. On detecting a likely invariant
violation, the program recovers forward by safely switching
to a conservatively optimized analysis. This requires careful
engineering to safely handle function returns after switching
the analysis versions.
It is interesting to note that it is challenging to construct
optimizations based on predicated backward dataﬂow analysis
that guarantees safe elision. For example, DIFT could be
further optimized by eliding monitors for instructions whose
destination operands never reach a sink. This requires a
backward-dataﬂow analysis from the source operands of all
sinks to the beginning of the program. A monitor elided using a
predicated version of this static analysis is not guaranteed to be
a safe elision. Because, in an execution, when a likely invariant
fails, it may invalidate the property assumed to elide a past
monitor as early as the beginning of the execution, requiring
an unbounded rollback. Thus, we employ only conservative
backward dataﬂow analysis in our system.
We implemented rollback-free optimistic hybrid DIFT us-
ing whole-program context-sensitive ﬂow-sensitive taint anal-
ysis. We evaluate our tool on security-critical applications with
realistic information ﬂow policies. We augment the Postﬁx
mail server application with information policies to check for
email integrity and privacy, and run the Nginx web server
application with detection against malicious overwrite attacks.
We compare the performance of our approach with conser-
vative hybrid and state-of-the-art full dynamic taint tracking
[20]. Dynamic taint tracking incurs 7× overhead over native
execution, and hybrid analysis-optimized taint tracking incurs
37% overhead. Our optimized taint tracking tool brings down
the overhead of dynamic taint tracking to 9%.
The contributions of this paper are as follows:
• We present a novel optimistic hybrid analysis technique
to realize low-overhead dynamic information-ﬂow track-
ing (DIFT) for live executions.
• We solve an important unresolved problem with opti-
mistic hybrid analysis, which prevents its use for live
analysis: need for unbounded roll-back when a likely
invariant fails. We prove that restricting predicated static
analysis to eliding only noop monitors guarantees meta-
data equivalence between optimistic and conservative
hybrid analyses. This property in turn enables forward
recovery when an invariant fails.
• We present a new proﬁling methodology for OHA
based on regression and beta-testing. We show that likely
invariants proﬁled using regression test suites are effec-
tive in obtaining majority of the performance beneﬁts.
• Our approach reduces the overhead of DIFT to 9%,
which is 4.4× lower than that with conservative hybrid
analysis, and 68× lower than that with pure dynamic
analysis.
II. BACKGROUND
Before discussing our analysis framework, we review the
necessary background related to taint tracking and how static
analysis is used to improve its performance.
A. Dynamic Taint Tracking
Dynamic information-ﬂow tracking (DIFT) [1] or dynamic
taint tracking instruments a program to monitor data-ﬂow from
certain program inputs (sources) to some program outputs
(sinks). Each source type is associated with a taint identiﬁer.
Each variable in an analyzed program has an associated taint
state, which is a set of taint identiﬁers, representing which
sources the variable derives its data from. A variable’s taint
state is deﬁned either by sources, or by the propagation
function when it is the destination of an instruction. Typically,
taints propagate via explicit data ﬂows (as we assume in this
paper), where a destination operand’s taint is derived from
the taints of source operands. We refer to analysis code that
propagates taints as track monitors. A few DIFT systems also
consider implicit ﬂows through control ﬂow [12]. A taint
analysis policy can also deﬁne certain operations to clear
or sanitize taint, which are common in hash or encryption
functions. Sinks are program locations where typically taint
of output values are asserted to be false. We refer to these
assertions as check monitors.
Figure 1(a) illustrates DIFT using an example. It assumes
that s is a source, and printf is a sink. Taint propagates
from s to y (line 2), and then it may or may not propagate
to z (line 4) depending on the branch outcome in line 3. If
the taint does propagate to z , it can reach out (line 5), and
then reach the sink (line 6), causing an assertion failure.
Taint analysis can be tailored to a speciﬁc application by
adjusting the taint policy. For example, information leakage is
an important concern in database and web-service applications,
where taint analysis is used to track the ﬂow of sensitive
information through program execution and prevent its leakage
through unsecured channels. Taint analysis [21] is widely used
in security analyses of programs to detect and prevent against
overwrite attacks [2]–[4], command injection attacks [5], [6],
(cid:21)(cid:26)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:28 UTC from IEEE Xplore.  Restrictions apply. 
sink: printf()
source: s
main (…) {
x = c + 3;
(cid:150)(cid:3)(cid:4666)x(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)c(cid:4667);
y = s;
y
(cid:150)(cid:3)(cid:4666)y(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)s(cid:4667);
if (p < 0){
z = c * y;
(cid:150)(cid:3)(cid:4666)z(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)c(cid:4667)(cid:3)(cid:513)(cid:3)(cid:150)(cid:3)(cid:4666)y(cid:4667);
1
2
3
4
}
out = z;
t(out) = t(z);
assert(!(cid:150)(cid:3)(cid:4666)z(cid:4667));
printf(z); }
5
6
main (…) {
x = c + 3;
y = s;
(cid:150)(cid:3)(cid:4666)y(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)s(cid:4667);
if (p < 0){
z = c * y;
(cid:150)(cid:3)(cid:4666)z(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)c(cid:4667)(cid:3)(cid:513)(cid:3)(cid:150)(cid:3)(cid:4666)y(cid:4667);
}
out = z;
t(out) = t(z);
assert(!(cid:150)(cid:3)(cid:4666)z(cid:4667));
printf(z); }
Region R is likely unreachable
!
main (…) {
x = c + 3;
y = s;
if (p < 0){
inv_check( );
z = c * y;
(cid:150)(cid:150)(cid:3)(cid:4666)z(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)c(cid:4667)(cid:3)(cid:513)(cid:3)(cid:150)(cid:3)(cid:4666)y(cid:4667);
**
}
out = z;
main (…) {
x = c + 3;
y = s;
(cid:150)(cid:3)(cid:4666)y(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)s(cid:4667);
if (p < 0){
inv_check();
z = c * y;
(cid:150)(cid:3)(cid:4666)z(cid:4667) (cid:3404)(cid:3)(cid:3)(cid:150)(cid:3)(cid:4666)c(cid:4667)(cid:3)(cid:513)(cid:3)(cid:150)(cid:3)(cid:4666)y(cid:4667);
}
out = z;
R
R
printf(z); }
printf(z); }
(a) Full dynamic analysis
(b) Conservative hybrid analysis
(c) Optimistic hybrid analysis
(d) Rollback-free OHA
Fig. 1: DIFT optimizations. Green dot indicates safe noop elisions, and ! indicates unsafe elision.
cross site scripting attacks in web applications [7], [8], and to
enforce information ﬂow policies [10]. It has also been applied
in semantic analysis of programs for program understanding
[22], testing and debugging [23], [24].
In this work, we study several custom taint policies for
preventing spam, ensuring email integrity, and detecting over-
write attacks against a web server. We also consider generic
taint policies to evaluate DIFT performance.
B. Conservative Hybrid Taint Tracking
As shown in Figure 1(a), a pure DIFT instruments virtually
all the instructions to propagate taints. This can result in an
order of magnitude or more overhead. However, this overhead
is not fundamental to enforcing a taint analysis. Because, in a
rigorously tested program, information-ﬂow leaks are rare. As
a result, many of the DIFT monitors are either not propagating
taints, or even if they do, they do no reach any sink. A sound
static data-ﬂow analysis can prove these properties and prune
these dynamic monitors [19].
A static analysis constructs a data-ﬂow model of the
program, using the same taint policy as the dynamic taint anal-
ysis. We assume that the analysis is done in the static-single
assignment (SSA) intermediate representation [25]. From this
static model, the hybrid analysis will typically optimize its
dynamic taint analysis in two ways:
• Forward Taint Analysis reasons from taint sources
forward in the program, determining if
the source
operands of an instruction may be tainted or not. If none
of the source operands may be tainted for an instruction,
then the static analysis can prune its track monitor. For
example, in Figure 1(b), the analysis can reason that
neither source operands in the instruction x = c + 3
are tainted, and therefore x will not be tainted, allowing
its monitor to be elided.
• Backward Taint Analysis reasons whether a destina-
tion operand of an instruction may reach a sink. If not,
track monitor for that instruction is elided, even if it can
be tainted. In Figure 1(b), the conservative static analysis
cannot leverage this optimization to elide any monitors,
because it cannot prove this property soundly for any of
the instructions.
Although static analysis is helpful in reducing DIFT over-
head, its effectiveness is limited in practice. The sound static
analysis used in traditional hybrid analysis must often make
overly-conservative assumptions to retain soundness for all
possible executions of a program. This inevitably includes
many infeasible program states into the analysis’s search space.
Furthermore, even an ideal static analysis that only explores
feasible program states, would still be ineffective, as most
dynamic executions cover only a small subset of common
execution states. For example, an encryption function provided
by a standard crypto library has many candidate algorithms,
but only a few of them are ever used, as many of them are dep-
recated or not preferred for use in certain systems. So, there is
a signiﬁcant gap between the states considered by sound static
analysis and those actually realized in dynamic executions.
This large discrepancy between the states that sound static
analysis considers and dynamic executions experience often
leads to highly inaccurate static analysis, and unacceptable
dynamic overheads.
III. DESIGN
We discuss a novel hybrid analysis, Iodine, to signiﬁcantly
reduce DIFT overhead based on optimistic hybrid analysis
(OHA) [18]. It supports live executions by eliminating the need
for rollback-replay.
A. Optimistic Hybrid Taint Analysis
Iodine leverages the key observation of OHA: static anal-
yses used for optimizing a dynamic analysis should ideally
consider only the states that will be realized in the analyzed
dynamic executions. By targeting expected executions, we can
signiﬁcantly improve the precision and scalability of static
analysis, and consequently optimize a dynamic analysis much
more efﬁciently than its traditional counterpart.
Figure 1(c) illustrates the untapped opportunity. If all
expected executions of this program only have non-negative
values for the variable p , the code region R is never executed.
A sound static analysis cannot assume this behavior, because
(cid:21)(cid:26)(cid:19)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:28 UTC from IEEE Xplore.  Restrictions apply. 
profiling
inputs
Predicated 
Points-to 
Analysis
Profiler
likely 
invariants
points-
to set
Monitor
Instrumenter
instrumented 
binary with 
monitors &
invariant 
checks
Monitored 
Dynamic 
Execution
Program
Taint 
Policy
Predicated 
Static Taint 
Analysis
Fig. 2: Workﬂow of optimistic hybrid taint analysis
there are legal executions where p < 0 . However, by con-
straining the static analysis to expected dynamic executions,
Iodine can reason that the variable z does not get tainted due
to y in line 4, and in turn proves that out in line 5 cannot
be tainted. Therefore, it elides track monitor for line 5, and
check monitor for the sink in line 6. Furthermore, backward
data-ﬂow analysis determines that taint of y in line 2 can
never reach any sink, and elides its track monitor. None of
these three monitors could be elided using conservative static
analysis (Figure 1(b)).
Iodine’s work-ﬂow is illustrated in Figure 2. First, a proﬁler
observes representative executions to gather a set of likely
invariants. These likely invariants are common-case dynamic
execution behaviors such as likely unreachable code, likely
callee sets, and likely unrealized call contexts [18]. These are
almost always true, but are hard to prove statically. Second,
these likely invariants are used as predicates to constrain the
§II-B,
state-space of the static taint analysis described in
resulting in a predicated static taint analysis. It
is much
more precise and scalable than a conservative sound static
taint analysis, and enables Iodine to aggressively elide DIFT
monitors. The program is instrumented with the remaining
DIFT monitors along with invariant checks.
In most dynamic executions, the likely invariants will hold
and the DIFT analysis will be sound. But, when the likely-
invariants do not hold, dynamic analysis may be rendered
unsound by the optimizations induced by predicated static
analysis. The dynamic analysis requires a mechanism to re-
cover from an invariant failure.
B. Problem: Rollback Recovery in OHA
When a likely invariant fails, it renders the predicated static
analysis’ optimizations unsound. As we use whole-program
static analysis, at runtime it is non-trivial to determine the
effect of a current invariant failure on the soundness of an
elided monitor in the past. For example, in Figure 1 (c), if
the likely unreachable code invariant (R) is violated in line 3,
it would render the past elision of monitor for line 2 to be
unsound.
Past work [18] conservatively addressed this problem by
completely redoing the dynamic analysis by replaying the
program execution from the beginning using the conservatively
optimized dynamic analysis. Since invariants rarely fail, this