## 沉浸式学习PostgreSQL|PolarDB 1: 短视频推荐去重、UV统计分析场景    
### 作者      
digoal      
### 日期      
2023-08-19    
### 标签      
PostgreSQL , PolarDB , 数据库 , 教学   
----      
## 背景     
非常欢迎数据库用户提出场景给我, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 一起来建设沉浸式数据库学习教学素材库, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.  
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31)来完成.    
如果你本地有docker环境也可以把镜像拉到本地来做实验:  
x86_64机器使用以下docker image:  
- [《amd64 , 使用Dockerfile+docker build制作PolarDB | PostgreSQL 开源docker镜像, 集成大量插件方便学习, 并推送到阿里云镜像服务》](../202307/20230710_03.md)  
Apple Chip机器使用以下docker image:  
- [《arm64 , 使用Dockerfile+docker build制作PolarDB | PostgreSQL 开源docker镜像, 集成大量插件方便学习, 并推送到阿里云镜像服务》](../202308/20230814_02.md)  
## 业务场景介绍1: UV统计分析场景  
例如有一个网站, 业务会记录用户每一次点击行为, 每一次点击一条记录.   
基于以上明细数据, 需要做如下分析(允许近似值, 要求高性能):   
- 按地域的UV/天  
- 按地域的相比前一天新增的访问人数(昨天没访问, 今天访问了的)  
- 整体UV/天  
- 整体相比前一天新增的访问人数(昨天没访问, 今天访问了的)  
- 按地域的UV/周  
- 按地域的相比前一周新增的访问人数(上周没访问, 这周访问了的)  
- 整体UV/周  
- 整体相比前一周新增的访问人数(上周没访问, 这周访问了的)  
- 按地域的UV/任意滑动周  
- 按地域的相比前一任意滑动周新增的访问人数(上个7日窗口没访问, 这个7日窗口访问了的)  
- 整体UV/任意滑动周  
- 整体相比前一任意滑动周新增的访问人数(上个7日窗口没访问, 这个7日窗口访问了的)  
### 实现和对比  
设计表结构:   
```  
drop table if exists tbl;  
create unlogged table tbl (  -- 用户行为表, 为了减轻测试负担, 使用unlogged table  
  id serial8 primary key,  -- 主键  
  uid int8,  -- 用户ID  
  rid int2,  -- 地域ID  
  cts timestamp,  -- 用户行为时间  
  info text  -- 用户行为   
);    
alter sequence tbl_id_seq cache 1000;   
```  
设计测试数据, 要求:  
- UID 取值范围1 到 2亿, 为了产生部分会员活跃的效果, UID随机值的生成按高斯分布.
    - 生成算法参考: [《生成泊松、高斯、指数、随机分布数据 - PostgreSQL 9.5 new feature - pgbench improve, gaussian (standard normal) & exponential distribution》](../201506/20150618_01.md)  
- 地域取值为 `mod(uid,200)`   
- cts为行为时间, 随机落在0-31天(2678400 秒)的范围内.   
- info字段在本实验中无意义, 随机填充, 表达用户行为.   
使用pgbench 生成用户行为原始数据1000万条. (threshold越大, 数据越集中在min,max的数学期望附. 下面设置`threshold=2.5`)    
```  
vi ~/t.sql   
\set uid random_gaussian(1, 200000000, 2.5)   
insert into tbl (uid,rid,cts,info) values (:uid, mod(:uid,200), '2023-01-01'::timestamp + (random()*2678400||' s')::interval, md5(random()::text));   
```  
```  
pgbench -M prepared -n -r -P 1 -f ~/t.sql -c 10 -j 10 -t 1000000    
```  
```  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
number of transactions per client: 1000000  
number of transactions actually processed: 10000000/10000000  
latency average = 0.064 ms  
latency stddev = 0.080 ms  
initial connection time = 19.642 ms  
tps = 155608.242432 (without initial connection time)  
```  
结果查看  
```  
postgres=# select * from tbl limit 10;  
  id  |    uid    | rid |            cts             |               info                 
------+-----------+-----+----------------------------+----------------------------------  
    1 |  97559812 |  12 | 2023-01-01 22:07:44.879178 | 4137dad1b052dcd704213e0b38735a1b  
    2 | 138253982 | 182 | 2023-01-15 02:38:03.556602 | ae3d5f27f61c8f0cd8f9864d79a693b5  
 3001 | 160494052 |  52 | 2023-01-17 23:45:29.174513 | b7972471fa02c8efa13113e96218c755  
    3 | 132545346 | 146 | 2023-01-05 22:23:11.484299 | 343f9298c26788d8bf454cfc7173a1f3  
    4 | 120769706 | 106 | 2023-01-16 21:47:52.81739  | a43a922d985b2ecc75e943af2c4c95be  
 5001 |  73660892 |  92 | 2023-01-30 05:42:50.828799 | 9515ed12769e13ff6c8f5e633860d548  
 3002 | 151242348 | 148 | 2023-01-31 07:03:15.446931 | 076c30be03af95f8a6dab1b65dd94903  
    5 | 164054658 |  58 | 2023-01-24 19:24:56.110967 | 19c46f300fe17397a108c6a2b69a7855  
 5002 | 131108032 |  32 | 2023-01-23 19:04:44.526588 | e930a9df98f90a3d47f48fe5cf1eaf9a  
    6 |  33572954 | 154 | 2023-01-16 00:47:17.449256 | 6a2ecb267b3281c91c5645b57a0b29d8  
(10 rows)  
postgres=# select count(*) from tbl;  
  count     
----------  
 10000000  
(1 row)  
postgres=# \dt+  
                                   List of relations  
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size  | Description   
--------+------+-------+----------+-------------+---------------+--------+-------------  
 public | tbl  | table | postgres | unlogged    | heap          | 965 MB |   
(1 row)  
postgres=# \di+  
                                         List of relations  
 Schema |   Name   | Type  |  Owner   | Table | Persistence | Access method |  Size  | Description   
--------+----------+-------+----------+-------+-------------+---------------+--------+-------------  
 public | tbl_pkey | index | postgres | tbl   | unlogged    | btree         | 343 MB |   
(1 row)  
postgres=# vacuum ANALYZE tbl;  
VACUUM  
```
#### 传统数据库设计和试验  
test case 1: 按地域的UV/天  
```  
select   
  rid,  
  date(cts),  
  count(distinct uid)   
from   
  tbl   
group by 1,2   
order by 1,2;  
```  
耗时: 5263.209 ms  
test case 2: 按地域的相比前一天新增的访问人数(昨天没访问, 今天访问了的)  
```  
select   
  t.d,   
  t.rid,   
  (select count(*) from   
    (select uid from tbl where date(cts)=t.d and rid=t.rid   
     except   
     select uid from tbl where date(cts)=t.d-1 and rid=t.rid) as tmp  
  ) as uv_incr   
from   
  (select date(cts) as d , rid from tbl group by 1,2) as t   
order by 1,2;  
```  
耗时: 超过 249922.704 ms   
test case 3: 整体UV/天  
```  
select   
  date(cts),  
  count(distinct uid)   
from   
  tbl   
group by 1   
order by 1;  
```  
耗时: 4824.847 ms   
test case 4: 整体相比前一天新增的访问人数(昨天没访问, 今天访问了的)  
```  
select   
  t.d,   
  (select count(*) from   
    (select uid from tbl where date(cts)=t.d   
     except   
     select uid from tbl where date(cts)=t.d-1) as tmp  
  ) as uv_incr   
from   
  (select distinct date(cts) as d from tbl) as t   
order by 1;   
```  
耗时: 41003.313 ms   
test case 5: 按地域的UV/周  
```  
select   
  EXTRACT(ISOYEAR FROM cts) as isoyear,   
  EXTRACT(week FROM cts) as week,   
  rid,  
  count(distinct uid)   
from   
  tbl   
group by 1,2,3   
order by 1,2,3;  
```  
耗时: 18654.469 ms  
test case 6: 按地域的相比前一周新增的访问人数(昨天没访问, 今天访问了的)  
```  
select   
  t.isoyear,   
  t.week,   
  t.rid,   
  (select count(*) from   
    (select uid from tbl where EXTRACT(ISOYEAR FROM cts)=t.isoyear and EXTRACT(week FROM cts)=t.week and rid=t.rid   
     except   
     select uid from tbl where EXTRACT(ISOYEAR FROM cts)=t.isoyear and EXTRACT(week FROM cts)=t.week-1 and rid=t.rid) as tmp  
  ) as uv_incr   
from   
  (select EXTRACT(ISOYEAR FROM cts) as isoyear, EXTRACT(week FROM cts) as week, rid from tbl group by 1,2,3) as t   
order by 1,2,3;  
```  
耗时: 超过 294874.983 ms  
跨年的话更加复杂, 因为年初的第一周的上一周是去年的最后一周, 写SQL时不好表达, 可以加case进行处理, 或者使用epoch来计算.   
留个作业: 有兴趣的小伙伴可以修改一下SQL, 实现跨年.   
test case 7: 整体UV/周  
```  
select   
  EXTRACT(ISOYEAR FROM cts) as isoyear,   
  EXTRACT(week FROM cts) as week,   
  count(distinct uid)   
from   
  tbl   
group by 1,2  
order by 1,2;  
```  
耗时: 10757.619 ms  
test case 8: 整体相比前一周新增的访问人数(昨天没访问, 今天访问了的)  
```  
select   
  t.isoyear,   
  t.week,   
  (select count(*) from   
    (select uid from tbl where EXTRACT(ISOYEAR FROM cts)=t.isoyear and EXTRACT(week FROM cts)=t.week   
     except   
     select uid from tbl where EXTRACT(ISOYEAR FROM cts)=t.isoyear and EXTRACT(week FROM cts)=t.week-1) as tmp  
  ) as uv_incr   
from   
  (select EXTRACT(ISOYEAR FROM cts) as isoyear, EXTRACT(week FROM cts) as week from tbl group by 1,2) as t   
order by 1,2;  
```  
耗时: 38512.642 ms  
test case 9: 按地域的UV/任意滑动周  
使用函数, 输入要对比的两个窗口变量.   
```  
create or replace function get_uv_byrid (  
  v_rid int2,   
  v_begin_cts1 date,   -- 窗口1的开始时间   
  v_end_cts1 date   -- 窗口1的结束时间   
) returns int8 as $$  
  select count(distinct uid) from tbl where rid=v_rid and cts >= v_begin_cts1 and cts < v_end_cts1;  
$$ language sql strict;  
select * from get_uv_byrid (1::int2, '2023-01-01', '2023-01-08');  
```  
耗时: 560.176 ms  
test case 10: 按地域的相比前一任意滑动周新增的访问人数(昨天没访问, 今天访问了的)  
使用函数, 输入要对比的两个窗口变量. 计算窗口2相比窗口1的新增uv.   
```  
create or replace function get_uv_incr_byrid (  
  v_rid int2,   
  v_begin_cts1 date,   -- 窗口1的开始时间   