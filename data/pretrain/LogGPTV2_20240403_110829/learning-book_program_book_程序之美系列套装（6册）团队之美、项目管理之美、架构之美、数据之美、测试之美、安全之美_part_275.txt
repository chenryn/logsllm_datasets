---
## Page 1558
图13-1：人类视觉系统善于识别出与众不同的鸭子
我们的大脑能够快速地对新事物和旧事物进行对比。我们善于进行
类比和扩展：将手套、毛衣和滑雪者关联在一起；卡通老鼠和卡通
熊是相似的：卡通熊和真正的熊相似；后两类的相似性本身很不一
样。
即使你抹去上下文，我们的视觉系统仍然非常擅长挑选模式。以图
13-2为例：你将如何把这些数据分成两组？
1557
---
## Page 1559
X2
图13-2：我们可以构建模型来区分两组数据集（见彩图47）
从添加维度和数据点开始，该任务如果由人来做，将会逐渐变得太
复杂；而计算机则可以较轻松地解析该数据。你或许可以在两个点
集之间画出一条近似曲线，但是计算机能够构建一个模型进而以最
精确的方式划分数据。
现在，看看图13-3的图表模式，它显示了三个主要制造商在2005年1
~10月这段时间的股票价格。观察以下图表，在阅读下一段前给出
答案：基于给定的模式，你预期这三只股票中哪一只股票在2006年
会涨？
你是选择了第三只股票吗？因为它看起来最后在涨。那么，你错
了。事实上，如果你选择第一只或者第二只股票，你也一样错了。
没有哪只股票会上涨，也没有哪只会下跌。实际上，这三个图表甚
至并不能表示股票价格。它们是随机生成的：垃圾数据一一可能有
人会如是说。但是一旦相信这些图表属于某个公司（在本例中指制
造业），就会产生各种各样的猜测。即使有真正的图表，除非你对
某个公司或者行业有专业知识，否则很难基于一只股票过去10个月
的业绩预测它将来的走势。
1558
---
## Page 1560
Jan'05
Apr'05
Jul'05
图13-3：三只股票（a、b和c）在2005年的业绩（见彩图48）
从噪音数据捏造故事的倾向有时被称为"叙述谬误"（nrrative
fallacy)。即使你对问题持怀疑态度（或者读得太快），当我们调查
一些拔尖的MBA学生—其中有些应聘金融业的工作——相同的问
题，他们很确定地表达对这些“股票”走势的信心。有些人说会涨，
有些人说会跌。当为这些图表补充一些随机生成的"新闻剪辑”，并
随机和某个图表放在一起时，这些学生更坚定了自己之前的预测
-这些可能显示了人们根据数据给自己讲一个好故事的能力
（Kumme，待发表）。（再看一下财经记者写的一些俏皮话：“对失
业率上升的恐惧导致道琼斯指数下跌100点。”)
如果说人类善于观察模式，则人类同时也是编造关于统计学故事的
大师。如果我们知道数据来自哪里及其涵义，这个问题就不那么严
1559
---
## Page 1561
重；如果我们面对的是来自很多数据源的证据和高赌注的产出时，
这个问题便可能会是灾难性的。
最后一个例子，在探讨问题之前，想一想你的期望。把过去的结论
应用于当前分析的倾向被称为“确认偏见"（cnfirmationbias）（Lrd等
1979）。（想一想你认识的某些人，他们只是为了选出一些语句来
进一步肯定自己的世界观而阅读。）这在处理数据时也是真实存在
的现象。观察表明，科学家更偏向于坚持过去的假设，有时在面临
看对过去假设否定的压倒性的证据面前亦是如此（Jng2006）。同
样，股票投资获得收益的投资商会根据经验舒缓地释放神经素多巴
胺，帮助他们对市场的行为做出决定（L和Repin2002）。
我们暂时假定你既不是科学家也不是股票投资商，而只是一个渺小
的调查员，对以下两个投资方案选项做出选择：
选项A：100%收益7400美元
选项B：75%可能收益10000美元，25%没有任何收益
这里没有什么技巧：你可以看到每种结果的期望效益。你会选择哪
一种呢？
现在，给出以下两种选项，你又会选择哪一种呢？
选项C：100%损失7400美元
选项D：75%可能亏损10000美元，25%没有亏损
绝大多数人选择A和D。这里出现了不对称的情况：我们往往在下
跌时更愿意冒险，而在上涨时则更保守。也就是说，稳赚比赚得更
多但可能不赚更吸引人，但是当需要支付一定资金时，我们宁愿选
择可能亏损更多可能不亏的情况。此外，这种投资组合并没有得到
最大回报：如果我们只是投机性地考虑收益和损失，我们应该选择
B+C的组合方式，因为其总期望收益是1000美元，而A+D组合方式
的总期望收益是-1000美元（也就是说，比起A+D组合方式，B+C组
合方式总期望收益高出2000美元）。
DanielKahneman和AmosTversky在20世纪70年代首先做了该实验，
它揭示了人们通常都不是以概率的方式思考问题：相反，我们想象
和每一种单一收益相关的感情收益。
1560
---
## Page 1562
事实上，在很多重要的方面，我们并不是以自己所假定的方式来处
理数据。
何时数据无法驱动
剩余部分讨论数据所不能做的，也就是说，其衡量和解释本身可以
转换数据的各种方式。本文不是一篇关于“谎言、天杀的谎言和统
计"的论文：我们知道数据可以被故意混淆；本文的重点是它如何
会被无意混淆。特别是在如下情况：
我们使用数据的方式不够准确
我们采用已知的偏见方式处理数据
展。“数据”用于表示任意从经验、观察和实验中积累的原始的事
实。
数据并非越多越好
统计是一门表示和近似的科学。我们捕获或者观察一个系统越多，
就越能真实地表示它。一篇入门性的文章往往会强调：随着你增加
样本大小，置信区间就减少，而没有丧失任何置信度。换句话说，
更多的数据可以帮助你控制误差边际（见图13-4）。
1561
---
## Page 1563
0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
图13-4：正态分布（见彩图49）
教科书上一个不错的真相。在游离世界外，需要审查一些假设。首
先，数据是如何分布的？它是否是正态的？例如，很多财务数据的
分布偏离常态。医学数据（例如，特征表达）通常更多的是呈高斯
分布，但是演变并不总是符合中心极限定理。
如果数据不是正态分布，更多的数据将不会减少你期望的误差边
际。KarlPopper描述了我们如何使用数据来回答问题上的偏态：
虽然无论有多少个与假设一致的结果都无法证明该假设是正确的，
但是只要存在一个反面结果，就可以推翻该假设。更多的数据只是
增加了必然性边际，而一个实例就可以推翻一个世纪的信仰。
其次，“误报率"(flsepositive)和"漏报率"(flsenegative)的代价相同
吗？即使你的数据是（或者看起来）是正态分布的，你对不同结果
的兴趣可能也是不对称的。
例如，无法检测到威胁生命的疾病的误差所付出的成本可能比错误
的诊断更高。在这种情况下，（通过减少“漏报率”）提高诊断正确
1562
---
## Page 1564
性的数据比通过大量数据来减少“误报率”更有用。
更多的数据并不容易
数据并不一定需要大规模。信息时代一个陈腐的“言”是：处理
10TB的数据和处理10比特的数据一样简单，而制作100亿个向导小
工具要比制作10个更昂贵。
在某些情况下，清洁和处理数据的代价不低。当需要人工肉眼校
验，比如阅读X射线或者问卷上的手写编码数据时，尤其如此。依
据"红桃皇后"RdQueen效应-，性能更好的计算机及其愈来愈强
的收集数据的能力驱动了（而且被驱动）并发新的工具和采用新的
方式来解析和使用数据。
也存在包含更多信息的认知成本。我们是选择超市的拥挤还是
“401(k)条款”（401(k)plans)I2L，研究表明随着选项的增加，决策需
要花费的时间越来越多，我们变得更可能不做任何选择而直接放
弃，而且对于自己做出的选择的满意度也降低了(lenger和Lepper
2000）。
最后，一个微妙的成本是：更多的数据会使我们变得盲目而看不到
其他的可能性，尤其当我们需要收集并整理数据时。很难想象，看
到更多的数据意味着更好地支持一个假设一—确认偏差和抽样问题
的必然结果之前已经讨论过了。
数据不会自我解释
人们做出了种种解释。你可能已经听说，相关性(crrelation)和因果
关系（cusality)是“聚头冤家"(srangebedfellows)。给定两个统计上密
切相关的变量，因果关系既可以变大也可以变小。统计学家喜欢滥
用相关性（更不用提很多博客了），比如对现代世界传统价值观的
衰落有所不满的老太太。
记者是这种统计“不满”的首要主导因素。例如，《华尔街日报》最
近的一篇文章指出(sellenbarger2008），由于婚前同居离婚的概率
更高，未婚夫妇为了提高婚后呆在一起的概率，应该避免婚前同
居。该项研究没有任何迹象表示其中存在因果关系，而这个记者基
于“数据”，给情侣们提供了她自已的建议。
1563
---
## Page 1565
用因果关系替代相关性不需要如此明显。当开展一项科学研究项目
时，存在以下假设：如果发现事物间存在相关性，就意味着它们存
在因果关系，否则其关系就是未知的。否则，为什么要去回答研究
问题呢：大规模地搜索没有因果关系的相关性属于偶然性计算，不
是科学。即使是所谓的大数据，科学依然是一个很强的由假设驱动
的过程。
经验研究的局限不是有道理的服输，只是小心谨慎地推进研究发
现，不受因果关系影响。基于数据创造故事是人之常情：研究是不
断地修改故事，使它变得合理。
仅仅是答案的数据是不好的
描述性统计信息会隐藏细节信息。例如，图13-5的图表显示了看起
来显著不同的四种分布，但其均值和方差却是相同的。描述性统计
学的两大支柱—均值和方差—提供的关于分布的信息很少
(Ascombe 1973）
12