title:BigStation: enabling scalable real-time signal processingin large
mu-mimo systems
author:Qing Yang and
Xiaoxiao Li and
Hongyi Yao and
Ji Fang and
Kun Tan and
Wenjun Hu and
Jiansong Zhang and
Yongguang Zhang
BigStation: Enabling Scalable Real-time Signal Processing
in Large MU-MIMO Systems
∗
∗
Qing Yang
Microsoft Research Asia
and CUHK
∗
Ji Fang
and BJTU
Microsoft Research Asia
Xiaoxiao Li
Microsoft Research Asia
and Tsinghua University
Kun Tan
Microsoft Research Asia
∗
Hongyi Yao
Microsoft Research Asia
and USTC
Wenjun Hu
Microsoft Research Asia
Jiansong Zhang
Microsoft Research Asia
Yongguang Zhang
Microsoft Research Asia
PI:EMAIL {v-lxiaox, v-hoya, v-fangji, kuntan, wenjun, jiazhang, ygz}@microsoft.com
ABSTRACT
Multi-user multiple-input multiple-output (MU-MIMO) is the lat-
est communication technology that promises to linearly increase
the wireless capacity by deploying more antennas on access points
(APs). However, the large number of MIMO antennas will generate
a huge amount of digital signal samples in real time. This imposes
a grand challenge on the AP design by multiplying the computa-
tion and the I/O requirements to process the digital samples. This
paper presents BigStation, a scalable architecture that enables real-
time signal processing in large-scale MIMO systems which may
have tens or hundreds of antennas. Our strategy to scale is to exten-
sively parallelize the MU-MIMO processing on many simple and
low-cost commodity computing devices. Our design can incremen-
tally support more antennas by proportionally adding more com-
puting devices. To reduce the overall processing latency, which is
a critical constraint for wireless communication, we parallelize the
MU-MIMO processing with a distributed pipeline based on its com-
putation and communication patterns. At each stage of the pipeline,
we further use data partitioning and computation partitioning to in-
crease the processing speed. As a proof of concept, we have built a
BigStation prototype based on commodity PC servers and standard
Ethernet switches. Our prototype employs 15 PC servers and can
support real-time processing of 12 software radio antennas. Our re-
sults show that the BigStation architecture is able to scale to tens to
hundreds of antennas. With 12 antennas, our BigStation prototype
can increase wireless capacity by 6.8× with a low mean process-
ing delay of 860µs. While this latency is not yet low enough for
the 802.11 MAC, it already satisﬁes the real-time requirements of
many existing wireless standards, e.g., LTE and WCDMA.
∗This work was performed while Qing Yang, Xiaoxiao Li, Hongyi
Yao, and Ji Fang were research interns at Microsoft Research Asia.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGCOMM’13, August 12–16, 2013, Hong Kong, China.
Copyright 2013 ACM 978-1-4503-2056-6/13/08 ...$15.00.
Categories and Subject Descriptors
C.2.1 [COMPUTER-COMMUNICATION NETWORKS]: Net-
work Architecture and Design—Wireless communication
General Terms
Algorithms, Design, Experimentation, Performance
Keywords
BigStation, MU-MIMO, software radio, parallel signal processing
1.
INTRODUCTION
The proliferation of mobile devices like tablets and smartphones,
along with many data-intensive applications, has created tremen-
dous demands for high-speed wireless communication. It has been
predicted that the amount of net trafﬁc carried on wireless (e.g., Wi-
Fi and 3G/4G) will exceed the amount of wired trafﬁc by 2015 [9].
To satisfy this demand, next-generation wireless networks need to
be engineered with a capacity matching their wired counterpart,
e.g., to deliver giga-bits per second of throughput to each network
user just like existing Ethernet.
One way to get more wireless capacity is to use more spectrum.
However, it is well understood that wireless spectrum is a scarce re-
source and also shared among all wireless transmitters. Therefore,
the capacity improvement from adding spectrum is still limited,
and it is hard to keep up with trafﬁc demands. A more promising
approach is to increase spectral efﬁciency with Multi-user MIMO
(MU-MIMO). MU-MIMO allows multiple users to transmit sig-
nals concurrently. With multiple antennas, MU-MIMO access point
(AP) will mesh the digital samples from all antennas together and
jointly decode data for each user (Figure 1(a)). By adding more an-
tennas to the APs, MU-MIMO has the potential to increase wireless
capacity signiﬁcantly – linearly with the number of deployed anten-
nas. Indeed, the whole wireless industry is moving in this direction.
For example, the 4G (LTE) standard [1] has deﬁned MU-MIMO op-
erations with eight antennas at the basestation, and the new Wi-Fi
standard, IEEE 802.11ac, also speciﬁes up to eight antennas to pro-
vide a 1 Gbps data rate to up to four users simultaneously. Recent
literature further suggests the possibility of even larger-scale MU-
MIMO systems with tens to hundreds of antennas to support tens of
concurrent users [16–18]. However, how to build such a powerful
AP and how well MU-MIMO may work in practice remain open
research questions.
399• With the distributed pipeline architecture, BigStation has a
low mean end-to-end processing delay of 860 µs. While this
latency may not be low enough to implement 802.11-type
MAC layer acknowledgment, it already satisﬁes the real-time
requirements for many existing wireless standards, e.g., LTE
and WCDMA.
• The capacity of a MU-MIMO system does not scale linearly
if the number of the AP antennas (M) equals the sum of client
antennas (N). The capacity may even decrease as N grows
large due to wireless channel hardening [11]. However, the
MU-MIMO capacity does scale linearly if the AP has more
antennas (M > N). With 12 antennas, our BigStation proto-
type can support 9 (M = 1.4N) concurrent transmitters and
increase the wireless capacity by 6.8× compared to a single-
antenna radio.
The rest of the paper is organized as follows: Section 2 outlines
MU-MIMO background and the system design challenges when the
number of antennas grows large. We discuss our parallelization
principles in Section 3. Section 4 presents the distributed pipeline
architecture of BigStation.
In Section 5, we apply our BigSta-
tion design principles in a system based on PC servers. Section 6
presents the implementation details and Section 7 evaluates our pro-
totype. We discuss related work in Section 8 and Section 9 con-
cludes the paper.
2. BACKGROUND
2.1 Multi-user MIMO
In a MU-MIMO system, a multi-antenna access point (AP) can
provide simultaneous links to many independent clients over the
shared wireless medium. Let M denote the number of antennas
at the AP and N the total aggregate number of antennas from all
active clients. As long as N ≤ M, the MU-MIMO system can sup-
port up to N concurrent data streams, potentially achieving N times
the capacity gain over single-antenna systems for the same channel
width. In contrast, a single-user MIMO system can serve only one
client at a time, where the capacity gain is bounded by the number
of antennas at the client, which can be far smaller than N. We as-
sume the MU-MIMO system is based on OFDM, the most popular
wireless communication technology. OFDM subdivides the chan-
nel into many narrow orthogonal subcarriers. Since each subcarrier
is narrow, its channel can be considered ﬂat fading.
In the uplink direction, all N antennas at the clients will simulta-
neously transmit symbols to the AP. These concurrent symbols add
up at each of the M receiving antennas. Let yk
i (t) denote the re-
ceived signal on antenna i on subcarrier k. Let Y k(t) be the vector
[yk
2 ,··· , yk
M ]T . We have
1 , yk
Y k(t) = H kX k(t),
2 ,··· , xk
1 , xk
where X k(t) = [xk
N ]T is the vector of transmitted
symbols, and H k is the M × N channel matrix on subcarrier k.
Hereafter, for simplicity, we may omit the superscript k when there
is no ambiguity. To decode each xj, the AP needs to ﬁrst com-
pute the pseudo-inverse of H, H + = (H∗H)−1H∗. Then, the AP
should multiply H + with the received signal vector Y (t) to obtain
the transmitted symbols X(t), as H +H = I. This operation is
called spatial demultiplexing, where receiver antennas collectively
recover each symbol stream transmitted by each sender antenna.
Finally, the AP will feed these spatial streams through a channel
decoder, e.g., Viterbi or Turbo decoder, to decode the information
bits.
(a)
(b)
Figure 1: An AP with many (MU-)MIMO antennas. (a) Tra-
ditional AP design: A central unit jointly processes all sample
streams from all antennas. (b) BigStation: Baseband sample
streams and computation are parallelized among many simple
processing units.
As the number of antennas on the AP increases, the demand for
MU-MIMO processing grows accordingly, which imposes a huge
challenge on the AP design. For example, an 802.11ac AP uses two
MIMO antennas and a 160 MHz wide channel to support a 1 Gbps
link to one user. To support 20 simultaneous 1 Gbps users, the
same AP would need to have 40 antennas 1. Collectively, these 40
antennas generate digital samples at 200 Gbps in real time, which
would require the AP to have a processing capability of multiple
trillions of operations per second for MU-MIMO decoding (Sec-
tion 2.2). This, however, is far beyond the capability of any ex-
isting single computing device (i.e., single processor or accelera-
tion chip). Therefore, a scalable MU-MIMO system should ex-
plore parallelism in signal processing and employ an architecture
to distribute the computation modules effectively among a number
of simple processing units.
In this research, we propose such a scalable architecture, named
BigStation, which extensively parallelizes the MU-MIMO process-
ing across many simple and low-cost commodity computing de-
vices (Figure 1(b)). Our design can incrementally scale out to sup-
port more MIMO antennas by proportionally adding more process-
ing units and the interconnecting bandwidth. To reduce the over-
all processing latency, which is critical for wireless communica-
tion, we parallelize the MU-MIMO processing with a distributed
pipeline based on its computation and communication patterns. At
each stage of the pipeline, we further use data partitioning and com-
putation partitioning to exploit the parallelism inside a processing
unit as well as across multiple units.
As a proof of concept, we present the design and implementa-
tion of BigStation based on commodity PC servers and standard
Ethernet switches. Besides serving as an instantiation of our scal-
able architecture, our exploration also provides a ﬁrst study toward
a large-scale software radio based centralized wireless infrastruc-
ture [2, 8], which holds the promise of reducing the cost and im-
proving the efﬁciency of existing wireless networks. We have built
a BigStation prototype with 15 PC servers connected to an 1/10Gb
Ethernet switch, and software radio front-ends supporting 12 an-
tennas. We have evaluated our prototype, and our main ﬁndings
are:
• The BigStation architecture is scalable. Our benchmarks and
analysis show that BigStation readily supports a few dozens
of antennas with current mid-range PC servers. With more
powerful high-end servers, we can scale BigStation to 100
antennas.
1As we will show later, the AP may need even more than 40 anten-
nas to avoid channel hardening [11].
Joint Processing UnitAnt0Ant1Ant MAccess PointAnt0Ant1Ant MAccess PointSimle (cid:3)Processing (cid:3)UnitSimle (cid:3)Processing (cid:3)UnitSimle (cid:3)Processing (cid:3)UnitSimle (cid:3)Processing (cid:3)UnitInterconnecting Network 400following, we study the magnitude of such computation and com-
munication requirements in a MU-MIMO AP.
Inside a high-speed digital wireless communication system, each
antenna will generate (or consume) a fairly large amount of high-
ﬁdelity digital samples. Depending on the channel width and the
physical layer (PHY) design, this number may range from 416 Mbps
(802.11g, 20 MHz channel) to 5 Gbps (802.11ac, 160 MHz chan-
nel), per antenna. If the AP has M antennas, the aggregate data rate
of digital samples will be simply multiplied by M. For example,
802.11ac uses 2 × 2 MIMO over 160 MHz of wireless spectrum to
deliver one giga-bit-per-second (Gbps) wireless link. To support 20
concurrent 1 Gbps wireless users, a MU-MIMO AP needs to have
at least 40 antennas. The aggregate volume for the sample streams
would exceed 200 Gbps.
Such a large amount of digital samples requires substantial com-
putation to process. Let R be the digital sample rate per antenna,
and W be the number of subcarriers in the wireless channel. Based
on the MU-MIMO operations described previously, we can esti-
mate the computational complexity as follows. Clearly, since we
need to support N data streams, the computation complexity for
the channel decoder is O(N R). For spatial demultiplexing, which
needs to compute a matrix vector multiplication, the complexity
is O(N M R). The complexity for channel inversion, which must
be calculated for every frame, is O(M N 2W/Tf ), where Tf is the
transmission time of a frame. To get a sense of how many cycles
are actually needed, we can do some back-of-the-envelope calcula-
tions for the above 40-antenna MU-MIMO case. According to the
802.11ac speciﬁcation, when the channel width is 160 MHz, we
have W = 468 and R ≈ 5 Gbps. We also have N = M = 40, to
support 20 concurrent 1 Gbps users. On the uplink, decoding a sin-
gle stream using a Viterbi decoder takes approximately 137 GOPS
(operations per second) by one estimate [14]. Multiplying by the
number of antennas, the channel decoding part requires approx-