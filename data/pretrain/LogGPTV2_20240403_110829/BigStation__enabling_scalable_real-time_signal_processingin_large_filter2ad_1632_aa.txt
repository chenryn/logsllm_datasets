# BigStation: Enabling Scalable Real-time Signal Processing in Large MU-MIMO Systems

## Authors
- Qing Yang, Microsoft Research Asia and CUHK
- Xiaoxiao Li, Microsoft Research Asia and Tsinghua University
- Hongyi Yao, Microsoft Research Asia and USTC
- Ji Fang, BJTU and Microsoft Research Asia
- Kun Tan, Microsoft Research Asia
- Wenjun Hu, Microsoft Research Asia
- Jiansong Zhang, Microsoft Research Asia
- Yongguang Zhang, Microsoft Research Asia

**Contact Email:** v-lxiaox, v-hoya, v-fangji, kuntan, wenjun, jiazhang, ygz@microsoft.com

## Abstract
Multi-user multiple-input multiple-output (MU-MIMO) is a cutting-edge communication technology that can linearly increase wireless capacity by deploying more antennas on access points (APs). However, the large number of MIMO antennas generates a massive amount of digital signal samples in real time, posing significant challenges for AP design, including increased computational and I/O requirements. This paper introduces BigStation, a scalable architecture that enables real-time signal processing in large-scale MU-MIMO systems with tens or hundreds of antennas. The key to scalability is extensive parallelization of MU-MIMO processing across many simple and low-cost commodity computing devices. Our design can incrementally support more antennas by proportionally adding more computing devices. To minimize overall processing latency, we employ a distributed pipeline based on computation and communication patterns, further enhanced by data and computation partitioning at each stage. As a proof of concept, we have built a BigStation prototype using 15 PC servers and standard Ethernet switches, capable of supporting 12 software radio antennas. Our results show that BigStation can scale to tens to hundreds of antennas, achieving a 6.8× increase in wireless capacity with a mean processing delay of 860 µs. While this latency is not yet suitable for 802.11 MAC, it meets the real-time requirements of existing wireless standards like LTE and WCDMA.

## 1. Introduction
The proliferation of mobile devices and data-intensive applications has created a significant demand for high-speed wireless communication. It is predicted that wireless traffic will exceed wired traffic by 2015 [9]. To meet this demand, next-generation wireless networks need to match the capacity of their wired counterparts, delivering gigabit-per-second throughput to each user, similar to existing Ethernet. One approach to increasing wireless capacity is to use more spectrum, but this is limited due to the scarcity and shared nature of wireless spectrum. A more promising approach is to increase spectral efficiency with Multi-user MIMO (MU-MIMO), which allows multiple users to transmit signals concurrently. By adding more antennas to APs, MU-MIMO can significantly increase wireless capacity, potentially linearly with the number of deployed antennas. The 4G (LTE) standard and the new Wi-Fi standard, IEEE 802.11ac, both specify MU-MIMO operations with up to eight antennas. Recent research suggests even larger-scale MU-MIMO systems with tens to hundreds of antennas, but building such powerful APs and understanding their practical performance remain open research questions.

## 2. Background
### 2.1 Multi-user MIMO
In a MU-MIMO system, a multi-antenna AP can provide simultaneous links to multiple independent clients over a shared wireless medium. Let \( M \) denote the number of antennas at the AP and \( N \) the total number of antennas from all active clients. As long as \( N \leq M \), the MU-MIMO system can support up to \( N \) concurrent data streams, potentially achieving \( N \) times the capacity gain over single-antenna systems for the same channel width. In contrast, a single-user MIMO system can serve only one client at a time, with a capacity gain bounded by the number of antennas at the client, which can be much smaller than \( N \). We assume the MU-MIMO system is based on OFDM, the most popular wireless communication technology, which subdivides the channel into many narrow orthogonal subcarriers.

In the uplink direction, all \( N \) antennas at the clients simultaneously transmit symbols to the AP. These concurrent symbols add up at each of the \( M \) receiving antennas. Let \( y^k_i(t) \) denote the received signal on antenna \( i \) on subcarrier \( k \). Let \( Y^k(t) = [y^k_1, y^k_2, \ldots, y^k_M]^T \). We have:
\[ Y^k(t) = H^k X^k(t), \]
where \( X^k(t) = [x^k_1, x^k_2, \ldots, x^k_N]^T \) is the vector of transmitted symbols, and \( H^k \) is the \( M \times N \) channel matrix on subcarrier \( k \). For simplicity, we may omit the superscript \( k \) when there is no ambiguity. To decode each \( x_j \), the AP needs to compute the pseudo-inverse of \( H \), \( H^+ = (H^*H)^{-1}H^* \). Then, the AP should multiply \( H^+ \) with the received signal vector \( Y(t) \) to obtain the transmitted symbols \( X(t) \), as \( H^+H = I \). This operation is called spatial demultiplexing, where receiver antennas collectively recover each symbol stream transmitted by each sender antenna. Finally, the AP will feed these spatial streams through a channel decoder, e.g., Viterbi or Turbo decoder, to decode the information bits.

As the number of antennas on the AP increases, the demand for MU-MIMO processing grows, imposing significant challenges on AP design. For example, an 802.11ac AP uses two MIMO antennas and a 160 MHz wide channel to support a 1 Gbps link to one user. To support 20 simultaneous 1 Gbps users, the same AP would need to have 40 antennas. Collectively, these 40 antennas generate digital samples at 200 Gbps in real time, requiring the AP to have a processing capability of multiple trillions of operations per second for MU-MIMO decoding. This is far beyond the capability of any existing single computing device. Therefore, a scalable MU-MIMO system should explore parallelism in signal processing and employ an architecture to distribute the computation modules effectively among a number of simple processing units.

## 3. Parallelization Principles
In this research, we propose a scalable architecture named BigStation, which extensively parallelizes the MU-MIMO processing across many simple and low-cost commodity computing devices. Our design can incrementally scale out to support more MIMO antennas by proportionally adding more processing units and interconnecting bandwidth. To reduce the overall processing latency, which is critical for wireless communication, we parallelize the MU-MIMO processing with a distributed pipeline based on its computation and communication patterns. At each stage of the pipeline, we further use data partitioning and computation partitioning to exploit the parallelism inside a processing unit as well as across multiple units.

## 4. Distributed Pipeline Architecture
BigStation employs a distributed pipeline architecture to handle the large volume of digital samples generated by multiple antennas. The pipeline is designed based on the computation and communication patterns of MU-MIMO processing. Each stage of the pipeline is optimized for parallel processing, and data and computation are partitioned to maximize efficiency. This architecture ensures that the processing load is balanced across the available computing resources, reducing the overall latency and enabling real-time signal processing.

## 5. System Design and Implementation
To demonstrate the feasibility of BigStation, we present the design and implementation of a prototype based on commodity PC servers and standard Ethernet switches. This prototype serves as a proof of concept and provides a first study toward a large-scale software radio-based centralized wireless infrastructure, which holds the promise of reducing the cost and improving the efficiency of existing wireless networks. We have built a BigStation prototype with 15 PC servers connected to a 1/10Gb Ethernet switch, and software radio front-ends supporting 12 antennas. Our evaluations show that BigStation is scalable and can support a few dozen antennas with current mid-range PC servers. With more powerful high-end servers, we can scale BigStation to 100 antennas.

## 6. Implementation Details
The implementation details of BigStation include the hardware setup, software architecture, and the specific algorithms used for signal processing. The hardware consists of 15 PC servers, each equipped with standard Ethernet interfaces, and a 1/10Gb Ethernet switch. The software architecture is designed to efficiently distribute the computational load across the servers, with each server handling a portion of the signal processing tasks. The algorithms used for spatial demultiplexing and channel decoding are optimized for parallel execution, ensuring that the system can handle the large volume of data in real time.

## 7. Evaluation
We have evaluated our BigStation prototype and found that it can achieve a 6.8× increase in wireless capacity with a mean processing delay of 860 µs. While this latency is not yet suitable for 802.11 MAC, it meets the real-time requirements of existing wireless standards like LTE and WCDMA. Our benchmarks and analysis show that BigStation readily supports a few dozen antennas with current mid-range PC servers. With more powerful high-end servers, we can scale BigStation to 100 antennas.

## 8. Related Work
We discuss related work in the field of MU-MIMO and large-scale wireless systems. Previous research has focused on various aspects of MU-MIMO, including theoretical capacity limits, practical implementation challenges, and the use of specialized hardware. Our work extends this research by proposing a scalable architecture that leverages commodity hardware and distributed processing to enable real-time signal processing in large-scale MU-MIMO systems.

## 9. Conclusion
In conclusion, BigStation is a scalable architecture that enables real-time signal processing in large-scale MU-MIMO systems. By extensively parallelizing the processing across many simple and low-cost commodity computing devices, BigStation can incrementally support more antennas and meet the real-time requirements of existing wireless standards. Our prototype demonstrates the feasibility of this approach and provides a foundation for future research in large-scale wireless systems.