### Participants' Decision Patterns Over Time

**Figure 4.** This figure illustrates the decision patterns over time for a subset of participants and their decisions. Each row represents the first, middle, and last 12 decisions made by each participant, allowing us to observe the varying privacy behaviors. Participants are categorized vertically into three groups: utility-concerned (top), somewhat-privacy-concerned (middle), and privacy-concerned (bottom).

### App Usage and Data Sparsity

On average, participants used 4.2 (±2.0) apps from our list of 29 apps. Our dataset includes data from 23 of these apps. The relatively small number of apps used by participants is advantageous for our analysis, as it allowed us to collect more decision data per app, thereby reducing data sparsity. **Figure 5** displays apps with more than 10 decisions and at least one participant. The three most popular apps are WhatsApp, Facebook, and Skype, with 36, 33, and 19 participants, respectively. The variation in the number of decisions is influenced not only by the number of participants per app but also by the type of app and the level of activity of each participant. For more detailed information on the number of decisions per app, refer to Table II in the Appendix.

### Data Analysis: Predicting Decisions

In this section, we present the machine learning analysis of our dataset, comparing various methods for context-aware and automatic permission decisions. Our objective is to predict users' preferred privacy levels for new permission prompts based on their past decisions and associated context.

#### A. Problem Statement

We index users by \( u \) and permission requests by \( i \) and \( j \). The decision of user \( u \) for the \( i \)-th permission request is denoted by \( y_{ui} \in \{\text{“Allow”, “Obfuscate”, “Deny”}\} \). The context of the permission request is represented by a feature vector \( x_{ui} \in X \subset \mathbb{R}^D \), and the time of the request is denoted by \( t_{ui} \). The set of all decision pairs \( \{y_{ui}, x_{ui}\} \) made before time \( t \) is denoted by \( D_{u,t} \). Our goal is to predict the user's decision \( y^* \) at a future time given a feature vector \( x^* \) and the user's past decisions \( D_{u,t} \).

We focus on two key aspects:
1. Learning to predict permission decisions.
2. Utilizing context to improve predictions.

As the amount of data per user increases, our predictions improve significantly when context is taken into account.

#### B. Baselines

We use two baselines for comparison:

1. **Static Policy Method**: This method is based on a survey completed by all participants. Decisions collected in the survey are used as fixed predictions for permission requests. This method does not learn users' preferences over time and only considers partial contextual information (i.e., app names and targeted data types). We expect this method to perform worse than dynamic methods that learn from user behavior. It approximates the current permission systems in Android 6+ and iOS.

2. **ZeroRt Method**: This baseline ignores contextual information but learns the preference function from past data. It predicts the most frequent decision made by the user until time \( t_u \) for all new decisions. Although dynamic, this method may miss contextual information and could perform worse than a context-aware method. We call this method ZeroRt, as it is an extension of the ZeroR classifier [46].

#### C. Context-Aware Method

We compare our baselines to a method that learns from user behavior and uses contextual information to make predictions. We model the privacy preferences of user \( u \) using a one-dimensional privacy-preference function \( f_u : X \rightarrow \mathbb{R} \). Given a feature vector \( x \in X \), the value of \( f_u(x) \) indicates the degree of privacy: a higher value indicates a higher desire for privacy.

The prediction is made by thresholding the preference function:
\[
y_{ui} =
\begin{cases}
\text{“Deny”}, & \text{if } \theta_1 < f_u(x_i) \\
\text{“Obfuscate”}, & \text{if } \theta_2 < f_u(x_i) \leq \theta_1 \\
\text{“Allow”}, & \text{if } f_u(x_i) \leq \theta_2
\end{cases}
\]
where \( \theta_1 \) and \( \theta_2 \) are real-valued scalars. This approach is an example of the Random Utility Model, widely used to model users' preference functions [47].

We use Bayesian linear regression (BLR) to model the preference function given the contextual information. The simplest model is a linear function:
\[
f_u(x) = \beta_{0u} + \beta_u^T x + \epsilon_{ui},
\]
where \( \beta_{0u} \in \mathbb{R} \), \( \beta_u \in \mathbb{R}^D \), and \( \epsilon_{ui} \) is the noise. Both \( \beta_u \) and the noise \( \epsilon_{ui} \) are modeled as i.i.d. Gaussian random variables.

Using Bayes' rule, we can compute the posterior distribution over predictions. However, the nonlinear function complicates this computation because it is not Gaussian. To simplify, we fix thresholds \( \theta_1 = 0.5 \) and \( \theta_2 = -0.5 \) and recode the decisions {“Allow”, “Obfuscate”, and “Deny”} as {−1, 0, +1}. This makes the decision \( y_{ui} \) Gaussian, and we can compute the posterior distribution in closed-form using Bayes' rule. The BLR model outputs a real-value \( \hat{y} \), which we threshold at \( \theta_1 \) and \( \theta_2 \) to get the discrete-valued decision.

This formulation allows us to use nonlinear models for \( f_u \) by using Gaussian Process models (GP). By changing the kernel matrix, we can obtain a variety of nonlinear models (see Chapter 2 in [48]). This approach is similar to SVM algorithms used in previous works [2], [8], but with the advantage that the GP model provides posterior probabilities for predictions, unlike SVM, which requires a two-stage procedure to avoid overfitting (see Chapter 7 in [49]).

Our approach, BLR, differs from previous works that use only two classes “allow” and “deny” [2], [8]. For a two-class problem, the ordering does not matter, but for our problem, “obfuscate” clearly requires less privacy than “deny” but more than “allow”. Therefore, the choice of a one-dimensional function is justified, although this approach can be extended to a multi-dimensional function [50]. Another alternative would be to use multi-class classification (e.g., support-vector machines, classification trees) with a cost-sensitive cost function [51]. However, BLR is a reasonable first choice for small datasets due to its simplicity.

#### D. Error Measure

To reliably compare methods, we propose the performance error measure \( E \) to evaluate the performance of a method \( M \):
\[
E_t^M(D, D_{\text{test}}) := \frac{1}{U} \sum_{u=1}^U \frac{1}{N_u} \sum_{i=1}^{N_u} L(y_{ui}, \hat{y}_{ui}|t),
\]
where \( L \) is a loss function, \( D_{\text{test}} \) is the set of test decisions \( y_{ui} \) for users \( u = 1, \ldots, U \), \( D \) is the set of past decisions and contextual information \( D_{u,t} \) for these users, \( N_u \) is the number of test decisions in \( D_{u,t} \), and \( \hat{y}_{ui}|t \) are predictions computed using \( D_{u,t} \) and the method \( M \). Note that the error measure is a random variable dependent on the choice of users in the test data and the data containing past decisions. This loss function is averaged over many users, penalizing methods that do not generalize well to multiple users. This is a better error measure than one-leave-out methods, which may show high variance across different trials.

We will use two types of loss functions. The first loss function is...