Pr
(m,m(cid:48))∼µR
[[[e]]m ∈ S]
Pr
(m,m(cid:48))∼µR
Pr
(m,m(cid:48))∼µR
Pr
(m,m(cid:48))∼µR
[[[e]]m ∈ S] + δ
[[[e]]m ∈ S ∧ m
[[[e]]m ∈ S ∧ m
m ∈ S] + e
(cid:48)
[[[e]]
[[[e]]m(cid:48) ∈ S] + e Pr
m(cid:48)∼µ2
[[[e]]m(cid:48) ∈ S] + δ + eδ
(cid:48)
= e Pr
m(cid:48)∼µ2
≤ e Pr
m(cid:48)∼µ2
(cid:48) |= Θ]
(cid:48) |= ¬Θ] + δ
(cid:48) |= ¬Θ] + δ
(m,m(cid:48))∼µR
[m
Pr
(cid:48) |= ¬Θ] + δ
[m
The ﬁrst inequality uses the bound on the distance between the wit-
nesses: ∆(µL, µR) ≤ δ. The second inequality uses the support of
µR. The ﬁnal inequality uses the fact that Prm(cid:48)∼µ2 [m(cid:48) |= ¬Θ] ≤
δ(cid:48). Since the distributions of [[e]] in µ1, µ2 satisfy (, δ + eδ(cid:48))-
differential privacy, we can again use Proposition 11 and Proposi-
tion 12 to show [UTB-R] is sound.
4.2 Propose-Test-Release
To give a small example of up-to-bad reasoning, we can prove
privacy for the Propose-Test-Release (PTR) framework [16, 48], a
classic example of privacy depending on an accuracy guarantee. The
goal is to release the answer to a function f. Rather than adding
noise directly to the answer (which may be non-numeric), PTR
estimates the distance to instability of the database d with respect
to f, denoted DistToInst f (d). This quantity measures the distance
from d to the closest database d(cid:48) such that f (d) (cid:54)= f (d(cid:48)), where
adjacent databases are at distance 1. We will use the following two
properties of DistToInst:
DistToInst f (d) > 1 → ∀d
(cid:48)
Adj(d, d
(cid:48)
) → |DistToInst f (d) − DistToInst f (d
(cid:48)
) → f (d) = f (d
(cid:48)
)| ≤ 1
(cid:48)
. (Adj(d, d
))
Since the distance itself is private information, PTR ﬁrst adds
noise to the distance, calling the noisy result dist. If it is large
enough, then PTR returns the value of f with no noise. Otherwise,
PTR returns a default value ⊥. In code:
dist $← L(DistToInst f (d));
if dist > ln(1/δ)/ + 1 then
r ← f (d);
r ← ⊥;
else
return r
The key to the privacy of PTR is that if the noise when estimating
dist is not too large, then there are two cases. If dist is large, then
there is no privacy cost for releasing the value of q when dist is
large. Otherwise, we return a default value ⊥ revealing nothing. In
either case, we just have privacy cost  from computing the noisy
distance. If the noise when estimating dist is too large (happening
with probability at most δ), we may violate privacy. So, we get an
(, δ)-private algorithm.
Theorem 14. PTR is (, δ)-differentially private for , δ > 0.
Proof sketch. To prove differential privacy, we will use the rule
[UTB-L]. We can take the event Θ to hold exactly when the noise
is not too large:
Θ (cid:44) |dist − DistToInst f (d)|  0, let:
∗ (cid:44)(cid:16)(cid:112)2n ln(1/ω)
(cid:17)

 + n(e − 1) and δ
∗ (cid:44) nδ + ω.
Then for every n ∈ N and a ∈ A, ∆∗ (f n(a), gn(a)) ≤ δ∗.
: A → B → Distr(A) be such that for every
Proof. Let hi
a ∈ A, hi(a, true) = fi(a) and hi(a, false) = gi(a). Then
∆(fi(a), gi(a)) ≤ δ iff hi(a) : B → Distr(A) is (, δ)-
differentially private for every a ∈ A.
By directly applying the advanced composition theorem of differ-
ential privacy (Theorem 7), the function hn(a) : B → Distr(A)
is (∗, δ∗)-differentially private for each a ∈ A. So for every
b, b(cid:48) ∈ B and a ∈ A, ∆∗ (hn(a, b), hn(a, b(cid:48))) ≤ δ∗. Now for
every a ∈ A, hn(a, true) = f n(a) and hn(a, false) = gn(a).
Therefore, ∆∗ (f n(a), gn(a)) ≤ δ∗.
Now that we have an advanced composition for -distance, it is
a simple matter to extend our result to approximate liftings. Note
here that we apply advanced composition not to the distributions
on A—which are related by an approximate lifting, but perhaps not
related by differential privacy—but rather to the two witnesses of
the lifting, distributions on pairs in A × A.
Proposition 16 (Advanced composition for lifting). Let fi, f(cid:48)
:
A → Distr(A) and Φ ⊆ A × A such that for every a, a(cid:48) ∈ A,
(a, a(cid:48)) |= Φ implies
i
fi(a) Φ(cid:93)(,δ) f
(cid:48)
(cid:48)
i (a
).
∗ (cid:44)(cid:16)(cid:112)2n ln(1/ω)
(cid:17)
Let n ∈ N and let ((cid:48), δ(cid:48)) be as in Theorem 7: For any ω > 0, let
∗ (cid:44) nδ + ω.
 + n(e − 1) and δ

Then for every a, a(cid:48) ∈ A such that (a, a(cid:48)) |= Φ, we have
f n(a) Φ(cid:93)(∗,δ∗) f
(cid:48)n(a
(cid:48)
).
Proof. We can map any pair (a, a(cid:48)) ∈ Φ to the left and right
witnesses of the approximate lifting. That is, there exists hl
i, hr
i :
(A × A) → Distr(A × A) such that for every (a, a(cid:48)) |= Φ:
• π1(hl
• supp(hl
• ∆(hl
i(a, a(cid:48))) = fi(a) and π2(hr
i(a, a(cid:48))) ⊆ Φ and supp(hr
i(a, a(cid:48)), hr
i (a, a(cid:48))) ≤ δ
i (a(cid:48))
i (a, a(cid:48))) = f(cid:48)
i (a, a(cid:48))) ⊆ Φ
i(a, a(cid:48)) =
Without loss of generality, we can assume that hl
i (a, a(cid:48)) = 0 if (a, a(cid:48)) |= ¬Φ. By Proposition 15, we also have
hr
∆∗ ((hl)n(a, a(cid:48)), (hr)n(a, a(cid:48))) ≤ δ∗ for every (a, a(cid:48)) |= Φ. By in-
duction on n, for every (a, a(cid:48)) |= Φ we have supp((hl)n(a, a(cid:48))) ⊆
Φ and supp((hr)n(a, a(cid:48))) ⊆ Φ, π1((hl)n(a, a(cid:48))) = f n(a) and
π2((hr)n(a, a(cid:48))) = f(cid:48)n(a(cid:48)).
We remark that our connection between the witnesses of liftings
and differential privacy allows us to directly import other composi-
tion theorems of differential privacy and their proofs without change.
For instance, Kairouz et al. [32] consider two variants of advanced
composition: an optimal variant that provably gives the best bound
on  and δ, and a heterogeneous variant that allows  and δ be dif-
ferent for the different mechanisms. In unpublished work, Rogers
et al. [43] consider a version of the advanced composition theorem
where the privacy level i and δi for the i-th mechanism may be
chosen adaptively, i.e., depending on the results from the ﬁrst i − 1
mechanisms. These composition theorems are quite tricky to prove,
involving sophisticated tools from martingale theory and hypothesis
testing. We expect that we can internalize all of these composition
theorems—and directly generalize to liftings—with minimal effort.
Based on the previous result, we introduce a new rule [AC-
WHILE] that formalizes advanced composition for loops. The sound-
ness for the new rule, which is given in Fig. 4 follows immediately
from the results of the previous section.
Theorem 17. The rule [AC-WHILE] is sound.
6.
INTERACTIVE PRIVACY
So far, we have seen how to incorporate composition theorems
and accuracy proofs into our logic. Now, we consider the last piece
needed to verify ASVbt: proving privacy for interactive algorithms.
To date, privacy has only been formally veriﬁed for algorithms where
the entire input is available in a single piece; such algorithms are
called ofﬂine algorithms. In contrast, interactive or online algorithms
accept input piece by piece, in a ﬁnite stream of input, and must
produce an intermediate outputs as inputs arrive.
The differential literature proposes several interactive algorithms;
examples include private counters [14, 21], the Sparse Vector mech-
anism, and other algorithms using these mechanisms [30]. The main
difﬁculty in verifying privacy is to model adaptivity: later inputs can
depend on earlier outputs. Indeed, differential privacy behaves well
under adaptivity, a highly useful property enabling applications to
adaptive data analysis and statistics [23].
We can view adaptive inputs as controlled by an adversary, who
receives earlier outputs and selects the next input. We draw on tech-
niques for formally verifying cryptographic proofs, which often also
involve an adversary who is trying to break the protocol. We take
inspiration from the treatment of adversaries in the logic pRHL,
an exact version of apRHL that has been used for verifying cryp-
tographic proofs [4]. Speciﬁcally, we extend apRHL with a rule
[ADV] for the adversary. The rule, displayed in Figure 5, general-
izes the adversary rule from pRHL; let Φ an assertion that does not
contain any adversary variable, and assume that the adversary A
has access to oracles O1, . . . , On and that each oracle guarantees
equality of outputs and an invariant Φ, provided it is called on equal
inputs that satisfy Φ. Then, A guarantees equality of outputs and
an invariant Φ, provided it is called on equal inputs that satisfy Φ.
Moreover, the privacy cost of calling the adversary A is equal to
k=1 qkδk(cid:105) where (cid:104)i, δi(cid:105) is the cost of calling once
the oracle Oi, and qi is the maximal number of adversarial queries
for oracle Oi. One can prove the soundness of the adversary rule by
induction on the code of the adversary.
Proposition 18. The rule [ADV] is sound.
(cid:104)(cid:80)n
k=1 qkk,(cid:80)n
Note that the proof of sparse vector only makes a restricted use of
the [ADV] rule: as A does not have access to any oracle, the pRHL
rule sufﬁces for the proof. However, the following, oracle based,
presentation of sparse vector uses the full power of the [ADV] rule:
l ← [];
u $← L/2(0);
A ← a − u;
B ← b + u;
x ← AO();
return l
where O is an oracle that takes a query and checks whether it is
between thresholds and updates a public list l, and A is allowed
to query O up to N times. In addition, we note that our new rule
can also be useful for cryptographic proofs which involve reasoning
about statistical distance.
7. OPTIMAL SUBSET COUPLING
The privacy proof of ASVbt relies on a new interval coupling
rule [LAPINT] for Laplace sampling, Fig. 6. This rule allows us to
relate a larger interval with a smaller interval nested inside. That
is, we can assume that the sample y1(cid:104)1(cid:105) lies in [p, q] if and only if
the sample y2(cid:104)2(cid:105) lies in [r, s] contained in [p, q]. The privacy cost
depends on two things: the difference in sizes of the two intervals
(q − p) − (s − r), and the size of the inner interval s − r. Roughly,
a larger inner interval and smaller outer interval yield a smaller
privacy cost.
To show that this rule is sound, we will ﬁrst prove a general
construction for liftings of the form
µ (y1 ∈ P ↔ y2 ∈ Q)(cid:93)(,0) µ
for Q ⊆ P . We call such such liftings subset couplings, since they
relate a set of outputs to a subset of outputs. Our construction applies
|= Θ ∧ e(cid:104)1(cid:105) ≤ 0 → ¬b1(cid:104)1(cid:105)