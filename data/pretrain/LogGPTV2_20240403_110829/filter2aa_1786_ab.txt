• e.g. Entry behaviours = method of entry; tools used; time of day; etc
• Property behaviours = property taken; property damaged; and so on
• These are our independent variables
• Make these dichotomous by turning into yes/no questions
• e.g. Entry behaviours: “was a screwdriver used? Was a crowbar used? 
Was a window open? Were the occupants home?” etc
PwC │ 35
Example
• Then apply a similarity coefficient
• Index of similarity
• Jaccard’s is coarse, but the measure of choice (Tonkin et al, 2008)
• x = count of behaviours present in both
• y = count of behaviours present in A but not in B
• z = inverse of y
PwC │ 36
Example
• 1 = perfect similarity
• 0 = perfect dissimilarity
• 1 coefficient per domain
• Ignores joint non-occurrences
• This is a concern when dealing with police data
• Something may have been present, but not recorded
• Less of a concern in this case
PwC │ 37
Example
• Each coefficient into direct logistic regression model
• Predictive analysis
• “To what extent does a given factor contribute to an outcome?”
• e.g. “to what extent does being a smoker contribute to the risk of having a 
heart attack?” 
• Or “does similarity in the entry behaviours domain predict whether or 
not the two burglaries are linked?”
PwC │ 38
Example
• Logistic regression tells us:
• Whether a variable is positively or negatively correlated with the outcome
• How well a given variable fits with the data
• The amount of variance that a given variable explains
• A p-value (probability of seeing this result if the null hypothesis is true)
• Run for each domain
PwC │ 39
Example
• Then forward stepwise logistic regression
• Start with one domain
• Add a domain at each step
• If this contributes to the model’s predictive power, keep it
• Else discard it
• Determines optimal combination of domains
PwC │ 40
Example
• Regression results into ROC curves
• Graphical representation
• x (probability of false positive) against y (probability of true positive)
• More reliable measure of predictive accuracy
• Based on area under the curve (AUC)
PwC │ 41
Example
• Overcomes statistical issue of using pairs from same sample 
(Tonkin et al, 2008)
• No reliance on arbitrary thresholds (Santtila et al, 2005)
• Measure of overall predictive accuracy (Swets, 1988)
PwC │ 42
Example
http://www.statisticshowto.com/wp-content/uploads/2016/08/ROC-curve.png
• Diagonal: no better than 
chance
• The higher the AUC value, the 
greater the predictive accuracy
• 0.5 – 0.7 = low
• 0.7 – 0.9 = good
• 0.9 – 1.0 = high 
• Swets, 1988
PwC │ 43
Exceptions
• Some offences are less suitable, e.g. homicide
• Bateman & Salfati, 2007; Harbort & Mokros, 2001; Sorochinski & Salfati, 2010
• Some offenders show more distinctiveness than others
• Bouhana et al, 2016
• Some behaviours less consistent, e.g. property stolen in burglaries
• Bennell & Canter, 2002; Bennell & Jones, 2005
PwC │ 44
Exceptions
• MO is a learned behaviour, and offenders develop
• Pervin, 2002; Douglas & Munn, 1992
• Offenders will change behaviours in response to events
• Donald & Canter, 2002
• Behaviours under offender’s control more likely to be stable
• Furr & Funder, 2004; Hettema & Hol, 1998
• So offences involving victim interaction may differ
• e.g. whether victim fights back / runs / shouts for help, etc
PwC │ 45
Exceptions
• Most research only applied to solved crimes
• Woodhams & Labuschagne, 2012
• Relatively small samples
• Only serial offences
• Slater et al, 2015
PwC │ 46
Experimentation
• Concept
• Research design
• Hypothesis
• Analysis
• Results
PwC │ 47
Concept
• Could CLA be applied to network intrusions?
• Specifically, where attacker has code execution
• Has never been done before
• Take granular behaviours (keystrokes, commands, etc)
• Apply CLA methodology
PwC │ 48
Research design
• Common approach historically: use police reports
• Can be inaccurate and/or incomplete
• Victim accounts may be inaccurate
• Alison et al, 2001; Canter & Alison, 2003
• Crimes are often traumatic
• Traumatic experiences can distort memories
• Freyd, 1996; Halligan et al, 2003
PwC │ 49
Research design
• Crime reports unlikely to be granular enough
• Previous studies on attacker profiling used simulations
• Honeypot?
• Needed ground truth, as CLA previously untested on this offence type
• Same IP addresses do not guarantee same individual at keyboard
• Need to also distinguish between bots and humans
• Honeypots can be fingerprinted
• Attackers may deliberately change approach
PwC │ 50
Research design
• Modified open source Python SSH keylogger (strace)
• https://github.com/NetSPI/skl
• Two VMs, exposed on the internet (SSH)
• One account per user per box
• Deliberate privesc vulnerabilities
• Plus fake data to exfiltrate
PwC │ 51
Research design
• Obtained participants
• 10x pentesters / students / amateur enthusiasts
• Asked to SSH into both machines and try to:
• Get root
• Steal data
• Cover tracks
• Poke around
• Meanwhile, I recorded all keystrokes on each VM
PwC │ 52
Hypothesis
Cyber attackers will exhibit consistent and distinctive 
behaviours whilst executing commands on compromised hosts, 
which will provide a statistically significant basis for 
distinguishing between linked and unlinked attack pairs.
PwC │ 53
Analysis
•
Split into behavioural domains, 40 behaviours each:
•
Navigation – moving through filesystem
•
Enumeration
•
Exploitation – privesc and exfil attempts
•
Also coded for 3 metadata variables:
•
Number of ms between each keystroke
•
Number of ms between each command
•
Number of backspaces (as percentage of all keystrokes)
PwC │ 54
Metadata variables
• Non-dichotomous
• Used in other CLA work, in addition to behavioural domains
• Intercrime distance (Bennell & Canter, 2002)
• Temporal proximity (Tonkin et al, 2008)
• Filippoupolitis et al, 2014: commands typed per second
• Problematic: length of command, time to complete, and time spent 
interpreting or manipulating output
PwC │ 55
Example behaviours
PwC │ 56
Analysis
• Average attack time per host: 133.34 minutes
• Average commands per host: 243
• 2 participants got root on Host A
• 1 participant got root on Host B
PwC │ 57
Similarity coefficients
• 10 attackers, 2 machines = 100 crime pairs
• Compare each attack against Host A to each attack against Host B
• 10 linked pairs, 90 unlinked pairs
• Wrote application to calculate the similarity coefficient:
• For each pair for the 3 behavioural domains
• And differences between the 3 metadata variables
• Ended up with CSV file:
• ID, paired (y/n), coefficients for each domain, differences for each metadata 
variable
PwC │ 58
Similarity coefficients - behaviours
PwC │ 59
Similarity coefficients - metadata
PwC │ 60
Logistic regression
• Imported CSV file into SPSS
• Strenuous Package for Sad Students 
• Significant Probability of Statistics-related Stress 
• Direct logistic regression for each predictor variable
• Then forward stepwise logistic regression
• Six models in total, for each domain
• Plus an optimal combination/order of all domains
PwC │ 61
Results
Here comes the slide you’ve all been waiting for…
PwC │ 62
Results
PwC │ 63
You’re too kind
(waits for applause to die down)
PwC │ 64
PwC │ 65
What does this tell us?
• Three behavioural domains can classify linked/unlinked offences 
• High level of accuracy
• Navigation: most effective predictor
• Followed by exploitation, then enumeration
• Strong positive correlation to dependent variable
• Keystroke and command interval variables not reliable predictors
• Backspace: weak negative correlation to linkage
• Results statistically significant for behavioural domains
• But not for any metadata variables
PwC │ 66
ROC curves
• Results used to build ROC curves
PwC │ 67
ROC curves
I got 0.992 
AUC, but it 
just ain’t 1
https://www.discogs.com/artist/21742-Jay-Z#images/30264081
Jay-Z
(A ROC fella)
PwC │ 68
ROC curve results
• Navigation = 0.992