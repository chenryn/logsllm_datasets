establish normal equivalence statically for real systems
but rather we will use a combination of static and dy-
namic arguments, along with assumptions about
the
target service. A combination of static and dynamic
techniques for checking equivalence may be able to
provide higher assurance without the overhead neces-
sary for full dynamic equivalence checking. Our proto-
type implementation checks equivalence dynamically at
the level of system calls, but relies on informal static
arguments to establish equivalence between them.
Implementation. To partition the address space, we
vary the location of the application data and code seg-
ments. The memory addresses used by P0 and P1 are
disjoint: any data address that is valid for P0 is invalid
for P1, and vice versa. We use a linker script to create
the two variants. Each variant loads both the code and
data segments of the variants at different starting ad-
dresses from the other variant. To ensure that their sets
of valid data memory addresses are disjoint, we use
ulimit to limit the size of P0’s data segment so it cannot
grow to overlap P1’s address space.
4.2 Instruction Set Tagging 
Whereas partitioning the memory address space dis-
rupts a class of memory corruption attacks, partitioning
the instruction set disrupts code injection attacks. There
are several possible ways to partition the instruction set.
One possibility would be to execute the variants on dif-
ferent processors, for example one variant could run on
an x86 and the other on a PowerPC. Establishing the
security of such an approach would be very difficult,
however. To obtain the normal equivalence property we
would need a way of mapping the concrete states of the
different machines to a common state. Worse, to obtain
the detection property, we would need to prove that no
string of bits that corresponds to a successful malicious
attack on one instruction set and a valid instruction se-
quence on the other instruction set. Although it is likely
that most sequences of malicious x86 instructions con-
tain an invalid PowerPC instruction, it is certainly pos-
sible for attackers to design instruction sequences that
are valid on both platforms (although we are not aware
of any programs that do this for the x86 and PowerPC,
Sjoerd Mullender and Robbert van Renesse won the
1984 International Obfuscated C Code Contest with an
entry that replaced main with an array of bytes that was
valid machine code for both the Vax and PDP-11 but
executed differently on each platform [35]).
Instead, we use a single instruction set but prepend a
variant-specific tag to all instructions. The diversifica-
tion transformation takes P and inserts the appropriate
tag bit before each instruction to produce each variant.
USENIX Association
Security ’06: 15th USENIX Security Symposium
111
in-
Detection. The variation detects any attack that
volves executing injected code, as long as the mecha-
nism used to inject code involves injecting complete
instructions. If memory is bit-addressable, an attacker
could overwrite just the part of the instruction after the
tag bit, thereby changing an existing instruction while
preserving the original tag bit. If the attacker can inject
the intended code in memory, and then have the pro-
gram execute code already in the executable that trans-
forms the injected memory (for example, by XORing
each byte with a constant that is different in the two
variants), then it is conceivable that an attacker could
execute an indirect code injection attack where the code
is transformed differently on the two variants before
executing to evade the detection property. For all
known realistic code injection attacks, neither of these
is considered a serious risk.
Normal equivalence. The only difference between the
two variants is the instruction tag, which has no effect
on instruction execution. The variants could diverge,
however, if the program examines its own instructions
and makes decisions that depend on the tag. It
is
unlikely that a non-malicious program would do this. As
with the memory partitioning, if the instruction tags are
visible to the executing process an attacker might be
able to make them execute code that depends on the
instruction tags to cause the variants to diverge before
launching the code injection attack on one of the vari-
ants. To prevent this, we need to store the tagged in-
structions in memory that is not readable to the execut-
ing process and remove the tags before those instruc-
tions reach the processor.
Implementation. To implement instruction set tagging,
we use a combination of binary rewriting before execu-
tion and software dynamic translation during execution.
We use Diablo [61, 22], a retargetable binary rewriting
framework, to insert the tags. Diablo provides mecha-
nisms for modifying an x86 binary in ELF format. We
use these to insert the appropriate variant-specific tag
before every instruction. For simplicity, we use a full
byte tag even though a single bit would suffice for two
variants. There is no need to keep the tags secret, just
that they are different; we use 10101010 and 01010101
for the A and B variant tags.
At run-time, the tags are checked and removed before
instructions reach the processor. This is done using
Strata, a software dynamic translation tool [52, 53].
Strata and other software dynamic translators [4, 11]
have demonstrated that it is possible to implement soft-
ware dynamic translation without unreasonable per-
formance penalty.
In our experiments (Section 5),
Strata’s overhead is only a few percent. The Strata VM
mediates application execution by examining and trans-
lating instructions before they execute on the host CPU.
Translated instructions are placed in the fragment cache
and then executed directly on the host CPU. Before
switching to the application code, the Strata VM uses
mprotect to protect critical data structures including the
fragment cache from being overwritten by the applica-
tion. At the end of a translated block, Strata appends
trampoline code that will switch execution back to the
Strata VM, passing in the next application PC so that
the next fragment can be translated and execution will
continue. We implement the instruction set tagging by
extending Strata’s instruction fetch module. The modi-
fied instruction fetch module checks that the fetched
instruction has the correct tag for this variant; if it does
not, a security violation is detected and execution ter-
minates. Otherwise, it removes the instruction tag be-
fore placing the actual instruction in the fragment cache.
The code executing on the host processor contains no
tags and can execute normally.
5. Framework Implementation
Implementing an N-variant system involves generating
variants such as those described in Section 4 as well as
implementing the polygrapher and monitor. The trusted
computing base comprises the polygrapher, monitor and
mechanisms used to produce the variants, as well as any
operating system functionality that is common across
the variants. An overriding constraint on our design is
that it be fully automated. Any technique that requires
manual modification of the server to create variants or
application-specific monitoring would impose too large
a deployment burden to be used widely. To enable rapid
development, our implementations are entirely in soft-
ware. Hardware implementations would have security
and performance advantages, especially in monitoring
the instruction tags. Furthermore, placing monitoring as
close as possible to the processor eliminates the risk
that an attacker can exploit a vulnerability in the moni-
toring mechanism to inject
instructions between the
enforcement mechanism and the processor.
The design space for N-variant systems implementa-
tions presents a challenging trade-off between isolation
of the variants, polygrapher, and monitor and the need
to keep the variant processes synchronized enough to
establish the normal equivalence property. The other
main design decision is the granularity of the monitor-
ing. Ideally, the complete state of each variant would be
inspected after each instruction. For performance rea-
sons, however, we can only observe aspects of the state
at key execution points.
Incomplete monitoring means
112
Security ’06: 15th USENIX Security Symposium
USENIX Association
that an attacker may be able to exploit a different vul-
nerability in the server to violate the normal equivalence
property, thereby enabling an attack that would have
otherwise been detected to be carried out without detec-
tion. For example, an attacker could exploit a race con-
dition in the server to make the variants diverge in ways
that are not detected by the monitor. Once the variants
have diverged, the attacker can construct an input that
exploits the vulnerability in one variant, but does not
produce the detected alarm state on the other variants
because they started from different states.
In our first proof-of-concept implementation, described
in Section 5.1, we emphasized isolation and executed
the variants on separate machines. This meant that any
nondeterminism in the server program or aspects of the
host state visible to the server program that differed
between the machines could be exploited by an attacker
to cause the processes to diverge and then allow a suc-
cessful attack. It also meant the monitor only observed
the outputs produced by the two variants that would be
sent over the network. This enabled certain attacks to be
detected, but meant a motivated attacker could cause the
states to diverge in ways that were not visible from the
output (such as corrupting server data) but still achieved
the attacker’s goals.
Our experience with this implementation led us to con-
clude that a general N-variant systems framework
needed closer integration of the variant processes to
prevent arbitrary divergences. We developed such a
framework as a kernel modification that allows multiple
variants to run on the same platform and normal equiva-
lence to be established at system call granularity. This
eliminates most causes of nondeterminism and improves
the performance of the overall system. Section 5.2 de-
scribes our Linux kernel implementation, and Section
5.3 presents performance results running Apache vari-
ants on our system.
5.1 Proof-of-Concept Implementation
In our proof-of-concept implementation, the variants are
isolated on separate machines and the polygrapher and
monitor are both implemented by the nvd process run-
ning on its own machine. We used our implementation
to protect both a toy server we constructed and Apache.
In order for our approach to work in practice it is essen-
tial that no manual modification to the server source
code is necessary. Hence, each server variant must exe-
cute in a context where it appears to be interacting nor-
mally with the client. We accomplish this by using di-
vert sockets to give each variant the illusion that it is
interacting directly with a normal client. To implement
the polygrapher we use ipfw, a firewall implementation
for FreeBSD [27] with a rule that redirects packets on
port 80 (HTTP server) to our nvd process which adjusts
the TCP sequence numbers to be consistent with the
variant’s numbering. Instead of sending responses di-
rectly to the client, the variant’s responses are diverted
back to nvd, which buffers the responses from all of the
variants. The responses from P0 are transmitted back to
the client only if a comparably long response is also
received from the other variants. Hence, if any variant
crashes on a client input, the response is never sent to
the client and nvd restarts the server in a known uncom-
promised state.
We tested our system by using it to protect a toy server
we constructed with a simple vulnerability and Apache,
and attempted to compromise those servers using pre-
viously known exploits as well as constructed exploits
designed to attack a particular variant. Exploit testing
does not provide any guarantees of the security of our
system, of course, but it does demonstrate that the cor-
rect behavior happens under the tested conditions to
increase our confidence in our approach and implemen-
tation. Our toy server contained a contrived format
string vulnerability, and we developed an exploit that
used that vulnerability to write to an arbitrary memory
address. The exploit could be customized to work
against either variation, but against the N-variant system
both versions would lead to one of the variants crash-
ing. The monitor detects the crash and prevents com-
promised outputs from reaching the client. We also
tested an Apache server containing a vulnerable
OpenSSL implementation (before 0.9.6e) that contained
a buffer overflow vulnerability that a remote attacker
could exploit to inject code [13]. When instruction set
tagging is used, the exploit is disrupted since it does not
contain the proper instruction tags in the injected code.
We also conducted some performance measurements on
our 2-variant system with memory address partitioning.
The average response latency for HTTP requests in-
creased from 0.2ms for the unmodified server to 2.9ms
for the 2-variant system.
The proof-of-concept implementation validated the N-
variant systems framework concept, but did not provide
a practical or secure implementation for realistic ser-
vices. Due to isolation of the variants, various non-
attack inputs could lead to divergences between the
variants caused by differences between the hosts. For
example, if the output web page includes a time stamp
or host IP address, these would differ between the vari-
ants. This means false positives could occur when the
monitor observes differences between the outputs for
USENIX Association
Security ’06: 15th USENIX Security Symposium
113
requests. Furthermore, a motivated attacker
normal
could take advantage of any of these differences to con-
struct an attack that would compromise one of the vari-
ants without leading to a detected divergence.
5.2 Kernel Implementation
The difficulties in eliminating nondeterminism and pro-
viding finer grain monitoring with the isolated imple-
mentation, as well as its performance results, convinced
us to develop a kernel implementation of the framework
by modifying the Linux 2.6.11 kernel. In this implemen-
tation, all the variants run on the same platform, along
with the polygrapher and monitor. We rely on existing
operating system mechanisms to provide isolation be-
tween the variants, which execute as separate processes.
We modified the kernel data structures to keep track of
variant processes and implemented wrappers around
system calls. These wrappers implement the polygraph-
ing functionality by wrapping input system calls so that
when both variants make the same input system call, the
actual input operation is performed once and the same
data is sent to all variants. They provide the monitoring
functionality by checking that all variants make the
same call with equivalent arguments before making the
actual system call.
This system call sharing approach removes nearly all of
the causes of nondeterminism that were problematic in
the proof-of-concept implementation. By wrapping the
system calls, we ensure that variants receive identical
results from all system calls. The remaining cause of
nondeterminism is due to scheduling differences,
in
particular in handling signals. We discuss these limita-
tions in Section 6.
In order to bring an N-variant system into execution we
created two new system calls: n_variant_fork, and
n_variant_execve. The program uses these system calls
similarly to the way a shell uses fork/execve to bring
processes into execution. The n_variant_fork system call
forks off the variants, however instead of creating a
single child process it creates one process per variant.
The variants then proceed to call n_variant_execve,
which will cause each of the variants to execute their
own diversified binary of the server. Note that our ap-
proach requires no modification of an existing binary to
execute it within an N-variant system; we simply invoke
a shell command that takes the pathnames of variant
binaries as parameters and executes n_variant_execve.
Next, we provide details on the system call wrappers
that implement the polygraphing and monitoring. The
Linux 2.6.11 kernel provides 267 system calls. We gen-
eralize them into three categories based on the type of
wrapper they need: shared system calls, reflective sys-
tem calls, and dangerous system calls.
including I/O system calls,
Shared System Calls. For system calls that interact
with external state,
the
wrapper checks that all variants make equivalent calls,
makes the actual call once, and sends the output to all
variants, copying data into each of the variants address
space if necessary. Figure 2 shows pseudocode for a
shared call, in this case the read system call. The actual
wrappers are generated using a set of preprocessor mac-
ros we developed to avoid duplicating code. The first if
statement checks whether this process is part of an
N-variant system. If not, the system call proceeds nor-
mally. Hence, a single platform can run both normal and
ssize_t sys_read(int fd, const void *buf, size_t count) {
if (!hasSibling (current)) { make system call normally } // not a variant process
else {
record that this variant process entered call
if (!inSystemCall (current->sibling)) { // this variant is first
save parameters
sleep // sibling will wake us up
get result and copy *buf data back into address space
return result;
} else if (currentSystemCall (current->sibling) == SYS_READ) { // this variant is second, sibling waiting
if (parameters match) { // what it means to “match” depends on variation and system call