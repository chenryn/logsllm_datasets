# iterate over color dictionary keys                df_temp = df[(df['correct'] == m)  & (df['Species'] == c)                sns.regplot(x = col1, y = col2,                            data = df_temp,                             fit_reg = False,                            scatter_kws={'color': colors[c]},                            marker = markers[m],                            ax = ax)        plt.xlabel(col1)        plt.ylabel(col2)        plt.title('Iris species by color')        return 'Done'    plot_shapes(iris_test, 'Petal_Width', 'Sepal_Length', markers, colors)    plot_shapes(iris_test, 'Sepal_Width', 'Sepal_Length', markers, colors)![](Images/0bacbc33dad3c65c1c8f0d86caf85930.png)savepage-src="https://static001.geekbang.org/resource/image/9e/7f/9e2c398552558a970ff1644905f6347f.png"}![](Images/a39f2775ae81d141f50b22c9fe4a66b9.png)savepage-src="https://static001.geekbang.org/resource/image/10/47/1057ba92123f1b3faa7d98b3162a4c47.png"}从显示的效果来说，分类还是挺明显的，熟悉了最基础的机器学习过程后，你可能会问，讲了半天，线性代数到底在哪里呢？关键就在KNeighborsClassifier模块上，这个模型算法的实现背后，其实用到了线性代数的核心原理。首先，因为每种鸢尾花都有四个特征：花萼的长、宽和花瓣的长、宽，所以每条数据都是四维向量。接着，量化样本之间的相似度，也就是计算向量之间的距离。而向量之间距离的运算有很多方式，比如：曼哈顿距离、欧式距离、切比雪夫距离、闵可夫斯基距离等等。其中，欧式距离你应该很熟悉了，因为我们初中都学过，在二维平面上计算两点之间的距离公式： {simplebar="init"} {.simplebar-wrapper style="margin: 0px;"} simplebar-height-auto-observer-wrapper simplebar-height-auto-observer simplebar-mask {.simplebar-offset style="right: 0px; bottom: 0px;"} {.simplebar-content-wrapper style="height: auto; overflow: hidden;"} {.simplebar-content style="padding: 0px;"} {slate-type="block-katex" ```{=html}``````{=html}``````{=html}```]{.strut style="height:0.69444em;vertical-align:0em;"}[d]{.mord.mathdefault}[]{.mspacestyle="margin-right:0.2777777777777778em;"}[=]{.mrel}[]{.mspacestyle="margin-right:0.2777777777777778em;"}]{.base}```{=html}```]{.strut style="height:1.84em;vertical-align:-0.454121em;"}```{=html}``````{=html}``````{=html}``````{=html}```]{.pstrut style="height:3.8em;"}[(]{.mopen .delimcenterstyle="top:0em;"}[[x]{.mord .mathdefault}[[[]{.pstrutstyle="height:2.7em;"}1]{.mord .mtight}]{.mord .mtight}]{.sizing.reset-size6 .size3.mtight}]{style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"}]{.vliststyle="height:0.30110799999999993em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.15em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.msupsub}]{.mord}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[−]{.mbin}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[[x]{.mord.mathdefault}[[[]{.pstrut style="height:2.7em;"}[[[2]{.mord.mtight}]{.mord .mtight}]{.sizing .reset-size6 .size3.mtight}]{style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"}]{.vliststyle="height:0.30110799999999993em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.15em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.msupsub}]{.mord}[)]{.mclose .delimcenterstyle="top:0em;"}]{.minner}[[[]{.pstrutstyle="height:2.7em;"}2]{.mord .mtight}]{.mord .mtight}]{.sizing.reset-size6 .size3.mtight}]{style="top:-3.2029em;margin-right:0.05em;"}]{.vliststyle="height:0.954008em;"}]{.vlist-r}]{.vlist-t}]{.msupsub}]{.minner}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[+]{.mbin}[]{.mspacestyle="margin-right:0.2222222222222222em;"}(]{.mopen .delimcenterstyle="top:0em;"}[[y]{.mord .mathdefaultstyle="margin-right:0.03588em;"}[[[]{.pstrutstyle="height:2.7em;"}1]{.mord .mtight}]{.mord .mtight}]{.sizing.reset-size6 .size3.mtight}]{style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"}]{.vliststyle="height:0.30110799999999993em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.15em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.msupsub}]{.mord}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[−]{.mbin}[]{.mspacestyle="margin-right:0.2222222222222222em;"}[[y]{.mord .mathdefaultstyle="margin-right:0.03588em;"}[[[]{.pstrutstyle="height:2.7em;"}2]{.mord .mtight}]{.mord .mtight}]{.sizing.reset-size6 .size3.mtight}]{style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"}]{.vliststyle="height:0.30110799999999993em;"}[​]{.vlist-s}]{.vlist-r}[[]{.vliststyle="height:0.15em;"}]{.vlist-r}]{.vlist-t.vlist-t2}]{.msupsub}]{.mord}[)]{.mclose .delimcenterstyle="top:0em;"}]{.minner}[[[]{.pstrutstyle="height:2.7em;"}2]{.mord .mtight}]{.mord .mtight}]{.sizing.reset-size6 .size3.mtight}]{style="top:-3.2029em;margin-right:0.05em;"}]{.vliststyle="height:0.954008em;"}]{.vlist-r}]{.vlist-t}]{.msupsub}]{.minner}]{.mordstyle="padding-left:1em;"}]{.svg-align style="top:-3.8em;"}```{=html}```]{.pstrut style="height:3.8em;"}```{=html}``````{=html}`````{=html}``{=html}```{=html}`````{=html}``{=html}``{=html}[​]{.vlist-s}``{=html}[[]{.vliststyle="height:0.454121em;"}]{.vlist-r}``{=html}``{=html}``{=html}``{=html}``{=html}``{=html} {.simplebar-placeholder style="width: auto; height: 72px;"} {.simplebar-track .simplebar-horizontal style="visibility: hidden;"} {.simplebar-scrollbar style="width: 0px; display: none; transform: translate3d(0px, 0px, 0px);"} {.simplebar-track .simplebar-vertical style="visibility: hidden;"} {.simplebar-scrollbar style="height: 0px; display: none;"}扩展到我们实例中的四维向量，也是同样的算法。你看，这就是线性代数在机器学习中的一种应用场景。KNN是一种监督学习算法，因为在样本集中有分类信息，通过计算距离来衡量样本之间相似度，算法简单，易于理解和实现。还有另一种机器学习算法是无监督学习，底层的数学原理其实也是差不多的，总的思想就是"物以类聚"。现在，你是不是有一种豁然开朗的感觉？终于看到了线性代数原来那么有意义，而且再简单的公式也是美的。本节小结好了，到这里导读这一讲就结束了，最后我再总结一下前面讲解的内容。这一讲我使用机器学习的监督学习算法KNN，在给定鸢尾花特征值的情况下，给鸢尾花做花种分类，让你了解机器学习最基本的过程外，能够真正了解其背后的线性代数真相，为你进入后面课程的学习提供一个感性的认知。机器学习中用到的线性代数知识点比比皆是，而且往往软件架构上看上去复杂的事情，在数学上反而很简单，希望你在学习了这门课程后，能够多从数学角度出发去构思解决问题的方案。同时，欢迎你在留言区说说自己对机器学习的理解，也可以分享一下自己的线性代数学习经历，如果你有所收获，也欢迎你把这篇文章分享给你的朋友。