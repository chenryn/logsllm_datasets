0
0
0
0
1
0
d
n
o
c
e
S
r
e
P
s
e
a
G
t
●
●
●
●
●
●
●
Us (Tie)
Us (EC2)
Frederiksen et al. (Tie)
Frederiksen et al. (EC2)
e
r
o
C
r
e
P
d
n
o
c
e
S
r
e
P
s
e
a
G
t
0
0
0
0
5
1
0
0
0
0
0
1
0
0
0
0
5
0
●
Us (Tie)
Us (EC2)
Frederiksen et al. (Tie)
Frederiksen et al. (EC2)
●
●
●
●
●
●
20
40
60
80
100
120
20
40
60
80
100
120
AES Circuit Count/Security Parameter
AES Circuit Count/Security Parameter
(a)
(b)
Figure 1: 1a) Circuit gate generation rates of [5] vs. our technique
using fully parallelizable circuit generation. 1b) Gates generation
rate per multi-processor on differing circuit sizes.
Next, we considered a number of different circuit sizes from both
Kreuter et al.[14], and circuits that we have constructed. Given our
support of PCF we can compare the same circuits as are tested by
Kreuter et al.[14]. We see in Fig. 2, the absolute performance of our
system versus that of Kreuter et al. in terms of Gates per sec, and
then in Figs. 4a and 4b the relative performance per core. Note that
performance per core is relatively stable across medium-to-large
circuit sizes. Recall that our cores are substantially more abundant,
and have lower cost and energy usage that those of Kreuter et al.
Using the metric of gates per second we ﬁnd our system, in the
case of generation, provides signiﬁcantly higher generation rates:
approximately three orders of magnitude. Our system tops out at
around 75 million gates per second, while Kreuter et al tops out at
0.35 million gates per second. We note that their system is built
for cluster computing, and so they pay a signiﬁcant overhead to
support it.
Normalized Gate Generation
Normalized Gate Generation
d
n
o
c
e
S
r
e
P
s
e
t
a
G
0
0
0
0
0
0
0
6
0
0
0
0
0
0
0
4
0
0
0
0
0
0
0
2
0
●
●●
●
●
●●
●
0
●
●
●
●
●
Us (cid:237) Tie (GPU)
Us (cid:237) EC2 (GPU)
Kreuter et al. (CPU)
5000000
10000000
15000000
20000000
25000000
Circuit Gate Count
(a) Gates Gen vs. Time
0
0
0
0
2
1
0
0
0
0
0
1
0
0
0
0
8
0
0
0
0
6
0
0
0
0
4
0
0
0
0
2
0
e
r
o
C
r
e
P
d
n
o
c
e
S
r
e
P
s
e
t
a
G
●●
●
●●●
●●●
●
0
●
Us (cid:237) Tie (GPU)
Us (cid:237) EC2 (GPU)
Kreuter et al. (CPU)
●
●
5000000
10000000
15000000
20000000
25000000
Circuit Gate Count
(b) Gate Gen Per Core Per Sec vs. Gate Count
Figure 2: Gate Generation Times comparing to Kreuter et al.[14].
8.3 GPU Evaluation
While on generation we signiﬁcantly outperform other systems,
we only comparable performance to the CPU evaluation techniques
of Kreuter et al. [15], and are slightly less efﬁcient on a than the
current implementation by Frederiksen and Nielsen [5]. Results are
given in Fig. 3.
The advantage that the cut-and-choose protocol entails to parallel
evaluation, especially on the SIMD architecture, makes it difﬁcult
for an HbC or 1BM model protocol to remain competitive. Our
evaluation problems seem to stem from two factors: i) It is difﬁcult
to keep the GPU fully engaged in processing, due to the limited
width of any level of a circuit (recall level i of a circuit must be
evaluated before level i + 1); and, ii) The lack of memory coa-
lescence in our circuit evaluation data structure seems to impose
harsh time penalties on our circuit evaluation times, due to poor
poor memory read/write performance. Memory coalescence occurs
on a GPU when all the threads in a warp access adjacent memory
locations. Problem ii) is one we believe we can partially improve
upon in future work, although we doubt it is possible to achieve
the same levels as the cut-and-choose protocol permits (discussed
below). Problem i) is inherently more problematic for the HbC and
1BM security model protocols, as one can never have guarantees
that there are k identical copies of each gate to evaluate, nor do
we have the ability to naturally multiply the width of circuits by
a factor of O(k). For naturally large circuits, there may be some
hope.
Recall core utilization rates and memory coalescence are less of
an issue for Frederiksen and Nielsen: not only are they in fact com-
puting many copies of the AES circuit in the malicious model as
we are, but their evaluation algorithm is guaranteed of this fact.
This allows them several advantages when constructing kernels to
evaluate their circuits. In particular, they can solve the two prob-
lems above. First, they can construct a kernel for evaluating each
gate in a circuit, and they can evaluate gates from lowest level to
the highest. As long as these kernels are scheduled in a leveled
order—something easily done— the GPU need never sit with low
usage while waiting on kernels to complete a level. Second, since
GPU Evaluation Comparison
GPU Evaluation Comparison
●
Us (Tie)
Us (EC2)
Frederiksen et al. (Tie)
Frederiksen et al. (EC2)
Kreuter et al. (CPU)
0
0
0
0
8
0
0
0
0
6
0
0
0
0
4
0
0
0
0
2
e
r
o
C
r
e
P
d
n
o
c
e
S
r
e
P
s
e
t
a
G
0
●● ● ● ●
●
0
2
1
0
0
1
0
8
0
6
0
4
0
2
0
●● ● ● ●
●
●
Us (Tie)
Us (EC2)
Frederiksen et al. (Tie)
Frederiksen et al. (EC2)
Kreuter et al. (CPU)
i
)