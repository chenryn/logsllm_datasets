title:Generic Semantic Security against a Kleptographic Adversary
author:Alexander Russell and
Qiang Tang and
Moti Yung and
Hong-Sheng Zhou
Generic Semantic Security against a Kleptographic Adversary
Alexander Russell(cid:42)
Qiang Tang†
Moti Yung‡
Hong-Sheng Zhou§
September 16, 2018
Abstract
Notable recent security incidents have generated intense interest in adversaries which
attempt to subvert—perhaps covertly—cryptographic algorithms. In this paper we develop
(IND-CPA) Semantically Secure encryption in this challenging setting.
This fundamental encryption primitive has been previously studied in the “kleptographic
setting,” though existing results must relax the model by introducing trusted components or
otherwise constraining the subversion power of the adversary: designing a Public Key System
that is kletographically semantically secure (with minimal trust) has remained elusive to date.
In this work, we ﬁnally achieve such systems, even when all relevant cryptographic al-
gorithms are subject to adversarial (kleptographic) subversion. To this end we exploit novel
inter-component randomized cryptographic checking techniques (with an oﬄine checking
component), combined with common and simple software engineering modular programming
techniques (applied to the system’s black box speciﬁcation level). Moreover, our methodology
yields a strong generic technique for the preservation of any semantically secure cryptosystem
when incorporated into the strong kleptographic adversary setting.
1 Introduction
Modern cryptography has been spectacularly successful, leading to cryptographic tools with re-
markable functionalities and security guarantees. Despite these advances, applying cryptographic
tools to provide robust security in practice is a notorious challenge. In particular, practical settings
often introduce threats that are not adequately reﬂected by conventional cryptographic security
modeling. In this article, we focus on one such disparity between conventional modeling and
practical application: the possibility of adversarial instantiation, subversion, or substitution of the
cryptographic algorithms themselves.
One implicit assumption in typical cryptographic security modeling is that the deployed imple-
mentations of cryptographic algorithms actually realize their “oﬃcial speciﬁcations.” In practice,
cryptographic implementations may diverge from their speciﬁcations for a variety of reasons,
including unintentional programming bugs or malicious tampering; in the kleptographic setting,
one considers the pathological possibility of fully adversarial implementations of cryptographic algo-
rithms. The goal of such an adversary is to produce implementations of cryptographic algorithms
(cid:42)University of Connecticut, PI:EMAIL
†New Jersey Institute of Technology, PI:EMAIL
‡Google Inc.& Columbia University, PI:EMAIL
§Virginia Commonwealth University, PI:EMAIL
1
which compromise security while appearing to be correct even in the face of fairly intensive testing.
(Formal models are discussed below.) We remark that the possibility of such kleptographic attacks
arise whenever a “third-party” software library or hardware device is relied upon for cryptographic
purposes.
The consequences of such attacks are rather surprising: It turns out that—in wide generality—
adversarial implementations of randomized algorithms may leak private information while producing
output that is indistinguishable from the speciﬁcation. The possibility of such threats was showcased
over two decades ago by Young and Yung [YY96, YY97]. Recently, starting with Bellare, Paterson,
and Rogaway [BPR14], the topic has received renewed formal attention [DGG+15, BH15, MS15,
DFP15, BJK15, AMV15, RTYZ15, DMSD15] motivated by startling evidence from the Snowden
revelations of past deployment of kleptographic attacks. The topic was also notably highlighted
by Rogaway’s 2015 IACR Distinguished Lecture [Rog15] calling for community-wide eﬀorts to
explore defending mechanisms. One of the most striking recent discoveries [BPR14, BJK15]
establishes that a steganographic channel can be embedded in the output of a subverted randomized
(encryption) algorithm so that secret information can be exclusively leaked to the adversary.
Such steganographic attacks can even be applied in settings where the subverted algorithms are
stateless [BJK15, RTYZ15].
As mentioned above, the kleptographic setting features an adversary who may substitute
malicious algorithms in place of intended cryptographic algorithms. The adversary’s attack,
however, is constrained by introducing a trusted party (we call it the “watchdog”) who may test
the (adversarially-provided) implementations against the speciﬁcation—this testing can provide
a measure of safety to the ﬁnal users of the implementation. The major question is whether a
combination of careful speciﬁcation and testing can preserve security despite such a powerful
adversary. The broad challenge is to rework the classical framework of cryptographic primitives
and constructions so that they provide security in this new environment. Recent eﬀorts have
partially explored the landscape and clearly identiﬁed the critical role played by randomized
algorithms in the kleptographic setting. Indeed, existing defending strategies roughly fall into two
categories:
• “Abandon” randomized algorithms and turn to deterministic counterparts, e.g., use deter-
ministic encryption with a unique ciphertext property as suggested in [BPR14, BH15, DFP15,
BJK15] for encryption schemes. Of course, key generation is a sticking point in this approach,
as it must be randomized; this has been handled by simply placing key generation outside
the subversion model (i.e., assuming honest key generation).
• Use a trusted reverse ﬁrewall to re-randomize all incoming/outgoing communication gener-
ated by the randomized algorithms [MS15, DMSD15].
While insisting on deterministic algorithms has favorable properties, it necessarily places
many central notions of security entirely out of reach: in particular, IND- security for public-key
encryptions is unattainable. Furthermore, as mentioned above, the process of key generation
is inherently stochastic; this diﬃculty has been avoided by placing key generation outside the
subversion model (or, equivalently, assuming it to be trusted). On the other hand, the ﬁrewall
model can provide general feasibility results but requires the assumption of an active trusted party
(in particular, it requires a source of trusted randomness). As the large-scale goal of the study
of kleptography is to reduce the need for trust in the underlying components, it is attractive to
understand to what extent we can eliminate such trusted randomness, algorithmic elements, etc.
2
In this paper, we address the following central questions:
1. Is it possible to generically annihilate subliminal channels in subverted randomized algorithms
without a trusted party?
2. Is it possible to achieve IND-CPA secure public-key encryption without trust in any of the component
algorithms.
We provide aﬃrmative answers to both questions.
Our principal technique (completely realizable in systems) involves a certain decomposition
of algorithms into a few functional “components,” which are tested by the watchdog and may be
independently run and “re-assembled” by the user.
The kleptographic model, in brief. The kleptographic model is meant to capture a situation where
an adversary (or “big brother” as we shall occasionally say) has the opportunity to implement
(and, indeed, “mis-implement” or subvert) our basic cryptographic tools. On the other hand, the
model also introduces a “watchdog” who will attempt to check, via black-box testing, that the
cryptographic tools have been faithfully implemented by the adversary. We imagine the adversary
to be “proud but malicious”: the adversary wishes to interfere with security, but does not wish to
be exposed as a fraud by the watchdog. The model, in brief:
1. Speciﬁcation (see also (cid:63) below.) The cryptographic primitive is speciﬁed as a tuple Πspec =
(F1spec, . . . , Fkspec) of “functionalities.” Each Fispec is either a function F : {0,1}∗ → {0,1}∗
(which
speciﬁes a deterministic algorithm) or a family of probability distributions, so that F(x) is a
probability distribution over {0,1}∗
for each x (which speciﬁes a randomized algorithm).
2. Subversion. The adversary provides us with all algorithmic and cryptographic building
blocks; that is, the adversary provides us with an “implementation” (F1impl, . . . , Fkimpl) for each
of the functionalities Fiimpl. Observe that the adversary may provide even the algorithms
that generate randomness and random objects such as keys. Of course, in general the
implementations may disagree with the speciﬁcation, which can provide the adversary a
novel avenue to attack the primitive.
3. Testing; the watchdog. The algorithmic and cryptographic building blocks are then sent to
trusted testing facility, the watchdog. The watchdog is aware of the oﬃcial speciﬁcation, and
may query the adversary’s implementations (treating them as block-boxes) in an attempt to
detect disagreements between the implementations and the speciﬁcations.
4. The security game. Assuming that the watchdog is satisﬁed, the implementations are pressed
into service, at which point their security is modeled by a conventional security game.
(cid:63) Remark: Decomposition and Amalgamation. We permit the designer of the cryptographic
primitive (who determines its speciﬁcation) an extra dimension of freedom which can assist
the watchdog in his veriﬁcation task: We permit the designer to functionally decompose the
primitives into a ﬁxed number of “pieces.” For example, rather than specifying a function
of interest f : X → Y , the designer may instead specify two functions h : X → W and
g : W → Y with the property that f = g ◦ h. (Thus h and g together implicitly specify f .) An
important example in our setting is specifying a randomized algorithm G(x) as a composition
dG(x,RG(1k)), where dG is a deterministic algorithm and RG is an algorithm which, given the
input 1k, produces k uniformly random bits as output. In general, the decomposition may be
arbitrary, but may only involve O(1) pieces and cannot depend on input length.
3
Our contributions. In this paper, we develop general techniques that eliminate subliminal chan-
nels introduced by adversarial implementations. We apply this general technique to construct
symmetric-key and public-key encryption schemes preserving the IND-CPA security when all the
algorithms are subject to adversarial subversion. In particular,
1. We ﬁrst deﬁne a property of “stego-freeness” by adjusting the previous models of [BPR14,
RTYZ15] to characterize whether an implementation of an algorithm can be considered to
be following its speciﬁcation in the kleptographic setting (where there is a watchdog). The
model includes several variants depending on the algorithm inputs and choices about the
decomposition. We also deﬁne a notion of “subversion resistance” for encryption schemes by
considering the kleptographic IND-CPA security game where the challengers use adversarial
implementations and the implementations are interrogated by an “oﬄine” watchdog. (See
below for formal deﬁnitions.)
2. We then consider how to defend against steganographic channel attacks by the simple
non-black-box technique of decomposition-and-amalgamation. We ﬁrst extend the attacks
of [BPR14, BJK15, DGG+15] to the setting where a public-key encryption algorithm is split
into two components: randomness generation (even when the immunization function is
modeled as a random oracle) and a deterministic component. We then demonstrate a “double-
splitting” strategy in which randomness generation is carried out by two independent com-
ponents RG0,RG1. We prove that when r0, r1 are sampled independently from RG0 and RG1,
mixing them with an immunization function Φ can indeed destroy subliminal channels in the
implementation of a wide class of randomized algorithms in the random oracle model.1 We
also consider how to achieve such results in the standard model (without a random oracle);
see Sec. D in the appendix.
3. We further apply this general technique to immunize each algorithm of a symmetric-key
(single-bit) encryption scheme, including key generation and encryption. Our construction
preserves IND-CPA security of the underlying primitive. We then focus on constructing
symmetric-key encryption schemes for large message spaces. To defend against input-trigger-
style attacks [DFP15], we allow the user to carry out one single trusted addition. We also
consider correctness in the kleptographic setting and draw connections to the theory of
self-correcting programs. These techniques can be applied directly to immunize public-key
encryption, and our construction gives the ﬁrst IND-CPA secure scheme in the kleptographic
setting without relying on a trusted party. Finally, we discuss some further applications, which
include bypassing the impossibility results for publicly immunized outputs of a backdoored
PRG; see Sec. E in the appendix.
Related works. Kleptography, as noted, was introduced by Young and Yung [YY96, YY97]; they
primarily highlighted the possibility of subverting key generation, and left open the problem
of defending against such subversion. Recent work [RTYZ15] has made initial progress on the
problem of protecting key generation for speciﬁc cryptographic algorithms (trapdoor one-way
permutations, pseudorandom generators, and digital signature scheme). However, these techniques
are highly tuned to speciﬁc algorithms and do not remove arbitrary steganographic channels, which
is one of our main goals.
1Same as [RTYZ15], we only assume the speciﬁcation RGspec to be an random oracle, while the implementation
RGimpl can be arbitrarily subverted.
4
Several research threads have studied the kleptographic setting, developing both new attacks
and defending mechanisms. In particular, Bellare, Paterson, and Rogaway [BPR14] studied sub-
verted randomized encryption algorithms, building a steganographic channel that leaks secrets bit
by bit; they also developed defending mechanisms in the setting where key generation is honest.
Such subliminal channel attacks turn out to be the major obstacle in this area, and have been further
explored by Ateniese et al. [AMV15], Bellare et al. [BH15, BJK15], Degabriele et al. [DFP15], and
Dodis et al. [DGG+15]. A common feature of these works [BPR14, BH15, BJK15, DFP15] is to adopt
deterministic algorithms and to assume honest key generation. Additionally, these works do not
rely merely on testing: Most, in fact, require an a priori “decryptability” condition which demands
that every message encrypted using the implementation should be decrypted correctly using the
speciﬁcation. A notable exception is [DFP15]; however, they rely on a watchdog that possesses
access to the actual challenger–adversary communication transcript (including the internal state of
the challenger).
Other works [MS15, DMSD15] considered defending mechanisms with a “reverse ﬁrewall”
that is trusted to generate good randomness and can “re-randomize” incoming and outgoing
communication. This model is attractive as it may permit quite general feasibility results; on the
other hand, it introduces another trusted party (and source of trusted randomness).
In contrast to previous work, our goal is to develop CPA-secure encryption in a much stricter
model that does not require strong watchdogs, clean keys, trusted randomness, or decryptability
assumptions.
2 Deﬁnitions and Models
The adversary in kleptographic settings is “proud-but-malicious”: The adversary prefers subversion
to be “under the radar” of any possible detection; on the other hand, she still wishes exploit her
power of subversion to violate security. As explained in the introduction, our central focus will
be the challenge of generically destroying subliminal channels which may have been adversarially
embedded in a subverted algorithm. We brieﬂy recall the notion of a subliminal channel to set the
stage for the basic deﬁnitions below.
Consider an (honest) randomized algorithm A which takes an input x and has additional access
to a “secret” bit s ∈ {0,1}. The algorithm produces a random output y, which we assume leaks no
information about s. A fundamental result in steganography [Sim83, Sim86, HLv02] asserts that
is is possible to construct a subverted algorithm ˜Az, whose behavior is determined by a hidden
random string z, so that
• for all inputs x and s, the distribution produced by ˜Az(x, s) (including the random selection
of z) is identical to the distribution produced by A(x, s), and hence leaks no information about
s; but,
• with knowledge of z, the output of ˜Az is highly correlated with s. In particular, an adversary
with access to z can use the output of ˜Az to infer s with high probability.
See Figs. 1a and 1b.
As mentioned above, subliminal channels are a major security obstacle in the kleptographic
setting and our main result is a method for destroying them. Intuitively, to achieve this goal, we
demand that the adversary cannot learn any extra information from the output of a subverted
5
x
s
A
y
(a) A randomized algorithm which leaks no
information about s.
x
s
˜Az
y
s
(b) A subverted algorithm depending on
a hidden random string z. Its output y is
indistinguishable from A, but with knowl-
edge of z it leaks s.
Figure 1: Embedding a subliminal channel in a randomized algorithm A.
implementation of an algorithm so long as it has passed the checking of the watchdog. We adopt
the general kleptographic deﬁnitional framework of [RTYZ15], and generalize the notion deﬁned
by the surveillance game in [BPR14] to formulate our deﬁnition of “destroying a steganographic
channel”—this deﬁnes a new notion that we call “stego-freeness.” Stego-free speciﬁcations for
algorithms will be the stepping stones to our ﬁnal construction of cryptographic primitives (e.g.,
public-key encryption) with subversion resistance.
In the deﬁnitional framework of [RTYZ15], the adversary A provides subverted implementa-
tions of the cryptographic algorithms for a particular primitive; the challenger C must then play the
(standard) cryptographic security game for the primitive with A. Of course, the challenger uses the
subverted implementations during the security game. However, to protect the challenger, there is a