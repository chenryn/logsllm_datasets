P
C
P
C
M
M
P
I
C
-
d
P
I
C
-e
n
e
c
o
d
e
c
o
d
e
G
.7
2
G
.7
2
G
S
G
S
M
M
J
P
E
J
P
E
1
-
d
e
c
o
d
e
1
-e
n
c
o
d
e
-
d
e
c
o
d
e
-e
n
c
o
d
e
G
-
d
e
c
o
d
e
G
-e
n
c
o
d
e
M
M
M
M
M
P
E
P
E
G
-e
n
G
-
d
e
c
o
d
e
e
s
a-
m
ip
e
s
a-
o
e
s
a-te
x
s
d
e
m
o
g
e
n
c
o
d
e
m
a
p
-
d
e
c
o
d
e
-e
n
c
o
d
e
P
E
P
E
P
G
P
G
R
A
G
G
W
W
I
T
-
d
I
T
e
cr
y
pt
-e
n
cr
y
pt
P
-
d
S
T
A
P
-e
n
cr
y
pt
e
cr
y
pt
Figure 7.  For each benchmark, the three Detours to which it is most sensitive. We only present the 
best-performing multiplier, I-cache, and shift Detours (“best mult”, “best ic”, “best shift”).
majority of Detouring’s fault coverage is provided by 
the  register  and  multiplier,  which  is  not  surprising 
because  they  comprise  a  large  fraction  of  the  area  of 
the OR1200 core. Of those faults that are covered, the 
register  and  multiplier  Detours  constitute  20%  and 
65%  respectively.  The  shifter,  divider,  and  bypass 
Detours  account  for  7%,  5%,  and  1%  of  the  covered 
faults, respectively. The Detours for sign-extension and 
for partial-word loads and stores cover less than 1% of 
tolerated  faults.  Some  of  these  low-coverage  Detours 
will be more relevant for cores other than the OR1200. 
For example, the operand bypassing Detours will pro-
vide  more  beneﬁt  for  VLIW  cores  (with  their  addi-
tional bypass paths), and the partial-word load Detour 
will provide more beneﬁt to cores with store buffers.
I-Cache Coverage. The  I-cache  Detour  covers  all 
faults in the I-cache except for faults in the sense amps 
and bitlines shared by all cores (>99% coverage). 
6.2.  Per-Detour Performance 
To  determine  the  performance  impact  of  each 
Detour, we used the OR1200 simulator and the Media-
Bench benchmark suite [12]. Figure
6 plots the slow-
down of each Detour with respect to the original binary 
(without  Detours)  running  on  a  fault-free  processor.1
The  graph  shows  minimum  slowdown,  maximum 
slowdown, and the three quartiles, as measured across 
all  benchmarks.  Register  and  I-Cache  Detours  are 
shown for different number of Detoured entries.
Figure
6 supports our initial intuition that Detouring 
is most useful for a CMP performing a number of dif-
ferent  tasks.  As  expected,  the  maximum  overhead  of 
each  Detour  is  quite  signiﬁcant.  If  this  were  not  the 
case, the Detoured piece of circuitry would be unneces-
sary. However, for each Detour, at least one benchmark 
shows  no  relevant  slowdown  and  at  least  half  of  the 
benchmarks have slowdowns less than 13%. 
Three non-intuitive phenomena in the results warrant 
further explanation. First, many Detours show a slight 
speed-up for some benchmarks. This phenomenon is in 
all cases due to a reduction in I-cache misses caused by 
code  reorganization  and  (for  register  Detours)  stack 
reorganization.  The  second  non-intuitive  result  is  that 
Detouring is slower for right shifts than for left shifts. 
The performance discrepancy is because left shifts by 
1.  All of our performance results include the mult_16x8 Detour, but 
not the mult_8x16 Detour, because they have identical performance.
8
Figure 8.  Throughput vs. number of errors for 
a 16-core CMP
Figure  9.  Expected  number  of  errors  that  can 
be tolerated for a given throughput target
one or two, which are very common, are optimized into 
one or two additions and thus require no multiplication. 
No  such  shortcut  exists  for  right  shifts.  Third,  shift-
based multiplication can be faster than our other multi-
plication  Detours  if  the  number  of  loop  iterations  is 
small (i.e., the second multiplicand is small).
To gain further insight into these results, we exam-
ined the sensitivity of each benchmark to each Detour. 
We studied, for each benchmark, the three Detours to 
which the benchmark is least sensitive and most sensi-
72 shows the three Detours to which each 
tive. Figure
benchmark  is  most  sensitive.  The  combination  and 
rank of Detours in the top three varies greatly between 
benchmarks. An analogous experiment to identify the 
Detours  to  which  each  benchmark  is  least  sensitive 
(graph not shown due to space constraints) shows that 
each benchmark has at least three Detours to which it is 
insensitive  (slowdown  less  than  2.6%).  From  these 
results, we conclude that (a) there is no single Detour 
that  has  a  large  detrimental  effect  on  all  benchmarks 
and (b) there is no single benchmark that is sensitive to 
all Detours. Thus, given a Detouring-aware scheduler 
and a diverse workload, the results show that Detour-
ing can salvage an otherwise useless core such that it 
can be used at almost full performance. 
6.3.  Aggregate Throughput
The ultimate goal of Detouring is to improve CMP 
throughput  in  the  presence  of  faults.  To  evaluate 
throughput,  we  have  developed  a  Monte  Carlo-based 
analytical  model  that  computes  the  estimated  perfor-
mance as a function of the number of faults present in a 
CMP.  For  this  analysis  we  assumed  faults  to  be  uni-
formly distributed. Most Detours tolerate faults by cir-
2.   Among  the  K_regs  Detours  in  Figure
16regs Detour because it has the most signiﬁcant impact. 
7,  we  consider  only  the 
cumventing  circuitry  at  a  very  coarse  grain  level; 
therefore, a small cluster of faults would have similar 
impact as a single fault in most cases.
The  results  of  our  analysis  are  shown  in  Figure
8, 
which compares four different fault tolerance conﬁgu-
rations of a 16-core CMP. The baseline system (Base) 
tolerates hard faults in a core by disabling it entirely. A 
hard fault in one of the caches is tolerated by disabling 
the affected cache, but will allow the associated core to 
continue execution. Spares is identical to the baseline 
conﬁguration, except that it assumes a single spare row 
per  cache  that  can  be  mapped  into  a  faulty  cache. 
Detour  and  Detour+Spares  show  the  results  for  the 
two  previously  described  systems  when  they  use 
Detouring techniques. 
In all conﬁgurations, throughput decreases dramati-
cally as the number of faults increases, but the use of 
Detours  can  signiﬁcantly  slow  down  the  performance 
decline. These results also show that spare cache rows 
are no substitute for Detouring, but that the two tech-
niques are complementary.
Another way of looking at this data is to determine 
how many hard faults a CMP can contain before it fails 
to  meet  a  certain  throughput  target.  This  question  is 
more relevant than pure throughput in applications that 
must  provide  a  certain  level  of  performance  (e.g.,  to 
display  a  movie  at  full  frame  rate  or  route  packets  at 
full link speed) to function properly. This data is shown 
in Figure
9. For any throughput target, the Detour con-
ﬁgurations tolerate at least twice as many errors as the 
Base system and the Detour+Spare system can still tol-
erate 60%-80% more errors than the Spare system.
7.  Conclusions and Future Work
As simple, low-power cores become more common 
in  multicore  chips,  we  will  need  to  develop  mecha-
nisms to enable them to operate correctly in the pres-
9
ence  of  hard  faults.  Because  these  cores  have  little 
hardware redundancy, fault tolerance must be provided 
by software. Detouring is an all-software solution that 
leverages  the  fault-free  hardware  to  improve  the 
throughput of CMPs with permanent faults. This per-
formance  improvement  is  achieved  by  allowing  some 
faulty cores, that would otherwise have to be disabled, 
to keep running at reduced performance. 
We believe that additional Detours, most notably for 
the data cache, could be developed to further improve 
coverage,  both  for  the  OR1200  and  for  other  simple 
processor cores, and we plan to pursue this avenue of 
research  in  our  future  work.  We  also  believe  that 
Detouring  could  achieve  better  performance—by 
increasing  fault  coverage  and  instantaneous  perfor-
mance—with the assistance of a small amount of hard-
ware. We plan to develop hardware “hooks” that will 
enable new Detours and improve the instantaneous per-
formance of other Detours.
Acknowledgments
This  material  is  based  upon  work  supported  by  the 
National  Science  Foundation  under  grant  CCR-
0444516, the National Aeronautics and Space Admin-
istration under grant NNG04GQ06G, Toyota InfoTech-
nology Center, and an equipment donation from Intel 
Corporation.  We  thank  Alvy  Lebeck  for  feedback  on 
this work. 
References
[1]  V.  Adve et al. LLVA: A Low-level Virtual Instruction 
Set  Architecture.  In  Proceedings  of  the  36th  Annual 
International 
IEEE/ACM 
on 
Microarchitecture, Dec. 2003.
Symposium 
[2]  F.  A.  Bower,  P.  G.  Shealy,  S.  Ozev,  and  D. 
J.  Sorin. 
Tolerating  Hard  Faults 
in  Microprocessor  Array 
Structures.  In  Proc.  of  the  Int’l  Conf.  on  Dependable 
Systems and Networks, pages 51–60, June 2004.
[3]  F.  A.  Bower,  D. 
J.  Sorin,  and  S.  Ozev.  A  Mechanism 
for  Online  Diagnosis 
in 
Microprocessors.  In  Proc.  of  the  38th  Annual  Int’l 
Symposium on Microarchitecture, Nov. 2005.
of  Hard  Faults 
[4]  B.  Buck and J.  K. Hollingsworth. An API for Runtime 
Code  Patching.  The  International  Journal  of  High 
Performance Computing Applications, 14(4):317–329, 
Winter 2000.
[5]  Cisco  Systems.  Cisco  Carrier  Router  System. 
http://www.cisco.com/application/pdf/en/us/guest/prod
ucts/ps5763/c1031/cdcco%  nt_0900aecd800f8118.pdf, 
Oct. 2006.
[6]  R.  P.  Colwell.  The  Pentium  Chronicles:  The  People, 
Passion, and Politics Behind Intel’s Landmark Chips. 
IEEE Computer Society Press, 2006.
[7]  K.  Constantinides, 
O.  Mutlu, 
T.  Austin, 
and 
10
V.  Bertacco.  Software-Based  Online  Detection  of 
Hardware Defects: Mechanisms, Architectural Support, 
and Evaluation. In Proc. of the 40th Annual Int’l Symp.
on Microarchitecture, pages 97–108, Dec. 2007.
  Gschwind  et  al.  Synergistic  Processing  in  Cell’s 
Multicore  Architecture.  IEEE  Micro,  26(2):10–24, 
Mar/Apr 2006.
[8]  M.
[9]  P.  Kongetira,  K.  Aingaran,  and  K.  Olukotun.  Niagara: 
A  32-way  Multithreaded  SPARC  Processor.  IEEE 
Micro, 25(2):21–29, Mar/Apr 2005.
[10]  D.  Lampret.  OpenRISC  1200  IP  Core  Specification, 
Rev. 0.7. http://www.opencores.org, Sept. 2001.
[11]  J.  R. Larus and E.  Schnarr. EEL: Machine-Independent 
Executable  Editing.  In  Proceedings  of  the  SIGPLAN 
1995  Conference  on  Programming  Language  Design 
and Implementation, pages 291–300, June 1995.
[12]  C.  Lee,  M.
Potkonjak,  and  W.
  H.  Mangione-Smith. 
MediaBench: A Tool for Evaluating and Synthesizing 
Multimedia and Communications Systems. In Proc. of 
the  30th  Annual  IEEE/ACM  International  Symposium 
on Microarchitecture, pages 330–335, Dec. 1997.
[13]  E.  McLellan.  The  Alpha  AXP  Architecture  and  the 
21064 Processor. IEEE Micro, 13(3):36–47, May/June 
1993.
[14]  J.  Montrym and H.  Moreton. The GeForce 6800. IEEE 
Micro, 25:41–51, March/April 2005.
[15]  N.  Oh,  P.  P.  Shirvani,  and  E. 
J.  McCluskey.  Error 
Detection  by  Duplicated  Instructions  in  Super-Scalar 
Processors. 
IEEE  Transactions  on  Reliability, 
51(1):63–74, Mar. 2002.
Psarakis et al. Systematic Software-based Self-test 
for Pipelined Processors. In Proc. of the 43rd Design 
Automation Conference, pages 393–398, July 2006.
[16]  M.
[17]  G.  A. Reis et al. SWIFT: Software Implemented Fault 
Tolerance. In Proc. of the International Symposium on 
Code Generation and Optimization, Mar. 2005.
[18]  E.  Schuchman  and  T.  N.  Vijaykumar.  Rescue:  A 
Microarchitecture for Testability and Defect Tolerance. 
In Proc. of the 32nd Annual International Symposium 
on Computer Architecture, pages 160–171, June 2005.
[19]  P.  Shivakumar,  S.  W.  Keckler,  C.  R.  Moore,  and 
D.  Burger.  Exploiting  Microarchitectural  Redundancy 
For Defect Tolerance. In Proceedings of the 21st Int’l
Conference on Computer Design, Oct. 2003.
[20]  J.  Srinivasan,  S.  V.  Adve,  P.  Bose,  and  J.  A.  Rivers. 
The  Impact  of  Technology  Scaling  on  Lifetime 
Reliability. In Proc. of the International Conference on 
Dependable Systems and Networks, June 2004.
[21]  R.  M.  Stallman  and  the  GCC  Developer
GNU 
http://gcc.gnu.org/onlinedocs/gccint.pdf, 2005.
Collection 
Compiler 
Community. 
Internals. 
[22]  G.  Xenoulis  et  al.  On-line  Periodic  Self-Testing  of 
High-Speed  Floating-Point  Units  in  Microprocessors. 
In Proc. 22nd IEEE International Symposium on Defect 
and Fault Tolerance in VLSI Systems, Sept. 2007.
[23]  T.  Y. Yeh, P.  Faloutsos, and S. 
J. Patel. ParallAX: An 
Architecture for Real-Time Physics. In Proceedings of 
the 34th Annual International Symposium on Computer 
Architecture, pages 232–243, June 2007.