the request packets traverse a legitimate Portcullis-enabled router
downstream, the attack trafﬁc is subject to regulation based on per-
computation fairness. Hence Portcullis achieves graceful perfor-
mance degradation in the face of such a partial deployment attack.
6. EVALUATION
In this section, we describe the details of our simulations. We
evaluate both simple ﬂooding DoC attacks and Portcullis-aware
DoC attacks. We also compare Portcullis with previous architec-
tures, in both full and partial deployments.
Internet Scale Simulation
6.1
We simulate the beneﬁts of the per-computation fairness pro-
vided by Portcullis using an Internet-scale simulation. The topol-
ogy for this simulation is derived from CAIDA Skitter probe re-
sults [7], which record router-level topology. The Skitter map forms
a tree rooted at the trace source (a root DNS server) and spans out
to over 174,000 networks scattered largely uniformly across the In-
ternet. We use the identical topology, but reverse the direction of
packet ﬂow such that packets from clients (both legitimate and at-
tackers) ﬂow up the branches of the tree to the root, which in our
scenario is the victim. We make the conservative assumption that
a single link connects the victim to the rest of the network. Multi-
ple links would increase the difﬁculty of a DDoS attack, since an
attacker would have to ﬂood all of the links to deny service to le-
gitimate clients. This realistic topology is essential to evaluate the
performance of TVA [32], which depends on topology to help it
differentiate legitimate trafﬁc from attack trafﬁc.
Since the Skitter map does not include bandwidth measurements,
our simulations employ a simple bandwidth model in which the
senders’ uplinks have one tenth the capacity of the victim’s network
connection, while the rest of the network links have 10 times that
of the victim’s network connection. Thus, each host has a small
link connecting it to a well provisioned core that narrows down to
reach the victim. Experiments using a uniform bandwidth model
produced similar results, though Portcullis performed even better;
space constraints prevent us from including these results.
To make these values concrete, sender’s uplinks have a total ca-
pacity of 20 Mbps, the victim’s link to the rest of the network has a
total capacity of 200 Mbps, and the core links are 2 Gbps. Assum-
ing each request packet is approximately 1000 bits, and each link
reserves 5% of its capacity for request trafﬁc, an attacker can ﬂood
its uplink’s request capacity by sending requests at 1 Mbps.
In our experiments, we measure the time each of 1,000 legiti-
mate clients requires to establish a capability. We vary the number
of attackers from 1,000 up to 20,000 (thus allowing the attackers to
signiﬁcantly outnumber the legitimate senders). For the Random,
TVA, speak-up, and Portcullis-Flooder scenarios, attackers send re-
quests at the full request capacity of their uplink. Both legitimate
clients and attackers are placed randomly in destination networks.
4Flooding a link controlled by the router itself is essentially the
same as dropping packets; hence it is out of the scope of this paper.
y
t
i
l
i
b
a
p
a
C
a
h
s
i
l
b
a
t
s
E
o
t
]
s
[
e
m
T
g
v
A
i
8
6
4
2
0
0
2.5 Mbps
5.0 Mbps
7.5 Mbps
10 Mbps
20 Mbps
30 Mbps
Flooding
5000
Number of Attackers
10000
15000
20000
Figure 3: Portcullis Attacker Strategies. The ideal strategy is
indicated by the top line, representing an attacker who spends all
of her CPU resources to create just enough packets to saturate
the victim’s 10 Mbps link to the network. The Flooding attacker
represents a traditional attacker who simply ﬂoods the network
with legacy packets. Both the Flooding attacker and the attacks
that fail to ﬁll the victim’s link (i.e., collectively sending requests
at 2.5, 5.0 or 7.5 Mbps), have virtually no effect on capability
establishment time, even for large numbers of attackers.
The exact strategies used by both attackers and clients are varied
in the course of the experiments, and are explained in detail be-
low. For experiments involving puzzle computation, we assume all
client machines have equal computational resources. The puzzle
difﬁculty levels are adjusted such that solving a puzzle at level (cid:2) re-
quires the sender to spend 10· 2(cid:2)−1 milliseconds computing. When
testing Portcullis, legitimate senders employ the Portcullis sending
policy from Section 4.1. In other words, a legitimate sender will
compute for 10 ms, and send a request at puzzle level 1. If that re-
quest fails, the sender will compute for 20 ms and send a request at
level 2, etc., until she receives a capability. In all experiments, we
delay the time at which legitimate senders begin sending requests
until after the trafﬁc from the attackers reaches a steady-state. Thus,
legitimate senders face the full brunt of the DoC attack.
6.2 Portcullis Attacker Strategies
The optimal attacker strategy in network DDoS attacks today is
simply to target bottleneck links near the victim with as many pack-
ets as possible in order to decrease the probability of a legitimate
packet ﬁnding space in a router’s queue. However, with Portcullis
the choice of attacker strategies is more subtle, as the attacker must
decide whether it is better to send many low priority packets, or
fewer packets each with higher priority.
We assume that attackers can pool their CPU resources to col-
lectively solve puzzles in order to maximize the power of their at-
tack. As we discussed in Section 5, sharing puzzle solutions does
not signiﬁcantly impact legitimate senders, so our simulation as-
sumes that all puzzle solutions are unique. As our analytical results
demonstrate, the ideal attacker strategy is to send the highest pri-
ority puzzles possible while still saturating the victim’s bottleneck
link(s). Figure 3 illustrates this, where the ideal strategy (top line)
is for the attackers to collectively send requests at 10 Mbps (the re-
quest capacity of the victim’s network link) and devote their pooled
CPU resources to computing the hardest puzzles possible for those
requests. To send more than 10 Mbps, an attacker must devote less
CPU power to each puzzle, lowering the computational threshold
for legitimate senders. Sending requests with higher puzzle levels
means that the attacker does not have the CPU resources to saturate
the link. Thus, legitimate packets reach the victim even when they
are of lower priority than attack trafﬁc.
This graph powerfully demonstrates results presented analyti-
cally earlier in the paper: even when attackers cooperate to com-
pute puzzles, a legitimate client can quickly increase its level of
puzzle difﬁcultly until the collective CPU power of the adversary
is insufﬁcient to keep the link saturated with equally difﬁcult puz-
zles. Wait times are approximately 8 seconds, even with 20,000
attackers using an optimal strategy.
6.3 Comparative Simulations
Our second set of simulations compare Portcullis, TVA [32],
speak-up [26], and a simple random-drop “legacy” forwarding scheme
on the same Internet-scale topology. For the Portcullis simulations,
we show both an attacker who employs the optimal puzzle-solving
strategy discussed above, as well as an attacker that simply ﬂoods
packets without solving puzzles.
With TVA, each router performs queuing based on the ingress
point of the packet into the current AS. Because the Skitter maps
do not include AS information, we use the Team Cymru “IP to
ASN” service [9], which creates mappings based on a diverse set
of BGP feeds. For the less than 2% of router IPs that did not suc-
cessfully map to an AS, we consider that router to be a member
of the most recent known AS in the path. These mappings result
in an average AS-path length of approximately 4.1, which is only
slightly less than the average length of 4.5 determined by previous
measurement work [2]. Since TVA does not specify a value for
source retransmission rates of request packets, we use a highly ag-
gressive retransmission rate of one packet/10ms for TVA clients. In
practice, such a high rate for legitimate senders may cause conges-
tion for trafﬁc to alternate destinations, but in this simulation the
higher transmission rate is strictly better for TVA.
For speak-up, both legitimate and malicious senders saturate their
uplinks with request packets. In the randomized dropping (legacy
router) scheme, each router simply chooses packets randomly from
its incoming queue until its outgoing queue reaches capacity, drop-
ping all remaining packets.
Figure 4 compares the speed with which 1,000 legitimate clients
acquire a capability when using various defense mechanisms. The
graphs represent different numbers of attackers (1,000 and 20,000),
which are representative of our results for different numbers of at-
tackers in between. Note that the x-axis uses a logarithmic scale.
The two lowest lines represent TVA and the randomized-drop
router strategy. With both strategies, many clients fail to acquire a
capability within the simulation period of 100 seconds when faced
with 20,000 attackers. A full Internet topology greatly reduces
the beneﬁts of TVA, because with each AS hop, legitimate trafﬁc
“mixes” and becomes indistinguishable from attack trafﬁc with re-
spect to TVA’s priority mechanism. In fact, if each AS has i ingress
points, and there are λ AS hops, the likelihood of a packet suc-
cessfully reaching the destination scales with the inverse of iλ−1
when the number of attackers is large. That is, loss rates with TVA
are heavily topology-dependent because they are exponential in the
number of AS-hops contained in the network path. On realistic
topologies, this mixing of trafﬁc results in performance that is sim-
ilar to the randomized best-effort transmission of request packets.
The original analysis of TVA [32] did not show this effect because
their simple topology contained only a single hop before the bottle-
neck link, meaning that no mixing of good and bad trafﬁc occurred.
100
100
d
e
h
s
i
l
b
a
t
s
E
y
t
i
l
i
b
a
p
a
C
%
80
60
40
20
0
0.1
Portcullis - Flooder
Portcullis - Puzzle Solver
Speak-up
Random
TVA
80
60
40
20
d
e
h
s
i
l
b
a
t
s
E
y
t
i
l
i
b
a
p
a
C
%
Portcullis - Flooder
Portcullis - Puzzle Solver
Speak-up
Random
TVA
1
Time (s)
10
100
0
0.1
1
Time (s)
10
100
Figure 4: Capability Setup Time. Cumulative distribution functions of the time required for a legitimate sender to acquire a capability
when faced with 1,000 attackers (left) and 20,000 attackers (right). The Portcullis Puzzle Solver attacker uses the optimal strategy
discussed in Section 6.2. Note that the x-axis uses a logarithmic scale.
Speak-up hosts gradually establish capabilities, but a signiﬁcant
portion (20%) take half a minute or more to succeed. Speak-up’s
performance declines as the number of attackers increases, since
the attackers have more bandwidth relative to the legitimate senders.
The Portcullis-Flooder line in Figure 4 demonstrates that Portcullis
provides clear beneﬁts if the attacker naively uses the same ﬂood-
ing strategy used against TVA. But what happens when the attacker
is smart and harnesses all of its computational power to compute
puzzles using an optimal strategy?
As we see in Figure 4, Portcullis guarantees legitimate clients
the ability to achieve fairness regardless of topology, even if the
attacker uses the ideal puzzle computation strategy.
In contrast,
TVA cannot offer a legitimate client real fairness once its trafﬁc
mixes with the higher-rate attack trafﬁc. Portcullis’s performance
illustrates the beneﬁts of a scheme that is orthogonal to topology.
The threshold-style shape of the line for the puzzle-solving at-
tacker scenario illustrates the puzzle scheme’s operation. Legiti-
mate senders start with low-level puzzles that cannot compete with
the attacker’s high-level puzzles. However, legitimate senders con-
tinue to increase their puzzle levels until they receive a capability.
When legitimate senders reach the puzzle level employed by the
attacker, some portion of their packets are randomly selected and
reach the victim, creating the ﬁrst jump in the percentage of capa-
bilities established. If a legitimate sender’s packet does not make
it through, the sender must spend time computing a new puzzle at
a higher puzzle level. The higher puzzle level of this next packet
guarantees that it receives priority over the attacker’s packets, and
hence the rest of the legitimate senders can establish capabilities.
Thus, the distance between the two “surges” represents the time
spent computing the higher-level puzzle.
6.4 Partial Deployment
While the previous experiments assume a complete deployment
scenario, we also run simulations to evaluate the effectiveness of
Portcullis in partial deployment. We focus on the performance for
an early adopter, so in our simulations, only the victim’s ISP up-
grades its routers. We deﬁne the victim’s ISP to encompass the
victim’s link to the network, plus the next three hops on paths lead-