m2
m1
m3
time
h1
h2
h3
g1
g3
g4
g2
(a)
auxiliary
groups
target
groups
h1
h2
h3
g1
g2
g3
g4
m
m
a-multicast(m)
a-deliver(m)
x-broadcast
x-deliver
m1
m2
m1
m2
m3
(b)
Fig. 1: (a) An overlay tree used in ByzCast with four target groups and three auxiliary groups. (b) An execution of ByzCast with three
messages: m1 is a-multicast to {g1, g2}, m2 to {g2, g3}, and m3 to g3. For clarity, each group has one (correct) process.
1) Any two messages m and m(cid:3) atomically multicast to
common destinations are ordered by at least one inner
group xk in the tree.
2) If m is ordered before m(cid:3) in xk, then m is ordered before
m(cid:3) in any other group that orders both messages (thanks
to the FIFO atomic broadcast used in each group).
We illustrate an execution of ByzCast in Fig. 1 (b) with
messages m1, m2 and m3 a-multicast to groups {g1, g2},
{g2, g3}, and {g3}, respectively. Assuming the overlay tree
shown in Fig. 1 (a), m1 is ﬁrst h2-broadcast in group h2.
Upon h2-delivering m1, processes in h2 atomically broadcast
m1 in g1 and in g2. Message m2 is ﬁrst h1-broadcast, and
then it continues down the tree until it is delivered by g2 and
g3, its destination target groups. Message m3 is g3-broadcast
in g3 directly since it is addressed to a single group. The order
between m1 and m2 is determined by their delivery order at
h2 since h2 is the highest group to deliver both messages.
ByzCast is a partially genuine atomic multicast protocol.
While messages addressed to a single group are ordered by
processes in the destination group only, messages addressed
to multiple groups may involve auxiliary groups. For example,
in Fig. 1, the atomic multicast of m1 (resp., m2) involves h2
(resp., h1, h2 and h3), which is not a destination of m1 (resp.,
m2). Since m3 involves a single destination group, only m3’s
sender and g3, m3’s destination, must coordinate to order the
message. The performance of messages multicast to multiple
groups largely depends on the overlay tree, as we discuss in
the next section.
Finally, even though we described ByzCast with auxiliary
groups as inner nodes of the tree, Algorithm 1 does not need
this restriction: target groups can be inner nodes in the overlay
tree, or we can have a tree that contains target groups only.
C. Optimizations
Laying out ByzCast overlay tree is an optimization problem
with conﬂicting goals: on the one hand, we aim at short trees to
reduce the latency of global messages; on the other hand, when
laying out the tree, we must avoid overloading groups. For
example, in Fig. 1, the height of the lowest common ancestor
of m1 and m2 are two and three, respectively. A two-level
tree where the four target groups descend directly from one
auxiliary group would improve the latency of global messages.
However, in a two-level tree all global messages must start at
the root group, which could become a performance bottleneck.
We now formulate the problem of laying out an optimized
ByzCast tree. The following parameters are input:
• Γ and Λ as already deﬁned, and N = Γ ∪ Λ;
• D ⊆ P(Γ): all possible destinations of a message, where
P(Γ) is the power set of Γ;
• F (d): maximum load in messages per second multicast
to destinations d in the workload, where d ∈ D; and
• K(x): maximum performance in messages per second
that group x can sustain, ∀x ∈ N .
Given this input, the problem consists in ﬁnding the directed
edges E ⊆ N × N of the optimized overlay tree T = (N , E).
To more precisely state the optimization function with con-
straints, we introduce additional deﬁnitions.
• P (T , d): the set of groups involved in a multicast to d
(i.e., groups in the paths from lca(d) to all groups in d);
• H (T , d): the height of the lowest common ancestor of
groups in d;
• T (T , x) = {d | d ∈ D and x ∈ P (T , d)}: set of
destinations that involve group x; and
(cid:3)
• L(T , x) =
d∈T (T ,x) F (d): load imposed on group x.
Among the candidate overlay trees, respecting the above
restrictions, we are interested in those that minimize the height
of the various destinations.
(cid:4)
minimize
d∈D
H(T , d)
In addition to topological constraints, we have that the load
imposed to each group respects its capacity.
subject to ∀x : L(T , x) ≤ K(x)
D. Correctness
In this section, we prove that ByzCast satisﬁes all
properties of atomic multicast (§II-B).
the
Lemma 1: For any message m atomically multicast
to
multiple groups, let group x0 be the lowest common ancestor
42
∈ m.dst, if correct process p in x0 x0-
of m.dst. For all xd
delivers m, then all correct processes in the path x1, ..., xd,
xk-deliver m (f + 1) times, where 1 ≤ k ≤ d.
PROOF: By induction. (Base step.) Since p x0-delivers m, x1
is a child of x0, and reach(x1) ∩ m.dst (cid:8)= ∅, p x1-broadcasts
m. The claim follows from the validity of atomic broadcast
and the fact that there are 2f + 1 correct processes in x0.
(Inductive step.) Assume each correct process r in xk xk-
deliver m at least (f + 1) times. From Alg.1, and the fact
that xk+1 is a child of xk and reach(xk+1) ∩ m.dst (cid:8)= ∅, r
xk+1-broadcasts m. From the validity of atomic broadcast and
the fact that there are 2f + 1 correct processes in xk, every
(cid:2)
correct process in xk+1 xk+1-delivers m.
Lemma 2: For any atomically multicast message m, let
group x0 be the lowest common ancestor of m.dst. For all
∈ m.dst, if correct process p in xd xd-delivers m, then all
xd
correct processes in the path x0, ..., xd, xk-deliver m, where
0 ≤ k ≤ d.
PROOF: By backwards induction. (Base step.) The case for
k = d follows directly from agreement of atomic broadcast in
group xd. (Inductive step.) Assume that every correct process
r ∈ xk xk-delivers m. We show that correct processes in xk−1
xk−1-deliver m. From Alg.1, r xk-delivered m (f + 1) times.
From integrity of atomic broadcast in xk, at least one correct
process s in xk−1 xk-broadcasts m. Therefore, s xk−1-delivers
m, and from agreement of atomic broadcast in xk−1 all correct
(cid:2)
processes xk−1-deliver m.
Proposition 1: (Validity) If a correct process p a-multicasts a
message m, then eventually all correct processes q ∈ g, where
g ∈ m.dst , a-deliver m.
PROOF: Let group x0 be the lowest common ancestor of m.dst
and xd a group in m.dst. From Alg.1, p x0-broadcasts m and
from validity of atomic broadcast, all correct processes in x0
x0-deliver m. From Lemma 1, all correct processes in xd, xd-
deliver m (f + 1) times. Hence, every correct process in xd
(cid:2)
a-delivers m.
Proposition 2: (Agreement) If a correct process p in group
xd a-delivers a message m, then eventually all correct pro-
cesses q ∈ g, where g ∈ m.dst , a-deliver m.
PROOF: From Lemma 2, all correct processes in x0, x0-deliver
∈ m.dst xd-deliver m (f +1)
m. Thus, from Lemma 1, all xd
times. It follows from Alg.1 that all q ∈ xd a-deliver m. (cid:2)
Proposition 3: (Integrity) For any correct process p and any
message m, p a-delivers m at most once, and only if p ∈ g,
g ∈ m.dst , and m was previously a-multicast.
PROOF: From Alg.1, it follows immediately that a correct
process p ∈ g a-delivers m at most once, only if g ∈ m.dst
(cid:2)
and m is a-multicast.
Lemma 3: If m and m(cid:3) are two messages atomically
multicast to one or more destination groups in common, then
lca(m) ∈ subtree(m(cid:3)) or lca(m(cid:3)) ∈ subtree(m).
PROOF: Assume group x is a common destination in m and
m(cid:3) (i.e., x ∈ m.dst ∩ m(cid:3).dst). Let path(x) be the sequence of
groups in the overlay tree T from the root until x. From Alg.1,
in order to reach x, lca(m) (resp., lca(m(cid:3))) must be a group
in path(x). Without loss of generality, assume that lca(m) is
higher than lca(m(cid:3)) or at the same height as lca(m(cid:3)). Then,
lca(m(cid:3)) ∈ subtree(m), which concludes the lemma.
(cid:2)
Lemma 4: If a correct process in group x0 x0-delivers m
before m(cid:3), then for every ancestor group xd of x0, where
∈ m.dst ∩ m(cid:3).dst, every correct process in xd xd-delivers
xd
m before m(cid:3).
PROOF: By induction on the path x0, ..., xk, ..., xd. (Base
step.) Trivially from the properties of atomic broadcast in
group x0. (Inductive step.) Let p ∈ xk xk-deliver m before
m(cid:3). Thus, p xk+1-broadcasts m before m(cid:3) and from the FIFO
guarantee of atomic broadcast in xk+1, every correct process
q ∈ xk+1 xk+1-delivers m before m(cid:3).
(cid:2)
Proposition 4: (Preﬁx order) For any two messages m and
m(cid:3) and any two correct processes p and q such that p ∈ g,
q ∈ h and {g, h} ⊆ m.dst ∩ m(cid:3).dst , if p a-delivers m and
q a-delivers m(cid:3), then either p a-delivers m(cid:3) before m or q
a-delivers m before m(cid:3).
PROOF: The proposition holds trivially if p and q are in the
same group, so assume that g (cid:8)= h. From Lemma 3, and
without loss of generality, assume that lca(m(cid:3)) ∈ subtree(m).
Thus, lca(m(cid:3)) will order m and m(cid:3). From Lemma 4, both p
and q a-deliver m and m(cid:3) in the same order as lca(m(cid:3)). (cid:2)
Proposition 5: (Acyclic order) The relation < is acyclic.
PROOF (SKETCH): For a contradiction, assume there is an
execution of ByzCast that results in a cycle m0 < ... < md <
m0. Since all correct processes in the same group a-deliver
messages in the same order, the cycle must involve messages
a-multicast to multiple groups. Let x be the highest lowest
common ancestor of all messages in the cycle. We deﬁne
subtree(x, 1), subtree(x, 2), ... as the subtrees of group x in
T . Since the cycle involves groups in the subtree of x, there
must exist messages m and m(cid:3) such that (a) m is a-delivered
before m(cid:3) in groups in subtree(x , i ) and (b) m(cid:3) is a-delivered
before m in groups in subtree(x , j ), i (cid:8)= j. From Lemma 4,
item (a) implies that processes in x x-deliver m and then m(cid:3),
and item (b) implies that processes in x x-deliver m(cid:3) and then
(cid:2)
m, a contradiction.
IV. IMPLEMENTATION
We implemented ByzCast on top of BFT-SMaRt, a well-
known library for BFT replication [18]. This library has been
used in many academic projects and a few recent blockchain
systems (e.g., [16], [33]).
BFT-SMaRt message ordering is implemented through the
Mod-SMaRt algorithm [34], which uses the Byzantine-variant
of Paxos described in [35] to establish consensus on the i-
th (batch of) operation(s) to be processed by the replicated
state machine. The leader starts a consensus instance every
43
f+1 identical
responses
request
BFT
Atomic
Multicast
c
p1
p2
p3
p4
p5
p6
p7
p8
h
g
BFT
Atomic
Multicast
(b)
c
p1
p2
p3
p4
request
BFT
Atomic
Multicast
(a)
f+1 identical
responses
Fig. 2: Executions of ByzCast with (a) a local message and (b) a global message. Each group has four processes, one of which may be
Byzantine. For clarity, the execution of ByzCast shows a single target group only.
time there are pending client requests to be processed and
there are no consensus being executed. Consensus follows a
message pattern similar to PBFT [17]: the leader proposes
a batch of messages to be processed, the replicas validate
this proposal by writing the proposal in the other replicas;
the replicas accept the proposal if a Byzantine quorum of
n − f replicas perform the write. When a replica learns that
n − f replicas accepted the proposal, it executes the operation
and sends replies to the clients. In case of leader failure
or network asynchrony, a new leader is elected. BFT-SMaRt
also implements protocols for replica recovering (i.e., state
transfer), and group reconﬁguration [18].
In ByzCast, each group (either target or auxiliary) corre-
sponds to a BFT replicated state machine. Each replica in
auxiliary groups connects to all the replicas in the next level.
We implemented two overlay trees. A three-level tree, as the
one presented in Fig. 1 and a two-level tree that uses a single
auxiliary group to order global messages.
Replicas only process messages from a higher-level group
when they (FIFO) a-deliver them f + 1 times. Target groups
execute a-delivered messages and reply either to clients or to
auxiliary groups whether the message is local or global. Both
clients and auxiliary groups wait for f + 1 correct replies.
Fig. 2 depicts the described logic in executions of a request
from a client in a local and a global message. Except for client
requests, which are single messages, all messages exchanges
between groups need f + 1 equal responses before they
can be processed. Even though multiple processes in group
invoke the broadcast of a message in another group, thanks to
BFT-SMaRt’s batching optimization, it is likely that all such
invocations are ordered in a single instance of consensus.
Clients run in a closed loop (i.e., only send a new message
after the previous message reply) and forward messages to
every replica in the lowest common ancestor group of the
message. ByzCast was implemented in Java and the source
code is publicly available.1
V. PERFORMANCE EVALUATION
In this section, we describe the main motivations that guided
the design of our experiments (§V-A), detail the environments
in which we conducted the experiments (§V-B), and then
present and discuss the results (§V-C–V-H).
A. Evaluation rationale
In the following, we explain our choices for environments,
benchmarks, and protocols.
1) Environments: We consider a local-area network (LAN)
and a wide-area network (WAN). The LAN provides a con-
trolled environment, where experiments run in isolation; the
WAN represents a more challenging setting.
2) Benchmarks: We use a microbenchmark with 64-byte
messages to evaluate particular scenarios in isolation. We vary
the number of groups (up to 8 groups, the largest conﬁguration
we can accommodate in our local
infrastructure) and the
number of message destinations. We assess two layouts for
the ByzCast tree: a 2-level and a 3-level tree. We consider
executions with a single client to understand the performance
of ByzCast without queueing effects, and with multiple clients
to evaluate our solution under stress. Finally, we consider
workloads with and without locality (i.e., skewed access).
3) Protocols: We compare ByzCast to BFT-SMaRt and to
a non-genuine 2-level atomic multicast protocol, which we
call Baseline. BFT-SMaRt uses a single group and provides a
reference to the performance of ByzCast with local messages.
The Baseline protocol has one auxiliary group that orders
all messages regardless of the message destination. After the
message is ordered, it is forwarded to its destinations. Each
process in the target group waits until it receives the message
from f + 1 processes in the auxiliary group. Although the
non-genuine protocol does not scale, it provides a performance
reference for global messages.
B. Environments and conﬁguration
We now detail the environments where we performed the
1https://github.com/tarcisiocjr/byzcast.
evaluation of the three protocols.
44
1) Local-area network (LAN): This environment consisted
of a set replica nodes with an eight-core Intel Xeon L5420
processor working at 2.5GHz, 8GB of memory, SATA SSD
disks, and 1Gbps ethernet card; and clients nodes with a
four-core AMD Opteron 2212 processor at 2.0GHz, 4GB of
memory, and 1Gbps ethernet card. Each node runs CentOS
7.1 64 bits. The RTT (round-trip time) between nodes in the
cluster is around 0.1ms.
2) Wide-area network (WAN): We used Amazon EC2, a
public wide-area network. All nodes are c4.xlarge instances,
with 4 vCPUs and 7.5GB of memory. We allocated nodes in
four regions: California (R1), North Virginia (R2), Frankfurt