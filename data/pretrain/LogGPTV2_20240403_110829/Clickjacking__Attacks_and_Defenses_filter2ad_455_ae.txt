and the maximum padding area tested (M=20px, Group
4c) resulted in a further reduction to 12 of 73 (16%).
The reduction in the ﬁrst-mouseover attack success rates
between Groups 4a and 4b was statistically signiﬁcant
(p=0.0155), as was the reduction from Groups 4b to 4c
(p=0.0151). We also noticed that adding a 10px padding
area even reduced the unﬁltered attack success rate from
76 of 77 (98%) in Group 4a to 67 of 78 (85%) in Group
4b, and a 20px padding area further reduced the unﬁl-
tered attack success rate to 51 of 73 (69%) in Group 4c.
The reduction in the unﬁltered attack success rates be-
tween Groups 4a and 4b was also statistically signiﬁcant
(p=0.0046), as was the reduction from Groups 4b to 4c
(p=0.0191). Thus, larger padding areas provide notice-
ably better clickjacking protection. Participants assigned
to Group 5 received the defense of 4c enhanced with a
lightbox, which further decreased the ﬁrst-mouseover at-
tack effectiveness to 10 of 73 (13%). The difference in
ﬁrst-mouseover success rates between Group 4c and 5
was not statistically signiﬁcant (p=0.8176).
Note that there is a large discrepancy comparing ﬁrst-
mouseover attack success to the survey-ﬁltered attack
success. After analyzing our event logs manually, we
realized that many users answered our survey questions
inaccurately. For example, some people told us that they
didn’t click on the Like button, and they wouldn’t ap-
prove clicking on it, whereas the logs show that while
their initial click was blocked by our defense, they con-
tinued moving the mouse around for several seconds be-
fore ﬁnally resolving to click the Like button. While
these users’ answers suggested that clickjacking protec-
tion should have stopped them, our defenses clearly had
no chance of stopping these kinds of scenarios.
Participants assigned to Groups 6a-d were protected
by the pointer-entry delay defense described in Sec-
tion 5.2: if the user clicks within a duration of TE ms of
the pointer entering the target region, the click is invalid.
In Groups 6a and 6b, we experiment with a pointer en-
try delay of TE=250ms and TE=500ms, respectively. We
used an appearance delay of TA=500ms and a padding
area of M=20px as in Group 4c. In both cases, we ob-
served that the addition of pointer entry delay was highly
effective. Only 3 of 73 (4%) participants in Group 6b
still clicked on the target button. We found a signiﬁ-
cant difference in attack success rate between Groups 4c
and 6b (p=0.0264), indicating that the pointer entry de-
lay helps stopping clickjacking attacks, compared to no
pointer entry delays. We then test a more extreme pointer
entry delay of TE=1000ms, in which the appearance de-
lay TA must also be adjusted to no less than 1000ms. This
was most successful in preventing clickjacking from suc-
ceeding: only 1 of 71 (1%) participants fell for the at-
tack. We also tested the pointer entry delay TE=500ms
without a padding area (M=0px), which allowed 16 of
77 (20%) participants in Group 6d to fall for the attack.
Note that the difference in ﬁrst-mouseover success rates
between Groups 6b and 6d was signiﬁcant (p=0.0026).
Again, our results suggest that attacks are much more
effective when there is no padding area around the tar-
get. Finally, in Group 7 we tested the lightbox effect in
addition to Group 6b. The attack succeeded on 6 of 73
(8%) participants in Group 7, in which the difference be-
tween Groups 6b and 7 was not statistically signiﬁcant
(p=0.4938).
Overall, we found that pointer entry delay was crucial
in reducing the ﬁrst-mouseover success rate, the part of
the attack’s efﬁcacy that could potentially be addressed
by a clickjacking defense. Thus, it is an important tech-
nique that should be included in a browser’s clickjacking
protection suite, alongside freezing with a sufﬁciently
large padding area, and the pointer re-entry protection.
The pointer entry delay subsumes, and may be used
in place of, the appearance delay. The only exception
would be for devices that have no pointer feedback; hav-
ing an appearance delay could still prove useful against
a whack-a-mole-like touch-based attack.
14
7.5 Ethics
The ethical elements of our study were reviewed as per
our research institution’s requirements. No participants
were actually attacked in the course of our experiments;
the images they were tricked to click appeared identical
to sensitive third-party embedded content elements, but
were actually harmless replicas. However, participants
may have realized that they had been tricked and this
discovery could potentially lead to anxiety. Thus, after
the simulated attack we not only disclosed the attack but
explained that it was simulated.
8 Conclusion
We have devised new clickjacking attack variants, which
bypass existing defenses and cause more severe harm
than previously known, such as compromising webcams,
user data, and web surﬁng anonymity.
To defend against clickjacking in a fundamental way,
we have proposed InContext, a web browser or OS mech-
anism to ensure that a user’s action on a sensitive UI el-
ement is in context, having visual integrity and temporal
integrity.
Our user studies on Amazon Mechanical Turk show
that our attacks are highly effective with success rates
ranging from 43% to 98%. Our InContext defense can
be very effective for clickjacking attacks in which the
use of clickjacking improves the attack effectiveness.
tacks and defenses.
ness of clickjacking attacks.
This paper made the following contributions:
• We provided a survey of existing clickjacking at-
• We conducted the ﬁrst user study on the effective-
• We introduced the concept of context integrity and
used it to deﬁne and characterize clickjacking at-
tacks and their root causes.
• We designed, implemented, and evaluated InCon-
text, a set of techniques to maintain context integrity
and defeat clickjacking.
With all these results, we advocate browser vendors
and client OS vendors to consider adopting InContext.
Acknowledgments
We are grateful
to Adam Barth, Dan Boneh, Elie
Bursztein, Mary Czerwinski, Carl Edlund, Rob Ennals,
Jeremiah Grossman, Robert Hansen, Brad Hill, Eric
Lawrence, Giorgio Maone, Jesse Ruderman, Sid Stamm,
Zhenbin Xu, Michal Zalewski, and the Security and Pri-
vacy Research Group at Microsoft Research for review-
ing and providing feedback on this work.
References
[1] F. Aboukhadijeh. HOW TO: Spy on the Webcams of Your
Website Visitors. http://www.feross.org/webcam-
spy/, 2011.
[2] Adobe.
Flash OBJECT and EMBED tag attributes.
http://kb2.adobe.com/cps/127/tn_12701.html,
2011.
[3] G. Aharonovsky.
Malicious camera spying using
http://blog.guya.net/2008/
ClickJacking.
10/07/malicious-camera-spying-using-
clickjacking/, 2008.
[4] L. C. Aun. Clickjacking with pointer-events. http://
jsbin.com/imuca.
[5] M. Balduzzi, M. Egele, E. Kirda, D. Balzarotti, and
C. Kruegel. A solution for the automated detection of
clickjacking attacks. In Proceedings of the 5th ACM Sym-
posium on Information, Computer and Communications
Security, 2010.
[6] D. Baron. Preventing attacks on a user’s history through
CSS :visited selectors. http://dbaron.org/mozilla/
visited-privacy, 2010.
[7] E. Bordi. Proof of Concept - CursorJacking (noScript).
http://static.vulnerability.fr/noscript-
cursorjacking.html.
[8] M. Cardwell. Abusing HTTP Status Codes to Ex-
https://grepular.
pose Private
com/Abusing_HTTP_Status_Codes_to_Expose_
Private_Information, 2011.
Information.
[9] J. Grossman. Clickjacking: Web pages can see and
hear you.
http://jeremiahgrossman.blogspot.
com/2008/10/clickjacking-web-pages-can-see-
and-hear.html, 2008.
[10] E. Hammer-Lahav. The OAuth 1.0 Protocol. RFC 5849
(Informational), Apr. 2010.
[11] R. Hansen.
Stealing mouse clicks for banner fraud.
http://ha.ckers.org/blog/20070116/stealing-
mouse-clicks-for-banner-fraud/, 2007.
[12] R. Hansen. Clickjacking details. http://ha.ckers.
org/blog/20081007/clickjacking-details/,
2008.
[13] R. Hansen and J. Grossman. Clickjacking. http://www.
sectheory.com/clickjacking.htm, 2008.
user
Adaptive
ran-
as
strat-
http://www.thesecuritypractice.
[14] B. Hill.
domization
egy.
com/the_security_practice/papers/
AdaptiveUserInterfaceRandomization.pdf,
May 2012.
anti-clickjacking
interface
an
[15] R. Hoffmann, P. Baudisch, and D. S. Weld. Evaluating
visual cues for switching windows on large screens. In
Proceedings of the 26th annual SIGCHI conference on
Human factors in computing systems, 2008.
[16] L.-S. Huang and C. Jackson.
Clickjacking attacks
http://mayscript.com/blog/david/
unresolved.
clickjacking-attacks-unresolved, 2011.
[17] C. Jackson.
Improving browser security policies. PhD
thesis, Stanford University, 2009.
[18] K. Kotowicz. Exploiting the unexploitable XSS with
clickjacking. http://blog.kotowicz.net/2011/03/
exploiting-unexploitable-xss-with.html, 2011.
Filejacking: How to make a ﬁle
server from your browser (with HTML5 of course).
http://blog.kotowicz.net/2011/04/how-to-
[19] K. Kotowicz.
15
make-file-server-from-your.html, 2011.
[20] K. Kotowicz.
Cursorjacking again.
http:
//blog.kotowicz.net/2012/01/cursorjacking-
again.html, 2012.
[21] E. Lawrence.
ing Defenses.
archive/2009/01/27/ie8-security-part-vii-
clickjacking-defenses.aspx, 2009.
IE8 Security Part VII: ClickJack-
http://blogs.msdn.com/b/ie/
[22] M. Mahemoff. Explaining the “Don’t Click” Clickjacking
Tweetbomb. http://softwareas.com/explaining-
the-dont-click-clickjacking-tweetbomb, 2009.
Hello ClearClick, Goodbye Clickjack-
ing! http://hackademix.net/2008/10/08/hello-
clearclick-goodbye-clickjacking/, 2008.
[23] G. Maone.
[24] G. Maone.
Fancy Clickjacking, Tougher NoScript.
http://hackademix.net/2011/07/11/fancy-
clickjacking-tougher-noscript/, 2011.
Busting frame busting: a study of clickjacking vulnera-
In Proceedings of the Web 2.0
bilities at popular sites.
Security and Privacy, 2010.
[38] S. Sclafani.
Clickjacking & OAuth.
http:
//stephensclafani.com/2009/05/04/
clickjacking-oauth/, 2009.
[39] S. Stamm, B. Sterne, and G. Markham. Reining in the
web with content security policy. In Proceedings of the
19th International Conference on World Wide Web, 2010.
[40] P. Stone. Next generation clickjacking. In Black Hat Eu-
rope, 2010.
[41] E. Vela.
About CSS Attacks.
http://
sirdarckcat.blogspot.com/2008/10/about-
css-attacks.html, 2008.
[42] W3C. CSS 2D Transforms. http://www.w3.org/TR/
css3-2d-transforms/, 2011.
[43] W3C.
HTML5, 2012.
http://www.w3.org/TR/
[25] Microsoft.
createPopup Method.
http://msdn.
html5/.
microsoft.com/en-us/library/ms536392(v=vs.
85).aspx.
[26] Microsoft.
SetDoubleClickTime
function.
http://msdn.microsoft.com/en-us/library/
windows/desktop/ms646263(v=vs.85).aspx.
[27] Microsoft.
Implementing Binary DHTML Be-
http://msdn.microsoft.com/en-
haviors.
us/library/ie/aa744100(v=vs.85).aspx, 2012.
[28] M. Niemietz. UI Redressing: Attacks and Countermea-
sures Revisited. In CONFidence, 2011.
[29] L. A. Price. Studying the mouse for CAD systems.
In
Proceedings of the 21st Design Automation Conference,
1984.
[30] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. J.
Wang, and C. Cowan. User-driven access control: Re-
thinking permission granting in modern operating sys-
tems. In IEEE Symposium on Security and Privacy, 2012.
[31] J. Ross, L. Irani, M. S. Silberman, A. Zaldivar, and
B. Tomlinson. Who are the crowdworkers?: shifting
In Proceedings of
demographics in mechanical turk.
the 28th International Conference On Human Factors In
Computing Systems, 2010.
[32] J. Rossi. Defense in depth: Locking down mash-
http://blogs.msdn.
ups with HTML5 Sandbox.
com/b/ie/archive/2011/07/14/defense-in-
depth-locking-down-mash-ups-with-html5-
sandbox.aspx?Redirected=true, 2011.
[33] J. Ruderman. Bug 162020 - pop up XPInstall/security
dialog when user is about to click. https://bugzilla.
mozilla.org/show\_bug.cgi?id=162020, 2002.
[34] J. Ruderman.
in security di-
http://www.squarefree.com/2004/07/01/
alogs.
race-conditions-in-security-dialogs/, 2004.
Race conditions
[35] J. Ruderman.
The Same Origin Policy.
//www.mozilla.org/projects/security/
components/same-origin.html, 2011.
http:
[36] G. Rydstedt, E. Bursztein, and D. Boneh. Framing attacks
on smart phones and dumb routers: Tap-jacking and geo-
In USENIX Workshop on Offensive Tech-
localization.
nologies, 2010.
[37] G. Rydstedt, E. Bursztein, D. Boneh, and C. Jackson.
16
[44] H. J. Wang, X. Fan, J. Howell, and C. Jackson. Protection
and Communication Abstractions in MashupOS. In ACM
Symposium on Operating System Principles, 2007.
[45] H. J. Wang, C. Grier, A. Moshchuk, S. T. King, P. Choud-
hury, and H. Venter. The Multi-Principal OS Construction
of the Gazelle Web Browser. In Proceedings of the 18th
Conference on USENIX Security Symposium, 2009.
[46] Wikipedia. Likejacking. http://en.wikipedia.org/
wiki/Clickjacking#Likejacking.
[47] C. Wisniewski.
Facebook adds speed bump to slow
down likejackers. http://nakedsecurity.sophos.
com/2011/03/30/facebook-adds-speed-bump-to-
slow-down-likejackers/, 2011.
[48] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel. A prac-
tical attack to de-anonymize social network users. In Pro-
ceedings of the 31th IEEE Symposium on Security and
Privacy, 2010.
[49] M. Zalewski.
Browser security handbook.
http:
//code.google.com/p/browsersec/wiki/Part2#
Arbitrary_page_mashups_(UI_redressing).
[50] M. Zalewski.
(possibly other browsers).
fulldisclosure/2007/Feb/226, 2007.
Firefox focus stealing vulnerability
http://seclists.org/
[51] M. Zalewski.
[whatwg] Dealing with UI
re-
to the current web.
dress vulnerabilities
http://lists.whatwg.org/pipermail/whatwg-
whatwg.org/2008-September/016284.html, 2008.
inherent
[52] M. Zalewski.
inverse strokejack-
http://lcamtuf.blogspot.com/2010/06/
ing.
curse-of-inverse-strokejacking.html, 2010.
The curse of
[53] M. Zalewski. Minor browser UI nitpicking.
http:
//seclists.org/fulldisclosure/2010/Dec/328,
2010.
[54] M. Zalewski.
On designing UIs for non-robots.
http://lcamtuf.blogspot.com/2010/08/on-
designing-uis-for-non-robots.html, 2010.
[55] M. Zalewski. X-Frame-Options, or solving the wrong
problem. http://lcamtuf.blogspot.com/2011/12/
x-frame-options-or-solving-wrong.html, 2011.