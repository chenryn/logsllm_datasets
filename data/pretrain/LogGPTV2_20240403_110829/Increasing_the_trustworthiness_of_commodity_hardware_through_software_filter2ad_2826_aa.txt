title:Increasing the trustworthiness of commodity hardware through software
author:Kevin Elphinstone and
Yanyan Shen
Increasing the Trustworthiness of Commodity Hardware Through Software
Kevin Elphinstone
NICTA and University of New South Wales
Sydney, Australia
Email: PI:EMAIL
Yanyan Shen
NICTA and University of New South Wales
Sydney, Australia
Email: PI:EMAIL
Abstract—Advances in formal software veriﬁcation has pro-
duced an operating system that is guaranteed mathematically
to be correct and enforce access isolation. Such an operating
system could potentially consolidate safety and security critical
software on a single device where previously multiple devices
were used. One of the barriers to consolidation on commodity
hardware is the lack of hardware dependability features. A
hardware fault triggered by cosmic rays, alpha particle strikes,
etc. potentially invalidates the strong mathematical guarantees.
This paper discusses improving the trustworthiness of com-
modity hardware to enable a veriﬁed microkernel to be used
in some situations previously needing separate computers. We
explore leveraging multicore processors to provide redundancy,
and report the results of our initial performance investigation.
Keywords-multicore; kernel; reliability;
I. INTRODUCTION
High security computer systems that aim to preserve
integrity or conﬁdentiality of data still use simple, yet
cumbersome techniques, such as an air gap to provide strong
guarantees of isolation between components of a computer
system [1]. This might be isolation of classiﬁed information
from networks or components of lower clearance, isolation
of red plain-text data from black encrypted data, or isolation
of faults from critical infrastructure.
Cloud computing provides many opportunities for more
ﬂexible and cost effective computing, however it is difﬁcult
to reconcile the cloud’s consolidation of computing with the
high security community’s conservative approach to strong
isolation. Approaches such as multiple independent level of
security (MILS) set a precedent in architecting the consol-
idation of previously disparate systems [2]. However, there
is a lack of trust in software systems to preserve isolation
in MILS-like architectures, either due to the potential for
bugs in the implementation of a sound design, or due to
potential faults in a design itself due to the complexity of the
system. The presence of side-channel attacks further reduces
the conﬁdence in cloud infrastructure to enforce isolation
[3].
Recent advances in veriﬁcation and microkernel design
have progressed to the point of providing mathematical
guarantees of functional correctness of the seL4 microkernel
[4]. Further research has extended that work to guarantee
the integrity of isolated subsystems built upon the seL4
microkernel [5]. Formal assurance of conﬁdentiality (and
the practical strength or otherwise of various formulations
of conﬁdentiality) is an active area of research. However,
we are approaching the point in time where lack of trust
in software to preserve acceptable isolation will no longer
be the main issue limiting the adoption of MILS-style
approaches to security and safety.
For MILS-style systems to succeed with a veriﬁed kernel,
the assumptions made in establishing the above formal
guarantees will need sufﬁcient guarantees that ﬁt the risk
proﬁle of the application domain. Some assumptions, like
compiler correctness, can be addressed by providing strong
mathematical guarantees [6], which is another area of on-
going research. Assumptions, such as hardware correctness,
are more difﬁcult to address as even correctly designed and
manufactured hardware can experience errors due to cosmic
radiation [7], [8].
Our work aims to explore how to increase the trust-
worthiness of commercial off-the-shelf (COTS) hardware
in order to deploy a veriﬁed microkernel
in application
domains which require both high security (or safety) and
hardware consolidation. The main focus of this paper is to
describe and motivate the problem area, and then examine
the performance implications at the microkernel level of us-
ing redundancy to improve the trustworthiness of hardware.
II. BACKGROUND AND PROBLEM
Veriﬁcation of software involves showing that a represen-
tation of the software (ideally the machine code itself) ad-
heres to an abstract speciﬁcation of the software’s behaviour.
The lowest-level representation of the program deﬁnes the
assumed behaviour of the machine. If actual hardware
behaviour deviates from assumed machine behaviour, any
proven properties of software potentially no longer hold.
Fortunately, there is a large body of work in the area of
hardware veriﬁcation. Hardware veriﬁcation aims to ensure
that the processor logic design adheres to the speciﬁcation
of the machine code. Veriﬁcation involves formal methods
combined with traditional simulation [9]–[11]. Post-silicon
validation tests aim to ensure the actual products adhere
to the machine speciﬁcations. For our work, we assume
a correct (or at least known) initial hardware design and
implementation that forms the foundation of the veriﬁed
software stack.
978-1-4799-0181-4/13/$31.00 ©2013 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:20 UTC from IEEE Xplore.  Restrictions apply. 
However, correctly designed and implemented hardware
is not guaranteed to behave correctly indeﬁnitely. Factors
including high temperatures, circuit aging, and radiation may
still trigger permanent or transient hardware faults [12], [13].
One recent serious service outage of the Amazon S3 system
was caused by a singe-bit corruption in several messages
[14]. A study of hardware failure rates of one million
consumer PCs showed signiﬁcant failure rates [15].
The ﬂow-on effect of hardware failures on software ob-
viously varies form benign to catastrophic. A recent study
showed 1-2% of activated errors injected into the wu-ftpd
and sshd resulted in permanent vulnerabilities being opened
[16]. A study of security violations introduced by transient
errors in the ﬁrewall subsystem of the Linux kernel result in
2% of injected errors causing vulnerabilities, with some vul-
nerabilities requiring rebooting the system to remove [17].
The Java virtual machine bytecode veriﬁer was successfuly
attacked via memory soft errors induced with a 50-watt light
bulb [18].
There are many approaches aiming to mitigate these
hardware faults. We survey various hardware and software
approaches later in section V. For now, we make the
following assertions.
• Hardware approaches using a combination of redun-
dancy, extensive self-checking circuitry, hardware iso-
lation, or radiation hardening are unlikely to become
ubiquitous in COTS hardware in the near future. Such
approaches are also at a disadvantage when power
consumption is an issue and high-dependability is not,
such as in consumer embedded devices.
• Software approaches that replicate computation, at ei-
ther instruction, process, or virtual machine granularity,
assume the correctness of the underlying operating
system or virtual machine monitor.
Thus in a general sense, the problem we aim to solve is
how to leverage ubiquitous multi-core processors to mitigate
hardware faults for a veriﬁed operating system, while min-
imizing the performance impact. More speciﬁcally, we aim
to:
• maximize the sphere of replication of the trusted soft-
ware stack, including the operating system kernel itself,
• minimize the performance impact of replication and
synchronization of replicas,
• and retain the formal guarantees of the existing formal
veriﬁcation within the replicas.
Of the three points above, this paper is mostly concerned
with the second point.
III. SAMPLE SCENARIO
To facilitate further discussion, Figure 1 shows a sample
security architecture where two virtual machines of differing
security classiﬁcations are co-located on a single machine
running the seL4 microkernel. The goal of the architecture is
to isolate one security classiﬁcation from another, i.e. ensure
the untrusted Linux virtual machines (VMs) are isolated
from each other, while at the same time, minimizing the
amount of code trusted to perform correctly. The VMs
communicate with the outside world via a cryptographic
(de-)multiplexer (e.g. a VPN termination endpoint) that
ensures all information is encrypted when passing out of a
VM, and decrypted when passing into a VM, thus allowing
different classiﬁcation VMs to share a network connection.
Figure 1. Server consolidation architecture
The seL4 microkernel is responsible for managing the
hardware-provided isolation mechanisms to establish the
security domains (the 4 upper boxes in the diagram), and
to establish only the communication channels indicated by
the arrows between those boxes. On seL4, device drivers
run at user-level, encapsulated within a security domain just
like a VM or traditional process. Where available, seL4 will
manage an I/O MMU (such as Intel VT-d) to limit DMA
access to within the security domain. Interrupts are delivered
via inter-process communication (IPC). Thus device drivers
have the potential to be untrusted when appropriate hardware
is available.
Examining our scenario, given the goal of conﬁning con-
ﬁdentiality of information within the virtual machines, irre-
spective of their behaviour. We observe that if in preserving
conﬁdentiality, we are willing to tolerate denial of service,
then the only trusted components in the architecture are
the hardware, the seL4 microkernel, and the cryptographic
(de-)multiplexer. The driver and two VMs cannot violate the
conﬁnement of conﬁdential information unless either:
• the cryptographic component leaks plain text data,
• seL4 fails to enforce the isolation boundaries indicated,
• or the hardware fails to behave correctly.
The seL4 microkernel has been formally veriﬁed to be-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:20 UTC from IEEE Xplore.  Restrictions apply. 
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:2)(cid:6)(cid:7)(cid:8)(cid:2)(cid:5)(cid:9)(cid:7)(cid:6)(cid:2)(cid:9)(cid:10)(cid:9)(cid:11)(cid:12)(cid:3)(cid:13)(cid:14)(cid:5)(cid:2)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:2)(cid:8)(cid:9)(cid:2)(cid:3)(cid:4)(cid:20)(cid:7)(cid:21)(cid:17)(cid:18)(cid:22)(cid:2)(cid:23)(cid:3)(cid:9)(cid:7)(cid:8)(cid:3)(cid:2)(cid:24)(cid:20)(cid:7)(cid:21)(cid:17)(cid:18)(cid:23)(cid:2)(cid:20)(cid:25)(cid:4)(cid:26)(cid:7)(cid:8)(cid:9)(cid:13)(cid:27)(cid:2)(cid:9)(cid:21)(cid:2)(cid:28)(cid:29)(cid:30)(cid:9)(cid:24)(cid:31)(cid:30)(cid:9)(cid:2) (cid:21)(cid:3)(cid:2)(cid:9)(cid:9)(cid:17)(cid:12)(cid:3)(cid:23)(cid:5)(cid:2)(cid:6)!(cid:4)(cid:22)(cid:2)"(cid:7)(cid:23)(cid:3)(cid:2)(cid:9)(cid:23)#(cid:4)(cid:5)(cid:26)$have correctly, including being able to control information
ﬂow (time-based covert channels are still an open area of
research). Similar techniques can be applied to the cryp-
tographic component. Thus the security of the architecture
hinges on the correct behaviour of the hardware as we
previously introduced.
We now re-examine two of our three aims from section II
in the context of our example.
• The maximal sphere of replication is obviously limited
by the availability of replicated hardware. Single de-
vices will be a single point of failure. However, multi-
core hardware is ubiquitous, which enables the sphere
of replication to ideally encompass all trusted software
that enforces the security property, if not the entire
software stack. The challenge will be minimising the
exposure to single point of failure at the single device
boundary, in this case the network driver.
The security property of interest in this case does not