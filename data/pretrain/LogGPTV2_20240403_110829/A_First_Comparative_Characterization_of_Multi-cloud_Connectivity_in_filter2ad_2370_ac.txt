### Optimized Text

#### Performance Characteristics of TPP vs. BEP Routes
TPP (Third-Party Provider) routes exhibit better latency and throughput characteristics compared to BEP (Best Effort Path) routes. The primary reasons for this include shorter paths and lower loss rates in TPP transits. Although our study is limited in scale, it underscores the need for greater transparency and access to open measurement platforms for all entities involved in interconnecting enterprises with multiple clouds.

#### A.1 Representation of Results
In this paper, we use letter-value plots [31] to represent data distributions. Similar to boxplots, letter-value plots are useful for summarizing data point distributions but offer finer details beyond quartiles. The median is depicted by a dark horizontal line, and the 1/2i quantile is encoded by the box width. The widest boxes around the median represent the quartiles, the second widest boxes correspond to the octiles, and so on. Distributions with low variance centered around a single value appear as narrow horizontal bars, while those with diverse values appear as vertical bars.

Throughout the paper, we aim to present full distributions of latency when illustrative. Additionally, we compare the latency characteristics of different paths using median and variance measures, avoiding reliance on minimum latency, which does not capture the stability and dynamics across each path.

#### A.2 Preliminary Results on E2C (Enterprise-to-Cloud) Perspective
To emulate an enterprise leveraging multi-clouds, we connected a cloud router in the Phoenix, AZ region to a physical server hosted in a colocation facility in Phoenix, AZ.

**TPP Routes Offer Better Latency than BEP Routes:**
Figure 6a shows the latency distribution for our measured E2C paths. We observe that TPP routes consistently outperform BEP routes, with lower baseline latency and less variation. The median latencies for TPP routes towards GCP, AWS, and Azure VM instances in California are 11 ms, 20 ms, and 21 ms, respectively. The reverse paths show symmetric distributions, which we omit for brevity. For E2C paths, we always observe direct peerings between the upstream provider (e.g., Cox Communications (AS22773)) and the CP network. Using bdrmapIT to infer peering points from traceroutes, we measure the latency on the peering hop. Figure 6b shows the latency distribution for the peering hop for E2C paths originating from CP instances in CA to our enterprise server in AZ. While GCP and Azure's routing policies for E2C paths are similar to our C2C (Cloud-to-Cloud) observations, Amazon appears to hand off traffic near the destination, unlike their hot-potato tendencies for C2C paths. This change in AWS policy may be to minimize operational costs via their Transit Gateway service, which provides finer control over egress/ingress points [6]. Observing equal or lower minimum latency for TPP routes suggests that these routes are shorter than BEP paths. We also find (not shown here) that the average loss rate on TPP routes is 6 * 10^-4, an order of magnitude lower than the 1.6 * 10^-3 experienced on BEP routes.

**TPP Offers Consistent Throughput for E2C Paths:**
Figure 6c depicts the throughput distribution for E2C paths between our server in AZ and CP instances in CA via TPP and BEP routes. TPP paths show very consistent throughput values near the purchased link capacity, while BEP paths exhibit higher variability, expected given the best-effort nature of public Internet paths. The better throughput of TPP routes can be attributed to lower loss rates and shorter fiber paths from the enterprise server to the CPs' instances in CA. Furthermore, third-party providers are often present in additional, distinct colocation facilities closer to the edge, partially answering the question posed in Section 4.3.

#### References
1. A first comparative characterization of multi-cloud connectivity in today’s internet (2020). https://gitlab.com/onrg/multicloudcmp
2. Ager, B., Chatzis, N., Feldmann, A., Sarrar, N., Uhlig, S., Willinger, W.: Anatomy of a large European IXP. In: SIGCOMM. ACM (2012)
3. Alexander, M., Luckie, M., Dhamdhere, A., Huﬀaker, B., Claﬀy, K., Jonathan, S.M.: Pushing the boundaries with bdrmapIT: mapping router ownership at internet scale. In: Internet Measurement Conference (IMC). ACM (2018)
4. Amazon: AWS Direct Connect. https://aws.amazon.com/directconnect/
5. Amazon: AWS Direct Connect Partners. https://aws.amazon.com/directconnect/partners/
6. Amazon: AWS Transit Gateway. https://aws.amazon.com/transit-gateway/
7. Amazon: AWS Direct Connect Pricing (2019). https://aws.amazon.com/directconnect/pricing/
8. Amazon: EC2 Instance Pricing - Amazon Web Services (2019). https://aws.amazon.com/ec2/pricing/on-demand/

... (Additional references continue as before)

This optimized text aims to enhance clarity, coherence, and professionalism, making it more accessible and informative for readers.