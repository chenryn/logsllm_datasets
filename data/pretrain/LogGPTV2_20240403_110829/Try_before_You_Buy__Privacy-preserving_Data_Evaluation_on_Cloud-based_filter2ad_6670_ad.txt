convolution layer, the shopper decrypts them by multiplying with
1/Ri
2. After obtaining the original prediction values, the shopper
then applies active learning to evaluate data informativeness.
2 × (cid:174)Yi
2 × Yi
2. If the prediction values Zn
We choose an uncertainty sampling algorithm as our active
learning algorithm. Most existing uncertainty sampling algorithms
[37] use the entropy score of prediction values to select informative
data for binary classification; however, the entropy score cannot
accurately reflect the uncertainty degree for multi-class learning
since the score is always affected by unimportant classes. Hence,
we adopt Best-vs-Second-Best (BvSB) selection algorithm [20] that
considers the difference between the best and the second guess.
Avoiding selecting duplicates or near-duplicates that seem to
be valuable, our data selection protocol does not choose a large
dataset at one time. Instead, it selects valuable data in multiple
steps. In each step, the shopper selects and purchases a small set
of samples to train their ML models. As a result, the features of
these samples will be learned by the shopper’s model, and thus the
informativeness of the corrsponding duplicates and near-duplicates
will decrease. Subsequently, the duplicates and near-duplicates are
not likely to be evaluated as valuable.
6 PRIVACY-PRESERVING DATA VALIDATION
We first present a privacy-preserving data training approach that
allows the cloud to perform training operations with a shopper’s
encrypted model and sellers’ encrypted data. Based on this train-
ing approach, we then offer a privacy-preserving data validation
protocol.
6.1 Privacy-preserving Model Training
There are multiple epochs in model training, each of which con-
sists of a feed forward process and a back propagation process. We
only present back propagation here since we have described feed
forward in Section 5.1. Considering the feature of our Primal frame-
work, back propagation is designed to the multi-party computation
involving an untrusted cloud, a data shopper (model owner), and
multiple data sellers (data owners).
267Try before You Buy
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
In a training epoch, the cloud first performs a feed forward pro-
cess and sends encrypted prediction values to the shopper. Then,
the shopper decrypts them and executes a cost function to output
the prediction cost between the original prediction values (cid:174)Z
2
n and
labels (cid:174)L. Here, for simplicity but without loss of generality, we as-
sume the cost function is the mean square error function. Therefore,
the gradients of the output layer can be presented as δ = (cid:174)Z
n − (cid:174)L.
For back propagation, the shopper needs to send the gradients
to the cloud. As the cloud may infer (cid:174)Zn
2 from the gradients, the
shopper chooses a random vector (cid:174)Rc = {r1, r2,· · · } to randomize
the gradients as δ′ = ( (cid:174)Rc × ( (cid:174)Z
n − (cid:174)L)) and then sends them to the
cloud. Subsequently, the cloud can compute the gradients of each
hidden layer and update all parameters. Since the parameters of the
first hidden layer and back layers are encrypted by two methods,
respectively, the cloud updates parameters in two forms.
Back Hidden layers. For the i-th hidden layer (i > 1), the cloud
can compute the following gradients according to the chain rule.
2
2
∂δ′
∂CWi
= Ti
G × ∂δ
∂Wi
,
(5)
2
where Ti
G
G[k][v] = ((cid:174)Rc × (cid:174)Rn) ∗ (cid:174)R
Ti
is a random matrix, which can be presented as follows.
i−1[v]/(cid:174)Ri[k],
(6)
where (cid:174)Ri is a random vector chosen for the i-th hidden layer, and
(cid:174)Rn is a random vector chosen for the last hidden layer.
Recall that the parameters of the i-th hidden layer (i > 1) are
CWi = Ci × Wi, where Ci[k][v] = (cid:174)Ri[k]/(cid:174)R
i−1[v]. Accordingly,
2
the shopper can generate an update matrix UPi = Ci/Ti
and send
G
it to the cloud. Then, the cloud can update parameters as follows.
CWi
′ = CWi − α ∗ UPi × ∂δ′
∂CWi
),
= Ci × (Wi − α ∗ ∂δ
∂Wi
(7)
where α is the learning rate. In this way, the encrypted parameters
are homomorphically updated to the new parameters.
First Hidden Layer. As input data and the parameters of the first
hidden layer are encrypted by IFE, the cloud cannot directly com-
pute the corresponding gradients. Instead, the cloud sends the gra-
dients ∂δ′
to the seller Cx who owns the training data (cid:174)x. Then, Cx
∂ (cid:174)Z1
can compute the following gradients.
∂δ′
∂CW1
∂δ′
∂ (cid:174)Z1
.
G
= ((cid:174)x
)T = T1
G × ∂δ
∂W1
(8)
As the original parameters W1 of the first hidden layer are trans-
formed to CW1 = C1 × W1, the shopper should generate an update
parameter matrix UP1 = C1/T1
to homomorphically update the
parameters. To be precise, the shopper send it to Cx , and Cx can
generate the following gradients to update CW1.
= C1 × ∂δ
∂W1
(9)
Note that the parameters CW1 are encrypted by IFE. It seems
that the gradients ∇CW1 cannot be directly used to update CW1.
However, we notice that training operations do not need to mod-
ify CW1, provided that the output (cid:174)Z
2
1 of the first hidden layer is
correctly updated. Therefore, Cx shares ∇CW1 with other sellers.
∇CW1 = UP1 × ∂δ′
∂CW1
.
,
∇ (cid:174)Z
Then, all sellers can compute the following output gradients with
data (cid:174)x′.
1 = (α ∗ ∇CW1 (cid:174)x′)2
2
(10)
2
1, the cloud can update the
2
1 and start a new feed forward process.
where α is the learning rate. With ∇ (cid:174)Z
output (cid:174)Z
6.2 Data Validation
As informative data may contain irrelevant or falsely labeled data
that degrade a shopper’s model performance, we design a data
validation protocol to help the shopper validate the quality of the
selected data. The key observation behind our data validation proto-
col is that the prediction performance of a model reveals the quality
of previously training data. Therefore, the shopper requires the
cloud to retrain its model with the selected data. Then, it can ob-
serve the prediction performance of the retrained model to estimate
the quality of the selected data.
The prediction performance of a specific model can be revealed
by prediction values. Thus, the shopper first requires the cloud to
choose some sellers’ data and use its retrained model to output the
prediction values of these data. To not bias prediction values, the
sellers’ data should be chosen uniformly in this process. Then, the
shopper collects and decrypts prediction values to estimate data
quality. Particularly, the shopper can set a variable threshold Tq to
screen out the data of different qualities. If the prediction errors
are lower than Tq, the shopper will send the corresponding data
IDs to the cloud and make a payment. To gain high validation accu-
racy, the shopper can perform fine-grained validation operations.
Namely, the shopper can split validation data into smaller subsets
and validate the subsets one by one.
7 SECURITY ANALYSIS
As our ML encryption protocol underlies the security of our frame-
work Primal, we conduct a security analysis towards our ML en-
cryption protocol to demonstrate the security of Primal. Here, we
utilize the universal composition (UC) security framework [6] to
define the security of our ML encryption protocol. In the security
framework, there exists an environment Z, which generates the
input to all parties, reads all outputs, and in addition interacts with
an adversary in an arbitrary way throughout the computation. The
UC security is captured by the real world versus ideal world game.
In the real world, we consider an adversary A who interacts with
the real protocol ΠP . In the ideal world, we consider an adversary S
(called a simulator) who runs the dummy protocol in the presence
of the ideal functionality FP (see Figure 6).
Definition 1 (ML Encryption Security). We can say that
our ML encryption protocol securely realizes a given functionality FP
if for any real-world A, there exists an ideal adversary S such that
|Pr(Realk(Z, A, ΠP)) − Pr(Idealk(Z,S, FP))| ≤ neдl(k)
(11)
Now, we give the following security theorem. (security proof
can be found in Appendix A)
Theorem 1. Our ML encryption protocol securely realizes a given
functionality FP if the random numbers chosen for each layer are
pseudo-random, and the inner-product functional encryption scheme
IFE is secure.
268ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Qiyang Song1, Jiahao Cao2,3, Kun Sun1, Qi Li2,3, and Ke Xu2,3
Parameters: a cloud P, a shopper S, and sellers C1, · · · , Cm.
Setup: On input a security parameter from S, outputs mpk to
C1, · · · , Cm, and store msk and random numbers internally.
Data encryption: On input data (cid:174)x or X from Ci, outputs (cid:174)Cx
or CX to P.
Model Encryption for a Layer: On input a parameter
matrix Wi or a kernel Ki from S, outputs CWi or CKi to P.
Figure 6: Ideal Function FP
8 SYSTEM EVALUATION
We implement the prototype of Primal, where IFE is implemented by
a simple IFE scheme [1], and the matrix transformation mechanism
is implemented by GMP [24], PBC [25], and Tensorflow [11]. We
conduct experiments to evaluate the benefits of our data selection
protocol, the accuracy of our data validation protocol, and the sys-
tem overhead. Our experiments are performed on a PC containing
four Intel Core-i5 2.3 GHz processors. We consider 100 sellers and
one shopper to simulate a real-world data marketplace. Particularly,
we randomly divide the training samples of MNIST [30] into 100
subsets and distribute them to each seller.
8.1 Benefits of Data Selection
To demonstrate Primal can provide valuable data to significantly
improve model performance, we compare our data selection with
random data selection. Particularly, we utilize the two methods to
select data and then use the data to retrain two models of different
scales. To be precise, the two models are trained with 5500 samples
55000 samples, respectively. Figure 7 shows the performance of
the two models after retraining. We can see our data selection can
reduce about 60% prediction errors compared to random selection
when the number of selected samples is between 400 and 2000.
replacement label should be the label lh or the label ls, on which
the shopper’s model has the highest or second-highest prediction
confidence. Specifically, if the original label li is lh, we replace it
with ls. Otherwise, we replace it with lh.
To gain high detection accuracy, we do not perform our valida-
tion protocol on whole low-quality samples at one time. Instead,
we split these low-quality samples into subsets and then apply
the validation protocol to detect each subset one by one. Figure 8
shows the accuracy of two different validation strategies, which
are conducted at 10 granularity and 50 granularity. Here, granular-
ity refers to the size of split subsets. Overall, the accuracy of the
two validation strategies exceeds 80%. Particularly, the validation
strategy of 10 granularity achieves much higher accuracy than the
validation strategy of 50 granularity. We also notice that the strat-
egy of smaller granularity consumes more computation sources
since it needs to perform more validation operations. Therefore, the
shopper should make a trade-off between security and efficiency.
Figure 8: Accuracy of Data Validation
8.3 System Overhead
Here, we mainly measure the overhead of our ML encryption proto-
col since it determines system overhead, and extra overhead can be
ignored. First, we show the overhead of IFE computation, which is
the key component of our ML encryption protocol. Second, we ap-
ply this protocol to encrypt a specific CNN model and measure the
execution time of relevant operations to demonstrate the efficiency
of our system.
(a) Model 1
(b) Model 2
Figure 7: The benefit of data selection. Here, Model 1 and 2
are trained with 5500 and 55000 samples, respectively.
8.2 Accuracy of Data Validation
In this experiment, we use our data validation protocol to detect
some low-quality samples. To better demonstrate the effectiveness
of this protocol, we simulate specific low-quality samples that are
most likely to evade this protocol. Recall that our validation protocol
can easily detect the low-quality samples that deviate from the
original distribution since these samples degrade the shopper’s
model performance. Therefore, our simulation policy should replace
each sample’s original label li with another label that does not
deviate far away from the shopper’s model distribution. Thus, the
(a) Row Number=1
(b) Row Number=20
Figure 9: IFE-based Model Encryption and Matrix Com-
putation
IFE-based Encryption and Computation. Figure 9 shows the
execution time of IFE-based model encryption and matrix computa-
tion. Since convolution computation can be transformed to matrix
computation, we only measure the time of matrix computation. We
can see the execution time of model encryption and matrix com-
putation is proportional to row and column numbers. Particularly,
the execution time can be significantly reduced by GPU computing
since a matrix can be divided into parallel vectors.
  0.5  0.6  0.7  0.8  0.9  1.0  4008001200 16002000  Prediction Error# of Selected Samplesour dataselectionrandom dataselection  0.5  0.6  0.7  0.8  0.9  1.0  4008001200 16002000  Prediction Error# of Selected Samples our data selectionrandom data selection 0  0.20.40.60.8 1.0 200400600 8001000  # of Validation Samplesgranularity = 10granularity = 50Validation Accuracy 0    0.5  1.0  1.5  2.02.5100300500700900 Execution Time (s)Column NumberMatrix ComputationModel Encryption   0   10  20  30  4050  100300700900 Execution Time (s)500Column NumberMatrix Encryption Matrix Computation269Try before You Buy
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
A Privacy-preserving CNN model. To demonstrate the efficiency
of our ML encryption protocol, we compare it with E2DM [19], one
of the most efficient ML homomorphic encryption approaches. We
utilize our ML encryption protocol and E2DM to encrypt two CNN
models with the same typology, respectively. The model typology
consists of six layers: (i) input layer: a 28 × 28 input matrix; (ii)
convolution layer: four 5 × 5 convolution kernels with the stride of
2; (iii) pooling layer: four 2 × 2 convolution kernels with the stride