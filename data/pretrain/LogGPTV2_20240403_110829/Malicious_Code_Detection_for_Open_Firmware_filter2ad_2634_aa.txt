title:Malicious Code Detection for Open Firmware
author:Frank Adelstein and
Matthew Stillerman and
Dexter Kozen
Malicious Code Detection for Open Firmware
Frank Adelstein, Matt Stillerman
Dexter Kozen
ATC-NY
33 Thornwood Drive, Suite 500
Ithaca, NY 14850-1250, USA
fadelstein or matt @atc-nycorp.com
Department of Computer Science
Cornell University
Ithaca, New York 14853-7501, USA
PI:EMAIL
Abstract
Malicious boot ﬁrmware is a largely unrecognized but
signiﬁcant security risk to our global information infra-
structure. Since boot ﬁrmware executes before the operat-
ing system is loaded, it can easily circumvent any operating
system-based security mechanism. Boot ﬁrmware programs
are typically written by third-party device manufacturers
and may come from various suppliers of unknown origin. In
this paper we describe an approach to this problem based
on load-time veriﬁcation of onboard device drivers against
a standard security policy designed to limit access to system
resources. We also describe our ongoing effort to construct
a prototype of this technique for Open Firmware boot plat-
forms.
1. Introduction
Our critical infrastructure for transportation, communi-
cation, ﬁnancial markets, energy distribution, and health
care is dangerously dependent on a computing base vulner-
able to many forms of malicious attack and software failure.
The consequences of a coordinated attack on our informa-
tion infrastructure could be devastating [22]. One serious
vulnerability that has largely been ignored up until now is
malicious boot ﬁrmware.
Most computing devices are powered up by a boot se-
quence—a series of computational steps in which the hard-
ware is initialized and the operating system loaded and
started. Boot ﬁrmware is the program that controls this pro-
cess. Boot ﬁrmware typically runs in privileged mode on
bare hardware. It has essentially limitless access to periph-
eral devices. The boot program runs before the operating
system is loaded, prior to the start of most security mea-
sures. Thus malicious boot ﬁrmware has the potential to
cause very serious harm. This harm falls into three general
categories:
(cid:15) It could prevent the computer from booting, thus ef-
fecting a denial of service.
(cid:15) It could operate devices maliciously, thereby damaging
them or causing other harm.
(cid:15) It could corrupt the operating system as it is loaded.
This last form of attack is perhaps the most serious, since
most other security measures depend on operating system
integrity. Even the most carefully crafted security mecha-
nisms implemented at the operating system, protocol, ap-
plication, or enterprise levels can be circumvented in this
manner.
On a typical computing platform, the boot ﬁrmware is
composed of many interacting modules. There is usually
a boot kernel, which governs the bootup process, as well
as boot-time device drivers supplied by the manufacturers
of various components. The purpose of a boot driver is to
initialize the device, perform diagnostic checks, establish
communication with other devices connected to it, allocate
system resources, and other similar tasks. The driver often
resides in ROM on the device itself and is loaded and run at
boot time.
To interact successfully, these pieces must respect well-
deﬁned abstraction boundaries and communicate only via
standardized interfaces. Yet at boot time, the pieces all run
in the same address space in privileged mode. There is no
isolation and no external enforcement of good citizenship.
It would be well within the means of determined opponent
to introduce malicious code into a device driver for a key-
board or mouse, for example.
One line of defense is to ensure the integrity of ﬁrmware
via digital signatures [2] or chain-of-custody and physical
protection. This strategy requires that we assume that the
boot ﬁrmware was originally benign. Such a belief could
be based on trust in the supplier or in some detailed exam-
ination of the code. It simply ensures that the code has not
been changed after it was approved. Thus, the strategy is
a means for preserving an existing relationship of trust, but
not of establishing trust.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
This strategy could be costly in practice. There may be a
large, far-ﬂung network of vendors for whom trust must be
established. Moreover, there are mechanisms for automati-
cally updating device drivers and ﬁrmware with patches via
the Internet. Firmware that is updated regularly would need
to be reexamined each time.
In this paper we describe an alternative technique that
provides a basis for trust in boot ﬁrmware, regardless of
its source. The technique involves automatic veriﬁcation of
boot ﬁrmware modules as they are loaded. We also describe
ongoing work to construct a prototype veriﬁcation system
using this technique for computers compliant with the Open
Firmware boot standard.
Our veriﬁcation technique is based on Efﬁcient Code
Certiﬁcation (ECC) proposed in [6]. ECC is related to other
recent language-based approaches to the security of mobile
code [12, 15]. Each time an untrusted ﬁrmware module
is loaded, it is veriﬁed against a standard security policy.
Inexpensive static checks on the compiled code sufﬁce to
guarantee dynamic properties of the program. Among other
things, the security policy asserts that device drivers must
access other devices only through a strict interface and must
only access memory or bus addresses allocated to them.
ECC veriﬁcation relies on a certifying compiler that pro-
duces particularly well-structured and annotated code, so
that the veriﬁer can analyze it statically. The veriﬁcation
step essentially prevents the compiler from being bypassed,
spoofed, or counterfeited. Conﬁdence in the safety of ver-
iﬁed device drivers only requires trust in the veriﬁer, not
in the compiler nor the code it produces. By “trust” here
we mean that the user must have some other rational basis
for believing in the integrity and correctness of the veriﬁer
– that it is in the trusted computing base (TCB). The com-
piler and its output, on the other hand, do not have to be in
the TCB. Any device driver code, whether produced by the
compiler or not, must be veriﬁed.
This technique, while a strong countermeasure to ma-
licious ﬁrmware, cannot protect against all forms of at-
tack. For example, certain denial-of-service attacks and ma-
licious hardware are difﬁcult or impossible to detect by this
method. However, it does raise the bar by making it more
difﬁcult to operate devices maliciously at boot time. Our ap-
proach is complementary to existing and proposed schemes
that employ digital signatures, trusted suppliers, and code
inspection. Those techniques would be appropriate to pro-
tect the integrity of the TCB, which will be relatively static.
Our prototype, currently under development, is compli-
ant with the Open Firmware standard [5] and operates in
that context. Open Firmware is an IEEE standard for boot
ﬁrmware that was developed in the mid 1990’s and is by
now in fairly widespread use (e.g., by Sun and Apple).
Several commercial implementations are available. One
key feature of Open Firmware that is responsible for its
power and ﬂexibility is its incorporation of boot-time de-
vice drivers and other modules written in fcode, a machine-
independent compiled form of the Forth programming lan-
guage. Open Firmware boot systems include an fcode in-
terpreter, allowing a single implementation of fcode-based
ﬁrmware to be reused across multiple platforms. The fcode
driver is typically stored in ROM on the device itself and re-
loaded into main memory during the boot cycle. It is these
fcode device drivers that are the subject of veriﬁcation in
our prototype.
The veriﬁer is part of the Open Firmware boot kernel
and is loaded from boot ROM when the machine powers
up. The veriﬁer, along with the fcode interpreter and other
parts of the Open Firmware kernel, are considered part of
the trusted computing base. The complementary protection
schemes mentioned above will be appropriate for protection
of this software because it is assumed to be static and sup-
plied by a single vendor.
The security policy is a combination of type safety and
various architectural constraints. The policy is designed
to rule out the most obvious forms of attack. The con-
straints are a formalization of conventions that all legiti-
mate fcode programs should adhere to, as well as restric-
tions that make veriﬁcation easier without imposing undue
limitations on the programmer. Those conventions are not
strict requirements of Open Firmware, yet any ﬁrmware that
violates them would likely be incorrect or malicious. For
instance, each device driver conventionally operates its own
device directly, and accesses the other devices only via their
drivers.
A cornerstone of the ECC technique is a certifying com-
piler. Our prototype compiler translates Java Virtual Ma-
chine code (bytecode) to Forth fcode. We expect develop-
ers to use Java as the source language and compile to Java
bytecode with a standard Java compiler such as the javac
compiler from Sun Microsystems as the ﬁrst stage. We are
also developing a Java API so that these programs can ac-
cess Open Firmware services and data structures. This API
is not just a matter of convenience—it is a key element in
our eventual assurance argument. The API presents a safer
interface than the standard one; we will verify that untrusted
code uses this interface and does not bypass it.
2 Open Firmware
Open Firmware is a standard for boot ﬁrmware plat-
forms [5]. This standard enables vendors to write machine-
independent and instruction set-independent boot ﬁrmware,
including boot-time drivers. The major advantage to this
approach is that Open Firmware-compliant ﬁrmware will
work across a wide range of hardware. Sun Microsystems
Open Boot works this way and was the inspiration for this
standard.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
(cid:27)
probe
fcode
ROM
storage
peripheral
device
fcode
interpreter
?
fcode
programs
other
software
Figure 1. Fcode Loading in Open Firmware
Manufacturers of peripherals need only write one boot-
time device driver. The same driver will work with any
Open Firmware implementation on any platform. This
driver is stored in ROM on the device itself.
The major tasks of boot ﬁrmware are:
(cid:15) to determine the physical conﬁguration of the host and
peripherals and build the device tree data structure to
represent this,
(cid:15) to initialize those devices that require it, and
(cid:15) to load the operating system (or runtime program) and
start it running.
Open Firmware provides an abstract model of this process.
A hardware-speciﬁc adaptation layer whose interface is de-
ﬁned in the standard supports this abstraction.
A key feature of Open Firmware is the incorporation of
an interpreter for Forth fcode (Fig. 1). Forth is a stack-based
programming language with a long history of use on mi-
croprocessors. Fcode is a standard compiled form of Forth
that is very compact. Forth programs are called words, and
a compiler that produces fcode from Forth is called a to-
kenizer. The mapping from Forth to fcode is completely
deﬁned in the Open Firmware standard.
Open Firmware boot systems contain an fcode inter-
preter. Such systems dynamically load and execute fcode
modules during the boot cycle. Our system uses ECC-style
veriﬁcation, described in Section 3 below, to detect unsafe
fcode programs.
Portions of the boot ﬁrmware (other than the adaptation
layer) can be written in Forth and will run identically on
different hardware platforms. This software will employ
the standard boot data structures and hardware abstractions.
In particular, peripheral devices are all accessed through a
standard API consisting of a set of Forth words that each de-
vice of a particular type must deﬁne. The boot-time driver
for each device is supplied in the form of an fcode program
that when executed causes all required words to be deﬁned
appropriately. It also builds the portion of the device tree
that represents this device. That fcode program is stored in
ROM on the device itself. Open Firmware deﬁnes a stan-
dard method to retrieve the driver-deﬁning code from any
device. During the boot process, all of these programs are
retrieved and executed, thus constructing an API for each
device.
3 ECC
The ECC project (for Efﬁcient Code Certiﬁcation) [6]
was conceived as a way to improve the runtime efﬁciency of
small, untrusted, run-once applications such as applets and
active messages while still ensuring safe execution. Run-
once means that the cost of veriﬁcation cannot be amortized
over the lifetime of the code, so certiﬁcates should be as
concise and easy to verify as possible.
ECC guarantees certain dynamic safety properties of
compiled code by performing efﬁcient static checks. In par-
ticular, it permits implementation of a module that, at boot-
time, veriﬁes the safety of the boot ﬁrmware before it is run.
This technique relies on certain general mathematical theo-
rems that relate the control ﬂow safety, memory safety, and
stack safety of a running program to the block structure of
its compiled form. As a practical matter, the technique re-
lies on a certifying compiler that produces particularly well-
structured code, so that a veriﬁer can perform appropriate
static checks just prior to runtime. The user need only trust
the veriﬁer, which is a particularly simple program that can
be persuasively validated by inspection.
ECC attempts to identify the minimum information nec-
essary to ensure a basic but nontrivial level of code safety
and to encapsulate this information in a succinct certiﬁcate
that is easy to produce and to verify. Performance and ease
of implementation are important concerns. ECC is able to
ensure
(cid:15) control ﬂow safety—the program never jumps to a ran-
dom location in the address space, but only addresses
within its own code segment containing valid instruc-
tions;
(cid:15) memory safety—the program does not access random
places in memory, but only valid locations in its own
data segment, system heap memory explicitly allo-
cated to it, or valid stack frames; and
(cid:15) stack safety—the state of the stack is preserved across
subroutine calls.
These safety conditions are mutually dependent in the sense
that none of them are safe unless all of them are safe. This
level of safety is roughly comparable to that provided by
Java bytecode veriﬁcation.
It also entails other ancillary
safety properties such as checking the number and types of
function call arguments.
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
A prototype certifying compiler for the Scheme language
to Intel Architecture (x86) machine code and a correspond-
ing veriﬁer have been developed [6].
The system does not rely on general theorem provers
or typing mechanisms. Although less ﬂexible than other
language-based approaches such as PCC or TAL [18, 12],
certiﬁcates are compact and easy to produce and to verify.
The certiﬁcate can be produced by the code supplier dur-
ing the code generation phase of compilation and veriﬁed
by the consumer at load time. Both operations can be made
automatic and invisible to both parties.
Drawbacks to ECC include platform-dependence and
fragility with respect to compiler optimization. Simple lo-
cal optimizations such as tail recursion elimination can be
handled. Preliminary experiments indicate that the sizes of
the certiﬁcates produced by the ECC prototype range from
6% to 25% of the size of the object code. This seems to in-
dicate a substantial improvement over PCC, although a fair
comparison would require a more careful analysis to take
all variables into account. The veriﬁcation process is very
efﬁcient. It is linear time except for a sorting step to sort
jump destinations, but since almost all jumps are forward
and local, a simple insertion sort sufﬁces.
4. The BootSafe System