title:Structural Data De-anonymization: Quantification, Practice, and Implications
author:Shouling Ji and
Weiqing Li and
Mudhakar Srivatsa and
Raheem A. Beyah
Structural Data De-anonymization: Quantiﬁcation,
Practice, and Implications
School of Electrical and Computer Engineering
School of Electrical and Computer Engineering
Shouling Ji
Weiqing Li
Georgia Institute of Technology
PI:EMAIL
Mudhakar Srivatsa
IBM T. J. Watson Research Center
PI:EMAIL
Georgia Institute of Technology
PI:EMAIL
Raheem Beyah
Georgia Institute of Technology
PI:EMAIL
School of Electrical and Computer Engineering
ABSTRACT
In this paper, we study the quantiﬁcation, practice, and
implications of structural data (e.g., social data, mobility
traces) De-Anonymization (DA). First, we address several
open problems in structural data DA by quantifying per-
fect and (1 − ϵ)-perfect structural data DA, where ϵ is the
error tolerated by a DA scheme. To the best of our knowl-
edge, this is the ﬁrst work on quantifying structural data DA
under a general data model, which closes the gap between
structural data DA practice and theory. Second, we con-
duct the ﬁrst large-scale study on the de-anonymizability of
26 real world structural datasets, including Social Networks
(SNs), Collaborations Networks, Communication Networks,
Autonomous Systems, and Peer-to-Peer networks. We also
quantitatively show the conditions for perfect and (1 − ϵ)-
perfect DA of the 26 datasets. Third, following our quantiﬁ-
cation, we design a practical and novel single-phase cold start
Optimization based DA (ODA) algorithm. Experimental
analysis of ODA shows that about 77.7%−83.3% of the users
in Gowalla (.2M users and 1M edges) and 86.9% − 95.5% of
the users in Google+ (4.7M users and 90.8M edges) are de-
anonymizable in diﬀerent scenarios, which implies optimiza-
tion based DA is implementable and powerful in practice.
Finally, we discuss the implications of our DA quantiﬁcation
and ODA and provide some general suggestions for future
secure data publishing.
Categories and Subject Descriptors
C.2.0 [General]: Security and protection; H.4 [Information
Systems Applications]: Miscellaneous; G.3 [Probability
and Statistics]: Stochastic processes
General Terms
Security, Privacy, Theory, Management
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660278.
Keywords
De-anonymization; structural data; quantiﬁcation; evalua-
tion; social networks; mobility traces
1.
INTRODUCTION
Nowadays, a large amount of data generated by comput-
er networks and services have a graph structure, which is
referred to as structural data. For instance, it is straight-
forward to model Social Networks (SNs), network topolo-
gies, etc. by graphs [2][5][6][26]. Additionally, mobility
traces (e.g., WiFi contacts, Instant Message contacts) can
also be modeled as graphs (structural data) [3]. Even gen-
eral spatiotemporal data (mobility traces) with the classi-
cal (latitude, longitude, timestamp) format can be convert-
ed to structural data by applying sophisticated techniques
[27]. Since these structural data have huge commercial value
to businesses and potentially signiﬁcant impacts to society
[28][29], the security and privacy issues that arise during da-
ta release to the public, sharing with commercial partners,
and/or transferring to third parties are attracting increasing
interest [1][2][3].
Currently, to protect structural data’s privacy, the most
common technique used is to anonymize data by remov-
ing the “Personally Identiﬁable Information (PII)” before
releasing data. Unfortunately, this naive method is shown
to be vulnerable to many De-Anonymization (DA) attacks
[6][7][8]. Latterly, some sophisticated anonymization schemes
to protect structural data privacy, e.g., k-anonymity and its
variants [6][7][8], were designed1. They can protect the pri-
vacy of structural data to some extent. However, they are
susceptible to emerging structure based DA attacks due to
the limitations of the schemes (e.g., they are syntactic prop-
erties based) and the rich amount of information available
to adversaries [1][2][3] (see the detailed analysis in Section
2).
In structure based DA attacks, some auxiliary data (graph-
s) are employed to break the privacy of anonymized struc-
tural data based only on the structural information. The fac-
t that the auxiliary data may come from either the same or
a diﬀerent domain/context with the anonymized data makes
1Also, diﬀerential privacy [9] was developed to protect
the privacy of interactive data release. However, it cannot
defend against structural data DA attacks which breach the
privacy of non-interactive data release [2][3][8][9].
the attack powerful, e.g., using Flickr to de-anonymize Twit-
ter [2], using Facebook to de-anonymize WiFi mobility traces
[3]. Furthermore, the wide availability of auxiliary data
makes the attack applicable and practical [2][3].
Structure based DA attacks were initially presented in [1],
where Backstrom et al. designed both active and passive at-
tacks to break the privacy of SN users. However, since the
attacks in [1] leverage the success of a “sybil” attack before
actual anonymized data publication, they are less practical.
Later, Narayanan and Shmatikov designed a new structure
based DA attack in [2], which successfully de-anonymized
a large scale directed social network by applying several
heuristics such as eccentricity, edge directionality, reverse
match.
In [3], Srivatsa and Hicks demonstrated that the
privacy of three kinds of mobility traces can be compro-
mised by structure based DA attacks. However, the attack-
s presented in [3] are only suitable for small datasets due
to the computational infeasibility of ﬁnding a proper land-
mark mappings for large datasets. Furthermore, each of the
aforementioned attacks consist of two phases: a landmark
identiﬁcation phase and a DA propagation phase.
Although we already have some successful structure based
DA techniques [1][2][3], we do not have any rigorous theo-
retical analysis under a general model yet that explains why
structure based DA attacks work.
In [5], Pedarsani and
Grossglauser quantiﬁed the privacy of anonymized struc-
tural data under the Erd¨os-R´enyi (ER) random graph mod-
el G(n, p) (every edge exits with identical probability p).
However, this quantiﬁcation is not suitable in practice since
most, if not all, observed real world structural data (e.g.,
SNs, collaboration networks [21][22][26]) do not follow the
ER model. Actually, they may follow the power-law mod-
el, exponential model, etc.
[21][22][26]. Therefore, under a
practical general data model, there are still some open ques-
tions in DA research, including: why can structural data
be de-anonymized ? what are the conditions for successful
structural data DA? and what portion of users can be de-
anonymized in a structural dataset? To close the practice-
theory gap, we study the quantiﬁcation, practice, and im-
plications of structural data DA in this paper. Speciﬁcally,
our contributions are as follows.
• To the best of our knowledge, this is the ﬁrst work on
quantifying structural data DA under a general data
model. In our quantiﬁcation, we answer several fun-
damental open questions: why can structural data be
de-anonymized based only on the topological informa-
tion (the inherent reason for the success of existing
structure based DA practices)? what are the condi-
tions for perfect and (1 − ϵ)-perfect DA, where ϵ is the
error tolerated by a DA scheme? what portion of users
can be de-anonymized in a structural dataset? Thus,
we close the gap between structural data DA practice
and theory.
• We conduct the ﬁrst large-scale study on the de-anonymiz-
ability of 26 real world structural datasets, including
SNs, location based mobility traces and SNs, collabo-
ration networks, communication networks, autonomous
systems, peer-to-peer networks, etc. Based on our s-
tudy, we ﬁnd that all the structural datasets that we
considered are perfectly or partially de-anonymizable.
We also quantitatively show the conditions for perfect
and (1 − ϵ)-perfect DA and what portion of users can
be de-anonymized for the 26 datasets.
• Following our quantiﬁcation, we present a novel Opti-
mization based DA (ODA) attack. Diﬀerent from ex-
isting structure based DA attacks [1][2][3], ODA is a
single-phase cold start algorithm without any require-
ment on priori knowledge, e.g., landmark mappings.
We also examine ODA on real datasets Gowalla (.2M
users and 1M edges) and Google+ (4.7M users and
90.8M edges). The results demonstrate that about
77.7% − 83.3% of the users in Gowalla and 86.9% −
95.5% of the users in Google+ are de-anonymizable,
which illustrates that optimization based DA is imple-
mentable and powerful in practice.
• Finally, we discuss some implications of this work ac-
cording to our structural DA quantiﬁcation and the
ODA attack. We further provide some general sugges-
tions for future secure data publishing.
The rest of this paper is organized as follows. In Section
In Section 3, we give
2, we summarize the related work.
the data and attack models. In Section 4, we theoretically
quantify perfect and (1− ϵ)-perfect DA attacks under a gen-
eral model, followed by a large-scale evaluation in Section
5. In Section 6, we present a novel optimization based DA
attack. We discuss the implications in Section 7. The paper
is concluded and future work is addressed in Section 8.
2. RELATED WORK
In this section, we ﬁrst brieﬂy survey the state-of-the-
art advances of security issues related to structural data.
Subsequently, we discuss the status quo on structural data
anonymization and DA followed by remarking the charac-
teristics that distinguish this paper from existing works.
2.1 State-of-the-Art Advances
Recently, the security and privacy issues related to struc-
tural data have attracted the interest of many researchers
[1]-[20]. In [10], Korolova et al. presented an attack on link
privacy in SNs. Another attack using link-based and group-
based classiﬁcation to study privacy implications in SNs is
discussed in [11] by Zheleva and Getoor. Based on four
previously unrecognized implicit identiﬁers, Pang et al. de-
veloped an automated procedure to identify users in 802.11
traces [12].
In [13], Backstrom proposed an algorithm to
predict users’ location using SN information. On the oth-
er hand, multiple strategies have been developed to protec-
t people’s privacy in SN systems and related applications,
e.g., pseudonym abstraction [14], decentralized protocols for
anonymous communications [15], guaranteed data lifetime
[16], compromised accounts detection [17], privacy preserv-
ing SN applications [18].
In addition, location based ser-
vices, especially those in smartphone-based SN applications,
have created big commercial beneﬁts. However, on the other
hand, the publicly availability of users’ mobility trace data
causes a potentially serious threat to users’ privacy and even
themselves [3][19][20].
2.2 Structural Data Anonymization and DA
2.2.1 Anonymization Schemes
To protect the privacy of structural data, the most com-
mon method is removing the PII [1][2][3]. However, this
widely used naive solution is proven to be vulnerable to
many DA attacks [6][7][8]. Later, researchers proposed some
sophisticated data anonymization solutions, e.g., k-anonymity
and its many variants [6][7][8]. These solutions do work to
protect users’ privacy against semantics based DA attacks to
some extent. However, according to recent empirical studies
[2][19], these solutions fail against emerging structure based
DA attacks. Some of the reasons are as follows. First, the
adversaries may obtain much richer auxiliary information
through multiple channels, e.g., data mining, advertising,
third-party applications, data aggregation. [1][2][3][4]. Sec-