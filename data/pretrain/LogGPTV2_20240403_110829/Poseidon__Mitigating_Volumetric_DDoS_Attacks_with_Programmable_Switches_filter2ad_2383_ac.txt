needed functions across the switches and the servers for
effective defense. At a high level, POSEIDON ﬁrst constructs a
directed graph of defense primitives, and computes an optimal
placement of the graph by solving several sets of constraints.
A. Analysis of Defense Primitives
As described before, POSEIDON has three classes of de-
fense primitives: a) monitors collect statistics over the network
trafﬁc (e.g., lines 1–2 in Fig. 4), b) actions specify the defense
decisions taken on a particular kind of packets (e.g., lines 5, 7,
and 9 in Fig. 4), and c) branches express the control ﬂow of
the defense (e.g., lines 4, 6, and 8 in Fig. 4). Before delving
into the details about primitive placement, we describe how
POSEIDON supports each kind of primitives, and how much
resource each primitive requires on the switch and/or server.
TABLE II contains a summary.
Monitors. The detection of DDoS attacks relies on collecting
trafﬁc statistics over packet headers. The monitors in PO-
SEIDON can be fully implemented in the switches for these
purposes. Under the hood, POSEIDON implements the monitors
using sketches [88], which are resource-efﬁcient data structures
that can approximate the needed statistics with well-known
error bounds. Instead of storing precise per-ﬂow information,
a sketch uses hash functions to compute several indexes of a
ﬂow ID, and then accesses the corresponding values in register
arrays. All these operations can be performed at line rate. A
sketch requires two match-action tables, one for hashing a key
(e.g., a ﬂow ID) to compute the indexes to the register arrays,
and another for updating the values in the arrays using stateful
ALUs. Since the index is computed by hashing the packet
header ﬁelds, it is unavoidable that different packet headers
may be mapped to the same index, resulting in collisions.
Nevertheless, it has been shown that the resulting error bound
is small enough to be practical for DDoS defense [27], [43].
Speciﬁcally, our count(P ,(cid:126)h, every) and aggr(P ,(cid:126)h, every)
primitives are implemented using a) count-min sketches [18] as
the primary data structure, and b) a match-action table to select
packets based on the given predicate P. To maintain timing-
related information for count and aggr, similar as NetHCF [6],
we use two register arrays in the switch SRAM. One array C
records information about the current time period, and another
P stores information about the most recent period in the past.
When packets come in, the ﬁrst array is updated to collect the
statistics; at the end of a period, we copy the content of C to
P using the switch control plane.
1
2
3
4
5
6
6
TABLE II: Implementation details and resource utilization of POSEIDON primitives.
Primitives
monitors
count(P , (cid:126)h, every) match-action entry +
Switch Component
count-min sketch
aggr(P , (cid:126)h, every) match-action entry +
count-min sketch
Switch Resource Usage
stages: 2, hash functions: (cid:100)log1/2 δ(cid:101), stateful ALUs: 6, SRAM: for the φ biggest
elements in a set, in order to achieve a relative error bound of ε with probability δ,
usage = 64(cid:100)log1/2 δ(cid:101)
stages: 2, hash functions: (cid:100)log1/2 δ(cid:101), stateful ALUs: 6, SRAM: for the φ biggest
elements in a set, in order to achieve a relative error bound of ε with probability δ,
usage = 64(cid:100)log1/2 δ(cid:101)
εφ
εφ
Server Component
N/A
N/A
N/A
N/A
N/A
N/A
CAPTCHA
aggregation
actions
drop
pass
rlimit
sproxy
puzzle
log
branches
if . . . else . . .
ﬂow entry
ﬂow entry
meter + ﬂow entry
proxy +
handshake
session relay
-
selecting, grouping
stages: 1, hash functions: 0, stateful ALUs: 0, SRAM: negligible
stages: 1, hash functions: 0, stateful ALUs: 0, SRAM: negligible
stages: 3, hash functions: 1, stateful ALUs: 0, SRAM: in order to achieve a false
positive rate of ε, usage =
stages: 3, hash functions: 2, stateful ALUs: 4, SRAM: in order to achieve a false
positive rate of ε, usage =
-
stages: 3, hash functions: 2, stateful ALUs: 2, SRAM: in order to achieve a false
positive rate of ε, usage =
ln(1/(1−ε))
ln(1/(1−ε))
32n
8n
32n
ln(1/(1−ε))
tag-based match action
stages: 1, hash functions: 0, stateful ALUs: 0, SRAM: negligible
N/A
Actions. POSEIDON has a set of defense primitives that take
actions on network trafﬁc based on the statistical results.
POSEIDON’s framework is general enough to capture a range
of defense actions, including a) the class of defenses that can
be supported entirely in the switch (“switch only”), b) the
class of defenses that require some level of server involvement
(“switch assisted”), and c) the class of defenses that needs to
run entirely on the servers (“server only”). Defenses in switch-
only class can ﬁt into the programming model of the switching
ASIC. The current version of POSEIDON supports drop, pass—
which can be mapped to the corresponding match-action table
entries easily, as well as rlimit and sproxy—which are more
complex and require more resources in the switch pipeline;
this set can be easily extended to include more defenses.
Switch-assisted defenses need to be carefully partitioned
into two separate components: a switch component that is
ofﬂoaded to hardware, and a server component that runs in
software. POSEIDON aims to carve out as much as logic
possible for hardware ofﬂoading, since this would translate to
higher performance. For instance, consider the log primitive
with three steps. It ﬁrst selects the kind of trafﬁc to be logged,
then groups the packets of interest based on certain keys
(e.g., ﬂow IDs), and ﬁnally aggregates the results for logging.
Similar as Marple [55] and *Flow [75], POSEIDON uses match-
action tables to implement the select step, uses stateful registers
to group the results, and performs the aggregation step on
servers since it involves more complex logic. In this example,
the servers only need to do minimal amount of work, since the
switch component has ﬁltered out most of the irrelevant data.
Server-only defenses require sophisticated actions that go
beyond the capability of the switching ASIC, such as those that
require complex arithmetic operations, loops, or application-
layer processing. Ofﬂoading these operations to the switch
is not possible at least with today’s switching hardware. A
representative case is puzzle [37], [82], [38], which is often
used to defend against HTTP-based ﬂood. Puzzle forces each
client to solve a cryptographic puzzle (e.g., graphical puzzles)
for each request before the server provides its resources,
thereby imposing a large computational task on attackers bent
on generating legitimate service requests to consume server
resources. We use CAPTCHA as an implementation of puzzle.
Policy declaration. First, DDoS defense usually takes different
actions for different types of trafﬁc, and this can be supported
using branches to specify the control ﬂow. An if . . . else . . .
branch could be implemented as a tag-based match-action
table, which classiﬁes incoming packets that match different
predicates using different tags. For example, in Fig. 4, we
generate different tags for packets that satisfy different pred-
icates, e.g., tags 1, 2, and 3 for the predicates in lines 4, 6,
and 8, respectively. Each branch is then mapped into a tag-
based match-action entry, and the following code block would
identify the packets based on their tags. Second, composition
operator | are very useful when operators want to compose
multiple policies, which allows operators to apply different
polices to different packet group together. Currently, if two
policies have different actions for the same packet, we simply
adopt the stricter one. For example, if policy 1 would like to
drop the incoming packet while policy 2 lets it pass, we will
drop it ﬁnally.
Flow afﬁnity. In addition, some defenses need to be state-
ful and have bidirectional semantics. For example, sproxy
requires that the inbound and outbound trafﬁc of the same
ﬂow are always steered to the same instance; similarly, DNS
requests and responses should also be processed by the same
instance. To achieve this, we design our hash function as
hash1(pkt.src) + hash2(pkt.dst), in which way exchanging
source and destination ﬁelds does not affect the ﬁnal hash
value.
B. Placing Defense Primitives
Next, we describe the algorithm that POSEIDON uses to
place the various defense primitives to the network.
Similar as [36], [72], POSEIDON extracts a graph structure
from the defense policy, where the nodes are the defense
primitives and the edges represent
the trafﬁc ﬂow. Note,
however, each defense primitive has self-contained state, and
for modularity,
it does not expose internal states to other
7
Output. We deﬁne X j
p,n = 1 if and only if the n-th node of the
p-th program starts at the j-th stage of the “abstracted” switch
(i.e., a path of switches), otherwise X j
p,n = 0. So for each
program P, the last node on the switch would be LastNp =
N X j
p,n. As a result, our objective can be written as
(cid:80)
(cid:80)
J
(cid:88)
n=LastNp(cid:88)
max
Tp,n
(1)
Fig. 7: SYN ﬂood defense graph.
P
n=1
primitives explicitly. Therefore, POSEIDON uses a topological
sort to transform the graph into an ordered list of primitives.
For instance, as shown in Fig. 7, the graph for syn ﬂood
defense could be transformed into a list of nodes 1(cid:13) 2(cid:13) 3(cid:13) 4(cid:13) 5(cid:13).
When there are multiple defenses that need to be deployed in
conjunction, POSEIDON would obtain a list of primitives for
each. It then computes the resource usage of the primitives
based on the analysis in §V-A, and uses the information for
placement.
POSEIDON then places the lists of nodes into the network,
including programmable switches and commodity servers.
Since programmable switches can achieve orders of magnitude
higher performance, our goal for our placement is to maximize
the amount of processing ofﬂoaded to the switches. Of course,
the resource limitations of the switches pose constraints to
our problem, most prominently in terms of the number of
stages in a switch, and the amount of SRAM (for registers)
and stateful ALUs per stage. Our placement algorithm takes
these constraints into account while optimizing for maximal
ofﬂoading.
increased to S =(cid:80)
To reduce the switch-server trafﬁc transfer, the placement
algorithm partitions each list once and only once—the ﬁrst
part is ofﬂoaded to the switch and the second to the servers. To
mitigate the resource limitations of a single switch, POSEIDON
can also leverage resources from multiple switches for process-
ing. Concretely, several switches can be organized together
sequentially, which can provide more processing stages and
memory resources as trafﬁc ﬂows through. This effectively
abstracts a path that consists of multiple switches into a much
larger switch—for instance, the number of usable stages has
switch N umstage. As future work, we are
also planning to support parallelism across multiple paths. The
sequential and parallel placement can also be used together to
achieve even higher performance. POSEIDON then formulates
the placement problem as an Integer Linear Program (ILP).
Input. Assume that POSEIDON needs to place P defense
programs, and that each program has Np nodes. We further
assume that the estimated volume of each type of attacks is
available to POSEIDON with a certain expected error probabil-
ity. Using the above information, we can compute the switch
resources each defense primitive would require. We use the
following notations for the various types of resources: for the
n-th node of program p, it uses a stage count of ST AGEp,n,
SRAM in the tth stage SRAMp,n,t, and the stateful ALUs
in the tth stage ACT IONp,n,t (1 ≤ t ≤ ST AGEp,n).
Furthermore, the amount of trafﬁc after passing through this
node is Tp,n. Every node in the processing would reduce the
trafﬁc volume, so that the amount of trafﬁc received by the
servers would be minimized.
Constraints. There are several types of constraints that we
need to consider.
Register memory per stage. For each stage, the amount of
SRAM allocated for packet processing cannot exceed SRAM.
Thus we have
∀j, t,
SRAMp,n,t · X j
p,n ≤ SRAM
(cid:88)
(cid:88)
(2)
P
N p
Number of stateful ALUs per stage. Similarly, for each
stage, the total number of stateful ALUs allocated for packet
processing cannot exceed ACT ION. Thus we have
∀j, t,
ACT IONp,n,t · X j
p,n ≤ ACT ION (3)
(cid:88)
(cid:88)
P
N p
Number of stages. The total number of stages for all
defense programs cannot exceed the upper limit of stage count
S. Here, we use Zp,n to denote the start stage of node n
for program p. Zp,n and X j
p,n = 1, then
Zp,n = j. Then we have
p,n are related: if X j
∀p, n, Zp,n + ST AGEp,n ≤ S
(4)
Node ordering. The placement should respect the ordering
of the nodes, i.e., for each program P , if the node n1 precedes
node n2, then the start stage of node n1 should appear earlier
than the start stage of node n2 subtracting ST AGEp,n1. Then
we have
∀p, if n1 < n2, Zp,n1 + ST AGEp,n1 < Zp,n2
(5)
Using the above constraints, we can solve the 0-1 Integer
Linear Programming (ILP) problem and obtain the optimal
placement using existing optimization toolboxes [31]. The
result would specify which primitives should be placed in the
switch, as well as the amount of allocated resources to each
primitive.
VI. HANDLING DYNAMIC ATTACKS
Next, we discuss how POSEIDON handles dynamic attacks
at runtime. To ensure defense correctness, we need to replicate
state in the programmable switches and use server memory
as a temporary store. When a switch is being reconﬁgured
with a new P4 program,
trafﬁc is steered to the relevant
servers that contain defense state for processing. To achieve
this, POSEIDON uses a central controller to coordinate the
switches and the servers (see Fig. 9). During a policy update,
the controller generates a new defense strategy, i.e., deploying
a new P4 program to the switches and a new conﬁguration
for the servers. The new P4 program would be loaded to
the switches directly, replacing the previous defense strategy.
8
syn_countack_countsproxydroppassunknownattackbenign①②③④⑤Fig. 8: Format of the state replication packets.
During this update, ﬂows are sent to the relevant servers for
processing. The servers always implement logic for all types
of defenses, but the switch-only defenses are never activated
unless in this transition state. In order to replicate state at
runtime, there are several issues that need to be solved for
efﬁcient and consistent replication.
States requiring replication. An intuitive approach is to
identify all states using program analysis techniques [41], [45]
(e.g., the registers in P4), and replicate these states to servers
when they are modiﬁed. However, on one hand, some states
can be automatically recovered after the trafﬁc is steered to the
servers, which means replicating these states is not necessary.
On the other hand, some states are no longer useful when an
attack ﬁnishes, such as monitor statistics, so they do not need to
be replicated. Our principle here is to identify the states which
will still take effect for legitimate trafﬁc even when attacks