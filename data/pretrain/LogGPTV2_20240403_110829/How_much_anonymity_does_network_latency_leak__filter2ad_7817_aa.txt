title:How much anonymity does network latency leak?
author:Nicholas Hopper and
Eugene Y. Vasserman and
Eric Chan-Tin
How Much Anonymity does Network Latency Leak?
Nicholas Hopper, Eugene Y. Vasserman, Eric Chan-Tin
University of Minnesota
200 Union St SE
Minneapolis, MN 55455 USA
{hopper, eyv, dchantin}@cs.umn.edu
ABSTRACT
Low-latency anonymity systems such as Tor, AN.ON, Crowds,
and Anonymizer.com aim to provide anonymous connections
that are both untraceable by “local” adversaries who control
only a few machines, and have low enough delay to sup-
port anonymous use of network services like web browsing
and remote login. One consequence of these goals is that
these services leak some information about the network la-
tency between the sender and one or more nodes in the sys-
tem. This paper reports on three experiments that partially
measure the extent to which such leakage can compromise
anonymity. First, using a public dataset of pairwise round-
trip times (RTTs) between 2000 Internet hosts, we estimate
that on average, knowing the network location of host A
and the RTT to host B leaks 3.64 bits of information about
the network location of B. Second, we describe an attack
that allows a pair of colluding web sites to predict, based on
local timing information and with no additional resources,
whether two connections from the same Tor exit node are
using the same circuit with 17% equal error rate. Finally,
we describe an attack that allows a malicious website, with
access to a network coordinate system and one corrupted
Tor router, to recover roughly 6.8 bits of network location
per hour.
Categories and Subject Descriptors
C.2.0 [Computer Networks]: General—Security and pro-
tection; K.4.1 [Computers and Society]: Public Policy
Issues—Privacy; E.3 [Data]: Encryption
General Terms
Security, Latency, Anonymity, Measurement
1.
INTRODUCTION
The goal of every anonymous communication scheme is
to allow users to communicate while concealing informa-
tion about who communicates with whom. The notion of
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010 ...$5.00.
anonymous communication schemes was ﬁrst introduced by
Chaum [5], who proposed sending messages through a “Mix
server” that mixes together messages from several senders
before forwarding these messages to their destinations, con-
cealing the relationships between senders and receivers. Since
then, a wide variety of anonymity schemes have been pro-
posed, yet all practical, deployed schemes rely to some extent
on this idea of forwarding messages through “mixing” relays.
Current, widely-used anonymity schemes can be catego-
rized as either high- or low-latency. High-latency systems
like Mixmaster and Mixminion [10, 25] deliver messages at
a signiﬁcant delay - around 4 hours, on average - with the
goal of ensuring anonymity against a strong adversary that
can see all network traﬃc and control some nodes partici-
pating in the anonymity scheme. In order to ensure secu-
rity against this type of adversary, these schemes implement
countermeasures that increase delay, such as pool mixing,
and consume additional bandwidth, such as cover traﬃc.
There is a wide range of literature [11, 12, 22] on how to fur-
ther strengthen such high-latency systems against various
types of attacks.
In contrast, low-latency protocols such as Tor [13], I2P [21],
AN.ON [15], Crowds [31], Anonymizer.com, and various com-
mercial proxy aggregators, actively seek to limit process-
ing delay and bandwidth overhead. Providing low-delay
anonymity enables anonymous use of more interesting appli-
cation services such as remote login and web browsing, but
this functionality comes at the cost of reduced anonymity
guarantees.
In particular, most of these services are eas-
ily defeated by a global passive adversary using relatively
straightforward attacks such as packet counting [34]. Fur-
thermore, using these same attacks, an adversary that con-
trols fraction f of the nodes in the system can trace fraction
f of the connections made to colluding servers and fraction
f 2 of all connections running through the system [36]. Thus,
these systems focus on oﬀering security against a “local” ad-
versary, such as a small coalition of malicious servers that
see only their own network traﬃc.
A “local” adversary is thus extremely limited, since he is
unlikely to have access to any traﬃc of interest before it exits
the anonymity service and arrives at his malicious servers.
A natural question to ask is: What information, outside of
the actual bits of data packets delivered to the adversary,
does a low-latency anonymity service leak, and to what ex-
tent does this leakage compromise the anonymity oﬀered by
the service?
Several recent works have explored the impact of the lo-
cal adversary’s access to information about the timing of
82events in a low-latency anonymity scheme, such as packet
arrival times. An example of this is the “circuit clogging”
attack variant of Murdoch and Danezis [27], which relies on
the observation that a sudden increase in the load of a Tor
server will increase the latency of all connections running
through it. Murdoch and Danezis show how a corrupt Tor
node and web server can exploit this property to determine
the nodes in a Tor circuit, i.e., the nodes that forward a
given connection through the network.
In the attack, the
corrupt Tor node regularly sends packets on a loop through
each Tor server, measuring the time the packets spend in
transit. Then when the malicious server wishes to trace a
connection, it modulates its throughput in a regular, on/oﬀ
burst pattern. By correlating the delay at each Tor server
against the timing of these burst periods, the attacker learns
which nodes are in the circuit. Since the estimated number
of Tor users (on the order of 105 as of April 2007) is less
than the number of possible circuits (on the order of 108)
seeing two connections that use the same circuit nodes is
a strong indicator that the connections are from the same
user. Thus at a minimum, timing information can leak the
linkage between Tor connections.
In this paper, we make use of a similar observation: mali-
cious servers acting as local adversaries can observe the net-
work latency of a connection made over a Tor circuit. While
it has been suggested before that this information might be a
potential avenue of attack [3], we are not aware of any work
reporting on the feasibility of performing an attack using
this information, or even suggesting a concrete attack mech-
anism. As a consequence, it was not known whether leaking
this information had any adverse eﬀect on the anonymity
provided by schemes like Tor. We address this issue by re-
porting on three experiments that measure the extent to
which this information leakage compromises the anonymity
of clients using a low-latency anonymity scheme:
• Analysis of noise-free anonymity leakage. Suppose
that an anonymity service could impose no delay at all on
a circuit, so that the only diﬀerence between a client con-
necting to a server normally and over the anonymity service
would be that in the latter case, the client’s IP address is
somehow missing. This would represent the best possible
case for an attack based solely on round-trip time (RTT)
information. We analyzed the publicly available MIT King
data set [17], a collection of pairwise RTTs between 1950 In-
ternet hosts, to estimate the average amount of information
that is leaked by knowing the RTT between a given host and
an unknown host. We found that, on average, knowing the
RTT to a host from one known server yields 3.64 bits of in-
formation about the host (equivalently, reduces the number
of possible hosts from n to n/23.64 ≈ 0.08n).
Of course, many hosts on the Internet will be essentially
indistinguishable by RTTs since they are located on the
same subnet; without a more detailed study it is diﬃcult
to estimate the number of such equivalence classes. A rea-
sonable estimate would seem to be the number of routable
IP address preﬁxes, currently around 200, 000, or about 218.
Thus on average, we estimate that an Internet host can be
uniquely identiﬁed, up to RTT equivalence, by knowing its
RTT to 5 other (randomly chosen) hosts. (Further work is
necessary to more precisely determine the extent to which
conditional entropy decreases with each measurement.)
• A passive linkability attack. When latency “noise” is
introduced in the form of additional delays due to forward-
ing and mixing with other streams, it is no longer clear how
to use latency or RTT information to identify anonymous
clients. We observe that even in this scenario, if a client
attempts to connect to two malicious servers (or make two
connections to the same malicious server) using the same cir-
cuit, then the server-client RTTs of these connections (mi-
nus the RTT from the last node to the server) will be drawn
from the same distribution, whereas other clients connecting
to the server will have diﬀerent RTTs.
Based on this observation, we develop an attack on Tor
that allows two colluding web servers to link connections
traversing the same Tor circuit. The attack uses only stan-
dard HTTP, the most commonly mentioned Tor application
layer, and requires no active probing of the Tor network and
has very minimal bandwidth requirements. Thus it can be
seen as a “lower cost” alternative to circuit clogging.
We report on an implementation and test of this attack us-
ing several hundred randomly chosen pairs of clients and ran-
domly chosen pairs of servers from the PlanetLab wide area
testbed [6], communicating over the deployed Tor network.
Our results suggest that we can classify pairs of connections
with an equal error rate of roughly 17%, and the test can be
tuned to support a lower false positive or false negative rate.
• An active client-identiﬁcation attack. Finally, we
show how latency information can be used to extend the
reach of the Murdoch-Danezis clogging attack, allowing a
malicious server to take advantage of repeated visits from a
client to gradually locate the client, up to RTT equivalence.
As with the clogging attack, our attack requires minimal
resources – one corrupted Tor server, plus access to a “la-
tency oracle” that can be used to estimate RTTs between
Tor servers and nodes in the RTT equivalence class of a sus-
pected client’s location – and uses only standard protocols.
We show that a latency oracle can be implemented with a
“network coordinate system,” [7,8,28] which could be imple-
mented using publicly available resources such as the Scrip-
tRoute [35] service or traceroute.org.
We evaluate our attack using over 200 runs with randomly
chosen client/server pairs from the PlanetLab wide area
testbed, using randomly chosen circuits among the currently
deployed Tor nodes (as of Jan./Feb. 2007). Our results sug-
gest that a malicious server with a periodically reloading
web page can recover, on average, about 6.8 bits of informa-
tion about a client’s location per hour. Thus a client’s RTT
equivalence class can be determined in 3 hours, on average.
We stress that both attacks are tested under real-world
conditions against the deployed Tor network using a stan-
dard protocol (HTTP), and very little has been done to op-
timize these attacks for speed or accuracy. It is our expecta-
tion that we could make improvements in both of these cat-
egories by using less widely-supported tools, such as persis-
tent HTTP over Tor. This would improve the performance
of the attack, while simultaneously limiting its scope; we
leave further investigations along these lines for future work.
These results have serious implications for the design of
low-latency anonymity schemes. In particular, they suggest
that, without new ideas for path selection, adding delay to a
connection may be unavoidable for security considerations.
In turn, this has implications for design decisions: for exam-
ple, if latency must be uniformly high, then TCP tunneling
over such services will provide extremely low bandwidth; or
if the latency of circuits can be masked with noise in the
short term, then circuit lifetimes may need to be shortened.
The remainder of this paper is organized as follows:
in
section 2, we give an overview of Tor, review the details
of the Murdoch-Danezis attack, and survey related work.
Section 3 presents the results of our analysis on the MIT
King dataset, estimating the average amount of information
leaked by the RTT between two nodes. We present details
of our passive linking attack and its evaluation in section 4,
and more details about our client-identiﬁcation attack in
section 5. Finally, we discuss countermeasures and future
work in section 6.
2. BACKGROUND AND RELATED WORK
2.1 An overview of Tor
Tor is a low-latency and bandwidth-eﬃcient anonymiz-
ing layer for TCP streams. Its growing popularity and the
availability of a test-bed deployment have proven to be a
fertile ground for research on implementing and attacking
low-delay anonymity schemes.
Tor works similarly to a circuit-switched telephone net-
work, where a communication path, or circuit, is ﬁrst estab-
lished, over which all communication during a given session
takes place. Anonymity is achieved by establishing that cir-
cuit through three nodes: an entry node, an intermediary
(middleman), and an exit node. Only the entry node knows
the identity of the client contacting it, in the form of its IP
address. The middleman node knows the identities of both
the entry and exit nodes, but not who the client is or the des-
tination he or she wishes to reach over the circuit. If the Tor
server is an “exit” node, which provides a gateway between
the Tor network and the Internet, it is responsible for making
application-layer connections to hosts on the Internet, and
serves as a relay between potentially non-encrypted Inter-
net connections and encrypted Tor traﬃc. Thus, it knows
the destination with whom the client wishes to communi-
cate, but not the identity of the client. In this manner, no
single node in the Tor network knows the identities of both
communicating parties associated with a given circuit. All
communications proceed through this encrypted tunnel.
Circuits are established iteratively by the client, who gets
a list of Tor nodes and long-term keys from a directory ser-
vice, selects a Tor node from that list (preferably one with
high uptime and bandwidth), negotiates a communication
key, and establishes an encrypted connection. To avoid sta-
tistical proﬁling attacks, by default each Tor client restricts
its choice of entry nodes to a persistent set of three ran-
domly chosen “entry guards”. The circuit is then extended
to additional nodes by tunneling through the established
links. Link encryption, using ephemeral Diﬃe-Hellman key
exchange for forward secrecy, is provided by SSL/TLS. To
extend the circuit to another Tor node, the client tunnels
that request over the newly-formed link.
Traﬃc between Tor nodes is broken up into cells of 512
bytes each. Cells are padded to that size when not enough
data is available. All cells from the client use layered (or
“onion”) encryption, in that if the client wishes for a mes-
sage to be passed to example.com via Tor nodes A, B, and C
(C being the exit node), the client encrypts the message with
a key shared with C, then again with a key shared with B,
and ﬁnally A. The message is then sent over the previously-
established encrypted tunnel to A (the entry node). A will
peel oﬀ a layer of encryption, ending up with a message en-