 20
 15
 10
 5
 0
 0
 0.2
 0.4
 0.6
Coverage (=w)
 0.8
 1
Minimum block size (m) = 40, (ICSI)
 a=40
 a=64
 a=128
 20
 15
 10
 5
 0
 0
 0.2
 0.4
 0.6
Coverage (=w)
 0.8
 1
Minimum block size (m) = 64, (ICSI)
 a=64
 a=128
 20
 15
 10
 5
a=64
a=128
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Coverage (w)
 0
 0
 0.2
 0.4
 0.6
Coverage (=w)
 0.8
 1
Figure 6: Sensitivity and Efﬁciency of Selected Signatures,
ICSI DMZ trace (24 hrs).
Figure 7: Number of Signatures, ICSI DMZ trace (24 hrs).
similar. Note that in these experiments, we apply the signa-
tures Autograph generates from the 24-hour trace to the same
24-hour trace used to generate them.
The x axis varies w. As w increases, the set of signatures
Autograph generates leads to greater sensitivity (fewer false
negatives). This result is expected; greater w values cause Au-
tograph to add content blocks to the signature set for an ever-
greater fraction of the suspicious ﬂow pool. Thus, if a worm
appears rarely in the suspicious ﬂow pool, and thus generates
non-prevalent content blocks, those blocks will eventually be
included in the signature set, for sufﬁciently large w.
However, recall from Figure 5 that about 5% of the suspi-
cious ﬂows are innocuous ﬂows that are misclassiﬁed by the
port-scanner heuristic as suspicious. As a result, for w > 95%,
COPP risks generating a less speciﬁc signature set, as COPP
begins to select content blocks from the innocuous ﬂows.
Those content blocks are most often HTTP trailers, found in
common across misclassiﬁed innocuous ﬂows.
For this trace, COPP with w ∈ [90%,94.8%] produces a set
of signatures that is perfect: it causes 0 false negatives and 0
false positives. Our claim is not that this w parameter value is
valid for traces at different sites, or even at different times; on
the contrary, we expect that the range in which no false posi-
tives and no false negatives occurs is sensitive to the details of
the suspicious ﬂow population. Note, however, that the exis-
tence of a range of w values for which perfect sensitivity and
speciﬁcity are possible serves as a very preliminary valida-
tion of the COPP approach—if no such range existed for this
trace, COPP would always be forced to trade false negatives
for false positives, or vice-versa, for any w parameter setting.
Further evaluation of COPP on a more diverse and numerous
set of trafﬁc traces is clearly required to determine whether
such a range exists for a wider range of workloads.
During examination of the false positive cases found by
Autograph-generated signatures when w > 94.8%, we noted
with interest that Autograph’s signatures detected Nimda
sources not detected by Bro’s stock signatures. There are only
three stock signatures used by Bro to spot a Nimda source,
and the Nimda sources in the ICSI trace did not transmit those
particular payloads. We removed these few cases from the
count of false positives, as Autograph’s signatures correctly
identiﬁed them as worm ﬂows, and thus we had erroneously
ﬂagged them as false positives by assuming that any ﬂow not
caught by Bro’s stock signatures is not a worm.
We now turn to the effect of content block size on the
speciﬁcity and the number of signatures Autograph generates.
Even in the presence of innocuous ﬂows misclassiﬁed as sus-
picious, the largest average and minimum content block sizes
(such as 64 and 128 bytes) avoid most false positives; efﬁ-
ciency remains close to 1. We expect this result because in-
creased block size lowers the probability of ﬁnding common
content across misclassiﬁed ﬂows during the signature gen-
eration process. Moreover, as signature length increases, the
number of innocuous ﬂows that match a signature decreases.
Thus, choosing larger a and m values will help Autograph
avoid generating signatures that cause false positives.
Note, however, there is a trade-off between content block
length and the number of signatures Autograph generates,
too. For large a and m, it is more difﬁcult for COPP to
detect commonality across worm ﬂows unless the ﬂows
are identical. So as a and m increase, COPP must se-
lect more signatures to match any group of variants of a
worm that contain some common content. The graphs in
Figure 7 present the size of the signature set Autograph
generates as a function of w. For smaller a and m, Au-
tograph needs fewer content blocks to cover w percent of
the suspicious ﬂows.
In this trace, for example, COPP
can select a short byte sequence in common across dif-
ferent Nimda payload variants (e.g., cmd.exe?c+dir
HTTP/1.0..Host:www..Connection:
close....) when we use small a and m, such as 16.
The size of the signature set becomes a particular concern
when worms aggressively vary their content across infection
attempts, as we discuss in the next section. Before continuing
on, we note that results obtained running Autograph on the
IRP and ICSI2 traces are quite similar to those reported
above, and are therefore elided in the interest of brevity.
4.2 Polymorphic and Metamorphic Worms
100 random payloads
s
e
r
u
t
a
n
g
S
i
f
o
r
e
b
m
u
N
100
90
80
70
60
50
40
30
20
10
0
8
16
24
32
40
48
64
128
Average Chunk Size (Bytes)
min=8 min=16 min=24 min=32 min=40 min=48
Figure 8: Content block size vs. number of signatures.
We expect short content blocks to be most robust against
worms that vary their content, such as polymorphic worms,
which encrypt their content differently on each connection,
and metamorphic worms, which obfuscate their instruction
sequences on each connection. Unfortunately (fortunately?)
no such Internet worm has yet been reported in the wild. To
test Autograph’s robustness against these varying worms, we
generate a synthetic polymorphic worm based on the Code-
RedII payload. A Code-RedII worm payload consists of a
regular HTTP GET header, more than 220 ﬁller characters,
a sequence of Unicode, and the main worm executable code.
The Unicode sequence causes a buffer overﬂow and transfers
execution ﬂow to the subsequent worm binary. We use ran-
dom values for all ﬁller bytes, and even for the worm code,
but leave the HTTP GET command and 56-byte Unicode se-
quence ﬁxed. This degree of variation in content is more
severe than that introduced by the various obfuscation tech-
niques discussed by Christodorescu et al. [2]. As shown in
Figure 8, when a relatively short, invariant string is present in
a polymorphic or metamorphic worm, Autograph can ﬁnd a
short signature that matches it, when run with small average
and minimum content block sizes. However, such short con-
tent block sizes may be unspeciﬁc, and thus yield signatures
that cause false positives.
5 Evaluation: Distributed Signature Detection
Our evaluation of Autograph in the preceding section focused
chieﬂy on the behavior of a single monitor’s content-based
approach to signature generation. That evaluation consid-
ered the case of ofﬂine signature detection on a DMZ trace
24 hours in length. We now turn to an examination of Au-
tograph’s speed in detecting a signature for a new worm af-
ter the worm’s release, and demonstrate that operating mul-
tiple, distributed instances of Autograph signiﬁcantly speeds
this process, vs. running a single instance of Autograph on
a single edge network. We use a combination of simula-
tion of a worm’s propagation and DMZ-trace-driven simu-
lation to evaluate the system in the online setting; our sense
of ethics restrains us from experimentally measuring Auto-
graph’s speed at detecting a novel worm in vivo.
Measuring how quickly Autograph detects and generates
a signature for a newly released worm is important because
it has been shown in the literature that successfully contain-
ing a worm requires early intervention. Recall that Provos’
results [12] show that reversing an epidemic such that fewer
than 50% of vulnerable hosts ever become infected can re-
quire intervening in the worm’s propagation before 5% of
vulnerable hosts are infected. Two delays contribute to the
total delay of signature generation:
• How long must an Autograph monitor wait until it accu-
mulates enough worm payloads to generate a signature
for that worm?
• Once an Autograph monitor receives sufﬁcient worm
payloads, how long will it take to generate a signature
for the worm, given the background “noise” (innocuous
ﬂows misclassiﬁed as suspicious) in the trace?
We proceed now to measure these two delays.
5.1 Single vs. Multiple Monitors
Let us now measure the time required for an Autograph mon-
itor to accumulate worm payloads after a worm is released.
We ﬁrst describe our simulation methodology for simulat-
ing a Code-RedI-v2-like worm, which is after that of Moore
et al. [9]. We simulate a vulnerable population of 338,652
)
%
i
(
s
e
n
h
c
a
M
d
e
t
c
e
f
n
I
 100
 90
 80
 70
 60
 50
 40
 30
 20
 10
 0
 0
 50
 100
 150
 200
 250
Time (min)
Figure 9: Infection progress for a simulated Code-RedI-v2-
like worm.
hosts, the number of infected source IPs observed in [8] that
are uniquely assignable to a single Autonomous System (AS)
in the BGP table data (obtained from RouteViews [20]) of
the 19th of July, 2001, the date of the Code-Red outbreak.
There are 6378 ASes that contain at least one such vulnera-
ble host in the simulation. Unlike Moore et al., we do not
simulate the reachability among ASes in that BGP table; we
make the simplifying assumption that all ASes may reach all
other ASes. This assumption may cause the worm to spread
somewhat faster in our simulation than in Moore et al.’s. We
assign actual IP address ranges for real ASes from the BGP
table snapshot to each AS in the simulation, according to a
truncated distribution of the per-AS IP address space sizes
from the entire BGP table snapshot. The distribution of ad-
dress ranges we assign is truncated in that we avoid assigning
any address blocks larger than /16s to any AS in the simu-
lation. We avoid large address blocks for two reasons: ﬁrst,
few such monitoring points exist, so it may be unreasonable
to assume that Autograph will be deployed at one, and sec-
ond, a worm programmer may trivially code a worm to avoid
scanning addresses within a /8 known to harbor an Autograph
monitor. Our avoidance of large address blocks only length-
ens the time it will take Autograph to generate a worm sig-
nature after a novel worm’s release. We assume 50% of the
address space within the vulnerable ASes is populated with
reachable hosts, that 25% of these reachable hosts run web
servers, and we ﬁx the 338,652 vulnerable web servers uni-
formly at random among the total population of web servers
in the simulation. Finally, the simulated worm propagates us-
ing random IP address scanning over the entire 228 non-class-
D IP address space, and a probe rate of 10 probes per sec-
ond. We simulate network and processing delays, randomly
chosen in [0.5,1.5] seconds, between a victim’s receipt of an
infecting connection and its initiation of outgoing infection
attempts. We begin the epidemic by infecting 25 vulnerable
hosts at time zero. Figure 9 shows the growth of the epidemic
within the vulnerable host population over time.
s=1 (Max)
s=4 (Max)
s=1 (Median)
s=4 (Median)
 10000
 1000
 100
 10
s
d
a
o
y
a
P
l
f
o
r
e
b
m
u
N
 1
 0
 50
 100
 150
 200
Time (min)
Figure 10: Payloads observed over time: single, isolated
monitors.
In these ﬁrst simulations, we place Autograph monitors at
a randomly selected 1% of the ASes that include vulnerable
hosts (63 monitors). Figure 10 shows the maximum and me-
dian numbers of payloads detected over time across all mon-
itors; note that the y axis is log-scaled. First, let us consider
the case where only a single site on the Internet deploys Au-
tograph on its network.
In this case, it is the median time
required by all 63 monitors to detect a given number of ﬂows
that approximates the expected time for a singleton monitor
to do the same. When monitors identify port scanners aggres-
sively, after a single failed connection from a source address
(s = 1), the median monitor accumulates 5 worm payloads af-
ter over 9000 seconds. Using the more conservative port-scan
threshold s = 4, the median monitor accumulates no payloads
within 10000 seconds. These results are not encouraging—
from Figure 9, we know that after 9000 seconds (150 min-
utes), over 25% of vulnerable hosts have been infected.
Now let us consider the case where 63 monitors are all in
active use simultaneously and distributedly. If we presume
that the ﬁrst monitor to generate a signature for the worm
may (nearly) instantly disseminate that signature to all who
wish to ﬁlter worm trafﬁc, by application-level multicast [1]
or other means, the earliest Autograph can possibly ﬁnd the
worm’s signature is governed by the “luckiest” monitor in
the system—the ﬁrst one to accumulate the required number
q of worm payloads. The “luckiest” monitor in this simu-
lated distributed deployment detects 5 worm payloads shortly
before 4000 seconds have elapsed. This result is far more
encouraging—after 4000 seconds (66 minutes), fewer than
1% of vulnerable hosts have been infected. Thus, provided
that all Autograph monitors disseminate the worm signatures