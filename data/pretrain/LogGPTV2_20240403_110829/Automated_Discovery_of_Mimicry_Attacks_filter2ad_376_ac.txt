– An attacker could transform an attack sequence detected by the program model into
a different sequence that produces the same malicious effect but is allowed by the
model. For example, meaningless nop system calls could be inserted into the attack,
and system calls such as write could be changed to other calls such as mmap. In
previous work, the onus of ﬁnding all attack variants was upon the human.
– This approach poorly handles program models that monitor both system calls and
system call arguments [23, 11]. Identifying nop system calls is not straightforward
when the allowed system call arguments are constrained by the model.
We decouple our approach from the need to know particular system call sequences
that execute attacks. Instead, we observe that regardless of the system call sequence
transformations used by an attacker, their attack will still impart the same adverse effect
upon the operating system. It is precisely this adverse effect that characterizes an attack:
it captures the malicious intent of the attacker. The actual system call sequence used
by the attacker to bring about their intent need not be known a priori, and in fact is
discovered automatically by our system.
To formalize attacks by their effect upon the operating system, we must ﬁrst formal-
ize the operating system itself. Our formalization has three components:
Automated Discovery of Mimicry Attacks
51
– a set of state variables,
– a set of initial assignments to those variables, and
– a set of system call transition relations that alter the state variables.
After developing the deﬁnitions of these components, we ﬁnally deﬁne attack effects.
4.1 State Variables
A collection of state variables model security-critical internal operating system state,
such as user IDs indicating process privilege, access permissions for ﬁles in the ﬁlesys-
tem, and active ﬁle descriptors. A state variable v has a value in the ﬁnite domain
dom(v) which contains either boolean values or integer values.
Deﬁnition 2. The set of all state variables is V . The set of all assignments of values
to variables in V is S. A conﬁguration is a boolean formula over V that characterizes
zero or more assignments.
Model checking algorithms operate over boolean variables; variables in a ﬁnite domain
are simply syntactic sugar and are represented internally as lists of boolean variables.
We additionally allow variables to be aggregated into arrays and C-style structures, both
of which our implementation automatically expands into ﬂat lists of variables.
Consider the example of the operating system’s per-process ﬁle descriptor table. We
abstract this structure as an array of ﬁle descriptors, each of which has a subset of actual
ﬁle descriptor data that we consider relevant to security:
FILEDESCRIPTORTABLE : array [0 .. MAXFD] of FILEDESCRIPTOR
FILEDESCRIPTOR : struct of
INUSE
: boolean
FORFILE
: integer
CANREAD : boolean
CANWRITE : boolean
: boolean
ATEOF
The INUSE ﬁeld indicates whether or not this ﬁle descriptor is active. The remaining
ﬁelds have meaning only for active descriptors. FORFILE is an index into an array of
ﬁle structures, not shown here, that abstract the ﬁle system. CANREAD and CANWRITE
indicate whether the ﬁle descriptor can be used to read or write the ﬁle pointed to by
the FORFILE ﬁeld. ATEOF is true when the ﬁle descriptor’s offset is at the end of the
ﬁle and allows us to distinguish between writes that overwrite data in the ﬁle and writes
that simply append data to the ﬁle.
Identifying what operating system data constitutes “security-relevant state” is cur-
rently a manual operation. Whether the subsequent model checking procedure ﬁnds an
undetected attack or reports that no attack exists, these results hold only with respect
to the chosen OS abstraction. An attack sequence is executable and can be validated
against the real operating system by actually running the attack in a sandboxed envi-
ronment and verifying that it was successful. However, when the model checker ﬁnds
no attack, there is no tangible artifact that may be veriﬁed. If relevant OS data is not
included in the abstraction, then our system may fail to discover a mimicry attack. As
52
J.T. Gifﬁn, S. Jha, and B.P. Miller
setuid (uid t uid)
{
(cid:3) = uid ∧ suid
[uid (cid:2)= −1 ∧ euid = 0 =⇒ ruid
[uid (cid:2)= −1 ∧ euid (cid:2)= 0 ∧ (ruid = uid ∨ suid = uid) =⇒ euid
[uid = −1 ∨ (euid (cid:2)= 0 ∧ ruid (cid:2)= uid ∧ suid (cid:2)= uid) =⇒ true]
(cid:3) = uid ∧ euid
}
(cid:3) = uid]∧
(cid:3) = uid]∧
(1)
(2)
(3)
Fig. 4. Speciﬁcation for the setuid system call. Unprimed variables denote preconditions that
must hold before the system call, and primed variables denote postconditions that hold after the
system call. Any variable not explicitly altered by a postcondition remains unchanged.
a result, the absence of an attack in the abstract OS provides evidence but not a mathe-
matical proof that the model will detect the attack when operating in a real OS.
The initial assignments of values to OS state variables encodes the OS state conﬁg-
uration present when a process is initialized for execution. We write these assignments
as a boolean formula I over the state variables V ; any assignment satisfying I is a
valid initial state. In our work, we developed two different boolean formula for differ-
ent classes of programs. The formula I for setuid root programs set the initial effective
user ID to root; the formula for all other programs set the user ID to a low-privilege
user.
4.2 System Call Transformers
System calls transform the state variables. For each system call, we provide a relation
specifying how that call changes state based upon the previous state.
Deﬁnition 3. Let π be a system call. Recall that V is the set of all OS state variables
and S is the set of all value assignments. The set of parameter variables for π is Λπ
where Λπ ∩ V = ∅. The system call transformer for π is a relation Δπ ⊆ S × S.
In English, each system call transformer produces new assignments of values to OS
state variables based upon the previous values of the OS state. We write each trans-
formation function as a collection of preconditions and postconditions that depend on
parameter variables. Preconditions are boolean formulas over V ∪ Λπ, and postcondi-
tions are boolean formulas over V . If a precondition formula holds before the system
call executes, then the corresponding postcondition formula will hold after the system
call.
Consider the example in Fig. 4. The speciﬁcation for setuid shows that the system
call has one parameter variable of type uid t, which is an integer valued type. The
boolean formula encodes three sets of preconditions and postconditions. From line (1),
if the uid argument is valid and the effective user ID before the setuid call is root, then
after the call, the real, effective, and saved user IDs are all set to the user ID speciﬁed
as the argument to setuid. Implicitly, all other OS state variables remain unchanged by
the call. Line (2) handles the case of a non-root user calling setuid. If either the real or
saved user IDs match the argument value, then the effective user ID is changed to that
value. Again, all other state is implicitly unchanged. Line (3) allows setuid to be used
as a nop transition that does not change OS state when neither the line (1) nor line (2)
Automated Discovery of Mimicry Attacks
53
preconditions hold true. We note that line (3) is redundant and can be omitted from the
setuid speciﬁcation; we show it here only to emphasize the ability of setuid to be used
as a nop.
We now have all components of the operating system abstraction:
Deﬁnition 4. The operating system (OS) model is Ω = (cid:5)V, I, Δ(cid:6) where V is the collec-
tion of OS state variables, I is a boolean formula over V indicating the initial OS state
conﬁguration, and Δ = {Δ1, . . . , Δn} is the collection of system call transformers.
4.3 Attacks
An attack is a sequence of system calls that executes some malicious action against
the operating system. However, these sequences are not unique. Attackers can pro-
duce an inﬁnite number of obfuscated attack sequences by inserting extraneous, nop
system calls into a known sequence and by changing attack system calls into other
semantically-equivalent calls. Manual speciﬁcation of actual attack sequences can be
incomplete, as there may be attack obfuscations not known to the individual specifying
the attacks. We circumvent this problem by specifying the effects of attacks rather than
the sequences themselves.
Deﬁnition 5. An attack effect E is a boolean formula over V .
The formula E characterizes bad operating system conﬁgurations indicative of a suc-
cessful intrusion. It describes the attacker’s intent and the effect of the attack upon the
OS. Any system call sequence A that takes the OS from an initial, safe conﬁguration
satisfying I to a conﬁguration satisfying E is then an attack sequence. If A is allowed
by the program model, than A is an undetected attack.
5 Automatic Attack Discovery
The role of automatic attack discovery is to determine if any system call sequences
accepted as valid execution by a program model will induce an attack conﬁguration E.
Let E be an attack effect. The notation (cid:2)¬E expresses a safety property in linear-
time temporal logic (LTL) that means “globally, E is never true”. A program model M
will detect any attack attempting to induce the effect E if and only if M (cid:3) (cid:2)¬E. That
is, within the executions allowed by M interpreted in the OS model Ω, the attack goal
can never occur. The model checker attempts to prove this formula true. If the proof
succeeds, then the attack goal could not be reached given the system call sequences
allowed by the program model. If the proof fails, then the model checker has discovered
a system call sequence that induces the attack goal.
We consider several examples:
Example 2 (Expanded from Sect. 3 Example 1). First, we ﬁnd attacks that execute a
root-shell undetected by the four models of Fig. 3.
If the attack succeeds, then the executing image ﬁle is /bin/sh and the effective
user ID is 0:
E : image = /bin/sh ∧ euid = 0
54
J.T. Gifﬁn, S. Jha, and B.P. Miller
This boolean expression expresses the effect of the attack rather than any particular
sequence of system calls that produces the effect. Running our tool for each of the four
models shows that none detect the attack, as shown in Sect. 3.3.
Example 3. Next, we try to ﬁnd undetected attacks that write to the system’s password
ﬁle.
If this attack succeeds, then the ﬁle /etc/passwd will have been altered:
E : f ile[/etc/passwd].written = true
The tool automatically ﬁnds a successful attack against the Digraph and NFA models:
read(0);
setreuid(0, 0);
write(0);
stat(0, 0);
open(“/etc/passwd”, O WRONLY | O APPEND) = 3;
mmap(0, 0, 0, 0, 0, 0);
write(3);
The attack sequence ﬁrst sets the effective user ID to root, which then allows the process
to open the password ﬁle and add a new user. The read, stat, mmap, and ﬁrst write
calls are all nops irrelevant to the attack.
Conversely, the tool discovers that the Stide and PDA models will always detect any
attack that tries to alter the password ﬁle. These models accept no system call sequence
that ever has write privilege to the ﬁle /etc/passwd.
Example 4. Finally, we try to ﬁnd undetected attacks that add a new root-level account
to the system and execute a user-level shell, with the expectation that the attacker can
subsequently switch to high privilege via the new account.
This combines elements of Examples 2 and 3:
E : image = /bin/sh ∧ f ile[/etc/passwd].written = true
The system ﬁnds an attack against the Digraph model:
read(0);
setreuid(0, 0)
write(0);
stat(0, 0);
open(“/etc/passwd”, O WRONLY | O APPEND) = 3;
mmap(0, 0, 0, 0, 0, 0);
write(3);
execve(“/bin/sh”);
The system proves that the Stide, NFA, and PDA models all detect this attack regardless
of any attempts to obfuscate a system call sequence. This is evident from the models: al-
though they accept sequences that open and write to a ﬁle, they do not allow subsequent
execution of a different program.
Automated Discovery of Mimicry Attacks
55
Compiler
Pushdown
System
Moped
Model
Checker
Attack Sequence
Fig. 5. Architecture
PDA Program Model
OS State Variables
Initial Configuration
Syscall Specifications
Attack Configuration
6 Implementation
Model checking either proves that an unsafe OS conﬁguration cannot be reached in
a program model or provides a counter-example system call trace that produces the
unsafe conﬁguration. As we are verifying transition systems that may be pushdown au-
tomata, we are limited in implementation options to pushdown model checkers [5, 17].
Moped [18] and Bebop [1] are interchangeable tools that analyze pushdown systems.
Our implementation uses Moped simply because of its public availability.
When a context-sensitive program model is used to verify a stream of system calls
generated by an executing process, we call that model a pushdown automaton (PDA).
The system calls are the input tape and the PDA has ﬁnal states that correspond to
possible program termination points. When we analyze a model to verify its ability to
detect attacks, we call the model a pushdown system.
Deﬁnition 6. A pushdown system (PDS) is a tuple Q = (cid:5)S, Σ, Γ, δ, s0, Z0(cid:6), where
each element of the tuple is deﬁned as in Deﬁnition 1.
The deﬁnition of a PDS is identical to that of a PDA, with the exception that the PDS
has no ﬁnal states and no input tape. A PDS is just a transition system used to analyze
properties of sequences and is not a language acceptor. Moped veriﬁes that no sequence
of system calls in the PDS will produce an unsafe operating system conﬁguration.
The input to Moped is a collection of variables and a PDS where each transition
in δ is tagged with a boolean formula. The formula expresses preconditions over the
variables that are required to hold before traversing the transition and postconditions
that hold after traversal. If no preconditions hold, then Moped will not traverse the
transition and will not alter the state variables. The Moped input language allows both
boolean and integer variables, although the integer variables are represented internally
as ordered lists of boolean bits.
We have written a speciﬁcation compiler that will produce valid Moped input ﬁles
from a PDA program model, the OS state variables, the initial OS conﬁguration, the
system call transformers, and the attack that we wish to prove is detected (Fig. 5). The
compiler converts the PDA to a PDS in a straightforward manner by simply removing
the designations for ﬁnal states. It compiles each system call transformer into a boolean
formula expected by Moped and annotates all system call transitions in the PDS with
these formulas. If the PDS contains other transitions, such as push and pop transitions
that do not correspond to system calls, the compiler annotates the transitions with a
formula whose preconditions match any OS variable assignment and whose postcon-
ditions simply maintain that assignment. We add one new state A to the PDS and new
J.T. Gifﬁn, S. Jha, and B.P. Miller
56
transitions to A after each system call transition. The precondition on these new transi-
tions is exactly the OS attack conﬁguration E that we wish to prove cannot be reached
in the model. We then invoke Moped so that it proves that state A cannot be reached or
provides a counterexample trace of system calls reaching state A.