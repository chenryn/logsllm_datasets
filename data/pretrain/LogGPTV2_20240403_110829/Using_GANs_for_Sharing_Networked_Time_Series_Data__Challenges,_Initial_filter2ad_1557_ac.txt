for many datasets and a simple autotuning of this hyperparameter
similar to this experiment can be used in practice (§4.4).
The above workflow of using RNNs with batch generation ig-
nores the timestamps from generation. In practice, for some datasets,
the timestamps may be important in addition to timeseries sam-
ples; e.g., if derived features such as inter-arrival times of requests
3 Our batch generation differs from two similarly-named concepts. Minibatching is a
standard practice of computing gradients on small sets of samples rather than the full
dataset for efficiency [56]. Generating batches of sequences in SeqGAN [118] involves
generating multiple time series during GAN training to estimate the reward of a
generator policy in their reinforcement learning framework. Both are orthogonal to
our batch generation.
468
R1R2R3R4RTRNNRNNRNNRNNRNN…Pass1Pass2Pass3Pass4PassTR1R2R3R4RTRNN…Pass1RNNPass2RNNPassT/3……R1R2R3R4RTRNNRNNRNNRNNRNN…Pass1Pass2Pass3Pass4PassTR1R2R3R4RTRNN…Pass1RNNPass2RNNPassT/3……01020304050S0.0010.0020.003Mean square errorIMC ’20, October 27–29, 2020, Virtual Event, USA
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar
d
e
z
i
l
a
m
r
o
N
s
w
e
i
v
e
g
a
p
Mode-collapsed
Auto-normalized
d
e
z
i
l
a
m
r
o
N
s
w
e
i
v
e
g
a
p
Figure 5: Without auto-normalization, generated samples
show telltale signs of mode collapse as they have similar
shapes and amplitudes.
may be important for downstream systems and networking tasks.
To this end, we support two simple alternatives. First, if the raw
timestamps are not important, we can assume that they are equally
spaced and are the same for all samples (e.g., when the dataset is
daily page views of websites). Second, if the derived temporal prop-
erties are critical, we can simply use the initial timestamp of each
sample as an additional metadata (i.e., start time of the sample) and
the inter-arrival times between consecutive records as an additional
measurement.
4.2 Tackling Mode Collapse
Mode collapse is a well-known problem [45], where the GAN out-
puts homogeneous samples despite being trained on a diverse
dataset. For example, suppose we train on web traffic data that
includes three distinct kinds of signals, corresponding to different
classes of users. A mode-collapsed GAN might learn to generate
only one of those traffic types.
For instance, fig. 5 (top) plots synthetic time series from a GAN
trained on the WWT dataset, normalized and shifted to [−1, 1]. The
generated samples are heavily mode-collapsed, exhibiting similar
amplitudes, offsets, and shapes.4
Existing work and limitations: Alleviating mode collapse is an
active research topic in the GAN community (e.g., [6, 50, 70, 101]).
We experimented with a number of state-of-the-art techniques for
mitigating mode collapse [50, 70]. However, these did not resolve
the problem on our datasets.
Our approach: Our intuition is that unlike images or medical data,
where value ranges tend to be similar across samples, networking
datasets exhibit much higher range variability. Datasets with a large
range (across samples) appear to worsen mode collapse because
they have a more diverse set of modes, making them harder to learn.
For example, in the WWT dataset, some web pages consistently
have >2000 page views per day, whereas others always have <10.
Rather than using a general solution for mode collapse, we build
on this insight to develop a custom auto-normalization heuristic.
Recall that each time series of measurements f i (e.g., network traffic
volume measurement of a client) is also assigned some metadata Ai
(e.g., the connection technology of the client, cable/fiber). Suppose
our dataset has two time series with different offsets: f 1(t) = sin(t)
and f 2(t) = sin(t) + 100 and no metadata, so A1 = A2 = (). We
have min(f 1) = −1, max(f 1) = 2, min(f 2) = 99, max(f 2) = 101.
A standard normalization approach (e.g. as in [116]) would be to
simply normalize this data by the global min and max, store them as
global constants, and train on the normalized data. However, this is
just scaling and shifting by a constant; from the GAN’s perspective,
the learning problem is the same, so mode collapse still occurs.
Instead, we normalize each time series signal individually, and
store the min/max as “fake" metadata. Rather than training on the
original (f i , Ai) pairs, we train on ˜f 1(t) = sin(t), ˜A1 = (−1, 1),
˜f 2(t) = sin(t), ˜A2 = (99, 101).5 Hence, the GAN learns to generate
these two fake metadata defining the max/min for each time series
individually, which are then used to rescale measurements to a
realistic range.
Note that this approach differs from typical feature normalization
in two ways: (1) it normalizes each sample individually, rather than
normalizing over the entire dataset, and (2) it treats the maximum
and minimum value of each time series as a random variable to
be learned (and generated). In this way, all time series have the
same range during generation, which alleviates the mode collapse
problem. Figure 5 (bottom) shows that by training DG with auto-
normalization on the WWT data, we generate samples with a broad
range of amplitudes, offsets, and shapes.
4.3 Capturing attribute relationships
So far, we have only discussed how to generate time series. How-
ever, metadata can strongly influence the characteristics of mea-
surements. For example, fiber users tend to use more traffic than
cable users. Hence, we need a mechanism to model the joint distri-
bution between measurements and metadata. As discussed in §3.3.2,
naively generating concatenated metadata Ai and measurements Ri
does not learn the correlations between them well. We hypothesize
that this is because jointly generating metadata and measurements
using a single generator is too difficult.
Existing work and limitations: A few papers have tackled this
problem, mostly in the context of generating multidimensional
data. The dominant approach in the literature is to train a vari-
ant of GANs called conditional GANs (CGANs), which learn to
produce data conditioned on a user-provided input label. For exam-
ple, prior works [35, 41, 119] learn a conditional model in which
the user inputs the desired metadata, and the architecture gener-
ates measurements conditioned on the attributes; generating the
attributes as well is a simple extension [35]. TimeGAN claims to
co-generate metadata and measurements, but it does not evaluate
on any datasets that include metadata in the paper, nor does the
released code handle metadata [116, 117].
4While mode collapse can happen both in measurements or in metadata, we observed
substantially more mode collapse in the measurements.
5In reality, we store ˜Ai = (max{f i } ± min{f i })/2 to ensure that our generated
min is always less than our max.
469
0100200300400500−1010100200300400500−101Using GANs for Sharing Networked Time Series Data: Challenges, Initial Promise, and Open Questions
IMC ’20, October 27–29, 2020, Virtual Event, USA
Our Approach: We start by decoupling this problem into two
sub-tasks: generating metadata and generating measurements con-
ditioned on metadata: P(Ai , Ri) = P(Ai) · P(Ri|Ai), each using a
dedicated generator; this is is conceptually similar to prior ap-
proaches [35, 119]. More specifically, we use a standard multi-layer
perceptron (MLP) network for generating the metadata. This is a
good choice, as MLPs are good at modeling (even high-dimensional)
non-time-series data. For measurement generation, we use the RNN-
based architecture from §4.1. To preserve the hidden relationships
between the metadata and the measurements, the generated meta-
data Ai is added as an input to the RNN at every step.
Recall from section 4.2 that we treat the max and min of each
time series as metadata to alleviate mode collapse. Using this condi-
tional framework, we divide the generation of max/min metadata
into three steps: (1) generate “real" metadata using the MLP gener-
ator (§4.3); (2) with the generated metadata as inputs, generate the
two “fake" (max/min) metadata using another MLP; (3) with the
generated real and fake metadata as inputs, generate measurements
using the architecture in §4.1 (see Figure 7).
Unfortunately, a decoupled architecture alone does not solve
the problem. Empirically, we find that when the average length of
measurements is long (e.g., in the WWT dataset, each sample con-
sists of 550 consecutive daily page views), the fidelity of generated
data—especially the metadata—is poor. To understand why, recall
that a GAN discriminator judges the fidelity of generated samples
and provides feedback for the generator to improve. When the total
dimension of samples (measurements + metadata) is large, judging
sample fidelity is hard.
Motivated by this, we introduce an auxiliary discriminator which
discriminates only on metadata. The losses from two discriminators
are combined by a weighting parameter α: minG maxD1,D2 L1(G, D1)+
αL2(G, D2) where Li, i ∈ {1, 2} is the Wasserstein loss of the
original and the auxiliary discriminator respectively. The genera-
tor effectively learns from this auxiliary discriminator to generate
high-fidelity metadata. Further, with the help of the original dis-
criminator, the generator can learn to generate measurements well.
Empirically, we find that this architecture improves the data fi-
delity significantly. Figure 6 shows a histogram of the (max+min)/2
metadata distribution from DG on the WWT dataset. That is, for
each time series, we extract the maximum and minimum value, and
compute their average; then we compute a histogram of these aver-
ages over many time series. This distribution implicitly reflects how
well DG reproduces the range of time series values in the dataset.
We observe that adding the auxiliary discriminator significantly
improves the fidelity of the generated distribution, particularly in
the tails of the true distribution.
4.4 Putting it all together
The overall DG architecture is in Figure 7, highlighting the key
differences from canonical approaches. First, to capture the cor-
relations between metadata and measurements, we use a decou-
pled generation of metadata and measurements using an auxiliary
discriminator, and conditioning the measurements based on the
metadata generated. Second, to address the mode collapse problem
for the measurements, we add the fake metadata capturing the
min/max values for each generated sample. Third, we use a batched
470
Figure 6: Distribution of (max+min)/2 of (a) DG without and
(b) DG with the auxiliary discriminator, (c) TimeGAN, and
(d) RCGAN (WWT data).
Figure 7: Architecture of DG highlighting key ideas and ex-
tensions to canonical GAN approaches.
RNN generator to capture the temporal correlations and synthesize
long time series that are representative.
The training phase requires two primary inputs: the data schema
(i.e., metadata/measurement dimensions, indicating whether they
are categorical or numeric) and the training data. The only minimal
tuning that data holders sharing a dataset using DG need to be
involved in is selecting the measurement batch size S (§4.1) con-
trols the number of measurements generated at each RNN pass.
Empirically, setting S so that T/S (the number of steps RNN needs
to take) is around 50 gives good results, whereas prior time series
GANs use S = 1 [13, 35, 117, 119]. Optionally, data holders can
−1.0−0.50.00.51.00100020003000RealDoppelGANger−1.0−0.50.00.51.0010002000RealDoppelGANger−1.0−0.50.00.51.00200040006000RealTimeGAN−1.0−0.50.00.51.002000040000RealTimeGANRNNNoiseMetadataGenerator(MLP)(A1,…,Am)NoiseMin/MaxGenerator(MLP)(min±max)/2AuxiliaryDiscriminatorDiscriminatorR1,…,RSRNNNoiseRT-s+1,…,RT……Decoupling attributes + conditioned generation to capture relationships (4.3)Normalization to tackle mode collapse (4.2)RNN with batched generation for capturing temporal correlation (4.1)Auxiliary discriminator to improve fidelity (4.3)Combined Discriminator×1×αRealFake(float)NoiseIMC ’20, October 27–29, 2020, Virtual Event, USA
Zinan Lin, Alankar Jain, Chen Wang, Giulia Fanti, and Vyas Sekar
Dataset
Multi-
dimensional
measurements
Variable-
length
signals
Correlated
in time &
metadata
x
x
x
WWT [47]
MBA [25]
GCUT [90]
Table 1: Challenging properties of studied datasets.
x
x
x
specify sensitive metadata, whose distribution can be masked or
request additional privacy settings to be used (§6). We envision data
holders sharing the generative model with the data users. Users can
then flexibly use this model and also optionally specify different
metadata distribution (e.g., for amplifying rare events) if needed.
That said, our workflow also accommodates a more restrictive mode
of sharing, where the holder uses DG to generate synthetic data
internally and then releases the generated data without sharing the
model.6
The code and a detailed documentation (on data format, hyper-
parameter setting, model training, data generation, etc.) are avail-
able at https://github.com/fjxmlzn/DoppelGANger.
5 FIDELITY EVALUATION
We evaluate the fidelity of DG on three datasets, whose properties
are summarized in Table 17.
5.1 Setup
5.1.1 Datasets. These datasets are chosen to exhibit different com-
binations of challenges: (1) correlations within time series and
metadata, (2) multi-dimensional measurements, and/or (3) variable
measurement lengths.
Wikipedia Web Traffic (WWT): This dataset tracks the number
of daily views of Wikipedia articles, starting from July 1st, 2015
to December 31st, 2016 [47]. In our language, each sample is a
page view counter for one Wikipedia page, with three metadata:
Wikipedia domain, type of access (e.g., mobile, desktop), and type of
agent (e.g., spider). Each sample has one measurement: the number
of daily page views.
Measuring Broadband America (MBA): This dataset was col-
lected by United States Federal Communications Commission (FCC)
[25] and consists of several measurements such as round-trip times
and packet loss rates from several clients in geographically di-
verse homes to different servers using different protocols (e.g. DNS,
HTTP, PING). Each sample consists of measurements from one