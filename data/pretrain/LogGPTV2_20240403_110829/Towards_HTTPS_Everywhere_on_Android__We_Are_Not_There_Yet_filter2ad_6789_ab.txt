or multiple pin nodes, each of which can contain a base64-
encoded SHA-256 of a speciﬁc server’s certiﬁcate. Multiple
pins can be used as a form of backup, to avoid issues while per-
forming key rotations, or to pin additional entities like the Root
CA that emitted the certiﬁcate for the domain. The connection
is allowed if and only if the hash of the certiﬁcate provided by
the server matches with at least one hash in the pin-set node.
KeyStore and CAs. The new version of the policy allows a
developer to specify which KeyStore to consider as trusted
when performing secure connections. The developer has ﬁrst
to deﬁne a trust-anchors node, which acts as a container for
one or more certificate nodes. Each certificate node
must have a src attribute, which indicates which certiﬁcate(s)
to trust. The values for src can be one of the following:
system, which indicates that the System KeyStore, the default
one; user, which indicates the user-installed certiﬁcates
within the User KeyStore; or a path to an X.509 certiﬁcate
within the app package. When multiple certificate nodes
are deﬁned, the system will trust their union.
Besides, the developer can also specify an overridePins
boolean attribute within a certificate node. This attribute
speciﬁes whether the CAs within this certiﬁcate node should
bypass certiﬁcate pinning. For example, if the attribute’s value
is true for the system CAs, then pinning is not performed on
certiﬁcate chains signed by one of these CAs.
Debug. Applications protected by the NSP are more diﬃcult
to debug. To address these concerns, the policy can contain
a debug-overrides node to indicate which policy should
be enforced when the app is compiled in debug mode.1 If the
developer leaves a debug-override node in the policy of a
release build, the content of the node is simply ignored.
3.2 Towards HTTPS Everywhere
Starting from Android 7.0, at apps’ installation time, the system
checks whether the developer did deﬁne a policy: if yes, it loads
1Apps can be compiled in release or debug mode. This can be done by
setting the android:debuggable manifest attribute accordingly. Apps must
be compiled in release mode to be accepted on the Play Store.
the policy; otherwise, it applies a default one. Note also that if a
policyis deﬁnedbutitdoesnotspecifya node oran attribute,the
system ﬁlls the missing values by inheriting them from a similar
node,or,whennoneareavailable,fromthedefaultconﬁguration.
The default values applied by the system do change over time
depending on the target API level and are becoming stricter—
and by forcing app developers to target high API levels to be
admitted on the oﬃcial Play Store, Google is leading a push
towards HTTPS everywhere. We now discuss how these default
values change depending on the target API level.
API 23 and Lower. An application targeting an API level
lower or equal than 23 cannot specify a policy since this
mechanism was introduced from API level 24. In this case,
the system will then enforce the following default policy:
This conﬁguration allows an app to use cleartext protocols and
to trust the union of CAs from both System and User KeyStore.
From API 24 to 27. The default policy for applications
targeting API levels from 24 to 27 changes as follows:
That is, cleartext traﬃc is still allowed, however, only CAs in
the System KeyStore are trusted by the application.
API Level 28 and Higher. For apps targeting an API level
greater or equal of 28, the policy is even stricter:
This change enforces that all cleartext protocols are blocked [8].
Starting from November 1st, 2019, all applications (and
updatesaswell)publishedontheoﬃcialGooglePlayStoremust
target at least API level 28, corresponding to Android 9.0 [28].
In Appendix, we report a concrete example of a (complex)
policy that touches on the various points previously discussed.
3.3 TrustKit
One library that is particularly relevant for our discussion is
TrustKit [19]. ThislibraryallowsthedeﬁnitionofaNSPforapps
targetingversionsofAndroidearlierthan7.0(which,aswemen-
tionedbefore,donotsupportNSP). From atechnicalstandpoint,
this library reimplements the logic behind the NSP, allowing an
application to import it as an external library. Note that TrustKit
346    29th USENIX Security Symposium
USENIX Association
only supports a subset of features: the developer cannot specify
a trust-anchors within a domain-config node, and it is
not possible to trust CAs in the User KeyStore. However, the
library implements a mechanism to send failure reports when
pinning failures occur on speciﬁc domains, allowing a devel-
oper to constantly monitor for pinning violations. Interestingly,
this feature is not available by the system-implemented NSP.
4 Policy Weaknesses
As discussed in the previous section, NSP is undoubtedly mak-
ing the speciﬁcation ofa ﬁne-grainednetworkpolicymore prac-
tical. However, each of the features introduced by the NSP may
be inadvertently disabled or weakened by an inexperienced de-
veloperduringthedeﬁnitionofthepolicy.Unfortunately,todate,
there are no tools that help developers to verify the correctness
of the deﬁned policy and to check that the settings she wanted
to implement are eﬀectively the ones enforced by the system.
This section discusses several potential pitfalls that may
occur when an inexperienced developer conﬁgures a NSP.
Allow Cleartext. As described in the previous section, a
developer has multiple ways to deﬁne the usage of cleartext pro-
tocols. For example, the developer can deﬁne a list of domains
and limit the adoption of cleartext only to them. Otherwise,
if the application contacts all the endpoints securely, she can
completely opt-out from cleartext communications and be sure
to identify potential regression issues. However, a developer
may conﬁgure her application with the following policy:
...
This conﬁguration allows the application to use cleartext
protocols, potentially exposing the user and the application
to threats described in Section 2. To make things worse, as
we will discuss throughout the paper, several online resources
suggest implementing this very coarse-grained policy, with
the goal of disabling the safer defaults: the main concern
is whether the inexperienced developer is fully aware of the
security repercussions of such policy.
For the sake of clarity,it is important to mention how this spe-
ciﬁc conﬁguration does not impact an application where all the
endpoints are already reached securely—this policy is useful
only when acting as a safety net. In other words, this conﬁgura-
tiondoesnotlowernorweakenthesecurityofanapplicationper-
forming all the network operations using, for example, HTTPS.
However, this conﬁguration is not able to identify regression
issues: if an endpoint is inadvertently moved from HTTPS to
HTTP, the insecure connection is allowed due to this “too open”
policy (while the default policy could have blocked that). A
similar scenario also aﬀects complex apps, which are either de-
veloped by diﬀerent teams within the same organization or that
are developed by embedding a high number of third-party de-
pendencies: in these cases,itis extremelychallenging,ifnotout-
right impossible, to make sure that no connection would rely on
cleartext protocols. Unfortunately, as we previously discussed,
even one single endpoint (or resource) reached through HTTP
might be enough to compromise the security of the entire app.
Certiﬁcate Pinning Override. The NSP makes the adoption
and conﬁguration of certiﬁcate pinning straightforward. The
developer now only needs to declare a valid certiﬁcate for each
of the domains she wants to protect: then, the system takes care
of all the logic to handle the veriﬁcation of the certiﬁcates at
connection time. On the other hand, we identiﬁed pitfalls that
an inexperienced developer may not be aware of. For example,
consider the following policy (which we took from a real app):
DOMAIN 
VALID_HASH 
We argue that this policy is misconﬁgured and that it is
very likely that the developer is not aware of it. Given the
speciﬁcation of the pin-set entries, it is clear that the intent
of the developer was to actually implement certiﬁcate pinning.
However,the overridePins attribute of the system certiﬁcate
entry is set to true: this indicates that certiﬁcate pinning
should not be enforced for any CAs belonging to the System
KeyStore, thus making the previous pin-set speciﬁcations
useless. We believe that this kind of policy oﬀers a “false sense”
of security for a developer, especially since no warnings are
raised at compilation time nor at runtime.
SilentMan-In-The-Middle.SwitchingfromHTTPtoHTTPS
does not always guarantee that the communication cannot
be eavesdropped. As described in Section 2, under certain
speciﬁc circumstances, it is possible to perform MITM over
SSL/TLS encrypted connection and break the conﬁdentiality,
integrity, and authenticity of the communication. Consider
the following policy taken from a real app:
This policy may expose an application to MITM (see Threat
Model 3). In fact, this policy trusts the union of the CAs in the
System and User KeyStore: hence, the traﬃc of the app can be
eavesdropped by anyone who controls a custom CA in one of
the KeyStores. This policy overrides the default conﬁguration
introduced on Android 7.0, which prevents applications from
trusting CAs stored in the User KeyStore when performing
secure connections. Even though trusting “user” certiﬁcates
may be the norm at the development phase, we believe that a
“production app” that actually trusts user certiﬁcate is often
a symptom of misconﬁguration since it is very rare that an
USENIX Association
29th USENIX Security Symposium    347
app would actually need to trust User CAs. For example, even
network-related apps such as VPN apps do not need to trust
User CAs, even when trusting custom certiﬁcates is required:
in fact, VPN apps can hardcode the custom CA within the app,
and add a trust-anchors node pointing to it. This has the net
eﬀect of trusting only this speciﬁc certiﬁcate, and nothing else.
One scenario where trusting User CAs seems required relates
to Mobile Device Management apps (MDM), which need to
install diﬀerent CAs coming from diﬀerent sources and that
cannotbe pre-packagedwithin the releasedapp. However,these
MDM apps constitute a rare exception, rather than the norm.
5 Policy Adoption
As one of the contributions of this paper, we set out to explore
how the NSP has been adopted by the Android ecosystem. This
section discusses our ﬁndings, and it is organized as follows.
First, we present the dataset we used for our study (§5.1). Sec-
ond, we discuss how apps use this new security mechanism, we
provide statistics on how frequently each feature of the policy is
used, and we present insights related to apps adopting policies
that are inherently “weak” and that likely constitute inadvertent
misconﬁgurations (§5.2). Last, we conclude this section with
an analysis of network libraries, which, from a technical
standpoint, is where the “enforcing” of the policies actually
lies; we have also developed an automatic testing framework
to determine whether a given network library correctly honors
the various elements of network policies (§5.3).
5.1 Dataset
To perform our analysis, we ﬁrst built a comprehensive
and representative dataset of apps. To determine which
apps to download, we obtained the package names from
AndroidRank [9], a service that provides “history data and
list of applications on Google Play.” We opted to select the
“most-installed applications” on the Google Play Store accord-
ing to the installation distribution, with apps whose unique
installation count ranges from 10K to more than a billion. In
total, we downloaded 125,419 apps, during June and July 2019.
5.2 Dataset Exploration & Weaknesses
Methodology. After extracting the policies from the apps,
we ﬁrst perform clustering to highlight common patterns and
whether two or more apps share the same exact policy (or
speciﬁc portions of it). In particular, we group two policies in
the same cluster if they contain the same nodes, attributes, and
values, in any order. This approach also helps us to determine
whether apps developers “copied” policies from known
developer websites, such as StackOverﬂow. We then analyze
the clusters to identify peculiar conﬁgurations or weaknesses.
Once an interesting conﬁguration has been identiﬁed, we then
proceed by performing queries on the entire dataset (that is,
inter-cluster) to measure how common this speciﬁc aspect of
the conﬁguration is and whether it aﬀects many apps.
We then performed an additional analysis step, which is
based on similar clustering techniques, but performed over
a normalized dataset. We refer to a policy as “normalized”
after we remove artifacts that are clearly speciﬁc to an app. We
replace all the concrete values of domains with the value URL,
all certiﬁcate hashes with HASH, and all the expiration dates
with DATE. The rationale behind this normalization step is to
be able to group policies “by semantics,” which is not aﬀected
when some speciﬁc concrete values diﬀer.
Overview. One of the ﬁrst insights is that, even though the
NSP was ﬁrstly introduced in Android 6.0 in 2015, we note
how 109,087 of the apps do not implement any policy (in
either of the two forms). Of the remaining 16,332 apps that do
implement a policy, 7,605 of them (6% of the total) adopt the
original version of the policy (available in Android 6.0), while
8,727 (6.95%) adopt the new, more expressive policy format
(available in Android 7.0). Our dataset is distributed as follows:
0.5% of the apps (83) target API level 29, 75% (12,261) API
level 28, 11% (1,803) API level 27, 12% (2,077) API level 26,
and the remaining 0.6% (108) target API level 25 or lower.
The ﬁrst clustering process creates in total 271 clusters
(where a cluster is formed by at least two apps): these clusters
group 7,184 apps out of the 8,727 apps deﬁning the policy—the
remaining 1,543 policies were unique and did not ﬁt any cluster.
The clustering process on the normalized dataset, instead,
generates 170 clusters, this time with only 311 applications
not belonging to any group. The remainder of this section
discusses several interesting insights and common patterns.
Cleartext. Among the generated clusters, one is particularly
big: it is formed by 1,595 apps. All these apps share the
trivial policy of “allowing cleartext globally.” The exact same
conﬁguration is also used by other 2,016 apps belonging to
60 diﬀerent clusters. Among the apps not belonging to any
cluster, this conﬁguration is used by 199 of them. Thus, in total,
4,174 apps of our dataset allow cleartext for the entire app.
We then investigated how many apps opted out from cleartext
and we found that only 156 apps block cleartext for the entire
app. Then, we considered also apps using the ﬁrst version of
the policy since it also allows a developer to fully opt-in, or
opt-out, from cleartext. Among the 7,605 apps using the ﬁrst
version of the policy, 97.5% (7,416) of them allow cleartext
protocols, while only the 2.48% (189) opted out from them.
As previously discussed in Section 3, the cleartext attribute
can also be enabled by default if an app is targeting an API level
lower or equal to 27 and it does not override it. By considering
also the default settings, the numbers are even more worrisome.
We noticed that among the 16,332 apps with a NSP, the 84.8%
of them (13,847) allow the usage of cleartext protocols. The
12.3% (1,837) ofthem enable cleartextdue to the defaultconﬁg-
uration not being overridden. To conclude, only the 1.2% (170)
opt-out from cleartext just for a speciﬁc subset of domains.
348    29th USENIX Security Symposium
USENIX Association
thiscase,anadvertisementlibraryexplicitlyrequestedthedevel-
opertomodifyherpolicytomakethelibrarywork.Wesuspected
that this pattern could be common to many other advertisement
libraries. Unfortunately, our suspicion proved to be correct: we
identiﬁed several ad libraries that explicitly request developers
to copy-paste a given policy. Moreover, we found how the ad
libraries’ documentations often attempt to convince developers
by including misleading and/or inaccurate arguments, and how
many of such policies’ modiﬁcations actually negatively aﬀect
the overall security of the entire app. We postpone an in-depth
discussion of these ﬁndings to the next section (Section 6).
Trusted Certiﬁcates. Another interesting cluster is formed
by 427 apps, which use a trust-anchors node for the entire
app to trust the union of System and User CAs. As previously
discussed, this conﬁguration might allow, under speciﬁc
circumstances, to perform a MITM over SSL/TLS connections
(see Threat Model 3). Nonetheless, we notice how this speciﬁc
conﬁguration is shared among other 1,083 apps, 600 of which
belong to 24 diﬀerent clusters. We then investigate how many
apps use the same conﬁguration for a subset of domains ending
up identifying 73 apps: thus, in total, we identiﬁed 1,159 apps