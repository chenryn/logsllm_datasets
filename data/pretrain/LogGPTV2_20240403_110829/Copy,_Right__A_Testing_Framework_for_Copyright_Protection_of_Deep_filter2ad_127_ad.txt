### Detection Performance and Analysis

Among the positive suspect models, RT-AL and P-60% exhibit significantly smaller detection areas compared to the other two, indicating that they are more challenging to detect. This difficulty arises because these two attacks involve the most extensive parameter modifications to the victim model. When comparing different metrics, activation-based metrics (e.g., NAD) generally outperform output-based metrics (e.g., NOD). Additionally, white-box metrics demonstrate superior performance over black-box metrics, especially against strong attacks like RT-AL.

In Appendix D, we provide a detailed analysis of the influencing factors, including adversarial test case generation and layer selection for computing the testing metrics, through several calibration experiments. Appendix H includes an analysis of how different levels of fine-tuning or pruning affect DEEPJUDGE's performance.

### Time Cost of DEEPJUDGE

The time cost of generating test cases using 1,000 seeds is provided in Appendix Table IX. For the black-box setting, we report the cost of PGD-based generation, while for the white-box setting, we report the cost of Algorithm 2. The results show that the time cost for white-box generation is slightly higher but remains very efficient in practice. The maximum time cost is observed on the SpeechCommands dataset for white-box generation, which is approximately 1.2 hours. This time cost is considered efficient, as test case generation is a one-time effort, and the additional time required to scan a suspect model with the generated test cases is negligible.

### Performance of DEEPJUDGE

#### Black-Box Setting

Table IV summarizes the performance of DEEPJUDGE against model fine-tuning and pruning attacks in the black-box setting. PGD [28] is used to generate the adversarial test cases. The validation accuracy (ACC) and the values of the metrics are provided. Values below the threshold τλ (indicating 'copy') are highlighted in red, and values above the threshold (indicating 'not copy') are highlighted in green. 'Yes (2/2)' indicates that both metrics vote for 'copy' (pcopy = 100%), and 'No (0/2)' indicates that neither metric votes for 'copy' (pcopy = 0%).

| Model Type | Victim Model | ACC | FT-LL | FT-AL | RT-AL | P-20% | P-60% | Neg-1 | Neg-2 |
|------------|--------------|-----|-------|-------|-------|-------|-------|-------|-------|
| MNIST      | RobD         | 98.5% | 0.019±0.003 | 0.045±0.016 | 0.298±0.039 | 0.058±0.014 | 0.172±0.024 | 0.968±0.014 | 0.949±0.029 |
| CIFAR-10   | RobD         | 84.8% | 0.016±0.002 | 0.033±0.010 | 0.151±0.017 | 0.035±0.009 | 0.097±0.010 | 0.614±0.016 | 0.600±0.020 |
| ImageNet   | RobD         | 74.4% | 0.034±0.007 | 0.073±0.011 | 0.192±0.008 | 0.106±0.010 | 0.161±0.017 | 0.737±0.007 | 0.760±0.010 |
| SpeechCommands | RobD | 94.9% | 0.009±0.003 | 0.043±0.011 | 0.251±0.015 | 0.064±0.003 | 0.091±0.004 | 0.395±0.006 | 0.429±0.004 |

#### White-Box Setting

Table V summarizes the performance of DEEPJUDGE against model fine-tuning and pruning attacks in the white-box setting. Algorithm 2 is used to generate the test cases. The values below the threshold τλ (indicating 'copy') are highlighted in red, and values above the threshold (indicating 'not copy') are highlighted in green. 'Yes (4/4)' indicates that all four metrics vote for 'copy' (pcopy = 100%), and 'No (0/4)' indicates that none of the metrics vote for 'copy' (pcopy = 0%).

| Model Type | NOD | NAD | LOD | LAD | Copy? |
|------------|-----|-----|-----|-----|-------|
| MNIST      | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | Yes (4/4) |
| CIFAR-10   | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | Yes (4/4) |
| ImageNet   | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | Yes (4/4) |
| SpeechCommands | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | 0.00±0.00 | Yes (4/4) |

### Comparison with Existing Techniques

We compare DEEPJUDGE with three state-of-the-art copyright defense methods against model fine-tuning and pruning attacks. Detailed information about these defense methods can be found in Appendix E.

#### Black-Box: Comparison to Watermarking and Fingerprinting

- **DNNWatermarking [47]**: A black-box watermarking method based on backdoors.
- **IPGuard [2]**: A black-box fingerprinting method based on targeted adversarial attacks.

For DNNWatermarking, we train the watermarked model (victim model) using additionally patched samples from scratch to embed the watermarks, and the Trigger Set Accuracy (TSA) of the suspect model is calculated for ownership verification. IPGuard generates targeted adversarial examples for the watermarked model and calculates the Matching Rate (MR) between the victim and the suspect for verification. For DEEPJUDGE, we use the Robustness Distance (RobD) metric for a fair comparison.

The left subfigure of Figure 6 visualizes the results. DEEPJUDGE demonstrates the best overall performance in this black-box setting. DNNWatermarking and IPGuard fail to identify the positive suspect models duplicated by FT-AL, RT-AL, P-20%, and P-60%. Their scores (TSA and MR) drop drastically against these four attacks, indicating that the embedded watermarks are completely removed or the fingerprint can no longer be verified. In contrast, the RobD metric of DEEPJUDGE maintains a significant gap between negative and positive suspects, demonstrating much better effectiveness against diverse fine-tuning and pruning attacks.

#### White-Box: Comparison to Watermarking

- **Embedding-Watermark [40]**: A white-box watermarking method based on signatures. It requires access to model parameters for signature extraction. We train the victim model with the embedding regularizer [40] from scratch to embed a 128-bit signature. The Bit Error Rate (BER) is calculated and used to measure the verification performance.

The right subfigure of Figure 6 visualizes the comparison results to two white-box DEEPJUDGE metrics, NOD and NAD. The three metrics show that DEEPJUDGE outperforms Embedding-Watermark in terms of robustness and effectiveness.

### Conclusion

DEEPJUDGE is effective and efficient in identifying fine-tuning and pruning copies. It outperforms existing techniques in both black-box and white-box settings, demonstrating its robustness and reliability in detecting various types of model attacks.