reverse proxy server that mirrors a target web page to a victim
while harvesting credentials, 2FA codes, and web page content in
transit. The important distinction between these toolkits and other
phishing tools is the continuous proxying of user traffic to and from
the target web server, pre- and post-authentication.
Using this definition, we searched for all MITM phishing toolk-
its on popular hacker forums and code repositories, both on the
clear web as well as on Tor [24]. Through this search, we iden-
tified three MITM phishing toolkits: Evilginx [8], Muraena [15],
and Modlishka [14]. We also discovered similar toolkits such as
CredSniper [6] and Reelphish [20]. However, as these do not proxy
user traffic to the target web server (i.e. they do not act as MITM
phishing toolkits), we consider them as out of scope for this work.
3.2 MITM Phishing Toolkit Functionality
While all current MITM phishing toolkits have a similar architecture
and share common goals, there are differences in their feature-sets
that influence their popularity among attackers.
Evilginx. Of the toolkits studied in this paper, Evilginx is the
easiest to operate due to its command-line interface which is used
to configure most aspects of the phishing server. Additionally, along
with hosting a web server, Evilginx also hosts its own DNS server
and automatically creates all TLS certificates needed using the Let’s
Encrypt [12] API. This significantly lowers the barrier of entry for
attackers, allowing even the least technically adept to launch their
own phishing campaigns. Evilginx is also the only tool of the three
studied that allows attackers to host multiple phishing pages simul-
taneously. Each individual phishing page responds to a subdomain
of the primary domain provided by the attacker. Code listing 1 in
the Appendix shows an example configuration file for Evilginx.
Evilginx allows attackers to launch highly targeted attacks, and
cloak their actions from anyone but the intended victim. This cloak-
ing is accomplished by generating tokenized URLs, referred to
internally as lures. These unique URL parameters must be included
in requests to view the phishing content. An example of a tokenized
URL generated by Evilginx is as follows: https://evil.com/xICcxSqs,
where the phishing domain name is followed by a random token.
All requests missing valid tokens are redirected to a web page of
the attacker’s choice. Attackers can also quickly disable individ-
ual tokens, preventing even tokenized URLs from responding with
phishing content. These features effectively cloak the presence
of Evilginx, increasing the uptime of campaigns before they are
detected and subsequently halted through blocklisting.
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea38Figure 2: Ratio of TCP SYN/ACK to valid and malformed HTTP GET Request RTTs over (a) HTTP and (b) HTTPS. (Muraena is not present in plot
(a) since it does not respond to HTTP requests.)
This diverse feature-set has led to a surge in the popularity of this
tool among attackers, and an increased attention from anti-virus
services. According to VirusTotal, eight different antivirus products
mark Evilginx as malicious [26]. This finding demonstrates the dual
nature of these types of toolkits where the very same tools that can
be used in the context of a legal penetration-testing engagement,
are also used by attackers when they break into servers.
Modlishka. Modlishka is a bare bones approach to a MITM
phishing toolkit. Unlike Evilginx, it is limited to targeting one do-
main at a time and does not provide a command-line interface for
configuration. Also, it is up to the attacker to provide a certificate, as
Modlishka is only capable of automatically generating self-signed
certificates. Modlishka can also be configured to remove all encryp-
tion and security headers from requests to target web servers.
Muraena. While Evilginx and Modlishka require the attacker
to manually create configuration files detailing the domains and
HTML attributes that should be replaced or removed from requests
and responses, Muraena automates this process using a web crawler.
Additionally, Muraena automates post-compromise actions that an
attacker would want to execute such as, changing passwords and
exfiltrating data. This is done using a companion tool called Necro-
browser [16]. This tool takes the session cookies extracted using
Muraena and launches an instrumented Chrome instance using
the Chrome DevTools Protocol, to perform the desired malicious
actions on the target website without attacker intervention, greatly
increasing the effectiveness of phishing campaigns.
3.3 Exploratory Data Analysis
As described in Section 2.3, the unique architecture of MITM phish-
ing toolkits allows attackers to create impersonating web pages that
effectively fool victims into providing their credentials. However,
this architecture also introduces discrepancies in packet round-trip-
times (RTTs), enabling the fingerprinting of these toolkits at the
network level. As two distinct HTTPS sessions must be maintained
to broker communication between the victim user and target web
server, the ratio of various packet RTTs, such as a TCP SYN/ACK
request and HTTP GET request, will be much higher when com-
municating with a reverse proxy server than with an origin web
server directly [45]. This ratio is further magnified when the re-
verse proxy server intercepts TLS requests, which holds true for
MITM phishing toolkits. Intuitively, this can be attributed to HTTP
requests propagating through to the target web server, while TCP
SYN packets are answered directly at the MITM phishing toolkit.
To verify the efficacy of these timing discrepancies in identifying
MITM phishing toolkits, we perform a series of exploratory mea-
surements. We record the RTTs of TCP SYN/ACK packets and HTTP
GET requests to each toolkit as well as an Apache [3] web server
under our control. We make both valid and malformed requests
in order to entice a direct response from the toolkits rather than a
proxied response from the target web server. The results from this
experiment are shown in Figure 2. The four cumulative distribution
functions represent the ratio of TCP SYN/ACK requests to valid
and malformed GET requests made over HTTP and HTTPS. Here,
smaller ratio values indicate that the two requests are answered
by the same physical machine, while larger ratio values imply re-
sponses to GET requests are sent by a machine at least one hop away
from the machine that responded to the TCP SYN request (i.e. an ori-
gin server situated behind a reverse proxy). We find that each of the
MITM phishing toolkits can be clearly distinguished from the direct-
server distribution in at least one of the four evaluated RTT ratios.
3.4 MITM Phishing Toolkit Classifier
Motivated by the results from our exploratory analysis, we develop
a machine-learning-based classifier trained on data gathered from
real-world websites and each of the MITM phishing toolkits in a
laboratory setting.
Feature Engineering
As mentioned in Section 2.3, all content viewed on the client de-
vice is at the complete control of the attacker, making any features
present in the application layer easily modifiable. Thus, when de-
signing our classifier, we focus on features inherent to the nature
of the man-in-the-middle architecture present in the toolkits. Using
these types of features provides us with a robust and powerful
classifier that is not only effective at the time of writing, but is also
adaptable to changes in existing tools as well as future tools.
To this end, we divide our feature set into Network Timing Fea-
tures, and TLS Library Features.
• Network Timing Features: As described in Section 3.3, we use
the RTT ratios of various points in TCP and TLS handshakes, as
well as HTTP GET requests. We make both valid and malformed
HTTP requests in order to solicit proxied and direct responses
respectively from MITM phishing toolkits.
02505007501000Ratio Value0.00.20.40.60.81.0GET/SYN RTT Ratio02505007501000Ratio ValueGET Error/SYN RTT Ratio02505007501000Ratio ValueGET/SYN RTT Ratio02505007501000Ratio ValueGET Error/SYN RTT Ratio(a)(b)DatasetEvilginxModlishkaMuraenaKnown DirectSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea39Figure 3: Architecture of experimental framework used to collect
network timing data of MITM phishing toolkits.
• TLS Library Features: Since MITM phishing toolkits typically
do not use the same web or reverse proxy server software as benign
websites, they make use of different TLS libraries to handle HTTPS
connections from clients. We therefore use TLS implementations as
a distinguishing factor. We treat each TLS version supported by the
current web server as a binary feature in our classifier. Additionally,
we use the TLS fingerprinting tool TLS Prober [23] to identify the
TLS library utilized by the current web server based on the format of
TLS packets it transmits. TLS Prober determines the library used by
a web server via a series of TLS Client Hello packets. By analyzing
the format of each server response, the TLS library implementation
can be determined. TLS Prober returns a map of TLS libraries to
the probability each library is used by the web server in question.
We treat each potential TLS library, and its associated probability,
as a numeric feature in our classifier. Since TLS Prober does not
make predictions off of configurable options, such as cipher suites,
an attacker attempting to bypass this fingerprinting would need to
re-engineer the entire TLS integration of a MITM phishing toolkit
and somehow mimic the TLS stack of a real web server.
By heavily relying on features deeply embedded into the architec-
ture of MITM phishing toolkits, our classifier is largely future-proof
and toolkit-agnostic. More specifically, of the 199 features our clas-
sifier is composed of, 14 are network timing features, and 185 are
TLS library features. Table 7 located in the Appendix shows our
full list of features.
Dataset Collection
Websites on the Internet are served from a variety of different net-
work architectures. More specifically, client requests are routed
either directly to web servers, or through reverse proxies in the
form of load balancers and CDNs. To effectively distinguish MITM
phishing toolkits from benign websites of these categories, we
collect ground-truth data from each of the following groups:
1. Non-Proxied Web Pages: To gather a list of websites with the
highest likelihood of being served directly by a web server without
an intervening proxy server, we use a heuristic of domains pointing
to IP addresses of the cloud-hosting providers Digital Ocean [7]
and Linode [13], as well as websites of local small businesses. The
aforementioned cloud-hosting providers are popular because they
offer simple virtual private servers, as opposed to the vast array
of products and services (including CDNs and load balancers) that
larger cloud-hosting providers (such as AWS and Google Cloud)
offer. We therefore reason that websites hosted on these platforms
are most likely hosted directly by origin servers. Similarly, because
Figure 4: Accuracy, False Positive, and False Negative rates of classifier
when iteratively removing most important features.
of the low traffic volume that the websites of local businesses attract
(such as local restaurants) we argue that they are highly unlikely
to be paying for load balancing and CDNs.
2. Reverse Proxy Web pages: We utilize the public IP address
range of Cloudflare [5] (one of the most popular anti-DDoS, CDN
services) to curate a list of benign websites hosted behind a reverse
proxy server. We use reverse DNS lookups on each IP address in the
Cloudflare subnet to gather a list of Cloudflare-managed domains.
3. MITM Phishing Toolkit Web pages: As the RTT of requests
will vary across different geographic distances, it is important to
collect network timing data from a large number of vantage points.
To accomplish this, we design a data collection methodology mod-
eled after the work of Alexander [29]. More specifically, we launch
30 globally distributed nodes hosted on AWS [1], where each node
hosts a web client, the three phishing toolkits, and an Apache
web server simultaneously. This globally distributed infrastructure,
visualized in Figure 3, allows us to record network timings for
many of the potential geographic distributions of victim→phishing
toolkit→target web server permutations. For example, our infras-
tructure allowed us to obtain measurements that included the three
parties (victim, phishing toolkit, and target web server) all being
located in North America, as well as the victims being located in
Asia, having their traffic proxied by an EU-residing phishing server,
onto a US-based target web server.
In each permutation, Node A sends an HTTP GET request to the
port of a phishing toolkit on Node B, where it is then forwarded
to the Apache web server hosted on Node C. Since it is unlikely
for a phishing toolkit to exist on the same host as a target web
server or victim user, we exclude these scenarios. This leaves us
with n(n−1)(n−2), or 24,360 permutations per toolkit. Since we
record data on three toolkits, we obtain a total of 73,080 network
measurements for the evaluated MITM phishing toolkits.
We compile a ground-truth dataset composed of all facets of
each tool’s requests and responses as well as benign websites. In
total, we collected 73,080 network requests from the MITM toolkit
and benign categories, for a total of 146,160 data points.
3.5 Model Training and Validation
Using our compiled ground truth data, we constructed training and
testing datasets with a 1:1 phishing-to-benign ratio. We then trained
a Random Forest classifier with a minimum sample split of 2 and 100
Features Dropped0.80.91.0050100150200Features Removed0.00.10.20.3AccuracyTLS Features RemovedNetwork Timing Features RemovedFalse Positive RateFalse Negative RateSession 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea40Table 2: Model performance when training on oldest release of each
MITM phishing toolkit and testing on all subsequent releases.
Accuracy
Precision
Recall
A. Restrict classifier to individual feature groups
TLS
Total
98.5%
99.9%
99.9%
Network Timing
98.5%
99.9%
99.9%
B. Training on oldest release, testing on newer releases
97.9%
Evilginx v2.0
85%
Muraena v0.1
Modlishka v1.0.0
99.8%
C. Exclude specified toolkit data from training dataset
97.5%
96.4%
99.8%
Evilginx
Muraena
Modlishka
100%
100%
100%
100%
100%
100%
98.5%
99.9%
99.9%
98.6%
87.7%
99.8%
97.5%
96.4%
99.8%
estimators. We empirically determined that these hyperparameters
provide us with the highest accuracy as well as lowest false positive
and negative rates. We chose a Random Forest classifier because of
its proven track record for security-related applications [30, 33, 48,
54, 56] while still maintaining a level of explainability, not found in
other types of machine-learning classifiers. We achieve an accuracy
score of 99.9% and a five-fold cross validation score of 99.9%.
Model Feature Importance
To ensure our classifier does not overfit on a small subset of pow-
erful toolkit-specific features, we study the decrease in accuracy as
well as the increase in false positive and false negative rates as we
iteratively remove the most important features.
Figure 4 demonstrates the decay in model effectiveness while
iteratively removing the most important feature and retraining. The
shaded regions represent the percentage of features from each of
the TLS and network timing categories removed throughout the
experiment. We observe that this feature removal does not have sig-
nificant effects on our classifier as the accuracy remains above 97%
even after removing the top 150 most important features. Further,
Table 2A shows the performance when restricting the classifier to
only one of the feature groups at a time (e.g. training using just
network-timing features and ignoring TLS). Our classifier continues
to perform well with each feature group isolated, demonstrating
that it is not dependent upon a small group of features, but rather