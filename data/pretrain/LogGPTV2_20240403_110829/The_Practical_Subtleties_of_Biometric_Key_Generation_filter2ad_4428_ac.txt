expected number of guesses it takes to ﬁnd an average
element in a set assuming an optimal guessing strategy
(i.e., ﬁrst guessing the element with the highest likeli-
hood, followed by guessing the element with the second
highest likelihood, etc.) Indeed, one might view Guess-
ing Distance as an extension of Guessing Entropy (see
Appendix A); however, we prefer Guessing Distance as
a measure of security as it provides more information
about non-uniform distributions over a key space. For
such distributions, Guessing Entropy is increased by the
elements that have a low probability, and thus might not
provide as conservative an estimate of security as de-
sired. Guessing Distance, on the other hand, can be com-
puted for each user, which brings to light the insecurity
afforded by a non-uniform distribution. We provide a
concrete example of such a case in Appendix A.
5 The Impact of Public Information on
Key Randomness
We now show why templates play a crucial role in the
computation of key entropy (REQ-KR from Section 3).
Our analysis brings to light two points: ﬁrst that tem-
plates, and in particular, error-correction information,
can indeed leak a substantial amount of information
about a key, and thus must be considered when com-
puting key entropy. Second, we show how standard ap-
proaches to computing key entropy, even if they were
to take templates into account, must be conducted with
care to avoid common pitfalls. Through our analysis we
demonstrate the ﬂexibility and utility of Guessing Dis-
66 
17th USENIX Security Symposium 
USENIX Association
tance. While we focus here on a speciﬁc proposal by
Vielhauer and Steinmetz [40, 41], we argue that our re-
sults are generally applicable to a host of similar propos-
als (see, e.g., [44, 7, 35, 17]) that use per-user feature-
space quantization for error correction. This complicates
the calculation of entropy and brings to light common
pitfalls.
The construction works as follows. Given 50 fea-
tures φ1, . . . , φ50 [40] that map biometric samples to
the set of non-negative integers, and ℓ enrollment sam-
ples B1, . . . , Bℓ, let ∆i be the difference between the
minimum and maximum value of φi(B1), . . . , φi(Bℓ),
expanded by a small tolerance. The scheme partitions
the output range of φi into ∆i-length segments. The
key is derived by letting Li be the smallest integer in
the segment that contains the user’s samples, comput-
ing Γi = Li mod ∆i, and setting the ith key element
ci = φi(B1)−Γi
∆i
. The key is K = c1 || . . . ||c50, and the
i =  φi(B′)−Γi
 and output K′ =
template T is composed of {(∆1, Γ1), . . . , (∆50, Γ50)}.
To later extract K given a biometric sample B′, and a
template T , set c′
c′
1 || . . . ||c′
correctness.
50. We refer the reader to [41] for details on
∆i
As is the case in many other proposals, Vielhauer et al.
perform an analysis that addresses requirement REQ-KR
by arguing that given that the template leaks only error
correcting information (i.e., the partitioning of the fea-
ture space) it does not indicate the values ci. To support
this argument, they conduct an empirical evaluation to
measure the Shannon entropy of each ci. For each user
u they derive Ku from Tu and Bu, then compute the en-
tropy of each element ci across all users. This analysis
is a standard estimate of entropy. To see why this is in-
accurate, consider two different users a and b such that
a outputs consistent values on feature φ and b does not.
Then the partitioning over φ’s range differs for each user.
Thus, even if the mean value of φ is the same when mea-
sured over both a’s and b’s samples, this mean will be
mapped to different partitions in the feature space, and
thus, a different key. This implies that computing entropy
over the ci overestimates security because the mapping
induced by the templates artiﬁcially ampliﬁes the entropy
of the biometrics. A more realistic estimate of the util-
ity afforded an adversary by auxiliary information can
be achieved by ﬁxing a user’s template, and using that
template to error-correct every other user’s samples to
generate a list of keys, then measuring how close those
keys are to the target user’s key. By conditioning the esti-
mate on the target users template we are able to eliminate
the artiﬁcial inﬂation of entropy and provide a better es-
timate of the security afforded by the construction.
Analysis. We implemented the construction and tested
the technique using all of the passphrases in the data
set we collected in [3], which consists of over 9,000
writing samples from 47 users. Each user wrote the
same ﬁve passphrases 10-20 times. In our analysis we
follow the standard approach to isolate the entropy as-
sociated with the biometric: we compute various en-
tropy measures using each user’s rendering of the same
passphrase [29, 5, 36] (this approach is justiﬁed as
user selected passphrases are assumed to have low en-
tropy). Tolerance values were set such that the approach
achieved a False Reject Rate (FRR) of 0.1% (as reported
in [40]) and all outliers and samples from users who
failed to enroll [24] were removed.
space is computed as H = 50
Figure 1 shows three different measures of key uncer-
tainty. The ﬁrst measure, denoted Standard, is the com-
mon measure of interpersonal variation as reported in the
literature (e.g., [17, 7]) using the data from our exper-
iments. Namely, if the key element ci has entropy Hi
across the entire population, then the entropy of the key
i=1 Hi. We also show
two estimates of guessing distance, the ﬁrst (GD(U, P),
plotted as GD-P) does not take a target user’s template
into account and P is just the distribution over all other
users’s keys in the population (the techniques we use to
compute these estimates are described in Appendix B).
The second (GD(U, P[Tu]), plotted as GD-U) takes the
user’s template into account, computing P[Tu] by taking
the biometrics from all other users in the population, and
generating keys using Tu, then computing the distribu-
tion over these keys.
Figure 1 shows the CDF of the number of guesses
that one would expect an adversary to make to ﬁnd each
user’s key. There are several important points to take
away from these results. The ﬁrst is the common pitfalls
associated with computing key entropy. The difference
between GD(U, P) and the standard measurement indi-
cates that the standard measurement of entropy (43 bits
in this case) is clearly misleading—under this view one
would expect an adversary to make 242 guesses on av-
erage before ﬁnding a key. However, from GD(U, P) it
is clear that an adversary can do substantially better than
this. The difference in estimates is due to the fact that
GD takes into account conditional information between
features whereas a more standard measure does not.
The second point is the impact of a user’s template
on computing GD. We can see by examining GD(U, P)
that if we take the usual approach of just computing en-
tropy over the keys, and ignore each user’s template, we
would assume only a small probability of guessing a key
in fewer than 221 attempts. On the other hand, since the
templates reduce the possible key space for each user, the
estimate GD(U, P[Tu]) provides a more realistic mea-
surement. In fact, an adversary with access to population
USENIX Association  
17th USENIX Security Symposium 
67
Ability of our Search Algorithm to Find Feature Values
Standard
GD-P
GD-U
 1
 0.8
 0.6
 0.4
 0.2
)
F
D
C
(
s
e
h
c
r
a
e
S
l
u
f
s
s
e
c
c
u
S
 0
 0
 5
 10
 15
 20
 25
 30
 35
 40
 45
Base-2 Logarithm of Guesses needed to Feature Values
Figure 1: CDF of the guesses required by an adversary to ﬁnd a key. We compare the Standard metric to two estimates
of GD, one that uses the target user’s template (GD-U), and one that uses each individual user’s template (GD-P).
statistics has a 50% chance of guessing a user’s key in
fewer than 222 attempts, and 15.5% chance guessing a
key in a single attempt!
These results also shed light on another pitfall worth
mentioning—namely, that of reporting an average case
estimate of key strength. If we take the target user’s tem-
plate into account in the current construction, 15.5% of
the keys can be guessed in one attempt despite the es-
timated Guessing Entropy being approximately 222. In
summary, this analysis highlights the importance of con-
ditioning entropy estimates on publicly available tem-
plates, and how several common entropy measures can
result in misleading estimates of security.
6 The Impact of Public Information on
Weak Biometric Privacy
Recall that a scheme that achieves Weak Biometric Pri-
vacy uses templates that do not leak information about
the biometrics input during enrollment. A standard ap-
proach to arguing that a scheme achieves REQ-WBP is
to show (1) auxiliary information leaks little useful in-
formation about the biometrics, and (2) templates do not
leak information about a biometric. This can be problem-
atic as the two steps are generally performed in isolation.
In our description of REQ-WBP, however, we argue that
step (2) should actually show that an adversary with ac-
cess to both templates and auxiliary information should
learn no information about the biometric. The key dif-
ference here is that auxiliary information is used in both
steps (1) and (2). This is essential as it is not difﬁcult to
create templates that are secure when considered in iso-
lation, but are insecure once we consider knowledge de-
rived from other users (e.g., population-wide statistics).
In what follows we shed light on this important consid-
eration by examining the scheme of Hao and Wah [17].
While our analysis focuses on their construction, it is per-
tinent to any BKG that stores partial information about
the biometric in the template [43, 26].
For completeness, we brieﬂy review the construction.
The BKG generates DSA signing keys from n dynamic
features associated with handwriting (e.g., pen tip veloc-
ity or writing time). The range of each feature is quan-
tized based on a user’s natural variation over the feature.
Each partition of a feature’s range is assigned a unique
integer; let pi be the integer that corresponds to the par-
tition containing the output of feature φi when applied
to the user’s biometric. The signing key is computed as
K = SHA1(p1 || . . . ||pn). The template stores informa-
tion that describes the partitions for each feature, as well
as the (x, y) coordinates that deﬁne the pen strokes of
the enrollment samples, and the veriﬁcation key corre-
sponding to K. The (x, y) coordinates of the enrollment
samples are used as input to the Dynamic Time Warp-
ing [32] algorithm during subsequent key generation; if
the provided sample diverges too greatly from the orig-
inal samples, it is immediately rejected and key genera-
tion aborted.
Hao et
typical
al. performed a
analysis of
they compute the entropy
REQ-WBP [17].
of the features over the entire population of users to
show that auxiliary information leaks little information
that could be used to discern the biometric. Second, the
First,
68 
17th USENIX Security Symposium 
USENIX Association
F
D
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Ability to guess a Biometric
Standard Estimate
Search Results
 5
 10
 15
 20
 25
 30
 35
 40
 45
Base-2 Logarithm of guesses needed to find a Biometric
Figure 2: Search results against the BKG proposed by Hao et al. [17]. Our search algorithm has a 22% chance of
ﬁnding a user’s key on the ﬁrst guess.
template is argued to be secure by making the following
three observations.
First, since the template only
speciﬁes the partitioning of the range of each feature, the
template only leaks the variation in each feature, not the
output. Second, for a computationally bound adversary,
a DSA veriﬁcation key leaks no information about
the DSA signing key. Third, since the BKG employs
only dynamic features,
the static (x, y) coordinates
leak no relevant information. Note that in this analysis
the template is analyzed without considering auxiliary