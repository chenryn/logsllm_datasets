that repeatedly executes 31 indirect jumps whose destinations
match the ﬁrst 31 jumps in the victim’s sequence followed by
an indirect jump to the virtual address of the victim’s gadget
(but in the attack process the instructions at this address return
control ﬂow back to the ﬁrst jump).
On a Haswell (i7-4650U) processor,
the victim process
executed 2.7 million iterations per second, and the attack
successfully poisoned the ﬁnal jump 99.7% of the time. On
a Kaby Lake (i7-7660U) processor, the victim executed 3.1
million iterations per second, with a 98.6% poisoning rate.
When the attack process stopped or executed on a different
core, no spurious cache hits at
the probe location were
observed. We thus conclude that indirect branch poisoning is
highly effective, including at speeds far above the rate at which
a typical victim program would perform a given indirect jump
that an attacker seeks to poison.
B. Indirect Branch Poisoning Proof-of-Concept on Windows
As a proof-of-concept, we constructed a simple target
application which provides the service of computing a SHA-
1 hash of a key and an input message. This implementation
consisted of a program which continuously runs a loop which
calls Sleep(0), loads the input from a ﬁle, invokes the
Windows cryptography functions to compute the hash, and
prints the hash whenever the input changes. We found that
the Sleep() call is done with data from the input ﬁle in
registers ebx, edi, and an attacker-known value for edx, i.e.,
the content of two registers is controlled by the attacker. This
is the input criteria for the type of Spectre gadget described
in the beginning of this section.
Searching the executable memory regions of the victim
process, we identiﬁed a byte sequence in ntdll.dll (on
both Windows 8 and Windows 10) which forms the following
(possibly misaligned) instruction sequence to use as a Spectre
gadget:
adc edi,dword ptr [ebx+edx+13BE13BDh]
adc dl,byte ptr [edi]
A. Experimental Results
Similar to our results on the conditional branch mispre-
diction (cf. Section IV-A), we observed the indirect branch
poisoning on multiple x86 processor architectures, including
Intel Ivy Bridge (i7-3630QM), Intel Haswell (i7-4650U), Intel
Broadwell (i7-5650U), Intel Skylake (unspeciﬁed Xeon on
Google Cloud, i5-6200U, i7-6600U, i7-6700K), Intel Kaby
Speculative execution of this gadget with attacker-controlled
ebx and edi allows an adversary to read the victim’s mem-
ory. The attacker sets edi to the base address of the probe
array, e.g., a memory region in a shared library, and sets
ebx = m − 0x13BE13BD − edx. Consequently, the ﬁrst
instruction reads a 32-bit value from address m and adds this
onto edi. The second instruction then fetches the index m
(cid:26)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
in the probe array into the cache. Similar gadgets can also be
found with byte-wise reads for the ﬁrst instruction.
For indirect branch poisoning, we targeted the ﬁrst instruc-
tion of the Sleep() function, where both the location of
the jump destination and the destination itself change per
reboot due to ASLR. To get the victim to execute the gadget
speculatively, the memory location containing the jump was
ﬂushed from the cache, and the branch predictor mistrained
to send speculative execution into the Spectre gadget. Since
the memory page containing the destination for the jump was
mapped copy-on-write, we were able to mistrain the branch
predictor by modifying the attacker copy of the Sleep()
function, changing the jump destination to the gadget address,
and place a ret instruction there. The mistraining was then
done by repeatedly jumping to the gadget address from mul-
tiple threads.
Code ASLR on Win32 only changes a few address bits, so
only a few combinations needed to be tried to ﬁnd a training
sequence that works on the victim. A single-instruction gadget,
comprising the instruction sbb eax,[esp+ebx], was used
to locate the stack.
In the attack process, a separate thread was used to mistrain
the branch predictor. This thread runs on the same core as
the victim (e.g., via hyperthreading), thus sharing the branch
predictor state. Because the branch predictor uses the pre-
ceding jump history in making predictions, each mistraining
iteration mimics the victim’s branch history prior to the jump
to redirect. Although mistraining could exactly match the exact
virtual addresses and instruction types of the victim, this is not
necessary. Instead, each mistraining iteration uses a series of
ret instructions whose destination addresses match the low
20 bits of the victim’s jump history (mapped to addresses in a
1 MB (220-byte) executable array ﬁlled with ret instructions).
After mimicking the history, the mistraining thread executes
the jump to redirect (which is modiﬁed to jump to the gadget).
The attacker can then leak memory by choosing values
for ebx (adjusting which memory address to read) and edi
(adjusting how the read result maps into the probe array).
Using Flush+Reload, the attacker then infers values from the
victim process. In Listing 1, the read value is spread over cache
lines, and can thus easily be inferred. However, in the example
above the least signiﬁcant 6 bits of the value are not spread
over cache lines, and thus values which fall into the same
cache line are not distinguishable with a basic Flush+Reload
attack. To distinguish such values, the base address of the
probe array can be shifted byte-wise to identify the threshold
where the accessed value falls into the consecutive cache
line. By repeating the attack, the attacker can read arbitrary
memory from the victim process. An unoptimized proof-of-
concept implementation on an Intel Haswell (i7-4650U), with
the ﬁle used by the attacker to inﬂuence the victim’s registers
placed on a RAM drive, reads 41 B/s including the overhead
to backtrack and correct errors (about 2% of attempts).
C. Reverse-Engineering Branch Prediction Internals
We now describe the basic approach used to reverse-
engineer Intel Haswell branch predictor internals in prepa-
ration for the attack against KVM. Such reverse-engineering
is helpful
to optimize branch predictor mistraining or to
characterize a processor’s vulnerability, although in practice
mistraining can often be achieved without full understanding
of the branch predictor.
The attack on KVM is described in Section V-D.
For reverse engineering, we started with information avail-
able from public sources. Intel’s public documentation con-
tains some basic but authoritative information about the branch
prediction implementations in its processors [35]. Agner
Fog [15] describes the basic ideas behind the branch prediction
of Intel Haswell processors. Finally, we used information from
prior research which reverse-engineered how direct jumps are
predicted on Intel processors [14].
The structure of the branch history buffer (BHB) is a logical
extension of the pattern history presented by [15]. The BHB
helps make predictions on the basis of instruction histories,
while preserving simplicity and the property of providing a
rolling hash. This naturally leads to a history buffer with
overlapping data, XOR-combinations (the simplest way to
mix two pieces of data), and no extra forward or backward
propagation inside the history buffer (to preserve the rolling
hash property in a simple way).
To determine the precise functions used by the branch
predictor, predictor collisions were leveraged. We set up two
hyperthreads that run identical code leading up to high-
latency indirect branches with different targets. The process
in hyperthread A was conﬁgured to execute a jump to target
address 1, while the process in hyperthread B was conﬁgured
to execute a jump to target address 2. In addition, code was
placed in hyperthread A at target address 2 that loads a cache
line for Flush+Reload. We then measured how often that cache
line was loaded in hyperthread A; this is the misprediction
rate. A high misprediction rate indicates that the processor
cannot distinguish the two branches, while a low misprediction
rate indicates that the processor can distinguish them. Various
changes, such as ﬂipping one or two bits at a time in addresses,
were applied in one of the threads. The misprediction rate
then acts as a binary oracle, revealing whether a given bit
inﬂuences branch prediction at all (single bit ﬂip) or whether
two bits are XORed together (two bit ﬂips at positions that
cause high low misprediction rates when ﬂipped individually
but low misprediction rates when both ﬂipped).
Combining this knowledge yields the overview shown in
Figure 3.
D. Attack against KVM
We implemented an attack (using an Intel Xeon Haswell
E5-1650 v3, running Linux kernel package linux-image-4.9.0-
3-amd64 at version 4.9.30-2+deb9u2) that leaks host memory
from inside a guest VM, provided that the attacker has access
to guest ring 0 (i.e., has full control over the operating system
running inside the VM).
(cid:18)(cid:17)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
58-bit
Branch History Buffer
58 bit
Taken branches
Source
Destination
bits
4-19 bits 0-5
XOR folding
(cf. Listing 4)
16 bit
Indirect branch prediction
Source
subset of 12 LSB
XOR folding
BTB lookup
64-bit destination
Direct branch prediction
XOR folding
bits 0-30
Source
BTB lookup
32-bit destination
4 GB straddle bit
cond. ±4 GB adjust
31
bit
3
2-6
3
bits
64-bit destination
Fig. 3: Multiple mechanisms inﬂuence the prediction of direct,
indirect, and conditional branches.
The ﬁrst phase of the attack determines information about
the environment. It ﬁnds the hypervisor ASLR location by ana-
lyzing branch history buffer and branch target buffer leaks [14,
72]. It also ﬁnds L3 cache set association information [48],
as well as physical memory map location information using
a Spectre gadget executed via branch target injection. This
initialization step takes 10 to 30 minutes, depending on the
processor. It then leaks hypervisor memory from attacker-
chosen addresses by executing the eBPF interpreter in hy-
pervisor memory as a Spectre gadget using indirect branch
poisoning (aka branch target injection), targeting the primary
prediction mechanism for indirect branches. We are able to
leak 1809 B/s with 1.7% of bytes wrong/unreadable.
VI. VARIATIONS
So far we have demonstrated attacks that leverage changes
in the state of the cache that occur during speculative execu-
tion. Future processors (or existing processors with different
microcode) may behave differently, e.g., if measures are taken
to prevent speculatively executed code from modifying the
cache state. In this section, we examine potential variants of
the attack, including how speculative execution could affect
the state of other microarchitectural components. In general,
Spectre attacks can be combined with other microarchitectural
attacks. In this section, we explore potential combinations and
conclude that virtually any observable effect of speculatively
executed code can potentially lead to leaks of sensitive infor-
mation. Although the following techniques are not needed for
the processors tested (and have not been implemented), it is
essential to understand potential variations when designing or
evaluating mitigations.
Spectre variant 4. Spectre variant 4 uses speculation in the
store-to-load forwarding logic [31]. The processor speculates
that a load does not depend on the previous store [73]. The
exploitation mechanics are similar to variant 1 and 2 that we
discussed in detail in this paper.
Evict+Time. The Evict+Time attack [52] works by measuring
the timing of operations that depend on the state of the cache.
This technique can be adapted to use Spectre as follows.
Consider the code:
if (false but mispredicts as true)
f
a
l
l
b
a
c
k
read array1[R1]
read [R2]
Suppose register R1 contains a secret value. If the specula-
tively executed memory read of array1[R1] is a cache hit,
then nothing will go on the memory bus, and the read from
[R2] will initiate quickly. If the read of array1[R1] is a
cache miss, then the second read may take longer, resulting
in different timing for the victim thread. In addition, other
components in the system that can access memory (such as
other processors) may be able to sense the presence of activity
on the memory bus or other effects of the memory read, e.g.,
changing the DRAM row address select [56]. We note that
this attack, unlike those we have implemented, would work
even if speculative execution does not modify the contents
of the cache. All that is required is that the state of the cache
affects the timing of speculatively executed code or some other
property that ultimately becomes visible to the attacker.
Instruction Timing.
Spectre vulnerabilities do not nec-
essarily need to involve caches. Instructions whose timing
depends on the values of the operands may leak information
on the operands [6]. In the following example, the multiplier
is occupied by the speculative execution of multiply R1,
R2. The timing of when the multiplier becomes available
for multiply R3, R4 (either for out-of-order execution or
after the misprediction is recognized) could be affected by the
timing of the ﬁrst multiplication, revealing information about
R1 and R2.
if (false but mispredicts as true)
multiply R1, R2
multiply R3, R4
Contention on the Register File.
Suppose the CPU has
a register ﬁle with a ﬁnite number of registers available for
storing checkpoints for speculative execution. In the following
example, if condition on R1 in the second ‘if’ is true,
then an extra speculative execution checkpoint will be created
than if condition on R1 is false. If an adversary can
detect this checkpoint, e.g., if speculative execution of code
in hyperthreads is reduced due to a shortage of storage, this
reveals information about R1.
if (false but mispredicts as true)
if (condition on R1)
if (condition)
Variations on Speculative Execution.
Even code that
contains no conditional branches can potentially be at risk.
For example, consider the case where an attacker wishes to
determine whether R1 contains an attacker-chosen value X or
some other value. The ability to make such determinations is
sufﬁcient to break some cryptographic implementations. The
attacker mistrains the branch predictor such that, after an inter-
rupt occurs, the interrupt return mispredicts to an instruction
(cid:18)(cid:18)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
that reads memory [R1]. The attacker then chooses X to
correspond to a memory address suitable for Flush+Reload,
revealing whether R1 = X. While the iret instruction is
serializing on Intel CPUs, other processors may apply branch
predictions.
Leveraging Arbitrary Observable Effects. Virtually any ob-
servable effect of speculatively executed code can be leveraged
to create the covert channel that leaks sensitive information.
For example, consider the case where the example in Listing 1
runs on a processor where speculative reads cannot modify the
cache. In this case, the speculative lookup in array2 still
occurs, and its timing will be affected by the cache state en-
tering speculative execution. This timing in turn can affect the
depth and timing of subsequent speculative operations. Thus,
by manipulating the state of the cache prior to speculative
execution, an adversary can potentially leverage virtually any
observable effect from speculative execution.
if (x < array1_size) {
y = array2[array1[x] * 4096];
// do something detectable when
// speculatively executed
}
The ﬁnal observable operation could involve virtually any
side channel or covert channel, including contention for re-
sources (buses, arithmetic units, etc.) and conventional side
channel emanations (such as electromagnetic radiation or
power consumption).
A more general form of this would be: