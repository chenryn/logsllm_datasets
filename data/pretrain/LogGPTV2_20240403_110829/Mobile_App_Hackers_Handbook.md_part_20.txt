int checkSymLinks(char *path)
{
struct stat s;
if (lstat(path, &s) == 0)
{
if (S_ISLNK(s.st_mode) == 1)
return 1;
}
return 0;
}
Aside from /Applications, jailbreaks often create a number of other symbolic links that you should also validate
for further confidence.
Securing Your Application Runtime
Frameworks such as Cydia Substrate (http://www.cydiasubstrate.com/) and Frida (http://www.frida.re/)
make instrumentation of mobile runtimes a relatively straightforward process and can often be leveraged to
modify application behavior and bypass security controls or to leak or steal sensitive data. In some cases they
have also been abused by malware that targets jailbroken devices as was the case with the “Unflod Baby Panda
malware” (https://www.sektioneins.de/en/blog/14-04-18-iOS-malware-campaign-unflod-baby-panda.html).
Instrumentation leads to a situation whereby an application cannot always trust its own runtime. For a secure
application, additional validation of the runtime is recommended.
The typical approach for runtime hooking used by frameworks such as Cydia Substrate is to inject a dynamic
library into the address space of your application and replace the implementation of a method that the attacker
wants to instrument. This typically leaves behind a trail that you can use to gain some confidence as to whether
your application is being instrumented. First, methods residing from within Apple SDKs will typically originate
from a finite set of locations, specifically:
/System/Library/TextInput
/System/Library/Accessibility
/System/Library/PrivateFrameworks/
/System/Library/Frameworks/
/usr/lib/
Furthermore, methods internal to your application should reside from within your application binary itself. You
can verify the source location of a method using the dladdr() function, which takes a function pointer to the
function that you want to retrieve information about. The following is a simple implementation that iterates a
given class’ methods and checks the source location of the image against a set of known possible image
locations. Finally, it checks whether the function resides within a path relative to the application itself:
int checkClassHooked(char * class_name)
{
char imagepath[512];
int n;
Dl_info info;
id c = objc_lookUpClass(class_name);
Method * m = class_copyMethodList(c, &n);
for (int i=0; i= 0; --j)
if(dyld[j] == '/') break;
char *name = strndup(dyld + ++j, slength - j);
for(int x=0; x < sizeof(evilLibs) / sizeof(char*); x++)
{
if(strstr(name, evilLibs[x]) ǁ strstr(dyld, evilLibs[x]))
fprintf(stderr,"Found injected library matching string: \
%s", evilLibs[x]);
}
free(name);
}
}
Another interesting technique for identifying hooking is to examine how hooks operate at a low level and
attempt to locate similar signatures in your application. As an example, consider a simple hook that has been
placed on the fork() function; first retrieve the address of the fork() function:
NSLog(@"Address of fork = %p", &fork);
This should print something similar to the following in the console log:
2014-09-25 19:09:28.619 HookMe[977:60b] Address of fork = 0x3900b7a5
Then run your application and examine the disassembly of the function without the hook in place (truncated for
brevity):
(lldb) disassemble -a 0x3900b7a5
libsystem_c.dylib'fork:
0x3900b7a4: push {r4, r5, r7, lr}
0x3900b7a6: movw r5, #0xe86c
0x3900b7aa: add r7, sp, #0x8
0x3900b7ac: movt r5, #0x1d0
0x3900b7b0: add r5, pc
0x3900b7b2: ldr r0, [r5]
0x3900b7b4: blx r0
0x3900b7b6: blx 0x39049820
Repeating these steps again shows a different result when the fork()function is being hooked:
(lldb) disassemble -a 0x3900b7a5
libsystem_c.dylib'fork:
0x3900b7a4: bx pc
0x3900b7a6: mov r8, r8
0x3900b7a8: .long 0xe51ff004
0x3900b7ac: bkpt #0x79
0x3900b7ae: lsls r5, r1, #0x6
0x3900b7b0: add r5, pc
0x3900b7b2: ldr r0, [r5]
0x3900b7b4: blx r0
As you can see, the opcode signature is entirely different. This can be attributed to the trampoline that is
inserted at 0x3900b7a8 by the Cydia Substrate framework. In assembly, the opcode 0xe51ff004 equates to the
ldr pc, [pc-4] instruction that causes the application to jump to the location pointed to by the next word after
the current value of the pc register, in this case 0x018dbe79.
Using this information you can now write a short routine to detect trampolines in your functions before you call
them, and as a consequence, determine whether it is being hooked. This is demonstrated in the following simple
example:
inline int checkFunctionHook() __attribute__((always_inline));
int checkFunctionHook(void * funcptr)
{
unsigned int * funcaddr = (unsigned int *) funcptr;
if (funcptr) {
if (funcaddr[0] == 0xe51ff004) return 1;
}
return 0;
}
Note that additional checks may be required depending on the architecture that your application is running
under. You can also use similar techniques to detect hooking of native code on the Android platform.
Tamperproofing Your Application
The tamperproofing protection mechanism is not widely deployed but can typically be found in applications that
have the most sensitive operating environments. Integrity validation attempts to ensure that static application
resources such as HTML files or shared libraries, as well as internal code structures, have not been modified.
From a native code perspective, this protection specifically looks to thwart attackers that have “patched” the
assembly for your application.
Integrity validation is often implemented using checksums, with CRC32 being a popular choice due to its speed
and simplicity. To validate static application resources such as HTML or shared library files the developer would
calculate a checksum for each resource (or indeed all resources combined) and embed it in the application along
with a validation routine to recalculate and compare the stored checksum periodically during the application’s
runtime. Similarly, to validate internal code structures, the application must have some means of calculating the
stored checksum.
Implementing such protections without external resources (such as the compiler or Mach-O/ELF modification
tools) typically means running the application and allowing it to self-generate a checksum of a function or set or
functions, then manually embedding the calculated checksum into the binary. You can achieve some success
with this method when you manually embed a “web” of checksum validation routines but it has a number of
drawbacks—primarily the inability to automatically randomize the protection across builds as well as the
manual efforts required to implement and maintain it.
A more complex but significantly better approach is to use the power of the low-level virtual machine (LLVM)
compiler and allow native code within iOS and Android applications to be self-validating. Using this approach
you can create an optimization pass that leverages LLVM’s JIT compiler to programmatically compile and
modify the LLVM bytecode. This strategy allows you to automatically calculate a checksum for your JIT-
compiled function and insert validation routines across the binary during the application’s compilation process,
without any modification to the code.
You should be aware that although integrity validation is a power protection mechanism, ultimately a
knowledgeable adversary could always bypass it because all the validation routines occur within the binary
itself. In the event that your checksum calculation functions can be easily identified—for example, through a
specific signature or via cross references—the attacker could simply patch out your routines to leave the
application unprotected.
Implementing Anti-Debugging Protections
Debugging is a popular technique used when reverse engineering mobile applications. It provides an insight into
the internal workings of an application and allows an attacker to modify control flow or internal code structures
to influence application behavior. This can have significant consequences for a security-conscious application;
some example use cases where debugging might be applied are to extract cryptographic key material from an
application, manipulate an application’s runtime by invoking methods on existing objects, or to understand the
significance of an attacker-generated fault.
Although preventing a privileged attacker from debugging your application is conceptually impossible, you can
take some measures to increase the complexity and time required for an attacker to achieve debugging results.
On iOS, debugging is usually achieved using the ptrace() system call. However, you can call this function from
within your third-party application and provide a specific operation that tells the system to prevent tracing from
a debugger. If the process is currently being traced then it will exit with the ENOTSUP status. As mentioned, this is
unlikely to thwart a skilled adversary but does provide an additional hurdle to overcome. The following is a
simple implementation of this technique. You should implement it not only throughout your application but
also as close to the process start (such as in the main function or a constructor) as possible:
inline void denyPtrace () __attribute__((always_inline));
void denyPtrace()
{
ptrace_ptr_t ptrace_ptr = dlsym(RTLD_SELF, "ptrace");
ptrace_ptr(PT_DENY_ATTACH, 0, 0, 0);
}
You may also want to implement a secondary measure of detecting whether your application is being debugged
to add further resilience in the event that your PT_DENY_ATTACH operation has been overcome. To detect whether
a debugger is attached to your application you can use the sysctl() function. This doesn’t explicitly prevent a
debugger from being attached to your application but returns sufficient information about your process to allow
you to determine whether it is being debugged. When invoked with the appropriate arguments, the sysctl()
function returns a structure with a kp_proc.p_flag flag that indicates the status of the process and whether or
not it is being debugged. The following is a simple example of how to implement this:
inline int checkDebugger () __attribute__((always_inline));
int checkDebugger()
{
int name[4];
struct kinfo_proc info;
size_t info_size = sizeof(info);
info.kp_proc.p_flag = 0;
name[0] = CTL_KERN;
name[1] = KERN_PROC;
name[2] = KERN_PROC_PID;
name[3] = getpid();
if (sysctl(name, 4, &info, &info_size, NULL, 0) == -1) {
return 1;
}
return ((info.kp_proc.p_flag & P_TRACED) != 0);
}
These are just a few examples of strategies that exist for debugger detection; many others exist. Indeed, there is
scope to be quite creative using more convoluted strategies such as execution timing, where you record the
amount of time it takes to complete a set of operations and if it’s outside a margin of acceptable execution times
you can have some assurance that your application is being debugged.
Obfuscating Your Application
In its simplest definition obfuscation is a technique used to complicate reverse engineering by making code
complex to understand. This principle is well understood throughout computer science and the topic is far
beyond the scope of this book; indeed, whole research projects have been dedicated to this topic alone. Instead,
we focus on how it is relevant to mobile applications and how you can apply it to iOS applications.
It is common knowledge that without obfuscation Objective-C is relatively simple to reverse engineer. As you
have already discovered from Chapter 2, retrieving class, method, and variable names from the OBJC segment of
a Mach-O binary is possible. This fact can be a thorn in the side of any developer who wants to protect his
intellectual property, and therefore obfuscation is often used to disguise the operations of an application
without entirely modifying the expected outcomes. At a high level, some of the techniques used by obfuscators
include:
Obscuring class, field, and method names
Inserting bogus code
Modifying the control flow
Using string encryption
Substituting code to make it appear more complex; for example, using reflection
Flattening control flow
Few options exist for obfuscating native code, with the exception of the Obfuscator-LLVM project, which can be
used to obfuscate the Android NDK or iOS applications using an LLVM compiler optimization pass. Obfuscator-
LLVM implements obfuscation passes using the following techniques:
Instructions substitution (–mllvm –sub)
Bogus control flow (–mllvm –bcf)
Control flow flattening (–mllvm –fla)
To use Obfuscator-LLVM within Xcode you must first create an Xcode plugin to reference the new compiler. For
instructions on how to perform this and build the project, you should refer to the O-LLVM wiki
(https://github.com/obfuscator-llvm/obfuscator/wiki/Installation).
Unfortunately, while Obfuscator-LLVM is an extremely useful obfuscator, it lacks the functionality to obfuscate
class and method names. However, an alternative solution can work in harmony with Obfuscator-LLVM and
together can make a relatively formidable obfuscator: iOS Class Guard works as an extension for the popular
class-dump tool and works by parsing your binary to generate an obfuscated symbol table that you can use in
future builds. For details on how to implement iOS Class Guard in your application, you should refer to the wiki
(https://github.com/Polidea/ios-class-guard).
Summary
Securing an iOS application can be a relatively daunting task even for seasoned developers due to the large
number of considerations and possible attack surfaces. Within this chapter you have learned how to secure your
application data not only at rest but also in transit, as well as securely erase it when it is no longer in use.
Furthermore, you learned how to implement a variety of binary protections that can be used to not only
decrease the pool of adversaries capable of attacking your application, but also increase the amount of time
needed to attack it. No silver bullet exists for securing an application, but with sufficient effort, building a self-
defending application that cannot be easily tampered with is possible. You should also be aware that when
securing an application using binary protections, you are not solving any vulnerabilities that your application
might have. Indeed particular care should be given to ensure that these protections do not mask any issues that
may have been identified without them.