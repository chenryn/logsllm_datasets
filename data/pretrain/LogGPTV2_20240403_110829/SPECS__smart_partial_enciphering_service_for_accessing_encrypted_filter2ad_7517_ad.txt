argmax protocol i.e. k − 1 comparisons and O(k) homomorphic operations. Thus, compared to non-encrypted
computation, the overhead comes only from the use of homomorphic encryption operations instead of plaintext
operations. Regarding the number of round trips, these are due to the argmax protocol: k − 1 runs of the comparison
protocol and k − 1 additional roundtrips.
7 Private decision trees
A private decision tree classiﬁer allows the server to traverse a binary decision tree using the client’s input x such that
the server does not learn the input x, and the client does not learn the structure of the tree and the thresholds at each
node. A challenge is that, in particular, the client should not learn the path in the tree that corresponds to x – the position
of the path in the tree and the length of the path leaks information about the model. The outcome of the classiﬁcation
does not necessarily leak the path in the tree
The idea is to express the decision tree as a polynomial P whose output is the result of the classiﬁcation, the class
predicted for x. Then, the server and the client privately compute inputs to this polynomial based on x and the thresholds
wi. Finally, the server evaluates the polynomial P privately.
7.1 Polynomial form of a decision tree
Consider that each node of the tree has a boolean variable associated to it. The value of the boolean at a node is 1 if, on
input x, one should follow the right branch, and 0 otherwise. For example, denote the boolean variable at the root of the
tree by b1. The value of b1 is 1 if x1 ≤ w1 (recall Figure 2), and 0 otherwise.
We construct a polynomial P that, on input all these boolean variables and the value of each class at a leaf
node, outputs the class predicted for x. The idea is that P is a sum of terms, where each term (say t) corresponds
13
to a path in the tree from root to a leaf node (say c). A term t evaluates to c iff x is classiﬁed along that path
in T , else it evaluates to zero. Hence, the term corresponding to a path in the tree is naturally the multiplication
of the boolean variables on that path and the class at the leaf node. For example, for the tree in Figure 3, P is
P (b1, b2, b3, b4, c1, . . . , c5) = b1(b3 · (b4 · c5 + (1 − b4) · c4) + (1 − b3) · c3) +(1 − b1)(b2 · c2 + (1 − b2) · c1).
Figure 3: Decision tree with booleans
We now present F, a recursive procedure for constructing P given a binary decision tree T :
If T consists only of a leaf node with category index ci, F(T ) = ci.
If T is empty, return F(T ) = 0.
Otherwise, T has an internal node using boolean b and T0 and T1 are its
left and right subtrees. Then F(T ) = b · F(T1) + (1 − b) · F(T0).
7.2 Private evaluation of a polynomial
Let us ﬁrst explain how to compute the values of the boolean variables securely. Let n be the number of nodes in the
tree and nleaves be the number of leaves in the tree. These values must remain unknown to the server because they
leak information about x: they are the result of the intermediate computations of the classiﬁcation criterion. For each
boolean variable bi, the server and the client engage in the comparison protocol to compare wi and the corresponding
to FHE using Protocol 2, thus obtaining [(cid:74)bi(cid:75)].
attribute of x. As a result, the server obtains [bi] for i ∈ 1 . . . n; the server then changes the encryption of these values
The server evaluates P on ([(cid:74)b1(cid:75)], . . . , [(cid:74)bn(cid:75)]) using the homomorphic properties of FHE. In most cases, FHE
evaluation is very slow, but we succeed to make it efﬁcient through a combination of techniques we now discuss. To
understand these techniques, recall that a typical FHE evaluation happens over a circuit whose gates are modular
addition and multiplication. The performance of FHE depends a lot on the depth of multiplications in this circuit.
First, we use a leveled FHE scheme: a scheme that supports only an a priori ﬁxed multiplicative depth instead of an
arbitrary such depth. As long as this depth is small, such a scheme is much faster than a full FHE scheme.
Second, we ensure that the multiplicative depth is very small using a tree-based evaluation. If hmax is the maximum
height of the decision tree, then P has a term a1 · . . . · ahmax. If we evaluate this term naïvely with FHE, we multiply
these values sequentially. This yields a multiplicative depth of hmax, which makes FHE slow for common hmax values.
Instead, we construct a binary tree over these values and multiply them in pairs based on the structure of this tree. This
results in a multiplicative depth of log2 hmax (e.g., 4), which makes FHE evaluation signiﬁcantly more efﬁcient.
14
b1b2c1c2b3c3b4c4c501011100cT1T0b01Finally, we use F2 as the plaintext space and SIMD slots for parallelism. FHE schemes are signiﬁcantly faster when
the values encrypted are bits (namely, in F2); however, P contains classes (e.g., c1) which are usually more than a bit
in length. To enable computing P over F2, we represent each class in binary. Let l = (cid:100)log2 k(cid:101) (k is the number of
classes) be the number of bits needed to represent a class. We evaluate P l times, once for each of the l bits of a class.
Concretely, the j-th evaluation of P takes as input b1, . . . , bn and for each leaf node ci, its j-th bit cij. The result is
P (b1, . . . , bn, c1j, c2j, . . . , cnleavesj), which represents the j-th bit of the outcome class. Hence, we need to run the FHE
evaluation l times.
To avoid this factor of l, the idea is to use a nice feature of FHE called SIMD slots (as described in [SV11]): these
allow encrypting multiple bits in a single ciphertext such that any operation applied to the ciphertext gets applied in
parallel to each of the bits. Hence, for each class cj, the server creates an FHE ciphertext [(cid:74)cj0, . . . , cjl−1(cid:75)]. For each
node bi, it creates an FHE ciphertext [(cid:74)bi, . . . , bi(cid:75)] by simply repeating the bi value in each slot. Then, the server runs
one FHE evaluation of P over all these ciphertexts and obtains [(cid:74)co0, . . . , col−1(cid:75)] where co is the outcome class. Hence,
instead of l FHE evaluations, the server runs the evaluation only once. This results in a performance improvement of
log k, a factor of 2 and more in our experiments. We were able to apply SIMD slots parallelism due to the fortunate fact
that the same polynomial P had to be computed for each slot.
Finally, evaluating the decision tree is done using 2n FHE multiplications and 2n FHE additions where n is the
number of criteria. The evaluation circuit has multiplication depth (cid:100)log2(n) + 1(cid:101).
7.3 Formal description
Protocol 6 describes the resulting protocol.
Protocol 6 Decision Tree Classiﬁer
Client’s (C) Input: x = (x1, . . . , xn) ∈ Zn, secret keys SKQR, SKF HE
Server’s (S) Input: The public keys PKQR, PKF HE, the model as a decision tree, including the n thresholds {wi}n
Client’s Output: The value of the leaf of the decision tree associated with the inputs b1, . . . , bn.
i=1.
corresponding attribute of x.
1: S produces an n-variate polynomial P as described in section 7.1.
2: S and C interact in the comparison protocol, so that S obtains [bi] for i ∈ [1 . . . n] by comparing wi to the
3: Using Protocol 2, S changes the encryption from QR to FHE and obtains [(cid:74)b1(cid:75)], . . . , [(cid:74)bn(cid:75)].
[(cid:74)ci1, . . . , cil(cid:75)]. S uses SIMD slots to compute homomorphically [(cid:74)P (b1, . . . , bn, c10, . . . , cnleaves0),
P (b1, . . . , bn, c1l−1, . . . , cnleavesl−1)(cid:75)]. It rerandomizes the resulting ciphertext using FHE’s rerandomization
5: C decrypts the result as the bit vector (v0, . . . , vl−1) and outputs(cid:80)l−1
4: To evaluate P , S encrypts the bits of each category ci using FHE and SIMD slots, obtaining
. . . ,
function, and sends the result to the client.
i=0 vi · 2i.
Proposition 7.1. Protocol 6 is secure in the honest-but-curious model.
Proof intuition. The proof is in Appendix C, but we give some intuition here. During the comparison protocol, the
server only learns encrypted bits, so it learns nothing about x. During FHE evaluation, it similarly learns nothing about
the input due to the security of FHE. The client does not learn the structure of the tree because the server performs the
evaluation of the polynomial. Similarly, the client does not learn the bits at the nodes in the tree because of the security
of the comparison protocol.
The interactions between the client and the server are due to the comparisons almost exclusively: the decision tree
evaluation does not need any interaction but sending the encrypted result of the evaluation.
15
bool Linear_Classifier_Client::run()
{
exchange_keys();
// values_ is a vector of integers
// compute the dot product
mpz_class v = compute_dot_product(values_);
mpz_class w = 1; // encryption of 0
// compare the dot product with 0
return enc_comparison(v, w, bit_size_, false);
}
void Linear_Classifier_Server_session::
run_session()
{
}
exchange_keys();
// enc_model_ is the encrypted model vector
// compute the dot product
help_compute_dot_product(enc_model_, true);
// help the client to get
// the sign of the dot product
help_enc_comparison(bit_size_, false);
Figure 4: Implementation example: a linear classiﬁer
Bit size
A Computation
B Computation
10
20
32
64
14.11 ms
18.29 ms
22.9 ms
34.7 ms
8.39 ms
14.1 ms
18.8 ms
32.6 ms
Total Time
105.5 ms
117.5 ms
122.6 ms
134.5 ms
Communication
Interactions
4.60 kB
8.82 kB
13.89 kB
27.38 kB
3
3
3
3
Table 3: Comparison with unencrypted input protocols evaluation.
8 Combining classiﬁers with AdaBoost
AdaBoost is a technique introduced in [FS97]. The idea is to combine a set of weak classiﬁers hi(x) : Rd (cid:55)→ {−1, +1}
(cid:33)
to obtain a better classiﬁer. The AdaBoost algorithm chooses t scalars {αi}t
i=1 and constructs a strong classiﬁer as:
(cid:32) t(cid:88)
H(x) = sign
αihi(x)
i=1
If each of the hi(·)’s is an instance of a classiﬁer supported by our protocols, then given the scalars αi, we can easily
and securely evaluate H(x) by simply composing our building blocks. First, we run the secure protocols for each of
hi, except that the server keeps the intermediate result, the outcome of hi(x), encrypted using one of our comparison
protocols (Rows 2 or 4 of Table 2). Second, if necessary, we convert them to Paillier’s encryption scheme with Protocol 2,
and combine these intermediate results using Paillier’s additive homomorphic property as in the dot product protocol
Protocol 3. Finally, we run the comparison over encrypted data algorithm to compare the result so far with zero, so that
the client gets the ﬁnal result.
9 Implementation
We have implemented the protocols and the classiﬁers in C++ using GMP4, Boost, Google’s Protocol Buffers5, and
HELib [Hal13] for the FHE implementation.
The code is written in a modular way: all the elementary protocols deﬁned in Section 4 can be used as black boxes
with minimal developer effort. Thus, writing secure classiﬁers comes down to invoking the right API calls to the
protocols. For example, for the linear classiﬁer, the client simply calls a key exchange protocol to setup the various
keys, followed by the dot product protocol, and then the comparison of encrypted data protocol to output the result, as
shown in Figure 4.
4http://gmplib.org/
5https://code.google.com/p/protobuf/
16
Protocol
Bit size
Comparison
Reversed Comp.
64
64
Computation
Party A
45.34 ms
48.78 ms
Party B
43.78 ms
42.49 ms
Total Time
Communication
Interactions
190.9 ms
195.7 ms
27.91 kB
27.91 kB
6
6
Table 4: Comparison with encrypted input protocols evaluation.
Party A Computation
Party B Computation
30.80 ms
255.3 ms
Total Time
360.7 ms
Communication
Interactions
420.1 kB
2
Table 5: Change encryption scheme protocol evaluation.
10 Evaluation
To evaluate our work, we answer the following questions: (i) can our building blocks be used to construct other
classiﬁers in a modular way (Section 10.1), (ii) what is the performance overhead of our building blocks (Section 10.3),
and (iii) what is the performance overhead of our classiﬁers (Section 10.4)?
10.1 Using our building blocks library
Here we demonstrate that our building blocks library can be used to build other classiﬁers modularly and that it is
a useful contribution by itself. We will construct a multiplexer and a face detector. A face detection algorithm over
encrypted data already exists [AB06, AB07], so our construction here is not the ﬁrst such construction, but it serves as
a proof of functionality for our library.
10.1.1 Building a multiplexer classiﬁer
A multiplexer is the following generalized comparison function:
(cid:40)
fα,β(a, b) =
α if a > b
β otherwise