tained the client’s verbal consent to participate. We also asked
participants for permission to audio record the consultation
for data collection purposes and received permission to record
36 out of 46 consultations. If the participant did not want to
be audio recorded, we instead took detailed notes.
After receiving the client’s consent to participate, we fol-
lowed the consultation procedure detailed in Section 4, in-
cluding questions from the TAQ, constructing a technograph,
scanning the client’s devices with ISDi, and performing man-
ual privacy conﬁguration checks. Whenever possible, we
suggested it may be advantageous for the client to have their
case manager or another IPV professional present during the
consultation so they could assist with safety planning and/or
documenting relevant ﬁndings. In total, 16 out of 44 clients
had a professional present during their consultation. After per-
forming all procedures and discussing relevant ﬁndings with
the client (and professional, if present) we thanked the client
for their time. For clients requiring followup, we discussed
what that followup would be and conﬁrmed the relevant pro-
fessional to contact when the followup was complete.
Data collection and analysis. We collected detailed hand-
written notes and audio recordings (when permitted) that
document each consultation, including client answers to TAQ
questions, discussion of their digital footprint, details of man-
ual privacy checks, results from ISDi device scans, the advice
or recommendations discussed with the client, and any fol-
lowups that were done. All audio recordings were profession-
ally transcribed and collated by consultation with the relevant
handwritten notes, completed technograph, and ISDi data.
USENIX Association
28th USENIX Security Symposium    113
We manually went through all this data multiple times to
carefully summarize each consultation and produce the de-
scriptive and aggregate statistics presented in Section 7. The
data was stored securely with controls limiting access to only
the subset of the research team that performed analysis.
Safety protocols. As discussed in Section 3, IPV presents
a sensitive landscape within which to conduct research and
survivors are a vulnerable, at-risk population. Our research
procedures were carefully designed to protect clients’ privacy
and safety. For example, we did not ask participants to sign
a consent form since we did not want to know or collect any
identifying information (e.g., names), and all communication
with clients took place through the referring professional,
including scheduling and any post-consultation followups.
Although we offered participants a variety of printed hand-
outs to help them understand their digital safety and privacy,
we explained there may be risks with taking such materi-
als home, especially if they still lived with their abuser, since
someone may discover they had received a consultation. In ad-
dition, since changing privacy settings or uninstalling surveil-
lance apps could lead to potentially dangerous escalation of
abuse, whenever possible we encouraged participants to have
a trusted IPV professional present during their consultation.
When this was not possible, we made sure that another experi-
enced case worker was available to help develop safety plans
that accounted for any detected tech abuse and/or discuss new
protection strategies that participants may want to adopt.
We also considered safety and well-being for our research
team. Part of our training included ways to balance the need
to properly inform participants about who we were and our
afﬁliation, while avoiding giving out detailed identifying in-
formation about the individual researchers. For example, we
introduced ourselves by ﬁrst name only. This was because
of the risk that spyware on devices was recording conversa-
tions.6 In addition, working with IPV survivors and hearing
their stories may be mentally and emotionally challenging.
We regularly met as a team after consultations to debrief and
encouraged team members to discuss their feelings, experi-
ences, or anything they were struggling with. Moreover, an
experienced IPV case worker was available at all times to
speak with researchers and help them process any upsetting
experiences that occurred during the consultations.
7 Results of the Field Study
The main goal of our study was to evaluate the utility of our
consultation protocol for IPV victims. Our tools and instru-
ments uncovered important, potentially dangerous security
problems that we discussed with clients and professionals.
This preliminary data suggests our consultation protocol pro-
6We explored other ways to protect researchers, such as leaving client
devices outside or placing them in sound-insulated containers or Faraday
bags, but these proved impractical.
vides beneﬁts. Given the small sample size taken from a sin-
gle city, we warn that our results should not be interpreted as
statistically representative of problems faced by IPV survivors.
We discuss limitations of our results more in Section 8.
For the sake of client anonymity, we necessarily cannot
report on the full details of our consultations. Instead, we give
aggregate results, or when we discuss a particular situation
we only do so in a way that makes it coincide with widely
reported IPV technology abuse situations, as per prior work [8,
14, 19, 20, 27, 35, 43] and our experiences.
Participants and devices. We conducted a total of 46 con-
sultations with 44 IPV survivors (43 female, 1 male) who
were all clients at the FJCs. Two clients received second con-
sultations (at their request) to scan additional devices. All
participants were adults and one still lived with their abuser.
As shown in Figure 3 (left table), clients brought a total
of 105 devices to the consultations. Of these 82 were An-
droid or iOS and we scanned 75 of these with ISDi. Two
unscanned devices were iPhone Xs, which initially caused an
error in ISDi when Apple changed the format of device IDs
(updates to ISDi ﬁxed this for subsequent scans). In two cases,
ISDi could not scan a very old iPhone, potentially due to an
error in the libimobiledevice tool we use to communicate with
devices. One iPhone was not scanned due to a client leaving
early and two other phones were not scanned either because
the client was locked out of the device or stated they were
not concerned about scanning it. All devices that were not
scanned with ISDi were checked manually, except two where
clients were locked out of the device (a phone and laptop).
We performed manual checks on 97 out of 105 devices
brought in by clients. Clients brought a number of devices for
which we did not have a protocol for manual privacy check up,
including Internet-of-Things devices such as Amazon Echos,
gaming systems, a Blackberry phone, and a ﬂip phone. We
performed a best-effort inspection in such cases, except the
ﬂip phone for which the client had no privacy concerns.
Participants’ chief concerns. Clients expressed a range of
chief concerns, as shown in Figure 3 (middle table). The
descriptions here, such as “abuser hacked accounts” reﬂect
terminology used by clients. A relatively large number of
clients (20) described experiences that suggest abusers had
access to clients’ online accounts (often described as “hack-
ing”) or reported evidence indicative of such access (e.g.,
abuser knows information only stored in an account). The
second most prevalent chief concern (18 clients) were gen-
eral concerns about their abuser tracking them or installing
spyware, but without speciﬁc reasons for suspecting it. Other
clients were concerned that their location was being tracked,
their phone was acting suspiciously, and more. Finally, a few
clients wanted to learn more about tech privacy and had no
speciﬁc concerns about tech abuse directed towards them.
Chief concerns were often connected to the security is-
sues we detected, discussed more below. For example, chief
114    28th USENIX Security Symposium
USENIX Association
Clients & Devices
Chief Concerns
Clients seen
Consultations performed
Devices seen
Devices manually inspected
Devices scanned w/ ISDi
Median devices per client
Max devices per client
Median apps per scanned device
44
46
105
97
75
2
7
170
Worried about tech abuse/tracking/spyware
Abuser hacked accounts or knows secrets
Worried abuser was tracking their location
Phone is glitchy
Abuser calls from unknown numbers
Unrecognized app on child’s phone
Money missing from bank account
Curious and want to learn about privacy
18
20
10
10
9
1
1
4
Detected Issues
Clients w/ vulnerabilities
Clients w/ unsolved problems
Clients w/ no problems detected
Potential spyware detected
Potential password compromise
Presence of unknown “trusted” devices
Shared family/phone plan
Rooted device
23
2
19
3
14
12
4
1
Figure 3: Summary of ﬁeld study results. Left: Breakdown of the number of clients seen, consultations performed, and devices
encountered. Middle: The chief concerns, as described by the clients (some had multiple chief concerns). Right: The problems
detected during consultations, including vulnerabilities, security risks, and spyware (some clients had multiple problems).
concerns involving illicit access to accounts were often best
explained by poor password practices, family sharing, or con-
ﬁrmation of account access by abuser devices. In one case
the chief concern was entirely unrelated to the discovered
security issue, however. All this conﬁrms the importance of
both identifying the chief concerns, but also using instruments
and procedures that may surface unexpected problems.
Security vulnerabilities discovered. For 23 of 44 clients
(52%), our consultations identiﬁed important security risks,
vulnerabilities, or plausible vectors for tech abuse. Before
describing our ﬁndings, it is important to note that, in most
cases, we do not have deﬁnitive proof that the vulnerabili-
ties discovered are the root causes of clients’ problems. For
example, if a client’s password is the name of a child they
share with the abuser, or if their phone is part of a shared
family plan, these provide plausible theories for, but not hard
evidence of, how compromises may be occurring.
Results from ISDi: ISDi ﬂagged a total of 79 apps as prob-
lematic across all device scans. The majority of these (61)
were dual-use apps, with “ﬁnd my phone” and child mon-
itoring apps the most prevalent categories. For all but one
of these dual-use apps, discussions with clients conﬁrmed
that they recognized the apps and were aware of their pres-
ence. For one dual use app, the client said that they did not
install or recognize the app, which was a controller for remote
home surveillance systems with WiFi, camera, and motion
detection capabilities. We treated this case as a true positive
result. The other 18 apps detected by ISDi were false pos-
itives (i.e., clearly not relevant to IPV) that the consultant
easily dismissed as such. The number of false positives in
any individual consultation was low, the maximum number
of ﬂagged apps on a client’s device was ﬁve. This meant that,
thus far, we have not had any issues with consultants being
overwhelmed by large numbers of apps ﬂagged by ISDi.
The relatively low rate of actual spyware detection may
be because, as discussed below, many abusers are seemingly
able to surveil clients via compromised accounts, and so may
not need to install spyware. In addition, almost all clients no
longer lived with the abuser, had changed or reset their devices
since leaving (which would remove spyware in most cases),
and for many devices the abuser no longer had physical access
needed to (re-)install spyware. Finally, ISDi detected that one
client’s Android tablet was rooted. Subsequent discussion
revealed that the abuser bought this tablet for the client, had
physical access to it during the relationship, and had insisted
the client log into her accounts with it. As a result of our
conversation, the client decided to stop using the tablet.
Results from TAQ and technograph: For many clients, we
discovered security vulnerabilities through combined use of
the TAQ, technograph, and/or manual privacy checks. In some
cases, the TAQ and technograph were the primary (or only)
way to uncover a potential problem. For example, four clients
reported that they were still part of a shared family plan or
that their abuser pays for their phone plan, vulnerabilities that
could give the abuser access to, for example, the location of
the client’s device and call and text history. Another common
problem that the TAQ and technograph revealed for 14 clients
was the use of passwords that the client said were known, or
could be guessed, by their abuser. In several of these cases, a
compromised password provided a plausible explanation for
how the abuser may be gaining access to the client’s accounts.
Results from manual checks: Combining TAQ and techno-
graph information with subsequent manual privacy checks
often yielded evidence of malicious account access. For ex-
ample, during manual checks of iCloud account settings for
four clients, we discovered that their iCloud accounts listed
“trusted” devices that the client either did not know or recog-
nized as belonging to the abuser. Similarly, manual checks of
client email and social media accounts showed unknown or
abuser device logins for another eight clients.
iCloud and email account access, whether by password
compromise or via unauthorized “trusted” device access, also
yielded plausible explanations for a range of other problems.
For example, three clients reported that they kept written
records of passwords for all their accounts in ﬁles that were
then synced with their compromised iCloud, potentially re-
sulting in the abuser obtaining all these passwords. Similarly,
several clients emailed copies of their new passwords to them-
selves via potentially compromised email accounts. Another
prevalent avenue for compromise that we saw happened when
USENIX Association
28th USENIX Security Symposium    115
clients used a compromised account as the backup account
for other services (e.g., social media), with clients unaware
of how this might result in abuser access to these services.
For two clients, manual checks of laptops revealed browser
extensions that the clients did not install or know about. In
one case, the extension was “off store” (not available via
the ofﬁcial Chrome Web Store), may have been sideloaded
(installed via developer mode), and had permission to read and
write all browser data. We regarded this as possible spyware.
For the other case, the extension is available via the Chrome
Store and is used to monitor access to web content. This
extension provides a plausible explanation for the client’s
chief concern, which was that her abuser knew about her
online activities, and we regarded it as probable spyware.
No problems detected. For 21 out of 44 clients, our instru-
ments did not surface any evidence of potential tech issues.
For 19 of these, the lack of discovered problems was reassur-
ing and many left the consultation visibly relieved and more
at ease. However, in two cases, the consultation’s inability to
address their chief concerns left the client unsatisﬁed. In these
cases we performed follow-up research, including reaching
out to other tech experts for second opinions about their con-
cerns (in an anonymized fashion) but unfortunately still have
no plausible explanation for what they were experiencing.
Hand-off and followup. For the 23 clients with discovered
problems and two clients with unresolved issues, we con-