complex fork choice rules and added reference links to convert the
blocktree into a directed acyclic graph (DAG). This allows blocks
to be voted on by blocks that are not necessarily its descendants.
2The powerful adversary will be precisely defined in the formal model.
3This idea was inspired by the concept of list decoding from information theory.
2
𝑂(𝐷)BitcoinPrism (order optimal)LatencySecurity parameter: log()𝑂(𝐶𝐷/𝐵-)Slope =𝑂(D)Slope =𝑂/01𝑂(1)Figure 2: Deconstructing the blockchain into transaction
blocks, partially ordered proposal blocks arranged by level,
and voter blocks organized in a voter tree. The main chain
is selected through voter blocks, which vote among the pro-
posal blocks at each level to select a leader block. For exam-
ple, at level 3, block b is elected the leader over block a.
While GHOST remains secure at low mining rates[11], there is
a balancing attack by the adversary [12, 17], which severely limits
the security at high mining rates. Thus, like Bitcoin, the throughput
of GHOST is security-limited. The other protocols Inclusive and
Conflux that rely on GHOST inherit this drawback. While Spectre
and Phantom improve latency and throughput, Spectre cannot pro-
vide a total order on all transactions (required for smart contracts)
and Phantom does not yet have a formal proof of security.
Decoupled consensus. Protocols such as BitcoinNG [7] decou-
ple transaction proposal and leader election (which are coupled
together in Bitcoin). BitcoinNG elects a single leader to propose
many transaction blocks till the next leader is elected by PoW. While
this achieves high throughput, the latency cannot be reduced using
this approach. Furthermore, BitcoinNG is vulnerable to bribery
or DDoS attacks, whereby an adversary can corrupt a leader af-
ter learning its identity (unlike Bitcoin). Subchains [22] and weak
blocks [3, 26] both employ blocks with lower hash threshold (“weak
blocks”) along with regular blocks in an attempt to scale through-
put. However, since weak blocks are required to form a chain, it
does not achieve the optimal throughput.
Hybrid blockchain-BFT consensus. Several protocols combine
ideas from Byzantine fault tolerant (BFT) based consensus into a
PoW setting [1, 13, 20, 21]. ByzCoin [13] and its predecessor Disc-
Coin [6] attempt to address the latency shortcoming of BitcoinNG
but is proven in a later paper [20] to be insecure when the ad-
versarial fraction β > 0.25. Hybrid consensus uses a combination
of proof-of-work based committee selection with Byzantine fault
tolerance (BFT) consensus [20]. However, this protocol is secure
only till β = 0.33. While the protocol latency is responsive, i.e., it
decreases with network delay linearly, for a known network delay,
it has similar non-optimal dependence on ε as Bitcoin.
A closely-related protocol called Thunderella [21] achieves very
low latency under optimistic conditions, i.e., when the leader is hon-
est and β < 0.25. However even when β is very small, a dishonest
leader can keep delaying transactions to the Bitcoin latency (since
such delaying behavior is detected by a slow PoW blockchain).
3
Figure 3: Prism. Throughput, latency and reliability are
scaled to the physical limits by increasing the number of
transaction blocks and the number of parallel voting chains.
1.5 Our Approach
Increasing the mining rate is critical to improving the throughput
and latency of blockchain protocols. The challenges facing the DAG
approaches arise from the fact that the DAG is unstructured, due to
the excessive random forking when the mining rate is increased.
In contrast, Prism is based on a structured DAG created by crypto-
graphic sortition of the mined blocks into different types of different
functionalities and scaling these functionalities separately.
Deconstruction. We start by deconstructing the basic blockchain
structure into its atomic functionalities, illustrated in Figure 2. The
selection of a main chain in a blockchain protocol (e.g., the longest
chain in Bitcoin) can be viewed as electing a leader block among
all the blocks at each level of the blocktree, where the level of
a block is defined as its distance (in number of blocks) from the
genesis block. Blocks in a blockchain then serve three purposes:
they stand for election to be leaders, they add transactions to the
main chain, and they vote for ancestor blocks through parent link
relationships. We explicitly separate these three functionalities
by representing the blocktree in a conceptually equivalent form
(Figure 3). In this representation, blocks are divided into three
types: proposer blocks, transaction blocks and voter blocks. The
voter blocks vote for transactions indirectly by voting for proposer
blocks, which in turn link to transaction blocks . Proposer blocks
are grouped according to their level in the original blocktree, and
each voter block votes among the proposer blocks at the same level
to select a leader block among them. The elected leader blocks can
then bring in the transactions to form the final ledger. The valid
voter blocks are the ones in the longest chain of the voter tree, and
this longest chain maintains the security of the whole system.
Scaling. This alternative representation of the traditional blockchain,
although seemingly more complex than the original blockchain
representation, provides a natural path for scaling performance
to approach physical limits (Figure 3). To increase the transaction
throughput, one can simply increase the number of transaction
blocks that a proposer block points to without compromising the
security of the blockchain. This number is limited only by the phys-
ical capacity of the underlying communication network. To provide
fast confirmation, one can increase the number of parallel voting
trees, voting on the proposal blocks in parallel to increase the voting
rate, until reaching the physical limit of confirming with speed-of-
light latency and extremely high reliability. Note that even though
the overall block generation rate has increased tremendously, the
Deconstructing BlockchainDecoupling TransactionsDecoupling Voting𝑎𝑎𝑏𝑏LLLLLLLLProposer blockTransaction blockLeader blockLVoter blockParent LinkReference LinkLLLLProposer blockTransaction blockLeader blockLVoter blockParent LinkReference LinkChain 1Chain 2Chain 𝑚number of proposal blocks per level remains small and manage-
able, and the voting blocks are organized into many separate voting
chains with low block mining rate per chain and hence little forking.
The overall structure, comprising of the different types of blocks
and the links between them, is a structured DAG.
Sortition. The sortition of blocks into the three types of blocks, and
further into blocks of different voting trees, can be accomplished by
using the random hash value when a block is successfully mined.
This sortition splits the adversary power equally across the struc-
tures and does not allow it to focus its power to attack specific
structures. This sortition is similar to the 2-for-1 PoW technique
used in [9], which is also used in Fruitchains [19] for the purpose
of providing fairness in rewards. In fact, the principle of decoupling
functionalities of the blockchain, central to our approach, has al-
ready been applied in Fruitchains, as well as other works such as
BitcoinNG. The focus of these works is only on decoupling the
transactions-carrying functionality. In our work, we broaden this
principle to decouple all functionalities. Concurrent work. We
were made aware of two independent but related works [8, 27]
which appeared after we posted this work online. [8] proposes two
protocols, one achieves high throughput O(C) but Bitcoin latency,
and the other achieves low latency O(1/√
C) but low throughput
O(1). In contrast, Prism achieves simultaneously high throughput
O(C) and even lower latency O(1/C). Although [8] also uses the
concept of multiple chains, the key difference with Prism is that
there is no decoupling: the blocks in each chain both carry trans-
actions and vote. Thus, either different transactions are put on the
different chains to increase throughput, but the voting rate is low
and hence the latency is poor, or the same transaction is repeated
across all the chains to increase the voting rate, but the throughput
is poor. In contrast, Prism decouples blocks into transaction blocks
and voter blocks, tied together through proposer blocks, and allo-
cate a fraction of the network capacity to each to deliver both low
latency and high throughput. The protocol in [27] is similar to first
one in [8], achieving high throughput but only Bitcoin latency.
1.6 Outline of paper
Section 2 presents our model. It is a combination of the synchronous
model used in [9] and a network model that ties the blockchain
parameters to physical parameters of the underlying network. In
Section 3, we give a pseudocode description of Prism. The analysis
of the security, throughput and latency of Prism is presented in
Section 4, with details of the proofs in the appendices. Section 5
contains simulation results.
2 MODEL
We consider a synchronous, round-based network model similar
to that of Garay et al. [9]. We define a blockchain protocol as a
pair (Π, д), where Π is an algorithm that maintains a blockchain
data structure C consisting of a set of blocks. The function д(tx, C)
encodes a ledger inclusion rule; it takes in a transaction tx and a
blockchain C, and outputs д(tx, C) = 1 if tx is contained in the
ledger defined by blockchain C and 0 otherwise. For example, in
Bitcoin, д(tx, C) = 1 iff tx appears in any block on the longest chain.
If there are multiple longest chains, д can resolve ties deterministi-
cally, e.g., by taking the chain with the smallest hash value.
4
The blockchain protocol proceeds in rounds of ∆ seconds each.
Letting κ denote a security parameter, the environment Z(1κ) cap-
tures all aspects external to the protocol itself, such as inputs to the
protocol (i.e., new transactions) or interaction with outputs.
Let N denote the set of participating nodes. The set of honest
nodes H ⊂ N strictly follow the blockchain protocol (Π, f ). Cor-
rupt nodes N \H are collectively controlled by an adversarial party
A. Both honest and corrupt nodes interact with a random function
H : {0, 1}∗ → {0, 1}κ through an oracle H(x), which outputs H(x).
In each round, each node n ∈ N is allowed to query the oracle H(·)
at most q times. The adversary’s corrupt nodes are collectively al-
lowed up to βq|N| sequential queries to oracle H(·), where β < 0.5
denotes the fraction of adversarial hash power, i.e., 1 − |H|
|N| = β.4
Like [9], the environment is not allowed to access the oracle. These
restrictions model the limited hash rate in the system.
In an execution of the blockchain protocol, the environment Z
first initializes all nodes as either honest or corrupt; like [9], once
the nodes are initialized, the environment can adaptively change
the set H between rounds, as long as the adversary’s total hash
power remains bounded by β. Thereafter, the protocol proceeds
in rounds. In each round, the environment first delivers inputs to
the appropriate nodes (e.g., new transactions), and the adversary
delivers any messages to be delivered in the current round. Here,
delivery means that the message appears on the recipient node’s
input tape. Nodes incorporate the inputs and any messages (e.g.,
new blocks) into their local blockchain data structure according to
protocol Π. The nodes then access the random oracle H(·) as many
times as their hash power allocation allows. Hence, in each round,
users call the oracle H(·) with different nonces s in an attempt to
find a valid proof of work. If an oracle call produces a proof of work,
then the node can deliver a new block to the environment. Note
that the computational constraints on calling oracle H(·) include
block validation. Since each block only needs to be validated once,
validation represents a small fraction of computational demands.
Since each node is allowed a finite number of calls to H(x) in each
round, the number of blocks mined per round is a Binomial random
variable. To simplify the analysis, we consider a limit of our model
as the number of nodes |N| → ∞. As |N| grows, the proof-of-work
threshold adjusts such that the expected number of blocks mined
per round remains constant. Hence, by the Poisson limit theorem,
the number of voter blocks mined per round converges to a Poisson
random variable.
All messages broadcast to the environment are delivered by the
adversary. The adversary has various capabilities and restrictions.
(1) Any message broadcast by an honest node in the previous round
must be delivered by the adversary at the beginning of the current
round to all remaining honest nodes. However, during delivery,
the adversary can present these messages to each honest node in
whatever order it chooses. (2) The adversary cannot forge or alter
any message sent by an honest node. (3) The adversary can control
the actions of corrupt nodes. For example, the adversary can choose
how corrupt nodes allocate their hash power, decide block content,
and release mined blocks. Notably, although honest blocks publish
mined blocks immediately, the adversary may choose to keep blocks
4β for bad. Like [9], we have assumed all nodes have the same hash power, but this
model can easily be generalized to arbitrary hash power distributions.
they mined private and release in future round. (4) The adversary
can deliver corrupt nodes’ messages to some honest nodes in one
round, and the remaining honest nodes in the next round. We
consider a “rushing” adversary that observes the honest nodes’
actions before taking its own action for a given round. Notice that
we do not model rational users who are not necessarily adversarial
but nevertheless may have incentives to deviate from protocol.
+ D
Physical Network Constraints. To connect to the physical param-
eters of the network, we assume a simple network model. Let B be
the size of a block, in units of number of transactions. The network
delay ∆ (in seconds) is given by:
∆ = B
C
(6)
i.e. there is a processing delay of B/C followed by a propagation
delay of D seconds. This is the same model used in [25], based on
empirical data in [5], as well in [22]. Notice that the network delay
∆ is by definition equal to the duration of a single round.
In practice, networks cannot transport an infinite number of
messages at once. We model this by allowing the environment to
transport only a finite volume of messages per round. This vol-
ume is parametrized by the network capacity C, measured in units
of transactions per second. Hence, during each round, the envi-
ronment can process a message volume equivalent to at most ∆C
transactions. This puts a constraint on the number of blocks mined
per unit time in any protocol. This stability constraint differenti-
ates our model from prior work, which has traditionally assumed
infinite network capacity; in particular, this gives us a foothold for
quantifying physical limits on throughput and latency.
For simplicity, we assume that the dissemination of new transac-
tions consumes no bandwidth. Instead, the cost of communicating
transaction messages is captured when the environment transmits
blocks carrying transactions. In other words, we assume that the
cost of transmitting transactions is counted only once.
Metrics. We let random variable VIEW
Π,A,Z denote the joint