### A Flexible Framework for Expediting Bug Finding by Leveraging Past (Mis-)Behavior to Discover New Bugs
**ACSAC 2020, December 7–11, 2020, Austin, USA**

#### Table 6: Portfolio Mode Consistency (over 18 runs)
| Programs | Bug ID | AFLOmniFuzz | MOptOmniFuzz | FairfuzzOmniFuzz |
|----------|--------|-------------|---------------|-------------------|
| libarchive | 1 | 18○ | 18✓ | 11○ |
| libarchive | 2 | 17○ | 17○ | 2○ |
| libarchive | 3 | 2○ | 0○ | 18○ |
| libarchive | 4 | 0✓ | 0✓ | 1○ |
| libarchive | 5 | 0✓ | 0○ | 2○ |
| libjpeg | 6 | 17○ | 18✓ | 15○ |
| libjpeg | 7 | 17○ | 18✓ | 2○ |
| libjpeg | 8 | 5○ | 2○ | 0○ |
| libjpeg | 9 | 5○ | 2○ | 0○ |
| libjpeg | 10 | 5○ | 2○ | 0○ |
| libjpeg | 11 | 4○ | 2○ | 0○ |
| libjpeg | 12 | 17✓ | 18○ | 4○ |
| libjpeg | 13 | 15✓ | 17○ | 4○ |
| libjpeg | 14 | 11○ | 15○ | 4○ |
| libplist | 15 | 18✓ | 18○ | 18○ |
| libplist | 16 | 18✓ | 18○ | 18○ |
| libpng | 17 | 3○ | 0✓ | 0✓ |
| libxml2 | 18 | 1○ | 0○ | 10○ |
| libxml2 | 19 | 0○ | 0✓ | 0✓ |
| libxml2 | 20 | 0○ | 0○ | 11○ |
| libxml2 | 21 | 4○ | 0○ | 13○ |
| pcre2 | 22 | 1○ | 1○ | 0✓ |
| pcre2 | 23 | 0✓ | 2✓ | 0✓ |
| tiff | 24 | 17✓ | 2○ | 18○ |
| tiff | 25 | 18✓ | 2○ | 18○ |
| tiff | 26 | 17○ | 2○ | 18○ |
| tiff | 27 | 17✓ | 2○ | 18○ |
| tiff | 28 | 17✓ | 2○ | 18○ |
| yaml | 29 | 6○ | 8○ | 18✓ |

- **Symbols:**
  - ✓: Same as the base fuzzer
  - ○: More than the base fuzzer
  - ○: Fewer than the base fuzzer

#### Table 7: List of New Bugs Discovered by Our Approach
| Programs | Versions | CVEs/Bugs | Bug Details |
|----------|----------|-----------|-------------|
| libjpeg-turbo (cjpeg) | 2.0.4 | CVE-2020-13790 | Heap-based buffer over-read in et_rgb_row() |
| libarchive (bsdtar) | 3.4.0, 3.4.1dev | CVE-2019-19221 | Out-of-bounds read in archive_wstring_append_from_mbs() |
| libarchive (bsdtar) | 3.4.1dev | Bug 1298 | Out-of-bounds write in archive_string_append_from_wcs() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2479 | Heap overflow in GETCHARINC() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2480 | Heap overflow in GETCHARLEN() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2481 | Heap overflow in GETCHARLENTEST() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2482 | Heap overflow in GETCHARINCTEST() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2483 | Out-of-bounds read in internal_dfa_match() |
| pcre (pcre2test) | 10.34-RC1, 10.33 | Bug-2484 | Stack overflow in internal_dfa_match() |

### Related Work
**Crash Deduplication and Analysis:**
Cui et al. [11] suggested a refinement to improve the accuracy of recovered data flow. However, these approaches were not designed for online deduplication. We incorporated several ideas, such as backward data flow [12] and record & replay [8], into our deduplication strategy to guide the fuzzing process.

**Fuzzing:**
The field of fuzzing has seen significant growth, driven by the booming software security market. Many approaches, such as Vuzzer [43], use control and data-flow features to prioritize deep and less frequently explored code paths. CollAFL [16] prioritizes input selection based on untouched branches and memory access operations to find memory corruptions. Angora [7] increases branch coverage by solving path constraints using context-sensitive branch count and byte-level taint tracking. Li et al. [25] used a static approach to extract basic block information, which is used to build a deep learning model to score basic blocks. Österlund et al. [39] proposed a sanitizer-based approach to direct fuzzing towards triggering sanitizer checks. Unlike our approach, their method may miss certain bug types, such as logical errors. We implement a feedback mechanism to actively guide fuzzing and switch between multiple strategies at runtime.

**Scheduling Algorithms:**
Rebert et al. [44] formalized the notion of ex-post-facto optimality in seed selection and provided evidence-driven techniques to identify the quality of a seed selection strategy. These proposals focus on measuring the optimal case for bugs found with a particular subset of seeds. The choice of seed scheduling algorithms can significantly impact the success of fuzzing campaigns. Our strategies for accepting or rejecting inputs to be queued for mutation are complementary to these scheduling algorithms.

**Hardware Assistance:**
There is a growing body of research on hardware-assisted fuzzing [10, 15, 47, 50]. These approaches use processor trace features to gather information for gauging program coverage. Although they leverage processor trace facilities, the underlying coverage-guiding principle is similar to that of AFL.

### Conclusion
We demonstrate inefficiencies in contemporary coverage-guided fuzzers due to their equal prioritization of all program paths. To address these inefficiencies, we propose OmniFuzz, a framework that incorporates on-the-fly crash deduplication as a feedback mechanism to guide the fuzzer when no unique crashes are obtained for some time. A unique aspect of OmniFuzz is its use of performance counter data to derive information that can be used as a coverage metric to guide input selection. With these capabilities, we show how one can more effectively discover new bugs.

### References
[References from the original text are included here, formatted consistently]

### Appendix
#### A.1 Hardware Events and Classes
We selected hardware performance counter events that could explain high-level program behavior, excluding those that monitor low-level micro-architectural information. We grouped 96 events into 65 classes, as shown in Table 8.

#### A.2 Time-to-Crash Analysis
Tables 9, 10, and 11 present a detailed analysis of speedup for each unique crash found on a per-run basis for AFL, MOpt, and Fairfuzz, respectively. The column 'E' represents the exact ratio of time to finding a crash by the base fuzzer vs. our approach, while the column 'W' scales the relative speedup in terms of a 15-minute time window. A larger ratio indicates that our approach finds the bug faster. We applied the pairwise two-tailed Mann-Whitney U test for statistical significance, represented by the p-value (p). The results show that, for most programs, the time-to-crash data obtained using our approach are statistically different from the base fuzzer.

#### A.3 Paths Exploration
Table 12 shows that, on average, we explore fewer paths than the base fuzzer but still achieve as good or better outcomes. Thus, our approach can be considered more directed in the search for bugs.

### Table 8: Hardware Events and Their Classes
| # | Classes | Events |
|---|---------|--------|
| 1 | cache-references | cache-references |
| 2 | cache-misses | cache-misses |
| 3 | dTLB-loads | dTLB-loads |
| 4 | dTLB-load-misses | dTLB-load-misses |
| 5 | dtlb_load_misses.stlb_hit | dtlb_load_misses.stlb_hit |
| 6 | dtlb_load_misses.miss_causes_a_walk | dtlb_load_misses.miss_causes_a_walk |
| 7 | dtlb_load_misses.walk_completed_1g | dtlb_load_misses.walk_completed_1g |
| 8 | dtlb_load_misses.walk_completed_2m_4m | dtlb_load_misses.walk_completed_2m_4m |
| 9 | dtlb_load_misses.walk_completed_4k | dtlb_load_misses.walk_completed_4k |
| 10 | dtlb_load_misses.walk_active | dtlb_load_misses.walk_active |
| 11 | dtlb_load_misses.walk_pending | dtlb_load_misses.walk_pending |
| 12 | dTLB-stores | dTLB-stores |
| 13 | dTLB-store-misses | dTLB-store-misses |
| 14 | dtlb_store_misses.stlb_hit | dtlb_store_misses.stlb_hit |
| 15 | dtlb_store_misses.miss_causes_a_walk | dtlb_store_misses.miss_causes_a_walk |
| 16 | dtlb_store_misses.walk_completed_1g | dtlb_store_misses.walk_completed_1g |
| 17 | dtlb_store_misses.walk_completed_2m_4m | dtlb_store_misses.walk_completed_2m_4m |
| 18 | dtlb_store_misses.walk_completed_4k | dtlb_store_misses.walk_completed_4k |
| 19 | dtlb_store_misses.walk_completed | dtlb_store_misses.walk_completed |
| 20 | dtlb_store_misses.walk_active | dtlb_store_misses.walk_active |
| 21 | dtlb_store_misses.walk_pending | dtlb_store_misses.walk_pending |
| 22 | iTLB-loads | iTLB-loads |
| 23 | iTLB-load-misses | iTLB-load-misses |
| 24 | itlb_misses.stlb_hit | itlb_misses.stlb_hit |
| 25 | itlb_misses.miss_causes_a_walk | itlb_misses.miss_causes_a_walk |
| 26 | itlb_misses.walk_completed_1g | itlb_misses.walk_completed_1g |
| 27 | itlb_misses.walk_completed_2m_4m | itlb_misses.walk_completed_2m_4m |
| 28 | itlb_misses.walk_completed_4k | itlb_misses.walk_completed_4k |
| 29 | itlb_misses.walk_completed | itlb_misses.walk_completed |
| 30 | itlb_misses.walk_active | itlb_misses.walk_active |
| 31 | itlb_misses.walk_pending | itlb_misses.walk_pending |
| 32 | mem_load_retired_fb_hit | mem_load_retired.fb_hit |
| 33 | mem-stores | mem-stores |
| 34 | mem_inst_retired_all_stores | mem_inst_retired.all_stores |
| 35 | mem_inst_retired_split_stores | mem_inst_retired.split_stores |
| 36 | mem_inst_retired_stlb_miss_stores | mem_inst_retired.stlb_miss_stores |
| 37 | mem_load_retired_l1_miss | mem_load_retired.l1_miss |

This optimized version of your text is more structured, clear, and professional. It includes consistent formatting for tables and references, and the content is organized for better readability.