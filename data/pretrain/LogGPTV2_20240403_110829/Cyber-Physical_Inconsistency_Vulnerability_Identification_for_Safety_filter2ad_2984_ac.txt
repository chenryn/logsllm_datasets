mum/minimum point of the cost functions. However, due to the
complexity of physical world and the subject system, the multiple
cost functions are unlikely smooth, that is, they are often hilly or
even discontinuous. They are typically non-linear and non-convex.
Gradient-based optimization techniques [14, 40] are suitable for
continuous and convex functions for single objective optimization
and hence do not perform well in our case. They often get stuck in
local optimals and have difficulties finding the global ones. Also,
they do not handle the multiple conflicting objectives well. In Fig-
ure 9, we use a very large number of samples 40,000 to approximate
Optimal Points (Pareto Front)CP-inconsistenciesSession 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA269the search space for an IRIS+ RV with the ArduCopter controller.
For the purpose of visualization, we use PCA [81] to reduce the
high dimensional input space to two dimensions and have the z di-
mension denote a weighted sum of the costs. Observe that there are
lots of ridges and (possible) discontinuities. The red points denote
the optimal set (i.e., Pareto optimal [78]) for the multiple objectives,
and CP-inconsistencies are located on the bottom left among the
optimal points. In our evaluation (Section 5.2), we compare different
search algorithms in exposing vulnerabilities.
Therefore, we make use of an evolutionary algorithm instead. In-
tuitively, the algorithm starts with a set of random test samples that
form the first generation. It executes these samples in the simulator
and computes the cost function values. Those samples that have
better cost function values (called healthy samples) are selected to
derive the next generation. The derivation is through two evolution
operations called cross-over and mutation, with the former mixing
parts from two parents into a child input and the latter randomly
altering values in a parent input to produce a child. The newly
derived children and the healthy parents form the next generation.
The process repeats until convergence (no better children can be
derived). According to [68], evolutionary algorithms have better
capabilities of handling noisy, discontinuous, and even discrete
functions. In the following, we explain the details of our solution.
Multi-objective Optimization for CP-inconsistency (MOP-CPi)
We reduce CP-inconsistency identification to a Multiple-objective
Optimization Problem (MOP) [25, 74]. In the previous section (Sec-
tion 4.2), we defined two types of cost functions (cyber and phys-
ical). Our goal is to search for the maximum difference between
the two. In normal conditions, both costs tend to have small values.
Conversely, in abnormal conditions, both have large values. Our
technique looks for the cases where the difference between the
two is maximum such that CP-inconsistency likely occurs. The
objective is formalized as follows.
minimize F =
subject to G = {д1, д2, . . . , дn }
Fover = {−Fγ , Fρ },
Funder = {Fγ , −Fρ },
if mode = f p
otherwise
(5)
Fover represents the objective for identifying over-approximation
vulnerabilities (false warnings), where we want to maximize the
cyber cost (i.e., minimize the negation of the cyber cost Fγ ) and
minimize the physical cost Fρ. Funder represents the objective for
under-approximation vulnerabilities (missing exceptions), where
we want to minimize the cyber cost and maximize the physical cost.
Fitness Ranking Function. Defining a ranking function to mea-
sure the level of heath of individual input samples is key to devising
an evolutionary algorithm. In our design, ranking is computed
based on the aforementioned objective function using (1) the Pareto
optimality level [25] and (2) the degree of physical anomaly.
Our objective function consists of multiple objectives (e.g., one
for each state variable or an expression derived from a safety check).
These objectives may contradict with each other, meaning that
improving one may undermine others. In our motivation example
(an under-approximation vulnerability), the cyber cost (d1, d2, d3)
for an input denoting a 0 collision angle is (1, 3, 0). It is (3, 2, 0)
when the angle is 30. Observe that the first objective d1 is better
(smaller) with a smaller angle whereas the second objective d2
is better with a larger angle. Hence, mutating the collision angle
input may have contradicting effects for different objectives. Pareto
(cid:40)
Algorithm 1 Evolutionary Testing for CP-inconsistencies Identifi-
cation
Input: G: number of generation, K: population size
Mc , Mp: number of objectives (cyber,physical)
N : number of inputs
I L, I U : input range vector (lower,upper)
Output: CP-inconsistency cases
▷ K input vectors
▷ K output vectors
▷ Initial population of size K
▷ Fitness Rankings of individuals in P
▷ main evolution loop with K individuals
▷ K/2 parents
▷ crossover/mutation, K children
▷ simulation
▷ 3K/2 candidates
▷ determine CPi cases
1: procedure CPI-Testing
X ← r andom(I L, I U )
2:
Y ← evaluation(X)
3:
P ← X, Y
4:
R ← f itness_r ank(P)
5:
6:
for G iterations || CPi found do
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19: end procedure
Ppar ent ← tournament_selection(P, R, K/2)
Xchild ← дene_op(Ppar ent , µ, η)
Ychild, R ← evaluation(Xchild)
Pchild ← Xchild, Ychild
Pcandi ← Ppar ent ∪ Pchild
CPi ← vulner able(Pcandi)
if |CPi | (cid:44) ∅ then
end if
Rcandi ← f itness_r ank(Pcandi)
P, R ← top_n_selection(Pcandi, R, K)
▷ best K individuals
save(CPi)
end for
dominance [78] was introduced to mitigate such problems. It is
widely used in optimization problems in economics, engineering
and so on. Intuitively, Pareto dominance states that an input x1
dominates (≺) x2 if x1 is not worse than x2 in all objectives and x1
is strictly better than x2 in at least one objective, which is defined
as follows:
fi(x1) ≤ fi(x2), ∀i = 1, 2, ..., M
fi(x1) < fi(x2), ∃i = 1, 2, ..., M
The Pareto optimal set (or Pareto front) contains all the elements
that are not dominated by others. It is defined as follows.
F ront(X) = {x1 ∈ X | ∄x2 ∈ X s .t . x2 ≺ x1 ∧ x1 (cid:44) x2}
(7)
Based on Pareto dominance, we can determine the optimality level
F(x) for each element x. Intuitively, the Pareto set of all elements
are at level one. After removing the level one elements, the Pareto
set of the remaining elements are at level two, and so on [28].
In addition to the Pareto optimality level, we also consider the
physical anomaly level Ω(x), which is the expected value of nor-
malized physical anomalies. It is defined as follows.
(6)
(8)
Mp
(cid:40)
1
Mp
i =1
ω(x),
−ω(x),
ω(x) =
Ω(x) =
pi − Lpi
Upi − Lpi
if mode = f p
otherwise
where Mp denotes the number of physical objectives, Upi
, Lpi
upper/lower bounds of objective pi. Depending on the search mode
f p, which is either over-approximation or under-approximation,
Ω(x) is ω(x) or its negation. Intuitively, we want higher physical
anomaly level for under-approximation and lower level for over-
approximation. Ω(x) ∈ (0, 1) enables selecting the better individuals
among those that have the same Pareto optimality level. In other
words, the fitness ranking function is the following.
(9)
The individuals with a small R value rank higher and are considered
healthier.
R(x) = F(x) + Ω(x)
Session 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA270Algorithm 1 presents the details. Each individual is represented
as an input vector of size N , with each dimension an input vari-
able. Evaluating an individual produces an output vector of size
M, each dimension denoting a cyber/physical objective. The input
vector is in the range (I L, IU ). After each generation, a population
includes the best K individuals. In lines 2-3, the algorithm generates
random inputs and evaluates them to produce the corresponding
outputs. The inputs and outputs together make the initial popu-
lation P (line 4). Based on the outputs (cyber and physical cost),
the fitness ranks are computed at line 5. It then performs evolution
over G generations (lines 6-18), or terminates when it converges.
The evolution procedure works as follows. First, it performs binary
tournament selection, which selects half of the population as par-
ents (line 7). Specifically, it picks two individuals randomly and
compares their ranks to select the better one. With the K/2 parents,
genetic operations are used to produce K children (line 8). We use
simulated binary crossover (SBX) [26] that creates an offspring by
combining parts of a pair of parents based on a parameterized prob-
ability function which simulates the natural crossover in biology,
and polynomial mutation [27, 29] that adds a small variation to a
parent which simulates biological mutation. The generic operations
take the parameters µ and η, which determine how well spread
the children will be from their parent in crossover and mutation,
respectively. We use a popular setting [28] µ = 20% and η = 20. The
children population is obtained with the inputs from the genetic op-
erations and the outputs from evaluation() (lines 9-10). Within
the current generation, including both the selected parents and the
generated children, the vulnerable() function determines if
the individuals denote CP-inconsistencies. After combining the
parents and the children, fitness_rank() further computes
the rank again and top_n_selection() selects the best K in-
dividuals for the next generation. Through evolution, the algorithm
learns to find the best individuals guided by the cost functions.
5 EVALUATION
We evaluate our technique with four popular RV control programs
running on 2 real vehicles and 6 simulated vehicles, including quad-
rotors, ground rover and fixed-wing airplane.
5.1 Evaluation Setup
Implementation. We have developed a prototype that in-
5.1.1
cludes: (1) SDF definitions to describe external environments (world.
sdf) and objects (model.sdf) with the SDF versions 1.5 and 1.6 ; (2)
Gazebo (version 8.6) plug-ins to generate customized environmen-
tal effects based on Gazebo APIs; (3) mission generator in python
for System Identification; (4) hybrid model generator implemented
on MATLAB; (5) static analysis for cyber-cost function generator;
(6) evolutionary test driver that includes a fitness ranking function
and genetic mutation operations unique to our technique.
Subject Systems. We evaluate our technique for 7 different
5.1.2
types of counter-measure functions. Table 2 shows the control pro-
grams and the vehicles. The 6th column (# Modes) represents the
number of operation modes such as loiter, auto, rtl, etc. The last
column shows the number of safety violations under test. Table 3
shows the types of safety violations that are being checked against
Table 2: Subject Programs
Software
Version
SLOC
Type
Vehicle
# Modes
# Safety
violations
ArduCopter
APMrover2
PX4
ArduPlane
3.7
3.2
1.5.3
3.5
1.8.2
3.10
212,470
119,326
212,601
Quadrotor
Quadrotor
Quadrotor
203,266
Rover
346,561
Quadrotor
208,828
Airplane
IRIS+
Erle-Copter
Solo
Husky
Erle-Rover
IRIS+
Solo
Zephyr
22
15
17
12
12
15
15
15
4
3
4
1
1
3
3
2
Table 3: Subject Safety-check Types
Safety-check Type
ArduCopter
APMrover2
PX4
ArduPlane
Crash
Thrust Loss
Ground Contact
Landing
Freefall
Control Loss (Parachute)
Flying (Landed)
✓: Supported, ✗: Not supported
✓
✓
✗
✓
✗
✓
✗
✓
✗
✗
✗
✗
✗
✗
✗
✗
✓
✓
✓
✗
✗
✓
✗
✗
✗
✗
✗
✓
in each control program. Note that the implementation and predi-
cates for the same type of violation are quite different across control
software. For example, in order to check a crash, ArduCopter re-
quires checking the motor status, flight mode, acceleration, angle
deviation, etc., while APMrover2 checks the current velocity, motor
speed, angular velocity, and so on. Specifically, Crash denotes a
kind of violation in which the vehicle collides with some object.
Thrust loss denotes the situation where the thrust of motors is lost,
which could lead to severe consequences such as crash. Landing
denotes the situation where the vehicle is in the process of landing.
It is safety related because the navigation logics refer to the status
for stable flights. Freefall means that the vehicle in free fall. Control
Loss checks if a vehicle has lost control. For example, in ArduCopter,
the vehicle is considered having lost control if it is more than 30 de-
grees off from the target roll and pitch continuously for at least one
second. This leads to disarming motors and releasing a parachute.
Flying checks if a vehicle is currently flying (or landed). It is safety
related because it affects the states of a few critical components
(e.g, throttle control).
(a) Real Vehicles
Figure 10: Subject Vehicles: (a) Erle-rover, 3DR Solo (b) IRIS+, Erle-
Copter, 3DR Solo (upper), Husky Rover, Erle-rover, Zephyr (lower)
(b) Simulated Vehicles
Session 1E: Cyberphysical Systems CCS '20, November 9–13, 2020, Virtual Event, USA271We used 6 simulated vehicles and 2 real vehicles (3DR Solo
and Erle-rover). Gazebo (version 8.6) has high-fidelity phsyics en-
gines and runs virtual vehicles with different environmental con-
ditions. The vehicles are shown in Figure 10. After we identify
CP-inconsistency cases, we validate the ones where we have the
physical vehicles in the real-world, following the (environmental)
exploit inputs generated by our technique.
5.2 Results
We first report the CP-inconsistency cases found by our technique.
Then we compare our technique with gradient descent and random
search to demonstrate the effectiveness of our technique. Lastly,
we show that the identification of these cases is not sensitive to
the threshold used in comparing RV and VRV states to detect real
accidents (Section 4.2.2).
CP-inconsistencies. Table 4 shows details of the CP-inconsistency
cases found by our technique. The information of each case is
presented in an upper row and an lower row. The second col-
umn and the third column (upper) indicate the controller software
and the safety-check type that exhibit the CP-inconsistency. The
fourth column (upper) shows the vulnerability type (under- or
over-approximation), and the last column (lower) shows the con-
sequences when the vulnerability is exploited. Additionally, VTF
configuration, main input type, and input condition columns in the
table describe the environmental conditions that trigger the vul-
nerability. And, #cyber objectives, #constraints and #model states
columns provide the number of elements in the cost functions used
in the testing that found the vulnerability. The check result column
shows the result of the checks (true and false) with the reaction