cols we consider in this paper relies on indistinguishability
under chosen-ciphertext attack with one parallel decryption
query (IND-1-CCA) [12] of the underlying labelled public-
key encryption scheme. Intuitively, IND-1-CCA requires that
no adversary can distinguish between encryptions of two
messages of the same length with probability signiﬁcantly
greater than 1/2, even if provided with a one-time access to
a batch decryption oracle.
A related, apparently stronger notion considers a multi-
challenge version (where the adversary sees polynomially
many challenge queries). We write poly-IND-1-CCA for this
latter security notion.
(cid:5)
(cid:4)
by
are
the
(λ) =
B,E,n
B,E,n
(λ) = 1
notions
− Pr
formalized
These
B,E,n
Exppoly-ind1cca,1
Advpoly-ind1cca
(cid:4)
B,E,n
Exppoly-ind1cca,0
experiment
Exppoly-ind1cca,β
deﬁned in Figure 1. The experiment considers
an adversary B with at most n access to the challenge oracle
Oc (that encrypts the left message if β = 0 and the right
message if β = 1) and one-time access to the decryption
oracle Od deﬁned using the encryption scheme E.
The advantage of the poly-IND-1-CCA adversary B over the
scheme E is deﬁned as:
(cid:5)(cid:3)(cid:3)(cid:3) .
(cid:3)(cid:3)(cid:3)Pr
(λ) = 1
We say that a labelled public-key encryption scheme E is
n-challenge poly-IND-1-CCA-secure if Advpoly-ind1cca
(λ) is
negligible (as a function of λ) for all p.p.t. B. Note that
Advpoly-ind1cca
(λ) is essentially the advantage for the single-
challenge IND-1-CCA notion. The following lemma estab-
lishes, by a standard hybrid argument, that multi-challenge
security is asymptotically the same as single challenge secu-
rity.
Lemma 1. A labelled public-key encryption scheme E
is n-challenge
is
poly-IND-1-CCA-secure for some polynomially bounded n.
Speciﬁcally, for any polynomially bounded adversary A there
exists a polynomially bounded adversary B such that for any
n and any λ the following statement holds:
IND-1-CCA-secure if and only if
B,E,1
B,E,1
it
i=1
for any list of ciphertext cL, and any secret key sk.
That is, addition of ciphertexts has as effect addition on
the underlying plaintexts. There are multiple security deﬁ-
nitions for encryption schemes. The security of the proto-
995
B,E,1
(λ) =
Advpoly-ind1cca
· Advpoly-ind1cca
1
n
is a homomorphic encryption
scheme, which, together with a proof of knowledge of the
randomness used for the encryption, has been shown to be
For example, El Gamal
A,E,n
(λ).
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:18 UTC from IEEE Xplore.  Restrictions apply. 
IND-1-CCA-secure [15]. Interestingly, in Helios which uses
this scheme, the proof of knowledge is primarily used to ensure
that the voter encrypts a valid vote, yet this proof also protects
the ciphertext from being modiﬁed. Notice that ciphertexts
still have an El Gamal component, which can be used to
homomorphically calculate over plaintexts.
PROOF SYSTEMS. Proof systems are a useful tool to ensure
that certain operations have been performed correctly. The
formalization starts with a relation R ⊆ X × W where the
elements of X are called statements and those of W are called
witnesses.2 For example, in Helios, a typical relation is that
the ciphertext (the statement) corresponds to the encryption
of 0 or 1. One can use as a witness the randomness used to
form the ciphertext. A proof system consists of a prover and
a veriﬁer algorithm which work on a common input x ∈ X;
the prover has an additional input w ∈ W. In a non-interactive
proof systems (as those considered in this paper) the prover
uses its inputs to compute a proof π ∈ PR and sends it to the
veriﬁer who then takes a binary decision. More formally:
Deﬁnition 3. A non-interactive proof system for relation R
is a pair of efﬁcient algorithms Σ = (P, V). P has as input
a statement in X and a witness in W, and produces a proof
π ∈ PR; V takes as input a statement in X and a proof in PR,
and produces an output in {0, 1}. For clarity, we write ΣR for
a proof system for relation R.
Useful proof systems need to satisfy three properties, sound-
ness, completeness, and zero-knowledge. Here we only recall
the latter two, as soundness has no bearing on vote privacy.
A proof system is said to be complete, if the prover can
produce a valid proof whenever the statement holds. Formally,
if for any (x, w) ∈ R, if π is a proof output by P(x, w) then
V(x, π) returns true with probability 1.
A proof system ΣR is zero-knowledge, if the proof does not
leak any information besides the fact that the relation is valid.
This is usually formalized by demanding the existence of a
p.p.t. simulator S that produces valid-looking proofs for any
statement x ∈ X without access to a corresponding witness.
More formally, consider the zero-knowledge adversary B in
the following experiments:
if (R(x, w)) then
(x, w, state) ← B(1λ)
(x, w, state) ← B(1λ)
Expzk,0B,P,R(λ)
1 :
2 : π ← ⊥
3 :
π ← P(x, w)
4 :
5 : β(cid:3) ← B(state, π)
6 :
The advantage of a zero-knowledge adversary B over the
Expzk,1B,S,R(λ)
1 :
2 : π ← ⊥
3 :
4 :
5 : β(cid:3) ← B(state, π)
6 :
if (R(x, w)) then
return β(cid:3)
return β(cid:3)
π ← S(x)
2In typical instantiations R is an NP-relation.
996
proof system ΣR = (P, V), and simulator S is deﬁned as:
AdvzkB,P,S,R(λ) =
(cid:4)
(cid:3)(cid:3)(cid:3)Pr
Expzk,0B,P,R(λ) = 1
(cid:5)
(cid:4)
− Pr
Expzk,1B,S,R(λ) = 1
(cid:5)(cid:3)(cid:3)(cid:3) .
Recall that we work in the random oracle model. Here, the
simulator has the additional capability (or responsibility) of
answering any calls the adversary makes to random oracles
used in the proof system. To keep notation simple we do
not show this dependence in the above formalization but, of
course, we account for it in our proofs.
B. Vote privacy in single-pass voting schemes
In this section we recall the syntax and security properties
of single-pass voting schemes, the class of schemes that we
treat in this paper. First we recall their syntax and then give
an overview of their desired properties related to vote privacy.
A single-pass voting system [13] is a tuple of algorithms
(cid:7)
(cid:6)
Setup, Vote, Valid, Publish, Tally, Verify
V =
.
Setup(1λ, m): Returns a pair of keys (pk, sk), and creates a
map uL that assigns m voter identities to their associated
labels.
Vote(id, (cid:3), v, pk): Constructs a ballot b that voter id uses to
cast their vote v, with label (cid:3).
Valid(BB, uL, b, pk): Checks the validity of ballot b with
respect to the ballot box BB and the label mapping uL.
Publish(BB): Returns the public view pbb of BB called the
public bulletin board; for example, the public bulletin
board can contain the whole content of the ballot box,
only the labels involved in ballots, or no information at
all.
Tally(BB, sk): Computes the result r of the election and a
proof Π of correct computation from BB.
Verify((pk, pbb, r), Π): Checks that Π is a valid proof of
correct computation for result r and public ballot box pbb.
In this section we recall several properties of single-pass
voting schemes. We start with ballot privacy, the key security
guarantee that these schemes need to satisfy.
BALLOT PRIVACY PROPERTY. A voting scheme V ensures
ballot privacy [13] (BPRIV, for short) if the ballots themselves
do not reveal any information about the votes that were cast.
This holds even for adversaries that can cast arbitrary ballots
in the voting process. This idea is formalized via a game-based
deﬁnition, that uses the experiment in Figure 2. The goal of the
adversary is to distinguish between two worlds. In the process,
the adversary chooses votes to be submitted by honest voters,
and may submit ballots on behalf of the corrupt users. The
adversary gets access to the bulletin board corresponding to
the real world (β = 0) or the ideal world (β = 1), where fake
votes are submitted by honest parties. The adversary always
learns the real result, that is, the tally is always performed on
BB0. The result comes with the real proof of validity if β = 0
or a fake proofs when β = 1. This fake proof is created by
an efﬁcient simulator (who only has access to the visible part
of the board). The adversary is expected to determine if it
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:18 UTC from IEEE Xplore.  Restrictions apply. 
Expbpriv,βA,V,Sim
(λ, m)
1 : BB0, BB1 ← [ ]
2 :
3 : β(cid:3) ← AO(1λ, pk, uL)
4 :
return β(cid:3)
(pk, sk, uL) ← Setup(1λ, m)
Oracle Otally() for β = 0
(r, Π) ← Tally(BB0, sk)
1 :
2 :
3 :
return (r, Π)
Oracle Otally() for β = 1
(r, Π) ← Tally(BB0, sk)
1 :
2 : Π(cid:3) ← Sim(pk, Publish(BB1), r)
3 :
return (r, Π(cid:3))
Oracle Ocast(b)
1 :
2 :
(cid:2)
Valid(BBβ, uL, b, pk)
BB0 ← BB0 + [b]; BB1 ← BB1 + [b]
then
if
(cid:3)
Oracle Ovote(id, v0, v1)
1 :
2 :
3 :
4 :
5 :
(cid:3) ← uL[id]
(cid:2)
(cid:3) (cid:5)= ⊥(cid:3)
if
b0 ← Vote(id, v0, (cid:3), pk); b1 ← Vote(id, v1, (cid:3), pk)
(cid:2)
Valid(BBβ, uL, bβ, pk)
if
BB0 ← BB0 + [b0]; BB1 ← BB1 + [b1]
then
(cid:3)
return Publish(BBβ)
Oracle Oboard()
1 :
In the experiments Expbpriv,βA,V , the adversary A has access to the set of oracles O = {Ocast, Ovote, Otally, Oboard}. The adversary is allowed
then
Fig. 2.
to call the Otally oracle at most once.
was playing with β = 0 or β = 1. Security demands that no
adversary can tell the difference between the two world: so the
board leaks no information about the content of the ballots,
and neither does the proof that accompanies the result.
We capture the adversarial abilities using the formal def-
initions of oracles in Figure 2. We provide below informal
descriptions of what these abilities represent.
Ovote : Receives two potential votes (v0, v1) for voter id.
Then, using the label (cid:3) assigned to id (if such a label
exists) it creates ballots b0 from v0 and b1 from v1. If
ballot bβ is valid with respect to board BBβ, then b0 is
added to BB0 and b1 is added to BB1;
Ocast : Lets the adversary cast a ballot on behalf of a
corrupted voter;
Oboard : Limits the adversary’s view of the bulletin board
to its public version, given by the Publish algorithm.
This public version of the board can vary very broadly,
with the following variants–among others–being used in
practice: the exact board, publish only the ciphertexts
from the ballots, or the empty set.
Otally : Computes the result on board BB0, and produces the
proof of correct computation using the output of the tally
algorithm for β = 0 or the proving simulator Sim for
β = 1.
Deﬁnition 4 (Ballot Privacy [13]). A voting scheme V has
ballot privacy if there exists a simulator Sim such that no
efﬁcient adversary A can distinguish between the games
Expbpriv,0A,V,Sim
(λ, m) deﬁned in Figure 2.
That is, the expression
(λ, m) and Expbpriv,1A,V,Sim
(λ, m) =
(cid:4)
AdvbprivA,V,S
(cid:3)(cid:3)(cid:3)Pr