example, SAL can denote what is the size of an array type
argument. We parse these annotations too and use them for
array type inference (see §V-C2).
B. Modular Analyzer
Recall from §IV-B, our modular analysis summarizes the
behavior of each function with abstract interpretation [20].
exp
stmt
::=
|
|
|
::=
|
|
reg
[ exp ]
int
exp ♦b exp
Put (reg, exp)
Store (exp, exp)
Call (f)
// Register
// Memory load
// Number
// Binary operation
Fig. 5. Simpliﬁed subset of B2R2 IR syntax for explanation.
(Abstract Integer)
(Abstract Location)
(Type Constraint)
(Abstract Value)
(Register Map)
(Memory)
(Abstract State)
I
L
T
=
=
|
|
|
=
|
V
=
R
=
M =
S
=
a ∗ symbol + b | ⊥ | (cid:62)
Global(Z)
Stack(f unction × Z)
Heap(allocsite × Z)
SymLoc(symbol × Z)
τ
SymTyp(symbol)
I × 2
L × 2
T
reg → V
L → V
R × M
Fig. 6. Our abstract domains.
At a high level, we perform a ﬂow-sensitive analysis on each
function, which computes an abstract program state for each
point in the CFG. With these abstract states, we summarize
each function by observing (1) which values are passed as a
syscall argument, and (2) how the state changes between the
entry and exit node of the function.
1) Abstract Domain: We deﬁne our abstract domains in
Figure 6, and present their join operation in Appendix A.
Z denotes the integer set, and symbol
is a new symbol
introduced at each argument of a function. Since we do not
know the value of a function argument at its entry, we initialize
every argument value with a fresh symbol.
Our abstract value V is a triple of an abstract integer, a set
of abstract locations, and a set of type constraints.
First, abstract integers represent a numeric value that a
register or a memory cell can hold. We use a linear expression
with a symbol to represent an abstract integer. It can be either
concrete, when a = 0, or symbolic, when a (cid:54)= 0.
Second, abstract locations present a potential location of a
value. We have four different kinds of locations: Global,
Stack, Heap, and SymLoc. Global(a) means a global
variable location at the address a, Stack(f ,o) represents
a local variable located in the stack frame of f at the offset
o, and Heap(a,o) represents a memory cell located at the
offset o of a heap object allocated from the address a. We
coalesce the heap locations based on their allocation site [39].
SymLoc(s,o) indicates a symbolic pointer with the pointer
symbol s and the offset o from the pointer. Note that in static
analysis, a pointer can point to multiple locations due to over-
L.
approximation. Thus, our abstract value entails 2
Third, we embed type constraints in our abstract domain as
in [19]. A type constraint can have either a concrete type τ,
or a symbolic type SymTyp(α), where alpha is a symbol.
For example, consider a function that takes in a single
argument as input. The argument can either be an integer
or a pointer, and we take both cases into account. We ﬁrst
assume that the argument has an abstract integer 1 ∗ α1 + 0
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:13:11 UTC from IEEE Xplore.  Restrictions apply. 
681
update(L)(v)(M ) =
(cid:40)
(cid:40)
where S = (cid:104)R, M(cid:105)
M [l (cid:55)→ v]
M [l1
w(cid:55)−→ v]...[ln
if L = {l}
w(cid:55)−→ v] if L = {l1, ..., ln}
V(reg)(S) = S[0](reg)
V([e])(S) =
(cid:71){S[1](l) | l ∈ V(e)(S)[1]}
(cid:104)0, φ, φ(cid:105)
V(i)(S) =
V(e1♦b e2)(S) = binop(♦b, e1, e2, S)
(cid:104)⊥, {Global(i)}, φ(cid:105) if i in data section
(cid:104)i, φ, {integer}(cid:105)
otherwise
if i = 0
(a) Evaluation of expressions (exp).
F (Put(r, e))(S) = (cid:104)R[r (cid:55)→ V(e)(S)], M(cid:105), where S = (cid:104)R, M(cid:105)
F (Store(e1, e2))(S) = (cid:104)R, update(V(e1)(S)[1])(V(e2)(S))(M )(cid:105),
F (Call(f ))(S) =
apply(δ, S) if f has side effect δ
S
otherwise
(b) Evaluation of statements (stmt).
Fig. 7. Abstract semantics of our static analyzer.
(or simply α1), where α1 is a fresh symbol. We also consider
the abstract location of the argument as it can be a pointer.
Thus, we introduce a new symbol α2 for representing a
symbolic location SymLoc(α2, 0). Since we do not know
the type constraint of the argument, we create a symbolic
type constraint SymTyp(α3). Finally, we subsume all
the
above information to initialize an abstract value V for the
argument as (cid:104)α1,{SymLoc(α2, 0)},{SymTyp(α3)}(cid:105). Once
we ﬁnish analyzing the function, we will obtain a summary
parameterized with these symbols.
Note our abstract domain differs from that of Value Set
Analysis (VSA) [5], [6]. VSA uses a variant of interval domain
to trace offsets of abstract locations, which enables a sound
analysis of memory access range, while making it prone to
imprecision. Since our focus is not on the soundness, we seek
for more precise results by giving up tracing complex offsets.
Instead, we focus on tracking constant offsets with Z. We
further justify our design in §V-B2.
2) Abstract Semantics: We now deﬁne our abstract seman-
tics on the B2R2 IR shown in Figure 5. Recall that the IR
is largely simpliﬁed for ease of explanation, and our actual
implementation of NTFUZZ handles the complete syntax.
First, we deﬁne V : exp → S → V that evaluates the given
expression exp within the provided abstract state S to return
an abstract value V. Figure 7a presents the semantics. Here,
we use X[n] to denote the (n + 1)-th element of a tuple. For
example, for an abstract state S ∈ S, S[0] returns the register
map (R) of the abstract state.
Register read and memory load expressions are trivial to
evaluate: we simply look up the given abstract state S and
return the corresponding value. Note that the four kinds of ab-
stract locations deﬁned in Figure 6 are naturally distinguished
as separate regions during the memory load.
Evaluating a number expression involves range checks.
When a given number is zero, we safely ignore its type as we
cannot distinguish between a NULL pointer and a constant
zero. When a number is within the range of data sections, we
consider it as a global pointer. For the rest of the cases, we
consider the number as an integer.
Binary operation binop is formally deﬁned in Appendix B,
and intuitively it performs arithmetic operations with the
abstract values and generates type constraints if possible. For
example, a multiplication of two values should have an integer
type. When computing a binary operation, we also calculate a
new offset of the abstract location L. To explain this semantics,
let us consider the following x86 snippet of a function f.
mov esi, ebp
sub esi, 40
# esi: array base
lea edi, [esi+4*ecx] # ecx: array index
This code computes the address of an array element indexed
by ecx. We will assume that ebp carries the initial stack
pointer at the entry of f, which will be converted as an abstract
location Stack(f, 0) in our domain. Ideally, traditional VSA
will try to capture the exact range of ecx with its congruence
interval domain, and calculate the accurate memory range
pointed to by edi. However, if the range of ecx is imprecisely
approximated to (cid:62), i.e., [−∞,∞], edi will be considered as
pointing to any arbitrary memory location.
To mitigate such problems, we trace only the constant
offsets, and ignore array index terms. For the sub instruction
in this example, we calculate the abstract location assigned in
esi as Stack(f,−40). However, for the lea instruction, we
ignore the added index term, and simply assign the abstract
locations of esi to edi. Intuitively, ignoring array index
means coalescing all the array elements into a single abstract
location. Such an array-insensitive design is indeed common
for static analyzers [72], [88].
We now deﬁne F : stmt → S → S that evaluates the given
statement stmt within the given abstract state and returns a
new abstract state. Figure 7b shows the deﬁnition of F. We
use m[k (cid:55)→ v] to denote a strong update of m with a new
mapping from k to v. Meanwhile, m[k w(cid:55)−→ v] means a weak
update: m is updated with a new mapping from k to m(k)(cid:116)v.
The abstract semantics of Put and Store are straight-
forward: they simply update the given abstract state with an
evaluated value. For the rationale behind distinguishing strong
and weak update, see [22].
The core semantics of Call is to apply the summarized
side-effect δ of the called function (see Appendix B for more
details of function apply). If the callee f is a documented
function, we can also update the type constraints of its
arguments accordingly. Additionally, we manually encode the
semantics for several core functions to improve the accuracy of
our analysis. For example, we encode the memory allocation
semantics of RtlAllocateHeap instead of analyzing the
function. Note writing custom semantics for core functions is
a common practice in static analysis [26], [83].
3) Comparison against VSA: As we discussed in §V-B2,
VSA can soundly analyze memory accesses by tracking
location offsets with interval domain. Unfortunately,
is
notoriously difﬁcult to achieve precise interval analysis in
it
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:13:11 UTC from IEEE Xplore.  Restrictions apply. 
682
practice, even with source code [46], [72]. When the interval
analysis yields imprecise results like [−∞,∞], pointer values
also lose precision in VSA. Meanwhile, our semantics design
is unsound, but it can always track a concrete offset for abstract
locations. That is, we trade-off soundness for precision.
Note, unlike our domain, the VSA domain does not suit
modular analysis well. To enable modular analysis with VSA,
we must extend its domain to support symbolic intervals.
At the entry of a function, we must initialize its argument
to have a symbolic location with symbolic boundaries, such
as SymLoc(s, [α, β]). However, when the offset interval is
symbolic, it becomes extremely difﬁcult to handle memory
operations in the abstract semantics. In Appendix C, we
discuss more details about possible strategies to cope with
this challenge, and explain why they are imperfect.
4) The Trade-Off: Since our goal is not at sound program
veriﬁcation, we can compromise the soundness of our analysis
to improve its scalability and precision. We brieﬂy summarize
some of the design choices we made for the trade-off.
During the intra-procedural analysis, we perform loop un-
rolling, which is a popular technique that many static analyzers
adopt to control the soundness [31], [50]. Also, we deliberately
allow strong updates for locations that should be always
weakly updated (e.g. heap locations). Note that F in Figure 7b
only checks whether the update is on a single location or not.
We also found that functions in real-world binaries often
take in nested pointers as an argument, which involves nu-
merous memory updates. As a result, we frequently observe
an explosion in the number of side effect entries. According
to our experience, soundly summarizing all these side effects
made the analyzer unscalable.
Therefore, we introduce NSE parameter, which sets the
maximum bound on the number of update entries to store
for a function summary. That is, we unsoundly prune out the
entries over this number. In §VII-B, we evaluate the impact of
NSE on the accuracy and scalability of the analysis.
C. Type Inferrer
The type inferrer decides syscall types based on the results
obtained from the modular analyzer.
1) Structure Inference:
If a syscall argument
is not a
pointer, we can trivially know its type from our abstract
domain in Figure 6. However, if the argument is a pointer, we
have to carefully inspect the analyzed memory state in order to
infer the type of the pointee. Let us revisit the running example
in Figure 4. At the syscall in Line 9, the abstract value of
the second argument should be (cid:104)⊥,{Heap(Line 3, 0)}, φ(cid:105).
Therefore, we look for the abstract memory cells, i.e. abstract
locations,
that correspond to the heap object allocated in
Line 3. That is, we search for any abstract memory cell that
is in the form of Heap(Line 3,∗), where ∗ indicates any
offset. This way, we can obtain two abstract memory cells
Heap(Line 3, 0) and Heap(Line 3, 4), and their abstract
values to obtain the structure in Figure 4c.
On the other hand, it is more challenging to infer a structure
type allocated on the stack. Consider an example in Figure 8a,
void f(void) {
struct S s;
int k;
s.x = 1; // int field
s.y = 2; // int field
k = 3;
syscall(&s);
print(k);
}
(a) Example with struct.
void f(void) {
int i = 1;
int j = 2;
int k = 3;
syscall(&s);
print(k);
1
2
3
4
5
6
7
8
9
1
2
3
4
5
6
7
Low
s.x
s.y
k
...
High
(c) Stack layout for (a).
Low