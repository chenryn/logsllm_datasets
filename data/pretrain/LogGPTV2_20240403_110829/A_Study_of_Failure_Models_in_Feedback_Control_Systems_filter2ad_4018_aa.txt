title:A Study of Failure Models in Feedback Control Systems
author:João Carlos Cunha and
Ricardo Maia and
M&apos;ario Zenha Rela and
João Gabriel Silva
A Study of Failure Models in Feedback Control Systems 
JoZo Carlos Cunha 
Dep. Eng. Informiitica e de Sistemas 
Instituto Superior de Engenharia de Coimbra 
P-3030 Coimbra - Portugal 
PI:EMAIL 
Ricardo Maia, Miirio Zenha Rela, JoZo Gabriel Silva 
Dep. Eng. InformiticdCISUC 
Universidade de Coimbra - P610 II 
P-3030 Coimbra - Portugal 
{ rjmaia, mzrela, jgabriel} @dei.uc.pt 
Abstract 
Feedback  Control  Systems  have  a  peculiar  behavior 
that  allows  them  to  compensate for disturbances  in  the 
controlled  application.  This  paper  investigates  whether 
this  resilience  also  extends  to  disturbances  originating 
from faults  in  the controller  itself:  The question of  what 
kind  of  failure  model  is  more  effective  in  this  type  of 
system  is  addressed,  with  three  different  models  being 
studied: arbitrary failure, fail-silent, and fail-bounded. 
The  study  is  conducted  essentially  by  experimental 
fault-injection in the controller of  one of  the best known 
and  most  demanding  of  the  benchmarks  used  in  the 
control  systems  area:  an 
inverted  pendulum.  The 
considered  failure  models  are  compared  according  to 
criteria  based on the quality of  the control  action. Other 
insights gained from the experiments made are described, 
for instance on how to significantly increase dependabil- 
ity at a  very low-cost in feedback  controllers, and  on the 
need  f o r   a  diferent  kind  of  real-time  scheduling 
algorithms. 
1.  Introduction 
Feedback  is  at  the  very  heart  of  computer  control 
systems.  Inputs  from  a  physical  process  are  compared 
against  a  set  of  reference  values  and  the  computer  that 
controls the  process  is  responsible  for producing outputs 
that  maintain  the  process  inside  a  given  region  of  its 
state-space.  This behavior  has  a  cyclic  nature:  get inputs 
from the sensors, process the data and output new  values 
to  the  actuators.  If  any  deviation  from  the  predefined 
set-point  is detected, due to the physical  characteristics of 
the  process  under  control  or  to  external  disturbances  of 
the  following  outputs  from  the  control 
some  kind, 
This work  was  partially  funded by the Portuguese Ministry  of Science 
and  Technology, the  European  Union  through  the  R&D  Unit  326194 
(CISUC) and the project PRAXIS/P/EEI  10205/1998 (CRON). 
0-7695-1101-5/01 $10.00 0 2001 IEEE 
3 14 
algorithm take that deviation into account to minimize  the 
error observed. 
The  computers  used  in  feedback  control  systems  are 
expected  to  be  very  dependable,  since  it  is  generally 
considered  unacceptable 
to  a  computer 
the  controlled  system  escapes  from  the 
malfunction, 
prescribed  operating  zone.  Outputs  are  expected  to  be 
delivered  correctly  and  on  time  - usually  up  until  the 
next input-process-output iteration  begins. 
that,  due 
Control  engineers  take  for  granted  that  computers 
behave  correctly,  concentrating  all  their  efforts  in  the 
algorithm’s resilience  to external disturbances. Thus most 
control  applications  use  highly  redundant  hardware  by 
replication  and  voting, to  guarantee that  all  non  common 
mode  errors  are  detected.  The  reasoning  behind  this 
approach is that,  in  case of  an error, most  probably  there 
won’t  be  time  to  detect,  reconfigure  and  recover:  errors 
have  to  be  masked  so that  correct results  are timely  sent 
to the outside world. 
In  fields  such  as  avionics,  nuclear  power  plants, 
medical 
support  systems,  and  similar  critical 
applications,  the  cost  of  replication  may  be  acceptable, 
but  there  is  a  much  larger  number  of  cases  in  process 
control  where  such  redundancy  is  not  economically 
viable. In this latter class of applications, errors have to be 
detected,  and  recovered  from,  within  the  response  time 
constraints of the system. 
life 
A common building  block  of  all these types of systems 
is  the  fail-silent  computer,  which  either  produces  correct 
results or does not  output any  value  at  all  [8]. However, 
several  studies have  shown  that  standard  computers  fail 
far  from  silently  [l].  Many  authors  even  assume  that 
computers  fail  maliciously  building  algorithms  to  face 
Byzantine faults [7], but  the  complexity and implementa- 
tion  cost of  the  algorithms built  on  that premise  severely 
restrict  their usability in real world systems. 
To  obtain  computers that  correspond  to  the  fail-silent 
model,  at  least  for  non  common-mode  faults  (the  case 
with  almost all hardware faults), the most  straightforward 
solution  is  to  use  duplicated  modules,  compare  their 
outputs and  halt  them  on  disagreement. This is often  the 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
approach  followed in  real-time  control  applications since 
it  also  guarantees  minimum  error  detection  latency. 
Nearly  all  existing algorithms and  techniques capable  of 
guaranteeing  real-time  constraints  are  built  on 
the 
implemented 
fail-silent  model.  They  are  generally 
through  replication,  which  gives  low  error  detection 
latency and high  error coverage, but at a rather high cost: 
the  minimum  redundancy 
to  achieve  fail-silentness 
involves  hardware  duplication  - an  overhead  above 
100% due to the non-standard nature of such hardware. 
For  the  above  reasons,  most  low  cost  control  com- 
puters  use  fault  avoidance  rather  than  dedicated  fault 
tolerance.  Typically,  the  only  standard  provisions  for 
error detection  in  such systems are the use of a watchdog 
timer that detects crashes and resets the processor, and of 
periodic  self-check  routines  that  detect  permanent  faults. 
If  a  less  demanding  failure  model  than  fail-silent  was 
feasible,  a  huge  number  of  control  applications  could 
benefit from it. 
The idea  explored  in  this  paper  consists  in  investigat- 
ing  whether 
the  characteristics  of  feedback  control 
algorithms, inherently designed to tolerate disturbances at 
the  controlled  system, are  helpful  also  to  tolerate  faults 
(disturbances)  in  the  control  computer  itself.  In  fact,  as 
long  as  the  errors  affecting  the  control  computer do not 
prevent  it  from  continuing  execution  (i.e.  if  the  errors 
leading  to  the  failure  were  transient),  we  find  that  it  is 
possible  to  use  the  control  algorithm  itself  for  forward 
error recovery. Permanent errors would be treated as they 
are currently: the application  is brought to a safe state by 
forcing the  controller  outputs into a predetermined  fixed 
state. 
The goal is to evaluate whether less demanding failure 
models  than  fail-silentness  are  usable.  We analyze  three 
different  failure  models:  arbitrary  failure,  fail-silent  [8] 
and fail-bounded [ 121. 
To  evaluate  this  hypothesis,  we  use  one  of 
the 
best-known  and  most demanding benchmarks  used  in  the 
control  systems area: an  inverted  pendulum  process.  The 
success or failure is measured by the quality of the service 
provided  by the process: the pendulum should not deviate 
significantly from its reference position, and certainly not 
fall,  despite  the  occurrence  of  faults.  The  evaluation  of 
this  research  hypothesis 
is  made  by  experimental 
fault-injection. 
To the best  of our knowledge, this is the first time that 
the  inherent  resiliency  of  feedback  control  algorithms  is 
tested  against  faults  in  the  controlling  computer  itself, 
While we  certainly  expected  the control  algorithm  to  be 
able to absorb some of the injected faults, we had  no idea 
on  what  fraction  of  the  faults  would  be  tolerated  in  this 
way. 
The structure  of  the  paper  is  as follows:  in  section 2, 
the  three  failure  models  tested  in  the  experiments  are 
reviewed, with  emphasis on  the most recent fail-bounded 
the 
approach.  In  the  following  section,  we  describe  the 
experimental  setup, 
the 
fault-injection tool that implements it.  Section 4 forms the 
core of  the  paper:  the  results  obtained  are presented  and 
discussed.  Section  5  closes 
the  paper  with  some 
conclusions and description of future work. 
fault-model  used,  and 
2.  The three failure models under study 
Fail-Arbitrary  means  exactly  what  the  name  sug- 
gests:  the  control  system  can  produce  any  output.  This 
failure model  is  represented  by  a  control  system without 
any dedicated  error detection or fault-tolerance technique 
in  general.  Actually,  the  system  does  have  somc  basic 
like  some  memory 
error  detection 
illegal 
protection,  detection  of  attempts 
instructions  and  detection  of  some  arithmetic  exceptions 
like  overflow  and  divide  by  zero.  This  is  our  baseline 
model. 
to  execute 
inherent 
it, 
to 
In the Fail-Silent approach, the system either produces 
a  correct  output,  or  produces  no  output  at  all.  This 
behavior  is  obtained  through  duplication  of  the  control 
computer  with  voted  outputs.  We  assume  that,  if  a 
disagreement occurs, the  physical application  is put  into a 
safe mode. 
The  Fail-Bounded  model  [ 121  is  somehow  between 
those two: while an incorrect output can be produced, it is 
not  arbitrary - it is within  a certain  bound of the correct 
value.  If  we  can  guarantee  that  the  results  of  a computa- 
tion  are  filtered  by  an  acceptance  test  or  assertion,  and 
that  these  outputs are  not  corrupted  after being  tested  by 
that assertion  (in which  case we call  it a robust ussertiorz 
[12]),  we  know  that  the  output,  even  if  wrong,  satisfics 
the invariant tested  by that assertion. The ensuing failures 
are thus not arbitrary, since the errors they exhibit have an 
upper bound that  depend  on the  output assertions used  by 
the programmer. A system is thus said to be Fail-Bounded 
if it either: 
a)  Produces correct outputs; 
b)  Stops  producing  outputs  after  detecting  some 
error; 
c)  Produces  wrong  outputs,  but  the  errors  have  an 
upper  bound  defined  by  the  output  assertions 
whose execution is guaranteed. 
A point that is central to the robust assertion concept is 
the  guarantee  of  end-to-end  protection  of data  [ 151. The 
output  data  sent  to  the  hardware  that  interfaces  with  the 
physical  process  is protected  with  a  “magic number” and 
a  checksum,  so  that  a  very  simple  hardware  check  can 
assure  with  very  high  probability  that  all  reasonableness 
tests  have  been  successfully  executed  on  the  control 
computer,  and  that  the  outputs  have  not  been  corrupted 
after being verified. 
The  fail-bounded  model  is  highly  dependent  on  the 
quality  of  the  assertions  used,  similarly  to  the  recovery 
315 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:07:01 UTC from IEEE Xplore.  Restrictions apply. 
block  concept  [9].  Although  in  our  setup  assertions  are 
used  essentially  to  detect  hardware  transients,  they  have 
the  added  benefit  of  being  able  to  detect  also  some 
software errors, a quite convenient feature. 
Assertions  can  be  quite  effective. A  recent  paper  [5] 
studied 
their  detection  capability,  showing  coverage 
figures as high as 99% for errors in monitored  signals and 
over 8 1 % for errors in  random locations in memory  areas 
of the target system. In a previous work [IO]  we have also 
used  assertions  on  top  of  other  error  detection  mecha- 
nisms  such  as  memory  protection  and  the  processor’s 
built-in  error  detection  mechanisms,  and  observed  that 
assertions  can  take  a  simplex  system  to  provide  a 
fail-silent  behavior for  90% up  to  98% of  a  comprehen- 
sive  set  of  faults.  These  are  quite  high  figures  if  we 
consider the low overhead involved. 
The use  of  acceptance tests  or assertions is not new in 
process  control.  For  instance,  Lui  Sha  [ I  I ]   describes  a 
system  to  illustrate  how  a  smooth upgrade from a  legacy 
process  controller to  a  more  sophisticated system can  be 
made.  The  two  systems  coexist  for  a  while  to  test  the 
correctness  of  the  new  system.  In  such  an  approach,  a 
stability  region  for  the  application at hand  is defined and 
the  legacy  controller  rnonitors  the  outputs  from  the  new 
one. While  the  outputs produced  by  the  controller under 
surveillance  are  reasonable,  its  outputs  are  allowed  to 
reach  the  actuators  of  the  process.  Otherwise,  the  new 
controller probably  needs debugging.  It  must  be  stressed 
that we are not working only in the value domain, but that 
time is involved - a particular output may be valid or not 
depending on the moment when it is produced. 
Controller 
F
I
variables 
Protect 
Input 
Assert 
Control 
output 
Protect 
output 
Assert 
Controlled Process 
1 
r 
output 
Figure  1.  Robust  Assertions  modules  for 
the Fail-Bounded model 
The  typical  structure  of  an  implementation  of  the 
Fail-Bounded model  into a control system is presented  in 
Figure  1.  To  guarantee  that  all  the  tests  are  indeed 
executed  with  very  high  probability,  a  very  simple 
software based  control  flow error detection mechanism  is 
used - the “magic number”.  It consists on a variable  that 
is  set  to  zero  at  the  beginning  of  each  iteration,  with 
different constants being  added  to  it  after each phase  of 
the  procedure.  In  the  end,  it  should  have  a  fixed  value, 
corresponding to the sum of all the constants - any other 
value indicates that  because  of  an  error some phase  was 
not correctly executed. 