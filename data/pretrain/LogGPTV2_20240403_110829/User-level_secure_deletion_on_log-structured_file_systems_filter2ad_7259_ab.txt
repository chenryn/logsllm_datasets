m
u
n
k
c
o
b
e
s
a
r
e
d
e
t
a
c
o
l
l
A
0
0
20
40
60
80
100
120
140
Time (hours)
Fig. 5.2 Sampled plot of erase block allocation over time for YAFFS on an Android phone. The
time between two points on the same horizontal line is the erase block reallocation period.
We perform experiments using YAFFS mounted on a virtual ﬂash storage medium
created by the kernel module nandsim. We use an erase block size of 64 2-KiB
pages, consistent with the Nexus One phone [65].
Deletion Latency.
Figure 5.2 shows a plot of the storage medium’s erase block allocations over time to
gain insight on its behaviour. The horizontal axis is time, and the vertical axis shows
the sampled space of sequentially numbered erase blocks. A black square on the
graph means that an erase block was allocated at that time. For clarity, we compress
the space of erase blocks into the rows by sampling every 15th erase block.
We present the results of our experiment in Table 5.1, which gives the median
and 95th percentile deletion times in hours for the patterns written onto the storage
medium during simulation. The maximum deletion latency is undeﬁned because
these systems provide no deletion guarantee and some data remained available after
the experiment. Table 5.1 provides results for YAFFS partitions with sizes 200 MiB,
1 GiB and 2 GiB based on our observed access patterns.
We observe the effect of cyclic erase block allocation in YAFFS. There is both
a linear growth in deletion latency as the size of the partition increases, and a high
5.5 User-Space Secure Deletion
63
Table 5.1 Deletion latency in hours for different conﬁguration parameters.
partition size and type
200 MiB YAFFS
1 GiB YAFFS
2 GiB YAFFS
deletion latency (hours)
median
41.5± 2.6
163.1± 7.1
349.4± 11.2
95th percentile
46.2± 0.5
169.7± 7.8
370.3± 5.9
percentile observation close to the median. For instance, a YAFFS implementation
on a 2 GiB partition (e.g., the data partition on the Samsung Galaxy S [80]) with the
same access patterns can expect deleted data to remain up to a median of two weeks
before actually being erased. In the next section, we present solutions to reduce this
data deletion latency.
5.5 User-Space Secure Deletion
In this section, we introduce our solutions for secure deletion: purging, ballooning,
and a hybrid of both. These solutions all work at user level, which has a limited
interface that can only create, modify, and delete the user’s own local ﬁles. Such so-
lutions cannot force the ﬁle system to perform erase block erasures, prioritize com-
paction of particular areas in memory, or even know where on the storage medium
the user’s data is stored.
All of the solutions we present operate with the following principle: they re-
duce the ﬁle system’s available free space to encourage more-frequent compaction,
thereby decreasing the deletion latency for deleted data. Purging consists of ﬁll-
ing the storage medium to capacity, thus ensuring that no deleted data can remain
on the storage medium. Purging executes intermittently and halts after completion.
Ballooning continually occupies some fraction of the storage medium’s empty space
to ensure it remains below a target threshold, thereby reducing the deletion latency.
Ballooning executes continually during the lifetime of the storage medium. The hy-
brid solution performs ballooning continually, and performs a clock-driven purge
operation to guarantee an upper bound on deletion latency.
We implement our solutions and examine their effectiveness for various storage
medium sizes. We use deletion latency and storage medium wear as metrics for
evaluating their effectiveness. We show that the hybrid solution is well suited for
large storage media, where the deletion latency is a trade-off with storage medium
wear.
64
5.5.1 Purging
5 User-Level Secure Deletion on Log-Structured File Systems
Purging attempts to completely ﬁll the ﬁle system’s empty space with junk ﬁles;
if the operation is successful then all partially ﬁlled erase blocks on the storage
medium are compacted, and therefore all previously discarded data is securely
deleted. Importantly, whether completely ﬁlling the ﬁle system from user space ac-
tually completely ﬁlls the storage medium depends on the implementation of the
actual ﬁle system.
After ﬁlling the storage medium, the junk ﬁles are deleted so that the ﬁle system
can again store data. Purging must be explicitly executed, which can take the form
of automated triggers: when the phone is idle, when the browser cache is cleared,
or when particular applications are closed. It is also useful for employees who are
contractually obligated to delete customer data, e.g., before crossing a border.
The fact that the storage medium must be completely ﬁlled follows from a worst-
case analysis of a SEMIPERSISTENT implementation whose allocatable space is the
same as the addressable space. Before the storage medium is completely full, there is
some area of the medium containing one last piece of unneeded but available data—
we must pessimistically assume that is our discarded data. It is important to note that
purging’s ability to securely delete data is dependent on the implementation of the
log-structured ﬁle system. In particular, we require the following condition to hold:
if the ﬁle system reports that it is out of space, then all previously deleted pages are
no longer available on the storage medium. While this condition holds for YAFFS,
the implementation of other ﬂash ﬁle systems and FTL hardware may differ.
A natural concern for purging’s correctness is its behaviour on multithreaded sys-
tems. However, using the previous reasoning, purging needs to keep writing to the
storage medium until it reports that it is completely full. This ensures that any data
that has been deleted prior to purging is irrecoverable as the drive is completely full.
Another concern is that, at the moment the storage medium is full, other applications
simultaneously writing to the storage medium are told that the storage medium is
full. We observe that any ungraceful handling of an unwritable storage medium is
a ﬂaw in the application and the storage medium’s lack of capacity is a temporary
condition that is quickly relieved.
We tested purging with the following experiment. We took a pristine memory
snapshot of the phone’s internal NAND memory by logging into the phone as root,
unmounting the ﬂash storage medium, and copying the raw data using cat from
/dev/mtd/mtd5 (the device that corresponds to the phone’s data partition) to the
phone’s external memory (SD card). We wrote an arbitrary pattern not yet written
on the storage medium, and obtained a memory snapshot to conﬁrm its presence.
We then deleted the pattern, obtained a new memory snapshot, and conﬁrmed that
the pattern still remained on the ﬂash memory. Finally, we ﬁlled the ﬁle system
to capacity with a junk ﬁle, deleted it, and obtained another memory snapshot to
conﬁrm that the pattern was no longer on the ﬂash memory.
The time it took to execute purging on the Nexus One was between thirty seconds
and a minute. As we soon see, however, this time is highly dependent on the storage
5.5 User-Space Secure Deletion
65
Fig. 5.3 Plot of erase block allocation over time for YAFFS (cf. Figure 5.2). After simulating
writing for some time, we performed purging, which is visible at the right edges of the plot where
many erase blocks are rapidly allocated.
medium’s size. During execution the system displayed a warning message that it
was nearing drive capacity, but the warning disappeared after completion.
Figure 5.3 shows the resulting erase block allocations reported by an instru-
mented version of YAFFS executing purging. The horizontal axis corresponds to
time in hours, and the vertical axis shows the sampled space of numbered erase
blocks. A small black square in the graph indicates when each erase block was allo-
cated. For clarity, as with Figure 5.2, only a sampled subset of erase blocks (every
15th) have their allocations plotted. At the right side of Figure 5.3, we see the near
immediate allocation of every erase block on the medium as indicated by the black
squares forming a near vertical line. This is the consequence of ﬁlling the storage
medium to capacity; a log-structured ﬁle system must compact every erase block
that contains at least one deleted page.
5.5.2 Ballooning
In contrast to purging, which guarantees secure data deletion with a bounded dele-
tion latency, we now present ballooning, which does not guarantee secure dele-
tion with any bound but does reduce the deletion latency in expectation. Bal-
66
5 User-Level Secure Deletion on Log-Structured File Systems
Fig. 5.4 Plot of erase block allocation over time for YAFFS while using aggressive ballooning.
looning artiﬁcially constrains the ﬁle system’s available free space. This results in
more-frequent compaction due to reduced capacity, and therefore reduces the time
any deleted data—regardless of when it is deleted—remains accessible on a log-
structured ﬁle system. Ballooning creates junk ﬁles to occupy the free space of the
storage medium, which reduces the total number of erase blocks available for allo-
cation. This reduces the expected erase block reallocation period, and therefore the
expected deletion latency. These ballooning junk ﬁles are periodically rotated—new
ones written and then old ones deleted—to promote efﬁcient wear levelling.
In Section 5.6, we explore how varying free space thresholds—the aggressive-
ness of ballooning—affect deletion latency and other measurements. First, however,
we visualize evidence that does not refute our hypothesis that ballooning reduces
the erase block reallocation period. Figure 5.4 shows the erase block allocations
that result from executing ballooning on YAFFS. We see a stark difference when
compared with Figure 5.2. As the number of allocatable erase blocks decreases,
YAFFS’ sequential allocation becomes much more erratic, and the erase block re-
allocation period decreases. Row segments in Figure 5.4 that contain no allocation
activity (i.e., a black square) likely correspond to erase blocks that are now ﬁlled
with junk ﬁles. The ﬁgure shows a decrease in the erase block allocation period,
which therefore reduces the expected deletion latency.
5.6 Experimental Evaluation
5.5.3 Hybrid Solution: Ballooning with Purging
67
The disadvantage of purging is that its cost is dependent on the free space available
on the storage medium. In contrast, the disadvantage of ballooning is that it cannot
provide a guarantee on when (or indeed if) data is deleted. By combining both these
solutions, we create a hybrid scheme that has neither disadvantage. We use peri-
odic purging for secure data deletion, and we use ballooning to ensure that a large
storage medium’s empty space must not be reﬁlled during every purging operation.
The result is a clock-based solution where purging is periodically performed, divid-
ing time into deletion epochs. The deletion latency of all data is therefore bounded
by the duration of a deletion epoch. The resulting storage medium has a SECDEL-
CLOCK behaviour.
Reducing the number of erase blocks that must be ﬁlled during purging mitigates
three concerns: purging’s wear on the storage medium, its power consumption, and
its execution time. Large capacity storage media are particular suitable to this so-
lution: they may have large segments of their capacity empty, which ballooning
occupies with junk ﬁles to achieve a deletion latency representative of smaller-sized
storage media. In the next section we quantify this with experimental results for
various storage medium sizes and ballooning aggressiveness settings.
5.6 Experimental Evaluation
We developed an application that implements our hybrid solution. The application
periodically examines the ﬁle system to determine the free space, and appropriately
creates and deletes junk ﬁles to maintain the free space within the upper and lower
thresholds. The lower threshold is user deﬁned and we set the upper threshold to be
4 MiB larger than the lower threshold to avoid a thrashing effect. The oldest junk ﬁle
is always deleted before more recent ones to load-balance ﬂash memory wear. Long-
lived junk ﬁles can also be removed, with new ones written, to perform appropriate
wear-levelling if necessary. The purging interval is user speciﬁed, allowing the user
to select a tradeoff between the timeliness of secure deletion and the resulting wear
on the device.
Our application runs successfully on the Android phone. The only permission it
requires is the ability to run while the phone is in a locked state; the application also
needs to specify that it runs as a service, meaning execution occurs even when the
application is not in the foreground. The application can be installed on the phone
without any elevated privileges and operates entirely in user space. Ballooning must
maintain a minimum of 5% of the erase blocks free to avoid perpetual warnings
about low free space. Purging triggers a brief warning about low free space that
disappears when purging completes.
We now present the experiments we performed using ballooning on simulated
ﬂash media of different sizes. We varied the amount of ballooning that was per-
formed and measured the time that discarded data remained on the storage medium
68
5 User-Level Secure Deletion on Log-Structured File Systems
to determine ballooning’s effectiveness. We measured the ratio of deleted pages on
erase blocks, which intuitively captures the amount of ballooning. We also measured
the rate of ﬂash erase block allocations, which intuitively captures the added cost of
ballooning. After each simulation execution, we performed purging and measured
the additional erase block allocations, which is the purging cost for the amount of
ballooning used by our hybrid solution.
The erase block allocation rate tells us directly the rate that pages are written
to the ﬂash storage medium. Data can be written from two sources: the actual data
written by the simulator, and the data copied by the log-structured ﬁle system’s com-
pactor. Our simulator uses a constant write distribution and therefore the expected
rate of writes from the simulator is the same for all experiments. Therefore, the ob-
served disparity in erase block allocation rates reﬂects exactly the additional writes
resulting from the increased compactions caused by our application to achieve se-
cure deletion.
To quantify how promptly secure data deletion occurs, we measure the expected
time data remains on the storage medium. We calculate this measurement using
our pattern writer that periodically writes one page pattern onto the medium and
deletes them. We then compute how long the written pattern remains on the storage
medium.
5.6.1 Experimental Results
Table 5.2 presents the results of simulated storage media usage with different bal-
looning thresholds. The partition size is the full storage capacity of the medium.
The ﬁll ratio is the average proportion of valid data on erase blocks in the stor-
age medium, ignoring both completely full and completely empty erase blocks. We
compute this by taking the periodic average of all ﬁll ratios for eligible erase blocks
and averaging these measurements (weighted by time between observations) over
the course of our experiment. The erase block allocations per hour is the rate that
erase blocks are allocated on the storage medium, indicating the frequency of writes
to the storage medium. We used the erase block allocation rate, along with an ex-
pected erase block lifetime of 104 erasures before becoming a bad block [66], to
compute an expected storage medium lifetime in years assuming even wear level-
ling. The purge cost is the number of erase blocks that must be allocated to execute
purging with this conﬁguration. Two deletion latencies are provided: the median
and 95th percentile, which give a good indication of the distribution. The maximum
value is undeﬁned, as ballooning provides no guarantee of secure deletion. Each ex-
periment was run four times and we provide 95% conﬁdence intervals for relevant
measurements.
5.6 Experimental Evaluation
69
Table 5.2 Erase block (EB) allocations, storage medium lifetimes, and deletion times for the
YAFFS ﬁle system.
partition
type
200 MiB
YAFFS
1 GiB
YAFFS
2 GiB
YAFFS
free
EBs
603.8
91.8