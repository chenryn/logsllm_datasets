title:Secure Content Sniffing for Web Browsers, or How to Stop Papers from
Reviewing Themselves
author:Adam Barth and
Juan Caballero and
Dawn Song
2009 30th IEEE Symposium on Security and Privacy
Secure Content Snifﬁng for Web Browsers, or
How to Stop Papers from Reviewing Themselves
Adam Barth
UC Berkeley
Juan Caballero
UC Berkeley and CMU
Dawn Song
UC Berkeley
Abstract
Cross-site scripting defenses often focus on HTML doc-
uments, neglecting attacks involving the browser’s content-
snifﬁng algorithm, which can treat non-HTML content as
HTML. Web applications, such as the one that manages this
conference, must defend themselves against these attacks or
risk authors uploading malicious papers that automatically
submit stellar self-reviews. In this paper, we formulate
content-snifﬁng XSS attacks and defenses. We study content-
snifﬁng XSS attacks systematically by constructing high-
ﬁdelity models of the content-snifﬁng algorithms used by
four major browsers. We compare these models with Web
site content ﬁltering policies to construct attacks. To de-
fend against these attacks, we propose and implement a
principled content-snifﬁng algorithm that provides security
while maintaining compatibility. Our principles have been
adopted, in part, by Internet Explorer 8 and, in full, by
Google Chrome and the HTML 5 working group.
1. Introduction
For compatibility, every Web browser employs a content-
snifﬁng algorithm that inspects the contents of HTTP re-
sponses and occasionally overrides the MIME type provided
by the server. For example, these algorithms let browsers
render the approximately 1% of HTTP responses that lack a
Content-Type header. In a competitive browser market,
a browser that guesses the “correct” MIME type is more
appealing to users than a browser that fails to render these
sites. Once one browser vendor implements content snifﬁng,
the other browser vendors are forced to follow suit or risk
losing market share [1].
If not carefully designed for security, a content-snifﬁng
algorithm can be leveraged by an attacker to launch cross-
site scripting (XSS) attacks. In this paper, we study these
content-snifﬁng XSS attacks. Aided by a technique we call
string-enhanced white-box exploration, we extract models of
the content-snifﬁng algorithms used by four major browsers
and use these models to ﬁnd content-snifﬁng XSS attacks
that affect Wikipedia, a popular user-edited encyclopedia,
and HotCRP, the conference management Web application
used by the 2009 IEEE Privacy & Security Symposium. We
%!PS-Adobe-2.0
%%Creator: 
%%Title: attack.dvi
Figure 1. A chameleon PostScript document that Inter-
net Explorer 7 treats as HTML.
then propose ﬁxing the root cause of these vulnerabilities:
the browser content-snifﬁng algorithm. We design an algo-
rithm based on two principles and evaluate the compatibility
of our algorithm on over a billion HTTP responses.
Attacks. We illustrate content-snifﬁng XSS attacks by de-
scribing an attack against the HotCRP conference manage-
ment system. Suppose a malicious author uploads a paper
to HotCRP in PostScript format. By carefully crafting the
paper, the author can create a chameleon document that
both is valid PostScript and contains HTML (see Figure 1).
HotCRP accepts the chameleon document as PostScript, but
when a reviewer attempts to read the paper using Internet
Explorer 7, the browser’s content-snifﬁng algorithm treats
the chameleon as HTML, letting the attacker run a malicious
script in HotCRP’s security origin. The attacker’s script can
perform actions on behalf of the reviewer, such as giving
the paper a glowing review and a high score.
Although content-snifﬁng XSS attacks have been known
for some time [2]–[4], the underlying vulnerabilities, dis-
crepancies between browser and Web site algorithms for
classifying the MIME type of content, are poorly under-
stood. To illuminate these algorithms, we build detailed
models of the content-snifﬁng algorithms used by four
popular browsers: Internet Explorer 7, Firefox 3, Safari 3.1,
and Google Chrome. For Firefox 3 and Google Chrome, we
extract the model using manual analysis of the source code.
For Internet Explorer 7 and Safari 3.1, which use proprietary
content-snifﬁng algorithms, we extract
the model of the
algorithm using string-enhanced white-box exploration on
their binaries. This white-box exploration technique reasons
directly about strings and generates models for closed-source
algorithms that are more accurate than those generated using
black-box approaches. Using our models, we ﬁnd such a
discrepancy in Wikipedia, leading to a content-snifﬁng XSS
attack (see Figure 2) that eluded Wikipedia’s developers.
1081-6011/09 $25.00 © 2009 IEEE
DOI 10.1109/SP.2009.3
360
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:16:06 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. To mount a content-snifﬁng XSS attack, the attacker uploads a GIF/HTML chameleon to Wikipedia. The
browser treats the chameleon as HTML and runs the attacker’s JavaScript.
Defenses. Although Web sites can use our models to con-
struct a correct upload ﬁlter today, we propose ﬁxing the
root cause of content-snifﬁng XSS attacks by changing
the browser’s content-snifﬁng algorithm. To evaluate the
security properties of our algorithm, we introduce a threat
model for content-snifﬁng XSS attacks, and we suggest two
design principles for a secure content-snifﬁng algorithm:
avoid privilege escalation, which protects sites that limit
the MIME types they use when serving malicious content,
and use preﬁx-disjoint signatures, which protects sites that
ﬁlter uploads. We evaluate the deployability of our algorithm
using Google’s search index and opt-in user metrics from
Google Chrome users. Using metrics from users who have
opted in, we improve our algorithm’s security by removing
over half of the algorithm’s MIME signatures while retaining
99.996% compatibility with the previous version of the
algorithm.
Google has deployed our secure content-snifﬁng algo-
rithm to all users of Google Chrome. The HTML 5 working
group has adopted our secure content-snifﬁng principles
in the draft HTML 5 speciﬁcation [5]. Microsoft has also
partially adopted one of our principles in Internet Explorer 8.
We look forward to continuing to work with browser vendors
to improve the security of their content-snifﬁng algorithms
and to eliminate content-snifﬁng XSS attacks.
Contributions. We make the following contributions:
• We build high-ﬁdelity models of the content-snifﬁng
algorithms of Internet Explorer 7, Firefox 3, Safari 3.1,
and Google Chrome. To extract models from the closed-
source browsers, we use string-enhanced white-box
exploration on the binaries.
• We use these models to craft attacks against Web sites
and to construct a comprehensive upload ﬁlter these
sites can use to defend themselves.
• We propose two design principles for secure content-
snifﬁng algorithms and evaluate the security and com-
patibility of these principles using real-world data.
• We implement and deploy a content-snifﬁng algorithm
based on our principles in Google Chrome and report
adoption of our principles by standard bodies and other
browser vendors.
Organization. Section 2 describes our analysis techniques,
the content-snifﬁng algorithms used by four major browsers,
and the concrete attacks we discover. Section 3 presents
our threat model, a server-based ﬁltering defense, our two
principles for secure content snifﬁng, a security analysis of
our principles, and a compatibility analysis of our implemen-
tation. Section 4 discusses related work. Section 5 concludes.
2. Attacks
In this section, we study content-snifﬁng XSS attacks.
First, we provide some background information. Then, we
introduce content-snifﬁng XSS attacks. Next, we describe a
technique for constructing models from binaries and apply
that
technique to extract models of the content-snifﬁng
algorithm from four major browsers. Finally, we construct
attacks against two popular Web sites by comparing their
upload ﬁlters with our models.
2.1. Background
In this section, we provide background information about
how servers identify the type of content included in an HTTP
response. We do this in the context of a Web site that allows
its users to upload content that can later be downloaded by
other users, such as in a photograph sharing or a conference
management site.
Content-Type. HTTP identiﬁes the type of content in up-
loads or downloads using the Content-Type header. This
header contains a MIME type1 such as text/plain or
application/postscript. When a user uploads a ﬁle
using HTTP, the server typically stores both the ﬁle itself
and a MIME type. Later, when another user requests the
ﬁle, the Web server sends the stored MIME type in the
Content-Type header. The browser uses this MIME type
to determine how to present the ﬁle to the user or to select
an appropriate plug-in.
1. Multipurpose Internet Mail Extensions (MIME) is an Internet stan-
dard [6]–[8] originally developed to let email include non-text attachments,
text using non-ASCII encodings, and multiple pieces of content in the same
message. MIME deﬁnes MIME types, which are used by a number of
protocols, including HTTP.
361
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:16:06 UTC from IEEE Xplore.  Restrictions apply. 
Some Web servers (including old versions of Apache [9])
send the wrong MIME type in the Content-Type header.
For example, a server might send a GIF image with
a Content-Type of text/html or text/plain.
Some HTTP responses lack a Content-Type header
entirely or contain an invalid MIME type, such as */*
or unknown/unknown. To render these Web sites cor-
rectly, browsers use content-snifﬁng algorithms that guess
the “correct” MIME type by inspecting the contents of
HTTP responses.
Upload ﬁlters. When a user uploads a ﬁle to a Web site,
the site has three options for assigning a MIME type to
the content: (1) the Web site can use the MIME type
received in the Content-Type header; (2) the Web site
can infer the MIME type from the ﬁle’s extension; (3) the
Web site can examine the contents of the ﬁle. In practice,
the MIME type in the Content-Type header or inferred
from the extension is often incorrect. Moreover, if the user
is malicious, neither option (1) nor option (2) is reliable. For
these reasons, many sites choose option (3).
2.2. Content-Snifﬁng XSS Attacks
When a Web site’s upload ﬁlter differs from a browser’s
content-snifﬁng algorithm, an attacker can often mount a
content-snifﬁng XSS attack. In a content-snifﬁng XSS attack,
the attacker uploads a seemingly benign ﬁle to an honest
Web site. Many Web sites accept user uploads. For example,
photograph sharing sites accept user-uploaded images and
conference management sites accepts user-uploaded research
papers. After the attacker uploads a malicious ﬁle,
the
attacker directs the user to view the ﬁle. Instead of treating
the ﬁle as an image or a research paper, the user’s browser
treats the ﬁle as HTML because the browser’s content-
snifﬁng algorithm overrides the server’s MIME type. The
browser then renders the attacker’s HTML in the honest
site’s security origin, letting the attacker steal the user’s
password or transact on behalf of the user.
To mount a content-snifﬁng XSS attack, the attacker must
craft a ﬁle that will be accepted by the honest site and
be treated as HTML by the user’s browser. Crafting such
a ﬁle requires exploiting a mismatch between the site’s
upload ﬁlters and the browser’s content-snifﬁng algorithm.
A chameleon document is a ﬁle that both conforms to a
benign ﬁle format (such as PostScript) and contains HTML.
Most ﬁle formats admit chameleon documents because they
contain ﬁelds for comments or metadata (such as EXIF [10]).
Site upload ﬁlters typically classify documents into different
MIME types and then check whether that MIME type
belongs to the site’s list of allowed MIME types. These
sites typically accept chameleon documents because they
are formated correctly. The browser, however, often treats
a well-crafted chameleon as HTML.
The existence of chameleon documents has been known
for some time [2]. Recently, security researchers have sug-
gested using PNG and PDF chameleon documents to launch
XSS attacks [3], [4], [11], [12], but these researchers have
not determined which MIME types are vulnerable to attack,
which browsers are affected, or whether existing defenses
actually protect sites.
2.3. Model Extraction
We investigate content-snifﬁng XSS attacks by extracting
high-ﬁdelity models of content-snifﬁng algorithms from
browsers and Web sites. When source code is available,
we manually analyze the source code to build the model.
Speciﬁcally, we manually extract models of the content-
snifﬁng algorithms from the source code of two browsers,
Firefox 3 and Google Chrome, and the upload ﬁlter of two
Web sites, Wikipedia [13] and HotCRP [14].
Extracting models from Internet Explorer 7 and Sa-
fari 3.12 is more difﬁcult because their source code is
not available publicly. We could use black-box testing to
construct models by observing the outputs generated from
selected inputs, but models extracted by black-box testing
are often insufﬁciently accurate for our purpose. For exam-
ple, the Wine project [15] used black-box testing and docu-
mentation [16] to re-implement Internet Explorer’s content-
snifﬁng algorithm, but Wine’s content-snifﬁng algorithm
differs signiﬁcantly from Internet Explorer’s content-snifﬁng
algorithm. For example,
the Wine signature for HTML
contains just the <html tag instead of the 10 tags we ﬁnd in
Internet Explorer’s content-snifﬁng algorithm by white-box
exploration.
To extract accurate models
from the closed-source
browsers, we employ string-enhanced white-box explo-
ration. Our technique is similar in spirit to previous white-
box exploration techniques used for automatic testing [17]–
[19]. Unlike previous work, our technique builds a model
from all the explored paths incrementally. Our technique
also reasons directly about string operations rather than the
individual byte-level operations that comprise those string
operations, and we apply our technique to building models
rather than generating test cases.
By reasoning directly about string operations, we can
explore paths more efﬁciently,
increasing the coverage
achieved by the exploration per unit of time and improving
the ﬁdelity of our models. We expect directly reasoning
about string operations will similarly improve the perfor-
mance of other white-box exploration applications.
Preparation. A prerequisite for the exploration is to extract
the prototype of the function that implements content sniff-
ing and to identify the string functions used by that function.
2. Although a large portion of Safari is open-source as part of the
WebKit project, Safari’s content-snifﬁng algorithm is implemented in the
CFNetwork.dll library, which is not part of the WebKit project.
362
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:16:06 UTC from IEEE Xplore.  Restrictions apply. 
For Internet Explorer 7, the online documentation at the
Microsoft Developer Network (MSDN) states that con-
tent snifﬁng is implemented by the FindMimeFromData
function [16]. MSDN also provides the prototype of
FindMimeFromData, including the parameters and return
values [20]. Using commercial off-the-self tools [21] as well
as our own binary analysis tools [22], [23], we identiﬁed
the string operations used by FindMimeFromData and
the function that implements Safari 3.1’s content-snifﬁng
algorithm after some dynamic analysis and a few hours of
manual reverse engineering.
Exploration. We build a model of the content-snifﬁng
algorithm incrementally by iteratively generating inputs that
traverse new execution paths in the program. In each iter-
ation, we send an input to the program, which runs in a
symbolic execution module that executes the program on
both symbolic and concrete inputs. The symbolic execution
module produces a path predicate, a conjunction of Boolean
constraints on the input that captures how the execution
path processes the input. From this path predicate, an input
generator produces a new input by negating one of the
constraints in the path predicate and solving the modiﬁed
predicate. The input generator repeats this process for each
constraint in the path predicate, generating many potential
inputs for the next iteration. A path selector assigns priorities
to these potential inputs and selects the input for the next
iteration. We start the iterative exploration process with an
initial input, called the seed, and continue exploring paths
until there are no more paths to explore or until a user-
speciﬁed maximum running time is exhausted. Once the
exploration ﬁnishes, we output the disjunction of the path
predicates as a model of the explored function.
String enhancements. String-enhanced white-box explo-
ration improves white-box exploration by including string
constraints in the path predicate. The input generator trans-
lates those string constraints into constraints understood by
the constraint solver. We process strings in three steps:
1) Instead of generating constraints from the byte-level
operations performed by string functions, the symbolic
execution module generates constraints based on the