# Title: Secure Content Sniffing for Web Browsers, or How to Stop Papers from Reviewing Themselves

**Authors:**
- Adam Barth, UC Berkeley
- Juan Caballero, UC Berkeley and CMU
- Dawn Song, UC Berkeley

**Conference:**
2009 30th IEEE Symposium on Security and Privacy

## Abstract
Cross-site scripting (XSS) defenses often focus on HTML documents while neglecting attacks that exploit the browser's content-sniffing algorithm, which can treat non-HTML content as HTML. Web applications, such as those managing academic conferences, must defend against these attacks to prevent authors from uploading malicious papers that automatically submit favorable self-reviews. In this paper, we define and analyze content-sniffing XSS attacks and propose effective defenses. We systematically study these attacks by constructing high-fidelity models of the content-sniffing algorithms used by four major browsers. By comparing these models with web site content filtering policies, we identify and construct specific attacks. To mitigate these vulnerabilities, we propose and implement a principled content-sniffing algorithm that enhances security while maintaining compatibility. Our principles have been partially adopted by Internet Explorer 8 and fully by Google Chrome and the HTML 5 working group.

## 1. Introduction
Web browsers use content-sniffing algorithms to inspect HTTP responses and sometimes override the MIME type provided by the server. This ensures that even responses lacking a `Content-Type` header can be rendered correctly. In a competitive market, browsers that accurately guess the MIME type are more appealing to users. However, if not designed securely, content-sniffing algorithms can be exploited to launch cross-site scripting (XSS) attacks.

In this paper, we investigate content-sniffing XSS attacks. Using a technique called string-enhanced white-box exploration, we extract detailed models of the content-sniffing algorithms used by four major browsers. We then use these models to find and demonstrate content-sniffing XSS attacks affecting Wikipedia and HotCRP, a conference management system. We propose a solution by redesigning the browser's content-sniffing algorithm based on two key principles. We evaluate our algorithm's compatibility using over a billion HTTP responses.

### Example Attack
Consider an attack on the HotCRP conference management system. A malicious author uploads a paper in PostScript format, but the paper is crafted to also contain HTML. HotCRP accepts the document as PostScript, but when a reviewer opens it in Internet Explorer 7, the browser's content-sniffling algorithm treats it as HTML, allowing the attacker to execute a script in HotCRP's security context. This script can perform actions on behalf of the reviewer, such as giving the paper a high score and a positive review.

Although content-sniffing XSS attacks have been known [2]–[4], the underlying vulnerabilities—discrepancies between browser and web site algorithms for classifying MIME types—are poorly understood. We build detailed models of the content-sniffing algorithms used by Internet Explorer 7, Firefox 3, Safari 3.1, and Google Chrome. For Firefox 3 and Google Chrome, we manually analyze the source code. For Internet Explorer 7 and Safari 3.1, which use proprietary algorithms, we use string-enhanced white-box exploration to extract the models. This technique provides more accurate models than black-box approaches. Using these models, we identify a discrepancy in Wikipedia, leading to a content-sniffing XSS attack (Figure 2).

### Defenses
While web sites can use our models to create effective upload filters, we propose fixing the root cause by changing the browser's content-sniffling algorithm. We introduce a threat model for content-sniffing XSS attacks and suggest two design principles for a secure content-sniffling algorithm: avoid privilege escalation and use prefix-disjoint signatures. We evaluate our algorithm's deployability using Google's search index and opt-in user metrics from Google Chrome. Our improved algorithm removes over half of the MIME signatures while retaining 99.996% compatibility.

Google has deployed our secure content-sniffling algorithm in Google Chrome, and the HTML 5 working group has adopted our principles in the draft HTML 5 specification. Microsoft has partially adopted one of our principles in Internet Explorer 8. We continue to work with browser vendors to enhance the security of their content-sniffling algorithms and eliminate content-sniffing XSS attacks.

## Contributions
- **Model Extraction:** We build high-fidelity models of the content-sniffling algorithms of Internet Explorer 7, Firefox 3, Safari 3.1, and Google Chrome. For closed-source browsers, we use string-enhanced white-box exploration.
- **Attack Construction:** We use these models to craft attacks against web sites and to develop comprehensive upload filters.
- **Design Principles:** We propose two design principles for secure content-sniffling algorithms and evaluate their security and compatibility using real-world data.
- **Deployment:** We implement and deploy a content-sniffling algorithm based on our principles in Google Chrome, and report adoption by standard bodies and other browser vendors.

## 2. Attacks
### 2.1. Background
Web servers use the `Content-Type` header to identify the type of content in HTTP responses. When a user uploads a file, the server typically stores both the file and its MIME type. Later, when another user requests the file, the server sends the stored MIME type in the `Content-Type` header. The browser uses this MIME type to determine how to present the file or select an appropriate plugin.

Some web servers send incorrect MIME types, and some HTTP responses lack a `Content-Type` header. Browsers use content-sniffing algorithms to guess the correct MIME type by inspecting the response content.

### 2.2. Content-Sniffing XSS Attacks
When a web site's upload filter differs from a browser's content-sniffling algorithm, an attacker can mount a content-sniffing XSS attack. The attacker uploads a seemingly benign file to an honest web site. When the user views the file, the browser's content-sniffling algorithm treats it as HTML, rendering the attacker's HTML in the site's security context. This allows the attacker to steal the user's password or perform actions on their behalf.

To mount such an attack, the attacker crafts a chameleon document that conforms to a benign file format (e.g., PostScript) but also contains HTML. Most file formats allow chameleon documents due to fields for comments or metadata. Web sites typically accept these documents because they are formatted correctly, but the browser may treat them as HTML.

### 2.3. Model Extraction
We extract high-fidelity models of content-sniffling algorithms from browsers and web sites. For open-source browsers (Firefox 3 and Google Chrome), we manually analyze the source code. For closed-source browsers (Internet Explorer 7 and Safari 3.1), we use string-enhanced white-box exploration, which is more accurate than black-box testing.

**Preparation:**
- For Internet Explorer 7, we use the `FindMimeFromData` function, documented on MSDN.
- For Safari 3.1, we use commercial and custom tools to identify the string operations and the function implementing content-sniffling.

**Exploration:**
- We iteratively generate inputs that traverse new execution paths in the program.
- The symbolic execution module produces a path predicate, and the input generator creates new inputs by negating constraints in the path predicate.
- The path selector assigns priorities to potential inputs and selects the next input.
- We start with an initial seed and continue until no more paths are left or a maximum running time is reached.
- The final model is the disjunction of all path predicates.

**String Enhancements:**
- String-enhanced white-box exploration includes string constraints in the path predicate.
- The input generator translates string constraints into constraints understood by the constraint solver, improving the efficiency and coverage of the exploration.

This approach allows us to build more accurate and comprehensive models of content-sniffling algorithms, enabling the identification and mitigation of content-sniffing XSS attacks.