packet via all ports except the ingress port (p.InPort).
We deﬁne ideal conditions as when all hosts are station-
ary, there are no packet losses, there are no link or router
failures, there are no deduplication mistakes (our mechanism
ensures that there are no false positives, so this requires that
there also be no false negatives), the maximal HC is larger
than the diameter of the network, and no switch mistakenly
thinks a host is directly attached when it is not. Under such
conditions, we can make the following two statements about
the behavior of the algorithm which hold regardless of the
else
if ! IsDuplicate then
Flood(p)
end if
if ! p.L then
Table.Unlearn(p.EthDst)
else if ! IsDuplicate then
end if
p.HC ← p.HC + 1
p.F ← True
Table.Learn(p.EthSrc, p.InPort, p.HC)
p.F ← False
1: if p has no AXE header then
Add AXE header
2:
p.Nonce ← NextNonce()
3:
p.HC ← 1, p.L ← True
4:
if ! Table.Lookup(p.EthSrc) then
5:
6:
7:
8:
9:
10:
11: else
12:
13: end if
14:
15: if p.F then
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31: else if ! Table.Lookup(p.EthDst) then
32:
33:
34:
35: else if IsPortDown(Table.Lookup(p.EthDst)) then
36:
37:
38:
39: else if p.HC > MAX_HOP_COUNT then
40:
41:
42:
43:
44: else
45:
46: end if
end if
p.F ← True, p.L ← (HC = 1)
Flood(p)
Output(p, p.InPort)
p.F ← True, p.L ← (HC = 1)
Flood(p)
Output(p, p.InPort)
p.F ← True, p.L ← False
Flood(p)
Output(p, p.InPort)
Table.Unlearn(p.EthDst)
Out put(p,Table.Lookup(p.EthDst).Port)
Table.Learn(p.EthSrc, p.InPort, p.HC)
Table.Learn(p.EthSrc, p.InPort, p.HC)
else if ! Table.Lookup(p.EthSrc) then
Table.Learn(p.EthSrc, p.InPort, p.HC)
else if IsPortDown(Table.Lookup(p.EthSrc)) then
else if Table.Lookup(p.EthSrc).HC ≥ p.HC then
Table.Learn(p.EthSrc, p.InPort, p.HC)
Algorithm 1: The clean algorithm.
forwarding state currently in the switches (subject to the con-
straint about directly attached hosts):
Delivery: Packets will be delivered to their destination.
This holds because there are only three possibilities: (i) the
packet reaches the intended host following existing forward-
ing state (i.e., it is not ﬂooded), (ii) the packet reaches a
switch without valid forwarding state and then is ﬂooded and
therefore reaches its destination, or (iii) the hopcount even-
tually reaches the maximal value causing the packet to be
ﬂooded which therefore reaches its destination. What cannot
happen under our assumption of ideal conditions is that for-
warding state on a switch delivers the packet to the wrong
host (except in the case of ﬂooding, where it reaches all
hosts). Note that this line of reasoning guarantees delivery
even in the non-ideal case when there are link/router fail-
ures, as long as they do not cause a partition during the time
the packet and its copies are in ﬂight.2
Eventually shortest path routes: Forwarding state that
is learned from undisturbed ﬂoods will route packets along
shortest paths. We call a ﬂood from source A with L set an
499
undisturbed ﬂood if no unlearning of A takes place during the
time the ﬂood has packets in transit (e.g., due to other ﬂoods
with destination A which have the L ﬂag unset). New state is
installed if and only if packets have both the F and L ﬂags
set, which happens only when packets are ﬂooded from the
ﬁrst-hop switch. When intermediate switches receive multi-
ple copies of the same packet, the ultimate state reﬂects the
lowest hopcount needed to travel from the ﬁrst-hop switch to
the intermediate switch. Thus, as long as no state is erased
during this process, when all copies of the ﬂood from source
A with L set have left the network, every switch ends up with
state pointing toward an output port that has a shortest path
to the destination. Any packet following this state will take
a shortest path to A. The reason we require the ﬂood to be
undisturbed is because if some state is erased during the orig-
inal ﬂood, then the last state written may not point towards a
shortest path (i.e., the state that was erased may have been the
state reﬂecting the shortest path). Note that this statement of
correctness applies even if two or more ﬂooded packets from
A with the L ﬂag set were in ﬂight at the same time: since
the network topology is constant under ideal conditions, all
last-written state will point towards a shortest path.2
Thus, the clean design under ideal conditions, but with
arbitrary initial forwarding state (subject to the constraint
on attached hosts), will deliver all packets, and undisturbed
ﬂoods will install shortest-path forwarding state. However,
under non-ideal conditions we can make no such guarantees.
Packets can be lost and routes can be far from shortest-path.
Indeed, one can ﬁnd examples where routing loops can be
established under non-ideal conditions (though these loops
will be transient, as a packet caught in such a loop will reach
the maximal hopcount value, be ﬂooded, and cause the in-
correct forwarding state to be erased).
Before turning to our practical algorithm, we now explain
in more detail why we need both the L and the F ﬂags.
Note that in traditional L2 learning, ﬂooding and learning
are completely local decisions: a switch ﬂoods a packet if
and only if that switch has no forwarding state for the desti-
nation, and it learns from all packets about how to reach the
source. This works because packets are either constrained to
a well-formed tree (which is established via STP) or dropped
(while STP is converging). In contrast, AXE switches set the
F ﬂag the ﬁrst time the packet arrives at a switch that has
no forwarding state for the destination (or has forwarding
state pointing to a dead link), and then the packet is ﬂooded
globally regardless of whether subsequent switches have for-
warding state for the destination. This allows for delivery
even when the forwarding state is corrupted (e.g., by failures
or unlearning) and there is no guarantee that following the
remaining forwarding entries will deliver the packet.
While ﬂooding is more prevalent in AXE than in tradi-
tional L2, learning is more restrictive: The clean AXE algo-
rithm only learns from ﬂooded packets with the L ﬂag set.
This is because when packets are ﬂooded from arbitrary lo-
cations, the resulting learned state might be misleading. Con-
sider the network depicted in Figure 1, and imagine packets
ﬂowing from A to B along the path S1–S2–S3–S4–S5. If there
is a disruption in the path, say the link S3–S4 is broken, AXE
Figure 1: A network with two hosts (A and B), six switches, and a failed
link.
will ﬂood packets arriving at S3 instead of attempting to send
them down the failed link toward S4. Packets ﬂooded from
a failure, such as those handled by S3, must necessarily go
backwards (in addition to going out all other ports), as that
may be the only remaining path to the destination (as is the
case in Figure 1, where after the failure of S3–S4, the only
valid path to B for packets at S3 is backward through the path
S2–S6–S4–S5). One certainly does not want to learn from
packets that have traveled backwards, as one could poten-
tially be learning the reverse of the actual path to the desti-
nation. In this example, S2 would learn that A is towards S3,
which is clearly incorrect. Thus, when packets are ﬂooded
after reaching a failure, the L ﬂag is switched off, indicating
that they are unlikely to be suitable for learning.
2.2 Practical Algorithm
We presented the clean algorithm to illustrate the basic ideas
and show how they lead to two correctness results under
ideal conditions. These ideal conditions do not hold if there
is congestion, since packet losses can occur; in the clean de-
sign we liberally use packet ﬂoods when problems are en-
countered, which only exacerbates congestion. Thus, for our
more practical approach we modify some aspects of the al-
gorithm to reduce the number of ﬂoods, to enable learning
from non-ﬂood packets, and to give priority to ﬂood packets.
Unfortunately, our correctness results no longer hold with
these modiﬁcations in place. However, simulations suggest
that both the clean and the practical designs perform well un-
der reasonable loads and failure rates, but that the practical
algorithm is signiﬁcantly better at dealing with and recover-
ing from overloads or networks with high rates of failure.
The main changes from the clean design are as follows:
• When a packet exhausts its HC, we merely drop the
packet and erase the local forwarding state (rather than
ﬂooding the packet). This reduces the number of ﬂoods
under severe overloads, though the packet in question
is not delivered (which violates the ﬁrst correctness
condition under ideal conditions).
• Switches learn from all packets with the L ﬂag set, not
just ﬂooded packets. This also reduces the number of
ﬂoods, though the resulting paths are not always the
shortest paths (which violates the second correctness
condition under ideal conditions).
• Switches have one queue for ﬂooded packets and an-
other for non-ﬂooded packets, and the ﬂood queue is
given higher priority. Because ﬂoods occur in the ab-
sence of any state or the presence of bad state, and be-
cause ﬂoods trigger learning, accelerating the delivery
of ﬂoods enhances the learning of good state.
500
S1S2S3S4S5S6xBAWe also introduced various other wrinkles into the practi-
cal algorithm that improved its performance in simulations,
such as only unlearning at the ﬁrst hop and dealing with
hairpinning (discussed later). While the old correctness con-
ditions no longer hold with these changes, we can say that
under ideal conditions (i) unless the state for an address con-
tains a loop or is longer than the maximal HC, packets sent to
it will be delivered; and (ii) the forwarding state established
by undisturbed learning will enable packets to reach the in-
tended destination, but the paths are not guaranteed to be
shortest. We feel that the loosening of the correctness results
is a good trade-off for the improved behavior under overload.
We later extend AXE to handle both multipath and multi-
cast delivery, but in the next two subsections we discuss the
implementation of the deduplication ﬁlter and then examine
the pseudocode for the practical unipath algorithm.
2.3 The Deduplication Filter
Our deduplication ﬁlter provides approximate set member-
ship with false negatives – the opposite of a Bloom ﬁlter’s ap-
proximate set membership with false positives. While there
are many ways to build such a ﬁlter; the approach we use is
essentially a hash set with a ﬁxed size and no collision reso-
lution (that is, you hash an entry to ﬁnd a position and then
just overwrite whatever older entry may be there). Each entry
contains a  tuple. On reception, these packet
ﬁelds are hashed along with an arbitrary per-switch salt (e.g.,
the Ethernet address of one of its interfaces), and the hash
value is used to look up an entry in the ﬁlter’s table. If the
src, nonce, and L in the table entry match the packet, the
packet is a duplicate and the ﬁlter returns True. If the values
stored in the table entry do not match the packet, the values
in the table entry are overwritten with the current packet’s
values, and the ﬁlter returns False.
Note that the response that a packet is a duplicate can only
be wrong if the nonce has been repeated. We implement the
nonce using a counter, but given that the nonce ﬁeld has a ﬁ-
nite size, it must eventually wrap. Thus, it is conceivable that
a switch might produce a nonce such that a ﬁlter somewhere
in the network still contains an entry for an older packet with
the same nonce, and the possibility of this increases as the
ﬁlter size increases (which is otherwise a good thing). Fortu-
nately, we can compute the minimal amount of time required
for this to occur. For example, with a 24 bit nonce space (as