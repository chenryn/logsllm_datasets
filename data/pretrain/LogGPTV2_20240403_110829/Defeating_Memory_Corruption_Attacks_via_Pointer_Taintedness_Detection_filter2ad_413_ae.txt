110M 
No 
GZIP 
485KB 
282KB 
6,926M 
No 
MCF 
304KB 
39.2KB 
1,653M 
No 
PARSER 
595KB 
743.0KB 
389M 
No 
VPR 
697KB 
6.4KB 
108M 
No 
Total 
6586KB 
2186KB 
15,139M 
No 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:19:55 UTC from IEEE Xplore.  Restrictions apply. 
Buffer  overflow  attacks  corrupting  critical  flags.
Table 4(B) depicts user authentication functionality, where 
a  flag  auth  is  defined  to  indicate  whether  a  user  is 
authenticated.  After  Line  3  sets  this  flag  by  calling 
do_auth(),  the  buffer  overflow  vulnerability  in Line 4 can 
be exploited to overwrite the authenticated flag to 1. Line 5 
grants  access  to  the  user  according  to  the  auth  flag,  and 
therefore an attacker can get the access without successful 
authentication.  This  attack  cannot  be  detected  by  our 
technique,  as  the  attack  simply  overflows  a  buffer  to 
corrupt  an  integer  following  it,  and  no  pointer  tainted 
during the attack.  
Table 4: False Negative Scenarios 
(A)  Integer  overflow 
causing array index out 
of boundary 
void foo( 
       unsigned int ui) { 
1:  int i = ui; 
2:  if (i >= ArraySize) 
3:     i = ArraySize – 1; 
4:  array[i] = 1; 
}
(B)  Buffer  overflow 
causing  critical  flags 
to be corrupted 
void bar () { 
1:  int auth; 
2:  char buf[100]; 
3:  auth =  do_auth (); 
4:  scanf(“%s”,buf); 
5:  if (auth) 
          grant_access(); 
}
string 
causing 
(C)Format 
attack 
information leak  
void leak() { 
1:  int secret_key; 
2:  char buf[12]; 
3:  recv(s,buf,12,0); 
4:  printf(buf); 
}
technique  prevents 
Format  string  attacks  causing  information  leaks.
Although  our 
the  attacker  from 
overwriting data through a format string attack, Table 4(C) 
shows that such a vulnerability could allow the attacker to 
get private information from memory data regions such as 
the stack. Function leak() defines an integer secret_key on 
the stack. A user input buffer buf is passed to printf() as the 
format argument. We have shown that if the attacker sends 
abcd%x%x%x%n  to  the  buffer,  an  alert  is  raised  because 
the %n directive attempts to dereference a tainted pointer. 
However, if the input is %x%x%x%x, the attacker can read 
the  top  four  words  on  the  stack,  including  the  secret_key.
Such  an  information  leak  attack  can  be  used  for  future 
security  compromises  not  based  on  memory  corruptions, 
for  example,  attacks  to  steal  user  passwords  and  secret 
random seeds. 
Despite  these  false  negative  scenarios,  the  technique 
proposed  in  this  paper  substantially  improves  security 
coverage  because  (1)  we  can  effectively  defeat  most 
attacks  corrupting  both  control  data  and  non-control  data, 
(2)  the  false  negative  scenarios  are  in  general  not 
defeatable by any generic runtime detection technique that 
we  are  aware  of,  and  (3)  the  false  negative  scenarios  are 
rare in the real world. 
Effectively  exploiting  buffer  overflow  vulnerabilities 
without  corrupting  any  pointer  is  also  challenging  for 
attackers,  because  only  a  limited  number  of  words 
following 
the  buffer  can  be  overwritten.  For  stack 
overflow, the critical flag must be in the same frame as the 
buffer  being  overrun.  For  heap  overflow,  this  limit  is 
guarded by the locations of the free-chunk links following 
the buffer. Once the overflowed data exceeds the limit, our 
technique  raises  an alert because the return address or the 
links are tainted. Our technique cannot prevent information 
leak  damage  in  format  string  attacks,  but  we  expect  their 
severity to be much lower than for memory corruptions.  
One  direction  that  can  potentially  reduce  the  false 
negative  rate  is  to  sacrifice  the  transparency  of  the 
proposed  taintedness  detection  architecture.  We  can  ask 
the  programmer  to  annotate  important  data  structures  that 
should  never  be  tainted.  The  annotated  data  can  then  be 
monitored  by  our  architecture.  Then,  whenever  an 
annotated structure becomes tainted, an alert is raised.  
5.4.  Architectural Overhead 
Area overhead. The proposed method will incur some 
area  overhead  in  a  microprocessor  and  in  the  overall 
memory  system.  Within  the  processor,  the  data  path 
between  pipeline  stages  needs 
to 
accommodate the taintedness bit for each byte of data. The 
internal  physical 
registers,  buffers,  and  other  data 
structures  should  be  expanded,  as  should  the  data  bus 
between  the  processor,  caches,  and  physical  memory 
banks.  Physical  memory  banks  should  also  increase  in 
width to accommodate the taintedness bit. 
to  be  expanded 
Performance  overhead.  The  proposed  detection 
mechanism  should  not  cause  slowdown  or  longer  cycle 
time in the pipeline of a modern processor. This is because 
the propagation of the taintedness bits through load, store, 
and  ALU  operations  are  not  on  the  critical  path  of  these 
operations.  For  example,  in  executing  add  r1,  r2,  r3,  the 
taintedness  tracking  algorithm  need  only  perform  a  logic 
OR operation, which can be carried out in parallel with the 
add  operation.  In  fact,  the  logic  OR  operation  takes  less 
time than the add operation to complete, so the taintedness 
tracking  algorithm  will  not  increase  clock  cycle  time  for 
the ALU pipeline stage. For load and store operations, the 
taintedness bit is directly copied from source to destination 
and  therefore  can  be  performed  at  wire  speed.  At  the 
retirement  stage,  the  processor  checks  whether  a  memory 
access  (load/store  or  control  flow  transfer  instructions) 
uses tainted address values, which is a single bit operation. 
Again,  the  checking is simpler than the normal operations 
required for instruction retirement. Based this analysis, we 
believe  that  the  operations  for  the  pointer  taintedness 
algorithm do not add pipeline stages or increase cycle time.  
Software  processing  overhead.  The  operating  system 
kernel  requires  changes.  In  particular,  the  kernel  should 
mark  data  originating  from  input  system  calls  as  tainted. 
This can be done before the operating system passes such 
data  back  to  user  space.  If  we  assume  that  tainting  a  byte 
requires  an  additional  instruction,  the  percentage  of 
additional  instructions  executed  by  a  SPEC  benchmark 
program is between 0.002% and 0.2% based on the data in 
Table  3.  Since  our  current  prototype  is  based  on  a 
processor  simulator, 
the  discussed  operating  system 
enhancement  is  implemented  via  system  call  interception. 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:19:55 UTC from IEEE Xplore.  Restrictions apply. 
Actual  modification  of  the  operating  system  requires 
further investigation.  
6. Conclusions 
The majority of security vulnerabilities are due to low-
level  programming  errors  that  allow  attackers  to  corrupt 
memory.  Protections  based  on  control-flow  integrity  have 
recently been developed to defeat most memory corruption 
attacks. These techniques are based on the assumption that 
a  successful  memory  corruption  attack  usually  requires 
corrupting control data. We found a number of non-control 
data  attacks  that  can  compromise  the  security  of  major 
network applications. These attacks cannot be detected by 
existing techniques.  
This  paper  proposes  a  protection  technique  to  defeat 
both control data and non-control data attacks. We observe 
that  tainting  a  pointer  is  a  critical  step  in  memory 
corruption  attacks.  Accordingly,  we  have  developed  a 
pointer  taintedness  detection  architecture  to  defeat  most 
memory  corruption  attacks.  We  present  the  hardware 
design  of  the  proposed  technique,  and  implement  a 
prototype  in  the  SimpleScalar  processor  simulator.  Based 
on  an  extensive  evaluation  using  both  synthetic  and  real-
world network applications, and the SPEC benchmarks, we 
conclude 
following:  The  proposed  architecture 
provides a substantial improvement in security coverage; a 
near-zero  false  positive  rate  can  be  expected  when  the 
architecture  is  deployed;  despite  some  synthetic  false 
negative  scenarios,  running  programs  on  the  proposed 
architecture  minimizes  the  chances  of  a  successful  attack; 
the incurred architectural overhead is likely to be low; and 
the  approach  is  transparent  to  existing  applications,  i.e., 
applications can run without recompilation. 
the 
Acknowledgments
This  work  is  supported  in  part  by  a  grant  from  Motorola 
Inc.  as  part  of  Motorola  Center  for  Communications,  in 
part  by  NSF  ACI  CNS-0406351,  and  in  part  by  MURI 
Grant  N00014-01-1-0576.  We  thank  Fran  Baker  for  her 
careful reading of an early draft of this manuscript. 
References: 
[1] Aleph  One.  “Smashing  the  Stack  for  Fun  and  Profit.”  Phrack 
[2]
Magazine, 49(7), Nov. 1996. 
“PaX  Address  Space  Layout  Randomization 
http://pax.grsecurity.net/docs/aslr.txt. 
(ASLR).” 
[3] Anonymous.  “Once  upon  a  free().”  Phrack  Magazine,  57(9), 
Aug. 2001. 
[4] S. Bhatkar, D. DuVarney, and R. Sekar. “Address Obfuscation: 
An  Efficient  Approach  to  Combat  a  Broad  Range  of  Memory 
Error  Exploits.”  12th  USENIX  Security  Symposium.
Washington, DC, August 2003.
[5] A. Baratloo, T. Tsai, N. Singh. “Transparent Run-Time Defense 
Against  Stack  Smashing  Attacks.”  Proc.    USENIX  Annual 
Technical Conference, June 2000. 
[6] C.  Cowan,  M.  Barringer,  S.  Beattie,  G.  Kroah-Hartman,  et  al. 
“FormatGuard: Automatic Protection From printf Format String 
[7]
10th  USENIX 
Security 
Vulnerabilities.” 
Washington, DC, August 2001.
J.  R.  Crandall  and  F.  T.  Chong.  Minos.  “Control  Data  Attack 
Prevention  Orthogonal  to  Memory  Model.”  To  appear  in  the 
37th International Symposium on Microarchitecture. Portland, 
Oregon. December 2004.
Symposium,
[8] CERT CC. http://www.cert.org. 
[9] B. Chess. “Improving Computer Security Using Extended Static 
Checking.” IEEE Symposium on Security and Privacy, 2002. 
[10] S.  Chen,  K.  Pattabiraman,  Z.  Kalbarczyk,  R.  K.  Iyer.  “Formal 
Reasoning of Various Categories of Widely Exploited Security 
Vulnerabilities  Using  Pointer  Taintedness  Semantics.”  19th
IFIP 
Security  Conference 
(SEC2004), Toulouse, France, August 23-26, 2004.
International 
Information 
[11] C.  Cowan,  C.  Pu,  D.  Maier,  et  al.  “Automatic  Detection  and 
Prevention of Buffer-Overflow Attacks.”  7th USENIX Security 
Symposium, San Antonio, TX, January 1998. 
[12] D.  Evans  and  D.  Larochelle.  “Improving  Security  Using 
Extensible  Lightweight  Static  Analysis.”  In  IEEE  Software,
Jan/Feb 2002. 
[13] Microsoft  TechNet.  “Changes  to  Functionality  in  Microsoft 
Windows  XP  Service  Pack  2  (Part  3:  Memory  Protection 
Technologies).” 
http://www.microsoft.com/technet/prodtechnol/ 
maintain/sp2mempr.mspx. 
winxppro/ 
[14] “Wu-Ftpd  Remote 
Format 
String 
Stack  Overwrite 
Vulnerability.” http://www.securityfocus.com/bid/1387 
[15] “Null  HTTPd  Remote  Heap  Overflow  Vulnerability.” 
http://www.securityfocus.com/bid/5774.
[16] “Ghttpd  Log()  Function  Buffer  Overflow  Vulnerability.” 
http://www.securityfocus.com/bid/5960.
[17] “LBNL  Traceroute  Heap  Corruption  Vulnerability.” 
http://www.securityfocus.com/bid/1739,
[18] G. Suh, J. Lee, and S. Devadas. “Secure Program Execution via 
Dynamic  Information  Flow  Tracking.”  11th  International 
Conference  on  Architectural  Support 
for  Programming 
Languages  and  Operating  Systems.  Boston,  Massachusetts. 
October 2004. 
[19] H. Shacham, M. Page, B. Pfaff, et al. “On the Effectiveness of 
Address  Space  Randomization.”  ACM  Computer  and 
Communications Security (CCS). Washington, DC. Oct. 2004. 
[20] D.  Burger  and  T.  Austin.  The  SimpleScalar  Tool  Set,  Version 
2.0.
[21] U.  Shankar,  K.  Talwar,  J.  Foster,  and  D.  Wagner.  “Detecting 
Format  String  Vulnerabilities  with  Type  Qualifiers.”  10th
USENIX Security Symposium, 2001. 
“Format 
Newsham. 
Attacks.” 
[22] Tim 
String 
http://muse.linuxmafia.org/lost+found/format-string-
attacks.pdf. 
[23] D.  Wagner,  J.  Foster,  E.  Brewer,  and  A.  Aiken.  “A  First  Step 
of  Buffer  Overrun 
Towards  Automated  Detection 
Vulnerabilities.”  Network  and  Distributed  System  Security 
Symposium (NDSS2000).
[24] J.  Xu,  Z.  Kalbarczyk  and  R.  K.  Iyer.  “Transparent  Runtime 
Randomization  for  Security.”  Proc.  of  22nd  Symposium  on 
Reliable and Distributed Systems (SRDS), Florence, Italy, Oct. 
6-8, 2003. 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:19:55 UTC from IEEE Xplore.  Restrictions apply.