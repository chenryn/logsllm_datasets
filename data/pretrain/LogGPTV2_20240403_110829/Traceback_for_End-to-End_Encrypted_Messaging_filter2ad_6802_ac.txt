property. More formally,
Advp-tr-conf
MT
Theorem 1. Let MT be the message tracing scheme for path trace-
back defined in Figure 3 using hash function H. Then if H is modeled
as a random oracle, for any PTrCONF adversary A that makes at
most q oracle queries, we give adversary B and C such that
(C)
(A) ≤ Advprf
F,q(B) + Advror-cpa
E,q
where if A runs in time T , then B and C run in time T ′ ≈ T and B
makes at most q oracle queries.
In the above, we use ≈ to hide small constants. We defer the
full proof as well as full definitions for the reduction targets to
Appendix A, and provide a sketch here.
Proof sketch: The proof proceeds in a straightforward fashion
through two main game hops. The first replaces the PRF evalua-
tion with that of a random function and bounds the distinguishing
advantage by the PRF security of F. The second replaces the encryp-
tion output with a random bit string and bounds the distinguishing
advantage by the real-or-random security of the underlying encryp-
tion scheme. After these two steps, it is easy to see that the sender
trace tag, which consists of the output mid of F and a ciphertext
ct, is a random bit string.
User trace confidentiality. In user trace confidentiality, a real-
or-random style definition will not work, as the recipient’s view
of tracing key, plaintext, and recipient trace tag have a related
structure and must verify under RecMsg. Instead, we focus on the
specific goal we aim to achieve under user trace confidentiality,
namely that message history is not revealed. We thus task the
adversary with distinguishing between the result of an authored
message and a forwarded message. The adversary gets to choose
the plaintext and, in the case the challenge oracle is forwarding,
the tracing key and recipient trace tag representing the message
to be forwarded. The game pseudocode is given in Figure 4 (right).
We define the distinguishing advantage of the adversary as:
(cid:12)(cid:12)(cid:12)Pr(cid:104) UTrCONFA,1
MT ⇒ 1(cid:105)
− Pr(cid:104) UTrCONFA,0
MT ⇒ 1(cid:105)(cid:12)(cid:12)(cid:12) .
Advu-tr-conf
MT
(A) =
In our path traceback scheme, the recipient’s view consists of the
message identifier mid, tracing key ki, and the plaintext. Impor-
tantly, the ciphertext ct is stored by the platform and not visible to
the recipient. The tracing key is randomly generated for each sent
message and the message identifier is calculated as a function of
the tracing key and plaintext, mid ← Fki(p). Thus, no part of the
recipient’s view is dependent on previous message trace metadata,
e.g., ki−1, and any adversary’s advantage against our scheme is 0.
Theorem 2. Let MT be the message tracing scheme for path trace-
back defined in Figure 3. For any UTrCONF adversary A,
Advu-tr-conf
MT
(A) = 0 .
PTrCONFA,b
MT :
b′ ←$ AChal
return b′
Chal(U1, U2, tmd, p):
(k, tt
s ←$ {0, 1}len(tts )
0
tt
return ttb
s
s) ←$ TagGen(U1, U2, p, tmd)
1
UTrCONFA,b
MT :
b′ ←$ AChal
return b′
Chal(st, U0, k, ttr , U1, U2, p):
tmd0 ← RecMsg(k, U0, U1, p, ttr )
if tmd0 = ⊥ then return ⊥
tmd1 ←$ NewMsg(U1, p)
(k′, tts) ←$ TagGen(U1, U2, p, tmdb)
((mid, ttp), tt′
r ) ← Svr-Process(st, U1, U2, tts)
return (k′, tt′
r )
Figure 4: Notions for (left) platform trace confidentiality and (right)
user trace confidentiality.
5.2 Accountability
Tracing should accurately identify the source of a message, but
malicious users can always obfuscate from whom they’ve received a
message. We therefore want tracing never to result in an honest user
erroneously implicated in having taken an action (sent, forwarded,
or received a message) they did not, in fact, perform.
To formalize accountability we use a game-based approach in
which an adversary interacts with some number n of honest users.
See Figure 5. The adversary can cause honest users to author and
send (adversarially chosen) messages via two oracles NewMsg and
Send. The adversary can also pose as any number of malicious
users, sending messages via a malicious send oracle SendMal. We
identify users by a number, user i is honest if i ∈ [1, n] and user i
is malicious if i (cid:60) [1, n]. In our exposition we often use variables
U1, . . . , Un to refer to the honest users, and Aj for j (cid:60) [1, n] for a
malicious user. The security experiment here assumes authenticated
channels — the adversary cannot send messages as an honest user
nor manipulate messages sent between the honest users and the
platform. On the other hand, we give the adversary the power
to observe trace tags generated by, or sent to, honest users, but
they only see the tracing keys sent by honest parties to malicious
users. Given the use of secure channels to send messages, it would
seem sufficient to not reveal communications from honest parties
to the platform and from the platform to honest parties, but giving
the adversary this information only makes the security achieved
stronger.
The adversary’s goal is to generate a report that results in an
invalid trace, one that indicates that an honest user took some
action that they did not, in fact, take. Note that the adversary can
either have an honest user or malicious user make a report. In
the honest case, the adversary outputs a value c∗ indicating which
message received by i∗ is being reported, and in the malicious case
the adversary directly outputs an opening k∗. The game loops over
the reported trace (skipping the loop entirely if Svr-Trace output
an error), and checks for each honest user implicated in the trace
whether the reported trace matches an action they in fact performed.
We do this via a set of predicates, corresponding to where in the
trace the honest user appears, and whether they actually received
and/or sent the indicated messages.
As a non-exhaustive list of example invalid traces ruled out
by these predicates, consider the following scenarios, where for
simplicity we use a single honest user (n = 1):
:
MT,n
TrUNFA
c ← 0
(i∗, p∗, k∗, c∗) ←$ AO
if i∗ ∈ [1, n] then p∗ ← pc∗ ; k∗ ← ki∗,c∗
(tr1, mid1,2, tr2, . . . , midτ −1,τ , trτ ) ← Svr-Trace(PT, i∗, p∗, k∗)
for j ∈ 1 to τ do
if tr j ∈ [1, n] then
if
if (cid:0)i∗ ∈ [1, n] ∧ τ = 1(cid:1) then return true
(cid:16)
(cid:16)
(cid:16)1 < j < τ ∧ WasFwd(tri−1, tri , midi−1,i , midi,i +1, p∗) = false
j = 1 ∧ (WasSent(tr1, tr2, mid1,2, p∗) = false
j = τ ∧ WasRec(trτ −1, trτ , midτ −1,τ , p∗) = false
(cid:17)
(cid:17)
(cid:17)
then
or
or
return true
return false
NewMsg(i, p):
if i (cid:60) [1, n] then return ⊥
c ← c + 1
pc ← p
ki,c ←$ NewMsg(i, pc)
midc ← auth
return
Send(i, j, s):
if i (cid:60) [1, n] ∨ ki,s = ⊥ then return ⊥
(k, tts) ←$ TagGen(i, j, ps , ki,s)
((mid, ttp), ttr ) ←$ Svr-Process(PT, i, j, tts)
PT[mid] ← ttp
if mids = auth then WasSent(i, j, mid, ps) ← true
else WasFwd(i, j, mids , mid, ps) ← true
if j ∈ [1, n] then
c ← c + 1
pc ← ps
kj,c ← RecMsg(k, i, j, pc , ttr )
WasRec(i, j, mid, ps) ← true
midc ← mid
return ttr
return (ttr , k)
SendMal(i, j, k, p, tts):
if i ∈ [1, n] then return ⊥
((mid, ttp), ttr ) ←$ Svr-Process(PT, i, j, tts)
PT[mid] ← ttp
if j ∈ [1, n] then
k ← RecMsg(k, p, ttr )
if k (cid:44) ⊥ then
c ← c + 1
pc ← p
kj,c ← k
WasRec(i, j, mid, p) ← true
midc ← mid
return ttr
Figure 5: Trace unforgeability security game for path traceback.
• Message replacement: Honest user U1 sends a message mid
with plaintext p to a malicious user A2, who then successfully
reports the trace p∗ : U1 mid−→ A2 for some plaintext p∗ (cid:44) p.
This frames the honest user as having sent the wrong plaintext.
The only valid trace in this case is p : U1 mid−→ A2.
Identity replacement: Honest user U1 sends a message mid
with plaintext p to a malicious user A2, who then successfully
reports the trace p : U1 mid−→ A3 for some distinct user A3.
This frames the honest user as having sent the message to a dif-
ferent user. The only valid trace in this case is p : U1 mid−→ A2.
•
•
• Path suffix: Malicious user A2 sends a message mida with
plaintext p to the honest user U1, and then U1 forwards mida
to another user A3 in message midb. Then A3 successfully
reports the trace p : U1 midb−→ A3. This frames the honest user
as having originated a message that they instead forwarded
from someone else. The valid traces that can be reported in
this case are p : A2 mida−→ U1 and p : A2 mida−→ U1 midb−→ A2.
Same-message, wrong path: Two malicious users A2, A3
send messages mida, midb with the same plaintext p to the
honest user U1. The honest user forwards the message mida
from A2 to a user A4 in a message midc. Finally A4 generates
a report resulting in trace p : A3 midb−→ U1 midc−→ A4. This frames
the honest user as having forwarded a different message, de-
spite the plaintext being the same this could be an account-
ability problem given that the sender and message time are
incorrect. The valid traces that can be reported in this case are
p : A2 mida−→ U1, p : A3 midb−→ U1, and p : A2 mida−→ U1 midc−→ A4.
Notice that the prefix of any valid trace is also a valid trace (though
the reporter would be different in each case), but suffixes of a valid
trace are not always valid (second example). Also the examples
highlight the importance of tracing particular messages, not just
plaintexts, as we want the platform to be able to reliably associate
metadata (senders, receivers, timing) of messages to a reported
trace.
users n, and adversary A the path traceback forging advantage
We associate to any tracing scheme MT, number of honest
MT,n(A) = Pr(cid:104) TrUNFA
Advtr-unf
where the probability is taken over the random choices made in the
game, including those made by the adversary.
Intuitively, trace unforgeability is achieved in our path traceback
scheme due to the binding of the plaintext to a message identifier
with the tracing key. Honest users check the binding of message
identifiers they receive and send, so an adversary that wishes to
frame a user must find a collision on one of the honest user’s
message identifiers. For example, to achieve the message replace-
ment attack described above, an adversary must find an alternate
plaintext and key that collides with the honest user’s sent message
identifier. We thus provide the following theorem statement:
Theorem 3. Let MT be the message tracing scheme for path trace-
back defined in Figure 3. Then, for any TrUNF adversary A that
makes at most qnm new message queries, qs send queries, and qsm
malicious send queries, we give adversaries B and C such that
qs + qsm
MT,n(A) ≤ Advprf
F,qnm(B) + Advcr
F (C) +
Advtr-unf
where if A runs in time T , then B and C run in time T ′ ≈ T and B
makes at most qs + qsm oracle queries.
2n
We build a reduction using the collision resistance and PRF
security of F. We defer the full proof as well as full definitions for
the reduction targets to Appendix B, and provide a sketch here.
Proof sketch: This proof proceeds as a careful case analysis of
the four adversary winning conditions. We show that nearly all
of the winning conditions correspond to an adversary finding a
(cid:105)
MT,n ⇒ true
collision in F. In the single subcase that does not result in a collision,
we argue that the probability of reaching this subcase corresponds
to guessing the output of F keyed by a tracing key sampled in
NewMsg. Since tracing keys sampled in NewMsg are never re-
vealed to the adversary, we can show this probability is low using
the PRF security of F.
(cid:16)
tra,
(cid:105)(cid:17)
6 TREE TRACEBACK
Next, we consider an alternative traceback goal, tree traceback.
The goal in tree traceback is to allow reporting of a message with
plaintext p, enabling the platform to identify not just the path of
forwarded messages to the original author, as in path traceback, but
the entire forwarding tree of messages for p rooted at the original
author. A tree is denoted as a tuple of user identifier and list of
children subtrees, where each element of the children subtree list is
recursively a tree, i.e., a user identifier and list of children subtrees,
along with the message identifier for the message sent between
parent and child:
(cid:104)(cid:0)mida,0, trb,[. . .](cid:1),(cid:0)mida,1, trc,[. . .](cid:1), . . .
tr =
where trα ∈ U identifies a user and each midα,i is an identifier
for a message sent by trα .
The doubly-linked tags scheme. The doubly-linked tags con-
struction for tree traceback extends the strategy taken in path
traceback of storing encrypted pointers between message identi-
fiers. In the path traceback construction, for each message between
a sender and recipient, the platform stored an encrypted pointer
to trace backwards to the previous message, i.e., where the sender
received the message from. Intuitively, in tree traceback, we need
to extend this approach to also trace forwards in order to build the
forwarding tree. This includes storing pointers to forwards made
by the sender and forwards made by the recipient. However, at-
tempting to explicitly store encrypted pointers to other forwards is
problematic as the number of forwards of a message are not known
at the time of sending; the recipient has not yet even received the
message, let alone forwarded it, and the sender could choose to
forward the message to new recipients in the future.
We address this challenge by efficiently representing an un-
bounded set of pointers with a PRF key, gk, which acts as a gener-
ator for all the tracing keys associated to forwards of a particular
message. One enumerates the tracing keys by evaluating the PRF on
a counter ctr which is stored in the client’s state, k ← Fgk(ctr). As
in the path traceback construction, a tracing key points to a message
identifier through the evaluation of a PRF, mid ← Fk(p). Thus, the
platform stores three encrypted values with each message identifier:
(1) an encrypted tracing key ctki−1 for the previous message; (2) an
encrypted tracing key generator ctgki
for other forwards by the
sender; and (3) an encrypted tracing key generator (ctgki +1 , ks1)
for forwards by the recipient.
The three encrypted values stored by the platform correspond
to three stages of performing tree traceback, each illustrated in Fig-
ure 6. Given a report consisting of a tracing key and plaintext, first
the platform follows the tracing keys, ki−1, for previous message
identifiers until reaching the message source, essentially perform-
ing path traceback (Figure 6 (a)). Next, using the sender tracing
key generator, gki, the platform enumerates the tracing keys and