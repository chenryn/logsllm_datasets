under various K values. Specifically, when K = 5 and K = 10,
our surrogate model achieves the PRES @K of 97.33% and 97.42%.
We notice that, the surrogate model performs worse on AirbnbU S
than on AirbnbN Y and AirbnbMA. The reason is that the portion
of collected items over the entire data in AirbnbU S is only 7.58%,
smaller than those in AirbnbN Y and AirbnbMA, which are 20%
and 25%, respectively. Similarly, our model performs the worst on
AmazonR with the highest and lowest PRES @K values of 75.46%
and 50.21%, respectively, for K = 5 and K = 20. The reason is that
Amazon includes over 350 million items, but the number of items
included in our sampling trails takes only 0.014%. Nonetheless,
we see better performance if the surrogate model is learned on
just one category of items, AmazonB, with 82.22% of PRES @K
for K = 20. In N etEase Music, our model still achieves 83.26%
and 81.30% for K = 3 and K = 5, even though the portion of
collected items only equals 0.1%. This is because only popular
songs in NetEase Music support the similarity recommendation,
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea59meaning that collected songs are popular and making our model
learn the item relationships easier. For sampling data collected from
MovieLens, the PRES @K are all higher than 70%. Obviously, the
surrogate model is seen to perform better on MoiveLens5k than
on MoiveLens2k. These results show that our surrogate model is
effective on learning the item relationship of original recommender
systems, without the prior knowledge of both the recommender
algorithms and data information. The model enables us to perform
effective attacks. It also gives us the insight that the attacker can
focus more on each small category of items in websites, to be more
practical and effective.
6.2.2 Recommendation on Real-world Datasets. We implement dif-
ferent recommender algorithms, i.e., IBCF, SV D, ALS, BPR, NCF,
CML, DCF, KGCN , and FAST discussed in Section 6.1.1 on each
real-world dataset, to make item recommendations. The Random
Injection Collection method proposed in Section 4.1 is employed to
collect the sampling trails from these datasets when running differ-
ent algorithms. Specifically, in each dataset under one algorithm,
we sample 100, 000 trails, each including the top-20 recommended
items (or users). Those sampled trails are used to train our surro-
gate model for recommendation. We evaluate the performance of
the surrogate model by considering the top-5 and top-10 recom-
mendations. Table 3 shows the PRES @K values of our surrogate
model on each dataset when reproducing the results of different
recommender algorithms. We observe that the PRES @K values of
our surrogate model are always more than 70% in all test scenarios,
meaning it reproduces at least 70% of original recommendations.
In different datasets, the surrogate model has disparate perfor-
mance in mimicking different recommender algorithms. Specifi-
cally, for dataset ml-100k and д+, the surrogate model can best
reproduce BPR in the top-10 recommendation with the PRES @10
of 95.12% and 88.21%, respectively. In ml-1m, ml-20m, n f , tr, and
ac, it best mimics CML, with PRES @10 values of 93.17%, 89.26%,
87.05%, 87.65% and 82.46%, respectively. In am-b and am-d, it best
reproduces IBCF with PRES @10 values of 92.75% and 91.84%, re-
spectively. The results demonstrate that our surrogate model is
effective in learning the item proximities from the black-box CF
recommendations.
When comparing different datasets, the surrogate model per-
forms best on ml-100k for both top-5 and top-10 recommendations
with the averaged PRES @5 of 90.39% and PRES @10 of 91.59%,
respectively. It performs worse in the ac dataset, able to recover
75.79% top-5 recommender results and 76.98% top-10 recommen-
dations in average. The performance discrepancy is caused by the
number of items in the dataset. For example, there are 1682 items in
ml-100k while 4, 107, 340 nodes are in ac. Our collected sample trails
from ml-100k include almost all items, but from ac, they include
only a small portion of items. When examining four movie datasets
(i.e., ml-100k, ml-1m, ml-20m, and n f ), the averaged PRES @10 are
91.59%, 90.29%, 85.14%, and 81.34%, respectively. We also explore
the impacts of various parameters (i.e., the numbers of items and
sampling trails), which are deferred to Appendix A.3.
merely the real-world datasets to perform the attack under those
algorithms. When generating the surrogate model and performing
attack, our solutions are in the black-box setting. However, all
compared methods perform white-box attacks with full or partial
knowledge of recommender algorithms and dataset information.
Details about the knowledge requirement of each attack are given
in Table 4. Three knowledge requirements are shown: 1) Item,
which includes item information and item statistics (e.g., average
rating and popularity), 2) Relationship, which denotes the item-
item relationships in the historical dataset, and 3) Alдorithm which
is the specific algorithm used by the targeted recommender system.
Notably, RandomT , Averaдe, and Bandwaдon require to have item
information while PGAT and SGLDT require full attack knowledge.
In contrast, both our proposed availability and target attacks require
none of such knowledge, applicable to various categories of CF
algorithms.
For each category of CF algorithms, both the results of availabil-
ity and target attacks are examined. We define the attack ratio (f r)
as the fraction of the injected fake user count over the total number
of users in dataset.
Attack Performance on Item-based CF (IBCF). Table 5 shows
the averaged PRE@10 values of our availability attack and baseline
attack RandomA on IBCF with 4 examined datasets (ml-100k, am-b,
tr, and ac), when the attack ratio f r increases from 0.1% to 5%. We
observe the PRE@10 values of our availability attack are always
much higher than those from RandomA with the same f r in the
same dataset. When f r = 0.1%, the PRE@10 results of RandomA
are only in the range of 1.07% and 1.76% across all datasets, but
our attack achieves results in the range of 5.05% to 9.34%. When
f r increases from 0.1% to 5%, the PRE@10 values of our availabil-
ity attack rise much faster than those of RandomA. Specifically,
PRE@10 values of our attack in ac dataset increase from 5.05%
to 80.16%. Among the four datasets, RandomA performs the best
for am-b, under which its PRE@10 values rise only from 1.23% to
15.33%. Our attack performs the worst for tr dataset, but under
which its PRE@10 values grow from 6.28% to 50.71%. Our attack
always well outperforms its RandomA counterpart under any given
dataset. Note that, for f r = 5% on ml-100k, only 48 fake users are
required for PRE@10 value to reach 44.28%. The running times of
our attack are 43.1s, 1253.6s, 1074.3s, and 652.4s, respectively, for
attacking ml-100k, am-b, tr, and ac datasets.
Table 6 shows the HR@10 results of our target attack (ReverseT )
and RandomT , on IBCF, under ml-20m, am-b, and д+ datasets. For
f r = 0.1%, our target attack achieves the HR@10 of 4.38%, 6.22%,
and 5.33% on three datasets, respectively, compared favorably to
those of all other attacks which always yield no more than 2%.
The HR@10 values of our target attack increase much faster than
those of all other attackers, when f r increases from 0.1% to 5%.
Specifically, for f r = 5%, the HR@10 values of our target attack on
three datasets increase to 38.53%, 39.81%, and 46.04%, respectively.
However, for RandomT , its HR@10 values under three datasets
increase only to 8.77%, 3.51%, and 3.14%, respectively.
6.3 Attack Performance
We evaluate our attack performance corresponding to different
CF recommender algorithms. For ethical consideration, we use
Attack Performance on Matrix Factorization-based CF (SV D,
ALS, and BPR). Due to the space limitation, we show our results
for only two datasets, i.e., ml-100k and am-d. Figures 5(a) and 5(b)
Session 1A: Cybercrime CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea60Table 3: Performance (PRES @K) of the surrogate model on real-world datasets
PRES @K
K
ml-100k
ml-1m
ml-20m
n f
am-b
am-d
tr
д+
ac
IBCF
SV D
ALS
BPR
NCF
CML
DCF
5
94.31
91.07
84.25
82.06
90.04
91.22
82.69
87.02
78.15
10
94.67
92.56
87.64
85.70
92.75
91.84
85.31
85.47
79.50
5
92.56
90.42
85.20
75.97
85.30
80.14
80.25
82.05
73.66
10
93.55
91.57
86.04
74.20
86.06
85.06
87.34
84.26
77.99
5
92.11
90.29
85.46
78.22
86.01
86.37
82.07
78.45
75.19
10
92.70
93.08
87.28
81.60
83.39
86.88
83.18
78.61
74.82
5
93.63
90.35
82.46
83.20
85.55
86.78
83.05
85.34
78.20
10
95.12
91.77
83.31
80.72
87.64
88.42
84.29
88.21
78.41
5
91.07
90.55
85.29
82.01
83.71
86.28
82.65
87.12
75.13
10
90.62
91.24
85.59
81.34
85.54
88.36
82.99
88.65
77.49
5
90.25
90.03
87.45
85.60
88.32
86.25
85.34
87.73
81.78
10
93.76
93.17
89.26
87.05
89.49
87.56
87.65
88.43
82.46
5
82.19
81.37
82.38
71.52
74.32
81.25
76.25
73.93
70.27
10
85.76
82.18
82.67
71.08
75.79
83.34
79.57
74.66
70.35
Table 4: Comparisons of knowledge requirements among
different attack methods
KGCN
5
FAST
10
88.40
87.91
80.27
84.65
82.35
79.23
78.27
83.33
75.82
5
89.26
88.42
83.79
84.26
81.19
81.27
77.12
82.22
75.16
10
89.77
89.15
84.21
85.63
82.20
83.15
81.21
85.39
76.02
88.14
86.72
80.04
81.35
80.01
78.45
77.65
82.35
74.61
Attack methods
Availability attack RandomA
ReverseA
Target attack
Knowledge requirements
Item Relationship Alдorithm
√
×
√
√
√
√
√
×
×
×
×
×
×
√
√
×
×
×
×
×
×
√
√
×
RandomT
Averaдe
Bandwaдon
PGAT
SGLDT
ReverseT
Table 5: PRE@10 results of our availability attack ReverseA
and its counterpart RandomA on the Item-based CF (i.e., IBCF)
PRE@10(%)
RandomA
ReverseA
ml-100k
am-b
tr
ac
ml-100k
am-b
tr
ac
0.1
1.07
1.23
1.76
1.58
5.83
9.34
6.28
5.05
0.3