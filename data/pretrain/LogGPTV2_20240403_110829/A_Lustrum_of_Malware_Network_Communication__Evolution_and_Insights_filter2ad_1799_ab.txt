from successive gTLD zone transfers and, since the removal
alone does not always indicate an expiration, were further
vetted using the Extensible Provisioning Protocol (EPP) with
a domain reseller account. This methodology is modeled off
of previous work that studied potential pitfalls resulting from
domain ownership changes [43].
DGArchive. Plohmann et al. [58] recently reverse-engineered
malware families that use a DGA. The results of their work is
collected in the DGArchive [12], a database of 50M domains
that can be generated by the DGAs of 66 malware families.
We use the DGArchive to identify DGA domains among the
domains resolved in the malware executions.
Limitations and Potential Biases. Despite our best efforts
to collect
the most comprehensive set of data sources to
perform our study, there are still some limitations and potential
biases worth mentioning. For example, our study cannot cover
samples that have failed to run or that used evasion techniques
to avoid revealing their network behavior in the analysis
sandbox. To ameliorate this issue, we combine three different
malware feeds each using their own sandbox environment. Our
datasets also have some geographical bias towards the United
States, since the passive DNS data was collected from a large
US ISP. However, we believe some form of bias is unavoidable
in this type of study. Compared to the state of the art in DNS
and malware analysis, our datasets still provide the broadest
and deepest view on malware network behavior to date by far.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:08 UTC from IEEE Xplore.  Restrictions apply. 
III. DOMAIN FILTERING
We start our analysis by processing the DNS requests
performed by malicious ﬁles run in dynamic analysis sand-
boxes. For this, we ﬁrst remove 255,747 samples that were
not ﬂagged as malicious by any AV vendor (according to the
results collected in our VirusTotal dataset). What was left was
a set of likely malicious or unwanted ﬁles.
Since malware does not interact with exclusively malicious
infrastructure, not all domains queried by malware samples
can be considered malicious. In fact, as it is often the case
with large datasets, the initial set of DNS requests was very
noisy and needed to be carefully pre-processed to remove
all spurious and unwanted entries. In our study, we want to
focus on domains that are associated with actual malicious
communication. However, despite the fact that all domains are
requested by malicious ﬁles, the vast majority of the requests in
our dataset did not fall in this category. While this may seem
surprising at ﬁrst, it is the consequence of several factors—
such as the presence of non-existent domains generated by
domain generation algorithms (DGAs), connectivity tests to
benign domains, sinkholes, and spam-related activity.
To remove this noise, we proceeded with an initial ﬁltering
phase divided into four separate steps with the goal of elimi-
nating invalid, benign, or sinkholed domains as well as reverse
delegation queries.
Invalid Domains. Since not all DNS requests result in a valid
resolution, we ﬁrst ﬁlter out DNS queries that request non-
existent domains (i.e., that do not return a valid IP address).
This step is particularly important to reduce the impact of
domain generation algorithms (DGAs), where malware tries
to resolve many possible domains until it ﬁnds one that has
been registered by the botmaster. We study the resolutions for
non-existent domains, which may be subsequently registered
and used for abuse, and DGA behavior in Section VII.
Overall, this ﬁrst ﬁltering step successfully reduced the
number of unique effective second level domains from
6,850,793 to 1,316,331 , and the number of fully qualiﬁed
domain names from 11,532,653 to 3,767,234 .
Benign Domains. The hardest part of domain ﬁltering consists
of identifying and removing the queries performed towards
benign domains. Their presence is due to many factors that
include malware using legitimate services (e.g., Dropbox),
testing if the infected machine has a working Internet connec-
tion, downloading components from compromised websites,
delivering spam messages to victim mail servers, and even
querying an existing benign domain as a result of collisions in
a poorly designed DGA algorithm.
The variety of potential causes makes it very difﬁcult to
automatically ﬁlter out all benign DNS requests. Our approach
relies on three separate steps. In the ﬁrst, we use the ALEXA
dataset to remove domains that appeared in the Alexa top ten
thousand most popular domains for at least a year, with the
exception of dynamic DNS domains—which are often abused
for malicious purposes. While the ALEXA dataset provides a
good starting point, it fails to capture some obviously popular
domains. Therefore, in the second step we manually sifted
through the most popular domains remaining after the Alexa
ﬁltering, and we identiﬁed and removed from our dataset
other popular sites such as content distribution networks. This
step reduced the set of effective second level domains from
1,316,331 to 1,291,313 and fully qualiﬁed domain names from
3,767,234 to 3,295,860.
Finally, we noticed that the remaining dataset was largely
dominated by spam bots, which query hundreds or even
thousands of benign domains with the goal of locating the
SMTP servers of their targets. A comprehensive study of spam
behavior is outside the scope of this study. Therefore, we used
an aggressive ﬁlter that removed any samples performing MX
lookups and, as some malware may receive a pre-generated list
of MX records, samples that queried for domains containing
mail-related keywords (e.g., mail, smtp, imap). While exclud-
ing entire samples matching this ﬁlter may seem aggressive, we
observed that only 405,742 (1.5%) distinct samples contained
at least one MX or mail related domain. The presence of these
domains suggests a different type of behavior from the rest of
the samples in our dataset, and therefore, we chose to discard
them to avoid missing less popular, benign domains they may
have queried.
In total, their removal reduced the set of effective second
level domains from 1,291,313 to 329,348 and fully qualiﬁed
domain names from 3,295,860 to 2,154,609.
Reverse Delegation Zones. DNS Pointer Records (PTR) often
reﬂect activity from system processes (e.g., gethostbyname())
trying to resolve IP addresses in a remote network. This can
occur when a program directly connects to an IP address
without performing a DNS resolution of a service’s domain
name. For example, Windows logging makes note of a network
socket connection but avoids listing the IP address—generating
a DNS PTR record instead. This behavior, associated with
Windows logging of RFC 1918 [53] host names, can be ob-
served at the root levels of DNS [25]. Thus, dynamic execution
of a malware may generate reverse delegation domain names
that point to remote residential IP space. While the IP could be
malicious, the reverse delegation domain name and its effective
second level domain cannot be considered malicious as they
are typically owned by the ISP (e.g., Verizon) or the hosting
provider (e.g., Rackspace).
While it may seem reasonable to remove all e2LD domains
seen in PTR records, this would result in too coarse of a ﬁlter
because the owner of the netblock has the power to assign any
domain as the reverse DNS pointer. Thus, some PTR domains
will contain the actual domain name used to resolve an IP
address instead of a domain, created by the ISP or hosting
provider, to describe the underlying infrastructure.
In our ﬁnal step, we remove benign PTR domain names
from our malware domain dataset by excluding zones
used by large ISPs and hosting providers for reverse DNS
delegation [21]. In simple terms, reverse DNS is the domain
name that an Internet provider has delegated to an IP address.
For example, for the IP address 173.53.80.48 the Internet
provider has assigned the following reverse DNS delegation:
static-173-53-80-48.rcmdva.fios.verizon.net.
This domain name can be retrieved by asking the PTR DNS
record of the original IP.
Since malware execution may result in DNS PTR records to
be created, we want to exclude the most frequently witnessed
791
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:08 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1: Number of malware samples, qnames, e2LDs, and IPs
according to the execution time of the samples.
Fig. 2: Malware and PUP samples over time. The drop in 2014
is due to a downtime of our largest feed of malware executions.
e2LDs in such reverse delegation. Therefore, we obtained a
PTR scan of of all IPv4 from the Internet Systems Consortium
(ISC), and we broke down all the e2LDs in this datasets
according to the number of /24 and /16 network that can be
seen. Our assumption here is that if the same e2LDs can be
seen in several /16 and /24 networks, it must reﬂect a reverse
DNS allocation conducted by an ISP or a hosting provider. We
decide to pick the top 1% of the e2LDs for both /16 and /24
networks in our datasets, which reﬂects e2LDs that have been
seen in more than ten /24 and /16 networks at the same time.
This methodology identiﬁes only 4,323 e2LDs—resulting in
reverse pointer domains that are very likely associated with
ISP or hosting networks. We use this list as the ﬁnal ﬁlter,
reducing the set of effective second level domains to 327,514
and 2,085,484 fully qualiﬁed domains.
Filtering Summary. The domain ﬁltering phase reduced the
initial candidate set of domains queried by malicious samples
by over 95%. However, despite the signiﬁcant reduction in
e2LDs, 20M malware samples remain after ﬁltering with at
least one valid resolution.
Overall, this ﬁltering was a very challenging and time-
consuming process and the ﬁnal result, as we will discuss later
in the paper, still likely contains some benign domains with
low popularity. However, we believe that our effort emphasizes
two very important problems. First, the vast majority of DNS
queries performed by malware are not malicious per se – and
this may have a large impact on those approaches that populate
domain blacklists based on the results of dynamic analysis
sandboxes. Second, performing studies on very large datasets
requires long periods—months in the case of this work—of
manual work to tune ﬁlters and properly remove unwanted
noise.
The ﬁnal distribution of samples and domains over the four
years of our dataset is summarized in Figure 1. The drop in
the second half of 2014 reﬂects a failure in our collection
infrastructure for the largest feed of malware executions.
IV. CLASSIFICATION
We perform 3 classiﬁcations on our dataset: grouping
samples into families, classifying families as either malware
or PUP, and assigning e2LDs to speciﬁc families.
Sample classiﬁcation. We cluster and label all samples into
known families using the AV labels in VirusTotal reports.
While AV labels are known to be noisy [22], [50], we leverage
AVClass [66], a recently released open-source tool for massive
malware labeling. AVClass successfully removes noise from
AV labels by addressing label normalization, generic token
detection, and alias detection. The tool achieves F1 measures
between 0.94 and 0.70 and it can process extremely large sets
of VT reports—each containing AV scans of one sample by
multiple AV engines. AVClass outputs for each sample the
most likely family name and a conﬁdence factor based on the
agreement across engines.
PUP/Malware family classiﬁcation. In addition to the family,
AVClass also outputs for each sample whether it is PUP or
malware by examining PUP-related keywords in the AV labels.
However, that classiﬁcation is conservative as AV vendors
often do not ﬂag PUP samples as such. Thus, some samples in
a family may be ﬂagged as PUP and other samples in the same
family as malware. To address this issue we have modiﬁed
AVClass to output a classiﬁcation for each family as PUP or
malware, so that all samples in the family can be considered
of the same class. Our modiﬁcation counts for each family
the number of samples ﬂagged as malware and PUP. Then, it
applies a plurality vote on the samples of a family to determine
if the family is PUP or malware. We have contributed this
modiﬁcation to AVClass to be integrated in the tool.
We use our modiﬁed AVClass to automatically cluster and
label 23.9M samples for which we have a VT report. As a com-
parison, the previous largest malware clustering/classiﬁcation
effort in the literature was the AVClass evaluation with 8.9
M samples [66]. Figure 2 shows the number of malware and
PUP samples over time. The ﬁgure shows an increase of PUP
samples over time, with PUP overtaking traditional malware
since 2014. Kotzias et al. [38] observed the same trend but on
a dataset two orders of magnitude smaller and from a single
792
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:08 UTC from IEEE Xplore.  Restrictions apply. 
Family
vobfus
Rank
1
2 multiplug
loadmoney
3
virut
4
5
softpulse
hotbar
6
installerex
7
ﬁrseria
8
outbrowse
9
10
installcore
Top 10
Samples
Type
PUP
PUP
2.8 M Malware
2.4 M
1.6 M
1.4 M Malware
1.3 M
1.1 M
847 K
795 K
771 K
661 K
49%
PUP
PUP
PUP
PUP
PUP
PUP
-
e2LDs
741
808
2,958
40,705
3,793
306
155
3,138
52
1,118
15%
FSeen
11/09
01/13
12/12
03/08
06/14
08/10
12/11
07/12
04/13
09/11
-
Family
virut
rodecap
zbot
tedroo
sality
upatre
fareit
softpulse
ircbot
ﬁrseria
Rank
1
2
3
4
5
6
7
8
9
10
Top 10
Type
e2LDs
40,705 Malware
17,382 Malware
12,959 Malware
6,272 Malware
4,964 Malware
4,658 Malware
4,217 Malware
3,793
3,635 Malware
3,138
31%
PUP
PUP
-
Samples
FSeen
1.4 M 03/08
05/09
11.8 K
01/08
163 K
11/08
5 K
463 K
12/08
09/13
503 K
61 K
10/11
1.3 M 06/14