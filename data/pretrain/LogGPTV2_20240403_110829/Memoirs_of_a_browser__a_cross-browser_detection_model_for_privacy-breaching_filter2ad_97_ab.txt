Deﬁnition 2. A memory snapshot is a vector c = [c1, . . . , cm]
where each element cj represents the j-th MPC, 1 ≤ j ≤ m,
and m is the total number of MPCs considered.
At the end of the monitoring phase, the resulting n mem-
ory snapshots are then combined together to form a memory
write distribution.
Deﬁnition 3. A memory write distribution is a n× m matrix
C = [c1, . . . , cn]T = [ci,j]n×m whose rows represent the
n memory snapshots and the columns represent the m MPC
distributions considered.
In our model, the memory write distribution is a com-
prehensive analytical representation of the behavior of the
target browser in response to a predetermined injection vec-
tor e. Once the injection vector has been ﬁxed, this property
allows us to repeat the experiment under different conditions
and compare the resulting memory write distributions to an-
alyze and model any behavioral differences. In particular, we
are interested in capturing the properties of the baseline be-
havior of the browser and compare it against the behavior
of the browser when a given legitimate or privacy-breaching
extension is installed.
Our ultimate goal is to analyze and model the properties
of a set of memory write distributions obtained by monitor-
ing legitimate browser behavior and a corresponding set of
memory write distributions that represent privacy-breaching
browser behavior. Given a sufﬁcient number of known mem-
ory write distributions, a new previously unseen distribu-
tion can then be automatically classiﬁed by our detection
technique. This strategy reﬂects a two-class classiﬁcation
problem, where positive and negative examples are given
by memory write distributions that reﬂect privacy-breaching
and legitimate browser behavior, respectively.
4.1 Support Vector Machine
To address the two-class classiﬁcation problem and au-
tomatically discriminate between legitimate and privacy-
breaching browser behavior, we select support vector ma-
chine (SVM) [8] as our binary classiﬁcation method. SVMs
have been largely used to address the two-class classiﬁca-
tion problem and offer state-of-the-art accuracy in many
different application scenarios [22]. An SVM-based binary
classiﬁer maps each training example as a data point into
a high-dimensional feature space and constructs the hyper-
plane that maximally separates positive from negative ex-
amples. The resulting maximum-margin hyperplane is used
to minimize the error when automatically classifying future
unknown examples. Each example is represented by a fea-
ture vector xi ∈ Rd and mapped into the feature space using
a kernel function K (xi, xh), which deﬁnes an inner prod-
uct in the target space. To ensure the effectiveness of SVM,
one must ﬁrst carefully select the features that make up the
feature vector, and then adopt an appropriate kernel func-
tion, kernel’s parameters, and soft margin parameter [5]. In
our particular setting, the feature vectors must be directly
derived from the corresponding memory write distributions.
This process applies to any positive, negative, or unclassi-
ﬁed example. The next subsections detail the extraction of
the relevant features from the memory write distributions
considered and discuss how to translate them into feature
vectors suitable for our SVM classiﬁer. To select the most
effective SVM parameters in our setting, we conducted re-
peated experiments and performed cross-validation on the
training data. All the experiments were conducted using
LIBSVM [4], a very popular and versatile SVM implemen-
tation. Our experiments showed that the linear kernel with
C-SVC = 10 and γ = 10 give the best results in terms of
accuracy in the setting considered.
4.2 Feature Selection
The features that constitute the feature vector should each
ideally detail how a particular component of the browser
reacts to the injection. To achieve this goal, we need to
identify a single feature for each of the m MPC distributions.
The memory activity associated to a particular MPC is a
relevant feature since it documents both how often particular
code paths are executed and the volume of memory writes
performed in particular memory regions. The next question
we need to address is how to represent every single feature
associated to a particular MPC. In other words, starting from
a MPC distribution, we need to determine a single numeric
feature value that is suitable for SVM-based classiﬁcation.
To address this concern, we immediately observe that dif-
ferent MPC distributions may reﬂect a completely different
behavior of the browser for a particular MPC. If there is no
browser activity for a particular MPC, we will observe a cor-
responding zero MPC distribution. If there is some browser
activity but unrelated to the event distribution being injected,
we will observe a corresponding MPC distribution that is
very dissimilar from the original injection vector. Finally, if
the browser activity associated to a particular MPC repre-
sents indeed a reaction of the browser to the injection, we
will observe a corresponding MPC distribution that closely
resembles the original injection vector. To identify every sin-
gle scenario correctly, we need a correlation measure that
can reliably ascertain whether two distributions are corre-
lated and causality can be inferred with good approximation.
For our purposes, we adopt the Pearson Correlation Coefﬁ-
cient (PCC) [28] to measure the correlation between the in-
jection vector and every single MPC distribution.
The PCC is suitable for our purposes since it is both scale
and location invariant, properties that make the measure re-
silient to linear transformations of the distributions under
analysis. This translates to the ability to compare the orig-
inal injection vector with any given MPC distribution, even
in face of several memory writes performed for each bogus
event injected (scale invariance property) and uniformly dis-
tributed browser activity performed in the background (loca-
tion invariance property). Given two generic distributions P
and Q, the PCC is deﬁned as follows:
(cid:0)Pi − ¯P(cid:1)(cid:0)Qi − ¯Q(cid:1)
(cid:80)N
(cid:113)(cid:80)N
(cid:0)Pi − ¯P(cid:1)2(cid:113)(cid:80)N
(cid:0)Qi − ¯Q(cid:1)2
i=1
P CC (P, Q) =
i=1
i=1
In our model, the PCC is used to ascertain whether a partic-
ular MPC distribution reﬂects a reaction of the browser to
the injected events. High correlation values indicate browser
activity directly triggered by the injection. This is important
for two reasons. First, the PCC is used as a feature selection
mechanism in our model. If a particular MPC distribution
is not correlated to the injection vector for a given browser
conﬁguration, the MPC is assumed not to be a relevant fea-
ture for the to-be-generated feature vector. All the features
deemed irrelevant for all the examples in the training set are
automatically excluded from the analysis. Second, the PCC
is used to determine whether a particular feature is relevant
for the browser in a pristine state (i.e., the baseline behavior
of the browser with no extension enabled). This is important
when comparing the memory write distribution of a particu-
lar extension with the memory write distribution of the base-
line to ﬁlter out background browser activity and improve
the accuracy of the analysis, as explained later.
Once all the relevant features have been identiﬁed, we
quantify the numerical value of a single feature associated
to a particular MPC distribution as the ampliﬁcation factor
computed with respect to the original injection vector. Given
that these two distributions exhibit high correlation, we ide-
ally expect an approximately constant ampliﬁcation factor
in terms of number of bytes written for each event injected
over all the time intervals considered. This is representative
of the intensity of the memory activity associated to a partic-
ular MPC and triggered by our injection. Moreover, in order
to model the behavior of a particular extension more accu-
rately, the intensity of the memory activity is always mea-
sured incrementally, in terms of the number of additional
memory writes performed by the extension for each event in-
jected with respect to the baseline. In other words, for each
extension, the feature vector can be directly derived from
the memory write distribution obtained for the extension, the
memory write distribution obtained for the baseline, and the
predetermined injection vector used in the experiments. The
next subsections present the feature vector used in our model
more formally.
4.3 Feature Vector: Ideal Case
Let us consider the ideal case ﬁrst. In the ideal case, we as-
sume no background memory activity for the browser. This
translates to all the MPC distributions reﬂecting only mem-
ory activity triggered by the artiﬁcially injected events. As
a consequence, a given MPC distribution is either fully cor-
related with the injection vector (i.e., PCC = 1), or is con-
stantly zero over all the time intervals if no event-processing
activity is found. The latter assumptions are valid for all the
possible memory write distributions (i.e., baseline or exten-
sion(s) enabled). Under these assumptions, the number of
bytes written for each event is constant (assuming determin-
istic execution) and so is the ampliﬁcation factor over all the
time intervals.
Let C B be the baseline memory write distribution and
C E the memory write distribution when a given extension
E is instead enabled, both generated from the same injec-
tion vector e. The element xj of the feature vector x =
[x1, . . . , xm] in the ideal case represents the constant ampli-
ﬁcation factor for the MPC distribution of the j-th memory
performance counter, 1 ≤ j ≤ m. Each element xj for any
given time interval i can be deﬁned as follows.
if P CC(cid:0)e, C E∗,j
(cid:1) ≥ T
otherwise
(cid:40) CE
i,j−CB
i,j
+ ε
xj =
ki
0
where T is a generic threshold, and ε is the baseline ampli-
ﬁcation factor.
The rationale behind the feature vector proposed is to
have positive ampliﬁcation factors for each feature that rep-
resents a reaction of the browser to our injection. The am-
pliﬁcation factor grows as the number of bytes written for
each event increases and departs from the baseline value.
The correction factor ε is necessary to ensure positive am-
pliﬁcation factors even for extensions that behave similarly
to the baseline for some feature xj (i.e., C E∗,j ≈ C B∗,j). In
addition, this guarantees that the feature vector used to rep-
resent the baseline during the training phase is always repre-
sented by xj = ε, 1 ≤ j ≤ m. Feature values that are not
representative of the browser reacting to our injection (i.e.,
their corresponding MPC distribution is not correlated to the
injection vector) are always assumed to be 0. This mapping
strategy is crucial to achieve good separability in the feature
space.
Note that the constructed feature vector contains only
relative ampliﬁcation measures and is independent of the
particular injection vector used, as long as both the base-
line and the extension memory write distributions have been
generated by the same injection vector. This allows us to
the baseline. This is done by conservatively replacing any
MPC distribution with a zero distribution when no signiﬁ-
cant correlation is found with the injection vector. This oper-
ation removes all the background noise associated to features
that are not correlated to the event-processing activity in the
baseline. This alone is insufﬁcient, however, to eliminate any
interference in the computation of the ampliﬁcation factors
when correlated MPC distributions present spurious patterns
of background memory activity. To address this problem, we
can ﬁrst increase the granularity of our code ranges in the
memory snapshots. This strategy can further isolate differ-
ent code paths and greatly reduce the probability of two dif-
ferent browser tasks revealing signiﬁcant memory activity in
the same underlying MPC distribution.
In addition, we consider the distribution of the ampli-
ﬁcation factors over all the time intervals and perform an
outlier removal step before averaging the factors and com-
puting the ﬁnal feature value. To remove outliers from each
distribution of ampliﬁcation factors, we use Peirce’s crite-
rion [32], a widely employed statistical procedure for outlier
elimination. Peirce’s criterion is suitable for our purposes as
it allows an arbitrary number of outliers, greatly reducing
the standard deviation of the original distribution when nec-
essary. This is crucial for our model, given that we expect
a low-variance ampliﬁcation factor distribution once all the
spurious elements have been eliminated. In our experiments,
for any reasonable choice of the number of time intervals n,
we hardly observed any distribution value distant from the
mean after the outlier removal step. We now give the formal
deﬁnition of the ﬁnal feature vector used in our model.
Deﬁnition 4. Let the feature vector x = [x1, . . . , xm]. The
single element xj of the feature vector measures the average
ampliﬁcation factor for the MPC distribution of the j-th
memory performance counter, 1 ≤ j ≤ m. Each element
xj is deﬁned as follows.
1
n
1
n
0
xj =
(cid:80)n
(cid:80)n
i=1 ωi
i=1 ωi
i,j−CB
CE
i,j
ki
+ ε
CE
i,j
ki
+ ε
if P CC(cid:0)e, C E∗,j
P CC(cid:0)e, C B∗,j
if P CC(cid:0)e, C E∗,j
P CC(cid:0)e, C B∗,j
(cid:1) ≥ T ,
(cid:1) ≥ T
(cid:1) ≥ T ,
(cid:1) < T
otherwise
where T is a generic threshold, ε is the baseline ampliﬁca-
tion factor, and ωi ∈ {0, 1} is an outlier removal factor.
5. Case of Study: Keylogging Extensions
This section exempliﬁes the application of our model to
extensions with keylogging behavior and details the steps of
the resulting detection process. To instantiate our detection
model to a particular class of privacy-breaching extensions,
we need to (i) carefully select the injection events to trigger
the reaction of interest; (ii) deﬁne an appropriate training set
that achieves sufﬁcient representativeness and separability
between the samples. To satisfy the former, we simply need
Figure 3. Memory activity of different idle browsers.
use different injection vectors in the training phase and the
testing phase with no restriction. More importantly, this al-
lows us to compare correctly ampliﬁcation factors obtained
for different extensions, as long as the baseline is main-
tained stable. In our model, the baseline characterizes the
default behavior of the browser. When switching to a new
browser version or implementation, the memory write dis-
tribution of the baseline may change and the classiﬁer needs
to be retrained. Finally, note the impact of the assumptions
in the ideal case. First, the ampliﬁcation factor is constant
over any given time interval. Second, features that are nor-
mally irrelevant for the baseline but become relevant for a
particular extension are always automatically assumed to
(cid:0)C E
i,j/ki + ε(cid:1), given that the corresponding
be (1/n)(cid:80)n
baseline MPC distribution is assumed to be constantly 0.
i=1
4.4 Feature Vector: Real Case
The construction of the feature vector we presented in the
previous section did not address the case of background
memory activities interfering with our analysis. Sporadic,
but intensive memory writes could hinder the correlation or