The conjunctive form of a query allows Alice to ask CAS-DB
whether CAS signs a particular fact, and include a statement about
the purpose that she intends to use that signed fact for (in the form
of a proposed release policy for the fact). For example, Alice
may query CAS-DB with ?(CAS lsigns auth(shaketable, Alice) ^
(CAS lsigns srelease(CAS lsigns auth(shaketable, Alice), Alice,
shaketable))). A more voluminous set of rules in the query would
allow Alice to explain that she will only give CAS’s authorization
statement to her proxies and to the shaketable. Because PeerAc-
cess peers can choose to ignore queries, a peer may choose not to
respond to a query that lacks an acceptable purpose. If it is impor-
tant to support nonrepudiation of queries (e.g., for legal purposes),
then we can require that queries be signed; in this paper, we do not
consider that option.
The run-time behavior of a set of peers, as encoded in their proof
hints, exposure policies, and ECA rules, depends on the peers’ de-
signers’ choice of run-time strategies, such as the proposals put
forth by [2, 4, 14, 25]. Different strategies have different conven-
tions for what the acceptable responses are to a query. For example,
SD3 adopts the convention that Bob’s response must be such that
Alice never has to ask Bob the same query again as she continues to
work on getting all the answers to her query [14]. The proposal of
[2] guarantees complete query answers, under an assumption that
peers are fully cooperative. We intend PeerAccess to be customiz-
able to support all of these proposed strategies and the many others
that will be proposed in the future; each such proposal can guaran-
tee (or not) properties such as termination, safety, and liveness in
its own way. Thus the only query answer requirement PeerAccess
imposes is that every answer must be an ordinary message (directly
signed, releasable, and true at the sender). This allows Bob’s query-
answering behavior to range from non-response to sending back all
releasable information already in his KB plus everything he can
glean from other peers, whether or not it is relevant to the query. In
our remaining space, we cannot investigate any strategy in detail,
but we will revisit example 1 to see the effect of proof hints and
queries on an SD3-like run-time strategy.
Example 1c. (Bob makes and signs his own authorization de-
cisions, relying on directly signed CAS statements in his internal
reasoning.) Alice starts the interaction by sending Bob the query
?Bob lsigns auth(shaketable, Alice). Bob’s KB contains the fol-
lowing, plus three additional release rules for the auth predicate:
Bob:
Bob lsigns auth(shaketable, X)   CAS signs auth(shaketable, X)
Bob lsigns ﬁnd(CAS signs auth(shaketable, X), X, CAS)
  X 6= Bob
Bob lsigns srelease(
Bob signs ﬁnd(CAS signs auth(shaketable, X), X, CAS)
  X 6= Bob, Y , Z)
Bob’s exposure policies allow him to receive queries about shake
table authorizations from individual parties who would like to be
authorized. Bob is conﬁgured so that he tries to prove “Bob signs
auth(shaketable, Alice)” when he receives Alice’s query.
Bob checks to see if “Bob lsigns auth(shaketable, Alice)” is al-
ready in his KB (signature derivation rule), and ﬁnds that it is not.
Next he looks for rules that will allow him to expand the lsigned
version of his goal (modus ponens derivation rule), and ﬁnds his
CAS delegation rule. Then his effort shifts to proving “CAS signs
auth(shaketable, Alice)”, which is not in his KB. It is not a self-
signed formula, so an lsigned version of the formula would not
help. He has no rules that allow him to expand this proof goal. Bob
is stuck, and there are no other rules that allow him to expand his
original proof goal.
Since his local proof attempts have failed, Bob looks for proof
hints in his KB that will tell him how to prove any of his proof
goals, or that suggest sources for new rules to use in expanding
his current set of proof goals. He has only one proof hint, and its
preconditions are not satisﬁed. Bob is not conﬁgured to look for
additional proof hints at run time, so his proof attempts have ended
in failure. This is exactly the desired outcome: Bob wants Alice
to do the work of querying CAS. In accordance with SD3’s princi-
ples, Bob sends Alice sufﬁcient information that she will not have
to ask him the same query again (except to get his direct signature
on his authorization); he sends her “Bob signs auth(shaketable, X)
  CAS signs auth(shaketable, X)”, after proving that this formula
is releasable (signature rule). Bob is conﬁgured to send along all re-
leasable proof hints that are possibly relevant to his answers, so he
also sends his proof hint. (It would not be unreasonable in this case
for Bob to be conﬁgured to send Alice every releasable formula in
his KB. Or Bob might respond with the counterquery ?CAS signs
auth(Alice, shaketable).)
Alice is conﬁgured with an exposure policy that allows her to ac-
cept Bob’s query and his associated proof hint, which she adds to
her KB. In attempting to answer Bob’s query, her local knowledge
immediately fails her and she makes use of Bob’s proof hint, which
tells her to query CAS. CAS accepts queries from parties who are
asking whether they are authorized to access resources that CAS
knows about. Thus CAS accepts Alice’s query, and tries to prove
“CAS signs auth(shaketable, Alice)” using local inference. If CAS
answers the query by sending Alice “CAS signs auth(shaketable,
Alice)”, then Alice can push that fact to Bob and repeat her earlier
query.
(If CAS does not give Alice a suitable release policy for
her to push that fact to Bob, she can query CAS for the policy she
needs: ?CAS signs srelease(CAS signs auth(shaketable, Alice), Al-
ice, Bob).) This time, Bob can use the instantiation, modus ponens,
and signature derivation rules to prove “Bob signs auth(shaketable,
Alice)”. Bob is conﬁgured to send this signed fact to Alice, after
proving that it is releasable (instantiation and modus ponens deriva-
tion rules). If he is also conﬁgured to send her all associated release
policies, then she will be able to send the authorization fact to any-
one. If he does not automatically send her the release policy, she
and her proxies will have to query him for release permission each
time they send out the authorization fact.
8. CONCLUSIONS
We have presented a brief overview of the PeerAccess frame-
work, concentrating on its handling of base and release policies,
and shown how it can be used in reasoning about the behavior of
resource owners, their clients, and the Community Authorization
Service deployed on supercomputing grids. We have also presented
a formal semantics and proof theory for PeerAccess, and shown
their equivalence in the Appendix.
The features of PeerAccess were motivated by our need to model
certain run-time authorization activities supported in the Grid Se-
curity Infrastructure. To meet these needs, PeerAccess allows one
to model the local reasoning of individual peers who are unaware
of the internal state of other peers. PeerAccess also allows one to
reason about possible future global evolution of the system (e.g.,
for safety or liveness analysis). PeerAccess supports peer auton-
omy in choice of run-time behavior; this behavior is encoded in
individual peers’ ECA rules, exposure policies, and proof hints,
and expressed in a peer’s choice of pushing or pulling information,
its willingness to accept pushed information and queries, and how
hard it will work to answer the queries it accepts (i.e., what other
peers it is willing to contact for help). Peers can easily describe
their purpose in asking a query, and the answering peer can eas-
ily limit the purposes for which the answers will be used (subject
to voluntary compliance). PeerAccess offers an extensible set of
features, including the ability to model a variety of kinds of infor-
mation release policies (including the sticky release policies used
in the CAS examples); non-repudiable, veriﬁable communications
between peers; easy ways to limit a peer’s effort to prove a con-
clusion, and to direct its efforts in the most promising directions,
through the use of proof hints; modeling of the interface a peer ex-
poses to the outside world, through exposure policies; and potential
easy extension of the underlying language for particular scenarios,
such as constraint Datalog, simple forms of negation, or additional
types of policies, such as audit policies. Total freedom in peer be-
havior can lead to total chaos in run-time results, and PeerAccess
offers an excellent base for modeling, comparing, and experiment-
ing with different proposals for controlling peer run-time behavior
through multi-party trust negotiation strategies and credential dis-
covery algorithms.
9. ACKNOWLEDGMENTS
Winslett’s research was supported by NSF under grants CCR-
0325951 and IIS-0331707 and by an NCSA Fellowship. Bon-
atti’s research was partially supported by the EU FP6 Network of
Excellence REWERSE (IST-2004-506779). Zhang is also associ-
ated with Cisco Systems Inc., USA. We thank W. Nejdl and D.
Olmedilla for discussions leading to the creation of PeerAccess.
10. REFERENCES
[1] J. Basney, W. Nejdl, D. Olmedilla, V. Welch, and
M. Winslett. Negotiating trust on the Grid. In 2nd Workshop
on Semantics in P2P and Grid Computing, New York, 2004.
[2] L. Bauer, S. Garriss, and M. K. Reiter. Distributed proving in
access-control systems. In Proceedings of the IEEE
Symposium on Security and Privacy, Berkeley, May 2005.
[3] M. Y. Becker and P. Sewell. Cassandra: distributed access
control policies with tunable expressiveness. In 5th IEEE
International Workshop on Policies for Distributed Systems
and Networks, Yorktown Heights, June 2004.
[4] M. Y. Becker and P. Sewell. Cassandra: ﬂexible trust
management, applied to electronic health records. In IEEE
Computer Security Foundations Workshop, 2004.
[5] M. Blaze, J. Feigenbaum, and A. D. Keromytis. KeyNote:
Trust management for public-key infrastructures (position
paper). Lect. Notes in Computer Science, 1550:59–63, 1999.
[6] P. Bonatti and P. Samarati. Regulating Service Access and
Information Release on the Web. In Conference on Computer
and Communications Security, Athens, Nov. 2000.
[7] P. A. Bonatti and D. Olmedilla. Driving and monitoring
provisional trust negotiation with metapolicies. In Workshop
on Policies for Distributed Systems and Networks, 2005.
[8] M. Burrows, M. Abadi, and R. Needham. A logic of
authentication. ACM Trans. on Comp. Systems, 8(1), 1990.
[9] J. Camenisch and E. V. Herreweghen. Design and
implementation of the idemix anonymous credential system.
In Computer and Communications Security, 2002.
[10] R. Gavriloaie, W. Nejdl, D. Olmedilla, K. Seamons, and
M. Winslett. No registration needed: How to use declarative
policies and negotiation to access sensitive resources on the
semantic web. In European Semantic Web Symposium, 2004.
[11] A. Herzberg, Y. Mass, J. Michaeli, D. Naor, and Y. Ravid.
Access control meets public key infrastructure, or: assigning
roles to strangers. In Symp. on Security and Privacy, 2000.
[12] A. Hess, J. Jacobson, H. Mills, R. Wamsley, K. E. Seamons,
and B. Smith. Advanced client/server authentication in TLS.
In Network and Dist. Systems Security Symp., 2002.
[13] T. Jim. SD3: A trust management system with certiﬁed
evaluation. In IEEE Symp. on Security and Privacy, 2001.
[14] T. Jim and D. Suciu. Dynamically distributed query
evaluation. In Principles of Database Systems, 2001.
[15] G. Karjoth, M. Schunter, and M. Waidner. Platform for
enterprise privacy practices: Privacy-enabled management of
customer data. In Workshop on Privacy Enhancing
Technologies, 2002.
[16] H. Koshutanski and F. Massacci. Interactive trust
management and negotiation scheme. In Workshop on
Formal Aspects in Security and Trust, Aug. 2004.
[17] N. Li and J. Mitchell. RT: A role-based trust-management
framework. In Third DARPA Information Survivability
Conference and Exposition, Apr. 2003.
[18] N. Li, W. Winsborough, and J. Mitchell. Distributed
credential chain discovery in trust management. Journal of
Computer Security, 11(1), Feb. 2003.
[19] L. Pearlman, V. Welch, I. Foster, C. Kesselman, and
C. Tuecke. A community authorization service for group
collaboration. In Workshop on Policies for Distributed
Systems and Networks, 2002.
[20] B. Pﬁtzmann and M. Waidner. Federated
identity-management protocols–where user authentication
protocols may go. In 11th Cambridge International
Workshop on Security Protocols, Apr. 2003.
[21] C. Ruan, V. Varadharajan, and Y. Zhang. Logic-based
reasoning on delegatable authorizations. In Foundations of
Intelligent Systems, ISMIS 2002, Lyon, June 2002.
[22] S. Staab, B. Bhargava, L. Lilien, A. Rosenthal, M. Winslett,
M. Sloman, T. S. Dillon, E. Chang, F. K. Hussain, W. Nejdl,
D. Olmedilla, and V. Kashyap. The pudding of trust. IEEE
Intelligent Systems, 19(5):74–88, Sep./Oct. 2004.
[23] L. Wang, D. Wijesekera, and S. Jajodia. A logic-based
framework for attribute based access control. In Workshop on
Formal Methods in Security Engineering, Oct. 2004.
[24] M. Winslett, T. Yu, K. E. Seamons, A. Hess, J. Jacobson,
R. Jarvis, B. Smith, and L. Yu. The TrustBuilder architecture
for trust negotiation. IEEE Internet Computing, 6(6), 2002.
[25] T. Yu, M. Winslett, and K. E. Seamons. Supporting
structured credentials and sensitive policies through
interoperable strategies for automated trust negotiation. ACM
Trans. on Info. and System Security, 6(1), 2003.