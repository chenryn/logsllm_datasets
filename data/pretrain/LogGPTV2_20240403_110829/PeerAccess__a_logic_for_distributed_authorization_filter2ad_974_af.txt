### Conjunctive Query Form and Purpose in CAS-DB

The conjunctive form of a query in CAS-DB allows Alice to inquire whether CAS has signed a specific fact, and to include a statement about the intended purpose for which she will use that signed fact. This purpose is typically expressed as a proposed release policy for the fact. For example, Alice might query CAS-DB with:

```
?(CAS lsigns auth(shaketable, Alice) ^ (CAS lsigns srelease(CAS lsigns auth(shaketable, Alice), Alice, shaketable)))
```

A more detailed set of rules in the query would allow Alice to specify that she will only share CAS's authorization statement with her proxies and the shaketable. Since PeerAccess peers can choose to ignore queries, a peer may opt not to respond if the query lacks an acceptable purpose. If non-repudiation of queries is important (e.g., for legal purposes), queries can be required to be signed. However, this paper does not consider that option.

### Run-Time Behavior and Strategies

The run-time behavior of a set of peers, as encoded in their proof hints, exposure policies, and ECA rules, depends on the run-time strategies chosen by the peers' designers. These strategies, such as those proposed by [2, 4, 14, 25], have different conventions for acceptable responses to a query. For instance, SD3 adopts the convention that Bob’s response must ensure Alice never needs to ask the same query again as she continues to gather all the answers [14]. The proposal in [2] guarantees complete query answers under the assumption that peers are fully cooperative. PeerAccess is designed to be customizable to support various proposed strategies and future proposals, each of which can guarantee or not properties like termination, safety, and liveness. The only requirement imposed by PeerAccess is that every answer must be an ordinary message (directly signed, releasable, and true at the sender). This allows Bob’s query-answering behavior to range from non-response to sending all releasable information in his knowledge base (KB) plus any additional information he can glean from other peers, regardless of its relevance to the query.

### Example 1c: Bob's Authorization Decisions

**Example 1c:** Bob makes and signs his own authorization decisions, relying on directly signed CAS statements in his internal reasoning. Alice initiates the interaction by sending Bob the query `?Bob lsigns auth(shaketable, Alice)`. Bob’s KB contains the following, plus three additional release rules for the `auth` predicate:

- `Bob lsigns auth(shaketable, X)   CAS signs auth(shaketable, X)`
- `Bob lsigns find(CAS signs auth(shaketable, X), X, CAS)  X != Bob`
- `Bob lsigns srelease(Bob signs find(CAS signs auth(shaketable, X), X, CAS)  X != Bob, Y, Z)`

Bob’s exposure policies allow him to receive queries about shake table authorizations from parties seeking authorization. When Bob receives Alice’s query, he attempts to prove `Bob signs auth(shaketable, Alice)`.

First, Bob checks if `Bob lsigns auth(shaketable, Alice)` is already in his KB (signature derivation rule) and finds it is not. He then looks for rules to expand the lsigned version of his goal (modus ponens derivation rule) and finds his CAS delegation rule. His next step is to prove `CAS signs auth(shaketable, Alice)`, which is not in his KB. Since it is not a self-signed formula, an lsigned version would not help, and he has no rules to expand this proof goal. Thus, Bob is stuck and cannot expand his original proof goal.

Since local proof attempts fail, Bob looks for proof hints in his KB to guide him in proving any of his proof goals or suggest sources for new rules. He has one proof hint, but its preconditions are not satisfied. Bob is not configured to seek additional proof hints at run time, so his proof attempts end in failure. This is the desired outcome: Bob wants Alice to query CAS. In line with SD3’s principles, Bob sends Alice sufficient information to avoid repeating the same query, specifically `Bob signs auth(shaketable, X)  CAS signs auth(shaketable, X)`, after proving it is releasable (signature rule). Bob also sends his proof hint, as he is configured to send all releasable proof hints relevant to his answers.

Alice, configured with an exposure policy allowing her to accept Bob’s query and proof hint, adds them to her KB. Attempting to answer Bob’s query, her local knowledge fails, and she uses Bob’s proof hint to query CAS. CAS accepts queries from parties asking about their authorization to access known resources. Thus, CAS accepts Alice’s query and tries to prove `CAS signs auth(shaketable, Alice)` using local inference. If CAS answers by sending `CAS signs auth(shaketable, Alice)`, Alice can push this fact to Bob and repeat her earlier query. If CAS does not provide a suitable release policy, Alice can query CAS for the needed policy: `?CAS signs srelease(CAS signs auth(shaketable, Alice), Alice, Bob)`. This time, Bob can use instantiation, modus ponens, and signature derivation rules to prove `Bob signs auth(shaketable, Alice)`. Bob is configured to send this signed fact to Alice after proving it is releasable. If he is also configured to send all associated release policies, Alice can share the authorization fact with anyone. Otherwise, she and her proxies must query Bob for release permission each time they send out the authorization fact.

### Conclusions

We have provided an overview of the PeerAccess framework, focusing on its handling of base and release policies, and demonstrated how it can be used to reason about the behavior of resource owners, clients, and the Community Authorization Service in supercomputing grids. We have also presented a formal semantics and proof theory for PeerAccess, showing their equivalence in the Appendix.

PeerAccess was motivated by the need to model certain run-time authorization activities in the Grid Security Infrastructure. It allows modeling the local reasoning of individual peers who are unaware of the internal state of other peers and supports reasoning about possible future global evolution of the system (e.g., for safety or liveness analysis). PeerAccess supports peer autonomy in choosing run-time behavior, encoded in individual peers’ ECA rules, exposure policies, and proof hints. Peers can easily describe their purpose in asking a query, and the answering peer can limit the purposes for which the answers will be used (subject to voluntary compliance). PeerAccess offers an extensible set of features, including the ability to model various kinds of information release policies, non-repudiable and verifiable communications, and easy ways to limit a peer’s effort to prove a conclusion. Total freedom in peer behavior can lead to chaos in run-time results, and PeerAccess provides an excellent base for modeling, comparing, and experimenting with different proposals for controlling peer run-time behavior through multi-party trust negotiation strategies and credential discovery algorithms.

### Acknowledgments

Winslett’s research was supported by NSF under grants CCR-0325951 and IIS-0331707 and by an NCSA Fellowship. Bonatti’s research was partially supported by the EU FP6 Network of Excellence REWERSE (IST-2004-506779). Zhang is also associated with Cisco Systems Inc., USA. We thank W. Nejdl and D. Olmedilla for discussions leading to the creation of PeerAccess.

### References

[References remain unchanged as they are already well-formatted and clear.]