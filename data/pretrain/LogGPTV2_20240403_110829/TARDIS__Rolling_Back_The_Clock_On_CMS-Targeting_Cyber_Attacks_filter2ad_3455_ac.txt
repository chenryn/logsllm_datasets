(Sev(elj(ψi−1))==High)∧[(Sev(elj(ψi))==N one)∨(Sev(elj(ψi))==Low)∨((elj(ψi)) /∈Vi)]
it
as
the
use
such
capabilities
to
snapshots
temporal snapshot ψi, TARDIS appends a code metric
EvDc(elj(ψi)) to Mi
indicating unsafe or suspicious
code, compressed to avoid more conventional detectors.
Code Generation Capability. We observed that
almost every server-side spatial element contributing to
the multi-stage CMS-targeting attack contained code
generation
of
create_function. Although several developers use this
as part of certain CMS plugins,
is very rarely
employed in ordinary server-side code development.
TARDIS scouts for such code generation capabilities
and appends a code metric CodeGen(elj(ψi)) to the
spatial metric set Mi upon ﬁnding an element elj ∈ Vi
satisfying the constraints.
C. Temporal Correlation and Forensic Recovery
Based on the collected spatial metrics
for each
snapshot, TARDIS now attempts
temporally
correlate these metrics across
to identify
suspicious activities that evolve within the website. Here,
TARDIS is programmed to track developments over a
sliding n − day time window (e.g. n = 20 means track
developments in the spatial metrics by comparing them
across 20 days). In this stage, TARDIS temporally
correlates the spatial metric set Mi at any temporal
snapshot ψi with the spatial metrics Mx from all
previous temporal snapshots within the sliding window
(i − n 
5 June, 13 June, 8 June, 14 June,21 April,..,29 June
This aligns with our earlier visual
inspection of the
diﬀerential ﬁle type metrics presented in Table I.
suspicious
suspicious
least
the
as
to
Note than these attack models are scalable irrespective
i.e. when a new tactic is
of the underlying CMS,
identiﬁed, the TARDIS framework is designed to be
highly modularized and can be easily updated to capture
the essence of the new tactic and the attack label
associated with it. Essentially, applying the attack
modeling rules to spatial metrics and incrementally
sliding along each temporal snapshot enables TARDIS
to assign appropriate labels L along the compromise
window, thus providing a timeline of the events as part
of the long-lived multi-stage attack investigation.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:40:22 UTC from IEEE Xplore.  Restrictions apply. 
1162
IV. Validating our Intuition
had
as
This
identiﬁed
In order
CodeGuard
research began with the key insight
that
CMS-targeting cyber attacks exhibit the “low and slow”
characteristics indicative of multi-stage attacks. Based on
this, we designed TARDIS to recover the compromise
window and reconstruct the attack timeline. We now
perform several micro-benchmarks with a ground truth
set of websites to validate this intuition.
Data Set and Ground Truth. Our preliminary study
in §II looked at the nightly backups of 70 CMS websites
which
recently
compromised. We manually investigated these websites
and labeled the observed attack models. We will use
these 70 websites again here as ground truth. To these 70
websites, we added the full history of nightly backups
from 93 additional CMS websites, selected randomly
from our collaborator’s data. Again, we performed a
manual investigation of these 93 new websites to obtain
ground truth (discussed below). This yielded a total of
163 websites, each of which represents backups collected
nightly during a 13-month period between April 2018
and May 2019.
to validate TARDIS’s performance, we
manually investigated the 163 websites to obtain ground
truth. We ﬁrst installed a clean version of the CMS
locally and removed any ﬁle which had not been
modiﬁed for each snapshot. We then searched all the
code ﬁles
for malware payloads and conﬁrmed our
ﬁndings with CodeGuard engineers. If our investigation
found an attack, we labeled the snapshot when the
attack ﬁrst appeared. If the attack was cleaned up via a
rollback, we labeled the corresponding snapshot. We then
annotated the expected attack labels for every snapshot
within that compromise window. From our 163 websites,
80 were found to be compromised. We note that this is
biased
of which were
known-compromised) but still provides a varied test suite
of benign and malicious cases.
We identiﬁed the CMS platform used by each website
using WhatCMS [30] and CMS Garden [31]. The CMS
market share distribution in this dataset is shown in
Table IV. The distribution is roughly similar to the
real-world distribution of CMS-based websites, e.g., a
majority of websites are built on WordPress with Drupal
and Joomla a close second and third.
A. Identiﬁcation of Attack Models
original
70
(all
by
the
We then drilled down into the websites identiﬁed as
compromised. To validate TARDIS’s attack timeline
reconstruction capability, we ﬁrst ran each website’s
sequence of backups through TARDIS and recorded
what attack labels were assigned to each nightly
snapshot. Note that TARDIS did not have nor need
access to our ground truth for investigating the website
backups, and it relied only on the temporal correlation of
spatial metrics and attack models for timeline extraction.
TABLE IV: Distribution of Compromises
Evaluation Dataset of 163 Websites.
in the
TARDIS 3
# of
1
1
0
0
0
1
0
0
0
3
0
0
0
0
0
0
0
0
0
0
92
23
17
9
2
8
4
3
5
163
#TP4 #FP5 #FN6
websites1 #GT2
47
15
10
2
0
3
1
0
2
80
CMS
WordPress
Drupal
Joomla
PivotX
Prestastop
TYPO3 CMS
Bourbon
Contao
Contenido
Total
1: Total number of websites evaluated for each CMS.
2: Total number of compromised websites (Groud Truth)
3: Total number of websites ﬂagged as compromised by TARDIS.
4: True Positive, 5: False Positive, 6: False Negative.
We then compared the TARDIS output attack labels
with our manually derived ground truth.
47
15
10
2
0
3
1
0
2
80
Table V presents the micro-benchmark results for the
163 websites. The CMS platform is listed in Column 1.
For each CMS platform, the subsequent pairs of columns
show the number of websites which TARDIS marked as
containing each attack label (denoted by #) and the
number of those labels which were false positive cases
(denoted by #FP), i.e. our derived ground truth for that
website does not contain that attack label. For example,
Row 3 of Table V shows TARDIS labeled obfuscated
code injection in 8 Joomla-based websites and 1 of them
is an FP. Note also that any attack labels detected in
known clean websites were marked as FPs.
From Table V, we make several observations: Taken
individually, TARDIS’s attack models detect the attack
labels within compromised websites with high accuracy.