Our analysis begins by examining the general characteristics of
cellular and WiFi performance in each of the target metro areas.
These characteristics can be found in Tables 3, 4, and 5. The side-
by-side comparison shows that WiFi provides better maximum and
average performance for nearly all regions for upload and down-
load performance and latency. One regional exception is Columbia,
SC, which has a number of very high throughput cellular tests that
cause the average and 95th percentile to be higher than WiFi. These
tests are all from devices using the 4G LTE cell access technology,
which has substantially higher throughput than some older access
technologies. The tables also show that the difference in upload
performance between WiFi and cell is much smaller than the dif-
ference in download performance.
In Figure 3 we show scatterplots of upload versus download per-
formance for cell (left) and Wiﬁ (right) for the Madison, WI metro
area. Each data point is computed as the 95th percentile value for
a given handset. These plots are representative of other metro ar-
eas. First, as with Tables 3 and 4, WiFi performance is generally
higher than cell. We note that the highest cellular throughputs are
for the LTE access technology. We also observe that for WiFi ac-
cess, there are more obvious “tiered” performance bands evident,
especially for AS7132 (AT&T) and AS20115 (Charter), than for
the cellular access networks. Note that Figure 3 is annotated to
point out some of these evident performance tiers in the upload di-
rection. For WiFi networks, these bands likely represent different
service plans available to customers. With cellular networks, there
are not typically service plan limits on throughputs, but rather on
total numbers of bytes transferred. Thus, the bands present in the
cellular plot (around 600 kb/s upload, and just over 1 Mb/s upload,
for UMTS and HSDPA) are more likely due to different modula-
tion rates in the cellular access. We observe in the plot that the
performance bands are most evident in the upload direction; es-
pecially for WiFi, there are no obvious download throughput tiers.
We hypothesize that this difference is due to the typically asymmet-
ric conﬁguration of last-mile access technologies (e.g.,, Cable and
DSL), which makes it easier for the Speedtest application to satu-
rate the available upload capacity. Lastly, we hypothesize that as
higher speed cellular access technologies become more prevalent
(e.g., LTE), providers may need to impose service plan rate lim-
its similar to wired broadband access networks in order to better
manage access network congestion.
In order to evaluate whether there are any signiﬁcant perfor-
mance differences between Android-based and iOS-based devices,
we plot in the left plot of Figure 4 the median download for iOS de-
vices versus the median download for Android devices computed
for each local access carrier in each of the ﬁve metro area types.
The right-hand plot shows median latency for iOS devices versus
median latency for Android devices, again computed for each local
access carrier. The plots are created from WiFi measurements only;
Table 5: Latency for cell and WiFi from the 15 target metro areas for full 15 week period. All values are in milliseconds.
Location
New York, NY
Los Angeles, CA
Chicago, IL
Columbia, SC
Syracuse, NY
Madison, WI
Jackson, TN
Lawrence, KS
Missoula, MT
Manchester, UK
Brussels, BE
Belgrade, SP
Palembang, ID
Almaty, KZ
Ulaanbaatar, MN
Cell Mean (Stdev) WiFi Mean (Stdev)
111.9 (261.8)
120.5 (314.4)
96.1 (227.1)
187.7 (313.6)
131.2 (225.3)
119.9 (258.1)
168.2 (309.4)
177.3 (286.0)
190.3 (241.1)
129.7 (265.6)
103.8 (242.1)
113.5 (379.0)
371.7 (1144.5)
141.3 (405.0)
239.3 (824.6)
282.0 (575.9)
268.0 (354.2)
178.5 (318.9)
252.2 (316.8)
238.9 (199.0)
262.3 (267.8)
339.1 (363.9)
323.5 (351.6)
360.3 (247.2)
335.2 (491.4)
281.6 (321.7)
329.4 (475.7)
583.8 (1334.4)
356.7 (663.3)
649.4 (1935.9)
Cell 5th% Cell Median
159.0
165.0
122.0
183.0
171.0
184.0
226.0
250.0
314.0
221.0
203.0
226.0
348.0
194.0
216.0
68.0
67.0
63.0
102.0
115.0
99.0
116.0
95.0
165.0
98.0
84.0
79.0
148.0
90.0
76.0
Cell 95th% WiFi 5th% WiFi Median WiFi 95th%
336.0
350.0
255.0
456.0
358.0
343.0
412.0
470.0
412.0
313.0
238.0
318.0
917.0
364.0
862.0
786.0
776.0
429.0
736.0
558.0
773.0
858.0
778.0
687.0
912.0
755.0
842.0
1095.0
1114.0
1990.0
21.0
24.0
22.0
55.0
29.0
24.0
23.0
30.0
47.0
34.0
28.0
22.0
62.0
27.0
17.0
54.0
64.0
53.0
120.0
73.0
69.0
107.0
113.0
115.0
92.0
67.0
52.0
179.0
77.0
67.0
Figure 3: Scatterplots of upload versus download performance for cellular (left) and WiFi (right) for the Madison, Wisconsin metro
area. Data points represent 95th percentile for a given handset. Points are colored based on service provider. and marker shapes are
different for each access technology.
we do not show results for cellular tests due to the lack of detailed
access technology information for iOS devices (we only know it is
cellular, not what speciﬁc ﬂavor). Interestingly, while throughput
does not appear to be affected by OS version (the upload plot re-
sults are similar to the download plot shown), iOS appears to induce
consistently higher latency measurements than Android. Since the
same organization (Ookla) designed the app for each OS, we con-
clude that iOS either introduces signiﬁcantly more buffering of net-
work data, or its APIs are not optimized to deliver low packet-level
latency.
Turning to a broader view of latency performance, we see in Ta-
ble 5 a vast difference between cell and WiFi performance. Cell
latencies are generally longer than WiFi, with mean cell latencies
approaching or exceeding a third of a second in many cases, and
very large 95th percentile latencies in all metro areas. Even the me-
dian cell latency is at least twice as large as WiFi latency for nearly
all regions we consider (Columbia, SC is the only exception). Re-
call that for each server, we only consider tests carried out within a
100 km radius.
To examine the latency issue further, we plot in Figure 5 empir-
ical cumulative distribution functions for WiFi connections and for
speciﬁc cellular access technologies, for providers from which we
see the most tests. The ﬁgure shows results for a large metro area
(Chicago, IL) and a much smaller metro area (Lawrence, KS). First,
we see that latencies for the larger Chicago market are generally
smaller than for the Lawrence market. Indeed, for other metro ar-
eas, the trend is clearly toward shorter latencies for large cities and
longer latencies for smaller cities. These results thus suggest that
service providers expend more effort to engineer their networks for
good performance in larger markets than smaller ones. We also see
that speciﬁc latency distributions are highly provider dependent:
for the Chicago plot, we see that the two curves showing WiFi
latency distributions are highly dissimilar: one provider delivers
quite low latencies, while another gives some of the worst latencies
observed overall. We also observe that the latency proﬁles for all
access types offered by a given provider often have similar charac-
teristics. This is especially true for the Lawrence, KS plot, but also
clearly evident in other metro areas (not shown). In other analyses
(also not shown), we did not ﬁnd any meaningful correlation be-
tween latency and distance to the server. This lack of correlation is
likely due to packets traversing cellular backhaul networks that are
possibly geographically far away from the local Speedtest server,
an issue that has been identiﬁed in prior work [18, 31].
Figure 4: Scatterplots of iOS versus Android download and latency performance for WiFi. The left plot shows median download
performance for iOS devices versus median download performance for Android devices, computed for each local access carrier in
each of the ﬁve metro area types. The right plot shows similar results but for latency (i.e., median latency of iOS devices versus
median latency of Android devices).
Figure 5: CDFs of latency for different access types; Chicago, IL (left) and Lawrence, KS (right).
4.1.2 Performance Consistency
We now examine consistency of performance results. We use
the method of Sundaresan et al. [33]: for each handset (user), we
construct cumulative distribution functions of normalized perfor-
mance, where the normalization is computed as the mean divided
by the 95th percentile. (For latency, instead of using the 95th per-
centile, we use the 5th percentile in the normalization computation.)
The motivation behind each of these normalizations is to identify
how far average measures deviate from good performance, where
good is deﬁned as the 95th percentile throughput and 5th percentile
latency. We produce separate CDFs for each local access provider
and for each access type. If throughputs are consistent, points along
each CDF curve should be close to 1; any points less than 1 repre-
sent degraded performance. Likewise, if latency is consistent, we
also expect to see points along each CDF curve to be close to 1.
However, any deviations from good latency will result in normal-
ized values higher than 1 (i.e., inﬂated latencies). For each of the
plots below, we only consider users for which we had at least 5 tests
from which to compute a consistency measure; all other users’ data
are discarded. The authors of [33] found that download and upload
performance for wired broadband access networks exhibited high
consistency, except for a small number of service providers.
In Figure 6 we plot download (left), upload (center), and la-
tency (right) performance consistency for Los Angeles (top) and
Belgrade (bottom). Plots shown are representative of other metro
areas. We observe in these plots a low degree of performance con-
Figure 6: Performance consistency for Los Angeles (left) and Belgrade (right) for download (top), upload (middle), and latency
(bottom). Plots shown are representative of other metro areas.
[33].
sistency, especially compared with the results of
In their
work, nearly all curves were very close to 1, representing highly
consistent performance (the one exception was the Cable provider
Charter). Our results are exclusively generated from wireless tests,
and reveal that mobile users generally have to cope with much more
variable performance than users on wired networks. In Figure 6, we
also observe that WiFi upload/download performance is generally
more consistent than cell upload/download, though it depends on
the local access provider. Furthermore, in many cases, we see sim-
ilar performance consistency characteristics for the various access
technologies that a given service provider supports in a metro area
(c.f. Figure 5). We hypothesize from these similarities that some
providers use the same network “backhaul” infrastructure for both
cellular and WiFi access in an effort to optimize their network in-
frastructures to minimize costs. Therefore, our hypothesis assumes
that a shared bottleneck in the provider network is the cause of
the observed similarity in performance consistency between cellu-
lar and WiFi. We intend to examine this hypothesis in detail in
future work.
Interestingly, we observe that while LTE offers high absolute
throughput performance, its upload performance consistency is poor.
For example, in the Los Angeles upload consistency plot (top mid-
dle) in Figure 6, we see that LTE’s performance consistency is
lower than many other access types. Other metro areas show simi-
lar characteristics. We hypothesize that the cause for this behavior
is simply that service providers have not yet optimized LTE instal-
lations, and have rather focused on getting services initially rolled
out.
With respect to latency performance consistency, we see that
while WiFi offers generally higher absolute throughputs and more
consistent throughput, cellular latency is generally more consistent.
In the case of Los Angeles (top right plot), except for one service
provider that delivers poor performance consistency for most ac-
cess types it offers (AS21928), WiFi latencies exhibit a lower de-
gree of consistency than cellular access types. Similarly, for the
Belgrade plot (lower right), 2 of the 4 least consistent access tech-
nologies are WiFi. We hypothesize that this lower degree of per-
formance consistency is due to the effect of overbuffering at ac-
cess routers. Many access routers are well known to exhibit la-
tency pathologies due to overprovisioning of buffers [21, 33], and
it is likely that user WiFi access is often through a home-grade
router connected to a wired broadband connection. Another pos-
sibility for the lower degree of performance consistency in WiFi
is higher contention for WiFi frequency bands, and differences be-
tween WiFi and cellular medium access control. However, since
we observe the same pattern of lower consistency in WiFi across
all metro areas—even the most sparsely populated ones where we
would not expect the effect of contention to be signiﬁcant—we be-
lieve that overbuffering is the more likely cause.
Lastly, we note that in different metro areas, there are clear in-
stances of some service providers exhibiting generally poor perfor-
mance consistency for all offered services. For example, AS21928
in Los Angeles, and to a lesser extent, AS8400 in Belgrade. This
observation further supports the notion that performance for vari-
ous access technologies offered by a given service provider exhibit
similar qualities due to using the same backhaul infrastructure.
Main ﬁndings.
Absolute WiFi performance is better than cellular access, in gen-
eral. Throughput performance does not appear to be correlated with
operating system (iOS or Android), however latency measurements
are generally higher with iOS devices, suggesting too much buffer-
ing or APIs that are suboptimally designed. Performance consis-
tency of WiFi throughput is generally better than cellular, but cel-
lular latency performance tends to be more consistent than WiFi.
Lower consistency of WiFi latency is likely due to the impact of
overbuffering at broadband access routers. Local providers exhibit
similar performance consistency characteristics for all offered ac-
cess types, suggesting that providers use the same backhaul infras-
tructure to support various last-mile access methods. Performance
consistency for wireless access is markedly lower than has been re-