deviation in the distribution of magnitudes in dSSIM Ls,
and optimal value of φc can be determined empirically.
The effect of different φa, φb, and φc values on keystroke
detection is presented in Section VII-A. Appropriately chosen
values of φa, φb, and φc would ideally eliminate false positives
related to frequently occurring minor body movements that are
closer to the mean value (µdSSIM Ls ), and can be otherwise
regarded as noise. Similarly, appropriately chosen values of
φa, φb, and φc will also eliminate false positives related
to infrequently occurring major body movement that are far
away from the mean value (µdSSIM Ls ), and can be otherwise
regarded as outliers.
Typing Activity Detection. As the target user may type at
speciﬁc instance(s) in time during the video call, it is necessary
for the adversary to detect the time periods (or windows) where
typing activity occurred. Typing activity detection is especially
needed to effectively eliminate false positives during keystroke
detection, which could otherwise result
in incorrect word
prediction results. We next outline a heuristic-based typing
activity detection technique which employs our individual
keystroke detection algorithm (Algorithm 1).
As outlined earlier, Algorithm 1 returns a set of frames
5
-0.04-0.03-0.02-0.0100.010.020.03338343347351356360365369373379dSSIM ScoredSSIM indexKeystroke Events for the Word “tend“Left HandRight HandFig. 3: Overview of the typing activity detection technique.
the number of keystrokes detected for a word, and the hand
(left/right) which was used to conduct individual keystrokes
of the word. Let us call this information as keystroke infor-
mation. The second group of information is the magnitude
and direction of body displacement, more speciﬁcally the arm
displacement, between consecutive keystrokes of the word.
Assuming that the target user typed on a standard QWERTY
keyboard, mapping the arm displacement between consecutive
keystrokes to relative position of the keys can signiﬁcantly
improve the inference accuracy. Let us call this information as
displacement information. After executing the typing activity
detection (utilizing Algorithm 1) the adversary already has
knowledge of the keystroke information – all the frame seg-
ments in which a keystroke was detected, separately for each
hand. However, the displacement information is not readily
available, and will require us to employ advanced computer
vision techniques to effectively measure arm displacement
between consecutive keystrokes.
Let keystrokesF SL denote the list of all detected left-
hand keystroke frame segments and keystrokesF SR de-
note the list of the right-hand keystroke frame segments.
keystrokesF SL and keystrokesF SR essentially constitute
the keystroke information. We now describe how to utilize
these two lists (keystrokesF SL and keystrokesF SR) to
derive the displacement information. In brief, we (i) identify
the outer contour of individual arms in each keystroke frame
segment, (ii) calculate the displacement of individual arms by
tracking change in position of the outer edge of the arms
across consecutive keystroke frame segments, and (iii) interpret
calculated arm displacements with respect to the QWERTY
keyboard layout. After obtaining the displacement information,
we describe how the adversary can utilize both the keystroke
and displacement information to carry out word predictions
using a dictionary or reference database.
Outer Edge Detection of Arms. In order to efﬁciently
measure arm displacement between consecutive keystrokes, we
focus on speciﬁc regions of the keystroke frame segments.
Instead of trying to analyze movement of all pixels between
two keystroke frame segments, we focus on pixels covering the
outer-edge movements of the arms (Figure 4a). The intuitive
reasoning behind this design decision is that the characteristics
of outer-edge movements are reﬂective of the movement of the
entire upper arm and shoulder. Let us label the subset of pixels
in a keystroke frame segment covering the outer contour/edge
of the body as the outer contour, or OC. To compute the
outer contour in each of the keystroke frame segments, we
ﬁrst detect all edges in a keystroke frame segment using Canny
edge detection technique [30]. As the background in the frame
6
(a)
(b)
(c)
(d)
(e)
Fig. 4: (a) A keystroke frame segment, (b) Outer contour
(OC), (c) 45° projection from pα that intersects OC at pβ,
(d) Shoulder contour (SC), and (e) Arm contour (AC).
segment is already removed during the keystroke detection step
(Section V-C), outer edges of the arm and shoulder are easily
captured by the edge detection process. However, there is a
possibility that edges within the arm and shoulder areas, such
as creases or patterns on a shirt, could also get detected as
an edge. To overcome this issue, we device a straightforward
approach to remove all additional edges (i.e., all edges except
the outer edge of the arm and shoulder), as described below.
In case of the left hand, for each row of pixels we keep the
rightmost pixel in the edge-detected frame segment that is part
of an edge. The intuition is that in the absence of a background,
the rightmost pixel in each row has to be part of the outer
contour. Similarly, in case of the right hand, for each row of
pixels we keep the leftmost pixel in the edge-detected frame
segment that is part of an edge. An example of outer contour
can be seen in (Figure 4b).
After the outer contour is computed for every keystroke
frame segment in keystrokesF SL and keystrokesF SR, we
next segment the outer contour into shoulder contour (SC) and
arm contour (AC) based on human physiology (Figure 16a).
This physiology-based division is approximated by drawing a
projection from the pixel nearest to the neck (pα) such that
the angle between this projection and the vertical boundary of
the frame segment is 45° (Figure 4c). Let pβ be the pixel
where this projection intersects the outer contour, and pγ
be the pixel farthest from the neck in the outer contour.
Pixels in the outer contour between pα and pβ becomes the
shoulder contour, and pixels in the outer contour between
pβ and pγ becomes the arm contour. Obviously, this is just
an approximate computation of shoulder and arm contours
as the underlying physiological differences between person to
person cannot be accurately modeled using available webcam
video data. Figure 4d and Figure 4e shows shoulder and arm
contours, respectively, computed for the outer contour example
mentioned earlier. While the arm contours are directly useful
in displacement calculations, explained next, shoulder contours
are also utilized for calibrating the displacement calculations.
Displacement Calculations. We employ sparse optical ﬂow
technique [45] to quantify hand displacements between con-
secutive keystrokes. Sparse optical ﬂow is a computer vision
technique that takes a set of pixels (for example, constituting
an object) within an image as input, and outputs a vector
set representing the displacement of those pixels (and thus
the object) in another image. Sparse optical ﬂow is especially
useful to track object movements across chronological frames
of a video. In our framework, we apply sparse optical ﬂow
Algorithm 1Algorithm 1Potential Keystroke ExtractionTyping-related FilteringLeft Predicted Typing- related KeystrokesMaximum Speed FilterLocation FilterHand DetectionRemovalAll Left Arm Frames Potential  KeystrokesAll Right Arm Frames Potential  KeystrokesExclusive FilterMinimum Speed FilterRight Predicted Typing- related Keystrokespαpγpβ45°pβpαpγpβi and Ls
to track the displacement of shoulder and arm contours across
all consecutive keystroke frame segments, individually for each
hand. For simplicity, we use the left hand to explain the use of
sparse optical ﬂow on two consecutive keystroke frame seg-
ments (∈ keystrokesF SL), say Ls
i+1, with respective
arm contours ACi and ACi+1. By applying sparse optical ﬂow
between ACi and ACi+1, we obtain a set of displacement
vectors representing the direction and magnitude of how each
pixel in ACi has shifted in ACi+1. We then use this set of
displacement vectors to calculate a mean displacement vector
for the arm contour, and let us call it −→oai. Calculated in a
similar fashion, let us call the mean displacement vector for
the shoulder contour as −→osi. In summary, a −→os represents
the average movement of the shoulder between consecutive
keystrokes, whereas a −→oa represents the average movement of
the hand between consecutive keystrokes.
Our objective behind computing −→os and −→oa is to use these
displacement vectors to determine the relative position of the
keys corresponding to keystrokes. We carry out two additional
operations using the displacement vectors −→oa and −→os in order
to make our inference framework more generalizable. First,
we observed that in certain scenarios the camera itself may
move slightly, in addition to the arm. This can be prominently
observed in the case of a laptop webcam, where a press on
the laptop keyboard can result in a noticeable motion of the
webcam which is generally located on top of the display. We
solve this by applying sparse optical ﬂow on the background
during the pre-processing (Section V-B), and negating the
−→
ob) from −→oa and
mean displacement vector of the background (
−→os. Second, we observed that in certain instances the typer
changes her/his posture in between consecutive keystrokes,
for example due to fatigue. To address this, we utilize the
shoulder displacement (−→os) as an approximation of posture
changes, and subtract it from −→oa. Combining both of these
operations, we obtain −→om = −→oa−−→os−−→
ob, where −→om represents
the approximate average arm displacement, free of inﬂuence
from posture or camera movements, that happened between
consecutive keystrokes.
Interpreting Calculated Arm Displacements. From our
keystroke detection (Section V-C), we are already aware of
which hand was used to type individual letters. While this
information alone can be very useful in conducting dictionary-
based predictions, we deploy the arm displacement vector (−→om)
computed now to further reduce the search space. Reduction
in the search space will in turn make our predictions more
accurate. Between any two consecutive keystrokes using the
same hand, we classify the corresponding −−→omi into one of
the four intercardinal directions: northeast (N E), northwest
(N W ), southeast (SE), southwest (SW ). The classiﬁcation
of a left hand −−→omi is conducted as per conditions listed in
−−−−→
omi(y) are
Table I (Appendix F). In Table I,
the x-axis and y-axis displacements (i.e., vector components),
respectively, measured in pixels. The classiﬁcation is isomor-
phic in case of right arm displacements between keystrokes,
as listed in Table II (Appendix F).
Template Inter-keystroke Directions. Now, we deﬁne tem-
plate inter-keystroke directions on the standard QWERTY
keyboard, which are the ideal directions a typer’s hand should
follow. To deﬁne the template inter-keystroke directions, we
ﬁrst divide the QWERTY keyboard into two halves (left
−−−−→
omi(x) and
and right). The left side of the keyboard contains the letters
{q, w, e, r, t, a, s, d, f, g, z, x, c, v, b} while the right side of the
keyboard contains the letters {y, u, i, o, p, h, j, k, l, n, m} as
shown in Figure 21 (Appendix F). Similar to prior works
that used an analogous modeling [39], [36], we assume that
a typer will predominantly type keys on the left side of the
keyboard using her/his left hand, and vice versa. However,
every key on the keyboard occupies a rectangular area, and
a typer can have some variance in the position within each
key where it is pressed. Some keys may be pressed in the
center, while others could be pressed around the edges. This
naturally occurring variance lead us to model the template
inter-keystroke directions more ﬂexibly using nine possible
scenarios between any two keys keyi and keyj, as detailed
in Table III (Appendix F) and exempliﬁed in Figure 21
(Appendix F).
Word Inference. Our word prediction is a dictionary-based
search for words based on (i) matching the order and number
of left and right handed keystrokes, and (ii) matching the
calculated direction of arm displacements with the template
inter-keystroke directions. To satisfy the ﬁrst criterion, a wordi
in the dictionary is deemed as a candidate for the typed word
if keystrokesF SL and keystrokesF SR contain a combined
number of keystroke frame segments equal to the length of
wordi. The keystroke frame segments in keystrokesF SL and
keystrokesF SR should also be chronologically interleaved
according to the alphabets in the left and right sides of the
keyboard (Figure 21). To satisfy the second criterion, a wordi
in the dictionary is deemed as a candidate if the calculated
arm displacements −−→omj between every letter of the wordi
satisﬁes the template mappings outlined in Table III. We also
sort the dictionary based on how frequently its words are used
in the English literature (in descending order), so as to improve
inference accuracy when there exists multiple candidate words
that satisfy the above two criteria. In addition to the top
prediction (i.e., the candidate word with the most usage in
English literature), we also evaluate if the typed word is con-
tained in top-k of such candidate words, as an adversary can
run additional semantical and contextual analyses to improve
inference of complete sentences. We, however, limit the scope
of this work to only word inferences. We next outline details
of the different experimental setups and evaluation experiments
that we conduct to evaluate our keystroke detection and word
prediction framework. Our ﬁrst set of evaluation experiments
are conducted in a slightly constrained (or “In-Lab”) setting
to analyze the best-case performance of our framework. Our
second set of experiments are conducted in a fully unrestricted
(or “At-Home”) setting to analyze the worst-case performance
of our framework. All our participant recruitment and data
collection experiments were approved by our university’s In-
stitutional Review Board (IRB).
VI.
IN-LAB EXPERIMENTAL SETUP
Our ﬁrst set of evaluation experiments were conducted by
ﬁxing the video call setup, including, the device(s) used for the
calls and participants’ sitting position during the call, and text
typed by the participants. For this set of experiments, which we
refer as In-Lab setup, we recruited a diverse set of 20 human
subject participants and collected video call data while they
were performing typing tasks, details of which are outlined
below.
7
Participant Demographics. Out of the 20 participants re-
cruited for this setting, 9 are females and 11 are males.
Based on a screening-survey, 4 participants conducted hunt-
and-peck typing, 5 conducted touch typing, and the remaining
11 participants conducted hybrid typing. One of the partici-
pants identiﬁed as being left-handed while the remaining 19
participants identiﬁed themselves as right-handed.
Participant Tasks. Each participant completed six different
sessions across different experimental parameters, which are
listed below. Each session was conducted on a different day.
Before every session, the experimental parameters were chosen
randomly to cover different combinations, and the participant
was informed about those parameters beforehand. The data
collection sessions were conducted in a controlled setting
inside a private ofﬁce, primarily to limit noise in the audio
data collected for equitable comparison (with an audio-only
framework by Compagno et al. [29]). The participants were
positioned in front of a computer with a display, keyboard, and
a webcam directly facing them. Each participant was shown
a random word on-screen in large font and the participant
was instructed to naturally type the displayed word followed
by a blank space. Upon entry of blank space, a new random
word replaced the previous word on-screen, and the participant
repeated this process for 300 words in each session. The
random words were picked from a dictionary of 4000 most
frequently used words (of 4 or more letters) in the English
literature [14]. In order to minimize the impact of fatigue while
typing, each session was divided in to three sub-sessions, each
consisting of 100 words. Participants were encouraged to take
a break between each of the sub-sessions.
It should be noted
that, despite the ﬁxed nature of the In-Lab setup, participants
were free to change their body posture and position based on
their need and comfort-level, both during and in-between the
typing sub-sessions.
Data Collected. On the data collection computer, our cus-
tom application recorded the webcam video (at 1920 × 1080
pixels), microphone audio (at 44.1 kHz) and time-stamped
ground-truth of the keys (characters) typed by the participant.
The ground-truth information is used to measure the accuracy
of our framework. To obtain realistic results, we later transmit-
ted the recorded video over the Internet through different video
calling software and captured it remotely on another computer.
Skype [10] was used for majority of the evaluation, but we also
compare it with Hangouts [5] and Zoom [17] in Section VII-B.