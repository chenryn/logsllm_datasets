taint tracking-based tools are unable to solve these constraints.
In purely symbolic execution-based approaches, this leads to
a massive state explosion.
2.4 Coverage-guided Grammar Fuzzing
Beside the problem of multi-byte magic values, there is an-
other issue which leads to large gaps between interesting
1988    28th USENIX Security Symposium
USENIX Association
Figure 2: The process of tracing a path in a program and introducing new bits and bytes in the global coverage map.
parts of the state space: programs with structured input lan-
guages. Examples for such programs are interpreters, com-
pilers, databases and text-based Internet protocols. As men-
tioned earlier, current mutational blind and coverage-guided
as well as hybrid fuzzers cannot efﬁciently fuzz programs
with structured input languages. To overcome this issue, gen-
erational fuzzers (whether blind, coverage-guided or hybrid)
use a speciﬁcation of the input language (often referred to as
a grammar) to generate valid inputs. Thereby, they reduce the
space of possible inputs to a subset that is much more likely
to trigger interesting states. Additionally, coverage-guided
grammar fuzzers can mutate inputs in this reduced subset by
using the provided grammar. We call these mutations large-
scale mutations since they modify large part of the input. This
behavior is illustrated in Figure 1(d).
Therefore, the performance of fuzzers can be increased
drastically by providing format speciﬁcations to the fuzzer, as
implemented in NAUTILUS [2] and AFLSMART [48]. These
speciﬁcations let the fuzzer spend more time exercising code
paths deep in the target application. Particularly, the fuzzer
is able to sensibly recombine inputs that trigger interesting
features in a way that has a good chance of triggering more
interesting behaviors.
Grammar fuzzers suffer from two major drawbacks. First,
they require human effort to provide precise format speciﬁca-
tion. Second, if the speciﬁcation is incomplete or inaccurate,
the fuzzer lacks the capability to address these shortcomings.
One can overcome these two drawbacks by automatically
inferring the speciﬁcation (grammar).
2.5 Grammar Inference
Due to the impact of grammars on software testing, vari-
ous approaches have been developed that automatically can
generate input grammars for target programs. Bastani et
al. [5] introduced GLADE, which uses a modiﬁed version of
the target as a black-box oracle that tests if a given input is
syntactically valid. GLADE turns valid inputs into regular
expressions that generate (mostly) valid inputs. Then, these
regular expressions are turned into full grammars by trying
to introduce recursive replacement rules. In each step, the va-
lidity of the resulting grammar is tested using multiple oracle
queries. This approach has three signiﬁcant drawbacks: First,
the inference process takes multiple hours for complex targets
such as scripting languages. Second, the user needs to provide
an automated testing oracle, which might not be trivial to pro-
duce. Third, in the context of fuzzing, the resulting grammars
are not well suited for fuzzing as our evaluation shows (see
Section 5.4 for details). Additionally, this approach requires
a pre-processing step before fuzzing starts in order to infer a
grammar from the input corpus.
Other approaches use the target application directly and
thus avoid the need to create an oracle. AUTOGRAM [34],
for instance, uses the original program and taint tracking to
infer grammars. It assumes that the functions that are called
during parsing reﬂect the non-terminals of the intended gram-
mar. Therefore, it does not work for recursive descent parsers.
PYGMALION [25] is based on simpliﬁed symbolic execution
of Python code to avoid the dependency on a set of good in-
puts. Similar to AUTOGRAM, PYGMALION assumes that the
function call stack contains relevant information to identify
recursive rules in the grammar. This approach works well for
hand-written, recursive descent parsers; however, it will have
severe difﬁculties with parsers generated by parser genera-
tors. These parsers are typically implemented as table-driven
automatons and do not use function calls at all. Addition-
ally, robust symbolic execution and taint tracking are still
challenging for binary-only targets.
USENIX Association
28th USENIX Security Symposium    1989
2.6 Shortcomings of Existing Approaches
To summarize, current automated software testing approaches
have the following disadvantages when used for fuzzing of
programs that accept structured input languages:
• Needs Human Assistance. Some techniques require
human assistance to function properly. Either in terms
of providing information or in terms of modifying the
target program.
• Requires Source Code. Some fuzzing techniques re-
quire access to source code. This puts them at a disad-
vantage as they cannot be applied to proprietary software
in binary format.
• Requires a Precise Environment Model. Techniques
based on formal reasoning such as symbolic/concolic
execution as well as taint tracking require precise seman-
tics of the underlying platform as well as semantics of
all used Operating System (OS) features (e. g., syscalls).
• Requires a Good Corpus. Many techniques only work
if the seed corpus already contains most features of the
input language.
• Requires a Format Speciﬁcation. Similarly, many
techniques described in this section require precise for-
mat speciﬁcations for structured input languages.
• Limited To Certain Types of Parsers. Some ap-
proaches make strong assumptions about the underlying
implementation of the parser. Notably, some approaches
are unable to deal with parses generated by common
parser generators such as GNU Bison [15] or Yacc [37].
• Provides Only Small-scale Mutations. As discussed
in this section, various approaches cannot provide muta-
tions that cross large gaps in the program space.
Table 1: Requirements and limitations of different fuzzers and inference
tools when used for fuzzing structured input languages. If a shortcoming
applies to a tool, it is denoted with , otherwise with .
H
C
A
E
P
L
F
A
N
E
E
U
Q
D
E
R
M
Y
S
Q
A
R
O
G
N
A
S
U
L
I
T
U
A
N
T
R
A
M
S
L
F
A
E
D
A
L
G
M
A
R
G
O
T
U
A
N
O
I
L
A
M
G
Y
P
E
R
I
O
M
I
R
G
human assistance
source code
environment model
good corpus
format speciﬁcations
certain parsers
small-scale mutations

     
    
   
      
     
  
 
 
  
    
   
    


        

 
      



We analyzed existing fuzzing methods, the results of this
survey are shown in Table 1. We found that all current ap-
proaches have at least one shortcoming for fuzzing programs
with highly structured inputs. In the next section, we propose
a design that avoids all the mentioned drawbacks.
3 Design
Based on the challenges identiﬁed above, we now introduce
the design of GRIMOIRE, a fully automated approach that syn-
thesizes the target’s structured input language during fuzzing.
Furthermore, we present large-scale mutations that cross sig-
niﬁcant gaps in the program space. Note that none of the
limitations listed in Table 1 applies to our approach. To
emphasize, our design does not require any previous infor-
mation about the input structure. Instead, we learn an ad-hoc
speciﬁcation based on the program semantics and use it for
coverage-guided fuzzing.
We ﬁrst provide a high-level overview of GRIMOIRE, fol-
lowed by a detailed description. GRIMOIRE is based on
identifying and recombining fragments in inputs that trig-
ger new code coverage during a normal fuzzing session. It
is implemented as an additional fuzzing stage on top of a
coverage-guided fuzzer. In this stage, we strip every new
input (that is found by the fuzzer and produced new coverage)
by replacing those parts of the input that can be modiﬁed or
replaced without affecting the input’s new coverage by the
symbol (cid:3). This can be understood as a generalization, in
which we reduce inputs to the fragments that trigger new cov-
erage, while maintaining information about gaps or candidate
positions (denoted by (cid:3)). These gaps are later used to splice
in fragments from other inputs.
Example 2. Consider the input “if(x>1) then x=3 end”
and assume it was the ﬁrst input to trigger the coverage for
a syntactically correct if-statement as well as for “x>1”. We
can delete the substring “x=3” without affecting the interest-
ing new coverage since the if-statement remains syntactically
correct. Additionally, the space between the condition and the
“then” is not mandatory. Therefore, we obtain the generalized
input “if(x>1)(cid:3)then (cid:3)end”.
After a set of inputs was successfully generalized, frag-
ments from the generalized inputs are recombined to produce
new candidate inputs. We incorporate various different strate-
gies to combine existing fragments, learned tokens (a special
form of substrings) and strings from the binary in an auto-
mated manner.
Example 3. Assume we obtained the following general-
ized inputs: “if(x>1)(cid:3)then (cid:3)end” and “(cid:3)x=(cid:3)y+(cid:3)”.
We can use this information in many ways to generate
plausible recombinations. For example, starting with the
input “if(x>1)(cid:3)then (cid:3)end”, we can replace the sec-
ond gap with the second input, obtaining “if(x>1)(cid:3)then
(cid:3)x=(cid:3)y+(cid:3)end”. Afterwards, we choose the slice “(cid:3)y+(cid:3)”
from the second input and splice it into the fourth gap and
obtain “if(x>1)(cid:3)then (cid:3)x=(cid:3)y+(cid:3)y+(cid:3)end”. In a last step,
1990    28th USENIX Security Symposium
USENIX Association
we replace all remaining gaps by an empty string. Thus, the
ﬁnal input is “if(x>1)then x=y+y+end”.
One could think of our approach as a context-free gram-
mar with a single non-terminal input (cid:3) and all fragments of
generalized inputs as production rules. Using these loose,
grammar-like recombination methods in combination with
feedback-driven fuzzing, we are able to automatically learn
interesting structures.
Input Generalization
3.1
We try to generalize inputs that produced new coverage (e. g.,
inputs that introduced new bytes to the bitmap, cf. Sec-
tion 2.2). The generalization process (Algorithm 1) tries
to identify parts of the input that are irrelevant and fragments
that caused new coverage. In a ﬁrst step, we use a set of rules
to obtain fragment boundaries (Line 3). Consecutively, we
remove individual fragments (Line 4). After each step, we
check if the reduced input still triggers the same new coverage
bytes as the original input (Line 5). If this is the case, we
replace the fragment that was removed by a (cid:3) and keep the
reduced input (Line 6).
Algorithm 1: Generalizing an input through fragment
identiﬁcation.
Data: input is the input to generalize, new_bytes are the new
Result: A generalized version of input
bytes of the input, splitting_rule deﬁnes how to split an
input
1 start ← 0
2 while start ’ as well as single and double quotes. To guess differ-
ent nesting levels in between these pairs of opening/closing
characters, we extend Algorithm 1 as follows: If the current
index start matches an opening character, we search the
furthermost matching closing character, create a candidate
by removing the substring in between and check if it triggers
the same new coverage. We iteratively do this by choosing
the next furthermost closing character—effectively shrinking
the fragment size—until we ﬁnd a substring that can be re-
moved without changing the new_bytes or until we reach the
index start. In doing so, we are able to remove the largest
matching fragments from the input that are irrelevant for the
input’s new coverage.
Since we want to recombine (generalized) inputs to ﬁnd
new coverage—as we describe in the following section—we
store the original input as well as its generalization. Further-
more, we split the generalized input at every (cid:3) and store the
substrings (tokens) in a set; these tokens often are syntacti-
cally interesting fragments of the structured input language.
Example 5. We map the input “if(x>1) then x=3 end”
to its generalization “if(x>1)(cid:3)then (cid:3)end”. In addition,
we extract the tokens “if(x>1)”, “then ” and “end”. For
the generalized input “(cid:3)x=(cid:3)y+(cid:3)”, we remember the tokens
“x=” and “y+”.
Input Mutation
3.2
GRIMOIRE builds upon knowledge obtained from the gener-
alization stage to generate inputs that have good chances of
ﬁnding new coverage. For this, it recombines (fragments of)
generalized inputs, tokens and strings (stored in a dictionary)
that are automatically obtained from the data section of the
target’s binary. On a high level, we can divide our mutations
into three standalone operations: input extension, recursive
replacement and string replacement.
Given the current input from the fuzzing queue, we add
these mutations to the so-called havoc phase [3] as described
in Algorithm 2. First, we use Redqueen’s havoc_amount to
determine—based on the input’s performance—how often
we should apply the following mutations (in general, be-
tween 512 and 1024 times). First, if the input triggered
new bytes in the bitmap, we take its generalized form
and apply the large-scale mutations input_extension and
recursive_replacement. Afterwards, we take the original
input string (accessed by input.content()) and apply the
USENIX Association
28th USENIX Security Symposium    1991
Figure 3: A high-level overview of our mutations. Given an input, we apply
various mutations on its generalized and original form. Each mutation then
feeds mutated variants of the input to the fuzzer’s execution engine.
string_replacement mutation. This process is illustrated
in Figure 3.
Algorithm 2: High-level overview of the mutations
introduced in GRIMOIRE.
Data: input is the current input in the queue, generalized is the
set of all previously generalized inputs, tokens and strings
from the dictionary, strings is the provided dictionary
obtained from the binary
1 content ← input.content()
2 n ← havoc_amount(input.performance())
3 for i ← 0 to n do
4