title:Raccoon: Closing Digital Side-Channels through Obfuscated Execution
author:Ashay Rane and
Calvin Lin and
Mohit Tiwari
Raccoon: Closing Digital Side-Channels through 
Obfuscated Execution
Ashay Rane, Calvin Lin, and Mohit Tiwari, The University of Texas at Austin
https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/rane
This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-939133-11-3Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXRaccoon: Closing Digital Side-Channels through Obfuscated Execution
Ashay Rane, Calvin Lin
Department of Computer Science,
The University of Texas at Austin
{ashay,lin} @cs.utexas.edu
Mohit Tiwari
Dept. of Electrical and Computer Engineering
The University of Texas at Austin
PI:EMAIL
Abstract
Side-channel attacks monitor some aspect of a com-
puter system’s behavior to infer the values of secret data.
Numerous side-channels have been exploited, including
those that monitor caches, the branch predictor, and the
memory address bus. This paper presents a method of
defending against a broad class of side-channel attacks,
which we refer to as digital side-channel attacks. The
key idea is to obfuscate the program at the source code
level to provide the illusion that many extraneous pro-
gram paths are executed. This paper describes the techni-
cal issues involved in using this idea to provide conﬁden-
tiality while minimizing execution overhead. We argue
about the correctness and security of our compiler trans-
formations and demonstrate that our transformations are
safe in the context of a modern processor. Our empiri-
cal evaluation shows that our solution is 8.9× faster than
prior work (GhostRider [20]) that speciﬁcally defends
against memory trace-based side-channel attacks.
1
Introduction
It is difﬁcult to keep secrets during program execu-
tion. Even with powerful encryption, the values of secret
variables can be inferred through various side-channels,
which are mechanisms for observing the program’s exe-
cution at the level of the operating system, the instruction
set architecture, or the physical hardware. Side-channel
attacks have been used to break AES [26] and RSA [27]
encryption schemes, to break the Difﬁe-Hellman key ex-
change [15], to ﬁngerprint software libraries [46], and to
reverse-engineer commercial processors [18].
To understand side-channel attacks, consider the pseu-
docode in Figure 1, which is found in old implementa-
tions of both the encryption and decryption steps of RSA,
DSA, and other cryptographic systems.
In this func-
tion, s is the secret key, but because the Taken branch
is computationally more expensive than the Not Taken
if b = 1 then
z ← 1
for bit b in s from left to right do
1: function SQUARE AND MULTIPLY(m,s,n)
2:
3:
4:
5:
6:
7:
8:
9:
10: return z
11: end function
z ← m· z2 mod n
z ← z2 mod n
end if
end for
else
Figure 1: Source code to compute ms mod n.
branch, an adversary who can measure the time it takes
to execute an iteration of the loop can infer whether the
branch was Taken or Not Taken, thereby inferring the
value of s one bit at a time [31, 5]. This particular block
of code has also been attacked using side-channels in-
volving the cache [44], power [16], fault injection [3, 41],
branch predictor [1], electromagnetic radiation [11], and
sound [32].
Over the past ﬁve decades, numerous solutions [20,
30, 21, 42, 35, 22, 40, 14, 43, 37, 39, 38, 23, 45, 25, 34,
9, 33, 10] have been proposed for defending against side-
channel attacks. Unfortunately, these defenses provide
point solutions that leave the program open to other side-
channel attacks. Given the vast number of possible side-
channels, and given the high overhead that comes from
composing multiple solutions, we ideally would ﬁnd a
single solution that simultaneously closes a broad class
of side-channels.
In this paper, we introduce a technique that does just
this, as we focus on the class of digital side-channels,
which we deﬁne as side-channels that carry information
over discrete bits. These side-channels are visible to the
adversary at the level of both the program state and the
instruction set architecture (ISA). Thus, address traces,
cache usage, and data size are examples of digital side-
USENIX Association  
24th USENIX Security Symposium  431
channels, while power draw, electromagnetic radiation,
and heat are not.
Our key insight is that all digital side-channels emerge
from variations in program execution, so while other so-
lutions attempt to hide the symptoms—for example, by
normalizing the number of instructions along two paths
of a branch—we instead attack the root cause by execut-
ing extraneous program paths, which we refer to as de-
coy paths. Intuitively, after obfuscation, the adversary’s
view through any digital side-channel appears the same
as if the program were run many times with different in-
puts. Of course, we must ensure that our system records
the output of only the real path and not the decoy paths,
so our solution uses a transaction-like system to update
memory. On the real paths, each store operation ﬁrst
reads the old value of a memory location before writing
the new value, while the decoy paths read the old value
and write the same old value.
The only distinction between real and decoy paths lies
in the values written to memory: Decoy and real paths
will write different values, but unless an adversary can
break the data encryption, she cannot distinguish decoy
from real paths by monitoring digital side-channels. Our
solution does not defend against non-digital side-channel
attacks, because analog side-channels might reveal the
difference between the encrypted values that are stored.
For example, a decoy path might “increment” some vari-
able x multiple times, and an adversary who can precisely
monitor some non-digital side-channel, such as power-
draw, might be able to detect that the “increments” to x
all write the same value, thereby revealing that the code
belongs to a decoy path.
Nevertheless, our new approach offers several advan-
tages. First, it defends against almost all digital side-
channel attacks.1 Second, it does not require that the
programs themselves be secret, just the data. Third, it
obviates the need for special-purpose hardware. Thus,
standard processor features such as caches, branch pre-
dictors and prefetchers do not need to be disabled. Fi-
nally, in contrast with previous solutions for hiding spe-
ciﬁc side channels, it places few fundamental restrictions
on the set of supported language features.
This paper makes the following contributions:
1. We design a set of mechanisms, embodied in a
system that we call Raccoon,2 that closes digital
side-channels for programs executing on commod-
ity hardware. Raccoon works for both single- and
multi-threaded programs.
1Section 3 (Threat Model) clariﬁes the speciﬁc side-channels closed
by our approach.
2Raccoons are known for their clever ability to break their scent
trails to elude predators. Raccoons introduce spurious paths as they
climb and descend trees, jump into water, and create loops.
2. We evaluate the security aspects of these mecha-
nisms in several ways. First, we argue that the ob-
fuscated data- and control-ﬂows are correct and are
always kept secret. Second, we use information
ﬂows over inference rules to argue that Raccoon’s
own code does not leak information. Third, as an
example of Raccoon’s defense, we show that Rac-
coon protects against a simple but powerful side-
channel attack through the OS interface.
3. We evaluate the performance overhead of Raccoon
and ﬁnd that its overhead is 8.9× smaller than
that of GhostRider, which is the most similar prior
work [20].3 Unlike GhostRider, Raccoon defends
against a broad range of side-channel attacks and
places many fewer restrictions on the programming
language, on the set of applicable compiler opti-
mizations, and on the underlying hardware.
This paper is organized as follows. Section 2 describes
background and related work, and Section 3 describes
our assumed threat model. We then describe our solu-
tion in detail in Section 4 before presenting our security
evaluation and our performance evaluation in Sections 5
and 6, respectively. We discuss the implications of Rac-
coon’s design in Section 7, and we conclude in Section 8.
2 Background and Related Work
Side-channel attacks through the OS, the underlying
hardware, or the processor’s output pins have been a sub-
ject of vigorous research. Formulated as the “conﬁne-
ment problem” by Lampson in 1973 [19], such attacks
have become relevant for cloud infrastructures where the
adversary and victim VMs can be co-resident [29] and
also for settings where adversaries have physical access
to the processor-DRAM interface [46, 22].
Side-Channels through OS and Microarchitecture.
Some application-level information leaks are beyond the
application’s control, for example, an adversary reading
a victim’s secrets through the /proc ﬁlesystem [13], or a
victim’s ﬂoating point registers that are not cleared on a
context switch [2]. In addition to such explicit informa-
tion leaks, implicit ﬂows rely on contention for shared
resources, as observed by Wang and Lee [39] for cache
channels and extended by Hunger et al. [37] to all mi-
croarchitectural channels.
Defenses against such attacks either partition re-
sources [40, 14, 43, 37], add noise [39, 38, 23, 45], or
3GhostRider [20] was evaluated with non-optimized programs exe-
cuting on embedded CPUs, which results in an unrealistically low over-
head (∼10×). Our measurements instead use a modern CPU with an
aggressively optimized binary as the baseline.
432  24th USENIX Security Symposium 
USENIX Association
2
normalize the channel [17, 20] to curb side-channel ca-
pacity. Raccoon’s defenses complement prior work that
modiﬁes the hardware and/or OS. Molnar et al. [25] de-
scribe a transformation that prevents control-ﬂow side-
channel attacks, but their approach does not apply to pro-
grams that contain function calls and it does not protect
against data-ﬂow-based side-channel attacks.
Physical Access Attacks and Secure Processors.
Execute-only Memory (XOM) [36] encrypts portions of
memory to prevent the adversary from reading secret
data or instructions from memory. The AEGIS [35] se-
cure processor provides the notion of tamper-evident ex-
ecution (recognizing integrity violations using a merkle
tree) and tamper-resistant computing (preventing an ad-
versary from learning secret data using memory encryp-
tion). Intel’s Software Guard Extensions (SGX) [24] cre-
ate “enclaves” in memory and limit accesses to these en-
claves. Both XOM and SGX are only partially successful
in prevent the adversary from accessing code because an
adversary can still disassemble the program binary that is
stored on the disk. In contrast, Raccoon permits release
of the transformed code to the adversary. Hence Raccoon
never needs to encrypt code memory.
Oblivious RAM. AEGIS, XOM, and Intel SGX do not
prevent information leakage via memory address traces.
Memory address traces can be protected using Oblivious
RAM, which re-encrypts and re-shufﬂes data after each
memory access. The Path ORAM algorithm [34] is a
tree-based ORAM scheme that adds two secret on-chip
data structures, the stash and position map, to piggyback
multiple writes to the in-memory data structure. While
Raccoon uses a modiﬁed version of the Path ORAM al-
gorithm, the speciﬁc ORAM implementation is orthogo-
nal to the Raccoon design.
The Ascend [9] secure processor encrypts memory
contents and uses the ORAM construct to hide mem-
ory access traces. Similarly, Phantom [22] implements
ORAM to hide memory access traces. Phantom’s mem-
ory controller leverages parallelism in DRAM banks to
reduce overhead of ORAM accesses. However, both
Phantom and Ascend assume that the adversary can only
access code by reading the contents of memory. By con-
trast, Raccoon hides memory access traces via control
ﬂow obfuscation and software ORAM while still permit-
ting the adversary to read the code. Ascend and Phan-
tom rely on custom memory controllers whereas Mem-
ory Trace Oblivious systems that build on Phantom [20]
rely on a new, deterministic processor pipeline. In con-
trast, Raccoon protects off-chip data on commodity hard-
ware.
Memory Trace Obliviousness. GhostRider [20, 21] is
a set of compiler and hardware modiﬁcations that trans-
forms programs to satisfy Memory Trace Obliviousness
(MTO). MTO hides control ﬂow by transforming pro-
grams to ensure that the memory access traces are the
same no matter which control ﬂow path is taken by the
program. GhostRider’s transformation uses a type sys-
tem to check whether the program is ﬁt for transforma-
tion and to identify security-sensitive program values. It
also pads execution paths along both sides of a branch so
that the length of the execution does not reveal the branch
predicate value.
However, unlike Raccoon, GhostRider cannot exe-
cute on generally-available processors and software envi-
ronments because GhostRider makes strict assumptions
about the underlying hardware and the user’s program.
Speciﬁcally, GhostRider (1) requires the use of new in-
structions to load and store data blocks, (2) requires sub-
stantial on-chip storage, (3) disallows the use of dynamic
branch prediction, (4) assumes in-order execution, and
(5) does not permit use of the hardware cache (it instead
uses a scratchpad memory controlled by the compiler).
GhostRider also does not permit the user code to contain
pointers or to contain function calls that use or return
secret information. By contrast, Raccoon runs on SGX-
enabled Intel processors (SGX is required to encrypt val-
ues on the data bus) and permits user programs to contain
pointers, permits the use of possibly unsafe arithmetic
statements, and allows the use of function calls that use
or return secret information.
3 Threat Model and System Guarantees
This section describes our assumptions about the under-
lying hardware and software, along with Raccoon’s ob-
fuscation guarantees.
Hardware Assumptions. We assume that the adver-
sary can monitor and tamper with any digital signals on
the processor’s I/O pins. We also assume that the pro-
cessor is a sealed chip [35], that all off-chip resources
(including DRAM, disks, and network devices) are un-
trusted, that all read and written values are encrypted,
and that the integrity of all reads and writes is checked.
Software Assumptions. We assume that the adversary
can run malicious applications on the same operating
system and/or hardware as the victim’s application. We
allow malicious applications to probe the victim applica-
tion’s run-time statistics exposed by the operating system
(e.g. the stack pointer in /proc/pid/stat). However,
we assume that the operating system is trusted, so Iago
attacks [7] are out of scope.
USENIX Association  
24th USENIX Security Symposium  433
3
The Raccoon design assumes that the input program
is free of errors, i.e. (1) the program does not contain
bugs that will induce application crashes, (2) the pro-
gram does not exhibit undeﬁned behavior, and (3) if
multi-threaded, then the program is data-race free. Un-
der these assumptions, Raccoon does not introduce new
termination-channel leaks, and Raccoon correctly obfus-
cates multi-threaded programs.
Raccoon statically transforms the user code into an ob-
fuscated binary; we assume that the adversary has access
to this transformed binary code and to any symbol table
and debug information that may be present.
In its current implementation, Raccoon does not sup-
port all features of the C99 standard. Speciﬁcally, Rac-
coon cannot obfuscate I/O statements4 and non-local
goto statements. While break and continue statements
do not present a fundamental challenge to Raccoon, our
current implementation does not obfuscate these state-
ments. Raccoon cannot analyze libraries since their
source code is not available when compiling the end-
user’s application.
As with related solutions [30, 20, 21], Raccoon does
not protect information leaks from loop trip counts, since
na¨ıvely obfuscating loop back-edges would create inﬁ-
nite loops. For the same reason, Raccoon does not ob-
fuscate branches that represent terminal cases of recur-
sive function calls. However, to address these issues, it is
possible to adapt complementary techniques designed to
close timing channels [42], which can limit information
leaks from loop trip counts and recursive function calls.
Raccoon includes static analyses that check if the in-
put program contains these unsupported language con-
structs. If such constructs are found in the input program,
the program is rejected.
System Guarantees. Within the constraints listed
above, Raccoon protects against all digital side-channel
attacks. Raccoon guarantees that an adversary monitor-
ing the digital signals of the processor chip cannot dif-
ferentiate between the real path execution and the de-
coy path executions. Even after executing multiple de-
coy program paths, Raccoon guarantees the same ﬁnal
program output as the original program.
Raccoon guarantees that its obfuscation steps will not
introduce new program bugs or crashes, so Raccoon does
not introduce new information leaks over the termination
channel.
Assuming that the original program is race-free, Rac-