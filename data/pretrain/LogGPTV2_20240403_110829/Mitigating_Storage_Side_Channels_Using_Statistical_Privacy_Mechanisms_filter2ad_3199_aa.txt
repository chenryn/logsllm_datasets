title:Mitigating Storage Side Channels Using Statistical Privacy Mechanisms
author:Qiuyu Xiao and
Michael K. Reiter and
Yinqian Zhang
Mitigating Storage Side Channels
Using Statistical Privacy Mechanisms
Qiuyu Xiao
Michael K. Reiter
University of North Carolina
University of North Carolina
Chapel Hill, NC, USA
PI:EMAIL
Chapel Hill, NC, USA
PI:EMAIL
Yinqian Zhang
The Ohio State University
Columbus, OH, USA
PI:EMAIL
ABSTRACT
A storage side channel occurs when an adversary accesses
data objects inﬂuenced by another, victim computation and
infers information about the victim that it is not permitted
to learn directly. We bring advances in privacy for statisti-
cal databases to bear on storage side-channel defense, and
speciﬁcally demonstrate the feasibility of applying diﬀeren-
tially private mechanisms to mitigate storage side channels
in procfs, a pseudo ﬁle system broadly used in Linux and
Android kernels. Using a principled design with quantiﬁ-
able security, our approach injects noise into kernel data-
structure values that are used to generate procfs contents,
but also reestablishes invariants on these noised values so
as to not violate assumptions on which procfs or its clients
depend. We show that our modiﬁcations to procfs can be
conﬁgured to mitigate known storage side channels while
preserving its utility for monitoring and diagnosis.
Categories and Subject Descriptors
D.4.6 [OPERATING SYSTEMS]: Security and Protec-
tion—Information ﬂow controls
General Terms
Security
Keywords
Side channels; diﬀerential privacy
1.
INTRODUCTION
Side-channel attacks aim at disclosing data in computer
systems by exﬁltrating sensitive information through inter-
faces that are not designed for this purpose. In recent years,
the scope of side-channel attacks has been extended beyond
their traditional use to attack cryptographic keys, and tech-
niques utilized in side-channel analysis have also increased
in variety and sophistication.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author(s).
Copyright is held by the owner/author(s).
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
ACM 978-1-4503-3832-5/15/10.
DOI: http://dx.doi.org/10.1145/2810103.2813645.
In this paper, we examine one particular type of side-
channel attack vector, which we call storage side channels.
Storage side channels occur when an adversary accesses data
objects associated with a victim computation and makes in-
ferences about the victim based on the contents of the data
objects themselves or their metadata. As we use the term
here, storage side channels form a subclass of storage covert
channels [35] that gleans information from an unwitting vic-
tim, versus receiving information inconspicuously from an
accomplice. Storage side (and covert) channels diﬀer from
legitimate communication channels since the data value or
the metadata exploited by the side channel is not considered
sensitive by itself; yet, it still leaks information that may be
exploited to infer victim secrets.
A generic approach to mitigate storage side (and covert)
channels is to reduce the accuracy of the data or its meta-
data being reported by adding random noise to disturb side-
channel observations [35]. A challenge in this approach is to
develop principled mechanisms to perturb the side channels
with provable security guarantees, and to do so while pre-
serving the utility of the data and metadata in the system.
In this paper, we present a novel approach to doing so by
leveraging privacy concepts in storage side-channel defense.
By limiting data reporting to conform to diﬀerential privacy
and generalizations thereof, we show how to introduce noise
into the data reporting so as to bound information leakage
mathematically. The diﬃculties in doing so, however, stem
from the challenges in (i) modeling these storage channels
as statistical databases, where diﬀerential privacy was pre-
viously applied; (ii) designing privacy mechanisms to add
noise so that side channels are provably mitigated; and (iii)
designing these mechanisms so as to minimize the loss of util-
ity of the released data. We will discuss methods to address
these challenges in the remaining sections of this paper. In
theory, these methods can be applied to mitigating a variety
of storage side channels. However, in this paper we illus-
trate the idea by focusing only on storage channels based on
procfs, a ﬁle-system interface for reporting resource usage
information on Linux and Android systems.
Toward this end, we propose a modiﬁed procfs, dubbed
dpprocfs, that provides guarantees about the inferences pos-
sible from values reported through the procfs interfaces. In
doing so, dpprocfs defends against a variety of storage side
channels recently exploited in procfs on both Linux and
Android (see Sec. 3.1 for a summary of these attacks). Our
work builds on the works of Dwork et al. [20, 21] and Chan et
al. [12], which consider diﬀerential privacy under continuous
observations, but we are forced to extend from this starting
1582point in multiple ways. First, diﬀerential privacy itself is
not a good match for side-channel mitigation in the procfs
context; rather, we turn to a recent generalization called
d-privacy [13] that is parameterized by a distance metric
d. By deﬁning a suitable distance metric d and expressing
side-channel mitigation goals in terms of the distance be-
tween two series of procfs observations, we prove that the
diﬀerentially private mechanism of Chan et al. [12] general-
izes to mitigate storage side channels. Second, however, the
naive application of this mechanism to noise procfs out-
puts would risk correctness of applications that depend on
invariants that procfs outputs satisfy in practice. To re-
tain the utility of procfs, dpprocfs therefore extracts and
reestablishes invariants on the noised outputs so as to assist
applications that depend on them.
We implemented dpprocfs for Linux as a suite that con-
sists of an extension of the Linux kernel, a userspace daemon
process, and a software tool that is used for generating in-
variants on the values of kernel data structures oﬄine. The
kernel extension alters the functionality of procfs to enforce
d-privacy on the exported data values while preserving the
standard procfs interfaces. The userspace daemon inter-
acts with the kernel extension to reestablish the invariants
procfs satisﬁes. We will elaborate on our implementation
choices in later sections.
We evaluate our prototype for both its security and utility.
For security, we demonstrate conﬁgurations that eﬀectively
mitigate existing procfs side-channel attacks from the liter-
ature. We speciﬁcally demonstrate preventing two attacks,
one that uses procfs data to measure keystroke behavior as
a means to recover a typed input, and another that mon-
itors the resource usage of a browser process to determine
the website it is accessing [25]. We evaluate the utility of
dpprocfs by measuring the relative error of protected ﬁelds
and the similarity of the resource-use rankings of processes
by the popular top utility to those rankings without noise.
In summary, our contributions are as follows:
• We bring advances in privacy for statistical databases
to bear on storage side-channel defense. Speciﬁcally, we
show that an existing mechanism due to Chan et al. [12]
for enforcing diﬀerential privacy under continuous binary
data release extends to implement d-privacy for a dis-
tance metric d∗ that can quantify storage side channels
in procfs. We deﬁne this distance metric d∗, argue its
utility for capturing storage side channels, and prove that
the Chan et al. mechanism implements d∗-privacy.
• We identify a challenge in inserting noise into procfs
outputs, namely the violation of invariants that procfs
clients (and procfs code itself) might depend. Drawing
from previous research in invariant identiﬁcation, we de-
velop a tool for extracting invariants and imposing them
upon noised values prior to returning procfs outputs. In
doing so, we ensure that procfs outputs are consistent,
even while being noised to interfere with side channels.
• We develop a working implementation of dpprocfs, our
variant of procfs that implements storage side-channel
defense, and evaluate both the protection it oﬀers against
previously published attacks and the utility it oﬀers for
monitoring and diagnosis. Our results illustrate that
side-channel defense can be accomplished while still main-
taining the utility of procfs for its intended purposes.
The remainder of this paper is organized as follows. Sec. 2
summarizes related work. Sec. 3 provides an overview of
storage side channel attacks via procfs, and the theoretical
basis of d-privacy. Sec. 4 presents our design of dpprocfs,
which is followed by details of its implementation in Sec. 5.
We evaluate both the security and utility of dpprocfs in
Sec. 6 and discuss remaining challenges in Sec. 7. We con-
clude the paper in Sec. 8. The proofs of propositions stated
in this paper can be found in App. A.
2. RELATED WORK
Relevant to our work is privacy in the context of statistical
databases. Statistical database systems allow users to query
aggregate statistics of subsets of entities in the database.
Privacy concerns arise when a database client learns infor-
mation about individuals represented in the database through
one or multiple queries to the database [4]. This concern has
driven decades of innovation in stronger privacy deﬁnitions
in this context and algorithms to achieve them (e.g., [4, 38,
41, 29, 18, 27, 36, 8]). Of particular interest here is diﬀeren-
tial privacy and extensions thereof; please see the works due
to Dwork [19] and Fung et al. [23] that survey advances in
diﬀerential privacy and compare it to other privacy models,
respectively.
Prior to our work, diﬀerential privacy has been imple-
mented in practical systems, e.g., to support privacy for
data accessed through SQL-like queries [32] or MapReduce
computations [37]. The security scenarios we consider, how-
ever, diﬀer from the statistical database privacy model in
two dimensions: First, storage side channels revolve around
information leakage due to an attacker continuously mon-
itoring the same data as it changes over time. Statistical
databases are typically static, however. Second, database
indistinguishability is not well deﬁned under our security
model, and hence we need to adapt the deﬁnition of diﬀer-
ential privacy for our intended purposes.
We build our work upon two lines of research in the lit-
erature. The ﬁrst line is concerned with diﬀerential privacy
with continuous data release [20, 21, 12].
In these works,
the continuous data release takes the form of a sequence of
binary values, and only sequences that diﬀer in a single bi-
nary value are rendered indistinguishable to the attacker.
In the model we consider, in contrast, the continuous data
release can be characterized as a sequence of integers, and
even sequences that diﬀer in multiple values might need to
be rendered indistinguishable. The second line of research
generalizes the deﬁnition of diﬀerential privacy for statistical
databases. In particular, Chatzikokolakis et al. [13] broad-
ened the deﬁnition of diﬀerential privacy by parameterizing
the deﬁnition with a distance metric d, and requiring that
the degree of indistinguishability of two databases be a func-
tion of their distance. (The original deﬁnition of diﬀerential
privacy can be viewed as a special case for Hamming dis-
tance [13].) We build from this approach, deﬁning a metric
d that applies to storage side channels and implementing
this defense in a working system.
While several prior works also extend the deﬁnition of dif-
ferential privacy to settings that are not statistical databases
(e.g., geo-location services [5, 9] and smart metering [3, 2, 17,
26, 31, 42, 7]), our work is the ﬁrst to our knowledge to ap-
ply diﬀerential privacy concepts in operating system security
and side-channel defense. Moreover, the domain of storage
side-channel defense introduces important diﬀerences that
1583require innovation. In particular, since the values that our
system must perturb to interfere with side channels are ones
that are used by other software, it is important that our
modiﬁcations do not violate invariants on which that soft-
ware depends. To our knowledge, this aspect distinguishes
the problem we address from work in geo-location and smart
metering and drives us to a novel design as discussed in the
balance of the paper.
3. BACKGROUND
3.1 Side Channel Attacks via PROCFS
procfs is a pseudo ﬁle system implemented in Linux, An-
droid, and a few other UNIX-like operating systems to fa-
cilitate userspace applications’ accesses to kernel-space in-
formation. Two types of information are typically shared
through procfs: per-process information and system-wide
information. Per-process information reveals conﬁguration
and state information about a process, including path of the
executable, environment variables, size of virtual and phys-
ical memory, CPU and network usage, and so on. While
some of the information should only be consumed by the
process itself, other information, especially statistics about
resource usage, is required for performance monitoring and
diagnosis. For instance, in Linux, top, ps, iostat, netstat,
pidstat, and others rely on procfs to function. In Android,
procfs is used for apps to monitor the resource usage, e.g.,
transferred network data, of other apps.
This useful facility has been exploited to conduct side-
channel attacks by several prior works. Particularly of in-
terest in this paper are the attacks exploiting publicly avail-
able per-process information to infer secrets of the targeted
process; see Table 1 for examples. The techniques under-
lying these attacks are similar. Jana et al. [25] introduced
an attack that, by reading from a ﬁle in procfs, /proc/
/statm, and learning the data resident size (drs) of
a Chrome browser, enables a malicious co-located applica-
tion to infer the website it is visiting. The feature used to
diﬀerentiate multiple websites being browsed is the snap-
shot of the application’s memory footprint. Zhou et al. [44]
explored ways in Android to infer a victim app’s activity
by monitoring its network communications. Speciﬁcally,
by sampling the ﬁles /proc/uid_stat//tcp_rcv and
/proc/uid_stat//tcp_snd, an adversary is able to
learn the packet sizes sent and received by the victim app
with high accuracy. Chen et al. [14] extracted the victim
app’s CPU utilization time, memory usage, and network us-
age from various procfs ﬁles to classify the application’s
behaviors. Lin et al. [28] also used utime to recognize a
user’s operation of the software keyboard on Android.
3.2 d-Privacy
In this paper we leverage a generalization of diﬀerential
privacy due to Chatzikokolakis et al. [13] called d-privacy,
which we summarize here brieﬂy. (Our summary is not of
the most general form of d-privacy, however.) A metric d on
a set X is a function d : X 2 → [0, ∞) satisfying d(x, x) = 0,
d(x, x′) = d(x′, x), and d(x, x′′) ≤ d(x, x′) + d(x′, x′′) for all
x, x′, x′′ ∈ X . A randomized algorithm A : X → Z satisﬁes
(d, ǫ)-privacy if
P (A(x) ∈ Z) ≤ exp(ǫ × d(x, x′)) × P¡A(x′) ∈ Z¢
for all Z ⊆ Z.
We leverage the following composition property of d-privacy:
Proposition 1. If A : X → Z is (d, ǫ)-private and A′ :
X → Z ′ is (d, ǫ′)-private, then A′′ : X 2 → Z × Z ′ deﬁned
by A′′(x, x′) = (A(x), A′(x′)) satisﬁes
P¡A′′(x, x′) ∈ Z × Z ′¢ ≤ exp(ǫ × d(x, x′′) + ǫ′ × d(x′, x′′′))
× P¡A′′(x′′, x′′′) ∈ Z × Z ′¢
for any Z ⊆ Z, any Z ′ ⊆ Z ′, and any x, x′, x′′, x′′′ ∈ X .
Let Z and R denote the integers and reals, respectively.
In the case X = Zn, a metric that will be of interest for our
purposes is L1 distance, deﬁned by
dL1(x, x′) =
n
Xi=1
|x[i] − x′[i] |
where x = hx[1] , . . . , x[n]i.
Proposition 2. Let A : Zn → Rn be the algorithm that
$←
returns A(x) = hx[1] + r1, . . . , x[n] + rni, where each ri
Lap¡ 1
ǫ¢. Then, for any x, x′ ∈ Zn and Z ⊆ Rn,
P (A(x) ∈ Z) ≤ exp(ǫ × dL1(x, x′)) × P¡A(x′) ∈ Z¢
4. DESIGN OF A d-PRIVATE PROCFS
In an eﬀort to suppress information leakages in procfs
such as those described in Sec. 3.1, we devise a new procfs-
like ﬁle system, called dpprocfs, that leverages diﬀerential
privacy principles. In this section, we describe how we apply
these principles in the design of dpprocfs.
4.1 Threat Model
This paper considers side-channel attacks exploiting statis-
tics values exported by procfs from co-located applications
running within the same OS. In particular, we consider the
default settings of procfs, which do not restrict accesses to
a process’ private directories in procfs by other processes.
Such settings are very typical in traditional desktop envi-