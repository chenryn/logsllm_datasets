# Mitigating Storage Side Channels Using Statistical Privacy Mechanisms

**Authors:**
- Qiuyu Xiao, University of North Carolina, Chapel Hill, NC, USA
- Michael K. Reiter, University://northcarolina.edu
- Yinqian Zhang, The Ohio State University, Columbus, OH, USA

## Abstract
A storage side channel occurs when an adversary accesses data objects influenced by another, victim computation and infers information about the victim that it is not permitted to learn directly. We apply advances in privacy for statistical databases to storage side-channel defense, specifically demonstrating the feasibility of using differentially private mechanisms to mitigate storage side channels in `procfs`, a pseudo file system widely used in Linux and Android kernels. Our approach injects noise into kernel data-structure values used to generate `procfs` contents while reestablishing invariants on these noised values to ensure they do not violate assumptions on which `procfs` or its clients depend. We show that our modifications to `procfs` can be configured to mitigate known storage side channels while preserving its utility for monitoring and diagnosis.

## 1. Introduction
Side-channel attacks aim to disclose data in computer systems by exfiltrating sensitive information through interfaces not designed for this purpose. In recent years, the scope of side-channel attacks has expanded beyond their traditional use in attacking cryptographic keys, with techniques becoming more varied and sophisticated.

In this paper, we focus on a specific type of side-channel attack vector, which we term storage side channels. These occur when an adversary accesses data objects associated with a victim computation and infers information about the victim based on the contents of the data objects or their metadata. Storage side channels are a subclass of storage covert channels, where the attacker gleans information from an unwitting victim rather than receiving information inconspicuously from an accomplice.

A generic approach to mitigate storage side (and covert) channels is to reduce the accuracy of the reported data or metadata by adding random noise. A challenge in this approach is to develop principled mechanisms that provide provable security guarantees while preserving the utility of the data and metadata in the system.

We present a novel approach to this problem by leveraging privacy concepts in storage side-channel defense. By limiting data reporting to conform to differential privacy and its generalizations, we introduce noise into the data reporting to mathematically bound information leakage. The difficulties in doing so stem from:
1. Modeling storage channels as statistical databases.
2. Designing privacy mechanisms to add noise and provably mitigate side channels.
3. Minimizing the loss of utility of the released data.

We illustrate this idea by focusing on storage channels based on `procfs`, a file-system interface for reporting resource usage information on Linux and Android systems. We propose a modified `procfs`, dubbed `dpprocfs`, that provides guarantees about the inferences possible from values reported through the `procfs` interfaces. This defends against various storage side channels recently exploited in `procfs` on both Linux and Android.

Our work builds on the works of Dwork et al. [20, 21] and Chan et al. [12], which consider differential privacy under continuous observations. However, we extend these works to address the specific challenges of `procfs`. We implement `dpprocfs` for Linux, consisting of a kernel extension, a userspace daemon, and a tool for generating invariants on kernel data structures. The kernel extension enforces d-privacy on exported data values while preserving standard `procfs` interfaces. The userspace daemon reestablishes invariants on the noised outputs.

We evaluate our prototype for both security and utility. For security, we demonstrate configurations that effectively mitigate existing `procfs` side-channel attacks. For utility, we measure the relative error of protected fields and the similarity of resource-use rankings by the `top` utility.

## 2. Related Work
Relevant to our work is privacy in the context of statistical databases, where users query aggregate statistics of subsets of entities. Privacy concerns arise when a database client learns information about individuals through queries. This has driven innovation in stronger privacy definitions and algorithms, such as differential privacy.

Differential privacy has been implemented in practical systems, e.g., for SQL-like queries [32] and MapReduce computations [37]. However, storage side channels differ from the statistical database privacy model in two ways: 
1. Information leakage due to continuous monitoring of changing data.
2. Database indistinguishability is not well-defined under our security model, requiring adaptation of differential privacy.

We build on research in differential privacy with continuous data release [20, 21, 12] and generalize the definition of differential privacy for statistical databases [13]. We define a metric \( d \) that applies to storage side channels and implement this defense in a working system.

While prior works extend differential privacy to non-statistical settings (e.g., geo-location services and smart metering), our work is the first to apply differential privacy concepts in operating system security and side-channel defense. The domain of storage side-channel defense introduces important differences, particularly the need to maintain invariants on which software depends.

## 3. Background
### 3.1. Side Channel Attacks via `procfs`
`procfs` is a pseudo file system in Linux, Android, and other UNIX-like systems, facilitating user-space applications' access to kernel-space information. It shares per-process and system-wide information, including configuration, state, and resource usage. While some information is only consumed by the process itself, other information, especially resource usage statistics, is required for performance monitoring and diagnosis.

Several prior works have exploited `procfs` to conduct side-channel attacks. For example, Jana et al. [25] introduced an attack that infers the website being visited by a Chrome browser by reading `/proc/<pid>/statm`. Zhou et al. [44] inferred a victim app's activity by monitoring network communications. Chen et al. [14] classified application behaviors using CPU utilization, memory usage, and network usage. Lin et al. [28] recognized user operations on the software keyboard.

### 3.2. d-Privacy
We leverage a generalization of differential privacy called d-privacy [13]. A metric \( d \) on a set \( X \) is a function \( d : X^2 \rightarrow [0, \infty) \) satisfying \( d(x, x) = 0 \), \( d(x, x') = d(x', x) \), and \( d(x, x'') \leq d(x, x') + d(x', x'') \). A randomized algorithm \( A : X \rightarrow Z \) satisfies \((d, \epsilon)\)-privacy if:
\[ P(A(x) \in Z) \leq \exp(\epsilon \times d(x, x')) \times P(A(x') \in Z) \]
for all \( Z \subseteq Z \).

We use the following composition property of d-privacy:
\[ P(A''(x, x') \in Z \times Z') \leq \exp(\epsilon \times d(x, x'') + \epsilon' \times d(x', x''')) \times P(A''(x'', x''') \in Z \times Z') \]

For \( X = \mathbb{Z}^n \), a metric of interest is L1 distance:
\[ d_{L1}(x, x') = \sum_{i=1}^n |x[i] - x'[i]| \]

Proposition 2: Let \( A : \mathbb{Z}^n \rightarrow \mathbb{R}^n \) be the algorithm that returns \( A(x) = \langle x[1] + r_1, \ldots, x[n] + r_n \rangle \), where each \( r_i \sim \text{Lap}\left(\frac{1}{\epsilon}\right) \). Then, for any \( x, x' \in \mathbb{Z}^n \) and \( Z \subseteq \mathbb{R}^n \):
\[ P(A(x) \in Z) \leq \exp(\epsilon \times d_{L1}(x, x')) \times P(A(x') \in Z) \]

## 4. Design of a d-Private `procfs`
To suppress information leakages in `procfs`, we design a new `procfs`-like file system, `dpprocfs`, that leverages differential privacy principles.

### 4.1. Threat Model
We consider side-channel attacks exploiting statistics values exported by `procfs` from co-located applications running within the same OS. Specifically, we consider the default settings of `procfs`, which do not restrict access to a process' private directories by other processes. Such settings are typical in traditional desktop environments.