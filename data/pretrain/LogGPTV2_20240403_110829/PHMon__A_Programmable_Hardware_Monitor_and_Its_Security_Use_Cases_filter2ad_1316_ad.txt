Our ﬁrst use case is a shadow stack, a security mechanism
that detects and prevents stack-based buffer overﬂows as well
as Return-Oriented-Programming (ROP) attacks. As data on
the stack is interleaved with control information such as func-
tion return addresses, an overﬂow of a buffer can violate
the integrity of such control information and in consequence
compromise system security. A shadow stack is a secondary
stack that keeps track of function return addresses to protect
them from being tampered with by an attacker. A stack buffer
overﬂow attack occurs when a program writes data into a
stack-allocated buffer, such that the data is larger than the
buffer itself. ROP is a contemporary code-reuse attack that
combines a sequence of so-called gadgets into a ROP-chain.
Gadgets typically consist of a small number of instructions
ending in a ret instruction. However, executing a ROP-chain
violates function call semantics (i.e., there are no correspond-
ing calls to the rets in the chain). A shadow stack can
therefore detect ROP attacks.
Rather than providing a dedicated hardware solution (e.g.,
Intel’s proposed shadow stack [67]), we leverage PHMon’s
ﬂexibility to implement a hardware shadow stack. A shadow
stack can easily be realized in PHMon with two MUs. We
program one MU (MU0) to monitor call instructions and
another MU (MU1) to monitor ret instructions. Also, we
conﬁgure each of the MUs to trigger an action for every mon-
itored instance of call and ret (threshold = 1).
The OS allocates a shared memory space, i.e., space for
the shadow stack, for each process that is being monitored.
Both MUs have access to this shared memory space. We can
simply protect this shared memory space against unautho-
rized accesses by monitoring load and store accesses to this
range of addresses leveraging a third MU (as described in Sec-
tion 4.3). Any user-space access to this memory space results
in an interrupt and termination of the violating process. Once
the OS allocates this memory space (during the initialization
of a new process), it stores the base address and the size of the
allocated memory in the ﬁrst two general-purpose registers of
the Local Register File in PHMon (refer to Appendix A for
more information about the Local Register File). We conﬁg-
ure the CFUs to use the base address register as the shadow
stack pointer. The AU accesses the shadow stack by sending
memory requests to the L1 cache using the RoCC interface.
The summary of our event-action scenario for implement-
ing a shadow stack is as follows: the ﬁrst MU (MU0) mon-
itors calls and pushes the corresponding pc_src value to
the shadow stack. The second MU (MU1) monitors rets
and compares the pc_dst value with the value stored on
the top of the shadow stack. If there is a mismatch between
calls and rets (e.g., an illegal ret address or a ROP attack),
PHMon triggers an interrupt and the OS handles the inter-
rupt. In our current implementation, the OS simply terminates
the process that caused the interrupt. Note that analogous
to [8], we can address call-ret matching violations caused
by setjmp/longjmp by augmenting the jmp_buf struct with
one more ﬁeld to store the shadow stack pointer.
5.2 Hardware-Accelerated Fuzzing
Fuzzing is the process of providing a program under test
with random inputs with the goal of eliciting a crash due to
814    29th USENIX Security Symposium
USENIX Association
a software bug. It is commonly used by software developers
and security experts to discover bugs and security vulnera-
bilities during the development of a software product and
mostly for the deployed software. Big software companies
such as Google [2] and Microsoft [68] use fuzzing extensively
and continuously. For instance, Google’s OSS-Fuzz platform
found over 1,000 bugs in 5 months [33]. Similarly, American
Fuzzy Lop (AFL) [85] is one of the state-of-the-art fuzzers
that successfully identiﬁed zero-day vulnerabilities in popular
programs, such as PHP and OpenSSH.
AFL aims to explore new execution paths in the code to
discover potential vulnerabilities. AFL consists of two main
units: the fuzzing logic and the instrumentation suite. The
fuzzing logic controls the mutation and scheduling of the in-
puts, and also decides if the current input is interesting enough
for further fuzzing. During fuzzing, the instrumentation suite
collects branch coverage information of the program for the
current input. In the current version of AFL (2.52b), the in-
strumentation can be applied either at compile time with a
modiﬁed gcc compiler (aﬂ-gcc) if source is available or at
runtime by adding instructions to the native binary through
user-mode QEMU for closed-source programs. As QEMU
uses DBI, it can instrument each control-ﬂow instruction with
the necessary book-keeping logic. While this capability is
ﬂexible, DBI comes at a signiﬁcant performance overhead
(2.5× to 5× [60]). PHMon can easily monitor the control-
ﬂow instructions and apply the necessary book-keeping logic
without incurring the DBI overhead. In this study, we do
not modify the fuzzing logic of AFL. However, we program
PHMon to implement the instrumentation suite.
AFL uses a shared memory region, called bitmap, to store
the encountered basic block transitions (a basic block is an
instruction sequence with only one entry and one exit point)
for the program executed with the most recent input. Each
basic block has an id, calculated by performing logical and
bitwise operations using the current basic block address. The
address that points to the transition information in the bitmap
is calculated based on the current and the previous block id.
We use PHMon as part of AFL as follows (see Figure 4):
(1) AFL starts executing the target program on the RISC-V
processor. (2) PHMon monitors the control-ﬂow instructions
of the target binary. (3) Whenever PHMon detects a control-
ﬂow instruction, it updates the bitmap. (4) The child process
(fuzzed program) terminates. (5) The fuzzing unit compares
the output bitmap with the global bitmap (the collection
of the previously observed basic block transitions) and de-
termines whether the current input is interesting enough for
further fuzzing.
PHMon conducts step (2) and step (3) of the above-
described AFL process. To this end, we program two MUs to
monitor the control-ﬂow instructions (branches and jumps)
with threshold = 1. Both of these MUs have access to the
bitmap allocated by AFL. We program each MU with 12
actions to update the bitmap.
Figure 4: Integration of PHMon with AFL.
5.3 Preventing Information Leakage
PHMon can also be used to prevent the leakage of sensitive
information, such as cryptographic keys. A concrete example
is Heartbleed [34], a buffer over-read vulnerability in the
popular OpenSSL library that allowed attackers to leak the
private key2 of any web-server relying on that library [34].
To prevent Heartbleed, we ﬁrst identiﬁed the memory ad-
dresses that contain the private key. Second, we manually
white-listed all legitimate read accesses (i.e., instructions that
access the key). As legitimate accesses to the key are conﬁned
to three functions that implement cryptographic primitives,
this was a straightforward task. Finally, we programmed PH-
Mon to trigger an interrupt in case any instruction but those
white-listed above accesses the key. To this end, we conﬁgure
an MU to monitor load instructions that access the key, and
the CFU contains a series of actions that compare the pc_src
of the load instruction against the white-list. As a proof of
concept, we programmed PHMon to prevent the leakage of
the prime number p and PHMon successfully prevented the
disclosure. Note that the location of sensitive information
and its legitimate accesses can vary in different environments.
Ideally, the information about the location of an instruction
that accesses sensitive data would be produced by a com-
piler (e.g., by annotating sensitive variables). However, we
leave augmenting a compiler tool-chain to produce such meta-
information which can be readily enforced by PHMon as
future work.
5.4 Watchpoints and Accelerated Debugger
As the last use case, we focus on the debugging capabilities of
PHMon. PHMon can provide watchpoints for an interactive
debugger, such as GDB, by monitoring memory addresses
(addr entry of the commit log) and then triggering an inter-
rupt. Although the number of MUs dictates the maximum
number of unique watchpoints that PHMon can monitor, our
watchpoint capability is not limited by the number of MUs.
Each MU can monitor a range of monitoring addresses, spec-
iﬁed by match and mask bits. Here, the range of watchpoint
addresses can be contiguous or non-contiguous. Additionally,
for each range, the user can conﬁgure PHMon to monitor read
2More precisely, the attack leaks the private prime number p which allows
the attacker to reconstruct the private key.
USENIX Association
29th USENIX Security Symposium    815
Parent Process (AFL)Child Process(The Fuzzed Program)Program ExecutionOn RISC-V ProcessorPHMonFork+Execv(1)Processterminates(4)Updating thebitmap with theexecution trace (3)Reading theexecution trace (5)Monitoring(2)Shared  Memory Region (BITMAP)Memoryaccesses, write accesses, or both by specifying the inst entry
of the commit log. It is worth mentioning that most modern
architectures only provide a few watchpoint registers (e.g.,
four in Intel x86). We have used and validated the watch-
point capability of PHMon as part of the information leak
prevention use case, described in Section 5.3.
In addition to watchpoints, PHMon accelerates the debug-
ging process. As an example, PHMon can provide an efﬁcient
conditional breakpoint and trap into GDB. Consider a debug-
ging scenario for a conditional breakpoint in a loop as “break
foo.c:1234 if i==100”, where i is the loop counter. Here,
we want to have a breakpoint and trap into GDB when the
loop reaches its 100th iteration. To this end, PHMon monitors
an event where pc_src has the corresponding PC value of
line 1234. Then, PHMon triggers an interrupt when the MU’s
counter reaches the threshold of 100. Subsequently, the
interrupt handler traps into GDB. In Section 6.2, we measure
the performance improvement of PHMon over GDB for such
a conditional breakpoint.
For the debugging use cases, such as watchpoints and con-
ditional breakpoints, the only required action in case of de-
tecting an event is triggering an interrupt. As a result, PHMon
is synchronized with the program’s execution.
6 Evaluation
In this section, we discuss our approach to validate the func-
tionality of PHMon as well as our evaluation of PHMon using
performance, power, and area metrics.
6.1 Experimental Setup
We implemented PHMon as a RoCC (using Chisel HDL [7])
and interfaced it with the RISC-V Rocket processor [5] that
we prototyped on a Xilinx Zynq Zedboard evaluation plat-
form [63]. We performed all experiments with a modiﬁed
RISC-V Linux (v4.15) kernel. We compared the PHMon de-
sign with a baseline implementation of the Rocket processor.
For both the baseline and PHMon experiments, we used the
same Rocket processor conﬁgurations featuring a 16K L1
instruction cache and a 16K L1 data cache. Table 2 lists the
microarchitectural parameters of Rocket core and PHMon.
Note that similar to HDFI [76], we do not include an L2 data
cache in our experiments running on Rocket core. Currently,
TileLink2 (the protocol that Rocket Chip uses to implement
the cache coherent interconnect) does not support L2 cache
while the L2 cache in older versions of TileLink is not mature
enough [76]. Due to the limitations of our evaluation board, in
our experiments, the Rocket Core operated with a maximum
frequency of 25 MHz (both in the baseline and PHMon exper-
iments). Note that for our ASIC evaluation, we synthesized
the Rocket core with a target frequency of 1 GHz.
For our shadow stack use case, we calculated the run time
overhead of 14 applications from MiBench [36], 9 appli-
cations (out of 12) from SPECint2000 [37], and 8 applica-
tions (out of 12) from SPECint2006 [38] benchmark suites.
To measure the performance improvement of our hardware-
Table 2: Parameters of Rocket core and PHMon.
Rocket Core
Pipeline
L1 instruction cache
L1 data cache
Register ﬁle
6-stage, in-order
16 KB, 4-way set-associative
16 KB, 4-way set-associative
31 entries, 64-bit
PHMon
MUs
Local Register File
Match Queue
Action Conﬁg Table
2
6 entries, 64-bit
2,048 entries, 129-bit
16 entries
accelerated AFL, we evaluated 6 vulnerable applications [85]
including indent 2.2.1, zstd, PCRE 8.38, sleuthkit 4.1.3,
nasm 2.11.07, and unace 1.2b.
To assess power and area, we used Cadence ASIC toolﬂow
for 45nm NanGate process [69] to synthesize PHMon and the
Rocket processor to operate at 1 GHz. We then measured the
post-extraction power consumption and the area of our system
as well as our baseline system, i.e., the unmodiﬁed Rocket
processor. We considered all memory blocks (both in PHMon
and Rocket) as SRAM blocks and used CACTI 6.5 [80] to
estimate their power and area.
6.2 Functionality Validation and Performance
Results
In this subsection, we validate the functionality of our use
cases and evaluate their performance overhead. Additionally,
we evaluate the performance overhead PHMon imposes dur-
ing context switches.
Shadow Stack. We validated the functionality of our shadow
stack using benign benchmarks and programs vulnerable to
buffer overﬂow attacks. All benchmark programs ran suc-
cessfully with the shadow stack enabled resulting in no false
detections from PHMon. We developed simple programs vul-
nerable to the buffer overﬂow using strcpy and exploited
this vulnerability.3 As designed, PHMon detected the mis-
matches between calls and rets, triggered an interrupt, and
the Linux Kernel terminated the process.
We measured the runtime overhead of our shadow
stack on different benchmark applications from MiBench,
SPECint2000, and SPECint2006 benchmark suites. We ran
each benchmark ﬁve times and calculated the average runtime
overhead. All standard deviations were below 1.5%. Unfortu-
nately, we were not able to successfully cross-compile and run
three of the SPECint2000 benchmarks, i.e., eon, perlbmk, and
vortex, for RISC-V. For the rest of the SPECint2000 bench-
marks, we used -O2 for compilation and reference input
for evaluation (we clarify the exceptions in the results). For
SPECint2006 benchmark applications, we used -O2 for com-
pilation. Considering the limitations of our evaluation board,
3We disabled Address Space Layout Randomization (ASLR) to simplify
our buffer overﬂow attack.
816    29th USENIX Security Symposium
USENIX Association
Figure 5: The performance overhead of PHMon as a shadow stack.
† We were not able to run mcf benchmark with reference input on our evaluation board; as a result, we used the test input for this benchmark.
(cid:63) Due to the memory limitations of our evaluation board, we had to reduce the buffer size of the reference input to 3 MB for gzip and bzip2 benchmarks.
± We had to use -O0 and an input buffer size of 96 MB to successfully run gap benchmark.
we used the test inputs to evaluate SPECint2006. Never-
theless, we were not able to run mcf, sjeng, omnetpp, and
perlbench benchmarks mainly due to memory limitations.
Figure 5 shows the performance overhead of PHMon as a
shadow stack over the baseline Rocket processor. On average,
PHMon incurs 0.5%, 1.4%, and 1.2% performance overhead
for our evaluated MiBench, SPECint2000, and SPECint2006
applications, respectively. Overall, PHMon has a 0.9% perfor-
mance overhead on the evaluated benchmarks.
Benchmark
PHMon HDFI
1.12%(cid:63)
1.12%
0.42%†
1.76%
1.92%±
3.34%
1.15%(cid:63)