integration-tests[druid-integration-tests]
Cindexing-servlce[druid-indexing-service]
indexing-hadoop [druid-indexing-hadoop]
extenisions-core
口
0
Cdistribution
common [druid-common]
benthmarks[druid-benchmarks]
Caws-common (druid-aws-common]
apidruid-p
Ddruidiml
Hgitignore
口
口idea
口
extensions-contrib
examples[druid-examples]
docs
图8-1
Druid项目列表
Druid实时大数据分析原理与实践
110
194
562
706
java文件数量
---
## Page 215
第8章
Main.java
Incrementallndex.java
IndexMerger.java
IndexIO.java
Segment.java
Column.java
核心项目
项目目录
publications
docs
文档相关
extensions-contrib
aws-common
indexing-hadoop
extensions-core
扩展接口
项目目录
如果想快速浏览代码，
核心源代码探析
项目文档
容不会放入最后的Druid发行版中
社区开发者可以在这个目录下增加扩展功能，但这个包的内
与AWS集成相关，包括账号权限管理等
与Hadoop索引相关的代码
核心扩展包，
功能
一些相关论文，包括KDD论文
服务程序人口
增量索引
持久化Index
装人Index文件
Segment
列
功能
可以从如下几个文件开始。
包括与Kafka,HDFS,S3的集成
$druid\services\src\main\java\io\druid\cli\Main.java
Isegment\incremental\IncrementalIndex.java
$druid\processinglsrc\main\javalio\druid
\druid\segment\IndexMerger.java
$druid\druid\processinglsrc\main\javalio
\druid\segment\IndexlO.java
$druid\druid\processing\src\main\java\io
\Segment.java
$druid\processingsrc\mainjava\io\druid\segment
\column\Column.java
$druidprocessing\src/mainjavalio\druid\segment
代码量（java）
5
178
163
java文件数量
续表
191
---
## Page 216
umn。以具体的Float类型为例，FloatColumn继承了Column，它的具体实现是使用Com-
8.4
式设计。
有的表述存储视图，有的表述内存结构视图，这些数据结构之间通常使用以下几种关系和模
8.3
192
Column是基础列的基础接口。继承它的类包括LongColumn、FloatColumn和SimpleCol-
Column的结构如图8-2所示
·修饰者（Decoration）设计模式：为了增强一些类的某些功能，又不失去灵活性，通
数据库的数据结构往往比较复杂。有些数据结构表述逻辑视图，有的表述具体实现等，
·适配器（Adapter）设计模式：该设计模式在数据基础结构中大量应用，比如我们已
·包含关系：一个对象包含几个其他的对象，实现一些组合功能。
·继承关系：父类通常为接口，子类继承父类，完成实现具体功能。
Column结构
过包含对象方式继承某类大部分功能，同时也灵活地附加一些额外的功能。
Index适配成有查询能力的对象。
经有了内存中的Index存储，为了支持查询功能，也需要提供适配器，将面向存储的
索引结构模块和层次关系
(rowUum)
Stngetvalye
ImmutableRTreegetRTree()
图8-2
Column的结构
Spatiallndex
iap(int
actory()
idx)
Druid实时大数据分析原理与实践
rch(Bound
bot
---
## Page 217
public interface Column
的类型，例如 FloatColumn、LongColumn等。这个Column提供了一个非常抽象的结构。
lcolumn\Column.java。它是一个接口并没有提供任何通用的定义，而是提供了几种Colunm
1.Column
Floats的列表结构。
第8章核心源代码探析
public SpatialIndex getSpatialIndex(）;
public BitmapIndex getBitmapIndex(）;
publicComplexColumn getComplexColumn(）;
public GenericColumn getGenericColumn(）;
public RunLengthColumn getRunLengthColumn(）;
public DictionaryEncodedColumn getDictionaryEncoding(）;
publicint getLength();
public ColumnCapabilities getCapabilities();
public static final String TIME_COLUMN_NAME="__time";
Column是Druid最基础的数据结构，代码位于\processing\src\main\Vjava\io\druid\segment
。GenericColumn是一般的列，包括字符串（String）浮点数（Float）和整数（Long）。
·Column并没有提供一些通用的接口，而是提供了不同类型的Column的获取方法，具
：ComplexColumn是一种复杂对象，常常用于一些扩展的数据类型，例如 HyperLoglog
·RunLengthColumn用于表示行程编码的列，尚未完全实现。这种压缩方式对于数据稀
Bitmap在内存中也会进行压缩，因此查询扫描时能够兼顾速度和内存大小。
疏的列有较好的压缩率和访问速度。
一
获取基数。
是这种结构，在值的基数不大的情况下都可以使用这种模式。它提供了getCardinality()
DictionaryEncodedColumn表示字典编码索引，Druid中的字符串的列实际上使用的都
体Column的实现由每个返回的Column实体对象负责。
193
---
## Page 218
是一个浮点数的列。
publicclass FloatColumn extends AbstractColumn
umn.
2.
194
public GenericColumn getGenericColumn()
@Override
publicint getLength()
@Override
public ColumnCapabilities getCapabilities()
@Override
public FloatColumn(CompressedFloatsIndexedSupplier column)
private final CompressedFloatsIndexedSupplier column;
private static final ColumnCapabilitiesImpl CAPABILITIES
return new IndexedFloatsGenericColumn(column.get();
return column.size():
return CAPABILITIES;
this.column =column;
FloatColumn
从上面代码中，
下面是一个FloatColumn例子，
new
ColumnCapabilitiesImpl().setType(ValueType.FLOAT);
：我们看出FloatColumn实际返回的是IndexedFloatsGenericColumnO)，
，它继承了AbstractColumn，AbstractColumn 继承了Col-
Druid实时大数据分析原理与实践
这
---
## Page 219
Segment的结构如图8-3所示。
8.5
Bitmap的对象由BitmapFactory生成。
public interface BitmapIndex
3.BitmapIndex
第8章核心源代码探析
提供了查询每行数据的能力。QueryableIndex在一定方式下可以转换成 StorageAdapter接口。
查询的数据接口，它提供了访问每一列的能力。StorageAdapter具有游标（Cursor）功能，它
提供了两类接口：一类是QueryableIndex；另一类是StorageAdapter。QueryableIndex是面向
publicImmutableBitmap getBitmap（int idx);
public int getIndex(String value);
public BitmapFactory getBitmapFactory()
public String getValue(int index);
publicint getCardinality(）;
BitmapIndex是Druid的核心结构，用于构造字符串类型列的索引。它为每个列值都创建
oublicboolean hasNulls();
Column用于管理单列，Segment就用于管理一组列，包括Dimension和Metric。Segment
Segment
getColumn
nn（String columnName)
ColumnSelector
inggetid
图8-3Segment的结构
tifier()
Segment
ral():
ilableDimensi
SeouencemakeCursors()
CS()
ons()
CursorFactory
√
159
---
## Page 220
化过程中，构建一个游标，并且将列中的每一个值都加人到Row中。
crementalIndexStorageAdapter提供了从Incrementallndex适配成StorageAdapter的实现。在转
过滤等。
方式可以参考后面的查询部分。
elector用于选择一个列的接口，因此QueryableIndex提供了精细到列的查询。其详细的使用
public interface QueryableIndex extends ColumnSelector,Closeable
public interface ColumnSelector
public interface Segment extends Closeable
196
publicvoid close(） throws IOException;
public Metadata getMetadata();
public BitmapFactory getBitmapFactoryForDimensions(）;
public Indexed getAvailableDimensions();
public Indexed getColumnNames();
publicint getNumRows();
public Interval getDataInterval(）;
public Column getColumn(String columnName);
public StorageAdapter asStorageAdapter();
public QueryableIndex asQueryableIndex(）;
public Interval getDataInterval();
public String getIdentifier(）;
StorageAdapter
QueryablelIndex 提供了访问每一列的能力，支持针对某些列的查询。
QueryableIndex
QueryableIndexStorageAdapter提供了从QueryableIndex适配成StorageAdapter的实现；In-
StorageAdapter实现了CursorFactory，可以通过游标访问每一行数据，包括对数据进行
QueryableIndex提供了Segment的元数据，例如列名等。它实现了ColumnSelector,ColumnS-
Druid实时大数据分析原理与实践
---
## Page 221
add(InputRow row)方法插入新数据，新数据的 Metric通过Aggregator 进行聚合。Incremen-
储队列的Ofset。
public interface StorageAdapter extends CursorFactory
3
public interface CursorFactory
第8章
public Metadata getMetadata();
public DateTime getMaxIngestedEventTime();
public int getNumRows();
public String getColumnTypeName(String column);
public ColumnCapabilities getColumnCapabilities(String column);
public Capabilities getCapabilities();
public DateTime getMaxTime(）;
public DateTime getMinTime(）;
public int getDimensionCardinality(String column);
public Iterable getAvaitableMetrics();
public Indexed getAvailableDimensions(）;
public String getSegmentIdentifier(）;
public Sequence makeCursors(Filter filter,
public
public
public
IncrementalIndex是增量索引的核心结构，它实现了Iterable接口，并且支持通过
IncrementalIndex
Metadata支持保持一些自定义的元数据，例如Kafka的实时服务就利用这个数据接口存
Comparable getMaxValue(String column);
Comparable getMinValue(String column);
Interval getInterval();
核心源代码探析
boolean descending);
QueryGranularity gran,
Interval interval,
197
---
## Page 222
protected Integer addToFacts(
198
}else
if （null !=priorIndex）{
Aggregator[] aggs;
final Integer priorIndex= facts.get(key);
对于数据插入部分，
aggs = new Aggregator[metrics.length];
aggs = concurrentGet(priorIndex);
SupplierrowSupplier)throws IndexSizeExceededException
AggregatorFactory[]metrics,
}else
if（null ==prev）{
final Integer prev =facts.putIfAbsent(key,rowIndex);
if (numEntries.get() >= maxRowCount && !facts.containsKey(key)）[
//Last ditch sanity checks
concurrentSet(rowIndex, aggs);
final Integer rowIndex= indexIncrement.getAndIncrement();
rowContainer.set(null);
for（inti=0;irowContainer,
TimeAndDims key,
AtomicInteger numEntries,
InputRow row,
boolean reportParseExceptions,
boolean deserializeComplexMetrics,
numEntries.incrementAndGet();
throw new IndexSizeExceededException(“Maximum number of rows[%d] reached"
aggs[i]=agg.factorize(selectors.get(agg.getName()));
final AggregatorFactory agg = metrics[i];
maxRowCount);
，可以参考Incremental的如下代码片段，其中包括聚合器的使用。
Druid实时大数据分析原理与实践
---
## Page 223
Local 的特点。
第8章核心源代码探析
在聚合过程中使用了aggregate，注意aggregate并没有携带任何参数，这里利用了Thread-
return numEntries.get（）;
rowContainer.set(null);
for（Aggregator agg:aggs）{
rowContainer.set(row);
synchronized （agg){
catch (ParseException e){
try{
//This isexpectedtooccur~80%ofthetime in the worst scenarios
concurrentRemove(rowIndex);
//Freeupthemisfire