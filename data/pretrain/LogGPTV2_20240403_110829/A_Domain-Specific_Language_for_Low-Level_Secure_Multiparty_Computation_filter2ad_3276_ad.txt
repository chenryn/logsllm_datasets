(cid:126)C(cid:127) = i
let x = v in e → e[x (cid:55)→ v]
if C then e1 else e0 → ei
3}
case: v1, v2, v3 → {v1
2, v3
1, v2
1/8−−−→ {b1, b2, b3}
rngBit()
Figure 2: Semantics of the core language
Figure 3: Protocol DSL compiler pipeline
agate bottom values (due to the case-construct introducing them).
However, this is not a problem for us because we are compiling
to an IR in the form of a ﬁnite directed acyclic graph (DAG) with
no control ﬂow constructs. This allows us to eliminate all such in-
eﬃciencies with dead-code elimination, by throwing away bottom
values and the operations that have introduced them. This seman-
tics is the basis for our compiler.
3.3 Compiler implementation
High-level overview of the compilation pipeline is presented in
Fig. 3. The frontend performs, in respective order, lexical analysis,
syntactic analysis, static checking and translation to the low-level
intermediate DAG representation. The IR is optimized, statically
checked for security guarantees and compiled to LLVM [29] code.
The generated LLVM code can in turn be compiled and linked with
Sharemind. The generated code is not tightly coupled to Sharemind
and does not depend at all on Sharemind’s functionality. Instead the
control is inverted, so that the generated code provides meta infor-
mation that Sharemind reads, and callbacks for every computation
round that Sharemind invokes with requested data (received mes-
sages, randomly generated data etc.). Many other SMC systems
can use the generated code given that they are able to send network
messages and provide random numbers.
On the high-level language we perform data type veriﬁcation
and party type veriﬁcation. After static checks we translate the
high-level code to a much simpler code that is based on system Fω
(λ-calculus with type application and type operators). This repre-
sentation is evaluated to a normal form which is converted to the
IR. The IR has well deﬁned syntax and semantics and is optimized
with a separate tool. Security analysis is performed on the IR to
provide additional guarantees that optimizations preserve security.
3.4 Low-level Intermediate Representation
Arithmetic circuits are the IR for our protocol compiler; this rep-
resentation is used for optimizations. An arithmetic circuit is a di-
rected acyclic graph (DAG), where the vertices are labeled with
operations and the incoming edges of each vertex are ordered. The
input nodes of the circuit correspond to the representation of the
inputs to the ABB operation that this protocol implements; in case
of protocol sets based on secret sharing, each input is represented
by a number of nodes equal to the number of the protocol parties.
Similarly, the output nodes correspond to shares of the output.
Communication between parties is expressed implicitly: each
node of the circuit is annotated with the executing party, and an
edge between nodes belonging to diﬀerent parties denotes commu-
nication. Such representation makes both the aspects of computa-
tion (relationships between values) and communication (how many
bits are sent in how many rounds?) in the protocol easily accessible
for analyses and optimizations. The fact that our DAG representa-
tion contains no control-ﬂow constructs or loops makes accurate
analysis and powerful optimizations possible even on large graphs.
To compile the protocols speciﬁed in our protocol DSL to cir-
cuits, loops have to be unrolled, function calls inlined, etc. The
type system and the compiler of the DSL ensure that loop counts
and function call depths (even for recursive functions) are known
during compile time. If the control ﬂow of a protocol requires the
knowledge of (public) data known only at runtime (e.g. the length
of an array), then this protocol cannot be fully speciﬁed in the pro-
tocol DSL and SecreC [6] has to be at least partially used. The
circuit corresponding to the multiplication protocol (Listing 3) is
shown in Fig. 4. Diﬀerent parties are identiﬁed by diﬀerent node
shapes. A solid edge denotes communication. We see that this pro-
tocol requires two rounds, because there are paths in this graph that
contain two solid edges.
3.5 Optimizations
The IR is used to optimize the protocols. Due to the composi-
tional nature of speciﬁcation, the protocols typically contain con-
stants that can be folded, duplicate computations, dead code, etc.
So far, we have implemented all optimizations analogous to the
ones reported in [27] for Boolean circuits (constant propagation,
merging of identical nodes, dead code removal). But as our circuits
are much smaller (the biggest protocols have less than a hundred
thousand nodes), and the arithmetic operations allow much more
information about the computation to be easily gleaned, we have
also successfully run more complex optimizations. We can sim-
plify certain arithmetic expressions, such as linear combinations,
even if communication is involved between operations.
Interestingly, we can move certain computations from one party
to another, or even duplicate computations, if it results in decrease
of communication (which is the bottleneck for current protocols of
Sharemind). In the multiplication protocol in Fig. 4(a), we can re-
duce the number of rounds to 1 by duplicating six subtraction nodes
and assigning them to diﬀerent parties (box → oval → diamond →
box) resulting in the circuit in Fig. 4(b). This does not turn a secure
protocol insecure because it does not make the view of any party
richer than it was. A small downside of the optimization is that
the resulting circuit has more nodes and thus has become slightly
slower to evaluate. This is an exception and in most cases the opti-
mizer reduces the size of circuits by a signiﬁcant margin.
To analyze the reduction in communication we have to view the
total communication as a sum of two parts: online and oﬄine. The
online part consists of communication from nodes that depend on
the inputs of the protocol. The oﬄine part depends only on the
randomly generated values and is a signiﬁcant portion of over-
all communication: the extensively used resharing protocols and
share conversion protocol generate such nodes. The circuit opti-
mizer manages to reduce the amount of online communication in
most of the protocols by a sizable amount (up to 10%) but does not
change the total communication. Table 1 lists the ratios for node
counts and online communication for unoptimized and optimized
DSLFrontendDAGOptimizerLLVMSecurityBackend(a) Generated DAG
(b) Optimized DAG
Figure 4: Multiplication protocol circuit
protocols. The table contains ratios for the following operations:
integer multiplication (mul), bit-shift right by a private (shr) and
by a public (shrc) amount, division with private (div) and pub-
lic divisor (divc), ﬂoating-point addition fadd and multiplication
fmul, ﬂoating-point reciprocal inv, square root sqrt and natural
logarithm ln. Integer operations have only been measured for 64-
bit integers and ﬂoating-point operations only for single-precision
operations. The size ratio of 1.12 for multiplication protocol means
that the optimizer added nodes.
uint64
Size ratio
Online ratio
ﬂoat32
Size ratio
Online ratio
mul
1.12
1.00
fadd
0.77
0.90
shrc
0.84
0.96
fmul
0.86
0.95
shr
0.56
0.99
inv
0.84
0.98
divc
0.90
0.97
sqrt
0.86
0.93
div
0.81
0.97
ln
0.79
0.91
Table 1: Optimizer performance: ratio of code size and online
communication
3.6
Integration with Sharemind
The speciﬁed protocols are used to generate protocol implemen-
tations for the Sharemind platform. While the speciﬁcations are
usually polymorphic in bit-width of the arguments and the result,
the Sharemind protocols work with integers of ﬁxed length. Hence,
together with our protocols we also specify the input and output
widths for which we want the implementations to be generated.
E.g., Sharemind currently has protocols for multiplying 8-, 16-, 32-,
and 64-bit integers.
The protocols are ﬁrst translated to a low-level IR, which is then
compiled to LLVM code. The protocols in Sec. 2 are deﬁned for
scalar values, but Sharemind mostly operates on vectors of values
and thus expects that operations are vectorized. Hence the LLVM
code generation also performs automatic vectorization (this process
does not increase the round count) — the inputs to the protocol are
vectors of values, which are pointwise operated on, and result in a
vector of outputs. The vectorization step is very important because
network latency is orders of magnitude larger than the time to takes
to perform arithmetic operations. E.g. it is an order of magnitude
faster to run the multiplication protocol on thousand elements in
parallel than it is do the same thing iteratively.
In code generation, the necessary communication between par-
ties is derived from the accesses to a party’s values from a diﬀerent
party’s code, which is directly visible in the DAG. Communication
is realized with the help of Sharemind’s networking API, packing
all values communicated at the same round into a single message or
a few messages of suitable length. During the translation to the IR,
all polymorphism is resolved, hence each compiled protocol is used
with values of a particular length and lengths of all exchanged mes-
sages are known at compile-time. The DSL generated protocols are
called through high-level language scripts. High-level SecreC [6]
code is translated to bytecode that the Sharemind virtual machine
evaluates. The bytecode speciﬁes the control ﬂow, the invoked pro-
tocols, and their arguments. The actual invocations are performed
by the virtual machine. This is summarized in Fig. 5.
4. SECURITY
4.1 Security deﬁnitions
The three-party additive secret-sharing based protocol set that
Sharemind uses provides security against one honest-but-curious
party. Security is deﬁned as the indistinguishability of the actual
execution of the protocol from a simulated one. Security implies
that (i) the protocol preserves the privacy of honest parties’ inputs,
and (ii) the protocol delivers correct outputs to all honest parties.
For honest-but-curious adversaries, the second property trivially
+++×××++y1$−−$$y3$+−$$++−+−y2+−−−+××××××x1x2x3$$$+++−+y1$$$y3$$$−−y2×−++−×+×x1x2×$$$−+++−−×−×−××++−−+x3+−++−×++−+−privacy [5]. Against honest-but-curious adversaries, the composi-
tion of a private protocol and a secure protocol (commonly reshar-
ing) is secure [5]. Against malicious adversaries, privacy limits the
amount of information they can learn about the inputs of the proto-
col by interfering with it [37].
A protocol optimization T transforms a protocol π implementing
an ideal functionality F into a new protocol T (π) also implement-
ing F . Each optimization we have implemented in our DSL com-
piler preserves the preservation of privacy — we show that there
exists an ITM T, such that
∀Sim :(cid:2)∀Z,A : Z(cid:107)π(cid:107)A ≈ Z(cid:107)F (cid:107)(Sim(cid:107)A) ⇒
∀Z,A : Z(cid:107)T (π)(cid:107)A ≈ Z(cid:107)F (cid:107)((T(cid:107)Simα)(cid:107)A)(cid:3),
where Simα denotes Sim with renamed tapes, such that it directly
communicates only with T. In eﬀect, if T is a protocol transfor-
mation, then T(cid:107)(·)α is the corresponding simulator transformation
used to transform a security proof of π to a security proof of T (π).
4.2 Proving security of protocols
Our protocol DSL contains no particular mechanisms to stati-
cally ensure the security or privacy of protocols. The type system
of the language only controls the lengths of the values, but not their
dependence on inputs or random variables. Hence we also cannot
speak about security-preserving compilation in the sense of [19].
We ensure the security of the generated protocols using data ﬂow
analysis at the level of the IR. Our compiler pipeline contains the
static analyzer by Pettai and Laud [37] that checks protocols ex-
pressed as arithmetic circuits for privacy against malicious adver-
saries. If a protocol passes that check and we know that it is fol-
lowed by a resharing protocol, then it is also secure against honest-
but-curious adversaries. The check is invoked after the translation
from the protocol DSL to the intermediate language, and the opti-
mization of the generated intermediate code. Having the security
check late in the pipeline ensures that the earlier operations do not
introduce uncaught vulnerabilities.
Our experience with the protocol DSL validates the security as-
pects of the language and compiler design. Indeed, we have found
the writing of secure protocols to be very straightforward. This can
be explained by most of the protocols being written as a composi-
tion of simpler ones. When writing in this style the composition
theorem automatically provides the privacy guarantee. It is very
rare that a protocol is added that is not purely a composition, and
even in this case the automatic privacy checker is there to provide
a safety net and validation for the programmer. In fact, for those
reasons, to implement eﬃcient and secure protocols in the protocol
DSL one does not need to have a deep understanding of the secu-
rity framework of the additive secret sharing scheme. The protocol
implementor never has to show that an implemented protocol is se-
cure: it is often trivially so by virtue of composition and this fact is
always automatically veriﬁed regardless.
5. EXPERIMENTAL RESULTS
We have implemented protocols for integer operations from [8]
and for ﬂoating-point operations from [23]. In this section we ex-
plore the performance of some of these DSL implemented proto-
cols compared to the existing C++ protocol set.