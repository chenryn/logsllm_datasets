the mixture model2. The basic idea is simple and involves considering unobser-
ved latent variables zij. The zij’s take on values 1 or 0 to indicate whether data
point i comes from cluster j’s model or not. The EM algorithm starts with an
initial guess for the parameters of the models for each cluster and then iterati-
2 Actually EM is a very general purpose tool that is applicable to many maximum
likelihood estimation settings (not just clustering).
210
A. McGregor et al.
vely applies a two step process in order to converge to the maximum likelihood
ﬁt. In the expectation step, a soft assignment of each training point to each
cluster is performed—i.e. the current estimates of the parameters are used to
assign cluster membership values according to the relative density of the trai-
ning points under each model. In the maximisation step, these density values are
treated as weights and used in the computation of new weighted estimates for
the parameters of each model. These two steps are repeated until the increase
in log-likelihood (the sum of the log of the density for each training point) of
the data given the current ﬁtted model becomes negligible. The EM algorithm
is guaranteed to converge to a local maximum which may or may not be the
same as the global maximum. It is normal practice to run EM multiple times
with diﬀerent initial settings for the parameter values, and then choose the ﬁnal
clustering with the largest log-likelihood score.
In practical situations there is likely to be more than just a single attribute to
be modelled. One simple extension of the univariate situation described above is
to treat attributes as independent within clusters. In this case the log-densities
for each attribute are summed to form the joint log-density for each data point.
This is the approach taken by our implementation3 of EM. In the case of a no-
minal attribute with v values, a discrete distribution—computed from frequency
counts for the v values—is used in place of a normal distribution. Zero frequency
problems for nominal attributes can be handled by using the Laplace estima-
tor. Of course it is unlikely that the attribute independence assumption holds in
real world data sets. In these cases, where there are known correlations between
attributes, various multivariate distributions can be used instead of the simple
univariate normal and discrete distributions. Using multivariate distributions
increases the number of parameters that have to be estimated, which in turn
increases the risk of overﬁtting the training data.
Another issue to be considered involves choosing the number of clusters to
model. If the number of clusters in the data is not known a-priori then hold-out
data can be used to evaluate the ﬁt obtained by modelling 1, 2, 3, ..., k clusters [4].
The training data can not be used for this purpose because of overﬁtting pro-
blems (i.e. greater numbers of clusters will ﬁt the training data more closely
and will result in better log-likelihood scores). Our implementation of EM has
an option to allow the number of clusters to be found automatically via cross-
validation. Cross-validation is a method for estimating the generalisation perfor-
mance (i.e. the performance on data that has not been seen during training) of
an algorithm based on resampling. The resulting estimates of performance (in
this case the log-likelihood) are often used to select among competing models
(in this case the number of clusters) for a particular problem.
4 Cluster Visualisation
The result of clustering is a grouping of ﬂows. By examining the IAT/packet size
plots it is possible, given enough thought, to make sense of the clusters produced
3 Included as part of the freely available Weka machine learning workbench
(http://www.cs.waikato.ac.nz/ml/weka)
Flow Clustering Using Machine Learning Techniques
211
but this is a diﬃcult process. To aid the interpretation of the meaning of the
clusters, we developed a visualisation based on the Kiviat graph[1]. The six top-
level clusters for one of our sample data sets are shown in ﬁgure 3. Each graph
describes the set of ﬂows in a cluster. The (blue) lines radiating out from the
centre point are axes representing each of the attributes we used for clustering.
The thick part of the axes represents one standard deviation above and below
the mean, the medium thickness lines represent two standard deviations, and the
thin lines represent three standard deviations. Note that, in some cases, the axis
extends beyond the graph plane and has been truncated. The mean point for each
attribute is connected to form the (red) shape in the centre of the graph. Diﬀerent
shapes are characteristic of diﬀerent traﬃc proﬁles. The standard deviation as a
percentage of the mean is shown on each axis. This ﬁgure gives an indication of
how important this attribute is in forming this cluster. If the percentage is high,
then this attribute is likely to be a strong classiﬁer.
The cluster shown in ﬁgure 3(a) contains 59% of the ﬂows in this sample.
In this cluster the mean packet size from the server is about 300 bytes and
has a large standard deviation. The total number of packets is small (especially
remembering the 7 packet overhead of a normal TCP connection). Clients send
about 900 bytes of data and servers send an average of about 2300. The duration
is short (¡1s) and the ﬂow normally stays in transaction mode. This cluster is
mostly typical web traﬃc, fetching small and medium sized objects, for example
HTML pages, icons and other small images.
There are two other similar clusters, clusters 3 and 4, shown in Fig 3(d)
and (e) respectively. These clusters represent a further 20% of ﬂows. Cluster 4
represents larger objects (with a mean server bytes of about 18000 bytes. In
addition to HTTP, quite a lot of SMTP traﬃc is included in this cluster. The
ﬂows in cluster 3 have a signiﬁcant idle time. These are mostly HTTP 1.1 ﬂows
with one or more objects fetched over the same connection. The connection is
held open, in the ideal state, for a time after an object is transfered to give the
client time to request another object.
Cluster ﬁve (Fig. 3(f)) contains classic bulk transfer ﬂows. They are short to
medium term (a mean of 1m 13s) and transfer a lot of data from the server to
the client. Clusters one and two (Fig. 3(b) and (c))are long duration ﬂows with
a lot of idle time. Flows in cluster two have many small packets transfered in
both directions. These are transaction based with multiple transactions in the
ﬂow, separated by signiﬁcant delays. IMAP and NTP are examples. Cluster one
has only a few packets. This is predominantly TCP DNS traﬃc. We suspect this
cluster includes applications where the connection is not correctly terminated.
5 Validation
We are still actively developing the methodology. As part of this process we have
undertaken four types of validation. We looked at the stability of the clusters
within diﬀerent segments of a single trace, comparing the clusters produced
from the whole trace with those produced from half of the trace. Secondly, we
compared two traces from diﬀerent, but similar, locations (the University of
Auckland and The University of Waikato). While there were diﬀerences in the
212
A. McGregor et al.
Proportion of flows in cluster 0: 59% (502857)
Proportion of flows in cluster 1: 4% (41107)
0.000001 (10000.00%)
idleTime
0.768800 (103.08%)
duration
2338.164400 (140.73%)
totalBytes_srv
7266.705500 (139.51%)
duration
7264.681800 (139.56%)
idleTime
1233.052500 (89.82%)
totalBytes_srv
0.065600 (380.03%)
timeInBulk
6.057200 (45.03%)
totalPackets_srv
0.000001 (10000.00%)
timeInBulk
6.803900 (68.25%)
totalPackets_srv
0.219000 (188.86%)
stateChanges
140.675700 (42.49%)
PSMeanClient
921.019400 (55.06%)
totalBytes_client
0.019000 (718.42%)
stateChanges
6.613600 (33.68%)
totalPackets_client
103.114000 (50.25%)
PSMeanClient
815.886700 (86.32%)
totalBytes_client
7.575900 (62.95%)
totalPackets_client
308.066100 (94.17%)
PSMeanServer
0.129600 (127.31%)
MeanIATServer
186.342100 (60.16%)
PSMeanServer
1766.130400 (153.38%)
MeanIATServer
0.226400 (95.98%)
IATvarClient
0.213400 (107.22%)
IATvarServer
(a)
0.125500 (111.71%)
MeanIATClient
1650.884700 (147.52%)
IATvarClient
1744.444200 (153.06%)
MeanIATClient
1635.730900 (149.14%)
IATvarServer
(b)
Proportion of flows in cluster 2: 2% (18326)
Proportion of flows in cluster 3: 12% (108618)
7269.490400 (142.42%)
duration
7252.984500 (142.58%)
idleTime
52016.719300 (229.46%)
totalBytes_srv
41.813200 (85.96%)
idleTime
44.239300 (81.74%)
duration
4534.395700 (148.00%)
totalBytes_srv
2408.096600 (168.08%)
timeInBulk
86.839400 (249.54%)
totalPackets_srv
10.385800 (256.54%)
timeInBulk
9.581700 (65.38%)
totalPackets_srv
8.140600 (305.41%)
stateChanges
124.188300 (93.84%)
PSMeanClient
8000.372400 (300.48%)
totalBytes_client
0.704400 (157.13%)
stateChanges
74.383700 (257.42%)
totalPackets_client
145.455400 (56.51%)
PSMeanClient
1561.308100 (93.04%)
totalBytes_client
10.242400 (55.21%)
totalPackets_client
625.666800 (65.15%)
PSMeanServer
280.016700 (295.87%)
MeanIATServer
349.135600 (98.40%)
PSMeanServer
4.766200 (100.26%)
MeanIATServer
608.487100 (190.48%)
IATvarClient
603.323900 (198.61%)
IATvarServer
(c)
253.750500 (228.71%)
MeanIATClient
8.970900 (98.32%)
IATvarClient
8.944800 (99.17%)
IATvarServer
4.165100 (93.00%)
MeanIATClient
(d)
Proportion of flows in cluster 4: 16% (140707)
Proportion of flows in cluster 5: 4% (37766)
1.697100 (150.48%)
idleTime
4.465200 (74.87%)
duration
18131.339300 (116.83%)
totalBytes_srv
58.330800 (124.11%)
idleTime
73.396300 (118.66%)
duration
126298.499900 (383.46%)
totalBytes_srv
1.609700 (142.23%)
timeInBulk
22.454800 (83.25%)
totalPackets_srv
50.863900 (139.71%)
timeInBulk
154.131900 (271.41%)
totalPackets_srv
0.866600 (73.09%)
stateChanges
144.548600 (87.51%)
PSMeanClient
2487.738300 (97.23%)
totalBytes_client
3.835500 (119.24%)
stateChanges
18.906000 (67.37%)
totalPackets_client
269.225100 (117.59%)
PSMeanClient
46502.217200 (659.80%)
totalBytes_client
122.780500 (288.85%)
totalPackets_client
645.696000 (72.45%)
PSMeanServer
0.361600 (104.81%)
MeanIATServer
760.954700 (60.66%)
PSMeanServer
0.868400 (131.93%)
MeanIATServer
0.708900 (73.97%)
IATvarClient
0.664800 (81.26%)
IATvarServer
(e)
0.386900 (90.51%)
MeanIATClient
5.113800 (111.49%)
IATvarClient
3.823500 (127.79%)
IATvarServer
1.193000 (112.27%)
MeanIATClient
(f)
Fig. 3. Clusters 1 (a), 2 (b) and 4 (c)
Flow Clustering Using Machine Learning Techniques
213
Fig. 4. Ports Across Clusters
statistics of the attributes, both these exercises yielded the same basic set of
clusters, as shown by their Kiviat graphs.
Next we examined the distribution of ports across the clusters. Because port
numbers are indicative of the application in use we expected ports to be focused
on particular clusters. The graphic in Fig 4 shows this distribution for the 20
most common ports. Each stack of bars represents a port with the most common
ports on the left and the least common on the right. The width of the bar
represents the number of ﬂows with that port type, on a logarithmic scale. Each
band represents a cluster, with the largest cluster (cluster 0) at the top, and the
smallest (cluster 2) at the bottom.
The distribution of ports across clusters is less diﬀerentiated than we expec-
ted. There are several reasons for this. First it should be noted that, the log scale
of ﬁgure 4 (which is necessary to allow the visualisation to show more than just
the two or three dominant port types) creates a false impression of the distribu-
tion of ports. The second, and more important reason is one we alluded to in the
introduction, we just under estimated its signiﬁcance. HTTP is the predominant
traﬃc type in these traces. HTTP has a wide range of uses and consequently
there is a signiﬁcant amount of HTTP traﬃc in all clusters.
Finally, we examined whether the algorithm was assigning ﬂows of particular
port types to clusters diﬀerently than a random assignment would. This analysis,
which we can not present here for space reasons, indicated that for most ports
there was good discrimination between clusters but for a few, there was not.
IMAP is one example where the discrimination was poor.
It seems that, the clustering is generally doing a good job of grouping ﬂows
together by their traﬃc type (bulk transfer, small transactions, multiple tran-
sactions etc.) but that individual applications behave more diﬀerently across
diﬀerent connections than we had expected. Even given these reasons, the clu-
stering does not currently meet our needs and we are continuing to develop the
approach, especially through the derivation of new attributes that we believe
214
A. McGregor et al.
will further discriminate between applications. The existence of idle time at the
end of a connection is one example.
6 Conclusion
The initial results of the methodology appear promising. The clusters are sensible
and the clustering and classiﬁcation algorithms indicate that a good ﬁt has been
obtained to the data. Initial analysis indicates that the clusters are stable over a
range of diﬀerent data with the same overall characteristics. The existing clusters
provide an alternative way to disaggregate a packet header stream and we expect
it to prove useful in traﬃc analysis that focuses on a particular traﬃc type. For
example, simulation of TCP optimisations for high performance bulk transfer.
However, further work is required to fully meet our initial goal of clustering
traﬃc into groups that a network manager would recognise as related to the
particular application types on their network.
References
1. Kolence, K., Kiviat, P.: Software Unit Proﬁles and Kiviat Figures. ACM SIGME-
TRICS, Performance Evaluation Review, Vol. 2, No. 3 September (1973) 2–12
2. Witten, I,. and Frank, E., Data Mining: Practical Machine Learning Tools and
Techniques with Java Implementations. Morgan Kaufmann (2000)
3. Hastie, T., Tibshirani, R., and Friedman, J., The Elements of Statistical Learning:
Data Mining, Inference, and Prediction Springer-Verlag (2001)
4. Smyth, P., Clustering Using Monte Carlo Cross-Validation Proceedings of the Se-
cond International Conference on Knowledge Discovery and Data Mining AAAI
Press (1996) 126–133
5. Hartigan, J., Clustering Algorithms John Wiley (1975)
6. Dempster, A., Laird, N., and Rubin, D., Maximum Likelihood from Incomplete
Data Via the EM Algorithm Journal of the Royal Statistical Society Series B, Vol.
30, No. 1 (1977) 1–38
7. http://www.nlanr.net/
8. http://www.wand.net.nz/
9. Claﬀy, K., Braun, H.-W. and Polyzos, G. Internet traﬃc ﬂow proﬁling Ap-
plied Network Research, San Diego Supercomputer Center (1994) Available at:
http://www.caida.org/outreach/papers/
10. Mochalski, K., Micheel, J. and Donnelly, S. Packet Delay and Loss at the Auckland
Internet Access Path Proceedings of the PAM2002 Passive and Active Measure-
ment Conference, Fort Collins, Colorado USA, (2002)