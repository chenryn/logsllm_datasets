title:Fault Tolerant Service Function Chaining
author:Milad Ghaznavi and
Elaheh Jalalpour and
Bernard Wong and
Raouf Boutaba and
Ali Jos&apos;e Mashtizadeh
Fault Tolerant Service Function Chaining
Milad Ghaznavi
University of Waterloo
PI:EMAIL
Elaheh Jalalpour
University of Waterloo
PI:EMAIL
Bernard Wong
University of Waterloo
PI:EMAIL
Raouf Boutaba
University of Waterloo
PI:EMAIL
Ali José Mashtizadeh
University of Waterloo
PI:EMAIL
ABSTRACT
Network traffic typically traverses a sequence of middleboxes form-
ing a service function chain, or simply a chain. Tolerating failures
when they occur along chains is imperative to the availability and
reliability of enterprise applications. Making a chain fault-tolerant
is challenging since, in the event of failures, the state of faulty mid-
dleboxes must be correctly and quickly recovered while providing
high throughput and low latency.
In this paper, we introduce FTC, a system design and protocol
for fault-tolerant service function chaining. FTC provides strong
consistency with up to f middlebox failures for chains of length
f + 1 or longer without requiring dedicated replica nodes. In FTC,
state updates caused by packet processing at a middlebox are col-
lected, piggybacked onto the packet, and sent along the chain to be
replicated. Our evaluation shows that compared with the state of
art [51], FTC improves throughput by 2–3.5× for a chain of two to
five middleboxes.
CCS CONCEPTS
• Computer systems organization → Fault-tolerant network
topologies; • Networks → Middle boxes / network appliances;
KEYWORDS
Service Function Chain Fault Tolerance; Middlebox Reliability
ACM Reference Format:
Milad Ghaznavi, Elaheh Jalalpour, Bernard Wong, Raouf Boutaba, and Ali
José Mashtizadeh. 2020. Fault Tolerant Service Function Chaining. In Annual
conference of the ACM Special Interest Group on Data Communication on the
applications, technologies, architectures, and protocols for computer communi-
cation (SIGCOMM ’20), August 10–14, 2020, Virtual Event, USA. ACM, New
York, NY, USA, 13 pages. https://doi.org/10.1145/3387514.3405863
1 INTRODUCTION
Middleboxes are widely deployed in enterprise networks, with each
providing a specific data plane function. These functions can be
composed to meet high-level service requirements by passing traffic
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
SIGCOMM ’20, August 10–14, 2020, Virtual Event, USA
© 2020 Copyright held by the owner/author(s). Publication rights licensed to the
Association for Computing Machinery.
ACM ISBN 978-1-4503-7955-7/20/08...$15.00
https://doi.org/10.1145/3387514.3405863
through an ordered sequence of middleboxes, forming a service
function chain [45, 46]. For instance, data center traffic commonly
passes through an intrusion detection system, a firewall, and a
network address translator before reaching the Internet [59].
Providing fault tolerance for middleboxes is critical as their fail-
ures have led to large network outages, significant financial losses,
and left networks vulnerable to attacks [11, 44, 55, 56]. Existing
middlebox frameworks [29, 32, 35, 47, 51] have focused on provid-
ing fault tolerance for individual middleboxes. For a chain, they
consider individual middleboxes as fault tolerant units that together
form a fault tolerant chain. This design introduces redundancies
and overheads that can limit a chain’s performance.
Independently replicating the state of each middlebox in a chain
requires a large number replica servers, which can increase cost.
Part of that cost can be mitigated by having middleboxes share the
same replica servers, although oversharing can affect performance.
More importantly, replication causes packets to experience more
than twice its normal delay, since each middlebox synchronously
replicates state updates before releasing a packet to the next mid-
dlebox [29, 32, 35, 47].
Current state-of-the-art middlebox frameworks also stall as they
capture a consistent snapshot of their state leading to lower through-
put and higher latency [35, 47, 51]. These stalls significantly increase
latency with packets experiencing latencies from 400 µs to 9 ms per
middlebox compared to 10–100 µs without fault tolerance [35, 47].
When these frameworks are used in a chain, the stalls cause pro-
cessing delays across the entire chain, similar to a pipeline stall in a
processor. As a result, we observed a ∼40% drop in throughput for
a chain of five middleboxes as compared to a single middlebox (see
§ 7.4).
In this paper, we introduce a system called fault tolerant chaining
(FTC) that provides fault tolerance to an entire chain. FTC is inspired
by chain replication [58] to efficiently provide fault tolerance. At
each middlebox, FTC collects state updates due to packet processing
and piggybacks them onto the packet. As the packet passes through
the chain, FTC replicates piggybacked state updates in servers
hosting middleboxes. This allows each server hosting a middlebox
to act as a replica for its predecessor middleboxes. If a middlebox
fails, FTC can recover the lost state from its successor servers. For
middleboxes at the end of the chain, FTC transfers and replicates
their state updates in servers hosting middleboxes at the beginning
of the chain. FTC does not need any dedicated replica servers to
tolerate f number of middlebox failures for chains with more than
f + 1 middleboxes.
We extend chain replication [58] to address challenges unique
to a service function chain. Unlike the original protocol where all
SIGCOMM ’20, August 10–14, 2020, Virtual Event, USA
nodes run an identical process, FTC must support a chain comprised
of different middleboxes processing traffic in the service function
chain order. Accordingly, FTC allows all servers to process traffic
and replicate state. Moreover, FTC’s failure recovery instantiates a
new middlebox at the failure position to maintain the service func-
tion chain order, rather than the traditional protocol that appends
a new node at the end of a chain.
Furthermore, FTC improves the performance of fault tolerant
multicore middleboxes. We introduce packet transactions to provide
a simple programming model to develop multithreaded middleboxes
that can effectively make use of multiple cores. Concurrent state
updates to middlebox state result in non-deterministic behavior that
is hard to restore. A transactional model for state updates allows
serializing concurrent state accesses that simplifies reasoning about
both middlebox and FTC correctness. The state-of-the-art [51] relies
on complex static analysis that supports unmodified applications,
but can have worse performance when its analysis falls short.
FTC also tracks dependencies among transactions using data
dependency vectors that define a partial ordering of transactions.
The partial ordering allows a replica to concurrently apply state
updates from non-dependent transactions to improve replication
performance. This approach has two major benefits compared to
thread-based approaches that allow concurrent state replication by
replaying the operations of threads [51]. First, FTC can support ver-
tical scaling by replacing a running middlebox with a new instance
with more CPU cores or failing over to a server with fewer CPU
cores when resources are scarce during a major outage. Second, it
enables a middlebox and its replicas to run with a different number
of threads.
FTC is implemented on Click [34] and uses the ONOS SDN
controller [7]. We compare its performance with the state-of-the-
art [51]. Our results for a chain of two to five middleboxes show
that FTC improves the throughput of the state of art [51] by 2× to
3.5× with lower latency per middlebox.
2 BACKGROUND
A service function chain is an ordered sequence of middleboxes.
Following the network function virtualization (NFV) vision [1], an
increasing number of middleboxes are implemented as software
running on commodity hardware.
In an NFV environment, as shown in Figure 1, an orchestrator
deploys, manages, and steers traffic through a chain of middleboxes.
Each middlebox runs multiple threads and is equipped with a multi-
queue network interface card (NIC) [15, 42, 50]. A thread receives
packets from a NIC’s input queue and sends packets to a NIC’s
output queue. Figure 1 shows two threaded middleboxes processing
two traffic flows.
Stateful middleboxes keep dynamic state for packets that they
process [24, 52]. For instance, a stateful firewall filters packets based
on statistics that it collects for network flows [6], and a network
address translator maps internal and external addresses using a
flow table [25, 53].
Middlebox state can be partitionable or shared [6, 20, 23, 47].
Partitionable state variables describe the state of a single traffic flow
(e.g., MTU size and timeouts in stateful firewalls [6, 20]) and are only
accessed by a single middlebox thread. Shared state variables are
Figure 1: Service function chain model in NFV
for a collection of flows, and multiple middlebox threads query and
update them (e.g., port-counts in an intrusion detection system).
A stateful middlebox is subject to both hardware and software
failures that can cause the loss of its state [44, 51]. The root causes
of these failures include bit corruptions, cable problems, software
bugs, and server failures due to maintenance operations and power
failures [22, 44]. We model these failures as fail-stop in which fail-
ures are detectable, and failed components are not restored.
2.1 Challenges
To recover from a middlebox failure, traffic must be rerouted to
a redundant middlebox where the state of the failed middlebox is
restored. State replication has two challenges that affect middlebox
performance.
First, most middleboxes are multithreaded [15, 26, 50, 51], and
the order in which interleaving threads access shared state is non-
deterministic. Parallel updates can lead to observable states that
are hard-to-restore. The difficulty in achieving high performance
multithreaded middleboxes is how we capture this state for recovery.
One approach to accommodate non-determinism is to log any state
read and write, which allows restoring any observable state from the
logs [51]. However, this complicates the failure recovery procedure
because of record/replay, and leads to high performance overheads
during normal operation.
Second, to tolerate f failures, a packet is released only when at
least f +1 replicas acknowledge that state updates due to processing
of this packet are replicated. In addition to increasing latency, syn-
chronous replication reduces throughput since expensive coordina-
tions between packet processing and state replication are required
for consistency (e.g., pausing packet processing until replication is
acknowledged [29, 32, 35, 47]). The overhead of this synchrony for a
middlebox depends on where its replicas are located, and how state
updates are transferred to these locations. For a solution designed
for individual middleboxes, the overheads can accumulate for each
middlebox of a chain.
2.2 Limitations of Existing Approaches
Existing middlebox frameworks provide fault tolerance for individ-
ual middleboxes. These frameworks provide fault tolerance for a
Orchestrator!"!"Middlebox!"!"!"!"!"!"PacketSDN NetworkFault Tolerant Service Function Chaining
SIGCOMM ’20, August 10–14, 2020, Virtual Event, USA
chain with middleboxes deployed over multiple servers; however,
their high overheads impact the chain’s performance.
Existing frameworks use one of two approaches. The first ap-
proach takes snapshots of middlebox state for state replication [35,
47, 51]. While taking snapshot, middlebox operations are stalled
for consistency. These frameworks take snapshots at different rates.
They take snapshots per packet or packet-batch introducing 400 µs
to 8–9 ms of per packet latency overhead [35, 47]. Periodic snap-
shots (e.g., at every 20–200 ms intervals) can cause periodic latency
spikes up to 6 ms [51]. We measure that per middlebox snapshots
cause 40% throughput drop going from a single middlebox to a
chain of five middleboxes (see § 7.4).
The second approach [29, 32] redesigns middleboxes to separate
and push state into a fault tolerant backend data store. This sepa-
ration incurs high performance penalties. Accessing state takes at
least a round trip delay. Moreover, a middlebox can release a packet
only when it receives an acknowledgement from the data store
that relevant state updates are replicated. Due to such overheads,
the middlebox throughput can drop by ∼60% [29] and reduce to
0.5 Gbps (for packets with 1434 B median size) [32].
3 SYSTEM DESIGN OVERVIEW
The limitations of existing work lead us to design fault tolerant
chaining (FTC); a new approach that replicates state along the chain
to provide fault tolerance.
3.1 Requirements
We design FTC to provide fault tolerance for a wide variety of
middleboxes. FTC adheres to four requirements:
Correct recovery: FTC ensures that the middlebox behavior after
a failure recovery is consistent with the behavior prior to the fail-
ure [54]. To tolerate f failures, a packet can only be released outside
of a chain once all necessary information needed to reconstruct the
internal state of all middleboxes is replicated to f + 1 servers.
Low overhead and fast failure recovery: Fault tolerance for a chain
must come with low overhead. A chain processes a high traffic vol-
ume and middlebox state can be modified very frequently. At each
middlebox of a chain, latency should be within 10 to 100 µs [51],
and the fault tolerance mechanism must support accessing vari-
ables 100 k to 1 M times per second [51]. Recovery time must be
short enough to prevent application outages. For instance, highly
available services timeout in just a few seconds [3].
Resource efficiency: Finally, the fault tolerance solution should be
resource efficient. To isolate the effect of possible failures, replicas of
a middlebox must be deployed on separate physical servers. We are
interested in a system that dedicates the fewest servers to achieve
a fixed replication factor.
3.2 Design Choices
We model packet processing as a transaction. FTC carefully col-