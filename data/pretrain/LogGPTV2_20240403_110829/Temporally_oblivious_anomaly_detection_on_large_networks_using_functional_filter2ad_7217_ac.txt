volume was always less than the incoming traﬃc. This
may imply a DDoS for which the server is unable to
keep up with requests.
Cluster 4: The hosts in this cluster behaved similarly to
those in Cluster 2; receiving low volumes of traﬃc
while sending signiﬁcantly larger ones. This cluster
is diﬀerentiated by the fact that no host sent traﬃc to
more IP addresses than it received traﬃc from. In fact,
66% of the 154 hosts sent traﬃc to fewer hosts. There
was an additional group within this cluster of hosts
that received traﬃc from a few sources, comprised of
large numbers of small byte packets in a minimal num-
ber of ﬂows, yet still sent a large volume of traﬃc in
return, approaching the maximum transmission unit
(MTU) size of the network (1,500 bytes/packet). This
appears to be large ﬁle-transfer traﬃc, which would ex-
plain the large outgoing packet sizes, low ﬂow counts,
and small incoming packet sizes (which would simply
by ACKs by the external host).
Our cluster descriptions provide a high-level understanding
of the diﬀerent types of detected anomalies. While there
were many “repeat oﬀenders”, 172 of the 1,658 anomalies
were attributed to unique IP addresses, and each cluster
contained at minimum 39 unique IP addresses. A ﬁner cat-
egorical granularity can be achieved by simply decreasing
the cutoﬀ threshold for the hierarchical cluster tree. For ex-
ample, when reducing the threshold to 1.2, Cluster 1 is now
split into the three clusters we previously observed as shown
in Fig. 3
3.1 Classifying New Anomalies
If new anomalies could be detected without a new cluster-
ing analysis, the qualitative categorization presented would
be of high value to analysts; abstracting them from the tech-
nical and statistical details concerning clustering. By train-
ing classiﬁers on anomalies detected over a period of time,
we can provide a label along with a conﬁdence for each newly
detected anomaly. In the absence of ground truth, we de-
velop our classiﬁer by using the previously clustered anoma-
lies as our training set. For this study, we train on the
high-level cluster labels represented in Fig. 3 (four classes),
and implement a simple linear classiﬁer on the normalized
anomaly data; choosing decision boundaries via linear dis-
criminant analysis. This results in a 1.69% classiﬁcation
error on the training set. Note that this error is in classi-
fying hosts which have already been ﬂagged as anomalous,
so there is a drastically lower cost for misclassiﬁcation than
with a traditional IDS.
We test this classiﬁer over seven days of traﬃc occurring
8 weeks after the data we trained on. We normalize the
newly ﬂagged anomalous data in the same manner, still us-
ing the f50 and f90 values from the training data in order
to preserve the appropriate scaling. There were 2,411 out
of a possible 1.4 million hosts ﬂagged during this testing
period, yielding an average of 1.24 hosts being ﬂagged as
anomalous during an observation window. After classifying
each anomaly, we note that the types of activity in each
class are consistent with those during the training period.
We can quantify the conﬁdence c(x) in these labels by us-
ing the posterior probability that a sample xi belongs to a
speciﬁc class Cj, which is denoted as P(Cj | xi). As each
sample is labeled according to the class Cj which maximizes
this value, we can set the conﬁdence of our classiﬁcation la-
bel as c(xi) = maxj P(Cj | xi). For the test data, 95.5%
of the detected anomalies had c(x) > 90%, conﬁrming that
the general categories of anomalies on the network did not
change. It is worth noting that 66% of the anomalies de-
tected during this testing phase were from IP addresses that
were never ﬂagged as anomalous during the training phase.
It is not simply the same hosts consistently exhibiting the
same anomalous behavior, but diﬀerent hosts behaving in
manners which fall under persistent categorizations. There
was one sample with a conﬁdence of < 50% (c(x) = 42%). A
sample with a conﬁdence this low may represent a new cat-
egory of anomaly, and a method for culling this information
automatically is an area for future work.
4. DISCUSSION
We’ve presented what we deem to be very promising re-
sults, yet our work has a few shortcomings which we now
address. First, while we provide intuition for our chosen pa-
rameter values, α and n, a more rigorous approach would
be necessary for a full deployment. Given the nature of
anomalies, and their lack of expert-deﬁned labels, there is
no straightforward way to deﬁne these parameters in an au-
tomated fashion. A network administrator deploying a sys-
tem such as ours would have to train the parameters to yield
an “acceptable” amount of alerts per observation period, as
is done in many IDS and anomaly detection systems, and
determine which classes of anomalous traﬃc are potentially
benign. The detected anomalies could then be ﬁltered based
on their class and network knowledge (eg. NATs) to reduce
the alerts an analyst must investigate.
There is a chance that a previously unseen anomaly could
occur which is not accurately described by the previously
trained classiﬁer. This is the nature of anomaly detection,
yet our system has the tools to account for this. Speciﬁcally,
the classiﬁcation conﬁdence of such an anomaly would be
predictably low (as shown in Section 3.1), and these types
of anomalies could be saved for retraining the system. As
with any classiﬁer, periodic retraining is necessary if the
statistics of the feature space change, and that will almost
always be the case for network data. It is future work to
determine how often this retraining would be necessary.
While our method is speciﬁcally not an IDS, we realize
that anomaly detection is often used for that purpose and
we want to detail how an adversary could circumvent this
system. A sophisticated attack could have an adversary in-
tentionally manipulate the traﬃc of multiple servers at the
same time in the same manner, causing them to form a
large enough group in the feature space that would not be
deemed anomalous. This would require knowledge of the
algorithm parameters, speciﬁcally the minimum cluster size
n, and would also increase the required resources for the
adversary.
4695. CONCLUSIONS
In this paper we have described a temporally-oblivious
approach for detecting anomalous hosts on large-scale net-
works. By modeling the behavior of functional peers, anoma-
lies stand out and can be described by a small set of qual-
itative characterizations. The fact that anomalous activity,
which by deﬁnition is signiﬁcantly abnormal, is categorically
consistent over time is intriguing. We utilized this discovery
to develop a labeling system for anomalies discovered during
new observation periods. This framework was trained over
seven days and tested over an additional seven days nearly
2 months later, with very similar results.
This work is presented as a proof-of-concept of a novel
method of detecting anomalies. We note that hierarchi-
cal clustering is an O(N 2) operation, meaning that it will
not purely scale to large N . This is why we operate our
system on a per service basis, focusing on port 80 in this
study. While port numbers do not restrict activity, many
are reserved for speciﬁed functions, so this split is logical
for anomaly detection. Since networks are made of a ﬁnite
number of services of interest, this split also enables scal-
ing to very large-scale networks. Determining a manner to
cluster across services is an area for future work. Addition-
ally, we would like to identify clusters of activity within the
non-anomalous traﬃc, seeing whether these clusters remain
consistent over time in a similar fashion as the clusters of
anomalous activity. This naturally lends itself to many re-
search areas in network behavioral analysis. The nature of
the clusters themselves provides network situational aware-
ness, and identifying the movement of hosts between clusters
could provide additional information.
Acknowledgements
We would like to thank the reviewers for their thoughtful
comments and William W. Streilein of MIT Lincoln Labo-
ratory for his help with our normalization methods.
4706. REFERENCES
[1] Cisco netﬂow. http://www.cisco.com.
[2] Barford, P., Kline, J., Plonka, D., and Ron, A.
A signal analysis of network traﬃc anomalies. In
Internet Measurement Workshop (2002), pp. 71–82.
[3] Brauckhoff, D., Wagner, A., and Salamatian,
K. Anomaly extraction in backbone networks using
association rules. In Proceedings of 9th ACM
SIGCOMM Internet Measurement Conference (2009),
pp. 28–34.
[4] Carl, G., Kesidis, G., Brooks, R. R., and Rai, S.
Denial-of-service attack-detection techniques. In IEEE
Internet Computing (Jan./Feb. 2006), vol. 10,
pp. 82–89.
[5] CERT/NetSA at Carnegie Mellon University.
SiLK (System for Internet-Level Knowledge). [Online].
Available: http://tools.netsa.cert.org/silk.
[6] Collins, M. P., and Reiter, M. K. Hit-list worm
detection and bot identiﬁcation in large networks
using protocol graphs. In Proceedings ofthe 10th
International Symposium on Recent Advances in
Intrusion Detection (RAID) (2007).
[7] Collins, M. P., and Reiter, M. K. On the limits of
payload-oblivious network attack detection. In
Proceedings of 11th International Symposium on
Recent Advances in Intrusion Detection (RAID)
(2008), pp. 251–270.
[8] Gu, G., Perdisci, R., Zhang, J., and Lee, W.
Botminer: Clustering analysis of network traﬃc for
protocol- and structure-independent botnet detection.
In Proceedings of 17th USENIX Security Symposium
(2008), pp. 139–154.
[9] Hastie, T., Tibshirani, R., and Friedman, J. The
Elements of Statistical Learning. Springer, July 2003.
[10] Lakhina, A., Crovella, M., and Diot, C.
Characterization of network-wide anomalies in traﬃc
ﬂows. In Proceedings of ACM/SIGCOMM Internet
Measurement Conference (2004), pp. 201–206.
[11] Lakhina, A., Crovella, M., and Diot, C.
Diagnosing network-wide traﬃc anomalies. In
Proceedings of ACM SIGCOMM (2004), pp. 219–230.
[12] Li, X., Bian, F., Crovella, M., Diot, C.,
Govindan, R., Iannaccone, G., and Lakhina, A.
Detection and identiﬁcation of network anomalies
using sketch subspaces. In Proceedings of 6th ACM
SIGCOMM Conference on Internet Measurement
(2006), pp. 147–152.
[13] Moore, A. W., and Zuev, D. Internet traﬃc
classiﬁcation using bayesian analysis techniques. In
Proceedings of 2005 ACM SIGMETRICS
International Conference on Measurement and
Modeling of Computer Systems (2005), pp. 50–60.
[14] Moore, D., Voelker, G., and Savage, S. Inferring
internet denial-of-service activity. In Proceedings of the
10th Usenix Security Symposium (2001), pp. 9–22.
[15] Nychis, G., Sekar, V., Andersen, D. G., Kim, H.,
and Zhang, H. An emperical evaluation of
entropy-based traﬃc anomaly detection. In
Proceedings of 8th ACM SIGCOMM Conference on
Internet Measurement (Oct. 2008), pp. 151–156.
[16] Paxson, V. Bro: A system for detecting network
intruders in real-time. Computer Networks 31, 23–24
(1999), 2435–2463.
[17] Roesch, M. Snort - lightweight intrusion detection for
networks. In Proceedings of 13th LISA Conference
(1999), pp. 229–238.
[18] Schechter, S. E., Jung, J., and Berger, A. W.
,
Fast detection of scanning worm infections. In
Proceedings of the 7th International Symposium on
Recent Advances in Intrusion Detection (RAID)
(2004), pp. 59–81.
[19] Sebaugh, J. L., and McCray, P. D. Deﬁning the
linear portion of a sigmoid-shaped curve: Bend points.
In Pharmaceutical Statistics, vol. 2. 2003, pp. 167–174.
[20] Sommer, R., and Paxson, V. Outside the closed
world: On using machine learning for network
intrusion detection. In Proceedings of 31st IEEE
Symposium on Security and Privacy (May 2010).
[21] Subhabrata, B. K., Krishnamurthy, E., Sen, S.,
Zhang, Y., and Chen, Y. Sketch-based change
detection: Methods, evaluation, and applications. In
Proceedings of ACM SIGCOMM Internet
Measurement Conference (2003), pp. 234–247.
[22] Thottan, M., and Ji, C. Anomaly detection in ip
networks. IEEE Transactions on Signal Processing 51
8 (Aug. 2003), 2191–2204.
[23] Wang, H., Zhang, D., and Shin, K. G. Detecting
syn ﬂooding attacks. In Proceedings of the IEEE
Infocom (2002), pp. 1530–1539.
471