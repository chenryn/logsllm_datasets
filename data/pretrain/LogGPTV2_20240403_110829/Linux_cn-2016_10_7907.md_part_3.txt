一旦我们完成 `assemble.py` 脚本文件，我们可以运行 `python assemble.py` 命令。你可以[在这里](https://github.com/dataquestio/loan-prediction/blob/master/assemble.py)查看完整的 `assemble.py` 文件。
这将会在 `processed` 目录下产生 2 个文件：
```
loan-prediction
├── data
│   ├── Acquisition_2012Q1.txt
│   ├── Acquisition_2012Q2.txt
│   ├── Performance_2012Q1.txt
│   ├── Performance_2012Q2.txt
│   └── ...
├── processed
│   ├── Acquisition.txt
│   ├── Performance.txt
├── .gitignore
├── assemble.py
├── README.md
├── requirements.txt
├── settings.py
```
### 计算来自执行数据的值
接下来我们会计算来自 `processed/Performance.txt` 中的值。我们要做的就是推测这些资产是否被取消赎回权。如果能够计算出来，我们只要看一下关联到贷款的执行数据的参数 `foreclosure_date` 就可以了。如果这个参数的值是 `None`，那么这些资产肯定没有收回。为了避免我们的样例中只有少量的执行数据，我们会为每个贷款计算出执行数据文件中的行数。这样我们就能够从我们的训练数据中筛选出贷款数据，排除了一些执行数据。
下面是我认为贷款数据和执行数据的关系：
![](/data/attachment/album/201610/28/101352pqj44fnouqvo45nx.jpg)
在上面的表格中，贷款数据中的每一行数据都关联到执行数据中的多行数据。在执行数据中，在取消赎回权的时候 `foreclosure_date` 就会出现在该季度，而之前它是空的。一些贷款还没有被取消赎回权，所以与执行数据中的贷款数据有关的行在 `foreclosure_date` 列都是空格。
我们需要计算 `foreclosure_status` 的值，它的值是布尔类型，可以表示一个特殊的贷款数据 `id` 是否被取消赎回权过，还有一个参数 `performance_count` ，它记录了执行数据中每个贷款 `id` 出现的行数。 
计算这些行数有多种不同的方法：
* 我们能够读取所有的执行数据，然后我们用 Pandas 的 [groupby](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html) 方法在 DataFrame 中计算出与每个贷款 `id` 有关的行的行数，然后就可以查看贷款 `id` 的 `foreclosure_date` 值是否为 `None` 。
	+ 这种方法的优点是从语法上来说容易执行。
	+ 它的缺点需要读取所有的 129236094 行数据，这样就会占用大量内存，并且运行起来极慢。
* 我们可以读取所有的执行数据，然后在贷款 DataFrame 上使用 [apply](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html) 去计算每个贷款 `id` 出现的次数。
	+ 这种方法的优点是容易理解。
	+ 缺点是需要读取所有的 129236094 行数据。这样会占用大量内存，并且运行起来极慢。
* 我们可以在迭代访问执行数据中的每一行数据，而且会建立一个单独的计数字典。
	+ 这种方法的优点是数据不需要被加载到内存中，所以运行起来会很快且不需要占用内存。
	+ 缺点是这样的话理解和执行上可能有点耗费时间，我们需要对每一行数据进行语法分析。
加载所有的数据会非常耗费内存，所以我们采用第三种方法。我们要做的就是迭代执行数据中的每一行数据，然后为每一个贷款 `id` 在字典中保留一个计数。在这个字典中，我们会计算出贷款 `id` 在执行数据中出现的次数，而且看看 `foreclosure_date` 是否是 `None` 。我们可以查看 `foreclosure_status` 和 `performance_count` 的值 。
我们会新建一个 `annotate.py` 文件，文件中的代码可以计算这些值。我们会使用下面的代码：
* 导入需要的库
* 定义一个函数 `count_performance_rows` 。
	+ 打开 `processed/Performance.txt` 文件。这不是在内存中读取文件而是打开了一个文件标识符，这个标识符可以用来以行为单位读取文件。
	+ 迭代文件的每一行数据。
	+ 使用分隔符`|`分开每行的不同数据。
	+ 检查 `loan_id` 是否在计数字典中。
		- 如果不存在，把它加进去。
	+ `loan_id` 的 `performance_count` 参数自增 1 次，因为我们这次迭代也包含其中。
	+ 如果 `date` 不是 `None ，我们就会知道贷款被取消赎回权了，然后为`foreclosure\_status` 设置合适的值。
```
import os
import settings
import pandas as pd
def count_performance_rows():
    counts = {}
    with open(os.path.join(settings.PROCESSED_DIR, "Performance.txt"), 'r') as f:
        for i, line in enumerate(f):
            if i == 0:
                # Skip header row
                continue
            loan_id, date = line.split("|")
            loan_id = int(loan_id)
            if loan_id not in counts:
                counts[loan_id] = {
                    "foreclosure_status": False,
                    "performance_count": 0
                }
            counts[loan_id]["performance_count"] += 1
            if len(date.strip()) > 0:
                counts[loan_id]["foreclosure_status"] = True
    return counts
```
### 获取值
只要我们创建了计数字典，我们就可以使用一个函数通过一个 `loan_id` 和一个 `key` 从字典中提取到需要的参数的值：
```
def get_performance_summary_value(loan_id, key, counts):
    value = counts.get(loan_id, {
        "foreclosure_status": False,
        "performance_count": 0
    })
    return value[key]
```
上面的函数会从 `counts` 字典中返回合适的值，我们也能够为贷款数据中的每一行赋一个 `foreclosure_status` 值和一个 `performance_count` 值。如果键不存在，字典的 [get](https://docs.python.org/3/library/stdtypes.html#dict.get) 方法会返回一个默认值，所以在字典中不存在键的时候我们就可以得到一个可知的默认值。
### 转换数据
我们已经在 `annotate.py` 中添加了一些功能，现在我们来看一看数据文件。我们需要将贷款到的数据转换到训练数据集来进行机器学习算法的训练。这涉及到以下几件事情:
* 转换所有列为数字。
* 填充缺失值。
* 为每一行分配 `performance_count` 和 `foreclosure_status`。
* 移除出现执行数据很少的行（`performance_count` 计数低）。
我们有几个列是文本类型的，看起来对于机器学习算法来说并不是很有用。然而，它们实际上是分类变量，其中有很多不同的类别代码，例如 `R`，`S` 等等. 我们可以把这些类别标签转换为数值：
![](/data/attachment/album/201610/28/101451p3xmfd34fyfq0xf5.jpg)
通过这种方法转换的列我们可以应用到机器学习算法中。
还有一些包含日期的列 (`first_payment_date` 和 `origination_date`）。我们可以将这些日期放到两个列中：
![](/data/attachment/album/201610/28/101502gn0icuiiziiug5ez.jpg)
在下面的代码中，我们将转换贷款数据。我们将定义一个函数如下：
* 在 `acquisition` 中创建 `foreclosure_status` 列，并从 `counts` 字典中得到值。
* 在 `acquisition` 中创建 `performance_count` 列，并从 `counts` 字典中得到值。
* 将下面的列从字符串转换为整数：
	+ `channel`
	+ `seller`
	+ `first_time_homebuyer`
	+ `loan_purpose`
	+ `property_type`
	+ `occupancy_status`
	+ `property_state`
	+ `product_type`
* 将 `first_payment_date` 和 `origination_date` 分别转换为两列：
	+ 通过斜杠分离列。
	+ 将第一部分分离成 `month` 列。
	+ 将第二部分分离成 `year` 列。
	+ 删除该列。
	+ 最后，我们得到 `first_payment_month`、`first_payment_year`、`rigination_month` 和 `origination_year`。
* 所有缺失值填充为 `-1`。
```
def annotate(acquisition, counts):
    acquisition["foreclosure_status"] = acquisition["id"].apply(lambda x: get_performance_summary_value(x, "foreclosure_status", counts))
    acquisition["performance_count"] = acquisition["id"].apply(lambda x: get_performance_summary_value(x, "performance_count", counts))
    for column in [
        "channel",
        "seller",
        "first_time_homebuyer",
        "loan_purpose",
        "property_type",
        "occupancy_status",
        "property_state",
        "product_type"
    ]:
        acquisition[column] = acquisition[column].astype('category').cat.codes
    for start in ["first_payment", "origination"]:
        column = "{}_date".format(start)
        acquisition["{}_year".format(start)] = pd.to_numeric(acquisition[column].str.split('/').str.get(1))
        acquisition["{}_month".format(start)] = pd.to_numeric(acquisition[column].str.split('/').str.get(0))
        del acquisition[column]
    acquisition = acquisition.fillna(-1)
    acquisition = acquisition[acquisition["performance_count"] > settings.MINIMUM_TRACKING_QUARTERS]
    return acquisition
```
### 聚合到一起
我们差不多准备就绪了，我们只需要再在 `annotate.py` 添加一点点代码。在下面代码中，我们将：
* 定义一个函数来读取贷款的数据。
* 定义一个函数来写入处理过的数据到 `processed/train.csv`。
* 如果该文件在命令行以 `python annotate.py` 的方式运行：
	+ 读取贷款数据。
	+ 计算执行数据的计数，并将其赋予 `counts`。
	+ 转换 `acquisition` DataFrame。
	+ 将`acquisition` DataFrame 写入到 `train.csv`。
```
def read():
    acquisition = pd.read_csv(os.path.join(settings.PROCESSED_DIR, "Acquisition.txt"), sep="|")
    return acquisition
def write(acquisition):
    acquisition.to_csv(os.path.join(settings.PROCESSED_DIR, "train.csv"), index=False)
if __name__ == "__main__":
    acquisition = read()
    counts = count_performance_rows()
    acquisition = annotate(acquisition, counts)
    write(acquisition)
```
修改完成以后，确保运行 `python annotate.py` 来生成 `train.csv` 文件。 你可以在[这里](https://github.com/dataquestio/loan-prediction/blob/master/annotate.py)找到完整的 `annotate.py` 文件。
现在文件夹看起来应该像这样：
```
loan-prediction
├── data
│   ├── Acquisition_2012Q1.txt
│   ├── Acquisition_2012Q2.txt
│   ├── Performance_2012Q1.txt
│   ├── Performance_2012Q2.txt
│   └── ...
├── processed
│   ├── Acquisition.txt
│   ├── Performance.txt
│   ├── train.csv
├── .gitignore
├── annotate.py
├── assemble.py
├── README.md
├── requirements.txt
├── settings.py
```