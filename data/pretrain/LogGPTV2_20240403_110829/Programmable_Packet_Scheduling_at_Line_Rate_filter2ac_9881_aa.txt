title:Programmable Packet Scheduling at Line Rate
author:Anirudh Sivaraman and
Suvinay Subramanian and
Mohammad Alizadeh and
Sharad Chole and
Shang-Tse Chuang and
Anurag Agrawal and
Hari Balakrishnan and
Tom Edsall and
Sachin Katti and
Nick McKeown
Programmable Packet Scheduling at Line Rate
Anirudh Sivaraman*, Suvinay Subramanian*, Mohammad Alizadeh*, Sharad Chole‡, Shang-Tse Chuang‡, Anurag Agrawal†,
Hari Balakrishnan*, Tom Edsall‡, Sachin Katti+, Nick McKeown+
*MIT CSAIL, †Barefoot Networks, ‡Cisco Systems, +Stanford University
ABSTRACT
Switches today provide a small menu of scheduling algo-
rithms. While we can tweak scheduling parameters, we
cannot modify algorithmic logic, or add a completely new
algorithm, after the switch has been designed. This pa-
per presents a design for a programmable packet scheduler,
which allows scheduling algorithms—potentially algorithms
that are unknown today—to be programmed into a switch
without requiring hardware redesign.
Our design uses the property that scheduling algorithms
make two decisions: in what order to schedule packets and
when to schedule them. Further, we observe that in many
scheduling algorithms, deﬁnitive decisions on these two
questions can be made when packets are enqueued. We use
these observations to build a programmable scheduler using
a single abstraction:
the push-in ﬁrst-out queue (PIFO), a
priority queue that maintains the scheduling order or time.
We show that a PIFO-based scheduler lets us program a
wide variety of scheduling algorithms. We present a hard-
ware design for this scheduler for a 64-port 10 Gbit/s shared-
memory (output-queued) switch. Our design costs an addi-
tional 4% in chip area. In return, it lets us program many so-
phisticated algorithms, such as a 5-level hierarchical sched-
uler with programmable decisions at each level.
CCS Concepts
•Networks → Programmable networks;
Keywords
Programmable scheduling; switch hardware
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than the author(s) must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22 - 26, 2016, Florianopolis , Brazil
© 2016 Copyright held by the owner/author(s). Publication rights licensed to
ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2934899
1.
INTRODUCTION
Today’s fastest switches, also known as line-rate switches,
provide a small menu of scheduling algorithms: typically,
a combination of Deﬁcit Round Robin [36], strict priority
scheduling, and trafﬁc shaping. A network operator can
change parameters in these algorithms, but cannot change
the core logic in an existing algorithm, or program a new
one, without building new switch hardware.
By contrast, with a programmable packet scheduler, net-
work operators could customize scheduling algorithms to
application requirements, e.g., minimizing ﬂow completion
times [12] using Shortest Remaining Processing Time [35],
allocating bandwidth ﬂexibly across ﬂows or tenants [26,
33] using Weighted Fair Queueing [20], minimizing tail
packet delays using Least Slack Time First [29], etc. More-
over, with a programmable packet scheduler, switch vendors
could implement scheduling algorithms as programs running
on a programmable switching chip, making it easier to ver-
ify and modify these algorithms compared to baking in the
same algorithms into a chip as rigid hardware.
This paper presents a design for programmable packet
scheduling in line-rate switches. All scheduling algorithms
in what order packets should
make two basic decisions:
be scheduled and when they should be scheduled, corre-
sponding to work-conserving and non-work-conserving al-
gorithms respectively. Furthermore, for many scheduling al-
gorithms, these two decisions can be made when a packet
is enqueued. This observation suggests a natural hardware
primitive for packet scheduling: a push-in ﬁrst-out queue
(PIFO) [19, 38]. A PIFO is a priority queue that allows el-
ements to be pushed into an arbitrary position based on an
element’s rank (the scheduling order or time),1 but always
dequeues elements from the head.
We develop a programming model for scheduling (§2)
based on PIFOs with two key ideas. First, we allow users to
set a packet’s rank in a PIFO by supplying a small program
for computing packet ranks (§2.1). Coupling this program
with a single PIFO allows the user to program any schedul-
ing algorithm where the relative scheduling order of buffered
packets does not change with future packet arrivals. Sec-
ond, users can compose PIFOs together in a tree to program
1When the rank denotes the scheduling time, the PIFO im-
plements a calendar queue; we distinguish between PIFOs
and priority queues for this reason.
hierarchical scheduling algorithms that violate this relative
ordering property (§2.2 and §2.3).
We ﬁnd that a PIFO-based scheduler lets us program many
scheduling algorithms (§3), e.g., Weighted Fair Queue-
ing [20], Token Bucket Filtering [10], Hierarchical Packet
Fair Queueing [13], Least-Slack Time-First [29], the Rate-
Controlled Service Disciplines [42], and ﬁne-grained prior-
ity scheduling (e.g., Shortest Job First). Until now, any line-
rate implementations of these algorithms—if they exist at
all—have been hard-wired into switch hardware. We also
describe the limits of the PIFO abstraction (§3.5) by pre-
senting examples of scheduling algorithms that cannot be
programmed using PIFOs.
To evaluate the hardware feasibility of PIFOs, we imple-
mented the design (§4) in Verilog [9] and synthesized it to
an industry-standard 16-nm standard-cell library (§5). The
main operation in our design is sorting an array of PIFO
elements at line rate. To implement this sort, tradition-
ally considered hard [30, 36], we exploit two observations.
One, most scheduling algorithms schedule across ﬂows, with
packet ranks increasingly monotonically within each ﬂow.
Hence, we only need to sort the head packets of all ﬂows to
dequeue from a PIFO. Two, transistor scaling now makes it
feasible to sort these head packets at line rate.
As a result, we ﬁnd (§5) that is feasible to build a pro-
grammable scheduler, which
• supports 5-level hierarchical scheduling, where the
scheduling algorithms at each level are programmable;
• runs at a clock frequency of 1 GHz—sufﬁcient for a
64-port 10 Gbit/s shared-memory switch;
• uses only 4% additional chip area compared to a
shared-memory switch that supports only a small menu
of scheduling algorithms; and
• has the same buffer size as a typical shared-memory
switch in a datacenter (~60K packets, ~1K ﬂows) [3].
While we have not produced a chip supporting PIFOs, our
synthesis results are promising and make a strong technical
case for switching chip manufacturers to invest in hardware
for programmable schedulers. To that end, C++ code for a
hardware reference model of our programmable scheduler
and Verilog code for our hardware design are available at
http://web.mit.edu/pifo/.
2. A PROGRAMMING MODEL FOR
PACKET SCHEDULING
For work-conserving scheduling algorithms, the charac-
teristic feature is the order in which packets are sched-
uled; for non-work-conserving ones, it is the time at which
each packet is sent. Moreover, for most algorithms used in
practice, these two decisions can be determined deﬁnitively
when a packet is enqueued into the packet buffer [38].
Our programming model is built around this observation
and has two underlying components:
f = flow (p) # compute flow from packet p
if f in last_finish :
p. start = max ( virtual_time , last_finish [f ])
else : # p is first packet in f
p. start = virtual_time
last_finish [f] = p. start + p. length /f. weight
p. rank = p. start
Figure 1: Scheduling transaction for STFQ. p.x refers to a
packet ﬁeld x in packet p. y refers to a state variable that is
persisted on the switch across packets, e.g., last_finish
and virtual_time in this snippet.
p.rank denotes the
packet’s computed rank.
1. The push-in ﬁrst-out queue (PIFO) [19], which main-
tains the scheduling order or scheduling time for en-
queued elements. A PIFO is a priority queue that al-
lows elements to be enqueued into an arbitrary position
based on the element’s rank, but dequeues elements
from the head. Elements with a lower rank are de-
queued ﬁrst; if two elements have the same value, the
element enqueued earlier is dequeued ﬁrst.
2. The computation of an element’s rank before it is en-
queued into a PIFO. We model this computation as a
packet transaction [37], an atomically executed block
of code that is executed once for each element before
enqueuing it in a PIFO.2
We note that scheduling with the PIFO abstraction does
not require packets to be stored in per-ﬂow queues.
We now describe the three main abstractions in our pro-
gramming model. First, we show how to use a scheduling
transaction to program simple work-conserving scheduling
algorithms using a single PIFO (§2.1). Second, we gen-
eralize to a scheduling tree to program hierarchical work-
conserving scheduling algorithms (§2.2). Third, we augment
nodes of this tree with a shaping transaction to program non-
work-conserving scheduling algorithms (§2.3).
2.1 Scheduling transactions
A scheduling transaction is a block of code associated
with a PIFO that is executed once for each packet before
the packet is enqueued. The scheduling transaction com-
putes the packet’s rank, which determines its position in the
PIFO. A single scheduling transaction and PIFO are sufﬁ-
cient to specify any scheduling algorithm where the relative
scheduling order of packets already in the buffer does not
change with the arrival of future packets.
Weighted Fair Queueing (WFQ) [20] is one example.
It achieves weighted max-min allocation of link capacity
across ﬂows3 sharing a link. Approximations to WFQ4
include Deﬁcit Round Robin (DRR) [36], Stochastic Fair-
2Any state visible on the switch after processing N consec-
utive packets is identical to a serial execution of the transac-
tions across the N packets in order of packet arrival [37].
3In this paper, a ﬂow is any set of packets sharing common
values for speciﬁc packet ﬁelds.
4An approximation is required because the original WFQ
algorithm [20] has a complex virtual time calculation.
f = flow (p) # see caption below
if f in last_finish :
p. start = max ( virtual_time , last_finish [f ])
else :
p. start = virtual_time
last_finish [f] = p. start + p. length / f. weight
p. rank = p. start
(c) Scheduling transaction for WFQ_Root, WFQ_Left,
WFQ_Right.
and
(a) Algorithm
(b) Scheduling tree
Figure 2: Programming HPFQ using PIFOs. “Left” and “Right” are classes. A, B, C, and D are ﬂows. Within each tree node in
the scheduling tree, the ﬁrst line is the packet predicate and the second is the scheduling transaction. All three nodes execute the
same code for the scheduling transaction except for their ﬂow() function, which returns a packet’s ﬂow/class. For WFQ_Root,
it returns the packet’s class: Left/Right. For WFQ_Left and WFQ_Right, it returns the packet’s ﬂow: A/B or C/D.
ness Queueing (SFQ) [30], and Start-Time Fair Queueing
(STFQ) [25]. We consider STFQ here, and show how to
program it using the scheduling transaction in Figure 1.
Before a packet is enqueued, STFQ computes a virtual
start time for that packet (p.start in Figure 1) as the maxi-
mum of the virtual ﬁnish time of the previous packet in that
packet’s ﬂow (last_finish[f] in Figure 1) and the current
value of the virtual time (virtual_time in Figure 1), a state
variable that tracks the virtual start time of the last dequeued
packet across all ﬂows (§5.5 discusses how this state vari-
able can be accessed on enqueue). Packets are scheduled in
order of increasing virtual start times, which is the packet’s
rank in the PIFO.
2.2 Scheduling trees
Scheduling algorithms that require changing the relative
order of buffered packets when a new packet arrives cannot
be programmed using a single scheduling transaction and
PIFO. An important class of such algorithms are hierarchi-
cal schedulers that compose multiple scheduling policies at
different levels of the hierarchy. We introduce a scheduling
tree for such algorithms.
To illustrate a scheduling tree, consider Hierarchical
Packet Fair Queueing (HPFQ) [13]. HPFQ ﬁrst divides
link capacity between classes, then recursively between sub
classes in each class, all the way down to the leaf nodes.
Figure 2a provides an example; the number on each child
indicates its weight relative to its siblings. HPFQ cannot
be realized using a single scheduling transaction and PIFO
because the relative scheduling order of packets that are al-
ready buffered can change with future packet arrivals (Sec-
tion 2.2 of the HPFQ paper [13] provides an example).
HPFQ can, however, be realized using a tree of PIFOs,
with a scheduling transaction attached to each PIFO in the
tree. To see how, observe that HPFQ executes WFQ at each
level of the hierarchy, with each node using WFQ among its
children. As discussed in §2.1, a single PIFO encodes the
current scheduling order for WFQ, i.e., the scheduling order
if there are no further arrivals. Similarly, a tree of PIFOs
(Figure 3), where each PIFO’s elements are either packets or
references to other PIFOs, can be used to encode the current
scheduling order of HPFQ and other hierarchical schedul-
ing algorithms. To determine this scheduling order, inspect
Figure 3: PIFO trees encode current scheduling order.
the root PIFO to determine the next child PIFO to sched-
ule. Then, recursively inspect the child PIFO to determine
the next grandchild PIFO to schedule, until reaching a leaf
PIFO that determines the next packet to schedule.
The current scheduling order of the PIFO tree can be mod-
iﬁed as packets are enqueued, by executing a scheduling
transaction at each node in the PIFO tree. This is our sec-
ond programming abstraction: a scheduling tree. Each node
in this tree is a tuple with two attributes. First, a packet
predicate that speciﬁes which packets execute that node’s