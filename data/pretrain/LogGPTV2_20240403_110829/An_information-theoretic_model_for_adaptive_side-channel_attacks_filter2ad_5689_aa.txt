title:An information-theoretic model for adaptive side-channel attacks
author:Boris K&quot;opf and
David A. Basin
An Information-Theoretic Model for Adaptive
Side-Channel Attacks
Boris Köpf
Information Security
ETH Zurich, Switzerland
PI:EMAIL
David Basin
Information Security
ETH Zurich, Switzerland
PI:EMAIL
ABSTRACT
We present a model of adaptive side-channel attacks which
we combine with information-theoretic metrics to quantify
the information revealed to an attacker. This allows us to
express an attacker’s remaining uncertainty about a secret
as a function of the number of side-channel measurements
made. We present algorithms and approximation techniques
for computing this measure. We also give examples of how
they can be used to analyze the resistance of hardware im-
plementations of cryptographic functions to both timing and
power attacks.
Categories and Subject Descriptors
D.4.6 [Software]: Security and Protection
General Terms
Security
1.
INTRODUCTION
Side-channel attacks against cryptographic algorithms aim
at breaking cryptography by exploiting information that is
revealed by the algorithm’s physical execution. Characteri-
stics such as running time [18, 6], cache behavior [28], power
consumption [19], and electromagnetic radiation [15, 31] ha-
ve all been exploited to recover secret keys from implemen-
tations of di(cid:11)erent cryptographic algorithms. Side-channel
attacks are now so e(cid:11)ective that they pose a real threat to
the security of devices like smart-cards, which can be sub-
jected to di(cid:11)erent kinds of measurements. This threat is not
covered by traditional notions of cryptographic security and
models for proving resistance against such attacks are only
now emerging [25, 37].
Two factors determine whether an attacker can successful-
ly mount a side-channel attack on a system and recover a
secret key (or other secret data): (cid:12)rst, he must be able to ex-
tract information about the key through side-channel mea-
surements. Second, he must be able to e(cid:11)ectively recover the
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010 ...$5.00.
key from the extracted information. To prove that a system
is resistant to side-channel attacks, one must ensure that no
realistic attacker can ful(cid:12)ll both conditions. In theory, key
recovery may be computationally infeasible, even if the key
is completely revealed in an information-theoretic sense.1
In practice, however, this is often not the case: keys have
been successfully recovered from side-channel information
from a broad range of cryptographic algorithms on di(cid:11)erent
platforms, e.g., [6, 8, 10, 19, 28]. When key recovery from
available information is feasible, the security of a system de-
pends entirely on the (cid:12)rst factor: the quantity of information
about the key that can be extracted from the system’s side-
channels. There are no known results for determining this
quantity for a given system with respect to the attackers
that can interact with it as in, e.g., [6, 8, 18, 28].
In this paper, we propose a solution to this problem for
deterministic systems: we present a model that allows us
to express the quantity of information that an adaptive at-
tacker can extract from a system, and we provide algorithms
and approximation techniques for computing this quantity.
Our model is based on a de(cid:12)nition of attack strategies,
which are explicit representations of the adaptive decisions
made by an attacker during attacks. We combine attack stra-
tegies with information-theoretic entropy measures. This al-
lows us to express the attacker’s expected uncertainty about
the secret after he has performed a side-channel attack fol-
lowing a given strategy.
Even if the attacker can perform arbitrary o(cid:11)-line analy-
sis on measurement data, his interactions with the system
under attack are often expensive or limited and their num-
ber needs to be considered when reasoning about a system’s
vulnerability. For example, the system may refuse multiple
interactions with the same agent or bound the number of
times it re-uses a secret, such as a session key. By quantify-
ing over all attack strategies of a (cid:12)xed length n, we express
what attackers can, in principle, achieve in n attack steps.
We use this to de(cid:12)ne a function (cid:8) that gives a lower bound
on the expected uncertainty about the key as a function of
the number of side-channel measurements. Since the bounds
given by (cid:8) are information-theoretic, they hold for any kind
of analysis technique that a computationally unbounded at-
tacker might apply to analyze the measurements. Note that
such strong bounds are realistic. In template attacks [10],
the entire information contained in each measurement is ef-
fectively exploited for key recovery.
We give algorithms and (exponential) complexity bounds
1For example, an RSA public key contains all the informa-
tion about the corresponding private key.
286for computing (cid:8). Furthermore, we propose two heuristic
techniques that reduce this complexity and thereby allow
us to estimate a system’s vulnerability for keyspace sizes for
which the direct computation of (cid:8) is infeasible.
Our approach is parametric in the physical characteristics
of the side-channel, which can be described by deterministic
hardware models of the target system. In this way, the ac-
curacy of our method only depends on the accuracy of the
system model used. Furthermore, our approach accommoda-
tes di(cid:11)erent notions of entropy that correspond to di(cid:11)erent
kinds of brute-force guessing.
Finally, we have implemented our approach and we report
on experimental results using the resulting prototype. We
have analyzed hardware implementations of cryptographic
algorithms for their resistance to timing and power attacks,
thereby obtaining the following results: (1) an attacker can
extract one operand’s Hamming weight from the timing of a
direct implementation of integer multiplication, but a more
defensive implementation reveals no information; (2) only
a few timing measurements are needed to extract the enti-
re exponent information from the (cid:12)nite-(cid:12)eld exponentiation
algorithm of [14]; and (3) one power trace of a (cid:12)nite-(cid:12)eld
multiplication algorithm contains all information about one
of its operands. These results illustrate the potential of our
approach for both detecting possible side-channel attacks
and showing their absence.
Overall, our contributions are twofold. Theoretically, we
develop a simple model for adaptive side-channel attacks
that connects information-theoretic notions of security to
models for physical characteristics of hardware. Practically,
we show that our model can be applied to nontrivial hard-
ware implementations of cryptographic algorithms and we
use it to analyze their vulnerability to power and timing
attacks.
The remainder of this paper is structured as follows. In
Section 2 we introduce our model of adaptive attacks and
in Section 3 we extend it with information-theoretic measu-
res. In Section 4 we give algorithms and complexity bounds
for computing these measures and we report on experimen-
tal results in Section 5. We present related work and draw
conclusions in Sections 6 and 7.
2. THE MODEL
We start by describing the assumptions underlying our
model.
2.1 Attackers and Side-Channels
Attack Scenario.
Let K be a (cid:12)nite set of keys, M be a (cid:12)nite set of messa-
ges, and D be an arbitrary set. We consider cryptographic
functions of type F : K (cid:2) M ! D, where we assume that
F is invoked by two collaborating callers. One caller is an
honest agent that provides a secret argument k 2 K and the
other caller is a malicious agent (the attacker) that provides
the argument m 2 M . Examples of F are encryption and
decryption functions and MACs.
We assume that the attacker has no access to the values
of k and F (k; m), but that he can make physical observati-
ons about F ’s implementation IF that are associated with
the computation of F (k; m). Examples of such observations
are the power or the time consumption of IF during the
computation (see [19, 24] and [18, 8, 6, 28], respectively).
Typically, the key k is a long-term secret that remains
constant during di(cid:11)erent calls to F . The malicious agent
performs an attack in order to gather information for dedu-
cing k or narrowing down its possible values. Such an attack
consists of a sequence of attack steps, each with two parts:
A query phase in which the attacker decides on a message m
and sends it to the system, and a response phase in which
he observes IF while it computes F (k; m). The attack is ad-
aptive if the attacker can use the observations made during
the (cid:12)rst n steps to choose the query for the n+1st step. An
attack ends if either the honest agent changes the key (as-
suming the independence of the old and new keys) or if the
attacker stops querying the system.
Discrete Side-Channel Measurements.
We assume that the attacker can make one side-channel
measurement per invocation of the function F and that no
measurement errors occur. Furthermore, we assume that the
attacker has full knowledge about the implementation IF .
These strong assumptions are justi(cid:12)ed as our goal is to gi-
ve bounds on what side-channel attackers can, in principle,
achieve.
Given our assumptions, a side-channel is a function fIF :
K (cid:2) M ! O, where O is the set of possible observations,
and fIF is known to the attacker. We will usually leave IF
implicit and abbreviate fIF by f .
Example 1. Suppose that F is implemented in synchro-
nous (clocked) hardware and that the attacker is able to de-
termine IF ’s running times up to single clock cycles. Then
the timing side-channel of IF can be modeled as a function
f : K (cid:2) M ! N that represents the number of clock ticks
consumed by an invocation of F . A hardware simulation en-
vironment can be used to compute f .
Example 2. Suppose F is given in a description language
for synchronous hardware. Power estimation techniques such
as [27, 40] can be used to determine a function f : K (cid:2) M !
Rn that estimates an implementation’s power consumption
during n clock ticks.
If the function f accurately models the side-channel, then
any randomness in a physical attacker’s measurements is due
to noise and the assumption of error-free measurements is
a safe worst-case characterization of the attacker’s capabili-
ties. One can also derive f from the implementation IF .
Example 3. Suppose a hardware implementation IF of F
is given. As in template attacks [10], average values of IF ’s
power consumption for (cid:12)xed input values k and m can be
used to de(cid:12)ne f (k; m).
As in template attacks, the attacker can use noise models of
the target implementation to extract the maximal informa-
tion from his measurements, that is, the value of f .
2.2 Attack Strategies
An adaptive attacker chooses his queries with the know-
ledge of previously revealed side-channel information. We
use trees to de(cid:12)ne attack strategies, which capture these ad-
aptive choices. Subsequently, we also formalize non-adaptive
attacks, that is, attacks in which the malicious agent gathers
all side-channel information before performing any analysis.
To begin with, we motivate an abstract view of attack steps,
which is the key to the simplicity of our model.
Attacker’s Choices and Knowledge.
During the query phase, the attacker decides which mes-
sage m 2 M to query the system with. In the response
phase, he learns the value f (k; m). In general, he cannot de-
duce k from f (k; m). What he can deduce though (assuming
full knowledge about the implementation IF and unbounded
computational power) is the set of keys that are coherent
with the observation f (k; m). Namely, assuming a (cid:12)xed f ,
we say that a key k is coherent with o 2 O under m 2 M
whenever f (k; m) = o holds. Two keys k and r are indistin-
guishable under m i(cid:11) f (r; m) = f (k; m). Note that for every
m 2 M , indistinguishability under m is an equivalence rela-
tion on K. For every o 2 O, the set of keys that are coherent
with o under m forms an equivalence class of indistinguis-
hability under m. The set of keys that are coherent with the
attacker’s observation under the attacker’s input is the set
of keys that could possibly have led to this observation; we
use this set to represent the attacker’s knowledge about the
key after an attack step.
Functions as Sets of Partitions.
We now provide an abstract formalization of attack steps.
As is standard, a partition P = fB1; : : : ; Brg of K is a set
of pairwise disjoint blocks with Sr
i=1 Bi = K. Observe that
every equivalence relation R on K corresponds to a partition
PR of K, where the equivalence classes of R are the blocks
of PR. In this way, a function f : K (cid:2) M ! O gives rise to
a set of partitions Pf = fPm j m 2 M g, where Pm is the
partition induced by indistinguishability under m.
In terms of the set of partitions Pf , the two phases of an
attack step can be described as follows.
1. In the query phase, the attacker chooses a partition
P 2 Pf .
2. In the response phase, the system reveals the block