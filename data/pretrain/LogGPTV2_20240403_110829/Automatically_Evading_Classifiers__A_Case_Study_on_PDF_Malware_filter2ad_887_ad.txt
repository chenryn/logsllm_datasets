The experiment of evading Hidost took around two days
to execute. Although Hidost was designed speciﬁcally to resist
evasion attempts,2 our method achieves a 100% evasion rate,
generating 2,859 evasive samples in total for 500 seeds (5.7
evasive samples per seed in average).
Trace Analysis. We analyze the efﬁcacy of each mutation trace
which is examined in the same way as for PDFrate. The length
and efﬁcacy of each mutation trace are shown in Figure 7. In
2Speciﬁcally,
the Hidost authors claim, “The most aggressive evasion
strategy we could conceive was successful for only 0.025% of malicious
examples tested against an off-the-shelf nonlinear SVM classiﬁer with the
RBF kernel using the binary embedding. Currently, we do not have a rigorous
mathematical explanation for such a surprising robustness. Our intuition
suggests that the main difﬁculty on attacker’s part lies in the fact that the input
features under his control, i.e., the structural elements of a PDF document,
are only loosely related to the true features used by a classiﬁer. The space of
true features is hidden behind a complex nonlinear transformation which is
mathematically hard to invert.” [28]
Fig. 7. The length and efﬁcacy of mutation traces for evading Hidost.
general, it required shorter mutation traces to achieve 100%
evasion rate in attacking Hidost than it did for PDFrate.
We observed two major differences compared to PDFrate.
First, there is no increasing trace length trend for newly found
mutation traces, unlike for PDFrate where the trace length
increases with the trace ID. Second, the trace length is more
correlated with the efﬁcacy: longer traces tend to be more
effective in generating evasive variants. Several short mutation
traces with fewer than 5 mutations are only effective on 1 or
2 malware seeds. In contrast, a long mutation trace containing
61 mutations is effective on 334 malware seeds.
The accumulated number of evasions found sorted by the
length of mutation traces is given in Figure 5. The plot is closer
to linear, suggesting that, in contrast to PDFrate, there is little
variation in the difﬁculty of ﬁnding evasive variants for differ-
ent seeds. We believe the differences from PDFrate stem from
the different feature set in Hidost. The mutation operations
have more direct inﬂuence on the structural path features in
Hidost. For example, an object deletion operation just deletes
the corresponding path of a feature (along with those of its
descendants). In contrast, feature changes in PDFrate resulting
from the same operation are less tangible. Besides decreasing
the counts of speciﬁc objects that we can expect, the other
positional features may also change due to the relocation of
objects in repacking the modiﬁed variant. As a result, there
are more inter-inﬂuences among the mutation operations in
evading PDFrate, and a larger number of mutations may be
required to reach the evasion threshold. The box plot of the
original classiﬁcation score in Hidost of each seed shown in
the right side of Figure 6 suggests that it usually requires more
mutations to ﬁnd an evasive variant for seeds that appear to
be more clearly malicious to the classiﬁer.
Feature Analysis. The binary features used in Hidost are much
easier to interpret than the variety of features used by PDFrate.
We ﬁrst look at the simplest mutation traces. There are 5
mutation traces in length 1, which are only effective on 1 or
2 malware seeds. They are:
10
(delete, /Root/OpenAction/JS/Length)
(delete, /Root/Names)
(delete, /Root/AcroForm/DR)
(replace, /Root/AcroForm/DR,
3: /Root/OpenAction/D/0/.../FontBBox/3)
(replace, /Root/AcroForm/DR,
3: /Root/Pages/Kids/3/.../DescendantFonts/0/DW)
The ﬁrst three mutations each delete a node from the original
malware seeds, changing the value of the corresponding Hidost
feature from 1 to 0. The ﬁrst deleted object similar to the
count javascript feature in PDFrate. Both capture properties
that frequently exist in malware samples but not in benign
ﬁles. However, they are optional in malicious code execution.
The other deleted objects are artifacts in the training dataset
that are not closely tied to malicious behavior. Although the
last two traces use replace operations, the important effects of
the replacements are to remove the features extracted from the
children objects of the original /Root/AcroForm/DR node.
Simply deleting some objects is not sufﬁcient to evade
Hidost (it
is only effective on 1 or 2 malware seeds in
our experiment), but additional mutations are enough to ﬁnd
evasive variants for all of the seeds. The longest mutation trace
contains 85 operations, which is effective on 198 malware
seeds for generating evasive variants to bypass Hidost. Table V
lists the all of feature changes observed over the 198 malware
seeds when executing that mutation trace. Unsurprisingly,
several auxiliary objects are added or deleted to fool Hidost.
For example, several metadata objects are inserted. Metadata
widely exists in benign PDFs when users generate PDF docu-
ments with popular PDF writers. On the other hand, it is rare in
PDF malware because malware authors did not add metadata
in hand-crafting PDF exploits. However, this is just an artifact
in the training dataset and not an essential difference between
PDF documents and PDF malware. Inserting metadata into a
PDF malware sample increases the likelihood of the sample
being considered benign by Hidost.
is to say,
As seen from this example, trace length itself is not a
good measure of evasion complexity. Although the stochastic
search process found an 85-operation trace to create these
evasive variants, the trace only impacts the 23 features (each
corresponding to a node in the PDF ﬁle) showing in Table V.
That
there is a 23-operation trace that would
be just as effective (and probably shorter traces since one
mutation can impact many features), and the trace found by
the search includes many useless or redundant mutations. For
the purposes of creating evasive malware, it is not important to
ﬁnd the shortest effective trace, although it would be possible
to develop techniques to automatically pare down a trace to
its essential operations if desired. The yellow triangle plot in
Figure 7 shows the number of affected features for each trace.
Although its authors claimed that Hidost was robust against
evasion attacks involving just feature addition, we found many
evasive variants that only added features. Among the 2,859
evasive variants, 761 are pure feature addition attacks, 21 of
them are pure feature deletion attacks, and the other 2,077
involved both feature addition and deletion. It
is already
unrealistic to assume attackers can only insert features, and,
as shown in the claims about non-evadability of Hidost,
TABLE V.
FEATURE CHANGES PRODUCED BY LONGEST HIDOST
MUTATION TRACE.
Added Features
Deleted Features
ViewerPreferences/Direction
Names/JavaScript/Names/S
AcroForm
Threads
Metadata
Metadata/Length
Metadata/Subtype
Metadata/Type
OpenAction/Contents
OpenAction/Contents/Filter
OpenAction/Contents/Length
Pages/MediaBox
AcroForm/DR/Encoding/PDFDocEncoding
AcroForm/.../PDFDocEncoding/Differences
AcroForm/.../PDFDocEncoding/Type
Pages/Rotate
AcroForm/Fields
AcroForm/DA
Outlines/Type
Outlines
Outlines/Count
Pages/Resources/ProcSet
Pages/Resources
dangerous to assume a technique cannot be evaded because
particular manual techniques fail.
A complete list of mutated features in evading Hidost is
given in Appendix B. These non-robust features should not be
used in a malware classiﬁer, as they can be easily changed
while preserving the original malicious properties.
C. Cross-Evasion Effects
Even though the classiﬁers are designed very differently
and trained with different training datasets, we suspected they
must share some properties in the same classiﬁcation task.
Therefore, we conducted a cross-evasion experiment by feed-
ing one classiﬁer with the evasive variants found in evading
the other classiﬁer.
For 388 of the malware seeds, the evasive variants found
by evading Hidost are also effective in evading PDFrate. That
is to say, without any access to PDFrate, a malware author
with access to Hidost could ﬁnd evasive variants for 77.6% of
the seeds. In contrast, the evasive variants found by evading
PDFrate are only effective against Hidost for two of the
malware seeds.
The signiﬁcant difference in the cross evasion effects
is due to the different feature sets in the two classiﬁers.
Indeed, the primary design goal for Hidost was to be less
easily evaded than other classiﬁers by using features based
on structural properties. The evasive variants generated by the
algorithm in evading PDFrate do change the measured features
signiﬁcantly, however, they have little effect on the structural
features used in Hidost. In the reverse direction, the evasive
variants targeting Hidost by directly altering structural features
(necessary to evade Hidost), incidentally impact the features
used by PDFrate.
D. Execution Cost
One drawback of evolutionary algorithms is that
they
provide no guarantees about generating good results within
a speciﬁc duration. For many problems, these methods can
require a huge amount of computing resources before a desired
result is found. Further, failing to ﬁnd the desired result may
be a sign that it doesn’t exist, or just that more computing re-
sources are required. Our experiments show that the resources
required for this instantiation are very reasonable.
For each classiﬁer target, the experiment was run in several
rounds. The ﬁrst round started with empty trace pools, so the
11
classiﬁers under attack. Based on the evasive samples we
generated, and the non-robust features we found in Section V,
we consider several possible approaches.
Information Hiding and Randomization. One of the most
direct solutions to protect classiﬁers is hiding the classiﬁcation
scores from the users or adding random noise to the scores [2].
Another proposed method is the multiple classiﬁer system, in
which the classiﬁcation scores are somewhat randomly picked
from different models trained with disjoint features [3]. As our
method heavily relies on the classiﬁcation scores of variants
to calculate ﬁtness scores that direct the evolution, the lack of
accurate score feedback makes the search for evasive variants
much harder and may make our approach infeasible.
However, the intrinsic non-robustness of superﬁcial fea-
tures should not be simply ignored. Considering the potential
cross-evasion effects (Section VI-C), hiding or randomizing the
information may not help much against an adversary who can
infer something about the types of features used by the target
classiﬁer. Moreover, previous work has shown that accurately
re-implementing a similar classiﬁer with a surrogate training
set is possible (indeed, this is what the authors of Mimicus did
to experiment with evadability of PDFrate [26, 29]).
Adapting to Evasive Variants. Our experiments assume that
adversary can test samples without exposing them to the
classiﬁer operator. In an on-line scenario, the classiﬁer may
be able to adapt to attempted variants. Note, however, that
retraining is expensive and opens up the classiﬁer to alternate
evasion strategies such as poisoning attacks.
Chinavle et al. proposed a method that would automatically
retrain the classiﬁer with pseudo labels once evasive variants
were detected by a mutual agreement measure on the ensemble
model, which had been shown effective on a spam detection
task [6]. However, adapting to users’ input without true labels
introduces a new risk of poisoning attacks.
Defeating Overﬁtting. The evadability of classiﬁers we
demonstrate could be just an issue of overﬁtting, in which case,
well known machine learning practices should work to defeat
overﬁtting. For example, collecting a much larger dataset for
training the model, or using model averaging to lower the
variance.
We don’t expect these conventional methods will help,
however. It is impossible to collect a complete dataset of future
malware, and none of these techniques anticipate an adversary
who is actively attempting to evade the classiﬁer.
Selecting Robust Features. We found many non-robust fea-
tures from the two classiﬁers in the evasion experiments.
Obviously, they should be removed from the feature set as they
can be easily manipulated by the attacker without corrupting
the malicious properties. The problem with the features used
by both Hidost and PDFrate, however, is that all of the features
are likely non-robust. The superﬁcial features used by these
classiﬁers do not have any intrinsic distinguishability between
benign and malicious PDFs, and it would be very surprising
if superﬁcial features were found that could be used for
robust classiﬁcation. Instead, it seems necessary to use deeper
features to build classiﬁers that can resist evasion attempts
Fig. 8. Time required to ﬁnd evasive variants for 500 malware samples.
search for evasive variants relies solely on the stochastic search
directed by the ﬁtness function. In later rounds, the successful
and promising mutation traces found previously were used to
accelerate the search. All the failed jobs in a round were re-
run in the next round with the all mutation traces stored in
previous rounds.
For PDFrate, it took four rounds to reach 100% evasion.
The evasion rate on Hidost reached 100% in the second round.
Figure 8 shows the total time needed to ﬁnd evasive variants
for all 500 malware seeds in evading the two classiﬁers. The
duration for each job is not meaningful because it mainly
depends on the job sequence. Later jobs are usually much
faster because they may beneﬁt from mutation traces found
earlier, but the order of trying the seeds is arbitrary.
It took less than 6 days to achieve a 100% evasion rate
on PDFrate. In other words, our method found an evasive
variant for each seed in 16 minutes on average running on
a commodity desktop. Evasive variants were found against
Hidost three times faster, taking 5 minutes per seed in average.
The main computation time is running the generated vari-
ants in the Cuckoo sandbox, which we use as the oracle in
our process. The machine with 16 virtual machines running
in parallel is able to test 1,000 samples per hour. This could
easily be accelerated by using more machines, since there are
no dependencies between the executions.
We also observed that the time spent on other tasks (includ-
ing mutation) in attacking PDFrate takes a larger proportion
of the total duration than for Hidost (8.3% vs. 4.1%). This is
because the benign ﬁles used as external object genome are
larger than those in attacking Hidost. Hence, it produced larger
variants,
increasing the computational burden for parsing,
manipulating, and repacking.
VII. DISCUSSION
In this section we discuss the potential defenses and future
directions suggested by our results.
A. Defense
Beyond understanding the vulnerabilities of current clas-
is to improve the robustness of
siﬁers, our ultimate goal
12
PDFrateHidostHours24487296120144OracleMutationClassiﬁerOthersweak spots in a classiﬁer model’s feature space and employs
a stochastic method to manipulate samples in diverse ways.
Maiorca et al. proposed reverse-mimicry attacks against
PDF malware classiﬁers [20]. In reverse-mimicry, a benign
sample is manipulated into a malicious one by inserting
malicious payloads into the structure. The attack is generic
to a class of classiﬁers based on structural features. However,
the hand-crafted attack only works on malware with simple
payloads. In contrast, our GP-based method is automatic and
does not have this limitation.
Evolutionary algorithms have also recently been used to
fool deep learning-based computer vision models [22]. In con-
trast, this work uses genetic programming, an important branch
of evolutionary algorithms for generating highly-structured
data like computer programs.
IX. CONCLUSIONS
Our experiments show how the traditional approach of
building machine learning classiﬁers can fail against deter-
mined adversaries. We argue that it is essential for designers
of classiﬁers used in security applications to consider how
adversaries will adapt to those classiﬁers, and important for
the research community to develop better ways of predicting
the actual effectiveness of a classiﬁer in deployment.
AVAILABILITY
The source code of our automatic evasion tool, along
with the data from all of our experiments, is available at
http://www.EvadeML.org.
ACKNOWLEDGMENTS
This work was partially supported by grants from the Air
Force Ofﬁce of Scientiﬁc Research and the National Science
Foundation. The authors gratefully thank Giovanni Vigna for
helpful assistance, Westley Weimer for fruitful discussions
about
this work and help with the genetic programming
experiments, and Hongning Wang for insightful comments
and assistance. We thank Nedim ˇSrndic and Pavel Laskov
for making an open source version of PDFrate and providing
Hidost, which were essential for our experiments.
by sophisticated adversaries. Such features will depend on
higher-level semantic analysis of the input ﬁle, in ways that are
difﬁcult to change without disrupting the malicious behavior.
B. Improving Automatic Evasion
Our automatic evasion method provides a general method
to evaluate the robustness of classiﬁers for security tasks.
Its ability to ﬁnd evasive variants against a target classiﬁer
demonstrates clear weaknesses, but if our method fails to ﬁnd
evasive variants against a particular classiﬁer this is certainly
not enough to be conﬁdent that other techniques (including
manual effort) would not be able to ﬁnd evasive variants.
Hence, it is valuable to improve the method to enable more
efﬁcient searching to target more challenging classiﬁers.
Parameter Tuning. In this work, we just arbitrarily choose
the search parameters. Tuning the parameters, or even trying
dynamic mechanisms like parameter decay, could make the
search algorithm more efﬁcient.
Learnable GP. The current method we use to generate evasive
variants is essentially a random search algorithm. Hence,
it often generates corrupted variants that lose the malicious
behavior. A probabilistic model would learn which mutations
are more effective for generating evasive variants to direct the
search more efﬁciently.
Other Applications. Our case study focused on PDF malware,
but we believe similar approaches could be effective against
other machine-learning based malware classiﬁers. The main
challenges in applying our approach to a new domain are
to develop suitable genetic mutation operations and ﬁnd an
appropriate oracle.
VIII. RELATED WORK
There have been several papers on evasion attacks against
classiﬁers in the machine learning community, mostly focused
on spam detection with simple models (e.g.,
[6, 10, 18].
Chinavle et al. argued that the adversarial problem is essen-
tially concept drift, which is a well studied ﬁeld in machine
learning that considers data distributions which change over
time [6]. However, the concept drift solutions assume the data
distribution changes are not due to the classiﬁer itself, not
resulting from an adversary intentionally adapting to it.
Evasion attacks against malware classiﬁers have been stud-
ied previously by Biggio et al. from the angle of classiﬁcation
models [4] and by ˇSrndic et al. [28]. However, these studies
assumed that attackers can only insert new features and they
conducted evasion experiments in the feature space without
generating actual evasive PDF malware. In fact, the experi-
ments in our work show attackers can also delete features while
preserving maliciousness, and our experiments veriﬁed that
the resulting evasive variants preserved maliciousness through
dynamic execution in a test environment.
ˇSrndic et al. demonstrated how PDFrate could be evaded
by exploiting an implementation ﬂaw in the feature extrac-
tion [29]. Our method does not rely on any particular imple-
mentation ﬂaw in a target classiﬁer. Instead, it exploits the