• Malicious Auditor Role. Until v is detected, they may
attempt to lie about an honest node’s correctness to inject
confusion into audit results. This would require v to
be able to generate a result message that implicates
the honest node, but this is not possible because the
Auditor component will only generate a result message
when presented with a valid authenticated audit response.
Because v cannot forge the result message, it is not in
their interest to lie about the honest node.
• Colluding Auditors. Multiple compromised nodes may
attempt to collude in the decentralized audit to conceal
their presence. A second dishonest node k cannot force an
audit challenge to v, but may randomly select v. Because
the untrusted environment controls network transmission,
k could then drop the result message that implicates
v. However, this would only delay the detection of v,
whose Logger would attempt to transmit Me again in
future challenges since k did not conﬁrm its replication.
More shrewdly, v and k could both comply with the audit,
then immediately delete both copies of Me. Because v’s
trusted Logger component received a valid result from k,
it may conclude that Me was replicated r times and stop
transmitting it in future challenges. G4 thus depends on
the probability that v receives consecutive challenges by
r malicious nodes and no honest nodes. We demonstrate
that this probability is negligible in Section IX-A.
Finally, CUSTOS satisﬁes G5 (minimal invasiveness) in that
it is fully interoperable with any upstream applications that
process Linux Audit events. CUSTOS runs in the process space
of auditd, but its semantics are independent of the existing
audit-userspace code base. In fact, CUSTOS requires
inserting just 26 lines of code into existing source ﬁles. This
makes porting CUSTOS to new versions extremely simple.
In addition, while we described CUSTOS in the scenario of
online auditing frameworks, CUSTOS’ Logger could easily be
extended to automatically generate integrity proofs ofﬂine at
predeﬁned time intervals or block sizes, without interaction
with any external party.
A. Probabilistic Analysis
Let v be a compromised node that seeks to conceal events
contained in block Me. We analyze the probability that v
succeeds in its mission without being reported, in the presence
of a distributed adversary. Let N + 1 be the number of nodes
participating in the protocol and f + 1 be the number of
compromised colluding nodes, including v. v’s enclave will
attempt to replicate Me to r auditors, in the order of challenge
8
TABLE IV: Probability  that a compromised node v is not audited
by any honest node under varying conﬁgurations of N, r and f.
N + 1 is the total number of nodes participating in the protocol, and
f + 1 ≤ N is the number of compromised nodes (including v).
r =
(cid:106) N
(cid:107)
4
f =
5.38 × 10−2
3.23 × 10−3
9.74 × 10−6
N
50
100
200
(cid:106) N
(cid:107)
25
f =
(cid:107)
(cid:106) N
2
2.449 × 10−1
5.87 × 10−2
3.38 × 10−3
(cid:107)
(cid:106) N
10
r =
(cid:106) N
(cid:107)
4
f =
3.74 × 10−4
1.89 × 10−7
2.92 × 10−14
(cid:106) N
(cid:107)
2
f =
2.51 × 10−2
5.93 × 10−4
3.32 × 10−7
arrival. v can also re-order challenges before passing them to
the enclave so long as they responded to within µ seconds.
1) Case A: Suppose v receives r consecutive audit chal-
lenges from colluding compromised auditors and no challenges
from honest auditors. This is the best-case scenario for the
adversary as v does not even need to re-order challenges. The
ﬁrst challenge arrives from a colluding node with probability
f
N . Given that, the second challenge arrives from a different
colluding node with probability f−1
the
probability of attack success () is:
N−1. It follows that
(cid:18) f
(cid:19)(cid:18) f − 1
(cid:19)
N
N − 1
(cid:18) f − r + 1
N − r + 1
(cid:19)
···
f !(N − r)!
(f − r)!N !
=
=
fPr
NPr
Table IV computes the value of this probability for different
conﬁgurations. In a network of N = 100 nodes, even with
f = 50 compromised colluding nodes, it sufﬁces to choose
r = 4 to have the probability of attack success  < 5.88%.
2) Case B: Let us now consider the case when v re-orders
challenges to keep the enclave from processing an honest
node’s challenge. Assume that v has received β < r distinct
challenges from colluding nodes and it is waiting for other
r − β challenges to arrive from other distinct colluding nodes.
The probability of this happening is fPβ/NPβ, using the same
method as in Case A. The (β + 1)-th challenge will arrive
from an honest auditor with probability N−f
N−β , making the
probability of v possessing β dishonest challenges followed
by one honest challenge:
P1 =
· N − f
N − β
fPβ
NPβ
If v chooses to delay the honest challenge while waiting for
r−β dishonest challenges, the dishonest challenges must arrive
within µ before v is detected by the honest node.
We can assume that the number of challenge arrivals per
unit of time follows a Poisson distribution [13]; this is because
at every T the auditors send challenges to nodes randomly and
thus challenges are sent to v independently of one another.
Let λ be the average rate of challenge arrival and X be the
random variable representing the number of challenges arriving
at v over a given interval. If we observe the system from the
perspective of v for a long time T , the total number of audit
T · N · w. There is a probability
challenges generated will be T
N that v gets selected for each of those challenges. Therefore,
the average number of challenges that arrive at v within T
1
T · N · w · 1
is T
N . It follows that the average rate at which v
T · N · w · 1
N · 1T , that is λ = w
receives a challenge is λ = T
T .
Since X is Poisson distributed, it follows that the probability
that v receives m challenges within µ is:
P2 = e−µλ · (µλ)m
m!
Now we calculate the probability P3 that, among m chal-
lenges received by v, at least (r − β) of them are from new
colluding nodes. For exactly y auditors to be colluding among
these m, distinct y nodes are chosen from remaining f − β
colluding nodes, and m − y nodes are chosen from remaining
N − f − 1 honest nodes. Let random variable Y denote
the number of colluding auditors among m. The probability
P (Y = y) will be calculated as:
P (Y = y) =
,
y = 0, . . . , m
Consequently, the probability that less than r − β colluding
nodes send challenges is:
(cid:1)(cid:0)N−f−1
(cid:0)f−β
(cid:1)
(cid:0)N−1−β
(cid:1)
m−y
y
m
r−β−1(cid:88)
y=0
∞(cid:88)
P3 =
P (Y = y)
Therefore, the probability that at least r−β of the m challenges
are from remaining colluding nodes is 1− P3. The probability
that v receives m challenges within µ after an honest node b’s
challenge arrival and that at least (r − β) among the m chal-
lenges are from distinct colluding nodes is P2 · (1− P3). Since
X follows a Poisson distribution, the cumulative probability
P for any m in this scenario will be:
P = P1 ·
P2(1 − P3)
m=1
The distributed adversary will be in the least advantageous
position if the ﬁrst of the r challenges to replicate Me is from
an honest auditor b, meaning that β = 0 and that to avoid
detection v would have to receive r colluding challenges within
µ. The best-case scenario for the adversary (other than Case
A) is when the ﬁrst challenge from an honest auditor b arrives
after β = r − 1 challenges from colluding auditors. In this
case, v only needs one more challenge from a colluding node
within µ to succeed in its mission. However, even in this best-
case scenario and with N = 100, f = 50, r = 4, w = 10,
µ = 15 s, and T = 60 s, v will be able to avoid detection with
a probability of just 4.43%.
X. PERFORMANCE EVALUATION
We now characterize the performance of CUSTOS. To
do so, we leverage two experimental setups. In both, we
conﬁgured Linux Audit to log all forensically-relevant system
calls, using the same ruleset employed in [66], [31], [75].8
8This set includes the syscalls: read, readv, write, writev, sendto, recvfrom,
sendmsg, recvmsg, mmap, mprotect, link, symlink, clone, fork, vfork, execve,
open, close, creat, openat, mknodat, mknod, dup, dup2, dup3, bind, accept,
accept4, connect, rename, setuid, setreuid, setresuid, chmod, fchmod, pipe,
pipe2, truncate, ftruncate, sendﬁle, unlink, unlinkat, socketpair, splice.
9
• Point-to-point Setup (Bare Metal): We deployed a
Logger on a server with an Intel Core i7-7700K CPU
at 4.20 GHz (4 physical cores) and 64 GB RAM running
Ubuntu Server 18.04 64 bit (Linux 4.15). We deployed
an Auditor on a different server with an Intel Xeon E5-
2630 v4 CPU at 2.20 GHz (10 physical cores) and 64 GB
RAM running Ubuntu Server 16.04 64 bit (Linux 4.4).
The Logger used SGX SDK version 2.3.1 with debug
mode on, while the Auditor used the same version in
simulation mode. During experimentation, we observed
an average latency of 176 µs between the two machines.
• Distributed Setup (VMs): We deployed CUSTOS on a
cluster of 100 Amazon EC2 m4.xlarge instances, each
with 4 VCPUs (2.3 GHz Intel Xeon E5-2686 v4 or 2.4
GHz Intel Xeon E5-2676 v3) and 16 GB of RAM. Each
instance was running Ubuntu Server 18.04 64 bit (Linux
4.15) and used SGX SDK version 2.3.1 in simulation
mode 9. A small script synthesized a constant workload
that generated an average of 32 log events (11.8 KB of log
data) per second on each node, which is a realistic (not
worst-case) rate for a server [76]. During experimentation,
we observed an average latency of 169 µs between any
two machines in the cluster.
A. Logger Microbenchmarks
We start by using the bare metal setup to measure the
time that CUSTOS’ Logger takes to perform each of the ﬁve
phases described in Section V. We run this microbenchmark
by manually invoking each Logger’s operation 500 times,
including in the measurement the time required to context
switch into and out of the enclave. Table V shows the results.
The phases that involve interaction with a hardware counter,
Initialization and Startup, are the most costly. This is because
Intel SGX’s monotonic counter operations are notoriously
slow [78], but these operations occur only once per session.
The next most costly phases, Commitment and Shutdown,
involve cryptographic signatures. However, these operations
are a function of challenge frequency, not the workload, and
in practice will occur orders of magnitude less frequently than
the Logging operation. Fortunately, Logging (ecalls) is the
most efﬁcient phase at 4.71 µs per event processed, but the
performance of this operation is paramount, since it is invoked
once per log event. We observed that the main cost of this
phase is switching context between the untrusted OS and the
trusted enclave [46]: thus, to further improve its performance,
we created a second Logging implementation using Hotcalls,
which were recently introduced by Weisse et al. [126]. Hotcalls
provide the same security guarantees of ecalls, but allow us to
reduce the cost of context-switching to the enclave, enabling
a signiﬁcant speed-up (0.92 µs) at the expense of running
an additional background thread permanently spinning inside
CUSTOS’ enclave. For the rest of our evaluation, we will
use the Hotcalls-based implementation of CUSTOS. In Section
X-B, we will evaluate the system-wide impact of this choice.
1) Prior Work Comparison: We have argued that prior
solutions for tamper-evident logging do not meet the needs