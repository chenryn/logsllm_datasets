between emulation and page-tracking based approaches. 
Figure 8 shows the comparison between emulation-based 
approaches  and  page-tracking  based  approaches.  The  main 
aim of the experiment is to find the optimal parameter values 
for the two categories of approaches. Figure 8(a) shows that 
in  user-space,  below  5  writes-per-page  (WPP),  emulation 
performs  better  than  PT.  Figure  8(b)  shows  that,  for 
hypervisor-assisted  approaches,  Emulxen  performs  better 
than PTxen for WPP below 1.3. Beyond these two numbers, 
the page-tracking based approaches have better performance.  
The  results  show  that  in  the  user-space,  five  write 
emulations  and  page  faults  are  equivalent  to  a  single  page 
protection  and  page  fault.  Compared  to  user-space  case, 
hypervisor-assisted  case  shows  a  much  lower  break-even 
point  (WPP  =  1.3).  This  illustrates  the  significant  overhead 
of page fault handling in user space.   
(a) vs. User-level 
(b) vs. Hypervisor-assisted 
Figure 9: Scanxen performance 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:59 UTC from IEEE Xplore.  Restrictions apply. 
377Figure 9 shows the performance of Scanxen with respect 
to PT (Figure 9(a)) and PTxen (Figure 9(b)). Although most 
of  the  Scanxen  overhead  comes  from  scanning  the  page-
tables,  there  is  some  impact  of  pages-per-transaction  (PPT) 
as can be seen from the positive slope of Scanxen lines in the 
two  figures.  At  the  end  of  each  transaction,  Scanxen 
constructs  the  list  of  dirty  pages.  The  work  involved  in 
building the list is proportional to the number of dirty pages 
(PPT).  The total cost y can be expressed with a simple linear 
equation:  
y = (PPT dependent cost) + static cost based on CDA. 
Based on Figure 9, we find that: 
y = (0.0625)*(PPT) + 2.5*(size of CDA in MB), 
where  the  first  term  represents  the  amount  of  work  to  be 
done for accumulating the list of dirty pages.  
For  large  critical  data  areas  (e.g.,  several  Mbytes)  the 
static  cost  is  dominant,  so  the  first  term  in  the  equation  is 
negligible.  On  the  other  hand  when  the  critical  data  area  is 
small (e.g., several tens of Kbytes) the first term has a bigger 
impact on the overall cost. 
The two figures show the break-even points for Scanxen 
when  compared  to  the  page-tracking  based  approaches.  As 
compared to PT, Scanxen performs better with higher values 
of  PPT  and  for  smaller  CDAs.  In  hypervisor-assisted  page-
tracking  case  (PTxen),  due  to  the  improved  performance  of 
PTxen,  Scanxen  cannot  outperform  it  in  most  cases,  except 
when the CDA is smaller (10s or 100s of Kbytes).  
Although  Scanxen  can  be  better  in  performance  for 
applications with small size CDA and large PPT transactions, 
the  range  of  values  for  which  it  is  better  is  so  small  that  in 
the practical case most applications do not fit the criteria. For 
most  real-world  applications,  PT  and  PTxen  can  easily 
outperform  Scanxen.  In  this  work  we  will  not  present 
additional results on Scanxen. 
E.  Summary 
Figure  10  summarizes  the  performance  of  the  various 
approaches  for  a  sample  case  of  WPP=4.  Overall,  we  note 
that  the  hypervisor-assisted  approaches  are  4-10x  better  in 
performance than user-level approaches.  
Figure 10: Comparison of approaches 
One interesting observation from the figure is that while 
Emul is better than PT in the user space under virtualization 
(at  least  for  WPP=4),  PTxen  is  better  than  Emulxen.  This 
suggests  that  the  gains  in  moving  page  protection  to 
hypervisor  space  are  especially  significant,  making  page 
tracking-based  approaches  with  hypervisor  assistance 
outperform other techniques. 
VI.  WORKLOAD EVALUATION 
To  evaluate  a  more  realistic  workload,  we  implemented 
data  structures  typically  used  in  most  applications   [25].  We 
studied  two  cases  â€“  (a)  where  each  transaction  had  a  single 
operation  (e.g.  an  insert  or  a  delete),  i.e.  Operations-per-
Transaction  (OPT)  is  1,  and  (b)  where  multiple  operations 
were merged into one transaction, specifically OPT = 5. 
Table  2  gives  a  list  of  the  data  structures  implemented. 
For each data structure it shows the average number of data 
writes and the average number of unique pages written to in 
a  transaction  by  insert  and  delete  operations.  In  the  case  of 
OPT=1  the  numbers  are  for  a  single  operation  and  when 
OPT=5 it is for five operations. In the workload experiment 
10000  unique  data  structure  operations  were  performed, 
resulting  in  10000  transactions  for  OPT  =  1  and  in  2000 
transactions for OPT=5. As an example, in the case of AVL 
tree  data  structure  with  OPT=1,  each  data  structure  insert 
operation created on average 30.5 writes and on average 5.1 
unique  pages  were  modified.  As  expected,  the  number  of 
write operations increases approximately five times between 
OPT=1  and  OPT=5.  However,  the  number  of  unique  pages 
touched  by  OPT=5  does  not  grow  linearly  with  respect  to 
OPT=1.  In  fact,  in  most  cases,  the  number  of  unique  pages 
touched  is  approximately  the  same.  This  is  because  the 
multiple  operations  within  the  transaction  may  touch  the 
same pages several times. 
Table 2: Data Structures and Operations  
Data 
OPT=1 
OPT=5 
Structures 
aa (AA-trees) 
avl (AVL trees) 
bin (Binomial queue) 
dsl 
hashquad  
hashsepchain  
leftheap (Leftist heap) 
heap (binary heaps) 
list (Linked list) 
queue (Queues) 
rb (Red black tree) 
splay (Splay trees) 
tree (Binary search tree) 
ops 
insert 
delete 
insert 
insert 
insert 
insert 
insert 
insert 
delete 
insert 
delete 
insert 
delete 
insert 
delete 
insert 
insert 
delete 
insert 
delete 
Avg. 
writes 
21.9 
20.4 
30.5 
27.9 
10.4 
11.3 
4 
23.5 
34.0 
2.8 
12.5 
4 
1 
3 
2 
13.7 
20.0 
7.7 
720.7 
1.7 
Avg. 
pages 
4.9 
6.0 
5.1 
2.0 
3.1 
1.0 
1.9 
3.0 
9.2 
2.4 
2.7 
1.0 
1 
1.8 
1 
4.6 
4.7 
3.0 
5.4 
1.7 
Avg. 
writes 
109.9 
102.0 
152.8 
139.9 
52.0 
56.9 
20 
117.8 
170.0 
14.3 
62.7 
20 
5 
15 
10 
68.5 
100.4 
38.8 
3603.9 
8.56 
Avg. 
pages 
5.0 
8.8 
5.1 
2.3 
3.6 
1.6 
1.9 
3.0 
18.5 
2.8 
4.1 
1.0 
1 
1.9 
1 
4.9 
5.0 
6.7 
5.5 
4.1 
Dsl=Deterministic skip list 
Hashquad=Quadratic probing hash 
Hashsepchain=Separate chaining hash 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:59 UTC from IEEE Xplore.  Restrictions apply. 
378A.  Performance with OPT=1 
Figure 11 shows the performance of some representative 
sets  of  data  structure  operations  from  the  table.  Note  that 
results  for  all  data  structures  are  not  shown  due  to  space 
constraints  and  the  fact  that  they  were  very  similar  to  the 
ones in the figure. For most operations including the queue, 
list,  heap,  splay  and  aa  shown  in  the  figures,  performance 
improves from PT to Emul to Emulxen to PTxen with PTxen 
being  the  best  in  most  cases,  although  there  are  some 
exceptions.  Results  for  hashquad,  bin  and  tree  show  that 
Emul  is  more  expensive  than  PT.  This  is  because  these 
operations  have  a  high  write  rate  (high  WPP)  and  a  low 
number of unique pages written to (low PPT) in a transaction. 
As  discussed  earlier,  page-tracking  based  approaches 
outperform  emulation-based  approaches  for  applications 
with  such  characteristics.  A  tree-insert  operation  has  a  very 
high value of WPP = 720.7/5.4 = 133.4, giving the emulation 
based approaches a very high overhead. 
Comparing insert and delete operation for lists for Emul 
and  Emulxen,  we  observe  that  insert  operations  are  more 
expensive  than  delete  operations.  This  is  because  insert 
operations incur more memory writes than delete operations. 
In  general,  the  overhead  of  emulation  based  approaches  is 
proportional to the number of memory writes.  
Figure 12: Speedup from hypervisor-assistance (OPT=1) 
Figure  12  shows  the  speedup  of  hypervisor-assisted 
approaches  compared 
their  user-level  counterparts. 
Emulxen shows up to 4x speedup (an average speedup of 3.5 
across data structures) and PTxen shows a speedup of up to 
13x (an average speedup of 11.4 across all data structures).  
B.  Transaction aggregation (OPT=5)  