2406    30th USENIX Security Symposium
USENIX Association
Analysis We use the Radare2 framework [64] for static
analysis and Triton [1] to perform taint tracking and symbolic
execution. Conceptually, for each system call, we explore
all possible execution paths that start at the system call’s en-
try point and end with its return. We look for loads whose
operand is unsafe (user-controlled) in one execution but safe
(kernel-controlled) in another execution. We detect such loads
by executing each path while performing taint analysis. We
maintain a taint bit for each architectural register and each
memory word. When analyzing a system call, we maintain
two sets: U and K, initially empty. For each path, we initially
taint the system call’s arguments (which are user-controlled)
and then symbolically execute the path while propagating
taint as described below. When we encounter a load instruc-
tion, we place it into U if its operand is tainted, or into K
otherwise. We ﬂag every load L ∈ U ∩ K. Listing 6 shows
pseudo code of the algorithm.
Our analysis is designed for ﬁnding proofs of concept. As
explained next, the analysis is not complete (may miss poten-
tial vulnerabilities), and it is not sound (may ﬂag a load that is
not a potential vulnerability). The results we report are after
manually discarding such false positives.
Incomplete: We often cannot explore all possible execu-
tion ﬂows of a system call, since their number is exponential
in the number of basic blocks. We therefore skip some paths,
which means we may miss potential vulnerabilities. We limit
the number of paths analyzed in each system call in two ways.
First, we limit the number of explored paths but ensure that
every basic block is covered. We start with the set Paths of the
1000 longest acyclic paths, to which we add the longest path
P (cid:54)∈ Paths that contains the basic block B, for each basic block
B not already covered by some path in Paths. The motivation
for adding these latter paths is to not ignore possible ﬂows to
other basic blocks; loads in a basic block covered by a single
explored path cannot themselves be identiﬁed as vulnerable.
Second, when exploring paths, we do not descend into
called functions (i.e., skip call instructions). Instead, we
queue that called function and the taint state, and analyze
them independently later. Overall, our analysis not ﬁnding
potential vulnerabilities does not imply that none exist.
Unsound: The analysis is unsound because it abstracts
memory and over-approximates taint. We model kernel and
user memory as unbounded arrays, MK and MU, respectively.
Let T (x) denote the taint of x, where x is either a regis-
ter or a memory location. Values in MU are always tainted
(∀a : T (MU [a]) = 1), whereas values in MK are initially un-
tainted, but may become tainted due to taint propagation.
We execute a memory access with an untainted operand
on MK, and from MU otherwise. A store MK[a] = R sets
T (MK[a]) = T (R). A load R = MK[a] sets T (R) = T (MK[a]),
and similarly for loads from MU. We assume that reads of
uninitialized memory locations read 0. As a result, many ob-
jects in the analyzed execution appear to alias (i.e., occupy the
same memory locations), which can lead to inaccurate taint
analyze_syscall(S):
U = K = /0
G = control-flow graph of S
for each acyclic path P ∈ G:
analyze_path(P)
analyze_path(P):
reset state, taint input argument registers
for each instruction I in P:
# propagate taint
if I is a load/store: propagate taint from/to memory
else: taint the output register of I iff
one of its operands is tainted
symbolically execute I
if I is a load:
add I to U or K, as appropriate
flag I if I ∈ U ∩ K
.
Listing 6: Finding potential compiler-introduced speculative type
confusion. (Conceptual algorithm, see text for optimizations.)
propagation. For instance, in the following code, a tainted
value is stored into MK[0x10] and taints it, which causes the
result of the subsequent load that reads MK[0x10] to be tainted.
In the real execution, however, the store and load do not alias
as they access different objects.
mov
mov
%rax ,0x10(%rbx)
0x10(%rcx),%rdx
# p->foo = x
# v = q->bar
Due to its unsoundness, we manually verify every potential
speculative type confusion ﬂagged by the analysis. Because
we limit the number of explored paths, the number of reports
(and thus false positives) is not prohibitive to inspect.
5.3 Analysis results
We analyze Linux v5.4.11, compiled with GCC 5.8.2 and
9.3.0. We use the allyes kernel conﬁguration, which enables
every conﬁguration option, except that we disable the kernel
address sanitizer and stack leak prevention, as they instrument
code and so increase the number of paths to explore. The
case studies below are valid with these options enabled. We
build the kernel with the -Os and -O3 optimization levels.
We analyze every system calls with arguments (393 in total).
Table 4 summarizes the results.
Depending on the optimization level, GCC 9.3.0 introduces
potential gadgets into 2–20 system calls, all of which stem
from the same optimization (§ 5.3.1). GCC 5.8.2 introduces a
“near miss” gadget into one system call (§ 5.3.2). This gadget
is not exploitable in the kernel we analyze, but the pattern
exhibited would be exploitable in other cases.
All the gadgets found are traditionally considered not ex-
ploitable, as the mispredicted branches depend on registers
whose value is available (not cache misses), and so can re-
solve quickly. We show, however, that branches with available
predicates are exploitable on certain x86 processors (§ 5.4).
USENIX Association
30th USENIX Security Symposium    2407
# vulnerable syscalls
compiler
GCC 9.3.0
GCC 9.3.0
GCC 5.8.2
GCC 5.8.2
† One potential vulnerability exists, see § 5.3.2.
ﬂags
-Os
-O3
-Os
-O3
20
2
0†
0
Table 4: Compiler-introduced speculative type confusion in Linux.
syscall(foo_t* uptr ) {
foo_t kfoo;
// some code
if ( uptr )
copy_from_user(&kfoo,
uptr ,
...);
f( uptr ? &kfoo : NULL);
// rest of code
}
# args: uptr in %rdi
...
testq %rdi , %rdi
je L # jump if %rdi ==0
# set copy_from_user args
...
# %rbp contains addr of
# stack buffer
mov %rbp, %rdi
call copy_from_user
L:callq f
(a) C pattern
Listing 7: Reusing registers for a function call.
(b) Emitted x86 code.
5.3.1 Supposedly NULL pointer dereference
The gadgets introduced by GCC 9.3.0 all stem from the same
pattern, a simpliﬁed example of which appears in Listing 7.
The system call receives an untrusted user pointer, uptr. If
uptr is not NULL, it safely copies its contents into a lo-
cal variable. Next, the system call invokes a helper f, which
receives NULL if uptr was NULL, or a pointer to the ker-
nel’s local variable otherwise. The helper f (not shown) thus
expects to receive a (possibly-NULL) kernel pointer, and
therefore dereferences it (after checking it is non-NULL).
In the emitted code, the compiler introduces a specula-
tive type confusion gadget by reusing uptr’s register to pass
NULL to f when uptr is NULL. If the attacker invokes the
system call with a non-NULL uptr and the NULL-checking
branch mispredicts “taken” (i.e., uptr=NULL), then f gets
called with the attacker-controlled value and dereferences it.
It is not clear that the gadget can be exploited, as both the
mispredicted branch and the dereference depend on the same
register. Why would the processor execute the dereference if it
knows that the branch mispredicted? We discuss this in § 5.4.
5.3.2 Stack slot reuse
GCC 5.8.2 with the -Os (optimize for space) ﬂag introduces
an interesting gadget. The gadget instance we ﬁnd is “almost”
exploitable. We describe it not only to show how a small
code change could render the gadget exploitable, but also to
demonstrate how insidious a compiler-introduced gadget can
be, and how difﬁcult it is for programmers to reason about.
The gadget (Listing 8) is emitted into a function called
long keyctl_instantiate_key_common(key_serial_t id,
struct iov_iter *from,
key_serial_t ringid) {
struct key *dest_keyring;
// ... code ...
ret = get_instantiation_keyring(ringid,rka,&dest_keyring);
if (ret target_key, payload,
plen, dest_keyring,
instkey);
// above call dereferences dest_keyring
}
(a) C code
# &dest_keyring argument
# ringid argument
0x18(%r14),%rsi # rka argument
%rsp,%rdx
%r15d,%edi
get_instantiation_keyring # returns error
%rax,%rax
%rax,%rbx
error2
# %rcx is a live register from caller
push %rcx
# ... code ...
lea
mov
mov
callq
test
mov
js
...
mov
# dest_keyring could be old %rcx if not
# overwritten in get_instantiation_keyring()
callq
# dest_keyring argument
# mispredict no error
key_instantiate_and_link
# if (ret < 0)
(%rsp),%rcx
(b) Emitted x86 code.
Listing 8: Attacker-controlled stack slot reuse in the keyctl system
call ﬂow.
by the keyctl system call. In this function, the com-
piler chooses to allocate space for the stack slot of a
local variable (dest_keyring) by pushing the rcx reg-
ister to the stack (a one-byte opcode) instead of sub-
tracting from the stack pointer (a four-byte opcode).
The rcx register holds a user-controlled value, one of
the caller’s (keyctl) arguments. The code then calls
get_instantiation_keyring(), passing it the address of
dest_keyring. If get_instantiation_keyring() returns
successfully, the code calls key_instantiate_and_link(),
which dereferences dest_keyring.
In
to
the
code
pass
reads
order
dest_keyring
to
key_instantiate_and_link(),
its
value from the stack. Consider what happens if the
earlier get_instantiation_keyring()
encoun-
ters an error, and therefore leaves the stack slot with
its original (user-controlled) value.
In a correct ex-
gets
ecution, key_instantiate_and_link()
called, due to the error-checking ﬂow. But
if an at-
tacker induces the error-checking branch to mispredict,
never
call
2408    30th USENIX Security Symposium
USENIX Association
called with
a
gets
key_instantiate_and_link()
user-controlled pointer argument
to dereference. The
only reason this instance is not exploitable is that
get_instantiation_keyring() error ﬂows overwrite
dest_keyring. There is no security-related reason for this
overwrite, since dest_keyring is a local variable that is
never exposed to the user (i.e., there is no potential kernel
information leak). Were this function to use a different coding
discipline, the gadget would be potentially exploitable.
5.4 Potential exploitability of the gadgets
Exploiting the gadgets described in § 5.3 appears impossible.
Typical Spectre gadgets exploit branches whose condition
depends on values being fetched from memory, and so take a
long time to resolve. In our case, the branch still mispredicts,
since prediction is done at fetch time (§ 2.2). However, the
branch condition is computable immediately when it enters
the processor backend, as the values of the registers involved
are known. One would expect the processor to immediately
squash all instructions following the branch once it realizes
that the branch is mispredicted, denying any subsequent leak-
ing instructions (if they exist) a chance to execute.
The above thought process implicitly assumes that the pro-
cessor squashes instructions in the shadow of a mispredicted
branch when the branch is executed. But what if the squash
happens only when the branch is retired? A branch’s retire-