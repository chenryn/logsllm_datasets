compute over a homomorphically encrypted database under the user’s own key. Their approach
supports diﬀerent kinds of queries, such as search-and-sum, search-and-max, and join queries, mak-
ing use of binary circuits for equality checks and comparisons.
Khedr et al. [33] constructed a secure email spam ﬁlter and a secure multi-keyword search from
homomorphic encryption. Exploiting the parallelism by working on a GPU platform, they achieve
good performance. In contrast to the other keyword search protocols, theirs has binary output: true
if a set of keywords exist in the encrypted ﬁle, and false otherwise.
1.6 Summary of Notations
– X is the sender’s set; Y is the receiver’s set. We assume |X| (cid:29) |Y |.
– σ is the length of items in X and Y .
– (cid:96) is the length of labels in Labeled PSI.
– n is the ring dimension in our FHE scheme (a power of 2); q is the ciphertext modulus; t is the
plaintext modulus [22,21].
– d is the degree of the extension ﬁeld in the SIMD encoding.
– m is the cuckoo hash table size.
– α is the number of partitions we use to split the sender’s set X in the PSI protocol (following
– [i, j] denotes the set {i, i + 1, ..., j}, and [j] is shorthand for the case i = 1.
[12]).
2 The CLR17 Protocol
We now review the protocol of [12] in detail. Following the architecture of [43], their protocol
instructs the receiver to construct a cuckoo hash table of its set Y . Speciﬁcally, the receiver will
use three hash functions h1, h2, h3, and a vector BR[0], . . . , BR[m] of O(|Y |) bins. For each y ∈ Y ,
the receiver will place y in bin BR[hi(y)] for some i such that all bins contain at most one item.
The sender will perform a diﬀerent hashing strategy. For all x ∈ X and all i ∈ {1, 2, 3}, the sender
places x in bin BS[hi(x)]. Note that each bin on the sender’s side will contain O(|X|/m) items with
high proabibility when |X| (cid:29) m. It then holds that the intersection of X ∩ Y is equal to the union
of all bin-wise intersections. That is,
X ∩ Y =
BR[j] ∩ BS[j] =
{yj} ∩ BS[j]
(cid:91)
(cid:91)
j
j
(cid:89)
x∈BS [j]
(cid:74)z(cid:75) := r
((cid:74)y(cid:75) − x)
where yj is the sole item in bin BR[j] (or a special sentinel value in the case that BR[j] is empty).
The protocol then speciﬁes a method for computing {y}∩ BS[j] using FHE. The receiver ﬁrst sends
an encryption of y, denoted as(cid:74)y(cid:75), to the sender who locally computes
When y ∈ BS[j], observe that one of the terms in the product is zero and therefore(cid:74)z(cid:75) will be an
encryption of zero.(cid:74)z(cid:75) is returned to the receiver, who concludes that y ∈ X if z = 0. In the case
that y (cid:54)∈ BS[j], the product will be the product of diﬀerences. The sender randomizes this product
using a uniformly sampled element r ∈ F∗ for some ﬁnite base ﬁeld F used to encode the items. As
a result, z = 0 if and only if y ∈ X. Otherwise z is uniformly distributed and independent of the
set X.
Building on this general protocol, [12] proposed several optimizations which make computing
this circuit computationally eﬃcient. First, recall that the receiver has a vector of m = O(|Y |) bins,
each containing (at most) a single element y1, ..., ym. Each yj must be intersected with BS[j]. FHE
naturally supports a technique which allows encrypting vectors and performing Single Instruction
Multiple Data (SIMD) operations on the encrypted vectors ([50]). In this way many of the items yj
can be encrypted into a single ciphertext and processed concurrently, which results in a signiﬁcant
performance improvement.
x∈BS [j]((cid:74)y(cid:75)− x) directly was observed to be ineﬃcient due to
Despite this, computing(cid:74)z(cid:75) := r(cid:81)
the performance penalty of using FHE to evaluate large degree polynomials on encrypted values.
The multiplicative depth of directly computing z is O(log B) for B ≈ |X|/m, and [12] reduced it to
O(log log B) using a windowing technique. Namely, observe that z can be viewed as a polynomial
P (y) = aByB + ... + a1y + a0 where the ai are determined by r and BS[j]. The sender needs to
compute encryptions of all the powers of y between 1 and B. Given an encryption of only y, this
can be done in O(log B) depth using the square-and-multiply algorithm. However, the receiver can
now assist in the computation by sending additional powers of y. For example, if the receiver sends
encryptions of y20, y21, y22, ..., y2log B , the sender can use these terms to compute all necessary powers
of y in multiplicative depth O(log log B). They also partitioned the sender’s bins into α subsets.
The sender can then process each of these subsets independently. This reduces multiplicative depth
further to O(log log B
α ). The downside of this approach is that for each y several response ciphertexts
z1, ..., zα must be sent back to the receiver, increasing the reply size by a factor of α. Finally, the
authors used the modulus switching technique to reduce the return communication.
3 PSI with Long Items
The [12] protocol achieves good performance for 32-bit items and scales well to very large sets on
the sender’s side. However, it scales less well for longer items for the following reasons. Suppose
the eﬀective item length is σ bits. Then they need to set the plaintext modulus in the FHE scheme
to t ≈ 2σ. Now let L denote the depth of the homomorphic evaluation at the sender’s side. In
[12] the depth L depends double-logarithmically on |X|. Hence for our purposes we assume L is a
constant. Then, the BFV scheme requires log q (cid:38) L log t for correctness, but using the complexity
estimates in Section 1.2 we see that the communication cost of [12] grows linearly with σ; on the
other hand, the computational cost grows quadratically with σ, which is undesirable.
Another side-eﬀect of large σ comes from the security requirement: it drives up the FHE pa-
rameters t and q, and in order to keep the security level on par, the parameter n needs to increase
as well. Now two cases can arise: if |Y | is large compared to n then—since increasing n will increase
the number of slots in each ciphertext—we end up using fewer ciphertexts, and the performance
overhead is small; on the other hand, if |Y | is of similar size as the previous n value then—after
switching to new value of n—many slots could remain unused, which means the communication
cost went up for no beneﬁt.
Regardless of the initial length of the items, it is customary to apply a hash function of output
length λ + log |X| + log |Y |, and perform the intersection protocol on these short hashes. Here
λ denotes the statistical security parameter. In practice, we set λ = 40, thus we require t to be
roughly 80 bits. However, using such a large value for t has a huge impact on the performance of
the [12] protocol. In this work, we resolve this issue by using the general SIMD encoding method
proposed in [50], which allows coeﬃcient-wise operations on vectors of ﬂexible length and width.
More precisely, for a tunable parameter d, we can operate on vectors of length n/d, where each
entry can take td diﬀerent values (when d = 1, this is the SIMD method used in [12]).
More precisely, the plaintext space of BFV scheme equals Rt = Zt[x]/(xn + 1). Suppose t is a
prime number, and xn + 1 (mod t) factors into a product of irreducible polynomials {Fj(x)}, each
of degree d. Moreover, suppose d is the smallest positive integer such that td ≡ 1 (mod 2n). Then
the SIMD encoding can be explained as the following two isomorphisms
φ−→(cid:89)
Rt
n/d(cid:89)
Zt[x]/(Fj(x))
ψ−→
F
td
td is a ﬁxed ﬁnite ﬁeld of td elements. Now SIMD encoding corresponds to φ−1 ◦ ψ−1, and
where F
decoding is the isomorphism ψ ◦ φ.
j
i=1
3.1 Trade-Oﬀs for SIMD with Wider Slots
Communication cost The concrete communication cost of our PSI protocol can be computed in the
following way: the query consists of m/k · (log(|X|/m)) ciphertexts, where k = n/d is the number
of slots supported in a ciphertext, and m = O(|Y |). Each ciphertext has size 2n log q = 2nL log t
bits. Here log t ≈ σ/d, since every element in the ﬁnite ﬁeld F
td can represent a d log t-bit item.
The reply from the sender consists of m/k · α ciphertexts, each with size roughly 2n log(tn) bits.6
6 This is because we can perform the modulus switching trick to reduce the modulus to q(cid:48) ≈ tn.
We view |Y | (and m), |X|, n, and L as constants. Then the query size is a constant multiple of
log d + log |X|− log n, so increasing d will increase the query size. However, in our setup we usually
have log |X| (cid:29) log n. Since d < n always, the log |X| term dominates. The reply size is also slightly
worse for larger d, but its eﬀect is small.
Computational cost The sender’s online computation consists of Θ(|X|/k) homomorphic multipli-
cations, each taking n log n(log q)2 bit operations. After hiding all the constants, we see that the
computational cost is Θ(1/d), so increasing d has a direct positive eﬀect on the online computing
time.
Eﬀect of choosing diﬀerent n Using a larger value of d has another implicit beneﬁt: it allows
choosing a smaller t for the same item bit-length, hence one can choose a smaller q, which also
opens the possibility of choosing a smaller n. We can use the above heuristics to analyze the eﬀect
of changing n. The computational cost is |X|/d log n· L2σ2 bit operations, and communication cost
|X|d
n ) · 2Lσ , so both the computation and communication depend only
is m(2d log n + σ)α + m log(
logarithmically on the value of n. Therefore, the eﬀect of n on performance is marginal when the
other parameters are held ﬁxed.
We conclude that under the same setup, using wider slots (i.e. a larger value of d) to encode
items results in larger communication and smaller on-line computation.
3.2 Lazy SIMD Encoding Algorithm
[50] suggested that an FFT algorithm can be utilized for fast SIMD encoding and decoding. The
FFT algorithm is very eﬃcient when d is small, but for larger values of d there exist more eﬃcient
algorithms. For example, the HElib library [27] performs the encoding in two steps. Let Fj =
td)k to F1 × ··· × Fk through k ﬁeld isomorphisms. Then a tree-based
Zt[x]/(Fj). They ﬁrst map (F
CRT algorithm is used to invert the ﬁrst map φ: given fj(x) ∈ Zt[x]/(Fj), return f ∈ Zt[x]/(F ),
such that fj = f mod Fj.
We make the observation that the second map ψ can sometimes be omitted in the encoding.
Indeed, it is necessary if one wishes to homomorphically permute items in the F
td slots. Since our
current application does not require such permutations, we could skip this step and solely use φ
and its inverse for decoding and encoding. This saves computation time as well as storage, since
evaluating ψ requires the information of the isomorphisms Fj → F
On the other hand, the FFT algorithm can perform ψ ◦ φ in one step, and there are fast
algorithms that work with the xn + 1 modulus. However, a natural way to utilize FFT in this
scenario seems to require working with data of length n, using the 2n-th roots of unity in F
td. The
complexity of such an algorithm is O(n log n) operations in F
td.
td.
To determine the optimal strategy, we performed a comparison by implementing both the lazy
encoding algorithm and the FFT algorithm using FLINT [28] and present the results in Figure 1.
From the results we can see that the lazy encoding algorithm has a speed advantage which grows
with the extension degree d.
4 OPRF Pre-processing
We now demonstrate how a pre-processing phase can be performed to facilitate a more eﬃcient
online phase. The core idea is to ﬁrst update the values being intersected using an oblivious PRF,
where only the sender knows the key. This has the eﬀect that several costly countermeasures
employed by [12] to protect the senders set can be eliminated.
log n
t
d FFT time (ms) Lazy SIMD time (ms)
11 0x2E01 8
12 0x13FF 8
13
0x3401 16
14 0x2A01 64
Table 1. Comparison of SIMD encoding algorithms.
3.3
12
32.6
512
1.5
4
9.2
23.5
4.1 The CLR17 Approach
The [12] protocol performs noise ﬂooding to prove the security for the sender. The need for this stems
from the fact that noise growth in homomorphic operations depends not only on the ciphertexts
being operated on, but also on the underlying plaintexts. Thus, their security proof cannot work if
the result ciphertexts are not re-randomized at the end, and if the underlying noise distribution is
not hidden by ﬂooding the noise by an appropriate number of bits.
There are at least two diﬀerent problems with this approach. First, it requires the sender to
estimate a heuristic upper bound on the size of noise, and ensure that there is enough noise room
left to perform an appropriate amount of noise ﬂooding. This makes it impossible to run their
protocol with small FHE parameters, even for very small sets. Also, their protocol is fragile against
malicious attacks. For example, the receiver can insert more noise into its ciphertexts, causing the
sender to noise-ﬂood by fewer bits than it thinks. Now, by examining the noise distribution after
the PSI computation, the receiver can potentially obtain extra information about the sender’s set.
4.2 Our Solution
We take a diﬀerent approach to solving this problem, allowing us to get rid of noise ﬂooding
altogether. Namely, we use an OPRF to hash the items on both sides before engaging in the PSI
protocol. This ensures that the sender’s items X \ Y are pseudo-random in the receiver’s view,
preventing the receiver from learning anything about the original items, even if it learns the hashed
values in full.
Abstractly, we have the sender sample a key k and instruct it to locally compute X(cid:48) = {Fk(x) |
x ∈ X}. The receiver then interactively applies the OPRF to its set, obtaining Y (cid:48) = {Fk(y) | y ∈ Y }.