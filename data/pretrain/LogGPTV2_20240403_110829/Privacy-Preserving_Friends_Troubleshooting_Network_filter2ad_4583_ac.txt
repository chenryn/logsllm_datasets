choose k = 6: Our data showed that the median number of
suspect entries is 1171, with 87% of them having a single
value, with 7% of them having 2 values, 3% having 3 values,
1
ClusterEntranceClusterExitClusterEntranceNon-HelperHelperHelperForwarderA cluster hop on the forwarding path 0111121333340.Receive a request1.Distribute shares2.Elect the cluster exit3.Unicastsubtotal4.Aggregate cluster sum and proxy162
163
(cid:161)
(cid:162)6. For a 4-valued entry, the odds are
and 3% more than 3. For a 2-valued entry, the odds of a
collision are 1
166 . For a 3-valued entry, the odds of at least one
1 − 15·14
collision are
(1− 15·14·13
)6. Collisions in entries with more values are even
more likely; however, we are only interested in the case where
there are enough collisions to produce only 3 or fewer values
in each hash function; otherwise, the collision is irrelevant as
the undercounted cardinality is unlikely to cause PeerPressure
to identify the entry as a root cause. The probability of such a
collision is lower than the probability of a collision among 4
values, so in the following computation we consider all entries
to have no more than 4 values.
The chances of a collision occuring in any of the 1171
entries can be calculated as:
(cid:180)0.03·1171
(cid:162)6
1 −(cid:161)
(cid:179)
1 −(cid:161)
·
1 − 1
166
(cid:162)0.07·1171 ·
(cid:162)6
(cid:179)
1 −(cid:161)
(cid:180)0.03·1171 ≈ 5%.
1 − 15·14
162
1 − 15·14·13
163
in about 5% of all
Therefore,
troubleshooting requests,
there will be some entry with an undercounted cardinality of
3 or less, which may be identiﬁed as a root cause. As we
will show next, such collisions can be discovered during the
second round query for the most popular values. If collisions
are found, then the sick machine can retry with a different
set of hash functions or larger k. The new request should
include only the entries where collisions occurred and thus
the communication overhead will be much smaller.
For any suspect entry e, hash collisions in this entry may
cause its ranking to improve, while hash collisions in lower-
ranked entries may cause them to overtake e and lower its
ranking. Nevertheless, it is hard for entries with signiﬁcantly
larger cardinality to catch up on ranking. Therefore, in the
second round, we query the most popular values of a few more
top-ranking entries in order to account for possible collisions.
2) Diagnosis on the Sick Machine and Second Round
Query: Using the aggregated histogram, the sick machine
estimates cardinalities for all suspect entries, and then ranks
suspected entries according to the PeerPressure algorithm.
However, the histogram does not reveal what the correct value
for the entry should be; in order to discover it, the sick machine
needs to perform another round of the protocol.
The sick machine can identify the hash of the most popular
value hj(v) = i, where hj is the hash function from which we
obtained the cardinality. It can then ask its friends to identify
which value has that hash. However, only someone who runs
the same application will be able to answer this query, and
we do not want to reveal who that might be. Therefore, we
once again make use of secure multiparty sum to ﬁnd the most
popular value without compromising privacy.
In the second round of the protocol, the sick machine makes
another request, this time containing a list of the top-ranking,
root-cause candidate entries, as well as the hash values of the
most popular value; i.e. triples (e, i, j). The second round
proceeds similarly to the ﬁrst one to compute an aggregate
over all the participants, except that it uses the same clusters
(cid:80)
and exit nodes as the ﬁrst round, rather than picking new ones.
The aggregate value computed is sume =
Ve|hj (Ve)=i Ve.
To do this, each participant who helped in the ﬁrst round, and
whose value for e matches the hash value in the second request
(hj(Ve) = i) will contribute Ve to the sum. All other members
will contribute 0.
Since Ve may be a string, we have to convert it to an integer
value. We do this by considering the bit representation of the
string as an integer and adding it to the sum. Since all the
shares in the multiparty sum must be of the same size, we
take the sum over 8192-bit integers. This allows us to support
strings that are up to 1024 bytes in length. The shares in this
round are larger than in the ﬁrst one; however, the number of
entries involved is much smaller and so the communication
complexity is similar to the ﬁrst round.
Once the sick machine receives the aggregate from all the
nodes, it can compute the most popular value Ve by dividing
sume by the histogram value i (i.e., the number of samples
with value Ve) for hash function j from the ﬁrst round.3 The
result, interpreted as a string, will be the most popular value,
which can then be used to repair the sick machine.
If the division results in a non-integral value, or the resulting
string is not intelligible (e.g., contains non-ASCII characters),
this signals that a collision occurred and there are multiple
values such that hj(Ve) = i. In this case, the sick machine
will know that the cardinality of e was undercounted. The
sick machine will need to repeat the ﬁrst-round query with
a different set of hash functions to obtain a more accurate
cardinality estimate, and then use the second round to obtain
the most popular values.
V. PROTOCOL EVALUATION
A. Security Analysis
To evaluate the security of our design, we consider the
kind of information that is revealed to each participant in the
protocol. Note that secure communication channels at each
link render eavesdropping attacks ineffective, and hence we do
not need to consider attacks from nodes who do not participate.
A cluster member that is neither an entrance nor an exit
will only learn the troubleshooting query, which does not
identify the sick machine and thus does not contain privacy-
compromising information.
A cluster entrance will see the query and the aggregate of
the contributions so far. However, since this aggregate includes
a random initialization, it will not be able to ﬁnd out the
contributions of past clusters or ﬁnd out whether the previous
hop was the sick machine or simply a forwarder. It will also
receive the aggregate data from the cluster exit. This data will
include the contribution from the cluster as well as from any
further hops. Because of the random wait, the cluster entrance
will not be able to tell whether further hops were involved and
isolate the contributions from the cluster members.
3A more robust scheme would recompute the count of contributors to Ve
in order to be more tolerant of cluster members that may have left between
the ﬁrst and second round.
The cluster exit will receive the shares of the cluster
members’ contributions and will be able to compute their sum.
However, this sum will include the aggregate from the past
hops contributed by the cluster entrance, hence the cluster exit
will not be able to isolate the contributions from the cluster. It
will also receive the aggregate from the next cluster entrance.
However, this aggregate will include contributions from mem-
bers of the next cluster as well as potential subsequent clusters,
all of which are not known to the cluster exit.
We can see that message inspection attacks at any single
node do not reveal any privacy-sensitive information. Next,
we will consider gossip attacks when two members collude.
If a cluster entrance colludes with the cluster exit, together
they will be able to determine the contributions of the other
cluster members. They will still be unable to determine what
each individual member contributed: the secure multi-party
sum ensures that all other cluster members must collude to
reveal the contributions of an individual member. However,
they will learn some facts, such as the number of cluster
members that decided to help. By reducing the probability to
help, this number will be a small fraction of the cluster size
and therefore not compromise the privacy of the participants.
Section V-C examines the corresponding trade-off between
privacy and protocol efﬁciency.
The fair random selection of the cluster exit mitigates the
chances of a collusion between the cluster entrance and exit.
If a cluster entrance has C colluders in the cluster, the chance
of one of them being picked as the exit is C/G, where G is
the cluster size. A Sybil attack can be used to increase these
chances; on the other hand, threshold participation (Section IV-
D.3) mitigates the consequences of a collusion. It is also
possible for a cluster entrance to cooperate with the entrance
of the next cluster and isolate the contributions of the cluster.
However, this type of collusion is less likely, since the next
entrance is picked by the cluster exit and never revealed to the
previous entrance.
The use of a historyless random walk makes polling attacks
less productive, as an attacker cannot reduce the likelihood of
a friend forwarding a troubleshooting request to other clusters.
Any response to a request is likely to include the aggregate
information from several clusters and not reveal privacy-
compromising details. As another defense against polling
attacks, we limit the rate at which a node becomes a helper
in queries (see Section VI).
B. Friends Network Characteristics
We obtained a snapshot of MSN IM operational data from
2003. It had 150,682,876 users. The number of friends of a
IM user represents the upper limit of our cluster size. Figure 3
depicts the distribution on the number of friends, showing a
median of 9, and an average of 19. We excluded those users
with just one friend since these nodes will not be included on
the FTN forwarding path.
The number of common friends impacts the FTN routing
because FTN needs to avoid loops or double-counting (Sec-
tion IV). we found that two neighboring nodes have 14.15%
Fig. 3. Distribution of the Number of Friends
of common friends in average; two nodes that are two hops
away from each other have 2%; three hops, 0.3%; and 4 hops,
less than 0.1%. Further, we randomly picked 100 IM users
with more than 4 friends (since an FTN node will not form
a cluster unless it has more than 4 friends (Section IV-D.1).
We ﬁnd that on average, 28.92% of a node’s friends do not
share any common friends with the node; 21.52% have one
common friend with the node; 10.61% have 2; 9.85% have 3;
the remaining 29.1% have 4 or more.
Another friends network characteristics that is of interest
to the FTN is how likely is a troubleshooting request to be
routed to a “dead end”, a node on the forwarding path with no
other friends to proxy the request on. In such cases, parameter
(cid:80)
propagation terminates without gathering enough samples. The
probability of routing to such dead ends is PT oDeadEnd =
i P (G = i) · PDeadEnd(i), where P (G = i) denotes the
percentage of clusters of size i, and PDeadEnd(i) represents
the average percentage of dead end participants in a cluster
of size i. According to our computation from our MSN IM
data, PT oDeadEnd = 0.0013. So, the average number of nodes
that need to be traversed before reaching such a dead end is
1/0.0013 = 770, which far exceeds the number of nodes that
need to be traversed with the FTN protocol (Section V-C).
C. Tradeoff Analysis
1) Metric: We use the metric of probable innocence that
was introduced by Reiter and Rubin [14] for measuring the
uncertainty of a cluster member being a helper: A cluster
member is considered to be probably innocent if, from the
colluders’ point of view, the member appears no more likely to
be a helper than not to be one. This requires that no more than
half of the cluster participants should help with troubleshoot-
ing, or Ph < 0.5. Therefore, we deﬁne the innocence level,
I = −log10PI, where PI is the probability that over half of
the cluster participants help with troubleshooting. We exclude
the cluster entrance and exit from the participants since we are
assuming that they are colluding in order to ﬁnd out the cluster
h(1 − Ph)G−2−i
aggregate. PI =
P i
where G is the cluster size. Here, we assume the worst case
scenario that every cluster member owns the application under
troubleshooting — if not, PI will be smaller. We also assume
that every cluster member chooses the same Ph. Therefore,
(cid:80)G−2
i=[(G−2)/2]+1
(cid:161)G−2
(cid:162)
i
0246810121427121722273237424752576267727782879297..Number of FriendsPercentage(100%)also simulated our FTN routing protocol on the static MSN IM
topology, conﬁgured with various innocence levels. For each
innocence level, we randomly picked 100 starting nodes as the
requestor, and set Pf = 1 − 1/N = 0.9 for N = 10 samples.
We list in Table I the number of clusters and nodes involved
based on our simulation. One can see that in general, the num-
ber of clusters involved in our simulation is slightly smaller
than our calculations. This is because we used an upper-bound
estimate of Poverlap = 2.33% for our calculations, while in
our simulation, Poverlap is different for each cluster, and is
in general less than 2.33%. In reality, the number of clusters
required to collect 10 samples might be larger, since not all
friends are available or own the corresponding application. It
is clear from the table that the higher the privacy requirement
is, the longer the routing path it takes.
3) Iterative helper selection.: Using the iterative helper
selection method described in Section IV-D.2, we can guar-
antee probable innocence for all the cluster participants in the
face of cluster entrance and exit collusion, while achieving
a higher participation rate. For example, we can set
the
probability to participate Pp based on the cluster size to the
value corresponding to I = 1 in Figure 4. The average number
of helpers in a cluster will match the one when Ph is chosen
similarly, and hence we expect the search to terminate after
only 2.02 clusters. However, we can compare the privacy level
to that with innocence level 9, as in both cases the probability
that more than half of the cluster members will become helpers
is negligible. (Of course, at innocence level 9, the expected
number of helpers will be signiﬁcantly less than half.)
The helper selection causes involves at
least one extra
round communication in each cluster, more if retries are
necessary, which will happen with probability 10% in our
example choice of Pp. Therefore, the latency of a request
using the iterative method going through n clusters will be
higher than if the adaptive Ph method is used by a factor
of about 3.1/2 (as there are two rounds of communication
in the adaptive Ph method). However, this is still lower than
the latency of a request when innocence level 3 or higher
is desired. Furthermore, since fewer machines are involved
in the aggregate computation,
there’s less of a chance of
encountering a malicious or compromised node. Therefore,
the iterative helper selection method is useful when a high
level of privacy is desired, and when the median cluster sizes
are small.
4) Threshold-Driven Helping Vs. Number of Clusters:
Now, we evaluate the path length overhead due to the use
of threshold-driven helping strategy (Section IV-D.3). Based
on our common friends data from the MSN IM network
(Section V-B), a threshold of T = 1 reduces the number of
helpers from the cluster by 28.92%, T = 2 by 50.44%, and
T = 3 by 61.05%. Figure 5 shows the trend of average number
of clusters needed with these threshold values to obtain 10
samples for nine different innocence levels.
Fig. 4. The Selection of Ph for Different Cluster Sizes to Achieve Different
Innocence Levels.
the higher the innocence level I is, the better the privacy is,
and the smaller the PI is. Figure 4 shows Ph’s that a member
should take with various cluster sizes for achieving different
innocence levels. In general, Ph takes a smaller value for a
higher innocence level or a smaller cluster size.
N
i P (G=i)·i·Ph,i
Pown·(cid:80)
We use the average number of clusters involved in trou-
bleshooting, E(Nc), as the metric for evaluating protocol
efﬁciency, since the troubleshooting response time E(Nc)
is dictated by the number of clusters a troubleshooting re-
quest traverses. (The expected number of nodes involved is
approximately 19 · E(Nc) since a node has 19 friends on