P given by the solution of the algebraic Riccati equation:
AP AT − P + R1 = AP C T (R2 + CP C T )
−1CP AT .
(6)
The reconstruction method given by (3)-(6) is referred to as
the steady state Kalman Filter, cf. [7].
2.2.2 Residuals and Hypothesis Testing
Although the notion of residuals and model-based detec-
tors is now routine in the fault detection literature, the pri-
mary focus has been on detecting and isolating faults that
occur with a speciﬁc structure (e.g., bias drifts). Now, in the
context of an intelligent adversarial attacker, new challenges
arise to understand the worst case eﬀect that an intruder can
have on the system. While fault detection techniques can be
used to detect attacks; it is important to assess the perfor-
mance of such methods against an intelligent adversary. In
this work, by means of our simulation study, we assess the
performance of two model-based fault detection procedures
(the chi-squared and the CUSUM procedures) for a variety
of attacks. These procedures rely on a state estimator (e.g.,
Kalman ﬁlter) to predict the evolution of the system. The
estimated values are compared with sensor measurements
¯yk (which may have been attacked). The diﬀerence between
the two should stay within a certain threshold under normal
operation, otherwise an alarm is triggered to point a poten-
tial attack. Deﬁne the residual random sequence rk, k ∈ N
as
rk := ¯yk − C ˆxk = Cek + ηk + δk.
(7)
If there are no attacks, the mean of the residual is
E[rk+1] = CE[ek+1] + E[ηk+1] = 0m×1.
(8)
where 0m×1 denotes an m×1 matrix composed of only zeros,
and the covariance is given by
Σ := E[rk+1rT
k+1] = CP C T + R2.
(9)
For this residual, we identify two hypothesis to be tested, H0
the normal mode (no attacks) and H1 the faulty mode (with
attacks). For our particular case of study, the pressure at
the nodes and the water level in the tank are the outputs of
the system. Using this data along with the state estimates,
we construct our residuals. Then, we have:
(cid:26) E[rk] = 0m×1,
E[rkrT
k ] = Σ,
H0 :
(cid:26) E[rk] (cid:54)= 0m×1,
E[rkrT
k ] (cid:54)= Σ.
or H1 :
Figure 4 shows the approximated distributions of the resid-
uals of the water level in the storage tank for both the at-
tacked and the attack-free cases. In Figure 4(b), the residual
under a bias injection attack (simple constant oﬀset on the
sensor measurements) is depicted. Our hypothesis can eas-
ily be veriﬁed by looking at the probability distribution of
residuals. Our null hypothesis H0 which follows a zero mean
normal distribution with variance Σ is also veriﬁed from plot
in Figure 4(a). Similarly, for the attacked scenario H1, we
do not have a zero mean normally distributed residual as
it is shown in Figure 4(b). We can formulate the hypoth-
esis testing in a more formal manner using existing change
detection techniques based on the statistics of the residuals.
2.2.3 Cumulative Sum (CUSUM) Detector
The CUSUM procedure is driven by the residual sequences.
In particular, the input to the CUSUM procedure is a dis-
tance measure, i.e., a measure of how deviated the estimator
is from the actual system, and this measure is a function of
the residuals. In this work, we assume there is a dedicated
detector on each sensor (or on any sensor we want to include
in the detection scheme). Throughout the rest of this paper
we will reserve the index i to denote the sensor/detector,
i ∈ I := {1, 2, . . . , m}. Thus, we can partition the attacked
output vector as ¯yk = col(¯yk,1, . . . , ¯yk,m) where ¯yk,i ∈ R
denotes the i-th entry of ¯yk ∈ Rm; then
¯yk,i = Cixk + ηk,i + δk,i,
(10)
with Ci being the i-th row of C and ηk,i and δk,i denoting
the i-th entries of ηk and δk, respectively. Inspired by the
empirical work in [9], we propose the absolute value of the
entries of the residual sequence as distance measure, i.e.,
zk,i := |rk,i| = |Ciek + ηk,i + δk,i|.
(11)
-6-4-20246Residue (r(i,k))00.050.10.150.20.250.30.35Probability Distribution-150-100-50050100150Residue (r(i,k))00.020.040.060.080.10.120.140.160.18Probability Distribution104Note that, if there are no attacks, rk,i ∼ N (0, σ2
i ) (see Figure
4(a)), where σ2
i denotes the i-th entry of the diagonal of
the covariance matrix Σ. Hence, δk = 0 implies that |rk,i|
follows a half-normal distribution [24] with
E(cid:2)|rk,i|(cid:3) =
√
2√
π
σi and var(cid:2)|rk,i|(cid:3) = σ2
i
(cid:16)
(cid:17)
.
1 − 2
π
(12)
Next, having presented the notion of distance measure, we
introduce the CUSUM procedure. For a given distance mea-
sure zk,i ∈ R, the CUSUM of Page [22] is written as follows.
Figure 5: CPS under attack.
CUSUM: S0,i = 0,
(cid:26) Sk,i = max(0, Sk−1,i + zk,i − bi),
i ∈ I,
Sk,i = 0 and ˜ki = k − 1,
if Sk−1,i ≤ τi,
if Sk−1,i > τi.
(13)
Design parameters: bias bi > 0 and threshold τi > 0.
Output: alarm time(s) ˜ki.
From (13), it can be seen that Sk,i accumulates the distance
measure zk,i over time. When this accumulation becomes
greater than a certain threshold τi an alarm is raised. The
sequence Sk,i is reset to zero each time it becomes negative
or larger than τi. If zk,i is an independent non-negative se-
quence (which is our case) and bi is not suﬃciently large, the
CUSUM sequence Sk,i grows unbounded until the threshold
τi is reached, no matter how large τi is set. In order to pre-
vent these drifts, the bias bi must be selected properly based
on the statistical properties of the distance measure. Once
the the bias is chosen, the threshold τi must be selected to
fulﬁll a required false alarm rate A∗
i . The occurrence of an
alarm in the CUSUM when there are no attacks to the CPS
is referred to as a false alarm, and Ai ∈ [0, 1] denotes the
false alarm rate for the CUSUM procedure deﬁned as the
expected proportion of observations which are false alarms
[3, 27].
2.2.4 Bad-Data Detector
We have also implemented the Bad-Data detector for this
case of study because it is widely used in the CPS security
literature [11, 17]. We also present a performance compari-
son between the CUSUM and the Bad-Data detectors. For
the residual sequence rk,i given by (7), the Bad-Data detec-
tor is deﬁned as follows.
Bad-Data Procedure:
|rk,i| > αi, ˜ki = k,
If
i ∈ I.
(14)
Design parameter: threshold αi > 0.
Output: alarm time(s) ˜ki.
Using the Bad-Data detector an alarm is triggered if dis-
tance measure |rk,i| exceeds the threshold αi. Similar to the
CUSUM procedure, the parameter αi is selected to satisfy
a required false alarm rate A∗
i .
3. ATTACKER AND ATTACK MODELS
In this section, we introduce the types of attacks launched
on our water distribution network. Essentially, the attacker
model encompasses the attacker’s intentions and it’s capa-
bilities. The attacker may choose its goals from a set of
intentions [26], including performance degradation, disturb-
ing a physical property of the system, or damaging a com-
ponent.
In our experiments, three classes of attacks are
modeled and executed. It is assumed that the attacker has
access to yk,i = Ciyk + ηk,i (i.e., the opponent has access to
sensor measurements). Also, the attacker knows the system
dynamics, the state space matrices, the control inputs and
outputs, and the implemented detection procedure. The ad-
versary has perfect knowledge of the Kalman ﬁlter and can
modify the sensor readings to an arbitrary value.
1. Bias Injection Attack : First, a failure-like attack is
designed. The attacker’s goal is to deceive the con-
trol system by sending incorrect sensor measurements.
In this scenario, the level sensor measurements are in-
creased while the actual tank level is invariant. This
makes the controller think that the attacked values
are true sensor readings; and hence, the water pump
keeps working until the tank is empty and the pump
is burned out. The attack vector can be deﬁned as,
¯yk = yk + ηk + ¯δ,
(15)
where ¯δ is the bias injected by the attacker.
2. Zero-Alarm Attack : The second attack is more sophis-
ticated and is carried out by carefully generating δk
to drive the system to an undesired state. The objec-
tive of this attack is to maximize the damage without
raising alarms. This attack is designed to deceive the
detection schemes explained in Section 2.2.3 and Sec-
tion 2.2.4. A detailed analysis on how to design such
an attack is presented in Section 4.2.1. This attack
does not cause alarms because the injected value and
the previous steady state measurement diﬀer only in
a small amount, then the residual value would not be
suﬃciently large to raise an alarm. By knowing the pa-
rameters of the detection procedure, it is always pos-
sible to modify the sensor values by an amount such
that the residuals never cross the detection thresholds.
3. Attack on Control Inputs: In the third type of attack,
the attacker changes the inputs to the actuators. In
our case of study, the user demand patterns are the
control inputs. By changing the user demands, the at-
tacker makes the controller think the demand has been
modiﬁed, ultimately leading to over/under pumping
of water. An schematic example of such an attack is
shown in Figure 5. This attack is executed on the
EPANET simulator and the details of the attack are
not available to us. This is intentionally done to test
our detection methods against completely unknown at-
tacks. Although we do not explicitly model these in-
put attacks, we observe that they lead to changes in
ttack atnput105the residuals such that our residual-based detection
methodology can be used as well.
4. PERFORMANCE LIMITATIONS OF
ATTACK DETECTORS
As speciﬁed in the previous section, it is important to
carefully select the parameters of the detectors. For the
bad-data detector, we only have to take care of threshold αi
but for CUSUM, we have two parameters, the bias bi and
the threshold τi. For selecting the thresholds, it is intuitive
to select them not too small or too large. Small thresholds
result in increased false alarms while large ones may result
in undetected attacks. For the CUSUM, too small values of
bias bi leads to unbounded growth of the CUSUM sequence
while too large bi hides the eﬀect of the attacker.
In [19,
20], the authors present tools for selecting bi and τi based
on the statistical properties of the distance measure zk,i. In
what follows, we brieﬂy introduce these tools.
4.1 Boundedness and False Alarm Rate
Consider the closed-loop system (1),(3)-(6). Assume that
sensors yk,i are monitored for attack detection. First, for
i ∈ {1, ..., m}, let δk,i = 0 and consider the CUSUM pro-
cedure (13) with distance measure zk,i = |rk,i| and residual
sequence (7). According to Theorem 1 in [19], the bias bi
must be selected larger than ¯bi = σi
square boundedness of Sk,i independent of the threshold τi.
The standard deviation σi is given by the square root of the
i-th entry of the residual covariance matrix Σ given in (9).
In our analysis we set bi = 2¯bi. Next, for the desired false
alarm rate A∗
i = 0.01(1%), we compute the corresponding
thresholds τi = τ∗
i , using Theorem 2 and Remark 2 in [19].
For the bad-data detector, we can also ﬁnd the thresholds
(cid:112)2/π to ensure mean
αi using the tools [19]. That is, if
√
∗
i :=
−1(1 − A∗
i ),
2σierf
αi = α
(16)
where erf(·) denotes the error function [15]. Then, Ai =
A∗
i for attack-free systems with rk,i ∼ N (0, σ2
i ), where Ai
denotes the actual false alarm rate and A∗
is the desired
false alarm rate.
4.2 State Estimation Under Attacks
i
In this section, we assess the performance of the bad-data