### Cookie Value and Ad Traffic Analysis

#### Key Fields in Ad Data
- **Creative ID**: A unique identifier assigned to each creative (ad) for tracking purposes.
- **Section ID**: A unique identifier for the specific ad space where the ad was displayed. For sold arbitrage traffic, this corresponds to a section ID owned by NETWORKX. For local traffic, it corresponds to a section ID owned by a local publisher. This field is not populated for auction or purchased arbitrage traffic.
- **Referrer**: The URL of the referring website for local publisher traffic, or a subdomain of NETWORKX for sold arbitrage traffic. This field is not populated for auction or purchased arbitrage traffic.
- **Impression/Click/Conversion**: Indicates whether the event was an impression, a click, or a conversion.
- **Advertiser Cost/Publisher Revenue**: The amount paid to the publisher and the amount charged to the advertiser. The difference between these values represents the earnings of the intermediary ad networks.
- **Buyer ID**: A unique identifier for each advertiser, or a network-owned buyer ID for bought arbitrage traffic. For auction traffic, this field is populated with the ID of a trusted partner network.
- **Seller ID**: A unique identifier for each publisher, or a network-owned seller ID for sold arbitrage traffic. For auction traffic, this field is populated with the ID of a trusted partner network, not a publisher.
- **User Agent ID**: Identifies the user-agent field specified in the HTTP headers. RightMedia currently enumerates 40 different types of browsers and versions.
- **Region ID**: Identifies local geographical areas (state, province, or city) using IP-address-based geo-location services.

#### Access to Network Accounts
Our close collaboration with NETWORKX provided us with access to advertiser and publisher accounts managed by the network. This allowed us to gather additional information from the data feed for local traffic, such as the domains used by publishers to sign up, their activity duration, and traffic statistics. This data enabled us to compare our results with RightMedia’s software, which was running on NETWORKX’s server. However, for auction and arbitrage traffic, we could not link IDs to real publisher accounts in RightMedia, limiting our analysis to local traffic.

#### Data Collection and Analysis
We analyzed ten days of data collected from NETWORKX, specifically from April 20 to April 30, 2011, totaling 513,644,248 impressions across all data flows. Table 1 outlines the overall statistics for each traffic flow. We focused on local publisher traffic due to its comprehensive information per impression. Out of NETWORKX’s 1,600 publishers, only about 300 were active, with the top 1% responsible for 40% of the local traffic and the top 10% for 92% of the local traffic. Our analysis revealed a click-through rate (CTR) of 0.56%, a conversion rate of 2.22%, an average CPM of $0.084, an average CPC of $0.017, and an average CPA of $0.055. We also found that there were approximately 1.5 unique cookie IDs per IP address in an hour, responsible for 2.4 impressions.

| Traffic Flow | Impressions (per hour) | CTR | Conversion Rate |
|--------------|------------------------|-----|-----------------|
| Auction      | 305,318                | 0.16% | 0.01%           |
| Publishers   | 15,794                 | 0.56% | 0.007%          |
| Arbitrage    | 489,184                | 0.12% | -               |

#### Establishing Ground Truth
To evaluate the effectiveness of our analysis and detection models, we needed ground truth about known good and bad publishers. Given that NETWORKX’s traffic came from a small number of publishers, we manually analyzed the top 100 publishers by visiting the referrer URLs of their ad requests. We used the following heuristics to determine the legitimacy of the sites:

**Indicators of Fraud:**
- The site does not serve content or serves non-renderable content.
- The site contains mostly ad content with little actual user content.
- The site hosts illegal content or content against RightMedia’s terms of use.
- The content is stolen or consists of leftover HTML templates.

**Indicators of Legitimacy:**
- The site is well-designed, visually appealing, and user-friendly.
- The site has a high Alexa ranking, especially compared to its NETWORKX traffic.
- The site features legitimate content with user engagement, such as comments or social media "likes."

A site was flagged as either good or bad if it conformed to multiple heuristics in one category and none in the other. Of the 100 publishers analyzed, 11 were identified as likely fraudulent, and 20 were identified as likely legitimate. These findings were verified by NETWORKX’s development team and CEO, leading to the termination of the malicious publishers’ accounts. None of the terminated publishers attempted to contact NETWORKX for outstanding payments or account renewal.

### Identifying Suspicious Traffic

#### Techniques for Detecting Fraudulent Ad Traffic
We explored two main approaches for detecting fraudulent ad traffic: reverse spidering and statistical modeling of ad request properties.

**4.1 Reverse Spidering**
To detect malware, we developed a reverse auditing system that crawled the referrers of each impression in our data feed. We deployed 50 virtual machines using the Selenium software-testing framework to programmatically control a real web browser. For each audit, we extracted the section ID fields on the web page and compared them with the section ID values from NETWORKX’s data feed. If the referring page did not contain the expected section ID, we inferred that the request might have been hijacked.

However, this method was not effective in practice. After several months of operation (August 2010 - April 2011), we found that 79.2% of the referred pages contained no section IDs. Manual analysis revealed that many sites used IP-address-based geo-location and ad delivery optimization services, making it difficult to distinguish between legitimate and fraudulent traffic. Therefore, we concluded that reverse spidering has significant limitations for fraud detection.

**4.2 Modeling Ad Requests**
We introduced several features to model the properties of ad traffic and establish models of normal, expected traffic. When certain requests deviate from these models, they are considered suspicious. We used the fraction of suspicious traffic per publisher to detect potential fraud.

**4.2.1 Building Models**
- **Impressions Per Cookie**: The number of impressions generated by each cookie. High values indicate potential fraud.
- **CTR Per Cookie**: The click-through-rate for each cookie. Values above 2% are suspicious.
- **Publisher Revenue Per Cookie**: The revenue generated for a publisher by each cookie. High values indicate potential fraud.
- **Unique IP Addresses Per Cookie**: The number of unique IP addresses a cookie generates requests from. High values are suspicious.
- **Impressions Per IP Address**: The number of impressions generated by each IP address. High values are suspicious.
- **CTR Per IP Address**: The CTR for each IP address. High values are suspicious.
- **Publisher Revenue Per IP Address**: The revenue generated for a publisher by each IP address. High values are suspicious.
- **Deviation of CTR Per IP Address**: The standard deviation of CTR values over time. Low values indicate potential fraud.

**Thresholds**
We used dynamic thresholds to determine which features are considered suspicious. Each threshold is computed based on historical data, and the threshold value is set to the mean plus N standard deviations. The values of N were empirically determined and are shown in Table 2.

| Anomaly Detection Algorithm | Threshold (Standard Deviation) |
|-----------------------------|--------------------------------|
| Impressions Per Cookie      | 3                              |
| CTR Per Cookie              | 3                              |
| Publisher Revenue Per Cookie| 2                              |
| Unique IP Addresses Per Cookie | 2                        |
| Impressions Per IP Address  | 4                              |
| CTR Per IP Address          | 4                              |
| Publisher Revenue Per IP Address | 3                     |

**Classifying Publishers**
For each time window (one hour), we identified cookies and IP addresses that violated at least one feature threshold. Using this information, we determined the publishers associated with these requests and calculated the fraction of suspicious requests for each publisher. This fraction served as an anomaly score, which was compared to an anomaly threshold to identify potentially fraudulent publishers.

**4.2.2 Evaluating Models**
We applied the models to our dataset and computed anomaly scores for each publisher. We then compared these scores to varying thresholds to classify publishers as suspicious or legitimate. Using our ground truth, we evaluated the performance of the models. No single model was reliable, with the best models achieving detection rates between 60% and 80% but also incorrectly flagging 10% of legitimate publishers. This indicates the need for more sophisticated methods to accurately distinguish between malicious and legitimate traffic. Nevertheless, these simple models can guide human analysts to focus on the most suspicious publishers.