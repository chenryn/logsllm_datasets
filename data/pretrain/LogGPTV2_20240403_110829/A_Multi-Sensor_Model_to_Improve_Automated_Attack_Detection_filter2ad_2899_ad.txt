### Web Server and Snort Heartbeat Simulation

To simulate a heartbeat for the Snort intrusion detection system (IDS), we added a special rule. We simulated the failure of the internal Snort sensor by terminating its process. All alerts generated during this simulation were collected and analyzed, with the results summarized in Table 3. The table does not include the conditional probability \( P(w1 = T | \ldots) \) for Example 2, but these values are similar to those shown in column 4 for Example 1. For instance, when there is no heartbeat, the probability that the internal sensor \( S1 \) is functioning is only 0.01.

Based on our decision function, we would further investigate the following cases:
- For Example 1: Case 1-4 and Case 1-6.
- For Example 2: Case 2-3, Case 2-4, and Case 2-6.

### Sensitivity Analysis

One limitation of our model is the difficulty in accurately estimating parameters. To address this, we perturbed each estimate in the model by 20% and recalculated the probability for node `inv-A`. In Example 1, there are 13 independent parameters, and the option to either add or subtract 20% from each estimate results in \( 2^{13} \) test cases. For each test case, we compared the outcome of the decision function (i.e., investigate or do not investigate) with the unperturbed network. No differences were observed, indicating that the model is relatively robust against estimation errors.

### Discussion

Columns 2 and 6 in Table 3 show the probability of a serious attack requiring investigation, given the observable evidence in the network. In a real system, we would likely use a decision function to categorize the outcomes as "investigate" or "do not investigate." Let's examine the results in detail.

#### Analysis of Scenario 1

In the upper half of Table 3 for Scenario 1, we do not encrypt the requests. Both sensors are operational, and we require alerts from both to investigate an attack. If only the web sensor raises an alert (Case 1-2), it is likely a normal request, as reflected by the low value of \( P(\text{inv-A} | \ldots) \). Similarly, if only Snort raises an alert (Case 1-3), no PHP script was executed, and the attack did not propagate. If both sensors raise alerts (Case 1-4), further investigation is warranted, as indicated by the high value.

In the lower part of Table 3, all requests are encrypted. There are no alerts, but the observed encrypted traffic is not considered highly sensitive, leading to a low value for Case 1-5. However, this value is five times that of Case 1-1, as only one sensor is operational. If the web IDS raises an alert when traffic is encrypted (Case 1-6), further investigation is recommended. The absence of an alert from Snort suggests either no attack or a non-functional Snort, with \( P(w1 = T | \ldots) = 0.01 \).

#### Analysis of Scenario 2

For Scenario 2, we receive a heartbeat from the internal Snort sensor. When there are no alerts (Case 2-1) or only the external sensor raises an alert (Case 2-2), the risks are low. Case 2-3 is interesting: an internal alert with no external alert suggests the external sensor is broken (\( P(w2 = T | \ldots) = 0.08 \)), and the alert should be investigated. If both sensors raise alerts (Case 2-4), further investigation is necessary.

In the lower part of Table 3, there is no heartbeat from the internal Snort sensor. An alert from the external sensor (Case 2-6) is more serious, as the lack of an internal alert indicates a broken sensor (S1), as discussed in Section 5.3.

#### Summary

The model adapts to environmental changes, as seen in the different evaluations of Case 1-2 and Case 1-6, and Case 2-2 and Case 2-6. The model can also predict sensor failures, as in Cases 1-5, 1-6, 2-3, 2-5, and 2-6. Our examples illustrate the basic principles of the model while remaining easy to understand. In real-world settings, the models would be more complex, incorporating both encrypted traffic and heartbeats. Adjusting the weight of evidence based on vulnerability scans could also enhance the model.

### Related Work

Several research groups have developed correlation techniques to cluster related alerts, reducing the number of alerts for security operators. These methods, however, do not alleviate the need for detailed analysis to determine if an attack is in progress. Our approach complements these efforts and can preprocess data before applying our model. Other approaches, such as Debar et al. [9] and Ning et al. [18], focus on recognizing predefined attack scenarios or correlating based on attacker capabilities, but they do not resolve conflicting evidence or model IDS failure modes as we do.

Other researchers, like Abad et al. [1], use data mining to correlate logs, while Dagorn [8] proposes a cooperative IDS using a Bayesian framework. Tombini et al. [20] combine anomaly and misuse IDSs, but they do not consider sensor failure. Morin et al. [17] introduce a formal model for correlation but do not provide a method to solve inconsistencies. Kruegel et al. [13] use Bayesian networks for OS call analysis, while Yu et al. [21] and Zhai et al. [22] use hidden colored Petri nets and Bayesian networks, respectively, but do not explicitly model IDS weaknesses.

### Future Work

We plan to extend our sensor models and test the system in more challenging environments to identify limitations and improvements. Adding a general threat node to adjust sensitivity based on operator input and developing a better-tailored sensor are also future goals.

### Conclusions

We have proposed and validated an intrusion detection model that analyzes alerts from multiple audit sources to improve overall detection accuracy. Our Bayesian network-based model resolves conflicting evidence and accounts for sensor states, reasoning about both positive and negative alerts. Our experiments demonstrate the model's ability to correctly interpret multi-source evidence and detect sensor failures.

### Acknowledgments

We thank our colleagues Daniel Hedin, Marina Papatriantaﬁlou, David Sands, and Alfonso Valdes for their valuable comments. This work was supported by the Swedish Emergency Management Agency.

### References

1. Abad, C., Taylor, J., Sengul, C., Yurcik, W., Zhou, Y., Rowe, K.: Log correlation for intrusion detection: A proof of concept. In: ACSAC 2003: Proceedings of the 19th Annual Computer Security Applications Conference, p. 255. IEEE Computer Society, Los Alamitos (2003)
2. Almgren, M., Debar, H., Dacier, M.: A lightweight tool for detecting web server attacks. In: Tsudik, G., Rubin, A. (eds.) Network and Distributed System Security Symposium (NDSS 2000), San Diego, USA, February 3–4, 2000, pp. 157–170. Internet Society (2000)
3. Almgren, M., Jonsson, E., Lindqvist, U.: A comparison of alternative audit sources for web server attack detection. In: Erlingsson, ´U., Sabelfeld, A. (eds.) 12th Nordic Workshop on Secure IT Systems (NordSec 2007), October 11–12, pp. 101–112. Reykjav´ık University, Iceland (2007)
4. Axelsson, S.: The base-rate fallacy and its implications for the difficulty of intrusion detection. In: Proceedings of the 6th ACM Conference on Computer and Communications Security, November 1999. Kent Ridge Digital Labs (1999)
5. Breese, J., Koller, D.: Tutorial on Bayesian Networks. Internet (1997), http://robotics.stanford.edu/∼koller/BNtut/BNtut.ppt
6. Cheung, S., Lindqvist, U., Fong, M.W.: Modeling multistep cyber attacks for scenario recognition. In: DARPA Information Survivability Conference and Exposition (DISCEX III), Washington, DC, April 22–24, 2003, vol. I, pp. 284–292 (2003)
7. Cuppens, F., Miege, A.: Alert correlation in a cooperative intrusion detection framework. In: Proceedings of the IEEE Symposium on Security and Privacy, Oakland, CA, May 2002, pp. 202–215. IEEE Press, Los Alamitos (2002)
8. Dagorn, N.: Cooperative intrusion detection for web applications. In: Pointcheval, D., Mu, Y., Chen, K. (eds.) CANS 2006. LNCS, vol. 4301, pp. 286–302. Springer, Heidelberg (2006)
9. Debar, H., Wespi, A.: Aggregation and correlation of intrusion-detection alerts. In: RAID 2000: Proceedings of the 4th International Symposium on Recent Advances in Intrusion Detection, pp. 85–103. Springer, Heidelberg (2001)
10. Decision Systems Laboratory, University of Pittsburgh. SMILE reasoning engine for graphical probabilistic model (2008), http://dsl.sis.pitt.edu
11. Domingos, P., Pazzani, M.: On the optimality of the simple Bayesian classifier under zero-one loss. Machine Learning 29(2-3), 103–130 (1997)
12. Hernan, S.V.: ‘phf’ CGI script fails to guard against newline characters. CERT/CC; Internet (January 2001), http://www.kb.cert.org/vuls/id/20276
13. Kruegel, C., Mutz, D., Robertson, W., Valeur, F.: Bayesian event classification for intrusion detection. In: ACSAC 2003: Proceedings of the 19th Annual Computer Security Applications Conference, p. 14. IEEE Computer Society, Los Alamitos (2003)
14. Kruegel, C., Valeur, F., Vigna, G.: Intrusion Detection and Correlation. Advances in Information Security, vol. 14. Springer, Heidelberg (2005)
15. Marty, R.: Thor - a tool to test intrusion detection systems by variations of attacks. Master’s thesis, Swiss Federal Institute of Technology (ETH), Institut f¨ur Technische Informatik und Kommunikationsnetze (TIK), Zurich, Switzerland (2002), http://www.raffy.ch/projects/ids/thor.ps.gz
16. Morin, B., Debar, H.: Correlation of intrusion symptoms: An application of Chronicles. In: Vigna, G., Jonsson, E., Kruegel, C. (eds.) RAID 2003. LNCS, vol. 2820, pp. 94–112. Springer, Heidelberg (2003)
17. Morin, B., M´e, L., Debar, H., Ducass´e, M.: M2D2: A formal data model for IDS alert correlation. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, pp. 115–137. Springer, Heidelberg (2002)
18. Ning, P., Cui, Y., Reeves, D.S.: Analyzing intensive intrusion alerts via correlation. In: Wespi, A., Vigna, G., Deri, L. (eds.) RAID 2002. LNCS, vol. 2516, pp. 74–94. Springer, Heidelberg (2002)
19. Swets, J.A.: Measuring the accuracy of diagnostic systems. Science 240(4857), 1285–1293 (1988)
20. Tombini, E., Debar, H., M´e, L., Ducass´e, M.: A serial combination of anomaly and misuse IDSes applied to HTTP traffic. In: ACSAC 2004: Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC 2004). IEEE Computer Society, Los Alamitos (2004)
21. Yu, D., Frincke, D.: Improving the quality of alerts and predicting intruder’s next goal with hidden colored petri-net. Comput. Netw. 51(3), 632–654 (2007)
22. Zhai, Y., Ning, P., Iyer, P., Reeves, D.S.: Reasoning about complementary intrusion evidence. In: ACSAC 2004: Proceedings of the 20th Annual Computer Security Applications Conference, Washington, DC, USA, pp. 39–48. IEEE Computer Society, Los Alamitos (2004)
23. Zhou, J., Heckman, M., Reynolds, B., Carlson, A., Bishop, M.: Modeling network intrusion detection alerts for correlation. ACM Trans. Inf. Syst. Secur. 10(1), 4 (2007)