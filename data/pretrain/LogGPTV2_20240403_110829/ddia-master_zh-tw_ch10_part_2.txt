[^i]: 有些人认为 `cat` 这里并没有必要，因为输入档案可以直接作为 awk 的引数。但这种写法让线性管道更为显眼。
```bash
cat /var/log/nginx/access.log | #1
  awk '{print $7}' | #2
  sort             | #3
  uniq -c          | #4
  sort -r -n       | #5
  head -n 5          #6
```
1. 读取日志档案
2. 将每一行按空格分割成不同的栏位，每行只输出第七个栏位，恰好是请求的 URL。在我们的例子中是 `/css/typography.css`。
3. 按字母顺序排列请求的 URL 列表。如果某个 URL 被请求过 n 次，那么排序后，档案将包含连续重复出现 n 次的该 URL。
4. `uniq` 命令透过检查两个相邻的行是否相同来过滤掉输入中的重复行。`-c` 则表示还要输出一个计数器：对于每个不同的 URL，它会报告输入中出现该 URL 的次数。
5. 第二种排序按每行起始处的数字（`-n`）排序，这是 URL 的请求次数。然后逆序（`-r`）返回结果，大的数字在前。
6. 最后，只输出前五行（`-n 5`），并丢弃其余的。该系列命令的输出如下所示：
```
    4189 /favicon.ico
    3631 /2013/05/24/improving-security-of-ssh-private-keys.html
    2124 /2012/12/05/schema-evolution-in-avro-protocol-buffers-thrift.html
    1369 /
     915 /css/typography.css
```
如果你不熟悉 Unix 工具，上面的命令列可能看起来有点吃力，但是它非常强大。它能在几秒钟内处理几 GB 的日志档案，并且你可以根据需要轻松修改命令。例如，如果要从报告中省略 CSS 档案，可以将 awk 引数更改为 `'$7 !~ /\.css$/ {print $7}'`, 如果想统计最多的客户端 IP 地址，可以把 awk 引数改为 `'{print $1}'`，等等。
我们不会在这里详细探索 Unix 工具，但是它非常值得学习。令人惊讶的是，使用 awk、sed、grep、sort、uniq 和 xargs 的组合，可以在几分钟内完成许多资料分析，并且它们的效能相当的好【8】。
#### 命令链与自定义程式
除了 Unix 命令链，你还可以写一个简单的程式来做同样的事情。例如在 Ruby 中，它可能看起来像这样：
```ruby
counts = Hash.new(0)         # 1
File.open('/var/log/nginx/access.log') do |file|
    file.each do |line|
        url = line.split[6]  # 2
        counts[url] += 1     # 3
    end
end
top5 = counts.map{|url, count| [count, url] }.sort.reverse[0...5] # 4
top5.each{|count, url| puts "#{count} #{url}" }                   # 5
```
1. `counts` 是一个储存计数器的杂凑表，储存了每个 URL 被浏览的次数，预设为 0。
2. 逐行读取日志，抽取每行第七个被空格分隔的栏位为 URL（这里的阵列索引是 6，因为 Ruby 的阵列索引从 0 开始计数）
3. 将日志当前行中 URL 对应的计数器值加一。
4. 按计数器值（降序）对杂凑表内容进行排序，并取前五位。
5. 打印出前五个条目。
这个程式并不像 Unix 管道那样简洁，但是它的可读性很强，喜欢哪一种属于口味的问题。但两者除了表面上的差异之外，执行流程也有很大差异，如果你在大档案上执行此分析，则会变得明显。
#### 排序 VS 记忆体中的聚合
Ruby 指令码在记忆体中储存了一个 URL 的杂凑表，将每个 URL 对映到它出现的次数。Unix 管道没有这样的杂凑表，而是依赖于对 URL 列表的排序，在这个 URL 列表中，同一个 URL 的只是简单地重复出现。
哪种方法更好？这取决于你有多少个不同的 URL。对于大多数中小型网站，你可能可以为所有不同网址提供一个计数器（假设我们使用 1GB 记忆体）。在此例中，作业的 **工作集**（working set，即作业需要随机访问的记忆体大小）仅取决于不同 URL 的数量：如果日志中只有单个 URL，重复出现一百万次，则散列表所需的空间表就只有一个 URL 加上一个计数器的大小。当工作集足够小时，记忆体散列表表现良好，甚至在效能较差的膝上型电脑上也可以正常工作。