Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1888
and stuff like this, we basically once a month tag
a version and push them out.” — P18.
Aside from set release windows, participants often mentioned
a more flexible approach to vulnerability fixes, e. g., “If you
have a vulnerability, Spectre, Meltdown, or something like
that,
then it can also happen that updates are released
completely unscheduled.” (P01).
The majority of our participants does not seem to specifi-
cally advertise new releases, e. g., “Most people who interact
with this project don’t actually even look at my GitHub. They
don’t look at the release assets or anything like that, they just
use [package registry] and it just works from there. They pull
it down and use it automatically.” (P24). Of the ones that
do advertise, preferred channels included social channels like
Twitter, Slack, or IRC (3), mailing lists (3), and websites (2).
Again, our participants seem to prefer a practical approach for
deprecating insecure or out-of-date releases, e. g., by simply
stopping support: “We only guarantee that we will backport
security fixes to the last two releases. So anything before
that
is not an LTS we will not fix, which could be seen
as deprecated from this point of view.” (P25) and “I don’t
have any official policy of supporting old versions, so they’re
effectively deprecated as soon as I release a new version.”
(P27).
they utilize external
For distributing releases, 12 participants specifically men-
tion that
infrastructure such as reg-
istries, app stores, or package managers. As a reason for not
distributing binary releases, P15 points to their community
composition: “We have no [binary] releases. We always build
the project ourselves, there are no pre-built binaries for end
users, because there are practically no end users.” (P15), as
well as P25: “All of our releases are done on GitHub tags,
because we release via source code, not via binaries, so it’s
a software release in the form of a git tag.” (P25).
Of our participants, 11 were aware of their projects’ releases
being signed. Their reasons for not or not correctly signing
releases included technical limitations:
“The Mac build is signed by my developer key, but
the builds for Raspberry Pi, Linux, Windows, they’re
unsigned. People just have to trust the integrity that
I’m the only person who has access to those and I
did it right. We’d love to have better solutions for
that, but none are available right now.” — P09,
Another reason was their general signing setup, which lead to
key ownership problems:
“[. . .] because our release procedure checklist only
states sign, meaning sign them in general. So people
use their GPG signing keys, and there is no control
where and how those keys are verified or belong to
a particular key ring. So this is something we need
to improve.” — P25.
Generally, our participants seem to be aware of the security
benefits of signing and releasing checksums of releases, but
some are not utilizing it for (all) releases due to technical
limitations and platform restrictions.
Summary: Releases and Updates. Our participants mostly
publish projects’ releases and updates based on direct com-
munity input and feedback, often mentioning exceptions
from their usual schedule for vulnerability fixes. Release
distribution and deprecation appear to be oriented towards
practicality, utilizing package registries and other distribu-
tion infrastructures, again depending on the needs of their
users.
F. Roles and Responsibilities
In this section, we sought to establish what hierarchies exist
between contributors in the participants’ projects and how they
affect the decision making process. We were also interested
in roles that directly deal with the projects’ security and role-
specific duties.
the top of
the pyramid,
Somewhat unsurprisingly, participants involved in projects
with corporate stakeholders frequently mentioned sophisti-
cated management structures that oversee the project’s de-
velopment: “At
there’s the PMC,
the project management committee and they’re essentially the
people who either funded the project or major industrial, or
representatives of major industrial partners.” (P13). Most of
our participants described the contributor hierarchy in their
projects as having two levels: The core team that is tasked
with reviewing code submissions and that has permissions to
merge new code into the source tree and everyone else whose
code is subject to the code review process. The core team was
often called a group of maintainers or simply committers:
“There’s two classes of contributors. There are the
maintainers and then there’s pretty much everyone
else. The maintainers are me and maybe seven other
people who contribute regularly to the project [. . .]
They can push directly to the main branch of the
project.” — P13.
Other projects make a distinction between the core team and
the project’s owners or they even have a dedicated role for
developers who have the ability to manipulate the repository
itself, e. g., by pushing to branches corresponding to pull
requests: “[. . .] then there are about [a few] people who have
maintainer status, so they can merge requests. And then there
are about a hundred people who have developer access, so
they can push to a branch inside the merge request.” (P26).
Some projects take centralization further and follow the so-
called Benevolent Dictator for Life (BDFL) model, where the
project’s founder steers the overall direction of the project and
has the final say in disputes: “[The project] is what [one of
our contributors] has dubbed a do-ocracy, and that is basically
whoever’s writing the code gets to decide how it’s done, but
our benevolent dictator has the final say so. We essentially
have this benevolent dictator, and everybody else under that.”
(P09). Participants whose projects have not grown out of
corporate contexts often mentioned a more relaxed contributor
structure, with direct influences on the code review process:
“It is basically a much more peer-to-peer structure
than a hierarchical structure. If you develop some-
thing, you don’t need to submit it to somebody to
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1889
get it into the tree. You do need to get a review from
people who are competent in this area, but that’s
all.” — P08.
Only five participants stated they were aware of roles within
their projects that deal with security. P08 summarized the
security team’s obligations as follows: “You can communicate
privately with the security team. They would classify your
issues and decide if it matches the criteria for the issued secu-
rity notice, how to proceed with patches, and how to publish
them.” (P08). Three of the five participants mentioned roles
that are not primarily or only indirectly involved with security,
such as IT departments or sysadmins: “We obviously have a
IT department that would follow up on [security incidents].”
(P19). Relying on a security response team existing within
the parent organization or foundation of the project was more
uncommon, which two participants reported: “There is a whole
security team at [organization]. They are pre-vetting those
issues, and filtering them, and contacting the PMC members
of the projects involved, whenever they see there is a need to
follow up on certain security issues.” (P11).
Summary: Roles and Responsibilities. Our participants’
projects have a variety of contributor hierarchies which
are mostly relatively flat with two levels. This practical
approach seems to be prevalent in projects of any size, bar
very small (single person) projects or ones that grew out
of a corporate context. Most of the projects do not staff
teams dedicated to project security, with some either relying
on their organization’s resources or leveraging members of
other teams such as their IT administrators.
G. Trust Processes
In this section, we explore the general
trust model of
projects, as well as their handling of and strategies for trust
challenges. We were also interested in how recently onboarded
contributors can become trusted members and if identity
checks or the the signing of a CLA is required.
Trust Models: Establishing trust for new committers is an
important step in the OSS onboarding process. The majority
of our participants described some form of meritocracy when
asked how new contributors gain trust within the community,
i. e., by making frequent, high-quality contributions to the
project:
“So it’s purely on contributions to the project, so it’s
meritocracy based. And this means that the person
essentially starts usually either just helping out on
filing issues like well documented issues, filing pull
requests and again well documented, reviewing pull
requests is also an important aspect of it.” — P22.
A less common approach involves trusting unknown contrib-
utors by default and giving them access early in the hope of
facilitating first-time contributions: “I really want to empower
people to contribute. [. . .] it’s very easy to get access to [the
project]. It’s not like super easy, but you just submit patches
and if you do some useful work, I default to just give you the
commit access.” (P16).
CLAs appear to be still somewhat rare, with only four
participants mentioning that their projects require one, e. g.,
“For licensing purposes, we require a [CLA], because
the project is licensed under the BSD license. We
have to have people assign their copyright, so when
people want to contribute, they fill out a form, just
sign it. It says, ‘Hey, I’m releasing my contributions
under the Berkeley Style License’.” — P09.
This low number agrees with the personal impressions of
some of our participants, e. g., “[. . .] I think that was the only
time I ever had to [sign a CLA], and I’ve submitted lots of
pull requests to many different projects. It doesn’t seem to be
very widely used.” (P24). In our interviews, projects affiliated
with corporate stakeholders or other organizations appear to
be more likely to require a CLA.
Trust Incidents: The term “trust incident” can cover a wide
field of potential incidents, including social conflicts due to
open source project often being community-focused. Still, the
majority of participants, 20, reported to never have experienced
a trust incident (by their definition) in their projects. Described
trust incidents included drive-by cryptocurrency miner com-
mits, failed background checks, and a pro-active block after
potential SSH key theft. Somewhat unsurprisingly, larger and
likely older projects appear to have had more experience with
trust incidents in the past.
The fact that most projects have never experienced a trust
incident is also reflected in their incident handling strategy,
with multiple participants reporting not having previously
thought about such cases, e. g., “[. . .] since it has never
happened, it is not something I have thought about.” (P26).
Reported incident response strategies, especially by smaller
projects, seem to be decided on a case-by-case basis, e. g.,
“[Incident response] is decided dynamically from case to case.
The infrastructures are so small that you can do this relatively
quickly. So it’s not like in the company that we have incident
playbooks. There are too few people involved for that.” (P01).
Again, larger and likely older projects appear to have a more
codified incident handling strategy in place. Two participants
pointed to their project’s or organization’s code of conduct,
which codifies the steps to take in the case of a breach of
trust:
“That is one place where then the code of conduct
will start to kick in. We actually have an enforcement
section for code of conduct with a step-by-step esca-
lation, which basically ends up with everything from
just asking someone not to do something through to
banning them and removing access.” — P27
Summary: Trust Processes. Most of our participants use
some form of meritocracy for establishing trust with new
contributors, with some even assuming trustworthiness by
default to facilitate first-time contributions. The majority
of participants never experienced a trust incident in their
projects and also did not establish specific trust incident
strategies. Larger, likely older projects seem to have more
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:27 UTC from IEEE Xplore.  Restrictions apply. 
1890
past experience with incidents, and often offer more specific
strategies.
H. Opinions and Improvements
Lastly, we asked participants about both the internal and
external reputation of their project in the context of security,
as well as how they would personally like to improve security
and trust in their projects.
With one exception, all participants reported a high internal
reputation of their projects, e. g., “Amongst the people on
the project, everybody trusts it a lot.” (P09) and “We follow
very, very high standards there, mainly because we have a
few people who are very, very keen on that.” (P11). The
same generally holds true for the external reputation, although
many participants are unsure about the actual awareness of the
project outside of their community. Overall, our participants
appear to take pride in their projects, but are quite humble
about their importance and reach in the OSS ecosystem.
We also asked our participants how they would like to
improve security and trust
in their projects, assuming no
limitations. For reporting, we roughly sorted the suggested
improvements into mainly requiring more person-hours (15),
requiring more money (9), or requiring a different infrastruc-
ture (9). Improvements requiring more person-hours focus on
alleviating past software development decisions and technical
debt, e. g., “If I could, I would write the entire stack myself.”
(P14) and “[. . .] I would rewrite a lot of the code. That’s
just a historical thing, because it has already become big and
complex [. . .] It’s just like building a house; you’d have to
build it three times before it becomes good.” (P20). Another
focus was enhancing the review process, e. g., “So the first
thing I do is that a group of people would review every pull
request exclusively from the view of security.” (P25).
Some of the improvements mainly requiring more money
also translated into necessitating more person-hours, just by
buying the time, e. g., “I could always use more participants
in the review process and so if I could hire some people, if I
had the disposable income to do that, I would probably hire
people to get more eyes on pull requests than just myself [. . .]”
(P24) and “I think getting more tools and more CI-type tools
to watch for that, because I think humans are vulnerable [. . .]
If I had unlimited budget and unlimited engineers, I’d really
work on improving our testing systems.” (P23). Other money-
based improvements included the introduction of security
bounties: “[Projects] mentioned they tried all the different
kinds of things, and the only thing that worked well was [a]
bounty process, and having bounties, and being able to reward
security researchers to bring up the security issues.” (P11).
For
improvements
requiring infrastructure, participants
mentioned improvements to build and test pipelines, e. g.,
“with unlimited resources, I would like some more investment
into automatic tools that are better in like finding vulnera-
bilities and problems with code.” (P07) and “I would like
to build [the binaries] on my own machine and then ship
the site final result. For anything binary related, that would
be way better than what we have right now.” (P18). Other
participants mentioned transitioning their projects’ codebases
to other languages, e. g. Rust: “What I’d like to do is oxidize
[the project] over time, to integrate Rust and Rust code into
the codebase – which is quite an undertaking [. . .] and an
incredibly tedious task to do it well.” (P03). Overall, even
improvements initially requiring more money or a different
infrastructure were traceable to the crux of all open source
project: the need for more contributors.
Summary: Problems and Improvements. Our participants
take pride in their projects but are quite humble about their
importance and reach in the OSS ecosystem. Overall, even
improvements initially requiring more money or a different
infrastructure ended up targeting the project’s need for more
contributors.
V. DISCUSSION
In this work, we investigated the security measures and
trust processes of a diverse set of open source project. We
conducted 27 in-depth, semi-structured interviews with open
source contributors, maintainers, and owners to explore the
following research questions:
RQ1: “How are open source projects structured behind-
the-scenes?” Our participants described their contributor hi-
erarchy as being mostly based on two levels: a core group
of maintainers tasked with reviewing code submissions and
with permissions to merge new code into the source tree and
other contributors that are subjected to a code review process.
Most of the projects do not staff dedicated security teams,
with some relying on other teams for security, such as their
IT administrators or their organization’s resources. Release
processes appear to be oriented towards practicality, including