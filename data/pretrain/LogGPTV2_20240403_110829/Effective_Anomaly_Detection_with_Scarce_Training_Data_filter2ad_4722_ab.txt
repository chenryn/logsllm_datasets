requirement typically imposed upon a training set is that
it should be attack-free – that is, it should not contain
traces of malicious activity that would induce the result-
ing models to consider malicious behavior as normal.
One solution to this issue is described in [8]. Another
requirement that a training set should satisfy is that it
should accurately represent the normal behavior of the
modeled features.
In some ways, this requirement is
the dual of the previous one: training data should com-
pletely cover all aspects of normal behavior.
The difﬁculty of obtaining sufﬁcient training data
to accurately model application behavior is intuitively
clear. We are, however, not aware of any solutions that
can address this issue when insufﬁcient training data
is available.
In a sense, this issue is similar to those
addressed by statistical analysis methods with missing
data [22]. Although a training procedure would beneﬁt
from such mechanisms, they require a complete redesign
of the training algorithm speciﬁc to each model. Instead,
a non-obtrusive approach that can improve an existing
system without modifying the undertrained models is
more desirable. Typically, anomaly-based detectors can-
not assume the presence of a testing environment that
can be leveraged to generate realistic training data that
exercises the web application in a safe, attack-free envi-
ronment. Instead, the anomaly detection system is de-
ployed in front of live web applications with no a priori
knowledge of the applications’ components and their be-
havior. If anomaly-based detectors required manual or
semi-automatic testing to be effective, their maintenance
would be as tedious as that of misuse-based systems.
/article = 475, 000
/comments = 15, 000
/comments/edit = 9, 000
/account = 900
/account/password = 100
Figure 4: Example non-uniform web application request dis-
tribution.
In the case of low-trafﬁc applications, problems arise
if the rate of client requests is inadequate to allow mod-
els to train in a timely manner. However, even in the
case of high-trafﬁc applications, a large subset of re-
source paths might fail to receive enough requests to ad-
equately train1 the associated models. This phenomenon
is a direct consequence of the fact that requests issued
by clients often follow a non-uniform distribution. To
illustrate this point, Figure 3 plots the normalized cumu-
lative distribution function of web client resource path
invocations for a variety of real-world, high-trafﬁc web
applications (details on this data are provided in Sec-
tion 4). Although several applications have an approxi-
mately uniform client access distribution, a clear major-
ity exhibit skewed distributions. Indeed, in many cases,
a large percentage of resource paths receive a compar-
atively minuscule number of requests. Returning to the
example resources shown in Figure 1, assuming an over-
all request volume of 500,000 requests per day, the ex-
ample resource path set might result in the client access
distribution shown in Figure 4.
Clearly, proﬁles for parameters to resource paths such
as /article will likely receive sufﬁcient training data.
1A more formal deﬁnition of the minimum amount of samples re-
quired for a complete training is provided in Section 3.1.
F
D
C
s
s
e
c
c
A
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
Site 1
Site 2
Site 3
Site 4
Site 5
Site 6
Site 7
Site 8
Site 9
Site 10
Site 11
Site 12
Site 13
Site 14
Site 15
Site 16
Site 17
Site 18
Site 19
Site 20
Site 21
Site 22
Site 23
Site 24
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
Figure 3: Web client resource path invocation distributions from a selection of real-world web applications.
Resources
This is not true, however, for proﬁles associated with
paths such as /account/password. Further exacerbat-
ing the situation is the fact that a client request does not
necessarily include all possible parameters.
The infeasibility for an anomaly detection system to
accurately model a large subset of a web application is
problematic in itself. We argue, however, that the impact
of the problem is magniﬁed by the fact that components
of a web application that are infrequently exercised are
also likely to contain a disproportionately large share of
security vulnerabilities. This is a consequence of the re-
duced amount of testing that developers invariably per-
form on less prominent components of a web applica-
tion, resulting in a higher rate of software defects. In ad-
dition, the relatively low request rate from users of the
web application results in a reduced exposure rate for
these defects. Finally, when ﬂaws are exposed and re-
ported, correcting the ﬂaws may be given a lower prior-
ity than those in higher trafﬁc components of a web ap-
plication. An example is the authentication manager of
a blog, which receives a low share of the trafﬁc if com-
pared with the component that handles the comments or
the archive.
Therefore, we conclude that a mechanism to address
the problem of model undertraining caused by the non-
uniform distribution of training data is necessary for a
web application anomaly detection system to provide an
acceptable level of security.
3 Exploiting global knowledge
The lack of available training data is a fundamental
obstacle when constructing accurate proﬁles for many
parameters of a web application. Without a minimum
number of requests to a given parameter, it is infeasi-
ble to construct models that encode a reasonably precise
approximation of normal behavior.
We observe, however,
that parameters associated
with the invocation of components belonging to differ-
ent web applications often exhibit a marked similarity
to each other. Referring again to the example shown in
Figure 1, many web applications take an integer value as
a unique identiﬁer for a class of objects such as a blog
article or comment, as in the case of the id parameter.
Many web applications also accept date ranges similar to
the date parameter as identiﬁers or as constraints upon
a search request. Similarly, as in the case of the title
parameter, web applications often expect a short phrase
of text as an input, or perhaps a longer block of text in
the form of a comment body. One can consider each of
these groupings of similar parameters as distinct param-
eter types, though this need not necessarily correspond
to the concept of types as understood in the program-
ming languages context.
The key insight behind our approach is that parame-
ters of the same type tend to induce model compositions
that are similar to each other in many respects. Conse-
quently, if the lack of training data for a subset of the
components of a web application prevents an anomaly
detection system from constructing accurate proﬁles for
the parameters of those components, it is possible to
substitute proﬁles for similar parameters of the same
type that were learned when enough training data was
available. It must be underlined that the substitution op-
erates at the granularity of parameters rather than re-
quests (which may contain more than one parameter).
This increases the likelihood of ﬁnding applicable pro-
ﬁle similarities, and allows for the substitution of mod-
els taken from radically different components. However,
although the experiments we run on real-world data con-
ﬁrm that the aforementioned insight is realistic, our hy-
pothesis might not hold in some very speciﬁc settings.
Thus, to minimize the risks brought by migrating global
knowledge across different deployments, we interpreted
this result only as an insight and developed a robust cri-
terion able to ﬁnd similar proﬁles independently from
the actual types of the modeled parameters.
Our approach is composed of three phases. The ﬁrst
phase, shown in Figures 5 and 6b, is an extension of
the training procedure originally implemented in [19],
where undertrained versions of proﬁles are recorded in
addition to their ﬁnal states.
In the second phase, a
global knowledge base of proﬁles C = (ai Cai is con-
structed ofﬂine, where Cai are knowledge bases contain-
ing only well-trained, stable proﬁles (right side of Fig-
ure 6a) from anomaly detection systems previously de-
ployed on a set of web applications(i ai. The left side
of Figure 6a depicts the progressive construction of the
knowledge base CI =(ai CI
ai of undertrained proﬁles(
i.e., an index into C, where CI
ai is a knowledge base of
undertrained proﬁles from the web application ai). Ad-
ditionally, we deﬁne a mapping f : )CI* ×C ai
&→ C
(shown as a dotted, directed arrow) between under-
trained and well-trained proﬁles.
The third phase is performed online. For any new
web application where insufﬁcient training data is avail-
able for a component’s parameter, the anomaly detector
ﬁrst extracts the undertrained proﬁle c!. Then, the global
knowledge base C is queried to ﬁnd a similar, previously
constructed proﬁle f+CI, c!, = c. The well-trained pro-
ﬁle c is then substituted for the undertrained proﬁle c! in
the detection process.
3.1 Phase I: Enhanced training
As a ﬁrst step, we extended the anomaly detector
described in [19] with a mechanism to generate under-
trained proﬁles from a data set. These undertrained pro-
ﬁles are generated using the following procedure. Let
Q(p)
ai = {q(p)
2 , . . .} denote a sequence of client re-
quests containing parameter p for a given web applica-
tion. Over Q(p)
ai , proﬁles are deliberately undertrained on
1 , q(p)
randomly sampled κ-sequences, where κ can take val-
ues in(8
i=0 2i (a discussion of appropriate values for κ
is deferred until Section 3.4). Each of the resulting pro-
ai. Note that
ﬁles is then added to a knowledge base CI
the random sub-sampling is performed with the goal of
inducing undertraining to show that clustering is feasible
and leads to the desired grouping even – and especially
– in the presence of undertraining.
In general, κ corresponds to a number of train-
ing samples that is considered insufﬁcient to accurately
characterize a feature. This, however, warrants a discus-
sion of what is considered sufﬁcient. An obvious choice
is to ﬁx a large, constant training phase length (e.g.,
1000 requests). Unfortunately, an appropriate training
phase length is dependent upon the complexity of mod-
eling a given set of features. Therefore, we have devel-
oped an automated method that leverages the notion of
model stability to determine when a model has observed
enough training samples to accurately approximate the
normal behavior of a parameter.
As new training samples are observed early in the
training phase, the state of a model typically exhibits
frequent and signiﬁcant change as its approximation of
the normal behavior of a parameter is updated. Infor-
mally, in an information-theoretic sense, the average in-
formation gain of each new training sample is high. As
a model’s state converges to a more precise approxima-
tion of normal behavior, its state gradually exhibits in-
frequent and incremental changes. In other words, the
information gain of new training samples approaches
zero, and the model stabilizes.
Each model monitors its stability during the training
phase by maintaining a history of snapshots of its inter-
nal state. Periodically, a model checks if the sequence of
deltas between each successive historical state is mono-
tonically decreasing and whether the degree of change
drops below a certain threshold. If both conditions are
satisﬁed, then the model is considered stable. Let κ(u)
stable
denote the number of training samples required for a
model to achieve stability. A proﬁle is considered sta-
ble when all of its constituent models are stable. Thus,
the number of training samples required for a proﬁle to
achieve stability is given by
κstable = max
u∈U
κ(u)
stable.
(3.1)
At the end of this phase, the ﬁnal state of each well-
trained, or stable, proﬁle is stored in a knowledge base
ai are collected from each web ap-
Cai. Both Cai and CI
plication, and serve as input to the next phase.
Instead of describing the internal stop criterion spe-
ciﬁc to each model, if any, we developed a model-
agnostic minimization algorithm detailed in Section 3.4
(and evaluated in Section 4) that allows one to trade off
Qa1
. . .
QaI
Training
. . .
Training
CI
a1
Ca1
CI
aI
CaI
Clustering
Q
Training
CI
C
c
CI
c
C
1st phase (oﬄine)
2nd phase (oﬄine)
3rd phase (online)
Figure 5: Overall procedure. Proﬁles, both undertrained and well-trained, are collected from a set of web applications. These
proﬁles are processed ofﬂine to generate the global knowledge base C and index CI. At another web application, given
an undertrained proﬁle c!, C can then be queried to ﬁnd a suitable replacement proﬁle c.
detection accuracy against the number of training sam-
ples available.
3.2 Phase II: Building proﬁle knowledge bases
a1,CI
a2, . . . ,CI
The second phase consists of processing the output
of the ﬁrst phase, namely the sets of knowledge bases of
both undertrained and well-trained proﬁles learned from
a variety of web applications. The goal is to create C
and CI, global knowledge bases of well-trained and un-
dertrained proﬁles, respectively, and a mapping between
the two, allowing CI to serve as an index to C.
3.2.1 Constructing global knowledge base indices
The construction of the undertrained proﬁle database
CI begins by merging a set of knowledge bases
)CI
aI* that have previously been built by
a web application anomaly detector over a set of web
applications(i ai during the ﬁrst phase. The proﬁles in
CI are then clustered to group proﬁles that are seman-
tically similar to each other. Proﬁle clustering is per-
formed in order to time-optimize query execution when
using CI as an index into C. The resulting clusters of
proﬁles in CI are denoted by H I =(i hI
i . In this work,
an agglomerative hierarchical clustering algorithm using
group average linkage was applied, although the cluster-
ing stage is agnostic as to the speciﬁc algorithm. In prin-
ciple, other mechanisms (e.g., Support Vector Machines,
Locality-Sensitive Hashing) to ﬁnd groups or classes of
similar models based on their features can be used. We
opted for a clustering algorithm as a proof-of-concept
implementation of Phase II primarily due to its simplic-