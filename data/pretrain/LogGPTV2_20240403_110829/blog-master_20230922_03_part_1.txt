## pg_tiktoken - 标记token数的工具. 防止问答超过AI大模型chatbot token上限, 导致回复截断    
### 作者            
digoal            
### 日期            
2023-09-22            
### 标签            
PostgreSQL , PolarDB , chatbot , token    
----            
## 背景       
chatbot是大模型应用之一, 在与chatbot沟通时会遇到token上限问题, 例如通义目前是8K, chatgpt是4K. 也就是问题上下文(包含多轮对话的内容)最多8k或4k, 超出就无法处理了.      
解释一下token: 对于通义模型来说, 中文字符串的token就是字数(含符号).  英文则可能是词、片段等.    
我们的核心目的是通过有限的上下文来拿到结果.     
这就需要你的prompt(上下文)足够精确, 防止无效垃圾对话浪费token限额.      
上下文的组成:    
1、每一轮对话的提问内容和大模型的回答内容    
2、外脑中的FAQ     
参考知识:     
- https://help.aliyun.com/zh/dashscope/developer-reference/api-details    
- https://neon.tech/docs/extensions/pg_tiktoken    
- https://neon.tech/docs/ai/ai-concepts    
- https://github.com/kelvich/pg_tiktoken    
## pg_tiktoken 扩展是什么?    
语言模型以称为标记的单位处理文本。标记可以短至单个字符，也可以长至完整的单词，例如“a”或“apple”。在一些语言中，标记可以包括少于单个字符或者甚至超出单个单词。    
例如，考虑“Neon 是无服务器 Postgres”这句话。它可以分为七个标记：[“Ne”、“on”、“is”、“server”、“less”、“Post”、“gres”]。    
pg_tiktoken 的核心功能是将文本转换为token, 以及统计文本的token数. 不同的大模型切token的方法可能不同, pg_tiktoken 支持多种模型.  
pg_tiktoken的2个函数:   
- tiktoken_encode：接受文本输入并返回标记化输出，使您能够无缝标记化文本数据。    
- tiktoken_count：计算给定文本中的标记数量。此功能可帮助您遵守文本长度限制，例如 OpenAI 语言模型设置的长度限制。    
## 体验pg_tiktoken  
可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/f55dbfac77c0467a9d3cd95ff6697a31)来完成.          
如果你本地有docker环境也可以把镜像拉到本地来做实验:          
x86_64机器使用以下docker image:          
- [《amd64 image》](../202307/20230710_03.md)          
ARM机器使用以下docker image:          
- [《arm64 image》](../202308/20230814_02.md)     
```  
CREATE EXTENSION pg_tiktoken;  
```  
### 使用tiktoken_encode功能    
该tiktoken_encode函数对文本输入进行标记并返回标记化的输出。该函数接受编码名称和 OpenAI 模型名称作为第一个参数，以及要标记化的文本作为第二个参数，如下所示：    
```  
SELECT tiktoken_encode('text-davinci-003', 'The universe is a vast and captivating mystery, waiting to be explored and understood.');    
tiktoken_encode     
--------------------------------------------------------------------------------    
 {464,6881,318,257,5909,290,3144,39438,10715,11,4953,284,307,18782,290,7247,13}    
(1 row)    
```  
该函数使用字节对编码 (BPE)算法对文本进行标记。    
### 使用tiktoken_count功能    
该tiktoken_count函数计算文本中标记的数量。该函数接受编码名称和 OpenAI 模型名称作为第一个参数，接受文本作为第二个参数，如下所示：    
```  
neondb=> SELECT tiktoken_count('text-davinci-003', 'The universe is a vast and captivating mystery, waiting to be explored and understood.');    
 tiktoken_count     
----------------    
             17    
(1 row)    
```  
支持以下模型：    
Encoding name	| OpenAI models  
---|---  
`cl100k_base`	|ChatGPT models, `text-embedding-ada-002`  
`p50k_base`	|Code models, `text-davinci-002`, `text-davinci-003`  
`p50k_edit`	|Use for edit models like `text-davinci-edit-001`, `code-davinci-edit-001`  
`r50k_base` (or `gpt2`)	|GPT-3 models like `davinci`  
例如我们可以设计一张表来存储问答的内容:    
```  
CREATE TABLE message (    
  role VARCHAR(50) NOT NULL,      -- equals to 'system', 'user' or 'assistant'    
  content TEXT NOT NULL,      
  created TIMESTAMP NOT NULL DEFAULT NOW(),    
  embedding vector,   -- 向量值   
  n_tokens INTEGER -- number of content tokens    
);    
```  
`gpt -3.5-turbo`聊天模型需要特定参数：    
```  
{    
  "model": "gpt-3.5-turbo",    
  "messages": [    
        {"role": "system", "content": "You are a helpful assistant."},    
        {"role": "user", "content": "Who won the world series in 2020?"},    
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."}    
    ]    
}    
```  
该messages参数是一个消息对象数组，每个对象包含两条信息：role消息发送者（system、user或assistant）的 和实际消息content。对话可以很简短，只有一条消息，也可以跨越多个页面，只要组合的消息令牌不超过 4096 个令牌的限制。    
要将role、content和标记数量插入数据库，请使用以下查询：    
```  
INSERT INTO message (role, content, n_tokens)    
VALUES ('user', 'Hello, how are you?', tiktoken_count('text-davinci-003','Hello, how are you?'));     
```  
### 管理文本标记    
当对话包含的标记多于模型可以处理的标记（例如，超过 `4096` 个标记`gpt-3.5-turbo`）时，您将需要截断文本以适应模型的限制。    
此外，冗长的对话可能会导致回复不完整。例如，如果`gpt-3.5-turbo`对话跨越 `4090` 个令牌，则响应将仅限于 `6` 个令牌。    
以下查询将检索消息，直至达到您所需的令牌限制：    
```  
WITH cte AS (    
  SELECT role, content, created, n_tokens,    
         SUM(tokens) OVER (ORDER BY created DESC) AS cumulative_sum    
  FROM message    
)    
SELECT role, content, created, n_tokens, cumulative_sum    
FROM cte    
WHERE cumulative_sum ;      
```  
``表示您想要保留以完成聊天的对话历史记录，遵循以下公式：    
```  